{"doc_key": "ai-test-1", "ner": [[5, 7, "algorithm"], [9, 11, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typical", "generative", "model", "approaches", "include", "naive", "Bayes", "classifiers", ",", "Gaussian", "mixture", "models", ",", "variational", "autoencoders", "and", "others", "."], "sentence-detokenized": "Typical generative model approaches include naive Bayes classifiers, Gaussian mixture models, variational autoencoders and others.", "token2charspan": [[0, 7], [8, 18], [19, 24], [25, 35], [36, 43], [44, 49], [50, 55], [56, 67], [67, 68], [69, 77], [78, 85], [86, 92], [92, 93], [94, 105], [106, 118], [119, 122], [123, 129], [129, 130]]}
{"doc_key": "ai-test-2", "ner": [[5, 5, "organisation"], [11, 11, "conference"], [14, 20, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 11, 11, "role", "", false, false], [14, 20, 11, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Finally", ",", "every", "two", "years", "ELRA", "organises", "a", "major", "conference", ",", "LREC", ",", "the", "International", "Conference", "on", "Language", "Resources", "and", "Evaluation", "."], "sentence-detokenized": "Finally, every two years ELRA organises a major conference, LREC, the International Conference on Language Resources and Evaluation.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 18], [19, 24], [25, 29], [30, 39], [40, 41], [42, 47], [48, 58], [58, 59], [60, 64], [64, 65], [66, 69], [70, 83], [84, 94], [95, 97], [98, 106], [107, 116], [117, 120], [121, 131], [131, 132]]}
{"doc_key": "ai-test-3", "ner": [[6, 9, "algorithm"], [12, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "task", "is", "usually", "to", "obtain", "the", "maximum", "likelihood", "estimate", "of", "the", "HMM", "parameters", ",", "given", "the", "output", "sequences", "."], "sentence-detokenized": "The task is usually to obtain the maximum likelihood estimate of the HMM parameters, given the output sequences.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 19], [20, 22], [23, 29], [30, 33], [34, 41], [42, 52], [53, 61], [62, 64], [65, 68], [69, 72], [73, 83], [83, 84], [85, 90], [91, 94], [95, 101], [102, 111], [111, 112]]}
{"doc_key": "ai-test-4", "ner": [[1, 1, "algorithm"], [4, 6, "algorithm"], [9, 9, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 9, 9, "compare", "", false, false], [4, 6, 9, 9, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Unlike", "neural", "networks", "and", "support", "vector", "machines", ",", "the", "AdaBoost", "training", "process", "selects", "only", "those", "features", "known", "to", "improve", "the", "predictive", "power", "of", "the", "model", ",", "reducing", "dimensionality", "and", "potentially", "improving", "runtime", "because", "irrelevant", "features", "do", "not", "need", "to", "be", "computed", "."], "sentence-detokenized": "Unlike neural networks and support vector machines, the AdaBoost training process selects only those features known to improve the predictive power of the model, reducing dimensionality and potentially improving runtime because irrelevant features do not need to be computed.", "token2charspan": [[0, 6], [7, 13], [14, 22], [23, 26], [27, 34], [35, 41], [42, 50], [50, 51], [52, 55], [56, 64], [65, 73], [74, 81], [82, 89], [90, 94], [95, 100], [101, 109], [110, 115], [116, 118], [119, 126], [127, 130], [131, 141], [142, 147], [148, 150], [151, 154], [155, 160], [160, 161], [162, 170], [171, 185], [186, 189], [190, 201], [202, 211], [212, 219], [220, 227], [228, 238], [239, 247], [248, 250], [251, 254], [255, 259], [260, 262], [263, 265], [266, 274], [274, 275]]}
{"doc_key": "ai-test-5", "ner": [[0, 0, "misc"], [11, 12, "misc"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 12, "part-of", "", false, false], [11, 12, 15, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Troponymy", "is", "one", "of", "the", "possible", "relationships", "between", "verbs", "in", "the", "semantic", "network", "of", "the", "Word", "Net", "database", "."], "sentence-detokenized": "Troponymy is one of the possible relationships between verbs in the semantic network of the WordNet database.", "token2charspan": [[0, 9], [10, 12], [13, 16], [17, 19], [20, 23], [24, 32], [33, 46], [47, 54], [55, 60], [61, 63], [64, 67], [68, 76], [77, 84], [85, 87], [88, 91], [92, 96], [96, 99], [100, 108], [108, 109]]}
{"doc_key": "ai-test-6", "ner": [[8, 9, "task"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 11, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "framework", "language", "is", "a", "technology", "used", "to", "represent", "knowledge", "in", "artificial", "intelligence", "."], "sentence-detokenized": "A framework language is a technology used to represent knowledge in artificial intelligence.", "token2charspan": [[0, 1], [2, 11], [12, 20], [21, 23], [24, 25], [26, 36], [37, 41], [42, 44], [45, 54], [55, 64], [65, 67], [68, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-7", "ner": [[0, 0, "metrics"], [4, 8, "metrics"], [11, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 8, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "Bilingual", "evaluation", "understudy", "in", "terms", "of", "calculating", "the", "shortening", "penalty", ",", "in", "that", "small", "variations", "in", "translation", "length", "do", "not", "have", "such", "a", "large", "impact", "on", "the", "overall", "score", "."], "sentence-detokenized": "NIST also differs from Bilingual evaluation understudy in terms of calculating the shortening penalty, in that small variations in translation length do not have such a large impact on the overall score.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 32], [33, 43], [44, 54], [55, 57], [58, 63], [64, 66], [67, 78], [79, 82], [83, 93], [94, 101], [101, 102], [103, 105], [106, 110], [111, 116], [117, 127], [128, 130], [131, 142], [143, 149], [150, 152], [153, 156], [157, 161], [162, 166], [167, 168], [169, 174], [175, 181], [182, 184], [185, 188], [189, 196], [197, 202], [202, 203]]}
{"doc_key": "ai-test-8", "ner": [[6, 7, "algorithm"], [10, 12, "algorithm"], [22, 24, "field"], [33, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[6, 7, 22, 24, "usage", "", false, false], [10, 12, 22, 24, "usage", "", false, false], [33, 38, 22, 24, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 3], "sentence": ["The", "model", "(", "e.g.", ",", "a", "neural", "network", "or", "a", "naive", "Bayes", "classifier", ")", "is", "trained", "on", "the", "training", "dataset", "using", "a", "supervised", "learning", "method", ",", "e.g.", ",", "using", "optimization", "methods", "such", "as", "gradient", "descent", "or", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The model (e.g., a neural network or a naive Bayes classifier) is trained on the training dataset using a supervised learning method, e.g., using optimization methods such as gradient descent or stochastic gradient descent.", "token2charspan": [[0, 3], [4, 9], [10, 11], [11, 15], [15, 16], [17, 18], [19, 25], [26, 33], [34, 36], [37, 38], [39, 44], [45, 50], [51, 61], [61, 62], [63, 65], [66, 73], [74, 76], [77, 80], [81, 89], [90, 97], [98, 103], [104, 105], [106, 116], [117, 125], [126, 132], [132, 133], [134, 138], [138, 139], [140, 145], [146, 158], [159, 166], [167, 171], [172, 174], [175, 183], [184, 191], [192, 194], [195, 205], [206, 214], [215, 222], [222, 223]]}
{"doc_key": "ai-test-9", "ner": [[0, 0, "product"], [8, 9, "task"], [11, 11, "task"], [13, 15, "task"], [18, 19, "task"], [25, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 0, 0, "usage", "", true, false], [11, 11, 0, 0, "usage", "", true, false], [13, 15, 0, 0, "usage", "", true, false], [18, 19, 0, 0, "usage", "", true, false], [25, 28, 0, 0, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["FrameNet", "has", "been", "used", "in", "applications", "such", "as", "question", "answering", ",", "paraphrasing", ",", "textual", "implication", "recognition", ",", "and", "information", "extraction", ",", "either", "directly", "or", "via", "semantic", "role", "tagging", "tools", "."], "sentence-detokenized": "FrameNet has been used in applications such as question answering, paraphrasing, textual implication recognition, and information extraction, either directly or via semantic role tagging tools.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 22], [23, 25], [26, 38], [39, 43], [44, 46], [47, 55], [56, 65], [65, 66], [67, 79], [79, 80], [81, 88], [89, 100], [101, 112], [112, 113], [114, 117], [118, 129], [130, 140], [140, 141], [142, 148], [149, 157], [158, 160], [161, 164], [165, 173], [174, 178], [179, 186], [187, 192], [192, 193]]}
{"doc_key": "ai-test-10", "ner": [[6, 10, "field"], [12, 12, "misc"], [15, 15, "product"], [18, 18, "misc"], [21, 21, "product"], [24, 25, "field"], [28, 28, "product"], [31, 33, "misc"], [36, 36, "product"], [38, 38, "product"], [40, 40, "product"], [43, 44, "misc"], [47, 48, "product"], [50, 51, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[15, 15, 12, 12, "general-affiliation", "", false, false], [21, 21, 18, 18, "general-affiliation", "", false, false], [28, 28, 24, 25, "general-affiliation", "", false, false], [36, 36, 31, 33, "type-of", "", false, false], [38, 38, 31, 33, "type-of", "", false, false], [40, 40, 31, 33, "type-of", "", false, false], [47, 48, 43, 44, "general-affiliation", "", false, false], [50, 51, 43, 44, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["This", "would", "include", "programs", "such", "as", "data", "analysis", "and", "extraction", "tools", ",", "spreadsheets", "(", "e.g.", "Excel", ")", ",", "databases", "(", "e.g.", "Access", ")", ",", "statistical", "analysis", "(", "e.g.", "SAS", ")", ",", "generalised", "audit", "software", "(", "e.g.", "ACL", ",", "Arbutus", ",", "EAS", ")", ",", "business", "intelligence", "(", "e.g.", "Crystal", "Reports", "and", "Business", "Objects", ")", ",", "etc", "."], "sentence-detokenized": "This would include programs such as data analysis and extraction tools, spreadsheets (e.g. Excel), databases (e.g. Access), statistical analysis (e.g. SAS), generalised audit software (e.g. ACL, Arbutus, EAS), business intelligence (e.g. Crystal Reports and Business Objects), etc.", "token2charspan": [[0, 4], [5, 10], [11, 18], [19, 27], [28, 32], [33, 35], [36, 40], [41, 49], [50, 53], [54, 64], [65, 70], [70, 71], [72, 84], [85, 86], [86, 90], [91, 96], [96, 97], [97, 98], [99, 108], [109, 110], [110, 114], [115, 121], [121, 122], [122, 123], [124, 135], [136, 144], [145, 146], [146, 150], [151, 154], [154, 155], [155, 156], [157, 168], [169, 174], [175, 183], [184, 185], [185, 189], [190, 193], [193, 194], [195, 202], [202, 203], [204, 207], [207, 208], [208, 209], [210, 218], [219, 231], [232, 233], [233, 237], [238, 245], [246, 253], [254, 257], [258, 266], [267, 274], [274, 275], [275, 276], [277, 280], [280, 281]]}
{"doc_key": "ai-test-11", "ner": [[0, 1, "organisation"], [5, 8, "researcher"], [12, 12, "organisation"], [15, 15, "product"], [21, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 8, "origin", "", false, false], [5, 8, 12, 12, "role", "", false, false], [15, 15, 21, 22, "type-of", "", false, false], [21, 22, 5, 8, "origin", "introduced_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Rethink", "Robotics", "-", "founded", "by", "Rodney", "Brooks", ",", "who", "previously", "worked", "at", "iRobot", "-", "unveiled", "Baxter", "in", "September", "2012", ",", "an", "industrial", "robot", "designed", "to", "interact", "safely", "with", "nearby", "human", "workers", "and", "that", "can", "be", "programmed", "to", "perform", "simple", "tasks", "."], "sentence-detokenized": "Rethink Robotics - founded by Rodney Brooks, who previously worked at iRobot - unveiled Baxter in September 2012, an industrial robot designed to interact safely with nearby human workers and that can be programmed to perform simple tasks.", "token2charspan": [[0, 7], [8, 16], [17, 18], [19, 26], [27, 29], [30, 36], [37, 43], [43, 44], [45, 48], [49, 59], [60, 66], [67, 69], [70, 76], [77, 78], [79, 87], [88, 94], [95, 97], [98, 107], [108, 112], [112, 113], [114, 116], [117, 127], [128, 133], [134, 142], [143, 145], [146, 154], [155, 161], [162, 166], [167, 173], [174, 179], [180, 187], [188, 191], [192, 196], [197, 200], [201, 203], [204, 214], [215, 217], [218, 225], [226, 232], [233, 238], [238, 239]]}
{"doc_key": "ai-test-12", "ner": [[1, 2, "field"], [5, 6, "task"], [8, 9, "task"], [11, 14, "task"], [16, 18, "task"], [20, 21, "task"], [23, 24, "task"], [27, 29, "task"], [36, 38, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 6, 1, 2, "part-of", "task_part_of_field", false, false], [8, 9, 1, 2, "part-of", "task_part_of_field", false, false], [11, 14, 1, 2, "part-of", "task_part_of_field", false, false], [16, 18, 1, 2, "part-of", "task_part_of_field", false, false], [20, 21, 1, 2, "part-of", "task_part_of_field", false, false], [23, 24, 1, 2, "part-of", "task_part_of_field", false, false], [27, 29, 1, 2, "part-of", "task_part_of_field", false, false], [36, 38, 1, 2, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Typical", "text", "mining", "tasks", "include", "text", "categorization", ",", "text", "clustering", ",", "concept", "/", "entity", "extraction", ",", "producing", "granular", "taxonomies", ",", "sentiment", "analysis", ",", "document", "summarization", ",", "and", "entity", "relationship", "modeling", "(", "i.e.", ",", "learning", "relationships", "between", "named", "entity", "recognition", ")", "."], "sentence-detokenized": "Typical text mining tasks include text categorization, text clustering, concept/entity extraction, producing granular taxonomies, sentiment analysis, document summarization, and entity relationship modeling (i.e., learning relationships between named entity recognition).", "token2charspan": [[0, 7], [8, 12], [13, 19], [20, 25], [26, 33], [34, 38], [39, 53], [53, 54], [55, 59], [60, 70], [70, 71], [72, 79], [79, 80], [80, 86], [87, 97], [97, 98], [99, 108], [109, 117], [118, 128], [128, 129], [130, 139], [140, 148], [148, 149], [150, 158], [159, 172], [172, 173], [174, 177], [178, 184], [185, 197], [198, 206], [207, 208], [208, 212], [212, 213], [214, 222], [223, 236], [237, 244], [245, 250], [251, 257], [258, 269], [269, 270], [270, 271]]}
{"doc_key": "ai-test-13", "ner": [[5, 5, "metrics"], [8, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "stemming", "reduces", "the", "accuracy", ",", "or", "rate", "of", "TRUE", "negative", "results", ",", "for", "such", "systems", "."], "sentence-detokenized": "However, stemming reduces the accuracy, or rate of TRUE negative results, for such systems.", "token2charspan": [[0, 7], [7, 8], [9, 17], [18, 25], [26, 29], [30, 38], [38, 39], [40, 42], [43, 47], [48, 50], [51, 55], [56, 64], [65, 72], [72, 73], [74, 77], [78, 82], [83, 90], [90, 91]]}
{"doc_key": "ai-test-14", "ner": [[4, 5, "task"], [10, 13, "misc"], [17, 18, "misc"], [28, 28, "product"], [30, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 13, 4, 5, "temporal", "", false, false], [17, 18, 10, 13, "named", "", false, false], [28, 28, 10, 13, "usage", "", false, false], [30, 30, 10, 13, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "special", "case", "of", "keyword", "detection", "is", "the", "detection", "of", "wake", "-", "up", "words", "(", "also", "called", "hot", "words", ")", ",", "used", "by", "personal", "digital", "assistants", "such", "as", "Alexa", "or", "Siri", "to", "wake", "up", "when", "their", "name", "is", "spoken", "."], "sentence-detokenized": "A special case of keyword detection is the detection of wake-up words (also called hot words), used by personal digital assistants such as Alexa or Siri to wake up when their name is spoken.", "token2charspan": [[0, 1], [2, 9], [10, 14], [15, 17], [18, 25], [26, 35], [36, 38], [39, 42], [43, 52], [53, 55], [56, 60], [60, 61], [61, 63], [64, 69], [70, 71], [71, 75], [76, 82], [83, 86], [87, 92], [92, 93], [93, 94], [95, 99], [100, 102], [103, 111], [112, 119], [120, 130], [131, 135], [136, 138], [139, 144], [145, 147], [148, 152], [153, 155], [156, 160], [161, 163], [164, 168], [169, 174], [175, 179], [180, 182], [183, 189], [189, 190]]}
{"doc_key": "ai-test-15", "ner": [[0, 0, "programlang"], [9, 9, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 0, 0, "part-of", "", false, false], [11, 11, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prova", "is", "an", "open", "source", "programming", "language", "that", "combines", "Prolog", "with", "Java", "."], "sentence-detokenized": "Prova is an open source programming language that combines Prolog with Java.", "token2charspan": [[0, 5], [6, 8], [9, 11], [12, 16], [17, 23], [24, 35], [36, 44], [45, 49], [50, 58], [59, 65], [66, 70], [71, 75], [75, 76]]}
{"doc_key": "ai-test-16", "ner": [[3, 4, "organisation"], [9, 9, "organisation"], [16, 18, "product"], [27, 30, "country"], [34, 34, "organisation"], [45, 45, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 9, 9, "part-of", "", false, false], [3, 4, 9, 9, "role", "sells", false, false], [3, 4, 27, 30, "role", "sells_to", false, false], [34, 34, 45, 45, "opposite", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "1987", ",", "Tocibai", "Machine", ",", "a", "subsidiary", "of", "Toshiba", ",", "was", "accused", "of", "illegally", "selling", "CNC", "milling", "cutters", "used", "to", "produce", "very", "quiet", "submarine", "propellers", "to", "the", "Soviet", "Union", "in", "violation", "of", "the", "CoCom", "agreement", ",", "an", "international", "embargo", "imposed", "on", "certain", "countries", "by", "COMECON", "."], "sentence-detokenized": "In 1987, Tocibai Machine, a subsidiary of Toshiba, was accused of illegally selling CNC milling cutters used to produce very quiet submarine propellers to the Soviet Union in violation of the CoCom agreement, an international embargo imposed on certain countries by COMECON.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 24], [24, 25], [26, 27], [28, 38], [39, 41], [42, 49], [49, 50], [51, 54], [55, 62], [63, 65], [66, 75], [76, 83], [84, 87], [88, 95], [96, 103], [104, 108], [109, 111], [112, 119], [120, 124], [125, 130], [131, 140], [141, 151], [152, 154], [155, 158], [159, 165], [166, 171], [172, 174], [175, 184], [185, 187], [188, 191], [192, 197], [198, 207], [207, 208], [209, 211], [212, 225], [226, 233], [234, 241], [242, 244], [245, 252], [253, 262], [263, 265], [266, 273], [273, 274]]}
{"doc_key": "ai-test-17", "ner": [[0, 0, "researcher"], [7, 10, "product"], [19, 22, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 10, 0, 0, "artifact", "", false, false], [7, 10, 19, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Engelberger", "'s", "most", "famous", "co-invention", ",", "the", "Unimate", "industrial", "robot", "arm", ",", "was", "among", "the", "first", "inductees", "into", "the", "Robot", "Hall", "of", "Fame", "in", "2003", "."], "sentence-detokenized": "Engelberger's most famous co-invention, the Unimate industrial robot arm, was among the first inductees into the Robot Hall of Fame in 2003.", "token2charspan": [[0, 11], [11, 13], [14, 18], [19, 25], [26, 38], [38, 39], [40, 43], [44, 51], [52, 62], [63, 68], [69, 72], [72, 73], [74, 77], [78, 83], [84, 87], [88, 93], [94, 103], [104, 108], [109, 112], [113, 118], [119, 123], [124, 126], [127, 131], [132, 134], [135, 139], [139, 140]]}
{"doc_key": "ai-test-18", "ner": [[3, 4, "misc"], [8, 8, "misc"], [10, 10, "person"], [13, 21, "field"], [17, 17, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 8, 8, "usage", "", false, false], [10, 10, 13, 21, "role", "", false, false], [13, 21, 17, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Originally", "controlled", "through", "static", "html", "web", "pages", "using", "CGI", ",", "Dalton", "introduced", "an", "augmented", "reality", "-", "based", "Java", "interface", ",", "which", "had", "limited", "success", "."], "sentence-detokenized": "Originally controlled through static html web pages using CGI, Dalton introduced an augmented reality-based Java interface, which had limited success.", "token2charspan": [[0, 10], [11, 21], [22, 29], [30, 36], [37, 41], [42, 45], [46, 51], [52, 57], [58, 61], [61, 62], [63, 69], [70, 80], [81, 83], [84, 93], [94, 101], [101, 102], [102, 107], [108, 112], [113, 122], [122, 123], [124, 129], [130, 133], [134, 141], [142, 149], [149, 150]]}
{"doc_key": "ai-test-19", "ner": [[5, 7, "task"], [10, 10, "organisation"], [30, 30, "conference"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[5, 7, 10, 10, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "publication", "on", "the", "LMF", "specification", "as", "ratified", "by", "ISO", "(", "this", "paper", "became", "(", "in", "2015", ")", "the", "9th", "most", "cited", "paper", "in", "the", "LREC", "conferences", "in", "the", "LREC", "proceedings", ")", ":"], "sentence-detokenized": "The first publication on the LMF specification as ratified by ISO (this paper became (in 2015) the 9th most cited paper in the LREC conferences in the LREC proceedings):", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 24], [25, 28], [29, 32], [33, 46], [47, 49], [50, 58], [59, 61], [62, 65], [66, 67], [67, 71], [72, 77], [78, 84], [85, 86], [86, 88], [89, 93], [93, 94], [95, 98], [99, 102], [103, 107], [108, 113], [114, 119], [120, 122], [123, 126], [127, 131], [132, 143], [144, 146], [147, 150], [151, 155], [156, 167], [167, 168], [168, 169]]}
{"doc_key": "ai-test-20", "ner": [[1, 1, "metrics"], [16, 18, "metrics"], [19, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 18, 1, 1, "usage", "", false, false], [16, 18, 19, 22, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "confusion", "matrix", "or", "a", "matching", "matrix", "is", "often", "used", "as", "a", "tool", "to", "validate", "the", "accuracy", "of", "the", "k", "-", "NN", "classification", "."], "sentence-detokenized": "A confusion matrix or a matching matrix is often used as a tool to validate the accuracy of the k -NN classification.", "token2charspan": [[0, 1], [2, 11], [12, 18], [19, 21], [22, 23], [24, 32], [33, 39], [40, 42], [43, 48], [49, 53], [54, 56], [57, 58], [59, 63], [64, 66], [67, 75], [76, 79], [80, 88], [89, 91], [92, 95], [96, 97], [98, 99], [99, 101], [102, 116], [116, 117]]}
{"doc_key": "ai-test-21", "ner": [[0, 1, "algorithm"], [12, 12, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 12, 12, "part-of", "", false, false], [0, 1, 14, 15, "part-of", "", false, false], [0, 1, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", "is", "one", "of", "the", "predictive", "modeling", "approaches", "used", "in", "statistics", ",", "data", "mining", "and", "machine", "learning", "."], "sentence-detokenized": "Decision tree learning is one of the predictive modeling approaches used in statistics, data mining and machine learning.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 47], [48, 56], [57, 67], [68, 72], [73, 75], [76, 86], [86, 87], [88, 92], [93, 99], [100, 103], [104, 111], [112, 120], [120, 121]]}
{"doc_key": "ai-test-22", "ner": [[5, 5, "misc"], [16, 17, "field"], [21, 23, "algorithm"], [25, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 16, 17, "related-to", "", true, false], [21, 23, 16, 17, "type-of", "", false, false], [25, 25, 16, 17, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["At", "runtime", ",", "the", "target", "prosody", "of", "a", "sentence", "is", "superimposed", "on", "these", "minimal", "units", "using", "signal", "processing", "techniques", "such", "as", "linear", "predictive", "coding", ",", "PSOLA"], "sentence-detokenized": "At runtime, the target prosody of a sentence is superimposed on these minimal units using signal processing techniques such as linear predictive coding, PSOLA", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 22], [23, 30], [31, 33], [34, 35], [36, 44], [45, 47], [48, 60], [61, 63], [64, 69], [70, 77], [78, 83], [84, 89], [90, 96], [97, 107], [108, 118], [119, 123], [124, 126], [127, 133], [134, 144], [145, 151], [151, 152], [153, 158]]}
{"doc_key": "ai-test-23", "ner": [[3, 4, "field"], [6, 7, "field"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 18, 3, 4, "usage", "", true, false], [17, 18, 6, 7, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "approach", "used", "artificial", "intelligence", "and", "machine", "learning", "to", "allow", "researchers", "to", "visually", "compare", "conventional", "and", "thermal", "facial", "images", "."], "sentence-detokenized": "This approach used artificial intelligence and machine learning to allow researchers to visually compare conventional and thermal facial images.", "token2charspan": [[0, 4], [5, 13], [14, 18], [19, 29], [30, 42], [43, 46], [47, 54], [55, 63], [64, 66], [67, 72], [73, 84], [85, 87], [88, 96], [97, 104], [105, 117], [118, 121], [122, 129], [130, 136], [137, 143], [143, 144]]}
{"doc_key": "ai-test-24", "ner": [[1, 2, "field"], [4, 5, "algorithm"], [10, 13, "task"], [15, 16, "misc"], [22, 23, "field"], [25, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 1, 2, "part-of", "", false, false], [4, 5, 10, 13, "topic", "", false, false], [10, 13, 15, 16, "origin", "", false, false], [22, 23, 1, 2, "part-of", "", false, false], [22, 23, 4, 5, "topic", "", false, false], [25, 27, 1, 2, "part-of", "", false, false], [25, 27, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "computer", "science", ",", "evolutionary", "computation", "is", "a", "family", "of", "global", "optimization", "algorithms", "inspired", "by", "biological", "evolution", ",", "and", "the", "subfield", "of", "artificial", "intelligence", "and", "soft", "computing", "that", "studies", "these", "algorithms", "."], "sentence-detokenized": "In computer science, evolutionary computation is a family of global optimization algorithms inspired by biological evolution, and the subfield of artificial intelligence and soft computing that studies these algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 33], [34, 45], [46, 48], [49, 50], [51, 57], [58, 60], [61, 67], [68, 80], [81, 91], [92, 100], [101, 103], [104, 114], [115, 124], [124, 125], [126, 129], [130, 133], [134, 142], [143, 145], [146, 156], [157, 169], [170, 173], [174, 178], [179, 188], [189, 193], [194, 201], [202, 207], [208, 218], [218, 219]]}
{"doc_key": "ai-test-25", "ner": [[11, 12, "metrics"], [16, 18, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "one", "can", "combine", "a", "measure", "based", "on", "the", "confusion", "matrix", "with", "the", "root", "mean", "square", "error", "evaluated", "between", "the", "raw", "model", "results", "and", "the", "true", "values", "."], "sentence-detokenized": "For example, one can combine a measure based on the confusion matrix with the root mean square error evaluated between the raw model results and the true values.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 20], [21, 28], [29, 30], [31, 38], [39, 44], [45, 47], [48, 51], [52, 61], [62, 68], [69, 73], [74, 77], [78, 82], [83, 87], [88, 94], [95, 100], [101, 110], [111, 118], [119, 122], [123, 126], [127, 132], [133, 140], [141, 144], [145, 148], [149, 153], [154, 160], [160, 161]]}
{"doc_key": "ai-test-26", "ner": [[8, 8, "product"], [11, 11, "researcher"], [7, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 11, 11, "origin", "", false, false], [8, 8, 7, 18, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Most", "of", "them", "are", "results", "of", "the", "word2vec", "model", "developed", "by", "Mikolov", "et", "al", ".", "or", "variants", "of", "word2vec", "."], "sentence-detokenized": "Most of them are results of the word2vec model developed by Mikolov et al. or variants of word2vec.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 16], [17, 24], [25, 27], [28, 31], [32, 40], [41, 46], [47, 56], [57, 59], [60, 67], [68, 70], [71, 73], [73, 74], [75, 77], [78, 86], [87, 89], [90, 98], [98, 99]]}
{"doc_key": "ai-test-27", "ner": [[14, 14, "conference"], [17, 21, "conference"], [23, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 23, 17, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["During", "this", "period", ",", "a", "total", "of", "43", "publications", "have", "been", "recognised", "by", "the", "CVPR", "and", "the", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "."], "sentence-detokenized": "During this period, a total of 43 publications have been recognised by the CVPR and the International Conference on Computer Vision (ICCV).", "token2charspan": [[0, 6], [7, 11], [12, 18], [18, 19], [20, 21], [22, 27], [28, 30], [31, 33], [34, 46], [47, 51], [52, 56], [57, 67], [68, 70], [71, 74], [75, 79], [80, 83], [84, 87], [88, 101], [102, 112], [113, 115], [116, 124], [125, 131], [132, 133], [133, 137], [137, 138], [138, 139]]}
{"doc_key": "ai-test-28", "ner": [[0, 0, "product"], [10, 11, "field"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 10, 11, "general-affiliation", "platform_for_education_about", false, false], [21, 22, 0, 0, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["AIBO", "has", "been", "widely", "used", "as", "an", "inexpensive", "platform", "for", "artificial", "intelligence", "education", "and", "research", "because", "it", "integrates", "a", "computer", ",", "computer", "vision", "system", "and", "articulators", "into", "a", "much", "cheaper", "package", "than", "conventional", "research", "robots", "."], "sentence-detokenized": "AIBO has been widely used as an inexpensive platform for artificial intelligence education and research because it integrates a computer, computer vision system and articulators into a much cheaper package than conventional research robots.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 20], [21, 25], [26, 28], [29, 31], [32, 43], [44, 52], [53, 56], [57, 67], [68, 80], [81, 90], [91, 94], [95, 103], [104, 111], [112, 114], [115, 125], [126, 127], [128, 136], [136, 137], [138, 146], [147, 153], [154, 160], [161, 164], [165, 177], [178, 182], [183, 184], [185, 189], [190, 197], [198, 205], [206, 210], [211, 223], [224, 232], [233, 239], [239, 240]]}
{"doc_key": "ai-test-29", "ner": [[6, 11, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "was", "programme", "chair", "of", "the", "International", "Conference", "on", "Computer", "Vision", "2021", "."], "sentence-detokenized": "He was programme chair of the International Conference on Computer Vision 2021.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 22], [23, 25], [26, 29], [30, 43], [44, 54], [55, 57], [58, 66], [67, 73], [74, 78], [78, 79]]}
{"doc_key": "ai-test-30", "ner": [[0, 0, "researcher"], [7, 17, "organisation"], [26, 27, "organisation"], [34, 37, "product"], [39, 39, "product"]], "ner_mapping_to_source": [0, 2, 3, 4, 5], "relations": [[0, 0, 7, 17, "role", "", true, false], [7, 17, 26, 27, "role", "develops_with", false, false], [34, 37, 7, 17, "artifact", "", false, false], [39, 39, 34, 37, "named", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4], "sentence": ["Scheinman", ",", "after", "receiving", "a", "grant", "from", "Unimation", "to", "develop", "his", "designs", ",", "sold", "these", "designs", "to", "Unimation", ",", "which", "further", "developed", "them", "with", "support", "from", "General", "Motors", "and", "later", "marketed", "them", "as", "the", "Programmable", "Universal", "Assembly", "Machine", "(", "PUMA", ")", "."], "sentence-detokenized": "Scheinman, after receiving a grant from Unimation to develop his designs, sold these designs to Unimation, which further developed them with support from General Motors and later marketed them as the Programmable Universal Assembly Machine (PUMA).", "token2charspan": [[0, 9], [9, 10], [11, 16], [17, 26], [27, 28], [29, 34], [35, 39], [40, 49], [50, 52], [53, 60], [61, 64], [65, 72], [72, 73], [74, 78], [79, 84], [85, 92], [93, 95], [96, 105], [105, 106], [107, 112], [113, 120], [121, 130], [131, 135], [136, 140], [141, 148], [149, 153], [154, 161], [162, 168], [169, 172], [173, 178], [179, 187], [188, 192], [193, 195], [196, 199], [200, 212], [213, 222], [223, 231], [232, 239], [240, 241], [241, 245], [245, 246], [246, 247]]}
{"doc_key": "ai-test-31", "ner": [[6, 6, "task"], [7, 11, "task"], [15, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 15, 6, 6, "general-affiliation", "works_with", false, false], [15, 15, 7, 11, "general-affiliation", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "overview", "of", "calibration", "methods", "for", "binary", "classification", "and", "multiclass", "classification", "tasks", "is", "provided", "by", "Gebel", "(", "2009", ")", "."], "sentence-detokenized": "An overview of calibration methods for binary classification and multiclass classification tasks is provided by Gebel (2009).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 34], [35, 38], [39, 45], [46, 60], [61, 64], [65, 75], [76, 90], [91, 96], [97, 99], [100, 108], [109, 111], [112, 117], [118, 119], [119, 123], [123, 124], [124, 125]]}
{"doc_key": "ai-test-32", "ner": [[7, 9, "task"], [11, 11, "task"], [14, 15, "task"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 7, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "involved", "in", "areas", "such", "as", "optical", "character", "recognition", "(", "OCR", ")", ",", "speech", "synthesis", ",", "speech", "recognition", "technology", "and", "electronic", "keyboard", "tools", "."], "sentence-detokenized": "He is involved in areas such as optical character recognition (OCR), speech synthesis, speech recognition technology and electronic keyboard tools.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 23], [24, 28], [29, 31], [32, 39], [40, 49], [50, 61], [62, 63], [63, 66], [66, 67], [67, 68], [69, 75], [76, 85], [85, 86], [87, 93], [94, 105], [106, 116], [117, 120], [121, 131], [132, 140], [141, 146], [146, 147]]}
{"doc_key": "ai-test-33", "ner": [[13, 15, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "more", "recent", "and", "state", "-", "of", "-", "the", "-", "art", "techniques", ",", "the", "Kaldi", "toolkit", "can", "be", "used", "."], "sentence-detokenized": "For more recent and state-of-the-art techniques, the Kaldi toolkit can be used.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 19], [20, 25], [25, 26], [26, 28], [28, 29], [29, 32], [32, 33], [33, 36], [37, 47], [47, 48], [49, 52], [53, 58], [59, 66], [67, 70], [71, 73], [74, 78], [78, 79]]}
{"doc_key": "ai-test-34", "ner": [[0, 2, "researcher"], [8, 10, "organisation"], [16, 20, "organisation"], [23, 24, "organisation"], [27, 28, "researcher"], [32, 35, "organisation"], [42, 44, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 8, 10, "role", "", false, false], [0, 2, 16, 20, "role", "", false, false], [0, 2, 23, 24, "role", "", false, false], [0, 2, 32, 35, "role", "", false, false], [0, 2, 42, 44, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Johnson", "-", "Laird", "is", "a", "Fellow", "of", "the", "American", "Philosophical", "Society", ",", "a", "Fellow", "of", "the", "Royal", "Society", ",", "a", "Fellow", "of", "the", "British", "Academy", ",", "a", "William", "James", "Fellow", "of", "the", "Association", "for", "Psychological", "Science", ",", "and", "a", "Fellow", "of", "the", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Johnson-Laird is a Fellow of the American Philosophical Society, a Fellow of the Royal Society, a Fellow of the British Academy, a William James Fellow of the Association for Psychological Science, and a Fellow of the Cognitive Science Society.", "token2charspan": [[0, 7], [7, 8], [8, 13], [14, 16], [17, 18], [19, 25], [26, 28], [29, 32], [33, 41], [42, 55], [56, 63], [63, 64], [65, 66], [67, 73], [74, 76], [77, 80], [81, 86], [87, 94], [94, 95], [96, 97], [98, 104], [105, 107], [108, 111], [112, 119], [120, 127], [127, 128], [129, 130], [131, 138], [139, 144], [145, 151], [152, 154], [155, 158], [159, 170], [171, 174], [175, 188], [189, 196], [196, 197], [198, 201], [202, 203], [204, 210], [211, 213], [214, 217], [218, 227], [228, 235], [236, 243], [243, 244]]}
{"doc_key": "ai-test-35", "ner": [[3, 8, "conference"], [10, 11, "researcher"], [13, 14, "researcher"], [17, 18, "researcher"], [20, 22, "algorithm"], [26, 30, "task"], [32, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 11, 3, 8, "physical", "", false, false], [10, 11, 3, 8, "temporal", "", false, false], [13, 14, 3, 8, "physical", "", false, false], [13, 14, 3, 8, "temporal", "", false, false], [17, 18, 3, 8, "physical", "", false, false], [17, 18, 3, 8, "temporal", "", false, false], [20, 22, 17, 18, "role", "extends", false, false], [26, 30, 17, 18, "role", "extends", false, false], [32, 32, 26, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["At", "the", "2010", "IEEE", "International", "Conference", "on", "Image", "Processing", ",", "Rui", "Hu", ",", "Mark", "Banard", ",", "and", "John", "Collomosse", "extended", "the", "HOG", "descriptor", "for", "use", "in", "sketch", "-", "based", "image", "retrieval", "(", "SBIR", ")", "."], "sentence-detokenized": "At the 2010 IEEE International Conference on Image Processing, Rui Hu, Mark Banard, and John Collomosse extended the HOG descriptor for use in sketch-based image retrieval (SBIR).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 30], [31, 41], [42, 44], [45, 50], [51, 61], [61, 62], [63, 66], [67, 69], [69, 70], [71, 75], [76, 82], [82, 83], [84, 87], [88, 92], [93, 103], [104, 112], [113, 116], [117, 120], [121, 131], [132, 135], [136, 139], [140, 142], [143, 149], [149, 150], [150, 155], [156, 161], [162, 171], [172, 173], [173, 177], [177, 178], [178, 179]]}
{"doc_key": "ai-test-36", "ner": [[0, 0, "metrics"], [6, 6, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["BLEU", "uses", "a", "modified", "form", "of", "precision", "to", "compare", "a", "candidate", "translation", "with", "several", "reference", "translations", "."], "sentence-detokenized": "BLEU uses a modified form of precision to compare a candidate translation with several reference translations.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 20], [21, 25], [26, 28], [29, 38], [39, 41], [42, 49], [50, 51], [52, 61], [62, 73], [74, 78], [79, 86], [87, 96], [97, 109], [109, 110]]}
{"doc_key": "ai-test-37", "ner": [[31, 32, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "case", "of", "a", "general", "math", "(", "Y", ",\\", "mathcal", "{", "B", "},\\", "no", ")", "/", "math", "basis", "space", "(", "i.e.", "a", "basis", "space", "that", "is", "not", "countable", ")", ",", "relative", "entropy", "is", "usually", "considered", "."], "sentence-detokenized": "In the case of a general math(Y,\\ mathcal {B},\\ no)/math basis space (i.e. a basis space that is not countable), relative entropy is usually considered.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 16], [17, 24], [25, 29], [29, 30], [30, 31], [31, 33], [34, 41], [42, 43], [43, 44], [44, 47], [48, 50], [50, 51], [51, 52], [52, 56], [57, 62], [63, 68], [69, 70], [70, 74], [75, 76], [77, 82], [83, 88], [89, 93], [94, 96], [97, 100], [101, 110], [110, 111], [111, 112], [113, 121], [122, 129], [130, 132], [133, 140], [141, 151], [151, 152]]}
{"doc_key": "ai-test-38", "ner": [[9, 9, "country"], [10, 12, "organisation"], [14, 14, "organisation"], [24, 27, "country"], [17, 18, "organisation"], [20, 20, "organisation"], [28, 30, "organisation"], [32, 32, "country"], [34, 39, "organisation"], [41, 41, "organisation"], [49, 49, "misc"], [50, 50, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[10, 12, 9, 9, "physical", "", false, false], [14, 14, 10, 12, "named", "", false, false], [17, 18, 24, 27, "physical", "", false, false], [20, 20, 17, 18, "named", "", false, false], [34, 39, 32, 32, "physical", "", false, false], [41, 41, 34, 39, "named", "", false, false], [49, 49, 50, 50, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["As", "of", "October", "2011", ",", "existing", "partnerships", "with", "the", "U.S.", "National", "Park", "Service", "(", "NPS", ")", ",", "Historic", "Scotland", "(", "HS", ")", "in", "the", "United", "Kingdom", ",", "the", "World", "Monuments", "Fund", "and", "Mexico", "'s", "Instituto", "Nacional", "de", "Antropolog\u00eda", "y", "Historia", "(", "INAH", ")", "have", "been", "greatly", "expanded", ",", "the", "CyArk", "website"], "sentence-detokenized": "As of October 2011, existing partnerships with the U.S. National Park Service (NPS), Historic Scotland (HS) in the United Kingdom, the World Monuments Fund and Mexico's Instituto Nacional de Antropolog\u00eda y Historia (INAH) have been greatly expanded, the CyArk website", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 18], [18, 19], [20, 28], [29, 41], [42, 46], [47, 50], [51, 55], [56, 64], [65, 69], [70, 77], [78, 79], [79, 82], [82, 83], [83, 84], [85, 93], [94, 102], [103, 104], [104, 106], [106, 107], [108, 110], [111, 114], [115, 121], [122, 129], [129, 130], [131, 134], [135, 140], [141, 150], [151, 155], [156, 159], [160, 166], [166, 168], [169, 178], [179, 187], [188, 190], [191, 203], [204, 205], [206, 214], [215, 216], [216, 220], [220, 221], [222, 226], [227, 231], [232, 239], [240, 248], [248, 249], [250, 253], [254, 259], [260, 267]]}
{"doc_key": "ai-test-39", "ner": [[0, 1, "algorithm"], [6, 8, "field"], [11, 11, "product"], [13, 13, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 11, 11, "part-of", "", false, false], [0, 1, 13, 13, "part-of", "", false, false], [11, 11, 6, 8, "general-affiliation", "", false, false], [13, 13, 6, 8, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kernel", "SVMs", "are", "available", "in", "many", "machine", "learning", "toolkits", ",", "including", "LIBSVM", ",", "MATLAB", "and", "others", "."], "sentence-detokenized": "Kernel SVMs are available in many machine learning toolkits, including LIBSVM, MATLAB and others.", "token2charspan": [[0, 6], [7, 11], [12, 15], [16, 25], [26, 28], [29, 33], [34, 41], [42, 50], [51, 59], [59, 60], [61, 70], [71, 77], [77, 78], [79, 85], [86, 89], [90, 96], [96, 97]]}
{"doc_key": "ai-test-40", "ner": [[0, 4, "misc"], [14, 14, "location"], [13, 16, "location"], [18, 18, "country"], [24, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 14, 14, "physical", "", false, false], [0, 4, 24, 26, "temporal", "", false, false], [14, 14, 13, 16, "physical", "", false, false], [13, 16, 18, 18, "physical", "", false, false], [24, 26, 14, 14, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "2009", "Loebner", "Prize", "competition", "took", "place", "on", "6", "September", "2009", "at", "the", "Brighton", "Centre", ",", "Brighton", ",", "UK", ",", "as", "part", "of", "the", "Interspeech", "2009", "conference", "."], "sentence-detokenized": "The 2009 Loebner Prize competition took place on 6 September 2009 at the Brighton Centre, Brighton, UK, as part of the Interspeech 2009 conference.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 34], [35, 39], [40, 45], [46, 48], [49, 50], [51, 60], [61, 65], [66, 68], [69, 72], [73, 81], [82, 88], [88, 89], [90, 98], [98, 99], [100, 102], [102, 103], [104, 106], [107, 111], [112, 114], [115, 118], [119, 130], [131, 135], [136, 146], [146, 147]]}
{"doc_key": "ai-test-41", "ner": [[0, 3, "product"], [10, 10, "product"], [16, 18, "product"], [19, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[19, 21, 0, 3, "part-of", "", false, false], [19, 21, 10, 10, "part-of", "", false, false], [19, 21, 16, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "QRIO", "humanoid", "robot", "was", "designed", "as", "the", "successor", "to", "AIBO", "and", "runs", "the", "same", "basic", "R", "-", "CODE", "Aperios", "operating", "system", "."], "sentence-detokenized": "The QRIO humanoid robot was designed as the successor to AIBO and runs the same basic R-CODE Aperios operating system.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 23], [24, 27], [28, 36], [37, 39], [40, 43], [44, 53], [54, 56], [57, 61], [62, 65], [66, 70], [71, 74], [75, 79], [80, 85], [86, 87], [87, 88], [88, 92], [93, 100], [101, 110], [111, 117], [117, 118]]}
{"doc_key": "ai-test-42", "ner": [[0, 2, "misc"], [7, 7, "algorithm"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 0, 2, "cause-effect", "", true, false], [12, 13, 0, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "speech", "waveforms", "are", "generated", "by", "the", "HMMs", "themselves", "based", "on", "the", "maximum", "likelihood", "criterion", "."], "sentence-detokenized": "The speech waveforms are generated by the HMMs themselves based on the maximum likelihood criterion.", "token2charspan": [[0, 3], [4, 10], [11, 20], [21, 24], [25, 34], [35, 37], [38, 41], [42, 46], [47, 57], [58, 63], [64, 66], [67, 70], [71, 78], [79, 89], [90, 99], [99, 100]]}
{"doc_key": "ai-test-43", "ner": [[0, 1, "product"], [5, 6, "task"], [7, 12, "task"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 5, 6, "type-of", "", false, false], [0, 1, 7, 12, "type-of", "", false, false], [0, 1, 16, 16, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Google", "Translate", "is", "a", "free", "multilingual", "statistical", "machine", "translation", "and", "neural", "machine", "translation", "service", "developed", "by", "Google", "to", "translate", "text", "and", "websites", "from", "one", "language", "to", "another", "."], "sentence-detokenized": "Google Translate is a free multilingual statistical machine translation and neural machine translation service developed by Google to translate text and websites from one language to another.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 39], [40, 51], [52, 59], [60, 71], [72, 75], [76, 82], [83, 90], [91, 102], [103, 110], [111, 120], [121, 123], [124, 130], [131, 133], [134, 143], [144, 148], [149, 152], [153, 161], [162, 166], [167, 170], [171, 179], [180, 182], [183, 190], [190, 191]]}
{"doc_key": "ai-test-44", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 12, "field"], [14, 16, "field"], [21, 23, "task"], [25, 26, "task"], [28, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[21, 23, 5, 6, "part-of", "", false, true], [21, 23, 8, 9, "part-of", "", false, true], [21, 23, 11, 12, "part-of", "", false, true], [25, 26, 5, 6, "part-of", "", false, true], [25, 26, 8, 9, "part-of", "", false, true], [25, 26, 11, 12, "part-of", "", false, true], [28, 31, 5, 6, "part-of", "", false, true], [28, 31, 8, 9, "part-of", "", false, true], [28, 31, 11, 12, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Skeletons", "are", "widely", "used", "in", "computer", "vision", ",", "image", "analysis", ",", "pattern", "recognition", "and", "digital", "image", "processing", "for", "purposes", "such", "as", "optical", "character", "recognition", ",", "fingerprint", "recognition", ",", "visual", "inspection", "or", "compression", "."], "sentence-detokenized": "Skeletons are widely used in computer vision, image analysis, pattern recognition and digital image processing for purposes such as optical character recognition, fingerprint recognition, visual inspection or compression.", "token2charspan": [[0, 9], [10, 13], [14, 20], [21, 25], [26, 28], [29, 37], [38, 44], [44, 45], [46, 51], [52, 60], [60, 61], [62, 69], [70, 81], [82, 85], [86, 93], [94, 99], [100, 110], [111, 114], [115, 123], [124, 128], [129, 131], [132, 139], [140, 149], [150, 161], [161, 162], [163, 174], [175, 186], [186, 187], [188, 194], [195, 205], [206, 208], [209, 220], [220, 221]]}
{"doc_key": "ai-test-45", "ner": [[0, 7, "conference"], [12, 15, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 7, 12, 15, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ImageNet", "large", "-", "scale", "visual", "recognition", "challenge", "is", "a", "benchmark", "in", "object", "classification", "and", "detection", ",", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "The ImageNet large-scale visual recognition challenge is a benchmark in object classification and detection, with millions of images and hundreds of object classes.", "token2charspan": [[0, 3], [4, 12], [13, 18], [18, 19], [19, 24], [25, 31], [32, 43], [44, 53], [54, 56], [57, 58], [59, 68], [69, 71], [72, 78], [79, 93], [94, 97], [98, 107], [107, 108], [109, 113], [114, 122], [123, 125], [126, 132], [133, 136], [137, 145], [146, 148], [149, 155], [156, 163], [163, 164]]}
{"doc_key": "ai-test-46", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 12, "researcher"], [17, 18, "misc"], [21, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 17, 18, "part-of", "", false, false], [0, 0, 21, 24, "part-of", "", false, false], [4, 5, 17, 18, "part-of", "", false, false], [4, 5, 21, 24, "part-of", "", false, false], [7, 12, 17, 18, "part-of", "", false, false], [7, 12, 21, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Bengio", ",", "along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "are", "called", "by", "some", "the", "godfathers", "of", "artificial", "intelligence", "and", "the", "godfathers", "of", "deep", "learning", "."], "sentence-detokenized": "Bengio, along with Geoffrey Hinton and Yann LeCun, are called by some the godfathers of artificial intelligence and the godfathers of deep learning.", "token2charspan": [[0, 6], [6, 7], [8, 13], [14, 18], [19, 27], [28, 34], [35, 38], [39, 43], [44, 49], [49, 50], [51, 54], [55, 61], [62, 64], [65, 69], [70, 73], [74, 84], [85, 87], [88, 98], [99, 111], [112, 115], [116, 119], [120, 130], [131, 133], [134, 138], [139, 147], [147, 148]]}
{"doc_key": "ai-test-47", "ner": [[7, 7, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "life", "member", "of", "the", "IEEE", "."], "sentence-detokenized": "He is a life member of the IEEE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 19], [20, 22], [23, 26], [27, 31], [31, 32]]}
{"doc_key": "ai-test-48", "ner": [[0, 1, "organisation"], [13, 18, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 13, 18, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NSA", "Bethesda", "is", "responsible", "for", "base", "operational", "support", "for", "its", "primary", "tenant", ",", "Walter", "Reed", "National", "Military", "Medical", "Center", "."], "sentence-detokenized": "NSA Bethesda is responsible for base operational support for its primary tenant, Walter Reed National Military Medical Center.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 31], [32, 36], [37, 48], [49, 56], [57, 60], [61, 64], [65, 72], [73, 79], [79, 80], [81, 87], [88, 92], [93, 101], [102, 110], [111, 118], [119, 125], [125, 126]]}
{"doc_key": "ai-test-49", "ner": [[6, 7, "field"], [9, 9, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "three", "major", "learning", "paradigms", "are", "supervised", "learning", ",", "unsupervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "The three major learning paradigms are supervised learning, unsupervised learning and reinforcement learning.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 24], [25, 34], [35, 38], [39, 49], [50, 58], [58, 59], [60, 72], [73, 81], [82, 85], [86, 99], [100, 108], [108, 109]]}
{"doc_key": "ai-test-50", "ner": [[2, 2, "task"], [4, 6, "task"], [11, 15, "task"], [17, 17, "task"], [20, 22, "task"], [24, 25, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Examples", "include", "control", ",", "planning", "and", "scheduling", ",", "the", "ability", "to", "answer", "diagnostic", "and", "consumer", "questions", ",", "handwriting", "recognition", ",", "natural", "language", "understanding", ",", "speech", "recognition", "and", "facial", "recognition", "."], "sentence-detokenized": "Examples include control, planning and scheduling, the ability to answer diagnostic and consumer questions, handwriting recognition, natural language understanding, speech recognition and facial recognition.", "token2charspan": [[0, 8], [9, 16], [17, 24], [24, 25], [26, 34], [35, 38], [39, 49], [49, 50], [51, 54], [55, 62], [63, 65], [66, 72], [73, 83], [84, 87], [88, 96], [97, 106], [106, 107], [108, 119], [120, 131], [131, 132], [133, 140], [141, 149], [150, 163], [163, 164], [165, 171], [172, 183], [184, 187], [188, 194], [195, 206], [206, 207]]}
{"doc_key": "ai-test-51", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1991", ",", "he", "was", "elected", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "1990", ",", "founding", "member", ")", "."], "sentence-detokenized": "In 1991, he was elected a member of the Association for the Advancement of Artificial Intelligence (1990, founding member).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [99, 100], [100, 104], [104, 105], [106, 114], [115, 121], [121, 122], [122, 123]]}
{"doc_key": "ai-test-52", "ner": [[11, 12, "misc"], [15, 16, "algorithm"], [29, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "by", "formulating", "the", "problem", "as", "a", "solution", "of", "a", "Toeplitz", "matrix", "and", "using", "Levinson", "recursion", ",", "we", "can", "relatively", "quickly", "estimate", "a", "filter", "with", "the", "smallest", "possible", "mean", "squared", "error", "."], "sentence-detokenized": "However, by formulating the problem as a solution of a Toeplitz matrix and using Levinson recursion, we can relatively quickly estimate a filter with the smallest possible mean squared error.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 23], [24, 27], [28, 35], [36, 38], [39, 40], [41, 49], [50, 52], [53, 54], [55, 63], [64, 70], [71, 74], [75, 80], [81, 89], [90, 99], [99, 100], [101, 103], [104, 107], [108, 118], [119, 126], [127, 135], [136, 137], [138, 144], [145, 149], [150, 153], [154, 162], [163, 171], [172, 176], [177, 184], [185, 190], [190, 191]]}
{"doc_key": "ai-test-53", "ner": [[5, 10, "conference"], [16, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 10, 16, 20, "physical", "", false, false], [16, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2011", ",", "the", "15th", "edition", "of", "Campus", "Party", "Spain", "will", "take", "place", "at", "the", "City", "of", "Arts", "and", "Sciences", "in", "Valencia", "."], "sentence-detokenized": "In July 2011, the 15th edition of Campus Party Spain will take place at the City of Arts and Sciences in Valencia.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 22], [23, 30], [31, 33], [34, 40], [41, 46], [47, 52], [53, 57], [58, 62], [63, 68], [69, 71], [72, 75], [76, 80], [81, 83], [84, 88], [89, 92], [93, 101], [102, 104], [105, 113], [113, 114]]}
{"doc_key": "ai-test-54", "ner": [[13, 13, "product"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Often", "this", "is", "only", "possible", "at", "the", "end", "of", "complicated", "games", "such", "as", "chess", "or", "go", ",", "because", "it", "is", "not", "computationally", "feasible", "to", "look", "forward", "to", "the", "completion", "of", "the", "game", "until", "towards", "the", "end", ",", "and", "instead", "positions", "are", "given", "finite", "values", "as", "estimates", "of", "the", "degree", "of", "confidence", "that", "they", "will", "lead", "to", "a", "win", "for", "one", "player", "or", "another", "."], "sentence-detokenized": "Often this is only possible at the end of complicated games such as chess or go, because it is not computationally feasible to look forward to the completion of the game until towards the end, and instead positions are given finite values as estimates of the degree of confidence that they will lead to a win for one player or another.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 18], [19, 27], [28, 30], [31, 34], [35, 38], [39, 41], [42, 53], [54, 59], [60, 64], [65, 67], [68, 73], [74, 76], [77, 79], [79, 80], [81, 88], [89, 91], [92, 94], [95, 98], [99, 114], [115, 123], [124, 126], [127, 131], [132, 139], [140, 142], [143, 146], [147, 157], [158, 160], [161, 164], [165, 169], [170, 175], [176, 183], [184, 187], [188, 191], [191, 192], [193, 196], [197, 204], [205, 214], [215, 218], [219, 224], [225, 231], [232, 238], [239, 241], [242, 251], [252, 254], [255, 258], [259, 265], [266, 268], [269, 279], [280, 284], [285, 289], [290, 294], [295, 299], [300, 302], [303, 304], [305, 308], [309, 312], [313, 316], [317, 323], [324, 326], [327, 334], [334, 335]]}
{"doc_key": "ai-test-55", "ner": [[4, 6, "algorithm"], [23, 24, "algorithm"], [26, 27, "algorithm"], [30, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 23, 24, "compare", "", false, false], [4, 6, 26, 27, "compare", "", false, false], [4, 6, 30, 32, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "difference", "between", "the", "multinomial", "logit", "model", "and", "many", "other", "methods", ",", "models", ",", "algorithms", ",", "etc.", "with", "the", "same", "basic", "configuration", "(", "perceptron", "algorithm", ",", "support", "vector", "machines", ",", "linear", "discriminant", "analysis", ",", "etc.", ")", "."], "sentence-detokenized": "The difference between the multinomial logit model and many other methods, models, algorithms, etc. with the same basic configuration (perceptron algorithm, support vector machines, linear discriminant analysis, etc.).", "token2charspan": [[0, 3], [4, 14], [15, 22], [23, 26], [27, 38], [39, 44], [45, 50], [51, 54], [55, 59], [60, 65], [66, 73], [73, 74], [75, 81], [81, 82], [83, 93], [93, 94], [95, 99], [100, 104], [105, 108], [109, 113], [114, 119], [120, 133], [134, 135], [135, 145], [146, 155], [155, 156], [157, 164], [165, 171], [172, 180], [180, 181], [182, 188], [189, 201], [202, 210], [210, 211], [212, 216], [216, 217], [217, 218]]}
{"doc_key": "ai-test-56", "ner": [[0, 3, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Association", "for", "Computational", "Linguistics", ",", "published", "by"], "sentence-detokenized": "Association for Computational Linguistics, published by", "token2charspan": [[0, 11], [12, 15], [16, 29], [30, 41], [41, 42], [43, 52], [53, 55]]}
{"doc_key": "ai-test-57", "ner": [[0, 3, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "computer", "facial", "recognition", ",", "each", "face", "is", "represented", "by", "a", "large", "number", "of", "pixel", "values", "."], "sentence-detokenized": "In computer facial recognition, each face is represented by a large number of pixel values.", "token2charspan": [[0, 2], [3, 11], [12, 18], [19, 30], [30, 31], [32, 36], [37, 41], [42, 44], [45, 56], [57, 59], [60, 61], [62, 67], [68, 74], [75, 77], [78, 83], [84, 90], [90, 91]]}
{"doc_key": "ai-test-58", "ner": [[5, 6, "person"], [13, 15, "organisation"], [22, 22, "country"], [25, 25, "person"], [34, 37, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 13, 15, "role", "", false, false], [5, 6, 22, 22, "physical", "", false, false], [25, 25, 34, 37, "origin", "", false, false], [25, 25, 34, 37, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2002", ",", "his", "son", "Daniel", "Pearl", ",", "a", "journalist", "working", "for", "the", "Wall", "Street", "Journal", ",", "was", "kidnapped", "and", "killed", "in", "Pakistan", ",", "prompting", "Judea", "and", "other", "family", "members", "and", "friends", "to", "create", "the", "Daniel", "Pearl", "Foundation", "."], "sentence-detokenized": "In 2002, his son Daniel Pearl, a journalist working for the Wall Street Journal, was kidnapped and killed in Pakistan, prompting Judea and other family members and friends to create the Daniel Pearl Foundation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 23], [24, 29], [29, 30], [31, 32], [33, 43], [44, 51], [52, 55], [56, 59], [60, 64], [65, 71], [72, 79], [79, 80], [81, 84], [85, 94], [95, 98], [99, 105], [106, 108], [109, 117], [117, 118], [119, 128], [129, 134], [135, 138], [139, 144], [145, 151], [152, 159], [160, 163], [164, 171], [172, 174], [175, 181], [182, 185], [186, 192], [193, 198], [199, 209], [209, 210]]}
{"doc_key": "ai-test-59", "ner": [[4, 7, "organisation"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 7, 18, 19, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "late", "2006", ",", "Red", "Envelope", "Entertainment", "has", "also", "expanded", "into", "original", "content", "production", "with", "directors", "such", "as", "John", "Waters", "."], "sentence-detokenized": "Since late 2006, Red Envelope Entertainment has also expanded into original content production with directors such as John Waters.", "token2charspan": [[0, 5], [6, 10], [11, 15], [15, 16], [17, 20], [21, 29], [30, 43], [44, 47], [48, 52], [53, 61], [62, 66], [67, 75], [76, 83], [84, 94], [95, 99], [100, 109], [110, 114], [115, 117], [118, 122], [123, 129], [129, 130]]}
{"doc_key": "ai-test-60", "ner": [[6, 10, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "building", "is", "now", "part", "of", "Beth", "Israel", "Deaconess", "Medical", "Center", "."], "sentence-detokenized": "The building is now part of Beth Israel Deaconess Medical Center.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 19], [20, 24], [25, 27], [28, 32], [33, 39], [40, 49], [50, 57], [58, 64], [64, 65]]}
{"doc_key": "ai-test-61", "ner": [[18, 19, "field"], [21, 22, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "common", "theme", "of", "this", "paper", "is", "the", "adoption", "of", "a", "sign", "-", "theoretic", "perspective", "on", "problems", "of", "artificial", "intelligence", "and", "knowledge", "representation", "."], "sentence-detokenized": "A common theme of this paper is the adoption of a sign-theoretic perspective on problems of artificial intelligence and knowledge representation.", "token2charspan": [[0, 1], [2, 8], [9, 14], [15, 17], [18, 22], [23, 28], [29, 31], [32, 35], [36, 44], [45, 47], [48, 49], [50, 54], [54, 55], [55, 64], [65, 76], [77, 79], [80, 88], [89, 91], [92, 102], [103, 115], [116, 119], [120, 129], [130, 144], [144, 145]]}
{"doc_key": "ai-test-62", "ner": [[5, 5, "task"], [9, 9, "task"], [19, 20, "task"], [38, 39, "task"], [41, 42, "task"], [48, 50, "task"], [52, 52, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 5, 19, 20, "type-of", "", false, false], [5, 5, 48, 50, "compare", "", false, false], [5, 5, 48, 50, "opposite", "", false, false], [9, 9, 5, 5, "named", "", false, false], [38, 39, 48, 50, "part-of", "", false, false], [41, 42, 48, 50, "part-of", "", false, false], [48, 50, 19, 20, "type-of", "", false, false], [52, 52, 48, 50, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["For", "example", ",", "the", "term", "neural", "machine", "translation", "(", "NMT", ")", "emphasizes", "that", "deep", "learning", "-", "based", "approaches", "in", "machine", "translation", "directly", "learn", "sequence", "-", "to", "-", "sequence", "transformations", ",", "eliminating", "the", "need", "for", "intermediate", "steps", "such", "as", "word", "alignment", "and", "language", "modeling", "that", "have", "been", "used", "in", "statistical", "machine", "translation", "(", "SMT", ")", "."], "sentence-detokenized": "For example, the term neural machine translation (NMT) emphasizes that deep learning-based approaches in machine translation directly learn sequence-to-sequence transformations, eliminating the need for intermediate steps such as word alignment and language modeling that have been used in statistical machine translation (SMT).", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 36], [37, 48], [49, 50], [50, 53], [53, 54], [55, 65], [66, 70], [71, 75], [76, 84], [84, 85], [85, 90], [91, 101], [102, 104], [105, 112], [113, 124], [125, 133], [134, 139], [140, 148], [148, 149], [149, 151], [151, 152], [152, 160], [161, 176], [176, 177], [178, 189], [190, 193], [194, 198], [199, 202], [203, 215], [216, 221], [222, 226], [227, 229], [230, 234], [235, 244], [245, 248], [249, 257], [258, 266], [267, 271], [272, 276], [277, 281], [282, 286], [287, 289], [290, 301], [302, 309], [310, 321], [322, 323], [323, 326], [326, 327], [327, 328]]}
{"doc_key": "ai-test-63", "ner": [[1, 1, "field"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 1, 6, 7, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Most", "WSD", "research", "is", "conducted", "using", "Word", "Net", "as", "a", "reference", "inventory", "for", "meanings", "."], "sentence-detokenized": "Most WSD research is conducted using WordNet as a reference inventory for meanings.", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 20], [21, 30], [31, 36], [37, 41], [41, 44], [45, 47], [48, 49], [50, 59], [60, 69], [70, 73], [74, 82], [82, 83]]}
{"doc_key": "ai-test-64", "ner": [[2, 2, "misc"], [10, 11, "researcher"], [13, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 2, 2, "general-affiliation", "", false, true], [13, 14, 2, 2, "general-affiliation", "", false, true]], "relations_mapping_to_source": [0, 1], "sentence": ["Notable", "former", "PhD", "and", "postdoctoral", "researchers", "in", "his", "group", "include", "Richard", "Zemel", "and", "Zoubin", "Ghahramani", "."], "sentence-detokenized": "Notable former PhD and postdoctoral researchers in his group include Richard Zemel and Zoubin Ghahramani.", "token2charspan": [[0, 7], [8, 14], [15, 18], [19, 22], [23, 35], [36, 47], [48, 50], [51, 54], [55, 60], [61, 68], [69, 76], [77, 82], [83, 86], [87, 93], [94, 104], [104, 105]]}
{"doc_key": "ai-test-65", "ner": [[7, 8, "metrics"], [13, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 13, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Each", "prediction", "result", "or", "instance", "of", "a", "confusion", "matrix", "represents", "a", "point", "in", "ROC", "space", "."], "sentence-detokenized": "Each prediction result or instance of a confusion matrix represents a point in ROC space.", "token2charspan": [[0, 4], [5, 15], [16, 22], [23, 25], [26, 34], [35, 37], [38, 39], [40, 49], [50, 56], [57, 67], [68, 69], [70, 75], [76, 78], [79, 82], [83, 88], [88, 89]]}
{"doc_key": "ai-test-66", "ner": [[3, 3, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [17, 19, "product"], [22, 24, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 22, 24, "physical", "", false, false], [7, 8, 22, 24, "physical", "", false, false], [10, 11, 22, 24, "physical", "", false, false], [17, 19, 3, 3, "artifact", "", false, false], [17, 19, 7, 8, "artifact", "", false, false], [17, 19, 10, 11, "artifact", "", false, false], [17, 19, 22, 24, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "1997", ",", "Thrun", "and", "his", "colleagues", "Wolfram", "Burgard", "and", "Dieter", "Fox", "developed", "the", "world", "'s", "first", "robotic", "tour", "guide", "in", "the", "Deutsches", "Museum", "Bonn", "(", "1997", ")", "."], "sentence-detokenized": "In 1997, Thrun and his colleagues Wolfram Burgard and Dieter Fox developed the world's first robotic tour guide in the Deutsches Museum Bonn (1997).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 18], [19, 22], [23, 33], [34, 41], [42, 49], [50, 53], [54, 60], [61, 64], [65, 74], [75, 78], [79, 84], [84, 86], [87, 92], [93, 100], [101, 105], [106, 111], [112, 114], [115, 118], [119, 128], [129, 135], [136, 140], [141, 142], [142, 146], [146, 147], [147, 148]]}
{"doc_key": "ai-test-67", "ner": [[0, 1, "product"], [7, 7, "misc"], [22, 24, "field"], [26, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 0, 1, "part-of", "", false, false], [22, 24, 0, 1, "usage", "", false, false], [26, 27, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Word", "Net", "is", "a", "lexical", "database", "containing", "semantic", "relationships", "between", "words", "in", "over", "200", "languages", ".", "It", "is", "mainly", "used", "in", "automatic", "natural", "language", "processing", "and", "artificial", "intelligence", "applications", "."], "sentence-detokenized": "WordNet is a lexical database containing semantic relationships between words in over 200 languages. It is mainly used in automatic natural language processing and artificial intelligence applications.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 12], [13, 20], [21, 29], [30, 40], [41, 49], [50, 63], [64, 71], [72, 77], [78, 80], [81, 85], [86, 89], [90, 99], [99, 100], [101, 103], [104, 106], [107, 113], [114, 118], [119, 121], [122, 131], [132, 139], [140, 148], [149, 159], [160, 163], [164, 174], [175, 187], [188, 200], [200, 201]]}
{"doc_key": "ai-test-68", "ner": [[5, 7, "field"], [12, 15, "conference"], [17, 25, "conference"], [27, 27, "conference"], [29, 29, "conference"], [7, 38, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 15, 5, 7, "topic", "", false, false], [12, 15, 7, 38, "topic", "", false, false], [17, 25, 5, 7, "topic", "", false, false], [17, 25, 7, 38, "topic", "", false, false], [27, 27, 5, 7, "topic", "", false, false], [27, 27, 7, 38, "topic", "", false, false], [29, 29, 5, 7, "topic", "", false, false], [29, 29, 7, 38, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Conferences", "in", "the", "field", "of", "natural", "language", "processing", ",", "such", "as", "the", "Association", "for", "Computational", "Linguistics", ",", "North", "American", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "EMNLP", "and", "HLT", ",", "are", "beginning", "to", "include", "papers", "on", "speech", "processing", "."], "sentence-detokenized": "Conferences in the field of natural language processing, such as the Association for Computational Linguistics, North American Chapter of the Association for Computational Linguistics, EMNLP and HLT, are beginning to include papers on speech processing.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 24], [25, 27], [28, 35], [36, 44], [45, 55], [55, 56], [57, 61], [62, 64], [65, 68], [69, 80], [81, 84], [85, 98], [99, 110], [110, 111], [112, 117], [118, 126], [127, 134], [135, 137], [138, 141], [142, 153], [154, 157], [158, 171], [172, 183], [183, 184], [185, 190], [191, 194], [195, 198], [198, 199], [200, 203], [204, 213], [214, 216], [217, 224], [225, 231], [232, 234], [235, 241], [242, 252], [252, 253]]}
{"doc_key": "ai-test-69", "ner": [[3, 3, "programlang"], [20, 22, "misc"], [32, 34, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "set", "of", "Java", "programs", "uses", "the", "lexicon", "to", "analyze", "variations", "in", "biomedical", "texts", "by", "correlating", "words", "according", "to", "their", "parts", "of", "speech", ",", "which", "can", "be", "useful", "in", "web", "searches", "or", "electronic", "medical", "records", "."], "sentence-detokenized": "A set of Java programs uses the lexicon to analyze variations in biomedical texts by correlating words according to their parts of speech, which can be useful in web searches or electronic medical records.", "token2charspan": [[0, 1], [2, 5], [6, 8], [9, 13], [14, 22], [23, 27], [28, 31], [32, 39], [40, 42], [43, 50], [51, 61], [62, 64], [65, 75], [76, 81], [82, 84], [85, 96], [97, 102], [103, 112], [113, 115], [116, 121], [122, 127], [128, 130], [131, 137], [137, 138], [139, 144], [145, 148], [149, 151], [152, 158], [159, 161], [162, 165], [166, 174], [175, 177], [178, 188], [189, 196], [197, 204], [204, 205]]}
{"doc_key": "ai-test-70", "ner": [[8, 8, "algorithm"], [10, 10, "algorithm"], [12, 12, "algorithm"], [14, 14, "algorithm"], [16, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "many", "more", "recent", "algorithms", "such", "as", "LPBoost", ",", "TotalBoost", ",", "BrownBoost", ",", "xgboost", ",", "MadaBoost", "and", "others", "."], "sentence-detokenized": "There are many more recent algorithms such as LPBoost, TotalBoost, BrownBoost, xgboost, MadaBoost and others.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 19], [20, 26], [27, 37], [38, 42], [43, 45], [46, 53], [53, 54], [55, 65], [65, 66], [67, 77], [77, 78], [79, 86], [86, 87], [88, 97], [98, 101], [102, 108], [108, 109]]}
{"doc_key": "ai-test-71", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "implementation", "in", "Python", ":"], "sentence-detokenized": "This is an example implementation in Python:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 33], [34, 36], [37, 43], [43, 44]]}
{"doc_key": "ai-test-72", "ner": [[1, 1, "organisation"], [2, 2, "product"], [7, 9, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 1, 1, "artifact", "made_by_company", false, false], [7, 9, 2, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Mattel", "Intellivision", "game", "console", "offered", "the", "Intellivoice", "Voice", "Synthesis", "module", "in", "1982", "."], "sentence-detokenized": "The Mattel Intellivision game console offered the Intellivoice Voice Synthesis module in 1982.", "token2charspan": [[0, 3], [4, 10], [11, 24], [25, 29], [30, 37], [38, 45], [46, 49], [50, 62], [63, 68], [69, 78], [79, 85], [86, 88], [89, 93], [93, 94]]}
{"doc_key": "ai-test-73", "ner": [[15, 20, "task"], [24, 25, "field"], [8, 38, "task"], [33, 37, "task"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [[33, 37, 8, 38, "type-of", "", false, false]], "relations_mapping_to_source": [3], "sentence": ["He", "has", "also", "worked", "in", "the", "field", "of", "machine", "translation", ",", "both", "in", "terms", "of", "high", "-", "precision", "knowledge", "-", "based", "machine", "translation", "and", "machine", "learning", "for", "statistical", "machine", "translation", "(", "such", "as", "generalized", "example", "-", "based", "machine", "translation", ")", "."], "sentence-detokenized": "He has also worked in the field of machine translation, both in terms of high-precision knowledge-based machine translation and machine learning for statistical machine translation (such as generalized example-based machine translation).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 21], [22, 25], [26, 31], [32, 34], [35, 42], [43, 54], [54, 55], [56, 60], [61, 63], [64, 69], [70, 72], [73, 77], [77, 78], [78, 87], [88, 97], [97, 98], [98, 103], [104, 111], [112, 123], [124, 127], [128, 135], [136, 144], [145, 148], [149, 160], [161, 168], [169, 180], [181, 182], [182, 186], [187, 189], [190, 201], [202, 209], [209, 210], [210, 215], [216, 223], [224, 235], [235, 236], [236, 237]]}
{"doc_key": "ai-test-74", "ner": [[0, 0, "misc"], [1, 7, "misc"], [22, 23, "algorithm"], [25, 26, "field"], [28, 29, "field"], [31, 31, "field"], [33, 34, "field"], [36, 36, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 22, 23, "general-affiliation", "", false, false], [0, 0, 25, 26, "general-affiliation", "", false, false], [0, 0, 28, 29, "general-affiliation", "", false, false], [0, 0, 31, 31, "general-affiliation", "", false, false], [0, 0, 33, 34, "general-affiliation", "", false, false], [0, 0, 36, 36, "general-affiliation", "", false, false], [1, 7, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Wolfram", "Mathematica", "(", "commonly", "referred", "to", "as", "Mathematica", ")", "is", "a", "modern", "technical", "computing", "system", "that", "covers", "most", "technical", "fields", "-", "including", "neural", "networks", ",", "machine", "learning", ",", "image", "processing", ",", "geometry", ",", "data", "science", ",", "visualizations", ",", "and", "more", "."], "sentence-detokenized": "Wolfram Mathematica (commonly referred to as Mathematica) is a modern technical computing system that covers most technical fields - including neural networks, machine learning, image processing, geometry, data science, visualizations, and more.", "token2charspan": [[0, 7], [8, 19], [20, 21], [21, 29], [30, 38], [39, 41], [42, 44], [45, 56], [56, 57], [58, 60], [61, 62], [63, 69], [70, 79], [80, 89], [90, 96], [97, 101], [102, 108], [109, 113], [114, 123], [124, 130], [131, 132], [133, 142], [143, 149], [150, 158], [158, 159], [160, 167], [168, 176], [176, 177], [178, 183], [184, 194], [194, 195], [196, 204], [204, 205], [206, 210], [211, 218], [218, 219], [220, 234], [234, 235], [236, 239], [240, 244], [244, 245]]}
{"doc_key": "ai-test-75", "ner": [[2, 7, "product"], [10, 11, "researcher"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 18, 2, 7, "type-of", "", false, false], [18, 18, 10, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "digitally", "operated", "and", "programmable", "robot", "was", "invented", "by", "George", "Devol", "in", "1954", "and", "was", "eventually", "named", "Unimate", "."], "sentence-detokenized": "The first digitally operated and programmable robot was invented by George Devol in 1954 and was eventually named Unimate.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 28], [29, 32], [33, 45], [46, 51], [52, 55], [56, 64], [65, 67], [68, 74], [75, 80], [81, 83], [84, 88], [89, 92], [93, 96], [97, 107], [108, 113], [114, 121], [121, 122]]}
{"doc_key": "ai-test-76", "ner": [[1, 1, "algorithm"], [3, 3, "algorithm"], [18, 19, "task"], [21, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 3, 3, "compare", "", false, false], [3, 3, 18, 19, "general-affiliation", "", false, false], [3, 3, 21, 22, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Like", "DBNs", ",", "DBMs", "can", "learn", "complex", "and", "abstract", "internal", "representations", "of", "input", "data", "in", "tasks", "such", "as", "object", "recognition", "or", "speech", "recognition", ",", "using", "limited", ",", "labeled", "data", "to", "fine", "-", "tune", "representations", "constructed", "using", "a", "large", "set", "of", "unlabeled", "sensory", "input", "data", "."], "sentence-detokenized": "Like DBNs, DBMs can learn complex and abstract internal representations of input data in tasks such as object recognition or speech recognition, using limited, labeled data to fine-tune representations constructed using a large set of unlabeled sensory input data.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 15], [16, 19], [20, 25], [26, 33], [34, 37], [38, 46], [47, 55], [56, 71], [72, 74], [75, 80], [81, 85], [86, 88], [89, 94], [95, 99], [100, 102], [103, 109], [110, 121], [122, 124], [125, 131], [132, 143], [143, 144], [145, 150], [151, 158], [158, 159], [160, 167], [168, 172], [173, 175], [176, 180], [180, 181], [181, 185], [186, 201], [202, 213], [214, 219], [220, 221], [222, 227], [228, 231], [232, 234], [235, 244], [245, 252], [253, 258], [259, 263], [263, 264]]}
{"doc_key": "ai-test-77", "ner": [[5, 9, "task"], [14, 14, "conference"], [16, 16, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 5, 9, "topic", "", false, false], [16, 16, 5, 9, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "scientific", "conferences", "where", "papers", "recognising", "vision", "-", "based", "activities", "often", "appear", "are", "the", "ICCV", "and", "CVPR", "."], "sentence-detokenized": "The scientific conferences where papers recognising vision-based activities often appear are the ICCV and CVPR.", "token2charspan": [[0, 3], [4, 14], [15, 26], [27, 32], [33, 39], [40, 51], [52, 58], [58, 59], [59, 64], [65, 75], [76, 81], [82, 88], [89, 92], [93, 96], [97, 101], [102, 105], [106, 110], [110, 111]]}
{"doc_key": "ai-test-78", "ner": [[1, 1, "field"], [4, 5, "algorithm"], [7, 7, "algorithm"], [17, 17, "metrics"], [16, 21, "metrics"], [23, 26, "metrics"], [37, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 5, 1, 1, "part-of", "", false, false], [4, 5, 17, 17, "related-to", "finds", false, false], [4, 5, 16, 21, "related-to", "finds", false, false], [4, 5, 37, 37, "related-to", "", false, false], [7, 7, 4, 5, "named", "", false, false], [23, 26, 16, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "statistics", ",", "an", "expectation", "maximization", "(", "EM", ")", "algorithm", "is", "an", "iterative", "method", "for", "finding", "maximum", "likelihood", "or", "maximum", "a", "posteriori", "(", "MAP", ")", "estimates", "of", "parameters", "in", "statistical", "models", "where", "the", "model", "depends", "on", "unobserved", "latent", "variables", "."], "sentence-detokenized": "In statistics, an expectation maximization (EM) algorithm is an iterative method for finding maximum likelihood or maximum a posteriori (MAP) estimates of parameters in statistical models where the model depends on unobserved latent variables.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 17], [18, 29], [30, 42], [43, 44], [44, 46], [46, 47], [48, 57], [58, 60], [61, 63], [64, 73], [74, 80], [81, 84], [85, 92], [93, 100], [101, 111], [112, 114], [115, 122], [123, 124], [125, 135], [136, 137], [137, 140], [140, 141], [142, 151], [152, 154], [155, 165], [166, 168], [169, 180], [181, 187], [188, 193], [194, 197], [198, 203], [204, 211], [212, 214], [215, 225], [226, 232], [233, 242], [242, 243]]}
{"doc_key": "ai-test-79", "ner": [[7, 8, "metrics"], [10, 12, "metrics"], [6, 15, "metrics"], [17, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 12, 7, 8, "named", "", false, false], [17, 17, 6, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Similarly", ",", "investigators", "sometimes", "report", "both", "false", "positive", "rates", "(", "FPR", ")", "and", "false", "negative", "rates", "(", "FNR", ")", "."], "sentence-detokenized": "Similarly, investigators sometimes report both false positive rates (FPR) and false negative rates (FNR).", "token2charspan": [[0, 9], [9, 10], [11, 24], [25, 34], [35, 41], [42, 46], [47, 52], [53, 61], [62, 67], [68, 69], [69, 72], [72, 73], [74, 77], [78, 83], [84, 92], [93, 98], [99, 100], [100, 103], [103, 104], [104, 105]]}
{"doc_key": "ai-test-80", "ner": [[6, 11, "metrics"], [14, 14, "field"], [17, 18, "metrics"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 14, 6, 11, "usage", "", false, false], [21, 22, 17, 18, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "concept", "is", "similar", "to", "the", "signal", "-", "to", "-", "noise", "ratio", "used", "in", "science", "and", "the", "confusion", "matrix", "used", "in", "artificial", "intelligence", "."], "sentence-detokenized": "The concept is similar to the signal-to-noise ratio used in science and the confusion matrix used in artificial intelligence.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 25], [26, 29], [30, 36], [36, 37], [37, 39], [39, 40], [40, 45], [46, 51], [52, 56], [57, 59], [60, 67], [68, 71], [72, 75], [76, 85], [86, 92], [93, 97], [98, 100], [101, 111], [112, 124], [124, 125]]}
{"doc_key": "ai-test-81", "ner": [[5, 6, "field"], [13, 14, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [33, 36, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 13, 14, "general-affiliation", "", false, false], [5, 6, 20, 21, "general-affiliation", "", false, false], [5, 6, 23, 24, "general-affiliation", "", false, false], [33, 36, 5, 6, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Code", "of", "Ethics", "on", "Human", "Augmentation", ",", "which", "was", "originally", "introduced", "by", "Steve", "Mann", "in", "2004", "and", "refined", "with", "Ray", "Kurzweil", "and", "Marvin", "Minsky", "in", "2013", ",", "was", "finally", "ratified", "at", "the", "Virtual", "Reality", "Toronto", "conference", "on", "June", "25", ",", "2017", "."], "sentence-detokenized": "The Code of Ethics on Human Augmentation, which was originally introduced by Steve Mann in 2004 and refined with Ray Kurzweil and Marvin Minsky in 2013, was finally ratified at the Virtual Reality Toronto conference on June 25, 2017.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 18], [19, 21], [22, 27], [28, 40], [40, 41], [42, 47], [48, 51], [52, 62], [63, 73], [74, 76], [77, 82], [83, 87], [88, 90], [91, 95], [96, 99], [100, 107], [108, 112], [113, 116], [117, 125], [126, 129], [130, 136], [137, 143], [144, 146], [147, 151], [151, 152], [153, 156], [157, 164], [165, 173], [174, 176], [177, 180], [181, 188], [189, 196], [197, 204], [205, 215], [216, 218], [219, 223], [224, 226], [226, 227], [228, 232], [232, 233]]}
{"doc_key": "ai-test-82", "ner": [[3, 6, "person"], [10, 13, "organisation"], [19, 20, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 6, 10, 13, "role", "directed_for", false, false], [3, 6, 19, 20, "role", "collaborator", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1913", ",", "Walter", "R.", "Booth", "directed", "10", "films", "for", "Kinoplastikon", "in", "the", "UK", ",", "probably", "in", "collaboration", "with", "Cecil", "Hepworth", "."], "sentence-detokenized": "In 1913, Walter R. Booth directed 10 films for Kinoplastikon in the UK, probably in collaboration with Cecil Hepworth.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 18], [19, 24], [25, 33], [34, 36], [37, 42], [43, 46], [47, 60], [61, 63], [64, 67], [68, 70], [70, 71], [72, 80], [81, 83], [84, 97], [98, 102], [103, 108], [109, 117], [117, 118]]}
{"doc_key": "ai-test-83", "ner": [[16, 16, "location"], [13, 14, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 14, 16, 16, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["They", "unveiled", "their", "new", "robot", "in", "1961", "at", "a", "trade", "show", "at", "the", "Cow", "Palace", "in", "Chicago", "."], "sentence-detokenized": "They unveiled their new robot in 1961 at a trade show at the Cow Palace in Chicago.", "token2charspan": [[0, 4], [5, 13], [14, 19], [20, 23], [24, 29], [30, 32], [33, 37], [38, 40], [41, 42], [43, 48], [49, 53], [54, 56], [57, 60], [61, 64], [65, 71], [72, 74], [75, 82], [82, 83]]}
{"doc_key": "ai-test-84", "ner": [[2, 8, "product"], [6, 7, "task"], [10, 12, "field"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 8, 6, 7, "usage", "", false, false], [2, 8, 10, 12, "usage", "", false, false], [2, 8, 15, 16, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["While", "some", "chatbot", "applications", "use", "extensive", "word", "classification", "processes", ",", "natural", "language", "processors", "and", "sophisticated", "artificial", "intelligence", ",", "others", "simply", "scan", "general", "keywords", "and", "generate", "responses", "using", "common", "phrases", "obtained", "from", "a", "library", "or", "related", "database", "."], "sentence-detokenized": "While some chatbot applications use extensive word classification processes, natural language processors and sophisticated artificial intelligence, others simply scan general keywords and generate responses using common phrases obtained from a library or related database.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 31], [32, 35], [36, 45], [46, 50], [51, 65], [66, 75], [75, 76], [77, 84], [85, 93], [94, 104], [105, 108], [109, 122], [123, 133], [134, 146], [146, 147], [148, 154], [155, 161], [162, 166], [167, 174], [175, 183], [184, 187], [188, 196], [197, 206], [207, 212], [213, 219], [220, 227], [228, 236], [237, 241], [242, 243], [244, 251], [252, 254], [255, 262], [263, 271], [271, 272]]}
{"doc_key": "ai-test-85", "ner": [[1, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "WaveNet", "model", "proposed", "in", "2016", "achieves", "outstanding", "performance", "in", "speech", "quality", "."], "sentence-detokenized": "The WaveNet model proposed in 2016 achieves outstanding performance in speech quality.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 43], [44, 55], [56, 67], [68, 70], [71, 77], [78, 85], [85, 86]]}
{"doc_key": "ai-test-86", "ner": [[4, 4, "product"], [6, 7, "misc"], [9, 10, "misc"], [12, 13, "misc"], [16, 19, "misc"], [21, 23, "organisation"], [25, 25, "organisation"], [27, 30, "organisation"], [32, 32, "organisation"], [34, 37, "organisation"], [39, 40, "organisation"], [42, 42, "organisation"], [44, 46, "organisation"], [48, 48, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 4, 6, 7, "general-affiliation", "", false, false], [4, 4, 9, 10, "general-affiliation", "", false, false], [4, 4, 12, 13, "general-affiliation", "", false, false], [4, 4, 16, 19, "general-affiliation", "", false, false], [21, 23, 4, 4, "usage", "", false, false], [25, 25, 4, 4, "usage", "", false, false], [27, 30, 4, 4, "usage", "", false, false], [32, 32, 4, 4, "usage", "", false, false], [34, 37, 4, 4, "usage", "", false, false], [39, 40, 4, 4, "usage", "", false, false], [42, 42, 4, 4, "usage", "", false, false], [44, 46, 4, 4, "usage", "", false, false], [48, 48, 4, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Organizations", "known", "to", "use", "ALE", "for", "emergency", "management", ",", "disaster", "relief", ",", "routine", "communication", ",", "or", "response", "to", "extraordinary", "situations", ":", "American", "Red", "Cross", ",", "FEMA", ",", "Disaster", "Medical", "Assistance", "Teams", ",", "NATO", ",", "Federal", "Bureau", "of", "Investigation", ",", "United", "Nations", ",", "AT&T", ",", "Civil", "Air", "Patrol", "(", "ARES", ")", "."], "sentence-detokenized": "Organizations known to use ALE for emergency management, disaster relief, routine communication, or response to extraordinary situations: American Red Cross, FEMA, Disaster Medical Assistance Teams, NATO, Federal Bureau of Investigation, United Nations, AT&T, Civil Air Patrol (ARES).", "token2charspan": [[0, 13], [14, 19], [20, 22], [23, 26], [27, 30], [31, 34], [35, 44], [45, 55], [55, 56], [57, 65], [66, 72], [72, 73], [74, 81], [82, 95], [95, 96], [97, 99], [100, 108], [109, 111], [112, 125], [126, 136], [136, 137], [138, 146], [147, 150], [151, 156], [156, 157], [158, 162], [162, 163], [164, 172], [173, 180], [181, 191], [192, 197], [197, 198], [199, 203], [203, 204], [205, 212], [213, 219], [220, 222], [223, 236], [236, 237], [238, 244], [245, 252], [252, 253], [254, 258], [258, 259], [260, 265], [266, 269], [270, 276], [277, 278], [278, 282], [282, 283], [283, 284]]}
{"doc_key": "ai-test-87", "ner": [[3, 4, "algorithm"], [15, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Here", ",", "the", "Kronecker", "delta", "is", "used", "for", "simplicity", "(", "see", "the", "derivative", "of", "a", "sigmoid", "function", ",", "which", "is", "expressed", "via", "the", "function", "itself", ")", "."], "sentence-detokenized": "Here, the Kronecker delta is used for simplicity (see the derivative of a sigmoid function, which is expressed via the function itself).", "token2charspan": [[0, 4], [4, 5], [6, 9], [10, 19], [20, 25], [26, 28], [29, 33], [34, 37], [38, 48], [49, 50], [50, 53], [54, 57], [58, 68], [69, 71], [72, 73], [74, 81], [82, 90], [90, 91], [92, 97], [98, 100], [101, 110], [111, 114], [115, 118], [119, 127], [128, 134], [134, 135], [135, 136]]}
{"doc_key": "ai-test-88", "ner": [[11, 12, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "theory", "is", "based", "on", "philosophical", "foundations", "and", "was", "founded", "by", "Ray", "Solomonoff", "around", "1960", ".", "Samuel", "Rathmanner", "and", "Marcus", "Hutter", "."], "sentence-detokenized": "The theory is based on philosophical foundations and was founded by Ray Solomonoff around 1960. Samuel Rathmanner and Marcus Hutter.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 36], [37, 48], [49, 52], [53, 56], [57, 64], [65, 67], [68, 71], [72, 82], [83, 89], [90, 94], [94, 95], [96, 102], [103, 113], [114, 117], [118, 124], [125, 131], [131, 132]]}
{"doc_key": "ai-test-89", "ner": [[0, 0, "product"], [10, 11, "misc"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 10, 11, "type-of", "", false, false], [0, 0, 14, 15, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["WordNet", ",", "a", "freely", "available", "database", "originally", "conceived", "as", "a", "semantic", "network", "based", "on", "psycholinguistic", "principles", ",", "has", "been", "extended", "by", "adding", "definitions", "and", "is", "now", "also", "seen", "as", "a", "dictionary", "."], "sentence-detokenized": "WordNet, a freely available database originally conceived as a semantic network based on psycholinguistic principles, has been extended by adding definitions and is now also seen as a dictionary.", "token2charspan": [[0, 7], [7, 8], [9, 10], [11, 17], [18, 27], [28, 36], [37, 47], [48, 57], [58, 60], [61, 62], [63, 71], [72, 79], [80, 85], [86, 88], [89, 105], [106, 116], [116, 117], [118, 121], [122, 126], [127, 135], [136, 138], [139, 145], [146, 157], [158, 161], [162, 164], [165, 168], [169, 173], [174, 178], [179, 181], [182, 183], [184, 194], [194, 195]]}
{"doc_key": "ai-test-90", "ner": [[2, 3, "field"], [13, 13, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 13, 2, 3, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Advances", "in", "computational", "imaging", "research", "are", "featured", "in", "several", "places", ",", "including", "in", "SIGGRAPH", "publications", "and", "in", "."], "sentence-detokenized": "Advances in computational imaging research are featured in several places, including in SIGGRAPH publications and in.", "token2charspan": [[0, 8], [9, 11], [12, 25], [26, 33], [34, 42], [43, 46], [47, 55], [56, 58], [59, 66], [67, 73], [73, 74], [75, 84], [85, 87], [88, 96], [97, 109], [110, 113], [114, 116], [116, 117]]}
{"doc_key": "ai-test-91", "ner": [[0, 0, "task"], [9, 10, "task"], [12, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 0, "part-of", "", false, false], [12, 12, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "viewed", "as", "two", "distinct", "problems", "-", "binary", "classification", "and", "multi-class", "classification", "."], "sentence-detokenized": "Classification can be viewed as two distinct problems - binary classification and multi-class classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 28], [29, 31], [32, 35], [36, 44], [45, 53], [54, 55], [56, 62], [63, 77], [78, 81], [82, 93], [94, 108], [108, 109]]}
{"doc_key": "ai-test-92", "ner": [[12, 12, "algorithm"], [17, 19, "algorithm"], [21, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 19, 12, 12, "type-of", "", false, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Advanced", "gene", "finders", "for", "both", "prokaryotic", "and", "eukaryotic", "genomes", "typically", "use", "complex", "probabilistic", "models", ",", "such", "as", "Hidden", "Markov", "Models", "(", "HMMs", ")", ",", "to", "combine", "information", "from", "a", "variety", "of", "different", "signal", "and", "content", "measurements", "."], "sentence-detokenized": "Advanced gene finders for both prokaryotic and eukaryotic genomes typically use complex probabilistic models, such as Hidden Markov Models (HMMs), to combine information from a variety of different signal and content measurements.", "token2charspan": [[0, 8], [9, 13], [14, 21], [22, 25], [26, 30], [31, 42], [43, 46], [47, 57], [58, 65], [66, 75], [76, 79], [80, 87], [88, 101], [102, 108], [108, 109], [110, 114], [115, 117], [118, 124], [125, 131], [132, 138], [139, 140], [140, 144], [144, 145], [145, 146], [147, 149], [150, 157], [158, 169], [170, 174], [175, 176], [177, 184], [185, 187], [188, 197], [198, 204], [205, 208], [209, 216], [217, 229], [229, 230]]}
{"doc_key": "ai-test-93", "ner": [[0, 2, "misc"], [7, 8, "field"], [11, 12, "algorithm"], [15, 17, "algorithm"], [19, 19, "algorithm"], [29, 30, "algorithm"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6], "relations": [[19, 19, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [4], "sentence": ["Neuroevolution", "or", "neuroevolution", "is", "a", "form", "of", "artificial", "intelligence", "that", "uses", "evolutionary", "algorithms", "to", "generate", "artificial", "neural", "networks", "(", "ANNs", ")", ",", "parameters", ",", "topology", "and", "rules", ".", "and", "evolutionary", "robotics", "."], "sentence-detokenized": "Neuroevolution or neuroevolution is a form of artificial intelligence that uses evolutionary algorithms to generate artificial neural networks (ANNs), parameters, topology and rules. and evolutionary robotics.", "token2charspan": [[0, 14], [15, 17], [18, 32], [33, 35], [36, 37], [38, 42], [43, 45], [46, 56], [57, 69], [70, 74], [75, 79], [80, 92], [93, 103], [104, 106], [107, 115], [116, 126], [127, 133], [134, 142], [143, 144], [144, 148], [148, 149], [149, 150], [151, 161], [161, 162], [163, 171], [172, 175], [176, 181], [181, 182], [183, 186], [187, 199], [200, 208], [208, 209]]}
{"doc_key": "ai-test-94", "ner": [[1, 1, "organisation"], [6, 6, "metrics"], [8, 8, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 1, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "IBM", "proposed", "and", "implemented", "the", "BLEU", "system", "Papineni", "et", "al", "."], "sentence-detokenized": "Since IBM proposed and implemented the BLEU system Papineni et al.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 22], [23, 34], [35, 38], [39, 43], [44, 50], [51, 59], [60, 62], [63, 65], [65, 66]]}
{"doc_key": "ai-test-95", "ner": [[9, 16, "conference"], [18, 18, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 18, 9, 16, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2009", ",", "experts", "attended", "a", "conference", "organised", "by", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "to", "discuss", "whether", "computers", "and", "robots", "could", "become", "autonomous", "and", "to", "what", "extent", "these", "abilities", "could", "pose", "a", "threat", "or", "a", "danger", "."], "sentence-detokenized": "In 2009, experts attended a conference organised by the Association for the Advancement of Artificial Intelligence (AAAI) to discuss whether computers and robots could become autonomous and to what extent these abilities could pose a threat or a danger.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 25], [26, 27], [28, 38], [39, 48], [49, 51], [52, 55], [56, 67], [68, 71], [72, 75], [76, 87], [88, 90], [91, 101], [102, 114], [115, 116], [116, 120], [120, 121], [122, 124], [125, 132], [133, 140], [141, 150], [151, 154], [155, 161], [162, 167], [168, 174], [175, 185], [186, 189], [190, 192], [193, 197], [198, 204], [205, 210], [211, 220], [221, 226], [227, 231], [232, 233], [234, 240], [241, 243], [244, 245], [246, 252], [252, 253]]}
{"doc_key": "ai-test-96", "ner": [[25, 27, "metrics"], [28, 30, "researcher"], [32, 33, "researcher"], [35, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[35, 40, 25, 27, "topic", "", false, false], [35, 40, 28, 30, "artifact", "", false, false], [35, 40, 32, 33, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["After", "amplification", ",", "a", "classifier", "constructed", "from", "200", "features", "could", "produce", "a", "95", "%", "detection", "rate", "under", "a", "^", "{", "-", "5", "}", "/", "math", "FALSE", "positive", "rate", ".P", ".", "Viola", ",", "M.", "Jones", ",", "Robust", "Real", "-", "time", "Object", "Detection", ",", "2001", "."], "sentence-detokenized": "After amplification, a classifier constructed from 200 features could produce a 95% detection rate under a ^ {-5} / math FALSE positive rate .P. Viola, M. Jones, Robust Real-time Object Detection, 2001.", "token2charspan": [[0, 5], [6, 19], [19, 20], [21, 22], [23, 33], [34, 45], [46, 50], [51, 54], [55, 63], [64, 69], [70, 77], [78, 79], [80, 82], [82, 83], [84, 93], [94, 98], [99, 104], [105, 106], [107, 108], [109, 110], [110, 111], [111, 112], [112, 113], [114, 115], [116, 120], [121, 126], [127, 135], [136, 140], [141, 143], [143, 144], [145, 150], [150, 151], [152, 154], [155, 160], [160, 161], [162, 168], [169, 173], [173, 174], [174, 178], [179, 185], [186, 195], [195, 196], [197, 201], [201, 202]]}
{"doc_key": "ai-test-97", "ner": [[5, 9, "programlang"], [10, 10, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Originally", ",", "the", "site", "was", "Perl", "-", "based", ",", "but", "IMDb", "no", "longer", "discloses", "what", "software", "it", "uses", "for", "security", "reasons", "."], "sentence-detokenized": "Originally, the site was Perl-based, but IMDb no longer discloses what software it uses for security reasons.", "token2charspan": [[0, 10], [10, 11], [12, 15], [16, 20], [21, 24], [25, 29], [29, 30], [30, 35], [35, 36], [37, 40], [41, 45], [46, 48], [49, 55], [56, 65], [66, 70], [71, 79], [80, 82], [83, 87], [88, 91], [92, 100], [101, 108], [108, 109]]}
{"doc_key": "ai-test-98", "ner": [[7, 8, "researcher"], [10, 11, "researcher"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "start", "-", "up", "was", "founded", "by", "Demis", "Hassabis", ",", "Shane", "Legg", "and", "Mustafa", "Suleyman", "in", "2010", "."], "sentence-detokenized": "The start-up was founded by Demis Hassabis, Shane Legg and Mustafa Suleyman in 2010.", "token2charspan": [[0, 3], [4, 9], [9, 10], [10, 12], [13, 16], [17, 24], [25, 27], [28, 33], [34, 42], [42, 43], [44, 49], [50, 54], [55, 58], [59, 66], [67, 75], [76, 78], [79, 83], [83, 84]]}
{"doc_key": "ai-test-99", "ner": [[3, 4, "misc"], [7, 10, "metrics"], [24, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 10, 3, 4, "type-of", "", false, false], [24, 25, 3, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "commonly", "used", "loss", "functions", "are", "the", "root", "mean", "square", "error", ",", "mathL", "(", "a", ")", "=", "a", "^2", "/", "math", ",", "and", "the", "absolute", "loss", ",", "mathL", "(", "a", ")", "=", "|", "a", "|", "/", "math", "."], "sentence-detokenized": "Two commonly used loss functions are the root mean square error, mathL (a) = a^2 / math, and the absolute loss, mathL (a) = | a | / math.", "token2charspan": [[0, 3], [4, 12], [13, 17], [18, 22], [23, 32], [33, 36], [37, 40], [41, 45], [46, 50], [51, 57], [58, 63], [63, 64], [65, 70], [71, 72], [72, 73], [73, 74], [75, 76], [77, 78], [78, 80], [81, 82], [83, 87], [87, 88], [89, 92], [93, 96], [97, 105], [106, 110], [110, 111], [112, 117], [118, 119], [119, 120], [120, 121], [122, 123], [124, 125], [126, 127], [128, 129], [130, 131], [132, 136], [136, 137]]}
{"doc_key": "ai-test-100", "ner": [[0, 5, "algorithm"], [12, 14, "algorithm"], [16, 16, "algorithm"], [19, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 5, 12, 14, "type-of", "example_of", false, false], [12, 14, 19, 20, "related-to", "", false, false], [16, 16, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "soft", "margin", "support", "vector", "machine", "described", "above", "is", "an", "example", "of", "empirical", "risk", "minimization", "(", "ERM", ")", "for", "hinge", "loss", "."], "sentence-detokenized": "The soft margin support vector machine described above is an example of empirical risk minimization (ERM) for hinge loss.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 23], [24, 30], [31, 38], [39, 48], [49, 54], [55, 57], [58, 60], [61, 68], [69, 71], [72, 81], [82, 86], [87, 99], [100, 101], [101, 104], [104, 105], [106, 109], [110, 115], [116, 120], [120, 121]]}
{"doc_key": "ai-test-101", "ner": [[8, 9, "field"], [0, 2, "task"], [19, 19, "organisation"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[0, 2, 8, 9, "origin", "", false, false], [19, 19, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 2], "sentence": ["Neural", "machine", "translation", ",", "an", "approach", "based", "on", "deep", "learning", ",", "has", "progressed", "rapidly", "in", "recent", "years", ",", "and", "Google", "has", "announced", "that", "its", "translation", "services", "now", "use", "this", "technology", "instead", "of", "previous", "statistical", "methods", "."], "sentence-detokenized": "Neural machine translation, an approach based on deep learning, has progressed rapidly in recent years, and Google has announced that its translation services now use this technology instead of previous statistical methods.", "token2charspan": [[0, 6], [7, 14], [15, 26], [26, 27], [28, 30], [31, 39], [40, 45], [46, 48], [49, 53], [54, 62], [62, 63], [64, 67], [68, 78], [79, 86], [87, 89], [90, 96], [97, 102], [102, 103], [104, 107], [108, 114], [115, 118], [119, 128], [129, 133], [134, 137], [138, 149], [150, 158], [159, 162], [163, 166], [167, 171], [172, 182], [183, 190], [191, 193], [194, 202], [203, 214], [215, 222], [222, 223]]}
{"doc_key": "ai-test-102", "ner": [[15, 15, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "tends", "to", "produce", "very", "large", "performance", "gains", "when", "working", "with", "large", "corpora", "such", "as", "WordNet", "."], "sentence-detokenized": "This tends to produce very large performance gains when working with large corpora such as WordNet.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 21], [22, 26], [27, 32], [33, 44], [45, 50], [51, 55], [56, 63], [64, 68], [69, 74], [75, 82], [83, 87], [88, 90], [91, 98], [98, 99]]}
{"doc_key": "ai-test-103", "ner": [[0, 2, "task"], [5, 5, "field"], [18, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 18, 20, "part-of", "", false, false], [18, 20, 5, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Face", "detection", "is", "used", "in", "biometrics", ",", "often", "as", "part", "of", "(", "or", "in", "conjunction", "with", ")", "a", "facial", "recognition", "system", "."], "sentence-detokenized": "Face detection is used in biometrics, often as part of (or in conjunction with) a facial recognition system.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 22], [23, 25], [26, 36], [36, 37], [38, 43], [44, 46], [47, 51], [52, 54], [55, 56], [56, 58], [59, 61], [62, 73], [74, 78], [78, 79], [80, 81], [82, 88], [89, 100], [101, 107], [107, 108]]}
{"doc_key": "ai-test-104", "ner": [[2, 4, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["trained", "by", "maximum", "likelihood", "estimation", "."], "sentence-detokenized": "trained by maximum likelihood estimation.", "token2charspan": [[0, 7], [8, 10], [11, 18], [19, 29], [30, 40], [40, 41]]}
{"doc_key": "ai-test-105", "ner": [[3, 3, "country"], [5, 10, "organisation"], [13, 13, "location"], [15, 15, "country"], [17, 20, "organisation"], [22, 22, "country"], [28, 28, "organisation"], [33, 37, "organisation"], [39, 39, "country"], [50, 53, "organisation"], [55, 57, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[5, 10, 13, 13, "physical", "", false, false], [13, 13, 15, 15, "physical", "", false, false], [17, 20, 22, 22, "physical", "", false, false], [33, 37, 39, 39, "physical", "", false, false], [50, 53, 55, 57, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Ltd", ".", "in", "Thailand", ";", "Komatsu", "(", "Shanghai", ")", "Ltd.", "in", "1996", "in", "Shanghai", ",", "China", ";", "Industrial", "Power", "Alliance", "Ltd.", "in", "Japan", ",", "a", "joint", "venture", "with", "Cummins", ",", "in", "1998", ";", "L", "&", "T-", "Komatsu", "Limited", "in", "India", "in", "1998", "(", "shares", "sold", "in", "2013", ")", ";", "and", "Komatsu", "Brasil", "International", "Ltda.", "in", "Brazil", ",", "in", "1998", "."], "sentence-detokenized": "Ltd. in Thailand; Komatsu (Shanghai) Ltd. in 1996 in Shanghai, China; Industrial Power Alliance Ltd. in Japan, a joint venture with Cummins, in 1998; L & T-Komatsu Limited in India in 1998 (shares sold in 2013); and Komatsu Brasil International Ltda. in Brazil, in 1998.", "token2charspan": [[0, 3], [3, 4], [5, 7], [8, 16], [16, 17], [18, 25], [26, 27], [27, 35], [35, 36], [37, 41], [42, 44], [45, 49], [50, 52], [53, 61], [61, 62], [63, 68], [68, 69], [70, 80], [81, 86], [87, 95], [96, 100], [101, 103], [104, 109], [109, 110], [111, 112], [113, 118], [119, 126], [127, 131], [132, 139], [139, 140], [141, 143], [144, 148], [148, 149], [150, 151], [152, 153], [154, 156], [156, 163], [164, 171], [172, 174], [175, 180], [181, 183], [184, 188], [189, 190], [190, 196], [197, 201], [202, 204], [205, 209], [209, 210], [210, 211], [212, 215], [216, 223], [224, 230], [231, 244], [245, 250], [251, 253], [254, 260], [260, 261], [262, 264], [265, 269], [269, 270]]}
{"doc_key": "ai-test-106", "ner": [[1, 1, "organisation"], [5, 7, "misc"], [10, 11, "misc"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 14, 1, 1, "physical", "", false, false], [13, 14, 5, 7, "general-affiliation", "", false, false], [13, 14, 10, 11, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "dgp", "also", "occasionally", "hosts", "artists", "in", "residence", "(", "e.g.", "Academy", "Award", "winner", "Chris", "Landreth", "."], "sentence-detokenized": "The dgp also occasionally hosts artists in residence (e.g. Academy Award winner Chris Landreth.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 25], [26, 31], [32, 39], [40, 42], [43, 52], [53, 54], [54, 58], [59, 66], [67, 72], [73, 79], [80, 85], [86, 94], [94, 95]]}
{"doc_key": "ai-test-107", "ner": [[6, 9, "misc"], [12, 13, "misc"], [17, 20, "misc"], [24, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "currently", "includes", "four", "sub-competitions", "-", "the", "RoboMaster", "Robotics", "Competition", ",", "the", "RoboMaster", "Technical", "Challenge", ",", "the", "ICRA", "RoboMaster", "AI", "Challenge", "and", "the", "new", "RoboMaster", "Youth", "Tournament", "."], "sentence-detokenized": "It currently includes four sub-competitions - the RoboMaster Robotics Competition, the RoboMaster Technical Challenge, the ICRA RoboMaster AI Challenge and the new RoboMaster Youth Tournament.", "token2charspan": [[0, 2], [3, 12], [13, 21], [22, 26], [27, 43], [44, 45], [46, 49], [50, 60], [61, 69], [70, 81], [81, 82], [83, 86], [87, 97], [98, 107], [108, 117], [117, 118], [119, 122], [123, 127], [128, 138], [139, 141], [142, 151], [152, 155], [156, 159], [160, 163], [164, 174], [175, 180], [181, 191], [191, 192]]}
{"doc_key": "ai-test-108", "ner": [[7, 8, "field"], [16, 19, "algorithm"], [22, 23, "algorithm"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 22, 23, "usage", "", false, false], [7, 8, 25, 26, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "the", "early", "2000s", ",", "the", "dominant", "speech", "processing", "strategy", "began", "to", "move", "away", "from", "the", "hidden", "Markov", "model", "towards", "more", "modern", "neural", "networks", "and", "deep", "learning", "."], "sentence-detokenized": "In the early 2000s, the dominant speech processing strategy began to move away from the hidden Markov model towards more modern neural networks and deep learning.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 18], [18, 19], [20, 23], [24, 32], [33, 39], [40, 50], [51, 59], [60, 65], [66, 68], [69, 73], [74, 78], [79, 83], [84, 87], [88, 94], [95, 101], [102, 107], [108, 115], [116, 120], [121, 127], [128, 134], [135, 143], [144, 147], [148, 152], [153, 161], [161, 162]]}
{"doc_key": "ai-test-109", "ner": [[9, 10, "misc"], [16, 16, "metrics"], [21, 22, "metrics"], [30, 30, "metrics"], [35, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[16, 16, 21, 22, "related-to", "equal", false, false], [30, 30, 35, 37, "related-to", "equal", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "equivalent", "expression", ",", "in", "the", "case", "of", "a", "binary", "target", "rate", ",", "is", "that", "the", "TRUE", "positive", "rate", "and", "the", "FALSE", "positive", "rate", "are", "equal", "(", "and", "therefore", "the", "FALSE", "negative", "rate", "and", "the", "TRUE", "negative", "rate", "are", "equal", ")", "for", "each", "value", "of", "the", "sensitive", "characteristics", ":"], "sentence-detokenized": "Another equivalent expression, in the case of a binary target rate, is that the TRUE positive rate and the FALSE positive rate are equal (and therefore the FALSE negative rate and the TRUE negative rate are equal) for each value of the sensitive characteristics:", "token2charspan": [[0, 7], [8, 18], [19, 29], [29, 30], [31, 33], [34, 37], [38, 42], [43, 45], [46, 47], [48, 54], [55, 61], [62, 66], [66, 67], [68, 70], [71, 75], [76, 79], [80, 84], [85, 93], [94, 98], [99, 102], [103, 106], [107, 112], [113, 121], [122, 126], [127, 130], [131, 136], [137, 138], [138, 141], [142, 151], [152, 155], [156, 161], [162, 170], [171, 175], [176, 179], [180, 183], [184, 188], [189, 197], [198, 202], [203, 206], [207, 212], [212, 213], [214, 217], [218, 222], [223, 228], [229, 231], [232, 235], [236, 245], [246, 261], [261, 262]]}
{"doc_key": "ai-test-110", "ner": [[0, 0, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["MATLAB", "function", ","], "sentence-detokenized": "MATLAB function,", "token2charspan": [[0, 6], [7, 15], [15, 16]]}
{"doc_key": "ai-test-111", "ner": [[1, 2, "product"], [7, 15, "misc"], [19, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 15, 1, 2, "part-of", "", false, false], [19, 20, 1, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "articulated", "robot", "is", "a", "robot", "with", "rotating", "joints", "(", "for", "example", ",", "a", "robot", "with", "legs", "or", "an", "industrial", "robot", ")", "."], "sentence-detokenized": "An articulated robot is a robot with rotating joints (for example, a robot with legs or an industrial robot).", "token2charspan": [[0, 2], [3, 14], [15, 20], [21, 23], [24, 25], [26, 31], [32, 36], [37, 45], [46, 52], [53, 54], [54, 57], [58, 65], [65, 66], [67, 68], [69, 74], [75, 79], [80, 84], [85, 87], [88, 90], [91, 101], [102, 107], [107, 108], [108, 109]]}
{"doc_key": "ai-test-112", "ner": [[0, 0, "product"], [5, 6, "product"], [8, 11, "product"], [13, 13, "misc"], [18, 22, "product"], [26, 28, "misc"], [32, 32, "location"], [34, 34, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 13, 13, "general-affiliation", "nationality", false, false], [0, 0, 26, 28, "usage", "", false, false], [0, 0, 32, 32, "physical", "", false, false], [5, 6, 0, 0, "named", "", false, false], [8, 11, 0, 0, "named", "", false, false], [32, 32, 34, 34, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pandora", "(", "also", "known", "as", "Pandora", "Media", "or", "Pandora", "Radio", ")", "is", "an", "American", "music", "streaming", "service", "and", "automated", "Internet", "radio", "recommendation", "system", "powered", "by", "the", "Music", "Genome", "Project", "and", "headquartered", "in", "Oakland", ",", "California", "."], "sentence-detokenized": "Pandora (also known as Pandora Media or Pandora Radio) is an American music streaming service and automated Internet radio recommendation system powered by the Music Genome Project and headquartered in Oakland, California.", "token2charspan": [[0, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 30], [31, 36], [37, 39], [40, 47], [48, 53], [53, 54], [55, 57], [58, 60], [61, 69], [70, 75], [76, 85], [86, 93], [94, 97], [98, 107], [108, 116], [117, 122], [123, 137], [138, 144], [145, 152], [153, 155], [156, 159], [160, 165], [166, 172], [173, 180], [181, 184], [185, 198], [199, 201], [202, 209], [209, 210], [211, 221], [221, 222]]}
{"doc_key": "ai-test-113", "ner": [[7, 14, "organisation"], [18, 19, "organisation"], [25, 26, "conference"], [17, 39, "conference"], [41, 41, "conference"], [43, 43, "conference"], [45, 45, "conference"], [47, 47, "conference"], [49, 49, "conference"], [51, 51, "conference"], [53, 53, "conference"], [55, 55, "conference"], [57, 57, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "is", "a", "board", "member", "of", "the", "International", "Machine", "Learning", "Society", ",", "was", "a", "member", "of", "the", "AAAI", "executive", "board", ",", "was", "PC", "co-chair", "of", "ICML", "2011", ",", "and", "has", "been", "a", "senior", "PC", "member", "for", "conferences", "such", "as", "AAAI", ",", "ICML", ",", "IJCAI", ",", "ISWC", ",", "KDD", ",", "SIGMOD", ",", "UAI", ",", "VLDB", ",", "WSDM", "and", "WWW", "."], "sentence-detokenized": "She is a board member of the International Machine Learning Society, was a member of the AAAI executive board, was PC co-chair of ICML 2011, and has been a senior PC member for conferences such as AAAI, ICML, IJCAI, ISWC, KDD, SIGMOD, UAI, VLDB, WSDM and WWW.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 14], [15, 21], [22, 24], [25, 28], [29, 42], [43, 50], [51, 59], [60, 67], [67, 68], [69, 72], [73, 74], [75, 81], [82, 84], [85, 88], [89, 93], [94, 103], [104, 109], [109, 110], [111, 114], [115, 117], [118, 126], [127, 129], [130, 134], [135, 139], [139, 140], [141, 144], [145, 148], [149, 153], [154, 155], [156, 162], [163, 165], [166, 172], [173, 176], [177, 188], [189, 193], [194, 196], [197, 201], [201, 202], [203, 207], [207, 208], [209, 214], [214, 215], [216, 220], [220, 221], [222, 225], [225, 226], [227, 233], [233, 234], [235, 238], [238, 239], [240, 244], [244, 245], [246, 250], [251, 254], [255, 258], [258, 259]]}
{"doc_key": "ai-test-114", "ner": [[0, 2, "researcher"], [5, 10, "organisation"], [12, 12, "organisation"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 10, "role", "", false, false], [12, 12, 5, 10, "named", "", false, false], [15, 15, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["James", "S.", "Albus", "of", "the", "National", "Institute", "of", "Standards", "and", "Technology", "(", "NIST", ")", "developed", "Robocrane", ",", "in", "which", "the", "platform", "is", "suspended", "by", "six", "cables", "instead", "of", "being", "supported", "by", "six", "sockets", "."], "sentence-detokenized": "James S. Albus of the National Institute of Standards and Technology (NIST) developed Robocrane, in which the platform is suspended by six cables instead of being supported by six sockets.", "token2charspan": [[0, 5], [6, 8], [9, 14], [15, 17], [18, 21], [22, 30], [31, 40], [41, 43], [44, 53], [54, 57], [58, 68], [69, 70], [70, 74], [74, 75], [76, 85], [86, 95], [95, 96], [97, 99], [100, 105], [106, 109], [110, 118], [119, 121], [122, 131], [132, 134], [135, 138], [139, 145], [146, 153], [154, 156], [157, 162], [163, 172], [173, 175], [176, 179], [180, 187], [187, 188]]}
{"doc_key": "ai-test-115", "ner": [[3, 5, "algorithm"], [8, 11, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 11, 3, 5, "type-of", "", false, false], [14, 15, 8, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "class", "of", "direct", "search", "algorithms", "are", "various", "evolutionary", "algorithms", ",", "for", "example", ",", "genetic", "algorithms", "."], "sentence-detokenized": "Another class of direct search algorithms are various evolutionary algorithms, for example, genetic algorithms.", "token2charspan": [[0, 7], [8, 13], [14, 16], [17, 23], [24, 30], [31, 41], [42, 45], [46, 53], [54, 66], [67, 77], [77, 78], [79, 82], [83, 90], [90, 91], [92, 99], [100, 110], [110, 111]]}
{"doc_key": "ai-test-116", "ner": [[0, 0, "organisation"], [3, 4, "misc"], [6, 6, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 0, 0, "named", "", false, false], [6, 6, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["KUKA", "is", "a", "German", "manufacturer", "of", "industrial", "robots", "and", "factory", "automation", "solutions", "."], "sentence-detokenized": "KUKA is a German manufacturer of industrial robots and factory automation solutions.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 16], [17, 29], [30, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 73], [74, 83], [83, 84]]}
{"doc_key": "ai-test-117", "ner": [[8, 8, "misc"], [11, 12, "person"], [14, 20, "misc"], [22, 23, "person"], [25, 25, "misc"], [27, 28, "person"], [30, 31, "misc"], [33, 38, "person"], [36, 38, "misc"], [40, 42, "person"], [44, 47, "misc"], [49, 53, "person"], [52, 55, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[11, 12, 8, 8, "usage", "", false, false], [14, 20, 11, 12, "artifact", "", false, false], [22, 23, 8, 8, "usage", "", false, false], [25, 25, 22, 23, "artifact", "", false, false], [27, 28, 8, 8, "usage", "", false, false], [30, 31, 27, 28, "artifact", "", false, false], [33, 38, 8, 8, "usage", "", false, false], [36, 38, 33, 38, "artifact", "", false, false], [40, 42, 8, 8, "usage", "", false, false], [44, 47, 40, 42, "artifact", "", false, false], [49, 53, 8, 8, "usage", "", false, false], [52, 55, 49, 53, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Other", "films", "from", "2016-2020", "that", "were", "filmed", "with", "IMAX", "cameras", "were", "Zack", "Snyder", "'s", "Batman", "v", "Superman", ":", "Dawn", "of", "Justice", ",", "Clint", "Eastwood", "'s", "Sully", ",", "Damien", "Chazelle", "'s", "First", "Man", ",", "Patty", "Jenkins", "'", "Wonder", "Woman", "1984", ",", "Cary", "Joji", "Fukunaga", "'s", "No", "Time", "to", "Die", "and", "Joseph", "Kosinski", "'s", "Top", "Gun", ":", "Maverick", "."], "sentence-detokenized": "Other films from 2016-2020 that were filmed with IMAX cameras were Zack Snyder's Batman v Superman: Dawn of Justice, Clint Eastwood's Sully, Damien Chazelle's First Man, Patty Jenkins' Wonder Woman 1984, Cary Joji Fukunaga's No Time to Die and Joseph Kosinski's Top Gun: Maverick.", "token2charspan": [[0, 5], [6, 11], [12, 16], [17, 26], [27, 31], [32, 36], [37, 43], [44, 48], [49, 53], [54, 61], [62, 66], [67, 71], [72, 78], [78, 80], [81, 87], [88, 89], [90, 98], [98, 99], [100, 104], [105, 107], [108, 115], [115, 116], [117, 122], [123, 131], [131, 133], [134, 139], [139, 140], [141, 147], [148, 156], [156, 158], [159, 164], [165, 168], [168, 169], [170, 175], [176, 183], [183, 184], [185, 191], [192, 197], [198, 202], [202, 203], [204, 208], [209, 213], [214, 222], [222, 224], [225, 227], [228, 232], [233, 235], [236, 239], [240, 243], [244, 250], [251, 259], [259, 261], [262, 265], [266, 269], [269, 270], [271, 279], [279, 280]]}
{"doc_key": "ai-test-118", "ner": [[0, 8, "misc"], [9, 13, "organisation"], [15, 15, "organisation"], [28, 28, "misc"], [35, 36, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 8, 28, 28, "named", "", false, false], [9, 13, 0, 8, "usage", "", false, false], [9, 13, 35, 36, "physical", "", false, false], [15, 15, 9, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "E13B", "MICR", "fo", "nt", "testing", "process", "was", "presented", "to", "the", "American", "Bankers", "Association", "(", "ABA", ")", "in", "July", "1956", ",", "which", "adopted", "it", "in", "1958", "as", "the", "MICR", "standard", "for", "negotiable", "documents", "in", "the", "United", "States", "."], "sentence-detokenized": "The E13B MICR font testing process was presented to the American Bankers Association (ABA) in July 1956, which adopted it in 1958 as the MICR standard for negotiable documents in the United States.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 16], [16, 18], [19, 26], [27, 34], [35, 38], [39, 48], [49, 51], [52, 55], [56, 64], [65, 72], [73, 84], [85, 86], [86, 89], [89, 90], [91, 93], [94, 98], [99, 103], [103, 104], [105, 110], [111, 118], [119, 121], [122, 124], [125, 129], [130, 132], [133, 136], [137, 141], [142, 150], [151, 154], [155, 165], [166, 175], [176, 178], [179, 182], [183, 189], [190, 196], [196, 197]]}
{"doc_key": "ai-test-119", "ner": [[0, 2, "misc"], [15, 16, "field"], [19, 20, "field"], [23, 23, "field"], [25, 26, "field"], [28, 28, "field"], [30, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 16, 0, 2, "usage", "", false, false], [19, 20, 15, 16, "part-of", "", false, false], [23, 23, 0, 2, "usage", "", false, false], [25, 26, 0, 2, "usage", "", false, false], [28, 28, 0, 2, "usage", "", false, false], [30, 30, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Local", "search", "algorithms", "are", "widely", "applied", "to", "many", "challenging", "computational", "problems", ",", "including", "problems", "in", "computer", "science", "(", "especially", "artificial", "intelligence", ")", ",", "mathematics", ",", "operations", "research", ",", "engineering", "and", "bioinformatics", "."], "sentence-detokenized": "Local search algorithms are widely applied to many challenging computational problems, including problems in computer science (especially artificial intelligence), mathematics, operations research, engineering and bioinformatics.", "token2charspan": [[0, 5], [6, 12], [13, 23], [24, 27], [28, 34], [35, 42], [43, 45], [46, 50], [51, 62], [63, 76], [77, 85], [85, 86], [87, 96], [97, 105], [106, 108], [109, 117], [118, 125], [126, 127], [127, 137], [138, 148], [149, 161], [161, 162], [162, 163], [164, 175], [175, 176], [177, 187], [188, 196], [196, 197], [198, 209], [210, 213], [214, 228], [228, 229]]}
{"doc_key": "ai-test-120", "ner": [[0, 1, "researcher"], [9, 9, "location"], [11, 11, "country"], [15, 15, "country"], [22, 23, "algorithm"], [25, 25, "algorithm"], [27, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 9, 9, "physical", "", false, false], [0, 1, 15, 15, "general-affiliation", "nationality", false, false], [0, 1, 22, 23, "general-affiliation", "topic_of_study", false, false], [0, 1, 25, 25, "general-affiliation", "topic_of_study", false, false], [9, 9, 11, 11, "physical", "", false, false], [25, 25, 27, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gerd", "Gigerenzer", "(", "b.", "September", "3", ",", "1947", ",", "Wallersdorf", ",", "Germany", ")", "is", "a", "German", "psychologist", "who", "studied", "the", "use", "of", "bounded", "rationality", "and", "heuristics", "in", "decision", "-", "making", "."], "sentence-detokenized": "Gerd Gigerenzer (b. September 3, 1947, Wallersdorf, Germany) is a German psychologist who studied the use of bounded rationality and heuristics in decision-making.", "token2charspan": [[0, 4], [5, 15], [16, 17], [17, 19], [20, 29], [30, 31], [31, 32], [33, 37], [37, 38], [39, 50], [50, 51], [52, 59], [59, 60], [61, 63], [64, 65], [66, 72], [73, 85], [86, 89], [90, 97], [98, 101], [102, 105], [106, 108], [109, 116], [117, 128], [129, 132], [133, 143], [144, 146], [147, 155], [155, 156], [156, 162], [162, 163]]}
{"doc_key": "ai-test-121", "ner": [[3, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["to", "minimize", "the", "mean", "squared", "error", "."], "sentence-detokenized": "to minimize the mean squared error.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 20], [21, 28], [29, 34], [34, 35]]}
{"doc_key": "ai-test-122", "ner": [[14, 15, "misc"], [18, 19, "organisation"], [34, 36, "field"], [52, 53, "misc"], [62, 64, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 15, 18, 19, "origin", "", false, false], [52, 53, 62, 64, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["But", "even", "an", "official", "language", "with", "an", "academy", "that", "regulates", "it", ",", "such", "as", "standard", "French", "with", "the", "French", "Academy", ",", "is", "classified", "as", "a", "natural", "language", "(", "e.g.", ",", "in", "the", "field", "of", "natural", "language", "processing", ")", "because", "its", "prescriptive", "points", "make", "it", "neither", "sufficiently", "constructed", "to", "be", "classified", "as", "a", "constructed", "language", "nor", "sufficiently", "controlled", "to", "be", "classified", "as", "a", "controlled", "natural", "language", "."], "sentence-detokenized": "But even an official language with an academy that regulates it, such as standard French with the French Academy, is classified as a natural language (e.g., in the field of natural language processing) because its prescriptive points make it neither sufficiently constructed to be classified as a constructed language nor sufficiently controlled to be classified as a controlled natural language.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 20], [21, 29], [30, 34], [35, 37], [38, 45], [46, 50], [51, 60], [61, 63], [63, 64], [65, 69], [70, 72], [73, 81], [82, 88], [89, 93], [94, 97], [98, 104], [105, 112], [112, 113], [114, 116], [117, 127], [128, 130], [131, 132], [133, 140], [141, 149], [150, 151], [151, 155], [155, 156], [157, 159], [160, 163], [164, 169], [170, 172], [173, 180], [181, 189], [190, 200], [200, 201], [202, 209], [210, 213], [214, 226], [227, 233], [234, 238], [239, 241], [242, 249], [250, 262], [263, 274], [275, 277], [278, 280], [281, 291], [292, 294], [295, 296], [297, 308], [309, 317], [318, 321], [322, 334], [335, 345], [346, 348], [349, 351], [352, 362], [363, 365], [366, 367], [368, 378], [379, 386], [387, 395], [395, 396]]}
{"doc_key": "ai-test-123", "ner": [[11, 11, "metrics"], [13, 14, "metrics"], [16, 16, "metrics"], [34, 35, "metrics"], [37, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[16, 16, 13, 14, "named", "", false, false], [37, 37, 34, 35, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "a", "number", "of", "other", "metrics", ",", "the", "simplest", "being", "accuracy", "or", "correct", "fraction", "(", "CF", ")", ",", "which", "measures", "the", "fraction", "of", "all", "instances", "that", "are", "correctly", "classified", ";", "the", "complement", "is", "incorrect", "fraction", "(", "FiC", ")", "."], "sentence-detokenized": "There are a number of other metrics, the simplest being accuracy or correct fraction (CF), which measures the fraction of all instances that are correctly classified; the complement is incorrect fraction (FiC).", "token2charspan": [[0, 5], [6, 9], [10, 11], [12, 18], [19, 21], [22, 27], [28, 35], [35, 36], [37, 40], [41, 49], [50, 55], [56, 64], [65, 67], [68, 75], [76, 84], [85, 86], [86, 88], [88, 89], [89, 90], [91, 96], [97, 105], [106, 109], [110, 118], [119, 121], [122, 125], [126, 135], [136, 140], [141, 144], [145, 154], [155, 165], [165, 166], [167, 170], [171, 181], [182, 184], [185, 194], [195, 203], [204, 205], [205, 208], [208, 209], [209, 210]]}
{"doc_key": "ai-test-124", "ner": [[0, 0, "researcher"], [6, 9, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 9, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cardie", "became", "a", "member", "of", "the", "Association", "for", "Computational", "Linguistics", "in", "2016", "."], "sentence-detokenized": "Cardie became a member of the Association for Computational Linguistics in 2016.", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 22], [23, 25], [26, 29], [30, 41], [42, 45], [46, 59], [60, 71], [72, 74], [75, 79], [79, 80]]}
{"doc_key": "ai-test-125", "ner": [[12, 15, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Learning", "the", "parameters", "math", "\\", "theta", "/", "math", "is", "usually", "done", "by", "learning", "with", "maximum", "likelihood", "for", "mathp", "(", "Y", "_", "i", "|", "X", "_", "i", ";\\", "theta", ")", "/", "math", "."], "sentence-detokenized": "Learning the parameters math\\ theta / math is usually done by learning with maximum likelihood for mathp (Y _ i | X _ i;\\ theta) / math.", "token2charspan": [[0, 8], [9, 12], [13, 23], [24, 28], [28, 29], [30, 35], [36, 37], [38, 42], [43, 45], [46, 53], [54, 58], [59, 61], [62, 70], [71, 75], [76, 83], [84, 94], [95, 98], [99, 104], [105, 106], [106, 107], [108, 109], [110, 111], [112, 113], [114, 115], [116, 117], [118, 119], [119, 121], [122, 127], [127, 128], [129, 130], [131, 135], [135, 136]]}
{"doc_key": "ai-test-126", "ner": [[0, 1, "task"], [3, 5, "algorithm"], [7, 8, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 0, 1, "usage", "", true, false], [7, 8, 3, 5, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cluster", "analysis", "and", "negative", "matrix", "factorization", "for", "descriptive", "extraction", "."], "sentence-detokenized": "Cluster analysis and negative matrix factorization for descriptive extraction.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 29], [30, 36], [37, 50], [51, 54], [55, 66], [67, 77], [77, 78]]}
{"doc_key": "ai-test-127", "ner": [[4, 5, "field"], [8, 10, "field"], [28, 30, "field"], [32, 33, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[28, 30, 4, 5, "part-of", "", false, false], [28, 30, 8, 10, "part-of", "", false, false], [32, 33, 4, 5, "part-of", "", false, false], [32, 33, 8, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "the", "field", "of", "computer", "science", "and", "the", "information", "technology", "it", "enables", ",", "it", "has", "been", "a", "long", "-", "term", "challenge", "to", "the", "ability", "of", "computers", "to", "do", "natural", "language", "processing", "and", "machine", "learning", "."], "sentence-detokenized": "In the field of computer science and the information technology it enables, it has been a long-term challenge to the ability of computers to do natural language processing and machine learning.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 24], [25, 32], [33, 36], [37, 40], [41, 52], [53, 63], [64, 66], [67, 74], [74, 75], [76, 78], [79, 82], [83, 87], [88, 89], [90, 94], [94, 95], [95, 99], [100, 109], [110, 112], [113, 116], [117, 124], [125, 127], [128, 137], [138, 140], [141, 143], [144, 151], [152, 160], [161, 171], [172, 175], [176, 183], [184, 192], [192, 193]]}
{"doc_key": "ai-test-128", "ner": [[3, 5, "algorithm"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 5, 9, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "Code", "for", "extracting", "Gabor", "features", "from", "images", "in", "MATLAB", "can", "be", "found", "at"], "sentence-detokenized": "(Code for extracting Gabor features from images in MATLAB can be found at", "token2charspan": [[0, 1], [1, 5], [6, 9], [10, 20], [21, 26], [27, 35], [36, 40], [41, 47], [48, 50], [51, 57], [58, 61], [62, 64], [65, 70], [71, 73]]}
{"doc_key": "ai-test-129", "ner": [[0, 0, "misc"], [13, 15, "algorithm"], [18, 18, "task"], [20, 20, "task"], [22, 23, "task"], [25, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 13, 15, "general-affiliation", "", false, false], [0, 0, 18, 18, "related-to", "solves_problem_of_type", false, false], [0, 0, 20, 20, "related-to", "solves_problem_of_type", false, false], [0, 0, 22, 23, "related-to", "solves_problem_of_type", false, false], [0, 0, 25, 26, "related-to", "solves_problem_of_type", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["NeuralExpert", "centers", "design", "specifications", "around", "the", "type", "of", "problem", "the", "user", "wants", "the", "neural", "network", "to", "solve", "(", "classification", ",", "prediction", ",", "function", "approximation", "or", "cluster", "analysis", ")", "."], "sentence-detokenized": "NeuralExpert centers design specifications around the type of problem the user wants the neural network to solve (classification, prediction, function approximation or cluster analysis).", "token2charspan": [[0, 12], [13, 20], [21, 27], [28, 42], [43, 49], [50, 53], [54, 58], [59, 61], [62, 69], [70, 73], [74, 78], [79, 84], [85, 88], [89, 95], [96, 103], [104, 106], [107, 112], [113, 114], [114, 128], [128, 129], [130, 140], [140, 141], [142, 150], [151, 164], [165, 167], [168, 175], [176, 184], [184, 185], [185, 186]]}
{"doc_key": "ai-test-130", "ner": [[3, 4, "misc"], [26, 30, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "the", "quantization", "step", "size", "(", "\u0394", ")", "is", "small", "relative", "to", "the", "variation", "of", "the", "quantized", "signal", ",", "it", "is", "relatively", "straightforward", "to", "show", "that", "the", "root", "mean", "square", "error", "produced", "by", "such", "a", "rounding", "operation", "will", "be", "approximately", "math", "\\", "Delta", "^", "2", "/", "12", "/", "math.math"], "sentence-detokenized": "When the quantization step size (\u0394) is small relative to the variation of the quantized signal, it is relatively straightforward to show that the root mean square error produced by such a rounding operation will be approximately math\\ Delta ^ 2 / 12 / math.math", "token2charspan": [[0, 4], [5, 8], [9, 21], [22, 26], [27, 31], [32, 33], [33, 34], [34, 35], [36, 38], [39, 44], [45, 53], [54, 56], [57, 60], [61, 70], [71, 73], [74, 77], [78, 87], [88, 94], [94, 95], [96, 98], [99, 101], [102, 112], [113, 128], [129, 131], [132, 136], [137, 141], [142, 145], [146, 150], [151, 155], [156, 162], [163, 168], [169, 177], [178, 180], [181, 185], [186, 187], [188, 196], [197, 206], [207, 211], [212, 214], [215, 228], [229, 233], [233, 234], [235, 240], [241, 242], [243, 244], [245, 246], [247, 249], [250, 251], [252, 261]]}
{"doc_key": "ai-test-131", "ner": [[16, 16, "product"], [24, 27, "researcher"], [29, 30, "researcher"], [32, 34, "researcher"], [36, 37, "researcher"], [39, 41, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Building", "a", "rich", "lexicon", "with", "a", "proper", "ontology", "requires", "significant", "effort", ",", "for", "example", ",", "the", "Wordnet", "lexicon", "took", "many", "years", "of", "work", ".", "G.", "A", ".", "Miller", ",", "R.", "Beckwith", ",", "C.", "D.", "Fellbaum", ",", "D.", "Gross", ",", "K", ".", "Miller", "."], "sentence-detokenized": "Building a rich lexicon with a proper ontology requires significant effort, for example, the Wordnet lexicon took many years of work. G. A. Miller, R. Beckwith, C. D. Fellbaum, D. Gross, K. Miller.", "token2charspan": [[0, 8], [9, 10], [11, 15], [16, 23], [24, 28], [29, 30], [31, 37], [38, 46], [47, 55], [56, 67], [68, 74], [74, 75], [76, 79], [80, 87], [87, 88], [89, 92], [93, 100], [101, 108], [109, 113], [114, 118], [119, 124], [125, 127], [128, 132], [132, 133], [134, 136], [137, 138], [138, 139], [140, 146], [146, 147], [148, 150], [151, 159], [159, 160], [161, 163], [164, 166], [167, 175], [175, 176], [177, 179], [180, 185], [185, 186], [187, 188], [188, 189], [190, 196], [196, 197]]}
{"doc_key": "ai-test-132", "ner": [[0, 1, "organisation"], [15, 16, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 16, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Kawasaki", "'s", "portfolio", "also", "includes", "retractable", "roofs", ",", "floors", "and", "other", "giant", "structures", ",", "the", "Sapporo", "Dome", "\"", "retractable", "surface", "\"", "being", "one", "example", "."], "sentence-detokenized": "Kawasaki's portfolio also includes retractable roofs, floors and other giant structures, the Sapporo Dome \"retractable surface\" being one example.", "token2charspan": [[0, 8], [8, 10], [11, 20], [21, 25], [26, 34], [35, 46], [47, 52], [52, 53], [54, 60], [61, 64], [65, 70], [71, 76], [77, 87], [87, 88], [89, 92], [93, 100], [101, 105], [106, 107], [107, 118], [119, 126], [126, 127], [128, 133], [134, 137], [138, 145], [145, 146]]}
{"doc_key": "ai-test-133", "ner": [[0, 1, "metrics"], [5, 5, "metrics"], [9, 11, "metrics"], [17, 18, "metrics"], [38, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 17, 18, "related-to", "", false, false], [0, 1, 38, 38, "opposite", "alternative_to", false, false], [5, 5, 0, 1, "type-of", "", false, false], [9, 11, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kappa", "statistics", ",", "such", "as", "Fleiss", "'s", "kappa", "and", "Cohen", "'s", "kappa", ",", "are", "methods", "for", "calculating", "inter-rater", "reliability", "based", "on", "various", "assumptions", "about", "marginal", "or", "prior", "distributions", "and", "are", "increasingly", "used", "as", "chance", "-", "corrected", "alternatives", "to", "accuracy", "in", "other", "contexts", "."], "sentence-detokenized": "Kappa statistics, such as Fleiss's kappa and Cohen's kappa, are methods for calculating inter-rater reliability based on various assumptions about marginal or prior distributions and are increasingly used as chance-corrected alternatives to accuracy in other contexts.", "token2charspan": [[0, 5], [6, 16], [16, 17], [18, 22], [23, 25], [26, 32], [32, 34], [35, 40], [41, 44], [45, 50], [50, 52], [53, 58], [58, 59], [60, 63], [64, 71], [72, 75], [76, 87], [88, 99], [100, 111], [112, 117], [118, 120], [121, 128], [129, 140], [141, 146], [147, 155], [156, 158], [159, 164], [165, 178], [179, 182], [183, 186], [187, 199], [200, 204], [205, 207], [208, 214], [214, 215], [215, 224], [225, 237], [238, 240], [241, 249], [250, 252], [253, 258], [259, 267], [267, 268]]}
{"doc_key": "ai-test-134", "ner": [[4, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [18, 19, "researcher"], [28, 30, "algorithm"], [32, 35, "algorithm"], [37, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 18, 19, "role", "student_of", false, false], [7, 8, 18, 19, "role", "student_of", false, false], [10, 11, 18, 19, "role", "student_of", false, false], [13, 14, 18, 19, "role", "student_of", false, false], [32, 35, 4, 5, "origin", "", false, false], [32, 35, 7, 8, "origin", "", false, false], [32, 35, 10, 11, "origin", "", false, false], [32, 35, 13, 14, "origin", "", false, false], [32, 35, 18, 19, "origin", "", false, false], [32, 35, 28, 30, "type-of", "", false, false], [37, 37, 32, 35, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Together", "with", "his", "students", "Sepp", "Hochreiter", ",", "Felix", "Gers", ",", "Fred", "Cummins", ",", "Alex", "Graves", "and", "others", ",", "Schmidhuber", "has", "published", "increasingly", "sophisticated", "versions", "of", "a", "type", "of", "recurrent", "neural", "network", "called", "short", "-", "term", "memory", "(", "LSTM", ")", "."], "sentence-detokenized": "Together with his students Sepp Hochreiter, Felix Gers, Fred Cummins, Alex Graves and others, Schmidhuber has published increasingly sophisticated versions of a type of recurrent neural network called short-term memory (LSTM).", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 26], [27, 31], [32, 42], [42, 43], [44, 49], [50, 54], [54, 55], [56, 60], [61, 68], [68, 69], [70, 74], [75, 81], [82, 85], [86, 92], [92, 93], [94, 105], [106, 109], [110, 119], [120, 132], [133, 146], [147, 155], [156, 158], [159, 160], [161, 165], [166, 168], [169, 178], [179, 185], [186, 193], [194, 200], [201, 206], [206, 207], [207, 211], [212, 218], [219, 220], [220, 224], [224, 225], [225, 226]]}
{"doc_key": "ai-test-135", "ner": [[4, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2004", "-", "The", "first", "KUKA", "LBR", "3", "Cobot", "is", "launched", "."], "sentence-detokenized": "2004 - The first KUKA LBR 3 Cobot is launched.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 16], [17, 21], [22, 25], [26, 27], [28, 33], [34, 36], [37, 45], [45, 46]]}
{"doc_key": "ai-test-136", "ner": [[10, 13, "algorithm"], [15, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Two", "shallow", "approaches", "used", "to", "train", "and", "then", "disambiguate", "are", "the", "Naive", "Bayes", "classifier", "and", "decision", "trees", "."], "sentence-detokenized": "Two shallow approaches used to train and then disambiguate are the Naive Bayes classifier and decision trees.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 27], [28, 30], [31, 36], [37, 40], [41, 45], [46, 58], [59, 62], [63, 66], [67, 72], [73, 78], [79, 89], [90, 93], [94, 102], [103, 108], [108, 109]]}
{"doc_key": "ai-test-137", "ner": [[5, 5, "misc"], [12, 13, "person"], [15, 17, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 12, 13, "origin", "", false, false], [5, 5, 15, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "practical", "forms", "of", "photography", "were", "introduced", "in", "January", "1839", "by", "Louis", "Daguerre", "and", "Henry", "Fox", "Talbot", "."], "sentence-detokenized": "The first practical forms of photography were introduced in January 1839 by Louis Daguerre and Henry Fox Talbot.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 25], [26, 28], [29, 40], [41, 45], [46, 56], [57, 59], [60, 67], [68, 72], [73, 75], [76, 81], [82, 90], [91, 94], [95, 100], [101, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-test-138", "ner": [[3, 4, "task"], [8, 9, "task"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 17, 18, "part-of", "task_part_of_field", false, false], [8, 9, 17, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "example", ",", "speech", "synthesis", ",", "combined", "with", "speech", "recognition", ",", "enables", "interaction", "with", "mobile", "devices", "via", "language", "processing", "interfaces", "."], "sentence-detokenized": "For example, speech synthesis, combined with speech recognition, enables interaction with mobile devices via language processing interfaces.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 19], [20, 29], [29, 30], [31, 39], [40, 44], [45, 51], [52, 63], [63, 64], [65, 72], [73, 84], [85, 89], [90, 96], [97, 104], [105, 108], [109, 117], [118, 128], [129, 139], [139, 140]]}
{"doc_key": "ai-test-139", "ner": [[0, 0, "product"], [14, 14, "programlang"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 14, 14, "general-affiliation", "", false, false], [0, 0, 16, 17, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Phidgets", "can", "be", "programmed", "using", "a", "variety", "of", "software", "and", "programming", "languages", ",", "from", "Java", "to", "Microsoft", "Excel", "."], "sentence-detokenized": "Phidgets can be programmed using a variety of software and programming languages, from Java to Microsoft Excel.", "token2charspan": [[0, 8], [9, 12], [13, 15], [16, 26], [27, 32], [33, 34], [35, 42], [43, 45], [46, 54], [55, 58], [59, 70], [71, 80], [80, 81], [82, 86], [87, 91], [92, 94], [95, 104], [105, 110], [110, 111]]}
{"doc_key": "ai-test-140", "ner": [[2, 3, "field"], [9, 10, "researcher"], [13, 15, "misc"], [20, 21, "field"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 9, 10, "origin", "", false, false], [9, 10, 20, 21, "general-affiliation", "topic_of_study", false, false], [9, 10, 23, 24, "general-affiliation", "topic_of_study", false, false], [13, 15, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "term", "machine", "learning", "was", "coined", "in", "1959", "by", "Arthur", "Samuel", ",", "an", "American", "at", "IBM", "and", "a", "pioneer", "in", "computer", "games", "and", "artificial", "intelligence", "."], "sentence-detokenized": "The term machine learning was coined in 1959 by Arthur Samuel, an American at IBM and a pioneer in computer games and artificial intelligence.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 25], [26, 29], [30, 36], [37, 39], [40, 44], [45, 47], [48, 54], [55, 61], [61, 62], [63, 65], [66, 74], [75, 77], [78, 81], [82, 85], [86, 87], [88, 95], [96, 98], [99, 107], [108, 113], [114, 117], [118, 128], [129, 141], [141, 142]]}
{"doc_key": "ai-test-141", "ner": [[0, 1, "misc"], [2, 3, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Israeli", "poet", "David", "Avidan", ",", "fascinated", "by", "the", "technologies", "of", "the", "future", "and", "their", "relationship", "to", "art", ",", "wanted", "to", "explore", "the", "use", "of", "computers", "to", "write", "literature", "."], "sentence-detokenized": "Israeli poet David Avidan, fascinated by the technologies of the future and their relationship to art, wanted to explore the use of computers to write literature.", "token2charspan": [[0, 7], [8, 12], [13, 18], [19, 25], [25, 26], [27, 37], [38, 40], [41, 44], [45, 57], [58, 60], [61, 64], [65, 71], [72, 75], [76, 81], [82, 94], [95, 97], [98, 101], [101, 102], [103, 109], [110, 112], [113, 120], [121, 124], [125, 128], [129, 131], [132, 141], [142, 144], [145, 150], [151, 161], [161, 162]]}
{"doc_key": "ai-test-142", "ner": [[4, 5, "misc"], [9, 9, "organisation"], [16, 16, "location"], [30, 30, "location"], [26, 28, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 9, 4, 5, "part-of", "", false, false], [26, 28, 30, 30, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "part", "of", "the", "GATEway", "project", "in", "2017", ",", "Oxbotica", "tested", "seven", "autonomous", "shuttle", "buses", "in", "Greenwich", ",", "navigating", "a", "two", "-", "mile", "riverside", "route", "near", "The", "O2", "Arena", "in", "London", "on", "a", "route", "also", "used", "by", "pedestrians", "and", "cyclists", "."], "sentence-detokenized": "As part of the GATEway project in 2017, Oxbotica tested seven autonomous shuttle buses in Greenwich, navigating a two-mile riverside route near The O2 Arena in London on a route also used by pedestrians and cyclists.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 22], [23, 30], [31, 33], [34, 38], [38, 39], [40, 48], [49, 55], [56, 61], [62, 72], [73, 80], [81, 86], [87, 89], [90, 99], [99, 100], [101, 111], [112, 113], [114, 117], [117, 118], [118, 122], [123, 132], [133, 138], [139, 143], [144, 147], [148, 150], [151, 156], [157, 159], [160, 166], [167, 169], [170, 171], [172, 177], [178, 182], [183, 187], [188, 190], [191, 202], [203, 206], [207, 215], [215, 216]]}
{"doc_key": "ai-test-143", "ner": [[12, 13, "task"], [15, 18, "metrics"], [23, 28, "misc"], [30, 35, "metrics"], [37, 37, "metrics"], [39, 41, "metrics"], [44, 44, "metrics"], [32, 46, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 5, 6, 7, 8, 9], "relations": [[15, 18, 23, 28, "related-to", "is_a", false, false], [30, 35, 44, 44, "opposite", "", false, false], [30, 35, 32, 46, "opposite", "", false, false], [37, 37, 30, 35, "named", "", false, false], [39, 41, 30, 35, "named", "", false, false]], "relations_mapping_to_source": [0, 5, 6, 7, 8], "sentence": ["An", "unrelated", ",", "but", "commonly", "used", ",", "combination", "of", "basic", "statistics", "in", "information", "retrieval", "is", "the", "F", "-", "score", ",", "which", "is", "a", "harmonic", "(", "possibly", "weighted", ")", "average", "of", "recall", "and", "precision", ",", "where", "recall", "=", "sensitivity", "=", "TRUE", "positive", "rate", ",", "but", "specificity", "and", "precision", "are", "totally", "different", "measures", "."], "sentence-detokenized": "An unrelated, but commonly used, combination of basic statistics in information retrieval is the F-score, which is a harmonic (possibly weighted) average of recall and precision, where recall = sensitivity = TRUE positive rate, but specificity and precision are totally different measures.", "token2charspan": [[0, 2], [3, 12], [12, 13], [14, 17], [18, 26], [27, 31], [31, 32], [33, 44], [45, 47], [48, 53], [54, 64], [65, 67], [68, 79], [80, 89], [90, 92], [93, 96], [97, 98], [98, 99], [99, 104], [104, 105], [106, 111], [112, 114], [115, 116], [117, 125], [126, 127], [127, 135], [136, 144], [144, 145], [146, 153], [154, 156], [157, 163], [164, 167], [168, 177], [177, 178], [179, 184], [185, 191], [192, 193], [194, 205], [206, 207], [208, 212], [213, 221], [222, 226], [226, 227], [228, 231], [232, 243], [244, 247], [248, 257], [258, 261], [262, 269], [270, 279], [280, 288], [288, 289]]}
{"doc_key": "ai-test-144", "ner": [[0, 1, "field"], [9, 9, "field"], [11, 11, "field"], [13, 13, "field"], [15, 16, "field"], [18, 19, "field"], [28, 28, "product"], [31, 34, "product"], [36, 37, "product"], [39, 40, "product"], [53, 55, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 9, 9, "origin", "takes_inspiration_from", false, false], [0, 1, 11, 11, "origin", "takes_inspiration_from", false, false], [0, 1, 13, 13, "origin", "takes_inspiration_from", false, false], [0, 1, 15, 16, "origin", "takes_inspiration_from", false, false], [0, 1, 18, 19, "origin", "takes_inspiration_from", false, false], [28, 28, 0, 1, "origin", "", false, false], [31, 34, 0, 1, "origin", "", false, false], [36, 37, 0, 1, "origin", "", false, false], [39, 40, 0, 1, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Neuromorphic", "engineering", "is", "an", "interdisciplinary", "discipline", "that", "draws", "on", "biology", ",", "physics", ",", "mathematics", ",", "computer", "science", "and", "electronic", "engineering", "to", "design", "artificial", "neural", "systems", ",", "such", "as", "vision", "systems", ",", "head", "-", "eye", "systems", ",", "auditory", "processors", "and", "autonomous", "robots", ",", "whose", "physical", "architecture", "and", "design", "principles", "are", "based", "on", "those", "of", "biological", "nervous", "systems", "."], "sentence-detokenized": "Neuromorphic engineering is an interdisciplinary discipline that draws on biology, physics, mathematics, computer science and electronic engineering to design artificial neural systems, such as vision systems, head-eye systems, auditory processors and autonomous robots, whose physical architecture and design principles are based on those of biological nervous systems.", "token2charspan": [[0, 12], [13, 24], [25, 27], [28, 30], [31, 48], [49, 59], [60, 64], [65, 70], [71, 73], [74, 81], [81, 82], [83, 90], [90, 91], [92, 103], [103, 104], [105, 113], [114, 121], [122, 125], [126, 136], [137, 148], [149, 151], [152, 158], [159, 169], [170, 176], [177, 184], [184, 185], [186, 190], [191, 193], [194, 200], [201, 208], [208, 209], [210, 214], [214, 215], [215, 218], [219, 226], [226, 227], [228, 236], [237, 247], [248, 251], [252, 262], [263, 269], [269, 270], [271, 276], [277, 285], [286, 298], [299, 302], [303, 309], [310, 320], [321, 324], [325, 330], [331, 333], [334, 339], [340, 342], [343, 353], [354, 361], [362, 369], [369, 370]]}
{"doc_key": "ai-test-145", "ner": [[5, 8, "metrics"], [11, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 11, 5, 8, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["To", "be", "more", "precise", ",", "the", "BIBO", "stability", "criterion", "requires", "the", "ROC", "of", "the", "system", "to", "include", "the", "unit", "circle", "."], "sentence-detokenized": "To be more precise, the BIBO stability criterion requires the ROC of the system to include the unit circle.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 18], [18, 19], [20, 23], [24, 28], [29, 38], [39, 48], [49, 57], [58, 61], [62, 65], [66, 68], [69, 72], [73, 79], [80, 82], [83, 90], [91, 94], [95, 99], [100, 106], [106, 107]]}
{"doc_key": "ai-test-146", "ner": [[7, 7, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2", "The", "program", "has", "been", "rewritten", "in", "Java", "since", "1998", "."], "sentence-detokenized": "2 The program has been rewritten in Java since 1998.", "token2charspan": [[0, 1], [2, 5], [6, 13], [14, 17], [18, 22], [23, 32], [33, 35], [36, 40], [41, 46], [47, 51], [51, 52]]}
{"doc_key": "ai-test-147", "ner": [[0, 1, "metrics"], [8, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 8, 9, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "MCC", "can", "be", "calculated", "directly", "from", "the", "confusion", "matrix", "using", "the", "formula", ":"], "sentence-detokenized": "The MCC can be calculated directly from the confusion matrix using the formula:", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 25], [26, 34], [35, 39], [40, 43], [44, 53], [54, 60], [61, 66], [67, 70], [71, 78], [78, 79]]}
{"doc_key": "ai-test-148", "ner": [[8, 13, "organisation"], [20, 25, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 13, 20, 25, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "developed", "by", "a", "team", "from", "the", "MIT", "-", "IBM", "Watson", "AI", "Lab", "and", "was", "first", "presented", "at", "the", "2018", "International", "Conference", "on", "Learning", "Representations", "."], "sentence-detokenized": "It was developed by a team from the MIT-IBM Watson AI Lab and was first presented at the 2018 International Conference on Learning Representations.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 31], [32, 35], [36, 39], [39, 40], [40, 43], [44, 50], [51, 53], [54, 57], [58, 61], [62, 65], [66, 71], [72, 81], [82, 84], [85, 88], [89, 93], [94, 107], [108, 118], [119, 121], [122, 130], [131, 146], [146, 147]]}
{"doc_key": "ai-test-149", "ner": [[1, 3, "metrics"], [16, 16, "metrics"], [17, 47, "metrics"], [49, 49, "metrics"], [55, 57, "metrics"], [60, 60, "metrics"], [62, 62, "metrics"], [19, 66, "metrics"], [71, 71, "metrics"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8, 9], "relations": [[16, 16, 17, 47, "type-of", "", false, false], [16, 16, 55, 57, "related-to", "collapses_to_identity", false, false], [60, 60, 71, 71, "related-to", "collapses_to_identity", false, false], [62, 62, 71, 71, "related-to", "collapses_to_identity", false, false], [19, 66, 71, 71, "related-to", "collapses_to_identity", false, false]], "relations_mapping_to_source": [0, 1, 5, 6, 7], "sentence": ["When", "the", "TRUE", "prevalences", "for", "the", "two", "positive", "variables", "are", "equal", ",", "as", "assumed", "in", "the", "Fleiss", "kappa", "and", "F", "-", "score", "case", ",", "i.e.", "the", "number", "of", "positive", "predictions", "matches", "the", "number", "of", "positive", "classes", "in", "the", "dichotomous", "case", "(", "two", "classes", ")", ",", "the", "different", "kappa", "and", "correlation", "measures", "collapse", "to", "identity", "with", "Youden", "'s", "J", ",", "and", "recall", ",", "precision", "and", "F", "-", "score", "are", "equally", "identical", "with", "accuracy", "."], "sentence-detokenized": "When the TRUE prevalences for the two positive variables are equal, as assumed in the Fleiss kappa and F-score case, i.e. the number of positive predictions matches the number of positive classes in the dichotomous case (two classes), the different kappa and correlation measures collapse to identity with Youden's J, and recall, precision and F-score are equally identical with accuracy.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 25], [26, 29], [30, 33], [34, 37], [38, 46], [47, 56], [57, 60], [61, 66], [66, 67], [68, 70], [71, 78], [79, 81], [82, 85], [86, 92], [93, 98], [99, 102], [103, 104], [104, 105], [105, 110], [111, 115], [115, 116], [117, 121], [122, 125], [126, 132], [133, 135], [136, 144], [145, 156], [157, 164], [165, 168], [169, 175], [176, 178], [179, 187], [188, 195], [196, 198], [199, 202], [203, 214], [215, 219], [220, 221], [221, 224], [225, 232], [232, 233], [233, 234], [235, 238], [239, 248], [249, 254], [255, 258], [259, 270], [271, 279], [280, 288], [289, 291], [292, 300], [301, 305], [306, 312], [312, 314], [315, 316], [316, 317], [318, 321], [322, 328], [328, 329], [330, 339], [340, 343], [344, 345], [345, 346], [346, 351], [352, 355], [356, 363], [364, 373], [374, 378], [379, 387], [387, 388]]}
{"doc_key": "ai-test-150", "ner": [[0, 7, "misc"], [5, 5, "misc"], [9, 9, "conference"], [14, 17, "task"], [18, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 7, 9, 9, "part-of", "", false, false], [0, 7, 9, 9, "physical", "", false, false], [0, 7, 9, 9, "temporal", "", false, false], [5, 5, 0, 7, "named", "", false, false], [14, 17, 0, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Building", "Educational", "Applications", "(", "BEA", ")", "workshop", "at", "NAACL", "2013", "hosted", "the", "inaugural", "NLI", "Joint", "Task", ".", "Tetreault", "et", "al", ",", "2013", "The", "competition", "resulted", "in", "29", "entries", "from", "teams", "around", "the", "world", ",", "24", "of", "which", "also", "published", "a", "paper", "describing", "their", "systems", "and", "approaches", "."], "sentence-detokenized": "The Building Educational Applications (BEA) workshop at NAACL 2013 hosted the inaugural NLI Joint Task. Tetreault et al, 2013 The competition resulted in 29 entries from teams around the world, 24 of which also published a paper describing their systems and approaches.", "token2charspan": [[0, 3], [4, 12], [13, 24], [25, 37], [38, 39], [39, 42], [42, 43], [44, 52], [53, 55], [56, 61], [62, 66], [67, 73], [74, 77], [78, 87], [88, 91], [92, 97], [98, 102], [102, 103], [104, 113], [114, 116], [117, 119], [119, 120], [121, 125], [126, 129], [130, 141], [142, 150], [151, 153], [154, 156], [157, 164], [165, 169], [170, 175], [176, 182], [183, 186], [187, 192], [192, 193], [194, 196], [197, 199], [200, 205], [206, 210], [211, 220], [221, 222], [223, 228], [229, 239], [240, 245], [246, 253], [254, 257], [258, 268], [268, 269]]}
{"doc_key": "ai-test-151", "ner": [[0, 2, "algorithm"], [5, 7, "algorithm"], [15, 16, "misc"], [1, 21, "misc"], [38, 38, "misc"], [37, 42, "algorithm"], [45, 45, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 5, 7, "type-of", "", false, false], [0, 2, 15, 16, "related-to", "finds", false, false], [1, 21, 15, 16, "type-of", "", false, false], [45, 45, 37, 42, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Viterbi", "algorithm", "is", "a", "dynamic", "programming", "algorithm", "for", "finding", "the", "most", "likely", "sequence", "of", "hidden", "states", ",", "called", "the", "Viterbi", "path", ",", "which", "results", "in", "a", "sequence", "of", "observed", "events", ",", "especially", "in", "the", "context", "of", "Markov", "information", "sources", "and", "Hidden", "Markov", "Models", "(", "HMMs", ")", "."], "sentence-detokenized": "The Viterbi algorithm is a dynamic programming algorithm for finding the most likely sequence of hidden states, called the Viterbi path, which results in a sequence of observed events, especially in the context of Markov information sources and Hidden Markov Models (HMMs).", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 24], [25, 26], [27, 34], [35, 46], [47, 56], [57, 60], [61, 68], [69, 72], [73, 77], [78, 84], [85, 93], [94, 96], [97, 103], [104, 110], [110, 111], [112, 118], [119, 122], [123, 130], [131, 135], [135, 136], [137, 142], [143, 150], [151, 153], [154, 155], [156, 164], [165, 167], [168, 176], [177, 183], [183, 184], [185, 195], [196, 198], [199, 202], [203, 210], [211, 213], [214, 220], [221, 232], [233, 240], [241, 244], [245, 251], [252, 258], [259, 265], [266, 267], [267, 271], [271, 272], [272, 273]]}
{"doc_key": "ai-test-152", "ner": [[1, 1, "field"], [3, 3, "algorithm"], [9, 9, "misc"], [4, 13, "algorithm"], [8, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 1, 1, "part-of", "", false, false], [3, 3, 9, 9, "general-affiliation", "", false, false], [3, 3, 4, 13, "related-to", "generalizes_from", false, false], [3, 3, 8, 18, "related-to", "generalizes_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "statistics", ",", "multinomial", "logistic", "regression", "is", "a", "classification", "method", "that", "generalizes", "logistic", "regression", "to", "multiclass", "classification", ",", "i.e.", "with", "more", "than", "two", "possible", "discrete", "outcomes", "."], "sentence-detokenized": "In statistics, multinomial logistic regression is a classification method that generalizes logistic regression to multiclass classification, i.e. with more than two possible discrete outcomes.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 26], [27, 35], [36, 46], [47, 49], [50, 51], [52, 66], [67, 73], [74, 78], [79, 90], [91, 99], [100, 110], [111, 113], [114, 124], [125, 139], [139, 140], [141, 145], [146, 150], [151, 155], [156, 160], [161, 164], [165, 173], [174, 182], [183, 191], [191, 192]]}
{"doc_key": "ai-test-153", "ner": [[0, 2, "algorithm"], [9, 10, "field"], [12, 14, "field"], [18, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "researcher"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 9, 10, "part-of", "", false, false], [0, 2, 12, 14, "part-of", "", false, false], [18, 18, 0, 2, "usage", "", true, false], [20, 21, 0, 2, "usage", "", true, false], [23, 24, 0, 2, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hidden", "Markov", "models", "are", "known", "for", "their", "applications", "in", "reinforcement", "learning", "and", "temporal", "pattern", "recognition", ",", "such", "as", "speech", ",", "handwriting", "recognition", ",", "gesture", "recognition", ",", "Thad", "Starner", ",", "Alex", "Pentland", "."], "sentence-detokenized": "Hidden Markov models are known for their applications in reinforcement learning and temporal pattern recognition, such as speech, handwriting recognition, gesture recognition, Thad Starner, Alex Pentland.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 30], [31, 34], [35, 40], [41, 53], [54, 56], [57, 70], [71, 79], [80, 83], [84, 92], [93, 100], [101, 112], [112, 113], [114, 118], [119, 121], [122, 128], [128, 129], [130, 141], [142, 153], [153, 154], [155, 162], [163, 174], [174, 175], [176, 180], [181, 188], [188, 189], [190, 194], [195, 203], [203, 204]]}
{"doc_key": "ai-test-154", "ner": [[33, 35, "metrics"], [7, 38, "misc"]], "ner_mapping_to_source": [1, 2], "relations": [[33, 35, 7, 38, "related-to", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Essentially", ",", "this", "means", "that", "if", "that", "graph", "has", "been", "seen", "more", "than", "k", "times", "during", "training", ",", "the", "conditional", "probability", "of", "a", "word", ",", "given", "its", "history", ",", "is", "proportional", "to", "the", "maximum", "likelihood", "estimate", "of", "that", "graph", "."], "sentence-detokenized": "Essentially, this means that if that graph has been seen more than k times during training, the conditional probability of a word, given its history, is proportional to the maximum likelihood estimate of that graph.", "token2charspan": [[0, 11], [11, 12], [13, 17], [18, 23], [24, 28], [29, 31], [32, 36], [37, 42], [43, 46], [47, 51], [52, 56], [57, 61], [62, 66], [67, 68], [69, 74], [75, 81], [82, 90], [90, 91], [92, 95], [96, 107], [108, 119], [120, 122], [123, 124], [125, 129], [129, 130], [131, 136], [137, 140], [141, 148], [148, 149], [150, 152], [153, 165], [166, 168], [169, 172], [173, 180], [181, 191], [192, 200], [201, 203], [204, 208], [209, 214], [214, 215]]}
{"doc_key": "ai-test-155", "ner": [[4, 5, "task"], [7, 8, "task"], [11, 11, "task"], [12, 19, "task"], [27, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[27, 29, 12, 19, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "interested", "in", "knowledge", "representation", ",", "commonsense", "reasoning", ",", "and", "natural", "language", "understanding", ",", "believing", "that", "deep", "language", "understanding", "can", "currently", "only", "be", "achieved", "by", "significant", "hand", "-", "crafting", "of", "semantically", "rich", "formalisms", ",", "along", "with", "statistical", "preferences", "."], "sentence-detokenized": "He is interested in knowledge representation, commonsense reasoning, and natural language understanding, believing that deep language understanding can currently only be achieved by significant hand-crafting of semantically rich formalisms, along with statistical preferences.", "token2charspan": [[0, 2], [3, 5], [6, 16], [17, 19], [20, 29], [30, 44], [44, 45], [46, 57], [58, 67], [67, 68], [69, 72], [73, 80], [81, 89], [90, 103], [103, 104], [105, 114], [115, 119], [120, 124], [125, 133], [134, 147], [148, 151], [152, 161], [162, 166], [167, 169], [170, 178], [179, 181], [182, 193], [194, 198], [198, 199], [199, 207], [208, 210], [211, 223], [224, 228], [229, 239], [239, 240], [241, 246], [247, 251], [252, 263], [264, 275], [275, 276]]}
{"doc_key": "ai-test-156", "ner": [[1, 1, "programlang"], [3, 3, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "JavaScript", ",", "Python", "or"], "sentence-detokenized": "In JavaScript, Python or", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 21], [22, 24]]}
{"doc_key": "ai-test-157", "ner": [[0, 2, "misc"], [6, 7, "misc"], [11, 11, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 6, 7, "part-of", "", false, false], [6, 7, 11, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Newcomb", "Awards", "are", "announced", "in", "AI", "Magazine", ",", "published", "by", "AAAI", "."], "sentence-detokenized": "The Newcomb Awards are announced in AI Magazine, published by AAAI.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 22], [23, 32], [33, 35], [36, 38], [39, 47], [47, 48], [49, 58], [59, 61], [62, 66], [66, 67]]}
{"doc_key": "ai-test-158", "ner": [[0, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "mean", "squared", "error", "on", "a", "test", "set", "of", "100", "specimens", "is", "0.084", ",", "which", "is", "smaller", "than", "the", "unnormalized", "error", "."], "sentence-detokenized": "The mean squared error on a test set of 100 specimens is 0.084, which is smaller than the unnormalized error.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 25], [26, 27], [28, 32], [33, 36], [37, 39], [40, 43], [44, 53], [54, 56], [57, 62], [62, 63], [64, 69], [70, 72], [73, 80], [81, 85], [86, 89], [90, 102], [103, 108], [108, 109]]}
{"doc_key": "ai-test-159", "ner": [[0, 3, "metrics"], [9, 11, "field"], [16, 18, "task"], [21, 21, "task"], [24, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 11, 0, 3, "usage", "", false, false], [16, 18, 9, 11, "part-of", "task_part_of_field", false, false], [21, 21, 16, 18, "named", "", false, false], [24, 25, 9, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "F", "-", "score", "has", "been", "widely", "used", "in", "natural", "language", "processing", "literature", ",", "such", "as", "named", "entity", "recognition", "evaluation", "(", "NER", ")", "and", "word", "segmentation", "."], "sentence-detokenized": "The F-score has been widely used in natural language processing literature, such as named entity recognition evaluation (NER) and word segmentation.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 15], [16, 20], [21, 27], [28, 32], [33, 35], [36, 43], [44, 52], [53, 63], [64, 74], [74, 75], [76, 80], [81, 83], [84, 89], [90, 96], [97, 108], [109, 119], [120, 121], [121, 124], [124, 125], [126, 129], [130, 134], [135, 147], [147, 148]]}
{"doc_key": "ai-test-160", "ner": [[0, 3, "product"], [5, 7, "product"], [17, 18, "misc"], [20, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 17, 18, "related-to", "performs_task", false, false], [0, 3, 20, 21, "related-to", "performs_task", false, false], [5, 7, 0, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Chatbots", "are", "commonly", "used", "in", "dialogue", "systems", "for", "a", "variety", "of", "purposes", ",", "including", "customer", "service", ",", "directing", "inquiries", "or", "gathering", "information", "."], "sentence-detokenized": "Chatbots are commonly used in dialogue systems for a variety of purposes, including customer service, directing inquiries or gathering information.", "token2charspan": [[0, 8], [9, 12], [13, 21], [22, 26], [27, 29], [30, 38], [39, 46], [47, 50], [51, 52], [53, 60], [61, 63], [64, 72], [72, 73], [74, 83], [84, 92], [93, 100], [100, 101], [102, 111], [112, 121], [122, 124], [125, 134], [135, 146], [146, 147]]}
{"doc_key": "ai-test-161", "ner": [[3, 9, "conference"], [16, 21, "conference"], [29, 39, "conference"], [45, 45, "conference"], [49, 52, "conference"], [54, 55, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[16, 21, 3, 9, "named", "", false, false], [29, 39, 3, 9, "named", "", false, false], [45, 45, 29, 39, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Important", "journals", "include", "IEEE", "Transactions", "on", "Speech", "and", "Audio", "Processing", "(", "subsequently", "renamed", "IEEE", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "and", ",", "as", "of", "September", "2014", ",", "IEEE", "/", "ACM", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "-", "after", "merging", "with", "an", "ACM", "publication", ")", ",", "Computer", "Speech", "and", "Language", "and", "Speech", "Communication", "."], "sentence-detokenized": "Important journals include IEEE Transactions on Speech and Audio Processing (subsequently renamed IEEE Transactions on Audio, Speech and Language Processing and, as of September 2014, IEEE/ACM Transactions on Audio, Speech and Language Processing - after merging with an ACM publication), Computer Speech and Language and Speech Communication.", "token2charspan": [[0, 9], [10, 18], [19, 26], [27, 31], [32, 44], [45, 47], [48, 54], [55, 58], [59, 64], [65, 75], [76, 77], [77, 89], [90, 97], [98, 102], [103, 115], [116, 118], [119, 124], [124, 125], [126, 132], [133, 136], [137, 145], [146, 156], [157, 160], [160, 161], [162, 164], [165, 167], [168, 177], [178, 182], [182, 183], [184, 188], [188, 189], [189, 192], [193, 205], [206, 208], [209, 214], [214, 215], [216, 222], [223, 226], [227, 235], [236, 246], [247, 248], [249, 254], [255, 262], [263, 267], [268, 270], [271, 274], [275, 286], [286, 287], [287, 288], [289, 297], [298, 304], [305, 308], [309, 317], [318, 321], [322, 328], [329, 342], [342, 343]]}
{"doc_key": "ai-test-162", "ner": [[0, 0, "algorithm"], [5, 6, "task"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 0, 0, "usage", "", false, false], [5, 6, 8, 9, "part-of", "task_part_of_field", false, false], [5, 6, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["EM", "is", "commonly", "used", "for", "clustering", "data", "in", "machine", "learning", "and", "computer", "vision", "."], "sentence-detokenized": "EM is commonly used for clustering data in machine learning and computer vision.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 19], [20, 23], [24, 34], [35, 39], [40, 42], [43, 50], [51, 59], [60, 63], [64, 72], [73, 79], [79, 80]]}
{"doc_key": "ai-test-163", "ner": [[8, 18, "metrics"], [24, 28, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 18, 24, 28, "related-to", "described_by", false, false]], "relations_mapping_to_source": [0], "sentence": ["Although", "there", "is", "no", "perfect", "way", "to", "describe", "the", "confusion", "matrix", "of", "TRUE", "and", "FALSE", "positive", "and", "negative", "responses", "with", "a", "single", "number", ",", "the", "Matthews", "correlation", "coefficient", "is", "generally", "considered", "to", "be", "one", "of", "the", "best", "measures", "of", "this", "type", "."], "sentence-detokenized": "Although there is no perfect way to describe the confusion matrix of TRUE and FALSE positive and negative responses with a single number, the Matthews correlation coefficient is generally considered to be one of the best measures of this type.", "token2charspan": [[0, 8], [9, 14], [15, 17], [18, 20], [21, 28], [29, 32], [33, 35], [36, 44], [45, 48], [49, 58], [59, 65], [66, 68], [69, 73], [74, 77], [78, 83], [84, 92], [93, 96], [97, 105], [106, 115], [116, 120], [121, 122], [123, 129], [130, 136], [136, 137], [138, 141], [142, 150], [151, 162], [163, 174], [175, 177], [178, 187], [188, 198], [199, 201], [202, 204], [205, 208], [209, 211], [212, 215], [216, 220], [221, 229], [230, 232], [233, 237], [238, 242], [242, 243]]}
{"doc_key": "ai-test-164", "ner": [[8, 10, "field"], [25, 26, "field"], [30, 33, "field"], [35, 36, "algorithm"], [38, 39, "task"], [41, 42, "algorithm"], [47, 49, "algorithm"], [51, 52, "algorithm"], [58, 60, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[30, 33, 25, 26, "part-of", "subfield", false, false], [35, 36, 30, 33, "part-of", "", false, true], [38, 39, 30, 33, "part-of", "", false, true], [41, 42, 30, 33, "part-of", "", false, true], [47, 49, 30, 33, "part-of", "", false, true], [51, 52, 30, 33, "part-of", "", false, true], [58, 60, 30, 33, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["As", "datasets", "grew", "in", "size", "and", "complexity", ",", "direct", "data", "analysis", "was", "complemented", "by", "indirect", "and", "automated", "data", "processing", ",", "aided", "by", "other", "developments", "in", "computer", "science", ",", "especially", "in", "machine", "learning", ",", "such", "as", "neural", "networks", ",", "cluster", "analysis", ",", "genetic", "algorithms", "(", "1950s", ")", ",", "decision", "tree", "learning", "and", "decision", "rules", "(", "1960s", ")", ",", "and", "support", "vector", "machines", "(", "1990", "s", ")", "."], "sentence-detokenized": "As datasets grew in size and complexity, direct data analysis was complemented by indirect and automated data processing, aided by other developments in computer science, especially in machine learning, such as neural networks, cluster analysis, genetic algorithms (1950s), decision tree learning and decision rules (1960s), and support vector machines (1990s).", "token2charspan": [[0, 2], [3, 11], [12, 16], [17, 19], [20, 24], [25, 28], [29, 39], [39, 40], [41, 47], [48, 52], [53, 61], [62, 65], [66, 78], [79, 81], [82, 90], [91, 94], [95, 104], [105, 109], [110, 120], [120, 121], [122, 127], [128, 130], [131, 136], [137, 149], [150, 152], [153, 161], [162, 169], [169, 170], [171, 181], [182, 184], [185, 192], [193, 201], [201, 202], [203, 207], [208, 210], [211, 217], [218, 226], [226, 227], [228, 235], [236, 244], [244, 245], [246, 253], [254, 264], [265, 266], [266, 271], [271, 272], [272, 273], [274, 282], [283, 287], [288, 296], [297, 300], [301, 309], [310, 315], [316, 317], [317, 322], [322, 323], [323, 324], [325, 328], [329, 336], [337, 343], [344, 352], [353, 354], [354, 358], [358, 359], [359, 360], [360, 361]]}
{"doc_key": "ai-test-165", "ner": [[6, 6, "researcher"], [11, 13, "misc"], [19, 20, "researcher"], [22, 23, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 13, 6, 6, "artifact", "", false, false], [11, 13, 19, 20, "artifact", "", false, false], [11, 13, 22, 23, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "fall", "of", "2005", ",", "Thrun", "published", "a", "textbook", "entitled", "Probabilistic", "Robotics", "with", "his", "long", "-", "time", "colleagues", "Dieter", "Fox", "and", "Wolfram", "Burgard", "."], "sentence-detokenized": "In the fall of 2005, Thrun published a textbook entitled Probabilistic Robotics with his long-time colleagues Dieter Fox and Wolfram Burgard.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 19], [19, 20], [21, 26], [27, 36], [37, 38], [39, 47], [48, 56], [57, 70], [71, 79], [80, 84], [85, 88], [89, 93], [93, 94], [94, 98], [99, 109], [110, 116], [117, 120], [121, 124], [125, 132], [133, 140], [140, 141]]}
{"doc_key": "ai-test-166", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 7, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["John", "D.", "Lafferty", ",", "Andrew", "McCallum", "and", "Pereiramath", ",", "as", "follows", ":"], "sentence-detokenized": "John D. Lafferty, Andrew McCallum and Pereiramath, as follows:", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 24], [25, 33], [34, 37], [38, 49], [49, 50], [51, 53], [54, 61], [61, 62]]}
{"doc_key": "ai-test-167", "ner": [[0, 1, "task"], [3, 3, "task"], [7, 8, "field"], [14, 15, "field"], [17, 19, "field"], [21, 21, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 14, 15, "part-of", "task_part_of_field", false, false], [0, 1, 17, 19, "part-of", "task_part_of_field", false, false], [3, 3, 0, 1, "named", "", false, false], [14, 15, 7, 8, "part-of", "subfield", false, false], [17, 19, 7, 8, "part-of", "subfield", false, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Question", "answering", "(", "QA", ")", "is", "a", "computer", "science", "discipline", "in", "the", "field", "of", "information", "retrieval", "and", "natural", "language", "processing", "(", "NLP", ")", "that", "deals", "with", "creating", "systems", "that", "automatically", "answer", "questions", "asked", "by", "humans", "in", "a", "natural", "language", "."], "sentence-detokenized": "Question answering (QA) is a computer science discipline in the field of information retrieval and natural language processing (NLP) that deals with creating systems that automatically answer questions asked by humans in a natural language.", "token2charspan": [[0, 8], [9, 18], [19, 20], [20, 22], [22, 23], [24, 26], [27, 28], [29, 37], [38, 45], [46, 56], [57, 59], [60, 63], [64, 69], [70, 72], [73, 84], [85, 94], [95, 98], [99, 106], [107, 115], [116, 126], [127, 128], [128, 131], [131, 132], [133, 137], [138, 143], [144, 148], [149, 157], [158, 165], [166, 170], [171, 184], [185, 191], [192, 201], [202, 207], [208, 210], [211, 217], [218, 220], [221, 222], [223, 230], [231, 239], [239, 240]]}
{"doc_key": "ai-test-168", "ner": [[8, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "in", "the", "measurement", "version", "used", "by", "NIST", "assessments", "prior", "to", "2009", ",", "the", "shortest", "reference", "sentence", "was", "used", "instead", "."], "sentence-detokenized": "However, in the measurement version used by NIST assessments prior to 2009, the shortest reference sentence was used instead.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 15], [16, 27], [28, 35], [36, 40], [41, 43], [44, 48], [49, 60], [61, 66], [67, 69], [70, 74], [74, 75], [76, 79], [80, 88], [89, 98], [99, 107], [108, 111], [112, 116], [117, 124], [124, 125]]}
{"doc_key": "ai-test-169", "ner": [[6, 6, "person"], [14, 17, "organisation"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 16, 16, "related-to", "invests_in", false, false], [16, 16, 14, 17, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["On", "August", "27", ",", "2018", ",", "Toyota", "announced", "a", "$", "500", "million", "investment", "in", "Uber", "'s", "autonomous", "cars", "."], "sentence-detokenized": "On August 27, 2018, Toyota announced a $500 million investment in Uber's autonomous cars.", "token2charspan": [[0, 2], [3, 9], [10, 12], [12, 13], [14, 18], [18, 19], [20, 26], [27, 36], [37, 38], [39, 40], [40, 43], [44, 51], [52, 62], [63, 65], [66, 70], [70, 72], [73, 83], [84, 88], [88, 89]]}
{"doc_key": "ai-test-170", "ner": [[5, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "sample", "maximum", "is", "the", "maximum", "likelihood", "estimator", "for", "the", "population", "maximum", "but", ",", "as", "discussed", "above", ",", "it", "is", "biased", "."], "sentence-detokenized": "The sample maximum is the maximum likelihood estimator for the population maximum but, as discussed above, it is biased.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 21], [22, 25], [26, 33], [34, 44], [45, 54], [55, 58], [59, 62], [63, 73], [74, 81], [82, 85], [85, 86], [87, 89], [90, 99], [100, 105], [105, 106], [107, 109], [110, 112], [113, 119], [119, 120]]}
{"doc_key": "ai-test-171", "ner": [[0, 0, "task"], [3, 3, "misc"], [6, 6, "metrics"], [15, 17, "algorithm"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 3, "related-to", "overcomes", false, false], [0, 0, 6, 6, "related-to", "increases", false, false], [3, 3, 15, 17, "opposite", "", false, false], [3, 3, 19, 21, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LSI", "helps", "overcome", "synonymy", "by", "increasing", "recall", ",", "one", "of", "the", "most", "problematic", "constraints", "of", "Boolean", "keyword", "queries", "and", "vector", "space", "models", "."], "sentence-detokenized": "LSI helps overcome synonymy by increasing recall, one of the most problematic constraints of Boolean keyword queries and vector space models.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 27], [28, 30], [31, 41], [42, 48], [48, 49], [50, 53], [54, 56], [57, 60], [61, 65], [66, 77], [78, 89], [90, 92], [93, 100], [101, 108], [109, 116], [117, 120], [121, 127], [128, 133], [134, 140], [140, 141]]}
{"doc_key": "ai-test-172", "ner": [[0, 1, "task"], [19, 19, "programlang"], [21, 21, "programlang"], [23, 23, "programlang"], [25, 26, "programlang"], [28, 28, "programlang"], [30, 30, "programlang"], [32, 32, "programlang"], [34, 34, "programlang"], [36, 36, "programlang"], [38, 38, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 19, 19, "general-affiliation", "", false, false], [0, 1, 21, 21, "general-affiliation", "", false, false], [0, 1, 23, 23, "general-affiliation", "", false, false], [0, 1, 25, 26, "general-affiliation", "", false, false], [0, 1, 28, 28, "general-affiliation", "", false, false], [0, 1, 30, 30, "general-affiliation", "", false, false], [0, 1, 32, 32, "general-affiliation", "", false, false], [0, 1, 34, 34, "general-affiliation", "", false, false], [0, 1, 36, 36, "general-affiliation", "", false, false], [0, 1, 38, 38, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Data", "acquisition", "applications", "are", "usually", "controlled", "by", "software", "programs", "developed", "using", "various", "general", "-", "purpose", "programming", "languages", "such", "as", "Assembly", ",", "BASIC", ",", "C", ",", "C", "++", ",", "C#", ",", "Fortran", ",", "Java", ",", "LabVIEW", ",", "Lisp", ",", "Pascal", ",", "etc."], "sentence-detokenized": "Data acquisition applications are usually controlled by software programs developed using various general-purpose programming languages such as Assembly, BASIC, C, C++, C#, Fortran, Java, LabVIEW, Lisp, Pascal, etc.", "token2charspan": [[0, 4], [5, 16], [17, 29], [30, 33], [34, 41], [42, 52], [53, 55], [56, 64], [65, 73], [74, 83], [84, 89], [90, 97], [98, 105], [105, 106], [106, 113], [114, 125], [126, 135], [136, 140], [141, 143], [144, 152], [152, 153], [154, 159], [159, 160], [161, 162], [162, 163], [164, 165], [165, 167], [167, 168], [169, 171], [171, 172], [173, 180], [180, 181], [182, 186], [186, 187], [188, 195], [195, 196], [197, 201], [201, 202], [203, 209], [209, 210], [211, 215]]}
{"doc_key": "ai-test-173", "ner": [[3, 3, "organisation"], [6, 9, "product"], [10, 10, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 9, 3, 3, "artifact", "", false, false], [6, 9, 10, 10, "physical", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2003", ",", "Honda", "launched", "the", "Cog", "commercial", "in", "the", "UK", "and", "on", "the", "internet", "."], "sentence-detokenized": "In 2003, Honda launched the Cog commercial in the UK and on the internet.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 27], [28, 31], [32, 42], [43, 45], [46, 49], [50, 52], [53, 56], [57, 59], [60, 63], [64, 72], [72, 73]]}
{"doc_key": "ai-test-174", "ner": [[0, 2, "conference"], [3, 7, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 3, 7, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Association", "for", "Computational", "Linguistics", "defines", "computational", "linguistics", "as", ":"], "sentence-detokenized": "The Association for Computational Linguistics defines computational linguistics as:", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 33], [34, 45], [46, 53], [54, 67], [68, 79], [80, 82], [82, 83]]}
{"doc_key": "ai-test-175", "ner": [[0, 2, "algorithm"], [9, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 9, 12, "related-to", "calculates", false, false]], "relations_mapping_to_source": [0], "sentence": ["Expectation", "-maximization", "algorithms", "can", "be", "used", "to", "compute", "approximate", "maximum", "likelihood", "estimates", "of", "unknown", "state", "-", "space", "parameters", "in", "minimum", "-variance", "filters", "and", "smoothers", "."], "sentence-detokenized": "Expectation-maximization algorithms can be used to compute approximate maximum likelihood estimates of unknown state-space parameters in minimum-variance filters and smoothers.", "token2charspan": [[0, 11], [11, 24], [25, 35], [36, 39], [40, 42], [43, 47], [48, 50], [51, 58], [59, 70], [71, 78], [79, 89], [90, 99], [100, 102], [103, 110], [111, 116], [116, 117], [117, 122], [123, 133], [134, 136], [137, 144], [144, 153], [154, 161], [162, 165], [166, 175], [175, 176]]}
{"doc_key": "ai-test-176", "ner": [[3, 3, "misc"], [5, 7, "person"], [9, 10, "person"], [12, 13, "person"], [16, 17, "misc"], [18, 19, "person"], [22, 23, "person"], [27, 27, "person"], [29, 30, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 7, 3, 3, "role", "actor_in", false, false], [9, 10, 3, 3, "role", "actor_in", false, false], [12, 13, 3, 3, "role", "actor_in", false, false], [18, 19, 16, 17, "role", "model_for", false, false], [27, 27, 29, 30, "social", "family", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Correspondents", "included", "former", "Baywatch", "actresses", "Donna", "D'", "Errico", ",", "Carmen", "Electra", "and", "Traci", "Bingham", ",", "former", "Playboy", "Playmate", "Heidi", "Mark", ",", "comedian", "Arj", "Barker", "and", "identical", "twins", "Randy", "and", "Jason", "Sklar", "."], "sentence-detokenized": "Correspondents included former Baywatch actresses Donna D'Errico, Carmen Electra and Traci Bingham, former Playboy Playmate Heidi Mark, comedian Arj Barker and identical twins Randy and Jason Sklar.", "token2charspan": [[0, 14], [15, 23], [24, 30], [31, 39], [40, 49], [50, 55], [56, 58], [58, 64], [64, 65], [66, 72], [73, 80], [81, 84], [85, 90], [91, 98], [98, 99], [100, 106], [107, 114], [115, 123], [124, 129], [130, 134], [134, 135], [136, 144], [145, 148], [149, 155], [156, 159], [160, 169], [170, 175], [176, 181], [182, 185], [186, 191], [192, 197], [197, 198]]}
{"doc_key": "ai-test-177", "ner": [[8, 9, "task"], [11, 11, "task"], [15, 18, "product"], [22, 23, "task"], [25, 25, "task"], [30, 31, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 8, 9, "named", "", false, false], [15, 18, 8, 9, "general-affiliation", "", false, false], [25, 25, 22, 23, "named", "", false, false], [30, 31, 22, 23, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "is", "commonly", "used", "to", "generate", "representations", "for", "speech", "recognition", "(", "ASR", ")", ",", "e.g.", "CMU", "'s", "Sphinx", "system", ",", "and", "for", "speech", "synthesis", "(", "TTS", ")", ",", "e.g.", "the", "Festival", "system", "."], "sentence-detokenized": "It is commonly used to generate representations for speech recognition (ASR), e.g. CMU's Sphinx system, and for speech synthesis (TTS), e.g. the Festival system.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 19], [20, 22], [23, 31], [32, 47], [48, 51], [52, 58], [59, 70], [71, 72], [72, 75], [75, 76], [76, 77], [78, 82], [83, 86], [86, 88], [89, 95], [96, 102], [102, 103], [104, 107], [108, 111], [112, 118], [119, 128], [129, 130], [130, 133], [133, 134], [134, 135], [136, 140], [141, 144], [145, 153], [154, 160], [160, 161]]}
{"doc_key": "ai-test-178", "ner": [[0, 0, "metrics"], [3, 4, "metrics"], [6, 6, "metrics"], [12, 12, "metrics"], [2, 28, "metrics"], [41, 42, "metrics"], [44, 44, "metrics"], [30, 48, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6, 7, 8], "relations": [[3, 4, 0, 0, "named", "", false, false], [6, 6, 3, 4, "named", "", false, false], [12, 12, 0, 0, "named", "", false, false], [44, 44, 41, 42, "named", "", false, false], [30, 48, 41, 42, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 4, 5], "sentence": ["Sensitivity", "or", "true", "positivity", "rate", "(", "TPR", ")", ",", "also", "known", "as", "recall", ",", "is", "the", "proportion", "of", "people", "who", "have", "tested", "positive", "and", "are", "positive", "(", "true", "positivity", ",", "TP", ")", "out", "of", "all", "people", "who", "are", "actually", "positive", "(", "positive", "condition", ",", "CP", "=", "TP", "+", "FN", ")", "."], "sentence-detokenized": "Sensitivity or true positivity rate (TPR), also known as recall, is the proportion of people who have tested positive and are positive (true positivity, TP) out of all people who are actually positive (positive condition, CP = TP + FN).", "token2charspan": [[0, 11], [12, 14], [15, 19], [20, 30], [31, 35], [36, 37], [37, 40], [40, 41], [41, 42], [43, 47], [48, 53], [54, 56], [57, 63], [63, 64], [65, 67], [68, 71], [72, 82], [83, 85], [86, 92], [93, 96], [97, 101], [102, 108], [109, 117], [118, 121], [122, 125], [126, 134], [135, 136], [136, 140], [141, 151], [151, 152], [153, 155], [155, 156], [157, 160], [161, 163], [164, 167], [168, 174], [175, 178], [179, 182], [183, 191], [192, 200], [201, 202], [202, 210], [211, 220], [220, 221], [222, 224], [225, 226], [227, 229], [230, 231], [232, 234], [234, 235], [235, 236]]}
{"doc_key": "ai-test-179", "ner": [[1, 2, "task"], [10, 10, "conference"], [12, 13, "conference"], [15, 15, "conference"], [17, 19, "conference"], [21, 22, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6], "relations": [[10, 10, 1, 2, "topic", "", false, false], [12, 13, 1, 2, "topic", "", false, false], [15, 15, 1, 2, "topic", "", false, false], [17, 19, 1, 2, "topic", "", false, false], [21, 22, 1, 2, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 4, 5], "sentence": ["Popular", "speech", "recognition", "conferences", "held", "every", "year", "or", "two", "include", "SpeechTEK", "and", "SpeechTEK", "Europe", ",", "ICASSP", ",", "Interspeech", "/", "Eurospeech", "and", "IEEE", "ASRU", "."], "sentence-detokenized": "Popular speech recognition conferences held every year or two include SpeechTEK and SpeechTEK Europe, ICASSP, Interspeech/Eurospeech and IEEE ASRU.", "token2charspan": [[0, 7], [8, 14], [15, 26], [27, 38], [39, 43], [44, 49], [50, 54], [55, 57], [58, 61], [62, 69], [70, 79], [80, 83], [84, 93], [94, 100], [100, 101], [102, 108], [108, 109], [110, 121], [121, 122], [122, 132], [133, 136], [137, 141], [142, 146], [146, 147]]}
{"doc_key": "ai-test-180", "ner": [[0, 0, "researcher"], [3, 3, "researcher"], [17, 18, "product"], [21, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 21, 0, 0, "artifact", "", false, false], [21, 21, 3, 3, "artifact", "", false, false], [21, 21, 17, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Devol", "collaborated", "with", "Engelberger", ",", "who", "was", "president", "of", "the", "company", ",", "to", "design", "and", "produce", "an", "industrial", "robot", "under", "the", "Unimate", "brand", "."], "sentence-detokenized": "Devol collaborated with Engelberger, who was president of the company, to design and produce an industrial robot under the Unimate brand.", "token2charspan": [[0, 5], [6, 18], [19, 23], [24, 35], [35, 36], [37, 40], [41, 44], [45, 54], [55, 57], [58, 61], [62, 69], [69, 70], [71, 73], [74, 80], [81, 84], [85, 92], [93, 95], [96, 106], [107, 112], [113, 118], [119, 122], [123, 130], [131, 136], [136, 137]]}
{"doc_key": "ai-test-181", "ner": [[1, 3, "algorithm"], [5, 5, "algorithm"], [9, 11, "algorithm"], [23, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 3, 9, 11, "general-affiliation", "", false, false], [5, 5, 1, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "hidden", "Markov", "model", "(", "HMM", ")", "is", "a", "statistical", "Markov", "model", "in", "which", "the", "system", "being", "modelled", "is", "assumed", "to", "be", "a", "Markov", "process", "with", "unobserved", "(", "hidden", ")", "states", "."], "sentence-detokenized": "A hidden Markov model (HMM) is a statistical Markov model in which the system being modelled is assumed to be a Markov process with unobserved (hidden) states.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [22, 23], [23, 26], [26, 27], [28, 30], [31, 32], [33, 44], [45, 51], [52, 57], [58, 60], [61, 66], [67, 70], [71, 77], [78, 83], [84, 92], [93, 95], [96, 103], [104, 106], [107, 109], [110, 111], [112, 118], [119, 126], [127, 131], [132, 142], [143, 144], [144, 150], [150, 151], [152, 158], [158, 159]]}
{"doc_key": "ai-test-182", "ner": [[16, 22, "metrics"], [19, 21, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "property", ",", "undesirable", "in", "many", "applications", ",", "has", "led", "researchers", "to", "use", "alternatives", "such", "as", "mean", "absolute", "or", "median", "-", "based", "errors", "."], "sentence-detokenized": "This property, undesirable in many applications, has led researchers to use alternatives such as mean absolute or median-based errors.", "token2charspan": [[0, 4], [5, 13], [13, 14], [15, 26], [27, 29], [30, 34], [35, 47], [47, 48], [49, 52], [53, 56], [57, 68], [69, 71], [72, 75], [76, 88], [89, 93], [94, 96], [97, 101], [102, 110], [111, 113], [114, 120], [120, 121], [121, 126], [127, 133], [133, 134]]}
{"doc_key": "ai-test-183", "ner": [[21, 21, "algorithm"], [30, 30, "field"], [22, 36, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[21, 21, 30, 30, "part-of", "", false, false], [21, 21, 22, 36, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Such", "a", "sequence", "(", "which", "depends", "on", "the", "outcome", "of", "the", "previous", "attribute", "search", "at", "each", "stage", ")", "is", "called", "a", "decision", "tree", "and", "is", "applied", "in", "the", "field", "of", "machine", "learning", "known", "as", "decision", "tree", "learning", "."], "sentence-detokenized": "Such a sequence (which depends on the outcome of the previous attribute search at each stage) is called a decision tree and is applied in the field of machine learning known as decision tree learning.", "token2charspan": [[0, 4], [5, 6], [7, 15], [16, 17], [17, 22], [23, 30], [31, 33], [34, 37], [38, 45], [46, 48], [49, 52], [53, 61], [62, 71], [72, 78], [79, 81], [82, 86], [87, 92], [92, 93], [94, 96], [97, 103], [104, 105], [106, 114], [115, 119], [120, 123], [124, 126], [127, 134], [135, 137], [138, 141], [142, 147], [148, 150], [151, 158], [159, 167], [168, 173], [174, 176], [177, 185], [186, 190], [191, 199], [199, 200]]}
{"doc_key": "ai-test-184", "ner": [[2, 3, "task"], [5, 5, "algorithm"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 3, 5, 5, "compare", "", false, false], [19, 21, 5, 5, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "with", "factor", "analysis", ",", "LCA", "can", "also", "be", "used", "to", "classify", "cases", "according", "to", "their", "membership", "of", "a", "maximum", "likelihood", "class", "."], "sentence-detokenized": "As with factor analysis, LCA can also be used to classify cases according to their membership of a maximum likelihood class.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 23], [23, 24], [25, 28], [29, 32], [33, 37], [38, 40], [41, 45], [46, 48], [49, 57], [58, 63], [64, 73], [74, 76], [77, 82], [83, 93], [94, 96], [97, 98], [99, 106], [107, 117], [118, 123], [123, 124]]}
{"doc_key": "ai-test-185", "ner": [[0, 2, "algorithm"], [5, 8, "metrics"], [10, 10, "metrics"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 8, "usage", "", false, false], [5, 8, 12, 13, "related-to", "", false, false], [10, 10, 5, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Supervised", "neural", "networks", "using", "a", "mean", "-", "squared", "error", "(", "MSE", ")", "cost", "function", "can", "use", "formal", "statistical", "methods", "to", "determine", "the", "confidence", "of", "the", "trained", "model", "."], "sentence-detokenized": "Supervised neural networks using a mean-squared error (MSE) cost function can use formal statistical methods to determine the confidence of the trained model.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 32], [33, 34], [35, 39], [39, 40], [40, 47], [48, 53], [54, 55], [55, 58], [58, 59], [60, 64], [65, 73], [74, 77], [78, 81], [82, 88], [89, 100], [101, 108], [109, 111], [112, 121], [122, 125], [126, 136], [137, 139], [140, 143], [144, 151], [152, 157], [157, 158]]}
{"doc_key": "ai-test-186", "ner": [[15, 16, "algorithm"], [19, 21, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 16, 19, 21, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "can", "be", "expressed", "directly", "as", "a", "linear", "program", ",", "but", "is", "also", "equivalent", "to", "Tikhonov", "regularization", "with", "the", "hinge", "loss", "function", ",", "mathV", "(", "f", "(", "x", ")", ",", "y", ")", "=\\", "max", "(", "0", ",", "1", "-", "yf", "(", "x", ")", ")", "/", "math", ":"], "sentence-detokenized": "This can be expressed directly as a linear program, but is also equivalent to Tikhonov regularization with the hinge loss function, mathV (f (x), y) =\\ max (0, 1 - yf (x)) / math:", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 21], [22, 30], [31, 33], [34, 35], [36, 42], [43, 50], [50, 51], [52, 55], [56, 58], [59, 63], [64, 74], [75, 77], [78, 86], [87, 101], [102, 106], [107, 110], [111, 116], [117, 121], [122, 130], [130, 131], [132, 137], [138, 139], [139, 140], [141, 142], [142, 143], [143, 144], [144, 145], [146, 147], [147, 148], [149, 151], [152, 155], [156, 157], [157, 158], [158, 159], [160, 161], [162, 163], [164, 166], [167, 168], [168, 169], [169, 170], [170, 171], [172, 173], [174, 178], [178, 179]]}
{"doc_key": "ai-test-187", "ner": [[6, 6, "researcher"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "following", "technique", "was", "described", "in", "Breiman", "'s", "original", "paper", "and", "is", "implemented", "in", "the", "R", "package", "randomForest", "."], "sentence-detokenized": "The following technique was described in Breiman's original paper and is implemented in the R package randomForest.", "token2charspan": [[0, 3], [4, 13], [14, 23], [24, 27], [28, 37], [38, 40], [41, 48], [48, 50], [51, 59], [60, 65], [66, 69], [70, 72], [73, 84], [85, 87], [88, 91], [92, 93], [94, 101], [102, 114], [114, 115]]}
{"doc_key": "ai-test-188", "ner": [[7, 7, "metrics"], [37, 37, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "image", "quality", "measurements", ",", "such", "as", "PSNR", ",", "are", "usually", "performed", "on", "fixed", "resolution", "images", "and", "do", "not", "take", "into", "account", "some", "aspects", "of", "the", "human", "visual", "system", ",", "such", "as", "spatial", "resolution", "change", "on", "the", "retina", "."], "sentence-detokenized": "Traditional image quality measurements, such as PSNR, are usually performed on fixed resolution images and do not take into account some aspects of the human visual system, such as spatial resolution change on the retina.", "token2charspan": [[0, 11], [12, 17], [18, 25], [26, 38], [38, 39], [40, 44], [45, 47], [48, 52], [52, 53], [54, 57], [58, 65], [66, 75], [76, 78], [79, 84], [85, 95], [96, 102], [103, 106], [107, 109], [110, 113], [114, 118], [119, 123], [124, 131], [132, 136], [137, 144], [145, 147], [148, 151], [152, 157], [158, 164], [165, 171], [171, 172], [173, 177], [178, 180], [181, 188], [189, 199], [200, 206], [207, 209], [210, 213], [214, 220], [220, 221]]}
{"doc_key": "ai-test-189", "ner": [[0, 1, "person"], [3, 4, "person"], [6, 7, "person"], [10, 14, "person"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 16, 17, "role", "", false, false], [3, 4, 16, 17, "role", "", false, false], [6, 7, 16, 17, "role", "", false, false], [16, 17, 10, 14, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["John", "Ireland", ",", "Joanne", "Dru", "and", "Macdonald", "Carey", "starred", "in", "Jack", "Broder", "'s", "color", "production", ",", "Hannah", "Lee", ",", "which", "premiered", "on", "June", "19", ",", "1953", "."], "sentence-detokenized": "John Ireland, Joanne Dru and Macdonald Carey starred in Jack Broder's color production, Hannah Lee, which premiered on June 19, 1953.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 20], [21, 24], [25, 28], [29, 38], [39, 44], [45, 52], [53, 55], [56, 60], [61, 67], [67, 69], [70, 75], [76, 86], [86, 87], [88, 94], [95, 98], [98, 99], [100, 105], [106, 115], [116, 118], [119, 123], [124, 126], [126, 127], [128, 132], [132, 133]]}
{"doc_key": "ai-test-190", "ner": [[4, 5, "task"], [9, 11, "field"], [16, 16, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 9, 11, "usage", "", false, false], [16, 16, 9, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "process", "is", "called", "image", "registration", "and", "uses", "various", "computer", "vision", "methods", ",", "mainly", "related", "to", "tracking", "."], "sentence-detokenized": "This process is called image registration and uses various computer vision methods, mainly related to tracking.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 22], [23, 28], [29, 41], [42, 45], [46, 50], [51, 58], [59, 67], [68, 74], [75, 82], [82, 83], [84, 90], [91, 98], [99, 101], [102, 110], [110, 111]]}
{"doc_key": "ai-test-191", "ner": [[18, 19, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Now", "let", "'s", "start", "to", "explain", "the", "different", "possible", "relationships", "between", "the", "predicted", "and", "the", "actual", "outcome", ":", "Confusion", "matrix"], "sentence-detokenized": "Now let's start to explain the different possible relationships between the predicted and the actual outcome: Confusion matrix", "token2charspan": [[0, 3], [4, 7], [7, 9], [10, 15], [16, 18], [19, 26], [27, 30], [31, 40], [41, 49], [50, 63], [64, 71], [72, 75], [76, 85], [86, 89], [90, 93], [94, 100], [101, 108], [108, 109], [110, 119], [120, 126]]}
{"doc_key": "ai-test-192", "ner": [[1, 1, "product"], [0, 4, "misc"], [6, 6, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 0, 4, "part-of", "", false, false], [1, 1, 0, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "VOICEBOX", "speech", "processing", "toolkit", "for", "MATLAB", "implements", "conversion", "and", "its", "inverse", "as", ":"], "sentence-detokenized": "The VOICEBOX speech processing toolkit for MATLAB implements conversion and its inverse as:", "token2charspan": [[0, 3], [4, 12], [13, 19], [20, 30], [31, 38], [39, 42], [43, 49], [50, 60], [61, 71], [72, 75], [76, 79], [80, 87], [88, 90], [90, 91]]}
{"doc_key": "ai-test-193", "ner": [[0, 0, "programlang"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 9, "general-affiliation", "", false, false], [0, 0, 11, 12, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolog", "is", "a", "logic", "programming", "language", "associated", "with", "artificial", "intelligence", "and", "computational", "linguistics", "."], "sentence-detokenized": "Prolog is a logic programming language associated with artificial intelligence and computational linguistics.", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 17], [18, 29], [30, 38], [39, 49], [50, 54], [55, 65], [66, 78], [79, 82], [83, 96], [97, 108], [108, 109]]}
{"doc_key": "ai-test-194", "ner": [[0, 1, "researcher"], [9, 9, "field"], [11, 11, "field"], [20, 20, "organisation"], [17, 26, "organisation"], [29, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 9, 9, "related-to", "works_with_topic", false, false], [0, 1, 11, 11, "related-to", "works_with_topic", false, false], [0, 1, 20, 20, "role", "", false, false], [0, 1, 17, 26, "role", "", false, false], [0, 1, 29, 32, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Milner", "has", "received", "numerous", "awards", "for", "his", "contributions", "to", "neuroscience", "and", "psychology", ",", "including", "membership", "of", "the", "Royal", "Society", "of", "London", ",", "the", "Royal", "Society", "of", "Canada", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Milner has received numerous awards for his contributions to neuroscience and psychology, including membership of the Royal Society of London, the Royal Society of Canada and the National Academy of Sciences.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 28], [29, 35], [36, 39], [40, 43], [44, 57], [58, 60], [61, 73], [74, 77], [78, 88], [88, 89], [90, 99], [100, 110], [111, 113], [114, 117], [118, 123], [124, 131], [132, 134], [135, 141], [141, 142], [143, 146], [147, 152], [153, 160], [161, 163], [164, 170], [171, 174], [175, 178], [179, 187], [188, 195], [196, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-test-195", "ner": [[8, 9, "field"], [13, 14, "task"], [16, 17, "task"], [19, 20, "task"], [23, 23, "task"], [22, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 14, 8, 9, "part-of", "task_part_of_field", false, false], [16, 17, 8, 9, "part-of", "task_part_of_field", false, false], [19, 20, 8, 9, "part-of", "task_part_of_field", false, false], [23, 23, 8, 9, "part-of", "task_part_of_field", false, false], [22, 25, 8, 9, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["By", "combining", "these", "operators", ",", "algorithms", "for", "many", "image", "processing", "tasks", "such", "as", "feature", "extraction", ",", "image", "segmentation", ",", "image", "enhancement", ",", "image", "filtering", "and", "classification", "can", "be", "obtained", "."], "sentence-detokenized": "By combining these operators, algorithms for many image processing tasks such as feature extraction, image segmentation, image enhancement, image filtering and classification can be obtained.", "token2charspan": [[0, 2], [3, 12], [13, 18], [19, 28], [28, 29], [30, 40], [41, 44], [45, 49], [50, 55], [56, 66], [67, 72], [73, 77], [78, 80], [81, 88], [89, 99], [99, 100], [101, 106], [107, 119], [119, 120], [121, 126], [127, 138], [138, 139], [140, 145], [146, 155], [156, 159], [160, 174], [175, 178], [179, 181], [182, 190], [190, 191]]}
{"doc_key": "ai-test-196", "ner": [[9, 11, "university"], [19, 21, "organisation"], [23, 24, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 24, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "2017", ",", "he", "has", "been", "Professor", "at", "the", "Coll\u00e8ge", "de", "France", "and", ",", "since", "1989", ",", "Director", "of", "INSERM", "Unit", "562", ",", "Cognitive", "Neuroimaging", "."], "sentence-detokenized": "Since 2017, he has been Professor at the Coll\u00e8ge de France and, since 1989, Director of INSERM Unit 562, Cognitive Neuroimaging.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 14], [15, 18], [19, 23], [24, 33], [34, 36], [37, 40], [41, 48], [49, 51], [52, 58], [59, 62], [62, 63], [64, 69], [70, 74], [74, 75], [76, 84], [85, 87], [88, 94], [95, 99], [100, 103], [103, 104], [105, 114], [115, 127], [127, 128]]}
{"doc_key": "ai-test-197", "ner": [[12, 13, "algorithm"], [15, 18, "algorithm"], [24, 24, "algorithm"], [26, 32, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[24, 24, 26, 32, "temporal", "", false, true]], "relations_mapping_to_source": [0], "sentence": ["There", "are", "many", "approaches", "to", "learning", "these", "embeddings", ",", "in", "particular", "using", "Bayesian", "clustering", "or", "energy", "-", "based", "frameworks", "and", ",", "more", "recently", ",", "TransE", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", "2013", ")", "."], "sentence-detokenized": "There are many approaches to learning these embeddings, in particular using Bayesian clustering or energy-based frameworks and, more recently, TransE (Conference on Neural Information Processing Systems 2013).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 25], [26, 28], [29, 37], [38, 43], [44, 54], [54, 55], [56, 58], [59, 69], [70, 75], [76, 84], [85, 95], [96, 98], [99, 105], [105, 106], [106, 111], [112, 122], [123, 126], [126, 127], [128, 132], [133, 141], [141, 142], [143, 149], [150, 151], [151, 161], [162, 164], [165, 171], [172, 183], [184, 194], [195, 202], [203, 207], [207, 208], [208, 209]]}
{"doc_key": "ai-test-198", "ner": [[7, 7, "metrics"], [8, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 8, 7, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "is", "an", "alternative", "to", "the", "Word", "Error", "Rate", "used", "in", "many", "countries", "."], "sentence-detokenized": "It is an alternative to the Word Error Rate used in many countries.", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 20], [21, 23], [24, 27], [28, 32], [33, 38], [39, 43], [44, 48], [49, 51], [52, 56], [57, 66], [66, 67]]}
{"doc_key": "ai-test-199", "ner": [[0, 0, "algorithm"], [11, 12, "task"], [14, 15, "task"], [17, 18, "task"], [20, 22, "task"], [24, 27, "task"], [29, 30, "task"], [46, 46, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 12, 0, 0, "usage", "", false, false], [14, 15, 0, 0, "usage", "", false, false], [17, 18, 0, 0, "usage", "", false, false], [20, 22, 0, 0, "usage", "", false, false], [24, 27, 0, 0, "usage", "", false, false], [29, 30, 0, 0, "usage", "", false, false], [46, 46, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["ANNs", "have", "been", "used", "for", "a", "variety", "of", "tasks", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "board", "and", "video", "games", ",", "medical", "diagnosis", ",", "and", "even", "in", "activities", "traditionally", "thought", "of", "as", "reserved", "for", "humans", ",", "such", "as", "painting", "."], "sentence-detokenized": "ANNs have been used for a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, board and video games, medical diagnosis, and even in activities traditionally thought of as reserved for humans, such as painting.", "token2charspan": [[0, 4], [5, 9], [10, 14], [15, 19], [20, 23], [24, 25], [26, 33], [34, 36], [37, 42], [42, 43], [44, 53], [54, 62], [63, 69], [69, 70], [71, 77], [78, 89], [89, 90], [91, 98], [99, 110], [110, 111], [112, 118], [119, 126], [127, 136], [136, 137], [138, 143], [144, 147], [148, 153], [154, 159], [159, 160], [161, 168], [169, 178], [178, 179], [180, 183], [184, 188], [189, 191], [192, 202], [203, 216], [217, 224], [225, 227], [228, 230], [231, 239], [240, 243], [244, 250], [250, 251], [252, 256], [257, 259], [260, 268], [268, 269]]}
{"doc_key": "ai-test-200", "ner": [[0, 4, "product"], [6, 6, "product"], [26, 28, "field"], [30, 30, "field"], [35, 35, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 26, 28, "related-to", "", false, false], [0, 4, 35, 35, "general-affiliation", "", false, false], [6, 6, 0, 4, "named", "", false, false], [30, 30, 26, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Modular", "Audio", "Recognition", "Framework", "(", "MARF", ")", "is", "an", "open", "-", "source", "research", "platform", "and", "collection", "of", "voice", ",", "sound", ",", "speech", ",", "text", "and", "natural", "language", "processing", "(", "NLP", ")", "algorithms", "written", "in", "Java", "and", "arranged", "in", "a", "modular", "and", "extensible", "framework", "that", "attempts", "to", "facilitate", "the", "addition", "of", "new", "algorithms", "."], "sentence-detokenized": "The Modular Audio Recognition Framework (MARF) is an open-source research platform and collection of voice, sound, speech, text and natural language processing (NLP) algorithms written in Java and arranged in a modular and extensible framework that attempts to facilitate the addition of new algorithms.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 29], [30, 39], [40, 41], [41, 45], [45, 46], [47, 49], [50, 52], [53, 57], [57, 58], [58, 64], [65, 73], [74, 82], [83, 86], [87, 97], [98, 100], [101, 106], [106, 107], [108, 113], [113, 114], [115, 121], [121, 122], [123, 127], [128, 131], [132, 139], [140, 148], [149, 159], [160, 161], [161, 164], [164, 165], [166, 176], [177, 184], [185, 187], [188, 192], [193, 196], [197, 205], [206, 208], [209, 210], [211, 218], [219, 222], [223, 233], [234, 243], [244, 248], [249, 257], [258, 260], [261, 271], [272, 275], [276, 284], [285, 287], [288, 291], [292, 302], [302, 303]]}
{"doc_key": "ai-test-201", "ner": [[13, 15, "organisation"], [22, 22, "country"], [25, 25, "organisation"], [27, 28, "organisation"], [23, 55, "organisation"], [33, 52, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6], "relations": [[25, 25, 22, 22, "physical", "", false, false], [25, 25, 23, 55, "named", "", false, false], [27, 28, 22, 22, "physical", "", false, false], [23, 55, 33, 52, "usage", "", false, false]], "relations_mapping_to_source": [0, 2, 3, 5], "sentence": ["In", "2018", ",", "a", "report", "by", "the", "civil", "rights", "and", "civil", "liberties", "organisation", "Big", "Brother", "Watch", "revealed", "that", "two", "UK", "police", "forces", ",", "South", "Wales", "Police", "and", "Metropolitan", "Police", ",", "were", "using", "live", "facial", "recognition", "at", "public", "events", "and", "in", "public", "spaces", ",", "in", "September", "2019", ",", "the", "use", "of", "facial", "recognition", "by", "South", "Wales", "Police", "was", "declared", "legal", "."], "sentence-detokenized": "In 2018, a report by the civil rights and civil liberties organisation Big Brother Watch revealed that two UK police forces, South Wales Police and Metropolitan Police, were using live facial recognition at public events and in public spaces, in September 2019, the use of facial recognition by South Wales Police was declared legal.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 17], [18, 20], [21, 24], [25, 30], [31, 37], [38, 41], [42, 47], [48, 57], [58, 70], [71, 74], [75, 82], [83, 88], [89, 97], [98, 102], [103, 106], [107, 109], [110, 116], [117, 123], [123, 124], [125, 130], [131, 136], [137, 143], [144, 147], [148, 160], [161, 167], [167, 168], [169, 173], [174, 179], [180, 184], [185, 191], [192, 203], [204, 206], [207, 213], [214, 220], [221, 224], [225, 227], [228, 234], [235, 241], [241, 242], [243, 245], [246, 255], [256, 260], [260, 261], [262, 265], [266, 269], [270, 272], [273, 279], [280, 291], [292, 294], [295, 300], [301, 306], [307, 313], [314, 317], [318, 326], [327, 332], [332, 333]]}
{"doc_key": "ai-test-202", "ner": [[0, 0, "product"], [5, 5, "programlang"], [14, 15, "field"], [17, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 5, "general-affiliation", "", false, false], [0, 0, 14, 15, "related-to", "", false, false], [0, 0, 17, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["ANIMAL", "has", "been", "ported", "to", "R", ",", "a", "freely", "available", "language", "and", "environment", "for", "statistical", "computing", "and", "graphics", "."], "sentence-detokenized": "ANIMAL has been ported to R, a freely available language and environment for statistical computing and graphics.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 22], [23, 25], [26, 27], [27, 28], [29, 30], [31, 37], [38, 47], [48, 56], [57, 60], [61, 72], [73, 76], [77, 88], [89, 98], [99, 102], [103, 111], [111, 112]]}
{"doc_key": "ai-test-203", "ner": [[0, 6, "algorithm"], [8, 10, "algorithm"], [17, 19, "algorithm"], [21, 21, "algorithm"], [24, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 6, 17, 19, "opposite", "alternative to", false, false], [8, 10, 0, 6, "named", "", false, false], [21, 21, 17, 19, "named", "", false, false], [24, 26, 0, 6, "usage", "", false, false], [24, 26, 17, 19, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "time", "-", "homogeneous", "hidden", "Bernoulli", "model", "(", "TI", "-", "HBM", ")", "is", "an", "alternative", "to", "the", "hidden", "Markov", "model", "(", "HMM", ")", "for", "automatic", "speech", "recognition", "."], "sentence-detokenized": "The time-homogeneous hidden Bernoulli model (TI-HBM) is an alternative to the hidden Markov model (HMM) for automatic speech recognition.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 20], [21, 27], [28, 37], [38, 43], [44, 45], [45, 47], [47, 48], [48, 51], [51, 52], [53, 55], [56, 58], [59, 70], [71, 73], [74, 77], [78, 84], [85, 91], [92, 97], [98, 99], [99, 102], [102, 103], [104, 107], [108, 117], [118, 124], [125, 136], [136, 137]]}
{"doc_key": "ai-test-204", "ner": [[4, 4, "organisation"], [12, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 12, 12, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "July", "2016", ",", "Nvidia", "demonstrated", "a", "new", "foveated", "rendering", "method", "at", "SIGGRAPH", "that", "claims", "to", "be", "invisible", "to", "users", "."], "sentence-detokenized": "In July 2016, Nvidia demonstrated a new foveated rendering method at SIGGRAPH that claims to be invisible to users.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 20], [21, 33], [34, 35], [36, 39], [40, 48], [49, 58], [59, 65], [66, 68], [69, 77], [78, 82], [83, 89], [90, 92], [93, 95], [96, 105], [106, 108], [109, 114], [114, 115]]}
{"doc_key": "ai-test-205", "ner": [[5, 7, "misc"], [10, 11, "researcher"], [18, 19, "researcher"], [21, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 7, 10, 11, "origin", "", false, false], [5, 7, 18, 19, "origin", "", false, false], [5, 7, 21, 21, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Both", "are", "based", "on", "the", "speech", "act", "theory", "developed", "by", "John", "Searle", "in", "the", "1960s", "and", "improved", "by", "Terry", "Winograd", "and", "Flores", "in", "the", "1970s", "."], "sentence-detokenized": "Both are based on the speech act theory developed by John Searle in the 1960s and improved by Terry Winograd and Flores in the 1970s.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 17], [18, 21], [22, 28], [29, 32], [33, 39], [40, 49], [50, 52], [53, 57], [58, 64], [65, 67], [68, 71], [72, 77], [78, 81], [82, 90], [91, 93], [94, 99], [100, 108], [109, 112], [113, 119], [120, 122], [123, 126], [127, 132], [132, 133]]}
{"doc_key": "ai-test-206", "ner": [[0, 2, "algorithm"], [23, 24, "researcher"], [26, 26, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 23, 24, "related-to", "", false, false], [26, 26, 23, 24, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Neural", "network", "models", "of", "concept", "formation", "and", "knowledge", "structure", "have", "paved", "the", "way", "for", "powerful", "hierarchical", "models", "of", "knowledge", "organization", ",", "such", "as", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "Neural network models of concept formation and knowledge structure have paved the way for powerful hierarchical models of knowledge organization, such as George Miller's Wordnet.", "token2charspan": [[0, 6], [7, 14], [15, 21], [22, 24], [25, 32], [33, 42], [43, 46], [47, 56], [57, 66], [67, 71], [72, 77], [78, 81], [82, 85], [86, 89], [90, 98], [99, 111], [112, 118], [119, 121], [122, 131], [132, 144], [144, 145], [146, 150], [151, 153], [154, 160], [161, 167], [167, 169], [170, 177], [177, 178]]}
{"doc_key": "ai-test-207", "ner": [[0, 1, "algorithm"], [12, 13, "field"], [16, 18, "product"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 12, 13, "part-of", "", false, false], [0, 1, 21, 23, "part-of", "", false, false], [16, 18, 12, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Template", "matching", "has", "various", "applications", "and", "is", "used", "in", "areas", "such", "as", "facial", "recognition", "(", "see", "facial", "recognition", "system", ")", "and", "medical", "image", "processing", "."], "sentence-detokenized": "Template matching has various applications and is used in areas such as facial recognition (see facial recognition system) and medical image processing.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 29], [30, 42], [43, 46], [47, 49], [50, 54], [55, 57], [58, 63], [64, 68], [69, 71], [72, 78], [79, 90], [91, 92], [92, 95], [96, 102], [103, 114], [115, 121], [121, 122], [123, 126], [127, 134], [135, 140], [141, 151], [151, 152]]}
{"doc_key": "ai-test-208", "ner": [[9, 10, "researcher"], [12, 13, "researcher"], [18, 27, "organisation"], [29, 29, "organisation"], [36, 37, "algorithm"], [40, 48, "conference"], [46, 46, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 10, 18, 27, "role", "", false, false], [9, 10, 40, 48, "physical", "", false, false], [9, 10, 40, 48, "temporal", "", false, false], [9, 10, 46, 46, "physical", "", false, false], [12, 13, 18, 27, "role", "", false, false], [12, 13, 40, 48, "temporal", "", false, false], [29, 29, 18, 27, "named", "", false, false], [40, 48, 36, 37, "topic", "", false, false], [46, 46, 40, 48, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["However", ",", "it", "was", "not", "until", "2005", ",", "when", "Navneet", "Dalal", "and", "Bill", "Triggs", ",", "researchers", "at", "the", "French", "National", "Institute", "for", "Research", "in", "Computer", "Science", "and", "Automation", "(", "INRIA", ")", ",", "presented", "further", "work", "on", "HOG", "descriptors", "at", "the", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "Conference", "."], "sentence-detokenized": "However, it was not until 2005, when Navneet Dalal and Bill Triggs, researchers at the French National Institute for Research in Computer Science and Automation (INRIA), presented further work on HOG descriptors at the Computer Vision and Pattern Recognition (CVPR) Conference.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 15], [16, 19], [20, 25], [26, 30], [30, 31], [32, 36], [37, 44], [45, 50], [51, 54], [55, 59], [60, 66], [66, 67], [68, 79], [80, 82], [83, 86], [87, 93], [94, 102], [103, 112], [113, 116], [117, 125], [126, 128], [129, 137], [138, 145], [146, 149], [150, 160], [161, 162], [162, 167], [167, 168], [168, 169], [170, 179], [180, 187], [188, 192], [193, 195], [196, 199], [200, 211], [212, 214], [215, 218], [219, 227], [228, 234], [235, 238], [239, 246], [247, 258], [259, 260], [260, 264], [264, 265], [266, 276], [276, 277]]}
{"doc_key": "ai-test-209", "ner": [[3, 3, "university"], [16, 18, "organisation"], [20, 21, "organisation"], [28, 29, "field"], [36, 38, "researcher"], [40, 42, "researcher"], [45, 47, "researcher"], [50, 52, "organisation"], [57, 59, "organisation"], [64, 65, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[20, 21, 28, 29, "related-to", "", false, false], [36, 38, 20, 21, "physical", "", false, false], [36, 38, 20, 21, "role", "", false, false], [40, 42, 20, 21, "physical", "", false, false], [40, 42, 20, 21, "role", "", false, false], [45, 47, 20, 21, "physical", "", false, false], [45, 47, 20, 21, "role", "", false, false], [64, 65, 57, 59, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Before", "joining", "the", "Penn", "faculty", "in", "2002", ",", "he", "spent", "a", "decade", "(", "1991-2001", ")", "at", "AT", "&T", "Labs", "and", "Bell", "Labs", ",", "including", "as", "head", "of", "the", "artificial", "intelligence", "department", "with", "colleagues", "such", "as", "Michael", "L", ".", "Littman", ",", "David", "A.", "McAllester", ",", "and", "Richard", "S.", "Sutton", ";", "the", "secure", "systems", "research", "department", ";", "and", "the", "machine", "learning", "department", "with", "members", "such", "as", "Michael", "Collins", "and", "the", "lead", ")", "."], "sentence-detokenized": "Before joining the Penn faculty in 2002, he spent a decade (1991-2001) at AT&T Labs and Bell Labs, including as head of the artificial intelligence department with colleagues such as Michael L. Littman, David A. McAllester, and Richard S. Sutton; the secure systems research department; and the machine learning department with members such as Michael Collins and the lead).", "token2charspan": [[0, 6], [7, 14], [15, 18], [19, 23], [24, 31], [32, 34], [35, 39], [39, 40], [41, 43], [44, 49], [50, 51], [52, 58], [59, 60], [60, 69], [69, 70], [71, 73], [74, 76], [76, 78], [79, 83], [84, 87], [88, 92], [93, 97], [97, 98], [99, 108], [109, 111], [112, 116], [117, 119], [120, 123], [124, 134], [135, 147], [148, 158], [159, 163], [164, 174], [175, 179], [180, 182], [183, 190], [191, 192], [192, 193], [194, 201], [201, 202], [203, 208], [209, 211], [212, 222], [222, 223], [224, 227], [228, 235], [236, 238], [239, 245], [245, 246], [247, 250], [251, 257], [258, 265], [266, 274], [275, 285], [285, 286], [287, 290], [291, 294], [295, 302], [303, 311], [312, 322], [323, 327], [328, 335], [336, 340], [341, 343], [344, 351], [352, 359], [360, 363], [364, 367], [368, 372], [372, 373], [373, 374]]}
{"doc_key": "ai-test-210", "ner": [[6, 14, "field"], [25, 26, "task"]], "ner_mapping_to_source": [1, 2], "relations": [[25, 26, 6, 14, "part-of", "", true, false]], "relations_mapping_to_source": [1], "sentence": ["When", "the", "data", "is", "unlabeled", ",", "supervised", "learning", "is", "not", "possible", "and", "an", "unsupervised", "learning", "approach", "is", "required", ",", "which", "attempts", "to", "find", "a", "natural", "cluster", "analysis", "in", "clusters", "and", "then", "map", "the", "new", "data", "to", "these", "formed", "clusters", "."], "sentence-detokenized": "When the data is unlabeled, supervised learning is not possible and an unsupervised learning approach is required, which attempts to find a natural cluster analysis in clusters and then map the new data to these formed clusters.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 26], [26, 27], [28, 38], [39, 47], [48, 50], [51, 54], [55, 63], [64, 67], [68, 70], [71, 83], [84, 92], [93, 101], [102, 104], [105, 113], [113, 114], [115, 120], [121, 129], [130, 132], [133, 137], [138, 139], [140, 147], [148, 155], [156, 164], [165, 167], [168, 176], [177, 180], [181, 185], [186, 189], [190, 193], [194, 197], [198, 202], [203, 205], [206, 211], [212, 218], [219, 227], [227, 228]]}
{"doc_key": "ai-test-211", "ner": [[3, 4, "field"], [15, 18, "organisation"], [25, 26, "field"], [28, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 15, 18, "origin", "", false, false], [3, 4, 25, 26, "part-of", "", false, false], [3, 4, 28, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "field", "of", "computer", "science", "developed", "in", "the", "1950s", "in", "academic", "institutions", "such", "as", "the", "MIT", "A.I", ".", "Lab", ",", "initially", "as", "a", "branch", "of", "artificial", "intelligence", "and", "robotics", "."], "sentence-detokenized": "This field of computer science developed in the 1950s in academic institutions such as the MIT A.I. Lab, initially as a branch of artificial intelligence and robotics.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 30], [31, 40], [41, 43], [44, 47], [48, 53], [54, 56], [57, 65], [66, 78], [79, 83], [84, 86], [87, 90], [91, 94], [95, 98], [98, 99], [100, 103], [103, 104], [105, 114], [115, 117], [118, 119], [120, 126], [127, 129], [130, 140], [141, 153], [154, 157], [158, 166], [166, 167]]}
{"doc_key": "ai-test-212", "ner": [[7, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "could", "also", "be", "replaced", "with", "the", "Log", "loss", "equation", "below", ":"], "sentence-detokenized": "It could also be replaced with the Log loss equation below:", "token2charspan": [[0, 2], [3, 8], [9, 13], [14, 16], [17, 25], [26, 30], [31, 34], [35, 38], [39, 43], [44, 52], [53, 58], [58, 59]]}
{"doc_key": "ai-test-213", "ner": [[0, 3, "organisation"], [7, 10, "organisation"], [16, 18, "university"], [20, 20, "university"], [22, 23, "university"], [26, 28, "university"], [31, 31, "country"], [35, 35, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 3, 35, 35, "related-to", "research_leader_in_field", false, false], [7, 10, 0, 3, "named", "", false, false], [7, 10, 35, 35, "related-to", "research_leader_in_field", false, false], [16, 18, 35, 35, "related-to", "research_leader_in_field", false, false], [20, 20, 35, 35, "related-to", "research_leader_in_field", false, false], [22, 23, 35, 35, "related-to", "research_leader_in_field", false, false], [26, 28, 31, 31, "physical", "", false, false], [26, 28, 35, 35, "related-to", "research_leader_in_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "Shirley", "Ryan", "AbilityLab", "(", "formerly", "the", "Rehabilitation", "Institute", "of", "Chicago", ")", ",", "the", "University", "of", "California", "at", "Berkeley", ",", "MIT", ",", "Stanford", "University", "and", "the", "University", "of", "Twente", "in", "the", "Netherlands", "are", "leaders", "in", "biomechanics", "research", "."], "sentence-detokenized": "The Shirley Ryan AbilityLab (formerly the Rehabilitation Institute of Chicago), the University of California at Berkeley, MIT, Stanford University and the University of Twente in the Netherlands are leaders in biomechanics research.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 27], [28, 29], [29, 37], [38, 41], [42, 56], [57, 66], [67, 69], [70, 77], [77, 78], [78, 79], [80, 83], [84, 94], [95, 97], [98, 108], [109, 111], [112, 120], [120, 121], [122, 125], [125, 126], [127, 135], [136, 146], [147, 150], [151, 154], [155, 165], [166, 168], [169, 175], [176, 178], [179, 182], [183, 194], [195, 198], [199, 206], [207, 209], [210, 222], [223, 231], [231, 232]]}
{"doc_key": "ai-test-214", "ner": [[27, 32, "metrics"], [44, 44, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Given", "a", "set", "of", "forecast", "values", "and", "a", "corresponding", "set", "of", "actual", "values", "for", "X", "for", "different", "time", "periods", ",", "a", "common", "evaluation", "technique", "is", "to", "use", "the", "root", "mean", "square", "forecast", "error", ";", "other", "measures", "are", "also", "available", "(", "see", "forecasts", "#", "forecasting", "accuracy", ")", "."], "sentence-detokenized": "Given a set of forecast values and a corresponding set of actual values for X for different time periods, a common evaluation technique is to use the root mean square forecast error; other measures are also available (see forecasts # forecasting accuracy).", "token2charspan": [[0, 5], [6, 7], [8, 11], [12, 14], [15, 23], [24, 30], [31, 34], [35, 36], [37, 50], [51, 54], [55, 57], [58, 64], [65, 71], [72, 75], [76, 77], [78, 81], [82, 91], [92, 96], [97, 104], [104, 105], [106, 107], [108, 114], [115, 125], [126, 135], [136, 138], [139, 141], [142, 145], [146, 149], [150, 154], [155, 159], [160, 166], [167, 175], [176, 181], [181, 182], [183, 188], [189, 197], [198, 201], [202, 206], [207, 216], [217, 218], [218, 221], [222, 231], [232, 233], [234, 245], [246, 254], [254, 255], [255, 256]]}
{"doc_key": "ai-test-215", "ner": [[13, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "measures", ",", "such", "as", "the", "proportion", "of", "correct", "predictions", "(", "also", "called", "accuracy", ")", ",", "are", "not", "useful", "when", "the", "two", "classes", "are", "of", "very", "different", "sizes", "."], "sentence-detokenized": "Other measures, such as the proportion of correct predictions (also called accuracy), are not useful when the two classes are of very different sizes.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 20], [21, 23], [24, 27], [28, 38], [39, 41], [42, 49], [50, 61], [62, 63], [63, 67], [68, 74], [75, 83], [83, 84], [84, 85], [86, 89], [90, 93], [94, 100], [101, 105], [106, 109], [110, 113], [114, 121], [122, 125], [126, 128], [129, 133], [134, 143], [144, 149], [149, 150]]}
{"doc_key": "ai-test-216", "ner": [[5, 6, "product"], [12, 16, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 12, 16, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "alpha", "version", "of", "OpenCV", "was", "released", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "in", "2000", ",", "and", "five", "beta", "versions", "were", "released", "between", "2001", "and", "2005", "."], "sentence-detokenized": "The first alpha version of OpenCV was released at the Conference on Computer Vision and Pattern Recognition in 2000, and five beta versions were released between 2001 and 2005.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 23], [24, 26], [27, 33], [34, 37], [38, 46], [47, 49], [50, 53], [54, 64], [65, 67], [68, 76], [77, 83], [84, 87], [88, 95], [96, 107], [108, 110], [111, 115], [115, 116], [117, 120], [121, 125], [126, 130], [131, 139], [140, 144], [145, 153], [154, 161], [162, 166], [167, 170], [171, 175], [175, 176]]}
{"doc_key": "ai-test-217", "ner": [[21, 21, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Results", "were", "presented", "showing", "a", "correlation", "of", "up", "to", "0.964", "with", "human", "judgement", "at", "the", "corpus", "level", ",", "compared", "to", "the", "BLEU", "result", "of", "0.817", "for", "the", "same", "dataset", "."], "sentence-detokenized": "Results were presented showing a correlation of up to 0.964 with human judgement at the corpus level, compared to the BLEU result of 0.817 for the same dataset.", "token2charspan": [[0, 7], [8, 12], [13, 22], [23, 30], [31, 32], [33, 44], [45, 47], [48, 50], [51, 53], [54, 59], [60, 64], [65, 70], [71, 80], [81, 83], [84, 87], [88, 94], [95, 100], [100, 101], [102, 110], [111, 113], [114, 117], [118, 122], [123, 129], [130, 132], [133, 138], [139, 142], [143, 146], [147, 151], [152, 159], [159, 160]]}
{"doc_key": "ai-test-218", "ner": [[4, 4, "metrics"], [17, 17, "metrics"], [19, 21, "metrics"], [23, 25, "metrics"], [36, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 17, 17, "compare", "", false, false], [4, 4, 19, 21, "compare", "", false, false], [4, 4, 23, 25, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["An", "early", "version", "of", "VMAF", "was", "found", "to", "outperform", "other", "image", "and", "video", "quality", "indicators", "such", "as", "SSIM", ",", "PSNR", "-", "HVS", "and", "VQM", "-", "VFD", "on", "three", "out", "of", "four", "datasets", "in", "terms", "of", "prediction", "accuracy", "compared", "to", "subjective", "assessments", "."], "sentence-detokenized": "An early version of VMAF was found to outperform other image and video quality indicators such as SSIM, PSNR -HVS and VQM-VFD on three out of four datasets in terms of prediction accuracy compared to subjective assessments.", "token2charspan": [[0, 2], [3, 8], [9, 16], [17, 19], [20, 24], [25, 28], [29, 34], [35, 37], [38, 48], [49, 54], [55, 60], [61, 64], [65, 70], [71, 78], [79, 89], [90, 94], [95, 97], [98, 102], [102, 103], [104, 108], [109, 110], [110, 113], [114, 117], [118, 121], [121, 122], [122, 125], [126, 128], [129, 134], [135, 138], [139, 141], [142, 146], [147, 155], [156, 158], [159, 164], [165, 167], [168, 178], [179, 187], [188, 196], [197, 199], [200, 210], [211, 222], [222, 223]]}
{"doc_key": "ai-test-219", "ner": [[20, 21, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 21, 28, 29, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "example", ",", "the", "ambiguity", "of", "the", "word", "\"", "mouse", "\"", "(", "animal", "or", "device", ")", "is", "not", "relevant", "for", "machine", "translation", ",", "but", "it", "is", "relevant", "for", "information", "retrieval", "."], "sentence-detokenized": "For example, the ambiguity of the word \"mouse\" (animal or device) is not relevant for machine translation, but it is relevant for information retrieval.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 26], [27, 29], [30, 33], [34, 38], [39, 40], [40, 45], [45, 46], [47, 48], [48, 54], [55, 57], [58, 64], [64, 65], [66, 68], [69, 72], [73, 81], [82, 85], [86, 93], [94, 105], [105, 106], [107, 110], [111, 113], [114, 116], [117, 125], [126, 129], [130, 141], [142, 151], [151, 152]]}
{"doc_key": "ai-test-220", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 0, 1, "usage", "", false, false], [12, 13, 6, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Geometric", "hashing", "was", "originally", "proposed", "in", "computer", "vision", "for", "2D", "and", "3D", "object", "recognition", ","], "sentence-detokenized": "Geometric hashing was originally proposed in computer vision for 2D and 3D object recognition,", "token2charspan": [[0, 9], [10, 17], [18, 21], [22, 32], [33, 41], [42, 44], [45, 53], [54, 60], [61, 64], [65, 67], [68, 71], [72, 74], [75, 81], [82, 93], [93, 94]]}
{"doc_key": "ai-test-221", "ner": [[9, 9, "field"], [13, 14, "field"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 14, 9, 9, "part-of", "subfield", false, false], [16, 17, 9, 9, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "is", "one", "of", "the", "three", "main", "categories", "of", "machine", "learning", ",", "alongside", "supervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "It is one of the three main categories of machine learning, alongside supervised learning and reinforcement learning.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 12], [13, 16], [17, 22], [23, 27], [28, 38], [39, 41], [42, 49], [50, 58], [58, 59], [60, 69], [70, 80], [81, 89], [90, 93], [94, 107], [108, 116], [116, 117]]}
{"doc_key": "ai-test-222", "ner": [[5, 6, "field"], [16, 16, "field"], [18, 19, "field"], [21, 22, "field"], [24, 25, "field"], [27, 30, "field"], [32, 33, "field"], [35, 36, "field"], [38, 38, "field"], [41, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[5, 6, 16, 16, "part-of", "subfield", false, false], [5, 6, 18, 19, "part-of", "subfield", false, false], [5, 6, 21, 22, "part-of", "subfield", false, false], [5, 6, 24, 25, "part-of", "subfield", false, false], [5, 6, 27, 30, "part-of", "subfield", false, false], [5, 6, 32, 33, "part-of", "subfield", false, false], [5, 6, 35, 36, "part-of", "subfield", false, false], [5, 6, 38, 38, "part-of", "subfield", false, false], [5, 6, 41, 42, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Because", "of", "its", "generality", ",", "reinforcement", "learning", "is", "studied", "in", "many", "other", "disciplines", ",", "such", "as", "games", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimization", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", ",", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Because of its generality, reinforcement learning is studied in many other disciplines, such as games, control theory, operations research, information theory, simulation-based optimization, multi-agent systems, swarm intelligence, statistics, and genetic algorithms.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 25], [25, 26], [27, 40], [41, 49], [50, 52], [53, 60], [61, 63], [64, 68], [69, 74], [75, 86], [86, 87], [88, 92], [93, 95], [96, 101], [101, 102], [103, 110], [111, 117], [117, 118], [119, 129], [130, 138], [138, 139], [140, 151], [152, 158], [158, 159], [160, 170], [170, 171], [171, 176], [177, 189], [189, 190], [191, 202], [203, 210], [210, 211], [212, 217], [218, 230], [230, 231], [232, 242], [242, 243], [244, 247], [248, 255], [256, 266], [266, 267]]}
{"doc_key": "ai-test-223", "ner": [[0, 1, "field"], [6, 7, "field"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "related-to", "", false, false], [0, 1, 9, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pattern", "recognition", "is", "closely", "related", "to", "artificial", "intelligence", "and", "machine", "learning", ","], "sentence-detokenized": "Pattern recognition is closely related to artificial intelligence and machine learning,", "token2charspan": [[0, 7], [8, 19], [20, 22], [23, 30], [31, 38], [39, 41], [42, 52], [53, 65], [66, 69], [70, 77], [78, 86], [86, 87]]}
{"doc_key": "ai-test-224", "ner": [[10, 11, "algorithm"], [14, 17, "field"], [16, 16, "field"], [28, 29, "task"], [31, 31, "task"], [33, 34, "task"], [36, 37, "algorithm"], [39, 41, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 11, 14, 17, "related-to", "", false, false], [10, 11, 16, 16, "related-to", "", false, false], [28, 29, 10, 11, "usage", "", true, false], [31, 31, 10, 11, "usage", "", true, false], [33, 34, 10, 11, "usage", "", true, false], [36, 37, 10, 11, "usage", "", true, false], [39, 41, 10, 11, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "software", "is", "used", "to", "design", ",", "train", "and", "implement", "neural", "network", "models", "(", "supervised", "and", "unsupervised", "learning", ")", "to", "perform", "a", "wide", "variety", "of", "tasks", "such", "as", "data", "mining", ",", "classification", ",", "function", "approximation", ",", "multivariate", "regression", "and", "time", "series", "prediction", "."], "sentence-detokenized": "The software is used to design, train and implement neural network models (supervised and unsupervised learning) to perform a wide variety of tasks such as data mining, classification, function approximation, multivariate regression and time series prediction.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 20], [21, 23], [24, 30], [30, 31], [32, 37], [38, 41], [42, 51], [52, 58], [59, 66], [67, 73], [74, 75], [75, 85], [86, 89], [90, 102], [103, 111], [111, 112], [113, 115], [116, 123], [124, 125], [126, 130], [131, 138], [139, 141], [142, 147], [148, 152], [153, 155], [156, 160], [161, 167], [167, 168], [169, 183], [183, 184], [185, 193], [194, 207], [207, 208], [209, 221], [222, 232], [233, 236], [237, 241], [242, 248], [249, 259], [259, 260]]}
{"doc_key": "ai-test-225", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2016", ",", "he", "was", "elected", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2016, he was elected a Fellow of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [98, 99]]}
{"doc_key": "ai-test-226", "ner": [[6, 9, "organisation"], [16, 21, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", "(", "since", "2005", ")", "and", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "(", "since", "2009", ")", ","], "sentence-detokenized": "She is a member of the National Academy of Sciences (since 2005) and the American Academy of Arts and Sciences (since 2009),", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 15], [16, 18], [19, 22], [23, 31], [32, 39], [40, 42], [43, 51], [52, 53], [53, 58], [59, 63], [63, 64], [65, 68], [69, 72], [73, 81], [82, 89], [90, 92], [93, 97], [98, 101], [102, 110], [111, 112], [112, 117], [118, 122], [122, 123], [123, 124]]}
{"doc_key": "ai-test-227", "ner": [[3, 5, "misc"], [9, 14, "product"], [17, 17, "country"], [19, 19, "country"], [23, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 14, 3, 5, "temporal", "", false, false], [9, 14, 17, 17, "physical", "", false, false], [9, 14, 19, 19, "physical", "", false, false], [9, 14, 23, 26, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["During", "the", "1973", "Yom", "Kippur", "War", ",", "Soviet", "-supplied", "surface", "-", "to", "-", "air", "missile", "batteries", "from", "Egypt", "and", "Syria", "caused", "significant", "damage", "to", "Israeli", "fighter", "planes", "."], "sentence-detokenized": "During the 1973 Yom Kippur War, Soviet-supplied surface-to-air missile batteries from Egypt and Syria caused significant damage to Israeli fighter planes.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 19], [20, 26], [27, 30], [30, 31], [32, 38], [38, 47], [48, 55], [55, 56], [56, 58], [58, 59], [59, 62], [63, 70], [71, 80], [81, 85], [86, 91], [92, 95], [96, 101], [102, 108], [109, 120], [121, 127], [128, 130], [131, 138], [139, 146], [147, 153], [153, 154]]}
{"doc_key": "ai-test-228", "ner": [[10, 11, "product"], [15, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 16, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Another", "resource", "(", "free", ",", "but", "copyrighted", ")", "is", "the", "HTK", "book", "(", "and", "accompanying", "HTK", "toolkit", ")", "."], "sentence-detokenized": "Another resource (free, but copyrighted) is the HTK book (and accompanying HTK toolkit).", "token2charspan": [[0, 7], [8, 16], [17, 18], [18, 22], [22, 23], [24, 27], [28, 39], [39, 40], [41, 43], [44, 47], [48, 51], [52, 56], [57, 58], [58, 61], [62, 74], [75, 78], [79, 86], [86, 87], [87, 88]]}
{"doc_key": "ai-test-229", "ner": [[5, 6, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["-", "were", "taken", "at", "the", "2004", "AAAI", "Spring", "Symposium", ",", "where", "linguists", ",", "computer", "scientists", "and", "other", "interested", "researchers", "first", "aligned", "their", "interests", "and", "proposed", "common", "tasks", "and", "benchmark", "datasets", "for", "systematic", "computational", "research", "on", "affect", ",", "attraction", ",", "subjectivity", "and", "sentiment", "in", "text", "."], "sentence-detokenized": "- were taken at the 2004 AAAI Spring Symposium, where linguists, computer scientists and other interested researchers first aligned their interests and proposed common tasks and benchmark datasets for systematic computational research on affect, attraction, subjectivity and sentiment in text.", "token2charspan": [[0, 1], [2, 6], [7, 12], [13, 15], [16, 19], [20, 24], [25, 29], [30, 36], [37, 46], [46, 47], [48, 53], [54, 63], [63, 64], [65, 73], [74, 84], [85, 88], [89, 94], [95, 105], [106, 117], [118, 123], [124, 131], [132, 137], [138, 147], [148, 151], [152, 160], [161, 167], [168, 173], [174, 177], [178, 187], [188, 196], [197, 200], [201, 211], [212, 225], [226, 234], [235, 237], [238, 244], [244, 245], [246, 256], [256, 257], [258, 270], [271, 274], [275, 284], [285, 287], [288, 292], [292, 293]]}
{"doc_key": "ai-test-230", "ner": [[12, 13, "task"], [23, 24, "task"], [26, 28, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "single", "grid", "can", "be", "analysed", "in", "terms", "of", "both", "content", "(", "visual", "inspection", ")", "and", "structure", "(", "the", "main", "techniques", "used", "are", "cluster", "analysis", ",", "principal", "component", "analysis", "and", "a", "variety", "of", "structural", "indices", "related", "to", "the", "complexity", "and", "range", "of", "assessments", ")", "."], "sentence-detokenized": "A single grid can be analysed in terms of both content (visual inspection) and structure (the main techniques used are cluster analysis, principal component analysis and a variety of structural indices related to the complexity and range of assessments).", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 17], [18, 20], [21, 29], [30, 32], [33, 38], [39, 41], [42, 46], [47, 54], [55, 56], [56, 62], [63, 73], [73, 74], [75, 78], [79, 88], [89, 90], [90, 93], [94, 98], [99, 109], [110, 114], [115, 118], [119, 126], [127, 135], [135, 136], [137, 146], [147, 156], [157, 165], [166, 169], [170, 171], [172, 179], [180, 182], [183, 193], [194, 201], [202, 209], [210, 212], [213, 216], [217, 227], [228, 231], [232, 237], [238, 240], [241, 252], [252, 253], [253, 254]]}
{"doc_key": "ai-test-231", "ner": [[3, 3, "organisation"], [13, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2018", ",", "Toyota", "was", "seen", "as", "lagging", "behind", "when", "it", "came", "to", "self", "-", "driving", "cars", "in", "need", "of", "innovation", "."], "sentence-detokenized": "In 2018, Toyota was seen as lagging behind when it came to self-driving cars in need of innovation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 24], [25, 27], [28, 35], [36, 42], [43, 47], [48, 50], [51, 55], [56, 58], [59, 63], [63, 64], [64, 71], [72, 76], [77, 79], [80, 84], [85, 87], [88, 98], [98, 99]]}
{"doc_key": "ai-test-232", "ner": [[38, 39, "misc"], [41, 42, "misc"], [45, 49, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "targets", "include", "natural", "objects", "such", "as", "land", ",", "sea", ",", "precipitation", "(", "such", "as", "rain", ",", "snow", "or", "hail", ")", ",", "sandstorms", ",", "animals", "(", "especially", "birds", ")", ",", "atmospheric", "turbulence", "and", "other", "atmospheric", "effects", "such", "as", "ionospheric", "reflections", ",", "meteor", "trails", "and", "the", "three", "-", "body", "scattering", "spike", "."], "sentence-detokenized": "Such targets include natural objects such as land, sea, precipitation (such as rain, snow or hail), sandstorms, animals (especially birds), atmospheric turbulence and other atmospheric effects such as ionospheric reflections, meteor trails and the three-body scattering spike.", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 28], [29, 36], [37, 41], [42, 44], [45, 49], [49, 50], [51, 54], [54, 55], [56, 69], [70, 71], [71, 75], [76, 78], [79, 83], [83, 84], [85, 89], [90, 92], [93, 97], [97, 98], [98, 99], [100, 110], [110, 111], [112, 119], [120, 121], [121, 131], [132, 137], [137, 138], [138, 139], [140, 151], [152, 162], [163, 166], [167, 172], [173, 184], [185, 192], [193, 197], [198, 200], [201, 212], [213, 224], [224, 225], [226, 232], [233, 239], [240, 243], [244, 247], [248, 253], [253, 254], [254, 258], [259, 269], [270, 275], [275, 276]]}
{"doc_key": "ai-test-233", "ner": [[20, 21, "product"], [40, 41, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "terms", "of", "planning", "and", "control", ",", "the", "key", "difference", "between", "humanoids", "and", "other", "types", "of", "robots", "(", "such", "as", "industrial", "robots", ")", "is", "that", "the", "robot", "'s", "movement", "must", "be", "human", "-", "like", ",", "using", "legged", "locomotion", ",", "especially", "bipedal", "walking", "."], "sentence-detokenized": "In terms of planning and control, the key difference between humanoids and other types of robots (such as industrial robots) is that the robot's movement must be human-like, using legged locomotion, especially bipedal walking.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 20], [21, 24], [25, 32], [32, 33], [34, 37], [38, 41], [42, 52], [53, 60], [61, 70], [71, 74], [75, 80], [81, 86], [87, 89], [90, 96], [97, 98], [98, 102], [103, 105], [106, 116], [117, 123], [123, 124], [125, 127], [128, 132], [133, 136], [137, 142], [142, 144], [145, 153], [154, 158], [159, 161], [162, 167], [167, 168], [168, 172], [172, 173], [174, 179], [180, 186], [187, 197], [197, 198], [199, 209], [210, 217], [218, 225], [225, 226]]}
{"doc_key": "ai-test-234", "ner": [[0, 1, "algorithm"], [9, 10, "misc"], [14, 14, "metrics"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Gradient", "descent", "may", "require", "many", "iterations", "to", "compute", "a", "local", "minimum", "with", "the", "required", "accuracy", "if", "the", "curvature", "in", "different", "directions", "is", "very", "different", "for", "the", "given", "function", "."], "sentence-detokenized": "Gradient descent may require many iterations to compute a local minimum with the required accuracy if the curvature in different directions is very different for the given function.", "token2charspan": [[0, 8], [9, 16], [17, 20], [21, 28], [29, 33], [34, 44], [45, 47], [48, 55], [56, 57], [58, 63], [64, 71], [72, 76], [77, 80], [81, 89], [90, 98], [99, 101], [102, 105], [106, 115], [116, 118], [119, 128], [129, 139], [140, 142], [143, 147], [148, 157], [158, 161], [162, 165], [166, 171], [172, 180], [180, 181]]}
{"doc_key": "ai-test-235", "ner": [[1, 5, "misc"], [0, 9, "misc"], [14, 21, "conference"], [23, 23, "location"], [25, 25, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 5, 0, 9, "part-of", "", true, false], [14, 21, 23, 23, "physical", "", false, true], [23, 23, 25, 25, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["RoboCup", "2D", "Soccer", "Simulation", "League", "1997", "was", "the", "first", "RoboCup", "competition", "promoted", "at", "the", "Joint", "International", "Conference", "on", "Artificial", "Intelligence", ",", "held", "in", "Nagoya", ",", "Japan", ",", "from", "23", "to", "29", "August", "1997", "."], "sentence-detokenized": "RoboCup 2D Soccer Simulation League 1997 was the first RoboCup competition promoted at the Joint International Conference on Artificial Intelligence, held in Nagoya, Japan, from 23 to 29 August 1997.", "token2charspan": [[0, 7], [8, 10], [11, 17], [18, 28], [29, 35], [36, 40], [41, 44], [45, 48], [49, 54], [55, 62], [63, 74], [75, 83], [84, 86], [87, 90], [91, 96], [97, 110], [111, 121], [122, 124], [125, 135], [136, 148], [148, 149], [150, 154], [155, 157], [158, 164], [164, 165], [166, 171], [171, 172], [173, 177], [178, 180], [181, 183], [184, 186], [187, 193], [194, 198], [198, 199]]}
{"doc_key": "ai-test-236", "ner": [[8, 8, "programlang"], [12, 13, "programlang"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "programming", "options", "include", "a", "built", "-", "in", "Python", "environment", "and", "an", "R", "console", ",", "plus", "support", "for", "Rserve", "."], "sentence-detokenized": "Other programming options include a built-in Python environment and an R console, plus support for Rserve.", "token2charspan": [[0, 5], [6, 17], [18, 25], [26, 33], [34, 35], [36, 41], [41, 42], [42, 44], [45, 51], [52, 63], [64, 67], [68, 70], [71, 72], [73, 80], [80, 81], [82, 86], [87, 94], [95, 98], [99, 105], [105, 106]]}
{"doc_key": "ai-test-237", "ner": [[1, 4, "location"], [9, 10, "field"], [12, 12, "field"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"], [35, 36, "field"], [40, 41, "field"], [44, 45, "field"], [49, 50, "field"], [52, 57, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[15, 16, 12, 12, "related-to", "contributes_to_field", true, false], [18, 19, 12, 12, "related-to", "contributes_to_field", true, false], [21, 22, 12, 12, "related-to", "contributes_to_field", true, false], [44, 45, 40, 41, "part-of", "", false, false], [49, 50, 44, 45, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Since", "Bonn", ",", "he", "has", "made", "fundamental", "contributions", "to", "artificial", "intelligence", "and", "robotics", "(", "with", "Wolfram", "Burgard", ",", "Dieter", "Fox", ",", "Sebastian", "Thrun", "among", "his", "students", ")", ",", "as", "well", "as", "to", "the", "development", "of", "software", "engineering", ",", "especially", "in", "civil", "engineering", ",", "and", "information", "systems", ",", "especially", "in", "geosciences", ".", "won", "the", "2016.2014", "AAAI", "Classic", "Paper", "Award", "."], "sentence-detokenized": "Since Bonn, he has made fundamental contributions to artificial intelligence and robotics (with Wolfram Burgard, Dieter Fox, Sebastian Thrun among his students), as well as to the development of software engineering, especially in civil engineering, and information systems, especially in geosciences. won the 2016.2014 AAAI Classic Paper Award.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 14], [15, 18], [19, 23], [24, 35], [36, 49], [50, 52], [53, 63], [64, 76], [77, 80], [81, 89], [90, 91], [91, 95], [96, 103], [104, 111], [111, 112], [113, 119], [120, 123], [123, 124], [125, 134], [135, 140], [141, 146], [147, 150], [151, 159], [159, 160], [160, 161], [162, 164], [165, 169], [170, 172], [173, 175], [176, 179], [180, 191], [192, 194], [195, 203], [204, 215], [215, 216], [217, 227], [228, 230], [231, 236], [237, 248], [248, 249], [250, 253], [254, 265], [266, 273], [273, 274], [275, 285], [286, 288], [289, 300], [300, 301], [302, 305], [306, 309], [310, 319], [320, 324], [325, 332], [333, 338], [339, 344], [344, 345]]}
{"doc_key": "ai-test-238", "ner": [[2, 9, "conference"], [16, 17, "location"], [19, 19, "location"], [21, 21, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 9, 16, 17, "physical", "", false, false], [16, 17, 19, 19, "physical", "", false, false], [19, 19, 21, 21, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "first", "US", "edition", "of", "Campus", "Party", "will", "take", "place", "August", "20", "-", "22", "at", "the", "TCF", "Center", "in", "Detroit", ",", "Michigan", "."], "sentence-detokenized": "The first US edition of Campus Party will take place August 20-22 at the TCF Center in Detroit, Michigan.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 20], [21, 23], [24, 30], [31, 36], [37, 41], [42, 46], [47, 52], [53, 59], [60, 62], [62, 63], [63, 65], [66, 68], [69, 72], [73, 76], [77, 83], [84, 86], [87, 94], [94, 95], [96, 104], [104, 105]]}
{"doc_key": "ai-test-239", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [10, 13, "misc"], [22, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 10, 13, "win-defeat", "", false, false], [5, 6, 10, 13, "win-defeat", "", false, false], [8, 8, 10, 13, "win-defeat", "", false, false], [10, 13, 22, 24, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Along", "with", "Yann", "LeCun", "and", "Yoshua", "Bengio", ",", "Hinton", "won", "the", "2018", "Turing", "Award", "for", "conceptual", "and", "engineering", "breakthroughs", "that", "have", "made", "deep", "neural", "networks", "a", "key", "component", "of", "computation", "."], "sentence-detokenized": "Along with Yann LeCun and Yoshua Bengio, Hinton won the 2018 Turing Award for conceptual and engineering breakthroughs that have made deep neural networks a key component of computation.", "token2charspan": [[0, 5], [6, 10], [11, 15], [16, 21], [22, 25], [26, 32], [33, 39], [39, 40], [41, 47], [48, 51], [52, 55], [56, 60], [61, 67], [68, 73], [74, 77], [78, 88], [89, 92], [93, 104], [105, 118], [119, 123], [124, 128], [129, 133], [134, 138], [139, 145], [146, 154], [155, 156], [157, 160], [161, 170], [171, 173], [174, 185], [185, 186]]}
{"doc_key": "ai-test-240", "ner": [[0, 2, "product"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 9, 9, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Euler", "Math", "Toolbox", "uses", "a", "matrix", "language", "similar", "to", "MATLAB", ",", "a", "system", "that", "has", "been", "developed", "since", "the", "1970s", "."], "sentence-detokenized": "Euler Math Toolbox uses a matrix language similar to MATLAB, a system that has been developed since the 1970s.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 23], [24, 25], [26, 32], [33, 41], [42, 49], [50, 52], [53, 59], [59, 60], [61, 62], [63, 69], [70, 74], [75, 78], [79, 83], [84, 93], [94, 99], [100, 103], [104, 109], [109, 110]]}
{"doc_key": "ai-test-241", "ner": [[6, 6, "programlang"], [8, 9, "programlang"], [11, 11, "programlang"], [13, 13, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "languages", "allow", "portability", "(", "e.g.", "Scheme", ",", "Common", "Lisp", ",", "Perl", "or", "D", ")", "."], "sentence-detokenized": "Some languages allow portability (e.g. Scheme, Common Lisp, Perl or D).", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 32], [33, 34], [34, 38], [39, 45], [45, 46], [47, 53], [54, 58], [58, 59], [60, 64], [65, 67], [68, 69], [69, 70], [70, 71]]}
{"doc_key": "ai-test-242", "ner": [[7, 7, "misc"], [11, 12, "researcher"], [14, 15, "researcher"], [30, 31, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 11, 12, "artifact", "", false, false], [7, 7, 14, 15, "artifact", "", false, false], [7, 7, 30, 31, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1969", ",", "a", "famous", "book", "called", "Perceptrons", ",", "written", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", ",", "showed", "that", "it", "was", "impossible", "for", "these", "classes", "of", "networks", "to", "learn", "an", "XOR", "function", "."], "sentence-detokenized": "In 1969, a famous book called Perceptrons, written by Marvin Minsky and Seymour Papert, showed that it was impossible for these classes of networks to learn an XOR function.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 17], [18, 22], [23, 29], [30, 41], [41, 42], [43, 50], [51, 53], [54, 60], [61, 67], [68, 71], [72, 79], [80, 86], [86, 87], [88, 94], [95, 99], [100, 102], [103, 106], [107, 117], [118, 121], [122, 127], [128, 135], [136, 138], [139, 147], [148, 150], [151, 156], [157, 159], [160, 163], [164, 172], [172, 173]]}
{"doc_key": "ai-test-243", "ner": [[4, 8, "misc"], [15, 15, "product"], [20, 24, "organisation"], [28, 33, "organisation"], [36, 41, "location"], [43, 43, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 24, 15, 15, "usage", "", false, false], [20, 24, 36, 41, "physical", "", false, false], [28, 33, 20, 24, "named", "", false, false], [36, 41, 43, 43, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "large", "number", "of", "Russian", "scientific", "and", "technical", "documents", "were", "translated", "with", "the", "help", "of", "SYSTRAN", "under", "the", "auspices", "of", "the", "USAF", "External", "Technology", "Division", "(", "later", "the", "National", "Air", "and", "Space", "Intelligence", "Center", ")", "at", "Wright", "-", "Patterson", "Air", "Force", "Base", ",", "Ohio", "."], "sentence-detokenized": "A large number of Russian scientific and technical documents were translated with the help of SYSTRAN under the auspices of the USAF External Technology Division (later the National Air and Space Intelligence Center) at Wright-Patterson Air Force Base, Ohio.", "token2charspan": [[0, 1], [2, 7], [8, 14], [15, 17], [18, 25], [26, 36], [37, 40], [41, 50], [51, 60], [61, 65], [66, 76], [77, 81], [82, 85], [86, 90], [91, 93], [94, 101], [102, 107], [108, 111], [112, 120], [121, 123], [124, 127], [128, 132], [133, 141], [142, 152], [153, 161], [162, 163], [163, 168], [169, 172], [173, 181], [182, 185], [186, 189], [190, 195], [196, 208], [209, 215], [215, 216], [217, 219], [220, 226], [226, 227], [227, 236], [237, 240], [241, 246], [247, 251], [251, 252], [253, 257], [257, 258]]}
{"doc_key": "ai-test-244", "ner": [[4, 5, "field"], [0, 14, "field"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Semi-supervised", "learning", "is", "between", "unsupervised", "learning", "(", "without", "labeled", "instructional", "data", ")", "and", "supervised", "learning", "(", "with", "fully", "labeled", "instructional", "data", ")", "."], "sentence-detokenized": "Semi-supervised learning is between unsupervised learning (without labeled instructional data) and supervised learning (with fully labeled instructional data).", "token2charspan": [[0, 15], [16, 24], [25, 27], [28, 35], [36, 48], [49, 57], [58, 59], [59, 66], [67, 74], [75, 88], [89, 93], [93, 94], [95, 98], [99, 109], [110, 118], [119, 120], [120, 124], [125, 130], [131, 138], [139, 152], [153, 157], [157, 158], [158, 159]]}
{"doc_key": "ai-test-245", "ner": [[0, 4, "algorithm"], [9, 11, "algorithm"], [26, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 9, 11, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Ann", "-", "gram", "model", "is", "a", "type", "of", "probabilistic", "language", "model", "for", "predicting", "the", "next", "element", "in", "such", "a", "sequence", "in", "the", "form", "of", "a", "Markov", "model", "of", "order", "(", "n", "-", "1", ")", ".efficient", "."], "sentence-detokenized": "The Ann -gram model is a type of probabilistic language model for predicting the next element in such a sequence in the form of a Markov model of order (n - 1) .efficient.", "token2charspan": [[0, 3], [4, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 24], [25, 29], [30, 32], [33, 46], [47, 55], [56, 61], [62, 65], [66, 76], [77, 80], [81, 85], [86, 93], [94, 96], [97, 101], [102, 103], [104, 112], [113, 115], [116, 119], [120, 124], [125, 127], [128, 129], [130, 136], [137, 142], [143, 145], [146, 151], [152, 153], [153, 154], [155, 156], [157, 158], [158, 159], [160, 170], [170, 171]]}
{"doc_key": "ai-test-246", "ner": [[0, 2, "organisation"], [4, 4, "product"], [8, 14, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 4, 4, "usage", "", false, false], [8, 14, 0, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Cleveland", "Clinic", "used", "Cyc", "to", "develop", "a", "natural", "language", "query", "interface", "for", "biomedical", "information", "that", "encompasses", "decades", "of", "cardiothoracic", "surgery", "information", "."], "sentence-detokenized": "The Cleveland Clinic used Cyc to develop a natural language query interface for biomedical information that encompasses decades of cardiothoracic surgery information.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 25], [26, 29], [30, 32], [33, 40], [41, 42], [43, 50], [51, 59], [60, 65], [66, 75], [76, 79], [80, 90], [91, 102], [103, 107], [108, 119], [120, 127], [128, 130], [131, 145], [146, 153], [154, 165], [165, 166]]}
{"doc_key": "ai-test-247", "ner": [[6, 7, "country"], [9, 9, "country"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 9, 9, "opposite", "strained_relations", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "incident", "strained", "relations", "between", "the", "United", "States", "and", "Japan", "and", "led", "to", "the", "arrest", "and", "prosecution", "of", "two", "executives", "and", "the", "imposition", "of", "sanctions", "against", "the", "company", "by", "both", "countries", "."], "sentence-detokenized": "The incident strained relations between the United States and Japan and led to the arrest and prosecution of two executives and the imposition of sanctions against the company by both countries.", "token2charspan": [[0, 3], [4, 12], [13, 21], [22, 31], [32, 39], [40, 43], [44, 50], [51, 57], [58, 61], [62, 67], [68, 71], [72, 75], [76, 78], [79, 82], [83, 89], [90, 93], [94, 105], [106, 108], [109, 112], [113, 123], [124, 127], [128, 131], [132, 142], [143, 145], [146, 155], [156, 163], [164, 167], [168, 175], [176, 178], [179, 183], [184, 193], [193, 194]]}
{"doc_key": "ai-test-248", "ner": [[6, 8, "algorithm"], [11, 16, "field"], [19, 19, "misc"], [29, 29, "misc"], [33, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 8, 11, 16, "type-of", "", false, false], [19, 19, 11, 16, "part-of", "", true, false], [29, 29, 11, 16, "part-of", "", true, false], [33, 33, 11, 16, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["When", "modeling", "is", "done", "using", "an", "artificial", "neural", "network", "or", "other", "machine", "learning", "methods", ",", "parameter", "optimization", "is", "called", "training", ",", "while", "hyperparameter", "optimization", "of", "the", "model", "is", "called", "tuning", "and", "often", "uses", "cross-validation", "..."], "sentence-detokenized": "When modeling is done using an artificial neural network or other machine learning methods, parameter optimization is called training, while hyperparameter optimization of the model is called tuning and often uses cross-validation...", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 21], [22, 27], [28, 30], [31, 41], [42, 48], [49, 56], [57, 59], [60, 65], [66, 73], [74, 82], [83, 90], [90, 91], [92, 101], [102, 114], [115, 117], [118, 124], [125, 133], [133, 134], [135, 140], [141, 155], [156, 168], [169, 171], [172, 175], [176, 181], [182, 184], [185, 191], [192, 198], [199, 202], [203, 208], [209, 213], [214, 230], [230, 233]]}
{"doc_key": "ai-test-249", "ner": [[8, 8, "country"], [10, 10, "country"], [12, 13, "country"], [22, 22, "organisation"], [17, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[22, 22, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Localised", "versions", "of", "the", "site", "available", "in", "the", "UK", ",", "India", "and", "Australia", "have", "been", "discontinued", "following", "Fandango", "'s", "acquisition", "of", "Rotten", "Tomatoes", "."], "sentence-detokenized": "Localised versions of the site available in the UK, India and Australia have been discontinued following Fandango's acquisition of Rotten Tomatoes.", "token2charspan": [[0, 9], [10, 18], [19, 21], [22, 25], [26, 30], [31, 40], [41, 43], [44, 47], [48, 50], [50, 51], [52, 57], [58, 61], [62, 71], [72, 76], [77, 81], [82, 94], [95, 104], [105, 113], [113, 115], [116, 127], [128, 130], [131, 137], [138, 146], [146, 147]]}
{"doc_key": "ai-test-250", "ner": [[1, 1, "task"], [11, 12, "metrics"], [24, 25, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 11, 12, "related-to", "", false, false], [11, 12, 24, 25, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "NER", "model", "is", "one", "of", "many", "methods", "for", "determining", "the", "accuracy", "of", "live", "captioning", "in", "television", "broadcasts", "and", "events", "that", "are", "produced", "using", "speech", "recognition", "."], "sentence-detokenized": "The NER model is one of many methods for determining the accuracy of live captioning in television broadcasts and events that are produced using speech recognition.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 20], [21, 23], [24, 28], [29, 36], [37, 40], [41, 52], [53, 56], [57, 65], [66, 68], [69, 73], [74, 84], [85, 87], [88, 98], [99, 109], [110, 113], [114, 120], [121, 125], [126, 129], [130, 138], [139, 144], [145, 151], [152, 163], [163, 164]]}
{"doc_key": "ai-test-251", "ner": [[0, 0, "researcher"], [4, 4, "university"], [8, 9, "university"], [11, 11, "location"], [13, 17, "university"], [19, 20, "university"], [22, 22, "location"], [25, 30, "university"], [32, 34, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 4, "physical", "", false, false], [0, 0, 4, 4, "role", "", false, false], [0, 0, 8, 9, "physical", "", false, false], [0, 0, 8, 9, "role", "", false, false], [0, 0, 13, 17, "physical", "", false, false], [0, 0, 13, 17, "role", "", false, false], [0, 0, 19, 20, "physical", "", false, false], [0, 0, 19, 20, "role", "", false, false], [0, 0, 25, 30, "physical", "", false, false], [0, 0, 25, 30, "role", "", false, false], [8, 9, 11, 11, "physical", "", false, false], [13, 17, 22, 22, "physical", "", false, false], [19, 20, 22, 22, "physical", "", false, false], [25, 30, 32, 34, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Atran", "has", "taught", "at", "Cambridge", "University", ",", "the", "Hebrew", "University", "of", "Jerusalem", ",", "\u00c9cole", "pratique", "des", "hautes", "\u00e9tudes", "and", "\u00c9cole", "Polytechnique", "in", "Paris", ",", "and", "John", "Jay", "College", "of", "Criminal", "Justice", "in", "New", "York", "City", "."], "sentence-detokenized": "Atran has taught at Cambridge University, the Hebrew University of Jerusalem, \u00c9cole pratique des hautes \u00e9tudes and \u00c9cole Polytechnique in Paris, and John Jay College of Criminal Justice in New York City.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 29], [30, 40], [40, 41], [42, 45], [46, 52], [53, 63], [64, 66], [67, 76], [76, 77], [78, 83], [84, 92], [93, 96], [97, 103], [104, 110], [111, 114], [115, 120], [121, 134], [135, 137], [138, 143], [143, 144], [145, 148], [149, 153], [154, 157], [158, 165], [166, 168], [169, 177], [178, 185], [186, 188], [189, 192], [193, 197], [198, 202], [202, 203]]}
{"doc_key": "ai-test-252", "ner": [[0, 0, "product"], [4, 6, "task"], [11, 12, "researcher"], [14, 14, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 6, "origin", "", false, false], [0, 0, 4, 6, "related-to", "", false, false], [4, 6, 14, 14, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["SHRDLU", "was", "an", "early", "natural", "language", "understanding", "computer", "program", "developed", "by", "Terry", "Winograd", "at", "MIT", "in", "1968", "-", "1970", "."], "sentence-detokenized": "SHRDLU was an early natural language understanding computer program developed by Terry Winograd at MIT in 1968-1970.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 19], [20, 27], [28, 36], [37, 50], [51, 59], [60, 67], [68, 77], [78, 80], [81, 86], [87, 95], [96, 98], [99, 102], [103, 105], [106, 110], [110, 111], [111, 115], [115, 116]]}
{"doc_key": "ai-test-253", "ner": [[0, 5, "misc"], [7, 9, "field"], [10, 14, "university"], [18, 18, "country"], [16, 29, "university"], [32, 32, "misc"], [34, 37, "field"], [41, 44, "university"], [45, 45, "misc"], [45, 49, "field"], [54, 54, "misc"], [59, 63, "university"], [68, 69, "field"], [73, 74, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "relations": [[0, 5, 7, 9, "topic", "", false, false], [0, 5, 10, 14, "origin", "", false, false], [10, 14, 16, 29, "role", "affiliated_with", false, false], [32, 32, 34, 37, "topic", "", false, false], [32, 32, 41, 44, "origin", "", false, false], [45, 45, 45, 49, "topic", "", false, false], [54, 54, 59, 63, "origin", "", false, false], [54, 54, 68, 69, "topic", "", false, false], [73, 74, 59, 63, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 3, 5, 6, 7, 8, 9, 10], "sentence": ["He", "received", "a", "bachelor", "'s", "degree", "in", "electronic", "engineering", "from", "B.M.S", ".", "College", "of", "Engineering", "in", "Bangalore", ",", "India", ",", "in", "1982", ",", "when", "he", "was", "affiliated", "with", "Bangalore", "University", ",", "an", "M.S.", "in", "electrical", "and", "computer", "engineering", "in", "1984", "from", "Drexel", "University", ",", "an", "M.S.", "in", "computer", "science", "in", "1989", ",", "and", "a", "Ph.D.", "in", "1990", "from", "the", "University", "of", "Wisconsin", "-", "Madison", ",", "where", "he", "studied", "artificial", "intelligence", "and", "worked", "with", "Leonard", "Uhr", "."], "sentence-detokenized": "He received a bachelor's degree in electronic engineering from B.M.S. College of Engineering in Bangalore, India, in 1982, when he was affiliated with Bangalore University, an M.S. in electrical and computer engineering in 1984 from Drexel University, an M.S. in computer science in 1989, and a Ph.D. in 1990 from the University of Wisconsin-Madison, where he studied artificial intelligence and worked with Leonard Uhr.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 22], [22, 24], [25, 31], [32, 34], [35, 45], [46, 57], [58, 62], [63, 68], [68, 69], [70, 77], [78, 80], [81, 92], [93, 95], [96, 105], [105, 106], [107, 112], [112, 113], [114, 116], [117, 121], [121, 122], [123, 127], [128, 130], [131, 134], [135, 145], [146, 150], [151, 160], [161, 171], [171, 172], [173, 175], [176, 180], [181, 183], [184, 194], [195, 198], [199, 207], [208, 219], [220, 222], [223, 227], [228, 232], [233, 239], [240, 250], [250, 251], [252, 254], [255, 259], [260, 262], [263, 271], [272, 279], [280, 282], [283, 287], [287, 288], [289, 292], [293, 294], [295, 300], [301, 303], [304, 308], [309, 313], [314, 317], [318, 328], [329, 331], [332, 341], [341, 342], [342, 349], [349, 350], [351, 356], [357, 359], [360, 367], [368, 378], [379, 391], [392, 395], [396, 402], [403, 407], [408, 415], [416, 419], [419, 420]]}
{"doc_key": "ai-test-254", "ner": [[6, 8, "metrics"], [10, 13, "metrics"], [19, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 13, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Accuracy", "is", "usually", "evaluated", "using", "the", "word", "error", "rate", "(", "WER", ")", ",", "while", "speed", "is", "measured", "using", "the", "real", "time", "factor", "."], "sentence-detokenized": "Accuracy is usually evaluated using the word error rate (WER), while speed is measured using the real time factor.", "token2charspan": [[0, 8], [9, 11], [12, 19], [20, 29], [30, 35], [36, 39], [40, 44], [45, 50], [51, 55], [56, 57], [57, 60], [60, 61], [61, 62], [63, 68], [69, 74], [75, 77], [78, 86], [87, 92], [93, 96], [97, 101], [102, 106], [107, 113], [113, 114]]}
{"doc_key": "ai-test-255", "ner": [[3, 4, "researcher"], [8, 10, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 8, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1971", ",", "Terry", "Winograd", "developed", "the", "first", "natural", "language", "processing", "engine", "capable", "of", "interpreting", "naturally", "written", "commands", "in", "a", "simple", "rule", "-", "governed", "environment", "."], "sentence-detokenized": "In 1971, Terry Winograd developed the first natural language processing engine capable of interpreting naturally written commands in a simple rule-governed environment.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 33], [34, 37], [38, 43], [44, 51], [52, 60], [61, 71], [72, 78], [79, 86], [87, 89], [90, 102], [103, 112], [113, 120], [121, 129], [130, 132], [133, 134], [135, 141], [142, 146], [146, 147], [147, 155], [156, 167], [167, 168]]}
{"doc_key": "ai-test-256", "ner": [[4, 5, "field"], [7, 8, "researcher"], [10, 13, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 7, 8, "related-to", "", false, false], [4, 5, 10, 13, "related-to", "", false, false], [4, 5, 15, 16, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "field", "of", "artificial", "intelligence", ",", "Marvin", "Minsky", ",", "Herbert", "A", ".", "Simon", "and", "Allen", "Newell", "stand", "out", "."], "sentence-detokenized": "In the field of artificial intelligence, Marvin Minsky, Herbert A. Simon and Allen Newell stand out.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 26], [27, 39], [39, 40], [41, 47], [48, 54], [54, 55], [56, 63], [64, 65], [65, 66], [67, 72], [73, 76], [77, 82], [83, 89], [90, 95], [96, 99], [99, 100]]}
{"doc_key": "ai-test-257", "ner": [[9, 9, "field"], [33, 33, "field"], [36, 37, "field"], [40, 41, "field"], [50, 53, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[33, 33, 9, 9, "origin", "", true, false], [33, 33, 9, 9, "part-of", "", false, false], [33, 33, 40, 41, "compare", "", false, false], [36, 37, 9, 9, "origin", "", true, false], [36, 37, 9, 9, "part-of", "", false, false], [36, 37, 40, 41, "compare", "", false, false], [40, 41, 9, 9, "origin", "", true, false], [40, 41, 9, 9, "part-of", "", false, false], [40, 41, 50, 53, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In", "the", "second", "half", "of", "the", "20th", "century", ",", "electrical", "engineering", "itself", "separated", "into", "several", "disciplines", ",", "specialising", "in", "the", "design", "and", "analysis", "of", "systems", "that", "manipulate", "physical", "signals", ";", "for", "example", ",", "electronic", "engineering", "and", "computer", "engineering", ";", "while", "design", "engineering", "developed", "to", "deal", "with", "the", "functional", "design", "of", "user", "-", "machine", "interfaces", "."], "sentence-detokenized": "In the second half of the 20th century, electrical engineering itself separated into several disciplines, specialising in the design and analysis of systems that manipulate physical signals; for example, electronic engineering and computer engineering; while design engineering developed to deal with the functional design of user-machine interfaces.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 18], [19, 21], [22, 25], [26, 30], [31, 38], [38, 39], [40, 50], [51, 62], [63, 69], [70, 79], [80, 84], [85, 92], [93, 104], [104, 105], [106, 118], [119, 121], [122, 125], [126, 132], [133, 136], [137, 145], [146, 148], [149, 156], [157, 161], [162, 172], [173, 181], [182, 189], [189, 190], [191, 194], [195, 202], [202, 203], [204, 214], [215, 226], [227, 230], [231, 239], [240, 251], [251, 252], [253, 258], [259, 265], [266, 277], [278, 287], [288, 290], [291, 295], [296, 300], [301, 304], [305, 315], [316, 322], [323, 325], [326, 330], [330, 331], [331, 338], [339, 349], [349, 350]]}
{"doc_key": "ai-test-258", "ner": [[5, 5, "metrics"], [7, 7, "metrics"], [10, 10, "metrics"], [47, 48, "metrics"], [46, 46, "metrics"], [61, 67, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 10, 7, 7, "named", "", false, false], [47, 48, 46, 46, "named", "", false, false], [46, 46, 61, 67, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Perhaps", "the", "simplest", "statistic", "is", "accuracy", "or", "correct", "fraction", "(", "CF", ")", ",", "which", "measures", "the", "fraction", "of", "all", "instances", "that", "are", "correctly", "classified", ";", "it", "is", "the", "ratio", "of", "the", "number", "of", "correct", "classifications", "to", "the", "total", "number", "of", "correct", "or", "incorrect", "classifications", ":", "(", "TP", "+", "TN", ")", "/", "total", "population", "=", "(", "TP", "+", "TN", ")", "/", "(", "TP", "+", "TN", "+", "FP", "+", "FN", ")", "."], "sentence-detokenized": "Perhaps the simplest statistic is accuracy or correct fraction (CF), which measures the fraction of all instances that are correctly classified; it is the ratio of the number of correct classifications to the total number of correct or incorrect classifications: (TP + TN) / total population = (TP + TN) / (TP + TN + FP + FN).", "token2charspan": [[0, 7], [8, 11], [12, 20], [21, 30], [31, 33], [34, 42], [43, 45], [46, 53], [54, 62], [63, 64], [64, 66], [66, 67], [67, 68], [69, 74], [75, 83], [84, 87], [88, 96], [97, 99], [100, 103], [104, 113], [114, 118], [119, 122], [123, 132], [133, 143], [143, 144], [145, 147], [148, 150], [151, 154], [155, 160], [161, 163], [164, 167], [168, 174], [175, 177], [178, 185], [186, 201], [202, 204], [205, 208], [209, 214], [215, 221], [222, 224], [225, 232], [233, 235], [236, 245], [246, 261], [261, 262], [263, 264], [264, 266], [267, 268], [269, 271], [271, 272], [273, 274], [275, 280], [281, 291], [292, 293], [294, 295], [295, 297], [298, 299], [300, 302], [302, 303], [304, 305], [306, 307], [307, 309], [310, 311], [312, 314], [315, 316], [317, 319], [320, 321], [322, 324], [324, 325], [325, 326]]}
{"doc_key": "ai-test-259", "ner": [[15, 23, "conference"], [25, 27, "conference"], [32, 32, "location"], [37, 37, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 23, 32, 32, "physical", "", false, false], [25, 27, 15, 23, "named", "", false, false], [37, 37, 15, 23, "role", "sponsors", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "academic", "community", ",", "the", "main", "research", "forums", "started", "in", "1995", ",", "when", "the", "first", "international", "conference", "on", "Data", "Mining", "and", "Knowledge", "Discovery", "(", "KDD", "-", "95", ")", "was", "launched", "in", "Montreal", "under", "the", "auspices", "of", "AAAI", "."], "sentence-detokenized": "In the academic community, the main research forums started in 1995, when the first international conference on Data Mining and Knowledge Discovery (KDD-95) was launched in Montreal under the auspices of AAAI.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 25], [25, 26], [27, 30], [31, 35], [36, 44], [45, 51], [52, 59], [60, 62], [63, 67], [67, 68], [69, 73], [74, 77], [78, 83], [84, 97], [98, 108], [109, 111], [112, 116], [117, 123], [124, 127], [128, 137], [138, 147], [148, 149], [149, 152], [152, 153], [153, 155], [155, 156], [157, 160], [161, 169], [170, 172], [173, 181], [182, 187], [188, 191], [192, 200], [201, 203], [204, 208], [208, 209]]}
{"doc_key": "ai-test-260", "ner": [[9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "this", "approach", ",", "models", "are", "developed", "using", "various", "data", "mining", "and", "machine", "learning", "algorithms", "to", "predict", "user", "ratings", "of", "unrated", "items", "."], "sentence-detokenized": "In this approach, models are developed using various data mining and machine learning algorithms to predict user ratings of unrated items.", "token2charspan": [[0, 2], [3, 7], [8, 16], [16, 17], [18, 24], [25, 28], [29, 38], [39, 44], [45, 52], [53, 57], [58, 64], [65, 68], [69, 76], [77, 85], [86, 96], [97, 99], [100, 107], [108, 112], [113, 120], [121, 123], [124, 131], [132, 137], [137, 138]]}
{"doc_key": "ai-test-261", "ner": [[11, 11, "algorithm"], [16, 17, "algorithm"], [19, 20, "algorithm"], [27, 28, "misc"], [31, 32, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 11, 16, 17, "related-to", "equivalent", false, false], [16, 17, 19, 20, "usage", "", false, false], [19, 20, 31, 32, "usage", "", false, false], [31, 32, 27, 28, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "light", "of", "the", "above", "discussion", ",", "we", "see", "that", "the", "SVM", "technique", "is", "equivalent", "to", "empirical", "risk", "with", "Tikhonov", "regularization", ",", "where", "in", "this", "case", "the", "loss", "function", "is", "the", "hinge", "loss"], "sentence-detokenized": "In light of the above discussion, we see that the SVM technique is equivalent to empirical risk with Tikhonov regularization, where in this case the loss function is the hinge loss", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 15], [16, 21], [22, 32], [32, 33], [34, 36], [37, 40], [41, 45], [46, 49], [50, 53], [54, 63], [64, 66], [67, 77], [78, 80], [81, 90], [91, 95], [96, 100], [101, 109], [110, 124], [124, 125], [126, 131], [132, 134], [135, 139], [140, 144], [145, 148], [149, 153], [154, 162], [163, 165], [166, 169], [170, 175], [176, 180]]}
{"doc_key": "ai-test-262", "ner": [[6, 7, "person"], [11, 12, "person"], [15, 15, "organisation"], [17, 18, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[17, 18, 15, 15, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "2015", "edition", "was", "hosted", "by", "Molly", "McGrath", ",", "with", "commentators", "Chris", "Rose", "and", "former", "UFC", "fighter", "Kenny", "Florian", "."], "sentence-detokenized": "The 2015 edition was hosted by Molly McGrath, with commentators Chris Rose and former UFC fighter Kenny Florian.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 27], [28, 30], [31, 36], [37, 44], [44, 45], [46, 50], [51, 63], [64, 69], [70, 74], [75, 78], [79, 85], [86, 89], [90, 97], [98, 103], [104, 111], [111, 112]]}
{"doc_key": "ai-test-263", "ner": [[3, 6, "product"], [9, 11, "researcher"], [16, 17, "researcher"], [18, 18, "researcher"], [20, 20, "researcher"], [27, 27, "researcher"], [30, 31, "task"], [29, 29, "product"], [13, 36, "researcher"], [37, 39, "task"], [42, 43, "researcher"], [47, 48, "task"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[3, 6, 9, 11, "origin", "", false, false], [3, 6, 16, 17, "origin", "", false, false], [3, 6, 18, 18, "origin", "", false, false], [16, 17, 20, 20, "named", "same", false, false], [16, 17, 27, 27, "named", "same", false, false], [30, 31, 29, 29, "related-to", "", false, false], [29, 29, 27, 27, "origin", "", false, false]], "relations_mapping_to_source": [0, 2, 3, 5, 6, 7, 8], "sentence": ["A", "subset", "called", "Micro", "-", "Planner", "was", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "Sussman", "and", "Winograd", "1971", "and", "has", "been", "used", "in", "Winograd", "'s", "SHRDLU", "natural", "language", "understanding", "program", ",", "Eugene", "Charniak", "'s", "story", "understanding", "work", ",", "Thorne", "McCarty", "'s", "work", "on", "legal", "reasoning", ",", "and", "several", "other", "projects", "."], "sentence-detokenized": "A subset called Micro-Planner was implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd Sussman and Winograd 1971 and has been used in Winograd's SHRDLU natural language understanding program, Eugene Charniak's story understanding work, Thorne McCarty's work on legal reasoning, and several other projects.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [21, 22], [22, 29], [30, 33], [34, 45], [46, 48], [49, 55], [56, 59], [60, 67], [67, 68], [69, 75], [76, 84], [85, 88], [89, 94], [95, 103], [104, 111], [112, 115], [116, 124], [125, 129], [130, 133], [134, 137], [138, 142], [143, 147], [148, 150], [151, 159], [159, 161], [162, 168], [169, 176], [177, 185], [186, 199], [200, 207], [207, 208], [209, 215], [216, 224], [224, 226], [227, 232], [233, 246], [247, 251], [251, 252], [253, 259], [260, 267], [267, 269], [270, 274], [275, 277], [278, 283], [284, 293], [293, 294], [295, 298], [299, 306], [307, 312], [313, 321], [321, 322]]}
{"doc_key": "ai-test-264", "ner": [[0, 1, "product"], [9, 10, "product"], [13, 15, "task"], [17, 18, "task"], [20, 22, "task"], [24, 25, "task"], [27, 28, "task"], [32, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[9, 10, 0, 1, "usage", "", true, false], [13, 15, 9, 10, "part-of", "", true, false], [17, 18, 9, 10, "part-of", "", true, false], [20, 22, 9, 10, "part-of", "", true, false], [24, 25, 9, 10, "part-of", "", true, false], [27, 28, 9, 10, "part-of", "", true, false], [32, 34, 9, 10, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Word", "Net", "has", "been", "used", "for", "many", "purposes", "in", "computer", "systems", ",", "including", "word", "sense", "disambiguation", ",", "information", "retrieval", ",", "automatic", "text", "classification", ",", "automatic", "summarization", ",", "automatic", "translation", ",", "and", "even", "automatic", "crossword", "generation", "."], "sentence-detokenized": "WordNet has been used for many purposes in computer systems, including word sense disambiguation, information retrieval, automatic text classification, automatic summarization, automatic translation, and even automatic crossword generation.", "token2charspan": [[0, 4], [4, 7], [8, 11], [12, 16], [17, 21], [22, 25], [26, 30], [31, 39], [40, 42], [43, 51], [52, 59], [59, 60], [61, 70], [71, 75], [76, 81], [82, 96], [96, 97], [98, 109], [110, 119], [119, 120], [121, 130], [131, 135], [136, 150], [150, 151], [152, 161], [162, 175], [175, 176], [177, 186], [187, 198], [198, 199], [200, 203], [204, 208], [209, 218], [219, 228], [229, 239], [239, 240]]}
{"doc_key": "ai-test-265", "ner": [[0, 0, "researcher"], [3, 3, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 3, 3, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Keutzer", "was", "appointed", "IEEE", "Fellow", "in", "1996", "."], "sentence-detokenized": "Keutzer was appointed IEEE Fellow in 1996.", "token2charspan": [[0, 7], [8, 11], [12, 21], [22, 26], [27, 33], [34, 36], [37, 41], [41, 42]]}
{"doc_key": "ai-test-266", "ner": [[7, 9, "algorithm"], [55, 57, "misc"], [66, 67, "algorithm"], [69, 70, "algorithm"], [72, 72, "algorithm"], [76, 77, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[66, 67, 55, 57, "type-of", "", false, false], [69, 70, 55, 57, "type-of", "", false, false], [72, 72, 55, 57, "type-of", "", false, false], [76, 77, 55, 57, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "widely", "used", "type", "of", "composition", "is", "nonlinear", "weighted", "sum", ",", "where", "math", "\\", "textstyle", "f", "(", "x", ")", "=", "K", "\\", "left", "(", "\\", "sum", "_", "i", "w", "_", "i", "g", "_", "i", "(", "x", ")", "\\", "right", ")", "/", "math", ",", "where", "math", "\\", "textstyle", "K", "/", "math", "(", "commonly", "referred", "to", "as", "the", "activation", "function", ")", "is", "a", "predefined", "function", ",", "such", "as", "hyperbolic", "tangent", ",", "sigmoid", "function", ",", "softmax", "function", ",", "or", "rectification", "function", "."], "sentence-detokenized": "A widely used type of composition is nonlinear weighted sum, where math\\ textstyle f (x) = K\\ left (\\ sum _ i w _ i g _ i (x)\\ right) / math, where math\\ textstyle K / math (commonly referred to as the activation function) is a predefined function, such as hyperbolic tangent, sigmoid function, softmax function, or rectification function.", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 18], [19, 21], [22, 33], [34, 36], [37, 46], [47, 55], [56, 59], [59, 60], [61, 66], [67, 71], [71, 72], [73, 82], [83, 84], [85, 86], [86, 87], [87, 88], [89, 90], [91, 92], [92, 93], [94, 98], [99, 100], [100, 101], [102, 105], [106, 107], [108, 109], [110, 111], [112, 113], [114, 115], [116, 117], [118, 119], [120, 121], [122, 123], [123, 124], [124, 125], [125, 126], [127, 132], [132, 133], [134, 135], [136, 140], [140, 141], [142, 147], [148, 152], [152, 153], [154, 163], [164, 165], [166, 167], [168, 172], [173, 174], [174, 182], [183, 191], [192, 194], [195, 197], [198, 201], [202, 212], [213, 221], [221, 222], [223, 225], [226, 227], [228, 238], [239, 247], [247, 248], [249, 253], [254, 256], [257, 267], [268, 275], [275, 276], [277, 284], [285, 293], [293, 294], [295, 302], [303, 311], [311, 312], [313, 315], [316, 329], [330, 338], [338, 339]]}
{"doc_key": "ai-test-267", "ner": [[3, 3, "misc"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "film", "Westworld", ",", "female", "robots", "had", "sex", "with", "men", "as", "part", "of", "an", "imaginary", "holiday", "world", "where", "customers", "pay", "to", "participate", "."], "sentence-detokenized": "In the film Westworld, female robots had sex with men as part of an imaginary holiday world where customers pay to participate.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 21], [21, 22], [23, 29], [30, 36], [37, 40], [41, 44], [45, 49], [50, 53], [54, 56], [57, 61], [62, 64], [65, 67], [68, 77], [78, 85], [86, 91], [92, 97], [98, 107], [108, 111], [112, 114], [115, 126], [126, 127]]}
{"doc_key": "ai-test-268", "ner": [[6, 7, "task"], [21, 26, "task"], [28, 28, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 21, 26, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Typically", ",", "the", "process", "starts", "by", "extracting", "terminology", "and", "concepts", "or", "noun", "phrases", "from", "plain", "text", "using", "linguistic", "processors", "such", "as", "part", "-", "of", "-", "speech", "tagging", "and", "phrase", "classification", "."], "sentence-detokenized": "Typically, the process starts by extracting terminology and concepts or noun phrases from plain text using linguistic processors such as part-of-speech tagging and phrase classification.", "token2charspan": [[0, 9], [9, 10], [11, 14], [15, 22], [23, 29], [30, 32], [33, 43], [44, 55], [56, 59], [60, 68], [69, 71], [72, 76], [77, 84], [85, 89], [90, 95], [96, 100], [101, 106], [107, 117], [118, 128], [129, 133], [134, 136], [137, 141], [141, 142], [142, 144], [144, 145], [145, 151], [152, 159], [160, 163], [164, 170], [171, 185], [185, 186]]}
{"doc_key": "ai-test-269", "ner": [[14, 16, "field"], [19, 20, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[19, 20, 14, 16, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0], "sentence": ["They", "have", "demonstrated", "its", "performance", "on", "a", "number", "of", "problems", "of", "interest", "to", "the", "machine", "learning", "community", ",", "including", "handwriting", "recognition", "."], "sentence-detokenized": "They have demonstrated its performance on a number of problems of interest to the machine learning community, including handwriting recognition.", "token2charspan": [[0, 4], [5, 9], [10, 22], [23, 26], [27, 38], [39, 41], [42, 43], [44, 50], [51, 53], [54, 62], [63, 65], [66, 74], [75, 77], [78, 81], [82, 89], [90, 98], [99, 108], [108, 109], [110, 119], [120, 131], [132, 143], [143, 144]]}
{"doc_key": "ai-test-270", "ner": [[3, 3, "university"], [5, 5, "researcher"], [11, 12, "researcher"], [16, 16, "product"], [20, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 5, 3, 3, "physical", "", false, false], [5, 5, 3, 3, "role", "", false, false], [16, 16, 11, 12, "origin", "", false, false], [16, 16, 20, 21, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["While", "studying", "at", "Stanford", ",", "Scheinman", "received", "a", "fellowship", "sponsored", "by", "George", "Devol", ",", "inventor", "of", "Unimate", ",", "the", "first", "industrial", "robot", "."], "sentence-detokenized": "While studying at Stanford, Scheinman received a fellowship sponsored by George Devol, inventor of Unimate, the first industrial robot.", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 26], [26, 27], [28, 37], [38, 46], [47, 48], [49, 59], [60, 69], [70, 72], [73, 79], [80, 85], [85, 86], [87, 95], [96, 98], [99, 106], [106, 107], [108, 111], [112, 117], [118, 128], [129, 134], [134, 135]]}
{"doc_key": "ai-test-271", "ner": [[5, 6, "task"], [10, 12, "metrics"], [8, 8, "metrics"], [21, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 10, 12, "usage", "", true, false], [8, 8, 10, 12, "named", "", false, false], [21, 23, 10, 12, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Although", "originally", "used", "to", "evaluate", "machine", "translations", ",", "BLEU", "(", "bilingual", "evaluation", "understudy", ")", "has", "also", "been", "successfully", "used", "to", "evaluate", "paraphrase", "generation", "models", "."], "sentence-detokenized": "Although originally used to evaluate machine translations, BLEU (bilingual evaluation understudy) has also been successfully used to evaluate paraphrase generation models.", "token2charspan": [[0, 8], [9, 19], [20, 24], [25, 27], [28, 36], [37, 44], [45, 57], [57, 58], [59, 63], [64, 65], [65, 74], [75, 85], [86, 96], [96, 97], [98, 101], [102, 106], [107, 111], [112, 124], [125, 129], [130, 132], [133, 141], [142, 152], [153, 163], [164, 170], [170, 171]]}
{"doc_key": "ai-test-272", "ner": [[2, 2, "organisation"], [7, 9, "organisation"], [11, 11, "organisation"], [15, 15, "product"], [17, 17, "country"], [19, 19, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 7, 9, "role", "licenses_to", false, false], [2, 2, 11, 11, "role", "licenses_to", false, false], [7, 9, 17, 17, "physical", "", false, false], [11, 11, 19, 19, "physical", "", false, false], [15, 15, 7, 9, "artifact", "produces", false, false], [15, 15, 11, 11, "artifact", "produces", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Subsequently", ",", "Unimation", "licensed", "its", "technology", "to", "Kawasaki", "Heavy", "Industries", "and", "GKN", ",", "which", "manufactured", "Unimate", "in", "Japan", "and", "England", "respectively", "."], "sentence-detokenized": "Subsequently, Unimation licensed its technology to Kawasaki Heavy Industries and GKN, which manufactured Unimate in Japan and England respectively.", "token2charspan": [[0, 12], [12, 13], [14, 23], [24, 32], [33, 36], [37, 47], [48, 50], [51, 59], [60, 65], [66, 76], [77, 80], [81, 84], [84, 85], [86, 91], [92, 104], [105, 112], [113, 115], [116, 121], [122, 125], [126, 133], [134, 146], [146, 147]]}
{"doc_key": "ai-test-273", "ner": [[18, 19, "conference"], [35, 36, "field"], [54, 58, "field"], [60, 60, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[35, 36, 54, 58, "compare", "", false, false], [60, 60, 54, 58, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Much", "of", "the", "confusion", "between", "these", "two", "research", "communities", "(", "which", "often", "have", "separate", "conferences", "and", "journals", ",", "ECML", "PKDD", "being", "a", "major", "exception", ")", "stems", "from", "the", "basic", "assumptions", "they", "work", "with", ":", "in", "machine", "learning", ",", "performance", "is", "usually", "assessed", "in", "terms", "of", "the", "ability", "to", "reproduce", "known", "knowledge", ",", "whereas", "in", "knowledge", "discovery", "and", "data", "mining", "(", "KDD", ")", ",", "the", "key", "task", "is", "the", "discovery", "of", "previously", "unknown", "knowledge", "."], "sentence-detokenized": "Much of the confusion between these two research communities (which often have separate conferences and journals, ECML PKDD being a major exception) stems from the basic assumptions they work with: in machine learning, performance is usually assessed in terms of the ability to reproduce known knowledge, whereas in knowledge discovery and data mining (KDD), the key task is the discovery of previously unknown knowledge.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 29], [30, 35], [36, 39], [40, 48], [49, 60], [61, 62], [62, 67], [68, 73], [74, 78], [79, 87], [88, 99], [100, 103], [104, 112], [112, 113], [114, 118], [119, 123], [124, 129], [130, 131], [132, 137], [138, 147], [147, 148], [149, 154], [155, 159], [160, 163], [164, 169], [170, 181], [182, 186], [187, 191], [192, 196], [196, 197], [198, 200], [201, 208], [209, 217], [217, 218], [219, 230], [231, 233], [234, 241], [242, 250], [251, 253], [254, 259], [260, 262], [263, 266], [267, 274], [275, 277], [278, 287], [288, 293], [294, 303], [303, 304], [305, 312], [313, 315], [316, 325], [326, 335], [336, 339], [340, 344], [345, 351], [352, 353], [353, 356], [356, 357], [357, 358], [359, 362], [363, 366], [367, 371], [372, 374], [375, 378], [379, 388], [389, 391], [392, 402], [403, 410], [411, 420], [420, 421]]}
{"doc_key": "ai-test-274", "ner": [[0, 1, "algorithm"], [9, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 9, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Hidden", "Markov", "models", "are", "the", "basis", "for", "most", "modern", "automatic", "speech", "recognition", "systems", "."], "sentence-detokenized": "Hidden Markov models are the basis for most modern automatic speech recognition systems.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 28], [29, 34], [35, 38], [39, 43], [44, 50], [51, 60], [61, 67], [68, 79], [80, 87], [87, 88]]}
{"doc_key": "ai-test-275", "ner": [[2, 2, "location"], [4, 6, "country"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 4, 6, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": [",", "a", "Bangalore", ",", "India", "-", "based", "company", "specializing", "in", "online", "handwriting", "recognition", "software", "."], "sentence-detokenized": ", a Bangalore, India-based company specializing in online handwriting recognition software.", "token2charspan": [[0, 1], [2, 3], [4, 13], [13, 14], [15, 20], [20, 21], [21, 26], [27, 34], [35, 47], [48, 50], [51, 57], [58, 69], [70, 81], [82, 90], [90, 91]]}
{"doc_key": "ai-test-276", "ner": [[24, 25, "misc"], [48, 48, "metrics"], [50, 54, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[48, 48, 50, 54, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Do", "repeated", "translations", "converge", "to", "a", "single", "expression", "in", "both", "languages", "?", "That", "is", ",", "does", "the", "translation", "method", "exhibit", "stationarity", "or", "produce", "a", "canonical", "form", "?", "Does", "the", "translation", "become", "stationary", "without", "losing", "the", "original", "meaning", "?", "This", "metric", "has", "been", "criticised", "as", "not", "correlating", "well", "with", "BLEU", "(", "BiLingual", "Evaluation", "Understudy", ")", "scores", "."], "sentence-detokenized": "Do repeated translations converge to a single expression in both languages? That is, does the translation method exhibit stationarity or produce a canonical form? Does the translation become stationary without losing the original meaning? This metric has been criticised as not correlating well with BLEU (BiLingual Evaluation Understudy) scores.", "token2charspan": [[0, 2], [3, 11], [12, 24], [25, 33], [34, 36], [37, 38], [39, 45], [46, 56], [57, 59], [60, 64], [65, 74], [74, 75], [76, 80], [81, 83], [83, 84], [85, 89], [90, 93], [94, 105], [106, 112], [113, 120], [121, 133], [134, 136], [137, 144], [145, 146], [147, 156], [157, 161], [161, 162], [163, 167], [168, 171], [172, 183], [184, 190], [191, 201], [202, 209], [210, 216], [217, 220], [221, 229], [230, 237], [237, 238], [239, 243], [244, 250], [251, 254], [255, 259], [260, 270], [271, 273], [274, 277], [278, 289], [290, 294], [295, 299], [300, 304], [305, 306], [306, 315], [316, 326], [327, 337], [337, 338], [339, 345], [345, 346]]}
{"doc_key": "ai-test-277", "ner": [[6, 10, "organisation"], [13, 20, "organisation"], [22, 23, "university"], [26, 26, "university"], [29, 30, "field"], [33, 37, "organisation"], [40, 44, "organisation"], [51, 54, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[13, 20, 22, 23, "part-of", "", false, false], [26, 26, 29, 30, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "is", "a", "Fellow", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", ",", "the", "Center", "for", "Advanced", "Study", "in", "the", "Behavioral", "Sciences", "at", "Stanford", "University", ",", "the", "MIT", "Center", "for", "Cognitive", "Science", ",", "the", "Canadian", "Institute", "for", "Advanced", "Research", ",", "the", "Canadian", "Psychological", "Association", ",", "and", "was", "elected", "a", "Fellow", "of", "the", "Royal", "Society", "of", "Canada", "in", "1998", "."], "sentence-detokenized": "He is a Fellow of the American Association for Artificial Intelligence, the Center for Advanced Study in the Behavioral Sciences at Stanford University, the MIT Center for Cognitive Science, the Canadian Institute for Advanced Research, the Canadian Psychological Association, and was elected a Fellow of the Royal Society of Canada in 1998.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 30], [31, 42], [43, 46], [47, 57], [58, 70], [70, 71], [72, 75], [76, 82], [83, 86], [87, 95], [96, 101], [102, 104], [105, 108], [109, 119], [120, 128], [129, 131], [132, 140], [141, 151], [151, 152], [153, 156], [157, 160], [161, 167], [168, 171], [172, 181], [182, 189], [189, 190], [191, 194], [195, 203], [204, 213], [214, 217], [218, 226], [227, 235], [235, 236], [237, 240], [241, 249], [250, 263], [264, 275], [275, 276], [277, 280], [281, 284], [285, 292], [293, 294], [295, 301], [302, 304], [305, 308], [309, 314], [315, 322], [323, 325], [326, 332], [333, 335], [336, 340], [340, 341]]}
{"doc_key": "ai-test-278", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [17, 18, "misc"], [21, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 17, 18, "part-of", "", false, false], [0, 0, 21, 24, "part-of", "", false, false], [4, 5, 17, 18, "part-of", "", false, false], [4, 5, 21, 24, "part-of", "", false, false], [7, 8, 17, 18, "part-of", "", false, false], [7, 8, 21, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Hinton", "-", "along", "with", "Yoshua", "Bengio", "and", "Yann", "LeCun", "-", "are", "called", "by", "some", "the", "godfathers", "of", "artificial", "intelligence", "and", "the", "godfathers", "of", "deep", "learning", "."], "sentence-detokenized": "Hinton - along with Yoshua Bengio and Yann LeCun - are called by some the godfathers of artificial intelligence and the godfathers of deep learning.", "token2charspan": [[0, 6], [7, 8], [9, 14], [15, 19], [20, 26], [27, 33], [34, 37], [38, 42], [43, 48], [49, 50], [51, 54], [55, 61], [62, 64], [65, 69], [70, 73], [74, 84], [85, 87], [88, 98], [99, 111], [112, 115], [116, 119], [120, 130], [131, 133], [134, 138], [139, 147], [147, 148]]}
{"doc_key": "ai-test-279", "ner": [[6, 6, "product"], [19, 19, "misc"], [21, 22, "misc"], [23, 23, "product"], [27, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 19, 19, "related-to", "", false, false], [6, 6, 21, 22, "related-to", "", false, false], [19, 19, 23, 23, "named", "same", false, false], [27, 28, 23, 23, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "lightweight", "open", "source", "speech", "project", "eSpeak", ",", "which", "has", "its", "own", "approach", "to", "synthesis", ",", "has", "experimented", "with", "Mandarin", "and", "Cantonese", ".", "eSpeak", "was", "used", "by", "Google", "Translate", "from", "May", "2010", "to", "2010", "."], "sentence-detokenized": "The lightweight open source speech project eSpeak, which has its own approach to synthesis, has experimented with Mandarin and Cantonese. eSpeak was used by Google Translate from May 2010 to 2010.", "token2charspan": [[0, 3], [4, 15], [16, 20], [21, 27], [28, 34], [35, 42], [43, 49], [49, 50], [51, 56], [57, 60], [61, 64], [65, 68], [69, 77], [78, 80], [81, 90], [90, 91], [92, 95], [96, 108], [109, 113], [114, 122], [123, 126], [127, 136], [136, 137], [138, 144], [145, 148], [149, 153], [154, 156], [157, 163], [164, 173], [174, 178], [179, 182], [183, 187], [188, 190], [191, 195], [195, 196]]}
{"doc_key": "ai-test-280", "ner": [[5, 7, "product"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 16, 17, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Also", "released", "in", "1982", ",", "Software", "Automatic", "Mouth", "was", "the", "first", "commercial", "full", "-", "software", "voice", "synthesis", "program", "."], "sentence-detokenized": "Also released in 1982, Software Automatic Mouth was the first commercial full-software voice synthesis program.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 21], [21, 22], [23, 31], [32, 41], [42, 47], [48, 51], [52, 55], [56, 61], [62, 72], [73, 77], [77, 78], [78, 86], [87, 92], [93, 102], [103, 110], [110, 111]]}
{"doc_key": "ai-test-281", "ner": [[7, 8, "metrics"], [10, 10, "metrics"], [15, 15, "metrics"], [17, 17, "metrics"], [20, 27, "metrics"], [33, 34, "metrics"], [36, 36, "metrics"], [39, 46, "metrics"], [6, 51, "metrics"], [53, 56, "metrics"], [58, 58, "metrics"], [60, 60, "metrics"], [63, 70, "metrics"], [32, 77, "metrics"], [79, 79, "metrics"], [82, 89, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[10, 10, 7, 8, "named", "", false, false], [15, 15, 7, 8, "named", "", false, false], [17, 17, 7, 8, "named", "", false, false], [20, 27, 7, 8, "named", "", false, false], [36, 36, 33, 34, "named", "", false, false], [39, 46, 33, 34, "named", "", false, false], [53, 56, 6, 51, "named", "", false, false], [58, 58, 6, 51, "named", "", false, false], [60, 60, 6, 51, "named", "", false, false], [63, 70, 6, 51, "named", "", false, false], [79, 79, 32, 77, "named", "", false, false], [82, 89, 32, 77, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["The", "ratios", "in", "the", "column", "are", "TRUE", "Positive", "Rate", "(", "TPR", ",", "also", "known", "as", "Sensitivity", "or", "recall", ")", "(", "TP", "/", "(", "TP", "+", "FN", ")", ")", ",", "with", "the", "complement", "FALSE", "Negative", "Rate", "(", "FNR", ")", "(", "FN", "/", "(", "TP", "+", "FN", ")", ")", ";", "and", "TRUE", "Negative", "Rate", "(", "TNR", ",", "also", "known", "as", "Specificity", ",", "SPC", ")", "(", "TN", "/", "(", "TN", "+", "FP", ")", ")", ",", "with", "the", "complement", "FALSE", "Positive", "Rate", "(", "FPR", ")", "(", "FP", "/", "(", "TN", "+", "FP", ")", ")", "."], "sentence-detokenized": "The ratios in the column are TRUE Positive Rate (TPR, also known as Sensitivity or recall) (TP / (TP + FN)), with the complement FALSE Negative Rate (FNR) (FN / (TP + FN)); and TRUE Negative Rate (TNR, also known as Specificity, SPC) (TN / (TN + FP)), with the complement FALSE Positive Rate (FPR) (FP / (TN + FP)).", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 17], [18, 24], [25, 28], [29, 33], [34, 42], [43, 47], [48, 49], [49, 52], [52, 53], [54, 58], [59, 64], [65, 67], [68, 79], [80, 82], [83, 89], [89, 90], [91, 92], [92, 94], [95, 96], [97, 98], [98, 100], [101, 102], [103, 105], [105, 106], [106, 107], [107, 108], [109, 113], [114, 117], [118, 128], [129, 134], [135, 143], [144, 148], [149, 150], [150, 153], [153, 154], [155, 156], [156, 158], [159, 160], [161, 162], [162, 164], [165, 166], [167, 169], [169, 170], [170, 171], [171, 172], [173, 176], [177, 181], [182, 190], [191, 195], [196, 197], [197, 200], [200, 201], [202, 206], [207, 212], [213, 215], [216, 227], [227, 228], [229, 232], [232, 233], [234, 235], [235, 237], [238, 239], [240, 241], [241, 243], [244, 245], [246, 248], [248, 249], [249, 250], [250, 251], [252, 256], [257, 260], [261, 271], [272, 277], [278, 286], [287, 291], [292, 293], [293, 296], [296, 297], [298, 299], [299, 301], [302, 303], [304, 305], [305, 307], [308, 309], [310, 312], [312, 313], [313, 314], [314, 315]]}
{"doc_key": "ai-test-282", "ner": [[0, 0, "person"], [2, 3, "person"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 16, 16, "role", "working_with", false, false], [2, 3, 16, 16, "role", "working_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Edsinger", "and", "Weber", "have", "also", "collaborated", "on", "many", "other", "robots", ",", "and", "their", "experience", "working", "with", "Kismet"], "sentence-detokenized": "Edsinger and Weber have also collaborated on many other robots, and their experience working with Kismet", "token2charspan": [[0, 8], [9, 12], [13, 18], [19, 23], [24, 28], [29, 41], [42, 44], [45, 49], [50, 55], [56, 62], [62, 63], [64, 67], [68, 73], [74, 84], [85, 92], [93, 97], [98, 104]]}
{"doc_key": "ai-test-283", "ner": [[0, 0, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 11, 11, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["R", "functionality", "is", "accessible", "from", "several", "scripting", "languages", ",", "such", "as", "Python", ",", "are", "also", "available", "."], "sentence-detokenized": "R functionality is accessible from several scripting languages, such as Python, are also available.", "token2charspan": [[0, 1], [2, 15], [16, 18], [19, 29], [30, 34], [35, 42], [43, 52], [53, 62], [62, 63], [64, 68], [69, 71], [72, 78], [78, 79], [80, 83], [84, 88], [89, 98], [98, 99]]}
{"doc_key": "ai-test-284", "ner": [[0, 0, "programlang"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 13, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VAL", "was", "one", "of", "the", "first", "robot", "languages", "and", "was", "used", "in", "Unimate", "robots", "."], "sentence-detokenized": "VAL was one of the first robot languages and was used in Unimate robots.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 18], [19, 24], [25, 30], [31, 40], [41, 44], [45, 48], [49, 53], [54, 56], [57, 64], [65, 71], [71, 72]]}
{"doc_key": "ai-test-285", "ner": [[13, 22, "conference"], [20, 20, "conference"], [24, 24, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 22, 24, 24, "physical", "", false, false], [20, 20, 13, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["They", "presented", "their", "database", "for", "the", "first", "time", "as", "a", "poster", "at", "the", "2009", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "Conference", "in", "Florida", "."], "sentence-detokenized": "They presented their database for the first time as a poster at the 2009 Computer Vision and Pattern Recognition (CVPR) Conference in Florida.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 29], [30, 33], [34, 37], [38, 43], [44, 48], [49, 51], [52, 53], [54, 60], [61, 63], [64, 67], [68, 72], [73, 81], [82, 88], [89, 92], [93, 100], [101, 112], [113, 114], [114, 118], [118, 119], [120, 130], [131, 133], [134, 141], [141, 142]]}
{"doc_key": "ai-test-286", "ner": [[0, 1, "misc"], [12, 12, "task"], [11, 15, "field"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 12, 0, 1, "type-of", "", false, false], [11, 15, 0, 1, "type-of", "", false, false], [17, 18, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Classification", "tasks", "where", "no", "labels", "are", "provided", "are", "referred", "to", "as", "unsupervised", "classification", ",", "unsupervised", "learning", ",", "cluster", "analysis", "."], "sentence-detokenized": "Classification tasks where no labels are provided are referred to as unsupervised classification, unsupervised learning, cluster analysis.", "token2charspan": [[0, 14], [15, 20], [21, 26], [27, 29], [30, 36], [37, 40], [41, 49], [50, 53], [54, 62], [63, 65], [66, 68], [69, 81], [82, 96], [96, 97], [98, 110], [111, 119], [119, 120], [121, 128], [129, 137], [137, 138]]}
{"doc_key": "ai-test-287", "ner": [[2, 3, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "must", "recognise", "objects", ",", "recognise", "and", "locate", "people", "and", "continue", "to", "recognise", "emotions", "."], "sentence-detokenized": "It must recognise objects, recognise and locate people and continue to recognise emotions.", "token2charspan": [[0, 2], [3, 7], [8, 17], [18, 25], [25, 26], [27, 36], [37, 40], [41, 47], [48, 54], [55, 58], [59, 67], [68, 70], [71, 80], [81, 89], [89, 90]]}
{"doc_key": "ai-test-288", "ner": [[6, 6, "misc"], [8, 8, "misc"], [10, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "process", "is", "complex", "and", "contains", "encoding", "and", "recall", "or", "retrieval", "."], "sentence-detokenized": "The process is complex and contains encoding and recall or retrieval.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 26], [27, 35], [36, 44], [45, 48], [49, 55], [56, 58], [59, 68], [68, 69]]}
{"doc_key": "ai-test-289", "ner": [[7, 7, "product"], [14, 16, "product"], [34, 34, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 14, 16, "named", "", false, false], [7, 7, 34, 34, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Also", "known", "as", "parallel", "robots", "or", "generalised", "Stewart", "platforms", "(", "in", "the", "case", "of", "the", "Stewart", "platform", ",", "the", "actuators", "are", "paired", "on", "both", "the", "base", "and", "the", "platform", ")", ",", "these", "systems", "are", "articulated", "robots", "that", "use", "similar", "mechanisms", "to", "move", "either", "the", "base", "robot", "or", "one", "or", "more", "manipulator", "arms", "."], "sentence-detokenized": "Also known as parallel robots or generalised Stewart platforms (in the case of the Stewart platform, the actuators are paired on both the base and the platform), these systems are articulated robots that use similar mechanisms to move either the base robot or one or more manipulator arms.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 29], [30, 32], [33, 44], [45, 52], [53, 62], [63, 64], [64, 66], [67, 70], [71, 75], [76, 78], [79, 82], [83, 90], [91, 99], [99, 100], [101, 104], [105, 114], [115, 118], [119, 125], [126, 128], [129, 133], [134, 137], [138, 142], [143, 146], [147, 150], [151, 159], [159, 160], [160, 161], [162, 167], [168, 175], [176, 179], [180, 191], [192, 198], [199, 203], [204, 207], [208, 215], [216, 226], [227, 229], [230, 234], [235, 241], [242, 245], [246, 250], [251, 256], [257, 259], [260, 263], [264, 266], [267, 271], [272, 283], [284, 288], [288, 289]]}
{"doc_key": "ai-test-290", "ner": [[0, 0, "field"], [4, 5, "field"], [1, 13, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 5, "part-of", "subfield", false, false], [0, 0, 1, 13, "compare", "", false, false], [1, 13, 18, 19, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Computer", "vision", "as", "a", "systems", "engineering", "discipline", "can", "be", "considered", "distinct", "from", "computer", "vision", ",", "a", "form", "of", "computer", "science", "."], "sentence-detokenized": "Computer vision as a systems engineering discipline can be considered distinct from computer vision, a form of computer science.", "token2charspan": [[0, 8], [9, 15], [16, 18], [19, 20], [21, 28], [29, 40], [41, 51], [52, 55], [56, 58], [59, 69], [70, 78], [79, 83], [84, 92], [93, 99], [99, 100], [101, 102], [103, 107], [108, 110], [111, 119], [120, 127], [127, 128]]}
{"doc_key": "ai-test-291", "ner": [[1, 2, "algorithm"], [8, 10, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 8, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "LSTM", "gate", "activation", "function", "is", "often", "the", "logistic", "sigmoid", "function", "."], "sentence-detokenized": "The LSTM gate activation function is often the logistic sigmoid function.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 24], [25, 33], [34, 36], [37, 42], [43, 46], [47, 55], [56, 63], [64, 72], [72, 73]]}
{"doc_key": "ai-test-292", "ner": [[5, 6, "metrics"], [18, 26, "metrics"], [24, 30, "metrics"], [33, 35, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 18, 26, "named", "", false, false], [5, 6, 33, 35, "named", "", false, false], [24, 30, 18, 26, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "other", "words", ",", "the", "sample", "mean", "is", "the", "efficient", "(", "necessarily", "unique", ")", "estimator", "and", "therefore", "also", "the", "minimum", "variance", "no", "deviation", "(", "MVUE", ")", "estimator", ",", "in", "addition", "to", "being", "the", "maximum", "likelihood", "estimator", "."], "sentence-detokenized": "In other words, the sample mean is the efficient (necessarily unique) estimator and therefore also the minimum variance no deviation (MVUE) estimator, in addition to being the maximum likelihood estimator.", "token2charspan": [[0, 2], [3, 8], [9, 14], [14, 15], [16, 19], [20, 26], [27, 31], [32, 34], [35, 38], [39, 48], [49, 50], [50, 61], [62, 68], [68, 69], [70, 79], [80, 83], [84, 93], [94, 98], [99, 102], [103, 110], [111, 119], [120, 122], [123, 132], [133, 134], [134, 138], [138, 139], [140, 149], [149, 150], [151, 153], [154, 162], [163, 165], [166, 171], [172, 175], [176, 183], [184, 194], [195, 204], [204, 205]]}
{"doc_key": "ai-test-293", "ner": [[2, 3, "academicjournal"], [6, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [22, 22, "product"], [25, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 22, 22, "topic", "", false, false], [2, 3, 25, 26, "topic", "", false, false], [6, 8, 2, 3, "role", "", false, false], [10, 11, 2, 3, "role", "", false, false], [13, 14, 2, 3, "role", "", false, false], [22, 22, 25, 26, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "2001", "Scientific", "American", "article", "by", "Berners", "-", "Lee", ",", "James", "Hendler", "and", "Ora", "Lassila", "described", "an", "expected", "evolution", "of", "the", "existing", "Web", "to", "a", "semantic", "Web", "."], "sentence-detokenized": "The 2001 Scientific American article by Berners-Lee, James Hendler and Ora Lassila described an expected evolution of the existing Web to a semantic Web.", "token2charspan": [[0, 3], [4, 8], [9, 19], [20, 28], [29, 36], [37, 39], [40, 47], [47, 48], [48, 51], [51, 52], [53, 58], [59, 66], [67, 70], [71, 74], [75, 82], [83, 92], [93, 95], [96, 104], [105, 114], [115, 117], [118, 121], [122, 130], [131, 134], [135, 137], [138, 139], [140, 148], [149, 152], [152, 153]]}
{"doc_key": "ai-test-294", "ner": [[0, 1, "misc"], [14, 15, "person"], [17, 17, "person"], [27, 27, "person"], [38, 38, "person"], [44, 45, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 15, 0, 1, "role", "actor_in_work", false, false], [17, 17, 14, 15, "named", "", false, false], [17, 17, 14, 15, "origin", "", false, false], [27, 27, 17, 17, "part-of", "", false, false], [44, 45, 17, 17, "role", "auditioned_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Blade", "Runner", "used", "a", "number", "of", "lesser", "-", "known", "actors", "at", "the", "time", ":", "Sean", "Young", "plays", "Rachael", ",", "an", "experimental", "replicant", "implanted", "with", "the", "memories", "of", "Tyrell", "'s", "niece", ",", "making", "her", "believe", "she", "is", "human", ";", "Sammon", ",", "pp.", "92", "-", "93", "Nina", "Axelrod", "auditioned", "for", "the", "role", "."], "sentence-detokenized": "Blade Runner used a number of lesser-known actors at the time: Sean Young plays Rachael, an experimental replicant implanted with the memories of Tyrell's niece, making her believe she is human; Sammon, pp. 92-93 Nina Axelrod auditioned for the role.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 19], [20, 26], [27, 29], [30, 36], [36, 37], [37, 42], [43, 49], [50, 52], [53, 56], [57, 61], [61, 62], [63, 67], [68, 73], [74, 79], [80, 87], [87, 88], [89, 91], [92, 104], [105, 114], [115, 124], [125, 129], [130, 133], [134, 142], [143, 145], [146, 152], [152, 154], [155, 160], [160, 161], [162, 168], [169, 172], [173, 180], [181, 184], [185, 187], [188, 193], [193, 194], [195, 201], [201, 202], [203, 206], [207, 209], [209, 210], [210, 212], [213, 217], [218, 225], [226, 236], [237, 240], [241, 244], [245, 249], [249, 250]]}
{"doc_key": "ai-test-295", "ner": [[0, 1, "researcher"], [3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [13, 15, "university"], [24, 26, "product"], [28, 29, "product"], [44, 44, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 13, 15, "physical", "", false, false], [3, 4, 13, 15, "physical", "", false, false], [6, 7, 13, 15, "physical", "", false, false], [9, 10, 13, 15, "physical", "", false, false], [13, 15, 44, 44, "physical", "", true, false], [24, 26, 13, 15, "temporal", "", false, false], [28, 29, 13, 15, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Gerry", "Sussman", ",", "Eugene", "Charniak", ",", "Seymour", "Papert", "and", "Terry", "Winograd", "visited", "the", "University", "of", "Edinburgh", "in", "1971", ",", "spreading", "the", "news", "about", "the", "Micro", "-", "Planner", "and", "SHRDLU", "and", "questioning", "the", "approach", "to", "uniform", "proof", "solving", "that", "had", "been", "the", "mainstay", "of", "the", "Edinburgh", "logicians", "."], "sentence-detokenized": "Gerry Sussman, Eugene Charniak, Seymour Papert and Terry Winograd visited the University of Edinburgh in 1971, spreading the news about the Micro-Planner and SHRDLU and questioning the approach to uniform proof solving that had been the mainstay of the Edinburgh logicians.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 21], [22, 30], [30, 31], [32, 39], [40, 46], [47, 50], [51, 56], [57, 65], [66, 73], [74, 77], [78, 88], [89, 91], [92, 101], [102, 104], [105, 109], [109, 110], [111, 120], [121, 124], [125, 129], [130, 135], [136, 139], [140, 145], [145, 146], [146, 153], [154, 157], [158, 164], [165, 168], [169, 180], [181, 184], [185, 193], [194, 196], [197, 204], [205, 210], [211, 218], [219, 223], [224, 227], [228, 232], [233, 236], [237, 245], [246, 248], [249, 252], [253, 262], [263, 272], [272, 273]]}
{"doc_key": "ai-test-296", "ner": [[0, 0, "researcher"], [7, 7, "field"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 11, 12, "role", "inspires", false, false], [0, 0, 14, 15, "role", "inspires", false, false], [0, 0, 17, 18, "role", "inspires", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Walter", "'s", "work", "inspired", "subsequent", "generations", "of", "robotics", "researchers", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "Walter's work inspired subsequent generations of robotics researchers such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 6], [6, 8], [9, 13], [14, 22], [23, 33], [34, 45], [46, 48], [49, 57], [58, 69], [70, 74], [75, 77], [78, 84], [85, 91], [91, 92], [93, 97], [98, 105], [106, 109], [110, 114], [115, 121], [121, 122]]}
{"doc_key": "ai-test-297", "ner": [[7, 7, "algorithm"], [9, 10, "researcher"], [16, 22, "event"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 9, 10, "origin", "", false, false], [7, 7, 16, 22, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Subsequently", ",", "a", "similar", "GPU", "-", "based", "CNN", "by", "Alex", "Krizhevsky", "et", "al", ".", "won", "the", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "2012", "."], "sentence-detokenized": "Subsequently, a similar GPU-based CNN by Alex Krizhevsky et al. won the ImageNet Large Scale Visual Recognition Challenge 2012.", "token2charspan": [[0, 12], [12, 13], [14, 15], [16, 23], [24, 27], [27, 28], [28, 33], [34, 37], [38, 40], [41, 45], [46, 56], [57, 59], [60, 62], [62, 63], [64, 67], [68, 71], [72, 80], [81, 86], [87, 92], [93, 99], [100, 111], [112, 121], [122, 126], [126, 127]]}
{"doc_key": "ai-test-298", "ner": [[2, 3, "misc"], [8, 9, "metrics"], [11, 12, "metrics"], [16, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 2, 3, "type-of", "", false, false], [11, 12, 2, 3, "type-of", "", false, false], [11, 12, 16, 18, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Commonly", "used", "loss", "functions", "for", "probabilistic", "classification", "include", "log", "loss", "and", "Brier", "score", "between", "predicted", "and", "TRUE", "probability", "distributions", "."], "sentence-detokenized": "Commonly used loss functions for probabilistic classification include log loss and Brier score between predicted and TRUE probability distributions.", "token2charspan": [[0, 8], [9, 13], [14, 18], [19, 28], [29, 32], [33, 46], [47, 61], [62, 69], [70, 73], [74, 78], [79, 82], [83, 88], [89, 94], [95, 102], [103, 112], [113, 116], [117, 121], [122, 133], [134, 147], [147, 148]]}
{"doc_key": "ai-test-299", "ner": [[4, 4, "organisation"], [9, 9, "field"], [13, 13, "organisation"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 9, 9, "general-affiliation", "field_of_study", false, false], [4, 4, 16, 17, "part-of", "", false, false], [13, 13, 4, 4, "role", "admits_E2_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "May", "2016", ",", "NtechLab", "was", "admitted", "to", "official", "biometric", "technology", "testing", "by", "NIST", "among", "three", "Russian", "companies", "."], "sentence-detokenized": "In May 2016, NtechLab was admitted to official biometric technology testing by NIST among three Russian companies.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [13, 21], [22, 25], [26, 34], [35, 37], [38, 46], [47, 56], [57, 67], [68, 75], [76, 78], [79, 83], [84, 89], [90, 95], [96, 103], [104, 113], [113, 114]]}
{"doc_key": "ai-test-300", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "floating", "point", "numbers", "have", "only", "a", "certain", "mathematical", "precision", "."], "sentence-detokenized": "However, floating point numbers have only a certain mathematical precision.", "token2charspan": [[0, 7], [7, 8], [9, 17], [18, 23], [24, 31], [32, 36], [37, 41], [42, 43], [44, 51], [52, 64], [65, 74], [74, 75]]}
{"doc_key": "ai-test-301", "ner": [[4, 4, "organisation"], [10, 18, "conference"], [16, 16, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 10, 18, "role", "contributes_to", false, false], [16, 16, 10, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["During", "2015", ",", "many", "SenseTime", "papers", "were", "accepted", "at", "the", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "Conference", "."], "sentence-detokenized": "During 2015, many SenseTime papers were accepted at the Computer Vision and Pattern Recognition (CVPR) Conference.", "token2charspan": [[0, 6], [7, 11], [11, 12], [13, 17], [18, 27], [28, 34], [35, 39], [40, 48], [49, 51], [52, 55], [56, 64], [65, 71], [72, 75], [76, 83], [84, 95], [96, 97], [97, 101], [101, 102], [103, 113], [113, 114]]}
{"doc_key": "ai-test-302", "ner": [[5, 7, "task"], [9, 9, "task"], [12, 13, "task"], [15, 18, "task"], [28, 34, "conference"], [42, 44, "misc"], [46, 47, "conference"], [23, 65, "misc"], [21, 67, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 6, 7, 8, 9, 10], "relations": [[9, 9, 5, 7, "named", "", false, false], [15, 18, 12, 13, "named", "", false, false], [42, 44, 46, 47, "temporal", "", false, false], [23, 65, 21, 67, "temporal", "", false, false]], "relations_mapping_to_source": [1, 3, 5, 6], "sentence": ["He", "co-developed", "optimal", "algorithms", "for", "Structure", "From", "Motion", "(", "SFM", ",", "or", "Visual", "SLAM", ",", "simultaneous", "localization", "and", "mapping", ",", "in", "Robotics", ";", "Best", "Paper", "Award", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "1998", ")", ",", "characterized", "its", "ambiguities", "(", "David", "Marr", "Award", "at", "ICCV", "1999", ")", ",", "also", "characterized", "the", "identifiability", "and", "observability", "of", "visual", "-", "inertial", "sensor", "fusion", "(", "Best", "Paper", "Award", "at", "Robotics", "2015", ")", "."], "sentence-detokenized": "He co-developed optimal algorithms for Structure From Motion (SFM, or Visual SLAM, simultaneous localization and mapping, in Robotics; Best Paper Award at the Conference on Computer Vision and Pattern Recognition 1998), characterized its ambiguities (David Marr Award at ICCV 1999), also characterized the identifiability and observability of visual-inertial sensor fusion (Best Paper Award at Robotics 2015).", "token2charspan": [[0, 2], [3, 15], [16, 23], [24, 34], [35, 38], [39, 48], [49, 53], [54, 60], [61, 62], [62, 65], [65, 66], [67, 69], [70, 76], [77, 81], [81, 82], [83, 95], [96, 108], [109, 112], [113, 120], [120, 121], [122, 124], [125, 133], [133, 134], [135, 139], [140, 145], [146, 151], [152, 154], [155, 158], [159, 169], [170, 172], [173, 181], [182, 188], [189, 192], [193, 200], [201, 212], [213, 217], [217, 218], [218, 219], [220, 233], [234, 237], [238, 249], [250, 251], [251, 256], [257, 261], [262, 267], [268, 270], [271, 275], [276, 280], [280, 281], [281, 282], [283, 287], [288, 301], [302, 305], [306, 321], [322, 325], [326, 339], [340, 342], [343, 349], [349, 350], [350, 358], [359, 365], [366, 372], [373, 374], [374, 378], [379, 384], [385, 390], [391, 393], [394, 402], [403, 407], [407, 408], [408, 409]]}
{"doc_key": "ai-test-303", "ner": [[0, 2, "researcher"], [3, 3, "organisation"], [5, 5, "organisation"], [7, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Stephen", "H.", "Muggleton", "FBCS", ",", "FIET", ",", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ","], "sentence-detokenized": "Stephen H. Muggleton FBCS, FIET, Association for the Advancement of Artificial Intelligence,", "token2charspan": [[0, 7], [8, 10], [11, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 44], [45, 48], [49, 52], [53, 64], [65, 67], [68, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-304", "ner": [[0, 1, "task"], [7, 8, "field"], [10, 10, "field"], [11, 14, "field"], [21, 22, "task"], [24, 24, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 7, 8, "part-of", "task_part_of_field", false, false], [0, 1, 10, 10, "part-of", "task_part_of_field", false, false], [0, 1, 11, 14, "part-of", "task_part_of_field", false, false], [0, 1, 21, 22, "part-of", "", false, false], [0, 1, 24, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Edge", "detection", "is", "a", "fundamental", "tool", "in", "image", "processing", ",", "machine", "vision", "and", "computer", "vision", ",", "especially", "in", "the", "area", "of", "feature", "detection", "and", "extraction", "."], "sentence-detokenized": "Edge detection is a fundamental tool in image processing, machine vision and computer vision, especially in the area of feature detection and extraction.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 19], [20, 31], [32, 36], [37, 39], [40, 45], [46, 56], [56, 57], [58, 65], [66, 72], [73, 76], [77, 85], [86, 92], [92, 93], [94, 104], [105, 107], [108, 111], [112, 116], [117, 119], [120, 127], [128, 137], [138, 141], [142, 152], [152, 153]]}
{"doc_key": "ai-test-305", "ner": [[10, 11, "misc"], [28, 31, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "example", "of", "this", "would", "be", "a", "variable", "such", "as", "outdoor", "temperature", "(", "mathtemp", "/", "math", ")", ",", "which", "in", "a", "given", "application", "can", "be", "recorded", "to", "several", "decimal", "places", "of", "accuracy", "(", "depending", "on", "the", "sensing", "device", ")", "."], "sentence-detokenized": "An example of this would be a variable such as outdoor temperature (mathtemp / math), which in a given application can be recorded to several decimal places of accuracy (depending on the sensing device).", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 18], [19, 24], [25, 27], [28, 29], [30, 38], [39, 43], [44, 46], [47, 54], [55, 66], [67, 68], [68, 76], [77, 78], [79, 83], [83, 84], [84, 85], [86, 91], [92, 94], [95, 96], [97, 102], [103, 114], [115, 118], [119, 121], [122, 130], [131, 133], [134, 141], [142, 149], [150, 156], [157, 159], [160, 168], [169, 170], [170, 179], [180, 182], [183, 186], [187, 194], [195, 201], [201, 202], [202, 203]]}
{"doc_key": "ai-test-306", "ner": [[4, 5, "person"], [7, 8, "person"], [10, 15, "person"], [19, 20, "person"], [22, 22, "misc"], [26, 26, "misc"], [28, 29, "person"], [31, 32, "organisation"], [33, 35, "person"], [37, 37, "organisation"], [39, 40, "person"], [43, 43, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[28, 29, 22, 22, "part-of", "", false, false], [28, 29, 26, 26, "role", "", false, false], [33, 35, 31, 32, "role", "", false, false], [39, 40, 37, 37, "role", "youtuber", false, false], [43, 43, 39, 40, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "returning", "judges", "include", "Fon", "Davis", ",", "Jessica", "Chobot", "and", "Leland", "Melvin", ",", "as", "well", "as", "celebrity", "guests", "actor", "Clark", "Gregg", ",", "MythBusters", "host", "and", "former", "Battlebots", "builder", "Adam", "Savage", ",", "American", "football", "player", "Vernon", "Davis", "and", "YouTube", "star", "Michael", "Stevens", ",", "aka", "Vsauce", "."], "sentence-detokenized": "The returning judges include Fon Davis, Jessica Chobot and Leland Melvin, as well as celebrity guests actor Clark Gregg, MythBusters host and former Battlebots builder Adam Savage, American football player Vernon Davis and YouTube star Michael Stevens, aka Vsauce.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 28], [29, 32], [33, 38], [38, 39], [40, 47], [48, 54], [55, 58], [59, 65], [66, 72], [72, 73], [74, 76], [77, 81], [82, 84], [85, 94], [95, 101], [102, 107], [108, 113], [114, 119], [119, 120], [121, 132], [133, 137], [138, 141], [142, 148], [149, 159], [160, 167], [168, 172], [173, 179], [179, 180], [181, 189], [190, 198], [199, 205], [206, 212], [213, 218], [219, 222], [223, 230], [231, 235], [236, 243], [244, 251], [251, 252], [253, 256], [257, 263], [263, 264]]}
{"doc_key": "ai-test-307", "ner": [[11, 12, "algorithm"], [15, 17, "algorithm"], [13, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 13, 21, "part-of", "", false, false], [15, 17, 13, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["But", "these", "methods", "have", "never", "been", "able", "to", "beat", "the", "non-uniform", "Gaussian", "mixture", "model", "/", "hidden", "Markov", "model", "(", "GMM", "-", "HMM", ")", "technology", "based", "on", "discriminatively", "trained", "generative", "speech", "models", "."], "sentence-detokenized": "But these methods have never been able to beat the non-uniform Gaussian mixture model/hidden Markov model (GMM-HMM) technology based on discriminatively trained generative speech models.", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 22], [23, 28], [29, 33], [34, 38], [39, 41], [42, 46], [47, 50], [51, 62], [63, 71], [72, 79], [80, 85], [85, 86], [86, 92], [93, 99], [100, 105], [106, 107], [107, 110], [110, 111], [111, 114], [114, 115], [116, 126], [127, 132], [133, 135], [136, 152], [153, 160], [161, 171], [172, 178], [179, 185], [185, 186]]}
{"doc_key": "ai-test-308", "ner": [[4, 4, "product"], [6, 7, "programlang"], [9, 9, "programlang"], [11, 11, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Software", "packages", "such", "as", "MATLAB", ",", "GNU", "Octave", ",", "Scilab", "and", "SciPy", "offer", "convenient", "ways", "to", "apply", "these", "different", "methods", "."], "sentence-detokenized": "Software packages such as MATLAB, GNU Octave, Scilab and SciPy offer convenient ways to apply these different methods.", "token2charspan": [[0, 8], [9, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 37], [38, 44], [44, 45], [46, 52], [53, 56], [57, 62], [63, 68], [69, 79], [80, 84], [85, 87], [88, 93], [94, 99], [100, 109], [110, 117], [117, 118]]}
{"doc_key": "ai-test-309", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [8, 9, "task"], [16, 18, "researcher"], [19, 20, "university"], [22, 23, "researcher"], [25, 28, "organisation"], [30, 30, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 8, 9, "related-to", "", false, false], [0, 2, 16, 18, "origin", "", false, false], [0, 2, 22, 23, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [16, 18, 19, 20, "physical", "", false, false], [16, 18, 19, 20, "role", "", false, false], [22, 23, 25, 28, "physical", "", false, false], [22, 23, 25, 28, "role", "", false, false], [30, 30, 25, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Linear", "Predictive", "Coding", "(", "LPC", ")", ",", "a", "speech", "processing", "algorithm", ",", "was", "first", "proposed", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", "."], "sentence-detokenized": "Linear Predictive Coding (LPC), a speech processing algorithm, was first proposed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [30, 31], [32, 33], [34, 40], [41, 51], [52, 61], [61, 62], [63, 66], [67, 72], [73, 81], [82, 84], [85, 93], [94, 101], [102, 104], [105, 111], [112, 122], [123, 126], [127, 132], [133, 138], [139, 141], [142, 148], [149, 158], [159, 162], [163, 172], [173, 174], [174, 177], [177, 178], [179, 181], [182, 186], [186, 187]]}
{"doc_key": "ai-test-310", "ner": [[20, 27, "conference"], [29, 29, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[29, 29, 20, 27, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2006", ",", "on", "the", "occasion", "of", "the", "25th", "anniversary", "of", "the", "algorithm", ",", "a", "workshop", "was", "held", "at", "the", "International", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "to", "summarize", "the", "latest", "contributions", "and", "variations", "of", "the", "original", "algorithm", ",", "mainly", "to", "improve", "algorithm", "speed", ",", "robustness", "and", "accuracy", "of", "the", "estimated", "solution", ",", "and", "to", "reduce", "dependence", "on", "user", "-", "defined", "constants", "."], "sentence-detokenized": "In 2006, on the occasion of the 25th anniversary of the algorithm, a workshop was held at the International Conference on Computer Vision and Pattern Recognition (CVPR) to summarize the latest contributions and variations of the original algorithm, mainly to improve algorithm speed, robustness and accuracy of the estimated solution, and to reduce dependence on user-defined constants.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 24], [25, 27], [28, 31], [32, 36], [37, 48], [49, 51], [52, 55], [56, 65], [65, 66], [67, 68], [69, 77], [78, 81], [82, 86], [87, 89], [90, 93], [94, 107], [108, 118], [119, 121], [122, 130], [131, 137], [138, 141], [142, 149], [150, 161], [162, 163], [163, 167], [167, 168], [169, 171], [172, 181], [182, 185], [186, 192], [193, 206], [207, 210], [211, 221], [222, 224], [225, 228], [229, 237], [238, 247], [247, 248], [249, 255], [256, 258], [259, 266], [267, 276], [277, 282], [282, 283], [284, 294], [295, 298], [299, 307], [308, 310], [311, 314], [315, 324], [325, 333], [333, 334], [335, 338], [339, 341], [342, 348], [349, 359], [360, 362], [363, 367], [367, 368], [368, 375], [376, 385], [385, 386]]}
{"doc_key": "ai-test-311", "ner": [[4, 6, "university"], [9, 12, "organisation"], [14, 16, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Members", "have", "attended", "the", "University", "of", "Debrecen", ",", "the", "Hungarian", "Academy", "of", "Sciences", ",", "E\u00f6tv\u00f6s", "Lor\u00e1nd", "University", ",", "etc", "."], "sentence-detokenized": "Members have attended the University of Debrecen, the Hungarian Academy of Sciences, E\u00f6tv\u00f6s Lor\u00e1nd University, etc.", "token2charspan": [[0, 7], [8, 12], [13, 21], [22, 25], [26, 36], [37, 39], [40, 48], [48, 49], [50, 53], [54, 63], [64, 71], [72, 74], [75, 83], [83, 84], [85, 91], [92, 98], [99, 109], [109, 110], [111, 114], [114, 115]]}
{"doc_key": "ai-test-312", "ner": [[2, 2, "algorithm"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 16, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["To", "extend", "SVM", "to", "cases", "where", "the", "data", "is", "not", "linearly", "separable", ",", "we", "introduce", "the", "loss", "function", ","], "sentence-detokenized": "To extend SVM to cases where the data is not linearly separable, we introduce the loss function,", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 16], [17, 22], [23, 28], [29, 32], [33, 37], [38, 40], [41, 44], [45, 53], [54, 63], [63, 64], [65, 67], [68, 77], [78, 81], [82, 86], [87, 95], [95, 96]]}
{"doc_key": "ai-test-313", "ner": [[0, 0, "programlang"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 10, 11, "origin", "", false, false], [0, 0, 13, 14, "origin", "", false, false], [0, 0, 16, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Logo", "is", "an", "educational", "programming", "language", "designed", "in", "1967", "by", "Wally", "Feurzeig", ",", "Seymour", "Papert", "and", "Cynthia", "Solomon", "."], "sentence-detokenized": "Logo is an educational programming language designed in 1967 by Wally Feurzeig, Seymour Papert and Cynthia Solomon.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 34], [35, 43], [44, 52], [53, 55], [56, 60], [61, 63], [64, 69], [70, 78], [78, 79], [80, 87], [88, 94], [95, 98], [99, 106], [107, 114], [114, 115]]}
{"doc_key": "ai-test-314", "ner": [[0, 3, "organisation"], [8, 12, "organisation"], [14, 17, "location"], [19, 19, "location"], [21, 21, "location"], [33, 36, "product"], [42, 49, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 8, 12, "role", "works_for", false, false], [8, 12, 14, 17, "physical", "", false, false], [14, 17, 19, 19, "physical", "", false, false], [19, 19, 21, 21, "physical", "", false, false], [33, 36, 0, 3, "origin", "", false, false], [42, 49, 33, 36, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "Eyring", "Research", "Institute", "was", "instrumental", "to", "the", "U.S.", "Air", "Force", "Missile", "Directorate", "at", "Hill", "Air", "Force", "Base", "near", "Ogden", ",", "Utah", ",", "in", "producing", ",", "in", "the", "utmost", "military", "secrecy", ",", "the", "Intelligent", "Systems", "Technology", "Software", "that", "formed", "the", "basis", "of", "Reagan", "'s", "later", "-", "named", "Star", "Wars", "program", "."], "sentence-detokenized": "The Eyring Research Institute was instrumental to the U.S. Air Force Missile Directorate at Hill Air Force Base near Ogden, Utah, in producing, in the utmost military secrecy, the Intelligent Systems Technology Software that formed the basis of Reagan's later-named Star Wars program.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 29], [30, 33], [34, 46], [47, 49], [50, 53], [54, 58], [59, 62], [63, 68], [69, 76], [77, 88], [89, 91], [92, 96], [97, 100], [101, 106], [107, 111], [112, 116], [117, 122], [122, 123], [124, 128], [128, 129], [130, 132], [133, 142], [142, 143], [144, 146], [147, 150], [151, 157], [158, 166], [167, 174], [174, 175], [176, 179], [180, 191], [192, 199], [200, 210], [211, 219], [220, 224], [225, 231], [232, 235], [236, 241], [242, 244], [245, 251], [251, 253], [254, 259], [259, 260], [260, 265], [266, 270], [271, 275], [276, 283], [283, 284]]}
{"doc_key": "ai-test-315", "ner": [[11, 14, "field"], [22, 25, "researcher"], [27, 28, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Over", "the", "decades", "he", "has", "researched", "and", "developed", "emerging", "areas", "of", "computer", "science", ",", "from", "compilers", ",", "programming", "languages", "and", "system", "architecture", "John", "F", ".", "Sowa", "and", "John", "Zachman", "(", "1992", ")", "."], "sentence-detokenized": "Over the decades he has researched and developed emerging areas of computer science, from compilers, programming languages and system architecture John F. Sowa and John Zachman (1992).", "token2charspan": [[0, 4], [5, 8], [9, 16], [17, 19], [20, 23], [24, 34], [35, 38], [39, 48], [49, 57], [58, 63], [64, 66], [67, 75], [76, 83], [83, 84], [85, 89], [90, 99], [99, 100], [101, 112], [113, 122], [123, 126], [127, 133], [134, 146], [147, 151], [152, 153], [153, 154], [155, 159], [160, 163], [164, 168], [169, 176], [177, 178], [178, 182], [182, 183], [183, 184]]}
{"doc_key": "ai-test-316", "ner": [[0, 2, "algorithm"], [7, 10, "algorithm"], [12, 13, "algorithm"], [18, 19, "field"], [21, 22, "field"], [27, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 10, 0, 2, "named", "", false, false], [12, 13, 0, 2, "named", "", false, false], [18, 19, 0, 2, "usage", "", false, false], [21, 22, 0, 2, "usage", "", false, false], [27, 28, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Sobel", "operator", ",", "sometimes", "called", "the", "Sobel", "-", "Feldman", "operator", "or", "Sobel", "filter", ",", "is", "used", "in", "image", "processing", "and", "computer", "vision", ",", "especially", "in", "edge", "detection", "algorithms", ",", "where", "it", "creates", "an", "image", "that", "highlights", "edges", "."], "sentence-detokenized": "The Sobel operator, sometimes called the Sobel-Feldman operator or Sobel filter, is used in image processing and computer vision, especially in edge detection algorithms, where it creates an image that highlights edges.", "token2charspan": [[0, 3], [4, 9], [10, 18], [18, 19], [20, 29], [30, 36], [37, 40], [41, 46], [46, 47], [47, 54], [55, 63], [64, 66], [67, 72], [73, 79], [79, 80], [81, 83], [84, 88], [89, 91], [92, 97], [98, 108], [109, 112], [113, 121], [122, 128], [128, 129], [130, 140], [141, 143], [144, 148], [149, 158], [159, 169], [169, 170], [171, 176], [177, 179], [180, 187], [188, 190], [191, 196], [197, 201], [202, 212], [213, 218], [218, 219]]}
{"doc_key": "ai-test-317", "ner": [[0, 0, "algorithm"], [3, 3, "field"], [12, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 3, 3, "compare", "", false, false], [0, 0, 3, 3, "type-of", "", false, false], [0, 0, 12, 12, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["LDA", "is", "a", "supervised", "learning", "algorithm", "that", "uses", "data", "labels", ",", "while", "PCA", "is", "a", "learning", "algorithm", "that", "ignores", "labels", "."], "sentence-detokenized": "LDA is a supervised learning algorithm that uses data labels, while PCA is a learning algorithm that ignores labels.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 19], [20, 28], [29, 38], [39, 43], [44, 48], [49, 53], [54, 60], [60, 61], [62, 67], [68, 71], [72, 74], [75, 76], [77, 85], [86, 95], [96, 100], [101, 108], [109, 115], [115, 116]]}
{"doc_key": "ai-test-318", "ner": [[5, 5, "algorithm"], [7, 9, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "linear", "classification", "algorithms", "include", "Winnow", ",", "support", "vector", "machine", "and", "logistic", "regression", "."], "sentence-detokenized": "Other linear classification algorithms include Winnow, support vector machine and logistic regression.", "token2charspan": [[0, 5], [6, 12], [13, 27], [28, 38], [39, 46], [47, 53], [53, 54], [55, 62], [63, 69], [70, 77], [78, 81], [82, 90], [91, 101], [101, 102]]}
{"doc_key": "ai-test-319", "ner": [[0, 1, "product"], [6, 7, "programlang"], [16, 18, "product"], [20, 20, "programlang"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 6, 7, "general-affiliation", "", true, false], [0, 1, 16, 18, "general-affiliation", "", true, false], [0, 1, 20, 20, "general-affiliation", "", true, false], [0, 1, 22, 22, "general-affiliation", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["VTK", "consists", "of", "a", "library", "of", "C", "++", "classes", "and", "several", "interpreted", "interface", "layers", ",", "including", "Tcl", "/", "Tk", ",", "Java", "and", "Python", "."], "sentence-detokenized": "VTK consists of a library of C++ classes and several interpreted interface layers, including Tcl/Tk, Java and Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 17], [18, 25], [26, 28], [29, 30], [30, 32], [33, 40], [41, 44], [45, 52], [53, 64], [65, 74], [75, 81], [81, 82], [83, 92], [93, 96], [96, 97], [97, 99], [99, 100], [101, 105], [106, 109], [110, 116], [116, 117]]}
{"doc_key": "ai-test-320", "ner": [[9, 11, "task"], [18, 20, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Also", ",", "text", "produced", "by", "spontaneous", "speech", "processing", "using", "automatic", "speech", "recognition", "and", "printed", "or", "handwritten", "text", "using", "optical", "character", "recognition", "contains", "processing", "noise", "."], "sentence-detokenized": "Also, text produced by spontaneous speech processing using automatic speech recognition and printed or handwritten text using optical character recognition contains processing noise.", "token2charspan": [[0, 4], [4, 5], [6, 10], [11, 19], [20, 22], [23, 34], [35, 41], [42, 52], [53, 58], [59, 68], [69, 75], [76, 87], [88, 91], [92, 99], [100, 102], [103, 114], [115, 119], [120, 125], [126, 133], [134, 143], [144, 155], [156, 164], [165, 175], [176, 181], [181, 182]]}
{"doc_key": "ai-test-321", "ner": [[0, 1, "researcher"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 10, 10, "role", "directs_development_of", false, false]], "relations_mapping_to_source": [0], "sentence": ["Miller", "has", "written", "several", "books", "and", "led", "the", "development", "of", "WordNet", ",", "an", "online", "database", "of", "word", "links", "that", "can", "be", "used", "by", "computer", "programs", "."], "sentence-detokenized": "Miller has written several books and led the development of WordNet, an online database of word links that can be used by computer programs.", "token2charspan": [[0, 6], [7, 10], [11, 18], [19, 26], [27, 32], [33, 36], [37, 40], [41, 44], [45, 56], [57, 59], [60, 67], [67, 68], [69, 71], [72, 78], [79, 87], [88, 90], [91, 95], [96, 101], [102, 106], [107, 110], [111, 113], [114, 118], [119, 121], [122, 130], [131, 139], [139, 140]]}
{"doc_key": "ai-test-322", "ner": [[1, 1, "field"], [8, 10, "organisation"], [13, 13, "country"], [15, 16, "person"], [18, 20, "person"], [22, 23, "person"], [25, 26, "person"], [29, 30, "country"], [32, 35, "location"], [37, 38, "misc"], [39, 40, "person"], [42, 43, "person"], [45, 45, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 10, 13, 13, "physical", "", false, false], [15, 16, 29, 30, "physical", "", false, false], [18, 20, 29, 30, "physical", "", false, false], [22, 23, 29, 30, "physical", "", false, false], [25, 26, 29, 30, "physical", "", false, false], [32, 35, 1, 1, "general-affiliation", "", false, false], [32, 35, 39, 40, "artifact", "", false, false], [37, 38, 39, 40, "named", "", false, false], [42, 43, 45, 45, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Contemporary", "automata", "are", "represented", "by", "the", "works", "of", "Cabaret", "Mechanical", "Theatre", "from", "the", "UK", ",", "Dug", "North", "and", "Chomick", "+", "Meder", ",", "Arthur", "Ganson", ",", "Joe", "Jones", "from", "the", "United", "States", ",", "Le", "D\u00e9fenseur", "du", "Temps", "by", "French", "artist", "Jacques", "Monestier", "and", "Fran\u00e7ois", "Junod", "from", "Switzerland", "."], "sentence-detokenized": "Contemporary automata are represented by the works of Cabaret Mechanical Theatre from the UK, Dug North and Chomick + Meder, Arthur Ganson, Joe Jones from the United States, Le D\u00e9fenseur du Temps by French artist Jacques Monestier and Fran\u00e7ois Junod from Switzerland.", "token2charspan": [[0, 12], [13, 21], [22, 25], [26, 37], [38, 40], [41, 44], [45, 50], [51, 53], [54, 61], [62, 72], [73, 80], [81, 85], [86, 89], [90, 92], [92, 93], [94, 97], [98, 103], [104, 107], [108, 115], [116, 117], [118, 123], [123, 124], [125, 131], [132, 138], [138, 139], [140, 143], [144, 149], [150, 154], [155, 158], [159, 165], [166, 172], [172, 173], [174, 176], [177, 186], [187, 189], [190, 195], [196, 198], [199, 205], [206, 212], [213, 220], [221, 230], [231, 234], [235, 243], [244, 249], [250, 254], [255, 266], [266, 267]]}
{"doc_key": "ai-test-323", "ner": [[0, 0, "product"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 21, 21, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MATLAB", "includes", "standard", "codefor", "/", "code", "and", "codewhile", "/", "code", "loops", ",", "but", "(", "as", "in", "other", "similar", "applications", "such", "as", "R", ")", ",", "the", "use", "of", "vectorized", "notation", "is", "encouraged", "and", "is", "often", "faster", "to", "execute", "."], "sentence-detokenized": "MATLAB includes standard codefor/code and codewhile/code loops, but (as in other similar applications such as R), the use of vectorized notation is encouraged and is often faster to execute.", "token2charspan": [[0, 6], [7, 15], [16, 24], [25, 32], [32, 33], [33, 37], [38, 41], [42, 51], [51, 52], [52, 56], [57, 62], [62, 63], [64, 67], [68, 69], [69, 71], [72, 74], [75, 80], [81, 88], [89, 101], [102, 106], [107, 109], [110, 111], [111, 112], [112, 113], [114, 117], [118, 121], [122, 124], [125, 135], [136, 144], [145, 147], [148, 158], [159, 162], [163, 165], [166, 171], [172, 178], [179, 181], [182, 189], [189, 190]]}
{"doc_key": "ai-test-324", "ner": [[0, 0, "researcher"], [6, 9, "conference"], [16, 17, "field"], [21, 27, "misc"], [18, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 21, 27, "win-defeat", "", false, false], [0, 0, 18, 39, "win-defeat", "", false, false], [21, 27, 6, 9, "temporal", "", false, false], [21, 27, 16, 17, "topic", "", false, false], [18, 39, 6, 9, "temporal", "", false, false], [18, 39, 16, 17, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pausch", "received", "two", "awards", "from", "the", "Association", "for", "Computing", "Machinery", "in", "2007", "for", "his", "achievements", "in", "computer", "science", "education", ":", "the", "Karl", "V", ".", "Karlstrom", "Outstanding", "Educator", "Award", "and", "the", "ACM", "SIGCSE", "Award", "for", "Outstanding", "Contributions", "to", "Computer", "Science", "Education", "."], "sentence-detokenized": "Pausch received two awards from the Association for Computing Machinery in 2007 for his achievements in computer science education: the Karl V. Karlstrom Outstanding Educator Award and the ACM SIGCSE Award for Outstanding Contributions to Computer Science Education.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 26], [27, 31], [32, 35], [36, 47], [48, 51], [52, 61], [62, 71], [72, 74], [75, 79], [80, 83], [84, 87], [88, 100], [101, 103], [104, 112], [113, 120], [121, 130], [130, 131], [132, 135], [136, 140], [141, 142], [142, 143], [144, 153], [154, 165], [166, 174], [175, 180], [181, 184], [185, 188], [189, 192], [193, 199], [200, 205], [206, 209], [210, 221], [222, 235], [236, 238], [239, 247], [248, 255], [256, 265], [265, 266]]}
{"doc_key": "ai-test-325", "ner": [[3, 3, "person"], [8, 9, "product"], [9, 9, "product"], [17, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 8, 9, "role", "sells", false, false], [8, 9, 9, 9, "general-affiliation", "", false, false], [8, 9, 17, 18, "physical", "shipped_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "delivered", "in", "1961", "to", "General", "Motors", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was delivered in 1961 to General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 75], [76, 78], [79, 83], [84, 86], [87, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-test-326", "ner": [[0, 3, "algorithm"], [5, 7, "field"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 0, 3, "usage", "", false, false], [11, 12, 5, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Semantic", "networks", "are", "used", "in", "natural", "language", "processing", "applications", "such", "as", "semantic", "analysis", "."], "sentence-detokenized": "Semantic networks are used in natural language processing applications such as semantic analysis.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 26], [27, 29], [30, 37], [38, 46], [47, 57], [58, 70], [71, 75], [76, 78], [79, 87], [88, 96], [96, 97]]}
{"doc_key": "ai-test-327", "ner": [[4, 5, "field"], [7, 8, "field"], [10, 11, "task"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[7, 8, 4, 5, "usage", "", false, false], [10, 11, 4, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Some", "successful", "applications", "of", "deep", "learning", "are", "computer", "vision", "and", "speech", "recognition", ".", "Honglak", "Lee", ",", "Roger", "Grosse", ",", "Rajesh", "Ranganath", ",", "Andrew", "Y", ".", "Ng", "."], "sentence-detokenized": "Some successful applications of deep learning are computer vision and speech recognition. Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng.", "token2charspan": [[0, 4], [5, 15], [16, 28], [29, 31], [32, 36], [37, 45], [46, 49], [50, 58], [59, 65], [66, 69], [70, 76], [77, 88], [88, 89], [90, 97], [98, 101], [101, 102], [103, 108], [109, 115], [115, 116], [117, 123], [124, 133], [133, 134], [135, 141], [142, 143], [143, 144], [145, 147], [147, 148]]}
{"doc_key": "ai-test-328", "ner": [[4, 7, "product"], [13, 13, "misc"], [16, 16, "misc"], [22, 22, "product"], [26, 27, "task"], [29, 29, "task"], [32, 33, "task"], [35, 37, "field"], [39, 41, "task"], [43, 44, "field"], [46, 47, "task"], [49, 50, "task"], [52, 53, "task"], [55, 55, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 7, 13, 13, "physical", "travels_to", false, false], [4, 7, 16, 16, "physical", "travels_to", false, false], [22, 22, 4, 7, "part-of", "", false, false], [22, 22, 4, 7, "role", "maintains", false, false], [22, 22, 26, 27, "related-to", "has_ability_to", false, false], [22, 22, 29, 29, "related-to", "has_ability_to", false, false], [22, 22, 32, 33, "related-to", "has_ability_to", false, false], [22, 22, 35, 37, "related-to", "has_ability_to", false, false], [22, 22, 39, 41, "related-to", "has_ability_to", false, false], [22, 22, 43, 44, "related-to", "has_ability_to", false, false], [22, 22, 46, 47, "related-to", "has_ability_to", false, false], [22, 22, 49, 50, "related-to", "has_ability_to", false, false], [22, 22, 52, 53, "related-to", "has_ability_to", false, false], [22, 22, 55, 55, "related-to", "has_ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["In", "addition", "to", "servicing", "Discovery", "One", "'s", "systems", "during", "its", "interplanetary", "mission", "to", "Jupiter", "(", "or", "Saturn", "in", "the", "novel", ")", ",", "HAL", "is", "capable", "of", "speech", "synthesis", ",", "voice", "recognition", ",", "facial", "recognition", ",", "natural", "language", "processing", ",", "lip", "-", "reading", ",", "artistic", "appreciation", ",", "affective", "computation", ",", "automatic", "reasoning", ",", "spacecraft", "piloting", "and", "chess", "playing", "."], "sentence-detokenized": "In addition to servicing Discovery One's systems during its interplanetary mission to Jupiter (or Saturn in the novel), HAL is capable of speech synthesis, voice recognition, facial recognition, natural language processing, lip-reading, artistic appreciation, affective computation, automatic reasoning, spacecraft piloting and chess playing.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 24], [25, 34], [35, 38], [38, 40], [41, 48], [49, 55], [56, 59], [60, 74], [75, 82], [83, 85], [86, 93], [94, 95], [95, 97], [98, 104], [105, 107], [108, 111], [112, 117], [117, 118], [118, 119], [120, 123], [124, 126], [127, 134], [135, 137], [138, 144], [145, 154], [154, 155], [156, 161], [162, 173], [173, 174], [175, 181], [182, 193], [193, 194], [195, 202], [203, 211], [212, 222], [222, 223], [224, 227], [227, 228], [228, 235], [235, 236], [237, 245], [246, 258], [258, 259], [260, 269], [270, 281], [281, 282], [283, 292], [293, 302], [302, 303], [304, 314], [315, 323], [324, 327], [328, 333], [334, 341], [341, 342]]}
{"doc_key": "ai-test-329", "ner": [[0, 1, "researcher"], [4, 4, "country"], [7, 8, "country"], [11, 13, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 4, "physical", "", false, false], [0, 1, 7, 8, "physical", "", false, false], [0, 1, 11, 13, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dr.", "Julesz", "emigrated", "from", "Hungary", "to", "the", "United", "States", "following", "the", "Soviet", "invasion", "in", "1956", "."], "sentence-detokenized": "Dr. Julesz emigrated from Hungary to the United States following the Soviet invasion in 1956.", "token2charspan": [[0, 3], [4, 10], [11, 20], [21, 25], [26, 33], [34, 36], [37, 40], [41, 47], [48, 54], [55, 64], [65, 68], [69, 75], [76, 84], [85, 87], [88, 92], [92, 93]]}
{"doc_key": "ai-test-330", "ner": [[0, 0, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sigmoid", "activation", "functions", "use", "a", "second", "nonlinearity", "for", "large", "inputs", ":", "math", "\\", "phi", "(", "v", "_", "i", ")", "=", "(", "1", "+\\", "exp", "(", "-", "v", "_", "i", ")", ")", "^", "{", "-1", "}", "/", "math", "."], "sentence-detokenized": "Sigmoid activation functions use a second nonlinearity for large inputs: math\\ phi (v _ i) = (1 +\\ exp (-v _ i)) ^ {-1} / math.", "token2charspan": [[0, 7], [8, 18], [19, 28], [29, 32], [33, 34], [35, 41], [42, 54], [55, 58], [59, 64], [65, 71], [71, 72], [73, 77], [77, 78], [79, 82], [83, 84], [84, 85], [86, 87], [88, 89], [89, 90], [91, 92], [93, 94], [94, 95], [96, 98], [99, 102], [103, 104], [104, 105], [105, 106], [107, 108], [109, 110], [110, 111], [111, 112], [113, 114], [115, 116], [116, 118], [118, 119], [120, 121], [122, 126], [126, 127]]}
{"doc_key": "ai-test-331", "ner": [[12, 14, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "probabilities", "are", "used", "to", "determine", "what", "the", "target", "is", "using", "a", "maximum", "likelihood", "decision", "."], "sentence-detokenized": "These probabilities are used to determine what the target is using a maximum likelihood decision.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 28], [29, 31], [32, 41], [42, 46], [47, 50], [51, 57], [58, 60], [61, 66], [67, 68], [69, 76], [77, 87], [88, 96], [96, 97]]}
{"doc_key": "ai-test-332", "ner": [[6, 9, "university"], [14, 16, "university"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1984", "he", "moved", "to", "the", "University", "of", "Konstanz", "and", "in", "1990", "to", "the", "University", "of", "Salzburg", "."], "sentence-detokenized": "In 1984 he moved to the University of Konstanz and in 1990 to the University of Salzburg.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 16], [17, 19], [20, 23], [24, 34], [35, 37], [38, 46], [47, 50], [51, 53], [54, 58], [59, 61], [62, 65], [66, 76], [77, 79], [80, 88], [88, 89]]}
{"doc_key": "ai-test-333", "ner": [[6, 7, "metrics"], [9, 11, "metrics"], [13, 15, "metrics"], [17, 17, "metrics"], [19, 20, "metrics"], [22, 24, "metrics"], [28, 29, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 11, 6, 7, "origin", "based_on", false, false], [13, 15, 6, 7, "origin", "based_on", false, false], [17, 17, 6, 7, "origin", "based_on", false, false], [19, 20, 6, 7, "origin", "based_on", false, false], [22, 24, 6, 7, "origin", "based_on", false, false], [28, 29, 6, 7, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Popular", "fitness", "functions", "based", "on", "the", "confusion", "matrix", "include", "sensitivity", "/", "specificity", ",", "recall", "/", "precision", ",", "F-measure", ",", "Jaccard", "similarity", ",", "Matthews", "correlation", "coefficient", "and", "cost", "/", "gain", "matrix", "which", "combines", "the", "costs", "and", "gains", "attributed", "to", "the", "4", "different", "types", "of", "classifications", "."], "sentence-detokenized": "Popular fitness functions based on the confusion matrix include sensitivity/specificity, recall/precision, F-measure, Jaccard similarity, Matthews correlation coefficient and cost/gain matrix which combines the costs and gains attributed to the 4 different types of classifications.", "token2charspan": [[0, 7], [8, 15], [16, 25], [26, 31], [32, 34], [35, 38], [39, 48], [49, 55], [56, 63], [64, 75], [75, 76], [76, 87], [87, 88], [89, 95], [95, 96], [96, 105], [105, 106], [107, 116], [116, 117], [118, 125], [126, 136], [136, 137], [138, 146], [147, 158], [159, 170], [171, 174], [175, 179], [179, 180], [180, 184], [185, 191], [192, 197], [198, 206], [207, 210], [211, 216], [217, 220], [221, 226], [227, 237], [238, 240], [241, 244], [245, 246], [247, 256], [257, 262], [263, 265], [266, 281], [281, 282]]}
{"doc_key": "ai-test-334", "ner": [[6, 6, "product"], [8, 8, "product"], [10, 10, "product"], [12, 12, "product"], [14, 16, "programlang"], [28, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[28, 30, 6, 6, "part-of", "", false, false], [28, 30, 8, 8, "part-of", "", false, false], [28, 30, 10, 10, "part-of", "", false, false], [28, 30, 12, 12, "part-of", "", false, false], [28, 30, 14, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Common", "numerical", "programming", "environments", "such", "as", "MATLAB", ",", "SciLab", ",", "NumPy", ",", "Sklearn", "and", "the", "R", "language", "provide", "some", "of", "the", "simplest", "techniques", "for", "extracting", "features", "(", "e.g.", "principal", "component", "analysis", ")", "using", "built", "-", "in", "commands", "."], "sentence-detokenized": "Common numerical programming environments such as MATLAB, SciLab, NumPy, Sklearn and the R language provide some of the simplest techniques for extracting features (e.g. principal component analysis) using built-in commands.", "token2charspan": [[0, 6], [7, 16], [17, 28], [29, 41], [42, 46], [47, 49], [50, 56], [56, 57], [58, 64], [64, 65], [66, 71], [71, 72], [73, 80], [81, 84], [85, 88], [89, 90], [91, 99], [100, 107], [108, 112], [113, 115], [116, 119], [120, 128], [129, 139], [140, 143], [144, 154], [155, 163], [164, 165], [165, 169], [170, 179], [180, 189], [190, 198], [198, 199], [200, 205], [206, 211], [211, 212], [212, 214], [215, 223], [223, 224]]}
{"doc_key": "ai-test-335", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Industrial", "robots", "have", "been", "deployed", "to", "collaborate", "with", "humans", "to", "perform", "industrial", "production", "tasks", "."], "sentence-detokenized": "Industrial robots have been deployed to collaborate with humans to perform industrial production tasks.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 27], [28, 36], [37, 39], [40, 51], [52, 56], [57, 63], [64, 66], [67, 74], [75, 85], [86, 96], [97, 102], [102, 103]]}
{"doc_key": "ai-test-336", "ner": [[6, 6, "field"], [8, 11, "researcher"], [21, 22, "field"], [24, 25, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 21, 22, "related-to", "", false, false], [6, 6, 24, 25, "related-to", "", false, false], [6, 6, 27, 28, "related-to", "", false, false], [8, 11, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "his", "first", "published", "work", "on", "CGs", ",", "John", "F", ".", "Sowa", "applied", "them", "to", "a", "wide", "range", "of", "topics", "in", "artificial", "intelligence", ",", "computer", "science", "and", "cognitive", "science", "."], "sentence-detokenized": "In his first published work on CGs, John F. Sowa applied them to a wide range of topics in artificial intelligence, computer science and cognitive science.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 22], [23, 27], [28, 30], [31, 34], [34, 35], [36, 40], [41, 42], [42, 43], [44, 48], [49, 56], [57, 61], [62, 64], [65, 66], [67, 71], [72, 77], [78, 80], [81, 87], [88, 90], [91, 101], [102, 114], [114, 115], [116, 124], [125, 132], [133, 136], [137, 146], [147, 154], [154, 155]]}
{"doc_key": "ai-test-337", "ner": [[0, 0, "metrics"], [4, 4, "metrics"], [9, 11, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 4, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "BLEU", "in", "the", "calculation", "of", "the", "shortness", "penalty", ",", "in", "that", "small", "variations", "in", "translation", "length", "do", "not", "have", "such", "a", "large", "impact", "on", "the", "overall", "score", "."], "sentence-detokenized": "NIST also differs from BLEU in the calculation of the shortness penalty, in that small variations in translation length do not have such a large impact on the overall score.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 27], [28, 30], [31, 34], [35, 46], [47, 49], [50, 53], [54, 63], [64, 71], [71, 72], [73, 75], [76, 80], [81, 86], [87, 97], [98, 100], [101, 112], [113, 119], [120, 122], [123, 126], [127, 131], [132, 136], [137, 138], [139, 144], [145, 151], [152, 154], [155, 158], [159, 166], [167, 172], [172, 173]]}
{"doc_key": "ai-test-338", "ner": [[0, 7, "misc"], [1, 14, "conference"], [23, 25, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 7, 1, 14, "temporal", "", false, false], [0, 7, 23, 25, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "IJCAI", "Award", "for", "Excellence", "in", "Research", "is", "a", "biannual", "award", "presented", "at", "the", "IJCAI", "conference", "to", "a", "researcher", "in", "the", "field", "of", "artificial", "intelligence", "in", "recognition", "of", "excellence", "in", "their", "career", "."], "sentence-detokenized": "The IJCAI Award for Excellence in Research is a biannual award presented at the IJCAI conference to a researcher in the field of artificial intelligence in recognition of excellence in their career.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 19], [20, 30], [31, 33], [34, 42], [43, 45], [46, 47], [48, 56], [57, 62], [63, 72], [73, 75], [76, 79], [80, 85], [86, 96], [97, 99], [100, 101], [102, 112], [113, 115], [116, 119], [120, 125], [126, 128], [129, 139], [140, 152], [153, 155], [156, 167], [168, 170], [171, 181], [182, 184], [185, 190], [191, 197], [197, 198]]}
{"doc_key": "ai-test-339", "ner": [[0, 0, "researcher"], [8, 8, "conference"], [19, 26, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 8, "role", "", false, false], [0, 0, 19, 26, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lenat", "was", "one", "of", "the", "first", "members", "of", "AAAI", "and", "is", "the", "only", "person", "to", "have", "served", "on", "the", "scientific", "advisory", "boards", "of", "both", "Microsoft", "and", "Apple", "."], "sentence-detokenized": "Lenat was one of the first members of AAAI and is the only person to have served on the scientific advisory boards of both Microsoft and Apple.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 16], [17, 20], [21, 26], [27, 34], [35, 37], [38, 42], [43, 46], [47, 49], [50, 53], [54, 58], [59, 65], [66, 68], [69, 73], [74, 80], [81, 83], [84, 87], [88, 98], [99, 107], [108, 114], [115, 117], [118, 122], [123, 132], [133, 136], [137, 142], [142, 143]]}
{"doc_key": "ai-test-340", "ner": [[0, 0, "algorithm"], [5, 6, "misc"], [10, 12, "metrics"], [19, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 6, "related-to", "minimise", false, false], [10, 12, 5, 6, "type-of", "", false, false], [19, 19, 5, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Autoencoders", "are", "trained", "to", "minimize", "reconstruction", "errors", "(", "such", "as", "mean", "squared", "error", ")", ",", "often", "referred", "to", "as", "loss", ":"], "sentence-detokenized": "Autoencoders are trained to minimize reconstruction errors (such as mean squared error), often referred to as loss:", "token2charspan": [[0, 12], [13, 16], [17, 24], [25, 27], [28, 36], [37, 51], [52, 58], [59, 60], [60, 64], [65, 67], [68, 72], [73, 80], [81, 86], [86, 87], [87, 88], [89, 94], [95, 103], [104, 106], [107, 109], [110, 114], [114, 115]]}
{"doc_key": "ai-test-341", "ner": [[28, 30, "misc"], [34, 34, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[34, 34, 28, 30, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "alternative", "to", "using", "definitions", "is", "to", "consider", "the", "general", "relationship", "between", "word", "senses", "and", "calculate", "the", "similarity", "of", "each", "pair", "of", "word", "senses", "based", "on", "a", "given", "lexical", "knowledge", "base", ",", "such", "as", "WordNet", "."], "sentence-detokenized": "An alternative to using definitions is to consider the general relationship between word senses and calculate the similarity of each pair of word senses based on a given lexical knowledge base, such as WordNet.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 23], [24, 35], [36, 38], [39, 41], [42, 50], [51, 54], [55, 62], [63, 75], [76, 83], [84, 88], [89, 95], [96, 99], [100, 109], [110, 113], [114, 124], [125, 127], [128, 132], [133, 137], [138, 140], [141, 145], [146, 152], [153, 158], [159, 161], [162, 163], [164, 169], [170, 177], [178, 187], [188, 192], [192, 193], [194, 198], [199, 201], [202, 209], [209, 210]]}
{"doc_key": "ai-test-342", "ner": [[0, 2, "algorithm"], [9, 13, "researcher"], [21, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 9, 13, "origin", "", false, false], [9, 13, 21, 22, "role", "work_based_on_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["TD", "-", "Lambda", "is", "a", "learning", "algorithm", "invented", "by", "Richard", "S.", "Sutton", "based", "on", "earlier", "work", "on", "temporal", "difference", "learning", "by", "Arthur", "Samuel", "."], "sentence-detokenized": "TD-Lambda is a learning algorithm invented by Richard S. Sutton based on earlier work on temporal difference learning by Arthur Samuel.", "token2charspan": [[0, 2], [2, 3], [3, 9], [10, 12], [13, 14], [15, 23], [24, 33], [34, 42], [43, 45], [46, 53], [54, 56], [57, 63], [64, 69], [70, 72], [73, 80], [81, 85], [86, 88], [89, 97], [98, 108], [109, 117], [118, 120], [121, 127], [128, 134], [134, 135]]}
{"doc_key": "ai-test-343", "ner": [[1, 2, "field"], [4, 4, "field"], [6, 7, "task"], [11, 13, "task"], [15, 15, "task"], [21, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 7, 1, 2, "part-of", "task_part_of_field", false, false], [6, 7, 4, 4, "part-of", "task_part_of_field", false, false], [11, 13, 6, 7, "named", "", false, false], [15, 15, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "data", "mining", "and", "statistics", ",", "hierarchical", "clustering", "(", "also", "called", "hierarchical", "cluster", "analysis", "or", "HCA", ")", "is", "a", "method", "of", "cluster", "analysis", "that", "aims", "to", "build", "a", "hierarchy", "of", "clusters", "."], "sentence-detokenized": "In data mining and statistics, hierarchical clustering (also called hierarchical cluster analysis or HCA) is a method of cluster analysis that aims to build a hierarchy of clusters.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 18], [19, 29], [29, 30], [31, 43], [44, 54], [55, 56], [56, 60], [61, 67], [68, 80], [81, 88], [89, 97], [98, 100], [101, 104], [104, 105], [106, 108], [109, 110], [111, 117], [118, 120], [121, 128], [129, 137], [138, 142], [143, 147], [148, 150], [151, 156], [157, 158], [159, 168], [169, 171], [172, 180], [180, 181]]}
{"doc_key": "ai-test-344", "ner": [[3, 3, "algorithm"], [8, 8, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 8, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "concept", "of", "deconvolution", "is", "widely", "used", "in", "signal", "processing", "and", "image", "processing", "techniques", "."], "sentence-detokenized": "The concept of deconvolution is widely used in signal processing and image processing techniques.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 28], [29, 31], [32, 38], [39, 43], [44, 46], [47, 53], [54, 64], [65, 68], [69, 74], [75, 85], [86, 96], [96, 97]]}
{"doc_key": "ai-test-345", "ner": [[0, 1, "algorithm"], [20, 21, "misc"], [24, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 20, 21, "related-to", "enhances", false, false], [0, 1, 20, 21, "related-to", "reduces", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cognitive", "maps", "serve", "to", "build", "and", "accumulate", "spatial", "knowledge", ",", "allowing", "the", "mind", "'s", "eye", "to", "visualise", "images", "to", "reduce", "cognitive", "load", ",", "improve", "recall", "and", "learning", "of", "information", "."], "sentence-detokenized": "Cognitive maps serve to build and accumulate spatial knowledge, allowing the mind's eye to visualise images to reduce cognitive load, improve recall and learning of information.", "token2charspan": [[0, 9], [10, 14], [15, 20], [21, 23], [24, 29], [30, 33], [34, 44], [45, 52], [53, 62], [62, 63], [64, 72], [73, 76], [77, 81], [81, 83], [84, 87], [88, 90], [91, 100], [101, 107], [108, 110], [111, 117], [118, 127], [128, 132], [132, 133], [134, 141], [142, 148], [149, 152], [153, 161], [162, 164], [165, 176], [176, 177]]}
{"doc_key": "ai-test-346", "ner": [[8, 8, "programlang"], [10, 11, "programlang"], [13, 13, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": [",", "usually", "providing", "links", "to", "languages", "such", "as", "Python", ",", "C", "++", ",", "Java", ")", "."], "sentence-detokenized": ", usually providing links to languages such as Python, C++, Java).", "token2charspan": [[0, 1], [2, 9], [10, 19], [20, 25], [26, 28], [29, 38], [39, 43], [44, 46], [47, 53], [53, 54], [55, 56], [56, 58], [58, 59], [60, 64], [64, 65], [65, 66]]}
{"doc_key": "ai-test-347", "ner": [[1, 3, "product"], [5, 5, "product"], [19, 20, "task"], [27, 29, "task"], [33, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 3, 19, 20, "usage", "", false, false], [1, 3, 27, 29, "usage", "", false, false], [1, 3, 33, 37, "usage", "", false, false], [5, 5, 1, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "voice", "-user", "interface", "(", "VUI", ")", "makes", "it", "possible", "for", "spoken", "humans", "to", "interact", "with", "computers", ",", "using", "speech", "recognition", "to", "understand", "voice", "commands", "and", "answer", "questions", ",", "and", "usually", "rendering", "a", "text", "response", "based", "on", "voice", "."], "sentence-detokenized": "A voice-user interface (VUI) makes it possible for spoken humans to interact with computers, using speech recognition to understand voice commands and answer questions, and usually rendering a text response based on voice.", "token2charspan": [[0, 1], [2, 7], [7, 12], [13, 22], [23, 24], [24, 27], [27, 28], [29, 34], [35, 37], [38, 46], [47, 50], [51, 57], [58, 64], [65, 67], [68, 76], [77, 81], [82, 91], [91, 92], [93, 98], [99, 105], [106, 117], [118, 120], [121, 131], [132, 137], [138, 146], [147, 150], [151, 157], [158, 167], [167, 168], [169, 172], [173, 180], [181, 190], [191, 192], [193, 197], [198, 206], [207, 212], [213, 215], [216, 221], [221, 222]]}
{"doc_key": "ai-test-348", "ner": [[0, 0, "programlang"], [3, 4, "misc"], [7, 7, "programlang"], [13, 16, "researcher"], [18, 19, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 4, "general-affiliation", "is_a", false, false], [0, 0, 7, 7, "general-affiliation", "made_with", false, false], [0, 0, 13, 16, "origin", "", false, false], [13, 16, 18, 19, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Jess", "is", "a", "rules", "engine", "for", "the", "Java", "platform", "that", "was", "developed", "by", "Ernest", "Friedman", "-", "Hill", "of", "Sandia", "National", "."], "sentence-detokenized": "Jess is a rules engine for the Java platform that was developed by Ernest Friedman-Hill of Sandia National.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 15], [16, 22], [23, 26], [27, 30], [31, 35], [36, 44], [45, 49], [50, 53], [54, 63], [64, 66], [67, 73], [74, 82], [82, 83], [83, 87], [88, 90], [91, 97], [98, 106], [106, 107]]}
{"doc_key": "ai-test-349", "ner": [[4, 5, "algorithm"], [19, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 19, 19, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "the", "case", "of", "multilayer", "perceptrons", ",", "where", "there", "is", "a", "hidden", "layer", ",", "more", "sophisticated", "algorithms", "such", "as", "backpropagation", "must", "be", "used", "."], "sentence-detokenized": "In the case of multilayer perceptrons, where there is a hidden layer, more sophisticated algorithms such as backpropagation must be used.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 25], [26, 37], [37, 38], [39, 44], [45, 50], [51, 53], [54, 55], [56, 62], [63, 68], [68, 69], [70, 74], [75, 88], [89, 99], [100, 104], [105, 107], [108, 123], [124, 128], [129, 131], [132, 136], [136, 137]]}
{"doc_key": "ai-test-350", "ner": [[0, 1, "product"], [3, 6, "product"], [11, 18, "algorithm"], [23, 24, "field"], [27, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 6, 0, 1, "part-of", "", false, false], [3, 6, 11, 18, "usage", "", false, true], [11, 18, 23, 24, "related-to", "performs", false, false], [27, 31, 23, 24, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Google", "Translate", "'s", "neural", "machine", "translation", "system", "uses", "a", "large", ",", "end", "-", "to", "-", "end", "artificial", "neural", "network", "that", "attempts", "to", "perform", "deep", "learning", ",", "especially", "short", "-", "term", "memory", "networks", "."], "sentence-detokenized": "Google Translate's neural machine translation system uses a large, end-to-end artificial neural network that attempts to perform deep learning, especially short-term memory networks.", "token2charspan": [[0, 6], [7, 16], [16, 18], [19, 25], [26, 33], [34, 45], [46, 52], [53, 57], [58, 59], [60, 65], [65, 66], [67, 70], [70, 71], [71, 73], [73, 74], [74, 77], [78, 88], [89, 95], [96, 103], [104, 108], [109, 117], [118, 120], [121, 128], [129, 133], [134, 142], [142, 143], [144, 154], [155, 160], [160, 161], [161, 165], [166, 172], [173, 181], [181, 182]]}
{"doc_key": "ai-test-351", "ner": [[7, 7, "researcher"], [9, 9, "researcher"], [11, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "1980s", "and", "early", "1990s", ",", "Werbos", ",", "Williams", ",", "Robinson", ",", "J\u00fcrgen", "Schmidhuber", ",", "Sepp", "Hochreiter", ",", "Pearlmutter", "and", "others", "developed", "various", "methods", "for", "this", "purpose", "."], "sentence-detokenized": "In the 1980s and early 1990s, Werbos, Williams, Robinson, J\u00fcrgen Schmidhuber, Sepp Hochreiter, Pearlmutter and others developed various methods for this purpose.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 16], [17, 22], [23, 28], [28, 29], [30, 36], [36, 37], [38, 46], [46, 47], [48, 56], [56, 57], [58, 64], [65, 76], [76, 77], [78, 82], [83, 93], [93, 94], [95, 106], [107, 110], [111, 117], [118, 127], [128, 135], [136, 143], [144, 147], [148, 152], [153, 160], [160, 161]]}
{"doc_key": "ai-test-352", "ner": [[1, 1, "organisation"], [2, 3, "organisation"], [8, 9, "organisation"], [16, 17, "task"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 8, 9, "role", "licenses_from", false, false], [2, 3, 1, 1, "named", "", false, false], [12, 12, 1, 1, "origin", "", false, false], [12, 12, 16, 17, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["|", "Apple", "Apple", "Inc.", "originally", "licensed", "software", "from", "Nuance", "to", "provide", "its", "Siri", "digital", "assistant", "with", "voice", "recognition", "capability", "."], "sentence-detokenized": "| Apple Apple Inc. originally licensed software from Nuance to provide its Siri digital assistant with voice recognition capability.", "token2charspan": [[0, 1], [2, 7], [8, 13], [14, 18], [19, 29], [30, 38], [39, 47], [48, 52], [53, 59], [60, 62], [63, 70], [71, 74], [75, 79], [80, 87], [88, 97], [98, 102], [103, 108], [109, 120], [121, 131], [131, 132]]}
{"doc_key": "ai-test-353", "ner": [[0, 1, "organisation"], [4, 5, "misc"], [8, 9, "person"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 5, "role", "releases_movies_in_genre", false, false], [8, 9, 0, 1, "role", "directs_for", false, false], [13, 14, 0, 1, "role", "directs_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Columbia", "has", "released", "several", "3D", "westerns", "produced", "by", "Sam", "Katzman", "and", "directed", "by", "William", "Castle", "."], "sentence-detokenized": "Columbia has released several 3D westerns produced by Sam Katzman and directed by William Castle.", "token2charspan": [[0, 8], [9, 12], [13, 21], [22, 29], [30, 32], [33, 41], [42, 50], [51, 53], [54, 57], [58, 65], [66, 69], [70, 78], [79, 81], [82, 89], [90, 96], [96, 97]]}
{"doc_key": "ai-test-354", "ner": [[9, 10, "field"], [12, 12, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "incorporates", "knowledge", "and", "research", "in", "the", "fields", "of", "computer", "science", ",", "linguistics", "and", "computer", "engineering", "."], "sentence-detokenized": "It incorporates knowledge and research in the fields of computer science, linguistics and computer engineering.", "token2charspan": [[0, 2], [3, 15], [16, 25], [26, 29], [30, 38], [39, 41], [42, 45], [46, 52], [53, 55], [56, 64], [65, 72], [72, 73], [74, 85], [86, 89], [90, 98], [99, 110], [110, 111]]}
{"doc_key": "ai-test-355", "ner": [[5, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Here", "is", "an", "example", "of", "R", "code", ":"], "sentence-detokenized": "Here is an example of R code:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 23], [24, 28], [28, 29]]}
{"doc_key": "ai-test-356", "ner": [[0, 2, "metrics"], [9, 9, "metrics"], [12, 12, "metrics"], [8, 18, "metrics"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 9, 9, "part-of", "plotted_into", false, false], [0, 2, 8, 18, "part-of", "plotted_into", false, false], [12, 12, 9, 9, "named", "", false, false], [20, 20, 8, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "ROC", "curve", "is", "created", "by", "plotting", "the", "TRUE", "positive", "rate", "(", "TPR", ")", "against", "the", "FALSE", "positive", "rate", "(", "FPR", ")", "at", "different", "threshold", "values", "."], "sentence-detokenized": "The ROC curve is created by plotting the TRUE positive rate (TPR) against the FALSE positive rate (FPR) at different threshold values.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 24], [25, 27], [28, 36], [37, 40], [41, 45], [46, 54], [55, 59], [60, 61], [61, 64], [64, 65], [66, 73], [74, 77], [78, 83], [84, 92], [93, 97], [98, 99], [99, 102], [102, 103], [104, 106], [107, 116], [117, 126], [127, 133], [133, 134]]}
{"doc_key": "ai-test-357", "ner": [[4, 5, "field"], [8, 9, "researcher"], [11, 12, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 4, 5, "related-to", "researches_field", false, false], [11, 12, 4, 5, "related-to", "researches_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Research", "stalled", "after", "the", "machine", "learning", "research", "of", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", ","], "sentence-detokenized": "Research stalled after the machine learning research of Marvin Minsky and Seymour Papert (1969),", "token2charspan": [[0, 8], [9, 16], [17, 22], [23, 26], [27, 34], [35, 43], [44, 52], [53, 55], [56, 62], [63, 69], [70, 73], [74, 81], [82, 88], [89, 90], [90, 94], [94, 95], [95, 96]]}
{"doc_key": "ai-test-358", "ner": [[8, 8, "task"], [11, 12, "programlang"], [15, 16, "product"], [18, 19, "programlang"], [21, 21, "product"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 8, 11, 12, "related-to", "used_to_build", false, false], [8, 8, 15, 16, "related-to", "used_to_build", false, false], [8, 8, 18, 19, "related-to", "used_to_build", false, false], [8, 8, 21, 21, "related-to", "used_to_build", false, false], [8, 8, 23, 23, "related-to", "used_to_build", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "programming", "environments", "that", "are", "used", "to", "build", "DAQ", "applications", "include", "ladder", "logic", ",", "Visual", "C", "++", ",", "Visual", "Basic", ",", "LabVIEW", "and", "MATLAB", "."], "sentence-detokenized": "Other programming environments that are used to build DAQ applications include ladder logic, Visual C++, Visual Basic, LabVIEW and MATLAB.", "token2charspan": [[0, 5], [6, 17], [18, 30], [31, 35], [36, 39], [40, 44], [45, 47], [48, 53], [54, 57], [58, 70], [71, 78], [79, 85], [86, 91], [91, 92], [93, 99], [100, 101], [101, 103], [103, 104], [105, 111], [112, 117], [117, 118], [119, 126], [127, 130], [131, 137], [137, 138]]}
{"doc_key": "ai-test-359", "ner": [[0, 17, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "metric", "was", "designed", "to", "solve", "some", "of", "the", "problems", "found", "in", "the", "more", "popular", "BLEU", "metric", "and", "also", "to", "produce", "a", "good", "correlation", "with", "human", "judgment", "at", "the", "sentence", "or", "segment", "level", "."], "sentence-detokenized": "The metric was designed to solve some of the problems found in the more popular BLEU metric and also to produce a good correlation with human judgment at the sentence or segment level.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 26], [27, 32], [33, 37], [38, 40], [41, 44], [45, 53], [54, 59], [60, 62], [63, 66], [67, 71], [72, 79], [80, 84], [85, 91], [92, 95], [96, 100], [101, 103], [104, 111], [112, 113], [114, 118], [119, 130], [131, 135], [136, 141], [142, 150], [151, 153], [154, 157], [158, 166], [167, 169], [170, 177], [178, 183], [183, 184]]}
{"doc_key": "ai-test-360", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "short", "-", "term", "memory", "are", "often", "used", "to", "exploit", "semantic", "correlations", "between", "consecutive", "video", "frames", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks and short-term memory are often used to exploit semantic correlations between consecutive video frames.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 83], [83, 84], [84, 88], [89, 95], [96, 99], [100, 105], [106, 110], [111, 113], [114, 121], [122, 130], [131, 143], [144, 151], [152, 163], [164, 169], [170, 176], [176, 177]]}
{"doc_key": "ai-test-361", "ner": [[3, 5, "product"], [7, 7, "product"], [14, 19, "product"], [23, 23, "product"], [40, 40, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 5, 14, 19, "artifact", "", false, false], [3, 5, 40, 40, "named", "", false, false], [7, 7, 3, 5, "named", "", false, false], [23, 23, 14, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Mass", "-", "produced", "printed", "circuit", "boards", "(", "PCBs", ")", "are", "almost", "exclusively", "manufactured", "by", "pick", "-", "and", "-", "place", "robots", ",", "usually", "with", "SCARA", "manipulators", ",", "which", "extract", "small", "electronic", "components", "from", "strips", "or", "trays", "and", "place", "them", "on", "the", "PCB", "with", "great", "precision", "."], "sentence-detokenized": "Mass-produced printed circuit boards (PCBs) are almost exclusively manufactured by pick-and-place robots, usually with SCARA manipulators, which extract small electronic components from strips or trays and place them on the PCB with great precision.", "token2charspan": [[0, 4], [4, 5], [5, 13], [14, 21], [22, 29], [30, 36], [37, 38], [38, 42], [42, 43], [44, 47], [48, 54], [55, 66], [67, 79], [80, 82], [83, 87], [87, 88], [88, 91], [91, 92], [92, 97], [98, 104], [104, 105], [106, 113], [114, 118], [119, 124], [125, 137], [137, 138], [139, 144], [145, 152], [153, 158], [159, 169], [170, 180], [181, 185], [186, 192], [193, 195], [196, 201], [202, 205], [206, 211], [212, 216], [217, 219], [220, 223], [224, 227], [228, 232], [233, 238], [239, 248], [248, 249]]}
{"doc_key": "ai-test-362", "ner": [[4, 5, "field"], [15, 16, "algorithm"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 29, "researcher"], [36, 37, "algorithm"], [39, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 16, 4, 5, "part-of", "", false, false], [15, 16, 20, 21, "origin", "", false, false], [15, 16, 23, 24, "origin", "", false, false], [15, 16, 26, 29, "origin", "", false, false], [15, 16, 36, 37, "type-of", "", false, false], [36, 37, 39, 40, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "the", "context", "of", "machine", "learning", ",", "where", "it", "is", "most", "widely", "applied", "today", ",", "LDA", "was", "independently", "rediscovered", "by", "David", "Blei", ",", "Andrew", "Ng", "and", "Michael", "I", ".", "Jordan", "in", "2003", "and", "presented", "as", "a", "graphical", "model", "for", "topic", "discovery", "."], "sentence-detokenized": "In the context of machine learning, where it is most widely applied today, LDA was independently rediscovered by David Blei, Andrew Ng and Michael I. Jordan in 2003 and presented as a graphical model for topic discovery.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 25], [26, 34], [34, 35], [36, 41], [42, 44], [45, 47], [48, 52], [53, 59], [60, 67], [68, 73], [73, 74], [75, 78], [79, 82], [83, 96], [97, 109], [110, 112], [113, 118], [119, 123], [123, 124], [125, 131], [132, 134], [135, 138], [139, 146], [147, 148], [148, 149], [150, 156], [157, 159], [160, 164], [165, 168], [169, 178], [179, 181], [182, 183], [184, 193], [194, 199], [200, 203], [204, 209], [210, 219], [219, 220]]}
{"doc_key": "ai-test-363", "ner": [[9, 9, "task"], [12, 14, "misc"], [16, 16, "metrics"], [18, 18, "metrics"], [20, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 9, 12, 14, "related-to", "task_across_domain", false, false]], "relations_mapping_to_source": [0], "sentence": ["Performance", "measured", "on", "the", "test", "data", "of", "eight", "naive", "WSIs", "from", "different", "moles", "resulted", "in", "a", "recall", ",", "accuracy", "and", "F1", "score", "of", "0.92", ",", "0.72", "and", "0.81", "respectively", "."], "sentence-detokenized": "Performance measured on the test data of eight naive WSIs from different moles resulted in a recall, accuracy and F1 score of 0.92, 0.72 and 0.81 respectively.", "token2charspan": [[0, 11], [12, 20], [21, 23], [24, 27], [28, 32], [33, 37], [38, 40], [41, 46], [47, 52], [53, 57], [58, 62], [63, 72], [73, 78], [79, 87], [88, 90], [91, 92], [93, 99], [99, 100], [101, 109], [110, 113], [114, 116], [117, 122], [123, 125], [126, 130], [130, 131], [132, 136], [137, 140], [141, 145], [146, 158], [158, 159]]}
{"doc_key": "ai-test-364", "ner": [[2, 3, "field"], [8, 9, "field"], [12, 13, "field"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 12, 13, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["With", "advanced", "augmented", "reality", "technologies", "(", "e.g.", "adding", "computer", "vision", ",", "embedding", "augmented", "reality", "cameras", "in", "smartphones", "and", "object", "recognition", ")", ",", "information", "about", "the", "real", "world", "around", "the", "user", "becomes", "interactive", "and", "digitally", "manipulated", "."], "sentence-detokenized": "With advanced augmented reality technologies (e.g. adding computer vision, embedding augmented reality cameras in smartphones and object recognition), information about the real world around the user becomes interactive and digitally manipulated.", "token2charspan": [[0, 4], [5, 13], [14, 23], [24, 31], [32, 44], [45, 46], [46, 50], [51, 57], [58, 66], [67, 73], [73, 74], [75, 84], [85, 94], [95, 102], [103, 110], [111, 113], [114, 125], [126, 129], [130, 136], [137, 148], [148, 149], [149, 150], [151, 162], [163, 168], [169, 172], [173, 177], [178, 183], [184, 190], [191, 194], [195, 199], [200, 207], [208, 219], [220, 223], [224, 233], [234, 245], [245, 246]]}
{"doc_key": "ai-test-365", "ner": [[3, 4, "researcher"], [8, 8, "organisation"], [16, 17, "field"], [27, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 8, 8, "role", "forms_company", false, false], [8, 8, 16, 17, "related-to", "works_with", false, false], [8, 8, 27, 30, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2014", ",", "Schmidhuber", "founded", "a", "company", ",", "Nnaisense", ",", "to", "work", "on", "commercial", "applications", "of", "artificial", "intelligence", "in", "areas", "such", "as", "finance", ",", "heavy", "industry", "and", "self", "-", "driving", "cars", "."], "sentence-detokenized": "In 2014, Schmidhuber founded a company, Nnaisense, to work on commercial applications of artificial intelligence in areas such as finance, heavy industry and self-driving cars.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 28], [29, 30], [31, 38], [38, 39], [40, 49], [49, 50], [51, 53], [54, 58], [59, 61], [62, 72], [73, 85], [86, 88], [89, 99], [100, 112], [113, 115], [116, 121], [122, 126], [127, 129], [130, 137], [137, 138], [139, 144], [145, 153], [154, 157], [158, 162], [162, 163], [163, 170], [171, 175], [175, 176]]}
{"doc_key": "ai-test-366", "ner": [[23, 26, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "not", "only", "alters", "the", "performance", "of", "all", "subsequent", "tests", "on", "the", "retained", "explanatory", "model", ",", "but", "can", "introduce", "bias", "and", "change", "the", "root", "mean", "square", "error", "in", "the", "estimation", "."], "sentence-detokenized": "This not only alters the performance of all subsequent tests on the retained explanatory model, but can introduce bias and change the root mean square error in the estimation.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 20], [21, 24], [25, 36], [37, 39], [40, 43], [44, 54], [55, 60], [61, 63], [64, 67], [68, 76], [77, 88], [89, 94], [94, 95], [96, 99], [100, 103], [104, 113], [114, 118], [119, 122], [123, 129], [130, 133], [134, 138], [139, 143], [144, 150], [151, 156], [157, 159], [160, 163], [164, 174], [174, 175]]}
{"doc_key": "ai-test-367", "ner": [[0, 0, "misc"], [7, 9, "algorithm"], [10, 11, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 0, 0, "usage", "", false, false], [7, 9, 10, 11, "topic", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Bigrams", "are", "used", "in", "the", "most", "successful", "language", "models", "for", "speech", "recognition", "."], "sentence-detokenized": "Bigrams are used in the most successful language models for speech recognition.", "token2charspan": [[0, 7], [8, 11], [12, 16], [17, 19], [20, 23], [24, 28], [29, 39], [40, 48], [49, 55], [56, 59], [60, 66], [67, 78], [78, 79]]}
{"doc_key": "ai-test-368", "ner": [[6, 9, "field"], [12, 14, "misc"], [20, 22, "misc"], [28, 30, "organisation"], [33, 35, "misc"], [41, 44, "organisation"], [47, 49, "misc"], [55, 59, "organisation"], [63, 65, "misc"], [71, 73, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[12, 14, 6, 9, "topic", "", false, false], [20, 22, 28, 30, "origin", "", false, false], [33, 35, 41, 44, "origin", "", false, false], [47, 49, 55, 59, "origin", "", false, false], [63, 65, 71, 73, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["His", "research", "in", "the", "field", "of", "cognitive", "psychology", "has", "been", "awarded", "the", "Early", "Career", "Award", "(", "1984", ")", "and", "the", "Boyd", "McCandless", "Award", "(", "1986", ")", "by", "the", "American", "Psychological", "Association", ",", "the", "Troland", "Research", "Award", "(", "1993", ")", "by", "the", "National", "Academy", "of", "Sciences", ",", "the", "Henry", "Dale", "Prize", "(", "2004", ")", "by", "the", "Royal", "Institution", "of", "Great", "Britain", ",", "and", "the", "George", "Miller", "Prize", "(", "2010", ")", "by", "the", "Cognitive", "Neuroscience", "Society", "."], "sentence-detokenized": "His research in the field of cognitive psychology has been awarded the Early Career Award (1984) and the Boyd McCandless Award (1986) by the American Psychological Association, the Troland Research Award (1993) by the National Academy of Sciences, the Henry Dale Prize (2004) by the Royal Institution of Great Britain, and the George Miller Prize (2010) by the Cognitive Neuroscience Society.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 19], [20, 25], [26, 28], [29, 38], [39, 49], [50, 53], [54, 58], [59, 66], [67, 70], [71, 76], [77, 83], [84, 89], [90, 91], [91, 95], [95, 96], [97, 100], [101, 104], [105, 109], [110, 120], [121, 126], [127, 128], [128, 132], [132, 133], [134, 136], [137, 140], [141, 149], [150, 163], [164, 175], [175, 176], [177, 180], [181, 188], [189, 197], [198, 203], [204, 205], [205, 209], [209, 210], [211, 213], [214, 217], [218, 226], [227, 234], [235, 237], [238, 246], [246, 247], [248, 251], [252, 257], [258, 262], [263, 268], [269, 270], [270, 274], [274, 275], [276, 278], [279, 282], [283, 288], [289, 300], [301, 303], [304, 309], [310, 317], [317, 318], [319, 322], [323, 326], [327, 333], [334, 340], [341, 346], [347, 348], [348, 352], [352, 353], [354, 356], [357, 360], [361, 370], [371, 383], [384, 391], [391, 392]]}
{"doc_key": "ai-test-369", "ner": [[1, 2, "misc"], [8, 9, "misc"], [11, 13, "product"], [17, 17, "researcher"], [19, 19, "researcher"], [26, 27, "researcher"], [29, 30, "researcher"], [32, 33, "task"], [35, 38, "researcher"], [40, 44, "researcher"], [45, 46, "task"], [48, 48, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[1, 2, 8, 9, "named", "", false, false], [1, 2, 48, 48, "named", "", false, false], [8, 9, 17, 17, "origin", "", false, false], [8, 9, 19, 19, "origin", "", false, false], [8, 9, 32, 33, "related-to", "used_for", false, false], [11, 13, 8, 9, "usage", "", false, false], [11, 13, 45, 46, "named", "", false, false], [26, 27, 8, 9, "usage", "", false, false], [26, 27, 35, 38, "named", "same", false, false], [29, 30, 8, 9, "usage", "", false, false], [29, 30, 40, 44, "named", "same", false, false], [45, 46, 48, 48, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["A", "proper", "face", "(", "The", "approach", "of", "using", "proper", "faces", "for", "face", "recognition", "system", "was", "developed", "by", "Sirovich", "and", "Kirby", "(", "1987", ")", "and", "used", "by", "Matthew", "Turk", "and", "Alex", "Pentland", "in", "face", "classification", ".", "Turk", ",", "Matthew", "A", "and", "Pentland", ",", "Alex", "P", ".", "Face", "recognition", "using", "eigenfaces", "."], "sentence-detokenized": "A proper face (The approach of using proper faces for face recognition system was developed by Sirovich and Kirby (1987) and used by Matthew Turk and Alex Pentland in face classification. Turk, Matthew A and Pentland, Alex P. Face recognition using eigenfaces.", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 15], [15, 18], [19, 27], [28, 30], [31, 36], [37, 43], [44, 49], [50, 53], [54, 58], [59, 70], [71, 77], [78, 81], [82, 91], [92, 94], [95, 103], [104, 107], [108, 113], [114, 115], [115, 119], [119, 120], [121, 124], [125, 129], [130, 132], [133, 140], [141, 145], [146, 149], [150, 154], [155, 163], [164, 166], [167, 171], [172, 186], [186, 187], [188, 192], [192, 193], [194, 201], [202, 203], [204, 207], [208, 216], [216, 217], [218, 222], [223, 224], [224, 225], [226, 230], [231, 242], [243, 248], [249, 259], [259, 260]]}
{"doc_key": "ai-test-370", "ner": [[6, 6, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "lexical", "dictionary", ",", "such", "as", "WordNet", ",", "can", "be", "used", "to", "understand", "the", "context", "."], "sentence-detokenized": "A lexical dictionary, such as WordNet, can be used to understand the context.", "token2charspan": [[0, 1], [2, 9], [10, 20], [20, 21], [22, 26], [27, 29], [30, 37], [37, 38], [39, 42], [43, 45], [46, 50], [51, 53], [54, 64], [65, 68], [69, 76], [76, 77]]}
{"doc_key": "ai-test-371", "ner": [[0, 2, "misc"], [8, 8, "misc"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 8, 8, "part-of", "", false, false], [8, 8, 15, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hyponymy", "is", "the", "most", "common", "coded", "relationship", "between", "synonyms", "used", "in", "lexical", "databases", "such", "as", "WordNet", "."], "sentence-detokenized": "Hyponymy is the most common coded relationship between synonyms used in lexical databases such as WordNet.", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 20], [21, 27], [28, 33], [34, 46], [47, 54], [55, 63], [64, 68], [69, 71], [72, 79], [80, 89], [90, 94], [95, 97], [98, 105], [105, 106]]}
{"doc_key": "ai-test-372", "ner": [[0, 0, "organisation"], [7, 8, "programlang"], [10, 10, "programlang"], [38, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 7, 8, "general-affiliation", "", false, false], [0, 0, 10, 10, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["OPeNDAP", "offers", "open", "-", "source", "libraries", "in", "C", "++", "and", "Java", ",", "but", "many", "customers", "rely", "on", "community", "-", "developed", "libraries", ",", "such", "as", "libraries", "that", "include", "built", "-", "in", "capabilities", "for", "retrieving", "(", "array", ")", "data", "from", "DAP", "servers", "."], "sentence-detokenized": "OPeNDAP offers open-source libraries in C++ and Java, but many customers rely on community-developed libraries, such as libraries that include built-in capabilities for retrieving (array) data from DAP servers.", "token2charspan": [[0, 7], [8, 14], [15, 19], [19, 20], [20, 26], [27, 36], [37, 39], [40, 41], [41, 43], [44, 47], [48, 52], [52, 53], [54, 57], [58, 62], [63, 72], [73, 77], [78, 80], [81, 90], [90, 91], [91, 100], [101, 110], [110, 111], [112, 116], [117, 119], [120, 129], [130, 134], [135, 142], [143, 148], [148, 149], [149, 151], [152, 164], [165, 168], [169, 179], [180, 181], [181, 186], [186, 187], [188, 192], [193, 197], [198, 201], [202, 209], [209, 210]]}
{"doc_key": "ai-test-373", "ner": [[4, 5, "misc"], [7, 7, "product"], [16, 16, "country"], [28, 30, "misc"], [44, 44, "organisation"], [45, 45, "product"], [47, 47, "organisation"], [48, 52, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 16, 16, "opposite", "", false, false], [7, 7, 16, 16, "artifact", "", false, false], [28, 30, 7, 7, "part-of", "", false, false], [45, 45, 44, 44, "artifact", "", false, false], [48, 52, 47, 47, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["On", "that", "page", ",", "Samurai", "Damashii", "hyped", "Senkousha", "as", "the", "crystallization", "of", "four", "thousand", "years", "of", "Chinese", "scientific", "knowledge", ",", "commented", "on", "the", "rudimentary", "design", "(", "e.g.", ",", "the", "Chinese", "cannon", "on", "the", "crotch", ")", ",", "and", "placed", "his", "image", "among", "images", "of", "the", "Honda", "ASIMO", "and", "Sony", "QRIO", "SDR", "-", "3", "X", "for", "juxtaposition", "."], "sentence-detokenized": "On that page, Samurai Damashii hyped Senkousha as the crystallization of four thousand years of Chinese scientific knowledge, commented on the rudimentary design (e.g., the Chinese cannon on the crotch), and placed his image among images of the Honda ASIMO and Sony QRIO SDR-3X for juxtaposition.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 21], [22, 30], [31, 36], [37, 46], [47, 49], [50, 53], [54, 69], [70, 72], [73, 77], [78, 86], [87, 92], [93, 95], [96, 103], [104, 114], [115, 124], [124, 125], [126, 135], [136, 138], [139, 142], [143, 154], [155, 161], [162, 163], [163, 167], [167, 168], [169, 172], [173, 180], [181, 187], [188, 190], [191, 194], [195, 201], [201, 202], [202, 203], [204, 207], [208, 214], [215, 218], [219, 224], [225, 230], [231, 237], [238, 240], [241, 244], [245, 250], [251, 256], [257, 260], [261, 265], [266, 270], [271, 274], [274, 275], [275, 276], [276, 277], [278, 281], [282, 295], [295, 296]]}
{"doc_key": "ai-test-374", "ner": [[8, 9, "algorithm"], [21, 21, "product"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 21, 21, "part-of", "includes_functionality_of", false, false], [8, 9, 23, 23, "part-of", "includes_functionality_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "also", "many", "programming", "libraries", "that", "contain", "neural", "network", "functionality", "that", "can", "be", "used", "in", "custom", "implementations", "(", "such", "as", "TensorFlow", ",", "Theano", ",", "etc.", ")", "."], "sentence-detokenized": "There are also many programming libraries that contain neural network functionality that can be used in custom implementations (such as TensorFlow, Theano, etc.).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 19], [20, 31], [32, 41], [42, 46], [47, 54], [55, 61], [62, 69], [70, 83], [84, 88], [89, 92], [93, 95], [96, 100], [101, 103], [104, 110], [111, 126], [127, 128], [128, 132], [133, 135], [136, 146], [146, 147], [148, 154], [154, 155], [156, 160], [160, 161], [161, 162]]}
{"doc_key": "ai-test-375", "ner": [[6, 9, "conference"], [11, 11, "organisation"], [13, 19, "conference"], [21, 21, "conference"], [23, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "Association", "for", "Computing", "Machinery", ",", "IEEE", ",", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "IAPR", "and", "SPIE", "."], "sentence-detokenized": "He is a member of the Association for Computing Machinery, IEEE, American Association for the Advancement of Science, IAPR and SPIE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 33], [34, 37], [38, 47], [48, 57], [57, 58], [59, 63], [63, 64], [65, 73], [74, 85], [86, 89], [90, 93], [94, 105], [106, 108], [109, 116], [116, 117], [118, 122], [123, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-test-376", "ner": [[6, 6, "organisation"], [11, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 6, 11, 12, "related-to", "runs_trials_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "test", "carried", "out", "by", "the", "RET", "in", "2011", ",", "with", "facial", "recognition", "cameras", "mounted", "on", "trams", ",", "ensured", "that", "people", "denied", "access", "to", "trams", "did", "not", "sneak", "in", "anyway", "."], "sentence-detokenized": "A test carried out by the RET in 2011, with facial recognition cameras mounted on trams, ensured that people denied access to trams did not sneak in anyway.", "token2charspan": [[0, 1], [2, 6], [7, 14], [15, 18], [19, 21], [22, 25], [26, 29], [30, 32], [33, 37], [37, 38], [39, 43], [44, 50], [51, 62], [63, 70], [71, 78], [79, 81], [82, 87], [87, 88], [89, 96], [97, 101], [102, 108], [109, 115], [116, 122], [123, 125], [126, 131], [132, 135], [136, 139], [140, 145], [146, 148], [149, 155], [155, 156]]}
{"doc_key": "ai-test-377", "ner": [[5, 10, "person"], [9, 9, "organisation"], [13, 14, "person"], [16, 19, "person"], [26, 27, "person"], [29, 30, "person"], [32, 33, "person"], [35, 36, "person"], [38, 39, "person"], [41, 42, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[5, 10, 9, 9, "role", "works_for", false, false], [13, 14, 9, 9, "role", "works_for", false, false], [16, 19, 9, 9, "role", "works_for", false, false], [26, 27, 9, 9, "role", "works_for", false, false], [29, 30, 9, 9, "role", "works_for", false, false], [32, 33, 9, 9, "role", "works_for", false, false], [35, 36, 9, 9, "role", "works_for", false, false], [38, 39, 9, 9, "role", "works_for", false, false], [41, 42, 9, 9, "role", "works_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "film", ",", "adapted", "from", "Cole", "Porter", "'s", "popular", "Broadway", "musical", ",", "starred", "Howard", "Keel", "and", "Kathryn", "Grayson", ",", "an", "MGM", "singing", "team", ",", "backed", "by", "Ann", "Miller", ",", "Keenan", "Wynn", ",", "Bobby", "Van", ",", "James", "Whitmore", ",", "Kurt", "Kasznar", "and", "Tommy", "Rall", "."], "sentence-detokenized": "The film, adapted from Cole Porter's popular Broadway musical, starred Howard Keel and Kathryn Grayson, an MGM singing team, backed by Ann Miller, Keenan Wynn, Bobby Van, James Whitmore, Kurt Kasznar and Tommy Rall.", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 17], [18, 22], [23, 27], [28, 34], [34, 36], [37, 44], [45, 53], [54, 61], [61, 62], [63, 70], [71, 77], [78, 82], [83, 86], [87, 94], [95, 102], [102, 103], [104, 106], [107, 110], [111, 118], [119, 123], [123, 124], [125, 131], [132, 134], [135, 138], [139, 145], [145, 146], [147, 153], [154, 158], [158, 159], [160, 165], [166, 169], [169, 170], [171, 176], [177, 185], [185, 186], [187, 191], [192, 199], [200, 203], [204, 209], [210, 214], [214, 215]]}
{"doc_key": "ai-test-378", "ner": [[20, 23, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "applications", "should", "streamline", "call", "flows", ",", "minimize", "requests", ",", "eliminate", "unnecessary", "iterations", ",", "and", "enable", "the", "development", "of", "a", "mixed", "-initiative", "dialogue", "system", "that", "allows", "callers", "to", "enter", "multiple", "pieces", "of", "information", "in", "a", "single", "utterance", "and", "in", "any", "order", "or", "combination", "."], "sentence-detokenized": "Such applications should streamline call flows, minimize requests, eliminate unnecessary iterations, and enable the development of a mixed-initiative dialogue system that allows callers to enter multiple pieces of information in a single utterance and in any order or combination.", "token2charspan": [[0, 4], [5, 17], [18, 24], [25, 35], [36, 40], [41, 46], [46, 47], [48, 56], [57, 65], [65, 66], [67, 76], [77, 88], [89, 99], [99, 100], [101, 104], [105, 111], [112, 115], [116, 127], [128, 130], [131, 132], [133, 138], [138, 149], [150, 158], [159, 165], [166, 170], [171, 177], [178, 185], [186, 188], [189, 194], [195, 203], [204, 210], [211, 213], [214, 225], [226, 228], [229, 230], [231, 237], [238, 247], [248, 251], [252, 254], [255, 258], [259, 264], [265, 267], [268, 279], [279, 280]]}
{"doc_key": "ai-test-379", "ner": [[4, 4, "algorithm"], [5, 10, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 10, 4, 4, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "such", ",", "traditional", "gradient", "descent", "(", "or", "stochastic", "gradient", "descent", ")", "methods", "can", "be", "adapted", ",", "in", "which", "instead", "of", "stepping", "in", "the", "direction", "of", "the", "gradient", "of", "the", "function", ",", "a", "step", "is", "taken", "in", "the", "direction", "of", "a", "vector", "selected", "from", "the", "subgradient", "of", "the", "function", "."], "sentence-detokenized": "As such, traditional gradient descent (or stochastic gradient descent) methods can be adapted, in which instead of stepping in the direction of the gradient of the function, a step is taken in the direction of a vector selected from the subgradient of the function.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 29], [30, 37], [38, 39], [39, 41], [42, 52], [53, 61], [62, 69], [69, 70], [71, 78], [79, 82], [83, 85], [86, 93], [93, 94], [95, 97], [98, 103], [104, 111], [112, 114], [115, 123], [124, 126], [127, 130], [131, 140], [141, 143], [144, 147], [148, 156], [157, 159], [160, 163], [164, 172], [172, 173], [174, 175], [176, 180], [181, 183], [184, 189], [190, 192], [193, 196], [197, 206], [207, 209], [210, 211], [212, 218], [219, 227], [228, 232], [233, 236], [237, 248], [249, 251], [252, 255], [256, 264], [264, 265]]}
{"doc_key": "ai-test-380", "ner": [[10, 13, "metrics"], [2, 17, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "distortion", "is", "assumed", "to", "be", "measured", "by", "the", "root", "mean", "square", "error", ",", "the", "distortion", "D", "is", "given", "by", ":"], "sentence-detokenized": "If the distortion is assumed to be measured by the root mean square error, the distortion D is given by:", "token2charspan": [[0, 2], [3, 6], [7, 17], [18, 20], [21, 28], [29, 31], [32, 34], [35, 43], [44, 46], [47, 50], [51, 55], [56, 60], [61, 67], [68, 73], [73, 74], [75, 78], [79, 89], [90, 91], [92, 94], [95, 100], [101, 103], [103, 104]]}
{"doc_key": "ai-test-381", "ner": [[0, 0, "algorithm"], [4, 5, "field"], [18, 19, "task"], [21, 22, "task"], [24, 25, "task"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 4, 5, "part-of", "", false, false], [18, 19, 0, 0, "part-of", "", false, false], [21, 22, 0, 0, "part-of", "", false, false], [24, 25, 0, 0, "part-of", "", false, false], [28, 29, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["MLPs", "were", "a", "popular", "machine", "learning", "solution", "in", "the", "1980s", ",", "finding", "applications", "in", "various", "fields", "such", "as", "speech", "recognition", ",", "image", "recognition", "and", "machine", "translation", "software", ",", "Neural", "Networks", "."], "sentence-detokenized": "MLPs were a popular machine learning solution in the 1980s, finding applications in various fields such as speech recognition, image recognition and machine translation software, Neural Networks.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 19], [20, 27], [28, 36], [37, 45], [46, 48], [49, 52], [53, 58], [58, 59], [60, 67], [68, 80], [81, 83], [84, 91], [92, 98], [99, 103], [104, 106], [107, 113], [114, 125], [125, 126], [127, 132], [133, 144], [145, 148], [149, 156], [157, 168], [169, 177], [177, 178], [179, 185], [186, 194], [194, 195]]}
{"doc_key": "ai-test-382", "ner": [[0, 0, "researcher"], [3, 4, "misc"], [6, 8, "university"], [15, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 8, "physical", "", false, false], [0, 0, 6, 8, "role", "", false, false], [3, 4, 0, 0, "origin", "", false, false], [15, 17, 0, 0, "role", "supervised", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Allen", "received", "his", "PhD", "from", "the", "University", "of", "Toronto", "in", "1979", "under", "the", "direction", "of", "C.", "Raymond", "Perrault", ","], "sentence-detokenized": "Allen received his PhD from the University of Toronto in 1979 under the direction of C. Raymond Perrault,", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 22], [23, 27], [28, 31], [32, 42], [43, 45], [46, 53], [54, 56], [57, 61], [62, 67], [68, 71], [72, 81], [82, 84], [85, 87], [88, 95], [96, 104], [104, 105]]}
{"doc_key": "ai-test-383", "ner": [[0, 0, "product"], [5, 7, "field"], [10, 10, "product"], [12, 12, "product"], [14, 14, "product"], [20, 20, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 5, 7, "related-to", "supports", false, false], [10, 10, 5, 7, "type-of", "", true, false], [12, 12, 5, 7, "type-of", "", true, false], [14, 14, 5, 7, "type-of", "", true, false], [14, 14, 20, 20, "related-to", "converting_to", true, false], [24, 24, 5, 7, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["OpenCV", "supports", "some", "models", "from", "deep", "learning", "frameworks", "such", "as", "TensorFlow", ",", "Torch", ",", "PyTorch", "(", "after", "conversion", "to", "an", "ONNX", "model", ")", "and", "Caffe", ",", "according", "to", "a", "defined", "list", "of", "supported", "layers", "."], "sentence-detokenized": "OpenCV supports some models from deep learning frameworks such as TensorFlow, Torch, PyTorch (after conversion to an ONNX model) and Caffe, according to a defined list of supported layers.", "token2charspan": [[0, 6], [7, 15], [16, 20], [21, 27], [28, 32], [33, 37], [38, 46], [47, 57], [58, 62], [63, 65], [66, 76], [76, 77], [78, 83], [83, 84], [85, 92], [93, 94], [94, 99], [100, 110], [111, 113], [114, 116], [117, 121], [122, 127], [127, 128], [129, 132], [133, 138], [138, 139], [140, 149], [150, 152], [153, 154], [155, 162], [163, 167], [168, 170], [171, 180], [181, 187], [187, 188]]}
{"doc_key": "ai-test-384", "ner": [[2, 2, "researcher"], [8, 11, "organisation"], [13, 13, "organisation"], [16, 20, "organisation"], [24, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 8, 11, "role", "", false, false], [2, 2, 16, 20, "role", "", false, false], [2, 2, 24, 24, "related-to", "lectures_in", false, false], [13, 13, 8, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Previously", ",", "Christensen", "was", "founding", "chair", "of", "the", "European", "Robotics", "Research", "Network", "(", "EURON", ")", "and", "IEEE", "Robotics", "and", "Automation", "Society", "Emeritus", "Lecturer", "in", "Robotics", "."], "sentence-detokenized": "Previously, Christensen was founding chair of the European Robotics Research Network (EURON) and IEEE Robotics and Automation Society Emeritus Lecturer in Robotics.", "token2charspan": [[0, 10], [10, 11], [12, 23], [24, 27], [28, 36], [37, 42], [43, 45], [46, 49], [50, 58], [59, 67], [68, 76], [77, 84], [85, 86], [86, 91], [91, 92], [93, 96], [97, 101], [102, 110], [111, 114], [115, 125], [126, 133], [134, 142], [143, 151], [152, 154], [155, 163], [163, 164]]}
{"doc_key": "ai-test-385", "ner": [[7, 7, "field"], [10, 11, "university"], [9, 13, "location"], [15, 18, "country"], [25, 25, "misc"], [27, 27, "field"], [30, 33, "organisation"], [35, 35, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 11, 9, 13, "physical", "", false, false], [9, 13, 15, 18, "physical", "", false, false], [25, 25, 27, 27, "topic", "", false, false], [30, 33, 35, 35, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "received", "a", "master", "'s", "degree", "in", "mathematics", "from", "Samarkand", "State", "University", ",", "Samarkand", ",", "Uzbek", "Soviet", "Socialist", "Republic", ",", "in", "1958", ",", "and", "a", "PhD", "in", "statistics", "from", "the", "Institute", "of", "Control", "Sciences", ",", "Moscow", ",", "in", "1964", "."], "sentence-detokenized": "He received a master's degree in mathematics from Samarkand State University, Samarkand, Uzbek Soviet Socialist Republic, in 1958, and a PhD in statistics from the Institute of Control Sciences, Moscow, in 1964.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 20], [20, 22], [23, 29], [30, 32], [33, 44], [45, 49], [50, 59], [60, 65], [66, 76], [76, 77], [78, 87], [87, 88], [89, 94], [95, 101], [102, 111], [112, 120], [120, 121], [122, 124], [125, 129], [129, 130], [131, 134], [135, 136], [137, 140], [141, 143], [144, 154], [155, 159], [160, 163], [164, 173], [174, 176], [177, 184], [185, 193], [193, 194], [195, 201], [201, 202], [203, 205], [206, 210], [210, 211]]}
{"doc_key": "ai-test-386", "ner": [[5, 5, "organisation"], [9, 13, "product"], [31, 32, "field"], [19, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 31, 32, "usage", "", false, false], [5, 5, 19, 36, "usage", "", false, false], [9, 13, 5, 5, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["However", ",", "the", "work", "at", "Cycorp", "increasingly", "involves", "the", "Cyc", "system", "'s", "ability", "to", "communicate", "with", "end", "users", "in", "natural", "language", "and", "assist", "in", "the", "ongoing", "process", "of", "knowledge", "formation", "through", "machine", "learning", "and", "natural", "language", "understanding", "."], "sentence-detokenized": "However, the work at Cycorp increasingly involves the Cyc system's ability to communicate with end users in natural language and assist in the ongoing process of knowledge formation through machine learning and natural language understanding.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 17], [18, 20], [21, 27], [28, 40], [41, 49], [50, 53], [54, 57], [58, 64], [64, 66], [67, 74], [75, 77], [78, 89], [90, 94], [95, 98], [99, 104], [105, 107], [108, 115], [116, 124], [125, 128], [129, 135], [136, 138], [139, 142], [143, 150], [151, 158], [159, 161], [162, 171], [172, 181], [182, 189], [190, 197], [198, 206], [207, 210], [211, 218], [219, 227], [228, 241], [241, 242]]}
{"doc_key": "ai-test-387", "ner": [[54, 54, "metrics"], [56, 56, "metrics"], [58, 58, "metrics"], [60, 61, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "when", "searching", "for", "the", "best", "classifier", "for", "a", "problem", ",", "the", "training", "dataset", "is", "used", "to", "train", "the", "candidate", "algorithms", ",", "the", "validation", "dataset", "is", "used", "to", "compare", "their", "performance", "and", "decide", "which", "one", "to", "choose", ",", "and", "finally", "the", "testing", "dataset", "is", "used", "to", "obtain", "the", "performance", "characteristics", "such", "as", "accuracy", ",", "sensitivity", ",", "specificity", ",", "F-", "measure", "and", "so", "on", "."], "sentence-detokenized": "For example, when searching for the best classifier for a problem, the training dataset is used to train the candidate algorithms, the validation dataset is used to compare their performance and decide which one to choose, and finally the testing dataset is used to obtain the performance characteristics such as accuracy, sensitivity, specificity, F-measure and so on.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 17], [18, 27], [28, 31], [32, 35], [36, 40], [41, 51], [52, 55], [56, 57], [58, 65], [65, 66], [67, 70], [71, 79], [80, 87], [88, 90], [91, 95], [96, 98], [99, 104], [105, 108], [109, 118], [119, 129], [129, 130], [131, 134], [135, 145], [146, 153], [154, 156], [157, 161], [162, 164], [165, 172], [173, 178], [179, 190], [191, 194], [195, 201], [202, 207], [208, 211], [212, 214], [215, 221], [221, 222], [223, 226], [227, 234], [235, 238], [239, 246], [247, 254], [255, 257], [258, 262], [263, 265], [266, 272], [273, 276], [277, 288], [289, 304], [305, 309], [310, 312], [313, 321], [321, 322], [323, 334], [334, 335], [336, 347], [347, 348], [349, 351], [351, 358], [359, 362], [363, 365], [366, 368], [368, 369]]}
{"doc_key": "ai-test-388", "ner": [[0, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "mean", "squared", "error", "is", "0.15", "."], "sentence-detokenized": "The mean squared error is 0.15.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 25], [26, 30], [30, 31]]}
{"doc_key": "ai-test-389", "ner": [[4, 5, "misc"], [10, 10, "organisation"], [15, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 4, 5, "role", "", false, false], [15, 15, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1979", ",", "a", "micromouse", "competition", "was", "organized", "by", "the", "IEEE", ",", "as", "reported", "in", "Spectrum", "magazine", "."], "sentence-detokenized": "In 1979, a micromouse competition was organized by the IEEE, as reported in Spectrum magazine.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 21], [22, 33], [34, 37], [38, 47], [48, 50], [51, 54], [55, 59], [59, 60], [61, 63], [64, 72], [73, 75], [76, 84], [85, 93], [93, 94]]}
{"doc_key": "ai-test-390", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [11, 13, "task"], [15, 15, "task"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 6, 7, "part-of", "", false, false], [11, 13, 6, 7, "part-of", "task_part_of_field", false, false], [15, 15, 6, 7, "part-of", "task_part_of_field", false, false], [18, 19, 6, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Gabor", "space", "is", "very", "useful", "in", "image", "processing", "applications", "such", "as", "optical", "character", "recognition", ",", "iris", "recognition", "and", "fingerprint", "recognition", "."], "sentence-detokenized": "Gabor space is very useful in image processing applications such as optical character recognition, iris recognition and fingerprint recognition.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 19], [20, 26], [27, 29], [30, 35], [36, 46], [47, 59], [60, 64], [65, 67], [68, 75], [76, 85], [86, 97], [97, 98], [99, 103], [104, 115], [116, 119], [120, 131], [132, 143], [143, 144]]}
{"doc_key": "ai-test-391", "ner": [[7, 7, "programlang"], [9, 9, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["or", "via", "high", "-", "level", "interfaces", "with", "Java", "and", "Tcl", "."], "sentence-detokenized": "or via high-level interfaces with Java and Tcl.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [12, 17], [18, 28], [29, 33], [34, 38], [39, 42], [43, 46], [46, 47]]}
{"doc_key": "ai-test-392", "ner": [[11, 13, "algorithm"], [20, 20, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 13, 20, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "recent", "research", ",", "kernel", "-", "based", "methods", ",", "such", "as", "support", "vector", "machines", ",", "have", "shown", "superior", "performance", "in", "surveillance", "."], "sentence-detokenized": "In recent research, kernel-based methods, such as support vector machines, have shown superior performance in surveillance.", "token2charspan": [[0, 2], [3, 9], [10, 18], [18, 19], [20, 26], [26, 27], [27, 32], [33, 40], [40, 41], [42, 46], [47, 49], [50, 57], [58, 64], [65, 73], [73, 74], [75, 79], [80, 85], [86, 94], [95, 106], [107, 109], [110, 122], [122, 123]]}
{"doc_key": "ai-test-393", "ner": [[14, 14, "misc"], [23, 23, "researcher"], [25, 25, "researcher"], [33, 33, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 33, 33, "usage", "", false, false], [25, 25, 33, 33, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["To", "illustrate", "the", "basic", "principles", "of", "baggage", ",", "an", "analysis", "of", "the", "relationship", "between", "ozone", "and", "temperature", "is", "presented", "below", "(", "data", "from", "Rousseeuw", "and", "Leroy", "(", "1986", ")", ",", "analysis", "performed", "in", "R", ")", "."], "sentence-detokenized": "To illustrate the basic principles of baggage, an analysis of the relationship between ozone and temperature is presented below (data from Rousseeuw and Leroy (1986), analysis performed in R).", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 23], [24, 34], [35, 37], [38, 45], [45, 46], [47, 49], [50, 58], [59, 61], [62, 65], [66, 78], [79, 86], [87, 92], [93, 96], [97, 108], [109, 111], [112, 121], [122, 127], [128, 129], [129, 133], [134, 138], [139, 148], [149, 152], [153, 158], [159, 160], [160, 164], [164, 165], [165, 166], [167, 175], [176, 185], [186, 188], [189, 190], [190, 191], [191, 192]]}
{"doc_key": "ai-test-394", "ner": [[0, 1, "organisation"], [11, 11, "product"], [18, 18, "product"], [21, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 0, 1, "artifact", "", false, false], [18, 18, 0, 1, "artifact", "", false, false], [21, 23, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Denso", "Wave", "is", "a", "subsidiary", "that", "manufactures", "automatic", "identification", "products", "(", "barcode", "readers", "and", "related", "products", ")", ",", "industrial", "robots", "and", "programmable", "logic", "controllers", "."], "sentence-detokenized": "Denso Wave is a subsidiary that manufactures automatic identification products (barcode readers and related products), industrial robots and programmable logic controllers.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 15], [16, 26], [27, 31], [32, 44], [45, 54], [55, 69], [70, 78], [79, 80], [80, 87], [88, 95], [96, 99], [100, 107], [108, 116], [116, 117], [117, 118], [119, 129], [130, 136], [137, 140], [141, 153], [154, 159], [160, 171], [171, 172]]}
{"doc_key": "ai-test-395", "ner": [[0, 3, "metrics"], [6, 8, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 19, 19, "compare", "", false, false], [6, 8, 0, 3, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["While", "Bilingual", "evaluation", "understudy", "simply", "calculates", "the", "accuracy", "of", "the", "graphs", ",", "adding", "an", "equal", "weight", "to", "each", ",", "NIST", "also", "calculates", "how", "informative", "a", "particular", "graph", "is", "."], "sentence-detokenized": "While Bilingual evaluation understudy simply calculates the accuracy of the graphs, adding an equal weight to each, NIST also calculates how informative a particular graph is.", "token2charspan": [[0, 5], [6, 15], [16, 26], [27, 37], [38, 44], [45, 55], [56, 59], [60, 68], [69, 71], [72, 75], [76, 82], [82, 83], [84, 90], [91, 93], [94, 99], [100, 106], [107, 109], [110, 114], [114, 115], [116, 120], [121, 125], [126, 136], [137, 140], [141, 152], [153, 154], [155, 165], [166, 171], [172, 174], [174, 175]]}
{"doc_key": "ai-test-396", "ner": [[15, 15, "algorithm"], [17, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "particular", ",", "they", "are", "used", "when", "calculating", "the", "likelihood", "of", "a", "tree", "(", "in", "Bayesian", "and", "maximum", "likelihood", "approaches", "to", "tree", "estimation", ")", "and", "are", "used", "to", "estimate", "the", "evolutionary", "distance", "between", "sequences", "based", "on", "observed", "differences", "between", "sequences", "."], "sentence-detokenized": "In particular, they are used when calculating the likelihood of a tree (in Bayesian and maximum likelihood approaches to tree estimation) and are used to estimate the evolutionary distance between sequences based on observed differences between sequences.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 19], [20, 23], [24, 28], [29, 33], [34, 45], [46, 49], [50, 60], [61, 63], [64, 65], [66, 70], [71, 72], [72, 74], [75, 83], [84, 87], [88, 95], [96, 106], [107, 117], [118, 120], [121, 125], [126, 136], [136, 137], [138, 141], [142, 145], [146, 150], [151, 153], [154, 162], [163, 166], [167, 179], [180, 188], [189, 196], [197, 206], [207, 212], [213, 215], [216, 224], [225, 236], [237, 244], [245, 254], [254, 255]]}
{"doc_key": "ai-test-397", "ner": [[0, 3, "conference"], [20, 21, "misc"], [23, 23, "misc"], [45, 46, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 20, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Audio", "Engineering", "Society", "recommends", "a", "sampling", "rate", "of", "48", "kHz", "for", "most", "applications", ",", "but", "recognises", "44.1", "kHz", "for", "Compact", "Disc", "(", "CD", ")", "and", "other", "consumer", "uses", ",", "32", "kHz", "for", "transmission", "-", "related", "applications", "and", "96", "kHz", "for", "higher", "bandwidth", "or", "relaxed", "anti-aliasing", "filtering", "."], "sentence-detokenized": "The Audio Engineering Society recommends a sampling rate of 48 kHz for most applications, but recognises 44.1 kHz for Compact Disc (CD) and other consumer uses, 32 kHz for transmission-related applications and 96 kHz for higher bandwidth or relaxed anti-aliasing filtering.", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 29], [30, 40], [41, 42], [43, 51], [52, 56], [57, 59], [60, 62], [63, 66], [67, 70], [71, 75], [76, 88], [88, 89], [90, 93], [94, 104], [105, 109], [110, 113], [114, 117], [118, 125], [126, 130], [131, 132], [132, 134], [134, 135], [136, 139], [140, 145], [146, 154], [155, 159], [159, 160], [161, 163], [164, 167], [168, 171], [172, 184], [184, 185], [185, 192], [193, 205], [206, 209], [210, 212], [213, 216], [217, 220], [221, 227], [228, 237], [238, 240], [241, 248], [249, 262], [263, 272], [272, 273]]}
{"doc_key": "ai-test-398", "ner": [[9, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Word", "and", "concept", "affectivity", "resources", "have", "been", "produced", "for", "WordNet", "{", "{", "read", "magazine"], "sentence-detokenized": "Word and concept affectivity resources have been produced for WordNet {{read magazine", "token2charspan": [[0, 4], [5, 8], [9, 16], [17, 28], [29, 38], [39, 43], [44, 48], [49, 57], [58, 61], [62, 69], [70, 71], [71, 72], [72, 76], [77, 85]]}
{"doc_key": "ai-test-399", "ner": [[2, 4, "misc"], [22, 23, "person"], [28, 31, "person"], [36, 38, "person"], [44, 49, "organisation"], [64, 65, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[28, 31, 36, 38, "role", "acts_in", false, false], [44, 49, 36, 38, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "the", "red", "-green", "anaglyph", ",", "the", "audience", "was", "shown", "three", "test", "reels", ",", "which", "included", "rural", "scenes", ",", "test", "footage", "of", "Marie", "Doro", ",", "a", "segment", "with", "John", "B", ".", "Mason", "performing", "some", "excerpts", "from", "Jim", "the", "Penman", "(", "a", "film", "released", "by", "Famous", "Players", "-", "Lasky", "that", "year", ",", "but", "not", "in", "3D", ")", ",", "Oriental", "dancers", ",", "and", "a", "reel", "of", "Niagara", "Falls", "footage", "."], "sentence-detokenized": "In the red-green anaglyph, the audience was shown three test reels, which included rural scenes, test footage of Marie Doro, a segment with John B. Mason performing some excerpts from Jim the Penman (a film released by Famous Players-Lasky that year, but not in 3D), Oriental dancers, and a reel of Niagara Falls footage.", "token2charspan": [[0, 2], [3, 6], [7, 10], [10, 16], [17, 25], [25, 26], [27, 30], [31, 39], [40, 43], [44, 49], [50, 55], [56, 60], [61, 66], [66, 67], [68, 73], [74, 82], [83, 88], [89, 95], [95, 96], [97, 101], [102, 109], [110, 112], [113, 118], [119, 123], [123, 124], [125, 126], [127, 134], [135, 139], [140, 144], [145, 146], [146, 147], [148, 153], [154, 164], [165, 169], [170, 178], [179, 183], [184, 187], [188, 191], [192, 198], [199, 200], [200, 201], [202, 206], [207, 215], [216, 218], [219, 225], [226, 233], [233, 234], [234, 239], [240, 244], [245, 249], [249, 250], [251, 254], [255, 258], [259, 261], [262, 264], [264, 265], [265, 266], [267, 275], [276, 283], [283, 284], [285, 288], [289, 290], [291, 295], [296, 298], [299, 306], [307, 312], [313, 320], [320, 321]]}
{"doc_key": "ai-test-400", "ner": [[7, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "a", "special", "way", "to", "implement", "maximum", "likelihood", "estimation", "for", "this", "problem", "."], "sentence-detokenized": "This is a special way to implement maximum likelihood estimation for this problem.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 17], [18, 21], [22, 24], [25, 34], [35, 42], [43, 53], [54, 64], [65, 68], [69, 73], [74, 81], [81, 82]]}
{"doc_key": "ai-test-401", "ner": [[0, 4, "product"], [11, 11, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Crawler", "-", "friendly", "web", "servers", "integrate", "the", "features", "of", "sitemaps", "and", "RSS", "feeds", "into", "a", "decentralized", "mechanism", "for", "computational", "biologists", "and", "bioinformaticians", "to", "openly", "disseminate", "and", "retrieve", "metadata", "about", "biomedical", "resources", "."], "sentence-detokenized": "Crawler-friendly web servers integrate the features of sitemaps and RSS feeds into a decentralized mechanism for computational biologists and bioinformaticians to openly disseminate and retrieve metadata about biomedical resources.", "token2charspan": [[0, 7], [7, 8], [8, 16], [17, 20], [21, 28], [29, 38], [39, 42], [43, 51], [52, 54], [55, 63], [64, 67], [68, 71], [72, 77], [78, 82], [83, 84], [85, 98], [99, 108], [109, 112], [113, 126], [127, 137], [138, 141], [142, 159], [160, 162], [163, 169], [170, 181], [182, 185], [186, 194], [195, 203], [204, 209], [210, 220], [221, 230], [230, 231]]}
{"doc_key": "ai-test-402", "ner": [[5, 12, "misc"], [15, 20, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "covered", "by", "the", "American", "National", "Standards", "Institute", "/", "NISO", "standard", "Z39.50", "and", "the", "International", "Organization", "for", "Standardization", "standard", "23950", "."], "sentence-detokenized": "It is covered by the American National Standards Institute/NISO standard Z39.50 and the International Organization for Standardization standard 23950.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 20], [21, 29], [30, 38], [39, 48], [49, 58], [58, 59], [59, 63], [64, 72], [73, 79], [80, 83], [84, 87], [88, 101], [102, 114], [115, 118], [119, 134], [135, 143], [144, 149], [149, 150]]}
{"doc_key": "ai-test-403", "ner": [[12, 16, "misc"], [23, 24, "metrics"], [26, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "encoder", "and", "decoder", "are", "trained", "to", "take", "a", "sentence", "and", "reproduce", "the", "single", "-", "focus", "distribution", "of", "a", "corresponding", "paraphrase", "by", "minimizing", "perplexity", "using", "simple", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The encoder and decoder are trained to take a sentence and reproduce the single-focus distribution of a corresponding paraphrase by minimizing perplexity using simple stochastic gradient descent.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 27], [28, 35], [36, 38], [39, 43], [44, 45], [46, 54], [55, 58], [59, 68], [69, 72], [73, 79], [79, 80], [80, 85], [86, 98], [99, 101], [102, 103], [104, 117], [118, 128], [129, 131], [132, 142], [143, 153], [154, 159], [160, 166], [167, 177], [178, 186], [187, 194], [194, 195]]}
{"doc_key": "ai-test-404", "ner": [[4, 4, "field"], [9, 9, "task"], [12, 14, "task"], [27, 29, "task"], [31, 37, "task"], [25, 44, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 9, 4, 4, "part-of", "task_part_of_field", false, false], [12, 14, 4, 4, "part-of", "task_part_of_field", false, false], [27, 29, 4, 4, "part-of", "task_part_of_field", false, false], [31, 37, 4, 4, "part-of", "task_part_of_field", false, false], [25, 44, 4, 4, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "typical", "applications", "of", "pattern", "recognition", "techniques", "are", "automatic", "speech", "recognition", ",", "multi-categorisation", "of", "text", "(", "e.g.", "spam", "/", "non", "-spam", "email", "messages", ")", ",", "handwriting", "recognition", "on", "postal", "envelopes", ",", "automatic", "recognition", "of", "images", "of", "human", "faces", "or", "handwriting", "image", "extraction", "from", "medical", "forms", "."], "sentence-detokenized": "Other typical applications of pattern recognition techniques are automatic speech recognition, multi-categorisation of text (e.g. spam/non-spam email messages), handwriting recognition on postal envelopes, automatic recognition of images of human faces or handwriting image extraction from medical forms.", "token2charspan": [[0, 5], [6, 13], [14, 26], [27, 29], [30, 37], [38, 49], [50, 60], [61, 64], [65, 74], [75, 81], [82, 93], [93, 94], [95, 115], [116, 118], [119, 123], [124, 125], [125, 129], [130, 134], [134, 135], [135, 138], [138, 143], [144, 149], [150, 158], [158, 159], [159, 160], [161, 172], [173, 184], [185, 187], [188, 194], [195, 204], [204, 205], [206, 215], [216, 227], [228, 230], [231, 237], [238, 240], [241, 246], [247, 252], [253, 255], [256, 267], [268, 273], [274, 284], [285, 289], [290, 297], [298, 303], [303, 304]]}
{"doc_key": "ai-test-405", "ner": [[0, 7, "algorithm"], [13, 14, "field"], [16, 17, "task"], [19, 20, "task"], [22, 24, "task"], [26, 29, "task"], [32, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 14, 0, 7, "usage", "", false, false], [16, 17, 0, 7, "usage", "", false, false], [19, 20, 0, 7, "usage", "", false, false], [22, 24, 0, 7, "usage", "", false, false], [26, 29, 0, 7, "usage", "", false, false], [32, 33, 0, 7, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Artificial", "neural", "networks", "have", "been", "used", "for", "a", "variety", "of", "tasks", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "board", "and", "video", "games", ",", "and", "medical", "diagnosis", "."], "sentence-detokenized": "Artificial neural networks have been used for a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, board and video games, and medical diagnosis.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 31], [32, 36], [37, 41], [42, 45], [46, 47], [48, 55], [56, 58], [59, 64], [64, 65], [66, 75], [76, 84], [85, 91], [91, 92], [93, 99], [100, 111], [111, 112], [113, 120], [121, 132], [132, 133], [134, 140], [141, 148], [149, 158], [158, 159], [160, 165], [166, 169], [170, 175], [176, 181], [181, 182], [183, 186], [187, 194], [195, 204], [204, 205]]}
{"doc_key": "ai-test-406", "ner": [[2, 3, "organisation"], [4, 4, "product"], [13, 13, "product"], [17, 17, "organisation"], [18, 19, "product"], [21, 21, "product"], [23, 25, "product"], [27, 27, "product"], [29, 29, "programlang"], [38, 39, "field"], [43, 43, "product"], [48, 48, "algorithm"], [50, 50, "algorithm"], [52, 52, "algorithm"], [56, 56, "product"], [64, 65, "task"], [69, 71, "algorithm"], [74, 74, "product"], [76, 76, "product"], [78, 80, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "relations": [[4, 4, 2, 3, "origin", "", false, false], [4, 4, 13, 13, "named", "same", false, false], [4, 4, 43, 43, "named", "same", false, false], [29, 29, 38, 39, "related-to", "used_for", false, false], [48, 48, 29, 29, "part-of", "", true, false], [48, 48, 43, 43, "origin", "", true, false], [50, 50, 29, 29, "part-of", "", true, false], [50, 50, 43, 43, "origin", "", true, false], [52, 52, 29, 29, "part-of", "", true, false], [52, 52, 43, 43, "origin", "", true, false], [56, 56, 64, 65, "related-to", "used_for", false, false], [69, 71, 56, 56, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Examples", "include", "Salford", "Systems", "CART", "(", "which", "licensed", "proprietary", "code", "from", "the", "original", "CART", "authors", ")", ",", "IBM", "SPSS", "Modeler", ",", "RapidMiner", ",", "SAS", "Enterprise", "Miner", ",", "Matlab", ",", "R", "(", "an", "open", "-", "source", "software", "environment", "for", "statistical", "computing", "that", "includes", "several", "CART", "implementations", "such", "as", "the", "rpart", ",", "party", "and", "randomForest", "packages", ")", ",", "Weka", "(", "a", "free", "and", "open", "-", "source", "data", "mining", "suite", "containing", "many", "decision", "tree", "algorithms", ")", ",", "Orange", ",", "KNIME", ",", "Microsoft", "SQL", "Server", "programming", "language", ")", "."], "sentence-detokenized": "Examples include Salford Systems CART (which licensed proprietary code from the original CART authors), IBM SPSS Modeler, RapidMiner, SAS Enterprise Miner, Matlab, R (an open-source software environment for statistical computing that includes several CART implementations such as the rpart, party and randomForest packages), Weka (a free and open-source data mining suite containing many decision tree algorithms), Orange, KNIME, Microsoft SQL Server programming language).", "token2charspan": [[0, 8], [9, 16], [17, 24], [25, 32], [33, 37], [38, 39], [39, 44], [45, 53], [54, 65], [66, 70], [71, 75], [76, 79], [80, 88], [89, 93], [94, 101], [101, 102], [102, 103], [104, 107], [108, 112], [113, 120], [120, 121], [122, 132], [132, 133], [134, 137], [138, 148], [149, 154], [154, 155], [156, 162], [162, 163], [164, 165], [166, 167], [167, 169], [170, 174], [174, 175], [175, 181], [182, 190], [191, 202], [203, 206], [207, 218], [219, 228], [229, 233], [234, 242], [243, 250], [251, 255], [256, 271], [272, 276], [277, 279], [280, 283], [284, 289], [289, 290], [291, 296], [297, 300], [301, 313], [314, 322], [322, 323], [323, 324], [325, 329], [330, 331], [331, 332], [333, 337], [338, 341], [342, 346], [346, 347], [347, 353], [354, 358], [359, 365], [366, 371], [372, 382], [383, 387], [388, 396], [397, 401], [402, 412], [412, 413], [413, 414], [415, 421], [421, 422], [423, 428], [428, 429], [430, 439], [440, 443], [444, 450], [451, 462], [463, 471], [471, 472], [472, 473]]}
{"doc_key": "ai-test-407", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [10, 12, "researcher"], [13, 14, "university"], [16, 17, "researcher"], [19, 22, "organisation"], [24, 24, "organisation"], [34, 36, "researcher"], [38, 40, "researcher"], [42, 45, "organisation"], [56, 60, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 2, 10, 12, "origin", "", false, false], [0, 2, 16, 17, "origin", "", false, false], [0, 2, 34, 36, "origin", "", false, false], [0, 2, 38, 40, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [10, 12, 13, 14, "physical", "", false, false], [10, 12, 13, 14, "role", "", false, false], [16, 17, 19, 22, "physical", "", false, false], [16, 17, 19, 22, "role", "", false, false], [24, 24, 19, 22, "named", "", false, false], [34, 36, 42, 45, "physical", "", false, false], [34, 36, 42, 45, "role", "", false, false], [38, 40, 42, 45, "physical", "", false, false], [38, 40, 42, 45, "role", "", false, false], [56, 60, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Linear", "predictive", "coding", "(", "LPC", ")", "was", "first", "developed", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", ",", "and", "was", "further", "developed", "by", "Bishnu", "S.", "Atal", "and", "Manfred", "R.", "Schroeder", "at", "Bell", "Labs", "in", "the", "early", "to", "mid-1970s", ",", "becoming", "a", "basis", "for", "the", "first", "DSP", "chips", "for", "speech", "synthesis", "in", "the", "late", "1970s", "."], "sentence-detokenized": "Linear predictive coding (LPC) was first developed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966, and was further developed by Bishnu S. Atal and Manfred R. Schroeder at Bell Labs in the early to mid-1970s, becoming a basis for the first DSP chips for speech synthesis in the late 1970s.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [31, 34], [35, 40], [41, 50], [51, 53], [54, 62], [63, 70], [71, 73], [74, 80], [81, 91], [92, 95], [96, 101], [102, 107], [108, 110], [111, 117], [118, 127], [128, 131], [132, 141], [142, 143], [143, 146], [146, 147], [148, 150], [151, 155], [155, 156], [157, 160], [161, 164], [165, 172], [173, 182], [183, 185], [186, 192], [193, 195], [196, 200], [201, 204], [205, 212], [213, 215], [216, 225], [226, 228], [229, 233], [234, 238], [239, 241], [242, 245], [246, 251], [252, 254], [255, 264], [264, 265], [266, 274], [275, 276], [277, 282], [283, 286], [287, 290], [291, 296], [297, 300], [301, 306], [307, 310], [311, 317], [318, 327], [328, 330], [331, 334], [335, 339], [340, 345], [345, 346]]}
{"doc_key": "ai-test-408", "ner": [[1, 3, "metrics"], [8, 8, "metrics"], [10, 10, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 1, 3, "part-of", "", false, false], [10, 10, 1, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "F", "-", "score", "is", "a", "combination", "of", "precision", "and", "recall", ",", "giving", "a", "single", "score", "."], "sentence-detokenized": "An F-score is a combination of precision and recall, giving a single score.", "token2charspan": [[0, 2], [3, 4], [4, 5], [5, 10], [11, 13], [14, 15], [16, 27], [28, 30], [31, 40], [41, 44], [45, 51], [51, 52], [53, 59], [60, 61], [62, 68], [69, 74], [74, 75]]}
{"doc_key": "ai-test-409", "ner": [[0, 1, "field"], [8, 10, "task"], [16, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 0, 1, "part-of", "task_part_of_field", false, false], [16, 18, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Image", "analysis", "tasks", "can", "be", "as", "simple", "as", "reading", "barcode", "labels", "or", "as", "sophisticated", "as", "a", "facial", "recognition", "system", "."], "sentence-detokenized": "Image analysis tasks can be as simple as reading barcode labels or as sophisticated as a facial recognition system.", "token2charspan": [[0, 5], [6, 14], [15, 20], [21, 24], [25, 27], [28, 30], [31, 37], [38, 40], [41, 48], [49, 56], [57, 63], [64, 66], [67, 69], [70, 83], [84, 86], [87, 88], [89, 95], [96, 107], [108, 114], [114, 115]]}
{"doc_key": "ai-test-410", "ner": [[5, 8, "algorithm"], [26, 27, "algorithm"], [34, 36, "algorithm"], [40, 40, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[34, 36, 26, 27, "type-of", "", false, false], [40, 40, 34, 36, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "special", "case", "of", "linear", "support", "-", "vector", "machines", "can", "be", "solved", "more", "efficiently", "by", "the", "same", "type", "of", "optimization", "algorithms", "as", "its", "close", "cousin", ",", "logistic", "regression", ";", "this", "class", "of", "algorithms", "includes", "stochastic", "gradient", "descent", "(", "e.g.", ",", "PEGASOS", ")", "."], "sentence-detokenized": "The special case of linear support-vector machines can be solved more efficiently by the same type of optimization algorithms as its close cousin, logistic regression; this class of algorithms includes stochastic gradient descent (e.g., PEGASOS).", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 19], [20, 26], [27, 34], [34, 35], [35, 41], [42, 50], [51, 54], [55, 57], [58, 64], [65, 69], [70, 81], [82, 84], [85, 88], [89, 93], [94, 98], [99, 101], [102, 114], [115, 125], [126, 128], [129, 132], [133, 138], [139, 145], [145, 146], [147, 155], [156, 166], [166, 167], [168, 172], [173, 178], [179, 181], [182, 192], [193, 201], [202, 212], [213, 221], [222, 229], [230, 231], [231, 235], [235, 236], [237, 244], [244, 245], [245, 246]]}
{"doc_key": "ai-test-411", "ner": [[1, 2, "product"], [4, 4, "product"], [26, 26, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 4, 4, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["When", "Siri", "on", "an", "iOS", "device", "is", "asked", "\"", "Do", "you", "have", "a", "pet", "?", "\"", ",", "one", "of", "the", "answers", "is", "\"", "I", "had", "an", "AIBO", "\"", "."], "sentence-detokenized": "When Siri on an iOS device is asked \"Do you have a pet?\", one of the answers is \"I had an AIBO\".", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 15], [16, 19], [20, 26], [27, 29], [30, 35], [36, 37], [37, 39], [40, 43], [44, 48], [49, 50], [51, 54], [54, 55], [55, 56], [56, 57], [58, 61], [62, 64], [65, 68], [69, 76], [77, 79], [80, 81], [81, 82], [83, 86], [87, 89], [90, 94], [94, 95], [95, 96]]}
{"doc_key": "ai-test-412", "ner": [[1, 2, "task"], [5, 8, "metrics"], [10, 11, "metrics"], [13, 13, "metrics"], [16, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 8, 1, 2, "part-of", "", false, false], [10, 11, 5, 8, "named", "", false, false], [13, 13, 1, 2, "part-of", "", false, false], [16, 16, 13, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "information", "retrieval", ",", "the", "positive", "predictive", "value", "is", "called", "accuracy", "and", "the", "sensitivity", "is", "called", "recall", "."], "sentence-detokenized": "In information retrieval, the positive predictive value is called accuracy and the sensitivity is called recall.", "token2charspan": [[0, 2], [3, 14], [15, 24], [24, 25], [26, 29], [30, 38], [39, 49], [50, 55], [56, 58], [59, 65], [66, 74], [75, 78], [79, 82], [83, 94], [95, 97], [98, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-test-413", "ner": [[11, 12, "field"], [14, 14, "task"], [16, 16, "task"], [18, 19, "task"], [34, 35, "task"], [37, 38, "task"], [40, 44, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[14, 14, 11, 12, "part-of", "task_part_of_field", false, false], [16, 16, 11, 12, "part-of", "task_part_of_field", false, false], [18, 19, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "particular", ",", "his", "research", "has", "focused", "on", "areas", "such", "as", "text", "mining", "(", "extraction", ",", "categorization", ",", "novelty", "detection", ")", "and", "new", "theoretical", "frameworks", "such", "as", "a", "unified", "utility", "-", "based", "theory", "linking", "information", "retrieval", ",", "automated", "summarization", ",", "free", "-", "text", "query", "answering", ",", "and", "other", "related", "tasks", "."], "sentence-detokenized": "In particular, his research has focused on areas such as text mining (extraction, categorization, novelty detection) and new theoretical frameworks such as a unified utility-based theory linking information retrieval, automated summarization, free-text query answering, and other related tasks.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 27], [28, 31], [32, 39], [40, 42], [43, 48], [49, 53], [54, 56], [57, 61], [62, 68], [69, 70], [70, 80], [80, 81], [82, 96], [96, 97], [98, 105], [106, 115], [115, 116], [117, 120], [121, 124], [125, 136], [137, 147], [148, 152], [153, 155], [156, 157], [158, 165], [166, 173], [173, 174], [174, 179], [180, 186], [187, 194], [195, 206], [207, 216], [216, 217], [218, 227], [228, 241], [241, 242], [243, 247], [247, 248], [248, 252], [253, 258], [259, 268], [268, 269], [270, 273], [274, 279], [280, 287], [288, 293], [293, 294]]}
{"doc_key": "ai-test-414", "ner": [[0, 0, "product"], [6, 7, "product"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 0, 0, "part-of", "", false, false], [14, 15, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Delta", "robots", "have", "base", "-", "mounted", "rotary", "actuators", "that", "move", "a", "lightweight", ",", "rigid", "parallelogram", "arm", "."], "sentence-detokenized": "Delta robots have base-mounted rotary actuators that move a lightweight, rigid parallelogram arm.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 22], [22, 23], [23, 30], [31, 37], [38, 47], [48, 52], [53, 57], [58, 59], [60, 71], [71, 72], [73, 78], [79, 92], [93, 96], [96, 97]]}
{"doc_key": "ai-test-415", "ner": [[8, 12, "metrics"], [16, 18, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "outcomes", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "in", "a", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four outcomes can be formulated in a 2 \u00d7 2 contingency table or in a confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 24], [25, 35], [36, 38], [39, 40], [41, 42], [43, 44], [45, 46], [47, 58], [59, 64], [65, 67], [68, 70], [71, 72], [73, 82], [83, 89], [90, 92], [93, 100], [100, 101]]}
{"doc_key": "ai-test-416", "ner": [[4, 5, "field"], [30, 31, "task"], [37, 38, "task"], [43, 45, "task"], [47, 49, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[30, 31, 4, 5, "part-of", "task_part_of_field", false, false], [37, 38, 4, 5, "part-of", "task_part_of_field", false, false], [43, 45, 4, 5, "part-of", "task_part_of_field", false, false], [47, 49, 4, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "actual", "task", "of", "data", "mining", "is", "the", "semi-automated", "or", "automated", "analysis", "of", "large", "amounts", "of", "data", "to", "extract", "unknown", ",", "interesting", "patterns", "such", "as", "groups", "of", "data", "records", "(", "cluster", "analysis", ")", ",", "unusual", "records", "(", "anomaly", "detection", ")", "and", "dependencies", "(", "association", "rule", "mining", ",", "sequential", "pattern", "mining", ")", "."], "sentence-detokenized": "The actual task of data mining is the semi-automated or automated analysis of large amounts of data to extract unknown, interesting patterns such as groups of data records (cluster analysis), unusual records (anomaly detection) and dependencies (association rule mining, sequential pattern mining).", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 18], [19, 23], [24, 30], [31, 33], [34, 37], [38, 52], [53, 55], [56, 65], [66, 74], [75, 77], [78, 83], [84, 91], [92, 94], [95, 99], [100, 102], [103, 110], [111, 118], [118, 119], [120, 131], [132, 140], [141, 145], [146, 148], [149, 155], [156, 158], [159, 163], [164, 171], [172, 173], [173, 180], [181, 189], [189, 190], [190, 191], [192, 199], [200, 207], [208, 209], [209, 216], [217, 226], [226, 227], [228, 231], [232, 244], [245, 246], [246, 257], [258, 262], [263, 269], [269, 270], [271, 281], [282, 289], [290, 296], [296, 297], [297, 298]]}
{"doc_key": "ai-test-417", "ner": [[2, 3, "product"], [5, 7, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 5, 7, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "a", "recommender", "system", ",", "sentiment", "analysis", "has", "proven", "to", "be", "a", "valuable", "technique", "."], "sentence-detokenized": "For a recommender system, sentiment analysis has proven to be a valuable technique.", "token2charspan": [[0, 3], [4, 5], [6, 17], [18, 24], [24, 25], [26, 35], [36, 44], [45, 48], [49, 55], [56, 58], [59, 61], [62, 63], [64, 72], [73, 82], [82, 83]]}
{"doc_key": "ai-test-418", "ner": [[3, 4, "misc"], [12, 12, "product"], [35, 35, "organisation"], [39, 40, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 12, 12, "usage", "", false, false], [35, 35, 39, 40, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["By", "chance", ",", "the", "Germans", "had", "chosen", "the", "operating", "frequency", "of", "the", "Wotan", "system", "very", "badly", ";", "it", "was", "operating", "at", "45", "MHz", ",", "which", "happened", "to", "be", "the", "frequency", "of", "the", "powerful", "but", "sleepy", "BBC", "television", "transmitter", "at", "Alexandra", "Palace", "."], "sentence-detokenized": "By chance, the Germans had chosen the operating frequency of the Wotan system very badly; it was operating at 45 MHz, which happened to be the frequency of the powerful but sleepy BBC television transmitter at Alexandra Palace.", "token2charspan": [[0, 2], [3, 9], [9, 10], [11, 14], [15, 22], [23, 26], [27, 33], [34, 37], [38, 47], [48, 57], [58, 60], [61, 64], [65, 70], [71, 77], [78, 82], [83, 88], [88, 89], [90, 92], [93, 96], [97, 106], [107, 109], [110, 112], [113, 116], [116, 117], [118, 123], [124, 132], [133, 135], [136, 138], [139, 142], [143, 152], [153, 155], [156, 159], [160, 168], [169, 172], [173, 179], [180, 183], [184, 194], [195, 206], [207, 209], [210, 219], [220, 226], [226, 227]]}
{"doc_key": "ai-test-419", "ner": [[8, 12, "metrics"], [16, 18, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "outcomes", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "in", "a", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four outcomes can be formulated in a 2 \u00d7 2 contingency table or in a confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 24], [25, 35], [36, 38], [39, 40], [41, 42], [43, 44], [45, 46], [47, 58], [59, 64], [65, 67], [68, 70], [71, 72], [73, 82], [83, 89], [90, 92], [93, 100], [100, 101]]}
{"doc_key": "ai-test-420", "ner": [[1, 3, "misc"], [8, 8, "misc"], [12, 12, "product"], [14, 14, "product"], [16, 18, "product"], [27, 27, "misc"], [42, 44, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 12, 8, 8, "usage", "", false, false], [14, 14, 8, 8, "usage", "", false, false], [16, 18, 14, 14, "named", "", false, false], [27, 27, 8, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "semantic", "web", "applications", "and", "in", "relatively", "popular", "RDF", "applications", "such", "as", "RSS", "and", "FOAF", "(", "Friend", "a", "Friend", ")", ",", "resources", "tend", "to", "be", "represented", "by", "URIs", "which", "are", "intentionally", "denoted", "and", "can", "be", "used", "to", "access", "real", "data", "on", "the", "World", "Wide", "Web", "."], "sentence-detokenized": "In semantic web applications and in relatively popular RDF applications such as RSS and FOAF (Friend a Friend), resources tend to be represented by URIs which are intentionally denoted and can be used to access real data on the World Wide Web.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 28], [29, 32], [33, 35], [36, 46], [47, 54], [55, 58], [59, 71], [72, 76], [77, 79], [80, 83], [84, 87], [88, 92], [93, 94], [94, 100], [101, 102], [103, 109], [109, 110], [110, 111], [112, 121], [122, 126], [127, 129], [130, 132], [133, 144], [145, 147], [148, 152], [153, 158], [159, 162], [163, 176], [177, 184], [185, 188], [189, 192], [193, 195], [196, 200], [201, 203], [204, 210], [211, 215], [216, 220], [221, 223], [224, 227], [228, 233], [234, 238], [239, 242], [242, 243]]}
{"doc_key": "ai-test-421", "ner": [[0, 7, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "has", "studied", "this", "topic", "in", "depth"], "sentence-detokenized": "The Association for the Advancement of Artificial Intelligence has studied this topic in depth", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 23], [24, 35], [36, 38], [39, 49], [50, 62], [63, 66], [67, 74], [75, 79], [80, 85], [86, 88], [89, 94]]}
{"doc_key": "ai-test-422", "ner": [[5, 9, "product"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 16, 5, 9, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Starting", "with", "a", "curiosity", ",", "Apple", "Macintosh", "'s", "speech", "system", "has", "evolved", "into", "a", "fully", "supported", "PlainTalk", "program", "for", "the", "visually", "impaired", "."], "sentence-detokenized": "Starting with a curiosity, Apple Macintosh's speech system has evolved into a fully supported PlainTalk program for the visually impaired.", "token2charspan": [[0, 8], [9, 13], [14, 15], [16, 25], [25, 26], [27, 32], [33, 42], [42, 44], [45, 51], [52, 58], [59, 62], [63, 70], [71, 75], [76, 77], [78, 83], [84, 93], [94, 103], [104, 111], [112, 115], [116, 119], [120, 128], [129, 137], [137, 138]]}
{"doc_key": "ai-test-423", "ner": [[7, 7, "field"], [9, 10, "task"], [12, 13, "task"], [15, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 7, 7, "part-of", "task_part_of_field", false, false], [12, 13, 7, 7, "part-of", "task_part_of_field", false, false], [15, 16, 7, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Other", "areas", "of", "use", "of", "ontologies", "in", "NLP", "include", "information", "retrieval", ",", "information", "extraction", "and", "automatic", "summarisation", "."], "sentence-detokenized": "Other areas of use of ontologies in NLP include information retrieval, information extraction and automatic summarisation.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 18], [19, 21], [22, 32], [33, 35], [36, 39], [40, 47], [48, 59], [60, 69], [69, 70], [71, 82], [83, 93], [94, 97], [98, 107], [108, 121], [121, 122]]}
{"doc_key": "ai-test-424", "ner": [[7, 14, "organisation"], [17, 21, "organisation"], [24, 27, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Institute", "has", "worked", "closely", "with", "the", "Janelia", "Farm", "Campus", "of", "Howard", "Hughes", "Medical", "Institute", ",", "the", "Allen", "Institute", "for", "Brain", "Science", "and", "the", "National", "Institutes", "of", "Health", "to", "develop", "better", "methods", "for", "reconstructing", "neural", "architectures", "."], "sentence-detokenized": "The Institute has worked closely with the Janelia Farm Campus of Howard Hughes Medical Institute, the Allen Institute for Brain Science and the National Institutes of Health to develop better methods for reconstructing neural architectures.", "token2charspan": [[0, 3], [4, 13], [14, 17], [18, 24], [25, 32], [33, 37], [38, 41], [42, 49], [50, 54], [55, 61], [62, 64], [65, 71], [72, 78], [79, 86], [87, 96], [96, 97], [98, 101], [102, 107], [108, 117], [118, 121], [122, 127], [128, 135], [136, 139], [140, 143], [144, 152], [153, 163], [164, 166], [167, 173], [174, 176], [177, 184], [185, 191], [192, 199], [200, 203], [204, 218], [219, 225], [226, 239], [239, 240]]}
{"doc_key": "ai-test-425", "ner": [[2, 2, "organisation"], [5, 6, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 2, 2, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Recently", ",", "Google", "announced", "that", "Google", "Translate", "translates", "approximately", "enough", "text", "to", "fill", "1", "million", "books", "in", "a", "single", "day", "(", "2012", ")", "."], "sentence-detokenized": "Recently, Google announced that Google Translate translates approximately enough text to fill 1 million books in a single day (2012).", "token2charspan": [[0, 8], [8, 9], [10, 16], [17, 26], [27, 31], [32, 38], [39, 48], [49, 59], [60, 73], [74, 80], [81, 85], [86, 88], [89, 93], [94, 95], [96, 103], [104, 109], [110, 112], [113, 114], [115, 121], [122, 125], [126, 127], [127, 131], [131, 132], [132, 133]]}
{"doc_key": "ai-test-426", "ner": [[15, 15, "country"], [17, 17, "country"], [19, 19, "country"], [21, 21, "country"], [23, 23, "country"], [25, 27, "country"], [37, 38, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "event", "s", "take", "place", "all", "over", "the", "world", "and", "are", "most", "popular", "in", "the", "UK", ",", "USA", ",", "Japan", ",", "Singapore", ",", "India", ",", "South", "Korea", "and", "are", "also", "becoming", "popular", "in", "subcontinent", "countries", "such", "as", "Sri", "Lanka", "."], "sentence-detokenized": "The events take place all over the world and are most popular in the UK, USA, Japan, Singapore, India, South Korea and are also becoming popular in subcontinent countries such as Sri Lanka.", "token2charspan": [[0, 3], [4, 9], [9, 10], [11, 15], [16, 21], [22, 25], [26, 30], [31, 34], [35, 40], [41, 44], [45, 48], [49, 53], [54, 61], [62, 64], [65, 68], [69, 71], [71, 72], [73, 76], [76, 77], [78, 83], [83, 84], [85, 94], [94, 95], [96, 101], [101, 102], [103, 108], [109, 114], [115, 118], [119, 122], [123, 127], [128, 136], [137, 144], [145, 147], [148, 160], [161, 170], [171, 175], [176, 178], [179, 182], [183, 188], [188, 189]]}
{"doc_key": "ai-test-427", "ner": [[6, 6, "programlang"], [10, 10, "programlang"], [12, 12, "programlang"], [14, 15, "programlang"], [17, 17, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "packages", "are", "mainly", "developed", "in", "R", "and", "sometimes", "in", "Java", ",", "C", ",", "C", "++", "and", "Fortran", "."], "sentence-detokenized": "These packages are mainly developed in R and sometimes in Java, C, C++ and Fortran.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 25], [26, 35], [36, 38], [39, 40], [41, 44], [45, 54], [55, 57], [58, 62], [62, 63], [64, 65], [65, 66], [67, 68], [68, 70], [71, 74], [75, 82], [82, 83]]}
{"doc_key": "ai-test-428", "ner": [[2, 7, "conference"], [9, 9, "conference"], [12, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"], [21, 22, "algorithm"], [26, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 9, 2, 7, "named", "", false, false], [12, 12, 2, 7, "physical", "", false, false], [12, 12, 2, 7, "role", "", false, false], [12, 12, 17, 18, "role", "teams_up_with", false, false], [12, 12, 21, 22, "usage", "", false, false], [14, 15, 2, 7, "physical", "", false, false], [14, 15, 2, 7, "role", "", false, false], [14, 15, 17, 18, "role", "teams_up_with", false, false], [14, 15, 21, 22, "usage", "", false, false], [17, 18, 2, 7, "physical", "", false, false], [17, 18, 2, 7, "role", "", false, false], [17, 18, 21, 22, "usage", "", false, false], [21, 22, 26, 32, "related-to", "used_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["At", "the", "2006", "European", "Conference", "on", "Computer", "Vision", "(", "ECCV", ")", ",", "Dalal", "and", "Triggs", "collaborated", "with", "Cordelia", "Schmid", "to", "apply", "HOG", "detectors", "to", "the", "problem", "of", "detecting", "people", "in", "movies", "and", "videos", "."], "sentence-detokenized": "At the 2006 European Conference on Computer Vision (ECCV), Dalal and Triggs collaborated with Cordelia Schmid to apply HOG detectors to the problem of detecting people in movies and videos.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 20], [21, 31], [32, 34], [35, 43], [44, 50], [51, 52], [52, 56], [56, 57], [57, 58], [59, 64], [65, 68], [69, 75], [76, 88], [89, 93], [94, 102], [103, 109], [110, 112], [113, 118], [119, 122], [123, 132], [133, 135], [136, 139], [140, 147], [148, 150], [151, 160], [161, 167], [168, 170], [171, 177], [178, 181], [182, 188], [188, 189]]}
{"doc_key": "ai-test-429", "ner": [[3, 3, "metrics"], [5, 7, "metrics"], [11, 12, "task"], [19, 21, "metrics"], [23, 23, "metrics"], [29, 29, "metrics"], [20, 35, "metrics"], [37, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 3, 11, 12, "related-to", "measured_with", false, false], [5, 7, 11, 12, "related-to", "measured_with", false, false], [19, 21, 11, 12, "related-to", "measured_with", false, false], [23, 23, 19, 21, "named", "", false, false], [29, 29, 19, 21, "named", "", false, false], [37, 37, 20, 35, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "addition", "to", "sensitivity", "and", "specificity", ",", "the", "performance", "of", "a", "binary", "classification", "test", "can", "be", "measured", "by", "the", "positive", "predictive", "value", "(", "PPV", ")", ",", "also", "known", "as", "accuracy", ",", "and", "the", "negative", "predictive", "value", "(", "NPV", ")", "."], "sentence-detokenized": "In addition to sensitivity and specificity, the performance of a binary classification test can be measured by the positive predictive value (PPV), also known as accuracy, and the negative predictive value (NPV).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 42], [42, 43], [44, 47], [48, 59], [60, 62], [63, 64], [65, 71], [72, 86], [87, 91], [92, 95], [96, 98], [99, 107], [108, 110], [111, 114], [115, 123], [124, 134], [135, 140], [141, 142], [142, 145], [145, 146], [146, 147], [148, 152], [153, 158], [159, 161], [162, 170], [170, 171], [172, 175], [176, 179], [180, 188], [189, 199], [200, 205], [206, 207], [207, 210], [210, 211], [211, 212]]}
{"doc_key": "ai-test-430", "ner": [[13, 16, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "models", "may", "give", "partial", "credit", "for", "overlapping", "correspondences", "(", "such", "as", "using", "the", "Jaccard", "index", "criterion", "."], "sentence-detokenized": "Such models may give partial credit for overlapping correspondences (such as using the Jaccard index criterion.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 28], [29, 35], [36, 39], [40, 51], [52, 67], [68, 69], [69, 73], [74, 76], [77, 82], [83, 86], [87, 94], [95, 100], [101, 110], [110, 111]]}
{"doc_key": "ai-test-431", "ner": [[9, 28, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Furthermore", ",", "in", "the", "case", "of", "single", "-", "sample", "estimation", ",", "it", "demonstrates", "the", "philosophical", "problems", "and", "possible", "misunderstandings", "in", "the", "use", "of", "maximum", "likelihood", "estimators", "and", "likelihood", "functions", "."], "sentence-detokenized": "Furthermore, in the case of single-sample estimation, it demonstrates the philosophical problems and possible misunderstandings in the use of maximum likelihood estimators and likelihood functions.", "token2charspan": [[0, 11], [11, 12], [13, 15], [16, 19], [20, 24], [25, 27], [28, 34], [34, 35], [35, 41], [42, 52], [52, 53], [54, 56], [57, 69], [70, 73], [74, 87], [88, 96], [97, 100], [101, 109], [110, 127], [128, 130], [131, 134], [135, 138], [139, 141], [142, 149], [150, 160], [161, 171], [172, 175], [176, 186], [187, 196], [196, 197]]}
