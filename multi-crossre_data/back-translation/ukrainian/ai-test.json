{"doc_key": "ai-test-1", "ner": [[6, 8, "algorithm"], [10, 11, "algorithm"], [14, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typical", "approaches", "to", "generative", "models", "include", "naive", "Bayesian", "classifiers", ",", "Gaussian", "mixture", "models", ",", "variational", "autoencoders", "and", "others", "."], "sentence-detokenized": "Typical approaches to generative models include naive Bayesian classifiers, Gaussian mixture models, variational autoencoders and others.", "token2charspan": [[0, 7], [8, 18], [19, 21], [22, 32], [33, 39], [40, 47], [48, 53], [54, 62], [63, 74], [74, 75], [76, 84], [85, 92], [93, 99], [99, 100], [101, 112], [113, 125], [126, 129], [130, 136], [136, 137]]}
{"doc_key": "ai-test-2", "ner": [[5, 5, "organisation"], [10, 10, "conference"], [13, 19, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 10, 10, "role", "", false, false], [13, 19, 10, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Finally", ",", "every", "two", "years", "ELRA", "organizes", "a", "major", "conference", "LREC", ",", "the", "International", "Conference", "on", "Language", "Resources", "and", "Evaluation", "."], "sentence-detokenized": "Finally, every two years ELRA organizes a major conference LREC, the International Conference on Language Resources and Evaluation.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 18], [19, 24], [25, 29], [30, 39], [40, 41], [42, 47], [48, 58], [59, 63], [63, 64], [65, 68], [69, 82], [83, 93], [94, 96], [97, 105], [106, 115], [116, 119], [120, 130], [130, 131]]}
{"doc_key": "ai-test-3", "ner": [[7, 13, "algorithm"], [14, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Usually", "the", "task", "is", "to", "obtain", "an", "estimate", "of", "the", "maximum", "likelihood", "of", "the", "GMM", "parameters", "from", "the", "given", "output", "sequences", "."], "sentence-detokenized": "Usually the task is to obtain an estimate of the maximum likelihood of the GMM parameters from the given output sequences.", "token2charspan": [[0, 7], [8, 11], [12, 16], [17, 19], [20, 22], [23, 29], [30, 32], [33, 41], [42, 44], [45, 48], [49, 56], [57, 67], [68, 70], [71, 74], [75, 78], [79, 89], [90, 94], [95, 98], [99, 104], [105, 111], [112, 121], [121, 122]]}
{"doc_key": "ai-test-4", "ner": [[1, 1, "algorithm"], [4, 6, "algorithm"], [8, 9, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 8, 9, "compare", "", false, false], [4, 6, 8, 9, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Unlike", "neural", "networks", "and", "support", "vector", "machines", ",", "AdaBoost", "'s", "learning", "process", "selects", "only", "those", "features", "that", "are", "known", "to", "improve", "the", "predictive", "ability", "of", "the", "model", ",", "reducing", "dimensionality", "and", "potentially", "improving", "runtime", ",", "as", "irrelevant", "features", "do", "not", "need", "to", "be", "computed", "."], "sentence-detokenized": "Unlike neural networks and support vector machines, AdaBoost's learning process selects only those features that are known to improve the predictive ability of the model, reducing dimensionality and potentially improving runtime, as irrelevant features do not need to be computed.", "token2charspan": [[0, 6], [7, 13], [14, 22], [23, 26], [27, 34], [35, 41], [42, 50], [50, 51], [52, 60], [60, 62], [63, 71], [72, 79], [80, 87], [88, 92], [93, 98], [99, 107], [108, 112], [113, 116], [117, 122], [123, 125], [126, 133], [134, 137], [138, 148], [149, 156], [157, 159], [160, 163], [164, 169], [169, 170], [171, 179], [180, 194], [195, 198], [199, 210], [211, 220], [221, 228], [228, 229], [230, 232], [233, 243], [244, 252], [253, 255], [256, 259], [260, 264], [265, 267], [268, 270], [271, 279], [279, 280]]}
{"doc_key": "ai-test-5", "ner": [[0, 1, "misc"], [11, 14, "misc"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 11, 14, "part-of", "", false, false], [11, 14, 15, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Troponymy", "is", "one", "of", "the", "possible", "connections", "between", "verbs", "in", "the", "semantic", "network", "of", "the", "Word", "Net", "database", "."], "sentence-detokenized": "Troponymy is one of the possible connections between verbs in the semantic network of the WordNet database.", "token2charspan": [[0, 9], [10, 12], [13, 16], [17, 19], [20, 23], [24, 32], [33, 44], [45, 52], [53, 58], [59, 61], [62, 65], [66, 74], [75, 82], [83, 85], [86, 89], [90, 94], [94, 97], [98, 106], [106, 107]]}
{"doc_key": "ai-test-6", "ner": [[7, 8, "task"], [10, 11, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Frame", "language", "is", "a", "technology", "used", "to", "represent", "knowledge", "in", "artificial", "intelligence", "."], "sentence-detokenized": "Frame language is a technology used to represent knowledge in artificial intelligence.", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 19], [20, 30], [31, 35], [36, 38], [39, 48], [49, 58], [59, 61], [62, 72], [73, 85], [85, 86]]}
{"doc_key": "ai-test-7", "ner": [[0, 0, "metrics"], [5, 7, "metrics"], [13, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 5, 7, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "the", "bilingual", "evaluation", "understudy", "in", "its", "calculation", "of", "the", "brevity", "penalty", "because", "small", "deviations", "in", "the", "amount", "of", "translation", "do", "not", "affect", "the", "overall", "score", "as", "much", "."], "sentence-detokenized": "NIST also differs from the bilingual evaluation understudy in its calculation of the brevity penalty because small deviations in the amount of translation do not affect the overall score as much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 26], [27, 36], [37, 47], [48, 58], [59, 61], [62, 65], [66, 77], [78, 80], [81, 84], [85, 92], [93, 100], [101, 108], [109, 114], [115, 125], [126, 128], [129, 132], [133, 139], [140, 142], [143, 154], [155, 157], [158, 161], [162, 168], [169, 172], [173, 180], [181, 186], [187, 189], [190, 194], [194, 195]]}
{"doc_key": "ai-test-8", "ner": [[14, 15, "algorithm"], [17, 21, "algorithm"], [29, 30, "field"], [39, 40, "algorithm"], [42, 44, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 15, 29, 30, "usage", "", false, false], [17, 21, 29, 30, "usage", "", false, false], [39, 40, 29, 30, "type-of", "", false, false], [42, 44, 29, 30, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "model", "is", "first", "fitted", "to", "the", "training", "dataset", ",", "The", "model", "(", "e.g.", "neural", "network", "or", "naive", "Bayesian", "classifier", ")", "is", "trained", "on", "the", "training", "dataset", "using", "a", "supervised", "learning", "method", ",", "e.g.", "using", "optimization", "techniques", "such", "as", "gradient", "descent", "or", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The model is first fitted to the training dataset, The model (e.g. neural network or naive Bayesian classifier) is trained on the training dataset using a supervised learning method, e.g. using optimization techniques such as gradient descent or stochastic gradient descent.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 18], [19, 25], [26, 28], [29, 32], [33, 41], [42, 49], [49, 50], [51, 54], [55, 60], [61, 62], [62, 66], [67, 73], [74, 81], [82, 84], [85, 90], [91, 99], [100, 110], [110, 111], [112, 114], [115, 122], [123, 125], [126, 129], [130, 138], [139, 146], [147, 152], [153, 154], [155, 165], [166, 174], [175, 181], [181, 182], [183, 187], [188, 193], [194, 206], [207, 217], [218, 222], [223, 225], [226, 234], [235, 242], [243, 245], [246, 256], [257, 265], [266, 273], [273, 274]]}
{"doc_key": "ai-test-9", "ner": [[0, 1, "product"], [8, 9, "task"], [11, 11, "task"], [13, 15, "task"], [18, 19, "task"], [25, 27, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 0, 1, "usage", "", true, false], [11, 11, 0, 1, "usage", "", true, false], [13, 15, 0, 1, "usage", "", true, false], [18, 19, 0, 1, "usage", "", true, false], [25, 27, 0, 1, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Frame", "Net", "is", "used", "in", "applications", "such", "as", "question", "answering", ",", "paraphrasing", ",", "text", "relationship", "recognition", ",", "and", "information", "extraction", ",", "either", "directly", "or", "through", "semantic", "role", "labeling", "tools", "."], "sentence-detokenized": "FrameNet is used in applications such as question answering, paraphrasing, text relationship recognition, and information extraction, either directly or through semantic role labeling tools.", "token2charspan": [[0, 5], [5, 8], [9, 11], [12, 16], [17, 19], [20, 32], [33, 37], [38, 40], [41, 49], [50, 59], [59, 60], [61, 73], [73, 74], [75, 79], [80, 92], [93, 104], [104, 105], [106, 109], [110, 121], [122, 132], [132, 133], [134, 140], [141, 149], [150, 152], [153, 160], [161, 169], [170, 174], [175, 183], [184, 189], [189, 190]]}
{"doc_key": "ai-test-10", "ner": [[5, 6, "field"], [11, 11, "misc"], [14, 14, "product"], [17, 17, "misc"], [20, 20, "product"], [23, 24, "field"], [27, 27, "product"], [30, 32, "misc"], [35, 35, "product"], [37, 37, "product"], [39, 39, "product"], [42, 43, "misc"], [46, 47, "product"], [49, 50, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[14, 14, 11, 11, "general-affiliation", "", false, false], [20, 20, 17, 17, "general-affiliation", "", false, false], [27, 27, 23, 24, "general-affiliation", "", false, false], [35, 35, 30, 32, "type-of", "", false, false], [37, 37, 30, 32, "type-of", "", false, false], [39, 39, 30, 32, "type-of", "", false, false], [46, 47, 42, 43, "general-affiliation", "", false, false], [49, 50, 42, 43, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["This", "includes", "applications", "such", "as", "data", "analysis", "and", "extraction", "tools", ",", "spreadsheets", "(", "e.g.", "Excel", ")", ",", "databases", "(", "e.g.", "Access", ")", ",", "statistical", "analysis", "(", "e.g.", "SAS", ")", ",", "generalized", "audit", "software", "(", "e.g.", "ACL", ",", "Arbutus", ",", "EAS", ")", ",", "business", "intelligence", "(", "e.g.", "Crystal", "Reports", "and", "Business", "Objects", ")", ",", "etc", "."], "sentence-detokenized": "This includes applications such as data analysis and extraction tools, spreadsheets (e.g. Excel), databases (e.g. Access), statistical analysis (e.g. SAS), generalized audit software (e.g. ACL, Arbutus, EAS), business intelligence (e.g. Crystal Reports and Business Objects), etc.", "token2charspan": [[0, 4], [5, 13], [14, 26], [27, 31], [32, 34], [35, 39], [40, 48], [49, 52], [53, 63], [64, 69], [69, 70], [71, 83], [84, 85], [85, 89], [90, 95], [95, 96], [96, 97], [98, 107], [108, 109], [109, 113], [114, 120], [120, 121], [121, 122], [123, 134], [135, 143], [144, 145], [145, 149], [150, 153], [153, 154], [154, 155], [156, 167], [168, 173], [174, 182], [183, 184], [184, 188], [189, 192], [192, 193], [194, 201], [201, 202], [203, 206], [206, 207], [207, 208], [209, 217], [218, 230], [231, 232], [232, 236], [237, 244], [245, 252], [253, 256], [257, 265], [266, 273], [273, 274], [274, 275], [276, 279], [279, 280]]}
{"doc_key": "ai-test-11", "ner": [[0, 1, "organisation"], [5, 8, "researcher"], [12, 12, "organisation"], [15, 15, "product"], [22, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 8, "origin", "", false, false], [5, 8, 12, 12, "role", "", false, false], [15, 15, 22, 23, "type-of", "", false, false], [22, 23, 5, 8, "origin", "introduced_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Rethink", "Robotics", ",", "founded", "by", "Rodney", "Brooks", ",", "who", "previously", "worked", "with", "iRobot", ",", "introduced", "Baxter", "in", "September", "2012", ";", "as", "an", "industrial", "robot", "designed", "to", "interact", "safely", "with", "nearby", "human", "workers", ",", "and", "can", "be", "programmed", "to", "perform", "simple", "tasks", "."], "sentence-detokenized": "Rethink Robotics, founded by Rodney Brooks, who previously worked with iRobot, introduced Baxter in September 2012; as an industrial robot designed to interact safely with nearby human workers, and can be programmed to perform simple tasks.", "token2charspan": [[0, 7], [8, 16], [16, 17], [18, 25], [26, 28], [29, 35], [36, 42], [42, 43], [44, 47], [48, 58], [59, 65], [66, 70], [71, 77], [77, 78], [79, 89], [90, 96], [97, 99], [100, 109], [110, 114], [114, 115], [116, 118], [119, 121], [122, 132], [133, 138], [139, 147], [148, 150], [151, 159], [160, 166], [167, 171], [172, 178], [179, 184], [185, 192], [192, 193], [194, 197], [198, 201], [202, 204], [205, 215], [216, 218], [219, 226], [227, 233], [234, 239], [239, 240]]}
{"doc_key": "ai-test-12", "ner": [[3, 4, "field"], [6, 7, "task"], [9, 10, "task"], [12, 15, "task"], [17, 20, "task"], [22, 23, "task"], [25, 26, "task"], [29, 31, "task"], [39, 41, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[6, 7, 3, 4, "part-of", "task_part_of_field", false, false], [9, 10, 3, 4, "part-of", "task_part_of_field", false, false], [12, 15, 3, 4, "part-of", "task_part_of_field", false, false], [17, 20, 3, 4, "part-of", "task_part_of_field", false, false], [22, 23, 3, 4, "part-of", "task_part_of_field", false, false], [25, 26, 3, 4, "part-of", "task_part_of_field", false, false], [29, 31, 3, 4, "part-of", "task_part_of_field", false, false], [39, 41, 3, 4, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Typical", "tasks", "in", "text", "mining", "include", "text", "categorization", ",", "text", "clustering", ",", "concept", "/", "entity", "extraction", ",", "creation", "of", "granular", "taxonomies", ",", "sentiment", "analysis", ",", "document", "summarization", ",", "and", "entity", "relationship", "modeling", "(", "i.e.", ",", "learning", "the", "relationships", "between", "named", "entity", "recognition", ")", "."], "sentence-detokenized": "Typical tasks in text mining include text categorization, text clustering, concept/entity extraction, creation of granular taxonomies, sentiment analysis, document summarization, and entity relationship modeling (i.e., learning the relationships between named entity recognition).", "token2charspan": [[0, 7], [8, 13], [14, 16], [17, 21], [22, 28], [29, 36], [37, 41], [42, 56], [56, 57], [58, 62], [63, 73], [73, 74], [75, 82], [82, 83], [83, 89], [90, 100], [100, 101], [102, 110], [111, 113], [114, 122], [123, 133], [133, 134], [135, 144], [145, 153], [153, 154], [155, 163], [164, 177], [177, 178], [179, 182], [183, 189], [190, 202], [203, 211], [212, 213], [213, 217], [217, 218], [219, 227], [228, 231], [232, 245], [246, 253], [254, 259], [260, 266], [267, 278], [278, 279], [279, 280]]}
{"doc_key": "ai-test-13", "ner": [[5, 5, "metrics"], [7, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "clipping", "reduces", "the", "accuracy", "or", "true", "negative", "rate", "for", "such", "systems", "."], "sentence-detokenized": "However, clipping reduces the accuracy or true negative rate for such systems.", "token2charspan": [[0, 7], [7, 8], [9, 17], [18, 25], [26, 29], [30, 38], [39, 41], [42, 46], [47, 55], [56, 60], [61, 64], [65, 69], [70, 77], [77, 78]]}
{"doc_key": "ai-test-14", "ner": [[4, 4, "task"], [7, 10, "misc"], [16, 21, "misc"], [29, 29, "product"], [31, 31, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 10, 4, 4, "temporal", "", false, false], [16, 21, 7, 10, "named", "", false, false], [29, 29, 7, 10, "usage", "", false, false], [31, 31, 7, 10, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "special", "case", "of", "keyword", "detection", "is", "wake", "-", "up", "word", "detection", "(", "also", "called", "\"", "hotword", "\"", ")", ",", "which", "is", "used", "by", "personal", "digital", "assistants", "such", "as", "Alexa", "or", "Siri", "to", "wake", "up", "when", "their", "name", "is", "spoken", "."], "sentence-detokenized": "A special case of keyword detection is wake-up word detection (also called \"hotword\"), which is used by personal digital assistants such as Alexa or Siri to wake up when their name is spoken.", "token2charspan": [[0, 1], [2, 9], [10, 14], [15, 17], [18, 25], [26, 35], [36, 38], [39, 43], [43, 44], [44, 46], [47, 51], [52, 61], [62, 63], [63, 67], [68, 74], [75, 76], [76, 83], [83, 84], [84, 85], [85, 86], [87, 92], [93, 95], [96, 100], [101, 103], [104, 112], [113, 120], [121, 131], [132, 136], [137, 139], [140, 145], [146, 148], [149, 153], [154, 156], [157, 161], [162, 164], [165, 169], [170, 175], [176, 180], [181, 183], [184, 190], [190, 191]]}
{"doc_key": "ai-test-15", "ner": [[0, 0, "programlang"], [9, 9, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 0, 0, "part-of", "", false, false], [11, 11, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prova", "is", "an", "open", "source", "programming", "language", "that", "combines", "Prolog", "and", "Java", "."], "sentence-detokenized": "Prova is an open source programming language that combines Prolog and Java.", "token2charspan": [[0, 5], [6, 8], [9, 11], [12, 16], [17, 23], [24, 35], [36, 44], [45, 49], [50, 58], [59, 65], [66, 69], [70, 74], [74, 75]]}
{"doc_key": "ai-test-16", "ner": [[3, 4, "organisation"], [9, 11, "organisation"], [16, 18, "product"], [27, 29, "country"], [34, 34, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[3, 4, 9, 11, "part-of", "", false, false], [3, 4, 9, 11, "role", "sells", false, false], [3, 4, 27, 29, "role", "sells_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1987", ",", "Tocibai", "Machine", ",", "a", "subsidiary", "of", "Toshiba", ",", "was", "accused", "of", "illegally", "selling", "CNC", "milling", "machines", "used", "to", "produce", "very", "quiet", "submarine", "propellers", "to", "the", "Soviet", "Union", "in", "violation", "of", "the", "CoCom", "agreement", ",", "an", "international", "embargo", "on", "the", "supply", "of", "certain", "goods", "to", "the", "member", "countries", "of", "the", "CMEA", "."], "sentence-detokenized": "In 1987, Tocibai Machine, a subsidiary of Toshiba, was accused of illegally selling CNC milling machines used to produce very quiet submarine propellers to the Soviet Union in violation of the CoCom agreement, an international embargo on the supply of certain goods to the member countries of the CMEA.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 24], [24, 25], [26, 27], [28, 38], [39, 41], [42, 49], [49, 50], [51, 54], [55, 62], [63, 65], [66, 75], [76, 83], [84, 87], [88, 95], [96, 104], [105, 109], [110, 112], [113, 120], [121, 125], [126, 131], [132, 141], [142, 152], [153, 155], [156, 159], [160, 166], [167, 172], [173, 175], [176, 185], [186, 188], [189, 192], [193, 198], [199, 208], [208, 209], [210, 212], [213, 226], [227, 234], [235, 237], [238, 241], [242, 248], [249, 251], [252, 259], [260, 265], [266, 268], [269, 272], [273, 279], [280, 289], [290, 292], [293, 296], [297, 301], [301, 302]]}
{"doc_key": "ai-test-17", "ner": [[0, 7, "researcher"], [8, 11, "product"], [23, 26, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 11, 0, 7, "artifact", "", false, false], [8, 11, 23, 26, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Engelberger", "'s", "most", "famous", "joint", "invention", ",", "the", "Unimate", "industrial", "robot", "manipulator", ",", "was", "one", "of", "the", "first", "to", "be", "inducted", "into", "the", "Robot", "Hall", "of", "Fame", "in", "2003", "."], "sentence-detokenized": "Engelberger's most famous joint invention, the Unimate industrial robot manipulator, was one of the first to be inducted into the Robot Hall of Fame in 2003.", "token2charspan": [[0, 11], [11, 13], [14, 18], [19, 25], [26, 31], [32, 41], [41, 42], [43, 46], [47, 54], [55, 65], [66, 71], [72, 83], [83, 84], [85, 88], [89, 92], [93, 95], [96, 99], [100, 105], [106, 108], [109, 111], [112, 120], [121, 125], [126, 129], [130, 135], [136, 140], [141, 143], [144, 148], [149, 151], [152, 156], [156, 157]]}
{"doc_key": "ai-test-18", "ner": [[3, 3, "misc"], [7, 7, "misc"], [9, 10, "person"], [20, 21, "field"], [17, 25, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 7, 7, "usage", "", false, false], [9, 10, 20, 21, "role", "", false, false], [20, 21, 17, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Initially", "driven", "by", "static", "html", "pages", "using", "CGI", ",", "Dalton", "'s", "work", "involved", "the", "implementation", "of", "a", "Java", "-", "based", "augmented", "reality", "interface", ",", "which", "had", "limited", "success", "."], "sentence-detokenized": "Initially driven by static html pages using CGI, Dalton's work involved the implementation of a Java-based augmented reality interface, which had limited success.", "token2charspan": [[0, 9], [10, 16], [17, 19], [20, 26], [27, 31], [32, 37], [38, 43], [44, 47], [47, 48], [49, 55], [55, 57], [58, 62], [63, 71], [72, 75], [76, 90], [91, 93], [94, 95], [96, 100], [100, 101], [101, 106], [107, 116], [117, 124], [125, 134], [134, 135], [136, 141], [142, 145], [146, 153], [154, 161], [161, 162]]}
{"doc_key": "ai-test-19", "ner": [[5, 7, "task"], [12, 12, "organisation"], [30, 31, "conference"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[5, 7, 12, 12, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "publication", "on", "the", "LMF", "specification", "as", "it", "was", "ratified", "by", "ISO", "(", "this", "paper", "was", "(", "in", "2015", ")", "the", "9th", "most", "cited", "paper", "at", "LREC", "conferences", "on", "LREC", "papers", ")", ":"], "sentence-detokenized": "The first publication on the LMF specification as it was ratified by ISO (this paper was (in 2015) the 9th most cited paper at LREC conferences on LREC papers):", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 24], [25, 28], [29, 32], [33, 46], [47, 49], [50, 52], [53, 56], [57, 65], [66, 68], [69, 72], [73, 74], [74, 78], [79, 84], [85, 88], [89, 90], [90, 92], [93, 97], [97, 98], [99, 102], [103, 106], [107, 111], [112, 117], [118, 123], [124, 126], [127, 131], [132, 143], [144, 146], [147, 151], [152, 158], [158, 159], [159, 160]]}
{"doc_key": "ai-test-20", "ner": [[0, 1, "metrics"], [14, 15, "metrics"], [16, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 15, 0, 1, "usage", "", false, false], [14, 15, 16, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Confusion", "matrix", "or", "correspondence", "matrix", "is", "often", "used", "as", "a", "tool", "to", "check", "the", "accuracy", "of", "k", "-", "NN", "classification", "."], "sentence-detokenized": "Confusion matrix or correspondence matrix is often used as a tool to check the accuracy of k -NN classification.", "token2charspan": [[0, 9], [10, 16], [17, 19], [20, 34], [35, 41], [42, 44], [45, 50], [51, 55], [56, 58], [59, 60], [61, 65], [66, 68], [69, 74], [75, 78], [79, 87], [88, 90], [91, 92], [93, 94], [94, 96], [97, 111], [111, 112]]}
{"doc_key": "ai-test-21", "ner": [[0, 1, "algorithm"], [12, 12, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 12, 12, "part-of", "", false, false], [0, 1, 14, 15, "part-of", "", false, false], [0, 1, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", "is", "one", "of", "the", "predictive", "modeling", "approaches", "used", "in", "statistics", ",", "data", "mining", "and", "machine", "learning", "."], "sentence-detokenized": "Decision tree learning is one of the predictive modeling approaches used in statistics, data mining and machine learning.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 47], [48, 56], [57, 67], [68, 72], [73, 75], [76, 86], [86, 87], [88, 92], [93, 99], [100, 103], [104, 111], [112, 120], [120, 121]]}
{"doc_key": "ai-test-22", "ner": [[6, 7, "misc"], [14, 15, "field"], [19, 21, "algorithm"], [23, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 7, 14, 15, "related-to", "", true, false], [19, 21, 14, 15, "type-of", "", false, false], [23, 23, 14, 15, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["At", "runtime", ",", "a", "target", "sentence", "prosody", "is", "superimposed", "on", "these", "minimal", "units", "using", "signal", "processing", "techniques", "such", "as", "linear", "predictive", "coding", ",", "PSOLA"], "sentence-detokenized": "At runtime, a target sentence prosody is superimposed on these minimal units using signal processing techniques such as linear predictive coding, PSOLA", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 13], [14, 20], [21, 29], [30, 37], [38, 40], [41, 53], [54, 56], [57, 62], [63, 70], [71, 76], [77, 82], [83, 89], [90, 100], [101, 111], [112, 116], [117, 119], [120, 126], [127, 137], [138, 144], [144, 145], [146, 151]]}
{"doc_key": "ai-test-23", "ner": [[3, 4, "field"], [6, 8, "field"], [17, 20, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 20, 3, 4, "usage", "", true, false], [17, 20, 6, 8, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "approach", "uses", "artificial", "intelligence", "and", "machine", "learning", "to", "allow", "researchers", "to", "visually", "compare", "conventional", "and", "thermal", "images", "of", "the", "face", "."], "sentence-detokenized": "This approach uses artificial intelligence and machine learning to allow researchers to visually compare conventional and thermal images of the face.", "token2charspan": [[0, 4], [5, 13], [14, 18], [19, 29], [30, 42], [43, 46], [47, 54], [55, 63], [64, 66], [67, 72], [73, 84], [85, 87], [88, 96], [97, 104], [105, 117], [118, 121], [122, 129], [130, 136], [137, 139], [140, 143], [144, 148], [148, 149]]}
{"doc_key": "ai-test-24", "ner": [[1, 2, "field"], [4, 6, "algorithm"], [10, 11, "task"], [15, 16, "misc"], [22, 23, "field"], [26, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 6, 1, 2, "part-of", "", false, false], [4, 6, 10, 11, "topic", "", false, false], [10, 11, 15, 16, "origin", "", false, false], [22, 23, 1, 2, "part-of", "", false, false], [22, 23, 4, 6, "topic", "", false, false], [26, 27, 1, 2, "part-of", "", false, false], [26, 27, 4, 6, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "computer", "science", ",", "evolutionary", "computation", "is", "a", "family", "of", "global", "optimization", "algorithms", "inspired", "by", "biological", "evolution", ",", "and", "a", "subfield", "of", "artificial", "intelligence", "and", "soft", "computing", "that", "studies", "these", "algorithms", "."], "sentence-detokenized": "In computer science, evolutionary computation is a family of global optimization algorithms inspired by biological evolution, and a subfield of artificial intelligence and soft computing that studies these algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 33], [34, 45], [46, 48], [49, 50], [51, 57], [58, 60], [61, 67], [68, 80], [81, 91], [92, 100], [101, 103], [104, 114], [115, 124], [124, 125], [126, 129], [130, 131], [132, 140], [141, 143], [144, 154], [155, 167], [168, 171], [172, 176], [177, 186], [187, 191], [192, 199], [200, 205], [206, 216], [216, 217]]}
{"doc_key": "ai-test-25", "ner": [[11, 12, "metrics"], [15, 18, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "one", "can", "combine", "some", "measure", "based", "on", "the", "confusion", "matrix", "with", "the", "root", "mean", "square", "error", "estimated", "between", "the", "model", "output", "and", "the", "actual", "values", "."], "sentence-detokenized": "For example, one can combine some measure based on the confusion matrix with the root mean square error estimated between the model output and the actual values.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 20], [21, 28], [29, 33], [34, 41], [42, 47], [48, 50], [51, 54], [55, 64], [65, 71], [72, 76], [77, 80], [81, 85], [86, 90], [91, 97], [98, 103], [104, 113], [114, 121], [122, 125], [126, 131], [132, 138], [139, 142], [143, 146], [147, 153], [154, 160], [160, 161]]}
{"doc_key": "ai-test-26", "ner": [[9, 9, "product"], [12, 12, "researcher"], [8, 8, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 12, 12, "origin", "", false, false], [9, 9, 8, 8, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Most", "of", "them", "are", "the", "results", "of", "the", "word2vec", "model", "developed", "by", "Nikolov", "et", "al", ".", "or", "its", "variants", "."], "sentence-detokenized": "Most of them are the results of the word2vec model developed by Nikolov et al. or its variants.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 16], [17, 20], [21, 28], [29, 31], [32, 35], [36, 44], [45, 50], [51, 60], [61, 63], [64, 71], [72, 74], [75, 77], [77, 78], [79, 81], [82, 85], [86, 94], [94, 95]]}
{"doc_key": "ai-test-27", "ner": [[12, 12, "conference"], [15, 19, "conference"], [21, 21, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[21, 21, 15, 19, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["During", "this", "time", ",", "a", "total", "of", "43", "publications", "were", "recognized", "by", "CVPR", "and", "the", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "."], "sentence-detokenized": "During this time, a total of 43 publications were recognized by CVPR and the International Conference on Computer Vision (ICCV).", "token2charspan": [[0, 6], [7, 11], [12, 16], [16, 17], [18, 19], [20, 25], [26, 28], [29, 31], [32, 44], [45, 49], [50, 60], [61, 63], [64, 68], [69, 72], [73, 76], [77, 90], [91, 101], [102, 104], [105, 113], [114, 120], [121, 122], [122, 126], [126, 127], [127, 128]]}
{"doc_key": "ai-test-28", "ner": [[0, 1, "product"], [18, 19, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 18, 19, "general-affiliation", "platform_for_education_about", false, false], [27, 28, 0, 1, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["AIBO", "is", "widely", "used", "as", "a", "low", "-", "cost", "platform", "for", "training", "and", "research", "in", "the", "field", "of", "artificial", "intelligence", ",", "as", "it", "integrates", "a", "computer", ",", "computer", "vision", "and", "articulators", "in", "a", "package", "that", "is", "significantly", "cheaper", "than", "conventional", "research", "robots", "."], "sentence-detokenized": "AIBO is widely used as a low-cost platform for training and research in the field of artificial intelligence, as it integrates a computer, computer vision and articulators in a package that is significantly cheaper than conventional research robots.", "token2charspan": [[0, 4], [5, 7], [8, 14], [15, 19], [20, 22], [23, 24], [25, 28], [28, 29], [29, 33], [34, 42], [43, 46], [47, 55], [56, 59], [60, 68], [69, 71], [72, 75], [76, 81], [82, 84], [85, 95], [96, 108], [108, 109], [110, 112], [113, 115], [116, 126], [127, 128], [129, 137], [137, 138], [139, 147], [148, 154], [155, 158], [159, 171], [172, 174], [175, 176], [177, 184], [185, 189], [190, 192], [193, 206], [207, 214], [215, 219], [220, 232], [233, 241], [242, 248], [248, 249]]}
{"doc_key": "ai-test-29", "ner": [[6, 12, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "was", "the", "program", "director", "of", "the", "International", "Conference", "on", "Computer", "Vision", "2021", "."], "sentence-detokenized": "She was the program director of the International Conference on Computer Vision 2021.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 19], [20, 28], [29, 31], [32, 35], [36, 49], [50, 60], [61, 63], [64, 72], [73, 79], [80, 84], [84, 85]]}
{"doc_key": "ai-test-30", "ner": [[0, 0, "researcher"], [7, 7, "organisation"], [16, 17, "organisation"], [27, 28, "organisation"], [37, 39, "product"], [42, 42, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 7, 7, "role", "", false, false], [0, 0, 16, 17, "role", "", true, false], [16, 17, 27, 28, "role", "develops_with", false, false], [37, 39, 16, 17, "artifact", "", false, false], [42, 42, 37, 39, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Sheinman", ",", "having", "received", "a", "scholarship", "from", "Unimation", "to", "develop", "his", "designs", ",", "sold", "these", "designs", "to", "Unimation", ",", "which", "continued", "their", "development", "with", "the", "support", "of", "General", "Motors", "and", "subsequently", "brought", "them", "to", "market", "as", "the", "Programmable", "Universal", "Assembly", "Machine", "(", "PUMA", ")", "."], "sentence-detokenized": "Sheinman, having received a scholarship from Unimation to develop his designs, sold these designs to Unimation, which continued their development with the support of General Motors and subsequently brought them to market as the Programmable Universal Assembly Machine (PUMA).", "token2charspan": [[0, 8], [8, 9], [10, 16], [17, 25], [26, 27], [28, 39], [40, 44], [45, 54], [55, 57], [58, 65], [66, 69], [70, 77], [77, 78], [79, 83], [84, 89], [90, 97], [98, 100], [101, 110], [110, 111], [112, 117], [118, 127], [128, 133], [134, 145], [146, 150], [151, 154], [155, 162], [163, 165], [166, 173], [174, 180], [181, 184], [185, 197], [198, 205], [206, 210], [211, 213], [214, 220], [221, 223], [224, 227], [228, 240], [241, 250], [251, 259], [260, 267], [268, 269], [269, 273], [273, 274], [274, 275]]}
{"doc_key": "ai-test-31", "ner": [[6, 6, "task"], [8, 12, "task"], [14, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 6, 6, "general-affiliation", "works_with", false, false], [14, 14, 8, 12, "general-affiliation", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "overview", "of", "calibration", "methods", "for", "binary", "and", "multiclass", "classification", "problems", "is", "given", "in", "Gebel", "(", "2009", ")"], "sentence-detokenized": "An overview of calibration methods for binary and multiclass classification problems is given in Gebel (2009)", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 34], [35, 38], [39, 45], [46, 49], [50, 60], [61, 75], [76, 84], [85, 87], [88, 93], [94, 96], [97, 102], [103, 104], [104, 108], [108, 109]]}
{"doc_key": "ai-test-32", "ner": [[7, 9, "task"], [11, 11, "task"], [14, 15, "task"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 7, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "involved", "in", "areas", "such", "as", "optical", "character", "recognition", "(", "OCR", ")", ",", "speech", "synthesis", ",", "speech", "recognition", "technologies", "and", "electronic", "keyboarding", "tools", "."], "sentence-detokenized": "He is involved in areas such as optical character recognition (OCR), speech synthesis, speech recognition technologies and electronic keyboarding tools.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 23], [24, 28], [29, 31], [32, 39], [40, 49], [50, 61], [62, 63], [63, 66], [66, 67], [67, 68], [69, 75], [76, 85], [85, 86], [87, 93], [94, 105], [106, 118], [119, 122], [123, 133], [134, 145], [146, 151], [151, 152]]}
{"doc_key": "ai-test-33", "ner": [[8, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "more", "modern", "and", "advanced", "techniques", ",", "the", "Kaldi", "toolkit", "can", "be", "used", "."], "sentence-detokenized": "For more modern and advanced techniques, the Kaldi toolkit can be used.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 19], [20, 28], [29, 39], [39, 40], [41, 44], [45, 50], [51, 58], [59, 62], [63, 65], [66, 70], [70, 71]]}
{"doc_key": "ai-test-34", "ner": [[0, 2, "researcher"], [8, 10, "organisation"], [16, 17, "organisation"], [23, 24, "organisation"], [30, 31, "researcher"], [32, 35, "organisation"], [42, 44, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 8, 10, "role", "", false, false], [0, 2, 16, 17, "role", "", false, false], [0, 2, 23, 24, "role", "", false, false], [0, 2, 32, 35, "role", "", false, false], [0, 2, 42, 44, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Johnson", "-", "Laird", "is", "a", "Fellow", "of", "the", "American", "Philosophical", "Society", ",", "a", "Fellow", "of", "the", "Royal", "Society", ",", "a", "Fellow", "of", "the", "British", "Academy", ",", "a", "Fellow", "of", "the", "William", "James", "Association", "for", "Psychological", "Science", ",", "and", "a", "Fellow", "of", "the", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Johnson-Laird is a Fellow of the American Philosophical Society, a Fellow of the Royal Society, a Fellow of the British Academy, a Fellow of the William James Association for Psychological Science, and a Fellow of the Cognitive Science Society.", "token2charspan": [[0, 7], [7, 8], [8, 13], [14, 16], [17, 18], [19, 25], [26, 28], [29, 32], [33, 41], [42, 55], [56, 63], [63, 64], [65, 66], [67, 73], [74, 76], [77, 80], [81, 86], [87, 94], [94, 95], [96, 97], [98, 104], [105, 107], [108, 111], [112, 119], [120, 127], [127, 128], [129, 130], [131, 137], [138, 140], [141, 144], [145, 152], [153, 158], [159, 170], [171, 174], [175, 188], [189, 196], [196, 197], [198, 201], [202, 203], [204, 210], [211, 213], [214, 217], [218, 227], [228, 235], [236, 243], [243, 244]]}
{"doc_key": "ai-test-35", "ner": [[3, 8, "conference"], [10, 11, "researcher"], [13, 14, "researcher"], [17, 18, "researcher"], [20, 22, "algorithm"], [26, 30, "task"], [32, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 11, 3, 8, "physical", "", false, false], [10, 11, 3, 8, "temporal", "", false, false], [13, 14, 3, 8, "physical", "", false, false], [13, 14, 3, 8, "temporal", "", false, false], [17, 18, 3, 8, "physical", "", false, false], [17, 18, 3, 8, "temporal", "", false, false], [20, 22, 17, 18, "role", "extends", false, false], [26, 30, 17, 18, "role", "extends", false, false], [32, 32, 26, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["At", "the", "2010", "IEEE", "International", "Conference", "on", "Image", "Processing", ",", "Rui", "Hu", ",", "Mark", "Banard", ",", "and", "John", "Collomoss", "extended", "the", "HOG", "descriptor", "for", "use", "in", "sketch", "-", "based", "image", "retrieval", "(", "SBIR", ")", "."], "sentence-detokenized": "At the 2010 IEEE International Conference on Image Processing, Rui Hu, Mark Banard, and John Collomoss extended the HOG descriptor for use in sketch-based image retrieval (SBIR).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 30], [31, 41], [42, 44], [45, 50], [51, 61], [61, 62], [63, 66], [67, 69], [69, 70], [71, 75], [76, 82], [82, 83], [84, 87], [88, 92], [93, 102], [103, 111], [112, 115], [116, 119], [120, 130], [131, 134], [135, 138], [139, 141], [142, 148], [148, 149], [149, 154], [155, 160], [161, 170], [171, 172], [172, 176], [176, 177], [177, 178]]}
{"doc_key": "ai-test-36", "ner": [[0, 0, "metrics"], [4, 4, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 4, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["BLEU", "uses", "a", "modified", "accuracy", "form", "to", "compare", "a", "candidate", "translation", "with", "several", "reference", "translations", "."], "sentence-detokenized": "BLEU uses a modified accuracy form to compare a candidate translation with several reference translations.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 20], [21, 29], [30, 34], [35, 37], [38, 45], [46, 47], [48, 57], [58, 69], [70, 74], [75, 82], [83, 92], [93, 105], [105, 106]]}
{"doc_key": "ai-test-37", "ner": [[32, 34, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "case", "of", "a", "general", "basis", "space", "math", "(", "Y", ",\\", "mathcal", "{", "B", "},\\", "nu", ")", "/", "math", "(", "i.e.", ",", "a", "basis", "space", "that", "is", "not", "countable", ")", ",", "relative", "entropy", "is", "usually", "considered", "."], "sentence-detokenized": "In the case of a general basis space math(Y,\\ mathcal{B},\\ nu)/math (i.e., a basis space that is not countable), relative entropy is usually considered.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 16], [17, 24], [25, 30], [31, 36], [37, 41], [41, 42], [42, 43], [43, 45], [46, 53], [53, 54], [54, 55], [55, 58], [59, 61], [61, 62], [62, 63], [63, 67], [68, 69], [69, 73], [73, 74], [75, 76], [77, 82], [83, 88], [89, 93], [94, 96], [97, 100], [101, 110], [110, 111], [111, 112], [113, 121], [122, 129], [130, 132], [133, 140], [141, 151], [151, 152]]}
{"doc_key": "ai-test-38", "ner": [[11, 11, "country"], [12, 14, "organisation"], [16, 16, "organisation"], [19, 20, "organisation"], [22, 22, "organisation"], [26, 28, "organisation"], [32, 37, "organisation"], [39, 41, "organisation"], [49, 49, "misc"], [50, 50, "misc"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6, 8, 9, 10, 11], "relations": [[12, 14, 11, 11, "physical", "", false, false], [16, 16, 12, 14, "named", "", false, false], [22, 22, 19, 20, "named", "", false, false], [39, 41, 32, 37, "named", "", false, false], [49, 49, 50, 50, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 3, 5, 6], "sentence": ["As", "of", "October", "2011", ",", "the", "already", "existing", "partnership", "with", "the", "U.S.", "National", "Park", "Service", "(", "NPS", ")", ",", "Historic", "Scotland", "(", "HS", ")", ",", "the", "World", "Monuments", "Fund", "and", "the", "Mexican", "National", "Institute", "of", "Anthropology", "and", "History", "(", "INAH", ")", "has", "been", "significantly", "expanded", ",", "according", "to", "the", "CyArk", "website", "."], "sentence-detokenized": "As of October 2011, the already existing partnership with the U.S. National Park Service (NPS), Historic Scotland (HS), the World Monuments Fund and the Mexican National Institute of Anthropology and History (INAH) has been significantly expanded, according to the CyArk website.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 18], [18, 19], [20, 23], [24, 31], [32, 40], [41, 52], [53, 57], [58, 61], [62, 66], [67, 75], [76, 80], [81, 88], [89, 90], [90, 93], [93, 94], [94, 95], [96, 104], [105, 113], [114, 115], [115, 117], [117, 118], [118, 119], [120, 123], [124, 129], [130, 139], [140, 144], [145, 148], [149, 152], [153, 160], [161, 169], [170, 179], [180, 182], [183, 195], [196, 199], [200, 207], [208, 209], [209, 213], [213, 214], [215, 218], [219, 223], [224, 237], [238, 246], [246, 247], [248, 257], [258, 260], [261, 264], [265, 270], [271, 278], [278, 279]]}
{"doc_key": "ai-test-39", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [10, 10, "product"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 10, 10, "part-of", "", false, false], [0, 1, 12, 12, "part-of", "", false, false], [10, 10, 6, 7, "general-affiliation", "", false, false], [12, 12, 6, 7, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kernel", "ANNs", "are", "available", "in", "many", "machine", "learning", "tools", "including", "LIBSVM", ",", "MATLAB", "and", "others", "."], "sentence-detokenized": "Kernel ANNs are available in many machine learning tools including LIBSVM, MATLAB and others.", "token2charspan": [[0, 6], [7, 11], [12, 15], [16, 25], [26, 28], [29, 33], [34, 41], [42, 50], [51, 56], [57, 66], [67, 73], [73, 74], [75, 81], [82, 85], [86, 92], [92, 93]]}
{"doc_key": "ai-test-40", "ner": [[2, 5, "misc"], [13, 14, "location"], [16, 16, "location"], [18, 18, "country"], [24, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 5, 13, 14, "physical", "", false, false], [2, 5, 24, 26, "temporal", "", false, false], [13, 14, 16, 16, "physical", "", false, false], [16, 16, 18, 18, "physical", "", false, false], [24, 26, 13, 14, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "2009", "Lobner", "Prize", "Competition", "was", "held", "on", "6", "September", "2009", "at", "the", "Brighton", "Centre", "in", "Brighton", ",", "UK", ",", "as", "part", "of", "the", "Interspeech", "2009", "conference", "."], "sentence-detokenized": "The 2009 Lobner Prize Competition was held on 6 September 2009 at the Brighton Centre in Brighton, UK, as part of the Interspeech 2009 conference.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 21], [22, 33], [34, 37], [38, 42], [43, 45], [46, 47], [48, 57], [58, 62], [63, 65], [66, 69], [70, 78], [79, 85], [86, 88], [89, 97], [97, 98], [99, 101], [101, 102], [103, 105], [106, 110], [111, 113], [114, 117], [118, 129], [130, 134], [135, 145], [145, 146]]}
{"doc_key": "ai-test-41", "ner": [[0, 2, "product"], [9, 9, "product"], [18, 20, "product"], [16, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 21, 0, 2, "part-of", "", false, false], [16, 21, 9, 9, "part-of", "", false, false], [16, 21, 18, 20, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["QRIO", "humanoid", "robot", "was", "developed", "as", "a", "successor", "to", "AIBO", "and", "runs", "on", "the", "same", "basic", "operating", "system", "R", "-", "CODE", "Aperios", "."], "sentence-detokenized": "QRIO humanoid robot was developed as a successor to AIBO and runs on the same basic operating system R-CODE Aperios.", "token2charspan": [[0, 4], [5, 13], [14, 19], [20, 23], [24, 33], [34, 36], [37, 38], [39, 48], [49, 51], [52, 56], [57, 60], [61, 65], [66, 68], [69, 72], [73, 77], [78, 83], [84, 93], [94, 100], [101, 102], [102, 103], [103, 107], [108, 115], [115, 116]]}
{"doc_key": "ai-test-42", "ner": [[0, 2, "misc"], [7, 7, "algorithm"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 0, 2, "cause-effect", "", true, false], [12, 13, 0, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Speech", "signal", "shapes", "are", "generated", "from", "the", "HMMs", "themselves", "based", "on", "the", "maximum", "likelihood", "criterion", "."], "sentence-detokenized": "Speech signal shapes are generated from the HMMs themselves based on the maximum likelihood criterion.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 34], [35, 39], [40, 43], [44, 48], [49, 59], [60, 65], [66, 68], [69, 72], [73, 80], [81, 91], [92, 101], [101, 102]]}
{"doc_key": "ai-test-43", "ner": [[0, 2, "product"], [5, 8, "task"], [10, 12, "task"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 8, "type-of", "", false, false], [0, 2, 10, 12, "type-of", "", false, false], [0, 2, 16, 17, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Google", "Translate", "is", "a", "free", "multilingual", "statistical", "machine", "translation", "and", "neural", "machine", "translation", "service", "developed", "by", "Google", "for", "translating", "texts", "and", "websites", "from", "one", "language", "to", "another", "."], "sentence-detokenized": "Google Translate is a free multilingual statistical machine translation and neural machine translation service developed by Google for translating texts and websites from one language to another.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 39], [40, 51], [52, 59], [60, 71], [72, 75], [76, 82], [83, 90], [91, 102], [103, 110], [111, 120], [121, 123], [124, 130], [131, 134], [135, 146], [147, 152], [153, 156], [157, 165], [166, 170], [171, 174], [175, 183], [184, 186], [187, 194], [194, 195]]}
{"doc_key": "ai-test-44", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 12, "field"], [14, 16, "field"], [21, 23, "task"], [25, 26, "task"], [28, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[21, 23, 5, 6, "part-of", "", false, true], [21, 23, 8, 9, "part-of", "", false, true], [21, 23, 11, 12, "part-of", "", false, true], [25, 26, 5, 6, "part-of", "", false, true], [25, 26, 8, 9, "part-of", "", false, true], [25, 26, 11, 12, "part-of", "", false, true], [28, 31, 5, 6, "part-of", "", false, true], [28, 31, 8, 9, "part-of", "", false, true], [28, 31, 11, 12, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Skeletons", "are", "widely", "used", "in", "computer", "vision", ",", "image", "analysis", ",", "pattern", "recognition", "and", "digital", "image", "processing", "for", "purposes", "such", "as", "optical", "character", "recognition", ",", "fingerprint", "recognition", ",", "visual", "inspection", "or", "compression", "."], "sentence-detokenized": "Skeletons are widely used in computer vision, image analysis, pattern recognition and digital image processing for purposes such as optical character recognition, fingerprint recognition, visual inspection or compression.", "token2charspan": [[0, 9], [10, 13], [14, 20], [21, 25], [26, 28], [29, 37], [38, 44], [44, 45], [46, 51], [52, 60], [60, 61], [62, 69], [70, 81], [82, 85], [86, 93], [94, 99], [100, 110], [111, 114], [115, 123], [124, 128], [129, 131], [132, 139], [140, 149], [150, 161], [161, 162], [163, 174], [175, 186], [186, 187], [188, 194], [195, 205], [206, 208], [209, 220], [220, 221]]}
{"doc_key": "ai-test-45", "ner": [[0, 6, "conference"], [11, 15, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 6, 11, 15, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "is", "a", "benchmark", "in", "object", "classification", "and", "detection", "involving", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object classification and detection involving millions of images and hundreds of object classes.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 24], [25, 31], [32, 43], [44, 53], [54, 56], [57, 58], [59, 68], [69, 71], [72, 78], [79, 93], [94, 97], [98, 107], [108, 117], [118, 126], [127, 129], [130, 136], [137, 140], [141, 149], [150, 152], [153, 159], [160, 167], [167, 168]]}
{"doc_key": "ai-test-46", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 12, "researcher"], [14, 16, "misc"], [21, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 14, 16, "part-of", "", false, false], [0, 0, 21, 25, "part-of", "", false, false], [4, 5, 14, 16, "part-of", "", false, false], [4, 5, 21, 25, "part-of", "", false, false], [7, 12, 14, 16, "part-of", "", false, false], [7, 12, 21, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Bengio", ",", "along", "with", "Jeffrey", "Hinton", "and", "Jan", "Lekun", ",", "are", "called", "the", "\"", "godfathers", "\"", "of", "AI", "and", "the", "\"", "godfathers", "\"", "of", "deep", "learning", "."], "sentence-detokenized": "Bengio, along with Jeffrey Hinton and Jan Lekun, are called the \"godfathers\" of AI and the \"godfathers\" of deep learning.", "token2charspan": [[0, 6], [6, 7], [8, 13], [14, 18], [19, 26], [27, 33], [34, 37], [38, 41], [42, 47], [47, 48], [49, 52], [53, 59], [60, 63], [64, 65], [65, 75], [75, 76], [77, 79], [80, 82], [83, 86], [87, 90], [91, 92], [92, 102], [102, 103], [104, 106], [107, 111], [112, 120], [120, 121]]}
{"doc_key": "ai-test-47", "ner": [[6, 6, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "life", "member", "of", "IEEE", "."], "sentence-detokenized": "He is a life member of IEEE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 19], [20, 22], [23, 27], [27, 28]]}
{"doc_key": "ai-test-48", "ner": [[0, 2, "organisation"], [15, 20, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 15, 20, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NSA", "Bethesda", "is", "responsible", "for", "operational", "support", "to", "the", "base", "for", "its", "primary", "tenant", ",", "Walter", "Reed", "National", "Military", "Medical", "Center", "."], "sentence-detokenized": "NSA Bethesda is responsible for operational support to the base for its primary tenant, Walter Reed National Military Medical Center.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 31], [32, 43], [44, 51], [52, 54], [55, 58], [59, 63], [64, 67], [68, 71], [72, 79], [80, 86], [86, 87], [88, 94], [95, 99], [100, 108], [109, 117], [118, 125], [126, 132], [132, 133]]}
{"doc_key": "ai-test-49", "ner": [[6, 7, "field"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "three", "main", "learning", "paradigms", "are", "supervised", "learning", ",", "unsupervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "The three main learning paradigms are supervised learning, unsupervised learning and reinforcement learning.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 23], [24, 33], [34, 37], [38, 48], [49, 57], [57, 58], [59, 71], [72, 80], [81, 84], [85, 98], [99, 107], [107, 108]]}
{"doc_key": "ai-test-50", "ner": [[2, 2, "task"], [4, 6, "task"], [11, 15, "task"], [17, 18, "task"], [20, 22, "task"], [24, 24, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Examples", "include", "control", ",", "planning", "and", "scheduling", ",", "the", "ability", "to", "answer", "diagnostic", "and", "consumer", "questions", ",", "handwriting", "recognition", ",", "natural", "language", "understanding", ",", "speech", "recognition", "and", "facial", "recognition", "."], "sentence-detokenized": "Examples include control, planning and scheduling, the ability to answer diagnostic and consumer questions, handwriting recognition, natural language understanding, speech recognition and facial recognition.", "token2charspan": [[0, 8], [9, 16], [17, 24], [24, 25], [26, 34], [35, 38], [39, 49], [49, 50], [51, 54], [55, 62], [63, 65], [66, 72], [73, 83], [84, 87], [88, 96], [97, 106], [106, 107], [108, 119], [120, 131], [131, 132], [133, 140], [141, 149], [150, 163], [163, 164], [165, 171], [172, 183], [184, 187], [188, 194], [195, 206], [206, 207]]}
{"doc_key": "ai-test-51", "ner": [[9, 15, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1991", "he", "was", "elected", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "1990", ",", "founding", "member", ")", "."], "sentence-detokenized": "In 1991 he was elected a member of the Association for the Advancement of Artificial Intelligence (1990, founding member).", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 22], [23, 24], [25, 31], [32, 34], [35, 38], [39, 50], [51, 54], [55, 58], [59, 70], [71, 73], [74, 84], [85, 97], [98, 99], [99, 103], [103, 104], [105, 113], [114, 120], [120, 121], [121, 122]]}
{"doc_key": "ai-test-52", "ner": [[11, 12, "misc"], [15, 16, "algorithm"], [29, 29, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "by", "formulating", "the", "problem", "as", "a", "solution", "of", "the", "Teplitz", "matrix", "and", "using", "Levinson", "recursion", ",", "it", "is", "possible", "to", "estimate", "the", "filter", "with", "the", "smallest", "RMS", "error", "relatively", "quickly", "."], "sentence-detokenized": "However, by formulating the problem as a solution of the Teplitz matrix and using Levinson recursion, it is possible to estimate the filter with the smallest RMS error relatively quickly.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 23], [24, 27], [28, 35], [36, 38], [39, 40], [41, 49], [50, 52], [53, 56], [57, 64], [65, 71], [72, 75], [76, 81], [82, 90], [91, 100], [100, 101], [102, 104], [105, 107], [108, 116], [117, 119], [120, 128], [129, 132], [133, 139], [140, 144], [145, 148], [149, 157], [158, 161], [162, 167], [168, 178], [179, 186], [186, 187]]}
{"doc_key": "ai-test-53", "ner": [[4, 9, "conference"], [13, 17, "location"], [19, 19, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 9, 13, 17, "physical", "", false, false], [13, 17, 19, 19, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2011", "the", "15th", "Campus", "Party", "Spain", "will", "be", "held", "in", "the", "City", "of", "Arts", "and", "Sciences", "in", "Valencia", "."], "sentence-detokenized": "In July 2011 the 15th Campus Party Spain will be held in the City of Arts and Sciences in Valencia.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 16], [17, 21], [22, 28], [29, 34], [35, 40], [41, 45], [46, 48], [49, 53], [54, 56], [57, 60], [61, 65], [66, 68], [69, 73], [74, 77], [78, 86], [87, 89], [90, 98], [98, 99]]}
{"doc_key": "ai-test-54", "ner": [[17, 17, "product"], [19, 19, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Often", ",", "this", "is", "only", "possible", "at", "all", "at", "the", "very", "end", "of", "complex", "games", "such", "as", "chess", "or", "go", ",", "since", "it", "is", "computationally", "impossible", "to", "look", "ahead", "to", "the", "end", "of", "the", "game", "except", "at", "the", "end", ",", "and", "instead", "positions", "are", "given", "end", "values", "as", "estimates", "of", "the", "degree", "of", "certainty", "that", "they", "will", "lead", "to", "a", "victory", "for", "one", "player", "or", "another", "."], "sentence-detokenized": "Often, this is only possible at all at the very end of complex games such as chess or go, since it is computationally impossible to look ahead to the end of the game except at the end, and instead positions are given end values as estimates of the degree of certainty that they will lead to a victory for one player or another.", "token2charspan": [[0, 5], [5, 6], [7, 11], [12, 14], [15, 19], [20, 28], [29, 31], [32, 35], [36, 38], [39, 42], [43, 47], [48, 51], [52, 54], [55, 62], [63, 68], [69, 73], [74, 76], [77, 82], [83, 85], [86, 88], [88, 89], [90, 95], [96, 98], [99, 101], [102, 117], [118, 128], [129, 131], [132, 136], [137, 142], [143, 145], [146, 149], [150, 153], [154, 156], [157, 160], [161, 165], [166, 172], [173, 175], [176, 179], [180, 183], [183, 184], [185, 188], [189, 196], [197, 206], [207, 210], [211, 216], [217, 220], [221, 227], [228, 230], [231, 240], [241, 243], [244, 247], [248, 254], [255, 257], [258, 267], [268, 272], [273, 277], [278, 282], [283, 287], [288, 290], [291, 292], [293, 300], [301, 304], [305, 308], [309, 315], [316, 318], [319, 326], [326, 327]]}
{"doc_key": "ai-test-55", "ner": [[3, 6, "algorithm"], [23, 24, "algorithm"], [26, 27, "algorithm"], [30, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 6, 23, 24, "compare", "", false, false], [3, 6, 26, 27, "compare", "", false, false], [3, 6, 30, 32, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "difference", "between", "the", "multinomial", "logit", "model", "and", "numerous", "other", "methods", ",", "models", ",", "algorithms", ",", "etc.", "with", "the", "same", "basic", "setup", "(", "perceptron", "algorithm", ",", "support", "vector", "machines", ",", "linear", "discriminant", "analysis", ",", "etc.", ")", "is", "that", "it", "has", "a", "wider", "range", "of", "applications", "."], "sentence-detokenized": "The difference between the multinomial logit model and numerous other methods, models, algorithms, etc. with the same basic setup (perceptron algorithm, support vector machines, linear discriminant analysis, etc.) is that it has a wider range of applications.", "token2charspan": [[0, 3], [4, 14], [15, 22], [23, 26], [27, 38], [39, 44], [45, 50], [51, 54], [55, 63], [64, 69], [70, 77], [77, 78], [79, 85], [85, 86], [87, 97], [97, 98], [99, 103], [104, 108], [109, 112], [113, 117], [118, 123], [124, 129], [130, 131], [131, 141], [142, 151], [151, 152], [153, 160], [161, 167], [168, 176], [176, 177], [178, 184], [185, 197], [198, 206], [206, 207], [208, 212], [212, 213], [214, 216], [217, 221], [222, 224], [225, 228], [229, 230], [231, 236], [237, 242], [243, 245], [246, 258], [258, 259]]}
{"doc_key": "ai-test-56", "ner": [[0, 3, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Association", "for", "Computational", "Linguistics", ",", "published", "by"], "sentence-detokenized": "Association for Computational Linguistics, published by", "token2charspan": [[0, 11], [12, 15], [16, 29], [30, 41], [41, 42], [43, 52], [53, 55]]}
{"doc_key": "ai-test-57", "ner": [[3, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "a", "computerized", "face", "recognition", "system", ",", "each", "face", "is", "represented", "by", "a", "large", "number", "of", "pixel", "values", "."], "sentence-detokenized": "In a computerized face recognition system, each face is represented by a large number of pixel values.", "token2charspan": [[0, 2], [3, 4], [5, 17], [18, 22], [23, 34], [35, 41], [41, 42], [43, 47], [48, 52], [53, 55], [56, 67], [68, 70], [71, 72], [73, 78], [79, 85], [86, 88], [89, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-test-58", "ner": [[6, 9, "person"], [14, 16, "organisation"], [23, 23, "country"], [26, 26, "person"], [36, 38, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 9, 14, 16, "role", "", false, false], [6, 9, 23, 23, "physical", "", false, false], [26, 26, 36, 38, "origin", "", false, false], [26, 26, 36, 38, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2002", ",", "his", "son", ",", "Daniel", "Pearl", ",", "a", "journalist", "working", "for", "the", "Wall", "Street", "Journal", ",", "was", "kidnapped", "and", "murdered", "in", "Pakistan", ",", "prompting", "Judah", "and", "other", "family", "members", "and", "friends", "to", "establish", "the", "Daniel", "Pearl", "Foundation", "."], "sentence-detokenized": "In 2002, his son, Daniel Pearl, a journalist working for the Wall Street Journal, was kidnapped and murdered in Pakistan, prompting Judah and other family members and friends to establish the Daniel Pearl Foundation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [16, 17], [18, 24], [25, 30], [30, 31], [32, 33], [34, 44], [45, 52], [53, 56], [57, 60], [61, 65], [66, 72], [73, 80], [80, 81], [82, 85], [86, 95], [96, 99], [100, 108], [109, 111], [112, 120], [120, 121], [122, 131], [132, 137], [138, 141], [142, 147], [148, 154], [155, 162], [163, 166], [167, 174], [175, 177], [178, 187], [188, 191], [192, 198], [199, 204], [205, 215], [215, 216]]}
{"doc_key": "ai-test-59", "ner": [[4, 6, "organisation"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 18, 19, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "late", "2006", ",", "Red", "Envelope", "Entertainment", "also", "expanded", "its", "production", "of", "original", "content", "with", "directors", "such", "as", "John", "Waters", "."], "sentence-detokenized": "In late 2006, Red Envelope Entertainment also expanded its production of original content with directors such as John Waters.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 26], [27, 40], [41, 45], [46, 54], [55, 58], [59, 69], [70, 72], [73, 81], [82, 89], [90, 94], [95, 104], [105, 109], [110, 112], [113, 117], [118, 124], [124, 125]]}
{"doc_key": "ai-test-60", "ner": [[7, 11, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Now", "the", "building", "is", "part", "of", "the", "Beth", "Israel", "Deaconess", "Medical", "Center", "."], "sentence-detokenized": "Now the building is part of the Beth Israel Deaconess Medical Center.", "token2charspan": [[0, 3], [4, 7], [8, 16], [17, 19], [20, 24], [25, 27], [28, 31], [32, 36], [37, 43], [44, 53], [54, 61], [62, 68], [68, 69]]}
{"doc_key": "ai-test-61", "ner": [[18, 19, "field"], [21, 22, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "common", "theme", "of", "this", "work", "is", "the", "adoption", "of", "a", "sign-", "theoretical", "view", "of", "the", "problems", "of", "artificial", "intelligence", "and", "knowledge", "representation", "."], "sentence-detokenized": "The common theme of this work is the adoption of a sign-theoretical view of the problems of artificial intelligence and knowledge representation.", "token2charspan": [[0, 3], [4, 10], [11, 16], [17, 19], [20, 24], [25, 29], [30, 32], [33, 36], [37, 45], [46, 48], [49, 50], [51, 56], [56, 67], [68, 72], [73, 75], [76, 79], [80, 88], [89, 91], [92, 102], [103, 115], [116, 119], [120, 129], [130, 144], [144, 145]]}
{"doc_key": "ai-test-62", "ner": [[6, 8, "task"], [11, 11, "task"], [17, 18, "task"], [41, 42, "task"], [44, 46, "task"], [50, 52, "task"], [54, 54, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[6, 8, 17, 18, "type-of", "", false, false], [6, 8, 50, 52, "compare", "", false, false], [6, 8, 50, 52, "opposite", "", false, false], [11, 11, 6, 8, "named", "", false, false], [41, 42, 50, 52, "part-of", "", false, false], [44, 46, 50, 52, "part-of", "", false, false], [50, 52, 17, 18, "type-of", "", false, false], [54, 54, 50, 52, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["For", "example", ",", "the", "term", "\"", "neural", "machine", "translation", "\"", "(", "NMT", ")", "emphasizes", "the", "fact", "that", "machine", "translation", "approaches", "based", "on", "deep", "learning", "directly", "learn", "sequence", "-", "to", "-", "sequence", "conversions", ",", "eliminating", "the", "need", "for", "intermediate", "steps", "such", "as", "word", "alignment", "and", "language", "modeling", "that", "were", "used", "in", "statistical", "machine", "translation", "(", "SMT", ")", "."], "sentence-detokenized": "For example, the term \"neural machine translation\" (NMT) emphasizes the fact that machine translation approaches based on deep learning directly learn sequence-to-sequence conversions, eliminating the need for intermediate steps such as word alignment and language modeling that were used in statistical machine translation (SMT).", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 23], [23, 29], [30, 37], [38, 49], [49, 50], [51, 52], [52, 55], [55, 56], [57, 67], [68, 71], [72, 76], [77, 81], [82, 89], [90, 101], [102, 112], [113, 118], [119, 121], [122, 126], [127, 135], [136, 144], [145, 150], [151, 159], [159, 160], [160, 162], [162, 163], [163, 171], [172, 183], [183, 184], [185, 196], [197, 200], [201, 205], [206, 209], [210, 222], [223, 228], [229, 233], [234, 236], [237, 241], [242, 251], [252, 255], [256, 264], [265, 273], [274, 278], [279, 283], [284, 288], [289, 291], [292, 303], [304, 311], [312, 323], [324, 325], [325, 328], [328, 329], [329, 330]]}
{"doc_key": "ai-test-63", "ner": [[6, 6, "field"], [10, 11, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 6, 10, 11, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Most", "research", "in", "the", "field", "of", "WSD", "is", "performed", "using", "Word", "Net", "as", "a", "reference", "semantic", "inventory", "for", "."], "sentence-detokenized": "Most research in the field of WSD is performed using WordNet as a reference semantic inventory for.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 20], [21, 26], [27, 29], [30, 33], [34, 36], [37, 46], [47, 52], [53, 57], [57, 60], [61, 63], [64, 65], [66, 75], [76, 84], [85, 94], [95, 98], [98, 99]]}
{"doc_key": "ai-test-64", "ner": [[12, 13, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Among", "the", "famous", "former", "graduate", "students", "and", "researchers", "from", "his", "group", "are", "Richard", "Zemel", "and", "Zubin", "Ghahramani", "."], "sentence-detokenized": "Among the famous former graduate students and researchers from his group are Richard Zemel and Zubin Ghahramani.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 23], [24, 32], [33, 41], [42, 45], [46, 57], [58, 62], [63, 66], [67, 72], [73, 76], [77, 84], [85, 90], [91, 94], [95, 100], [101, 111], [111, 112]]}
{"doc_key": "ai-test-65", "ner": [[7, 9, "metrics"], [14, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 9, 14, 14, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Each", "prediction", "result", "or", "instance", "of", "the", "confusion", "matrix", "represents", "one", "point", "in", "the", "ROC", "space", "."], "sentence-detokenized": "Each prediction result or instance of the confusion matrix represents one point in the ROC space.", "token2charspan": [[0, 4], [5, 15], [16, 22], [23, 25], [26, 34], [35, 37], [38, 41], [42, 51], [52, 58], [59, 69], [70, 73], [74, 79], [80, 82], [83, 86], [87, 90], [91, 96], [96, 97]]}
{"doc_key": "ai-test-66", "ner": [[2, 2, "researcher"], [8, 9, "researcher"], [11, 12, "researcher"], [19, 20, "product"], [23, 26, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 23, 26, "physical", "", false, false], [8, 9, 23, 26, "physical", "", false, false], [11, 12, 23, 26, "physical", "", false, false], [19, 20, 2, 2, "artifact", "", false, false], [19, 20, 8, 9, "artifact", "", false, false], [19, 20, 11, 12, "artifact", "", false, false], [19, 20, 23, 26, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "1997", "Trun", ",", "together", "with", "his", "colleagues", "Wolfram", "Burgard", "and", "Dieter", "Fox", ",", "developed", "the", "world", "'s", "first", "robot", "guide", "at", "the", "German", "Museum", "in", "Bonn", "(", "1997", ")", "."], "sentence-detokenized": "In 1997 Trun, together with his colleagues Wolfram Burgard and Dieter Fox, developed the world's first robot guide at the German Museum in Bonn (1997).", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 22], [23, 27], [28, 31], [32, 42], [43, 50], [51, 58], [59, 62], [63, 69], [70, 73], [73, 74], [75, 84], [85, 88], [89, 94], [94, 96], [97, 102], [103, 108], [109, 114], [115, 117], [118, 121], [122, 128], [129, 135], [136, 138], [139, 143], [144, 145], [145, 149], [149, 150], [150, 151]]}
{"doc_key": "ai-test-67", "ner": [[0, 2, "product"], [7, 8, "misc"], [23, 25, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 0, 2, "part-of", "", false, false], [23, 25, 0, 2, "usage", "", false, false], [27, 28, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Word", "Net", "is", "a", "lexical", "database", "of", "semantic", "relations", "between", "words", "in", "more", "than", "200", "languages", ".", "It", "s", "main", "application", "is", "automatic", "natural", "language", "processing", "and", "artificial", "intelligence", "applications", "."], "sentence-detokenized": "WordNet is a lexical database of semantic relations between words in more than 200 languages. Its main application is automatic natural language processing and artificial intelligence applications.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 12], [13, 20], [21, 29], [30, 32], [33, 41], [42, 51], [52, 59], [60, 65], [66, 68], [69, 73], [74, 78], [79, 82], [83, 92], [92, 93], [94, 96], [96, 97], [98, 102], [103, 114], [115, 117], [118, 127], [128, 135], [136, 144], [145, 155], [156, 159], [160, 170], [171, 183], [184, 196], [196, 197]]}
{"doc_key": "ai-test-68", "ner": [[5, 7, "field"], [12, 15, "conference"], [18, 26, "conference"], [28, 28, "conference"], [31, 33, "conference"], [39, 40, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 15, 5, 7, "topic", "", false, false], [12, 15, 39, 40, "topic", "", false, false], [18, 26, 5, 7, "topic", "", false, false], [18, 26, 39, 40, "topic", "", false, false], [28, 28, 5, 7, "topic", "", false, false], [28, 28, 39, 40, "topic", "", false, false], [31, 33, 5, 7, "topic", "", false, false], [31, 33, 39, 40, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Conferences", "in", "the", "field", "of", "natural", "language", "processing", ",", "such", "as", "the", "Association", "for", "Computational", "Linguistics", ",", "the", "North", "American", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "EMNLP", ",", "and", "HLT", ",", "are", "beginning", "to", "include", "papers", "on", "speech", "processing", "."], "sentence-detokenized": "Conferences in the field of natural language processing, such as the Association for Computational Linguistics, the North American Chapter of the Association for Computational Linguistics, EMNLP, and HLT, are beginning to include papers on speech processing.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 24], [25, 27], [28, 35], [36, 44], [45, 55], [55, 56], [57, 61], [62, 64], [65, 68], [69, 80], [81, 84], [85, 98], [99, 110], [110, 111], [112, 115], [116, 121], [122, 130], [131, 138], [139, 141], [142, 145], [146, 157], [158, 161], [162, 175], [176, 187], [187, 188], [189, 194], [194, 195], [196, 199], [200, 203], [203, 204], [205, 208], [209, 218], [219, 221], [222, 229], [230, 236], [237, 239], [240, 246], [247, 257], [257, 258]]}
{"doc_key": "ai-test-69", "ner": [[3, 5, "programlang"], [20, 22, "misc"], [32, 34, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "set", "of", "Java", "-", "based", "programs", "uses", "a", "lexicon", "to", "handle", "variations", "in", "biomedical", "texts", "by", "linking", "words", "by", "part", "of", "speech", ",", "which", "can", "be", "useful", "in", "web", "searches", "or", "electronic", "medical", "record", "searches", "."], "sentence-detokenized": "A set of Java-based programs uses a lexicon to handle variations in biomedical texts by linking words by part of speech, which can be useful in web searches or electronic medical record searches.", "token2charspan": [[0, 1], [2, 5], [6, 8], [9, 13], [13, 14], [14, 19], [20, 28], [29, 33], [34, 35], [36, 43], [44, 46], [47, 53], [54, 64], [65, 67], [68, 78], [79, 84], [85, 87], [88, 95], [96, 101], [102, 104], [105, 109], [110, 112], [113, 119], [119, 120], [121, 126], [127, 130], [131, 133], [134, 140], [141, 143], [144, 147], [148, 156], [157, 159], [160, 170], [171, 178], [179, 185], [186, 194], [194, 195]]}
{"doc_key": "ai-test-70", "ner": [[8, 8, "algorithm"], [10, 10, "algorithm"], [12, 12, "algorithm"], [14, 14, "algorithm"], [16, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "many", "more", "modern", "algorithms", "such", "as", "LPBoost", ",", "TotalBoost", ",", "BrownBoost", ",", "xgboost", ",", "MadaBoost", "and", "others", "."], "sentence-detokenized": "There are many more modern algorithms such as LPBoost, TotalBoost, BrownBoost, xgboost, MadaBoost and others.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 19], [20, 26], [27, 37], [38, 42], [43, 45], [46, 53], [53, 54], [55, 65], [65, 66], [67, 77], [77, 78], [79, 86], [86, 87], [88, 97], [98, 101], [102, 108], [108, 109]]}
{"doc_key": "ai-test-71", "ner": [[7, 7, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "of", "implementation", "in", "Python", ":"], "sentence-detokenized": "This is an example of implementation in Python:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 36], [37, 39], [40, 46], [46, 47]]}
{"doc_key": "ai-test-72", "ner": [[0, 1, "organisation"], [2, 2, "product"], [7, 9, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 0, 1, "artifact", "made_by_company", false, false], [7, 9, 2, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Mattel", "Intellivision", "game", "console", "offered", "the", "Intellivoice", "voice", "synthesis", "module", "in", "1982", "."], "sentence-detokenized": "The Mattel Intellivision game console offered the Intellivoice voice synthesis module in 1982.", "token2charspan": [[0, 3], [4, 10], [11, 24], [25, 29], [30, 37], [38, 45], [46, 49], [50, 62], [63, 68], [69, 78], [79, 85], [86, 88], [89, 93], [93, 94]]}
{"doc_key": "ai-test-73", "ner": [[4, 5, "task"], [8, 13, "task"], [15, 16, "field"], [18, 20, "task"], [24, 27, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 13, 4, 5, "part-of", "", false, false], [15, 16, 4, 5, "part-of", "", false, false], [18, 20, 4, 5, "part-of", "", false, false], [24, 27, 18, 20, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "also", "worked", "on", "machine", "translation", ",", "both", "high", "accuracy", "knowledge", "-", "based", "translation", "and", "machine", "learning", "for", "statistical", "machine", "translation", "(", "e.g.", "translation", "based", "on", "generalized", "examples", ")", "."], "sentence-detokenized": "He also worked on machine translation, both high accuracy knowledge-based translation and machine learning for statistical machine translation (e.g. translation based on generalized examples).", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 17], [18, 25], [26, 37], [37, 38], [39, 43], [44, 48], [49, 57], [58, 67], [67, 68], [68, 73], [74, 85], [86, 89], [90, 97], [98, 106], [107, 110], [111, 122], [123, 130], [131, 142], [143, 144], [144, 148], [149, 160], [161, 166], [167, 169], [170, 181], [182, 190], [190, 191], [191, 192]]}
{"doc_key": "ai-test-74", "ner": [[0, 1, "misc"], [7, 10, "misc"], [21, 22, "algorithm"], [24, 25, "field"], [27, 28, "field"], [30, 30, "field"], [32, 33, "field"], [35, 35, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 21, 22, "general-affiliation", "", false, false], [0, 1, 24, 25, "general-affiliation", "", false, false], [0, 1, 27, 28, "general-affiliation", "", false, false], [0, 1, 30, 30, "general-affiliation", "", false, false], [0, 1, 32, 33, "general-affiliation", "", false, false], [0, 1, 35, 35, "general-affiliation", "", false, false], [7, 10, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Wolfram", "Mathematica", "(", "commonly", "referred", "to", "as", "Mathematica", ")", "is", "a", "modern", "technical", "computing", "system", "covering", "most", "technical", "fields", ",", "including", "neural", "networks", ",", "machine", "learning", ",", "image", "processing", ",", "geometry", ",", "data", "science", ",", "visualization", "and", "others", "."], "sentence-detokenized": "Wolfram Mathematica (commonly referred to as Mathematica) is a modern technical computing system covering most technical fields, including neural networks, machine learning, image processing, geometry, data science, visualization and others.", "token2charspan": [[0, 7], [8, 19], [20, 21], [21, 29], [30, 38], [39, 41], [42, 44], [45, 56], [56, 57], [58, 60], [61, 62], [63, 69], [70, 79], [80, 89], [90, 96], [97, 105], [106, 110], [111, 120], [121, 127], [127, 128], [129, 138], [139, 145], [146, 154], [154, 155], [156, 163], [164, 172], [172, 173], [174, 179], [180, 190], [190, 191], [192, 200], [200, 201], [202, 206], [207, 214], [214, 215], [216, 229], [230, 233], [234, 240], [240, 241]]}
{"doc_key": "ai-test-75", "ner": [[2, 7, "product"], [10, 12, "researcher"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 18, 2, 7, "type-of", "", false, false], [18, 18, 10, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "robot", "with", "digital", "control", "and", "programming", "was", "invented", "by", "George", "Devol", "in", "1954", "and", "was", "called", "Unimate", "."], "sentence-detokenized": "The first robot with digital control and programming was invented by George Devol in 1954 and was called Unimate.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 20], [21, 28], [29, 36], [37, 40], [41, 52], [53, 56], [57, 65], [66, 68], [69, 75], [76, 81], [82, 84], [85, 89], [90, 93], [94, 97], [98, 104], [105, 112], [112, 113]]}
{"doc_key": "ai-test-76", "ner": [[2, 2, "algorithm"], [4, 4, "algorithm"], [19, 20, "task"], [22, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 2, 4, 4, "compare", "", false, false], [4, 4, 19, 20, "general-affiliation", "", false, false], [4, 4, 22, 23, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Similar", "to", "BNFs", ",", "RDBMSs", "can", "learn", "complex", "and", "abstract", "internal", "representations", "of", "input", "data", "in", "tasks", "such", "as", "object", "recognition", "or", "speech", "recognition", "by", "using", "limited", ",", "labeled", "data", "to", "fine", "-", "tune", "representations", "built", "using", "a", "large", "set", "of", "unlabeled", "sensory", "input", "data", "."], "sentence-detokenized": "Similar to BNFs, RDBMSs can learn complex and abstract internal representations of input data in tasks such as object recognition or speech recognition by using limited, labeled data to fine-tune representations built using a large set of unlabeled sensory input data.", "token2charspan": [[0, 7], [8, 10], [11, 15], [15, 16], [17, 23], [24, 27], [28, 33], [34, 41], [42, 45], [46, 54], [55, 63], [64, 79], [80, 82], [83, 88], [89, 93], [94, 96], [97, 102], [103, 107], [108, 110], [111, 117], [118, 129], [130, 132], [133, 139], [140, 151], [152, 154], [155, 160], [161, 168], [168, 169], [170, 177], [178, 182], [183, 185], [186, 190], [190, 191], [191, 195], [196, 211], [212, 217], [218, 223], [224, 225], [226, 231], [232, 235], [236, 238], [239, 248], [249, 256], [257, 262], [263, 267], [267, 268]]}
{"doc_key": "ai-test-77", "ner": [[5, 9, "task"], [13, 13, "conference"], [15, 15, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 13, 5, 9, "topic", "", false, false], [15, 15, 5, 9, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Scientific", "conferences", "where", "papers", "on", "vision", "-", "based", "activity", "recognition", "often", "appear", "are", "ICCV", "and", "CVPR", "."], "sentence-detokenized": "Scientific conferences where papers on vision-based activity recognition often appear are ICCV and CVPR.", "token2charspan": [[0, 10], [11, 22], [23, 28], [29, 35], [36, 38], [39, 45], [45, 46], [46, 51], [52, 60], [61, 72], [73, 78], [79, 85], [86, 89], [90, 94], [95, 98], [99, 103], [103, 104]]}
{"doc_key": "ai-test-78", "ner": [[1, 3, "field"], [4, 5, "algorithm"], [7, 7, "algorithm"], [17, 18, "metrics"], [20, 22, "metrics"], [36, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6], "relations": [[4, 5, 1, 3, "part-of", "", false, false], [4, 5, 17, 18, "related-to", "finds", false, false], [4, 5, 20, 22, "related-to", "finds", false, false], [4, 5, 36, 37, "related-to", "", false, false], [7, 7, 4, 5, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "statistics", ",", "the", "Expectation", "Maximization", "(", "EM", ")", "algorithm", "is", "an", "iterative", "method", "for", "finding", "the", "maximum", "likelihood", "or", "maximum", "a", "posteriori", "estimates", "of", "the", "parameters", "of", "statistical", "models", "when", "the", "model", "depends", "on", "unobserved", "latent", "variables", "."], "sentence-detokenized": "In statistics, the Expectation Maximization (EM) algorithm is an iterative method for finding the maximum likelihood or maximum a posteriori estimates of the parameters of statistical models when the model depends on unobserved latent variables.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 30], [31, 43], [44, 45], [45, 47], [47, 48], [49, 58], [59, 61], [62, 64], [65, 74], [75, 81], [82, 85], [86, 93], [94, 97], [98, 105], [106, 116], [117, 119], [120, 127], [128, 129], [130, 140], [141, 150], [151, 153], [154, 157], [158, 168], [169, 171], [172, 183], [184, 190], [191, 195], [196, 199], [200, 205], [206, 213], [214, 216], [217, 227], [228, 234], [235, 244], [244, 245]]}
{"doc_key": "ai-test-79", "ner": [[5, 6, "metrics"], [9, 9, "metrics"], [14, 16, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 5, 6, "named", "", false, false], [18, 18, 14, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Similarly", ",", "investigators", "sometimes", "report", "false", "positive", "rate", "(", "FPR", ")", "as", "well", "as", "false", "negative", "rate", "(", "FNR", ")", "."], "sentence-detokenized": "Similarly, investigators sometimes report false positive rate (FPR) as well as false negative rate (FNR).", "token2charspan": [[0, 9], [9, 10], [11, 24], [25, 34], [35, 41], [42, 47], [48, 56], [57, 61], [62, 63], [63, 66], [66, 67], [68, 70], [71, 75], [76, 78], [79, 84], [85, 93], [94, 98], [99, 100], [100, 103], [103, 104], [104, 105]]}
{"doc_key": "ai-test-80", "ner": [[6, 11, "metrics"], [14, 15, "field"], [18, 19, "metrics"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 15, 6, 11, "usage", "", false, false], [22, 23, 18, 19, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "concept", "is", "similar", "to", "the", "signal", "-", "to", "-", "noise", "ratio", "used", "in", "natural", "sciences", "and", "the", "confusion", "matrix", "used", "in", "artificial", "intelligence", "."], "sentence-detokenized": "The concept is similar to the signal-to-noise ratio used in natural sciences and the confusion matrix used in artificial intelligence.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 25], [26, 29], [30, 36], [36, 37], [37, 39], [39, 40], [40, 45], [46, 51], [52, 56], [57, 59], [60, 67], [68, 76], [77, 80], [81, 84], [85, 94], [95, 101], [102, 106], [107, 109], [110, 120], [121, 133], [133, 134]]}
{"doc_key": "ai-test-81", "ner": [[5, 6, "field"], [13, 14, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [33, 38, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 13, 14, "general-affiliation", "", false, false], [5, 6, 20, 21, "general-affiliation", "", false, false], [5, 6, 23, 24, "general-affiliation", "", false, false], [33, 38, 5, 6, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Code", "of", "Ethics", "for", "Human", "Augmentation", ",", "which", "was", "first", "introduced", "by", "Steve", "Mann", "in", "2004", "and", "finalized", "by", "Ray", "Kurzweil", "and", "Marvin", "Minsky", "in", "2013", ",", "was", "finally", "ratified", "at", "the", "Virtual", "Reality", "Conference", "in", "Toronto", "on", "June", "25", ",", "2017", "."], "sentence-detokenized": "The Code of Ethics for Human Augmentation, which was first introduced by Steve Mann in 2004 and finalized by Ray Kurzweil and Marvin Minsky in 2013, was finally ratified at the Virtual Reality Conference in Toronto on June 25, 2017.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 18], [19, 22], [23, 28], [29, 41], [41, 42], [43, 48], [49, 52], [53, 58], [59, 69], [70, 72], [73, 78], [79, 83], [84, 86], [87, 91], [92, 95], [96, 105], [106, 108], [109, 112], [113, 121], [122, 125], [126, 132], [133, 139], [140, 142], [143, 147], [147, 148], [149, 152], [153, 160], [161, 169], [170, 172], [173, 176], [177, 184], [185, 192], [193, 203], [204, 206], [207, 214], [215, 217], [218, 222], [223, 225], [225, 226], [227, 231], [231, 232]]}
{"doc_key": "ai-test-82", "ner": [[3, 6, "person"], [11, 14, "organisation"], [20, 21, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 6, 11, 14, "role", "directed_for", false, false], [3, 6, 20, 21, "role", "collaborator", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1913", ",", "Walter", "R.", "Booth", "made", "10", "films", "for", "the", "British", "film", "company", "Kinoplasticon", ",", "presumably", "in", "collaboration", "with", "Cecil", "Hepworth", "."], "sentence-detokenized": "In 1913, Walter R. Booth made 10 films for the British film company Kinoplasticon, presumably in collaboration with Cecil Hepworth.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 18], [19, 24], [25, 29], [30, 32], [33, 38], [39, 42], [43, 46], [47, 54], [55, 59], [60, 67], [68, 81], [81, 82], [83, 93], [94, 96], [97, 110], [111, 115], [116, 121], [122, 130], [130, 131]]}
{"doc_key": "ai-test-83", "ner": [[13, 14, "location"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["They", "presented", "their", "new", "robot", "in", "1961", "at", "an", "exhibition", "in", "Chicago", "'s", "Cow", "Palace", "."], "sentence-detokenized": "They presented their new robot in 1961 at an exhibition in Chicago's Cow Palace.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 24], [25, 30], [31, 33], [34, 38], [39, 41], [42, 44], [45, 55], [56, 58], [59, 66], [66, 68], [69, 72], [73, 79], [79, 80]]}
{"doc_key": "ai-test-84", "ner": [[2, 2, "product"], [6, 7, "task"], [10, 11, "field"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 2, 6, 7, "usage", "", false, false], [2, 2, 10, 11, "usage", "", false, false], [2, 2, 15, 16, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["While", "some", "chatbot", "programs", "use", "sophisticated", "word", "classification", "processes", ",", "natural", "language", "processors", "and", "sophisticated", "artificial", "intelligence", ",", "others", "simply", "scan", "for", "common", "keywords", "and", "generate", "responses", "using", "common", "phrases", "retrieved", "from", "an", "appropriate", "library", "or", "database", "."], "sentence-detokenized": "While some chatbot programs use sophisticated word classification processes, natural language processors and sophisticated artificial intelligence, others simply scan for common keywords and generate responses using common phrases retrieved from an appropriate library or database.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 27], [28, 31], [32, 45], [46, 50], [51, 65], [66, 75], [75, 76], [77, 84], [85, 93], [94, 104], [105, 108], [109, 122], [123, 133], [134, 146], [146, 147], [148, 154], [155, 161], [162, 166], [167, 170], [171, 177], [178, 186], [187, 190], [191, 199], [200, 209], [210, 215], [216, 222], [223, 230], [231, 240], [241, 245], [246, 248], [249, 260], [261, 268], [269, 271], [272, 280], [280, 281]]}
{"doc_key": "ai-test-85", "ner": [[1, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "WaveNet", "model", "proposed", "in", "2016", "achieves", "high", "broadcasting", "quality", "indicators", "."], "sentence-detokenized": "The WaveNet model proposed in 2016 achieves high broadcasting quality indicators.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 43], [44, 48], [49, 61], [62, 69], [70, 80], [80, 81]]}
{"doc_key": "ai-test-86", "ner": [[4, 4, "product"], [6, 7, "misc"], [9, 10, "misc"], [12, 13, "misc"], [15, 16, "misc"], [18, 20, "organisation"], [22, 22, "organisation"], [24, 26, "organisation"], [28, 28, "organisation"], [30, 33, "organisation"], [36, 36, "organisation"], [38, 38, "organisation"], [40, 42, "organisation"], [44, 44, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 4, 6, 7, "general-affiliation", "", false, false], [4, 4, 9, 10, "general-affiliation", "", false, false], [4, 4, 12, 13, "general-affiliation", "", false, false], [4, 4, 15, 16, "general-affiliation", "", false, false], [18, 20, 4, 4, "usage", "", false, false], [22, 22, 4, 4, "usage", "", false, false], [24, 26, 4, 4, "usage", "", false, false], [28, 28, 4, 4, "usage", "", false, false], [30, 33, 4, 4, "usage", "", false, false], [36, 36, 4, 4, "usage", "", false, false], [38, 38, 4, 4, "usage", "", false, false], [40, 42, 4, 4, "usage", "", false, false], [44, 44, 4, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Organizations", "known", "to", "use", "ALE", "for", "emergency", "management", ",", "disaster", "relief", ",", "routine", "communications", "or", "emergency", "response", ":", "American", "Red", "Cross", ",", "FEMA", ",", "disaster", "medical", "teams", ",", "NATO", ",", "Federal", "Bureau", "of", "Investigation", ",", "United", "Nations", ",", "AT&T", ",", "Civil", "Air", "Patrol", "(", "ARES", ")", "."], "sentence-detokenized": "Organizations known to use ALE for emergency management, disaster relief, routine communications or emergency response: American Red Cross, FEMA, disaster medical teams, NATO, Federal Bureau of Investigation, United Nations, AT&T, Civil Air Patrol (ARES).", "token2charspan": [[0, 13], [14, 19], [20, 22], [23, 26], [27, 30], [31, 34], [35, 44], [45, 55], [55, 56], [57, 65], [66, 72], [72, 73], [74, 81], [82, 96], [97, 99], [100, 109], [110, 118], [118, 119], [120, 128], [129, 132], [133, 138], [138, 139], [140, 144], [144, 145], [146, 154], [155, 162], [163, 168], [168, 169], [170, 174], [174, 175], [176, 183], [184, 190], [191, 193], [194, 207], [207, 208], [209, 215], [216, 223], [223, 224], [225, 229], [229, 230], [231, 236], [237, 240], [241, 247], [248, 249], [249, 253], [253, 254], [254, 255]]}
{"doc_key": "ai-test-87", "ner": [[5, 8, "algorithm"], [16, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Here", ",", "for", "simplicity", ",", "Kronecker", "'s", "delta", "is", "used", "(", "cf", ".", "the", "derivative", "of", "a", "sigmoid", "function", "expressed", "through", "the", "function", "itself", ")", "."], "sentence-detokenized": "Here, for simplicity, Kronecker's delta is used (cf. the derivative of a sigmoid function expressed through the function itself).", "token2charspan": [[0, 4], [4, 5], [6, 9], [10, 20], [20, 21], [22, 31], [31, 33], [34, 39], [40, 42], [43, 47], [48, 49], [49, 51], [51, 52], [53, 56], [57, 67], [68, 70], [71, 72], [73, 80], [81, 89], [90, 99], [100, 107], [108, 111], [112, 120], [121, 127], [127, 128], [128, 129]]}
{"doc_key": "ai-test-88", "ner": [[11, 12, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "theory", "is", "based", "on", "philosophical", "principles", "and", "was", "founded", "by", "Ray", "Solomonov", "around", "1960", ".", "Samuel", "Rathmanners", "and", "Markus", "Hutter", "."], "sentence-detokenized": "The theory is based on philosophical principles and was founded by Ray Solomonov around 1960. Samuel Rathmanners and Markus Hutter.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 36], [37, 47], [48, 51], [52, 55], [56, 63], [64, 66], [67, 70], [71, 80], [81, 87], [88, 92], [92, 93], [94, 100], [101, 112], [113, 116], [117, 123], [124, 130], [130, 131]]}
{"doc_key": "ai-test-89", "ner": [[0, 0, "product"], [10, 11, "misc"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 10, 11, "type-of", "", false, false], [0, 0, 14, 15, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["WordNet", ",", "a", "freely", "accessible", "database", "originally", "developed", "as", "a", "semantic", "network", "based", "on", "psycholinguistic", "principles", ",", "has", "been", "expanded", "to", "include", "definitions", "and", "is", "now", "also", "considered", "a", "dictionary", "."], "sentence-detokenized": "WordNet, a freely accessible database originally developed as a semantic network based on psycholinguistic principles, has been expanded to include definitions and is now also considered a dictionary.", "token2charspan": [[0, 7], [7, 8], [9, 10], [11, 17], [18, 28], [29, 37], [38, 48], [49, 58], [59, 61], [62, 63], [64, 72], [73, 80], [81, 86], [87, 89], [90, 106], [107, 117], [117, 118], [119, 122], [123, 127], [128, 136], [137, 139], [140, 147], [148, 159], [160, 163], [164, 166], [167, 170], [171, 175], [176, 186], [187, 188], [189, 199], [199, 200]]}
{"doc_key": "ai-test-90", "ner": [[2, 3, "field"], [12, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 12, 2, 3, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Advances", "in", "computer", "image", "research", "are", "presented", "in", "several", "venues", ",", "including", "SIGGRAPH", "publications", "and", "the", "."], "sentence-detokenized": "Advances in computer image research are presented in several venues, including SIGGRAPH publications and the.", "token2charspan": [[0, 8], [9, 11], [12, 20], [21, 26], [27, 35], [36, 39], [40, 49], [50, 52], [53, 60], [61, 67], [67, 68], [69, 78], [79, 87], [88, 100], [101, 104], [105, 108], [108, 109]]}
{"doc_key": "ai-test-91", "ner": [[0, 0, "task"], [9, 10, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 0, "part-of", "", false, false], [12, 13, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "considered", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multiclass", "classification", "."], "sentence-detokenized": "Classification can be considered as two separate problems - binary classification and multiclass classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 32], [33, 35], [36, 39], [40, 48], [49, 57], [58, 59], [60, 66], [67, 81], [82, 85], [86, 96], [97, 111], [111, 112]]}
{"doc_key": "ai-test-92", "ner": [[13, 13, "algorithm"], [18, 19, "algorithm"], [22, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 19, 13, 13, "type-of", "", false, false], [22, 22, 18, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Advanced", "gene", "discovery", "systems", "for", "both", "prokaryotic", "and", "eukaryotic", "genomes", "typically", "use", "sophisticated", "probabilistic", "models", ",", "such", "as", "Hidden", "Markov", "Models", "(", "HMMs", ")", ",", "to", "combine", "information", "derived", "from", "different", "signal", "and", "content", "measurements", "."], "sentence-detokenized": "Advanced gene discovery systems for both prokaryotic and eukaryotic genomes typically use sophisticated probabilistic models, such as Hidden Markov Models (HMMs), to combine information derived from different signal and content measurements.", "token2charspan": [[0, 8], [9, 13], [14, 23], [24, 31], [32, 35], [36, 40], [41, 52], [53, 56], [57, 67], [68, 75], [76, 85], [86, 89], [90, 103], [104, 117], [118, 124], [124, 125], [126, 130], [131, 133], [134, 140], [141, 147], [148, 154], [155, 156], [156, 160], [160, 161], [161, 162], [163, 165], [166, 173], [174, 185], [186, 193], [194, 198], [199, 208], [209, 215], [216, 219], [220, 227], [228, 240], [240, 241]]}
{"doc_key": "ai-test-93", "ner": [[0, 0, "misc"], [3, 5, "misc"], [9, 10, "field"], [13, 14, "algorithm"], [17, 18, "algorithm"], [21, 21, "algorithm"], [32, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 9, 10, "part-of", "", false, false], [0, 0, 13, 14, "usage", "", false, false], [3, 5, 0, 0, "named", "", false, false], [17, 18, 0, 0, "origin", "", true, false], [21, 21, 17, 18, "named", "", false, false], [32, 33, 0, 0, "origin", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Neuroevolution", ",", "or", "neurofusion", ",", "is", "a", "form", "of", "artificial", "intelligence", "that", "uses", "evolutionary", "algorithms", "to", "generate", "artificial", "neural", "networks", "(", "ANNs", ")", ",", "parameters", ",", "topology", ",", "and", "rules", ".", "and", "evolutionary", "robotics", "."], "sentence-detokenized": "Neuroevolution, or neurofusion, is a form of artificial intelligence that uses evolutionary algorithms to generate artificial neural networks (ANNs), parameters, topology, and rules. and evolutionary robotics.", "token2charspan": [[0, 14], [14, 15], [16, 18], [19, 30], [30, 31], [32, 34], [35, 36], [37, 41], [42, 44], [45, 55], [56, 68], [69, 73], [74, 78], [79, 91], [92, 102], [103, 105], [106, 114], [115, 125], [126, 132], [133, 141], [142, 143], [143, 147], [147, 148], [148, 149], [150, 160], [160, 161], [162, 170], [170, 171], [172, 175], [176, 181], [181, 182], [183, 186], [187, 199], [200, 208], [208, 209]]}
{"doc_key": "ai-test-94", "ner": [[1, 1, "organisation"], [6, 6, "metrics"], [8, 8, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 1, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "IBM", "proposed", "and", "implemented", "the", "BLEU", "system", "Papineni", "et", "al", "."], "sentence-detokenized": "Since IBM proposed and implemented the BLEU system Papineni et al.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 22], [23, 34], [35, 38], [39, 43], [44, 50], [51, 59], [60, 62], [63, 65], [65, 66]]}
{"doc_key": "ai-test-95", "ner": [[11, 18, "conference"], [20, 20, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 20, 11, 18, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2009", ",", "experts", "took", "part", "in", "a", "conference", "organized", "by", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "to", "discuss", "whether", "computers", "and", "robots", "can", "acquire", "any", "autonomy", ",", "and", "to", "what", "extent", "these", "abilities", "can", "pose", "a", "threat", "or", "danger", "."], "sentence-detokenized": "In 2009, experts took part in a conference organized by the Association for the Advancement of Artificial Intelligence (AAAI) to discuss whether computers and robots can acquire any autonomy, and to what extent these abilities can pose a threat or danger.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 21], [22, 26], [27, 29], [30, 31], [32, 42], [43, 52], [53, 55], [56, 59], [60, 71], [72, 75], [76, 79], [80, 91], [92, 94], [95, 105], [106, 118], [119, 120], [120, 124], [124, 125], [126, 128], [129, 136], [137, 144], [145, 154], [155, 158], [159, 165], [166, 169], [170, 177], [178, 181], [182, 190], [190, 191], [192, 195], [196, 198], [199, 203], [204, 210], [211, 216], [217, 226], [227, 230], [231, 235], [236, 237], [238, 244], [245, 247], [248, 254], [254, 255]]}
{"doc_key": "ai-test-96", "ner": [[20, 22, "metrics"], [22, 23, "researcher"], [25, 26, "researcher"], [28, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[28, 33, 20, 22, "topic", "", false, false], [28, 33, 22, 23, "artifact", "", false, false], [28, 33, 25, 26, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["After", "boosting", ",", "a", "classifier", "built", "from", "200", "features", "can", "give", "95", "%", "detection", "with", "^{", "-5", "}", "/", "math", "FALSE", "positive", "rate.P.", "Viola", ",", "M.", "Jones", ",", "Robust", "Real", "-", "time", "Object", "Detection", ",", "2001", "."], "sentence-detokenized": "After boosting, a classifier built from 200 features can give 95% detection with ^{-5} / math FALSE positive rate.P. Viola, M. Jones, Robust Real-time Object Detection, 2001.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 17], [18, 28], [29, 34], [35, 39], [40, 43], [44, 52], [53, 56], [57, 61], [62, 64], [64, 65], [66, 75], [76, 80], [81, 83], [83, 85], [85, 86], [87, 88], [89, 93], [94, 99], [100, 108], [109, 116], [117, 122], [122, 123], [124, 126], [127, 132], [132, 133], [134, 140], [141, 145], [145, 146], [146, 150], [151, 157], [158, 167], [167, 168], [169, 173], [173, 174]]}
{"doc_key": "ai-test-97", "ner": [[6, 6, "programlang"], [9, 9, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "website", "was", "originally", "based", "on", "Perl", ",", "but", "IMDb", "no", "longer", "discloses", "what", "software", "it", "uses", "for", "security", "reasons", "."], "sentence-detokenized": "The website was originally based on Perl, but IMDb no longer discloses what software it uses for security reasons.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 26], [27, 32], [33, 35], [36, 40], [40, 41], [42, 45], [46, 50], [51, 53], [54, 60], [61, 70], [71, 75], [76, 84], [85, 87], [88, 92], [93, 96], [97, 105], [106, 113], [113, 114]]}
{"doc_key": "ai-test-98", "ner": [[5, 6, "researcher"], [8, 9, "researcher"], [11, 12, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "startup", "was", "founded", "by", "Demis", "Hassabis", ",", "Shane", "Legg", "and", "Mustafa", "Suleiman", "in", "2010", "."], "sentence-detokenized": "The startup was founded by Demis Hassabis, Shane Legg and Mustafa Suleiman in 2010.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 26], [27, 32], [33, 41], [41, 42], [43, 48], [49, 53], [54, 57], [58, 65], [66, 74], [75, 77], [78, 82], [82, 83]]}
{"doc_key": "ai-test-99", "ner": [[4, 6, "misc"], [8, 10, "metrics"], [24, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 4, 6, "type-of", "", false, false], [24, 25, 4, 6, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "very", "commonly", "used", "loss", "functions", "are", "the", "mean", "square", "error", ",", "mathL", "(", "a", ")", "=", "a", "^2", "/", "math", ",", "and", "the", "absolute", "loss", ",", "mathL", "(", "a", ")", "=", "|", "a", "|", "/", "math", "."], "sentence-detokenized": "Two very commonly used loss functions are the mean square error, mathL(a) = a^2 / math, and the absolute loss, mathL(a) = | a | / math.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 27], [28, 37], [38, 41], [42, 45], [46, 50], [51, 57], [58, 63], [63, 64], [65, 70], [70, 71], [71, 72], [72, 73], [74, 75], [76, 77], [77, 79], [80, 81], [82, 86], [86, 87], [88, 91], [92, 95], [96, 104], [105, 109], [109, 110], [111, 116], [116, 117], [117, 118], [118, 119], [120, 121], [122, 123], [124, 125], [126, 127], [128, 129], [130, 134], [134, 135]]}
{"doc_key": "ai-test-100", "ner": [[1, 5, "algorithm"], [12, 14, "algorithm"], [16, 16, "algorithm"], [19, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 5, 12, 14, "type-of", "example_of", false, false], [12, 14, 19, 20, "related-to", "", false, false], [16, 16, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "soft", "margin", "support", "vector", "machine", "described", "above", "is", "an", "example", "of", "Empirical", "Risk", "Minimization", "(", "ERM", ")", "for", "hinge", "loss", "."], "sentence-detokenized": "The soft margin support vector machine described above is an example of Empirical Risk Minimization (ERM) for hinge loss.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 23], [24, 30], [31, 38], [39, 48], [49, 54], [55, 57], [58, 60], [61, 68], [69, 71], [72, 81], [82, 86], [87, 99], [100, 101], [101, 104], [104, 105], [106, 109], [110, 115], [116, 120], [120, 121]]}
{"doc_key": "ai-test-101", "ner": [[1, 4, "field"], [7, 7, "task"], [9, 11, "task"], [20, 21, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 11, 1, 4, "origin", "", false, false], [9, 11, 7, 7, "type-of", "", false, false], [20, 21, 9, 11, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "deep", "learning", "-", "based", "approach", "to", "MT", ",", "neural", "machine", "translation", "has", "made", "rapid", "progress", "in", "recent", "years", "and", "Google", "has", "announced", "that", "its", "translation", "services", "now", "use", "this", "technology", "in", "preference", "to", "the", "statistical", "methods", "used", "previously", "."], "sentence-detokenized": "A deep learning-based approach to MT, neural machine translation has made rapid progress in recent years and Google has announced that its translation services now use this technology in preference to the statistical methods used previously.", "token2charspan": [[0, 1], [2, 6], [7, 15], [15, 16], [16, 21], [22, 30], [31, 33], [34, 36], [36, 37], [38, 44], [45, 52], [53, 64], [65, 68], [69, 73], [74, 79], [80, 88], [89, 91], [92, 98], [99, 104], [105, 108], [109, 115], [116, 119], [120, 129], [130, 134], [135, 138], [139, 150], [151, 159], [160, 163], [164, 167], [168, 172], [173, 183], [184, 186], [187, 197], [198, 200], [201, 204], [205, 216], [217, 224], [225, 229], [230, 240], [240, 241]]}
{"doc_key": "ai-test-102", "ner": [[14, 14, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "usually", "gives", "very", "large", "performance", "gains", "when", "working", "with", "large", "corpora", "such", "as", "WordNet", "."], "sentence-detokenized": "This usually gives very large performance gains when working with large corpora such as WordNet.", "token2charspan": [[0, 4], [5, 12], [13, 18], [19, 23], [24, 29], [30, 41], [42, 47], [48, 52], [53, 60], [61, 65], [66, 71], [72, 79], [80, 84], [85, 87], [88, 95], [95, 96]]}
{"doc_key": "ai-test-103", "ner": [[0, 2, "task"], [5, 5, "field"], [17, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 17, 19, "part-of", "", false, false], [17, 19, 5, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Face", "detection", "is", "used", "in", "biometrics", ",", "often", "as", "part", "of", "(", "or", "together", "with", ")", "a", "face", "recognition", "system", "."], "sentence-detokenized": "Face detection is used in biometrics, often as part of (or together with) a face recognition system.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 22], [23, 25], [26, 36], [36, 37], [38, 43], [44, 46], [47, 51], [52, 54], [55, 56], [56, 58], [59, 67], [68, 72], [72, 73], [74, 75], [76, 80], [81, 92], [93, 99], [99, 100]]}
{"doc_key": "ai-test-104", "ner": [[5, 6, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["trained", "by", "the", "method", "of", "maximum", "plausibility", "."], "sentence-detokenized": "trained by the method of maximum plausibility.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 21], [22, 24], [25, 32], [33, 45], [45, 46]]}
{"doc_key": "ai-test-105", "ner": [[3, 3, "country"], [5, 9, "organisation"], [13, 13, "location"], [15, 15, "country"], [17, 20, "organisation"], [22, 22, "country"], [28, 28, "organisation"], [33, 35, "organisation"], [37, 38, "country"], [48, 51, "organisation"], [53, 54, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[5, 9, 13, 13, "physical", "", false, false], [13, 13, 15, 15, "physical", "", false, false], [17, 20, 22, 22, "physical", "", false, false], [33, 35, 37, 38, "physical", "", false, false], [48, 51, 53, 54, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Ltd", ".", "in", "Thailand", ";", "Komatsu", "(", "Shanghai", ")", "Ltd.", "in", "1996", "in", "Shanghai", ",", "China", ";", "Industrial", "Power", "Alliance", "Ltd.", "in", "Japan", ",", "a", "joint", "venture", "with", "Cummins", ",", "in", "1998", ";", "L&T-", "Komatsu", "Limited", "in", "India", "in", "1998", "(", "shares", "sold", "in", "2013", ")", ";", "and", "Komatsu", "Brasil", "International", "Ltda", "in", "Brazil", "in", "1998", "."], "sentence-detokenized": "Ltd. in Thailand; Komatsu (Shanghai) Ltd. in 1996 in Shanghai, China; Industrial Power Alliance Ltd. in Japan, a joint venture with Cummins, in 1998; L&T-Komatsu Limited in India in 1998 (shares sold in 2013); and Komatsu Brasil International Ltda in Brazil in 1998.", "token2charspan": [[0, 3], [3, 4], [5, 7], [8, 16], [16, 17], [18, 25], [26, 27], [27, 35], [35, 36], [37, 41], [42, 44], [45, 49], [50, 52], [53, 61], [61, 62], [63, 68], [68, 69], [70, 80], [81, 86], [87, 95], [96, 100], [101, 103], [104, 109], [109, 110], [111, 112], [113, 118], [119, 126], [127, 131], [132, 139], [139, 140], [141, 143], [144, 148], [148, 149], [150, 154], [154, 161], [162, 169], [170, 172], [173, 178], [179, 181], [182, 186], [187, 188], [188, 194], [195, 199], [200, 202], [203, 207], [207, 208], [208, 209], [210, 213], [214, 221], [222, 228], [229, 242], [243, 247], [248, 250], [251, 257], [258, 260], [261, 265], [265, 266]]}
{"doc_key": "ai-test-106", "ner": [[0, 0, "organisation"], [4, 4, "misc"], [7, 7, "misc"], [9, 10, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 0, 0, "physical", "", false, false], [9, 10, 4, 4, "general-affiliation", "", false, false], [9, 10, 7, 7, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["dgp", "also", "occasionally", "hosts", "artists", "(", "e.g.", "Oscar", "winner", "Chris", "Landreth", ")", "."], "sentence-detokenized": "dgp also occasionally hosts artists (e.g. Oscar winner Chris Landreth).", "token2charspan": [[0, 3], [4, 8], [9, 21], [22, 27], [28, 35], [36, 37], [37, 41], [42, 47], [48, 54], [55, 60], [61, 69], [69, 70], [70, 71]]}
{"doc_key": "ai-test-107", "ner": [[6, 6, "misc"], [7, 12, "misc"], [14, 20, "misc"], [22, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "currently", "includes", "four", "sub-competitions", "-", "RoboMaster", "Robotics", "Competition", ",", "RoboMaster", "Technical", "Competition", ",", "ICRA", "RoboMaster", "Artificial", "Intelligence", "Competition", "and", "the", "new", "RoboMaster", "Youth", "Tournament", "."], "sentence-detokenized": "It currently includes four sub-competitions - RoboMaster Robotics Competition, RoboMaster Technical Competition, ICRA RoboMaster Artificial Intelligence Competition and the new RoboMaster Youth Tournament.", "token2charspan": [[0, 2], [3, 12], [13, 21], [22, 26], [27, 43], [44, 45], [46, 56], [57, 65], [66, 77], [77, 78], [79, 89], [90, 99], [100, 111], [111, 112], [113, 117], [118, 128], [129, 139], [140, 152], [153, 164], [165, 168], [169, 172], [173, 176], [177, 187], [188, 193], [194, 204], [204, 205]]}
{"doc_key": "ai-test-108", "ner": [[7, 8, "field"], [16, 17, "algorithm"], [21, 22, "algorithm"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 21, 22, "usage", "", false, false], [7, 8, 24, 25, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "the", "early", "2000s", ",", "the", "dominant", "speech", "processing", "strategy", "began", "to", "shift", "from", "the", "hidden", "Markov", "model", "to", "more", "modern", "neural", "networks", "and", "deep", "learning", "."], "sentence-detokenized": "In the early 2000s, the dominant speech processing strategy began to shift from the hidden Markov model to more modern neural networks and deep learning.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 18], [18, 19], [20, 23], [24, 32], [33, 39], [40, 50], [51, 59], [60, 65], [66, 68], [69, 74], [75, 79], [80, 83], [84, 90], [91, 97], [98, 103], [104, 106], [107, 111], [112, 118], [119, 125], [126, 134], [135, 138], [139, 143], [144, 152], [152, 153]]}
{"doc_key": "ai-test-109", "ner": [[8, 11, "misc"], [17, 18, "metrics"], [21, 24, "metrics"], [30, 32, "metrics"], [35, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[17, 18, 21, 24, "related-to", "equal", false, false], [30, 32, 35, 38, "related-to", "equal", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "equivalent", "expression", ",", "in", "the", "case", "of", "a", "binary", "target", "rate", ",", "is", "that", "the", "true", "positive", "rate", "and", "the", "false", "positive", "rate", "are", "equal", "(", "and", "hence", "the", "false", "negative", "rate", "and", "the", "true", "negative", "rate", "are", "equal", ")", "for", "each", "value", "of", "the", "sensitivities", ":"], "sentence-detokenized": "Another equivalent expression, in the case of a binary target rate, is that the true positive rate and the false positive rate are equal (and hence the false negative rate and the true negative rate are equal) for each value of the sensitivities:", "token2charspan": [[0, 7], [8, 18], [19, 29], [29, 30], [31, 33], [34, 37], [38, 42], [43, 45], [46, 47], [48, 54], [55, 61], [62, 66], [66, 67], [68, 70], [71, 75], [76, 79], [80, 84], [85, 93], [94, 98], [99, 102], [103, 106], [107, 112], [113, 121], [122, 126], [127, 130], [131, 136], [137, 138], [138, 141], [142, 147], [148, 151], [152, 157], [158, 166], [167, 171], [172, 175], [176, 179], [180, 184], [185, 193], [194, 198], [199, 202], [203, 208], [208, 209], [210, 213], [214, 218], [219, 224], [225, 227], [228, 231], [232, 245], [245, 246]]}
{"doc_key": "ai-test-110", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["MATLAB", "function", ","], "sentence-detokenized": "MATLAB function,", "token2charspan": [[0, 6], [7, 15], [15, 16]]}
{"doc_key": "ai-test-111", "ner": [[0, 4, "product"], [8, 8, "misc"], [18, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 0, 4, "part-of", "", false, false], [18, 19, 0, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "articulated", "robot", "is", "a", "robot", "with", "articulated", "joints", "(", "for", "example", ",", "a", "legged", "robot", "or", "an", "industrial", "robot", ")", "."], "sentence-detokenized": "An articulated robot is a robot with articulated joints (for example, a legged robot or an industrial robot).", "token2charspan": [[0, 2], [3, 14], [15, 20], [21, 23], [24, 25], [26, 31], [32, 36], [37, 48], [49, 55], [56, 57], [57, 60], [61, 68], [68, 69], [70, 71], [72, 78], [79, 84], [85, 87], [88, 90], [91, 101], [102, 107], [107, 108], [108, 109]]}
{"doc_key": "ai-test-112", "ner": [[0, 0, "product"], [5, 6, "product"], [8, 9, "product"], [13, 13, "misc"], [20, 27, "product"], [28, 31, "misc"], [34, 34, "location"], [36, 36, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 13, 13, "general-affiliation", "nationality", false, false], [0, 0, 28, 31, "usage", "", false, false], [0, 0, 34, 34, "physical", "", false, false], [5, 6, 0, 0, "named", "", false, false], [8, 9, 0, 0, "named", "", false, false], [34, 34, 36, 36, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pandora", "(", "also", "known", "as", "Pandora", "Media", "or", "Pandora", "Radio", ")", "is", "an", "American", "music", "streaming", "internet", "radio", "station", "with", "an", "automated", "recommendation", "system", ",", "powered", "by", "the", "Music", "Genome", "Project", "and", "headquartered", "in", "Oakland", ",", "California", "."], "sentence-detokenized": "Pandora (also known as Pandora Media or Pandora Radio) is an American music streaming internet radio station with an automated recommendation system, powered by the Music Genome Project and headquartered in Oakland, California.", "token2charspan": [[0, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 30], [31, 36], [37, 39], [40, 47], [48, 53], [53, 54], [55, 57], [58, 60], [61, 69], [70, 75], [76, 85], [86, 94], [95, 100], [101, 108], [109, 113], [114, 116], [117, 126], [127, 141], [142, 148], [148, 149], [150, 157], [158, 160], [161, 164], [165, 170], [171, 177], [178, 185], [186, 189], [190, 203], [204, 206], [207, 214], [214, 215], [216, 226], [226, 227]]}
{"doc_key": "ai-test-113", "ner": [[7, 11, "organisation"], [17, 21, "organisation"], [26, 27, "conference"], [40, 40, "conference"], [42, 42, "conference"], [44, 44, "conference"], [46, 46, "conference"], [48, 48, "conference"], [50, 50, "conference"], [52, 52, "conference"], [54, 54, "conference"], [56, 56, "conference"], [59, 59, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "is", "a", "board", "member", "of", "the", "International", "Society", "for", "Machine", "Learning", ",", "was", "a", "member", "of", "the", "Executive", "Board", "of", "AAAI", ",", "co-chair", "of", "the", "ICML", "2011", "PC", ",", "and", "a", "senior", "member", "of", "the", "PCs", "of", "conferences", "including", "AAAI", ",", "ICML", ",", "IJCAI", ",", "ISWC", ",", "KDD", ",", "SIGMOD", ",", "UAI", ",", "VLDB", ",", "WSDM", ",", "and", "WWW", "."], "sentence-detokenized": "She is a board member of the International Society for Machine Learning, was a member of the Executive Board of AAAI, co-chair of the ICML 2011 PC, and a senior member of the PCs of conferences including AAAI, ICML, IJCAI, ISWC, KDD, SIGMOD, UAI, VLDB, WSDM, and WWW.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 14], [15, 21], [22, 24], [25, 28], [29, 42], [43, 50], [51, 54], [55, 62], [63, 71], [71, 72], [73, 76], [77, 78], [79, 85], [86, 88], [89, 92], [93, 102], [103, 108], [109, 111], [112, 116], [116, 117], [118, 126], [127, 129], [130, 133], [134, 138], [139, 143], [144, 146], [146, 147], [148, 151], [152, 153], [154, 160], [161, 167], [168, 170], [171, 174], [175, 178], [179, 181], [182, 193], [194, 203], [204, 208], [208, 209], [210, 214], [214, 215], [216, 221], [221, 222], [223, 227], [227, 228], [229, 232], [232, 233], [234, 240], [240, 241], [242, 245], [245, 246], [247, 251], [251, 252], [253, 257], [257, 258], [259, 262], [263, 266], [266, 267]]}
{"doc_key": "ai-test-114", "ner": [[0, 2, "researcher"], [5, 10, "organisation"], [12, 12, "organisation"], [17, 18, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 10, "role", "", false, false], [12, 12, 5, 10, "named", "", false, false], [17, 18, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["James", "S.", "Albus", "of", "the", "National", "Institute", "of", "Standards", "and", "Technology", "(", "NIST", ")", "has", "developed", "a", "robocrane", "in", "which", "the", "platform", "hangs", "on", "six", "cables", "rather", "than", "being", "supported", "by", "six", "jacks", "."], "sentence-detokenized": "James S. Albus of the National Institute of Standards and Technology (NIST) has developed a robocrane in which the platform hangs on six cables rather than being supported by six jacks.", "token2charspan": [[0, 5], [6, 8], [9, 14], [15, 17], [18, 21], [22, 30], [31, 40], [41, 43], [44, 53], [54, 57], [58, 68], [69, 70], [70, 74], [74, 75], [76, 79], [80, 89], [90, 91], [92, 101], [102, 104], [105, 110], [111, 114], [115, 123], [124, 129], [130, 132], [133, 136], [137, 143], [144, 150], [151, 155], [156, 161], [162, 171], [172, 174], [175, 178], [179, 184], [184, 185]]}
{"doc_key": "ai-test-115", "ner": [[3, 5, "algorithm"], [8, 9, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 3, 5, "type-of", "", false, false], [13, 14, 8, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "class", "of", "direct", "search", "algorithms", "are", "various", "evolutionary", "algorithms", ",", "such", "as", "genetic", "algorithms", "."], "sentence-detokenized": "Another class of direct search algorithms are various evolutionary algorithms, such as genetic algorithms.", "token2charspan": [[0, 7], [8, 13], [14, 16], [17, 23], [24, 30], [31, 41], [42, 45], [46, 53], [54, 66], [67, 77], [77, 78], [79, 83], [84, 86], [87, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-test-116", "ner": [[0, 0, "organisation"], [3, 5, "misc"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 0, 0, "named", "", false, false], [6, 7, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["KUKA", "is", "a", "German", "manufacturer", "of", "industrial", "robots", "and", "solutions", "for", "production", "automation", "."], "sentence-detokenized": "KUKA is a German manufacturer of industrial robots and solutions for production automation.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 16], [17, 29], [30, 32], [33, 43], [44, 50], [51, 54], [55, 64], [65, 68], [69, 79], [80, 90], [90, 91]]}
{"doc_key": "ai-test-117", "ner": [[4, 6, "misc"], [19, 20, "person"], [10, 18, "misc"], [26, 27, "person"], [23, 25, "misc"], [34, 35, "person"], [30, 33, "misc"], [42, 43, "person"], [38, 40, "misc"], [52, 54, "person"], [46, 51, "misc"], [61, 62, "person"], [63, 67, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[19, 20, 4, 6, "usage", "", false, false], [10, 18, 19, 20, "artifact", "", false, false], [26, 27, 4, 6, "usage", "", false, false], [23, 25, 26, 27, "artifact", "", false, false], [34, 35, 4, 6, "usage", "", false, false], [30, 33, 34, 35, "artifact", "", false, false], [42, 43, 4, 6, "usage", "", false, false], [38, 40, 42, 43, "artifact", "", false, false], [52, 54, 4, 6, "usage", "", false, false], [46, 51, 52, 54, "artifact", "", false, false], [61, 62, 4, 6, "usage", "", false, false], [63, 67, 61, 62, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Other", "films", "shot", "with", "IMAX", "cameras", "in", "2016-2020", "include", "\"", "Batman", "v", "Superman", ":", "Dawn", "of", "Justice", "\"", "by", "Zack", "Snyder", ",", "\"", "Sully", "\"", "by", "Clint", "Eastwood", ",", "\"", "First", "Man", "\"", "by", "Damien", "Chazelle", ",", "\"", "Wonder", "Woman", "1984", "\"", "Patty", "Jenkins", ",", "\"", "No", "Time", "to", "Die", "\"", "by", "Cary", "Jo", "Fukunaga", "and", "\"", "Top", "Gun", "\"", "by", "Joseph", "Kosinski", ":", "Maverick", "by", "Joseph", "Kosinski", "."], "sentence-detokenized": "Other films shot with IMAX cameras in 2016-2020 include \"Batman v Superman: Dawn of Justice\" by Zack Snyder, \"Sully\" by Clint Eastwood, \"First Man\" by Damien Chazelle, \"Wonder Woman 1984\" Patty Jenkins, \"No Time to Die\" by Cary Jo Fukunaga and \"Top Gun\" by Joseph Kosinski: Maverick by Joseph Kosinski.", "token2charspan": [[0, 5], [6, 11], [12, 16], [17, 21], [22, 26], [27, 34], [35, 37], [38, 47], [48, 55], [56, 57], [57, 63], [64, 65], [66, 74], [74, 75], [76, 80], [81, 83], [84, 91], [91, 92], [93, 95], [96, 100], [101, 107], [107, 108], [109, 110], [110, 115], [115, 116], [117, 119], [120, 125], [126, 134], [134, 135], [136, 137], [137, 142], [143, 146], [146, 147], [148, 150], [151, 157], [158, 166], [166, 167], [168, 169], [169, 175], [176, 181], [182, 186], [186, 187], [188, 193], [194, 201], [201, 202], [203, 204], [204, 206], [207, 211], [212, 214], [215, 218], [218, 219], [220, 222], [223, 227], [228, 230], [231, 239], [240, 243], [244, 245], [245, 248], [249, 252], [252, 253], [254, 256], [257, 263], [264, 272], [272, 273], [274, 282], [283, 285], [286, 292], [293, 301], [301, 302]]}
{"doc_key": "ai-test-118", "ner": [[4, 5, "misc"], [9, 13, "organisation"], [15, 17, "organisation"], [28, 28, "misc"], [35, 36, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 28, 28, "named", "", false, false], [9, 13, 4, 5, "usage", "", false, false], [9, 13, 35, 36, "physical", "", false, false], [15, 17, 9, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "prototype", "of", "the", "MICR", "E13B", "font", "was", "demonstrated", "to", "the", "American", "Bankers", "Association", "(", "ABA", ")", "in", "July", "1956", ",", "which", "adopted", "it", "in", "1958", "as", "the", "MICR", "standard", "for", "contract", "documents", "in", "the", "United", "States", "."], "sentence-detokenized": "A prototype of the MICR E13B font was demonstrated to the American Bankers Association (ABA) in July 1956, which adopted it in 1958 as the MICR standard for contract documents in the United States.", "token2charspan": [[0, 1], [2, 11], [12, 14], [15, 18], [19, 23], [24, 28], [29, 33], [34, 37], [38, 50], [51, 53], [54, 57], [58, 66], [67, 74], [75, 86], [87, 88], [88, 91], [91, 92], [93, 95], [96, 100], [101, 105], [105, 106], [107, 112], [113, 120], [121, 123], [124, 126], [127, 131], [132, 134], [135, 138], [139, 143], [144, 152], [153, 156], [157, 165], [166, 175], [176, 178], [179, 182], [183, 189], [190, 196], [196, 197]]}
{"doc_key": "ai-test-119", "ner": [[0, 2, "misc"], [16, 17, "field"], [22, 23, "field"], [26, 26, "field"], [28, 29, "field"], [31, 31, "field"], [9, 33, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[16, 17, 0, 2, "usage", "", false, false], [22, 23, 16, 17, "part-of", "", false, false], [26, 26, 0, 2, "usage", "", false, false], [28, 29, 0, 2, "usage", "", false, false], [31, 31, 0, 2, "usage", "", false, false], [9, 33, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Local", "search", "algorithms", "are", "widely", "used", "to", "solve", "numerous", "complex", "computational", "problems", ",", "including", "problems", "in", "computer", "science", "(", "in", "particular", ",", "artificial", "intelligence", ")", ",", "mathematics", ",", "operations", "research", ",", "engineering", "and", "bioinformatics", "."], "sentence-detokenized": "Local search algorithms are widely used to solve numerous complex computational problems, including problems in computer science (in particular, artificial intelligence), mathematics, operations research, engineering and bioinformatics.", "token2charspan": [[0, 5], [6, 12], [13, 23], [24, 27], [28, 34], [35, 39], [40, 42], [43, 48], [49, 57], [58, 65], [66, 79], [80, 88], [88, 89], [90, 99], [100, 108], [109, 111], [112, 120], [121, 128], [129, 130], [130, 132], [133, 143], [143, 144], [145, 155], [156, 168], [168, 169], [169, 170], [171, 182], [182, 183], [184, 194], [195, 203], [203, 204], [205, 216], [217, 220], [221, 235], [235, 236]]}
{"doc_key": "ai-test-120", "ner": [[0, 1, "researcher"], [9, 9, "location"], [11, 11, "country"], [15, 15, "country"], [23, 24, "algorithm"], [26, 26, "algorithm"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 9, 9, "physical", "", false, false], [0, 1, 15, 15, "general-affiliation", "nationality", false, false], [0, 1, 23, 24, "general-affiliation", "topic_of_study", false, false], [0, 1, 26, 26, "general-affiliation", "topic_of_study", false, false], [9, 9, 11, 11, "physical", "", false, false], [26, 26, 28, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gerd", "Gigerenzer", "(", "born", "September", "3", ",", "1947", ",", "Wallersdorf", ",", "Germany", ")", "is", "a", "German", "psychologist", "who", "has", "researched", "the", "use", "of", "bounded", "rationality", "and", "heuristics", "in", "decision", "making", "."], "sentence-detokenized": "Gerd Gigerenzer (born September 3, 1947, Wallersdorf, Germany) is a German psychologist who has researched the use of bounded rationality and heuristics in decision making.", "token2charspan": [[0, 4], [5, 15], [16, 17], [17, 21], [22, 31], [32, 33], [33, 34], [35, 39], [39, 40], [41, 52], [52, 53], [54, 61], [61, 62], [63, 65], [66, 67], [68, 74], [75, 87], [88, 91], [92, 95], [96, 106], [107, 110], [111, 114], [115, 117], [118, 125], [126, 137], [138, 141], [142, 152], [153, 155], [156, 164], [165, 171], [171, 172]]}
{"doc_key": "ai-test-121", "ner": [[3, 6, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["to", "minimize", "the", "root", "mean", "square", "error", "."], "sentence-detokenized": "to minimize the root mean square error.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 20], [21, 25], [26, 32], [33, 38], [38, 39]]}
{"doc_key": "ai-test-122", "ner": [[12, 13, "misc"], [16, 17, "organisation"], [31, 33, "field"], [48, 49, "misc"], [58, 60, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 13, 16, 17, "origin", "", false, false], [48, 49, 58, 60, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["But", "even", "an", "official", "language", "with", "a", "regulating", "academy", ",", "such", "as", "Standard", "French", "with", "the", "Acad\u00e9mie", "fran\u00e7aise", ",", "is", "classified", "as", "a", "natural", "language", "(", "e.g.", "in", "the", "field", "of", "natural", "language", "processing", ")", "because", "its", "prescriptions", "make", "it", "neither", "sufficiently", "constructed", "to", "be", "classified", "as", "a", "constructed", "language", "nor", "sufficiently", "controlled", "to", "be", "classified", "as", "a", "controlled", "natural", "language", "."], "sentence-detokenized": "But even an official language with a regulating academy, such as Standard French with the Acad\u00e9mie fran\u00e7aise, is classified as a natural language (e.g. in the field of natural language processing) because its prescriptions make it neither sufficiently constructed to be classified as a constructed language nor sufficiently controlled to be classified as a controlled natural language.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 20], [21, 29], [30, 34], [35, 36], [37, 47], [48, 55], [55, 56], [57, 61], [62, 64], [65, 73], [74, 80], [81, 85], [86, 89], [90, 98], [99, 108], [108, 109], [110, 112], [113, 123], [124, 126], [127, 128], [129, 136], [137, 145], [146, 147], [147, 151], [152, 154], [155, 158], [159, 164], [165, 167], [168, 175], [176, 184], [185, 195], [195, 196], [197, 204], [205, 208], [209, 222], [223, 227], [228, 230], [231, 238], [239, 251], [252, 263], [264, 266], [267, 269], [270, 280], [281, 283], [284, 285], [286, 297], [298, 306], [307, 310], [311, 323], [324, 334], [335, 337], [338, 340], [341, 351], [352, 354], [355, 356], [357, 367], [368, 375], [376, 384], [384, 385]]}
{"doc_key": "ai-test-123", "ner": [[14, 14, "metrics"], [16, 17, "metrics"], [19, 19, "metrics"], [40, 41, "metrics"], [43, 43, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 19, 16, 17, "named", "", false, false], [43, 43, 40, 41, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "a", "number", "of", "other", "indicators", ",", "the", "simplest", "of", "which", "is", "the", "accuracy", "or", "Fraction", "Correct", "(", "FC", ")", ",", "which", "measures", "the", "proportion", "of", "all", "cases", "that", "were", "correctly", "classified", ";", "a", "complement", "to", "this", "is", "the", "Fraction", "Incorrect", "(", "FiC", ")", "."], "sentence-detokenized": "There are a number of other indicators, the simplest of which is the accuracy or Fraction Correct (FC), which measures the proportion of all cases that were correctly classified; a complement to this is the Fraction Incorrect (FiC).", "token2charspan": [[0, 5], [6, 9], [10, 11], [12, 18], [19, 21], [22, 27], [28, 38], [38, 39], [40, 43], [44, 52], [53, 55], [56, 61], [62, 64], [65, 68], [69, 77], [78, 80], [81, 89], [90, 97], [98, 99], [99, 101], [101, 102], [102, 103], [104, 109], [110, 118], [119, 122], [123, 133], [134, 136], [137, 140], [141, 146], [147, 151], [152, 156], [157, 166], [167, 177], [177, 178], [179, 180], [181, 191], [192, 194], [195, 199], [200, 202], [203, 206], [207, 215], [216, 225], [226, 227], [227, 230], [230, 231], [231, 232]]}
{"doc_key": "ai-test-124", "ner": [[0, 0, "researcher"], [6, 9, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 9, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cardi", "became", "a", "member", "of", "the", "Association", "for", "Computational", "Linguistics", "in", "2016", "."], "sentence-detokenized": "Cardi became a member of the Association for Computational Linguistics in 2016.", "token2charspan": [[0, 5], [6, 12], [13, 14], [15, 21], [22, 24], [25, 28], [29, 40], [41, 44], [45, 58], [59, 70], [71, 73], [74, 78], [78, 79]]}
{"doc_key": "ai-test-125", "ner": [[15, 16, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "training", "of", "the", "parameters", "math", "\\", "theta", "/", "math", "is", "usually", "performed", "by", "the", "maximum", "likelihood", "method", "for", "mathp", "(", "Y", "_", "i", "|", "X", "_", "i", ";", "\\", "theta", ")", "/", "math", "."], "sentence-detokenized": "The training of the parameters math\\ theta/math is usually performed by the maximum likelihood method for mathp(Y _ i | X _ i;\\ theta)/math.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 19], [20, 30], [31, 35], [35, 36], [37, 42], [42, 43], [43, 47], [48, 50], [51, 58], [59, 68], [69, 71], [72, 75], [76, 83], [84, 94], [95, 101], [102, 105], [106, 111], [111, 112], [112, 113], [114, 115], [116, 117], [118, 119], [120, 121], [122, 123], [124, 125], [125, 126], [126, 127], [128, 133], [133, 134], [134, 135], [135, 139], [139, 140]]}
{"doc_key": "ai-test-126", "ner": [[0, 1, "task"], [3, 5, "algorithm"], [7, 8, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 0, 1, "usage", "", true, false], [7, 8, 3, 5, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cluster", "analysis", "and", "Non-negative", "matrix", "factorization", "for", "descriptive", "mining", "."], "sentence-detokenized": "Cluster analysis and Non-negative matrix factorization for descriptive mining.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 33], [34, 40], [41, 54], [55, 58], [59, 70], [71, 77], [77, 78]]}
{"doc_key": "ai-test-127", "ner": [[1, 2, "field"], [5, 6, "field"], [21, 24, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 24, 1, 2, "part-of", "", false, false], [21, 24, 5, 6, "part-of", "", false, false], [27, 28, 1, 2, "part-of", "", false, false], [27, 28, 5, 6, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", "and", "the", "information", "technology", "it", "enables", ",", "a", "long", "-", "standing", "challenge", "has", "been", "the", "ability", "of", "computers", "to", "process", "natural", "language", "and", "perform", "machine", "learning", "."], "sentence-detokenized": "In computer science and the information technology it enables, a long-standing challenge has been the ability of computers to process natural language and perform machine learning.", "token2charspan": [[0, 2], [3, 11], [12, 19], [20, 23], [24, 27], [28, 39], [40, 50], [51, 53], [54, 61], [61, 62], [63, 64], [65, 69], [69, 70], [70, 78], [79, 88], [89, 92], [93, 97], [98, 101], [102, 109], [110, 112], [113, 122], [123, 125], [126, 133], [134, 141], [142, 150], [151, 154], [155, 162], [163, 170], [171, 179], [179, 180]]}
{"doc_key": "ai-test-128", "ner": [[4, 6, "algorithm"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 10, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "The", "code", "for", "extracting", "Gabor", "features", "from", "images", "in", "MATLAB", "can", "be", "found", "here"], "sentence-detokenized": "(The code for extracting Gabor features from images in MATLAB can be found here", "token2charspan": [[0, 1], [1, 4], [5, 9], [10, 13], [14, 24], [25, 30], [31, 39], [40, 44], [45, 51], [52, 54], [55, 61], [62, 65], [66, 68], [69, 74], [75, 79]]}
{"doc_key": "ai-test-129", "ner": [[0, 1, "misc"], [16, 17, "algorithm"], [19, 19, "task"], [21, 21, "task"], [23, 24, "task"], [26, 27, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 16, 17, "general-affiliation", "", false, false], [0, 1, 19, 19, "related-to", "solves_problem_of_type", false, false], [0, 1, 21, 21, "related-to", "solves_problem_of_type", false, false], [0, 1, 23, 24, "related-to", "solves_problem_of_type", false, false], [0, 1, 26, 27, "related-to", "solves_problem_of_type", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["NeuralExpert", "focuses", "project", "specifications", "on", "the", "type", "of", "problem", "the", "user", "wants", "to", "solve", "with", "a", "neural", "network", "(", "classification", ",", "prediction", ",", "function", "approximation", "or", "cluster", "analysis", ")", "."], "sentence-detokenized": "NeuralExpert focuses project specifications on the type of problem the user wants to solve with a neural network (classification, prediction, function approximation or cluster analysis).", "token2charspan": [[0, 12], [13, 20], [21, 28], [29, 43], [44, 46], [47, 50], [51, 55], [56, 58], [59, 66], [67, 70], [71, 75], [76, 81], [82, 84], [85, 90], [91, 95], [96, 97], [98, 104], [105, 112], [113, 114], [114, 128], [128, 129], [130, 140], [140, 141], [142, 150], [151, 164], [165, 167], [168, 175], [176, 184], [184, 185], [185, 186]]}
{"doc_key": "ai-test-130", "ner": [[2, 4, "misc"], [27, 28, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "the", "quantization", "step", "size", "(", "\u0394", ")", "is", "small", "relative", "to", "the", "variation", "of", "the", "quantized", "signal", ",", "it", "is", "relatively", "simple", "to", "show", "that", "the", "RMS", "error", "produced", "by", "such", "a", "rounding", "operation", "will", "be", "approximately", "equal", "to", "math", "\\", "Delta^2/12", "/math.math"], "sentence-detokenized": "When the quantization step size (\u0394) is small relative to the variation of the quantized signal, it is relatively simple to show that the RMS error produced by such a rounding operation will be approximately equal to math\\ Delta^2/12/math.math", "token2charspan": [[0, 4], [5, 8], [9, 21], [22, 26], [27, 31], [32, 33], [33, 34], [34, 35], [36, 38], [39, 44], [45, 53], [54, 56], [57, 60], [61, 70], [71, 73], [74, 77], [78, 87], [88, 94], [94, 95], [96, 98], [99, 101], [102, 112], [113, 119], [120, 122], [123, 127], [128, 132], [133, 136], [137, 140], [141, 146], [147, 155], [156, 158], [159, 163], [164, 165], [166, 174], [175, 184], [185, 189], [190, 192], [193, 206], [207, 212], [213, 215], [216, 220], [220, 221], [222, 232], [232, 242]]}
{"doc_key": "ai-test-131", "ner": [[16, 16, "product"], [26, 29, "researcher"], [31, 32, "researcher"], [34, 36, "researcher"], [38, 39, "researcher"], [41, 43, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Building", "a", "rich", "lexicon", "with", "an", "appropriate", "ontology", "requires", "considerable", "effort", ",", "for", "example", ",", "the", "Wordnet", "lexicon", "required", "many", "man", "-", "years", "of", "effort", ".", "G.", "A", ".", "Miller", ",", "R.", "Beckwith", ",", "C.", "D.", "Fellbaum", ",", "D.", "Gross", ",", "K", ".", "Miller", "."], "sentence-detokenized": "Building a rich lexicon with an appropriate ontology requires considerable effort, for example, the Wordnet lexicon required many man-years of effort. G. A. Miller, R. Beckwith, C. D. Fellbaum, D. Gross, K. Miller.", "token2charspan": [[0, 8], [9, 10], [11, 15], [16, 23], [24, 28], [29, 31], [32, 43], [44, 52], [53, 61], [62, 74], [75, 81], [81, 82], [83, 86], [87, 94], [94, 95], [96, 99], [100, 107], [108, 115], [116, 124], [125, 129], [130, 133], [133, 134], [134, 139], [140, 142], [143, 149], [149, 150], [151, 153], [154, 155], [155, 156], [157, 163], [163, 164], [165, 167], [168, 176], [176, 177], [178, 180], [181, 183], [184, 192], [192, 193], [194, 196], [197, 202], [202, 203], [204, 205], [205, 206], [207, 213], [213, 214]]}
{"doc_key": "ai-test-132", "ner": [[0, 0, "organisation"], [20, 21, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 21, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Kawasaki", "'s", "portfolio", "also", "includes", "retractable", "roofs", ",", "floors", "and", "other", "giant", "structures", ",", "one", "example", "of", "which", "is", "the", "Sapporo", "Dome", "retractable", "surface", "."], "sentence-detokenized": "Kawasaki's portfolio also includes retractable roofs, floors and other giant structures, one example of which is the Sapporo Dome retractable surface.", "token2charspan": [[0, 8], [8, 10], [11, 20], [21, 25], [26, 34], [35, 46], [47, 52], [52, 53], [54, 60], [61, 64], [65, 70], [71, 76], [77, 87], [87, 88], [89, 92], [93, 100], [101, 103], [104, 109], [110, 112], [113, 116], [117, 124], [125, 129], [130, 141], [142, 149], [149, 150]]}
{"doc_key": "ai-test-133", "ner": [[0, 1, "metrics"], [5, 5, "metrics"], [9, 11, "metrics"], [17, 20, "metrics"], [38, 40, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 17, 20, "related-to", "", false, false], [0, 1, 38, 40, "opposite", "alternative_to", false, false], [5, 5, 0, 1, "type-of", "", false, false], [9, 11, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kappa", "statistics", ",", "such", "as", "Fleiss", "'", "kappa", "and", "Cohen", "'s", "kappa", ",", "are", "methods", "for", "calculating", "inter-rater", "reliability", "based", "on", "different", "assumptions", "about", "marginal", "or", "prior", "distributions", ",", "and", "are", "increasingly", "used", "as", "alternatives", "to", "chance", "-", "corrected", "precision", "in", "other", "contexts", "."], "sentence-detokenized": "Kappa statistics, such as Fleiss' kappa and Cohen's kappa, are methods for calculating inter-rater reliability based on different assumptions about marginal or prior distributions, and are increasingly used as alternatives to chance-corrected precision in other contexts.", "token2charspan": [[0, 5], [6, 16], [16, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 39], [40, 43], [44, 49], [49, 51], [52, 57], [57, 58], [59, 62], [63, 70], [71, 74], [75, 86], [87, 98], [99, 110], [111, 116], [117, 119], [120, 129], [130, 141], [142, 147], [148, 156], [157, 159], [160, 165], [166, 179], [179, 180], [181, 184], [185, 188], [189, 201], [202, 206], [207, 209], [210, 222], [223, 225], [226, 232], [232, 233], [233, 242], [243, 252], [253, 255], [256, 261], [262, 270], [270, 271]]}
{"doc_key": "ai-test-134", "ner": [[4, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [13, 16, "researcher"], [19, 19, "researcher"], [28, 30, "algorithm"], [33, 37, "algorithm"], [39, 39, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 19, 19, "role", "student_of", false, false], [7, 8, 19, 19, "role", "student_of", false, false], [10, 11, 19, 19, "role", "student_of", false, false], [13, 16, 19, 19, "role", "student_of", false, false], [33, 37, 4, 5, "origin", "", false, false], [33, 37, 7, 8, "origin", "", false, false], [33, 37, 10, 11, "origin", "", false, false], [33, 37, 13, 16, "origin", "", false, false], [33, 37, 19, 19, "origin", "", false, false], [33, 37, 28, 30, "type-of", "", false, false], [39, 39, 33, 37, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Together", "with", "his", "students", "Sepp", "Hochreiter", ",", "Felix", "Gers", ",", "Fred", "Cummins", ",", "Alex", "Graves", ",", "and", "others", ",", "Schmidhuber", "published", "increasingly", "sophisticated", "versions", "of", "a", "type", "of", "recurrent", "neural", "network", "called", "a", "long", "short", "-", "term", "memory", "(", "LSTM", ")", "."], "sentence-detokenized": "Together with his students Sepp Hochreiter, Felix Gers, Fred Cummins, Alex Graves, and others, Schmidhuber published increasingly sophisticated versions of a type of recurrent neural network called a long short-term memory (LSTM).", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 26], [27, 31], [32, 42], [42, 43], [44, 49], [50, 54], [54, 55], [56, 60], [61, 68], [68, 69], [70, 74], [75, 81], [81, 82], [83, 86], [87, 93], [93, 94], [95, 106], [107, 116], [117, 129], [130, 143], [144, 152], [153, 155], [156, 157], [158, 162], [163, 165], [166, 175], [176, 182], [183, 190], [191, 197], [198, 199], [200, 204], [205, 210], [210, 211], [211, 215], [216, 222], [223, 224], [224, 228], [228, 229], [229, 230]]}
{"doc_key": "ai-test-135", "ner": [[4, 8, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2004", "-", "The", "first", "Cobot", "KUKA", "LBR", "3", "is", "released", "."], "sentence-detokenized": "2004 - The first Cobot KUKA LBR 3 is released.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 16], [17, 22], [23, 27], [28, 31], [32, 33], [34, 36], [37, 45], [45, 46]]}
{"doc_key": "ai-test-136", "ner": [[10, 12, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Two", "superficial", "approaches", "used", "for", "training", "and", "subsequent", "recognition", "are", "naive", "Bayesian", "classifier", "and", "decision", "trees", "."], "sentence-detokenized": "Two superficial approaches used for training and subsequent recognition are naive Bayesian classifier and decision trees.", "token2charspan": [[0, 3], [4, 15], [16, 26], [27, 31], [32, 35], [36, 44], [45, 48], [49, 59], [60, 71], [72, 75], [76, 81], [82, 90], [91, 101], [102, 105], [106, 114], [115, 120], [120, 121]]}
{"doc_key": "ai-test-137", "ner": [[5, 5, "misc"], [12, 13, "person"], [15, 17, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 12, 13, "origin", "", false, false], [5, 5, 15, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "practical", "forms", "of", "photography", "were", "introduced", "in", "January", "1839", "by", "Louis", "Daguerre", "and", "Henry", "Fox", "Talbot", "."], "sentence-detokenized": "The first practical forms of photography were introduced in January 1839 by Louis Daguerre and Henry Fox Talbot.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 25], [26, 28], [29, 40], [41, 45], [46, 56], [57, 59], [60, 67], [68, 72], [73, 75], [76, 81], [82, 90], [91, 94], [95, 100], [101, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-test-138", "ner": [[3, 4, "task"], [7, 8, "task"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 17, 18, "part-of", "task_part_of_field", false, false], [7, 8, 17, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "example", ",", "speech", "synthesis", "combined", "with", "speech", "recognition", "allows", "you", "to", "interact", "with", "mobile", "devices", "through", "speech", "processing", "interfaces", "."], "sentence-detokenized": "For example, speech synthesis combined with speech recognition allows you to interact with mobile devices through speech processing interfaces.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 19], [20, 29], [30, 38], [39, 43], [44, 50], [51, 62], [63, 69], [70, 73], [74, 76], [77, 85], [86, 90], [91, 97], [98, 105], [106, 113], [114, 120], [121, 131], [132, 142], [142, 143]]}
{"doc_key": "ai-test-139", "ner": [[0, 0, "product"], [15, 15, "programlang"], [17, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 15, 15, "general-affiliation", "", false, false], [0, 0, 17, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Fidgets", "can", "be", "programmed", "using", "a", "variety", "of", "software", "and", "programming", "languages", ",", "ranging", "from", "Java", "to", "Microsoft", "Excel", "."], "sentence-detokenized": "Fidgets can be programmed using a variety of software and programming languages, ranging from Java to Microsoft Excel.", "token2charspan": [[0, 7], [8, 11], [12, 14], [15, 25], [26, 31], [32, 33], [34, 41], [42, 44], [45, 53], [54, 57], [58, 69], [70, 79], [79, 80], [81, 88], [89, 93], [94, 98], [99, 101], [102, 111], [112, 117], [117, 118]]}
{"doc_key": "ai-test-140", "ner": [[3, 4, "field"], [10, 14, "researcher"], [15, 16, "misc"], [24, 25, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 10, 14, "origin", "", false, false], [10, 14, 24, 25, "general-affiliation", "topic_of_study", false, false], [10, 14, 27, 28, "general-affiliation", "topic_of_study", false, false], [15, 16, 10, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "term", "\"", "machine", "learning", "\"", "was", "coined", "in", "1959", "by", "Arthur", "Samuel", ",", "an", "American", "IBM", "employee", "and", "pioneer", "in", "the", "field", "of", "computer", "games", "and", "artificial", "intelligence", "."], "sentence-detokenized": "The term \"machine learning\" was coined in 1959 by Arthur Samuel, an American IBM employee and pioneer in the field of computer games and artificial intelligence.", "token2charspan": [[0, 3], [4, 8], [9, 10], [10, 17], [18, 26], [26, 27], [28, 31], [32, 38], [39, 41], [42, 46], [47, 49], [50, 56], [57, 63], [63, 64], [65, 67], [68, 76], [77, 80], [81, 89], [90, 93], [94, 101], [102, 104], [105, 108], [109, 114], [115, 117], [118, 126], [127, 132], [133, 136], [137, 147], [148, 160], [160, 161]]}
{"doc_key": "ai-test-141", "ner": [[0, 1, "misc"], [2, 3, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Israeli", "poet", "David", "Avidan", ",", "who", "was", "fascinated", "by", "future", "technologies", "and", "their", "connection", "with", "art", ",", "wanted", "to", "explore", "the", "use", "of", "computers", "for", "writing", "literary", "works", "."], "sentence-detokenized": "Israeli poet David Avidan, who was fascinated by future technologies and their connection with art, wanted to explore the use of computers for writing literary works.", "token2charspan": [[0, 7], [8, 12], [13, 18], [19, 25], [25, 26], [27, 30], [31, 34], [35, 45], [46, 48], [49, 55], [56, 68], [69, 72], [73, 78], [79, 89], [90, 94], [95, 98], [98, 99], [100, 106], [107, 109], [110, 117], [118, 121], [122, 125], [126, 128], [129, 138], [139, 142], [143, 150], [151, 159], [160, 165], [165, 166]]}
{"doc_key": "ai-test-142", "ner": [[4, 5, "misc"], [7, 7, "organisation"], [13, 14, "location"], [28, 29, "location"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[7, 7, 4, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "part", "of", "the", "GATEway", "project", ",", "Oxbotica", "tested", "seven", "autonomous", "buses", "in", "Greenwich", "in", "2017", ",", "driving", "along", "a", "two", "-", "mile", "riverside", "path", "near", "London", "'s", "O2", "arena", "on", "a", "route", "also", "used", "by", "pedestrians", "and", "cyclists", "."], "sentence-detokenized": "As part of the GATEway project, Oxbotica tested seven autonomous buses in Greenwich in 2017, driving along a two-mile riverside path near London's O2 arena on a route also used by pedestrians and cyclists.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 22], [23, 30], [30, 31], [32, 40], [41, 47], [48, 53], [54, 64], [65, 70], [71, 73], [74, 83], [84, 86], [87, 91], [91, 92], [93, 100], [101, 106], [107, 108], [109, 112], [112, 113], [113, 117], [118, 127], [128, 132], [133, 137], [138, 144], [144, 146], [147, 149], [150, 155], [156, 158], [159, 160], [161, 166], [167, 171], [172, 176], [177, 179], [180, 191], [192, 195], [196, 204], [204, 205]]}
{"doc_key": "ai-test-143", "ner": [[12, 14, "metrics"], [23, 24, "misc"], [26, 26, "metrics"], [28, 28, "metrics"], [31, 31, "metrics"], [33, 33, "metrics"], [35, 37, "metrics"], [40, 40, "metrics"], [42, 42, "metrics"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[12, 14, 23, 24, "related-to", "is_a", false, false], [12, 14, 26, 26, "usage", "", false, false], [12, 14, 28, 28, "usage", "", false, false], [26, 26, 31, 31, "named", "same", false, false], [28, 28, 42, 42, "named", "same", false, false], [31, 31, 40, 40, "opposite", "", false, false], [31, 31, 42, 42, "opposite", "", false, false], [33, 33, 31, 31, "named", "", false, false], [35, 37, 31, 31, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["An", "unrelated", "but", "frequently", "used", "combination", "of", "basic", "retrieval", "statistics", "is", "the", "F", "-", "score", ",", "which", "is", "a", "(", "possibly", "weighted", ")", "harmonic", "mean", "of", "recall", "and", "precision", ",", "where", "recall", "=", "sensitivity", "=", "true", "positive", "frequency", ",", "but", "specificity", "and", "precision", "are", "completely", "different", "measures", "."], "sentence-detokenized": "An unrelated but frequently used combination of basic retrieval statistics is the F-score, which is a (possibly weighted) harmonic mean of recall and precision, where recall = sensitivity = true positive frequency, but specificity and precision are completely different measures.", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 27], [28, 32], [33, 44], [45, 47], [48, 53], [54, 63], [64, 74], [75, 77], [78, 81], [82, 83], [83, 84], [84, 89], [89, 90], [91, 96], [97, 99], [100, 101], [102, 103], [103, 111], [112, 120], [120, 121], [122, 130], [131, 135], [136, 138], [139, 145], [146, 149], [150, 159], [159, 160], [161, 166], [167, 173], [174, 175], [176, 187], [188, 189], [190, 194], [195, 203], [204, 213], [213, 214], [215, 218], [219, 230], [231, 234], [235, 244], [245, 248], [249, 259], [260, 269], [270, 278], [278, 279]]}
{"doc_key": "ai-test-144", "ner": [[0, 3, "field"], [10, 10, "field"], [12, 12, "field"], [14, 14, "field"], [16, 17, "field"], [20, 21, "field"], [30, 31, "product"], [33, 36, "product"], [38, 39, "product"], [42, 43, "product"], [57, 59, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 3, 10, 10, "origin", "takes_inspiration_from", false, false], [0, 3, 12, 12, "origin", "takes_inspiration_from", false, false], [0, 3, 14, 14, "origin", "takes_inspiration_from", false, false], [0, 3, 16, 17, "origin", "takes_inspiration_from", false, false], [0, 3, 20, 21, "origin", "takes_inspiration_from", false, false], [30, 31, 0, 3, "origin", "", false, false], [33, 36, 0, 3, "origin", "", false, false], [38, 39, 0, 3, "origin", "", false, false], [42, 43, 0, 3, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Neuromorphic", "engineering", "is", "an", "interdisciplinary", "subject", "that", "draws", "inspiration", "from", "biology", ",", "physics", ",", "mathematics", ",", "computer", "science", ",", "and", "electronic", "engineering", "to", "develop", "artificial", "neural", "systems", ",", "such", "as", "vision", "systems", ",", "head", "-", "eye", "systems", ",", "auditory", "processors", ",", "and", "autonomous", "robots", ",", "whose", "physical", "architecture", "and", "design", "principles", "are", "based", "on", "those", "of", "the", "biological", "nervous", "system", "."], "sentence-detokenized": "Neuromorphic engineering is an interdisciplinary subject that draws inspiration from biology, physics, mathematics, computer science, and electronic engineering to develop artificial neural systems, such as vision systems, head-eye systems, auditory processors, and autonomous robots, whose physical architecture and design principles are based on those of the biological nervous system.", "token2charspan": [[0, 12], [13, 24], [25, 27], [28, 30], [31, 48], [49, 56], [57, 61], [62, 67], [68, 79], [80, 84], [85, 92], [92, 93], [94, 101], [101, 102], [103, 114], [114, 115], [116, 124], [125, 132], [132, 133], [134, 137], [138, 148], [149, 160], [161, 163], [164, 171], [172, 182], [183, 189], [190, 197], [197, 198], [199, 203], [204, 206], [207, 213], [214, 221], [221, 222], [223, 227], [227, 228], [228, 231], [232, 239], [239, 240], [241, 249], [250, 260], [260, 261], [262, 265], [266, 276], [277, 283], [283, 284], [285, 290], [291, 299], [300, 312], [313, 316], [317, 323], [324, 334], [335, 338], [339, 344], [345, 347], [348, 353], [354, 356], [357, 360], [361, 371], [372, 379], [380, 386], [386, 387]]}
{"doc_key": "ai-test-145", "ner": [[0, 7, "metrics"], [11, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 13, 0, 7, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["To", "be", "precise", ",", "the", "BIBO", "stability", "criterion", "requires", "that", "the", "ROC", "of", "the", "system", "includes", "a", "unit", "circle", "."], "sentence-detokenized": "To be precise, the BIBO stability criterion requires that the ROC of the system includes a unit circle.", "token2charspan": [[0, 2], [3, 5], [6, 13], [13, 14], [15, 18], [19, 23], [24, 33], [34, 43], [44, 52], [53, 57], [58, 61], [62, 65], [66, 68], [69, 72], [73, 79], [80, 88], [89, 90], [91, 95], [96, 102], [102, 103]]}
{"doc_key": "ai-test-146", "ner": [[7, 7, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2", "The", "program", "has", "been", "rewritten", "in", "Java", "since", "1998", "."], "sentence-detokenized": "2 The program has been rewritten in Java since 1998.", "token2charspan": [[0, 1], [2, 5], [6, 13], [14, 17], [18, 22], [23, 32], [33, 35], [36, 40], [41, 46], [47, 51], [51, 52]]}
{"doc_key": "ai-test-147", "ner": [[0, 0, "metrics"], [7, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 7, 8, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MCC", "can", "be", "calculated", "directly", "from", "the", "confusion", "matrix", "using", "the", "formula", ":"], "sentence-detokenized": "MCC can be calculated directly from the confusion matrix using the formula:", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 21], [22, 30], [31, 35], [36, 39], [40, 49], [50, 56], [57, 62], [63, 66], [67, 74], [74, 75]]}
{"doc_key": "ai-test-148", "ner": [[7, 12, "organisation"], [18, 23, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 12, 18, 23, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "developed", "by", "the", "team", "of", "MIT", "-", "IBM", "Watson", "AI", "Lab", "and", "first", "presented", "at", "the", "International", "Conference", "on", "Learning", "Representations", "2018", "."], "sentence-detokenized": "It was developed by the team of MIT-IBM Watson AI Lab and first presented at the International Conference on Learning Representations 2018.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 23], [24, 28], [29, 31], [32, 35], [35, 36], [36, 39], [40, 46], [47, 49], [50, 53], [54, 57], [58, 63], [64, 73], [74, 76], [77, 80], [81, 94], [95, 105], [106, 108], [109, 117], [118, 133], [134, 138], [138, 139]]}
{"doc_key": "ai-test-149", "ner": [[3, 3, "metrics"], [15, 17, "metrics"], [19, 21, "metrics"], [48, 48, "metrics"], [50, 50, "metrics"], [57, 59, "metrics"], [62, 62, "metrics"], [65, 65, "metrics"], [67, 68, "metrics"], [74, 74, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[15, 17, 48, 48, "type-of", "", false, false], [15, 17, 57, 59, "related-to", "collapses_to_identity", false, false], [19, 21, 50, 50, "type-of", "", false, false], [19, 21, 57, 59, "related-to", "collapses_to_identity", false, false], [19, 21, 67, 68, "named", "same", false, false], [62, 62, 74, 74, "related-to", "collapses_to_identity", false, false], [65, 65, 74, 74, "related-to", "collapses_to_identity", false, false], [67, 68, 74, 74, "related-to", "collapses_to_identity", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["When", "the", "TRUE", "prevalences", "for", "the", "two", "positive", "variables", "are", "equal", ",", "as", "assumed", "in", "Fleiss", "'", "kappa", "and", "F", "-", "test", ",", "i.e.", "the", "number", "of", "positive", "predictions", "corresponds", "to", "the", "number", "of", "positive", "classes", "in", "the", "dichotomous", "(", "two", "-", "class", ")", "case", ",", "the", "different", "kappas", "and", "correlation", "measures", "reduce", "to", "the", "identity", "with", "Juden", "'s", "J", ",", "and", "recall", "that", "the", "precision", "and", "F-", "test", "are", "similarly", "identical", "to", "the", "accuracy", "."], "sentence-detokenized": "When the TRUE prevalences for the two positive variables are equal, as assumed in Fleiss' kappa and F-test, i.e. the number of positive predictions corresponds to the number of positive classes in the dichotomous (two-class) case, the different kappas and correlation measures reduce to the identity with Juden's J, and recall that the precision and F-test are similarly identical to the accuracy.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 25], [26, 29], [30, 33], [34, 37], [38, 46], [47, 56], [57, 60], [61, 66], [66, 67], [68, 70], [71, 78], [79, 81], [82, 88], [88, 89], [90, 95], [96, 99], [100, 101], [101, 102], [102, 106], [106, 107], [108, 112], [113, 116], [117, 123], [124, 126], [127, 135], [136, 147], [148, 159], [160, 162], [163, 166], [167, 173], [174, 176], [177, 185], [186, 193], [194, 196], [197, 200], [201, 212], [213, 214], [214, 217], [217, 218], [218, 223], [223, 224], [225, 229], [229, 230], [231, 234], [235, 244], [245, 251], [252, 255], [256, 267], [268, 276], [277, 283], [284, 286], [287, 290], [291, 299], [300, 304], [305, 310], [310, 312], [313, 314], [314, 315], [316, 319], [320, 326], [327, 331], [332, 335], [336, 345], [346, 349], [350, 352], [352, 356], [357, 360], [361, 370], [371, 380], [381, 383], [384, 387], [388, 396], [396, 397]]}
{"doc_key": "ai-test-150", "ner": [[10, 15, "misc"], [13, 13, "misc"], [17, 17, "conference"], [2, 4, "task"], [20, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 15, 17, 17, "part-of", "", false, false], [10, 15, 17, 17, "physical", "", false, false], [10, 15, 17, 17, "temporal", "", false, false], [13, 13, 10, 15, "named", "", false, false], [2, 4, 10, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "first", "NLI", "collaborative", "challenge", "was", "held", "at", "the", "Building", "Educational", "Applications", "(", "BEA", ")", "workshop", "at", "NAACL", "2013", ".", "Tetreault", "et", "al", ",", "2013", ".", "29", "submissions", "were", "received", "from", "teams", "around", "the", "world", ",", "24", "of", "which", "also", "published", "papers", "describing", "their", "systems", "and", "approaches", "."], "sentence-detokenized": "The first NLI collaborative challenge was held at the Building Educational Applications (BEA) workshop at NAACL 2013. Tetreault et al, 2013. 29 submissions were received from teams around the world, 24 of which also published papers describing their systems and approaches.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 27], [28, 37], [38, 41], [42, 46], [47, 49], [50, 53], [54, 62], [63, 74], [75, 87], [88, 89], [89, 92], [92, 93], [94, 102], [103, 105], [106, 111], [112, 116], [116, 117], [118, 127], [128, 130], [131, 133], [133, 134], [135, 139], [139, 140], [141, 143], [144, 155], [156, 160], [161, 169], [170, 174], [175, 180], [181, 187], [188, 191], [192, 197], [197, 198], [199, 201], [202, 204], [205, 210], [211, 215], [216, 225], [226, 232], [233, 243], [244, 249], [250, 257], [258, 261], [262, 272], [272, 273]]}
{"doc_key": "ai-test-151", "ner": [[0, 2, "algorithm"], [5, 7, "algorithm"], [15, 16, "misc"], [20, 21, "misc"], [37, 38, "misc"], [41, 42, "algorithm"], [45, 45, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 5, 7, "type-of", "", false, false], [0, 2, 15, 16, "related-to", "finds", false, false], [20, 21, 15, 16, "type-of", "", false, false], [45, 45, 41, 42, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Viterbi", "algorithm", "is", "a", "dynamic", "programming", "algorithm", "for", "finding", "the", "most", "probable", "sequence", "of", "hidden", "states", ",", "called", "the", "Viterbi", "path", ",", "that", "leads", "to", "a", "sequence", "of", "observable", "events", ",", "especially", "in", "the", "context", "of", "Markov", "information", "sources", "and", "Hidden", "Markov", "Models", "(", "HMMs", ")", "."], "sentence-detokenized": "The Viterbi algorithm is a dynamic programming algorithm for finding the most probable sequence of hidden states, called the Viterbi path, that leads to a sequence of observable events, especially in the context of Markov information sources and Hidden Markov Models (HMMs).", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 24], [25, 26], [27, 34], [35, 46], [47, 56], [57, 60], [61, 68], [69, 72], [73, 77], [78, 86], [87, 95], [96, 98], [99, 105], [106, 112], [112, 113], [114, 120], [121, 124], [125, 132], [133, 137], [137, 138], [139, 143], [144, 149], [150, 152], [153, 154], [155, 163], [164, 166], [167, 177], [178, 184], [184, 185], [186, 196], [197, 199], [200, 203], [204, 211], [212, 214], [215, 221], [222, 233], [234, 241], [242, 245], [246, 252], [253, 259], [260, 266], [267, 268], [268, 272], [272, 273], [273, 274]]}
{"doc_key": "ai-test-152", "ner": [[1, 1, "field"], [2, 5, "algorithm"], [8, 9, "misc"], [12, 13, "algorithm"], [15, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 5, 1, 1, "part-of", "", false, false], [2, 5, 8, 9, "general-affiliation", "", false, false], [2, 5, 12, 13, "related-to", "generalizes_from", false, false], [2, 5, 15, 18, "related-to", "generalizes_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "statistics", ",", "multivariate", "logistic", "regression", "is", "a", "classification", "method", "that", "generalizes", "logistic", "regression", "to", "multiclass", "classification", ",", "i.e.", "with", "more", "than", "two", "possible", "discrete", "outcomes", "."], "sentence-detokenized": "In statistics, multivariate logistic regression is a classification method that generalizes logistic regression to multiclass classification, i.e. with more than two possible discrete outcomes.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 27], [28, 36], [37, 47], [48, 50], [51, 52], [53, 67], [68, 74], [75, 79], [80, 91], [92, 100], [101, 111], [112, 114], [115, 125], [126, 140], [140, 141], [142, 146], [147, 151], [152, 156], [157, 161], [162, 165], [166, 174], [175, 183], [184, 192], [192, 193]]}
{"doc_key": "ai-test-153", "ner": [[0, 2, "algorithm"], [9, 10, "field"], [12, 14, "field"], [18, 18, "task"], [21, 22, "task"], [24, 25, "task"], [27, 28, "researcher"], [30, 31, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 9, 10, "part-of", "", false, false], [0, 2, 12, 14, "part-of", "", false, false], [18, 18, 0, 2, "usage", "", true, false], [21, 22, 0, 2, "usage", "", true, false], [24, 25, 0, 2, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hidden", "Markov", "models", "are", "known", "for", "their", "applications", "in", "reinforcement", "learning", "and", "temporal", "pattern", "recognition", ",", "such", "as", "speech", "recognition", ",", "handwriting", "recognition", ",", "gesture", "recognition", ",", "Thad", "Starner", ",", "Alex", "Pentland", "."], "sentence-detokenized": "Hidden Markov models are known for their applications in reinforcement learning and temporal pattern recognition, such as speech recognition, handwriting recognition, gesture recognition, Thad Starner, Alex Pentland.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 30], [31, 34], [35, 40], [41, 53], [54, 56], [57, 70], [71, 79], [80, 83], [84, 92], [93, 100], [101, 112], [112, 113], [114, 118], [119, 121], [122, 128], [129, 140], [140, 141], [142, 153], [154, 165], [165, 166], [167, 174], [175, 186], [186, 187], [188, 192], [193, 200], [200, 201], [202, 206], [207, 215], [215, 216]]}
{"doc_key": "ai-test-154", "ner": [[8, 11, "misc"], [38, 44, "metrics"], [45, 48, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 11, 45, 48, "named", "", false, false], [38, 44, 45, 48, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "essence", ",", "this", "means", "that", "if", "a", "then", "-", "gram", "has", "been", "shown", "more", "than", "k", "times", "during", "training", ",", "then", "the", "conditional", "probability", "of", "the", "word", ",", "taking", "into", "account", "its", "history", ",", "is", "proportional", "to", "the", "estimate", "of", "the", "maximum", "probability", "of", "this", "n", "-", "gram", "."], "sentence-detokenized": "In essence, this means that if a then-gram has been shown more than k times during training, then the conditional probability of the word, taking into account its history, is proportional to the estimate of the maximum probability of this n-gram.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 16], [17, 22], [23, 27], [28, 30], [31, 32], [33, 37], [37, 38], [38, 42], [43, 46], [47, 51], [52, 57], [58, 62], [63, 67], [68, 69], [70, 75], [76, 82], [83, 91], [91, 92], [93, 97], [98, 101], [102, 113], [114, 125], [126, 128], [129, 132], [133, 137], [137, 138], [139, 145], [146, 150], [151, 158], [159, 162], [163, 170], [170, 171], [172, 174], [175, 187], [188, 190], [191, 194], [195, 203], [204, 206], [207, 210], [211, 218], [219, 230], [231, 233], [234, 238], [239, 240], [240, 241], [241, 245], [245, 246]]}
{"doc_key": "ai-test-155", "ner": [[4, 5, "task"], [7, 8, "task"], [11, 13, "task"], [17, 20, "task"], [28, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[28, 30, 17, 20, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "interested", "in", "knowledge", "representation", ",", "common", "sense", ",", "and", "natural", "language", "understanding", ",", "believing", "that", "deep", "understanding", "of", "language", "can", "currently", "only", "be", "achieved", "through", "significant", "manual", "engineering", "of", "semantically", "rich", "formalisms", "combined", "with", "statistical", "inference", "."], "sentence-detokenized": "He is interested in knowledge representation, common sense, and natural language understanding, believing that deep understanding of language can currently only be achieved through significant manual engineering of semantically rich formalisms combined with statistical inference.", "token2charspan": [[0, 2], [3, 5], [6, 16], [17, 19], [20, 29], [30, 44], [44, 45], [46, 52], [53, 58], [58, 59], [60, 63], [64, 71], [72, 80], [81, 94], [94, 95], [96, 105], [106, 110], [111, 115], [116, 129], [130, 132], [133, 141], [142, 145], [146, 155], [156, 160], [161, 163], [164, 172], [173, 180], [181, 192], [193, 199], [200, 211], [212, 214], [215, 227], [228, 232], [233, 243], [244, 252], [253, 257], [258, 269], [270, 279], [279, 280]]}
{"doc_key": "ai-test-156", "ner": [[1, 1, "programlang"], [3, 3, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "JavaScript", ",", "Python", "or"], "sentence-detokenized": "In JavaScript, Python or", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 21], [22, 24]]}
{"doc_key": "ai-test-157", "ner": [[1, 2, "misc"], [6, 7, "misc"], [11, 11, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 6, 7, "part-of", "", false, false], [6, 7, 11, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Newcomb", "Awards", "are", "announced", "in", "AI", "Magazine", ",", "published", "by", "AAAI", "."], "sentence-detokenized": "The Newcomb Awards are announced in AI Magazine, published by AAAI.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 22], [23, 32], [33, 35], [36, 38], [39, 47], [47, 48], [49, 58], [59, 61], [62, 66], [66, 67]]}
{"doc_key": "ai-test-158", "ner": [[0, 2, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "standard", "error", "on", "the", "test", "sample", "of", "100", "samples", "is", "0.084", ",", "which", "is", "less", "than", "the", "non-normalized", "error", "."], "sentence-detokenized": "The standard error on the test sample of 100 samples is 0.084, which is less than the non-normalized error.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 21], [22, 25], [26, 30], [31, 37], [38, 40], [41, 44], [45, 52], [53, 55], [56, 61], [61, 62], [63, 68], [69, 71], [72, 76], [77, 81], [82, 85], [86, 100], [101, 106], [106, 107]]}
{"doc_key": "ai-test-159", "ner": [[0, 3, "metrics"], [8, 10, "field"], [18, 20, "task"], [22, 22, "task"], [25, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 10, 0, 3, "usage", "", false, false], [18, 20, 8, 10, "part-of", "task_part_of_field", false, false], [22, 22, 18, 20, "named", "", false, false], [25, 26, 8, 10, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["F", "-", "score", "is", "widely", "used", "in", "the", "natural", "language", "processing", "literature", ",", "for", "example", ",", "to", "evaluate", "Named", "Entity", "Recognition", "(", "NER", ")", "and", "word", "segmentation", "."], "sentence-detokenized": "F-score is widely used in the natural language processing literature, for example, to evaluate Named Entity Recognition (NER) and word segmentation.", "token2charspan": [[0, 1], [1, 2], [2, 7], [8, 10], [11, 17], [18, 22], [23, 25], [26, 29], [30, 37], [38, 46], [47, 57], [58, 68], [68, 69], [70, 73], [74, 81], [81, 82], [83, 85], [86, 94], [95, 100], [101, 107], [108, 119], [120, 121], [121, 124], [124, 125], [126, 129], [130, 134], [135, 147], [147, 148]]}
{"doc_key": "ai-test-160", "ner": [[0, 1, "product"], [5, 6, "product"], [17, 18, "misc"], [21, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 17, 18, "related-to", "performs_task", false, false], [0, 1, 21, 22, "related-to", "performs_task", false, false], [5, 6, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Chatbots", "are", "commonly", "used", "in", "dialogue", "systems", "for", "a", "variety", "of", "purposes", ",", "including", "customer", "service", ",", "query", "routing", ",", "or", "information", "gathering", "."], "sentence-detokenized": "Chatbots are commonly used in dialogue systems for a variety of purposes, including customer service, query routing, or information gathering.", "token2charspan": [[0, 8], [9, 12], [13, 21], [22, 26], [27, 29], [30, 38], [39, 46], [47, 50], [51, 52], [53, 60], [61, 63], [64, 72], [72, 73], [74, 83], [84, 92], [93, 100], [100, 101], [102, 107], [108, 115], [115, 116], [117, 119], [120, 131], [132, 141], [141, 142]]}
{"doc_key": "ai-test-161", "ner": [[3, 9, "conference"], [14, 22, "conference"], [30, 40, "conference"], [46, 46, "conference"], [49, 52, "conference"], [54, 55, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 22, 3, 9, "named", "", false, false], [30, 40, 3, 9, "named", "", false, false], [46, 46, 30, 40, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Important", "journals", "are", "IEEE", "Transactions", "on", "Speech", "and", "Audio", "Processing", "(", "later", "renamed", "to", "IEEE", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", ",", "and", "since", "September", "2014", "renamed", "to", "IEEE", "/", "ACM", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "-", "after", "the", "merger", "with", "ACM", ")", ",", "Computer", "Speech", "and", "Language", "and", "Speech", "Communication", "."], "sentence-detokenized": "Important journals are IEEE Transactions on Speech and Audio Processing (later renamed to IEEE Transactions on Audio, Speech and Language Processing, and since September 2014 renamed to IEEE/ACM Transactions on Audio, Speech and Language Processing - after the merger with ACM), Computer Speech and Language and Speech Communication.", "token2charspan": [[0, 9], [10, 18], [19, 22], [23, 27], [28, 40], [41, 43], [44, 50], [51, 54], [55, 60], [61, 71], [72, 73], [73, 78], [79, 86], [87, 89], [90, 94], [95, 107], [108, 110], [111, 116], [116, 117], [118, 124], [125, 128], [129, 137], [138, 148], [148, 149], [150, 153], [154, 159], [160, 169], [170, 174], [175, 182], [183, 185], [186, 190], [190, 191], [191, 194], [195, 207], [208, 210], [211, 216], [216, 217], [218, 224], [225, 228], [229, 237], [238, 248], [249, 250], [251, 256], [257, 260], [261, 267], [268, 272], [273, 276], [276, 277], [277, 278], [279, 287], [288, 294], [295, 298], [299, 307], [308, 311], [312, 318], [319, 332], [332, 333]]}
{"doc_key": "ai-test-162", "ner": [[0, 1, "algorithm"], [5, 6, "task"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 0, 1, "usage", "", false, false], [5, 6, 8, 9, "part-of", "task_part_of_field", false, false], [5, 6, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["EM", "is", "often", "used", "for", "data", "clustering", "in", "machine", "learning", "and", "computer", "vision", "."], "sentence-detokenized": "EM is often used for data clustering in machine learning and computer vision.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 16], [17, 20], [21, 25], [26, 36], [37, 39], [40, 47], [48, 56], [57, 60], [61, 69], [70, 76], [76, 77]]}
{"doc_key": "ai-test-163", "ner": [[9, 11, "metrics"], [29, 32, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 29, 32, "related-to", "described_by", false, false]], "relations_mapping_to_source": [0], "sentence": ["While", "there", "is", "no", "perfect", "way", "to", "describe", "the", "confusion", "matrix", "of", "positive", "and", "negative", "\"", "TRUE", "\"", "and", "\"", "FALSE", "\"", "statements", "with", "a", "single", "number", ",", "the", "Matthews", "correlation", "coefficient", "is", "generally", "considered", "to", "be", "one", "of", "the", "best", "such", "measures", "."], "sentence-detokenized": "While there is no perfect way to describe the confusion matrix of positive and negative \"TRUE\" and \"FALSE\" statements with a single number, the Matthews correlation coefficient is generally considered to be one of the best such measures.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 17], [18, 25], [26, 29], [30, 32], [33, 41], [42, 45], [46, 55], [56, 62], [63, 65], [66, 74], [75, 78], [79, 87], [88, 89], [89, 93], [93, 94], [95, 98], [99, 100], [100, 105], [105, 106], [107, 117], [118, 122], [123, 124], [125, 131], [132, 138], [138, 139], [140, 143], [144, 152], [153, 164], [165, 176], [177, 179], [180, 189], [190, 200], [201, 203], [204, 206], [207, 210], [211, 213], [214, 217], [218, 222], [223, 227], [228, 236], [236, 237]]}
{"doc_key": "ai-test-164", "ner": [[11, 12, "field"], [26, 27, "field"], [34, 35, "field"], [39, 40, "algorithm"], [42, 43, "task"], [45, 46, "algorithm"], [51, 56, "algorithm"], [54, 55, "algorithm"], [62, 64, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[34, 35, 26, 27, "part-of", "subfield", false, false], [39, 40, 34, 35, "part-of", "", false, true], [42, 43, 34, 35, "part-of", "", false, true], [45, 46, 34, 35, "part-of", "", false, true], [51, 56, 34, 35, "part-of", "", false, true], [54, 55, 34, 35, "part-of", "", false, true], [62, 64, 34, 35, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["As", "the", "size", "and", "complexity", "of", "datasets", "increased", ",", "direct", "practical", "data", "analysis", "was", "complemented", "by", "indirect", "automated", "data", "processing", ",", "facilitated", "by", "other", "discoveries", "in", "computer", "science", ",", "especially", "in", "the", "field", "of", "machine", "learning", ",", "such", "as", "neural", "networks", ",", "cluster", "analysis", ",", "genetic", "algorithms", "(", "1950s", ")", ",", "decision", "tree", "and", "decision", "rule", "learning", "(", "1960s", ")", ",", "and", "support", "vector", "machines", "(", "1990", "s", ")", "."], "sentence-detokenized": "As the size and complexity of datasets increased, direct practical data analysis was complemented by indirect automated data processing, facilitated by other discoveries in computer science, especially in the field of machine learning, such as neural networks, cluster analysis, genetic algorithms (1950s), decision tree and decision rule learning (1960s), and support vector machines (1990s).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 15], [16, 26], [27, 29], [30, 38], [39, 48], [48, 49], [50, 56], [57, 66], [67, 71], [72, 80], [81, 84], [85, 97], [98, 100], [101, 109], [110, 119], [120, 124], [125, 135], [135, 136], [137, 148], [149, 151], [152, 157], [158, 169], [170, 172], [173, 181], [182, 189], [189, 190], [191, 201], [202, 204], [205, 208], [209, 214], [215, 217], [218, 225], [226, 234], [234, 235], [236, 240], [241, 243], [244, 250], [251, 259], [259, 260], [261, 268], [269, 277], [277, 278], [279, 286], [287, 297], [298, 299], [299, 304], [304, 305], [305, 306], [307, 315], [316, 320], [321, 324], [325, 333], [334, 338], [339, 347], [348, 349], [349, 354], [354, 355], [355, 356], [357, 360], [361, 368], [369, 375], [376, 384], [385, 386], [386, 390], [390, 391], [391, 392], [392, 393]]}
{"doc_key": "ai-test-165", "ner": [[4, 4, "researcher"], [9, 10, "misc"], [19, 20, "researcher"], [22, 23, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 4, 4, "artifact", "", false, false], [9, 10, 19, 20, "artifact", "", false, false], [9, 10, 22, 23, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "autumn", "2005", ",", "Trun", "published", "the", "textbook", "\"", "Probabilistic", "Robotics", "\"", "together", "with", "his", "long", "-", "term", "collaborators", "Dieter", "Fox", "and", "Wolfram", "Burgard", "."], "sentence-detokenized": "In autumn 2005, Trun published the textbook \"Probabilistic Robotics\" together with his long-term collaborators Dieter Fox and Wolfram Burgard.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 20], [21, 30], [31, 34], [35, 43], [44, 45], [45, 58], [59, 67], [67, 68], [69, 77], [78, 82], [83, 86], [87, 91], [91, 92], [92, 96], [97, 110], [111, 117], [118, 121], [122, 125], [126, 133], [134, 141], [141, 142]]}
{"doc_key": "ai-test-166", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 7, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["John", "D.", "Lafferty", ",", "Andrew", "McCallum", "and", "Pereyramat", ":"], "sentence-detokenized": "John D. Lafferty, Andrew McCallum and Pereyramat:", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 24], [25, 33], [34, 37], [38, 48], [48, 49]]}
{"doc_key": "ai-test-167", "ner": [[0, 1, "task"], [3, 3, "task"], [7, 7, "field"], [13, 14, "field"], [16, 18, "field"], [20, 20, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 13, 14, "part-of", "task_part_of_field", false, false], [0, 1, 16, 18, "part-of", "task_part_of_field", false, false], [3, 3, 0, 1, "named", "", false, false], [13, 14, 7, 7, "part-of", "subfield", false, false], [16, 18, 7, 7, "part-of", "subfield", false, false], [20, 20, 16, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Question", "answering", "(", "QA", ")", "is", "a", "computer", "discipline", "in", "the", "field", "of", "information", "retrieval", "and", "natural", "language", "processing", "(", "NLP", ")", ",", "which", "deals", "with", "the", "construction", "of", "systems", "that", "automatically", "answer", "questions", "posed", "by", "humans", "in", "natural", "language", "."], "sentence-detokenized": "Question answering (QA) is a computer discipline in the field of information retrieval and natural language processing (NLP), which deals with the construction of systems that automatically answer questions posed by humans in natural language.", "token2charspan": [[0, 8], [9, 18], [19, 20], [20, 22], [22, 23], [24, 26], [27, 28], [29, 37], [38, 48], [49, 51], [52, 55], [56, 61], [62, 64], [65, 76], [77, 86], [87, 90], [91, 98], [99, 107], [108, 118], [119, 120], [120, 123], [123, 124], [124, 125], [126, 131], [132, 137], [138, 142], [143, 146], [147, 159], [160, 162], [163, 170], [171, 175], [176, 189], [190, 196], [197, 206], [207, 212], [213, 215], [216, 222], [223, 225], [226, 233], [234, 242], [242, 243]]}
{"doc_key": "ai-test-168", "ner": [[9, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "the", "version", "of", "the", "metric", "used", "in", "NIST", "assessments", "prior", "to", "2009", "used", "the", "shortest", "sentence", "instead", "."], "sentence-detokenized": "However, the version of the metric used in NIST assessments prior to 2009 used the shortest sentence instead.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 20], [21, 23], [24, 27], [28, 34], [35, 39], [40, 42], [43, 47], [48, 59], [60, 65], [66, 68], [69, 73], [74, 78], [79, 82], [83, 91], [92, 100], [101, 108], [108, 109]]}
{"doc_key": "ai-test-169", "ner": [[6, 6, "person"], [15, 15, "organisation"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 16, 16, "related-to", "invests_in", false, false], [16, 16, 15, 15, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["On", "August", "27", ",", "2018", ",", "Toyota", "announced", "an", "investment", "of", "$", "500", "million", "in", "Uber", "autonomous", "cars", "."], "sentence-detokenized": "On August 27, 2018, Toyota announced an investment of $500 million in Uber autonomous cars.", "token2charspan": [[0, 2], [3, 9], [10, 12], [12, 13], [14, 18], [18, 19], [20, 26], [27, 36], [37, 39], [40, 50], [51, 53], [54, 55], [55, 58], [59, 66], [67, 69], [70, 74], [75, 85], [86, 90], [90, 91]]}
{"doc_key": "ai-test-170", "ner": [[5, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "sample", "maximum", "is", "an", "estimate", "of", "the", "maximum", "likelihood", "for", "the", "general", "maximum", ",", "but", "as", "noted", "above", ",", "it", "is", "biased", "."], "sentence-detokenized": "The sample maximum is an estimate of the maximum likelihood for the general maximum, but as noted above, it is biased.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 21], [22, 24], [25, 33], [34, 36], [37, 40], [41, 48], [49, 59], [60, 63], [64, 67], [68, 75], [76, 83], [83, 84], [85, 88], [89, 91], [92, 97], [98, 103], [103, 104], [105, 107], [108, 110], [111, 117], [117, 118]]}
{"doc_key": "ai-test-171", "ner": [[0, 0, "task"], [3, 4, "misc"], [6, 6, "metrics"], [15, 18, "algorithm"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 4, "related-to", "overcomes", false, false], [0, 0, 6, 6, "related-to", "increases", false, false], [3, 4, 15, 18, "opposite", "", false, false], [3, 4, 19, 21, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LSI", "helps", "overcome", "synonymy", "by", "increasing", "recall", ",", "one", "of", "the", "most", "problematic", "limitations", "of", "Boolean", "keyword", "queries", "and", "vector", "space", "models", "."], "sentence-detokenized": "LSI helps overcome synonymy by increasing recall, one of the most problematic limitations of Boolean keyword queries and vector space models.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 27], [28, 30], [31, 41], [42, 48], [48, 49], [50, 53], [54, 56], [57, 60], [61, 65], [66, 77], [78, 89], [90, 92], [93, 100], [101, 108], [109, 116], [117, 120], [121, 127], [128, 133], [134, 140], [140, 141]]}
{"doc_key": "ai-test-172", "ner": [[0, 3, "task"], [17, 17, "programlang"], [19, 19, "programlang"], [21, 21, "programlang"], [23, 24, "programlang"], [26, 26, "programlang"], [28, 28, "programlang"], [30, 30, "programlang"], [32, 32, "programlang"], [34, 34, "programlang"], [36, 36, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 3, 17, 17, "general-affiliation", "", false, false], [0, 3, 19, 19, "general-affiliation", "", false, false], [0, 3, 21, 21, "general-affiliation", "", false, false], [0, 3, 23, 24, "general-affiliation", "", false, false], [0, 3, 26, 26, "general-affiliation", "", false, false], [0, 3, 28, 28, "general-affiliation", "", false, false], [0, 3, 30, 30, "general-affiliation", "", false, false], [0, 3, 32, 32, "general-affiliation", "", false, false], [0, 3, 34, 34, "general-affiliation", "", false, false], [0, 3, 36, 36, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Data", "collection", "programs", "are", "usually", "driven", "by", "software", "developed", "using", "various", "general", "purpose", "programming", "languages", "such", "as", "Assembly", ",", "BASIC", ",", "C", ",", "C", "++", ",", "C#", ",", "Fortran", ",", "Java", ",", "LabVIEW", ",", "Lisp", ",", "Pascal", ",", "etc."], "sentence-detokenized": "Data collection programs are usually driven by software developed using various general purpose programming languages such as Assembly, BASIC, C, C++, C#, Fortran, Java, LabVIEW, Lisp, Pascal, etc.", "token2charspan": [[0, 4], [5, 15], [16, 24], [25, 28], [29, 36], [37, 43], [44, 46], [47, 55], [56, 65], [66, 71], [72, 79], [80, 87], [88, 95], [96, 107], [108, 117], [118, 122], [123, 125], [126, 134], [134, 135], [136, 141], [141, 142], [143, 144], [144, 145], [146, 147], [147, 149], [149, 150], [151, 153], [153, 154], [155, 162], [162, 163], [164, 168], [168, 169], [170, 177], [177, 178], [179, 183], [183, 184], [185, 191], [191, 192], [193, 197]]}
{"doc_key": "ai-test-173", "ner": [[3, 3, "organisation"], [5, 5, "product"], [9, 9, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 3, 3, "artifact", "", false, false], [5, 5, 9, 9, "physical", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2003", ",", "Honda", "released", "Cog", "ads", "in", "the", "UK", "and", "online", "."], "sentence-detokenized": "In 2003, Honda released Cog ads in the UK and online.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 27], [28, 31], [32, 34], [35, 38], [39, 41], [42, 45], [46, 52], [52, 53]]}
{"doc_key": "ai-test-174", "ner": [[0, 4, "conference"], [6, 7, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 4, 6, 7, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Association", "for", "Computational", "Linguistics", "defines", "computational", "linguistics", "as", ":"], "sentence-detokenized": "The Association for Computational Linguistics defines computational linguistics as:", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 33], [34, 45], [46, 53], [54, 67], [68, 79], [80, 82], [82, 83]]}
{"doc_key": "ai-test-175", "ner": [[23, 27, "algorithm"], [3, 8, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[23, 27, 3, 8, "related-to", "calculates", false, false]], "relations_mapping_to_source": [0], "sentence": ["To", "calculate", "approximate", "estimates", "of", "the", "maximum", "likelihood", "of", "unknown", "parameters", "of", "the", "state", "space", "in", "filters", "and", "smoothers", "with", "minimum", "variance", ",", "algorithms", "for", "maximizing", "mathematical", "expectation", "can", "be", "used", "."], "sentence-detokenized": "To calculate approximate estimates of the maximum likelihood of unknown parameters of the state space in filters and smoothers with minimum variance, algorithms for maximizing mathematical expectation can be used.", "token2charspan": [[0, 2], [3, 12], [13, 24], [25, 34], [35, 37], [38, 41], [42, 49], [50, 60], [61, 63], [64, 71], [72, 82], [83, 85], [86, 89], [90, 95], [96, 101], [102, 104], [105, 112], [113, 116], [117, 126], [127, 131], [132, 139], [140, 148], [148, 149], [150, 160], [161, 164], [165, 175], [176, 188], [189, 200], [201, 204], [205, 207], [208, 212], [212, 213]]}
{"doc_key": "ai-test-176", "ner": [[5, 5, "misc"], [7, 9, "person"], [11, 12, "person"], [14, 15, "person"], [18, 19, "misc"], [20, 21, "person"], [24, 25, "person"], [29, 29, "person"], [31, 32, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[7, 9, 5, 5, "role", "actor_in", false, false], [11, 12, 5, 5, "role", "actor_in", false, false], [14, 15, 5, 5, "role", "actor_in", false, false], [20, 21, 18, 19, "role", "model_for", false, false], [29, 29, 31, 32, "social", "family", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Among", "the", "correspondents", "were", "former", "Baywatch", "actresses", "Donna", "D'", "Errico", ",", "Carmen", "Electra", "and", "Tracy", "Bingham", ",", "former", "Playboy", "model", "Heidi", "Mark", ",", "comedian", "Arj", "Barker", "and", "identical", "twins", "Randy", "and", "Jason", "Sklar", "."], "sentence-detokenized": "Among the correspondents were former Baywatch actresses Donna D'Errico, Carmen Electra and Tracy Bingham, former Playboy model Heidi Mark, comedian Arj Barker and identical twins Randy and Jason Sklar.", "token2charspan": [[0, 5], [6, 9], [10, 24], [25, 29], [30, 36], [37, 45], [46, 55], [56, 61], [62, 64], [64, 70], [70, 71], [72, 78], [79, 86], [87, 90], [91, 96], [97, 104], [104, 105], [106, 112], [113, 120], [121, 126], [127, 132], [133, 137], [137, 138], [139, 147], [148, 151], [152, 158], [159, 162], [163, 172], [173, 178], [179, 184], [185, 188], [189, 194], [195, 200], [200, 201]]}
{"doc_key": "ai-test-177", "ner": [[8, 9, "task"], [11, 11, "task"], [18, 20, "product"], [23, 24, "task"], [26, 26, "task"], [33, 34, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 8, 9, "named", "", false, false], [18, 20, 8, 9, "general-affiliation", "", false, false], [26, 26, 23, 24, "named", "", false, false], [33, 34, 23, 24, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "is", "widely", "used", "to", "generate", "representations", "for", "speech", "recognition", "(", "ASR", ")", ",", "such", "as", "in", "the", "CMU", "Sphinx", "system", ",", "and", "speech", "synthesis", "(", "TTS", ")", ",", "such", "as", "in", "the", "Festival", "system", "."], "sentence-detokenized": "It is widely used to generate representations for speech recognition (ASR), such as in the CMU Sphinx system, and speech synthesis (TTS), such as in the Festival system.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 17], [18, 20], [21, 29], [30, 45], [46, 49], [50, 56], [57, 68], [69, 70], [70, 73], [73, 74], [74, 75], [76, 80], [81, 83], [84, 86], [87, 90], [91, 94], [95, 101], [102, 108], [108, 109], [110, 113], [114, 120], [121, 130], [131, 132], [132, 135], [135, 136], [136, 137], [138, 142], [143, 145], [146, 148], [149, 152], [153, 161], [162, 168], [168, 169]]}
{"doc_key": "ai-test-178", "ner": [[0, 1, "metrics"], [3, 4, "metrics"], [7, 7, "metrics"], [14, 17, "metrics"], [28, 30, "metrics"], [32, 32, "metrics"], [43, 45, "metrics"], [47, 51, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 8], "relations": [[3, 4, 0, 1, "named", "", false, false], [7, 7, 3, 4, "named", "", false, false], [14, 17, 0, 1, "named", "", false, false], [32, 32, 28, 30, "named", "", false, false], [47, 51, 43, 45, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5], "sentence": ["The", "sensitivity", "or", "true", "-positive", "rate", "(", "TPR", ")", ",", "also", "known", "as", "the", "recall", ",", "is", "the", "proportion", "of", "people", "who", "are", "tested", "and", "are", "positive", "(", "true", "-", "positive", ",", "TP", ")", "out", "of", "all", "people", "who", "are", "actually", "positive", "(", "false", "-", "positive", ",", "FP", "=", "TP", "+", "FP", ")", "."], "sentence-detokenized": "The sensitivity or true-positive rate (TPR), also known as the recall, is the proportion of people who are tested and are positive (true-positive, TP) out of all people who are actually positive (false-positive, FP = TP + FP).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 23], [23, 32], [33, 37], [38, 39], [39, 42], [42, 43], [43, 44], [45, 49], [50, 55], [56, 58], [59, 62], [63, 69], [69, 70], [71, 73], [74, 77], [78, 88], [89, 91], [92, 98], [99, 102], [103, 106], [107, 113], [114, 117], [118, 121], [122, 130], [131, 132], [132, 136], [136, 137], [137, 145], [145, 146], [147, 149], [149, 150], [151, 154], [155, 157], [158, 161], [162, 168], [169, 172], [173, 176], [177, 185], [186, 194], [195, 196], [196, 201], [201, 202], [202, 210], [210, 211], [212, 214], [215, 216], [217, 219], [220, 221], [222, 224], [224, 225], [225, 226]]}
{"doc_key": "ai-test-179", "ner": [[1, 2, "task"], [11, 11, "conference"], [13, 14, "conference"], [16, 16, "conference"], [18, 20, "conference"], [22, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6], "relations": [[11, 11, 1, 2, "topic", "", false, false], [13, 14, 1, 2, "topic", "", false, false], [16, 16, 1, 2, "topic", "", false, false], [18, 20, 1, 2, "topic", "", false, false], [22, 23, 1, 2, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 4, 5], "sentence": ["Popular", "speech", "recognition", "conferences", "held", "once", "every", "year", "or", "two", "include", "SpeechTEK", "and", "SpeechTEK", "Europe", ",", "ICASSP", ",", "Interspeech", "/", "Eurospeech", "and", "IEEE", "ASRU", "."], "sentence-detokenized": "Popular speech recognition conferences held once every year or two include SpeechTEK and SpeechTEK Europe, ICASSP, Interspeech/Eurospeech and IEEE ASRU.", "token2charspan": [[0, 7], [8, 14], [15, 26], [27, 38], [39, 43], [44, 48], [49, 54], [55, 59], [60, 62], [63, 66], [67, 74], [75, 84], [85, 88], [89, 98], [99, 105], [105, 106], [107, 113], [113, 114], [115, 126], [126, 127], [127, 137], [138, 141], [142, 146], [147, 151], [151, 152]]}
{"doc_key": "ai-test-180", "ner": [[0, 0, "researcher"], [3, 3, "researcher"], [17, 19, "product"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 22, 0, 0, "artifact", "", false, false], [22, 22, 3, 3, "artifact", "", false, false], [22, 22, 17, 19, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Devol", "worked", "with", "Engelberger", ",", "who", "served", "as", "president", "of", "the", "company", ",", "to", "develop", "and", "manufacture", "an", "industrial", "robot", "under", "the", "Unimate", "brand", "."], "sentence-detokenized": "Devol worked with Engelberger, who served as president of the company, to develop and manufacture an industrial robot under the Unimate brand.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 29], [29, 30], [31, 34], [35, 41], [42, 44], [45, 54], [55, 57], [58, 61], [62, 69], [69, 70], [71, 73], [74, 81], [82, 85], [86, 97], [98, 100], [101, 111], [112, 117], [118, 123], [124, 127], [128, 135], [136, 141], [141, 142]]}
{"doc_key": "ai-test-181", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [8, 10, "algorithm"], [23, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 8, 10, "general-affiliation", "", false, false], [4, 4, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hidden", "Markov", "Model", "(", "HMM", ")", "is", "a", "statistical", "Markov", "model", "in", "which", "it", "is", "assumed", "that", "the", "system", "being", "modeled", "is", "a", "Markov", "process", "with", "unobservable", "(", "hidden", ")", "states", "."], "sentence-detokenized": "Hidden Markov Model (HMM) is a statistical Markov model in which it is assumed that the system being modeled is a Markov process with unobservable (hidden) states.", "token2charspan": [[0, 6], [7, 13], [14, 19], [20, 21], [21, 24], [24, 25], [26, 28], [29, 30], [31, 42], [43, 49], [50, 55], [56, 58], [59, 64], [65, 67], [68, 70], [71, 78], [79, 83], [84, 87], [88, 94], [95, 100], [101, 108], [109, 111], [112, 113], [114, 120], [121, 128], [129, 133], [134, 146], [147, 148], [148, 154], [154, 155], [156, 162], [162, 163]]}
{"doc_key": "ai-test-182", "ner": [[16, 18, "metrics"], [25, 25, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "property", ",", "undesirable", "for", "many", "applications", ",", "has", "led", "researchers", "to", "use", "alternatives", "such", "as", "mean", "absolute", "error", ",", "or", "those", "based", "on", "the", "median", "."], "sentence-detokenized": "This property, undesirable for many applications, has led researchers to use alternatives such as mean absolute error, or those based on the median.", "token2charspan": [[0, 4], [5, 13], [13, 14], [15, 26], [27, 30], [31, 35], [36, 48], [48, 49], [50, 53], [54, 57], [58, 69], [70, 72], [73, 76], [77, 89], [90, 94], [95, 97], [98, 102], [103, 111], [112, 117], [117, 118], [119, 121], [122, 127], [128, 133], [134, 136], [137, 140], [141, 147], [147, 148]]}
{"doc_key": "ai-test-183", "ner": [[20, 21, "algorithm"], [29, 30, "field"], [33, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[20, 21, 29, 30, "part-of", "", false, false], [20, 21, 33, 35, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Such", "a", "sequence", "(", "which", "depends", "on", "the", "results", "of", "the", "previous", "attributes", "at", "each", "stage", ")", "is", "called", "a", "decision", "tree", "and", "is", "used", "in", "the", "field", "of", "machine", "learning", "known", "as", "decision", "tree", "learning", "."], "sentence-detokenized": "Such a sequence (which depends on the results of the previous attributes at each stage) is called a decision tree and is used in the field of machine learning known as decision tree learning.", "token2charspan": [[0, 4], [5, 6], [7, 15], [16, 17], [17, 22], [23, 30], [31, 33], [34, 37], [38, 45], [46, 48], [49, 52], [53, 61], [62, 72], [73, 75], [76, 80], [81, 86], [86, 87], [88, 90], [91, 97], [98, 99], [100, 108], [109, 113], [114, 117], [118, 120], [121, 125], [126, 128], [129, 132], [133, 138], [139, 141], [142, 149], [150, 158], [159, 164], [165, 167], [168, 176], [177, 181], [182, 190], [190, 191]]}
{"doc_key": "ai-test-184", "ner": [[2, 3, "task"], [5, 5, "algorithm"], [16, 18, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 3, 5, 5, "compare", "", false, false], [16, 18, 5, 5, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "in", "factor", "analysis", ",", "LCA", "can", "also", "be", "used", "to", "classify", "cases", "according", "to", "their", "maximum", "probability", "of", "belonging", "to", "a", "class", "."], "sentence-detokenized": "As in factor analysis, LCA can also be used to classify cases according to their maximum probability of belonging to a class.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 21], [21, 22], [23, 26], [27, 30], [31, 35], [36, 38], [39, 43], [44, 46], [47, 55], [56, 61], [62, 71], [72, 74], [75, 80], [81, 88], [89, 100], [101, 103], [104, 113], [114, 116], [117, 118], [119, 124], [124, 125]]}
{"doc_key": "ai-test-185", "ner": [[0, 2, "algorithm"], [8, 8, "metrics"], [10, 10, "metrics"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 8, 8, "usage", "", false, false], [8, 8, 12, 13, "related-to", "", false, false], [10, 10, 8, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Supervised", "neural", "networks", "that", "use", "the", "Mean", "Squared", "Error", "(", "MSE", ")", "cost", "function", "can", "use", "formal", "statistical", "methods", "to", "determine", "the", "validity", "of", "the", "trained", "model", "."], "sentence-detokenized": "Supervised neural networks that use the Mean Squared Error (MSE) cost function can use formal statistical methods to determine the validity of the trained model.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 31], [32, 35], [36, 39], [40, 44], [45, 52], [53, 58], [59, 60], [60, 63], [63, 64], [65, 69], [70, 78], [79, 82], [83, 86], [87, 93], [94, 105], [106, 113], [114, 116], [117, 126], [127, 130], [131, 139], [140, 142], [143, 146], [147, 154], [155, 160], [160, 161]]}
{"doc_key": "ai-test-186", "ner": [[17, 18, "algorithm"], [21, 23, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 18, 21, 23, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "can", "be", "directly", "expressed", "as", "a", "linear", "program", ",", "but", "it", "is", "also", "equivalent", "to", "a", "Tikhonov", "regularization", "with", "a", "loop", "loss", "function", ",", "mathV", "(", "f", "(", "x", ")", ",", "y", ")", "=\\", "max", "(", "0", ",", "1", "-", "yf", "(", "x", ")", ")", "/", "math", ":"], "sentence-detokenized": "This can be directly expressed as a linear program, but it is also equivalent to a Tikhonov regularization with a loop loss function, mathV (f (x), y) =\\ max (0, 1 - yf (x)) / math:", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 20], [21, 30], [31, 33], [34, 35], [36, 42], [43, 50], [50, 51], [52, 55], [56, 58], [59, 61], [62, 66], [67, 77], [78, 80], [81, 82], [83, 91], [92, 106], [107, 111], [112, 113], [114, 118], [119, 123], [124, 132], [132, 133], [134, 139], [140, 141], [141, 142], [143, 144], [144, 145], [145, 146], [146, 147], [148, 149], [149, 150], [151, 153], [154, 157], [158, 159], [159, 160], [160, 161], [162, 163], [164, 165], [166, 168], [169, 170], [170, 171], [171, 172], [172, 173], [174, 175], [176, 180], [180, 181]]}
{"doc_key": "ai-test-187", "ner": [[10, 10, "researcher"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "following", "method", "is", "described", "in", "the", "original", "paper", "by", "Breiman", "and", "implemented", "in", "the", "R", "package", "randomForest", "."], "sentence-detokenized": "The following method is described in the original paper by Breiman and implemented in the R package randomForest.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 23], [24, 33], [34, 36], [37, 40], [41, 49], [50, 55], [56, 58], [59, 66], [67, 70], [71, 82], [83, 85], [86, 89], [90, 91], [92, 99], [100, 112], [112, 113]]}
{"doc_key": "ai-test-188", "ner": [[7, 9, "metrics"], [38, 38, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "image", "quality", "measurements", ",", "such", "as", "PSNR", ",", "are", "usually", "performed", "on", "fixed", "resolution", "images", "and", "do", "not", "take", "into", "account", "some", "aspects", "of", "the", "human", "visual", "system", ",", "such", "as", "the", "changing", "spatial", "resolution", "on", "the", "retina", "."], "sentence-detokenized": "Traditional image quality measurements, such as PSNR, are usually performed on fixed resolution images and do not take into account some aspects of the human visual system, such as the changing spatial resolution on the retina.", "token2charspan": [[0, 11], [12, 17], [18, 25], [26, 38], [38, 39], [40, 44], [45, 47], [48, 52], [52, 53], [54, 57], [58, 65], [66, 75], [76, 78], [79, 84], [85, 95], [96, 102], [103, 106], [107, 109], [110, 113], [114, 118], [119, 123], [124, 131], [132, 136], [137, 144], [145, 147], [148, 151], [152, 157], [158, 164], [165, 171], [171, 172], [173, 177], [178, 180], [181, 184], [185, 193], [194, 201], [202, 212], [213, 215], [216, 219], [220, 226], [226, 227]]}
{"doc_key": "ai-test-189", "ner": [[0, 1, "person"], [3, 4, "person"], [6, 8, "person"], [10, 12, "person"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 16, 17, "role", "", false, false], [3, 4, 16, 17, "role", "", false, false], [6, 8, 16, 17, "role", "", false, false], [16, 17, 10, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["John", "Ireland", ",", "Joan", "Drew", "and", "Macdonald", "Carey", "starred", "in", "Jack", "Broder", "'s", "color", "production", "of", "Hannah", "Lee", ",", "which", "premiered", "on", "June", "19", ",", "1953", "."], "sentence-detokenized": "John Ireland, Joan Drew and Macdonald Carey starred in Jack Broder's color production of Hannah Lee, which premiered on June 19, 1953.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 18], [19, 23], [24, 27], [28, 37], [38, 43], [44, 51], [52, 54], [55, 59], [60, 66], [66, 68], [69, 74], [75, 85], [86, 88], [89, 95], [96, 99], [99, 100], [101, 106], [107, 116], [117, 119], [120, 124], [125, 127], [127, 128], [129, 133], [133, 134]]}
{"doc_key": "ai-test-190", "ner": [[4, 5, "task"], [9, 11, "field"], [16, 16, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 9, 11, "usage", "", false, false], [16, 16, 9, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "process", "is", "called", "image", "registration", "and", "uses", "various", "computer", "vision", "techniques", ",", "mainly", "related", "to", "tracking", "."], "sentence-detokenized": "This process is called image registration and uses various computer vision techniques, mainly related to tracking.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 22], [23, 28], [29, 41], [42, 45], [46, 50], [51, 58], [59, 67], [68, 74], [75, 85], [85, 86], [87, 93], [94, 101], [102, 104], [105, 113], [113, 114]]}
{"doc_key": "ai-test-191", "ner": [[18, 19, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Now", "let", "us", "move", "on", "to", "explaining", "the", "different", "possible", "correlations", "between", "the", "predicted", "and", "actual", "outcome", ":", "Confusion", "matrix"], "sentence-detokenized": "Now let us move on to explaining the different possible correlations between the predicted and actual outcome: Confusion matrix", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 15], [16, 18], [19, 21], [22, 32], [33, 36], [37, 46], [47, 55], [56, 68], [69, 76], [77, 80], [81, 90], [91, 94], [95, 101], [102, 109], [109, 110], [111, 120], [121, 127]]}
{"doc_key": "ai-test-192", "ner": [[0, 1, "product"], [1, 4, "misc"], [6, 6, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 1, 4, "part-of", "", false, false], [0, 1, 1, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "VOICEBOX", "speech", "processing", "toolkit", "for", "MATLAB", "implements", "the", "transform", "and", "its", "inverse", "in", "the", "form", ":"], "sentence-detokenized": "The VOICEBOX speech processing toolkit for MATLAB implements the transform and its inverse in the form:", "token2charspan": [[0, 3], [4, 12], [13, 19], [20, 30], [31, 38], [39, 42], [43, 49], [50, 60], [61, 64], [65, 74], [75, 78], [79, 82], [83, 90], [91, 93], [94, 97], [98, 102], [102, 103]]}
{"doc_key": "ai-test-193", "ner": [[0, 0, "programlang"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 9, "general-affiliation", "", false, false], [0, 0, 11, 12, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolog", "is", "a", "logical", "programming", "language", "related", "to", "artificial", "intelligence", "and", "computational", "linguistics", "."], "sentence-detokenized": "Prolog is a logical programming language related to artificial intelligence and computational linguistics.", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 19], [20, 31], [32, 40], [41, 48], [49, 51], [52, 62], [63, 75], [76, 79], [80, 93], [94, 105], [105, 106]]}
{"doc_key": "ai-test-194", "ner": [[0, 1, "researcher"], [9, 9, "field"], [11, 11, "field"], [17, 20, "organisation"], [23, 26, "organisation"], [30, 33, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 9, 9, "related-to", "works_with_topic", false, false], [0, 1, 11, 11, "related-to", "works_with_topic", false, false], [0, 1, 17, 20, "role", "", false, false], [0, 1, 23, 26, "role", "", false, false], [0, 1, 30, 33, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Milner", "has", "received", "numerous", "awards", "for", "her", "contributions", "to", "neuroscience", "and", "psychology", ",", "including", "membership", "in", "the", "Royal", "Society", "of", "London", ",", "the", "Royal", "Society", "of", "Canada", ",", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Milner has received numerous awards for her contributions to neuroscience and psychology, including membership in the Royal Society of London, the Royal Society of Canada, and the National Academy of Sciences.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 28], [29, 35], [36, 39], [40, 43], [44, 57], [58, 60], [61, 73], [74, 77], [78, 88], [88, 89], [90, 99], [100, 110], [111, 113], [114, 117], [118, 123], [124, 131], [132, 134], [135, 141], [141, 142], [143, 146], [147, 152], [153, 160], [161, 163], [164, 170], [170, 171], [172, 175], [176, 179], [180, 188], [189, 196], [197, 199], [200, 208], [208, 209]]}
{"doc_key": "ai-test-195", "ner": [[11, 12, "field"], [16, 17, "task"], [19, 20, "task"], [23, 23, "task"], [25, 25, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[16, 17, 11, 12, "part-of", "task_part_of_field", false, false], [19, 20, 11, 12, "part-of", "task_part_of_field", false, false], [23, 23, 11, 12, "part-of", "task_part_of_field", false, false], [25, 25, 11, 12, "part-of", "task_part_of_field", false, false], [27, 28, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["By", "combining", "these", "operators", ",", "algorithms", "can", "be", "obtained", "for", "many", "image", "processing", "tasks", "such", "as", "feature", "extraction", ",", "image", "segmentation", ",", "image", "sharpening", ",", "filtering", "and", "image", "classification", "."], "sentence-detokenized": "By combining these operators, algorithms can be obtained for many image processing tasks such as feature extraction, image segmentation, image sharpening, filtering and image classification.", "token2charspan": [[0, 2], [3, 12], [13, 18], [19, 28], [28, 29], [30, 40], [41, 44], [45, 47], [48, 56], [57, 60], [61, 65], [66, 71], [72, 82], [83, 88], [89, 93], [94, 96], [97, 104], [105, 115], [115, 116], [117, 122], [123, 135], [135, 136], [137, 142], [143, 153], [153, 154], [155, 164], [165, 168], [169, 174], [175, 189], [189, 190]]}
{"doc_key": "ai-test-196", "ner": [[10, 12, "university"], [25, 28, "organisation"], [29, 30, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[29, 30, 25, 28, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "2017", ",", "he", "has", "been", "a", "professor", "at", "the", "Coll\u00e8ge", "de", "France", ",", "and", "since", "1989", ",", "he", "has", "been", "the", "director", "of", "the", "562", "INSERM", "unit", "on", "cognitive", "neuroimaging", "."], "sentence-detokenized": "Since 2017, he has been a professor at the Coll\u00e8ge de France, and since 1989, he has been the director of the 562 INSERM unit on cognitive neuroimaging.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 14], [15, 18], [19, 23], [24, 25], [26, 35], [36, 38], [39, 42], [43, 50], [51, 53], [54, 60], [60, 61], [62, 65], [66, 71], [72, 76], [76, 77], [78, 80], [81, 84], [85, 89], [90, 93], [94, 102], [103, 105], [106, 109], [110, 113], [114, 120], [121, 125], [126, 128], [129, 138], [139, 151], [151, 152]]}
{"doc_key": "ai-test-197", "ner": [[12, 13, "algorithm"], [15, 18, "algorithm"], [23, 23, "algorithm"], [25, 31, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 25, 31, "temporal", "", false, true]], "relations_mapping_to_source": [0], "sentence": ["There", "are", "many", "approaches", "to", "studying", "these", "embeddings", ",", "in", "particular", "using", "Bayesian", "clustering", "or", "energy", "-", "based", "structures", ",", "and", "more", "recently", "TransE", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", "2013", ")", "."], "sentence-detokenized": "There are many approaches to studying these embeddings, in particular using Bayesian clustering or energy-based structures, and more recently TransE (Conference on Neural Information Processing Systems 2013).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 25], [26, 28], [29, 37], [38, 43], [44, 54], [54, 55], [56, 58], [59, 69], [70, 75], [76, 84], [85, 95], [96, 98], [99, 105], [105, 106], [106, 111], [112, 122], [122, 123], [124, 127], [128, 132], [133, 141], [142, 148], [149, 150], [150, 160], [161, 163], [164, 170], [171, 182], [183, 193], [194, 201], [202, 206], [206, 207], [207, 208]]}
{"doc_key": "ai-test-198", "ner": [[5, 5, "metrics"], [6, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 9, 5, 5, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "is", "an", "alternative", "to", "Word", "Error", "Rate", ",", "which", "is", "used", "in", "some", "countries", "."], "sentence-detokenized": "It is an alternative to Word Error Rate, which is used in some countries.", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 20], [21, 23], [24, 28], [29, 34], [35, 39], [39, 40], [41, 46], [47, 49], [50, 54], [55, 57], [58, 62], [63, 72], [72, 73]]}
{"doc_key": "ai-test-199", "ner": [[0, 0, "algorithm"], [11, 12, "task"], [14, 15, "task"], [17, 18, "task"], [20, 23, "task"], [25, 29, "task"], [31, 32, "task"], [45, 45, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 12, 0, 0, "usage", "", false, false], [14, 15, 0, 0, "usage", "", false, false], [17, 18, 0, 0, "usage", "", false, false], [20, 23, 0, 0, "usage", "", false, false], [25, 29, 0, 0, "usage", "", false, false], [31, 32, 0, 0, "usage", "", false, false], [45, 45, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["ANNs", "are", "used", "to", "solve", "a", "variety", "of", "tasks", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "filtering", "in", "social", "networks", ",", "playing", "board", "and", "video", "games", ",", "medical", "diagnostics", ",", "and", "even", "in", "activities", "traditionally", "reserved", "for", "humans", ",", "such", "as", "drawing", "."], "sentence-detokenized": "ANNs are used to solve a variety of tasks, including computer vision, speech recognition, machine translation, filtering in social networks, playing board and video games, medical diagnostics, and even in activities traditionally reserved for humans, such as drawing.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 22], [23, 24], [25, 32], [33, 35], [36, 41], [41, 42], [43, 52], [53, 61], [62, 68], [68, 69], [70, 76], [77, 88], [88, 89], [90, 97], [98, 109], [109, 110], [111, 120], [121, 123], [124, 130], [131, 139], [139, 140], [141, 148], [149, 154], [155, 158], [159, 164], [165, 170], [170, 171], [172, 179], [180, 191], [191, 192], [193, 196], [197, 201], [202, 204], [205, 215], [216, 229], [230, 238], [239, 242], [243, 249], [249, 250], [251, 255], [256, 258], [259, 266], [266, 267]]}
{"doc_key": "ai-test-200", "ner": [[0, 4, "product"], [6, 6, "product"], [26, 28, "field"], [30, 30, "field"], [35, 35, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 26, 28, "related-to", "", false, false], [0, 4, 35, 35, "general-affiliation", "", false, false], [6, 6, 0, 4, "named", "", false, false], [30, 30, 26, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Modular", "Audio", "Recognition", "Framework", "(", "MARF", ")", "is", "an", "open", "source", "research", "platform", "and", "collection", "of", "voice", ",", "audio", ",", "speech", ",", "text", ",", "and", "natural", "language", "processing", "(", "NLP", ")", "algorithms", "written", "in", "Java", "and", "organized", "in", "a", "modular", "and", "extensible", "framework", "that", "attempts", "to", "facilitate", "the", "addition", "of", "new", "algorithms", "."], "sentence-detokenized": "The Modular Audio Recognition Framework (MARF) is an open source research platform and collection of voice, audio, speech, text, and natural language processing (NLP) algorithms written in Java and organized in a modular and extensible framework that attempts to facilitate the addition of new algorithms.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 29], [30, 39], [40, 41], [41, 45], [45, 46], [47, 49], [50, 52], [53, 57], [58, 64], [65, 73], [74, 82], [83, 86], [87, 97], [98, 100], [101, 106], [106, 107], [108, 113], [113, 114], [115, 121], [121, 122], [123, 127], [127, 128], [129, 132], [133, 140], [141, 149], [150, 160], [161, 162], [162, 165], [165, 166], [167, 177], [178, 185], [186, 188], [189, 193], [194, 197], [198, 207], [208, 210], [211, 212], [213, 220], [221, 224], [225, 235], [236, 245], [246, 250], [251, 259], [260, 262], [263, 273], [274, 277], [278, 286], [287, 289], [290, 293], [294, 304], [304, 305]]}
{"doc_key": "ai-test-201", "ner": [[5, 10, "organisation"], [20, 24, "country"], [25, 27, "organisation"], [30, 31, "organisation"], [34, 36, "task"], [54, 60, "organisation"], [52, 53, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[25, 27, 20, 24, "physical", "", false, false], [25, 27, 34, 36, "usage", "", false, false], [25, 27, 54, 60, "named", "", false, false], [30, 31, 20, 24, "physical", "", false, false], [30, 31, 34, 36, "usage", "", false, false], [54, 60, 52, 53, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "a", "report", "by", "Big", "Brother", "Watch", ",", "a", "civil", "liberties", "and", "rights", "organization", ",", "found", "that", "two", "UK", "police", "forces", "-", "the", "South", "Wales", "Police", "and", "the", "Metropolitan", "Police", "-", "used", "facial", "recognition", "at", "public", "events", "and", "in", "public", "places", ",", "and", "in", "September", "2019", ",", "the", "use", "of", "facial", "recognition", "by", "the", "South", "Wales", "Police", "was", "made", "legal", "."], "sentence-detokenized": "In 2018, a report by Big Brother Watch, a civil liberties and rights organization, found that two UK police forces - the South Wales Police and the Metropolitan Police - used facial recognition at public events and in public places, and in September 2019, the use of facial recognition by the South Wales Police was made legal.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 17], [18, 20], [21, 24], [25, 32], [33, 38], [38, 39], [40, 41], [42, 47], [48, 57], [58, 61], [62, 68], [69, 81], [81, 82], [83, 88], [89, 93], [94, 97], [98, 100], [101, 107], [108, 114], [115, 116], [117, 120], [121, 126], [127, 132], [133, 139], [140, 143], [144, 147], [148, 160], [161, 167], [168, 169], [170, 174], [175, 181], [182, 193], [194, 196], [197, 203], [204, 210], [211, 214], [215, 217], [218, 224], [225, 231], [231, 232], [233, 236], [237, 239], [240, 249], [250, 254], [254, 255], [256, 259], [260, 263], [264, 266], [267, 273], [274, 285], [286, 288], [289, 292], [293, 298], [299, 304], [305, 311], [312, 315], [316, 320], [321, 326], [326, 327]]}
{"doc_key": "ai-test-202", "ner": [[0, 0, "product"], [4, 4, "programlang"], [13, 14, "field"], [16, 16, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 4, "general-affiliation", "", false, false], [0, 0, 13, 14, "related-to", "", false, false], [0, 0, 16, 16, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["ANIMAL", "was", "ported", "to", "R", ",", "a", "freely", "available", "language", "and", "environment", "for", "statistical", "computing", "and", "graphics", "."], "sentence-detokenized": "ANIMAL was ported to R, a freely available language and environment for statistical computing and graphics.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 20], [21, 22], [22, 23], [24, 25], [26, 32], [33, 42], [43, 51], [52, 55], [56, 67], [68, 71], [72, 83], [84, 93], [94, 97], [98, 106], [106, 107]]}
{"doc_key": "ai-test-203", "ner": [[0, 5, "algorithm"], [7, 9, "algorithm"], [15, 17, "algorithm"], [19, 19, "algorithm"], [22, 24, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 5, 15, 17, "opposite", "alternative to", false, false], [7, 9, 0, 5, "named", "", false, false], [19, 19, 15, 17, "named", "", false, false], [22, 24, 0, 5, "usage", "", false, false], [22, 24, 15, 17, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Time", "-", "invariant", "Hidden", "Bernoulli", "Model", "(", "TI", "-", "HBM", ")", "is", "an", "alternative", "to", "Hidden", "Markov", "Model", "(", "HMM", ")", "for", "automatic", "speech", "recognition", "."], "sentence-detokenized": "Time-invariant Hidden Bernoulli Model (TI-HBM) is an alternative to Hidden Markov Model (HMM) for automatic speech recognition.", "token2charspan": [[0, 4], [4, 5], [5, 14], [15, 21], [22, 31], [32, 37], [38, 39], [39, 41], [41, 42], [42, 45], [45, 46], [47, 49], [50, 52], [53, 64], [65, 67], [68, 74], [75, 81], [82, 87], [88, 89], [89, 92], [92, 93], [94, 97], [98, 107], [108, 114], [115, 126], [126, 127]]}
{"doc_key": "ai-test-204", "ner": [[4, 4, "organisation"], [12, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 12, 12, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "July", "2016", ",", "Nvidia", "demonstrated", "a", "new", "foveated", "rendering", "method", "at", "SIGGRAPH", ",", "which", "is", "claimed", "to", "be", "invisible", "to", "users", "."], "sentence-detokenized": "In July 2016, Nvidia demonstrated a new foveated rendering method at SIGGRAPH, which is claimed to be invisible to users.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 20], [21, 33], [34, 35], [36, 39], [40, 48], [49, 58], [59, 65], [66, 68], [69, 77], [77, 78], [79, 84], [85, 87], [88, 95], [96, 98], [99, 101], [102, 111], [112, 114], [115, 120], [120, 121]]}
{"doc_key": "ai-test-205", "ner": [[6, 8, "misc"], [11, 12, "researcher"], [19, 20, "researcher"], [22, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 8, 11, 12, "origin", "", false, false], [6, 8, 19, 20, "origin", "", false, false], [6, 8, 22, 22, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Both", "approaches", "are", "based", "on", "the", "speech", "act", "theory", "developed", "by", "John", "Searle", "in", "the", "1960s", "and", "improved", "by", "Terry", "Winograd", "and", "Flores", "in", "the", "1970s", "."], "sentence-detokenized": "Both approaches are based on the speech act theory developed by John Searle in the 1960s and improved by Terry Winograd and Flores in the 1970s.", "token2charspan": [[0, 4], [5, 15], [16, 19], [20, 25], [26, 28], [29, 32], [33, 39], [40, 43], [44, 50], [51, 60], [61, 63], [64, 68], [69, 75], [76, 78], [79, 82], [83, 88], [89, 92], [93, 101], [102, 104], [105, 110], [111, 119], [120, 123], [124, 130], [131, 133], [134, 137], [138, 143], [143, 144]]}
{"doc_key": "ai-test-206", "ner": [[0, 3, "algorithm"], [20, 20, "researcher"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 20, 20, "related-to", "", false, false], [23, 23, 20, 20, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Neural", "network", "models", "of", "concept", "formation", "and", "knowledge", "structure", "have", "opened", "powerful", "hierarchical", "models", "of", "knowledge", "organization", ",", "such", "as", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "Neural network models of concept formation and knowledge structure have opened powerful hierarchical models of knowledge organization, such as George Miller's Wordnet.", "token2charspan": [[0, 6], [7, 14], [15, 21], [22, 24], [25, 32], [33, 42], [43, 46], [47, 56], [57, 66], [67, 71], [72, 78], [79, 87], [88, 100], [101, 107], [108, 110], [111, 120], [121, 133], [133, 134], [135, 139], [140, 142], [143, 149], [150, 156], [156, 158], [159, 166], [166, 167]]}
{"doc_key": "ai-test-207", "ner": [[0, 1, "algorithm"], [12, 13, "field"], [16, 18, "product"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 12, 13, "part-of", "", false, false], [0, 1, 21, 23, "part-of", "", false, false], [16, 18, 12, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Pattern", "matching", "has", "various", "applications", "and", "is", "used", "in", "areas", "such", "as", "face", "recognition", "(", "see", "face", "recognition", "system", ")", "and", "medical", "image", "processing", "."], "sentence-detokenized": "Pattern matching has various applications and is used in areas such as face recognition (see face recognition system) and medical image processing.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 28], [29, 41], [42, 45], [46, 48], [49, 53], [54, 56], [57, 62], [63, 67], [68, 70], [71, 75], [76, 87], [88, 89], [89, 92], [93, 97], [98, 109], [110, 116], [116, 117], [118, 121], [122, 129], [130, 135], [136, 146], [146, 147]]}
{"doc_key": "ai-test-208", "ner": [[12, 13, "researcher"], [15, 16, "researcher"], [20, 30, "organisation"], [32, 32, "organisation"], [40, 41, "algorithm"], [44, 50, "conference"], [52, 52, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 13, 20, 30, "role", "", false, false], [12, 13, 44, 50, "physical", "", false, false], [12, 13, 44, 50, "temporal", "", false, false], [12, 13, 52, 52, "physical", "", false, false], [15, 16, 20, 30, "role", "", false, false], [15, 16, 44, 50, "temporal", "", false, false], [32, 32, 20, 30, "named", "", false, false], [44, 50, 40, 41, "topic", "", false, false], [52, 52, 44, 50, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["However", ",", "the", "use", "did", "not", "become", "widespread", "until", "2005", ",", "when", "Navneet", "Dalal", "and", "Bill", "Triggs", ",", "researchers", "at", "the", "French", "National", "Institute", "for", "Research", "in", "Computer", "Science", "and", "Automation", "(", "INRIA", ")", ",", "presented", "their", "additional", "work", "on", "HOG", "descriptors", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "."], "sentence-detokenized": "However, the use did not become widespread until 2005, when Navneet Dalal and Bill Triggs, researchers at the French National Institute for Research in Computer Science and Automation (INRIA), presented their additional work on HOG descriptors at the Conference on Computer Vision and Pattern Recognition (CVPR).", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 16], [17, 20], [21, 24], [25, 31], [32, 42], [43, 48], [49, 53], [53, 54], [55, 59], [60, 67], [68, 73], [74, 77], [78, 82], [83, 89], [89, 90], [91, 102], [103, 105], [106, 109], [110, 116], [117, 125], [126, 135], [136, 139], [140, 148], [149, 151], [152, 160], [161, 168], [169, 172], [173, 183], [184, 185], [185, 190], [190, 191], [191, 192], [193, 202], [203, 208], [209, 219], [220, 224], [225, 227], [228, 231], [232, 243], [244, 246], [247, 250], [251, 261], [262, 264], [265, 273], [274, 280], [281, 284], [285, 292], [293, 304], [305, 306], [306, 310], [310, 311], [311, 312]]}
{"doc_key": "ai-test-209", "ner": [[4, 4, "university"], [17, 19, "organisation"], [21, 22, "organisation"], [35, 37, "researcher"], [39, 41, "researcher"], [44, 46, "researcher"], [49, 52, "organisation"], [56, 72, "organisation"], [63, 64, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6, 7, 8, 9], "relations": [[35, 37, 21, 22, "physical", "", false, false], [35, 37, 21, 22, "role", "", false, false], [39, 41, 21, 22, "physical", "", false, false], [39, 41, 21, 22, "role", "", false, false], [44, 46, 21, 22, "physical", "", false, false], [44, 46, 21, 22, "role", "", false, false], [63, 64, 56, 72, "role", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "sentence": ["Prior", "to", "joining", "the", "Penn", "faculty", "in", "2002", ",", "he", "spent", "ten", "years", "(", "1991-2001", ")", "at", "AT", "&T", "Labs", "and", "Bell", "Labs", ",", "including", "as", "head", "of", "the", "Artificial", "Intelligence", "Division", "with", "colleagues", "including", "Michael", "L.", "Littman", ",", "David", "A.", "McAllister", ",", "and", "Richard", "S.", "Sutton", ";", "the", "Secure", "Systems", "Research", "Division", ";", "and", "the", "Machine", "Learning", "Division", "with", "members", "such", "as", "Michael", "Collins", "and", "the", "head", "of", "the", "Machine", "Learning", "Group", ".", ")"], "sentence-detokenized": "Prior to joining the Penn faculty in 2002, he spent ten years (1991-2001) at AT&T Labs and Bell Labs, including as head of the Artificial Intelligence Division with colleagues including Michael L. Littman, David A. McAllister, and Richard S. Sutton; the Secure Systems Research Division; and the Machine Learning Division with members such as Michael Collins and the head of the Machine Learning Group.)", "token2charspan": [[0, 5], [6, 8], [9, 16], [17, 20], [21, 25], [26, 33], [34, 36], [37, 41], [41, 42], [43, 45], [46, 51], [52, 55], [56, 61], [62, 63], [63, 72], [72, 73], [74, 76], [77, 79], [79, 81], [82, 86], [87, 90], [91, 95], [96, 100], [100, 101], [102, 111], [112, 114], [115, 119], [120, 122], [123, 126], [127, 137], [138, 150], [151, 159], [160, 164], [165, 175], [176, 185], [186, 193], [194, 196], [197, 204], [204, 205], [206, 211], [212, 214], [215, 225], [225, 226], [227, 230], [231, 238], [239, 241], [242, 248], [248, 249], [250, 253], [254, 260], [261, 268], [269, 277], [278, 286], [286, 287], [288, 291], [292, 295], [296, 303], [304, 312], [313, 321], [322, 326], [327, 334], [335, 339], [340, 342], [343, 350], [351, 358], [359, 362], [363, 366], [367, 371], [372, 374], [375, 378], [379, 386], [387, 395], [396, 401], [401, 402], [402, 403]]}
{"doc_key": "ai-test-210", "ner": [[7, 10, "field"], [13, 14, "field"], [25, 26, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 10, 13, 14, "compare", "", false, false], [25, 26, 13, 14, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["When", "the", "data", "is", "unlabeled", ",", "supervised", "learning", "is", "not", "possible", "and", "an", "unsupervised", "learning", "approach", "is", "needed", ",", "which", "tries", "to", "find", "a", "natural", "clustering", "analysis", "for", "the", "groups", "and", "then", "map", "the", "new", "data", "to", "these", "formed", "groups", "."], "sentence-detokenized": "When the data is unlabeled, supervised learning is not possible and an unsupervised learning approach is needed, which tries to find a natural clustering analysis for the groups and then map the new data to these formed groups.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 26], [26, 27], [28, 38], [39, 47], [48, 50], [51, 54], [55, 63], [64, 67], [68, 70], [71, 83], [84, 92], [93, 101], [102, 104], [105, 111], [111, 112], [113, 118], [119, 124], [125, 127], [128, 132], [133, 134], [135, 142], [143, 153], [154, 162], [163, 166], [167, 170], [171, 177], [178, 181], [182, 186], [187, 190], [191, 194], [195, 198], [199, 203], [204, 206], [207, 212], [213, 219], [220, 226], [226, 227]]}
{"doc_key": "ai-test-211", "ner": [[3, 4, "field"], [22, 22, "organisation"], [15, 30, "field"], [32, 32, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 22, 22, "origin", "", false, false], [3, 4, 15, 30, "part-of", "", false, false], [3, 4, 32, 32, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "branch", "of", "computer", "science", "developed", "in", "the", "1950s", "in", "academic", "institutions", "such", "as", "the", "Massachusetts", "Institute", "of", "Technology", "'s", "Artificial", "Intelligence", "Laboratory", ",", "initially", "as", "a", "branch", "of", "artificial", "intelligence", "and", "robotics", "."], "sentence-detokenized": "This branch of computer science developed in the 1950s in academic institutions such as the Massachusetts Institute of Technology's Artificial Intelligence Laboratory, initially as a branch of artificial intelligence and robotics.", "token2charspan": [[0, 4], [5, 11], [12, 14], [15, 23], [24, 31], [32, 41], [42, 44], [45, 48], [49, 54], [55, 57], [58, 66], [67, 79], [80, 84], [85, 87], [88, 91], [92, 105], [106, 115], [116, 118], [119, 129], [129, 131], [132, 142], [143, 155], [156, 166], [166, 167], [168, 177], [178, 180], [181, 182], [183, 189], [190, 192], [193, 203], [204, 216], [217, 220], [221, 229], [229, 230]]}
{"doc_key": "ai-test-212", "ner": [[7, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "can", "also", "be", "replaced", "by", "the", "wood", "loss", "equation", "below", ":"], "sentence-detokenized": "It can also be replaced by the wood loss equation below:", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 23], [24, 26], [27, 30], [31, 35], [36, 40], [41, 49], [50, 55], [55, 56]]}
{"doc_key": "ai-test-213", "ner": [[11, 13, "organisation"], [17, 19, "organisation"], [23, 27, "university"], [30, 33, "university"], [35, 36, "university"], [39, 41, "university"], [44, 44, "country"], [8, 10, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 13, 8, 10, "related-to", "research_leader_in_field", false, false], [17, 19, 11, 13, "named", "", false, false], [17, 19, 8, 10, "related-to", "research_leader_in_field", false, false], [23, 27, 8, 10, "related-to", "research_leader_in_field", false, false], [30, 33, 8, 10, "related-to", "research_leader_in_field", false, false], [35, 36, 8, 10, "related-to", "research_leader_in_field", false, false], [39, 41, 44, 44, "physical", "", false, false], [39, 41, 8, 10, "related-to", "research_leader_in_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "leaders", "of", "research", "in", "the", "field", "of", "biomechatronics", "are", "the", "Shirley", "Ryan", "AbilityLab", "(", "formerly", "the", "Chicago", "Rehabilitation", "Institute", ")", ",", "the", "University", "of", "California", "at", "Berkeley", ",", "the", "Massachusetts", "Institute", "of", "Technology", ",", "Stanford", "University", "and", "the", "University", "of", "Twente", "in", "the", "Netherlands", "."], "sentence-detokenized": "The leaders of research in the field of biomechatronics are the Shirley Ryan AbilityLab (formerly the Chicago Rehabilitation Institute), the University of California at Berkeley, the Massachusetts Institute of Technology, Stanford University and the University of Twente in the Netherlands.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 23], [24, 26], [27, 30], [31, 36], [37, 39], [40, 55], [56, 59], [60, 63], [64, 71], [72, 76], [77, 87], [88, 89], [89, 97], [98, 101], [102, 109], [110, 124], [125, 134], [134, 135], [135, 136], [137, 140], [141, 151], [152, 154], [155, 165], [166, 168], [169, 177], [177, 178], [179, 182], [183, 196], [197, 206], [207, 209], [210, 220], [220, 221], [222, 230], [231, 241], [242, 245], [246, 249], [250, 260], [261, 263], [264, 270], [271, 273], [274, 277], [278, 289], [289, 290]]}
{"doc_key": "ai-test-214", "ner": [[27, 34, "metrics"], [44, 46, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Given", "a", "set", "of", "predicted", "values", "and", "a", "corresponding", "set", "of", "actual", "values", "for", "X", "for", "different", "time", "periods", ",", "a", "common", "evaluation", "technique", "is", "to", "use", "the", "root", "mean", "square", "error", "of", "the", "prediction", ";", "other", "measures", "are", "also", "available", "(", "see", "forecasting", "#", "forecasting", "accuracy", ")", "."], "sentence-detokenized": "Given a set of predicted values and a corresponding set of actual values for X for different time periods, a common evaluation technique is to use the root mean square error of the prediction; other measures are also available (see forecasting #forecasting accuracy).", "token2charspan": [[0, 5], [6, 7], [8, 11], [12, 14], [15, 24], [25, 31], [32, 35], [36, 37], [38, 51], [52, 55], [56, 58], [59, 65], [66, 72], [73, 76], [77, 78], [79, 82], [83, 92], [93, 97], [98, 105], [105, 106], [107, 108], [109, 115], [116, 126], [127, 136], [137, 139], [140, 142], [143, 146], [147, 150], [151, 155], [156, 160], [161, 167], [168, 173], [174, 176], [177, 180], [181, 191], [191, 192], [193, 198], [199, 207], [208, 211], [212, 216], [217, 226], [227, 228], [228, 231], [232, 243], [244, 245], [245, 256], [257, 265], [265, 266], [266, 267]]}
{"doc_key": "ai-test-215", "ner": [[12, 14, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "measures", "such", "as", "the", "proportion", "of", "correct", "predictions", "(", "also", "called", "accuracy", ")", "are", "not", "useful", "when", "the", "two", "classes", "are", "very", "different", "in", "size", "."], "sentence-detokenized": "Other measures such as the proportion of correct predictions (also called accuracy) are not useful when the two classes are very different in size.", "token2charspan": [[0, 5], [6, 14], [15, 19], [20, 22], [23, 26], [27, 37], [38, 40], [41, 48], [49, 60], [61, 62], [62, 66], [67, 73], [74, 82], [82, 83], [84, 87], [88, 91], [92, 98], [99, 103], [104, 107], [108, 111], [112, 119], [120, 123], [124, 128], [129, 138], [139, 141], [142, 146], [146, 147]]}
{"doc_key": "ai-test-216", "ner": [[5, 5, "product"], [13, 17, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 13, 17, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "alpha", "version", "of", "OpenCV", "was", "presented", "to", "the", "public", "at", "the", "Computer", "Vision", "and", "Pattern", "Recognition", "Conference", "in", "2000", ",", "and", "five", "beta", "versions", "were", "released", "between", "2001", "and", "2005", "."], "sentence-detokenized": "The first alpha version of OpenCV was presented to the public at the Computer Vision and Pattern Recognition Conference in 2000, and five beta versions were released between 2001 and 2005.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 23], [24, 26], [27, 33], [34, 37], [38, 47], [48, 50], [51, 54], [55, 61], [62, 64], [65, 68], [69, 77], [78, 84], [85, 88], [89, 96], [97, 108], [109, 119], [120, 122], [123, 127], [127, 128], [129, 132], [133, 137], [138, 142], [143, 151], [152, 156], [157, 165], [166, 173], [174, 178], [179, 182], [183, 187], [187, 188]]}
{"doc_key": "ai-test-217", "ner": [[21, 22, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Results", "were", "presented", "that", "give", "a", "correlation", "of", "up", "to", "0.964", "with", "human", "judgment", "at", "the", "corpus", "level", ",", "compared", "to", "BLEU", "'s", "achievement", "of", "0.817", "on", "the", "same", "dataset", "."], "sentence-detokenized": "Results were presented that give a correlation of up to 0.964 with human judgment at the corpus level, compared to BLEU's achievement of 0.817 on the same dataset.", "token2charspan": [[0, 7], [8, 12], [13, 22], [23, 27], [28, 32], [33, 34], [35, 46], [47, 49], [50, 52], [53, 55], [56, 61], [62, 66], [67, 72], [73, 81], [82, 84], [85, 88], [89, 95], [96, 101], [101, 102], [103, 111], [112, 114], [115, 119], [119, 121], [122, 133], [134, 136], [137, 142], [143, 145], [146, 149], [150, 154], [155, 162], [162, 163]]}
{"doc_key": "ai-test-218", "ner": [[8, 8, "metrics"], [18, 18, "metrics"], [20, 22, "metrics"], [24, 26, "metrics"], [37, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 8, 18, 18, "compare", "", false, false], [8, 8, 20, 22, "compare", "", false, false], [8, 8, 24, 26, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["It", "is", "shown", "that", "the", "early", "version", "of", "VMAF", "outperforms", "other", "image", "and", "video", "quality", "metrics", "such", "as", "SSIM", ",", "PSNR", "-", "HVS", "and", "VQM", "-", "VFD", "on", "three", "out", "of", "four", "datasets", "in", "terms", "of", "prediction", "accuracy", "when", "compared", "to", "subjective", "estimates", "."], "sentence-detokenized": "It is shown that the early version of VMAF outperforms other image and video quality metrics such as SSIM, PSNR -HVS and VQM-VFD on three out of four datasets in terms of prediction accuracy when compared to subjective estimates.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 16], [17, 20], [21, 26], [27, 34], [35, 37], [38, 42], [43, 54], [55, 60], [61, 66], [67, 70], [71, 76], [77, 84], [85, 92], [93, 97], [98, 100], [101, 105], [105, 106], [107, 111], [112, 113], [113, 116], [117, 120], [121, 124], [124, 125], [125, 128], [129, 131], [132, 137], [138, 141], [142, 144], [145, 149], [150, 158], [159, 161], [162, 167], [168, 170], [171, 181], [182, 190], [191, 195], [196, 204], [205, 207], [208, 218], [219, 228], [228, 229]]}
{"doc_key": "ai-test-219", "ner": [[20, 21, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 21, 28, 29, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "example", ",", "the", "ambiguity", "of", "the", "word", "\"", "mouse", "\"", "(", "animal", "or", "device", ")", "does", "not", "matter", "for", "machine", "translation", ",", "but", "it", "does", "matter", "for", "information", "retrieval", "."], "sentence-detokenized": "For example, the ambiguity of the word \"mouse\" (animal or device) does not matter for machine translation, but it does matter for information retrieval.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 26], [27, 29], [30, 33], [34, 38], [39, 40], [40, 45], [45, 46], [47, 48], [48, 54], [55, 57], [58, 64], [64, 65], [66, 70], [71, 74], [75, 81], [82, 85], [86, 93], [94, 105], [105, 106], [107, 110], [111, 113], [114, 118], [119, 125], [126, 129], [130, 141], [142, 151], [151, 152]]}
{"doc_key": "ai-test-220", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [9, 10, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 0, 1, "usage", "", false, false], [9, 10, 6, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Geometric", "hashing", "was", "originally", "proposed", "in", "computer", "vision", "for", "object", "recognition", "in", "2D", "and", "3D", ","], "sentence-detokenized": "Geometric hashing was originally proposed in computer vision for object recognition in 2D and 3D,", "token2charspan": [[0, 9], [10, 17], [18, 21], [22, 32], [33, 41], [42, 44], [45, 53], [54, 60], [61, 64], [65, 71], [72, 83], [84, 86], [87, 89], [90, 93], [94, 96], [96, 97]]}
{"doc_key": "ai-test-221", "ner": [[9, 10, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 15, 9, 10, "part-of", "subfield", false, false], [17, 18, 9, 10, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "is", "one", "of", "the", "three", "main", "categories", "of", "machine", "learning", ",", "along", "with", "supervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "It is one of the three main categories of machine learning, along with supervised learning and reinforcement learning.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 12], [13, 16], [17, 22], [23, 27], [28, 38], [39, 41], [42, 49], [50, 58], [58, 59], [60, 65], [66, 70], [71, 81], [82, 90], [91, 94], [95, 108], [109, 117], [117, 118]]}
{"doc_key": "ai-test-222", "ner": [[0, 1, "field"], [17, 17, "field"], [18, 21, "field"], [23, 24, "field"], [26, 27, "field"], [29, 32, "field"], [34, 35, "field"], [37, 38, "field"], [40, 40, "field"], [42, 43, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 1, 17, 17, "part-of", "subfield", false, false], [0, 1, 18, 21, "part-of", "subfield", false, false], [0, 1, 23, 24, "part-of", "subfield", false, false], [0, 1, 26, 27, "part-of", "subfield", false, false], [0, 1, 29, 32, "part-of", "subfield", false, false], [0, 1, 34, 35, "part-of", "subfield", false, false], [0, 1, 37, 38, "part-of", "subfield", false, false], [0, 1, 40, 40, "part-of", "subfield", false, false], [0, 1, 42, 43, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Reinforcement", "learning", ",", "due", "to", "its", "generality", ",", "is", "studied", "in", "many", "other", "disciplines", ",", "such", "as", "game", "theory", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimization", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Reinforcement learning, due to its generality, is studied in many other disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimization, multi-agent systems, swarm intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 13], [14, 22], [22, 23], [24, 27], [28, 30], [31, 34], [35, 45], [45, 46], [47, 49], [50, 57], [58, 60], [61, 65], [66, 71], [72, 83], [83, 84], [85, 89], [90, 92], [93, 97], [98, 104], [104, 105], [106, 113], [114, 120], [120, 121], [122, 132], [133, 141], [141, 142], [143, 154], [155, 161], [161, 162], [163, 173], [173, 174], [174, 179], [180, 192], [192, 193], [194, 205], [206, 213], [213, 214], [215, 220], [221, 233], [233, 234], [235, 245], [246, 249], [250, 257], [258, 268], [268, 269]]}
{"doc_key": "ai-test-223", "ner": [[0, 1, "field"], [6, 7, "field"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "related-to", "", false, false], [0, 1, 9, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pattern", "recognition", "is", "closely", "related", "to", "artificial", "intelligence", "and", "machine", "learning", ","], "sentence-detokenized": "Pattern recognition is closely related to artificial intelligence and machine learning,", "token2charspan": [[0, 7], [8, 19], [20, 22], [23, 30], [31, 38], [39, 41], [42, 52], [53, 65], [66, 69], [70, 77], [78, 86], [86, 87]]}
{"doc_key": "ai-test-224", "ner": [[10, 11, "algorithm"], [14, 14, "field"], [16, 17, "field"], [28, 28, "task"], [31, 31, "task"], [33, 34, "task"], [36, 37, "algorithm"], [39, 41, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 11, 14, 14, "related-to", "", false, false], [10, 11, 16, 17, "related-to", "", false, false], [28, 28, 10, 11, "usage", "", true, false], [31, 31, 10, 11, "usage", "", true, false], [33, 34, 10, 11, "usage", "", true, false], [36, 37, 10, 11, "usage", "", true, false], [39, 41, 10, 11, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "software", "is", "used", "to", "design", ",", "train", "and", "deploy", "neural", "network", "models", "(", "supervised", "and", "unsupervised", "learning", ")", "to", "perform", "a", "wide", "range", "of", "tasks", "such", "as", "data", "mining", ",", "classification", ",", "function", "approximation", ",", "multivariate", "regression", "and", "time", "series", "forecasting", "."], "sentence-detokenized": "The software is used to design, train and deploy neural network models (supervised and unsupervised learning) to perform a wide range of tasks such as data mining, classification, function approximation, multivariate regression and time series forecasting.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 20], [21, 23], [24, 30], [30, 31], [32, 37], [38, 41], [42, 48], [49, 55], [56, 63], [64, 70], [71, 72], [72, 82], [83, 86], [87, 99], [100, 108], [108, 109], [110, 112], [113, 120], [121, 122], [123, 127], [128, 133], [134, 136], [137, 142], [143, 147], [148, 150], [151, 155], [156, 162], [162, 163], [164, 178], [178, 179], [180, 188], [189, 202], [202, 203], [204, 216], [217, 227], [228, 231], [232, 236], [237, 243], [244, 255], [255, 256]]}
{"doc_key": "ai-test-225", "ner": [[9, 15, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2016", "he", "was", "elected", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2016 he was elected a member of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 22], [23, 24], [25, 31], [32, 34], [35, 38], [39, 50], [51, 54], [55, 58], [59, 70], [71, 73], [74, 84], [85, 97], [97, 98]]}
{"doc_key": "ai-test-226", "ner": [[6, 9, "organisation"], [16, 21, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", "(", "since", "2005", ")", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "(", "since", "2009", ")", ","], "sentence-detokenized": "She is a member of the National Academy of Sciences (since 2005), the American Academy of Arts and Sciences (since 2009),", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 15], [16, 18], [19, 22], [23, 31], [32, 39], [40, 42], [43, 51], [52, 53], [53, 58], [59, 63], [63, 64], [64, 65], [66, 69], [70, 78], [79, 86], [87, 89], [90, 94], [95, 98], [99, 107], [108, 109], [109, 114], [115, 119], [119, 120], [120, 121]]}
{"doc_key": "ai-test-227", "ner": [[5, 5, "misc"], [8, 9, "product"], [12, 12, "country"], [14, 15, "country"], [19, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 9, 5, 5, "temporal", "", false, false], [8, 9, 12, 12, "physical", "", false, false], [8, 9, 14, 15, "physical", "", false, false], [8, 9, 19, 20, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["During", "the", "1973", "Yom", "Kippur", "War", ",", "Soviet", "anti-aircraft", "missile", "batteries", "in", "Egypt", "and", "Syria", "inflicted", "significant", "damage", "on", "Israeli", "fighters", "."], "sentence-detokenized": "During the 1973 Yom Kippur War, Soviet anti-aircraft missile batteries in Egypt and Syria inflicted significant damage on Israeli fighters.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 19], [20, 26], [27, 30], [30, 31], [32, 38], [39, 52], [53, 60], [61, 70], [71, 73], [74, 79], [80, 83], [84, 89], [90, 99], [100, 111], [112, 118], [119, 121], [122, 129], [130, 138], [138, 139]]}
{"doc_key": "ai-test-228", "ner": [[9, 10, "product"], [14, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 15, 9, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Another", "resource", "(", "free", "but", "copyrighted", ")", "is", "the", "HTK", "book", "(", "and", "accompanying", "HTK", "toolkit", ")", "."], "sentence-detokenized": "Another resource (free but copyrighted) is the HTK book (and accompanying HTK toolkit).", "token2charspan": [[0, 7], [8, 16], [17, 18], [18, 22], [23, 26], [27, 38], [38, 39], [40, 42], [43, 46], [47, 50], [51, 55], [56, 57], [57, 60], [61, 73], [74, 77], [78, 85], [85, 86], [86, 87]]}
{"doc_key": "ai-test-229", "ner": [[5, 6, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["-", "were", "adopted", "at", "the", "2004", "AAAI", "Spring", "Symposium", ",", "where", "linguists", ",", "computer", "scientists", ",", "and", "other", "interested", "researchers", "for", "the", "first", "time", "aligned", "interests", "and", "proposed", "common", "objectives", "and", "benchmark", "datasets", "for", "systematic", "computational", "studies", "of", "affect", ",", "appeal", ",", "subjectivity", ",", "and", "sentiment", "in", "text", "."], "sentence-detokenized": "- were adopted at the 2004 AAAI Spring Symposium, where linguists, computer scientists, and other interested researchers for the first time aligned interests and proposed common objectives and benchmark datasets for systematic computational studies of affect, appeal, subjectivity, and sentiment in text.", "token2charspan": [[0, 1], [2, 6], [7, 14], [15, 17], [18, 21], [22, 26], [27, 31], [32, 38], [39, 48], [48, 49], [50, 55], [56, 65], [65, 66], [67, 75], [76, 86], [86, 87], [88, 91], [92, 97], [98, 108], [109, 120], [121, 124], [125, 128], [129, 134], [135, 139], [140, 147], [148, 157], [158, 161], [162, 170], [171, 177], [178, 188], [189, 192], [193, 202], [203, 211], [212, 215], [216, 226], [227, 240], [241, 248], [249, 251], [252, 258], [258, 259], [260, 266], [266, 267], [268, 280], [280, 281], [282, 285], [286, 295], [296, 298], [299, 303], [303, 304]]}
{"doc_key": "ai-test-230", "ner": [[12, 15, "task"], [18, 19, "task"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "single", "grid", "can", "be", "analysed", "both", "in", "terms", "of", "content", "(", "eyewitness", "analysis", ")", "and", "structure", "(", "cluster", "analysis", ",", "principal", "component", "analysis", "and", "a", "variety", "of", "structural", "indices", "relating", "to", "complexity", "and", "range", "of", "ratings", "are", "the", "main", "methods", "used", ")", "."], "sentence-detokenized": "A single grid can be analysed both in terms of content (eyewitness analysis) and structure (cluster analysis, principal component analysis and a variety of structural indices relating to complexity and range of ratings are the main methods used).", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 17], [18, 20], [21, 29], [30, 34], [35, 37], [38, 43], [44, 46], [47, 54], [55, 56], [56, 66], [67, 75], [75, 76], [77, 80], [81, 90], [91, 92], [92, 99], [100, 108], [108, 109], [110, 119], [120, 129], [130, 138], [139, 142], [143, 144], [145, 152], [153, 155], [156, 166], [167, 174], [175, 183], [184, 186], [187, 197], [198, 201], [202, 207], [208, 210], [211, 218], [219, 222], [223, 226], [227, 231], [232, 239], [240, 244], [244, 245], [245, 246]]}
{"doc_key": "ai-test-231", "ner": [[3, 3, "organisation"], [12, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2018", ",", "Toyota", "was", "considered", "lagging", "behind", "in", "the", "field", "of", "self", "-", "driving", "cars", "and", "in", "need", "of", "innovation", "."], "sentence-detokenized": "In 2018, Toyota was considered lagging behind in the field of self-driving cars and in need of innovation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 30], [31, 38], [39, 45], [46, 48], [49, 52], [53, 58], [59, 61], [62, 66], [66, 67], [67, 74], [75, 79], [80, 83], [84, 86], [87, 91], [92, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-test-232", "ner": [[39, 39, "misc"], [41, 42, "misc"], [45, 49, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "targets", "include", "natural", "objects", "such", "as", "land", ",", "sea", ",", "precipitation", "(", "such", "as", "rain", ",", "snow", "or", "hail", ")", ",", "sandstorms", ",", "animals", "(", "especially", "birds", ")", ",", "atmospheric", "turbulence", "and", "other", "atmospheric", "effects", "such", "as", "ionospheric", "reflections", ",", "meteorite", "trails", "and", "the", "three", "-", "body", "scattering", "peak", "."], "sentence-detokenized": "Such targets include natural objects such as land, sea, precipitation (such as rain, snow or hail), sandstorms, animals (especially birds), atmospheric turbulence and other atmospheric effects such as ionospheric reflections, meteorite trails and the three-body scattering peak.", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 28], [29, 36], [37, 41], [42, 44], [45, 49], [49, 50], [51, 54], [54, 55], [56, 69], [70, 71], [71, 75], [76, 78], [79, 83], [83, 84], [85, 89], [90, 92], [93, 97], [97, 98], [98, 99], [100, 110], [110, 111], [112, 119], [120, 121], [121, 131], [132, 137], [137, 138], [138, 139], [140, 151], [152, 162], [163, 166], [167, 172], [173, 184], [185, 192], [193, 197], [198, 200], [201, 212], [213, 224], [224, 225], [226, 235], [236, 242], [243, 246], [247, 250], [251, 256], [256, 257], [257, 261], [262, 272], [273, 277], [277, 278]]}
{"doc_key": "ai-test-233", "ner": [[17, 18, "product"], [37, 38, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "planning", "and", "control", ",", "a", "significant", "difference", "between", "humanoids", "and", "other", "types", "of", "robots", "(", "e.g.", "industrial", "robots", ")", "is", "that", "the", "robot", "'s", "movement", "should", "be", "similar", "to", "human", ",", "using", "leg", "locomotion", ",", "especially", "bipedal", "gait", "."], "sentence-detokenized": "In planning and control, a significant difference between humanoids and other types of robots (e.g. industrial robots) is that the robot's movement should be similar to human, using leg locomotion, especially bipedal gait.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 23], [23, 24], [25, 26], [27, 38], [39, 49], [50, 57], [58, 67], [68, 71], [72, 77], [78, 83], [84, 86], [87, 93], [94, 95], [95, 99], [100, 110], [111, 117], [117, 118], [119, 121], [122, 126], [127, 130], [131, 136], [136, 138], [139, 147], [148, 154], [155, 157], [158, 165], [166, 168], [169, 174], [174, 175], [176, 181], [182, 185], [186, 196], [196, 197], [198, 208], [209, 216], [217, 221], [221, 222]]}
{"doc_key": "ai-test-234", "ner": [[0, 1, "algorithm"], [9, 10, "misc"], [14, 14, "metrics"], [17, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Gradient", "descent", "may", "take", "many", "iterations", "to", "compute", "the", "local", "minimum", "with", "the", "required", "accuracy", "if", "the", "curvature", "in", "different", "directions", "is", "very", "different", "for", "a", "given", "function", "."], "sentence-detokenized": "Gradient descent may take many iterations to compute the local minimum with the required accuracy if the curvature in different directions is very different for a given function.", "token2charspan": [[0, 8], [9, 16], [17, 20], [21, 25], [26, 30], [31, 41], [42, 44], [45, 52], [53, 56], [57, 62], [63, 70], [71, 75], [76, 79], [80, 88], [89, 97], [98, 100], [101, 104], [105, 114], [115, 117], [118, 127], [128, 138], [139, 141], [142, 146], [147, 156], [157, 160], [161, 162], [163, 168], [169, 177], [177, 178]]}
{"doc_key": "ai-test-235", "ner": [[1, 6, "misc"], [10, 16, "misc"], [17, 22, "conference"], [25, 25, "location"], [27, 27, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 6, 10, 16, "part-of", "", true, false], [17, 22, 25, 25, "physical", "", false, true], [25, 25, 27, 27, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "1997", "RoboCup", "2D", "Football", "Simulation", "League", "was", "the", "first", "RoboCup", "competition", "organized", "as", "part", "of", "the", "International", "Joint", "Conference", "on", "Artificial", "Intelligence", "held", "in", "Nagoya", ",", "Japan", ",", "from", "August", "23", "to", "29", ",", "1997", "."], "sentence-detokenized": "The 1997 RoboCup 2D Football Simulation League was the first RoboCup competition organized as part of the International Joint Conference on Artificial Intelligence held in Nagoya, Japan, from August 23 to 29, 1997.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 19], [20, 28], [29, 39], [40, 46], [47, 50], [51, 54], [55, 60], [61, 68], [69, 80], [81, 90], [91, 93], [94, 98], [99, 101], [102, 105], [106, 119], [120, 125], [126, 136], [137, 139], [140, 150], [151, 163], [164, 168], [169, 171], [172, 178], [178, 179], [180, 185], [185, 186], [187, 191], [192, 198], [199, 201], [202, 204], [205, 207], [207, 208], [209, 213], [213, 214]]}
{"doc_key": "ai-test-236", "ner": [[8, 8, "programlang"], [11, 11, "programlang"], [14, 14, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "programming", "options", "include", "the", "built", "-", "in", "Python", "environment", "and", "R", "Console", "with", "Rserve", "support", "."], "sentence-detokenized": "Other programming options include the built-in Python environment and R Console with Rserve support.", "token2charspan": [[0, 5], [6, 17], [18, 25], [26, 33], [34, 37], [38, 43], [43, 44], [44, 46], [47, 53], [54, 65], [66, 69], [70, 71], [72, 79], [80, 84], [85, 91], [92, 99], [99, 100]]}
{"doc_key": "ai-test-237", "ner": [[1, 1, "location"], [12, 13, "field"], [15, 15, "field"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 30, "researcher"], [37, 40, "field"], [43, 44, "field"], [47, 50, "field"], [53, 54, "field"], [57, 60, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[20, 21, 15, 15, "related-to", "contributes_to_field", true, false], [23, 24, 15, 15, "related-to", "contributes_to_field", true, false], [26, 30, 15, 15, "related-to", "contributes_to_field", true, false], [47, 50, 43, 44, "part-of", "", false, false], [53, 54, 47, 50, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["From", "Bonn", ",", "he", "has", "made", "fundamental", "contributions", "to", "the", "development", "of", "artificial", "intelligence", "and", "robotics", "(", "among", "his", "students", "Wolfram", "Burgard", ",", "Dieter", "Fox", ",", "Sebastian", "Thrun", ")", ",", "as", "well", "as", "to", "the", "development", "of", "software", "engineering", ",", "in", "particular", "in", "civil", "engineering", ",", "and", "information", "systems", ",", "in", "particular", "in", "geosciences", ".", "received", "the", "AAAI", "Classic", "Paper", "Award", "2016.2014", "."], "sentence-detokenized": "From Bonn, he has made fundamental contributions to the development of artificial intelligence and robotics (among his students Wolfram Burgard, Dieter Fox, Sebastian Thrun), as well as to the development of software engineering, in particular in civil engineering, and information systems, in particular in geosciences. received the AAAI Classic Paper Award 2016.2014.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 13], [14, 17], [18, 22], [23, 34], [35, 48], [49, 51], [52, 55], [56, 67], [68, 70], [71, 81], [82, 94], [95, 98], [99, 107], [108, 109], [109, 114], [115, 118], [119, 127], [128, 135], [136, 143], [143, 144], [145, 151], [152, 155], [155, 156], [157, 166], [167, 172], [172, 173], [173, 174], [175, 177], [178, 182], [183, 185], [186, 188], [189, 192], [193, 204], [205, 207], [208, 216], [217, 228], [228, 229], [230, 232], [233, 243], [244, 246], [247, 252], [253, 264], [264, 265], [266, 269], [270, 281], [282, 289], [289, 290], [291, 293], [294, 304], [305, 307], [308, 319], [319, 320], [321, 329], [330, 333], [334, 338], [339, 346], [347, 352], [353, 358], [359, 368], [368, 369]]}
{"doc_key": "ai-test-238", "ner": [[2, 6, "conference"], [17, 18, "location"], [20, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 6, 17, 18, "physical", "", false, false], [17, 18, 20, 20, "physical", "", false, false], [20, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "first", "American", "edition", "of", "Campus", "Party", "will", "take", "place", "from", "August", "20", "to", "22", "at", "the", "TCF", "Center", "in", "Detroit", ",", "Michigan", "."], "sentence-detokenized": "The first American edition of Campus Party will take place from August 20 to 22 at the TCF Center in Detroit, Michigan.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 26], [27, 29], [30, 36], [37, 42], [43, 47], [48, 52], [53, 58], [59, 63], [64, 70], [71, 73], [74, 76], [77, 79], [80, 82], [83, 86], [87, 90], [91, 97], [98, 100], [101, 108], [108, 109], [110, 118], [118, 119]]}
{"doc_key": "ai-test-239", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [0, 13, "misc"], [22, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 0, 13, "win-defeat", "", false, false], [5, 6, 0, 13, "win-defeat", "", false, false], [8, 8, 0, 13, "win-defeat", "", false, false], [0, 13, 22, 25, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Together", "with", "Jan", "Lekun", "and", "Joshua", "Bengio", ",", "Hinton", "received", "the", "2018", "Turing", "Prize", "for", "conceptual", "and", "engineering", "breakthroughs", "that", "have", "made", "deep", "neural", "networks", "a", "critical", "component", "of", "computing", "."], "sentence-detokenized": "Together with Jan Lekun and Joshua Bengio, Hinton received the 2018 Turing Prize for conceptual and engineering breakthroughs that have made deep neural networks a critical component of computing.", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 23], [24, 27], [28, 34], [35, 41], [41, 42], [43, 49], [50, 58], [59, 62], [63, 67], [68, 74], [75, 80], [81, 84], [85, 95], [96, 99], [100, 111], [112, 125], [126, 130], [131, 135], [136, 140], [141, 145], [146, 152], [153, 161], [162, 163], [164, 172], [173, 182], [183, 185], [186, 195], [195, 196]]}
{"doc_key": "ai-test-240", "ner": [[0, 2, "product"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 9, 9, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Euler", "Math", "Toolbox", "uses", "a", "matrix", "language", "similar", "to", "MATLAB", ",", "a", "system", "that", "has", "been", "developed", "since", "the", "1970s", "."], "sentence-detokenized": "Euler Math Toolbox uses a matrix language similar to MATLAB, a system that has been developed since the 1970s.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 23], [24, 25], [26, 32], [33, 41], [42, 49], [50, 52], [53, 59], [59, 60], [61, 62], [63, 69], [70, 74], [75, 78], [79, 83], [84, 93], [94, 99], [100, 103], [104, 109], [109, 110]]}
{"doc_key": "ai-test-241", "ner": [[11, 11, "programlang"], [13, 14, "programlang"], [16, 16, "programlang"], [18, 18, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "languages", "make", "this", "possible", "in", "a", "portable", "way", "(", "e.g.", "Scheme", ",", "Common", "Lisp", ",", "Perl", "or", "D", ")", "."], "sentence-detokenized": "Some languages make this possible in a portable way (e.g. Scheme, Common Lisp, Perl or D).", "token2charspan": [[0, 4], [5, 14], [15, 19], [20, 24], [25, 33], [34, 36], [37, 38], [39, 47], [48, 51], [52, 53], [53, 57], [58, 64], [64, 65], [66, 72], [73, 77], [77, 78], [79, 83], [84, 86], [87, 88], [88, 89], [89, 90]]}
{"doc_key": "ai-test-242", "ner": [[8, 8, "misc"], [10, 11, "researcher"], [13, 14, "researcher"], [23, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 10, 11, "artifact", "", false, false], [8, 8, 13, 14, "artifact", "", false, false], [8, 8, 23, 24, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1969", ",", "in", "the", "famous", "book", "\"", "Perceptrons", "\"", "Marvin", "Minsky", "and", "Seymour", "Papert", "showed", "that", "it", "is", "impossible", "to", "learn", "the", "XOR", "function", "for", "these", "classes", "of", "networks", "."], "sentence-detokenized": "In 1969, in the famous book \"Perceptrons\" Marvin Minsky and Seymour Papert showed that it is impossible to learn the XOR function for these classes of networks.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 22], [23, 27], [28, 29], [29, 40], [40, 41], [42, 48], [49, 55], [56, 59], [60, 67], [68, 74], [75, 81], [82, 86], [87, 89], [90, 92], [93, 103], [104, 106], [107, 112], [113, 116], [117, 120], [121, 129], [130, 133], [134, 139], [140, 147], [148, 150], [151, 159], [159, 160]]}
{"doc_key": "ai-test-243", "ner": [[4, 8, "misc"], [12, 12, "product"], [18, 23, "organisation"], [27, 32, "organisation"], [35, 40, "location"], [42, 42, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[18, 23, 12, 12, "usage", "", false, false], [18, 23, 35, 40, "physical", "", false, false], [27, 32, 18, 23, "named", "", false, false], [35, 40, 42, 42, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "large", "number", "of", "Russian", "scientific", "and", "technical", "documents", "were", "translated", "using", "SYSTRAN", "under", "the", "auspices", "of", "the", "U.S.", "Air", "Force", "Foreign", "Technology", "Division", "(", "later", "the", "National", "Air", "and", "Space", "Intelligence", "Center", ")", "at", "Wright", "-", "Patterson", "Air", "Force", "Base", ",", "Ohio", "."], "sentence-detokenized": "A large number of Russian scientific and technical documents were translated using SYSTRAN under the auspices of the U.S. Air Force Foreign Technology Division (later the National Air and Space Intelligence Center) at Wright-Patterson Air Force Base, Ohio.", "token2charspan": [[0, 1], [2, 7], [8, 14], [15, 17], [18, 25], [26, 36], [37, 40], [41, 50], [51, 60], [61, 65], [66, 76], [77, 82], [83, 90], [91, 96], [97, 100], [101, 109], [110, 112], [113, 116], [117, 121], [122, 125], [126, 131], [132, 139], [140, 150], [151, 159], [160, 161], [161, 166], [167, 170], [171, 179], [180, 183], [184, 187], [188, 193], [194, 206], [207, 213], [213, 214], [215, 217], [218, 224], [224, 225], [225, 234], [235, 238], [239, 244], [245, 249], [249, 250], [251, 255], [255, 256]]}
{"doc_key": "ai-test-244", "ner": [[0, 1, "field"], [4, 5, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Semi-supervised", "learning", "is", "between", "unsupervised", "learning", "(", "without", "any", "labeled", "training", "data", ")", "and", "supervised", "learning", "(", "with", "fully", "labeled", "training", "data", ")", "."], "sentence-detokenized": "Semi-supervised learning is between unsupervised learning (without any labeled training data) and supervised learning (with fully labeled training data).", "token2charspan": [[0, 15], [16, 24], [25, 27], [28, 35], [36, 48], [49, 57], [58, 59], [59, 66], [67, 70], [71, 78], [79, 87], [88, 92], [92, 93], [94, 97], [98, 108], [109, 117], [118, 119], [119, 123], [124, 129], [130, 137], [138, 146], [147, 151], [151, 152], [152, 153]]}
{"doc_key": "ai-test-245", "ner": [[0, 5, "algorithm"], [9, 11, "algorithm"], [26, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 5, 9, 11, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "an", "-", "gram", "model", "is", "a", "kind", "of", "probabilistic", "language", "model", "for", "predicting", "the", "next", "element", "in", "such", "a", "sequence", "in", "the", "form", "of", "a", "Markov", "model", "of", "(", "n", "-", "1", ")", "-", "th", "order", ",", "which", "allows", "to", "predict", "the", "next", "element", "efficiently", "."], "sentence-detokenized": "An an-gram model is a kind of probabilistic language model for predicting the next element in such a sequence in the form of a Markov model of (n - 1)-th order, which allows to predict the next element efficiently.", "token2charspan": [[0, 2], [3, 5], [5, 6], [6, 10], [11, 16], [17, 19], [20, 21], [22, 26], [27, 29], [30, 43], [44, 52], [53, 58], [59, 62], [63, 73], [74, 77], [78, 82], [83, 90], [91, 93], [94, 98], [99, 100], [101, 109], [110, 112], [113, 116], [117, 121], [122, 124], [125, 126], [127, 133], [134, 139], [140, 142], [143, 144], [144, 145], [146, 147], [148, 149], [149, 150], [150, 151], [151, 153], [154, 159], [159, 160], [161, 166], [167, 173], [174, 176], [177, 184], [185, 188], [189, 193], [194, 201], [202, 213], [213, 214]]}
{"doc_key": "ai-test-246", "ner": [[0, 2, "organisation"], [4, 4, "product"], [7, 14, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 4, 4, "usage", "", false, false], [7, 14, 0, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Cleveland", "Clinic", "used", "Cyc", "to", "develop", "a", "natural", "language", "query", "interface", "to", "biomedical", "information", "spanning", "decades", "of", "cardiothoracic", "surgery", "information", "."], "sentence-detokenized": "The Cleveland Clinic used Cyc to develop a natural language query interface to biomedical information spanning decades of cardiothoracic surgery information.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 25], [26, 29], [30, 32], [33, 40], [41, 42], [43, 50], [51, 59], [60, 65], [66, 75], [76, 78], [79, 89], [90, 101], [102, 110], [111, 118], [119, 121], [122, 136], [137, 144], [145, 156], [156, 157]]}
{"doc_key": "ai-test-247", "ner": [[6, 6, "country"], [8, 12, "country"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 6, 8, 12, "opposite", "strained_relations", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "incident", "strained", "relations", "between", "the", "US", "and", "Japan", "and", "led", "to", "the", "arrest", "and", "prosecution", "of", "two", "senior", "executives", "of", "the", "company", ",", "as", "well", "as", "the", "imposition", "of", "sanctions", "against", "it", "by", "both", "countries", "."], "sentence-detokenized": "The incident strained relations between the US and Japan and led to the arrest and prosecution of two senior executives of the company, as well as the imposition of sanctions against it by both countries.", "token2charspan": [[0, 3], [4, 12], [13, 21], [22, 31], [32, 39], [40, 43], [44, 46], [47, 50], [51, 56], [57, 60], [61, 64], [65, 67], [68, 71], [72, 78], [79, 82], [83, 94], [95, 97], [98, 101], [102, 108], [109, 119], [120, 122], [123, 126], [127, 134], [134, 135], [136, 138], [139, 143], [144, 146], [147, 150], [151, 161], [162, 164], [165, 174], [175, 182], [183, 185], [186, 188], [189, 193], [194, 203], [203, 204]]}
{"doc_key": "ai-test-248", "ner": [[6, 9, "algorithm"], [12, 15, "field"], [22, 22, "misc"], [35, 35, "misc"], [39, 39, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 9, 12, 15, "type-of", "", false, false], [22, 22, 12, 15, "part-of", "", true, false], [35, 35, 12, 15, "part-of", "", true, false], [39, 39, 12, 15, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["If", "the", "modeling", "is", "done", "using", "an", "artificial", "neural", "network", "or", "other", "machine", "learning", ",", "the", "optimization", "of", "the", "parameters", "is", "called", "training", ",", "while", "the", "optimization", "of", "the", "hyperparameters", "of", "the", "model", "is", "called", "tuning", "and", "often", "uses", "cross-validation", "."], "sentence-detokenized": "If the modeling is done using an artificial neural network or other machine learning, the optimization of the parameters is called training, while the optimization of the hyperparameters of the model is called tuning and often uses cross-validation.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 18], [19, 23], [24, 29], [30, 32], [33, 43], [44, 50], [51, 58], [59, 61], [62, 67], [68, 75], [76, 84], [84, 85], [86, 89], [90, 102], [103, 105], [106, 109], [110, 120], [121, 123], [124, 130], [131, 139], [139, 140], [141, 146], [147, 150], [151, 163], [164, 166], [167, 170], [171, 186], [187, 189], [190, 193], [194, 199], [200, 202], [203, 209], [210, 216], [217, 220], [221, 226], [227, 231], [232, 248], [248, 249]]}
{"doc_key": "ai-test-249", "ner": [[8, 8, "country"], [10, 10, "country"], [12, 12, "country"], [19, 21, "organisation"], [22, 22, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 21, 22, 22, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Localized", "versions", "of", "the", "site", "available", "in", "the", "UK", ",", "India", "and", "Australia", "were", "discontinued", "following", "the", "acquisition", "of", "Rotten", "Tomatoes", "by", "Fandango", "."], "sentence-detokenized": "Localized versions of the site available in the UK, India and Australia were discontinued following the acquisition of Rotten Tomatoes by Fandango.", "token2charspan": [[0, 9], [10, 18], [19, 21], [22, 25], [26, 30], [31, 40], [41, 43], [44, 47], [48, 50], [50, 51], [52, 57], [58, 61], [62, 71], [72, 76], [77, 89], [90, 99], [100, 103], [104, 115], [116, 118], [119, 125], [126, 134], [135, 137], [138, 146], [146, 147]]}
{"doc_key": "ai-test-250", "ner": [[0, 1, "task"], [13, 14, "metrics"], [24, 25, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 13, 14, "related-to", "", false, false], [13, 14, 24, 25, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "NER", "model", "is", "one", "of", "a", "number", "of", "methods", "for", "determining", "the", "accuracy", "of", "subtitles", "in", "live", "television", "broadcasts", "and", "events", "produced", "using", "speech", "recognition", "."], "sentence-detokenized": "The NER model is one of a number of methods for determining the accuracy of subtitles in live television broadcasts and events produced using speech recognition.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 20], [21, 23], [24, 25], [26, 32], [33, 35], [36, 43], [44, 47], [48, 59], [60, 63], [64, 72], [73, 75], [76, 85], [86, 88], [89, 93], [94, 104], [105, 115], [116, 119], [120, 126], [127, 135], [136, 141], [142, 148], [149, 160], [160, 161]]}
{"doc_key": "ai-test-251", "ner": [[0, 0, "researcher"], [5, 7, "university"], [10, 12, "university"], [13, 13, "location"], [19, 19, "university"], [20, 20, "university"], [22, 22, "location"], [25, 30, "university"], [32, 33, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 5, 7, "physical", "", false, false], [0, 0, 5, 7, "role", "", false, false], [0, 0, 10, 12, "physical", "", false, false], [0, 0, 10, 12, "role", "", false, false], [0, 0, 19, 19, "physical", "", false, false], [0, 0, 19, 19, "role", "", false, false], [0, 0, 20, 20, "physical", "", false, false], [0, 0, 20, 20, "role", "", false, false], [0, 0, 25, 30, "physical", "", false, false], [0, 0, 25, 30, "role", "", false, false], [10, 12, 13, 13, "physical", "", false, false], [19, 19, 22, 22, "physical", "", false, false], [20, 20, 22, 22, "physical", "", false, false], [25, 30, 32, 33, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Atran", "has", "taught", "at", "the", "University", "of", "Cambridge", ",", "the", "Hebrew", "University", "of", "Jerusalem", ",", "the", "Ecole", "Normale", "Sup\u00e9rieure", "et", "Polytechnique", "in", "Paris", ",", "and", "John", "Jay", "College", "of", "Criminal", "Justice", "in", "New", "York", "."], "sentence-detokenized": "Atran has taught at the University of Cambridge, the Hebrew University of Jerusalem, the Ecole Normale Sup\u00e9rieure et Polytechnique in Paris, and John Jay College of Criminal Justice in New York.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 23], [24, 34], [35, 37], [38, 47], [47, 48], [49, 52], [53, 59], [60, 70], [71, 73], [74, 83], [83, 84], [85, 88], [89, 94], [95, 102], [103, 113], [114, 116], [117, 130], [131, 133], [134, 139], [139, 140], [141, 144], [145, 149], [150, 153], [154, 161], [162, 164], [165, 173], [174, 181], [182, 184], [185, 188], [189, 193], [193, 194]]}
{"doc_key": "ai-test-252", "ner": [[0, 2, "product"], [7, 9, "task"], [12, 13, "researcher"], [15, 15, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 7, 9, "origin", "", false, false], [0, 2, 7, 9, "related-to", "", false, false], [7, 9, 15, 15, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["SHRDLU", "is", "an", "early", "computer", "program", "for", "natural", "language", "understanding", "developed", "by", "Terry", "Winograd", "at", "MIT", "in", "1968-", "1970"], "sentence-detokenized": "SHRDLU is an early computer program for natural language understanding developed by Terry Winograd at MIT in 1968-1970", "token2charspan": [[0, 6], [7, 9], [10, 12], [13, 18], [19, 27], [28, 35], [36, 39], [40, 47], [48, 56], [57, 70], [71, 80], [81, 83], [84, 89], [90, 98], [99, 101], [102, 105], [106, 108], [109, 114], [114, 118]]}
{"doc_key": "ai-test-253", "ner": [[3, 4, "misc"], [7, 7, "field"], [8, 11, "university"], [13, 13, "location"], [15, 17, "country"], [24, 27, "university"], [28, 28, "misc"], [30, 34, "field"], [37, 38, "university"], [42, 42, "misc"], [43, 46, "field"], [51, 51, "misc"], [55, 59, "university"], [64, 66, "field"], [69, 70, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "relations": [[3, 4, 7, 7, "topic", "", false, false], [3, 4, 8, 11, "origin", "", false, false], [8, 11, 13, 13, "physical", "", false, false], [8, 11, 24, 27, "role", "affiliated_with", false, false], [13, 13, 15, 17, "physical", "", false, false], [28, 28, 30, 34, "topic", "", false, false], [28, 28, 37, 38, "origin", "", false, false], [42, 42, 43, 46, "topic", "", false, false], [51, 51, 55, 59, "origin", "", false, false], [51, 51, 64, 66, "topic", "", false, false], [69, 70, 55, 59, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["He", "received", "his", "Bachelor", "'s", "degree", "in", "Electronics", "Engineering", "from", "B.", "M.S.", "in", "Bangalore", ",", "India", ",", "in", "1982", "when", "he", "was", "affiliated", "to", "Bangalore", "University", ",", "an", "M.S.", "in", "Electrical", "and", "Computer", "Engineering", "in", "1984", "from", "Drexel", "University", ",", "and", "an", "M.S.", "in", "Computer", "Science", "in", "1989", "and", "a", "Ph.D.", "in", "1990", "from", "the", "University", "of", "Wisconsin", "-", "Madison", ",", "where", "he", "studied", "artificial", "intelligence", "and", "worked", "with", "Leonard", "Uhr", "."], "sentence-detokenized": "He received his Bachelor's degree in Electronics Engineering from B. M.S. in Bangalore, India, in 1982 when he was affiliated to Bangalore University, an M.S. in Electrical and Computer Engineering in 1984 from Drexel University, and an M.S. in Computer Science in 1989 and a Ph.D. in 1990 from the University of Wisconsin-Madison, where he studied artificial intelligence and worked with Leonard Uhr.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 24], [24, 26], [27, 33], [34, 36], [37, 48], [49, 60], [61, 65], [66, 68], [69, 73], [74, 76], [77, 86], [86, 87], [88, 93], [93, 94], [95, 97], [98, 102], [103, 107], [108, 110], [111, 114], [115, 125], [126, 128], [129, 138], [139, 149], [149, 150], [151, 153], [154, 158], [159, 161], [162, 172], [173, 176], [177, 185], [186, 197], [198, 200], [201, 205], [206, 210], [211, 217], [218, 228], [228, 229], [230, 233], [234, 236], [237, 241], [242, 244], [245, 253], [254, 261], [262, 264], [265, 269], [270, 273], [274, 275], [276, 281], [282, 284], [285, 289], [290, 294], [295, 298], [299, 309], [310, 312], [313, 322], [322, 323], [323, 330], [330, 331], [332, 337], [338, 340], [341, 348], [349, 359], [360, 372], [373, 376], [377, 383], [384, 388], [389, 396], [397, 400], [400, 401]]}
{"doc_key": "ai-test-254", "ner": [[6, 7, "metrics"], [10, 10, "metrics"], [19, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Accuracy", "is", "usually", "measured", "by", "the", "word", "error", "rate", "(", "WER", ")", ",", "while", "speed", "is", "measured", "by", "the", "real", "-", "time", "rate", "."], "sentence-detokenized": "Accuracy is usually measured by the word error rate (WER), while speed is measured by the real-time rate.", "token2charspan": [[0, 8], [9, 11], [12, 19], [20, 28], [29, 31], [32, 35], [36, 40], [41, 46], [47, 51], [52, 53], [53, 56], [56, 57], [57, 58], [59, 64], [65, 70], [71, 73], [74, 82], [83, 85], [86, 89], [90, 94], [94, 95], [95, 99], [100, 104], [104, 105]]}
{"doc_key": "ai-test-255", "ner": [[3, 4, "researcher"], [8, 10, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 8, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1971", ",", "Terry", "Winograd", "developed", "an", "early", "natural", "language", "processing", "engine", "capable", "of", "interpreting", "naturally", "written", "commands", "in", "a", "simple", "rule", "-", "driven", "environment", "."], "sentence-detokenized": "In 1971, Terry Winograd developed an early natural language processing engine capable of interpreting naturally written commands in a simple rule-driven environment.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 33], [34, 36], [37, 42], [43, 50], [51, 59], [60, 70], [71, 77], [78, 85], [86, 88], [89, 101], [102, 111], [112, 119], [120, 128], [129, 131], [132, 133], [134, 140], [141, 145], [145, 146], [146, 152], [153, 164], [164, 165]]}
{"doc_key": "ai-test-256", "ner": [[16, 17, "field"], [0, 1, "researcher"], [3, 6, "researcher"], [8, 9, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 17, 0, 1, "related-to", "", false, false], [16, 17, 3, 6, "related-to", "", false, false], [16, 17, 8, 9, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Marvin", "Minsky", ",", "Herbert", "A", ".", "Simon", "and", "Allen", "Newell", "are", "prominent", "in", "the", "field", "of", "artificial", "intelligence", "."], "sentence-detokenized": "Marvin Minsky, Herbert A. Simon and Allen Newell are prominent in the field of artificial intelligence.", "token2charspan": [[0, 6], [7, 13], [13, 14], [15, 22], [23, 24], [24, 25], [26, 31], [32, 35], [36, 41], [42, 48], [49, 52], [53, 62], [63, 65], [66, 69], [70, 75], [76, 78], [79, 89], [90, 102], [102, 103]]}
{"doc_key": "ai-test-257", "ner": [[9, 10, "field"], [29, 30, "field"], [32, 33, "field"], [38, 39, "field"], [48, 52, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[29, 30, 9, 10, "origin", "", true, false], [29, 30, 9, 10, "part-of", "", false, false], [29, 30, 38, 39, "compare", "", false, false], [32, 33, 9, 10, "origin", "", true, false], [32, 33, 9, 10, "part-of", "", false, false], [32, 33, 38, 39, "compare", "", false, false], [38, 39, 9, 10, "origin", "", true, false], [38, 39, 9, 10, "part-of", "", false, false], [38, 39, 48, 52, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In", "the", "second", "half", "of", "the", "20th", "century", ",", "electrical", "engineering", "itself", "split", "into", "several", "disciplines", "specializing", "in", "the", "design", "and", "analysis", "of", "systems", "that", "manipulate", "physical", "signals", ";", "electronic", "engineering", "and", "computer", "engineering", "as", "examples", ";", "while", "design", "engineering", "evolved", "to", "deal", "with", "the", "functional", "design", "of", "interfaces", "between", "user", "and", "machine", "."], "sentence-detokenized": "In the second half of the 20th century, electrical engineering itself split into several disciplines specializing in the design and analysis of systems that manipulate physical signals; electronic engineering and computer engineering as examples; while design engineering evolved to deal with the functional design of interfaces between user and machine.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 18], [19, 21], [22, 25], [26, 30], [31, 38], [38, 39], [40, 50], [51, 62], [63, 69], [70, 75], [76, 80], [81, 88], [89, 100], [101, 113], [114, 116], [117, 120], [121, 127], [128, 131], [132, 140], [141, 143], [144, 151], [152, 156], [157, 167], [168, 176], [177, 184], [184, 185], [186, 196], [197, 208], [209, 212], [213, 221], [222, 233], [234, 236], [237, 245], [245, 246], [247, 252], [253, 259], [260, 271], [272, 279], [280, 282], [283, 287], [288, 292], [293, 296], [297, 307], [308, 314], [315, 317], [318, 328], [329, 336], [337, 341], [342, 345], [346, 353], [353, 354]]}
{"doc_key": "ai-test-258", "ner": [[6, 6, "metrics"], [8, 9, "metrics"], [11, 11, "metrics"], [47, 49, "metrics"], [56, 58, "metrics"], [62, 68, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 8, 9, "named", "", false, false], [47, 49, 56, 58, "named", "", false, false], [56, 58, 62, 68, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Perhaps", "the", "simplest", "statistic", "is", "the", "accuracy", "or", "Fraction", "Correct", "(", "FC", ")", ",", "which", "measures", "the", "proportion", "of", "all", "cases", "that", "were", "correctly", "classified", ";", "it", "is", "the", "ratio", "of", "the", "number", "of", "correct", "classifications", "to", "the", "total", "number", "of", "correct", "or", "incorrect", "classifications", ":", "(", "TP", "+", "TN", ")", "/", "Total", "population", "=", "(", "TP", "+", "TN", ")", "/", "(", "TP", "+", "TN", "+", "FP", "+", "FN", ")", "."], "sentence-detokenized": "Perhaps the simplest statistic is the accuracy or Fraction Correct (FC), which measures the proportion of all cases that were correctly classified; it is the ratio of the number of correct classifications to the total number of correct or incorrect classifications: (TP + TN) / Total population = (TP + TN) / (TP + TN + FP + FN).", "token2charspan": [[0, 7], [8, 11], [12, 20], [21, 30], [31, 33], [34, 37], [38, 46], [47, 49], [50, 58], [59, 66], [67, 68], [68, 70], [70, 71], [71, 72], [73, 78], [79, 87], [88, 91], [92, 102], [103, 105], [106, 109], [110, 115], [116, 120], [121, 125], [126, 135], [136, 146], [146, 147], [148, 150], [151, 153], [154, 157], [158, 163], [164, 166], [167, 170], [171, 177], [178, 180], [181, 188], [189, 204], [205, 207], [208, 211], [212, 217], [218, 224], [225, 227], [228, 235], [236, 238], [239, 248], [249, 264], [264, 265], [266, 267], [267, 269], [270, 271], [272, 274], [274, 275], [276, 277], [278, 283], [284, 294], [295, 296], [297, 298], [298, 300], [301, 302], [303, 305], [305, 306], [307, 308], [309, 310], [310, 312], [313, 314], [315, 317], [318, 319], [320, 322], [323, 324], [325, 327], [327, 328], [328, 329]]}
{"doc_key": "ai-test-259", "ner": [[16, 24, "conference"], [26, 28, "conference"], [33, 33, "location"], [30, 38, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 24, 33, 33, "physical", "", false, false], [26, 28, 16, 24, "named", "", false, false], [30, 38, 16, 24, "role", "sponsors", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "academic", "community", ",", "the", "main", "forums", "for", "research", "began", "in", "1995", ",", "when", "the", "First", "International", "Conference", "on", "Data", "Mining", "and", "Knowledge", "Discovery", "(", "KDD", "-", "95", ")", "was", "held", "in", "Montreal", "under", "the", "auspices", "of", "AAAI", "."], "sentence-detokenized": "In the academic community, the main forums for research began in 1995, when the First International Conference on Data Mining and Knowledge Discovery (KDD-95) was held in Montreal under the auspices of AAAI.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 25], [25, 26], [27, 30], [31, 35], [36, 42], [43, 46], [47, 55], [56, 61], [62, 64], [65, 69], [69, 70], [71, 75], [76, 79], [80, 85], [86, 99], [100, 110], [111, 113], [114, 118], [119, 125], [126, 129], [130, 139], [140, 149], [150, 151], [151, 154], [154, 155], [155, 157], [157, 158], [159, 162], [163, 167], [168, 170], [171, 179], [180, 185], [186, 189], [190, 198], [199, 201], [202, 206], [206, 207]]}
{"doc_key": "ai-test-260", "ner": [[11, 12, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "this", "approach", ",", "models", "are", "developed", "using", "various", "algorithms", "of", "data", "mining", ",", "machine", "learning", "to", "predict", "user", "evaluation", "of", "unrated", "products", "."], "sentence-detokenized": "In this approach, models are developed using various algorithms of data mining, machine learning to predict user evaluation of unrated products.", "token2charspan": [[0, 2], [3, 7], [8, 16], [16, 17], [18, 24], [25, 28], [29, 38], [39, 44], [45, 52], [53, 63], [64, 66], [67, 71], [72, 78], [78, 79], [80, 87], [88, 96], [97, 99], [100, 107], [108, 112], [113, 123], [124, 126], [127, 134], [135, 143], [143, 144]]}
{"doc_key": "ai-test-261", "ner": [[11, 11, "algorithm"], [16, 17, "algorithm"], [19, 20, "algorithm"], [26, 28, "misc"], [31, 32, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 11, 16, 17, "related-to", "equivalent", false, false], [16, 17, 19, 20, "usage", "", false, false], [19, 20, 31, 32, "usage", "", false, false], [31, 32, 26, 28, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "light", "of", "the", "above", "discussion", ",", "we", "see", "that", "the", "SVM", "method", "is", "equivalent", "to", "empirical", "risk", "with", "Tikhonov", "regularization", ",", "where", "in", "this", "case", "the", "loss", "function", "is", "the", "loop", "loss"], "sentence-detokenized": "In light of the above discussion, we see that the SVM method is equivalent to empirical risk with Tikhonov regularization, where in this case the loss function is the loop loss", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 15], [16, 21], [22, 32], [32, 33], [34, 36], [37, 40], [41, 45], [46, 49], [50, 53], [54, 60], [61, 63], [64, 74], [75, 77], [78, 87], [88, 92], [93, 97], [98, 106], [107, 121], [121, 122], [123, 128], [129, 131], [132, 136], [137, 141], [142, 145], [146, 150], [151, 159], [160, 162], [163, 166], [167, 171], [172, 176]]}
{"doc_key": "ai-test-262", "ner": [[8, 9, "person"], [15, 16, "person"], [19, 19, "organisation"], [21, 22, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 22, 19, 19, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2015", ",", "the", "program", "was", "hosted", "by", "Molly", "McGrath", ",", "and", "the", "commentators", "were", "Chris", "Rose", "and", "former", "UFC", "fighter", "Kenny", "Florian", "."], "sentence-detokenized": "In 2015, the program was hosted by Molly McGrath, and the commentators were Chris Rose and former UFC fighter Kenny Florian.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 20], [21, 24], [25, 31], [32, 34], [35, 40], [41, 48], [48, 49], [50, 53], [54, 57], [58, 70], [71, 75], [76, 81], [82, 86], [87, 90], [91, 97], [98, 101], [102, 109], [110, 115], [116, 123], [123, 124]]}
{"doc_key": "ai-test-263", "ner": [[3, 5, "product"], [9, 11, "researcher"], [13, 14, "researcher"], [17, 17, "researcher"], [19, 20, "researcher"], [18, 22, "researcher"], [30, 31, "researcher"], [33, 35, "task"], [32, 32, "product"], [38, 40, "researcher"], [43, 44, "task"], [46, 48, "researcher"], [51, 52, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[3, 5, 9, 11, "origin", "", false, false], [3, 5, 13, 14, "origin", "", false, false], [3, 5, 17, 17, "origin", "", false, false], [3, 5, 19, 20, "origin", "", false, false], [13, 14, 38, 40, "named", "same", false, false], [17, 17, 18, 22, "named", "same", false, false], [17, 17, 30, 31, "named", "same", false, false], [33, 35, 32, 32, "related-to", "", false, false], [32, 32, 30, 31, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["A", "subset", "called", "Micro", "-", "Planner", "was", "implemented", "by", "Gerald", "J.", "Sussman", ",", "Eugene", "Czarniak", ",", "and", "Terry", "Winograd", "of", "Sussman", "and", "Winograd", "in", "1971", "and", "has", "been", "used", "in", "Winograd", "'s", "SHRDLU", "natural", "language", "understanding", "program", ",", "Eugene", "Czarniak", "'s", "work", "on", "narrative", "understanding", ",", "Thorne", "McCarthy", "'s", "work", "on", "legal", "reasoning", ",", "and", "several", "other", "projects", "."], "sentence-detokenized": "A subset called Micro-Planner was implemented by Gerald J. Sussman, Eugene Czarniak, and Terry Winograd of Sussman and Winograd in 1971 and has been used in Winograd's SHRDLU natural language understanding program, Eugene Czarniak's work on narrative understanding, Thorne McCarthy's work on legal reasoning, and several other projects.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [21, 22], [22, 29], [30, 33], [34, 45], [46, 48], [49, 55], [56, 58], [59, 66], [66, 67], [68, 74], [75, 83], [83, 84], [85, 88], [89, 94], [95, 103], [104, 106], [107, 114], [115, 118], [119, 127], [128, 130], [131, 135], [136, 139], [140, 143], [144, 148], [149, 153], [154, 156], [157, 165], [165, 167], [168, 174], [175, 182], [183, 191], [192, 205], [206, 213], [213, 214], [215, 221], [222, 230], [230, 232], [233, 237], [238, 240], [241, 250], [251, 264], [264, 265], [266, 272], [273, 281], [281, 283], [284, 288], [289, 291], [292, 297], [298, 307], [307, 308], [309, 312], [313, 320], [321, 326], [327, 335], [335, 336]]}
{"doc_key": "ai-test-264", "ner": [[0, 1, "product"], [5, 8, "product"], [12, 14, "task"], [16, 17, "task"], [19, 21, "task"], [23, 24, "task"], [26, 27, "task"], [30, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[5, 8, 0, 1, "usage", "", true, false], [12, 14, 5, 8, "part-of", "", true, false], [16, 17, 5, 8, "part-of", "", true, false], [19, 21, 5, 8, "part-of", "", true, false], [23, 24, 5, 8, "part-of", "", true, false], [26, 27, 5, 8, "part-of", "", true, false], [30, 32, 5, 8, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Word", "Net", "is", "used", "in", "information", "systems", "for", "various", "purposes", ",", "including", "word", "meaning", "recognition", ",", "information", "retrieval", ",", "automatic", "text", "classification", ",", "automatic", "abstracting", ",", "machine", "translation", "and", "even", "automatic", "crossword", "puzzles", "."], "sentence-detokenized": "WordNet is used in information systems for various purposes, including word meaning recognition, information retrieval, automatic text classification, automatic abstracting, machine translation and even automatic crossword puzzles.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 15], [16, 18], [19, 30], [31, 38], [39, 42], [43, 50], [51, 59], [59, 60], [61, 70], [71, 75], [76, 83], [84, 95], [95, 96], [97, 108], [109, 118], [118, 119], [120, 129], [130, 134], [135, 149], [149, 150], [151, 160], [161, 172], [172, 173], [174, 181], [182, 193], [194, 197], [198, 202], [203, 212], [213, 222], [223, 230], [230, 231]]}
{"doc_key": "ai-test-265", "ner": [[3, 3, "researcher"], [10, 10, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 10, 10, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1996", ",", "Keitzer", "was", "elected", "a", "Fellow", "of", "the", "IEEE", "."], "sentence-detokenized": "In 1996, Keitzer was elected a Fellow of the IEEE.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 20], [21, 28], [29, 30], [31, 37], [38, 40], [41, 44], [45, 49], [49, 50]]}
{"doc_key": "ai-test-266", "ner": [[8, 10, "algorithm"], [55, 56, "misc"], [65, 66, "algorithm"], [68, 69, "algorithm"], [71, 71, "algorithm"], [74, 75, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[65, 66, 55, 56, "type-of", "", false, false], [68, 69, 55, 56, "type-of", "", false, false], [71, 71, 55, 56, "type-of", "", false, false], [74, 75, 55, 56, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "commonly", "used", "type", "of", "composition", "is", "the", "nonlinear", "weighted", "sum", ",", "where", "math", "\\", "textstyle", "f", "(", "x", ")", "=", "K", "\\", "left", "(", "\\", "sum", "_", "i", "w", "_", "i", "g", "_", "i", "(", "x", ")", "\\", "right", ")", "/", "math", ",", "where", "math", "\\", "textstyle", "K", "/", "math", "(", "usually", "called", "the", "activation", "function", ")", "is", "some", "predefined", "function", "such", "as", "a", "hyperbolic", "tangent", ",", "sigmoidal", "function", ",", "softmax", "function", "or", "straightening", "function", "."], "sentence-detokenized": "A commonly used type of composition is the nonlinear weighted sum, where math\\ textstyle f (x) = K\\ left (\\ sum _ i w _ i g _ i (x)\\ right) / math, where math\\ textstyle K / math (usually called the activation function) is some predefined function such as a hyperbolic tangent, sigmoidal function, softmax function or straightening function.", "token2charspan": [[0, 1], [2, 10], [11, 15], [16, 20], [21, 23], [24, 35], [36, 38], [39, 42], [43, 52], [53, 61], [62, 65], [65, 66], [67, 72], [73, 77], [77, 78], [79, 88], [89, 90], [91, 92], [92, 93], [93, 94], [95, 96], [97, 98], [98, 99], [100, 104], [105, 106], [106, 107], [108, 111], [112, 113], [114, 115], [116, 117], [118, 119], [120, 121], [122, 123], [124, 125], [126, 127], [128, 129], [129, 130], [130, 131], [131, 132], [133, 138], [138, 139], [140, 141], [142, 146], [146, 147], [148, 153], [154, 158], [158, 159], [160, 169], [170, 171], [172, 173], [174, 178], [179, 180], [180, 187], [188, 194], [195, 198], [199, 209], [210, 218], [218, 219], [220, 222], [223, 227], [228, 238], [239, 247], [248, 252], [253, 255], [256, 257], [258, 268], [269, 276], [276, 277], [278, 287], [288, 296], [296, 297], [298, 305], [306, 314], [315, 317], [318, 331], [332, 340], [340, 341]]}
{"doc_key": "ai-test-267", "ner": [[4, 4, "misc"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "film", "\"", "Westworld", "\"", ",", "female", "robots", "actually", "had", "sexual", "relations", "with", "human", "men", "in", "a", "fictional", "leisure", "world", ",", "which", "was", "paid", "for", "by", "human", "customers", "."], "sentence-detokenized": "In the film \"Westworld\", female robots actually had sexual relations with human men in a fictional leisure world, which was paid for by human customers.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 13], [13, 22], [22, 23], [23, 24], [25, 31], [32, 38], [39, 47], [48, 51], [52, 58], [59, 68], [69, 73], [74, 79], [80, 83], [84, 86], [87, 88], [89, 98], [99, 106], [107, 112], [112, 113], [114, 119], [120, 123], [124, 128], [129, 132], [133, 135], [136, 141], [142, 151], [151, 152]]}
{"doc_key": "ai-test-268", "ner": [[6, 7, "task"], [21, 26, "task"], [28, 28, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 21, 26, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Typically", ",", "the", "process", "starts", "by", "extracting", "terminology", "and", "concepts", "or", "noun", "phrases", "from", "plain", "text", "using", "linguistic", "processors", "such", "as", "part", "-", "of", "-", "speech", "tagging", "and", "phrase", "splitting", "."], "sentence-detokenized": "Typically, the process starts by extracting terminology and concepts or noun phrases from plain text using linguistic processors such as part-of-speech tagging and phrase splitting.", "token2charspan": [[0, 9], [9, 10], [11, 14], [15, 22], [23, 29], [30, 32], [33, 43], [44, 55], [56, 59], [60, 68], [69, 71], [72, 76], [77, 84], [85, 89], [90, 95], [96, 100], [101, 106], [107, 117], [118, 128], [129, 133], [134, 136], [137, 141], [141, 142], [142, 144], [144, 145], [145, 151], [152, 159], [160, 163], [164, 170], [171, 180], [180, 181]]}
{"doc_key": "ai-test-269", "ner": [[13, 14, "field"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 19, 13, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0], "sentence": ["They", "demonstrated", "its", "performance", "on", "a", "number", "of", "tasks", "of", "interest", "to", "the", "machine", "learning", "community", ",", "including", "handwriting", "recognition", "."], "sentence-detokenized": "They demonstrated its performance on a number of tasks of interest to the machine learning community, including handwriting recognition.", "token2charspan": [[0, 4], [5, 17], [18, 21], [22, 33], [34, 36], [37, 38], [39, 45], [46, 48], [49, 54], [55, 57], [58, 66], [67, 69], [70, 73], [74, 81], [82, 90], [91, 100], [100, 101], [102, 111], [112, 123], [124, 135], [135, 136]]}
{"doc_key": "ai-test-270", "ner": [[3, 3, "university"], [5, 5, "researcher"], [11, 12, "researcher"], [20, 20, "product"], [18, 19, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 5, 3, 3, "physical", "", false, false], [5, 5, 3, 3, "role", "", false, false], [20, 20, 11, 12, "origin", "", false, false], [20, 20, 18, 19, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["While", "studying", "at", "Stanford", ",", "Shainman", "received", "a", "scholarship", "sponsored", "by", "George", "Devol", ",", "inventor", "of", "the", "first", "industrial", "robot", "Unimate", "."], "sentence-detokenized": "While studying at Stanford, Shainman received a scholarship sponsored by George Devol, inventor of the first industrial robot Unimate.", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 26], [26, 27], [28, 36], [37, 45], [46, 47], [48, 59], [60, 69], [70, 72], [73, 79], [80, 85], [85, 86], [87, 95], [96, 98], [99, 102], [103, 108], [109, 119], [120, 125], [126, 133], [133, 134]]}
{"doc_key": "ai-test-271", "ner": [[7, 8, "task"], [11, 14, "metrics"], [16, 16, "metrics"], [25, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 11, 14, "usage", "", true, false], [16, 16, 11, 14, "named", "", false, false], [25, 27, 11, 14, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Although", "it", "was", "originally", "used", "to", "evaluate", "machine", "translation", ",", "the", "Bilingual", "Linguistic", "Evaluation", "Unit", "(", "BLEU", ")", "has", "also", "been", "successfully", "applied", "to", "evaluate", "paraphrase", "generation", "models", "."], "sentence-detokenized": "Although it was originally used to evaluate machine translation, the Bilingual Linguistic Evaluation Unit (BLEU) has also been successfully applied to evaluate paraphrase generation models.", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 26], [27, 31], [32, 34], [35, 43], [44, 51], [52, 63], [63, 64], [65, 68], [69, 78], [79, 89], [90, 100], [101, 105], [106, 107], [107, 111], [111, 112], [113, 116], [117, 121], [122, 126], [127, 139], [140, 147], [148, 150], [151, 159], [160, 170], [171, 181], [182, 188], [188, 189]]}
{"doc_key": "ai-test-272", "ner": [[0, 0, "organisation"], [6, 8, "organisation"], [10, 12, "organisation"], [14, 14, "product"], [16, 16, "country"], [18, 18, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 8, "role", "licenses_to", false, false], [0, 0, 10, 12, "role", "licenses_to", false, false], [6, 8, 16, 16, "physical", "", false, false], [10, 12, 18, 18, "physical", "", false, false], [14, 14, 6, 8, "artifact", "produces", false, false], [14, 14, 10, 12, "artifact", "produces", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Unimation", "later", "licensed", "its", "technology", "to", "Kawasaki", "Heavy", "Industries", "and", "GKN", ",", "which", "manufacture", "Unimates", "in", "Japan", "and", "England", "respectively", "."], "sentence-detokenized": "Unimation later licensed its technology to Kawasaki Heavy Industries and GKN, which manufacture Unimates in Japan and England respectively.", "token2charspan": [[0, 9], [10, 15], [16, 24], [25, 28], [29, 39], [40, 42], [43, 51], [52, 57], [58, 68], [69, 72], [73, 76], [76, 77], [78, 83], [84, 95], [96, 104], [105, 107], [108, 113], [114, 117], [118, 125], [126, 138], [138, 139]]}
{"doc_key": "ai-test-273", "ner": [[19, 20, "conference"], [36, 37, "field"], [55, 59, "field"], [61, 61, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[36, 37, 55, 59, "compare", "", false, false], [61, 61, 55, 59, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Much", "of", "the", "confusion", "between", "these", "two", "research", "communities", "(", "which", "often", "have", "separate", "conferences", "and", "separate", "journals", ",", "ECML", "PKDD", "being", "a", "major", "exception", ")", "stems", "from", "the", "underlying", "assumptions", "they", "work", "with", ":", "in", "machine", "learning", ",", "performance", "is", "typically", "measured", "in", "terms", "of", "the", "ability", "to", "reproduce", "known", "knowledge", ",", "while", "in", "knowledge", "discovery", "and", "data", "mining", "(", "KDD", ")", ",", "the", "key", "objective", "is", "to", "discover", "previously", "unknown", "knowledge", "."], "sentence-detokenized": "Much of the confusion between these two research communities (which often have separate conferences and separate journals, ECML PKDD being a major exception) stems from the underlying assumptions they work with: in machine learning, performance is typically measured in terms of the ability to reproduce known knowledge, while in knowledge discovery and data mining (KDD), the key objective is to discover previously unknown knowledge.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 29], [30, 35], [36, 39], [40, 48], [49, 60], [61, 62], [62, 67], [68, 73], [74, 78], [79, 87], [88, 99], [100, 103], [104, 112], [113, 121], [121, 122], [123, 127], [128, 132], [133, 138], [139, 140], [141, 146], [147, 156], [156, 157], [158, 163], [164, 168], [169, 172], [173, 183], [184, 195], [196, 200], [201, 205], [206, 210], [210, 211], [212, 214], [215, 222], [223, 231], [231, 232], [233, 244], [245, 247], [248, 257], [258, 266], [267, 269], [270, 275], [276, 278], [279, 282], [283, 290], [291, 293], [294, 303], [304, 309], [310, 319], [319, 320], [321, 326], [327, 329], [330, 339], [340, 349], [350, 353], [354, 358], [359, 365], [366, 367], [367, 370], [370, 371], [371, 372], [373, 376], [377, 380], [381, 390], [391, 393], [394, 396], [397, 405], [406, 416], [417, 424], [425, 434], [434, 435]]}
{"doc_key": "ai-test-274", "ner": [[0, 1, "algorithm"], [9, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 9, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Hidden", "Markov", "models", "are", "the", "basis", "of", "most", "modern", "automatic", "speech", "recognition", "systems", "."], "sentence-detokenized": "Hidden Markov models are the basis of most modern automatic speech recognition systems.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 28], [29, 34], [35, 37], [38, 42], [43, 49], [50, 59], [60, 66], [67, 78], [79, 86], [86, 87]]}
{"doc_key": "ai-test-275", "ner": [[0, 2, "location"], [4, 6, "country"], [10, 15, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 4, 6, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["is", "a", "Bangalore", ",", "India", "-", "based", "company", "specializing", "in", "handwriting", "recognition", "software", "for", "the", "Internet", "."], "sentence-detokenized": "is a Bangalore, India-based company specializing in handwriting recognition software for the Internet.", "token2charspan": [[0, 2], [3, 4], [5, 14], [14, 15], [16, 21], [21, 22], [22, 27], [28, 35], [36, 48], [49, 51], [52, 63], [64, 75], [76, 84], [85, 88], [89, 92], [93, 101], [101, 102]]}
{"doc_key": "ai-test-276", "ner": [[24, 25, "misc"], [47, 47, "metrics"], [49, 51, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[47, 47, 49, 51, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Do", "multiple", "translations", "coincide", "to", "the", "same", "expression", "in", "both", "languages", "?", "That", "is", ",", "does", "the", "translation", "method", "demonstrate", "stationarity", "or", "produce", "a", "canonical", "form", "?", "Does", "the", "translation", "become", "stationary", "without", "losing", "the", "original", "meaning", "?", "This", "indicator", "is", "criticized", "for", "being", "poorly", "correlated", "with", "BLEU", "(", "BiLingual", "Evaluation", "Understudy", ")", "scores", "."], "sentence-detokenized": "Do multiple translations coincide to the same expression in both languages? That is, does the translation method demonstrate stationarity or produce a canonical form? Does the translation become stationary without losing the original meaning? This indicator is criticized for being poorly correlated with BLEU (BiLingual Evaluation Understudy) scores.", "token2charspan": [[0, 2], [3, 11], [12, 24], [25, 33], [34, 36], [37, 40], [41, 45], [46, 56], [57, 59], [60, 64], [65, 74], [74, 75], [76, 80], [81, 83], [83, 84], [85, 89], [90, 93], [94, 105], [106, 112], [113, 124], [125, 137], [138, 140], [141, 148], [149, 150], [151, 160], [161, 165], [165, 166], [167, 171], [172, 175], [176, 187], [188, 194], [195, 205], [206, 213], [214, 220], [221, 224], [225, 233], [234, 241], [241, 242], [243, 247], [248, 257], [258, 260], [261, 271], [272, 275], [276, 281], [282, 288], [289, 299], [300, 304], [305, 309], [310, 311], [311, 320], [321, 331], [332, 342], [342, 343], [344, 350], [350, 351]]}
{"doc_key": "ai-test-277", "ner": [[3, 9, "organisation"], [12, 19, "organisation"], [20, 22, "university"], [30, 30, "university"], [27, 29, "field"], [31, 37, "organisation"], [40, 42, "organisation"], [53, 56, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[12, 19, 20, 22, "part-of", "", false, false], [30, 30, 27, 29, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "holds", "fellowships", "from", "the", "American", "Association", "for", "Artificial", "Intelligence", ",", "the", "Center", "for", "the", "Advanced", "Study", "of", "Behavioral", "Sciences", "at", "Stanford", "University", ",", "the", "Center", "for", "Cognitive", "Science", "at", "MIT", ",", "the", "Canadian", "Institute", "for", "Advanced", "Study", ",", "the", "Canadian", "Psychological", "Association", ",", "and", "in", "1998", "was", "elected", "a", "Fellow", "of", "the", "Royal", "Society", "of", "Canada", "."], "sentence-detokenized": "He holds fellowships from the American Association for Artificial Intelligence, the Center for the Advanced Study of Behavioral Sciences at Stanford University, the Center for Cognitive Science at MIT, the Canadian Institute for Advanced Study, the Canadian Psychological Association, and in 1998 was elected a Fellow of the Royal Society of Canada.", "token2charspan": [[0, 2], [3, 8], [9, 20], [21, 25], [26, 29], [30, 38], [39, 50], [51, 54], [55, 65], [66, 78], [78, 79], [80, 83], [84, 90], [91, 94], [95, 98], [99, 107], [108, 113], [114, 116], [117, 127], [128, 136], [137, 139], [140, 148], [149, 159], [159, 160], [161, 164], [165, 171], [172, 175], [176, 185], [186, 193], [194, 196], [197, 200], [200, 201], [202, 205], [206, 214], [215, 224], [225, 228], [229, 237], [238, 243], [243, 244], [245, 248], [249, 257], [258, 271], [272, 283], [283, 284], [285, 288], [289, 291], [292, 296], [297, 300], [301, 308], [309, 310], [311, 317], [318, 320], [321, 324], [325, 330], [331, 338], [339, 341], [342, 348], [348, 349]]}
{"doc_key": "ai-test-278", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [15, 18, "misc"], [21, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 15, 18, "part-of", "", false, false], [0, 0, 21, 24, "part-of", "", false, false], [4, 5, 15, 18, "part-of", "", false, false], [4, 5, 21, 24, "part-of", "", false, false], [7, 8, 15, 18, "part-of", "", false, false], [7, 8, 21, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Hinton", "-", "along", "with", "Joshua", "Bengio", "and", "Jan", "Lekun", "-", "is", "called", "by", "some", "the", "godfathers", "of", "artificial", "intelligence", "and", "the", "godfathers", "of", "deep", "learning", "."], "sentence-detokenized": "Hinton - along with Joshua Bengio and Jan Lekun - is called by some the godfathers of artificial intelligence and the godfathers of deep learning.", "token2charspan": [[0, 6], [7, 8], [9, 14], [15, 19], [20, 26], [27, 33], [34, 37], [38, 41], [42, 47], [48, 49], [50, 52], [53, 59], [60, 62], [63, 67], [68, 71], [72, 82], [83, 85], [86, 96], [97, 109], [110, 113], [114, 117], [118, 128], [129, 131], [132, 136], [137, 145], [145, 146]]}
{"doc_key": "ai-test-279", "ner": [[6, 6, "product"], [19, 19, "misc"], [21, 21, "misc"], [23, 24, "product"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 19, 19, "related-to", "", false, false], [6, 6, 21, 21, "related-to", "", false, false], [19, 19, 23, 24, "named", "same", false, false], [28, 29, 23, 24, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "lightweight", "open", "source", "language", "project", "eSpeak", ",", "which", "has", "its", "own", "approach", "to", "synthesis", ",", "has", "experimented", "with", "Mandarin", "and", "Cantonese", ".", "eSpeak", "has", "been", "used", "by", "Google", "Translate", "since", "May", "2010", "."], "sentence-detokenized": "The lightweight open source language project eSpeak, which has its own approach to synthesis, has experimented with Mandarin and Cantonese. eSpeak has been used by Google Translate since May 2010.", "token2charspan": [[0, 3], [4, 15], [16, 20], [21, 27], [28, 36], [37, 44], [45, 51], [51, 52], [53, 58], [59, 62], [63, 66], [67, 70], [71, 79], [80, 82], [83, 92], [92, 93], [94, 97], [98, 110], [111, 115], [116, 124], [125, 128], [129, 138], [138, 139], [140, 146], [147, 150], [151, 155], [156, 160], [161, 163], [164, 170], [171, 180], [181, 186], [187, 190], [191, 195], [195, 196]]}
{"doc_key": "ai-test-280", "ner": [[5, 7, "product"], [17, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 17, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Also", "released", "in", "1982", ",", "Software", "Automatic", "Mouth", "was", "the", "first", "commercial", "fully", "software", "-", "based", "voice", "synthesis", "program", "."], "sentence-detokenized": "Also released in 1982, Software Automatic Mouth was the first commercial fully software-based voice synthesis program.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 21], [21, 22], [23, 31], [32, 41], [42, 47], [48, 51], [52, 55], [56, 61], [62, 72], [73, 78], [79, 87], [87, 88], [88, 93], [94, 99], [100, 109], [110, 117], [117, 118]]}
{"doc_key": "ai-test-281", "ner": [[7, 9, "metrics"], [13, 17, "metrics"], [19, 19, "metrics"], [23, 28, "metrics"], [33, 36, "metrics"], [38, 42, "metrics"], [43, 49, "metrics"], [53, 55, "metrics"], [58, 58, "metrics"], [63, 63, "metrics"], [73, 73, "metrics"], [69, 72, "metrics"], [82, 85, "metrics"], [87, 87, "metrics"], [91, 96, "metrics"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[13, 17, 7, 9, "named", "", false, false], [19, 19, 7, 9, "named", "", false, false], [23, 28, 7, 9, "named", "", false, false], [38, 42, 33, 36, "named", "", false, false], [43, 49, 33, 36, "named", "", false, false], [58, 58, 53, 55, "named", "", false, false], [63, 63, 53, 55, "named", "", false, false], [73, 73, 53, 55, "named", "", false, false], [69, 72, 53, 55, "named", "", false, false], [87, 87, 82, 85, "named", "", false, false], [91, 96, 82, 85, "named", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["The", "ratios", "in", "the", "columns", "are", "the", "true", "-", "positive", "rate", "(", "TPR", ",", "also", "known", "as", "sensitivity", "or", "recall", ")", "(", "TPR", "/", "(", "TPR", "+", "RR", ")", ")", ",", "with", "the", "false", "-", "negative", "rate", "(", "FNR", ")", "added", "(", "FNR", "/", "(", "TPR", "+", "RR", ")", ")", ";", "and", "the", "true", "-", "negative", "rate", "(", "TNR", ",", "also", "known", "as", "specificity", ",", "SNR", ")", "(", "TNR", "/", "(", "TNR", "+", "SP", ")", ")", ",", "with", "the", "addition", "of", "the", "false", "-", "positive", "rate", "(", "FPR", ")", "(", "FPR", "/", "(", "TNR", "+", "SP", ")", ")", "."], "sentence-detokenized": "The ratios in the columns are the true-positive rate (TPR, also known as sensitivity or recall) (TPR / (TPR + RR)), with the false-negative rate (FNR) added (FNR / (TPR + RR)); and the true-negative rate (TNR, also known as specificity, SNR) (TNR / (TNR + SP)), with the addition of the false-positive rate (FPR) (FPR / (TNR + SP)).", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 17], [18, 25], [26, 29], [30, 33], [34, 38], [38, 39], [39, 47], [48, 52], [53, 54], [54, 57], [57, 58], [59, 63], [64, 69], [70, 72], [73, 84], [85, 87], [88, 94], [94, 95], [96, 97], [97, 100], [101, 102], [103, 104], [104, 107], [108, 109], [110, 112], [112, 113], [113, 114], [114, 115], [116, 120], [121, 124], [125, 130], [130, 131], [131, 139], [140, 144], [145, 146], [146, 149], [149, 150], [151, 156], [157, 158], [158, 161], [162, 163], [164, 165], [165, 168], [169, 170], [171, 173], [173, 174], [174, 175], [175, 176], [177, 180], [181, 184], [185, 189], [189, 190], [190, 198], [199, 203], [204, 205], [205, 208], [208, 209], [210, 214], [215, 220], [221, 223], [224, 235], [235, 236], [237, 240], [240, 241], [242, 243], [243, 246], [247, 248], [249, 250], [250, 253], [254, 255], [256, 258], [258, 259], [259, 260], [260, 261], [262, 266], [267, 270], [271, 279], [280, 282], [283, 286], [287, 292], [292, 293], [293, 301], [302, 306], [307, 308], [308, 311], [311, 312], [313, 314], [314, 317], [318, 319], [320, 321], [321, 324], [325, 326], [327, 329], [329, 330], [330, 331], [331, 332]]}
{"doc_key": "ai-test-282", "ner": [[0, 0, "person"], [2, 3, "person"], [14, 14, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 14, 14, "role", "working_with", false, false], [2, 3, 14, 14, "role", "working_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Edsinger", "and", "Weber", "have", "collaborated", "on", "many", "other", "works", ",", "and", "their", "experience", "with", "Kismet"], "sentence-detokenized": "Edsinger and Weber have collaborated on many other works, and their experience with Kismet", "token2charspan": [[0, 8], [9, 12], [13, 18], [19, 23], [24, 36], [37, 39], [40, 44], [45, 50], [51, 56], [56, 57], [58, 61], [62, 67], [68, 78], [79, 83], [84, 90]]}
{"doc_key": "ai-test-283", "ner": [[0, 3, "programlang"], [10, 10, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 10, 10, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["R", "is", "also", "available", "from", "several", "scripting", "languages", "such", "as", "Python", "."], "sentence-detokenized": "R is also available from several scripting languages such as Python.", "token2charspan": [[0, 1], [2, 4], [5, 9], [10, 19], [20, 24], [25, 32], [33, 42], [43, 52], [53, 57], [58, 60], [61, 67], [67, 68]]}
{"doc_key": "ai-test-284", "ner": [[0, 0, "programlang"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 13, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VAL", "was", "one", "of", "the", "first", "robot", "languages", "and", "was", "used", "in", "Unimate", "robots", "."], "sentence-detokenized": "VAL was one of the first robot languages and was used in Unimate robots.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 18], [19, 24], [25, 30], [31, 40], [41, 44], [45, 48], [49, 53], [54, 56], [57, 64], [65, 71], [71, 72]]}
{"doc_key": "ai-test-285", "ner": [[10, 22, "conference"], [16, 16, "conference"], [20, 21, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 22, 20, 21, "physical", "", false, false], [16, 16, 10, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["They", "first", "presented", "their", "database", "as", "a", "poster", "at", "the", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "conference", "in", "Florida", "in", "2009", "."], "sentence-detokenized": "They first presented their database as a poster at the Computer Vision and Pattern Recognition (CVPR) conference in Florida in 2009.", "token2charspan": [[0, 4], [5, 10], [11, 20], [21, 26], [27, 35], [36, 38], [39, 40], [41, 47], [48, 50], [51, 54], [55, 63], [64, 70], [71, 74], [75, 82], [83, 94], [95, 96], [96, 100], [100, 101], [102, 112], [113, 115], [116, 123], [124, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-test-286", "ner": [[0, 1, "misc"], [6, 7, "task"], [10, 10, "field"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 7, 0, 1, "type-of", "", false, false], [10, 10, 0, 1, "type-of", "", false, false], [12, 13, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Categorization", "tasks", "without", "labels", "are", "called", "unsupervised", "classification", ",", "unsupervised", "learning", ",", "cluster", "analysis", "."], "sentence-detokenized": "Categorization tasks without labels are called unsupervised classification, unsupervised learning, cluster analysis.", "token2charspan": [[0, 14], [15, 20], [21, 28], [29, 35], [36, 39], [40, 46], [47, 59], [60, 74], [74, 75], [76, 88], [89, 97], [97, 98], [99, 106], [107, 115], [115, 116]]}
{"doc_key": "ai-test-287", "ner": [[3, 3, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "should", "recognize", "objects", ",", "recognize", "and", "locate", "a", "person", "and", "further", "recognize", "emotions", "."], "sentence-detokenized": "It should recognize objects, recognize and locate a person and further recognize emotions.", "token2charspan": [[0, 2], [3, 9], [10, 19], [20, 27], [27, 28], [29, 38], [39, 42], [43, 49], [50, 51], [52, 58], [59, 62], [63, 70], [71, 80], [81, 89], [89, 90]]}
{"doc_key": "ai-test-288", "ner": [[6, 6, "misc"], [8, 8, "misc"], [10, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "process", "is", "complex", "and", "involves", "encoding", "and", "recall", "or", "retrieval", "."], "sentence-detokenized": "The process is complex and involves encoding and recall or retrieval.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 26], [27, 35], [36, 44], [45, 48], [49, 55], [56, 58], [59, 68], [68, 69]]}
{"doc_key": "ai-test-289", "ner": [[8, 9, "product"], [12, 17, "product"], [32, 33, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 12, 17, "named", "", false, false], [8, 9, 32, 33, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Also", "known", "as", "parallel", "robots", ",", "or", "generalized", "Stewart", "platforms", "(", "in", "a", "Stewart", "platform", ",", "actuators", "are", "connected", "together", "on", "both", "the", "base", "and", "the", "platform", ")", ",", "these", "systems", "are", "articulated", "robots", "that", "use", "similar", "mechanisms", "to", "move", "either", "the", "robot", "on", "its", "base", "or", "one", "or", "more", "arms", "of", "the", "manipulator", "."], "sentence-detokenized": "Also known as parallel robots, or generalized Stewart platforms (in a Stewart platform, actuators are connected together on both the base and the platform), these systems are articulated robots that use similar mechanisms to move either the robot on its base or one or more arms of the manipulator.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 29], [29, 30], [31, 33], [34, 45], [46, 53], [54, 63], [64, 65], [65, 67], [68, 69], [70, 77], [78, 86], [86, 87], [88, 97], [98, 101], [102, 111], [112, 120], [121, 123], [124, 128], [129, 132], [133, 137], [138, 141], [142, 145], [146, 154], [154, 155], [155, 156], [157, 162], [163, 170], [171, 174], [175, 186], [187, 193], [194, 198], [199, 202], [203, 210], [211, 221], [222, 224], [225, 229], [230, 236], [237, 240], [241, 246], [247, 249], [250, 253], [254, 258], [259, 261], [262, 265], [266, 268], [269, 273], [274, 278], [279, 281], [282, 285], [286, 297], [297, 298]]}
{"doc_key": "ai-test-290", "ner": [[0, 1, "field"], [6, 7, "field"], [13, 18, "field"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 6, 7, "part-of", "subfield", false, false], [0, 1, 13, 18, "compare", "", false, false], [13, 18, 21, 22, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "vision", "as", "a", "discipline", "of", "systems", "engineering", "can", "be", "considered", "separately", "from", "computer", "vision", ",", "which", "is", "a", "kind", "of", "computer", "science", "."], "sentence-detokenized": "Machine vision as a discipline of systems engineering can be considered separately from computer vision, which is a kind of computer science.", "token2charspan": [[0, 7], [8, 14], [15, 17], [18, 19], [20, 30], [31, 33], [34, 41], [42, 53], [54, 57], [58, 60], [61, 71], [72, 82], [83, 87], [88, 96], [97, 103], [103, 104], [105, 110], [111, 113], [114, 115], [116, 120], [121, 123], [124, 132], [133, 140], [140, 141]]}
{"doc_key": "ai-test-291", "ner": [[0, 2, "algorithm"], [8, 10, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 8, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "LSTM", "gate", "activation", "function", "is", "often", "a", "logistic", "sigmoid", "function", "."], "sentence-detokenized": "The LSTM gate activation function is often a logistic sigmoid function.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 24], [25, 33], [34, 36], [37, 42], [43, 44], [45, 53], [54, 61], [62, 70], [70, 71]]}
{"doc_key": "ai-test-292", "ner": [[5, 6, "metrics"], [18, 21, "metrics"], [23, 23, "metrics"], [29, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 18, 21, "named", "", false, false], [5, 6, 29, 31, "named", "", false, false], [23, 23, 18, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "other", "words", ",", "the", "sample", "mean", "is", "the", "(", "necessarily", "only", ")", "efficient", "estimator", "and", "hence", "the", "unbiased", "minimum", "variance", "estimator", "(", "MVUE", ")", "as", "well", "as", "the", "maximum", "likelihood", "estimator", "."], "sentence-detokenized": "In other words, the sample mean is the (necessarily only) efficient estimator and hence the unbiased minimum variance estimator (MVUE) as well as the maximum likelihood estimator.", "token2charspan": [[0, 2], [3, 8], [9, 14], [14, 15], [16, 19], [20, 26], [27, 31], [32, 34], [35, 38], [39, 40], [40, 51], [52, 56], [56, 57], [58, 67], [68, 77], [78, 81], [82, 87], [88, 91], [92, 100], [101, 108], [109, 117], [118, 127], [128, 129], [129, 133], [133, 134], [135, 137], [138, 142], [143, 145], [146, 149], [150, 157], [158, 168], [169, 178], [178, 179]]}
{"doc_key": "ai-test-293", "ner": [[14, 16, "academicjournal"], [3, 5, "researcher"], [7, 8, "researcher"], [10, 13, "researcher"], [25, 25, "product"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 16, 25, 25, "topic", "", false, false], [14, 16, 28, 29, "topic", "", false, false], [3, 5, 14, 16, "role", "", false, false], [7, 8, 14, 16, "role", "", false, false], [10, 13, 14, 16, "role", "", false, false], [25, 25, 28, 29, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["An", "article", "by", "Berners", "-", "Lee", ",", "James", "Handler", "and", "Ora", "Lassila", "published", "in", "Scientific", "American", "in", "2001", "described", "the", "expected", "evolution", "of", "the", "existing", "Internet", "to", "the", "Semantic", "Web", "."], "sentence-detokenized": "An article by Berners-Lee, James Handler and Ora Lassila published in Scientific American in 2001 described the expected evolution of the existing Internet to the Semantic Web.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 21], [21, 22], [22, 25], [25, 26], [27, 32], [33, 40], [41, 44], [45, 48], [49, 56], [57, 66], [67, 69], [70, 80], [81, 89], [90, 92], [93, 97], [98, 107], [108, 111], [112, 120], [121, 130], [131, 133], [134, 137], [138, 146], [147, 155], [156, 158], [159, 162], [163, 171], [172, 175], [175, 176]]}
{"doc_key": "ai-test-294", "ner": [[0, 3, "misc"], [12, 13, "person"], [15, 15, "person"], [28, 29, "person"], [40, 40, "person"], [46, 47, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 13, 0, 3, "role", "actor_in_work", false, false], [15, 15, 12, 13, "named", "", false, false], [15, 15, 12, 13, "origin", "", false, false], [28, 29, 15, 15, "part-of", "", false, false], [46, 47, 15, 15, "role", "auditioned_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Blade", "Runner", "featured", "a", "number", "of", "then", "little", "-", "known", "actors", ":", "Sean", "Young", "portrays", "Rachel", ",", "an", "experimental", "replicant", "who", "has", "been", "implanted", "with", "the", "memories", "of", "Tyrell", "'s", "niece", ",", "leading", "her", "to", "believe", "she", "is", "human", ";", "Sammon", ",", "pp.", "92", "-", "93", "Nina", "Axelrod", "auditioned", "for", "the", "role", "."], "sentence-detokenized": "Blade Runner featured a number of then little-known actors: Sean Young portrays Rachel, an experimental replicant who has been implanted with the memories of Tyrell's niece, leading her to believe she is human; Sammon, pp. 92-93 Nina Axelrod auditioned for the role.", "token2charspan": [[0, 5], [6, 12], [13, 21], [22, 23], [24, 30], [31, 33], [34, 38], [39, 45], [45, 46], [46, 51], [52, 58], [58, 59], [60, 64], [65, 70], [71, 79], [80, 86], [86, 87], [88, 90], [91, 103], [104, 113], [114, 117], [118, 121], [122, 126], [127, 136], [137, 141], [142, 145], [146, 154], [155, 157], [158, 164], [164, 166], [167, 172], [172, 173], [174, 181], [182, 185], [186, 188], [189, 196], [197, 200], [201, 203], [204, 209], [209, 210], [211, 217], [217, 218], [219, 222], [223, 225], [225, 226], [226, 228], [229, 233], [234, 241], [242, 252], [253, 256], [257, 260], [261, 265], [265, 266]]}
{"doc_key": "ai-test-295", "ner": [[0, 1, "researcher"], [3, 4, "researcher"], [6, 7, "researcher"], [10, 11, "researcher"], [14, 15, "university"], [24, 26, "product"], [28, 28, "product"], [16, 43, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 14, 15, "physical", "", false, false], [3, 4, 14, 15, "physical", "", false, false], [6, 7, 14, 15, "physical", "", false, false], [10, 11, 14, 15, "physical", "", false, false], [14, 15, 16, 43, "physical", "", true, false], [24, 26, 14, 15, "temporal", "", false, false], [28, 28, 14, 15, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Jerry", "Sussman", ",", "Eugene", "Czarniak", ",", "Seymour", "Papert", ",", "and", "Terry", "Winograd", "visited", "the", "University", "of", "Edinburgh", "in", "1971", ",", "spreading", "the", "news", "about", "Micro", "-", "Planner", "and", "SHRDLU", "and", "questioning", "the", "single", "resolution", "proof", "approach", "that", "had", "been", "a", "mainstay", "of", "the", "Edinburgh", "Logicians", "."], "sentence-detokenized": "Jerry Sussman, Eugene Czarniak, Seymour Papert, and Terry Winograd visited the University of Edinburgh in 1971, spreading the news about Micro-Planner and SHRDLU and questioning the single resolution proof approach that had been a mainstay of the Edinburgh Logicians.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 21], [22, 30], [30, 31], [32, 39], [40, 46], [46, 47], [48, 51], [52, 57], [58, 66], [67, 74], [75, 78], [79, 89], [90, 92], [93, 102], [103, 105], [106, 110], [110, 111], [112, 121], [122, 125], [126, 130], [131, 136], [137, 142], [142, 143], [143, 150], [151, 154], [155, 161], [162, 165], [166, 177], [178, 181], [182, 188], [189, 199], [200, 205], [206, 214], [215, 219], [220, 223], [224, 228], [229, 230], [231, 239], [240, 242], [243, 246], [247, 256], [257, 266], [266, 267]]}
{"doc_key": "ai-test-296", "ner": [[0, 1, "researcher"], [7, 7, "field"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 11, 12, "role", "inspires", false, false], [0, 1, 14, 15, "role", "inspires", false, false], [0, 1, 17, 18, "role", "inspires", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Walter", "'s", "work", "inspired", "subsequent", "generations", "of", "robotics", "researchers", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "Walter's work inspired subsequent generations of robotics researchers such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 6], [6, 8], [9, 13], [14, 22], [23, 33], [34, 45], [46, 48], [49, 57], [58, 69], [70, 74], [75, 77], [78, 84], [85, 91], [91, 92], [93, 97], [98, 105], [106, 109], [110, 114], [115, 121], [121, 122]]}
{"doc_key": "ai-test-297", "ner": [[7, 7, "algorithm"], [9, 12, "researcher"], [16, 22, "event"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 9, 12, "origin", "", false, false], [7, 7, 16, 22, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Later", ",", "a", "similar", "GPU", "-", "based", "CNN", "by", "Alex", "Kryzewski", "et", "al", ".", "won", "the", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "2012", "."], "sentence-detokenized": "Later, a similar GPU-based CNN by Alex Kryzewski et al. won the ImageNet Large Scale Visual Recognition Challenge 2012.", "token2charspan": [[0, 5], [5, 6], [7, 8], [9, 16], [17, 20], [20, 21], [21, 26], [27, 30], [31, 33], [34, 38], [39, 48], [49, 51], [52, 54], [54, 55], [56, 59], [60, 63], [64, 72], [73, 78], [79, 84], [85, 91], [92, 103], [104, 113], [114, 118], [118, 119]]}
{"doc_key": "ai-test-298", "ner": [[2, 3, "misc"], [8, 9, "metrics"], [11, 12, "metrics"], [17, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 2, 3, "type-of", "", false, false], [11, 12, 2, 3, "type-of", "", false, false], [11, 12, 17, 18, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Commonly", "used", "loss", "functions", "for", "probabilistic", "classification", "include", "wood", "loss", "and", "Brier", "estimation", "between", "the", "predicted", "and", "true", "probability", "distributions", "."], "sentence-detokenized": "Commonly used loss functions for probabilistic classification include wood loss and Brier estimation between the predicted and true probability distributions.", "token2charspan": [[0, 8], [9, 13], [14, 18], [19, 28], [29, 32], [33, 46], [47, 61], [62, 69], [70, 74], [75, 79], [80, 83], [84, 89], [90, 100], [101, 108], [109, 112], [113, 122], [123, 126], [127, 131], [132, 143], [144, 157], [157, 158]]}
{"doc_key": "ai-test-299", "ner": [[3, 3, "organisation"], [11, 11, "field"], [14, 14, "organisation"], [17, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 11, 11, "general-affiliation", "field_of_study", false, false], [3, 3, 17, 18, "part-of", "", false, false], [14, 14, 3, 3, "role", "admits_E2_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "May", "2016", "NtechLab", "was", "admitted", "to", "the", "official", "testing", "of", "biometric", "technologies", "by", "NIST", "among", "three", "Russian", "companies", "."], "sentence-detokenized": "In May 2016 NtechLab was admitted to the official testing of biometric technologies by NIST among three Russian companies.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 20], [21, 24], [25, 33], [34, 36], [37, 40], [41, 49], [50, 57], [58, 60], [61, 70], [71, 83], [84, 86], [87, 91], [92, 97], [98, 103], [104, 111], [112, 121], [121, 122]]}
{"doc_key": "ai-test-300", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "floating", "point", "numbers", "have", "only", "a", "certain", "mathematical", "precision", "."], "sentence-detokenized": "However, floating point numbers have only a certain mathematical precision.", "token2charspan": [[0, 7], [7, 8], [9, 17], [18, 23], [24, 31], [32, 36], [37, 41], [42, 43], [44, 51], [52, 64], [65, 74], [74, 75]]}
{"doc_key": "ai-test-301", "ner": [[4, 6, "organisation"], [10, 15, "conference"], [17, 17, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 10, 15, "role", "contributes_to", false, false], [17, 17, 10, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["During", "2015", ",", "many", "SenseTime", "papers", "were", "accepted", "to", "the", "Computer", "Vision", "and", "Pattern", "Recognition", "Conference", "(", "CVPR", ")", "."], "sentence-detokenized": "During 2015, many SenseTime papers were accepted to the Computer Vision and Pattern Recognition Conference (CVPR).", "token2charspan": [[0, 6], [7, 11], [11, 12], [13, 17], [18, 27], [28, 34], [35, 39], [40, 48], [49, 51], [52, 55], [56, 64], [65, 71], [72, 75], [76, 83], [84, 95], [96, 106], [107, 108], [108, 112], [112, 113], [113, 114]]}
{"doc_key": "ai-test-302", "ner": [[6, 8, "task"], [10, 10, "task"], [13, 14, "task"], [16, 19, "task"], [22, 22, "field"], [24, 26, "misc"], [30, 35, "conference"], [42, 44, "misc"], [46, 50, "conference"], [63, 65, "misc"], [67, 67, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[6, 8, 22, 22, "part-of", "task_part_of_field", false, false], [10, 10, 6, 8, "named", "", false, false], [13, 14, 22, 22, "part-of", "task_part_of_field", false, false], [16, 19, 13, 14, "named", "", false, false], [24, 26, 30, 35, "temporal", "", false, false], [42, 44, 46, 50, "temporal", "", false, false], [63, 65, 67, 67, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["He", "has", "developed", "optimal", "algorithms", "for", "Structure", "From", "Motion", "(", "SFM", ",", "or", "Visual", "SLAM", ",", "simultaneous", "localization", "and", "mapping", ",", "in", "robotics", ";", "best", "paper", "award", "at", "the", "1998", "Computer", "Vision", "and", "Pattern", "Recognition", "Conference", ")", ",", "characterized", "its", "ambiguities", "(", "David", "Marr", "Award", "at", "ICCV", "1999", ")", ",", "and", "characterized", "the", "identification", "and", "observability", "of", "visual", "-", "inertial", "sensor", "fusion", "(", "best", "paper", "award", "at", "Robotics", "2015", ")", "."], "sentence-detokenized": "He has developed optimal algorithms for Structure From Motion (SFM, or Visual SLAM, simultaneous localization and mapping, in robotics; best paper award at the 1998 Computer Vision and Pattern Recognition Conference), characterized its ambiguities (David Marr Award at ICCV 1999), and characterized the identification and observability of visual-inertial sensor fusion (best paper award at Robotics 2015).", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 24], [25, 35], [36, 39], [40, 49], [50, 54], [55, 61], [62, 63], [63, 66], [66, 67], [68, 70], [71, 77], [78, 82], [82, 83], [84, 96], [97, 109], [110, 113], [114, 121], [121, 122], [123, 125], [126, 134], [134, 135], [136, 140], [141, 146], [147, 152], [153, 155], [156, 159], [160, 164], [165, 173], [174, 180], [181, 184], [185, 192], [193, 204], [205, 215], [215, 216], [216, 217], [218, 231], [232, 235], [236, 247], [248, 249], [249, 254], [255, 259], [260, 265], [266, 268], [269, 273], [274, 278], [278, 279], [279, 280], [281, 284], [285, 298], [299, 302], [303, 317], [318, 321], [322, 335], [336, 338], [339, 345], [345, 346], [346, 354], [355, 361], [362, 368], [369, 370], [370, 374], [375, 380], [381, 386], [387, 389], [390, 398], [399, 403], [403, 404], [404, 405]]}
{"doc_key": "ai-test-303", "ner": [[0, 1, "researcher"], [2, 2, "organisation"], [4, 4, "organisation"], [6, 12, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Stephen", "Muggleton", "FBCS", ",", "FIET", ",", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ","], "sentence-detokenized": "Stephen Muggleton FBCS, FIET, Association for the Advancement of Artificial Intelligence,", "token2charspan": [[0, 7], [8, 17], [18, 22], [22, 23], [24, 28], [28, 29], [30, 41], [42, 45], [46, 49], [50, 61], [62, 64], [65, 75], [76, 88], [88, 89]]}
{"doc_key": "ai-test-304", "ner": [[0, 1, "task"], [7, 8, "field"], [10, 10, "field"], [12, 13, "field"], [18, 18, "task"], [17, 20, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 7, 8, "part-of", "task_part_of_field", false, false], [0, 1, 10, 10, "part-of", "task_part_of_field", false, false], [0, 1, 12, 13, "part-of", "task_part_of_field", false, false], [0, 1, 18, 18, "part-of", "", false, false], [0, 1, 17, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Edge", "detection", "is", "a", "fundamental", "tool", "in", "image", "processing", ",", "machine", "and", "computer", "vision", ",", "especially", "in", "object", "detection", "and", "extraction", "."], "sentence-detokenized": "Edge detection is a fundamental tool in image processing, machine and computer vision, especially in object detection and extraction.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 19], [20, 31], [32, 36], [37, 39], [40, 45], [46, 56], [56, 57], [58, 65], [66, 69], [70, 78], [79, 85], [85, 86], [87, 97], [98, 100], [101, 107], [108, 117], [118, 121], [122, 132], [132, 133]]}
{"doc_key": "ai-test-305", "ner": [[10, 11, "misc"], [27, 31, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "example", "of", "this", "is", "a", "variable", "such", "as", "the", "outdoor", "temperature", "(", "mathtemp", "/", "math", ")", ",", "which", "in", "this", "application", "can", "be", "written", "with", "an", "accuracy", "of", "several", "decimal", "places", "(", "depending", "on", "the", "measuring", "device", ")", "."], "sentence-detokenized": "An example of this is a variable such as the outdoor temperature (mathtemp/math), which in this application can be written with an accuracy of several decimal places (depending on the measuring device).", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 18], [19, 21], [22, 23], [24, 32], [33, 37], [38, 40], [41, 44], [45, 52], [53, 64], [65, 66], [66, 74], [74, 75], [75, 79], [79, 80], [80, 81], [82, 87], [88, 90], [91, 95], [96, 107], [108, 111], [112, 114], [115, 122], [123, 127], [128, 130], [131, 139], [140, 142], [143, 150], [151, 158], [159, 165], [166, 167], [167, 176], [177, 179], [180, 183], [184, 193], [194, 200], [200, 201], [201, 202]]}
{"doc_key": "ai-test-306", "ner": [[3, 4, "person"], [6, 7, "person"], [9, 10, "person"], [19, 20, "person"], [22, 22, "misc"], [27, 27, "misc"], [29, 33, "person"], [32, 32, "organisation"], [34, 35, "person"], [37, 37, "organisation"], [39, 43, "person"], [45, 45, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[29, 33, 22, 22, "part-of", "", false, false], [29, 33, 27, 27, "role", "", false, false], [34, 35, 32, 32, "role", "", false, false], [39, 43, 37, 37, "role", "youtuber", false, false], [45, 45, 39, 43, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Returning", "judges", "include", "Von", "Davis", ",", "Jessica", "Chobot", "and", "Leland", "Melvin", ",", "as", "well", "as", "celebrity", "guest", "judges", "actor", "Clark", "Gregg", ",", "Mythbusters", "host", "and", "former", "battle", "robot", "creator", "Adam", "Savage", ",", "NFL", "player", "Vernon", "Davis", "and", "YouTube", "star", "Michael", "Stevens", ",", "known", "as", "\"", "Vsauce", ".", "\""], "sentence-detokenized": "Returning judges include Von Davis, Jessica Chobot and Leland Melvin, as well as celebrity guest judges actor Clark Gregg, Mythbusters host and former battle robot creator Adam Savage, NFL player Vernon Davis and YouTube star Michael Stevens, known as \"Vsauce.\"", "token2charspan": [[0, 9], [10, 16], [17, 24], [25, 28], [29, 34], [34, 35], [36, 43], [44, 50], [51, 54], [55, 61], [62, 68], [68, 69], [70, 72], [73, 77], [78, 80], [81, 90], [91, 96], [97, 103], [104, 109], [110, 115], [116, 121], [121, 122], [123, 134], [135, 139], [140, 143], [144, 150], [151, 157], [158, 163], [164, 171], [172, 176], [177, 183], [183, 184], [185, 188], [189, 195], [196, 202], [203, 208], [209, 212], [213, 220], [221, 225], [226, 233], [234, 241], [241, 242], [243, 248], [249, 251], [252, 253], [253, 259], [259, 260], [260, 261]]}
{"doc_key": "ai-test-307", "ner": [[15, 17, "algorithm"], [19, 21, "algorithm"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 17, 23, 25, "part-of", "", false, false], [19, 21, 23, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["But", "these", "methods", "have", "not", "been", "able", "to", "defeat", "the", "technology", "of", "heterogeneous", "internal", "processing", "Gaussian", "mixture", "model", "/", "Hidden", "Markov", "model", "(", "GMM", "-", "HMM", ")", ",", "based", "on", "generative", "models", "of", "language", "that", "are", "trained", "discriminantly", "."], "sentence-detokenized": "But these methods have not been able to defeat the technology of heterogeneous internal processing Gaussian mixture model / Hidden Markov model (GMM-HMM), based on generative models of language that are trained discriminantly.", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 22], [23, 26], [27, 31], [32, 36], [37, 39], [40, 46], [47, 50], [51, 61], [62, 64], [65, 78], [79, 87], [88, 98], [99, 107], [108, 115], [116, 121], [122, 123], [124, 130], [131, 137], [138, 143], [144, 145], [145, 148], [148, 149], [149, 152], [152, 153], [153, 154], [155, 160], [161, 163], [164, 174], [175, 181], [182, 184], [185, 193], [194, 198], [199, 202], [203, 210], [211, 225], [225, 226]]}
{"doc_key": "ai-test-308", "ner": [[4, 4, "product"], [6, 7, "programlang"], [9, 9, "programlang"], [11, 11, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Software", "packages", "such", "as", "MATLAB", ",", "GNU", "Octave", ",", "Scilab", "and", "SciPy", "provide", "convenient", "ways", "to", "apply", "these", "different", "methods", "."], "sentence-detokenized": "Software packages such as MATLAB, GNU Octave, Scilab and SciPy provide convenient ways to apply these different methods.", "token2charspan": [[0, 8], [9, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 37], [38, 44], [44, 45], [46, 52], [53, 56], [57, 62], [63, 70], [71, 81], [82, 86], [87, 89], [90, 95], [96, 101], [102, 111], [112, 119], [119, 120]]}
{"doc_key": "ai-test-309", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [8, 9, "task"], [16, 17, "researcher"], [19, 20, "university"], [22, 23, "researcher"], [25, 28, "organisation"], [30, 30, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 8, 9, "related-to", "", false, false], [0, 2, 16, 17, "origin", "", false, false], [0, 2, 22, 23, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [16, 17, 19, 20, "physical", "", false, false], [16, 17, 19, 20, "role", "", false, false], [22, 23, 25, 28, "physical", "", false, false], [22, 23, 25, 28, "role", "", false, false], [30, 30, 25, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Linear", "predictive", "coding", "(", "LPC", ")", ",", "a", "speech", "processing", "algorithm", ",", "was", "first", "proposed", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", "."], "sentence-detokenized": "Linear predictive coding (LPC), a speech processing algorithm, was first proposed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [30, 31], [32, 33], [34, 40], [41, 51], [52, 61], [61, 62], [63, 66], [67, 72], [73, 81], [82, 84], [85, 93], [94, 101], [102, 104], [105, 111], [112, 122], [123, 126], [127, 132], [133, 138], [139, 141], [142, 148], [149, 158], [159, 162], [163, 172], [173, 174], [174, 177], [177, 178], [179, 181], [182, 186], [186, 187]]}
{"doc_key": "ai-test-310", "ner": [[20, 27, "conference"], [29, 29, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[29, 29, 20, 27, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2006", ",", "on", "the", "occasion", "of", "the", "25th", "anniversary", "of", "the", "algorithm", ",", "a", "workshop", "was", "organized", "at", "the", "International", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "to", "summarize", "recent", "contributions", "and", "variations", "of", "the", "original", "algorithm", ",", "mainly", "aimed", "at", "improving", "the", "speed", "of", "the", "algorithm", ",", "the", "reliability", "and", "accuracy", "of", "the", "estimated", "solution", ",", "and", "reducing", "the", "dependence", "on", "user", "-", "defined", "constants", "."], "sentence-detokenized": "In 2006, on the occasion of the 25th anniversary of the algorithm, a workshop was organized at the International Conference on Computer Vision and Pattern Recognition (CVPR) to summarize recent contributions and variations of the original algorithm, mainly aimed at improving the speed of the algorithm, the reliability and accuracy of the estimated solution, and reducing the dependence on user-defined constants.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 24], [25, 27], [28, 31], [32, 36], [37, 48], [49, 51], [52, 55], [56, 65], [65, 66], [67, 68], [69, 77], [78, 81], [82, 91], [92, 94], [95, 98], [99, 112], [113, 123], [124, 126], [127, 135], [136, 142], [143, 146], [147, 154], [155, 166], [167, 168], [168, 172], [172, 173], [174, 176], [177, 186], [187, 193], [194, 207], [208, 211], [212, 222], [223, 225], [226, 229], [230, 238], [239, 248], [248, 249], [250, 256], [257, 262], [263, 265], [266, 275], [276, 279], [280, 285], [286, 288], [289, 292], [293, 302], [302, 303], [304, 307], [308, 319], [320, 323], [324, 332], [333, 335], [336, 339], [340, 349], [350, 358], [358, 359], [360, 363], [364, 372], [373, 376], [377, 387], [388, 390], [391, 395], [395, 396], [396, 403], [404, 413], [413, 414]]}
{"doc_key": "ai-test-311", "ner": [[7, 9, "university"], [11, 14, "organisation"], [16, 18, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "members", "of", "the", "group", "visited", "the", "University", "of", "Debrecen", ",", "Hungarian", "Academy", "of", "Sciences", ",", "E\u00f6tv\u00f6s", "Lor\u00e1nd", "University", ",", "etc", "."], "sentence-detokenized": "The members of the group visited the University of Debrecen, Hungarian Academy of Sciences, E\u00f6tv\u00f6s Lor\u00e1nd University, etc.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 18], [19, 24], [25, 32], [33, 36], [37, 47], [48, 50], [51, 59], [59, 60], [61, 70], [71, 78], [79, 81], [82, 90], [90, 91], [92, 98], [99, 105], [106, 116], [116, 117], [118, 121], [121, 122]]}
{"doc_key": "ai-test-312", "ner": [[2, 2, "algorithm"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 16, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["To", "extend", "SVM", "to", "cases", "where", "the", "data", "are", "not", "linearly", "separable", ",", "we", "introduce", "a", "loss", "function", ","], "sentence-detokenized": "To extend SVM to cases where the data are not linearly separable, we introduce a loss function,", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 16], [17, 22], [23, 28], [29, 32], [33, 37], [38, 41], [42, 45], [46, 54], [55, 64], [64, 65], [66, 68], [69, 78], [79, 80], [81, 85], [86, 94], [94, 95]]}
{"doc_key": "ai-test-313", "ner": [[0, 2, "programlang"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 10, 11, "origin", "", false, false], [0, 2, 13, 14, "origin", "", false, false], [0, 2, 16, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Logo", "is", "an", "educational", "programming", "language", "developed", "in", "1967", "by", "Wally", "Fairzeig", ",", "Seymour", "Papert", "and", "Cynthia", "Solomon", "."], "sentence-detokenized": "Logo is an educational programming language developed in 1967 by Wally Fairzeig, Seymour Papert and Cynthia Solomon.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 34], [35, 43], [44, 53], [54, 56], [57, 61], [62, 64], [65, 70], [71, 79], [79, 80], [81, 88], [89, 95], [96, 99], [100, 107], [108, 115], [115, 116]]}
{"doc_key": "ai-test-314", "ner": [[0, 3, "organisation"], [6, 10, "organisation"], [12, 15, "location"], [17, 17, "location"], [19, 21, "location"], [29, 34, "product"], [37, 46, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 6, 10, "role", "works_for", false, false], [6, 10, 12, 15, "physical", "", false, false], [12, 15, 17, 17, "physical", "", false, false], [17, 17, 19, 21, "physical", "", false, false], [29, 34, 0, 3, "origin", "", false, false], [37, 46, 29, 34, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "Eyring", "Research", "Institute", "helped", "the", "U.S.", "Air", "Force", "Missile", "Command", "at", "Hill", "Air", "Force", "Base", "near", "Ogden", ",", "Utah", ",", "develop", ",", "under", "strict", "military", "secrecy", ",", "the", "intelligent", "systems", "software", "that", "became", "the", "basis", "for", "Reagan", "'s", "Star", "Wars", "program", ",", "later", "called", "Star", "Wars", "."], "sentence-detokenized": "The Eyring Research Institute helped the U.S. Air Force Missile Command at Hill Air Force Base near Ogden, Utah, develop, under strict military secrecy, the intelligent systems software that became the basis for Reagan's Star Wars program, later called Star Wars.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 29], [30, 36], [37, 40], [41, 45], [46, 49], [50, 55], [56, 63], [64, 71], [72, 74], [75, 79], [80, 83], [84, 89], [90, 94], [95, 99], [100, 105], [105, 106], [107, 111], [111, 112], [113, 120], [120, 121], [122, 127], [128, 134], [135, 143], [144, 151], [151, 152], [153, 156], [157, 168], [169, 176], [177, 185], [186, 190], [191, 197], [198, 201], [202, 207], [208, 211], [212, 218], [218, 220], [221, 225], [226, 230], [231, 238], [238, 239], [240, 245], [246, 252], [253, 257], [258, 262], [262, 263]]}
{"doc_key": "ai-test-315", "ner": [[10, 15, "field"], [25, 27, "researcher"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "decades", "he", "has", "researched", "and", "developed", "new", "areas", "of", "computer", "science", ",", "starting", "with", "the", "compiler", ",", "programming", "languages", "and", "system", "architecture", "of", "John", "F", ".", "Sowa", "and", "John", "Zachman", "(", "1992", ")", "."], "sentence-detokenized": "For decades he has researched and developed new areas of computer science, starting with the compiler, programming languages and system architecture of John F. Sowa and John Zachman (1992).", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 18], [19, 29], [30, 33], [34, 43], [44, 47], [48, 53], [54, 56], [57, 65], [66, 73], [73, 74], [75, 83], [84, 88], [89, 92], [93, 101], [101, 102], [103, 114], [115, 124], [125, 128], [129, 135], [136, 148], [149, 151], [152, 156], [157, 158], [158, 159], [160, 164], [165, 168], [169, 173], [174, 181], [182, 183], [183, 187], [187, 188], [188, 189]]}
{"doc_key": "ai-test-316", "ner": [[0, 2, "algorithm"], [7, 10, "algorithm"], [12, 13, "algorithm"], [18, 19, "field"], [21, 22, "field"], [26, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 10, 0, 2, "named", "", false, false], [12, 13, 0, 2, "named", "", false, false], [18, 19, 0, 2, "usage", "", false, false], [21, 22, 0, 2, "usage", "", false, false], [26, 28, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Sobel", "operator", ",", "sometimes", "called", "the", "Sobel", "-", "Feldman", "operator", "or", "Sobel", "filter", ",", "is", "used", "in", "image", "processing", "and", "computer", "vision", ",", "particularly", "in", "edge", "detection", "algorithms", "where", "it", "produces", "an", "image", "that", "emphasizes", "edges", "."], "sentence-detokenized": "The Sobel operator, sometimes called the Sobel-Feldman operator or Sobel filter, is used in image processing and computer vision, particularly in edge detection algorithms where it produces an image that emphasizes edges.", "token2charspan": [[0, 3], [4, 9], [10, 18], [18, 19], [20, 29], [30, 36], [37, 40], [41, 46], [46, 47], [47, 54], [55, 63], [64, 66], [67, 72], [73, 79], [79, 80], [81, 83], [84, 88], [89, 91], [92, 97], [98, 108], [109, 112], [113, 121], [122, 128], [128, 129], [130, 142], [143, 145], [146, 150], [151, 160], [161, 171], [172, 177], [178, 180], [181, 189], [190, 192], [193, 198], [199, 203], [204, 214], [215, 220], [220, 221]]}
{"doc_key": "ai-test-317", "ner": [[0, 1, "algorithm"], [3, 4, "field"], [12, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 3, 4, "compare", "", false, false], [0, 1, 3, 4, "type-of", "", false, false], [0, 1, 12, 12, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["LDA", "is", "a", "supervised", "learning", "algorithm", "that", "uses", "data", "labels", ",", "while", "PCA", "is", "a", "learning", "algorithm", "that", "ignores", "labels", "."], "sentence-detokenized": "LDA is a supervised learning algorithm that uses data labels, while PCA is a learning algorithm that ignores labels.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 19], [20, 28], [29, 38], [39, 43], [44, 48], [49, 53], [54, 60], [60, 61], [62, 67], [68, 71], [72, 74], [75, 76], [77, 85], [86, 95], [96, 100], [101, 108], [109, 115], [115, 116]]}
{"doc_key": "ai-test-318", "ner": [[5, 5, "algorithm"], [7, 9, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "linear", "classification", "algorithms", "include", "Winnow", ",", "support", "vector", "machine", "and", "logistic", "regression", "."], "sentence-detokenized": "Other linear classification algorithms include Winnow, support vector machine and logistic regression.", "token2charspan": [[0, 5], [6, 12], [13, 27], [28, 38], [39, 46], [47, 53], [53, 54], [55, 62], [63, 69], [70, 77], [78, 81], [82, 90], [91, 101], [101, 102]]}
{"doc_key": "ai-test-319", "ner": [[0, 0, "product"], [4, 5, "programlang"], [14, 16, "product"], [18, 18, "programlang"], [20, 20, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 4, 5, "general-affiliation", "", true, false], [0, 0, 14, 16, "general-affiliation", "", true, false], [0, 0, 18, 18, "general-affiliation", "", true, false], [0, 0, 20, 20, "general-affiliation", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["VTK", "consists", "of", "a", "C", "++", "class", "library", "and", "several", "interpreted", "interface", "layers", "including", "Tcl", "/", "Tk", ",", "Java", "and", "Python", "."], "sentence-detokenized": "VTK consists of a C++ class library and several interpreted interface layers including Tcl/Tk, Java and Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 17], [18, 19], [19, 21], [22, 27], [28, 35], [36, 39], [40, 47], [48, 59], [60, 69], [70, 76], [77, 86], [87, 90], [90, 91], [91, 93], [93, 94], [95, 99], [100, 103], [104, 110], [110, 111]]}
{"doc_key": "ai-test-320", "ner": [[10, 16, "task"], [22, 24, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", ",", "text", "obtained", "by", "processing", "spontaneous", "speech", "using", "automatic", "speech", "recognition", ",", "as", "well", "as", "printed", "or", "handwritten", "text", "using", "optical", "character", "recognition", "contains", "processing", "noise", "."], "sentence-detokenized": "In addition, text obtained by processing spontaneous speech using automatic speech recognition, as well as printed or handwritten text using optical character recognition contains processing noise.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 17], [18, 26], [27, 29], [30, 40], [41, 52], [53, 59], [60, 65], [66, 75], [76, 82], [83, 94], [94, 95], [96, 98], [99, 103], [104, 106], [107, 114], [115, 117], [118, 129], [130, 134], [135, 140], [141, 148], [149, 158], [159, 170], [171, 179], [180, 190], [191, 196], [196, 197]]}
{"doc_key": "ai-test-321", "ner": [[0, 0, "researcher"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 9, 9, "role", "directs_development_of", false, false]], "relations_mapping_to_source": [0], "sentence": ["Miller", "wrote", "several", "books", "and", "led", "the", "development", "of", "WordNet", ",", "an", "online", "database", "of", "word", "relationships", "used", "by", "computer", "programs", "."], "sentence-detokenized": "Miller wrote several books and led the development of WordNet, an online database of word relationships used by computer programs.", "token2charspan": [[0, 6], [7, 12], [13, 20], [21, 26], [27, 30], [31, 34], [35, 38], [39, 50], [51, 53], [54, 61], [61, 62], [63, 65], [66, 72], [73, 81], [82, 84], [85, 89], [90, 103], [104, 108], [109, 111], [112, 120], [121, 129], [129, 130]]}
{"doc_key": "ai-test-322", "ner": [[1, 1, "field"], [5, 7, "organisation"], [10, 10, "country"], [12, 13, "person"], [15, 17, "person"], [19, 20, "person"], [22, 23, "person"], [26, 26, "country"], [28, 31, "location"], [32, 34, "misc"], [35, 36, "person"], [38, 39, "person"], [41, 41, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[5, 7, 10, 10, "physical", "", false, false], [12, 13, 26, 26, "physical", "", false, false], [15, 17, 26, 26, "physical", "", false, false], [19, 20, 26, 26, "physical", "", false, false], [22, 23, 26, 26, "physical", "", false, false], [28, 31, 1, 1, "general-affiliation", "", false, false], [28, 31, 35, 36, "artifact", "", false, false], [32, 34, 35, 36, "named", "", false, false], [38, 39, 41, 41, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Modern", "automata", "are", "represented", "by", "Cabaret", "Mechanical", "Theatre", "in", "the", "UK", ",", "Dug", "North", "and", "Chomick", "+", "Meder", ",", "Arthur", "Ganson", ",", "Joe", "Jones", "in", "the", "USA", ",", "Le", "D\u00e9fenseur", "du", "Temps", "by", "French", "artist", "Jacques", "Monestier", "and", "Fran\u00e7ois", "Junod", "in", "Switzerland", "."], "sentence-detokenized": "Modern automata are represented by Cabaret Mechanical Theatre in the UK, Dug North and Chomick + Meder, Arthur Ganson, Joe Jones in the USA, Le D\u00e9fenseur du Temps by French artist Jacques Monestier and Fran\u00e7ois Junod in Switzerland.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 31], [32, 34], [35, 42], [43, 53], [54, 61], [62, 64], [65, 68], [69, 71], [71, 72], [73, 76], [77, 82], [83, 86], [87, 94], [95, 96], [97, 102], [102, 103], [104, 110], [111, 117], [117, 118], [119, 122], [123, 128], [129, 131], [132, 135], [136, 139], [139, 140], [141, 143], [144, 153], [154, 156], [157, 162], [163, 165], [166, 172], [173, 179], [180, 187], [188, 197], [198, 201], [202, 210], [211, 216], [217, 219], [220, 231], [231, 232]]}
{"doc_key": "ai-test-323", "ner": [[0, 0, "product"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 21, 21, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MATLAB", "includes", "standard", "codefor", "/", "code", "and", "codewhile", "/", "code", "loops", ",", "but", "(", "as", "in", "other", "similar", "programs", "such", "as", "R", ")", ",", "the", "use", "of", "vector", "notation", "is", "encouraged", "and", "often", "faster", "to", "execute", "."], "sentence-detokenized": "MATLAB includes standard codefor/code and codewhile/code loops, but (as in other similar programs such as R), the use of vector notation is encouraged and often faster to execute.", "token2charspan": [[0, 6], [7, 15], [16, 24], [25, 32], [32, 33], [33, 37], [38, 41], [42, 51], [51, 52], [52, 56], [57, 62], [62, 63], [64, 67], [68, 69], [69, 71], [72, 74], [75, 80], [81, 88], [89, 97], [98, 102], [103, 105], [106, 107], [107, 108], [108, 109], [110, 113], [114, 117], [118, 120], [121, 127], [128, 136], [137, 139], [140, 150], [151, 154], [155, 160], [161, 167], [168, 170], [171, 178], [178, 179]]}
{"doc_key": "ai-test-324", "ner": [[3, 3, "researcher"], [9, 12, "conference"], [17, 18, "field"], [21, 27, "misc"], [31, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 21, 27, "win-defeat", "", false, false], [3, 3, 31, 39, "win-defeat", "", false, false], [21, 27, 9, 12, "temporal", "", false, false], [21, 27, 17, 18, "topic", "", false, false], [31, 39, 9, 12, "temporal", "", false, false], [31, 39, 17, 18, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2007", ",", "Pausch", "received", "two", "awards", "from", "the", "Association", "for", "Computing", "Machinery", "for", "his", "achievements", "in", "computer", "education", ":", "the", "Karl", "V", ".", "Karlstrom", "Outstanding", "Educator", "Award", "and", "the", "ACM", "SIGCSE", "Award", "for", "outstanding", "contributions", "to", "computer", "science", "education", "."], "sentence-detokenized": "In 2007, Pausch received two awards from the Association for Computing Machinery for his achievements in computer education: the Karl V. Karlstrom Outstanding Educator Award and the ACM SIGCSE Award for outstanding contributions to computer science education.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 24], [25, 28], [29, 35], [36, 40], [41, 44], [45, 56], [57, 60], [61, 70], [71, 80], [81, 84], [85, 88], [89, 101], [102, 104], [105, 113], [114, 123], [123, 124], [125, 128], [129, 133], [134, 135], [135, 136], [137, 146], [147, 158], [159, 167], [168, 173], [174, 177], [178, 181], [182, 185], [186, 192], [193, 198], [199, 202], [203, 214], [215, 228], [229, 231], [232, 240], [241, 248], [249, 258], [258, 259]]}
{"doc_key": "ai-test-325", "ner": [[3, 3, "person"], [8, 8, "product"], [9, 9, "product"], [15, 16, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 8, 8, "role", "sells", false, false], [8, 8, 9, 9, "general-affiliation", "", false, false], [8, 8, 15, 16, "physical", "shipped_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "shipped", "to", "General", "Motors", "in", "1961", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was shipped to General Motors in 1961.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 73], [74, 76], [77, 84], [85, 91], [92, 94], [95, 99], [99, 100]]}
{"doc_key": "ai-test-326", "ner": [[0, 2, "algorithm"], [5, 7, "field"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 0, 2, "usage", "", false, false], [11, 12, 5, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Semantic", "networks", "are", "used", "in", "natural", "language", "processing", "applications", "such", "as", "semantic", "parsing", "."], "sentence-detokenized": "Semantic networks are used in natural language processing applications such as semantic parsing.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 26], [27, 29], [30, 37], [38, 46], [47, 57], [58, 70], [71, 75], [76, 78], [79, 87], [88, 95], [95, 96]]}
{"doc_key": "ai-test-327", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 12, "task"], [14, 15, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"], [23, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[8, 9, 5, 6, "usage", "", false, false], [11, 12, 5, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Among", "the", "successful", "applications", "of", "deep", "learning", "are", "computer", "vision", "and", "speech", "recognition", ".", "Hongluck", "Lee", ",", "Roger", "Gross", ",", "Rajesh", "Ranganath", ",", "Andrew", "Y", ".", "Ng", "."], "sentence-detokenized": "Among the successful applications of deep learning are computer vision and speech recognition. Hongluck Lee, Roger Gross, Rajesh Ranganath, Andrew Y. Ng.", "token2charspan": [[0, 5], [6, 9], [10, 20], [21, 33], [34, 36], [37, 41], [42, 50], [51, 54], [55, 63], [64, 70], [71, 74], [75, 81], [82, 93], [93, 94], [95, 103], [104, 107], [107, 108], [109, 114], [115, 120], [120, 121], [122, 128], [129, 138], [138, 139], [140, 146], [147, 148], [148, 149], [150, 152], [152, 153]]}
{"doc_key": "ai-test-328", "ner": [[4, 9, "product"], [15, 15, "misc"], [18, 20, "misc"], [24, 24, "product"], [28, 29, "task"], [32, 32, "task"], [34, 35, "task"], [31, 39, "field"], [41, 42, "task"], [44, 45, "field"], [47, 48, "task"], [50, 51, "task"], [53, 54, "task"], [57, 57, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 9, 15, 15, "physical", "travels_to", false, false], [4, 9, 18, 20, "physical", "travels_to", false, false], [24, 24, 4, 9, "part-of", "", false, false], [24, 24, 4, 9, "role", "maintains", false, false], [24, 24, 28, 29, "related-to", "has_ability_to", false, false], [24, 24, 32, 32, "related-to", "has_ability_to", false, false], [24, 24, 34, 35, "related-to", "has_ability_to", false, false], [24, 24, 31, 39, "related-to", "has_ability_to", false, false], [24, 24, 41, 42, "related-to", "has_ability_to", false, false], [24, 24, 44, 45, "related-to", "has_ability_to", false, false], [24, 24, 47, 48, "related-to", "has_ability_to", false, false], [24, 24, 50, 51, "related-to", "has_ability_to", false, false], [24, 24, 53, 54, "related-to", "has_ability_to", false, false], [24, 24, 57, 57, "related-to", "has_ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["In", "addition", "to", "servicing", "the", "Discovery", "One", "spacecraft", "'s", "systems", "during", "its", "interplanetary", "mission", "to", "Jupiter", "(", "or", "Saturn", "in", "the", "novel", ")", ",", "HAL", "is", "capable", "of", "speech", "synthesis", ",", "speech", "recognition", ",", "facial", "recognition", ",", "natural", "language", "processing", ",", "lip", "reading", ",", "art", "appreciation", ",", "affective", "computing", ",", "automated", "reasoning", ",", "spacecraft", "piloting", ",", "and", "chess", "."], "sentence-detokenized": "In addition to servicing the Discovery One spacecraft's systems during its interplanetary mission to Jupiter (or Saturn in the novel), HAL is capable of speech synthesis, speech recognition, facial recognition, natural language processing, lip reading, art appreciation, affective computing, automated reasoning, spacecraft piloting, and chess.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 24], [25, 28], [29, 38], [39, 42], [43, 53], [53, 55], [56, 63], [64, 70], [71, 74], [75, 89], [90, 97], [98, 100], [101, 108], [109, 110], [110, 112], [113, 119], [120, 122], [123, 126], [127, 132], [132, 133], [133, 134], [135, 138], [139, 141], [142, 149], [150, 152], [153, 159], [160, 169], [169, 170], [171, 177], [178, 189], [189, 190], [191, 197], [198, 209], [209, 210], [211, 218], [219, 227], [228, 238], [238, 239], [240, 243], [244, 251], [251, 252], [253, 256], [257, 269], [269, 270], [271, 280], [281, 290], [290, 291], [292, 301], [302, 311], [311, 312], [313, 323], [324, 332], [332, 333], [334, 337], [338, 343], [343, 344]]}
{"doc_key": "ai-test-329", "ner": [[0, 1, "researcher"], [4, 4, "country"], [7, 8, "country"], [11, 11, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 4, "physical", "", false, false], [0, 1, 7, 8, "physical", "", false, false], [0, 1, 11, 11, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dr.", "Julisch", "emigrated", "from", "Hungary", "to", "the", "United", "States", "after", "the", "Soviet", "invasion", "of", "1956", "."], "sentence-detokenized": "Dr. Julisch emigrated from Hungary to the United States after the Soviet invasion of 1956.", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 26], [27, 34], [35, 37], [38, 41], [42, 48], [49, 55], [56, 61], [62, 65], [66, 72], [73, 81], [82, 84], [85, 89], [89, 90]]}
{"doc_key": "ai-test-330", "ner": [[0, 2, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sigmoid", "activation", "functions", "use", "the", "second", "nonlinearity", "for", "large", "inputs", ":", "math", "\\", "phi", "(", "v", "_", "i", ")", "=", "(", "1", "+\\", "exp", "(", "-", "v", "_", "i", ")", ")", "^", "{", "-1", "}", "/", "math", "."], "sentence-detokenized": "Sigmoid activation functions use the second nonlinearity for large inputs: math\\ phi (v _ i) = (1 +\\ exp (-v _ i)) ^ {-1} / math.", "token2charspan": [[0, 7], [8, 18], [19, 28], [29, 32], [33, 36], [37, 43], [44, 56], [57, 60], [61, 66], [67, 73], [73, 74], [75, 79], [79, 80], [81, 84], [85, 86], [86, 87], [88, 89], [90, 91], [91, 92], [93, 94], [95, 96], [96, 97], [98, 100], [101, 104], [105, 106], [106, 107], [107, 108], [109, 110], [111, 112], [112, 113], [113, 114], [115, 116], [117, 118], [118, 120], [120, 121], [122, 123], [124, 128], [128, 129]]}
{"doc_key": "ai-test-331", "ner": [[12, 14, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "probabilities", "are", "used", "to", "determine", "what", "the", "target", "is", "using", "the", "maximum", "likelihood", "solution", "."], "sentence-detokenized": "These probabilities are used to determine what the target is using the maximum likelihood solution.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 28], [29, 31], [32, 41], [42, 46], [47, 50], [51, 57], [58, 60], [61, 66], [67, 70], [71, 78], [79, 89], [90, 98], [98, 99]]}
{"doc_key": "ai-test-332", "ner": [[6, 8, "university"], [16, 18, "university"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1984", "he", "moved", "to", "the", "University", "of", "Konstanz", ",", "and", "in", "1990", "-", "to", "the", "University", "of", "Salzburg", "."], "sentence-detokenized": "In 1984 he moved to the University of Konstanz, and in 1990 - to the University of Salzburg.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 16], [17, 19], [20, 23], [24, 34], [35, 37], [38, 46], [46, 47], [48, 51], [52, 54], [55, 59], [60, 61], [62, 64], [65, 68], [69, 79], [80, 82], [83, 91], [91, 92]]}
{"doc_key": "ai-test-333", "ner": [[7, 8, "metrics"], [10, 12, "metrics"], [14, 16, "metrics"], [18, 18, "metrics"], [20, 22, "metrics"], [24, 27, "metrics"], [31, 34, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 12, 7, 8, "origin", "based_on", false, false], [14, 16, 7, 8, "origin", "based_on", false, false], [18, 18, 7, 8, "origin", "based_on", false, false], [20, 22, 7, 8, "origin", "based_on", false, false], [24, 27, 7, 8, "origin", "based_on", false, false], [31, 34, 7, 8, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Some", "popular", "fitness", "functions", "based", "on", "the", "confusion", "matrix", "include", "sensitivity", "/", "specificity", ",", "recall", "/", "precision", ",", "F-measure", ",", "Jaccard", "'s", "similarity", ",", "Matthews", "'", "correlation", "coefficient", ",", "and", "a", "cost", "/", "benefit", "matrix", "that", "combines", "the", "costs", "and", "benefits", "associated", "with", "4", "different", "types", "of", "classifications", "."], "sentence-detokenized": "Some popular fitness functions based on the confusion matrix include sensitivity/specificity, recall/precision, F-measure, Jaccard's similarity, Matthews' correlation coefficient, and a cost/benefit matrix that combines the costs and benefits associated with 4 different types of classifications.", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 30], [31, 36], [37, 39], [40, 43], [44, 53], [54, 60], [61, 68], [69, 80], [80, 81], [81, 92], [92, 93], [94, 100], [100, 101], [101, 110], [110, 111], [112, 121], [121, 122], [123, 130], [130, 132], [133, 143], [143, 144], [145, 153], [153, 154], [155, 166], [167, 178], [178, 179], [180, 183], [184, 185], [186, 190], [190, 191], [191, 198], [199, 205], [206, 210], [211, 219], [220, 223], [224, 229], [230, 233], [234, 242], [243, 253], [254, 258], [259, 260], [261, 270], [271, 276], [277, 279], [280, 295], [295, 296]]}
{"doc_key": "ai-test-334", "ner": [[6, 6, "product"], [8, 8, "product"], [10, 10, "product"], [12, 12, "product"], [16, 17, "programlang"], [29, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[29, 31, 6, 6, "part-of", "", false, false], [29, 31, 8, 8, "part-of", "", false, false], [29, 31, 10, 10, "part-of", "", false, false], [29, 31, 12, 12, "part-of", "", false, false], [29, 31, 16, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Common", "numerical", "programming", "environments", "such", "as", "MATLAB", ",", "SciLab", ",", "NumPy", ",", "Sklearn", ",", "and", "the", "R", "language", "provide", "some", "of", "the", "simplest", "feature", "extraction", "methods", "(", "e.g.", ",", "principal", "component", "analysis", ")", "with", "built", "-", "in", "commands", "."], "sentence-detokenized": "Common numerical programming environments such as MATLAB, SciLab, NumPy, Sklearn, and the R language provide some of the simplest feature extraction methods (e.g., principal component analysis) with built-in commands.", "token2charspan": [[0, 6], [7, 16], [17, 28], [29, 41], [42, 46], [47, 49], [50, 56], [56, 57], [58, 64], [64, 65], [66, 71], [71, 72], [73, 80], [80, 81], [82, 85], [86, 89], [90, 91], [92, 100], [101, 108], [109, 113], [114, 116], [117, 120], [121, 129], [130, 137], [138, 148], [149, 156], [157, 158], [158, 162], [162, 163], [164, 173], [174, 183], [184, 192], [192, 193], [194, 198], [199, 204], [204, 205], [205, 207], [208, 216], [216, 217]]}
{"doc_key": "ai-test-335", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Industrial", "robots", "were", "introduced", "to", "collaborate", "with", "humans", "to", "perform", "industrial", "production", "tasks", "."], "sentence-detokenized": "Industrial robots were introduced to collaborate with humans to perform industrial production tasks.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 33], [34, 36], [37, 48], [49, 53], [54, 60], [61, 63], [64, 71], [72, 82], [83, 93], [94, 99], [99, 100]]}
{"doc_key": "ai-test-336", "ner": [[6, 6, "field"], [8, 11, "researcher"], [21, 22, "field"], [24, 25, "field"], [28, 29, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 21, 22, "related-to", "", false, false], [6, 6, 24, 25, "related-to", "", false, false], [6, 6, 28, 29, "related-to", "", false, false], [8, 11, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "the", "first", "published", "article", "on", "AI", ",", "John", "F", ".", "Sova", "applied", "them", "to", "a", "wide", "range", "of", "topics", "in", "artificial", "intelligence", ",", "computer", "science", ",", "and", "cognitive", "science", "."], "sentence-detokenized": "In the first published article on AI, John F. Sova applied them to a wide range of topics in artificial intelligence, computer science, and cognitive science.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 22], [23, 30], [31, 33], [34, 36], [36, 37], [38, 42], [43, 44], [44, 45], [46, 50], [51, 58], [59, 63], [64, 66], [67, 68], [69, 73], [74, 79], [80, 82], [83, 89], [90, 92], [93, 103], [104, 116], [116, 117], [118, 126], [127, 134], [134, 135], [136, 139], [140, 149], [150, 157], [157, 158]]}
{"doc_key": "ai-test-337", "ner": [[0, 0, "metrics"], [4, 4, "metrics"], [10, 11, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 4, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "BLEU", "in", "its", "calculation", "of", "the", "brevity", "penalty", ",", "as", "small", "deviations", "in", "translation", "scope", "do", "not", "affect", "the", "overall", "score", "as", "much", "."], "sentence-detokenized": "NIST also differs from BLEU in its calculation of the brevity penalty, as small deviations in translation scope do not affect the overall score as much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 27], [28, 30], [31, 34], [35, 46], [47, 49], [50, 53], [54, 61], [62, 69], [69, 70], [71, 73], [74, 79], [80, 90], [91, 93], [94, 105], [106, 111], [112, 114], [115, 118], [119, 125], [126, 129], [130, 137], [138, 143], [144, 146], [147, 151], [151, 152]]}
{"doc_key": "ai-test-338", "ner": [[0, 7, "misc"], [15, 15, "conference"], [23, 25, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 7, 15, 15, "temporal", "", false, false], [0, 7, 23, 25, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "IJCAI", "Award", "for", "Research", "Excellence", "is", "an", "award", "given", "twice", "a", "year", "at", "the", "IJCAI", "conference", "to", "researchers", "in", "the", "field", "of", "artificial", "intelligence", "in", "recognition", "of", "excellence", "in", "their", "careers", "."], "sentence-detokenized": "The IJCAI Award for Research Excellence is an award given twice a year at the IJCAI conference to researchers in the field of artificial intelligence in recognition of excellence in their careers.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 19], [20, 28], [29, 39], [40, 42], [43, 45], [46, 51], [52, 57], [58, 63], [64, 65], [66, 70], [71, 73], [74, 77], [78, 83], [84, 94], [95, 97], [98, 109], [110, 112], [113, 116], [117, 122], [123, 125], [126, 136], [137, 149], [150, 152], [153, 164], [165, 167], [168, 178], [179, 181], [182, 187], [188, 195], [195, 196]]}
{"doc_key": "ai-test-339", "ner": [[0, 0, "researcher"], [6, 6, "conference"], [17, 24, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 6, 6, "role", "", false, false], [0, 0, 17, 24, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lenat", "was", "one", "of", "the", "first", "AAAI", "Fellows", ",", "and", "is", "the", "only", "person", "to", "serve", "on", "the", "Scientific", "Advisory", "Boards", "of", "Microsoft", "and", "Apple", "."], "sentence-detokenized": "Lenat was one of the first AAAI Fellows, and is the only person to serve on the Scientific Advisory Boards of Microsoft and Apple.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 16], [17, 20], [21, 26], [27, 31], [32, 39], [39, 40], [41, 44], [45, 47], [48, 51], [52, 56], [57, 63], [64, 66], [67, 72], [73, 75], [76, 79], [80, 90], [91, 99], [100, 106], [107, 109], [110, 119], [120, 123], [124, 129], [129, 130]]}
{"doc_key": "ai-test-340", "ner": [[0, 1, "algorithm"], [5, 6, "misc"], [10, 13, "metrics"], [20, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 5, 6, "related-to", "minimise", false, false], [10, 13, 5, 6, "type-of", "", false, false], [20, 20, 5, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Autoencoders", "are", "trained", "to", "minimize", "reconstruction", "errors", "(", "such", "as", "root", "mean", "square", "error", ")", ",", "often", "referred", "to", "as", "loss", ":"], "sentence-detokenized": "Autoencoders are trained to minimize reconstruction errors (such as root mean square error), often referred to as loss:", "token2charspan": [[0, 12], [13, 16], [17, 24], [25, 27], [28, 36], [37, 51], [52, 58], [59, 60], [60, 64], [65, 67], [68, 72], [73, 77], [78, 84], [85, 90], [90, 91], [91, 92], [93, 98], [99, 107], [108, 110], [111, 113], [114, 118], [118, 119]]}
{"doc_key": "ai-test-341", "ner": [[31, 33, "misc"], [37, 37, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[37, 37, 31, 33, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "alternative", "to", "using", "definitions", "is", "to", "consider", "the", "general", "relatedness", "between", "a", "word", "and", "a", "meaning", "and", "calculate", "the", "similarity", "of", "each", "pair", "of", "word", "meanings", "based", "on", "a", "given", "lexical", "knowledge", "base", ",", "such", "as", "WordNet", "."], "sentence-detokenized": "An alternative to using definitions is to consider the general relatedness between a word and a meaning and calculate the similarity of each pair of word meanings based on a given lexical knowledge base, such as WordNet.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 23], [24, 35], [36, 38], [39, 41], [42, 50], [51, 54], [55, 62], [63, 74], [75, 82], [83, 84], [85, 89], [90, 93], [94, 95], [96, 103], [104, 107], [108, 117], [118, 121], [122, 132], [133, 135], [136, 140], [141, 145], [146, 148], [149, 153], [154, 162], [163, 168], [169, 171], [172, 173], [174, 179], [180, 187], [188, 197], [198, 202], [202, 203], [204, 208], [209, 211], [212, 219], [219, 220]]}
{"doc_key": "ai-test-342", "ner": [[0, 3, "algorithm"], [8, 11, "researcher"], [14, 23, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 8, 11, "origin", "", false, false], [8, 11, 14, 23, "role", "work_based_on_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["TD", "-", "Lambda", "is", "a", "learning", "algorithm", "invented", "by", "Richard", "S.", "Sutton", "based", "on", "Arthur", "Samuel", "'s", "earlier", "work", "on", "time", "-", "difference", "learning", "."], "sentence-detokenized": "TD-Lambda is a learning algorithm invented by Richard S. Sutton based on Arthur Samuel's earlier work on time-difference learning.", "token2charspan": [[0, 2], [2, 3], [3, 9], [10, 12], [13, 14], [15, 23], [24, 33], [34, 42], [43, 45], [46, 53], [54, 56], [57, 63], [64, 69], [70, 72], [73, 79], [80, 86], [86, 88], [89, 96], [97, 101], [102, 104], [105, 109], [109, 110], [110, 120], [121, 129], [129, 130]]}
{"doc_key": "ai-test-343", "ner": [[1, 2, "field"], [4, 4, "field"], [5, 7, "task"], [11, 13, "task"], [15, 18, "task"], [19, 20, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 7, 1, 2, "part-of", "task_part_of_field", false, false], [5, 7, 4, 4, "part-of", "task_part_of_field", false, false], [11, 13, 5, 7, "named", "", false, false], [15, 18, 5, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "data", "mining", "and", "statistics", ",", "hierarchical", "clustering", "(", "also", "called", "hierarchical", "cluster", "analysis", "or", "HCA", ")", "is", "a", "cluster", "analysis", "method", "that", "aims", "to", "build", "a", "hierarchy", "of", "clusters", "."], "sentence-detokenized": "In data mining and statistics, hierarchical clustering (also called hierarchical cluster analysis or HCA) is a cluster analysis method that aims to build a hierarchy of clusters.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 18], [19, 29], [29, 30], [31, 43], [44, 54], [55, 56], [56, 60], [61, 67], [68, 80], [81, 88], [89, 97], [98, 100], [101, 104], [104, 105], [106, 108], [109, 110], [111, 118], [119, 127], [128, 134], [135, 139], [140, 144], [145, 147], [148, 153], [154, 155], [156, 165], [166, 168], [169, 177], [177, 178]]}
{"doc_key": "ai-test-344", "ner": [[3, 4, "algorithm"], [8, 11, "field"], [10, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 8, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "concept", "of", "deconvolution", "is", "widely", "used", "in", "signal", "and", "image", "processing", "engineering", "."], "sentence-detokenized": "The concept of deconvolution is widely used in signal and image processing engineering.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 28], [29, 31], [32, 38], [39, 43], [44, 46], [47, 53], [54, 57], [58, 63], [64, 74], [75, 86], [86, 87]]}
{"doc_key": "ai-test-345", "ner": [[0, 1, "algorithm"], [22, 23, "misc"], [26, 29, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 22, 23, "related-to", "enhances", false, false], [0, 1, 22, 23, "related-to", "reduces", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cognitive", "maps", "serve", "to", "build", "and", "accumulate", "spatial", "knowledge", ",", "allowing", "the", "mind", "'s", "eye", "to", "visualize", "images", "in", "order", "to", "reduce", "cognitive", "load", ",", "improve", "memorization", "and", "assimilation", "of", "information", "."], "sentence-detokenized": "Cognitive maps serve to build and accumulate spatial knowledge, allowing the mind's eye to visualize images in order to reduce cognitive load, improve memorization and assimilation of information.", "token2charspan": [[0, 9], [10, 14], [15, 20], [21, 23], [24, 29], [30, 33], [34, 44], [45, 52], [53, 62], [62, 63], [64, 72], [73, 76], [77, 81], [81, 83], [84, 87], [88, 90], [91, 100], [101, 107], [108, 110], [111, 116], [117, 119], [120, 126], [127, 136], [137, 141], [141, 142], [143, 150], [151, 163], [164, 167], [168, 180], [181, 183], [184, 195], [195, 196]]}
{"doc_key": "ai-test-346", "ner": [[8, 8, "programlang"], [10, 11, "programlang"], [13, 13, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["which", "usually", "provides", "binding", "to", "such", "languages", "as", "Python", ",", "C", "++", ",", "Java", ")", "."], "sentence-detokenized": "which usually provides binding to such languages as Python, C++, Java).", "token2charspan": [[0, 5], [6, 13], [14, 22], [23, 30], [31, 33], [34, 38], [39, 48], [49, 51], [52, 58], [58, 59], [60, 61], [61, 63], [63, 64], [65, 69], [69, 70], [70, 71]]}
{"doc_key": "ai-test-347", "ner": [[0, 3, "product"], [5, 5, "product"], [15, 16, "task"], [22, 27, "task"], [29, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 15, 16, "usage", "", false, false], [0, 3, 22, 27, "usage", "", false, false], [0, 3, 29, 32, "usage", "", false, false], [5, 5, 0, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "Voice", "User", "Interface", "(", "VUI", ")", "enables", "conversational", "human", "-", "computer", "interaction", "by", "using", "speech", "recognition", "to", "understand", "spoken", "commands", "and", "answers", "to", "questions", ",", "and", "typically", "converting", "text", "to", "speech", "to", "reproduce", "the", "response", "."], "sentence-detokenized": "A Voice User Interface (VUI) enables conversational human-computer interaction by using speech recognition to understand spoken commands and answers to questions, and typically converting text to speech to reproduce the response.", "token2charspan": [[0, 1], [2, 7], [8, 12], [13, 22], [23, 24], [24, 27], [27, 28], [29, 36], [37, 51], [52, 57], [57, 58], [58, 66], [67, 78], [79, 81], [82, 87], [88, 94], [95, 106], [107, 109], [110, 120], [121, 127], [128, 136], [137, 140], [141, 148], [149, 151], [152, 161], [161, 162], [163, 166], [167, 176], [177, 187], [188, 192], [193, 195], [196, 202], [203, 205], [206, 215], [216, 219], [220, 228], [228, 229]]}
{"doc_key": "ai-test-348", "ner": [[0, 1, "programlang"], [3, 4, "misc"], [7, 7, "programlang"], [11, 14, "researcher"], [16, 17, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 3, 4, "general-affiliation", "is_a", false, false], [0, 1, 7, 7, "general-affiliation", "made_with", false, false], [0, 1, 11, 14, "origin", "", false, false], [11, 14, 16, 17, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Jess", "is", "a", "rule", "engine", "for", "the", "Java", "platform", "developed", "by", "Ernest", "Friedman", "-", "Hill", "of", "Sandia", "National", "."], "sentence-detokenized": "Jess is a rule engine for the Java platform developed by Ernest Friedman-Hill of Sandia National.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 14], [15, 21], [22, 25], [26, 29], [30, 34], [35, 43], [44, 53], [54, 56], [57, 63], [64, 72], [72, 73], [73, 77], [78, 80], [81, 87], [88, 96], [96, 97]]}
{"doc_key": "ai-test-349", "ner": [[1, 2, "algorithm"], [20, 21, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 20, 21, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "multilayer", "perceptrons", "where", "there", "is", "a", "hidden", "layer", ",", "it", "is", "necessary", "to", "use", "more", "complex", "algorithms", "such", "as", "back", "propagation", "."], "sentence-detokenized": "For multilayer perceptrons where there is a hidden layer, it is necessary to use more complex algorithms such as back propagation.", "token2charspan": [[0, 3], [4, 14], [15, 26], [27, 32], [33, 38], [39, 41], [42, 43], [44, 50], [51, 56], [56, 57], [58, 60], [61, 63], [64, 73], [74, 76], [77, 80], [81, 85], [86, 93], [94, 104], [105, 109], [110, 112], [113, 117], [118, 129], [129, 130]]}
{"doc_key": "ai-test-350", "ner": [[0, 2, "product"], [3, 6, "product"], [10, 17, "algorithm"], [22, 23, "field"], [26, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 6, 0, 2, "part-of", "", false, false], [3, 6, 10, 17, "usage", "", false, true], [10, 17, 22, 23, "related-to", "performs", false, false], [26, 31, 22, 23, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Google", "Translate", "'s", "neural", "machine", "translation", "system", "uses", "a", "large", "end", "-", "to", "-", "end", "artificial", "neural", "network", "that", "attempts", "to", "perform", "deep", "learning", ",", "particularly", "long", "short", "-", "term", "memory", "networks", "."], "sentence-detokenized": "Google Translate's neural machine translation system uses a large end-to-end artificial neural network that attempts to perform deep learning, particularly long short-term memory networks.", "token2charspan": [[0, 6], [7, 16], [16, 18], [19, 25], [26, 33], [34, 45], [46, 52], [53, 57], [58, 59], [60, 65], [66, 69], [69, 70], [70, 72], [72, 73], [73, 76], [77, 87], [88, 94], [95, 102], [103, 107], [108, 116], [117, 119], [120, 127], [128, 132], [133, 141], [141, 142], [143, 155], [156, 160], [161, 166], [166, 167], [167, 171], [172, 178], [179, 187], [187, 188]]}
{"doc_key": "ai-test-351", "ner": [[13, 13, "researcher"], [15, 15, "researcher"], [17, 17, "researcher"], [19, 20, "researcher"], [22, 23, "researcher"], [25, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Various", "methods", "for", "this", "were", "developed", "in", "the", "1980s", "and", "early", "1990s", "by", "Verbos", ",", "Williams", ",", "Robinson", ",", "J\u00fcrgen", "Schmidhuber", ",", "Sepp", "Hochreiter", ",", "Perlmutter", "and", "others", "."], "sentence-detokenized": "Various methods for this were developed in the 1980s and early 1990s by Verbos, Williams, Robinson, J\u00fcrgen Schmidhuber, Sepp Hochreiter, Perlmutter and others.", "token2charspan": [[0, 7], [8, 15], [16, 19], [20, 24], [25, 29], [30, 39], [40, 42], [43, 46], [47, 52], [53, 56], [57, 62], [63, 68], [69, 71], [72, 78], [78, 79], [80, 88], [88, 89], [90, 98], [98, 99], [100, 106], [107, 118], [118, 119], [120, 124], [125, 135], [135, 136], [137, 147], [148, 151], [152, 158], [158, 159]]}
{"doc_key": "ai-test-352", "ner": [[0, 3, "organisation"], [8, 8, "organisation"], [11, 14, "task"], [18, 18, "product"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [[18, 18, 11, 14, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [3], "sentence": ["|", "Apple", "Apple", "Inc", "initially", "licensed", "software", "from", "Nuance", "to", "provide", "speech", "recognition", "capabilities", "for", "its", "digital", "assistant", "Siri", "."], "sentence-detokenized": "| Apple Apple Inc initially licensed software from Nuance to provide speech recognition capabilities for its digital assistant Siri.", "token2charspan": [[0, 1], [2, 7], [8, 13], [14, 17], [18, 27], [28, 36], [37, 45], [46, 50], [51, 57], [58, 60], [61, 68], [69, 75], [76, 87], [88, 100], [101, 104], [105, 108], [109, 116], [117, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-test-353", "ner": [[0, 0, "organisation"], [4, 5, "misc"], [8, 10, "person"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 5, "role", "releases_movies_in_genre", false, false], [8, 10, 0, 0, "role", "directs_for", false, false], [13, 14, 0, 0, "role", "directs_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Columbia", "has", "released", "several", "3D", "westerns", "produced", "by", "Sam", "Katzman", "and", "directed", "by", "William", "Castle", "."], "sentence-detokenized": "Columbia has released several 3D westerns produced by Sam Katzman and directed by William Castle.", "token2charspan": [[0, 8], [9, 12], [13, 21], [22, 29], [30, 32], [33, 41], [42, 50], [51, 53], [54, 57], [58, 65], [66, 69], [70, 78], [79, 81], [82, 89], [90, 96], [96, 97]]}
{"doc_key": "ai-test-354", "ner": [[6, 7, "field"], [9, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "combines", "knowledge", "and", "research", "in", "computer", "science", ",", "linguistics", "and", "computer", "engineering", "."], "sentence-detokenized": "It combines knowledge and research in computer science, linguistics and computer engineering.", "token2charspan": [[0, 2], [3, 11], [12, 21], [22, 25], [26, 34], [35, 37], [38, 46], [47, 54], [54, 55], [56, 67], [68, 71], [72, 80], [81, 92], [92, 93]]}
{"doc_key": "ai-test-355", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["Here", "is", "an", "example", "of", "R-", "code", ":"], "sentence-detokenized": "Here is an example of R-code:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 24], [24, 28], [28, 29]]}
{"doc_key": "ai-test-356", "ner": [[0, 2, "metrics"], [8, 10, "metrics"], [12, 12, "metrics"], [16, 18, "metrics"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 8, 10, "part-of", "plotted_into", false, false], [0, 2, 16, 18, "part-of", "plotted_into", false, false], [12, 12, 8, 10, "named", "", false, false], [20, 20, 16, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "ROC", "curve", "is", "created", "by", "plotting", "the", "True", "Positive", "Frequency", "(", "TPF", ")", "against", "the", "False", "Positive", "Frequency", "(", "FPF", ")", "at", "different", "thresholds", "."], "sentence-detokenized": "The ROC curve is created by plotting the True Positive Frequency (TPF) against the False Positive Frequency (FPF) at different thresholds.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 24], [25, 27], [28, 36], [37, 40], [41, 45], [46, 54], [55, 64], [65, 66], [66, 69], [69, 70], [71, 78], [79, 82], [83, 88], [89, 97], [98, 107], [108, 109], [109, 112], [112, 113], [114, 116], [117, 126], [127, 137], [137, 138]]}
{"doc_key": "ai-test-357", "ner": [[4, 5, "field"], [8, 9, "researcher"], [11, 12, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 4, 5, "related-to", "researches_field", false, false], [11, 12, 4, 5, "related-to", "researches_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Research", "stalled", "after", "the", "machine", "learning", "research", "of", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", ","], "sentence-detokenized": "Research stalled after the machine learning research of Marvin Minsky and Seymour Papert (1969),", "token2charspan": [[0, 8], [9, 16], [17, 22], [23, 26], [27, 34], [35, 43], [44, 52], [53, 55], [56, 62], [63, 69], [70, 73], [74, 81], [82, 88], [89, 90], [90, 94], [94, 95], [95, 96]]}
{"doc_key": "ai-test-358", "ner": [[6, 6, "task"], [9, 10, "programlang"], [12, 14, "product"], [16, 17, "programlang"], [19, 19, "product"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 6, 9, 10, "related-to", "used_to_build", false, false], [6, 6, 12, 14, "related-to", "used_to_build", false, false], [6, 6, 16, 17, "related-to", "used_to_build", false, false], [6, 6, 19, 19, "related-to", "used_to_build", false, false], [6, 6, 22, 22, "related-to", "used_to_build", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "programming", "environments", "used", "to", "create", "DAQ", "applications", "include", "ladder", "logic", ",", "Visual", "C", "++", ",", "Visual", "Basic", ",", "LabVIEW", ",", "and", "MATLAB", "."], "sentence-detokenized": "Other programming environments used to create DAQ applications include ladder logic, Visual C++, Visual Basic, LabVIEW, and MATLAB.", "token2charspan": [[0, 5], [6, 17], [18, 30], [31, 35], [36, 38], [39, 45], [46, 49], [50, 62], [63, 70], [71, 77], [78, 83], [83, 84], [85, 91], [92, 93], [93, 95], [95, 96], [97, 103], [104, 109], [109, 110], [111, 118], [118, 119], [120, 123], [124, 130], [130, 131]]}
{"doc_key": "ai-test-359", "ner": [[15, 16, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "metric", "was", "developed", "to", "fix", "some", "of", "the", "problems", "found", "in", "the", "more", "popular", "BLEU", "metric", "and", "also", "to", "provide", "a", "good", "correlation", "with", "human", "judgment", "at", "the", "sentence", "or", "segment", "level", "."], "sentence-detokenized": "The metric was developed to fix some of the problems found in the more popular BLEU metric and also to provide a good correlation with human judgment at the sentence or segment level.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 24], [25, 27], [28, 31], [32, 36], [37, 39], [40, 43], [44, 52], [53, 58], [59, 61], [62, 65], [66, 70], [71, 78], [79, 83], [84, 90], [91, 94], [95, 99], [100, 102], [103, 110], [111, 112], [113, 117], [118, 129], [130, 134], [135, 140], [141, 149], [150, 152], [153, 156], [157, 165], [166, 168], [169, 176], [177, 182], [182, 183]]}
{"doc_key": "ai-test-360", "ner": [[3, 5, "algorithm"], [8, 9, "algorithm"], [11, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Methods", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "long", "short", "-", "term", "memory", "are", "often", "used", "to", "exploit", "semantic", "correlations", "between", "consecutive", "video", "frames", "."], "sentence-detokenized": "Methods such as dynamic Markov networks, convolutional neural networks and long short-term memory are often used to exploit semantic correlations between consecutive video frames.", "token2charspan": [[0, 7], [8, 12], [13, 15], [16, 23], [24, 30], [31, 39], [39, 40], [41, 54], [55, 61], [62, 70], [71, 74], [75, 79], [80, 85], [85, 86], [86, 90], [91, 97], [98, 101], [102, 107], [108, 112], [113, 115], [116, 123], [124, 132], [133, 145], [146, 153], [154, 165], [166, 171], [172, 178], [178, 179]]}
{"doc_key": "ai-test-361", "ner": [[3, 5, "product"], [7, 7, "product"], [14, 14, "product"], [18, 18, "product"], [36, 36, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 5, 14, 14, "artifact", "", false, false], [3, 5, 36, 36, "named", "", false, false], [7, 7, 3, 5, "named", "", false, false], [18, 18, 14, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Mass", "-", "produced", "printed", "circuit", "boards", "(", "PCBs", ")", "are", "almost", "entirely", "manufactured", "using", "robots", ",", "typically", "with", "SCARA", "manipulators", ",", "which", "pick", "up", "tiny", "electronic", "components", "from", "strips", "or", "trays", "and", "place", "them", "on", "the", "PCB", "with", "great", "precision", "."], "sentence-detokenized": "Mass-produced printed circuit boards (PCBs) are almost entirely manufactured using robots, typically with SCARA manipulators, which pick up tiny electronic components from strips or trays and place them on the PCB with great precision.", "token2charspan": [[0, 4], [4, 5], [5, 13], [14, 21], [22, 29], [30, 36], [37, 38], [38, 42], [42, 43], [44, 47], [48, 54], [55, 63], [64, 76], [77, 82], [83, 89], [89, 90], [91, 100], [101, 105], [106, 111], [112, 124], [124, 125], [126, 131], [132, 136], [137, 139], [140, 144], [145, 155], [156, 166], [167, 171], [172, 178], [179, 181], [182, 187], [188, 191], [192, 197], [198, 202], [203, 205], [206, 209], [210, 213], [214, 218], [219, 224], [225, 234], [234, 235]]}
{"doc_key": "ai-test-362", "ner": [[4, 5, "field"], [15, 15, "algorithm"], [19, 21, "researcher"], [23, 24, "researcher"], [26, 29, "researcher"], [36, 37, "algorithm"], [39, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 15, 4, 5, "part-of", "", false, false], [15, 15, 19, 21, "origin", "", false, false], [15, 15, 23, 24, "origin", "", false, false], [15, 15, 26, 29, "origin", "", false, false], [15, 15, 36, 37, "type-of", "", false, false], [36, 37, 39, 40, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "the", "context", "of", "machine", "learning", ",", "where", "it", "is", "most", "widely", "used", "today", ",", "LDA", "was", "discovered", "independently", "by", "David", "Bley", ",", "Andrew", "Ng", "and", "Michael", "I", ".", "Jordan", "in", "2003", "and", "presented", "as", "a", "graphical", "model", "for", "topic", "discovery", "."], "sentence-detokenized": "In the context of machine learning, where it is most widely used today, LDA was discovered independently by David Bley, Andrew Ng and Michael I. Jordan in 2003 and presented as a graphical model for topic discovery.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 25], [26, 34], [34, 35], [36, 41], [42, 44], [45, 47], [48, 52], [53, 59], [60, 64], [65, 70], [70, 71], [72, 75], [76, 79], [80, 90], [91, 104], [105, 107], [108, 113], [114, 118], [118, 119], [120, 126], [127, 129], [130, 133], [134, 141], [142, 143], [143, 144], [145, 151], [152, 154], [155, 159], [160, 163], [164, 173], [174, 176], [177, 178], [179, 188], [189, 194], [195, 198], [199, 204], [205, 214], [214, 215]]}
{"doc_key": "ai-test-363", "ner": [[8, 8, "task"], [11, 11, "misc"], [14, 14, "metrics"], [16, 16, "metrics"], [18, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 8, 11, 11, "related-to", "task_across_domain", false, false]], "relations_mapping_to_source": [0], "sentence": ["Measured", "performance", "on", "test", "data", "from", "eight", "naive", "WSIs", "under", "different", "tauopathies", "resulted", "in", "recall", ",", "precision", "and", "F1", "scores", "of", "0.92", ",", "0.72", "and", "0.81", ",", "respectively", "."], "sentence-detokenized": "Measured performance on test data from eight naive WSIs under different tauopathies resulted in recall, precision and F1 scores of 0.92, 0.72 and 0.81, respectively.", "token2charspan": [[0, 8], [9, 20], [21, 23], [24, 28], [29, 33], [34, 38], [39, 44], [45, 50], [51, 55], [56, 61], [62, 71], [72, 83], [84, 92], [93, 95], [96, 102], [102, 103], [104, 113], [114, 117], [118, 120], [121, 127], [128, 130], [131, 135], [135, 136], [137, 141], [142, 145], [146, 150], [150, 151], [152, 164], [164, 165]]}
{"doc_key": "ai-test-364", "ner": [[12, 13, "field"], [22, 23, "task"]], "ner_mapping_to_source": [1, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["With", "the", "help", "of", "advanced", "AR", "technologies", "(", "for", "example", ",", "adding", "computer", "vision", ",", "embedding", "AR", "cameras", "in", "a", "smartphone", "and", "object", "recognition", ")", ",", "information", "about", "the", "user", "'s", "real", "world", "becomes", "interactive", "and", "digitally", "manipulated", "."], "sentence-detokenized": "With the help of advanced AR technologies (for example, adding computer vision, embedding AR cameras in a smartphone and object recognition), information about the user's real world becomes interactive and digitally manipulated.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 25], [26, 28], [29, 41], [42, 43], [43, 46], [47, 54], [54, 55], [56, 62], [63, 71], [72, 78], [78, 79], [80, 89], [90, 92], [93, 100], [101, 103], [104, 105], [106, 116], [117, 120], [121, 127], [128, 139], [139, 140], [140, 141], [142, 153], [154, 159], [160, 163], [164, 168], [168, 170], [171, 175], [176, 181], [182, 189], [190, 201], [202, 205], [206, 215], [216, 227], [227, 228]]}
{"doc_key": "ai-test-365", "ner": [[3, 3, "researcher"], [5, 5, "organisation"], [12, 13, "field"], [23, 25, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 5, 5, "role", "forms_company", false, false], [5, 5, 12, 13, "related-to", "works_with", false, false], [5, 5, 23, 25, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2014", ",", "Schmidhuber", "founded", "Nnaisense", "to", "work", "on", "commercial", "applications", "of", "artificial", "intelligence", "in", "areas", "such", "as", "finance", ",", "heavy", "industry", "and", "self", "-", "driving", "cars", "."], "sentence-detokenized": "In 2014, Schmidhuber founded Nnaisense to work on commercial applications of artificial intelligence in areas such as finance, heavy industry and self-driving cars.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 28], [29, 38], [39, 41], [42, 46], [47, 49], [50, 60], [61, 73], [74, 76], [77, 87], [88, 100], [101, 103], [104, 109], [110, 114], [115, 117], [118, 125], [125, 126], [127, 132], [133, 141], [142, 145], [146, 150], [150, 151], [151, 158], [159, 163], [163, 164]]}
{"doc_key": "ai-test-366", "ner": [[29, 32, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Not", "only", "does", "this", "change", "the", "results", "of", "all", "subsequent", "tests", "on", "the", "remaining", "explanatory", "model", ",", "but", "it", "can", "also", "lead", "to", "a", "bias", "and", "change", "in", "the", "standard", "error", "of", "the", "estimate", "."], "sentence-detokenized": "Not only does this change the results of all subsequent tests on the remaining explanatory model, but it can also lead to a bias and change in the standard error of the estimate.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 18], [19, 25], [26, 29], [30, 37], [38, 40], [41, 44], [45, 55], [56, 61], [62, 64], [65, 68], [69, 78], [79, 90], [91, 96], [96, 97], [98, 101], [102, 104], [105, 108], [109, 113], [114, 118], [119, 121], [122, 123], [124, 128], [129, 132], [133, 139], [140, 142], [143, 146], [147, 155], [156, 161], [162, 164], [165, 168], [169, 177], [177, 178]]}
{"doc_key": "ai-test-367", "ner": [[0, 0, "misc"], [6, 6, "algorithm"], [9, 10, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 0, 0, "usage", "", false, false], [6, 6, 9, 10, "topic", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Bigrams", "are", "used", "in", "most", "successful", "language", "models", "for", "speech", "recognition", "."], "sentence-detokenized": "Bigrams are used in most successful language models for speech recognition.", "token2charspan": [[0, 7], [8, 11], [12, 16], [17, 19], [20, 24], [25, 35], [36, 44], [45, 51], [52, 55], [56, 62], [63, 74], [74, 75]]}
{"doc_key": "ai-test-368", "ner": [[3, 9, "field"], [22, 22, "misc"], [17, 18, "misc"], [10, 12, "organisation"], [25, 25, "misc"], [32, 35, "organisation"], [38, 40, "misc"], [46, 50, "organisation"], [54, 56, "misc"], [62, 65, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[22, 22, 3, 9, "topic", "", false, false], [17, 18, 10, 12, "origin", "", false, false], [25, 25, 32, 35, "origin", "", false, false], [38, 40, 46, 50, "origin", "", false, false], [54, 56, 62, 65, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["His", "research", "in", "cognitive", "psychology", "has", "been", "recognized", "by", "the", "American", "Psychological", "Association", "(", "1984", ")", "and", "Boyd", "McCandless", "(", "1986", ")", "awards", ",", "the", "Trolland", "Prize", "(", "1993", ")", "of", "the", "National", "Academy", "of", "Sciences", ",", "the", "Henry", "Dale", "Prize", "(", "2004", ")", "of", "the", "Royal", "Institution", "of", "Great", "Britain", ",", "and", "the", "George", "Miller", "Prize", "(", "2010", ")", "of", "the", "Society", "for", "Cognitive", "Neuroscience", "."], "sentence-detokenized": "His research in cognitive psychology has been recognized by the American Psychological Association (1984) and Boyd McCandless (1986) awards, the Trolland Prize (1993) of the National Academy of Sciences, the Henry Dale Prize (2004) of the Royal Institution of Great Britain, and the George Miller Prize (2010) of the Society for Cognitive Neuroscience.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 25], [26, 36], [37, 40], [41, 45], [46, 56], [57, 59], [60, 63], [64, 72], [73, 86], [87, 98], [99, 100], [100, 104], [104, 105], [106, 109], [110, 114], [115, 125], [126, 127], [127, 131], [131, 132], [133, 139], [139, 140], [141, 144], [145, 153], [154, 159], [160, 161], [161, 165], [165, 166], [167, 169], [170, 173], [174, 182], [183, 190], [191, 193], [194, 202], [202, 203], [204, 207], [208, 213], [214, 218], [219, 224], [225, 226], [226, 230], [230, 231], [232, 234], [235, 238], [239, 244], [245, 256], [257, 259], [260, 265], [266, 273], [273, 274], [275, 278], [279, 282], [283, 289], [290, 296], [297, 302], [303, 304], [304, 308], [308, 309], [310, 312], [313, 316], [317, 324], [325, 328], [329, 338], [339, 351], [351, 352]]}
{"doc_key": "ai-test-369", "ner": [[0, 0, "misc"], [6, 6, "misc"], [8, 10, "product"], [14, 14, "researcher"], [16, 16, "researcher"], [23, 24, "researcher"], [26, 27, "researcher"], [29, 30, "task"], [32, 35, "researcher"], [37, 41, "researcher"], [42, 43, "task"], [45, 45, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[0, 0, 6, 6, "named", "", false, false], [0, 0, 45, 45, "named", "", false, false], [6, 6, 14, 14, "origin", "", false, false], [6, 6, 16, 16, "origin", "", false, false], [6, 6, 29, 30, "related-to", "used_for", false, false], [8, 10, 6, 6, "usage", "", false, false], [8, 10, 42, 43, "named", "", false, false], [23, 24, 6, 6, "usage", "", false, false], [23, 24, 32, 35, "named", "same", false, false], [26, 27, 6, 6, "usage", "", false, false], [26, 27, 37, 41, "named", "same", false, false], [42, 43, 45, 45, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Eigenface", "(", "The", "approach", "of", "using", "eigenfaces", "for", "face", "recognition", "system", "was", "developed", "by", "Sirovich", "and", "Kirby", "(", "1987", ")", "and", "used", "by", "Matthew", "Turk", "and", "Alex", "Pentland", "in", "face", "classification", ".", "Turk", ",", "Matthew", "A", "and", "Pentland", ",", "Alex", "P", ".", "Face", "recognition", "using", "eigenfaces", "."], "sentence-detokenized": "Eigenface (The approach of using eigenfaces for face recognition system was developed by Sirovich and Kirby (1987) and used by Matthew Turk and Alex Pentland in face classification. Turk, Matthew A and Pentland, Alex P. Face recognition using eigenfaces.", "token2charspan": [[0, 9], [10, 11], [11, 14], [15, 23], [24, 26], [27, 32], [33, 43], [44, 47], [48, 52], [53, 64], [65, 71], [72, 75], [76, 85], [86, 88], [89, 97], [98, 101], [102, 107], [108, 109], [109, 113], [113, 114], [115, 118], [119, 123], [124, 126], [127, 134], [135, 139], [140, 143], [144, 148], [149, 157], [158, 160], [161, 165], [166, 180], [180, 181], [182, 186], [186, 187], [188, 195], [196, 197], [198, 201], [202, 210], [210, 211], [212, 216], [217, 218], [218, 219], [220, 224], [225, 236], [237, 242], [243, 253], [253, 254]]}
{"doc_key": "ai-test-370", "ner": [[14, 14, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["To", "understand", "the", "context", ",", "you", "can", "use", "a", "lexical", "dictionary", ",", "such", "as", "WordNet", "."], "sentence-detokenized": "To understand the context, you can use a lexical dictionary, such as WordNet.", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 25], [25, 26], [27, 30], [31, 34], [35, 38], [39, 40], [41, 48], [49, 59], [59, 60], [61, 65], [66, 68], [69, 76], [76, 77]]}
{"doc_key": "ai-test-371", "ner": [[0, 0, "misc"], [8, 8, "misc"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 8, "part-of", "", false, false], [8, 8, 15, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hyponymy", "is", "the", "most", "frequently", "encoded", "relation", "among", "synonyms", "used", "in", "lexical", "databases", "such", "as", "WordNet", "."], "sentence-detokenized": "Hyponymy is the most frequently encoded relation among synonyms used in lexical databases such as WordNet.", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 20], [21, 31], [32, 39], [40, 48], [49, 54], [55, 63], [64, 68], [69, 71], [72, 79], [80, 89], [90, 94], [95, 97], [98, 105], [105, 106]]}
{"doc_key": "ai-test-372", "ner": [[0, 0, "organisation"], [6, 7, "programlang"], [9, 9, "programlang"], [39, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 7, "general-affiliation", "", false, false], [0, 0, 9, 9, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["OPeNDAP", "offers", "open", "source", "libraries", "in", "C", "++", "and", "Java", ",", "but", "many", "customers", "rely", "on", "community", "-", "developed", "libraries", ",", "for", "example", ",", "libraries", "include", "built", "-", "in", "capabilities", "to", "retrieve", "(", "array", "-", "style", ")", "data", "from", "DAP", "servers", "."], "sentence-detokenized": "OPeNDAP offers open source libraries in C++ and Java, but many customers rely on community-developed libraries, for example, libraries include built-in capabilities to retrieve (array-style) data from DAP servers.", "token2charspan": [[0, 7], [8, 14], [15, 19], [20, 26], [27, 36], [37, 39], [40, 41], [41, 43], [44, 47], [48, 52], [52, 53], [54, 57], [58, 62], [63, 72], [73, 77], [78, 80], [81, 90], [90, 91], [91, 100], [101, 110], [110, 111], [112, 115], [116, 123], [123, 124], [125, 134], [135, 142], [143, 148], [148, 149], [149, 151], [152, 164], [165, 167], [168, 176], [177, 178], [178, 183], [183, 184], [184, 189], [189, 190], [191, 195], [196, 200], [201, 204], [205, 212], [212, 213]]}
{"doc_key": "ai-test-373", "ner": [[4, 5, "misc"], [8, 8, "product"], [17, 17, "country"], [29, 32, "misc"], [43, 43, "organisation"], [45, 45, "product"], [47, 47, "organisation"], [49, 53, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 17, 17, "opposite", "", false, false], [8, 8, 17, 17, "artifact", "", false, false], [29, 32, 8, 8, "part-of", "", false, false], [45, 45, 43, 43, "artifact", "", false, false], [49, 53, 47, 47, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["On", "this", "page", ",", "Samurai", "Damashii", "exaggerated", "the", "senkoushu", "as", "the", "crystallization", "of", "four", "thousand", "years", "of", "Chinese", "scientific", "knowledge", ",", "commented", "on", "the", "crude", "design", "(", "such", "as", "the", "Chinese", "crotch", "cannon", ")", ",", "and", "placed", "it", "s", "image", "among", "images", "of", "Honda", "'s", "ASIMO", "and", "Sony", "'s", "QRIO", "SDR", "-", "3", "X", "for", "comparison", "."], "sentence-detokenized": "On this page, Samurai Damashii exaggerated the senkoushu as the crystallization of four thousand years of Chinese scientific knowledge, commented on the crude design (such as the Chinese crotch cannon), and placed its image among images of Honda's ASIMO and Sony's QRIO SDR-3X for comparison.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 21], [22, 30], [31, 42], [43, 46], [47, 56], [57, 59], [60, 63], [64, 79], [80, 82], [83, 87], [88, 96], [97, 102], [103, 105], [106, 113], [114, 124], [125, 134], [134, 135], [136, 145], [146, 148], [149, 152], [153, 158], [159, 165], [166, 167], [167, 171], [172, 174], [175, 178], [179, 186], [187, 193], [194, 200], [200, 201], [201, 202], [203, 206], [207, 213], [214, 216], [216, 217], [218, 223], [224, 229], [230, 236], [237, 239], [240, 245], [245, 247], [248, 253], [254, 257], [258, 262], [262, 264], [265, 269], [270, 273], [273, 274], [274, 275], [275, 276], [277, 280], [281, 291], [291, 292]]}
{"doc_key": "ai-test-374", "ner": [[8, 9, "algorithm"], [20, 20, "product"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 20, 20, "part-of", "includes_functionality_of", false, false], [8, 9, 22, 22, "part-of", "includes_functionality_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "also", "many", "programming", "libraries", "that", "contain", "neural", "network", "functionality", "and", "can", "be", "used", "in", "custom", "implementations", "(", "e.g.", "TensorFlow", ",", "Theano", ",", "etc.", ")", "."], "sentence-detokenized": "There are also many programming libraries that contain neural network functionality and can be used in custom implementations (e.g. TensorFlow, Theano, etc.).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 19], [20, 31], [32, 41], [42, 46], [47, 54], [55, 61], [62, 69], [70, 83], [84, 87], [88, 91], [92, 94], [95, 99], [100, 102], [103, 109], [110, 125], [126, 127], [127, 131], [132, 142], [142, 143], [144, 150], [150, 151], [152, 156], [156, 157], [157, 158]]}
{"doc_key": "ai-test-375", "ner": [[6, 9, "conference"], [11, 11, "organisation"], [13, 19, "conference"], [21, 21, "conference"], [24, 24, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "Association", "for", "Computing", "Machinery", ",", "IEEE", ",", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "IAPR", ",", "and", "SPIE", "."], "sentence-detokenized": "He is a member of the Association for Computing Machinery, IEEE, American Association for the Advancement of Science, IAPR, and SPIE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 33], [34, 37], [38, 47], [48, 57], [57, 58], [59, 63], [63, 64], [65, 73], [74, 85], [86, 89], [90, 93], [94, 105], [106, 108], [109, 116], [116, 117], [118, 122], [122, 123], [124, 127], [128, 132], [132, 133]]}
{"doc_key": "ai-test-376", "ner": [[3, 3, "organisation"], [7, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 7, 8, "related-to", "runs_trials_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "trial", "by", "RET", "in", "2011", "with", "facial", "recognition", "cameras", "installed", "on", "trams", "showed", "that", "people", "who", "were", "banned", "from", "riding", "in", "the", "city", "still", "did", "not", "enter", "the", "trams", "."], "sentence-detokenized": "A trial by RET in 2011 with facial recognition cameras installed on trams showed that people who were banned from riding in the city still did not enter the trams.", "token2charspan": [[0, 1], [2, 7], [8, 10], [11, 14], [15, 17], [18, 22], [23, 27], [28, 34], [35, 46], [47, 54], [55, 64], [65, 67], [68, 73], [74, 80], [81, 85], [86, 92], [93, 96], [97, 101], [102, 108], [109, 113], [114, 120], [121, 123], [124, 127], [128, 132], [133, 138], [139, 142], [143, 146], [147, 152], [153, 156], [157, 162], [162, 163]]}
{"doc_key": "ai-test-377", "ner": [[10, 14, "person"], [7, 7, "organisation"], [19, 20, "person"], [22, 25, "person"], [33, 34, "person"], [36, 37, "person"], [39, 40, "person"], [42, 43, "person"], [45, 46, "person"], [48, 49, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[10, 14, 7, 7, "role", "works_for", false, false], [19, 20, 7, 7, "role", "works_for", false, false], [22, 25, 7, 7, "role", "works_for", false, false], [33, 34, 7, 7, "role", "works_for", false, false], [36, 37, 7, 7, "role", "works_for", false, false], [39, 40, 7, 7, "role", "works_for", false, false], [42, 43, 7, 7, "role", "works_for", false, false], [45, 46, 7, 7, "role", "works_for", false, false], [48, 49, 7, 7, "role", "works_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "film", ",", "based", "on", "the", "popular", "Broadway", "musical", "by", "Cole", "Porter", ",", "stars", "the", "MGM", "songbirds", "team", "of", "Howard", "Keel", "and", "Katherine", "Grayson", "in", "the", "lead", "roles", ",", "with", "the", "support", "of", "Ann", "Miller", ",", "Keenan", "Wynn", ",", "Bobby", "Wang", ",", "James", "Whitmore", ",", "Kurt", "Kaznar", "and", "Tommy", "Rall", "."], "sentence-detokenized": "The film, based on the popular Broadway musical by Cole Porter, stars the MGM songbirds team of Howard Keel and Katherine Grayson in the lead roles, with the support of Ann Miller, Keenan Wynn, Bobby Wang, James Whitmore, Kurt Kaznar and Tommy Rall.", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 15], [16, 18], [19, 22], [23, 30], [31, 39], [40, 47], [48, 50], [51, 55], [56, 62], [62, 63], [64, 69], [70, 73], [74, 77], [78, 87], [88, 92], [93, 95], [96, 102], [103, 107], [108, 111], [112, 121], [122, 129], [130, 132], [133, 136], [137, 141], [142, 147], [147, 148], [149, 153], [154, 157], [158, 165], [166, 168], [169, 172], [173, 179], [179, 180], [181, 187], [188, 192], [192, 193], [194, 199], [200, 204], [204, 205], [206, 211], [212, 220], [220, 221], [222, 226], [227, 233], [234, 237], [238, 243], [244, 248], [248, 249]]}
{"doc_key": "ai-test-378", "ner": [[19, 23, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "applications", "should", "optimize", "call", "flows", ",", "minimize", "prompts", ",", "eliminate", "unnecessary", "iterations", ",", "and", "allow", "for", "an", "advanced", "system", "of", "mixed", "initiative", "dialogues", "that", "allow", "callers", "to", "enter", "multiple", "pieces", "of", "information", "in", "a", "single", "utterance", "and", "in", "any", "order", "or", "combination", "."], "sentence-detokenized": "Such applications should optimize call flows, minimize prompts, eliminate unnecessary iterations, and allow for an advanced system of mixed initiative dialogues that allow callers to enter multiple pieces of information in a single utterance and in any order or combination.", "token2charspan": [[0, 4], [5, 17], [18, 24], [25, 33], [34, 38], [39, 44], [44, 45], [46, 54], [55, 62], [62, 63], [64, 73], [74, 85], [86, 96], [96, 97], [98, 101], [102, 107], [108, 111], [112, 114], [115, 123], [124, 130], [131, 133], [134, 139], [140, 150], [151, 160], [161, 165], [166, 171], [172, 179], [180, 182], [183, 188], [189, 197], [198, 204], [205, 207], [208, 219], [220, 222], [223, 224], [225, 231], [232, 241], [242, 245], [246, 248], [249, 252], [253, 258], [259, 261], [262, 273], [273, 274]]}
{"doc_key": "ai-test-379", "ner": [[3, 4, "algorithm"], [7, 9, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 9, 3, 4, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Thus", ",", "traditional", "gradient", "descent", "(", "or", "stochastic", "gradient", "descent", ")", "methods", "can", "be", "adapted", ",", "where", "instead", "of", "stepping", "in", "the", "direction", "of", "the", "function", "gradient", ",", "a", "step", "is", "taken", "in", "the", "direction", "of", "a", "vector", "selected", "from", "the", "function", "subgradient", "."], "sentence-detokenized": "Thus, traditional gradient descent (or stochastic gradient descent) methods can be adapted, where instead of stepping in the direction of the function gradient, a step is taken in the direction of a vector selected from the function subgradient.", "token2charspan": [[0, 4], [4, 5], [6, 17], [18, 26], [27, 34], [35, 36], [36, 38], [39, 49], [50, 58], [59, 66], [66, 67], [68, 75], [76, 79], [80, 82], [83, 90], [90, 91], [92, 97], [98, 105], [106, 108], [109, 117], [118, 120], [121, 124], [125, 134], [135, 137], [138, 141], [142, 150], [151, 159], [159, 160], [161, 162], [163, 167], [168, 170], [171, 176], [177, 179], [180, 183], [184, 193], [194, 196], [197, 198], [199, 205], [206, 214], [215, 219], [220, 223], [224, 232], [233, 244], [244, 245]]}
{"doc_key": "ai-test-380", "ner": [[9, 14, "metrics"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "it", "is", "assumed", "that", "the", "distortion", "is", "measured", "by", "the", "root", "mean", "square", "error", ",", "then", "the", "distortion", "D", "is", "given", "by", "the", "value", ":"], "sentence-detokenized": "If it is assumed that the distortion is measured by the root mean square error, then the distortion D is given by the value:", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 16], [17, 21], [22, 25], [26, 36], [37, 39], [40, 48], [49, 51], [52, 55], [56, 60], [61, 65], [66, 72], [73, 78], [78, 79], [80, 84], [85, 88], [89, 99], [100, 101], [102, 104], [105, 110], [111, 113], [114, 117], [118, 123], [123, 124]]}
{"doc_key": "ai-test-381", "ner": [[0, 0, "algorithm"], [6, 7, "field"], [19, 20, "task"], [22, 23, "task"], [25, 27, "task"], [29, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 7, "part-of", "", false, false], [19, 20, 0, 0, "part-of", "", false, false], [22, 23, 0, 0, "part-of", "", false, false], [25, 27, 0, 0, "part-of", "", false, false], [29, 30, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["MLPs", "were", "a", "popular", "solution", "for", "machine", "learning", "in", "the", "1980s", ",", "finding", "applications", "in", "various", "fields", "such", "as", "speech", "recognition", ",", "image", "recognition", "and", "machine", "translation", "software", ",", "neural", "networks", "."], "sentence-detokenized": "MLPs were a popular solution for machine learning in the 1980s, finding applications in various fields such as speech recognition, image recognition and machine translation software, neural networks.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 19], [20, 28], [29, 32], [33, 40], [41, 49], [50, 52], [53, 56], [57, 62], [62, 63], [64, 71], [72, 84], [85, 87], [88, 95], [96, 102], [103, 107], [108, 110], [111, 117], [118, 129], [129, 130], [131, 136], [137, 148], [149, 152], [153, 160], [161, 172], [173, 181], [181, 182], [183, 189], [190, 198], [198, 199]]}
{"doc_key": "ai-test-382", "ner": [[0, 0, "researcher"], [3, 3, "misc"], [6, 8, "university"], [15, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 8, "physical", "", false, false], [0, 0, 6, 8, "role", "", false, false], [3, 3, 0, 0, "origin", "", false, false], [15, 17, 0, 0, "role", "supervised", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Allen", "received", "his", "PhD", "from", "the", "University", "of", "Toronto", "in", "1979", "under", "the", "supervision", "of", "C.", "Raymond", "Perrault", ","], "sentence-detokenized": "Allen received his PhD from the University of Toronto in 1979 under the supervision of C. Raymond Perrault,", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 22], [23, 27], [28, 31], [32, 42], [43, 45], [46, 53], [54, 56], [57, 61], [62, 67], [68, 71], [72, 83], [84, 86], [87, 89], [90, 97], [98, 106], [106, 107]]}
{"doc_key": "ai-test-383", "ner": [[0, 0, "product"], [5, 7, "field"], [10, 10, "product"], [12, 12, "product"], [14, 14, "product"], [19, 19, "product"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 5, 7, "related-to", "supports", false, false], [10, 10, 5, 7, "type-of", "", true, false], [12, 12, 5, 7, "type-of", "", true, false], [14, 14, 5, 7, "type-of", "", true, false], [14, 14, 19, 19, "related-to", "converting_to", true, false], [23, 23, 5, 7, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["OpenCV", "supports", "some", "models", "from", "deep", "learning", "frameworks", "such", "as", "TensorFlow", ",", "Torch", ",", "PyTorch", "(", "after", "conversion", "to", "ONNX", "model", ")", "and", "Caffe", "according", "to", "the", "defined", "list", "of", "supported", "layers", "."], "sentence-detokenized": "OpenCV supports some models from deep learning frameworks such as TensorFlow, Torch, PyTorch (after conversion to ONNX model) and Caffe according to the defined list of supported layers.", "token2charspan": [[0, 6], [7, 15], [16, 20], [21, 27], [28, 32], [33, 37], [38, 46], [47, 57], [58, 62], [63, 65], [66, 76], [76, 77], [78, 83], [83, 84], [85, 92], [93, 94], [94, 99], [100, 110], [111, 113], [114, 118], [119, 124], [124, 125], [126, 129], [130, 135], [136, 145], [146, 148], [149, 152], [153, 160], [161, 165], [166, 168], [169, 178], [179, 185], [185, 186]]}
{"doc_key": "ai-test-384", "ner": [[2, 2, "researcher"], [9, 12, "organisation"], [14, 14, "organisation"], [25, 28, "organisation"], [21, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 9, 12, "role", "", false, false], [2, 2, 25, 28, "role", "", false, false], [2, 2, 21, 24, "related-to", "lectures_in", false, false], [14, 14, 9, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Previously", ",", "Christensen", "was", "the", "founding", "chairman", "of", "the", "European", "Robotics", "Research", "Network", "(", "EURON", ")", "and", "a", "Distinguished", "Lecturer", "in", "Robotics", "at", "the", "IEEE", "Robotics", "and", "Automation", "Society", "."], "sentence-detokenized": "Previously, Christensen was the founding chairman of the European Robotics Research Network (EURON) and a Distinguished Lecturer in Robotics at the IEEE Robotics and Automation Society.", "token2charspan": [[0, 10], [10, 11], [12, 23], [24, 27], [28, 31], [32, 40], [41, 49], [50, 52], [53, 56], [57, 65], [66, 74], [75, 83], [84, 91], [92, 93], [93, 98], [98, 99], [100, 103], [104, 105], [106, 119], [120, 128], [129, 131], [132, 140], [141, 143], [144, 147], [148, 152], [153, 161], [162, 165], [166, 176], [177, 184], [184, 185]]}
{"doc_key": "ai-test-385", "ner": [[6, 7, "field"], [9, 11, "university"], [13, 13, "location"], [15, 18, "country"], [24, 24, "misc"], [26, 26, "field"], [29, 32, "organisation"], [34, 34, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[9, 11, 13, 13, "physical", "", false, false], [13, 13, 15, 18, "physical", "", false, false], [24, 24, 26, 26, "topic", "", false, false], [29, 32, 34, 34, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "received", "a", "Master", "'s", "degree", "in", "Mathematics", "from", "Samarkand", "State", "University", ",", "Samarkand", ",", "Uzbek", "Soviet", "Socialist", "Republic", ",", "in", "1958", "and", "a", "PhD", "in", "Statistics", "from", "the", "Institute", "of", "Management", "Sciences", ",", "Moscow", ",", "in", "1964", "."], "sentence-detokenized": "He received a Master's degree in Mathematics from Samarkand State University, Samarkand, Uzbek Soviet Socialist Republic, in 1958 and a PhD in Statistics from the Institute of Management Sciences, Moscow, in 1964.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 20], [20, 22], [23, 29], [30, 32], [33, 44], [45, 49], [50, 59], [60, 65], [66, 76], [76, 77], [78, 87], [87, 88], [89, 94], [95, 101], [102, 111], [112, 120], [120, 121], [122, 124], [125, 129], [130, 133], [134, 135], [136, 139], [140, 142], [143, 153], [154, 158], [159, 162], [163, 172], [173, 175], [176, 186], [187, 195], [195, 196], [197, 203], [203, 204], [205, 207], [208, 212], [212, 213]]}
{"doc_key": "ai-test-386", "ner": [[6, 6, "organisation"], [10, 11, "product"], [30, 31, "field"], [33, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 30, 31, "usage", "", false, false], [6, 6, 33, 35, "usage", "", false, false], [10, 11, 6, 6, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Increasingly", ",", "however", ",", "working", "at", "Cycorp", "involves", "enabling", "the", "Cyc", "system", "to", "communicate", "with", "end", "users", "in", "natural", "language", "and", "assist", "in", "the", "ongoing", "process", "of", "knowledge", "building", "through", "machine", "learning", "and", "natural", "language", "understanding", "."], "sentence-detokenized": "Increasingly, however, working at Cycorp involves enabling the Cyc system to communicate with end users in natural language and assist in the ongoing process of knowledge building through machine learning and natural language understanding.", "token2charspan": [[0, 12], [12, 13], [14, 21], [21, 22], [23, 30], [31, 33], [34, 40], [41, 49], [50, 58], [59, 62], [63, 66], [67, 73], [74, 76], [77, 88], [89, 93], [94, 97], [98, 103], [104, 106], [107, 114], [115, 123], [124, 127], [128, 134], [135, 137], [138, 141], [142, 149], [150, 157], [158, 160], [161, 170], [171, 179], [180, 187], [188, 195], [196, 204], [205, 208], [209, 216], [217, 225], [226, 239], [239, 240]]}
{"doc_key": "ai-test-387", "ner": [[55, 55, "metrics"], [57, 57, "metrics"], [59, 59, "metrics"], [61, 62, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "if", "the", "most", "suitable", "classifier", "for", "a", "task", "is", "sought", ",", "the", "training", "dataset", "is", "used", "to", "train", "the", "candidate", "algorithms", ",", "the", "validation", "dataset", "is", "used", "to", "compare", "their", "performance", "and", "decide", "which", "one", "to", "take", ",", "and", "finally", ",", "the", "test", "dataset", "is", "used", "to", "obtain", "performance", "characteristics", "such", "as", "accuracy", ",", "sensitivity", ",", "specificity", ",", "F-", "measure", "and", "so", "on", "."], "sentence-detokenized": "For example, if the most suitable classifier for a task is sought, the training dataset is used to train the candidate algorithms, the validation dataset is used to compare their performance and decide which one to take, and finally, the test dataset is used to obtain performance characteristics such as accuracy, sensitivity, specificity, F-measure and so on.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 19], [20, 24], [25, 33], [34, 44], [45, 48], [49, 50], [51, 55], [56, 58], [59, 65], [65, 66], [67, 70], [71, 79], [80, 87], [88, 90], [91, 95], [96, 98], [99, 104], [105, 108], [109, 118], [119, 129], [129, 130], [131, 134], [135, 145], [146, 153], [154, 156], [157, 161], [162, 164], [165, 172], [173, 178], [179, 190], [191, 194], [195, 201], [202, 207], [208, 211], [212, 214], [215, 219], [219, 220], [221, 224], [225, 232], [232, 233], [234, 237], [238, 242], [243, 250], [251, 253], [254, 258], [259, 261], [262, 268], [269, 280], [281, 296], [297, 301], [302, 304], [305, 313], [313, 314], [315, 326], [326, 327], [328, 339], [339, 340], [341, 343], [343, 350], [351, 354], [355, 357], [358, 360], [360, 361]]}
{"doc_key": "ai-test-388", "ner": [[0, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "mean", "square", "error", "is", "0.15", "."], "sentence-detokenized": "The mean square error is 0.15.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 21], [22, 24], [25, 29], [29, 30]]}
{"doc_key": "ai-test-389", "ner": [[7, 12, "misc"], [4, 4, "organisation"], [17, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 7, 12, "role", "", false, false], [17, 17, 7, 12, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1979", ",", "the", "IEEE", "organized", "the", "Micromouse", "competition", ",", "which", "was", "reported", "in", "the", "journal", "\"", "Spectrum", "\"", "."], "sentence-detokenized": "In 1979, the IEEE organized the Micromouse competition, which was reported in the journal \"Spectrum\".", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 17], [18, 27], [28, 31], [32, 42], [43, 54], [54, 55], [56, 61], [62, 65], [66, 74], [75, 77], [78, 81], [82, 89], [90, 91], [91, 99], [99, 100], [100, 101]]}
{"doc_key": "ai-test-390", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [10, 12, "task"], [14, 15, "task"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 6, 7, "part-of", "", false, false], [10, 12, 6, 7, "part-of", "task_part_of_field", false, false], [14, 15, 6, 7, "part-of", "task_part_of_field", false, false], [17, 18, 6, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Gabor", "space", "is", "very", "useful", "for", "image", "processing", "such", "as", "optical", "character", "recognition", ",", "iris", "recognition", "and", "fingerprint", "recognition", "."], "sentence-detokenized": "Gabor space is very useful for image processing such as optical character recognition, iris recognition and fingerprint recognition.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 19], [20, 26], [27, 30], [31, 36], [37, 47], [48, 52], [53, 55], [56, 63], [64, 73], [74, 85], [85, 86], [87, 91], [92, 103], [104, 107], [108, 119], [120, 131], [131, 132]]}
{"doc_key": "ai-test-391", "ner": [[7, 7, "programlang"], [9, 9, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["or", "through", "high", "-", "level", "interfaces", "to", "Java", "and", "Tcl", "."], "sentence-detokenized": "or through high-level interfaces to Java and Tcl.", "token2charspan": [[0, 2], [3, 10], [11, 15], [15, 16], [16, 21], [22, 32], [33, 35], [36, 40], [41, 44], [45, 48], [48, 49]]}
{"doc_key": "ai-test-392", "ner": [[10, 11, "algorithm"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 11, 18, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "recent", "studies", ",", "kernel", "-", "based", "methods", "such", "as", "support", "vector", "machines", "have", "shown", "superior", "performance", "in", "supervised", "mode", "."], "sentence-detokenized": "In recent studies, kernel-based methods such as support vector machines have shown superior performance in supervised mode.", "token2charspan": [[0, 2], [3, 9], [10, 17], [17, 18], [19, 25], [25, 26], [26, 31], [32, 39], [40, 44], [45, 47], [48, 55], [56, 62], [63, 71], [72, 76], [77, 82], [83, 91], [92, 103], [104, 106], [107, 117], [118, 122], [122, 123]]}
{"doc_key": "ai-test-393", "ner": [[16, 16, "misc"], [22, 22, "researcher"], [24, 24, "researcher"], [32, 32, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 22, 32, 32, "usage", "", false, false], [24, 24, 32, 32, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["To", "illustrate", "the", "basic", "principles", "of", "packaging", ",", "below", "is", "an", "analysis", "of", "the", "relationship", "between", "ozone", "and", "temperature", "(", "data", "from", "Rousseeuw", "and", "Leroy", "(", "1986", ")", ",", "analysis", "performed", "in", "R", ")", "."], "sentence-detokenized": "To illustrate the basic principles of packaging, below is an analysis of the relationship between ozone and temperature (data from Rousseeuw and Leroy (1986), analysis performed in R).", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 23], [24, 34], [35, 37], [38, 47], [47, 48], [49, 54], [55, 57], [58, 60], [61, 69], [70, 72], [73, 76], [77, 89], [90, 97], [98, 103], [104, 107], [108, 119], [120, 121], [121, 125], [126, 130], [131, 140], [141, 144], [145, 150], [151, 152], [152, 156], [156, 157], [157, 158], [159, 167], [168, 177], [178, 180], [181, 182], [182, 183], [183, 184]]}
{"doc_key": "ai-test-394", "ner": [[0, 3, "organisation"], [11, 11, "product"], [18, 19, "product"], [21, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 0, 3, "artifact", "", false, false], [18, 19, 0, 3, "artifact", "", false, false], [21, 23, 0, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Denso", "Wave", "is", "a", "subsidiary", "that", "manufactures", "automatic", "identification", "products", "(", "barcode", "readers", "and", "related", "products", ")", ",", "industrial", "robots", "and", "programmable", "logic", "controllers", "."], "sentence-detokenized": "Denso Wave is a subsidiary that manufactures automatic identification products (barcode readers and related products), industrial robots and programmable logic controllers.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 15], [16, 26], [27, 31], [32, 44], [45, 54], [55, 69], [70, 78], [79, 80], [80, 87], [88, 95], [96, 99], [100, 107], [108, 116], [116, 117], [117, 118], [119, 129], [130, 136], [137, 140], [141, 153], [154, 159], [160, 171], [171, 172]]}
{"doc_key": "ai-test-395", "ner": [[0, 4, "metrics"], [8, 10, "metrics"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 20, 20, "compare", "", false, false], [8, 10, 0, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Whereas", "the", "bilingual", "score", "understudy", "simply", "calculates", "the", "accuracy", "of", "the", "n-grams", ",", "giving", "each", "of", "them", "equal", "weight", ",", "NIST", "also", "calculates", "how", "informative", "a", "particular", "n-", "gram", "is", "."], "sentence-detokenized": "Whereas the bilingual score understudy simply calculates the accuracy of the n-grams, giving each of them equal weight, NIST also calculates how informative a particular n-gram is.", "token2charspan": [[0, 7], [8, 11], [12, 21], [22, 27], [28, 38], [39, 45], [46, 56], [57, 60], [61, 69], [70, 72], [73, 76], [77, 84], [84, 85], [86, 92], [93, 97], [98, 100], [101, 105], [106, 111], [112, 118], [118, 119], [120, 124], [125, 129], [130, 140], [141, 144], [145, 156], [157, 158], [159, 169], [170, 172], [172, 176], [177, 179], [179, 180]]}
{"doc_key": "ai-test-396", "ner": [[15, 15, "algorithm"], [17, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "particular", ",", "they", "are", "used", "in", "calculating", "the", "likelihood", "of", "a", "tree", "(", "in", "Bayesian", "and", "maximum", "likelihood", "approaches", "to", "tree", "estimation", ")", ",", "and", "are", "also", "used", "to", "estimate", "the", "evolutionary", "distance", "between", "sequences", "from", "observed", "differences", "between", "sequences", "."], "sentence-detokenized": "In particular, they are used in calculating the likelihood of a tree (in Bayesian and maximum likelihood approaches to tree estimation), and are also used to estimate the evolutionary distance between sequences from observed differences between sequences.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 19], [20, 23], [24, 28], [29, 31], [32, 43], [44, 47], [48, 58], [59, 61], [62, 63], [64, 68], [69, 70], [70, 72], [73, 81], [82, 85], [86, 93], [94, 104], [105, 115], [116, 118], [119, 123], [124, 134], [134, 135], [135, 136], [137, 140], [141, 144], [145, 149], [150, 154], [155, 157], [158, 166], [167, 170], [171, 183], [184, 192], [193, 200], [201, 210], [211, 215], [216, 224], [225, 236], [237, 244], [245, 254], [254, 255]]}
{"doc_key": "ai-test-397", "ner": [[0, 3, "conference"], [20, 21, "misc"], [23, 23, "misc"], [46, 47, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 20, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Audio", "Engineering", "Society", "recommends", "a", "sampling", "rate", "of", "48", "kHz", "for", "most", "applications", ",", "but", "recognizes", "44.1", "kHz", "for", "compact", "discs", "(", "CDs", ")", "and", "other", "consumer", "applications", ",", "32", "kHz", "for", "transmission", "-", "related", "applications", ",", "and", "96", "kHz", "for", "wider", "bandwidth", "or", "relaxed", "anti-aliasing", "filtering", "."], "sentence-detokenized": "The Audio Engineering Society recommends a sampling rate of 48 kHz for most applications, but recognizes 44.1 kHz for compact discs (CDs) and other consumer applications, 32 kHz for transmission-related applications, and 96 kHz for wider bandwidth or relaxed anti-aliasing filtering.", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 29], [30, 40], [41, 42], [43, 51], [52, 56], [57, 59], [60, 62], [63, 66], [67, 70], [71, 75], [76, 88], [88, 89], [90, 93], [94, 104], [105, 109], [110, 113], [114, 117], [118, 125], [126, 131], [132, 133], [133, 136], [136, 137], [138, 141], [142, 147], [148, 156], [157, 169], [169, 170], [171, 173], [174, 177], [178, 181], [182, 194], [194, 195], [195, 202], [203, 215], [215, 216], [217, 220], [221, 223], [224, 227], [228, 231], [232, 237], [238, 247], [248, 250], [251, 258], [259, 272], [273, 282], [282, 283]]}
{"doc_key": "ai-test-398", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Word", "Net", "has", "created", "affective", "resources", "for", "words", "and", "concepts", "{{", "cited", "journal"], "sentence-detokenized": "WordNet has created affective resources for words and concepts {{cited journal", "token2charspan": [[0, 4], [4, 7], [8, 11], [12, 19], [20, 29], [30, 39], [40, 43], [44, 49], [50, 53], [54, 62], [63, 65], [65, 70], [71, 78]]}
{"doc_key": "ai-test-399", "ner": [[2, 7, "misc"], [25, 26, "person"], [31, 34, "person"], [41, 44, "person"], [50, 54, "organisation"], [73, 74, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[31, 34, 41, 44, "role", "acts_in", false, false], [50, 54, 41, 44, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "a", "red", "and", "green", "anaglyph", ",", "the", "audience", "was", "presented", "with", "three", "reels", "of", "test", "footage", "that", "included", "rural", "scenes", ",", "test", "footage", "of", "Marie", "Doro", ",", "a", "segment", "with", "John", "B", ".", "Mason", "playing", "a", "number", "of", "excerpts", "from", "Jim", "the", "Pen", "Man", "(", "a", "film", "released", "by", "Famous", "Players", "-", "Lasky", "the", "same", "year", ",", "but", "not", "in", "3D", ")", ",", "oriental", "dancers", ",", "and", "a", "reel", "of", "footage", "of", "Niagara", "Falls", "."], "sentence-detokenized": "In a red and green anaglyph, the audience was presented with three reels of test footage that included rural scenes, test footage of Marie Doro, a segment with John B. Mason playing a number of excerpts from Jim the Pen Man (a film released by Famous Players-Lasky the same year, but not in 3D), oriental dancers, and a reel of footage of Niagara Falls.", "token2charspan": [[0, 2], [3, 4], [5, 8], [9, 12], [13, 18], [19, 27], [27, 28], [29, 32], [33, 41], [42, 45], [46, 55], [56, 60], [61, 66], [67, 72], [73, 75], [76, 80], [81, 88], [89, 93], [94, 102], [103, 108], [109, 115], [115, 116], [117, 121], [122, 129], [130, 132], [133, 138], [139, 143], [143, 144], [145, 146], [147, 154], [155, 159], [160, 164], [165, 166], [166, 167], [168, 173], [174, 181], [182, 183], [184, 190], [191, 193], [194, 202], [203, 207], [208, 211], [212, 215], [216, 219], [220, 223], [224, 225], [225, 226], [227, 231], [232, 240], [241, 243], [244, 250], [251, 258], [258, 259], [259, 264], [265, 268], [269, 273], [274, 278], [278, 279], [280, 283], [284, 287], [288, 290], [291, 293], [293, 294], [294, 295], [296, 304], [305, 312], [312, 313], [314, 317], [318, 319], [320, 324], [325, 327], [328, 335], [336, 338], [339, 346], [347, 352], [352, 353]]}
{"doc_key": "ai-test-400", "ner": [[8, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "a", "special", "way", "to", "implement", "the", "maximum", "likelihood", "method", "for", "a", "given", "problem", "."], "sentence-detokenized": "This is a special way to implement the maximum likelihood method for a given problem.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 17], [18, 21], [22, 24], [25, 34], [35, 38], [39, 46], [47, 57], [58, 64], [65, 68], [69, 70], [71, 76], [77, 84], [84, 85]]}
{"doc_key": "ai-test-401", "ner": [[0, 4, "product"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Crawler", "-", "friendly", "Web", "Servers", ",", "and", "it", "integrates", "the", "functions", "of", "sitemaps", "and", "RSS", "feeds", "into", "a", "decentralized", "mechanism", "for", "computational", "biologists", "and", "bioinformaticians", "to", "openly", "broadcast", "and", "retrieve", "meta", "-", "data", "about", "biomedical", "resources", "."], "sentence-detokenized": "Crawler-friendly Web Servers, and it integrates the functions of sitemaps and RSS feeds into a decentralized mechanism for computational biologists and bioinformaticians to openly broadcast and retrieve meta-data about biomedical resources.", "token2charspan": [[0, 7], [7, 8], [8, 16], [17, 20], [21, 28], [28, 29], [30, 33], [34, 36], [37, 47], [48, 51], [52, 61], [62, 64], [65, 73], [74, 77], [78, 81], [82, 87], [88, 92], [93, 94], [95, 108], [109, 118], [119, 122], [123, 136], [137, 147], [148, 151], [152, 169], [170, 172], [173, 179], [180, 189], [190, 193], [194, 202], [203, 207], [207, 208], [208, 212], [213, 218], [219, 229], [230, 239], [239, 240]]}
{"doc_key": "ai-test-402", "ner": [[5, 14, "misc"], [18, 23, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "subject", "to", "the", "American", "National", "Standards", "Institute", "/", "NISO", "Z39.50", "standard", ",", "as", "well", "as", "the", "International", "Organization", "for", "Standardization", "standard", "23950", "."], "sentence-detokenized": "It is subject to the American National Standards Institute / NISO Z39.50 standard, as well as the International Organization for Standardization standard 23950.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 20], [21, 29], [30, 38], [39, 48], [49, 58], [59, 60], [61, 65], [66, 72], [73, 81], [81, 82], [83, 85], [86, 90], [91, 93], [94, 97], [98, 111], [112, 124], [125, 128], [129, 144], [145, 153], [154, 159], [159, 160]]}
{"doc_key": "ai-test-403", "ner": [[13, 18, "misc"], [23, 23, "metrics"], [26, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "encoder", "and", "decoder", "are", "trained", "to", "accept", "a", "phrase", "and", "produce", "a", "one", "-", "step", "distribution", "of", "the", "corresponding", "paraphrase", ",", "minimizing", "confusion", "using", "simple", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The encoder and decoder are trained to accept a phrase and produce a one-step distribution of the corresponding paraphrase, minimizing confusion using simple stochastic gradient descent.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 27], [28, 35], [36, 38], [39, 45], [46, 47], [48, 54], [55, 58], [59, 66], [67, 68], [69, 72], [72, 73], [73, 77], [78, 90], [91, 93], [94, 97], [98, 111], [112, 122], [122, 123], [124, 134], [135, 144], [145, 150], [151, 157], [158, 168], [169, 177], [178, 185], [185, 186]]}
{"doc_key": "ai-test-404", "ner": [[4, 5, "field"], [8, 10, "task"], [12, 17, "task"], [27, 31, "task"], [33, 39, "task"], [41, 47, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 10, 4, 5, "part-of", "task_part_of_field", false, false], [12, 17, 4, 5, "part-of", "task_part_of_field", false, false], [27, 31, 4, 5, "part-of", "task_part_of_field", false, false], [33, 39, 4, 5, "part-of", "task_part_of_field", false, false], [41, 47, 4, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "typical", "applications", "of", "pattern", "recognition", "methods", "are", "automatic", "speech", "recognition", ",", "classification", "of", "text", "into", "several", "categories", "(", "e.g.", "spam", "/", "non", "-", "spam", ")", ",", "handwriting", "recognition", "on", "postal", "envelopes", ",", "automatic", "recognition", "of", "images", "of", "human", "faces", "or", "extraction", "of", "handwriting", "images", "from", "medical", "forms", "."], "sentence-detokenized": "Other typical applications of pattern recognition methods are automatic speech recognition, classification of text into several categories (e.g. spam/non-spam), handwriting recognition on postal envelopes, automatic recognition of images of human faces or extraction of handwriting images from medical forms.", "token2charspan": [[0, 5], [6, 13], [14, 26], [27, 29], [30, 37], [38, 49], [50, 57], [58, 61], [62, 71], [72, 78], [79, 90], [90, 91], [92, 106], [107, 109], [110, 114], [115, 119], [120, 127], [128, 138], [139, 140], [140, 144], [145, 149], [149, 150], [150, 153], [153, 154], [154, 158], [158, 159], [159, 160], [161, 172], [173, 184], [185, 187], [188, 194], [195, 204], [204, 205], [206, 215], [216, 227], [228, 230], [231, 237], [238, 240], [241, 246], [247, 252], [253, 255], [256, 266], [267, 269], [270, 281], [282, 288], [289, 293], [294, 301], [302, 307], [307, 308]]}
{"doc_key": "ai-test-405", "ner": [[0, 3, "algorithm"], [13, 14, "field"], [16, 17, "task"], [19, 20, "task"], [22, 24, "task"], [26, 29, "task"], [31, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 14, 0, 3, "usage", "", false, false], [16, 17, 0, 3, "usage", "", false, false], [19, 20, 0, 3, "usage", "", false, false], [22, 24, 0, 3, "usage", "", false, false], [26, 29, 0, 3, "usage", "", false, false], [31, 32, 0, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Artificial", "neural", "networks", "are", "used", "to", "solve", "a", "variety", "of", "problems", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "media", "filtering", ",", "board", "and", "video", "games", ",", "medical", "diagnostics", "."], "sentence-detokenized": "Artificial neural networks are used to solve a variety of problems, including computer vision, speech recognition, machine translation, social media filtering, board and video games, medical diagnostics.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 30], [31, 35], [36, 38], [39, 44], [45, 46], [47, 54], [55, 57], [58, 66], [66, 67], [68, 77], [78, 86], [87, 93], [93, 94], [95, 101], [102, 113], [113, 114], [115, 122], [123, 134], [134, 135], [136, 142], [143, 148], [149, 158], [158, 159], [160, 165], [166, 169], [170, 175], [176, 181], [181, 182], [183, 190], [191, 202], [202, 203]]}
{"doc_key": "ai-test-406", "ner": [[2, 3, "organisation"], [4, 4, "product"], [17, 17, "product"], [20, 20, "organisation"], [21, 22, "product"], [24, 24, "product"], [26, 28, "product"], [30, 30, "product"], [32, 32, "programlang"], [40, 41, "field"], [47, 47, "product"], [52, 52, "algorithm"], [54, 54, "algorithm"], [56, 56, "algorithm"], [60, 60, "product"], [67, 67, "task"], [73, 75, "algorithm"], [78, 78, "product"], [80, 80, "product"], [83, 85, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "relations": [[4, 4, 2, 3, "origin", "", false, false], [4, 4, 17, 17, "named", "same", false, false], [4, 4, 47, 47, "named", "same", false, false], [32, 32, 40, 41, "related-to", "used_for", false, false], [52, 52, 32, 32, "part-of", "", true, false], [52, 52, 47, 47, "origin", "", true, false], [54, 54, 32, 32, "part-of", "", true, false], [54, 54, 47, 47, "origin", "", true, false], [56, 56, 32, 32, "part-of", "", true, false], [56, 56, 47, 47, "origin", "", true, false], [60, 60, 67, 67, "related-to", "used_for", false, false], [73, 75, 60, 60, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Examples", "are", "Salford", "Systems", "CART", "(", "which", "has", "licensed", "the", "proprietary", "code", "of", "the", "original", "authors", "of", "CART", ")", ",", "IBM", "SPSS", "Modeler", ",", "RapidMiner", ",", "SAS", "Enterprise", "Miner", ",", "Matlab", ",", "R", "(", "an", "open", "source", "software", "environment", "for", "statistical", "computing", "that", "includes", "several", "implementations", "of", "CART", ",", "such", "as", "the", "rpart", ",", "party", "and", "randomForest", "packages", ")", ",", "Weka", "(", "a", "free", "and", "open", "source", "data", "mining", "package", "that", "contains", "many", "decision", "tree", "algorithms", ")", ",", "Orange", ",", "KNIME", ",", "and", "Microsoft", "SQL", "Server", "programming", "language", ")", "."], "sentence-detokenized": "Examples are Salford Systems CART (which has licensed the proprietary code of the original authors of CART), IBM SPSS Modeler, RapidMiner, SAS Enterprise Miner, Matlab, R (an open source software environment for statistical computing that includes several implementations of CART, such as the rpart, party and randomForest packages), Weka (a free and open source data mining package that contains many decision tree algorithms), Orange, KNIME, and Microsoft SQL Server programming language).", "token2charspan": [[0, 8], [9, 12], [13, 20], [21, 28], [29, 33], [34, 35], [35, 40], [41, 44], [45, 53], [54, 57], [58, 69], [70, 74], [75, 77], [78, 81], [82, 90], [91, 98], [99, 101], [102, 106], [106, 107], [107, 108], [109, 112], [113, 117], [118, 125], [125, 126], [127, 137], [137, 138], [139, 142], [143, 153], [154, 159], [159, 160], [161, 167], [167, 168], [169, 170], [171, 172], [172, 174], [175, 179], [180, 186], [187, 195], [196, 207], [208, 211], [212, 223], [224, 233], [234, 238], [239, 247], [248, 255], [256, 271], [272, 274], [275, 279], [279, 280], [281, 285], [286, 288], [289, 292], [293, 298], [298, 299], [300, 305], [306, 309], [310, 322], [323, 331], [331, 332], [332, 333], [334, 338], [339, 340], [340, 341], [342, 346], [347, 350], [351, 355], [356, 362], [363, 367], [368, 374], [375, 382], [383, 387], [388, 396], [397, 401], [402, 410], [411, 415], [416, 426], [426, 427], [427, 428], [429, 435], [435, 436], [437, 442], [442, 443], [444, 447], [448, 457], [458, 461], [462, 468], [469, 480], [481, 489], [489, 490], [490, 491]]}
{"doc_key": "ai-test-407", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [10, 11, "researcher"], [13, 14, "university"], [16, 17, "researcher"], [19, 22, "organisation"], [24, 24, "organisation"], [33, 35, "researcher"], [37, 39, "researcher"], [41, 44, "organisation"], [56, 57, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 2, 10, 11, "origin", "", false, false], [0, 2, 16, 17, "origin", "", false, false], [0, 2, 33, 35, "origin", "", false, false], [0, 2, 37, 39, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [10, 11, 13, 14, "physical", "", false, false], [10, 11, 13, 14, "role", "", false, false], [16, 17, 19, 22, "physical", "", false, false], [16, 17, 19, 22, "role", "", false, false], [24, 24, 19, 22, "named", "", false, false], [33, 35, 41, 44, "physical", "", false, false], [33, 35, 41, 44, "role", "", false, false], [37, 39, 41, 44, "physical", "", false, false], [37, 39, 41, 44, "role", "", false, false], [56, 57, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Linear", "Predictive", "Coding", "(", "LPC", ")", "was", "first", "developed", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", ",", "and", "then", "developed", "by", "Bishnu", "S.", "Atal", "and", "Manfred", "R.", "Schroeder", "at", "Bell", "Labs", "in", "the", "early", "to", "mid", "1970s", ",", "becoming", "the", "basis", "for", "the", "first", "speech", "synthesizer", "chips", "in", "the", "late", "1970s", "."], "sentence-detokenized": "Linear Predictive Coding (LPC) was first developed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966, and then developed by Bishnu S. Atal and Manfred R. Schroeder at Bell Labs in the early to mid 1970s, becoming the basis for the first speech synthesizer chips in the late 1970s.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [31, 34], [35, 40], [41, 50], [51, 53], [54, 62], [63, 70], [71, 73], [74, 80], [81, 91], [92, 95], [96, 101], [102, 107], [108, 110], [111, 117], [118, 127], [128, 131], [132, 141], [142, 143], [143, 146], [146, 147], [148, 150], [151, 155], [155, 156], [157, 160], [161, 165], [166, 175], [176, 178], [179, 185], [186, 188], [189, 193], [194, 197], [198, 205], [206, 208], [209, 218], [219, 221], [222, 226], [227, 231], [232, 234], [235, 238], [239, 244], [245, 247], [248, 251], [252, 257], [257, 258], [259, 267], [268, 271], [272, 277], [278, 281], [282, 285], [286, 291], [292, 298], [299, 310], [311, 316], [317, 319], [320, 323], [324, 328], [329, 334], [334, 335]]}
{"doc_key": "ai-test-408", "ner": [[0, 3, "metrics"], [7, 7, "metrics"], [9, 9, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 0, 3, "part-of", "", false, false], [9, 9, 0, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["F", "-", "score", "is", "a", "combination", "of", "accuracy", "and", "recall", "that", "gives", "a", "single", "score", "."], "sentence-detokenized": "F-score is a combination of accuracy and recall that gives a single score.", "token2charspan": [[0, 1], [1, 2], [2, 7], [8, 10], [11, 12], [13, 24], [25, 27], [28, 36], [37, 40], [41, 47], [48, 52], [53, 58], [59, 60], [61, 67], [68, 73], [73, 74]]}
{"doc_key": "ai-test-409", "ner": [[0, 1, "field"], [8, 11, "task"], [17, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 11, 0, 1, "part-of", "task_part_of_field", false, false], [17, 19, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Image", "analysis", "tasks", "can", "be", "as", "simple", "as", "reading", "a", "d-tag", "barcode", "or", "as", "complex", "as", "a", "face", "recognition", "system", "."], "sentence-detokenized": "Image analysis tasks can be as simple as reading a d-tag barcode or as complex as a face recognition system.", "token2charspan": [[0, 5], [6, 14], [15, 20], [21, 24], [25, 27], [28, 30], [31, 37], [38, 40], [41, 48], [49, 50], [51, 56], [57, 64], [65, 67], [68, 70], [71, 78], [79, 81], [82, 83], [84, 88], [89, 100], [101, 107], [107, 108]]}
{"doc_key": "ai-test-410", "ner": [[5, 7, "algorithm"], [26, 27, "algorithm"], [34, 36, "algorithm"], [40, 40, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[34, 36, 26, 27, "type-of", "", false, false], [40, 40, 34, 36, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "special", "case", "of", "linear", "support", "vector", "machines", "can", "be", "solved", "more", "efficiently", "by", "using", "the", "same", "type", "of", "algorithms", "to", "optimize", "their", "close", "relative", ",", "logistic", "regression", ";", "this", "class", "of", "algorithms", "includes", "stochastic", "gradient", "descent", "(", "e.g.", ",", "PEGASOS", ")", "."], "sentence-detokenized": "The special case of linear support vector machines can be solved more efficiently by using the same type of algorithms to optimize their close relative, logistic regression; this class of algorithms includes stochastic gradient descent (e.g., PEGASOS).", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 19], [20, 26], [27, 34], [35, 41], [42, 50], [51, 54], [55, 57], [58, 64], [65, 69], [70, 81], [82, 84], [85, 90], [91, 94], [95, 99], [100, 104], [105, 107], [108, 118], [119, 121], [122, 130], [131, 136], [137, 142], [143, 151], [151, 152], [153, 161], [162, 172], [172, 173], [174, 178], [179, 184], [185, 187], [188, 198], [199, 207], [208, 218], [219, 227], [228, 235], [236, 237], [237, 241], [241, 242], [243, 250], [250, 251], [251, 252]]}
{"doc_key": "ai-test-411", "ner": [[1, 1, "product"], [4, 4, "product"], [26, 27, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 4, 4, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["When", "Siri", "on", "an", "iOS", "device", "is", "asked", "\"", "Do", "you", "have", "a", "pet", "?", "\"", ",", "one", "of", "the", "answers", "is", "\"", "I", "had", "an", "AIBO", "pet", "\"", "."], "sentence-detokenized": "When Siri on an iOS device is asked \"Do you have a pet?\", one of the answers is \"I had an AIBO pet\".", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 15], [16, 19], [20, 26], [27, 29], [30, 35], [36, 37], [37, 39], [40, 43], [44, 48], [49, 50], [51, 54], [54, 55], [55, 56], [56, 57], [58, 61], [62, 64], [65, 68], [69, 76], [77, 79], [80, 81], [81, 82], [83, 86], [87, 89], [90, 94], [95, 98], [98, 99], [99, 100]]}
{"doc_key": "ai-test-412", "ner": [[1, 2, "task"], [4, 6, "metrics"], [9, 9, "metrics"], [11, 11, "metrics"], [14, 14, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 1, 2, "part-of", "", false, false], [9, 9, 4, 6, "named", "", false, false], [11, 11, 1, 2, "part-of", "", false, false], [14, 14, 11, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "information", "retrieval", ",", "positive", "predictive", "value", "is", "called", "accuracy", "and", "sensitivity", "is", "called", "recall", "."], "sentence-detokenized": "In information retrieval, positive predictive value is called accuracy and sensitivity is called recall.", "token2charspan": [[0, 2], [3, 14], [15, 24], [24, 25], [26, 34], [35, 45], [46, 51], [52, 54], [55, 61], [62, 70], [71, 74], [75, 86], [87, 89], [90, 96], [97, 103], [103, 104]]}
{"doc_key": "ai-test-413", "ner": [[12, 13, "field"], [15, 15, "task"], [17, 17, "task"], [19, 20, "task"], [37, 38, "task"], [40, 41, "task"], [43, 47, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 15, 12, 13, "part-of", "task_part_of_field", false, false], [17, 17, 12, 13, "part-of", "task_part_of_field", false, false], [19, 20, 12, 13, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "particular", ",", "his", "research", "has", "been", "focused", "on", "areas", "such", "as", "text", "mining", "(", "extraction", ",", "categorization", ",", "novelty", "detection", ")", "and", "in", "new", "theoretical", "frameworks", "such", "as", "a", "unified", "utility", "-", "based", "theory", "that", "integrates", "information", "retrieval", ",", "automatic", "summarization", ",", "free", "-", "text", "question", "answering", "and", "related", "tasks", "."], "sentence-detokenized": "In particular, his research has been focused on areas such as text mining (extraction, categorization, novelty detection) and in new theoretical frameworks such as a unified utility-based theory that integrates information retrieval, automatic summarization, free-text question answering and related tasks.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 27], [28, 31], [32, 36], [37, 44], [45, 47], [48, 53], [54, 58], [59, 61], [62, 66], [67, 73], [74, 75], [75, 85], [85, 86], [87, 101], [101, 102], [103, 110], [111, 120], [120, 121], [122, 125], [126, 128], [129, 132], [133, 144], [145, 155], [156, 160], [161, 163], [164, 165], [166, 173], [174, 181], [181, 182], [182, 187], [188, 194], [195, 199], [200, 210], [211, 222], [223, 232], [232, 233], [234, 243], [244, 257], [257, 258], [259, 263], [263, 264], [264, 268], [269, 277], [278, 287], [288, 291], [292, 299], [300, 305], [305, 306]]}
{"doc_key": "ai-test-414", "ner": [[0, 1, "product"], [6, 7, "product"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 0, 1, "part-of", "", false, false], [15, 16, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Delta", "robots", "have", "base", "-", "mounted", "rotary", "actuators", "that", "move", "a", "lightweight", ",", "rigid", ",", "parallelogram", "arm", "."], "sentence-detokenized": "Delta robots have base-mounted rotary actuators that move a lightweight, rigid, parallelogram arm.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 22], [22, 23], [23, 30], [31, 37], [38, 47], [48, 52], [53, 57], [58, 59], [60, 71], [71, 72], [73, 78], [78, 79], [80, 93], [94, 97], [97, 98]]}
{"doc_key": "ai-test-415", "ner": [[8, 12, "metrics"], [16, 19, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "outcomes", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "in", "a", "confusion", "matrix", "as", "shown", "below", ":"], "sentence-detokenized": "The four outcomes can be formulated in a 2 \u00d7 2 contingency table or in a confusion matrix as shown below:", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 24], [25, 35], [36, 38], [39, 40], [41, 42], [43, 44], [45, 46], [47, 58], [59, 64], [65, 67], [68, 70], [71, 72], [73, 82], [83, 89], [90, 92], [93, 98], [99, 104], [104, 105]]}
{"doc_key": "ai-test-416", "ner": [[4, 5, "field"], [29, 30, "task"], [36, 37, "task"], [42, 43, "task"], [46, 48, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[29, 30, 4, 5, "part-of", "task_part_of_field", false, false], [36, 37, 4, 5, "part-of", "task_part_of_field", false, false], [42, 43, 4, 5, "part-of", "task_part_of_field", false, false], [46, 48, 4, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "actual", "task", "of", "data", "mining", "is", "semi-automatic", "or", "automatic", "analysis", "of", "large", "amounts", "of", "data", "to", "extract", "unknown", ",", "interesting", "patterns", "such", "as", "groups", "of", "data", "records", "(", "cluster", "analysis", ")", ",", "unusual", "records", "(", "anomaly", "detection", ")", "and", "dependencies", "(", "association", "rule", "mining", ",", "sequential", "pattern", "mining", ")", "."], "sentence-detokenized": "The actual task of data mining is semi-automatic or automatic analysis of large amounts of data to extract unknown, interesting patterns such as groups of data records (cluster analysis), unusual records (anomaly detection) and dependencies (association rule mining, sequential pattern mining).", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 18], [19, 23], [24, 30], [31, 33], [34, 48], [49, 51], [52, 61], [62, 70], [71, 73], [74, 79], [80, 87], [88, 90], [91, 95], [96, 98], [99, 106], [107, 114], [114, 115], [116, 127], [128, 136], [137, 141], [142, 144], [145, 151], [152, 154], [155, 159], [160, 167], [168, 169], [169, 176], [177, 185], [185, 186], [186, 187], [188, 195], [196, 203], [204, 205], [205, 212], [213, 222], [222, 223], [224, 227], [228, 240], [241, 242], [242, 253], [254, 258], [259, 265], [265, 266], [267, 277], [278, 285], [286, 292], [292, 293], [293, 294]]}
{"doc_key": "ai-test-417", "ner": [[10, 11, "product"], [0, 5, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 11, 0, 5, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Sentiment", "analysis", "proved", "to", "be", "a", "valuable", "method", "for", "the", "recommendation", "system", "."], "sentence-detokenized": "Sentiment analysis proved to be a valuable method for the recommendation system.", "token2charspan": [[0, 9], [10, 18], [19, 25], [26, 28], [29, 31], [32, 33], [34, 42], [43, 49], [50, 53], [54, 57], [58, 72], [73, 79], [79, 80]]}
{"doc_key": "ai-test-418", "ner": [[4, 4, "misc"], [14, 16, "product"], [35, 39, "organisation"], [40, 41, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 14, 16, "usage", "", false, false], [35, 39, 40, 41, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["By", "chance", ",", "the", "Germans", "very", "unsuccessfully", "chose", "the", "operating", "frequency", "of", "the", "\"", "Votan", "\"", "system", "-", "it", "operated", "at", "a", "frequency", "of", "45", "MHz", ",", "which", "was", "just", "a", "powerful", ",", "but", "inoperative", "BBC", "television", "transmitter", "in", "the", "Alexander", "Palace", "."], "sentence-detokenized": "By chance, the Germans very unsuccessfully chose the operating frequency of the \"Votan\" system - it operated at a frequency of 45 MHz, which was just a powerful, but inoperative BBC television transmitter in the Alexander Palace.", "token2charspan": [[0, 2], [3, 9], [9, 10], [11, 14], [15, 22], [23, 27], [28, 42], [43, 48], [49, 52], [53, 62], [63, 72], [73, 75], [76, 79], [80, 81], [81, 86], [86, 87], [88, 94], [95, 96], [97, 99], [100, 108], [109, 111], [112, 113], [114, 123], [124, 126], [127, 129], [130, 133], [133, 134], [135, 140], [141, 144], [145, 149], [150, 151], [152, 160], [160, 161], [162, 165], [166, 177], [178, 181], [182, 192], [193, 204], [205, 207], [208, 211], [212, 221], [222, 228], [228, 229]]}
{"doc_key": "ai-test-419", "ner": [[8, 12, "metrics"], [16, 19, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "outcomes", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "in", "a", "confusion", "matrix", "as", "shown", "below", ":"], "sentence-detokenized": "The four outcomes can be formulated in a 2 \u00d7 2 contingency table or in a confusion matrix as shown below:", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 24], [25, 35], [36, 38], [39, 40], [41, 42], [43, 44], [45, 46], [47, 58], [59, 64], [65, 67], [68, 70], [71, 72], [73, 82], [83, 89], [90, 92], [93, 98], [99, 104], [104, 105]]}
{"doc_key": "ai-test-420", "ner": [[1, 3, "misc"], [9, 9, "misc"], [13, 13, "product"], [15, 15, "product"], [17, 20, "product"], [28, 28, "misc"], [42, 44, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 13, 9, 9, "usage", "", false, false], [15, 15, 9, 9, "usage", "", false, false], [17, 20, 15, 15, "named", "", false, false], [28, 28, 9, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "Semantic", "Web", "applications", ",", "and", "in", "relatively", "popular", "RDF", "applications", "such", "as", "RSS", "and", "FOAF", "(", "Friend", "of", "a", "Friend", ")", ",", "resources", "are", "typically", "represented", "by", "URIs", "that", "intentionally", "denote", "and", "can", "be", "used", "to", "access", "actual", "data", "on", "the", "World", "Wide", "Web", "."], "sentence-detokenized": "In Semantic Web applications, and in relatively popular RDF applications such as RSS and FOAF (Friend of a Friend), resources are typically represented by URIs that intentionally denote and can be used to access actual data on the World Wide Web.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 28], [28, 29], [30, 33], [34, 36], [37, 47], [48, 55], [56, 59], [60, 72], [73, 77], [78, 80], [81, 84], [85, 88], [89, 93], [94, 95], [95, 101], [102, 104], [105, 106], [107, 113], [113, 114], [114, 115], [116, 125], [126, 129], [130, 139], [140, 151], [152, 154], [155, 159], [160, 164], [165, 178], [179, 185], [186, 189], [190, 193], [194, 196], [197, 201], [202, 204], [205, 211], [212, 218], [219, 223], [224, 226], [227, 230], [231, 236], [237, 241], [242, 245], [245, 246]]}
{"doc_key": "ai-test-421", "ner": [[0, 8, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Association", "for", "the", "Development", "of", "Artificial", "Intelligence", "has", "deeply", "studied", "this", "topic"], "sentence-detokenized": "The Association for the Development of Artificial Intelligence has deeply studied this topic", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 23], [24, 35], [36, 38], [39, 49], [50, 62], [63, 66], [67, 73], [74, 81], [82, 86], [87, 92]]}
{"doc_key": "ai-test-422", "ner": [[6, 11, "product"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 16, 6, 11, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Starting", "as", "a", "curiosity", ",", "the", "Apple", "Macintosh", "language", "system", "has", "evolved", "into", "a", "fully", "supported", "PlainTalk", "program", "for", "the", "visually", "impaired", "."], "sentence-detokenized": "Starting as a curiosity, the Apple Macintosh language system has evolved into a fully supported PlainTalk program for the visually impaired.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 23], [23, 24], [25, 28], [29, 34], [35, 44], [45, 53], [54, 60], [61, 64], [65, 72], [73, 77], [78, 79], [80, 85], [86, 95], [96, 105], [106, 113], [114, 117], [118, 121], [122, 130], [131, 139], [139, 140]]}
{"doc_key": "ai-test-423", "ner": [[5, 5, "field"], [7, 8, "task"], [10, 11, "task"], [14, 15, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 5, 5, "part-of", "task_part_of_field", false, false], [10, 11, 5, 5, "part-of", "task_part_of_field", false, false], [14, 15, 5, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Other", "uses", "of", "ontologies", "within", "NLP", "include", "information", "retrieval", ",", "information", "extraction", ",", "and", "automatic", "summarization", "."], "sentence-detokenized": "Other uses of ontologies within NLP include information retrieval, information extraction, and automatic summarization.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 24], [25, 31], [32, 35], [36, 43], [44, 55], [56, 65], [65, 66], [67, 78], [79, 89], [89, 90], [91, 94], [95, 104], [105, 118], [118, 119]]}
{"doc_key": "ai-test-424", "ner": [[6, 13, "organisation"], [16, 20, "organisation"], [23, 27, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "institute", "works", "closely", "with", "the", "Janelia", "Farm", "campus", "of", "Howard", "Hughes", "Medical", "Institute", ",", "the", "Allen", "Institute", "for", "Brain", "Research", "and", "the", "National", "Institutes", "of", "Health", "to", "develop", "better", "methods", "for", "reconstructing", "neural", "architecture", "."], "sentence-detokenized": "The institute works closely with the Janelia Farm campus of Howard Hughes Medical Institute, the Allen Institute for Brain Research and the National Institutes of Health to develop better methods for reconstructing neural architecture.", "token2charspan": [[0, 3], [4, 13], [14, 19], [20, 27], [28, 32], [33, 36], [37, 44], [45, 49], [50, 56], [57, 59], [60, 66], [67, 73], [74, 81], [82, 91], [91, 92], [93, 96], [97, 102], [103, 112], [113, 116], [117, 122], [123, 131], [132, 135], [136, 139], [140, 148], [149, 159], [160, 162], [163, 169], [170, 172], [173, 180], [181, 187], [188, 195], [196, 199], [200, 214], [215, 221], [222, 234], [234, 235]]}
{"doc_key": "ai-test-425", "ner": [[0, 0, "organisation"], [4, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 0, 0, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Google", "recently", "announced", "that", "Google", "Translate", "translates", "approximately", "as", "much", "text", "as", "1", "million", "books", "in", "one", "day", "(", "2012", ")", "."], "sentence-detokenized": "Google recently announced that Google Translate translates approximately as much text as 1 million books in one day (2012).", "token2charspan": [[0, 6], [7, 15], [16, 25], [26, 30], [31, 37], [38, 47], [48, 58], [59, 72], [73, 75], [76, 80], [81, 85], [86, 88], [89, 90], [91, 98], [99, 104], [105, 107], [108, 111], [112, 115], [116, 117], [117, 121], [121, 122], [122, 123]]}
{"doc_key": "ai-test-426", "ner": [[14, 14, "country"], [16, 16, "country"], [18, 18, "country"], [20, 20, "country"], [22, 22, "country"], [24, 25, "country"], [37, 38, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "events", "are", "held", "all", "over", "the", "world", "and", "are", "most", "popular", "in", "the", "UK", ",", "USA", ",", "Japan", ",", "Singapore", ",", "India", ",", "South", "Korea", "and", "are", "becoming", "popular", "in", "countries", "of", "the", "subcontinent", "such", "as", "Sri", "Lanka", "."], "sentence-detokenized": "The events are held all over the world and are most popular in the UK, USA, Japan, Singapore, India, South Korea and are becoming popular in countries of the subcontinent such as Sri Lanka.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 19], [20, 23], [24, 28], [29, 32], [33, 38], [39, 42], [43, 46], [47, 51], [52, 59], [60, 62], [63, 66], [67, 69], [69, 70], [71, 74], [74, 75], [76, 81], [81, 82], [83, 92], [92, 93], [94, 99], [99, 100], [101, 106], [107, 112], [113, 116], [117, 120], [121, 129], [130, 137], [138, 140], [141, 150], [151, 153], [154, 157], [158, 170], [171, 175], [176, 178], [179, 182], [183, 188], [188, 189]]}
{"doc_key": "ai-test-427", "ner": [[6, 6, "programlang"], [11, 11, "programlang"], [13, 13, "programlang"], [15, 16, "programlang"], [18, 18, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "packages", "are", "developed", "mainly", "in", "R", ",", "and", "sometimes", "in", "Java", ",", "C", ",", "C", "++", "and", "Fortran", "."], "sentence-detokenized": "These packages are developed mainly in R, and sometimes in Java, C, C++ and Fortran.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 28], [29, 35], [36, 38], [39, 40], [40, 41], [42, 45], [46, 55], [56, 58], [59, 63], [63, 64], [65, 66], [66, 67], [68, 69], [69, 71], [72, 75], [76, 83], [83, 84]]}
{"doc_key": "ai-test-428", "ner": [[2, 7, "conference"], [9, 9, "conference"], [12, 12, "researcher"], [14, 16, "researcher"], [18, 19, "researcher"], [22, 25, "algorithm"], [28, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 9, 2, 7, "named", "", false, false], [12, 12, 2, 7, "physical", "", false, false], [12, 12, 2, 7, "role", "", false, false], [12, 12, 18, 19, "role", "teams_up_with", false, false], [12, 12, 22, 25, "usage", "", false, false], [14, 16, 2, 7, "physical", "", false, false], [14, 16, 2, 7, "role", "", false, false], [14, 16, 18, 19, "role", "teams_up_with", false, false], [14, 16, 22, 25, "usage", "", false, false], [18, 19, 2, 7, "physical", "", false, false], [18, 19, 2, 7, "role", "", false, false], [18, 19, 22, 25, "usage", "", false, false], [22, 25, 28, 33, "related-to", "used_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["At", "the", "2006", "European", "Conference", "on", "Computer", "Vision", "(", "ECCV", ")", ",", "Dalal", "and", "Triggs", "teamed", "up", "with", "Cordelia", "Schmid", "to", "apply", "HOG", "detectors", "to", "the", "problem", "of", "detecting", "people", "in", "movies", "and", "videos", "."], "sentence-detokenized": "At the 2006 European Conference on Computer Vision (ECCV), Dalal and Triggs teamed up with Cordelia Schmid to apply HOG detectors to the problem of detecting people in movies and videos.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 20], [21, 31], [32, 34], [35, 43], [44, 50], [51, 52], [52, 56], [56, 57], [57, 58], [59, 64], [65, 68], [69, 75], [76, 82], [83, 85], [86, 90], [91, 99], [100, 106], [107, 109], [110, 115], [116, 119], [120, 129], [130, 132], [133, 136], [137, 144], [145, 147], [148, 157], [158, 164], [165, 167], [168, 174], [175, 178], [179, 185], [185, 186]]}
{"doc_key": "ai-test-429", "ner": [[3, 3, "metrics"], [5, 5, "metrics"], [11, 12, "task"], [19, 21, "metrics"], [23, 23, "metrics"], [29, 29, "metrics"], [33, 35, "metrics"], [37, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 3, 11, 12, "related-to", "measured_with", false, false], [5, 5, 11, 12, "related-to", "measured_with", false, false], [19, 21, 11, 12, "related-to", "measured_with", false, false], [23, 23, 19, 21, "named", "", false, false], [29, 29, 19, 21, "named", "", false, false], [37, 37, 33, 35, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "addition", "to", "sensitivity", "and", "specificity", ",", "the", "performance", "of", "a", "binary", "classification", "test", "can", "be", "measured", "using", "the", "positive", "predictive", "value", "(", "PPV", ")", ",", "also", "known", "as", "accuracy", ",", "and", "the", "negative", "predictive", "value", "(", "NPV", ")", "."], "sentence-detokenized": "In addition to sensitivity and specificity, the performance of a binary classification test can be measured using the positive predictive value (PPV), also known as accuracy, and the negative predictive value (NPV).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 42], [42, 43], [44, 47], [48, 59], [60, 62], [63, 64], [65, 71], [72, 86], [87, 91], [92, 95], [96, 98], [99, 107], [108, 113], [114, 117], [118, 126], [127, 137], [138, 143], [144, 145], [145, 148], [148, 149], [149, 150], [151, 155], [156, 161], [162, 164], [165, 173], [173, 174], [175, 178], [179, 182], [183, 191], [192, 202], [203, 208], [209, 210], [210, 213], [213, 214], [214, 215]]}
{"doc_key": "ai-test-430", "ner": [[15, 17, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "models", "can", "partially", "take", "into", "account", "overlapping", "coincidences", "(", "for", "example", ",", "using", "the", "Jaccard", "index", "criterion", ")", "."], "sentence-detokenized": "Such models can partially take into account overlapping coincidences (for example, using the Jaccard index criterion).", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 25], [26, 30], [31, 35], [36, 43], [44, 55], [56, 68], [69, 70], [70, 73], [74, 81], [81, 82], [83, 88], [89, 92], [93, 100], [101, 106], [107, 116], [116, 117], [117, 118]]}
{"doc_key": "ai-test-431", "ner": [[21, 26, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Furthermore", ",", "in", "the", "case", "of", "single", "sample", "estimation", ",", "it", "demonstrates", "philosophical", "issues", "and", "possible", "misunderstandings", "in", "the", "use", "of", "maximum", "likelihood", "estimators", "and", "likelihood", "functions", "."], "sentence-detokenized": "Furthermore, in the case of single sample estimation, it demonstrates philosophical issues and possible misunderstandings in the use of maximum likelihood estimators and likelihood functions.", "token2charspan": [[0, 11], [11, 12], [13, 15], [16, 19], [20, 24], [25, 27], [28, 34], [35, 41], [42, 52], [52, 53], [54, 56], [57, 69], [70, 83], [84, 90], [91, 94], [95, 103], [104, 121], [122, 124], [125, 128], [129, 132], [133, 135], [136, 143], [144, 154], [155, 165], [166, 169], [170, 180], [181, 190], [190, 191]]}
