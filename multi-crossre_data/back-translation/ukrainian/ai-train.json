{"doc_key": "ai-train-1", "ner": [[1, 5, "product"], [11, 12, "field"], [14, 15, "task"], [17, 18, "task"], [22, 24, "task"], [28, 29, "field"], [30, 32, "researcher"], [34, 36, "researcher"], [38, 41, "researcher"], [43, 44, "researcher"], [48, 48, "researcher"], [50, 53, "researcher"], [55, 56, "researcher"], [58, 59, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[1, 5, 11, 12, "part-of", "", false, false], [1, 5, 11, 12, "usage", "", false, false], [1, 5, 14, 15, "part-of", "", false, false], [1, 5, 14, 15, "usage", "", false, false], [1, 5, 17, 18, "part-of", "", false, false], [1, 5, 17, 18, "usage", "", false, false], [1, 5, 28, 29, "part-of", "", false, false], [1, 5, 28, 29, "usage", "", false, false], [22, 24, 17, 18, "part-of", "", false, false], [22, 24, 17, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Popular", "opinion", "-", "based", "recommender", "system", "approaches", "use", "various", "techniques", "including", "text", "mining", ",", "information", "retrieval", ",", "sentiment", "analysis", "(", "see", "also", "Multimodal", "sentiment", "analysis", ")", ",", "and", "deep", "learning", "X.Y", ".", "Feng", ",", "H", ".", "Zhang", ",", "Y", ".", "J.", "Ren", ",", "P.H.", "Shang", ",", "Y", ".", "Zhu", ",", "Y", ".", "C.", "Liang", ",", "R.C.", "Guan", ",", "D.", "Xu", ",", "(", "2019", ")", ",", ",", "21", "(", "5", ")", ":", "e12957", "."], "sentence-detokenized": "Popular opinion-based recommender system approaches use various techniques including text mining, information retrieval, sentiment analysis (see also Multimodal sentiment analysis), and deep learning X.Y. Feng, H. Zhang, Y. J. Ren, P.H. Shang, Y. Zhu, Y. C. Liang, R.C. Guan, D. Xu, (2019),, 21 (5): e12957.", "token2charspan": [[0, 7], [8, 15], [15, 16], [16, 21], [22, 33], [34, 40], [41, 51], [52, 55], [56, 63], [64, 74], [75, 84], [85, 89], [90, 96], [96, 97], [98, 109], [110, 119], [119, 120], [121, 130], [131, 139], [140, 141], [141, 144], [145, 149], [150, 160], [161, 170], [171, 179], [179, 180], [180, 181], [182, 185], [186, 190], [191, 199], [200, 203], [203, 204], [205, 209], [209, 210], [211, 212], [212, 213], [214, 219], [219, 220], [221, 222], [222, 223], [224, 226], [227, 230], [230, 231], [232, 236], [237, 242], [242, 243], [244, 245], [245, 246], [247, 250], [250, 251], [252, 253], [253, 254], [255, 257], [258, 263], [263, 264], [265, 269], [270, 274], [274, 275], [276, 278], [279, 281], [281, 282], [283, 284], [284, 288], [288, 289], [289, 290], [290, 291], [292, 294], [295, 296], [296, 297], [297, 298], [298, 299], [300, 306], [306, 307]]}
{"doc_key": "ai-train-2", "ner": [[9, 12, "university"], [17, 18, "researcher"], [20, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 18, 9, 12, "physical", "", false, false], [17, 18, 9, 12, "role", "", false, false], [20, 21, 9, 12, "physical", "", false, false], [20, 21, 9, 12, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Proponents", "of", "procedural", "representation", "were", "mainly", "concentrated", "at", "the", "Massachusetts", "Institute", "of", "Technology", "under", "the", "leadership", "of", "Marvin", "Minsky", "and", "Seymour", "Papert", "."], "sentence-detokenized": "Proponents of procedural representation were mainly concentrated at the Massachusetts Institute of Technology under the leadership of Marvin Minsky and Seymour Papert.", "token2charspan": [[0, 10], [11, 13], [14, 24], [25, 39], [40, 44], [45, 51], [52, 64], [65, 67], [68, 71], [72, 85], [86, 95], [96, 98], [99, 109], [110, 115], [116, 119], [120, 130], [131, 133], [134, 140], [141, 147], [148, 151], [152, 159], [160, 166], [166, 167]]}
{"doc_key": "ai-train-3", "ner": [[10, 10, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "standard", "interface", "and", "the", "calculator", "interface", "are", "written", "in", "Java", "."], "sentence-detokenized": "The standard interface and the calculator interface are written in Java.", "token2charspan": [[0, 3], [4, 12], [13, 22], [23, 26], [27, 30], [31, 41], [42, 51], [52, 55], [56, 63], [64, 66], [67, 71], [71, 72]]}
{"doc_key": "ai-train-4", "ner": [[0, 0, "product"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 23, 23, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["Octave", "helps", "to", "numerically", "solve", "linear", "and", "nonlinear", "problems", "as", "well", "as", "perform", "other", "numerical", "experiments", "using", "software", "that", "is", "mostly", "compatible", "with", "MATLAB", "."], "sentence-detokenized": "Octave helps to numerically solve linear and nonlinear problems as well as perform other numerical experiments using software that is mostly compatible with MATLAB.", "token2charspan": [[0, 6], [7, 12], [13, 15], [16, 27], [28, 33], [34, 40], [41, 44], [45, 54], [55, 63], [64, 66], [67, 71], [72, 74], [75, 82], [83, 88], [89, 98], [99, 110], [111, 116], [117, 125], [126, 130], [131, 133], [134, 140], [141, 151], [152, 156], [157, 163], [163, 164]]}
{"doc_key": "ai-train-5", "ner": [[2, 6, "algorithm"], [9, 10, "misc"], [12, 13, "researcher"], [11, 21, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 6, 12, 13, "origin", "", false, false], [9, 10, 12, 13, "origin", "", false, false], [12, 13, 11, 21, "physical", "", false, false], [12, 13, 11, 21, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Variants", "of", "the", "backpropagation", "algorithm", ",", "as", "well", "as", "unsupervised", "methods", "by", "Jeff", "Hinton", "and", "his", "colleagues", "at", "the", "University", "of", "Toronto", ",", "can", "be", "used", "to", "train", "deep", ",", "highly", "nonlinear", "neural", "architectures", ",", "{{", "quote", "from", "the", "journal"], "sentence-detokenized": "Variants of the backpropagation algorithm, as well as unsupervised methods by Jeff Hinton and his colleagues at the University of Toronto, can be used to train deep, highly nonlinear neural architectures, {{quote from the journal", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 31], [32, 41], [41, 42], [43, 45], [46, 50], [51, 53], [54, 66], [67, 74], [75, 77], [78, 82], [83, 89], [90, 93], [94, 97], [98, 108], [109, 111], [112, 115], [116, 126], [127, 129], [130, 137], [137, 138], [139, 142], [143, 145], [146, 150], [151, 153], [154, 159], [160, 164], [164, 165], [166, 172], [173, 182], [183, 189], [190, 203], [203, 204], [205, 207], [207, 212], [213, 217], [218, 221], [222, 229]]}
{"doc_key": "ai-train-6", "ner": [[3, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["or", "equivalent", "using", "DCG", "notation", ":"], "sentence-detokenized": "or equivalent using DCG notation:", "token2charspan": [[0, 2], [3, 13], [14, 19], [20, 23], [24, 32], [32, 33]]}
{"doc_key": "ai-train-7", "ner": [[0, 3, "algorithm"], [7, 11, "algorithm"], [14, 17, "algorithm"], [20, 22, "algorithm"], [25, 25, "algorithm"], [27, 28, "algorithm"], [44, 47, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 7, 11, "type-of", "", false, false], [0, 3, 14, 17, "usage", "part-of?", true, false], [14, 17, 20, 22, "compare", "", false, false], [25, 25, 20, 22, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Self", "-", "organizing", "maps", "differ", "from", "other", "artificial", "neural", "networks", "in", "that", "they", "employ", "competitive", "learning", "(", "as", "opposed", "to", "error", "-correcting", "learning", "such", "as", "backpropagation", "with", "gradient", "descent", ")", ",", "and", "in", "the", "sense", "that", "they", "use", "the", "neighborhood", "function", "to", "preserve", "the", "topological", "properties", "of", "the", "input", "space", "."], "sentence-detokenized": "Self-organizing maps differ from other artificial neural networks in that they employ competitive learning (as opposed to error-correcting learning such as backpropagation with gradient descent), and in the sense that they use the neighborhood function to preserve the topological properties of the input space.", "token2charspan": [[0, 4], [4, 5], [5, 15], [16, 20], [21, 27], [28, 32], [33, 38], [39, 49], [50, 56], [57, 65], [66, 68], [69, 73], [74, 78], [79, 85], [86, 97], [98, 106], [107, 108], [108, 110], [111, 118], [119, 121], [122, 127], [127, 138], [139, 147], [148, 152], [153, 155], [156, 171], [172, 176], [177, 185], [186, 193], [193, 194], [194, 195], [196, 199], [200, 202], [203, 206], [207, 212], [213, 217], [218, 222], [223, 226], [227, 230], [231, 243], [244, 252], [253, 255], [256, 264], [265, 268], [269, 280], [281, 291], [292, 294], [295, 298], [299, 304], [305, 310], [310, 311]]}
{"doc_key": "ai-train-8", "ner": [[11, 16, "organisation"], [29, 30, "misc"], [39, 40, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Since", "the", "early", "1990s", ",", "several", "authoritative", "organizations", ",", "including", "the", "Society", "of", "Audio", "Engineers", ",", "have", "recommended", "that", "dynamic", "range", "measurements", "be", "made", "in", "the", "presence", "of", "an", "audio", "signal", ",", "which", "is", "then", "filtered", "out", "in", "the", "noise", "measurement", "used", "in", "determining", "dynamic", "range", ".", "This", "avoids", "questionable", "measurements", "based", "on", "the", "use", "of", "empty", "media", "or", "damping", "circuits", "."], "sentence-detokenized": "Since the early 1990s, several authoritative organizations, including the Society of Audio Engineers, have recommended that dynamic range measurements be made in the presence of an audio signal, which is then filtered out in the noise measurement used in determining dynamic range. This avoids questionable measurements based on the use of empty media or damping circuits.", "token2charspan": [[0, 5], [6, 9], [10, 15], [16, 21], [21, 22], [23, 30], [31, 44], [45, 58], [58, 59], [60, 69], [70, 73], [74, 81], [82, 84], [85, 90], [91, 100], [100, 101], [102, 106], [107, 118], [119, 123], [124, 131], [132, 137], [138, 150], [151, 153], [154, 158], [159, 161], [162, 165], [166, 174], [175, 177], [178, 180], [181, 186], [187, 193], [193, 194], [195, 200], [201, 203], [204, 208], [209, 217], [218, 221], [222, 224], [225, 228], [229, 234], [235, 246], [247, 251], [252, 254], [255, 266], [267, 274], [275, 280], [280, 281], [282, 286], [287, 293], [294, 306], [307, 319], [320, 325], [326, 328], [329, 332], [333, 336], [337, 339], [340, 345], [346, 351], [352, 354], [355, 362], [363, 371], [371, 372]]}
{"doc_key": "ai-train-9", "ner": [[5, 6, "misc"], [17, 18, "task"], [20, 20, "task"], [23, 24, "task"], [26, 27, "task"], [29, 34, "task"], [37, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6, 7], "relations": [[5, 6, 17, 18, "part-of", "concept_used_in", true, false], [5, 6, 20, 20, "part-of", "concept_used_in", false, false], [5, 6, 23, 24, "part-of", "concept_used_in", false, false], [5, 6, 26, 27, "part-of", "concept_used_in", false, false], [5, 6, 29, 34, "part-of", "concept_used_in", false, false], [5, 6, 37, 39, "part-of", "concept_used_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5, 6], "sentence": ["The", "techniques", "used", "in", "creating", "custom", "interfaces", "and", "using", "them", "for", "recognition", "are", "also", "used", "outside", "of", "face", "recognition", ":", "handwriting", "recognition", ",", "lip", "reading", ",", "voice", "recognition", ",", "sign", "language", "/", "hand", "gesture", "interpretation", ",", "and", "medical", "image", "analysis", "."], "sentence-detokenized": "The techniques used in creating custom interfaces and using them for recognition are also used outside of face recognition: handwriting recognition, lip reading, voice recognition, sign language/hand gesture interpretation, and medical image analysis.", "token2charspan": [[0, 3], [4, 14], [15, 19], [20, 22], [23, 31], [32, 38], [39, 49], [50, 53], [54, 59], [60, 64], [65, 68], [69, 80], [81, 84], [85, 89], [90, 94], [95, 102], [103, 105], [106, 110], [111, 122], [122, 123], [124, 135], [136, 147], [147, 148], [149, 152], [153, 160], [160, 161], [162, 167], [168, 179], [179, 180], [181, 185], [186, 194], [194, 195], [195, 199], [200, 207], [208, 222], [222, 223], [224, 227], [228, 235], [236, 241], [242, 250], [250, 251]]}
{"doc_key": "ai-train-10", "ner": [[0, 3, "organisation"], [8, 12, "organisation"], [14, 14, "organisation"], [21, 21, "organisation"], [27, 28, "organisation"], [31, 34, "organisation"], [37, 41, "organisation"], [43, 43, "organisation"], [48, 52, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[8, 12, 0, 3, "part-of", "", false, false], [14, 14, 8, 12, "named", "", false, false], [21, 21, 0, 3, "part-of", "", false, false], [27, 28, 0, 3, "part-of", "", false, false], [31, 34, 0, 3, "part-of", "", false, false], [37, 41, 0, 3, "part-of", "", false, false], [43, 43, 37, 41, "named", "", false, false], [48, 52, 0, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "National", "Science", "Foundation", "coordinated", "research", "from", "the", "National", "Aeronautics", "and", "Space", "Administration", "(", "NASA", ")", ",", "the", "U.S.", "Department", "of", "Energy", ",", "the", "U.S.", "Department", "of", "Commerce", "NIST", ",", "the", "U.S.", "Department", "of", "Defense", ",", "the", "Defense", "Advanced", "Research", "Projects", "Agency", "(", "DARPA", ")", ",", "and", "the", "Office", "of", "Naval", "Research", "to", "inform", "strategic", "planners", "in", "their", "deliberations", "."], "sentence-detokenized": "The National Science Foundation coordinated research from the National Aeronautics and Space Administration (NASA), the U.S. Department of Energy, the U.S. Department of Commerce NIST, the U.S. Department of Defense, the Defense Advanced Research Projects Agency (DARPA), and the Office of Naval Research to inform strategic planners in their deliberations.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 31], [32, 43], [44, 52], [53, 57], [58, 61], [62, 70], [71, 82], [83, 86], [87, 92], [93, 107], [108, 109], [109, 113], [113, 114], [114, 115], [116, 119], [120, 124], [125, 135], [136, 138], [139, 145], [145, 146], [147, 150], [151, 155], [156, 166], [167, 169], [170, 178], [179, 183], [183, 184], [185, 188], [189, 193], [194, 204], [205, 207], [208, 215], [215, 216], [217, 220], [221, 228], [229, 237], [238, 246], [247, 255], [256, 262], [263, 264], [264, 269], [269, 270], [270, 271], [272, 275], [276, 279], [280, 286], [287, 289], [290, 295], [296, 304], [305, 307], [308, 314], [315, 324], [325, 333], [334, 336], [337, 342], [343, 356], [356, 357]]}
{"doc_key": "ai-train-11", "ner": [[5, 6, "metrics"], [9, 11, "algorithm"], [14, 16, "researcher"], [21, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 9, 11, "part-of", "", false, false], [14, 16, 21, 22, "related-to", "added_appendix_to_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "fast", "method", "for", "computing", "maximum", "likelihood", "estimates", "for", "a", "probit", "model", "was", "proposed", "by", "Ronald", "Fisher", "as", "an", "extension", "of", "Bliss", "'s", "work", "in", "1935", "."], "sentence-detokenized": "A fast method for computing maximum likelihood estimates for a probit model was proposed by Ronald Fisher as an extension of Bliss's work in 1935.", "token2charspan": [[0, 1], [2, 6], [7, 13], [14, 17], [18, 27], [28, 35], [36, 46], [47, 56], [57, 60], [61, 62], [63, 69], [70, 75], [76, 79], [80, 88], [89, 91], [92, 98], [99, 105], [106, 108], [109, 111], [112, 121], [122, 124], [125, 130], [130, 132], [133, 137], [138, 140], [141, 145], [145, 146]]}
{"doc_key": "ai-train-12", "ner": [[12, 13, "product"], [16, 17, "product"], [20, 20, "organisation"], [22, 22, "product"], [25, 25, "organisation"], [27, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[22, 22, 16, 17, "usage", "uses_software", false, false], [22, 22, 20, 20, "artifact", "", false, false], [22, 22, 27, 28, "named", "", false, false], [27, 28, 25, 25, "artifact", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Some", "of", "these", "programs", "are", "available", "on", "the", "Internet", ",", "such", "as", "Google", "Translate", "and", "the", "SYSTRAN", "system", "that", "powers", "AltaVista", "'s", "BabelFish", "(", "now", "Yahoo", "'s", "Babelfish", "since", "May", "9", ",", "2008", ")", "."], "sentence-detokenized": "Some of these programs are available on the Internet, such as Google Translate and the SYSTRAN system that powers AltaVista's BabelFish (now Yahoo's Babelfish since May 9, 2008).", "token2charspan": [[0, 4], [5, 7], [8, 13], [14, 22], [23, 26], [27, 36], [37, 39], [40, 43], [44, 52], [52, 53], [54, 58], [59, 61], [62, 68], [69, 78], [79, 82], [83, 86], [87, 94], [95, 101], [102, 106], [107, 113], [114, 123], [123, 125], [126, 135], [136, 137], [137, 140], [141, 146], [146, 148], [149, 158], [159, 164], [165, 168], [169, 170], [170, 171], [172, 176], [176, 177], [177, 178]]}
{"doc_key": "ai-train-13", "ner": [[3, 3, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [20, 22, "field"], [26, 27, "misc"], [31, 32, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 3, 20, 22, "related-to", "", true, false], [3, 3, 26, 27, "related-to", "", true, false], [3, 3, 31, 32, "related-to", "", true, false], [7, 8, 20, 22, "related-to", "", true, false], [7, 8, 26, 27, "related-to", "", true, false], [7, 8, 31, 32, "related-to", "", true, false], [10, 11, 20, 22, "related-to", "", true, false], [10, 11, 26, 27, "related-to", "", true, false], [10, 11, 31, 32, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In", "2002", ",", "Hutter", ",", "together", "with", "J\u00fcrgen", "Schmidhuber", "and", "Shane", "Legg", ",", "developed", "and", "published", "a", "mathematical", "theory", "of", "artificial", "general", "intelligence", "based", "on", "idealized", "intelligent", "agents", "and", "reward", "-motivated", "reinforcement", "learning", "."], "sentence-detokenized": "In 2002, Hutter, together with J\u00fcrgen Schmidhuber and Shane Legg, developed and published a mathematical theory of artificial general intelligence based on idealized intelligent agents and reward-motivated reinforcement learning.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [15, 16], [17, 25], [26, 30], [31, 37], [38, 49], [50, 53], [54, 59], [60, 64], [64, 65], [66, 75], [76, 79], [80, 89], [90, 91], [92, 104], [105, 111], [112, 114], [115, 125], [126, 133], [134, 146], [147, 152], [153, 155], [156, 165], [166, 177], [178, 184], [185, 188], [189, 195], [195, 205], [206, 219], [220, 228], [228, 229]]}
{"doc_key": "ai-train-14", "ner": [[11, 11, "metrics"], [13, 19, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 11, 13, 19, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "most", "common", "way", "is", "to", "use", "the", "so", "-", "called", "ROUGE", "(", "Recall", "-", "Oriented", "Understudy", "for", "Gisting", "Evaluation", ")", "."], "sentence-detokenized": "The most common way is to use the so-called ROUGE (Recall-Oriented Understudy for Gisting Evaluation).", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 19], [20, 22], [23, 25], [26, 29], [30, 33], [34, 36], [36, 37], [37, 43], [44, 49], [50, 51], [51, 57], [57, 58], [58, 66], [67, 77], [78, 81], [82, 89], [90, 100], [100, 101], [101, 102]]}
{"doc_key": "ai-train-15", "ner": [[0, 0, "product"], [13, 13, "programlang"], [15, 15, "programlang"], [18, 19, "researcher"], [21, 22, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 13, 13, "related-to", "", false, false], [0, 0, 15, 15, "related-to", "", false, false], [18, 19, 21, 22, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["RapidMiner", "provides", "training", "schemes", ",", "models", "and", "algorithms", "and", "can", "be", "extended", "with", "R", "and", "Python", "scripts", ".", "David", "Norris", ",", "Bloor", "Research", ",", "November", "13", ",", "2013", "."], "sentence-detokenized": "RapidMiner provides training schemes, models and algorithms and can be extended with R and Python scripts. David Norris, Bloor Research, November 13, 2013.", "token2charspan": [[0, 10], [11, 19], [20, 28], [29, 36], [36, 37], [38, 44], [45, 48], [49, 59], [60, 63], [64, 67], [68, 70], [71, 79], [80, 84], [85, 86], [87, 90], [91, 97], [98, 105], [105, 106], [107, 112], [113, 119], [119, 120], [121, 126], [127, 135], [135, 136], [137, 145], [146, 148], [148, 149], [150, 154], [154, 155]]}
{"doc_key": "ai-train-16", "ner": [[4, 5, "programlang"], [8, 9, "product"]], "ner_mapping_to_source": [4, 5], "relations": [[8, 9, 4, 5, "general-affiliation", "", true, false]], "relations_mapping_to_source": [4], "sentence": ["But", "the", "newest", "fully", "Java", "-oriented", "version", "(", "Weka", "3", ")", ",", "whose", "development", "began", "in", "1997", ",", "is", "now", "used", "in", "many", "different", "applications", ",", "including", "education", "and", "research", "."], "sentence-detokenized": "But the newest fully Java-oriented version (Weka 3), whose development began in 1997, is now used in many different applications, including education and research.", "token2charspan": [[0, 3], [4, 7], [8, 14], [15, 20], [21, 25], [25, 34], [35, 42], [43, 44], [44, 48], [49, 50], [50, 51], [51, 52], [53, 58], [59, 70], [71, 76], [77, 79], [80, 84], [84, 85], [86, 88], [89, 92], [93, 97], [98, 100], [101, 105], [106, 115], [116, 128], [128, 129], [130, 139], [140, 149], [150, 153], [154, 162], [162, 163]]}
{"doc_key": "ai-train-17", "ner": [[0, 0, "product"], [14, 22, "misc"], [26, 28, "misc"], [31, 40, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 22, 0, 0, "topic", "", false, false], [14, 22, 26, 28, "win-defeat", "", false, false], [26, 28, 31, 40, "temporal", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Evrisko", "made", "many", "interesting", "discoveries", "and", "received", "considerable", "recognition", ",", "and", "his", "work", "\"", "Heuristics", ":", "A", "Theory", "and", "Study", "of", "Heuristic", "Rules", "\"", "won", "the", "best", "paper", "award", "at", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "competition", "in", "1982", "."], "sentence-detokenized": "Evrisko made many interesting discoveries and received considerable recognition, and his work \"Heuristics: A Theory and Study of Heuristic Rules\" won the best paper award at the Association for the Advancement of Artificial Intelligence competition in 1982.", "token2charspan": [[0, 7], [8, 12], [13, 17], [18, 29], [30, 41], [42, 45], [46, 54], [55, 67], [68, 79], [79, 80], [81, 84], [85, 88], [89, 93], [94, 95], [95, 105], [105, 106], [107, 108], [109, 115], [116, 119], [120, 125], [126, 128], [129, 138], [139, 144], [144, 145], [146, 149], [150, 153], [154, 158], [159, 164], [165, 170], [171, 173], [174, 177], [178, 189], [190, 193], [194, 197], [198, 209], [210, 212], [213, 223], [224, 236], [237, 248], [249, 251], [252, 256], [256, 257]]}
{"doc_key": "ai-train-18", "ner": [[11, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "order", "to", "take", "into", "account", "several", "objects", ",", "a", "separate", "loop", "loss", "is", "calculated", "for", "each", "capsule", "."], "sentence-detokenized": "In order to take into account several objects, a separate loop loss is calculated for each capsule.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 16], [17, 21], [22, 29], [30, 37], [38, 45], [45, 46], [47, 48], [49, 57], [58, 62], [63, 67], [68, 70], [71, 81], [82, 85], [86, 90], [91, 98], [98, 99]]}
{"doc_key": "ai-train-19", "ner": [[8, 10, "product"], [12, 14, "product"], [16, 17, "product"], [19, 21, "product"], [23, 25, "product"], [28, 28, "product"], [37, 42, "product"], [45, 46, "product"], [48, 49, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[8, 10, 28, 28, "type-of", "", false, false], [12, 14, 28, 28, "type-of", "", false, false], [16, 17, 28, 28, "type-of", "", false, false], [19, 21, 28, 28, "type-of", "", false, false], [23, 25, 28, 28, "type-of", "", false, false], [45, 46, 37, 42, "type-of", "", false, false], [48, 49, 37, 42, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["With", "the", "advent", "of", "conversational", "assistants", "such", "as", "Apple", "'s", "Siri", ",", "Amazon", "'s", "Alexa", ",", "Google", "Assistant", ",", "Microsoft", "'s", "Cortana", "and", "Samsung", "'s", "Bixby", ",", "voice", "portals", "can", "now", "be", "accessed", "via", "mobile", "devices", "and", "long", "-", "range", "voice", "smart", "speakers", "such", "as", "Amazon", "Echo", "and", "Google", "Home", "."], "sentence-detokenized": "With the advent of conversational assistants such as Apple's Siri, Amazon's Alexa, Google Assistant, Microsoft's Cortana and Samsung's Bixby, voice portals can now be accessed via mobile devices and long-range voice smart speakers such as Amazon Echo and Google Home.", "token2charspan": [[0, 4], [5, 8], [9, 15], [16, 18], [19, 33], [34, 44], [45, 49], [50, 52], [53, 58], [58, 60], [61, 65], [65, 66], [67, 73], [73, 75], [76, 81], [81, 82], [83, 89], [90, 99], [99, 100], [101, 110], [110, 112], [113, 120], [121, 124], [125, 132], [132, 134], [135, 140], [140, 141], [142, 147], [148, 155], [156, 159], [160, 163], [164, 166], [167, 175], [176, 179], [180, 186], [187, 194], [195, 198], [199, 203], [203, 204], [204, 209], [210, 215], [216, 221], [222, 230], [231, 235], [236, 238], [239, 245], [246, 250], [251, 254], [255, 261], [262, 266], [266, 267]]}
{"doc_key": "ai-train-20", "ner": [[3, 3, "field"], [5, 7, "algorithm"], [9, 11, "algorithm"], [13, 14, "algorithm"], [16, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 7, 3, 3, "type-of", "", false, false], [9, 11, 3, 3, "type-of", "", false, false], [13, 14, 3, 3, "type-of", "", false, false], [16, 16, 3, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Examples", "of", "supervised", "learning", "are", "naive", "Bayes", "classifier", ",", "support", "vector", "machine", ",", "Gaussian", "mixture", "and", "networks", "."], "sentence-detokenized": "Examples of supervised learning are naive Bayes classifier, support vector machine, Gaussian mixture and networks.", "token2charspan": [[0, 8], [9, 11], [12, 22], [23, 31], [32, 35], [36, 41], [42, 47], [48, 58], [58, 59], [60, 67], [68, 74], [75, 82], [82, 83], [84, 92], [93, 100], [101, 104], [105, 113], [113, 114]]}
{"doc_key": "ai-train-21", "ner": [[7, 7, "algorithm"], [30, 32, "algorithm"], [34, 34, "task"], [39, 40, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 30, 32, "part-of", "", true, false], [39, 40, 34, 34, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["You", "can", "use", "an", "on", "-", "screen", "algorithm", "to", "derive", "math", "O", "(", "\\", "sqrt", "{", "T", "}", ")", "/", "math", "the", "regret", "bounds", "for", "the", "online", "version", "of", "the", "support", "vector", "machine", "for", "classification", ",", "which", "uses", "the", "loop", "loss", "math", "v", "_t", "(", "w", ")", "=\\", "max", "\\", "{", "0", ",", "1", "-", "y", "_t", "(", "w", "\\", "cdot", "x", "_t", ")", "\\}", "/", "math"], "sentence-detokenized": "You can use an on-screen algorithm to derive math O(\\ sqrt {T}) / math the regret bounds for the online version of the support vector machine for classification, which uses the loop loss math v _t (w) =\\ max\\ {0, 1 - y _t (w\\ cdot x _t)\\} / math", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 17], [17, 18], [18, 24], [25, 34], [35, 37], [38, 44], [45, 49], [50, 51], [51, 52], [52, 53], [54, 58], [59, 60], [60, 61], [61, 62], [62, 63], [64, 65], [66, 70], [71, 74], [75, 81], [82, 88], [89, 92], [93, 96], [97, 103], [104, 111], [112, 114], [115, 118], [119, 126], [127, 133], [134, 141], [142, 145], [146, 160], [160, 161], [162, 167], [168, 172], [173, 176], [177, 181], [182, 186], [187, 191], [192, 193], [194, 196], [197, 198], [198, 199], [199, 200], [201, 203], [204, 207], [207, 208], [209, 210], [210, 211], [211, 212], [213, 214], [215, 216], [217, 218], [219, 221], [222, 223], [223, 224], [224, 225], [226, 230], [231, 232], [233, 235], [235, 236], [236, 238], [239, 240], [241, 245]]}
{"doc_key": "ai-train-22", "ner": [[2, 3, "task"], [5, 6, "task"], [8, 8, "task"], [10, 11, "task"], [13, 14, "task"], [16, 17, "task"], [19, 20, "task"], [22, 24, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Applications", "include", "object", "recognition", ",", "robotic", "mapping", "and", "navigation", ",", "image", "stitching", ",", "3D", "modeling", ",", "gesture", "recognition", ",", "video", "tracking", ",", "individual", "wildlife", "identification", ",", "and", "match", "tracking", "."], "sentence-detokenized": "Applications include object recognition, robotic mapping and navigation, image stitching, 3D modeling, gesture recognition, video tracking, individual wildlife identification, and match tracking.", "token2charspan": [[0, 12], [13, 20], [21, 27], [28, 39], [39, 40], [41, 48], [49, 56], [57, 60], [61, 71], [71, 72], [73, 78], [79, 88], [88, 89], [90, 92], [93, 101], [101, 102], [103, 110], [111, 122], [122, 123], [124, 129], [130, 138], [138, 139], [140, 150], [151, 159], [160, 174], [174, 175], [176, 179], [180, 185], [186, 194], [194, 195]]}
{"doc_key": "ai-train-23", "ner": [[9, 10, "task"], [16, 17, "university"], [19, 20, "university"], [23, 24, "university"], [26, 27, "university"], [31, 33, "university"], [35, 37, "university"], [40, 43, "university"], [44, 44, "university"], [46, 51, "university"], [53, 53, "university"], [56, 59, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[9, 10, 16, 17, "related-to", "", true, false], [9, 10, 19, 20, "related-to", "", true, false], [9, 10, 23, 24, "related-to", "", true, false], [9, 10, 26, 27, "related-to", "", true, false], [9, 10, 31, 33, "related-to", "", true, false], [9, 10, 35, 37, "related-to", "", true, false], [9, 10, 40, 43, "related-to", "", true, false], [9, 10, 44, 44, "related-to", "", true, false], [9, 10, 46, 51, "related-to", "", true, false], [9, 10, 53, 53, "related-to", "", true, false], [9, 10, 56, 59, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["A", "number", "of", "groups", "and", "companies", "are", "engaged", "in", "pose", "estimation", "research", ",", "including", "groups", "at", "Brown", "University", ",", "Carnegie", "Mellon", "University", ",", "MPI", "Saarbrucken", ",", "Stanford", "University", ",", "University", "of", "California", "San", "Diego", ",", "University", "of", "Toronto", ",", "Ecole", "Centrale", "Paris", ",", "ETH", "Zurich", ",", "National", "University", "of", "Science", "and", "Technology", "(", "NUST", ")", "and", "University", "of", "California", "Irvine", "."], "sentence-detokenized": "A number of groups and companies are engaged in pose estimation research, including groups at Brown University, Carnegie Mellon University, MPI Saarbrucken, Stanford University, University of California San Diego, University of Toronto, Ecole Centrale Paris, ETH Zurich, National University of Science and Technology (NUST) and University of California Irvine.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 18], [19, 22], [23, 32], [33, 36], [37, 44], [45, 47], [48, 52], [53, 63], [64, 72], [72, 73], [74, 83], [84, 90], [91, 93], [94, 99], [100, 110], [110, 111], [112, 120], [121, 127], [128, 138], [138, 139], [140, 143], [144, 155], [155, 156], [157, 165], [166, 176], [176, 177], [178, 188], [189, 191], [192, 202], [203, 206], [207, 212], [212, 213], [214, 224], [225, 227], [228, 235], [235, 236], [237, 242], [243, 251], [252, 257], [257, 258], [259, 262], [263, 269], [269, 270], [271, 279], [280, 290], [291, 293], [294, 301], [302, 305], [306, 316], [317, 318], [318, 322], [322, 323], [324, 327], [328, 338], [339, 341], [342, 352], [353, 359], [359, 360]]}
{"doc_key": "ai-train-24", "ner": [[0, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "sigmoidal", "Cross", "entropy", "loss", "function", "is", "used", "to", "predict", "K", "independent", "probability", "values", "with", "an", "accuracy", "of", "0.1", "/", "math", "."], "sentence-detokenized": "The sigmoidal Cross entropy loss function is used to predict K independent probability values with an accuracy of 0.1 / math.", "token2charspan": [[0, 3], [4, 13], [14, 19], [20, 27], [28, 32], [33, 41], [42, 44], [45, 49], [50, 52], [53, 60], [61, 62], [63, 74], [75, 86], [87, 93], [94, 98], [99, 101], [102, 110], [111, 113], [114, 117], [118, 119], [120, 124], [124, 125]]}
{"doc_key": "ai-train-25", "ner": [[13, 14, "misc"], [17, 17, "field"], [19, 20, "field"], [6, 27, "university"], [28, 28, "country"], [31, 33, "misc"], [36, 39, "university"], [41, 41, "country"], [8, 8, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[13, 14, 17, 17, "topic", "", false, false], [13, 14, 19, 20, "topic", "", false, false], [13, 14, 6, 27, "physical", "", true, false], [6, 27, 28, 28, "physical", "", false, false], [31, 33, 36, 39, "physical", "", true, false], [36, 39, 41, 41, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Before", "becoming", "a", "professor", "at", "the", "University", "of", "Cambridge", ",", "he", "held", "the", "Johann", "Bernoulli", "Chair", "of", "Mathematics", "and", "Computer", "Science", "at", "the", "University", "of", "Groningen", "in", "the", "Netherlands", "and", "the", "Toshiba", "Endowed", "Chair", "at", "the", "Tokyo", "Institute", "of", "Technology", "in", "Japan", "."], "sentence-detokenized": "Before becoming a professor at the University of Cambridge, he held the Johann Bernoulli Chair of Mathematics and Computer Science at the University of Groningen in the Netherlands and the Toshiba Endowed Chair at the Tokyo Institute of Technology in Japan.", "token2charspan": [[0, 6], [7, 15], [16, 17], [18, 27], [28, 30], [31, 34], [35, 45], [46, 48], [49, 58], [58, 59], [60, 62], [63, 67], [68, 71], [72, 78], [79, 88], [89, 94], [95, 97], [98, 109], [110, 113], [114, 122], [123, 130], [131, 133], [134, 137], [138, 148], [149, 151], [152, 161], [162, 164], [165, 168], [169, 180], [181, 184], [185, 188], [189, 196], [197, 204], [205, 210], [211, 213], [214, 217], [218, 223], [224, 233], [234, 236], [237, 247], [248, 250], [251, 256], [256, 257]]}
{"doc_key": "ai-train-26", "ner": [[8, 9, "algorithm"], [13, 16, "algorithm"], [18, 18, "algorithm"], [26, 27, "researcher"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 9, 13, 16, "usage", "", true, false], [13, 16, 26, 27, "origin", "", false, false], [13, 16, 29, 30, "origin", "", false, false], [18, 18, 13, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Another", "technique", "that", "is", "particularly", "commonly", "used", "for", "recurrent", "neural", "networks", "is", "the", "Long", "Short", "Term", "Memory", "(", "LSTM", ")", "network", ",", "developed", "in", "1997", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Another technique that is particularly commonly used for recurrent neural networks is the Long Short Term Memory (LSTM) network, developed in 1997 by Sepp Hochreiter and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 7], [8, 17], [18, 22], [23, 25], [26, 38], [39, 47], [48, 52], [53, 56], [57, 66], [67, 73], [74, 82], [83, 85], [86, 89], [90, 94], [95, 100], [101, 105], [106, 112], [113, 114], [114, 118], [118, 119], [120, 127], [127, 128], [129, 138], [139, 141], [142, 146], [147, 149], [150, 154], [155, 165], [166, 169], [170, 176], [177, 188], [188, 189]]}
{"doc_key": "ai-train-27", "ner": [[4, 5, "programlang"], [8, 9, "product"], [15, 15, "product"], [43, 43, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 4, 5, "general-affiliation", "", false, false], [8, 9, 15, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "inclusion", "of", "a", "C", "++", "interpreter", "(", "CI", "NT", "up", "to", "version", "5.34", ",", "Cling", "since", "version", "6", ")", "makes", "this", "package", "very", "versatile", "as", "it", "can", "be", "used", "in", "interactive", ",", "scripted", "and", "compiled", "modes", "similar", "to", "commercial", "products", "such", "as", "MATLAB", "."], "sentence-detokenized": "The inclusion of a C++ interpreter (CINT up to version 5.34, Cling since version 6) makes this package very versatile as it can be used in interactive, scripted and compiled modes similar to commercial products such as MATLAB.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 18], [19, 20], [20, 22], [23, 34], [35, 36], [36, 38], [38, 40], [41, 43], [44, 46], [47, 54], [55, 59], [59, 60], [61, 66], [67, 72], [73, 80], [81, 82], [82, 83], [84, 89], [90, 94], [95, 102], [103, 107], [108, 117], [118, 120], [121, 123], [124, 127], [128, 130], [131, 135], [136, 138], [139, 150], [150, 151], [152, 160], [161, 164], [165, 173], [174, 179], [180, 187], [188, 190], [191, 201], [202, 210], [211, 215], [216, 218], [219, 225], [225, 226]]}
{"doc_key": "ai-train-28", "ner": [[0, 2, "product"], [26, 28, "field"], [32, 34, "task"], [36, 38, "task"], [40, 41, "task"], [44, 45, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 26, 28, "related-to", "", false, false], [32, 34, 26, 28, "part-of", "", false, false], [36, 38, 26, 28, "part-of", "", false, false], [40, 41, 26, 28, "part-of", "", false, false], [44, 45, 26, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Voice", "user", "interfaces", ",", "which", "interpret", "and", "manage", "the", "state", "of", "a", "conversation", ",", "are", "challenging", "to", "develop", "due", "to", "the", "inherent", "difficulty", "of", "integrating", "complex", "natural", "language", "processing", "tasks", "such", "as", "basic", "reference", "discrimination", ",", "named", "object", "recognition", ",", "information", "retrieval", ",", "and", "dialogue", "management", "."], "sentence-detokenized": "Voice user interfaces, which interpret and manage the state of a conversation, are challenging to develop due to the inherent difficulty of integrating complex natural language processing tasks such as basic reference discrimination, named object recognition, information retrieval, and dialogue management.", "token2charspan": [[0, 5], [6, 10], [11, 21], [21, 22], [23, 28], [29, 38], [39, 42], [43, 49], [50, 53], [54, 59], [60, 62], [63, 64], [65, 77], [77, 78], [79, 82], [83, 94], [95, 97], [98, 105], [106, 109], [110, 112], [113, 116], [117, 125], [126, 136], [137, 139], [140, 151], [152, 159], [160, 167], [168, 176], [177, 187], [188, 193], [194, 198], [199, 201], [202, 207], [208, 217], [218, 232], [232, 233], [234, 239], [240, 246], [247, 258], [258, 259], [260, 271], [272, 281], [281, 282], [283, 286], [287, 295], [296, 306], [306, 307]]}
{"doc_key": "ai-train-29", "ner": [[8, 9, "algorithm"], [12, 14, "algorithm"], [22, 23, "researcher"], [26, 30, "organisation"], [36, 37, "field"], [39, 40, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 22, 23, "origin", "", false, false], [8, 9, 36, 37, "part-of", "", false, false], [8, 9, 39, 40, "part-of", "", false, false], [12, 14, 22, 23, "origin", "", false, false], [12, 14, 36, 37, "part-of", "", false, false], [12, 14, 39, 40, "part-of", "", false, false], [22, 23, 26, 30, "physical", "", false, false], [22, 23, 26, 30, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["In", "the", "period", "from", "2009", "to", "2012", ",", "recurrent", "neural", "networks", "and", "deep", "feedforward", "neural", "networks", "developed", "in", "the", "research", "group", "of", "J\u00fcrgen", "Schmidhuber", "at", "the", "Swiss", "Artificial", "Intelligence", "Laboratory", "IDSIA", "won", "eight", "international", "competitions", "in", "pattern", "recognition", "and", "machine", "learning", "."], "sentence-detokenized": "In the period from 2009 to 2012, recurrent neural networks and deep feedforward neural networks developed in the research group of J\u00fcrgen Schmidhuber at the Swiss Artificial Intelligence Laboratory IDSIA won eight international competitions in pattern recognition and machine learning.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 18], [19, 23], [24, 26], [27, 31], [31, 32], [33, 42], [43, 49], [50, 58], [59, 62], [63, 67], [68, 79], [80, 86], [87, 95], [96, 105], [106, 108], [109, 112], [113, 121], [122, 127], [128, 130], [131, 137], [138, 149], [150, 152], [153, 156], [157, 162], [163, 173], [174, 186], [187, 197], [198, 203], [204, 207], [208, 213], [214, 227], [228, 240], [241, 243], [244, 251], [252, 263], [264, 267], [268, 275], [276, 284], [284, 285]]}
{"doc_key": "ai-train-30", "ner": [[1, 3, "product"], [6, 7, "product"], [9, 10, "product"], [14, 17, "task"], [16, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 3, 6, 7, "usage", "", false, false], [1, 3, 9, 10, "usage", "", false, false], [1, 3, 14, 17, "usage", "", true, false], [1, 3, 16, 16, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Modern", "Windows", "desktop", "systems", "can", "use", "SAPI", "4", "and", "SAPI", "5", "components", "to", "support", "speech", "and", "speech", "synthesis", "."], "sentence-detokenized": "Modern Windows desktop systems can use SAPI 4 and SAPI 5 components to support speech and speech synthesis.", "token2charspan": [[0, 6], [7, 14], [15, 22], [23, 30], [31, 34], [35, 38], [39, 43], [44, 45], [46, 49], [50, 54], [55, 56], [57, 67], [68, 70], [71, 78], [79, 85], [86, 89], [90, 96], [97, 106], [106, 107]]}
{"doc_key": "ai-train-31", "ner": [[10, 12, "field"], [13, 15, "university"], [22, 25, "field"], [26, 32, "university"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [[22, 25, 26, 32, "related-to", "", true, false]], "relations_mapping_to_source": [2], "sentence": ["He", "received", "two", "honorary", "degrees", ":", "an", "honorary", "doctorate", "in", "psychology", "from", "the", "University", "of", "Padua", "in", "1995", "and", "a", "doctorate", "in", "industrial", "design", "and", "engineering", "from", "Delft", "University", "of", "Technology", "in", "Delft", "."], "sentence-detokenized": "He received two honorary degrees: an honorary doctorate in psychology from the University of Padua in 1995 and a doctorate in industrial design and engineering from Delft University of Technology in Delft.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 24], [25, 32], [32, 33], [34, 36], [37, 45], [46, 55], [56, 58], [59, 69], [70, 74], [75, 78], [79, 89], [90, 92], [93, 98], [99, 101], [102, 106], [107, 110], [111, 112], [113, 122], [123, 125], [126, 136], [137, 143], [144, 147], [148, 159], [160, 164], [165, 170], [171, 181], [182, 184], [185, 195], [196, 198], [199, 204], [204, 205]]}
{"doc_key": "ai-train-32", "ner": [[3, 4, "researcher"], [10, 13, "organisation"], [15, 15, "location"], [17, 17, "researcher"], [29, 29, "misc"], [39, 42, "misc"], [55, 56, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 4, 10, 13, "physical", "", false, false], [3, 4, 10, 13, "role", "", false, false], [10, 13, 15, 15, "physical", "", false, false], [17, 17, 29, 29, "related-to", "works_with", true, false], [17, 17, 39, 42, "related-to", "works_with", true, false], [17, 17, 55, 56, "related-to", "works_with", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["With", "longtime", "collaborator", "Laurent", "Cohen", ",", "a", "neurologist", "at", "the", "Piti\u00e9", "-", "Salp\u00eatri\u00e8re", "Hospital", "in", "Paris", ",", "Dehen", "also", "identified", "patients", "with", "lesions", "in", "different", "areas", "of", "the", "parietal", "lobe", "with", "impaired", "multiplication", "but", "preserved", "subtraction", "(", "associated", "with", "inferior", "parietal", "lobe", "lesions", ")", "and", "others", "with", "impaired", "subtraction", "but", "preserved", "multiplication", "(", "associated", "with", "intraparietal", "sulcus", "lesions", ")", "."], "sentence-detokenized": "With longtime collaborator Laurent Cohen, a neurologist at the Piti\u00e9-Salp\u00eatri\u00e8re Hospital in Paris, Dehen also identified patients with lesions in different areas of the parietal lobe with impaired multiplication but preserved subtraction (associated with inferior parietal lobe lesions) and others with impaired subtraction but preserved multiplication (associated with intraparietal sulcus lesions).", "token2charspan": [[0, 4], [5, 13], [14, 26], [27, 34], [35, 40], [40, 41], [42, 43], [44, 55], [56, 58], [59, 62], [63, 68], [68, 69], [69, 80], [81, 89], [90, 92], [93, 98], [98, 99], [100, 105], [106, 110], [111, 121], [122, 130], [131, 135], [136, 143], [144, 146], [147, 156], [157, 162], [163, 165], [166, 169], [170, 178], [179, 183], [184, 188], [189, 197], [198, 212], [213, 216], [217, 226], [227, 238], [239, 240], [240, 250], [251, 255], [256, 264], [265, 273], [274, 278], [279, 286], [286, 287], [288, 291], [292, 298], [299, 303], [304, 312], [313, 324], [325, 328], [329, 338], [339, 353], [354, 355], [355, 365], [366, 370], [371, 384], [385, 391], [392, 399], [399, 400], [400, 401]]}
{"doc_key": "ai-train-33", "ner": [[6, 8, "product"], [14, 18, "misc"], [23, 31, "misc"], [36, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 18, 6, 8, "topic", "", false, false], [23, 31, 6, 8, "topic", "", false, false], [36, 38, 6, 8, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["More", "recently", ",", "fictional", "depictions", "of", "artificially", "intelligent", "robots", "in", "films", "such", "as", "\"", "Artificial", "Intelligence", "A", ".", "I", ".", "\"", "and", "\"", "Ex", "Machina", ",", "\"", "as", "well", "as", "the", "2016", "television", "adaptation", "of", "\"", "Westworld", "\"", "in", "2016", "have", "made", "viewers", "sympathetic", "to", "the", "robots", "themselves", "."], "sentence-detokenized": "More recently, fictional depictions of artificially intelligent robots in films such as \"Artificial Intelligence A. I.\" and \"Ex Machina,\" as well as the 2016 television adaptation of \"Westworld\" in 2016 have made viewers sympathetic to the robots themselves.", "token2charspan": [[0, 4], [5, 13], [13, 14], [15, 24], [25, 35], [36, 38], [39, 51], [52, 63], [64, 70], [71, 73], [74, 79], [80, 84], [85, 87], [88, 89], [89, 99], [100, 112], [113, 114], [114, 115], [116, 117], [117, 118], [118, 119], [120, 123], [124, 125], [125, 127], [128, 135], [135, 136], [136, 137], [138, 140], [141, 145], [146, 148], [149, 152], [153, 157], [158, 168], [169, 179], [180, 182], [183, 184], [184, 193], [193, 194], [195, 197], [198, 202], [203, 207], [208, 212], [213, 220], [221, 232], [233, 235], [236, 239], [240, 246], [247, 257], [257, 258]]}
{"doc_key": "ai-train-34", "ner": [[6, 7, "field"], [9, 11, "algorithm"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 11, 6, 7, "part-of", "", false, false], [13, 14, 6, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "two", "main", "methods", "used", "in", "teacherless", "learning", "are", "principal", "component", "analysis", "and", "cluster", "analysis", "."], "sentence-detokenized": "The two main methods used in teacherless learning are principal component analysis and cluster analysis.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 20], [21, 25], [26, 28], [29, 40], [41, 49], [50, 53], [54, 63], [64, 73], [74, 82], [83, 86], [87, 94], [95, 103], [103, 104]]}
{"doc_key": "ai-train-35", "ner": [[0, 3, "organisation"], [23, 24, "misc"], [31, 32, "misc"], [35, 37, "person"], [42, 43, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[23, 24, 0, 3, "artifact", "", false, false], [31, 32, 0, 3, "artifact", "", false, false], [31, 32, 35, 37, "role", "director_of", false, false], [31, 32, 42, 43, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Walt", "Disney", "Company", "also", "began", "to", "use", "3D", "films", "more", "actively", "in", "special", "venues", "to", "impress", "the", "audience", ",", "among", "which", "\"", "Magical", "Journeys", "\"", "(", "1982", ")", "and", "\"", "Captain", "EO", "\"", "(", "Francis", "Ford", "Coppola", ",", "1986", ",", "starring", "Michael", "Jackson", ")", "are", "the", "most", "striking", "examples", "."], "sentence-detokenized": "The Walt Disney Company also began to use 3D films more actively in special venues to impress the audience, among which \"Magical Journeys\" (1982) and \"Captain EO\" (Francis Ford Coppola, 1986, starring Michael Jackson) are the most striking examples.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 23], [24, 28], [29, 34], [35, 37], [38, 41], [42, 44], [45, 50], [51, 55], [56, 64], [65, 67], [68, 75], [76, 82], [83, 85], [86, 93], [94, 97], [98, 106], [106, 107], [108, 113], [114, 119], [120, 121], [121, 128], [129, 137], [137, 138], [139, 140], [140, 144], [144, 145], [146, 149], [150, 151], [151, 158], [159, 161], [161, 162], [163, 164], [164, 171], [172, 176], [177, 184], [184, 185], [186, 190], [190, 191], [192, 200], [201, 208], [209, 216], [216, 217], [218, 221], [222, 225], [226, 230], [231, 239], [240, 248], [248, 249]]}
{"doc_key": "ai-train-36", "ner": [[12, 14, "field"], [19, 23, "task"], [26, 26, "task"], [28, 28, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[19, 23, 12, 14, "part-of", "", false, false], [26, 26, 12, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Since", "2002", ",", "perceptron", "learning", "has", "become", "popular", "in", "the", "field", "of", "natural", "language", "processing", "for", "tasks", "such", "as", "part", "-", "of", "-", "speech", "tagging", "and", "parsing", "(", "Collins", ",", "2002", ")", "."], "sentence-detokenized": "Since 2002, perceptron learning has become popular in the field of natural language processing for tasks such as part-of-speech tagging and parsing (Collins, 2002).", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 22], [23, 31], [32, 35], [36, 42], [43, 50], [51, 53], [54, 57], [58, 63], [64, 66], [67, 74], [75, 83], [84, 94], [95, 98], [99, 104], [105, 109], [110, 112], [113, 117], [117, 118], [118, 120], [120, 121], [121, 127], [128, 135], [136, 139], [140, 147], [148, 149], [149, 156], [156, 157], [158, 162], [162, 163], [163, 164]]}
{"doc_key": "ai-train-37", "ner": [[2, 4, "product"], [8, 13, "organisation"], [14, 15, "organisation"], [17, 17, "country"], [21, 24, "product"], [28, 29, "researcher"], [39, 39, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[8, 13, 2, 4, "role", "introduces_to_market", true, false], [14, 15, 2, 4, "role", "introduces_to_market", true, false], [14, 15, 17, 17, "physical", "", false, false], [21, 24, 39, 39, "related-to", "sold_to", true, false], [28, 29, 21, 24, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "first", "robot", "palletizer", "was", "introduced", "in", "1963", "by", "Fuji", "Yusoki", "Kogyo", ".", "by", "KUKA", "robotics", "in", "Germany", ",", "and", "the", "programmable", "universal", "assembly", "machine", "was", "invented", "by", "Victor", "Sheinman", "in", "1976", ",", "and", "the", "design", "was", "sold", "to", "Unimation", "."], "sentence-detokenized": "The first robot palletizer was introduced in 1963 by Fuji Yusoki Kogyo. by KUKA robotics in Germany, and the programmable universal assembly machine was invented by Victor Sheinman in 1976, and the design was sold to Unimation.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 26], [27, 30], [31, 41], [42, 44], [45, 49], [50, 52], [53, 57], [58, 64], [65, 70], [70, 71], [72, 74], [75, 79], [80, 88], [89, 91], [92, 99], [99, 100], [101, 104], [105, 108], [109, 121], [122, 131], [132, 140], [141, 148], [149, 152], [153, 161], [162, 164], [165, 171], [172, 180], [181, 183], [184, 188], [188, 189], [190, 193], [194, 197], [198, 204], [205, 208], [209, 213], [214, 216], [217, 226], [226, 227]]}
{"doc_key": "ai-train-38", "ner": [[10, 10, "conference"], [12, 12, "researcher"], [21, 21, "field"], [36, 37, "researcher"], [43, 50, "researcher"], [60, 60, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 12, 10, 10, "role", "president_of", false, false], [12, 12, 36, 37, "role", "colleagues", false, false], [21, 21, 60, 60, "named", "same", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "mid-1990s", ",", "while", "serving", "as", "president", "of", "the", "AAAI", ",", "Hayes", "launched", "a", "series", "of", "attacks", "on", "critics", "of", "AI", ",", "mostly", "framed", "in", "an", "ironic", "light", ",", "and", "(", "along", "with", "his", "colleague", "Kenneth", "Ford", ")", "came", "up", "with", "the", "Simon", "Newcomb", "Award", ",", "which", "would", "be", "given", "for", "the", "most", "ridiculous", "argument", "refuting", "the", "possibility", "of", "AI", "."], "sentence-detokenized": "In the mid-1990s, while serving as president of the AAAI, Hayes launched a series of attacks on critics of AI, mostly framed in an ironic light, and (along with his colleague Kenneth Ford) came up with the Simon Newcomb Award, which would be given for the most ridiculous argument refuting the possibility of AI.", "token2charspan": [[0, 2], [3, 6], [7, 16], [16, 17], [18, 23], [24, 31], [32, 34], [35, 44], [45, 47], [48, 51], [52, 56], [56, 57], [58, 63], [64, 72], [73, 74], [75, 81], [82, 84], [85, 92], [93, 95], [96, 103], [104, 106], [107, 109], [109, 110], [111, 117], [118, 124], [125, 127], [128, 130], [131, 137], [138, 143], [143, 144], [145, 148], [149, 150], [150, 155], [156, 160], [161, 164], [165, 174], [175, 182], [183, 187], [187, 188], [189, 193], [194, 196], [197, 201], [202, 205], [206, 211], [212, 219], [220, 225], [225, 226], [227, 232], [233, 238], [239, 241], [242, 247], [248, 251], [252, 255], [256, 260], [261, 271], [272, 280], [281, 289], [290, 293], [294, 305], [306, 308], [309, 311], [311, 312]]}
{"doc_key": "ai-train-39", "ner": [[13, 19, "algorithm"], [39, 40, "algorithm"], [52, 54, "algorithm"], [57, 60, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 19, 39, 40, "named", "same", false, false], [52, 54, 13, 19, "type-of", "", false, false], [57, 60, 13, 19, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "optimal", "value", "of", "math", "\\", "alpha", "/", "math", "can", "be", "found", "using", "a", "linear", "search", "algorithm", ",", "i.e.", "the", "value", "of", "math", "\\", "alpha", "/", "math", "is", "determined", "by", "finding", "the", "value", "that", "minimizes", "S", ",", "usually", "by", "linear", "search", "in", "the", "interval", "math0", "\\", "alpha", "1", "/", "math", "or", "by", "inverse", "linear", "search", "such", "as", "Armijo", "'s", "linear", "search", "."], "sentence-detokenized": "The optimal value of math\\ alpha / math can be found using a linear search algorithm, i.e. the value of math\\ alpha / math is determined by finding the value that minimizes S, usually by linear search in the interval math0\\ alpha 1 / math or by inverse linear search such as Armijo's linear search.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 20], [21, 25], [25, 26], [27, 32], [33, 34], [35, 39], [40, 43], [44, 46], [47, 52], [53, 58], [59, 60], [61, 67], [68, 74], [75, 84], [84, 85], [86, 90], [91, 94], [95, 100], [101, 103], [104, 108], [108, 109], [110, 115], [116, 117], [118, 122], [123, 125], [126, 136], [137, 139], [140, 147], [148, 151], [152, 157], [158, 162], [163, 172], [173, 174], [174, 175], [176, 183], [184, 186], [187, 193], [194, 200], [201, 203], [204, 207], [208, 216], [217, 222], [222, 223], [224, 229], [230, 231], [232, 233], [234, 238], [239, 241], [242, 244], [245, 252], [253, 259], [260, 266], [267, 271], [272, 274], [275, 281], [281, 283], [284, 290], [291, 297], [297, 298]]}
{"doc_key": "ai-train-40", "ner": [[2, 5, "algorithm"], [7, 10, "algorithm"], [20, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "discusses", "Breadth", "-", "first", "search", "and", "Depth", "-", "first", "search", "methods", ",", "but", "ultimately", "concludes", "that", "the", "results", "are", "expert", "systems", "that", "embody", "a", "lot", "of", "technical", "knowledge", ",", "but", "do", "not", "shed", "much", "light", "on", "the", "mental", "processes", "that", "humans", "use", "to", "solve", "such", "puzzles", "."], "sentence-detokenized": "He discusses Breadth-first search and Depth-first search methods, but ultimately concludes that the results are expert systems that embody a lot of technical knowledge, but do not shed much light on the mental processes that humans use to solve such puzzles.", "token2charspan": [[0, 2], [3, 12], [13, 20], [20, 21], [21, 26], [27, 33], [34, 37], [38, 43], [43, 44], [44, 49], [50, 56], [57, 64], [64, 65], [66, 69], [70, 80], [81, 90], [91, 95], [96, 99], [100, 107], [108, 111], [112, 118], [119, 126], [127, 131], [132, 138], [139, 140], [141, 144], [145, 147], [148, 157], [158, 167], [167, 168], [169, 172], [173, 175], [176, 179], [180, 184], [185, 189], [190, 195], [196, 198], [199, 202], [203, 209], [210, 219], [220, 224], [225, 231], [232, 235], [236, 238], [239, 244], [245, 249], [250, 257], [257, 258]]}
{"doc_key": "ai-train-41", "ner": [[0, 1, "task"], [3, 6, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Speech", "recognition", "and", "speech", "synthesis", "refer", "to", "how", "spoken", "language", "can", "be", "understood", "or", "created", "using", "computers", "."], "sentence-detokenized": "Speech recognition and speech synthesis refer to how spoken language can be understood or created using computers.", "token2charspan": [[0, 6], [7, 18], [19, 22], [23, 29], [30, 39], [40, 45], [46, 48], [49, 52], [53, 59], [60, 68], [69, 72], [73, 75], [76, 86], [87, 89], [90, 97], [98, 103], [104, 113], [113, 114]]}
{"doc_key": "ai-train-42", "ner": [[14, 15, "algorithm"], [33, 33, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "math", "\\", "theta", "^", "{", "*}", "/", "math", "is", "usually", "estimated", "using", "the", "maximum", "likelihood", "(", "math", "\\", "theta", "^", "{", "*}", "=\\", "theta", "^", "{", "ML", "}", "/", "math", ")", "or", "maximum", "a", "posteriori", "(", "math", "\\", "theta", "^", "{", "*}", "=\\", "theta", "^", "{", "MAP", "}", "/", "math", ")", "procedure", "."], "sentence-detokenized": "This math\\ theta ^ {*} / math is usually estimated using the maximum likelihood (math\\ theta ^ {*} =\\ theta ^ {ML} / math) or maximum a posteriori (math\\ theta ^ {*} =\\ theta ^ {MAP} / math) procedure.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 16], [17, 18], [19, 20], [20, 22], [23, 24], [25, 29], [30, 32], [33, 40], [41, 50], [51, 56], [57, 60], [61, 68], [69, 79], [80, 81], [81, 85], [85, 86], [87, 92], [93, 94], [95, 96], [96, 98], [99, 101], [102, 107], [108, 109], [110, 111], [111, 113], [113, 114], [115, 116], [117, 121], [121, 122], [123, 125], [126, 133], [134, 135], [136, 146], [147, 148], [148, 152], [152, 153], [154, 159], [160, 161], [162, 163], [163, 165], [166, 168], [169, 174], [175, 176], [177, 178], [178, 181], [181, 182], [183, 184], [185, 189], [189, 190], [191, 200], [200, 201]]}
{"doc_key": "ai-train-43", "ner": [[8, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "less", "common", "languages", "use", "the", "open", "source", "eSpeak", "synthesizer", "for", "their", "speech", ",", "which", "produces", "a", "robotic", ",", "clunky", "voice", "that", "can", "be", "difficult", "to", "understand", "."], "sentence-detokenized": "Some less common languages use the open source eSpeak synthesizer for their speech, which produces a robotic, clunky voice that can be difficult to understand.", "token2charspan": [[0, 4], [5, 9], [10, 16], [17, 26], [27, 30], [31, 34], [35, 39], [40, 46], [47, 53], [54, 65], [66, 69], [70, 75], [76, 82], [82, 83], [84, 89], [90, 98], [99, 100], [101, 108], [108, 109], [110, 116], [117, 122], [123, 127], [128, 131], [132, 134], [135, 144], [145, 147], [148, 158], [158, 159]]}
{"doc_key": "ai-train-44", "ner": [[1, 2, "programlang"], [37, 38, "programlang"], [40, 40, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 37, 38, "compare", "", false, false], [1, 2, 40, 40, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Although", "R", "is", "used", "mainly", "by", "statisticians", "and", "other", "practitioners", "who", "need", "an", "environment", "for", "statistical", "computing", "and", "software", "development", ",", "it", "can", "also", "work", "as", "a", "general", "toolkit", "for", "matrix", "computing", "-", "with", "performance", "comparable", "to", "GNU", "Octave", "or", "MATLAB", "."], "sentence-detokenized": "Although R is used mainly by statisticians and other practitioners who need an environment for statistical computing and software development, it can also work as a general toolkit for matrix computing - with performance comparable to GNU Octave or MATLAB.", "token2charspan": [[0, 8], [9, 10], [11, 13], [14, 18], [19, 25], [26, 28], [29, 42], [43, 46], [47, 52], [53, 66], [67, 70], [71, 75], [76, 78], [79, 90], [91, 94], [95, 106], [107, 116], [117, 120], [121, 129], [130, 141], [141, 142], [143, 145], [146, 149], [150, 154], [155, 159], [160, 162], [163, 164], [165, 172], [173, 180], [181, 184], [185, 191], [192, 201], [202, 203], [204, 208], [209, 220], [221, 231], [232, 234], [235, 238], [239, 245], [246, 248], [249, 255], [255, 256]]}
{"doc_key": "ai-train-45", "ner": [[0, 1, "algorithm"], [3, 4, "field"], [7, 11, "misc"], [12, 13, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 3, 4, "part-of", "", false, false], [0, 1, 12, 13, "origin", "", false, false], [7, 11, 12, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Heterodyne", "is", "a", "signal", "processing", "method", "invented", "by", "Canadian", "inventor", "-", "engineer", "Reginald", "Fessenden", ",", "which", "creates", "new", "frequencies", "by", "the", "combined", "mixing", "of", "two", "frequencies", "."], "sentence-detokenized": "Heterodyne is a signal processing method invented by Canadian inventor-engineer Reginald Fessenden, which creates new frequencies by the combined mixing of two frequencies.", "token2charspan": [[0, 10], [11, 13], [14, 15], [16, 22], [23, 33], [34, 40], [41, 49], [50, 52], [53, 61], [62, 70], [70, 71], [71, 79], [80, 88], [89, 98], [98, 99], [100, 105], [106, 113], [114, 117], [118, 129], [130, 132], [133, 136], [137, 145], [146, 152], [153, 155], [156, 159], [160, 171], [171, 172]]}
{"doc_key": "ai-train-46", "ner": [[13, 15, "person"], [16, 16, "misc"], [20, 22, "organisation"], [25, 25, "organisation"], [27, 29, "misc"], [31, 32, "person"], [34, 34, "organisation"], [36, 38, "misc"], [40, 41, "person"], [43, 44, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[13, 15, 16, 16, "role", "actor_in", false, false], [16, 16, 20, 22, "artifact", "", false, false], [27, 29, 25, 25, "artifact", "", false, false], [31, 32, 27, 29, "role", "actor_in", false, false], [36, 38, 34, 34, "artifact", "", false, false], [40, 41, 36, 38, "role", "actor_in", false, false], [43, 44, 36, 38, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Other", "films", "that", "helped", "put", "3D", "back", "on", "the", "map", "that", "month", "included", "John", "Wayne", "'s", "Hondo", "(", "distributed", "by", "Warner", "Bros", ".", ")", ",", "Columbia", "'s", "Miss", "Sadie", "Thompson", "starring", "Rita", "Hayworth", "and", "Paramount", "'s", "Money", "From", "Home", "starring", "Dean", "Martin", "and", "Jerry", "Lewis", "."], "sentence-detokenized": "Other films that helped put 3D back on the map that month included John Wayne's Hondo (distributed by Warner Bros.), Columbia's Miss Sadie Thompson starring Rita Hayworth and Paramount's Money From Home starring Dean Martin and Jerry Lewis.", "token2charspan": [[0, 5], [6, 11], [12, 16], [17, 23], [24, 27], [28, 30], [31, 35], [36, 38], [39, 42], [43, 46], [47, 51], [52, 57], [58, 66], [67, 71], [72, 77], [77, 79], [80, 85], [86, 87], [87, 98], [99, 101], [102, 108], [109, 113], [113, 114], [114, 115], [115, 116], [117, 125], [125, 127], [128, 132], [133, 138], [139, 147], [148, 156], [157, 161], [162, 170], [171, 174], [175, 184], [184, 186], [187, 192], [193, 197], [198, 202], [203, 211], [212, 216], [217, 223], [224, 227], [228, 233], [234, 239], [239, 240]]}
{"doc_key": "ai-train-47", "ner": [[0, 0, "product"], [3, 4, "field"], [5, 6, "task"], [10, 11, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 6, "general-affiliation", "", false, false], [0, 0, 10, 11, "artifact", "", false, false], [5, 6, 3, 4, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["DeepFace", "is", "a", "deep", "learning", "face", "recognition", "system", "created", "by", "Facebook", "'s", "research", "team", "."], "sentence-detokenized": "DeepFace is a deep learning face recognition system created by Facebook's research team.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 18], [19, 27], [28, 32], [33, 44], [45, 51], [52, 59], [60, 62], [63, 71], [71, 73], [74, 82], [83, 87], [87, 88]]}
{"doc_key": "ai-train-48", "ner": [[0, 1, "field"], [8, 8, "conference"], [15, 16, "field"], [25, 27, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 15, 16, "part-of", "subfield", false, false], [8, 8, 0, 1, "topic", "", false, false], [25, 27, 0, 1, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Geometry", "processing", "is", "a", "common", "research", "topic", "at", "SIGGRAPH", ",", "the", "leading", "academic", "conference", "on", "computer", "graphics", ",", "and", "the", "main", "topic", "of", "the", "annual", "Geometry", "Processing", "Symposium", "."], "sentence-detokenized": "Geometry processing is a common research topic at SIGGRAPH, the leading academic conference on computer graphics, and the main topic of the annual Geometry Processing Symposium.", "token2charspan": [[0, 8], [9, 19], [20, 22], [23, 24], [25, 31], [32, 40], [41, 46], [47, 49], [50, 58], [58, 59], [60, 63], [64, 71], [72, 80], [81, 91], [92, 94], [95, 103], [104, 112], [112, 113], [114, 117], [118, 121], [122, 126], [127, 132], [133, 135], [136, 139], [140, 146], [147, 155], [156, 166], [167, 176], [176, 177]]}
{"doc_key": "ai-train-49", "ner": [[0, 1, "task"], [3, 4, "task"], [13, 15, "algorithm"], [17, 17, "algorithm"], [20, 22, "algorithm"], [24, 24, "algorithm"], [27, 29, "algorithm"], [31, 31, "algorithm"], [35, 38, "misc"], [39, 41, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[13, 15, 35, 38, "general-affiliation", "", false, false], [17, 17, 13, 15, "named", "", false, false], [20, 22, 35, 38, "general-affiliation", "", false, false], [24, 24, 20, 22, "named", "", false, false], [27, 29, 35, 38, "general-affiliation", "", false, false], [31, 31, 27, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Feature", "extraction", "and", "dimensionality", "reduction", "can", "be", "combined", "in", "a", "single", "step", "using", "Principal", "Component", "Analysis", "(", "PCA", ")", ",", "Linear", "Discriminant", "Analysis", "(", "LDA", ")", "or", "Canonical", "Correlation", "Analysis", "(", "CCA", ")", "as", "a", "preprocessing", "step", "followed", "by", "k", "-", "NN", "clustering", "of", "feature", "vectors", "in", "the", "reduced", "dimensionality", "space", "."], "sentence-detokenized": "Feature extraction and dimensionality reduction can be combined in a single step using Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA) or Canonical Correlation Analysis (CCA) as a preprocessing step followed by k -NN clustering of feature vectors in the reduced dimensionality space.", "token2charspan": [[0, 7], [8, 18], [19, 22], [23, 37], [38, 47], [48, 51], [52, 54], [55, 63], [64, 66], [67, 68], [69, 75], [76, 80], [81, 86], [87, 96], [97, 106], [107, 115], [116, 117], [117, 120], [120, 121], [121, 122], [123, 129], [130, 142], [143, 151], [152, 153], [153, 156], [156, 157], [158, 160], [161, 170], [171, 182], [183, 191], [192, 193], [193, 196], [196, 197], [198, 200], [201, 202], [203, 216], [217, 221], [222, 230], [231, 233], [234, 235], [236, 237], [237, 239], [240, 250], [251, 253], [254, 261], [262, 269], [270, 272], [273, 276], [277, 284], [285, 299], [300, 305], [305, 306]]}
{"doc_key": "ai-train-50", "ner": [[0, 3, "algorithm"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 9, 10, "related-to", "good_at", true, false], [0, 3, 12, 13, "related-to", "good_at", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Artificial", "neural", "networks", "are", "computational", "models", "that", "excel", "in", "machine", "learning", "and", "pattern", "recognition", "."], "sentence-detokenized": "Artificial neural networks are computational models that excel in machine learning and pattern recognition.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 30], [31, 44], [45, 51], [52, 56], [57, 62], [63, 65], [66, 73], [74, 82], [83, 86], [87, 94], [95, 106], [106, 107]]}
{"doc_key": "ai-train-51", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 11, "misc"], [13, 17, "conference"], [19, 19, "conference"], [37, 40, "algorithm"], [41, 42, "researcher"], [44, 46, "researcher"], [48, 54, "misc"], [56, 65, "conference"], [67, 67, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[7, 11, 0, 2, "artifact", "", false, false], [7, 11, 4, 5, "artifact", "", false, false], [7, 11, 13, 17, "temporal", "", false, false], [19, 19, 13, 17, "named", "", false, false], [48, 54, 37, 40, "topic", "", false, false], [48, 54, 41, 42, "artifact", "", false, false], [48, 54, 44, 46, "artifact", "", false, false], [48, 54, 56, 65, "temporal", "", false, false], [67, 67, 56, 65, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["C", ".", "Papageorgiou", "and", "T.", "Poggio", ",", "A", "Trainable", "Pedestrian", "Detection", "system", ",", "International", "Journal", "of", "Computer", "Vision", "(", "IJCV", ")", ",", "pages", "1", ":", "15", "-", "33", ",", "2000", "others", "use", "local", "features", "such", "as", "the", "histogram", "of", "oriented", "gradients", "N.", "Dalal", ",", "B", ".", "Triggs", ",", "Histograms", "of", "oriented", "gradients", "for", "human", "detection", ",", "IEEE", "Computer", "Society", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", ",", "pages", "1", ":", "886-893", ",", "2005", "descriptors", "."], "sentence-detokenized": "C. Papageorgiou and T. Poggio, A Trainable Pedestrian Detection system, International Journal of Computer Vision (IJCV), pages 1: 15-33, 2000 others use local features such as the histogram of oriented gradients N. Dalal, B. Triggs, Histograms of oriented gradients for human detection, IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), pages 1: 886-893, 2005 descriptors.", "token2charspan": [[0, 1], [1, 2], [3, 15], [16, 19], [20, 22], [23, 29], [29, 30], [31, 32], [33, 42], [43, 53], [54, 63], [64, 70], [70, 71], [72, 85], [86, 93], [94, 96], [97, 105], [106, 112], [113, 114], [114, 118], [118, 119], [119, 120], [121, 126], [127, 128], [128, 129], [130, 132], [132, 133], [133, 135], [135, 136], [137, 141], [142, 148], [149, 152], [153, 158], [159, 167], [168, 172], [173, 175], [176, 179], [180, 189], [190, 192], [193, 201], [202, 211], [212, 214], [215, 220], [220, 221], [222, 223], [223, 224], [225, 231], [231, 232], [233, 243], [244, 246], [247, 255], [256, 265], [266, 269], [270, 275], [276, 285], [285, 286], [287, 291], [292, 300], [301, 308], [309, 319], [320, 322], [323, 331], [332, 338], [339, 342], [343, 350], [351, 362], [363, 364], [364, 368], [368, 369], [369, 370], [371, 376], [377, 378], [378, 379], [380, 387], [387, 388], [389, 393], [394, 405], [405, 406]]}
{"doc_key": "ai-train-52", "ner": [[0, 0, "algorithm"], [5, 7, "algorithm"], [10, 11, "task"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 7, "type-of", "", false, false], [10, 11, 0, 0, "usage", "", true, false], [10, 11, 13, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Autoencoder", "is", "a", "type", "of", "artificial", "neural", "network", "used", "for", "feature", "learning", "in", "unsupervised", "mode", "."], "sentence-detokenized": "Autoencoder is a type of artificial neural network used for feature learning in unsupervised mode.", "token2charspan": [[0, 11], [12, 14], [15, 16], [17, 21], [22, 24], [25, 35], [36, 42], [43, 50], [51, 55], [56, 59], [60, 67], [68, 76], [77, 79], [80, 92], [93, 97], [97, 98]]}
{"doc_key": "ai-train-53", "ner": [[0, 0, "researcher"], [6, 6, "organisation"], [11, 12, "field"], [14, 15, "field"], [21, 26, "organisation"], [28, 28, "organisation"], [34, 35, "field"], [37, 38, "field"], [44, 44, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 6, 6, "role", "fellow_of", false, false], [0, 0, 11, 12, "related-to", "contributes_to", false, false], [0, 0, 14, 15, "related-to", "contributes_to", false, false], [0, 0, 21, 26, "role", "fellow_of", false, false], [0, 0, 34, 35, "related-to", "contributes_to", false, false], [0, 0, 37, 38, "related-to", "contributes_to", false, false], [28, 28, 21, 26, "named", "", false, false], [44, 44, 21, 26, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Haralick", "is", "a", "Fellow", "of", "the", "IEEE", "for", "his", "contributions", "to", "computer", "vision", "and", "image", "processing", ",", "and", "a", "Fellow", "of", "the", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", "for", "his", "contributions", "to", "pattern", "recognition", ",", "image", "processing", ",", "and", "for", "services", "to", "IAPR", "."], "sentence-detokenized": "Haralick is a Fellow of the IEEE for his contributions to computer vision and image processing, and a Fellow of the International Association for Pattern Recognition (IAPR) for his contributions to pattern recognition, image processing, and for services to IAPR.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 20], [21, 23], [24, 27], [28, 32], [33, 36], [37, 40], [41, 54], [55, 57], [58, 66], [67, 73], [74, 77], [78, 83], [84, 94], [94, 95], [96, 99], [100, 101], [102, 108], [109, 111], [112, 115], [116, 129], [130, 141], [142, 145], [146, 153], [154, 165], [166, 167], [167, 171], [171, 172], [173, 176], [177, 180], [181, 194], [195, 197], [198, 205], [206, 217], [217, 218], [219, 224], [225, 235], [235, 236], [237, 240], [241, 244], [245, 253], [254, 256], [257, 261], [261, 262]]}
{"doc_key": "ai-train-54", "ner": [[4, 9, "task"], [14, 16, "algorithm"], [18, 18, "algorithm"], [23, 24, "researcher"], [26, 27, "organisation"], [29, 30, "researcher"], [33, 35, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 9, 14, 16, "usage", "", false, false], [14, 16, 23, 24, "origin", "", true, false], [14, 16, 29, 30, "origin", "", true, false], [18, 18, 14, 16, "named", "", false, false], [23, 24, 26, 27, "physical", "", false, false], [23, 24, 26, 27, "role", "", false, false], [29, 30, 33, 35, "physical", "", false, false], [29, 30, 33, 35, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "first", "attempt", "at", "end", "-", "to", "-", "end", "ASR", "were", "systems", "based", "on", "Connectionist", "Temporal", "Classification", "(", "CTC", ")", ",", "presented", "by", "Alex", "Graves", "of", "Google", "DeepMind", "and", "Navdeep", "Jaitley", "of", "the", "University", "of", "Toronto", "in", "2014", "."], "sentence-detokenized": "The first attempt at end-to-end ASR were systems based on Connectionist Temporal Classification (CTC), presented by Alex Graves of Google DeepMind and Navdeep Jaitley of the University of Toronto in 2014.", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 20], [21, 24], [24, 25], [25, 27], [27, 28], [28, 31], [32, 35], [36, 40], [41, 48], [49, 54], [55, 57], [58, 71], [72, 80], [81, 95], [96, 97], [97, 100], [100, 101], [101, 102], [103, 112], [113, 115], [116, 120], [121, 127], [128, 130], [131, 137], [138, 146], [147, 150], [151, 158], [159, 166], [167, 169], [170, 173], [174, 184], [185, 187], [188, 195], [196, 198], [199, 203], [203, 204]]}
{"doc_key": "ai-train-55", "ner": [[0, 2, "algorithm"], [10, 11, "algorithm"], [13, 13, "algorithm"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[10, 11, 0, 2, "type-of", "", false, false], [13, 13, 10, 11, "named", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["Linear", "fractional", "programming", "(", "LFP", ")", "is", "a", "generalization", "of", "linear", "programming", "(", "LP", ")", "."], "sentence-detokenized": "Linear fractional programming (LFP) is a generalization of linear programming (LP).", "token2charspan": [[0, 6], [7, 17], [18, 29], [30, 31], [31, 34], [34, 35], [36, 38], [39, 40], [41, 55], [56, 58], [59, 65], [66, 77], [78, 79], [79, 81], [81, 82], [82, 83]]}
{"doc_key": "ai-train-56", "ner": [[0, 1, "researcher"], [8, 15, "misc"], [18, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 8, 15, "win-defeat", "", false, false], [8, 15, 18, 26, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lafferty", "has", "received", "numerous", "awards", ",", "including", "two", "\"", "Test", "-", "of", "-", "Time", "\"", "awards", "at", "the", "International", "Conference", "on", "Machine", "Learning", "in", "2011", "and", "2012", ","], "sentence-detokenized": "Lafferty has received numerous awards, including two \"Test-of-Time\" awards at the International Conference on Machine Learning in 2011 and 2012,", "token2charspan": [[0, 8], [9, 12], [13, 21], [22, 30], [31, 37], [37, 38], [39, 48], [49, 52], [53, 54], [54, 58], [58, 59], [59, 61], [61, 62], [62, 66], [66, 67], [68, 74], [75, 77], [78, 81], [82, 95], [96, 106], [107, 109], [110, 117], [118, 126], [127, 129], [130, 134], [135, 138], [139, 143], [143, 144]]}
{"doc_key": "ai-train-57", "ner": [[10, 10, "product"], [12, 12, "programlang"], [25, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["With", "the", "advent", "of", "component", "-", "based", "frameworks", "such", "as", ".NET", "and", "Java", ",", "component", "-", "based", "development", "environments", "are", "able", "to", "deploy", "the", "developed", "neural", "network", "in", "these", "frameworks", "as", "inherited", "components", "."], "sentence-detokenized": "With the advent of component-based frameworks such as .NET and Java, component-based development environments are able to deploy the developed neural network in these frameworks as inherited components.", "token2charspan": [[0, 4], [5, 8], [9, 15], [16, 18], [19, 28], [28, 29], [29, 34], [35, 45], [46, 50], [51, 53], [54, 58], [59, 62], [63, 67], [67, 68], [69, 78], [78, 79], [79, 84], [85, 96], [97, 109], [110, 113], [114, 118], [119, 121], [122, 128], [129, 132], [133, 142], [143, 149], [150, 157], [158, 160], [161, 166], [167, 177], [178, 180], [181, 190], [191, 201], [201, 202]]}
{"doc_key": "ai-train-58", "ner": [[5, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["As", "in", "the", "case", "of", "BLEU", ",", "the", "basic", "unit", "of", "evaluation", "is", "the", "sentence", ",", "the", "algorithm", "first", "creates", "a", "correspondence", "(", "see", "illustrations", ")", "between", "two", "sentences", ",", "a", "candidate", "translation", "string", "and", "a", "reference", "translation", "string", "."], "sentence-detokenized": "As in the case of BLEU, the basic unit of evaluation is the sentence, the algorithm first creates a correspondence (see illustrations) between two sentences, a candidate translation string and a reference translation string.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 14], [15, 17], [18, 22], [22, 23], [24, 27], [28, 33], [34, 38], [39, 41], [42, 52], [53, 55], [56, 59], [60, 68], [68, 69], [70, 73], [74, 83], [84, 89], [90, 97], [98, 99], [100, 114], [115, 116], [116, 119], [120, 133], [133, 134], [135, 142], [143, 146], [147, 156], [156, 157], [158, 159], [160, 169], [170, 181], [182, 188], [189, 192], [193, 194], [195, 204], [205, 216], [217, 223], [223, 224]]}
{"doc_key": "ai-train-59", "ner": [[7, 14, "conference"], [22, 22, "task"], [24, 24, "task"], [28, 29, "metrics"], [31, 37, "metrics"], [42, 45, "conference"], [47, 47, "conference"], [50, 50, "location"], [52, 52, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[7, 14, 22, 22, "related-to", "subject_at", false, false], [7, 14, 24, 24, "related-to", "subject_at", false, false], [28, 29, 7, 14, "temporal", "", false, false], [31, 37, 28, 29, "named", "", true, false], [47, 47, 42, 45, "named", "", false, false], [50, 50, 52, 52, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["One", "of", "the", "metrics", "used", "at", "the", "annual", "NIST", "conferences", "on", "document", "understanding", ",", "where", "research", "groups", "present", "their", "systems", "for", "both", "summarization", "and", "translation", ",", "is", "the", "ROUGE", "metric", "(", "Recall", "-", "Oriented", "Understudy", "for", "Gisting", "Evaluation", ",", "In", "Advances", "of", "Neural", "Information", "Processing", "Systems", "(", "NIPS", ")", ",", "Montreal", ",", "Canada", ",", "December", "-", "2014", "."], "sentence-detokenized": "One of the metrics used at the annual NIST conferences on document understanding, where research groups present their systems for both summarization and translation, is the ROUGE metric (Recall-Oriented Understudy for Gisting Evaluation, In Advances of Neural Information Processing Systems (NIPS), Montreal, Canada, December - 2014.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 18], [19, 23], [24, 26], [27, 30], [31, 37], [38, 42], [43, 54], [55, 57], [58, 66], [67, 80], [80, 81], [82, 87], [88, 96], [97, 103], [104, 111], [112, 117], [118, 125], [126, 129], [130, 134], [135, 148], [149, 152], [153, 164], [164, 165], [166, 168], [169, 172], [173, 178], [179, 185], [186, 187], [187, 193], [193, 194], [194, 202], [203, 213], [214, 217], [218, 225], [226, 236], [236, 237], [238, 240], [241, 249], [250, 252], [253, 259], [260, 271], [272, 282], [283, 290], [291, 292], [292, 296], [296, 297], [297, 298], [299, 307], [307, 308], [309, 315], [315, 316], [317, 325], [326, 327], [328, 332], [332, 333]]}
{"doc_key": "ai-train-60", "ner": [[7, 7, "programlang"], [9, 9, "product"], [11, 12, "programlang"], [16, 16, "product"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 7, 11, 12, "type-of", "", false, false], [7, 7, 22, 22, "named", "", false, false], [9, 9, 11, 12, "part-of", "", false, false], [9, 9, 16, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "same", "implementation", ",", "to", "run", "in", "Java", "with", "JShell", "(", "Java", "9", "minimum", ")", ":", "codejshell", "scriptfile", "/", "codesyntaxhighlight", "lang", "=", "java"], "sentence-detokenized": "The same implementation, to run in Java with JShell (Java 9 minimum): codejshell scriptfile / codesyntaxhighlight lang = java", "token2charspan": [[0, 3], [4, 8], [9, 23], [23, 24], [25, 27], [28, 31], [32, 34], [35, 39], [40, 44], [45, 51], [52, 53], [53, 57], [58, 59], [60, 67], [67, 68], [68, 69], [70, 80], [81, 91], [92, 93], [94, 113], [114, 118], [119, 120], [121, 125]]}
{"doc_key": "ai-train-61", "ner": [[0, 2, "metrics"], [7, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 7, 8, "origin", "based_on", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "NIST", "metric", "is", "based", "on", "the", "BLEU", "metric", ",", "but", "with", "some", "changes", "."], "sentence-detokenized": "The NIST metric is based on the BLEU metric, but with some changes.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 18], [19, 24], [25, 27], [28, 31], [32, 36], [37, 43], [43, 44], [45, 48], [49, 53], [54, 58], [59, 66], [66, 67]]}
{"doc_key": "ai-train-62", "ner": [[6, 6, "country"], [10, 12, "university"], [15, 17, "university"], [25, 26, "product"], [31, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 12, 6, 6, "physical", "", false, false], [15, 17, 6, 6, "physical", "", false, false], [25, 26, 10, 12, "origin", "", false, false], [25, 26, 15, 17, "origin", "", false, false], [25, 26, 31, 32, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "the", "late", "1980s", ",", "two", "Dutch", "universities", ",", "the", "University", "of", "Groningen", "and", "the", "University", "of", "Twente", ",", "jointly", "started", "a", "project", "called", "\"", "Knowledge", "Graphs", "\"", ",", "which", "are", "semantic", "networks", ",", "but", "with", "the", "additional", "constraint", "that", "the", "edges", "must", "be", "from", "a", "limited", "set", "of", "possible", "connections", ",", "to", "facilitate", "algebra", "on", "the", "graph", "."], "sentence-detokenized": "In the late 1980s, two Dutch universities, the University of Groningen and the University of Twente, jointly started a project called \"Knowledge Graphs\", which are semantic networks, but with the additional constraint that the edges must be from a limited set of possible connections, to facilitate algebra on the graph.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 17], [17, 18], [19, 22], [23, 28], [29, 41], [41, 42], [43, 46], [47, 57], [58, 60], [61, 70], [71, 74], [75, 78], [79, 89], [90, 92], [93, 99], [99, 100], [101, 108], [109, 116], [117, 118], [119, 126], [127, 133], [134, 135], [135, 144], [145, 151], [151, 152], [152, 153], [154, 159], [160, 163], [164, 172], [173, 181], [181, 182], [183, 186], [187, 191], [192, 195], [196, 206], [207, 217], [218, 222], [223, 226], [227, 232], [233, 237], [238, 240], [241, 245], [246, 247], [248, 255], [256, 259], [260, 262], [263, 271], [272, 283], [283, 284], [285, 287], [288, 298], [299, 306], [307, 309], [310, 313], [314, 319], [319, 320]]}
{"doc_key": "ai-train-63", "ner": [[0, 2, "product"], [18, 35, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 18, 35, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Grammar", "checkers", "are", "most", "commonly", "implemented", "as", "a", "function", "of", "a", "larger", "program", ",", "such", "as", "a", "word", "processor", ",", "but", "are", "also", "available", "as", "a", "standalone", "application", "that", "can", "be", "activated", "from", "within", "word", "processing", "programs", "."], "sentence-detokenized": "Grammar checkers are most commonly implemented as a function of a larger program, such as a word processor, but are also available as a standalone application that can be activated from within word processing programs.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 25], [26, 34], [35, 46], [47, 49], [50, 51], [52, 60], [61, 63], [64, 65], [66, 72], [73, 80], [80, 81], [82, 86], [87, 89], [90, 91], [92, 96], [97, 106], [106, 107], [108, 111], [112, 115], [116, 120], [121, 130], [131, 133], [134, 135], [136, 146], [147, 158], [159, 163], [164, 167], [168, 170], [171, 180], [181, 185], [186, 192], [193, 197], [198, 208], [209, 217], [217, 218]]}
{"doc_key": "ai-train-64", "ner": [[6, 12, "organisation"], [15, 21, "conference"], [25, 30, "organisation"], [35, 37, "conference"], [39, 41, "conference"], [44, 46, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "fellow", "of", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ",", "and", "the", "Cognitive", "Science", "Society", ",", "and", "an", "editor", "of", "the", "journals", "J.", "Automated", "Reasoning", ",", "J.", "Learning", "Sciences", ",", "and", "J.", "Applied", "Ontology", "."], "sentence-detokenized": "He is a fellow of the American Association for the Advancement of Science, the Association for the Advancement of Artificial Intelligence, and the Cognitive Science Society, and an editor of the journals J. Automated Reasoning, J. Learning Sciences, and J. Applied Ontology.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 30], [31, 42], [43, 46], [47, 50], [51, 62], [63, 65], [66, 73], [73, 74], [75, 78], [79, 90], [91, 94], [95, 98], [99, 110], [111, 113], [114, 124], [125, 137], [137, 138], [139, 142], [143, 146], [147, 156], [157, 164], [165, 172], [172, 173], [174, 177], [178, 180], [181, 187], [188, 190], [191, 194], [195, 203], [204, 206], [207, 216], [217, 226], [226, 227], [228, 230], [231, 239], [240, 248], [248, 249], [250, 253], [254, 256], [257, 264], [265, 273], [273, 274]]}
{"doc_key": "ai-train-65", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [10, 11, "task"], [20, 21, "researcher"], [23, 24, "university"], [26, 27, "researcher"], [29, 32, "organisation"], [34, 34, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 10, 11, "type-of", "", false, false], [0, 2, 20, 21, "origin", "", false, false], [0, 2, 26, 27, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [20, 21, 23, 24, "physical", "", false, false], [20, 21, 23, 24, "role", "", false, false], [26, 27, 29, 32, "role", "", false, false], [34, 34, 29, 32, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Linear", "predictive", "coding", "(", "LPC", ")", ",", "a", "form", "of", "speech", "coding", ",", "began", "to", "develop", "with", "the", "work", "of", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", "."], "sentence-detokenized": "Linear predictive coding (LPC), a form of speech coding, began to develop with the work of Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [30, 31], [32, 33], [34, 38], [39, 41], [42, 48], [49, 55], [55, 56], [57, 62], [63, 65], [66, 73], [74, 78], [79, 82], [83, 87], [88, 90], [91, 99], [100, 107], [108, 110], [111, 117], [118, 128], [129, 132], [133, 138], [139, 144], [145, 147], [148, 154], [155, 164], [165, 168], [169, 178], [179, 180], [180, 183], [183, 184], [185, 187], [188, 192], [192, 193]]}
{"doc_key": "ai-train-66", "ner": [[58, 60, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "signal", "is", "ergodic", ",", "then", "all", "sample", "trajectories", "have", "the", "same", "time", "average", "and", "thus", "mathR", "_", "x", "^", "{", "n", "/", "T", "_", "0", "}", "(", "\\", "tau", ")", "=\\", "widehat", "{", "R", "}", "_", "x", "^", "{", "n", "/", "T", "_", "0", "}", "(", "\\", "tau", ")", "/", "math", "in", "the", "sense", "of", "the", "mean", "square", "error", "."], "sentence-detokenized": "If the signal is ergodic, then all sample trajectories have the same time average and thus mathR _ x ^ {n / T _ 0} (\\ tau) =\\ widehat {R} _ x ^ {n / T _ 0} (\\ tau) / math in the sense of the mean square error.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 16], [17, 24], [24, 25], [26, 30], [31, 34], [35, 41], [42, 54], [55, 59], [60, 63], [64, 68], [69, 73], [74, 81], [82, 85], [86, 90], [91, 96], [97, 98], [99, 100], [101, 102], [103, 104], [104, 105], [106, 107], [108, 109], [110, 111], [112, 113], [113, 114], [115, 116], [116, 117], [118, 121], [121, 122], [123, 125], [126, 133], [134, 135], [135, 136], [136, 137], [138, 139], [140, 141], [142, 143], [144, 145], [145, 146], [147, 148], [149, 150], [151, 152], [153, 154], [154, 155], [156, 157], [157, 158], [159, 162], [162, 163], [164, 165], [166, 170], [171, 173], [174, 177], [178, 183], [184, 186], [187, 190], [191, 195], [196, 202], [203, 208], [208, 209]]}
{"doc_key": "ai-train-67", "ner": [[0, 1, "task"], [3, 4, "task"], [13, 15, "algorithm"], [17, 17, "algorithm"], [20, 22, "algorithm"], [24, 24, "algorithm"], [27, 29, "algorithm"], [31, 31, "algorithm"], [34, 36, "algorithm"], [38, 38, "algorithm"], [42, 45, "misc"], [46, 48, "algorithm"], [52, 55, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[13, 15, 42, 45, "related-to", "", false, false], [17, 17, 13, 15, "named", "", false, false], [20, 22, 42, 45, "related-to", "", false, false], [24, 24, 20, 22, "named", "", false, false], [27, 29, 42, 45, "related-to", "", false, false], [31, 31, 27, 29, "named", "", false, false], [34, 36, 42, 45, "related-to", "", false, false], [38, 38, 34, 36, "named", "", false, false], [46, 48, 52, 55, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Feature", "extraction", "and", "dimensionality", "reduction", "can", "be", "combined", "in", "a", "single", "step", "using", "Principal", "Component", "Analysis", "(", "PCA", ")", ",", "Linear", "Discriminant", "Analysis", "(", "LDA", ")", ",", "Canonical", "Correlation", "Analysis", "(", "CCA", ")", "or", "Nonnegative", "Matrix", "Factorization", "(", "NMF", ")", "as", "a", "preprocessing", "step", "followed", "by", "K", "-", "NN", "clustering", "on", "the", "feature", "vectors", "in", "the", "reduced", "dimensionality", "space", "."], "sentence-detokenized": "Feature extraction and dimensionality reduction can be combined in a single step using Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA), Canonical Correlation Analysis (CCA) or Nonnegative Matrix Factorization (NMF) as a preprocessing step followed by K-NN clustering on the feature vectors in the reduced dimensionality space.", "token2charspan": [[0, 7], [8, 18], [19, 22], [23, 37], [38, 47], [48, 51], [52, 54], [55, 63], [64, 66], [67, 68], [69, 75], [76, 80], [81, 86], [87, 96], [97, 106], [107, 115], [116, 117], [117, 120], [120, 121], [121, 122], [123, 129], [130, 142], [143, 151], [152, 153], [153, 156], [156, 157], [157, 158], [159, 168], [169, 180], [181, 189], [190, 191], [191, 194], [194, 195], [196, 198], [199, 210], [211, 217], [218, 231], [232, 233], [233, 236], [236, 237], [238, 240], [241, 242], [243, 256], [257, 261], [262, 270], [271, 273], [274, 275], [275, 276], [276, 278], [279, 289], [290, 292], [293, 296], [297, 304], [305, 312], [313, 315], [316, 319], [320, 327], [328, 342], [343, 348], [348, 349]]}
{"doc_key": "ai-train-68", "ner": [[3, 3, "programlang"], [5, 5, "programlang"], [7, 7, "programlang"], [9, 9, "programlang"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 15, 3, 3, "related-to", "program_type_compatible_with", false, false], [15, 15, 5, 5, "related-to", "program_type_compatible_with", false, false], [15, 15, 7, 7, "related-to", "program_type_compatible_with", false, false], [15, 15, 9, 9, "related-to", "program_type_compatible_with", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Libraries", "written", "in", "Perl", ",", "Java", ",", "ActiveX", "or", ".NET", "can", "be", "directly", "called", "from", "MATLAB", ","], "sentence-detokenized": "Libraries written in Perl, Java, ActiveX or .NET can be directly called from MATLAB,", "token2charspan": [[0, 9], [10, 17], [18, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 40], [41, 43], [44, 48], [49, 52], [53, 55], [56, 64], [65, 71], [72, 76], [77, 83], [83, 84]]}
{"doc_key": "ai-train-69", "ner": [[3, 10, "task"], [11, 13, "task"], [31, 32, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 10, 11, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "task", "of", "recognizing", "named", "objects", "in", "the", "text", "is", "called", "named", "object", "recognition", ",", "and", "the", "task", "of", "determining", "the", "identity", "of", "named", "objects", "mentioned", "in", "the", "text", "is", "called", "Entity", "Linking", "."], "sentence-detokenized": "The task of recognizing named objects in the text is called named object recognition, and the task of determining the identity of named objects mentioned in the text is called Entity Linking.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 23], [24, 29], [30, 37], [38, 40], [41, 44], [45, 49], [50, 52], [53, 59], [60, 65], [66, 72], [73, 84], [84, 85], [86, 89], [90, 93], [94, 98], [99, 101], [102, 113], [114, 117], [118, 126], [127, 129], [130, 135], [136, 143], [144, 153], [154, 156], [157, 160], [161, 165], [166, 168], [169, 175], [176, 182], [183, 190], [190, 191]]}
{"doc_key": "ai-train-70", "ner": [[27, 27, "programlang"], [0, 29, "algorithm"]], "ner_mapping_to_source": [1, 2], "relations": [[0, 29, 27, 27, "part-of", "", true, false]], "relations_mapping_to_source": [1], "sentence": ["The", "sigmoid", "functions", "and", "derivatives", "used", "in", "the", "package", "were", "originally", "included", "in", "the", "package", "starting", "with", "version", "0.8.0", ",", "they", "have", "been", "released", "in", "a", "separate", "R", "sigmoid", "package", ",", "with", "the", "intention", "of", "providing", "wider", "use", "."], "sentence-detokenized": "The sigmoid functions and derivatives used in the package were originally included in the package starting with version 0.8.0, they have been released in a separate R sigmoid package, with the intention of providing wider use.", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 25], [26, 37], [38, 42], [43, 45], [46, 49], [50, 57], [58, 62], [63, 73], [74, 82], [83, 85], [86, 89], [90, 97], [98, 106], [107, 111], [112, 119], [120, 125], [125, 126], [127, 131], [132, 136], [137, 141], [142, 150], [151, 153], [154, 155], [156, 164], [165, 166], [167, 174], [175, 182], [182, 183], [184, 188], [189, 192], [193, 202], [203, 205], [206, 215], [216, 221], [222, 225], [225, 226]]}
{"doc_key": "ai-train-71", "ner": [[0, 1, "programlang"], [10, 14, "organisation"], [16, 16, "organisation"], [19, 19, "location"], [21, 23, "location"], [24, 25, "researcher"], [27, 29, "researcher"], [30, 31, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 24, 25, "artifact", "", true, false], [0, 1, 27, 29, "artifact", "", true, false], [0, 1, 30, 31, "artifact", "", true, false], [16, 16, 10, 14, "named", "", false, false], [16, 16, 19, 19, "physical", "", false, false], [19, 19, 21, 23, "physical", "", false, false], [24, 25, 10, 14, "role", "", false, false], [27, 29, 10, 14, "role", "", false, false], [30, 31, 10, 14, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "logo", "was", "created", "in", "1967", "at", "the", "research", "firm", "Bolt", ",", "Beranek", "and", "Newman", "(", "BBN", ")", ",", "Cambridge", ",", "Massachusetts", ",", "by", "Wally", "Fairzeig", ",", "Cynthia", "Solomon", "and", "Seymour", "Papert", "."], "sentence-detokenized": "The logo was created in 1967 at the research firm Bolt, Beranek and Newman (BBN), Cambridge, Massachusetts, by Wally Fairzeig, Cynthia Solomon and Seymour Papert.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 20], [21, 23], [24, 28], [29, 31], [32, 35], [36, 44], [45, 49], [50, 54], [54, 55], [56, 63], [64, 67], [68, 74], [75, 76], [76, 79], [79, 80], [80, 81], [82, 91], [91, 92], [93, 106], [106, 107], [108, 110], [111, 116], [117, 125], [125, 126], [127, 134], [135, 142], [143, 146], [147, 154], [155, 161], [161, 162]]}
{"doc_key": "ai-train-72", "ner": [[0, 1, "misc"], [8, 9, "field"], [17, 18, "field"], [22, 23, "algorithm"], [26, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 8, 9, "part-of", "", false, false], [0, 1, 17, 18, "compare", "", false, false], [22, 23, 17, 18, "part-of", "", false, false], [26, 27, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Neuroevolution", "is", "typically", "used", "as", "part", "of", "a", "reinforcement", "learning", "paradigm", "and", "can", "be", "contrasted", "with", "conventional", "deep", "learning", "methods", "that", "use", "gradient", "descent", "on", "a", "neural", "network", "with", "a", "fixed", "topology", "."], "sentence-detokenized": "Neuroevolution is typically used as part of a reinforcement learning paradigm and can be contrasted with conventional deep learning methods that use gradient descent on a neural network with a fixed topology.", "token2charspan": [[0, 14], [15, 17], [18, 27], [28, 32], [33, 35], [36, 40], [41, 43], [44, 45], [46, 59], [60, 68], [69, 77], [78, 81], [82, 85], [86, 88], [89, 99], [100, 104], [105, 117], [118, 122], [123, 131], [132, 139], [140, 144], [145, 148], [149, 157], [158, 165], [166, 168], [169, 170], [171, 177], [178, 185], [186, 190], [191, 192], [193, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-train-73", "ner": [[4, 5, "algorithm"], [58, 60, "metrics"], [62, 62, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[62, 62, 58, 60, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["If", "we", "use", "the", "least", "squares", "method", "to", "fit", "a", "function", "in", "the", "form", "of", "a", "hyperplane", "\u0177", "=", "a", "+", "\u03b2", "supT", "/", "sup", "x", "to", "the", "data", "(", "x", "sub", "i", "/", "sub", ",", "y", "sub", "i", "/", "sub", ")", "sub", "1", "\u2264", "i", "\u2264n", "/", "sub", ",", "we", "could", "then", "evaluate", "the", "fit", "using", "the", "mean", "square", "error", "(", "MSE", ")", "."], "sentence-detokenized": "If we use the least squares method to fit a function in the form of a hyperplane \u0177 = a + \u03b2 supT / sup x to the data (x sub i / sub, y sub i / sub) sub 1 \u2264 i \u2264n / sub, we could then evaluate the fit using the mean square error (MSE).", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 13], [14, 19], [20, 27], [28, 34], [35, 37], [38, 41], [42, 43], [44, 52], [53, 55], [56, 59], [60, 64], [65, 67], [68, 69], [70, 80], [81, 82], [83, 84], [85, 86], [87, 88], [89, 90], [91, 95], [96, 97], [98, 101], [102, 103], [104, 106], [107, 110], [111, 115], [116, 117], [117, 118], [119, 122], [123, 124], [125, 126], [127, 130], [130, 131], [132, 133], [134, 137], [138, 139], [140, 141], [142, 145], [145, 146], [147, 150], [151, 152], [153, 154], [155, 156], [157, 159], [160, 161], [162, 165], [165, 166], [167, 169], [170, 175], [176, 180], [181, 189], [190, 193], [194, 197], [198, 203], [204, 207], [208, 212], [213, 219], [220, 225], [226, 227], [227, 230], [230, 231], [231, 232]]}
{"doc_key": "ai-train-74", "ner": [[7, 7, "country"], [9, 9, "country"], [11, 11, "country"], [13, 13, "country"], [15, 15, "country"], [17, 17, "country"], [19, 19, "country"], [21, 21, "country"], [23, 23, "country"], [25, 25, "country"], [27, 27, "country"], [29, 29, "country"], [49, 51, "country"], [31, 31, "country"], [33, 40, "country"], [35, 36, "country"], [38, 38, "country"], [42, 42, "country"], [44, 44, "country"], [46, 48, "country"], [53, 53, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "company", "has", "international", "representative", "offices", "in", "Australia", ",", "Brazil", ",", "Canada", ",", "China", ",", "Germany", ",", "India", ",", "Italy", ",", "Japan", ",", "Korea", ",", "Lithuania", ",", "Poland", ",", "Malaysia", ",", "Russia", ",", "Singapore", ",", "South", "Africa", ",", "Spain", ",", "Singapore", ",", "Taiwan", ",", "Thailand", ",", "Turkey", ",", "the", "Philippines", ",", "the", "United", "Kingdom", "and", "the", "United", "States", "."], "sentence-detokenized": "The company has international representative offices in Australia, Brazil, Canada, China, Germany, India, Italy, Japan, Korea, Lithuania, Poland, Malaysia, Russia, Singapore, South Africa, Spain, Singapore, Taiwan, Thailand, Turkey, the Philippines, the United Kingdom and the United States.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 29], [30, 44], [45, 52], [53, 55], [56, 65], [65, 66], [67, 73], [73, 74], [75, 81], [81, 82], [83, 88], [88, 89], [90, 97], [97, 98], [99, 104], [104, 105], [106, 111], [111, 112], [113, 118], [118, 119], [120, 125], [125, 126], [127, 136], [136, 137], [138, 144], [144, 145], [146, 154], [154, 155], [156, 162], [162, 163], [164, 173], [173, 174], [175, 180], [181, 187], [187, 188], [189, 194], [194, 195], [196, 205], [205, 206], [207, 213], [213, 214], [215, 223], [223, 224], [225, 231], [231, 232], [233, 236], [237, 248], [248, 249], [250, 253], [254, 260], [261, 268], [269, 272], [273, 276], [277, 283], [284, 290], [290, 291]]}
{"doc_key": "ai-train-75", "ner": [[3, 3, "misc"], [5, 8, "field"], [13, 13, "organisation"], [16, 24, "university"], [28, 30, "organisation"], [32, 37, "university"], [41, 42, "university"], [44, 45, "university"], [49, 51, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 3, 5, 8, "topic", "", false, false], [3, 3, 13, 13, "origin", "", false, false], [3, 3, 16, 24, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "holds", "a", "Ph.D.", "in", "Electrical", "and", "Computer", "Engineering", "(", "2000", ")", "from", "India", "and", "the", "University", "of", "Nice", "Sophia", "Antipolis", ",", "and", "has", "held", "permanent", "positions", "at", "Siemens", "Corporate", "Technology", ",", "\u00c9cole", "des", "ponts", "ParisTech", ",", "and", "visiting", "positions", "at", "Rutgers", "University", ",", "Yale", "University", ",", "and", "the", "University", "of", "Houston", "."], "sentence-detokenized": "He holds a Ph.D. in Electrical and Computer Engineering (2000) from India and the University of Nice Sophia Antipolis, and has held permanent positions at Siemens Corporate Technology, \u00c9cole des ponts ParisTech, and visiting positions at Rutgers University, Yale University, and the University of Houston.", "token2charspan": [[0, 2], [3, 8], [9, 10], [11, 16], [17, 19], [20, 30], [31, 34], [35, 43], [44, 55], [56, 57], [57, 61], [61, 62], [63, 67], [68, 73], [74, 77], [78, 81], [82, 92], [93, 95], [96, 100], [101, 107], [108, 117], [117, 118], [119, 122], [123, 126], [127, 131], [132, 141], [142, 151], [152, 154], [155, 162], [163, 172], [173, 183], [183, 184], [185, 190], [191, 194], [195, 200], [201, 210], [210, 211], [212, 215], [216, 224], [225, 234], [235, 237], [238, 245], [246, 256], [256, 257], [258, 262], [263, 273], [273, 274], [275, 278], [279, 282], [283, 293], [294, 296], [297, 304], [304, 305]]}
{"doc_key": "ai-train-76", "ner": [[6, 8, "researcher"], [12, 12, "researcher"], [16, 17, "product"], [20, 21, "country"], [23, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 12, 6, 8, "role", "licensing_patent_to", false, false], [12, 12, 20, 21, "physical", "", false, false], [23, 26, 12, 12, "artifact", "", false, false], [23, 26, 16, 17, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["After", "obtaining", "a", "license", "to", "inventor", "George", "Devol", "'s", "original", "patent", ",", "Engelberger", "developed", "the", "first", "industrial", "robot", "in", "the", "United", "States", ",", "Unimate", ",", "in", "the", "1950s", "."], "sentence-detokenized": "After obtaining a license to inventor George Devol's original patent, Engelberger developed the first industrial robot in the United States, Unimate, in the 1950s.", "token2charspan": [[0, 5], [6, 15], [16, 17], [18, 25], [26, 28], [29, 37], [38, 44], [45, 50], [50, 52], [53, 61], [62, 68], [68, 69], [70, 81], [82, 91], [92, 95], [96, 101], [102, 112], [113, 118], [119, 121], [122, 125], [126, 132], [133, 139], [139, 140], [141, 148], [148, 149], [150, 152], [153, 156], [157, 162], [162, 163]]}
{"doc_key": "ai-train-77", "ner": [[4, 5, "task"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "input", "is", "called", "speech", "recognition", "and", "the", "output", "is", "called", "speech", "synthesis", "."], "sentence-detokenized": "The input is called speech recognition and the output is called speech synthesis.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 19], [20, 26], [27, 38], [39, 42], [43, 46], [47, 53], [54, 56], [57, 63], [64, 70], [71, 80], [80, 81]]}
{"doc_key": "ai-train-78", "ner": [[3, 3, "programlang"], [6, 6, "programlang"], [14, 14, "programlang"], [18, 18, "programlang"], [28, 28, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 14, 14, "named", "", false, false], [6, 6, 3, 3, "origin", "descendant_of", false, false], [6, 6, 18, 18, "general-affiliation", "", false, false], [6, 6, 28, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Descendants", "of", "the", "CLIPS", "language", "include", "Jess", "(", "the", "rule", "-", "based", "part", "of", "CLIPS", ",", "rewritten", "in", "Java", ",", "later", "evolved", "in", "a", "different", "direction", ")", ",", "JESS", "was", "originally", "inspired", "by"], "sentence-detokenized": "Descendants of the CLIPS language include Jess (the rule-based part of CLIPS, rewritten in Java, later evolved in a different direction), JESS was originally inspired by", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 24], [25, 33], [34, 41], [42, 46], [47, 48], [48, 51], [52, 56], [56, 57], [57, 62], [63, 67], [68, 70], [71, 76], [76, 77], [78, 87], [88, 90], [91, 95], [95, 96], [97, 102], [103, 110], [111, 113], [114, 115], [116, 125], [126, 135], [135, 136], [136, 137], [138, 142], [143, 146], [147, 157], [158, 166], [167, 169]]}
{"doc_key": "ai-train-79", "ner": [[8, 8, "product"], [12, 14, "product"], [17, 18, "organisation"], [22, 23, "product"], [40, 41, "product"], [43, 44, "product"], [59, 60, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 14, 8, 8, "type-of", "", false, false], [17, 18, 12, 14, "usage", "", false, false], [22, 23, 17, 18, "artifact", "", false, false], [40, 41, 17, 18, "origin", "", true, false], [40, 41, 59, 60, "related-to", "", true, false], [43, 44, 17, 18, "origin", "", true, false], [43, 44, 59, 60, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["She", "has", "also", "created", "flexible", "intelligent", "applications", "for", "AGVs", ",", "developing", "the", "Motivity", "control", "system", "used", "by", "RMT", "Robotics", "to", "develop", "the", "ADAM", "iAGV", "(", "Self", "-", "Guided", "Vehicle", ")", "used", "for", "complex", "pick", "and", "place", "operations", ",", "combined", "with", "gantry", "systems", "and", "industrial", "robot", "arms", "used", "in", "tier", "one", "factories", "to", "move", "products", "from", "process", "to", "process", "in", "non-linear", "patterns", "."], "sentence-detokenized": "She has also created flexible intelligent applications for AGVs, developing the Motivity control system used by RMT Robotics to develop the ADAM iAGV (Self-Guided Vehicle) used for complex pick and place operations, combined with gantry systems and industrial robot arms used in tier one factories to move products from process to process in non-linear patterns.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 20], [21, 29], [30, 41], [42, 54], [55, 58], [59, 63], [63, 64], [65, 75], [76, 79], [80, 88], [89, 96], [97, 103], [104, 108], [109, 111], [112, 115], [116, 124], [125, 127], [128, 135], [136, 139], [140, 144], [145, 149], [150, 151], [151, 155], [155, 156], [156, 162], [163, 170], [170, 171], [172, 176], [177, 180], [181, 188], [189, 193], [194, 197], [198, 203], [204, 214], [214, 215], [216, 224], [225, 229], [230, 236], [237, 244], [245, 248], [249, 259], [260, 265], [266, 270], [271, 275], [276, 278], [279, 283], [284, 287], [288, 297], [298, 300], [301, 305], [306, 314], [315, 319], [320, 327], [328, 330], [331, 338], [339, 341], [342, 352], [353, 361], [361, 362]]}
{"doc_key": "ai-train-80", "ner": [[6, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Parameters", "\u03b2", "are", "usually", "estimated", "by", "maximum", "likelihood", "."], "sentence-detokenized": "Parameters \u03b2 are usually estimated by maximum likelihood.", "token2charspan": [[0, 10], [11, 12], [13, 16], [17, 24], [25, 34], [35, 37], [38, 45], [46, 56], [56, 57]]}
{"doc_key": "ai-train-81", "ner": [[0, 1, "task"], [5, 5, "metrics"], [7, 7, "metrics"], [9, 10, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 0, 1, "part-of", "", false, false], [7, 7, 0, 1, "part-of", "", false, false], [9, 10, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Information", "retrieval", "metrics", "such", "as", "precision", "and", "recall", "or", "DCG", "are", "useful", "to", "assess", "the", "quality", "of", "the", "recommendation", "method", "."], "sentence-detokenized": "Information retrieval metrics such as precision and recall or DCG are useful to assess the quality of the recommendation method.", "token2charspan": [[0, 11], [12, 21], [22, 29], [30, 34], [35, 37], [38, 47], [48, 51], [52, 58], [59, 61], [62, 65], [66, 69], [70, 76], [77, 79], [80, 86], [87, 90], [91, 98], [99, 101], [102, 105], [106, 120], [121, 127], [127, 128]]}
{"doc_key": "ai-train-82", "ner": [[6, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "typical", "factory", "contains", "hundreds", "of", "industrial", "robots", "working", "on", "fully", "automated", "production", "lines", ",", "with", "one", "robot", "for", "every", "ten", "human", "workers", "."], "sentence-detokenized": "A typical factory contains hundreds of industrial robots working on fully automated production lines, with one robot for every ten human workers.", "token2charspan": [[0, 1], [2, 9], [10, 17], [18, 26], [27, 35], [36, 38], [39, 49], [50, 56], [57, 64], [65, 67], [68, 73], [74, 83], [84, 94], [95, 100], [100, 101], [102, 106], [107, 110], [111, 116], [117, 120], [121, 126], [127, 130], [131, 136], [137, 144], [144, 145]]}
{"doc_key": "ai-train-83", "ner": [[5, 5, "product"], [14, 14, "field"], [17, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "task"], [29, 29, "task"], [32, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[14, 14, 5, 5, "usage", "", false, true], [17, 18, 14, 14, "part-of", "", false, false], [20, 21, 14, 14, "part-of", "", false, false], [23, 24, 14, 14, "part-of", "", false, false], [26, 27, 14, 14, "part-of", "", false, false], [29, 29, 14, 14, "part-of", "", false, false], [32, 33, 14, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Over", "the", "past", "decade", ",", "PCNNs", "have", "been", "used", "in", "various", "areas", "of", "image", "processing", "including", ":", "image", "segmentation", ",", "feature", "generation", ",", "face", "extraction", ",", "motion", "detection", ",", "region", "augmentation", "and", "noise", "reduction", "."], "sentence-detokenized": "Over the past decade, PCNNs have been used in various areas of image processing including: image segmentation, feature generation, face extraction, motion detection, region augmentation and noise reduction.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 20], [20, 21], [22, 27], [28, 32], [33, 37], [38, 42], [43, 45], [46, 53], [54, 59], [60, 62], [63, 68], [69, 79], [80, 89], [89, 90], [91, 96], [97, 109], [109, 110], [111, 118], [119, 129], [129, 130], [131, 135], [136, 146], [146, 147], [148, 154], [155, 164], [164, 165], [166, 172], [173, 185], [186, 189], [190, 195], [196, 205], [205, 206]]}
{"doc_key": "ai-train-84", "ner": [[0, 0, "researcher"], [16, 17, "field"], [21, 21, "misc"], [27, 33, "conference"], [35, 35, "conference"], [39, 41, "misc"], [45, 49, "conference"], [50, 50, "conference"], [56, 57, "conference"], [59, 59, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 0, 16, 17, "related-to", "contributes_to", false, false], [0, 0, 21, 21, "win-defeat", "", false, false], [0, 0, 39, 41, "win-defeat", "", false, false], [21, 21, 27, 33, "temporal", "", false, false], [35, 35, 27, 33, "named", "", false, false], [39, 41, 45, 49, "temporal", "", false, false], [39, 41, 56, 57, "temporal", "", false, false], [50, 50, 45, 49, "named", "", false, false], [59, 59, 56, 57, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Xu", "has", "published", "more", "than", "50", "papers", "in", "international", "conferences", "and", "journals", "in", "the", "field", "of", "computer", "vision", "and", "received", "the", "best", "paper", "award", "at", "the", "2012", "International", "Conference", "on", "Non-photorealistic", "Rendering", "and", "Animation", "(", "NPAR", ")", "and", "the", "best", "reviewer", "award", "at", "the", "2012", "Asian", "Conference", "on", "Computer", "Vision", "ACCV", "and", "2015", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "."], "sentence-detokenized": "Xu has published more than 50 papers in international conferences and journals in the field of computer vision and received the best paper award at the 2012 International Conference on Non-photorealistic Rendering and Animation (NPAR) and the best reviewer award at the 2012 Asian Conference on Computer Vision ACCV and 2015 International Conference on Computer Vision (ICCV).", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 21], [22, 26], [27, 29], [30, 36], [37, 39], [40, 53], [54, 65], [66, 69], [70, 78], [79, 81], [82, 85], [86, 91], [92, 94], [95, 103], [104, 110], [111, 114], [115, 123], [124, 127], [128, 132], [133, 138], [139, 144], [145, 147], [148, 151], [152, 156], [157, 170], [171, 181], [182, 184], [185, 203], [204, 213], [214, 217], [218, 227], [228, 229], [229, 233], [233, 234], [235, 238], [239, 242], [243, 247], [248, 256], [257, 262], [263, 265], [266, 269], [270, 274], [275, 280], [281, 291], [292, 294], [295, 303], [304, 310], [311, 315], [316, 319], [320, 324], [325, 338], [339, 349], [350, 352], [353, 361], [362, 368], [369, 370], [370, 374], [374, 375], [375, 376]]}
{"doc_key": "ai-train-85", "ner": [[0, 0, "programlang"], [2, 3, "field"], [5, 6, "field"], [9, 10, "misc"], [13, 15, "researcher"], [16, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 2, 3, "part-of", "", false, false], [0, 0, 5, 6, "part-of", "", false, false], [0, 0, 9, 10, "type-of", "", false, false], [16, 18, 0, 0, "usage", "", false, false], [16, 18, 13, 15, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["CycL", "in", "computer", "science", "and", "artificial", "intelligence", "is", "an", "ontology", "language", "used", "in", "Doug", "Lenat", "'s", "artificial", "project", "Cyc."], "sentence-detokenized": "CycL in computer science and artificial intelligence is an ontology language used in Doug Lenat's artificial project Cyc.", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 24], [25, 28], [29, 39], [40, 52], [53, 55], [56, 58], [59, 67], [68, 76], [77, 81], [82, 84], [85, 89], [90, 95], [95, 97], [98, 108], [109, 116], [117, 121]]}
{"doc_key": "ai-train-86", "ner": [[2, 5, "task"], [6, 8, "metrics"], [14, 18, "metrics"], [20, 27, "metrics"], [35, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 8, 2, 5, "part-of", "", false, false], [14, 18, 6, 8, "named", "", false, false], [20, 27, 6, 8, "named", "", false, false], [35, 38, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Also", "in", "regression", "analysis", ",", "the", "mean", "square", "error", ",", "often", "called", "the", "root", "mean", "square", "error", "of", "prediction", "or", "out", "-", "of", "-", "sample", "mean", "square", "error", ",", "can", "mean", "the", "average", "of", "the", "squared", "deviations", "of", "the", "predictions", "from", "the", "true", "values", "on", "an", "out", "-", "of", "-", "sample", "test", "space", "generated", "by", "a", "model", "estimated", "on", "a", "particular", "sample", "space", "."], "sentence-detokenized": "Also in regression analysis, the mean square error, often called the root mean square error of prediction or out-of-sample mean square error, can mean the average of the squared deviations of the predictions from the true values on an out-of-sample test space generated by a model estimated on a particular sample space.", "token2charspan": [[0, 4], [5, 7], [8, 18], [19, 27], [27, 28], [29, 32], [33, 37], [38, 44], [45, 50], [50, 51], [52, 57], [58, 64], [65, 68], [69, 73], [74, 78], [79, 85], [86, 91], [92, 94], [95, 105], [106, 108], [109, 112], [112, 113], [113, 115], [115, 116], [116, 122], [123, 127], [128, 134], [135, 140], [140, 141], [142, 145], [146, 150], [151, 154], [155, 162], [163, 165], [166, 169], [170, 177], [178, 188], [189, 191], [192, 195], [196, 207], [208, 212], [213, 216], [217, 221], [222, 228], [229, 231], [232, 234], [235, 238], [238, 239], [239, 241], [241, 242], [242, 248], [249, 253], [254, 259], [260, 269], [270, 272], [273, 274], [275, 280], [281, 290], [291, 293], [294, 295], [296, 306], [307, 313], [314, 319], [319, 320]]}
{"doc_key": "ai-train-87", "ner": [[6, 8, "algorithm"], [10, 11, "algorithm"], [20, 23, "algorithm"], [35, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 8, 10, 11, "compare", "", false, false], [6, 8, 20, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "terms", "of", "results", ",", "the", "C", "-", "HOG", "and", "R-", "HOG", "block", "descriptors", "perform", "comparably", "well", ",", "with", "the", "C", "-", "HOG", "descriptors", "maintaining", "a", "slight", "advantage", "in", "miss", "detection", "rate", "at", "a", "fixed", "false", "positive", "rate", "in", "both", "datasets", "."], "sentence-detokenized": "In terms of results, the C-HOG and R-HOG block descriptors perform comparably well, with the C-HOG descriptors maintaining a slight advantage in miss detection rate at a fixed false positive rate in both datasets.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 19], [19, 20], [21, 24], [25, 26], [26, 27], [27, 30], [31, 34], [35, 37], [37, 40], [41, 46], [47, 58], [59, 66], [67, 77], [78, 82], [82, 83], [84, 88], [89, 92], [93, 94], [94, 95], [95, 98], [99, 110], [111, 122], [123, 124], [125, 131], [132, 141], [142, 144], [145, 149], [150, 159], [160, 164], [165, 167], [168, 169], [170, 175], [176, 181], [182, 190], [191, 195], [196, 198], [199, 203], [204, 212], [212, 213]]}
{"doc_key": "ai-train-88", "ner": [[4, 6, "algorithm"], [8, 8, "misc"], [10, 12, "algorithm"], [14, 15, "algorithm"], [17, 19, "algorithm"], [21, 23, "algorithm"], [25, 27, "algorithm"], [29, 30, "misc"], [36, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[4, 6, 8, 8, "usage", "", false, false], [10, 12, 29, 30, "usage", "", false, false], [14, 15, 29, 30, "usage", "", false, false], [17, 19, 29, 30, "usage", "", false, false], [21, 23, 29, 30, "usage", "", false, false], [25, 27, 29, 30, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Popular", "recognition", "algorithms", "include", "principal", "component", "analysis", "using", "eigenfaces", ",", "linear", "discriminant", "analysis", ",", "elastic", "matching", "using", "Fisher", "'s", "algorithm", ",", "hidden", "Markov", "model", ",", "multilinear", "subspace", "learning", "using", "tensor", "representation", ",", "and", "neuron", "-", "motivated", "dynamic", "linkage", "matching", "."], "sentence-detokenized": "Popular recognition algorithms include principal component analysis using eigenfaces, linear discriminant analysis, elastic matching using Fisher's algorithm, hidden Markov model, multilinear subspace learning using tensor representation, and neuron-motivated dynamic linkage matching.", "token2charspan": [[0, 7], [8, 19], [20, 30], [31, 38], [39, 48], [49, 58], [59, 67], [68, 73], [74, 84], [84, 85], [86, 92], [93, 105], [106, 114], [114, 115], [116, 123], [124, 132], [133, 138], [139, 145], [145, 147], [148, 157], [157, 158], [159, 165], [166, 172], [173, 178], [178, 179], [180, 191], [192, 200], [201, 209], [210, 215], [216, 222], [223, 237], [237, 238], [239, 242], [243, 249], [249, 250], [250, 259], [260, 267], [268, 275], [276, 284], [284, 285]]}
{"doc_key": "ai-train-89", "ner": [[3, 7, "misc"], [17, 19, "location"], [36, 38, "location"], [53, 53, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[17, 19, 3, 7, "temporal", "", false, false], [36, 38, 3, 7, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Beginning", "with", "the", "2019", "Toronto", "International", "Film", "Festival", ",", "films", "may", "be", "banned", "from", "screening", "at", "the", "Scotiabank", "Theatre", "Toronto", "-", "one", "of", "the", "festival", "'s", "main", "venues", "-", "and", "shown", "elsewhere", "(", "such", "as", "the", "TIFF", "Bell", "Lightbox", "and", "other", "local", "cinemas", ")", "if", "they", "are", "distributed", "by", "a", "service", "such", "as", "Netflix", "."], "sentence-detokenized": "Beginning with the 2019 Toronto International Film Festival, films may be banned from screening at the Scotiabank Theatre Toronto - one of the festival's main venues - and shown elsewhere (such as the TIFF Bell Lightbox and other local cinemas) if they are distributed by a service such as Netflix.", "token2charspan": [[0, 9], [10, 14], [15, 18], [19, 23], [24, 31], [32, 45], [46, 50], [51, 59], [59, 60], [61, 66], [67, 70], [71, 73], [74, 80], [81, 85], [86, 95], [96, 98], [99, 102], [103, 113], [114, 121], [122, 129], [130, 131], [132, 135], [136, 138], [139, 142], [143, 151], [151, 153], [154, 158], [159, 165], [166, 167], [168, 171], [172, 177], [178, 187], [188, 189], [189, 193], [194, 196], [197, 200], [201, 205], [206, 210], [211, 219], [220, 223], [224, 229], [230, 235], [236, 243], [243, 244], [245, 247], [248, 252], [253, 256], [257, 268], [269, 271], [272, 273], [274, 281], [282, 286], [287, 289], [290, 297], [297, 298]]}
{"doc_key": "ai-train-90", "ner": [[3, 3, "organisation"], [8, 9, "researcher"], [5, 7, "organisation"], [13, 14, "researcher"], [24, 29, "product"], [37, 38, "researcher"], [40, 42, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 3, 5, 7, "related-to", "purchases", false, false], [8, 9, 13, 14, "named", "same", false, false], [8, 9, 37, 38, "named", "same", false, false], [5, 7, 8, 9, "origin", "founded_by", false, false], [24, 29, 3, 3, "artifact", "", false, false], [40, 42, 37, 38, "artifact", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "1977", ",", "Unimation", "acquired", "Vicarm", "Inc", ".", "Victor", "Scheinman", ",", "and", "with", "Scheinman", "'s", "help", ",", "the", "company", "created", "and", "began", "producing", "the", "Programmable", "Universal", "Assembly", "Manipulator", ",", "a", "new", "model", "of", "robotic", "arm", ",", "using", "Scheinman", "'s", "advanced", "VAL", "programming", "language", "."], "sentence-detokenized": "In 1977, Unimation acquired Vicarm Inc. Victor Scheinman, and with Scheinman's help, the company created and began producing the Programmable Universal Assembly Manipulator, a new model of robotic arm, using Scheinman's advanced VAL programming language.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 18], [19, 27], [28, 34], [35, 38], [38, 39], [40, 46], [47, 56], [56, 57], [58, 61], [62, 66], [67, 76], [76, 78], [79, 83], [83, 84], [85, 88], [89, 96], [97, 104], [105, 108], [109, 114], [115, 124], [125, 128], [129, 141], [142, 151], [152, 160], [161, 172], [172, 173], [174, 175], [176, 179], [180, 185], [186, 188], [189, 196], [197, 200], [200, 201], [202, 207], [208, 217], [217, 219], [220, 228], [229, 232], [233, 244], [245, 253], [253, 254]]}
{"doc_key": "ai-train-91", "ner": [[0, 2, "product"], [10, 11, "algorithm"], [14, 17, "product"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[0, 2, 10, 11, "origin", "implementation_of", false, false], [0, 2, 14, 17, "part-of", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["J", "48", "is", "an", "open", "source", "Java", "implementation", "of", "the", "C4.5", "algorithm", "in", "the", "Weka", "data", "mining", "tool", "."], "sentence-detokenized": "J48 is an open source Java implementation of the C4.5 algorithm in the Weka data mining tool.", "token2charspan": [[0, 1], [1, 3], [4, 6], [7, 9], [10, 14], [15, 21], [22, 26], [27, 41], [42, 44], [45, 48], [49, 53], [54, 63], [64, 66], [67, 70], [71, 75], [76, 80], [81, 87], [88, 92], [92, 93]]}
{"doc_key": "ai-train-92", "ner": [[9, 9, "metrics"], [2, 5, "product"], [21, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 2, 5, "win-defeat", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["According", "to", "Google", "Scholar", ",", "the", "2004", "article", "on", "SSIM", "has", "been", "cited", "more", "than", "20,000", "times", ",", "it", "also", "received", "the", "IEEE", "Signal", "Processing", "Society", "Sustained", "Impact", "Award", "for", "2016", ",", "which", "indicates", "that", "the", "article", "has", "an", "extremely", "high", "impact", "for", "at", "least", "10", "years", "after", "its", "publication", "."], "sentence-detokenized": "According to Google Scholar, the 2004 article on SSIM has been cited more than 20,000 times, it also received the IEEE Signal Processing Society Sustained Impact Award for 2016, which indicates that the article has an extremely high impact for at least 10 years after its publication.", "token2charspan": [[0, 9], [10, 12], [13, 19], [20, 27], [27, 28], [29, 32], [33, 37], [38, 45], [46, 48], [49, 53], [54, 57], [58, 62], [63, 68], [69, 73], [74, 78], [79, 85], [86, 91], [91, 92], [93, 95], [96, 100], [101, 109], [110, 113], [114, 118], [119, 125], [126, 136], [137, 144], [145, 154], [155, 161], [162, 167], [168, 171], [172, 176], [176, 177], [178, 183], [184, 193], [194, 198], [199, 202], [203, 210], [211, 214], [215, 217], [218, 227], [228, 232], [233, 239], [240, 243], [244, 246], [247, 252], [253, 255], [256, 261], [262, 267], [268, 271], [272, 283], [283, 284]]}
{"doc_key": "ai-train-93", "ner": [[0, 6, "task"], [20, 22, "product"], [39, 41, "product"], [44, 44, "organisation"], [45, 45, "product"], [50, 50, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 6, 44, 44, "artifact", "", false, false], [20, 22, 0, 6, "related-to", "performs", false, false], [20, 22, 39, 41, "part-of", "", false, false], [44, 44, 50, 50, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Speech", "synthesis", "is", "getting", "closer", "to", "being", "completely", "indistinguishable", "from", "the", "real", "human", "voice", "with", "the", "advent", "in", "2016", "of", "Adobe", "'s", "Voco", "voice", "editing", "and", "generation", "software", ",", "a", "prototype", "that", "is", "planned", "to", "be", "part", "of", "the", "Adobe", "Creative", "Suite", ",", "and", "DeepMind", "WaveNet", ",", "a", "prototype", "from", "Google", "."], "sentence-detokenized": "Speech synthesis is getting closer to being completely indistinguishable from the real human voice with the advent in 2016 of Adobe's Voco voice editing and generation software, a prototype that is planned to be part of the Adobe Creative Suite, and DeepMind WaveNet, a prototype from Google.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 27], [28, 34], [35, 37], [38, 43], [44, 54], [55, 72], [73, 77], [78, 81], [82, 86], [87, 92], [93, 98], [99, 103], [104, 107], [108, 114], [115, 117], [118, 122], [123, 125], [126, 131], [131, 133], [134, 138], [139, 144], [145, 152], [153, 156], [157, 167], [168, 176], [176, 177], [178, 179], [180, 189], [190, 194], [195, 197], [198, 205], [206, 208], [209, 211], [212, 216], [217, 219], [220, 223], [224, 229], [230, 238], [239, 244], [244, 245], [246, 249], [250, 258], [259, 266], [266, 267], [268, 269], [270, 279], [280, 284], [285, 291], [291, 292]]}
{"doc_key": "ai-train-94", "ner": [[0, 0, "researcher"], [7, 9, "organisation"], [15, 27, "organisation"], [28, 28, "conference"], [35, 39, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 7, 9, "role", "", false, false], [0, 0, 15, 27, "role", "", false, false], [0, 0, 28, 28, "role", "", false, false], [0, 0, 35, 39, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Poggio", "is", "a", "Distinguished", "Fellow", "of", "the", "Neuroscience", "Research", "Program", ",", "a", "Fellow", "of", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "and", "a", "founding", "member", "of", "the", "AAAI", "and", "a", "founding", "member", "of", "the", "McGovern", "Institute", "for", "Brain", "Research", "."], "sentence-detokenized": "Poggio is a Distinguished Fellow of the Neuroscience Research Program, a Fellow of the American Academy of Arts and Sciences, and a founding member of the AAAI and a founding member of the McGovern Institute for Brain Research.", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 25], [26, 32], [33, 35], [36, 39], [40, 52], [53, 61], [62, 69], [69, 70], [71, 72], [73, 79], [80, 82], [83, 86], [87, 95], [96, 103], [104, 106], [107, 111], [112, 115], [116, 124], [124, 125], [126, 129], [130, 131], [132, 140], [141, 147], [148, 150], [151, 154], [155, 159], [160, 163], [164, 165], [166, 174], [175, 181], [182, 184], [185, 188], [189, 197], [198, 207], [208, 211], [212, 217], [218, 226], [226, 227]]}
{"doc_key": "ai-train-95", "ner": [[9, 9, "task"], [8, 11, "task"], [15, 16, "task"], [23, 23, "misc"], [24, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 9, 15, 16, "cause-effect", "", false, false], [8, 11, 15, 16, "cause-effect", "", false, false], [24, 25, 15, 16, "topic", "", false, false], [24, 25, 23, 23, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "the", "1990s", ",", "inspired", "by", "advances", "in", "speech", "recognition", "and", "synthesis", ",", "research", "in", "speech", "translation", "began", "with", "the", "development", "of", "the", "German", "Verbmobil", "project", "."], "sentence-detokenized": "In the 1990s, inspired by advances in speech recognition and synthesis, research in speech translation began with the development of the German Verbmobil project.", "token2charspan": [[0, 2], [3, 6], [7, 12], [12, 13], [14, 22], [23, 25], [26, 34], [35, 37], [38, 44], [45, 56], [57, 60], [61, 70], [70, 71], [72, 80], [81, 83], [84, 90], [91, 102], [103, 108], [109, 113], [114, 117], [118, 129], [130, 132], [133, 136], [137, 143], [144, 153], [154, 161], [161, 162]]}
{"doc_key": "ai-train-96", "ner": [[3, 4, "researcher"], [8, 9, "researcher"], [11, 12, "researcher"], [17, 21, "algorithm"], [27, 27, "algorithm"], [14, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 8, 9, "role", "", false, false], [17, 21, 3, 4, "origin", "", false, false], [17, 21, 8, 9, "origin", "", false, false], [17, 21, 11, 12, "origin", "", false, false], [17, 21, 14, 32, "part-of", "", false, false], [27, 27, 17, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "1999", ",", "Felix", "Gers", ",", "his", "advisor", "J\u00fcrgen", "Schmidhuber", "and", "Fred", "Cummins", "introduced", "the", "\"", "closed", "gate", "\"", "technology", "(", "the", "so", "-", "called", "\"", "stored", "gate", "\"", ")", "into", "the", "LSTM", "architecture", ","], "sentence-detokenized": "In 1999, Felix Gers, his advisor J\u00fcrgen Schmidhuber and Fred Cummins introduced the \"closed gate\" technology (the so-called \"stored gate\") into the LSTM architecture,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 19], [19, 20], [21, 24], [25, 32], [33, 39], [40, 51], [52, 55], [56, 60], [61, 68], [69, 79], [80, 83], [84, 85], [85, 91], [92, 96], [96, 97], [98, 108], [109, 110], [110, 113], [114, 116], [116, 117], [117, 123], [124, 125], [125, 131], [132, 136], [136, 137], [137, 138], [139, 143], [144, 147], [148, 152], [153, 165], [165, 166]]}
{"doc_key": "ai-train-97", "ner": [[4, 8, "field"], [2, 7, "field"], [10, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 14, 4, 8, "part-of", "", false, false], [10, 14, 2, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "the", "theory", "of", "digital", "signal", "and", "information", "processing", ",", "the", "normalized", "function", "sinc", "is", "usually", "defined", "for"], "sentence-detokenized": "In the theory of digital signal and information processing, the normalized function sinc is usually defined for", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 16], [17, 24], [25, 31], [32, 35], [36, 47], [48, 58], [58, 59], [60, 63], [64, 74], [75, 83], [84, 88], [89, 91], [92, 99], [100, 107], [108, 111]]}
{"doc_key": "ai-train-98", "ner": [[3, 4, "field"], [9, 11, "researcher"], [18, 21, "conference"], [24, 28, "organisation"], [30, 30, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 9, 11, "origin", "coined_term", false, false], [9, 11, 18, 21, "role", "", false, false], [9, 11, 24, 28, "role", "", false, false], [30, 30, 24, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "term", "\"", "computational", "linguistics", "\"", "was", "first", "proposed", "by", "David", "Hayes", ",", "a", "founding", "member", "of", "the", "Association", "for", "Computational", "Linguistics", "and", "the", "International", "Committee", "for", "Computational", "Linguistics", "(", "ICCL", ")", "."], "sentence-detokenized": "The term \"computational linguistics\" was first proposed by David Hayes, a founding member of the Association for Computational Linguistics and the International Committee for Computational Linguistics (ICCL).", "token2charspan": [[0, 3], [4, 8], [9, 10], [10, 23], [24, 35], [35, 36], [37, 40], [41, 46], [47, 55], [56, 58], [59, 64], [65, 70], [70, 71], [72, 73], [74, 82], [83, 89], [90, 92], [93, 96], [97, 108], [109, 112], [113, 126], [127, 138], [139, 142], [143, 146], [147, 160], [161, 170], [171, 174], [175, 188], [189, 200], [201, 202], [202, 206], [206, 207], [207, 208]]}
{"doc_key": "ai-train-99", "ner": [[8, 13, "misc"], [11, 11, "misc"], [33, 35, "metrics"], [39, 40, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[39, 40, 33, 35, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["59", ",", "pp.", "2547-2553", ",", "Oct.", "2011", "In", "one", "-dimensional", "polynomial", "DACs", "with", "memory", "(", "or", "without", "memory", ")", "to", "find", "the", "coefficients", "of", "the", "polynomials", "of", "the", "digital", "preamplifier", "and", "minimize", "the", "mean", "square", "error", "(", "MSE", ")", ",", "the", "distorted", "output", "of", "the", "nonlinear", "system", "must", "be", "resampled", "at", "a", "rate", "that", "allows", "to", "capture", "the", "nonlinear", "products", "of", "the", "order", "of", "the", "digital", "preamplifier", "."], "sentence-detokenized": "59, pp. 2547-2553, Oct. 2011 In one-dimensional polynomial DACs with memory (or without memory) to find the coefficients of the polynomials of the digital preamplifier and minimize the mean square error (MSE), the distorted output of the nonlinear system must be resampled at a rate that allows to capture the nonlinear products of the order of the digital preamplifier.", "token2charspan": [[0, 2], [2, 3], [4, 7], [8, 17], [17, 18], [19, 23], [24, 28], [29, 31], [32, 35], [35, 47], [48, 58], [59, 63], [64, 68], [69, 75], [76, 77], [77, 79], [80, 87], [88, 94], [94, 95], [96, 98], [99, 103], [104, 107], [108, 120], [121, 123], [124, 127], [128, 139], [140, 142], [143, 146], [147, 154], [155, 167], [168, 171], [172, 180], [181, 184], [185, 189], [190, 196], [197, 202], [203, 204], [204, 207], [207, 208], [208, 209], [210, 213], [214, 223], [224, 230], [231, 233], [234, 237], [238, 247], [248, 254], [255, 259], [260, 262], [263, 272], [273, 275], [276, 277], [278, 282], [283, 287], [288, 294], [295, 297], [298, 305], [306, 309], [310, 319], [320, 328], [329, 331], [332, 335], [336, 341], [342, 344], [345, 348], [349, 356], [357, 369], [369, 370]]}
{"doc_key": "ai-train-100", "ner": [[0, 1, "researcher"], [9, 9, "location"], [11, 12, "location"], [14, 15, "country"], [19, 19, "location"], [21, 21, "country"], [36, 43, "organisation"], [44, 47, "organisation"], [49, 49, "location"], [54, 58, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 1, 9, 9, "physical", "", false, false], [0, 1, 44, 47, "physical", "", false, false], [0, 1, 54, 58, "role", "", false, false], [9, 9, 11, 12, "physical", "", false, false], [11, 12, 14, 15, "physical", "", false, false], [36, 43, 44, 47, "part-of", "", false, false], [44, 47, 49, 49, "physical", "", false, false], [54, 58, 36, 43, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Boris", "Katz", "(", "born", "October", "5", ",", "1947", ",", "Chisinau", ",", "Moldavian", "SSR", ",", "Soviet", "Union", ",", "(", "now", "Chisinau", ",", "Moldova", ")", ")", "is", "a", "leading", "American", "research", "scientist", "(", "computer", "scientist", ")", "at", "the", "Computer", "Science", "and", "Artificial", "Intelligence", "Laboratory", "of", "the", "Massachusetts", "Institute", "of", "Technology", "in", "Cambridge", ",", "head", "of", "the", "InfoLab", "group", "of", "the", "laboratory", "."], "sentence-detokenized": "Boris Katz (born October 5, 1947, Chisinau, Moldavian SSR, Soviet Union, (now Chisinau, Moldova)) is a leading American research scientist (computer scientist) at the Computer Science and Artificial Intelligence Laboratory of the Massachusetts Institute of Technology in Cambridge, head of the InfoLab group of the laboratory.", "token2charspan": [[0, 5], [6, 10], [11, 12], [12, 16], [17, 24], [25, 26], [26, 27], [28, 32], [32, 33], [34, 42], [42, 43], [44, 53], [54, 57], [57, 58], [59, 65], [66, 71], [71, 72], [73, 74], [74, 77], [78, 86], [86, 87], [88, 95], [95, 96], [96, 97], [98, 100], [101, 102], [103, 110], [111, 119], [120, 128], [129, 138], [139, 140], [140, 148], [149, 158], [158, 159], [160, 162], [163, 166], [167, 175], [176, 183], [184, 187], [188, 198], [199, 211], [212, 222], [223, 225], [226, 229], [230, 243], [244, 253], [254, 256], [257, 267], [268, 270], [271, 280], [280, 281], [282, 286], [287, 289], [290, 293], [294, 301], [302, 307], [308, 310], [311, 314], [315, 325], [325, 326]]}
