{"doc_key": "ai-dev-1", "ner": [[2, 2, "metrics"], [7, 7, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 7, 2, 2, "part-of", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Here", "the", "accuracy", "is", "measured", "by", "the", "error", "rate", ",", "which", "is", "defined", "as", ":"], "sentence-detokenized": "Here the accuracy is measured by the error rate, which is defined as:", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 20], [21, 29], [30, 32], [33, 36], [37, 42], [43, 47], [47, 48], [49, 54], [55, 57], [58, 65], [66, 68], [68, 69]]}
{"doc_key": "ai-dev-2", "ner": [[6, 6, "algorithm"], [13, 14, "misc"], [17, 20, "algorithm"], [18, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 13, 14, "type-of", "", false, false], [6, 6, 17, 20, "related-to", "", false, false], [6, 6, 18, 21, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["From", "this", "point", "of", "view", ",", "SVM", "is", "closely", "related", "to", "other", "fundamental", "classification", "algorithms", "such", "as", "regularized", "logistic", "least", "squares", "regression", "."], "sentence-detokenized": "From this point of view, SVM is closely related to other fundamental classification algorithms such as regularized logistic least squares regression.", "token2charspan": [[0, 4], [5, 9], [10, 15], [16, 18], [19, 23], [23, 24], [25, 28], [29, 31], [32, 39], [40, 47], [48, 50], [51, 56], [57, 68], [69, 83], [84, 94], [95, 99], [100, 102], [103, 114], [115, 123], [124, 129], [130, 137], [138, 148], [148, 149]]}
{"doc_key": "ai-dev-3", "ner": [[0, 1, "person"], [3, 6, "person"], [13, 15, "person"], [16, 18, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 6, 0, 1, "named", "actor_plays_character", false, false], [3, 6, 0, 1, "origin", "actor_plays_character", false, false], [16, 18, 13, 15, "named", "actor_plays_character", false, false], [16, 18, 13, 15, "origin", "actor_plays_character", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Brion", "James", "plays", "Leon", "Kowalski", ",", "a", "replicant", "fighter", "and", "worker", ",", "and", "Joanna", "Cassidy", "plays", "Zhora", ",", "a", "replicant", "killer", "."], "sentence-detokenized": "Brion James plays Leon Kowalski, a replicant fighter and worker, and Joanna Cassidy plays Zhora, a replicant killer.", "token2charspan": [[0, 5], [6, 11], [12, 17], [18, 22], [23, 31], [31, 32], [33, 34], [35, 44], [45, 52], [53, 56], [57, 63], [63, 64], [65, 68], [69, 75], [76, 83], [84, 89], [90, 95], [95, 96], [97, 98], [99, 108], [109, 115], [115, 116]]}
{"doc_key": "ai-dev-4", "ner": [[17, 20, "product"], [22, 22, "product"], [25, 25, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 20, 25, 25, "physical", "", false, false], [22, 22, 17, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "image", "to", "be", "scanned", ",", "stored", "and", "reproduced", "in", "digital", "pixels", "was", "shown", "on", "the", "Standards", "Eastern", "Automatic", "Computer", "(", "SEAC", ")", "at", "NIST", "."], "sentence-detokenized": "The first image to be scanned, stored and reproduced in digital pixels was shown on the Standards Eastern Automatic Computer (SEAC) at NIST.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 18], [19, 21], [22, 29], [29, 30], [31, 37], [38, 41], [42, 52], [53, 55], [56, 63], [64, 70], [71, 74], [75, 80], [81, 83], [84, 87], [88, 97], [98, 105], [106, 115], [116, 124], [125, 126], [126, 130], [130, 131], [132, 134], [135, 139], [139, 140]]}
{"doc_key": "ai-dev-5", "ner": [[0, 6, "task"], [21, 22, "task"], [24, 25, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 6, 21, 22, "part-of", "", false, false], [0, 6, 24, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Segmentation", "of", "text", "by", "topics", "or", "cues", "can", "be", "useful", "in", "some", "natural", "language", "processing", "tasks", ":", "it", "can", "significantly", "improve", "information", "retrieval", "or", "speech", "recognition", "(", "by", "indexing", "/", "recognizing", "documents", "more", "accurately", "or", "by", "retrieving", "the", "specific", "part", "of", "the", "document", "that", "matches", "the", "query", ")", "."], "sentence-detokenized": "Segmentation of text by topics or cues can be useful in some natural language processing tasks: it can significantly improve information retrieval or speech recognition (by indexing/recognizing documents more accurately or by retrieving the specific part of the document that matches the query).", "token2charspan": [[0, 12], [13, 15], [16, 20], [21, 23], [24, 30], [31, 33], [34, 38], [39, 42], [43, 45], [46, 52], [53, 55], [56, 60], [61, 68], [69, 77], [78, 88], [89, 94], [94, 95], [96, 98], [99, 102], [103, 116], [117, 124], [125, 136], [137, 146], [147, 149], [150, 156], [157, 168], [169, 170], [170, 172], [173, 181], [181, 182], [182, 193], [194, 203], [204, 208], [209, 219], [220, 222], [223, 225], [226, 236], [237, 240], [241, 249], [250, 254], [255, 257], [258, 261], [262, 270], [271, 275], [276, 283], [284, 287], [288, 293], [293, 294], [294, 295]]}
{"doc_key": "ai-dev-6", "ner": [[6, 7, "university"], [22, 23, "conference"], [26, 30, "university"], [37, 38, "researcher"], [40, 41, "researcher"], [43, 44, "researcher"], [46, 47, "researcher"], [49, 50, "researcher"], [52, 53, "researcher"], [55, 57, "researcher"], [60, 61, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[22, 23, 26, 30, "physical", "", false, false], [37, 38, 22, 23, "physical", "", false, false], [37, 38, 22, 23, "role", "", false, false], [37, 38, 22, 23, "temporal", "", false, false], [40, 41, 22, 23, "physical", "", false, false], [40, 41, 22, 23, "role", "", false, false], [40, 41, 22, 23, "temporal", "", false, false], [43, 44, 22, 23, "physical", "", false, false], [43, 44, 22, 23, "role", "", false, false], [43, 44, 22, 23, "temporal", "", false, false], [46, 47, 22, 23, "physical", "", false, false], [46, 47, 22, 23, "role", "", false, false], [46, 47, 22, 23, "temporal", "", false, false], [49, 50, 22, 23, "physical", "", false, false], [49, 50, 22, 23, "role", "", false, false], [49, 50, 22, 23, "temporal", "", false, false], [52, 53, 22, 23, "physical", "", false, false], [52, 53, 22, 23, "role", "", false, false], [52, 53, 22, 23, "temporal", "", false, false], [55, 57, 22, 23, "physical", "", false, false], [55, 57, 22, 23, "role", "", false, false], [55, 57, 22, 23, "temporal", "", false, false], [60, 61, 22, 23, "physical", "", false, false], [60, 61, 22, 23, "role", "", false, false], [60, 61, 22, 23, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "sentence": ["He", "organized", "such", "a", "symposium", "at", "Indiana", "University", "in", "1999", ",", "and", "in", "April", "2000", "he", "organized", "a", "larger", "symposium", "entitled", "\"", "Spiritual", "Works", "\"", "at", "Stanford", "University", ",", "where", "he", "moderated", "a", "panel", "of", "experts", "including", "Ray", "Kurzweil", ",", "Hans", "Moravec", ",", "Kevin", "Kelly", ",", "Ralph", "Merkle", ",", "Bill", "Joy", ",", "Frank", "Drake", ",", "John", "Henry", "Holland", ",", "and", "John", "Koz", "."], "sentence-detokenized": "He organized such a symposium at Indiana University in 1999, and in April 2000 he organized a larger symposium entitled \"Spiritual Works\" at Stanford University, where he moderated a panel of experts including Ray Kurzweil, Hans Moravec, Kevin Kelly, Ralph Merkle, Bill Joy, Frank Drake, John Henry Holland, and John Koz.", "token2charspan": [[0, 2], [3, 12], [13, 17], [18, 19], [20, 29], [30, 32], [33, 40], [41, 51], [52, 54], [55, 59], [59, 60], [61, 64], [65, 67], [68, 73], [74, 78], [79, 81], [82, 91], [92, 93], [94, 100], [101, 110], [111, 119], [120, 121], [121, 130], [131, 136], [136, 137], [138, 140], [141, 149], [150, 160], [160, 161], [162, 167], [168, 170], [171, 180], [181, 182], [183, 188], [189, 191], [192, 199], [200, 209], [210, 213], [214, 222], [222, 223], [224, 228], [229, 236], [236, 237], [238, 243], [244, 249], [249, 250], [251, 256], [257, 263], [263, 264], [265, 269], [270, 273], [273, 274], [275, 280], [281, 286], [286, 287], [288, 292], [293, 298], [299, 306], [306, 307], [308, 311], [312, 316], [317, 320], [320, 321]]}
{"doc_key": "ai-dev-7", "ner": [[7, 7, "metrics"], [8, 8, "metrics"], [11, 11, "metrics"], [12, 14, "metrics"], [21, 22, "metrics"], [43, 43, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 7, 21, 22, "named", "", false, false], [8, 8, 7, 7, "named", "", false, false], [11, 11, 43, 43, "named", "", false, false], [12, 14, 11, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["To", "calculate", "the", "score", ",", "both", "the", "accuracy", "p", "and", "the", "recall", "r", "of", "the", "test", "are", "taken", "into", "account", ":", "p", "is", "the", "number", "of", "correct", "positive", "results", "divided", "by", "the", "number", "of", "all", "positive", "results", "returned", "by", "the", "classifier", ",", "and", "r", "is", "the", "number", "of", "correct", "positive", "results", "divided", "by", "the", "number", "of", "all", "relevant", "samples", "(", "all", "samples", "that", "should", "have", "been", "identified", "as", "positive", ")", "."], "sentence-detokenized": "To calculate the score, both the accuracy p and the recall r of the test are taken into account: p is the number of correct positive results divided by the number of all positive results returned by the classifier, and r is the number of correct positive results divided by the number of all relevant samples (all samples that should have been identified as positive).", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 22], [22, 23], [24, 28], [29, 32], [33, 41], [42, 43], [44, 47], [48, 51], [52, 58], [59, 60], [61, 63], [64, 67], [68, 72], [73, 76], [77, 82], [83, 87], [88, 95], [95, 96], [97, 98], [99, 101], [102, 105], [106, 112], [113, 115], [116, 123], [124, 132], [133, 140], [141, 148], [149, 151], [152, 155], [156, 162], [163, 165], [166, 169], [170, 178], [179, 186], [187, 195], [196, 198], [199, 202], [203, 213], [213, 214], [215, 218], [219, 220], [221, 223], [224, 227], [228, 234], [235, 237], [238, 245], [246, 254], [255, 262], [263, 270], [271, 273], [274, 277], [278, 284], [285, 287], [288, 291], [292, 300], [301, 308], [309, 310], [310, 313], [314, 321], [322, 326], [327, 333], [334, 338], [339, 343], [344, 354], [355, 357], [358, 366], [366, 367], [367, 368]]}
{"doc_key": "ai-dev-8", "ner": [[4, 6, "organisation"], [26, 28, "product"], [34, 37, "person"], [41, 41, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 26, 28, "artifact", "", false, false], [26, 28, 34, 37, "win-defeat", "", false, false], [26, 28, 41, 41, "win-defeat", "", true, false], [34, 37, 41, 41, "win-defeat", "lose", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "its", "acquisition", "by", "Google", ",", "the", "company", "has", "made", "a", "number", "of", "significant", "achievements", ",", "among", "which", "perhaps", "the", "most", "notable", "is", "the", "creation", "of", "AlphaGo", ",", "the", "program", "that", "defeated", "world", "champion", "Lee", "Sedol", "in", "a", "challenging", "game", "of", "Go", "."], "sentence-detokenized": "Since its acquisition by Google, the company has made a number of significant achievements, among which perhaps the most notable is the creation of AlphaGo, the program that defeated world champion Lee Sedol in a challenging game of Go.", "token2charspan": [[0, 5], [6, 9], [10, 21], [22, 24], [25, 31], [31, 32], [33, 36], [37, 44], [45, 48], [49, 53], [54, 55], [56, 62], [63, 65], [66, 77], [78, 90], [90, 91], [92, 97], [98, 103], [104, 111], [112, 115], [116, 120], [121, 128], [129, 131], [132, 135], [136, 144], [145, 147], [148, 155], [155, 156], [157, 160], [161, 168], [169, 173], [174, 182], [183, 188], [189, 197], [198, 201], [202, 207], [208, 210], [211, 212], [213, 224], [225, 229], [230, 232], [233, 235], [235, 236]]}
{"doc_key": "ai-dev-9", "ner": [[16, 17, "misc"], [30, 33, "field"], [34, 36, "product"], [53, 54, "misc"], [58, 59, "misc"], [62, 62, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[16, 17, 30, 33, "part-of", "", false, false], [16, 17, 58, 59, "named", "same", false, false], [34, 36, 53, 54, "related-to", "", false, false], [34, 36, 58, 59, "usage", "", false, false], [34, 36, 62, 62, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "representation", "of", "words", "with", "respect", "to", "their", "context", "using", "dense", "fixed", "-", "size", "vectors", "(", "word", "embeddings", ")", "has", "become", "one", "of", "the", "most", "fundamental", "building", "blocks", "in", "several", "NLP", "systems", ".", "An", "unsupervised", "recognition", "system", "uses", "the", "similarity", "between", "word", "meanings", "in", "a", "fixed", "context", "window", "to", "select", "the", "most", "appropriate", "word", "meaning", "using", "a", "pre-trained", "word", "embedding", "model", "and", "WordNet", "."], "sentence-detokenized": "The representation of words with respect to their context using dense fixed-size vectors (word embeddings) has become one of the most fundamental building blocks in several NLP systems. An unsupervised recognition system uses the similarity between word meanings in a fixed context window to select the most appropriate word meaning using a pre-trained word embedding model and WordNet.", "token2charspan": [[0, 3], [4, 18], [19, 21], [22, 27], [28, 32], [33, 40], [41, 43], [44, 49], [50, 57], [58, 63], [64, 69], [70, 75], [75, 76], [76, 80], [81, 88], [89, 90], [90, 94], [95, 105], [105, 106], [107, 110], [111, 117], [118, 121], [122, 124], [125, 128], [129, 133], [134, 145], [146, 154], [155, 161], [162, 164], [165, 172], [173, 176], [177, 184], [184, 185], [186, 188], [189, 201], [202, 213], [214, 220], [221, 225], [226, 229], [230, 240], [241, 248], [249, 253], [254, 262], [263, 265], [266, 267], [268, 273], [274, 281], [282, 288], [289, 291], [292, 298], [299, 302], [303, 307], [308, 319], [320, 324], [325, 332], [333, 338], [339, 340], [341, 352], [353, 357], [358, 367], [368, 373], [374, 377], [378, 385], [385, 386]]}
{"doc_key": "ai-dev-10", "ner": [[0, 1, "field"], [6, 6, "field"], [7, 9, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 0, 1, "part-of", "", false, false], [7, 9, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "techniques", ",", "both", "supervised", "and", "unsupervised", ",", "have", "been", "used", "to", "automatically", "create", "such", "rules", "."], "sentence-detokenized": "Machine learning techniques, both supervised and unsupervised, have been used to automatically create such rules.", "token2charspan": [[0, 7], [8, 16], [17, 27], [27, 28], [29, 33], [34, 44], [45, 48], [49, 61], [61, 62], [63, 67], [68, 72], [73, 77], [78, 80], [81, 94], [95, 101], [102, 106], [107, 112], [112, 113]]}
{"doc_key": "ai-dev-11", "ner": [[3, 3, "researcher"], [5, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1969", ",", "Shainman", "invented", "the", "Stanford", "manipulator", ","], "sentence-detokenized": "In 1969, Shainman invented the Stanford manipulator,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 17], [18, 26], [27, 30], [31, 39], [40, 51], [51, 52]]}
{"doc_key": "ai-dev-12", "ner": [[2, 3, "metrics"], [8, 9, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Since", "the", "Log", "loss", "is", "differentiable", ",", "the", "gradient", "method", "can", "be", "used", "to", "optimize", "the", "model", "."], "sentence-detokenized": "Since the Log loss is differentiable, the gradient method can be used to optimize the model.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 18], [19, 21], [22, 36], [36, 37], [38, 41], [42, 50], [51, 57], [58, 61], [62, 64], [65, 69], [70, 72], [73, 81], [82, 85], [86, 91], [91, 92]]}
{"doc_key": "ai-dev-13", "ner": [[1, 2, "field"], [4, 6, "algorithm"], [8, 8, "algorithm"], [11, 13, "algorithm"], [16, 17, "field"], [27, 27, "task"], [29, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 6, 16, 17, "part-of", "", false, false], [8, 8, 4, 6, "named", "", false, false], [11, 13, 4, 6, "named", "", false, false], [16, 17, 1, 2, "part-of", "subfield", false, false], [27, 27, 16, 17, "part-of", "", false, false], [29, 30, 16, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "machine", "learning", ",", "support", "vector", "machines", "(", "SVMs", ",", "also", "support", "vector", "networks", ")", "are", "supervised", "learning", "models", "with", "learning", "algorithms", "that", "analyze", "data", "used", "for", "classification", "and", "regression", "analysis", "."], "sentence-detokenized": "In machine learning, support vector machines (SVMs, also support vector networks) are supervised learning models with learning algorithms that analyze data used for classification and regression analysis.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 28], [29, 35], [36, 44], [45, 46], [46, 50], [50, 51], [52, 56], [57, 64], [65, 71], [72, 80], [80, 81], [82, 85], [86, 96], [97, 105], [106, 112], [113, 117], [118, 126], [127, 137], [138, 142], [143, 150], [151, 155], [156, 160], [161, 164], [165, 179], [180, 183], [184, 194], [195, 203], [203, 204]]}
{"doc_key": "ai-dev-14", "ner": [[9, 10, "task"], [12, 12, "task"], [29, 29, "metrics"], [31, 31, "metrics"], [33, 33, "researcher"], [35, 35, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 12, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "2002", ")", "as", "an", "automatic", "metric", "for", "evaluating", "machine", "translation", "(", "MT", ")", ",", "many", "other", "methods", "have", "been", "proposed", "to", "revise", "or", "improve", "it", ",", "such", "as", "TER", ",", "METEOR", ",", "Banerjee", "and", "Lavie", ",", "(", "2005", ")", ",", "etc", "."], "sentence-detokenized": "(2002) as an automatic metric for evaluating machine translation (MT), many other methods have been proposed to revise or improve it, such as TER, METEOR, Banerjee and Lavie, (2005), etc.", "token2charspan": [[0, 1], [1, 5], [5, 6], [7, 9], [10, 12], [13, 22], [23, 29], [30, 33], [34, 44], [45, 52], [53, 64], [65, 66], [66, 68], [68, 69], [69, 70], [71, 75], [76, 81], [82, 89], [90, 94], [95, 99], [100, 108], [109, 111], [112, 118], [119, 121], [122, 129], [130, 132], [132, 133], [134, 138], [139, 141], [142, 145], [145, 146], [147, 153], [153, 154], [155, 163], [164, 167], [168, 173], [173, 174], [175, 176], [176, 180], [180, 181], [181, 182], [183, 186], [186, 187]]}
{"doc_key": "ai-dev-15", "ner": [[3, 4, "misc"], [8, 8, "organisation"], [9, 9, "organisation"], [15, 16, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 9, 9, "origin", "", false, false], [9, 9, 8, 8, "part-of", "", false, false], [15, 16, 9, 9, "role", "", false, false], [18, 19, 9, 9, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "includes", "the", "top", "ontology", "created", "by", "the", "IEEE", "P1600.1", "working", "group", "(", "authors", "-", "Ian", "Niles", "and", "Adam", "Pease", ")", "."], "sentence-detokenized": "It includes the top ontology created by the IEEE P1600.1 working group (authors - Ian Niles and Adam Pease).", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 19], [20, 28], [29, 36], [37, 39], [40, 43], [44, 48], [49, 56], [57, 64], [65, 70], [71, 72], [72, 79], [80, 81], [82, 85], [86, 91], [92, 95], [96, 100], [101, 106], [106, 107], [107, 108]]}
{"doc_key": "ai-dev-16", "ner": [[1, 2, "misc"], [31, 33, "algorithm"], [35, 36, "algorithm"], [39, 42, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[31, 33, 1, 2, "part-of", "", true, false], [35, 36, 1, 2, "part-of", "", true, false], [39, 42, 35, 36, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "cryo-electron", "tomography", ",", "where", "a", "limited", "number", "of", "projections", "are", "obtained", "due", "to", "hardware", "limitations", "and", "to", "avoid", "damage", "to", "the", "biological", "sample", ",", "it", "can", "be", "used", "together", "with", "compression", "sensing", "techniques", "or", "regularization", "functions", "(", "e.g.", "Huber", "loss", ")", "to", "improve", "the", "reconstruction", "for", "better", "interpretation", "."], "sentence-detokenized": "In cryo-electron tomography, where a limited number of projections are obtained due to hardware limitations and to avoid damage to the biological sample, it can be used together with compression sensing techniques or regularization functions (e.g. Huber loss) to improve the reconstruction for better interpretation.", "token2charspan": [[0, 2], [3, 16], [17, 27], [27, 28], [29, 34], [35, 36], [37, 44], [45, 51], [52, 54], [55, 66], [67, 70], [71, 79], [80, 83], [84, 86], [87, 95], [96, 107], [108, 111], [112, 114], [115, 120], [121, 127], [128, 130], [131, 134], [135, 145], [146, 152], [152, 153], [154, 156], [157, 160], [161, 163], [164, 168], [169, 177], [178, 182], [183, 194], [195, 202], [203, 213], [214, 216], [217, 231], [232, 241], [242, 243], [243, 247], [248, 253], [254, 258], [258, 259], [260, 262], [263, 270], [271, 274], [275, 289], [290, 293], [294, 300], [301, 315], [315, 316]]}
{"doc_key": "ai-dev-17", "ner": [[6, 6, "programlang"], [9, 10, "algorithm"], [12, 13, "algorithm"], [18, 21, "algorithm"], [25, 27, "product"], [30, 30, "product"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6], "relations": [[25, 27, 6, 6, "general-affiliation", "", true, false], [25, 27, 6, 6, "part-of", "", true, false], [30, 30, 25, 27, "role", "publishes", false, false]], "relations_mapping_to_source": [4, 5, 6], "sentence": ["Implementations", "of", "several", "whitening", "procedures", "in", "R", ",", "including", "ZCA", "whitening", "and", "PCA", "whitening", ",", "as", "well", "as", "CCA", "whitening", ",", "are", "available", "in", "the", "R", "whitening", "package", "published", "on", "CRAN", "."], "sentence-detokenized": "Implementations of several whitening procedures in R, including ZCA whitening and PCA whitening, as well as CCA whitening, are available in the R whitening package published on CRAN.", "token2charspan": [[0, 15], [16, 18], [19, 26], [27, 36], [37, 47], [48, 50], [51, 52], [52, 53], [54, 63], [64, 67], [68, 77], [78, 81], [82, 85], [86, 95], [95, 96], [97, 99], [100, 104], [105, 107], [108, 111], [112, 121], [121, 122], [123, 126], [127, 136], [137, 139], [140, 143], [144, 145], [146, 155], [156, 163], [164, 173], [174, 176], [177, 181], [181, 182]]}
{"doc_key": "ai-dev-18", "ner": [[28, 28, "product"], [30, 30, "product"], [32, 32, "product"], [34, 34, "product"], [36, 36, "product"], [38, 38, "product"], [41, 42, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[28, 28, 32, 32, "compare", "", false, false], [28, 28, 34, 34, "compare", "", false, false], [28, 28, 36, 36, "compare", "", false, false], [28, 28, 38, 38, "compare", "", false, false], [28, 28, 41, 42, "compare", "", false, false], [30, 30, 32, 32, "compare", "", false, false], [30, 30, 34, 34, "compare", "", false, false], [30, 30, 36, 36, "compare", "", false, false], [30, 30, 38, 38, "compare", "", false, false], [30, 30, 41, 42, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Today", "this", "field", "has", "become", "even", "more", "complex", "and", "sophisticated", "with", "the", "addition", "of", "languages", "and", "software", "for", "analyzing", "and", "designing", "circuits", ",", "systems", "and", "signals", ",", "from", "MATLAB", "and", "Simulink", "to", "NumPy", ",", "VHDL", ",", "PSpice", ",", "Verilog", "and", "even", "Assembly", "language", "."], "sentence-detokenized": "Today this field has become even more complex and sophisticated with the addition of languages and software for analyzing and designing circuits, systems and signals, from MATLAB and Simulink to NumPy, VHDL, PSpice, Verilog and even Assembly language.", "token2charspan": [[0, 5], [6, 10], [11, 16], [17, 20], [21, 27], [28, 32], [33, 37], [38, 45], [46, 49], [50, 63], [64, 68], [69, 72], [73, 81], [82, 84], [85, 94], [95, 98], [99, 107], [108, 111], [112, 121], [122, 125], [126, 135], [136, 144], [144, 145], [146, 153], [154, 157], [158, 165], [165, 166], [167, 171], [172, 178], [179, 182], [183, 191], [192, 194], [195, 200], [200, 201], [202, 206], [206, 207], [208, 214], [214, 215], [216, 223], [224, 227], [228, 232], [233, 241], [242, 250], [250, 251]]}
{"doc_key": "ai-dev-19", "ner": [[5, 6, "person"], [13, 14, "person"], [15, 16, "organisation"], [19, 19, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 16, 13, 14, "origin", "", false, false], [19, 19, 15, 16, "artifact", "builds", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "company", "was", "founded", "by", "Kiichiro", "Toyoda", "in", "1937", "as", "an", "offshoot", "of", "Sakichi", "Toyoda", "Toyota", "Industries", "to", "create", "automobiles", "."], "sentence-detokenized": "The company was founded by Kiichiro Toyoda in 1937 as an offshoot of Sakichi Toyoda Toyota Industries to create automobiles.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 26], [27, 35], [36, 42], [43, 45], [46, 50], [51, 53], [54, 56], [57, 65], [66, 68], [69, 76], [77, 83], [84, 90], [91, 101], [102, 104], [105, 111], [112, 123], [123, 124]]}
{"doc_key": "ai-dev-20", "ner": [[0, 4, "field"], [55, 56, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[55, 56, 0, 4, "origin", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Unsupervised", "learning", ",", "on", "the", "other", "hand", ",", "takes", "training", "data", "that", "has", "not", "been", "manually", "labeled", "and", "attempts", "to", "find", "inherent", "patterns", "in", "the", "data", ",", "which", "can", "then", "be", "used", "to", "determine", "the", "correct", "output", "value", "for", "new", "data", "instances", ".", "A", "combination", "of", "these", "two", "methods", "that", "has", "recently", "been", "explored", "is", "semi-supervised", "learning", ",", "which", "uses", "a", "combination", "of", "labeled", "and", "unlabeled", "data", "(", "typically", "a", "small", "set", "of", "labeled", "data", "combined", "with", "a", "large", "amount", "of", "unlabeled", "data", ")", "."], "sentence-detokenized": "Unsupervised learning, on the other hand, takes training data that has not been manually labeled and attempts to find inherent patterns in the data, which can then be used to determine the correct output value for new data instances. A combination of these two methods that has recently been explored is semi-supervised learning, which uses a combination of labeled and unlabeled data (typically a small set of labeled data combined with a large amount of unlabeled data).", "token2charspan": [[0, 12], [13, 21], [21, 22], [23, 25], [26, 29], [30, 35], [36, 40], [40, 41], [42, 47], [48, 56], [57, 61], [62, 66], [67, 70], [71, 74], [75, 79], [80, 88], [89, 96], [97, 100], [101, 109], [110, 112], [113, 117], [118, 126], [127, 135], [136, 138], [139, 142], [143, 147], [147, 148], [149, 154], [155, 158], [159, 163], [164, 166], [167, 171], [172, 174], [175, 184], [185, 188], [189, 196], [197, 203], [204, 209], [210, 213], [214, 217], [218, 222], [223, 232], [232, 233], [234, 235], [236, 247], [248, 250], [251, 256], [257, 260], [261, 268], [269, 273], [274, 277], [278, 286], [287, 291], [292, 300], [301, 303], [304, 319], [320, 328], [328, 329], [330, 335], [336, 340], [341, 342], [343, 354], [355, 357], [358, 365], [366, 369], [370, 379], [380, 384], [385, 386], [386, 395], [396, 397], [398, 403], [404, 407], [408, 410], [411, 418], [419, 423], [424, 432], [433, 437], [438, 439], [440, 445], [446, 452], [453, 455], [456, 465], [466, 470], [470, 471], [471, 472]]}
{"doc_key": "ai-dev-21", "ner": [[23, 23, "organisation"], [21, 21, "product"], [27, 28, "organisation"], [25, 25, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 21, 23, 23, "artifact", "", false, false], [27, 28, 25, 25, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Despite", "the", "utilitarian", "purpose", "of", "these", "robots", ",", "there", "are", "also", "those", "that", "are", "designed", "for", "entertainment", "purposes", ",", "such", "as", "QRIO", "from", "Sony", "and", "RoboSapien", "from", "Wow", "Wee", "."], "sentence-detokenized": "Despite the utilitarian purpose of these robots, there are also those that are designed for entertainment purposes, such as QRIO from Sony and RoboSapien from Wow Wee.", "token2charspan": [[0, 7], [8, 11], [12, 23], [24, 31], [32, 34], [35, 40], [41, 47], [47, 48], [49, 54], [55, 58], [59, 63], [64, 69], [70, 74], [75, 78], [79, 87], [88, 91], [92, 105], [106, 114], [114, 115], [116, 120], [121, 123], [124, 128], [129, 133], [134, 138], [139, 142], [143, 153], [154, 158], [159, 162], [163, 166], [166, 167]]}
{"doc_key": "ai-dev-22", "ner": [[3, 3, "researcher"], [9, 15, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 9, 15, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1991", ",", "Webber", "became", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ","], "sentence-detokenized": "In 1991, Webber became a member of the Association for the Advancement of Artificial Intelligence,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 22], [23, 24], [25, 31], [32, 34], [35, 38], [39, 50], [51, 54], [55, 58], [59, 70], [71, 73], [74, 84], [85, 97], [97, 98]]}
{"doc_key": "ai-dev-23", "ner": [[7, 7, "field"], [10, 10, "field"], [22, 25, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 25, 7, 7, "part-of", "task_part_of_field", false, false], [22, 25, 10, 10, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["With", "this", "company", "he", "developed", "technologies", "for", "data", "mining", "and", "database", "analysis", ",", "more", "specifically", "high", "-", "level", "ontologies", "for", "intelligence", "and", "automated", "natural", "language", "understanding", "."], "sentence-detokenized": "With this company he developed technologies for data mining and database analysis, more specifically high-level ontologies for intelligence and automated natural language understanding.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 20], [21, 30], [31, 43], [44, 47], [48, 52], [53, 59], [60, 63], [64, 72], [73, 81], [81, 82], [83, 87], [88, 100], [101, 105], [105, 106], [106, 111], [112, 122], [123, 126], [127, 139], [140, 143], [144, 153], [154, 161], [162, 170], [171, 184], [184, 185]]}
{"doc_key": "ai-dev-24", "ner": [[25, 26, "misc"], [28, 31, "misc"], [33, 34, "misc"], [36, 36, "country"], [38, 40, "organisation"], [42, 42, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[25, 26, 36, 36, "physical", "", false, false], [28, 31, 36, 36, "physical", "", false, false], [33, 34, 36, 36, "physical", "", false, false], [38, 40, 42, 42, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["At", "the", "same", "time", ",", "in", "recent", "years", "we", "can", "observe", "the", "emergence", "of", "various", "e-services", "and", "related", "initiatives", "in", "developing", "countries", ",", "such", "as", "Project", "Nemmadi", ",", "MCA21", "Mission", "Mode", "Project", "or", "Digital", "India", "in", "India", ",", "Directorate", "of", "e-Government", "in", "Pakistan", ",", "etc", "."], "sentence-detokenized": "At the same time, in recent years we can observe the emergence of various e-services and related initiatives in developing countries, such as Project Nemmadi, MCA21 Mission Mode Project or Digital India in India, Directorate of e-Government in Pakistan, etc.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [16, 17], [18, 20], [21, 27], [28, 33], [34, 36], [37, 40], [41, 48], [49, 52], [53, 62], [63, 65], [66, 73], [74, 84], [85, 88], [89, 96], [97, 108], [109, 111], [112, 122], [123, 132], [132, 133], [134, 138], [139, 141], [142, 149], [150, 157], [157, 158], [159, 164], [165, 172], [173, 177], [178, 185], [186, 188], [189, 196], [197, 202], [203, 205], [206, 211], [211, 212], [213, 224], [225, 227], [228, 240], [241, 243], [244, 252], [252, 253], [254, 257], [257, 258]]}
{"doc_key": "ai-dev-25", "ner": [[15, 15, "misc"], [17, 17, "field"], [19, 21, "field"], [23, 25, "university"], [27, 29, "university"], [8, 12, "university"], [38, 39, "field"], [42, 44, "misc"], [45, 45, "university"], [47, 49, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10], "relations": [[15, 15, 17, 17, "topic", "", false, false], [15, 15, 19, 21, "topic", "", false, false], [15, 15, 23, 25, "origin", "", false, false], [23, 25, 27, 29, "part-of", "", false, false], [8, 12, 23, 25, "part-of", "", false, false], [42, 44, 45, 45, "origin", "", false, false], [45, 45, 47, 49, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 7, 8], "sentence": ["In", "1979", ",", "as", "a", "student", "of", "the", "Indian", "Statistical", "Institute", ",", "he", "received", "a", "PhD", "in", "Radiophysics", "and", "Electronics", "from", "the", "Rajabazar", "College", "of", "Science", ",", "University", "of", "Calcutta", ",", "and", "in", "1982", ",", "a", "PhD", "in", "Electrical", "Engineering", "and", "a", "diploma", "from", "Imperial", "College", ",", "University", "of", "London", "."], "sentence-detokenized": "In 1979, as a student of the Indian Statistical Institute, he received a PhD in Radiophysics and Electronics from the Rajabazar College of Science, University of Calcutta, and in 1982, a PhD in Electrical Engineering and a diploma from Imperial College, University of London.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 13], [14, 21], [22, 24], [25, 28], [29, 35], [36, 47], [48, 57], [57, 58], [59, 61], [62, 70], [71, 72], [73, 76], [77, 79], [80, 92], [93, 96], [97, 108], [109, 113], [114, 117], [118, 127], [128, 135], [136, 138], [139, 146], [146, 147], [148, 158], [159, 161], [162, 170], [170, 171], [172, 175], [176, 178], [179, 183], [183, 184], [185, 186], [187, 190], [191, 193], [194, 204], [205, 216], [217, 220], [221, 222], [223, 230], [231, 235], [236, 244], [245, 252], [252, 253], [254, 264], [265, 267], [268, 274], [274, 275]]}
{"doc_key": "ai-dev-26", "ner": [[0, 2, "location"], [23, 25, "misc"], [32, 33, "misc"], [36, 38, "person"], [40, 44, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[23, 25, 0, 2, "temporal", "", false, false], [32, 33, 0, 2, "temporal", "", false, false], [36, 38, 32, 33, "role", "actor_in", false, false], [40, 44, 32, 33, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Expo", "II", "was", "announced", "as", "the", "world", "premiere", "venue", "for", "several", "films", "that", "have", "never", "been", "shown", "in", "3D", "before", ",", "including", "\"", "The", "Diamond", "Master", "\"", "and", "the", "short", "film", "\"", "Hawaiian", "Nights", "\"", "starring", "Mamie", "Van", "Doren", "and", "Pinky", "Lee", ",", "produced", "by", "Universal", "."], "sentence-detokenized": "Expo II was announced as the world premiere venue for several films that have never been shown in 3D before, including \"The Diamond Master\" and the short film \"Hawaiian Nights\" starring Mamie Van Doren and Pinky Lee, produced by Universal.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 24], [25, 28], [29, 34], [35, 43], [44, 49], [50, 53], [54, 61], [62, 67], [68, 72], [73, 77], [78, 83], [84, 88], [89, 94], [95, 97], [98, 100], [101, 107], [107, 108], [109, 118], [119, 120], [120, 123], [124, 131], [132, 138], [138, 139], [140, 143], [144, 147], [148, 153], [154, 158], [159, 160], [160, 168], [169, 175], [175, 176], [177, 185], [186, 191], [192, 195], [196, 201], [202, 205], [206, 211], [212, 215], [215, 216], [217, 225], [226, 228], [229, 238], [238, 239]]}
{"doc_key": "ai-dev-27", "ner": [[7, 8, "researcher"], [16, 20, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 16, 20, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "maximum", "subarray", "problem", "was", "proposed", "by", "Ulf", "Grenander", "in", "1977", "as", "a", "simplified", "model", "for", "estimating", "the", "maximum", "likelihood", "of", "images", "in", "digitized", "images", "."], "sentence-detokenized": "The maximum subarray problem was proposed by Ulf Grenander in 1977 as a simplified model for estimating the maximum likelihood of images in digitized images.", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 28], [29, 32], [33, 41], [42, 44], [45, 48], [49, 58], [59, 61], [62, 66], [67, 69], [70, 71], [72, 82], [83, 88], [89, 92], [93, 103], [104, 107], [108, 115], [116, 126], [127, 129], [130, 136], [137, 139], [140, 149], [150, 156], [156, 157]]}
{"doc_key": "ai-dev-28", "ner": [[0, 1, "product"], [3, 4, "product"], [6, 8, "product"], [10, 11, "product"], [13, 15, "product"], [17, 20, "product"], [33, 33, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[33, 33, 0, 1, "part-of", "", false, false], [33, 33, 3, 4, "part-of", "", false, false], [33, 33, 6, 8, "part-of", "", false, false], [33, 33, 10, 11, "part-of", "", false, false], [33, 33, 13, 15, "part-of", "", false, false], [33, 33, 17, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["iPhone", "4S", ",", "iPad", "3", ",", "iPad", "Mini", "1G", ",", "iPad", "Air", ",", "iPad", "Pro", "1G", ",", "iPod", "Touch", "5", "G", "and", "later", "models", "are", "equipped", "with", "a", "more", "advanced", "voice", "assistant", "called", "Siri", "."], "sentence-detokenized": "iPhone 4S, iPad 3, iPad Mini 1G, iPad Air, iPad Pro 1G, iPod Touch 5G and later models are equipped with a more advanced voice assistant called Siri.", "token2charspan": [[0, 6], [7, 9], [9, 10], [11, 15], [16, 17], [17, 18], [19, 23], [24, 28], [29, 31], [31, 32], [33, 37], [38, 41], [41, 42], [43, 47], [48, 51], [52, 54], [54, 55], [56, 60], [61, 66], [67, 68], [68, 69], [70, 73], [74, 79], [80, 86], [87, 90], [91, 99], [100, 104], [105, 106], [107, 111], [112, 120], [121, 126], [127, 136], [137, 143], [144, 148], [148, 149]]}
{"doc_key": "ai-dev-29", "ner": [[6, 7, "metrics"], [9, 12, "metrics"], [14, 17, "metrics"], [45, 48, "metrics"], [53, 56, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 12, 45, 48, "named", "", false, false], [14, 17, 9, 12, "named", "", false, false], [45, 48, 53, 56, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["It", "is", "easy", "to", "check", "that", "logistic", "loss", "and", "binary", "cross", "entropy", "loss", "(", "Log", "loss", ")", "are", "actually", "the", "same", "(", "up", "to", "the", "multiplicative", "constant", "math", "\\", "frac", "{", "1", "}", "{", "\\", "log", "(", "2", ")", "}", "/", "math", ")", ".", "The", "cross", "entropy", "loss", "is", "closely", "related", "to", "the", "Kullback", "-", "Leibler", "discrepancy", "between", "the", "empirical", "distribution", "and", "the", "predicted", "distribution", "."], "sentence-detokenized": "It is easy to check that logistic loss and binary cross entropy loss (Log loss) are actually the same (up to the multiplicative constant math\\ frac {1} {\\ log (2)} / math). The cross entropy loss is closely related to the Kullback-Leibler discrepancy between the empirical distribution and the predicted distribution.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 13], [14, 19], [20, 24], [25, 33], [34, 38], [39, 42], [43, 49], [50, 55], [56, 63], [64, 68], [69, 70], [70, 73], [74, 78], [78, 79], [80, 83], [84, 92], [93, 96], [97, 101], [102, 103], [103, 105], [106, 108], [109, 112], [113, 127], [128, 136], [137, 141], [141, 142], [143, 147], [148, 149], [149, 150], [150, 151], [152, 153], [153, 154], [155, 158], [159, 160], [160, 161], [161, 162], [162, 163], [164, 165], [166, 170], [170, 171], [171, 172], [173, 176], [177, 182], [183, 190], [191, 195], [196, 198], [199, 206], [207, 214], [215, 217], [218, 221], [222, 230], [230, 231], [231, 238], [239, 250], [251, 258], [259, 262], [263, 272], [273, 285], [286, 289], [290, 293], [294, 303], [304, 316], [316, 317]]}
{"doc_key": "ai-dev-30", "ner": [[0, 2, "algorithm"], [10, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 11, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "EM", "algorithm", "is", "used", "to", "find", "(", "local", ")", "maximum", "likelihood", "parameters", "of", "a", "statistical", "model", "in", "cases", "where", "the", "equations", "can", "not", "be", "solved", "directly", "."], "sentence-detokenized": "The EM algorithm is used to find (local) maximum likelihood parameters of a statistical model in cases where the equations cannot be solved directly.", "token2charspan": [[0, 3], [4, 6], [7, 16], [17, 19], [20, 24], [25, 27], [28, 32], [33, 34], [34, 39], [39, 40], [41, 48], [49, 59], [60, 70], [71, 73], [74, 75], [76, 87], [88, 93], [94, 96], [97, 102], [103, 108], [109, 112], [113, 122], [123, 126], [126, 129], [130, 132], [133, 139], [140, 148], [148, 149]]}
{"doc_key": "ai-dev-31", "ner": [[12, 13, "task"], [15, 19, "task"], [25, 25, "task"], [24, 29, "task"], [33, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "studies", "have", "become", "fundamental", "for", "the", "development", "of", "modern", "methods", "of", "speech", "synthesis", ",", "reading", "machines", "for", "the", "blind", ",", "the", "study", "of", "speech", "perception", "and", "recognition", ",", "the", "development", "of", "the", "motor", "theory", "of", "speech", "perception", "."], "sentence-detokenized": "These studies have become fundamental for the development of modern methods of speech synthesis, reading machines for the blind, the study of speech perception and recognition, the development of the motor theory of speech perception.", "token2charspan": [[0, 5], [6, 13], [14, 18], [19, 25], [26, 37], [38, 41], [42, 45], [46, 57], [58, 60], [61, 67], [68, 75], [76, 78], [79, 85], [86, 95], [95, 96], [97, 104], [105, 113], [114, 117], [118, 121], [122, 127], [127, 128], [129, 132], [133, 138], [139, 141], [142, 148], [149, 159], [160, 163], [164, 175], [175, 176], [177, 180], [181, 192], [193, 195], [196, 199], [200, 205], [206, 212], [213, 215], [216, 222], [223, 233], [233, 234]]}
{"doc_key": "ai-dev-32", "ner": [[0, 1, "product"], [2, 4, "misc"], [6, 6, "misc"], [10, 12, "misc"], [15, 15, "product"], [17, 17, "product"], [19, 19, "product"], [26, 26, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[2, 4, 0, 1, "origin", "", false, false], [2, 4, 10, 12, "type-of", "", false, false], [2, 4, 15, 15, "related-to", "program_for", false, false], [2, 4, 17, 17, "related-to", "program_for", false, false], [2, 4, 19, 19, "related-to", "program_for", false, false], [2, 4, 26, 26, "related-to", "program_for", false, false], [6, 6, 2, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "Arduino", "Integrated", "Development", "Environment", "(", "IDE", ")", "is", "a", "cross", "-platform", "application", "(", "for", "Windows", ",", "macOS", "and", "Linux", ")", "that", "is", "written", "in", "the", "Java", "programming", "language", "."], "sentence-detokenized": "The Arduino Integrated Development Environment (IDE) is a cross-platform application (for Windows, macOS and Linux) that is written in the Java programming language.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 34], [35, 46], [47, 48], [48, 51], [51, 52], [53, 55], [56, 57], [58, 63], [63, 72], [73, 84], [85, 86], [86, 89], [90, 97], [97, 98], [99, 104], [105, 108], [109, 114], [114, 115], [116, 120], [121, 123], [124, 131], [132, 134], [135, 138], [139, 143], [144, 155], [156, 164], [164, 165]]}
{"doc_key": "ai-dev-33", "ner": [[0, 1, "algorithm"], [8, 9, "field"], [11, 13, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 8, 9, "opposite", "", false, false], [11, 13, 8, 9, "related-to", "works_with", false, false], [15, 16, 8, 9, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Neural", "network", "research", "stagnated", "after", "the", "publication", "of", "machine", "learning", "research", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", "."], "sentence-detokenized": "Neural network research stagnated after the publication of machine learning research by Marvin Minsky and Seymour Papert (1969).", "token2charspan": [[0, 6], [7, 14], [15, 23], [24, 33], [34, 39], [40, 43], [44, 55], [56, 58], [59, 66], [67, 75], [76, 84], [85, 87], [88, 94], [95, 101], [102, 105], [106, 113], [114, 120], [121, 122], [122, 126], [126, 127], [127, 128]]}
{"doc_key": "ai-dev-34", "ner": [[17, 18, "organisation"], [20, 20, "organisation"], [23, 25, "country"], [27, 30, "organisation"], [33, 33, "country"], [35, 36, "organisation"], [39, 39, "country"], [41, 41, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[27, 30, 23, 25, "general-affiliation", "", false, false], [35, 36, 33, 33, "general-affiliation", "", false, false], [41, 41, 39, 39, "general-affiliation", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Only", "a", "few", "non-Japanese", "companies", "eventually", "managed", "to", "survive", "in", "this", "market", ",", "the", "main", "ones", "being", "Adept", "Technology", ",", "St\u00e4ubli", ",", "the", "Swedish", "-", "Swiss", "company", "ABB", "Asea", "Brown", "Boveri", ",", "the", "German", "company", "KUKA", "Robotics", "and", "the", "Italian", "company", "Comau", "."], "sentence-detokenized": "Only a few non-Japanese companies eventually managed to survive in this market, the main ones being Adept Technology, St\u00e4ubli, the Swedish-Swiss company ABB Asea Brown Boveri, the German company KUKA Robotics and the Italian company Comau.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 23], [24, 33], [34, 44], [45, 52], [53, 55], [56, 63], [64, 66], [67, 71], [72, 78], [78, 79], [80, 83], [84, 88], [89, 93], [94, 99], [100, 105], [106, 116], [116, 117], [118, 125], [125, 126], [127, 130], [131, 138], [138, 139], [139, 144], [145, 152], [153, 156], [157, 161], [162, 167], [168, 174], [174, 175], [176, 179], [180, 186], [187, 194], [195, 199], [200, 208], [209, 212], [213, 216], [217, 224], [225, 232], [233, 238], [238, 239]]}
{"doc_key": "ai-dev-35", "ner": [[7, 8, "conference"], [15, 15, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 15, 7, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Research", "activities", "include", "the", "annual", "scientific", "conference", "RuleML", "Symposium", ",", "also", "known", "by", "the", "acronym", "RuleML", "."], "sentence-detokenized": "Research activities include the annual scientific conference RuleML Symposium, also known by the acronym RuleML.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 31], [32, 38], [39, 49], [50, 60], [61, 67], [68, 77], [77, 78], [79, 83], [84, 89], [90, 92], [93, 96], [97, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-dev-36", "ner": [[9, 9, "field"], [11, 12, "field"], [14, 14, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Concepts", "are", "used", "as", "formal", "tools", "or", "models", "in", "mathematics", ",", "computer", "science", ",", "databases", ",", "and", "artificial", "intelligence", ",", "where", "they", "are", "sometimes", "called", "classes", ",", "schemas", ",", "or", "categories", "."], "sentence-detokenized": "Concepts are used as formal tools or models in mathematics, computer science, databases, and artificial intelligence, where they are sometimes called classes, schemas, or categories.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 20], [21, 27], [28, 33], [34, 36], [37, 43], [44, 46], [47, 58], [58, 59], [60, 68], [69, 76], [76, 77], [78, 87], [87, 88], [89, 92], [93, 103], [104, 116], [116, 117], [118, 123], [124, 128], [129, 132], [133, 142], [143, 149], [150, 157], [157, 158], [159, 166], [166, 167], [168, 170], [171, 181], [181, 182]]}
{"doc_key": "ai-dev-37", "ner": [[4, 8, "organisation"], [11, 14, "organisation"], [17, 17, "organisation"], [18, 21, "organisation"], [25, 27, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "received", "awards", "from", "the", "American", "Psychological", "Association", ",", "the", "National", "Academy", "of", "Sciences", ",", "the", "Royal", "Society", "for", "Cognitive", "Neuroscience", ",", "and", "the", "American", "Humanist", "Association", "."], "sentence-detokenized": "He has received awards from the American Psychological Association, the National Academy of Sciences, the Royal Society for Cognitive Neuroscience, and the American Humanist Association.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 22], [23, 27], [28, 31], [32, 40], [41, 54], [55, 66], [66, 67], [68, 71], [72, 80], [81, 88], [89, 91], [92, 100], [100, 101], [102, 105], [106, 111], [112, 119], [120, 123], [124, 133], [134, 146], [146, 147], [148, 151], [152, 155], [156, 164], [165, 173], [174, 185], [185, 186]]}
{"doc_key": "ai-dev-38", "ner": [[0, 4, "person"], [6, 7, "person"], [9, 14, "person"], [17, 20, "person"], [22, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[22, 28, 17, 20, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "film", "starring", "Harrison", "Ford", ",", "Rutger", "Hauer", "and", "Sean", "Young", "is", "based", "on", "the", "novel", "by", "Philip", "K", ".", "Dick", "\"", "Do", "Androids", "Dream", "of", "Electric", "Sheep", "?", "\"", "(", "1968", ")", "."], "sentence-detokenized": "The film starring Harrison Ford, Rutger Hauer and Sean Young is based on the novel by Philip K. Dick \"Do Androids Dream of Electric Sheep?\" (1968).", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 26], [27, 31], [31, 32], [33, 39], [40, 45], [46, 49], [50, 54], [55, 60], [61, 63], [64, 69], [70, 72], [73, 76], [77, 82], [83, 85], [86, 92], [93, 94], [94, 95], [96, 100], [101, 102], [102, 104], [105, 113], [114, 119], [120, 122], [123, 131], [132, 137], [137, 138], [138, 139], [140, 141], [141, 145], [145, 146], [146, 147]]}
{"doc_key": "ai-dev-39", "ner": [[0, 1, "task"], [3, 6, "algorithm"], [11, 12, "field"], [14, 15, "task"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 3, 6, "usage", "", false, false], [0, 1, 11, 12, "part-of", "task_part_of_field", false, false], [0, 1, 14, 15, "part-of", "task_part_of_field", false, false], [0, 1, 17, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Image", "segmentation", "using", "k-means", "clustering", "algorithms", "has", "long", "been", "used", "for", "pattern", "recognition", ",", "object", "detection", "and", "medical", "imaging", "."], "sentence-detokenized": "Image segmentation using k-means clustering algorithms has long been used for pattern recognition, object detection and medical imaging.", "token2charspan": [[0, 5], [6, 18], [19, 24], [25, 32], [33, 43], [44, 54], [55, 58], [59, 63], [64, 68], [69, 73], [74, 77], [78, 85], [86, 97], [97, 98], [99, 105], [106, 115], [116, 119], [120, 127], [128, 135], [135, 136]]}
{"doc_key": "ai-dev-40", "ner": [[12, 12, "algorithm"], [15, 16, "algorithm"], [19, 19, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["General", "truncated", "normal", "sampling", "can", "be", "achieved", "using", "approximations", "to", "the", "normal", "CDF", "and", "the", "probit", "function", ",", "and", "R", "has", "the", "codertnorm", "(", ")", "/", "code", "function", "to", "generate", "truncated", "normal", "samples", "."], "sentence-detokenized": "General truncated normal sampling can be achieved using approximations to the normal CDF and the probit function, and R has the codertnorm() / code function to generate truncated normal samples.", "token2charspan": [[0, 7], [8, 17], [18, 24], [25, 33], [34, 37], [38, 40], [41, 49], [50, 55], [56, 70], [71, 73], [74, 77], [78, 84], [85, 88], [89, 92], [93, 96], [97, 103], [104, 112], [112, 113], [114, 117], [118, 119], [120, 123], [124, 127], [128, 138], [138, 139], [139, 140], [141, 142], [143, 147], [148, 156], [157, 159], [160, 168], [169, 178], [179, 185], [186, 193], [193, 194]]}
{"doc_key": "ai-dev-41", "ner": [[7, 9, "university"], [11, 11, "university"], [13, 15, "university"], [17, 19, "university"], [21, 22, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "also", "received", "honorary", "doctorates", "from", "the", "Universities", "of", "Newcastle", ",", "Surrey", ",", "Tel", "Aviv", "University", ",", "Simon", "Fraser", "University", "and", "Troms\u00f8", "University", "."], "sentence-detokenized": "He also received honorary doctorates from the Universities of Newcastle, Surrey, Tel Aviv University, Simon Fraser University and Troms\u00f8 University.", "token2charspan": [[0, 2], [3, 7], [8, 16], [17, 25], [26, 36], [37, 41], [42, 45], [46, 58], [59, 61], [62, 71], [71, 72], [73, 79], [79, 80], [81, 84], [85, 89], [90, 100], [100, 101], [102, 107], [108, 114], [115, 125], [126, 129], [130, 136], [137, 147], [147, 148]]}
{"doc_key": "ai-dev-42", "ner": [[2, 2, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Implementation", "in", "Java", "using", "zero", "array", "indexes", "and", "a", "convenient", "method", "of", "outputting", "the", "solved", "order", "of", "operations", ":"], "sentence-detokenized": "Implementation in Java using zero array indexes and a convenient method of outputting the solved order of operations:", "token2charspan": [[0, 14], [15, 17], [18, 22], [23, 28], [29, 33], [34, 39], [40, 47], [48, 51], [52, 53], [54, 64], [65, 71], [72, 74], [75, 85], [86, 89], [90, 96], [97, 102], [103, 105], [106, 116], [116, 117]]}
{"doc_key": "ai-dev-43", "ner": [[7, 8, "metrics"], [11, 12, "metrics"], [14, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 7, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Such", "networks", "are", "usually", "trained", "in", "the", "cross", "-entropy", "(", "or", "cross", "-entropy", ")", "regime", ",", "which", "gives", "a", "nonlinear", "version", "of", "multinomial", "logistic", "regression", "."], "sentence-detokenized": "Such networks are usually trained in the cross-entropy (or cross-entropy) regime, which gives a nonlinear version of multinomial logistic regression.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 25], [26, 33], [34, 36], [37, 40], [41, 46], [46, 54], [55, 56], [56, 58], [59, 64], [64, 72], [72, 73], [74, 80], [80, 81], [82, 87], [88, 93], [94, 95], [96, 105], [106, 113], [114, 116], [117, 128], [129, 137], [138, 148], [148, 149]]}
{"doc_key": "ai-dev-44", "ner": [[0, 0, "conference"], [2, 3, "misc"], [4, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 3, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["ACL", "has", "a", "European", "branch", "(", "European", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ")"], "sentence-detokenized": "ACL has a European branch (European Chapter of the Association for Computational Linguistics)", "token2charspan": [[0, 3], [4, 7], [8, 9], [10, 18], [19, 25], [26, 27], [27, 35], [36, 43], [44, 46], [47, 50], [51, 62], [63, 66], [67, 80], [81, 92], [92, 93]]}
{"doc_key": "ai-dev-45", "ner": [[3, 4, "researcher"], [6, 8, "researcher"], [27, 27, "misc"], [31, 32, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 27, 27, "role", "", false, false], [6, 8, 27, 27, "role", "", false, false], [27, 27, 31, 32, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "professors", ",", "Hal", "Abelson", "and", "Gerald", "J.", "Sussman", ",", "decided", "to", "remain", "neutral", "-", "their", "group", "was", "called", "differently", "over", "the", "next", "30", "years", ":", "\"", "Switzerland", "\"", "and", "\"", "Project", "MAC", "\"", "."], "sentence-detokenized": "Two professors, Hal Abelson and Gerald J. Sussman, decided to remain neutral - their group was called differently over the next 30 years: \"Switzerland\" and \"Project MAC\".", "token2charspan": [[0, 3], [4, 14], [14, 15], [16, 19], [20, 27], [28, 31], [32, 38], [39, 41], [42, 49], [49, 50], [51, 58], [59, 61], [62, 68], [69, 76], [77, 78], [79, 84], [85, 90], [91, 94], [95, 101], [102, 113], [114, 118], [119, 122], [123, 127], [128, 130], [131, 136], [136, 137], [138, 139], [139, 150], [150, 151], [152, 155], [156, 157], [157, 164], [165, 168], [168, 169], [169, 170]]}
{"doc_key": "ai-dev-46", "ner": [[3, 3, "misc"], [5, 5, "researcher"], [9, 12, "university"], [19, 20, "organisation"], [23, 25, "organisation"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 3, 5, 5, "temporal", "", false, false], [5, 5, 19, 20, "physical", "", false, false], [5, 5, 19, 20, "role", "", false, false], [5, 5, 23, 25, "role", "", false, false], [23, 25, 9, 12, "part-of", "", false, false], [29, 30, 23, 25, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["After", "receiving", "his", "PhD", ",", "Ghahramani", "moved", "to", "the", "University", "of", "Toronto", "in", "1995", "as", "a", "postdoctoral", "researcher", "at", "the", "MTRC", "in", "the", "Artificial", "Intelligence", "Laboratory", ",", "working", "with", "Jeffrey", "Hinton", "."], "sentence-detokenized": "After receiving his PhD, Ghahramani moved to the University of Toronto in 1995 as a postdoctoral researcher at the MTRC in the Artificial Intelligence Laboratory, working with Jeffrey Hinton.", "token2charspan": [[0, 5], [6, 15], [16, 19], [20, 23], [23, 24], [25, 35], [36, 41], [42, 44], [45, 48], [49, 59], [60, 62], [63, 70], [71, 73], [74, 78], [79, 81], [82, 83], [84, 96], [97, 107], [108, 110], [111, 114], [115, 119], [120, 122], [123, 126], [127, 137], [138, 150], [151, 161], [161, 162], [163, 170], [171, 175], [176, 183], [184, 190], [190, 191]]}
{"doc_key": "ai-dev-47", "ner": [[28, 29, "metrics"], [31, 31, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[31, 31, 28, 29, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Further", "work", "was", "focused", "on", "solving", "these", "problems", ",", "but", "only", "with", "the", "advent", "of", "modern", "computers", "and", "the", "popularization", "of", "methods", "of", "parameterization", "by", "the", "method", "of", "maximum", "likelihood", "(", "ML", ")", ",", "the", "research", "gained", "a", "real", "scale", "."], "sentence-detokenized": "Further work was focused on solving these problems, but only with the advent of modern computers and the popularization of methods of parameterization by the method of maximum likelihood (ML), the research gained a real scale.", "token2charspan": [[0, 7], [8, 12], [13, 16], [17, 24], [25, 27], [28, 35], [36, 41], [42, 50], [50, 51], [52, 55], [56, 60], [61, 65], [66, 69], [70, 76], [77, 79], [80, 86], [87, 96], [97, 100], [101, 104], [105, 119], [120, 122], [123, 130], [131, 133], [134, 150], [151, 153], [154, 157], [158, 164], [165, 167], [168, 175], [176, 186], [187, 188], [188, 190], [190, 191], [191, 192], [193, 196], [197, 205], [206, 212], [213, 214], [215, 219], [220, 225], [225, 226]]}
{"doc_key": "ai-dev-48", "ner": [[5, 6, "person"], [9, 10, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "series", "was", "produced", "by", "David", "Fincher", "and", "starred", "Kevin", "Spacey", "."], "sentence-detokenized": "The series was produced by David Fincher and starred Kevin Spacey.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 26], [27, 32], [33, 40], [41, 44], [45, 52], [53, 58], [59, 65], [65, 66]]}
{"doc_key": "ai-dev-49", "ner": [[17, 17, "metrics"], [24, 25, "algorithm"], [31, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[24, 25, 31, 33, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Due", "to", "computational", "power", "limitations", ",", "current", "in", "silico", "methods", "are", "usually", "forced", "to", "sacrifice", "speed", "for", "accuracy", ";", "for", "example", ",", "using", "fast", "protein", "docking", "methods", "instead", "of", "computationally", "expensive", "free", "energy", "calculations", "."], "sentence-detokenized": "Due to computational power limitations, current in silico methods are usually forced to sacrifice speed for accuracy; for example, using fast protein docking methods instead of computationally expensive free energy calculations.", "token2charspan": [[0, 3], [4, 6], [7, 20], [21, 26], [27, 38], [38, 39], [40, 47], [48, 50], [51, 57], [58, 65], [66, 69], [70, 77], [78, 84], [85, 87], [88, 97], [98, 103], [104, 107], [108, 116], [116, 117], [118, 121], [122, 129], [129, 130], [131, 136], [137, 141], [142, 149], [150, 157], [158, 165], [166, 173], [174, 176], [177, 192], [193, 202], [203, 207], [208, 214], [215, 227], [227, 228]]}
{"doc_key": "ai-dev-50", "ner": [[4, 7, "country"], [9, 9, "country"], [11, 11, "country"], [13, 13, "country"], [15, 15, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "had", "over", "30", "branches", "in", "the", "USA", ",", "Canada", ",", "Mexico", ",", "Brazil", "and", "Argentina", "."], "sentence-detokenized": "It had over 30 branches in the USA, Canada, Mexico, Brazil and Argentina.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 23], [24, 26], [27, 30], [31, 34], [34, 35], [36, 42], [42, 43], [44, 50], [50, 51], [52, 58], [59, 62], [63, 72], [72, 73]]}
{"doc_key": "ai-dev-51", "ner": [[5, 6, "field"], [11, 13, "product"], [15, 17, "algorithm"], [23, 23, "task"], [26, 27, "task"], [32, 32, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 13, 5, 6, "part-of", "", false, false], [11, 13, 15, 17, "usage", "", false, false], [23, 23, 5, 6, "part-of", "task_part_of_field", false, false], [23, 23, 32, 32, "related-to", "performs", false, false], [26, 27, 5, 6, "part-of", "task_part_of_field", false, false], [26, 27, 32, 32, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["An", "example", "of", "a", "typical", "computer", "vision", "computation", "pipeline", "for", "a", "face", "recognition", "system", "using", "k", "-", "NN", ",", "including", "preprocessing", "steps", "for", "feature", "extraction", "and", "dimensionality", "reduction", "(", "usually", "implemented", "with", "OpenCV", ")", ":"], "sentence-detokenized": "An example of a typical computer vision computation pipeline for a face recognition system using k -NN, including preprocessing steps for feature extraction and dimensionality reduction (usually implemented with OpenCV):", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 23], [24, 32], [33, 39], [40, 51], [52, 60], [61, 64], [65, 66], [67, 71], [72, 83], [84, 90], [91, 96], [97, 98], [99, 100], [100, 102], [102, 103], [104, 113], [114, 127], [128, 133], [134, 137], [138, 145], [146, 156], [157, 160], [161, 175], [176, 185], [186, 187], [187, 194], [195, 206], [207, 211], [212, 218], [218, 219], [219, 220]]}
{"doc_key": "ai-dev-52", "ner": [[10, 15, "algorithm"], [17, 17, "misc"], [20, 20, "misc"], [27, 27, "programlang"], [29, 29, "product"], [33, 34, "algorithm"], [36, 37, "misc"], [39, 39, "misc"], [41, 41, "misc"], [43, 43, "misc"], [49, 49, "misc"], [52, 52, "misc"], [54, 55, "misc"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "has", "a", "rich", "set", "of", "features", ",", "libraries", "for", "programming", "on", "the", "logic", "of", "constraints", ",", "multithreading", ",", "unit", "testing", ",", "graphical", "interface", ",", "interface", "to", "Java", ",", "ODBC", "and", "others", ",", "competent", "programming", ",", "web", "server", ",", "SGML", ",", "RDF", ",", "RDFS", ",", "developer", "tools", "(", "including", "IDE", "with", "graphical", "debugger", "and", "GUI", "profiler", ")", ",", "extensive", "documentation", "."], "sentence-detokenized": "It has a rich set of features, libraries for programming on the logic of constraints, multithreading, unit testing, graphical interface, interface to Java, ODBC and others, competent programming, web server, SGML, RDF, RDFS, developer tools (including IDE with graphical debugger and GUI profiler), extensive documentation.", "token2charspan": [[0, 2], [3, 6], [7, 8], [9, 13], [14, 17], [18, 20], [21, 29], [29, 30], [31, 40], [41, 44], [45, 56], [57, 59], [60, 63], [64, 69], [70, 72], [73, 84], [84, 85], [86, 100], [100, 101], [102, 106], [107, 114], [114, 115], [116, 125], [126, 135], [135, 136], [137, 146], [147, 149], [150, 154], [154, 155], [156, 160], [161, 164], [165, 171], [171, 172], [173, 182], [183, 194], [194, 195], [196, 199], [200, 206], [206, 207], [208, 212], [212, 213], [214, 217], [217, 218], [219, 223], [223, 224], [225, 234], [235, 240], [241, 242], [242, 251], [252, 255], [256, 260], [261, 270], [271, 279], [280, 283], [284, 287], [288, 296], [296, 297], [297, 298], [299, 308], [309, 322], [322, 323]]}
{"doc_key": "ai-dev-53", "ner": [[1, 2, "field"], [4, 7, "field"], [10, 12, "misc"], [14, 16, "misc"], [19, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 12, 1, 2, "part-of", "", true, false], [10, 12, 4, 7, "part-of", "", false, false], [10, 12, 19, 21, "type-of", "", false, false], [14, 16, 1, 2, "part-of", "", false, false], [14, 16, 4, 7, "part-of", "", false, false], [14, 16, 19, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "computer", "vision", "and", "image", "processing", ",", "the", "concept", "of", "scale", "space", "representation", "and", "Gaussian", "derivative", "operators", "is", "a", "canonical", "multiscale", "representation", "."], "sentence-detokenized": "In computer vision and image processing, the concept of scale space representation and Gaussian derivative operators is a canonical multiscale representation.", "token2charspan": [[0, 2], [3, 11], [12, 18], [19, 22], [23, 28], [29, 39], [39, 40], [41, 44], [45, 52], [53, 55], [56, 61], [62, 67], [68, 82], [83, 86], [87, 95], [96, 106], [107, 116], [117, 119], [120, 121], [122, 131], [132, 142], [143, 157], [157, 158]]}
{"doc_key": "ai-dev-54", "ner": [[6, 12, "organisation"], [19, 22, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 12, 19, 22, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "also", "President", "of", "the", "Neural", "Information", "Processing", "Systems", "Foundation", ",", "a", "non-profit", "organization", "that", "oversees", "the", "annual", "Neural", "Information", "Processing", "Systems", "Conference", "."], "sentence-detokenized": "He is also President of the Neural Information Processing Systems Foundation, a non-profit organization that oversees the annual Neural Information Processing Systems Conference.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 20], [21, 23], [24, 27], [28, 34], [35, 46], [47, 57], [58, 65], [66, 76], [76, 77], [78, 79], [80, 90], [91, 103], [104, 108], [109, 117], [118, 121], [122, 128], [129, 135], [136, 147], [148, 158], [159, 166], [167, 177], [177, 178]]}
{"doc_key": "ai-dev-55", "ner": [[1, 2, "task"], [6, 7, "metrics"], [8, 14, "misc"], [17, 17, "task"], [19, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 6, 7, "usage", "", false, false], [6, 7, 8, 14, "type-of", "", false, false], [17, 17, 19, 20, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["For", "regression", "analysis", "problems", ",", "the", "squared", "error", "can", "be", "used", "as", "a", "loss", "function", ",", "for", "classification", "-", "cross", "entropy", "."], "sentence-detokenized": "For regression analysis problems, the squared error can be used as a loss function, for classification - cross entropy.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 32], [32, 33], [34, 37], [38, 45], [46, 51], [52, 55], [56, 58], [59, 63], [64, 66], [67, 68], [69, 73], [74, 82], [82, 83], [84, 87], [88, 102], [103, 104], [105, 110], [111, 118], [118, 119]]}
{"doc_key": "ai-dev-56", "ner": [[0, 2, "researcher"], [20, 25, "conference"], [31, 32, "university"], [34, 36, "field"], [45, 49, "conference"]], "ner_mapping_to_source": [0, 2, 3, 4, 5], "relations": [[0, 2, 31, 32, "physical", "", false, false], [0, 2, 31, 32, "role", "", false, false], [0, 2, 45, 49, "role", "", false, false], [31, 32, 34, 36, "related-to", "subject_of_study_at", false, false]], "relations_mapping_to_source": [1, 2, 3, 5], "sentence": ["Lafferty", "has", "held", "many", "prestigious", "positions", ",", "including", ":", "1", ")", "Program", "Co-", "Chair", "and", "General", "Co-", "Chair", "of", "the", "Conference", "on", "Neural", "Information", "Processing", "Systems", ";", "2", ")", "Co-Director", "of", "CMU", "'s", "new", "Machine", "Learning", "Ph.D.", "program", ";", "3", ")", "Associate", "Editor", "of", "the", "Journal", "of", "Machine", "Learning", "Research"], "sentence-detokenized": "Lafferty has held many prestigious positions, including: 1) Program Co-Chair and General Co-Chair of the Conference on Neural Information Processing Systems; 2) Co-Director of CMU's new Machine Learning Ph.D. program; 3) Associate Editor of the Journal of Machine Learning Research", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 22], [23, 34], [35, 44], [44, 45], [46, 55], [55, 56], [57, 58], [58, 59], [60, 67], [68, 71], [71, 76], [77, 80], [81, 88], [89, 92], [92, 97], [98, 100], [101, 104], [105, 115], [116, 118], [119, 125], [126, 137], [138, 148], [149, 156], [156, 157], [158, 159], [159, 160], [161, 172], [173, 175], [176, 179], [179, 181], [182, 185], [186, 193], [194, 202], [203, 208], [209, 216], [216, 217], [218, 219], [219, 220], [221, 230], [231, 237], [238, 240], [241, 244], [245, 252], [253, 255], [256, 263], [264, 272], [273, 281]]}
{"doc_key": "ai-dev-57", "ner": [[0, 1, "misc"], [4, 4, "algorithm"], [6, 6, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 0, 1, "type-of", "", false, false], [6, 6, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Convex", "algorithms", "such", "as", "AdaBoost", "and", "LogitBoost", "can", "be", "defeated", "by", "random", "noise", ",", "so", "that", "they", "can", "not", "learn", "the", "basic", "combinations", "of", "weak", "hypotheses", "that", "can", "be", "learned", "."], "sentence-detokenized": "Convex algorithms such as AdaBoost and LogitBoost can be defeated by random noise, so that they cannot learn the basic combinations of weak hypotheses that can be learned.", "token2charspan": [[0, 6], [7, 17], [18, 22], [23, 25], [26, 34], [35, 38], [39, 49], [50, 53], [54, 56], [57, 65], [66, 68], [69, 75], [76, 81], [81, 82], [83, 85], [86, 90], [91, 95], [96, 99], [99, 102], [103, 108], [109, 112], [113, 118], [119, 131], [132, 134], [135, 139], [140, 150], [151, 155], [156, 159], [160, 162], [163, 170], [170, 171]]}
{"doc_key": "ai-dev-58", "ner": [[0, 0, "product"], [3, 7, "product"], [10, 12, "algorithm"], [22, 23, "algorithm"], [26, 31, "task"], [33, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 3, 7, "type-of", "", false, false], [0, 0, 10, 12, "usage", "", false, false], [0, 0, 22, 23, "usage", "", false, false], [22, 23, 26, 31, "related-to", "used_for", true, false], [22, 23, 33, 35, "related-to", "used_for", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Apertium", "is", "a", "shallow", "translation", "machine", "translation", "system", "that", "uses", "finite", "state", "transducers", "for", "all", "its", "lexical", "transformations", ",", "as", "well", "as", "hidden", "Markov", "models", "for", "part", "-", "of", "-", "speech", "tagging", "or", "word", "category", "recognition", "."], "sentence-detokenized": "Apertium is a shallow translation machine translation system that uses finite state transducers for all its lexical transformations, as well as hidden Markov models for part-of-speech tagging or word category recognition.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 21], [22, 33], [34, 41], [42, 53], [54, 60], [61, 65], [66, 70], [71, 77], [78, 83], [84, 95], [96, 99], [100, 103], [104, 107], [108, 115], [116, 131], [131, 132], [133, 135], [136, 140], [141, 143], [144, 150], [151, 157], [158, 164], [165, 168], [169, 173], [173, 174], [174, 176], [176, 177], [177, 183], [184, 191], [192, 194], [195, 199], [200, 208], [209, 220], [220, 221]]}
{"doc_key": "ai-dev-59", "ner": [[0, 2, "misc"], [13, 17, "metrics"], [33, 34, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 13, 17, "related-to", "", true, false], [13, 17, 33, 34, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "natural", "gradient", "mathE", "f", "(", "x", ")", "/", "math", ",", "which", "corresponds", "to", "the", "Fisher", "information", "metric", "(", "a", "measure", "of", "the", "information", "distance", "between", "probability", "distributions", "and", "the", "curvature", "of", "the", "relative", "entropy", ")", ",", "now", "has", "the", "form"], "sentence-detokenized": "The natural gradient mathE f (x) / math, which corresponds to the Fisher information metric (a measure of the information distance between probability distributions and the curvature of the relative entropy), now has the form", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 26], [27, 28], [29, 30], [30, 31], [31, 32], [33, 34], [35, 39], [39, 40], [41, 46], [47, 58], [59, 61], [62, 65], [66, 72], [73, 84], [85, 91], [92, 93], [93, 94], [95, 102], [103, 105], [106, 109], [110, 121], [122, 130], [131, 138], [139, 150], [151, 164], [165, 168], [169, 172], [173, 182], [183, 185], [186, 189], [190, 198], [199, 206], [206, 207], [207, 208], [209, 212], [213, 216], [217, 220], [221, 225]]}
{"doc_key": "ai-dev-60", "ner": [[0, 3, "programlang"], [9, 12, "product"], [14, 14, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 12, 0, 3, "origin", "", false, false], [14, 14, 0, 3, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "S", "programming", "language", "inspired", "the", "creation", "of", "the", "S", "\"", "-", "PLUS", "and", "R", "systems", "."], "sentence-detokenized": "The S programming language inspired the creation of the S\"-PLUS and R systems.", "token2charspan": [[0, 3], [4, 5], [6, 17], [18, 26], [27, 35], [36, 39], [40, 48], [49, 51], [52, 55], [56, 57], [57, 58], [58, 59], [59, 63], [64, 67], [68, 69], [70, 77], [77, 78]]}
{"doc_key": "ai-dev-61", "ner": [[5, 5, "product"], [10, 10, "product"], [12, 14, "product"], [18, 20, "researcher"], [22, 23, "researcher"], [26, 27, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 5, 10, 10, "named", "same", false, false], [12, 14, 10, 10, "origin", "derived_from", false, false], [12, 14, 18, 20, "origin", "", false, false], [12, 14, 22, 23, "origin", "", false, false], [12, 14, 26, 27, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "most", "influential", "implementation", "of", "Planner", "was", "a", "subset", "of", "Planner", "called", "Micro", "-", "Planner", ",", "implemented", "by", "Gerald", "J.", "Sussman", ",", "Eugene", "Czarniak", ",", "and", "Terry", "Winograd", "."], "sentence-detokenized": "The most influential implementation of Planner was a subset of Planner called Micro-Planner, implemented by Gerald J. Sussman, Eugene Czarniak, and Terry Winograd.", "token2charspan": [[0, 3], [4, 8], [9, 20], [21, 35], [36, 38], [39, 46], [47, 50], [51, 52], [53, 59], [60, 62], [63, 70], [71, 77], [78, 83], [83, 84], [84, 91], [91, 92], [93, 104], [105, 107], [108, 114], [115, 117], [118, 125], [125, 126], [127, 133], [134, 142], [142, 143], [144, 147], [148, 153], [154, 162], [162, 163]]}
{"doc_key": "ai-dev-62", "ner": [[4, 6, "country"], [8, 10, "researcher"], [19, 21, "misc"], [22, 27, "university"], [34, 35, "misc"], [41, 42, "misc"], [49, 51, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "relations": [[8, 10, 4, 6, "general-affiliation", "from_country", false, false], [22, 27, 19, 21, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["In", "1779", ",", "the", "German", "-", "Danish", "scientist", "Christian", "Gottlieb", "Kratzenstein", "received", "the", "first", "prize", "at", "the", "competition", "announced", "by", "the", "Russian", "Imperial", "Academy", "of", "Sciences", "and", "Arts", "for", "his", "model", "of", "the", "human", "vocal", "tract", "capable", "of", "reproducing", "five", "long", "vowel", "sounds", "(", "in", "the", "designation", "of", "the", "International", "Phonetic", "Alphabet", ")", ":"], "sentence-detokenized": "In 1779, the German-Danish scientist Christian Gottlieb Kratzenstein received the first prize at the competition announced by the Russian Imperial Academy of Sciences and Arts for his model of the human vocal tract capable of reproducing five long vowel sounds (in the designation of the International Phonetic Alphabet):", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 19], [19, 20], [20, 26], [27, 36], [37, 46], [47, 55], [56, 68], [69, 77], [78, 81], [82, 87], [88, 93], [94, 96], [97, 100], [101, 112], [113, 122], [123, 125], [126, 129], [130, 137], [138, 146], [147, 154], [155, 157], [158, 166], [167, 170], [171, 175], [176, 179], [180, 183], [184, 189], [190, 192], [193, 196], [197, 202], [203, 208], [209, 214], [215, 222], [223, 225], [226, 237], [238, 242], [243, 247], [248, 253], [254, 260], [261, 262], [262, 264], [265, 268], [269, 280], [281, 283], [284, 287], [288, 301], [302, 310], [311, 319], [319, 320], [320, 321]]}
{"doc_key": "ai-dev-63", "ner": [[5, 7, "product"], [8, 9, "misc"], [12, 16, "misc"], [35, 36, "misc"], [59, 60, "task"], [65, 68, "product"], [67, 67, "product"], [72, 72, "task"], [74, 75, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 7, 65, 68, "related-to", "supports_program", false, false], [5, 7, 67, 67, "related-to", "supports_program", false, false], [8, 9, 5, 7, "part-of", "", false, false], [12, 16, 5, 7, "part-of", "", false, false], [35, 36, 5, 7, "part-of", "", false, false], [59, 60, 5, 7, "part-of", "", false, false], [72, 72, 5, 7, "part-of", "", false, false], [74, 75, 5, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Among", "the", "new", "features", "of", "Office", "XP", "are", "smart", "tags", ",", "a", "selection", "-", "based", "search", "function", "that", "recognizes", "different", "types", "of", "text", "in", "a", "document", "so", "that", "users", "can", "perform", "additional", "actions", ";", "a", "taskbar", "interface", "that", "brings", "together", "popular", "menu", "bar", "commands", "on", "the", "right", "side", "of", "the", "screen", "to", "facilitate", "quick", "access", "to", "them", ";", "new", "document", "collaboration", "features", ",", "support", "for", "MSN", "and", "SharePoint", "groups", ";", "and", "integrated", "handwriting", "and", "speech", "recognition", "capabilities", "."], "sentence-detokenized": "Among the new features of Office XP are smart tags, a selection-based search function that recognizes different types of text in a document so that users can perform additional actions; a taskbar interface that brings together popular menu bar commands on the right side of the screen to facilitate quick access to them; new document collaboration features, support for MSN and SharePoint groups; and integrated handwriting and speech recognition capabilities.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 22], [23, 25], [26, 32], [33, 35], [36, 39], [40, 45], [46, 50], [50, 51], [52, 53], [54, 63], [63, 64], [64, 69], [70, 76], [77, 85], [86, 90], [91, 101], [102, 111], [112, 117], [118, 120], [121, 125], [126, 128], [129, 130], [131, 139], [140, 142], [143, 147], [148, 153], [154, 157], [158, 165], [166, 176], [177, 184], [184, 185], [186, 187], [188, 195], [196, 205], [206, 210], [211, 217], [218, 226], [227, 234], [235, 239], [240, 243], [244, 252], [253, 255], [256, 259], [260, 265], [266, 270], [271, 273], [274, 277], [278, 284], [285, 287], [288, 298], [299, 304], [305, 311], [312, 314], [315, 319], [319, 320], [321, 324], [325, 333], [334, 347], [348, 356], [356, 357], [358, 365], [366, 369], [370, 373], [374, 377], [378, 388], [389, 395], [395, 396], [397, 400], [401, 411], [412, 423], [424, 427], [428, 434], [435, 446], [447, 459], [459, 460]]}
{"doc_key": "ai-dev-64", "ner": [[11, 12, "algorithm"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 15, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "many", "applications", ",", "the", "blocks", "of", "these", "networks", "apply", "a", "sigmoid", "function", "as", "an", "activation", "function", "."], "sentence-detokenized": "In many applications, the blocks of these networks apply a sigmoid function as an activation function.", "token2charspan": [[0, 2], [3, 7], [8, 20], [20, 21], [22, 25], [26, 32], [33, 35], [36, 41], [42, 50], [51, 56], [57, 58], [59, 66], [67, 75], [76, 78], [79, 81], [82, 92], [93, 101], [101, 102]]}
{"doc_key": "ai-dev-65", "ner": [[3, 6, "researcher"], [11, 17, "organisation"], [27, 33, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 6, 11, 17, "role", "", false, false], [3, 6, 27, 33, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2001", ",", "Mehler", "was", "elected", "a", "foreign", "honorary", "member", "of", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "and", "in", "2003", "-", "a", "member", "of", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In 2001, Mehler was elected a foreign honorary member of the American Academy of Arts and Sciences, and in 2003 - a member of the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 27], [28, 29], [30, 37], [38, 46], [47, 53], [54, 56], [57, 60], [61, 69], [70, 77], [78, 80], [81, 85], [86, 89], [90, 98], [98, 99], [100, 103], [104, 106], [107, 111], [112, 113], [114, 115], [116, 122], [123, 125], [126, 129], [130, 138], [139, 150], [151, 154], [155, 158], [159, 170], [171, 173], [174, 181], [181, 182]]}
{"doc_key": "ai-dev-66", "ner": [[4, 6, "task"], [8, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 8, 10, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Extending", "this", "concept", "to", "non", "-binary", "classifications", "yields", "a", "confusion", "matrix", "."], "sentence-detokenized": "Extending this concept to non-binary classifications yields a confusion matrix.", "token2charspan": [[0, 9], [10, 14], [15, 22], [23, 25], [26, 29], [29, 36], [37, 52], [53, 59], [60, 61], [62, 71], [72, 78], [78, 79]]}
{"doc_key": "ai-dev-67", "ner": [[13, 14, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "updated", "estimate", "of", "the", "measurement", "noise", "variance", "can", "be", "obtained", "from", "the", "maximum", "likelihood", "calculation"], "sentence-detokenized": "An updated estimate of the measurement noise variance can be obtained from the maximum likelihood calculation", "token2charspan": [[0, 2], [3, 10], [11, 19], [20, 22], [23, 26], [27, 38], [39, 44], [45, 53], [54, 57], [58, 60], [61, 69], [70, 74], [75, 78], [79, 86], [87, 97], [98, 109]]}
{"doc_key": "ai-dev-68", "ner": [[1, 2, "field"], [4, 6, "algorithm"], [7, 8, "field"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 7, 8, "usage", "", true, false], [4, 6, 11, 12, "related-to", "", true, false], [7, 8, 1, 2, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "machine", "learning", ",", "perceptron", "is", "a", "supervised", "learning", "algorithm", "for", "binary", "classification", "."], "sentence-detokenized": "In machine learning, perceptron is a supervised learning algorithm for binary classification.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 31], [32, 34], [35, 36], [37, 47], [48, 56], [57, 66], [67, 70], [71, 77], [78, 92], [92, 93]]}
{"doc_key": "ai-dev-69", "ner": [[12, 13, "field"], [15, 15, "field"], [19, 24, "conference"], [27, 31, "conference"], [34, 40, "conference"], [43, 47, "conference"], [51, 55, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[19, 24, 12, 13, "topic", "", false, false], [19, 24, 15, 15, "topic", "", false, false], [27, 31, 12, 13, "topic", "", false, false], [27, 31, 15, 15, "topic", "", false, false], [34, 40, 12, 13, "topic", "", false, false], [34, 40, 15, 15, "topic", "", false, false], [43, 47, 12, 13, "topic", "", false, false], [43, 47, 15, 15, "topic", "", false, false], [51, 55, 12, 13, "topic", "", false, false], [51, 55, 15, 15, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["She", "has", "also", "served", "as", "a", "session", "chair", "for", "several", "conferences", "on", "machine", "learning", "and", "vision", ",", "including", "the", "Conference", "on", "Neural", "Information", "Processing", "Systems", ",", "the", "International", "Conference", "on", "Representation", "Learning", ",", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "the", "International", "Conference", "on", "Computer", "Vision", ",", "and", "the", "European", "Conference", "on", "Computer", "Vision", "."], "sentence-detokenized": "She has also served as a session chair for several conferences on machine learning and vision, including the Conference on Neural Information Processing Systems, the International Conference on Representation Learning, the Conference on Computer Vision and Pattern Recognition, the International Conference on Computer Vision, and the European Conference on Computer Vision.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 19], [20, 22], [23, 24], [25, 32], [33, 38], [39, 42], [43, 50], [51, 62], [63, 65], [66, 73], [74, 82], [83, 86], [87, 93], [93, 94], [95, 104], [105, 108], [109, 119], [120, 122], [123, 129], [130, 141], [142, 152], [153, 160], [160, 161], [162, 165], [166, 179], [180, 190], [191, 193], [194, 208], [209, 217], [217, 218], [219, 222], [223, 233], [234, 236], [237, 245], [246, 252], [253, 256], [257, 264], [265, 276], [276, 277], [278, 281], [282, 295], [296, 306], [307, 309], [310, 318], [319, 325], [325, 326], [327, 330], [331, 334], [335, 343], [344, 354], [355, 357], [358, 366], [367, 373], [373, 374]]}
{"doc_key": "ai-dev-70", "ner": [[0, 2, "algorithm"], [8, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 10, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "condensation", "algorithm", "was", "also", "used", "for", "the", "face", "recognition", "system", "in", "the", "video", "sequence", "."], "sentence-detokenized": "The condensation algorithm was also used for the face recognition system in the video sequence.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 30], [31, 35], [36, 40], [41, 44], [45, 48], [49, 53], [54, 65], [66, 72], [73, 75], [76, 79], [80, 85], [86, 94], [94, 95]]}
{"doc_key": "ai-dev-71", "ner": [[0, 2, "task"], [7, 8, "organisation"], [17, 21, "conference"], [25, 31, "academicjournal"], [33, 33, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[17, 21, 0, 2, "topic", "", false, false], [17, 21, 7, 8, "origin", "", false, false], [25, 31, 0, 2, "topic", "", false, false], [25, 31, 7, 8, "origin", "", true, false], [33, 33, 25, 31, "role", "edited_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Dissemination", "of", "information", "is", "also", "part", "of", "ELRA", "'s", "mission", ",", "both", "through", "the", "organization", "of", "the", "LREC", "conference", "and", "through", "the", "publication", "of", "the", "journal", "Language", "Resources", "and", "Assessment", ",", "published", "by", "Springer", "."], "sentence-detokenized": "Dissemination of information is also part of ELRA's mission, both through the organization of the LREC conference and through the publication of the journal Language Resources and Assessment, published by Springer.", "token2charspan": [[0, 13], [14, 16], [17, 28], [29, 31], [32, 36], [37, 41], [42, 44], [45, 49], [49, 51], [52, 59], [59, 60], [61, 65], [66, 73], [74, 77], [78, 90], [91, 93], [94, 97], [98, 102], [103, 113], [114, 117], [118, 125], [126, 129], [130, 141], [142, 144], [145, 148], [149, 156], [157, 165], [166, 175], [176, 179], [180, 190], [190, 191], [192, 201], [202, 204], [205, 213], [213, 214]]}
{"doc_key": "ai-dev-72", "ner": [[2, 10, "field"], [12, 13, "field"], [17, 19, "field"], [21, 22, "field"], [58, 60, "field"], [64, 64, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 10, 58, 60, "named", "", false, false], [17, 19, 2, 10, "named", "", false, false], [64, 64, 12, 13, "part-of", "", true, false], [64, 64, 17, 19, "part-of", "", true, false], [64, 64, 58, 60, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "the", "theory", "of", "linear", "time", "invariant", "(", "LTI", ")", "systems", ",", "control", "theory", ",", "and", "in", "digital", "signal", "processing", "or", "signal", "processing", ",", "the", "relationship", "between", "the", "input", "signal", ",", "math", "\\", "displaystyle", "x", "(", "t", ")", "/", "math", ",", "and", "the", "output", "signal", ",", "math", "\\", "displaystyle", "y", "(", "t", ")", "/", "math", ",", "of", "an", "LTI", "system", "is", "governed", "by", "the", "convolution", "operation", ":"], "sentence-detokenized": "In the theory of linear time invariant (LTI) systems, control theory, and in digital signal processing or signal processing, the relationship between the input signal, math\\ displaystyle x(t)/math, and the output signal, math\\ displaystyle y(t)/math, of an LTI system is governed by the convolution operation:", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 16], [17, 23], [24, 28], [29, 38], [39, 40], [40, 43], [43, 44], [45, 52], [52, 53], [54, 61], [62, 68], [68, 69], [70, 73], [74, 76], [77, 84], [85, 91], [92, 102], [103, 105], [106, 112], [113, 123], [123, 124], [125, 128], [129, 141], [142, 149], [150, 153], [154, 159], [160, 166], [166, 167], [168, 172], [172, 173], [174, 186], [187, 188], [188, 189], [189, 190], [190, 191], [191, 192], [192, 196], [196, 197], [198, 201], [202, 205], [206, 212], [213, 219], [219, 220], [221, 225], [225, 226], [227, 239], [240, 241], [241, 242], [242, 243], [243, 244], [244, 245], [245, 249], [249, 250], [251, 253], [254, 256], [257, 260], [261, 267], [268, 270], [271, 279], [280, 282], [283, 286], [287, 298], [299, 308], [308, 309]]}
{"doc_key": "ai-dev-73", "ner": [[15, 16, "field"], [18, 19, "field"], [21, 22, "field"], [24, 25, "field"], [27, 30, "field"], [32, 33, "product"], [35, 36, "field"], [38, 38, "field"], [40, 41, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Due", "to", "its", "generality", ",", "this", "area", "is", "studied", "in", "many", "other", "disciplines", "such", "as", "game", "theory", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimization", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Due to its generality, this area is studied in many other disciplines such as game theory, control theory, operations research, information theory, simulation-based optimization, multi-agent systems, swarm intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 21], [21, 22], [23, 27], [28, 32], [33, 35], [36, 43], [44, 46], [47, 51], [52, 57], [58, 69], [70, 74], [75, 77], [78, 82], [83, 89], [89, 90], [91, 98], [99, 105], [105, 106], [107, 117], [118, 126], [126, 127], [128, 139], [140, 146], [146, 147], [148, 158], [158, 159], [159, 164], [165, 177], [177, 178], [179, 190], [191, 198], [198, 199], [200, 205], [206, 218], [218, 219], [220, 230], [231, 234], [235, 242], [243, 253], [253, 254]]}
{"doc_key": "ai-dev-74", "ner": [[0, 2, "algorithm"], [15, 16, "field"], [22, 23, "algorithm"], [26, 27, "algorithm"], [34, 35, "algorithm"], [39, 39, "algorithm"], [40, 42, "researcher"], [44, 45, "researcher"], [47, 49, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[15, 16, 0, 2, "usage", "", true, false], [22, 23, 15, 16, "part-of", "", true, false], [26, 27, 15, 16, "part-of", "", true, false], [34, 35, 15, 16, "part-of", "", true, false], [39, 39, 15, 16, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Stochastic", "gradient", "descent", "is", "a", "popular", "algorithm", "for", "training", "a", "wide", "range", "of", "models", "in", "machine", "learning", ",", "including", "(", "linear", ")", "support", "vector", "machines", ",", "logistic", "regression", "(", "see", ",", "for", "example", ",", "Vowpal", "Wabbit", ")", ",", "and", "graphical", "models.Jenny", "Rose", "Finkel", ",", "Alex", "Kleeman", ",", "Christopher", "D.", "Manning", "(", "2008", ")", "."], "sentence-detokenized": "Stochastic gradient descent is a popular algorithm for training a wide range of models in machine learning, including (linear) support vector machines, logistic regression (see, for example, Vowpal Wabbit), and graphical models.Jenny Rose Finkel, Alex Kleeman, Christopher D. Manning (2008).", "token2charspan": [[0, 10], [11, 19], [20, 27], [28, 30], [31, 32], [33, 40], [41, 50], [51, 54], [55, 63], [64, 65], [66, 70], [71, 76], [77, 79], [80, 86], [87, 89], [90, 97], [98, 106], [106, 107], [108, 117], [118, 119], [119, 125], [125, 126], [127, 134], [135, 141], [142, 150], [150, 151], [152, 160], [161, 171], [172, 173], [173, 176], [176, 177], [178, 181], [182, 189], [189, 190], [191, 197], [198, 204], [204, 205], [205, 206], [207, 210], [211, 220], [221, 233], [234, 238], [239, 245], [245, 246], [247, 251], [252, 259], [259, 260], [261, 272], [273, 275], [276, 283], [284, 285], [285, 289], [289, 290], [290, 291]]}
{"doc_key": "ai-dev-75", "ner": [[8, 8, "organisation"], [12, 14, "product"], [20, 20, "country"], [22, 25, "university"], [27, 27, "location"], [29, 31, "university"], [33, 33, "location"], [35, 35, "university"], [38, 38, "location"], [40, 42, "university"], [44, 44, "location"], [46, 47, "university"], [49, 49, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 8, 22, 25, "role", "donates_to", false, false], [8, 8, 29, 31, "role", "donates_to", false, false], [8, 8, 35, 35, "role", "donates_to", false, false], [8, 8, 40, 42, "role", "donates_to", false, false], [8, 8, 46, 47, "role", "donates_to", false, false], [12, 14, 8, 8, "origin", "donates", true, false], [22, 25, 27, 27, "physical", "", false, false], [27, 27, 20, 20, "physical", "", false, false], [29, 31, 33, 33, "physical", "", false, false], [33, 33, 20, 20, "physical", "", false, false], [35, 35, 38, 38, "physical", "", false, false], [38, 38, 20, 20, "physical", "", false, false], [40, 42, 44, 44, "physical", "", false, false], [44, 44, 20, 20, "physical", "", false, false], [46, 47, 49, 49, "physical", "", false, false], [49, 49, 20, 20, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "sentence": ["In", "August", "2011", ",", "it", "was", "announced", "that", "Hitachi", "will", "donate", "an", "electron", "microscope", "to", "each", "of", "five", "universities", "in", "Indonesia", "(", "University", "of", "North", "Sumatra", "in", "Medan", ",", "Indonesian", "Christian", "University", "in", "Jakarta", ",", "Pajajaran", "University", "in", "Bandung", ",", "Genderal", "Soedirman", "University", "in", "Purwokerto", "and", "Muhammadiyah", "University", "in", "Malang", ")", "."], "sentence-detokenized": "In August 2011, it was announced that Hitachi will donate an electron microscope to each of five universities in Indonesia (University of North Sumatra in Medan, Indonesian Christian University in Jakarta, Pajajaran University in Bandung, Genderal Soedirman University in Purwokerto and Muhammadiyah University in Malang).", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 18], [19, 22], [23, 32], [33, 37], [38, 45], [46, 50], [51, 57], [58, 60], [61, 69], [70, 80], [81, 83], [84, 88], [89, 91], [92, 96], [97, 109], [110, 112], [113, 122], [123, 124], [124, 134], [135, 137], [138, 143], [144, 151], [152, 154], [155, 160], [160, 161], [162, 172], [173, 182], [183, 193], [194, 196], [197, 204], [204, 205], [206, 215], [216, 226], [227, 229], [230, 237], [237, 238], [239, 247], [248, 257], [258, 268], [269, 271], [272, 282], [283, 286], [287, 299], [300, 310], [311, 313], [314, 320], [320, 321], [321, 322]]}
{"doc_key": "ai-dev-76", "ner": [[0, 0, "field"], [3, 4, "field"], [8, 8, "algorithm"], [10, 11, "algorithm"], [20, 21, "field"], [26, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 3, 4, "part-of", "", false, false], [0, 0, 20, 21, "related-to", "", true, false], [0, 0, 26, 27, "related-to", "", true, false], [8, 8, 0, 0, "type-of", "", false, false], [10, 11, 0, 0, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Optimization", "methods", "of", "operations", "research", ",", "such", "as", "linear", "or", "dynamic", "programming", ",", "are", "often", "impractical", "for", "large", "-", "scale", "software", "engineering", "problems", "due", "to", "their", "computational", "complexity", "."], "sentence-detokenized": "Optimization methods of operations research, such as linear or dynamic programming, are often impractical for large-scale software engineering problems due to their computational complexity.", "token2charspan": [[0, 12], [13, 20], [21, 23], [24, 34], [35, 43], [43, 44], [45, 49], [50, 52], [53, 59], [60, 62], [63, 70], [71, 82], [82, 83], [84, 87], [88, 93], [94, 105], [106, 109], [110, 115], [115, 116], [116, 121], [122, 130], [131, 142], [143, 151], [152, 155], [156, 158], [159, 164], [165, 178], [179, 189], [189, 190]]}
{"doc_key": "ai-dev-77", "ner": [[0, 1, "metrics"], [7, 7, "metrics"], [9, 11, "metrics"], [16, 17, "metrics"], [20, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 7, 7, "compare", "", false, false], [0, 1, 9, 11, "compare", "", false, false], [16, 17, 9, 11, "part-of", "", false, false], [20, 23, 9, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sensitivity", "is", "not", "the", "same", "thing", "as", "accuracy", "or", "positive", "predictive", "value", "(", "the", "ratio", "of", "true", "positives", "to", "combined", "true", "and", "false", "positives", ")", ",", "which", "is", "as", "much", "a", "statement", "about", "the", "proportion", "of", "true", "positives", "in", "the", "tested", "population", "as", "it", "is", "about", "the", "test", "."], "sentence-detokenized": "Sensitivity is not the same thing as accuracy or positive predictive value (the ratio of true positives to combined true and false positives), which is as much a statement about the proportion of true positives in the tested population as it is about the test.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 22], [23, 27], [28, 33], [34, 36], [37, 45], [46, 48], [49, 57], [58, 68], [69, 74], [75, 76], [76, 79], [80, 85], [86, 88], [89, 93], [94, 103], [104, 106], [107, 115], [116, 120], [121, 124], [125, 130], [131, 140], [140, 141], [141, 142], [143, 148], [149, 151], [152, 154], [155, 159], [160, 161], [162, 171], [172, 177], [178, 181], [182, 192], [193, 195], [196, 200], [201, 210], [211, 213], [214, 217], [218, 224], [225, 235], [236, 238], [239, 241], [242, 244], [245, 250], [251, 254], [255, 259], [259, 260]]}
{"doc_key": "ai-dev-78", "ner": [[0, 2, "person"], [9, 9, "product"], [13, 13, "person"], [27, 27, "person"], [34, 35, "person"], [39, 40, "person"], [45, 48, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 39, 40, "named", "same", false, false], [9, 9, 0, 2, "artifact", "", false, false], [34, 35, 45, 48, "role", "convinces", false, false], [45, 48, 9, 9, "role", "producer", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Hampton", "Fancher", "'s", "script", "--", "originally", "not", "called", "\"", "Android", "\"", "--", "see", "Sammon", ",", "pp.", "32", "and", "38", "for", "explanation", "--", "was", "selected", "in", "1977", ".", "Sammon", ",", "pp.", "23", "-", "30", "Producer", "Michael", "Deeley", "became", "interested", "in", "Fancher", "'s", "project", "and", "convinced", "director", "Ridley", "Scott", "to", "adapt", "it", "."], "sentence-detokenized": "Hampton Fancher's script -- originally not called \"Android\" -- see Sammon, pp. 32 and 38 for explanation -- was selected in 1977. Sammon, pp. 23-30 Producer Michael Deeley became interested in Fancher's project and convinced director Ridley Scott to adapt it.", "token2charspan": [[0, 7], [8, 15], [15, 17], [18, 24], [25, 27], [28, 38], [39, 42], [43, 49], [50, 51], [51, 58], [58, 59], [60, 62], [63, 66], [67, 73], [73, 74], [75, 78], [79, 81], [82, 85], [86, 88], [89, 92], [93, 104], [105, 107], [108, 111], [112, 120], [121, 123], [124, 128], [128, 129], [130, 136], [136, 137], [138, 141], [142, 144], [144, 145], [145, 147], [148, 156], [157, 164], [165, 171], [172, 178], [179, 189], [190, 192], [193, 200], [200, 202], [203, 210], [211, 214], [215, 224], [225, 233], [234, 240], [241, 246], [247, 249], [250, 255], [256, 258], [258, 259]]}
{"doc_key": "ai-dev-79", "ner": [[0, 1, "field"], [3, 4, "task"], [6, 7, "task"], [10, 12, "misc"], [14, 15, "field"], [17, 19, "task"], [21, 22, "task"], [24, 24, "field"], [25, 31, "task"], [33, 33, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[3, 4, 0, 1, "part-of", "", false, false], [6, 7, 0, 1, "part-of", "", false, false], [10, 12, 0, 1, "part-of", "", false, false], [14, 15, 0, 1, "part-of", "", false, false], [17, 19, 0, 1, "part-of", "", false, false], [21, 22, 0, 1, "part-of", "", false, false], [24, 24, 0, 1, "part-of", "", false, false], [25, 31, 0, 1, "part-of", "", false, false], [33, 33, 0, 1, "part-of", "", false, false], [35, 36, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Text", "mining", "includes", "information", "retrieval", ",", "lexical", "analysis", "to", "study", "word", "frequency", "distribution", ",", "pattern", "recognition", ",", "tagging", "/", "annotation", ",", "information", "extraction", ",", "data", "mining", "techniques", "including", "link", "and", "association", "analysis", ",", "visualization", "and", "predictive", "analytics", "."], "sentence-detokenized": "Text mining includes information retrieval, lexical analysis to study word frequency distribution, pattern recognition, tagging/annotation, information extraction, data mining techniques including link and association analysis, visualization and predictive analytics.", "token2charspan": [[0, 4], [5, 11], [12, 20], [21, 32], [33, 42], [42, 43], [44, 51], [52, 60], [61, 63], [64, 69], [70, 74], [75, 84], [85, 97], [97, 98], [99, 106], [107, 118], [118, 119], [120, 127], [127, 128], [128, 138], [138, 139], [140, 151], [152, 162], [162, 163], [164, 168], [169, 175], [176, 186], [187, 196], [197, 201], [202, 205], [206, 217], [218, 226], [226, 227], [228, 241], [242, 245], [246, 256], [257, 266], [266, 267]]}
{"doc_key": "ai-dev-80", "ner": [[3, 3, "product"], [11, 12, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 3, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Several", "metrics", "use", "WordNet", ",", "a", "manually", "created", "lexical", "database", "of", "English", "words", "."], "sentence-detokenized": "Several metrics use WordNet, a manually created lexical database of English words.", "token2charspan": [[0, 7], [8, 15], [16, 19], [20, 27], [27, 28], [29, 30], [31, 39], [40, 47], [48, 55], [56, 64], [65, 67], [68, 75], [76, 81], [81, 82]]}
{"doc_key": "ai-dev-81", "ner": [[12, 13, "field"], [15, 16, "task"], [0, 19, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["To", "find", "answers", ",", "the", "system", "uses", "a", "combination", "of", "methods", "from", "computational", "linguistics", ",", "information", "retrieval", "and", "knowledge", "representation", "."], "sentence-detokenized": "To find answers, the system uses a combination of methods from computational linguistics, information retrieval and knowledge representation.", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 20], [21, 27], [28, 32], [33, 34], [35, 46], [47, 49], [50, 57], [58, 62], [63, 76], [77, 88], [88, 89], [90, 101], [102, 111], [112, 115], [116, 125], [126, 140], [140, 141]]}
{"doc_key": "ai-dev-82", "ner": [[6, 7, "metrics"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 13, 14, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "performance", "measure", ",", "the", "uncertainty", "factor", "has", "an", "advantage", "over", "simple", "accuracy", "in", "that", "it", "is", "not", "affected", "by", "the", "relative", "sizes", "of", "the", "different", "classes", "."], "sentence-detokenized": "As a performance measure, the uncertainty factor has an advantage over simple accuracy in that it is not affected by the relative sizes of the different classes.", "token2charspan": [[0, 2], [3, 4], [5, 16], [17, 24], [24, 25], [26, 29], [30, 41], [42, 48], [49, 52], [53, 55], [56, 65], [66, 70], [71, 77], [78, 86], [87, 89], [90, 94], [95, 97], [98, 100], [101, 104], [105, 113], [114, 116], [117, 120], [121, 129], [130, 135], [136, 138], [139, 142], [143, 152], [153, 160], [160, 161]]}
{"doc_key": "ai-dev-83", "ner": [[9, 10, "algorithm"], [12, 13, "algorithm"], [15, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Researchers", "have", "tried", "a", "number", "of", "methods", "such", "as", "optical", "flow", ",", "Kalman", "filtering", ",", "hidden", "Markov", "models", ",", "etc", "."], "sentence-detokenized": "Researchers have tried a number of methods such as optical flow, Kalman filtering, hidden Markov models, etc.", "token2charspan": [[0, 11], [12, 16], [17, 22], [23, 24], [25, 31], [32, 34], [35, 42], [43, 47], [48, 50], [51, 58], [59, 63], [63, 64], [65, 71], [72, 81], [81, 82], [83, 89], [90, 96], [97, 103], [103, 104], [105, 108], [108, 109]]}
{"doc_key": "ai-dev-84", "ner": [[15, 22, "conference"], [32, 35, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "has", "served", "as", "president", ",", "vice", "president", ",", "and", "secretary", "-", "treasurer", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "and", "was", "a", "board", "member", "and", "secretary", "of", "the", "board", "of", "the", "Association", "for", "Computing", "Research", "."], "sentence-detokenized": "She has served as president, vice president, and secretary-treasurer of the Association for Computational Linguistics, and was a board member and secretary of the board of the Association for Computing Research.", "token2charspan": [[0, 3], [4, 7], [8, 14], [15, 17], [18, 27], [27, 28], [29, 33], [34, 43], [43, 44], [45, 48], [49, 58], [58, 59], [59, 68], [69, 71], [72, 75], [76, 87], [88, 91], [92, 105], [106, 117], [117, 118], [119, 122], [123, 126], [127, 128], [129, 134], [135, 141], [142, 145], [146, 155], [156, 158], [159, 162], [163, 168], [169, 171], [172, 175], [176, 187], [188, 191], [192, 201], [202, 210], [210, 211]]}
{"doc_key": "ai-dev-85", "ner": [[6, 6, "programlang"], [8, 8, "product"], [10, 10, "programlang"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 10, 10, "compare", "", false, false], [6, 6, 12, 13, "related-to", "supports", false, false], [8, 8, 10, 10, "compare", "", false, false], [8, 8, 12, 13, "related-to", "supports", false, false], [10, 10, 12, 13, "related-to", "supports", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Like", "other", "similar", "languages", "such", "as", "APL", "and", "MATLAB", ",", "R", "supports", "matrix", "arithmetic", "."], "sentence-detokenized": "Like other similar languages such as APL and MATLAB, R supports matrix arithmetic.", "token2charspan": [[0, 4], [5, 10], [11, 18], [19, 28], [29, 33], [34, 36], [37, 40], [41, 44], [45, 51], [51, 52], [53, 54], [55, 63], [64, 70], [71, 81], [81, 82]]}
{"doc_key": "ai-dev-86", "ner": [[11, 12, "misc"], [8, 10, "organisation"], [17, 18, "researcher"], [21, 24, "university"], [27, 32, "misc"], [34, 34, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 12, 8, 10, "physical", "", false, false], [11, 12, 27, 32, "temporal", "", false, false], [17, 18, 11, 12, "role", "arranges", false, false], [17, 18, 21, 24, "role", "works_for", false, false], [34, 34, 11, 12, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["On", "June", "7", ",", "2014", ",", "at", "the", "Royal", "Society", "'s", "Turing", "Test", "Competition", ",", "organized", "by", "Kevin", "Warwick", "of", "the", "University", "of", "Reading", "to", "mark", "the", "60th", "anniversary", "of", "Turing", "'s", "death", ",", "Gustman", "won", "after", "33", "%", "of", "the", "judges", "were", "convinced", "that", "the", "bot", "was", "human", "."], "sentence-detokenized": "On June 7, 2014, at the Royal Society's Turing Test Competition, organized by Kevin Warwick of the University of Reading to mark the 60th anniversary of Turing's death, Gustman won after 33% of the judges were convinced that the bot was human.", "token2charspan": [[0, 2], [3, 7], [8, 9], [9, 10], [11, 15], [15, 16], [17, 19], [20, 23], [24, 29], [30, 37], [37, 39], [40, 46], [47, 51], [52, 63], [63, 64], [65, 74], [75, 77], [78, 83], [84, 91], [92, 94], [95, 98], [99, 109], [110, 112], [113, 120], [121, 123], [124, 128], [129, 132], [133, 137], [138, 149], [150, 152], [153, 159], [159, 161], [162, 167], [167, 168], [169, 176], [177, 180], [181, 186], [187, 189], [189, 190], [191, 193], [194, 197], [198, 204], [205, 209], [210, 219], [220, 224], [225, 228], [229, 232], [233, 236], [237, 242], [242, 243]]}
{"doc_key": "ai-dev-87", "ner": [[0, 2, "product"], [4, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "collaborative", "robot", "or", "cobot", "is", "a", "robot", "that", "can", "safely", "and", "efficiently", "interact", "with", "human", "workers", "to", "perform", "simple", "industrial", "tasks", "."], "sentence-detokenized": "A collaborative robot or cobot is a robot that can safely and efficiently interact with human workers to perform simple industrial tasks.", "token2charspan": [[0, 1], [2, 15], [16, 21], [22, 24], [25, 30], [31, 33], [34, 35], [36, 41], [42, 46], [47, 50], [51, 57], [58, 61], [62, 73], [74, 82], [83, 87], [88, 93], [94, 101], [102, 104], [105, 112], [113, 119], [120, 130], [131, 136], [136, 137]]}
{"doc_key": "ai-dev-88", "ner": [[11, 12, "field"], [16, 17, "task"], [19, 20, "task"], [22, 23, "task"], [25, 26, "task"], [28, 29, "task"], [31, 33, "task"], [36, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[16, 17, 11, 12, "part-of", "task_part_of_field", false, false], [19, 20, 11, 12, "part-of", "task_part_of_field", false, false], [22, 23, 11, 12, "part-of", "task_part_of_field", false, false], [25, 26, 11, 12, "part-of", "task_part_of_field", false, false], [28, 29, 11, 12, "part-of", "task_part_of_field", false, false], [31, 33, 11, 12, "part-of", "task_part_of_field", false, false], [36, 37, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["This", "general", "framework", "has", "been", "applied", "to", "a", "wide", "range", "of", "computer", "vision", "problems", ",", "including", "feature", "detection", ",", "feature", "classification", ",", "image", "segmentation", ",", "image", "matching", ",", "motion", "estimation", ",", "shape", "feature", "computation", ",", "and", "object", "recognition", "."], "sentence-detokenized": "This general framework has been applied to a wide range of computer vision problems, including feature detection, feature classification, image segmentation, image matching, motion estimation, shape feature computation, and object recognition.", "token2charspan": [[0, 4], [5, 12], [13, 22], [23, 26], [27, 31], [32, 39], [40, 42], [43, 44], [45, 49], [50, 55], [56, 58], [59, 67], [68, 74], [75, 83], [83, 84], [85, 94], [95, 102], [103, 112], [112, 113], [114, 121], [122, 136], [136, 137], [138, 143], [144, 156], [156, 157], [158, 163], [164, 172], [172, 173], [174, 180], [181, 191], [191, 192], [193, 198], [199, 206], [207, 218], [218, 219], [220, 223], [224, 230], [231, 242], [242, 243]]}
{"doc_key": "ai-dev-89", "ner": [[12, 15, "task"], [16, 22, "algorithm"], [6, 7, "algorithm"], [27, 29, "algorithm"], [33, 36, "algorithm"], [40, 40, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 15, 16, 22, "part-of", "", false, false], [12, 15, 6, 7, "usage", "", false, false], [16, 22, 27, 29, "named", "same", false, false], [27, 29, 33, 36, "related-to", "", false, false], [27, 29, 40, 40, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "many", "practical", "applications", ",", "the", "maximum", "likelihood", "method", "is", "used", "to", "estimate", "the", "parameters", "of", "naive", "Bayesian", "models", ",", "i.e.", "it", "is", "possible", "to", "work", "with", "a", "naive", "Bayesian", "model", "without", "assuming", "Bayesian", "probability", "and", "without", "using", "any", "Bayesian", "methods", "."], "sentence-detokenized": "In many practical applications, the maximum likelihood method is used to estimate the parameters of naive Bayesian models, i.e. it is possible to work with a naive Bayesian model without assuming Bayesian probability and without using any Bayesian methods.", "token2charspan": [[0, 2], [3, 7], [8, 17], [18, 30], [30, 31], [32, 35], [36, 43], [44, 54], [55, 61], [62, 64], [65, 69], [70, 72], [73, 81], [82, 85], [86, 96], [97, 99], [100, 105], [106, 114], [115, 121], [121, 122], [123, 127], [128, 130], [131, 133], [134, 142], [143, 145], [146, 150], [151, 155], [156, 157], [158, 163], [164, 172], [173, 178], [179, 186], [187, 195], [196, 204], [205, 216], [217, 220], [221, 228], [229, 234], [235, 238], [239, 247], [248, 255], [255, 256]]}
{"doc_key": "ai-dev-90", "ner": [[3, 5, "researcher"], [7, 8, "misc"], [13, 16, "university"], [18, 20, "researcher"], [22, 23, "misc"], [27, 27, "university"], [29, 29, "university"], [31, 31, "misc"], [39, 41, "university"], [48, 51, "misc"], [55, 58, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[3, 5, 13, 16, "physical", "", false, false], [3, 5, 13, 16, "role", "", false, false], [3, 5, 18, 20, "social", "brothers", false, false], [7, 8, 3, 5, "named", "", false, false], [18, 20, 27, 27, "physical", "", false, false], [18, 20, 27, 27, "role", "", false, false], [18, 20, 29, 29, "physical", "", false, false], [18, 20, 29, 29, "role", "", false, false], [18, 20, 39, 41, "physical", "", false, false], [18, 20, 39, 41, "role", "", false, false], [22, 23, 18, 20, "named", "", false, false], [31, 31, 18, 20, "origin", "", false, false], [48, 51, 18, 20, "artifact", "", false, false], [48, 51, 55, 58, "part-of", "part", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["The", "brothers", "are", "Victor", "Gershevich", "Katz", ",", "American", "mathematician", ",", "professor", "at", "the", "Massachusetts", "Institute", "of", "Technology", ";", "Michael", "Gershevich", "Katz", ",", "Israeli", "mathematician", ",", "graduate", "of", "Harvard", "and", "Columbia", "(", "PhD", ",", "1984", ")", "universities", ",", "professor", "at", "Bar-", "Ilan", "University", ",", "author", "of", "the", "monograph", "\"", "Systolic", "Geometry", "and", "Topology", "\"", "(", "\"", "Mathematical", "Studies", "and", "Monographs", "\"", ",", "vol", ".", "1", ")", "."], "sentence-detokenized": "The brothers are Victor Gershevich Katz, American mathematician, professor at the Massachusetts Institute of Technology; Michael Gershevich Katz, Israeli mathematician, graduate of Harvard and Columbia (PhD, 1984) universities, professor at Bar-Ilan University, author of the monograph \"Systolic Geometry and Topology\" (\"Mathematical Studies and Monographs\", vol. 1).", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 23], [24, 34], [35, 39], [39, 40], [41, 49], [50, 63], [63, 64], [65, 74], [75, 77], [78, 81], [82, 95], [96, 105], [106, 108], [109, 119], [119, 120], [121, 128], [129, 139], [140, 144], [144, 145], [146, 153], [154, 167], [167, 168], [169, 177], [178, 180], [181, 188], [189, 192], [193, 201], [202, 203], [203, 206], [206, 207], [208, 212], [212, 213], [214, 226], [226, 227], [228, 237], [238, 240], [241, 245], [245, 249], [250, 260], [260, 261], [262, 268], [269, 271], [272, 275], [276, 285], [286, 287], [287, 295], [296, 304], [305, 308], [309, 317], [317, 318], [319, 320], [320, 321], [321, 333], [334, 341], [342, 345], [346, 356], [356, 357], [357, 358], [359, 362], [362, 363], [364, 365], [365, 366], [366, 367]]}
{"doc_key": "ai-dev-91", "ner": [[3, 4, "person"], [10, 11, "conference"], [16, 20, "organisation"], [22, 28, "location"], [32, 34, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 10, 11, "physical", "", false, false], [3, 4, 10, 11, "role", "", false, false], [3, 4, 16, 20, "role", "", false, false], [16, 20, 22, 28, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2000", ",", "Manuel", "Tojaria", ",", "a", "speaker", "at", "previous", "campus", "celebrations", "and", "director", "of", "the", "Museo", "de", "Ciencias", "Pr\u00edncipe", "Felipe", "in", "Valencia", "'s", "City", "of", "Arts", "and", "Sciences", ",", "suggested", "to", "Ragag\u00fcelles", "that", "the", "event", "should", "be", "expanded", "and", "made", "more", "international", "by", "moving", "it", "to", "a", "well", "-", "known", "museum", "."], "sentence-detokenized": "In 2000, Manuel Tojaria, a speaker at previous campus celebrations and director of the Museo de Ciencias Pr\u00edncipe Felipe in Valencia's City of Arts and Sciences, suggested to Ragag\u00fcelles that the event should be expanded and made more international by moving it to a well-known museum.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 23], [23, 24], [25, 26], [27, 34], [35, 37], [38, 46], [47, 53], [54, 66], [67, 70], [71, 79], [80, 82], [83, 86], [87, 92], [93, 95], [96, 104], [105, 113], [114, 120], [121, 123], [124, 132], [132, 134], [135, 139], [140, 142], [143, 147], [148, 151], [152, 160], [160, 161], [162, 171], [172, 174], [175, 186], [187, 191], [192, 195], [196, 201], [202, 208], [209, 211], [212, 220], [221, 224], [225, 229], [230, 234], [235, 248], [249, 251], [252, 258], [259, 261], [262, 264], [265, 266], [267, 271], [271, 272], [272, 277], [278, 284], [284, 285]]}
{"doc_key": "ai-dev-92", "ner": [[5, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Within", "20", "minutes", ",", "the", "face", "recognition", "system", "identifies", "personal", "information", ",", "including", "name", ",", "surname", ",", "ID", "number", "and", "address", ",", "which", "are", "displayed", "on", "the", "outdoor", "advertising", "screen", "."], "sentence-detokenized": "Within 20 minutes, the face recognition system identifies personal information, including name, surname, ID number and address, which are displayed on the outdoor advertising screen.", "token2charspan": [[0, 6], [7, 9], [10, 17], [17, 18], [19, 22], [23, 27], [28, 39], [40, 46], [47, 57], [58, 66], [67, 78], [78, 79], [80, 89], [90, 94], [94, 95], [96, 103], [103, 104], [105, 107], [108, 114], [115, 118], [119, 126], [126, 127], [128, 133], [134, 137], [138, 147], [148, 150], [151, 154], [155, 162], [163, 174], [175, 181], [181, 182]]}
{"doc_key": "ai-dev-93", "ner": [[6, 6, "field"], [9, 9, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Recent", "research", "has", "increasingly", "focused", "on", "unsupervised", "and", "semi-supervised", "learning", "algorithms", "."], "sentence-detokenized": "Recent research has increasingly focused on unsupervised and semi-supervised learning algorithms.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 32], [33, 40], [41, 43], [44, 56], [57, 60], [61, 76], [77, 85], [86, 96], [96, 97]]}
{"doc_key": "ai-dev-94", "ner": [[4, 4, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Calculating", "this", "example", "using", "Python", "code", ":"], "sentence-detokenized": "Calculating this example using Python code:", "token2charspan": [[0, 11], [12, 16], [17, 24], [25, 30], [31, 37], [38, 42], [42, 43]]}
{"doc_key": "ai-dev-95", "ner": [[7, 9, "task"], [15, 16, "field"], [19, 22, "algorithm"], [24, 24, "algorithm"], [28, 30, "algorithm"], [33, 34, "researcher"], [36, 38, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[19, 22, 15, 16, "part-of", "", false, false], [19, 22, 28, 30, "type-of", "", false, false], [19, 22, 33, 34, "origin", "", false, false], [19, 22, 36, 38, "origin", "", false, false], [24, 24, 19, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Today", ",", "however", ",", "many", "aspects", "of", "speech", "recognition", "have", "been", "taken", "over", "by", "a", "deep", "learning", "method", "called", "Long", "Short", "Term", "Memory", "(", "LSTM", ")", ",", "a", "recurrent", "neural", "network", "published", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "in", "1997", "."], "sentence-detokenized": "Today, however, many aspects of speech recognition have been taken over by a deep learning method called Long Short Term Memory (LSTM), a recurrent neural network published by Sepp Hochreiter and J\u00fcrgen Schmidhuber in 1997.", "token2charspan": [[0, 5], [5, 6], [7, 14], [14, 15], [16, 20], [21, 28], [29, 31], [32, 38], [39, 50], [51, 55], [56, 60], [61, 66], [67, 71], [72, 74], [75, 76], [77, 81], [82, 90], [91, 97], [98, 104], [105, 109], [110, 115], [116, 120], [121, 127], [128, 129], [129, 133], [133, 134], [134, 135], [136, 137], [138, 147], [148, 154], [155, 162], [163, 172], [173, 175], [176, 180], [181, 191], [192, 195], [196, 202], [203, 214], [215, 217], [218, 222], [222, 223]]}
{"doc_key": "ai-dev-96", "ner": [[8, 8, "algorithm"], [10, 13, "algorithm"], [18, 18, "algorithm"], [22, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 10, 13, "compare", "", false, false], [8, 8, 22, 22, "named", "same", false, false], [18, 18, 22, 22, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "preliminary", "experimental", "results", "on", "noisy", "datasets", ",", "BrownBoost", "outperformed", "AdaBoost", "in", "terms", "of", "generalization", "error", ",", "but", "LogitBoost", "performed", "similarly", "to", "BrownBoost", "."], "sentence-detokenized": "In preliminary experimental results on noisy datasets, BrownBoost outperformed AdaBoost in terms of generalization error, but LogitBoost performed similarly to BrownBoost.", "token2charspan": [[0, 2], [3, 14], [15, 27], [28, 35], [36, 38], [39, 44], [45, 53], [53, 54], [55, 65], [66, 78], [79, 87], [88, 90], [91, 96], [97, 99], [100, 114], [115, 120], [120, 121], [122, 125], [126, 136], [137, 146], [147, 156], [157, 159], [160, 170], [170, 171]]}
{"doc_key": "ai-dev-97", "ner": [[0, 1, "algorithm"], [5, 6, "researcher"], [9, 10, "country"], [13, 15, "researcher"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 6, "part-of", "", false, false], [5, 6, 9, 10, "physical", "", false, false], [19, 21, 13, 15, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Evolutionary", "programming", "was", "introduced", "by", "Lawrence", "Vogel", "in", "the", "United", "States", ",", "and", "John", "Henry", "Holland", "called", "his", "method", "a", "genetic", "algorithm", "."], "sentence-detokenized": "Evolutionary programming was introduced by Lawrence Vogel in the United States, and John Henry Holland called his method a genetic algorithm.", "token2charspan": [[0, 12], [13, 24], [25, 28], [29, 39], [40, 42], [43, 51], [52, 57], [58, 60], [61, 64], [65, 71], [72, 78], [78, 79], [80, 83], [84, 88], [89, 94], [95, 102], [103, 109], [110, 113], [114, 120], [121, 122], [123, 130], [131, 140], [140, 141]]}
{"doc_key": "ai-dev-98", "ner": [[9, 9, "researcher"], [11, 11, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 27, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 9, 17, 18, "role", "", false, false], [9, 9, 20, 21, "role", "", false, false], [9, 9, 23, 24, "role", "", false, false], [9, 9, 26, 27, "role", "", false, false], [11, 11, 17, 18, "role", "", false, false], [11, 11, 20, 21, "role", "", false, false], [11, 11, 23, 24, "role", "", false, false], [11, 11, 26, 27, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Back", "-", "of", "-", "the", "-", "envelope", "calculations", "by", "Doug", ",", "Alan", "and", "their", "colleagues", "(", "including", "Marvin", "Minsky", ",", "Allen", "Newell", ",", "Edward", "Feigenbaum", "and", "John", "McCarthy", ")", "showed", "that", "this", "effort", "would", "require", "between", "1000", "and", "3000", "man", "-", "years", ",", "well", "beyond", "the", "standard", "academic", "project", "model", "."], "sentence-detokenized": "Back-of-the-envelope calculations by Doug, Alan and their colleagues (including Marvin Minsky, Allen Newell, Edward Feigenbaum and John McCarthy) showed that this effort would require between 1000 and 3000 man-years, well beyond the standard academic project model.", "token2charspan": [[0, 4], [4, 5], [5, 7], [7, 8], [8, 11], [11, 12], [12, 20], [21, 33], [34, 36], [37, 41], [41, 42], [43, 47], [48, 51], [52, 57], [58, 68], [69, 70], [70, 79], [80, 86], [87, 93], [93, 94], [95, 100], [101, 107], [107, 108], [109, 115], [116, 126], [127, 130], [131, 135], [136, 144], [144, 145], [146, 152], [153, 157], [158, 162], [163, 169], [170, 175], [176, 183], [184, 191], [192, 196], [197, 200], [201, 205], [206, 209], [209, 210], [210, 215], [215, 216], [217, 221], [222, 228], [229, 232], [233, 241], [242, 250], [251, 258], [259, 264], [264, 265]]}
{"doc_key": "ai-dev-99", "ner": [[5, 7, "metrics"], [11, 11, "metrics"], [14, 16, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 7, 11, 11, "part-of", "implemented_in", false, false], [14, 16, 19, 19, "part-of", "implemented_in", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "common", "criteria", "are", "the", "mean", "square", "error", "criterion", "implemented", "in", "MSECriterion", "and", "the", "cross", "entropy", "criterion", "implemented", "in", "NLLCriterion", "."], "sentence-detokenized": "The common criteria are the mean square error criterion implemented in MSECriterion and the cross entropy criterion implemented in NLLCriterion.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 23], [24, 27], [28, 32], [33, 39], [40, 45], [46, 55], [56, 67], [68, 70], [71, 83], [84, 87], [88, 91], [92, 97], [98, 105], [106, 115], [116, 127], [128, 130], [131, 143], [143, 144]]}
{"doc_key": "ai-dev-100", "ner": [[0, 1, "researcher"], [11, 11, "organisation"], [15, 26, "misc"], [32, 36, "conference"], [44, 44, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 11, 11, "role", "", false, false], [0, 1, 32, 36, "role", "", false, false], [0, 1, 44, 44, "role", "", false, false], [15, 26, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Zurada", "has", "served", "the", "engineering", "profession", "as", "a", "long", "-", "time", "IEEE", "volunteer", ":", "as", "IEEE", "Vice", "President", "for", "Technical", "Activities", "(", "TAB", "Chair", ")", "in", "2014", ",", "as", "President", "of", "the", "IEEE", "Computational", "Intelligence", "Society", "in", "2004", "-", "05", ",", "and", "as", "an", "ADCOM", "member", "in", "2009", "-", "14", ",", "2016", "-", "18", ",", "and", "earlier", "."], "sentence-detokenized": "Zurada has served the engineering profession as a long-time IEEE volunteer: as IEEE Vice President for Technical Activities (TAB Chair) in 2014, as President of the IEEE Computational Intelligence Society in 2004-05, and as an ADCOM member in 2009-14, 2016-18, and earlier.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 21], [22, 33], [34, 44], [45, 47], [48, 49], [50, 54], [54, 55], [55, 59], [60, 64], [65, 74], [74, 75], [76, 78], [79, 83], [84, 88], [89, 98], [99, 102], [103, 112], [113, 123], [124, 125], [125, 128], [129, 134], [134, 135], [136, 138], [139, 143], [143, 144], [145, 147], [148, 157], [158, 160], [161, 164], [165, 169], [170, 183], [184, 196], [197, 204], [205, 207], [208, 212], [212, 213], [213, 215], [215, 216], [217, 220], [221, 223], [224, 226], [227, 232], [233, 239], [240, 242], [243, 247], [247, 248], [248, 250], [250, 251], [252, 256], [256, 257], [257, 259], [259, 260], [261, 264], [265, 272], [272, 273]]}
{"doc_key": "ai-dev-101", "ner": [[3, 4, "field"], [12, 13, "field"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 13, 3, 4, "part-of", "", false, false], [15, 16, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "general", ",", "computational", "linguistics", "relies", "on", "the", "involvement", "of", "linguists", ",", "computer", "scientists", ",", "artificial", "intelligence", "specialists", ",", "mathematicians", ",", "logicians", ",", "philosophers", ",", "cognitive", "scientists", ",", "cognitive", "psychologists", ",", "psycholinguists", ",", "anthropologists", ",", "neurobiologists", "and", "other", "specialists", "."], "sentence-detokenized": "In general, computational linguistics relies on the involvement of linguists, computer scientists, artificial intelligence specialists, mathematicians, logicians, philosophers, cognitive scientists, cognitive psychologists, psycholinguists, anthropologists, neurobiologists and other specialists.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 25], [26, 37], [38, 44], [45, 47], [48, 51], [52, 63], [64, 66], [67, 76], [76, 77], [78, 86], [87, 97], [97, 98], [99, 109], [110, 122], [123, 134], [134, 135], [136, 150], [150, 151], [152, 161], [161, 162], [163, 175], [175, 176], [177, 186], [187, 197], [197, 198], [199, 208], [209, 222], [222, 223], [224, 239], [239, 240], [241, 256], [256, 257], [258, 273], [274, 277], [278, 283], [284, 295], [295, 296]]}
{"doc_key": "ai-dev-102", "ner": [[10, 12, "algorithm"], [15, 16, "algorithm"], [18, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["To", "exploit", "inter", "-", "frame", "correlation", ",", "methods", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "long", "short", "-", "term", "memory", "are", "often", "used", "."], "sentence-detokenized": "To exploit inter-frame correlation, methods such as dynamic Markov networks, convolutional neural networks and long short-term memory are often used.", "token2charspan": [[0, 2], [3, 10], [11, 16], [16, 17], [17, 22], [23, 34], [34, 35], [36, 43], [44, 48], [49, 51], [52, 59], [60, 66], [67, 75], [75, 76], [77, 90], [91, 97], [98, 106], [107, 110], [111, 115], [116, 121], [121, 122], [122, 126], [127, 133], [134, 137], [138, 143], [144, 148], [148, 149]]}
{"doc_key": "ai-dev-103", "ner": [[0, 0, "product"], [4, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Unimate", "was", "the", "first", "industrial", "robot", ","], "sentence-detokenized": "Unimate was the first industrial robot,", "token2charspan": [[0, 7], [8, 11], [12, 15], [16, 21], [22, 32], [33, 38], [38, 39]]}
{"doc_key": "ai-dev-104", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [0, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 0, 13, "win-defeat", "", false, false], [5, 6, 0, 13, "win-defeat", "", false, false], [8, 8, 0, 13, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Together", "with", "Geoffrey", "Hinton", "and", "Jan", "Lekun", ",", "Bengio", "won", "the", "2018", "Turing", "Prize", "."], "sentence-detokenized": "Together with Geoffrey Hinton and Jan Lekun, Bengio won the 2018 Turing Prize.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 29], [30, 33], [34, 37], [38, 43], [43, 44], [45, 51], [52, 55], [56, 59], [60, 64], [65, 71], [72, 77], [77, 78]]}
{"doc_key": "ai-dev-105", "ner": [[7, 7, "country"], [21, 24, "misc"], [26, 26, "country"], [30, 31, "organisation"], [35, 36, "person"], [39, 41, "person"], [48, 50, "misc"], [55, 55, "country"], [60, 60, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[21, 24, 7, 7, "physical", "filmed_in", false, false], [35, 36, 30, 31, "role", "host", false, false], [39, 41, 30, 31, "role", "reporter", false, false], [48, 50, 7, 7, "physical", "filmed_in", false, false], [48, 50, 55, 55, "physical", "distributed_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Additional", "series", "have", "been", "filmed", "on", "the", "UK", "set", "for", "specific", "sectors", "of", "the", "global", "market", ",", "including", "two", "series", "of", "Robot", "Wars", "Extreme", "Warriors", "with", "American", "competitors", "for", "the", "TNN", "network", "(", "hosted", "by", "Mick", "Foley", ",", "with", "Rebecca", "Grant", "as", "reporter", ")", ",", "two", "series", "of", "Dutch", "Robot", "Wars", "for", "distribution", "in", "the", "Netherlands", "and", "one", "series", "for", "Germany", "."], "sentence-detokenized": "Additional series have been filmed on the UK set for specific sectors of the global market, including two series of Robot Wars Extreme Warriors with American competitors for the TNN network (hosted by Mick Foley, with Rebecca Grant as reporter), two series of Dutch Robot Wars for distribution in the Netherlands and one series for Germany.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 27], [28, 34], [35, 37], [38, 41], [42, 44], [45, 48], [49, 52], [53, 61], [62, 69], [70, 72], [73, 76], [77, 83], [84, 90], [90, 91], [92, 101], [102, 105], [106, 112], [113, 115], [116, 121], [122, 126], [127, 134], [135, 143], [144, 148], [149, 157], [158, 169], [170, 173], [174, 177], [178, 181], [182, 189], [190, 191], [191, 197], [198, 200], [201, 205], [206, 211], [211, 212], [213, 217], [218, 225], [226, 231], [232, 234], [235, 243], [243, 244], [244, 245], [246, 249], [250, 256], [257, 259], [260, 265], [266, 271], [272, 276], [277, 280], [281, 293], [294, 296], [297, 300], [301, 312], [313, 316], [317, 320], [321, 327], [328, 331], [332, 339], [339, 340]]}
{"doc_key": "ai-dev-106", "ner": [[8, 8, "researcher"], [13, 13, "product"], [33, 34, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 13, 13, "role", "", false, false], [33, 34, 13, 13, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "many", "years", ",", "beginning", "in", "1986", ",", "Miller", "led", "the", "development", "of", "WordNet", ",", "a", "large", "electronic", "reference", "book", "that", "can", "be", "read", "on", "a", "computer", "and", "used", "in", "applications", "such", "as", "search", "engines", "."], "sentence-detokenized": "For many years, beginning in 1986, Miller led the development of WordNet, a large electronic reference book that can be read on a computer and used in applications such as search engines.", "token2charspan": [[0, 3], [4, 8], [9, 14], [14, 15], [16, 25], [26, 28], [29, 33], [33, 34], [35, 41], [42, 45], [46, 49], [50, 61], [62, 64], [65, 72], [72, 73], [74, 75], [76, 81], [82, 92], [93, 102], [103, 107], [108, 112], [113, 116], [117, 119], [120, 124], [125, 127], [128, 129], [130, 138], [139, 142], [143, 147], [148, 150], [151, 163], [164, 168], [169, 171], [172, 178], [179, 186], [186, 187]]}
{"doc_key": "ai-dev-107", "ner": [[3, 4, "algorithm"], [7, 12, "algorithm"], [19, 20, "researcher"], [23, 28, "organisation"], [31, 33, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 19, 20, "origin", "", false, false], [3, 4, 31, 33, "win-defeat", "", false, false], [7, 12, 19, 20, "origin", "", false, false], [7, 12, 31, 33, "win-defeat", "", false, false], [19, 20, 23, 28, "physical", "", false, false], [19, 20, 23, 28, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Since", "2009", ",", "recurrent", "neural", "networks", "and", "neural", "networks", "with", "deep", "feedforward", "connections", "developed", "in", "the", "research", "group", "of", "J\u00fcrgen", "Schmidhuber", "at", "the", "Swiss", "Artificial", "Intelligence", "Laboratory", "IDSIA", "have", "won", "several", "international", "handwriting", "competitions", "."], "sentence-detokenized": "Since 2009, recurrent neural networks and neural networks with deep feedforward connections developed in the research group of J\u00fcrgen Schmidhuber at the Swiss Artificial Intelligence Laboratory IDSIA have won several international handwriting competitions.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 21], [22, 28], [29, 37], [38, 41], [42, 48], [49, 57], [58, 62], [63, 67], [68, 79], [80, 91], [92, 101], [102, 104], [105, 108], [109, 117], [118, 123], [124, 126], [127, 133], [134, 145], [146, 148], [149, 152], [153, 158], [159, 169], [170, 182], [183, 193], [194, 199], [200, 204], [205, 208], [209, 216], [217, 230], [231, 242], [243, 255], [255, 256]]}
{"doc_key": "ai-dev-108", "ner": [[5, 6, "programlang"], [10, 10, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "software", "is", "implemented", "in", "C", "++", "and", "wrapped", "in", "Python", "."], "sentence-detokenized": "The software is implemented in C++ and wrapped in Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 30], [31, 32], [32, 34], [35, 38], [39, 46], [47, 49], [50, 56], [56, 57]]}
{"doc_key": "ai-dev-109", "ner": [[8, 9, "country"], [14, 15, "misc"], [23, 26, "misc"], [36, 38, "misc"], [39, 39, "misc"], [42, 42, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[23, 26, 8, 9, "temporal", "", false, false], [23, 26, 14, 15, "artifact", "", false, false], [23, 26, 42, 42, "physical", "", false, false], [39, 39, 36, 38, "named", "", false, false], [39, 39, 42, 42, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1857", ",", "at", "the", "request", "of", "the", "Tokugawa", "Shogunate", ",", "a", "group", "of", "Dutch", "engineers", "began", "work", "on", "the", "creation", "of", "the", "Nagasaki", "Yotetsusho", ",", "a", "modern", "western", "-", "style", "foundry", "and", "shipyard", "near", "the", "Dutch", "settlement", "of", "Dejima", ",", "in", "Nagasaki", "."], "sentence-detokenized": "In 1857, at the request of the Tokugawa Shogunate, a group of Dutch engineers began work on the creation of the Nagasaki Yotetsusho, a modern western-style foundry and shipyard near the Dutch settlement of Dejima, in Nagasaki.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 30], [31, 39], [40, 49], [49, 50], [51, 52], [53, 58], [59, 61], [62, 67], [68, 77], [78, 83], [84, 88], [89, 91], [92, 95], [96, 104], [105, 107], [108, 111], [112, 120], [121, 131], [131, 132], [133, 134], [135, 141], [142, 149], [149, 150], [150, 155], [156, 163], [164, 167], [168, 176], [177, 181], [182, 185], [186, 191], [192, 202], [203, 205], [206, 212], [212, 213], [214, 216], [217, 225], [225, 226]]}
{"doc_key": "ai-dev-110", "ner": [[11, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["We", "are", "being", "as", "precise", "as", "possible", "by", "measuring", "the", "root", "mean", "square", "error", "between", "mathy", "/", "math", "and", "math", "\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", "/", "math", ":", "we", "want", "math", "(", "y", "-\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", ")", "^", "2", "/", "math", "to", "be", "minimal", ",", "both", "for", "mathx", "_", "1", ",\\", "points", ",", "x", "_", "n", "/", "math", ",", "and", "for", "points", "outside", "our", "sample", "."], "sentence-detokenized": "We are being as precise as possible by measuring the root mean square error between mathy / math and math\\ hat {f} (x; D) / math: we want math (y -\\ hat {f} (x; D)) ^ 2 / math to be minimal, both for mathx _ 1,\\ points, x _ n / math, and for points outside our sample.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 23], [24, 26], [27, 35], [36, 38], [39, 48], [49, 52], [53, 57], [58, 62], [63, 69], [70, 75], [76, 83], [84, 89], [90, 91], [92, 96], [97, 100], [101, 105], [105, 106], [107, 110], [111, 112], [112, 113], [113, 114], [115, 116], [116, 117], [117, 118], [119, 120], [120, 121], [122, 123], [124, 128], [128, 129], [130, 132], [133, 137], [138, 142], [143, 144], [144, 145], [146, 148], [149, 152], [153, 154], [154, 155], [155, 156], [157, 158], [158, 159], [159, 160], [161, 162], [162, 163], [163, 164], [165, 166], [167, 168], [169, 170], [171, 175], [176, 178], [179, 181], [182, 189], [189, 190], [191, 195], [196, 199], [200, 205], [206, 207], [208, 209], [209, 211], [212, 218], [218, 219], [220, 221], [222, 223], [224, 225], [226, 227], [228, 232], [232, 233], [234, 237], [238, 241], [242, 248], [249, 256], [257, 260], [261, 267], [267, 268]]}
{"doc_key": "ai-dev-111", "ner": [[7, 10, "organisation"], [3, 23, "product"], [29, 30, "task"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[3, 23, 7, 10, "temporal", "", false, false], [3, 23, 29, 30, "related-to", "performs", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["He", "subsequently", "invited", "Weidner", "to", "attend", "the", "American", "Translators", "Association", "'s", "annual", "meeting", "in", "October", ",", "where", "the", "Weidner", "machine", "translation", "system", "was", "recognized", "as", "an", "anticipated", "breakthrough", "in", "machine", "translation", "."], "sentence-detokenized": "He subsequently invited Weidner to attend the American Translators Association's annual meeting in October, where the Weidner machine translation system was recognized as an anticipated breakthrough in machine translation.", "token2charspan": [[0, 2], [3, 15], [16, 23], [24, 31], [32, 34], [35, 41], [42, 45], [46, 54], [55, 66], [67, 78], [78, 80], [81, 87], [88, 95], [96, 98], [99, 106], [106, 107], [108, 113], [114, 117], [118, 125], [126, 133], [134, 145], [146, 152], [153, 156], [157, 167], [168, 170], [171, 173], [174, 185], [186, 198], [199, 201], [202, 209], [210, 221], [221, 222]]}
{"doc_key": "ai-dev-112", "ner": [[2, 10, "conference"], [3, 8, "conference"], [14, 14, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 8, 2, 10, "named", "", false, false], [3, 8, 2, 10, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["At", "the", "2018", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", "conference", ",", "researchers", "from", "Google", "presented", "the", "paper", "."], "sentence-detokenized": "At the 2018 Neural Information Processing Systems (NeurIPS) conference, researchers from Google presented the paper.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 30], [31, 41], [42, 49], [50, 51], [51, 58], [58, 59], [60, 70], [70, 71], [72, 83], [84, 88], [89, 95], [96, 105], [106, 109], [110, 115], [115, 116]]}
{"doc_key": "ai-dev-113", "ner": [[0, 4, "algorithm"], [10, 11, "algorithm"], [15, 19, "metrics"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 4, 10, 11, "usage", "", false, false], [10, 11, 15, 19, "related-to", "", true, false], [15, 19, 23, 25, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Baum", "-", "Welch", "algorithm", "uses", "the", "well", "-", "known", "EM", "algorithm", "to", "find", "the", "maximum", "likelihood", "estimate", "of", "the", "parameters", "of", "a", "hidden", "Markov", "model", "given", "a", "set", "of", "observed", "feature", "vectors", "."], "sentence-detokenized": "The Baum-Welch algorithm uses the well-known EM algorithm to find the maximum likelihood estimate of the parameters of a hidden Markov model given a set of observed feature vectors.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 14], [15, 24], [25, 29], [30, 33], [34, 38], [38, 39], [39, 44], [45, 47], [48, 57], [58, 60], [61, 65], [66, 69], [70, 77], [78, 88], [89, 97], [98, 100], [101, 104], [105, 115], [116, 118], [119, 120], [121, 127], [128, 134], [135, 140], [141, 146], [147, 148], [149, 152], [153, 155], [156, 164], [165, 172], [173, 180], [180, 181]]}
{"doc_key": "ai-dev-114", "ner": [[9, 9, "product"], [11, 11, "product"], [32, 33, "misc"], [38, 47, "product"], [50, 52, "programlang"], [53, 58, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 9, 11, 11, "compare", "", false, false], [32, 33, 11, 11, "part-of", "", false, false], [38, 47, 11, 11, "part-of", "", false, false], [53, 58, 11, 11, "part-of", "", false, false], [53, 58, 50, 52, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": [")", "In", "addition", "to", "the", "taxonomic", "information", "contained", "in", "OpenCyc", ",", "ResearchCyc", "includes", "considerably", "more", "semantic", "knowledge", "(", "i.e.", ",", "additional", "facts", "and", "empirical", "rules", ")", "related", "to", "the", "concepts", "in", "its", "knowledge", "base", ";", "it", "also", "includes", "an", "extensive", "lexicon", ",", "parsing", "and", "generation", "tools", "in", "English", ",", "and", "Java", "-", "based", "interfaces", "for", "knowledge", "editing", "and", "querying", "."], "sentence-detokenized": ") In addition to the taxonomic information contained in OpenCyc, ResearchCyc includes considerably more semantic knowledge (i.e., additional facts and empirical rules) related to the concepts in its knowledge base; it also includes an extensive lexicon, parsing and generation tools in English, and Java-based interfaces for knowledge editing and querying.", "token2charspan": [[0, 1], [2, 4], [5, 13], [14, 16], [17, 20], [21, 30], [31, 42], [43, 52], [53, 55], [56, 63], [63, 64], [65, 76], [77, 85], [86, 98], [99, 103], [104, 112], [113, 122], [123, 124], [124, 128], [128, 129], [130, 140], [141, 146], [147, 150], [151, 160], [161, 166], [166, 167], [168, 175], [176, 178], [179, 182], [183, 191], [192, 194], [195, 198], [199, 208], [209, 213], [213, 214], [215, 217], [218, 222], [223, 231], [232, 234], [235, 244], [245, 252], [252, 253], [254, 261], [262, 265], [266, 276], [277, 282], [283, 285], [286, 293], [293, 294], [295, 298], [299, 303], [303, 304], [304, 309], [310, 320], [321, 324], [325, 334], [335, 342], [343, 346], [347, 355], [355, 356]]}
{"doc_key": "ai-dev-115", "ner": [[0, 1, "algorithm"], [4, 5, "task"], [9, 10, "field"], [12, 13, "field"], [15, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 4, 5, "type-of", "", false, false], [4, 5, 9, 10, "part-of", "task_part_of_field", false, false], [4, 5, 12, 13, "part-of", "task_part_of_field", false, false], [4, 5, 15, 17, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Hough", "transform", "is", "a", "feature", "extraction", "method", "used", "in", "image", "analysis", ",", "computer", "vision", "and", "digital", "image", "processing", "."], "sentence-detokenized": "Hough transform is a feature extraction method used in image analysis, computer vision and digital image processing.", "token2charspan": [[0, 5], [6, 15], [16, 18], [19, 20], [21, 28], [29, 39], [40, 46], [47, 51], [52, 54], [55, 60], [61, 69], [69, 70], [71, 79], [80, 86], [87, 90], [91, 98], [99, 104], [105, 115], [115, 116]]}
{"doc_key": "ai-dev-116", "ner": [[4, 4, "product"], [6, 10, "product"], [16, 16, "organisation"], [18, 18, "product"], [20, 21, "researcher"], [28, 29, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 4, 6, 10, "named", "", false, false], [4, 4, 16, 16, "artifact", "", false, false], [4, 4, 18, 18, "origin", "developed_from", false, false], [18, 18, 20, 21, "artifact", "", false, false], [28, 29, 16, 16, "role", "supported", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1978", ",", "the", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", "robot", "was", "developed", "by", "Unimation", "with", "Vicarm", "(", "Victor", "Scheinman", ")", "and", "with", "the", "support", "of", "General", "Motors", "."], "sentence-detokenized": "In 1978, the PUMA (Programmable Universal Machine for Assembly) robot was developed by Unimation with Vicarm (Victor Scheinman) and with the support of General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 17], [18, 19], [19, 31], [32, 41], [42, 49], [50, 53], [54, 62], [62, 63], [64, 69], [70, 73], [74, 83], [84, 86], [87, 96], [97, 101], [102, 108], [109, 110], [110, 116], [117, 126], [126, 127], [128, 131], [132, 136], [137, 140], [141, 148], [149, 151], [152, 159], [160, 166], [166, 167]]}
{"doc_key": "ai-dev-117", "ner": [[0, 1, "algorithm"], [6, 7, "researcher"], [9, 10, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "origin", "", false, false], [0, 1, 9, 10, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["LSTM", "was", "proposed", "in", "1997", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "LSTM was proposed in 1997 by Sepp Hochreiter and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 20], [21, 25], [26, 28], [29, 33], [34, 44], [45, 48], [49, 55], [56, 67], [67, 68]]}
{"doc_key": "ai-dev-118", "ner": [[11, 12, "metrics"], [16, 19, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "outcomes", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "in", "a", "confusion", "matrix", "as", "shown", "below", ":"], "sentence-detokenized": "The four outcomes can be formulated in a 2 \u00d7 2 contingency table or in a confusion matrix as shown below:", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 24], [25, 35], [36, 38], [39, 40], [41, 42], [43, 44], [45, 46], [47, 58], [59, 64], [65, 67], [68, 70], [71, 72], [73, 82], [83, 89], [90, 92], [93, 98], [99, 104], [104, 105]]}
{"doc_key": "ai-dev-119", "ner": [[8, 10, "conference"], [11, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "also", "contributed", "significantly", "to", "the", "establishment", "of", "ELRA", "and", "the", "LREC", "conference", "."], "sentence-detokenized": "He also contributed significantly to the establishment of ELRA and the LREC conference.", "token2charspan": [[0, 2], [3, 7], [8, 19], [20, 33], [34, 36], [37, 40], [41, 54], [55, 57], [58, 62], [63, 66], [67, 70], [71, 75], [76, 86], [86, 87]]}
{"doc_key": "ai-dev-120", "ner": [[11, 11, "misc"], [15, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 18, 11, 11, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "popular", "application", "of", "serial", "robots", "in", "modern", "industry", "is", "an", "assembly", "robot", "called", "a", "SCARA", "robot", ",", "which", "has", "four", "degrees", "of", "freedom", "."], "sentence-detokenized": "A popular application of serial robots in modern industry is an assembly robot called a SCARA robot, which has four degrees of freedom.", "token2charspan": [[0, 1], [2, 9], [10, 21], [22, 24], [25, 31], [32, 38], [39, 41], [42, 48], [49, 57], [58, 60], [61, 63], [64, 72], [73, 78], [79, 85], [86, 87], [88, 93], [94, 99], [99, 100], [101, 106], [107, 110], [111, 115], [116, 123], [124, 126], [127, 134], [134, 135]]}
{"doc_key": "ai-dev-121", "ner": [[15, 23, "conference"], [25, 28, "conference"], [29, 34, "conference"], [41, 41, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[25, 28, 15, 23, "named", "", false, false], [41, 41, 29, 34, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "one", "of", "the", "founding", "members", "and", "former", "chair", "(", "2006-2008", ")", "of", "the", "Special", "Interest", "Group", "on", "the", "Web", "as", "a", "Corpus", "(", "SIGWAC", ")", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "and", "one", "of", "the", "founding", "organizers", "of", "SENSEVAL", "."], "sentence-detokenized": "He was one of the founding members and former chair (2006-2008) of the Special Interest Group on the Web as a Corpus (SIGWAC) of the Association for Computational Linguistics, and one of the founding organizers of SENSEVAL.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 13], [14, 17], [18, 26], [27, 34], [35, 38], [39, 45], [46, 51], [52, 53], [53, 62], [62, 63], [64, 66], [67, 70], [71, 78], [79, 87], [88, 93], [94, 96], [97, 100], [101, 104], [105, 107], [108, 109], [110, 116], [117, 118], [118, 124], [124, 125], [126, 128], [129, 132], [133, 144], [145, 148], [149, 162], [163, 174], [174, 175], [176, 179], [180, 183], [184, 186], [187, 190], [191, 199], [200, 210], [211, 213], [214, 222], [222, 223]]}
{"doc_key": "ai-dev-122", "ner": [[4, 4, "product"], [8, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 4, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "platform", ",", "LinguaStream", "provides", "an", "advanced", "Java", "API", "."], "sentence-detokenized": "As a platform, LinguaStream provides an advanced Java API.", "token2charspan": [[0, 2], [3, 4], [5, 13], [13, 14], [15, 27], [28, 36], [37, 39], [40, 48], [49, 53], [54, 57], [57, 58]]}
{"doc_key": "ai-dev-123", "ner": [[13, 13, "programlang"], [15, 17, "misc"], [20, 22, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 13, 20, 22, "type-of", "", false, false], [15, 17, 20, 22, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "robot", "kit", "is", "based", "on", "the", "Android", "platform", "and", "is", "programmed", "using", "Java", ",", "Blocks", "programming", "interface", "or", "other", "Android", "programming", "systems", "."], "sentence-detokenized": "The robot kit is based on the Android platform and is programmed using Java, Blocks programming interface or other Android programming systems.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 16], [17, 22], [23, 25], [26, 29], [30, 37], [38, 46], [47, 50], [51, 53], [54, 64], [65, 70], [71, 75], [75, 76], [77, 83], [84, 95], [96, 105], [106, 108], [109, 114], [115, 122], [123, 134], [135, 142], [142, 143]]}
{"doc_key": "ai-dev-124", "ner": [[9, 17, "algorithm"], [13, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "way", "a", "linked", "list", "is", "defined", "determines", "whether", "depth", "-", "first", "or", "breadth", "-", "first", "search", "is", "used", "."], "sentence-detokenized": "The way a linked list is defined determines whether depth-first or breadth-first search is used.", "token2charspan": [[0, 3], [4, 7], [8, 9], [10, 16], [17, 21], [22, 24], [25, 32], [33, 43], [44, 51], [52, 57], [57, 58], [58, 63], [64, 66], [67, 74], [74, 75], [75, 80], [81, 87], [88, 90], [91, 95], [95, 96]]}
{"doc_key": "ai-dev-125", "ner": [[19, 20, "task"], [24, 27, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "areas", "can", "signal", "the", "presence", "of", "objects", "or", "parts", "of", "objects", "in", "the", "image", "area", "with", "applications", "for", "object", "recognition", "and", "/", "or", "video", "tracking", "of", "objects", "."], "sentence-detokenized": "These areas can signal the presence of objects or parts of objects in the image area with applications for object recognition and/or video tracking of objects.", "token2charspan": [[0, 5], [6, 11], [12, 15], [16, 22], [23, 26], [27, 35], [36, 38], [39, 46], [47, 49], [50, 55], [56, 58], [59, 66], [67, 69], [70, 73], [74, 79], [80, 84], [85, 89], [90, 102], [103, 106], [107, 113], [114, 125], [126, 129], [129, 130], [130, 132], [133, 138], [139, 147], [148, 150], [151, 158], [158, 159]]}
{"doc_key": "ai-dev-126", "ner": [[4, 5, "algorithm"], [7, 9, "product"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 4, 5, "type-of", "", false, false], [7, 9, 14, 15, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "a", "semantic", "network", "is", "WordNet", "-", "a", "lexical", "database", "of", "the", "English", "language", "."], "sentence-detokenized": "An example of a semantic network is WordNet - a lexical database of the English language.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 24], [25, 32], [33, 35], [36, 43], [44, 45], [46, 47], [48, 55], [56, 64], [65, 67], [68, 71], [72, 79], [80, 88], [88, 89]]}
{"doc_key": "ai-dev-127", "ner": [[0, 3, "task"], [7, 8, "field"], [10, 11, "field"], [20, 24, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 7, 8, "part-of", "", false, false], [0, 3, 10, 11, "named", "same", false, false], [0, 3, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Speech", "recognition", "is", "an", "interdisciplinary", "subfield", "of", "computer", "science", "and", "computational", "linguistics", "that", "develops", "methodologies", "and", "technologies", "that", "allow", "to", "recognize", "and", "translate", "spoken", "language", "into", "text", "using", "a", "computer", "."], "sentence-detokenized": "Speech recognition is an interdisciplinary subfield of computer science and computational linguistics that develops methodologies and technologies that allow to recognize and translate spoken language into text using a computer.", "token2charspan": [[0, 6], [7, 18], [19, 21], [22, 24], [25, 42], [43, 51], [52, 54], [55, 63], [64, 71], [72, 75], [76, 89], [90, 101], [102, 106], [107, 115], [116, 129], [130, 133], [134, 146], [147, 151], [152, 157], [158, 160], [161, 170], [171, 174], [175, 184], [185, 191], [192, 200], [201, 205], [206, 210], [211, 216], [217, 218], [219, 227], [227, 228]]}
{"doc_key": "ai-dev-128", "ner": [[0, 2, "field"], [6, 7, "misc"], [12, 14, "field"], [16, 16, "task"], [18, 19, "task"], [38, 38, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 38, 38, "named", "same", false, false], [12, 14, 0, 2, "part-of", "subfield", false, false], [16, 16, 0, 2, "part-of", "", false, false], [16, 16, 12, 14, "part-of", "", false, false], [18, 19, 12, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Artificial", "intelligence", "attracts", "most", "attention", "to", "applied", "ontology", "in", "subfields", "such", "as", "natural", "language", "processing", "in", "machines", "and", "knowledge", "representation", ",", "but", "ontology", "editors", "are", "often", "used", "in", "fields", "such", "as", "education", "without", "the", "intention", "of", "contributing", "to", "AI", "."], "sentence-detokenized": "Artificial intelligence attracts most attention to applied ontology in subfields such as natural language processing in machines and knowledge representation, but ontology editors are often used in fields such as education without the intention of contributing to AI.", "token2charspan": [[0, 10], [11, 23], [24, 32], [33, 37], [38, 47], [48, 50], [51, 58], [59, 67], [68, 70], [71, 80], [81, 85], [86, 88], [89, 96], [97, 105], [106, 116], [117, 119], [120, 128], [129, 132], [133, 142], [143, 157], [157, 158], [159, 162], [163, 171], [172, 179], [180, 183], [184, 189], [190, 194], [195, 197], [198, 204], [205, 209], [210, 212], [213, 222], [223, 230], [231, 234], [235, 244], [245, 247], [248, 260], [261, 263], [264, 266], [266, 267]]}
{"doc_key": "ai-dev-129", "ner": [[9, 11, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 13, 14, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["This", "update", "rule", "is", "actually", "an", "update", "of", "the", "stochastic", "gradient", "descent", "for", "linear", "regression", "."], "sentence-detokenized": "This update rule is actually an update of the stochastic gradient descent for linear regression.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 19], [20, 28], [29, 31], [32, 38], [39, 41], [42, 45], [46, 56], [57, 65], [66, 73], [74, 77], [78, 84], [85, 95], [95, 96]]}
{"doc_key": "ai-dev-130", "ner": [[5, 10, "organisation"], [13, 16, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "was", "elected", "to", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "and", "the", "National", "Academy", "of", "Sciences", "and", "received", "a", "number", "of", "awards", ":"], "sentence-detokenized": "He was elected to the American Academy of Arts and Sciences and the National Academy of Sciences and received a number of awards:", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 21], [22, 30], [31, 38], [39, 41], [42, 46], [47, 50], [51, 59], [60, 63], [64, 67], [68, 76], [77, 84], [85, 87], [88, 96], [97, 100], [101, 109], [110, 111], [112, 118], [119, 121], [122, 128], [128, 129]]}
{"doc_key": "ai-dev-131", "ner": [[7, 7, "organisation"], [13, 14, "person"], [16, 20, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 13, 14, "related-to", "written_about_by", false, false], [7, 7, 16, 20, "related-to", "written_about_by", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "recent", "school", "of", "thought", "on", "Honda", "strategy", "was", "put", "forward", "by", "Gary", "Hamel", "and", "K", ".", "K", ".", "Prahalad", "in", "1989", "."], "sentence-detokenized": "The most recent school of thought on Honda strategy was put forward by Gary Hamel and K. K. Prahalad in 1989.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 22], [23, 25], [26, 33], [34, 36], [37, 42], [43, 51], [52, 55], [56, 59], [60, 67], [68, 70], [71, 75], [76, 81], [82, 85], [86, 87], [87, 88], [89, 90], [90, 91], [92, 100], [101, 103], [104, 108], [108, 109]]}
{"doc_key": "ai-dev-132", "ner": [[1, 1, "metrics"], [5, 6, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 5, 6, "related-to", "calculates", true, false], [1, 1, 18, 18, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["While", "BLEU", "simply", "calculates", "the", "accuracy", "of", "n", "-", "grams", "by", "giving", "each", "of", "them", "equal", "weight", ",", "NIST", "also", "calculates", "how", "informative", "a", "particular", "n-", "gram", "is", "."], "sentence-detokenized": "While BLEU simply calculates the accuracy of n-grams by giving each of them equal weight, NIST also calculates how informative a particular n-gram is.", "token2charspan": [[0, 5], [6, 10], [11, 17], [18, 28], [29, 32], [33, 41], [42, 44], [45, 46], [46, 47], [47, 52], [53, 55], [56, 62], [63, 67], [68, 70], [71, 75], [76, 81], [82, 88], [88, 89], [90, 94], [95, 99], [100, 110], [111, 114], [115, 126], [127, 128], [129, 139], [140, 142], [142, 146], [147, 149], [149, 150]]}
{"doc_key": "ai-dev-133", "ner": [[4, 6, "misc"], [10, 13, "conference"], [15, 15, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 10, 13, "temporal", "", false, false], [15, 15, 10, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "awarded", "the", "2019", "Lifetime", "Achievement", "Award", "from", "the", "Association", "for", "Computational", "Linguistics", "(", "ACL", ")", "."], "sentence-detokenized": "He was awarded the 2019 Lifetime Achievement Award from the Association for Computational Linguistics (ACL).", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 18], [19, 23], [24, 32], [33, 44], [45, 50], [51, 55], [56, 59], [60, 71], [72, 75], [76, 89], [90, 101], [102, 103], [103, 106], [106, 107], [107, 108]]}
{"doc_key": "ai-dev-134", "ner": [[0, 0, "researcher"], [6, 11, "organisation"], [13, 13, "organisation"], [20, 24, "conference"], [26, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 11, "role", "", false, false], [0, 0, 20, 24, "role", "", false, false], [13, 13, 6, 11, "named", "", false, false], [26, 26, 20, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sikara", "is", "a", "Fellow", "of", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", "and", "a", "member", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Sikara is a Fellow of the Institute of Electrical and Electronics Engineers (IEEE) and a member of the American Association for Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 18], [19, 21], [22, 25], [26, 35], [36, 38], [39, 49], [50, 53], [54, 65], [66, 75], [76, 77], [77, 81], [81, 82], [83, 86], [87, 88], [89, 95], [96, 98], [99, 102], [103, 111], [112, 123], [124, 127], [128, 138], [139, 151], [152, 153], [153, 157], [157, 158], [158, 159]]}
{"doc_key": "ai-dev-135", "ner": [[9, 12, "misc"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "MATLAB", "code", "below", "demonstrates", "a", "concrete", "solution", "to", "the", "nonlinear", "system", "of", "equations", "given", "in", "the", "previous", "section", ":", "See", "also"], "sentence-detokenized": "The MATLAB code below demonstrates a concrete solution to the nonlinear system of equations given in the previous section: See also", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 21], [22, 34], [35, 36], [37, 45], [46, 54], [55, 57], [58, 61], [62, 71], [72, 78], [79, 81], [82, 91], [92, 97], [98, 100], [101, 104], [105, 113], [114, 121], [121, 122], [123, 126], [127, 131]]}
{"doc_key": "ai-dev-136", "ner": [[0, 4, "product"], [14, 14, "field"], [37, 37, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 14, 14, "related-to", "trained_by", true, false], [0, 4, 37, 37, "related-to", "trained_by", true, false], [14, 14, 37, 37, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Pattern", "recognition", "systems", "are", "in", "many", "cases", "trained", "on", "labeled", "training", "data", "(", "supervised", "learning", ")", ",", "but", "in", "the", "absence", "of", "labeled", "data", ",", "other", "algorithms", "can", "be", "used", "to", "detect", "previously", "unknown", "patterns", "(", "unsupervised", "learning", ")", "."], "sentence-detokenized": "Pattern recognition systems are in many cases trained on labeled training data (supervised learning), but in the absence of labeled data, other algorithms can be used to detect previously unknown patterns (unsupervised learning).", "token2charspan": [[0, 7], [8, 19], [20, 27], [28, 31], [32, 34], [35, 39], [40, 45], [46, 53], [54, 56], [57, 64], [65, 73], [74, 78], [79, 80], [80, 90], [91, 99], [99, 100], [100, 101], [102, 105], [106, 108], [109, 112], [113, 120], [121, 123], [124, 131], [132, 136], [136, 137], [138, 143], [144, 154], [155, 158], [159, 161], [162, 166], [167, 169], [170, 176], [177, 187], [188, 195], [196, 204], [205, 206], [206, 218], [219, 227], [227, 228], [228, 229]]}
{"doc_key": "ai-dev-137", "ner": [[5, 6, "researcher"], [9, 10, "country"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 9, 10, "physical", "", false, false], [5, 6, 22, 23, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "was", "first", "applied", "by", "Lawrence", "Vogel", "in", "the", "USA", "in", "1960", "to", "use", "simulated", "evolution", "as", "a", "learning", "process", "to", "create", "artificial", "intelligence", "."], "sentence-detokenized": "It was first applied by Lawrence Vogel in the USA in 1960 to use simulated evolution as a learning process to create artificial intelligence.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 20], [21, 23], [24, 32], [33, 38], [39, 41], [42, 45], [46, 49], [50, 52], [53, 57], [58, 60], [61, 64], [65, 74], [75, 84], [85, 87], [88, 89], [90, 98], [99, 106], [107, 109], [110, 116], [117, 127], [128, 140], [140, 141]]}
{"doc_key": "ai-dev-138", "ner": [[0, 1, "field"], [10, 11, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[0, 1, 10, 11, "part-of", "", false, false], [18, 19, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 2], "sentence": ["Reinforcement", "learning", "is", "one", "of", "the", "three", "main", "paradigms", "of", "machine", "learning", ",", "along", "with", "supervised", "learning", "and", "unsupervised", "learning", "."], "sentence-detokenized": "Reinforcement learning is one of the three main paradigms of machine learning, along with supervised learning and unsupervised learning.", "token2charspan": [[0, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 42], [43, 47], [48, 57], [58, 60], [61, 68], [69, 77], [77, 78], [79, 84], [85, 89], [90, 100], [101, 109], [110, 113], [114, 126], [127, 135], [135, 136]]}
{"doc_key": "ai-dev-139", "ner": [[4, 5, "field"], [12, 12, "programlang"], [28, 29, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 28, 29, "usage", "applies", false, false], [12, 12, 28, 29, "usage", "applies", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "such", "cases", ",", "cloud", "computing", "and", "the", "open", "source", "programming", "language", "R", "can", "help", "small", "banks", "implement", "risk", "analytics", "and", "support", "branch", "-", "level", "monitoring", "by", "applying", "predictive", "analytics", "."], "sentence-detokenized": "In such cases, cloud computing and the open source programming language R can help small banks implement risk analytics and support branch-level monitoring by applying predictive analytics.", "token2charspan": [[0, 2], [3, 7], [8, 13], [13, 14], [15, 20], [21, 30], [31, 34], [35, 38], [39, 43], [44, 50], [51, 62], [63, 71], [72, 73], [74, 77], [78, 82], [83, 88], [89, 94], [95, 104], [105, 109], [110, 119], [120, 123], [124, 131], [132, 138], [138, 139], [139, 144], [145, 155], [156, 158], [159, 167], [168, 178], [179, 188], [188, 189]]}
{"doc_key": "ai-dev-140", "ner": [[11, 12, "researcher"], [16, 16, "algorithm"], [20, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 20, 21, "named", "same", false, false], [16, 16, 11, 12, "origin", "proves_function", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["One", "of", "the", "first", "versions", "of", "the", "theorem", "was", "proved", "by", "George", "Cybenko", "in", "1989", "for", "sigmoidal", "activation", "functions", ".", "Cybenko", "G.", "(", "1989", ")", ",", "2", "(", "4", ")", ",", "303-314", "."], "sentence-detokenized": "One of the first versions of the theorem was proved by George Cybenko in 1989 for sigmoidal activation functions. Cybenko G. (1989), 2 (4), 303-314.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [17, 25], [26, 28], [29, 32], [33, 40], [41, 44], [45, 51], [52, 54], [55, 61], [62, 69], [70, 72], [73, 77], [78, 81], [82, 91], [92, 102], [103, 112], [112, 113], [114, 121], [122, 124], [125, 126], [126, 130], [130, 131], [131, 132], [133, 134], [135, 136], [136, 137], [137, 138], [138, 139], [140, 147], [147, 148]]}
{"doc_key": "ai-dev-141", "ner": [[8, 8, "algorithm"], [11, 12, "metrics"], [18, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 8, 8, "part-of", "", false, false], [18, 21, 11, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "this", "process", ",", "which", "is", "known", "as", "cross-validation", ",", "the", "MSE", "is", "often", "referred", "to", "as", "the", "mean", "squared", "forecast", "error", ",", "and", "is", "calculated", "as"], "sentence-detokenized": "In this process, which is known as cross-validation, the MSE is often referred to as the mean squared forecast error, and is calculated as", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 22], [23, 25], [26, 31], [32, 34], [35, 51], [51, 52], [53, 56], [57, 60], [61, 63], [64, 69], [70, 78], [79, 81], [82, 84], [85, 88], [89, 93], [94, 101], [102, 110], [111, 116], [116, 117], [118, 121], [122, 124], [125, 135], [136, 138]]}
{"doc_key": "ai-dev-142", "ner": [[0, 0, "task"], [4, 6, "task"], [8, 8, "task"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 6, "compare", "", false, false], [4, 6, 18, 19, "part-of", "", false, false], [8, 8, 4, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OMR", "usually", "differs", "from", "optical", "character", "recognition", "(", "OCR", ")", "in", "that", "it", "does", "not", "require", "a", "complex", "pattern", "recognition", "mechanism", "."], "sentence-detokenized": "OMR usually differs from optical character recognition (OCR) in that it does not require a complex pattern recognition mechanism.", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 24], [25, 32], [33, 42], [43, 54], [55, 56], [56, 59], [59, 60], [61, 63], [64, 68], [69, 71], [72, 76], [77, 80], [81, 88], [89, 90], [91, 98], [99, 106], [107, 118], [119, 128], [128, 129]]}
{"doc_key": "ai-dev-143", "ner": [[10, 10, "location"], [12, 12, "location"], [14, 14, "location"], [18, 19, "location"], [21, 22, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 12, 14, 14, "physical", "", false, false], [18, 19, 12, 12, "physical", "", false, false], [21, 22, 12, 12, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2018", "and", "2019", ",", "the", "Championship", "was", "held", "in", "Houston", "and", "Detroit", ",", "Michigan", ",", "at", "the", "TCF", "Center", "and", "Ford", "Field", "stadiums", "."], "sentence-detokenized": "In 2018 and 2019, the Championship was held in Houston and Detroit, Michigan, at the TCF Center and Ford Field stadiums.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 16], [16, 17], [18, 21], [22, 34], [35, 38], [39, 43], [44, 46], [47, 54], [55, 58], [59, 66], [66, 67], [68, 76], [76, 77], [78, 80], [81, 84], [85, 88], [89, 95], [96, 99], [100, 104], [105, 110], [111, 119], [119, 120]]}
{"doc_key": "ai-dev-144", "ner": [[0, 0, "task"], [9, 10, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 0, "part-of", "", false, false], [12, 13, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "considered", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multiclass", "classification", "."], "sentence-detokenized": "Classification can be considered as two separate problems - binary classification and multiclass classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 32], [33, 35], [36, 39], [40, 48], [49, 57], [58, 59], [60, 66], [67, 81], [82, 85], [86, 96], [97, 111], [111, 112]]}
{"doc_key": "ai-dev-145", "ner": [[4, 5, "product"], [8, 9, "product"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 4, 5, "type-of", "", false, false], [12, 13, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "examples", "of", "popular", "parallel", "robots", "are", "the", "Stewart", "platform", "and", "the", "Delta", "robot", "."], "sentence-detokenized": "Two examples of popular parallel robots are the Stewart platform and the Delta robot.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 23], [24, 32], [33, 39], [40, 43], [44, 47], [48, 55], [56, 64], [65, 68], [69, 72], [73, 78], [79, 84], [84, 85]]}
{"doc_key": "ai-dev-146", "ner": [[4, 6, "algorithm"], [21, 21, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 21, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "However", ",", "the", "ReLU", "activation", "function", ",", "undifferentiable", "at", "0", ",", "has", "become", "quite", "popular", ",", "for", "example", ",", "in", "AlexNet", ")"], "sentence-detokenized": "(However, the ReLU activation function, undifferentiable at 0, has become quite popular, for example, in AlexNet)", "token2charspan": [[0, 1], [1, 8], [8, 9], [10, 13], [14, 18], [19, 29], [30, 38], [38, 39], [40, 56], [57, 59], [60, 61], [61, 62], [63, 66], [67, 73], [74, 79], [80, 87], [87, 88], [89, 92], [93, 100], [100, 101], [102, 104], [105, 112], [112, 113]]}
{"doc_key": "ai-dev-147", "ner": [[0, 3, "metrics"], [10, 11, "task"], [17, 17, "task"], [19, 20, "task"], [22, 23, "task"], [26, 28, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 3, 26, 28, "named", "", true, false], [10, 11, 0, 3, "usage", "", true, false], [17, 17, 10, 11, "part-of", "", false, false], [19, 20, 10, 11, "part-of", "", false, false], [22, 23, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["F", "-", "score", "is", "often", "used", "in", "the", "field", "of", "information", "retrieval", "to", "measure", "the", "effectiveness", "of", "search", ",", "document", "classification", "and", "query", "classification", ",", "so", "F_beta", "has", "a", "wide", "application", "."], "sentence-detokenized": "F-score is often used in the field of information retrieval to measure the effectiveness of search, document classification and query classification, so F_beta has a wide application.", "token2charspan": [[0, 1], [1, 2], [2, 7], [8, 10], [11, 16], [17, 21], [22, 24], [25, 28], [29, 34], [35, 37], [38, 49], [50, 59], [60, 62], [63, 70], [71, 74], [75, 88], [89, 91], [92, 98], [98, 99], [100, 108], [109, 123], [124, 127], [128, 133], [134, 148], [148, 149], [150, 152], [153, 159], [160, 163], [164, 165], [166, 170], [171, 182], [182, 183]]}
{"doc_key": "ai-dev-148", "ner": [[18, 19, "algorithm"], [21, 21, "algorithm"], [25, 25, "algorithm"], [27, 27, "algorithm"], [30, 32, "algorithm"], [34, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[21, 21, 18, 19, "named", "", false, false], [27, 27, 25, 25, "named", "", false, false], [34, 34, 30, 32, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "is", "done", "by", "modeling", "the", "received", "signal", "and", "then", "using", "a", "statistical", "evaluation", "method", ",", "such", "as", "maximum", "likelihood", "(", "ML", ")", ",", "majority", "voting", "(", "MV", ")", "or", "maximum", "a", "posteriori", "(", "MAP", ")", ",", "to", "decide", "which", "target", "in", "the", "library", "best", "fits", "the", "model", "built", "using", "the", "received", "signal", "."], "sentence-detokenized": "This is done by modeling the received signal and then using a statistical evaluation method, such as maximum likelihood (ML), majority voting (MV) or maximum a posteriori (MAP), to decide which target in the library best fits the model built using the received signal.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 15], [16, 24], [25, 28], [29, 37], [38, 44], [45, 48], [49, 53], [54, 59], [60, 61], [62, 73], [74, 84], [85, 91], [91, 92], [93, 97], [98, 100], [101, 108], [109, 119], [120, 121], [121, 123], [123, 124], [124, 125], [126, 134], [135, 141], [142, 143], [143, 145], [145, 146], [147, 149], [150, 157], [158, 159], [160, 170], [171, 172], [172, 175], [175, 176], [176, 177], [178, 180], [181, 187], [188, 193], [194, 200], [201, 203], [204, 207], [208, 215], [216, 220], [221, 225], [226, 229], [230, 235], [236, 241], [242, 247], [248, 251], [252, 260], [261, 267], [267, 268]]}
{"doc_key": "ai-dev-149", "ner": [[3, 3, "researcher"], [6, 8, "misc"], [11, 11, "field"], [14, 17, "university"], [23, 24, "misc"], [25, 26, "field"], [29, 30, "university"], [40, 41, "field"], [44, 47, "university"], [54, 62, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10], "relations": [[3, 3, 14, 17, "physical", "", false, false], [3, 3, 14, 17, "role", "", false, false], [3, 3, 29, 30, "physical", "", false, false], [3, 3, 29, 30, "role", "", false, false], [3, 3, 44, 47, "physical", "", false, false], [3, 3, 44, 47, "role", "", false, false], [6, 8, 3, 3, "origin", "", false, false], [6, 8, 11, 11, "topic", "", false, false], [23, 24, 3, 3, "origin", "", false, false], [23, 24, 25, 26, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["In", "1962", ",", "Sova", "received", "a", "Bachelor", "of", "Science", "degree", "in", "mathematics", "from", "the", "Massachusetts", "Institute", "of", "Technology", ",", "in", "1966", "-", "a", "Master", "of", "Applied", "Science", "degree", "from", "Harvard", "University", ",", "and", "in", "1999", "-", "a", "PhD", "degree", "in", "computer", "science", "from", "the", "Free", "University", "of", "Brussels", ",", "defending", "his", "dissertation", "on", "\"", "Knowledge", "Representation", ":", "Logical", ",", "Philosophical", "and", "Computational", "Foundations", "."], "sentence-detokenized": "In 1962, Sova received a Bachelor of Science degree in mathematics from the Massachusetts Institute of Technology, in 1966 - a Master of Applied Science degree from Harvard University, and in 1999 - a PhD degree in computer science from the Free University of Brussels, defending his dissertation on \"Knowledge Representation: Logical, Philosophical and Computational Foundations.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 13], [14, 22], [23, 24], [25, 33], [34, 36], [37, 44], [45, 51], [52, 54], [55, 66], [67, 71], [72, 75], [76, 89], [90, 99], [100, 102], [103, 113], [113, 114], [115, 117], [118, 122], [123, 124], [125, 126], [127, 133], [134, 136], [137, 144], [145, 152], [153, 159], [160, 164], [165, 172], [173, 183], [183, 184], [185, 188], [189, 191], [192, 196], [197, 198], [199, 200], [201, 204], [205, 211], [212, 214], [215, 223], [224, 231], [232, 236], [237, 240], [241, 245], [246, 256], [257, 259], [260, 268], [268, 269], [270, 279], [280, 283], [284, 296], [297, 299], [300, 301], [301, 310], [311, 325], [325, 326], [327, 334], [334, 335], [336, 349], [350, 353], [354, 367], [368, 379], [379, 380]]}
{"doc_key": "ai-dev-150", "ner": [[1, 2, "task"], [8, 8, "task"], [17, 17, "metrics"], [19, 20, "metrics"], [22, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 8, 8, "general-affiliation", "", false, false], [17, 17, 1, 2, "part-of", "", true, false], [19, 20, 1, 2, "part-of", "", true, false], [22, 24, 1, 2, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "paraphrase", "recognition", "can", "be", "considered", "as", "a", "classification", "problem", ",", "most", "standard", "evaluation", "metrics", "such", "as", "precision", ",", "f1", "score", "or", "ROC", "curve", "give", "relatively", "good", "results", "."], "sentence-detokenized": "Since paraphrase recognition can be considered as a classification problem, most standard evaluation metrics such as precision, f1 score or ROC curve give relatively good results.", "token2charspan": [[0, 5], [6, 16], [17, 28], [29, 32], [33, 35], [36, 46], [47, 49], [50, 51], [52, 66], [67, 74], [74, 75], [76, 80], [81, 89], [90, 100], [101, 108], [109, 113], [114, 116], [117, 126], [126, 127], [128, 130], [131, 136], [137, 139], [140, 143], [144, 149], [150, 154], [155, 165], [166, 170], [171, 178], [178, 179]]}
{"doc_key": "ai-dev-151", "ner": [[17, 17, "algorithm"], [26, 26, "algorithm"], [27, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 17, 26, 26, "opposite", "not_suited_for", false, false], [17, 17, 27, 30, "opposite", "not_suited_for", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "makes", "it", "practical", "for", "analyzing", "large", "datasets", "(", "hundreds", "or", "thousands", "of", "taxa", ")", "and", "for", "bootstrapping", ",", "for", "which", "other", "analysis", "tools", "(", "e.g.", "maximum", "parsimony", ",", "maximum", "likelihood", ")", "may", "be", "too", "expensive", "to", "compute", "."], "sentence-detokenized": "This makes it practical for analyzing large datasets (hundreds or thousands of taxa) and for bootstrapping, for which other analysis tools (e.g. maximum parsimony, maximum likelihood) may be too expensive to compute.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 23], [24, 27], [28, 37], [38, 43], [44, 52], [53, 54], [54, 62], [63, 65], [66, 75], [76, 78], [79, 83], [83, 84], [85, 88], [89, 92], [93, 106], [106, 107], [108, 111], [112, 117], [118, 123], [124, 132], [133, 138], [139, 140], [140, 144], [145, 152], [153, 162], [162, 163], [164, 171], [172, 182], [182, 183], [184, 187], [188, 190], [191, 194], [195, 204], [205, 207], [208, 215], [215, 216]]}
{"doc_key": "ai-dev-152", "ner": [[7, 12, "programlang"], [13, 16, "organisation"], [18, 18, "organisation"], [25, 25, "programlang"], [28, 39, "organisation"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[18, 18, 13, 16, "named", "", false, false], [28, 39, 7, 12, "role", "submits", true, false], [28, 39, 13, 16, "role", "submits_to", true, false]], "relations_mapping_to_source": [1, 3, 4], "sentence": ["In", "2002", ",", "the", "submission", "of", "the", "DAML", "+", "OIL", "language", "to", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", "was", "a", "work", "done", "by", "DAML", "contractors", "and", "an", "ad", "hoc", "European", "Union", "/", "US", "Joint", "Committee", "on", "Markup", "Languages", "."], "sentence-detokenized": "In 2002, the submission of the DAML+OIL language to the World Wide Web Consortium (W3C) was a work done by DAML contractors and an ad hoc European Union/US Joint Committee on Markup Languages.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 23], [24, 26], [27, 30], [31, 35], [35, 36], [36, 39], [40, 48], [49, 51], [52, 55], [56, 61], [62, 66], [67, 70], [71, 81], [82, 83], [83, 86], [86, 87], [88, 91], [92, 93], [94, 98], [99, 103], [104, 106], [107, 111], [112, 123], [124, 127], [128, 130], [131, 133], [134, 137], [138, 146], [147, 152], [152, 153], [153, 155], [156, 161], [162, 171], [172, 174], [175, 181], [182, 191], [191, 192]]}
{"doc_key": "ai-dev-153", "ner": [[3, 4, "misc"], [9, 13, "misc"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 13, 3, 4, "part-of", "", true, false], [14, 15, 3, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "nonlinear", "normalization", "is", "the", "case", "when", "normalization", "is", "performed", "by", "a", "sigmoid", "function", ",", "in", "which", "case", "the", "normalized", "image", "is", "calculated", "by", "the", "formula"], "sentence-detokenized": "An example of nonlinear normalization is the case when normalization is performed by a sigmoid function, in which case the normalized image is calculated by the formula", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 23], [24, 37], [38, 40], [41, 44], [45, 49], [50, 54], [55, 68], [69, 71], [72, 81], [82, 84], [85, 86], [87, 94], [95, 103], [103, 104], [105, 107], [108, 113], [114, 118], [119, 122], [123, 133], [134, 139], [140, 142], [143, 153], [154, 156], [157, 160], [161, 168]]}
{"doc_key": "ai-dev-154", "ner": [[9, 10, "metrics"], [14, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 10, 14, 14, "related-to", "used_together", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "noted", "that", "to", "overcome", "this", "problem", ",", "accuracy", "is", "usually", "combined", "with", "memory"], "sentence-detokenized": "It was noted that to overcome this problem, accuracy is usually combined with memory", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 17], [18, 20], [21, 29], [30, 34], [35, 42], [42, 43], [44, 52], [53, 55], [56, 63], [64, 72], [73, 77], [78, 84]]}
{"doc_key": "ai-dev-155", "ner": [[7, 9, "metrics"], [6, 14, "metrics"], [24, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[24, 25, 6, 14, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "most", "commonly", "used", "metrics", "are", "root", "mean", "square", "error", "and", "root", "mean", "square", "error", ",", "the", "latter", "of", "which", "was", "used", "in", "the", "Netflix", "award", "."], "sentence-detokenized": "The most commonly used metrics are root mean square error and root mean square error, the latter of which was used in the Netflix award.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 30], [31, 34], [35, 39], [40, 44], [45, 51], [52, 57], [58, 61], [62, 66], [67, 71], [72, 78], [79, 84], [84, 85], [86, 89], [90, 96], [97, 99], [100, 105], [106, 109], [110, 114], [115, 117], [118, 121], [122, 129], [130, 135], [135, 136]]}
{"doc_key": "ai-dev-156", "ner": [[10, 13, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "August", "2016", ",", "a", "research", "program", "was", "announced", "with", "University", "College", "Hospital", "to", "develop", "an", "algorithm", "that", "can", "automatically", "differentiate", "between", "healthy", "and", "cancerous", "tissues", "in", "the", "head", "and", "neck", "region", "."], "sentence-detokenized": "In August 2016, a research program was announced with University College Hospital to develop an algorithm that can automatically differentiate between healthy and cancerous tissues in the head and neck region.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 17], [18, 26], [27, 34], [35, 38], [39, 48], [49, 53], [54, 64], [65, 72], [73, 81], [82, 84], [85, 92], [93, 95], [96, 105], [106, 110], [111, 114], [115, 128], [129, 142], [143, 150], [151, 158], [159, 162], [163, 172], [173, 180], [181, 183], [184, 187], [188, 192], [193, 196], [197, 201], [202, 208], [208, 209]]}
{"doc_key": "ai-dev-157", "ner": [[3, 4, "researcher"], [16, 18, "organisation"], [21, 24, "organisation"], [27, 30, "organisation"], [33, 38, "organisation"], [41, 47, "organisation"], [51, 54, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 4, 16, 18, "role", "", false, false], [3, 4, 21, 24, "role", "", false, false], [3, 4, 27, 30, "role", "", false, false], [3, 4, 33, 38, "role", "", false, false], [3, 4, 41, 47, "role", "", false, false], [3, 4, 51, 54, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "impact", "of", "Posner", "'s", "theoretical", "and", "empirical", "contributions", "has", "been", "recognized", "through", "membership", "in", "the", "American", "Psychological", "Association", ",", "the", "Association", "for", "Psychological", "Science", ",", "the", "Society", "for", "Experimental", "Psychology", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "The impact of Posner's theoretical and empirical contributions has been recognized through membership in the American Psychological Association, the Association for Psychological Science, the Society for Experimental Psychology, the American Academy of Arts and Sciences, the American Association for the Advancement of Science, and the National Academy of Sciences.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 20], [20, 22], [23, 34], [35, 38], [39, 48], [49, 62], [63, 66], [67, 71], [72, 82], [83, 90], [91, 101], [102, 104], [105, 108], [109, 117], [118, 131], [132, 143], [143, 144], [145, 148], [149, 160], [161, 164], [165, 178], [179, 186], [186, 187], [188, 191], [192, 199], [200, 203], [204, 216], [217, 227], [227, 228], [229, 232], [233, 241], [242, 249], [250, 252], [253, 257], [258, 261], [262, 270], [270, 271], [272, 275], [276, 284], [285, 296], [297, 300], [301, 304], [305, 316], [317, 319], [320, 327], [327, 328], [329, 332], [333, 336], [337, 345], [346, 353], [354, 356], [357, 365], [365, 366]]}
{"doc_key": "ai-dev-158", "ner": [[2, 2, "product"], [7, 8, "field"], [11, 12, "task"], [14, 16, "task"], [18, 18, "task"], [21, 23, "task"], [25, 25, "task"], [28, 29, "field"], [31, 32, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 2, 7, 8, "usage", "", false, false], [11, 12, 7, 8, "part-of", "", false, false], [14, 16, 7, 8, "part-of", "", false, false], [18, 18, 14, 16, "named", "", false, false], [21, 23, 7, 8, "part-of", "", false, false], [25, 25, 21, 23, "named", "", false, false], [28, 29, 7, 8, "part-of", "", false, false], [31, 32, 7, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["These", "intelligent", "chatbots", "use", "all", "kinds", "of", "artificial", "intelligence", "such", "as", "image", "moderation", "and", "natural", "language", "understanding", "(", "NLU", ")", ",", "natural", "language", "generation", "(", "NLG", ")", ",", "machine", "learning", "and", "deep", "learning", "."], "sentence-detokenized": "These intelligent chatbots use all kinds of artificial intelligence such as image moderation and natural language understanding (NLU), natural language generation (NLG), machine learning and deep learning.", "token2charspan": [[0, 5], [6, 17], [18, 26], [27, 30], [31, 34], [35, 40], [41, 43], [44, 54], [55, 67], [68, 72], [73, 75], [76, 81], [82, 92], [93, 96], [97, 104], [105, 113], [114, 127], [128, 129], [129, 132], [132, 133], [133, 134], [135, 142], [143, 151], [152, 162], [163, 164], [164, 167], [167, 168], [168, 169], [170, 177], [178, 186], [187, 190], [191, 195], [196, 204], [204, 205]]}
{"doc_key": "ai-dev-159", "ner": [[7, 9, "metrics"], [11, 11, "metrics"], [16, 16, "metrics"], [19, 25, "metrics"], [33, 35, "metrics"], [37, 37, "metrics"], [40, 47, "metrics"], [51, 53, "metrics"], [55, 55, "metrics"], [58, 64, "metrics"], [72, 74, "metrics"], [76, 76, "metrics"], [79, 86, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[11, 11, 7, 9, "named", "", false, false], [16, 16, 7, 9, "named", "", false, false], [19, 25, 7, 9, "named", "", false, false], [37, 37, 33, 35, "named", "", false, false], [40, 47, 33, 35, "named", "", false, false], [55, 55, 51, 53, "named", "", false, false], [58, 64, 51, 53, "named", "", false, false], [76, 76, 72, 74, "named", "", false, false], [79, 86, 72, 74, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "coefficients", "of", "the", "series", "are", "the", "positive", "predictive", "value", "(", "PPV", ",", "also", "known", "as", "accuracy", ")", "(", "TP", "/", "(", "TP", "+", "FP", ")", ")", ",", "with", "the", "addition", "of", "the", "false", "discovery", "rate", "(", "FDR", ")", "(", "FP", "/", "(", "TP", "+", "FP", ")", ")", ";", "and", "the", "negative", "predictive", "value", "(", "NPV", ")", "(", "TN", "/", "(", "TN", "+", "FN", ")", ")", ",", "with", "the", "addition", "of", "the", "false", "omission", "rate", "(", "FOR", ")", "(", "FN", "/", "(", "TN", "+", "FN", ")", ")", "."], "sentence-detokenized": "The coefficients of the series are the positive predictive value (PPV, also known as accuracy) (TP / (TP + FP)), with the addition of the false discovery rate (FDR) (FP / (TP + FP)); and the negative predictive value (NPV) (TN / (TN + FN)), with the addition of the false omission rate (FOR) (FN / (TN + FN)).", "token2charspan": [[0, 3], [4, 16], [17, 19], [20, 23], [24, 30], [31, 34], [35, 38], [39, 47], [48, 58], [59, 64], [65, 66], [66, 69], [69, 70], [71, 75], [76, 81], [82, 84], [85, 93], [93, 94], [95, 96], [96, 98], [99, 100], [101, 102], [102, 104], [105, 106], [107, 109], [109, 110], [110, 111], [111, 112], [113, 117], [118, 121], [122, 130], [131, 133], [134, 137], [138, 143], [144, 153], [154, 158], [159, 160], [160, 163], [163, 164], [165, 166], [166, 168], [169, 170], [171, 172], [172, 174], [175, 176], [177, 179], [179, 180], [180, 181], [181, 182], [183, 186], [187, 190], [191, 199], [200, 210], [211, 216], [217, 218], [218, 221], [221, 222], [223, 224], [224, 226], [227, 228], [229, 230], [230, 232], [233, 234], [235, 237], [237, 238], [238, 239], [239, 240], [241, 245], [246, 249], [250, 258], [259, 261], [262, 265], [266, 271], [272, 280], [281, 285], [286, 287], [287, 290], [290, 291], [292, 293], [293, 295], [296, 297], [298, 299], [299, 301], [302, 303], [304, 306], [306, 307], [307, 308], [308, 309]]}
{"doc_key": "ai-dev-160", "ner": [[8, 8, "misc"], [14, 15, "algorithm"], [17, 17, "algorithm"], [20, 22, "algorithm"], [24, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[17, 17, 14, 15, "named", "", false, false], [24, 24, 20, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "information", "is", "a", "combination", "of", "sitemaps", "and", "RSS", "and", "is", "created", "using", "the", "Information", "Model", "(", "IM", ")", "and", "Biomedical", "Resources", "Ontology", "(", "BRO", ")", "."], "sentence-detokenized": "The information is a combination of sitemaps and RSS and is created using the Information Model (IM) and Biomedical Resources Ontology (BRO).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 20], [21, 32], [33, 35], [36, 44], [45, 48], [49, 52], [53, 56], [57, 59], [60, 67], [68, 73], [74, 77], [78, 89], [90, 95], [96, 97], [97, 99], [99, 100], [101, 104], [105, 115], [116, 125], [126, 134], [135, 136], [136, 139], [139, 140], [140, 141]]}
{"doc_key": "ai-dev-161", "ner": [[1, 3, "task"], [7, 9, "algorithm"], [11, 15, "algorithm"], [22, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 3, 11, 15, "origin", "based_on", false, false], [11, 15, 7, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Modern", "text", "recognition", "is", "based", "on", "a", "recurrent", "neural", "network", "(", "long", "short", "-", "term", "memory", ")", "and", "does", "not", "require", "a", "language", "model", "."], "sentence-detokenized": "Modern text recognition is based on a recurrent neural network (long short-term memory) and does not require a language model.", "token2charspan": [[0, 6], [7, 11], [12, 23], [24, 26], [27, 32], [33, 35], [36, 37], [38, 47], [48, 54], [55, 62], [63, 64], [64, 68], [69, 74], [74, 75], [75, 79], [80, 86], [86, 87], [88, 91], [92, 96], [97, 100], [101, 108], [109, 110], [111, 119], [120, 125], [125, 126]]}
{"doc_key": "ai-dev-162", "ner": [[1, 2, "misc"], [4, 5, "metrics"], [8, 9, "algorithm"], [12, 13, "metrics"], [16, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 1, 2, "type-of", "", false, false], [8, 9, 4, 5, "related-to", "", true, false], [12, 13, 1, 2, "type-of", "", false, false], [16, 17, 12, 13, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Popular", "loss", "functions", "include", "loop", "loss", "(", "for", "linear", "SVMs", ")", "and", "log", "loss", "(", "for", "logistic", "regression", ")", "."], "sentence-detokenized": "Popular loss functions include loop loss (for linear SVMs) and log loss (for logistic regression).", "token2charspan": [[0, 7], [8, 12], [13, 22], [23, 30], [31, 35], [36, 40], [41, 42], [42, 45], [46, 52], [53, 57], [57, 58], [59, 62], [63, 66], [67, 71], [72, 73], [73, 76], [77, 85], [86, 96], [96, 97], [97, 98]]}
{"doc_key": "ai-dev-163", "ner": [[0, 0, "metrics"], [9, 15, "metrics"], [17, 17, "metrics"], [20, 22, "metrics"], [24, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 9, 15, "compare", "", false, false], [0, 0, 20, 22, "compare", "", false, false], [17, 17, 9, 15, "named", "", false, false], [24, 24, 20, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SSIM", "is", "designed", "to", "improve", "traditional", "methods", "such", "as", "peak", "signal", "-", "to", "-", "noise", "ratio", "(", "PSNR", ")", "and", "mean", "square", "error", "(", "MSE", ")", "."], "sentence-detokenized": "SSIM is designed to improve traditional methods such as peak signal-to-noise ratio (PSNR) and mean square error (MSE).", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 19], [20, 27], [28, 39], [40, 47], [48, 52], [53, 55], [56, 60], [61, 67], [67, 68], [68, 70], [70, 71], [71, 76], [77, 82], [83, 84], [84, 88], [88, 89], [90, 93], [94, 98], [99, 105], [106, 111], [112, 113], [113, 116], [116, 117], [117, 118]]}
{"doc_key": "ai-dev-164", "ner": [[10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "work", "inspired", "subsequent", "generations", "of", "robotics", "researchers", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "His work inspired subsequent generations of robotics researchers such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 28], [29, 40], [41, 43], [44, 52], [53, 64], [65, 69], [70, 72], [73, 79], [80, 86], [86, 87], [88, 92], [93, 100], [101, 104], [105, 109], [110, 116], [116, 117]]}
{"doc_key": "ai-dev-165", "ner": [[13, 14, "algorithm"], [18, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 19, 13, 14, "origin", "based_on", false, false]], "relations_mapping_to_source": [0], "sentence": ["Further", "pulse", "training", "is", "not", "differentiated", ",", "which", "excludes", "training", "methods", "based", "on", "backward", "propagation", ",", "such", "as", "gradient", "descent", "."], "sentence-detokenized": "Further pulse training is not differentiated, which excludes training methods based on backward propagation, such as gradient descent.", "token2charspan": [[0, 7], [8, 13], [14, 22], [23, 25], [26, 29], [30, 44], [44, 45], [46, 51], [52, 60], [61, 69], [70, 77], [78, 83], [84, 86], [87, 95], [96, 107], [107, 108], [109, 113], [114, 116], [117, 125], [126, 133], [133, 134]]}
{"doc_key": "ai-dev-166", "ner": [[8, 9, "metrics"], [16, 17, "metrics"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 16, 17, "related-to", "describes", false, false], [16, 17, 18, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "relationship", "can", "be", "easily", "represented", "by", "an", "error", "matrix", ",", "a", "table", "that", "describes", "the", "accuracy", "of", "the", "classification", "model", "."], "sentence-detokenized": "This relationship can be easily represented by an error matrix, a table that describes the accuracy of the classification model.", "token2charspan": [[0, 4], [5, 17], [18, 21], [22, 24], [25, 31], [32, 43], [44, 46], [47, 49], [50, 55], [56, 62], [62, 63], [64, 65], [66, 71], [72, 76], [77, 86], [87, 90], [91, 99], [100, 102], [103, 106], [107, 121], [122, 127], [127, 128]]}
{"doc_key": "ai-dev-167", "ner": [[2, 8, "conference"], [10, 10, "conference"], [15, 15, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 2, 8, "named", "", false, false], [15, 15, 2, 8, "physical", "", false, false], [15, 15, 2, 8, "role", "", false, false], [15, 15, 2, 8, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["At", "the", "2018", "conference", "on", "neural", "information", "processing", "systems", "(", "NeurIPS", ")", ",", "researchers", "from", "Google", "presented", "a", "paper"], "sentence-detokenized": "At the 2018 conference on neural information processing systems (NeurIPS), researchers from Google presented a paper", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 22], [23, 25], [26, 32], [33, 44], [45, 55], [56, 63], [64, 65], [65, 72], [72, 73], [73, 74], [75, 86], [87, 91], [92, 98], [99, 108], [109, 110], [111, 116]]}
{"doc_key": "ai-dev-168", "ner": [[3, 4, "university"], [14, 14, "product"], [19, 21, "misc"], [25, 25, "conference"], [30, 33, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 14, 19, 21, "win-defeat", "", false, false], [19, 21, 25, 25, "temporal", "", false, false], [30, 33, 25, 25, "part-of", "", false, false], [30, 33, 25, 25, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["While", "studying", "at", "Duke", "University", ",", "he", "worked", "on", "the", "automated", "crossword", "puzzle", "solver", "PROVERB", ",", "which", "received", "the", "Outstanding", "Paper", "Award", "in", "1999", "from", "AAAI", "and", "participated", "in", "the", "American", "Crossword", "Puzzle", "Tournament", "."], "sentence-detokenized": "While studying at Duke University, he worked on the automated crossword puzzle solver PROVERB, which received the Outstanding Paper Award in 1999 from AAAI and participated in the American Crossword Puzzle Tournament.", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 22], [23, 33], [33, 34], [35, 37], [38, 44], [45, 47], [48, 51], [52, 61], [62, 71], [72, 78], [79, 85], [86, 93], [93, 94], [95, 100], [101, 109], [110, 113], [114, 125], [126, 131], [132, 137], [138, 140], [141, 145], [146, 150], [151, 155], [156, 159], [160, 172], [173, 175], [176, 179], [180, 188], [189, 198], [199, 205], [206, 216], [216, 217]]}
{"doc_key": "ai-dev-169", "ner": [[5, 6, "location"], [8, 9, "location"], [16, 17, "country"], [19, 19, "country"], [21, 21, "country"], [23, 23, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 6, 8, 9, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "company", "is", "headquartered", "in", "Rochester", "Hills", ",", "Michigan", "and", "has", "10", "regional", "offices", "in", "the", "United", "States", ",", "Canada", ",", "Mexico", "and", "Brazil", "."], "sentence-detokenized": "The company is headquartered in Rochester Hills, Michigan and has 10 regional offices in the United States, Canada, Mexico and Brazil.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 28], [29, 31], [32, 41], [42, 47], [47, 48], [49, 57], [58, 61], [62, 65], [66, 68], [69, 77], [78, 85], [86, 88], [89, 92], [93, 99], [100, 106], [106, 107], [108, 114], [114, 115], [116, 122], [123, 126], [127, 133], [133, 134]]}
{"doc_key": "ai-dev-170", "ner": [[12, 12, "product"], [14, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "joins", "a", "collection", "of", "historically", "important", "robots", "that", "includes", "the", "early", "Unimate", "and", "Odetics", "Odex", "1", "."], "sentence-detokenized": "It joins a collection of historically important robots that includes the early Unimate and Odetics Odex 1.", "token2charspan": [[0, 2], [3, 8], [9, 10], [11, 21], [22, 24], [25, 37], [38, 47], [48, 54], [55, 59], [60, 68], [69, 72], [73, 78], [79, 86], [87, 90], [91, 98], [99, 103], [104, 105], [105, 106]]}
{"doc_key": "ai-dev-171", "ner": [[8, 9, "researcher"], [11, 11, "organisation"], [13, 14, "researcher"], [24, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 11, 11, "physical", "", false, false], [8, 9, 11, 11, "role", "", false, false], [13, 14, 11, 11, "physical", "", false, false], [13, 14, 11, 11, "role", "", false, false], [13, 14, 24, 29, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "guest", "editor", "for", "this", "issue", "will", "be", "David", "'s", "former", "NIST", "colleague", "Judah", "Levine", ",", "who", "is", "the", "most", "recent", "recipient", "of", "the", "I", ".", "I", ".", "Raby", "Award", "."], "sentence-detokenized": "The guest editor for this issue will be David's former NIST colleague Judah Levine, who is the most recent recipient of the I. I. Raby Award.", "token2charspan": [[0, 3], [4, 9], [10, 16], [17, 20], [21, 25], [26, 31], [32, 36], [37, 39], [40, 45], [45, 47], [48, 54], [55, 59], [60, 69], [70, 75], [76, 82], [82, 83], [84, 87], [88, 90], [91, 94], [95, 99], [100, 106], [107, 116], [117, 119], [120, 123], [124, 125], [125, 126], [127, 128], [128, 129], [130, 134], [135, 140], [140, 141]]}
{"doc_key": "ai-dev-172", "ner": [[12, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "can", "be", "summarized", "in", "a", "2", "\u00d7", "2", "contingency", "table", "(", "confusion", "matrix", ")", ",", "conventionally", "with", "the", "test", "result", "on", "the", "vertical", "axis", "and", "the", "actual", "condition", "on", "the", "horizontal", "axis", "."], "sentence-detokenized": "These can be summarized in a 2 \u00d7 2 contingency table (confusion matrix), conventionally with the test result on the vertical axis and the actual condition on the horizontal axis.", "token2charspan": [[0, 5], [6, 9], [10, 12], [13, 23], [24, 26], [27, 28], [29, 30], [31, 32], [33, 34], [35, 46], [47, 52], [53, 54], [54, 63], [64, 70], [70, 71], [71, 72], [73, 87], [88, 92], [93, 96], [97, 101], [102, 108], [109, 111], [112, 115], [116, 124], [125, 129], [130, 133], [134, 137], [138, 144], [145, 154], [155, 157], [158, 161], [162, 172], [173, 177], [177, 178]]}
{"doc_key": "ai-dev-173", "ner": [[0, 4, "product"], [8, 8, "product"], [10, 10, "product"], [12, 13, "product"], [16, 18, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 8, 8, "part-of", "", false, false], [0, 4, 10, 10, "part-of", "", false, false], [0, 4, 12, 13, "part-of", "", false, false], [0, 4, 16, 18, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Apple", "iOS", "operating", "system", "used", "on", "the", "iPhone", ",", "iPad", "and", "iPod", "Touch", "uses", "the", "VoiceOver", "speech", "synthesis", "feature", "."], "sentence-detokenized": "The Apple iOS operating system used on the iPhone, iPad and iPod Touch uses the VoiceOver speech synthesis feature.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 23], [24, 30], [31, 35], [36, 38], [39, 42], [43, 49], [49, 50], [51, 55], [56, 59], [60, 64], [65, 70], [71, 75], [76, 79], [80, 89], [90, 96], [97, 106], [107, 114], [114, 115]]}
{"doc_key": "ai-dev-174", "ner": [[8, 10, "conference"], [16, 18, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "the", "best", "system", "included", "in", "MUC", "-", "7", "scored", "93.39", "%", "of", "the", "F", "-", "measure", ",", "while", "human", "annotators", "scored", "97.6", "%", "and", "96.95", "%", "."], "sentence-detokenized": "For example, the best system included in MUC-7 scored 93.39% of the F-measure, while human annotators scored 97.6% and 96.95%.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 37], [38, 40], [41, 44], [44, 45], [45, 46], [47, 53], [54, 59], [59, 60], [61, 63], [64, 67], [68, 69], [69, 70], [70, 77], [77, 78], [79, 84], [85, 90], [91, 101], [102, 108], [109, 113], [113, 114], [115, 118], [119, 124], [124, 125], [125, 126]]}
{"doc_key": "ai-dev-175", "ner": [[11, 13, "algorithm"], [15, 17, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 17, 11, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "this", "purpose", ",", "standard", "neural", "network", "training", "algorithms", "such", "as", "stochastic", "gradient", "descent", "with", "back", "propagation", "are", "used", "."], "sentence-detokenized": "For this purpose, standard neural network training algorithms such as stochastic gradient descent with back propagation are used.", "token2charspan": [[0, 3], [4, 8], [9, 16], [16, 17], [18, 26], [27, 33], [34, 41], [42, 50], [51, 61], [62, 66], [67, 69], [70, 80], [81, 89], [90, 97], [98, 102], [103, 107], [108, 119], [120, 123], [124, 128], [128, 129]]}
{"doc_key": "ai-dev-176", "ner": [[0, 3, "organisation"], [19, 21, "country"], [26, 26, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 19, 21, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Rotten", "Tomatoes", "is", "among", "the", "top", "1000", "sites", ",", "ranking", "about", "400th", "in", "the", "world", "and", "150th", "in", "the", "United", "States", "alone", ",", "according", "to", "the", "Alexa", "site", "ranking", "."], "sentence-detokenized": "Rotten Tomatoes is among the top 1000 sites, ranking about 400th in the world and 150th in the United States alone, according to the Alexa site ranking.", "token2charspan": [[0, 6], [7, 15], [16, 18], [19, 24], [25, 28], [29, 32], [33, 37], [38, 43], [43, 44], [45, 52], [53, 58], [59, 64], [65, 67], [68, 71], [72, 77], [78, 81], [82, 87], [88, 90], [91, 94], [95, 101], [102, 108], [109, 114], [114, 115], [116, 125], [126, 128], [129, 132], [133, 138], [139, 143], [144, 151], [151, 152]]}
{"doc_key": "ai-dev-177", "ner": [[15, 16, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Generally", "speaking", ",", "any", "learning", "reflects", "an", "incremental", "change", "over", "time", ",", "but", "describes", "a", "sigmoid", "function", "that", "looks", "different", "depending", "on", "the", "time", "scale", "of", "observation", "."], "sentence-detokenized": "Generally speaking, any learning reflects an incremental change over time, but describes a sigmoid function that looks different depending on the time scale of observation.", "token2charspan": [[0, 9], [10, 18], [18, 19], [20, 23], [24, 32], [33, 41], [42, 44], [45, 56], [57, 63], [64, 68], [69, 73], [73, 74], [75, 78], [79, 88], [89, 90], [91, 98], [99, 107], [108, 112], [113, 118], [119, 128], [129, 138], [139, 141], [142, 145], [146, 150], [151, 156], [157, 159], [160, 171], [171, 172]]}
{"doc_key": "ai-dev-178", "ner": [[0, 12, "metrics"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "root", "mean", "square", "error", "is", "also", "known", "as", "the", "mean", "square", "error", "."], "sentence-detokenized": "The root mean square error is also known as the mean square error.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 20], [21, 26], [27, 29], [30, 34], [35, 40], [41, 43], [44, 47], [48, 52], [53, 59], [60, 65], [65, 66]]}
{"doc_key": "ai-dev-179", "ner": [[0, 2, "algorithm"], [4, 5, "algorithm"], [7, 9, "algorithm"], [21, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 21, 22, "related-to", "can_be_related_to", true, false], [4, 5, 21, 22, "related-to", "can_be_related_to", true, false], [7, 9, 21, 22, "related-to", "can_be_related_to", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", ",", "neural", "networks", "or", "naive", "Bayesian", "classifier", "can", "be", "used", "in", "combination", "with", "model", "quality", "metrics", "such", "as", "balanced", "accuracy", "."], "sentence-detokenized": "Decision tree learning, neural networks or naive Bayesian classifier can be used in combination with model quality metrics such as balanced accuracy.", "token2charspan": [[0, 8], [9, 13], [14, 22], [22, 23], [24, 30], [31, 39], [40, 42], [43, 48], [49, 57], [58, 68], [69, 72], [73, 75], [76, 80], [81, 83], [84, 95], [96, 100], [101, 106], [107, 114], [115, 122], [123, 127], [128, 130], [131, 139], [140, 148], [148, 149]]}
{"doc_key": "ai-dev-180", "ner": [[16, 16, "conference"], [24, 25, "conference"], [29, 33, "misc"], [37, 42, "product"], [46, 49, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[29, 33, 24, 25, "origin", "", false, false], [29, 33, 24, 25, "temporal", "", false, false], [37, 42, 29, 33, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "is", "a", "past", "president", "(", "1979", ")", "and", "inaugural", "fellow", "(", "2011", ")", "of", "the", "ACL", ",", "one", "of", "the", "recipients", "of", "the", "1992", "Association", "for", "Computing", "Machinery", "Software", "Systems", "Award", "for", "his", "contributions", "to", "the", "Interlisp", "programming", "system", ",", "and", "a", "Fellow", "of", "the", "Association", "for", "Computing", "Machinery", "."], "sentence-detokenized": "He is a past president (1979) and inaugural fellow (2011) of the ACL, one of the recipients of the 1992 Association for Computing Machinery Software Systems Award for his contributions to the Interlisp programming system, and a Fellow of the Association for Computing Machinery.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 22], [23, 24], [24, 28], [28, 29], [30, 33], [34, 43], [44, 50], [51, 52], [52, 56], [56, 57], [58, 60], [61, 64], [65, 68], [68, 69], [70, 73], [74, 76], [77, 80], [81, 91], [92, 94], [95, 98], [99, 103], [104, 115], [116, 119], [120, 129], [130, 139], [140, 148], [149, 156], [157, 162], [163, 166], [167, 170], [171, 184], [185, 187], [188, 191], [192, 201], [202, 213], [214, 220], [220, 221], [222, 225], [226, 227], [228, 234], [235, 237], [238, 241], [242, 253], [254, 257], [258, 267], [268, 277], [277, 278]]}
{"doc_key": "ai-dev-181", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 9, "researcher"], [32, 33, "researcher"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 22, 23, "related-to", "", false, false], [5, 6, 22, 23, "related-to", "", false, false], [8, 9, 22, 23, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Along", "with", "Jeffrey", "Hinton", "and", "Jan", "Lekun", ",", "Bengio", "is", "considered", "one", "of", "the", "three", "people", "most", "responsible", "for", "the", "development", "of", "deep", "learning", "during", "the", "1990s", "and", "2000s", ",", "according", "to", "Cade", "Metz", "."], "sentence-detokenized": "Along with Jeffrey Hinton and Jan Lekun, Bengio is considered one of the three people most responsible for the development of deep learning during the 1990s and 2000s, according to Cade Metz.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 25], [26, 29], [30, 33], [34, 39], [39, 40], [41, 47], [48, 50], [51, 61], [62, 65], [66, 68], [69, 72], [73, 78], [79, 85], [86, 90], [91, 102], [103, 106], [107, 110], [111, 122], [123, 125], [126, 130], [131, 139], [140, 146], [147, 150], [151, 156], [157, 160], [161, 166], [166, 167], [168, 177], [178, 180], [181, 185], [186, 190], [190, 191]]}
{"doc_key": "ai-dev-182", "ner": [[1, 2, "field"], [4, 7, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "information", "theory", "and", "computer", "science", ",", "a", "code", "is", "usually", "considered", "as", "an", "algorithm", "that", "uniquely", "represents", "characters", "from", "some", "source", "alphabet", "by", "encoded", "strings", "that", "may", "be", "in", "some", "other", "target", "alphabet", "."], "sentence-detokenized": "In information theory and computer science, a code is usually considered as an algorithm that uniquely represents characters from some source alphabet by encoded strings that may be in some other target alphabet.", "token2charspan": [[0, 2], [3, 14], [15, 21], [22, 25], [26, 34], [35, 42], [42, 43], [44, 45], [46, 50], [51, 53], [54, 61], [62, 72], [73, 75], [76, 78], [79, 88], [89, 93], [94, 102], [103, 113], [114, 124], [125, 129], [130, 134], [135, 141], [142, 150], [151, 153], [154, 161], [162, 169], [170, 174], [175, 178], [179, 181], [182, 184], [185, 189], [190, 195], [196, 202], [203, 211], [211, 212]]}
{"doc_key": "ai-dev-183", "ner": [[6, 8, "algorithm"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 13, 6, 8, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "fairly", "simple", "nonlinear", "function", ",", "a", "sigmoidal", "function", "such", "as", "the", "logistic", "function", ",", "also", "has", "an", "easily", "computable", "derivative", ",", "which", "can", "be", "important", "when", "calculating", "weight", "updates", "in", "a", "network", "."], "sentence-detokenized": "A fairly simple nonlinear function, a sigmoidal function such as the logistic function, also has an easily computable derivative, which can be important when calculating weight updates in a network.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 25], [26, 34], [34, 35], [36, 37], [38, 47], [48, 56], [57, 61], [62, 64], [65, 68], [69, 77], [78, 86], [86, 87], [88, 92], [93, 96], [97, 99], [100, 106], [107, 117], [118, 128], [128, 129], [130, 135], [136, 139], [140, 142], [143, 152], [153, 157], [158, 169], [170, 176], [177, 184], [185, 187], [188, 189], [190, 197], [197, 198]]}
{"doc_key": "ai-dev-184", "ner": [[0, 0, "person"], [4, 4, "location"], [6, 6, "location"], [9, 11, "country"], [14, 14, "country"], [7, 18, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 4, 4, "physical", "", false, false], [4, 4, 6, 6, "physical", "", false, false], [6, 6, 9, 11, "physical", "", false, false], [6, 6, 14, 14, "physical", "", false, false], [6, 6, 7, 18, "physical", "", false, false], [14, 14, 9, 11, "origin", "", false, false], [7, 18, 14, 14, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["\u010capek", "was", "born", "in", "Hronov", ",", "Czech", "Republic", "(", "Austria", "-", "Hungary", ",", "later", "Czechoslovakia", ",", "now", "Czech", "Republic", ")", "in", "1887", "."], "sentence-detokenized": "\u010capek was born in Hronov, Czech Republic (Austria-Hungary, later Czechoslovakia, now Czech Republic) in 1887.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 17], [18, 24], [24, 25], [26, 31], [32, 40], [41, 42], [42, 49], [49, 50], [50, 57], [57, 58], [59, 64], [65, 79], [79, 80], [81, 84], [85, 90], [91, 99], [99, 100], [101, 103], [104, 108], [108, 109]]}
{"doc_key": "ai-dev-185", "ner": [[5, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "specialized", "applications", "can", "sound", "RSS", "."], "sentence-detokenized": "Some specialized applications can sound RSS.", "token2charspan": [[0, 4], [5, 16], [17, 29], [30, 33], [34, 39], [40, 43], [43, 44]]}
{"doc_key": "ai-dev-186", "ner": [[7, 8, "task"], [12, 13, "task"], [15, 15, "task"], [17, 17, "task"], [20, 22, "task"], [29, 30, "task"], [33, 34, "task"], [38, 39, "task"], [42, 44, "product"], [46, 47, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[7, 8, 12, 13, "related-to", "", true, false], [7, 8, 15, 15, "related-to", "", true, false], [7, 8, 17, 17, "related-to", "", true, false], [33, 34, 29, 30, "usage", "", true, false], [42, 44, 38, 39, "type-of", "", false, false], [46, 47, 38, 39, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Aspects", "of", "the", "ontology", "editors", "include", ":", "visual", "navigation", "capabilities", "in", "the", "knowledge", "model", ",", "inference", "and", "extraction", "mechanisms", ";", "support", "for", "modules", ";", "import", "and", "export", "of", "foreign", "knowledge", "representation", "languages", "for", "ontology", "harmonization", ";", "support", "for", "meta", "-ontologies", "such", "as", "OWL", "-", "S", ",", "Dublin", "Core", ",", "etc", "."], "sentence-detokenized": "Aspects of the ontology editors include: visual navigation capabilities in the knowledge model, inference and extraction mechanisms; support for modules; import and export of foreign knowledge representation languages for ontology harmonization; support for meta-ontologies such as OWL-S, Dublin Core, etc.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 23], [24, 31], [32, 39], [39, 40], [41, 47], [48, 58], [59, 71], [72, 74], [75, 78], [79, 88], [89, 94], [94, 95], [96, 105], [106, 109], [110, 120], [121, 131], [131, 132], [133, 140], [141, 144], [145, 152], [152, 153], [154, 160], [161, 164], [165, 171], [172, 174], [175, 182], [183, 192], [193, 207], [208, 217], [218, 221], [222, 230], [231, 244], [244, 245], [246, 253], [254, 257], [258, 262], [262, 273], [274, 278], [279, 281], [282, 285], [285, 286], [286, 287], [287, 288], [289, 295], [296, 300], [300, 301], [302, 305], [305, 306]]}
{"doc_key": "ai-dev-187", "ner": [[0, 1, "organisation"], [6, 11, "misc"], [13, 14, "task"], [20, 20, "field"], [23, 23, "misc"], [25, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 11, 0, 1, "origin", "", false, false], [13, 14, 6, 11, "part-of", "", false, false], [20, 20, 6, 11, "part-of", "", false, false], [23, 23, 20, 20, "type-of", "", false, false], [25, 26, 20, 20, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "FBI", "has", "also", "introduced", "its", "Next", "Generation", "Identification", "Program", ",", "which", "includes", "facial", "recognition", "as", "well", "as", "more", "traditional", "biometrics", "such", "as", "fingerprints", "and", "iris", "scans", ",", "which", "can", "be", "obtained", "from", "both", "criminal", "and", "civil", "databases", "."], "sentence-detokenized": "The FBI has also introduced its Next Generation Identification Program, which includes facial recognition as well as more traditional biometrics such as fingerprints and iris scans, which can be obtained from both criminal and civil databases.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 16], [17, 27], [28, 31], [32, 36], [37, 47], [48, 62], [63, 70], [70, 71], [72, 77], [78, 86], [87, 93], [94, 105], [106, 108], [109, 113], [114, 116], [117, 121], [122, 133], [134, 144], [145, 149], [150, 152], [153, 165], [166, 169], [170, 174], [175, 180], [180, 181], [182, 187], [188, 191], [192, 194], [195, 203], [204, 208], [209, 213], [214, 222], [223, 226], [227, 232], [233, 242], [242, 243]]}
{"doc_key": "ai-dev-188", "ner": [[5, 6, "person"], [12, 13, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "2016", "season", ",", "Samantha", "Ponder", "became", "the", "host", ",", "replacing", "Molly", "McGrath", "."], "sentence-detokenized": "In the 2016 season, Samantha Ponder became the host, replacing Molly McGrath.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [18, 19], [20, 28], [29, 35], [36, 42], [43, 46], [47, 51], [51, 52], [53, 62], [63, 68], [69, 76], [76, 77]]}
{"doc_key": "ai-dev-189", "ner": [[0, 5, "algorithm"], [16, 20, "misc"], [22, 22, "misc"], [24, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "a", "competitive", "search", "algorithm", "commonly", "used", "to", "machine", "play", "two", "-", "player", "games", "(", "tic", "-", "tac", "-", "toe", ",", "chess", ",", "go", ",", "etc.", ")", "."], "sentence-detokenized": "It is a competitive search algorithm commonly used to machine play two-player games (tic-tac-toe, chess, go, etc.).", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 19], [20, 26], [27, 36], [37, 45], [46, 50], [51, 53], [54, 61], [62, 66], [67, 70], [70, 71], [71, 77], [78, 83], [84, 85], [85, 88], [88, 89], [89, 92], [92, 93], [93, 96], [96, 97], [98, 103], [103, 104], [105, 107], [107, 108], [109, 113], [113, 114], [114, 115]]}
{"doc_key": "ai-dev-190", "ner": [[5, 5, "field"], [7, 8, "field"], [10, 11, "field"], [17, 18, "field"], [20, 21, "field"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "covers", "the", "fields", "of", "computer", "or", "machine", "vision", "and", "medical", "imaging", "and", "makes", "extensive", "use", "of", "pattern", "recognition", ",", "digital", "geometry", "and", "signal", "processing", "."], "sentence-detokenized": "It covers the fields of computer or machine vision and medical imaging and makes extensive use of pattern recognition, digital geometry and signal processing.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 20], [21, 23], [24, 32], [33, 35], [36, 43], [44, 50], [51, 54], [55, 62], [63, 70], [71, 74], [75, 80], [81, 90], [91, 94], [95, 97], [98, 105], [106, 117], [117, 118], [119, 126], [127, 135], [136, 139], [140, 146], [147, 157], [157, 158]]}
{"doc_key": "ai-dev-191", "ner": [[5, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "in", "the", "face", "recognition", "system", ",", "the", "input", "will", "be", "a", "photo", "of", "a", "person", "'s", "face", ",", "and", "the", "output", "will", "be", "the", "name", "of", "this", "person", "."], "sentence-detokenized": "For example, in the face recognition system, the input will be a photo of a person's face, and the output will be the name of this person.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 19], [20, 24], [25, 36], [37, 43], [43, 44], [45, 48], [49, 54], [55, 59], [60, 62], [63, 64], [65, 70], [71, 73], [74, 75], [76, 82], [82, 84], [85, 89], [89, 90], [91, 94], [95, 98], [99, 105], [106, 110], [111, 113], [114, 117], [118, 122], [123, 125], [126, 130], [131, 137], [137, 138]]}
{"doc_key": "ai-dev-192", "ner": [[0, 1, "organisation"], [3, 4, "product"], [8, 10, "product"], [22, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 3, 4, "artifact", "", false, false], [3, 4, 8, 10, "part-of", "", false, false], [8, 10, 3, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Apple", "Inc", "introduced", "Face", "ID", "in", "the", "flagship", "i", "Phone", "X", "as", "the", "successor", "to", "the", "fingerprint", "-", "based", "biometric", "authentication", "system", "Touch", "ID", "."], "sentence-detokenized": "Apple Inc introduced Face ID in the flagship iPhone X as the successor to the fingerprint-based biometric authentication system Touch ID.", "token2charspan": [[0, 5], [6, 9], [10, 20], [21, 25], [26, 28], [29, 31], [32, 35], [36, 44], [45, 46], [46, 51], [52, 53], [54, 56], [57, 60], [61, 70], [71, 73], [74, 77], [78, 89], [89, 90], [90, 95], [96, 105], [106, 120], [121, 127], [128, 133], [134, 136], [136, 137]]}
{"doc_key": "ai-dev-193", "ner": [[3, 5, "metrics"], [8, 9, "metrics"], [20, 24, "metrics"], [27, 30, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Or", "combine", "the", "F", "-", "measure", "with", "the", "R-", "square", "estimated", "for", "the", "model", "output", "and", "the", "target", ";", "or", "the", "cost", "/", "benefit", "matrix", "with", "the", "correlation", "coefficient", ",", "etc", "."], "sentence-detokenized": "Or combine the F-measure with the R-square estimated for the model output and the target; or the cost/benefit matrix with the correlation coefficient, etc.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 16], [16, 17], [17, 24], [25, 29], [30, 33], [34, 36], [36, 42], [43, 52], [53, 56], [57, 60], [61, 66], [67, 73], [74, 77], [78, 81], [82, 88], [88, 89], [90, 92], [93, 96], [97, 101], [101, 102], [102, 109], [110, 116], [117, 121], [122, 125], [126, 137], [138, 149], [149, 150], [151, 154], [154, 155]]}
{"doc_key": "ai-dev-194", "ner": [[6, 11, "conference"], [16, 18, "location"], [20, 20, "location"], [24, 27, "location"], [29, 29, "location"], [31, 31, "country"], [38, 40, "location"], [43, 47, "location"], [49, 49, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[6, 11, 16, 18, "physical", "", false, false], [6, 11, 24, 27, "physical", "", false, false], [6, 11, 38, 40, "physical", "", false, false], [6, 11, 43, 47, "physical", "", false, false], [16, 18, 20, 20, "physical", "", false, false], [24, 27, 29, 29, "physical", "", false, false], [29, 29, 31, 31, "physical", "", false, false], [38, 40, 49, 49, "physical", "", false, false], [43, 47, 49, 49, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Over", "the", "past", "15", "years", ",", "the", "Spanish", "edition", "of", "Campus", "Party", "has", "been", "held", "at", "Miguel", "Hern\u00e1ndez", "College", "in", "Seoul", "and", "at", "the", "Benalm\u00e1dena", "Municipal", "Sports", "Arena", "in", "M\u00e1laga", ",", "Spain", ";", "as", "well", "as", "at", "the", "Valencia", "County", "Fair", "and", "the", "City", "of", "Arts", "and", "Sciences", "in", "Valencia", "."], "sentence-detokenized": "Over the past 15 years, the Spanish edition of Campus Party has been held at Miguel Hern\u00e1ndez College in Seoul and at the Benalm\u00e1dena Municipal Sports Arena in M\u00e1laga, Spain; as well as at the Valencia County Fair and the City of Arts and Sciences in Valencia.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 22], [22, 23], [24, 27], [28, 35], [36, 43], [44, 46], [47, 53], [54, 59], [60, 63], [64, 68], [69, 73], [74, 76], [77, 83], [84, 93], [94, 101], [102, 104], [105, 110], [111, 114], [115, 117], [118, 121], [122, 133], [134, 143], [144, 150], [151, 156], [157, 159], [160, 166], [166, 167], [168, 173], [173, 174], [175, 177], [178, 182], [183, 185], [186, 188], [189, 192], [193, 201], [202, 208], [209, 213], [214, 217], [218, 221], [222, 226], [227, 229], [230, 234], [235, 238], [239, 247], [248, 250], [251, 259], [259, 260]]}
{"doc_key": "ai-dev-195", "ner": [[0, 0, "product"], [15, 15, "programlang"], [19, 19, "product"], [21, 21, "product"], [25, 25, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 15, 0, 0, "general-affiliation", "", false, false], [19, 19, 15, 15, "part-of", "", false, false], [21, 21, 15, 15, "part-of", "", false, false], [25, 25, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["gnuplot", "can", "be", "used", "from", "a", "variety", "of", "programming", "languages", "to", "plot", "data", ",", "including", "Perl", "(", "via", "the", "PDL", "and", "CPAN", "packages", ")", ",", "Python", "(", "via", ")", "."], "sentence-detokenized": "gnuplot can be used from a variety of programming languages to plot data, including Perl (via the PDL and CPAN packages), Python (via).", "token2charspan": [[0, 7], [8, 11], [12, 14], [15, 19], [20, 24], [25, 26], [27, 34], [35, 37], [38, 49], [50, 59], [60, 62], [63, 67], [68, 72], [72, 73], [74, 83], [84, 88], [89, 90], [90, 93], [94, 97], [98, 101], [102, 105], [106, 110], [111, 119], [119, 120], [120, 121], [122, 128], [129, 130], [130, 133], [133, 134], [134, 135]]}
{"doc_key": "ai-dev-196", "ner": [[3, 6, "product"], [19, 19, "conference"], [21, 21, "conference"], [35, 35, "conference"], [37, 37, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 19, 3, 6, "topic", "", false, false], [21, 21, 3, 6, "topic", "", false, false], [35, 35, 3, 6, "topic", "", false, false], [37, 37, 3, 6, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "field", "of", "spoken", "dialogue", "systems", "is", "quite", "large", "and", "includes", "research", "(", "presented", "at", "scientific", "conferences", "such", "as", "SIGdial", "and", "Interspeech", ")", "and", "a", "large", "industrial", "sector", "(", "with", "its", "own", "meetings", "such", "as", "SpeechTek", "and", "AVIOS", ")", "."], "sentence-detokenized": "The field of spoken dialogue systems is quite large and includes research (presented at scientific conferences such as SIGdial and Interspeech) and a large industrial sector (with its own meetings such as SpeechTek and AVIOS).", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 19], [20, 28], [29, 36], [37, 39], [40, 45], [46, 51], [52, 55], [56, 64], [65, 73], [74, 75], [75, 84], [85, 87], [88, 98], [99, 110], [111, 115], [116, 118], [119, 126], [127, 130], [131, 142], [142, 143], [144, 147], [148, 149], [150, 155], [156, 166], [167, 173], [174, 175], [175, 179], [180, 183], [184, 187], [188, 196], [197, 201], [202, 204], [205, 214], [215, 218], [219, 224], [224, 225], [225, 226]]}
{"doc_key": "ai-dev-197", "ner": [[2, 5, "field"], [9, 10, "task"], [12, 14, "task"], [16, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 2, 5, "part-of", "task_part_of_field", false, false], [12, 14, 2, 5, "part-of", "task_part_of_field", false, false], [16, 18, 2, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Problems", "in", "natural", "language", "processing", "are", "often", "related", "to", "speech", "recognition", ",", "natural", "language", "understanding", "and", "natural", "language", "generation", "."], "sentence-detokenized": "Problems in natural language processing are often related to speech recognition, natural language understanding and natural language generation.", "token2charspan": [[0, 8], [9, 11], [12, 19], [20, 28], [29, 39], [40, 43], [44, 49], [50, 57], [58, 60], [61, 67], [68, 79], [79, 80], [81, 88], [89, 97], [98, 111], [112, 115], [116, 123], [124, 132], [133, 143], [143, 144]]}
{"doc_key": "ai-dev-198", "ner": [[10, 10, "product"], [5, 9, "product"], [36, 37, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 5, 9, "part-of", "", false, false], [10, 10, 36, 37, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "systems", ",", "such", "as", "the", "iOS", "operating", "system", "'s", "Siri", ",", "work", "on", "a", "similar", "pattern", "recognition", "methodology", "as", "text", "-", "based", "systems", ",", "but", "in", "the", "former", ",", "user", "input", "is", "carried", "out", "using", "speech", "recognition", "."], "sentence-detokenized": "These systems, such as the iOS operating system's Siri, work on a similar pattern recognition methodology as text-based systems, but in the former, user input is carried out using speech recognition.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 22], [23, 26], [27, 30], [31, 40], [41, 47], [47, 49], [50, 54], [54, 55], [56, 60], [61, 63], [64, 65], [66, 73], [74, 81], [82, 93], [94, 105], [106, 108], [109, 113], [113, 114], [114, 119], [120, 127], [127, 128], [129, 132], [133, 135], [136, 139], [140, 146], [146, 147], [148, 152], [153, 158], [159, 161], [162, 169], [170, 173], [174, 179], [180, 186], [187, 198], [198, 199]]}
{"doc_key": "ai-dev-199", "ner": [[1, 3, "algorithm"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 3, 13, 14, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["More", "exotic", "fit", "functions", "that", "explore", "model", "granularity", "include", "the", "area", "under", "the", "ROC", "curve", "and", "the", "rank", "measure", "."], "sentence-detokenized": "More exotic fit functions that explore model granularity include the area under the ROC curve and the rank measure.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 25], [26, 30], [31, 38], [39, 44], [45, 56], [57, 64], [65, 68], [69, 73], [74, 79], [80, 83], [84, 87], [88, 93], [94, 97], [98, 101], [102, 106], [107, 114], [114, 115]]}
{"doc_key": "ai-dev-200", "ner": [[3, 4, "product"], [9, 12, "researcher"], [17, 19, "product"], [24, 27, "organisation"], [29, 29, "organisation"], [38, 40, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 9, 12, "origin", "", false, false], [9, 12, 24, 27, "role", "", false, false], [17, 19, 9, 12, "origin", "", false, false], [29, 29, 24, 27, "named", "", false, false], [38, 40, 24, 27, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "term", "\"", "semantic", "web", "\"", "was", "coined", "by", "Tim", "Berners", "-", "Lee", ",", "inventor", "of", "the", "World", "Wide", "Web", "and", "director", "of", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", ",", "which", "oversees", "the", "development", "of", "proposed", "semantic", "web", "standards", "."], "sentence-detokenized": "The term \"semantic web\" was coined by Tim Berners-Lee, inventor of the World Wide Web and director of the World Wide Web Consortium (W3C), which oversees the development of proposed semantic web standards.", "token2charspan": [[0, 3], [4, 8], [9, 10], [10, 18], [19, 22], [22, 23], [24, 27], [28, 34], [35, 37], [38, 41], [42, 49], [49, 50], [50, 53], [53, 54], [55, 63], [64, 66], [67, 70], [71, 76], [77, 81], [82, 85], [86, 89], [90, 98], [99, 101], [102, 105], [106, 111], [112, 116], [117, 120], [121, 131], [132, 133], [133, 136], [136, 137], [137, 138], [139, 144], [145, 153], [154, 157], [158, 169], [170, 172], [173, 181], [182, 190], [191, 194], [195, 204], [204, 205]]}
{"doc_key": "ai-dev-201", "ner": [[0, 1, "task"], [9, 9, "task"], [16, 17, "product"], [19, 23, "product"], [25, 25, "product"], [29, 30, "product"], [37, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 16, 17, "opposite", "", false, false], [0, 1, 19, 23, "opposite", "", false, false], [0, 1, 29, 30, "opposite", "", false, false], [0, 1, 37, 39, "part-of", "", false, false], [9, 9, 0, 1, "named", "", false, false], [25, 25, 19, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Machine", "translation", ",", "sometimes", "referred", "to", "by", "the", "abbreviation", "MT", "(", "not", "to", "be", "confused", "with", "computer", "translation", ",", "machine", "-", "aided", "human", "translation", "(", "MAHT", ")", ",", "or", "interactive", "translation", ")", ",", "is", "a", "subfield", "of", "computational", "linguistics", "that", "studies", "the", "use", "of", "software", "to", "translate", "text", "or", "speech", "from", "one", "language", "to", "another", "."], "sentence-detokenized": "Machine translation, sometimes referred to by the abbreviation MT (not to be confused with computer translation, machine-aided human translation (MAHT), or interactive translation), is a subfield of computational linguistics that studies the use of software to translate text or speech from one language to another.", "token2charspan": [[0, 7], [8, 19], [19, 20], [21, 30], [31, 39], [40, 42], [43, 45], [46, 49], [50, 62], [63, 65], [66, 67], [67, 70], [71, 73], [74, 76], [77, 85], [86, 90], [91, 99], [100, 111], [111, 112], [113, 120], [120, 121], [121, 126], [127, 132], [133, 144], [145, 146], [146, 150], [150, 151], [151, 152], [153, 155], [156, 167], [168, 179], [179, 180], [180, 181], [182, 184], [185, 186], [187, 195], [196, 198], [199, 212], [213, 224], [225, 229], [230, 237], [238, 241], [242, 245], [246, 248], [249, 257], [258, 260], [261, 270], [271, 275], [276, 278], [279, 285], [286, 290], [291, 294], [295, 303], [304, 306], [307, 314], [314, 315]]}
{"doc_key": "ai-dev-202", "ner": [[1, 3, "product"], [8, 8, "university"], [12, 14, "researcher"], [16, 17, "researcher"], [40, 41, "location"], [43, 43, "location"], [47, 50, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 3, 12, 14, "artifact", "", false, false], [1, 3, 16, 17, "artifact", "", false, false], [12, 14, 8, 8, "physical", "", false, false], [12, 14, 8, 8, "role", "", false, false], [16, 17, 8, 8, "physical", "", false, false], [16, 17, 8, 8, "role", "", false, false], [40, 41, 43, 43, "physical", "", false, false], [47, 50, 40, 41, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Early", "inter-lingual", "MT", "systems", "were", "also", "created", "at", "Stanford", "in", "the", "1970s", "by", "Roger", "Shank", "and", "Yorick", "Wilkes", ";", "the", "former", "became", "the", "basis", "of", "a", "commercial", "remittance", "system", ",", "and", "the", "code", "for", "the", "latter", "is", "preserved", "at", "the", "Computer", "Museum", "in", "Boston", "as", "the", "first", "inter-lingual", "machine", "translation", "system", "."], "sentence-detokenized": "Early inter-lingual MT systems were also created at Stanford in the 1970s by Roger Shank and Yorick Wilkes; the former became the basis of a commercial remittance system, and the code for the latter is preserved at the Computer Museum in Boston as the first inter-lingual machine translation system.", "token2charspan": [[0, 5], [6, 19], [20, 22], [23, 30], [31, 35], [36, 40], [41, 48], [49, 51], [52, 60], [61, 63], [64, 67], [68, 73], [74, 76], [77, 82], [83, 88], [89, 92], [93, 99], [100, 106], [106, 107], [108, 111], [112, 118], [119, 125], [126, 129], [130, 135], [136, 138], [139, 140], [141, 151], [152, 162], [163, 169], [169, 170], [171, 174], [175, 178], [179, 183], [184, 187], [188, 191], [192, 198], [199, 201], [202, 211], [212, 214], [215, 218], [219, 227], [228, 234], [235, 237], [238, 244], [245, 247], [248, 251], [252, 257], [258, 271], [272, 279], [280, 291], [292, 298], [298, 299]]}
{"doc_key": "ai-dev-203", "ner": [[0, 0, "researcher"], [5, 10, "conference"], [12, 13, "conference"], [19, 25, "conference"], [27, 28, "conference"], [34, 39, "organisation"], [47, 47, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 5, 10, "role", "", false, false], [0, 0, 19, 25, "role", "", false, false], [0, 0, 34, 39, "role", "", false, false], [0, 0, 47, 47, "role", "", false, false], [12, 13, 5, 10, "named", "", false, false], [27, 28, 19, 25, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sikara", "was", "program", "chair", "of", "the", "Second", "International", "Semantic", "Web", "Conference", "(", "ISWC", "2003", ")", ";", "general", "chair", "of", "the", "Second", "International", "Conference", "on", "Autonomous", "Agents", "(", "Agents", "98", ")", ";", "chair", "of", "the", "Steering", "Committee", "of", "the", "Agents", "Conference", "(", "1999-2001", ")", ";", "chair", "of", "the", "AAAI", "Scholarship", "Committee", "(", "1993-1999", ")", ";"], "sentence-detokenized": "Sikara was program chair of the Second International Semantic Web Conference (ISWC 2003); general chair of the Second International Conference on Autonomous Agents (Agents 98); chair of the Steering Committee of the Agents Conference (1999-2001); chair of the AAAI Scholarship Committee (1993-1999);", "token2charspan": [[0, 6], [7, 10], [11, 18], [19, 24], [25, 27], [28, 31], [32, 38], [39, 52], [53, 61], [62, 65], [66, 76], [77, 78], [78, 82], [83, 87], [87, 88], [88, 89], [90, 97], [98, 103], [104, 106], [107, 110], [111, 117], [118, 131], [132, 142], [143, 145], [146, 156], [157, 163], [164, 165], [165, 171], [172, 174], [174, 175], [175, 176], [177, 182], [183, 185], [186, 189], [190, 198], [199, 208], [209, 211], [212, 215], [216, 222], [223, 233], [234, 235], [235, 244], [244, 245], [245, 246], [247, 252], [253, 255], [256, 259], [260, 264], [265, 276], [277, 286], [287, 288], [288, 297], [297, 298], [298, 299]]}
{"doc_key": "ai-dev-204", "ner": [[10, 10, "conference"], [12, 25, "conference"], [19, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 25, 10, 10, "named", "", false, false], [19, 23, 10, 10, "part-of", "", false, false], [19, 23, 10, 10, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2016", "she", "was", "selected", "as", "a", "laureate", "of", "the", "ACL", "(", "Association", "for", "Computational", "Linguistics", ")", "award", "for", "achievements", "in", "the", "field", "of", "computational", "linguistics", "."], "sentence-detokenized": "In 2016 she was selected as a laureate of the ACL (Association for Computational Linguistics) award for achievements in the field of computational linguistics.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 15], [16, 24], [25, 27], [28, 29], [30, 38], [39, 41], [42, 45], [46, 49], [50, 51], [51, 62], [63, 66], [67, 80], [81, 92], [92, 93], [94, 99], [100, 103], [104, 116], [117, 119], [120, 123], [124, 129], [130, 132], [133, 146], [147, 158], [158, 159]]}
{"doc_key": "ai-dev-205", "ner": [[0, 1, "researcher"], [3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Zepp", "Hochreiter", ",", "J.", "Bengio", ",", "P.", "Frasconi", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Zepp Hochreiter, J. Bengio, P. Frasconi and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 15], [15, 16], [17, 19], [20, 26], [26, 27], [28, 30], [31, 39], [40, 43], [44, 50], [51, 62], [62, 63]]}
{"doc_key": "ai-dev-206", "ner": [[3, 3, "product"], [6, 7, "misc"], [9, 9, "programlang"], [19, 20, "product"], [35, 35, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 9, 9, "usage", "", false, false], [9, 9, 6, 7, "type-of", "", false, false], [9, 9, 19, 20, "related-to", "", false, false], [35, 35, 3, 3, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["For", "example", ",", "A.L.I.C.E.", "uses", "a", "markup", "language", "called", "AIML", ",", "which", "is", "specific", "to", "its", "function", "as", "a", "dialog", "system", ",", "and", "has", "since", "been", "adopted", "by", "various", "other", "developers", "of", "so", "-", "called", "Alicebots", "."], "sentence-detokenized": "For example, A.L.I.C.E. uses a markup language called AIML, which is specific to its function as a dialog system, and has since been adopted by various other developers of so-called Alicebots.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 23], [24, 28], [29, 30], [31, 37], [38, 46], [47, 53], [54, 58], [58, 59], [60, 65], [66, 68], [69, 77], [78, 80], [81, 84], [85, 93], [94, 96], [97, 98], [99, 105], [106, 112], [112, 113], [114, 117], [118, 121], [122, 127], [128, 132], [133, 140], [141, 143], [144, 151], [152, 157], [158, 168], [169, 171], [172, 174], [174, 175], [175, 181], [182, 191], [191, 192]]}
{"doc_key": "ai-dev-207", "ner": [[9, 15, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2000", "she", "was", "elected", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2000 she was elected a member of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [98, 99]]}
{"doc_key": "ai-dev-208", "ner": [[0, 2, "misc"], [4, 4, "misc"], [10, 15, "misc"], [24, 25, "algorithm"], [35, 35, "field"], [37, 38, "field"], [41, 42, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 10, 15, "type-of", "", false, false], [0, 2, 35, 35, "related-to", "performs", true, false], [0, 2, 37, 38, "related-to", "performs", true, false], [0, 2, 41, 42, "related-to", "performs", true, false], [4, 4, 0, 2, "named", "", false, false], [24, 25, 10, 15, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Learning", "classifier", "systems", "(", "LCS", ")", "are", "a", "family", "of", "rule", "-", "based", "machine", "learning", "algorithms", "that", "combine", "a", "detection", "component", ",", "typically", "a", "genetic", "algorithm", ",", "with", "a", "learning", "component", "that", "performs", "either", "supervised", "learning", ",", "reinforcement", "learning", ",", "or", "unsupervised", "learning", "."], "sentence-detokenized": "Learning classifier systems (LCS) are a family of rule-based machine learning algorithms that combine a detection component, typically a genetic algorithm, with a learning component that performs either supervised learning, reinforcement learning, or unsupervised learning.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 29], [29, 32], [32, 33], [34, 37], [38, 39], [40, 46], [47, 49], [50, 54], [54, 55], [55, 60], [61, 68], [69, 77], [78, 88], [89, 93], [94, 101], [102, 103], [104, 113], [114, 123], [123, 124], [125, 134], [135, 136], [137, 144], [145, 154], [154, 155], [156, 160], [161, 162], [163, 171], [172, 181], [182, 186], [187, 195], [196, 202], [203, 213], [214, 222], [222, 223], [224, 237], [238, 246], [246, 247], [248, 250], [251, 263], [264, 272], [272, 273]]}
{"doc_key": "ai-dev-209", "ner": [[14, 14, "algorithm"], [19, 19, "algorithm"], [27, 28, "algorithm"], [31, 33, "misc"], [42, 44, "algorithm"], [52, 56, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 14, 27, 28, "origin", "", false, false], [14, 14, 31, 33, "usage", "", false, false], [19, 19, 14, 14, "named", "", false, false], [42, 44, 31, 33, "type-of", "", false, false], [42, 44, 52, 56, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "unknown", "parameters", "in", "each", "\u03b2subk", "/", "sub", "vector", "are", "typically", "jointly", "estimated", "using", "maximum", "a", "posteriori", "estimation", "(", "MAP", ")", ",", "which", "is", "an", "extension", "of", "maximum", "likelihood", "using", "a", "regularization", "of", "the", "weights", "to", "prevent", "pathological", "solutions", "(", "usually", "a", "quadratic", "regularizing", "function", ",", "which", "is", "equivalent", "to", "placing", "a", "zero", "mean", "Gaussian", "prior", "distribution", "on", "the", "weights", ",", "but", "other", "distributions", "are", "also", "possible", ")", "."], "sentence-detokenized": "The unknown parameters in each \u03b2subk/sub vector are typically jointly estimated using maximum a posteriori estimation (MAP), which is an extension of maximum likelihood using a regularization of the weights to prevent pathological solutions (usually a quadratic regularizing function, which is equivalent to placing a zero mean Gaussian prior distribution on the weights, but other distributions are also possible).", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 25], [26, 30], [31, 36], [36, 37], [37, 40], [41, 47], [48, 51], [52, 61], [62, 69], [70, 79], [80, 85], [86, 93], [94, 95], [96, 106], [107, 117], [118, 119], [119, 122], [122, 123], [123, 124], [125, 130], [131, 133], [134, 136], [137, 146], [147, 149], [150, 157], [158, 168], [169, 174], [175, 176], [177, 191], [192, 194], [195, 198], [199, 206], [207, 209], [210, 217], [218, 230], [231, 240], [241, 242], [242, 249], [250, 251], [252, 261], [262, 274], [275, 283], [283, 284], [285, 290], [291, 293], [294, 304], [305, 307], [308, 315], [316, 317], [318, 322], [323, 327], [328, 336], [337, 342], [343, 355], [356, 358], [359, 362], [363, 370], [370, 371], [372, 375], [376, 381], [382, 395], [396, 399], [400, 404], [405, 413], [413, 414], [414, 415]]}
{"doc_key": "ai-dev-210", "ner": [[9, 9, "researcher"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 12, 9, 9, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "hierarchical", "structure", "of", "words", "was", "clearly", "reflected", "in", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "The hierarchical structure of words was clearly reflected in George Miller's Wordnet.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 29], [30, 35], [36, 39], [40, 47], [48, 57], [58, 60], [61, 67], [68, 74], [74, 76], [77, 84], [84, 85]]}
{"doc_key": "ai-dev-211", "ner": [[7, 14, "conference"], [17, 21, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 21, 7, 14, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "illustration", "of", "their", "capabilities", "is", "the", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", ",", "a", "benchmark", "in", "object", "classification", "and", "detection", "involving", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "An illustration of their capabilities is the ImageNet Large Scale Visual Recognition Challenge, a benchmark in object classification and detection involving millions of images and hundreds of object classes.", "token2charspan": [[0, 2], [3, 15], [16, 18], [19, 24], [25, 37], [38, 40], [41, 44], [45, 53], [54, 59], [60, 65], [66, 72], [73, 84], [85, 94], [94, 95], [96, 97], [98, 107], [108, 110], [111, 117], [118, 132], [133, 136], [137, 146], [147, 156], [157, 165], [166, 168], [169, 175], [176, 179], [180, 188], [189, 191], [192, 198], [199, 206], [206, 207]]}
{"doc_key": "ai-dev-212", "ner": [[1, 2, "misc"], [24, 24, "misc"], [26, 28, "person"], [30, 30, "misc"], [36, 39, "person"], [42, 44, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[24, 24, 1, 2, "general-affiliation", "", false, false], [30, 30, 1, 2, "general-affiliation", "", false, false], [30, 30, 26, 28, "artifact", "", false, false], [42, 44, 1, 2, "general-affiliation", "", false, false], [42, 44, 36, 39, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "science", "fiction", ",", "female", "robots", "are", "often", "created", "to", "be", "used", "as", "domestic", "servants", "and", "sex", "slaves", ",", "as", "shown", "in", "the", "film", "Westworld", ",", "Paul", "McAuley", "'s", "novel", "Fairyland", "(", "1995", ")", ",", "and", "Lester", "Del", "Rey", "'s", "short", "story", "Helen", "O'", "Loy", "(", "1938", ")", ",", "and", "sometimes", "as", "warriors", ",", "assassins", ",", "or", "laborers", "."], "sentence-detokenized": "In science fiction, female robots are often created to be used as domestic servants and sex slaves, as shown in the film Westworld, Paul McAuley's novel Fairyland (1995), and Lester Del Rey's short story Helen O'Loy (1938), and sometimes as warriors, assassins, or laborers.", "token2charspan": [[0, 2], [3, 10], [11, 18], [18, 19], [20, 26], [27, 33], [34, 37], [38, 43], [44, 51], [52, 54], [55, 57], [58, 62], [63, 65], [66, 74], [75, 83], [84, 87], [88, 91], [92, 98], [98, 99], [100, 102], [103, 108], [109, 111], [112, 115], [116, 120], [121, 130], [130, 131], [132, 136], [137, 144], [144, 146], [147, 152], [153, 162], [163, 164], [164, 168], [168, 169], [169, 170], [171, 174], [175, 181], [182, 185], [186, 189], [189, 191], [192, 197], [198, 203], [204, 209], [210, 212], [212, 215], [216, 217], [217, 221], [221, 222], [222, 223], [224, 227], [228, 237], [238, 240], [241, 249], [249, 250], [251, 260], [260, 261], [262, 264], [265, 273], [273, 274]]}
{"doc_key": "ai-dev-213", "ner": [[0, 1, "task"], [3, 4, "task"], [6, 7, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["answering", "questions", ",", "speech", "recognition", "and", "machine", "translation", "."], "sentence-detokenized": "answering questions, speech recognition and machine translation.", "token2charspan": [[0, 9], [10, 19], [19, 20], [21, 27], [28, 39], [40, 43], [44, 51], [52, 63], [63, 64]]}
{"doc_key": "ai-dev-214", "ner": [[5, 6, "researcher"], [9, 13, "organisation"], [15, 18, "location"], [21, 21, "location"], [23, 23, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 9, 13, "role", "", false, false], [9, 13, 15, 18, "physical", "", false, false], [15, 18, 21, 21, "physical", "", false, false], [21, 21, 23, 23, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "his", "seminal", "work", ",", "Harry", "Blum", "of", "the", "Cambridge", "Air", "Force", "Research", "Laboratory", "at", "Hanscom", "Air", "Force", "Base", ",", "in", "Bedford", ",", "Massachusetts", ",", "defined", "the", "medial", "axis", "to", "calculate", "the", "skeleton", "of", "a", "figure", "using", "an", "intuitive", "model", "of", "fire", "spread", "on", "a", "grass", "field", "where", "the", "field", "has", "a", "given", "shape", "."], "sentence-detokenized": "In his seminal work, Harry Blum of the Cambridge Air Force Research Laboratory at Hanscom Air Force Base, in Bedford, Massachusetts, defined the medial axis to calculate the skeleton of a figure using an intuitive model of fire spread on a grass field where the field has a given shape.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 19], [19, 20], [21, 26], [27, 31], [32, 34], [35, 38], [39, 48], [49, 52], [53, 58], [59, 67], [68, 78], [79, 81], [82, 89], [90, 93], [94, 99], [100, 104], [104, 105], [106, 108], [109, 116], [116, 117], [118, 131], [131, 132], [133, 140], [141, 144], [145, 151], [152, 156], [157, 159], [160, 169], [170, 173], [174, 182], [183, 185], [186, 187], [188, 194], [195, 200], [201, 203], [204, 213], [214, 219], [220, 222], [223, 227], [228, 234], [235, 237], [238, 239], [240, 245], [246, 251], [252, 257], [258, 261], [262, 267], [268, 271], [272, 273], [274, 279], [280, 285], [285, 286]]}
{"doc_key": "ai-dev-215", "ner": [[15, 15, "algorithm"], [17, 17, "algorithm"], [20, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 15, 20, 21, "compare", "", false, false], [17, 17, 20, 21, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "unlike", "boosting", "algorithms", "that", "analytically", "minimize", "a", "convex", "loss", "function", "(", "e.g.", ",", "AdaBoost", "and", "LogitBoost", ")", ",", "Brown", "Boost", "solves", "a", "system", "of", "two", "equations", "and", "two", "unknowns", "using", "standard", "numerical", "methods", "."], "sentence-detokenized": "However, unlike boosting algorithms that analytically minimize a convex loss function (e.g., AdaBoost and LogitBoost), BrownBoost solves a system of two equations and two unknowns using standard numerical methods.", "token2charspan": [[0, 7], [7, 8], [9, 15], [16, 24], [25, 35], [36, 40], [41, 53], [54, 62], [63, 64], [65, 71], [72, 76], [77, 85], [86, 87], [87, 91], [91, 92], [93, 101], [102, 105], [106, 116], [116, 117], [117, 118], [119, 124], [124, 129], [130, 136], [137, 138], [139, 145], [146, 148], [149, 152], [153, 162], [163, 166], [167, 170], [171, 179], [180, 185], [186, 194], [195, 204], [205, 212], [212, 213]]}
{"doc_key": "ai-dev-216", "ner": [[0, 0, "researcher"], [8, 9, "misc"], [18, 24, "conference"], [26, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 8, 9, "win-defeat", "", false, false], [0, 0, 18, 24, "role", "", false, false], [26, 26, 18, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Getur", "has", "numerous", "best", "paper", "awards", ",", "an", "NSF", "career", "award", ",", "and", "is", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Getur has numerous best paper awards, an NSF career award, and is a member of the Association for the Advancement of Artificial Intelligence (AAAI).", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 23], [24, 29], [30, 36], [36, 37], [38, 40], [41, 44], [45, 51], [52, 57], [57, 58], [59, 62], [63, 65], [66, 67], [68, 74], [75, 77], [78, 81], [82, 93], [94, 97], [98, 101], [102, 113], [114, 116], [117, 127], [128, 140], [141, 142], [142, 146], [146, 147], [147, 148]]}
{"doc_key": "ai-dev-217", "ner": [[0, 1, "misc"], [6, 12, "misc"], [17, 17, "misc"], [23, 30, "misc"], [35, 37, "misc"], [38, 43, "university"], [48, 55, "misc"], [60, 68, "misc"], [73, 77, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["ACM", "Fellow", "(", "2015", ")", "br", "Fellow", "of", "the", "Association", "for", "Computational", "Linguistics", "(", "2011", ")", "br", "AAAI", "Fellow", "(", "1994", ")", "br", "Fellow", "of", "the", "International", "Association", "for", "Speech", "Communications", "(", "2011", ")", "br", "Honorary", "Doctor", "of", "the", "Royal", "Institute", "of", "Technology", "KTH", "(", "2007", ")", "br", "Columbia", "Engineering", "Alumni", "Association", "Outstanding", "Faculty", "Lecturer", "Award", "(", "2009", ")", "br", "IEEE", "James", "L.", "Flanagan", "Speech", "and", "Audio", "Processing", "Award", "(", "2011", ")", "br", "ISCA", "medal", "for", "scientific", "achievements", "(", "2011", ")"], "sentence-detokenized": "ACM Fellow (2015) br Fellow of the Association for Computational Linguistics (2011) br AAAI Fellow (1994) br Fellow of the International Association for Speech Communications (2011) br Honorary Doctor of the Royal Institute of Technology KTH (2007) br Columbia Engineering Alumni Association Outstanding Faculty Lecturer Award (2009) br IEEE James L. Flanagan Speech and Audio Processing Award (2011) br ISCA medal for scientific achievements (2011)", "token2charspan": [[0, 3], [4, 10], [11, 12], [12, 16], [16, 17], [18, 20], [21, 27], [28, 30], [31, 34], [35, 46], [47, 50], [51, 64], [65, 76], [77, 78], [78, 82], [82, 83], [84, 86], [87, 91], [92, 98], [99, 100], [100, 104], [104, 105], [106, 108], [109, 115], [116, 118], [119, 122], [123, 136], [137, 148], [149, 152], [153, 159], [160, 174], [175, 176], [176, 180], [180, 181], [182, 184], [185, 193], [194, 200], [201, 203], [204, 207], [208, 213], [214, 223], [224, 226], [227, 237], [238, 241], [242, 243], [243, 247], [247, 248], [249, 251], [252, 260], [261, 272], [273, 279], [280, 291], [292, 303], [304, 311], [312, 320], [321, 326], [327, 328], [328, 332], [332, 333], [334, 336], [337, 341], [342, 347], [348, 350], [351, 359], [360, 366], [367, 370], [371, 376], [377, 387], [388, 393], [394, 395], [395, 399], [399, 400], [401, 403], [404, 408], [409, 414], [415, 418], [419, 429], [430, 442], [443, 444], [444, 448], [448, 449]]}
{"doc_key": "ai-dev-218", "ner": [[6, 7, "university"], [15, 17, "task"], [29, 36, "metrics"], [43, 45, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[29, 36, 43, 45, "opposite", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["An", "unfortunate", "result", "of", "the", "same", "Stanford", "University", "study", "(", "and", "other", "attempts", "to", "improve", "name", "recognition", "translation", ")", "is", "that", "in", "many", "cases", ",", "the", "decline", "in", "the", "understudy", "'s", "score", "on", "the", "bilingual", "translation", "evaluation", "will", "be", "the", "result", "of", "incorporating", "named", "entity", "translation", "methods", "."], "sentence-detokenized": "An unfortunate result of the same Stanford University study (and other attempts to improve name recognition translation) is that in many cases, the decline in the understudy's score on the bilingual translation evaluation will be the result of incorporating named entity translation methods.", "token2charspan": [[0, 2], [3, 14], [15, 21], [22, 24], [25, 28], [29, 33], [34, 42], [43, 53], [54, 59], [60, 61], [61, 64], [65, 70], [71, 79], [80, 82], [83, 90], [91, 95], [96, 107], [108, 119], [119, 120], [121, 123], [124, 128], [129, 131], [132, 136], [137, 142], [142, 143], [144, 147], [148, 155], [156, 158], [159, 162], [163, 173], [173, 175], [176, 181], [182, 184], [185, 188], [189, 198], [199, 210], [211, 221], [222, 226], [227, 229], [230, 233], [234, 240], [241, 243], [244, 257], [258, 263], [264, 270], [271, 282], [283, 290], [290, 291]]}
{"doc_key": "ai-dev-219", "ner": [[0, 0, "organisation"], [12, 14, "organisation"], [17, 22, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 12, 14, "role", "works_with", false, false], [0, 0, 17, 22, "role", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Medtronic", "is", "using", "the", "PM", "data", "collected", "and", "working", "with", "researchers", "at", "Johns", "Hopkins", "Hospital", "and", "the", "University", "of", "Washington", "School", "of", "Medicine", "to", "help", "answer", "specific", "questions", "about", "heart", "disease", ",", "such", "as", "whether", "a", "weak", "heart", "causes", "arrhythmias", "or", "vice", "versa", "."], "sentence-detokenized": "Medtronic is using the PM data collected and working with researchers at Johns Hopkins Hospital and the University of Washington School of Medicine to help answer specific questions about heart disease, such as whether a weak heart causes arrhythmias or vice versa.", "token2charspan": [[0, 9], [10, 12], [13, 18], [19, 22], [23, 25], [26, 30], [31, 40], [41, 44], [45, 52], [53, 57], [58, 69], [70, 72], [73, 78], [79, 86], [87, 95], [96, 99], [100, 103], [104, 114], [115, 117], [118, 128], [129, 135], [136, 138], [139, 147], [148, 150], [151, 155], [156, 162], [163, 171], [172, 181], [182, 187], [188, 193], [194, 201], [201, 202], [203, 207], [208, 210], [211, 218], [219, 220], [221, 225], [226, 231], [232, 238], [239, 250], [251, 253], [254, 258], [259, 264], [264, 265]]}
{"doc_key": "ai-dev-220", "ner": [[4, 8, "organisation"], [10, 10, "misc"], [13, 14, "person"], [16, 17, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 10, 4, 8, "artifact", "made_by_studio", false, false], [13, 14, 10, 10, "role", "", false, false], [16, 17, 10, 10, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "was", "followed", "by", "Paramount", "'s", "first", "feature", "film", "\"", "Sangari", "\"", "with", "Fernando", "Lamas", "and", "Arlene", "Dahl", "."], "sentence-detokenized": "This was followed by Paramount's first feature film \"Sangari\" with Fernando Lamas and Arlene Dahl.", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 20], [21, 30], [30, 32], [33, 38], [39, 46], [47, 51], [52, 53], [53, 60], [60, 61], [62, 66], [67, 75], [76, 81], [82, 85], [86, 92], [93, 97], [97, 98]]}
{"doc_key": "ai-dev-221", "ner": [[0, 0, "programlang"], [8, 10, "researcher"], [12, 14, "researcher"], [15, 16, "organisation"], [18, 19, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 10, "origin", "", false, false], [0, 0, 12, 14, "origin", "", false, false], [8, 10, 15, 16, "physical", "", false, false], [8, 10, 15, 16, "role", "", false, false], [12, 14, 18, 19, "physical", "", false, false], [12, 14, 18, 19, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["KRL", "is", "a", "knowledge", "representation", "language", "developed", "by", "Daniel", "G.", "Bobrow", "and", "Terry", "Winograd", "at", "Xerox", "PARC", "and", "Stanford", "University", "respectively", "."], "sentence-detokenized": "KRL is a knowledge representation language developed by Daniel G. Bobrow and Terry Winograd at Xerox PARC and Stanford University respectively.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 18], [19, 33], [34, 42], [43, 52], [53, 55], [56, 62], [63, 65], [66, 72], [73, 76], [77, 82], [83, 91], [92, 94], [95, 100], [101, 105], [106, 109], [110, 118], [119, 129], [130, 142], [142, 143]]}
{"doc_key": "ai-dev-222", "ner": [[2, 9, "conference"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"], [33, 34, "task"], [36, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 9, 33, 34, "topic", "", true, false], [13, 14, 2, 9, "physical", "", false, false], [13, 14, 2, 9, "role", "", false, false], [13, 14, 2, 9, "temporal", "", false, false], [16, 17, 2, 9, "physical", "", false, false], [16, 17, 2, 9, "role", "", false, false], [16, 17, 2, 9, "temporal", "", false, false], [19, 20, 2, 9, "physical", "", false, false], [19, 20, 2, 9, "role", "", false, false], [19, 20, 2, 9, "temporal", "", false, false], [22, 25, 2, 9, "physical", "", false, false], [22, 25, 2, 9, "role", "", false, false], [22, 25, 2, 9, "temporal", "", false, false], [33, 34, 36, 38, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["At", "the", "IEEE", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "in", "2006", ",", "Qian", "Zhu", ",", "Shai", "Avidan", ",", "Mei-Chen", "Ye", "and", "Kwan", "-", "Ting", "Cheng", "presented", "an", "algorithm", "that", "significantly", "speeds", "up", "human", "detection", "using", "HOG", "descriptor", "methods", "."], "sentence-detokenized": "At the IEEE Conference on Computer Vision and Pattern Recognition in 2006, Qian Zhu, Shai Avidan, Mei-Chen Ye and Kwan-Ting Cheng presented an algorithm that significantly speeds up human detection using HOG descriptor methods.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 22], [23, 25], [26, 34], [35, 41], [42, 45], [46, 53], [54, 65], [66, 68], [69, 73], [73, 74], [75, 79], [80, 83], [83, 84], [85, 89], [90, 96], [96, 97], [98, 106], [107, 109], [110, 113], [114, 118], [118, 119], [119, 123], [124, 129], [130, 139], [140, 142], [143, 152], [153, 157], [158, 171], [172, 178], [179, 181], [182, 187], [188, 197], [198, 203], [204, 207], [208, 218], [219, 226], [226, 227]]}
{"doc_key": "ai-dev-223", "ner": [[0, 0, "researcher"], [5, 5, "conference"], [8, 10, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 5, 5, "role", "", false, false], [0, 0, 8, 10, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hayes", "is", "a", "Fellow", "of", "AAAI", "and", "the", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Hayes is a Fellow of AAAI and the Cognitive Science Society.", "token2charspan": [[0, 5], [6, 8], [9, 10], [11, 17], [18, 20], [21, 25], [26, 29], [30, 33], [34, 43], [44, 51], [52, 59], [59, 60]]}
{"doc_key": "ai-dev-224", "ner": [[0, 2, "misc"], [5, 5, "field"], [7, 8, "field"], [10, 11, "field"], [13, 13, "field"], [15, 16, "field"], [18, 19, "field"], [21, 22, "field"], [24, 24, "field"], [26, 27, "field"], [29, 29, "field"], [31, 32, "field"], [43, 44, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[0, 2, 5, 5, "part-of", "", false, false], [0, 2, 5, 5, "usage", "", false, false], [0, 2, 7, 8, "part-of", "", false, false], [0, 2, 7, 8, "usage", "", false, false], [0, 2, 10, 11, "part-of", "", false, false], [0, 2, 10, 11, "usage", "", false, false], [0, 2, 13, 13, "part-of", "", false, false], [0, 2, 13, 13, "usage", "", false, false], [0, 2, 15, 16, "part-of", "", false, false], [0, 2, 15, 16, "usage", "", false, false], [0, 2, 18, 19, "part-of", "", false, false], [0, 2, 18, 19, "usage", "", false, false], [0, 2, 21, 22, "part-of", "", false, false], [0, 2, 21, 22, "usage", "", false, false], [0, 2, 24, 24, "part-of", "", false, false], [0, 2, 24, 24, "usage", "", false, false], [0, 2, 26, 27, "part-of", "", false, false], [0, 2, 26, 27, "usage", "", false, false], [0, 2, 29, 29, "part-of", "", false, false], [0, 2, 29, 29, "usage", "", false, false], [0, 2, 31, 32, "part-of", "", false, false], [0, 2, 31, 32, "usage", "", false, false], [0, 2, 43, 44, "part-of", "", false, false], [0, 2, 43, 44, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "sentence": ["Time", "series", "are", "used", "in", "statistics", ",", "signal", "processing", ",", "pattern", "recognition", ",", "econometrics", ",", "mathematical", "finance", ",", "weather", "forecasting", ",", "earthquake", "prediction", ",", "electroencephalography", ",", "control", "engineering", ",", "astronomy", ",", "communications", "engineering", ",", "and", "to", "a", "large", "extent", "in", "any", "field", "of", "applied", "science", "and", "technology", "that", "involves", "temporal", "measurements", "."], "sentence-detokenized": "Time series are used in statistics, signal processing, pattern recognition, econometrics, mathematical finance, weather forecasting, earthquake prediction, electroencephalography, control engineering, astronomy, communications engineering, and to a large extent in any field of applied science and technology that involves temporal measurements.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 23], [24, 34], [34, 35], [36, 42], [43, 53], [53, 54], [55, 62], [63, 74], [74, 75], [76, 88], [88, 89], [90, 102], [103, 110], [110, 111], [112, 119], [120, 131], [131, 132], [133, 143], [144, 154], [154, 155], [156, 178], [178, 179], [180, 187], [188, 199], [199, 200], [201, 210], [210, 211], [212, 226], [227, 238], [238, 239], [240, 243], [244, 246], [247, 248], [249, 254], [255, 261], [262, 264], [265, 268], [269, 274], [275, 277], [278, 285], [286, 293], [294, 297], [298, 308], [309, 313], [314, 322], [323, 331], [332, 344], [344, 345]]}
{"doc_key": "ai-dev-225", "ner": [[14, 15, "metrics"], [37, 39, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "principle", ",", "the", "exact", "recovery", "can", "be", "solved", "in", "its", "feasible", "range", "using", "maximum", "likelihood", ",", "but", "this", "amounts", "to", "solving", "a", "constrained", "or", "regularized", "section", "problem", "such", "as", "the", "minimum", "bisection", ",", "which", "is", "typically", "NP", "-", "complete", "."], "sentence-detokenized": "In principle, the exact recovery can be solved in its feasible range using maximum likelihood, but this amounts to solving a constrained or regularized section problem such as the minimum bisection, which is typically NP-complete.", "token2charspan": [[0, 2], [3, 12], [12, 13], [14, 17], [18, 23], [24, 32], [33, 36], [37, 39], [40, 46], [47, 49], [50, 53], [54, 62], [63, 68], [69, 74], [75, 82], [83, 93], [93, 94], [95, 98], [99, 103], [104, 111], [112, 114], [115, 122], [123, 124], [125, 136], [137, 139], [140, 151], [152, 159], [160, 167], [168, 172], [173, 175], [176, 179], [180, 187], [188, 197], [197, 198], [199, 204], [205, 207], [208, 217], [218, 220], [220, 221], [221, 229], [229, 230]]}
{"doc_key": "ai-dev-226", "ner": [[2, 3, "task"], [11, 11, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 11, 2, 3, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["in", "its", "pedestrian", "detection", "work", ",", "which", "was", "first", "described", "at", "BMVC", "in", "2009", "."], "sentence-detokenized": "in its pedestrian detection work, which was first described at BMVC in 2009.", "token2charspan": [[0, 2], [3, 6], [7, 17], [18, 27], [28, 32], [32, 33], [34, 39], [40, 43], [44, 49], [50, 59], [60, 62], [63, 67], [68, 70], [71, 75], [75, 76]]}
{"doc_key": "ai-dev-227", "ner": [[5, 9, "conference"], [11, 11, "researcher"], [14, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 5, 9, "physical", "", false, false], [11, 11, 5, 9, "role", "", false, false], [11, 11, 14, 22, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2007", ",", "at", "the", "International", "Conference", "on", "Computer", "Vision", ",", "Terzopoulos", "was", "awarded", "the", "first", "IEEE", "PAMI", "Computer", "Vision", "Distinguished", "Researcher", "Award", "for", "his", "pioneering", "and", "sustained", "research", "on", "deformable", "models", "and", "their", "applications", "."], "sentence-detokenized": "In 2007, at the International Conference on Computer Vision, Terzopoulos was awarded the first IEEE PAMI Computer Vision Distinguished Researcher Award for his pioneering and sustained research on deformable models and their applications.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 29], [30, 40], [41, 43], [44, 52], [53, 59], [59, 60], [61, 72], [73, 76], [77, 84], [85, 88], [89, 94], [95, 99], [100, 104], [105, 113], [114, 120], [121, 134], [135, 145], [146, 151], [152, 155], [156, 159], [160, 170], [171, 174], [175, 184], [185, 193], [194, 196], [197, 207], [208, 214], [215, 218], [219, 224], [225, 237], [237, 238]]}
{"doc_key": "ai-dev-228", "ner": [[0, 0, "task"], [1, 4, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 1, 4, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cluster", "analysis", "or", "cluster", "analysis", "involves", "dividing", "data", "points", "into", "clusters", "so", "that", "items", "in", "the", "same", "cluster", "are", "as", "similar", "as", "possible", "and", "items", "belonging", "to", "different", "clusters", "are", "as", "different", "as", "possible", "."], "sentence-detokenized": "Cluster analysis or cluster analysis involves dividing data points into clusters so that items in the same cluster are as similar as possible and items belonging to different clusters are as different as possible.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 27], [28, 36], [37, 45], [46, 54], [55, 59], [60, 66], [67, 71], [72, 80], [81, 83], [84, 88], [89, 94], [95, 97], [98, 101], [102, 106], [107, 114], [115, 118], [119, 121], [122, 129], [130, 132], [133, 141], [142, 145], [146, 151], [152, 161], [162, 164], [165, 174], [175, 183], [184, 187], [188, 190], [191, 200], [201, 203], [204, 212], [212, 213]]}
{"doc_key": "ai-dev-229", "ner": [[8, 8, "field"], [16, 16, "field"], [19, 20, "task"], [22, 22, "field"], [26, 26, "field"], [29, 29, "field"], [9, 36, "field"], [38, 39, "task"], [41, 41, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[8, 8, 16, 16, "named", "", false, false], [8, 8, 22, 22, "named", "", false, false], [8, 8, 29, 29, "named", "", false, false], [19, 20, 16, 16, "part-of", "task_part_of_field", false, false], [26, 26, 22, 22, "part-of", "", false, false], [9, 36, 29, 29, "part-of", "", false, false], [38, 39, 9, 36, "part-of", "", false, false], [41, 41, 9, 36, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["(", "2005", ")", ",", "three", "different", "perspectives", "of", "text", "mining", "can", "be", "distinguished", ",", "namely", ":", "text", "mining", "as", "information", "extraction", ",", "text", "mining", "as", "text", "data", "extraction", "and", "text", "mining", "as", "a", "process", "of", "Data", "Mining", "(", "Knowledge", "Discovery", "in", "Databases", ")", ".", "Hotho", ",", "A.", ",", "N\u00fcrnberger", ",", "A.", "and", "Paa\u00df", ",", "G.", "(", "2005", ")", "."], "sentence-detokenized": "(2005), three different perspectives of text mining can be distinguished, namely: text mining as information extraction, text mining as text data extraction and text mining as a process of Data Mining (Knowledge Discovery in Databases).Hotho, A., N\u00fcrnberger, A. and Paa\u00df, G. (2005).", "token2charspan": [[0, 1], [1, 5], [5, 6], [6, 7], [8, 13], [14, 23], [24, 36], [37, 39], [40, 44], [45, 51], [52, 55], [56, 58], [59, 72], [72, 73], [74, 80], [80, 81], [82, 86], [87, 93], [94, 96], [97, 108], [109, 119], [119, 120], [121, 125], [126, 132], [133, 135], [136, 140], [141, 145], [146, 156], [157, 160], [161, 165], [166, 172], [173, 175], [176, 177], [178, 185], [186, 188], [189, 193], [194, 200], [201, 202], [202, 211], [212, 221], [222, 224], [225, 234], [234, 235], [235, 236], [236, 241], [241, 242], [243, 245], [245, 246], [247, 257], [257, 258], [259, 261], [262, 265], [266, 270], [270, 271], [272, 274], [275, 276], [276, 280], [280, 281], [281, 282]]}
{"doc_key": "ai-dev-230", "ner": [[0, 2, "product"], [14, 20, "location"], [22, 22, "location"], [24, 35, "university"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[0, 2, 14, 20, "related-to", "developed_for", false, false], [14, 20, 22, 22, "physical", "", false, false], [24, 35, 0, 2, "role", "buys", false, false]], "relations_mapping_to_source": [0, 1, 3], "sentence": ["The", "Rancho", "Arm", "was", "developed", "as", "a", "robotic", "arm", "to", "assist", "disabled", "patients", "at", "the", "Rancho", "Los", "Amigos", "National", "Rehabilitation", "Center", "in", "Downey", ",", "California", ";", "this", "computer", "-", "controlled", "arm", "was", "purchased", "by", "Stanford", "University", "in", "1963", "."], "sentence-detokenized": "The Rancho Arm was developed as a robotic arm to assist disabled patients at the Rancho Los Amigos National Rehabilitation Center in Downey, California; this computer-controlled arm was purchased by Stanford University in 1963.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 18], [19, 28], [29, 31], [32, 33], [34, 41], [42, 45], [46, 48], [49, 55], [56, 64], [65, 73], [74, 76], [77, 80], [81, 87], [88, 91], [92, 98], [99, 107], [108, 122], [123, 129], [130, 132], [133, 139], [139, 140], [141, 151], [151, 152], [153, 157], [158, 166], [166, 167], [167, 177], [178, 181], [182, 185], [186, 195], [196, 198], [199, 207], [208, 218], [219, 221], [222, 226], [226, 227]]}
{"doc_key": "ai-dev-231", "ner": [[1, 1, "university"], [3, 3, "researcher"], [9, 12, "organisation"], [19, 22, "organisation"], [26, 27, "researcher"], [29, 31, "researcher"], [44, 46, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 3, 1, 1, "physical", "", false, false], [3, 3, 1, 1, "role", "", false, false], [3, 3, 9, 12, "role", "founder", false, false], [3, 3, 19, 22, "role", "founder", false, false], [19, 22, 44, 46, "physical", "", false, false], [26, 27, 19, 22, "role", "founder", false, false], [29, 31, 19, 22, "role", "founder", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["At", "UCU", ",", "Norman", "was", "the", "founder", "of", "the", "Institute", "for", "Cognitive", "Science", "and", "one", "of", "the", "organizers", "of", "the", "Cognitive", "Science", "Society", "(", "along", "with", "Roger", "Shenk", ",", "Allan", "M.", "Collins", "and", "others", ")", ",", "which", "held", "it", "s", "first", "meeting", "on", "the", "UCU", "campus", "in", "1979", "."], "sentence-detokenized": "At UCU, Norman was the founder of the Institute for Cognitive Science and one of the organizers of the Cognitive Science Society (along with Roger Shenk, Allan M. Collins and others), which held its first meeting on the UCU campus in 1979.", "token2charspan": [[0, 2], [3, 6], [6, 7], [8, 14], [15, 18], [19, 22], [23, 30], [31, 33], [34, 37], [38, 47], [48, 51], [52, 61], [62, 69], [70, 73], [74, 77], [78, 80], [81, 84], [85, 95], [96, 98], [99, 102], [103, 112], [113, 120], [121, 128], [129, 130], [130, 135], [136, 140], [141, 146], [147, 152], [152, 153], [154, 159], [160, 162], [163, 170], [171, 174], [175, 181], [181, 182], [182, 183], [184, 189], [190, 194], [195, 197], [197, 198], [199, 204], [205, 212], [213, 215], [216, 219], [220, 223], [224, 230], [231, 233], [234, 238], [238, 239]]}
{"doc_key": "ai-dev-232", "ner": [[6, 7, "product"], [9, 10, "product"], [12, 13, "product"], [17, 18, "product"], [20, 21, "product"], [23, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 21, 17, 18, "type-of", "", false, false], [23, 28, 17, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "common", "robot", "configurations", "are", "articulated", "robots", ",", "SCARA", "robots", ",", "delta", "robots", "and", "robots", "with", "Cartesian", "coordinates", "(", "gantry", "robots", "or", "x", "-", "y", "-", "z", "robots", ")", "."], "sentence-detokenized": "The most common robot configurations are articulated robots, SCARA robots, delta robots and robots with Cartesian coordinates (gantry robots or x-y-z robots).", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 21], [22, 36], [37, 40], [41, 52], [53, 59], [59, 60], [61, 66], [67, 73], [73, 74], [75, 80], [81, 87], [88, 91], [92, 98], [99, 103], [104, 113], [114, 125], [126, 127], [127, 133], [134, 140], [141, 143], [144, 145], [145, 146], [146, 147], [147, 148], [148, 149], [150, 156], [156, 157], [157, 158]]}
{"doc_key": "ai-dev-233", "ner": [[9, 9, "programlang"], [10, 11, "misc"], [16, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 9, 9, "part-of", "", false, false], [16, 16, 10, 11, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "addition", ",", "it", "can", "be", "used", "directly", "with", "Perl", "Module", "TM", "(", "which", "also", "supports", "LTM", ")", "."], "sentence-detokenized": "In addition, it can be used directly with Perl Module TM (which also supports LTM).", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 15], [16, 19], [20, 22], [23, 27], [28, 36], [37, 41], [42, 46], [47, 53], [54, 56], [57, 58], [58, 63], [64, 68], [69, 77], [78, 81], [81, 82], [82, 83]]}
{"doc_key": "ai-dev-234", "ner": [[4, 4, "country"], [7, 8, "organisation"], [16, 16, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 4, 4, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "winner", "was", "the", "US", "team", "from", "Newton", "Labs", ",", "and", "the", "competition", "was", "broadcast", "on", "CNN", "."], "sentence-detokenized": "The winner was the US team from Newton Labs, and the competition was broadcast on CNN.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 18], [19, 21], [22, 26], [27, 31], [32, 38], [39, 43], [43, 44], [45, 48], [49, 52], [53, 64], [65, 68], [69, 78], [79, 81], [82, 85], [85, 86]]}
{"doc_key": "ai-dev-235", "ner": [[0, 7, "misc"], [11, 13, "person"], [15, 16, "person"], [18, 22, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 13, 0, 7, "role", "directs", false, false], [15, 16, 0, 7, "role", "acts_in", false, false], [18, 22, 0, 7, "role", "acts_in", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "short", "film", "\"", "The", "Butler", "in", "Love", "\"", "directed", "by", "David", "Arquette", "and", "starring", "Elizabeth", "Berkeley", "and", "Thomas", "Jane", "was", "released", "on", "June", "23", ",", "2008", "."], "sentence-detokenized": "The short film \"The Butler in Love\" directed by David Arquette and starring Elizabeth Berkeley and Thomas Jane was released on June 23, 2008.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 16], [16, 19], [20, 26], [27, 29], [30, 34], [34, 35], [36, 44], [45, 47], [48, 53], [54, 62], [63, 66], [67, 75], [76, 85], [86, 94], [95, 98], [99, 105], [106, 110], [111, 114], [115, 123], [124, 126], [127, 131], [132, 134], [134, 135], [136, 140], [140, 141]]}
{"doc_key": "ai-dev-236", "ner": [[3, 5, "product"], [9, 10, "field"], [17, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 17, 17, "general-affiliation", "", false, false], [9, 10, 3, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "example", ",", "Word", "Net", "is", "a", "resource", "containing", "a", "taxonomy", "whose", "elements", "are", "the", "meanings", "of", "English", "words", "."], "sentence-detokenized": "For example, WordNet is a resource containing a taxonomy whose elements are the meanings of English words.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 17], [17, 20], [21, 23], [24, 25], [26, 34], [35, 45], [46, 47], [48, 56], [57, 62], [63, 71], [72, 75], [76, 79], [80, 88], [89, 91], [92, 99], [100, 105], [105, 106]]}
{"doc_key": "ai-dev-237", "ner": [[1, 3, "product"], [6, 6, "product"], [8, 8, "product"], [14, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 1, 3, "type-of", "", false, false], [6, 6, 14, 14, "related-to", "ability_to", false, false], [8, 8, 1, 3, "type-of", "", false, false], [8, 8, 14, 14, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Existing", "humanoid", "robotic", "systems", "such", "as", "ASIMO", "and", "QRIO", "use", "many", "motors", "to", "achieve", "locomotion", "."], "sentence-detokenized": "Existing humanoid robotic systems such as ASIMO and QRIO use many motors to achieve locomotion.", "token2charspan": [[0, 8], [9, 17], [18, 25], [26, 33], [34, 38], [39, 41], [42, 47], [48, 51], [52, 56], [57, 60], [61, 65], [66, 72], [73, 75], [76, 83], [84, 94], [94, 95]]}
{"doc_key": "ai-dev-238", "ner": [[0, 0, "metrics"], [11, 11, "metrics"], [13, 13, "metrics"], [15, 20, "misc"], [22, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 11, 0, 0, "part-of", "", false, false], [13, 13, 0, 0, "part-of", "", false, false], [15, 20, 0, 0, "part-of", "", false, false], [22, 22, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LEPOR", "is", "designed", "to", "take", "into", "account", "the", "factors", "of", "increased", "length", ",", "accuracy", ",", "n", "-", "gram", "word", "order", "penalty", "and", "recall", "."], "sentence-detokenized": "LEPOR is designed to take into account the factors of increased length, accuracy, n-gram word order penalty and recall.", "token2charspan": [[0, 5], [6, 8], [9, 17], [18, 20], [21, 25], [26, 30], [31, 38], [39, 42], [43, 50], [51, 53], [54, 63], [64, 70], [70, 71], [72, 80], [80, 81], [82, 83], [83, 84], [84, 88], [89, 93], [94, 99], [100, 107], [108, 111], [112, 118], [118, 119]]}
{"doc_key": "ai-dev-239", "ner": [[5, 10, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "based", "on", "the", "metric", "of", "the", "bilingual", "assessment", "understudy", ",", "but", "with", "some", "modifications", "."], "sentence-detokenized": "It is based on the metric of the bilingual assessment understudy, but with some modifications.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 14], [15, 18], [19, 25], [26, 28], [29, 32], [33, 42], [43, 53], [54, 64], [64, 65], [66, 69], [70, 74], [75, 79], [80, 93], [93, 94]]}
{"doc_key": "ai-dev-240", "ner": [[7, 7, "product"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "of", "implementation", "in", "MATLAB", "/", "Octave", ":"], "sentence-detokenized": "This is an example of implementation in MATLAB / Octave:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 36], [37, 39], [40, 46], [47, 48], [49, 55], [55, 56]]}
{"doc_key": "ai-dev-241", "ner": [[13, 13, "programlang"], [15, 15, "programlang"], [17, 17, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "designed", "to", "be", "used", "with", "a", "number", "of", "computer", "languages", "including", "Python", ",", "Ruby", "and", "Scheme", "."], "sentence-detokenized": "It is designed to be used with a number of computer languages including Python, Ruby and Scheme.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 20], [21, 25], [26, 30], [31, 32], [33, 39], [40, 42], [43, 51], [52, 61], [62, 71], [72, 78], [78, 79], [80, 84], [85, 88], [89, 95], [95, 96]]}
{"doc_key": "ai-dev-242", "ner": [[0, 2, "researcher"], [7, 7, "organisation"], [14, 14, "conference"], [21, 22, "academicjournal"], [27, 29, "organisation"], [35, 39, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 7, 7, "role", "", false, false], [0, 2, 14, 14, "role", "", false, false], [0, 2, 21, 22, "role", "", false, false], [0, 2, 27, 29, "role", "", false, false], [0, 2, 35, 39, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hayes", "has", "served", "as", "secretary", "of", "the", "AISB", ",", "chair", "and", "trustee", "of", "the", "IJCAI", ",", "associate", "editor", "of", "the", "journal", "Artificial", "Intelligence", ",", "chair", "of", "the", "Cognitive", "Science", "Society", ",", "and", "president", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "."], "sentence-detokenized": "Hayes has served as secretary of the AISB, chair and trustee of the IJCAI, associate editor of the journal Artificial Intelligence, chair of the Cognitive Science Society, and president of the American Association for Artificial Intelligence.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 29], [30, 32], [33, 36], [37, 41], [41, 42], [43, 48], [49, 52], [53, 60], [61, 63], [64, 67], [68, 73], [73, 74], [75, 84], [85, 91], [92, 94], [95, 98], [99, 106], [107, 117], [118, 130], [130, 131], [132, 137], [138, 140], [141, 144], [145, 154], [155, 162], [163, 170], [170, 171], [172, 175], [176, 185], [186, 188], [189, 192], [193, 201], [202, 213], [214, 217], [218, 228], [229, 241], [241, 242]]}
{"doc_key": "ai-dev-243", "ner": [[7, 12, "misc"], [18, 23, "misc"], [26, 27, "person"], [32, 36, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[26, 27, 7, 12, "role", "directed_by", false, false], [26, 27, 18, 23, "role", "directed_by", false, false], [26, 27, 32, 36, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "of", "them", ",", "\"", "It", "'s", "Time", "to", "Put", "on", "Your", "Glasses", "\"", "and", "\"", "All", "Around", "is", "All", "Around", "\"", ",", "were", "made", "by", "Norman", "McLaren", "in", "1951", "for", "the", "National", "Film", "Board", "of", "Canada", "."], "sentence-detokenized": "Two of them, \"It's Time to Put on Your Glasses\" and \"All Around is All Around\", were made by Norman McLaren in 1951 for the National Film Board of Canada.", "token2charspan": [[0, 3], [4, 6], [7, 11], [11, 12], [13, 14], [14, 16], [16, 18], [19, 23], [24, 26], [27, 30], [31, 33], [34, 38], [39, 46], [46, 47], [48, 51], [52, 53], [53, 56], [57, 63], [64, 66], [67, 70], [71, 77], [77, 78], [78, 79], [80, 84], [85, 89], [90, 92], [93, 99], [100, 107], [108, 110], [111, 115], [116, 119], [120, 123], [124, 132], [133, 137], [138, 143], [144, 146], [147, 153], [153, 154]]}
{"doc_key": "ai-dev-244", "ner": [[0, 2, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "recommendation", "system", "aims", "to", "predict", "which", "product", "the", "target", "user", "will", "prefer", "."], "sentence-detokenized": "The recommendation system aims to predict which product the target user will prefer.", "token2charspan": [[0, 3], [4, 18], [19, 25], [26, 30], [31, 33], [34, 41], [42, 47], [48, 55], [56, 59], [60, 66], [67, 71], [72, 76], [77, 83], [83, 84]]}
{"doc_key": "ai-dev-245", "ner": [[0, 0, "algorithm"], [7, 7, "field"], [9, 9, "field"], [11, 12, "field"], [14, 16, "field"], [18, 18, "field"], [20, 20, "field"], [23, 23, "field"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 7, 7, "part-of", "", true, false], [0, 0, 9, 9, "part-of", "", true, false], [0, 0, 11, 12, "part-of", "", true, false], [0, 0, 14, 16, "part-of", "", true, false], [0, 0, 18, 18, "part-of", "", true, false], [0, 0, 20, 20, "part-of", "", true, false], [0, 0, 23, 23, "part-of", "", true, false], [0, 0, 25, 26, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Convolution", "has", "applications", "in", "areas", "such", "as", "probability", ",", "statistics", ",", "computer", "vision", ",", "natural", "language", "processing", ",", "image", "and", "signal", "processing", ",", "engineering", "and", "differential", "equations", "."], "sentence-detokenized": "Convolution has applications in areas such as probability, statistics, computer vision, natural language processing, image and signal processing, engineering and differential equations.", "token2charspan": [[0, 11], [12, 15], [16, 28], [29, 31], [32, 37], [38, 42], [43, 45], [46, 57], [57, 58], [59, 69], [69, 70], [71, 79], [80, 86], [86, 87], [88, 95], [96, 104], [105, 115], [115, 116], [117, 122], [123, 126], [127, 133], [134, 144], [144, 145], [146, 157], [158, 161], [162, 174], [175, 184], [184, 185]]}
{"doc_key": "ai-dev-246", "ner": [[0, 0, "field"], [3, 5, "task"], [7, 8, "task"], [10, 10, "task"], [11, 11, "task"], [12, 12, "task"], [14, 15, "task"], [17, 18, "task"], [20, 21, "task"], [26, 27, "task"], [29, 29, "field"], [31, 31, "field"], [33, 35, "field"], [37, 37, "field"], [39, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15], "relations": [[0, 0, 3, 5, "part-of", "", true, false], [0, 0, 7, 8, "part-of", "", true, false], [0, 0, 10, 10, "part-of", "", true, false], [0, 0, 11, 11, "part-of", "", true, false], [0, 0, 12, 12, "part-of", "", true, false], [0, 0, 14, 15, "part-of", "", true, false], [0, 0, 17, 18, "part-of", "", true, false], [0, 0, 20, 21, "part-of", "", true, false], [0, 0, 26, 27, "part-of", "", true, false], [0, 0, 29, 29, "part-of", "", true, false], [0, 0, 31, 31, "part-of", "", true, false], [0, 0, 33, 35, "part-of", "", true, false], [0, 0, 37, 37, "part-of", "", true, false], [0, 0, 39, 39, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14], "sentence": ["DSP", "applications", "include", "audio", "signal", "processing", ",", "audio", "compression", ",", "digital", "image", "processing", ",", "video", "compression", ",", "speech", "processing", ",", "speech", "recognition", ",", "digital", "communications", ",", "digital", "synthesizers", ",", "radar", ",", "sonar", ",", "financial", "signal", "processing", ",", "seismology", "and", "biomedicine", "."], "sentence-detokenized": "DSP applications include audio signal processing, audio compression, digital image processing, video compression, speech processing, speech recognition, digital communications, digital synthesizers, radar, sonar, financial signal processing, seismology and biomedicine.", "token2charspan": [[0, 3], [4, 16], [17, 24], [25, 30], [31, 37], [38, 48], [48, 49], [50, 55], [56, 67], [67, 68], [69, 76], [77, 82], [83, 93], [93, 94], [95, 100], [101, 112], [112, 113], [114, 120], [121, 131], [131, 132], [133, 139], [140, 151], [151, 152], [153, 160], [161, 175], [175, 176], [177, 184], [185, 197], [197, 198], [199, 204], [204, 205], [206, 211], [211, 212], [213, 222], [223, 229], [230, 240], [240, 241], [242, 252], [253, 256], [257, 268], [268, 269]]}
{"doc_key": "ai-dev-247", "ner": [[13, 14, "misc"], [19, 19, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["(", "February", "20", ",", "1912", "-", "August", "11", ",", "2011", ")", "was", "an", "American", "inventor", "best", "known", "for", "creating", "Unimate", ",", "the", "first", "industrial", "robot", "."], "sentence-detokenized": "(February 20, 1912 - August 11, 2011) was an American inventor best known for creating Unimate, the first industrial robot.", "token2charspan": [[0, 1], [1, 9], [10, 12], [12, 13], [14, 18], [19, 20], [21, 27], [28, 30], [30, 31], [32, 36], [36, 37], [38, 41], [42, 44], [45, 53], [54, 62], [63, 67], [68, 73], [74, 77], [78, 86], [87, 94], [94, 95], [96, 99], [100, 105], [106, 116], [117, 122], [122, 123]]}
{"doc_key": "ai-dev-248", "ner": [[2, 4, "researcher"], [6, 8, "researcher"], [10, 10, "researcher"], [21, 23, "algorithm"], [26, 28, "algorithm"], [33, 34, "task"], [31, 32, "algorithm"], [42, 43, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[2, 4, 21, 23, "related-to", "writes_about", true, false], [6, 8, 21, 23, "related-to", "writes_about", true, false], [10, 10, 21, 23, "related-to", "writes_about", true, false], [21, 23, 26, 28, "related-to", "", true, false], [33, 34, 31, 32, "related-to", "", true, false], [42, 43, 31, 32, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Along", "with", "David", "E.", "Rumelhart", "and", "Ronald", "J.", "Williams", ",", "Hinton", "co-authored", "a", "highly", "cited", "paper", "published", "in", "1986", "that", "popularized", "a", "backpropagation", "algorithm", "for", "training", "multilayer", "neural", "networks", ",", "the", "Alex", "Net", "Image", "Recognition", "Dramatic", "Milestone", ",", "developed", "by", "his", "student", "Alex", "Kryzewski", "{", "{", "web", "link"], "sentence-detokenized": "Along with David E. Rumelhart and Ronald J. Williams, Hinton co-authored a highly cited paper published in 1986 that popularized a backpropagation algorithm for training multilayer neural networks, the AlexNet Image Recognition Dramatic Milestone, developed by his student Alex Kryzewski {{web link", "token2charspan": [[0, 5], [6, 10], [11, 16], [17, 19], [20, 29], [30, 33], [34, 40], [41, 43], [44, 52], [52, 53], [54, 60], [61, 72], [73, 74], [75, 81], [82, 87], [88, 93], [94, 103], [104, 106], [107, 111], [112, 116], [117, 128], [129, 130], [131, 146], [147, 156], [157, 160], [161, 169], [170, 180], [181, 187], [188, 196], [196, 197], [198, 201], [202, 206], [206, 209], [210, 215], [216, 227], [228, 236], [237, 246], [246, 247], [248, 257], [258, 260], [261, 264], [265, 272], [273, 277], [278, 287], [288, 289], [289, 290], [290, 293], [294, 298]]}
{"doc_key": "ai-dev-249", "ner": [[9, 11, "metrics"], [16, 16, "metrics"], [13, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "predicted", "value", "is", "continuously", "distributed", ",", "the", "mean", "square", "error", ",", "root", "mean", "square", "error", "or", "median", "absolute", "deviation", "can", "be", "used", "to", "summarize", "the", "errors", "."], "sentence-detokenized": "If the predicted value is continuously distributed, the mean square error, root mean square error or median absolute deviation can be used to summarize the errors.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 22], [23, 25], [26, 38], [39, 50], [50, 51], [52, 55], [56, 60], [61, 67], [68, 73], [73, 74], [75, 79], [80, 84], [85, 91], [92, 97], [98, 100], [101, 107], [108, 116], [117, 126], [127, 130], [131, 133], [134, 138], [139, 141], [142, 151], [152, 155], [156, 162], [162, 163]]}
{"doc_key": "ai-dev-250", "ner": [[0, 1, "algorithm"], [9, 10, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 9, 10, "part-of", "", true, false], [0, 1, 13, 14, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Conceptual", "clustering", "developed", "mainly", "during", "the", "1980s", "as", "a", "machine", "learning", "paradigm", "for", "unsupervised", "learning", "."], "sentence-detokenized": "Conceptual clustering developed mainly during the 1980s as a machine learning paradigm for unsupervised learning.", "token2charspan": [[0, 10], [11, 21], [22, 31], [32, 38], [39, 45], [46, 49], [50, 55], [56, 58], [59, 60], [61, 68], [69, 77], [78, 86], [87, 90], [91, 103], [104, 112], [112, 113]]}
{"doc_key": "ai-dev-251", "ner": [[7, 10, "product"], [28, 30, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "named", "entities", "can", "not", "be", "recognized", "by", "the", "machine", "translator", ",", "they", "may", "be", "mistakenly", "translated", "as", "common", "nouns", ",", "which", "most", "likely", "will", "not", "affect", "the", "Bilingual", "evaluation", "score", ",", "but", "will", "change", "the", "readability", "of", "the", "text", "for", "humans", "."], "sentence-detokenized": "If named entities cannot be recognized by the machine translator, they may be mistakenly translated as common nouns, which most likely will not affect the Bilingual evaluation score, but will change the readability of the text for humans.", "token2charspan": [[0, 2], [3, 8], [9, 17], [18, 21], [21, 24], [25, 27], [28, 38], [39, 41], [42, 45], [46, 53], [54, 64], [64, 65], [66, 70], [71, 74], [75, 77], [78, 88], [89, 99], [100, 102], [103, 109], [110, 115], [115, 116], [117, 122], [123, 127], [128, 134], [135, 139], [140, 143], [144, 150], [151, 154], [155, 164], [165, 175], [176, 181], [181, 182], [183, 186], [187, 191], [192, 198], [199, 202], [203, 214], [215, 217], [218, 221], [222, 226], [227, 230], [231, 237], [237, 238]]}
{"doc_key": "ai-dev-252", "ner": [[0, 1, "researcher"], [10, 11, "misc"], [12, 19, "conference"], [21, 23, "location"], [25, 25, "country"], [39, 42, "researcher"], [46, 47, "researcher"], [50, 51, "university"], [55, 56, "researcher"], [58, 59, "researcher"], [62, 63, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 11, "related-to", "writes_about", false, false], [0, 1, 12, 19, "temporal", "", true, false], [12, 19, 21, 23, "physical", "", false, false], [21, 23, 25, 25, "physical", "", false, false], [46, 47, 50, 51, "physical", "", false, false], [46, 47, 50, 51, "role", "", false, false], [55, 56, 50, 51, "physical", "", false, false], [55, 56, 50, 51, "role", "", false, false], [58, 59, 50, 51, "physical", "", false, false], [58, 59, 50, 51, "role", "", false, false], [62, 63, 50, 51, "physical", "", false, false], [62, 63, 50, 51, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Roger", "Shank", ",", "1969", ",", "A", "Conceptual", "Dependency", "Analyzer", "for", "Natural", "Language", "Proceedings", "of", "the", "1969", "Conference", "on", "Computational", "Linguistics", ",", "Song", "-", "Sebi", ",", "Sweden", ",", "pages", "1-", "3", "This", "model", ",", "partly", "influenced", "by", "the", "work", "of", "Sidney", "Lamb", ",", "was", "widely", "used", "by", "Shank", "'s", "students", "at", "Yale", "University", ",", "such", "as", "Robert", "Wilensky", ",", "Wendy", "Lehnert", ",", "and", "Janet", "Kolodner", "."], "sentence-detokenized": "Roger Shank, 1969, A Conceptual Dependency Analyzer for Natural Language Proceedings of the 1969 Conference on Computational Linguistics, Song-Sebi, Sweden, pages 1-3 This model, partly influenced by the work of Sidney Lamb, was widely used by Shank's students at Yale University, such as Robert Wilensky, Wendy Lehnert, and Janet Kolodner.", "token2charspan": [[0, 5], [6, 11], [11, 12], [13, 17], [17, 18], [19, 20], [21, 31], [32, 42], [43, 51], [52, 55], [56, 63], [64, 72], [73, 84], [85, 87], [88, 91], [92, 96], [97, 107], [108, 110], [111, 124], [125, 136], [136, 137], [138, 142], [142, 143], [143, 147], [147, 148], [149, 155], [155, 156], [157, 162], [163, 165], [165, 166], [167, 171], [172, 177], [177, 178], [179, 185], [186, 196], [197, 199], [200, 203], [204, 208], [209, 211], [212, 218], [219, 223], [223, 224], [225, 228], [229, 235], [236, 240], [241, 243], [244, 249], [249, 251], [252, 260], [261, 263], [264, 268], [269, 279], [279, 280], [281, 285], [286, 288], [289, 295], [296, 304], [304, 305], [306, 311], [312, 319], [319, 320], [321, 324], [325, 330], [331, 339], [339, 340]]}
{"doc_key": "ai-dev-253", "ner": [[2, 4, "algorithm"], [6, 8, "algorithm"], [13, 13, "algorithm"], [15, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 8, 2, 4, "named", "", false, false], [13, 13, 2, 4, "named", "", false, false], [15, 16, 2, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Improved", "Maximum", "Likelihood", "Method", "(", "IMLM", ")", "is", "a", "combination", "of", "two", "MLM", "(", "maximum", "likelihood", ")", "estimators", "."], "sentence-detokenized": "The Improved Maximum Likelihood Method (IMLM) is a combination of two MLM (maximum likelihood) estimators.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 31], [32, 38], [39, 40], [40, 44], [44, 45], [46, 48], [49, 50], [51, 62], [63, 65], [66, 69], [70, 73], [74, 75], [75, 82], [83, 93], [93, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-dev-254", "ner": [[20, 21, "metrics"], [24, 25, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[24, 25, 20, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["These", "methods", "may", "also", "analyze", "the", "output", "of", "the", "program", "and", "its", "utility", "and", "therefore", "may", "include", "analysis", "of", "its", "confusion", "matrix", "(", "or", "confusion", "table", ")", "."], "sentence-detokenized": "These methods may also analyze the output of the program and its utility and therefore may include analysis of its confusion matrix (or confusion table).", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 22], [23, 30], [31, 34], [35, 41], [42, 44], [45, 48], [49, 56], [57, 60], [61, 64], [65, 72], [73, 76], [77, 86], [87, 90], [91, 98], [99, 107], [108, 110], [111, 114], [115, 124], [125, 131], [132, 133], [133, 135], [136, 145], [146, 151], [151, 152], [152, 153]]}
{"doc_key": "ai-dev-255", "ner": [[0, 0, "product"], [5, 6, "researcher"], [8, 9, "researcher"], [11, 13, "researcher"], [18, 24, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 6, "origin", "", false, false], [0, 0, 8, 9, "origin", "", false, false], [0, 0, 11, 13, "origin", "", false, false], [0, 0, 18, 24, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SURF", "was", "first", "published", "by", "Herbert", "Bey", ",", "Tinne", "Tuiteelaars", "and", "Luc", "Van", "Gool", "and", "presented", "at", "the", "European", "Conference", "on", "Computer", "Vision", "in", "2006", "."], "sentence-detokenized": "SURF was first published by Herbert Bey, Tinne Tuiteelaars and Luc Van Gool and presented at the European Conference on Computer Vision in 2006.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 24], [25, 27], [28, 35], [36, 39], [39, 40], [41, 46], [47, 58], [59, 62], [63, 66], [67, 70], [71, 75], [76, 79], [80, 89], [90, 92], [93, 96], [97, 105], [106, 116], [117, 119], [120, 128], [129, 135], [136, 138], [139, 143], [143, 144]]}
{"doc_key": "ai-dev-256", "ner": [[0, 2, "task"], [10, 11, "field"], [13, 14, "field"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 10, 11, "part-of", "", false, false], [0, 2, 13, 14, "part-of", "", false, false], [0, 2, 16, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OCR", "is", "a", "branch", "of", "research", "in", "the", "field", "of", "pattern", "recognition", ",", "artificial", "intelligence", "and", "computer", "vision", "."], "sentence-detokenized": "OCR is a branch of research in the field of pattern recognition, artificial intelligence and computer vision.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 15], [16, 18], [19, 27], [28, 30], [31, 34], [35, 40], [41, 43], [44, 51], [52, 63], [63, 64], [65, 75], [76, 88], [89, 92], [93, 101], [102, 108], [108, 109]]}
{"doc_key": "ai-dev-257", "ner": [[4, 6, "metrics"], [9, 11, "algorithm"], [13, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 16, 9, 11, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Continuing", "the", "example", "using", "maximum", "likelihood", "estimation", ",", "the", "probability", "density", "function", "(", "pdf", ")", "of", "the", "noise", "for", "one", "sample", "mathwn", "/", "math", "is"], "sentence-detokenized": "Continuing the example using maximum likelihood estimation, the probability density function (pdf) of the noise for one sample mathwn / math is", "token2charspan": [[0, 10], [11, 14], [15, 22], [23, 28], [29, 36], [37, 47], [48, 58], [58, 59], [60, 63], [64, 75], [76, 83], [84, 92], [93, 94], [94, 97], [97, 98], [99, 101], [102, 105], [106, 111], [112, 115], [116, 119], [120, 126], [127, 133], [134, 135], [136, 140], [141, 143]]}
{"doc_key": "ai-dev-258", "ner": [[2, 3, "field"], [5, 6, "task"], [8, 9, "task"], [11, 12, "task"], [14, 15, "task"], [17, 20, "task"], [22, 22, "task"], [24, 24, "task"], [26, 27, "task"], [29, 30, "task"], [32, 35, "task"], [38, 39, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[5, 6, 2, 3, "part-of", "", false, false], [8, 9, 2, 3, "part-of", "", false, false], [11, 12, 2, 3, "part-of", "", false, false], [14, 15, 2, 3, "part-of", "", false, false], [17, 20, 2, 3, "part-of", "", false, false], [22, 22, 2, 3, "part-of", "", false, false], [24, 24, 2, 3, "part-of", "", false, false], [26, 27, 2, 3, "part-of", "", false, false], [29, 30, 2, 3, "part-of", "", false, false], [32, 35, 2, 3, "part-of", "", false, false], [38, 39, 2, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Subfields", "of", "computer", "vision", "include", "scene", "reconstruction", ",", "event", "detection", ",", "video", "tracking", ",", "object", "recognition", ",", "three", "-dimensional", "pose", "estimation", ",", "learning", ",", "indexing", ",", "motion", "estimation", ",", "visual", "servo", ",", "three", "-dimensional", "scene", "modeling", ",", "and", "image", "restoration", "."], "sentence-detokenized": "Subfields of computer vision include scene reconstruction, event detection, video tracking, object recognition, three-dimensional pose estimation, learning, indexing, motion estimation, visual servo, three-dimensional scene modeling, and image restoration.", "token2charspan": [[0, 9], [10, 12], [13, 21], [22, 28], [29, 36], [37, 42], [43, 57], [57, 58], [59, 64], [65, 74], [74, 75], [76, 81], [82, 90], [90, 91], [92, 98], [99, 110], [110, 111], [112, 117], [117, 129], [130, 134], [135, 145], [145, 146], [147, 155], [155, 156], [157, 165], [165, 166], [167, 173], [174, 184], [184, 185], [186, 192], [193, 198], [198, 199], [200, 205], [205, 217], [218, 223], [224, 232], [232, 233], [234, 237], [238, 243], [244, 255], [255, 256]]}
{"doc_key": "ai-dev-259", "ner": [[5, 9, "conference"], [11, 11, "researcher"], [15, 16, "misc"], [19, 19, "conference"], [22, 22, "researcher"], [24, 24, "researcher"], [26, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 9, 19, 19, "named", "", false, false], [11, 11, 15, 16, "win-defeat", "", false, false], [11, 11, 26, 27, "related-to", "writes_about", true, false], [15, 16, 5, 9, "temporal", "", false, false], [22, 22, 15, 16, "win-defeat", "", false, true], [22, 22, 26, 27, "related-to", "writes_about", true, false], [24, 24, 15, 16, "win-defeat", "", false, true], [24, 24, 26, 27, "related-to", "writes_about", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["In", "2013", ",", "at", "the", "International", "Conference", "on", "Computer", "Vision", ",", "Terzopoulos", "was", "awarded", "the", "Helmholtz", "Prize", "for", "his", "1987", "work", "with", "Kass", "and", "Witkin", "on", "active", "contour", "models", "."], "sentence-detokenized": "In 2013, at the International Conference on Computer Vision, Terzopoulos was awarded the Helmholtz Prize for his 1987 work with Kass and Witkin on active contour models.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 29], [30, 40], [41, 43], [44, 52], [53, 59], [59, 60], [61, 72], [73, 76], [77, 84], [85, 88], [89, 98], [99, 104], [105, 108], [109, 112], [113, 117], [118, 122], [123, 127], [128, 132], [133, 136], [137, 143], [144, 146], [147, 153], [154, 161], [162, 168], [168, 169]]}
{"doc_key": "ai-dev-260", "ner": [[15, 16, "task"], [18, 20, "algorithm"], [22, 23, "algorithm"], [25, 27, "algorithm"], [29, 30, "algorithm"], [32, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[15, 16, 18, 20, "usage", "", true, false], [15, 16, 22, 23, "usage", "", true, false], [15, 16, 25, 27, "usage", "", true, false], [15, 16, 29, 30, "usage", "", true, false], [15, 16, 32, 32, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["If", "the", "regularization", "function", "Many", "algorithms", "exist", "to", "solve", "such", "problems", ";", "popular", "ones", "for", "linear", "classification", "include", "Stochastic", "gradient", "descent", ",", "Gradient", "descent", ",", "L", "-", "BFGS", ",", "Coordinate", "descent", "and", "Newton", "methods", "."], "sentence-detokenized": "If the regularization function Many algorithms exist to solve such problems; popular ones for linear classification include Stochastic gradient descent, Gradient descent, L-BFGS, Coordinate descent and Newton methods.", "token2charspan": [[0, 2], [3, 6], [7, 21], [22, 30], [31, 35], [36, 46], [47, 52], [53, 55], [56, 61], [62, 66], [67, 75], [75, 76], [77, 84], [85, 89], [90, 93], [94, 100], [101, 115], [116, 123], [124, 134], [135, 143], [144, 151], [151, 152], [153, 161], [162, 169], [169, 170], [171, 172], [172, 173], [173, 177], [177, 178], [179, 189], [190, 197], [198, 201], [202, 208], [209, 216], [216, 217]]}
{"doc_key": "ai-dev-261", "ner": [[0, 3, "algorithm"], [5, 5, "algorithm"], [11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 11, 12, "origin", "", false, false], [5, 5, 0, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Long", "Short", "Term", "Memory", "(", "LSTM", ")", "networks", "were", "invented", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "in", "1997", "and", "have", "set", "accuracy", "records", "in", "many", "applications", "."], "sentence-detokenized": "Long Short Term Memory (LSTM) networks were invented by Sepp Hochreiter and J\u00fcrgen Schmidhuber in 1997 and have set accuracy records in many applications.", "token2charspan": [[0, 4], [5, 10], [11, 15], [16, 22], [23, 24], [24, 28], [28, 29], [30, 38], [39, 43], [44, 52], [53, 55], [56, 60], [61, 71], [72, 75], [76, 82], [83, 94], [95, 97], [98, 102], [103, 106], [107, 111], [112, 115], [116, 124], [125, 132], [133, 135], [136, 140], [141, 153], [153, 154]]}
{"doc_key": "ai-dev-262", "ner": [[0, 1, "product"], [5, 7, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 5, 7, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "TN", "was", "developed", "at", "Massachusetts", "General", "Hospital", "and", "has", "been", "tested", "in", "several", "scenarios", ",", "including", "extraction", "of", "smoking", "status", ",", "family", "history", "of", "CHD", ",", "and", "identification", "of", "patients", "with", "sleep", "disorders", ","], "sentence-detokenized": "The TN was developed at Massachusetts General Hospital and has been tested in several scenarios, including extraction of smoking status, family history of CHD, and identification of patients with sleep disorders,", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 20], [21, 23], [24, 37], [38, 45], [46, 54], [55, 58], [59, 62], [63, 67], [68, 74], [75, 77], [78, 85], [86, 95], [95, 96], [97, 106], [107, 117], [118, 120], [121, 128], [129, 135], [135, 136], [137, 143], [144, 151], [152, 154], [155, 158], [158, 159], [160, 163], [164, 178], [179, 181], [182, 190], [191, 195], [196, 201], [202, 211], [211, 212]]}
{"doc_key": "ai-dev-263", "ner": [[3, 3, "researcher"], [8, 8, "product"], [15, 16, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 8, 8, "role", "sells", false, false], [8, 8, 15, 16, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "shipped", "to", "General", "Motors", "in", "1961", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was shipped to General Motors in 1961.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 73], [74, 76], [77, 84], [85, 91], [92, 94], [95, 99], [99, 100]]}
{"doc_key": "ai-dev-264", "ner": [[0, 3, "conference"], [12, 13, "location"], [15, 15, "location"], [17, 17, "country"], [31, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 12, 13, "physical", "", false, false], [12, 13, 15, 15, "physical", "", false, false], [15, 15, 17, 17, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Campus", "Party", "Europe", "took", "place", "on", "14", "-", "18", "April", "2010", "at", "Caja", "M\u00e1gica", "in", "Madrid", ",", "Spain", ",", "with", "800", "participants", "from", "each", "of", "the", "27", "member", "states", "of", "the", "European", "Union", "."], "sentence-detokenized": "Campus Party Europe took place on 14-18 April 2010 at Caja M\u00e1gica in Madrid, Spain, with 800 participants from each of the 27 member states of the European Union.", "token2charspan": [[0, 6], [7, 12], [13, 19], [20, 24], [25, 30], [31, 33], [34, 36], [36, 37], [37, 39], [40, 45], [46, 50], [51, 53], [54, 58], [59, 65], [66, 68], [69, 75], [75, 76], [77, 82], [82, 83], [84, 88], [89, 92], [93, 105], [106, 110], [111, 115], [116, 118], [119, 122], [123, 125], [126, 132], [133, 139], [140, 142], [143, 146], [147, 155], [156, 161], [161, 162]]}
{"doc_key": "ai-dev-265", "ner": [[9, 9, "organisation"], [11, 13, "organisation"], [16, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 20, 9, 9, "origin", "", false, false], [16, 20, 11, 13, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2016", ",", "a", "collaboration", "was", "announced", "between", "DeepMind", "and", "Moorfields", "Eye", "Hospital", "to", "develop", "artificial", "intelligence", "applications", "for", "medicine", "."], "sentence-detokenized": "In July 2016, a collaboration was announced between DeepMind and Moorfields Eye Hospital to develop artificial intelligence applications for medicine.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 15], [16, 29], [30, 33], [34, 43], [44, 51], [52, 60], [61, 64], [65, 75], [76, 79], [80, 88], [89, 91], [92, 99], [100, 110], [111, 123], [124, 136], [137, 140], [141, 149], [149, 150]]}
{"doc_key": "ai-dev-266", "ner": [[7, 7, "misc"], [13, 14, "university"], [16, 16, "university"], [18, 19, "university"], [21, 22, "university"], [24, 27, "university"], [29, 42, "university"], [32, 34, "university"], [36, 36, "university"], [38, 40, "university"], [48, 49, "university"], [50, 50, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[7, 7, 13, 14, "physical", "", false, false], [7, 7, 16, 16, "physical", "", false, false], [7, 7, 18, 19, "physical", "", false, false], [7, 7, 21, 22, "physical", "", false, false], [7, 7, 24, 27, "physical", "", false, false], [7, 7, 29, 42, "physical", "", false, false], [7, 7, 32, 34, "physical", "", false, false], [7, 7, 36, 36, "physical", "", false, false], [7, 7, 38, 40, "physical", "", false, false], [7, 7, 48, 49, "physical", "", false, false], [7, 7, 50, 50, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["In", "the", "end", ",", "they", "awarded", "eleven", "PR2s", "to", "different", "institutions", ",", "including", "Freiburg", "University", ",", "Bosch", ",", "Georgia", "Tech", ",", "Leuven", "University", ",", "Massachusetts", "Institute", "of", "Technology", ",", "Stanford", "University", ",", "Munich", "Technical", "University", ",", "Berkeley", ",", "University", "of", "Pennsylvania", ",", "California", "State", "University", ",", "and", "the", "University", "of", "Tokyo", "."], "sentence-detokenized": "In the end, they awarded eleven PR2s to different institutions, including Freiburg University, Bosch, Georgia Tech, Leuven University, Massachusetts Institute of Technology, Stanford University, Munich Technical University, Berkeley, University of Pennsylvania, California State University, and the University of Tokyo.", "token2charspan": [[0, 2], [3, 6], [7, 10], [10, 11], [12, 16], [17, 24], [25, 31], [32, 36], [37, 39], [40, 49], [50, 62], [62, 63], [64, 73], [74, 82], [83, 93], [93, 94], [95, 100], [100, 101], [102, 109], [110, 114], [114, 115], [116, 122], [123, 133], [133, 134], [135, 148], [149, 158], [159, 161], [162, 172], [172, 173], [174, 182], [183, 193], [193, 194], [195, 201], [202, 211], [212, 222], [222, 223], [224, 232], [232, 233], [234, 244], [245, 247], [248, 260], [260, 261], [262, 272], [273, 278], [279, 289], [289, 290], [291, 294], [295, 298], [299, 309], [310, 312], [313, 318], [318, 319]]}
{"doc_key": "ai-dev-267", "ner": [[0, 0, "metrics"], [2, 2, "metrics"], [4, 4, "metrics"], [6, 6, "metrics"], [17, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 17, 18, "part-of", "", false, false], [2, 2, 17, 18, "part-of", "", false, false], [4, 4, 17, 18, "part-of", "", false, false], [6, 6, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["TP", ",", "TN", ",", "FP", "and", "FN", "counts", "are", "usually", "kept", "in", "a", "table", "known", "as", "a", "confusion", "matrix", "."], "sentence-detokenized": "TP, TN, FP and FN counts are usually kept in a table known as a confusion matrix.", "token2charspan": [[0, 2], [2, 3], [4, 6], [6, 7], [8, 10], [11, 14], [15, 17], [18, 24], [25, 28], [29, 36], [37, 41], [42, 44], [45, 46], [47, 52], [53, 58], [59, 61], [62, 63], [64, 73], [74, 80], [80, 81]]}
{"doc_key": "ai-dev-268", "ner": [[0, 1, "metrics"], [3, 4, "metrics"], [6, 7, "metrics"], [9, 11, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Information", "gain", ",", "cross", "entropy", ",", "mutual", "information", "and", "odds", "ratio", "are", "usually", "used", "as", "a", "set", "of", "features", "."], "sentence-detokenized": "Information gain, cross entropy, mutual information and odds ratio are usually used as a set of features.", "token2charspan": [[0, 11], [12, 16], [16, 17], [18, 23], [24, 31], [31, 32], [33, 39], [40, 51], [52, 55], [56, 60], [61, 66], [67, 70], [71, 78], [79, 83], [84, 86], [87, 88], [89, 92], [93, 95], [96, 104], [104, 105]]}
{"doc_key": "ai-dev-269", "ner": [[11, 12, "task"], [14, 15, "task"], [17, 17, "task"], [19, 19, "task"], [21, 21, "task"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[23, 23, 21, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "has", "been", "successfully", "applied", "to", "a", "variety", "of", "tasks", "including", "robot", "control", ",", "elevator", "scheduling", ",", "telecommunications", ",", "checkers", "and", "Go", "(", "AlphaGo", ")", "."], "sentence-detokenized": "It has been successfully applied to a variety of tasks including robot control, elevator scheduling, telecommunications, checkers and Go (AlphaGo).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 24], [25, 32], [33, 35], [36, 37], [38, 45], [46, 48], [49, 54], [55, 64], [65, 70], [71, 78], [78, 79], [80, 88], [89, 99], [99, 100], [101, 119], [119, 120], [121, 129], [130, 133], [134, 136], [137, 138], [138, 145], [145, 146], [146, 147]]}
{"doc_key": "ai-dev-270", "ner": [[12, 17, "misc"], [18, 21, "university"], [24, 24, "location"], [26, 26, "location"], [30, 35, "location"], [38, 40, "location"], [42, 42, "location"], [44, 44, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[12, 17, 18, 21, "physical", "", false, false], [18, 21, 24, 24, "physical", "", false, false], [24, 24, 26, 26, "physical", "", false, false], [30, 35, 38, 40, "physical", "", false, false], [38, 40, 42, 42, "physical", "", false, false], [42, 42, 44, 44, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "the", "first", "year", "of", "the", "8th", "mission", ",", "the", "US", "site", "was", "held", "at", "the", "Georgia", "Institute", "of", "Technology", "campus", "in", "Atlanta", ",", "Georgia", ",", "and", "the", "Asia", "-", "Pacific", "site", "was", "held", "at", "the", "Beihang", "University", "Gymnasium", "in", "Beijing", ",", "China", "."], "sentence-detokenized": "In 2018, the first year of the 8th mission, the US site was held at the Georgia Institute of Technology campus in Atlanta, Georgia, and the Asia-Pacific site was held at the Beihang University Gymnasium in Beijing, China.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 18], [19, 23], [24, 26], [27, 30], [31, 34], [35, 42], [42, 43], [44, 47], [48, 50], [51, 55], [56, 59], [60, 64], [65, 67], [68, 71], [72, 79], [80, 89], [90, 92], [93, 103], [104, 110], [111, 113], [114, 121], [121, 122], [123, 130], [130, 131], [132, 135], [136, 139], [140, 144], [144, 145], [145, 152], [153, 157], [158, 161], [162, 166], [167, 169], [170, 173], [174, 181], [182, 192], [193, 202], [203, 205], [206, 213], [213, 214], [215, 220], [220, 221]]}
{"doc_key": "ai-dev-271", "ner": [[0, 2, "field"], [6, 7, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 6, 7, "origin", "", false, false], [0, 2, 6, 7, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "is", "closely", "related", "to", "pattern", "recognition", "and", "is", "derived", "from", "artificial", "intelligence", "."], "sentence-detokenized": "Machine learning is closely related to pattern recognition and is derived from artificial intelligence.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 27], [28, 35], [36, 38], [39, 46], [47, 58], [59, 62], [63, 65], [66, 73], [74, 78], [79, 89], [90, 102], [102, 103]]}
{"doc_key": "ai-dev-272", "ner": [[4, 4, "programlang"], [17, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "comes", "with", "3", "Java", "games", "that", "are", "controlled", "by", "the", "remote", "control", "and", "displayed", "on", "its", "LCD", "screen", "."], "sentence-detokenized": "It comes with 3 Java games that are controlled by the remote control and displayed on its LCD screen.", "token2charspan": [[0, 2], [3, 8], [9, 13], [14, 15], [16, 20], [21, 26], [27, 31], [32, 35], [36, 46], [47, 49], [50, 53], [54, 60], [61, 68], [69, 72], [73, 82], [83, 85], [86, 89], [90, 93], [94, 100], [100, 101]]}
{"doc_key": "ai-dev-273", "ner": [[7, 18, "task"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[19, 21, 7, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "commercially", "successful", "but", "specialized", "technology", "for", "estimating", "the", "pose", "of", "an", "articulated", "body", "based", "on", "computer", "vision", "is", "optical", "motion", "capture", "."], "sentence-detokenized": "A commercially successful but specialized technology for estimating the pose of an articulated body based on computer vision is optical motion capture.", "token2charspan": [[0, 1], [2, 14], [15, 25], [26, 29], [30, 41], [42, 52], [53, 56], [57, 67], [68, 71], [72, 76], [77, 79], [80, 82], [83, 94], [95, 99], [100, 105], [106, 108], [109, 117], [118, 124], [125, 127], [128, 135], [136, 142], [143, 150], [150, 151]]}
{"doc_key": "ai-dev-274", "ner": [[0, 1, "organisation"], [8, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 8, 9, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["SMC", "is", "very", "similar", "to", "the", "more", "popular", "Jaccard", "index", "."], "sentence-detokenized": "SMC is very similar to the more popular Jaccard index.", "token2charspan": [[0, 3], [4, 6], [7, 11], [12, 19], [20, 22], [23, 26], [27, 31], [32, 39], [40, 47], [48, 53], [53, 54]]}
{"doc_key": "ai-dev-275", "ner": [[0, 0, "product"], [2, 6, "product"], [7, 9, "product"], [15, 16, "researcher"], [22, 22, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 7, 9, "named", "", false, false], [0, 0, 15, 16, "artifact", "", false, false], [0, 0, 22, 22, "artifact", "", false, false], [2, 6, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", "is", "an", "industrial", "robot", "manipulator", "developed", "by", "Victor", "Sheinman", "at", "the", "pioneering", "robotics", "company", "Unimation", "."], "sentence-detokenized": "PUMA (Programmable Universal Machine for Assembly) is an industrial robot manipulator developed by Victor Sheinman at the pioneering robotics company Unimation.", "token2charspan": [[0, 4], [5, 6], [6, 18], [19, 28], [29, 36], [37, 40], [41, 49], [49, 50], [51, 53], [54, 56], [57, 67], [68, 73], [74, 85], [86, 95], [96, 98], [99, 105], [106, 114], [115, 117], [118, 121], [122, 132], [133, 141], [142, 149], [150, 159], [159, 160]]}
{"doc_key": "ai-dev-276", "ner": [[4, 4, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "written", "in", "Python", "language", "."], "sentence-detokenized": "It is written in Python language.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 23], [24, 32], [32, 33]]}
{"doc_key": "ai-dev-277", "ner": [[0, 0, "misc"], [2, 2, "misc"], [12, 12, "field"], [14, 15, "field"], [17, 18, "field"], [20, 21, "field"], [23, 24, "field"], [26, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 2, 2, "related-to", "metric_for", true, false], [0, 0, 12, 12, "part-of", "", false, false], [0, 0, 14, 15, "part-of", "", false, false], [0, 0, 17, 18, "part-of", "", false, false], [0, 0, 20, 21, "part-of", "", false, false], [0, 0, 23, 24, "part-of", "", false, false], [0, 0, 26, 26, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Bandwidth", "in", "hertz", "is", "a", "central", "concept", "in", "many", "fields", ",", "including", "electronics", ",", "information", "theory", ",", "digital", "communications", ",", "radio", "communications", ",", "signal", "processing", "and", "spectroscopy", ",", "and", "is", "one", "of", "the", "determining", "factors", "of", "the", "bandwidth", "of", "a", "given", "communication", "channel", "."], "sentence-detokenized": "Bandwidth in hertz is a central concept in many fields, including electronics, information theory, digital communications, radio communications, signal processing and spectroscopy, and is one of the determining factors of the bandwidth of a given communication channel.", "token2charspan": [[0, 9], [10, 12], [13, 18], [19, 21], [22, 23], [24, 31], [32, 39], [40, 42], [43, 47], [48, 54], [54, 55], [56, 65], [66, 77], [77, 78], [79, 90], [91, 97], [97, 98], [99, 106], [107, 121], [121, 122], [123, 128], [129, 143], [143, 144], [145, 151], [152, 162], [163, 166], [167, 179], [179, 180], [181, 184], [185, 187], [188, 191], [192, 194], [195, 198], [199, 210], [211, 218], [219, 221], [222, 225], [226, 235], [236, 238], [239, 240], [241, 246], [247, 260], [261, 268], [268, 269]]}
{"doc_key": "ai-dev-278", "ner": [[8, 8, "algorithm"], [10, 10, "algorithm"], [17, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 17, 20, "part-of", "", false, false], [10, 10, 17, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["If", "convex", "loss", "is", "used", "(", "as", "in", "AdaBoost", ",", "LogitBoost", ",", "and", "all", "members", "of", "the", "AnyBoost", "family", "of", "algorithms", ")", ",", "then", "an", "example", "with", "a", "larger", "margin", "will", "receive", "less", "(", "or", "equal", ")", "weight", "than", "an", "example", "with", "a", "smaller", "margin", "."], "sentence-detokenized": "If convex loss is used (as in AdaBoost, LogitBoost, and all members of the AnyBoost family of algorithms), then an example with a larger margin will receive less (or equal) weight than an example with a smaller margin.", "token2charspan": [[0, 2], [3, 9], [10, 14], [15, 17], [18, 22], [23, 24], [24, 26], [27, 29], [30, 38], [38, 39], [40, 50], [50, 51], [52, 55], [56, 59], [60, 67], [68, 70], [71, 74], [75, 83], [84, 90], [91, 93], [94, 104], [104, 105], [105, 106], [107, 111], [112, 114], [115, 122], [123, 127], [128, 129], [130, 136], [137, 143], [144, 148], [149, 156], [157, 161], [162, 163], [163, 165], [166, 171], [171, 172], [173, 179], [180, 184], [185, 187], [188, 195], [196, 200], [201, 202], [203, 210], [211, 217], [217, 218]]}
{"doc_key": "ai-dev-279", "ner": [[0, 2, "researcher"], [8, 9, "researcher"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 8, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Sepp", "Hochreiter", "'s", "graduation", "thesis", ",", "1991", ".", "Sepp", "Hochreiter", "."], "sentence-detokenized": "Sepp Hochreiter's graduation thesis, 1991. Sepp Hochreiter.", "token2charspan": [[0, 4], [5, 15], [15, 17], [18, 28], [29, 35], [35, 36], [37, 41], [41, 42], [43, 47], [48, 58], [58, 59]]}
{"doc_key": "ai-dev-280", "ner": [[4, 5, "algorithm"], [7, 7, "algorithm"], [10, 11, "algorithm"], [14, 14, "algorithm"], [17, 21, "algorithm"], [23, 23, "algorithm"], [26, 28, "algorithm"], [31, 32, "algorithm"], [34, 36, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[7, 7, 4, 5, "named", "", false, false], [14, 14, 10, 11, "named", "", false, false], [17, 21, 26, 28, "related-to", "", true, false], [23, 23, 17, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Typical", "discriminant", "models", "include", "Logistic", "Regression", "(", "LR", ")", ",", "Support", "Vector", "Machines", "(", "SVM", ")", ",", "Conditional", "Random", "Fields", "(", "CRF", ")", "(", "defined", "on", "an", "undirected", "graph", ")", ",", "Decision", "Trees", ",", "Neural", "Networks", "and", "many", "others", "."], "sentence-detokenized": "Typical discriminant models include Logistic Regression (LR), Support Vector Machines (SVM), Conditional Random Fields (CRF) (defined on an undirected graph), Decision Trees, Neural Networks and many others.", "token2charspan": [[0, 7], [8, 20], [21, 27], [28, 35], [36, 44], [45, 55], [56, 57], [57, 59], [59, 60], [60, 61], [62, 69], [70, 76], [77, 85], [86, 87], [87, 90], [90, 91], [91, 92], [93, 104], [105, 111], [112, 118], [119, 120], [120, 123], [123, 124], [125, 126], [126, 133], [134, 136], [137, 139], [140, 150], [151, 156], [156, 157], [157, 158], [159, 167], [168, 173], [173, 174], [175, 181], [182, 190], [191, 194], [195, 199], [200, 206], [206, 207]]}
{"doc_key": "ai-dev-281", "ner": [[13, 15, "metrics"], [37, 39, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Then", "it", "is", "also", "possible", "to", "use", "these", "probabilities", "and", "estimate", "the", "root", "mean", "square", "error", "(", "or", "some", "other", "similar", "measure", ")", "between", "the", "probabilities", "and", "the", "actual", "values", ",", "and", "then", "combine", "this", "with", "the", "confusion", "matrix", "to", "create", "very", "efficient", "goodness", "-", "of", "-", "fit", "functions", "for", "logistic", "regression", "."], "sentence-detokenized": "Then it is also possible to use these probabilities and estimate the root mean square error (or some other similar measure) between the probabilities and the actual values, and then combine this with the confusion matrix to create very efficient goodness-of-fit functions for logistic regression.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 15], [16, 24], [25, 27], [28, 31], [32, 37], [38, 51], [52, 55], [56, 64], [65, 68], [69, 73], [74, 78], [79, 85], [86, 91], [92, 93], [93, 95], [96, 100], [101, 106], [107, 114], [115, 122], [122, 123], [124, 131], [132, 135], [136, 149], [150, 153], [154, 157], [158, 164], [165, 171], [171, 172], [173, 176], [177, 181], [182, 189], [190, 194], [195, 199], [200, 203], [204, 213], [214, 220], [221, 223], [224, 230], [231, 235], [236, 245], [246, 254], [254, 255], [255, 257], [257, 258], [258, 261], [262, 271], [272, 275], [276, 284], [285, 295], [295, 296]]}
{"doc_key": "ai-dev-282", "ner": [[0, 3, "product"], [7, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 7, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VoiceOver", "was", "first", "introduced", "in", "2005", "in", "Mac", "OS", "X", "Tiger", "(", "10.4", ")", "."], "sentence-detokenized": "VoiceOver was first introduced in 2005 in Mac OS X Tiger (10.4).", "token2charspan": [[0, 9], [10, 13], [14, 19], [20, 30], [31, 33], [34, 38], [39, 41], [42, 45], [46, 48], [49, 50], [51, 56], [57, 58], [58, 62], [62, 63], [63, 64]]}
{"doc_key": "ai-dev-283", "ner": [[13, 14, "algorithm"], [19, 21, "misc"], [26, 27, "metrics"], [29, 31, "algorithm"], [62, 65, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 14, 19, 21, "related-to", "applied_to", false, false], [26, 27, 19, 21, "type-of", "", false, false], [26, 27, 29, 31, "related-to", "used_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "practice", ",", "machine", "learning", "algorithms", "cope", "with", "this", "either", "by", "using", "a", "convex", "approximation", "to", "the", "0", "-", "1", "loss", "function", "(", "e.g.", ",", "the", "loop", "loss", "for", "support", "vector", "machines", ")", ",", "which", "is", "easier", "to", "optimize", ",", "or", "by", "imposing", "assumptions", "on", "the", "distribution", "mathP", "(", "x", ",", "y", ")", "/", "math", "(", "and", "thus", "cease", "to", "be", "the", "learning", "algorithm", "agnostic", "to", "which", "the", "above", "result", "refers", ")", "."], "sentence-detokenized": "In practice, machine learning algorithms cope with this either by using a convex approximation to the 0-1 loss function (e.g., the loop loss for support vector machines), which is easier to optimize, or by imposing assumptions on the distribution mathP (x, y) / math (and thus cease to be the learning algorithm agnostic to which the above result refers).", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 20], [21, 29], [30, 40], [41, 45], [46, 50], [51, 55], [56, 62], [63, 65], [66, 71], [72, 73], [74, 80], [81, 94], [95, 97], [98, 101], [102, 103], [103, 104], [104, 105], [106, 110], [111, 119], [120, 121], [121, 125], [125, 126], [127, 130], [131, 135], [136, 140], [141, 144], [145, 152], [153, 159], [160, 168], [168, 169], [169, 170], [171, 176], [177, 179], [180, 186], [187, 189], [190, 198], [198, 199], [200, 202], [203, 205], [206, 214], [215, 226], [227, 229], [230, 233], [234, 246], [247, 252], [253, 254], [254, 255], [255, 256], [257, 258], [258, 259], [260, 261], [262, 266], [267, 268], [268, 271], [272, 276], [277, 282], [283, 285], [286, 288], [289, 292], [293, 301], [302, 311], [312, 320], [321, 323], [324, 329], [330, 333], [334, 339], [340, 346], [347, 353], [353, 354], [354, 355]]}
{"doc_key": "ai-dev-284", "ner": [[3, 4, "misc"], [16, 19, "field"], [26, 27, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 16, 19, "usage", "", false, false], [3, 4, 26, 27, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "film", "\"", "Western", "World", "\"", "(", "1973", ")", "was", "the", "first", "feature", "film", "to", "use", "digital", "image", "processing", "to", "simulate", "the", "point", "of", "view", "of", "an", "android", "."], "sentence-detokenized": "The film \"Western World\" (1973) was the first feature film to use digital image processing to simulate the point of view of an android.", "token2charspan": [[0, 3], [4, 8], [9, 10], [10, 17], [18, 23], [23, 24], [25, 26], [26, 30], [30, 31], [32, 35], [36, 39], [40, 45], [46, 53], [54, 58], [59, 61], [62, 65], [66, 73], [74, 79], [80, 90], [91, 93], [94, 102], [103, 106], [107, 112], [113, 115], [116, 120], [121, 123], [124, 126], [127, 134], [134, 135]]}
{"doc_key": "ai-dev-285", "ner": [[7, 8, "task"], [10, 11, "task"], [13, 13, "task"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Now", "it", "is", "also", "widely", "used", "in", "speech", "recognition", ",", "speech", "synthesis", ",", "diarization", ",", "Xavier", "Anguera", "et", "al", "."], "sentence-detokenized": "Now it is also widely used in speech recognition, speech synthesis, diarization, Xavier Anguera et al.", "token2charspan": [[0, 3], [4, 6], [7, 9], [10, 14], [15, 21], [22, 26], [27, 29], [30, 36], [37, 48], [48, 49], [50, 56], [57, 66], [66, 67], [68, 79], [79, 80], [81, 87], [88, 95], [96, 98], [99, 101], [101, 102]]}
{"doc_key": "ai-dev-286", "ner": [[6, 8, "algorithm"], [13, 14, "algorithm"], [17, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 14, 6, 8, "type-of", "", false, false], [17, 19, 6, 8, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Here", "math\\sigma", "/", "math", "is", "an", "elementary", "activation", "function", ",", "such", "as", "a", "sigmoid", "function", "or", "a", "rectified", "linear", "unit", "."], "sentence-detokenized": "Here math\\sigma/math is an elementary activation function, such as a sigmoid function or a rectified linear unit.", "token2charspan": [[0, 4], [5, 15], [15, 16], [16, 20], [21, 23], [24, 26], [27, 37], [38, 48], [49, 57], [57, 58], [59, 63], [64, 66], [67, 68], [69, 76], [77, 85], [86, 88], [89, 90], [91, 100], [101, 107], [108, 112], [112, 113]]}
{"doc_key": "ai-dev-287", "ner": [[10, 12, "algorithm"], [21, 21, "misc"], [23, 23, "misc"], [25, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "phonetic", "approaches", "(", "i.e.", "all", "models", "based", "on", "the", "hidden", "Markov", "model", ")", "required", "separate", "components", "and", "training", "for", "the", "pronunciation", ",", "acoustic", "and", "speech", "model", "."], "sentence-detokenized": "Traditional phonetic approaches (i.e. all models based on the hidden Markov model) required separate components and training for the pronunciation, acoustic and speech model.", "token2charspan": [[0, 11], [12, 20], [21, 31], [32, 33], [33, 37], [38, 41], [42, 48], [49, 54], [55, 57], [58, 61], [62, 68], [69, 75], [76, 81], [81, 82], [83, 91], [92, 100], [101, 111], [112, 115], [116, 124], [125, 128], [129, 132], [133, 146], [146, 147], [148, 156], [157, 160], [161, 167], [168, 173], [173, 174]]}
{"doc_key": "ai-dev-288", "ner": [[0, 3, "algorithm"], [7, 8, "field"], [10, 11, "field"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 13, 14, "related-to", "used_for", false, false], [7, 8, 0, 3, "usage", "", false, false], [10, 11, 0, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Roberts", "cross", "operator", "is", "used", "in", "image", "processing", "and", "computer", "vision", "to", "detect", "edges", "."], "sentence-detokenized": "The Roberts cross operator is used in image processing and computer vision to detect edges.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 37], [38, 43], [44, 54], [55, 58], [59, 67], [68, 74], [75, 77], [78, 84], [85, 90], [90, 91]]}
{"doc_key": "ai-dev-289", "ner": [[0, 0, "metrics"], [2, 2, "metrics"], [23, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 23, 23, "opposite", "", false, false], [2, 2, 23, 23, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Sensitivity", "and", "specificity", "values", "are", "agnostic", "to", "the", "percentage", "of", "positive", "cases", "in", "the", "population", "of", "interest", "(", "unlike", ",", "for", "example", ",", "accuracy", ")", "."], "sentence-detokenized": "Sensitivity and specificity values are agnostic to the percentage of positive cases in the population of interest (unlike, for example, accuracy).", "token2charspan": [[0, 11], [12, 15], [16, 27], [28, 34], [35, 38], [39, 47], [48, 50], [51, 54], [55, 65], [66, 68], [69, 77], [78, 83], [84, 86], [87, 90], [91, 101], [102, 104], [105, 113], [114, 115], [115, 121], [121, 122], [123, 126], [127, 134], [134, 135], [136, 144], [144, 145], [145, 146]]}
{"doc_key": "ai-dev-290", "ner": [[3, 5, "algorithm"], [12, 12, "misc"], [15, 16, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 12, 3, 5, "topic", "", false, false], [12, 12, 15, 16, "artifact", "", false, false], [12, 12, 18, 19, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["But", "very", "unpopular", "models", "of", "perceptrons", "were", "made", "by", "the", "book", "\"", "Perceptrons", "\"", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", ",", "published", "in", "1969", "."], "sentence-detokenized": "But very unpopular models of perceptrons were made by the book \"Perceptrons\" by Marvin Minsky and Seymour Papert, published in 1969.", "token2charspan": [[0, 3], [4, 8], [9, 18], [19, 25], [26, 28], [29, 40], [41, 45], [46, 50], [51, 53], [54, 57], [58, 62], [63, 64], [64, 75], [75, 76], [77, 79], [80, 86], [87, 93], [94, 97], [98, 105], [106, 112], [112, 113], [114, 123], [124, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-dev-291", "ner": [[0, 3, "conference"], [7, 8, "organisation"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 21, 23, "topic", "", false, false], [7, 8, 0, 3, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Document", "Understanding", "Conferences", "held", "annually", "by", "NIST", "have", "developed", "sophisticated", "criteria", "for", "evaluating", "methods", "that", "take", "on", "the", "challenge", "of", "summarizing", "multi-document", "documents", "."], "sentence-detokenized": "The Document Understanding Conferences held annually by NIST have developed sophisticated criteria for evaluating methods that take on the challenge of summarizing multi-document documents.", "token2charspan": [[0, 3], [4, 12], [13, 26], [27, 38], [39, 43], [44, 52], [53, 55], [56, 60], [61, 65], [66, 75], [76, 89], [90, 98], [99, 102], [103, 113], [114, 121], [122, 126], [127, 131], [132, 134], [135, 138], [139, 148], [149, 151], [152, 163], [164, 178], [179, 188], [188, 189]]}
{"doc_key": "ai-dev-292", "ner": [[0, 2, "product"], [26, 27, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 26, 27, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "parallel", "arm", "is", "designed", "so", "that", "each", "chain", "is", "generally", "short", ",", "simple", "and", "thus", "can", "be", "rigid", "against", "unwanted", "movement", ",", "compared", "to", "a", "series", "arm", "."], "sentence-detokenized": "A parallel arm is designed so that each chain is generally short, simple and thus can be rigid against unwanted movement, compared to a series arm.", "token2charspan": [[0, 1], [2, 10], [11, 14], [15, 17], [18, 26], [27, 29], [30, 34], [35, 39], [40, 45], [46, 48], [49, 58], [59, 64], [64, 65], [66, 72], [73, 76], [77, 81], [82, 85], [86, 88], [89, 94], [95, 102], [103, 111], [112, 120], [120, 121], [122, 130], [131, 133], [134, 135], [136, 142], [143, 146], [146, 147]]}
{"doc_key": "ai-dev-293", "ner": [[25, 25, "misc"], [27, 29, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "manipulator", "is", "what", "makes", "the", "robot", "move", ",", "and", "the", "design", "of", "these", "systems", "can", "be", "divided", "into", "several", "general", "types", ",", "such", "as", "SCARA", "and", "Cartesian", "coordinate", "robots", ",", "which", "use", "different", "coordinate", "systems", "to", "control", "the", "arms", "of", "the", "machine", "."], "sentence-detokenized": "The manipulator is what makes the robot move, and the design of these systems can be divided into several general types, such as SCARA and Cartesian coordinate robots, which use different coordinate systems to control the arms of the machine.", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 23], [24, 29], [30, 33], [34, 39], [40, 44], [44, 45], [46, 49], [50, 53], [54, 60], [61, 63], [64, 69], [70, 77], [78, 81], [82, 84], [85, 92], [93, 97], [98, 105], [106, 113], [114, 119], [119, 120], [121, 125], [126, 128], [129, 134], [135, 138], [139, 148], [149, 159], [160, 166], [166, 167], [168, 173], [174, 177], [178, 187], [188, 198], [199, 206], [207, 209], [210, 217], [218, 221], [222, 226], [227, 229], [230, 233], [234, 241], [241, 242]]}
{"doc_key": "ai-dev-294", "ner": [[2, 2, "country"], [9, 12, "organisation"], [15, 20, "organisation"], [23, 26, "organisation"], [29, 31, "organisation"], [34, 40, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 12, 2, 2, "physical", "", false, false], [15, 20, 2, 2, "physical", "", false, false], [23, 26, 2, 2, "physical", "", false, false], [29, 31, 2, 2, "physical", "", false, false], [34, 40, 2, 2, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "the", "USA", "he", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "Linguistic", "Society", "of", "America", ",", "the", "American", "Philosophical", "Association", "and", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In the USA he is a member of the National Academy of Sciences, the American Academy of Arts and Sciences, the Linguistic Society of America, the American Philosophical Association and the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 13], [14, 16], [17, 18], [19, 25], [26, 28], [29, 32], [33, 41], [42, 49], [50, 52], [53, 61], [61, 62], [63, 66], [67, 75], [76, 83], [84, 86], [87, 91], [92, 95], [96, 104], [104, 105], [106, 109], [110, 120], [121, 128], [129, 131], [132, 139], [139, 140], [141, 144], [145, 153], [154, 167], [168, 179], [180, 183], [184, 187], [188, 196], [197, 208], [209, 212], [213, 216], [217, 228], [229, 231], [232, 239], [239, 240]]}
{"doc_key": "ai-dev-295", "ner": [[8, 10, "algorithm"], [12, 12, "algorithm"], [23, 24, "algorithm"], [27, 29, "algorithm"], [33, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 10, 23, 24, "named", "", false, false], [12, 12, 8, 10, "named", "", false, false], [23, 24, 27, 29, "compare", "", false, false], [23, 24, 33, 34, "related-to", "performs", false, false], [27, 29, 33, 34, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["They", "became", "very", "popular", "with", "the", "popularity", "of", "support", "vector", "machines", "(", "SVMs", ")", "in", "the", "1990s", ",", "when", "it", "was", "discovered", "that", "SVMs", "could", "compete", "with", "neural", "networks", "in", "tasks", "such", "as", "handwriting", "recognition", "."], "sentence-detokenized": "They became very popular with the popularity of support vector machines (SVMs) in the 1990s, when it was discovered that SVMs could compete with neural networks in tasks such as handwriting recognition.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 24], [25, 29], [30, 33], [34, 44], [45, 47], [48, 55], [56, 62], [63, 71], [72, 73], [73, 77], [77, 78], [79, 81], [82, 85], [86, 91], [91, 92], [93, 97], [98, 100], [101, 104], [105, 115], [116, 120], [121, 125], [126, 131], [132, 139], [140, 144], [145, 151], [152, 160], [161, 163], [164, 169], [170, 174], [175, 177], [178, 189], [190, 201], [201, 202]]}
{"doc_key": "ai-dev-296", "ner": [[2, 3, "misc"], [9, 9, "misc"], [13, 14, "algorithm"], [22, 23, "misc"], [29, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 9, 9, "usage", "", false, false], [2, 3, 22, 23, "usage", "", false, false], [9, 9, 13, 14, "origin", "result_of_algorithm", false, false], [22, 23, 29, 30, "origin", "result_of_algorithm", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "empirical", "whitening", "transformation", "is", "obtained", "by", "estimating", "the", "covariance", "(", "e.g.", ",", "maximum", "likelihood", ")", "and", "then", "constructing", "the", "corresponding", "estimated", "whitening", "matrix", "(", "e.g.", ",", "using", "the", "Cholesky", "decomposition", ")", "."], "sentence-detokenized": "The empirical whitening transformation is obtained by estimating the covariance (e.g., maximum likelihood) and then constructing the corresponding estimated whitening matrix (e.g., using the Cholesky decomposition).", "token2charspan": [[0, 3], [4, 13], [14, 23], [24, 38], [39, 41], [42, 50], [51, 53], [54, 64], [65, 68], [69, 79], [80, 81], [81, 85], [85, 86], [87, 94], [95, 105], [105, 106], [107, 110], [111, 115], [116, 128], [129, 132], [133, 146], [147, 156], [157, 166], [167, 173], [174, 175], [175, 179], [179, 180], [181, 186], [187, 190], [191, 199], [200, 213], [213, 214], [214, 215]]}
{"doc_key": "ai-dev-297", "ner": [[0, 0, "organisation"], [8, 10, "product"], [23, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 0, 0, "artifact", "", false, false], [23, 24, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["IAI", "is", "the", "world", "'s", "largest", "manufacturer", "of", "Cartesian", "coordinate", "robots", "and", "a", "recognized", "leader", "in", "low", "-", "cost", ",", "high", "-", "performance", "SCARA", "robots", "."], "sentence-detokenized": "IAI is the world's largest manufacturer of Cartesian coordinate robots and a recognized leader in low-cost, high-performance SCARA robots.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [16, 18], [19, 26], [27, 39], [40, 42], [43, 52], [53, 63], [64, 70], [71, 74], [75, 76], [77, 87], [88, 94], [95, 97], [98, 101], [101, 102], [102, 106], [106, 107], [108, 112], [112, 113], [113, 124], [125, 130], [131, 137], [137, 138]]}
{"doc_key": "ai-dev-298", "ner": [[10, 10, "field"], [13, 14, "field"], [16, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 28, "field"], [30, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [], "relations_mapping_to_source": [], "sentence": ["Formal", "conceptual", "analysis", "finds", "practical", "application", "in", "such", "fields", "as", "data", "mining", ",", "text", "mining", ",", "machine", "learning", ",", "knowledge", "management", ",", "semantic", "web", ",", "software", "development", ",", "chemistry", "and", "biology", "."], "sentence-detokenized": "Formal conceptual analysis finds practical application in such fields as data mining, text mining, machine learning, knowledge management, semantic web, software development, chemistry and biology.", "token2charspan": [[0, 6], [7, 17], [18, 26], [27, 32], [33, 42], [43, 54], [55, 57], [58, 62], [63, 69], [70, 72], [73, 77], [78, 84], [84, 85], [86, 90], [91, 97], [97, 98], [99, 106], [107, 115], [115, 116], [117, 126], [127, 137], [137, 138], [139, 147], [148, 151], [151, 152], [153, 161], [162, 173], [173, 174], [175, 184], [185, 188], [189, 196], [196, 197]]}
{"doc_key": "ai-dev-299", "ner": [[1, 2, "field"], [3, 6, "field"], [10, 11, "field"], [17, 18, "field"], [29, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 6, 17, 18, "part-of", "", false, false], [3, 6, 29, 30, "topic", "", false, false], [10, 11, 3, 6, "named", "", false, false], [17, 18, 1, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", ",", "computational", "learning", "theory", "(", "or", "simply", "learning", "theory", ")", "is", "a", "subfield", "of", "artificial", "intelligence", "devoted", "to", "the", "study", "of", "the", "design", "and", "analysis", "of", "machine", "learning", "algorithms", "."], "sentence-detokenized": "In computer science, computational learning theory (or simply learning theory) is a subfield of artificial intelligence devoted to the study of the design and analysis of machine learning algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 34], [35, 43], [44, 50], [51, 52], [52, 54], [55, 61], [62, 70], [71, 77], [77, 78], [79, 81], [82, 83], [84, 92], [93, 95], [96, 106], [107, 119], [120, 127], [128, 130], [131, 134], [135, 140], [141, 143], [144, 147], [148, 154], [155, 158], [159, 167], [168, 170], [171, 178], [179, 187], [188, 198], [198, 199]]}
{"doc_key": "ai-dev-300", "ner": [[0, 1, "algorithm"], [3, 3, "algorithm"], [9, 10, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 0, 1, "named", "", false, false], [9, 10, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Collaborative", "filtering", "(", "CF", ")", "is", "a", "method", "used", "by", "recommender", "systems", "."], "sentence-detokenized": "Collaborative filtering (CF) is a method used by recommender systems.", "token2charspan": [[0, 13], [14, 23], [24, 25], [25, 27], [27, 28], [29, 31], [32, 33], [34, 40], [41, 45], [46, 48], [49, 60], [61, 68], [68, 69]]}
{"doc_key": "ai-dev-301", "ner": [[0, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["False", "positive", "rate", "is", "the", "proportion", "of", "all", "negative", "results", "that", "still", "yield", "positive", "test", "results", ",", "i.e.", "the", "conditional", "probability", "of", "a", "positive", "test", "result", "in", "the", "presence", "of", "an", "event", "that", "was", "not", "present", "."], "sentence-detokenized": "False positive rate is the proportion of all negative results that still yield positive test results, i.e. the conditional probability of a positive test result in the presence of an event that was not present.", "token2charspan": [[0, 5], [6, 14], [15, 19], [20, 22], [23, 26], [27, 37], [38, 40], [41, 44], [45, 53], [54, 61], [62, 66], [67, 72], [73, 78], [79, 87], [88, 92], [93, 100], [100, 101], [102, 106], [107, 110], [111, 122], [123, 134], [135, 137], [138, 139], [140, 148], [149, 153], [154, 160], [161, 163], [164, 167], [168, 176], [177, 179], [180, 182], [183, 188], [189, 193], [194, 197], [198, 201], [202, 209], [209, 210]]}
{"doc_key": "ai-dev-302", "ner": [[1, 15, "misc"], [40, 41, "metrics"], [44, 44, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 15, 40, 41, "topic", "", false, false], [1, 15, 44, 44, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "VLDB", "'", "8", ":", "Proceedings", "of", "the", "34th", "International", "Conference", "on", "Very", "Large", "Data", "Bases", ",", "pages", "422--433", ".", "it", "is", "shown", "that", "the", "given", "values", "for", "mathC", "/", "math", "and", "mathK", "/", "math", "in", "general", "mean", "relatively", "low", "accuracy", "of", "iteratively", "computed", "SimRank", "estimates", "."], "sentence-detokenized": "In VLDB '8: Proceedings of the 34th International Conference on Very Large Data Bases, pages 422--433. it is shown that the given values for mathC/math and mathK/math in general mean relatively low accuracy of iteratively computed SimRank estimates.", "token2charspan": [[0, 2], [3, 7], [8, 9], [9, 10], [10, 11], [12, 23], [24, 26], [27, 30], [31, 35], [36, 49], [50, 60], [61, 63], [64, 68], [69, 74], [75, 79], [80, 85], [85, 86], [87, 92], [93, 101], [101, 102], [103, 105], [106, 108], [109, 114], [115, 119], [120, 123], [124, 129], [130, 136], [137, 140], [141, 146], [146, 147], [147, 151], [152, 155], [156, 161], [161, 162], [162, 166], [167, 169], [170, 177], [178, 182], [183, 193], [194, 197], [198, 206], [207, 209], [210, 221], [222, 230], [231, 238], [239, 248], [248, 249]]}
{"doc_key": "ai-dev-303", "ner": [[5, 8, "misc"], [10, 12, "misc"], [20, 20, "person"], [23, 25, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 12, 5, 8, "general-affiliation", "", false, false], [10, 12, 20, 20, "artifact", "", false, false], [10, 12, 23, 25, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "June", "2015", ",", "the", "sci", "-", "fi", "drama", "\"", "Sense8", "\"", "was", "released", ",", "written", "and", "produced", "by", "the", "Wachowski", "couple", "and", "J.", "Michael", "Straczynski", "."], "sentence-detokenized": "In June 2015, the sci-fi drama \"Sense8\" was released, written and produced by the Wachowski couple and J. Michael Straczynski.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 21], [21, 22], [22, 24], [25, 30], [31, 32], [32, 38], [38, 39], [40, 43], [44, 52], [52, 53], [54, 61], [62, 65], [66, 74], [75, 77], [78, 81], [82, 91], [92, 98], [99, 102], [103, 105], [106, 113], [114, 125], [125, 126]]}
{"doc_key": "ai-dev-304", "ner": [[1, 2, "misc"], [6, 7, "product"], [26, 28, "misc"], [36, 36, "country"], [38, 38, "country"], [40, 40, "country"], [42, 42, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 2, 6, 7, "topic", "", false, false], [36, 36, 26, 28, "type-of", "", false, false], [38, 38, 26, 28, "type-of", "", false, false], [40, 40, 26, 28, "type-of", "", false, false], [42, 42, 26, 28, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Although", "Eurotra", "never", "established", "a", "working", "MT", "system", ",", "the", "project", "had", "a", "far", "-", "reaching", "long", "-", "term", "impact", "on", "the", "nascent", "broadcasting", "industry", "in", "European", "member", "states", ",", "particularly", "in", "the", "southern", "countries", "of", "Greece", ",", "Italy", ",", "Spain", "and", "Portugal", "."], "sentence-detokenized": "Although Eurotra never established a working MT system, the project had a far-reaching long-term impact on the nascent broadcasting industry in European member states, particularly in the southern countries of Greece, Italy, Spain and Portugal.", "token2charspan": [[0, 8], [9, 16], [17, 22], [23, 34], [35, 36], [37, 44], [45, 47], [48, 54], [54, 55], [56, 59], [60, 67], [68, 71], [72, 73], [74, 77], [77, 78], [78, 86], [87, 91], [91, 92], [92, 96], [97, 103], [104, 106], [107, 110], [111, 118], [119, 131], [132, 140], [141, 143], [144, 152], [153, 159], [160, 166], [166, 167], [168, 180], [181, 183], [184, 187], [188, 196], [197, 206], [207, 209], [210, 216], [216, 217], [218, 223], [223, 224], [225, 230], [231, 234], [235, 243], [243, 244]]}
{"doc_key": "ai-dev-305", "ner": [[0, 2, "algorithm"], [6, 8, "task"], [16, 18, "task"], [20, 20, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 8, 0, 2, "usage", "", true, false], [16, 18, 6, 8, "named", "", false, false], [20, 20, 16, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Autoencoder", "has", "been", "successfully", "applied", "to", "machine", "translation", "of", "human", "speech", ",", "commonly", "referred", "to", "as", "Neural", "Machine", "Translation", "(", "NMT", ")", "."], "sentence-detokenized": "Autoencoder has been successfully applied to machine translation of human speech, commonly referred to as Neural Machine Translation (NMT).", "token2charspan": [[0, 11], [12, 15], [16, 20], [21, 33], [34, 41], [42, 44], [45, 52], [53, 64], [65, 67], [68, 73], [74, 80], [80, 81], [82, 90], [91, 99], [100, 102], [103, 105], [106, 112], [113, 120], [121, 132], [133, 134], [134, 137], [137, 138], [138, 139]]}
{"doc_key": "ai-dev-306", "ner": [[9, 11, "metrics"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Popular", "examples", "of", "probability", "-", "based", "fitness", "functions", "are", "maximum", "likelihood", "estimation", "and", "loop", "loss", "."], "sentence-detokenized": "Popular examples of probability-based fitness functions are maximum likelihood estimation and loop loss.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 31], [31, 32], [32, 37], [38, 45], [46, 55], [56, 59], [60, 67], [68, 78], [79, 89], [90, 93], [94, 98], [99, 103], [103, 104]]}
{"doc_key": "ai-dev-307", "ner": [[0, 0, "field"], [1, 13, "task"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 13, 0, 0, "part-of", "", false, false], [15, 16, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Data", "mining", "is", "a", "related", "field", "of", "study", "that", "focuses", "on", "exploratory", "data", "analysis", "through", "unsupervised", "learning", "."], "sentence-detokenized": "Data mining is a related field of study that focuses on exploratory data analysis through unsupervised learning.", "token2charspan": [[0, 4], [5, 11], [12, 14], [15, 16], [17, 24], [25, 30], [31, 33], [34, 39], [40, 44], [45, 52], [53, 55], [56, 67], [68, 72], [73, 81], [82, 89], [90, 102], [103, 111], [111, 112]]}
{"doc_key": "ai-dev-308", "ner": [[0, 1, "algorithm"], [13, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 13, 14, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Collaborative", "filtering", "covers", "methods", "of", "matching", "people", "with", "similar", "interests", "and", "creating", "a", "recommendation", "system", "based", "on", "this", "."], "sentence-detokenized": "Collaborative filtering covers methods of matching people with similar interests and creating a recommendation system based on this.", "token2charspan": [[0, 13], [14, 23], [24, 30], [31, 38], [39, 41], [42, 50], [51, 57], [58, 62], [63, 70], [71, 80], [81, 84], [85, 93], [94, 95], [96, 110], [111, 117], [118, 123], [124, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-dev-309", "ner": [[3, 8, "algorithm"], [13, 13, "programlang"], [16, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 19, 3, 8, "type-of", "", false, false], [16, 19, 13, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "number", "of", "WordNet", "-", "based", "word", "similarity", "algorithms", "are", "implemented", "in", "the", "Perl", "package", "called", "WordNet", ":", ":", "Similarity", "."], "sentence-detokenized": "A number of WordNet-based word similarity algorithms are implemented in the Perl package called WordNet:: Similarity.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 19], [19, 20], [20, 25], [26, 30], [31, 41], [42, 52], [53, 56], [57, 68], [69, 71], [72, 75], [76, 80], [81, 88], [89, 95], [96, 103], [103, 104], [104, 105], [106, 116], [116, 117]]}
{"doc_key": "ai-dev-310", "ner": [[4, 4, "conference"], [6, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Another", "paper", "presented", "at", "CVPR", "2000", "by", "Eric", "Miller", ",", "Nicholas", "Matsakis", "and", "Paul", "Viola", "will", "also", "be", "discussed", "."], "sentence-detokenized": "Another paper presented at CVPR 2000 by Eric Miller, Nicholas Matsakis and Paul Viola will also be discussed.", "token2charspan": [[0, 7], [8, 13], [14, 23], [24, 26], [27, 31], [32, 36], [37, 39], [40, 44], [45, 51], [51, 52], [53, 61], [62, 70], [71, 74], [75, 79], [80, 85], [86, 90], [91, 95], [96, 98], [99, 108], [108, 109]]}
{"doc_key": "ai-dev-311", "ner": [[0, 0, "algorithm"], [7, 8, "misc"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 13, 14, "compare", "", false, false], [13, 14, 7, 8, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Quality", "was", "not", "assessed", "by", "traditional", "modern", "clustering", "algorithms", ",", "except", "for", "the", "Jaccard", "index", "."], "sentence-detokenized": "Quality was not assessed by traditional modern clustering algorithms, except for the Jaccard index.", "token2charspan": [[0, 7], [8, 11], [12, 15], [16, 24], [25, 27], [28, 39], [40, 46], [47, 57], [58, 68], [68, 69], [70, 76], [77, 80], [81, 84], [85, 92], [93, 98], [98, 99]]}
{"doc_key": "ai-dev-312", "ner": [[2, 5, "misc"], [11, 15, "misc"], [7, 8, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 15, 2, 5, "physical", "", false, false], [11, 15, 7, 8, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["During", "the", "VEX", "Robotics", "World", "Championships", ",", "Freedom", "Hall", "hosts", "the", "Parade", "of", "Nations", ",", "in", "which", "hundreds", "of", "students", "from", "over", "30", "countries", "participate", "."], "sentence-detokenized": "During the VEX Robotics World Championships, Freedom Hall hosts the Parade of Nations, in which hundreds of students from over 30 countries participate.", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 23], [24, 29], [30, 43], [43, 44], [45, 52], [53, 57], [58, 63], [64, 67], [68, 74], [75, 77], [78, 85], [85, 86], [87, 89], [90, 95], [96, 104], [105, 107], [108, 116], [117, 121], [122, 126], [127, 129], [130, 139], [140, 151], [151, 152]]}
{"doc_key": "ai-dev-313", "ner": [[5, 7, "metrics"], [10, 10, "metrics"], [14, 16, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 10, 5, 7, "named", "", false, false], [18, 18, 14, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Other", "accuracy", "measures", "include", "the", "single", "word", "error", "rate", "(", "SWER", ")", "and", "the", "command", "success", "rate", "(", "CSR", ")", "."], "sentence-detokenized": "Other accuracy measures include the single word error rate (SWER) and the command success rate (CSR).", "token2charspan": [[0, 5], [6, 14], [15, 23], [24, 31], [32, 35], [36, 42], [43, 47], [48, 53], [54, 58], [59, 60], [60, 64], [64, 65], [66, 69], [70, 73], [74, 81], [82, 89], [90, 94], [95, 96], [96, 99], [99, 100], [100, 101]]}
{"doc_key": "ai-dev-314", "ner": [[9, 10, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["They", "presented", "their", "method", "and", "results", "in", "the", "journal", "SIGGRAPH", "2000", "."], "sentence-detokenized": "They presented their method and results in the journal SIGGRAPH 2000.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 27], [28, 31], [32, 39], [40, 42], [43, 46], [47, 54], [55, 63], [64, 68], [68, 69]]}
{"doc_key": "ai-dev-315", "ner": [[0, 2, "conference"], [7, 7, "misc"], [9, 13, "misc"], [18, 19, "conference"], [25, 31, "researcher"], [40, 41, "researcher"], [47, 48, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 7, 7, "origin", "", false, false], [7, 7, 18, 19, "physical", "", false, false], [7, 7, 18, 19, "temporal", "", false, false], [7, 7, 25, 31, "origin", "", false, false], [7, 7, 40, 41, "origin", "", false, false], [9, 13, 7, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "KDD", "conference", "grew", "out", "of", "the", "KDD", "(", "Knowledge", "Discovery", "and", "Data", "Mining", ")", "workshops", "at", "the", "AAAI", "conferences", ",", "which", "were", "started", "by", "Grigory", "I", ".", "Pyatetsky", "-", "Shapiro", "in", "1989", ",", "1991", ",", "and", "1993", "and", "by", "Osama", "Fayyad", "in", "1994", ".", "Computer", "Science", "|", "ACM", "."], "sentence-detokenized": "The KDD conference grew out of the KDD (Knowledge Discovery and Data Mining) workshops at the AAAI conferences, which were started by Grigory I. Pyatetsky-Shapiro in 1989, 1991, and 1993 and by Osama Fayyad in 1994. Computer Science | ACM.", "token2charspan": [[0, 3], [4, 7], [8, 18], [19, 23], [24, 27], [28, 30], [31, 34], [35, 38], [39, 40], [40, 49], [50, 59], [60, 63], [64, 68], [69, 75], [75, 76], [77, 86], [87, 89], [90, 93], [94, 98], [99, 110], [110, 111], [112, 117], [118, 122], [123, 130], [131, 133], [134, 141], [142, 143], [143, 144], [145, 154], [154, 155], [155, 162], [163, 165], [166, 170], [170, 171], [172, 176], [176, 177], [178, 181], [182, 186], [187, 190], [191, 193], [194, 199], [200, 206], [207, 209], [210, 214], [214, 215], [216, 224], [225, 232], [233, 234], [235, 238], [238, 239]]}
{"doc_key": "ai-dev-316", "ner": [[9, 12, "conference"], [14, 14, "conference"], [18, 23, "organisation"], [25, 25, "organisation"], [29, 33, "conference"], [35, 35, "conference"], [39, 45, "conference"], [47, 47, "conference"], [51, 57, "conference"], [59, 59, "conference"], [64, 68, "conference"], [70, 70, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[14, 14, 9, 12, "named", "", false, false], [25, 25, 18, 23, "named", "", false, false], [35, 35, 29, 33, "named", "", false, false], [47, 47, 39, 45, "named", "", false, false], [59, 59, 51, 57, "named", "", false, false], [70, 70, 64, 68, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["He", "has", "been", "elected", "as", "a", "member", "of", "the", "Association", "for", "Computing", "Machinery", "(", "ACM", ")", ",", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", ",", "the", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", ",", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "(", "AAAS", ")", ",", "and", "the", "Society", "for", "Optics", "and", "Photonics", "(", "SPIE", ")", "."], "sentence-detokenized": "He has been elected as a member of the Association for Computing Machinery (ACM), the Institute of Electrical and Electronics Engineers (IEEE), the International Association for Pattern Recognition (IAPR), the Association for the Advancement of Artificial Intelligence (AAAI), the American Association for the Advancement of Science (AAAS), and the Society for Optics and Photonics (SPIE).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 19], [20, 22], [23, 24], [25, 31], [32, 34], [35, 38], [39, 50], [51, 54], [55, 64], [65, 74], [75, 76], [76, 79], [79, 80], [80, 81], [82, 85], [86, 95], [96, 98], [99, 109], [110, 113], [114, 125], [126, 135], [136, 137], [137, 141], [141, 142], [142, 143], [144, 147], [148, 161], [162, 173], [174, 177], [178, 185], [186, 197], [198, 199], [199, 203], [203, 204], [204, 205], [206, 209], [210, 221], [222, 225], [226, 229], [230, 241], [242, 244], [245, 255], [256, 268], [269, 270], [270, 274], [274, 275], [275, 276], [277, 280], [281, 289], [290, 301], [302, 305], [306, 309], [310, 321], [322, 324], [325, 332], [333, 334], [334, 338], [338, 339], [339, 340], [341, 344], [345, 348], [349, 356], [357, 360], [361, 367], [368, 371], [372, 381], [382, 383], [383, 387], [387, 388], [388, 389]]}
{"doc_key": "ai-dev-317", "ner": [[0, 1, "field"], [3, 4, "field"], [16, 17, "field"], [30, 31, "field"], [46, 51, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 16, 17, "named", "", false, false], [3, 4, 30, 31, "named", "", false, false], [30, 31, 46, 51, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "learning", "and", "data", "mining", "often", "use", "the", "same", "techniques", "and", "overlap", "considerably", ",", "but", "while", "machine", "learning", "focuses", "on", "prediction", "based", "on", "known", "properties", "derived", "from", "training", "data", ",", "data", "mining", "focuses", "on", "discovering", "(", "previously", ")", "unknown", "properties", "in", "data", "(", "this", "is", "the", "knowledge", "discovery", "step", "of", "database", "mining", ")", "."], "sentence-detokenized": "Machine learning and data mining often use the same techniques and overlap considerably, but while machine learning focuses on prediction based on known properties derived from training data, data mining focuses on discovering (previously) unknown properties in data (this is the knowledge discovery step of database mining).", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 25], [26, 32], [33, 38], [39, 42], [43, 46], [47, 51], [52, 62], [63, 66], [67, 74], [75, 87], [87, 88], [89, 92], [93, 98], [99, 106], [107, 115], [116, 123], [124, 126], [127, 137], [138, 143], [144, 146], [147, 152], [153, 163], [164, 171], [172, 176], [177, 185], [186, 190], [190, 191], [192, 196], [197, 203], [204, 211], [212, 214], [215, 226], [227, 228], [228, 238], [238, 239], [240, 247], [248, 258], [259, 261], [262, 266], [267, 268], [268, 272], [273, 275], [276, 279], [280, 289], [290, 299], [300, 304], [305, 307], [308, 316], [317, 323], [323, 324], [324, 325]]}
{"doc_key": "ai-dev-318", "ner": [[0, 1, "product"], [4, 4, "programlang"], [11, 11, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 4, 4, "general-affiliation", "", false, false], [0, 1, 4, 4, "related-to", "runs_on", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Indy", "is", "written", "in", "Java", "and", "therefore", "runs", "on", "most", "modern", "operating", "systems", "."], "sentence-detokenized": "Indy is written in Java and therefore runs on most modern operating systems.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 23], [24, 27], [28, 37], [38, 42], [43, 45], [46, 50], [51, 57], [58, 67], [68, 75], [75, 76]]}
{"doc_key": "ai-dev-319", "ner": [[0, 0, "algorithm"], [5, 7, "algorithm"], [9, 9, "algorithm"], [15, 17, "algorithm"], [19, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 7, "type-of", "", true, false], [9, 9, 5, 7, "named", "", false, false], [15, 17, 5, 7, "type-of", "", true, false], [19, 19, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["NMF", "is", "an", "example", "of", "nonnegative", "quadratic", "programming", "(", "NQP", ")", ",", "as", "well", "as", "support", "vector", "machine", "(", "SVM", ")", "."], "sentence-detokenized": "NMF is an example of nonnegative quadratic programming (NQP), as well as support vector machine (SVM).", "token2charspan": [[0, 3], [4, 6], [7, 9], [10, 17], [18, 20], [21, 32], [33, 42], [43, 54], [55, 56], [56, 59], [59, 60], [60, 61], [62, 64], [65, 69], [70, 72], [73, 80], [81, 87], [88, 95], [96, 97], [97, 100], [100, 101], [101, 102]]}
{"doc_key": "ai-dev-320", "ner": [[8, 9, "misc"], [12, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 12, 14, "usage", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["The", "method", "is", "based", "on", "the", "estimation", "of", "conditional", "probabilities", "using", "the", "nonparametric", "maximum", "likelihood", "method", ",", "which", "leads", "to"], "sentence-detokenized": "The method is based on the estimation of conditional probabilities using the nonparametric maximum likelihood method, which leads to", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 26], [27, 37], [38, 40], [41, 52], [53, 66], [67, 72], [73, 76], [77, 90], [91, 98], [99, 109], [110, 116], [116, 117], [118, 123], [124, 129], [130, 132]]}
{"doc_key": "ai-dev-321", "ner": [[8, 8, "algorithm"], [10, 12, "algorithm"], [15, 17, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "basic", "concepts", "used", "in", "spectral", "estimation", "include", "autocorrelation", ",", "multivariate", "Fourier", "transform", ",", "root", "mean", "square", "error", "and", "entropy", "."], "sentence-detokenized": "The basic concepts used in spectral estimation include autocorrelation, multivariate Fourier transform, root mean square error and entropy.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 23], [24, 26], [27, 35], [36, 46], [47, 54], [55, 70], [70, 71], [72, 84], [85, 92], [93, 102], [102, 103], [104, 108], [109, 113], [114, 120], [121, 126], [127, 130], [131, 138], [138, 139]]}
{"doc_key": "ai-dev-322", "ner": [[5, 7, "algorithm"], [11, 11, "field"], [13, 13, "algorithm"], [15, 17, "algorithm"], [19, 20, "task"], [22, 22, "field"], [24, 24, "field"], [26, 27, "task"], [29, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 7, 11, 11, "part-of", "", false, false], [5, 7, 13, 13, "part-of", "", false, false], [5, 7, 15, 17, "part-of", "", false, false], [5, 7, 19, 20, "part-of", "", false, false], [5, 7, 22, 22, "part-of", "", false, false], [5, 7, 24, 24, "part-of", "", false, false], [5, 7, 26, 27, "part-of", "", false, false], [5, 7, 29, 30, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "fields", "of", "application", "of", "nuclear", "methods", "are", "diverse", "and", "include", "geostatistics", ",", "kriging", ",", "inverse", "distance", "weighting", ",", "3D", "reconstruction", ",", "bioinformatics", ",", "chemoinformatics", ",", "information", "extraction", "and", "handwriting", "recognition", "."], "sentence-detokenized": "The fields of application of nuclear methods are diverse and include geostatistics, kriging, inverse distance weighting, 3D reconstruction, bioinformatics, chemoinformatics, information extraction and handwriting recognition.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 25], [26, 28], [29, 36], [37, 44], [45, 48], [49, 56], [57, 60], [61, 68], [69, 82], [82, 83], [84, 91], [91, 92], [93, 100], [101, 109], [110, 119], [119, 120], [121, 123], [124, 138], [138, 139], [140, 154], [154, 155], [156, 172], [172, 173], [174, 185], [186, 196], [197, 200], [201, 212], [213, 224], [224, 225]]}
{"doc_key": "ai-dev-323", "ner": [[13, 13, "organisation"], [15, 19, "product"], [21, 21, "product"], [26, 30, "product"], [32, 32, "product"], [36, 37, "product"], [39, 41, "product"], [43, 43, "product"], [46, 48, "product"], [52, 53, "product"], [59, 59, "product"], [64, 69, "product"], [73, 74, "product"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[15, 19, 13, 13, "artifact", "", false, false], [15, 19, 36, 37, "compare", "", false, false], [15, 19, 39, 41, "compare", "", false, false], [15, 19, 43, 43, "compare", "", false, false], [15, 19, 46, 48, "compare", "", false, false], [15, 19, 52, 53, "compare", "", false, false], [15, 19, 59, 59, "compare", "", false, false], [15, 19, 64, 69, "compare", "", false, false], [15, 19, 73, 74, "compare", "", false, false], [21, 21, 15, 19, "named", "", false, false], [26, 30, 36, 37, "compare", "", false, false], [26, 30, 39, 41, "compare", "", false, false], [26, 30, 43, 43, "compare", "", false, false], [26, 30, 46, 48, "compare", "", false, false], [26, 30, 52, 53, "compare", "", false, false], [26, 30, 59, 59, "compare", "", false, false], [26, 30, 64, 69, "compare", "", false, false], [26, 30, 73, 74, "compare", "", false, false], [32, 32, 26, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19], "sentence": ["Robots", "can", "be", "autonomous", "or", "semi-autonomous", "and", "range", "from", "humanoids", ",", "such", "as", "Honda", "'s", "Advanced", "Step", "in", "Innovative", "Mobility", "(", "ASIMO", ")", "and", "TOSY", "'s", "TOSY", "Ping", "Pong", "Playing", "Robot", "(", "TOPIO", ")", ",", "to", "industrial", "robots", ",", "medical", "operating", "robots", ",", "patient", "assistants", ",", "dog", "therapy", "robots", ",", "collectively", "programmed", "swarm", "robots", ",", "unmanned", "aerial", "vehicles", "(", "UAVs", ")", "such", "as", "the", "General", "Atomics", "MQ", "-", "1", "Predator", ",", "and", "even", "microscopic", "nanorobots", "."], "sentence-detokenized": "Robots can be autonomous or semi-autonomous and range from humanoids, such as Honda's Advanced Step in Innovative Mobility (ASIMO) and TOSY's TOSY Ping Pong Playing Robot (TOPIO), to industrial robots, medical operating robots, patient assistants, dog therapy robots, collectively programmed swarm robots, unmanned aerial vehicles (UAVs) such as the General Atomics MQ-1 Predator, and even microscopic nanorobots.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 24], [25, 27], [28, 43], [44, 47], [48, 53], [54, 58], [59, 68], [68, 69], [70, 74], [75, 77], [78, 83], [83, 85], [86, 94], [95, 99], [100, 102], [103, 113], [114, 122], [123, 124], [124, 129], [129, 130], [131, 134], [135, 139], [139, 141], [142, 146], [147, 151], [152, 156], [157, 164], [165, 170], [171, 172], [172, 177], [177, 178], [178, 179], [180, 182], [183, 193], [194, 200], [200, 201], [202, 209], [210, 219], [220, 226], [226, 227], [228, 235], [236, 246], [246, 247], [248, 251], [252, 259], [260, 266], [266, 267], [268, 280], [281, 291], [292, 297], [298, 304], [304, 305], [306, 314], [315, 321], [322, 330], [331, 332], [332, 336], [336, 337], [338, 342], [343, 345], [346, 349], [350, 357], [358, 365], [366, 368], [368, 369], [369, 370], [371, 379], [379, 380], [381, 384], [385, 389], [390, 401], [402, 412], [412, 413]]}
{"doc_key": "ai-dev-324", "ner": [[0, 0, "product"], [2, 3, "product"], [9, 16, "university"], [17, 18, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 27, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 17, 18, "artifact", "", false, false], [0, 0, 20, 21, "artifact", "", false, false], [0, 0, 23, 24, "artifact", "", false, false], [0, 0, 26, 27, "artifact", "", false, false], [2, 3, 17, 18, "artifact", "", false, false], [2, 3, 20, 21, "artifact", "", false, false], [2, 3, 23, 24, "artifact", "", false, false], [2, 3, 26, 27, "artifact", "", false, false], [17, 18, 9, 16, "physical", "", false, false], [20, 21, 9, 16, "physical", "", false, false], [23, 24, 9, 16, "physical", "", false, false], [26, 27, 9, 16, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Freddy", "and", "Freddy", "II", "are", "robots", "created", "at", "the", "University", "of", "Edinburgh", "'s", "School", "of", "Informatics", "by", "Pat", "Ambler", ",", "Robin", "Popplestone", ",", "Austin", "Tate", "and", "Donald", "Mitchie", ",", "capable", "of", "assembling", "wooden", "blocks", "in", "a", "few", "hours", "."], "sentence-detokenized": "Freddy and Freddy II are robots created at the University of Edinburgh's School of Informatics by Pat Ambler, Robin Popplestone, Austin Tate and Donald Mitchie, capable of assembling wooden blocks in a few hours.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 20], [21, 24], [25, 31], [32, 39], [40, 42], [43, 46], [47, 57], [58, 60], [61, 70], [70, 72], [73, 79], [80, 82], [83, 94], [95, 97], [98, 101], [102, 108], [108, 109], [110, 115], [116, 127], [127, 128], [129, 135], [136, 140], [141, 144], [145, 151], [152, 159], [159, 160], [161, 168], [169, 171], [172, 182], [183, 189], [190, 196], [197, 199], [200, 201], [202, 205], [206, 211], [211, 212]]}
{"doc_key": "ai-dev-325", "ner": [[6, 6, "location"], [8, 8, "country"], [15, 15, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 8, 8, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "spent", "his", "childhood", "years", "in", "Paris", ",", "France", ",", "where", "his", "parents", "emigrated", "from", "Lithuania", "in", "the", "early", "1920s", "."], "sentence-detokenized": "He spent his childhood years in Paris, France, where his parents emigrated from Lithuania in the early 1920s.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 22], [23, 28], [29, 31], [32, 37], [37, 38], [39, 45], [45, 46], [47, 52], [53, 56], [57, 64], [65, 74], [75, 79], [80, 89], [90, 92], [93, 96], [97, 102], [103, 108], [108, 109]]}
{"doc_key": "ai-dev-326", "ner": [[2, 3, "researcher"], [6, 8, "misc"], [14, 17, "organisation"], [10, 13, "university"], [24, 35, "university"], [38, 39, "university"], [42, 45, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 3, 6, 8, "role", "", false, false], [2, 3, 10, 13, "physical", "", false, false], [2, 3, 24, 35, "role", "", false, false], [2, 3, 38, 39, "role", "", false, false], [2, 3, 42, 45, "role", "", false, false], [6, 8, 14, 17, "part-of", "", false, false], [14, 17, 10, 13, "part-of", "", false, false], [38, 39, 24, 35, "part-of", "", false, false], [42, 45, 24, 35, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Previously", ",", "Dr.", "Paulos", "held", "the", "Cooper-", "Siegel", "Chair", "at", "Carnegie", "Mellon", "University", "'s", "School", "of", "Computer", "Science", ",", "where", "he", "taught", "in", "the", "Human", "-", "Computer", "Interaction", "Institute", "and", "served", "as", "a", "volunteer", "faculty", "member", "at", "the", "Robotics", "Institute", "and", "the", "Center", "for", "Entertainment", "Technology", "."], "sentence-detokenized": "Previously, Dr. Paulos held the Cooper-Siegel Chair at Carnegie Mellon University's School of Computer Science, where he taught in the Human-Computer Interaction Institute and served as a volunteer faculty member at the Robotics Institute and the Center for Entertainment Technology.", "token2charspan": [[0, 10], [10, 11], [12, 15], [16, 22], [23, 27], [28, 31], [32, 39], [39, 45], [46, 51], [52, 54], [55, 63], [64, 70], [71, 81], [81, 83], [84, 90], [91, 93], [94, 102], [103, 110], [110, 111], [112, 117], [118, 120], [121, 127], [128, 130], [131, 134], [135, 140], [140, 141], [141, 149], [150, 161], [162, 171], [172, 175], [176, 182], [183, 185], [186, 187], [188, 197], [198, 205], [206, 212], [213, 215], [216, 219], [220, 228], [229, 238], [239, 242], [243, 246], [247, 253], [254, 257], [258, 271], [272, 282], [282, 283]]}
{"doc_key": "ai-dev-327", "ner": [[3, 4, "researcher"], [6, 7, "university"], [9, 13, "product"], [17, 21, "product"], [26, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 6, 7, "physical", "", false, false], [3, 4, 6, 7, "role", "", false, false], [9, 13, 3, 4, "artifact", "", false, false], [9, 13, 17, 21, "type-of", "", false, false], [9, 13, 26, 29, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1969", ",", "Victor", "Sheinman", "of", "Stanford", "University", "invented", "the", "Stanford", "Arm", ",", "an", "all", "-", "electric", "6", "-", "axis", "articulated", "robot", "designed", "to", "provide", "a", "solution", "for", "the", "hand", "."], "sentence-detokenized": "In 1969, Victor Sheinman of Stanford University invented the Stanford Arm, an all-electric 6-axis articulated robot designed to provide a solution for the hand.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 24], [25, 27], [28, 36], [37, 47], [48, 56], [57, 60], [61, 69], [70, 73], [73, 74], [75, 77], [78, 81], [81, 82], [82, 90], [91, 92], [92, 93], [93, 97], [98, 109], [110, 115], [116, 124], [125, 127], [128, 135], [136, 137], [138, 146], [147, 150], [151, 154], [155, 159], [159, 160]]}
{"doc_key": "ai-dev-328", "ner": [[5, 6, "product"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 14, 15, "related-to", "", false, false], [5, 6, 17, 18, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "creation", "and", "implementation", "of", "chatbots", "is", "still", "a", "developing", "area", "closely", "related", "to", "artificial", "intelligence", "and", "machine", "learning", ",", "so", "the", "presented", "solutions", ",", "while", "having", "obvious", "advantages", ",", "have", "a", "number", "of", "significant", "limitations", "in", "terms", "of", "functionality", "and", "use", "cases", "."], "sentence-detokenized": "The creation and implementation of chatbots is still a developing area closely related to artificial intelligence and machine learning, so the presented solutions, while having obvious advantages, have a number of significant limitations in terms of functionality and use cases.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 31], [32, 34], [35, 43], [44, 46], [47, 52], [53, 54], [55, 65], [66, 70], [71, 78], [79, 86], [87, 89], [90, 100], [101, 113], [114, 117], [118, 125], [126, 134], [134, 135], [136, 138], [139, 142], [143, 152], [153, 162], [162, 163], [164, 169], [170, 176], [177, 184], [185, 195], [195, 196], [197, 201], [202, 203], [204, 210], [211, 213], [214, 225], [226, 237], [238, 240], [241, 246], [247, 249], [250, 263], [264, 267], [268, 271], [272, 277], [277, 278]]}
{"doc_key": "ai-dev-329", "ner": [[7, 10, "university"], [11, 12, "product"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 7, 10, "part-of", "", true, false], [21, 23, 11, 12, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "terms", "of", "freely", "available", "resources", ",", "Carnegie", "Mellon", "University", "'s", "Sphinx", "toolkit", "is", "one", "place", "to", "start", "both", "learning", "about", "speech", "recognition", "and", "experimenting", "."], "sentence-detokenized": "In terms of freely available resources, Carnegie Mellon University's Sphinx toolkit is one place to start both learning about speech recognition and experimenting.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 18], [19, 28], [29, 38], [38, 39], [40, 48], [49, 55], [56, 66], [66, 68], [69, 75], [76, 83], [84, 86], [87, 90], [91, 96], [97, 99], [100, 105], [106, 110], [111, 119], [120, 125], [126, 132], [133, 144], [145, 148], [149, 162], [162, 163]]}
{"doc_key": "ai-dev-330", "ner": [[2, 3, "misc"], [13, 18, "misc"], [14, 20, "misc"], [25, 25, "university"], [27, 27, "location"], [29, 29, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 13, 18, "temporal", "", false, false], [14, 20, 13, 18, "named", "", false, false], [14, 20, 27, 27, "physical", "", false, false], [25, 25, 14, 20, "role", "", false, false], [27, 27, 29, 29, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "official", "RoboCup", "competition", "was", "preceded", "by", "the", "(", "often", "unrecognized", ")", "first", "International", "Microrobot", "Soccer", "World", "Cup", "Tournament", "(", "MIROSOT", ")", ",", "hosted", "by", "KAIST", "in", "Daejeon", ",", "Korea", "in", "November", "1996", "."], "sentence-detokenized": "The official RoboCup competition was preceded by the (often unrecognized) first International Microrobot Soccer World Cup Tournament (MIROSOT), hosted by KAIST in Daejeon, Korea in November 1996.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 32], [33, 36], [37, 45], [46, 48], [49, 52], [53, 54], [54, 59], [60, 72], [72, 73], [74, 79], [80, 93], [94, 104], [105, 111], [112, 117], [118, 121], [122, 132], [133, 134], [134, 141], [141, 142], [142, 143], [144, 150], [151, 153], [154, 159], [160, 162], [163, 170], [170, 171], [172, 177], [178, 180], [181, 189], [190, 194], [194, 195]]}
{"doc_key": "ai-dev-331", "ner": [[5, 6, "metrics"], [24, 25, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", "to", "the", "standard", "loop", "loss", "math", "(", "1-", "yf", "(", "x", ")", ")", "_", "+", "/", "math", "for", "labeled", "data", ",", "the", "loss", "function", "math", "(", "-", "1", "|", "f", "(", "x", ")", "|", ")", "_", "+", "/", "math", "is", "introduced", "over", "unlabeled", "data", ",", "let", "mathy", "=\\", "operatorname", "{", "sign", "}", "{", "f", "(", "x", ")", "}", "/", "math", "."], "sentence-detokenized": "In addition to the standard loop loss math (1-yf (x)) _ + / math for labeled data, the loss function math (-1 | f (x) |) _ + / math is introduced over unlabeled data, let mathy =\\ operatorname {sign} {f (x)} / math.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 18], [19, 27], [28, 32], [33, 37], [38, 42], [43, 44], [44, 46], [46, 48], [49, 50], [50, 51], [51, 52], [52, 53], [54, 55], [56, 57], [58, 59], [60, 64], [65, 68], [69, 76], [77, 81], [81, 82], [83, 86], [87, 91], [92, 100], [101, 105], [106, 107], [107, 108], [108, 109], [110, 111], [112, 113], [114, 115], [115, 116], [116, 117], [118, 119], [119, 120], [121, 122], [123, 124], [125, 126], [127, 131], [132, 134], [135, 145], [146, 150], [151, 160], [161, 165], [165, 166], [167, 170], [171, 176], [177, 179], [180, 192], [193, 194], [194, 198], [198, 199], [200, 201], [201, 202], [203, 204], [204, 205], [205, 206], [206, 207], [208, 209], [210, 214], [214, 215]]}
{"doc_key": "ai-dev-332", "ner": [[3, 3, "misc"], [9, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 9, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "particular", ",", "RLS", "is", "designed", "to", "minimize", "the", "root", "mean", "square", "error", "between", "the", "predicted", "values", "and", "TRUE", "labels", "under", "the", "condition", "of", "regularization", "."], "sentence-detokenized": "In particular, RLS is designed to minimize the root mean square error between the predicted values and TRUE labels under the condition of regularization.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 21], [22, 30], [31, 33], [34, 42], [43, 46], [47, 51], [52, 56], [57, 63], [64, 69], [70, 77], [78, 81], [82, 91], [92, 98], [99, 102], [103, 107], [108, 114], [115, 120], [121, 124], [125, 134], [135, 137], [138, 152], [152, 153]]}
{"doc_key": "ai-dev-333", "ner": [[4, 6, "algorithm"], [9, 10, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 9, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Essentially", ",", "it", "combines", "maximum", "likelihood", "estimation", "with", "a", "regularization", "procedure", "that", "favors", "simpler", "models", "over", "more", "complex", "ones", "."], "sentence-detokenized": "Essentially, it combines maximum likelihood estimation with a regularization procedure that favors simpler models over more complex ones.", "token2charspan": [[0, 11], [11, 12], [13, 15], [16, 24], [25, 32], [33, 43], [44, 54], [55, 59], [60, 61], [62, 76], [77, 86], [87, 91], [92, 98], [99, 106], [107, 113], [114, 118], [119, 123], [124, 131], [132, 136], [136, 137]]}
{"doc_key": "ai-dev-334", "ner": [[0, 3, "metrics"], [9, 9, "metrics"], [11, 11, "metrics"], [13, 16, "misc"], [21, 22, "misc"], [36, 40, "algorithm"], [37, 42, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 9, 0, 3, "named", "", false, false], [11, 11, 0, 3, "named", "", false, false], [13, 16, 21, 22, "related-to", "", false, false], [13, 16, 36, 40, "related-to", "ratio", false, false], [36, 40, 37, 42, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "true", "-", "positive", "rate", "is", "also", "known", "as", "sensitivity", ",", "recall", "or", "detection", "probability", "(", "a", "mathematical", "expression", "of", "the", "discrimination", "threshold", ")", "of", "the", "probability", "of", "detection", "on", "the", "y", "-axis", "compared", "to", "the", "cumulative", "probability", "distribution", "function", "of", "false", "positives", "on", "the", "x-", "axis", "."], "sentence-detokenized": "The true-positive rate is also known as sensitivity, recall or detection probability (a mathematical expression of the discrimination threshold) of the probability of detection on the y-axis compared to the cumulative probability distribution function of false positives on the x-axis.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 17], [18, 22], [23, 25], [26, 30], [31, 36], [37, 39], [40, 51], [51, 52], [53, 59], [60, 62], [63, 72], [73, 84], [85, 86], [86, 87], [88, 100], [101, 111], [112, 114], [115, 118], [119, 133], [134, 143], [143, 144], [145, 147], [148, 151], [152, 163], [164, 166], [167, 176], [177, 179], [180, 183], [184, 185], [185, 190], [191, 199], [200, 202], [203, 206], [207, 217], [218, 229], [230, 242], [243, 251], [252, 254], [255, 260], [261, 270], [271, 273], [274, 277], [278, 280], [280, 284], [284, 285]]}
{"doc_key": "ai-dev-335", "ner": [[1, 1, "misc"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 10, 1, 1, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "English", ",", "an", "example", "of", "a", "semantic", "network", "is", "WordNet", "."], "sentence-detokenized": "In English, an example of a semantic network is WordNet.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 14], [15, 22], [23, 25], [26, 27], [28, 36], [37, 44], [45, 47], [48, 55], [55, 56]]}
{"doc_key": "ai-dev-336", "ner": [[3, 5, "product"], [8, 9, "product"], [22, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 23, 3, 5, "usage", "", false, false], [22, 23, 8, 9, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolonged", "use", "of", "speech", "recognition", "software", "combined", "with", "word", "processors", "has", "shown", "benefits", "in", "restoring", "short", "-", "term", "memory", "in", "patients", "with", "brain", "AVMs", "who", "have", "undergone", "resection", "."], "sentence-detokenized": "Prolonged use of speech recognition software combined with word processors has shown benefits in restoring short-term memory in patients with brain AVMs who have undergone resection.", "token2charspan": [[0, 9], [10, 13], [14, 16], [17, 23], [24, 35], [36, 44], [45, 53], [54, 58], [59, 63], [64, 74], [75, 78], [79, 84], [85, 93], [94, 96], [97, 106], [107, 112], [112, 113], [113, 117], [118, 124], [125, 127], [128, 136], [137, 141], [142, 147], [148, 152], [153, 156], [157, 161], [162, 171], [172, 181], [181, 182]]}
{"doc_key": "ai-dev-337", "ner": [[9, 10, "researcher"], [12, 13, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "founders", "and", "editors", "-", "in", "-", "chief", "were", "Ron", "Sun", ",", "Vasant", "Honavar", "and", "Gregg", "Oden", "(", "from", "1999", "to", "2014", ")", "."], "sentence-detokenized": "The founders and editors-in-chief were Ron Sun, Vasant Honavar and Gregg Oden (from 1999 to 2014).", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 24], [24, 25], [25, 27], [27, 28], [28, 33], [34, 38], [39, 42], [43, 46], [46, 47], [48, 54], [55, 62], [63, 66], [67, 72], [73, 77], [78, 79], [79, 83], [84, 88], [89, 91], [92, 96], [96, 97], [97, 98]]}
{"doc_key": "ai-dev-338", "ner": [[10, 11, "product"], [16, 20, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 11, 16, 20, "opposite", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Their", "\"", "parallel", "\"", "difference", ",", "in", "contrast", "to", "the", "serial", "manipulator", ",", "is", "that", "the", "final", "executive", "body", "(", "or", "\"", "arm", "\"", ")", "of", "this", "link", "(", "or", "\"", "shoulder", "\"", ")", "is", "directly", "connected", "to", "it", "s", "base", "by", "several", "(", "usually", "three", "or", "six", ")", "separate", "and", "independent", "links", "operating", "simultaneously", "."], "sentence-detokenized": "Their \"parallel\" difference, in contrast to the serial manipulator, is that the final executive body (or \"arm\") of this link (or \"shoulder\") is directly connected to its base by several (usually three or six) separate and independent links operating simultaneously.", "token2charspan": [[0, 5], [6, 7], [7, 15], [15, 16], [17, 27], [27, 28], [29, 31], [32, 40], [41, 43], [44, 47], [48, 54], [55, 66], [66, 67], [68, 70], [71, 75], [76, 79], [80, 85], [86, 95], [96, 100], [101, 102], [102, 104], [105, 106], [106, 109], [109, 110], [110, 111], [112, 114], [115, 119], [120, 124], [125, 126], [126, 128], [129, 130], [130, 138], [138, 139], [139, 140], [141, 143], [144, 152], [153, 162], [163, 165], [166, 168], [168, 169], [170, 174], [175, 177], [178, 185], [186, 187], [187, 194], [195, 200], [201, 203], [204, 207], [207, 208], [209, 217], [218, 221], [222, 233], [234, 239], [240, 249], [250, 264], [264, 265]]}
{"doc_key": "ai-dev-339", "ner": [[4, 5, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 23, "researcher"], [25, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "supervisor", "was", "Professor", "Cordell", "Green", ",", "and", "the", "dissertation", "committee", "included", "Professors", "Edward", "Feigenbaum", ",", "Joshua", "Lederberg", ",", "Paul", "Cohen", ",", "Allen", "Newell", ",", "Herbert", "Simon", "."], "sentence-detokenized": "His supervisor was Professor Cordell Green, and the dissertation committee included Professors Edward Feigenbaum, Joshua Lederberg, Paul Cohen, Allen Newell, Herbert Simon.", "token2charspan": [[0, 3], [4, 14], [15, 18], [19, 28], [29, 36], [37, 42], [42, 43], [44, 47], [48, 51], [52, 64], [65, 74], [75, 83], [84, 94], [95, 101], [102, 112], [112, 113], [114, 120], [121, 130], [130, 131], [132, 136], [137, 142], [142, 143], [144, 149], [150, 156], [156, 157], [158, 165], [166, 171], [171, 172]]}
{"doc_key": "ai-dev-340", "ner": [[3, 5, "metrics"], [7, 10, "metrics"], [12, 14, "metrics"], [16, 18, "metrics"], [20, 23, "metrics"], [25, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "functions", "include", "mean", "square", "error", ",", "root", "mean", "square", "error", ",", "mean", "absolute", "error", ",", "relative", "square", "error", ",", "root", "relative", "square", "error", ",", "relative", "absolute", "error", "and", "others", "."], "sentence-detokenized": "Such functions include mean square error, root mean square error, mean absolute error, relative square error, root relative square error, relative absolute error and others.", "token2charspan": [[0, 4], [5, 14], [15, 22], [23, 27], [28, 34], [35, 40], [40, 41], [42, 46], [47, 51], [52, 58], [59, 64], [64, 65], [66, 70], [71, 79], [80, 85], [85, 86], [87, 95], [96, 102], [103, 108], [108, 109], [110, 114], [115, 123], [124, 130], [131, 136], [136, 137], [138, 146], [147, 155], [156, 161], [162, 165], [166, 172], [172, 173]]}
{"doc_key": "ai-dev-341", "ner": [[5, 5, "programlang"], [7, 7, "programlang"], [9, 9, "product"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "is", "a", "binding", "to", "Python", ",", "Java", "and", "MATLAB", "/", "OCTAVE", "."], "sentence-detokenized": "There is a binding to Python, Java and MATLAB / OCTAVE.", "token2charspan": [[0, 5], [6, 8], [9, 10], [11, 18], [19, 21], [22, 28], [28, 29], [30, 34], [35, 38], [39, 45], [46, 47], [48, 54], [54, 55]]}
{"doc_key": "ai-dev-342", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "MATLAB", "implementation", "can", "be", "found", "on", "the", "website", "."], "sentence-detokenized": "The MATLAB implementation can be found on the website.", "token2charspan": [[0, 3], [4, 10], [11, 25], [26, 29], [30, 32], [33, 38], [39, 41], [42, 45], [46, 53], [53, 54]]}
{"doc_key": "ai-dev-343", "ner": [[0, 1, "researcher"], [9, 10, "field"], [14, 15, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"], [23, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 10, 0, 1, "origin", "", false, false], [9, 10, 14, 15, "origin", "", false, false], [9, 10, 17, 18, "origin", "", false, false], [9, 10, 20, 21, "origin", "", false, false], [9, 10, 23, 26, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["John", "McCarthy", "is", "one", "of", "the", "founding", "fathers", "of", "artificial", "intelligence", ",", "along", "with", "Alan", "Turing", ",", "Marvin", "Minsky", ",", "Allen", "Newell", "and", "Herbert", "A", ".", "Simon", "."], "sentence-detokenized": "John McCarthy is one of the founding fathers of artificial intelligence, along with Alan Turing, Marvin Minsky, Allen Newell and Herbert A. Simon.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 20], [21, 23], [24, 27], [28, 36], [37, 44], [45, 47], [48, 58], [59, 71], [71, 72], [73, 78], [79, 83], [84, 88], [89, 95], [95, 96], [97, 103], [104, 110], [110, 111], [112, 117], [118, 124], [125, 128], [129, 136], [137, 138], [138, 139], [140, 145], [145, 146]]}
{"doc_key": "ai-dev-344", "ner": [[10, 12, "product"], [19, 20, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "parallel", "manipulator", "is", "a", "mechanical", "system", "that", "uses", "multiple", "manipulators", "in", "series", "to", "support", "a", "single", "platform", "or", "end", "effector", "."], "sentence-detokenized": "A parallel manipulator is a mechanical system that uses multiple manipulators in series to support a single platform or end effector.", "token2charspan": [[0, 1], [2, 10], [11, 22], [23, 25], [26, 27], [28, 38], [39, 45], [46, 50], [51, 55], [56, 64], [65, 77], [78, 80], [81, 87], [88, 90], [91, 98], [99, 100], [101, 107], [108, 116], [117, 119], [120, 123], [124, 132], [132, 133]]}
{"doc_key": "ai-dev-345", "ner": [[0, 0, "product"], [3, 4, "task"], [2, 7, "product"], [9, 15, "product"], [27, 27, "misc"], [30, 30, "misc"], [33, 34, "misc"], [36, 43, "task"], [44, 48, "product"], [51, 52, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[2, 7, 0, 0, "part-of", "", false, false], [2, 7, 3, 4, "type-of", "", false, false], [9, 15, 2, 7, "named", "", false, false], [27, 27, 2, 7, "part-of", "", false, false], [30, 30, 2, 7, "part-of", "", false, false], [33, 34, 2, 7, "part-of", "", false, false], [36, 43, 2, 7, "part-of", "", false, false], [44, 48, 2, 7, "part-of", "", false, false], [51, 52, 2, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["GATE", "includes", "an", "information", "extraction", "system", "called", "ANNIE", "(", "A", "Nearly", "-", "New", "Information", "Extraction", "System", ")", ",", "which", "is", "a", "set", "of", "modules", "that", "includes", "a", "tokenizer", ",", "a", "dictionary", ",", "a", "sentence", "separator", ",", "part", "-", "of", "-", "speech", "taggers", ",", "a", "named", "-", "object", "recognition", "converter", ",", "and", "coreference", "taggers", "."], "sentence-detokenized": "GATE includes an information extraction system called ANNIE (A Nearly-New Information Extraction System), which is a set of modules that includes a tokenizer, a dictionary, a sentence separator, part-of-speech taggers, a named-object recognition converter, and coreference taggers.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 28], [29, 39], [40, 46], [47, 53], [54, 59], [60, 61], [61, 62], [63, 69], [69, 70], [70, 73], [74, 85], [86, 96], [97, 103], [103, 104], [104, 105], [106, 111], [112, 114], [115, 116], [117, 120], [121, 123], [124, 131], [132, 136], [137, 145], [146, 147], [148, 157], [157, 158], [159, 160], [161, 171], [171, 172], [173, 174], [175, 183], [184, 193], [193, 194], [195, 199], [199, 200], [200, 202], [202, 203], [203, 209], [210, 217], [217, 218], [219, 220], [221, 226], [226, 227], [227, 233], [234, 245], [246, 255], [255, 256], [257, 260], [261, 272], [273, 280], [280, 281]]}
{"doc_key": "ai-dev-346", "ner": [[3, 5, "university"], [10, 11, "country"], [21, 23, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "graduated", "from", "Moscow", "State", "University", "and", "left", "for", "the", "United", "States", "in", "November", "1978", "thanks", "to", "the", "personal", "intervention", "of", "Senator", "Edward", "Kennedy", "."], "sentence-detokenized": "He graduated from Moscow State University and left for the United States in November 1978 thanks to the personal intervention of Senator Edward Kennedy.", "token2charspan": [[0, 2], [3, 12], [13, 17], [18, 24], [25, 30], [31, 41], [42, 45], [46, 50], [51, 54], [55, 58], [59, 65], [66, 72], [73, 75], [76, 84], [85, 89], [90, 96], [97, 99], [100, 103], [104, 112], [113, 125], [126, 128], [129, 136], [137, 143], [144, 151], [151, 152]]}
{"doc_key": "ai-dev-347", "ner": [[3, 5, "organisation"], [0, 12, "misc"], [17, 17, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 0, 12, "win-defeat", "", false, false], [0, 12, 17, 17, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2017", ",", "DeepMind", "AlphaGo", "team", "received", "the", "first", "IJCAI", "Marvin", "Minsky", "Medal", "for", "outstanding", "achievements", "in", "AI", "."], "sentence-detokenized": "In 2017, DeepMind AlphaGo team received the first IJCAI Marvin Minsky Medal for outstanding achievements in AI.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 17], [18, 25], [26, 30], [31, 39], [40, 43], [44, 49], [50, 55], [56, 62], [63, 69], [70, 75], [76, 79], [80, 91], [92, 104], [105, 107], [108, 110], [110, 111]]}
{"doc_key": "ai-dev-348", "ner": [[3, 4, "misc"], [7, 10, "misc"], [15, 15, "misc"], [25, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 7, 10, "related-to", "is_recorded_by", false, false], [7, 10, 15, 15, "cause-effect", "", false, false], [7, 10, 15, 15, "physical", "", false, false], [7, 10, 25, 26, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Other", "ways", "of", "anomalous", "propagation", "are", "registered", "by", "tropospheric", "scatterers", "that", "cause", "inhomogeneities", "in", "the", "troposphere", ",", "scattering", "due", "to", "meteors", ",", "refraction", "in", "ionized", "regions", "and", "layers", "of", "the", "ionosphere", ",", "reflection", "from", "the", "ionosphere", "."], "sentence-detokenized": "Other ways of anomalous propagation are registered by tropospheric scatterers that cause inhomogeneities in the troposphere, scattering due to meteors, refraction in ionized regions and layers of the ionosphere, reflection from the ionosphere.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 23], [24, 35], [36, 39], [40, 50], [51, 53], [54, 66], [67, 77], [78, 82], [83, 88], [89, 104], [105, 107], [108, 111], [112, 123], [123, 124], [125, 135], [136, 139], [140, 142], [143, 150], [150, 151], [152, 162], [163, 165], [166, 173], [174, 181], [182, 185], [186, 192], [193, 195], [196, 199], [200, 210], [210, 211], [212, 222], [223, 227], [228, 231], [232, 242], [242, 243]]}
{"doc_key": "ai-dev-349", "ner": [[0, 2, "field"], [4, 4, "field"], [10, 10, "field"], [12, 13, "field"], [15, 16, "field"], [18, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 10, 10, "part-of", "", false, false], [0, 2, 12, 13, "part-of", "", false, false], [0, 2, 15, 16, "part-of", "", false, false], [0, 2, 18, 23, "part-of", "", false, false], [4, 4, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Natural", "Language", "Processing", "(", "NLP", ")", "is", "a", "subfield", "of", "linguistics", ",", "computer", "science", ",", "information", "engineering", "and", "artificial", "intelligence", "that", "deals", "with", "the", "interaction", "between", "computers", "and", "human", "(", "natural", ")", "languages", ",", "in", "particular", "how", "to", "program", "computers", "to", "process", "and", "analyze", "large", "amounts", "of", "natural", "language", "data", "."], "sentence-detokenized": "Natural Language Processing (NLP) is a subfield of linguistics, computer science, information engineering and artificial intelligence that deals with the interaction between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 29], [29, 32], [32, 33], [34, 36], [37, 38], [39, 47], [48, 50], [51, 62], [62, 63], [64, 72], [73, 80], [80, 81], [82, 93], [94, 105], [106, 109], [110, 120], [121, 133], [134, 138], [139, 144], [145, 149], [150, 153], [154, 165], [166, 173], [174, 183], [184, 187], [188, 193], [194, 195], [195, 202], [202, 203], [204, 213], [213, 214], [215, 217], [218, 228], [229, 232], [233, 235], [236, 243], [244, 253], [254, 256], [257, 264], [265, 268], [269, 276], [277, 282], [283, 290], [291, 293], [294, 301], [302, 310], [311, 315], [315, 316]]}
{"doc_key": "ai-dev-350", "ner": [[6, 7, "organisation"], [9, 10, "organisation"], [12, 13, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "active", "youth", "climate", "groups", "include", "Extinction", "Rebellion", ",", "Sunrise", "Movement", ",", "SustainUS", "and", "others", "working", "both", "transnationally", "and", "locally", "."], "sentence-detokenized": "Other active youth climate groups include Extinction Rebellion, Sunrise Movement, SustainUS and others working both transnationally and locally.", "token2charspan": [[0, 5], [6, 12], [13, 18], [19, 26], [27, 33], [34, 41], [42, 52], [53, 62], [62, 63], [64, 71], [72, 80], [80, 81], [82, 91], [92, 95], [96, 102], [103, 110], [111, 115], [116, 131], [132, 135], [136, 143], [143, 144]]}
