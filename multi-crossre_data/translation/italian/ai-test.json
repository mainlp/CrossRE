{"doc_key": "ai-test-1", "ner": [[8, 10, "algorithm"], [13, 16, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Gli", "approcci", "tipici", "ai", "modelli", "generativi", "includono", "i", "classificatori", "naive", "Bayes", ",", "i", "modelli", "a", "miscela", "gaussiana", ",", "gli", "autoencoder", "variazionali", "e", "altri", "."], "sentence-detokenized": "Gli approcci tipici ai modelli generativi includono i classificatori naive Bayes, i modelli a miscela gaussiana, gli autoencoder variazionali e altri.", "token2charspan": [[0, 3], [4, 12], [13, 19], [20, 22], [23, 30], [31, 41], [42, 51], [52, 53], [54, 68], [69, 74], [75, 80], [80, 81], [82, 83], [84, 91], [92, 93], [94, 101], [102, 111], [111, 112], [113, 116], [117, 128], [129, 141], [142, 143], [144, 149], [149, 150]]}
{"doc_key": "ai-test-2", "ner": [[6, 6, "organisation"], [11, 11, "conference"], [14, 21, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 11, 11, "role", "", false, false], [14, 21, 11, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Infine", ",", "ogni", "due", "anni", ",", "ELRA", "organizza", "un'", "importante", "conferenza", "LREC", ",", "la", "Conferenza", "internazionale", "sulle", "risorse", "linguistiche", "e", "la", "valutazione", "."], "sentence-detokenized": "Infine, ogni due anni, ELRA organizza un'importante conferenza LREC, la Conferenza internazionale sulle risorse linguistiche e la valutazione.", "token2charspan": [[0, 6], [6, 7], [8, 12], [13, 16], [17, 21], [21, 22], [23, 27], [28, 37], [38, 41], [41, 51], [52, 62], [63, 67], [67, 68], [69, 71], [72, 82], [83, 97], [98, 103], [104, 111], [112, 124], [125, 126], [127, 129], [130, 141], [141, 142]]}
{"doc_key": "ai-test-3", "ner": [[8, 11, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Il", "compito", "\u00e8", "solitamente", "quello", "di", "ricavare", "la", "stima", "della", "massima", "verosimiglianza", "dei", "parametri", "dell'", "HMM", "date", "le", "sequenze", "di", "output."], "sentence-detokenized": "Il compito \u00e8 solitamente quello di ricavare la stima della massima verosimiglianza dei parametri dell'HMM date le sequenze di output.", "token2charspan": [[0, 2], [3, 10], [11, 12], [13, 24], [25, 31], [32, 34], [35, 43], [44, 46], [47, 52], [53, 58], [59, 66], [67, 82], [83, 86], [87, 96], [97, 102], [102, 105], [106, 110], [111, 113], [114, 122], [123, 125], [126, 133]]}
{"doc_key": "ai-test-4", "ner": [[3, 4, "algorithm"], [7, 9, "algorithm"], [16, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 16, 16, "compare", "", false, false], [7, 9, 16, 16, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "differenza", "delle", "reti", "neurali", "e", "delle", "Support", "vector", "machine", ",", "il", "processo", "di", "addestramento", "di", "AdaBoost", "seleziona", "solo", "le", "caratteristiche", "note", "per", "migliorare", "il", "potere", "predittivo", "del", "modello", ",", "riducendo", "la", "dimensionalit\u00e0", "e", "potenzialmente", "migliorando", "il", "tempo", "di", "esecuzione", ",", "poich\u00e9", "non", "\u00e8", "necessario", "calcolare", "le", "caratteristiche", "irrilevanti", "."], "sentence-detokenized": "A differenza delle reti neurali e delle Support vector machine, il processo di addestramento di AdaBoost seleziona solo le caratteristiche note per migliorare il potere predittivo del modello, riducendo la dimensionalit\u00e0 e potenzialmente migliorando il tempo di esecuzione, poich\u00e9 non \u00e8 necessario calcolare le caratteristiche irrilevanti.", "token2charspan": [[0, 1], [2, 12], [13, 18], [19, 23], [24, 31], [32, 33], [34, 39], [40, 47], [48, 54], [55, 62], [62, 63], [64, 66], [67, 75], [76, 78], [79, 92], [93, 95], [96, 104], [105, 114], [115, 119], [120, 122], [123, 138], [139, 143], [144, 147], [148, 158], [159, 161], [162, 168], [169, 179], [180, 183], [184, 191], [191, 192], [193, 202], [203, 205], [206, 220], [221, 222], [223, 237], [238, 249], [250, 252], [253, 258], [259, 261], [262, 272], [272, 273], [274, 280], [281, 284], [285, 286], [287, 297], [298, 307], [308, 310], [311, 326], [327, 338], [338, 339]]}
{"doc_key": "ai-test-5", "ner": [[0, 1, "misc"], [10, 11, "misc"], [13, 14, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 10, 11, "part-of", "", false, false], [10, 11, 13, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "troponimia", "\u00e8", "una", "delle", "possibili", "relazioni", "tra", "verbi", "nella", "rete", "semantica", "del", "database", "WordNet", "."], "sentence-detokenized": "La troponimia \u00e8 una delle possibili relazioni tra verbi nella rete semantica del database WordNet.", "token2charspan": [[0, 2], [3, 13], [14, 15], [16, 19], [20, 25], [26, 35], [36, 45], [46, 49], [50, 55], [56, 61], [62, 66], [67, 76], [77, 80], [81, 89], [90, 97], [97, 98]]}
{"doc_key": "ai-test-6", "ner": [[10, 12, "task"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 12, 14, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Un", "linguaggio", "a", "frame", "\u00e8", "una", "tecnologia", "utilizzata", "per", "la", "rappresentazione", "della", "conoscenza", "nell'", "intelligenza", "artificiale", "."], "sentence-detokenized": "Un linguaggio a frame \u00e8 una tecnologia utilizzata per la rappresentazione della conoscenza nell'intelligenza artificiale.", "token2charspan": [[0, 2], [3, 13], [14, 15], [16, 21], [22, 23], [24, 27], [28, 38], [39, 49], [50, 53], [54, 56], [57, 73], [74, 79], [80, 90], [91, 96], [96, 108], [109, 120], [120, 121]]}
{"doc_key": "ai-test-7", "ner": [[0, 2, "metrics"], [5, 7, "metrics"], [13, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 5, 7, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Il", "NIST", "si", "differenzia", "da", "Bilingual", "evaluation", "understudy", "anche", "per", "il", "calcolo", "della", "penalit\u00e0", "di", "brevit\u00e0", ",", "in", "quanto", "piccole", "variazioni", "nella", "lunghezza", "della", "traduzione", "non", "incidono", "pi\u00f9", "di", "tanto", "sul", "punteggio", "complessivo", "."], "sentence-detokenized": "Il NIST si differenzia da Bilingual evaluation understudy anche per il calcolo della penalit\u00e0 di brevit\u00e0, in quanto piccole variazioni nella lunghezza della traduzione non incidono pi\u00f9 di tanto sul punteggio complessivo.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 22], [23, 25], [26, 35], [36, 46], [47, 57], [58, 63], [64, 67], [68, 70], [71, 78], [79, 84], [85, 93], [94, 96], [97, 104], [104, 105], [106, 108], [109, 115], [116, 123], [124, 134], [135, 140], [141, 150], [151, 156], [157, 167], [168, 171], [172, 180], [181, 184], [185, 187], [188, 193], [194, 197], [198, 207], [208, 219], [219, 220]]}
{"doc_key": "ai-test-8", "ner": [[7, 8, "algorithm"], [11, 14, "algorithm"], [28, 29, "field"], [39, 41, "algorithm"], [44, 47, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 8, 28, 29, "usage", "", false, false], [11, 14, 28, 29, "usage", "", false, false], [39, 41, 28, 29, "type-of", "", false, false], [44, 47, 28, 29, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Il", "modello", "(", "ad", "esempio", ",", "una", "rete", "neurale", "o", "un", "classificatore", "di", "Bayes", "ingenuo", ")", "viene", "addestrato", "sul", "set", "di", "dati", "di", "addestramento", "utilizzando", "un", "metodo", "di", "apprendimento", "supervisionato", ",", "ad", "esempio", "utilizzando", "metodi", "di", "ottimizzazione", "come", "la", "discesa", "del", "gradiente", "o", "la", "discesa", "del", "gradiente", "stocastica", "."], "sentence-detokenized": "Il modello (ad esempio, una rete neurale o un classificatore di Bayes ingenuo) viene addestrato sul set di dati di addestramento utilizzando un metodo di apprendimento supervisionato, ad esempio utilizzando metodi di ottimizzazione come la discesa del gradiente o la discesa del gradiente stocastica.", "token2charspan": [[0, 2], [3, 10], [11, 12], [12, 14], [15, 22], [22, 23], [24, 27], [28, 32], [33, 40], [41, 42], [43, 45], [46, 60], [61, 63], [64, 69], [70, 77], [77, 78], [79, 84], [85, 95], [96, 99], [100, 103], [104, 106], [107, 111], [112, 114], [115, 128], [129, 140], [141, 143], [144, 150], [151, 153], [154, 167], [168, 182], [182, 183], [184, 186], [187, 194], [195, 206], [207, 213], [214, 216], [217, 231], [232, 236], [237, 239], [240, 247], [248, 251], [252, 261], [262, 263], [264, 266], [267, 274], [275, 278], [279, 288], [289, 299], [299, 300]]}
{"doc_key": "ai-test-9", "ner": [[0, 0, "product"], [8, 10, "task"], [13, 13, "task"], [16, 19, "task"], [22, 24, "task"], [31, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 10, 0, 0, "usage", "", true, false], [13, 13, 0, 0, "usage", "", true, false], [16, 19, 0, 0, "usage", "", true, false], [22, 24, 0, 0, "usage", "", true, false], [31, 34, 0, 0, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["FrameNet", "\u00e8", "stato", "utilizzato", "in", "applicazioni", "come", "la", "risposta", "alle", "domande", ",", "la", "parafrasi", ",", "il", "riconoscimento", "dell'", "implicazione", "testuale", "e", "l'", "estrazione", "di", "informazioni", ",", "direttamente", "o", "tramite", "strumenti", "di", "etichettatura", "dei", "ruoli", "semantici", "."], "sentence-detokenized": "FrameNet \u00e8 stato utilizzato in applicazioni come la risposta alle domande, la parafrasi, il riconoscimento dell'implicazione testuale e l'estrazione di informazioni, direttamente o tramite strumenti di etichettatura dei ruoli semantici.", "token2charspan": [[0, 8], [9, 10], [11, 16], [17, 27], [28, 30], [31, 43], [44, 48], [49, 51], [52, 60], [61, 65], [66, 73], [73, 74], [75, 77], [78, 87], [87, 88], [89, 91], [92, 106], [107, 112], [112, 124], [125, 133], [134, 135], [136, 138], [138, 148], [149, 151], [152, 164], [164, 165], [166, 178], [179, 180], [181, 188], [189, 198], [199, 201], [202, 215], [216, 219], [220, 225], [226, 235], [235, 236]]}
{"doc_key": "ai-test-10", "ner": [[7, 11, "field"], [13, 15, "misc"], [20, 20, "product"], [23, 23, "misc"], [28, 28, "product"], [31, 32, "field"], [37, 37, "product"], [40, 43, "misc"], [48, 48, "product"], [50, 50, "product"], [52, 52, "product"], [55, 56, "misc"], [61, 62, "product"], [64, 65, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[20, 20, 13, 15, "general-affiliation", "", false, false], [28, 28, 23, 23, "general-affiliation", "", false, false], [37, 37, 31, 32, "general-affiliation", "", false, false], [48, 48, 40, 43, "type-of", "", false, false], [50, 50, 40, 43, "type-of", "", false, false], [52, 52, 40, 43, "type-of", "", false, false], [61, 62, 55, 56, "general-affiliation", "", false, false], [64, 65, 55, 56, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Si", "tratta", "di", "programmi", "quali", "strumenti", "di", "analisi", "ed", "estrazione", "dei", "dati", ",", "fogli", "di", "calcolo", "(", "ad", "es", ".", "Excel", ")", ",", "database", "(", "ad", "es", ".", "Access", ")", ",", "analisi", "statistica", "(", "ad", "es", ".", "SAS", ")", ",", "software", "di", "audit", "generalizzato", "(", "ad", "es", ".", "ACL", ",", "Arbutus", ",", "EAS", ")", ",", "business", "intelligence", "(", "ad", "es", ".", "Crystal", "Reports", "e", "Business", "Objects", ")", ",", "ecc", "."], "sentence-detokenized": "Si tratta di programmi quali strumenti di analisi ed estrazione dei dati, fogli di calcolo (ad es. Excel), database (ad es. Access), analisi statistica (ad es. SAS), software di audit generalizzato (ad es. ACL, Arbutus, EAS), business intelligence (ad es. Crystal Reports e Business Objects), ecc.", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 22], [23, 28], [29, 38], [39, 41], [42, 49], [50, 52], [53, 63], [64, 67], [68, 72], [72, 73], [74, 79], [80, 82], [83, 90], [91, 92], [92, 94], [95, 97], [97, 98], [99, 104], [104, 105], [105, 106], [107, 115], [116, 117], [117, 119], [120, 122], [122, 123], [124, 130], [130, 131], [131, 132], [133, 140], [141, 151], [152, 153], [153, 155], [156, 158], [158, 159], [160, 163], [163, 164], [164, 165], [166, 174], [175, 177], [178, 183], [184, 197], [198, 199], [199, 201], [202, 204], [204, 205], [206, 209], [209, 210], [211, 218], [218, 219], [220, 223], [223, 224], [224, 225], [226, 234], [235, 247], [248, 249], [249, 251], [252, 254], [254, 255], [256, 263], [264, 271], [272, 273], [274, 282], [283, 290], [290, 291], [291, 292], [293, 296], [296, 297]]}
{"doc_key": "ai-test-11", "ner": [[0, 1, "organisation"], [5, 6, "researcher"], [10, 10, "organisation"], [14, 14, "product"], [23, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 6, "origin", "", false, false], [5, 6, 10, 10, "role", "", false, false], [14, 14, 23, 24, "type-of", "", false, false], [23, 24, 5, 6, "origin", "introduced_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Rethink", "Robotics", "-", "fondata", "da", "Rodney", "Brooks", ",", "precedentemente", "in", "iRobot", "-", "ha", "presentato", "Baxter", "nel", "settembre", "2012", ";", "si", "tratta", "di", "un", "robot", "industriale", "progettato", "per", "interagire", "in", "modo", "sicuro", "con", "i", "lavoratori", "umani", "vicini", "e", "programmabile", "per", "eseguire", "compiti", "semplici", "."], "sentence-detokenized": "Rethink Robotics - fondata da Rodney Brooks, precedentemente in iRobot - ha presentato Baxter nel settembre 2012; si tratta di un robot industriale progettato per interagire in modo sicuro con i lavoratori umani vicini e programmabile per eseguire compiti semplici.", "token2charspan": [[0, 7], [8, 16], [17, 18], [19, 26], [27, 29], [30, 36], [37, 43], [43, 44], [45, 60], [61, 63], [64, 70], [71, 72], [73, 75], [76, 86], [87, 93], [94, 97], [98, 107], [108, 112], [112, 113], [114, 116], [117, 123], [124, 126], [127, 129], [130, 135], [136, 147], [148, 158], [159, 162], [163, 173], [174, 176], [177, 181], [182, 188], [189, 192], [193, 194], [195, 205], [206, 211], [212, 218], [219, 220], [221, 234], [235, 238], [239, 247], [248, 255], [256, 264], [264, 265]]}
{"doc_key": "ai-test-12", "ner": [[3, 5, "field"], [8, 10, "task"], [13, 15, "task"], [18, 22, "task"], [25, 28, "task"], [31, 33, "task"], [36, 38, "task"], [41, 45, "task"], [53, 55, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[8, 10, 3, 5, "part-of", "task_part_of_field", false, false], [13, 15, 3, 5, "part-of", "task_part_of_field", false, false], [18, 22, 3, 5, "part-of", "task_part_of_field", false, false], [25, 28, 3, 5, "part-of", "task_part_of_field", false, false], [31, 33, 3, 5, "part-of", "task_part_of_field", false, false], [36, 38, 3, 5, "part-of", "task_part_of_field", false, false], [41, 45, 3, 5, "part-of", "task_part_of_field", false, false], [53, 55, 3, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["I", "compiti", "tipici", "del", "text", "mining", "includono", "la", "categorizzazione", "del", "testo", ",", "il", "clustering", "del", "testo", ",", "l'", "estrazione", "di", "concetti", "/", "entit\u00e0", ",", "la", "produzione", "di", "tassonomie", "granulari", ",", "l'", "analisi", "del", "sentiment", ",", "la", "sintesi", "dei", "documenti", "e", "la", "modellazione", "delle", "relazioni", "tra", "entit\u00e0", "(", "cio\u00e8", "l'", "apprendimento", "delle", "relazioni", "tra", "entit\u00e0", "denominate", "riconosciute", ")", "."], "sentence-detokenized": "I compiti tipici del text mining includono la categorizzazione del testo, il clustering del testo, l'estrazione di concetti/entit\u00e0, la produzione di tassonomie granulari, l'analisi del sentiment, la sintesi dei documenti e la modellazione delle relazioni tra entit\u00e0 (cio\u00e8 l'apprendimento delle relazioni tra entit\u00e0 denominate riconosciute).", "token2charspan": [[0, 1], [2, 9], [10, 16], [17, 20], [21, 25], [26, 32], [33, 42], [43, 45], [46, 62], [63, 66], [67, 72], [72, 73], [74, 76], [77, 87], [88, 91], [92, 97], [97, 98], [99, 101], [101, 111], [112, 114], [115, 123], [123, 124], [124, 130], [130, 131], [132, 134], [135, 145], [146, 148], [149, 159], [160, 169], [169, 170], [171, 173], [173, 180], [181, 184], [185, 194], [194, 195], [196, 198], [199, 206], [207, 210], [211, 220], [221, 222], [223, 225], [226, 238], [239, 244], [245, 254], [255, 258], [259, 265], [266, 267], [267, 271], [272, 274], [274, 287], [288, 293], [294, 303], [304, 307], [308, 314], [315, 325], [326, 338], [338, 339], [339, 340]]}
{"doc_key": "ai-test-13", "ner": [[6, 6, "metrics"], [10, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Tuttavia", ",", "lo", "stemming", "riduce", "la", "precisione", ",", "o", "il", "tasso", "di", "veri", "negativi", ",", "per", "questi", "sistemi", "."], "sentence-detokenized": "Tuttavia, lo stemming riduce la precisione, o il tasso di veri negativi, per questi sistemi.", "token2charspan": [[0, 8], [8, 9], [10, 12], [13, 21], [22, 28], [29, 31], [32, 42], [42, 43], [44, 45], [46, 48], [49, 54], [55, 57], [58, 62], [63, 71], [71, 72], [73, 76], [77, 83], [84, 91], [91, 92]]}
{"doc_key": "ai-test-14", "ner": [[4, 7, "task"], [12, 14, "misc"], [18, 19, "misc"], [28, 28, "product"], [30, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 14, 4, 7, "temporal", "", false, false], [18, 19, 12, 14, "named", "", false, false], [28, 28, 12, 14, "usage", "", false, false], [30, 30, 12, 14, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Un", "caso", "particolare", "di", "individuazione", "delle", "parole", "chiave", "\u00e8", "il", "rilevamento", "delle", "parole", "d'", "ordine", "(", "dette", "anche", "parole", "calde", ")", ",", "utilizzato", "dagli", "assistenti", "digitali", "personali", "come", "Alexa", "o", "Siri", "per", "svegliarsi", "quando", "viene", "pronunciato", "il", "loro", "nome", "."], "sentence-detokenized": "Un caso particolare di individuazione delle parole chiave \u00e8 il rilevamento delle parole d'ordine (dette anche parole calde), utilizzato dagli assistenti digitali personali come Alexa o Siri per svegliarsi quando viene pronunciato il loro nome.", "token2charspan": [[0, 2], [3, 7], [8, 19], [20, 22], [23, 37], [38, 43], [44, 50], [51, 57], [58, 59], [60, 62], [63, 74], [75, 80], [81, 87], [88, 90], [90, 96], [97, 98], [98, 103], [104, 109], [110, 116], [117, 122], [122, 123], [123, 124], [125, 135], [136, 141], [142, 152], [153, 161], [162, 171], [172, 176], [177, 182], [183, 184], [185, 189], [190, 193], [194, 204], [205, 211], [212, 217], [218, 229], [230, 232], [233, 237], [238, 242], [242, 243]]}
{"doc_key": "ai-test-15", "ner": [[0, 0, "programlang"], [10, 10, "programlang"], [12, 12, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 0, 0, "part-of", "", false, false], [12, 12, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prova", "\u00e8", "un", "linguaggio", "di", "programmazione", "open", "source", "che", "combina", "Prolog", "e", "Java", "."], "sentence-detokenized": "Prova \u00e8 un linguaggio di programmazione open source che combina Prolog e Java.", "token2charspan": [[0, 5], [6, 7], [8, 10], [11, 21], [22, 24], [25, 39], [40, 44], [45, 51], [52, 55], [56, 63], [64, 70], [71, 72], [73, 77], [77, 78]]}
{"doc_key": "ai-test-16", "ner": [[3, 4, "organisation"], [9, 9, "organisation"], [21, 22, "product"], [19, 20, "country"], [35, 35, "organisation"], [46, 46, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 9, 9, "part-of", "", false, false], [3, 4, 9, 9, "role", "sells", false, false], [3, 4, 19, 20, "role", "sells_to", false, false], [35, 35, 46, 46, "opposite", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Nel", "1987", ",", "Tocibai", "Machine", ",", "una", "consociata", "di", "Toshiba", ",", "\u00e8", "stata", "accusata", "di", "aver", "venduto", "illegalmente", "all'", "Unione", "Sovietica", "frese", "CNC", "utilizzate", "per", "produrre", "eliche", "sottomarine", "molto", "silenziose", ",", "in", "violazione", "dell'", "accordo", "CoCom", ",", "un", "embargo", "internazionale", "nei", "confronti", "di", "alcuni", "Paesi", "del", "COMECON."], "sentence-detokenized": "Nel 1987, Tocibai Machine, una consociata di Toshiba, \u00e8 stata accusata di aver venduto illegalmente all'Unione Sovietica frese CNC utilizzate per produrre eliche sottomarine molto silenziose, in violazione dell'accordo CoCom, un embargo internazionale nei confronti di alcuni Paesi del COMECON.", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 17], [18, 25], [25, 26], [27, 30], [31, 41], [42, 44], [45, 52], [52, 53], [54, 55], [56, 61], [62, 70], [71, 73], [74, 78], [79, 86], [87, 99], [100, 104], [104, 110], [111, 120], [121, 126], [127, 130], [131, 141], [142, 145], [146, 154], [155, 161], [162, 173], [174, 179], [180, 190], [190, 191], [192, 194], [195, 205], [206, 211], [211, 218], [219, 224], [224, 225], [226, 228], [229, 236], [237, 251], [252, 255], [256, 265], [266, 268], [269, 275], [276, 281], [282, 285], [286, 294]]}
{"doc_key": "ai-test-17", "ner": [[7, 7, "researcher"], [10, 13, "product"], [24, 27, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 13, 7, 7, "artifact", "", false, false], [10, 13, 24, 27, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "pi\u00f9", "famosa", "co", "-", "invenzione", "di", "Engelberger", ",", "il", "braccio", "robotico", "industriale", "Unimate", ",", "\u00e8", "stata", "tra", "le", "prime", "ad", "essere", "inserita", "nella", "Robot", "Hall", "of", "Fame", "nel", "2003", "."], "sentence-detokenized": "La pi\u00f9 famosa co-invenzione di Engelberger, il braccio robotico industriale Unimate, \u00e8 stata tra le prime ad essere inserita nella Robot Hall of Fame nel 2003.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 16], [16, 17], [17, 27], [28, 30], [31, 42], [42, 43], [44, 46], [47, 54], [55, 63], [64, 75], [76, 83], [83, 84], [85, 86], [87, 92], [93, 96], [97, 99], [100, 105], [106, 108], [109, 115], [116, 124], [125, 130], [131, 136], [137, 141], [142, 144], [145, 149], [150, 153], [154, 158], [158, 159]]}
{"doc_key": "ai-test-18", "ner": [[5, 7, "misc"], [10, 10, "misc"], [15, 15, "person"], [23, 25, "field"], [28, 28, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 7, 10, 10, "usage", "", false, false], [15, 15, 23, 25, "role", "", false, false], [23, 25, 28, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Inizialmente", "controllato", "tramite", "pagine", "web", "statiche", "in", "html", "che", "utilizzavano", "CGI", ",", "il", "lavoro", "di", "Dalton", "ha", "visto", "l'", "introduzione", "di", "un'", "interfaccia", "in", "realt\u00e0", "aumentata", "basata", "su", "Java", ",", "che", "ha", "riscosso", "un", "successo", "limitato", "."], "sentence-detokenized": "Inizialmente controllato tramite pagine web statiche in html che utilizzavano CGI, il lavoro di Dalton ha visto l'introduzione di un'interfaccia in realt\u00e0 aumentata basata su Java, che ha riscosso un successo limitato.", "token2charspan": [[0, 12], [13, 24], [25, 32], [33, 39], [40, 43], [44, 52], [53, 55], [56, 60], [61, 64], [65, 77], [78, 81], [81, 82], [83, 85], [86, 92], [93, 95], [96, 102], [103, 105], [106, 111], [112, 114], [114, 126], [127, 129], [130, 133], [133, 144], [145, 147], [148, 154], [155, 164], [165, 171], [172, 174], [175, 179], [179, 180], [181, 184], [185, 187], [188, 196], [197, 199], [200, 208], [209, 217], [217, 218]]}
{"doc_key": "ai-test-19", "ner": [[4, 5, "task"], [12, 12, "organisation"], [31, 31, "conference"], [35, 35, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 12, 12, "origin", "", false, false], [31, 31, 35, 35, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "prima", "pubblicazione", "sulla", "specifica", "LMF", "cos\u00ec", "come", "\u00e8", "stata", "ratificata", "dall'", "ISO", "(", "questo", "documento", "\u00e8", "diventato", "(", "nel", "2015", ")", "il", "9\u00b0", "documento", "pi\u00f9", "citato", "nell'", "ambito", "delle", "conferenze", "LREC", "tra", "i", "documenti", "LREC", ")", ":"], "sentence-detokenized": "La prima pubblicazione sulla specifica LMF cos\u00ec come \u00e8 stata ratificata dall'ISO (questo documento \u00e8 diventato (nel 2015) il 9\u00b0 documento pi\u00f9 citato nell'ambito delle conferenze LREC tra i documenti LREC):", "token2charspan": [[0, 2], [3, 8], [9, 22], [23, 28], [29, 38], [39, 42], [43, 47], [48, 52], [53, 54], [55, 60], [61, 71], [72, 77], [77, 80], [81, 82], [82, 88], [89, 98], [99, 100], [101, 110], [111, 112], [112, 115], [116, 120], [120, 121], [122, 124], [125, 127], [128, 137], [138, 141], [142, 148], [149, 154], [154, 160], [161, 166], [167, 177], [178, 182], [183, 186], [187, 188], [189, 198], [199, 203], [203, 204], [204, 205]]}
{"doc_key": "ai-test-20", "ner": [[1, 3, "metrics"], [16, 16, "metrics"], [18, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 16, 1, 3, "usage", "", false, false], [16, 16, 18, 21, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Una", "matrice", "di", "confusione", "o", "matrice", "di", "corrispondenza", "viene", "spesso", "utilizzata", "come", "strumento", "per", "convalidare", "l'", "accuratezza", "della", "classificazione", "k", "-", "NN."], "sentence-detokenized": "Una matrice di confusione o matrice di corrispondenza viene spesso utilizzata come strumento per convalidare l'accuratezza della classificazione k -NN.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 25], [26, 27], [28, 35], [36, 38], [39, 53], [54, 59], [60, 66], [67, 77], [78, 82], [83, 92], [93, 96], [97, 108], [109, 111], [111, 122], [123, 128], [129, 144], [145, 146], [147, 148], [148, 151]]}
{"doc_key": "ai-test-21", "ner": [[3, 4, "algorithm"], [14, 14, "field"], [16, 17, "field"], [19, 20, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 14, 14, "part-of", "", false, false], [3, 4, 16, 17, "part-of", "", false, false], [3, 4, 19, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["L'", "apprendimento", "degli", "alberi", "decisionali", "\u00e8", "uno", "degli", "approcci", "di", "modellazione", "predittiva", "utilizzati", "in", "statistica", ",", "data", "mining", "e", "machine", "learning", "."], "sentence-detokenized": "L'apprendimento degli alberi decisionali \u00e8 uno degli approcci di modellazione predittiva utilizzati in statistica, data mining e machine learning.", "token2charspan": [[0, 2], [2, 15], [16, 21], [22, 28], [29, 40], [41, 42], [43, 46], [47, 52], [53, 61], [62, 64], [65, 77], [78, 88], [89, 99], [100, 102], [103, 113], [113, 114], [115, 119], [120, 126], [127, 128], [129, 136], [137, 145], [145, 146]]}
{"doc_key": "ai-test-22", "ner": [[6, 6, "misc"], [21, 26, "field"], [27, 29, "algorithm"], [31, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 21, 26, "related-to", "", true, false], [27, 29, 21, 26, "type-of", "", false, false], [31, 31, 21, 26, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "fase", "di", "esecuzione", ",", "la", "prosodia", "target", "di", "una", "frase", "viene", "sovrapposta", "a", "queste", "unit\u00e0", "minime", "per", "mezzo", "di", "tecniche", "di", "elaborazione", "del", "segnale", "come", "la", "codifica", "predittiva", "lineare", ",", "PSOLA"], "sentence-detokenized": "In fase di esecuzione, la prosodia target di una frase viene sovrapposta a queste unit\u00e0 minime per mezzo di tecniche di elaborazione del segnale come la codifica predittiva lineare, PSOLA", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 21], [21, 22], [23, 25], [26, 34], [35, 41], [42, 44], [45, 48], [49, 54], [55, 60], [61, 72], [73, 74], [75, 81], [82, 87], [88, 94], [95, 98], [99, 104], [105, 107], [108, 116], [117, 119], [120, 132], [133, 136], [137, 144], [145, 149], [150, 152], [153, 161], [162, 172], [173, 180], [180, 181], [182, 187]]}
{"doc_key": "ai-test-23", "ner": [[5, 6, "field"], [9, 10, "field"], [19, 20, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 20, 5, 6, "usage", "", true, false], [19, 20, 9, 10, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Questo", "approccio", "ha", "utilizzato", "l'", "intelligenza", "artificiale", "e", "l'", "apprendimento", "automatico", "per", "consentire", "ai", "ricercatori", "di", "confrontare", "visivamente", "le", "immagini", "facciali", "convenzionali", "e", "quelle", "termiche", "."], "sentence-detokenized": "Questo approccio ha utilizzato l'intelligenza artificiale e l'apprendimento automatico per consentire ai ricercatori di confrontare visivamente le immagini facciali convenzionali e quelle termiche.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 30], [31, 33], [33, 45], [46, 57], [58, 59], [60, 62], [62, 75], [76, 86], [87, 90], [91, 101], [102, 104], [105, 116], [117, 119], [120, 131], [132, 143], [144, 146], [147, 155], [156, 164], [165, 178], [179, 180], [181, 187], [188, 196], [196, 197]]}
{"doc_key": "ai-test-24", "ner": [[1, 1, "field"], [4, 5, "algorithm"], [13, 14, "task"], [17, 18, "misc"], [23, 24, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 1, 1, "part-of", "", false, false], [4, 5, 13, 14, "topic", "", false, false], [13, 14, 17, 18, "origin", "", false, false], [23, 24, 1, 1, "part-of", "", false, false], [23, 24, 4, 5, "topic", "", false, false], [27, 28, 1, 1, "part-of", "", false, false], [27, 28, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "informatica", ",", "la", "computazione", "evolutiva", "\u00e8", "una", "famiglia", "di", "algoritmi", "per", "l'", "ottimizzazione", "globale", "ispirati", "all'", "evoluzione", "biologica", "e", "il", "sottocampo", "dell'", "intelligenza", "artificiale", "e", "del", "soft", "computing", "che", "studia", "questi", "algoritmi", "."], "sentence-detokenized": "In informatica, la computazione evolutiva \u00e8 una famiglia di algoritmi per l'ottimizzazione globale ispirati all'evoluzione biologica e il sottocampo dell'intelligenza artificiale e del soft computing che studia questi algoritmi.", "token2charspan": [[0, 2], [3, 14], [14, 15], [16, 18], [19, 31], [32, 41], [42, 43], [44, 47], [48, 56], [57, 59], [60, 69], [70, 73], [74, 76], [76, 90], [91, 98], [99, 107], [108, 112], [112, 122], [123, 132], [133, 134], [135, 137], [138, 148], [149, 154], [154, 166], [167, 178], [179, 180], [181, 184], [185, 189], [190, 199], [200, 203], [204, 210], [211, 217], [218, 227], [227, 228]]}
{"doc_key": "ai-test-25", "ner": [[10, 12, "metrics"], [15, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ad", "esempio", ",", "si", "pu\u00f2", "combinare", "una", "misura", "basata", "sulla", "matrice", "di", "confusione", "con", "l'", "errore", "quadratico", "medio", "valutato", "tra", "i", "risultati", "grezzi", "del", "modello", "e", "i", "valori", "reali", "."], "sentence-detokenized": "Ad esempio, si pu\u00f2 combinare una misura basata sulla matrice di confusione con l'errore quadratico medio valutato tra i risultati grezzi del modello e i valori reali.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 14], [15, 18], [19, 28], [29, 32], [33, 39], [40, 46], [47, 52], [53, 60], [61, 63], [64, 74], [75, 78], [79, 81], [81, 87], [88, 98], [99, 104], [105, 113], [114, 117], [118, 119], [120, 129], [130, 136], [137, 140], [141, 148], [149, 150], [151, 152], [153, 159], [160, 165], [165, 166]]}
{"doc_key": "ai-test-26", "ner": [[6, 7, "product"], [10, 10, "researcher"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 10, 10, "origin", "", false, false], [6, 7, 18, 18, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "maggior", "parte", "sono", "risultati", "del", "modello", "word2vec", "sviluppato", "da", "Mikolov", "et", "al", ".", "o", "di", "varianti", "di", "word2vec", "."], "sentence-detokenized": "La maggior parte sono risultati del modello word2vec sviluppato da Mikolov et al. o di varianti di word2vec.", "token2charspan": [[0, 2], [3, 10], [11, 16], [17, 21], [22, 31], [32, 35], [36, 43], [44, 52], [53, 63], [64, 66], [67, 74], [75, 77], [78, 80], [80, 81], [82, 83], [84, 86], [87, 95], [96, 98], [99, 107], [107, 108]]}
{"doc_key": "ai-test-27", "ner": [[13, 13, "conference"], [16, 20, "conference"], [22, 22, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 22, 16, 20, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Durante", "questo", "periodo", ",", "un", "totale", "di", "43", "pubblicazioni", "sono", "state", "riconosciute", "dal", "CVPR", "e", "dalla", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "."], "sentence-detokenized": "Durante questo periodo, un totale di 43 pubblicazioni sono state riconosciute dal CVPR e dalla International Conference on Computer Vision (ICCV).", "token2charspan": [[0, 7], [8, 14], [15, 22], [22, 23], [24, 26], [27, 33], [34, 36], [37, 39], [40, 53], [54, 58], [59, 64], [65, 77], [78, 81], [82, 86], [87, 88], [89, 94], [95, 108], [109, 119], [120, 122], [123, 131], [132, 138], [139, 140], [140, 144], [144, 145], [145, 146]]}
{"doc_key": "ai-test-28", "ner": [[1, 1, "product"], [16, 17, "field"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 16, 17, "general-affiliation", "platform_for_education_about", false, false], [25, 26, 1, 1, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["L'", "AIBO", "\u00e8", "stato", "molto", "utilizzato", "come", "piattaforma", "economica", "per", "l'", "istruzione", "e", "la", "ricerca", "sull'", "intelligenza", "artificiale", ",", "perch\u00e9", "integra", "un", "computer", ",", "la", "visione", "computerizzata", "e", "gli", "articolatori", "in", "un", "pacchetto", "molto", "pi\u00f9", "economico", "dei", "robot", "di", "ricerca", "convenzionali", "."], "sentence-detokenized": "L'AIBO \u00e8 stato molto utilizzato come piattaforma economica per l'istruzione e la ricerca sull'intelligenza artificiale, perch\u00e9 integra un computer, la visione computerizzata e gli articolatori in un pacchetto molto pi\u00f9 economico dei robot di ricerca convenzionali.", "token2charspan": [[0, 2], [2, 6], [7, 8], [9, 14], [15, 20], [21, 31], [32, 36], [37, 48], [49, 58], [59, 62], [63, 65], [65, 75], [76, 77], [78, 80], [81, 88], [89, 94], [94, 106], [107, 118], [118, 119], [120, 126], [127, 134], [135, 137], [138, 146], [146, 147], [148, 150], [151, 158], [159, 173], [174, 175], [176, 179], [180, 192], [193, 195], [196, 198], [199, 208], [209, 214], [215, 218], [219, 228], [229, 232], [233, 238], [239, 241], [242, 249], [250, 263], [263, 264]]}
{"doc_key": "ai-test-29", "ner": [[6, 11, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["\u00c8", "stata", "presidente", "del", "programma", "della", "Conferenza", "internazionale", "sulla", "visione", "artificiale", "2021", "."], "sentence-detokenized": "\u00c8 stata presidente del programma della Conferenza internazionale sulla visione artificiale 2021.", "token2charspan": [[0, 1], [2, 7], [8, 18], [19, 22], [23, 32], [33, 38], [39, 49], [50, 64], [65, 70], [71, 78], [79, 90], [91, 95], [95, 96]]}
{"doc_key": "ai-test-30", "ner": [[0, 0, "researcher"], [10, 10, "organisation"], [20, 20, "organisation"], [29, 30, "organisation"], [37, 42, "product"], [44, 44, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 10, 10, "role", "", false, false], [0, 0, 20, 20, "role", "", true, false], [20, 20, 29, 30, "role", "develops_with", false, false], [37, 42, 20, 20, "artifact", "", false, false], [44, 44, 37, 42, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Scheinman", ",", "dopo", "aver", "ricevuto", "una", "borsa", "di", "studio", "da", "Unimation", "per", "sviluppare", "i", "suoi", "progetti", ",", "li", "vendette", "a", "Unimation", "che", "li", "svilupp\u00f2", "ulteriormente", "con", "il", "supporto", "di", "General", "Motors", "e", "li", "commercializz\u00f2", "in", "seguito", "come", "Macchina", "Universale", "Programmabile", "per", "l'", "Assemblaggio", "(", "PUMA", ")", "."], "sentence-detokenized": "Scheinman, dopo aver ricevuto una borsa di studio da Unimation per sviluppare i suoi progetti, li vendette a Unimation che li svilupp\u00f2 ulteriormente con il supporto di General Motors e li commercializz\u00f2 in seguito come Macchina Universale Programmabile per l'Assemblaggio (PUMA).", "token2charspan": [[0, 9], [9, 10], [11, 15], [16, 20], [21, 29], [30, 33], [34, 39], [40, 42], [43, 49], [50, 52], [53, 62], [63, 66], [67, 77], [78, 79], [80, 84], [85, 93], [93, 94], [95, 97], [98, 106], [107, 108], [109, 118], [119, 122], [123, 125], [126, 134], [135, 148], [149, 152], [153, 155], [156, 164], [165, 167], [168, 175], [176, 182], [183, 184], [185, 187], [188, 202], [203, 205], [206, 213], [214, 218], [219, 227], [228, 238], [239, 252], [253, 256], [257, 259], [259, 271], [272, 273], [273, 277], [277, 278], [278, 279]]}
{"doc_key": "ai-test-31", "ner": [[9, 10, "task"], [7, 12, "task"], [16, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 16, 9, 10, "general-affiliation", "works_with", false, false], [16, 16, 7, 12, "general-affiliation", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Una", "panoramica", "dei", "metodi", "di", "calibrazione", "per", "compiti", "di", "classificazione", "binaria", "e", "multiclasse", "\u00e8", "fornita", "da", "Gebel", "(", "2009", ")"], "sentence-detokenized": "Una panoramica dei metodi di calibrazione per compiti di classificazione binaria e multiclasse \u00e8 fornita da Gebel (2009)", "token2charspan": [[0, 3], [4, 14], [15, 18], [19, 25], [26, 28], [29, 41], [42, 45], [46, 53], [54, 56], [57, 72], [73, 80], [81, 82], [83, 94], [95, 96], [97, 104], [105, 107], [108, 113], [114, 115], [115, 119], [119, 120]]}
{"doc_key": "ai-test-32", "ner": [[6, 9, "task"], [11, 11, "task"], [15, 16, "task"], [21, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 6, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["\u00c8", "coinvolto", "in", "campi", "quali", "il", "riconoscimento", "ottico", "dei", "caratteri", "(", "OCR", ")", ",", "la", "sintesi", "vocale", ",", "la", "tecnologia", "di", "riconoscimento", "vocale", "e", "gli", "strumenti", "elettronici", "a", "tastiera", "."], "sentence-detokenized": "\u00c8 coinvolto in campi quali il riconoscimento ottico dei caratteri (OCR), la sintesi vocale, la tecnologia di riconoscimento vocale e gli strumenti elettronici a tastiera.", "token2charspan": [[0, 1], [2, 11], [12, 14], [15, 20], [21, 26], [27, 29], [30, 44], [45, 51], [52, 55], [56, 65], [66, 67], [67, 70], [70, 71], [71, 72], [73, 75], [76, 83], [84, 90], [90, 91], [92, 94], [95, 105], [106, 108], [109, 123], [124, 130], [131, 132], [133, 136], [137, 146], [147, 158], [159, 160], [161, 169], [169, 170]]}
{"doc_key": "ai-test-33", "ner": [[13, 14, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Per", "le", "tecniche", "pi\u00f9", "recenti", "e", "all'", "avanguardia", ",", "\u00e8", "possibile", "utilizzare", "il", "toolkit", "Kaldi", "."], "sentence-detokenized": "Per le tecniche pi\u00f9 recenti e all'avanguardia, \u00e8 possibile utilizzare il toolkit Kaldi.", "token2charspan": [[0, 3], [4, 6], [7, 15], [16, 19], [20, 27], [28, 29], [30, 34], [34, 45], [45, 46], [47, 48], [49, 58], [59, 69], [70, 72], [73, 80], [81, 86], [86, 87]]}
{"doc_key": "ai-test-34", "ner": [[0, 2, "researcher"], [6, 8, "organisation"], [12, 13, "organisation"], [17, 18, "organisation"], [20, 21, "researcher"], [24, 27, "organisation"], [31, 33, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 6, 8, "role", "", false, false], [0, 2, 12, 13, "role", "", false, false], [0, 2, 17, 18, "role", "", false, false], [0, 2, 24, 27, "role", "", false, false], [0, 2, 31, 33, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Johnson", "-", "Laird", "\u00e8", "Fellow", "dell'", "American", "Philosophical", "Society", ",", "Fellow", "della", "Royal", "Society", ",", "Fellow", "della", "British", "Academy", ",", "William", "James", "Fellow", "dell'", "Association", "for", "Psychological", "Science", "e", "Fellow", "della", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Johnson-Laird \u00e8 Fellow dell'American Philosophical Society, Fellow della Royal Society, Fellow della British Academy, William James Fellow dell'Association for Psychological Science e Fellow della Cognitive Science Society.", "token2charspan": [[0, 7], [7, 8], [8, 13], [14, 15], [16, 22], [23, 28], [28, 36], [37, 50], [51, 58], [58, 59], [60, 66], [67, 72], [73, 78], [79, 86], [86, 87], [88, 94], [95, 100], [101, 108], [109, 116], [116, 117], [118, 125], [126, 131], [132, 138], [139, 144], [144, 155], [156, 159], [160, 173], [174, 181], [182, 183], [184, 190], [191, 196], [197, 206], [207, 214], [215, 222], [222, 223]]}
{"doc_key": "ai-test-35", "ner": [[1, 8, "conference"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 20, "researcher"], [23, 24, "algorithm"], [29, 34, "task"], [36, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 13, 1, 8, "physical", "", false, false], [12, 13, 1, 8, "temporal", "", false, false], [15, 16, 1, 8, "physical", "", false, false], [15, 16, 1, 8, "temporal", "", false, false], [18, 20, 1, 8, "physical", "", false, false], [18, 20, 1, 8, "temporal", "", false, false], [23, 24, 18, 20, "role", "extends", false, false], [29, 34, 18, 20, "role", "extends", false, false], [36, 36, 29, 34, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Alla", "Conferenza", "internazionale", "sull'", "elaborazione", "delle", "immagini", "dell'", "IEEE", "nel", "2010", ",", "Rui", "Hu", ",", "Mark", "Banard", "e", "John", "Collomosse", "hanno", "esteso", "il", "descrittore", "HOG", "per", "l'", "uso", "nel", "recupero", "di", "immagini", "basato", "su", "schizzi", "(", "SBIR", ")", "."], "sentence-detokenized": "Alla Conferenza internazionale sull'elaborazione delle immagini dell'IEEE nel 2010, Rui Hu, Mark Banard e John Collomosse hanno esteso il descrittore HOG per l'uso nel recupero di immagini basato su schizzi (SBIR).", "token2charspan": [[0, 4], [5, 15], [16, 30], [31, 36], [36, 48], [49, 54], [55, 63], [64, 69], [69, 73], [74, 77], [78, 82], [82, 83], [84, 87], [88, 90], [90, 91], [92, 96], [97, 103], [104, 105], [106, 110], [111, 121], [122, 127], [128, 134], [135, 137], [138, 149], [150, 153], [154, 157], [158, 160], [160, 163], [164, 167], [168, 176], [177, 179], [180, 188], [189, 195], [196, 198], [199, 206], [207, 208], [208, 212], [212, 213], [213, 214]]}
{"doc_key": "ai-test-36", "ner": [[0, 0, "metrics"], [6, 6, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["BLEU", "utilizza", "una", "forma", "modificata", "di", "precisione", "per", "confrontare", "una", "traduzione", "candidata", "con", "pi\u00f9", "traduzioni", "di", "riferimento", "."], "sentence-detokenized": "BLEU utilizza una forma modificata di precisione per confrontare una traduzione candidata con pi\u00f9 traduzioni di riferimento.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 23], [24, 34], [35, 37], [38, 48], [49, 52], [53, 64], [65, 68], [69, 79], [80, 89], [90, 93], [94, 97], [98, 108], [109, 111], [112, 123], [123, 124]]}
{"doc_key": "ai-test-37", "ner": [[40, 41, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Per", "il", "caso", "di", "uno", "spazio", "di", "base", "generale", "math", "(", "Y", ",", "\\", "mathcal", "{", "B", "}", ",", "\\", "nu", ")", "/", "math", "(", "cio\u00e8", "uno", "spazio", "di", "base", "che", "non", "\u00e8", "conteggiabile", ")", ",", "si", "considera", "tipicamente", "l'", "entropia", "relativa", "."], "sentence-detokenized": "Per il caso di uno spazio di base generale math (Y,\\ mathcal {B},\\ nu) / math (cio\u00e8 uno spazio di base che non \u00e8 conteggiabile), si considera tipicamente l'entropia relativa.", "token2charspan": [[0, 3], [4, 6], [7, 11], [12, 14], [15, 18], [19, 25], [26, 28], [29, 33], [34, 42], [43, 47], [48, 49], [49, 50], [50, 51], [51, 52], [53, 60], [61, 62], [62, 63], [63, 64], [64, 65], [65, 66], [67, 69], [69, 70], [71, 72], [73, 77], [78, 79], [79, 83], [84, 87], [88, 94], [95, 97], [98, 102], [103, 106], [107, 110], [111, 112], [113, 126], [126, 127], [127, 128], [129, 131], [132, 141], [142, 153], [154, 156], [156, 164], [165, 173], [173, 174]]}
{"doc_key": "ai-test-38", "ner": [[17, 18, "country"], [10, 12, "organisation"], [14, 14, "organisation"], [27, 28, "country"], [21, 22, "organisation"], [24, 24, "organisation"], [31, 33, "organisation"], [46, 47, "country"], [36, 41, "organisation"], [43, 43, "organisation"], [58, 58, "misc"], [54, 57, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[10, 12, 17, 18, "physical", "", false, false], [14, 14, 10, 12, "named", "", false, false], [21, 22, 27, 28, "physical", "", false, false], [24, 24, 21, 22, "named", "", false, false], [36, 41, 46, 47, "physical", "", false, false], [43, 43, 36, 41, "named", "", false, false], [58, 58, 54, 57, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["A", "ottobre", "2011", ",", "le", "partnership", "gi\u00e0", "esistenti", "con", "il", "National", "Park", "Service", "(", "NPS", ")", "degli", "Stati", "Uniti", ",", "l'", "Historic", "Scotland", "(", "HS", ")", "del", "Regno", "Unito", ",", "il", "World", "Monuments", "Fund", "e", "l'", "Instituto", "Nacional", "de", "Antropolog\u00eda", "y", "Historia", "(", "INAH", ")", "del", "Messico", "sono", "state", "notevolmente", "ampliate", ",", "si", "legge", "sul", "sito", "web", "di", "CyArk", "."], "sentence-detokenized": "A ottobre 2011, le partnership gi\u00e0 esistenti con il National Park Service (NPS) degli Stati Uniti, l'Historic Scotland (HS) del Regno Unito, il World Monuments Fund e l'Instituto Nacional de Antropolog\u00eda y Historia (INAH) del Messico sono state notevolmente ampliate, si legge sul sito web di CyArk.", "token2charspan": [[0, 1], [2, 9], [10, 14], [14, 15], [16, 18], [19, 30], [31, 34], [35, 44], [45, 48], [49, 51], [52, 60], [61, 65], [66, 73], [74, 75], [75, 78], [78, 79], [80, 85], [86, 91], [92, 97], [97, 98], [99, 101], [101, 109], [110, 118], [119, 120], [120, 122], [122, 123], [124, 127], [128, 133], [134, 139], [139, 140], [141, 143], [144, 149], [150, 159], [160, 164], [165, 166], [167, 169], [169, 178], [179, 187], [188, 190], [191, 203], [204, 205], [206, 214], [215, 216], [216, 220], [220, 221], [222, 225], [226, 233], [234, 238], [239, 244], [245, 257], [258, 266], [266, 267], [268, 270], [271, 276], [277, 280], [281, 285], [286, 289], [290, 292], [293, 298], [298, 299]]}
{"doc_key": "ai-test-39", "ner": [[0, 3, "algorithm"], [10, 11, "field"], [15, 15, "product"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 15, 15, "part-of", "", false, false], [0, 3, 17, 17, "part-of", "", false, false], [15, 15, 10, 11, "general-affiliation", "", false, false], [17, 17, 10, 11, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Le", "SVM", "a", "kernel", "sono", "disponibili", "in", "molti", "toolkit", "di", "apprendimento", "automatico", ",", "tra", "cui", "LIBSVM", ",", "MATLAB", "e", "altri", "."], "sentence-detokenized": "Le SVM a kernel sono disponibili in molti toolkit di apprendimento automatico, tra cui LIBSVM, MATLAB e altri.", "token2charspan": [[0, 2], [3, 6], [7, 8], [9, 15], [16, 20], [21, 32], [33, 35], [36, 41], [42, 49], [50, 52], [53, 66], [67, 77], [77, 78], [79, 82], [83, 86], [87, 93], [93, 94], [95, 101], [102, 103], [104, 109], [109, 110]]}
{"doc_key": "ai-test-40", "ner": [[0, 4, "misc"], [15, 16, "location"], [18, 18, "location"], [19, 19, "country"], [25, 27, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 15, 16, "physical", "", false, false], [0, 4, 25, 27, "temporal", "", false, false], [15, 16, 18, 18, "physical", "", false, false], [18, 18, 19, 19, "physical", "", false, false], [25, 27, 15, 16, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Il", "concorso", "del", "Premio", "Loebner", "2009", "si", "\u00e8", "tenuto", "il", "6", "settembre", "2009", "presso", "il", "Brighton", "Centre", ",", "Brighton", "UK", ",", "in", "concomitanza", "con", "la", "conferenza", "Interspeech", "2009", "."], "sentence-detokenized": "Il concorso del Premio Loebner 2009 si \u00e8 tenuto il 6 settembre 2009 presso il Brighton Centre, Brighton UK, in concomitanza con la conferenza Interspeech 2009.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 22], [23, 30], [31, 35], [36, 38], [39, 40], [41, 47], [48, 50], [51, 52], [53, 62], [63, 67], [68, 74], [75, 77], [78, 86], [87, 93], [93, 94], [95, 103], [104, 106], [106, 107], [108, 110], [111, 123], [124, 127], [128, 130], [131, 141], [142, 153], [154, 158], [158, 159]]}
{"doc_key": "ai-test-41", "ner": [[0, 3, "product"], [10, 10, "product"], [19, 19, "product"], [15, 20, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 20, 0, 3, "part-of", "", false, false], [15, 20, 10, 10, "part-of", "", false, false], [15, 20, 19, 19, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Il", "robot", "umanoide", "QRIO", "\u00e8", "stato", "progettato", "come", "successore", "di", "AIBO", "e", "utilizza", "lo", "stesso", "sistema", "operativo", "di", "base", "R-CODE", "Aperios", "."], "sentence-detokenized": "Il robot umanoide QRIO \u00e8 stato progettato come successore di AIBO e utilizza lo stesso sistema operativo di base R-CODE Aperios.", "token2charspan": [[0, 2], [3, 8], [9, 17], [18, 22], [23, 24], [25, 30], [31, 41], [42, 46], [47, 57], [58, 60], [61, 65], [66, 67], [68, 76], [77, 79], [80, 86], [87, 94], [95, 104], [105, 107], [108, 112], [113, 119], [120, 127], [127, 128]]}
{"doc_key": "ai-test-42", "ner": [[0, 5, "misc"], [10, 11, "algorithm"], [16, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 0, 5, "cause-effect", "", true, false], [16, 17, 0, 5, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Le", "forme", "d'", "onda", "del", "parlato", "sono", "generate", "dagli", "stessi", "HMM", "in", "base", "al", "criterio", "della", "massima", "verosimiglianza", "."], "sentence-detokenized": "Le forme d'onda del parlato sono generate dagli stessi HMM in base al criterio della massima verosimiglianza.", "token2charspan": [[0, 2], [3, 8], [9, 11], [11, 15], [16, 19], [20, 27], [28, 32], [33, 41], [42, 47], [48, 54], [55, 58], [59, 61], [62, 66], [67, 69], [70, 78], [79, 84], [85, 92], [93, 108], [108, 109]]}
{"doc_key": "ai-test-43", "ner": [[0, 1, "product"], [7, 12, "task"], [11, 11, "task"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 7, 12, "type-of", "", false, false], [0, 1, 11, 11, "type-of", "", false, false], [0, 1, 15, 15, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Google", "Translate", "\u00e8", "un", "servizio", "gratuito", "di", "traduzione", "automatica", "statistica", "e", "neurale", "multilingue", "sviluppato", "da", "Google", "per", "tradurre", "testi", "e", "siti", "web", "da", "una", "lingua", "all'", "altra", "."], "sentence-detokenized": "Google Translate \u00e8 un servizio gratuito di traduzione automatica statistica e neurale multilingue sviluppato da Google per tradurre testi e siti web da una lingua all'altra.", "token2charspan": [[0, 6], [7, 16], [17, 18], [19, 21], [22, 30], [31, 39], [40, 42], [43, 53], [54, 64], [65, 75], [76, 77], [78, 85], [86, 97], [98, 108], [109, 111], [112, 118], [119, 122], [123, 131], [132, 137], [138, 139], [140, 144], [145, 148], [149, 151], [152, 155], [156, 162], [163, 167], [167, 172], [172, 173]]}
{"doc_key": "ai-test-44", "ner": [[6, 7, "field"], [10, 12, "field"], [15, 17, "field"], [20, 23, "field"], [28, 31, "task"], [34, 37, "task"], [40, 44, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[28, 31, 6, 7, "part-of", "", false, true], [28, 31, 10, 12, "part-of", "", false, true], [28, 31, 15, 17, "part-of", "", false, true], [34, 37, 6, 7, "part-of", "", false, true], [34, 37, 10, 12, "part-of", "", false, true], [34, 37, 15, 17, "part-of", "", false, true], [40, 44, 6, 7, "part-of", "", false, true], [40, 44, 10, 12, "part-of", "", false, true], [40, 44, 15, 17, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Gli", "scheletri", "sono", "ampiamente", "utilizzati", "nella", "computer", "vision", ",", "nell'", "analisi", "delle", "immagini", ",", "nel", "riconoscimento", "dei", "modelli", "e", "nell'", "elaborazione", "delle", "immagini", "digitali", "per", "scopi", "quali", "il", "riconoscimento", "ottico", "dei", "caratteri", ",", "il", "riconoscimento", "delle", "impronte", "digitali", ",", "l'", "ispezione", "visiva", "o", "la", "compressione", "."], "sentence-detokenized": "Gli scheletri sono ampiamente utilizzati nella computer vision, nell'analisi delle immagini, nel riconoscimento dei modelli e nell'elaborazione delle immagini digitali per scopi quali il riconoscimento ottico dei caratteri, il riconoscimento delle impronte digitali, l'ispezione visiva o la compressione.", "token2charspan": [[0, 3], [4, 13], [14, 18], [19, 29], [30, 40], [41, 46], [47, 55], [56, 62], [62, 63], [64, 69], [69, 76], [77, 82], [83, 91], [91, 92], [93, 96], [97, 111], [112, 115], [116, 123], [124, 125], [126, 131], [131, 143], [144, 149], [150, 158], [159, 167], [168, 171], [172, 177], [178, 183], [184, 186], [187, 201], [202, 208], [209, 212], [213, 222], [222, 223], [224, 226], [227, 241], [242, 247], [248, 256], [257, 265], [265, 266], [267, 269], [269, 278], [279, 285], [286, 287], [288, 290], [291, 303], [303, 304]]}
{"doc_key": "ai-test-45", "ner": [[1, 6, "conference"], [14, 19, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 6, 14, 19, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["L'", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "\u00e8", "un", "punto", "di", "riferimento", "per", "la", "classificazione", "e", "il", "rilevamento", "degli", "oggetti", ",", "con", "milioni", "di", "immagini", "e", "centinaia", "di", "classi", "di", "oggetti", "."], "sentence-detokenized": "L'ImageNet Large Scale Visual Recognition Challenge \u00e8 un punto di riferimento per la classificazione e il rilevamento degli oggetti, con milioni di immagini e centinaia di classi di oggetti.", "token2charspan": [[0, 2], [2, 10], [11, 16], [17, 22], [23, 29], [30, 41], [42, 51], [52, 53], [54, 56], [57, 62], [63, 65], [66, 77], [78, 81], [82, 84], [85, 100], [101, 102], [103, 105], [106, 117], [118, 123], [124, 131], [131, 132], [133, 136], [137, 144], [145, 147], [148, 156], [157, 158], [159, 168], [169, 171], [172, 178], [179, 181], [182, 189], [189, 190]]}
{"doc_key": "ai-test-46", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [16, 18, "misc"], [21, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 16, 18, "part-of", "", false, false], [0, 0, 21, 24, "part-of", "", false, false], [4, 5, 16, 18, "part-of", "", false, false], [4, 5, 21, 24, "part-of", "", false, false], [7, 8, 16, 18, "part-of", "", false, false], [7, 8, 21, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Bengio", ",", "insieme", "a", "Geoffrey", "Hinton", "e", "Yann", "LeCun", ",", "viene", "definito", "da", "alcuni", "come", "i", "padrini", "dell'", "IA", "e", "i", "padrini", "del", "Deep", "Learning", "."], "sentence-detokenized": "Bengio, insieme a Geoffrey Hinton e Yann LeCun, viene definito da alcuni come i padrini dell'IA e i padrini del Deep Learning.", "token2charspan": [[0, 6], [6, 7], [8, 15], [16, 17], [18, 26], [27, 33], [34, 35], [36, 40], [41, 46], [46, 47], [48, 53], [54, 62], [63, 65], [66, 72], [73, 77], [78, 79], [80, 87], [88, 93], [93, 95], [96, 97], [98, 99], [100, 107], [108, 111], [112, 116], [117, 125], [125, 126]]}
{"doc_key": "ai-test-47", "ner": [[5, 5, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["\u00c8", "membro", "a", "vita", "dell'", "IEEE", "."], "sentence-detokenized": "\u00c8 membro a vita dell'IEEE.", "token2charspan": [[0, 1], [2, 8], [9, 10], [11, 15], [16, 21], [21, 25], [25, 26]]}
{"doc_key": "ai-test-48", "ner": [[0, 2, "organisation"], [17, 22, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 17, 22, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["L'", "NSA", "Bethesda", "\u00e8", "responsabile", "del", "supporto", "operativo", "della", "base", "per", "il", "suo", "principale", "inquilino", ",", "il", "Walter", "Reed", "National", "Military", "Medical", "Center", "."], "sentence-detokenized": "L'NSA Bethesda \u00e8 responsabile del supporto operativo della base per il suo principale inquilino, il Walter Reed National Military Medical Center.", "token2charspan": [[0, 2], [2, 5], [6, 14], [15, 16], [17, 29], [30, 33], [34, 42], [43, 52], [53, 58], [59, 63], [64, 67], [68, 70], [71, 74], [75, 85], [86, 95], [95, 96], [97, 99], [100, 106], [107, 111], [112, 120], [121, 129], [130, 137], [138, 144], [144, 145]]}
{"doc_key": "ai-test-49", "ner": [[8, 9, "field"], [12, 14, "field"], [17, 19, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["I", "tre", "principali", "paradigmi", "di", "apprendimento", "sono", "l'", "apprendimento", "supervisionato", ",", "l'", "apprendimento", "non", "supervisionato", "e", "l'", "apprendimento", "per", "rinforzo", "."], "sentence-detokenized": "I tre principali paradigmi di apprendimento sono l'apprendimento supervisionato, l'apprendimento non supervisionato e l'apprendimento per rinforzo.", "token2charspan": [[0, 1], [2, 5], [6, 16], [17, 26], [27, 29], [30, 43], [44, 48], [49, 51], [51, 64], [65, 79], [79, 80], [81, 83], [83, 96], [97, 100], [101, 115], [116, 117], [118, 120], [120, 133], [134, 137], [138, 146], [146, 147]]}
{"doc_key": "ai-test-50", "ner": [[6, 6, "task"], [9, 12, "task"], [17, 23, "task"], [26, 28, "task"], [31, 34, "task"], [37, 38, "task"], [41, 42, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Tra", "gli", "esempi", "vi", "sono", "il", "controllo", ",", "la", "pianificazione", "e", "la", "programmazione", ",", "la", "capacit\u00e0", "di", "rispondere", "a", "domande", "diagnostiche", "e", "di", "consumo", ",", "il", "riconoscimento", "della", "scrittura", ",", "la", "comprensione", "del", "linguaggio", "naturale", ",", "il", "riconoscimento", "vocale", "e", "il", "riconoscimento", "facciale", "."], "sentence-detokenized": "Tra gli esempi vi sono il controllo, la pianificazione e la programmazione, la capacit\u00e0 di rispondere a domande diagnostiche e di consumo, il riconoscimento della scrittura, la comprensione del linguaggio naturale, il riconoscimento vocale e il riconoscimento facciale.", "token2charspan": [[0, 3], [4, 7], [8, 14], [15, 17], [18, 22], [23, 25], [26, 35], [35, 36], [37, 39], [40, 54], [55, 56], [57, 59], [60, 74], [74, 75], [76, 78], [79, 87], [88, 90], [91, 101], [102, 103], [104, 111], [112, 124], [125, 126], [127, 129], [130, 137], [137, 138], [139, 141], [142, 156], [157, 162], [163, 172], [172, 173], [174, 176], [177, 189], [190, 193], [194, 204], [205, 213], [213, 214], [215, 217], [218, 232], [233, 239], [240, 241], [242, 244], [245, 259], [260, 268], [268, 269]]}
{"doc_key": "ai-test-51", "ner": [[7, 13, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Nel", "1991", "\u00e8", "stato", "eletto", "fellow", "dell'", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "1990", ",", "founding", "fellow", ")", "."], "sentence-detokenized": "Nel 1991 \u00e8 stato eletto fellow dell'Association for the Advancement of Artificial Intelligence (1990, founding fellow).", "token2charspan": [[0, 3], [4, 8], [9, 10], [11, 16], [17, 23], [24, 30], [31, 36], [36, 47], [48, 51], [52, 55], [56, 67], [68, 70], [71, 81], [82, 94], [95, 96], [96, 100], [100, 101], [102, 110], [111, 117], [117, 118], [118, 119]]}
{"doc_key": "ai-test-52", "ner": [[9, 11, "misc"], [15, 17, "algorithm"], [30, 32, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Tuttavia", ",", "formulando", "il", "problema", "come", "soluzione", "di", "una", "matrice", "di", "Toeplitz", "e", "utilizzando", "la", "ricorsione", "di", "Levinson", ",", "possiamo", "stimare", "in", "modo", "relativamente", "rapido", "un", "filtro", "con", "il", "minor", "errore", "quadratico", "medio", "possibile", "."], "sentence-detokenized": "Tuttavia, formulando il problema come soluzione di una matrice di Toeplitz e utilizzando la ricorsione di Levinson, possiamo stimare in modo relativamente rapido un filtro con il minor errore quadratico medio possibile.", "token2charspan": [[0, 8], [8, 9], [10, 20], [21, 23], [24, 32], [33, 37], [38, 47], [48, 50], [51, 54], [55, 62], [63, 65], [66, 74], [75, 76], [77, 88], [89, 91], [92, 102], [103, 105], [106, 114], [114, 115], [116, 124], [125, 132], [133, 135], [136, 140], [141, 154], [155, 161], [162, 164], [165, 171], [172, 175], [176, 178], [179, 184], [185, 191], [192, 202], [203, 208], [209, 218], [218, 219]]}
{"doc_key": "ai-test-53", "ner": [[6, 11, "conference"], [14, 19, "location"], [21, 21, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 11, 14, 19, "physical", "", false, false], [14, 19, 21, 21, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Nel", "luglio", "2011", "si", "terr\u00e0", "la", "15a", "edizione", "di", "Campus", "Party", "Spagna", "presso", "la", "Citt\u00e0", "delle", "Arti", "e", "delle", "Scienze", "di", "Valencia", "."], "sentence-detokenized": "Nel luglio 2011 si terr\u00e0 la 15a edizione di Campus Party Spagna presso la Citt\u00e0 delle Arti e delle Scienze di Valencia.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 18], [19, 24], [25, 27], [28, 31], [32, 40], [41, 43], [44, 50], [51, 56], [57, 63], [64, 70], [71, 73], [74, 79], [80, 85], [86, 90], [91, 92], [93, 98], [99, 106], [107, 109], [110, 118], [118, 119]]}
{"doc_key": "ai-test-54", "ner": [[12, 12, "product"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Spesso", "questo", "\u00e8", "possibile", "solo", "alla", "fine", "di", "giochi", "complicati", "come", "gli", "scacchi", "o", "il", "go", ",", "poich\u00e9", "non", "\u00e8", "computazionalmente", "fattibile", "guardare", "avanti", "fino", "al", "completamento", "della", "partita", ",", "se", "non", "verso", "la", "fine", ",", "e", "invece", "le", "posizioni", "sono", "date", "a", "valori", "finiti", "come", "stime", "del", "grado", "di", "convinzione", "che", "porteranno", "a", "una", "vittoria", "per", "un", "giocatore", "o", "per", "un", "altro", "."], "sentence-detokenized": "Spesso questo \u00e8 possibile solo alla fine di giochi complicati come gli scacchi o il go, poich\u00e9 non \u00e8 computazionalmente fattibile guardare avanti fino al completamento della partita, se non verso la fine, e invece le posizioni sono date a valori finiti come stime del grado di convinzione che porteranno a una vittoria per un giocatore o per un altro.", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 25], [26, 30], [31, 35], [36, 40], [41, 43], [44, 50], [51, 61], [62, 66], [67, 70], [71, 78], [79, 80], [81, 83], [84, 86], [86, 87], [88, 94], [95, 98], [99, 100], [101, 119], [120, 129], [130, 138], [139, 145], [146, 150], [151, 153], [154, 167], [168, 173], [174, 181], [181, 182], [183, 185], [186, 189], [190, 195], [196, 198], [199, 203], [203, 204], [205, 206], [207, 213], [214, 216], [217, 226], [227, 231], [232, 236], [237, 238], [239, 245], [246, 252], [253, 257], [258, 263], [264, 267], [268, 273], [274, 276], [277, 288], [289, 292], [293, 303], [304, 305], [306, 309], [310, 318], [319, 322], [323, 325], [326, 335], [336, 337], [338, 341], [342, 344], [345, 350], [350, 351]]}
{"doc_key": "ai-test-55", "ner": [[4, 6, "algorithm"], [26, 28, "algorithm"], [31, 34, "algorithm"], [37, 39, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 26, 28, "compare", "", false, false], [4, 6, 31, 34, "compare", "", false, false], [4, 6, 37, 39, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "differenza", "tra", "il", "modello", "logit", "multinomiale", "e", "numerosi", "altri", "metodi", ",", "modelli", ",", "algoritmi", ",", "ecc", ".", "con", "la", "stessa", "impostazione", "di", "base", "(", "l'", "algoritmo", "del", "perceptron", ",", "le", "macchine", "vettoriali", "di", "supporto", ",", "l'", "analisi", "discriminante", "lineare", ",", "ecc", "."], "sentence-detokenized": "La differenza tra il modello logit multinomiale e numerosi altri metodi, modelli, algoritmi, ecc. con la stessa impostazione di base (l'algoritmo del perceptron, le macchine vettoriali di supporto, l'analisi discriminante lineare, ecc.", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 20], [21, 28], [29, 34], [35, 47], [48, 49], [50, 58], [59, 64], [65, 71], [71, 72], [73, 80], [80, 81], [82, 91], [91, 92], [93, 96], [96, 97], [98, 101], [102, 104], [105, 111], [112, 124], [125, 127], [128, 132], [133, 134], [134, 136], [136, 145], [146, 149], [150, 160], [160, 161], [162, 164], [165, 173], [174, 184], [185, 187], [188, 196], [196, 197], [198, 200], [200, 207], [208, 221], [222, 229], [229, 230], [231, 234], [234, 235]]}
{"doc_key": "ai-test-56", "ner": [[0, 3, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Association", "for", "Computational", "Linguistics", ",", "pubblicato", "da"], "sentence-detokenized": "Association for Computational Linguistics, pubblicato da", "token2charspan": [[0, 11], [12, 15], [16, 29], [30, 41], [41, 42], [43, 53], [54, 56]]}
{"doc_key": "ai-test-57", "ner": [[1, 4, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Nel", "sistema", "di", "riconoscimento", "facciale", "computerizzato", ",", "ogni", "volto", "\u00e8", "rappresentato", "da", "un", "gran", "numero", "di", "valori", "di", "pixel", "."], "sentence-detokenized": "Nel sistema di riconoscimento facciale computerizzato, ogni volto \u00e8 rappresentato da un gran numero di valori di pixel.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 29], [30, 38], [39, 53], [53, 54], [55, 59], [60, 65], [66, 67], [68, 81], [82, 84], [85, 87], [88, 92], [93, 99], [100, 102], [103, 109], [110, 112], [113, 118], [118, 119]]}
{"doc_key": "ai-test-58", "ner": [[5, 6, "person"], [14, 16, "organisation"], [24, 24, "country"], [27, 27, "person"], [40, 42, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 14, 16, "role", "", false, false], [5, 6, 24, 24, "physical", "", false, false], [27, 27, 40, 42, "origin", "", false, false], [27, 27, 40, 42, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Nel", "2002", ",", "suo", "figlio", "Daniel", "Pearl", ",", "un", "giornalista", "che", "lavorava", "per", "il", "Wall", "Street", "Journal", ",", "\u00e8", "stato", "rapito", "e", "assassinato", "in", "Pakistan", ",", "portando", "Judea", "e", "gli", "altri", "membri", "della", "famiglia", "e", "gli", "amici", "a", "creare", "la", "Daniel", "Pearl", "Foundation", "."], "sentence-detokenized": "Nel 2002, suo figlio Daniel Pearl, un giornalista che lavorava per il Wall Street Journal, \u00e8 stato rapito e assassinato in Pakistan, portando Judea e gli altri membri della famiglia e gli amici a creare la Daniel Pearl Foundation.", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 13], [14, 20], [21, 27], [28, 33], [33, 34], [35, 37], [38, 49], [50, 53], [54, 62], [63, 66], [67, 69], [70, 74], [75, 81], [82, 89], [89, 90], [91, 92], [93, 98], [99, 105], [106, 107], [108, 119], [120, 122], [123, 131], [131, 132], [133, 141], [142, 147], [148, 149], [150, 153], [154, 159], [160, 166], [167, 172], [173, 181], [182, 183], [184, 187], [188, 193], [194, 195], [196, 202], [203, 205], [206, 212], [213, 218], [219, 229], [229, 230]]}
{"doc_key": "ai-test-59", "ner": [[7, 9, "organisation"], [22, 23, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 9, 22, 23, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "partire", "dalla", "fine", "del", "2006", ",", "Red", "Envelope", "Entertainment", "si", "\u00e8", "estesa", "anche", "alla", "produzione", "di", "contenuti", "originali", "con", "registi", "come", "John", "Waters", "."], "sentence-detokenized": "A partire dalla fine del 2006, Red Envelope Entertainment si \u00e8 estesa anche alla produzione di contenuti originali con registi come John Waters.", "token2charspan": [[0, 1], [2, 9], [10, 15], [16, 20], [21, 24], [25, 29], [29, 30], [31, 34], [35, 43], [44, 57], [58, 60], [61, 62], [63, 69], [70, 75], [76, 80], [81, 91], [92, 94], [95, 104], [105, 114], [115, 118], [119, 126], [127, 131], [132, 136], [137, 143], [143, 144]]}
{"doc_key": "ai-test-60", "ner": [[6, 10, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["L'", "edificio", "fa", "ora", "parte", "del", "Beth", "Israel", "Deaconess", "Medical", "Center", "."], "sentence-detokenized": "L'edificio fa ora parte del Beth Israel Deaconess Medical Center.", "token2charspan": [[0, 2], [2, 10], [11, 13], [14, 17], [18, 23], [24, 27], [28, 32], [33, 39], [40, 49], [50, 57], [58, 64], [64, 65]]}
{"doc_key": "ai-test-61", "ner": [[18, 19, "field"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Un", "tema", "comune", "di", "questo", "lavoro", "\u00e8", "l'", "adozione", "di", "una", "prospettiva", "segnico", "-", "teorica", "su", "questioni", "di", "intelligenza", "artificiale", "e", "rappresentazione", "della", "conoscenza", "."], "sentence-detokenized": "Un tema comune di questo lavoro \u00e8 l'adozione di una prospettiva segnico-teorica su questioni di intelligenza artificiale e rappresentazione della conoscenza.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 17], [18, 24], [25, 31], [32, 33], [34, 36], [36, 44], [45, 47], [48, 51], [52, 63], [64, 71], [71, 72], [72, 79], [80, 82], [83, 92], [93, 95], [96, 108], [109, 120], [121, 122], [123, 139], [140, 145], [146, 156], [156, 157]]}
{"doc_key": "ai-test-62", "ner": [[5, 7, "task"], [9, 9, "task"], [18, 19, "task"], [41, 43, "task"], [46, 48, "task"], [52, 54, "task"], [56, 56, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 7, 18, 19, "type-of", "", false, false], [5, 7, 52, 54, "compare", "", false, false], [5, 7, 52, 54, "opposite", "", false, false], [9, 9, 5, 7, "named", "", false, false], [41, 43, 52, 54, "part-of", "", false, false], [46, 48, 52, 54, "part-of", "", false, false], [52, 54, 18, 19, "type-of", "", false, false], [56, 56, 52, 54, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Ad", "esempio", ",", "il", "termine", "neural", "machine", "translation", "(", "NMT", ")", "sottolinea", "il", "fatto", "che", "gli", "approcci", "alla", "traduzione", "automatica", "basati", "sull'", "apprendimento", "profondo", "apprendono", "direttamente", "le", "trasformazioni", "da", "sequenza", "a", "sequenza", ",", "eliminando", "la", "necessit\u00e0", "di", "fasi", "intermedie", "come", "l'", "allineamento", "delle", "parole", "e", "la", "modellazione", "del", "linguaggio", ",", "utilizzate", "nella", "traduzione", "automatica", "statistica", "(", "SMT", ")", "."], "sentence-detokenized": "Ad esempio, il termine neural machine translation (NMT) sottolinea il fatto che gli approcci alla traduzione automatica basati sull'apprendimento profondo apprendono direttamente le trasformazioni da sequenza a sequenza, eliminando la necessit\u00e0 di fasi intermedie come l'allineamento delle parole e la modellazione del linguaggio, utilizzate nella traduzione automatica statistica (SMT).", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 14], [15, 22], [23, 29], [30, 37], [38, 49], [50, 51], [51, 54], [54, 55], [56, 66], [67, 69], [70, 75], [76, 79], [80, 83], [84, 92], [93, 97], [98, 108], [109, 119], [120, 126], [127, 132], [132, 145], [146, 154], [155, 165], [166, 178], [179, 181], [182, 196], [197, 199], [200, 208], [209, 210], [211, 219], [219, 220], [221, 231], [232, 234], [235, 244], [245, 247], [248, 252], [253, 263], [264, 268], [269, 271], [271, 283], [284, 289], [290, 296], [297, 298], [299, 301], [302, 314], [315, 318], [319, 329], [329, 330], [331, 341], [342, 347], [348, 358], [359, 369], [370, 380], [381, 382], [382, 385], [385, 386], [386, 387]]}
{"doc_key": "ai-test-63", "ner": [[8, 8, "field"], [13, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 8, 13, 13, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["La", "maggior", "parte", "della", "ricerca", "nel", "campo", "della", "WSD", "\u00e8", "stata", "condotta", "utilizzando", "WordNet", "come", "inventario", "di", "senso", "di", "riferimento", "."], "sentence-detokenized": "La maggior parte della ricerca nel campo della WSD \u00e8 stata condotta utilizzando WordNet come inventario di senso di riferimento.", "token2charspan": [[0, 2], [3, 10], [11, 16], [17, 22], [23, 30], [31, 34], [35, 40], [41, 46], [47, 50], [51, 52], [53, 58], [59, 67], [68, 79], [80, 87], [88, 92], [93, 103], [104, 106], [107, 112], [113, 115], [116, 127], [127, 128]]}
{"doc_key": "ai-test-64", "ner": [[14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Tra", "gli", "ex", "dottorandi", "e", "ricercatori", "post", "-", "dottorato", "del", "suo", "gruppo", "si", "ricordano", "Richard", "Zemel", "e", "Zoubin", "Ghahramani", "."], "sentence-detokenized": "Tra gli ex dottorandi e ricercatori post-dottorato del suo gruppo si ricordano Richard Zemel e Zoubin Ghahramani.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 21], [22, 23], [24, 35], [36, 40], [40, 41], [41, 50], [51, 54], [55, 58], [59, 65], [66, 68], [69, 78], [79, 86], [87, 92], [93, 94], [95, 101], [102, 112], [112, 113]]}
{"doc_key": "ai-test-65", "ner": [[8, 10, "metrics"], [16, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 10, 16, 16, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Ogni", "risultato", "di", "previsione", "o", "istanza", "di", "una", "matrice", "di", "confusione", "rappresenta", "un", "punto", "nello", "spazio", "ROC."], "sentence-detokenized": "Ogni risultato di previsione o istanza di una matrice di confusione rappresenta un punto nello spazio ROC.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 28], [29, 30], [31, 38], [39, 41], [42, 45], [46, 53], [54, 56], [57, 67], [68, 79], [80, 82], [83, 88], [89, 94], [95, 101], [102, 106]]}
{"doc_key": "ai-test-66", "ner": [[2, 2, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [16, 18, "product"], [22, 25, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 22, 25, "physical", "", false, false], [7, 8, 22, 25, "physical", "", false, false], [10, 11, 22, 25, "physical", "", false, false], [16, 18, 2, 2, "artifact", "", false, false], [16, 18, 7, 8, "artifact", "", false, false], [16, 18, 10, 11, "artifact", "", false, false], [16, 18, 22, 25, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Nel", "1997", "Thrun", "e", "i", "suoi", "colleghi", "Wolfram", "Burgard", "e", "Dieter", "Fox", "hanno", "sviluppato", "la", "prima", "guida", "turistica", "robotica", "al", "mondo", "nel", "Deutsches", "Museum", "di", "Bonn", "(", "1997", ")", "."], "sentence-detokenized": "Nel 1997 Thrun e i suoi colleghi Wolfram Burgard e Dieter Fox hanno sviluppato la prima guida turistica robotica al mondo nel Deutsches Museum di Bonn (1997).", "token2charspan": [[0, 3], [4, 8], [9, 14], [15, 16], [17, 18], [19, 23], [24, 32], [33, 40], [41, 48], [49, 50], [51, 57], [58, 61], [62, 67], [68, 78], [79, 81], [82, 87], [88, 93], [94, 103], [104, 112], [113, 115], [116, 121], [122, 125], [126, 135], [136, 142], [143, 145], [146, 150], [151, 152], [152, 156], [156, 157], [157, 158]]}
{"doc_key": "ai-test-67", "ner": [[0, 2, "product"], [6, 7, "misc"], [22, 26, "field"], [30, 32, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 7, 0, 2, "part-of", "", false, false], [22, 26, 0, 2, "usage", "", false, false], [30, 32, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["WordNet", "\u00e8", "un", "database", "lessicale", "di", "relazioni", "semantiche", "tra", "parole", "in", "pi\u00f9", "di", "200", "lingue", ".", "Il", "suo", "uso", "principale", "\u00e8", "l'", "elaborazione", "automatica", "del", "linguaggio", "naturale", "e", "le", "applicazioni", "di", "intelligenza", "artificiale", "."], "sentence-detokenized": "WordNet \u00e8 un database lessicale di relazioni semantiche tra parole in pi\u00f9 di 200 lingue. Il suo uso principale \u00e8 l'elaborazione automatica del linguaggio naturale e le applicazioni di intelligenza artificiale.", "token2charspan": [[0, 7], [8, 9], [10, 12], [13, 21], [22, 31], [32, 34], [35, 44], [45, 55], [56, 59], [60, 66], [67, 69], [70, 73], [74, 76], [77, 80], [81, 87], [87, 88], [89, 91], [92, 95], [96, 99], [100, 110], [111, 112], [113, 115], [115, 127], [128, 138], [139, 142], [143, 153], [154, 162], [163, 164], [165, 167], [168, 180], [181, 183], [184, 196], [197, 208], [208, 209]]}
{"doc_key": "ai-test-68", "ner": [[5, 8, "field"], [12, 15, "conference"], [18, 26, "conference"], [29, 29, "conference"], [32, 32, "conference"], [40, 42, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 15, 5, 8, "topic", "", false, false], [12, 15, 40, 42, "topic", "", false, false], [18, 26, 5, 8, "topic", "", false, false], [18, 26, 40, 42, "topic", "", false, false], [29, 29, 5, 8, "topic", "", false, false], [29, 29, 40, 42, "topic", "", false, false], [32, 32, 5, 8, "topic", "", false, false], [32, 32, 40, 42, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Le", "conferenze", "nel", "campo", "dell'", "elaborazione", "del", "linguaggio", "naturale", ",", "come", "l'", "Association", "for", "Computational", "Linguistics", ",", "il", "North", "American", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "l'", "EMNLP", "e", "l'", "HLT", ",", "stanno", "iniziando", "a", "includere", "articoli", "sull'", "elaborazione", "del", "parlato", "."], "sentence-detokenized": "Le conferenze nel campo dell'elaborazione del linguaggio naturale, come l'Association for Computational Linguistics, il North American Chapter of the Association for Computational Linguistics, l'EMNLP e l'HLT, stanno iniziando a includere articoli sull'elaborazione del parlato.", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 23], [24, 29], [29, 41], [42, 45], [46, 56], [57, 65], [65, 66], [67, 71], [72, 74], [74, 85], [86, 89], [90, 103], [104, 115], [115, 116], [117, 119], [120, 125], [126, 134], [135, 142], [143, 145], [146, 149], [150, 161], [162, 165], [166, 179], [180, 191], [191, 192], [193, 195], [195, 200], [201, 202], [203, 205], [205, 208], [208, 209], [210, 216], [217, 226], [227, 228], [229, 238], [239, 247], [248, 253], [253, 265], [266, 269], [270, 277], [277, 278]]}
{"doc_key": "ai-test-69", "ner": [[4, 4, "programlang"], [24, 26, "misc"], [40, 42, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Una", "serie", "di", "programmi", "Java", "utilizza", "il", "lessico", "per", "analizzare", "le", "variazioni", "nei", "testi", "biomedici", "mettendo", "in", "relazione", "le", "parole", "in", "base", "alle", "loro", "parti", "del", "discorso", ",", "il", "che", "pu\u00f2", "essere", "utile", "nelle", "ricerche", "sul", "Web", "o", "in", "una", "cartella", "clinica", "elettronica", "."], "sentence-detokenized": "Una serie di programmi Java utilizza il lessico per analizzare le variazioni nei testi biomedici mettendo in relazione le parole in base alle loro parti del discorso, il che pu\u00f2 essere utile nelle ricerche sul Web o in una cartella clinica elettronica.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 22], [23, 27], [28, 36], [37, 39], [40, 47], [48, 51], [52, 62], [63, 65], [66, 76], [77, 80], [81, 86], [87, 96], [97, 105], [106, 108], [109, 118], [119, 121], [122, 128], [129, 131], [132, 136], [137, 141], [142, 146], [147, 152], [153, 156], [157, 165], [165, 166], [167, 169], [170, 173], [174, 177], [178, 184], [185, 190], [191, 196], [197, 205], [206, 209], [210, 213], [214, 215], [216, 218], [219, 222], [223, 231], [232, 239], [240, 251], [251, 252]]}
{"doc_key": "ai-test-70", "ner": [[7, 7, "algorithm"], [9, 9, "algorithm"], [11, 11, "algorithm"], [13, 13, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Esistono", "molti", "algoritmi", "pi\u00f9", "recenti", ",", "come", "LPBoost", ",", "TotalBoost", ",", "BrownBoost", ",", "xgboost", ",", "MadaBoost", "e", "altri", "."], "sentence-detokenized": "Esistono molti algoritmi pi\u00f9 recenti, come LPBoost, TotalBoost, BrownBoost, xgboost, MadaBoost e altri.", "token2charspan": [[0, 8], [9, 14], [15, 24], [25, 28], [29, 36], [36, 37], [38, 42], [43, 50], [50, 51], [52, 62], [62, 63], [64, 74], [74, 75], [76, 83], [83, 84], [85, 94], [95, 96], [97, 102], [102, 103]]}
{"doc_key": "ai-test-71", "ner": [[7, 7, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Questo", "\u00e8", "un", "esempio", "di", "implementazione", "in", "Python", ":"], "sentence-detokenized": "Questo \u00e8 un esempio di implementazione in Python:", "token2charspan": [[0, 6], [7, 8], [9, 11], [12, 19], [20, 22], [23, 38], [39, 41], [42, 48], [48, 49]]}
{"doc_key": "ai-test-72", "ner": [[4, 4, "organisation"], [5, 6, "product"], [11, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 4, 4, "artifact", "made_by_company", false, false], [11, 13, 5, 6, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "console", "di", "gioco", "Mattel", "Intellivision", "ha", "offerto", "il", "modulo", "di", "sintesi", "vocale", "Intellivoice", "nel", "1982", "."], "sentence-detokenized": "La console di gioco Mattel Intellivision ha offerto il modulo di sintesi vocale Intellivoice nel 1982.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 19], [20, 26], [27, 40], [41, 43], [44, 51], [52, 54], [55, 61], [62, 64], [65, 72], [73, 79], [80, 92], [93, 96], [97, 101], [101, 102]]}
{"doc_key": "ai-test-73", "ner": [[5, 6, "task"], [10, 17, "task"], [20, 21, "field"], [24, 26, "task"], [30, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 17, 5, 6, "part-of", "", false, false], [20, 21, 5, 6, "part-of", "", false, false], [24, 26, 5, 6, "part-of", "", false, false], [30, 35, 24, 26, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Si", "\u00e8", "occupato", "anche", "di", "traduzione", "automatica", ",", "sia", "di", "traduzione", "automatica", "ad", "alta", "precisione", "basata", "sulla", "conoscenza", "che", "di", "apprendimento", "automatico", "per", "la", "traduzione", "automatica", "statistica", "(", "come", "la", "traduzione", "automatica", "basata", "su", "esempi", "generalizzati", ")", "."], "sentence-detokenized": "Si \u00e8 occupato anche di traduzione automatica, sia di traduzione automatica ad alta precisione basata sulla conoscenza che di apprendimento automatico per la traduzione automatica statistica (come la traduzione automatica basata su esempi generalizzati).", "token2charspan": [[0, 2], [3, 4], [5, 13], [14, 19], [20, 22], [23, 33], [34, 44], [44, 45], [46, 49], [50, 52], [53, 63], [64, 74], [75, 77], [78, 82], [83, 93], [94, 100], [101, 106], [107, 117], [118, 121], [122, 124], [125, 138], [139, 149], [150, 153], [154, 156], [157, 167], [168, 178], [179, 189], [190, 191], [191, 195], [196, 198], [199, 209], [210, 220], [221, 227], [228, 230], [231, 237], [238, 251], [251, 252], [252, 253]]}
{"doc_key": "ai-test-74", "ner": [[0, 1, "misc"], [5, 5, "misc"], [26, 27, "algorithm"], [30, 31, "field"], [34, 36, "field"], [39, 39, "field"], [42, 44, "field"], [47, 47, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 26, 27, "general-affiliation", "", false, false], [0, 1, 30, 31, "general-affiliation", "", false, false], [0, 1, 34, 36, "general-affiliation", "", false, false], [0, 1, 39, 39, "general-affiliation", "", false, false], [0, 1, 42, 44, "general-affiliation", "", false, false], [0, 1, 47, 47, "general-affiliation", "", false, false], [5, 5, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Wolfram", "Mathematica", "(", "solitamente", "chiamato", "Mathematica", ")", "\u00e8", "un", "moderno", "sistema", "di", "calcolo", "tecnico", "che", "abbraccia", "la", "maggior", "parte", "delle", "aree", "tecniche", ",", "tra", "cui", "le", "reti", "neurali", ",", "l'", "apprendimento", "automatico", ",", "l'", "elaborazione", "delle", "immagini", ",", "la", "geometria", ",", "la", "scienza", "dei", "dati", ",", "le", "visualizzazioni", "e", "altre", "ancora", "."], "sentence-detokenized": "Wolfram Mathematica (solitamente chiamato Mathematica) \u00e8 un moderno sistema di calcolo tecnico che abbraccia la maggior parte delle aree tecniche, tra cui le reti neurali, l'apprendimento automatico, l'elaborazione delle immagini, la geometria, la scienza dei dati, le visualizzazioni e altre ancora.", "token2charspan": [[0, 7], [8, 19], [20, 21], [21, 32], [33, 41], [42, 53], [53, 54], [55, 56], [57, 59], [60, 67], [68, 75], [76, 78], [79, 86], [87, 94], [95, 98], [99, 108], [109, 111], [112, 119], [120, 125], [126, 131], [132, 136], [137, 145], [145, 146], [147, 150], [151, 154], [155, 157], [158, 162], [163, 170], [170, 171], [172, 174], [174, 187], [188, 198], [198, 199], [200, 202], [202, 214], [215, 220], [221, 229], [229, 230], [231, 233], [234, 243], [243, 244], [245, 247], [248, 255], [256, 259], [260, 264], [264, 265], [266, 268], [269, 284], [285, 286], [287, 292], [293, 299], [299, 300]]}
{"doc_key": "ai-test-75", "ner": [[2, 6, "product"], [10, 11, "researcher"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 17, 2, 6, "type-of", "", false, false], [17, 17, 10, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Il", "primo", "robot", "programmabile", "e", "azionato", "digitalmente", "fu", "inventato", "da", "George", "Devol", "nel", "1954", "e", "fu", "chiamato", "Unimate", "."], "sentence-detokenized": "Il primo robot programmabile e azionato digitalmente fu inventato da George Devol nel 1954 e fu chiamato Unimate.", "token2charspan": [[0, 2], [3, 8], [9, 14], [15, 28], [29, 30], [31, 39], [40, 52], [53, 55], [56, 65], [66, 68], [69, 75], [76, 81], [82, 85], [86, 90], [91, 92], [93, 95], [96, 104], [105, 112], [112, 113]]}
{"doc_key": "ai-test-76", "ner": [[2, 2, "algorithm"], [4, 5, "algorithm"], [19, 21, "task"], [24, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 2, 4, 5, "compare", "", false, false], [4, 5, 19, 21, "general-affiliation", "", false, false], [4, 5, 24, 25, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Come", "i", "DBN", ",", "i", "DBM", "possono", "apprendere", "rappresentazioni", "interne", "complesse", "e", "astratte", "dell'", "input", "in", "compiti", "come", "il", "riconoscimento", "di", "oggetti", "o", "il", "riconoscimento", "vocale", ",", "utilizzando", "dati", "limitati", "ed", "etichettati", "per", "mettere", "a", "punto", "le", "rappresentazioni", "costruite", "utilizzando", "un", "ampio", "insieme", "di", "dati", "sensoriali", "in", "ingresso", "non", "etichettati", "."], "sentence-detokenized": "Come i DBN, i DBM possono apprendere rappresentazioni interne complesse e astratte dell'input in compiti come il riconoscimento di oggetti o il riconoscimento vocale, utilizzando dati limitati ed etichettati per mettere a punto le rappresentazioni costruite utilizzando un ampio insieme di dati sensoriali in ingresso non etichettati.", "token2charspan": [[0, 4], [5, 6], [7, 10], [10, 11], [12, 13], [14, 17], [18, 25], [26, 36], [37, 53], [54, 61], [62, 71], [72, 73], [74, 82], [83, 88], [88, 93], [94, 96], [97, 104], [105, 109], [110, 112], [113, 127], [128, 130], [131, 138], [139, 140], [141, 143], [144, 158], [159, 165], [165, 166], [167, 178], [179, 183], [184, 192], [193, 195], [196, 207], [208, 211], [212, 219], [220, 221], [222, 227], [228, 230], [231, 247], [248, 257], [258, 269], [270, 272], [273, 278], [279, 286], [287, 289], [290, 294], [295, 305], [306, 308], [309, 317], [318, 321], [322, 333], [333, 334]]}
{"doc_key": "ai-test-77", "ner": [[10, 15, "task"], [17, 17, "conference"], [19, 19, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 17, 10, 15, "topic", "", false, false], [19, 19, 10, 15, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Le", "conferenze", "scientifiche", "in", "cui", "vengono", "spesso", "presentati", "lavori", "di", "riconoscimento", "delle", "attivit\u00e0", "basati", "sulla", "visione", "sono", "ICCV", "e", "CVPR."], "sentence-detokenized": "Le conferenze scientifiche in cui vengono spesso presentati lavori di riconoscimento delle attivit\u00e0 basati sulla visione sono ICCV e CVPR.", "token2charspan": [[0, 2], [3, 13], [14, 26], [27, 29], [30, 33], [34, 41], [42, 48], [49, 59], [60, 66], [67, 69], [70, 84], [85, 90], [91, 99], [100, 106], [107, 112], [113, 120], [121, 125], [126, 130], [131, 132], [133, 138]]}
{"doc_key": "ai-test-78", "ner": [[1, 1, "field"], [6, 8, "algorithm"], [10, 10, "algorithm"], [20, 21, "metrics"], [24, 26, "metrics"], [28, 28, "metrics"], [41, 42, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[6, 8, 1, 1, "part-of", "", false, false], [6, 8, 20, 21, "related-to", "finds", false, false], [6, 8, 24, 26, "related-to", "finds", false, false], [6, 8, 41, 42, "related-to", "", false, false], [10, 10, 6, 8, "named", "", false, false], [28, 28, 24, 26, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "statistica", ",", "l'", "algoritmo", "di", "massimizzazione", "dell'", "aspettativa", "(", "EM", ")", "\u00e8", "un", "metodo", "iterativo", "per", "trovare", "stime", "di", "massima", "verosimiglianza", "o", "di", "massima", "a", "posteriori", "(", "MAP", ")", "dei", "parametri", "nei", "modelli", "statistici", ",", "dove", "il", "modello", "dipende", "da", "variabili", "latenti", "non", "osservate", "."], "sentence-detokenized": "In statistica, l'algoritmo di massimizzazione dell'aspettativa (EM) \u00e8 un metodo iterativo per trovare stime di massima verosimiglianza o di massima a posteriori (MAP) dei parametri nei modelli statistici, dove il modello dipende da variabili latenti non osservate.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 17], [17, 26], [27, 29], [30, 45], [46, 51], [51, 62], [63, 64], [64, 66], [66, 67], [68, 69], [70, 72], [73, 79], [80, 89], [90, 93], [94, 101], [102, 107], [108, 110], [111, 118], [119, 134], [135, 136], [137, 139], [140, 147], [148, 149], [150, 160], [161, 162], [162, 165], [165, 166], [167, 170], [171, 180], [181, 184], [185, 192], [193, 203], [203, 204], [205, 209], [210, 212], [213, 220], [221, 228], [229, 231], [232, 241], [242, 249], [250, 253], [254, 263], [263, 264]]}
{"doc_key": "ai-test-79", "ner": [[10, 13, "metrics"], [15, 15, "metrics"], [19, 22, "metrics"], [24, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 15, 10, 13, "named", "", false, false], [24, 24, 19, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Allo", "stesso", "modo", ",", "gli", "sperimentatori", "a", "volte", "riportano", "il", "tasso", "di", "positivit\u00e0", "FALSA", "(", "FPR", ")", "e", "il", "tasso", "di", "negativit\u00e0", "FALSA", "(", "FNR", ")", "."], "sentence-detokenized": "Allo stesso modo, gli sperimentatori a volte riportano il tasso di positivit\u00e0 FALSA (FPR) e il tasso di negativit\u00e0 FALSA (FNR).", "token2charspan": [[0, 4], [5, 11], [12, 16], [16, 17], [18, 21], [22, 36], [37, 38], [39, 44], [45, 54], [55, 57], [58, 63], [64, 66], [67, 77], [78, 83], [84, 85], [85, 88], [88, 89], [90, 91], [92, 94], [95, 100], [101, 103], [104, 114], [115, 120], [121, 122], [122, 125], [125, 126], [126, 127]]}
{"doc_key": "ai-test-80", "ner": [[5, 8, "metrics"], [11, 11, "field"], [14, 16, "metrics"], [19, 20, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 5, 8, "usage", "", false, false], [19, 20, 14, 16, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Il", "concetto", "\u00e8", "simile", "al", "rapporto", "segnale", "/", "rumore", "utilizzato", "nelle", "scienze", "e", "alla", "matrice", "di", "confusione", "utilizzata", "nell'", "intelligenza", "artificiale", "."], "sentence-detokenized": "Il concetto \u00e8 simile al rapporto segnale/rumore utilizzato nelle scienze e alla matrice di confusione utilizzata nell'intelligenza artificiale.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 20], [21, 23], [24, 32], [33, 40], [40, 41], [41, 47], [48, 58], [59, 64], [65, 72], [73, 74], [75, 79], [80, 87], [88, 90], [91, 101], [102, 112], [113, 118], [118, 130], [131, 142], [142, 143]]}
{"doc_key": "ai-test-81", "ner": [[4, 5, "field"], [10, 11, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"], [30, 33, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 10, 11, "general-affiliation", "", false, false], [4, 5, 17, 18, "general-affiliation", "", false, false], [4, 5, 20, 21, "general-affiliation", "", false, false], [30, 33, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Il", "Codice", "Etico", "sull'", "Aumento", "Umano", ",", "originariamente", "introdotto", "da", "Steve", "Mann", "nel", "2004", "e", "perfezionato", "con", "Ray", "Kurzweil", "e", "Marvin", "Minsky", "nel", "2013", ",", "\u00e8", "stato", "infine", "ratificato", "alla", "conferenza", "Virtual", "Reality", "Toronto", "il", "25", "giugno", "2017", "."], "sentence-detokenized": "Il Codice Etico sull'Aumento Umano, originariamente introdotto da Steve Mann nel 2004 e perfezionato con Ray Kurzweil e Marvin Minsky nel 2013, \u00e8 stato infine ratificato alla conferenza Virtual Reality Toronto il 25 giugno 2017.", "token2charspan": [[0, 2], [3, 9], [10, 15], [16, 21], [21, 28], [29, 34], [34, 35], [36, 51], [52, 62], [63, 65], [66, 71], [72, 76], [77, 80], [81, 85], [86, 87], [88, 100], [101, 104], [105, 108], [109, 117], [118, 119], [120, 126], [127, 133], [134, 137], [138, 142], [142, 143], [144, 145], [146, 151], [152, 158], [159, 169], [170, 174], [175, 185], [186, 193], [194, 201], [202, 209], [210, 212], [213, 215], [216, 222], [223, 227], [227, 228]]}
{"doc_key": "ai-test-82", "ner": [[3, 5, "person"], [11, 12, "organisation"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 11, 12, "role", "directed_for", false, false], [3, 5, 18, 19, "role", "collaborator", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Nel", "1913", ",", "Walter", "R.", "Booth", "diresse", "10", "film", "per", "la", "U.K.", "Kinoplastikon", ",", "presumibilmente", "in", "collaborazione", "con", "Cecil", "Hepworth", "."], "sentence-detokenized": "Nel 1913, Walter R. Booth diresse 10 film per la U.K. Kinoplastikon, presumibilmente in collaborazione con Cecil Hepworth.", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 16], [17, 19], [20, 25], [26, 33], [34, 36], [37, 41], [42, 45], [46, 48], [49, 53], [54, 67], [67, 68], [69, 84], [85, 87], [88, 102], [103, 106], [107, 112], [113, 121], [121, 122]]}
{"doc_key": "ai-test-83", "ner": [[16, 16, "location"], [13, 14, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 14, 16, 16, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Il", "nuovo", "robot", "fu", "presentato", "nel", "1961", "in", "occasione", "di", "una", "fiera", "al", "Cow", "Palace", "di", "Chicago", "."], "sentence-detokenized": "Il nuovo robot fu presentato nel 1961 in occasione di una fiera al Cow Palace di Chicago.", "token2charspan": [[0, 2], [3, 8], [9, 14], [15, 17], [18, 28], [29, 32], [33, 37], [38, 40], [41, 50], [51, 53], [54, 57], [58, 63], [64, 66], [67, 70], [71, 77], [78, 80], [81, 88], [88, 89]]}
{"doc_key": "ai-test-84", "ner": [[4, 4, "product"], [9, 11, "task"], [15, 18, "field"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 9, 11, "usage", "", false, false], [4, 4, 15, 18, "usage", "", false, false], [4, 4, 22, 23, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Mentre", "alcune", "applicazioni", "di", "chatbot", "utilizzano", "ampi", "processi", "di", "classificazione", "delle", "parole", ",", "processori", "di", "elaborazione", "del", "linguaggio", "naturale", "e", "una", "sofisticata", "intelligenza", "artificiale", ",", "altre", "si", "limitano", "a", "scansionare", "parole", "chiave", "generiche", "e", "a", "generare", "risposte", "utilizzando", "frasi", "comuni", "ottenute", "da", "una", "libreria", "o", "da", "un", "database", "associato", "."], "sentence-detokenized": "Mentre alcune applicazioni di chatbot utilizzano ampi processi di classificazione delle parole, processori di elaborazione del linguaggio naturale e una sofisticata intelligenza artificiale, altre si limitano a scansionare parole chiave generiche e a generare risposte utilizzando frasi comuni ottenute da una libreria o da un database associato.", "token2charspan": [[0, 6], [7, 13], [14, 26], [27, 29], [30, 37], [38, 48], [49, 53], [54, 62], [63, 65], [66, 81], [82, 87], [88, 94], [94, 95], [96, 106], [107, 109], [110, 122], [123, 126], [127, 137], [138, 146], [147, 148], [149, 152], [153, 164], [165, 177], [178, 189], [189, 190], [191, 196], [197, 199], [200, 208], [209, 210], [211, 222], [223, 229], [230, 236], [237, 246], [247, 248], [249, 250], [251, 259], [260, 268], [269, 280], [281, 286], [287, 293], [294, 302], [303, 305], [306, 309], [310, 318], [319, 320], [321, 323], [324, 326], [327, 335], [336, 345], [345, 346]]}
{"doc_key": "ai-test-85", "ner": [[2, 2, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Il", "modello", "WaveNet", "proposto", "nel", "2016", "ottiene", "ottime", "prestazioni", "sulla", "qualit\u00e0", "del", "parlato", "."], "sentence-detokenized": "Il modello WaveNet proposto nel 2016 ottiene ottime prestazioni sulla qualit\u00e0 del parlato.", "token2charspan": [[0, 2], [3, 10], [11, 18], [19, 27], [28, 31], [32, 36], [37, 44], [45, 51], [52, 63], [64, 69], [70, 77], [78, 81], [82, 89], [89, 90]]}
{"doc_key": "ai-test-86", "ner": [[6, 6, "product"], [9, 11, "misc"], [14, 18, "misc"], [21, 22, "misc"], [25, 28, "misc"], [30, 32, "organisation"], [34, 34, "organisation"], [36, 41, "organisation"], [43, 43, "organisation"], [45, 48, "organisation"], [50, 51, "organisation"], [53, 55, "organisation"], [57, 59, "organisation"], [62, 62, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[6, 6, 9, 11, "general-affiliation", "", false, false], [6, 6, 14, 18, "general-affiliation", "", false, false], [6, 6, 21, 22, "general-affiliation", "", false, false], [6, 6, 25, 28, "general-affiliation", "", false, false], [30, 32, 6, 6, "usage", "", false, false], [34, 34, 6, 6, "usage", "", false, false], [36, 41, 6, 6, "usage", "", false, false], [43, 43, 6, 6, "usage", "", false, false], [45, 48, 6, 6, "usage", "", false, false], [50, 51, 6, 6, "usage", "", false, false], [53, 55, 6, 6, "usage", "", false, false], [57, 59, 6, 6, "usage", "", false, false], [62, 62, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Organizzazioni", "note", "per", "l'", "utilizzo", "di", "ALE", "per", "la", "gestione", "delle", "emergenze", ",", "i", "soccorsi", "in", "caso", "di", "disastri", ",", "la", "comunicazione", "ordinaria", "o", "la", "risposta", "a", "situazioni", "straordinarie", ":", "Croce", "Rossa", "Americana", ",", "FEMA", ",", "squadre", "di", "assistenza", "medica", "per", "disastri", ",", "NATO", ",", "Federal", "Bureau", "of", "Investigation", ",", "Nazioni", "Unite", ",", "AT", "&", "T", ",", "Civil", "Air", "Patrol", ",", "(", "ARES", ")", "."], "sentence-detokenized": "Organizzazioni note per l'utilizzo di ALE per la gestione delle emergenze, i soccorsi in caso di disastri, la comunicazione ordinaria o la risposta a situazioni straordinarie: Croce Rossa Americana, FEMA, squadre di assistenza medica per disastri, NATO, Federal Bureau of Investigation, Nazioni Unite, AT & T, Civil Air Patrol, (ARES).", "token2charspan": [[0, 14], [15, 19], [20, 23], [24, 26], [26, 34], [35, 37], [38, 41], [42, 45], [46, 48], [49, 57], [58, 63], [64, 73], [73, 74], [75, 76], [77, 85], [86, 88], [89, 93], [94, 96], [97, 105], [105, 106], [107, 109], [110, 123], [124, 133], [134, 135], [136, 138], [139, 147], [148, 149], [150, 160], [161, 174], [174, 175], [176, 181], [182, 187], [188, 197], [197, 198], [199, 203], [203, 204], [205, 212], [213, 215], [216, 226], [227, 233], [234, 237], [238, 246], [246, 247], [248, 252], [252, 253], [254, 261], [262, 268], [269, 271], [272, 285], [285, 286], [287, 294], [295, 300], [300, 301], [302, 304], [305, 306], [307, 308], [308, 309], [310, 315], [316, 319], [320, 326], [326, 327], [328, 329], [329, 333], [333, 334], [334, 335]]}
{"doc_key": "ai-test-87", "ner": [[9, 11, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "questo", "caso", ",", "si", "utilizza", "per", "semplicit\u00e0", "il", "delta", "di", "Kronecker", "(", "cfr", ".", "la", "derivata", "di", "una", "funzione", "sigmoide", ",", "espressa", "tramite", "la", "funzione", "stessa", ")", "."], "sentence-detokenized": "In questo caso, si utilizza per semplicit\u00e0 il delta di Kronecker (cfr. la derivata di una funzione sigmoide, espressa tramite la funzione stessa).", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 18], [19, 27], [28, 31], [32, 42], [43, 45], [46, 51], [52, 54], [55, 64], [65, 66], [66, 69], [69, 70], [71, 73], [74, 82], [83, 85], [86, 89], [90, 98], [99, 107], [107, 108], [109, 117], [118, 125], [126, 128], [129, 137], [138, 144], [144, 145], [145, 146]]}
{"doc_key": "ai-test-88", "ner": [[12, 13, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "teoria", "si", "basa", "su", "fondamenti", "filosofici", "ed", "\u00e8", "stata", "fondata", "da", "Ray", "Solomonoff", "intorno", "al", "1960", ".", "Samuel", "Rathmanner", "e", "Marcus", "Hutter", "."], "sentence-detokenized": "La teoria si basa su fondamenti filosofici ed \u00e8 stata fondata da Ray Solomonoff intorno al 1960. Samuel Rathmanner e Marcus Hutter.", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 17], [18, 20], [21, 31], [32, 42], [43, 45], [46, 47], [48, 53], [54, 61], [62, 64], [65, 68], [69, 79], [80, 87], [88, 90], [91, 95], [95, 96], [97, 103], [104, 114], [115, 116], [117, 123], [124, 130], [130, 131]]}
{"doc_key": "ai-test-89", "ner": [[0, 0, "product"], [11, 12, "misc"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 12, "type-of", "", false, false], [0, 0, 15, 16, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["WordNet", ",", "un", "database", "liberamente", "disponibile", ",", "originariamente", "concepito", "come", "una", "rete", "semantica", "basata", "su", "principi", "psicolinguistici", ",", "\u00e8", "stato", "ampliato", "con", "l'", "aggiunta", "di", "definizioni", "ed", "\u00e8", "ora", "visto", "anche", "come", "un", "dizionario", "."], "sentence-detokenized": "WordNet, un database liberamente disponibile, originariamente concepito come una rete semantica basata su principi psicolinguistici, \u00e8 stato ampliato con l'aggiunta di definizioni ed \u00e8 ora visto anche come un dizionario.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 20], [21, 32], [33, 44], [44, 45], [46, 61], [62, 71], [72, 76], [77, 80], [81, 85], [86, 95], [96, 102], [103, 105], [106, 114], [115, 131], [131, 132], [133, 134], [135, 140], [141, 149], [150, 153], [154, 156], [156, 164], [165, 167], [168, 179], [180, 182], [183, 184], [185, 188], [189, 194], [195, 200], [201, 205], [206, 208], [209, 219], [219, 220]]}
{"doc_key": "ai-test-90", "ner": [[7, 8, "field"], [20, 20, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 20, 7, 8, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["I", "progressi", "nel", "campo", "della", "ricerca", "sull'", "imaging", "computazionale", "sono", "presentati", "in", "diverse", "sedi", ",", "tra", "cui", "le", "pubblicazioni", "del", "SIGGRAPH", "e", "del", "Congresso", "."], "sentence-detokenized": "I progressi nel campo della ricerca sull'imaging computazionale sono presentati in diverse sedi, tra cui le pubblicazioni del SIGGRAPH e del Congresso.", "token2charspan": [[0, 1], [2, 11], [12, 15], [16, 21], [22, 27], [28, 35], [36, 41], [41, 48], [49, 63], [64, 68], [69, 79], [80, 82], [83, 90], [91, 95], [95, 96], [97, 100], [101, 104], [105, 107], [108, 121], [122, 125], [126, 134], [135, 136], [137, 140], [141, 150], [150, 151]]}
{"doc_key": "ai-test-91", "ner": [[0, 1, "task"], [11, 12, "task"], [15, 16, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 0, 1, "part-of", "", false, false], [15, 16, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "classificazione", "pu\u00f2", "essere", "considerata", "come", "due", "problemi", "distinti", ":", "la", "classificazione", "binaria", "e", "la", "classificazione", "multiclasse", "."], "sentence-detokenized": "La classificazione pu\u00f2 essere considerata come due problemi distinti: la classificazione binaria e la classificazione multiclasse.", "token2charspan": [[0, 2], [3, 18], [19, 22], [23, 29], [30, 41], [42, 46], [47, 50], [51, 59], [60, 68], [68, 69], [70, 72], [73, 88], [89, 96], [97, 98], [99, 101], [102, 117], [118, 129], [129, 130]]}
{"doc_key": "ai-test-92", "ner": [[14, 15, "algorithm"], [22, 23, "algorithm"], [25, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 23, 14, 15, "type-of", "", false, false], [25, 25, 22, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["I", "cercatori", "di", "geni", "avanzati", "per", "i", "genomi", "procariotici", "ed", "eucariotici", "utilizzano", "in", "genere", "modelli", "probabilistici", "complessi", ",", "come", "i", "modelli", "di", "Markov", "nascosti", "(", "HMM", ")", ",", "per", "combinare", "le", "informazioni", "provenienti", "da", "una", "serie", "di", "diverse", "misure", "di", "segnale", "e", "di", "contenuto", "."], "sentence-detokenized": "I cercatori di geni avanzati per i genomi procariotici ed eucariotici utilizzano in genere modelli probabilistici complessi, come i modelli di Markov nascosti (HMM), per combinare le informazioni provenienti da una serie di diverse misure di segnale e di contenuto.", "token2charspan": [[0, 1], [2, 11], [12, 14], [15, 19], [20, 28], [29, 32], [33, 34], [35, 41], [42, 54], [55, 57], [58, 69], [70, 80], [81, 83], [84, 90], [91, 98], [99, 113], [114, 123], [123, 124], [125, 129], [130, 131], [132, 139], [140, 142], [143, 149], [150, 158], [159, 160], [160, 163], [163, 164], [164, 165], [166, 169], [170, 179], [180, 182], [183, 195], [196, 207], [208, 210], [211, 214], [215, 220], [221, 223], [224, 231], [232, 238], [239, 241], [242, 249], [250, 251], [252, 254], [255, 264], [264, 265]]}
{"doc_key": "ai-test-93", "ner": [[0, 1, "misc"], [4, 4, "misc"], [10, 11, "field"], [14, 15, "algorithm"], [18, 20, "algorithm"], [22, 22, "algorithm"], [32, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 10, 11, "part-of", "", false, false], [0, 1, 14, 15, "usage", "", false, false], [4, 4, 0, 1, "named", "", false, false], [18, 20, 0, 1, "origin", "", true, false], [22, 22, 18, 20, "named", "", false, false], [32, 33, 0, 1, "origin", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["La", "neuroevoluzione", ",", "o", "neuroevoluzione", ",", "\u00e8", "una", "forma", "di", "intelligenza", "artificiale", "che", "utilizza", "algoritmi", "evolutivi", "per", "generare", "reti", "neurali", "artificiali", "(", "RNA", ")", ",", "parametri", ",", "topologia", "e", "regole", ".", "e", "robotica", "evolutiva", "."], "sentence-detokenized": "La neuroevoluzione, o neuroevoluzione, \u00e8 una forma di intelligenza artificiale che utilizza algoritmi evolutivi per generare reti neurali artificiali (RNA), parametri, topologia e regole. e robotica evolutiva.", "token2charspan": [[0, 2], [3, 18], [18, 19], [20, 21], [22, 37], [37, 38], [39, 40], [41, 44], [45, 50], [51, 53], [54, 66], [67, 78], [79, 82], [83, 91], [92, 101], [102, 111], [112, 115], [116, 124], [125, 129], [130, 137], [138, 149], [150, 151], [151, 154], [154, 155], [155, 156], [157, 166], [166, 167], [168, 177], [178, 179], [180, 186], [186, 187], [188, 189], [190, 198], [199, 208], [208, 209]]}
{"doc_key": "ai-test-94", "ner": [[2, 2, "organisation"], [10, 10, "metrics"], [11, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 2, 2, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Da", "quando", "IBM", "ha", "proposto", "e", "realizzato", "il", "sistema", "di", "BLEU", "Papineni", "et", "al", "."], "sentence-detokenized": "Da quando IBM ha proposto e realizzato il sistema di BLEU Papineni et al.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 16], [17, 25], [26, 27], [28, 38], [39, 41], [42, 49], [50, 52], [53, 57], [58, 66], [67, 69], [70, 72], [72, 73]]}
{"doc_key": "ai-test-95", "ner": [[12, 18, "conference"], [20, 20, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 20, 12, 18, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Nel", "2009", ",", "gli", "esperti", "hanno", "partecipato", "a", "una", "conferenza", "organizzata", "dall'", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "per", "discutere", "se", "i", "computer", "e", "i", "robot", "potessero", "essere", "in", "grado", "di", "acquisire", "autonomia", "e", "quanto", "queste", "capacit\u00e0", "potessero", "rappresentare", "una", "minaccia", "o", "un", "pericolo", "."], "sentence-detokenized": "Nel 2009, gli esperti hanno partecipato a una conferenza organizzata dall'Association for the Advancement of Artificial Intelligence (AAAI) per discutere se i computer e i robot potessero essere in grado di acquisire autonomia e quanto queste capacit\u00e0 potessero rappresentare una minaccia o un pericolo.", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 13], [14, 21], [22, 27], [28, 39], [40, 41], [42, 45], [46, 56], [57, 68], [69, 74], [74, 85], [86, 89], [90, 93], [94, 105], [106, 108], [109, 119], [120, 132], [133, 134], [134, 138], [138, 139], [140, 143], [144, 153], [154, 156], [157, 158], [159, 167], [168, 169], [170, 171], [172, 177], [178, 187], [188, 194], [195, 197], [198, 203], [204, 206], [207, 216], [217, 226], [227, 228], [229, 235], [236, 242], [243, 251], [252, 261], [262, 275], [276, 279], [280, 288], [289, 290], [291, 293], [294, 302], [302, 303]]}
{"doc_key": "ai-test-96", "ner": [[30, 31, "researcher"], [33, 34, "researcher"], [36, 41, "task"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[36, 41, 30, 31, "artifact", "", false, false], [36, 41, 33, 34, "artifact", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["Dopo", "il", "boosting", ",", "un", "classificatore", "costruito", "da", "200", "caratteristiche", "potrebbe", "produrre", "un", "tasso", "di", "rilevamento", "del", "95", "%", "con", "un", "tasso", "di", "positivit\u00e0", "^", "{", "-", "5", "}", "/", "P.", "Viola", ",", "M.", "Jones", ",", "Robust", "Real", "-", "time", "Object", "Detection", ",", "2001", "."], "sentence-detokenized": "Dopo il boosting, un classificatore costruito da 200 caratteristiche potrebbe produrre un tasso di rilevamento del 95% con un tasso di positivit\u00e0 ^ {-5} / P. Viola, M. Jones, Robust Real-time Object Detection, 2001.", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 20], [21, 35], [36, 45], [46, 48], [49, 52], [53, 68], [69, 77], [78, 86], [87, 89], [90, 95], [96, 98], [99, 110], [111, 114], [115, 117], [117, 118], [119, 122], [123, 125], [126, 131], [132, 134], [135, 145], [146, 147], [148, 149], [149, 150], [150, 151], [151, 152], [153, 154], [155, 157], [158, 163], [163, 164], [165, 167], [168, 173], [173, 174], [175, 181], [182, 186], [186, 187], [187, 191], [192, 198], [199, 208], [208, 209], [210, 214], [214, 215]]}
{"doc_key": "ai-test-97", "ner": [[6, 6, "programlang"], [9, 9, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Il", "sito", "era", "originariamente", "basato", "su", "Perl", ",", "ma", "IMDb", "non", "rivela", "pi\u00f9", "quale", "software", "utilizza", "per", "motivi", "di", "sicurezza", "."], "sentence-detokenized": "Il sito era originariamente basato su Perl, ma IMDb non rivela pi\u00f9 quale software utilizza per motivi di sicurezza.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 27], [28, 34], [35, 37], [38, 42], [42, 43], [44, 46], [47, 51], [52, 55], [56, 62], [63, 66], [67, 72], [73, 81], [82, 90], [91, 94], [95, 101], [102, 104], [105, 114], [114, 115]]}
{"doc_key": "ai-test-98", "ner": [[6, 7, "researcher"], [9, 10, "researcher"], [12, 13, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "start-up", "\u00e8", "stata", "fondata", "da", "Demis", "Hassabis", ",", "Shane", "Legg", "e", "Mustafa", "Suleyman", "nel", "2010", "."], "sentence-detokenized": "La start-up \u00e8 stata fondata da Demis Hassabis, Shane Legg e Mustafa Suleyman nel 2010.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 19], [20, 27], [28, 30], [31, 36], [37, 45], [45, 46], [47, 52], [53, 57], [58, 59], [60, 67], [68, 76], [77, 80], [81, 85], [85, 86]]}
{"doc_key": "ai-test-99", "ner": [[1, 3, "misc"], [8, 10, "metrics"], [25, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 1, 3, "type-of", "", false, false], [25, 26, 1, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Due", "funzioni", "di", "perdita", "molto", "utilizzate", "sono", "l'", "errore", "quadratico", "medio", ",", "mathL", "(", "a", ")", "=", "a", "^", "2", "/", "math", ",", "e", "la", "perdita", "assoluta", ",", "mathL", "(", "a", ")", "=", "|", "a", "|", "/", "math", "."], "sentence-detokenized": "Due funzioni di perdita molto utilizzate sono l'errore quadratico medio, mathL (a) = a ^ 2 / math, e la perdita assoluta, mathL (a) = | a | / math.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 23], [24, 29], [30, 40], [41, 45], [46, 48], [48, 54], [55, 65], [66, 71], [71, 72], [73, 78], [79, 80], [80, 81], [81, 82], [83, 84], [85, 86], [87, 88], [89, 90], [91, 92], [93, 97], [97, 98], [99, 100], [101, 103], [104, 111], [112, 120], [120, 121], [122, 127], [128, 129], [129, 130], [130, 131], [132, 133], [134, 135], [136, 137], [138, 139], [140, 141], [142, 146], [146, 147]]}
{"doc_key": "ai-test-100", "ner": [[0, 4, "algorithm"], [14, 17, "algorithm"], [19, 19, "algorithm"], [23, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 4, 14, 17, "type-of", "example_of", false, false], [14, 17, 23, 25, "related-to", "", false, false], [19, 19, 14, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "macchina", "vettoriale", "di", "supporto", "soft", "-", "margin", "descritta", "sopra", "\u00e8", "un", "esempio", "di", "minimizzazione", "empirica", "del", "rischio", "(", "ERM", ")", "per", "la", "perdita", "della", "cerniera", "."], "sentence-detokenized": "La macchina vettoriale di supporto soft-margin descritta sopra \u00e8 un esempio di minimizzazione empirica del rischio (ERM) per la perdita della cerniera.", "token2charspan": [[0, 2], [3, 11], [12, 22], [23, 25], [26, 34], [35, 39], [39, 40], [40, 46], [47, 56], [57, 62], [63, 64], [65, 67], [68, 75], [76, 78], [79, 93], [94, 102], [103, 106], [107, 114], [115, 116], [116, 119], [119, 120], [121, 124], [125, 127], [128, 135], [136, 141], [142, 150], [150, 151]]}
{"doc_key": "ai-test-101", "ner": [[7, 8, "field"], [3, 4, "task"], [11, 13, "task"], [22, 22, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 13, 7, 8, "origin", "", false, false], [11, 13, 3, 4, "type-of", "", false, false], [22, 22, 11, 13, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Un", "approccio", "alla", "traduzione", "automatica", "basato", "sull'", "apprendimento", "profondo", ",", "la", "traduzione", "automatica", "neurale", "ha", "compiuto", "rapidi", "progressi", "negli", "ultimi", "anni", "e", "Google", "ha", "annunciato", "che", "i", "suoi", "servizi", "di", "traduzione", "utilizzano", "ora", "questa", "tecnologia", "in", "sostituzione", "dei", "precedenti", "metodi", "statistici", "."], "sentence-detokenized": "Un approccio alla traduzione automatica basato sull'apprendimento profondo, la traduzione automatica neurale ha compiuto rapidi progressi negli ultimi anni e Google ha annunciato che i suoi servizi di traduzione utilizzano ora questa tecnologia in sostituzione dei precedenti metodi statistici.", "token2charspan": [[0, 2], [3, 12], [13, 17], [18, 28], [29, 39], [40, 46], [47, 52], [52, 65], [66, 74], [74, 75], [76, 78], [79, 89], [90, 100], [101, 108], [109, 111], [112, 120], [121, 127], [128, 137], [138, 143], [144, 150], [151, 155], [156, 157], [158, 164], [165, 167], [168, 178], [179, 182], [183, 184], [185, 189], [190, 197], [198, 200], [201, 211], [212, 222], [223, 226], [227, 233], [234, 244], [245, 247], [248, 260], [261, 264], [265, 275], [276, 282], [283, 293], [293, 294]]}
{"doc_key": "ai-test-102", "ner": [[17, 17, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ci\u00f2", "tende", "a", "produrre", "grandi", "guadagni", "di", "prestazioni", "quando", "si", "lavora", "con", "corpora", "di", "grandi", "dimensioni", "come", "WordNet."], "sentence-detokenized": "Ci\u00f2 tende a produrre grandi guadagni di prestazioni quando si lavora con corpora di grandi dimensioni come WordNet.", "token2charspan": [[0, 3], [4, 9], [10, 11], [12, 20], [21, 27], [28, 36], [37, 39], [40, 51], [52, 58], [59, 61], [62, 68], [69, 72], [73, 80], [81, 83], [84, 90], [91, 101], [102, 106], [107, 115]]}
{"doc_key": "ai-test-103", "ner": [[0, 3, "task"], [7, 7, "field"], [18, 21, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 18, 21, "part-of", "", false, false], [18, 21, 7, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Il", "rilevamento", "dei", "volti", "viene", "utilizzato", "nella", "biometria", ",", "spesso", "come", "parte", "(", "o", "insieme", ")", "a", "un", "sistema", "di", "riconoscimento", "facciale", "."], "sentence-detokenized": "Il rilevamento dei volti viene utilizzato nella biometria, spesso come parte (o insieme) a un sistema di riconoscimento facciale.", "token2charspan": [[0, 2], [3, 14], [15, 18], [19, 24], [25, 30], [31, 41], [42, 47], [48, 57], [57, 58], [59, 65], [66, 70], [71, 76], [77, 78], [78, 79], [80, 87], [87, 88], [89, 90], [91, 93], [94, 101], [102, 104], [105, 119], [120, 128], [128, 129]]}
{"doc_key": "ai-test-104", "ner": [[2, 5, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["addestrati", "mediante", "stima", "della", "massima", "verosimiglianza", "."], "sentence-detokenized": "addestrati mediante stima della massima verosimiglianza.", "token2charspan": [[0, 10], [11, 19], [20, 25], [26, 31], [32, 39], [40, 55], [55, 56]]}
{"doc_key": "ai-test-105", "ner": [[2, 2, "country"], [4, 8, "organisation"], [12, 12, "location"], [14, 14, "country"], [16, 19, "organisation"], [21, 21, "country"], [27, 27, "organisation"], [32, 35, "organisation"], [37, 37, "country"], [48, 52, "organisation"], [54, 54, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[4, 8, 12, 12, "physical", "", false, false], [12, 12, 14, 14, "physical", "", false, false], [16, 19, 21, 21, "physical", "", false, false], [32, 35, 37, 37, "physical", "", false, false], [48, 52, 54, 54, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Ltd.", "in", "Tailandia", ";", "Komatsu", "(", "Shanghai", ")", "Ltd.", "nel", "1996", "a", "Shanghai", ",", "Cina", ";", "Industrial", "Power", "Alliance", "Ltd.", "in", "Giappone", ",", "una", "joint", "venture", "con", "Cummins", ",", "nel", "1998", ";", "L", "&", "T-Komatsu", "Limited", "in", "India", "nel", "1998", "(", "azioni", "vendute", "nel", "2013", ")", ";", "e", "Komatsu", "Brasil", "International", "Ltda", ".", "in", "Brasile", "nel", "1998", "."], "sentence-detokenized": "Ltd. in Tailandia; Komatsu (Shanghai) Ltd. nel 1996 a Shanghai, Cina; Industrial Power Alliance Ltd. in Giappone, una joint venture con Cummins, nel 1998; L & T-Komatsu Limited in India nel 1998 (azioni vendute nel 2013); e Komatsu Brasil International Ltda. in Brasile nel 1998.", "token2charspan": [[0, 4], [5, 7], [8, 17], [17, 18], [19, 26], [27, 28], [28, 36], [36, 37], [38, 42], [43, 46], [47, 51], [52, 53], [54, 62], [62, 63], [64, 68], [68, 69], [70, 80], [81, 86], [87, 95], [96, 100], [101, 103], [104, 112], [112, 113], [114, 117], [118, 123], [124, 131], [132, 135], [136, 143], [143, 144], [145, 148], [149, 153], [153, 154], [155, 156], [157, 158], [159, 168], [169, 176], [177, 179], [180, 185], [186, 189], [190, 194], [195, 196], [196, 202], [203, 210], [211, 214], [215, 219], [219, 220], [220, 221], [222, 223], [224, 231], [232, 238], [239, 252], [253, 257], [257, 258], [259, 261], [262, 269], [270, 273], [274, 278], [278, 279]]}
{"doc_key": "ai-test-106", "ner": [[0, 1, "organisation"], [5, 7, "misc"], [13, 13, "misc"], [14, 15, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 15, 0, 1, "physical", "", false, false], [14, 15, 5, 7, "general-affiliation", "", false, false], [14, 15, 13, 13, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "dgp", "ospita", "occasionalmente", "anche", "artisti", "in", "residenza", "(", "ad", "esempio", "il", "premio", "Oscar", "Chris", "Landreth", ")", "."], "sentence-detokenized": "La dgp ospita occasionalmente anche artisti in residenza (ad esempio il premio Oscar Chris Landreth).", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 29], [30, 35], [36, 43], [44, 46], [47, 56], [57, 58], [58, 60], [61, 68], [69, 71], [72, 78], [79, 84], [85, 90], [91, 99], [99, 100], [100, 101]]}
{"doc_key": "ai-test-107", "ner": [[8, 10, "misc"], [13, 15, "misc"], [18, 21, "misc"], [25, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Attualmente", "comprende", "quattro", "sotto", "-", "competizioni", ":", "la", "RoboMaster", "Robotics", "Competition", ",", "la", "RoboMaster", "Technical", "Challenge", ",", "la", "ICRA", "RoboMaster", "AI", "Challenge", "e", "il", "nuovo", "RoboMaster", "Youth", "Tournament."], "sentence-detokenized": "Attualmente comprende quattro sotto-competizioni: la RoboMaster Robotics Competition, la RoboMaster Technical Challenge, la ICRA RoboMaster AI Challenge e il nuovo RoboMaster Youth Tournament.", "token2charspan": [[0, 11], [12, 21], [22, 29], [30, 35], [35, 36], [36, 48], [48, 49], [50, 52], [53, 63], [64, 72], [73, 84], [84, 85], [86, 88], [89, 99], [100, 109], [110, 119], [119, 120], [121, 123], [124, 128], [129, 139], [140, 142], [143, 152], [153, 154], [155, 157], [158, 163], [164, 174], [175, 180], [181, 192]]}
{"doc_key": "ai-test-108", "ner": [[9, 11, "field"], [18, 21, "algorithm"], [26, 27, "algorithm"], [30, 31, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 11, 26, 27, "usage", "", false, false], [9, 11, 30, 31, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["All'", "inizio", "degli", "anni", "2000", ",", "la", "strategia", "di", "elaborazione", "del", "parlato", "dominante", "ha", "iniziato", "a", "spostarsi", "dal", "modello", "di", "Markov", "nascosto", "verso", "le", "pi\u00f9", "moderne", "reti", "neurali", "e", "il", "deep", "learning", "."], "sentence-detokenized": "All'inizio degli anni 2000, la strategia di elaborazione del parlato dominante ha iniziato a spostarsi dal modello di Markov nascosto verso le pi\u00f9 moderne reti neurali e il deep learning.", "token2charspan": [[0, 4], [4, 10], [11, 16], [17, 21], [22, 26], [26, 27], [28, 30], [31, 40], [41, 43], [44, 56], [57, 60], [61, 68], [69, 78], [79, 81], [82, 90], [91, 92], [93, 102], [103, 106], [107, 114], [115, 117], [118, 124], [125, 133], [134, 139], [140, 142], [143, 146], [147, 154], [155, 159], [160, 167], [168, 169], [170, 172], [173, 177], [178, 186], [186, 187]]}
{"doc_key": "ai-test-109", "ner": [[9, 11, "misc"], [16, 18, "metrics"], [21, 23, "metrics"], [30, 32, "metrics"], [35, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[16, 18, 21, 23, "related-to", "equal", false, false], [30, 32, 35, 37, "related-to", "equal", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Un'", "altra", "espressione", "equivalente", ",", "nel", "caso", "di", "un", "tasso", "target", "binario", ",", "\u00e8", "che", "il", "tasso", "positivo", "VERO", "e", "il", "tasso", "positivo", "FALSO", "sono", "uguali", "(", "e", "quindi", "il", "tasso", "negativo", "FALSO", "e", "il", "tasso", "negativo", "VERO", "sono", "uguali", ")", "per", "ogni", "valore", "delle", "caratteristiche", "sensibili", ":"], "sentence-detokenized": "Un'altra espressione equivalente, nel caso di un tasso target binario, \u00e8 che il tasso positivo VERO e il tasso positivo FALSO sono uguali (e quindi il tasso negativo FALSO e il tasso negativo VERO sono uguali) per ogni valore delle caratteristiche sensibili:", "token2charspan": [[0, 3], [3, 8], [9, 20], [21, 32], [32, 33], [34, 37], [38, 42], [43, 45], [46, 48], [49, 54], [55, 61], [62, 69], [69, 70], [71, 72], [73, 76], [77, 79], [80, 85], [86, 94], [95, 99], [100, 101], [102, 104], [105, 110], [111, 119], [120, 125], [126, 130], [131, 137], [138, 139], [139, 140], [141, 147], [148, 150], [151, 156], [157, 165], [166, 171], [172, 173], [174, 176], [177, 182], [183, 191], [192, 196], [197, 201], [202, 208], [208, 209], [210, 213], [214, 218], [219, 225], [226, 231], [232, 247], [248, 257], [257, 258]]}
{"doc_key": "ai-test-110", "ner": [[2, 2, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "funzione", "MATLAB", ","], "sentence-detokenized": "La funzione MATLAB,", "token2charspan": [[0, 2], [3, 11], [12, 18], [18, 19]]}
{"doc_key": "ai-test-111", "ner": [[1, 2, "product"], [7, 8, "misc"], [19, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 1, 2, "part-of", "", false, false], [19, 20, 1, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Un", "robot", "articolato", "\u00e8", "un", "robot", "con", "giunti", "rotanti", "(", "ad", "esempio", ",", "un", "robot", "con", "gambe", "o", "un", "robot", "industriale", ")", "."], "sentence-detokenized": "Un robot articolato \u00e8 un robot con giunti rotanti (ad esempio, un robot con gambe o un robot industriale).", "token2charspan": [[0, 2], [3, 8], [9, 19], [20, 21], [22, 24], [25, 30], [31, 34], [35, 41], [42, 49], [50, 51], [51, 53], [54, 61], [61, 62], [63, 65], [66, 71], [72, 75], [76, 81], [82, 83], [84, 86], [87, 92], [93, 104], [104, 105], [105, 106]]}
{"doc_key": "ai-test-112", "ner": [[0, 0, "product"], [5, 6, "product"], [8, 9, "product"], [14, 14, "misc"], [23, 26, "product"], [30, 32, "misc"], [37, 37, "location"], [40, 40, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 14, 14, "general-affiliation", "nationality", false, false], [0, 0, 30, 32, "usage", "", false, false], [0, 0, 37, 37, "physical", "", false, false], [5, 6, 0, 0, "named", "", false, false], [8, 9, 0, 0, "named", "", false, false], [37, 37, 40, 40, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pandora", "(", "nota", "anche", "come", "Pandora", "Media", "o", "Pandora", "Radio", ")", "\u00e8", "un", "servizio", "americano", "di", "streaming", "musicale", "e", "di", "radio", "internet", "con", "sistema", "di", "raccomandazione", "automatizzato", ",", "gestito", "dal", "Music", "Genome", "Project", "e", "con", "sede", "a", "Oakland", ",", "in", "California", "."], "sentence-detokenized": "Pandora (nota anche come Pandora Media o Pandora Radio) \u00e8 un servizio americano di streaming musicale e di radio internet con sistema di raccomandazione automatizzato, gestito dal Music Genome Project e con sede a Oakland, in California.", "token2charspan": [[0, 7], [8, 9], [9, 13], [14, 19], [20, 24], [25, 32], [33, 38], [39, 40], [41, 48], [49, 54], [54, 55], [56, 57], [58, 60], [61, 69], [70, 79], [80, 82], [83, 92], [93, 101], [102, 103], [104, 106], [107, 112], [113, 121], [122, 125], [126, 133], [134, 136], [137, 152], [153, 166], [166, 167], [168, 175], [176, 179], [180, 185], [186, 192], [193, 200], [201, 202], [203, 206], [207, 211], [212, 213], [214, 221], [221, 222], [223, 225], [226, 236], [236, 237]]}
{"doc_key": "ai-test-113", "ner": [[7, 10, "organisation"], [16, 19, "organisation"], [27, 28, "conference"], [44, 44, "conference"], [46, 46, "conference"], [48, 48, "conference"], [50, 50, "conference"], [52, 52, "conference"], [54, 54, "conference"], [56, 56, "conference"], [58, 58, "conference"], [60, 60, "conference"], [62, 62, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [], "relations_mapping_to_source": [], "sentence": ["\u00c8", "membro", "del", "consiglio", "di", "amministrazione", "della", "International", "Machine", "Learning", "Society", ",", "\u00e8", "stata", "membro", "del", "consiglio", "esecutivo", "dell'", "AAAI", ",", "\u00e8", "stata", "co", "-", "presidente", "dell'", "ICML", "2011", "e", "ha", "ricoperto", "il", "ruolo", "di", "membro", "senior", "del", "consiglio", "di", "amministrazione", "per", "conferenze", "quali", "AAAI", ",", "ICML", ",", "IJCAI", ",", "ISWC", ",", "KDD", ",", "SIGMOD", ",", "UAI", ",", "VLDB", ",", "WSDM", "e", "WWW."], "sentence-detokenized": "\u00c8 membro del consiglio di amministrazione della International Machine Learning Society, \u00e8 stata membro del consiglio esecutivo dell'AAAI, \u00e8 stata co-presidente dell'ICML 2011 e ha ricoperto il ruolo di membro senior del consiglio di amministrazione per conferenze quali AAAI, ICML, IJCAI, ISWC, KDD, SIGMOD, UAI, VLDB, WSDM e WWW.", "token2charspan": [[0, 1], [2, 8], [9, 12], [13, 22], [23, 25], [26, 41], [42, 47], [48, 61], [62, 69], [70, 78], [79, 86], [86, 87], [88, 89], [90, 95], [96, 102], [103, 106], [107, 116], [117, 126], [127, 132], [132, 136], [136, 137], [138, 139], [140, 145], [146, 148], [148, 149], [149, 159], [160, 165], [165, 169], [170, 174], [175, 176], [177, 179], [180, 189], [190, 192], [193, 198], [199, 201], [202, 208], [209, 215], [216, 219], [220, 229], [230, 232], [233, 248], [249, 252], [253, 263], [264, 269], [270, 274], [274, 275], [276, 280], [280, 281], [282, 287], [287, 288], [289, 293], [293, 294], [295, 298], [298, 299], [300, 306], [306, 307], [308, 311], [311, 312], [313, 317], [317, 318], [319, 323], [324, 325], [326, 330]]}
{"doc_key": "ai-test-114", "ner": [[0, 2, "researcher"], [4, 9, "organisation"], [11, 11, "organisation"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 4, 9, "role", "", false, false], [11, 11, 4, 9, "named", "", false, false], [16, 16, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["James", "S.", "Albus", "del", "National", "Institute", "of", "Standards", "and", "Technology", "(", "NIST", ")", "ha", "sviluppato", "la", "Robocrane", ",", "in", "cui", "la", "piattaforma", "pende", "da", "sei", "cavi", "invece", "di", "essere", "sostenuta", "da", "sei", "jack", "."], "sentence-detokenized": "James S. Albus del National Institute of Standards and Technology (NIST) ha sviluppato la Robocrane, in cui la piattaforma pende da sei cavi invece di essere sostenuta da sei jack.", "token2charspan": [[0, 5], [6, 8], [9, 14], [15, 18], [19, 27], [28, 37], [38, 40], [41, 50], [51, 54], [55, 65], [66, 67], [67, 71], [71, 72], [73, 75], [76, 86], [87, 89], [90, 99], [99, 100], [101, 103], [104, 107], [108, 110], [111, 122], [123, 128], [129, 131], [132, 135], [136, 140], [141, 147], [148, 150], [151, 157], [158, 167], [168, 170], [171, 174], [175, 179], [179, 180]]}
{"doc_key": "ai-test-115", "ner": [[4, 7, "algorithm"], [12, 13, "algorithm"], [18, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 13, 4, 7, "type-of", "", false, false], [18, 19, 12, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Un'", "altra", "classe", "di", "algoritmi", "di", "ricerca", "diretta", "\u00e8", "costituita", "dai", "vari", "algoritmi", "evolutivi", ",", "ad", "esempio", "gli", "algoritmi", "genetici", "."], "sentence-detokenized": "Un'altra classe di algoritmi di ricerca diretta \u00e8 costituita dai vari algoritmi evolutivi, ad esempio gli algoritmi genetici.", "token2charspan": [[0, 3], [3, 8], [9, 15], [16, 18], [19, 28], [29, 31], [32, 39], [40, 47], [48, 49], [50, 60], [61, 64], [65, 69], [70, 79], [80, 89], [89, 90], [91, 93], [94, 101], [102, 105], [106, 115], [116, 124], [124, 125]]}
{"doc_key": "ai-test-116", "ner": [[0, 0, "organisation"], [3, 4, "misc"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 0, 0, "named", "", false, false], [6, 7, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["KUKA", "\u00e8", "un", "produttore", "tedesco", "di", "robot", "industriali", "e", "di", "soluzioni", "per", "l'", "automazione", "di", "fabbrica", "."], "sentence-detokenized": "KUKA \u00e8 un produttore tedesco di robot industriali e di soluzioni per l'automazione di fabbrica.", "token2charspan": [[0, 4], [5, 6], [7, 9], [10, 20], [21, 28], [29, 31], [32, 37], [38, 49], [50, 51], [52, 54], [55, 64], [65, 68], [69, 71], [71, 82], [83, 85], [86, 94], [94, 95]]}
{"doc_key": "ai-test-117", "ner": [[11, 11, "misc"], [22, 23, "person"], [14, 20, "misc"], [27, 28, "person"], [25, 25, "misc"], [33, 34, "person"], [30, 31, "misc"], [40, 41, "person"], [36, 38, "misc"], [50, 52, "person"], [43, 48, "misc"], [57, 58, "person"], [54, 63, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[22, 23, 11, 11, "usage", "", false, false], [14, 20, 22, 23, "artifact", "", false, false], [27, 28, 11, 11, "usage", "", false, false], [25, 25, 27, 28, "artifact", "", false, false], [33, 34, 11, 11, "usage", "", false, false], [30, 31, 33, 34, "artifact", "", false, false], [40, 41, 11, 11, "usage", "", false, false], [36, 38, 40, 41, "artifact", "", false, false], [50, 52, 11, 11, "usage", "", false, false], [43, 48, 50, 52, "artifact", "", false, false], [57, 58, 11, 11, "usage", "", false, false], [54, 63, 57, 58, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Altri", "film", "tra", "il", "2016", "e", "il", "2020", "ripresi", "con", "telecamere", "IMAX", "sono", "stati", "Batman", "v", "Superman", ":", "Dawn", "of", "Justice", "di", "Zack", "Snyder", ",", "Sully", "di", "Clint", "Eastwood", ",", "First", "Man", "di", "Damien", "Chazelle", ",", "Wonder", "Woman", "1984", "di", "Patty", "Jenkins", ",", "Non", "c'", "\u00e8", "tempo", "per", "morire", "di", "Cary", "Joji", "Fukunaga", "e", "Top", "Gun", "di", "Joseph", "Kosinski", ":", "Maverick", "di", "Joseph", "Kosinski", "."], "sentence-detokenized": "Altri film tra il 2016 e il 2020 ripresi con telecamere IMAX sono stati Batman v Superman: Dawn of Justice di Zack Snyder, Sully di Clint Eastwood, First Man di Damien Chazelle, Wonder Woman 1984 di Patty Jenkins, Non c'\u00e8 tempo per morire di Cary Joji Fukunaga e Top Gun di Joseph Kosinski: Maverick di Joseph Kosinski.", "token2charspan": [[0, 5], [6, 10], [11, 14], [15, 17], [18, 22], [23, 24], [25, 27], [28, 32], [33, 40], [41, 44], [45, 55], [56, 60], [61, 65], [66, 71], [72, 78], [79, 80], [81, 89], [89, 90], [91, 95], [96, 98], [99, 106], [107, 109], [110, 114], [115, 121], [121, 122], [123, 128], [129, 131], [132, 137], [138, 146], [146, 147], [148, 153], [154, 157], [158, 160], [161, 167], [168, 176], [176, 177], [178, 184], [185, 190], [191, 195], [196, 198], [199, 204], [205, 212], [212, 213], [214, 217], [218, 220], [220, 221], [222, 227], [228, 231], [232, 238], [239, 241], [242, 246], [247, 251], [252, 260], [261, 262], [263, 266], [267, 270], [271, 273], [274, 280], [281, 289], [289, 290], [291, 299], [300, 302], [303, 309], [310, 318], [318, 319]]}
{"doc_key": "ai-test-118", "ner": [[4, 5, "misc"], [10, 12, "organisation"], [14, 14, "organisation"], [28, 28, "misc"], [34, 35, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 28, 28, "named", "", false, false], [10, 12, 4, 5, "usage", "", false, false], [10, 12, 34, 35, "physical", "", false, false], [14, 14, 10, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["La", "prova", "del", "carattere", "MICR", "E13B", "\u00e8", "stata", "mostrata", "all'", "American", "Bankers", "Association", "(", "ABA", ")", "nel", "luglio", "1956", ",", "che", "l'", "ha", "adottata", "nel", "1958", "come", "standard", "MICR", "per", "i", "documenti", "negoziabili", "negli", "Stati", "Uniti", "."], "sentence-detokenized": "La prova del carattere MICR E13B \u00e8 stata mostrata all'American Bankers Association (ABA) nel luglio 1956, che l'ha adottata nel 1958 come standard MICR per i documenti negoziabili negli Stati Uniti.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 22], [23, 27], [28, 32], [33, 34], [35, 40], [41, 49], [50, 54], [54, 62], [63, 70], [71, 82], [83, 84], [84, 87], [87, 88], [89, 92], [93, 99], [100, 104], [104, 105], [106, 109], [110, 112], [112, 114], [115, 123], [124, 127], [128, 132], [133, 137], [138, 146], [147, 151], [152, 155], [156, 157], [158, 167], [168, 179], [180, 185], [186, 191], [192, 197], [197, 198]]}
{"doc_key": "ai-test-119", "ner": [[0, 4, "misc"], [18, 18, "field"], [23, 24, "field"], [27, 27, "field"], [29, 30, "field"], [32, 32, "field"], [34, 34, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[18, 18, 0, 4, "usage", "", false, false], [23, 24, 18, 18, "part-of", "", false, false], [27, 27, 0, 4, "usage", "", false, false], [29, 30, 0, 4, "usage", "", false, false], [32, 32, 0, 4, "usage", "", false, false], [34, 34, 0, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gli", "algoritmi", "di", "ricerca", "locale", "sono", "ampiamente", "applicati", "a", "numerosi", "problemi", "computazionali", "difficili", ",", "tra", "cui", "problemi", "di", "informatica", "(", "in", "particolare", "di", "intelligenza", "artificiale", ")", ",", "matematica", ",", "ricerca", "operativa", ",", "ingegneria", "e", "bioinformatica", "."], "sentence-detokenized": "Gli algoritmi di ricerca locale sono ampiamente applicati a numerosi problemi computazionali difficili, tra cui problemi di informatica (in particolare di intelligenza artificiale), matematica, ricerca operativa, ingegneria e bioinformatica.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 24], [25, 31], [32, 36], [37, 47], [48, 57], [58, 59], [60, 68], [69, 77], [78, 92], [93, 102], [102, 103], [104, 107], [108, 111], [112, 120], [121, 123], [124, 135], [136, 137], [137, 139], [140, 151], [152, 154], [155, 167], [168, 179], [179, 180], [180, 181], [182, 192], [192, 193], [194, 201], [202, 211], [211, 212], [213, 223], [224, 225], [226, 240], [240, 241]]}
{"doc_key": "ai-test-120", "ner": [[0, 1, "researcher"], [9, 9, "location"], [11, 11, "country"], [16, 16, "country"], [23, 24, "algorithm"], [27, 27, "algorithm"], [29, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 9, 9, "physical", "", false, false], [0, 1, 16, 16, "general-affiliation", "nationality", false, false], [0, 1, 23, 24, "general-affiliation", "topic_of_study", false, false], [0, 1, 27, 27, "general-affiliation", "topic_of_study", false, false], [9, 9, 11, 11, "physical", "", false, false], [27, 27, 29, 30, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gerd", "Gigerenzer", "(", "nato", "il", "3", "settembre", "1947", "a", "Wallersdorf", ",", "Germania", ")", "\u00e8", "uno", "psicologo", "tedesco", "che", "ha", "studiato", "l'", "uso", "della", "razionalit\u00e0", "limitata", "e", "delle", "euristiche", "nel", "processo", "decisionale", "."], "sentence-detokenized": "Gerd Gigerenzer (nato il 3 settembre 1947 a Wallersdorf, Germania) \u00e8 uno psicologo tedesco che ha studiato l'uso della razionalit\u00e0 limitata e delle euristiche nel processo decisionale.", "token2charspan": [[0, 4], [5, 15], [16, 17], [17, 21], [22, 24], [25, 26], [27, 36], [37, 41], [42, 43], [44, 55], [55, 56], [57, 65], [65, 66], [67, 68], [69, 72], [73, 82], [83, 90], [91, 94], [95, 97], [98, 106], [107, 109], [109, 112], [113, 118], [119, 130], [131, 139], [140, 141], [142, 147], [148, 158], [159, 162], [163, 171], [172, 183], [183, 184]]}
{"doc_key": "ai-test-121", "ner": [[3, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["per", "minimizzare", "l'", "errore", "quadratico", "medio", "."], "sentence-detokenized": "per minimizzare l'errore quadratico medio.", "token2charspan": [[0, 3], [4, 15], [16, 18], [18, 24], [25, 35], [36, 41], [41, 42]]}
{"doc_key": "ai-test-122", "ner": [[12, 13, "misc"], [16, 17, "organisation"], [31, 34, "field"], [52, 53, "misc"], [61, 63, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 13, 16, 17, "origin", "", false, false], [52, 53, 61, 63, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Ma", "anche", "una", "lingua", "ufficiale", "con", "un'", "accademia", "regolatrice", ",", "come", "il", "francese", "standard", "con", "l'", "Acad\u00e9mie", "fran\u00e7aise", ",", "\u00e8", "classificata", "come", "lingua", "naturale", "(", "per", "esempio", ",", "nel", "campo", "dell'", "elaborazione", "del", "linguaggio", "naturale", ")", ",", "poich\u00e9", "i", "suoi", "punti", "prescrittivi", "non", "la", "rendono", "n\u00e9", "abbastanza", "costruita", "da", "essere", "classificata", "come", "lingua", "costruita", "n\u00e9", "abbastanza", "controllata", "da", "essere", "classificata", "come", "lingua", "naturale", "controllata", "."], "sentence-detokenized": "Ma anche una lingua ufficiale con un'accademia regolatrice, come il francese standard con l'Acad\u00e9mie fran\u00e7aise, \u00e8 classificata come lingua naturale (per esempio, nel campo dell'elaborazione del linguaggio naturale), poich\u00e9 i suoi punti prescrittivi non la rendono n\u00e9 abbastanza costruita da essere classificata come lingua costruita n\u00e9 abbastanza controllata da essere classificata come lingua naturale controllata.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 19], [20, 29], [30, 33], [34, 37], [37, 46], [47, 58], [58, 59], [60, 64], [65, 67], [68, 76], [77, 85], [86, 89], [90, 92], [92, 100], [101, 110], [110, 111], [112, 113], [114, 126], [127, 131], [132, 138], [139, 147], [148, 149], [149, 152], [153, 160], [160, 161], [162, 165], [166, 171], [172, 177], [177, 189], [190, 193], [194, 204], [205, 213], [213, 214], [214, 215], [216, 222], [223, 224], [225, 229], [230, 235], [236, 248], [249, 252], [253, 255], [256, 263], [264, 266], [267, 277], [278, 287], [288, 290], [291, 297], [298, 310], [311, 315], [316, 322], [323, 332], [333, 335], [336, 346], [347, 358], [359, 361], [362, 368], [369, 381], [382, 386], [387, 393], [394, 402], [403, 414], [414, 415]]}
{"doc_key": "ai-test-123", "ner": [[14, 14, "metrics"], [16, 17, "metrics"], [19, 19, "metrics"], [37, 38, "metrics"], [40, 40, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 19, 16, 17, "named", "", false, false], [40, 40, 37, 38, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Esiste", "una", "serie", "di", "altre", "metriche", ",", "la", "pi\u00f9", "semplice", "delle", "quali", "\u00e8", "l'", "accuratezza", "o", "frazione", "corretta", "(", "FC", ")", ",", "che", "misura", "la", "frazione", "di", "tutte", "le", "istanze", "categorizzate", "correttamente", ";", "il", "complemento", "\u00e8", "la", "frazione", "errata", "(", "FiC", ")", "."], "sentence-detokenized": "Esiste una serie di altre metriche, la pi\u00f9 semplice delle quali \u00e8 l'accuratezza o frazione corretta (FC), che misura la frazione di tutte le istanze categorizzate correttamente; il complemento \u00e8 la frazione errata (FiC).", "token2charspan": [[0, 6], [7, 10], [11, 16], [17, 19], [20, 25], [26, 34], [34, 35], [36, 38], [39, 42], [43, 51], [52, 57], [58, 63], [64, 65], [66, 68], [68, 79], [80, 81], [82, 90], [91, 99], [100, 101], [101, 103], [103, 104], [104, 105], [106, 109], [110, 116], [117, 119], [120, 128], [129, 131], [132, 137], [138, 140], [141, 148], [149, 162], [163, 176], [176, 177], [178, 180], [181, 192], [193, 194], [195, 197], [198, 206], [207, 213], [214, 215], [215, 218], [218, 219], [219, 220]]}
{"doc_key": "ai-test-124", "ner": [[0, 1, "researcher"], [5, 8, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 5, 8, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cardie", "\u00e8", "diventato", "Fellow", "dell'", "Association", "for", "Computational", "Linguistics", "nel", "2016", "."], "sentence-detokenized": "Cardie \u00e8 diventato Fellow dell'Association for Computational Linguistics nel 2016.", "token2charspan": [[0, 6], [7, 8], [9, 18], [19, 25], [26, 31], [31, 42], [43, 46], [47, 60], [61, 72], [73, 76], [77, 81], [81, 82]]}
{"doc_key": "ai-test-125", "ner": [[14, 17, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["L'", "apprendimento", "dei", "parametri", "math", "\\", "theta", "/", "math", "\u00e8", "solitamente", "effettuato", "mediante", "l'", "apprendimento", "della", "massima", "verosimiglianza", "per", "mathp", "(", "Y", "_", "i", "|", "X", "_", "i", ";", "\\", "theta", ")", "/", "math", "."], "sentence-detokenized": "L'apprendimento dei parametri math\\ theta / math \u00e8 solitamente effettuato mediante l'apprendimento della massima verosimiglianza per mathp (Y _ i | X _ i;\\ theta) / math.", "token2charspan": [[0, 2], [2, 15], [16, 19], [20, 29], [30, 34], [34, 35], [36, 41], [42, 43], [44, 48], [49, 50], [51, 62], [63, 73], [74, 82], [83, 85], [85, 98], [99, 104], [105, 112], [113, 128], [129, 132], [133, 138], [139, 140], [140, 141], [142, 143], [144, 145], [146, 147], [148, 149], [150, 151], [152, 153], [153, 154], [154, 155], [156, 161], [161, 162], [163, 164], [165, 169], [169, 170]]}
{"doc_key": "ai-test-126", "ner": [[0, 2, "task"], [4, 8, "algorithm"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 0, 2, "usage", "", true, false], [11, 12, 4, 8, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Analisi", "dei", "cluster", "e", "fattorizzazione", "della", "matrice", "non", "negativa", "per", "l'", "estrazione", "descrittiva", "."], "sentence-detokenized": "Analisi dei cluster e fattorizzazione della matrice non negativa per l'estrazione descrittiva.", "token2charspan": [[0, 7], [8, 11], [12, 19], [20, 21], [22, 37], [38, 43], [44, 51], [52, 55], [56, 64], [65, 68], [69, 71], [71, 81], [82, 93], [93, 94]]}
{"doc_key": "ai-test-127", "ner": [[3, 3, "field"], [6, 7, "field"], [24, 27, "field"], [30, 31, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[24, 27, 3, 3, "part-of", "", false, false], [24, 27, 6, 7, "part-of", "", false, false], [30, 31, 3, 3, "part-of", "", false, false], [30, 31, 6, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Nell'", "ambito", "dell'", "informatica", "e", "delle", "tecnologie", "informatiche", "che", "essa", "consente", ",", "\u00e8", "stata", "una", "sfida", "a", "lungo", "termine", "la", "capacit\u00e0", "dei", "computer", "di", "elaborare", "il", "linguaggio", "naturale", "e", "l'", "apprendimento", "automatico", "."], "sentence-detokenized": "Nell'ambito dell'informatica e delle tecnologie informatiche che essa consente, \u00e8 stata una sfida a lungo termine la capacit\u00e0 dei computer di elaborare il linguaggio naturale e l'apprendimento automatico.", "token2charspan": [[0, 5], [5, 11], [12, 17], [17, 28], [29, 30], [31, 36], [37, 47], [48, 60], [61, 64], [65, 69], [70, 78], [78, 79], [80, 81], [82, 87], [88, 91], [92, 97], [98, 99], [100, 105], [106, 113], [114, 116], [117, 125], [126, 129], [130, 138], [139, 141], [142, 151], [152, 154], [155, 165], [166, 174], [175, 176], [177, 179], [179, 192], [193, 203], [203, 204]]}
{"doc_key": "ai-test-128", "ner": [[5, 8, "algorithm"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 8, 12, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "Il", "codice", "per", "l'", "estrazione", "di", "caratteristiche", "Gabor", "dalle", "immagini", "in", "MATLAB", "\u00e8", "disponibile", "all'", "indirizzo"], "sentence-detokenized": "(Il codice per l'estrazione di caratteristiche Gabor dalle immagini in MATLAB \u00e8 disponibile all'indirizzo", "token2charspan": [[0, 1], [1, 3], [4, 10], [11, 14], [15, 17], [17, 27], [28, 30], [31, 46], [47, 52], [53, 58], [59, 67], [68, 70], [71, 77], [78, 79], [80, 91], [92, 96], [96, 105]]}
{"doc_key": "ai-test-129", "ner": [[0, 0, "misc"], [17, 18, "algorithm"], [20, 20, "task"], [22, 22, "task"], [24, 26, "task"], [28, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 17, 18, "general-affiliation", "", false, false], [0, 0, 20, 20, "related-to", "solves_problem_of_type", false, false], [0, 0, 22, 22, "related-to", "solves_problem_of_type", false, false], [0, 0, 24, 26, "related-to", "solves_problem_of_type", false, false], [0, 0, 28, 30, "related-to", "solves_problem_of_type", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["NeuralExpert", "incentra", "le", "specifiche", "di", "progettazione", "sul", "tipo", "di", "problema", "che", "l'", "utente", "desidera", "risolvere", "con", "la", "rete", "neurale", "(", "classificazione", ",", "previsione", ",", "approssimazione", "di", "funzioni", "o", "analisi", "dei", "cluster", ")", "."], "sentence-detokenized": "NeuralExpert incentra le specifiche di progettazione sul tipo di problema che l'utente desidera risolvere con la rete neurale (classificazione, previsione, approssimazione di funzioni o analisi dei cluster).", "token2charspan": [[0, 12], [13, 21], [22, 24], [25, 35], [36, 38], [39, 52], [53, 56], [57, 61], [62, 64], [65, 73], [74, 77], [78, 80], [80, 86], [87, 95], [96, 105], [106, 109], [110, 112], [113, 117], [118, 125], [126, 127], [127, 142], [142, 143], [144, 154], [154, 155], [156, 171], [172, 174], [175, 183], [184, 185], [186, 193], [194, 197], [198, 205], [205, 206], [206, 207]]}
{"doc_key": "ai-test-130", "ner": [[2, 6, "misc"], [26, 28, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Quando", "la", "dimensione", "del", "passo", "di", "quantizzazione", "(", "\u0394", ")", "\u00e8", "piccola", "rispetto", "alla", "variazione", "del", "segnale", "da", "quantizzare", ",", "\u00e8", "relativamente", "semplice", "dimostrare", "che", "l'", "errore", "quadratico", "medio", "prodotto", "da", "tale", "operazione", "di", "arrotondamento", "sar\u00e0", "approssimativamente", "math", "\\", "Delta", "^", "2", "/", "12", "/", "math.math"], "sentence-detokenized": "Quando la dimensione del passo di quantizzazione (\u0394) \u00e8 piccola rispetto alla variazione del segnale da quantizzare, \u00e8 relativamente semplice dimostrare che l'errore quadratico medio prodotto da tale operazione di arrotondamento sar\u00e0 approssimativamente math\\ Delta ^ 2 / 12 / math.math", "token2charspan": [[0, 6], [7, 9], [10, 20], [21, 24], [25, 30], [31, 33], [34, 48], [49, 50], [50, 51], [51, 52], [53, 54], [55, 62], [63, 71], [72, 76], [77, 87], [88, 91], [92, 99], [100, 102], [103, 114], [114, 115], [116, 117], [118, 131], [132, 140], [141, 151], [152, 155], [156, 158], [158, 164], [165, 175], [176, 181], [182, 190], [191, 193], [194, 198], [199, 209], [210, 212], [213, 227], [228, 232], [233, 252], [253, 257], [257, 258], [259, 264], [265, 266], [267, 268], [269, 270], [271, 273], [274, 275], [276, 285]]}
{"doc_key": "ai-test-131", "ner": [[20, 20, "product"], [28, 30, "researcher"], [32, 33, "researcher"], [35, 37, "researcher"], [39, 40, "researcher"], [42, 43, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "costruzione", "di", "un", "lessico", "ricco", "con", "un'", "ontologia", "adeguata", "richiede", "uno", "sforzo", "significativo", ",", "ad", "esempio", "il", "lessico", "di", "Wordnet", "ha", "richiesto", "molti", "anni", "di", "lavoro", ".", "G.", "A.", "Miller", ",", "R.", "Beckwith", ",", "C.", "D.", "Fellbaum", ",", "D.", "Gross", ",", "K.", "Miller", "."], "sentence-detokenized": "La costruzione di un lessico ricco con un'ontologia adeguata richiede uno sforzo significativo, ad esempio il lessico di Wordnet ha richiesto molti anni di lavoro. G. A. Miller, R. Beckwith, C. D. Fellbaum, D. Gross, K. Miller.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 20], [21, 28], [29, 34], [35, 38], [39, 42], [42, 51], [52, 60], [61, 69], [70, 73], [74, 80], [81, 94], [94, 95], [96, 98], [99, 106], [107, 109], [110, 117], [118, 120], [121, 128], [129, 131], [132, 141], [142, 147], [148, 152], [153, 155], [156, 162], [162, 163], [164, 166], [167, 169], [170, 176], [176, 177], [178, 180], [181, 189], [189, 190], [191, 193], [194, 196], [197, 205], [205, 206], [207, 209], [210, 215], [215, 216], [217, 219], [220, 226], [226, 227]]}
{"doc_key": "ai-test-132", "ner": [[3, 3, "organisation"], [19, 22, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[19, 22, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Il", "portafoglio", "di", "Kawasaki", "comprende", "anche", "tetti", ",", "pavimenti", "e", "altre", "strutture", "giganti", "retrattili", ";", "la", "superficie", "retrattile", "del", "Sapporo", "Dome", "ne", "\u00e8", "un", "esempio", "."], "sentence-detokenized": "Il portafoglio di Kawasaki comprende anche tetti, pavimenti e altre strutture giganti retrattili; la superficie retrattile del Sapporo Dome ne \u00e8 un esempio.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 26], [27, 36], [37, 42], [43, 48], [48, 49], [50, 59], [60, 61], [62, 67], [68, 77], [78, 85], [86, 96], [96, 97], [98, 100], [101, 111], [112, 122], [123, 126], [127, 134], [135, 139], [140, 142], [143, 144], [145, 147], [148, 155], [155, 156]]}
{"doc_key": "ai-test-133", "ner": [[0, 2, "metrics"], [6, 8, "metrics"], [11, 13, "metrics"], [19, 23, "metrics"], [45, 45, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 19, 23, "related-to", "", false, false], [0, 2, 45, 45, "opposite", "alternative_to", false, false], [6, 8, 0, 2, "type-of", "", false, false], [11, 13, 0, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Le", "statistiche", "kappa", ",", "come", "la", "kappa", "di", "Fleiss", "e", "la", "kappa", "di", "Cohen", ",", "sono", "metodi", "per", "calcolare", "l'", "affidabilit\u00e0", "inter", "-", "rater", "basati", "su", "diverse", "ipotesi", "sulle", "distribuzioni", "marginali", "o", "precedenti", ",", "e", "sono", "sempre", "pi\u00f9", "utilizzate", "come", "alternative", "corrette", "dal", "caso", "all'", "accuratezza", "in", "altri", "contesti", "."], "sentence-detokenized": "Le statistiche kappa, come la kappa di Fleiss e la kappa di Cohen, sono metodi per calcolare l'affidabilit\u00e0 inter-rater basati su diverse ipotesi sulle distribuzioni marginali o precedenti, e sono sempre pi\u00f9 utilizzate come alternative corrette dal caso all'accuratezza in altri contesti.", "token2charspan": [[0, 2], [3, 14], [15, 20], [20, 21], [22, 26], [27, 29], [30, 35], [36, 38], [39, 45], [46, 47], [48, 50], [51, 56], [57, 59], [60, 65], [65, 66], [67, 71], [72, 78], [79, 82], [83, 92], [93, 95], [95, 107], [108, 113], [113, 114], [114, 119], [120, 126], [127, 129], [130, 137], [138, 145], [146, 151], [152, 165], [166, 175], [176, 177], [178, 188], [188, 189], [190, 191], [192, 196], [197, 203], [204, 207], [208, 218], [219, 223], [224, 235], [236, 244], [245, 248], [249, 253], [254, 258], [258, 269], [270, 272], [273, 278], [279, 287], [287, 288]]}
{"doc_key": "ai-test-134", "ner": [[4, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [18, 18, "researcher"], [29, 31, "algorithm"], [33, 36, "algorithm"], [38, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 18, 18, "role", "student_of", false, false], [7, 8, 18, 18, "role", "student_of", false, false], [10, 11, 18, 18, "role", "student_of", false, false], [13, 14, 18, 18, "role", "student_of", false, false], [33, 36, 4, 5, "origin", "", false, false], [33, 36, 7, 8, "origin", "", false, false], [33, 36, 10, 11, "origin", "", false, false], [33, 36, 13, 14, "origin", "", false, false], [33, 36, 18, 18, "origin", "", false, false], [33, 36, 29, 31, "type-of", "", false, false], [38, 38, 33, 36, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Con", "i", "suoi", "studenti", "Sepp", "Hochreiter", ",", "Felix", "Gers", ",", "Fred", "Cummins", ",", "Alex", "Graves", "e", "altri", ",", "Schmidhuber", "ha", "pubblicato", "versioni", "sempre", "pi\u00f9", "sofisticate", "di", "un", "tipo", "di", "rete", "neurale", "ricorrente", "chiamata", "memoria", "a", "breve", "termine", "(", "LSTM", ")", "."], "sentence-detokenized": "Con i suoi studenti Sepp Hochreiter, Felix Gers, Fred Cummins, Alex Graves e altri, Schmidhuber ha pubblicato versioni sempre pi\u00f9 sofisticate di un tipo di rete neurale ricorrente chiamata memoria a breve termine (LSTM).", "token2charspan": [[0, 3], [4, 5], [6, 10], [11, 19], [20, 24], [25, 35], [35, 36], [37, 42], [43, 47], [47, 48], [49, 53], [54, 61], [61, 62], [63, 67], [68, 74], [75, 76], [77, 82], [82, 83], [84, 95], [96, 98], [99, 109], [110, 118], [119, 125], [126, 129], [130, 141], [142, 144], [145, 147], [148, 152], [153, 155], [156, 160], [161, 168], [169, 179], [180, 188], [189, 196], [197, 198], [199, 204], [205, 212], [213, 214], [214, 218], [218, 219], [219, 220]]}
{"doc_key": "ai-test-135", "ner": [[6, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2004", "-", "Viene", "presentato", "il", "primo", "Cobot", "KUKA", "LBR", "3", "."], "sentence-detokenized": "2004 - Viene presentato il primo Cobot KUKA LBR 3.", "token2charspan": [[0, 4], [5, 6], [7, 12], [13, 23], [24, 26], [27, 32], [33, 38], [39, 43], [44, 47], [48, 49], [49, 50]]}
{"doc_key": "ai-test-136", "ner": [[12, 15, "algorithm"], [18, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Due", "approcci", "poco", "profondi", "utilizzati", "per", "addestrare", "e", "poi", "disambiguare", "sono", "il", "classificatore", "di", "Naive", "Bayes", "e", "gli", "alberi", "decisionali", "."], "sentence-detokenized": "Due approcci poco profondi utilizzati per addestrare e poi disambiguare sono il classificatore di Naive Bayes e gli alberi decisionali.", "token2charspan": [[0, 3], [4, 12], [13, 17], [18, 26], [27, 37], [38, 41], [42, 52], [53, 54], [55, 58], [59, 71], [72, 76], [77, 79], [80, 94], [95, 97], [98, 103], [104, 109], [110, 111], [112, 115], [116, 122], [123, 134], [134, 135]]}
{"doc_key": "ai-test-137", "ner": [[5, 5, "misc"], [12, 13, "person"], [15, 17, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 12, 13, "origin", "", false, false], [5, 5, 15, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Le", "prime", "forme", "pratiche", "di", "fotografia", "furono", "introdotte", "nel", "gennaio", "1839", "da", "Louis", "Daguerre", "e", "Henry", "Fox", "Talbot", "."], "sentence-detokenized": "Le prime forme pratiche di fotografia furono introdotte nel gennaio 1839 da Louis Daguerre e Henry Fox Talbot.", "token2charspan": [[0, 2], [3, 8], [9, 14], [15, 23], [24, 26], [27, 37], [38, 44], [45, 55], [56, 59], [60, 67], [68, 72], [73, 75], [76, 81], [82, 90], [91, 92], [93, 98], [99, 102], [103, 109], [109, 110]]}
{"doc_key": "ai-test-138", "ner": [[4, 5, "task"], [10, 11, "task"], [23, 25, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 23, 25, "part-of", "task_part_of_field", false, false], [10, 11, 23, 25, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Ad", "esempio", ",", "la", "sintesi", "vocale", ",", "combinata", "con", "il", "riconoscimento", "vocale", ",", "consente", "di", "interagire", "con", "i", "dispositivi", "mobili", "tramite", "interfacce", "di", "elaborazione", "del", "linguaggio", "."], "sentence-detokenized": "Ad esempio, la sintesi vocale, combinata con il riconoscimento vocale, consente di interagire con i dispositivi mobili tramite interfacce di elaborazione del linguaggio.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 14], [15, 22], [23, 29], [29, 30], [31, 40], [41, 44], [45, 47], [48, 62], [63, 69], [69, 70], [71, 79], [80, 82], [83, 93], [94, 97], [98, 99], [100, 111], [112, 118], [119, 126], [127, 137], [138, 140], [141, 153], [154, 157], [158, 168], [168, 169]]}
{"doc_key": "ai-test-139", "ner": [[0, 1, "product"], [14, 14, "programlang"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 14, 14, "general-affiliation", "", false, false], [0, 1, 16, 17, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["I", "phidget", "possono", "essere", "programmati", "utilizzando", "diversi", "software", "e", "linguaggi", "di", "programmazione", ",", "da", "Java", "a", "Microsoft", "Excel", "."], "sentence-detokenized": "I phidget possono essere programmati utilizzando diversi software e linguaggi di programmazione, da Java a Microsoft Excel.", "token2charspan": [[0, 1], [2, 9], [10, 17], [18, 24], [25, 36], [37, 48], [49, 56], [57, 65], [66, 67], [68, 77], [78, 80], [81, 95], [95, 96], [97, 99], [100, 104], [105, 106], [107, 116], [117, 122], [122, 123]]}
{"doc_key": "ai-test-140", "ner": [[2, 3, "field"], [10, 11, "researcher"], [13, 16, "misc"], [22, 24, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 10, 11, "origin", "", false, false], [10, 11, 22, 24, "general-affiliation", "topic_of_study", false, false], [10, 11, 27, 28, "general-affiliation", "topic_of_study", false, false], [13, 16, 10, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Il", "termine", "machine", "learning", "\u00e8", "stato", "coniato", "nel", "1959", "da", "Arthur", "Samuel", ",", "dipendente", "americano", "dell'", "IBM", "e", "pioniere", "nel", "campo", "dei", "giochi", "per", "computer", "e", "dell'", "intelligenza", "artificiale", "."], "sentence-detokenized": "Il termine machine learning \u00e8 stato coniato nel 1959 da Arthur Samuel, dipendente americano dell'IBM e pioniere nel campo dei giochi per computer e dell'intelligenza artificiale.", "token2charspan": [[0, 2], [3, 10], [11, 18], [19, 27], [28, 29], [30, 35], [36, 43], [44, 47], [48, 52], [53, 55], [56, 62], [63, 69], [69, 70], [71, 81], [82, 91], [92, 97], [97, 100], [101, 102], [103, 111], [112, 115], [116, 121], [122, 125], [126, 132], [133, 136], [137, 145], [146, 147], [148, 153], [153, 165], [166, 177], [177, 178]]}
{"doc_key": "ai-test-141", "ner": [[1, 2, "misc"], [3, 4, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 1, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Il", "poeta", "israeliano", "David", "Avidan", ",", "affascinato", "dalle", "tecnologie", "del", "futuro", "e", "dal", "loro", "rapporto", "con", "l'", "arte", ",", "desiderava", "esplorare", "l'", "uso", "del", "computer", "per", "la", "scrittura", "letteraria", "."], "sentence-detokenized": "Il poeta israeliano David Avidan, affascinato dalle tecnologie del futuro e dal loro rapporto con l'arte, desiderava esplorare l'uso del computer per la scrittura letteraria.", "token2charspan": [[0, 2], [3, 8], [9, 19], [20, 25], [26, 32], [32, 33], [34, 45], [46, 51], [52, 62], [63, 66], [67, 73], [74, 75], [76, 79], [80, 84], [85, 93], [94, 97], [98, 100], [100, 104], [104, 105], [106, 116], [117, 126], [127, 129], [129, 132], [133, 136], [137, 145], [146, 149], [150, 152], [153, 162], [163, 173], [173, 174]]}
{"doc_key": "ai-test-142", "ner": [[6, 7, "misc"], [9, 9, "organisation"], [17, 17, "location"], [34, 34, "location"], [31, 32, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 9, 6, 7, "part-of", "", false, false], [31, 32, 34, 34, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Nel", "2017", ",", "nell'", "ambito", "del", "progetto", "GATEway", ",", "Oxbotica", "ha", "sperimentato", "sette", "bus", "navetta", "autonomi", "a", "Greenwich", ",", "navigando", "su", "un", "percorso", "di", "due", "miglia", "lungo", "il", "fiume", "vicino", "alla", "O2", "Arena", "di", "Londra", ",", "su", "un", "percorso", "utilizzato", "anche", "da", "pedoni", "e", "ciclisti", "."], "sentence-detokenized": "Nel 2017, nell'ambito del progetto GATEway, Oxbotica ha sperimentato sette bus navetta autonomi a Greenwich, navigando su un percorso di due miglia lungo il fiume vicino alla O2 Arena di Londra, su un percorso utilizzato anche da pedoni e ciclisti.", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 15], [15, 21], [22, 25], [26, 34], [35, 42], [42, 43], [44, 52], [53, 55], [56, 68], [69, 74], [75, 78], [79, 86], [87, 95], [96, 97], [98, 107], [107, 108], [109, 118], [119, 121], [122, 124], [125, 133], [134, 136], [137, 140], [141, 147], [148, 153], [154, 156], [157, 162], [163, 169], [170, 174], [175, 177], [178, 183], [184, 186], [187, 193], [193, 194], [195, 197], [198, 200], [201, 209], [210, 220], [221, 226], [227, 229], [230, 236], [237, 238], [239, 247], [247, 248]]}
{"doc_key": "ai-test-143", "ner": [[13, 15, "task"], [18, 19, "metrics"], [24, 25, "misc"], [31, 31, "metrics"], [33, 33, "metrics"], [36, 36, "metrics"], [38, 38, "metrics"], [40, 43, "metrics"], [46, 46, "metrics"], [48, 48, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[18, 19, 24, 25, "related-to", "is_a", false, false], [18, 19, 31, 31, "usage", "", false, false], [18, 19, 33, 33, "usage", "", false, false], [31, 31, 36, 36, "named", "same", false, false], [33, 33, 48, 48, "named", "same", false, false], [36, 36, 46, 46, "opposite", "", false, false], [36, 36, 48, 48, "opposite", "", false, false], [38, 38, 36, 36, "named", "", false, false], [40, 43, 36, 36, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Una", "combinazione", "non", "correlata", "ma", "comunemente", "utilizzata", "di", "statistiche", "di", "base", "per", "il", "recupero", "delle", "informazioni", "\u00e8", "il", "punteggio", "F", ",", "che", "\u00e8", "una", "media", "armonica", "(", "eventualmente", "ponderata", ")", "di", "richiamo", "e", "precisione", ",", "dove", "richiamo", "=", "sensibilit\u00e0", "=", "tasso", "di", "veri", "positivi", ",", "ma", "specificit\u00e0", "e", "precisione", "sono", "misure", "completamente", "diverse", "."], "sentence-detokenized": "Una combinazione non correlata ma comunemente utilizzata di statistiche di base per il recupero delle informazioni \u00e8 il punteggio F, che \u00e8 una media armonica (eventualmente ponderata) di richiamo e precisione, dove richiamo = sensibilit\u00e0 = tasso di veri positivi, ma specificit\u00e0 e precisione sono misure completamente diverse.", "token2charspan": [[0, 3], [4, 16], [17, 20], [21, 30], [31, 33], [34, 45], [46, 56], [57, 59], [60, 71], [72, 74], [75, 79], [80, 83], [84, 86], [87, 95], [96, 101], [102, 114], [115, 116], [117, 119], [120, 129], [130, 131], [131, 132], [133, 136], [137, 138], [139, 142], [143, 148], [149, 157], [158, 159], [159, 172], [173, 182], [182, 183], [184, 186], [187, 195], [196, 197], [198, 208], [208, 209], [210, 214], [215, 223], [224, 225], [226, 237], [238, 239], [240, 245], [246, 248], [249, 253], [254, 262], [262, 263], [264, 266], [267, 278], [279, 280], [281, 291], [292, 296], [297, 303], [304, 317], [318, 325], [325, 326]]}
{"doc_key": "ai-test-144", "ner": [[0, 2, "field"], [11, 11, "field"], [14, 14, "field"], [17, 17, "field"], [20, 20, "field"], [23, 24, "field"], [32, 34, "product"], [36, 39, "product"], [41, 42, "product"], [44, 45, "product"], [62, 64, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 2, 11, 11, "origin", "takes_inspiration_from", false, false], [0, 2, 14, 14, "origin", "takes_inspiration_from", false, false], [0, 2, 17, 17, "origin", "takes_inspiration_from", false, false], [0, 2, 20, 20, "origin", "takes_inspiration_from", false, false], [0, 2, 23, 24, "origin", "takes_inspiration_from", false, false], [32, 34, 0, 2, "origin", "", false, false], [36, 39, 0, 2, "origin", "", false, false], [41, 42, 0, 2, "origin", "", false, false], [44, 45, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["L'", "ingegneria", "neuromorfica", "\u00e8", "una", "materia", "interdisciplinare", "che", "trae", "ispirazione", "dalla", "biologia", ",", "dalla", "fisica", ",", "dalla", "matematica", ",", "dall'", "informatica", "e", "dall'", "ingegneria", "elettronica", "per", "progettare", "sistemi", "neurali", "artificiali", ",", "come", "sistemi", "di", "visione", ",", "sistemi", "testa", "-", "occhio", ",", "processori", "uditivi", "e", "robot", "autonomi", ",", "la", "cui", "architettura", "fisica", "e", "i", "cui", "principi", "di", "progettazione", "si", "basano", "su", "quelli", "dei", "sistemi", "nervosi", "biologici", "."], "sentence-detokenized": "L'ingegneria neuromorfica \u00e8 una materia interdisciplinare che trae ispirazione dalla biologia, dalla fisica, dalla matematica, dall'informatica e dall'ingegneria elettronica per progettare sistemi neurali artificiali, come sistemi di visione, sistemi testa-occhio, processori uditivi e robot autonomi, la cui architettura fisica e i cui principi di progettazione si basano su quelli dei sistemi nervosi biologici.", "token2charspan": [[0, 2], [2, 12], [13, 25], [26, 27], [28, 31], [32, 39], [40, 57], [58, 61], [62, 66], [67, 78], [79, 84], [85, 93], [93, 94], [95, 100], [101, 107], [107, 108], [109, 114], [115, 125], [125, 126], [127, 132], [132, 143], [144, 145], [146, 151], [151, 161], [162, 173], [174, 177], [178, 188], [189, 196], [197, 204], [205, 216], [216, 217], [218, 222], [223, 230], [231, 233], [234, 241], [241, 242], [243, 250], [251, 256], [256, 257], [257, 263], [263, 264], [265, 275], [276, 283], [284, 285], [286, 291], [292, 300], [300, 301], [302, 304], [305, 308], [309, 321], [322, 328], [329, 330], [331, 332], [333, 336], [337, 345], [346, 348], [349, 362], [363, 365], [366, 372], [373, 375], [376, 382], [383, 386], [387, 394], [395, 402], [403, 412], [412, 413]]}
{"doc_key": "ai-test-145", "ner": [[4, 7, "metrics"], [11, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 11, 4, 7, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "particolare", ",", "il", "criterio", "di", "stabilit\u00e0", "BIBO", "richiede", "che", "la", "ROC", "del", "sistema", "includa", "il", "cerchio", "unitario", "."], "sentence-detokenized": "In particolare, il criterio di stabilit\u00e0 BIBO richiede che la ROC del sistema includa il cerchio unitario.", "token2charspan": [[0, 2], [3, 14], [14, 15], [16, 18], [19, 27], [28, 30], [31, 40], [41, 45], [46, 54], [55, 58], [59, 61], [62, 65], [66, 69], [70, 77], [78, 85], [86, 88], [89, 96], [97, 105], [105, 106]]}
{"doc_key": "ai-test-146", "ner": [[7, 7, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2", "Il", "programma", "\u00e8", "stato", "riscritto", "in", "Java", "a", "partire", "dal", "1998", "."], "sentence-detokenized": "2 Il programma \u00e8 stato riscritto in Java a partire dal 1998.", "token2charspan": [[0, 1], [2, 4], [5, 14], [15, 16], [17, 22], [23, 32], [33, 35], [36, 40], [41, 42], [43, 50], [51, 54], [55, 59], [59, 60]]}
{"doc_key": "ai-test-147", "ner": [[0, 1, "metrics"], [7, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 7, 9, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["La", "MCC", "pu\u00f2", "essere", "calcolata", "direttamente", "dalla", "matrice", "di", "confusione", "utilizzando", "la", "formula", ":"], "sentence-detokenized": "La MCC pu\u00f2 essere calcolata direttamente dalla matrice di confusione utilizzando la formula:", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 17], [18, 27], [28, 40], [41, 46], [47, 54], [55, 57], [58, 68], [69, 80], [81, 83], [84, 91], [91, 92]]}
{"doc_key": "ai-test-148", "ner": [[7, 12, "organisation"], [20, 25, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 12, 20, 25, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["\u00c8", "stato", "sviluppato", "da", "un", "team", "del", "MIT", "-", "IBM", "Watson", "AI", "Lab", "e", "presentato", "per", "la", "prima", "volta", "alla", "2018", "International", "Conference", "on", "Learning", "Representations", "."], "sentence-detokenized": "\u00c8 stato sviluppato da un team del MIT-IBM Watson AI Lab e presentato per la prima volta alla 2018 International Conference on Learning Representations.", "token2charspan": [[0, 1], [2, 7], [8, 18], [19, 21], [22, 24], [25, 29], [30, 33], [34, 37], [37, 38], [38, 41], [42, 48], [49, 51], [52, 55], [56, 57], [58, 68], [69, 72], [73, 75], [76, 81], [82, 87], [88, 92], [93, 97], [98, 111], [112, 122], [123, 125], [126, 134], [135, 150], [150, 151]]}
{"doc_key": "ai-test-149", "ner": [[2, 3, "metrics"], [15, 16, "metrics"], [18, 19, "metrics"], [45, 45, "metrics"], [47, 47, "metrics"], [54, 56, "metrics"], [59, 59, "metrics"], [61, 61, "metrics"], [63, 65, "metrics"], [70, 70, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[15, 16, 45, 45, "type-of", "", false, false], [15, 16, 54, 56, "related-to", "collapses_to_identity", false, false], [18, 19, 47, 47, "type-of", "", false, false], [18, 19, 54, 56, "related-to", "collapses_to_identity", false, false], [18, 19, 63, 65, "named", "same", false, false], [59, 59, 70, 70, "related-to", "collapses_to_identity", false, false], [61, 61, 70, 70, "related-to", "collapses_to_identity", false, false], [63, 65, 70, 70, "related-to", "collapses_to_identity", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Quando", "le", "prevalenze", "VERE", "per", "le", "due", "variabili", "positive", "sono", "uguali", ",", "come", "ipotizzato", "in", "Fleiss", "kappa", "e", "F-", "score", ",", "cio\u00e8", "il", "numero", "di", "previsioni", "positive", "corrisponde", "al", "numero", "di", "classi", "positive", "nel", "caso", "dicotomico", "(", "due", "classi", ")", ",", "le", "diverse", "misure", "di", "kappa", "e", "correlazione", "collassano", "fino", "a", "diventare", "identiche", "alla", "J", "di", "Youden", ",", "e", "recall", ",", "precision", "e", "F", "-", "score", "sono", "analogamente", "identici", "all'", "accuratezza", "."], "sentence-detokenized": "Quando le prevalenze VERE per le due variabili positive sono uguali, come ipotizzato in Fleiss kappa e F-score, cio\u00e8 il numero di previsioni positive corrisponde al numero di classi positive nel caso dicotomico (due classi), le diverse misure di kappa e correlazione collassano fino a diventare identiche alla J di Youden, e recall, precision e F-score sono analogamente identici all'accuratezza.", "token2charspan": [[0, 6], [7, 9], [10, 20], [21, 25], [26, 29], [30, 32], [33, 36], [37, 46], [47, 55], [56, 60], [61, 67], [67, 68], [69, 73], [74, 84], [85, 87], [88, 94], [95, 100], [101, 102], [103, 105], [105, 110], [110, 111], [112, 116], [117, 119], [120, 126], [127, 129], [130, 140], [141, 149], [150, 161], [162, 164], [165, 171], [172, 174], [175, 181], [182, 190], [191, 194], [195, 199], [200, 210], [211, 212], [212, 215], [216, 222], [222, 223], [223, 224], [225, 227], [228, 235], [236, 242], [243, 245], [246, 251], [252, 253], [254, 266], [267, 277], [278, 282], [283, 284], [285, 294], [295, 304], [305, 309], [310, 311], [312, 314], [315, 321], [321, 322], [323, 324], [325, 331], [331, 332], [333, 342], [343, 344], [345, 346], [346, 347], [347, 352], [353, 357], [358, 370], [371, 379], [380, 384], [384, 395], [395, 396]]}
{"doc_key": "ai-test-150", "ner": [[1, 4, "misc"], [6, 6, "misc"], [9, 9, "conference"], [15, 18, "task"], [19, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 4, 9, 9, "part-of", "", false, false], [1, 4, 9, 9, "physical", "", false, false], [1, 4, 9, 9, "temporal", "", false, false], [6, 6, 1, 4, "named", "", false, false], [15, 18, 1, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Il", "workshop", "Building", "Educational", "Applications", "(", "BEA", ")", "del", "NAACL", "2013", "ha", "ospitato", "il", "primo", "compito", "condiviso", "NLI", ".", "Tetreault", "et", "al", ",", "2013", "Il", "concorso", "ha", "visto", "la", "partecipazione", "di", "29", "team", "di", "tutto", "il", "mondo", ",", "24", "dei", "quali", "hanno", "anche", "pubblicato", "un", "articolo", "che", "descrive", "i", "loro", "sistemi", "e", "approcci", "."], "sentence-detokenized": "Il workshop Building Educational Applications (BEA) del NAACL 2013 ha ospitato il primo compito condiviso NLI. Tetreault et al, 2013 Il concorso ha visto la partecipazione di 29 team di tutto il mondo, 24 dei quali hanno anche pubblicato un articolo che descrive i loro sistemi e approcci.", "token2charspan": [[0, 2], [3, 11], [12, 20], [21, 32], [33, 45], [46, 47], [47, 50], [50, 51], [52, 55], [56, 61], [62, 66], [67, 69], [70, 78], [79, 81], [82, 87], [88, 95], [96, 105], [106, 109], [109, 110], [111, 120], [121, 123], [124, 126], [126, 127], [128, 132], [133, 135], [136, 144], [145, 147], [148, 153], [154, 156], [157, 171], [172, 174], [175, 177], [178, 182], [183, 185], [186, 191], [192, 194], [195, 200], [200, 201], [202, 204], [205, 208], [209, 214], [215, 220], [221, 226], [227, 237], [238, 240], [241, 249], [250, 253], [254, 262], [263, 264], [265, 269], [270, 277], [278, 279], [280, 288], [288, 289]]}
{"doc_key": "ai-test-151", "ner": [[0, 3, "algorithm"], [6, 9, "algorithm"], [17, 18, "misc"], [21, 23, "misc"], [40, 41, "misc"], [44, 47, "algorithm"], [49, 49, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 6, 9, "type-of", "", false, false], [0, 3, 17, 18, "related-to", "finds", false, false], [21, 23, 17, 18, "type-of", "", false, false], [49, 49, 44, 47, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["L'", "algoritmo", "di", "Viterbi", "\u00e8", "un", "algoritmo", "di", "programmazione", "dinamica", "per", "trovare", "la", "sequenza", "pi\u00f9", "probabile", "di", "stati", "nascosti", ",", "chiamata", "percorso", "di", "Viterbi", ",", "che", "risulta", "in", "una", "sequenza", "di", "eventi", "osservati", ",", "soprattutto", "nel", "contesto", "delle", "fonti", "di", "informazione", "Markov", "e", "dei", "modelli", "di", "Markov", "nascosti", "(", "HMM", ")", "."], "sentence-detokenized": "L'algoritmo di Viterbi \u00e8 un algoritmo di programmazione dinamica per trovare la sequenza pi\u00f9 probabile di stati nascosti, chiamata percorso di Viterbi, che risulta in una sequenza di eventi osservati, soprattutto nel contesto delle fonti di informazione Markov e dei modelli di Markov nascosti (HMM).", "token2charspan": [[0, 2], [2, 11], [12, 14], [15, 22], [23, 24], [25, 27], [28, 37], [38, 40], [41, 55], [56, 64], [65, 68], [69, 76], [77, 79], [80, 88], [89, 92], [93, 102], [103, 105], [106, 111], [112, 120], [120, 121], [122, 130], [131, 139], [140, 142], [143, 150], [150, 151], [152, 155], [156, 163], [164, 166], [167, 170], [171, 179], [180, 182], [183, 189], [190, 199], [199, 200], [201, 212], [213, 216], [217, 225], [226, 231], [232, 237], [238, 240], [241, 253], [254, 260], [261, 262], [263, 266], [267, 274], [275, 277], [278, 284], [285, 293], [294, 295], [295, 298], [298, 299], [299, 300]]}
{"doc_key": "ai-test-152", "ner": [[1, 1, "field"], [4, 6, "algorithm"], [9, 11, "misc"], [15, 16, "algorithm"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 1, 1, "part-of", "", false, false], [4, 6, 9, 11, "general-affiliation", "", false, false], [4, 6, 15, 16, "related-to", "generalizes_from", false, false], [4, 6, 18, 19, "related-to", "generalizes_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "statistica", ",", "la", "regressione", "logistica", "multinomiale", "\u00e8", "un", "metodo", "di", "classificazione", "che", "generalizza", "la", "regressione", "logistica", "alla", "classificazione", "multiclasse", ",", "cio\u00e8", "con", "pi\u00f9", "di", "due", "possibili", "esiti", "discreti", "."], "sentence-detokenized": "In statistica, la regressione logistica multinomiale \u00e8 un metodo di classificazione che generalizza la regressione logistica alla classificazione multiclasse, cio\u00e8 con pi\u00f9 di due possibili esiti discreti.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 17], [18, 29], [30, 39], [40, 52], [53, 54], [55, 57], [58, 64], [65, 67], [68, 83], [84, 87], [88, 99], [100, 102], [103, 114], [115, 124], [125, 129], [130, 145], [146, 157], [157, 158], [159, 163], [164, 167], [168, 171], [172, 174], [175, 178], [179, 188], [189, 194], [195, 203], [203, 204]]}
{"doc_key": "ai-test-153", "ner": [[0, 4, "algorithm"], [12, 14, "field"], [17, 20, "field"], [23, 23, "task"], [26, 28, "task"], [31, 33, "task"], [35, 36, "researcher"], [38, 39, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 4, 12, 14, "part-of", "", false, false], [0, 4, 17, 20, "part-of", "", false, false], [23, 23, 0, 4, "usage", "", true, false], [26, 28, 0, 4, "usage", "", true, false], [31, 33, 0, 4, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["I", "modelli", "di", "Markov", "nascosti", "sono", "noti", "per", "le", "loro", "applicazioni", "all'", "apprendimento", "per", "rinforzo", "e", "al", "riconoscimento", "di", "modelli", "temporali", "come", "il", "parlato", ",", "il", "riconoscimento", "della", "scrittura", ",", "il", "riconoscimento", "dei", "gesti", ",", "Thad", "Starner", ",", "Alex", "Pentland", "."], "sentence-detokenized": "I modelli di Markov nascosti sono noti per le loro applicazioni all'apprendimento per rinforzo e al riconoscimento di modelli temporali come il parlato, il riconoscimento della scrittura, il riconoscimento dei gesti, Thad Starner, Alex Pentland.", "token2charspan": [[0, 1], [2, 9], [10, 12], [13, 19], [20, 28], [29, 33], [34, 38], [39, 42], [43, 45], [46, 50], [51, 63], [64, 68], [68, 81], [82, 85], [86, 94], [95, 96], [97, 99], [100, 114], [115, 117], [118, 125], [126, 135], [136, 140], [141, 143], [144, 151], [151, 152], [153, 155], [156, 170], [171, 176], [177, 186], [186, 187], [188, 190], [191, 205], [206, 209], [210, 215], [215, 216], [217, 221], [222, 229], [229, 230], [231, 235], [236, 244], [244, 245]]}
{"doc_key": "ai-test-154", "ner": [[7, 8, "misc"], [35, 38, "metrics"], [41, 41, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 41, 41, "named", "", false, false], [35, 38, 41, 41, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "sostanza", ",", "ci\u00f2", "significa", "che", "se", "un", "grammo", "\u00e8", "stato", "visto", "pi\u00f9", "di", "k", "volte", "durante", "l'", "addestramento", ",", "la", "probabilit\u00e0", "condizionata", "di", "una", "parola", ",", "data", "la", "sua", "storia", ",", "\u00e8", "proporzionale", "alla", "stima", "della", "massima", "verosimiglianza", "di", "quel", "grammo", "."], "sentence-detokenized": "In sostanza, ci\u00f2 significa che se un grammo \u00e8 stato visto pi\u00f9 di k volte durante l'addestramento, la probabilit\u00e0 condizionata di una parola, data la sua storia, \u00e8 proporzionale alla stima della massima verosimiglianza di quel grammo.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 16], [17, 26], [27, 30], [31, 33], [34, 36], [37, 43], [44, 45], [46, 51], [52, 57], [58, 61], [62, 64], [65, 66], [67, 72], [73, 80], [81, 83], [83, 96], [96, 97], [98, 100], [101, 112], [113, 125], [126, 128], [129, 132], [133, 139], [139, 140], [141, 145], [146, 148], [149, 152], [153, 159], [159, 160], [161, 162], [163, 176], [177, 181], [182, 187], [188, 193], [194, 201], [202, 217], [218, 220], [221, 225], [226, 232], [232, 233]]}
{"doc_key": "ai-test-155", "ner": [[3, 5, "task"], [7, 10, "task"], [12, 15, "task"], [21, 24, "task"], [32, 33, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[32, 33, 21, 24, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Si", "interessa", "di", "rappresentazione", "della", "conoscenza", ",", "ragionamento", "di", "senso", "compiuto", "e", "comprensione", "del", "linguaggio", "naturale", ",", "ritenendo", "che", "attualmente", "la", "comprensione", "profonda", "del", "linguaggio", "possa", "essere", "raggiunta", "solo", "attraverso", "una", "significativa", "ingegnerizzazione", "manuale", "di", "formalismi", "ricchi", "di", "semantica", ",", "unita", "a", "preferenze", "statistiche", "."], "sentence-detokenized": "Si interessa di rappresentazione della conoscenza, ragionamento di senso compiuto e comprensione del linguaggio naturale, ritenendo che attualmente la comprensione profonda del linguaggio possa essere raggiunta solo attraverso una significativa ingegnerizzazione manuale di formalismi ricchi di semantica, unita a preferenze statistiche.", "token2charspan": [[0, 2], [3, 12], [13, 15], [16, 32], [33, 38], [39, 49], [49, 50], [51, 63], [64, 66], [67, 72], [73, 81], [82, 83], [84, 96], [97, 100], [101, 111], [112, 120], [120, 121], [122, 131], [132, 135], [136, 147], [148, 150], [151, 163], [164, 172], [173, 176], [177, 187], [188, 193], [194, 200], [201, 210], [211, 215], [216, 226], [227, 230], [231, 244], [245, 262], [263, 270], [271, 273], [274, 284], [285, 291], [292, 294], [295, 304], [304, 305], [306, 311], [312, 313], [314, 324], [325, 336], [336, 337]]}
{"doc_key": "ai-test-156", "ner": [[1, 1, "programlang"], [3, 3, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "JavaScript", ",", "Python", "o"], "sentence-detokenized": "In JavaScript, Python o", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 21], [22, 23]]}
{"doc_key": "ai-test-157", "ner": [[1, 2, "misc"], [6, 7, "misc"], [10, 10, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 6, 7, "part-of", "", false, false], [6, 7, 10, 10, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["I", "premi", "Newcomb", "sono", "annunciati", "nella", "rivista", "AI", "pubblicata", "dall'", "AAAI", "."], "sentence-detokenized": "I premi Newcomb sono annunciati nella rivista AI pubblicata dall'AAAI.", "token2charspan": [[0, 1], [2, 7], [8, 15], [16, 20], [21, 31], [32, 37], [38, 45], [46, 48], [49, 59], [60, 65], [65, 69], [69, 70]]}
{"doc_key": "ai-test-158", "ner": [[1, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["L'", "errore", "quadratico", "medio", "su", "un", "set", "di", "test", "di", "100", "esemplari", "\u00e8", "di", "0,084", ",", "inferiore", "all'", "errore", "non", "normalizzato", "."], "sentence-detokenized": "L'errore quadratico medio su un set di test di 100 esemplari \u00e8 di 0,084, inferiore all'errore non normalizzato.", "token2charspan": [[0, 2], [2, 8], [9, 19], [20, 25], [26, 28], [29, 31], [32, 35], [36, 38], [39, 43], [44, 46], [47, 50], [51, 60], [61, 62], [63, 65], [66, 71], [71, 72], [73, 82], [83, 87], [87, 93], [94, 97], [98, 110], [110, 111]]}
{"doc_key": "ai-test-159", "ner": [[0, 3, "metrics"], [10, 13, "field"], [21, 24, "task"], [26, 26, "task"], [30, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 13, 0, 3, "usage", "", false, false], [21, 24, 10, 13, "part-of", "task_part_of_field", false, false], [26, 26, 21, 24, "named", "", false, false], [30, 32, 10, 13, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Il", "punteggio", "F", "\u00e8", "stato", "ampiamente", "utilizzato", "nella", "letteratura", "sull'", "elaborazione", "del", "linguaggio", "naturale", ",", "ad", "esempio", "per", "la", "valutazione", "del", "riconoscimento", "di", "entit\u00e0", "denominate", "(", "NER", ")", "e", "della", "segmentazione", "delle", "parole", "."], "sentence-detokenized": "Il punteggio F \u00e8 stato ampiamente utilizzato nella letteratura sull'elaborazione del linguaggio naturale, ad esempio per la valutazione del riconoscimento di entit\u00e0 denominate (NER) e della segmentazione delle parole.", "token2charspan": [[0, 2], [3, 12], [13, 14], [15, 16], [17, 22], [23, 33], [34, 44], [45, 50], [51, 62], [63, 68], [68, 80], [81, 84], [85, 95], [96, 104], [104, 105], [106, 108], [109, 116], [117, 120], [121, 123], [124, 135], [136, 139], [140, 154], [155, 157], [158, 164], [165, 175], [176, 177], [177, 180], [180, 181], [182, 183], [184, 189], [190, 203], [204, 209], [210, 216], [216, 217]]}
{"doc_key": "ai-test-160", "ner": [[0, 1, "product"], [6, 8, "product"], [20, 22, "misc"], [25, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 20, 22, "related-to", "performs_task", false, false], [0, 1, 25, 27, "related-to", "performs_task", false, false], [6, 8, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["I", "chatbot", "sono", "tipicamente", "utilizzati", "nei", "sistemi", "di", "dialogo", "per", "vari", "scopi", ",", "tra", "cui", "il", "servizio", "clienti", ",", "l'", "instradamento", "delle", "richieste", "o", "la", "raccolta", "di", "informazioni", "."], "sentence-detokenized": "I chatbot sono tipicamente utilizzati nei sistemi di dialogo per vari scopi, tra cui il servizio clienti, l'instradamento delle richieste o la raccolta di informazioni.", "token2charspan": [[0, 1], [2, 9], [10, 14], [15, 26], [27, 37], [38, 41], [42, 49], [50, 52], [53, 60], [61, 64], [65, 69], [70, 75], [75, 76], [77, 80], [81, 84], [85, 87], [88, 96], [97, 104], [104, 105], [106, 108], [108, 121], [122, 127], [128, 137], [138, 139], [140, 142], [143, 151], [152, 154], [155, 167], [167, 168]]}
{"doc_key": "ai-test-161", "ner": [[8, 14, "conference"], [18, 26, "conference"], [32, 42, "conference"], [50, 50, "conference"], [53, 56, "conference"], [58, 59, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[18, 26, 8, 14, "named", "", false, false], [32, 42, 8, 14, "named", "", false, false], [50, 50, 32, 42, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Tra", "le", "riviste", "pi\u00f9", "importanti", "vi", "sono", "le", "IEEE", "Transactions", "on", "Speech", "and", "Audio", "Processing", "(", "successivamente", "rinominate", "IEEE", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "e", "dal", "settembre", "2014", "rinominate", "IEEE", "/", "ACM", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "-", "dopo", "la", "fusione", "con", "una", "pubblicazione", "ACM", ")", ",", "Computer", "Speech", "and", "Language", "e", "Speech", "Communication", "."], "sentence-detokenized": "Tra le riviste pi\u00f9 importanti vi sono le IEEE Transactions on Speech and Audio Processing (successivamente rinominate IEEE Transactions on Audio, Speech and Language Processing e dal settembre 2014 rinominate IEEE / ACM Transactions on Audio, Speech and Language Processing - dopo la fusione con una pubblicazione ACM), Computer Speech and Language e Speech Communication.", "token2charspan": [[0, 3], [4, 6], [7, 14], [15, 18], [19, 29], [30, 32], [33, 37], [38, 40], [41, 45], [46, 58], [59, 61], [62, 68], [69, 72], [73, 78], [79, 89], [90, 91], [91, 106], [107, 117], [118, 122], [123, 135], [136, 138], [139, 144], [144, 145], [146, 152], [153, 156], [157, 165], [166, 176], [177, 178], [179, 182], [183, 192], [193, 197], [198, 208], [209, 213], [214, 215], [216, 219], [220, 232], [233, 235], [236, 241], [241, 242], [243, 249], [250, 253], [254, 262], [263, 273], [274, 275], [276, 280], [281, 283], [284, 291], [292, 295], [296, 299], [300, 313], [314, 317], [317, 318], [318, 319], [320, 328], [329, 335], [336, 339], [340, 348], [349, 350], [351, 357], [358, 371], [371, 372]]}
{"doc_key": "ai-test-162", "ner": [[0, 1, "algorithm"], [7, 9, "task"], [11, 12, "field"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 9, 0, 1, "usage", "", false, false], [7, 9, 11, 12, "part-of", "task_part_of_field", false, false], [7, 9, 15, 16, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["L'", "EM", "\u00e8", "spesso", "utilizzato", "per", "il", "clustering", "dei", "dati", "nell'", "apprendimento", "automatico", "e", "nella", "visione", "artificiale", "."], "sentence-detokenized": "L'EM \u00e8 spesso utilizzato per il clustering dei dati nell'apprendimento automatico e nella visione artificiale.", "token2charspan": [[0, 2], [2, 4], [5, 6], [7, 13], [14, 24], [25, 28], [29, 31], [32, 42], [43, 46], [47, 51], [52, 57], [57, 70], [71, 81], [82, 83], [84, 89], [90, 97], [98, 109], [109, 110]]}
{"doc_key": "ai-test-163", "ner": [[9, 11, "metrics"], [25, 29, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 25, 29, "related-to", "described_by", false, false]], "relations_mapping_to_source": [0], "sentence": ["Sebbene", "non", "esista", "un", "modo", "perfetto", "per", "descrivere", "la", "matrice", "di", "confusione", "di", "positivi", "e", "negativi", "VERI", "e", "FALSI", "con", "un", "unico", "numero", ",", "il", "coefficiente", "di", "correlazione", "di", "Matthews", "\u00e8", "generalmente", "considerato", "una", "delle", "migliori", "misure", "di", "questo", "tipo", "."], "sentence-detokenized": "Sebbene non esista un modo perfetto per descrivere la matrice di confusione di positivi e negativi VERI e FALSI con un unico numero, il coefficiente di correlazione di Matthews \u00e8 generalmente considerato una delle migliori misure di questo tipo.", "token2charspan": [[0, 7], [8, 11], [12, 18], [19, 21], [22, 26], [27, 35], [36, 39], [40, 50], [51, 53], [54, 61], [62, 64], [65, 75], [76, 78], [79, 87], [88, 89], [90, 98], [99, 103], [104, 105], [106, 111], [112, 115], [116, 118], [119, 124], [125, 131], [131, 132], [133, 135], [136, 148], [149, 151], [152, 164], [165, 167], [168, 176], [177, 178], [179, 191], [192, 203], [204, 207], [208, 213], [214, 222], [223, 229], [230, 232], [233, 239], [240, 244], [244, 245]]}
{"doc_key": "ai-test-164", "ner": [[14, 17, "field"], [35, 35, "field"], [42, 43, "field"], [47, 48, "algorithm"], [51, 53, "task"], [56, 57, "algorithm"], [64, 67, "algorithm"], [70, 71, "algorithm"], [78, 81, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[42, 43, 35, 35, "part-of", "subfield", false, false], [47, 48, 42, 43, "part-of", "", false, true], [51, 53, 42, 43, "part-of", "", false, true], [56, 57, 42, 43, "part-of", "", false, true], [64, 67, 42, 43, "part-of", "", false, true], [70, 71, 42, 43, "part-of", "", false, true], [78, 81, 42, 43, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Con", "l'", "aumento", "delle", "dimensioni", "e", "della", "complessit\u00e0", "degli", "insiemi", "di", "dati", ",", "l'", "analisi", "diretta", "dei", "dati", "\u00e8", "stata", "affiancata", "da", "un'", "elaborazione", "indiretta", "e", "automatizzata", "dei", "dati", ",", "aiutata", "da", "altre", "scoperte", "dell'", "informatica", ",", "in", "particolare", "nel", "campo", "dell'", "apprendimento", "automatico", ",", "come", "le", "reti", "neurali", ",", "l'", "analisi", "dei", "cluster", ",", "gli", "algoritmi", "genetici", "(", "anni", "'50", ")", ",", "l'", "apprendimento", "degli", "alberi", "decisionali", "e", "le", "regole", "decisionali", "(", "anni", "'60", ")", "e", "le", "macchine", "vettoriali", "di", "supporto", "(", "anni", "'90", ")", "."], "sentence-detokenized": "Con l'aumento delle dimensioni e della complessit\u00e0 degli insiemi di dati, l'analisi diretta dei dati \u00e8 stata affiancata da un'elaborazione indiretta e automatizzata dei dati, aiutata da altre scoperte dell'informatica, in particolare nel campo dell'apprendimento automatico, come le reti neurali, l'analisi dei cluster, gli algoritmi genetici (anni '50), l'apprendimento degli alberi decisionali e le regole decisionali (anni '60) e le macchine vettoriali di supporto (anni '90).", "token2charspan": [[0, 3], [4, 6], [6, 13], [14, 19], [20, 30], [31, 32], [33, 38], [39, 50], [51, 56], [57, 64], [65, 67], [68, 72], [72, 73], [74, 76], [76, 83], [84, 91], [92, 95], [96, 100], [101, 102], [103, 108], [109, 119], [120, 122], [123, 126], [126, 138], [139, 148], [149, 150], [151, 164], [165, 168], [169, 173], [173, 174], [175, 182], [183, 185], [186, 191], [192, 200], [201, 206], [206, 217], [217, 218], [219, 221], [222, 233], [234, 237], [238, 243], [244, 249], [249, 262], [263, 273], [273, 274], [275, 279], [280, 282], [283, 287], [288, 295], [295, 296], [297, 299], [299, 306], [307, 310], [311, 318], [318, 319], [320, 323], [324, 333], [334, 342], [343, 344], [344, 348], [349, 352], [352, 353], [353, 354], [355, 357], [357, 370], [371, 376], [377, 383], [384, 395], [396, 397], [398, 400], [401, 407], [408, 419], [420, 421], [421, 425], [426, 429], [429, 430], [431, 432], [433, 435], [436, 444], [445, 455], [456, 458], [459, 467], [468, 469], [469, 473], [474, 477], [477, 478], [478, 479]]}
{"doc_key": "ai-test-165", "ner": [[5, 6, "researcher"], [13, 16, "misc"], [22, 23, "researcher"], [25, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 16, 5, 6, "artifact", "", false, false], [13, 16, 22, 23, "artifact", "", false, false], [13, 16, 25, 26, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Nell'", "autunno", "del", "2005", ",", "Thrun", "ha", "pubblicato", "un", "libro", "di", "testo", "intitolato", "Probabilistic", "Robotics", "insieme", "ai", "suoi", "collaboratori", "di", "lunga", "data", "Dieter", "Fox", "e", "Wolfram", "Burgard", "."], "sentence-detokenized": "Nell'autunno del 2005, Thrun ha pubblicato un libro di testo intitolato Probabilistic Robotics insieme ai suoi collaboratori di lunga data Dieter Fox e Wolfram Burgard.", "token2charspan": [[0, 5], [5, 12], [13, 16], [17, 21], [21, 22], [23, 28], [29, 31], [32, 42], [43, 45], [46, 51], [52, 54], [55, 60], [61, 71], [72, 85], [86, 94], [95, 102], [103, 105], [106, 110], [111, 124], [125, 127], [128, 133], [134, 138], [139, 145], [146, 149], [150, 151], [152, 159], [160, 167], [167, 168]]}
{"doc_key": "ai-test-166", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 7, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["John", "D.", "Lafferty", ",", "Andrew", "McCallum", "e", "Pereiramath", "come", "segue", ":"], "sentence-detokenized": "John D. Lafferty, Andrew McCallum e Pereiramath come segue:", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 24], [25, 33], [34, 35], [36, 47], [48, 52], [53, 58], [58, 59]]}
{"doc_key": "ai-test-167", "ner": [[0, 3, "task"], [5, 5, "task"], [10, 10, "field"], [16, 17, "field"], [20, 23, "field"], [25, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 3, 16, 17, "part-of", "task_part_of_field", false, false], [0, 3, 20, 23, "part-of", "task_part_of_field", false, false], [5, 5, 0, 3, "named", "", false, false], [16, 17, 10, 10, "part-of", "subfield", false, false], [20, 23, 10, 10, "part-of", "subfield", false, false], [25, 25, 20, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["La", "risposta", "alle", "domande", "(", "QA", ")", "\u00e8", "una", "disciplina", "informatica", "che", "rientra", "nei", "campi", "dell'", "information", "retrieval", "e", "dell'", "elaborazione", "del", "linguaggio", "naturale", "(", "NLP", ")", "e", "che", "si", "occupa", "di", "costruire", "sistemi", "che", "rispondano", "automaticamente", "alle", "domande", "poste", "dall'", "uomo", "in", "un", "linguaggio", "naturale", "."], "sentence-detokenized": "La risposta alle domande (QA) \u00e8 una disciplina informatica che rientra nei campi dell'information retrieval e dell'elaborazione del linguaggio naturale (NLP) e che si occupa di costruire sistemi che rispondano automaticamente alle domande poste dall'uomo in un linguaggio naturale.", "token2charspan": [[0, 2], [3, 11], [12, 16], [17, 24], [25, 26], [26, 28], [28, 29], [30, 31], [32, 35], [36, 46], [47, 58], [59, 62], [63, 70], [71, 74], [75, 80], [81, 86], [86, 97], [98, 107], [108, 109], [110, 115], [115, 127], [128, 131], [132, 142], [143, 151], [152, 153], [153, 156], [156, 157], [158, 159], [160, 163], [164, 166], [167, 173], [174, 176], [177, 186], [187, 194], [195, 198], [199, 209], [210, 225], [226, 230], [231, 238], [239, 244], [245, 250], [250, 254], [255, 257], [258, 260], [261, 271], [272, 280], [280, 281]]}
{"doc_key": "ai-test-168", "ner": [[9, 10, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Tuttavia", ",", "nella", "versione", "della", "metrica", "utilizzata", "dalle", "valutazioni", "del", "NIST", "prima", "del", "2009", ",", "veniva", "utilizzata", "la", "frase", "di", "riferimento", "pi\u00f9", "breve", "."], "sentence-detokenized": "Tuttavia, nella versione della metrica utilizzata dalle valutazioni del NIST prima del 2009, veniva utilizzata la frase di riferimento pi\u00f9 breve.", "token2charspan": [[0, 8], [8, 9], [10, 15], [16, 24], [25, 30], [31, 38], [39, 49], [50, 55], [56, 67], [68, 71], [72, 76], [77, 82], [83, 86], [87, 91], [91, 92], [93, 99], [100, 110], [111, 113], [114, 119], [120, 122], [123, 134], [135, 138], [139, 144], [144, 145]]}
{"doc_key": "ai-test-169", "ner": [[5, 6, "person"], [19, 19, "organisation"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 16, 17, "related-to", "invests_in", false, false], [16, 17, 19, 19, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Il", "27", "agosto", "2018", ",", "Toyota", "ha", "annunciato", "un", "investimento", "di", "500", "milioni", "di", "dollari", "nelle", "auto", "autonome", "di", "Uber", "."], "sentence-detokenized": "Il 27 agosto 2018, Toyota ha annunciato un investimento di 500 milioni di dollari nelle auto autonome di Uber.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 17], [17, 18], [19, 25], [26, 28], [29, 39], [40, 42], [43, 55], [56, 58], [59, 62], [63, 70], [71, 73], [74, 81], [82, 87], [88, 92], [93, 101], [102, 104], [105, 109], [109, 110]]}
{"doc_key": "ai-test-170", "ner": [[5, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Il", "massimo", "campionario", "\u00e8", "lo", "stimatore", "di", "massima", "verosimiglianza", "del", "massimo", "della", "popolazione", ",", "ma", ",", "come", "discusso", "in", "precedenza", ",", "\u00e8", "distorto", "."], "sentence-detokenized": "Il massimo campionario \u00e8 lo stimatore di massima verosimiglianza del massimo della popolazione, ma, come discusso in precedenza, \u00e8 distorto.", "token2charspan": [[0, 2], [3, 10], [11, 22], [23, 24], [25, 27], [28, 37], [38, 40], [41, 48], [49, 64], [65, 68], [69, 76], [77, 82], [83, 94], [94, 95], [96, 98], [98, 99], [100, 104], [105, 113], [114, 116], [117, 127], [127, 128], [129, 130], [131, 139], [139, 140]]}
{"doc_key": "ai-test-171", "ner": [[0, 0, "task"], [5, 5, "misc"], [8, 8, "metrics"], [16, 20, "algorithm"], [23, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 5, "related-to", "overcomes", false, false], [0, 0, 8, 8, "related-to", "increases", false, false], [5, 5, 16, 20, "opposite", "", false, false], [5, 5, 23, 26, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LSI", "aiuta", "a", "superare", "la", "sinonimia", "aumentando", "il", "richiamo", ",", "uno", "dei", "vincoli", "pi\u00f9", "problematici", "delle", "query", "di", "parole", "chiave", "booleane", "e", "dei", "modelli", "di", "spazio", "vettoriale", "."], "sentence-detokenized": "LSI aiuta a superare la sinonimia aumentando il richiamo, uno dei vincoli pi\u00f9 problematici delle query di parole chiave booleane e dei modelli di spazio vettoriale.", "token2charspan": [[0, 3], [4, 9], [10, 11], [12, 20], [21, 23], [24, 33], [34, 44], [45, 47], [48, 56], [56, 57], [58, 61], [62, 65], [66, 73], [74, 77], [78, 90], [91, 96], [97, 102], [103, 105], [106, 112], [113, 119], [120, 128], [129, 130], [131, 134], [135, 142], [143, 145], [146, 152], [153, 163], [163, 164]]}
{"doc_key": "ai-test-172", "ner": [[3, 4, "task"], [19, 19, "programlang"], [21, 21, "programlang"], [23, 23, "programlang"], [25, 27, "programlang"], [29, 30, "programlang"], [32, 32, "programlang"], [34, 34, "programlang"], [36, 36, "programlang"], [38, 38, "programlang"], [40, 40, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[3, 4, 19, 19, "general-affiliation", "", false, false], [3, 4, 21, 21, "general-affiliation", "", false, false], [3, 4, 23, 23, "general-affiliation", "", false, false], [3, 4, 25, 27, "general-affiliation", "", false, false], [3, 4, 29, 30, "general-affiliation", "", false, false], [3, 4, 32, 32, "general-affiliation", "", false, false], [3, 4, 34, 34, "general-affiliation", "", false, false], [3, 4, 36, 36, "general-affiliation", "", false, false], [3, 4, 38, 38, "general-affiliation", "", false, false], [3, 4, 40, 40, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Le", "applicazioni", "di", "acquisizione", "dati", "sono", "solitamente", "controllate", "da", "programmi", "software", "sviluppati", "utilizzando", "vari", "linguaggi", "di", "programmazione", "generici", "come", "Assembly", ",", "BASIC", ",", "C", ",", "C", "+", "+", ",", "C", "#", ",", "Fortran", ",", "Java", ",", "LabVIEW", ",", "Lisp", ",", "Pascal", ",", "ecc", "."], "sentence-detokenized": "Le applicazioni di acquisizione dati sono solitamente controllate da programmi software sviluppati utilizzando vari linguaggi di programmazione generici come Assembly, BASIC, C, C + +, C #, Fortran, Java, LabVIEW, Lisp, Pascal, ecc.", "token2charspan": [[0, 2], [3, 15], [16, 18], [19, 31], [32, 36], [37, 41], [42, 53], [54, 65], [66, 68], [69, 78], [79, 87], [88, 98], [99, 110], [111, 115], [116, 125], [126, 128], [129, 143], [144, 152], [153, 157], [158, 166], [166, 167], [168, 173], [173, 174], [175, 176], [176, 177], [178, 179], [180, 181], [182, 183], [183, 184], [185, 186], [187, 188], [188, 189], [190, 197], [197, 198], [199, 203], [203, 204], [205, 212], [212, 213], [214, 218], [218, 219], [220, 226], [226, 227], [228, 231], [231, 232]]}
{"doc_key": "ai-test-173", "ner": [[3, 4, "organisation"], [9, 9, "product"], [11, 12, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 3, 4, "artifact", "", false, false], [9, 9, 11, 12, "physical", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Nel", "2003", ",", "Honda", "ha", "diffuso", "la", "pubblicit\u00e0", "del", "Cog", "nel", "Regno", "Unito", "e", "su", "Internet."], "sentence-detokenized": "Nel 2003, Honda ha diffuso la pubblicit\u00e0 del Cog nel Regno Unito e su Internet.", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 15], [16, 18], [19, 26], [27, 29], [30, 40], [41, 44], [45, 48], [49, 52], [53, 58], [59, 64], [65, 66], [67, 69], [70, 79]]}
{"doc_key": "ai-test-174", "ner": [[1, 4, "conference"], [7, 8, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 4, 7, 8, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["L'", "Association", "for", "Computational", "Linguistics", "definisce", "la", "linguistica", "computazionale", "come", ":"], "sentence-detokenized": "L'Association for Computational Linguistics definisce la linguistica computazionale come:", "token2charspan": [[0, 2], [2, 13], [14, 17], [18, 31], [32, 43], [44, 53], [54, 56], [57, 68], [69, 83], [84, 88], [88, 89]]}
{"doc_key": "ai-test-175", "ner": [[0, 5, "algorithm"], [11, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 5, 11, 15, "related-to", "calculates", false, false]], "relations_mapping_to_source": [0], "sentence": ["Gli", "algoritmi", "di", "massimizzazione", "dell'", "aspettativa", "possono", "essere", "impiegati", "per", "calcolare", "stime", "approssimate", "di", "massima", "verosimiglianza", "dei", "parametri", "sconosciuti", "dello", "spazio", "di", "stato", "all'", "interno", "di", "filtri", "e", "smoothers", "a", "minima", "varianza", "."], "sentence-detokenized": "Gli algoritmi di massimizzazione dell'aspettativa possono essere impiegati per calcolare stime approssimate di massima verosimiglianza dei parametri sconosciuti dello spazio di stato all'interno di filtri e smoothers a minima varianza.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 32], [33, 38], [38, 49], [50, 57], [58, 64], [65, 74], [75, 78], [79, 88], [89, 94], [95, 107], [108, 110], [111, 118], [119, 134], [135, 138], [139, 148], [149, 160], [161, 166], [167, 173], [174, 176], [177, 182], [183, 187], [187, 194], [195, 197], [198, 204], [205, 206], [207, 216], [217, 218], [219, 225], [226, 234], [234, 235]]}
{"doc_key": "ai-test-176", "ner": [[9, 9, "misc"], [10, 12, "person"], [14, 15, "person"], [17, 18, "person"], [22, 24, "misc"], [25, 26, "person"], [30, 31, "person"], [36, 36, "person"], [38, 39, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[10, 12, 9, 9, "role", "actor_in", false, false], [14, 15, 9, 9, "role", "actor_in", false, false], [17, 18, 9, 9, "role", "actor_in", false, false], [25, 26, 22, 24, "role", "model_for", false, false], [36, 36, 38, 39, "social", "family", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Tra", "i", "corrispondenti", "c'", "erano", "le", "ex", "attrici", "di", "Baywatch", "Donna", "D'", "Errico", ",", "Carmen", "Electra", "e", "Traci", "Bingham", ",", "l'", "ex", "Playmate", "di", "Playboy", "Heidi", "Mark", ",", "il", "comico", "Arj", "Barker", "e", "i", "gemelli", "identici", "Randy", "e", "Jason", "Sklar", "."], "sentence-detokenized": "Tra i corrispondenti c'erano le ex attrici di Baywatch Donna D'Errico, Carmen Electra e Traci Bingham, l'ex Playmate di Playboy Heidi Mark, il comico Arj Barker e i gemelli identici Randy e Jason Sklar.", "token2charspan": [[0, 3], [4, 5], [6, 20], [21, 23], [23, 28], [29, 31], [32, 34], [35, 42], [43, 45], [46, 54], [55, 60], [61, 63], [63, 69], [69, 70], [71, 77], [78, 85], [86, 87], [88, 93], [94, 101], [101, 102], [103, 105], [105, 107], [108, 116], [117, 119], [120, 127], [128, 133], [134, 138], [138, 139], [140, 142], [143, 149], [150, 153], [154, 160], [161, 162], [163, 164], [165, 172], [173, 181], [182, 187], [188, 189], [190, 195], [196, 201], [201, 202]]}
{"doc_key": "ai-test-177", "ner": [[8, 9, "task"], [11, 11, "task"], [17, 20, "product"], [25, 26, "task"], [28, 28, "task"], [34, 35, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 8, 9, "named", "", false, false], [17, 20, 8, 9, "general-affiliation", "", false, false], [28, 28, 25, 26, "named", "", false, false], [34, 35, 25, 26, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["\u00c8", "comunemente", "utilizzato", "per", "generare", "rappresentazioni", "per", "il", "riconoscimento", "vocale", "(", "ASR", ")", ",", "ad", "esempio", "il", "sistema", "Sphinx", "della", "CMU", ",", "e", "per", "la", "sintesi", "vocale", "(", "TTS", ")", ",", "ad", "esempio", "il", "sistema", "Festival", "."], "sentence-detokenized": "\u00c8 comunemente utilizzato per generare rappresentazioni per il riconoscimento vocale (ASR), ad esempio il sistema Sphinx della CMU, e per la sintesi vocale (TTS), ad esempio il sistema Festival.", "token2charspan": [[0, 1], [2, 13], [14, 24], [25, 28], [29, 37], [38, 54], [55, 58], [59, 61], [62, 76], [77, 83], [84, 85], [85, 88], [88, 89], [89, 90], [91, 93], [94, 101], [102, 104], [105, 112], [113, 119], [120, 125], [126, 129], [129, 130], [131, 132], [133, 136], [137, 139], [140, 147], [148, 154], [155, 156], [156, 159], [159, 160], [160, 161], [162, 164], [165, 172], [173, 175], [176, 183], [184, 192], [192, 193]]}
{"doc_key": "ai-test-178", "ner": [[0, 1, "metrics"], [3, 6, "metrics"], [8, 8, "metrics"], [14, 14, "metrics"], [32, 33, "metrics"], [35, 35, "metrics"], [47, 48, "metrics"], [50, 50, "metrics"], [52, 54, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 6, 0, 1, "named", "", false, false], [8, 8, 3, 6, "named", "", false, false], [14, 14, 0, 1, "named", "", false, false], [35, 35, 32, 33, "named", "", false, false], [50, 50, 47, 48, "named", "", false, false], [52, 54, 47, 48, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["La", "sensibilit\u00e0", "o", "tasso", "di", "positivit\u00e0", "reale", "(", "TPR", ")", ",", "noto", "anche", "come", "richiamo", ",", "\u00e8", "la", "proporzione", "di", "persone", "che", "sono", "risultate", "positive", "al", "test", "e", "che", "sono", "positive", "(", "positivit\u00e0", "reale", ",", "TP", ")", "rispetto", "a", "tutte", "le", "persone", "che", "sono", "effettivamente", "positive", "(", "condizione", "positiva", ",", "CP", "=", "TP", "+", "FN", ")", "."], "sentence-detokenized": "La sensibilit\u00e0 o tasso di positivit\u00e0 reale (TPR), noto anche come richiamo, \u00e8 la proporzione di persone che sono risultate positive al test e che sono positive (positivit\u00e0 reale, TP) rispetto a tutte le persone che sono effettivamente positive (condizione positiva, CP = TP + FN).", "token2charspan": [[0, 2], [3, 14], [15, 16], [17, 22], [23, 25], [26, 36], [37, 42], [43, 44], [44, 47], [47, 48], [48, 49], [50, 54], [55, 60], [61, 65], [66, 74], [74, 75], [76, 77], [78, 80], [81, 92], [93, 95], [96, 103], [104, 107], [108, 112], [113, 122], [123, 131], [132, 134], [135, 139], [140, 141], [142, 145], [146, 150], [151, 159], [160, 161], [161, 171], [172, 177], [177, 178], [179, 181], [181, 182], [183, 191], [192, 193], [194, 199], [200, 202], [203, 210], [211, 214], [215, 219], [220, 234], [235, 243], [244, 245], [245, 255], [256, 264], [264, 265], [266, 268], [269, 270], [271, 273], [274, 275], [276, 278], [278, 279], [279, 280]]}
{"doc_key": "ai-test-179", "ner": [[2, 4, "task"], [13, 13, "conference"], [15, 16, "conference"], [18, 18, "conference"], [20, 20, "conference"], [22, 22, "conference"], [24, 25, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 13, 2, 4, "topic", "", false, false], [15, 16, 2, 4, "topic", "", false, false], [18, 18, 2, 4, "topic", "", false, false], [20, 20, 2, 4, "topic", "", false, false], [22, 22, 2, 4, "topic", "", false, false], [24, 25, 2, 4, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Le", "conferenze", "sul", "riconoscimento", "vocale", "che", "si", "tengono", "ogni", "anno", "o", "due", "includono", "SpeechTEK", "e", "SpeechTEK", "Europe", ",", "ICASSP", ",", "Interspeech", "/", "Eurospeech", "e", "IEEE", "ASRU."], "sentence-detokenized": "Le conferenze sul riconoscimento vocale che si tengono ogni anno o due includono SpeechTEK e SpeechTEK Europe, ICASSP, Interspeech / Eurospeech e IEEE ASRU.", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 32], [33, 39], [40, 43], [44, 46], [47, 54], [55, 59], [60, 64], [65, 66], [67, 70], [71, 80], [81, 90], [91, 92], [93, 102], [103, 109], [109, 110], [111, 117], [117, 118], [119, 130], [131, 132], [133, 143], [144, 145], [146, 150], [151, 156]]}
{"doc_key": "ai-test-180", "ner": [[0, 1, "researcher"], [4, 4, "researcher"], [18, 19, "product"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 0, 1, "artifact", "", false, false], [23, 23, 4, 4, "artifact", "", false, false], [23, 23, 18, 19, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Devol", "ha", "collaborato", "con", "Engelberger", ",", "che", "\u00e8", "stato", "presidente", "dell'", "azienda", ",", "per", "progettare", "e", "produrre", "un", "robot", "industriale", "con", "il", "marchio", "Unimate", "."], "sentence-detokenized": "Devol ha collaborato con Engelberger, che \u00e8 stato presidente dell'azienda, per progettare e produrre un robot industriale con il marchio Unimate.", "token2charspan": [[0, 5], [6, 8], [9, 20], [21, 24], [25, 36], [36, 37], [38, 41], [42, 43], [44, 49], [50, 60], [61, 66], [66, 73], [73, 74], [75, 78], [79, 89], [90, 91], [92, 100], [101, 103], [104, 109], [110, 121], [122, 125], [126, 128], [129, 136], [137, 144], [144, 145]]}
{"doc_key": "ai-test-181", "ner": [[1, 3, "algorithm"], [5, 5, "algorithm"], [9, 12, "algorithm"], [24, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 3, 9, 12, "general-affiliation", "", false, false], [5, 5, 1, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Un", "modello", "Hidden", "Markov", "(", "HMM", ")", "\u00e8", "un", "modello", "statistico", "di", "Markov", "in", "cui", "si", "assume", "che", "il", "sistema", "da", "modellare", "sia", "un", "processo", "di", "Markov", "con", "stati", "non", "osservati", "(", "nascosti", ")", "."], "sentence-detokenized": "Un modello Hidden Markov (HMM) \u00e8 un modello statistico di Markov in cui si assume che il sistema da modellare sia un processo di Markov con stati non osservati (nascosti).", "token2charspan": [[0, 2], [3, 10], [11, 17], [18, 24], [25, 26], [26, 29], [29, 30], [31, 32], [33, 35], [36, 43], [44, 54], [55, 57], [58, 64], [65, 67], [68, 71], [72, 74], [75, 81], [82, 85], [86, 88], [89, 96], [97, 99], [100, 109], [110, 113], [114, 116], [117, 125], [126, 128], [129, 135], [136, 139], [140, 145], [146, 149], [150, 159], [160, 161], [161, 169], [169, 170], [170, 171]]}
{"doc_key": "ai-test-182", "ner": [[17, 19, "metrics"], [24, 24, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Questa", "propriet\u00e0", ",", "indesiderabile", "in", "molte", "applicazioni", ",", "ha", "portato", "i", "ricercatori", "a", "utilizzare", "alternative", "come", "l'", "errore", "assoluto", "medio", "o", "quelle", "basate", "sulla", "mediana", "."], "sentence-detokenized": "Questa propriet\u00e0, indesiderabile in molte applicazioni, ha portato i ricercatori a utilizzare alternative come l'errore assoluto medio o quelle basate sulla mediana.", "token2charspan": [[0, 6], [7, 16], [16, 17], [18, 32], [33, 35], [36, 41], [42, 54], [54, 55], [56, 58], [59, 66], [67, 68], [69, 80], [81, 82], [83, 93], [94, 105], [106, 110], [111, 113], [113, 119], [120, 128], [129, 134], [135, 136], [137, 143], [144, 150], [151, 156], [157, 164], [164, 165]]}
{"doc_key": "ai-test-183", "ner": [[21, 22, "algorithm"], [29, 30, "field"], [33, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[21, 22, 29, 30, "part-of", "", false, false], [21, 22, 33, 35, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Una", "sequenza", "di", "questo", "tipo", "(", "che", "dipende", "dall'", "esito", "dell'", "indagine", "sugli", "attributi", "precedenti", "in", "ogni", "fase", ")", "\u00e8", "chiamata", "albero", "decisionale", "e", "trova", "applicazione", "nell'", "area", "dell'", "apprendimento", "automatico", "nota", "come", "decision", "tree", "learning", "."], "sentence-detokenized": "Una sequenza di questo tipo (che dipende dall'esito dell'indagine sugli attributi precedenti in ogni fase) \u00e8 chiamata albero decisionale e trova applicazione nell'area dell'apprendimento automatico nota come decision tree learning.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 22], [23, 27], [28, 29], [29, 32], [33, 40], [41, 46], [46, 51], [52, 57], [57, 65], [66, 71], [72, 81], [82, 92], [93, 95], [96, 100], [101, 105], [105, 106], [107, 108], [109, 117], [118, 124], [125, 136], [137, 138], [139, 144], [145, 157], [158, 163], [163, 167], [168, 173], [173, 186], [187, 197], [198, 202], [203, 207], [208, 216], [217, 221], [222, 230], [230, 231]]}
{"doc_key": "ai-test-184", "ner": [[2, 4, "task"], [7, 7, "algorithm"], [24, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 4, 7, 7, "compare", "", false, false], [24, 25, 7, 7, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Come", "nell'", "analisi", "dei", "fattori", ",", "la", "LCA", "pu\u00f2", "essere", "utilizzata", "anche", "per", "classificare", "i", "casi", "in", "base", "alla", "loro", "appartenenza", "alla", "classe", "di", "massima", "verosimiglianza", "."], "sentence-detokenized": "Come nell'analisi dei fattori, la LCA pu\u00f2 essere utilizzata anche per classificare i casi in base alla loro appartenenza alla classe di massima verosimiglianza.", "token2charspan": [[0, 4], [5, 10], [10, 17], [18, 21], [22, 29], [29, 30], [31, 33], [34, 37], [38, 41], [42, 48], [49, 59], [60, 65], [66, 69], [70, 82], [83, 84], [85, 89], [90, 92], [93, 97], [98, 102], [103, 107], [108, 120], [121, 125], [126, 132], [133, 135], [136, 143], [144, 159], [159, 160]]}
{"doc_key": "ai-test-185", "ner": [[0, 3, "algorithm"], [11, 13, "metrics"], [15, 15, "metrics"], [7, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 11, 13, "usage", "", false, false], [11, 13, 7, 10, "related-to", "", false, false], [15, 15, 11, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Le", "reti", "neurali", "supervisionate", "che", "utilizzano", "una", "funzione", "di", "costo", "dell'", "errore", "quadratico", "medio", "(", "MSE", ")", "possono", "utilizzare", "metodi", "statistici", "formali", "per", "determinare", "la", "fiducia", "del", "modello", "addestrato", "."], "sentence-detokenized": "Le reti neurali supervisionate che utilizzano una funzione di costo dell'errore quadratico medio (MSE) possono utilizzare metodi statistici formali per determinare la fiducia del modello addestrato.", "token2charspan": [[0, 2], [3, 7], [8, 15], [16, 30], [31, 34], [35, 45], [46, 49], [50, 58], [59, 61], [62, 67], [68, 73], [73, 79], [80, 90], [91, 96], [97, 98], [98, 101], [101, 102], [103, 110], [111, 121], [122, 128], [129, 139], [140, 147], [148, 151], [152, 163], [164, 166], [167, 174], [175, 178], [179, 186], [187, 197], [197, 198]]}
{"doc_key": "ai-test-186", "ner": [[15, 17, "algorithm"], [20, 24, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 17, 20, 24, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Questo", "pu\u00f2", "essere", "espresso", "direttamente", "come", "un", "programma", "lineare", ",", "ma", "\u00e8", "anche", "equivalente", "alla", "regolarizzazione", "di", "Tikhonov", "con", "la", "funzione", "di", "perdita", "a", "cerniera", ",", "mathV", "(", "f", "(", "x", ")", ",", "y", ")", "=", "\\", "max", "(", "0", ",", "1", "-", "yf", "(", "x", ")", ")", "/", "math", ":"], "sentence-detokenized": "Questo pu\u00f2 essere espresso direttamente come un programma lineare, ma \u00e8 anche equivalente alla regolarizzazione di Tikhonov con la funzione di perdita a cerniera, mathV (f (x), y) =\\ max (0, 1 - yf (x)) / math:", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 26], [27, 39], [40, 44], [45, 47], [48, 57], [58, 65], [65, 66], [67, 69], [70, 71], [72, 77], [78, 89], [90, 94], [95, 111], [112, 114], [115, 123], [124, 127], [128, 130], [131, 139], [140, 142], [143, 150], [151, 152], [153, 161], [161, 162], [163, 168], [169, 170], [170, 171], [172, 173], [173, 174], [174, 175], [175, 176], [177, 178], [178, 179], [180, 181], [181, 182], [183, 186], [187, 188], [188, 189], [189, 190], [191, 192], [193, 194], [195, 197], [198, 199], [199, 200], [200, 201], [201, 202], [203, 204], [205, 209], [209, 210]]}
{"doc_key": "ai-test-187", "ner": [[10, 10, "researcher"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "tecnica", "seguente", "\u00e8", "stata", "descritta", "nell'", "articolo", "originale", "di", "Breiman", "ed", "\u00e8", "implementata", "nel", "pacchetto", "R", "randomForest."], "sentence-detokenized": "La tecnica seguente \u00e8 stata descritta nell'articolo originale di Breiman ed \u00e8 implementata nel pacchetto R randomForest.", "token2charspan": [[0, 2], [3, 10], [11, 19], [20, 21], [22, 27], [28, 37], [38, 43], [43, 51], [52, 61], [62, 64], [65, 72], [73, 75], [76, 77], [78, 90], [91, 94], [95, 104], [105, 106], [107, 120]]}
{"doc_key": "ai-test-188", "ner": [[10, 10, "metrics"], [39, 39, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Le", "misure", "tradizionali", "della", "qualit\u00e0", "delle", "immagini", ",", "come", "il", "PSNR", ",", "sono", "tipicamente", "eseguite", "su", "immagini", "a", "risoluzione", "fissa", "e", "non", "tengono", "conto", "di", "alcuni", "aspetti", "del", "sistema", "visivo", "umano", ",", "come", "la", "variazione", "della", "risoluzione", "spaziale", "sulla", "retina", "."], "sentence-detokenized": "Le misure tradizionali della qualit\u00e0 delle immagini, come il PSNR, sono tipicamente eseguite su immagini a risoluzione fissa e non tengono conto di alcuni aspetti del sistema visivo umano, come la variazione della risoluzione spaziale sulla retina.", "token2charspan": [[0, 2], [3, 9], [10, 22], [23, 28], [29, 36], [37, 42], [43, 51], [51, 52], [53, 57], [58, 60], [61, 65], [65, 66], [67, 71], [72, 83], [84, 92], [93, 95], [96, 104], [105, 106], [107, 118], [119, 124], [125, 126], [127, 130], [131, 138], [139, 144], [145, 147], [148, 154], [155, 162], [163, 166], [167, 174], [175, 181], [182, 187], [187, 188], [189, 193], [194, 196], [197, 207], [208, 213], [214, 225], [226, 234], [235, 240], [241, 247], [247, 248]]}
{"doc_key": "ai-test-189", "ner": [[0, 1, "person"], [3, 4, "person"], [6, 7, "person"], [15, 16, "person"], [17, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 17, 18, "role", "", false, false], [3, 4, 17, 18, "role", "", false, false], [6, 7, 17, 18, "role", "", false, false], [17, 18, 15, 16, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["John", "Ireland", ",", "Joanne", "Dru", "e", "Macdonald", "Carey", "hanno", "recitato", "nella", "produzione", "a", "colori", "di", "Jack", "Broder", "Hannah", "Lee", ",", "che", "ha", "debuttato", "il", "19", "giugno", "1953", "."], "sentence-detokenized": "John Ireland, Joanne Dru e Macdonald Carey hanno recitato nella produzione a colori di Jack Broder Hannah Lee, che ha debuttato il 19 giugno 1953.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 20], [21, 24], [25, 26], [27, 36], [37, 42], [43, 48], [49, 57], [58, 63], [64, 74], [75, 76], [77, 83], [84, 86], [87, 91], [92, 98], [99, 105], [106, 109], [109, 110], [111, 114], [115, 117], [118, 127], [128, 130], [131, 133], [134, 140], [141, 145], [145, 146]]}
{"doc_key": "ai-test-190", "ner": [[4, 6, "task"], [12, 13, "field"], [20, 20, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 12, 13, "usage", "", false, false], [20, 20, 12, 13, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Questo", "processo", "\u00e8", "chiamato", "registrazione", "dell'", "immagine", "e", "utilizza", "diversi", "metodi", "di", "computer", "vision", ",", "per", "lo", "pi\u00f9", "legati", "al", "tracciamento", "."], "sentence-detokenized": "Questo processo \u00e8 chiamato registrazione dell'immagine e utilizza diversi metodi di computer vision, per lo pi\u00f9 legati al tracciamento.", "token2charspan": [[0, 6], [7, 15], [16, 17], [18, 26], [27, 40], [41, 46], [46, 54], [55, 56], [57, 65], [66, 73], [74, 80], [81, 83], [84, 92], [93, 99], [99, 100], [101, 104], [105, 107], [108, 111], [112, 118], [119, 121], [122, 134], [134, 135]]}
{"doc_key": "ai-test-191", "ner": [[16, 18, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ora", "iniziamo", "a", "spiegare", "le", "diverse", "relazioni", "possibili", "tra", "il", "risultato", "previsto", "e", "quello", "effettivo", ":", "Matrice", "di", "confusione"], "sentence-detokenized": "Ora iniziamo a spiegare le diverse relazioni possibili tra il risultato previsto e quello effettivo: Matrice di confusione", "token2charspan": [[0, 3], [4, 12], [13, 14], [15, 23], [24, 26], [27, 34], [35, 44], [45, 54], [55, 58], [59, 61], [62, 71], [72, 80], [81, 82], [83, 89], [90, 99], [99, 100], [101, 108], [109, 111], [112, 122]]}
{"doc_key": "ai-test-192", "ner": [[5, 5, "product"], [1, 4, "misc"], [7, 7, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 1, 4, "part-of", "", false, false], [5, 5, 1, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Il", "toolbox", "di", "elaborazione", "vocale", "VOICEBOX", "per", "MATLAB", "implementa", "la", "conversione", "e", "la", "sua", "inversione", "come", ":"], "sentence-detokenized": "Il toolbox di elaborazione vocale VOICEBOX per MATLAB implementa la conversione e la sua inversione come:", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 26], [27, 33], [34, 42], [43, 46], [47, 53], [54, 64], [65, 67], [68, 79], [80, 81], [82, 84], [85, 88], [89, 99], [100, 104], [104, 105]]}
{"doc_key": "ai-test-193", "ner": [[0, 1, "programlang"], [10, 11, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 10, 11, "general-affiliation", "", false, false], [0, 1, 14, 15, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Il", "Prolog", "\u00e8", "un", "linguaggio", "di", "programmazione", "logica", "associato", "all'", "intelligenza", "artificiale", "e", "alla", "linguistica", "computazionale", "."], "sentence-detokenized": "Il Prolog \u00e8 un linguaggio di programmazione logica associato all'intelligenza artificiale e alla linguistica computazionale.", "token2charspan": [[0, 2], [3, 9], [10, 11], [12, 14], [15, 25], [26, 28], [29, 43], [44, 50], [51, 60], [61, 65], [65, 77], [78, 89], [90, 91], [92, 96], [97, 108], [109, 123], [123, 124]]}
{"doc_key": "ai-test-194", "ner": [[0, 0, "researcher"], [10, 10, "field"], [13, 13, "field"], [20, 23, "organisation"], [26, 29, "organisation"], [32, 35, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 10, 10, "related-to", "works_with_topic", false, false], [0, 0, 13, 13, "related-to", "works_with_topic", false, false], [0, 0, 20, 23, "role", "", false, false], [0, 0, 26, 29, "role", "", false, false], [0, 0, 32, 35, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Milner", "ha", "ricevuto", "numerosi", "riconoscimenti", "per", "i", "suoi", "contributi", "alle", "neuroscienze", "e", "alla", "psicologia", ",", "tra", "cui", "l'", "appartenenza", "alla", "Royal", "Society", "di", "Londra", ",", "alla", "Royal", "Society", "del", "Canada", "e", "alla", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Milner ha ricevuto numerosi riconoscimenti per i suoi contributi alle neuroscienze e alla psicologia, tra cui l'appartenenza alla Royal Society di Londra, alla Royal Society del Canada e alla National Academy of Sciences.", "token2charspan": [[0, 6], [7, 9], [10, 18], [19, 27], [28, 42], [43, 46], [47, 48], [49, 53], [54, 64], [65, 69], [70, 82], [83, 84], [85, 89], [90, 100], [100, 101], [102, 105], [106, 109], [110, 112], [112, 124], [125, 129], [130, 135], [136, 143], [144, 146], [147, 153], [153, 154], [155, 159], [160, 165], [166, 173], [174, 177], [178, 184], [185, 186], [187, 191], [192, 200], [201, 208], [209, 211], [212, 220], [220, 221]]}
{"doc_key": "ai-test-195", "ner": [[10, 13, "field"], [17, 19, "task"], [22, 24, "task"], [27, 29, "task"], [32, 34, "task"], [37, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[17, 19, 10, 13, "part-of", "task_part_of_field", false, false], [22, 24, 10, 13, "part-of", "task_part_of_field", false, false], [27, 29, 10, 13, "part-of", "task_part_of_field", false, false], [32, 34, 10, 13, "part-of", "task_part_of_field", false, false], [37, 37, 10, 13, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Combinando", "questi", "operatori", "si", "possono", "ottenere", "algoritmi", "per", "molte", "attivit\u00e0", "di", "elaborazione", "delle", "immagini", ",", "come", "l'", "estrazione", "di", "caratteristiche", ",", "la", "segmentazione", "delle", "immagini", ",", "la", "nitidezza", "delle", "immagini", ",", "il", "filtraggio", "delle", "immagini", "e", "la", "classificazione", "."], "sentence-detokenized": "Combinando questi operatori si possono ottenere algoritmi per molte attivit\u00e0 di elaborazione delle immagini, come l'estrazione di caratteristiche, la segmentazione delle immagini, la nitidezza delle immagini, il filtraggio delle immagini e la classificazione.", "token2charspan": [[0, 10], [11, 17], [18, 27], [28, 30], [31, 38], [39, 47], [48, 57], [58, 61], [62, 67], [68, 76], [77, 79], [80, 92], [93, 98], [99, 107], [107, 108], [109, 113], [114, 116], [116, 126], [127, 129], [130, 145], [145, 146], [147, 149], [150, 163], [164, 169], [170, 178], [178, 179], [180, 182], [183, 192], [193, 198], [199, 207], [207, 208], [209, 211], [212, 222], [223, 228], [229, 237], [238, 239], [240, 242], [243, 258], [258, 259]]}
{"doc_key": "ai-test-196", "ner": [[5, 7, "university"], [15, 17, "organisation"], [19, 20, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 20, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Dal", "2017", "\u00e8", "professore", "al", "Coll\u00e8ge", "de", "France", "e", ",", "dal", "1989", ",", "direttore", "dell'", "Unit\u00e0", "INSERM", "562", ",", "Neuroimaging", "cognitivo", "."], "sentence-detokenized": "Dal 2017 \u00e8 professore al Coll\u00e8ge de France e, dal 1989, direttore dell'Unit\u00e0 INSERM 562, Neuroimaging cognitivo.", "token2charspan": [[0, 3], [4, 8], [9, 10], [11, 21], [22, 24], [25, 32], [33, 35], [36, 42], [43, 44], [44, 45], [46, 49], [50, 54], [54, 55], [56, 65], [66, 71], [71, 76], [77, 83], [84, 87], [87, 88], [89, 101], [102, 111], [111, 112]]}
{"doc_key": "ai-test-197", "ner": [[12, 15, "algorithm"], [17, 20, "algorithm"], [25, 25, "algorithm"], [27, 33, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[25, 25, 27, 33, "temporal", "", false, true]], "relations_mapping_to_source": [0], "sentence": ["Esistono", "molti", "approcci", "all'", "apprendimento", "di", "queste", "incorporazioni", ",", "in", "particolare", "utilizzando", "framework", "di", "clustering", "bayesiano", "o", "basati", "sull'", "energia", "e", ",", "pi\u00f9", "recentemente", ",", "TransE", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", "2013", ")", "."], "sentence-detokenized": "Esistono molti approcci all'apprendimento di queste incorporazioni, in particolare utilizzando framework di clustering bayesiano o basati sull'energia e, pi\u00f9 recentemente, TransE (Conference on Neural Information Processing Systems 2013).", "token2charspan": [[0, 8], [9, 14], [15, 23], [24, 28], [28, 41], [42, 44], [45, 51], [52, 66], [66, 67], [68, 70], [71, 82], [83, 94], [95, 104], [105, 107], [108, 118], [119, 128], [129, 130], [131, 137], [138, 143], [143, 150], [151, 152], [152, 153], [154, 157], [158, 170], [170, 171], [172, 178], [179, 180], [180, 190], [191, 193], [194, 200], [201, 212], [213, 223], [224, 231], [232, 236], [236, 237], [237, 238]]}
{"doc_key": "ai-test-198", "ner": [[4, 11, "metrics"], [12, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 12, 4, 11, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["\u00c8", "un'", "alternativa", "al", "tasso", "di", "errore", "di", "parola", "(", "Word", "Error", "Rate", ")", "utilizzato", "in", "diversi", "Paesi", "."], "sentence-detokenized": "\u00c8 un'alternativa al tasso di errore di parola (Word Error Rate) utilizzato in diversi Paesi.", "token2charspan": [[0, 1], [2, 5], [5, 16], [17, 19], [20, 25], [26, 28], [29, 35], [36, 38], [39, 45], [46, 47], [47, 51], [52, 57], [58, 62], [62, 63], [64, 74], [75, 77], [78, 85], [86, 91], [91, 92]]}
{"doc_key": "ai-test-199", "ner": [[0, 1, "algorithm"], [14, 15, "task"], [18, 19, "task"], [22, 23, "task"], [26, 29, "task"], [32, 38, "task"], [41, 42, "task"], [56, 56, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[14, 15, 0, 1, "usage", "", false, false], [18, 19, 0, 1, "usage", "", false, false], [22, 23, 0, 1, "usage", "", false, false], [26, 29, 0, 1, "usage", "", false, false], [32, 38, 0, 1, "usage", "", false, false], [41, 42, 0, 1, "usage", "", false, false], [56, 56, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Le", "RNA", "sono", "state", "utilizzate", "per", "una", "variet\u00e0", "di", "compiti", ",", "tra", "cui", "la", "visione", "computerizzata", ",", "il", "riconoscimento", "vocale", ",", "la", "traduzione", "automatica", ",", "il", "filtraggio", "dei", "social", "network", ",", "la", "riproduzione", "di", "giochi", "da", "tavolo", "e", "videogiochi", ",", "la", "diagnosi", "medica", "e", "persino", "in", "attivit\u00e0", "tradizionalmente", "considerate", "riservate", "agli", "esseri", "umani", ",", "come", "la", "pittura", "."], "sentence-detokenized": "Le RNA sono state utilizzate per una variet\u00e0 di compiti, tra cui la visione computerizzata, il riconoscimento vocale, la traduzione automatica, il filtraggio dei social network, la riproduzione di giochi da tavolo e videogiochi, la diagnosi medica e persino in attivit\u00e0 tradizionalmente considerate riservate agli esseri umani, come la pittura.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 17], [18, 28], [29, 32], [33, 36], [37, 44], [45, 47], [48, 55], [55, 56], [57, 60], [61, 64], [65, 67], [68, 75], [76, 90], [90, 91], [92, 94], [95, 109], [110, 116], [116, 117], [118, 120], [121, 131], [132, 142], [142, 143], [144, 146], [147, 157], [158, 161], [162, 168], [169, 176], [176, 177], [178, 180], [181, 193], [194, 196], [197, 203], [204, 206], [207, 213], [214, 215], [216, 227], [227, 228], [229, 231], [232, 240], [241, 247], [248, 249], [250, 257], [258, 260], [261, 269], [270, 286], [287, 298], [299, 308], [309, 313], [314, 320], [321, 326], [326, 327], [328, 332], [333, 335], [336, 343], [343, 344]]}
{"doc_key": "ai-test-200", "ner": [[0, 3, "product"], [5, 5, "product"], [22, 37, "field"], [39, 39, "field"], [43, 43, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 22, 37, "related-to", "", false, false], [0, 3, 43, 43, "general-affiliation", "", false, false], [5, 5, 0, 3, "named", "", false, false], [39, 39, 22, 37, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Modular", "Audio", "Recognition", "Framework", "(", "MARF", ")", "\u00e8", "una", "piattaforma", "di", "ricerca", "open", "-", "source", "e", "una", "raccolta", "di", "algoritmi", "per", "l'", "elaborazione", "della", "voce", ",", "del", "suono", ",", "del", "parlato", ",", "del", "testo", "e", "del", "linguaggio", "naturale", "(", "NLP", ")", "scritti", "in", "Java", "e", "organizzati", "in", "un", "framework", "modulare", "ed", "estensibile", "che", "cerca", "di", "facilitare", "l'", "aggiunta", "di", "nuovi", "algoritmi", "."], "sentence-detokenized": "Modular Audio Recognition Framework (MARF) \u00e8 una piattaforma di ricerca open-source e una raccolta di algoritmi per l'elaborazione della voce, del suono, del parlato, del testo e del linguaggio naturale (NLP) scritti in Java e organizzati in un framework modulare ed estensibile che cerca di facilitare l'aggiunta di nuovi algoritmi.", "token2charspan": [[0, 7], [8, 13], [14, 25], [26, 35], [36, 37], [37, 41], [41, 42], [43, 44], [45, 48], [49, 60], [61, 63], [64, 71], [72, 76], [76, 77], [77, 83], [84, 85], [86, 89], [90, 98], [99, 101], [102, 111], [112, 115], [116, 118], [118, 130], [131, 136], [137, 141], [141, 142], [143, 146], [147, 152], [152, 153], [154, 157], [158, 165], [165, 166], [167, 170], [171, 176], [177, 178], [179, 182], [183, 193], [194, 202], [203, 204], [204, 207], [207, 208], [209, 216], [217, 219], [220, 224], [225, 226], [227, 238], [239, 241], [242, 244], [245, 254], [255, 263], [264, 266], [267, 278], [279, 282], [283, 288], [289, 291], [292, 302], [303, 305], [305, 313], [314, 316], [317, 322], [323, 332], [332, 333]]}
{"doc_key": "ai-test-201", "ner": [[16, 18, "organisation"], [26, 28, "country"], [31, 33, "organisation"], [36, 37, "organisation"], [41, 42, "task"], [65, 68, "organisation"], [61, 62, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[31, 33, 26, 28, "physical", "", false, false], [31, 33, 41, 42, "usage", "", false, false], [31, 33, 65, 68, "named", "", false, false], [36, 37, 26, 28, "physical", "", false, false], [36, 37, 41, 42, "usage", "", false, false], [65, 68, 61, 62, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Nel", "2018", ",", "un", "rapporto", "dell'", "organizzazione", "per", "la", "difesa", "delle", "libert\u00e0", "civili", "e", "dei", "diritti", "Big", "Brother", "Watch", "ha", "rivelato", "che", "due", "forze", "di", "polizia", "del", "Regno", "Unito", ",", "la", "South", "Wales", "Police", "e", "la", "Metropolitan", "Police", ",", "utilizzavano", "il", "riconoscimento", "facciale", "in", "diretta", "durante", "gli", "eventi", "pubblici", "e", "negli", "spazi", "pubblici", ";", "nel", "settembre", "2019", ",", "l'", "uso", "del", "riconoscimento", "facciale", "da", "parte", "della", "South", "Wales", "Police", "\u00e8", "stato", "dichiarato", "legale", "."], "sentence-detokenized": "Nel 2018, un rapporto dell'organizzazione per la difesa delle libert\u00e0 civili e dei diritti Big Brother Watch ha rivelato che due forze di polizia del Regno Unito, la South Wales Police e la Metropolitan Police, utilizzavano il riconoscimento facciale in diretta durante gli eventi pubblici e negli spazi pubblici; nel settembre 2019, l'uso del riconoscimento facciale da parte della South Wales Police \u00e8 stato dichiarato legale.", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 12], [13, 21], [22, 27], [27, 41], [42, 45], [46, 48], [49, 55], [56, 61], [62, 69], [70, 76], [77, 78], [79, 82], [83, 90], [91, 94], [95, 102], [103, 108], [109, 111], [112, 120], [121, 124], [125, 128], [129, 134], [135, 137], [138, 145], [146, 149], [150, 155], [156, 161], [161, 162], [163, 165], [166, 171], [172, 177], [178, 184], [185, 186], [187, 189], [190, 202], [203, 209], [209, 210], [211, 223], [224, 226], [227, 241], [242, 250], [251, 253], [254, 261], [262, 269], [270, 273], [274, 280], [281, 289], [290, 291], [292, 297], [298, 303], [304, 312], [312, 313], [314, 317], [318, 327], [328, 332], [332, 333], [334, 336], [336, 339], [340, 343], [344, 358], [359, 367], [368, 370], [371, 376], [377, 382], [383, 388], [389, 394], [395, 401], [402, 403], [404, 409], [410, 420], [421, 427], [427, 428]]}
{"doc_key": "ai-test-202", "ner": [[0, 0, "product"], [5, 5, "programlang"], [16, 17, "field"], [20, 20, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 5, "general-affiliation", "", false, false], [0, 0, 16, 17, "related-to", "", false, false], [0, 0, 20, 20, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["ANIMAL", "\u00e8", "stato", "portato", "in", "R", ",", "un", "linguaggio", "e", "un", "ambiente", "liberamente", "disponibili", "per", "il", "calcolo", "statistico", "e", "la", "grafica", "."], "sentence-detokenized": "ANIMAL \u00e8 stato portato in R, un linguaggio e un ambiente liberamente disponibili per il calcolo statistico e la grafica.", "token2charspan": [[0, 6], [7, 8], [9, 14], [15, 22], [23, 25], [26, 27], [27, 28], [29, 31], [32, 42], [43, 44], [45, 47], [48, 56], [57, 68], [69, 80], [81, 84], [85, 87], [88, 95], [96, 106], [107, 108], [109, 111], [112, 119], [119, 120]]}
{"doc_key": "ai-test-203", "ner": [[0, 6, "algorithm"], [8, 10, "algorithm"], [16, 19, "algorithm"], [21, 21, "algorithm"], [25, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 6, 16, 19, "opposite", "alternative to", false, false], [8, 10, 0, 6, "named", "", false, false], [21, 21, 16, 19, "named", "", false, false], [25, 28, 0, 6, "usage", "", false, false], [25, 28, 16, 19, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Il", "modello", "di", "Bernoulli", "nascosto", "temporalmente", "omogeneo", "(", "TI", "-", "HBM", ")", "\u00e8", "un'", "alternativa", "al", "modello", "di", "Markov", "nascosto", "(", "HMM", ")", "per", "il", "riconoscimento", "automatico", "del", "parlato", "."], "sentence-detokenized": "Il modello di Bernoulli nascosto temporalmente omogeneo (TI-HBM) \u00e8 un'alternativa al modello di Markov nascosto (HMM) per il riconoscimento automatico del parlato.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 23], [24, 32], [33, 46], [47, 55], [56, 57], [57, 59], [59, 60], [60, 63], [63, 64], [65, 66], [67, 70], [70, 81], [82, 84], [85, 92], [93, 95], [96, 102], [103, 111], [112, 113], [113, 116], [116, 117], [118, 121], [122, 124], [125, 139], [140, 150], [151, 154], [155, 162], [162, 163]]}
{"doc_key": "ai-test-204", "ner": [[4, 5, "organisation"], [9, 9, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 9, 9, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Nel", "luglio", "2016", ",", "Nvidia", "ha", "dimostrato", "durante", "il", "SIGGRAPH", "un", "nuovo", "metodo", "di", "rendering", "foveated", "che", "si", "afferma", "essere", "invisibile", "agli", "utenti", "."], "sentence-detokenized": "Nel luglio 2016, Nvidia ha dimostrato durante il SIGGRAPH un nuovo metodo di rendering foveated che si afferma essere invisibile agli utenti.", "token2charspan": [[0, 3], [4, 10], [11, 15], [15, 16], [17, 23], [24, 26], [27, 37], [38, 45], [46, 48], [49, 57], [58, 60], [61, 66], [67, 73], [74, 76], [77, 86], [87, 95], [96, 99], [100, 102], [103, 110], [111, 117], [118, 128], [129, 133], [134, 140], [140, 141]]}
{"doc_key": "ai-test-205", "ner": [[4, 8, "misc"], [11, 12, "researcher"], [19, 20, "researcher"], [22, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 8, 11, 12, "origin", "", false, false], [4, 8, 19, 20, "origin", "", false, false], [4, 8, 22, 22, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Entrambi", "si", "basano", "sulla", "teoria", "degli", "atti", "di", "parola", "sviluppata", "da", "John", "Searle", "negli", "anni", "Sessanta", "e", "migliorata", "da", "Terry", "Winograd", "e", "Flores", "negli", "anni", "Settanta", "."], "sentence-detokenized": "Entrambi si basano sulla teoria degli atti di parola sviluppata da John Searle negli anni Sessanta e migliorata da Terry Winograd e Flores negli anni Settanta.", "token2charspan": [[0, 8], [9, 11], [12, 18], [19, 24], [25, 31], [32, 37], [38, 42], [43, 45], [46, 52], [53, 63], [64, 66], [67, 71], [72, 78], [79, 84], [85, 89], [90, 98], [99, 100], [101, 111], [112, 114], [115, 120], [121, 129], [130, 131], [132, 138], [139, 144], [145, 149], [150, 158], [158, 159]]}
{"doc_key": "ai-test-206", "ner": [[0, 4, "algorithm"], [28, 29, "researcher"], [26, 26, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 28, 29, "related-to", "", false, false], [26, 26, 28, 29, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["I", "modelli", "di", "reti", "neurali", "sulla", "formazione", "dei", "concetti", "e", "sulla", "struttura", "della", "conoscenza", "hanno", "aperto", "potenti", "modelli", "gerarchici", "di", "organizzazione", "della", "conoscenza", ",", "come", "la", "Wordnet", "di", "George", "Miller", "."], "sentence-detokenized": "I modelli di reti neurali sulla formazione dei concetti e sulla struttura della conoscenza hanno aperto potenti modelli gerarchici di organizzazione della conoscenza, come la Wordnet di George Miller.", "token2charspan": [[0, 1], [2, 9], [10, 12], [13, 17], [18, 25], [26, 31], [32, 42], [43, 46], [47, 55], [56, 57], [58, 63], [64, 73], [74, 79], [80, 90], [91, 96], [97, 103], [104, 111], [112, 119], [120, 130], [131, 133], [134, 148], [149, 154], [155, 165], [165, 166], [167, 171], [172, 174], [175, 182], [183, 185], [186, 192], [193, 199], [199, 200]]}
{"doc_key": "ai-test-207", "ner": [[0, 3, "algorithm"], [14, 16, "field"], [19, 22, "product"], [26, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 14, 16, "part-of", "", false, false], [0, 3, 26, 29, "part-of", "", false, false], [19, 22, 14, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "corrispondenza", "dei", "modelli", "ha", "diverse", "applicazioni", "e", "viene", "utilizzata", "in", "campi", "quali", "il", "riconoscimento", "dei", "volti", "(", "vedi", "sistema", "di", "riconoscimento", "facciale", ")", "e", "l'", "elaborazione", "di", "immagini", "mediche", "."], "sentence-detokenized": "La corrispondenza dei modelli ha diverse applicazioni e viene utilizzata in campi quali il riconoscimento dei volti (vedi sistema di riconoscimento facciale) e l'elaborazione di immagini mediche.", "token2charspan": [[0, 2], [3, 17], [18, 21], [22, 29], [30, 32], [33, 40], [41, 53], [54, 55], [56, 61], [62, 72], [73, 75], [76, 81], [82, 87], [88, 90], [91, 105], [106, 109], [110, 115], [116, 117], [117, 121], [122, 129], [130, 132], [133, 147], [148, 156], [156, 157], [158, 159], [160, 162], [162, 174], [175, 177], [178, 186], [187, 194], [194, 195]]}
{"doc_key": "ai-test-208", "ner": [[12, 13, "researcher"], [15, 16, "researcher"], [20, 29, "organisation"], [31, 31, "organisation"], [41, 42, "algorithm"], [44, 50, "conference"], [52, 52, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 13, 20, 29, "role", "", false, false], [12, 13, 44, 50, "physical", "", false, false], [12, 13, 44, 50, "temporal", "", false, false], [12, 13, 52, 52, "physical", "", false, false], [15, 16, 20, 29, "role", "", false, false], [15, 16, 44, 50, "temporal", "", false, false], [31, 31, 20, 29, "named", "", false, false], [44, 50, 41, 42, "topic", "", false, false], [52, 52, 44, 50, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Tuttavia", ",", "l'", "uso", "si", "\u00e8", "diffuso", "solo", "nel", "2005", ",", "quando", "Navneet", "Dalal", "e", "Bill", "Triggs", ",", "ricercatori", "dell'", "Istituto", "Nazionale", "Francese", "per", "la", "Ricerca", "in", "Informatica", "e", "Automazione", "(", "INRIA", ")", ",", "hanno", "presentato", "il", "loro", "lavoro", "supplementare", "sui", "descrittori", "HOG", "alla", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "."], "sentence-detokenized": "Tuttavia, l'uso si \u00e8 diffuso solo nel 2005, quando Navneet Dalal e Bill Triggs, ricercatori dell'Istituto Nazionale Francese per la Ricerca in Informatica e Automazione (INRIA), hanno presentato il loro lavoro supplementare sui descrittori HOG alla Conference on Computer Vision and Pattern Recognition (CVPR).", "token2charspan": [[0, 8], [8, 9], [10, 12], [12, 15], [16, 18], [19, 20], [21, 28], [29, 33], [34, 37], [38, 42], [42, 43], [44, 50], [51, 58], [59, 64], [65, 66], [67, 71], [72, 78], [78, 79], [80, 91], [92, 97], [97, 105], [106, 115], [116, 124], [125, 128], [129, 131], [132, 139], [140, 142], [143, 154], [155, 156], [157, 168], [169, 170], [170, 175], [175, 176], [176, 177], [178, 183], [184, 194], [195, 197], [198, 202], [203, 209], [210, 223], [224, 227], [228, 239], [240, 243], [244, 248], [249, 259], [260, 262], [263, 271], [272, 278], [279, 282], [283, 290], [291, 302], [303, 304], [304, 308], [308, 309], [309, 310]]}
{"doc_key": "ai-test-209", "ner": [[8, 9, "university"], [24, 27, "organisation"], [30, 31, "organisation"], [39, 39, "field"], [43, 45, "researcher"], [47, 49, "researcher"], [51, 53, "researcher"], [56, 61, "organisation"], [64, 67, "organisation"], [71, 72, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[30, 31, 39, 39, "related-to", "", false, false], [43, 45, 30, 31, "physical", "", false, false], [43, 45, 30, 31, "role", "", false, false], [47, 49, 30, 31, "physical", "", false, false], [47, 49, 30, 31, "role", "", false, false], [51, 53, 30, 31, "physical", "", false, false], [51, 53, 30, 31, "role", "", false, false], [71, 72, 64, 67, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Prima", "di", "entrare", "a", "far", "parte", "della", "facolt\u00e0", "della", "Penn", "nel", "2002", ",", "ha", "trascorso", "un", "decennio", "(", "1991", "-", "2001", ")", "presso", "gli", "AT", "&", "T", "Labs", "e", "i", "Bell", "Labs", ",", "anche", "come", "capo", "del", "dipartimento", "di", "IA", "con", "colleghi", "quali", "Michael", "L.", "Littman", ",", "David", "A.", "McAllester", "e", "Richard", "S.", "Sutton", ";", "del", "dipartimento", "di", "ricerca", "sui", "sistemi", "sicuri", "e", "del", "dipartimento", "di", "apprendimento", "automatico", "con", "membri", "quali", "Michael", "Collins", "e", "il", "leader", ")", "."], "sentence-detokenized": "Prima di entrare a far parte della facolt\u00e0 della Penn nel 2002, ha trascorso un decennio (1991-2001) presso gli AT & T Labs e i Bell Labs, anche come capo del dipartimento di IA con colleghi quali Michael L. Littman, David A. McAllester e Richard S. Sutton; del dipartimento di ricerca sui sistemi sicuri e del dipartimento di apprendimento automatico con membri quali Michael Collins e il leader).", "token2charspan": [[0, 5], [6, 8], [9, 16], [17, 18], [19, 22], [23, 28], [29, 34], [35, 42], [43, 48], [49, 53], [54, 57], [58, 62], [62, 63], [64, 66], [67, 76], [77, 79], [80, 88], [89, 90], [90, 94], [94, 95], [95, 99], [99, 100], [101, 107], [108, 111], [112, 114], [115, 116], [117, 118], [119, 123], [124, 125], [126, 127], [128, 132], [133, 137], [137, 138], [139, 144], [145, 149], [150, 154], [155, 158], [159, 171], [172, 174], [175, 177], [178, 181], [182, 190], [191, 196], [197, 204], [205, 207], [208, 215], [215, 216], [217, 222], [223, 225], [226, 236], [237, 238], [239, 246], [247, 249], [250, 256], [256, 257], [258, 261], [262, 274], [275, 277], [278, 285], [286, 289], [290, 297], [298, 304], [305, 306], [307, 310], [311, 323], [324, 326], [327, 340], [341, 351], [352, 355], [356, 362], [363, 368], [369, 376], [377, 384], [385, 386], [387, 389], [390, 396], [396, 397], [397, 398]]}
{"doc_key": "ai-test-210", "ner": [[8, 9, "field"], [19, 21, "field"], [27, 30, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 19, 21, "compare", "", false, false], [27, 30, 19, 21, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Quando", "i", "dati", "non", "sono", "etichettati", ",", "l'", "apprendimento", "supervisionato", "non", "\u00e8", "possibile", "ed", "\u00e8", "necessario", "un", "approccio", "di", "apprendimento", "non", "supervisionato", "che", "cerchi", "di", "trovare", "un'", "analisi", "naturale", "dei", "cluster", "in", "gruppi", "e", "quindi", "di", "mappare", "i", "nuovi", "dati", "in", "questi", "gruppi", "formati", "."], "sentence-detokenized": "Quando i dati non sono etichettati, l'apprendimento supervisionato non \u00e8 possibile ed \u00e8 necessario un approccio di apprendimento non supervisionato che cerchi di trovare un'analisi naturale dei cluster in gruppi e quindi di mappare i nuovi dati in questi gruppi formati.", "token2charspan": [[0, 6], [7, 8], [9, 13], [14, 17], [18, 22], [23, 34], [34, 35], [36, 38], [38, 51], [52, 66], [67, 70], [71, 72], [73, 82], [83, 85], [86, 87], [88, 98], [99, 101], [102, 111], [112, 114], [115, 128], [129, 132], [133, 147], [148, 151], [152, 158], [159, 161], [162, 169], [170, 173], [173, 180], [181, 189], [190, 193], [194, 201], [202, 204], [205, 211], [212, 213], [214, 220], [221, 223], [224, 231], [232, 233], [234, 239], [240, 244], [245, 247], [248, 254], [255, 261], [262, 269], [269, 270]]}
{"doc_key": "ai-test-211", "ner": [[3, 3, "field"], [15, 18, "organisation"], [24, 25, "field"], [28, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 15, 18, "origin", "", false, false], [3, 3, 24, 25, "part-of", "", false, false], [3, 3, 28, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Questo", "settore", "dell'", "informatica", "si", "\u00e8", "sviluppato", "negli", "anni", "'50", "presso", "istituzioni", "accademiche", "come", "il", "MIT", "A.I", ".", "Lab", ",", "originariamente", "come", "branca", "dell'", "intelligenza", "artificiale", "e", "della", "robotica", "."], "sentence-detokenized": "Questo settore dell'informatica si \u00e8 sviluppato negli anni '50 presso istituzioni accademiche come il MIT A.I. Lab, originariamente come branca dell'intelligenza artificiale e della robotica.", "token2charspan": [[0, 6], [7, 14], [15, 20], [20, 31], [32, 34], [35, 36], [37, 47], [48, 53], [54, 58], [59, 62], [63, 69], [70, 81], [82, 93], [94, 98], [99, 101], [102, 105], [106, 109], [109, 110], [111, 114], [114, 115], [116, 131], [132, 136], [137, 143], [144, 149], [149, 161], [162, 173], [174, 175], [176, 181], [182, 190], [190, 191]]}
{"doc_key": "ai-test-212", "ner": [[8, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Si", "potrebbe", "anche", "sostituirla", "con", "l'", "equazione", "della", "perdita", "logica", "riportata", "di", "seguito", ":"], "sentence-detokenized": "Si potrebbe anche sostituirla con l'equazione della perdita logica riportata di seguito:", "token2charspan": [[0, 2], [3, 11], [12, 17], [18, 29], [30, 33], [34, 36], [36, 45], [46, 51], [52, 59], [60, 66], [67, 76], [77, 79], [80, 87], [87, 88]]}
{"doc_key": "ai-test-213", "ner": [[1, 3, "organisation"], [6, 9, "organisation"], [13, 17, "university"], [20, 20, "university"], [23, 25, "university"], [28, 30, "university"], [32, 33, "country"], [40, 40, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[1, 3, 40, 40, "related-to", "research_leader_in_field", false, false], [6, 9, 1, 3, "named", "", false, false], [6, 9, 40, 40, "related-to", "research_leader_in_field", false, false], [13, 17, 40, 40, "related-to", "research_leader_in_field", false, false], [20, 20, 40, 40, "related-to", "research_leader_in_field", false, false], [23, 25, 40, 40, "related-to", "research_leader_in_field", false, false], [28, 30, 32, 33, "physical", "", false, false], [28, 30, 40, 40, "related-to", "research_leader_in_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Lo", "Shirley", "Ryan", "AbilityLab", "(", "ex", "Rehabilitation", "Institute", "of", "Chicago", ")", ",", "l'", "Universit\u00e0", "della", "California", "a", "Berkeley", ",", "il", "MIT", ",", "l'", "Universit\u00e0", "di", "Stanford", "e", "l'", "Universit\u00e0", "di", "Twente", "nei", "Paesi", "Bassi", "sono", "i", "leader", "della", "ricerca", "sulla", "biomeccatronica", "."], "sentence-detokenized": "Lo Shirley Ryan AbilityLab (ex Rehabilitation Institute of Chicago), l'Universit\u00e0 della California a Berkeley, il MIT, l'Universit\u00e0 di Stanford e l'Universit\u00e0 di Twente nei Paesi Bassi sono i leader della ricerca sulla biomeccatronica.", "token2charspan": [[0, 2], [3, 10], [11, 15], [16, 26], [27, 28], [28, 30], [31, 45], [46, 55], [56, 58], [59, 66], [66, 67], [67, 68], [69, 71], [71, 81], [82, 87], [88, 98], [99, 100], [101, 109], [109, 110], [111, 113], [114, 117], [117, 118], [119, 121], [121, 131], [132, 134], [135, 143], [144, 145], [146, 148], [148, 158], [159, 161], [162, 168], [169, 172], [173, 178], [179, 184], [185, 189], [190, 191], [192, 198], [199, 204], [205, 212], [213, 218], [219, 234], [234, 235]]}
{"doc_key": "ai-test-214", "ner": [[31, 35, "metrics"], [45, 47, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Dato", "un", "insieme", "di", "valori", "previsti", "e", "un", "corrispondente", "insieme", "di", "valori", "effettivi", "per", "X", "per", "vari", "periodi", "di", "tempo", ",", "una", "tecnica", "di", "valutazione", "comune", "\u00e8", "quella", "di", "utilizzare", "l'", "errore", "medio", "quadratico", "di", "previsione", ";", "sono", "disponibili", "anche", "altre", "misure", "(", "vedi", "previsione", "#accuratezza", "della", "previsione", ")", "."], "sentence-detokenized": "Dato un insieme di valori previsti e un corrispondente insieme di valori effettivi per X per vari periodi di tempo, una tecnica di valutazione comune \u00e8 quella di utilizzare l'errore medio quadratico di previsione; sono disponibili anche altre misure (vedi previsione #accuratezza della previsione).", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 25], [26, 34], [35, 36], [37, 39], [40, 54], [55, 62], [63, 65], [66, 72], [73, 82], [83, 86], [87, 88], [89, 92], [93, 97], [98, 105], [106, 108], [109, 114], [114, 115], [116, 119], [120, 127], [128, 130], [131, 142], [143, 149], [150, 151], [152, 158], [159, 161], [162, 172], [173, 175], [175, 181], [182, 187], [188, 198], [199, 201], [202, 212], [212, 213], [214, 218], [219, 230], [231, 236], [237, 242], [243, 249], [250, 251], [251, 255], [256, 266], [267, 279], [280, 285], [286, 296], [296, 297], [297, 298]]}
{"doc_key": "ai-test-215", "ner": [[12, 12, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Altre", "misure", ",", "come", "la", "percentuale", "di", "previsioni", "corrette", "(", "definita", "anche", "accuratezza", ")", ",", "non", "sono", "utili", "quando", "le", "due", "classi", "sono", "di", "dimensioni", "molto", "diverse", "."], "sentence-detokenized": "Altre misure, come la percentuale di previsioni corrette (definita anche accuratezza), non sono utili quando le due classi sono di dimensioni molto diverse.", "token2charspan": [[0, 5], [6, 12], [12, 13], [14, 18], [19, 21], [22, 33], [34, 36], [37, 47], [48, 56], [57, 58], [58, 66], [67, 72], [73, 84], [84, 85], [85, 86], [87, 90], [91, 95], [96, 101], [102, 108], [109, 111], [112, 115], [116, 122], [123, 127], [128, 130], [131, 141], [142, 147], [148, 155], [155, 156]]}
{"doc_key": "ai-test-216", "ner": [[5, 5, "product"], [16, 20, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 16, 20, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["La", "prima", "versione", "alfa", "di", "OpenCV", "\u00e8", "stata", "rilasciata", "al", "pubblico", "in", "occasione", "della", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "del", "2000", ",", "mentre", "tra", "il", "2001", "e", "il", "2005", "sono", "state", "rilasciate", "cinque", "versioni", "beta", "."], "sentence-detokenized": "La prima versione alfa di OpenCV \u00e8 stata rilasciata al pubblico in occasione della Conference on Computer Vision and Pattern Recognition del 2000, mentre tra il 2001 e il 2005 sono state rilasciate cinque versioni beta.", "token2charspan": [[0, 2], [3, 8], [9, 17], [18, 22], [23, 25], [26, 32], [33, 34], [35, 40], [41, 51], [52, 54], [55, 63], [64, 66], [67, 76], [77, 82], [83, 93], [94, 96], [97, 105], [106, 112], [113, 116], [117, 124], [125, 136], [137, 140], [141, 145], [145, 146], [147, 153], [154, 157], [158, 160], [161, 165], [166, 167], [168, 170], [171, 175], [176, 180], [181, 186], [187, 197], [198, 204], [205, 213], [214, 218], [218, 219]]}
{"doc_key": "ai-test-217", "ner": [[24, 24, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sono", "stati", "presentati", "risultati", "che", "danno", "una", "correlazione", "fino", "a", "0,964", "con", "il", "giudizio", "umano", "a", "livello", "di", "corpus", ",", "rispetto", "al", "risultato", "di", "BLEU", "di", "0,817", "sullo", "stesso", "set", "di", "dati", "."], "sentence-detokenized": "Sono stati presentati risultati che danno una correlazione fino a 0,964 con il giudizio umano a livello di corpus, rispetto al risultato di BLEU di 0,817 sullo stesso set di dati.", "token2charspan": [[0, 4], [5, 10], [11, 21], [22, 31], [32, 35], [36, 41], [42, 45], [46, 58], [59, 63], [64, 65], [66, 71], [72, 75], [76, 78], [79, 87], [88, 93], [94, 95], [96, 103], [104, 106], [107, 113], [113, 114], [115, 123], [124, 126], [127, 136], [137, 139], [140, 144], [145, 147], [148, 153], [154, 159], [160, 166], [167, 170], [171, 173], [174, 178], [178, 179]]}
{"doc_key": "ai-test-218", "ner": [[4, 7, "metrics"], [19, 19, "metrics"], [21, 23, "metrics"], [25, 28, "metrics"], [38, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 7, 19, 19, "compare", "", false, false], [4, 7, 21, 23, "compare", "", false, false], [4, 7, 25, 28, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Una", "prima", "versione", "di", "VMAF", "ha", "dimostrato", "di", "superare", "altre", "metriche", "di", "qualit\u00e0", "delle", "immagini", "e", "dei", "video", "come", "SSIM", ",", "PSNR", "-", "HVS", "e", "VQM", "-", "VFD", "su", "tre", "dei", "quattro", "set", "di", "dati", "in", "termini", "di", "accuratezza", "della", "previsione", ",", "se", "confrontata", "con", "le", "valutazioni", "soggettive", "."], "sentence-detokenized": "Una prima versione di VMAF ha dimostrato di superare altre metriche di qualit\u00e0 delle immagini e dei video come SSIM, PSNR -HVS e VQM-VFD su tre dei quattro set di dati in termini di accuratezza della previsione, se confrontata con le valutazioni soggettive.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 21], [22, 26], [27, 29], [30, 40], [41, 43], [44, 52], [53, 58], [59, 67], [68, 70], [71, 78], [79, 84], [85, 93], [94, 95], [96, 99], [100, 105], [106, 110], [111, 115], [115, 116], [117, 121], [122, 123], [123, 126], [127, 128], [129, 132], [132, 133], [133, 136], [137, 139], [140, 143], [144, 147], [148, 155], [156, 159], [160, 162], [163, 167], [168, 170], [171, 178], [179, 181], [182, 193], [194, 199], [200, 210], [210, 211], [212, 214], [215, 226], [227, 230], [231, 233], [234, 245], [246, 256], [256, 257]]}
{"doc_key": "ai-test-219", "ner": [[18, 19, "task"], [25, 27, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 19, 25, 27, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Ad", "esempio", ",", "l'", "ambiguit\u00e0", "di", "\"", "mouse", "\"", "(", "animale", "o", "dispositivo", ")", "non", "\u00e8", "rilevante", "nella", "traduzione", "automatica", ",", "ma", "lo", "\u00e8", "nel", "recupero", "delle", "informazioni", "."], "sentence-detokenized": "Ad esempio, l'ambiguit\u00e0 di \"mouse\" (animale o dispositivo) non \u00e8 rilevante nella traduzione automatica, ma lo \u00e8 nel recupero delle informazioni.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 14], [14, 23], [24, 26], [27, 28], [28, 33], [33, 34], [35, 36], [36, 43], [44, 45], [46, 57], [57, 58], [59, 62], [63, 64], [65, 74], [75, 80], [81, 91], [92, 102], [102, 103], [104, 106], [107, 109], [110, 111], [112, 115], [116, 124], [125, 130], [131, 143], [143, 144]]}
{"doc_key": "ai-test-220", "ner": [[0, 2, "algorithm"], [8, 9, "field"], [12, 14, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 0, 2, "usage", "", false, false], [12, 14, 8, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["L'", "hashing", "geometrico", "\u00e8", "stato", "originariamente", "proposto", "nella", "computer", "vision", "per", "il", "riconoscimento", "di", "oggetti", "in", "2D", "e", "3D", ","], "sentence-detokenized": "L'hashing geometrico \u00e8 stato originariamente proposto nella computer vision per il riconoscimento di oggetti in 2D e 3D,", "token2charspan": [[0, 2], [2, 9], [10, 20], [21, 22], [23, 28], [29, 44], [45, 53], [54, 59], [60, 68], [69, 75], [76, 79], [80, 82], [83, 97], [98, 100], [101, 108], [109, 111], [112, 114], [115, 116], [117, 119], [119, 120]]}
{"doc_key": "ai-test-221", "ner": [[7, 8, "field"], [12, 13, "field"], [16, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 13, 7, 8, "part-of", "subfield", false, false], [16, 18, 7, 8, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Costituisce", "una", "delle", "tre", "categorie", "principali", "dell'", "apprendimento", "automatico", ",", "insieme", "all'", "apprendimento", "supervisionato", "e", "all'", "apprendimento", "per", "rinforzo", "."], "sentence-detokenized": "Costituisce una delle tre categorie principali dell'apprendimento automatico, insieme all'apprendimento supervisionato e all'apprendimento per rinforzo.", "token2charspan": [[0, 11], [12, 15], [16, 21], [22, 25], [26, 35], [36, 46], [47, 52], [52, 65], [66, 76], [76, 77], [78, 85], [86, 90], [90, 103], [104, 118], [119, 120], [121, 125], [125, 138], [139, 142], [143, 151], [151, 152]]}
{"doc_key": "ai-test-222", "ner": [[0, 3, "field"], [19, 19, "field"], [22, 24, "field"], [27, 28, "field"], [31, 33, "field"], [36, 39, "field"], [42, 45, "field"], [48, 50, "field"], [53, 53, "field"], [56, 57, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 3, 19, 19, "part-of", "subfield", false, false], [0, 3, 22, 24, "part-of", "subfield", false, false], [0, 3, 27, 28, "part-of", "subfield", false, false], [0, 3, 31, 33, "part-of", "subfield", false, false], [0, 3, 36, 39, "part-of", "subfield", false, false], [0, 3, 42, 45, "part-of", "subfield", false, false], [0, 3, 48, 50, "part-of", "subfield", false, false], [0, 3, 53, 53, "part-of", "subfield", false, false], [0, 3, 56, 57, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["L'", "apprendimento", "per", "rinforzo", ",", "grazie", "alla", "sua", "generalit\u00e0", ",", "\u00e8", "studiato", "in", "molte", "altre", "discipline", ",", "come", "i", "giochi", ",", "la", "teoria", "del", "controllo", ",", "la", "ricerca", "operativa", ",", "la", "teoria", "dell'", "informazione", ",", "l'", "ottimizzazione", "basata", "sulla", "simulazione", ",", "i", "sistemi", "multi", "-", "agente", ",", "l'", "intelligenza", "degli", "sciami", ",", "la", "statistica", "e", "gli", "algoritmi", "genetici", "."], "sentence-detokenized": "L'apprendimento per rinforzo, grazie alla sua generalit\u00e0, \u00e8 studiato in molte altre discipline, come i giochi, la teoria del controllo, la ricerca operativa, la teoria dell'informazione, l'ottimizzazione basata sulla simulazione, i sistemi multi-agente, l'intelligenza degli sciami, la statistica e gli algoritmi genetici.", "token2charspan": [[0, 2], [2, 15], [16, 19], [20, 28], [28, 29], [30, 36], [37, 41], [42, 45], [46, 56], [56, 57], [58, 59], [60, 68], [69, 71], [72, 77], [78, 83], [84, 94], [94, 95], [96, 100], [101, 102], [103, 109], [109, 110], [111, 113], [114, 120], [121, 124], [125, 134], [134, 135], [136, 138], [139, 146], [147, 156], [156, 157], [158, 160], [161, 167], [168, 173], [173, 185], [185, 186], [187, 189], [189, 203], [204, 210], [211, 216], [217, 228], [228, 229], [230, 231], [232, 239], [240, 245], [245, 246], [246, 252], [252, 253], [254, 256], [256, 268], [269, 274], [275, 281], [281, 282], [283, 285], [286, 296], [297, 298], [299, 302], [303, 312], [313, 321], [321, 322]]}
{"doc_key": "ai-test-223", "ner": [[0, 3, "field"], [8, 9, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 8, 9, "related-to", "", false, false], [0, 3, 12, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Il", "riconoscimento", "dei", "pattern", "\u00e8", "strettamente", "legato", "all'", "intelligenza", "artificiale", "e", "all'", "apprendimento", "automatico", ","], "sentence-detokenized": "Il riconoscimento dei pattern \u00e8 strettamente legato all'intelligenza artificiale e all'apprendimento automatico,", "token2charspan": [[0, 2], [3, 17], [18, 21], [22, 29], [30, 31], [32, 44], [45, 51], [52, 56], [56, 68], [69, 80], [81, 82], [83, 87], [87, 100], [101, 111], [111, 112]]}
{"doc_key": "ai-test-224", "ner": [[11, 13, "algorithm"], [15, 16, "field"], [18, 19, "field"], [30, 31, "task"], [33, 33, "task"], [35, 37, "task"], [39, 40, "algorithm"], [42, 45, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 13, 15, 16, "related-to", "", false, false], [11, 13, 18, 19, "related-to", "", false, false], [30, 31, 11, 13, "usage", "", true, false], [33, 33, 11, 13, "usage", "", true, false], [35, 37, 11, 13, "usage", "", true, false], [39, 40, 11, 13, "usage", "", true, false], [42, 45, 11, 13, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Il", "software", "viene", "utilizzato", "per", "progettare", ",", "addestrare", "e", "distribuire", "modelli", "di", "reti", "neurali", "(", "apprendimento", "supervisionato", "e", "non", "supervisionato", ")", "per", "eseguire", "un'", "ampia", "gamma", "di", "compiti", ",", "quali", "data", "mining", ",", "classificazione", ",", "approssimazione", "di", "funzioni", ",", "regressione", "multivariata", "e", "previsione", "di", "serie", "temporali", "."], "sentence-detokenized": "Il software viene utilizzato per progettare, addestrare e distribuire modelli di reti neurali (apprendimento supervisionato e non supervisionato) per eseguire un'ampia gamma di compiti, quali data mining, classificazione, approssimazione di funzioni, regressione multivariata e previsione di serie temporali.", "token2charspan": [[0, 2], [3, 11], [12, 17], [18, 28], [29, 32], [33, 43], [43, 44], [45, 55], [56, 57], [58, 69], [70, 77], [78, 80], [81, 85], [86, 93], [94, 95], [95, 108], [109, 123], [124, 125], [126, 129], [130, 144], [144, 145], [146, 149], [150, 158], [159, 162], [162, 167], [168, 173], [174, 176], [177, 184], [184, 185], [186, 191], [192, 196], [197, 203], [203, 204], [205, 220], [220, 221], [222, 237], [238, 240], [241, 249], [249, 250], [251, 262], [263, 275], [276, 277], [278, 288], [289, 291], [292, 297], [298, 307], [307, 308]]}
{"doc_key": "ai-test-225", "ner": [[7, 13, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Nel", "2016", "\u00e8", "stato", "eletto", "Fellow", "dell'", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "Nel 2016 \u00e8 stato eletto Fellow dell'Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 3], [4, 8], [9, 10], [11, 16], [17, 23], [24, 30], [31, 36], [36, 47], [48, 51], [52, 55], [56, 67], [68, 70], [71, 81], [82, 94], [94, 95]]}
{"doc_key": "ai-test-226", "ner": [[3, 6, "organisation"], [13, 18, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["\u00c8", "membro", "della", "National", "Academy", "of", "Sciences", "(", "dal", "2005", ")", "e", "dell'", "American", "Academy", "of", "Arts", "and", "Sciences", "(", "dal", "2009", ")", ","], "sentence-detokenized": "\u00c8 membro della National Academy of Sciences (dal 2005) e dell'American Academy of Arts and Sciences (dal 2009),", "token2charspan": [[0, 1], [2, 8], [9, 14], [15, 23], [24, 31], [32, 34], [35, 43], [44, 45], [45, 48], [49, 53], [53, 54], [55, 56], [57, 62], [62, 70], [71, 78], [79, 81], [82, 86], [87, 90], [91, 99], [100, 101], [101, 104], [105, 109], [109, 110], [110, 111]]}
{"doc_key": "ai-test-227", "ner": [[2, 5, "misc"], [12, 15, "product"], [20, 20, "country"], [22, 23, "country"], [26, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 15, 2, 5, "temporal", "", false, false], [12, 15, 20, 20, "physical", "", false, false], [12, 15, 22, 23, "physical", "", false, false], [12, 15, 26, 30, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Durante", "la", "guerra", "dello", "Yom", "Kippur", "del", "1973", ",", "le", "batterie", "di", "missili", "terra", "-", "aria", "fornite", "dai", "sovietici", "in", "Egitto", "e", "Siria", "hanno", "danneggiato", "pesantemente", "i", "jet", "da", "combattimento", "israeliani", "."], "sentence-detokenized": "Durante la guerra dello Yom Kippur del 1973, le batterie di missili terra-aria fornite dai sovietici in Egitto e Siria hanno danneggiato pesantemente i jet da combattimento israeliani.", "token2charspan": [[0, 7], [8, 10], [11, 17], [18, 23], [24, 27], [28, 34], [35, 38], [39, 43], [43, 44], [45, 47], [48, 56], [57, 59], [60, 67], [68, 73], [73, 74], [74, 78], [79, 86], [87, 90], [91, 100], [101, 103], [104, 110], [111, 112], [113, 118], [119, 124], [125, 136], [137, 149], [150, 151], [152, 155], [156, 158], [159, 172], [173, 183], [183, 184]]}
{"doc_key": "ai-test-228", "ner": [[12, 13, "product"], [17, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 18, 12, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Un'", "altra", "risorsa", "(", "gratuita", "ma", "coperta", "da", "copyright", ")", "\u00e8", "il", "libro", "HTK", "(", "e", "il", "toolkit", "HTK", "che", "lo", "accompagna", ")", "."], "sentence-detokenized": "Un'altra risorsa (gratuita ma coperta da copyright) \u00e8 il libro HTK (e il toolkit HTK che lo accompagna).", "token2charspan": [[0, 3], [3, 8], [9, 16], [17, 18], [18, 26], [27, 29], [30, 37], [38, 40], [41, 50], [50, 51], [52, 53], [54, 56], [57, 62], [63, 66], [67, 68], [68, 69], [70, 72], [73, 80], [81, 84], [85, 88], [89, 91], [92, 102], [102, 103], [103, 104]]}
{"doc_key": "ai-test-229", "ner": [[10, 13, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["-", "sono", "stati", "presi", "in", "occasione", "del", "simposio", "di", "primavera", "dell'", "AAAI", "del", "2004", ",", "in", "cui", "linguisti", ",", "informatici", "e", "altri", "ricercatori", "interessati", "hanno", "per", "la", "prima", "volta", "allineato", "gli", "interessi", "e", "proposto", "compiti", "condivisi", "e", "set", "di", "dati", "di", "riferimento", "per", "la", "ricerca", "computazionale", "sistematica", "su", "affetti", ",", "attrattiva", ",", "soggettivit\u00e0", "e", "sentimento", "nei", "testi", "."], "sentence-detokenized": "- sono stati presi in occasione del simposio di primavera dell'AAAI del 2004, in cui linguisti, informatici e altri ricercatori interessati hanno per la prima volta allineato gli interessi e proposto compiti condivisi e set di dati di riferimento per la ricerca computazionale sistematica su affetti, attrattiva, soggettivit\u00e0 e sentimento nei testi.", "token2charspan": [[0, 1], [2, 6], [7, 12], [13, 18], [19, 21], [22, 31], [32, 35], [36, 44], [45, 47], [48, 57], [58, 63], [63, 67], [68, 71], [72, 76], [76, 77], [78, 80], [81, 84], [85, 94], [94, 95], [96, 107], [108, 109], [110, 115], [116, 127], [128, 139], [140, 145], [146, 149], [150, 152], [153, 158], [159, 164], [165, 174], [175, 178], [179, 188], [189, 190], [191, 199], [200, 207], [208, 217], [218, 219], [220, 223], [224, 226], [227, 231], [232, 234], [235, 246], [247, 250], [251, 253], [254, 261], [262, 276], [277, 288], [289, 291], [292, 299], [299, 300], [301, 311], [311, 312], [313, 325], [326, 327], [328, 338], [339, 342], [343, 348], [348, 349]]}
{"doc_key": "ai-test-230", "ner": [[11, 13, "task"], [26, 27, "task"], [30, 33, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Una", "singola", "griglia", "pu\u00f2", "essere", "analizzata", "sia", "per", "il", "contenuto", "(", "ispezione", "a", "occhio", ")", "sia", "per", "la", "struttura", "(", "le", "principali", "tecniche", "utilizzate", "sono", "la", "cluster", "analysis", ",", "l'", "analisi", "delle", "componenti", "principali", "e", "una", "serie", "di", "indici", "strutturali", "relativi", "alla", "complessit\u00e0", "e", "alla", "gamma", "delle", "valutazioni", ")", "."], "sentence-detokenized": "Una singola griglia pu\u00f2 essere analizzata sia per il contenuto (ispezione a occhio) sia per la struttura (le principali tecniche utilizzate sono la cluster analysis, l'analisi delle componenti principali e una serie di indici strutturali relativi alla complessit\u00e0 e alla gamma delle valutazioni).", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 23], [24, 30], [31, 41], [42, 45], [46, 49], [50, 52], [53, 62], [63, 64], [64, 73], [74, 75], [76, 82], [82, 83], [84, 87], [88, 91], [92, 94], [95, 104], [105, 106], [106, 108], [109, 119], [120, 128], [129, 139], [140, 144], [145, 147], [148, 155], [156, 164], [164, 165], [166, 168], [168, 175], [176, 181], [182, 192], [193, 203], [204, 205], [206, 209], [210, 215], [216, 218], [219, 225], [226, 237], [238, 246], [247, 251], [252, 263], [264, 265], [266, 270], [271, 276], [277, 282], [283, 294], [294, 295], [295, 296]]}
{"doc_key": "ai-test-231", "ner": [[2, 2, "organisation"], [9, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Nel", "2018", "Toyota", "\u00e8", "stata", "considerata", "in", "ritardo", "nella", "guida", "autonoma", "e", "bisognosa", "di", "innovazione", "."], "sentence-detokenized": "Nel 2018 Toyota \u00e8 stata considerata in ritardo nella guida autonoma e bisognosa di innovazione.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 17], [18, 23], [24, 35], [36, 38], [39, 46], [47, 52], [53, 58], [59, 67], [68, 69], [70, 79], [80, 82], [83, 94], [94, 95]]}
{"doc_key": "ai-test-232", "ner": [[47, 49, "misc"], [52, 54, "misc"], [57, 62, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Tali", "bersagli", "includono", "oggetti", "naturali", "come", "il", "suolo", ",", "il", "mare", ",", "le", "precipitazioni", "(", "come", "pioggia", ",", "neve", "o", "grandine", ")", ",", "le", "tempeste", "di", "sabbia", ",", "gli", "animali", "(", "in", "particolare", "gli", "uccelli", ")", ",", "la", "turbolenza", "atmosferica", "e", "altri", "effetti", "atmosferici", ",", "come", "le", "riflessioni", "della", "ionosfera", ",", "le", "scie", "di", "meteoriti", "e", "i", "picchi", "di", "dispersione", "dei", "tre", "corpi", "."], "sentence-detokenized": "Tali bersagli includono oggetti naturali come il suolo, il mare, le precipitazioni (come pioggia, neve o grandine), le tempeste di sabbia, gli animali (in particolare gli uccelli), la turbolenza atmosferica e altri effetti atmosferici, come le riflessioni della ionosfera, le scie di meteoriti e i picchi di dispersione dei tre corpi.", "token2charspan": [[0, 4], [5, 13], [14, 23], [24, 31], [32, 40], [41, 45], [46, 48], [49, 54], [54, 55], [56, 58], [59, 63], [63, 64], [65, 67], [68, 82], [83, 84], [84, 88], [89, 96], [96, 97], [98, 102], [103, 104], [105, 113], [113, 114], [114, 115], [116, 118], [119, 127], [128, 130], [131, 137], [137, 138], [139, 142], [143, 150], [151, 152], [152, 154], [155, 166], [167, 170], [171, 178], [178, 179], [179, 180], [181, 183], [184, 194], [195, 206], [207, 208], [209, 214], [215, 222], [223, 234], [234, 235], [236, 240], [241, 243], [244, 255], [256, 261], [262, 271], [271, 272], [273, 275], [276, 280], [281, 283], [284, 293], [294, 295], [296, 297], [298, 304], [305, 307], [308, 319], [320, 323], [324, 327], [328, 333], [333, 334]]}
{"doc_key": "ai-test-233", "ner": [[20, 20, "product"], [44, 45, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Nella", "pianificazione", "e", "nel", "controllo", ",", "la", "differenza", "essenziale", "tra", "gli", "umanoidi", "e", "altri", "tipi", "di", "robot", "(", "come", "quelli", "industriali", ")", "\u00e8", "che", "il", "movimento", "del", "robot", "deve", "essere", "simile", "a", "quello", "umano", ",", "utilizzando", "la", "locomozione", "delle", "gambe", ",", "in", "particolare", "l'", "andatura", "bipede", "."], "sentence-detokenized": "Nella pianificazione e nel controllo, la differenza essenziale tra gli umanoidi e altri tipi di robot (come quelli industriali) \u00e8 che il movimento del robot deve essere simile a quello umano, utilizzando la locomozione delle gambe, in particolare l'andatura bipede.", "token2charspan": [[0, 5], [6, 20], [21, 22], [23, 26], [27, 36], [36, 37], [38, 40], [41, 51], [52, 62], [63, 66], [67, 70], [71, 79], [80, 81], [82, 87], [88, 92], [93, 95], [96, 101], [102, 103], [103, 107], [108, 114], [115, 126], [126, 127], [128, 129], [130, 133], [134, 136], [137, 146], [147, 150], [151, 156], [157, 161], [162, 168], [169, 175], [176, 177], [178, 184], [185, 190], [190, 191], [192, 203], [204, 206], [207, 218], [219, 224], [225, 230], [230, 231], [232, 234], [235, 246], [247, 249], [249, 257], [258, 264], [264, 265]]}
{"doc_key": "ai-test-234", "ner": [[1, 3, "algorithm"], [11, 12, "misc"], [15, 15, "metrics"], [20, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "discesa", "del", "gradiente", "pu\u00f2", "richiedere", "molte", "iterazioni", "per", "calcolare", "un", "minimo", "locale", "con", "la", "precisione", "richiesta", ",", "se", "la", "curvatura", "nelle", "diverse", "direzioni", "\u00e8", "molto", "diversa", "per", "la", "funzione", "data", "."], "sentence-detokenized": "La discesa del gradiente pu\u00f2 richiedere molte iterazioni per calcolare un minimo locale con la precisione richiesta, se la curvatura nelle diverse direzioni \u00e8 molto diversa per la funzione data.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 24], [25, 28], [29, 39], [40, 45], [46, 56], [57, 60], [61, 70], [71, 73], [74, 80], [81, 87], [88, 91], [92, 94], [95, 105], [106, 115], [115, 116], [117, 119], [120, 122], [123, 132], [133, 138], [139, 146], [147, 156], [157, 158], [159, 164], [165, 172], [173, 176], [177, 179], [180, 188], [189, 193], [193, 194]]}
{"doc_key": "ai-test-235", "ner": [[1, 7, "misc"], [13, 13, "misc"], [19, 24, "conference"], [27, 27, "location"], [30, 30, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 7, 13, 13, "part-of", "", true, false], [19, 24, 27, 27, "physical", "", false, true], [27, 27, 30, 30, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "RoboCup", "2D", "Soccer", "Simulation", "League", "del", "1997", "\u00e8", "stata", "la", "prima", "competizione", "RoboCup", "promossa", "in", "concomitanza", "con", "la", "International", "Joint", "Conference", "on", "Artificial", "Intelligence", "tenutasi", "a", "Nagoya", ",", "in", "Giappone", ",", "dal", "23", "al", "29", "agosto", "1997", "."], "sentence-detokenized": "La RoboCup 2D Soccer Simulation League del 1997 \u00e8 stata la prima competizione RoboCup promossa in concomitanza con la International Joint Conference on Artificial Intelligence tenutasi a Nagoya, in Giappone, dal 23 al 29 agosto 1997.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 20], [21, 31], [32, 38], [39, 42], [43, 47], [48, 49], [50, 55], [56, 58], [59, 64], [65, 77], [78, 85], [86, 94], [95, 97], [98, 110], [111, 114], [115, 117], [118, 131], [132, 137], [138, 148], [149, 151], [152, 162], [163, 175], [176, 184], [185, 186], [187, 193], [193, 194], [195, 197], [198, 206], [206, 207], [208, 211], [212, 214], [215, 217], [218, 220], [221, 227], [228, 232], [232, 233]]}
{"doc_key": "ai-test-236", "ner": [[7, 7, "programlang"], [12, 12, "programlang"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Altre", "opzioni", "di", "programmazione", "includono", "un", "ambiente", "Python", "integrato", "e", "una", "console", "R", "con", "supporto", "per", "Rserve", "."], "sentence-detokenized": "Altre opzioni di programmazione includono un ambiente Python integrato e una console R con supporto per Rserve.", "token2charspan": [[0, 5], [6, 13], [14, 16], [17, 31], [32, 41], [42, 44], [45, 53], [54, 60], [61, 70], [71, 72], [73, 76], [77, 84], [85, 86], [87, 90], [91, 99], [100, 103], [104, 110], [110, 111]]}
{"doc_key": "ai-test-237", "ner": [[1, 1, "location"], [8, 9, "field"], [12, 12, "field"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"], [33, 35, "field"], [40, 41, "field"], [45, 46, "field"], [51, 53, "field"], [56, 59, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[15, 16, 12, 12, "related-to", "contributes_to_field", true, false], [18, 19, 12, 12, "related-to", "contributes_to_field", true, false], [21, 22, 12, 12, "related-to", "contributes_to_field", true, false], [45, 46, 40, 41, "part-of", "", false, false], [51, 53, 45, 46, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Da", "Bonn", "ha", "contribuito", "in", "modo", "fondamentale", "all'", "intelligenza", "artificiale", "e", "alla", "robotica", "(", "con", "Wolfram", "Burgard", ",", "Dieter", "Fox", ",", "Sebastian", "Thrun", "tra", "i", "suoi", "studenti", ")", ",", "e", "allo", "sviluppo", "dell'", "ingegneria", "del", "software", ",", "in", "particolare", "nell'", "ingegneria", "civile", ",", "e", "dei", "sistemi", "informativi", ",", "in", "particolare", "nelle", "geoscienze", ".", "ha", "vinto", "il", "premio", "AAAI", "Classic", "Paper", "del", "2016.2014", "."], "sentence-detokenized": "Da Bonn ha contribuito in modo fondamentale all'intelligenza artificiale e alla robotica (con Wolfram Burgard, Dieter Fox, Sebastian Thrun tra i suoi studenti), e allo sviluppo dell'ingegneria del software, in particolare nell'ingegneria civile, e dei sistemi informativi, in particolare nelle geoscienze. ha vinto il premio AAAI Classic Paper del 2016.2014.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 22], [23, 25], [26, 30], [31, 43], [44, 48], [48, 60], [61, 72], [73, 74], [75, 79], [80, 88], [89, 90], [90, 93], [94, 101], [102, 109], [109, 110], [111, 117], [118, 121], [121, 122], [123, 132], [133, 138], [139, 142], [143, 144], [145, 149], [150, 158], [158, 159], [159, 160], [161, 162], [163, 167], [168, 176], [177, 182], [182, 192], [193, 196], [197, 205], [205, 206], [207, 209], [210, 221], [222, 227], [227, 237], [238, 244], [244, 245], [246, 247], [248, 251], [252, 259], [260, 271], [271, 272], [273, 275], [276, 287], [288, 293], [294, 304], [304, 305], [306, 308], [309, 314], [315, 317], [318, 324], [325, 329], [330, 337], [338, 343], [344, 347], [348, 357], [357, 358]]}
{"doc_key": "ai-test-238", "ner": [[2, 8, "conference"], [15, 16, "location"], [18, 18, "location"], [20, 20, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 8, 15, 16, "physical", "", false, false], [15, 16, 18, 18, "physical", "", false, false], [18, 18, 20, 20, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "prima", "edizione", "USA", "del", "Campus", "Party", "si", "terr\u00e0", "dal", "20", "al", "22", "agosto", "al", "TCF", "Center", "di", "Detroit", ",", "Michigan", "."], "sentence-detokenized": "La prima edizione USA del Campus Party si terr\u00e0 dal 20 al 22 agosto al TCF Center di Detroit, Michigan.", "token2charspan": [[0, 2], [3, 8], [9, 17], [18, 21], [22, 25], [26, 32], [33, 38], [39, 41], [42, 47], [48, 51], [52, 54], [55, 57], [58, 60], [61, 67], [68, 70], [71, 74], [75, 81], [82, 84], [85, 92], [92, 93], [94, 102], [102, 103]]}
{"doc_key": "ai-test-239", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [12, 13, "misc"], [25, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 12, 13, "win-defeat", "", false, false], [5, 6, 12, 13, "win-defeat", "", false, false], [8, 8, 12, 13, "win-defeat", "", false, false], [12, 13, 25, 27, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Insieme", "a", "Yann", "LeCun", "e", "Yoshua", "Bengio", ",", "Hinton", "ha", "vinto", "il", "Premio", "Turing", "2018", "per", "le", "scoperte", "concettuali", "e", "ingegneristiche", "che", "hanno", "reso", "le", "reti", "neurali", "profonde", "una", "componente", "fondamentale", "dell'", "informatica", "."], "sentence-detokenized": "Insieme a Yann LeCun e Yoshua Bengio, Hinton ha vinto il Premio Turing 2018 per le scoperte concettuali e ingegneristiche che hanno reso le reti neurali profonde una componente fondamentale dell'informatica.", "token2charspan": [[0, 7], [8, 9], [10, 14], [15, 20], [21, 22], [23, 29], [30, 36], [36, 37], [38, 44], [45, 47], [48, 53], [54, 56], [57, 63], [64, 70], [71, 75], [76, 79], [80, 82], [83, 91], [92, 103], [104, 105], [106, 121], [122, 125], [126, 131], [132, 136], [137, 139], [140, 144], [145, 152], [153, 161], [162, 165], [166, 176], [177, 189], [190, 195], [195, 206], [206, 207]]}
{"doc_key": "ai-test-240", "ner": [[0, 2, "product"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 9, 9, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Euler", "Math", "Toolbox", "utilizza", "un", "linguaggio", "matriciale", "simile", "a", "MATLAB", ",", "un", "sistema", "in", "fase", "di", "sviluppo", "dagli", "anni", "Settanta", "."], "sentence-detokenized": "Euler Math Toolbox utilizza un linguaggio matriciale simile a MATLAB, un sistema in fase di sviluppo dagli anni Settanta.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 27], [28, 30], [31, 41], [42, 52], [53, 59], [60, 61], [62, 68], [68, 69], [70, 72], [73, 80], [81, 83], [84, 88], [89, 91], [92, 100], [101, 106], [107, 111], [112, 120], [120, 121]]}
{"doc_key": "ai-test-241", "ner": [[11, 11, "programlang"], [13, 14, "programlang"], [16, 16, "programlang"], [18, 18, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Alcuni", "linguaggi", "lo", "rendono", "possibile", "in", "modo", "portabile", "(", "ad", "esempio", "Scheme", ",", "Common", "Lisp", ",", "Perl", "o", "D", ")", "."], "sentence-detokenized": "Alcuni linguaggi lo rendono possibile in modo portabile (ad esempio Scheme, Common Lisp, Perl o D).", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 27], [28, 37], [38, 40], [41, 45], [46, 55], [56, 57], [57, 59], [60, 67], [68, 74], [74, 75], [76, 82], [83, 87], [87, 88], [89, 93], [94, 95], [96, 97], [97, 98], [98, 99]]}
{"doc_key": "ai-test-242", "ner": [[6, 6, "misc"], [8, 9, "researcher"], [11, 12, "researcher"], [24, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 8, 9, "artifact", "", false, false], [6, 6, 11, 12, "artifact", "", false, false], [6, 6, 24, 25, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Nel", "1969", "un", "famoso", "libro", "intitolato", "Perceptrons", "di", "Marvin", "Minsky", "e", "Seymour", "Papert", "dimostr\u00f2", "che", "era", "impossibile", "per", "queste", "classi", "di", "reti", "apprendere", "una", "funzione", "XOR."], "sentence-detokenized": "Nel 1969 un famoso libro intitolato Perceptrons di Marvin Minsky e Seymour Papert dimostr\u00f2 che era impossibile per queste classi di reti apprendere una funzione XOR.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 18], [19, 24], [25, 35], [36, 47], [48, 50], [51, 57], [58, 64], [65, 66], [67, 74], [75, 81], [82, 90], [91, 94], [95, 98], [99, 110], [111, 114], [115, 121], [122, 128], [129, 131], [132, 136], [137, 147], [148, 151], [152, 160], [161, 165]]}
{"doc_key": "ai-test-243", "ner": [[4, 8, "misc"], [13, 13, "product"], [18, 21, "organisation"], [24, 29, "organisation"], [33, 38, "location"], [41, 41, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[18, 21, 13, 13, "usage", "", false, false], [18, 21, 33, 38, "physical", "", false, false], [24, 29, 18, 21, "named", "", false, false], [33, 38, 41, 41, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Un", "gran", "numero", "di", "documenti", "scientifici", "e", "tecnici", "russi", "sono", "stati", "tradotti", "con", "SYSTRAN", "sotto", "gli", "auspici", "della", "USAF", "Foreign", "Technology", "Division", "(", "poi", "National", "Air", "and", "Space", "Intelligence", "Center", ")", "presso", "la", "Wright", "-", "Patterson", "Air", "Force", "Base", ",", "in", "Ohio", "."], "sentence-detokenized": "Un gran numero di documenti scientifici e tecnici russi sono stati tradotti con SYSTRAN sotto gli auspici della USAF Foreign Technology Division (poi National Air and Space Intelligence Center) presso la Wright-Patterson Air Force Base, in Ohio.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 17], [18, 27], [28, 39], [40, 41], [42, 49], [50, 55], [56, 60], [61, 66], [67, 75], [76, 79], [80, 87], [88, 93], [94, 97], [98, 105], [106, 111], [112, 116], [117, 124], [125, 135], [136, 144], [145, 146], [146, 149], [150, 158], [159, 162], [163, 166], [167, 172], [173, 185], [186, 192], [192, 193], [194, 200], [201, 203], [204, 210], [210, 211], [211, 220], [221, 224], [225, 230], [231, 235], [235, 236], [237, 239], [240, 244], [244, 245]]}
{"doc_key": "ai-test-244", "ner": [[0, 4, "field"], [9, 11, "field"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["L'", "apprendimento", "semi", "-", "supervisionato", "si", "colloca", "tra", "l'", "apprendimento", "non", "supervisionato", "(", "senza", "dati", "di", "formazione", "etichettati", ")", "e", "l'", "apprendimento", "supervisionato", "(", "con", "dati", "di", "formazione", "completamente", "etichettati", ")", "."], "sentence-detokenized": "L'apprendimento semi-supervisionato si colloca tra l'apprendimento non supervisionato (senza dati di formazione etichettati) e l'apprendimento supervisionato (con dati di formazione completamente etichettati).", "token2charspan": [[0, 2], [2, 15], [16, 20], [20, 21], [21, 35], [36, 38], [39, 46], [47, 50], [51, 53], [53, 66], [67, 70], [71, 85], [86, 87], [87, 92], [93, 97], [98, 100], [101, 111], [112, 123], [123, 124], [125, 126], [127, 129], [129, 142], [143, 157], [158, 159], [159, 162], [163, 167], [168, 170], [171, 181], [182, 195], [196, 207], [207, 208], [208, 209]]}
{"doc_key": "ai-test-245", "ner": [[0, 4, "algorithm"], [9, 11, "algorithm"], [25, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 9, 11, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Il", "modello", "Ann", "-", "gram", "\u00e8", "un", "tipo", "di", "modello", "linguistico", "probabilistico", "per", "la", "previsione", "dell'", "elemento", "successivo", "in", "tale", "sequenza", "sotto", "forma", "di", "un", "modello", "di", "Markov", "di", "(", "n", "-", "1", ")", "ordine", ".efficiente", "."], "sentence-detokenized": "Il modello Ann -gram \u00e8 un tipo di modello linguistico probabilistico per la previsione dell'elemento successivo in tale sequenza sotto forma di un modello di Markov di (n - 1) ordine .efficiente.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 16], [16, 20], [21, 22], [23, 25], [26, 30], [31, 33], [34, 41], [42, 53], [54, 68], [69, 72], [73, 75], [76, 86], [87, 92], [92, 100], [101, 111], [112, 114], [115, 119], [120, 128], [129, 134], [135, 140], [141, 143], [144, 146], [147, 154], [155, 157], [158, 164], [165, 167], [168, 169], [169, 170], [171, 172], [173, 174], [174, 175], [176, 182], [183, 194], [194, 195]]}
{"doc_key": "ai-test-246", "ner": [[1, 2, "organisation"], [5, 5, "product"], [9, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 5, 5, "usage", "", false, false], [9, 17, 1, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "Cleveland", "Clinic", "ha", "utilizzato", "Cyc", "per", "sviluppare", "un'", "interfaccia", "di", "interrogazione", "in", "linguaggio", "naturale", "di", "informazioni", "biomediche", ",", "che", "copre", "decenni", "di", "informazioni", "sugli", "interventi", "di", "chirurgia", "cardiotoracica", "."], "sentence-detokenized": "La Cleveland Clinic ha utilizzato Cyc per sviluppare un'interfaccia di interrogazione in linguaggio naturale di informazioni biomediche, che copre decenni di informazioni sugli interventi di chirurgia cardiotoracica.", "token2charspan": [[0, 2], [3, 12], [13, 19], [20, 22], [23, 33], [34, 37], [38, 41], [42, 52], [53, 56], [56, 67], [68, 70], [71, 85], [86, 88], [89, 99], [100, 108], [109, 111], [112, 124], [125, 135], [135, 136], [137, 140], [141, 146], [147, 154], [155, 157], [158, 170], [171, 176], [177, 187], [188, 190], [191, 200], [201, 215], [215, 216]]}
{"doc_key": "ai-test-247", "ner": [[10, 11, "country"], [13, 13, "country"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 11, 13, 13, "opposite", "strained_relations", false, false]], "relations_mapping_to_source": [0], "sentence": ["L'", "incidente", "ha", "messo", "a", "dura", "prova", "le", "relazioni", "tra", "Stati", "Uniti", "e", "Giappone", "e", "ha", "portato", "all'", "arresto", "e", "all'", "incriminazione", "di", "due", "dirigenti", "e", "all'", "imposizione", "di", "sanzioni", "alla", "societ\u00e0", "da", "parte", "di", "entrambi", "i", "Paesi", "."], "sentence-detokenized": "L'incidente ha messo a dura prova le relazioni tra Stati Uniti e Giappone e ha portato all'arresto e all'incriminazione di due dirigenti e all'imposizione di sanzioni alla societ\u00e0 da parte di entrambi i Paesi.", "token2charspan": [[0, 2], [2, 11], [12, 14], [15, 20], [21, 22], [23, 27], [28, 33], [34, 36], [37, 46], [47, 50], [51, 56], [57, 62], [63, 64], [65, 73], [74, 75], [76, 78], [79, 86], [87, 91], [91, 98], [99, 100], [101, 105], [105, 119], [120, 122], [123, 126], [127, 136], [137, 138], [139, 143], [143, 154], [155, 157], [158, 166], [167, 171], [172, 179], [180, 182], [183, 188], [189, 191], [192, 200], [201, 202], [203, 208], [208, 209]]}
{"doc_key": "ai-test-248", "ner": [[7, 9, "algorithm"], [16, 17, "field"], [25, 25, "misc"], [36, 36, "misc"], [41, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 9, 16, 17, "type-of", "", false, false], [25, 25, 16, 17, "part-of", "", true, false], [36, 36, 16, 17, "part-of", "", true, false], [41, 42, 16, 17, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Se", "la", "modellazione", "\u00e8", "effettuata", "da", "una", "rete", "neurale", "artificiale", "o", "da", "un", "altro", "tipo", "di", "apprendimento", "automatico", ",", "l'", "ottimizzazione", "dei", "parametri", "\u00e8", "chiamata", "addestramento", ",", "mentre", "l'", "ottimizzazione", "degli", "iperparametri", "del", "modello", "\u00e8", "chiamata", "sintonizzazione", "e", "spesso", "utilizza", "la", "convalida", "incrociata", "."], "sentence-detokenized": "Se la modellazione \u00e8 effettuata da una rete neurale artificiale o da un altro tipo di apprendimento automatico, l'ottimizzazione dei parametri \u00e8 chiamata addestramento, mentre l'ottimizzazione degli iperparametri del modello \u00e8 chiamata sintonizzazione e spesso utilizza la convalida incrociata.", "token2charspan": [[0, 2], [3, 5], [6, 18], [19, 20], [21, 31], [32, 34], [35, 38], [39, 43], [44, 51], [52, 63], [64, 65], [66, 68], [69, 71], [72, 77], [78, 82], [83, 85], [86, 99], [100, 110], [110, 111], [112, 114], [114, 128], [129, 132], [133, 142], [143, 144], [145, 153], [154, 167], [167, 168], [169, 175], [176, 178], [178, 192], [193, 198], [199, 212], [213, 216], [217, 224], [225, 226], [227, 235], [236, 251], [252, 253], [254, 260], [261, 269], [270, 272], [273, 282], [283, 293], [293, 294]]}
{"doc_key": "ai-test-249", "ner": [[7, 8, "country"], [10, 11, "country"], [14, 14, "country"], [23, 24, "organisation"], [28, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[23, 24, 28, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Le", "versioni", "localizzate", "del", "sito", "disponibili", "nel", "Regno", "Unito", ",", "in", "India", "e", "in", "Australia", "sono", "state", "interrotte", "in", "seguito", "all'", "acquisizione", "di", "Rotten", "Tomatoes", "da", "parte", "di", "Fandango", "."], "sentence-detokenized": "Le versioni localizzate del sito disponibili nel Regno Unito, in India e in Australia sono state interrotte in seguito all'acquisizione di Rotten Tomatoes da parte di Fandango.", "token2charspan": [[0, 2], [3, 11], [12, 23], [24, 27], [28, 32], [33, 44], [45, 48], [49, 54], [55, 60], [60, 61], [62, 64], [65, 70], [71, 72], [73, 75], [76, 85], [86, 90], [91, 96], [97, 107], [108, 110], [111, 118], [119, 123], [123, 135], [136, 138], [139, 145], [146, 154], [155, 157], [158, 163], [164, 166], [167, 175], [175, 176]]}
{"doc_key": "ai-test-250", "ner": [[2, 2, "task"], [10, 10, "metrics"], [26, 27, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 10, 10, "related-to", "", false, false], [10, 10, 26, 27, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Il", "modello", "NER", "\u00e8", "uno", "dei", "metodi", "per", "determinare", "l'", "accuratezza", "dei", "sottotitoli", "in", "diretta", "nelle", "trasmissioni", "televisive", "e", "negli", "eventi", "che", "vengono", "prodotti", "utilizzando", "il", "riconoscimento", "vocale", "."], "sentence-detokenized": "Il modello NER \u00e8 uno dei metodi per determinare l'accuratezza dei sottotitoli in diretta nelle trasmissioni televisive e negli eventi che vengono prodotti utilizzando il riconoscimento vocale.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 16], [17, 20], [21, 24], [25, 31], [32, 35], [36, 47], [48, 50], [50, 61], [62, 65], [66, 77], [78, 80], [81, 88], [89, 94], [95, 107], [108, 118], [119, 120], [121, 126], [127, 133], [134, 137], [138, 145], [146, 154], [155, 166], [167, 169], [170, 184], [185, 191], [191, 192]]}
{"doc_key": "ai-test-251", "ner": [[0, 0, "researcher"], [4, 6, "university"], [9, 10, "university"], [12, 12, "location"], [15, 19, "university"], [22, 23, "university"], [25, 25, "location"], [28, 33, "university"], [35, 36, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 6, "physical", "", false, false], [0, 0, 4, 6, "role", "", false, false], [0, 0, 9, 10, "physical", "", false, false], [0, 0, 9, 10, "role", "", false, false], [0, 0, 15, 19, "physical", "", false, false], [0, 0, 15, 19, "role", "", false, false], [0, 0, 22, 23, "physical", "", false, false], [0, 0, 22, 23, "role", "", false, false], [0, 0, 28, 33, "physical", "", false, false], [0, 0, 28, 33, "role", "", false, false], [9, 10, 12, 12, "physical", "", false, false], [15, 19, 25, 25, "physical", "", false, false], [22, 23, 25, 25, "physical", "", false, false], [28, 33, 35, 36, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Atran", "ha", "insegnato", "all'", "Universit\u00e0", "di", "Cambridge", ",", "alla", "Hebrew", "University", "di", "Gerusalemme", ",", "all'", "\u00c9cole", "pratique", "des", "hautes", "\u00e9tudes", "e", "all'", "\u00c9cole", "Polytechnique", "di", "Parigi", "e", "al", "John", "Jay", "College", "of", "Criminal", "Justice", "di", "New", "York", "."], "sentence-detokenized": "Atran ha insegnato all'Universit\u00e0 di Cambridge, alla Hebrew University di Gerusalemme, all'\u00c9cole pratique des hautes \u00e9tudes e all'\u00c9cole Polytechnique di Parigi e al John Jay College of Criminal Justice di New York.", "token2charspan": [[0, 5], [6, 8], [9, 18], [19, 23], [23, 33], [34, 36], [37, 46], [46, 47], [48, 52], [53, 59], [60, 70], [71, 73], [74, 85], [85, 86], [87, 91], [91, 96], [97, 105], [106, 109], [110, 116], [117, 123], [124, 125], [126, 130], [130, 135], [136, 149], [150, 152], [153, 159], [160, 161], [162, 164], [165, 169], [170, 173], [174, 181], [182, 184], [185, 193], [194, 201], [202, 204], [205, 208], [209, 213], [213, 214]]}
{"doc_key": "ai-test-252", "ner": [[0, 0, "product"], [6, 9, "task"], [13, 14, "researcher"], [16, 16, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 9, "origin", "", false, false], [0, 0, 6, 9, "related-to", "", false, false], [6, 9, 16, 16, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["SHRDLU", "era", "un", "primo", "programma", "di", "comprensione", "del", "linguaggio", "naturale", ",", "sviluppato", "da", "Terry", "Winograd", "al", "MIT", "nel", "1968", "-", "1970", "."], "sentence-detokenized": "SHRDLU era un primo programma di comprensione del linguaggio naturale, sviluppato da Terry Winograd al MIT nel 1968-1970.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 19], [20, 29], [30, 32], [33, 45], [46, 49], [50, 60], [61, 69], [69, 70], [71, 81], [82, 84], [85, 90], [91, 99], [100, 102], [103, 106], [107, 110], [111, 115], [115, 116], [116, 120], [120, 121]]}
{"doc_key": "ai-test-253", "ner": [[3, 3, "misc"], [5, 6, "field"], [9, 12, "university"], [14, 14, "location"], [17, 17, "country"], [26, 28, "university"], [31, 31, "misc"], [33, 36, "field"], [41, 42, "university"], [45, 45, "misc"], [47, 47, "field"], [52, 54, "misc"], [61, 65, "university"], [70, 71, "field"], [76, 77, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "relations": [[3, 3, 5, 6, "topic", "", false, false], [3, 3, 9, 12, "origin", "", false, false], [9, 12, 14, 14, "physical", "", false, false], [9, 12, 26, 28, "role", "affiliated_with", false, false], [14, 14, 17, 17, "physical", "", false, false], [31, 31, 33, 36, "topic", "", false, false], [31, 31, 41, 42, "origin", "", false, false], [45, 45, 47, 47, "topic", "", false, false], [52, 54, 61, 65, "origin", "", false, false], [52, 54, 70, 71, "topic", "", false, false], [76, 77, 61, 65, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Ha", "conseguito", "un", "B.E.", "in", "ingegneria", "elettronica", "presso", "il", "B.M.S.", "College", "of", "Engineering", "di", "Bangalore", ",", "in", "India", ",", "nel", "1982", ",", "quando", "era", "affiliato", "all'", "Universit\u00e0", "di", "Bangalore", ",", "un", "M.S.", "in", "ingegneria", "elettrica", "e", "informatica", "nel", "1984", "presso", "la", "Drexel", "University", "e", "un", "M.S.", "in", "informatica", "nel", "1989", "e", "un", "dottorato", "di", "ricerca", "nel", "1990", ",", "rispettivamente", "presso", "l'", "Universit\u00e0", "del", "Wisconsin", "-", "Madison", ",", "dove", "ha", "studiato", "intelligenza", "artificiale", "e", "ha", "lavorato", "con", "Leonard", "Uhr", "."], "sentence-detokenized": "Ha conseguito un B.E. in ingegneria elettronica presso il B.M.S. College of Engineering di Bangalore, in India, nel 1982, quando era affiliato all'Universit\u00e0 di Bangalore, un M.S. in ingegneria elettrica e informatica nel 1984 presso la Drexel University e un M.S. in informatica nel 1989 e un dottorato di ricerca nel 1990, rispettivamente presso l'Universit\u00e0 del Wisconsin-Madison, dove ha studiato intelligenza artificiale e ha lavorato con Leonard Uhr.", "token2charspan": [[0, 2], [3, 13], [14, 16], [17, 21], [22, 24], [25, 35], [36, 47], [48, 54], [55, 57], [58, 64], [65, 72], [73, 75], [76, 87], [88, 90], [91, 100], [100, 101], [102, 104], [105, 110], [110, 111], [112, 115], [116, 120], [120, 121], [122, 128], [129, 132], [133, 142], [143, 147], [147, 157], [158, 160], [161, 170], [170, 171], [172, 174], [175, 179], [180, 182], [183, 193], [194, 203], [204, 205], [206, 217], [218, 221], [222, 226], [227, 233], [234, 236], [237, 243], [244, 254], [255, 256], [257, 259], [260, 264], [265, 267], [268, 279], [280, 283], [284, 288], [289, 290], [291, 293], [294, 303], [304, 306], [307, 314], [315, 318], [319, 323], [323, 324], [325, 340], [341, 347], [348, 350], [350, 360], [361, 364], [365, 374], [374, 375], [375, 382], [382, 383], [384, 388], [389, 391], [392, 400], [401, 413], [414, 425], [426, 427], [428, 430], [431, 439], [440, 443], [444, 451], [452, 455], [455, 456]]}
{"doc_key": "ai-test-254", "ner": [[7, 11, "metrics"], [13, 13, "metrics"], [23, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 13, 7, 11, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["La", "precisione", "viene", "solitamente", "valutata", "con", "il", "tasso", "di", "errore", "di", "parola", "(", "WER", ")", ",", "mentre", "la", "velocit\u00e0", "viene", "misurata", "con", "il", "fattore", "tempo", "reale", "."], "sentence-detokenized": "La precisione viene solitamente valutata con il tasso di errore di parola (WER), mentre la velocit\u00e0 viene misurata con il fattore tempo reale.", "token2charspan": [[0, 2], [3, 13], [14, 19], [20, 31], [32, 40], [41, 44], [45, 47], [48, 53], [54, 56], [57, 63], [64, 66], [67, 73], [74, 75], [75, 78], [78, 79], [79, 80], [81, 87], [88, 90], [91, 99], [100, 105], [106, 114], [115, 118], [119, 121], [122, 129], [130, 135], [136, 141], [141, 142]]}
{"doc_key": "ai-test-255", "ner": [[2, 3, "researcher"], [8, 12, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 8, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Nel", "1971", "Terry", "Winograd", "svilupp\u00f2", "un", "primo", "motore", "di", "elaborazione", "del", "linguaggio", "naturale", "in", "grado", "di", "interpretare", "comandi", "scritti", "naturalmente", "all'", "interno", "di", "un", "semplice", "ambiente", "governato", "da", "regole", "."], "sentence-detokenized": "Nel 1971 Terry Winograd svilupp\u00f2 un primo motore di elaborazione del linguaggio naturale in grado di interpretare comandi scritti naturalmente all'interno di un semplice ambiente governato da regole.", "token2charspan": [[0, 3], [4, 8], [9, 14], [15, 23], [24, 32], [33, 35], [36, 41], [42, 48], [49, 51], [52, 64], [65, 68], [69, 79], [80, 88], [89, 91], [92, 97], [98, 100], [101, 113], [114, 121], [122, 129], [130, 142], [143, 147], [147, 154], [155, 157], [158, 160], [161, 169], [170, 178], [179, 188], [189, 191], [192, 198], [198, 199]]}
{"doc_key": "ai-test-256", "ner": [[3, 4, "field"], [6, 7, "researcher"], [9, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 6, 7, "related-to", "", false, false], [3, 4, 9, 12, "related-to", "", false, false], [3, 4, 14, 15, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Nel", "campo", "dell'", "intelligenza", "artificiale", ",", "Marvin", "Minsky", ",", "Herbert", "A", ".", "Simon", "e", "Allen", "Newell", "sono", "i", "principali", "protagonisti", "."], "sentence-detokenized": "Nel campo dell'intelligenza artificiale, Marvin Minsky, Herbert A. Simon e Allen Newell sono i principali protagonisti.", "token2charspan": [[0, 3], [4, 9], [10, 15], [15, 27], [28, 39], [39, 40], [41, 47], [48, 54], [54, 55], [56, 63], [64, 65], [65, 66], [67, 72], [73, 74], [75, 80], [81, 87], [88, 92], [93, 94], [95, 105], [106, 118], [118, 119]]}
{"doc_key": "ai-test-257", "ner": [[8, 9, "field"], [36, 37, "field"], [40, 41, "field"], [45, 47, "field"], [57, 60, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[36, 37, 8, 9, "origin", "", true, false], [36, 37, 8, 9, "part-of", "", false, false], [36, 37, 45, 47, "compare", "", false, false], [40, 41, 8, 9, "origin", "", true, false], [40, 41, 8, 9, "part-of", "", false, false], [40, 41, 45, 47, "compare", "", false, false], [45, 47, 8, 9, "origin", "", true, false], [45, 47, 8, 9, "part-of", "", false, false], [45, 47, 57, 60, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Nella", "seconda", "met\u00e0", "del", "XX", "secolo", ",", "l'", "ingegneria", "elettrica", "stessa", "si", "\u00e8", "separata", "in", "diverse", "discipline", ",", "specializzate", "nella", "progettazione", "e", "nell'", "analisi", "di", "sistemi", "che", "manipolano", "segnali", "fisici", ";", "ne", "sono", "un", "esempio", "l'", "ingegneria", "elettronica", "e", "l'", "ingegneria", "informatica", ",", "mentre", "l'", "ingegneria", "del", "design", "si", "\u00e8", "sviluppata", "per", "occuparsi", "della", "progettazione", "funzionale", "delle", "interfacce", "utente", "-", "macchina", "."], "sentence-detokenized": "Nella seconda met\u00e0 del XX secolo, l'ingegneria elettrica stessa si \u00e8 separata in diverse discipline, specializzate nella progettazione e nell'analisi di sistemi che manipolano segnali fisici; ne sono un esempio l'ingegneria elettronica e l'ingegneria informatica, mentre l'ingegneria del design si \u00e8 sviluppata per occuparsi della progettazione funzionale delle interfacce utente-macchina.", "token2charspan": [[0, 5], [6, 13], [14, 18], [19, 22], [23, 25], [26, 32], [32, 33], [34, 36], [36, 46], [47, 56], [57, 63], [64, 66], [67, 68], [69, 77], [78, 80], [81, 88], [89, 99], [99, 100], [101, 114], [115, 120], [121, 134], [135, 136], [137, 142], [142, 149], [150, 152], [153, 160], [161, 164], [165, 175], [176, 183], [184, 190], [190, 191], [192, 194], [195, 199], [200, 202], [203, 210], [211, 213], [213, 223], [224, 235], [236, 237], [238, 240], [240, 250], [251, 262], [262, 263], [264, 270], [271, 273], [273, 283], [284, 287], [288, 294], [295, 297], [298, 299], [300, 310], [311, 314], [315, 324], [325, 330], [331, 344], [345, 355], [356, 361], [362, 372], [373, 379], [379, 380], [380, 388], [388, 389]]}
{"doc_key": "ai-test-258", "ner": [[7, 7, "metrics"], [9, 10, "metrics"], [12, 12, "metrics"], [46, 48, "metrics"], [55, 57, "metrics"], [61, 67, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 12, 9, 10, "named", "", false, false], [46, 48, 55, 57, "named", "", false, false], [55, 57, 61, 67, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Forse", "la", "statistica", "pi\u00f9", "semplice", "\u00e8", "l'", "accuratezza", "o", "Frazione", "corretta", "(", "FC", ")", ",", "che", "misura", "la", "frazione", "di", "tutte", "le", "istanze", "classificate", "correttamente", ";", "\u00e8", "il", "rapporto", "tra", "il", "numero", "di", "classificazioni", "corrette", "e", "il", "numero", "totale", "di", "classificazioni", "corrette", "o", "errate", ":", "(", "TP", "+", "TN", ")", "/", "Popolazione", "totale", "=", "(", "TP", "+", "TN", ")", "/", "(", "TP", "+", "TN", "+", "FP", "+", "FN", ")", "."], "sentence-detokenized": "Forse la statistica pi\u00f9 semplice \u00e8 l'accuratezza o Frazione corretta (FC), che misura la frazione di tutte le istanze classificate correttamente; \u00e8 il rapporto tra il numero di classificazioni corrette e il numero totale di classificazioni corrette o errate: (TP + TN) / Popolazione totale = (TP + TN) / (TP + TN + FP + FN).", "token2charspan": [[0, 5], [6, 8], [9, 19], [20, 23], [24, 32], [33, 34], [35, 37], [37, 48], [49, 50], [51, 59], [60, 68], [69, 70], [70, 72], [72, 73], [73, 74], [75, 78], [79, 85], [86, 88], [89, 97], [98, 100], [101, 106], [107, 109], [110, 117], [118, 130], [131, 144], [144, 145], [146, 147], [148, 150], [151, 159], [160, 163], [164, 166], [167, 173], [174, 176], [177, 192], [193, 201], [202, 203], [204, 206], [207, 213], [214, 220], [221, 223], [224, 239], [240, 248], [249, 250], [251, 257], [257, 258], [259, 260], [260, 262], [263, 264], [265, 267], [267, 268], [269, 270], [271, 282], [283, 289], [290, 291], [292, 293], [293, 295], [296, 297], [298, 300], [300, 301], [302, 303], [304, 305], [305, 307], [308, 309], [310, 312], [313, 314], [315, 317], [318, 319], [320, 322], [322, 323], [323, 324]]}
{"doc_key": "ai-test-259", "ner": [[19, 26, "conference"], [28, 28, "conference"], [31, 31, "location"], [35, 36, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[19, 26, 31, 31, "physical", "", false, false], [28, 28, 19, 26, "named", "", false, false], [35, 36, 19, 26, "role", "sponsors", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Nella", "comunit\u00e0", "accademica", ",", "i", "principali", "forum", "di", "ricerca", "sono", "iniziati", "nel", "1995", ",", "quando", "\u00e8", "stata", "avviata", "la", "prima", "conferenza", "internazionale", "Data", "Mining", "and", "Knowledge", "Discovery", "(", "KDD-95", ")", "a", "Montreal", "con", "il", "patrocinio", "dell'", "AAAI", "."], "sentence-detokenized": "Nella comunit\u00e0 accademica, i principali forum di ricerca sono iniziati nel 1995, quando \u00e8 stata avviata la prima conferenza internazionale Data Mining and Knowledge Discovery (KDD-95) a Montreal con il patrocinio dell'AAAI.", "token2charspan": [[0, 5], [6, 14], [15, 25], [25, 26], [27, 28], [29, 39], [40, 45], [46, 48], [49, 56], [57, 61], [62, 70], [71, 74], [75, 79], [79, 80], [81, 87], [88, 89], [90, 95], [96, 103], [104, 106], [107, 112], [113, 123], [124, 138], [139, 143], [144, 150], [151, 154], [155, 164], [165, 174], [175, 176], [176, 182], [182, 183], [184, 185], [186, 194], [195, 198], [199, 201], [202, 212], [213, 218], [218, 222], [222, 223]]}
{"doc_key": "ai-test-260", "ner": [[11, 13, "field"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "questo", "approccio", ",", "vengono", "sviluppati", "modelli", "che", "utilizzano", "diversi", "algoritmi", "di", "data", "mining", "e", "machine", "learning", "per", "prevedere", "le", "valutazioni", "degli", "utenti", "sugli", "articoli", "non", "valutati", "."], "sentence-detokenized": "In questo approccio, vengono sviluppati modelli che utilizzano diversi algoritmi di data mining e machine learning per prevedere le valutazioni degli utenti sugli articoli non valutati.", "token2charspan": [[0, 2], [3, 9], [10, 19], [19, 20], [21, 28], [29, 39], [40, 47], [48, 51], [52, 62], [63, 70], [71, 80], [81, 83], [84, 88], [89, 95], [96, 97], [98, 105], [106, 114], [115, 118], [119, 128], [129, 131], [132, 143], [144, 149], [150, 156], [157, 162], [163, 171], [172, 175], [176, 184], [184, 185]]}
{"doc_key": "ai-test-261", "ner": [[10, 10, "algorithm"], [14, 15, "algorithm"], [17, 19, "algorithm"], [26, 28, "misc"], [31, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 10, 14, 15, "related-to", "equivalent", false, false], [14, 15, 17, 19, "usage", "", false, false], [17, 19, 31, 33, "usage", "", false, false], [31, 33, 26, 28, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Alla", "luce", "della", "discussione", "precedente", ",", "vediamo", "che", "la", "tecnica", "SVM", "\u00e8", "equivalente", "al", "rischio", "empirico", "con", "regolarizzazione", "di", "Tikhonov", ",", "dove", "in", "questo", "caso", "la", "funzione", "di", "perdita", "\u00e8", "la", "perdita", "a", "cerniera"], "sentence-detokenized": "Alla luce della discussione precedente, vediamo che la tecnica SVM \u00e8 equivalente al rischio empirico con regolarizzazione di Tikhonov, dove in questo caso la funzione di perdita \u00e8 la perdita a cerniera", "token2charspan": [[0, 4], [5, 9], [10, 15], [16, 27], [28, 38], [38, 39], [40, 47], [48, 51], [52, 54], [55, 62], [63, 66], [67, 68], [69, 80], [81, 83], [84, 91], [92, 100], [101, 104], [105, 121], [122, 124], [125, 133], [133, 134], [135, 139], [140, 142], [143, 149], [150, 154], [155, 157], [158, 166], [167, 169], [170, 177], [178, 179], [180, 182], [183, 190], [191, 192], [193, 201]]}
{"doc_key": "ai-test-262", "ner": [[7, 8, "person"], [11, 12, "person"], [17, 17, "organisation"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[18, 19, 17, 17, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["L'", "edizione", "2015", "\u00e8", "stata", "condotta", "da", "Molly", "McGrath", ",", "con", "Chris", "Rose", "e", "l'", "ex", "lottatore", "UFC", "Kenny", "Florian", "come", "commentatori", "."], "sentence-detokenized": "L'edizione 2015 \u00e8 stata condotta da Molly McGrath, con Chris Rose e l'ex lottatore UFC Kenny Florian come commentatori.", "token2charspan": [[0, 2], [2, 10], [11, 15], [16, 17], [18, 23], [24, 32], [33, 35], [36, 41], [42, 49], [49, 50], [51, 54], [55, 60], [61, 65], [66, 67], [68, 70], [70, 72], [73, 82], [83, 86], [87, 92], [93, 100], [101, 105], [106, 118], [118, 119]]}
{"doc_key": "ai-test-263", "ner": [[3, 5, "product"], [10, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"], [19, 19, "researcher"], [21, 21, "researcher"], [37, 37, "researcher"], [31, 34, "task"], [35, 35, "product"], [42, 44, "researcher"], [45, 47, "task"], [52, 53, "researcher"], [55, 56, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[3, 5, 10, 12, "origin", "", false, false], [3, 5, 14, 15, "origin", "", false, false], [3, 5, 17, 18, "origin", "", false, false], [3, 5, 19, 19, "origin", "", false, false], [14, 15, 42, 44, "named", "same", false, false], [17, 18, 21, 21, "named", "same", false, false], [17, 18, 37, 37, "named", "same", false, false], [31, 34, 35, 35, "related-to", "", false, false], [35, 35, 37, 37, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Un", "sottoinsieme", "chiamato", "Micro", "-", "Planner", "\u00e8", "stato", "implementato", "da", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "e", "Terry", "Winograd", "Sussman", "e", "Winograd", "nel", "1971", "ed", "\u00e8", "stato", "utilizzato", "nel", "programma", "di", "comprensione", "del", "linguaggio", "naturale", "SHRDLU", "di", "Winograd", ",", "nel", "lavoro", "di", "Eugene", "Charniak", "sulla", "comprensione", "delle", "storie", ",", "nel", "lavoro", "di", "Thorne", "McCarty", "sul", "ragionamento", "giuridico", "e", "in", "alcuni", "altri", "progetti", "."], "sentence-detokenized": "Un sottoinsieme chiamato Micro-Planner \u00e8 stato implementato da Gerald Jay Sussman, Eugene Charniak e Terry Winograd Sussman e Winograd nel 1971 ed \u00e8 stato utilizzato nel programma di comprensione del linguaggio naturale SHRDLU di Winograd, nel lavoro di Eugene Charniak sulla comprensione delle storie, nel lavoro di Thorne McCarty sul ragionamento giuridico e in alcuni altri progetti.", "token2charspan": [[0, 2], [3, 15], [16, 24], [25, 30], [30, 31], [31, 38], [39, 40], [41, 46], [47, 59], [60, 62], [63, 69], [70, 73], [74, 81], [81, 82], [83, 89], [90, 98], [99, 100], [101, 106], [107, 115], [116, 123], [124, 125], [126, 134], [135, 138], [139, 143], [144, 146], [147, 148], [149, 154], [155, 165], [166, 169], [170, 179], [180, 182], [183, 195], [196, 199], [200, 210], [211, 219], [220, 226], [227, 229], [230, 238], [238, 239], [240, 243], [244, 250], [251, 253], [254, 260], [261, 269], [270, 275], [276, 288], [289, 294], [295, 301], [301, 302], [303, 306], [307, 313], [314, 316], [317, 323], [324, 331], [332, 335], [336, 348], [349, 358], [359, 360], [361, 363], [364, 370], [371, 376], [377, 385], [385, 386]]}
{"doc_key": "ai-test-264", "ner": [[0, 0, "product"], [8, 9, "product"], [14, 18, "task"], [21, 23, "task"], [26, 29, "task"], [32, 33, "task"], [36, 37, "task"], [41, 44, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[8, 9, 0, 0, "usage", "", true, false], [14, 18, 8, 9, "part-of", "", true, false], [21, 23, 8, 9, "part-of", "", true, false], [26, 29, 8, 9, "part-of", "", true, false], [32, 33, 8, 9, "part-of", "", true, false], [36, 37, 8, 9, "part-of", "", true, false], [41, 44, 8, 9, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["WordNet", "\u00e8", "stato", "utilizzato", "per", "diversi", "scopi", "nei", "sistemi", "informativi", ",", "tra", "cui", "la", "disambiguazione", "del", "senso", "delle", "parole", ",", "il", "recupero", "di", "informazioni", ",", "la", "classificazione", "automatica", "dei", "testi", ",", "la", "sintesi", "automatica", ",", "la", "traduzione", "automatica", "e", "persino", "la", "generazione", "automatica", "di", "cruciverba", "."], "sentence-detokenized": "WordNet \u00e8 stato utilizzato per diversi scopi nei sistemi informativi, tra cui la disambiguazione del senso delle parole, il recupero di informazioni, la classificazione automatica dei testi, la sintesi automatica, la traduzione automatica e persino la generazione automatica di cruciverba.", "token2charspan": [[0, 7], [8, 9], [10, 15], [16, 26], [27, 30], [31, 38], [39, 44], [45, 48], [49, 56], [57, 68], [68, 69], [70, 73], [74, 77], [78, 80], [81, 96], [97, 100], [101, 106], [107, 112], [113, 119], [119, 120], [121, 123], [124, 132], [133, 135], [136, 148], [148, 149], [150, 152], [153, 168], [169, 179], [180, 183], [184, 189], [189, 190], [191, 193], [194, 201], [202, 212], [212, 213], [214, 216], [217, 227], [228, 238], [239, 240], [241, 248], [249, 251], [252, 263], [264, 274], [275, 277], [278, 288], [288, 289]]}
{"doc_key": "ai-test-265", "ner": [[0, 0, "researcher"], [6, 6, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 6, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Keutzer", "\u00e8", "stato", "nominato", "Fellow", "dell'", "IEEE", "nel", "1996", "."], "sentence-detokenized": "Keutzer \u00e8 stato nominato Fellow dell'IEEE nel 1996.", "token2charspan": [[0, 7], [8, 9], [10, 15], [16, 24], [25, 31], [32, 37], [37, 41], [42, 45], [46, 50], [50, 51]]}
{"doc_key": "ai-test-266", "ner": [[8, 11, "algorithm"], [55, 57, "misc"], [66, 67, "algorithm"], [70, 71, "algorithm"], [74, 75, "algorithm"], [78, 79, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[66, 67, 55, 57, "type-of", "", false, false], [70, 71, 55, 57, "type-of", "", false, false], [74, 75, 55, 57, "type-of", "", false, false], [78, 79, 55, 57, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Un", "tipo", "di", "composizione", "ampiamente", "utilizzato", "\u00e8", "la", "somma", "pesata", "non", "lineare", ",", "dove", "math", "\\", "textstyle", "f", "(", "x", ")", "=", "K", "\\", "left", "(", "\\", "sum", "_", "i", "w", "_", "i", "g", "_", "i", "(", "x", ")", "\\", "right", ")", "/", "math", ",", "dove", "math", "\\", "textstyle", "K", "/", "math", "(", "comunemente", "chiamata", "funzione", "di", "attivazione", ")", "\u00e8", "una", "funzione", "predefinita", ",", "come", "la", "tangente", "iperbolica", ",", "la", "funzione", "sigmoide", ",", "la", "funzione", "softmax", "o", "la", "funzione", "raddrizzatrice", "."], "sentence-detokenized": "Un tipo di composizione ampiamente utilizzato \u00e8 la somma pesata non lineare, dove math\\ textstyle f (x) = K\\ left (\\ sum _ i w _ i g _ i (x)\\ right) / math, dove math\\ textstyle K / math (comunemente chiamata funzione di attivazione) \u00e8 una funzione predefinita, come la tangente iperbolica, la funzione sigmoide, la funzione softmax o la funzione raddrizzatrice.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 23], [24, 34], [35, 45], [46, 47], [48, 50], [51, 56], [57, 63], [64, 67], [68, 75], [75, 76], [77, 81], [82, 86], [86, 87], [88, 97], [98, 99], [100, 101], [101, 102], [102, 103], [104, 105], [106, 107], [107, 108], [109, 113], [114, 115], [115, 116], [117, 120], [121, 122], [123, 124], [125, 126], [127, 128], [129, 130], [131, 132], [133, 134], [135, 136], [137, 138], [138, 139], [139, 140], [140, 141], [142, 147], [147, 148], [149, 150], [151, 155], [155, 156], [157, 161], [162, 166], [166, 167], [168, 177], [178, 179], [180, 181], [182, 186], [187, 188], [188, 199], [200, 208], [209, 217], [218, 220], [221, 232], [232, 233], [234, 235], [236, 239], [240, 248], [249, 260], [260, 261], [262, 266], [267, 269], [270, 278], [279, 289], [289, 290], [291, 293], [294, 302], [303, 311], [311, 312], [313, 315], [316, 324], [325, 332], [333, 334], [335, 337], [338, 346], [347, 361], [361, 362]]}
{"doc_key": "ai-test-267", "ner": [[2, 2, "misc"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Nel", "film", "Westworld", ",", "le", "donne", "robot", "hanno", "effettivamente", "avuto", "rapporti", "sessuali", "con", "uomini", "umani", "come", "parte", "del", "mondo", "di", "vacanza", "immaginario", "a", "cui", "i", "clienti", "umani", "pagavano", "per", "partecipare", "."], "sentence-detokenized": "Nel film Westworld, le donne robot hanno effettivamente avuto rapporti sessuali con uomini umani come parte del mondo di vacanza immaginario a cui i clienti umani pagavano per partecipare.", "token2charspan": [[0, 3], [4, 8], [9, 18], [18, 19], [20, 22], [23, 28], [29, 34], [35, 40], [41, 55], [56, 61], [62, 70], [71, 79], [80, 83], [84, 90], [91, 96], [97, 101], [102, 107], [108, 111], [112, 117], [118, 120], [121, 128], [129, 140], [141, 142], [143, 146], [147, 148], [149, 156], [157, 162], [163, 171], [172, 175], [176, 187], [187, 188]]}
{"doc_key": "ai-test-268", "ner": [[8, 10, "task"], [27, 31, "task"], [34, 35, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 27, 31, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "genere", ",", "il", "processo", "inizia", "con", "l'", "estrazione", "della", "terminologia", "e", "dei", "concetti", "o", "delle", "frasi", "sostantive", "dal", "testo", "semplice", ",", "utilizzando", "processori", "linguistici", "come", "il", "part", "-", "of-", "speech", "tagging", "e", "il", "phrase", "chunking", "."], "sentence-detokenized": "In genere, il processo inizia con l'estrazione della terminologia e dei concetti o delle frasi sostantive dal testo semplice, utilizzando processori linguistici come il part-of-speech tagging e il phrase chunking.", "token2charspan": [[0, 2], [3, 9], [9, 10], [11, 13], [14, 22], [23, 29], [30, 33], [34, 36], [36, 46], [47, 52], [53, 65], [66, 67], [68, 71], [72, 80], [81, 82], [83, 88], [89, 94], [95, 105], [106, 109], [110, 115], [116, 124], [124, 125], [126, 137], [138, 148], [149, 160], [161, 165], [166, 168], [169, 173], [173, 174], [174, 177], [177, 183], [184, 191], [192, 193], [194, 196], [197, 203], [204, 212], [212, 213]]}
{"doc_key": "ai-test-269", "ner": [[16, 17, "field"], [22, 24, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[22, 24, 16, 17, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0], "sentence": ["Hanno", "dimostrato", "le", "sue", "prestazioni", "su", "una", "serie", "di", "problemi", "di", "interesse", "per", "la", "comunit\u00e0", "dell'", "apprendimento", "automatico", ",", "tra", "cui", "il", "riconoscimento", "della", "scrittura", "."], "sentence-detokenized": "Hanno dimostrato le sue prestazioni su una serie di problemi di interesse per la comunit\u00e0 dell'apprendimento automatico, tra cui il riconoscimento della scrittura.", "token2charspan": [[0, 5], [6, 16], [17, 19], [20, 23], [24, 35], [36, 38], [39, 42], [43, 48], [49, 51], [52, 60], [61, 63], [64, 73], [74, 77], [78, 80], [81, 89], [90, 95], [95, 108], [109, 119], [119, 120], [121, 124], [125, 128], [129, 131], [132, 146], [147, 152], [153, 162], [162, 163]]}
{"doc_key": "ai-test-270", "ner": [[3, 3, "university"], [5, 6, "researcher"], [13, 14, "researcher"], [19, 19, "product"], [23, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 3, 3, "physical", "", false, false], [5, 6, 3, 3, "role", "", false, false], [19, 19, 13, 14, "origin", "", false, false], [19, 19, 23, 24, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Mentre", "studiava", "a", "Stanford", ",", "Scheinman", "ottenne", "una", "borsa", "di", "studio", "sponsorizzata", "da", "George", "Devol", ",", "l'", "inventore", "dell'", "Unimate", ",", "il", "primo", "robot", "industriale", "."], "sentence-detokenized": "Mentre studiava a Stanford, Scheinman ottenne una borsa di studio sponsorizzata da George Devol, l'inventore dell'Unimate, il primo robot industriale.", "token2charspan": [[0, 6], [7, 15], [16, 17], [18, 26], [26, 27], [28, 37], [38, 45], [46, 49], [50, 55], [56, 58], [59, 65], [66, 79], [80, 82], [83, 89], [90, 95], [95, 96], [97, 99], [99, 108], [109, 114], [114, 121], [121, 122], [123, 125], [126, 131], [132, 137], [138, 149], [149, 150]]}
{"doc_key": "ai-test-271", "ner": [[8, 9, "task"], [12, 14, "metrics"], [16, 16, "metrics"], [27, 31, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 12, 14, "usage", "", true, false], [16, 16, 12, 14, "named", "", false, false], [27, 31, 12, 14, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Sebbene", "sia", "stato", "originariamente", "utilizzato", "per", "valutare", "le", "traduzioni", "automatiche", ",", "il", "bilingual", "evaluation", "understudy", "(", "BLEU", ")", "\u00e8", "stato", "utilizzato", "con", "successo", "anche", "per", "valutare", "i", "modelli", "di", "generazione", "di", "parafrasi", "."], "sentence-detokenized": "Sebbene sia stato originariamente utilizzato per valutare le traduzioni automatiche, il bilingual evaluation understudy (BLEU) \u00e8 stato utilizzato con successo anche per valutare i modelli di generazione di parafrasi.", "token2charspan": [[0, 7], [8, 11], [12, 17], [18, 33], [34, 44], [45, 48], [49, 57], [58, 60], [61, 71], [72, 83], [83, 84], [85, 87], [88, 97], [98, 108], [109, 119], [120, 121], [121, 125], [125, 126], [127, 128], [129, 134], [135, 145], [146, 149], [150, 158], [159, 164], [165, 168], [169, 177], [178, 179], [180, 187], [188, 190], [191, 202], [203, 205], [206, 215], [215, 216]]}
{"doc_key": "ai-test-272", "ner": [[2, 2, "organisation"], [11, 13, "organisation"], [15, 15, "organisation"], [19, 19, "product"], [22, 22, "country"], [25, 25, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 11, 13, "role", "licenses_to", false, false], [2, 2, 15, 15, "role", "licenses_to", false, false], [11, 13, 22, 22, "physical", "", false, false], [15, 15, 25, 25, "physical", "", false, false], [19, 19, 11, 13, "artifact", "produces", false, false], [19, 19, 15, 15, "artifact", "produces", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "seguito", "Unimation", "ha", "concesso", "la", "propria", "tecnologia", "in", "licenza", "a", "Kawasaki", "Heavy", "Industries", "e", "GKN", ",", "che", "producono", "Unimation", "rispettivamente", "in", "Giappone", "e", "in", "Inghilterra", "."], "sentence-detokenized": "In seguito Unimation ha concesso la propria tecnologia in licenza a Kawasaki Heavy Industries e GKN, che producono Unimation rispettivamente in Giappone e in Inghilterra.", "token2charspan": [[0, 2], [3, 10], [11, 20], [21, 23], [24, 32], [33, 35], [36, 43], [44, 54], [55, 57], [58, 65], [66, 67], [68, 76], [77, 82], [83, 93], [94, 95], [96, 99], [99, 100], [101, 104], [105, 114], [115, 124], [125, 140], [141, 143], [144, 152], [153, 154], [155, 157], [158, 169], [169, 170]]}
{"doc_key": "ai-test-273", "ner": [[20, 21, "conference"], [38, 39, "field"], [57, 64, "field"], [66, 66, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[38, 39, 57, 64, "compare", "", false, false], [66, 66, 57, 64, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Gran", "parte", "della", "confusione", "tra", "queste", "due", "comunit\u00e0", "di", "ricerca", "(", "che", "spesso", "hanno", "conferenze", "e", "riviste", "separate", ",", "l'", "ECML", "PKDD", "\u00e8", "una", "delle", "principali", "eccezioni", ")", "deriva", "dai", "presupposti", "di", "base", "con", "cui", "lavorano", ":", "nell'", "apprendimento", "automatico", ",", "le", "prestazioni", "sono", "solitamente", "valutate", "rispetto", "alla", "capacit\u00e0", "di", "riprodurre", "la", "conoscenza", "nota", ",", "mentre", "nella", "scoperta", "della", "conoscenza", "e", "nell'", "estrazione", "dei", "dati", "(", "KDD", ")", "il", "compito", "principale", "\u00e8", "la", "scoperta", "di", "conoscenza", "precedentemente", "sconosciuta", "."], "sentence-detokenized": "Gran parte della confusione tra queste due comunit\u00e0 di ricerca (che spesso hanno conferenze e riviste separate, l'ECML PKDD \u00e8 una delle principali eccezioni) deriva dai presupposti di base con cui lavorano: nell'apprendimento automatico, le prestazioni sono solitamente valutate rispetto alla capacit\u00e0 di riprodurre la conoscenza nota, mentre nella scoperta della conoscenza e nell'estrazione dei dati (KDD) il compito principale \u00e8 la scoperta di conoscenza precedentemente sconosciuta.", "token2charspan": [[0, 4], [5, 10], [11, 16], [17, 27], [28, 31], [32, 38], [39, 42], [43, 51], [52, 54], [55, 62], [63, 64], [64, 67], [68, 74], [75, 80], [81, 91], [92, 93], [94, 101], [102, 110], [110, 111], [112, 114], [114, 118], [119, 123], [124, 125], [126, 129], [130, 135], [136, 146], [147, 156], [156, 157], [158, 164], [165, 168], [169, 180], [181, 183], [184, 188], [189, 192], [193, 196], [197, 205], [205, 206], [207, 212], [212, 225], [226, 236], [236, 237], [238, 240], [241, 252], [253, 257], [258, 269], [270, 278], [279, 287], [288, 292], [293, 301], [302, 304], [305, 315], [316, 318], [319, 329], [330, 334], [334, 335], [336, 342], [343, 348], [349, 357], [358, 363], [364, 374], [375, 376], [377, 382], [382, 392], [393, 396], [397, 401], [402, 403], [403, 406], [406, 407], [408, 410], [411, 418], [419, 429], [430, 431], [432, 434], [435, 443], [444, 446], [447, 457], [458, 473], [474, 485], [485, 486]]}
{"doc_key": "ai-test-274", "ner": [[3, 4, "algorithm"], [13, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 13, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["I", "modelli", "di", "Markov", "nascosti", "sono", "alla", "base", "della", "maggior", "parte", "dei", "moderni", "sistemi", "di", "riconoscimento", "automatico", "del", "parlato", "."], "sentence-detokenized": "I modelli di Markov nascosti sono alla base della maggior parte dei moderni sistemi di riconoscimento automatico del parlato.", "token2charspan": [[0, 1], [2, 9], [10, 12], [13, 19], [20, 28], [29, 33], [34, 38], [39, 43], [44, 49], [50, 57], [58, 63], [64, 67], [68, 75], [76, 83], [84, 86], [87, 101], [102, 112], [113, 116], [117, 124], [124, 125]]}
{"doc_key": "ai-test-275", "ner": [[4, 4, "location"], [7, 7, "country"], [12, 15, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 7, 7, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": [",", "un'", "azienda", "di", "Bangalore", ",", "in", "India", ",", "specializzata", "in", "software", "di", "riconoscimento", "della", "scrittura", "online", "."], "sentence-detokenized": ", un'azienda di Bangalore, in India, specializzata in software di riconoscimento della scrittura online.", "token2charspan": [[0, 1], [2, 5], [5, 12], [13, 15], [16, 25], [25, 26], [27, 29], [30, 35], [35, 36], [37, 50], [51, 53], [54, 62], [63, 65], [66, 80], [81, 86], [87, 96], [97, 103], [103, 104]]}
{"doc_key": "ai-test-276", "ner": [[24, 25, "misc"], [50, 50, "metrics"], [52, 54, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[50, 50, 52, 54, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Le", "traduzioni", "ripetute", "convergono", "su", "un'", "unica", "espressione", "in", "entrambe", "le", "lingue", "?", "Cio\u00e8", ",", "il", "metodo", "di", "traduzione", "mostra", "stazionariet\u00e0", "o", "produce", "una", "forma", "canonica", "?", "La", "traduzione", "diventa", "stazionaria", "senza", "perdere", "il", "significato", "originale", "?", "Questa", "metrica", "\u00e8", "stata", "criticata", "perch\u00e9", "non", "\u00e8", "ben", "correlata", "con", "i", "punteggi", "BLEU", "(", "BiLingual", "Evaluation", "Understudy", ")", "."], "sentence-detokenized": "Le traduzioni ripetute convergono su un'unica espressione in entrambe le lingue? Cio\u00e8, il metodo di traduzione mostra stazionariet\u00e0 o produce una forma canonica? La traduzione diventa stazionaria senza perdere il significato originale? Questa metrica \u00e8 stata criticata perch\u00e9 non \u00e8 ben correlata con i punteggi BLEU (BiLingual Evaluation Understudy).", "token2charspan": [[0, 2], [3, 13], [14, 22], [23, 33], [34, 36], [37, 40], [40, 45], [46, 57], [58, 60], [61, 69], [70, 72], [73, 79], [79, 80], [81, 85], [85, 86], [87, 89], [90, 96], [97, 99], [100, 110], [111, 117], [118, 131], [132, 133], [134, 141], [142, 145], [146, 151], [152, 160], [160, 161], [162, 164], [165, 175], [176, 183], [184, 195], [196, 201], [202, 209], [210, 212], [213, 224], [225, 234], [234, 235], [236, 242], [243, 250], [251, 252], [253, 258], [259, 268], [269, 275], [276, 279], [280, 281], [282, 285], [286, 295], [296, 299], [300, 301], [302, 310], [311, 315], [316, 317], [317, 326], [327, 337], [338, 348], [348, 349], [349, 350]]}
{"doc_key": "ai-test-277", "ner": [[7, 11, "organisation"], [14, 21, "organisation"], [23, 25, "university"], [28, 28, "university"], [31, 32, "field"], [35, 39, "organisation"], [42, 44, "organisation"], [51, 54, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[14, 21, 23, 25, "part-of", "", false, false], [28, 28, 31, 32, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Ha", "ottenuto", "borse", "di", "studio", "presso", "l'", "American", "Association", "for", "Artificial", "Intelligence", ",", "il", "Center", "for", "Advanced", "Study", "in", "the", "Behavioral", "Sciences", "dell'", "Universit\u00e0", "di", "Stanford", ",", "il", "MIT", "Center", "for", "Cognitive", "Science", ",", "il", "Canadian", "Institute", "for", "Advanced", "Research", ",", "la", "Canadian", "Psychological", "Association", "ed", "\u00e8", "stato", "eletto", "Fellow", "della", "Royal", "Society", "of", "Canada", "nel", "1998", "."], "sentence-detokenized": "Ha ottenuto borse di studio presso l'American Association for Artificial Intelligence, il Center for Advanced Study in the Behavioral Sciences dell'Universit\u00e0 di Stanford, il MIT Center for Cognitive Science, il Canadian Institute for Advanced Research, la Canadian Psychological Association ed \u00e8 stato eletto Fellow della Royal Society of Canada nel 1998.", "token2charspan": [[0, 2], [3, 11], [12, 17], [18, 20], [21, 27], [28, 34], [35, 37], [37, 45], [46, 57], [58, 61], [62, 72], [73, 85], [85, 86], [87, 89], [90, 96], [97, 100], [101, 109], [110, 115], [116, 118], [119, 122], [123, 133], [134, 142], [143, 148], [148, 158], [159, 161], [162, 170], [170, 171], [172, 174], [175, 178], [179, 185], [186, 189], [190, 199], [200, 207], [207, 208], [209, 211], [212, 220], [221, 230], [231, 234], [235, 243], [244, 252], [252, 253], [254, 256], [257, 265], [266, 279], [280, 291], [292, 294], [295, 296], [297, 302], [303, 309], [310, 316], [317, 322], [323, 328], [329, 336], [337, 339], [340, 346], [347, 350], [351, 355], [355, 356]]}
{"doc_key": "ai-test-278", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [16, 19, "misc"], [22, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 16, 19, "part-of", "", false, false], [0, 0, 22, 23, "part-of", "", false, false], [4, 5, 16, 19, "part-of", "", false, false], [4, 5, 22, 23, "part-of", "", false, false], [7, 8, 16, 19, "part-of", "", false, false], [7, 8, 22, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Hinton", ",", "insieme", "a", "Yoshua", "Bengio", "e", "Yann", "LeCun", ",", "viene", "definito", "da", "alcuni", "come", "i", "padrini", "dell'", "intelligenza", "artificiale", "e", "dell'", "apprendimento", "profondo", "."], "sentence-detokenized": "Hinton, insieme a Yoshua Bengio e Yann LeCun, viene definito da alcuni come i padrini dell'intelligenza artificiale e dell'apprendimento profondo.", "token2charspan": [[0, 6], [6, 7], [8, 15], [16, 17], [18, 24], [25, 31], [32, 33], [34, 38], [39, 44], [44, 45], [46, 51], [52, 60], [61, 63], [64, 70], [71, 75], [76, 77], [78, 85], [86, 91], [91, 103], [104, 115], [116, 117], [118, 123], [123, 136], [137, 145], [145, 146]]}
{"doc_key": "ai-test-279", "ner": [[7, 7, "product"], [20, 20, "misc"], [23, 24, "misc"], [25, 25, "product"], [30, 31, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 7, 20, 20, "related-to", "", false, false], [7, 7, 23, 24, "related-to", "", false, false], [20, 20, 25, 25, "named", "same", false, false], [30, 31, 25, 25, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Il", "progetto", "vocale", "open", "-", "source", "leggero", "eSpeak", ",", "che", "ha", "un", "proprio", "approccio", "alla", "sintesi", ",", "ha", "sperimentato", "il", "mandarino", "e", "il", "cantonese", ".", "eSpeak", "\u00e8", "stato", "utilizzato", "da", "Google", "Translate", "dal", "maggio", "2010", "-", "2010", "."], "sentence-detokenized": "Il progetto vocale open-source leggero eSpeak, che ha un proprio approccio alla sintesi, ha sperimentato il mandarino e il cantonese. eSpeak \u00e8 stato utilizzato da Google Translate dal maggio 2010-2010.", "token2charspan": [[0, 2], [3, 11], [12, 18], [19, 23], [23, 24], [24, 30], [31, 38], [39, 45], [45, 46], [47, 50], [51, 53], [54, 56], [57, 64], [65, 74], [75, 79], [80, 87], [87, 88], [89, 91], [92, 104], [105, 107], [108, 117], [118, 119], [120, 122], [123, 132], [132, 133], [134, 140], [141, 142], [143, 148], [149, 159], [160, 162], [163, 169], [170, 179], [180, 183], [184, 190], [191, 195], [195, 196], [196, 200], [200, 201]]}
{"doc_key": "ai-test-280", "ner": [[6, 8, "product"], [13, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 13, 16, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Rilasciato", "anch'", "esso", "nel", "1982", ",", "Software", "Automatic", "Mouth", "\u00e8", "stato", "il", "primo", "programma", "commerciale", "di", "sintesi", "vocale", "interamente", "software", "."], "sentence-detokenized": "Rilasciato anch'esso nel 1982, Software Automatic Mouth \u00e8 stato il primo programma commerciale di sintesi vocale interamente software.", "token2charspan": [[0, 10], [11, 16], [16, 20], [21, 24], [25, 29], [29, 30], [31, 39], [40, 49], [50, 55], [56, 57], [58, 63], [64, 66], [67, 72], [73, 82], [83, 94], [95, 97], [98, 105], [106, 112], [113, 124], [125, 133], [133, 134]]}
{"doc_key": "ai-test-281", "ner": [[5, 8, "metrics"], [10, 10, "metrics"], [13, 13, "metrics"], [15, 15, "metrics"], [18, 24, "metrics"], [30, 33, "metrics"], [35, 35, "metrics"], [38, 44, "metrics"], [48, 51, "metrics"], [53, 53, "metrics"], [56, 56, "metrics"], [58, 58, "metrics"], [61, 67, "metrics"], [73, 76, "metrics"], [78, 78, "metrics"], [81, 87, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[10, 10, 5, 8, "named", "", false, false], [13, 13, 5, 8, "named", "", false, false], [15, 15, 5, 8, "named", "", false, false], [18, 24, 5, 8, "named", "", false, false], [35, 35, 30, 33, "named", "", false, false], [38, 44, 30, 33, "named", "", false, false], [53, 53, 48, 51, "named", "", false, false], [56, 56, 48, 51, "named", "", false, false], [58, 58, 48, 51, "named", "", false, false], [61, 67, 48, 51, "named", "", false, false], [78, 78, 73, 76, "named", "", false, false], [81, 87, 73, 76, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["I", "rapporti", "di", "colonna", "sono", "Tasso", "di", "positivit\u00e0", "reale", "(", "TPR", ",", "alias", "sensibilit\u00e0", "o", "richiamo", ")", "(", "TP", "/", "(", "TP", "+", "FN", ")", ")", ",", "con", "complemento", "il", "Tasso", "di", "negativit\u00e0", "FALSA", "(", "FNR", ")", "(", "FN", "/", "(", "TP", "+", "FN", ")", ")", ";", "e", "Tasso", "di", "negativit\u00e0", "reale", "(", "TNR", ",", "alias", "specificit\u00e0", ",", "SPC", ")", "(", "TN", "/", "(", "TN", "+", "FP", ")", ")", ",", "con", "complemento", "il", "Tasso", "di", "positivit\u00e0", "FALSA", "(", "FPR", ")", "(", "FP", "/", "(", "TN", "+", "FP", ")", ")", "."], "sentence-detokenized": "I rapporti di colonna sono Tasso di positivit\u00e0 reale (TPR, alias sensibilit\u00e0 o richiamo) (TP / (TP + FN)), con complemento il Tasso di negativit\u00e0 FALSA (FNR) (FN / (TP + FN)); e Tasso di negativit\u00e0 reale (TNR, alias specificit\u00e0, SPC) (TN / (TN + FP)), con complemento il Tasso di positivit\u00e0 FALSA (FPR) (FP / (TN + FP)).", "token2charspan": [[0, 1], [2, 10], [11, 13], [14, 21], [22, 26], [27, 32], [33, 35], [36, 46], [47, 52], [53, 54], [54, 57], [57, 58], [59, 64], [65, 76], [77, 78], [79, 87], [87, 88], [89, 90], [90, 92], [93, 94], [95, 96], [96, 98], [99, 100], [101, 103], [103, 104], [104, 105], [105, 106], [107, 110], [111, 122], [123, 125], [126, 131], [132, 134], [135, 145], [146, 151], [152, 153], [153, 156], [156, 157], [158, 159], [159, 161], [162, 163], [164, 165], [165, 167], [168, 169], [170, 172], [172, 173], [173, 174], [174, 175], [176, 177], [178, 183], [184, 186], [187, 197], [198, 203], [204, 205], [205, 208], [208, 209], [210, 215], [216, 227], [227, 228], [229, 232], [232, 233], [234, 235], [235, 237], [238, 239], [240, 241], [241, 243], [244, 245], [246, 248], [248, 249], [249, 250], [250, 251], [252, 255], [256, 267], [268, 270], [271, 276], [277, 279], [280, 290], [291, 296], [297, 298], [298, 301], [301, 302], [303, 304], [304, 306], [307, 308], [309, 310], [310, 312], [313, 314], [315, 317], [317, 318], [318, 319], [319, 320]]}
{"doc_key": "ai-test-282", "ner": [[0, 0, "person"], [2, 2, "person"], [19, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 19, 19, "role", "working_with", false, false], [2, 2, 19, 19, "role", "working_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Edsinger", "e", "Weber", "hanno", "collaborato", "anche", "a", "molti", "altri", "robot", ",", "e", "la", "loro", "esperienza", "di", "lavoro", "con", "il", "Kismet"], "sentence-detokenized": "Edsinger e Weber hanno collaborato anche a molti altri robot, e la loro esperienza di lavoro con il Kismet", "token2charspan": [[0, 8], [9, 10], [11, 16], [17, 22], [23, 34], [35, 40], [41, 42], [43, 48], [49, 54], [55, 60], [60, 61], [62, 63], [64, 66], [67, 71], [72, 82], [83, 85], [86, 92], [93, 96], [97, 99], [100, 106]]}
{"doc_key": "ai-test-283", "ner": [[3, 3, "programlang"], [14, 14, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 14, 14, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Le", "funzionalit\u00e0", "di", "R", "sono", "accessibili", "anche", "da", "diversi", "linguaggi", "di", "scripting", ",", "come", "Python", "."], "sentence-detokenized": "Le funzionalit\u00e0 di R sono accessibili anche da diversi linguaggi di scripting, come Python.", "token2charspan": [[0, 2], [3, 15], [16, 18], [19, 20], [21, 25], [26, 37], [38, 43], [44, 46], [47, 54], [55, 64], [65, 67], [68, 77], [77, 78], [79, 83], [84, 90], [90, 91]]}
{"doc_key": "ai-test-284", "ner": [[0, 0, "programlang"], [14, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 15, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VAL", "\u00e8", "stato", "uno", "dei", "primi", "linguaggi", "per", "robot", "ed", "\u00e8", "stato", "utilizzato", "nei", "robot", "Unimate", "."], "sentence-detokenized": "VAL \u00e8 stato uno dei primi linguaggi per robot ed \u00e8 stato utilizzato nei robot Unimate.", "token2charspan": [[0, 3], [4, 5], [6, 11], [12, 15], [16, 19], [20, 25], [26, 35], [36, 39], [40, 45], [46, 48], [49, 50], [51, 56], [57, 67], [68, 71], [72, 77], [78, 85], [85, 86]]}
{"doc_key": "ai-test-285", "ner": [[14, 28, "conference"], [24, 24, "conference"], [29, 29, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 28, 29, 29, "physical", "", false, false], [24, 24, 14, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hanno", "presentato", "il", "loro", "database", "per", "la", "prima", "volta", "sotto", "forma", "di", "poster", "alla", "Conferenza", "sulla", "visione", "artificiale", "e", "il", "riconoscimento", "dei", "modelli", "(", "CVPR", ")", "del", "2009", "in", "Florida", "."], "sentence-detokenized": "Hanno presentato il loro database per la prima volta sotto forma di poster alla Conferenza sulla visione artificiale e il riconoscimento dei modelli (CVPR) del 2009 in Florida.", "token2charspan": [[0, 5], [6, 16], [17, 19], [20, 24], [25, 33], [34, 37], [38, 40], [41, 46], [47, 52], [53, 58], [59, 64], [65, 67], [68, 74], [75, 79], [80, 90], [91, 96], [97, 104], [105, 116], [117, 118], [119, 121], [122, 136], [137, 140], [141, 148], [149, 150], [150, 154], [154, 155], [156, 159], [160, 164], [165, 167], [168, 175], [175, 176]]}
{"doc_key": "ai-test-286", "ner": [[0, 3, "misc"], [12, 14, "task"], [16, 18, "field"], [20, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 14, 0, 3, "type-of", "", false, false], [16, 18, 0, 3, "type-of", "", false, false], [20, 22, 0, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["I", "compiti", "di", "categorizzazione", "in", "cui", "non", "vengono", "fornite", "etichette", "sono", "definiti", "classificazione", "non", "supervisionata", ",", "apprendimento", "non", "supervisionato", ",", "analisi", "dei", "cluster", "."], "sentence-detokenized": "I compiti di categorizzazione in cui non vengono fornite etichette sono definiti classificazione non supervisionata, apprendimento non supervisionato, analisi dei cluster.", "token2charspan": [[0, 1], [2, 9], [10, 12], [13, 29], [30, 32], [33, 36], [37, 40], [41, 48], [49, 56], [57, 66], [67, 71], [72, 80], [81, 96], [97, 100], [101, 115], [115, 116], [117, 130], [131, 134], [135, 149], [149, 150], [151, 158], [159, 162], [163, 170], [170, 171]]}
{"doc_key": "ai-test-287", "ner": [[1, 3, "task"], [12, 15, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Deve", "riconoscere", "gli", "oggetti", ",", "riconoscere", "e", "localizzare", "gli", "esseri", "umani", "e", "riconoscere", "ulteriormente", "le", "emozioni", "."], "sentence-detokenized": "Deve riconoscere gli oggetti, riconoscere e localizzare gli esseri umani e riconoscere ulteriormente le emozioni.", "token2charspan": [[0, 4], [5, 16], [17, 20], [21, 28], [28, 29], [30, 41], [42, 43], [44, 55], [56, 59], [60, 66], [67, 72], [73, 74], [75, 86], [87, 100], [101, 103], [104, 112], [112, 113]]}
{"doc_key": "ai-test-288", "ner": [[7, 7, "misc"], [10, 10, "misc"], [13, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Il", "processo", "\u00e8", "complesso", "e", "comprende", "la", "codifica", "e", "il", "richiamo", "o", "il", "recupero", "."], "sentence-detokenized": "Il processo \u00e8 complesso e comprende la codifica e il richiamo o il recupero.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 23], [24, 25], [26, 35], [36, 38], [39, 47], [48, 49], [50, 52], [53, 61], [62, 63], [64, 66], [67, 75], [75, 76]]}
{"doc_key": "ai-test-289", "ner": [[6, 7, "product"], [11, 12, "product"], [29, 30, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 11, 12, "named", "", false, false], [6, 7, 29, 30, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Conosciuti", "anche", "come", "robot", "paralleli", "o", "piattaforme", "Stewart", "generalizzate", "(", "nella", "piattaforma", "Stewart", ",", "gli", "attuatori", "sono", "accoppiati", "sia", "sulla", "base", "che", "sulla", "piattaforma", ")", ",", "questi", "sistemi", "sono", "robot", "articolati", "che", "utilizzano", "meccanismi", "simili", "per", "il", "movimento", "del", "robot", "sulla", "base", "o", "di", "uno", "o", "pi\u00f9", "bracci", "manipolatori", "."], "sentence-detokenized": "Conosciuti anche come robot paralleli o piattaforme Stewart generalizzate (nella piattaforma Stewart, gli attuatori sono accoppiati sia sulla base che sulla piattaforma), questi sistemi sono robot articolati che utilizzano meccanismi simili per il movimento del robot sulla base o di uno o pi\u00f9 bracci manipolatori.", "token2charspan": [[0, 10], [11, 16], [17, 21], [22, 27], [28, 37], [38, 39], [40, 51], [52, 59], [60, 73], [74, 75], [75, 80], [81, 92], [93, 100], [100, 101], [102, 105], [106, 115], [116, 120], [121, 131], [132, 135], [136, 141], [142, 146], [147, 150], [151, 156], [157, 168], [168, 169], [169, 170], [171, 177], [178, 185], [186, 190], [191, 196], [197, 207], [208, 211], [212, 222], [223, 233], [234, 240], [241, 244], [245, 247], [248, 257], [258, 261], [262, 267], [268, 273], [274, 278], [279, 280], [281, 283], [284, 287], [288, 289], [290, 293], [294, 300], [301, 313], [313, 314]]}
{"doc_key": "ai-test-290", "ner": [[0, 2, "field"], [6, 8, "field"], [14, 15, "field"], [20, 20, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 6, 8, "part-of", "subfield", false, false], [0, 2, 14, 15, "compare", "", false, false], [14, 15, 20, 20, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "visione", "artificiale", "come", "disciplina", "di", "ingegneria", "dei", "sistemi", "pu\u00f2", "essere", "considerata", "distinta", "dalla", "computer", "vision", ",", "una", "forma", "di", "informatica", "."], "sentence-detokenized": "La visione artificiale come disciplina di ingegneria dei sistemi pu\u00f2 essere considerata distinta dalla computer vision, una forma di informatica.", "token2charspan": [[0, 2], [3, 10], [11, 22], [23, 27], [28, 38], [39, 41], [42, 52], [53, 56], [57, 64], [65, 68], [69, 75], [76, 87], [88, 96], [97, 102], [103, 111], [112, 118], [118, 119], [120, 123], [124, 129], [130, 132], [133, 144], [144, 145]]}
{"doc_key": "ai-test-291", "ner": [[5, 6, "algorithm"], [10, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 10, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["La", "funzione", "di", "attivazione", "delle", "porte", "LSTM", "\u00e8", "spesso", "la", "funzione", "sigmoide", "logistica", "."], "sentence-detokenized": "La funzione di attivazione delle porte LSTM \u00e8 spesso la funzione sigmoide logistica.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 32], [33, 38], [39, 43], [44, 45], [46, 52], [53, 55], [56, 64], [65, 73], [74, 83], [83, 84]]}
{"doc_key": "ai-test-292", "ner": [[5, 6, "metrics"], [19, 24, "metrics"], [26, 26, "metrics"], [33, 36, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 19, 24, "named", "", false, false], [5, 6, 33, 36, "named", "", false, false], [26, 26, 19, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "altre", "parole", ",", "la", "media", "campionaria", "\u00e8", "lo", "stimatore", "efficiente", "(", "necessariamente", "unico", ")", "e", "quindi", "anche", "lo", "stimatore", "non", "condizionato", "dalla", "minima", "varianza", "(", "MVUE", ")", ",", "oltre", "a", "essere", "lo", "stimatore", "di", "massima", "verosimiglianza", "."], "sentence-detokenized": "In altre parole, la media campionaria \u00e8 lo stimatore efficiente (necessariamente unico) e quindi anche lo stimatore non condizionato dalla minima varianza (MVUE), oltre a essere lo stimatore di massima verosimiglianza.", "token2charspan": [[0, 2], [3, 8], [9, 15], [15, 16], [17, 19], [20, 25], [26, 37], [38, 39], [40, 42], [43, 52], [53, 63], [64, 65], [65, 80], [81, 86], [86, 87], [88, 89], [90, 96], [97, 102], [103, 105], [106, 115], [116, 119], [120, 132], [133, 138], [139, 145], [146, 154], [155, 156], [156, 160], [160, 161], [161, 162], [163, 168], [169, 170], [171, 177], [178, 180], [181, 190], [191, 193], [194, 201], [202, 217], [217, 218]]}
{"doc_key": "ai-test-293", "ner": [[3, 4, "academicjournal"], [8, 10, "researcher"], [12, 13, "researcher"], [15, 16, "researcher"], [22, 22, "product"], [26, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 22, 22, "topic", "", false, false], [3, 4, 26, 27, "topic", "", false, false], [8, 10, 3, 4, "role", "", false, false], [12, 13, 3, 4, "role", "", false, false], [15, 16, 3, 4, "role", "", false, false], [22, 22, 26, 27, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["L'", "articolo", "di", "Scientific", "American", "del", "2001", "di", "Berners", "-", "Lee", ",", "James", "Hendler", "e", "Ora", "Lassila", "descriveva", "la", "prevista", "evoluzione", "del", "Web", "esistente", "in", "un", "Web", "semantico", "."], "sentence-detokenized": "L'articolo di Scientific American del 2001 di Berners-Lee, James Hendler e Ora Lassila descriveva la prevista evoluzione del Web esistente in un Web semantico.", "token2charspan": [[0, 2], [2, 10], [11, 13], [14, 24], [25, 33], [34, 37], [38, 42], [43, 45], [46, 53], [53, 54], [54, 57], [57, 58], [59, 64], [65, 72], [73, 74], [75, 78], [79, 86], [87, 97], [98, 100], [101, 109], [110, 120], [121, 124], [125, 128], [129, 138], [139, 141], [142, 144], [145, 148], [149, 158], [158, 159]]}
{"doc_key": "ai-test-294", "ner": [[0, 2, "misc"], [12, 13, "person"], [15, 15, "person"], [29, 29, "person"], [37, 37, "person"], [43, 44, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 13, 0, 2, "role", "actor_in_work", false, false], [15, 15, 12, 13, "named", "", false, false], [15, 15, 12, 13, "origin", "", false, false], [29, 29, 15, 15, "part-of", "", false, false], [43, 44, 15, 15, "role", "auditioned_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Blade", "Runner", "ha", "utilizzato", "una", "serie", "di", "attori", "allora", "poco", "conosciuti", ":", "Sean", "Young", "interpreta", "Rachael", ",", "un", "replicante", "sperimentale", "a", "cui", "vengono", "impiantati", "i", "ricordi", "della", "nipote", "di", "Tyrell", ",", "facendole", "credere", "di", "essere", "umana", ";", "Sammon", ",", "pp.", "92", "-", "93", "Nina", "Axelrod", "fece", "un", "provino", "per", "il", "ruolo", "."], "sentence-detokenized": "Blade Runner ha utilizzato una serie di attori allora poco conosciuti: Sean Young interpreta Rachael, un replicante sperimentale a cui vengono impiantati i ricordi della nipote di Tyrell, facendole credere di essere umana; Sammon, pp. 92-93 Nina Axelrod fece un provino per il ruolo.", "token2charspan": [[0, 5], [6, 12], [13, 15], [16, 26], [27, 30], [31, 36], [37, 39], [40, 46], [47, 53], [54, 58], [59, 69], [69, 70], [71, 75], [76, 81], [82, 92], [93, 100], [100, 101], [102, 104], [105, 115], [116, 128], [129, 130], [131, 134], [135, 142], [143, 153], [154, 155], [156, 163], [164, 169], [170, 176], [177, 179], [180, 186], [186, 187], [188, 197], [198, 205], [206, 208], [209, 215], [216, 221], [221, 222], [223, 229], [229, 230], [231, 234], [235, 237], [237, 238], [238, 240], [241, 245], [246, 253], [254, 258], [259, 261], [262, 269], [270, 273], [274, 276], [277, 282], [282, 283]]}
{"doc_key": "ai-test-295", "ner": [[0, 1, "researcher"], [3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [13, 15, "university"], [23, 25, "product"], [27, 27, "product"], [49, 50, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 13, 15, "physical", "", false, false], [3, 4, 13, 15, "physical", "", false, false], [6, 7, 13, 15, "physical", "", false, false], [9, 10, 13, 15, "physical", "", false, false], [13, 15, 49, 50, "physical", "", true, false], [23, 25, 13, 15, "temporal", "", false, false], [27, 27, 13, 15, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Gerry", "Sussman", ",", "Eugene", "Charniak", ",", "Seymour", "Papert", "e", "Terry", "Winograd", "visitarono", "l'", "Universit\u00e0", "di", "Edimburgo", "nel", "1971", ",", "diffondendo", "le", "notizie", "su", "Micro", "-", "Planner", "e", "SHRDLU", "e", "mettendo", "in", "dubbio", "l'", "approccio", "alla", "procedura", "di", "prova", "uniforme", "della", "risoluzione", ",", "che", "era", "stato", "il", "pilastro", "dei", "logici", "di", "Edimburgo", "."], "sentence-detokenized": "Gerry Sussman, Eugene Charniak, Seymour Papert e Terry Winograd visitarono l'Universit\u00e0 di Edimburgo nel 1971, diffondendo le notizie su Micro-Planner e SHRDLU e mettendo in dubbio l'approccio alla procedura di prova uniforme della risoluzione, che era stato il pilastro dei logici di Edimburgo.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 21], [22, 30], [30, 31], [32, 39], [40, 46], [47, 48], [49, 54], [55, 63], [64, 74], [75, 77], [77, 87], [88, 90], [91, 100], [101, 104], [105, 109], [109, 110], [111, 122], [123, 125], [126, 133], [134, 136], [137, 142], [142, 143], [143, 150], [151, 152], [153, 159], [160, 161], [162, 170], [171, 173], [174, 180], [181, 183], [183, 192], [193, 197], [198, 207], [208, 210], [211, 216], [217, 225], [226, 231], [232, 243], [243, 244], [245, 248], [249, 252], [253, 258], [259, 261], [262, 270], [271, 274], [275, 281], [282, 284], [285, 294], [294, 295]]}
{"doc_key": "ai-test-296", "ner": [[3, 4, "researcher"], [12, 12, "field"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 15, 16, "role", "inspires", false, false], [3, 4, 18, 19, "role", "inspires", false, false], [3, 4, 21, 22, "role", "inspires", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Il", "lavoro", "di", "Walter", "ha", "ispirato", "le", "generazioni", "successive", "di", "ricercatori", "di", "robotica", ",", "come", "Rodney", "Brooks", ",", "Hans", "Moravec", "e", "Mark", "Tilden", "."], "sentence-detokenized": "Il lavoro di Walter ha ispirato le generazioni successive di ricercatori di robotica, come Rodney Brooks, Hans Moravec e Mark Tilden.", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 19], [20, 22], [23, 31], [32, 34], [35, 46], [47, 57], [58, 60], [61, 72], [73, 75], [76, 84], [84, 85], [86, 90], [91, 97], [98, 104], [104, 105], [106, 110], [111, 118], [119, 120], [121, 125], [126, 132], [132, 133]]}
{"doc_key": "ai-test-297", "ner": [[3, 3, "algorithm"], [9, 10, "researcher"], [17, 23, "event"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 9, 10, "origin", "", false, false], [3, 3, 17, 23, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Successivamente", ",", "una", "CNN", "simile", "basata", "su", "GPU", "di", "Alex", "Krizhevsky", "et", "al", ".", "ha", "vinto", "la", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "2012", "."], "sentence-detokenized": "Successivamente, una CNN simile basata su GPU di Alex Krizhevsky et al. ha vinto la ImageNet Large Scale Visual Recognition Challenge 2012.", "token2charspan": [[0, 15], [15, 16], [17, 20], [21, 24], [25, 31], [32, 38], [39, 41], [42, 45], [46, 48], [49, 53], [54, 64], [65, 67], [68, 70], [70, 71], [72, 74], [75, 80], [81, 83], [84, 92], [93, 98], [99, 104], [105, 111], [112, 123], [124, 133], [134, 138], [138, 139]]}
{"doc_key": "ai-test-298", "ner": [[0, 3, "misc"], [12, 13, "metrics"], [16, 18, "metrics"], [23, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 13, 0, 3, "type-of", "", false, false], [16, 18, 0, 3, "type-of", "", false, false], [16, 18, 23, 27, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Le", "funzioni", "di", "perdita", "comunemente", "utilizzate", "per", "la", "classificazione", "probabilistica", "includono", "la", "log", "loss", "e", "il", "punteggio", "di", "Brier", "tra", "le", "distribuzioni", "di", "probabilit\u00e0", "previste", "e", "quelle", "VERE."], "sentence-detokenized": "Le funzioni di perdita comunemente utilizzate per la classificazione probabilistica includono la log loss e il punteggio di Brier tra le distribuzioni di probabilit\u00e0 previste e quelle VERE.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 22], [23, 34], [35, 45], [46, 49], [50, 52], [53, 68], [69, 83], [84, 93], [94, 96], [97, 100], [101, 105], [106, 107], [108, 110], [111, 120], [121, 123], [124, 129], [130, 133], [134, 136], [137, 150], [151, 153], [154, 165], [166, 174], [175, 176], [177, 183], [184, 189]]}
{"doc_key": "ai-test-299", "ner": [[4, 4, "organisation"], [13, 13, "field"], [17, 17, "organisation"], [21, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 13, 13, "general-affiliation", "field_of_study", false, false], [4, 4, 21, 22, "part-of", "", false, false], [17, 17, 4, 4, "role", "admits_E2_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Nel", "maggio", "2016", ",", "NtechLab", "\u00e8", "stata", "ammessa", "al", "test", "ufficiale", "della", "tecnologia", "biometrica", "da", "parte", "del", "NIST", "tra", "le", "tre", "aziende", "russe", "."], "sentence-detokenized": "Nel maggio 2016, NtechLab \u00e8 stata ammessa al test ufficiale della tecnologia biometrica da parte del NIST tra le tre aziende russe.", "token2charspan": [[0, 3], [4, 10], [11, 15], [15, 16], [17, 25], [26, 27], [28, 33], [34, 41], [42, 44], [45, 49], [50, 59], [60, 65], [66, 76], [77, 87], [88, 90], [91, 96], [97, 100], [101, 105], [106, 109], [110, 112], [113, 116], [117, 124], [125, 130], [130, 131]]}
{"doc_key": "ai-test-300", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["Tuttavia", ",", "i", "numeri", "in", "virgola", "mobile", "hanno", "solo", "una", "certa", "precisione", "matematica", "."], "sentence-detokenized": "Tuttavia, i numeri in virgola mobile hanno solo una certa precisione matematica.", "token2charspan": [[0, 8], [8, 9], [10, 11], [12, 18], [19, 21], [22, 29], [30, 36], [37, 42], [43, 47], [48, 51], [52, 57], [58, 68], [69, 79], [79, 80]]}
{"doc_key": "ai-test-301", "ner": [[8, 8, "organisation"], [13, 19, "conference"], [21, 21, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 13, 19, "role", "contributes_to", false, false], [21, 21, 13, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Nel", "corso", "del", "2015", ",", "molti", "lavori", "di", "SenseTime", "sono", "stati", "accettati", "alla", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "."], "sentence-detokenized": "Nel corso del 2015, molti lavori di SenseTime sono stati accettati alla Conference on Computer Vision and Pattern Recognition (CVPR).", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 18], [18, 19], [20, 25], [26, 32], [33, 35], [36, 45], [46, 50], [51, 56], [57, 66], [67, 71], [72, 82], [83, 85], [86, 94], [95, 101], [102, 105], [106, 113], [114, 125], [126, 127], [127, 131], [131, 132], [132, 133]]}
{"doc_key": "ai-test-302", "ner": [[8, 10, "task"], [12, 12, "task"], [15, 16, "task"], [18, 21, "task"], [24, 24, "field"], [26, 28, "misc"], [30, 36, "conference"], [46, 48, "misc"], [50, 51, "conference"], [70, 72, "misc"], [74, 74, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[8, 10, 24, 24, "part-of", "task_part_of_field", false, false], [12, 12, 8, 10, "named", "", false, false], [15, 16, 24, 24, "part-of", "task_part_of_field", false, false], [18, 21, 15, 16, "named", "", false, false], [26, 28, 30, 36, "temporal", "", false, false], [46, 48, 50, 51, "temporal", "", false, false], [70, 72, 74, 74, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Ha", "co", "-", "sviluppato", "algoritmi", "ottimali", "per", "la", "Structure", "From", "Motion", "(", "SFM", ",", "o", "Visual", "SLAM", ",", "localizzazione", "e", "mappatura", "simultanee", ",", "in", "Robotica", ";", "premio", "Best", "Paper", "alla", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "1998", ")", ",", "ne", "ha", "caratterizzato", "le", "ambiguit\u00e0", "(", "premio", "David", "Marr", "all'", "ICCV", "1999", ")", ",", "ha", "inoltre", "caratterizzato", "l'", "identificabilit\u00e0", "e", "l'", "osservabilit\u00e0", "della", "fusione", "di", "sensori", "visivi", "-", "inerziali", "(", "premio", "Best", "Paper", "alla", "Robotica", "2015", ")", "."], "sentence-detokenized": "Ha co-sviluppato algoritmi ottimali per la Structure From Motion (SFM, o Visual SLAM, localizzazione e mappatura simultanee, in Robotica; premio Best Paper alla Conference on Computer Vision and Pattern Recognition 1998), ne ha caratterizzato le ambiguit\u00e0 (premio David Marr all'ICCV 1999), ha inoltre caratterizzato l'identificabilit\u00e0 e l'osservabilit\u00e0 della fusione di sensori visivi-inerziali (premio Best Paper alla Robotica 2015).", "token2charspan": [[0, 2], [3, 5], [5, 6], [6, 16], [17, 26], [27, 35], [36, 39], [40, 42], [43, 52], [53, 57], [58, 64], [65, 66], [66, 69], [69, 70], [71, 72], [73, 79], [80, 84], [84, 85], [86, 100], [101, 102], [103, 112], [113, 123], [123, 124], [125, 127], [128, 136], [136, 137], [138, 144], [145, 149], [150, 155], [156, 160], [161, 171], [172, 174], [175, 183], [184, 190], [191, 194], [195, 202], [203, 214], [215, 219], [219, 220], [220, 221], [222, 224], [225, 227], [228, 242], [243, 245], [246, 255], [256, 257], [257, 263], [264, 269], [270, 274], [275, 279], [279, 283], [284, 288], [288, 289], [289, 290], [291, 293], [294, 301], [302, 316], [317, 319], [319, 335], [336, 337], [338, 340], [340, 353], [354, 359], [360, 367], [368, 370], [371, 378], [379, 385], [385, 386], [386, 395], [396, 397], [397, 403], [404, 408], [409, 414], [415, 419], [420, 428], [429, 433], [433, 434], [434, 435]]}
{"doc_key": "ai-test-303", "ner": [[0, 2, "researcher"], [3, 3, "organisation"], [5, 5, "organisation"], [7, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Stephen", "H.", "Muggleton", "FBCS", ",", "FIET", ",", "Associazione", "per", "il", "progresso", "dell'", "intelligenza", "artificiale", ","], "sentence-detokenized": "Stephen H. Muggleton FBCS, FIET, Associazione per il progresso dell'intelligenza artificiale,", "token2charspan": [[0, 7], [8, 10], [11, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 45], [46, 49], [50, 52], [53, 62], [63, 68], [68, 80], [81, 92], [92, 93]]}
{"doc_key": "ai-test-304", "ner": [[0, 3, "task"], [9, 11, "field"], [14, 15, "field"], [18, 19, "field"], [26, 31, "task"], [29, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 3, 9, 11, "part-of", "task_part_of_field", false, false], [0, 3, 14, 15, "part-of", "task_part_of_field", false, false], [0, 3, 18, 19, "part-of", "task_part_of_field", false, false], [0, 3, 26, 31, "part-of", "", false, false], [0, 3, 29, 30, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Il", "rilevamento", "dei", "bordi", "\u00e8", "uno", "strumento", "fondamentale", "nell'", "elaborazione", "delle", "immagini", ",", "nella", "visione", "artificiale", "e", "nella", "computer", "vision", ",", "in", "particolare", "nelle", "aree", "del", "rilevamento", "e", "dell'", "estrazione", "delle", "caratteristiche", "."], "sentence-detokenized": "Il rilevamento dei bordi \u00e8 uno strumento fondamentale nell'elaborazione delle immagini, nella visione artificiale e nella computer vision, in particolare nelle aree del rilevamento e dell'estrazione delle caratteristiche.", "token2charspan": [[0, 2], [3, 14], [15, 18], [19, 24], [25, 26], [27, 30], [31, 40], [41, 53], [54, 59], [59, 71], [72, 77], [78, 86], [86, 87], [88, 93], [94, 101], [102, 113], [114, 115], [116, 121], [122, 130], [131, 137], [137, 138], [139, 141], [142, 153], [154, 159], [160, 164], [165, 168], [169, 180], [181, 182], [183, 188], [188, 198], [199, 204], [205, 220], [220, 221]]}
{"doc_key": "ai-test-305", "ner": [[9, 10, "misc"], [27, 29, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Un", "esempio", "\u00e8", "rappresentato", "da", "una", "variabile", "come", "la", "temperatura", "esterna", "(", "mathtemp", "/", "math", ")", ",", "che", "in", "una", "determinata", "applicazione", "potrebbe", "essere", "registrata", "con", "diversi", "decimali", "di", "precisione", "(", "a", "seconda", "dell'", "apparecchiatura", "di", "rilevamento", ")", "."], "sentence-detokenized": "Un esempio \u00e8 rappresentato da una variabile come la temperatura esterna (mathtemp / math), che in una determinata applicazione potrebbe essere registrata con diversi decimali di precisione (a seconda dell'apparecchiatura di rilevamento).", "token2charspan": [[0, 2], [3, 10], [11, 12], [13, 26], [27, 29], [30, 33], [34, 43], [44, 48], [49, 51], [52, 63], [64, 71], [72, 73], [73, 81], [82, 83], [84, 88], [88, 89], [89, 90], [91, 94], [95, 97], [98, 101], [102, 113], [114, 126], [127, 135], [136, 142], [143, 153], [154, 157], [158, 165], [166, 174], [175, 177], [178, 188], [189, 190], [190, 191], [192, 199], [200, 205], [205, 220], [221, 223], [224, 235], [235, 236], [236, 237]]}
{"doc_key": "ai-test-306", "ner": [[5, 6, "person"], [8, 9, "person"], [11, 12, "person"], [22, 23, "person"], [28, 28, "misc"], [33, 33, "misc"], [34, 35, "person"], [39, 40, "organisation"], [41, 42, "person"], [47, 47, "organisation"], [48, 49, "person"], [52, 52, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[34, 35, 28, 28, "part-of", "", false, false], [34, 35, 33, 33, "role", "", false, false], [41, 42, 39, 40, "role", "", false, false], [48, 49, 47, 47, "role", "youtuber", false, false], [52, 52, 48, 49, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["I", "giudici", "che", "ritornano", "sono", "Fon", "Davis", ",", "Jessica", "Chobot", "e", "Leland", "Melvin", ",", "oltre", "a", "giudici", "ospiti", "famosi", "come", "l'", "attore", "Clark", "Gregg", ",", "il", "conduttore", "di", "MythBusters", "ed", "ex", "costruttore", "di", "Battlebots", "Adam", "Savage", ",", "il", "tightend", "della", "NFL", "Vernon", "Davis", "e", "la", "star", "di", "YouTube", "Michael", "Stevens", ",", "alias", "Vsauce", "."], "sentence-detokenized": "I giudici che ritornano sono Fon Davis, Jessica Chobot e Leland Melvin, oltre a giudici ospiti famosi come l'attore Clark Gregg, il conduttore di MythBusters ed ex costruttore di Battlebots Adam Savage, il tightend della NFL Vernon Davis e la star di YouTube Michael Stevens, alias Vsauce.", "token2charspan": [[0, 1], [2, 9], [10, 13], [14, 23], [24, 28], [29, 32], [33, 38], [38, 39], [40, 47], [48, 54], [55, 56], [57, 63], [64, 70], [70, 71], [72, 77], [78, 79], [80, 87], [88, 94], [95, 101], [102, 106], [107, 109], [109, 115], [116, 121], [122, 127], [127, 128], [129, 131], [132, 142], [143, 145], [146, 157], [158, 160], [161, 163], [164, 175], [176, 178], [179, 189], [190, 194], [195, 201], [201, 202], [203, 205], [206, 214], [215, 220], [221, 224], [225, 231], [232, 237], [238, 239], [240, 242], [243, 247], [248, 250], [251, 258], [259, 266], [267, 274], [274, 275], [276, 281], [282, 288], [288, 289]]}
{"doc_key": "ai-test-307", "ner": [[14, 17, "algorithm"], [22, 25, "algorithm"], [27, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 17, 27, 29, "part-of", "", false, false], [22, 25, 27, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Questi", "metodi", ",", "per\u00f2", ",", "non", "hanno", "mai", "avuto", "la", "meglio", "sulla", "tecnologia", "del", "modello", "a", "miscela", "gaussiana", "non", "uniforme", "interna", "/", "modello", "di", "Markov", "nascosto", "(", "GMM", "-", "HMM", ")", ",", "basata", "su", "modelli", "generativi", "del", "parlato", "addestrati", "in", "modo", "discriminatorio", "."], "sentence-detokenized": "Questi metodi, per\u00f2, non hanno mai avuto la meglio sulla tecnologia del modello a miscela gaussiana non uniforme interna / modello di Markov nascosto (GMM-HMM), basata su modelli generativi del parlato addestrati in modo discriminatorio.", "token2charspan": [[0, 6], [7, 13], [13, 14], [15, 19], [19, 20], [21, 24], [25, 30], [31, 34], [35, 40], [41, 43], [44, 50], [51, 56], [57, 67], [68, 71], [72, 79], [80, 81], [82, 89], [90, 99], [100, 103], [104, 112], [113, 120], [121, 122], [123, 130], [131, 133], [134, 140], [141, 149], [150, 151], [151, 154], [154, 155], [155, 158], [158, 159], [159, 160], [161, 167], [168, 170], [171, 178], [179, 189], [190, 193], [194, 201], [202, 212], [213, 215], [216, 220], [221, 236], [236, 237]]}
{"doc_key": "ai-test-308", "ner": [[3, 3, "product"], [5, 6, "programlang"], [8, 8, "programlang"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Pacchetti", "software", "come", "MATLAB", ",", "GNU", "Octave", ",", "Scilab", "e", "SciPy", "offrono", "modi", "pratici", "per", "applicare", "questi", "diversi", "metodi", "."], "sentence-detokenized": "Pacchetti software come MATLAB, GNU Octave, Scilab e SciPy offrono modi pratici per applicare questi diversi metodi.", "token2charspan": [[0, 9], [10, 18], [19, 23], [24, 30], [30, 31], [32, 35], [36, 42], [42, 43], [44, 50], [51, 52], [53, 58], [59, 66], [67, 71], [72, 79], [80, 83], [84, 93], [94, 100], [101, 108], [109, 115], [115, 116]]}
{"doc_key": "ai-test-309", "ner": [[0, 3, "algorithm"], [5, 5, "algorithm"], [10, 13, "task"], [23, 24, "researcher"], [26, 28, "university"], [31, 32, "researcher"], [34, 37, "organisation"], [39, 39, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 3, 10, 13, "related-to", "", false, false], [0, 3, 23, 24, "origin", "", false, false], [0, 3, 31, 32, "origin", "", false, false], [5, 5, 0, 3, "named", "", false, false], [23, 24, 26, 28, "physical", "", false, false], [23, 24, 26, 28, "role", "", false, false], [31, 32, 34, 37, "physical", "", false, false], [31, 32, 34, 37, "role", "", false, false], [39, 39, 34, 37, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["La", "codifica", "predittiva", "lineare", "(", "LPC", ")", ",", "un", "algoritmo", "di", "elaborazione", "del", "parlato", ",", "\u00e8", "stata", "proposta", "per", "la", "prima", "volta", "da", "Fumitada", "Itakura", "dell'", "Universit\u00e0", "di", "Nagoya", "e", "da", "Shuzo", "Saito", "della", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "nel", "1966", "."], "sentence-detokenized": "La codifica predittiva lineare (LPC), un algoritmo di elaborazione del parlato, \u00e8 stata proposta per la prima volta da Fumitada Itakura dell'Universit\u00e0 di Nagoya e da Shuzo Saito della Nippon Telegraph and Telephone (NTT) nel 1966.", "token2charspan": [[0, 2], [3, 11], [12, 22], [23, 30], [31, 32], [32, 35], [35, 36], [36, 37], [38, 40], [41, 50], [51, 53], [54, 66], [67, 70], [71, 78], [78, 79], [80, 81], [82, 87], [88, 96], [97, 100], [101, 103], [104, 109], [110, 115], [116, 118], [119, 127], [128, 135], [136, 141], [141, 151], [152, 154], [155, 161], [162, 163], [164, 166], [167, 172], [173, 178], [179, 184], [185, 191], [192, 201], [202, 205], [206, 215], [216, 217], [217, 220], [220, 221], [222, 225], [226, 230], [230, 231]]}
{"doc_key": "ai-test-310", "ner": [[17, 24, "conference"], [26, 26, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[26, 26, 17, 24, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Nel", "2006", ",", "in", "occasione", "del", "25\u00b0", "anniversario", "dell'", "algoritmo", ",", "\u00e8", "stato", "organizzato", "un", "workshop", "all'", "International", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "per", "riassumere", "i", "contributi", "pi\u00f9", "recenti", "e", "le", "variazioni", "apportate", "all'", "algoritmo", "originale", ",", "volte", "soprattutto", "a", "migliorare", "la", "velocit\u00e0", "dell'", "algoritmo", ",", "la", "robustezza", "e", "l'", "accuratezza", "della", "soluzione", "stimata", "e", "a", "diminuire", "la", "dipendenza", "da", "costanti", "definite", "dall'", "utente", "."], "sentence-detokenized": "Nel 2006, in occasione del 25\u00b0 anniversario dell'algoritmo, \u00e8 stato organizzato un workshop all'International Conference on Computer Vision and Pattern Recognition (CVPR) per riassumere i contributi pi\u00f9 recenti e le variazioni apportate all'algoritmo originale, volte soprattutto a migliorare la velocit\u00e0 dell'algoritmo, la robustezza e l'accuratezza della soluzione stimata e a diminuire la dipendenza da costanti definite dall'utente.", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 12], [13, 22], [23, 26], [27, 30], [31, 43], [44, 49], [49, 58], [58, 59], [60, 61], [62, 67], [68, 79], [80, 82], [83, 91], [92, 96], [96, 109], [110, 120], [121, 123], [124, 132], [133, 139], [140, 143], [144, 151], [152, 163], [164, 165], [165, 169], [169, 170], [171, 174], [175, 185], [186, 187], [188, 198], [199, 202], [203, 210], [211, 212], [213, 215], [216, 226], [227, 236], [237, 241], [241, 250], [251, 260], [260, 261], [262, 267], [268, 279], [280, 281], [282, 292], [293, 295], [296, 304], [305, 310], [310, 319], [319, 320], [321, 323], [324, 334], [335, 336], [337, 339], [339, 350], [351, 356], [357, 366], [367, 374], [375, 376], [377, 378], [379, 388], [389, 391], [392, 402], [403, 405], [406, 414], [415, 423], [424, 429], [429, 435], [435, 436]]}
{"doc_key": "ai-test-311", "ner": [[5, 7, "university"], [10, 13, "organisation"], [16, 18, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["I", "membri", "hanno", "frequentato", "l'", "Universit\u00e0", "di", "Debrecen", ",", "l'", "Accademia", "ungherese", "delle", "scienze", ",", "l'", "Universit\u00e0", "E\u00f6tv\u00f6s", "Lor\u00e1nd", ",", "ecc", "."], "sentence-detokenized": "I membri hanno frequentato l'Universit\u00e0 di Debrecen, l'Accademia ungherese delle scienze, l'Universit\u00e0 E\u00f6tv\u00f6s Lor\u00e1nd, ecc.", "token2charspan": [[0, 1], [2, 8], [9, 14], [15, 26], [27, 29], [29, 39], [40, 42], [43, 51], [51, 52], [53, 55], [55, 64], [65, 74], [75, 80], [81, 88], [88, 89], [90, 92], [92, 102], [103, 109], [110, 116], [116, 117], [118, 121], [121, 122]]}
{"doc_key": "ai-test-312", "ner": [[2, 2, "algorithm"], [16, 18, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 16, 18, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Per", "estendere", "SVM", "ai", "casi", "in", "cui", "i", "dati", "non", "sono", "linearmente", "separabili", ",", "introduciamo", "la", "funzione", "di", "perdita", ","], "sentence-detokenized": "Per estendere SVM ai casi in cui i dati non sono linearmente separabili, introduciamo la funzione di perdita,", "token2charspan": [[0, 3], [4, 13], [14, 17], [18, 20], [21, 25], [26, 28], [29, 32], [33, 34], [35, 39], [40, 43], [44, 48], [49, 60], [61, 71], [71, 72], [73, 85], [86, 88], [89, 97], [98, 100], [101, 108], [108, 109]]}
{"doc_key": "ai-test-313", "ner": [[0, 0, "programlang"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 12, 13, "origin", "", false, false], [0, 0, 15, 16, "origin", "", false, false], [0, 0, 18, 19, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Logo", "\u00e8", "un", "linguaggio", "di", "programmazione", "educativo", ",", "progettato", "nel", "1967", "da", "Wally", "Feurzeig", ",", "Seymour", "Papert", "e", "Cynthia", "Solomon", "."], "sentence-detokenized": "Logo \u00e8 un linguaggio di programmazione educativo, progettato nel 1967 da Wally Feurzeig, Seymour Papert e Cynthia Solomon.", "token2charspan": [[0, 4], [5, 6], [7, 9], [10, 20], [21, 23], [24, 38], [39, 48], [48, 49], [50, 60], [61, 64], [65, 69], [70, 72], [73, 78], [79, 87], [87, 88], [89, 96], [97, 103], [104, 105], [106, 113], [114, 121], [121, 122]]}
{"doc_key": "ai-test-314", "ner": [[0, 4, "organisation"], [10, 17, "organisation"], [20, 23, "location"], [27, 27, "location"], [30, 30, "location"], [42, 47, "product"], [54, 57, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 4, 10, 17, "role", "works_for", false, false], [10, 17, 20, 23, "physical", "", false, false], [20, 23, 27, 27, "physical", "", false, false], [27, 27, 30, 30, "physical", "", false, false], [42, 47, 0, 4, "origin", "", false, false], [54, 57, 42, 47, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["L'", "Istituto", "di", "Ricerca", "Eyring", "\u00e8", "stato", "determinante", "per", "il", "Direttorato", "Missili", "dell'", "Aeronautica", "Militare", "degli", "Stati", "Uniti", "presso", "la", "Base", "Aerea", "di", "Hill", ",", "vicino", "a", "Ogden", ",", "nello", "Utah", ",", "per", "la", "produzione", ",", "in", "gran", "segreto", "militare", ",", "del", "software", "di", "tecnologia", "dei", "sistemi", "intelligenti", "che", "\u00e8", "stato", "fondamentale", "per", "il", "programma", "Reagan", "Star", "Wars", "."], "sentence-detokenized": "L'Istituto di Ricerca Eyring \u00e8 stato determinante per il Direttorato Missili dell'Aeronautica Militare degli Stati Uniti presso la Base Aerea di Hill, vicino a Ogden, nello Utah, per la produzione, in gran segreto militare, del software di tecnologia dei sistemi intelligenti che \u00e8 stato fondamentale per il programma Reagan Star Wars.", "token2charspan": [[0, 2], [2, 10], [11, 13], [14, 21], [22, 28], [29, 30], [31, 36], [37, 49], [50, 53], [54, 56], [57, 68], [69, 76], [77, 82], [82, 93], [94, 102], [103, 108], [109, 114], [115, 120], [121, 127], [128, 130], [131, 135], [136, 141], [142, 144], [145, 149], [149, 150], [151, 157], [158, 159], [160, 165], [165, 166], [167, 172], [173, 177], [177, 178], [179, 182], [183, 185], [186, 196], [196, 197], [198, 200], [201, 205], [206, 213], [214, 222], [222, 223], [224, 227], [228, 236], [237, 239], [240, 250], [251, 254], [255, 262], [263, 275], [276, 279], [280, 281], [282, 287], [288, 300], [301, 304], [305, 307], [308, 317], [318, 324], [325, 329], [330, 334], [334, 335]]}
{"doc_key": "ai-test-315", "ner": [[12, 12, "field"], [25, 27, "researcher"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Nel", "corso", "dei", "decenni", "ha", "svolto", "ricerche", "e", "sviluppato", "campi", "emergenti", "dell'", "informatica", ",", "dai", "compilatori", "ai", "linguaggi", "di", "programmazione", "e", "all'", "architettura", "di", "sistema", "John", "F.", "Sowa", "e", "John", "Zachman", "(", "1992", ")", "."], "sentence-detokenized": "Nel corso dei decenni ha svolto ricerche e sviluppato campi emergenti dell'informatica, dai compilatori ai linguaggi di programmazione e all'architettura di sistema John F. Sowa e John Zachman (1992).", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 21], [22, 24], [25, 31], [32, 40], [41, 42], [43, 53], [54, 59], [60, 69], [70, 75], [75, 86], [86, 87], [88, 91], [92, 103], [104, 106], [107, 116], [117, 119], [120, 134], [135, 136], [137, 141], [141, 153], [154, 156], [157, 164], [165, 169], [170, 172], [173, 177], [178, 179], [180, 184], [185, 192], [193, 194], [194, 198], [198, 199], [199, 200]]}
{"doc_key": "ai-test-316", "ner": [[0, 3, "algorithm"], [7, 11, "algorithm"], [13, 15, "algorithm"], [20, 22, "field"], [25, 26, "field"], [31, 35, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 11, 0, 3, "named", "", false, false], [13, 15, 0, 3, "named", "", false, false], [20, 22, 0, 3, "usage", "", false, false], [25, 26, 0, 3, "usage", "", false, false], [31, 35, 0, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["L'", "operatore", "di", "Sobel", ",", "talvolta", "chiamato", "operatore", "di", "Sobel", "-", "Feldman", "o", "filtro", "di", "Sobel", ",", "\u00e8", "utilizzato", "nell'", "elaborazione", "delle", "immagini", "e", "nella", "visione", "artificiale", ",", "in", "particolare", "negli", "algoritmi", "di", "rilevamento", "dei", "bordi", ",", "dove", "crea", "un'", "immagine", "che", "enfatizza", "i", "bordi", "."], "sentence-detokenized": "L'operatore di Sobel, talvolta chiamato operatore di Sobel-Feldman o filtro di Sobel, \u00e8 utilizzato nell'elaborazione delle immagini e nella visione artificiale, in particolare negli algoritmi di rilevamento dei bordi, dove crea un'immagine che enfatizza i bordi.", "token2charspan": [[0, 2], [2, 11], [12, 14], [15, 20], [20, 21], [22, 30], [31, 39], [40, 49], [50, 52], [53, 58], [58, 59], [59, 66], [67, 68], [69, 75], [76, 78], [79, 84], [84, 85], [86, 87], [88, 98], [99, 104], [104, 116], [117, 122], [123, 131], [132, 133], [134, 139], [140, 147], [148, 159], [159, 160], [161, 163], [164, 175], [176, 181], [182, 191], [192, 194], [195, 206], [207, 210], [211, 216], [216, 217], [218, 222], [223, 227], [228, 231], [231, 239], [240, 243], [244, 253], [254, 255], [256, 261], [261, 262]]}
{"doc_key": "ai-test-317", "ner": [[0, 0, "algorithm"], [5, 6, "field"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 5, 6, "compare", "", false, false], [0, 0, 5, 6, "type-of", "", false, false], [0, 0, 15, 15, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["LDA", "\u00e8", "un", "algoritmo", "di", "apprendimento", "supervisionato", "che", "utilizza", "le", "etichette", "dei", "dati", ",", "mentre", "PCA", "\u00e8", "un", "algoritmo", "di", "apprendimento", "che", "ignora", "le", "etichette", "."], "sentence-detokenized": "LDA \u00e8 un algoritmo di apprendimento supervisionato che utilizza le etichette dei dati, mentre PCA \u00e8 un algoritmo di apprendimento che ignora le etichette.", "token2charspan": [[0, 3], [4, 5], [6, 8], [9, 18], [19, 21], [22, 35], [36, 50], [51, 54], [55, 63], [64, 66], [67, 76], [77, 80], [81, 85], [85, 86], [87, 93], [94, 97], [98, 99], [100, 102], [103, 112], [113, 115], [116, 129], [130, 133], [134, 140], [141, 143], [144, 153], [153, 154]]}
{"doc_key": "ai-test-318", "ner": [[6, 6, "algorithm"], [8, 10, "algorithm"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Altri", "algoritmi", "di", "classificazione", "lineare", "sono", "Winnow", ",", "support", "vector", "machine", "e", "regressione", "logistica", "."], "sentence-detokenized": "Altri algoritmi di classificazione lineare sono Winnow, support vector machine e regressione logistica.", "token2charspan": [[0, 5], [6, 15], [16, 18], [19, 34], [35, 42], [43, 47], [48, 54], [54, 55], [56, 63], [64, 70], [71, 78], [79, 80], [81, 92], [93, 102], [102, 103]]}
{"doc_key": "ai-test-319", "ner": [[0, 0, "product"], [8, 9, "programlang"], [20, 22, "product"], [24, 24, "programlang"], [26, 26, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 9, "general-affiliation", "", true, false], [0, 0, 20, 22, "general-affiliation", "", true, false], [0, 0, 24, 24, "general-affiliation", "", true, false], [0, 0, 26, 26, "general-affiliation", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["VTK", "\u00e8", "costituito", "da", "una", "libreria", "di", "classi", "in", "C+", "e", "da", "diversi", "livelli", "di", "interfaccia", "interpretati", ",", "tra", "cui", "Tcl", "/", "Tk", ",", "Java", "e", "Python", "."], "sentence-detokenized": "VTK \u00e8 costituito da una libreria di classi in C+ e da diversi livelli di interfaccia interpretati, tra cui Tcl / Tk, Java e Python.", "token2charspan": [[0, 3], [4, 5], [6, 16], [17, 19], [20, 23], [24, 32], [33, 35], [36, 42], [43, 45], [46, 48], [49, 50], [51, 53], [54, 61], [62, 69], [70, 72], [73, 84], [85, 97], [97, 98], [99, 102], [103, 106], [107, 110], [111, 112], [113, 115], [115, 116], [117, 121], [122, 123], [124, 130], [130, 131]]}
{"doc_key": "ai-test-320", "ner": [[12, 14, "task"], [25, 28, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Inoltre", ",", "il", "testo", "prodotto", "dall'", "elaborazione", "del", "parlato", "spontaneo", "mediante", "il", "riconoscimento", "vocale", "automatico", "e", "del", "testo", "stampato", "o", "scritto", "a", "mano", "mediante", "il", "riconoscimento", "ottico", "dei", "caratteri", "contiene", "rumore", "di", "elaborazione", "."], "sentence-detokenized": "Inoltre, il testo prodotto dall'elaborazione del parlato spontaneo mediante il riconoscimento vocale automatico e del testo stampato o scritto a mano mediante il riconoscimento ottico dei caratteri contiene rumore di elaborazione.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 17], [18, 26], [27, 32], [32, 44], [45, 48], [49, 56], [57, 66], [67, 75], [76, 78], [79, 93], [94, 100], [101, 111], [112, 113], [114, 117], [118, 123], [124, 132], [133, 134], [135, 142], [143, 144], [145, 149], [150, 158], [159, 161], [162, 176], [177, 183], [184, 187], [188, 197], [198, 206], [207, 213], [214, 216], [217, 229], [229, 230]]}
{"doc_key": "ai-test-321", "ner": [[0, 1, "researcher"], [11, 11, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 11, 11, "role", "directs_development_of", false, false]], "relations_mapping_to_source": [0], "sentence": ["Miller", "ha", "scritto", "diversi", "libri", "e", "ha", "diretto", "lo", "sviluppo", "di", "WordNet", ",", "un", "database", "online", "di", "collegamenti", "tra", "parole", "utilizzabile", "da", "programmi", "informatici", "."], "sentence-detokenized": "Miller ha scritto diversi libri e ha diretto lo sviluppo di WordNet, un database online di collegamenti tra parole utilizzabile da programmi informatici.", "token2charspan": [[0, 6], [7, 9], [10, 17], [18, 25], [26, 31], [32, 33], [34, 36], [37, 44], [45, 47], [48, 56], [57, 59], [60, 67], [67, 68], [69, 71], [72, 80], [81, 87], [88, 90], [91, 103], [104, 107], [108, 114], [115, 127], [128, 130], [131, 140], [141, 152], [152, 153]]}
{"doc_key": "ai-test-322", "ner": [[0, 1, "field"], [8, 10, "organisation"], [12, 13, "country"], [15, 16, "person"], [18, 20, "person"], [22, 23, "person"], [25, 26, "person"], [28, 29, "country"], [31, 34, "location"], [36, 37, "misc"], [38, 39, "person"], [41, 42, "person"], [44, 44, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 10, 12, 13, "physical", "", false, false], [15, 16, 28, 29, "physical", "", false, false], [18, 20, 28, 29, "physical", "", false, false], [22, 23, 28, 29, "physical", "", false, false], [25, 26, 28, 29, "physical", "", false, false], [31, 34, 0, 1, "general-affiliation", "", false, false], [31, 34, 38, 39, "artifact", "", false, false], [36, 37, 38, 39, "named", "", false, false], [41, 42, 44, 44, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Gli", "automi", "contemporanei", "sono", "rappresentati", "dalle", "opere", "di", "Cabaret", "Mechanical", "Theatre", "nel", "Regno", "Unito", ",", "Dug", "North", "e", "Chomick", "+", "Meder", ",", "Arthur", "Ganson", ",", "Joe", "Jones", "negli", "Stati", "Uniti", ",", "Le", "D\u00e9fenseur", "du", "Temps", "dell'", "artista", "francese", "Jacques", "Monestier", "e", "Fran\u00e7ois", "Junod", "in", "Svizzera", "."], "sentence-detokenized": "Gli automi contemporanei sono rappresentati dalle opere di Cabaret Mechanical Theatre nel Regno Unito, Dug North e Chomick + Meder, Arthur Ganson, Joe Jones negli Stati Uniti, Le D\u00e9fenseur du Temps dell'artista francese Jacques Monestier e Fran\u00e7ois Junod in Svizzera.", "token2charspan": [[0, 3], [4, 10], [11, 24], [25, 29], [30, 43], [44, 49], [50, 55], [56, 58], [59, 66], [67, 77], [78, 85], [86, 89], [90, 95], [96, 101], [101, 102], [103, 106], [107, 112], [113, 114], [115, 122], [123, 124], [125, 130], [130, 131], [132, 138], [139, 145], [145, 146], [147, 150], [151, 156], [157, 162], [163, 168], [169, 174], [174, 175], [176, 178], [179, 188], [189, 191], [192, 197], [198, 203], [203, 210], [211, 219], [220, 227], [228, 237], [238, 239], [240, 248], [249, 254], [255, 257], [258, 266], [266, 267]]}
{"doc_key": "ai-test-323", "ner": [[0, 0, "product"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 21, 21, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MATLAB", "include", "i", "cicli", "standard", "codefor", "/", "code", "e", "codewhile", "/", "code", ",", "ma", "(", "come", "in", "altre", "applicazioni", "simili", "come", "R", ")", ",", "l'", "uso", "della", "notazione", "vettoriale", "\u00e8", "incoraggiato", "ed", "\u00e8", "spesso", "pi\u00f9", "veloce", "da", "eseguire", "."], "sentence-detokenized": "MATLAB include i cicli standard codefor / code e codewhile / code, ma (come in altre applicazioni simili come R), l'uso della notazione vettoriale \u00e8 incoraggiato ed \u00e8 spesso pi\u00f9 veloce da eseguire.", "token2charspan": [[0, 6], [7, 14], [15, 16], [17, 22], [23, 31], [32, 39], [40, 41], [42, 46], [47, 48], [49, 58], [59, 60], [61, 65], [65, 66], [67, 69], [70, 71], [71, 75], [76, 78], [79, 84], [85, 97], [98, 104], [105, 109], [110, 111], [111, 112], [112, 113], [114, 116], [116, 119], [120, 125], [126, 135], [136, 146], [147, 148], [149, 161], [162, 164], [165, 166], [167, 173], [174, 177], [178, 184], [185, 187], [188, 196], [196, 197]]}
{"doc_key": "ai-test-324", "ner": [[2, 3, "researcher"], [8, 11, "conference"], [17, 18, "field"], [21, 26, "misc"], [29, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 21, 26, "win-defeat", "", false, false], [2, 3, 29, 38, "win-defeat", "", false, false], [21, 26, 8, 11, "temporal", "", false, false], [21, 26, 17, 18, "topic", "", false, false], [29, 38, 8, 11, "temporal", "", false, false], [29, 38, 17, 18, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Nel", "2007", "Pausch", "ha", "ricevuto", "due", "premi", "dall'", "Association", "for", "Computing", "Machinery", "per", "i", "suoi", "successi", "nell'", "educazione", "informatica", ":", "il", "Karl", "V.", "Karlstrom", "Outstanding", "Educator", "Award", "e", "l'", "ACM", "SIGCSE", "Award", "for", "Outstanding", "Contributions", "to", "Computer", "Science", "Education", "."], "sentence-detokenized": "Nel 2007 Pausch ha ricevuto due premi dall'Association for Computing Machinery per i suoi successi nell'educazione informatica: il Karl V. Karlstrom Outstanding Educator Award e l'ACM SIGCSE Award for Outstanding Contributions to Computer Science Education.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 18], [19, 27], [28, 31], [32, 37], [38, 43], [43, 54], [55, 58], [59, 68], [69, 78], [79, 82], [83, 84], [85, 89], [90, 98], [99, 104], [104, 114], [115, 126], [126, 127], [128, 130], [131, 135], [136, 138], [139, 148], [149, 160], [161, 169], [170, 175], [176, 177], [178, 180], [180, 183], [184, 190], [191, 196], [197, 200], [201, 212], [213, 226], [227, 229], [230, 238], [239, 246], [247, 256], [256, 257]]}
{"doc_key": "ai-test-325", "ner": [[3, 3, "person"], [9, 9, "product"], [8, 8, "product"], [17, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 9, 9, "role", "sells", false, false], [9, 9, 8, 8, "general-affiliation", "", false, false], [9, 9, 17, 18, "physical", "shipped_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Nel", "1960", ",", "Devol", "vendette", "personalmente", "il", "primo", "robot", "Unimate", ",", "che", "fu", "spedito", "nel", "1961", "alla", "General", "Motors", "."], "sentence-detokenized": "Nel 1960, Devol vendette personalmente il primo robot Unimate, che fu spedito nel 1961 alla General Motors.", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 15], [16, 24], [25, 38], [39, 41], [42, 47], [48, 53], [54, 61], [61, 62], [63, 66], [67, 69], [70, 77], [78, 81], [82, 86], [87, 91], [92, 99], [100, 106], [106, 107]]}
{"doc_key": "ai-test-326", "ner": [[0, 2, "algorithm"], [8, 11, "field"], [15, 16, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 16, 0, 2, "usage", "", false, false], [15, 16, 8, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Le", "reti", "semantiche", "sono", "utilizzate", "nelle", "applicazioni", "di", "elaborazione", "del", "linguaggio", "naturale", ",", "come", "il", "parsing", "semantico", "."], "sentence-detokenized": "Le reti semantiche sono utilizzate nelle applicazioni di elaborazione del linguaggio naturale, come il parsing semantico.", "token2charspan": [[0, 2], [3, 7], [8, 18], [19, 23], [24, 34], [35, 40], [41, 53], [54, 56], [57, 69], [70, 73], [74, 84], [85, 93], [93, 94], [95, 99], [100, 102], [103, 110], [111, 120], [120, 121]]}
{"doc_key": "ai-test-327", "ner": [[5, 6, "field"], [9, 10, "field"], [13, 14, "task"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 23, "researcher"], [25, 28, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 10, 5, 6, "usage", "", false, false], [13, 14, 5, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Alcune", "applicazioni", "di", "successo", "del", "deep", "learning", "sono", "la", "visione", "artificiale", "e", "il", "riconoscimento", "vocale", ".", "Honglak", "Lee", ",", "Roger", "Grosse", ",", "Rajesh", "Ranganath", ",", "Andrew", "Y", ".", "Ng."], "sentence-detokenized": "Alcune applicazioni di successo del deep learning sono la visione artificiale e il riconoscimento vocale. Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng.", "token2charspan": [[0, 6], [7, 19], [20, 22], [23, 31], [32, 35], [36, 40], [41, 49], [50, 54], [55, 57], [58, 65], [66, 77], [78, 79], [80, 82], [83, 97], [98, 104], [104, 105], [106, 113], [114, 117], [117, 118], [119, 124], [125, 131], [131, 132], [133, 139], [140, 149], [149, 150], [151, 157], [158, 159], [159, 160], [161, 164]]}
{"doc_key": "ai-test-328", "ner": [[4, 8, "product"], [14, 14, "misc"], [17, 17, "misc"], [22, 22, "product"], [29, 30, "task"], [33, 34, "task"], [37, 38, "task"], [41, 44, "field"], [47, 49, "task"], [52, 54, "field"], [57, 58, "task"], [61, 62, "task"], [65, 68, "task"], [71, 73, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 8, 14, 14, "physical", "travels_to", false, false], [4, 8, 17, 17, "physical", "travels_to", false, false], [22, 22, 4, 8, "part-of", "", false, false], [22, 22, 4, 8, "role", "maintains", false, false], [22, 22, 29, 30, "related-to", "has_ability_to", false, false], [22, 22, 33, 34, "related-to", "has_ability_to", false, false], [22, 22, 37, 38, "related-to", "has_ability_to", false, false], [22, 22, 41, 44, "related-to", "has_ability_to", false, false], [22, 22, 47, 49, "related-to", "has_ability_to", false, false], [22, 22, 52, 54, "related-to", "has_ability_to", false, false], [22, 22, 57, 58, "related-to", "has_ability_to", false, false], [22, 22, 61, 62, "related-to", "has_ability_to", false, false], [22, 22, 65, 68, "related-to", "has_ability_to", false, false], [22, 22, 71, 73, "related-to", "has_ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Oltre", "a", "mantenere", "i", "sistemi", "della", "navicella", "Discovery", "One", "durante", "la", "missione", "interplanetaria", "verso", "Giove", "(", "o", "Saturno", "nel", "romanzo", ")", ",", "HAL", "\u00e8", "in", "grado", "di", "effettuare", "la", "sintesi", "vocale", ",", "il", "riconoscimento", "vocale", ",", "il", "riconoscimento", "facciale", ",", "l'", "elaborazione", "del", "linguaggio", "naturale", ",", "la", "lettura", "delle", "labbra", ",", "l'", "apprezzamento", "dell'", "arte", ",", "l'", "informatica", "affettiva", ",", "il", "ragionamento", "automatizzato", ",", "il", "pilotaggio", "di", "navicelle", "spaziali", "e", "il", "gioco", "degli", "scacchi", "."], "sentence-detokenized": "Oltre a mantenere i sistemi della navicella Discovery One durante la missione interplanetaria verso Giove (o Saturno nel romanzo), HAL \u00e8 in grado di effettuare la sintesi vocale, il riconoscimento vocale, il riconoscimento facciale, l'elaborazione del linguaggio naturale, la lettura delle labbra, l'apprezzamento dell'arte, l'informatica affettiva, il ragionamento automatizzato, il pilotaggio di navicelle spaziali e il gioco degli scacchi.", "token2charspan": [[0, 5], [6, 7], [8, 17], [18, 19], [20, 27], [28, 33], [34, 43], [44, 53], [54, 57], [58, 65], [66, 68], [69, 77], [78, 93], [94, 99], [100, 105], [106, 107], [107, 108], [109, 116], [117, 120], [121, 128], [128, 129], [129, 130], [131, 134], [135, 136], [137, 139], [140, 145], [146, 148], [149, 159], [160, 162], [163, 170], [171, 177], [177, 178], [179, 181], [182, 196], [197, 203], [203, 204], [205, 207], [208, 222], [223, 231], [231, 232], [233, 235], [235, 247], [248, 251], [252, 262], [263, 271], [271, 272], [273, 275], [276, 283], [284, 289], [290, 296], [296, 297], [298, 300], [300, 313], [314, 319], [319, 323], [323, 324], [325, 327], [327, 338], [339, 348], [348, 349], [350, 352], [353, 365], [366, 379], [379, 380], [381, 383], [384, 394], [395, 397], [398, 407], [408, 416], [417, 418], [419, 421], [422, 427], [428, 433], [434, 441], [441, 442]]}
{"doc_key": "ai-test-329", "ner": [[0, 3, "researcher"], [6, 6, "country"], [8, 9, "country"], [13, 13, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 6, 6, "physical", "", false, false], [0, 3, 8, 9, "physical", "", false, false], [0, 3, 13, 13, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Il", "dottor", "Julesz", "\u00e8", "emigrato", "dall'", "Ungheria", "negli", "Stati", "Uniti", "dopo", "l'", "invasione", "sovietica", "del", "1956", "."], "sentence-detokenized": "Il dottor Julesz \u00e8 emigrato dall'Ungheria negli Stati Uniti dopo l'invasione sovietica del 1956.", "token2charspan": [[0, 2], [3, 9], [10, 16], [17, 18], [19, 27], [28, 33], [33, 41], [42, 47], [48, 53], [54, 59], [60, 64], [65, 67], [67, 76], [77, 86], [87, 90], [91, 95], [95, 96]]}
{"doc_key": "ai-test-330", "ner": [[0, 6, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Le", "funzioni", "di", "attivazione", "della", "funzione", "sigmoide", "utilizzano", "una", "seconda", "non", "-", "linearit\u00e0", "per", "ingressi", "di", "grandi", "dimensioni", ":", "math", "\\", "phi", "(", "v", "_", "i", ")", "=", "(", "1", "+", "\\", "exp", "(", "-", "v", "_", "i", ")", ")", "^", "{", "-", "1", "}", "/", "math", "."], "sentence-detokenized": "Le funzioni di attivazione della funzione sigmoide utilizzano una seconda non-linearit\u00e0 per ingressi di grandi dimensioni: math\\ phi (v _ i) = (1 +\\ exp (-v _ i)) ^ {-1} / math.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 32], [33, 41], [42, 50], [51, 61], [62, 65], [66, 73], [74, 77], [77, 78], [78, 87], [88, 91], [92, 100], [101, 103], [104, 110], [111, 121], [121, 122], [123, 127], [127, 128], [129, 132], [133, 134], [134, 135], [136, 137], [138, 139], [139, 140], [141, 142], [143, 144], [144, 145], [146, 147], [147, 148], [149, 152], [153, 154], [154, 155], [155, 156], [157, 158], [159, 160], [160, 161], [161, 162], [163, 164], [165, 166], [166, 167], [167, 168], [168, 169], [170, 171], [172, 176], [176, 177]]}
{"doc_key": "ai-test-331", "ner": [[12, 15, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Queste", "probabilit\u00e0", "vengono", "utilizzate", "per", "determinare", "quale", "sia", "l'", "obiettivo", "utilizzando", "una", "decisione", "di", "massima", "verosimiglianza", "."], "sentence-detokenized": "Queste probabilit\u00e0 vengono utilizzate per determinare quale sia l'obiettivo utilizzando una decisione di massima verosimiglianza.", "token2charspan": [[0, 6], [7, 18], [19, 26], [27, 37], [38, 41], [42, 53], [54, 59], [60, 63], [64, 66], [66, 75], [76, 87], [88, 91], [92, 101], [102, 104], [105, 112], [113, 128], [128, 129]]}
{"doc_key": "ai-test-332", "ner": [[6, 8, "university"], [13, 15, "university"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Nel", "1984", "si", "\u00e8", "trasferito", "all'", "Universit\u00e0", "di", "Costanza", "e", "nel", "1990", "all'", "Universit\u00e0", "di", "Salisburgo", "."], "sentence-detokenized": "Nel 1984 si \u00e8 trasferito all'Universit\u00e0 di Costanza e nel 1990 all'Universit\u00e0 di Salisburgo.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 13], [14, 24], [25, 29], [29, 39], [40, 42], [43, 51], [52, 53], [54, 57], [58, 62], [63, 67], [67, 77], [78, 80], [81, 91], [91, 92]]}
{"doc_key": "ai-test-333", "ner": [[7, 9, "metrics"], [11, 13, "metrics"], [15, 17, "metrics"], [19, 20, "metrics"], [22, 24, "metrics"], [26, 30, "metrics"], [32, 35, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 13, 7, 9, "origin", "based_on", false, false], [15, 17, 7, 9, "origin", "based_on", false, false], [19, 20, 7, 9, "origin", "based_on", false, false], [22, 24, 7, 9, "origin", "based_on", false, false], [26, 30, 7, 9, "origin", "based_on", false, false], [32, 35, 7, 9, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Alcune", "popolari", "funzioni", "di", "fitness", "basate", "sulla", "matrice", "di", "confusione", "includono", "sensibilit\u00e0", "/", "specificit\u00e0", ",", "richiamo", "/", "precisione", ",", "misura", "F", ",", "somiglianza", "di", "Jaccard", ",", "coefficiente", "di", "correlazione", "di", "Matthews", "e", "matrice", "costo", "/", "guadagno", "che", "combina", "i", "costi", "e", "i", "guadagni", "assegnati", "ai", "4", "diversi", "tipi", "di", "classificazione", "."], "sentence-detokenized": "Alcune popolari funzioni di fitness basate sulla matrice di confusione includono sensibilit\u00e0/specificit\u00e0, richiamo/precisione, misura F, somiglianza di Jaccard, coefficiente di correlazione di Matthews e matrice costo/guadagno che combina i costi e i guadagni assegnati ai 4 diversi tipi di classificazione.", "token2charspan": [[0, 6], [7, 15], [16, 24], [25, 27], [28, 35], [36, 42], [43, 48], [49, 56], [57, 59], [60, 70], [71, 80], [81, 92], [92, 93], [93, 104], [104, 105], [106, 114], [114, 115], [115, 125], [125, 126], [127, 133], [134, 135], [135, 136], [137, 148], [149, 151], [152, 159], [159, 160], [161, 173], [174, 176], [177, 189], [190, 192], [193, 201], [202, 203], [204, 211], [212, 217], [217, 218], [218, 226], [227, 230], [231, 238], [239, 240], [241, 246], [247, 248], [249, 250], [251, 259], [260, 269], [270, 272], [273, 274], [275, 282], [283, 287], [288, 290], [291, 306], [306, 307]]}
{"doc_key": "ai-test-334", "ner": [[8, 8, "product"], [10, 10, "product"], [12, 12, "product"], [14, 14, "product"], [17, 18, "programlang"], [35, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[35, 38, 8, 8, "part-of", "", false, false], [35, 38, 10, 10, "part-of", "", false, false], [35, 38, 12, 12, "part-of", "", false, false], [35, 38, 14, 14, "part-of", "", false, false], [35, 38, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["I", "comuni", "ambienti", "di", "programmazione", "numerica", ",", "come", "MATLAB", ",", "SciLab", ",", "NumPy", ",", "Sklearn", "e", "il", "linguaggio", "R", ",", "forniscono", "alcune", "delle", "tecniche", "pi\u00f9", "semplici", "di", "estrazione", "delle", "caratteristiche", "(", "ad", "esempio", ",", "l'", "analisi", "delle", "componenti", "principali", ")", "tramite", "comandi", "integrati", "."], "sentence-detokenized": "I comuni ambienti di programmazione numerica, come MATLAB, SciLab, NumPy, Sklearn e il linguaggio R, forniscono alcune delle tecniche pi\u00f9 semplici di estrazione delle caratteristiche (ad esempio, l'analisi delle componenti principali) tramite comandi integrati.", "token2charspan": [[0, 1], [2, 8], [9, 17], [18, 20], [21, 35], [36, 44], [44, 45], [46, 50], [51, 57], [57, 58], [59, 65], [65, 66], [67, 72], [72, 73], [74, 81], [82, 83], [84, 86], [87, 97], [98, 99], [99, 100], [101, 111], [112, 118], [119, 124], [125, 133], [134, 137], [138, 146], [147, 149], [150, 160], [161, 166], [167, 182], [183, 184], [184, 186], [187, 194], [194, 195], [196, 198], [198, 205], [206, 211], [212, 222], [223, 233], [233, 234], [235, 242], [243, 250], [251, 260], [260, 261]]}
{"doc_key": "ai-test-335", "ner": [[0, 2, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["I", "robot", "industriali", "sono", "stati", "implementati", "per", "collaborare", "con", "l'", "uomo", "nell'", "esecuzione", "di", "compiti", "di", "produzione", "industriale", "."], "sentence-detokenized": "I robot industriali sono stati implementati per collaborare con l'uomo nell'esecuzione di compiti di produzione industriale.", "token2charspan": [[0, 1], [2, 7], [8, 19], [20, 24], [25, 30], [31, 43], [44, 47], [48, 59], [60, 63], [64, 66], [66, 70], [71, 76], [76, 86], [87, 89], [90, 97], [98, 100], [101, 111], [112, 123], [123, 124]]}
{"doc_key": "ai-test-336", "ner": [[5, 5, "field"], [7, 9, "researcher"], [20, 21, "field"], [23, 23, "field"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 5, 20, 21, "related-to", "", false, false], [5, 5, 23, 23, "related-to", "", false, false], [5, 5, 25, 26, "related-to", "", false, false], [7, 9, 5, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Nel", "primo", "articolo", "pubblicato", "sulle", "CG", ",", "John", "F.", "Sowa", "le", "ha", "applicate", "a", "un'", "ampia", "gamma", "di", "argomenti", "di", "intelligenza", "artificiale", ",", "informatica", "e", "scienze", "cognitive", "."], "sentence-detokenized": "Nel primo articolo pubblicato sulle CG, John F. Sowa le ha applicate a un'ampia gamma di argomenti di intelligenza artificiale, informatica e scienze cognitive.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 29], [30, 35], [36, 38], [38, 39], [40, 44], [45, 47], [48, 52], [53, 55], [56, 58], [59, 68], [69, 70], [71, 74], [74, 79], [80, 85], [86, 88], [89, 98], [99, 101], [102, 114], [115, 126], [126, 127], [128, 139], [140, 141], [142, 149], [150, 159], [159, 160]]}
{"doc_key": "ai-test-337", "ner": [[0, 2, "metrics"], [5, 5, "metrics"], [11, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 5, 5, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Il", "NIST", "si", "differenzia", "dal", "BLEU", "anche", "per", "il", "calcolo", "della", "penalit\u00e0", "di", "brevit\u00e0", ",", "nella", "misura", "in", "cui", "piccole", "variazioni", "nella", "lunghezza", "della", "traduzione", "non", "incidono", "pi\u00f9", "di", "tanto", "sul", "punteggio", "complessivo", "."], "sentence-detokenized": "Il NIST si differenzia dal BLEU anche per il calcolo della penalit\u00e0 di brevit\u00e0, nella misura in cui piccole variazioni nella lunghezza della traduzione non incidono pi\u00f9 di tanto sul punteggio complessivo.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 22], [23, 26], [27, 31], [32, 37], [38, 41], [42, 44], [45, 52], [53, 58], [59, 67], [68, 70], [71, 78], [78, 79], [80, 85], [86, 92], [93, 95], [96, 99], [100, 107], [108, 118], [119, 124], [125, 134], [135, 140], [141, 151], [152, 155], [156, 164], [165, 168], [169, 171], [172, 177], [178, 181], [182, 191], [192, 203], [203, 204]]}
{"doc_key": "ai-test-338", "ner": [[0, 5, "misc"], [13, 13, "conference"], [19, 20, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 5, 13, 13, "temporal", "", false, false], [0, 5, 19, 20, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["L'", "IJCAI", "Award", "for", "Research", "Excellence", "\u00e8", "un", "premio", "biennale", "assegnato", "alla", "conferenza", "IJCAI", "a", "ricercatori", "nel", "campo", "dell'", "intelligenza", "artificiale", "come", "riconoscimento", "dell'", "eccellenza", "della", "loro", "carriera", "."], "sentence-detokenized": "L'IJCAI Award for Research Excellence \u00e8 un premio biennale assegnato alla conferenza IJCAI a ricercatori nel campo dell'intelligenza artificiale come riconoscimento dell'eccellenza della loro carriera.", "token2charspan": [[0, 2], [2, 7], [8, 13], [14, 17], [18, 26], [27, 37], [38, 39], [40, 42], [43, 49], [50, 58], [59, 68], [69, 73], [74, 84], [85, 90], [91, 92], [93, 104], [105, 108], [109, 114], [115, 120], [120, 132], [133, 144], [145, 149], [150, 164], [165, 170], [170, 180], [181, 186], [187, 191], [192, 200], [200, 201]]}
{"doc_key": "ai-test-339", "ner": [[0, 0, "researcher"], [8, 8, "conference"], [18, 23, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 8, "role", "", false, false], [0, 0, 18, 23, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lenat", "\u00e8", "stato", "uno", "dei", "Fellow", "originali", "dell'", "AAAI", "ed", "\u00e8", "l'", "unico", "individuo", "a", "far", "parte", "dei", "consigli", "scientifici", "di", "Microsoft", "e", "Apple", "."], "sentence-detokenized": "Lenat \u00e8 stato uno dei Fellow originali dell'AAAI ed \u00e8 l'unico individuo a far parte dei consigli scientifici di Microsoft e Apple.", "token2charspan": [[0, 5], [6, 7], [8, 13], [14, 17], [18, 21], [22, 28], [29, 38], [39, 44], [44, 48], [49, 51], [52, 53], [54, 56], [56, 61], [62, 71], [72, 73], [74, 77], [78, 83], [84, 87], [88, 96], [97, 108], [109, 111], [112, 121], [122, 123], [124, 129], [129, 130]]}
{"doc_key": "ai-test-340", "ner": [[0, 1, "algorithm"], [7, 9, "misc"], [13, 15, "metrics"], [21, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 7, 9, "related-to", "minimise", false, false], [13, 15, 7, 9, "type-of", "", false, false], [21, 21, 7, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Gli", "autoencoder", "vengono", "addestrati", "per", "minimizzare", "gli", "errori", "di", "ricostruzione", "(", "come", "l'", "errore", "quadratico", "medio", ")", ",", "spesso", "indicati", "come", "perdita", ":"], "sentence-detokenized": "Gli autoencoder vengono addestrati per minimizzare gli errori di ricostruzione (come l'errore quadratico medio), spesso indicati come perdita:", "token2charspan": [[0, 3], [4, 15], [16, 23], [24, 34], [35, 38], [39, 50], [51, 54], [55, 61], [62, 64], [65, 78], [79, 80], [80, 84], [85, 87], [87, 93], [94, 104], [105, 110], [110, 111], [111, 112], [113, 119], [120, 128], [129, 133], [134, 141], [141, 142]]}
{"doc_key": "ai-test-341", "ner": [[35, 38, "misc"], [41, 41, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[41, 41, 35, 38, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Un'", "alternativa", "all'", "uso", "delle", "definizioni", "\u00e8", "quella", "di", "considerare", "la", "parentela", "generale", "tra", "i", "sensi", "delle", "parole", "e", "di", "calcolare", "la", "somiglianza", "di", "ogni", "coppia", "di", "sensi", "delle", "parole", "sulla", "base", "di", "una", "determinata", "base", "di", "conoscenza", "lessicale", ",", "come", "WordNet", "."], "sentence-detokenized": "Un'alternativa all'uso delle definizioni \u00e8 quella di considerare la parentela generale tra i sensi delle parole e di calcolare la somiglianza di ogni coppia di sensi delle parole sulla base di una determinata base di conoscenza lessicale, come WordNet.", "token2charspan": [[0, 3], [3, 14], [15, 19], [19, 22], [23, 28], [29, 40], [41, 42], [43, 49], [50, 52], [53, 64], [65, 67], [68, 77], [78, 86], [87, 90], [91, 92], [93, 98], [99, 104], [105, 111], [112, 113], [114, 116], [117, 126], [127, 129], [130, 141], [142, 144], [145, 149], [150, 156], [157, 159], [160, 165], [166, 171], [172, 178], [179, 184], [185, 189], [190, 192], [193, 196], [197, 208], [209, 213], [214, 216], [217, 227], [228, 237], [237, 238], [239, 243], [244, 251], [251, 252]]}
{"doc_key": "ai-test-342", "ner": [[0, 1, "algorithm"], [9, 11, "researcher"], [24, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 9, 11, "origin", "", false, false], [9, 11, 24, 25, "role", "work_based_on_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["TD-", "Lambda", "\u00e8", "un", "algoritmo", "di", "apprendimento", "inventato", "da", "Richard", "S.", "Sutton", "sulla", "base", "di", "un", "precedente", "lavoro", "sull'", "apprendimento", "per", "differenza", "temporale", "di", "Arthur", "Samuel", "."], "sentence-detokenized": "TD-Lambda \u00e8 un algoritmo di apprendimento inventato da Richard S. Sutton sulla base di un precedente lavoro sull'apprendimento per differenza temporale di Arthur Samuel.", "token2charspan": [[0, 3], [3, 9], [10, 11], [12, 14], [15, 24], [25, 27], [28, 41], [42, 51], [52, 54], [55, 62], [63, 65], [66, 72], [73, 78], [79, 83], [84, 86], [87, 89], [90, 100], [101, 107], [108, 113], [113, 126], [127, 130], [131, 141], [142, 151], [152, 154], [155, 161], [162, 168], [168, 169]]}
{"doc_key": "ai-test-343", "ner": [[1, 2, "field"], [5, 5, "field"], [8, 9, "task"], [13, 16, "task"], [18, 18, "task"], [24, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 1, 2, "part-of", "task_part_of_field", false, false], [8, 9, 5, 5, "part-of", "task_part_of_field", false, false], [13, 16, 8, 9, "named", "", false, false], [18, 18, 8, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Nel", "data", "mining", "e", "nella", "statistica", ",", "il", "clustering", "gerarchico", "(", "chiamato", "anche", "analisi", "gerarchica", "dei", "cluster", "o", "HCA", ")", "\u00e8", "un", "metodo", "di", "analisi", "dei", "cluster", "che", "cerca", "di", "costruire", "una", "gerarchia", "di", "cluster", "."], "sentence-detokenized": "Nel data mining e nella statistica, il clustering gerarchico (chiamato anche analisi gerarchica dei cluster o HCA) \u00e8 un metodo di analisi dei cluster che cerca di costruire una gerarchia di cluster.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 17], [18, 23], [24, 34], [34, 35], [36, 38], [39, 49], [50, 60], [61, 62], [62, 70], [71, 76], [77, 84], [85, 95], [96, 99], [100, 107], [108, 109], [110, 113], [113, 114], [115, 116], [117, 119], [120, 126], [127, 129], [130, 137], [138, 141], [142, 149], [150, 153], [154, 159], [160, 162], [163, 172], [173, 176], [177, 186], [187, 189], [190, 197], [197, 198]]}
{"doc_key": "ai-test-344", "ner": [[3, 3, "algorithm"], [10, 12, "field"], [15, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 10, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Il", "concetto", "di", "deconvoluzione", "\u00e8", "ampiamente", "utilizzato", "nelle", "tecniche", "di", "elaborazione", "dei", "segnali", "e", "delle", "immagini", "."], "sentence-detokenized": "Il concetto di deconvoluzione \u00e8 ampiamente utilizzato nelle tecniche di elaborazione dei segnali e delle immagini.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 29], [30, 31], [32, 42], [43, 53], [54, 59], [60, 68], [69, 71], [72, 84], [85, 88], [89, 96], [97, 98], [99, 104], [105, 113], [113, 114]]}
{"doc_key": "ai-test-345", "ner": [[0, 2, "algorithm"], [25, 26, "misc"], [30, 30, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 25, 26, "related-to", "enhances", false, false], [0, 2, 25, 26, "related-to", "reduces", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Le", "mappe", "cognitive", "servono", "alla", "costruzione", "e", "all'", "accumulo", "di", "conoscenze", "spaziali", ",", "consentendo", "all'", "occhio", "della", "mente", "di", "visualizzare", "le", "immagini", "per", "ridurre", "il", "carico", "cognitivo", ",", "migliorare", "il", "ricordo", "e", "l'", "apprendimento", "delle", "informazioni", "."], "sentence-detokenized": "Le mappe cognitive servono alla costruzione e all'accumulo di conoscenze spaziali, consentendo all'occhio della mente di visualizzare le immagini per ridurre il carico cognitivo, migliorare il ricordo e l'apprendimento delle informazioni.", "token2charspan": [[0, 2], [3, 8], [9, 18], [19, 26], [27, 31], [32, 43], [44, 45], [46, 50], [50, 58], [59, 61], [62, 72], [73, 81], [81, 82], [83, 94], [95, 99], [99, 105], [106, 111], [112, 117], [118, 120], [121, 133], [134, 136], [137, 145], [146, 149], [150, 157], [158, 160], [161, 167], [168, 177], [177, 178], [179, 189], [190, 192], [193, 200], [201, 202], [203, 205], [205, 218], [219, 224], [225, 237], [237, 238]]}
{"doc_key": "ai-test-346", "ner": [[9, 9, "programlang"], [11, 13, "programlang"], [15, 15, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": [",", "che", "in", "genere", "fornisce", "binding", "a", "linguaggi", "come", "Python", ",", "C", "+", "+", ",", "Java", ")", "."], "sentence-detokenized": ", che in genere fornisce binding a linguaggi come Python, C ++, Java).", "token2charspan": [[0, 1], [2, 5], [6, 8], [9, 15], [16, 24], [25, 32], [33, 34], [35, 44], [45, 49], [50, 56], [56, 57], [58, 59], [60, 61], [61, 62], [62, 63], [64, 68], [68, 69], [69, 70]]}
{"doc_key": "ai-test-347", "ner": [[1, 3, "product"], [5, 5, "product"], [19, 20, "task"], [28, 30, "task"], [35, 38, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 3, 19, 20, "usage", "", false, false], [1, 3, 28, 30, "usage", "", false, false], [1, 3, 35, 38, "usage", "", false, false], [5, 5, 1, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Un'", "interfaccia", "utente", "vocale", "(", "VUI", ")", "rende", "possibile", "l'", "interazione", "umana", "parlata", "con", "i", "computer", ",", "utilizzando", "il", "riconoscimento", "vocale", "per", "comprendere", "i", "comandi", "vocali", "e", "le", "risposte", "alle", "domande", ",", "e", "tipicamente", "il", "text", "to", "speech", "per", "riprodurre", "una", "risposta", "."], "sentence-detokenized": "Un'interfaccia utente vocale (VUI) rende possibile l'interazione umana parlata con i computer, utilizzando il riconoscimento vocale per comprendere i comandi vocali e le risposte alle domande, e tipicamente il text to speech per riprodurre una risposta.", "token2charspan": [[0, 3], [3, 14], [15, 21], [22, 28], [29, 30], [30, 33], [33, 34], [35, 40], [41, 50], [51, 53], [53, 64], [65, 70], [71, 78], [79, 82], [83, 84], [85, 93], [93, 94], [95, 106], [107, 109], [110, 124], [125, 131], [132, 135], [136, 147], [148, 149], [150, 157], [158, 164], [165, 166], [167, 169], [170, 178], [179, 183], [184, 191], [191, 192], [193, 194], [195, 206], [207, 209], [210, 214], [215, 217], [218, 224], [225, 228], [229, 239], [240, 243], [244, 252], [252, 253]]}
{"doc_key": "ai-test-348", "ner": [[0, 0, "programlang"], [3, 5, "misc"], [9, 9, "programlang"], [13, 16, "researcher"], [18, 19, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 5, "general-affiliation", "is_a", false, false], [0, 0, 9, 9, "general-affiliation", "made_with", false, false], [0, 0, 13, 16, "origin", "", false, false], [13, 16, 18, 19, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Jess", "\u00e8", "un", "motore", "di", "regole", "per", "la", "piattaforma", "Java", ",", "sviluppato", "da", "Ernest", "Friedman", "-", "Hill", "del", "Sandia", "National", "."], "sentence-detokenized": "Jess \u00e8 un motore di regole per la piattaforma Java, sviluppato da Ernest Friedman-Hill del Sandia National.", "token2charspan": [[0, 4], [5, 6], [7, 9], [10, 16], [17, 19], [20, 26], [27, 30], [31, 33], [34, 45], [46, 50], [50, 51], [52, 62], [63, 65], [66, 72], [73, 81], [81, 82], [82, 86], [87, 90], [91, 97], [98, 106], [106, 107]]}
{"doc_key": "ai-test-349", "ner": [[2, 3, "algorithm"], [20, 20, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 20, 20, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Per", "i", "perceptron", "multistrato", ",", "dove", "esiste", "uno", "strato", "nascosto", ",", "\u00e8", "necessario", "utilizzare", "algoritmi", "pi\u00f9", "sofisticati", ",", "come", "la", "backpropagation", "."], "sentence-detokenized": "Per i perceptron multistrato, dove esiste uno strato nascosto, \u00e8 necessario utilizzare algoritmi pi\u00f9 sofisticati, come la backpropagation.", "token2charspan": [[0, 3], [4, 5], [6, 16], [17, 28], [28, 29], [30, 34], [35, 41], [42, 45], [46, 52], [53, 61], [61, 62], [63, 64], [65, 75], [76, 86], [87, 96], [97, 100], [101, 112], [112, 113], [114, 118], [119, 121], [122, 137], [137, 138]]}
{"doc_key": "ai-test-350", "ner": [[7, 8, "product"], [0, 5, "product"], [12, 17, "algorithm"], [23, 24, "field"], [29, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 5, 7, 8, "part-of", "", false, false], [0, 5, 12, 17, "usage", "", false, true], [12, 17, 23, 24, "related-to", "performs", false, false], [29, 34, 23, 24, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Il", "sistema", "di", "traduzione", "automatica", "neurale", "di", "Google", "Translate", "utilizza", "una", "grande", "rete", "neurale", "artificiale", "end-to", "-", "end", "che", "cerca", "di", "eseguire", "l'", "apprendimento", "profondo", ",", "in", "particolare", "le", "reti", "di", "memoria", "a", "breve", "termine", "."], "sentence-detokenized": "Il sistema di traduzione automatica neurale di Google Translate utilizza una grande rete neurale artificiale end-to-end che cerca di eseguire l'apprendimento profondo, in particolare le reti di memoria a breve termine.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 24], [25, 35], [36, 43], [44, 46], [47, 53], [54, 63], [64, 72], [73, 76], [77, 83], [84, 88], [89, 96], [97, 108], [109, 115], [115, 116], [116, 119], [120, 123], [124, 129], [130, 132], [133, 141], [142, 144], [144, 157], [158, 166], [166, 167], [168, 170], [171, 182], [183, 185], [186, 190], [191, 193], [194, 201], [202, 203], [204, 209], [210, 217], [217, 218]]}
{"doc_key": "ai-test-351", "ner": [[8, 8, "researcher"], [10, 10, "researcher"], [12, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"], [20, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Negli", "anni", "'80", "e", "nei", "primi", "anni", "'90", "Werbos", ",", "Williams", ",", "Robinson", ",", "J\u00fcrgen", "Schmidhuber", ",", "Sepp", "Hochreiter", ",", "Pearlmutter", "e", "altri", "hanno", "sviluppato", "diversi", "metodi", "per", "farlo", "."], "sentence-detokenized": "Negli anni '80 e nei primi anni '90 Werbos, Williams, Robinson, J\u00fcrgen Schmidhuber, Sepp Hochreiter, Pearlmutter e altri hanno sviluppato diversi metodi per farlo.", "token2charspan": [[0, 5], [6, 10], [11, 14], [15, 16], [17, 20], [21, 26], [27, 31], [32, 35], [36, 42], [42, 43], [44, 52], [52, 53], [54, 62], [62, 63], [64, 70], [71, 82], [82, 83], [84, 88], [89, 99], [99, 100], [101, 112], [113, 114], [115, 120], [121, 126], [127, 137], [138, 145], [146, 152], [153, 156], [157, 162], [162, 163]]}
{"doc_key": "ai-test-352", "ner": [[0, 1, "organisation"], [2, 3, "organisation"], [12, 12, "organisation"], [17, 19, "task"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 12, 12, "role", "licenses_from", false, false], [2, 3, 0, 1, "named", "", false, false], [24, 24, 0, 1, "origin", "", false, false], [24, 24, 17, 19, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["|", "Apple", "Apple", "Inc", "ha", "originariamente", "preso", "in", "licenza", "il", "software", "di", "Nuance", "per", "fornire", "la", "capacit\u00e0", "di", "riconoscimento", "vocale", "al", "suo", "assistente", "digitale", "Siri", "."], "sentence-detokenized": "| Apple Apple Inc ha originariamente preso in licenza il software di Nuance per fornire la capacit\u00e0 di riconoscimento vocale al suo assistente digitale Siri.", "token2charspan": [[0, 1], [2, 7], [8, 13], [14, 17], [18, 20], [21, 36], [37, 42], [43, 45], [46, 53], [54, 56], [57, 65], [66, 68], [69, 75], [76, 79], [80, 87], [88, 90], [91, 99], [100, 102], [103, 117], [118, 124], [125, 127], [128, 131], [132, 142], [143, 151], [152, 156], [156, 157]]}
{"doc_key": "ai-test-353", "ner": [[0, 2, "organisation"], [5, 8, "misc"], [11, 12, "person"], [16, 17, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 8, "role", "releases_movies_in_genre", false, false], [11, 12, 0, 2, "role", "directs_for", false, false], [16, 17, 0, 2, "role", "directs_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "Columbia", "ha", "pubblicato", "diversi", "film", "western", "in", "3D", "prodotti", "da", "Sam", "Katzman", "e", "diretti", "da", "William", "Castle", "."], "sentence-detokenized": "La Columbia ha pubblicato diversi film western in 3D prodotti da Sam Katzman e diretti da William Castle.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 25], [26, 33], [34, 38], [39, 46], [47, 49], [50, 52], [53, 61], [62, 64], [65, 68], [69, 76], [77, 78], [79, 86], [87, 89], [90, 97], [98, 104], [104, 105]]}
{"doc_key": "ai-test-354", "ner": [[9, 9, "field"], [12, 12, "field"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Il", "progetto", "incorpora", "conoscenze", "e", "ricerche", "nei", "campi", "dell'", "informatica", ",", "della", "linguistica", "e", "dell'", "ingegneria", "informatica", "."], "sentence-detokenized": "Il progetto incorpora conoscenze e ricerche nei campi dell'informatica, della linguistica e dell'ingegneria informatica.", "token2charspan": [[0, 2], [3, 11], [12, 21], [22, 32], [33, 34], [35, 43], [44, 47], [48, 53], [54, 59], [59, 70], [70, 71], [72, 77], [78, 89], [90, 91], [92, 97], [97, 107], [108, 119], [119, 120]]}
{"doc_key": "ai-test-355", "ner": [[5, 5, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ecco", "un", "esempio", "di", "codice", "R", ":"], "sentence-detokenized": "Ecco un esempio di codice R:", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 25], [26, 27], [27, 28]]}
{"doc_key": "ai-test-356", "ner": [[0, 2, "metrics"], [7, 10, "metrics"], [12, 12, "metrics"], [16, 19, "metrics"], [21, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 7, 10, "part-of", "plotted_into", false, false], [0, 2, 16, 19, "part-of", "plotted_into", false, false], [12, 12, 7, 10, "named", "", false, false], [21, 21, 16, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["La", "curva", "ROC", "viene", "creata", "tracciando", "il", "tasso", "di", "VERI", "positivi", "(", "TPR", ")", "rispetto", "al", "tasso", "di", "FALSI", "positivi", "(", "FPR", ")", "a", "varie", "impostazioni", "di", "soglia", "."], "sentence-detokenized": "La curva ROC viene creata tracciando il tasso di VERI positivi (TPR) rispetto al tasso di FALSI positivi (FPR) a varie impostazioni di soglia.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 18], [19, 25], [26, 36], [37, 39], [40, 45], [46, 48], [49, 53], [54, 62], [63, 64], [64, 67], [67, 68], [69, 77], [78, 80], [81, 86], [87, 89], [90, 95], [96, 104], [105, 106], [106, 109], [109, 110], [111, 112], [113, 118], [119, 131], [132, 134], [135, 141], [141, 142]]}
{"doc_key": "ai-test-357", "ner": [[9, 10, "field"], [12, 13, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 13, 9, 10, "related-to", "researches_field", false, false], [15, 16, 9, 10, "related-to", "researches_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "ricerca", "si", "\u00e8", "arenata", "dopo", "le", "ricerche", "sull'", "apprendimento", "automatico", "di", "Marvin", "Minsky", "e", "Seymour", "Papert", "(", "1969", ")", ","], "sentence-detokenized": "La ricerca si \u00e8 arenata dopo le ricerche sull'apprendimento automatico di Marvin Minsky e Seymour Papert (1969),", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 23], [24, 28], [29, 31], [32, 40], [41, 46], [46, 59], [60, 70], [71, 73], [74, 80], [81, 87], [88, 89], [90, 97], [98, 104], [105, 106], [106, 110], [110, 111], [111, 112]]}
{"doc_key": "ai-test-358", "ner": [[8, 8, "task"], [11, 12, "programlang"], [14, 15, "product"], [17, 18, "programlang"], [20, 20, "product"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 8, 11, 12, "related-to", "used_to_build", false, false], [8, 8, 14, 15, "related-to", "used_to_build", false, false], [8, 8, 17, 18, "related-to", "used_to_build", false, false], [8, 8, 20, 20, "related-to", "used_to_build", false, false], [8, 8, 22, 22, "related-to", "used_to_build", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Altri", "ambienti", "di", "programmazione", "utilizzati", "per", "costruire", "applicazioni", "DAQ", "sono", "la", "logica", "ladder", ",", "Visual", "C+", ",", "Visual", "Basic", ",", "LabVIEW", "e", "MATLAB."], "sentence-detokenized": "Altri ambienti di programmazione utilizzati per costruire applicazioni DAQ sono la logica ladder, Visual C+, Visual Basic, LabVIEW e MATLAB.", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 32], [33, 43], [44, 47], [48, 57], [58, 70], [71, 74], [75, 79], [80, 82], [83, 89], [90, 96], [96, 97], [98, 104], [105, 107], [107, 108], [109, 115], [116, 121], [121, 122], [123, 130], [131, 132], [133, 140]]}
{"doc_key": "ai-test-359", "ner": [[14, 15, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "metrica", "\u00e8", "stata", "progettata", "per", "risolvere", "alcuni", "dei", "problemi", "riscontrati", "nella", "pi\u00f9", "popolare", "metrica", "BLEU", "e", "per", "produrre", "una", "buona", "correlazione", "con", "il", "giudizio", "umano", "a", "livello", "di", "frase", "o", "di", "segmento", "."], "sentence-detokenized": "La metrica \u00e8 stata progettata per risolvere alcuni dei problemi riscontrati nella pi\u00f9 popolare metrica BLEU e per produrre una buona correlazione con il giudizio umano a livello di frase o di segmento.", "token2charspan": [[0, 2], [3, 10], [11, 12], [13, 18], [19, 29], [30, 33], [34, 43], [44, 50], [51, 54], [55, 63], [64, 75], [76, 81], [82, 85], [86, 94], [95, 102], [103, 107], [108, 109], [110, 113], [114, 122], [123, 126], [127, 132], [133, 145], [146, 149], [150, 152], [153, 161], [162, 167], [168, 169], [170, 177], [178, 180], [181, 186], [187, 188], [189, 191], [192, 200], [200, 201]]}
{"doc_key": "ai-test-360", "ner": [[15, 18, "algorithm"], [21, 23, "algorithm"], [26, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Per", "sfruttare", "le", "correlazioni", "semantiche", "tra", "fotogrammi", "video", "consecutivi", "si", "utilizzano", "spesso", "tecniche", "come", "le", "reti", "di", "Markov", "dinamiche", ",", "le", "reti", "neurali", "convoluzionali", "e", "la", "memoria", "a", "breve", "termine", "."], "sentence-detokenized": "Per sfruttare le correlazioni semantiche tra fotogrammi video consecutivi si utilizzano spesso tecniche come le reti di Markov dinamiche, le reti neurali convoluzionali e la memoria a breve termine.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 29], [30, 40], [41, 44], [45, 55], [56, 61], [62, 73], [74, 76], [77, 87], [88, 94], [95, 103], [104, 108], [109, 111], [112, 116], [117, 119], [120, 126], [127, 136], [136, 137], [138, 140], [141, 145], [146, 153], [154, 168], [169, 170], [171, 173], [174, 181], [182, 183], [184, 189], [190, 197], [197, 198]]}
{"doc_key": "ai-test-361", "ner": [[0, 2, "product"], [4, 4, "product"], [14, 19, "product"], [25, 25, "product"], [40, 40, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 14, 19, "artifact", "", false, false], [0, 2, 40, 40, "named", "", false, false], [4, 4, 0, 2, "named", "", false, false], [25, 25, 14, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["I", "circuiti", "stampati", "(", "PCB", ")", "prodotti", "in", "serie", "sono", "realizzati", "quasi", "esclusivamente", "da", "robot", "pick", "-", "and", "-", "place", ",", "in", "genere", "con", "manipolatori", "SCARA", ",", "che", "rimuovono", "piccoli", "componenti", "elettronici", "da", "strisce", "o", "vassoi", "e", "li", "posizionano", "sui", "PCB", "con", "grande", "precisione", "."], "sentence-detokenized": "I circuiti stampati (PCB) prodotti in serie sono realizzati quasi esclusivamente da robot pick-and-place, in genere con manipolatori SCARA, che rimuovono piccoli componenti elettronici da strisce o vassoi e li posizionano sui PCB con grande precisione.", "token2charspan": [[0, 1], [2, 10], [11, 19], [20, 21], [21, 24], [24, 25], [26, 34], [35, 37], [38, 43], [44, 48], [49, 59], [60, 65], [66, 80], [81, 83], [84, 89], [90, 94], [94, 95], [95, 98], [98, 99], [99, 104], [104, 105], [106, 108], [109, 115], [116, 119], [120, 132], [133, 138], [138, 139], [140, 143], [144, 153], [154, 161], [162, 172], [173, 184], [185, 187], [188, 195], [196, 197], [198, 204], [205, 206], [207, 209], [210, 221], [222, 225], [226, 229], [230, 233], [234, 240], [241, 251], [251, 252]]}
{"doc_key": "ai-test-362", "ner": [[3, 4, "field"], [13, 13, "algorithm"], [21, 22, "researcher"], [24, 25, "researcher"], [27, 30, "researcher"], [37, 38, "algorithm"], [41, 43, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 13, 3, 4, "part-of", "", false, false], [13, 13, 21, 22, "origin", "", false, false], [13, 13, 24, 25, "origin", "", false, false], [13, 13, 27, 30, "origin", "", false, false], [13, 13, 37, 38, "type-of", "", false, false], [37, 38, 41, 43, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Nell'", "ambito", "dell'", "apprendimento", "automatico", ",", "dove", "oggi", "trova", "maggiore", "applicazione", ",", "la", "LDA", "\u00e8", "stata", "riscoperta", "in", "modo", "indipendente", "da", "David", "Blei", ",", "Andrew", "Ng", "e", "Michael", "I", ".", "Jordan", "nel", "2003", "e", "presentata", "come", "un", "modello", "grafico", "per", "la", "scoperta", "di", "argomenti", "."], "sentence-detokenized": "Nell'ambito dell'apprendimento automatico, dove oggi trova maggiore applicazione, la LDA \u00e8 stata riscoperta in modo indipendente da David Blei, Andrew Ng e Michael I. Jordan nel 2003 e presentata come un modello grafico per la scoperta di argomenti.", "token2charspan": [[0, 5], [5, 11], [12, 17], [17, 30], [31, 41], [41, 42], [43, 47], [48, 52], [53, 58], [59, 67], [68, 80], [80, 81], [82, 84], [85, 88], [89, 90], [91, 96], [97, 107], [108, 110], [111, 115], [116, 128], [129, 131], [132, 137], [138, 142], [142, 143], [144, 150], [151, 153], [154, 155], [156, 163], [164, 165], [165, 166], [167, 173], [174, 177], [178, 182], [183, 184], [185, 195], [196, 200], [201, 203], [204, 211], [212, 219], [220, 223], [224, 226], [227, 235], [236, 238], [239, 248], [248, 249]]}
{"doc_key": "ai-test-363", "ner": [[9, 9, "task"], [13, 13, "misc"], [19, 19, "metrics"], [22, 22, "metrics"], [25, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 9, 13, 13, "related-to", "task_across_domain", false, false]], "relations_mapping_to_source": [0], "sentence": ["Le", "prestazioni", "misurate", "sui", "dati", "di", "prova", "di", "otto", "WSI", "naive", "di", "varie", "tauopatie", "hanno", "dato", "come", "risultato", "un", "richiamo", ",", "una", "precisione", "e", "un", "punteggio", "F1", "rispettivamente", "di", "0,92", ",", "0,72", "e", "0,81", "."], "sentence-detokenized": "Le prestazioni misurate sui dati di prova di otto WSI naive di varie tauopatie hanno dato come risultato un richiamo, una precisione e un punteggio F1 rispettivamente di 0,92, 0,72 e 0,81.", "token2charspan": [[0, 2], [3, 14], [15, 23], [24, 27], [28, 32], [33, 35], [36, 41], [42, 44], [45, 49], [50, 53], [54, 59], [60, 62], [63, 68], [69, 78], [79, 84], [85, 89], [90, 94], [95, 104], [105, 107], [108, 116], [116, 117], [118, 121], [122, 132], [133, 134], [135, 137], [138, 147], [148, 150], [151, 166], [167, 169], [170, 174], [174, 175], [176, 180], [181, 182], [183, 187], [187, 188]]}
{"doc_key": "ai-test-364", "ner": [[5, 5, "field"], [14, 15, "field"], [21, 21, "field"], [26, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 21, 21, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["Con", "l'", "aiuto", "di", "tecnologie", "AR", "avanzate", "(", "ad", "esempio", ",", "l'", "aggiunta", "di", "computer", "vision", ",", "l'", "incorporazione", "di", "telecamere", "AR", "negli", "smartphone", "e", "il", "riconoscimento", "degli", "oggetti", ")", ",", "le", "informazioni", "sul", "mondo", "reale", "circostante", "dell'", "utente", "diventano", "interattive", "e", "manipolate", "digitalmente", "."], "sentence-detokenized": "Con l'aiuto di tecnologie AR avanzate (ad esempio, l'aggiunta di computer vision, l'incorporazione di telecamere AR negli smartphone e il riconoscimento degli oggetti), le informazioni sul mondo reale circostante dell'utente diventano interattive e manipolate digitalmente.", "token2charspan": [[0, 3], [4, 6], [6, 11], [12, 14], [15, 25], [26, 28], [29, 37], [38, 39], [39, 41], [42, 49], [49, 50], [51, 53], [53, 61], [62, 64], [65, 73], [74, 80], [80, 81], [82, 84], [84, 98], [99, 101], [102, 112], [113, 115], [116, 121], [122, 132], [133, 134], [135, 137], [138, 152], [153, 158], [159, 166], [166, 167], [167, 168], [169, 171], [172, 184], [185, 188], [189, 194], [195, 200], [201, 212], [213, 218], [218, 224], [225, 234], [235, 246], [247, 248], [249, 259], [260, 272], [272, 273]]}
{"doc_key": "ai-test-365", "ner": [[2, 3, "researcher"], [8, 8, "organisation"], [16, 17, "field"], [29, 32, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 8, 8, "role", "forms_company", false, false], [8, 8, 16, 17, "related-to", "works_with", false, false], [8, 8, 29, 32, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Nel", "2014", "Schmidhuber", "ha", "costituito", "una", "societ\u00e0", ",", "Nnaisense", ",", "per", "lavorare", "sulle", "applicazioni", "commerciali", "dell'", "intelligenza", "artificiale", "in", "campi", "come", "la", "finanza", ",", "l'", "industria", "pesante", "e", "le", "auto", "a", "guida", "autonoma", "."], "sentence-detokenized": "Nel 2014 Schmidhuber ha costituito una societ\u00e0, Nnaisense, per lavorare sulle applicazioni commerciali dell'intelligenza artificiale in campi come la finanza, l'industria pesante e le auto a guida autonoma.", "token2charspan": [[0, 3], [4, 8], [9, 20], [21, 23], [24, 34], [35, 38], [39, 46], [46, 47], [48, 57], [57, 58], [59, 62], [63, 71], [72, 77], [78, 90], [91, 102], [103, 108], [108, 120], [121, 132], [133, 135], [136, 141], [142, 146], [147, 149], [150, 157], [157, 158], [159, 161], [161, 170], [171, 178], [179, 180], [181, 183], [184, 188], [189, 190], [191, 196], [197, 205], [205, 206]]}
{"doc_key": "ai-test-366", "ner": [[23, 25, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Questo", "non", "solo", "altera", "la", "performance", "di", "tutti", "i", "test", "successivi", "sul", "modello", "esplicativo", "mantenuto", ",", "ma", "pu\u00f2", "introdurre", "bias", "e", "alterare", "l'", "errore", "quadratico", "medio", "nella", "stima", "."], "sentence-detokenized": "Questo non solo altera la performance di tutti i test successivi sul modello esplicativo mantenuto, ma pu\u00f2 introdurre bias e alterare l'errore quadratico medio nella stima.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 22], [23, 25], [26, 37], [38, 40], [41, 46], [47, 48], [49, 53], [54, 64], [65, 68], [69, 76], [77, 88], [89, 98], [98, 99], [100, 102], [103, 106], [107, 117], [118, 122], [123, 124], [125, 133], [134, 136], [136, 142], [143, 153], [154, 159], [160, 165], [166, 171], [171, 172]]}
{"doc_key": "ai-test-367", "ner": [[0, 1, "misc"], [8, 10, "algorithm"], [14, 15, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 0, 1, "usage", "", false, false], [8, 10, 14, 15, "topic", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["I", "bigrammi", "sono", "utilizzati", "nella", "maggior", "parte", "dei", "modelli", "linguistici", "di", "successo", "per", "il", "riconoscimento", "vocale", "."], "sentence-detokenized": "I bigrammi sono utilizzati nella maggior parte dei modelli linguistici di successo per il riconoscimento vocale.", "token2charspan": [[0, 1], [2, 10], [11, 15], [16, 26], [27, 32], [33, 40], [41, 46], [47, 50], [51, 58], [59, 70], [71, 73], [74, 82], [83, 86], [87, 89], [90, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-test-368", "ner": [[4, 5, "field"], [11, 13, "misc"], [19, 21, "misc"], [26, 28, "organisation"], [31, 33, "misc"], [38, 41, "organisation"], [44, 46, "misc"], [51, 55, "organisation"], [58, 60, "misc"], [65, 67, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[11, 13, 4, 5, "topic", "", false, false], [19, 21, 26, 28, "origin", "", false, false], [31, 33, 38, 41, "origin", "", false, false], [44, 46, 51, 55, "origin", "", false, false], [58, 60, 65, 67, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Le", "sue", "ricerche", "in", "psicologia", "cognitiva", "sono", "state", "premiate", "con", "l'", "Early", "Career", "Award", "(", "1984", ")", "e", "il", "Boyd", "McCandless", "Award", "(", "1986", ")", "dell'", "American", "Psychological", "Association", ",", "il", "Troland", "Research", "Award", "(", "1993", ")", "della", "National", "Academy", "of", "Sciences", ",", "l'", "Henry", "Dale", "Prize", "(", "2004", ")", "della", "Royal", "Institution", "of", "Great", "Britain", "e", "il", "George", "Miller", "Prize", "(", "2010", ")", "della", "Cognitive", "Neuroscience", "Society", "."], "sentence-detokenized": "Le sue ricerche in psicologia cognitiva sono state premiate con l'Early Career Award (1984) e il Boyd McCandless Award (1986) dell'American Psychological Association, il Troland Research Award (1993) della National Academy of Sciences, l'Henry Dale Prize (2004) della Royal Institution of Great Britain e il George Miller Prize (2010) della Cognitive Neuroscience Society.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 18], [19, 29], [30, 39], [40, 44], [45, 50], [51, 59], [60, 63], [64, 66], [66, 71], [72, 78], [79, 84], [85, 86], [86, 90], [90, 91], [92, 93], [94, 96], [97, 101], [102, 112], [113, 118], [119, 120], [120, 124], [124, 125], [126, 131], [131, 139], [140, 153], [154, 165], [165, 166], [167, 169], [170, 177], [178, 186], [187, 192], [193, 194], [194, 198], [198, 199], [200, 205], [206, 214], [215, 222], [223, 225], [226, 234], [234, 235], [236, 238], [238, 243], [244, 248], [249, 254], [255, 256], [256, 260], [260, 261], [262, 267], [268, 273], [274, 285], [286, 288], [289, 294], [295, 302], [303, 304], [305, 307], [308, 314], [315, 321], [322, 327], [328, 329], [329, 333], [333, 334], [335, 340], [341, 350], [351, 363], [364, 371], [371, 372]]}
{"doc_key": "ai-test-369", "ner": [[5, 5, "misc"], [8, 11, "product"], [16, 16, "researcher"], [18, 18, "researcher"], [25, 26, "researcher"], [28, 29, "researcher"], [31, 33, "task"], [35, 38, "researcher"], [40, 44, "researcher"], [45, 46, "task"], [48, 48, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[5, 5, 16, 16, "origin", "", false, false], [5, 5, 18, 18, "origin", "", false, false], [5, 5, 31, 33, "related-to", "used_for", false, false], [8, 11, 5, 5, "usage", "", false, false], [8, 11, 45, 46, "named", "", false, false], [25, 26, 5, 5, "usage", "", false, false], [25, 26, 35, 38, "named", "same", false, false], [28, 29, 5, 5, "usage", "", false, false], [28, 29, 40, 44, "named", "same", false, false], [45, 46, 48, 48, "usage", "", false, false]], "relations_mapping_to_source": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["L'", "approccio", "all'", "uso", "di", "autofacce", "per", "il", "sistema", "di", "riconoscimento", "facciale", "\u00e8", "stato", "sviluppato", "da", "Sirovich", "e", "Kirby", "(", "1987", ")", "e", "utilizzato", "da", "Matthew", "Turk", "e", "Alex", "Pentland", "nella", "classificazione", "dei", "volti", ".", "Turk", ",", "Matthew", "A", "e", "Pentland", ",", "Alex", "P", ".", "Face", "recognition", "using", "eigenfaces", "."], "sentence-detokenized": "L'approccio all'uso di autofacce per il sistema di riconoscimento facciale \u00e8 stato sviluppato da Sirovich e Kirby (1987) e utilizzato da Matthew Turk e Alex Pentland nella classificazione dei volti. Turk, Matthew A e Pentland, Alex P. Face recognition using eigenfaces.", "token2charspan": [[0, 2], [2, 11], [12, 16], [16, 19], [20, 22], [23, 32], [33, 36], [37, 39], [40, 47], [48, 50], [51, 65], [66, 74], [75, 76], [77, 82], [83, 93], [94, 96], [97, 105], [106, 107], [108, 113], [114, 115], [115, 119], [119, 120], [121, 122], [123, 133], [134, 136], [137, 144], [145, 149], [150, 151], [152, 156], [157, 165], [166, 171], [172, 187], [188, 191], [192, 197], [197, 198], [199, 203], [203, 204], [205, 212], [213, 214], [215, 216], [217, 225], [225, 226], [227, 231], [232, 233], [233, 234], [235, 239], [240, 251], [252, 257], [258, 268], [268, 269]]}
{"doc_key": "ai-test-370", "ner": [[4, 4, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Un", "dizionario", "lessicale", "come", "WordNet", "pu\u00f2", "quindi", "essere", "utilizzato", "per", "comprendere", "il", "contesto", "."], "sentence-detokenized": "Un dizionario lessicale come WordNet pu\u00f2 quindi essere utilizzato per comprendere il contesto.", "token2charspan": [[0, 2], [3, 13], [14, 23], [24, 28], [29, 36], [37, 40], [41, 47], [48, 54], [55, 65], [66, 69], [70, 81], [82, 84], [85, 93], [93, 94]]}
{"doc_key": "ai-test-371", "ner": [[0, 1, "misc"], [10, 10, "misc"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 10, 10, "part-of", "", false, false], [10, 10, 16, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["L'", "iponimia", "\u00e8", "la", "relazione", "pi\u00f9", "frequentemente", "codificata", "tra", "i", "sintagmi", "utilizzati", "nei", "database", "lessicali", "come", "WordNet", "."], "sentence-detokenized": "L'iponimia \u00e8 la relazione pi\u00f9 frequentemente codificata tra i sintagmi utilizzati nei database lessicali come WordNet.", "token2charspan": [[0, 2], [2, 10], [11, 12], [13, 15], [16, 25], [26, 29], [30, 44], [45, 55], [56, 59], [60, 61], [62, 70], [71, 81], [82, 85], [86, 94], [95, 104], [105, 109], [110, 117], [117, 118]]}
{"doc_key": "ai-test-372", "ner": [[0, 0, "organisation"], [7, 7, "programlang"], [9, 9, "programlang"], [43, 43, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 7, 7, "general-affiliation", "", false, false], [0, 0, 9, 9, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["OPeNDAP", "offre", "librerie", "open", "-", "source", "in", "C+", "e", "Java", ",", "ma", "molti", "client", "si", "affidano", "a", "librerie", "sviluppate", "dalla", "comunit\u00e0", ",", "come", "ad", "esempio", "le", "librerie", "che", "includono", "funzionalit\u00e0", "integrate", "per", "il", "recupero", "di", "dati", "(", "di", "tipo", "array", ")", "dai", "server", "DAP", "."], "sentence-detokenized": "OPeNDAP offre librerie open-source in C+ e Java, ma molti client si affidano a librerie sviluppate dalla comunit\u00e0, come ad esempio le librerie che includono funzionalit\u00e0 integrate per il recupero di dati (di tipo array) dai server DAP.", "token2charspan": [[0, 7], [8, 13], [14, 22], [23, 27], [27, 28], [28, 34], [35, 37], [38, 40], [41, 42], [43, 47], [47, 48], [49, 51], [52, 57], [58, 64], [65, 67], [68, 76], [77, 78], [79, 87], [88, 98], [99, 104], [105, 113], [113, 114], [115, 119], [120, 122], [123, 130], [131, 133], [134, 142], [143, 146], [147, 156], [157, 169], [170, 179], [180, 183], [184, 186], [187, 195], [196, 198], [199, 203], [204, 205], [205, 207], [208, 212], [213, 218], [218, 219], [220, 223], [224, 230], [231, 234], [234, 235]]}
{"doc_key": "ai-test-373", "ner": [[4, 5, "misc"], [8, 8, "product"], [19, 19, "country"], [29, 30, "misc"], [44, 44, "organisation"], [42, 42, "product"], [52, 52, "organisation"], [47, 50, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 19, 19, "opposite", "", false, false], [8, 8, 19, 19, "artifact", "", false, false], [29, 30, 8, 8, "part-of", "", false, false], [42, 42, 44, 44, "artifact", "", false, false], [47, 50, 52, 52, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "quella", "pagina", ",", "Samurai", "Damashii", "esaltava", "il", "Senkousha", "come", "la", "cristallizzazione", "dei", "quattromila", "anni", "di", "conoscenza", "scientifica", "della", "Cina", ",", "commentava", "il", "design", "grezzo", "(", "ad", "esempio", "il", "cannone", "cinese", "sul", "cavallo", ")", "e", "metteva", "la", "sua", "immagine", "tra", "quelle", "dell'", "ASIMO", "di", "Honda", "e", "del", "QRIO", "SDR", "-", "3X", "di", "Sony", "per", "accostarlo", "."], "sentence-detokenized": "In quella pagina, Samurai Damashii esaltava il Senkousha come la cristallizzazione dei quattromila anni di conoscenza scientifica della Cina, commentava il design grezzo (ad esempio il cannone cinese sul cavallo) e metteva la sua immagine tra quelle dell'ASIMO di Honda e del QRIO SDR-3X di Sony per accostarlo.", "token2charspan": [[0, 2], [3, 9], [10, 16], [16, 17], [18, 25], [26, 34], [35, 43], [44, 46], [47, 56], [57, 61], [62, 64], [65, 82], [83, 86], [87, 98], [99, 103], [104, 106], [107, 117], [118, 129], [130, 135], [136, 140], [140, 141], [142, 152], [153, 155], [156, 162], [163, 169], [170, 171], [171, 173], [174, 181], [182, 184], [185, 192], [193, 199], [200, 203], [204, 211], [211, 212], [213, 214], [215, 222], [223, 225], [226, 229], [230, 238], [239, 242], [243, 249], [250, 255], [255, 260], [261, 263], [264, 269], [270, 271], [272, 275], [276, 280], [281, 284], [284, 285], [285, 287], [288, 290], [291, 295], [296, 299], [300, 310], [310, 311]]}
{"doc_key": "ai-test-374", "ner": [[10, 11, "algorithm"], [22, 22, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 22, 22, "part-of", "includes_functionality_of", false, false], [10, 11, 24, 24, "part-of", "includes_functionality_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Esistono", "anche", "molte", "librerie", "di", "programmazione", "che", "contengono", "funzionalit\u00e0", "di", "rete", "neurale", "e", "che", "possono", "essere", "utilizzate", "in", "implementazioni", "personalizzate", "(", "come", "TensorFlow", ",", "Theano", ",", "ecc.", ")", "."], "sentence-detokenized": "Esistono anche molte librerie di programmazione che contengono funzionalit\u00e0 di rete neurale e che possono essere utilizzate in implementazioni personalizzate (come TensorFlow, Theano, ecc.).", "token2charspan": [[0, 8], [9, 14], [15, 20], [21, 29], [30, 32], [33, 47], [48, 51], [52, 62], [63, 75], [76, 78], [79, 83], [84, 91], [92, 93], [94, 97], [98, 105], [106, 112], [113, 123], [124, 126], [127, 142], [143, 157], [158, 159], [159, 163], [164, 174], [174, 175], [176, 182], [182, 183], [184, 188], [188, 189], [189, 190]]}
{"doc_key": "ai-test-375", "ner": [[3, 6, "conference"], [9, 9, "organisation"], [12, 18, "conference"], [21, 21, "conference"], [24, 24, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["\u00c8", "membro", "dell'", "Association", "for", "Computing", "Machinery", ",", "dell'", "IEEE", ",", "dell'", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "dell'", "IAPR", "e", "della", "SPIE."], "sentence-detokenized": "\u00c8 membro dell'Association for Computing Machinery, dell'IEEE, dell'American Association for the Advancement of Science, dell'IAPR e della SPIE.", "token2charspan": [[0, 1], [2, 8], [9, 14], [14, 25], [26, 29], [30, 39], [40, 49], [49, 50], [51, 56], [56, 60], [60, 61], [62, 67], [67, 75], [76, 87], [88, 91], [92, 95], [96, 107], [108, 110], [111, 118], [118, 119], [120, 125], [125, 129], [130, 131], [132, 137], [138, 143]]}
{"doc_key": "ai-test-376", "ner": [[4, 4, "organisation"], [10, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 10, 14, "related-to", "runs_trials_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["Un", "esperimento", "condotto", "da", "RET", "nel", "2011", "con", "le", "telecamere", "del", "sistema", "di", "riconoscimento", "facciale", "montate", "sui", "tram", "ha", "fatto", "s\u00ec", "che", "le", "persone", "a", "cui", "era", "stato", "vietato", "l'", "accesso", "ai", "tram", "della", "citt\u00e0", "non", "salissero", "comunque", "di", "nascosto", "."], "sentence-detokenized": "Un esperimento condotto da RET nel 2011 con le telecamere del sistema di riconoscimento facciale montate sui tram ha fatto s\u00ec che le persone a cui era stato vietato l'accesso ai tram della citt\u00e0 non salissero comunque di nascosto.", "token2charspan": [[0, 2], [3, 14], [15, 23], [24, 26], [27, 30], [31, 34], [35, 39], [40, 43], [44, 46], [47, 57], [58, 61], [62, 69], [70, 72], [73, 87], [88, 96], [97, 104], [105, 108], [109, 113], [114, 116], [117, 122], [123, 125], [126, 129], [130, 132], [133, 140], [141, 142], [143, 146], [147, 150], [151, 156], [157, 164], [165, 167], [167, 174], [175, 177], [178, 182], [183, 188], [189, 194], [195, 198], [199, 208], [209, 217], [218, 220], [221, 229], [229, 230]]}
{"doc_key": "ai-test-377", "ner": [[10, 11, "person"], [7, 9, "organisation"], [23, 24, "person"], [26, 27, "person"], [31, 32, "person"], [34, 35, "person"], [37, 38, "person"], [40, 41, "person"], [43, 44, "person"], [46, 47, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[10, 11, 7, 9, "role", "works_for", false, false], [23, 24, 7, 9, "role", "works_for", false, false], [26, 27, 7, 9, "role", "works_for", false, false], [31, 32, 7, 9, "role", "works_for", false, false], [34, 35, 7, 9, "role", "works_for", false, false], [37, 38, 7, 9, "role", "works_for", false, false], [40, 41, 7, 9, "role", "works_for", false, false], [43, 44, 7, 9, "role", "works_for", false, false], [46, 47, 7, 9, "role", "works_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Il", "film", ",", "adattato", "dal", "popolare", "musical", "di", "Broadway", "di", "Cole", "Porter", ",", "\u00e8", "interpretato", "dalla", "coppia", "di", "cantanti", "della", "MGM", "composta", "da", "Howard", "Keel", "e", "Kathryn", "Grayson", ",", "affiancati", "da", "Ann", "Miller", ",", "Keenan", "Wynn", ",", "Bobby", "Van", ",", "James", "Whitmore", ",", "Kurt", "Kasznar", "e", "Tommy", "Rall", "."], "sentence-detokenized": "Il film, adattato dal popolare musical di Broadway di Cole Porter, \u00e8 interpretato dalla coppia di cantanti della MGM composta da Howard Keel e Kathryn Grayson, affiancati da Ann Miller, Keenan Wynn, Bobby Van, James Whitmore, Kurt Kasznar e Tommy Rall.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 17], [18, 21], [22, 30], [31, 38], [39, 41], [42, 50], [51, 53], [54, 58], [59, 65], [65, 66], [67, 68], [69, 81], [82, 87], [88, 94], [95, 97], [98, 106], [107, 112], [113, 116], [117, 125], [126, 128], [129, 135], [136, 140], [141, 142], [143, 150], [151, 158], [158, 159], [160, 170], [171, 173], [174, 177], [178, 184], [184, 185], [186, 192], [193, 197], [197, 198], [199, 204], [205, 208], [208, 209], [210, 215], [216, 224], [224, 225], [226, 230], [231, 238], [239, 240], [241, 246], [247, 251], [251, 252]]}
{"doc_key": "ai-test-378", "ner": [[25, 30, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Tali", "applicazioni", "dovrebbero", "snellire", "i", "flussi", "di", "chiamata", ",", "ridurre", "al", "minimo", "le", "richieste", ",", "eliminare", "le", "iterazioni", "non", "necessarie", "e", "consentire", "l'", "elaborazione", "di", "sistemi", "di", "dialogo", "a", "iniziativa", "mista", ",", "che", "consentano", "ai", "chiamanti", "di", "inserire", "diverse", "informazioni", "in", "un'", "unica", "pronuncia", "e", "in", "qualsiasi", "ordine", "o", "combinazione", "."], "sentence-detokenized": "Tali applicazioni dovrebbero snellire i flussi di chiamata, ridurre al minimo le richieste, eliminare le iterazioni non necessarie e consentire l'elaborazione di sistemi di dialogo a iniziativa mista, che consentano ai chiamanti di inserire diverse informazioni in un'unica pronuncia e in qualsiasi ordine o combinazione.", "token2charspan": [[0, 4], [5, 17], [18, 28], [29, 37], [38, 39], [40, 46], [47, 49], [50, 58], [58, 59], [60, 67], [68, 70], [71, 77], [78, 80], [81, 90], [90, 91], [92, 101], [102, 104], [105, 115], [116, 119], [120, 130], [131, 132], [133, 143], [144, 146], [146, 158], [159, 161], [162, 169], [170, 172], [173, 180], [181, 182], [183, 193], [194, 199], [199, 200], [201, 204], [205, 215], [216, 218], [219, 228], [229, 231], [232, 240], [241, 248], [249, 261], [262, 264], [265, 268], [268, 273], [274, 283], [284, 285], [286, 288], [289, 298], [299, 305], [306, 307], [308, 320], [320, 321]]}
{"doc_key": "ai-test-379", "ner": [[11, 13, "algorithm"], [17, 20, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 20, 11, 13, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Per", "questo", "motivo", ",", "\u00e8", "possibile", "adattare", "i", "metodi", "tradizionali", "di", "discesa", "del", "gradiente", "(", "o", "di", "discesa", "stocastica", "del", "gradiente", ")", ",", "in", "cui", ",", "anzich\u00e9", "eseguire", "un", "passo", "nella", "direzione", "del", "gradiente", "della", "funzione", ",", "si", "esegue", "un", "passo", "nella", "direzione", "di", "un", "vettore", "selezionato", "dal", "sottogradiente", "della", "funzione", "."], "sentence-detokenized": "Per questo motivo, \u00e8 possibile adattare i metodi tradizionali di discesa del gradiente (o di discesa stocastica del gradiente), in cui, anzich\u00e9 eseguire un passo nella direzione del gradiente della funzione, si esegue un passo nella direzione di un vettore selezionato dal sottogradiente della funzione.", "token2charspan": [[0, 3], [4, 10], [11, 17], [17, 18], [19, 20], [21, 30], [31, 39], [40, 41], [42, 48], [49, 61], [62, 64], [65, 72], [73, 76], [77, 86], [87, 88], [88, 89], [90, 92], [93, 100], [101, 111], [112, 115], [116, 125], [125, 126], [126, 127], [128, 130], [131, 134], [134, 135], [136, 143], [144, 152], [153, 155], [156, 161], [162, 167], [168, 177], [178, 181], [182, 191], [192, 197], [198, 206], [206, 207], [208, 210], [211, 217], [218, 220], [221, 226], [227, 232], [233, 242], [243, 245], [246, 248], [249, 256], [257, 268], [269, 272], [273, 287], [288, 293], [294, 302], [302, 303]]}
{"doc_key": "ai-test-380", "ner": [[9, 11, "metrics"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Se", "si", "assume", "che", "la", "distorsione", "sia", "misurata", "dall'", "errore", "quadratico", "medio", ",", "la", "distorsione", "D", "\u00e8", "data", "da", ":"], "sentence-detokenized": "Se si assume che la distorsione sia misurata dall'errore quadratico medio, la distorsione D \u00e8 data da:", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 16], [17, 19], [20, 31], [32, 35], [36, 44], [45, 50], [50, 56], [57, 67], [68, 73], [73, 74], [75, 77], [78, 89], [90, 91], [92, 93], [94, 98], [99, 101], [101, 102]]}
{"doc_key": "ai-test-381", "ner": [[0, 1, "algorithm"], [7, 8, "field"], [22, 23, "task"], [26, 28, "task"], [33, 34, "task"], [37, 38, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 7, 8, "part-of", "", false, false], [22, 23, 0, 1, "part-of", "", false, false], [26, 28, 0, 1, "part-of", "", false, false], [33, 34, 0, 1, "part-of", "", false, false], [37, 38, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Le", "MLP", "sono", "state", "una", "soluzione", "di", "apprendimento", "automatico", "molto", "popolare", "negli", "anni", "'80", ",", "trovando", "applicazione", "in", "diversi", "campi", "come", "il", "riconoscimento", "vocale", ",", "il", "riconoscimento", "di", "immagini", "e", "il", "software", "di", "traduzione", "automatica", ",", "le", "reti", "neurali", "."], "sentence-detokenized": "Le MLP sono state una soluzione di apprendimento automatico molto popolare negli anni '80, trovando applicazione in diversi campi come il riconoscimento vocale, il riconoscimento di immagini e il software di traduzione automatica, le reti neurali.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 17], [18, 21], [22, 31], [32, 34], [35, 48], [49, 59], [60, 65], [66, 74], [75, 80], [81, 85], [86, 89], [89, 90], [91, 99], [100, 112], [113, 115], [116, 123], [124, 129], [130, 134], [135, 137], [138, 152], [153, 159], [159, 160], [161, 163], [164, 178], [179, 181], [182, 190], [191, 192], [193, 195], [196, 204], [205, 207], [208, 218], [219, 229], [229, 230], [231, 233], [234, 238], [239, 246], [246, 247]]}
{"doc_key": "ai-test-382", "ner": [[0, 1, "researcher"], [4, 6, "misc"], [9, 11, "university"], [19, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 9, 11, "physical", "", false, false], [0, 1, 9, 11, "role", "", false, false], [4, 6, 0, 1, "origin", "", false, false], [19, 21, 0, 1, "role", "supervised", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Allen", "ha", "conseguito", "il", "dottorato", "di", "ricerca", "presso", "l'", "Universit\u00e0", "di", "Toronto", "nel", "1979", ",", "sotto", "la", "supervisione", "di", "C.", "Raymond", "Perrault", ","], "sentence-detokenized": "Allen ha conseguito il dottorato di ricerca presso l'Universit\u00e0 di Toronto nel 1979, sotto la supervisione di C. Raymond Perrault,", "token2charspan": [[0, 5], [6, 8], [9, 19], [20, 22], [23, 32], [33, 35], [36, 43], [44, 50], [51, 53], [53, 63], [64, 66], [67, 74], [75, 78], [79, 83], [83, 84], [85, 90], [91, 93], [94, 106], [107, 109], [110, 112], [113, 120], [121, 129], [129, 130]]}
{"doc_key": "ai-test-383", "ner": [[0, 0, "product"], [5, 8, "field"], [10, 10, "product"], [12, 12, "product"], [14, 14, "product"], [22, 22, "product"], [25, 25, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 5, 8, "related-to", "supports", false, false], [10, 10, 5, 8, "type-of", "", true, false], [12, 12, 5, 8, "type-of", "", true, false], [14, 14, 5, 8, "type-of", "", true, false], [14, 14, 22, 22, "related-to", "converting_to", true, false], [25, 25, 5, 8, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["OpenCV", "supporta", "alcuni", "modelli", "di", "framework", "di", "deep", "learning", "come", "TensorFlow", ",", "Torch", ",", "PyTorch", "(", "dopo", "la", "conversione", "in", "un", "modello", "ONNX", ")", "e", "Caffe", "secondo", "un", "elenco", "definito", "di", "livelli", "supportati", "."], "sentence-detokenized": "OpenCV supporta alcuni modelli di framework di deep learning come TensorFlow, Torch, PyTorch (dopo la conversione in un modello ONNX) e Caffe secondo un elenco definito di livelli supportati.", "token2charspan": [[0, 6], [7, 15], [16, 22], [23, 30], [31, 33], [34, 43], [44, 46], [47, 51], [52, 60], [61, 65], [66, 76], [76, 77], [78, 83], [83, 84], [85, 92], [93, 94], [94, 98], [99, 101], [102, 113], [114, 116], [117, 119], [120, 127], [128, 132], [132, 133], [134, 135], [136, 141], [142, 149], [150, 152], [153, 159], [160, 168], [169, 171], [172, 179], [180, 190], [190, 191]]}
{"doc_key": "ai-test-384", "ner": [[3, 3, "researcher"], [9, 14, "organisation"], [16, 16, "organisation"], [23, 27, "organisation"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 9, 14, "role", "", false, false], [3, 3, 23, 27, "role", "", false, false], [3, 3, 21, 22, "related-to", "lectures_in", false, false], [16, 16, 9, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "precedenza", ",", "Christensen", "\u00e8", "stato", "presidente", "fondatore", "della", "Rete", "europea", "di", "ricerca", "sulla", "robotica", "(", "EURON", ")", "e", "docente", "di", "robotica", "della", "IEEE", "Robotics", "and", "Automation", "Society", "."], "sentence-detokenized": "In precedenza, Christensen \u00e8 stato presidente fondatore della Rete europea di ricerca sulla robotica (EURON) e docente di robotica della IEEE Robotics and Automation Society.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 26], [27, 28], [29, 34], [35, 45], [46, 55], [56, 61], [62, 66], [67, 74], [75, 77], [78, 85], [86, 91], [92, 100], [101, 102], [102, 107], [107, 108], [109, 110], [111, 118], [119, 121], [122, 130], [131, 136], [137, 141], [142, 150], [151, 154], [155, 165], [166, 173], [173, 174]]}
{"doc_key": "ai-test-385", "ner": [[5, 5, "field"], [8, 11, "university"], [13, 13, "location"], [15, 18, "country"], [23, 23, "misc"], [25, 25, "field"], [28, 32, "organisation"], [34, 34, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[8, 11, 13, 13, "physical", "", false, false], [13, 13, 15, 18, "physical", "", false, false], [23, 23, 25, 25, "topic", "", false, false], [28, 32, 34, 34, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Ha", "conseguito", "il", "master", "in", "matematica", "presso", "l'", "Universit\u00e0", "Statale", "di", "Samarcanda", ",", "Samarcanda", ",", "Repubblica", "Socialista", "Sovietica", "Uzbeka", "nel", "1958", "e", "il", "dottorato", "in", "statistica", "presso", "l'", "Istituto", "di", "Scienze", "del", "Controllo", "di", "Mosca", "nel", "1964", "."], "sentence-detokenized": "Ha conseguito il master in matematica presso l'Universit\u00e0 Statale di Samarcanda, Samarcanda, Repubblica Socialista Sovietica Uzbeka nel 1958 e il dottorato in statistica presso l'Istituto di Scienze del Controllo di Mosca nel 1964.", "token2charspan": [[0, 2], [3, 13], [14, 16], [17, 23], [24, 26], [27, 37], [38, 44], [45, 47], [47, 57], [58, 65], [66, 68], [69, 79], [79, 80], [81, 91], [91, 92], [93, 103], [104, 114], [115, 124], [125, 131], [132, 135], [136, 140], [141, 142], [143, 145], [146, 155], [156, 158], [159, 169], [170, 176], [177, 179], [179, 187], [188, 190], [191, 198], [199, 202], [203, 212], [213, 215], [216, 221], [222, 225], [226, 230], [230, 231]]}
{"doc_key": "ai-test-386", "ner": [[9, 9, "organisation"], [14, 15, "product"], [38, 39, "field"], [42, 45, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 38, 39, "usage", "", false, false], [9, 9, 42, 45, "usage", "", false, false], [14, 15, 9, 9, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Sempre", "pi\u00f9", "spesso", ",", "tuttavia", ",", "il", "lavoro", "di", "Cycorp", "consiste", "nel", "dare", "al", "sistema", "Cyc", "la", "capacit\u00e0", "di", "comunicare", "con", "gli", "utenti", "finali", "in", "linguaggio", "naturale", "e", "di", "assistere", "il", "processo", "di", "formazione", "della", "conoscenza", "attraverso", "l'", "apprendimento", "automatico", "e", "la", "comprensione", "del", "linguaggio", "naturale", "."], "sentence-detokenized": "Sempre pi\u00f9 spesso, tuttavia, il lavoro di Cycorp consiste nel dare al sistema Cyc la capacit\u00e0 di comunicare con gli utenti finali in linguaggio naturale e di assistere il processo di formazione della conoscenza attraverso l'apprendimento automatico e la comprensione del linguaggio naturale.", "token2charspan": [[0, 6], [7, 10], [11, 17], [17, 18], [19, 27], [27, 28], [29, 31], [32, 38], [39, 41], [42, 48], [49, 57], [58, 61], [62, 66], [67, 69], [70, 77], [78, 81], [82, 84], [85, 93], [94, 96], [97, 107], [108, 111], [112, 115], [116, 122], [123, 129], [130, 132], [133, 143], [144, 152], [153, 154], [155, 157], [158, 167], [168, 170], [171, 179], [180, 182], [183, 193], [194, 199], [200, 210], [211, 221], [222, 224], [224, 237], [238, 248], [249, 250], [251, 253], [254, 266], [267, 270], [271, 281], [282, 290], [290, 291]]}
{"doc_key": "ai-test-387", "ner": [[57, 57, "metrics"], [59, 59, "metrics"], [61, 61, "metrics"], [63, 64, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ad", "esempio", ",", "se", "si", "cerca", "il", "classificatore", "pi\u00f9", "adatto", "al", "problema", ",", "il", "dataset", "di", "addestramento", "viene", "utilizzato", "per", "addestrare", "gli", "algoritmi", "candidati", ",", "il", "dataset", "di", "validazione", "viene", "utilizzato", "per", "confrontare", "le", "loro", "prestazioni", "e", "decidere", "quale", "scegliere", "e", ",", "infine", ",", "il", "dataset", "di", "test", "viene", "utilizzato", "per", "ottenere", "le", "caratteristiche", "di", "prestazione", "come", "accuratezza", ",", "sensibilit\u00e0", ",", "specificit\u00e0", ",", "misura", "F", "e", "cos\u00ec", "via", "."], "sentence-detokenized": "Ad esempio, se si cerca il classificatore pi\u00f9 adatto al problema, il dataset di addestramento viene utilizzato per addestrare gli algoritmi candidati, il dataset di validazione viene utilizzato per confrontare le loro prestazioni e decidere quale scegliere e, infine, il dataset di test viene utilizzato per ottenere le caratteristiche di prestazione come accuratezza, sensibilit\u00e0, specificit\u00e0, misura F e cos\u00ec via.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 14], [15, 17], [18, 23], [24, 26], [27, 41], [42, 45], [46, 52], [53, 55], [56, 64], [64, 65], [66, 68], [69, 76], [77, 79], [80, 93], [94, 99], [100, 110], [111, 114], [115, 125], [126, 129], [130, 139], [140, 149], [149, 150], [151, 153], [154, 161], [162, 164], [165, 176], [177, 182], [183, 193], [194, 197], [198, 209], [210, 212], [213, 217], [218, 229], [230, 231], [232, 240], [241, 246], [247, 256], [257, 258], [258, 259], [260, 266], [266, 267], [268, 270], [271, 278], [279, 281], [282, 286], [287, 292], [293, 303], [304, 307], [308, 316], [317, 319], [320, 335], [336, 338], [339, 350], [351, 355], [356, 367], [367, 368], [369, 380], [380, 381], [382, 393], [393, 394], [395, 401], [402, 403], [404, 405], [406, 410], [411, 414], [414, 415]]}
{"doc_key": "ai-test-388", "ner": [[1, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["L'", "errore", "quadratico", "medio", "\u00e8", "pari", "a", "0,15", "."], "sentence-detokenized": "L'errore quadratico medio \u00e8 pari a 0,15.", "token2charspan": [[0, 2], [2, 8], [9, 19], [20, 25], [26, 27], [28, 32], [33, 34], [35, 39], [39, 40]]}
{"doc_key": "ai-test-389", "ner": [[6, 8, "misc"], [3, 3, "organisation"], [14, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 6, 8, "role", "", false, false], [14, 14, 6, 8, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Nel", "1979", "l'", "IEEE", "organizz\u00f2", "una", "gara", "di", "micromouse", ",", "come", "mostrato", "nella", "rivista", "Spectrum", "."], "sentence-detokenized": "Nel 1979 l'IEEE organizz\u00f2 una gara di micromouse, come mostrato nella rivista Spectrum.", "token2charspan": [[0, 3], [4, 8], [9, 11], [11, 15], [16, 25], [26, 29], [30, 34], [35, 37], [38, 48], [48, 49], [50, 54], [55, 63], [64, 69], [70, 77], [78, 86], [86, 87]]}
{"doc_key": "ai-test-390", "ner": [[0, 3, "algorithm"], [9, 12, "field"], [16, 19, "task"], [22, 24, "task"], [27, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 9, 12, "part-of", "", false, false], [16, 19, 9, 12, "part-of", "task_part_of_field", false, false], [22, 24, 9, 12, "part-of", "task_part_of_field", false, false], [27, 30, 9, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Lo", "spazio", "di", "Gabor", "\u00e8", "molto", "utile", "nelle", "applicazioni", "di", "elaborazione", "delle", "immagini", ",", "come", "il", "riconoscimento", "ottico", "dei", "caratteri", ",", "il", "riconoscimento", "dell'", "iride", "e", "il", "riconoscimento", "delle", "impronte", "digitali", "."], "sentence-detokenized": "Lo spazio di Gabor \u00e8 molto utile nelle applicazioni di elaborazione delle immagini, come il riconoscimento ottico dei caratteri, il riconoscimento dell'iride e il riconoscimento delle impronte digitali.", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 18], [19, 20], [21, 26], [27, 32], [33, 38], [39, 51], [52, 54], [55, 67], [68, 73], [74, 82], [82, 83], [84, 88], [89, 91], [92, 106], [107, 113], [114, 117], [118, 127], [127, 128], [129, 131], [132, 146], [147, 152], [152, 157], [158, 159], [160, 162], [163, 177], [178, 183], [184, 192], [193, 201], [201, 202]]}
{"doc_key": "ai-test-391", "ner": [[7, 7, "programlang"], [9, 9, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["o", "tramite", "interfacce", "di", "alto", "livello", "per", "Java", "e", "Tcl."], "sentence-detokenized": "o tramite interfacce di alto livello per Java e Tcl.", "token2charspan": [[0, 1], [2, 9], [10, 20], [21, 23], [24, 28], [29, 36], [37, 40], [41, 45], [46, 47], [48, 52]]}
{"doc_key": "ai-test-392", "ner": [[12, 15, "algorithm"], [22, 22, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 15, 22, 22, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Nella", "ricerca", "recente", ",", "i", "metodi", "basati", "su", "kernel", ",", "come", "le", "macchine", "vettoriali", "di", "supporto", ",", "hanno", "dimostrato", "prestazioni", "superiori", "nella", "supervisione", "."], "sentence-detokenized": "Nella ricerca recente, i metodi basati su kernel, come le macchine vettoriali di supporto, hanno dimostrato prestazioni superiori nella supervisione.", "token2charspan": [[0, 5], [6, 13], [14, 21], [21, 22], [23, 24], [25, 31], [32, 38], [39, 41], [42, 48], [48, 49], [50, 54], [55, 57], [58, 66], [67, 77], [78, 80], [81, 89], [89, 90], [91, 96], [97, 107], [108, 119], [120, 129], [130, 135], [136, 148], [148, 149]]}
{"doc_key": "ai-test-393", "ner": [[18, 18, "misc"], [25, 25, "researcher"], [27, 27, "researcher"], [35, 35, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[25, 25, 35, 35, "usage", "", false, false], [27, 27, 35, 35, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Per", "illustrare", "i", "principi", "di", "base", "del", "bagging", ",", "di", "seguito", "\u00e8", "riportata", "un'", "analisi", "della", "relazione", "tra", "ozono", "e", "temperatura", "(", "dati", "tratti", "da", "Rousseeuw", "e", "Leroy", "(", "1986", ")", ",", "analisi", "effettuata", "in", "R", ")", "."], "sentence-detokenized": "Per illustrare i principi di base del bagging, di seguito \u00e8 riportata un'analisi della relazione tra ozono e temperatura (dati tratti da Rousseeuw e Leroy (1986), analisi effettuata in R).", "token2charspan": [[0, 3], [4, 14], [15, 16], [17, 25], [26, 28], [29, 33], [34, 37], [38, 45], [45, 46], [47, 49], [50, 57], [58, 59], [60, 69], [70, 73], [73, 80], [81, 86], [87, 96], [97, 100], [101, 106], [107, 108], [109, 120], [121, 122], [122, 126], [127, 133], [134, 136], [137, 146], [147, 148], [149, 154], [155, 156], [156, 160], [160, 161], [161, 162], [163, 170], [171, 181], [182, 184], [185, 186], [186, 187], [187, 188]]}
{"doc_key": "ai-test-394", "ner": [[0, 1, "organisation"], [13, 16, "product"], [22, 23, "product"], [25, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 16, 0, 1, "artifact", "", false, false], [22, 23, 0, 1, "artifact", "", false, false], [25, 27, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Denso", "Wave", "\u00e8", "una", "consociata", "che", "produce", "prodotti", "di", "identificazione", "automatica", "(", "lettori", "di", "codici", "a", "barre", "e", "prodotti", "correlati", ")", ",", "robot", "industriali", "e", "controllori", "logici", "programmabili", "."], "sentence-detokenized": "Denso Wave \u00e8 una consociata che produce prodotti di identificazione automatica (lettori di codici a barre e prodotti correlati), robot industriali e controllori logici programmabili.", "token2charspan": [[0, 5], [6, 10], [11, 12], [13, 16], [17, 27], [28, 31], [32, 39], [40, 48], [49, 51], [52, 67], [68, 78], [79, 80], [80, 87], [88, 90], [91, 97], [98, 99], [100, 105], [106, 107], [108, 116], [117, 126], [126, 127], [127, 128], [129, 134], [135, 146], [147, 148], [149, 160], [161, 167], [168, 181], [181, 182]]}
{"doc_key": "ai-test-395", "ner": [[1, 3, "metrics"], [9, 9, "metrics"], [22, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 3, 22, 23, "compare", "", false, false], [9, 9, 1, 3, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Mentre", "Bilingual", "evaluation", "understudy", "si", "limita", "a", "calcolare", "la", "precisione", "dei", "grafemi", ",", "attribuendo", "lo", "stesso", "peso", "a", "ciascuno", "di", "essi", ",", "il", "NIST", "calcola", "anche", "il", "grado", "di", "informazione", "di", "un", "particolare", "grafema", "."], "sentence-detokenized": "Mentre Bilingual evaluation understudy si limita a calcolare la precisione dei grafemi, attribuendo lo stesso peso a ciascuno di essi, il NIST calcola anche il grado di informazione di un particolare grafema.", "token2charspan": [[0, 6], [7, 16], [17, 27], [28, 38], [39, 41], [42, 48], [49, 50], [51, 60], [61, 63], [64, 74], [75, 78], [79, 86], [86, 87], [88, 99], [100, 102], [103, 109], [110, 114], [115, 116], [117, 125], [126, 128], [129, 133], [133, 134], [135, 137], [138, 142], [143, 150], [151, 156], [157, 159], [160, 165], [166, 168], [169, 181], [182, 184], [185, 187], [188, 199], [200, 207], [207, 208]]}
{"doc_key": "ai-test-396", "ner": [[16, 16, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "particolare", ",", "vengono", "utilizzati", "durante", "il", "calcolo", "della", "verosimiglianza", "di", "un", "albero", "(", "negli", "approcci", "bayesiani", "e", "di", "massima", "verosimiglianza", "alla", "stima", "degli", "alberi", ")", "e", "vengono", "utilizzati", "per", "stimare", "la", "distanza", "evolutiva", "tra", "le", "sequenze", "a", "partire", "dalle", "differenze", "osservate", "tra", "le", "sequenze", "."], "sentence-detokenized": "In particolare, vengono utilizzati durante il calcolo della verosimiglianza di un albero (negli approcci bayesiani e di massima verosimiglianza alla stima degli alberi) e vengono utilizzati per stimare la distanza evolutiva tra le sequenze a partire dalle differenze osservate tra le sequenze.", "token2charspan": [[0, 2], [3, 14], [14, 15], [16, 23], [24, 34], [35, 42], [43, 45], [46, 53], [54, 59], [60, 75], [76, 78], [79, 81], [82, 88], [89, 90], [90, 95], [96, 104], [105, 114], [115, 116], [117, 119], [120, 127], [128, 143], [144, 148], [149, 154], [155, 160], [161, 167], [167, 168], [169, 170], [171, 178], [179, 189], [190, 193], [194, 201], [202, 204], [205, 213], [214, 223], [224, 227], [228, 230], [231, 239], [240, 241], [242, 249], [250, 255], [256, 266], [267, 276], [277, 280], [281, 283], [284, 292], [292, 293]]}
{"doc_key": "ai-test-397", "ner": [[1, 3, "conference"], [25, 26, "misc"], [28, 28, "misc"], [57, 60, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[28, 28, 25, 26, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["L'", "Audio", "Engineering", "Society", "raccomanda", "una", "frequenza", "di", "campionamento", "di", "48", "kHz", "per", "la", "maggior", "parte", "delle", "applicazioni", ",", "ma", "riconosce", "44,1", "kHz", "per", "i", "Compact", "Disc", "(", "CD", ")", "e", "altri", "usi", "consumer", ",", "32", "kHz", "per", "le", "applicazioni", "legate", "alle", "trasmissioni", "e", "96", "kHz", "per", "una", "maggiore", "larghezza", "di", "banda", "o", "per", "l'", "utilizzo", "di", "filtri", "anti", "-", "aliasing", "rilassati", "."], "sentence-detokenized": "L'Audio Engineering Society raccomanda una frequenza di campionamento di 48 kHz per la maggior parte delle applicazioni, ma riconosce 44,1 kHz per i Compact Disc (CD) e altri usi consumer, 32 kHz per le applicazioni legate alle trasmissioni e 96 kHz per una maggiore larghezza di banda o per l'utilizzo di filtri anti-aliasing rilassati.", "token2charspan": [[0, 2], [2, 7], [8, 19], [20, 27], [28, 38], [39, 42], [43, 52], [53, 55], [56, 69], [70, 72], [73, 75], [76, 79], [80, 83], [84, 86], [87, 94], [95, 100], [101, 106], [107, 119], [119, 120], [121, 123], [124, 133], [134, 138], [139, 142], [143, 146], [147, 148], [149, 156], [157, 161], [162, 163], [163, 165], [165, 166], [167, 168], [169, 174], [175, 178], [179, 187], [187, 188], [189, 191], [192, 195], [196, 199], [200, 202], [203, 215], [216, 222], [223, 227], [228, 240], [241, 242], [243, 245], [246, 249], [250, 253], [254, 257], [258, 266], [267, 276], [277, 279], [280, 285], [286, 287], [288, 291], [292, 294], [294, 302], [303, 305], [306, 312], [313, 317], [317, 318], [318, 326], [327, 336], [336, 337]]}
{"doc_key": "ai-test-398", "ner": [[12, 12, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sono", "state", "create", "risorse", "per", "l'", "affettivit\u00e0", "di", "parole", "e", "concetti", "per", "WordNet", "{", "{", "cite", "journal"], "sentence-detokenized": "Sono state create risorse per l'affettivit\u00e0 di parole e concetti per WordNet {{cite journal", "token2charspan": [[0, 4], [5, 10], [11, 17], [18, 25], [26, 29], [30, 32], [32, 43], [44, 46], [47, 53], [54, 55], [56, 64], [65, 68], [69, 76], [77, 78], [78, 79], [79, 83], [84, 91]]}
{"doc_key": "ai-test-399", "ner": [[1, 4, "misc"], [25, 26, "person"], [31, 33, "person"], [39, 41, "person"], [47, 50, "organisation"], [68, 70, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[31, 33, 39, 41, "role", "acts_in", false, false], [47, 50, 39, 41, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "anaglifo", "rosso", "-", "verde", ",", "al", "pubblico", "sono", "state", "presentate", "tre", "bobine", "di", "prova", ",", "che", "comprendevano", "scene", "rurali", ",", "riprese", "di", "prova", "di", "Marie", "Doro", ",", "un", "segmento", "di", "John", "B.", "Mason", "che", "recitava", "alcuni", "passaggi", "di", "Jim", "the", "Penman", "(", "un", "film", "distribuito", "da", "Famous", "Players", "-", "Lasky", "quell'", "anno", ",", "ma", "non", "in", "3D", ")", ",", "danzatrici", "orientali", "e", "una", "bobina", "di", "filmati", "delle", "cascate", "del", "Niagara", "."], "sentence-detokenized": "In anaglifo rosso-verde, al pubblico sono state presentate tre bobine di prova, che comprendevano scene rurali, riprese di prova di Marie Doro, un segmento di John B. Mason che recitava alcuni passaggi di Jim the Penman (un film distribuito da Famous Players-Lasky quell'anno, ma non in 3D), danzatrici orientali e una bobina di filmati delle cascate del Niagara.", "token2charspan": [[0, 2], [3, 11], [12, 17], [17, 18], [18, 23], [23, 24], [25, 27], [28, 36], [37, 41], [42, 47], [48, 58], [59, 62], [63, 69], [70, 72], [73, 78], [78, 79], [80, 83], [84, 97], [98, 103], [104, 110], [110, 111], [112, 119], [120, 122], [123, 128], [129, 131], [132, 137], [138, 142], [142, 143], [144, 146], [147, 155], [156, 158], [159, 163], [164, 166], [167, 172], [173, 176], [177, 185], [186, 192], [193, 201], [202, 204], [205, 208], [209, 212], [213, 219], [220, 221], [221, 223], [224, 228], [229, 240], [241, 243], [244, 250], [251, 258], [258, 259], [259, 264], [265, 271], [271, 275], [275, 276], [277, 279], [280, 283], [284, 286], [287, 289], [289, 290], [290, 291], [292, 302], [303, 312], [313, 314], [315, 318], [319, 325], [326, 328], [329, 336], [337, 342], [343, 350], [351, 354], [355, 362], [362, 363]]}
{"doc_key": "ai-test-400", "ner": [[9, 12, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Si", "tratta", "di", "un", "modo", "particolare", "di", "implementare", "la", "stima", "della", "massima", "verosimiglianza", "per", "questo", "problema", "."], "sentence-detokenized": "Si tratta di un modo particolare di implementare la stima della massima verosimiglianza per questo problema.", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 15], [16, 20], [21, 32], [33, 35], [36, 48], [49, 51], [52, 57], [58, 63], [64, 71], [72, 87], [88, 91], [92, 98], [99, 107], [107, 108]]}
{"doc_key": "ai-test-401", "ner": [[8, 8, "misc"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Integra", "le", "caratteristiche", "delle", "sitemap", "e", "dei", "feed", "RSS", "in", "un", "meccanismo", "decentralizzato", "che", "consente", "ai", "biologi", "computazionali", "e", "ai", "bioinformatici", "di", "trasmettere", "e", "recuperare", "apertamente", "i", "metadati", "sulle", "risorse", "biomediche", "."], "sentence-detokenized": "Integra le caratteristiche delle sitemap e dei feed RSS in un meccanismo decentralizzato che consente ai biologi computazionali e ai bioinformatici di trasmettere e recuperare apertamente i metadati sulle risorse biomediche.", "token2charspan": [[0, 7], [8, 10], [11, 26], [27, 32], [33, 40], [41, 42], [43, 46], [47, 51], [52, 55], [56, 58], [59, 61], [62, 72], [73, 88], [89, 92], [93, 101], [102, 104], [105, 112], [113, 127], [128, 129], [130, 132], [133, 147], [148, 150], [151, 162], [163, 164], [165, 175], [176, 187], [188, 189], [190, 198], [199, 204], [205, 212], [213, 223], [223, 224]]}
{"doc_key": "ai-test-402", "ner": [[3, 11, "misc"], [14, 20, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["\u00c8", "coperto", "dallo", "standard", "Z39.50", "dell'", "American", "National", "Standards", "Institute", "/", "NISO", "e", "dallo", "standard", "23950", "dell'", "International", "Organization", "for", "Standardization", "."], "sentence-detokenized": "\u00c8 coperto dallo standard Z39.50 dell'American National Standards Institute / NISO e dallo standard 23950 dell'International Organization for Standardization.", "token2charspan": [[0, 1], [2, 9], [10, 15], [16, 24], [25, 31], [32, 37], [37, 45], [46, 54], [55, 64], [65, 74], [75, 76], [77, 81], [82, 83], [84, 89], [90, 98], [99, 104], [105, 110], [110, 123], [124, 136], [137, 140], [141, 156], [156, 157]]}
{"doc_key": "ai-test-403", "ner": [[15, 18, "misc"], [25, 26, "metrics"], [30, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Il", "codificatore", "e", "il", "decodificatore", "sono", "addestrati", "a", "prendere", "una", "frase", "e", "a", "riprodurre", "la", "distribuzione", "one", "-", "hot", "di", "una", "parafrasi", "corrispondente", ",", "minimizzando", "la", "perplessit\u00e0", "mediante", "una", "semplice", "discesa", "stocastica", "del", "gradiente", "."], "sentence-detokenized": "Il codificatore e il decodificatore sono addestrati a prendere una frase e a riprodurre la distribuzione one-hot di una parafrasi corrispondente, minimizzando la perplessit\u00e0 mediante una semplice discesa stocastica del gradiente.", "token2charspan": [[0, 2], [3, 15], [16, 17], [18, 20], [21, 35], [36, 40], [41, 51], [52, 53], [54, 62], [63, 66], [67, 72], [73, 74], [75, 76], [77, 87], [88, 90], [91, 104], [105, 108], [108, 109], [109, 112], [113, 115], [116, 119], [120, 129], [130, 144], [144, 145], [146, 158], [159, 161], [162, 173], [174, 182], [183, 186], [187, 195], [196, 203], [204, 214], [215, 218], [219, 228], [228, 229]]}
{"doc_key": "ai-test-404", "ner": [[6, 8, "field"], [11, 14, "task"], [17, 22, "task"], [38, 45, "task"], [48, 54, "task"], [57, 66, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 14, 6, 8, "part-of", "task_part_of_field", false, false], [17, 22, 6, 8, "part-of", "task_part_of_field", false, false], [38, 45, 6, 8, "part-of", "task_part_of_field", false, false], [48, 54, 6, 8, "part-of", "task_part_of_field", false, false], [57, 66, 6, 8, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Altre", "applicazioni", "tipiche", "delle", "tecniche", "di", "riconoscimento", "di", "pattern", "sono", "il", "riconoscimento", "automatico", "del", "parlato", ",", "la", "classificazione", "del", "testo", "in", "diverse", "categorie", "(", "ad", "esempio", ",", "messaggi", "di", "posta", "elettronica", "spam", "/", "non", "spam", ")", ",", "il", "riconoscimento", "della", "scrittura", "a", "mano", "su", "buste", "postali", ",", "il", "riconoscimento", "automatico", "di", "immagini", "di", "volti", "umani", "o", "l'", "estrazione", "di", "immagini", "di", "scrittura", "a", "mano", "da", "moduli", "medici", "."], "sentence-detokenized": "Altre applicazioni tipiche delle tecniche di riconoscimento di pattern sono il riconoscimento automatico del parlato, la classificazione del testo in diverse categorie (ad esempio, messaggi di posta elettronica spam/non spam), il riconoscimento della scrittura a mano su buste postali, il riconoscimento automatico di immagini di volti umani o l'estrazione di immagini di scrittura a mano da moduli medici.", "token2charspan": [[0, 5], [6, 18], [19, 26], [27, 32], [33, 41], [42, 44], [45, 59], [60, 62], [63, 70], [71, 75], [76, 78], [79, 93], [94, 104], [105, 108], [109, 116], [116, 117], [118, 120], [121, 136], [137, 140], [141, 146], [147, 149], [150, 157], [158, 167], [168, 169], [169, 171], [172, 179], [179, 180], [181, 189], [190, 192], [193, 198], [199, 210], [211, 215], [215, 216], [216, 219], [220, 224], [224, 225], [225, 226], [227, 229], [230, 244], [245, 250], [251, 260], [261, 262], [263, 267], [268, 270], [271, 276], [277, 284], [284, 285], [286, 288], [289, 303], [304, 314], [315, 317], [318, 326], [327, 329], [330, 335], [336, 341], [342, 343], [344, 346], [346, 356], [357, 359], [360, 368], [369, 371], [372, 381], [382, 383], [384, 388], [389, 391], [392, 398], [399, 405], [405, 406]]}
{"doc_key": "ai-test-405", "ner": [[0, 3, "algorithm"], [16, 17, "field"], [20, 21, "task"], [24, 25, "task"], [28, 31, "task"], [34, 40, "task"], [43, 44, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[16, 17, 0, 3, "usage", "", false, false], [20, 21, 0, 3, "usage", "", false, false], [24, 25, 0, 3, "usage", "", false, false], [28, 31, 0, 3, "usage", "", false, false], [34, 40, 0, 3, "usage", "", false, false], [43, 44, 0, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Le", "reti", "neurali", "artificiali", "sono", "state", "utilizzate", "per", "una", "variet\u00e0", "di", "compiti", ",", "tra", "cui", "la", "computer", "vision", ",", "il", "riconoscimento", "vocale", ",", "la", "traduzione", "automatica", ",", "il", "filtraggio", "dei", "social", "network", ",", "la", "riproduzione", "di", "giochi", "da", "tavolo", "e", "video", "e", "la", "diagnosi", "medica", "."], "sentence-detokenized": "Le reti neurali artificiali sono state utilizzate per una variet\u00e0 di compiti, tra cui la computer vision, il riconoscimento vocale, la traduzione automatica, il filtraggio dei social network, la riproduzione di giochi da tavolo e video e la diagnosi medica.", "token2charspan": [[0, 2], [3, 7], [8, 15], [16, 27], [28, 32], [33, 38], [39, 49], [50, 53], [54, 57], [58, 65], [66, 68], [69, 76], [76, 77], [78, 81], [82, 85], [86, 88], [89, 97], [98, 104], [104, 105], [106, 108], [109, 123], [124, 130], [130, 131], [132, 134], [135, 145], [146, 156], [156, 157], [158, 160], [161, 171], [172, 175], [176, 182], [183, 190], [190, 191], [192, 194], [195, 207], [208, 210], [211, 217], [218, 220], [221, 227], [228, 229], [230, 235], [236, 237], [238, 240], [241, 249], [250, 256], [256, 257]]}
{"doc_key": "ai-test-406", "ner": [[5, 6, "organisation"], [7, 7, "product"], [21, 21, "product"], [24, 24, "organisation"], [25, 26, "product"], [28, 28, "product"], [30, 32, "product"], [34, 34, "product"], [36, 36, "programlang"], [46, 47, "field"], [54, 54, "product"], [58, 58, "algorithm"], [60, 60, "algorithm"], [62, 62, "algorithm"], [65, 65, "product"], [70, 72, "task"], [84, 85, "algorithm"], [88, 88, "product"], [90, 90, "product"], [96, 98, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "relations": [[7, 7, 5, 6, "origin", "", false, false], [7, 7, 21, 21, "named", "same", false, false], [7, 7, 54, 54, "named", "same", false, false], [36, 36, 46, 47, "related-to", "used_for", false, false], [58, 58, 36, 36, "part-of", "", true, false], [58, 58, 54, 54, "origin", "", true, false], [60, 60, 36, 36, "part-of", "", true, false], [60, 60, 54, 54, "origin", "", true, false], [62, 62, 36, 36, "part-of", "", true, false], [62, 62, 54, 54, "origin", "", true, false], [65, 65, 70, 72, "related-to", "used_for", false, false], [84, 85, 65, 65, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Tra", "gli", "esempi", "vi", "sono", "Salford", "Systems", "CART", "(", "che", "ha", "concesso", "in", "licenza", "il", "codice", "proprietario", "degli", "autori", "originali", "di", "CART", ")", ",", "IBM", "SPSS", "Modeler", ",", "RapidMiner", ",", "SAS", "Enterprise", "Miner", ",", "Matlab", ",", "R", "(", "un", "ambiente", "software", "open", "-", "source", "per", "l'", "elaborazione", "statistica", ",", "che", "include", "diverse", "implementazioni", "di", "CART", "come", "i", "pacchetti", "rpart", ",", "party", "e", "randomForest", ")", ",", "Weka", "(", "una", "suite", "di", "data", "-", "mining", "gratuita", "e", "open", "-", "source", ",", "che", "contiene", "molti", "algoritmi", "di", "alberi", "decisionali", ")", ",", "Orange", ",", "KNIME", ",", "il", "linguaggio", "di", "programmazione", "Microsoft", "SQL", "Server", ")", "."], "sentence-detokenized": "Tra gli esempi vi sono Salford Systems CART (che ha concesso in licenza il codice proprietario degli autori originali di CART), IBM SPSS Modeler, RapidMiner, SAS Enterprise Miner, Matlab, R (un ambiente software open-source per l'elaborazione statistica, che include diverse implementazioni di CART come i pacchetti rpart, party e randomForest), Weka (una suite di data-mining gratuita e open-source, che contiene molti algoritmi di alberi decisionali), Orange, KNIME, il linguaggio di programmazione Microsoft SQL Server).", "token2charspan": [[0, 3], [4, 7], [8, 14], [15, 17], [18, 22], [23, 30], [31, 38], [39, 43], [44, 45], [45, 48], [49, 51], [52, 60], [61, 63], [64, 71], [72, 74], [75, 81], [82, 94], [95, 100], [101, 107], [108, 117], [118, 120], [121, 125], [125, 126], [126, 127], [128, 131], [132, 136], [137, 144], [144, 145], [146, 156], [156, 157], [158, 161], [162, 172], [173, 178], [178, 179], [180, 186], [186, 187], [188, 189], [190, 191], [191, 193], [194, 202], [203, 211], [212, 216], [216, 217], [217, 223], [224, 227], [228, 230], [230, 242], [243, 253], [253, 254], [255, 258], [259, 266], [267, 274], [275, 290], [291, 293], [294, 298], [299, 303], [304, 305], [306, 315], [316, 321], [321, 322], [323, 328], [329, 330], [331, 343], [343, 344], [344, 345], [346, 350], [351, 352], [352, 355], [356, 361], [362, 364], [365, 369], [369, 370], [370, 376], [377, 385], [386, 387], [388, 392], [392, 393], [393, 399], [399, 400], [401, 404], [405, 413], [414, 419], [420, 429], [430, 432], [433, 439], [440, 451], [451, 452], [452, 453], [454, 460], [460, 461], [462, 467], [467, 468], [469, 471], [472, 482], [483, 485], [486, 500], [501, 510], [511, 514], [515, 521], [521, 522], [522, 523]]}
{"doc_key": "ai-test-407", "ner": [[0, 3, "algorithm"], [5, 5, "algorithm"], [15, 16, "researcher"], [18, 20, "university"], [23, 24, "researcher"], [26, 29, "organisation"], [31, 31, "organisation"], [43, 45, "researcher"], [47, 50, "researcher"], [53, 54, "organisation"], [70, 74, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 3, 15, 16, "origin", "", false, false], [0, 3, 23, 24, "origin", "", false, false], [0, 3, 43, 45, "origin", "", false, false], [0, 3, 47, 50, "origin", "", false, false], [5, 5, 0, 3, "named", "", false, false], [15, 16, 18, 20, "physical", "", false, false], [15, 16, 18, 20, "role", "", false, false], [23, 24, 26, 29, "physical", "", false, false], [23, 24, 26, 29, "role", "", false, false], [31, 31, 26, 29, "named", "", false, false], [43, 45, 53, 54, "physical", "", false, false], [43, 45, 53, 54, "role", "", false, false], [47, 50, 53, 54, "physical", "", false, false], [47, 50, 53, 54, "role", "", false, false], [70, 74, 0, 3, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["La", "codifica", "predittiva", "lineare", "(", "LPC", ")", "\u00e8", "stata", "sviluppata", "per", "la", "prima", "volta", "da", "Fumitada", "Itakura", "dell'", "Universit\u00e0", "di", "Nagoya", "e", "da", "Shuzo", "Saito", "della", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "nel", "1966", ",", "ed", "\u00e8", "stata", "poi", "ulteriormente", "sviluppata", "da", "Bishnu", "S.", "Atal", "e", "Manfred", "R", ".", "Schroeder", "presso", "i", "Bell", "Labs", "all'", "inizio", "e", "alla", "met\u00e0", "degli", "anni", "'70", ",", "diventando", "la", "base", "per", "i", "primi", "chip", "DSP", "di", "sintesi", "vocale", "alla", "fine", "degli", "anni", "'70", "."], "sentence-detokenized": "La codifica predittiva lineare (LPC) \u00e8 stata sviluppata per la prima volta da Fumitada Itakura dell'Universit\u00e0 di Nagoya e da Shuzo Saito della Nippon Telegraph and Telephone (NTT) nel 1966, ed \u00e8 stata poi ulteriormente sviluppata da Bishnu S. Atal e Manfred R. Schroeder presso i Bell Labs all'inizio e alla met\u00e0 degli anni '70, diventando la base per i primi chip DSP di sintesi vocale alla fine degli anni '70.", "token2charspan": [[0, 2], [3, 11], [12, 22], [23, 30], [31, 32], [32, 35], [35, 36], [37, 38], [39, 44], [45, 55], [56, 59], [60, 62], [63, 68], [69, 74], [75, 77], [78, 86], [87, 94], [95, 100], [100, 110], [111, 113], [114, 120], [121, 122], [123, 125], [126, 131], [132, 137], [138, 143], [144, 150], [151, 160], [161, 164], [165, 174], [175, 176], [176, 179], [179, 180], [181, 184], [185, 189], [189, 190], [191, 193], [194, 195], [196, 201], [202, 205], [206, 219], [220, 230], [231, 233], [234, 240], [241, 243], [244, 248], [249, 250], [251, 258], [259, 260], [260, 261], [262, 271], [272, 278], [279, 280], [281, 285], [286, 290], [291, 295], [295, 301], [302, 303], [304, 308], [309, 313], [314, 319], [320, 324], [325, 328], [328, 329], [330, 340], [341, 343], [344, 348], [349, 352], [353, 354], [355, 360], [361, 365], [366, 369], [370, 372], [373, 380], [381, 387], [388, 392], [393, 397], [398, 403], [404, 408], [409, 412], [412, 413]]}
{"doc_key": "ai-test-408", "ner": [[0, 2, "metrics"], [7, 7, "metrics"], [9, 9, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 0, 2, "part-of", "", false, false], [9, 9, 0, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Il", "punteggio", "F", "\u00e8", "una", "combinazione", "di", "precisione", "e", "richiamo", ",", "che", "fornisce", "un", "unico", "punteggio", "."], "sentence-detokenized": "Il punteggio F \u00e8 una combinazione di precisione e richiamo, che fornisce un unico punteggio.", "token2charspan": [[0, 2], [3, 12], [13, 14], [15, 16], [17, 20], [21, 33], [34, 36], [37, 47], [48, 49], [50, 58], [58, 59], [60, 63], [64, 72], [73, 75], [76, 81], [82, 91], [91, 92]]}
{"doc_key": "ai-test-409", "ner": [[0, 3, "field"], [9, 14, "task"], [18, 21, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 14, 0, 3, "part-of", "task_part_of_field", false, false], [18, 21, 0, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["L'", "analisi", "delle", "immagini", "pu\u00f2", "essere", "semplice", "come", "la", "lettura", "di", "codici", "a", "barre", "o", "sofisticata", "come", "un", "sistema", "di", "riconoscimento", "facciale", "."], "sentence-detokenized": "L'analisi delle immagini pu\u00f2 essere semplice come la lettura di codici a barre o sofisticata come un sistema di riconoscimento facciale.", "token2charspan": [[0, 2], [2, 9], [10, 15], [16, 24], [25, 28], [29, 35], [36, 44], [45, 49], [50, 52], [53, 60], [61, 63], [64, 70], [71, 72], [73, 78], [79, 80], [81, 92], [93, 97], [98, 100], [101, 108], [109, 111], [112, 126], [127, 135], [135, 136]]}
{"doc_key": "ai-test-410", "ner": [[4, 8, "algorithm"], [31, 32, "algorithm"], [40, 43, "algorithm"], [48, 48, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[40, 43, 31, 32, "type-of", "", false, false], [48, 48, 40, 43, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Il", "caso", "speciale", "delle", "macchine", "a", "vettore", "di", "supporto", "lineare", "pu\u00f2", "essere", "risolto", "in", "modo", "pi\u00f9", "efficiente", "con", "lo", "stesso", "tipo", "di", "algoritmi", "che", "ottimizzano", "la", "sua", "cugina", "stretta", ",", "la", "regressione", "logistica", ";", "questa", "classe", "di", "algoritmi", "comprende", "la", "discesa", "del", "gradiente", "stocastica", "(", "ad", "esempio", ",", "PEGASOS", ")", "."], "sentence-detokenized": "Il caso speciale delle macchine a vettore di supporto lineare pu\u00f2 essere risolto in modo pi\u00f9 efficiente con lo stesso tipo di algoritmi che ottimizzano la sua cugina stretta, la regressione logistica; questa classe di algoritmi comprende la discesa del gradiente stocastica (ad esempio, PEGASOS).", "token2charspan": [[0, 2], [3, 7], [8, 16], [17, 22], [23, 31], [32, 33], [34, 41], [42, 44], [45, 53], [54, 61], [62, 65], [66, 72], [73, 80], [81, 83], [84, 88], [89, 92], [93, 103], [104, 107], [108, 110], [111, 117], [118, 122], [123, 125], [126, 135], [136, 139], [140, 151], [152, 154], [155, 158], [159, 165], [166, 173], [173, 174], [175, 177], [178, 189], [190, 199], [199, 200], [201, 207], [208, 214], [215, 217], [218, 227], [228, 237], [238, 240], [241, 248], [249, 252], [253, 262], [263, 273], [274, 275], [275, 277], [278, 285], [285, 286], [287, 294], [294, 295], [295, 296]]}
{"doc_key": "ai-test-411", "ner": [[2, 2, "product"], [6, 6, "product"], [21, 21, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 6, 6, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Quando", "a", "Siri", "su", "un", "dispositivo", "iOS", "viene", "chiesto", "Hai", "un", "animale", "domestico", "?", ",", "una", "delle", "risposte", "\u00e8", "Avevo", "un", "AIBO", "."], "sentence-detokenized": "Quando a Siri su un dispositivo iOS viene chiesto Hai un animale domestico?, una delle risposte \u00e8 Avevo un AIBO.", "token2charspan": [[0, 6], [7, 8], [9, 13], [14, 16], [17, 19], [20, 31], [32, 35], [36, 41], [42, 49], [50, 53], [54, 56], [57, 64], [65, 74], [74, 75], [75, 76], [77, 80], [81, 86], [87, 95], [96, 97], [98, 103], [104, 106], [107, 111], [111, 112]]}
{"doc_key": "ai-test-412", "ner": [[1, 3, "task"], [6, 8, "metrics"], [11, 11, "metrics"], [15, 15, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 8, 1, 3, "part-of", "", false, false], [11, 11, 6, 8, "named", "", false, false], [15, 15, 1, 3, "part-of", "", false, false], [18, 18, 15, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Nel", "recupero", "delle", "informazioni", ",", "il", "valore", "predittivo", "positivo", "\u00e8", "chiamato", "precisione", ",", "mentre", "la", "sensibilit\u00e0", "\u00e8", "chiamata", "richiamo", "."], "sentence-detokenized": "Nel recupero delle informazioni, il valore predittivo positivo \u00e8 chiamato precisione, mentre la sensibilit\u00e0 \u00e8 chiamata richiamo.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 31], [31, 32], [33, 35], [36, 42], [43, 53], [54, 62], [63, 64], [65, 73], [74, 84], [84, 85], [86, 92], [93, 95], [96, 107], [108, 109], [110, 118], [119, 127], [127, 128]]}
{"doc_key": "ai-test-413", "ner": [[13, 14, "field"], [16, 16, "task"], [18, 18, "task"], [20, 22, "task"], [39, 41, "task"], [44, 45, "task"], [48, 53, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[16, 16, 13, 14, "part-of", "task_part_of_field", false, false], [18, 18, 13, 14, "part-of", "task_part_of_field", false, false], [20, 22, 13, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "particolare", ",", "la", "sua", "ricerca", "si", "\u00e8", "concentrata", "su", "aree", "come", "il", "text", "mining", "(", "estrazione", ",", "categorizzazione", ",", "rilevamento", "di", "novit\u00e0", ")", "e", "su", "nuovi", "quadri", "teorici", "come", "una", "teoria", "unificata", "basata", "sull'", "utilit\u00e0", "che", "collega", "il", "reperimento", "di", "informazioni", ",", "la", "sintesi", "automatica", ",", "la", "risposta", "a", "domande", "a", "testo", "libero", "e", "compiti", "correlati", "."], "sentence-detokenized": "In particolare, la sua ricerca si \u00e8 concentrata su aree come il text mining (estrazione, categorizzazione, rilevamento di novit\u00e0) e su nuovi quadri teorici come una teoria unificata basata sull'utilit\u00e0 che collega il reperimento di informazioni, la sintesi automatica, la risposta a domande a testo libero e compiti correlati.", "token2charspan": [[0, 2], [3, 14], [14, 15], [16, 18], [19, 22], [23, 30], [31, 33], [34, 35], [36, 47], [48, 50], [51, 55], [56, 60], [61, 63], [64, 68], [69, 75], [76, 77], [77, 87], [87, 88], [89, 105], [105, 106], [107, 118], [119, 121], [122, 128], [128, 129], [130, 131], [132, 134], [135, 140], [141, 147], [148, 155], [156, 160], [161, 164], [165, 171], [172, 181], [182, 188], [189, 194], [194, 201], [202, 205], [206, 213], [214, 216], [217, 228], [229, 231], [232, 244], [244, 245], [246, 248], [249, 256], [257, 267], [267, 268], [269, 271], [272, 280], [281, 282], [283, 290], [291, 292], [293, 298], [299, 305], [306, 307], [308, 315], [316, 325], [325, 326]]}
{"doc_key": "ai-test-414", "ner": [[0, 2, "product"], [6, 7, "product"], [14, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 0, 2, "part-of", "", false, false], [14, 20, 0, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["I", "robot", "Delta", "sono", "dotati", "di", "attuatori", "rotanti", "montati", "alla", "base", "che", "muovono", "un", "braccio", "leggero", ",", "rigido", "e", "a", "parallelogramma", "."], "sentence-detokenized": "I robot Delta sono dotati di attuatori rotanti montati alla base che muovono un braccio leggero, rigido e a parallelogramma.", "token2charspan": [[0, 1], [2, 7], [8, 13], [14, 18], [19, 25], [26, 28], [29, 38], [39, 46], [47, 54], [55, 59], [60, 64], [65, 68], [69, 76], [77, 79], [80, 87], [88, 95], [95, 96], [97, 103], [104, 105], [106, 107], [108, 123], [123, 124]]}
{"doc_key": "ai-test-415", "ner": [[8, 13, "metrics"], [15, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["I", "quattro", "risultati", "possono", "essere", "formulati", "in", "una", "tabella", "di", "contingenza", "2", "\u00d7", "2", "o", "matrice", "di", "confusione", ",", "come", "segue", ":"], "sentence-detokenized": "I quattro risultati possono essere formulati in una tabella di contingenza 2 \u00d7 2 o matrice di confusione, come segue:", "token2charspan": [[0, 1], [2, 9], [10, 19], [20, 27], [28, 34], [35, 44], [45, 47], [48, 51], [52, 59], [60, 62], [63, 74], [75, 76], [77, 78], [79, 80], [81, 82], [83, 90], [91, 93], [94, 104], [104, 105], [106, 110], [111, 116], [116, 117]]}
{"doc_key": "ai-test-416", "ner": [[3, 4, "field"], [33, 35, "task"], [41, 43, "task"], [48, 50, "task"], [52, 54, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[33, 35, 3, 4, "part-of", "task_part_of_field", false, false], [41, 43, 3, 4, "part-of", "task_part_of_field", false, false], [48, 50, 3, 4, "part-of", "task_part_of_field", false, false], [52, 54, 3, 4, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["L'", "attivit\u00e0", "di", "data", "mining", "vera", "e", "propria", "consiste", "nell'", "analisi", "semiautomatica", "o", "automatica", "di", "grandi", "quantit\u00e0", "di", "dati", "per", "estrarre", "modelli", "sconosciuti", "e", "interessanti", ",", "come", "gruppi", "di", "record", "di", "dati", "(", "analisi", "dei", "cluster", ")", ",", "record", "insoliti", "(", "rilevamento", "di", "anomalie", ")", "e", "dipendenze", "(", "association", "rule", "mining", ",", "sequential", "pattern", "mining", ")", "."], "sentence-detokenized": "L'attivit\u00e0 di data mining vera e propria consiste nell'analisi semiautomatica o automatica di grandi quantit\u00e0 di dati per estrarre modelli sconosciuti e interessanti, come gruppi di record di dati (analisi dei cluster), record insoliti (rilevamento di anomalie) e dipendenze (association rule mining, sequential pattern mining).", "token2charspan": [[0, 2], [2, 10], [11, 13], [14, 18], [19, 25], [26, 30], [31, 32], [33, 40], [41, 49], [50, 55], [55, 62], [63, 77], [78, 79], [80, 90], [91, 93], [94, 100], [101, 109], [110, 112], [113, 117], [118, 121], [122, 130], [131, 138], [139, 150], [151, 152], [153, 165], [165, 166], [167, 171], [172, 178], [179, 181], [182, 188], [189, 191], [192, 196], [197, 198], [198, 205], [206, 209], [210, 217], [217, 218], [218, 219], [220, 226], [227, 235], [236, 237], [237, 248], [249, 251], [252, 260], [260, 261], [262, 263], [264, 274], [275, 276], [276, 287], [288, 292], [293, 299], [299, 300], [301, 311], [312, 319], [320, 326], [326, 327], [327, 328]]}
{"doc_key": "ai-test-417", "ner": [[2, 4, "product"], [7, 8, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 4, 7, 8, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Per", "un", "sistema", "di", "raccomandazione", ",", "la", "sentiment", "analysis", "si", "\u00e8", "dimostrata", "una", "tecnica", "preziosa", "."], "sentence-detokenized": "Per un sistema di raccomandazione, la sentiment analysis si \u00e8 dimostrata una tecnica preziosa.", "token2charspan": [[0, 3], [4, 6], [7, 14], [15, 17], [18, 33], [33, 34], [35, 37], [38, 47], [48, 56], [57, 59], [60, 61], [62, 72], [73, 76], [77, 84], [85, 93], [93, 94]]}
{"doc_key": "ai-test-418", "ner": [[4, 4, "misc"], [15, 15, "product"], [31, 32, "organisation"], [34, 35, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 15, 15, "usage", "", false, false], [31, 32, 34, 35, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Per", "caso", ",", "i", "tedeschi", "avevano", "scelto", "molto", "male", "la", "frequenza", "di", "funzionamento", "del", "sistema", "Wotan", ",", "che", "operava", "a", "45", "MHz", ",", "la", "frequenza", "del", "potente", "ma", "inattivo", "trasmettitore", "televisivo", "della", "BBC", "ad", "Alexandra", "Palace", "."], "sentence-detokenized": "Per caso, i tedeschi avevano scelto molto male la frequenza di funzionamento del sistema Wotan, che operava a 45 MHz, la frequenza del potente ma inattivo trasmettitore televisivo della BBC ad Alexandra Palace.", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 11], [12, 20], [21, 28], [29, 35], [36, 41], [42, 46], [47, 49], [50, 59], [60, 62], [63, 76], [77, 80], [81, 88], [89, 94], [94, 95], [96, 99], [100, 107], [108, 109], [110, 112], [113, 116], [116, 117], [118, 120], [121, 130], [131, 134], [135, 142], [143, 145], [146, 154], [155, 168], [169, 179], [180, 185], [186, 189], [190, 192], [193, 202], [203, 209], [209, 210]]}
{"doc_key": "ai-test-419", "ner": [[8, 13, "metrics"], [15, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["I", "quattro", "risultati", "possono", "essere", "formulati", "in", "una", "tabella", "di", "contingenza", "2", "\u00d7", "2", "o", "matrice", "di", "confusione", ",", "come", "segue", ":"], "sentence-detokenized": "I quattro risultati possono essere formulati in una tabella di contingenza 2 \u00d7 2 o matrice di confusione, come segue:", "token2charspan": [[0, 1], [2, 9], [10, 19], [20, 27], [28, 34], [35, 44], [45, 47], [48, 51], [52, 59], [60, 62], [63, 74], [75, 76], [77, 78], [79, 80], [81, 82], [83, 90], [91, 93], [94, 104], [104, 105], [106, 110], [111, 116], [116, 117]]}
{"doc_key": "ai-test-420", "ner": [[1, 4, "misc"], [11, 11, "misc"], [14, 14, "product"], [16, 16, "product"], [18, 20, "product"], [30, 30, "misc"], [46, 48, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[14, 14, 11, 11, "usage", "", false, false], [16, 16, 11, 11, "usage", "", false, false], [18, 20, 16, 16, "named", "", false, false], [30, 30, 11, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Nelle", "applicazioni", "del", "Web", "semantico", "e", "in", "quelle", "relativamente", "popolari", "di", "RDF", ",", "come", "RSS", "e", "FOAF", "(", "Friend", "a", "Friend", ")", ",", "le", "risorse", "tendono", "a", "essere", "rappresentate", "da", "URI", "che", "denotano", "intenzionalmente", ",", "e", "possono", "essere", "utilizzati", "per", "accedere", ",", "a", "dati", "reali", "sul", "World", "Wide", "Web", "."], "sentence-detokenized": "Nelle applicazioni del Web semantico e in quelle relativamente popolari di RDF, come RSS e FOAF (Friend a Friend), le risorse tendono a essere rappresentate da URI che denotano intenzionalmente, e possono essere utilizzati per accedere, a dati reali sul World Wide Web.", "token2charspan": [[0, 5], [6, 18], [19, 22], [23, 26], [27, 36], [37, 38], [39, 41], [42, 48], [49, 62], [63, 71], [72, 74], [75, 78], [78, 79], [80, 84], [85, 88], [89, 90], [91, 95], [96, 97], [97, 103], [104, 105], [106, 112], [112, 113], [113, 114], [115, 117], [118, 125], [126, 133], [134, 135], [136, 142], [143, 156], [157, 159], [160, 163], [164, 167], [168, 176], [177, 193], [193, 194], [195, 196], [197, 204], [205, 211], [212, 222], [223, 226], [227, 235], [235, 236], [237, 238], [239, 243], [244, 249], [250, 253], [254, 259], [260, 264], [265, 268], [268, 269]]}
{"doc_key": "ai-test-421", "ner": [[1, 7, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["L'", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "ha", "studiato", "a", "fondo", "questo", "argomento", "."], "sentence-detokenized": "L'Association for the Advancement of Artificial Intelligence ha studiato a fondo questo argomento.", "token2charspan": [[0, 2], [2, 13], [14, 17], [18, 21], [22, 33], [34, 36], [37, 47], [48, 60], [61, 63], [64, 72], [73, 74], [75, 80], [81, 87], [88, 97], [97, 98]]}
{"doc_key": "ai-test-422", "ner": [[6, 10, "product"], [20, 20, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 20, 6, 10, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Partito", "come", "una", "curiosit\u00e0", ",", "il", "sistema", "vocale", "di", "Apple", "Macintosh", "si", "\u00e8", "evoluto", "in", "un", "programma", "completamente", "supportato", ",", "PlainTalk", ",", "per", "le", "persone", "con", "problemi", "di", "vista", "."], "sentence-detokenized": "Partito come una curiosit\u00e0, il sistema vocale di Apple Macintosh si \u00e8 evoluto in un programma completamente supportato, PlainTalk, per le persone con problemi di vista.", "token2charspan": [[0, 7], [8, 12], [13, 16], [17, 26], [26, 27], [28, 30], [31, 38], [39, 45], [46, 48], [49, 54], [55, 64], [65, 67], [68, 69], [70, 77], [78, 80], [81, 83], [84, 93], [94, 107], [108, 118], [118, 119], [120, 129], [129, 130], [131, 134], [135, 137], [138, 145], [146, 149], [150, 158], [159, 161], [162, 167], [167, 168]]}
{"doc_key": "ai-test-423", "ner": [[9, 9, "field"], [12, 14, "task"], [17, 19, "task"], [22, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 14, 9, 9, "part-of", "task_part_of_field", false, false], [17, 19, 9, 9, "part-of", "task_part_of_field", false, false], [22, 23, 9, 9, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Altre", "aree", "di", "utilizzo", "delle", "ontologie", "nell'", "ambito", "della", "PNL", "sono", "il", "reperimento", "di", "informazioni", ",", "l'", "estrazione", "di", "informazioni", "e", "la", "sintesi", "automatica", "."], "sentence-detokenized": "Altre aree di utilizzo delle ontologie nell'ambito della PNL sono il reperimento di informazioni, l'estrazione di informazioni e la sintesi automatica.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 22], [23, 28], [29, 38], [39, 44], [44, 50], [51, 56], [57, 60], [61, 65], [66, 68], [69, 80], [81, 83], [84, 96], [96, 97], [98, 100], [100, 110], [111, 113], [114, 126], [127, 128], [129, 131], [132, 139], [140, 150], [150, 151]]}
{"doc_key": "ai-test-424", "ner": [[7, 14, "organisation"], [18, 22, "organisation"], [26, 29, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["L'", "Istituto", "ha", "collaborato", "strettamente", "con", "il", "Janelia", "Farm", "Campus", "dell'", "Howard", "Hughes", "Medical", "Institute", ",", "con", "l'", "Allen", "Institute", "for", "Brain", "Science", "e", "con", "i", "National", "Institutes", "of", "Health", "per", "sviluppare", "metodi", "migliori", "di", "ricostruzione", "delle", "architetture", "neuronali", "."], "sentence-detokenized": "L'Istituto ha collaborato strettamente con il Janelia Farm Campus dell'Howard Hughes Medical Institute, con l'Allen Institute for Brain Science e con i National Institutes of Health per sviluppare metodi migliori di ricostruzione delle architetture neuronali.", "token2charspan": [[0, 2], [2, 10], [11, 13], [14, 25], [26, 38], [39, 42], [43, 45], [46, 53], [54, 58], [59, 65], [66, 71], [71, 77], [78, 84], [85, 92], [93, 102], [102, 103], [104, 107], [108, 110], [110, 115], [116, 125], [126, 129], [130, 135], [136, 143], [144, 145], [146, 149], [150, 151], [152, 160], [161, 171], [172, 174], [175, 181], [182, 185], [186, 196], [197, 203], [204, 212], [213, 215], [216, 229], [230, 235], [236, 248], [249, 258], [258, 259]]}
{"doc_key": "ai-test-425", "ner": [[2, 3, "organisation"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 2, 3, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Recentemente", ",", "Google", "ha", "annunciato", "che", "Google", "Translate", "traduce", "una", "quantit\u00e0", "di", "testo", "sufficiente", "a", "riempire", "1", "milione", "di", "libri", "in", "un", "giorno", "(", "2012", ")", "."], "sentence-detokenized": "Recentemente, Google ha annunciato che Google Translate traduce una quantit\u00e0 di testo sufficiente a riempire 1 milione di libri in un giorno (2012).", "token2charspan": [[0, 12], [12, 13], [14, 20], [21, 23], [24, 34], [35, 38], [39, 45], [46, 55], [56, 63], [64, 67], [68, 76], [77, 79], [80, 85], [86, 97], [98, 99], [100, 108], [109, 110], [111, 118], [119, 121], [122, 127], [128, 130], [131, 133], [134, 140], [141, 142], [142, 146], [146, 147], [147, 148]]}
{"doc_key": "ai-test-426", "ner": [[13, 14, "country"], [17, 18, "country"], [21, 21, "country"], [23, 24, "country"], [27, 27, "country"], [30, 32, "country"], [44, 45, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Gli", "eventi", "si", "tengono", "in", "tutto", "il", "mondo", "e", "sono", "pi\u00f9", "popolari", "nel", "Regno", "Unito", ",", "negli", "Stati", "Uniti", ",", "in", "Giappone", ",", "a", "Singapore", ",", "in", "India", ",", "nella", "Corea", "del", "Sud", "e", "stanno", "diventando", "popolari", "anche", "nei", "Paesi", "del", "subcontinente", "come", "lo", "Sri", "Lanka", "."], "sentence-detokenized": "Gli eventi si tengono in tutto il mondo e sono pi\u00f9 popolari nel Regno Unito, negli Stati Uniti, in Giappone, a Singapore, in India, nella Corea del Sud e stanno diventando popolari anche nei Paesi del subcontinente come lo Sri Lanka.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 21], [22, 24], [25, 30], [31, 33], [34, 39], [40, 41], [42, 46], [47, 50], [51, 59], [60, 63], [64, 69], [70, 75], [75, 76], [77, 82], [83, 88], [89, 94], [94, 95], [96, 98], [99, 107], [107, 108], [109, 110], [111, 120], [120, 121], [122, 124], [125, 130], [130, 131], [132, 137], [138, 143], [144, 147], [148, 151], [152, 153], [154, 160], [161, 171], [172, 180], [181, 186], [187, 190], [191, 196], [197, 200], [201, 214], [215, 219], [220, 222], [223, 226], [227, 232], [232, 233]]}
{"doc_key": "ai-test-427", "ner": [[6, 6, "programlang"], [10, 10, "programlang"], [12, 12, "programlang"], [14, 14, "programlang"], [16, 16, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Questi", "pacchetti", "sono", "sviluppati", "principalmente", "in", "R", "e", "talvolta", "in", "Java", ",", "C", ",", "C+", "e", "Fortran", "."], "sentence-detokenized": "Questi pacchetti sono sviluppati principalmente in R e talvolta in Java, C, C+ e Fortran.", "token2charspan": [[0, 6], [7, 16], [17, 21], [22, 32], [33, 47], [48, 50], [51, 52], [53, 54], [55, 63], [64, 66], [67, 71], [71, 72], [73, 74], [74, 75], [76, 78], [79, 80], [81, 88], [88, 89]]}
{"doc_key": "ai-test-428", "ner": [[3, 12, "conference"], [9, 9, "conference"], [14, 14, "researcher"], [16, 16, "researcher"], [20, 21, "researcher"], [24, 26, "algorithm"], [30, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 9, 3, 12, "named", "", false, false], [14, 14, 3, 12, "physical", "", false, false], [14, 14, 3, 12, "role", "", false, false], [14, 14, 20, 21, "role", "teams_up_with", false, false], [14, 14, 24, 26, "usage", "", false, false], [16, 16, 3, 12, "physical", "", false, false], [16, 16, 3, 12, "role", "", false, false], [16, 16, 20, 21, "role", "teams_up_with", false, false], [16, 16, 24, 26, "usage", "", false, false], [20, 21, 3, 12, "physical", "", false, false], [20, 21, 3, 12, "role", "", false, false], [20, 21, 24, 26, "usage", "", false, false], [24, 26, 30, 35, "related-to", "used_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Nell'", "ambito", "della", "European", "Conference", "on", "Computer", "Vision", "(", "ECCV", ")", "del", "2006", ",", "Dalal", "e", "Triggs", "hanno", "collaborato", "con", "Cordelia", "Schmid", "per", "applicare", "i", "rilevatori", "HOG", "al", "problema", "del", "rilevamento", "umano", "in", "film", "e", "video", "."], "sentence-detokenized": "Nell'ambito della European Conference on Computer Vision (ECCV) del 2006, Dalal e Triggs hanno collaborato con Cordelia Schmid per applicare i rilevatori HOG al problema del rilevamento umano in film e video.", "token2charspan": [[0, 5], [5, 11], [12, 17], [18, 26], [27, 37], [38, 40], [41, 49], [50, 56], [57, 58], [58, 62], [62, 63], [64, 67], [68, 72], [72, 73], [74, 79], [80, 81], [82, 88], [89, 94], [95, 106], [107, 110], [111, 119], [120, 126], [127, 130], [131, 140], [141, 142], [143, 153], [154, 157], [158, 160], [161, 169], [170, 173], [174, 185], [186, 191], [192, 194], [195, 199], [200, 201], [202, 207], [207, 208]]}
{"doc_key": "ai-test-429", "ner": [[2, 2, "metrics"], [5, 5, "metrics"], [13, 14, "task"], [20, 22, "metrics"], [24, 24, "metrics"], [30, 30, "metrics"], [34, 36, "metrics"], [38, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[2, 2, 13, 14, "related-to", "measured_with", false, false], [5, 5, 13, 14, "related-to", "measured_with", false, false], [20, 22, 13, 14, "related-to", "measured_with", false, false], [24, 24, 20, 22, "named", "", false, false], [30, 30, 20, 22, "named", "", false, false], [38, 38, 34, 36, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Oltre", "alla", "sensibilit\u00e0", "e", "alla", "specificit\u00e0", ",", "le", "prestazioni", "di", "un", "test", "di", "classificazione", "binaria", "possono", "essere", "misurate", "con", "il", "valore", "predittivo", "positivo", "(", "PPV", ")", ",", "noto", "anche", "come", "precisione", ",", "e", "il", "valore", "predittivo", "negativo", "(", "NPV", ")", "."], "sentence-detokenized": "Oltre alla sensibilit\u00e0 e alla specificit\u00e0, le prestazioni di un test di classificazione binaria possono essere misurate con il valore predittivo positivo (PPV), noto anche come precisione, e il valore predittivo negativo (NPV).", "token2charspan": [[0, 5], [6, 10], [11, 22], [23, 24], [25, 29], [30, 41], [41, 42], [43, 45], [46, 57], [58, 60], [61, 63], [64, 68], [69, 71], [72, 87], [88, 95], [96, 103], [104, 110], [111, 119], [120, 123], [124, 126], [127, 133], [134, 144], [145, 153], [154, 155], [155, 158], [158, 159], [159, 160], [161, 165], [166, 171], [172, 176], [177, 187], [187, 188], [189, 190], [191, 193], [194, 200], [201, 211], [212, 220], [221, 222], [222, 225], [225, 226], [226, 227]]}
{"doc_key": "ai-test-430", "ner": [[15, 19, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Tali", "modelli", "possono", "attribuire", "un", "credito", "parziale", "alle", "corrispondenze", "sovrapposte", "(", "ad", "esempio", "utilizzando", "il", "criterio", "dell'", "indice", "di", "Jaccard", ")", "."], "sentence-detokenized": "Tali modelli possono attribuire un credito parziale alle corrispondenze sovrapposte (ad esempio utilizzando il criterio dell'indice di Jaccard).", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 31], [32, 34], [35, 42], [43, 51], [52, 56], [57, 71], [72, 83], [84, 85], [85, 87], [88, 95], [96, 107], [108, 110], [111, 119], [120, 125], [125, 131], [132, 134], [135, 142], [142, 143], [143, 144]]}
{"doc_key": "ai-test-431", "ner": [[23, 31, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Inoltre", ",", "nel", "caso", "di", "stime", "basate", "su", "un", "singolo", "campione", ",", "dimostra", "le", "questioni", "filosofiche", "e", "i", "possibili", "fraintendimenti", "nell'", "uso", "degli", "stimatori", "di", "massima", "verosimiglianza", "e", "delle", "funzioni", "di", "verosimiglianza", "."], "sentence-detokenized": "Inoltre, nel caso di stime basate su un singolo campione, dimostra le questioni filosofiche e i possibili fraintendimenti nell'uso degli stimatori di massima verosimiglianza e delle funzioni di verosimiglianza.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 17], [18, 20], [21, 26], [27, 33], [34, 36], [37, 39], [40, 47], [48, 56], [56, 57], [58, 66], [67, 69], [70, 79], [80, 91], [92, 93], [94, 95], [96, 105], [106, 121], [122, 127], [127, 130], [131, 136], [137, 146], [147, 149], [150, 157], [158, 173], [174, 175], [176, 181], [182, 190], [191, 193], [194, 209], [209, 210]]}
