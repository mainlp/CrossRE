{"doc_key": "ai-train-1", "ner": [[5, 10, "product"], [18, 19, "field"], [22, 23, "task"], [26, 27, "task"], [31, 33, "task"], [37, 38, "field"], [39, 40, "researcher"], [42, 43, "researcher"], [45, 46, "researcher"], [48, 49, "researcher"], [51, 53, "researcher"], [55, 56, "researcher"], [58, 59, "researcher"], [61, 62, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[5, 10, 18, 19, "part-of", "", false, false], [5, 10, 18, 19, "usage", "", false, false], [5, 10, 22, 23, "part-of", "", false, false], [5, 10, 22, 23, "usage", "", false, false], [5, 10, 26, 27, "part-of", "", false, false], [5, 10, 26, 27, "usage", "", false, false], [5, 10, 37, 38, "part-of", "", false, false], [5, 10, 37, 38, "usage", "", false, false], [31, 33, 26, 27, "part-of", "", false, false], [31, 33, 26, 27, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Gli", "approcci", "pi\u00f9", "diffusi", "ai", "sistemi", "di", "raccomandazione", "basati", "sulle", "opinioni", "utilizzano", "varie", "tecniche", ",", "tra", "cui", "il", "text", "mining", ",", "l'", "information", "retrieval", ",", "la", "sentiment", "analysis", "(", "vedi", "anche", "Multimodal", "sentiment", "analysis", ")", "e", "il", "deep", "learning", "X.Y.", "Feng", ",", "H.", "Zhang", ",", "Y.J.", "Ren", ",", "P.H.", "Shang", ",", "Y", ".", "Zhu", ",", "Y.C.", "Liang", ",", "R.C.", "Guan", ",", "D.", "Xu", ",", "(", "2019", ")", ",", "21", "(", "5", ")", ":", "e12957", "."], "sentence-detokenized": "Gli approcci pi\u00f9 diffusi ai sistemi di raccomandazione basati sulle opinioni utilizzano varie tecniche, tra cui il text mining, l'information retrieval, la sentiment analysis (vedi anche Multimodal sentiment analysis) e il deep learning X.Y. Feng, H. Zhang, Y.J. Ren, P.H. Shang, Y. Zhu, Y.C. Liang, R.C. Guan, D. Xu, (2019), 21 (5): e12957.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 24], [25, 27], [28, 35], [36, 38], [39, 54], [55, 61], [62, 67], [68, 76], [77, 87], [88, 93], [94, 102], [102, 103], [104, 107], [108, 111], [112, 114], [115, 119], [120, 126], [126, 127], [128, 130], [130, 141], [142, 151], [151, 152], [153, 155], [156, 165], [166, 174], [175, 176], [176, 180], [181, 186], [187, 197], [198, 207], [208, 216], [216, 217], [218, 219], [220, 222], [223, 227], [228, 236], [237, 241], [242, 246], [246, 247], [248, 250], [251, 256], [256, 257], [258, 262], [263, 266], [266, 267], [268, 272], [273, 278], [278, 279], [280, 281], [281, 282], [283, 286], [286, 287], [288, 292], [293, 298], [298, 299], [300, 304], [305, 309], [309, 310], [311, 313], [314, 316], [316, 317], [318, 319], [319, 323], [323, 324], [324, 325], [326, 328], [329, 330], [330, 331], [331, 332], [332, 333], [334, 340], [340, 341]]}
{"doc_key": "ai-train-2", "ner": [[10, 10, "university"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 17, 10, 10, "physical", "", false, false], [16, 17, 10, 10, "role", "", false, false], [19, 20, 10, 10, "physical", "", false, false], [19, 20, 10, 10, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["I", "sostenitori", "delle", "rappresentazioni", "procedurali", "si", "sono", "concentrati", "soprattutto", "al", "MIT", ",", "sotto", "la", "guida", "di", "Marvin", "Minsky", "e", "Seymour", "Papert."], "sentence-detokenized": "I sostenitori delle rappresentazioni procedurali si sono concentrati soprattutto al MIT, sotto la guida di Marvin Minsky e Seymour Papert.", "token2charspan": [[0, 1], [2, 13], [14, 19], [20, 36], [37, 48], [49, 51], [52, 56], [57, 68], [69, 80], [81, 83], [84, 87], [87, 88], [89, 94], [95, 97], [98, 103], [104, 106], [107, 113], [114, 120], [121, 122], [123, 130], [131, 138]]}
{"doc_key": "ai-train-3", "ner": [[11, 11, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["L'", "interfaccia", "standard", "e", "l'", "interfaccia", "della", "calcolatrice", "sono", "scritte", "in", "Java", "."], "sentence-detokenized": "L'interfaccia standard e l'interfaccia della calcolatrice sono scritte in Java.", "token2charspan": [[0, 2], [2, 13], [14, 22], [23, 24], [25, 27], [27, 38], [39, 44], [45, 57], [58, 62], [63, 70], [71, 73], [74, 78], [78, 79]]}
{"doc_key": "ai-train-4", "ner": [[0, 0, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 24, 24, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["Octave", "aiuta", "a", "risolvere", "numericamente", "problemi", "lineari", "e", "non", "lineari", "e", "a", "eseguire", "altri", "esperimenti", "numerici", "utilizzando", "un", "programma", "per", "lo", "pi\u00f9", "compatibile", "con", "MATLAB."], "sentence-detokenized": "Octave aiuta a risolvere numericamente problemi lineari e non lineari e a eseguire altri esperimenti numerici utilizzando un programma per lo pi\u00f9 compatibile con MATLAB.", "token2charspan": [[0, 6], [7, 12], [13, 14], [15, 24], [25, 38], [39, 47], [48, 55], [56, 57], [58, 61], [62, 69], [70, 71], [72, 73], [74, 82], [83, 88], [89, 100], [101, 109], [110, 121], [122, 124], [125, 134], [135, 138], [139, 141], [142, 145], [146, 157], [158, 161], [162, 169]]}
{"doc_key": "ai-train-5", "ner": [[2, 6, "algorithm"], [9, 11, "misc"], [13, 14, "researcher"], [18, 20, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 6, 13, 14, "origin", "", false, false], [9, 11, 13, 14, "origin", "", false, false], [13, 14, 18, 20, "physical", "", false, false], [13, 14, 18, 20, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Varianti", "dell'", "algoritmo", "di", "back", "-", "propagation", "e", "i", "metodi", "non", "supervisionati", "di", "Geoff", "Hinton", "e", "colleghi", "dell'", "Universit\u00e0", "di", "Toronto", "possono", "essere", "utilizzati", "per", "addestrare", "architetture", "neurali", "profonde", "e", "altamente", "non", "lineari", ",", "{", "{", "cite", "journal"], "sentence-detokenized": "Varianti dell'algoritmo di back-propagation e i metodi non supervisionati di Geoff Hinton e colleghi dell'Universit\u00e0 di Toronto possono essere utilizzati per addestrare architetture neurali profonde e altamente non lineari, {{cite journal", "token2charspan": [[0, 8], [9, 14], [14, 23], [24, 26], [27, 31], [31, 32], [32, 43], [44, 45], [46, 47], [48, 54], [55, 58], [59, 73], [74, 76], [77, 82], [83, 89], [90, 91], [92, 100], [101, 106], [106, 116], [117, 119], [120, 127], [128, 135], [136, 142], [143, 153], [154, 157], [158, 168], [169, 181], [182, 189], [190, 198], [199, 200], [201, 210], [211, 214], [215, 222], [222, 223], [224, 225], [225, 226], [226, 230], [231, 238]]}
{"doc_key": "ai-train-6", "ner": [[5, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["o", "equivalentemente", "utilizzando", "la", "notazione", "DCG", ":"], "sentence-detokenized": "o equivalentemente utilizzando la notazione DCG:", "token2charspan": [[0, 1], [2, 18], [19, 30], [31, 33], [34, 43], [44, 47], [47, 48]]}
{"doc_key": "ai-train-7", "ner": [[0, 5, "algorithm"], [9, 11, "algorithm"], [16, 17, "algorithm"], [21, 25, "algorithm"], [28, 28, "algorithm"], [30, 32, "algorithm"], [46, 48, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 5, 9, 11, "type-of", "", false, false], [0, 5, 16, 17, "usage", "part-of?", true, false], [16, 17, 21, 25, "compare", "", false, false], [28, 28, 21, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Le", "mappe", "auto", "-", "organizzanti", "si", "differenziano", "dalle", "altre", "reti", "neurali", "artificiali", "in", "quanto", "applicano", "l'", "apprendimento", "competitivo", "in", "contrapposizione", "all'", "apprendimento", "a", "correzione", "d'", "errore", "come", "la", "retropropagazione", "con", "discesa", "del", "gradiente", ")", "e", "nel", "senso", "che", "utilizzano", "una", "funzione", "di", "vicinato", "per", "preservare", "le", "propriet\u00e0", "topologiche", "dello", "spazio", "di", "input."], "sentence-detokenized": "Le mappe auto-organizzanti si differenziano dalle altre reti neurali artificiali in quanto applicano l'apprendimento competitivo in contrapposizione all'apprendimento a correzione d'errore come la retropropagazione con discesa del gradiente) e nel senso che utilizzano una funzione di vicinato per preservare le propriet\u00e0 topologiche dello spazio di input.", "token2charspan": [[0, 2], [3, 8], [9, 13], [13, 14], [14, 26], [27, 29], [30, 43], [44, 49], [50, 55], [56, 60], [61, 68], [69, 80], [81, 83], [84, 90], [91, 100], [101, 103], [103, 116], [117, 128], [129, 131], [132, 148], [149, 153], [153, 166], [167, 168], [169, 179], [180, 182], [182, 188], [189, 193], [194, 196], [197, 214], [215, 218], [219, 226], [227, 230], [231, 240], [240, 241], [242, 243], [244, 247], [248, 253], [254, 257], [258, 268], [269, 272], [273, 281], [282, 284], [285, 293], [294, 297], [298, 308], [309, 311], [312, 321], [322, 333], [334, 339], [340, 346], [347, 349], [350, 356]]}
{"doc_key": "ai-train-8", "ner": [[12, 14, "organisation"], [26, 27, "misc"], [35, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Dall'", "inizio", "degli", "anni", "'90", ",", "diverse", "autorit\u00e0", ",", "tra", "cui", "l'", "Audio", "Engineering", "Society", ",", "raccomandano", "di", "effettuare", "le", "misurazioni", "della", "gamma", "dinamica", "con", "un", "segnale", "audio", "presente", ",", "che", "viene", "poi", "filtrato", "nella", "misura", "del", "rumore", "di", "fondo", "utilizzata", "per", "determinare", "la", "gamma", "dinamica", ".", "In", "questo", "modo", "si", "evitano", "misurazioni", "discutibili", "basate", "sull'", "uso", "di", "supporti", "vuoti", "o", "di", "circuiti", "di", "muting", "."], "sentence-detokenized": "Dall'inizio degli anni '90, diverse autorit\u00e0, tra cui l'Audio Engineering Society, raccomandano di effettuare le misurazioni della gamma dinamica con un segnale audio presente, che viene poi filtrato nella misura del rumore di fondo utilizzata per determinare la gamma dinamica. In questo modo si evitano misurazioni discutibili basate sull'uso di supporti vuoti o di circuiti di muting.", "token2charspan": [[0, 5], [5, 11], [12, 17], [18, 22], [23, 26], [26, 27], [28, 35], [36, 44], [44, 45], [46, 49], [50, 53], [54, 56], [56, 61], [62, 73], [74, 81], [81, 82], [83, 95], [96, 98], [99, 109], [110, 112], [113, 124], [125, 130], [131, 136], [137, 145], [146, 149], [150, 152], [153, 160], [161, 166], [167, 175], [175, 176], [177, 180], [181, 186], [187, 190], [191, 199], [200, 205], [206, 212], [213, 216], [217, 223], [224, 226], [227, 232], [233, 243], [244, 247], [248, 259], [260, 262], [263, 268], [269, 277], [277, 278], [279, 281], [282, 288], [289, 293], [294, 296], [297, 304], [305, 316], [317, 328], [329, 335], [336, 341], [341, 344], [345, 347], [348, 356], [357, 362], [363, 364], [365, 367], [368, 376], [377, 379], [380, 386], [386, 387]]}
{"doc_key": "ai-train-9", "ner": [[6, 6, "misc"], [19, 20, "task"], [22, 24, "task"], [26, 28, "task"], [30, 31, "task"], [34, 37, "task"], [33, 42, "task"], [44, 47, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[6, 6, 19, 20, "part-of", "concept_used_in", true, false], [6, 6, 22, 24, "part-of", "concept_used_in", false, false], [6, 6, 26, 28, "part-of", "concept_used_in", false, false], [6, 6, 30, 31, "part-of", "concept_used_in", false, false], [6, 6, 34, 37, "part-of", "concept_used_in", false, false], [6, 6, 33, 42, "part-of", "concept_used_in", false, false], [6, 6, 44, 47, "part-of", "concept_used_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["La", "tecnica", "utilizzata", "per", "creare", "gli", "autofatti", "e", "utilizzarli", "per", "il", "riconoscimento", "viene", "utilizzata", "anche", "al", "di", "fuori", "del", "riconoscimento", "facciale", ":", "riconoscimento", "della", "scrittura", ",", "lettura", "delle", "labbra", ",", "riconoscimento", "vocale", ",", "interpretazione", "del", "linguaggio", "dei", "segni", "e", "dei", "gesti", "delle", "mani", "e", "analisi", "delle", "immagini", "mediche", "."], "sentence-detokenized": "La tecnica utilizzata per creare gli autofatti e utilizzarli per il riconoscimento viene utilizzata anche al di fuori del riconoscimento facciale: riconoscimento della scrittura, lettura delle labbra, riconoscimento vocale, interpretazione del linguaggio dei segni e dei gesti delle mani e analisi delle immagini mediche.", "token2charspan": [[0, 2], [3, 10], [11, 21], [22, 25], [26, 32], [33, 36], [37, 46], [47, 48], [49, 60], [61, 64], [65, 67], [68, 82], [83, 88], [89, 99], [100, 105], [106, 108], [109, 111], [112, 117], [118, 121], [122, 136], [137, 145], [145, 146], [147, 161], [162, 167], [168, 177], [177, 178], [179, 186], [187, 192], [193, 199], [199, 200], [201, 215], [216, 222], [222, 223], [224, 239], [240, 243], [244, 254], [255, 258], [259, 264], [265, 266], [267, 270], [271, 276], [277, 282], [283, 287], [288, 289], [290, 297], [298, 303], [304, 312], [313, 320], [320, 321]]}
{"doc_key": "ai-train-10", "ner": [[1, 3, "organisation"], [10, 14, "organisation"], [16, 16, "organisation"], [20, 25, "organisation"], [28, 34, "organisation"], [37, 42, "organisation"], [45, 49, "organisation"], [51, 51, "organisation"], [55, 58, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[10, 14, 1, 3, "part-of", "", false, false], [16, 16, 10, 14, "named", "", false, false], [20, 25, 1, 3, "part-of", "", false, false], [28, 34, 1, 3, "part-of", "", false, false], [37, 42, 1, 3, "part-of", "", false, false], [45, 49, 1, 3, "part-of", "", false, false], [51, 51, 45, 49, "named", "", false, false], [55, 58, 1, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["La", "National", "Science", "Foundation", "\u00e8", "stata", "un", "ombrello", "per", "la", "National", "Aeronautics", "and", "Space", "Administration", "(", "NASA", ")", ",", "il", "Dipartimento", "dell'", "Energia", "degli", "Stati", "Uniti", ",", "il", "Dipartimento", "del", "Commercio", "degli", "Stati", "Uniti", "NIST", ",", "il", "Dipartimento", "della", "Difesa", "degli", "Stati", "Uniti", ",", "la", "Defense", "Advanced", "Research", "Projects", "Agency", "(", "DARPA", ")", "e", "l'", "Office", "of", "Naval", "Research", "hanno", "coordinato", "gli", "studi", "per", "informare", "i", "pianificatori", "strategici", "nelle", "loro", "deliberazioni", "."], "sentence-detokenized": "La National Science Foundation \u00e8 stata un ombrello per la National Aeronautics and Space Administration (NASA), il Dipartimento dell'Energia degli Stati Uniti, il Dipartimento del Commercio degli Stati Uniti NIST, il Dipartimento della Difesa degli Stati Uniti, la Defense Advanced Research Projects Agency (DARPA) e l'Office of Naval Research hanno coordinato gli studi per informare i pianificatori strategici nelle loro deliberazioni.", "token2charspan": [[0, 2], [3, 11], [12, 19], [20, 30], [31, 32], [33, 38], [39, 41], [42, 50], [51, 54], [55, 57], [58, 66], [67, 78], [79, 82], [83, 88], [89, 103], [104, 105], [105, 109], [109, 110], [110, 111], [112, 114], [115, 127], [128, 133], [133, 140], [141, 146], [147, 152], [153, 158], [158, 159], [160, 162], [163, 175], [176, 179], [180, 189], [190, 195], [196, 201], [202, 207], [208, 212], [212, 213], [214, 216], [217, 229], [230, 235], [236, 242], [243, 248], [249, 254], [255, 260], [260, 261], [262, 264], [265, 272], [273, 281], [282, 290], [291, 299], [300, 306], [307, 308], [308, 313], [313, 314], [315, 316], [317, 319], [319, 325], [326, 328], [329, 334], [335, 343], [344, 349], [350, 360], [361, 364], [365, 370], [371, 374], [375, 384], [385, 386], [387, 400], [401, 411], [412, 417], [418, 422], [423, 436], [436, 437]]}
{"doc_key": "ai-train-11", "ner": [[8, 9, "metrics"], [12, 13, "algorithm"], [18, 19, "researcher"], [25, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 12, 13, "part-of", "", false, false], [18, 19, 25, 25, "related-to", "added_appendix_to_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Un", "metodo", "rapido", "per", "calcolare", "le", "stime", "di", "massima", "verosimiglianza", "per", "il", "modello", "probit", "\u00e8", "stato", "proposto", "da", "Ronald", "Fisher", "come", "appendice", "al", "lavoro", "di", "Bliss", "nel", "1935", "."], "sentence-detokenized": "Un metodo rapido per calcolare le stime di massima verosimiglianza per il modello probit \u00e8 stato proposto da Ronald Fisher come appendice al lavoro di Bliss nel 1935.", "token2charspan": [[0, 2], [3, 9], [10, 16], [17, 20], [21, 30], [31, 33], [34, 39], [40, 42], [43, 50], [51, 66], [67, 70], [71, 73], [74, 81], [82, 88], [89, 90], [91, 96], [97, 105], [106, 108], [109, 115], [116, 122], [123, 127], [128, 137], [138, 140], [141, 147], [148, 150], [151, 156], [157, 160], [161, 165], [165, 166]]}
{"doc_key": "ai-train-12", "ner": [[9, 10, "product"], [13, 14, "product"], [19, 19, "organisation"], [17, 17, "product"], [24, 24, "organisation"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[17, 17, 13, 14, "usage", "uses_software", false, false], [17, 17, 19, 19, "artifact", "", false, false], [17, 17, 22, 22, "named", "", false, false], [22, 22, 24, 24, "artifact", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Molti", "di", "questi", "programmi", "sono", "disponibili", "online", ",", "come", "Google", "Translate", "e", "il", "sistema", "SYSTRAN", "che", "alimenta", "BabelFish", "di", "AltaVista", "(", "ora", "Babelfish", "di", "Yahoo", "dal", "9", "maggio", "2008", ")", "."], "sentence-detokenized": "Molti di questi programmi sono disponibili online, come Google Translate e il sistema SYSTRAN che alimenta BabelFish di AltaVista (ora Babelfish di Yahoo dal 9 maggio 2008).", "token2charspan": [[0, 5], [6, 8], [9, 15], [16, 25], [26, 30], [31, 42], [43, 49], [49, 50], [51, 55], [56, 62], [63, 72], [73, 74], [75, 77], [78, 85], [86, 93], [94, 97], [98, 106], [107, 116], [117, 119], [120, 129], [130, 131], [131, 134], [135, 144], [145, 147], [148, 153], [154, 157], [158, 159], [160, 166], [167, 171], [171, 172], [172, 173]]}
{"doc_key": "ai-train-13", "ner": [[2, 2, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [20, 22, "field"], [25, 26, "misc"], [30, 32, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 20, 22, "related-to", "", true, false], [2, 2, 25, 26, "related-to", "", true, false], [2, 2, 30, 32, "related-to", "", true, false], [6, 7, 20, 22, "related-to", "", true, false], [6, 7, 25, 26, "related-to", "", true, false], [6, 7, 30, 32, "related-to", "", true, false], [9, 10, 20, 22, "related-to", "", true, false], [9, 10, 25, 26, "related-to", "", true, false], [9, 10, 30, 32, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Nel", "2002", "Hutter", ",", "insieme", "a", "J\u00fcrgen", "Schmidhuber", "e", "Shane", "Legg", ",", "ha", "sviluppato", "e", "pubblicato", "una", "teoria", "matematica", "dell'", "intelligenza", "artificiale", "generale", "basata", "su", "agenti", "intelligenti", "idealizzati", "e", "sull'", "apprendimento", "per", "rinforzo", "motivato", "dalla", "ricompensa", "."], "sentence-detokenized": "Nel 2002 Hutter, insieme a J\u00fcrgen Schmidhuber e Shane Legg, ha sviluppato e pubblicato una teoria matematica dell'intelligenza artificiale generale basata su agenti intelligenti idealizzati e sull'apprendimento per rinforzo motivato dalla ricompensa.", "token2charspan": [[0, 3], [4, 8], [9, 15], [15, 16], [17, 24], [25, 26], [27, 33], [34, 45], [46, 47], [48, 53], [54, 58], [58, 59], [60, 62], [63, 73], [74, 75], [76, 86], [87, 90], [91, 97], [98, 108], [109, 114], [114, 126], [127, 138], [139, 147], [148, 154], [155, 157], [158, 164], [165, 177], [178, 189], [190, 191], [192, 197], [197, 210], [211, 214], [215, 223], [224, 232], [233, 238], [239, 249], [249, 250]]}
{"doc_key": "ai-train-14", "ner": [[11, 11, "metrics"], [13, 19, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 11, 13, 19, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Il", "modo", "pi\u00f9", "comune", "\u00e8", "quello", "di", "utilizzare", "la", "cosiddetta", "misura", "ROUGE", "(", "Recall", "-", "Oriented", "Understudy", "for", "Gisting", "Evaluation", ")", "."], "sentence-detokenized": "Il modo pi\u00f9 comune \u00e8 quello di utilizzare la cosiddetta misura ROUGE (Recall-Oriented Understudy for Gisting Evaluation).", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 18], [19, 20], [21, 27], [28, 30], [31, 41], [42, 44], [45, 55], [56, 62], [63, 68], [69, 70], [70, 76], [76, 77], [77, 85], [86, 96], [97, 100], [101, 108], [109, 119], [119, 120], [120, 121]]}
{"doc_key": "ai-train-15", "ner": [[0, 0, "product"], [15, 15, "programlang"], [17, 17, "programlang"], [18, 19, "researcher"], [21, 22, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 15, 15, "related-to", "", false, false], [0, 0, 17, 17, "related-to", "", false, false], [18, 19, 21, 22, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["RapidMiner", "fornisce", "schemi", "di", "apprendimento", ",", "modelli", "e", "algoritmi", "e", "pu\u00f2", "essere", "esteso", "utilizzando", "script", "R", "e", "Python.", "David", "Norris", ",", "Bloor", "Research", ",", "13", "novembre", "2013", "."], "sentence-detokenized": "RapidMiner fornisce schemi di apprendimento, modelli e algoritmi e pu\u00f2 essere esteso utilizzando script R e Python. David Norris, Bloor Research, 13 novembre 2013.", "token2charspan": [[0, 10], [11, 19], [20, 26], [27, 29], [30, 43], [43, 44], [45, 52], [53, 54], [55, 64], [65, 66], [67, 70], [71, 77], [78, 84], [85, 96], [97, 103], [104, 105], [106, 107], [108, 115], [116, 121], [122, 128], [128, 129], [130, 135], [136, 144], [144, 145], [146, 148], [149, 157], [158, 162], [162, 163]]}
{"doc_key": "ai-train-16", "ner": [[8, 8, "programlang"], [10, 11, "product"]], "ner_mapping_to_source": [4, 5], "relations": [[10, 11, 8, 8, "general-affiliation", "", true, false]], "relations_mapping_to_source": [4], "sentence": ["La", "versione", "pi\u00f9", "recente", ",", "completamente", "basata", "su", "Java", "(", "Weka", "3", ")", ",", "il", "cui", "sviluppo", "\u00e8", "iniziato", "nel", "1997", ",", "\u00e8", "oggi", "utilizzata", "in", "molti", "ambiti", "applicativi", "diversi", ",", "in", "particolare", "per", "scopi", "didattici", "e", "di", "ricerca", "."], "sentence-detokenized": "La versione pi\u00f9 recente, completamente basata su Java (Weka 3), il cui sviluppo \u00e8 iniziato nel 1997, \u00e8 oggi utilizzata in molti ambiti applicativi diversi, in particolare per scopi didattici e di ricerca.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 23], [23, 24], [25, 38], [39, 45], [46, 48], [49, 53], [54, 55], [55, 59], [60, 61], [61, 62], [62, 63], [64, 66], [67, 70], [71, 79], [80, 81], [82, 90], [91, 94], [95, 99], [99, 100], [101, 102], [103, 107], [108, 118], [119, 121], [122, 127], [128, 134], [135, 146], [147, 154], [154, 155], [156, 158], [159, 170], [171, 174], [175, 180], [181, 190], [191, 192], [193, 195], [196, 203], [203, 204]]}
{"doc_key": "ai-train-17", "ner": [[0, 1, "product"], [16, 23, "misc"], [27, 29, "misc"], [31, 39, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 23, 0, 1, "topic", "", false, false], [16, 23, 27, 29, "win-defeat", "", false, false], [27, 29, 31, 39, "temporal", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Eurisko", "ha", "fatto", "molte", "scoperte", "interessanti", "e", "ha", "riscosso", "un", "notevole", "successo", ":", "il", "suo", "articolo", "Heuretics", ":", "Theoretical", "and", "Study", "of", "Heuristic", "Rules", "ha", "vinto", "il", "premio", "Best", "Paper", "all'", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "del", "1982", "."], "sentence-detokenized": "Eurisko ha fatto molte scoperte interessanti e ha riscosso un notevole successo: il suo articolo Heuretics: Theoretical and Study of Heuristic Rules ha vinto il premio Best Paper all'Association for the Advancement of Artificial Intelligence del 1982.", "token2charspan": [[0, 7], [8, 10], [11, 16], [17, 22], [23, 31], [32, 44], [45, 46], [47, 49], [50, 58], [59, 61], [62, 70], [71, 79], [79, 80], [81, 83], [84, 87], [88, 96], [97, 106], [106, 107], [108, 119], [120, 123], [124, 129], [130, 132], [133, 142], [143, 148], [149, 151], [152, 157], [158, 160], [161, 167], [168, 172], [173, 178], [179, 183], [183, 194], [195, 198], [199, 202], [203, 214], [215, 217], [218, 228], [229, 241], [242, 245], [246, 250], [250, 251]]}
{"doc_key": "ai-train-18", "ner": [[13, 15, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Per", "tenere", "conto", "di", "pi\u00f9", "entit\u00e0", ",", "per", "ogni", "capsula", "viene", "calcolata", "una", "perdita", "di", "cerniera", "separata", "."], "sentence-detokenized": "Per tenere conto di pi\u00f9 entit\u00e0, per ogni capsula viene calcolata una perdita di cerniera separata.", "token2charspan": [[0, 3], [4, 10], [11, 16], [17, 19], [20, 23], [24, 30], [30, 31], [32, 35], [36, 40], [41, 48], [49, 54], [55, 64], [65, 68], [69, 76], [77, 79], [80, 88], [89, 97], [97, 98]]}
{"doc_key": "ai-train-19", "ner": [[7, 9, "product"], [11, 13, "product"], [15, 16, "product"], [18, 20, "product"], [22, 24, "product"], [27, 28, "product"], [36, 40, "product"], [42, 43, "product"], [45, 46, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[7, 9, 27, 28, "type-of", "", false, false], [11, 13, 27, 28, "type-of", "", false, false], [15, 16, 27, 28, "type-of", "", false, false], [18, 20, 27, 28, "type-of", "", false, false], [22, 24, 27, 28, "type-of", "", false, false], [42, 43, 36, 40, "type-of", "", false, false], [45, 46, 36, 40, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Con", "l'", "emergere", "di", "assistenti", "conversazionali", "come", "Siri", "di", "Apple", ",", "Alexa", "di", "Amazon", ",", "Google", "Assistant", ",", "Cortana", "di", "Microsoft", "e", "Bixby", "di", "Samsung", ",", "i", "portali", "vocali", "sono", "ora", "accessibili", "attraverso", "dispositivi", "mobili", "e", "smart", "speaker", "vocali", "Far", "Field", "come", "Amazon", "Echo", "e", "Google", "Home", "."], "sentence-detokenized": "Con l'emergere di assistenti conversazionali come Siri di Apple, Alexa di Amazon, Google Assistant, Cortana di Microsoft e Bixby di Samsung, i portali vocali sono ora accessibili attraverso dispositivi mobili e smart speaker vocali Far Field come Amazon Echo e Google Home.", "token2charspan": [[0, 3], [4, 6], [6, 14], [15, 17], [18, 28], [29, 44], [45, 49], [50, 54], [55, 57], [58, 63], [63, 64], [65, 70], [71, 73], [74, 80], [80, 81], [82, 88], [89, 98], [98, 99], [100, 107], [108, 110], [111, 120], [121, 122], [123, 128], [129, 131], [132, 139], [139, 140], [141, 142], [143, 150], [151, 157], [158, 162], [163, 166], [167, 178], [179, 189], [190, 201], [202, 208], [209, 210], [211, 216], [217, 224], [225, 231], [232, 235], [236, 241], [242, 246], [247, 253], [254, 258], [259, 260], [261, 267], [268, 272], [272, 273]]}
{"doc_key": "ai-train-20", "ner": [[2, 3, "field"], [6, 9, "algorithm"], [12, 14, "algorithm"], [17, 19, "algorithm"], [22, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 9, 2, 3, "type-of", "", false, false], [12, 14, 2, 3, "type-of", "", false, false], [17, 19, 2, 3, "type-of", "", false, false], [22, 22, 2, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Esempi", "di", "apprendimento", "supervisionato", "sono", "il", "classificatore", "di", "Naive", "Bayes", ",", "la", "Support", "vector", "machine", ",", "le", "miscele", "di", "Gaussiane", "e", "la", "rete", "."], "sentence-detokenized": "Esempi di apprendimento supervisionato sono il classificatore di Naive Bayes, la Support vector machine, le miscele di Gaussiane e la rete.", "token2charspan": [[0, 6], [7, 9], [10, 23], [24, 38], [39, 43], [44, 46], [47, 61], [62, 64], [65, 70], [71, 76], [76, 77], [78, 80], [81, 88], [89, 95], [96, 103], [103, 104], [105, 107], [108, 115], [116, 118], [119, 128], [129, 130], [131, 133], [134, 138], [138, 139]]}
{"doc_key": "ai-train-21", "ner": [[4, 5, "algorithm"], [27, 30, "algorithm"], [33, 33, "task"], [38, 40, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 27, 30, "part-of", "", true, false], [38, 40, 33, 33, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Si", "pu\u00f2", "utilizzare", "l'", "algoritmo", "OSD", "per", "ricavare", "limiti", "di", "rimpianto", "matematici", "O", "(", "\\", "sqrt", "{", "T", "}", ")", "/", "matematici", "per", "la", "versione", "online", "della", "macchina", "vettoriale", "di", "supporto", "per", "la", "classificazione", ",", "che", "utilizza", "la", "perdita", "di", "cerniera", "matematico", "v", "_t", "(", "w", ")", "=", "\\", "max", "\\", "{", "0", ",", "1", "-", "y", "_t", "(", "w", "cdot", "x", "_t", ")", "\\", "}", "/", "matematica"], "sentence-detokenized": "Si pu\u00f2 utilizzare l'algoritmo OSD per ricavare limiti di rimpianto matematici O (\\ sqrt {T}) / matematici per la versione online della macchina vettoriale di supporto per la classificazione, che utilizza la perdita di cerniera matematico v _t (w) =\\ max\\ {0, 1 - y _t (w cdot x _t)\\} / matematica", "token2charspan": [[0, 2], [3, 6], [7, 17], [18, 20], [20, 29], [30, 33], [34, 37], [38, 46], [47, 53], [54, 56], [57, 66], [67, 77], [78, 79], [80, 81], [81, 82], [83, 87], [88, 89], [89, 90], [90, 91], [91, 92], [93, 94], [95, 105], [106, 109], [110, 112], [113, 121], [122, 128], [129, 134], [135, 143], [144, 154], [155, 157], [158, 166], [167, 170], [171, 173], [174, 189], [189, 190], [191, 194], [195, 203], [204, 206], [207, 214], [215, 217], [218, 226], [227, 237], [238, 239], [240, 242], [243, 244], [244, 245], [245, 246], [247, 248], [248, 249], [250, 253], [253, 254], [255, 256], [256, 257], [257, 258], [259, 260], [261, 262], [263, 264], [265, 267], [268, 269], [269, 270], [271, 275], [276, 277], [278, 280], [280, 281], [281, 282], [282, 283], [284, 285], [286, 296]]}
{"doc_key": "ai-train-22", "ner": [[4, 6, "task"], [9, 13, "task"], [12, 12, "task"], [16, 18, "task"], [21, 22, "task"], [25, 27, "task"], [30, 32, "task"], [35, 39, "task"], [42, 44, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Le", "applicazioni", "includono", "il", "riconoscimento", "di", "oggetti", ",", "la", "mappatura", "e", "la", "navigazione", "robotica", ",", "lo", "stitching", "di", "immagini", ",", "la", "modellazione", "3D", ",", "il", "riconoscimento", "di", "gesti", ",", "il", "tracciamento", "di", "video", ",", "l'", "identificazione", "individuale", "di", "animali", "selvatici", "e", "lo", "spostamento", "di", "partite", "."], "sentence-detokenized": "Le applicazioni includono il riconoscimento di oggetti, la mappatura e la navigazione robotica, lo stitching di immagini, la modellazione 3D, il riconoscimento di gesti, il tracciamento di video, l'identificazione individuale di animali selvatici e lo spostamento di partite.", "token2charspan": [[0, 2], [3, 15], [16, 25], [26, 28], [29, 43], [44, 46], [47, 54], [54, 55], [56, 58], [59, 68], [69, 70], [71, 73], [74, 85], [86, 94], [94, 95], [96, 98], [99, 108], [109, 111], [112, 120], [120, 121], [122, 124], [125, 137], [138, 140], [140, 141], [142, 144], [145, 159], [160, 162], [163, 168], [168, 169], [170, 172], [173, 185], [186, 188], [189, 194], [194, 195], [196, 198], [198, 213], [214, 225], [226, 228], [229, 236], [237, 246], [247, 248], [249, 251], [252, 263], [264, 266], [267, 274], [274, 275]]}
{"doc_key": "ai-train-23", "ner": [[8, 10, "task"], [16, 17, "university"], [20, 22, "university"], [25, 27, "university"], [30, 31, "university"], [34, 40, "university"], [43, 45, "university"], [48, 51, "university"], [54, 56, "university"], [59, 65, "university"], [67, 67, "university"], [71, 75, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[8, 10, 16, 17, "related-to", "", true, false], [8, 10, 20, 22, "related-to", "", true, false], [8, 10, 25, 27, "related-to", "", true, false], [8, 10, 30, 31, "related-to", "", true, false], [8, 10, 34, 40, "related-to", "", true, false], [8, 10, 43, 45, "related-to", "", true, false], [8, 10, 48, 51, "related-to", "", true, false], [8, 10, 54, 56, "related-to", "", true, false], [8, 10, 59, 65, "related-to", "", true, false], [8, 10, 67, 67, "related-to", "", true, false], [8, 10, 71, 75, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Numerosi", "gruppi", "e", "aziende", "stanno", "conducendo", "ricerche", "sulla", "stima", "della", "posa", ",", "tra", "cui", "gruppi", "della", "Brown", "University", ",", "della", "Carnegie", "Mellon", "University", ",", "dell'", "MPI", "di", "Saarbruecken", ",", "della", "Stanford", "University", ",", "dell'", "Universit\u00e0", "della", "California", ",", "di", "San", "Diego", ",", "dell'", "Universit\u00e0", "di", "Toronto", ",", "dell'", "Ecole", "Centrale", "di", "Parigi", ",", "del", "Politecnico", "di", "Zurigo", ",", "dell'", "Universit\u00e0", "Nazionale", "delle", "Scienze", "e", "della", "Tecnologia", "(", "NUST", ")", "e", "dell'", "Universit\u00e0", "della", "California", ",", "Irvine", "."], "sentence-detokenized": "Numerosi gruppi e aziende stanno conducendo ricerche sulla stima della posa, tra cui gruppi della Brown University, della Carnegie Mellon University, dell'MPI di Saarbruecken, della Stanford University, dell'Universit\u00e0 della California, di San Diego, dell'Universit\u00e0 di Toronto, dell'Ecole Centrale di Parigi, del Politecnico di Zurigo, dell'Universit\u00e0 Nazionale delle Scienze e della Tecnologia (NUST) e dell'Universit\u00e0 della California, Irvine.", "token2charspan": [[0, 8], [9, 15], [16, 17], [18, 25], [26, 32], [33, 43], [44, 52], [53, 58], [59, 64], [65, 70], [71, 75], [75, 76], [77, 80], [81, 84], [85, 91], [92, 97], [98, 103], [104, 114], [114, 115], [116, 121], [122, 130], [131, 137], [138, 148], [148, 149], [150, 155], [155, 158], [159, 161], [162, 174], [174, 175], [176, 181], [182, 190], [191, 201], [201, 202], [203, 208], [208, 218], [219, 224], [225, 235], [235, 236], [237, 239], [240, 243], [244, 249], [249, 250], [251, 256], [256, 266], [267, 269], [270, 277], [277, 278], [279, 284], [284, 289], [290, 298], [299, 301], [302, 308], [308, 309], [310, 313], [314, 325], [326, 328], [329, 335], [335, 336], [337, 342], [342, 352], [353, 362], [363, 368], [369, 376], [377, 378], [379, 384], [385, 395], [396, 397], [397, 401], [401, 402], [403, 404], [405, 410], [410, 420], [421, 426], [427, 437], [437, 438], [439, 445], [445, 446]]}
{"doc_key": "ai-train-24", "ner": [[0, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "funzione", "sigmoide", "Cross", "entropy", "loss", "viene", "utilizzata", "per", "prevedere", "K", "valori", "di", "probabilit\u00e0", "indipendenti", "in", "matematica", "0,1", "/", "matematica", "."], "sentence-detokenized": "La funzione sigmoide Cross entropy loss viene utilizzata per prevedere K valori di probabilit\u00e0 indipendenti in matematica 0,1 / matematica.", "token2charspan": [[0, 2], [3, 11], [12, 20], [21, 26], [27, 34], [35, 39], [40, 45], [46, 56], [57, 60], [61, 70], [71, 72], [73, 79], [80, 82], [83, 94], [95, 107], [108, 110], [111, 121], [122, 125], [126, 127], [128, 138], [138, 139]]}
{"doc_key": "ai-train-25", "ner": [[10, 16, "misc"], [12, 12, "field"], [14, 14, "field"], [19, 21, "university"], [23, 24, "country"], [27, 29, "misc"], [32, 35, "university"], [37, 37, "country"], [5, 5, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[10, 16, 12, 12, "topic", "", false, false], [10, 16, 14, 14, "topic", "", false, false], [10, 16, 19, 21, "physical", "", true, false], [19, 21, 23, 24, "physical", "", false, false], [27, 29, 32, 35, "physical", "", true, false], [32, 35, 37, 37, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Prima", "di", "diventare", "professore", "a", "Cambridge", ",", "ha", "ricoperto", "la", "cattedra", "di", "matematica", "e", "informatica", "Johann", "Bernoulli", "presso", "l'", "Universit\u00e0", "di", "Groningen", "nei", "Paesi", "Bassi", "e", "la", "Toshiba", "Endowed", "Chair", "presso", "il", "Tokyo", "Institute", "of", "Technology", "in", "Giappone", "."], "sentence-detokenized": "Prima di diventare professore a Cambridge, ha ricoperto la cattedra di matematica e informatica Johann Bernoulli presso l'Universit\u00e0 di Groningen nei Paesi Bassi e la Toshiba Endowed Chair presso il Tokyo Institute of Technology in Giappone.", "token2charspan": [[0, 5], [6, 8], [9, 18], [19, 29], [30, 31], [32, 41], [41, 42], [43, 45], [46, 55], [56, 58], [59, 67], [68, 70], [71, 81], [82, 83], [84, 95], [96, 102], [103, 112], [113, 119], [120, 122], [122, 132], [133, 135], [136, 145], [146, 149], [150, 155], [156, 161], [162, 163], [164, 166], [167, 174], [175, 182], [183, 188], [189, 195], [196, 198], [199, 204], [205, 214], [215, 217], [218, 228], [229, 231], [232, 240], [240, 241]]}
{"doc_key": "ai-train-26", "ner": [[7, 9, "algorithm"], [14, 17, "algorithm"], [19, 19, "algorithm"], [24, 25, "researcher"], [27, 28, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 9, 14, 17, "usage", "", true, false], [14, 17, 24, 25, "origin", "", false, false], [14, 17, 27, 28, "origin", "", false, false], [19, 19, 14, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Un'", "altra", "tecnica", "particolarmente", "utilizzata", "per", "le", "reti", "neurali", "ricorrenti", "\u00e8", "la", "rete", "a", "memoria", "a", "breve", "termine", "(", "LSTM", ")", "del", "1997", "di", "Sepp", "Hochreiter", "e", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Un'altra tecnica particolarmente utilizzata per le reti neurali ricorrenti \u00e8 la rete a memoria a breve termine (LSTM) del 1997 di Sepp Hochreiter e J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 3], [3, 8], [9, 16], [17, 32], [33, 43], [44, 47], [48, 50], [51, 55], [56, 63], [64, 74], [75, 76], [77, 79], [80, 84], [85, 86], [87, 94], [95, 96], [97, 102], [103, 110], [111, 112], [112, 116], [116, 117], [118, 121], [122, 126], [127, 129], [130, 134], [135, 145], [146, 147], [148, 154], [155, 166], [166, 167]]}
{"doc_key": "ai-train-27", "ner": [[5, 5, "programlang"], [7, 7, "product"], [13, 13, "product"], [43, 43, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 5, 5, "general-affiliation", "", false, false], [7, 7, 13, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["L'", "inclusione", "di", "un", "interprete", "C+", "(", "CINT", "fino", "alla", "versione", "5.34", ",", "Cling", "dalla", "versione", "6", ")", "rende", "questo", "pacchetto", "molto", "versatile", ",", "in", "quanto", "pu\u00f2", "essere", "utilizzato", "in", "modalit\u00e0", "interattiva", ",", "scripted", "e", "compilata", "in", "modo", "simile", "a", "prodotti", "commerciali", "come", "MATLAB."], "sentence-detokenized": "L'inclusione di un interprete C+ (CINT fino alla versione 5.34, Cling dalla versione 6) rende questo pacchetto molto versatile, in quanto pu\u00f2 essere utilizzato in modalit\u00e0 interattiva, scripted e compilata in modo simile a prodotti commerciali come MATLAB.", "token2charspan": [[0, 2], [2, 12], [13, 15], [16, 18], [19, 29], [30, 32], [33, 34], [34, 38], [39, 43], [44, 48], [49, 57], [58, 62], [62, 63], [64, 69], [70, 75], [76, 84], [85, 86], [86, 87], [88, 93], [94, 100], [101, 110], [111, 116], [117, 126], [126, 127], [128, 130], [131, 137], [138, 141], [142, 148], [149, 159], [160, 162], [163, 171], [172, 183], [183, 184], [185, 193], [194, 195], [196, 205], [206, 208], [209, 213], [214, 220], [221, 222], [223, 231], [232, 243], [244, 248], [249, 256]]}
{"doc_key": "ai-train-28", "ner": [[0, 2, "product"], [24, 28, "field"], [31, 33, "task"], [36, 39, "task"], [42, 44, "task"], [47, 49, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 24, 28, "related-to", "", false, false], [31, 33, 24, 28, "part-of", "", false, false], [36, 39, 24, 28, "part-of", "", false, false], [42, 44, 24, 28, "part-of", "", false, false], [47, 49, 24, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Le", "interfacce", "vocali", "che", "interpretano", "e", "gestiscono", "lo", "stato", "della", "conversazione", "sono", "difficili", "da", "progettare", "a", "causa", "della", "difficolt\u00e0", "intrinseca", "di", "integrare", "compiti", "complessi", "di", "elaborazione", "del", "linguaggio", "naturale", "come", "la", "risoluzione", "di", "coreferenze", ",", "il", "riconoscimento", "di", "entit\u00e0", "nominate", ",", "il", "recupero", "di", "informazioni", "e", "la", "gestione", "del", "dialogo", "."], "sentence-detokenized": "Le interfacce vocali che interpretano e gestiscono lo stato della conversazione sono difficili da progettare a causa della difficolt\u00e0 intrinseca di integrare compiti complessi di elaborazione del linguaggio naturale come la risoluzione di coreferenze, il riconoscimento di entit\u00e0 nominate, il recupero di informazioni e la gestione del dialogo.", "token2charspan": [[0, 2], [3, 13], [14, 20], [21, 24], [25, 37], [38, 39], [40, 50], [51, 53], [54, 59], [60, 65], [66, 79], [80, 84], [85, 94], [95, 97], [98, 108], [109, 110], [111, 116], [117, 122], [123, 133], [134, 144], [145, 147], [148, 157], [158, 165], [166, 175], [176, 178], [179, 191], [192, 195], [196, 206], [207, 215], [216, 220], [221, 223], [224, 235], [236, 238], [239, 250], [250, 251], [252, 254], [255, 269], [270, 272], [273, 279], [280, 288], [288, 289], [290, 292], [293, 301], [302, 304], [305, 317], [318, 319], [320, 322], [323, 331], [332, 335], [336, 343], [343, 344]]}
{"doc_key": "ai-train-29", "ner": [[8, 10, "algorithm"], [13, 17, "algorithm"], [24, 25, "researcher"], [28, 33, "organisation"], [42, 44, "field"], [47, 48, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 10, 24, 25, "origin", "", false, false], [8, 10, 42, 44, "part-of", "", false, false], [8, 10, 47, 48, "part-of", "", false, false], [13, 17, 24, 25, "origin", "", false, false], [13, 17, 42, 44, "part-of", "", false, false], [13, 17, 47, 48, "part-of", "", false, false], [24, 25, 28, 33, "physical", "", false, false], [24, 25, 28, 33, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Tra", "il", "2009", "e", "il", "2012", ",", "le", "reti", "neurali", "ricorrenti", "e", "le", "reti", "neurali", "profonde", "a", "feedforward", "sviluppate", "dal", "gruppo", "di", "ricerca", "di", "J\u00fcrgen", "Schmidhuber", "presso", "il", "laboratorio", "svizzero", "di", "intelligenza", "artificiale", "IDSIA", "hanno", "vinto", "otto", "concorsi", "internazionali", "nel", "campo", "del", "riconoscimento", "dei", "modelli", "e", "dell'", "apprendimento", "automatico", "."], "sentence-detokenized": "Tra il 2009 e il 2012, le reti neurali ricorrenti e le reti neurali profonde a feedforward sviluppate dal gruppo di ricerca di J\u00fcrgen Schmidhuber presso il laboratorio svizzero di intelligenza artificiale IDSIA hanno vinto otto concorsi internazionali nel campo del riconoscimento dei modelli e dell'apprendimento automatico.", "token2charspan": [[0, 3], [4, 6], [7, 11], [12, 13], [14, 16], [17, 21], [21, 22], [23, 25], [26, 30], [31, 38], [39, 49], [50, 51], [52, 54], [55, 59], [60, 67], [68, 76], [77, 78], [79, 90], [91, 101], [102, 105], [106, 112], [113, 115], [116, 123], [124, 126], [127, 133], [134, 145], [146, 152], [153, 155], [156, 167], [168, 176], [177, 179], [180, 192], [193, 204], [205, 210], [211, 216], [217, 222], [223, 227], [228, 236], [237, 251], [252, 255], [256, 261], [262, 265], [266, 280], [281, 284], [285, 292], [293, 294], [295, 300], [300, 313], [314, 324], [324, 325]]}
{"doc_key": "ai-train-30", "ner": [[2, 4, "product"], [9, 10, "product"], [12, 13, "product"], [17, 18, "task"], [21, 21, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 9, 10, "usage", "", false, false], [2, 4, 12, 13, "usage", "", false, false], [2, 4, 17, 18, "usage", "", true, false], [2, 4, 21, 21, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["I", "moderni", "sistemi", "desktop", "Windows", "possono", "utilizzare", "i", "componenti", "SAPI", "4", "e", "SAPI", "5", "per", "supportare", "la", "sintesi", "vocale", "e", "il", "parlato", "."], "sentence-detokenized": "I moderni sistemi desktop Windows possono utilizzare i componenti SAPI 4 e SAPI 5 per supportare la sintesi vocale e il parlato.", "token2charspan": [[0, 1], [2, 9], [10, 17], [18, 25], [26, 33], [34, 41], [42, 52], [53, 54], [55, 65], [66, 70], [71, 72], [73, 74], [75, 79], [80, 81], [82, 85], [86, 96], [97, 99], [100, 107], [108, 114], [115, 116], [117, 119], [120, 127], [127, 128]]}
{"doc_key": "ai-train-31", "ner": [[8, 13, "misc"], [15, 15, "field"], [17, 19, "university"], [26, 29, "field"], [31, 35, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 13, 15, 15, "topic", "topic_of_award", false, false], [8, 13, 17, 19, "origin", "", true, false], [26, 29, 31, 35, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Ha", "ricevuto", "due", "lauree", "honoris", "causa", ",", "una", "S.", "V.", "della", "laurea", "ad", "honorem", "in", "Psicologia", "dall'", "Universit\u00e0", "di", "Padova", "nel", "1995", "e", "un", "dottorato", "in", "Disegno", "Industriale", "e", "Ingegneria", "dall'", "Universit\u00e0", "di", "Tecnologia", "di", "Delft."], "sentence-detokenized": "Ha ricevuto due lauree honoris causa, una S. V. della laurea ad honorem in Psicologia dall'Universit\u00e0 di Padova nel 1995 e un dottorato in Disegno Industriale e Ingegneria dall'Universit\u00e0 di Tecnologia di Delft.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 22], [23, 30], [31, 36], [36, 37], [38, 41], [42, 44], [45, 47], [48, 53], [54, 60], [61, 63], [64, 71], [72, 74], [75, 85], [86, 91], [91, 101], [102, 104], [105, 111], [112, 115], [116, 120], [121, 122], [123, 125], [126, 135], [136, 138], [139, 146], [147, 158], [159, 160], [161, 171], [172, 177], [177, 187], [188, 190], [191, 201], [202, 204], [205, 211]]}
{"doc_key": "ai-train-32", "ner": [[6, 7, "researcher"], [12, 15, "organisation"], [17, 17, "location"], [19, 19, "researcher"], [30, 31, "misc"], [45, 47, "misc"], [64, 65, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[6, 7, 12, 15, "physical", "", false, false], [6, 7, 12, 15, "role", "", false, false], [12, 15, 17, 17, "physical", "", false, false], [19, 19, 30, 31, "related-to", "works_with", true, false], [19, 19, 45, 47, "related-to", "works_with", true, false], [19, 19, 64, 65, "related-to", "works_with", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Con", "il", "collaboratore", "di", "lunga", "data", "Laurent", "Cohen", ",", "neurologo", "presso", "l'", "Ospedale", "Piti\u00e9", "-", "Salp\u00eatri\u00e8re", "di", "Parigi", ",", "Dehaene", "ha", "identificato", "anche", "pazienti", "con", "lesioni", "in", "diverse", "regioni", "del", "lobo", "parietale", "con", "alterazione", "della", "moltiplicazione", ",", "ma", "sottrazione", "conservata", "(", "associati", "a", "lesioni", "del", "lobulo", "parietale", "inferiore", ")", "e", "altri", "con", "alterazione", "della", "sottrazione", ",", "ma", "moltiplicazione", "conservata", "(", "associati", "a", "lesioni", "del", "solco", "intraparietale", ")", "."], "sentence-detokenized": "Con il collaboratore di lunga data Laurent Cohen, neurologo presso l'Ospedale Piti\u00e9-Salp\u00eatri\u00e8re di Parigi, Dehaene ha identificato anche pazienti con lesioni in diverse regioni del lobo parietale con alterazione della moltiplicazione, ma sottrazione conservata (associati a lesioni del lobulo parietale inferiore) e altri con alterazione della sottrazione, ma moltiplicazione conservata (associati a lesioni del solco intraparietale).", "token2charspan": [[0, 3], [4, 6], [7, 20], [21, 23], [24, 29], [30, 34], [35, 42], [43, 48], [48, 49], [50, 59], [60, 66], [67, 69], [69, 77], [78, 83], [83, 84], [84, 95], [96, 98], [99, 105], [105, 106], [107, 114], [115, 117], [118, 130], [131, 136], [137, 145], [146, 149], [150, 157], [158, 160], [161, 168], [169, 176], [177, 180], [181, 185], [186, 195], [196, 199], [200, 211], [212, 217], [218, 233], [233, 234], [235, 237], [238, 249], [250, 260], [261, 262], [262, 271], [272, 273], [274, 281], [282, 285], [286, 292], [293, 302], [303, 312], [312, 313], [314, 315], [316, 321], [322, 325], [326, 337], [338, 343], [344, 355], [355, 356], [357, 359], [360, 375], [376, 386], [387, 388], [388, 397], [398, 399], [400, 407], [408, 411], [412, 417], [418, 432], [432, 433], [433, 434]]}
{"doc_key": "ai-train-33", "ner": [[7, 9, "product"], [13, 16, "misc"], [18, 19, "misc"], [27, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 16, 7, 9, "topic", "", false, false], [18, 19, 7, 9, "topic", "", false, false], [27, 27, 7, 9, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Pi\u00f9", "recentemente", ",", "le", "rappresentazioni", "fittizie", "di", "robot", "artificialmente", "intelligenti", "in", "film", "come", "A.I", ".", "Intelligenza", "Artificiale", "ed", "Ex", "Machina", "e", "l'", "adattamento", "televisivo", "del", "2016", "di", "Westworld", "hanno", "suscitato", "la", "simpatia", "del", "pubblico", "per", "i", "robot", "stessi", "."], "sentence-detokenized": "Pi\u00f9 recentemente, le rappresentazioni fittizie di robot artificialmente intelligenti in film come A.I. Intelligenza Artificiale ed Ex Machina e l'adattamento televisivo del 2016 di Westworld hanno suscitato la simpatia del pubblico per i robot stessi.", "token2charspan": [[0, 3], [4, 16], [16, 17], [18, 20], [21, 37], [38, 46], [47, 49], [50, 55], [56, 71], [72, 84], [85, 87], [88, 92], [93, 97], [98, 101], [101, 102], [103, 115], [116, 127], [128, 130], [131, 133], [134, 141], [142, 143], [144, 146], [146, 157], [158, 168], [169, 172], [173, 177], [178, 180], [181, 190], [191, 196], [197, 206], [207, 209], [210, 218], [219, 222], [223, 231], [232, 235], [236, 237], [238, 243], [244, 250], [250, 251]]}
{"doc_key": "ai-train-34", "ner": [[6, 8, "field"], [11, 14, "algorithm"], [17, 19, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 14, 6, 8, "part-of", "", false, false], [17, 19, 6, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Due", "dei", "principali", "metodi", "utilizzati", "nell'", "apprendimento", "non", "supervisionato", "sono", "l'", "analisi", "delle", "componenti", "principali", "e", "l'", "analisi", "dei", "cluster", "."], "sentence-detokenized": "Due dei principali metodi utilizzati nell'apprendimento non supervisionato sono l'analisi delle componenti principali e l'analisi dei cluster.", "token2charspan": [[0, 3], [4, 7], [8, 18], [19, 25], [26, 36], [37, 42], [42, 55], [56, 59], [60, 74], [75, 79], [80, 82], [82, 89], [90, 95], [96, 106], [107, 117], [118, 119], [120, 122], [122, 129], [130, 133], [134, 141], [141, 142]]}
{"doc_key": "ai-train-35", "ner": [[1, 4, "organisation"], [25, 26, "misc"], [31, 32, "misc"], [34, 36, "person"], [41, 42, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[25, 26, 1, 4, "artifact", "", false, false], [31, 32, 1, 4, "artifact", "", false, false], [31, 32, 34, 36, "role", "director_of", false, false], [31, 32, 41, 42, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Anche", "la", "Walt", "Disney", "Company", "ha", "iniziato", "a", "utilizzare", "in", "modo", "pi\u00f9", "marcato", "i", "film", "in", "3D", "in", "luoghi", "speciali", "per", "impressionare", "il", "pubblico", ":", "Viaggi", "magici", "(", "1982", ")", "e", "Capitan", "EO", "(", "Francis", "Ford", "Coppola", ",", "1986", ",", "con", "Michael", "Jackson", ")", "ne", "sono", "esempi", "notevoli", "."], "sentence-detokenized": "Anche la Walt Disney Company ha iniziato a utilizzare in modo pi\u00f9 marcato i film in 3D in luoghi speciali per impressionare il pubblico: Viaggi magici (1982) e Capitan EO (Francis Ford Coppola, 1986, con Michael Jackson) ne sono esempi notevoli.", "token2charspan": [[0, 5], [6, 8], [9, 13], [14, 20], [21, 28], [29, 31], [32, 40], [41, 42], [43, 53], [54, 56], [57, 61], [62, 65], [66, 73], [74, 75], [76, 80], [81, 83], [84, 86], [87, 89], [90, 96], [97, 105], [106, 109], [110, 123], [124, 126], [127, 135], [135, 136], [137, 143], [144, 150], [151, 152], [152, 156], [156, 157], [158, 159], [160, 167], [168, 170], [171, 172], [172, 179], [180, 184], [185, 192], [192, 193], [194, 198], [198, 199], [200, 203], [204, 211], [212, 219], [219, 220], [221, 223], [224, 228], [229, 235], [236, 244], [244, 245]]}
{"doc_key": "ai-train-36", "ner": [[13, 16, "field"], [21, 25, "task"], [28, 29, "task"], [31, 31, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 25, 13, 16, "part-of", "", false, false], [28, 29, 13, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Dal", "2002", ",", "l'", "addestramento", "dei", "percettori", "\u00e8", "diventato", "popolare", "nel", "campo", "dell'", "elaborazione", "del", "linguaggio", "naturale", "per", "compiti", "quali", "il", "tagging", "part", "-", "of-", "speech", "e", "il", "parsing", "sintattico", "(", "Collins", ",", "2002", ")", "."], "sentence-detokenized": "Dal 2002, l'addestramento dei percettori \u00e8 diventato popolare nel campo dell'elaborazione del linguaggio naturale per compiti quali il tagging part-of-speech e il parsing sintattico (Collins, 2002).", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 12], [12, 25], [26, 29], [30, 40], [41, 42], [43, 52], [53, 61], [62, 65], [66, 71], [72, 77], [77, 89], [90, 93], [94, 104], [105, 113], [114, 117], [118, 125], [126, 131], [132, 134], [135, 142], [143, 147], [147, 148], [148, 151], [151, 157], [158, 159], [160, 162], [163, 170], [171, 181], [182, 183], [183, 190], [190, 191], [192, 196], [196, 197], [197, 198]]}
{"doc_key": "ai-train-37", "ner": [[2, 4, "product"], [11, 15, "organisation"], [17, 18, "organisation"], [20, 20, "country"], [24, 29, "product"], [34, 35, "researcher"], [45, 45, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 15, 2, 4, "role", "introduces_to_market", true, false], [17, 18, 2, 4, "role", "introduces_to_market", true, false], [17, 18, 20, 20, "physical", "", false, false], [24, 29, 45, 45, "related-to", "sold_to", true, false], [34, 35, 24, 29, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Il", "primo", "robot", "di", "pallettizzazione", "\u00e8", "stato", "introdotto", "nel", "1963", "dalla", "Fuji", "Yusoki", "Kogyo", "Company", ".", "dalla", "KUKA", "robotics", "in", "Germania", ",", "mentre", "la", "macchina", "universale", "programmabile", "per", "l'", "assemblaggio", "\u00e8", "stata", "inventata", "da", "Victor", "Scheinman", "nel", "1976", "e", "il", "progetto", "\u00e8", "stato", "venduto", "a", "Unimation", "."], "sentence-detokenized": "Il primo robot di pallettizzazione \u00e8 stato introdotto nel 1963 dalla Fuji Yusoki Kogyo Company. dalla KUKA robotics in Germania, mentre la macchina universale programmabile per l'assemblaggio \u00e8 stata inventata da Victor Scheinman nel 1976 e il progetto \u00e8 stato venduto a Unimation.", "token2charspan": [[0, 2], [3, 8], [9, 14], [15, 17], [18, 34], [35, 36], [37, 42], [43, 53], [54, 57], [58, 62], [63, 68], [69, 73], [74, 80], [81, 86], [87, 94], [94, 95], [96, 101], [102, 106], [107, 115], [116, 118], [119, 127], [127, 128], [129, 135], [136, 138], [139, 147], [148, 158], [159, 172], [173, 176], [177, 179], [179, 191], [192, 193], [194, 199], [200, 209], [210, 212], [213, 219], [220, 229], [230, 233], [234, 238], [239, 240], [241, 243], [244, 252], [253, 254], [255, 260], [261, 268], [269, 270], [271, 280], [280, 281]]}
{"doc_key": "ai-train-38", "ner": [[10, 10, "conference"], [12, 12, "researcher"], [21, 21, "field"], [36, 37, "researcher"], [44, 45, "researcher"], [57, 57, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 12, 10, 10, "role", "president_of", false, false], [12, 12, 36, 37, "role", "colleagues", false, false], [21, 21, 57, 57, "named", "same", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "met\u00e0", "degli", "anni", "Novanta", ",", "mentre", "era", "presidente", "dell'", "AAAI", ",", "Hayes", "inizi\u00f2", "una", "serie", "di", "attacchi", "ai", "critici", "dell'", "IA", ",", "per", "lo", "pi\u00f9", "formulati", "in", "chiave", "ironica", ",", "e", "(", "insieme", "al", "collega", "Kenneth", "Ford", ")", "invent\u00f2", "un", "premio", "intitolato", "a", "Simon", "Newcomb", "da", "assegnare", "all'", "argomentazione", "pi\u00f9", "ridicola", "che", "confutava", "la", "possibilit\u00e0", "dell'", "IA", "."], "sentence-detokenized": "A met\u00e0 degli anni Novanta, mentre era presidente dell'AAAI, Hayes inizi\u00f2 una serie di attacchi ai critici dell'IA, per lo pi\u00f9 formulati in chiave ironica, e (insieme al collega Kenneth Ford) invent\u00f2 un premio intitolato a Simon Newcomb da assegnare all'argomentazione pi\u00f9 ridicola che confutava la possibilit\u00e0 dell'IA.", "token2charspan": [[0, 1], [2, 6], [7, 12], [13, 17], [18, 25], [25, 26], [27, 33], [34, 37], [38, 48], [49, 54], [54, 58], [58, 59], [60, 65], [66, 72], [73, 76], [77, 82], [83, 85], [86, 94], [95, 97], [98, 105], [106, 111], [111, 113], [113, 114], [115, 118], [119, 121], [122, 125], [126, 135], [136, 138], [139, 145], [146, 153], [153, 154], [155, 156], [157, 158], [158, 165], [166, 168], [169, 176], [177, 184], [185, 189], [189, 190], [191, 198], [199, 201], [202, 208], [209, 219], [220, 221], [222, 227], [228, 235], [236, 238], [239, 248], [249, 253], [253, 267], [268, 271], [272, 280], [281, 284], [285, 294], [295, 297], [298, 309], [310, 315], [315, 317], [317, 318]]}
{"doc_key": "ai-train-39", "ner": [[14, 17, "algorithm"], [41, 42, "algorithm"], [53, 57, "algorithm"], [59, 61, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 17, 41, 42, "named", "same", false, false], [53, 57, 14, 17, "type-of", "", false, false], [59, 61, 14, 17, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Un", "valore", "ottimale", "per", "math", "\\", "alpha", "/", "math", "pu\u00f2", "essere", "trovato", "utilizzando", "un", "algoritmo", "di", "ricerca", "lineare", ",", "cio\u00e8", "la", "grandezza", "di", "math", "\\", "alpha", "/", "math", "\u00e8", "determinata", "trovando", "il", "valore", "che", "minimizza", "S", ",", "di", "solito", "utilizzando", "una", "ricerca", "lineare", "nell'", "intervallo", "math0", "\\", "alpha", "1", "/", "math", "o", "una", "ricerca", "lineare", "a", "ritroso", "come", "la", "ricerca", "lineare", "Armijo", "."], "sentence-detokenized": "Un valore ottimale per math\\ alpha / math pu\u00f2 essere trovato utilizzando un algoritmo di ricerca lineare, cio\u00e8 la grandezza di math\\ alpha / math \u00e8 determinata trovando il valore che minimizza S, di solito utilizzando una ricerca lineare nell'intervallo math0\\ alpha 1 / math o una ricerca lineare a ritroso come la ricerca lineare Armijo.", "token2charspan": [[0, 2], [3, 9], [10, 18], [19, 22], [23, 27], [27, 28], [29, 34], [35, 36], [37, 41], [42, 45], [46, 52], [53, 60], [61, 72], [73, 75], [76, 85], [86, 88], [89, 96], [97, 104], [104, 105], [106, 110], [111, 113], [114, 123], [124, 126], [127, 131], [131, 132], [133, 138], [139, 140], [141, 145], [146, 147], [148, 159], [160, 168], [169, 171], [172, 178], [179, 182], [183, 192], [193, 194], [194, 195], [196, 198], [199, 205], [206, 217], [218, 221], [222, 229], [230, 237], [238, 243], [243, 253], [254, 259], [259, 260], [261, 266], [267, 268], [269, 270], [271, 275], [276, 277], [278, 281], [282, 289], [290, 297], [298, 299], [300, 307], [308, 312], [313, 315], [316, 323], [324, 331], [332, 338], [338, 339]]}
{"doc_key": "ai-train-40", "ner": [[4, 7, "algorithm"], [9, 11, "algorithm"], [21, 22, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Discute", "le", "tecniche", "di", "ricerca", "Breadth", "-", "first", "e", "Depth", "-", "first", ",", "ma", "alla", "fine", "conclude", "che", "i", "risultati", "rappresentano", "sistemi", "esperti", "che", "incarnano", "molte", "conoscenze", "tecniche", ",", "ma", "non", "fanno", "molta", "luce", "sui", "processi", "mentali", "che", "gli", "esseri", "umani", "utilizzano", "per", "risolvere", "tali", "enigmi", "."], "sentence-detokenized": "Discute le tecniche di ricerca Breadth-first e Depth-first, ma alla fine conclude che i risultati rappresentano sistemi esperti che incarnano molte conoscenze tecniche, ma non fanno molta luce sui processi mentali che gli esseri umani utilizzano per risolvere tali enigmi.", "token2charspan": [[0, 7], [8, 10], [11, 19], [20, 22], [23, 30], [31, 38], [38, 39], [39, 44], [45, 46], [47, 52], [52, 53], [53, 58], [58, 59], [60, 62], [63, 67], [68, 72], [73, 81], [82, 85], [86, 87], [88, 97], [98, 111], [112, 119], [120, 127], [128, 131], [132, 141], [142, 147], [148, 158], [159, 167], [167, 168], [169, 171], [172, 175], [176, 181], [182, 187], [188, 192], [193, 196], [197, 205], [206, 213], [214, 217], [218, 221], [222, 228], [229, 234], [235, 245], [246, 249], [250, 259], [260, 264], [265, 271], [271, 272]]}
{"doc_key": "ai-train-41", "ner": [[0, 6, "task"], [4, 4, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Il", "riconoscimento", "e", "la", "sintesi", "vocale", "si", "occupano", "di", "come", "il", "linguaggio", "parlato", "possa", "essere", "compreso", "o", "creato", "con", "i", "computer", "."], "sentence-detokenized": "Il riconoscimento e la sintesi vocale si occupano di come il linguaggio parlato possa essere compreso o creato con i computer.", "token2charspan": [[0, 2], [3, 17], [18, 19], [20, 22], [23, 30], [31, 37], [38, 40], [41, 49], [50, 52], [53, 57], [58, 60], [61, 71], [72, 79], [80, 85], [86, 92], [93, 101], [102, 103], [104, 110], [111, 114], [115, 116], [117, 125], [125, 126]]}
{"doc_key": "ai-train-42", "ner": [[17, 18, "algorithm"], [39, 40, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Questa", "math", "\\", "theta", "^", "{", "*", "}", "/", "matematica", "\u00e8", "normalmente", "stimata", "utilizzando", "una", "procedura", "di", "massima", "verosimiglianza", "(", "math", "\\", "theta", "^", "{", "*", "}", "=", "\\", "theta", "^", "{", "ML", "}", "/", "matematica", ")", "o", "di", "massima", "positivit\u00e0", "(", "math", "\\", "theta", "^", "{", "*", "}", "=", "\\", "theta", "^", "{", "MAP", "}", "/", "matematica", ")", "."], "sentence-detokenized": "Questa math\\ theta ^ {*} / matematica \u00e8 normalmente stimata utilizzando una procedura di massima verosimiglianza (math\\ theta ^ {*} =\\ theta ^ {ML} / matematica) o di massima positivit\u00e0 (math\\ theta ^ {*} =\\ theta ^ {MAP} / matematica).", "token2charspan": [[0, 6], [7, 11], [11, 12], [13, 18], [19, 20], [21, 22], [22, 23], [23, 24], [25, 26], [27, 37], [38, 39], [40, 51], [52, 59], [60, 71], [72, 75], [76, 85], [86, 88], [89, 96], [97, 112], [113, 114], [114, 118], [118, 119], [120, 125], [126, 127], [128, 129], [129, 130], [130, 131], [132, 133], [133, 134], [135, 140], [141, 142], [143, 144], [144, 146], [146, 147], [148, 149], [150, 160], [160, 161], [162, 163], [164, 166], [167, 174], [175, 185], [186, 187], [187, 191], [191, 192], [193, 198], [199, 200], [201, 202], [202, 203], [203, 204], [205, 206], [206, 207], [208, 213], [214, 215], [216, 217], [217, 220], [220, 221], [222, 223], [224, 234], [234, 235], [235, 236]]}
{"doc_key": "ai-train-43", "ner": [[6, 10, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Alcune", "lingue", "meno", "diffuse", "utilizzano", "il", "sintetizzatore", "open", "-", "source", "eSpeak", "per", "il", "parlato", ",", "producendo", "una", "voce", "robotica", "e", "sgraziata", "che", "pu\u00f2", "essere", "difficile", "da", "capire", "."], "sentence-detokenized": "Alcune lingue meno diffuse utilizzano il sintetizzatore open-source eSpeak per il parlato, producendo una voce robotica e sgraziata che pu\u00f2 essere difficile da capire.", "token2charspan": [[0, 6], [7, 13], [14, 18], [19, 26], [27, 37], [38, 40], [41, 55], [56, 60], [60, 61], [61, 67], [68, 74], [75, 78], [79, 81], [82, 89], [89, 90], [91, 101], [102, 105], [106, 110], [111, 119], [120, 121], [122, 131], [132, 135], [136, 139], [140, 146], [147, 156], [157, 159], [160, 166], [166, 167]]}
{"doc_key": "ai-train-44", "ner": [[24, 24, "programlang"], [40, 41, "programlang"], [43, 43, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[24, 24, 40, 41, "compare", "", false, false], [24, 24, 43, 43, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Sebbene", "sia", "utilizzato", "principalmente", "da", "statistici", "e", "altri", "professionisti", "che", "necessitano", "di", "un", "ambiente", "per", "il", "calcolo", "statistico", "e", "lo", "sviluppo", "di", "software", ",", "R", "pu\u00f2", "anche", "funzionare", "come", "toolbox", "generale", "per", "il", "calcolo", "matriciale", ",", "con", "prestazioni", "paragonabili", "a", "GNU", "Octave", "o", "MATLAB."], "sentence-detokenized": "Sebbene sia utilizzato principalmente da statistici e altri professionisti che necessitano di un ambiente per il calcolo statistico e lo sviluppo di software, R pu\u00f2 anche funzionare come toolbox generale per il calcolo matriciale, con prestazioni paragonabili a GNU Octave o MATLAB.", "token2charspan": [[0, 7], [8, 11], [12, 22], [23, 37], [38, 40], [41, 51], [52, 53], [54, 59], [60, 74], [75, 78], [79, 90], [91, 93], [94, 96], [97, 105], [106, 109], [110, 112], [113, 120], [121, 131], [132, 133], [134, 136], [137, 145], [146, 148], [149, 157], [157, 158], [159, 160], [161, 164], [165, 170], [171, 181], [182, 186], [187, 194], [195, 203], [204, 207], [208, 210], [211, 218], [219, 229], [229, 230], [231, 234], [235, 246], [247, 259], [260, 261], [262, 265], [266, 272], [273, 274], [275, 282]]}
{"doc_key": "ai-train-45", "ner": [[0, 1, "algorithm"], [5, 8, "field"], [11, 14, "misc"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 5, 8, "part-of", "", false, false], [0, 1, 15, 16, "origin", "", false, false], [11, 14, 15, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["L'", "eterodirezione", "\u00e8", "una", "tecnica", "di", "elaborazione", "del", "segnale", "inventata", "dall'", "inventore", "-", "ingegnere", "canadese", "Reginald", "Fessenden", "che", "crea", "nuove", "frequenze", "combinando", "due", "frequenze", "."], "sentence-detokenized": "L'eterodirezione \u00e8 una tecnica di elaborazione del segnale inventata dall'inventore-ingegnere canadese Reginald Fessenden che crea nuove frequenze combinando due frequenze.", "token2charspan": [[0, 2], [2, 16], [17, 18], [19, 22], [23, 30], [31, 33], [34, 46], [47, 50], [51, 58], [59, 68], [69, 74], [74, 83], [83, 84], [84, 93], [94, 102], [103, 111], [112, 121], [122, 125], [126, 130], [131, 136], [137, 146], [147, 157], [158, 161], [162, 171], [171, 172]]}
{"doc_key": "ai-train-46", "ner": [[18, 19, "person"], [20, 20, "misc"], [24, 25, "organisation"], [32, 32, "organisation"], [28, 30, "misc"], [34, 35, "person"], [41, 41, "organisation"], [37, 39, "misc"], [43, 44, "person"], [46, 47, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[18, 19, 20, 20, "role", "actor_in", false, false], [20, 20, 24, 25, "artifact", "", false, false], [28, 30, 32, 32, "artifact", "", false, false], [34, 35, 28, 30, "role", "actor_in", false, false], [37, 39, 41, 41, "artifact", "", false, false], [43, 44, 37, 39, "role", "actor_in", false, false], [46, 47, 37, 39, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Molti", "altri", "film", "che", "contribuirono", "a", "riportare", "il", "3D", "sulla", "mappa", "in", "quel", "mese", "furono", "il", "film", "di", "John", "Wayne", "Hondo", "(", "distribuito", "dalla", "Warner", "Bros.", ")", ",", "Miss", "Sadie", "Thompson", "della", "Columbia", "con", "Rita", "Hayworth", "e", "Money", "From", "Home", "della", "Paramount", "con", "Dean", "Martin", "e", "Jerry", "Lewis", "."], "sentence-detokenized": "Molti altri film che contribuirono a riportare il 3D sulla mappa in quel mese furono il film di John Wayne Hondo (distribuito dalla Warner Bros.), Miss Sadie Thompson della Columbia con Rita Hayworth e Money From Home della Paramount con Dean Martin e Jerry Lewis.", "token2charspan": [[0, 5], [6, 11], [12, 16], [17, 20], [21, 34], [35, 36], [37, 46], [47, 49], [50, 52], [53, 58], [59, 64], [65, 67], [68, 72], [73, 77], [78, 84], [85, 87], [88, 92], [93, 95], [96, 100], [101, 106], [107, 112], [113, 114], [114, 125], [126, 131], [132, 138], [139, 144], [144, 145], [145, 146], [147, 151], [152, 157], [158, 166], [167, 172], [173, 181], [182, 185], [186, 190], [191, 199], [200, 201], [202, 207], [208, 212], [213, 217], [218, 223], [224, 233], [234, 237], [238, 242], [243, 249], [250, 251], [252, 257], [258, 263], [263, 264]]}
{"doc_key": "ai-train-47", "ner": [[0, 0, "product"], [7, 9, "field"], [5, 6, "task"], [17, 17, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 6, "general-affiliation", "", false, false], [0, 0, 17, 17, "artifact", "", false, false], [5, 6, 7, 9, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["DeepFace", "\u00e8", "un", "sistema", "di", "riconoscimento", "facciale", "ad", "apprendimento", "profondo", "creato", "da", "un", "gruppo", "di", "ricerca", "di", "Facebook", "."], "sentence-detokenized": "DeepFace \u00e8 un sistema di riconoscimento facciale ad apprendimento profondo creato da un gruppo di ricerca di Facebook.", "token2charspan": [[0, 8], [9, 10], [11, 13], [14, 21], [22, 24], [25, 39], [40, 48], [49, 51], [52, 65], [66, 74], [75, 81], [82, 84], [85, 87], [88, 94], [95, 97], [98, 105], [106, 108], [109, 117], [117, 118]]}
{"doc_key": "ai-train-48", "ner": [[0, 3, "field"], [11, 11, "conference"], [18, 19, "field"], [26, 31, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 18, 19, "part-of", "subfield", false, false], [11, 11, 0, 3, "topic", "", false, false], [26, 31, 0, 3, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["L'", "elaborazione", "della", "geometria", "\u00e8", "un", "argomento", "di", "ricerca", "comune", "al", "SIGGRAPH", ",", "la", "principale", "conferenza", "accademica", "di", "computer", "grafica", ",", "e", "l'", "argomento", "principale", "del", "Simposio", "annuale", "sull'", "elaborazione", "della", "geometria", "."], "sentence-detokenized": "L'elaborazione della geometria \u00e8 un argomento di ricerca comune al SIGGRAPH, la principale conferenza accademica di computer grafica, e l'argomento principale del Simposio annuale sull'elaborazione della geometria.", "token2charspan": [[0, 2], [2, 14], [15, 20], [21, 30], [31, 32], [33, 35], [36, 45], [46, 48], [49, 56], [57, 63], [64, 66], [67, 75], [75, 76], [77, 79], [80, 90], [91, 101], [102, 112], [113, 115], [116, 124], [125, 132], [132, 133], [134, 135], [136, 138], [138, 147], [148, 158], [159, 162], [163, 171], [172, 179], [180, 185], [185, 197], [198, 203], [204, 213], [213, 214]]}
{"doc_key": "ai-train-49", "ner": [[0, 3, "task"], [6, 8, "task"], [18, 21, "algorithm"], [23, 23, "algorithm"], [27, 29, "algorithm"], [31, 31, "algorithm"], [35, 38, "algorithm"], [40, 40, "algorithm"], [45, 47, "misc"], [53, 55, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[18, 21, 45, 47, "general-affiliation", "", false, false], [23, 23, 18, 21, "named", "", false, false], [27, 29, 45, 47, "general-affiliation", "", false, false], [31, 31, 27, 29, "named", "", false, false], [35, 38, 45, 47, "general-affiliation", "", false, false], [40, 40, 35, 38, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["L'", "estrazione", "delle", "caratteristiche", "e", "la", "riduzione", "delle", "dimensioni", "possono", "essere", "combinate", "in", "un'", "unica", "fase", "utilizzando", "l'", "analisi", "delle", "componenti", "principali", "(", "PCA", ")", ",", "l'", "analisi", "discriminante", "lineare", "(", "LDA", ")", "o", "l'", "analisi", "di", "correlazione", "canonica", "(", "CCA", ")", "come", "fase", "di", "pre", "-", "elaborazione", ",", "seguita", "dal", "clustering", "mediante", "k", "-", "NN", "sui", "vettori", "delle", "caratteristiche", "nello", "spazio", "a", "dimensioni", "ridotte", "."], "sentence-detokenized": "L'estrazione delle caratteristiche e la riduzione delle dimensioni possono essere combinate in un'unica fase utilizzando l'analisi delle componenti principali (PCA), l'analisi discriminante lineare (LDA) o l'analisi di correlazione canonica (CCA) come fase di pre-elaborazione, seguita dal clustering mediante k-NN sui vettori delle caratteristiche nello spazio a dimensioni ridotte.", "token2charspan": [[0, 2], [2, 12], [13, 18], [19, 34], [35, 36], [37, 39], [40, 49], [50, 55], [56, 66], [67, 74], [75, 81], [82, 91], [92, 94], [95, 98], [98, 103], [104, 108], [109, 120], [121, 123], [123, 130], [131, 136], [137, 147], [148, 158], [159, 160], [160, 163], [163, 164], [164, 165], [166, 168], [168, 175], [176, 189], [190, 197], [198, 199], [199, 202], [202, 203], [204, 205], [206, 208], [208, 215], [216, 218], [219, 231], [232, 240], [241, 242], [242, 245], [245, 246], [247, 251], [252, 256], [257, 259], [260, 263], [263, 264], [264, 276], [276, 277], [278, 285], [286, 289], [290, 300], [301, 309], [310, 311], [311, 312], [312, 314], [315, 318], [319, 326], [327, 332], [333, 348], [349, 354], [355, 361], [362, 363], [364, 374], [375, 382], [382, 383]]}
{"doc_key": "ai-train-50", "ner": [[0, 3, "algorithm"], [10, 11, "field"], [14, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 10, 11, "related-to", "good_at", true, false], [0, 3, 14, 16, "related-to", "good_at", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Le", "reti", "neurali", "artificiali", "sono", "modelli", "computazionali", "che", "eccellono", "nell'", "apprendimento", "automatico", "e", "nel", "riconoscimento", "dei", "modelli", "."], "sentence-detokenized": "Le reti neurali artificiali sono modelli computazionali che eccellono nell'apprendimento automatico e nel riconoscimento dei modelli.", "token2charspan": [[0, 2], [3, 7], [8, 15], [16, 27], [28, 32], [33, 40], [41, 55], [56, 59], [60, 69], [70, 75], [75, 88], [89, 99], [100, 101], [102, 105], [106, 120], [121, 124], [125, 132], [132, 133]]}
{"doc_key": "ai-train-51", "ner": [[1, 2, "researcher"], [4, 5, "researcher"], [7, 11, "misc"], [13, 17, "conference"], [19, 19, "conference"], [36, 39, "algorithm"], [40, 41, "researcher"], [43, 44, "researcher"], [46, 52, "misc"], [54, 63, "conference"], [65, 65, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[7, 11, 1, 2, "artifact", "", false, false], [7, 11, 4, 5, "artifact", "", false, false], [7, 11, 13, 17, "temporal", "", false, false], [19, 19, 13, 17, "named", "", false, false], [46, 52, 36, 39, "topic", "", false, false], [46, 52, 40, 41, "artifact", "", false, false], [46, 52, 43, 44, "artifact", "", false, false], [46, 52, 54, 63, "temporal", "", false, false], [65, 65, 54, 63, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": [",", "C.", "Papageorgiou", "e", "T.", "Poggio", ",", "A", "Trainable", "Pedestrian", "Detection", "system", ",", "International", "Journal", "of", "Computer", "Vision", "(", "IJCV", ")", ",", "pagine", "1", ":", "15", "-", "33", ",", "2000", "altri", "utilizzano", "caratteristiche", "locali", "come", "l'", "istogramma", "dei", "gradienti", "orientati", "N.", "Dalal", ",", "B.", "Triggs", ",", "Histograms", "of", "oriented", "gradients", "for", "human", "detection", ",", "IEEE", "Computer", "Society", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", ",", "pagine", "1", ":", "886", "-", "893", ",", "2005", "descriptors", "."], "sentence-detokenized": ", C. Papageorgiou e T. Poggio, A Trainable Pedestrian Detection system, International Journal of Computer Vision (IJCV), pagine 1: 15-33, 2000 altri utilizzano caratteristiche locali come l'istogramma dei gradienti orientati N. Dalal, B. Triggs, Histograms of oriented gradients for human detection, IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), pagine 1: 886-893, 2005 descriptors.", "token2charspan": [[0, 1], [2, 4], [5, 17], [18, 19], [20, 22], [23, 29], [29, 30], [31, 32], [33, 42], [43, 53], [54, 63], [64, 70], [70, 71], [72, 85], [86, 93], [94, 96], [97, 105], [106, 112], [113, 114], [114, 118], [118, 119], [119, 120], [121, 127], [128, 129], [129, 130], [131, 133], [133, 134], [134, 136], [136, 137], [138, 142], [143, 148], [149, 159], [160, 175], [176, 182], [183, 187], [188, 190], [190, 200], [201, 204], [205, 214], [215, 224], [225, 227], [228, 233], [233, 234], [235, 237], [238, 244], [244, 245], [246, 256], [257, 259], [260, 268], [269, 278], [279, 282], [283, 288], [289, 298], [298, 299], [300, 304], [305, 313], [314, 321], [322, 332], [333, 335], [336, 344], [345, 351], [352, 355], [356, 363], [364, 375], [376, 377], [377, 381], [381, 382], [382, 383], [384, 390], [391, 392], [392, 393], [394, 397], [397, 398], [398, 401], [401, 402], [403, 407], [408, 419], [419, 420]]}
{"doc_key": "ai-train-52", "ner": [[1, 1, "algorithm"], [6, 8, "algorithm"], [14, 15, "task"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 6, 8, "type-of", "", false, false], [14, 15, 1, 1, "usage", "", true, false], [14, 15, 17, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Un", "autoencoder", "\u00e8", "un", "tipo", "di", "rete", "neurale", "artificiale", "utilizzata", "per", "l'", "apprendimento", "di", "funzioni", "in", "modo", "non", "supervisionato", "."], "sentence-detokenized": "Un autoencoder \u00e8 un tipo di rete neurale artificiale utilizzata per l'apprendimento di funzioni in modo non supervisionato.", "token2charspan": [[0, 2], [3, 14], [15, 16], [17, 19], [20, 24], [25, 27], [28, 32], [33, 40], [41, 52], [53, 63], [64, 67], [68, 70], [70, 83], [84, 86], [87, 95], [96, 98], [99, 103], [104, 107], [108, 122], [122, 123]]}
{"doc_key": "ai-train-53", "ner": [[0, 0, "researcher"], [4, 4, "organisation"], [10, 11, "field"], [14, 16, "field"], [20, 24, "organisation"], [26, 26, "organisation"], [33, 35, "field"], [38, 40, "field"], [47, 47, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 4, "role", "fellow_of", false, false], [0, 0, 10, 11, "related-to", "contributes_to", false, false], [0, 0, 14, 16, "related-to", "contributes_to", false, false], [0, 0, 20, 24, "role", "fellow_of", false, false], [0, 0, 33, 35, "related-to", "contributes_to", false, false], [0, 0, 38, 40, "related-to", "contributes_to", false, false], [26, 26, 20, 24, "named", "", false, false], [47, 47, 20, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Haralick", "\u00e8", "Fellow", "dell'", "IEEE", "per", "i", "suoi", "contributi", "nella", "computer", "vision", "e", "nell'", "elaborazione", "delle", "immagini", "e", "Fellow", "dell'", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", "per", "i", "suoi", "contributi", "nel", "riconoscimento", "dei", "modelli", ",", "nell'", "elaborazione", "delle", "immagini", "e", "per", "il", "servizio", "reso", "all'", "IAPR."], "sentence-detokenized": "Haralick \u00e8 Fellow dell'IEEE per i suoi contributi nella computer vision e nell'elaborazione delle immagini e Fellow dell'International Association for Pattern Recognition (IAPR) per i suoi contributi nel riconoscimento dei modelli, nell'elaborazione delle immagini e per il servizio reso all'IAPR.", "token2charspan": [[0, 8], [9, 10], [11, 17], [18, 23], [23, 27], [28, 31], [32, 33], [34, 38], [39, 49], [50, 55], [56, 64], [65, 71], [72, 73], [74, 79], [79, 91], [92, 97], [98, 106], [107, 108], [109, 115], [116, 121], [121, 134], [135, 146], [147, 150], [151, 158], [159, 170], [171, 172], [172, 176], [176, 177], [178, 181], [182, 183], [184, 188], [189, 199], [200, 203], [204, 218], [219, 222], [223, 230], [230, 231], [232, 237], [237, 249], [250, 255], [256, 264], [265, 266], [267, 270], [271, 273], [274, 282], [283, 287], [288, 292], [292, 297]]}
{"doc_key": "ai-train-54", "ner": [[4, 8, "task"], [16, 18, "algorithm"], [20, 20, "algorithm"], [25, 26, "researcher"], [28, 29, "organisation"], [31, 32, "researcher"], [34, 36, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 8, 16, 18, "usage", "", false, false], [16, 18, 25, 26, "origin", "", true, false], [16, 18, 31, 32, "origin", "", true, false], [20, 20, 16, 18, "named", "", false, false], [25, 26, 28, 29, "physical", "", false, false], [25, 26, 28, 29, "role", "", false, false], [31, 32, 34, 36, "physical", "", false, false], [31, 32, 34, 36, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Il", "primo", "tentativo", "di", "ASR", "end-", "to", "-", "end", "\u00e8", "stato", "quello", "dei", "sistemi", "basati", "sulla", "Connectionist", "Temporal", "Classification", "(", "CTC", ")", ",", "introdotti", "da", "Alex", "Graves", "di", "Google", "DeepMind", "e", "Navdeep", "Jaitly", "dell'", "Universit\u00e0", "di", "Toronto", "nel", "2014", "."], "sentence-detokenized": "Il primo tentativo di ASR end-to-end \u00e8 stato quello dei sistemi basati sulla Connectionist Temporal Classification (CTC), introdotti da Alex Graves di Google DeepMind e Navdeep Jaitly dell'Universit\u00e0 di Toronto nel 2014.", "token2charspan": [[0, 2], [3, 8], [9, 18], [19, 21], [22, 25], [26, 30], [30, 32], [32, 33], [33, 36], [37, 38], [39, 44], [45, 51], [52, 55], [56, 63], [64, 70], [71, 76], [77, 90], [91, 99], [100, 114], [115, 116], [116, 119], [119, 120], [120, 121], [122, 132], [133, 135], [136, 140], [141, 147], [148, 150], [151, 157], [158, 166], [167, 168], [169, 176], [177, 183], [184, 189], [189, 199], [200, 202], [203, 210], [211, 214], [215, 219], [219, 220]]}
{"doc_key": "ai-train-55", "ner": [[0, 4, "algorithm"], [6, 6, "algorithm"], [12, 13, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 0, 4, "named", "", false, false], [12, 13, 0, 4, "type-of", "", false, false], [15, 15, 12, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "programmazione", "lineare", "-", "frazionaria", "(", "LFP", ")", "\u00e8", "una", "generalizzazione", "della", "programmazione", "lineare", "(", "LP", ")", "."], "sentence-detokenized": "La programmazione lineare-frazionaria (LFP) \u00e8 una generalizzazione della programmazione lineare (LP).", "token2charspan": [[0, 2], [3, 17], [18, 25], [25, 26], [26, 37], [38, 39], [39, 42], [42, 43], [44, 45], [46, 49], [50, 66], [67, 72], [73, 87], [88, 95], [96, 97], [97, 99], [99, 100], [100, 101]]}
{"doc_key": "ai-train-56", "ner": [[0, 0, "researcher"], [9, 13, "misc"], [15, 22, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 9, 13, "win-defeat", "", false, false], [9, 13, 15, 22, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lafferty", "ha", "ricevuto", "numerosi", "riconoscimenti", ",", "tra", "cui", "due", "premi", "Test", "-", "of", "-Time", "alla", "International", "Conference", "on", "Machine", "Learning", "2011", "e", "2012", ","], "sentence-detokenized": "Lafferty ha ricevuto numerosi riconoscimenti, tra cui due premi Test-of-Time alla International Conference on Machine Learning 2011 e 2012,", "token2charspan": [[0, 8], [9, 11], [12, 20], [21, 29], [30, 44], [44, 45], [46, 49], [50, 53], [54, 57], [58, 63], [64, 68], [68, 69], [69, 71], [71, 76], [77, 81], [82, 95], [96, 106], [107, 109], [110, 117], [118, 126], [127, 131], [132, 133], [134, 138], [138, 139]]}
{"doc_key": "ai-train-57", "ner": [[10, 10, "product"], [12, 12, "programlang"], [27, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Con", "l'", "avvento", "dei", "framework", "basati", "sui", "componenti", ",", "come", ".NET", "e", "Java", ",", "gli", "ambienti", "di", "sviluppo", "basati", "sui", "componenti", "sono", "in", "grado", "di", "distribuire", "la", "rete", "neurale", "sviluppata", "in", "questi", "framework", "come", "componenti", "ereditabili", "."], "sentence-detokenized": "Con l'avvento dei framework basati sui componenti, come .NET e Java, gli ambienti di sviluppo basati sui componenti sono in grado di distribuire la rete neurale sviluppata in questi framework come componenti ereditabili.", "token2charspan": [[0, 3], [4, 6], [6, 13], [14, 17], [18, 27], [28, 34], [35, 38], [39, 49], [49, 50], [51, 55], [56, 60], [61, 62], [63, 67], [67, 68], [69, 72], [73, 81], [82, 84], [85, 93], [94, 100], [101, 104], [105, 115], [116, 120], [121, 123], [124, 129], [130, 132], [133, 144], [145, 147], [148, 152], [153, 160], [161, 171], [172, 174], [175, 181], [182, 191], [192, 196], [197, 207], [208, 219], [219, 220]]}
{"doc_key": "ai-train-58", "ner": [[4, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Come", "nel", "caso", "del", "BLEU", ",", "l'", "unit\u00e0", "di", "base", "della", "valutazione", "\u00e8", "la", "frase", ";", "l'", "algoritmo", "crea", "innanzitutto", "un", "allineamento", "(", "vedi", "illustrazioni", ")", "tra", "due", "frasi", ",", "la", "stringa", "di", "traduzione", "candidata", "e", "la", "stringa", "di", "traduzione", "di", "riferimento", "."], "sentence-detokenized": "Come nel caso del BLEU, l'unit\u00e0 di base della valutazione \u00e8 la frase; l'algoritmo crea innanzitutto un allineamento (vedi illustrazioni) tra due frasi, la stringa di traduzione candidata e la stringa di traduzione di riferimento.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 17], [18, 22], [22, 23], [24, 26], [26, 31], [32, 34], [35, 39], [40, 45], [46, 57], [58, 59], [60, 62], [63, 68], [68, 69], [70, 72], [72, 81], [82, 86], [87, 99], [100, 102], [103, 115], [116, 117], [117, 121], [122, 135], [135, 136], [137, 140], [141, 144], [145, 150], [150, 151], [152, 154], [155, 162], [163, 165], [166, 176], [177, 186], [187, 188], [189, 191], [192, 199], [200, 202], [203, 213], [214, 216], [217, 228], [228, 229]]}
{"doc_key": "ai-train-59", "ner": [[5, 12, "conference"], [27, 27, "task"], [25, 29, "task"], [33, 34, "metrics"], [36, 42, "metrics"], [47, 50, "conference"], [52, 52, "conference"], [55, 55, "location"], [57, 57, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 12, 27, 27, "related-to", "subject_at", false, false], [5, 12, 25, 29, "related-to", "subject_at", false, false], [33, 34, 5, 12, "temporal", "", false, false], [36, 42, 33, 34, "named", "", true, false], [52, 52, 47, 50, "named", "", false, false], [55, 55, 57, 57, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Una", "delle", "metriche", "utilizzate", "nelle", "conferenze", "annuali", "del", "NIST", "sulla", "comprensione", "dei", "documenti", ",", "in", "cui", "i", "gruppi", "di", "ricerca", "presentano", "i", "loro", "sistemi", "per", "compiti", "di", "riassunto", "e", "traduzione", ",", "\u00e8", "la", "metrica", "ROUGE", "(", "Recall", "-", "Oriented", "Understudy", "for", "Gisting", "Evaluation", ",", "In", "Advances", "of", "Neural", "Information", "Processing", "Systems", "(", "NIPS", ")", ",", "Montreal", ",", "Canada", ",", "dicembre", "-", "2014", "."], "sentence-detokenized": "Una delle metriche utilizzate nelle conferenze annuali del NIST sulla comprensione dei documenti, in cui i gruppi di ricerca presentano i loro sistemi per compiti di riassunto e traduzione, \u00e8 la metrica ROUGE (Recall-Oriented Understudy for Gisting Evaluation, In Advances of Neural Information Processing Systems (NIPS), Montreal, Canada, dicembre - 2014.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 29], [30, 35], [36, 46], [47, 54], [55, 58], [59, 63], [64, 69], [70, 82], [83, 86], [87, 96], [96, 97], [98, 100], [101, 104], [105, 106], [107, 113], [114, 116], [117, 124], [125, 135], [136, 137], [138, 142], [143, 150], [151, 154], [155, 162], [163, 165], [166, 175], [176, 177], [178, 188], [188, 189], [190, 191], [192, 194], [195, 202], [203, 208], [209, 210], [210, 216], [216, 217], [217, 225], [226, 236], [237, 240], [241, 248], [249, 259], [259, 260], [261, 263], [264, 272], [273, 275], [276, 282], [283, 294], [295, 305], [306, 313], [314, 315], [315, 319], [319, 320], [320, 321], [322, 330], [330, 331], [332, 338], [338, 339], [340, 348], [349, 350], [351, 355], [355, 356]]}
{"doc_key": "ai-train-60", "ner": [[6, 6, "programlang"], [8, 8, "product"], [11, 12, "programlang"], [15, 15, "product"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 11, 12, "type-of", "", false, false], [6, 6, 21, 21, "named", "", false, false], [8, 8, 11, 12, "part-of", "", false, false], [8, 8, 15, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Stessa", "implementazione", ",", "da", "eseguire", "in", "Java", "con", "JShell", "(", "minimo", "Java", "9", ")", ":", "codejshell", "scriptfile", "/", "codesyntaxhighlight", "lang", "=", "java"], "sentence-detokenized": "Stessa implementazione, da eseguire in Java con JShell (minimo Java 9): codejshell scriptfile / codesyntaxhighlight lang = java", "token2charspan": [[0, 6], [7, 22], [22, 23], [24, 26], [27, 35], [36, 38], [39, 43], [44, 47], [48, 54], [55, 56], [56, 62], [63, 67], [68, 69], [69, 70], [70, 71], [72, 82], [83, 93], [94, 95], [96, 115], [116, 120], [121, 122], [123, 127]]}
{"doc_key": "ai-train-61", "ner": [[0, 2, "metrics"], [6, 7, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 6, 7, "origin", "based_on", false, false]], "relations_mapping_to_source": [0], "sentence": ["La", "metrica", "NIST", "si", "basa", "sulla", "metrica", "BLEU", ",", "ma", "con", "alcune", "modifiche", "."], "sentence-detokenized": "La metrica NIST si basa sulla metrica BLEU, ma con alcune modifiche.", "token2charspan": [[0, 2], [3, 10], [11, 15], [16, 18], [19, 23], [24, 29], [30, 37], [38, 42], [42, 43], [44, 46], [47, 50], [51, 57], [58, 67], [67, 68]]}
{"doc_key": "ai-train-62", "ner": [[8, 8, "country"], [11, 13, "university"], [16, 18, "university"], [26, 31, "product"], [36, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 13, 8, 8, "physical", "", false, false], [16, 18, 8, 8, "physical", "", false, false], [26, 31, 11, 13, "origin", "", false, false], [26, 31, 16, 18, "origin", "", false, false], [26, 31, 36, 37, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Alla", "fine", "degli", "anni", "'80", ",", "due", "universit\u00e0", "olandesi", ",", "l'", "Universit\u00e0", "di", "Groningen", "e", "l'", "Universit\u00e0", "di", "Twente", ",", "hanno", "avviato", "un", "progetto", "congiunto", "chiamato", "Knowledge", "Graphs", "(", "grafi", "della", "conoscenza", ")", ",", "che", "sono", "reti", "semantiche", ",", "ma", "con", "il", "vincolo", "aggiuntivo", "che", "gli", "spigoli", "devono", "appartenere", "a", "un", "insieme", "limitato", "di", "relazioni", "possibili", ",", "per", "facilitare", "le", "algebre", "sul", "grafo", "."], "sentence-detokenized": "Alla fine degli anni '80, due universit\u00e0 olandesi, l'Universit\u00e0 di Groningen e l'Universit\u00e0 di Twente, hanno avviato un progetto congiunto chiamato Knowledge Graphs (grafi della conoscenza), che sono reti semantiche, ma con il vincolo aggiuntivo che gli spigoli devono appartenere a un insieme limitato di relazioni possibili, per facilitare le algebre sul grafo.", "token2charspan": [[0, 4], [5, 9], [10, 15], [16, 20], [21, 24], [24, 25], [26, 29], [30, 40], [41, 49], [49, 50], [51, 53], [53, 63], [64, 66], [67, 76], [77, 78], [79, 81], [81, 91], [92, 94], [95, 101], [101, 102], [103, 108], [109, 116], [117, 119], [120, 128], [129, 138], [139, 147], [148, 157], [158, 164], [165, 166], [166, 171], [172, 177], [178, 188], [188, 189], [189, 190], [191, 194], [195, 199], [200, 204], [205, 215], [215, 216], [217, 219], [220, 223], [224, 226], [227, 234], [235, 245], [246, 249], [250, 253], [254, 261], [262, 268], [269, 280], [281, 282], [283, 285], [286, 293], [294, 302], [303, 305], [306, 315], [316, 325], [325, 326], [327, 330], [331, 341], [342, 344], [345, 352], [353, 356], [357, 362], [362, 363]]}
{"doc_key": "ai-train-63", "ner": [[0, 2, "product"], [16, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 16, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["I", "correttori", "grammaticali", "sono", "spesso", "implementati", "come", "funzionalit\u00e0", "di", "un", "programma", "pi\u00f9", "ampio", ",", "come", "un", "elaboratore", "di", "testi", ",", "ma", "sono", "anche", "disponibili", "come", "applicazione", "autonoma", "che", "pu\u00f2", "essere", "attivata", "all'", "interno", "di", "programmi", "che", "lavorano", "con", "testo", "modificabile", "."], "sentence-detokenized": "I correttori grammaticali sono spesso implementati come funzionalit\u00e0 di un programma pi\u00f9 ampio, come un elaboratore di testi, ma sono anche disponibili come applicazione autonoma che pu\u00f2 essere attivata all'interno di programmi che lavorano con testo modificabile.", "token2charspan": [[0, 1], [2, 12], [13, 25], [26, 30], [31, 37], [38, 50], [51, 55], [56, 68], [69, 71], [72, 74], [75, 84], [85, 88], [89, 94], [94, 95], [96, 100], [101, 103], [104, 115], [116, 118], [119, 124], [124, 125], [126, 128], [129, 133], [134, 139], [140, 151], [152, 156], [157, 169], [170, 178], [179, 182], [183, 186], [187, 193], [194, 202], [203, 207], [207, 214], [215, 217], [218, 227], [228, 231], [232, 240], [241, 244], [245, 250], [251, 263], [263, 264]]}
{"doc_key": "ai-train-64", "ner": [[3, 9, "organisation"], [12, 17, "conference"], [20, 22, "organisation"], [27, 29, "conference"], [31, 33, "conference"], [35, 37, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["\u00c8", "membro", "dell'", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "dell'", "Association", "for", "the", "Advancement", "Artificial", "Intelligence", "e", "della", "Cognitive", "Science", "Society", ",", "nonch\u00e9", "redattore", "di", "J.", "Automated", "Reasoning", ",", "J.", "Learning", "Sciences", "e", "J.", "Applied", "Ontology", "."], "sentence-detokenized": "\u00c8 membro dell'American Association for the Advancement of Science, dell'Association for the Advancement Artificial Intelligence e della Cognitive Science Society, nonch\u00e9 redattore di J. Automated Reasoning, J. Learning Sciences e J. Applied Ontology.", "token2charspan": [[0, 1], [2, 8], [9, 14], [14, 22], [23, 34], [35, 38], [39, 42], [43, 54], [55, 57], [58, 65], [65, 66], [67, 72], [72, 83], [84, 87], [88, 91], [92, 103], [104, 114], [115, 127], [128, 129], [130, 135], [136, 145], [146, 153], [154, 161], [161, 162], [163, 169], [170, 179], [180, 182], [183, 185], [186, 195], [196, 205], [205, 206], [207, 209], [210, 218], [219, 227], [228, 229], [230, 232], [233, 240], [241, 249], [249, 250]]}
{"doc_key": "ai-train-65", "ner": [[0, 3, "algorithm"], [5, 5, "algorithm"], [11, 13, "task"], [23, 24, "researcher"], [26, 28, "university"], [30, 31, "researcher"], [33, 36, "organisation"], [38, 38, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 3, 11, 13, "type-of", "", false, false], [0, 3, 23, 24, "origin", "", false, false], [0, 3, 30, 31, "origin", "", false, false], [5, 5, 0, 3, "named", "", false, false], [23, 24, 26, 28, "physical", "", false, false], [23, 24, 26, 28, "role", "", false, false], [30, 31, 33, 36, "role", "", false, false], [38, 38, 33, 36, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["La", "codifica", "predittiva", "lineare", "(", "LPC", ")", ",", "una", "forma", "di", "codifica", "del", "parlato", ",", "ha", "iniziato", "a", "svilupparsi", "con", "il", "lavoro", "di", "Fumitada", "Itakura", "dell'", "Universit\u00e0", "di", "Nagoya", "e", "Shuzo", "Saito", "della", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "nel", "1966", "."], "sentence-detokenized": "La codifica predittiva lineare (LPC), una forma di codifica del parlato, ha iniziato a svilupparsi con il lavoro di Fumitada Itakura dell'Universit\u00e0 di Nagoya e Shuzo Saito della Nippon Telegraph and Telephone (NTT) nel 1966.", "token2charspan": [[0, 2], [3, 11], [12, 22], [23, 30], [31, 32], [32, 35], [35, 36], [36, 37], [38, 41], [42, 47], [48, 50], [51, 59], [60, 63], [64, 71], [71, 72], [73, 75], [76, 84], [85, 86], [87, 98], [99, 102], [103, 105], [106, 112], [113, 115], [116, 124], [125, 132], [133, 138], [138, 148], [149, 151], [152, 158], [159, 160], [161, 166], [167, 172], [173, 178], [179, 185], [186, 195], [196, 199], [200, 209], [210, 211], [211, 214], [214, 215], [216, 219], [220, 224], [224, 225]]}
{"doc_key": "ai-train-66", "ner": [[59, 61, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Se", "il", "segnale", "\u00e8", "ulteriormente", "ergodico", ",", "tutti", "i", "percorsi", "di", "campionamento", "presentano", "la", "stessa", "media", "temporale", "e", "quindi", "mathR", "_", "x", "^", "{", "n", "/", "T", "_", "0", "}", "(", "\\", "tau", ")", "=", "\\", "widehat", "{", "R", "}", "_", "x", "^", "{", "n", "/", "T", "_", "0", "}", "(", "\\", "tau", ")", "/", "math", "in", "senso", "di", "errore", "quadratico", "medio", "."], "sentence-detokenized": "Se il segnale \u00e8 ulteriormente ergodico, tutti i percorsi di campionamento presentano la stessa media temporale e quindi mathR _ x ^ {n / T _ 0} (\\ tau) =\\ widehat {R} _ x ^ {n / T _ 0} (\\ tau) / math in senso di errore quadratico medio.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 15], [16, 29], [30, 38], [38, 39], [40, 45], [46, 47], [48, 56], [57, 59], [60, 73], [74, 84], [85, 87], [88, 94], [95, 100], [101, 110], [111, 112], [113, 119], [120, 125], [126, 127], [128, 129], [130, 131], [132, 133], [133, 134], [135, 136], [137, 138], [139, 140], [141, 142], [142, 143], [144, 145], [145, 146], [147, 150], [150, 151], [152, 153], [153, 154], [155, 162], [163, 164], [164, 165], [165, 166], [167, 168], [169, 170], [171, 172], [173, 174], [174, 175], [176, 177], [178, 179], [180, 181], [182, 183], [183, 184], [185, 186], [186, 187], [188, 191], [191, 192], [193, 194], [195, 199], [200, 202], [203, 208], [209, 211], [212, 218], [219, 229], [230, 235], [235, 236]]}
{"doc_key": "ai-train-67", "ner": [[0, 3, "task"], [6, 8, "task"], [18, 21, "algorithm"], [23, 23, "algorithm"], [27, 29, "algorithm"], [31, 31, "algorithm"], [35, 38, "algorithm"], [40, 40, "algorithm"], [46, 50, "algorithm"], [52, 52, "algorithm"], [55, 59, "misc"], [65, 67, "algorithm"], [69, 71, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[18, 21, 55, 59, "related-to", "", false, false], [23, 23, 18, 21, "named", "", false, false], [27, 29, 55, 59, "related-to", "", false, false], [31, 31, 27, 29, "named", "", false, false], [35, 38, 55, 59, "related-to", "", false, false], [40, 40, 35, 38, "named", "", false, false], [46, 50, 55, 59, "related-to", "", false, false], [52, 52, 46, 50, "named", "", false, false], [65, 67, 69, 71, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["L'", "estrazione", "delle", "caratteristiche", "e", "la", "riduzione", "delle", "dimensioni", "possono", "essere", "combinate", "in", "un'", "unica", "fase", "utilizzando", "l'", "analisi", "delle", "componenti", "principali", "(", "PCA", ")", ",", "l'", "analisi", "discriminante", "lineare", "(", "LDA", ")", ",", "l'", "analisi", "di", "correlazione", "canonica", "(", "CCA", ")", "o", "le", "tecniche", "di", "fattorizzazione", "della", "matrice", "non", "negativa", "(", "NMF", ")", "come", "fase", "di", "pre", "-", "elaborazione", ",", "seguita", "da", "un", "clustering", "K", "-", "NN", "sui", "vettori", "delle", "caratteristiche", "nello", "spazio", "a", "dimensioni", "ridotte", "."], "sentence-detokenized": "L'estrazione delle caratteristiche e la riduzione delle dimensioni possono essere combinate in un'unica fase utilizzando l'analisi delle componenti principali (PCA), l'analisi discriminante lineare (LDA), l'analisi di correlazione canonica (CCA) o le tecniche di fattorizzazione della matrice non negativa (NMF) come fase di pre-elaborazione, seguita da un clustering K-NN sui vettori delle caratteristiche nello spazio a dimensioni ridotte.", "token2charspan": [[0, 2], [2, 12], [13, 18], [19, 34], [35, 36], [37, 39], [40, 49], [50, 55], [56, 66], [67, 74], [75, 81], [82, 91], [92, 94], [95, 98], [98, 103], [104, 108], [109, 120], [121, 123], [123, 130], [131, 136], [137, 147], [148, 158], [159, 160], [160, 163], [163, 164], [164, 165], [166, 168], [168, 175], [176, 189], [190, 197], [198, 199], [199, 202], [202, 203], [203, 204], [205, 207], [207, 214], [215, 217], [218, 230], [231, 239], [240, 241], [241, 244], [244, 245], [246, 247], [248, 250], [251, 259], [260, 262], [263, 278], [279, 284], [285, 292], [293, 296], [297, 305], [306, 307], [307, 310], [310, 311], [312, 316], [317, 321], [322, 324], [325, 328], [328, 329], [329, 341], [341, 342], [343, 350], [351, 353], [354, 356], [357, 367], [368, 369], [369, 370], [370, 372], [373, 376], [377, 384], [385, 390], [391, 406], [407, 412], [413, 419], [420, 421], [422, 432], [433, 440], [440, 441]]}
{"doc_key": "ai-train-68", "ner": [[4, 4, "programlang"], [6, 6, "programlang"], [8, 8, "programlang"], [10, 10, "programlang"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[16, 16, 4, 4, "related-to", "program_type_compatible_with", false, false], [16, 16, 6, 6, "related-to", "program_type_compatible_with", false, false], [16, 16, 8, 8, "related-to", "program_type_compatible_with", false, false], [16, 16, 10, 10, "related-to", "program_type_compatible_with", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Le", "librerie", "scritte", "in", "Perl", ",", "Java", ",", "ActiveX", "o", ".NET", "possono", "essere", "richiamate", "direttamente", "da", "MATLAB", ","], "sentence-detokenized": "Le librerie scritte in Perl, Java, ActiveX o .NET possono essere richiamate direttamente da MATLAB,", "token2charspan": [[0, 2], [3, 11], [12, 19], [20, 22], [23, 27], [27, 28], [29, 33], [33, 34], [35, 42], [43, 44], [45, 49], [50, 57], [58, 64], [65, 75], [76, 88], [89, 91], [92, 98], [98, 99]]}
{"doc_key": "ai-train-69", "ner": [[3, 8, "task"], [11, 13, "task"], [30, 31, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 8, 11, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Il", "compito", "di", "riconoscere", "le", "entit\u00e0", "nominate", "nel", "testo", "\u00e8", "il", "Named", "Entity", "Recognition", ",", "mentre", "il", "compito", "di", "determinare", "l'", "identit\u00e0", "delle", "entit\u00e0", "nominate", "menzionate", "nel", "testo", "\u00e8", "chiamato", "Entity", "Linking", "."], "sentence-detokenized": "Il compito di riconoscere le entit\u00e0 nominate nel testo \u00e8 il Named Entity Recognition, mentre il compito di determinare l'identit\u00e0 delle entit\u00e0 nominate menzionate nel testo \u00e8 chiamato Entity Linking.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 25], [26, 28], [29, 35], [36, 44], [45, 48], [49, 54], [55, 56], [57, 59], [60, 65], [66, 72], [73, 84], [84, 85], [86, 92], [93, 95], [96, 103], [104, 106], [107, 118], [119, 121], [121, 129], [130, 135], [136, 142], [143, 151], [152, 162], [163, 166], [167, 172], [173, 174], [175, 183], [184, 190], [191, 198], [198, 199]]}
{"doc_key": "ai-train-70", "ner": [[1, 2, "algorithm"], [27, 27, "programlang"], [30, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 30, 30, "part-of", "", true, false], [30, 30, 27, 27, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Le", "funzioni", "sigmoidi", "e", "le", "derivate", "utilizzate", "nel", "pacchetto", "erano", "originariamente", "incluse", "nel", "pacchetto", ",", "ma", "a", "partire", "dalla", "versione", "0.8.0", "sono", "state", "rilasciate", "in", "un", "pacchetto", "R", "separato", ",", "sigmoid", ",", "con", "l'", "intento", "di", "consentirne", "un", "uso", "pi\u00f9", "generale", "."], "sentence-detokenized": "Le funzioni sigmoidi e le derivate utilizzate nel pacchetto erano originariamente incluse nel pacchetto, ma a partire dalla versione 0.8.0 sono state rilasciate in un pacchetto R separato, sigmoid, con l'intento di consentirne un uso pi\u00f9 generale.", "token2charspan": [[0, 2], [3, 11], [12, 20], [21, 22], [23, 25], [26, 34], [35, 45], [46, 49], [50, 59], [60, 65], [66, 81], [82, 89], [90, 93], [94, 103], [103, 104], [105, 107], [108, 109], [110, 117], [118, 123], [124, 132], [133, 138], [139, 143], [144, 149], [150, 160], [161, 163], [164, 166], [167, 176], [177, 178], [179, 187], [187, 188], [189, 196], [196, 197], [198, 201], [202, 204], [204, 211], [212, 214], [215, 226], [227, 229], [230, 233], [234, 237], [238, 246], [246, 247]]}
{"doc_key": "ai-train-71", "ner": [[0, 1, "programlang"], [8, 12, "organisation"], [14, 14, "organisation"], [22, 22, "location"], [24, 24, "location"], [27, 28, "researcher"], [30, 31, "researcher"], [33, 34, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 27, 28, "artifact", "", true, false], [0, 1, 30, 31, "artifact", "", true, false], [0, 1, 33, 34, "artifact", "", true, false], [14, 14, 8, 12, "named", "", false, false], [14, 14, 22, 22, "physical", "", false, false], [22, 22, 24, 24, "physical", "", false, false], [27, 28, 8, 12, "role", "", false, false], [30, 31, 8, 12, "role", "", false, false], [33, 34, 8, 12, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Il", "logo", "\u00e8", "stato", "creato", "nel", "1967", "presso", "Bolt", ",", "Beranek", "and", "Newman", "(", "BBN", ")", ",", "una", "societ\u00e0", "di", "ricerca", "di", "Cambridge", ",", "Massachusetts", ",", "da", "Wally", "Feurzeig", ",", "Cynthia", "Solomon", "e", "Seymour", "Papert."], "sentence-detokenized": "Il logo \u00e8 stato creato nel 1967 presso Bolt, Beranek and Newman (BBN), una societ\u00e0 di ricerca di Cambridge, Massachusetts, da Wally Feurzeig, Cynthia Solomon e Seymour Papert.", "token2charspan": [[0, 2], [3, 7], [8, 9], [10, 15], [16, 22], [23, 26], [27, 31], [32, 38], [39, 43], [43, 44], [45, 52], [53, 56], [57, 63], [64, 65], [65, 68], [68, 69], [69, 70], [71, 74], [75, 82], [83, 85], [86, 93], [94, 96], [97, 106], [106, 107], [108, 121], [121, 122], [123, 125], [126, 131], [132, 140], [140, 141], [142, 149], [150, 157], [158, 159], [160, 167], [168, 175]]}
{"doc_key": "ai-train-72", "ner": [[0, 1, "misc"], [10, 12, "field"], [21, 22, "field"], [26, 28, "algorithm"], [31, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 10, 12, "part-of", "", false, false], [0, 1, 21, 22, "compare", "", false, false], [26, 28, 21, 22, "part-of", "", false, false], [31, 32, 21, 22, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["La", "neuroevoluzione", "\u00e8", "comunemente", "utilizzata", "come", "parte", "del", "paradigma", "dell'", "apprendimento", "per", "rinforzo", "e", "pu\u00f2", "essere", "contrapposta", "alle", "tecniche", "convenzionali", "di", "apprendimento", "profondo", "che", "utilizzano", "la", "discesa", "del", "gradiente", "su", "una", "rete", "neurale", "con", "una", "topologia", "fissa", "."], "sentence-detokenized": "La neuroevoluzione \u00e8 comunemente utilizzata come parte del paradigma dell'apprendimento per rinforzo e pu\u00f2 essere contrapposta alle tecniche convenzionali di apprendimento profondo che utilizzano la discesa del gradiente su una rete neurale con una topologia fissa.", "token2charspan": [[0, 2], [3, 18], [19, 20], [21, 32], [33, 43], [44, 48], [49, 54], [55, 58], [59, 68], [69, 74], [74, 87], [88, 91], [92, 100], [101, 102], [103, 106], [107, 113], [114, 126], [127, 131], [132, 140], [141, 154], [155, 157], [158, 171], [172, 180], [181, 184], [185, 195], [196, 198], [199, 206], [207, 210], [211, 220], [221, 223], [224, 227], [228, 232], [233, 240], [241, 244], [245, 248], [249, 258], [259, 264], [264, 265]]}
{"doc_key": "ai-train-73", "ner": [[3, 4, "algorithm"], [51, 53, "metrics"], [55, 55, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[55, 55, 51, 53, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Se", "utilizziamo", "i", "minimi", "quadrati", "per", "adattare", "una", "funzione", "sotto", "forma", "di", "iperpiano", "\u0177", "=", "a", "+", "\u03b2", "supT", "/", "sup", "x", "ai", "dati", "(", "x", "sub", "i", "/", "sub", ",", "y", "sub", "i", "/", "sub", ")", "sub", "1", "\u2264", "i", "\u2264n", "/", "sub", ",", "potremmo", "valutare", "l'", "adattamento", "utilizzando", "l'", "errore", "quadratico", "medio", "(", "MSE", ")", "."], "sentence-detokenized": "Se utilizziamo i minimi quadrati per adattare una funzione sotto forma di iperpiano \u0177 = a + \u03b2 supT / sup x ai dati (x sub i / sub, y sub i / sub) sub 1 \u2264 i \u2264n / sub, potremmo valutare l'adattamento utilizzando l'errore quadratico medio (MSE).", "token2charspan": [[0, 2], [3, 14], [15, 16], [17, 23], [24, 32], [33, 36], [37, 45], [46, 49], [50, 58], [59, 64], [65, 70], [71, 73], [74, 83], [84, 85], [86, 87], [88, 89], [90, 91], [92, 93], [94, 98], [99, 100], [101, 104], [105, 106], [107, 109], [110, 114], [115, 116], [116, 117], [118, 121], [122, 123], [124, 125], [126, 129], [129, 130], [131, 132], [133, 136], [137, 138], [139, 140], [141, 144], [144, 145], [146, 149], [150, 151], [152, 153], [154, 155], [156, 158], [159, 160], [161, 164], [164, 165], [166, 174], [175, 183], [184, 186], [186, 197], [198, 209], [210, 212], [212, 218], [219, 229], [230, 235], [236, 237], [237, 240], [240, 241], [241, 242]]}
{"doc_key": "ai-train-74", "ner": [[6, 6, "country"], [8, 8, "country"], [10, 10, "country"], [12, 12, "country"], [14, 14, "country"], [16, 16, "country"], [18, 18, "country"], [20, 20, "country"], [22, 22, "country"], [24, 24, "country"], [26, 26, "country"], [28, 28, "country"], [30, 30, "country"], [32, 32, "country"], [34, 34, "country"], [36, 36, "country"], [38, 38, "country"], [40, 40, "country"], [42, 42, "country"], [44, 44, "country"], [46, 47, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "relations": [], "relations_mapping_to_source": [], "sentence": ["L'", "azienda", "ha", "sedi", "internazionali", "in", "Australia", ",", "Brasile", ",", "Canada", ",", "Cina", ",", "Germania", ",", "India", ",", "Italia", ",", "Giappone", ",", "Corea", ",", "Lituania", ",", "Polonia", ",", "Malesia", ",", "Filippine", ",", "Russia", ",", "Singapore", ",", "Sudafrica", ",", "Spagna", ",", "Taiwan", ",", "Thailandia", ",", "Turchia", "e", "Regno", "Unito", "."], "sentence-detokenized": "L'azienda ha sedi internazionali in Australia, Brasile, Canada, Cina, Germania, India, Italia, Giappone, Corea, Lituania, Polonia, Malesia, Filippine, Russia, Singapore, Sudafrica, Spagna, Taiwan, Thailandia, Turchia e Regno Unito.", "token2charspan": [[0, 2], [2, 9], [10, 12], [13, 17], [18, 32], [33, 35], [36, 45], [45, 46], [47, 54], [54, 55], [56, 62], [62, 63], [64, 68], [68, 69], [70, 78], [78, 79], [80, 85], [85, 86], [87, 93], [93, 94], [95, 103], [103, 104], [105, 110], [110, 111], [112, 120], [120, 121], [122, 129], [129, 130], [131, 138], [138, 139], [140, 149], [149, 150], [151, 157], [157, 158], [159, 168], [168, 169], [170, 179], [179, 180], [181, 187], [187, 188], [189, 195], [195, 196], [197, 207], [207, 208], [209, 216], [217, 218], [219, 224], [225, 230], [230, 231]]}
{"doc_key": "ai-train-75", "ner": [[3, 5, "misc"], [7, 10, "field"], [15, 16, "organisation"], [19, 26, "university"], [31, 33, "organisation"], [35, 38, "university"], [45, 46, "university"], [49, 50, "university"], [53, 55, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 5, 7, 10, "topic", "", false, false], [3, 5, 15, 16, "origin", "", false, false], [3, 5, 19, 26, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Ha", "conseguito", "un", "dottorato", "di", "ricerca", "in", "ingegneria", "elettrica", "e", "informatica", "(", "2000", ")", "presso", "l'", "Inria", "e", "l'", "Universit\u00e0", "di", "Nizza", "Sophia", "Antipolis", ",", "e", "ha", "ricoperto", "incarichi", "permanenti", "presso", "Siemens", "Corporate", "Technology", ",", "\u00c9cole", "des", "ponts", "ParisTech", "e", "incarichi", "di", "visita", "presso", "la", "Rutgers", "University", ",", "la", "Yale", "University", "e", "l'", "Universit\u00e0", "di", "Houston", "."], "sentence-detokenized": "Ha conseguito un dottorato di ricerca in ingegneria elettrica e informatica (2000) presso l'Inria e l'Universit\u00e0 di Nizza Sophia Antipolis, e ha ricoperto incarichi permanenti presso Siemens Corporate Technology, \u00c9cole des ponts ParisTech e incarichi di visita presso la Rutgers University, la Yale University e l'Universit\u00e0 di Houston.", "token2charspan": [[0, 2], [3, 13], [14, 16], [17, 26], [27, 29], [30, 37], [38, 40], [41, 51], [52, 61], [62, 63], [64, 75], [76, 77], [77, 81], [81, 82], [83, 89], [90, 92], [92, 97], [98, 99], [100, 102], [102, 112], [113, 115], [116, 121], [122, 128], [129, 138], [138, 139], [140, 141], [142, 144], [145, 154], [155, 164], [165, 175], [176, 182], [183, 190], [191, 200], [201, 211], [211, 212], [213, 218], [219, 222], [223, 228], [229, 238], [239, 240], [241, 250], [251, 253], [254, 260], [261, 267], [268, 270], [271, 278], [279, 289], [289, 290], [291, 293], [294, 298], [299, 309], [310, 311], [312, 314], [314, 324], [325, 327], [328, 335], [335, 336]]}
{"doc_key": "ai-train-76", "ner": [[9, 10, "researcher"], [12, 12, "researcher"], [19, 20, "product"], [22, 23, "country"], [26, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 12, 9, 10, "role", "licensing_patent_to", false, false], [12, 12, 22, 23, "physical", "", false, false], [26, 26, 12, 12, "artifact", "", false, false], [26, 26, 19, 20, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Concedendo", "in", "licenza", "il", "brevetto", "originale", "assegnato", "all'", "inventore", "George", "Devol", ",", "Engelberger", "svilupp\u00f2", "negli", "anni", "Cinquanta", "il", "primo", "robot", "industriale", "degli", "Stati", "Uniti", ",", "l'", "Unimate", "."], "sentence-detokenized": "Concedendo in licenza il brevetto originale assegnato all'inventore George Devol, Engelberger svilupp\u00f2 negli anni Cinquanta il primo robot industriale degli Stati Uniti, l'Unimate.", "token2charspan": [[0, 10], [11, 13], [14, 21], [22, 24], [25, 33], [34, 43], [44, 53], [54, 58], [58, 67], [68, 74], [75, 80], [80, 81], [82, 93], [94, 102], [103, 108], [109, 113], [114, 123], [124, 126], [127, 132], [133, 138], [139, 150], [151, 156], [157, 162], [163, 168], [168, 169], [170, 172], [172, 179], [179, 180]]}
{"doc_key": "ai-train-77", "ner": [[4, 5, "task"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["L'", "input", "\u00e8", "chiamato", "riconoscimento", "vocale", "e", "l'", "output", "\u00e8", "chiamato", "sintesi", "vocale", "."], "sentence-detokenized": "L'input \u00e8 chiamato riconoscimento vocale e l'output \u00e8 chiamato sintesi vocale.", "token2charspan": [[0, 2], [2, 7], [8, 9], [10, 18], [19, 33], [34, 40], [41, 42], [43, 45], [45, 51], [52, 53], [54, 62], [63, 70], [71, 77], [77, 78]]}
{"doc_key": "ai-train-78", "ner": [[4, 4, "programlang"], [6, 6, "programlang"], [10, 10, "programlang"], [17, 17, "programlang"], [28, 28, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 10, 10, "named", "", false, false], [6, 6, 4, 4, "origin", "descendant_of", false, false], [6, 6, 17, 17, "general-affiliation", "", false, false], [6, 6, 28, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["I", "discendenti", "del", "linguaggio", "CLIPS", "includono", "Jess", "(", "porzione", "di", "CLIPS", "basata", "su", "regole", "e", "riscritta", "in", "Java", ",", "in", "seguito", "cresciuta", "in", "una", "direzione", "diversa", ")", ",", "JESS", "\u00e8", "stato", "originariamente", "ispirato"], "sentence-detokenized": "I discendenti del linguaggio CLIPS includono Jess (porzione di CLIPS basata su regole e riscritta in Java, in seguito cresciuta in una direzione diversa), JESS \u00e8 stato originariamente ispirato", "token2charspan": [[0, 1], [2, 13], [14, 17], [18, 28], [29, 34], [35, 44], [45, 49], [50, 51], [51, 59], [60, 62], [63, 68], [69, 75], [76, 78], [79, 85], [86, 87], [88, 97], [98, 100], [101, 105], [105, 106], [107, 109], [110, 117], [118, 127], [128, 130], [131, 134], [135, 144], [145, 152], [152, 153], [153, 154], [155, 159], [160, 161], [162, 167], [168, 183], [184, 192]]}
{"doc_key": "ai-train-79", "ner": [[4, 4, "product"], [11, 14, "product"], [17, 18, "organisation"], [23, 24, "product"], [44, 46, "product"], [48, 50, "product"], [71, 73, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 14, 4, 4, "type-of", "", false, false], [17, 18, 11, 14, "usage", "", false, false], [23, 24, 17, 18, "artifact", "", false, false], [44, 46, 17, 18, "origin", "", true, false], [44, 46, 71, 73, "related-to", "", true, false], [48, 50, 17, 18, "origin", "", true, false], [48, 50, 71, 73, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Ha", "inoltre", "creato", "applicazioni", "AGV", "intelligenti", "e", "flessibili", ",", "progettando", "il", "sistema", "di", "controllo", "Motivity", "utilizzato", "da", "RMT", "Robotics", "per", "sviluppare", "il", "suo", "ADAM", "iAGV", "(", "Self", "-", "Guided", "Vehicle", ")", ",", "utilizzato", "per", "complesse", "operazioni", "di", "pick", "and", "place", ",", "in", "combinazione", "con", "sistemi", "a", "portale", "e", "bracci", "robotici", "industriali", ",", "utilizzati", "nelle", "fabbriche", "di", "forniture", "automobilistiche", "di", "primo", "livello", "per", "spostare", "i", "prodotti", "da", "un", "processo", "all'", "altro", "in", "layout", "non", "lineari", "."], "sentence-detokenized": "Ha inoltre creato applicazioni AGV intelligenti e flessibili, progettando il sistema di controllo Motivity utilizzato da RMT Robotics per sviluppare il suo ADAM iAGV (Self-Guided Vehicle), utilizzato per complesse operazioni di pick and place, in combinazione con sistemi a portale e bracci robotici industriali, utilizzati nelle fabbriche di forniture automobilistiche di primo livello per spostare i prodotti da un processo all'altro in layout non lineari.", "token2charspan": [[0, 2], [3, 10], [11, 17], [18, 30], [31, 34], [35, 47], [48, 49], [50, 60], [60, 61], [62, 73], [74, 76], [77, 84], [85, 87], [88, 97], [98, 106], [107, 117], [118, 120], [121, 124], [125, 133], [134, 137], [138, 148], [149, 151], [152, 155], [156, 160], [161, 165], [166, 167], [167, 171], [171, 172], [172, 178], [179, 186], [186, 187], [187, 188], [189, 199], [200, 203], [204, 213], [214, 224], [225, 227], [228, 232], [233, 236], [237, 242], [242, 243], [244, 246], [247, 259], [260, 263], [264, 271], [272, 273], [274, 281], [282, 283], [284, 290], [291, 299], [300, 311], [311, 312], [313, 323], [324, 329], [330, 339], [340, 342], [343, 352], [353, 369], [370, 372], [373, 378], [379, 386], [387, 390], [391, 399], [400, 401], [402, 410], [411, 413], [414, 416], [417, 425], [426, 430], [430, 435], [436, 438], [439, 445], [446, 449], [450, 457], [457, 458]]}
{"doc_key": "ai-train-80", "ner": [[8, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["I", "parametri", "\u03b2", "sono", "tipicamente", "stimati", "con", "la", "massima", "verosimiglianza", "."], "sentence-detokenized": "I parametri \u03b2 sono tipicamente stimati con la massima verosimiglianza.", "token2charspan": [[0, 1], [2, 11], [12, 13], [14, 18], [19, 30], [31, 38], [39, 42], [43, 45], [46, 53], [54, 69], [69, 70]]}
{"doc_key": "ai-train-81", "ner": [[3, 4, "task"], [6, 6, "metrics"], [8, 8, "metrics"], [10, 10, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 3, 4, "part-of", "", false, false], [8, 8, 3, 4, "part-of", "", false, false], [10, 10, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Le", "metriche", "di", "information", "retrieval", "come", "precision", "e", "recall", "o", "DCG", "sono", "utili", "per", "valutare", "la", "qualit\u00e0", "di", "un", "metodo", "di", "raccomandazione", "."], "sentence-detokenized": "Le metriche di information retrieval come precision e recall o DCG sono utili per valutare la qualit\u00e0 di un metodo di raccomandazione.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 36], [37, 41], [42, 51], [52, 53], [54, 60], [61, 62], [63, 66], [67, 71], [72, 77], [78, 81], [82, 90], [91, 93], [94, 101], [102, 104], [105, 107], [108, 114], [115, 117], [118, 133], [133, 134]]}
{"doc_key": "ai-train-82", "ner": [[6, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Una", "tipica", "fabbrica", "contiene", "centinaia", "di", "robot", "industriali", "che", "lavorano", "su", "linee", "di", "produzione", "completamente", "automatizzate", ",", "con", "un", "robot", "ogni", "dieci", "lavoratori", "umani", "."], "sentence-detokenized": "Una tipica fabbrica contiene centinaia di robot industriali che lavorano su linee di produzione completamente automatizzate, con un robot ogni dieci lavoratori umani.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 28], [29, 38], [39, 41], [42, 47], [48, 59], [60, 63], [64, 72], [73, 75], [76, 81], [82, 84], [85, 95], [96, 109], [110, 123], [123, 124], [125, 128], [129, 131], [132, 137], [138, 142], [143, 148], [149, 159], [160, 165], [165, 166]]}
{"doc_key": "ai-train-83", "ner": [[6, 6, "product"], [13, 16, "field"], [21, 23, "task"], [25, 27, "task"], [29, 31, "task"], [33, 35, "task"], [37, 38, "task"], [40, 42, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[13, 16, 6, 6, "usage", "", false, true], [21, 23, 13, 16, "part-of", "", false, false], [25, 27, 13, 16, "part-of", "", false, false], [29, 31, 13, 16, "part-of", "", false, false], [33, 35, 13, 16, "part-of", "", false, false], [37, 38, 13, 16, "part-of", "", false, false], [40, 42, 13, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Negli", "ultimi", "dieci", "anni", ",", "le", "PCNN", "sono", "state", "utilizzate", "in", "diverse", "applicazioni", "di", "elaborazione", "delle", "immagini", ",", "tra", "cui", ":", "segmentazione", "delle", "immagini", ",", "generazione", "di", "caratteristiche", ",", "estrazione", "di", "volti", ",", "rilevamento", "del", "movimento", ",", "region", "growing", "e", "riduzione", "del", "rumore", "."], "sentence-detokenized": "Negli ultimi dieci anni, le PCNN sono state utilizzate in diverse applicazioni di elaborazione delle immagini, tra cui: segmentazione delle immagini, generazione di caratteristiche, estrazione di volti, rilevamento del movimento, region growing e riduzione del rumore.", "token2charspan": [[0, 5], [6, 12], [13, 18], [19, 23], [23, 24], [25, 27], [28, 32], [33, 37], [38, 43], [44, 54], [55, 57], [58, 65], [66, 78], [79, 81], [82, 94], [95, 100], [101, 109], [109, 110], [111, 114], [115, 118], [118, 119], [120, 133], [134, 139], [140, 148], [148, 149], [150, 161], [162, 164], [165, 180], [180, 181], [182, 192], [193, 195], [196, 201], [201, 202], [203, 214], [215, 218], [219, 228], [228, 229], [230, 236], [237, 244], [245, 246], [247, 256], [257, 260], [261, 267], [267, 268]]}
{"doc_key": "ai-train-84", "ner": [[0, 0, "researcher"], [15, 16, "field"], [21, 23, "misc"], [25, 32, "conference"], [34, 34, "conference"], [39, 41, "misc"], [43, 49, "conference"], [50, 51, "conference"], [53, 57, "conference"], [59, 59, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 0, 15, 16, "related-to", "contributes_to", false, false], [0, 0, 21, 23, "win-defeat", "", false, false], [0, 0, 39, 41, "win-defeat", "", false, false], [21, 23, 25, 32, "temporal", "", false, false], [34, 34, 25, 32, "named", "", false, false], [39, 41, 43, 49, "temporal", "", false, false], [39, 41, 53, 57, "temporal", "", false, false], [50, 51, 43, 49, "named", "", false, false], [59, 59, 53, 57, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Xu", "ha", "pubblicato", "pi\u00f9", "di", "50", "articoli", "in", "conferenze", "internazionali", "e", "riviste", "nel", "campo", "della", "computer", "vision", "e", "ha", "vinto", "il", "Best", "Paper", "Award", "alla", "conferenza", "internazionale", "Non", "-", "Photorealistic", "Rendering", "and", "Animation", "(", "NPAR", ")", "2012", "e", "il", "Best", "Reviewer", "Award", "alle", "conferenze", "internazionali", "Asian", "Conference", "on", "Computer", "Vision", "ACCV", "2012", "e", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "2015", "."], "sentence-detokenized": "Xu ha pubblicato pi\u00f9 di 50 articoli in conferenze internazionali e riviste nel campo della computer vision e ha vinto il Best Paper Award alla conferenza internazionale Non-Photorealistic Rendering and Animation (NPAR) 2012 e il Best Reviewer Award alle conferenze internazionali Asian Conference on Computer Vision ACCV 2012 e International Conference on Computer Vision (ICCV) 2015.", "token2charspan": [[0, 2], [3, 5], [6, 16], [17, 20], [21, 23], [24, 26], [27, 35], [36, 38], [39, 49], [50, 64], [65, 66], [67, 74], [75, 78], [79, 84], [85, 90], [91, 99], [100, 106], [107, 108], [109, 111], [112, 117], [118, 120], [121, 125], [126, 131], [132, 137], [138, 142], [143, 153], [154, 168], [169, 172], [172, 173], [173, 187], [188, 197], [198, 201], [202, 211], [212, 213], [213, 217], [217, 218], [219, 223], [224, 225], [226, 228], [229, 233], [234, 242], [243, 248], [249, 253], [254, 264], [265, 279], [280, 285], [286, 296], [297, 299], [300, 308], [309, 315], [316, 320], [321, 325], [326, 327], [328, 341], [342, 352], [353, 355], [356, 364], [365, 371], [372, 373], [373, 377], [377, 378], [379, 383], [383, 384]]}
{"doc_key": "ai-train-85", "ner": [[0, 0, "programlang"], [2, 2, "field"], [4, 5, "field"], [8, 9, "misc"], [16, 17, "researcher"], [12, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 2, 2, "part-of", "", false, false], [0, 0, 4, 5, "part-of", "", false, false], [0, 0, 8, 9, "type-of", "", false, false], [12, 14, 0, 0, "usage", "", false, false], [12, 14, 16, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["CycL", "in", "informatica", "e", "intelligenza", "artificiale", "\u00e8", "un", "linguaggio", "ontologico", "utilizzato", "dal", "progetto", "artificiale", "Cyc", "di", "Doug", "Lenat."], "sentence-detokenized": "CycL in informatica e intelligenza artificiale \u00e8 un linguaggio ontologico utilizzato dal progetto artificiale Cyc di Doug Lenat.", "token2charspan": [[0, 4], [5, 7], [8, 19], [20, 21], [22, 34], [35, 46], [47, 48], [49, 51], [52, 62], [63, 73], [74, 84], [85, 88], [89, 97], [98, 109], [110, 113], [114, 116], [117, 121], [122, 128]]}
{"doc_key": "ai-train-86", "ner": [[2, 4, "task"], [7, 9, "metrics"], [14, 18, "metrics"], [20, 25, "metrics"], [33, 34, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 9, 2, 4, "part-of", "", false, false], [14, 18, 7, 9, "named", "", false, false], [20, 25, 7, 9, "named", "", false, false], [33, 34, 7, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sempre", "nell'", "analisi", "di", "regressione", ",", "l'", "errore", "quadratico", "medio", ",", "spesso", "indicato", "come", "errore", "di", "previsione", "quadratico", "medio", "o", "errore", "quadratico", "medio", "fuori", "dal", "campione", ",", "pu\u00f2", "riferirsi", "al", "valore", "medio", "delle", "deviazioni", "quadratiche", "delle", "previsioni", "dai", "valori", "VERI", ",", "su", "uno", "spazio", "di", "prova", "fuori", "dal", "campione", ",", "generato", "da", "un", "modello", "stimato", "su", "un", "particolare", "spazio", "campionario", "."], "sentence-detokenized": "Sempre nell'analisi di regressione, l'errore quadratico medio, spesso indicato come errore di previsione quadratico medio o errore quadratico medio fuori dal campione, pu\u00f2 riferirsi al valore medio delle deviazioni quadratiche delle previsioni dai valori VERI, su uno spazio di prova fuori dal campione, generato da un modello stimato su un particolare spazio campionario.", "token2charspan": [[0, 6], [7, 12], [12, 19], [20, 22], [23, 34], [34, 35], [36, 38], [38, 44], [45, 55], [56, 61], [61, 62], [63, 69], [70, 78], [79, 83], [84, 90], [91, 93], [94, 104], [105, 115], [116, 121], [122, 123], [124, 130], [131, 141], [142, 147], [148, 153], [154, 157], [158, 166], [166, 167], [168, 171], [172, 181], [182, 184], [185, 191], [192, 197], [198, 203], [204, 214], [215, 226], [227, 232], [233, 243], [244, 247], [248, 254], [255, 259], [259, 260], [261, 263], [264, 267], [268, 274], [275, 277], [278, 283], [284, 289], [290, 293], [294, 302], [302, 303], [304, 312], [313, 315], [316, 318], [319, 326], [327, 334], [335, 337], [338, 340], [341, 352], [353, 359], [360, 371], [371, 372]]}
{"doc_key": "ai-train-87", "ner": [[10, 11, "algorithm"], [13, 15, "algorithm"], [21, 23, "algorithm"], [37, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 11, 13, 15, "compare", "", false, false], [10, 11, 21, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Per", "quanto", "riguarda", "i", "risultati", ",", "i", "descrittori", "a", "blocchi", "C", "-HOG", "e", "R", "-HOG", "hanno", "prestazioni", "comparabili", ",", "con", "i", "descrittori", "C", "-HOG", "che", "mantengono", "un", "leggero", "vantaggio", "nel", "tasso", "di", "mancata", "rilevazione", "a", "tassi", "fissi", "di", "FALSO", "positivo", "su", "entrambi", "i", "set", "di", "dati", "."], "sentence-detokenized": "Per quanto riguarda i risultati, i descrittori a blocchi C-HOG e R-HOG hanno prestazioni comparabili, con i descrittori C-HOG che mantengono un leggero vantaggio nel tasso di mancata rilevazione a tassi fissi di FALSO positivo su entrambi i set di dati.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 21], [22, 31], [31, 32], [33, 34], [35, 46], [47, 48], [49, 56], [57, 58], [58, 62], [63, 64], [65, 66], [66, 70], [71, 76], [77, 88], [89, 100], [100, 101], [102, 105], [106, 107], [108, 119], [120, 121], [121, 125], [126, 129], [130, 140], [141, 143], [144, 151], [152, 161], [162, 165], [166, 171], [172, 174], [175, 182], [183, 194], [195, 196], [197, 202], [203, 208], [209, 211], [212, 217], [218, 226], [227, 229], [230, 238], [239, 240], [241, 244], [245, 247], [248, 252], [252, 253]]}
{"doc_key": "ai-train-88", "ner": [[8, 11, "algorithm"], [14, 17, "misc"], [20, 22, "algorithm"], [25, 26, "algorithm"], [30, 32, "algorithm"], [35, 38, "algorithm"], [41, 44, "algorithm"], [48, 49, "misc"], [52, 55, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[8, 11, 14, 17, "usage", "", false, false], [20, 22, 48, 49, "usage", "", false, false], [25, 26, 48, 49, "usage", "", false, false], [30, 32, 48, 49, "usage", "", false, false], [35, 38, 48, 49, "usage", "", false, false], [41, 44, 48, 49, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gli", "algoritmi", "di", "riconoscimento", "pi\u00f9", "diffusi", "includono", "l'", "analisi", "delle", "componenti", "principali", "che", "utilizza", "gli", "autogeni", "delle", "facce", ",", "l'", "analisi", "discriminante", "lineare", ",", "la", "corrispondenza", "elastica", "che", "utilizza", "l'", "algoritmo", "di", "Fisherface", ",", "il", "modello", "di", "Markov", "nascosto", ",", "l'", "apprendimento", "del", "sottospazio", "multilineare", "che", "utilizza", "la", "rappresentazione", "tensoriale", "e", "la", "corrispondenza", "dinamica", "dei", "collegamenti", "motivata", "dai", "neuroni", "."], "sentence-detokenized": "Gli algoritmi di riconoscimento pi\u00f9 diffusi includono l'analisi delle componenti principali che utilizza gli autogeni delle facce, l'analisi discriminante lineare, la corrispondenza elastica che utilizza l'algoritmo di Fisherface, il modello di Markov nascosto, l'apprendimento del sottospazio multilineare che utilizza la rappresentazione tensoriale e la corrispondenza dinamica dei collegamenti motivata dai neuroni.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 31], [32, 35], [36, 43], [44, 53], [54, 56], [56, 63], [64, 69], [70, 80], [81, 91], [92, 95], [96, 104], [105, 108], [109, 117], [118, 123], [124, 129], [129, 130], [131, 133], [133, 140], [141, 154], [155, 162], [162, 163], [164, 166], [167, 181], [182, 190], [191, 194], [195, 203], [204, 206], [206, 215], [216, 218], [219, 229], [229, 230], [231, 233], [234, 241], [242, 244], [245, 251], [252, 260], [260, 261], [262, 264], [264, 277], [278, 281], [282, 293], [294, 306], [307, 310], [311, 319], [320, 322], [323, 339], [340, 350], [351, 352], [353, 355], [356, 370], [371, 379], [380, 383], [384, 396], [397, 405], [406, 409], [410, 417], [417, 418]]}
{"doc_key": "ai-train-89", "ner": [[3, 9, "misc"], [19, 22, "location"], [37, 39, "location"], [51, 51, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[19, 22, 3, 9, "temporal", "", false, false], [37, 39, 3, 9, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "partire", "dall'", "edizione", "2019", "del", "Toronto", "International", "Film", "Festival", ",", "i", "film", "potranno", "essere", "esclusi", "dalla", "proiezione", "allo", "Scotiabank", "Theatre", "di", "Toronto", "-", "una", "delle", "sedi", "principali", "del", "festival", "-", "e", "proiettati", "altrove", "(", "come", "il", "TIFF", "Bell", "Lightbox", "e", "altri", "cinema", "locali", ")", "se", "distribuiti", "da", "un", "servizio", "come", "Netflix", "."], "sentence-detokenized": "A partire dall'edizione 2019 del Toronto International Film Festival, i film potranno essere esclusi dalla proiezione allo Scotiabank Theatre di Toronto - una delle sedi principali del festival - e proiettati altrove (come il TIFF Bell Lightbox e altri cinema locali) se distribuiti da un servizio come Netflix.", "token2charspan": [[0, 1], [2, 9], [10, 15], [15, 23], [24, 28], [29, 32], [33, 40], [41, 54], [55, 59], [60, 68], [68, 69], [70, 71], [72, 76], [77, 85], [86, 92], [93, 100], [101, 106], [107, 117], [118, 122], [123, 133], [134, 141], [142, 144], [145, 152], [153, 154], [155, 158], [159, 164], [165, 169], [170, 180], [181, 184], [185, 193], [194, 195], [196, 197], [198, 208], [209, 216], [217, 218], [218, 222], [223, 225], [226, 230], [231, 235], [236, 244], [245, 246], [247, 252], [253, 259], [260, 266], [266, 267], [268, 270], [271, 282], [283, 285], [286, 288], [289, 297], [298, 302], [303, 310], [310, 311]]}
{"doc_key": "ai-train-90", "ner": [[0, 0, "organisation"], [6, 7, "researcher"], [3, 4, "organisation"], [16, 16, "researcher"], [26, 31, "product"], [49, 49, "researcher"], [42, 45, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 3, 4, "related-to", "purchases", false, false], [6, 7, 16, 16, "named", "same", false, false], [6, 7, 49, 49, "named", "same", false, false], [3, 4, 6, 7, "origin", "founded_by", false, false], [26, 31, 0, 0, "artifact", "", false, false], [42, 45, 49, 49, "artifact", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Unimation", "acquist\u00f2", "la", "Vicarm", "Inc.", "di", "Victor", "Scheinman", "nel", "1977", "e", ",", "con", "l'", "aiuto", "di", "Scheinman", ",", "l'", "azienda", "cre\u00f2", "e", "inizi\u00f2", "a", "produrre", "la", "Macchina", "Universale", "Programmabile", "per", "l'", "Assemblaggio", ",", "un", "nuovo", "modello", "di", "braccio", "robotico", ",", "utilizzando", "il", "linguaggio", "di", "programmazione", "VAL", "all'", "avanguardia", "di", "Scheinman", "."], "sentence-detokenized": "Unimation acquist\u00f2 la Vicarm Inc. di Victor Scheinman nel 1977 e, con l'aiuto di Scheinman, l'azienda cre\u00f2 e inizi\u00f2 a produrre la Macchina Universale Programmabile per l'Assemblaggio, un nuovo modello di braccio robotico, utilizzando il linguaggio di programmazione VAL all'avanguardia di Scheinman.", "token2charspan": [[0, 9], [10, 18], [19, 21], [22, 28], [29, 33], [34, 36], [37, 43], [44, 53], [54, 57], [58, 62], [63, 64], [64, 65], [66, 69], [70, 72], [72, 77], [78, 80], [81, 90], [90, 91], [92, 94], [94, 101], [102, 106], [107, 108], [109, 115], [116, 117], [118, 126], [127, 129], [130, 138], [139, 149], [150, 163], [164, 167], [168, 170], [170, 182], [182, 183], [184, 186], [187, 192], [193, 200], [201, 203], [204, 211], [212, 220], [220, 221], [222, 233], [234, 236], [237, 247], [248, 250], [251, 265], [266, 269], [270, 274], [274, 285], [286, 288], [289, 298], [298, 299]]}
{"doc_key": "ai-train-91", "ner": [[0, 0, "product"], [6, 7, "programlang"], [9, 10, "algorithm"], [12, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 7, "general-affiliation", "", false, false], [0, 0, 9, 10, "origin", "implementation_of", false, false], [0, 0, 12, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["J48", "\u00e8", "un'", "implementazione", "open", "source", "in", "Java", "dell'", "algoritmo", "C4.5", "nello", "strumento", "di", "data", "mining", "Weka", "."], "sentence-detokenized": "J48 \u00e8 un'implementazione open source in Java dell'algoritmo C4.5 nello strumento di data mining Weka.", "token2charspan": [[0, 3], [4, 5], [6, 9], [9, 24], [25, 29], [30, 36], [37, 39], [40, 44], [45, 50], [50, 59], [60, 64], [65, 70], [71, 80], [81, 83], [84, 88], [89, 95], [96, 100], [100, 101]]}
{"doc_key": "ai-train-92", "ner": [[2, 2, "metrics"], [12, 13, "product"], [18, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 12, 13, "win-defeat", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Il", "documento", "SSIM", "del", "2004", "\u00e8", "stato", "citato", "oltre", "20.000", "volte", "secondo", "Google", "Scholar", "e", "ha", "ricevuto", "il", "Sustained", "Impact", "Award", "della", "IEEE", "Signal", "Processing", "Society", "per", "il", "2016", ",", "che", "indica", "un", "documento", "con", "un", "impatto", "insolitamente", "elevato", "per", "almeno", "10", "anni", "dopo", "la", "sua", "pubblicazione", "."], "sentence-detokenized": "Il documento SSIM del 2004 \u00e8 stato citato oltre 20.000 volte secondo Google Scholar e ha ricevuto il Sustained Impact Award della IEEE Signal Processing Society per il 2016, che indica un documento con un impatto insolitamente elevato per almeno 10 anni dopo la sua pubblicazione.", "token2charspan": [[0, 2], [3, 12], [13, 17], [18, 21], [22, 26], [27, 28], [29, 34], [35, 41], [42, 47], [48, 54], [55, 60], [61, 68], [69, 75], [76, 83], [84, 85], [86, 88], [89, 97], [98, 100], [101, 110], [111, 117], [118, 123], [124, 129], [130, 134], [135, 141], [142, 152], [153, 160], [161, 164], [165, 167], [168, 172], [172, 173], [174, 177], [178, 184], [185, 187], [188, 197], [198, 201], [202, 204], [205, 212], [213, 226], [227, 234], [235, 238], [239, 245], [246, 248], [249, 253], [254, 258], [259, 261], [262, 265], [266, 279], [279, 280]]}
{"doc_key": "ai-train-93", "ner": [[1, 2, "task"], [27, 28, "product"], [37, 39, "product"], [41, 41, "organisation"], [42, 42, "product"], [47, 47, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 2, 41, 41, "artifact", "", false, false], [27, 28, 1, 2, "related-to", "performs", false, false], [27, 28, 37, 39, "part-of", "", false, false], [41, 41, 47, 47, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["La", "sintesi", "vocale", "sta", "per", "diventare", "completamente", "indistinguibile", "dalla", "voce", "di", "un", "essere", "umano", "reale", "con", "l'", "introduzione", "nel", "2016", "del", "software", "di", "editing", "e", "generazione", "vocale", "Adobe", "Voco", ",", "un", "prototipo", "destinato", "a", "far", "parte", "della", "Adobe", "Creative", "Suite", "e", "DeepMind", "WaveNet", ",", "un", "prototipo", "di", "Google", "."], "sentence-detokenized": "La sintesi vocale sta per diventare completamente indistinguibile dalla voce di un essere umano reale con l'introduzione nel 2016 del software di editing e generazione vocale Adobe Voco, un prototipo destinato a far parte della Adobe Creative Suite e DeepMind WaveNet, un prototipo di Google.", "token2charspan": [[0, 2], [3, 10], [11, 17], [18, 21], [22, 25], [26, 35], [36, 49], [50, 65], [66, 71], [72, 76], [77, 79], [80, 82], [83, 89], [90, 95], [96, 101], [102, 105], [106, 108], [108, 120], [121, 124], [125, 129], [130, 133], [134, 142], [143, 145], [146, 153], [154, 155], [156, 167], [168, 174], [175, 180], [181, 185], [185, 186], [187, 189], [190, 199], [200, 209], [210, 211], [212, 215], [216, 221], [222, 227], [228, 233], [234, 242], [243, 248], [249, 250], [251, 259], [260, 267], [267, 268], [269, 271], [272, 281], [282, 284], [285, 291], [291, 292]]}
{"doc_key": "ai-train-94", "ner": [[0, 0, "researcher"], [5, 7, "organisation"], [11, 16, "organisation"], [21, 21, "conference"], [26, 30, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 7, "role", "", false, false], [0, 0, 11, 16, "role", "", false, false], [0, 0, 21, 21, "role", "", false, false], [0, 0, 26, 30, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Poggio", "\u00e8", "membro", "onorario", "del", "Neuroscience", "Research", "Program", ",", "membro", "dell'", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "socio", "fondatore", "dell'", "AAAI", "e", "membro", "fondatore", "del", "McGovern", "Institute", "for", "Brain", "Research", "."], "sentence-detokenized": "Poggio \u00e8 membro onorario del Neuroscience Research Program, membro dell'American Academy of Arts and Sciences, socio fondatore dell'AAAI e membro fondatore del McGovern Institute for Brain Research.", "token2charspan": [[0, 6], [7, 8], [9, 15], [16, 24], [25, 28], [29, 41], [42, 50], [51, 58], [58, 59], [60, 66], [67, 72], [72, 80], [81, 88], [89, 91], [92, 96], [97, 100], [101, 109], [109, 110], [111, 116], [117, 126], [127, 132], [132, 136], [137, 138], [139, 145], [146, 155], [156, 159], [160, 168], [169, 178], [179, 182], [183, 188], [189, 197], [197, 198]]}
{"doc_key": "ai-train-95", "ner": [[9, 9, "task"], [12, 13, "task"], [20, 21, "task"], [27, 27, "misc"], [26, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 9, 20, 21, "cause-effect", "", false, false], [12, 13, 20, 21, "cause-effect", "", false, false], [26, 28, 20, 21, "topic", "", false, false], [26, 28, 27, 27, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Negli", "anni", "'90", ",", "incoraggiati", "dai", "successi", "ottenuti", "nel", "riconoscimento", "e", "nella", "sintesi", "vocale", ",", "\u00e8", "iniziata", "la", "ricerca", "sulla", "traduzione", "vocale", "con", "lo", "sviluppo", "del", "progetto", "tedesco", "Verbmobil", "."], "sentence-detokenized": "Negli anni '90, incoraggiati dai successi ottenuti nel riconoscimento e nella sintesi vocale, \u00e8 iniziata la ricerca sulla traduzione vocale con lo sviluppo del progetto tedesco Verbmobil.", "token2charspan": [[0, 5], [6, 10], [11, 14], [14, 15], [16, 28], [29, 32], [33, 41], [42, 50], [51, 54], [55, 69], [70, 71], [72, 77], [78, 85], [86, 92], [92, 93], [94, 95], [96, 104], [105, 107], [108, 115], [116, 121], [122, 132], [133, 139], [140, 143], [144, 146], [147, 155], [156, 159], [160, 168], [169, 176], [177, 186], [186, 187]]}
{"doc_key": "ai-train-96", "ner": [[3, 4, "researcher"], [9, 10, "researcher"], [12, 13, "researcher"], [16, 18, "algorithm"], [22, 24, "algorithm"], [28, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 9, 10, "role", "", false, false], [16, 18, 3, 4, "origin", "", false, false], [16, 18, 9, 10, "origin", "", false, false], [16, 18, 12, 13, "origin", "", false, false], [16, 18, 28, 28, "part-of", "", false, false], [22, 24, 16, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Nel", "1999", ",", "Felix", "Gers", "e", "il", "suo", "consulente", "J\u00fcrgen", "Schmidhuber", "e", "Fred", "Cummins", "introdussero", "la", "porta", "di", "dimenticanza", "(", "chiamata", "anche", "porta", "di", "mantenimento", ")", "nell'", "architettura", "LSTM", ","], "sentence-detokenized": "Nel 1999, Felix Gers e il suo consulente J\u00fcrgen Schmidhuber e Fred Cummins introdussero la porta di dimenticanza (chiamata anche porta di mantenimento) nell'architettura LSTM,", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 15], [16, 20], [21, 22], [23, 25], [26, 29], [30, 40], [41, 47], [48, 59], [60, 61], [62, 66], [67, 74], [75, 87], [88, 90], [91, 96], [97, 99], [100, 112], [113, 114], [114, 122], [123, 128], [129, 134], [135, 137], [138, 150], [150, 151], [152, 157], [157, 169], [170, 174], [174, 175]]}
{"doc_key": "ai-train-97", "ner": [[1, 4, "field"], [7, 9, "field"], [12, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 14, 1, 4, "part-of", "", false, false], [12, 14, 7, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Nell'", "elaborazione", "digitale", "dei", "segnali", "e", "nella", "teoria", "dell'", "informazione", ",", "la", "funzione", "sinc", "normalizzata", "\u00e8", "comunemente", "definita", "da"], "sentence-detokenized": "Nell'elaborazione digitale dei segnali e nella teoria dell'informazione, la funzione sinc normalizzata \u00e8 comunemente definita da", "token2charspan": [[0, 5], [5, 17], [18, 26], [27, 30], [31, 38], [39, 40], [41, 46], [47, 53], [54, 59], [59, 71], [71, 72], [73, 75], [76, 84], [85, 89], [90, 102], [103, 104], [105, 116], [117, 125], [126, 128]]}
{"doc_key": "ai-train-98", "ner": [[4, 5, "field"], [14, 15, "researcher"], [20, 23, "conference"], [26, 30, "organisation"], [32, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 14, 15, "origin", "coined_term", false, false], [14, 15, 20, 23, "role", "", false, false], [14, 15, 26, 30, "role", "", false, false], [32, 32, 26, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Il", "termine", "stesso", "di", "linguistica", "computazionale", "\u00e8", "stato", "coniato", "per", "la", "prima", "volta", "da", "David", "Hays", ",", "membro", "fondatore", "dell'", "Association", "for", "Computational", "Linguistics", "e", "dell'", "International", "Committee", "on", "Computational", "Linguistics", "(", "ICCL", ")", "."], "sentence-detokenized": "Il termine stesso di linguistica computazionale \u00e8 stato coniato per la prima volta da David Hays, membro fondatore dell'Association for Computational Linguistics e dell'International Committee on Computational Linguistics (ICCL).", "token2charspan": [[0, 2], [3, 10], [11, 17], [18, 20], [21, 32], [33, 47], [48, 49], [50, 55], [56, 63], [64, 67], [68, 70], [71, 76], [77, 82], [83, 85], [86, 91], [92, 96], [96, 97], [98, 104], [105, 114], [115, 120], [120, 131], [132, 135], [136, 149], [150, 161], [162, 163], [164, 169], [169, 182], [183, 192], [193, 195], [196, 209], [210, 221], [222, 223], [223, 227], [227, 228], [228, 229]]}
{"doc_key": "ai-train-99", "ner": [[11, 16, "misc"], [10, 10, "misc"], [37, 39, "metrics"], [41, 41, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[41, 41, 37, 39, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["59", ",", "pp.", "2547", "-", "2553", ",", "ottobre", "2011", "Nel", "DPD", "monodimensionale", "basato", "su", "polinomi", "con", "memoria", "(", "o", "senza", "memoria", ")", ",", "per", "risolvere", "i", "coefficienti", "dei", "polinomi", "del", "pre", "-", "distorsore", "digitale", "e", "minimizzare", "l'", "errore", "quadratico", "medio", "(", "MSE", ")", ",", "l'", "uscita", "distorta", "del", "sistema", "non", "lineare", "deve", "essere", "sovracampionata", "a", "una", "velocit\u00e0", "tale", "da", "consentire", "l'", "acquisizione", "dei", "prodotti", "non", "lineari", "dell'", "ordine", "del", "pre", "-", "distorsore", "digitale", "."], "sentence-detokenized": "59, pp. 2547-2553, ottobre 2011 Nel DPD monodimensionale basato su polinomi con memoria (o senza memoria), per risolvere i coefficienti dei polinomi del pre-distorsore digitale e minimizzare l'errore quadratico medio (MSE), l'uscita distorta del sistema non lineare deve essere sovracampionata a una velocit\u00e0 tale da consentire l'acquisizione dei prodotti non lineari dell'ordine del pre-distorsore digitale.", "token2charspan": [[0, 2], [2, 3], [4, 7], [8, 12], [12, 13], [13, 17], [17, 18], [19, 26], [27, 31], [32, 35], [36, 39], [40, 56], [57, 63], [64, 66], [67, 75], [76, 79], [80, 87], [88, 89], [89, 90], [91, 96], [97, 104], [104, 105], [105, 106], [107, 110], [111, 120], [121, 122], [123, 135], [136, 139], [140, 148], [149, 152], [153, 156], [156, 157], [157, 167], [168, 176], [177, 178], [179, 190], [191, 193], [193, 199], [200, 210], [211, 216], [217, 218], [218, 221], [221, 222], [222, 223], [224, 226], [226, 232], [233, 241], [242, 245], [246, 253], [254, 257], [258, 265], [266, 270], [271, 277], [278, 293], [294, 295], [296, 299], [300, 308], [309, 313], [314, 316], [317, 327], [328, 330], [330, 342], [343, 346], [347, 355], [356, 359], [360, 367], [368, 373], [373, 379], [380, 383], [384, 387], [387, 388], [388, 398], [399, 407], [407, 408]]}
{"doc_key": "ai-train-100", "ner": [[0, 1, "researcher"], [10, 10, "location"], [12, 13, "location"], [15, 16, "country"], [20, 20, "location"], [22, 22, "country"], [34, 40, "organisation"], [42, 45, "organisation"], [47, 47, "location"], [51, 52, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 1, 10, 10, "physical", "", false, false], [0, 1, 42, 45, "physical", "", false, false], [0, 1, 51, 52, "role", "", false, false], [10, 10, 12, 13, "physical", "", false, false], [12, 13, 15, 16, "physical", "", false, false], [34, 40, 42, 45, "part-of", "", false, false], [42, 45, 47, 47, "physical", "", false, false], [51, 52, 34, 40, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Boris", "Katz", ",", "(", "nato", "il", "5", "ottobre", "1947", "a", "Chi\u0219in\u0103u", ",", "Moldavian", "SSR", ",", "Unione", "Sovietica", ",", "(", "ora", "Chi\u0219in\u0103u", ",", "Moldavia", ")", ")", "\u00e8", "un", "ricercatore", "americano", "(", "informatico", ")", "presso", "il", "MIT", "Computer", "Science", "and", "Artificial", "Intelligence", "Laboratory", "del", "Massachusetts", "Institute", "of", "Technology", "di", "Cambridge", "e", "capo", "del", "gruppo", "InfoLab", "del", "laboratorio", "."], "sentence-detokenized": "Boris Katz, (nato il 5 ottobre 1947 a Chi\u0219in\u0103u, Moldavian SSR, Unione Sovietica, (ora Chi\u0219in\u0103u, Moldavia)) \u00e8 un ricercatore americano (informatico) presso il MIT Computer Science and Artificial Intelligence Laboratory del Massachusetts Institute of Technology di Cambridge e capo del gruppo InfoLab del laboratorio.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 13], [13, 17], [18, 20], [21, 22], [23, 30], [31, 35], [36, 37], [38, 46], [46, 47], [48, 57], [58, 61], [61, 62], [63, 69], [70, 79], [79, 80], [81, 82], [82, 85], [86, 94], [94, 95], [96, 104], [104, 105], [105, 106], [107, 108], [109, 111], [112, 123], [124, 133], [134, 135], [135, 146], [146, 147], [148, 154], [155, 157], [158, 161], [162, 170], [171, 178], [179, 182], [183, 193], [194, 206], [207, 217], [218, 221], [222, 235], [236, 245], [246, 248], [249, 259], [260, 262], [263, 272], [273, 274], [275, 279], [280, 283], [284, 290], [291, 298], [299, 302], [303, 314], [314, 315]]}
