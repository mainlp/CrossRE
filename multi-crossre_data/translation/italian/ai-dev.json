{"doc_key": "ai-dev-1", "ner": [[5, 5, "metrics"], [9, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 5, 5, "part-of", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["In", "questo", "caso", ",", "l'", "accuratezza", "\u00e8", "misurata", "dal", "tasso", "di", "errore", ",", "definito", "come", ":"], "sentence-detokenized": "In questo caso, l'accuratezza \u00e8 misurata dal tasso di errore, definito come:", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 18], [18, 29], [30, 31], [32, 40], [41, 44], [45, 50], [51, 53], [54, 60], [60, 61], [62, 70], [71, 75], [75, 76]]}
{"doc_key": "ai-dev-2", "ner": [[6, 6, "algorithm"], [12, 14, "misc"], [21, 24, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 12, 14, "type-of", "", false, false], [6, 6, 21, 24, "related-to", "", false, false], [6, 6, 19, 20, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Da", "questo", "punto", "di", "vista", ",", "SVM", "\u00e8", "strettamente", "legato", "ad", "altri", "algoritmi", "di", "classificazione", "fondamentali", ",", "come", "la", "regressione", "logistica", "dei", "minimi", "quadrati", "regolarizzata", "."], "sentence-detokenized": "Da questo punto di vista, SVM \u00e8 strettamente legato ad altri algoritmi di classificazione fondamentali, come la regressione logistica dei minimi quadrati regolarizzata.", "token2charspan": [[0, 2], [3, 9], [10, 15], [16, 18], [19, 24], [24, 25], [26, 29], [30, 31], [32, 44], [45, 51], [52, 54], [55, 60], [61, 70], [71, 73], [74, 89], [90, 102], [102, 103], [104, 108], [109, 111], [112, 123], [124, 133], [134, 137], [138, 144], [145, 153], [154, 167], [167, 168]]}
{"doc_key": "ai-dev-3", "ner": [[0, 1, "person"], [3, 4, "person"], [14, 15, "person"], [17, 17, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 0, 1, "named", "actor_plays_character", false, false], [3, 4, 0, 1, "origin", "actor_plays_character", false, false], [17, 17, 14, 15, "named", "actor_plays_character", false, false], [17, 17, 14, 15, "origin", "actor_plays_character", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Brion", "James", "interpreta", "Leon", "Kowalski", ",", "un", "replicante", "che", "combatte", "e", "lavora", ",", "e", "Joanna", "Cassidy", "interpreta", "Zhora", ",", "un", "replicante", "assassino", "."], "sentence-detokenized": "Brion James interpreta Leon Kowalski, un replicante che combatte e lavora, e Joanna Cassidy interpreta Zhora, un replicante assassino.", "token2charspan": [[0, 5], [6, 11], [12, 22], [23, 27], [28, 36], [36, 37], [38, 40], [41, 51], [52, 55], [56, 64], [65, 66], [67, 73], [73, 74], [75, 76], [77, 83], [84, 91], [92, 102], [103, 108], [108, 109], [110, 112], [113, 123], [124, 133], [133, 134]]}
{"doc_key": "ai-dev-4", "ner": [[17, 20, "product"], [22, 22, "product"], [25, 25, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 20, 25, 25, "physical", "", false, false], [22, 22, 17, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "prima", "immagine", "ad", "essere", "scansionata", ",", "memorizzata", "e", "ricreata", "in", "pixel", "digitali", "\u00e8", "stata", "visualizzata", "sullo", "Standards", "Eastern", "Automatic", "Computer", "(", "SEAC", ")", "del", "NIST."], "sentence-detokenized": "La prima immagine ad essere scansionata, memorizzata e ricreata in pixel digitali \u00e8 stata visualizzata sullo Standards Eastern Automatic Computer (SEAC) del NIST.", "token2charspan": [[0, 2], [3, 8], [9, 17], [18, 20], [21, 27], [28, 39], [39, 40], [41, 52], [53, 54], [55, 63], [64, 66], [67, 72], [73, 81], [82, 83], [84, 89], [90, 102], [103, 108], [109, 118], [119, 126], [127, 136], [137, 145], [146, 147], [147, 151], [151, 152], [153, 156], [157, 162]]}
{"doc_key": "ai-dev-5", "ner": [[0, 9, "task"], [24, 26, "task"], [29, 30, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 9, 24, 26, "part-of", "", false, false], [0, 9, 29, 30, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "segmentazione", "del", "testo", "in", "argomenti", "o", "turni", "di", "discorso", "pu\u00f2", "essere", "utile", "in", "alcuni", "compiti", "di", "elaborazione", "naturale", ":", "pu\u00f2", "migliorare", "significativamente", "il", "reperimento", "di", "informazioni", "o", "il", "riconoscimento", "vocale", "(", "indicizzando", "/", "riconoscendo", "i", "documenti", "in", "modo", "pi\u00f9", "preciso", "o", "fornendo", "come", "risultato", "la", "parte", "specifica", "di", "un", "documento", "corrispondente", "all'", "interrogazione", ")", "."], "sentence-detokenized": "La segmentazione del testo in argomenti o turni di discorso pu\u00f2 essere utile in alcuni compiti di elaborazione naturale: pu\u00f2 migliorare significativamente il reperimento di informazioni o il riconoscimento vocale (indicizzando/riconoscendo i documenti in modo pi\u00f9 preciso o fornendo come risultato la parte specifica di un documento corrispondente all'interrogazione).", "token2charspan": [[0, 2], [3, 16], [17, 20], [21, 26], [27, 29], [30, 39], [40, 41], [42, 47], [48, 50], [51, 59], [60, 63], [64, 70], [71, 76], [77, 79], [80, 86], [87, 94], [95, 97], [98, 110], [111, 119], [119, 120], [121, 124], [125, 135], [136, 154], [155, 157], [158, 169], [170, 172], [173, 185], [186, 187], [188, 190], [191, 205], [206, 212], [213, 214], [214, 226], [226, 227], [227, 239], [240, 241], [242, 251], [252, 254], [255, 259], [260, 263], [264, 271], [272, 273], [274, 282], [283, 287], [288, 297], [298, 300], [301, 306], [307, 316], [317, 319], [320, 322], [323, 332], [333, 347], [348, 352], [352, 366], [366, 367], [367, 368]]}
{"doc_key": "ai-dev-6", "ner": [[11, 13, "university"], [27, 28, "conference"], [32, 34, "university"], [44, 45, "researcher"], [47, 48, "researcher"], [50, 51, "researcher"], [53, 54, "researcher"], [56, 57, "researcher"], [59, 60, "researcher"], [62, 64, "researcher"], [66, 67, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[27, 28, 32, 34, "physical", "", false, false], [44, 45, 27, 28, "physical", "", false, false], [44, 45, 27, 28, "role", "", false, false], [44, 45, 27, 28, "temporal", "", false, false], [47, 48, 27, 28, "physical", "", false, false], [47, 48, 27, 28, "role", "", false, false], [47, 48, 27, 28, "temporal", "", false, false], [50, 51, 27, 28, "physical", "", false, false], [50, 51, 27, 28, "role", "", false, false], [50, 51, 27, 28, "temporal", "", false, false], [53, 54, 27, 28, "physical", "", false, false], [53, 54, 27, 28, "role", "", false, false], [53, 54, 27, 28, "temporal", "", false, false], [56, 57, 27, 28, "physical", "", false, false], [56, 57, 27, 28, "role", "", false, false], [56, 57, 27, 28, "temporal", "", false, false], [59, 60, 27, 28, "physical", "", false, false], [59, 60, 27, 28, "role", "", false, false], [59, 60, 27, 28, "temporal", "", false, false], [62, 64, 27, 28, "physical", "", false, false], [62, 64, 27, 28, "role", "", false, false], [62, 64, 27, 28, "temporal", "", false, false], [66, 67, 27, 28, "physical", "", false, false], [66, 67, 27, 28, "role", "", false, false], [66, 67, 27, 28, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "sentence": ["Nel", "1999", "ha", "organizzato", "un", "simposio", "di", "questo", "tipo", "presso", "l'", "Universit\u00e0", "dell'", "Indiana", "e", "nell'", "aprile", "del", "2000", "ha", "organizzato", "un", "simposio", "pi\u00f9", "ampio", ",", "intitolato", "Spiritual", "Robots", ",", "presso", "l'", "Universit\u00e0", "di", "Stanford", ",", "in", "cui", "ha", "moderato", "un", "panel", "composto", "da", "Ray", "Kurzweil", ",", "Hans", "Moravec", ",", "Kevin", "Kelly", ",", "Ralph", "Merkle", ",", "Bill", "Joy", ",", "Frank", "Drake", ",", "John", "Henry", "Holland", "e", "John", "Koza", "."], "sentence-detokenized": "Nel 1999 ha organizzato un simposio di questo tipo presso l'Universit\u00e0 dell'Indiana e nell'aprile del 2000 ha organizzato un simposio pi\u00f9 ampio, intitolato Spiritual Robots, presso l'Universit\u00e0 di Stanford, in cui ha moderato un panel composto da Ray Kurzweil, Hans Moravec, Kevin Kelly, Ralph Merkle, Bill Joy, Frank Drake, John Henry Holland e John Koza.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 23], [24, 26], [27, 35], [36, 38], [39, 45], [46, 50], [51, 57], [58, 60], [60, 70], [71, 76], [76, 83], [84, 85], [86, 91], [91, 97], [98, 101], [102, 106], [107, 109], [110, 121], [122, 124], [125, 133], [134, 137], [138, 143], [143, 144], [145, 155], [156, 165], [166, 172], [172, 173], [174, 180], [181, 183], [183, 193], [194, 196], [197, 205], [205, 206], [207, 209], [210, 213], [214, 216], [217, 225], [226, 228], [229, 234], [235, 243], [244, 246], [247, 250], [251, 259], [259, 260], [261, 265], [266, 273], [273, 274], [275, 280], [281, 286], [286, 287], [288, 293], [294, 300], [300, 301], [302, 306], [307, 310], [310, 311], [312, 317], [318, 323], [323, 324], [325, 329], [330, 335], [336, 343], [344, 345], [346, 350], [351, 355], [355, 356]]}
{"doc_key": "ai-dev-7", "ner": [[8, 8, "metrics"], [9, 9, "metrics"], [12, 12, "metrics"], [13, 13, "metrics"], [17, 17, "metrics"], [38, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 8, 17, 17, "named", "", false, false], [9, 9, 8, 8, "named", "", false, false], [12, 12, 38, 38, "named", "", false, false], [13, 13, 12, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Per", "calcolare", "il", "punteggio", "si", "considerano", "sia", "la", "precisione", "p", "che", "il", "richiamo", "r", "del", "test", ":", "p", "\u00e8", "il", "numero", "di", "risultati", "positivi", "corretti", "diviso", "per", "il", "numero", "di", "tutti", "i", "risultati", "positivi", "restituiti", "dal", "classificatore", "e", "r", "\u00e8", "il", "numero", "di", "risultati", "positivi", "corretti", "diviso", "per", "il", "numero", "di", "tutti", "i", "campioni", "rilevanti", "(", "tutti", "i", "campioni", "che", "avrebbero", "dovuto", "essere", "identificati", "come", "positivi", ")", "."], "sentence-detokenized": "Per calcolare il punteggio si considerano sia la precisione p che il richiamo r del test: p \u00e8 il numero di risultati positivi corretti diviso per il numero di tutti i risultati positivi restituiti dal classificatore e r \u00e8 il numero di risultati positivi corretti diviso per il numero di tutti i campioni rilevanti (tutti i campioni che avrebbero dovuto essere identificati come positivi).", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 26], [27, 29], [30, 41], [42, 45], [46, 48], [49, 59], [60, 61], [62, 65], [66, 68], [69, 77], [78, 79], [80, 83], [84, 88], [88, 89], [90, 91], [92, 93], [94, 96], [97, 103], [104, 106], [107, 116], [117, 125], [126, 134], [135, 141], [142, 145], [146, 148], [149, 155], [156, 158], [159, 164], [165, 166], [167, 176], [177, 185], [186, 196], [197, 200], [201, 215], [216, 217], [218, 219], [220, 221], [222, 224], [225, 231], [232, 234], [235, 244], [245, 253], [254, 262], [263, 269], [270, 273], [274, 276], [277, 283], [284, 286], [287, 292], [293, 294], [295, 303], [304, 313], [314, 315], [315, 320], [321, 322], [323, 331], [332, 335], [336, 345], [346, 352], [353, 359], [360, 372], [373, 377], [378, 386], [386, 387], [387, 388]]}
{"doc_key": "ai-dev-8", "ner": [[6, 6, "organisation"], [27, 27, "product"], [38, 39, "person"], [44, 44, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 27, 27, "artifact", "", false, false], [27, 27, 38, 39, "win-defeat", "", false, false], [27, 27, 44, 44, "win-defeat", "", true, false], [38, 39, 44, 44, "win-defeat", "lose", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Dopo", "l'", "acquisizione", "da", "parte", "di", "Google", ",", "l'", "azienda", "ha", "ottenuto", "una", "serie", "di", "risultati", "significativi", ",", "il", "pi\u00f9", "importante", "dei", "quali", "\u00e8", "la", "creazione", "di", "AlphaGo", ",", "un", "programma", "che", "ha", "sconfitto", "il", "campione", "del", "mondo", "Lee", "Sedol", "nel", "complesso", "gioco", "del", "Go", "."], "sentence-detokenized": "Dopo l'acquisizione da parte di Google, l'azienda ha ottenuto una serie di risultati significativi, il pi\u00f9 importante dei quali \u00e8 la creazione di AlphaGo, un programma che ha sconfitto il campione del mondo Lee Sedol nel complesso gioco del Go.", "token2charspan": [[0, 4], [5, 7], [7, 19], [20, 22], [23, 28], [29, 31], [32, 38], [38, 39], [40, 42], [42, 49], [50, 52], [53, 61], [62, 65], [66, 71], [72, 74], [75, 84], [85, 98], [98, 99], [100, 102], [103, 106], [107, 117], [118, 121], [122, 127], [128, 129], [130, 132], [133, 142], [143, 145], [146, 153], [153, 154], [155, 157], [158, 167], [168, 171], [172, 174], [175, 184], [185, 187], [188, 196], [197, 200], [201, 206], [207, 210], [211, 216], [217, 220], [221, 230], [231, 236], [237, 240], [241, 243], [243, 244]]}
{"doc_key": "ai-dev-9", "ner": [[15, 16, "misc"], [27, 27, "field"], [30, 34, "product"], [52, 54, "misc"], [61, 62, "misc"], [67, 67, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[15, 16, 27, 27, "part-of", "", false, false], [15, 16, 61, 62, "named", "same", false, false], [30, 34, 52, 54, "related-to", "", false, false], [30, 34, 61, 62, "usage", "", false, false], [30, 34, 67, 67, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Rappresentare", "le", "parole", "tenendo", "conto", "del", "loro", "contesto", "attraverso", "vettori", "densi", "di", "dimensioni", "fisse", "(", "word", "embeddings", ")", "\u00e8", "diventato", "uno", "dei", "blocchi", "fondamentali", "in", "diversi", "sistemi", "NLP", ".", "Un", "sistema", "di", "disambiguazione", "non", "supervisionato", "utilizza", "la", "somiglianza", "tra", "i", "sensi", "delle", "parole", "in", "una", "finestra", "di", "contesto", "fissa", "per", "selezionare", "il", "senso", "della", "parola", "pi\u00f9", "adatto", "utilizzando", "un", "modello", "di", "word", "embedding", "pre", "-", "trainato", "e", "WordNet", "."], "sentence-detokenized": "Rappresentare le parole tenendo conto del loro contesto attraverso vettori densi di dimensioni fisse (word embeddings) \u00e8 diventato uno dei blocchi fondamentali in diversi sistemi NLP. Un sistema di disambiguazione non supervisionato utilizza la somiglianza tra i sensi delle parole in una finestra di contesto fissa per selezionare il senso della parola pi\u00f9 adatto utilizzando un modello di word embedding pre-trainato e WordNet.", "token2charspan": [[0, 13], [14, 16], [17, 23], [24, 31], [32, 37], [38, 41], [42, 46], [47, 55], [56, 66], [67, 74], [75, 80], [81, 83], [84, 94], [95, 100], [101, 102], [102, 106], [107, 117], [117, 118], [119, 120], [121, 130], [131, 134], [135, 138], [139, 146], [147, 159], [160, 162], [163, 170], [171, 178], [179, 182], [182, 183], [184, 186], [187, 194], [195, 197], [198, 213], [214, 217], [218, 232], [233, 241], [242, 244], [245, 256], [257, 260], [261, 262], [263, 268], [269, 274], [275, 281], [282, 284], [285, 288], [289, 297], [298, 300], [301, 309], [310, 315], [316, 319], [320, 331], [332, 334], [335, 340], [341, 346], [347, 353], [354, 357], [358, 364], [365, 376], [377, 379], [380, 387], [388, 390], [391, 395], [396, 405], [406, 409], [409, 410], [410, 418], [419, 420], [421, 428], [428, 429]]}
{"doc_key": "ai-dev-10", "ner": [[3, 4, "field"], [8, 9, "field"], [12, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 3, 4, "part-of", "", false, false], [12, 14, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Le", "tecniche", "di", "apprendimento", "automatico", ",", "sia", "di", "apprendimento", "supervisionato", "che", "di", "apprendimento", "non", "supervisionato", ",", "sono", "state", "utilizzate", "per", "indurre", "tali", "regole", "automaticamente", "."], "sentence-detokenized": "Le tecniche di apprendimento automatico, sia di apprendimento supervisionato che di apprendimento non supervisionato, sono state utilizzate per indurre tali regole automaticamente.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 28], [29, 39], [39, 40], [41, 44], [45, 47], [48, 61], [62, 76], [77, 80], [81, 83], [84, 97], [98, 101], [102, 116], [116, 117], [118, 122], [123, 128], [129, 139], [140, 143], [144, 151], [152, 156], [157, 163], [164, 179], [179, 180]]}
{"doc_key": "ai-dev-11", "ner": [[3, 3, "researcher"], [6, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Nel", "1969", ",", "Scheinman", "inventa", "il", "braccio", "di", "Stanford", ","], "sentence-detokenized": "Nel 1969, Scheinman inventa il braccio di Stanford,", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 19], [20, 27], [28, 30], [31, 38], [39, 41], [42, 50], [50, 51]]}
{"doc_key": "ai-dev-12", "ner": [[2, 3, "metrics"], [11, 14, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Poich\u00e9", "il", "Log", "loss", "\u00e8", "differenziabile", ",", "\u00e8", "possibile", "utilizzare", "un", "metodo", "basato", "sul", "gradiente", "per", "ottimizzare", "il", "modello", "."], "sentence-detokenized": "Poich\u00e9 il Log loss \u00e8 differenziabile, \u00e8 possibile utilizzare un metodo basato sul gradiente per ottimizzare il modello.", "token2charspan": [[0, 6], [7, 9], [10, 13], [14, 18], [19, 20], [21, 36], [36, 37], [38, 39], [40, 49], [50, 60], [61, 63], [64, 70], [71, 77], [78, 81], [82, 91], [92, 95], [96, 107], [108, 110], [111, 118], [118, 119]]}
{"doc_key": "ai-dev-13", "ner": [[1, 2, "field"], [5, 9, "algorithm"], [11, 11, "algorithm"], [14, 18, "algorithm"], [23, 24, "field"], [36, 36, "task"], [39, 41, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 9, 23, 24, "part-of", "", false, false], [11, 11, 5, 9, "named", "", false, false], [14, 18, 5, 9, "named", "", false, false], [23, 24, 1, 2, "part-of", "subfield", false, false], [36, 36, 23, 24, "part-of", "", false, false], [39, 41, 23, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Nell'", "apprendimento", "automatico", ",", "le", "macchine", "a", "vettore", "di", "supporto", "(", "SVM", ",", "anche", "reti", "a", "vettore", "di", "supporto", ")", "sono", "modelli", "di", "apprendimento", "supervisionati", "con", "algoritmi", "di", "apprendimento", "che", "analizzano", "i", "dati", "utilizzati", "per", "la", "classificazione", "e", "l'", "analisi", "di", "regressione", "."], "sentence-detokenized": "Nell'apprendimento automatico, le macchine a vettore di supporto (SVM, anche reti a vettore di supporto) sono modelli di apprendimento supervisionati con algoritmi di apprendimento che analizzano i dati utilizzati per la classificazione e l'analisi di regressione.", "token2charspan": [[0, 5], [5, 18], [19, 29], [29, 30], [31, 33], [34, 42], [43, 44], [45, 52], [53, 55], [56, 64], [65, 66], [66, 69], [69, 70], [71, 76], [77, 81], [82, 83], [84, 91], [92, 94], [95, 103], [103, 104], [105, 109], [110, 117], [118, 120], [121, 134], [135, 149], [150, 153], [154, 163], [164, 166], [167, 180], [181, 184], [185, 195], [196, 197], [198, 202], [203, 213], [214, 217], [218, 220], [221, 236], [237, 238], [239, 241], [241, 248], [249, 251], [252, 263], [263, 264]]}
{"doc_key": "ai-dev-14", "ner": [[10, 11, "task"], [13, 13, "task"], [28, 28, "metrics"], [30, 30, "metrics"], [32, 32, "researcher"], [34, 34, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 13, 10, 11, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "2002", ")", "come", "metrica", "automatica", "per", "la", "valutazione", "della", "traduzione", "automatica", "(", "MT", ")", ",", "sono", "stati", "proposti", "molti", "altri", "metodi", "per", "rivederla", "o", "migliorarla", ",", "come", "TER", ",", "METEOR", ",", "Banerjee", "e", "Lavie", "(", "2005", ")", "ecc", "."], "sentence-detokenized": "(2002) come metrica automatica per la valutazione della traduzione automatica (MT), sono stati proposti molti altri metodi per rivederla o migliorarla, come TER, METEOR, Banerjee e Lavie (2005) ecc.", "token2charspan": [[0, 1], [1, 5], [5, 6], [7, 11], [12, 19], [20, 30], [31, 34], [35, 37], [38, 49], [50, 55], [56, 66], [67, 77], [78, 79], [79, 81], [81, 82], [82, 83], [84, 88], [89, 94], [95, 103], [104, 109], [110, 115], [116, 122], [123, 126], [127, 136], [137, 138], [139, 150], [150, 151], [152, 156], [157, 160], [160, 161], [162, 168], [168, 169], [170, 178], [179, 180], [181, 186], [187, 188], [188, 192], [192, 193], [194, 197], [197, 198]]}
{"doc_key": "ai-dev-15", "ner": [[2, 3, "misc"], [10, 10, "organisation"], [11, 11, "organisation"], [15, 16, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 11, 11, "origin", "", false, false], [11, 11, 10, 10, "part-of", "", false, false], [15, 16, 11, 11, "role", "", false, false], [18, 19, 11, 11, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Include", "un'", "ontologia", "superiore", ",", "creata", "dal", "gruppo", "di", "lavoro", "IEEE", "P1600.1", "(", "originariamente", "da", "Ian", "Niles", "e", "Adam", "Pease", ")", "."], "sentence-detokenized": "Include un'ontologia superiore, creata dal gruppo di lavoro IEEE P1600.1 (originariamente da Ian Niles e Adam Pease).", "token2charspan": [[0, 7], [8, 11], [11, 20], [21, 30], [30, 31], [32, 38], [39, 42], [43, 49], [50, 52], [53, 59], [60, 64], [65, 72], [73, 74], [74, 89], [90, 92], [93, 96], [97, 102], [103, 104], [105, 109], [110, 115], [115, 116], [116, 117]]}
{"doc_key": "ai-dev-16", "ner": [[1, 3, "misc"], [32, 35, "algorithm"], [38, 40, "algorithm"], [46, 48, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[32, 35, 1, 3, "part-of", "", true, false], [38, 40, 1, 3, "part-of", "", true, false], [46, 48, 38, 40, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Nella", "tomografia", "elettronica", "criogenica", ",", "dove", "viene", "acquisito", "un", "numero", "limitato", "di", "proiezioni", "a", "causa", "delle", "limitazioni", "hardware", "e", "per", "evitare", "il", "danneggiamento", "del", "campione", "biologico", ",", "pu\u00f2", "essere", "utilizzata", "insieme", "a", "tecniche", "di", "rilevamento", "compressivo", "o", "a", "funzioni", "di", "regolarizzazione", "(", "ad", "esempio", ",", "la", "perdita", "di", "Huber", ")", "per", "migliorare", "la", "ricostruzione", "per", "una", "migliore", "interpretazione", "."], "sentence-detokenized": "Nella tomografia elettronica criogenica, dove viene acquisito un numero limitato di proiezioni a causa delle limitazioni hardware e per evitare il danneggiamento del campione biologico, pu\u00f2 essere utilizzata insieme a tecniche di rilevamento compressivo o a funzioni di regolarizzazione (ad esempio, la perdita di Huber) per migliorare la ricostruzione per una migliore interpretazione.", "token2charspan": [[0, 5], [6, 16], [17, 28], [29, 39], [39, 40], [41, 45], [46, 51], [52, 61], [62, 64], [65, 71], [72, 80], [81, 83], [84, 94], [95, 96], [97, 102], [103, 108], [109, 120], [121, 129], [130, 131], [132, 135], [136, 143], [144, 146], [147, 161], [162, 165], [166, 174], [175, 184], [184, 185], [186, 189], [190, 196], [197, 207], [208, 215], [216, 217], [218, 226], [227, 229], [230, 241], [242, 253], [254, 255], [256, 257], [258, 266], [267, 269], [270, 286], [287, 288], [288, 290], [291, 298], [298, 299], [300, 302], [303, 310], [311, 313], [314, 319], [319, 320], [321, 324], [325, 335], [336, 338], [339, 352], [353, 356], [357, 360], [361, 369], [370, 385], [385, 386]]}
{"doc_key": "ai-dev-17", "ner": [[5, 6, "misc"], [8, 8, "programlang"], [13, 14, "algorithm"], [13, 18, "algorithm"], [23, 24, "algorithm"], [29, 31, "product"], [34, 34, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 6, 8, 8, "part-of", "", false, false], [13, 14, 5, 6, "type-of", "", false, false], [13, 18, 5, 6, "type-of", "", false, false], [23, 24, 5, 6, "type-of", "", false, false], [29, 31, 8, 8, "general-affiliation", "", true, false], [29, 31, 8, 8, "part-of", "", true, false], [34, 34, 29, 31, "role", "publishes", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Un'", "implementazione", "di", "diverse", "procedure", "di", "sbiancamento", "in", "R", ",", "tra", "cui", "lo", "sbiancamento", "ZCA", "e", "lo", "sbiancamento", "PCA", ",", "ma", "anche", "lo", "sbiancamento", "CCA", ",", "\u00e8", "disponibile", "nel", "pacchetto", "R", "whitening", "pubblicato", "su", "CRAN."], "sentence-detokenized": "Un'implementazione di diverse procedure di sbiancamento in R, tra cui lo sbiancamento ZCA e lo sbiancamento PCA, ma anche lo sbiancamento CCA, \u00e8 disponibile nel pacchetto R whitening pubblicato su CRAN.", "token2charspan": [[0, 3], [3, 18], [19, 21], [22, 29], [30, 39], [40, 42], [43, 55], [56, 58], [59, 60], [60, 61], [62, 65], [66, 69], [70, 72], [73, 85], [86, 89], [90, 91], [92, 94], [95, 107], [108, 111], [111, 112], [113, 115], [116, 121], [122, 124], [125, 137], [138, 141], [141, 142], [143, 144], [145, 156], [157, 160], [161, 170], [171, 172], [173, 182], [183, 193], [194, 196], [197, 202]]}
{"doc_key": "ai-dev-18", "ner": [[31, 31, "product"], [33, 33, "product"], [35, 35, "product"], [37, 37, "product"], [39, 39, "product"], [41, 41, "product"], [45, 46, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[31, 31, 35, 35, "compare", "", false, false], [31, 31, 37, 37, "compare", "", false, false], [31, 31, 39, 39, "compare", "", false, false], [31, 31, 41, 41, "compare", "", false, false], [31, 31, 45, 46, "compare", "", false, false], [33, 33, 35, 35, "compare", "", false, false], [33, 33, 37, 37, "compare", "", false, false], [33, 33, 39, 39, "compare", "", false, false], [33, 33, 41, 41, "compare", "", false, false], [33, 33, 45, 46, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Oggi", "il", "campo", "\u00e8", "diventato", "ancora", "pi\u00f9", "scoraggiante", "e", "complesso", "con", "l'", "aggiunta", "di", "linguaggi", "e", "software", "per", "l'", "analisi", "e", "la", "progettazione", "di", "circuiti", ",", "sistemi", "e", "segnali", ",", "da", "MATLAB", "e", "Simulink", "a", "NumPy", ",", "VHDL", ",", "PSpice", ",", "Verilog", "e", "persino", "il", "linguaggio", "Assembly", "."], "sentence-detokenized": "Oggi il campo \u00e8 diventato ancora pi\u00f9 scoraggiante e complesso con l'aggiunta di linguaggi e software per l'analisi e la progettazione di circuiti, sistemi e segnali, da MATLAB e Simulink a NumPy, VHDL, PSpice, Verilog e persino il linguaggio Assembly.", "token2charspan": [[0, 4], [5, 7], [8, 13], [14, 15], [16, 25], [26, 32], [33, 36], [37, 49], [50, 51], [52, 61], [62, 65], [66, 68], [68, 76], [77, 79], [80, 89], [90, 91], [92, 100], [101, 104], [105, 107], [107, 114], [115, 116], [117, 119], [120, 133], [134, 136], [137, 145], [145, 146], [147, 154], [155, 156], [157, 164], [164, 165], [166, 168], [169, 175], [176, 177], [178, 186], [187, 188], [189, 194], [194, 195], [196, 200], [200, 201], [202, 208], [208, 209], [210, 217], [218, 219], [220, 227], [228, 230], [231, 241], [242, 250], [250, 251]]}
{"doc_key": "ai-dev-19", "ner": [[6, 7, "person"], [18, 19, "person"], [15, 17, "organisation"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 17, 18, 19, "origin", "", false, false], [22, 22, 15, 17, "artifact", "builds", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["L'", "azienda", "\u00e8", "stata", "fondata", "da", "Kiichiro", "Toyoda", "nel", "1937", ",", "come", "spinoff", "della", "societ\u00e0", "Toyota", "Industries", "di", "Sakichi", "Toyoda", "per", "creare", "automobili", "."], "sentence-detokenized": "L'azienda \u00e8 stata fondata da Kiichiro Toyoda nel 1937, come spinoff della societ\u00e0 Toyota Industries di Sakichi Toyoda per creare automobili.", "token2charspan": [[0, 2], [2, 9], [10, 11], [12, 17], [18, 25], [26, 28], [29, 37], [38, 44], [45, 48], [49, 53], [53, 54], [55, 59], [60, 67], [68, 73], [74, 81], [82, 88], [89, 99], [100, 102], [103, 110], [111, 117], [118, 121], [122, 128], [129, 139], [139, 140]]}
{"doc_key": "ai-dev-20", "ner": [[0, 3, "field"], [57, 60, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[57, 60, 0, 3, "origin", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["L'", "apprendimento", "non", "supervisionato", ",", "invece", ",", "assume", "dati", "di", "addestramento", "che", "non", "sono", "stati", "etichettati", "a", "mano", "e", "cerca", "di", "trovare", "modelli", "intrinseci", "nei", "dati", "che", "possono", "essere", "utilizzati", "per", "determinare", "il", "valore", "di", "uscita", "corretto", "per", "le", "nuove", "istanze", "di", "dati", ".", "Una", "combinazione", "di", "questi", "due", "metodi", "che", "\u00e8", "stata", "recentemente", "esplorata", "\u00e8", "l'", "apprendimento", "semi", "-", "supervisionato", ",", "che", "utilizza", "una", "combinazione", "di", "dati", "etichettati", "e", "non", "etichettati", "(", "in", "genere", "un", "piccolo", "insieme", "di", "dati", "etichettati", "combinati", "con", "una", "grande", "quantit\u00e0", "di", "dati", "non", "etichettati", ")", "."], "sentence-detokenized": "L'apprendimento non supervisionato, invece, assume dati di addestramento che non sono stati etichettati a mano e cerca di trovare modelli intrinseci nei dati che possono essere utilizzati per determinare il valore di uscita corretto per le nuove istanze di dati. Una combinazione di questi due metodi che \u00e8 stata recentemente esplorata \u00e8 l'apprendimento semi-supervisionato, che utilizza una combinazione di dati etichettati e non etichettati (in genere un piccolo insieme di dati etichettati combinati con una grande quantit\u00e0 di dati non etichettati).", "token2charspan": [[0, 2], [2, 15], [16, 19], [20, 34], [34, 35], [36, 42], [42, 43], [44, 50], [51, 55], [56, 58], [59, 72], [73, 76], [77, 80], [81, 85], [86, 91], [92, 103], [104, 105], [106, 110], [111, 112], [113, 118], [119, 121], [122, 129], [130, 137], [138, 148], [149, 152], [153, 157], [158, 161], [162, 169], [170, 176], [177, 187], [188, 191], [192, 203], [204, 206], [207, 213], [214, 216], [217, 223], [224, 232], [233, 236], [237, 239], [240, 245], [246, 253], [254, 256], [257, 261], [261, 262], [263, 266], [267, 279], [280, 282], [283, 289], [290, 293], [294, 300], [301, 304], [305, 306], [307, 312], [313, 325], [326, 335], [336, 337], [338, 340], [340, 353], [354, 358], [358, 359], [359, 373], [373, 374], [375, 378], [379, 387], [388, 391], [392, 404], [405, 407], [408, 412], [413, 424], [425, 426], [427, 430], [431, 442], [443, 444], [444, 446], [447, 453], [454, 456], [457, 464], [465, 472], [473, 475], [476, 480], [481, 492], [493, 502], [503, 506], [507, 510], [511, 517], [518, 526], [527, 529], [530, 534], [535, 538], [539, 550], [550, 551], [551, 552]]}
{"doc_key": "ai-dev-21", "ner": [[22, 22, "organisation"], [20, 20, "product"], [26, 27, "organisation"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[20, 20, 22, 22, "artifact", "", false, false], [26, 27, 24, 24, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Nonostante", "questi", "robot", "umanoidi", "siano", "destinati", "a", "usi", "utilitari", ",", "ve", "ne", "sono", "alcuni", "che", "mirano", "all'", "intrattenimento", ",", "come", "QRIO", "di", "Sony", "e", "RoboSapien", "di", "Wow", "Wee", "."], "sentence-detokenized": "Nonostante questi robot umanoidi siano destinati a usi utilitari, ve ne sono alcuni che mirano all'intrattenimento, come QRIO di Sony e RoboSapien di Wow Wee.", "token2charspan": [[0, 10], [11, 17], [18, 23], [24, 32], [33, 38], [39, 48], [49, 50], [51, 54], [55, 64], [64, 65], [66, 68], [69, 71], [72, 76], [77, 83], [84, 87], [88, 94], [95, 99], [99, 114], [114, 115], [116, 120], [121, 125], [126, 128], [129, 133], [134, 135], [136, 146], [147, 149], [150, 153], [154, 157], [157, 158]]}
{"doc_key": "ai-dev-22", "ner": [[0, 1, "researcher"], [5, 11, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 5, 11, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Webber", "\u00e8", "diventato", "Fellow", "dell'", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "nel", "1991", ","], "sentence-detokenized": "Webber \u00e8 diventato Fellow dell'Association for the Advancement of Artificial Intelligence nel 1991,", "token2charspan": [[0, 6], [7, 8], [9, 18], [19, 25], [26, 31], [31, 42], [43, 46], [47, 50], [51, 62], [63, 65], [66, 76], [77, 89], [90, 93], [94, 98], [98, 99]]}
{"doc_key": "ai-dev-23", "ner": [[7, 9, "field"], [11, 11, "field"], [24, 28, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[24, 28, 7, 9, "part-of", "task_part_of_field", false, false], [24, 28, 11, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Con", "questa", "societ\u00e0", "ha", "sviluppato", "tecnologie", "di", "data", "-", "mining", "e", "database", ",", "in", "particolare", "ontologie", "di", "alto", "livello", "per", "l'", "intelligenza", "e", "la", "comprensione", "automatica", "del", "linguaggio", "naturale", "."], "sentence-detokenized": "Con questa societ\u00e0 ha sviluppato tecnologie di data-mining e database, in particolare ontologie di alto livello per l'intelligenza e la comprensione automatica del linguaggio naturale.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 21], [22, 32], [33, 43], [44, 46], [47, 51], [51, 52], [52, 58], [59, 60], [61, 69], [69, 70], [71, 73], [74, 85], [86, 95], [96, 98], [99, 103], [104, 111], [112, 115], [116, 118], [118, 130], [131, 132], [133, 135], [136, 148], [149, 159], [160, 163], [164, 174], [175, 183], [183, 184]]}
{"doc_key": "ai-dev-24", "ner": [[27, 28, "misc"], [31, 34, "misc"], [38, 39, "misc"], [41, 41, "country"], [44, 46, "organisation"], [48, 48, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[27, 28, 41, 41, "physical", "", false, false], [31, 34, 41, 41, "physical", "", false, false], [38, 39, 41, 41, "physical", "", false, false], [44, 46, 48, 48, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Tuttavia", ",", "negli", "ultimi", "anni", "si", "pu\u00f2", "osservare", "la", "comparsa", "di", "diversi", "servizi", "elettronici", "e", "di", "iniziative", "correlate", "nei", "Paesi", "in", "via", "di", "sviluppo", ",", "come", "il", "Progetto", "Nemmadi", ",", "il", "Progetto", "MCA21", "Mission", "Mode", "o", "ancora", "l'", "India", "Digitale", "in", "India", ";", "l'", "Electronic", "Government", "Directorate", "in", "Pakistan", ",", "ecc", "."], "sentence-detokenized": "Tuttavia, negli ultimi anni si pu\u00f2 osservare la comparsa di diversi servizi elettronici e di iniziative correlate nei Paesi in via di sviluppo, come il Progetto Nemmadi, il Progetto MCA21 Mission Mode o ancora l'India Digitale in India; l'Electronic Government Directorate in Pakistan, ecc.", "token2charspan": [[0, 8], [8, 9], [10, 15], [16, 22], [23, 27], [28, 30], [31, 34], [35, 44], [45, 47], [48, 56], [57, 59], [60, 67], [68, 75], [76, 87], [88, 89], [90, 92], [93, 103], [104, 113], [114, 117], [118, 123], [124, 126], [127, 130], [131, 133], [134, 142], [142, 143], [144, 148], [149, 151], [152, 160], [161, 168], [168, 169], [170, 172], [173, 181], [182, 187], [188, 195], [196, 200], [201, 202], [203, 209], [210, 212], [212, 217], [218, 226], [227, 229], [230, 235], [235, 236], [237, 239], [239, 249], [250, 260], [261, 272], [273, 275], [276, 284], [284, 285], [286, 289], [289, 290]]}
{"doc_key": "ai-dev-25", "ner": [[3, 5, "misc"], [7, 7, "field"], [9, 9, "field"], [14, 16, "university"], [18, 20, "university"], [26, 28, "university"], [33, 35, "misc"], [37, 38, "field"], [41, 44, "misc"], [47, 48, "university"], [50, 52, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[3, 5, 7, 7, "topic", "", false, false], [3, 5, 9, 9, "topic", "", false, false], [3, 5, 14, 16, "origin", "", false, false], [14, 16, 18, 20, "part-of", "", false, false], [26, 28, 14, 16, "part-of", "", false, false], [33, 35, 37, 38, "topic", "", false, false], [33, 35, 47, 48, "origin", "", false, false], [41, 44, 47, 48, "origin", "", false, false], [47, 48, 50, 52, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Ha", "conseguito", "un", "dottorato", "di", "ricerca", "in", "Radiofisica", "ed", "Elettronica", "presso", "il", "campus", "del", "Rajabazar", "Science", "College", "dell'", "Universit\u00e0", "di", "Calcutta", "nel", "1979", "come", "studente", "dell'", "Indian", "Statistical", "Institute", ",", "e", "un", "altro", "dottorato", "di", "ricerca", "in", "Ingegneria", "Elettrica", "insieme", "al", "Diploma", "dell'", "Imperial", "College", "presso", "l'", "Imperial", "College", "dell'", "Universit\u00e0", "di", "Londra", "nel", "1982", "."], "sentence-detokenized": "Ha conseguito un dottorato di ricerca in Radiofisica ed Elettronica presso il campus del Rajabazar Science College dell'Universit\u00e0 di Calcutta nel 1979 come studente dell'Indian Statistical Institute, e un altro dottorato di ricerca in Ingegneria Elettrica insieme al Diploma dell'Imperial College presso l'Imperial College dell'Universit\u00e0 di Londra nel 1982.", "token2charspan": [[0, 2], [3, 13], [14, 16], [17, 26], [27, 29], [30, 37], [38, 40], [41, 52], [53, 55], [56, 67], [68, 74], [75, 77], [78, 84], [85, 88], [89, 98], [99, 106], [107, 114], [115, 120], [120, 130], [131, 133], [134, 142], [143, 146], [147, 151], [152, 156], [157, 165], [166, 171], [171, 177], [178, 189], [190, 199], [199, 200], [201, 202], [203, 205], [206, 211], [212, 221], [222, 224], [225, 232], [233, 235], [236, 246], [247, 256], [257, 264], [265, 267], [268, 275], [276, 281], [281, 289], [290, 297], [298, 304], [305, 307], [307, 315], [316, 323], [324, 329], [329, 339], [340, 342], [343, 349], [350, 353], [354, 358], [358, 359]]}
{"doc_key": "ai-dev-26", "ner": [[0, 2, "location"], [20, 22, "misc"], [29, 30, "misc"], [32, 34, "person"], [36, 37, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[20, 22, 0, 2, "temporal", "", false, false], [29, 30, 0, 2, "temporal", "", false, false], [32, 34, 29, 30, "role", "actor_in", false, false], [36, 37, 29, 30, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["All'", "Expo", "II", "\u00e8", "stata", "annunciata", "l'", "anteprima", "mondiale", "di", "diversi", "film", "mai", "visti", "prima", "in", "3D", ",", "tra", "cui", "The", "Diamond", "Wizard", "e", "il", "cortometraggio", "della", "Universal", ",", "Hawaiian", "Nights", "con", "Mamie", "Van", "Doren", "e", "Pinky", "Lee", "."], "sentence-detokenized": "All'Expo II \u00e8 stata annunciata l'anteprima mondiale di diversi film mai visti prima in 3D, tra cui The Diamond Wizard e il cortometraggio della Universal, Hawaiian Nights con Mamie Van Doren e Pinky Lee.", "token2charspan": [[0, 4], [4, 8], [9, 11], [12, 13], [14, 19], [20, 30], [31, 33], [33, 42], [43, 51], [52, 54], [55, 62], [63, 67], [68, 71], [72, 77], [78, 83], [84, 86], [87, 89], [89, 90], [91, 94], [95, 98], [99, 102], [103, 110], [111, 117], [118, 119], [120, 122], [123, 137], [138, 143], [144, 153], [153, 154], [155, 163], [164, 170], [171, 174], [175, 180], [181, 184], [185, 190], [191, 192], [193, 198], [199, 202], [202, 203]]}
{"doc_key": "ai-dev-27", "ner": [[9, 10, "researcher"], [18, 21, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 10, 18, 21, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Il", "problema", "del", "massimo", "subarray", "\u00e8", "stato", "proposto", "da", "Ulf", "Grenander", "nel", "1977", "come", "modello", "semplificato", "per", "la", "stima", "della", "massima", "verosimiglianza", "di", "modelli", "in", "immagini", "digitalizzate", "."], "sentence-detokenized": "Il problema del massimo subarray \u00e8 stato proposto da Ulf Grenander nel 1977 come modello semplificato per la stima della massima verosimiglianza di modelli in immagini digitalizzate.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 23], [24, 32], [33, 34], [35, 40], [41, 49], [50, 52], [53, 56], [57, 66], [67, 70], [71, 75], [76, 80], [81, 88], [89, 101], [102, 105], [106, 108], [109, 114], [115, 120], [121, 128], [129, 144], [145, 147], [148, 155], [156, 158], [159, 167], [168, 181], [181, 182]]}
{"doc_key": "ai-dev-28", "ner": [[1, 2, "product"], [5, 6, "product"], [9, 11, "product"], [14, 15, "product"], [18, 20, "product"], [23, 25, "product"], [38, 38, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[38, 38, 1, 2, "part-of", "", false, false], [38, 38, 5, 6, "part-of", "", false, false], [38, 38, 9, 11, "part-of", "", false, false], [38, 38, 14, 15, "part-of", "", false, false], [38, 38, 18, 20, "part-of", "", false, false], [38, 38, 23, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["L'", "iPhone", "4S", ",", "l'", "iPad", "3", ",", "l'", "iPad", "Mini", "1G", ",", "l'", "iPad", "Air", ",", "l'", "iPad", "Pro", "1G", ",", "l'", "iPod", "Touch", "5G", "e", "successivi", "sono", "tutti", "dotati", "di", "un", "assistente", "vocale", "pi\u00f9", "avanzato", "chiamato", "Siri", "."], "sentence-detokenized": "L'iPhone 4S, l'iPad 3, l'iPad Mini 1G, l'iPad Air, l'iPad Pro 1G, l'iPod Touch 5G e successivi sono tutti dotati di un assistente vocale pi\u00f9 avanzato chiamato Siri.", "token2charspan": [[0, 2], [2, 8], [9, 11], [11, 12], [13, 15], [15, 19], [20, 21], [21, 22], [23, 25], [25, 29], [30, 34], [35, 37], [37, 38], [39, 41], [41, 45], [46, 49], [49, 50], [51, 53], [53, 57], [58, 61], [62, 64], [64, 65], [66, 68], [68, 72], [73, 78], [79, 81], [82, 83], [84, 94], [95, 99], [100, 105], [106, 112], [113, 115], [116, 118], [119, 129], [130, 136], [137, 140], [141, 149], [150, 158], [159, 163], [163, 164]]}
{"doc_key": "ai-dev-29", "ner": [[5, 6, "metrics"], [9, 13, "metrics"], [15, 16, "metrics"], [36, 39, "metrics"], [44, 48, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 13, 36, 39, "named", "", false, false], [15, 16, 9, 13, "named", "", false, false], [36, 39, 44, 48, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["\u00c8", "facile", "verificare", "che", "la", "perdita", "logistica", "e", "la", "perdita", "di", "entropia", "incrociata", "binaria", "(", "Log", "loss", ")", "sono", "di", "fatto", "uguali", "(", "fino", "a", "una", "costante", "moltiplicativa", "math", "\\", "frac", "{", "1", "}", "{", "La", "perdita", "di", "entropia", "incrociata", "\u00e8", "strettamente", "correlata", "alla", "divergenza", "di", "Kullback", "-", "Leibler", "tra", "la", "distribuzione", "empirica", "e", "quella", "prevista", "."], "sentence-detokenized": "\u00c8 facile verificare che la perdita logistica e la perdita di entropia incrociata binaria (Log loss) sono di fatto uguali (fino a una costante moltiplicativa math\\ frac {1} {La perdita di entropia incrociata \u00e8 strettamente correlata alla divergenza di Kullback-Leibler tra la distribuzione empirica e quella prevista.", "token2charspan": [[0, 1], [2, 8], [9, 19], [20, 23], [24, 26], [27, 34], [35, 44], [45, 46], [47, 49], [50, 57], [58, 60], [61, 69], [70, 80], [81, 88], [89, 90], [90, 93], [94, 98], [98, 99], [100, 104], [105, 107], [108, 113], [114, 120], [121, 122], [122, 126], [127, 128], [129, 132], [133, 141], [142, 156], [157, 161], [161, 162], [163, 167], [168, 169], [169, 170], [170, 171], [172, 173], [173, 175], [176, 183], [184, 186], [187, 195], [196, 206], [207, 208], [209, 221], [222, 231], [232, 236], [237, 247], [248, 250], [251, 259], [259, 260], [260, 267], [268, 271], [272, 274], [275, 288], [289, 297], [298, 299], [300, 306], [307, 315], [315, 316]]}
{"doc_key": "ai-dev-30", "ner": [[1, 2, "algorithm"], [9, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 1, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["L'", "algoritmo", "EM", "viene", "utilizzato", "per", "trovare", "i", "parametri", "di", "massima", "verosimiglianza", "(", "locale", ")", "di", "un", "modello", "statistico", "nei", "casi", "in", "cui", "le", "equazioni", "non", "possono", "essere", "risolte", "direttamente", "."], "sentence-detokenized": "L'algoritmo EM viene utilizzato per trovare i parametri di massima verosimiglianza (locale) di un modello statistico nei casi in cui le equazioni non possono essere risolte direttamente.", "token2charspan": [[0, 2], [2, 11], [12, 14], [15, 20], [21, 31], [32, 35], [36, 43], [44, 45], [46, 55], [56, 58], [59, 66], [67, 82], [83, 84], [84, 90], [90, 91], [92, 94], [95, 97], [98, 105], [106, 116], [117, 120], [121, 125], [126, 128], [129, 132], [133, 135], [136, 145], [146, 149], [150, 157], [158, 164], [165, 172], [173, 185], [185, 186]]}
{"doc_key": "ai-dev-31", "ner": [[12, 13, "task"], [16, 21, "task"], [26, 26, "task"], [29, 30, "task"], [35, 39, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Queste", "ricerche", "sono", "state", "fondamentali", "per", "lo", "sviluppo", "delle", "moderne", "tecniche", "di", "sintesi", "vocale", ",", "delle", "macchine", "di", "lettura", "per", "non", "vedenti", ",", "dello", "studio", "della", "percezione", "e", "del", "riconoscimento", "vocale", "e", "dello", "sviluppo", "della", "teoria", "motoria", "della", "percezione", "vocale", "."], "sentence-detokenized": "Queste ricerche sono state fondamentali per lo sviluppo delle moderne tecniche di sintesi vocale, delle macchine di lettura per non vedenti, dello studio della percezione e del riconoscimento vocale e dello sviluppo della teoria motoria della percezione vocale.", "token2charspan": [[0, 6], [7, 15], [16, 20], [21, 26], [27, 39], [40, 43], [44, 46], [47, 55], [56, 61], [62, 69], [70, 78], [79, 81], [82, 89], [90, 96], [96, 97], [98, 103], [104, 112], [113, 115], [116, 123], [124, 127], [128, 131], [132, 139], [139, 140], [141, 146], [147, 153], [154, 159], [160, 170], [171, 172], [173, 176], [177, 191], [192, 198], [199, 200], [201, 206], [207, 215], [216, 221], [222, 228], [229, 236], [237, 242], [243, 253], [254, 260], [260, 261]]}
{"doc_key": "ai-dev-32", "ner": [[8, 8, "product"], [1, 4, "misc"], [6, 6, "misc"], [11, 12, "misc"], [15, 15, "product"], [17, 17, "product"], [19, 19, "product"], [26, 26, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[1, 4, 8, 8, "origin", "", false, false], [1, 4, 11, 12, "type-of", "", false, false], [1, 4, 15, 15, "related-to", "program_for", false, false], [1, 4, 17, 17, "related-to", "program_for", false, false], [1, 4, 19, 19, "related-to", "program_for", false, false], [1, 4, 26, 26, "related-to", "program_for", false, false], [6, 6, 1, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["L'", "ambiente", "di", "sviluppo", "integrato", "(", "IDE", ")", "Arduino", "\u00e8", "un'", "applicazione", "multipiattaforma", "(", "per", "Windows", ",", "macOS", "e", "Linux", ")", "scritta", "nel", "linguaggio", "di", "programmazione", "Java", "."], "sentence-detokenized": "L'ambiente di sviluppo integrato (IDE) Arduino \u00e8 un'applicazione multipiattaforma (per Windows, macOS e Linux) scritta nel linguaggio di programmazione Java.", "token2charspan": [[0, 2], [2, 10], [11, 13], [14, 22], [23, 32], [33, 34], [34, 37], [37, 38], [39, 46], [47, 48], [49, 52], [52, 64], [65, 81], [82, 83], [83, 86], [87, 94], [94, 95], [96, 101], [102, 103], [104, 109], [109, 110], [111, 118], [119, 122], [123, 133], [134, 136], [137, 151], [152, 156], [156, 157]]}
{"doc_key": "ai-dev-33", "ner": [[3, 4, "algorithm"], [13, 15, "field"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 13, 15, "opposite", "", false, false], [16, 17, 13, 15, "related-to", "works_with", false, false], [19, 20, 13, 15, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "ricerca", "sulle", "reti", "neurali", "ha", "ristagnato", "dopo", "la", "pubblicazione", "delle", "ricerche", "sull'", "apprendimento", "automatico", "di", "Marvin", "Minsky", "e", "Seymour", "Papert", "(", "1969", ")", "."], "sentence-detokenized": "La ricerca sulle reti neurali ha ristagnato dopo la pubblicazione delle ricerche sull'apprendimento automatico di Marvin Minsky e Seymour Papert (1969).", "token2charspan": [[0, 2], [3, 10], [11, 16], [17, 21], [22, 29], [30, 32], [33, 43], [44, 48], [49, 51], [52, 65], [66, 71], [72, 80], [81, 86], [86, 99], [100, 110], [111, 113], [114, 120], [121, 127], [128, 129], [130, 137], [138, 144], [145, 146], [146, 150], [150, 151], [151, 152]]}
{"doc_key": "ai-dev-34", "ner": [[19, 20, "organisation"], [22, 22, "organisation"], [26, 28, "country"], [29, 32, "organisation"], [36, 36, "country"], [37, 38, "organisation"], [42, 42, "country"], [43, 43, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[29, 32, 26, 28, "general-affiliation", "", false, false], [37, 38, 36, 36, "general-affiliation", "", false, false], [43, 43, 42, 42, "general-affiliation", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Solo", "poche", "aziende", "non", "giapponesi", "sono", "riuscite", "a", "sopravvivere", "in", "questo", "mercato", ",", "le", "principali", "delle", "quali", "sono", ":", "Adept", "Technology", ",", "St\u00e4ubli", ",", "l'", "azienda", "svedese", "-", "svizzera", "ABB", "Asea", "Brown", "Boveri", ",", "l'", "azienda", "tedesca", "KUKA", "Robotics", "e", "l'", "azienda", "italiana", "Comau", "."], "sentence-detokenized": "Solo poche aziende non giapponesi sono riuscite a sopravvivere in questo mercato, le principali delle quali sono: Adept Technology, St\u00e4ubli, l'azienda svedese-svizzera ABB Asea Brown Boveri, l'azienda tedesca KUKA Robotics e l'azienda italiana Comau.", "token2charspan": [[0, 4], [5, 10], [11, 18], [19, 22], [23, 33], [34, 38], [39, 47], [48, 49], [50, 62], [63, 65], [66, 72], [73, 80], [80, 81], [82, 84], [85, 95], [96, 101], [102, 107], [108, 112], [112, 113], [114, 119], [120, 130], [130, 131], [132, 139], [139, 140], [141, 143], [143, 150], [151, 158], [158, 159], [159, 167], [168, 171], [172, 176], [177, 182], [183, 189], [189, 190], [191, 193], [193, 200], [201, 208], [209, 213], [214, 222], [223, 224], [225, 227], [227, 234], [235, 243], [244, 249], [249, 250]]}
{"doc_key": "ai-dev-35", "ner": [[10, 11, "conference"], [16, 16, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 16, 10, 11, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Le", "attivit\u00e0", "di", "ricerca", "comprendono", "una", "conferenza", "annuale", ",", "il", "RuleML", "Symposium", ",", "noto", "anche", "come", "RuleML", "."], "sentence-detokenized": "Le attivit\u00e0 di ricerca comprendono una conferenza annuale, il RuleML Symposium, noto anche come RuleML.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 22], [23, 34], [35, 38], [39, 49], [50, 57], [57, 58], [59, 61], [62, 68], [69, 78], [78, 79], [80, 84], [85, 90], [91, 95], [96, 102], [102, 103]]}
{"doc_key": "ai-dev-36", "ner": [[10, 10, "field"], [12, 12, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["I", "concetti", "sono", "utilizzati", "come", "strumenti", "o", "modelli", "formali", "in", "matematica", ",", "informatica", ",", "banche", "dati", "e", "intelligenza", "artificiale", ",", "dove", "sono", "talvolta", "chiamati", "classi", ",", "schemi", "o", "categorie", "."], "sentence-detokenized": "I concetti sono utilizzati come strumenti o modelli formali in matematica, informatica, banche dati e intelligenza artificiale, dove sono talvolta chiamati classi, schemi o categorie.", "token2charspan": [[0, 1], [2, 10], [11, 15], [16, 26], [27, 31], [32, 41], [42, 43], [44, 51], [52, 59], [60, 62], [63, 73], [73, 74], [75, 86], [86, 87], [88, 94], [95, 99], [100, 101], [102, 114], [115, 126], [126, 127], [128, 132], [133, 137], [138, 146], [147, 155], [156, 162], [162, 163], [164, 170], [171, 172], [173, 182], [182, 183]]}
{"doc_key": "ai-dev-37", "ner": [[4, 6, "organisation"], [9, 12, "organisation"], [15, 15, "organisation"], [18, 20, "organisation"], [23, 25, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["\u00c8", "stato", "premiato", "dall'", "American", "Psychological", "Association", ",", "dalla", "National", "Academy", "of", "Sciences", ",", "dalla", "Royal", ",", "dalla", "Cognitive", "Neuroscience", "Society", "e", "dall'", "American", "Humanist", "Association", "."], "sentence-detokenized": "\u00c8 stato premiato dall'American Psychological Association, dalla National Academy of Sciences, dalla Royal, dalla Cognitive Neuroscience Society e dall'American Humanist Association.", "token2charspan": [[0, 1], [2, 7], [8, 16], [17, 22], [22, 30], [31, 44], [45, 56], [56, 57], [58, 63], [64, 72], [73, 80], [81, 83], [84, 92], [92, 93], [94, 99], [100, 105], [105, 106], [107, 112], [113, 122], [123, 135], [136, 143], [144, 145], [146, 151], [151, 159], [160, 168], [169, 180], [180, 181]]}
{"doc_key": "ai-dev-38", "ner": [[2, 3, "person"], [5, 6, "person"], [8, 9, "person"], [17, 19, "person"], [20, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[20, 26, 17, 19, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Interpretato", "da", "Harrison", "Ford", ",", "Rutger", "Hauer", "e", "Sean", "Young", ",", "\u00e8", "liberamente", "tratto", "dal", "romanzo", "di", "Philip", "K.", "Dick", "Do", "Androids", "Dream", "of", "Electric", "Sheep", "?", "(", "1968", ")", "."], "sentence-detokenized": "Interpretato da Harrison Ford, Rutger Hauer e Sean Young, \u00e8 liberamente tratto dal romanzo di Philip K. Dick Do Androids Dream of Electric Sheep? (1968).", "token2charspan": [[0, 12], [13, 15], [16, 24], [25, 29], [29, 30], [31, 37], [38, 43], [44, 45], [46, 50], [51, 56], [56, 57], [58, 59], [60, 71], [72, 78], [79, 82], [83, 90], [91, 93], [94, 100], [101, 103], [104, 108], [109, 111], [112, 120], [121, 126], [127, 129], [130, 138], [139, 144], [144, 145], [146, 147], [147, 151], [151, 152], [152, 153]]}
{"doc_key": "ai-dev-39", "ner": [[0, 3, "task"], [5, 8, "algorithm"], [16, 18, "field"], [21, 23, "task"], [26, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 5, 8, "usage", "", false, false], [0, 3, 16, 18, "part-of", "task_part_of_field", false, false], [0, 3, 21, 23, "part-of", "task_part_of_field", false, false], [0, 3, 26, 27, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["La", "segmentazione", "delle", "immagini", "mediante", "algoritmi", "di", "clustering", "k-means", "\u00e8", "stata", "a", "lungo", "utilizzata", "per", "il", "riconoscimento", "di", "pattern", ",", "il", "rilevamento", "di", "oggetti", "e", "l'", "imaging", "medico", "."], "sentence-detokenized": "La segmentazione delle immagini mediante algoritmi di clustering k-means \u00e8 stata a lungo utilizzata per il riconoscimento di pattern, il rilevamento di oggetti e l'imaging medico.", "token2charspan": [[0, 2], [3, 16], [17, 22], [23, 31], [32, 40], [41, 50], [51, 53], [54, 64], [65, 72], [73, 74], [75, 80], [81, 82], [83, 88], [89, 99], [100, 103], [104, 106], [107, 121], [122, 124], [125, 132], [132, 133], [134, 136], [137, 148], [149, 151], [152, 159], [160, 161], [162, 164], [164, 171], [172, 178], [178, 179]]}
{"doc_key": "ai-dev-40", "ner": [[12, 12, "algorithm"], [16, 17, "algorithm"], [20, 20, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Il", "campionamento", "generale", "dalla", "normale", "troncata", "pu\u00f2", "essere", "ottenuto", "utilizzando", "approssimazioni", "alla", "CDF", "normale", "e", "alla", "funzione", "probit", ",", "e", "R", "ha", "una", "funzione", "codertnorm", "(", ")", "/", "codice", "per", "generare", "campioni", "di", "normali", "troncate", "."], "sentence-detokenized": "Il campionamento generale dalla normale troncata pu\u00f2 essere ottenuto utilizzando approssimazioni alla CDF normale e alla funzione probit, e R ha una funzione codertnorm () / codice per generare campioni di normali troncate.", "token2charspan": [[0, 2], [3, 16], [17, 25], [26, 31], [32, 39], [40, 48], [49, 52], [53, 59], [60, 68], [69, 80], [81, 96], [97, 101], [102, 105], [106, 113], [114, 115], [116, 120], [121, 129], [130, 136], [136, 137], [138, 139], [140, 141], [142, 144], [145, 148], [149, 157], [158, 168], [169, 170], [170, 171], [172, 173], [174, 180], [181, 184], [185, 193], [194, 202], [203, 205], [206, 213], [214, 222], [222, 223]]}
{"doc_key": "ai-dev-41", "ner": [[6, 8, "university"], [10, 10, "university"], [12, 14, "university"], [16, 18, "university"], [20, 22, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ha", "inoltre", "ricevuto", "dottorati", "onorari", "dalle", "universit\u00e0", "di", "Newcastle", ",", "Surrey", ",", "Tel", "Aviv", "University", ",", "Simon", "Fraser", "University", "e", "Universit\u00e0", "di", "Troms\u00f8", "."], "sentence-detokenized": "Ha inoltre ricevuto dottorati onorari dalle universit\u00e0 di Newcastle, Surrey, Tel Aviv University, Simon Fraser University e Universit\u00e0 di Troms\u00f8.", "token2charspan": [[0, 2], [3, 10], [11, 19], [20, 29], [30, 37], [38, 43], [44, 54], [55, 57], [58, 67], [67, 68], [69, 75], [75, 76], [77, 80], [81, 85], [86, 96], [96, 97], [98, 103], [104, 110], [111, 121], [122, 123], [124, 134], [135, 137], [138, 144], [144, 145]]}
{"doc_key": "ai-dev-42", "ner": [[2, 2, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Un'", "implementazione", "Java", "che", "utilizza", "indici", "di", "array", "basati", "su", "zero", "e", "un", "metodo", "pratico", "per", "stampare", "l'", "ordine", "risolto", "delle", "operazioni", ":"], "sentence-detokenized": "Un'implementazione Java che utilizza indici di array basati su zero e un metodo pratico per stampare l'ordine risolto delle operazioni:", "token2charspan": [[0, 3], [3, 18], [19, 23], [24, 27], [28, 36], [37, 43], [44, 46], [47, 52], [53, 59], [60, 62], [63, 67], [68, 69], [70, 72], [73, 79], [80, 87], [88, 91], [92, 100], [101, 103], [103, 109], [110, 117], [118, 123], [124, 134], [134, 135]]}
{"doc_key": "ai-dev-43", "ner": [[9, 10, "metrics"], [13, 15, "metrics"], [24, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 15, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Tali", "reti", "sono", "comunemente", "addestrate", "in", "un", "regime", "di", "entropia", "incrociata", "(", "o", "cross", "-", "entropia", ")", ",", "fornendo", "una", "variante", "non", "lineare", "della", "regressione", "logistica", "multinomiale", "."], "sentence-detokenized": "Tali reti sono comunemente addestrate in un regime di entropia incrociata (o cross-entropia), fornendo una variante non lineare della regressione logistica multinomiale.", "token2charspan": [[0, 4], [5, 9], [10, 14], [15, 26], [27, 37], [38, 40], [41, 43], [44, 50], [51, 53], [54, 62], [63, 73], [74, 75], [75, 76], [77, 82], [82, 83], [83, 91], [91, 92], [92, 93], [94, 102], [103, 106], [107, 115], [116, 119], [120, 127], [128, 133], [134, 145], [146, 155], [156, 168], [168, 169]]}
{"doc_key": "ai-dev-44", "ner": [[1, 1, "conference"], [5, 5, "misc"], [4, 14, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 1, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["L'", "ACL", "ha", "un", "capitolo", "europeo", "(", "European", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ")", "."], "sentence-detokenized": "L'ACL ha un capitolo europeo (European Chapter of the Association for Computational Linguistics).", "token2charspan": [[0, 2], [2, 5], [6, 8], [9, 11], [12, 20], [21, 28], [29, 30], [30, 38], [39, 46], [47, 49], [50, 53], [54, 65], [66, 69], [70, 83], [84, 95], [95, 96], [96, 97]]}
{"doc_key": "ai-dev-45", "ner": [[3, 4, "researcher"], [6, 8, "researcher"], [28, 28, "misc"], [30, 31, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 28, 28, "role", "", false, false], [6, 8, 28, 28, "role", "", false, false], [28, 28, 30, 31, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Due", "professori", ",", "Hal", "Abelson", "e", "Gerald", "Jay", "Sussman", ",", "scelsero", "di", "rimanere", "neutrali", ":", "per", "i", "successivi", "30", "anni", "il", "loro", "gruppo", "fu", "chiamato", "in", "vario", "modo", "Svizzera", "e", "Progetto", "MAC."], "sentence-detokenized": "Due professori, Hal Abelson e Gerald Jay Sussman, scelsero di rimanere neutrali: per i successivi 30 anni il loro gruppo fu chiamato in vario modo Svizzera e Progetto MAC.", "token2charspan": [[0, 3], [4, 14], [14, 15], [16, 19], [20, 27], [28, 29], [30, 36], [37, 40], [41, 48], [48, 49], [50, 58], [59, 61], [62, 70], [71, 79], [79, 80], [81, 84], [85, 86], [87, 97], [98, 100], [101, 105], [106, 108], [109, 113], [114, 120], [121, 123], [124, 132], [133, 135], [136, 141], [142, 146], [147, 155], [156, 157], [158, 166], [167, 171]]}
{"doc_key": "ai-dev-46", "ner": [[2, 2, "misc"], [6, 8, "researcher"], [11, 13, "university"], [17, 19, "organisation"], [20, 23, "organisation"], [27, 28, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 6, 8, "temporal", "", false, false], [6, 8, 17, 19, "physical", "", false, false], [6, 8, 17, 19, "role", "", false, false], [6, 8, 20, 23, "role", "", false, false], [20, 23, 11, 13, "part-of", "", false, false], [27, 28, 20, 23, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Dopo", "il", "dottorato", ",", "nel", "1995", "Ghahramani", "si", "\u00e8", "trasferito", "all'", "Universit\u00e0", "di", "Toronto", "come", "Postdoctoral", "Fellow", "dell'", "ITRC", "nel", "Laboratorio", "di", "Intelligenza", "Artificiale", ",", "lavorando", "con", "Geoffrey", "Hinton", "."], "sentence-detokenized": "Dopo il dottorato, nel 1995 Ghahramani si \u00e8 trasferito all'Universit\u00e0 di Toronto come Postdoctoral Fellow dell'ITRC nel Laboratorio di Intelligenza Artificiale, lavorando con Geoffrey Hinton.", "token2charspan": [[0, 4], [5, 7], [8, 17], [17, 18], [19, 22], [23, 27], [28, 38], [39, 41], [42, 43], [44, 54], [55, 59], [59, 69], [70, 72], [73, 80], [81, 85], [86, 98], [99, 105], [106, 111], [111, 115], [116, 119], [120, 131], [132, 134], [135, 147], [148, 159], [159, 160], [161, 170], [171, 174], [175, 183], [184, 190], [190, 191]]}
{"doc_key": "ai-dev-47", "ner": [[30, 31, "metrics"], [33, 33, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[33, 33, 30, 31, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["I", "lavori", "successivi", "si", "sono", "concentrati", "sulla", "risoluzione", "di", "questi", "problemi", ",", "ma", "\u00e8", "stato", "solo", "con", "l'", "avvento", "del", "computer", "moderno", "e", "la", "diffusione", "delle", "tecniche", "di", "parametrizzazione", "della", "massima", "verosimiglianza", "(", "MLE", ")", "che", "la", "ricerca", "ha", "preso", "davvero", "piede", "."], "sentence-detokenized": "I lavori successivi si sono concentrati sulla risoluzione di questi problemi, ma \u00e8 stato solo con l'avvento del computer moderno e la diffusione delle tecniche di parametrizzazione della massima verosimiglianza (MLE) che la ricerca ha preso davvero piede.", "token2charspan": [[0, 1], [2, 8], [9, 19], [20, 22], [23, 27], [28, 39], [40, 45], [46, 57], [58, 60], [61, 67], [68, 76], [76, 77], [78, 80], [81, 82], [83, 88], [89, 93], [94, 97], [98, 100], [100, 107], [108, 111], [112, 120], [121, 128], [129, 130], [131, 133], [134, 144], [145, 150], [151, 159], [160, 162], [163, 180], [181, 186], [187, 194], [195, 210], [211, 212], [212, 215], [215, 216], [217, 220], [221, 223], [224, 231], [232, 234], [235, 240], [241, 248], [249, 254], [254, 255]]}
{"doc_key": "ai-dev-48", "ner": [[6, 7, "person"], [11, 12, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "serie", "\u00e8", "stata", "prodotta", "da", "David", "Fincher", "e", "interpretata", "da", "Kevin", "Spacey", "."], "sentence-detokenized": "La serie \u00e8 stata prodotta da David Fincher e interpretata da Kevin Spacey.", "token2charspan": [[0, 2], [3, 8], [9, 10], [11, 16], [17, 25], [26, 28], [29, 34], [35, 42], [43, 44], [45, 57], [58, 60], [61, 66], [67, 73], [73, 74]]}
{"doc_key": "ai-dev-49", "ner": [[21, 21, "metrics"], [30, 32, "algorithm"], [35, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[30, 32, 35, 38, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "causa", "dei", "limiti", "della", "potenza", "di", "calcolo", ",", "gli", "attuali", "metodi", "in", "silico", "devono", "solitamente", "scambiare", "la", "velocit\u00e0", "con", "l'", "accuratezza", ";", "ad", "esempio", ",", "utilizzare", "metodi", "rapidi", "di", "docking", "delle", "proteine", "invece", "di", "calcoli", "dell'", "energia", "libera", "costosi", "dal", "punto", "di", "vista", "computazionale", "."], "sentence-detokenized": "A causa dei limiti della potenza di calcolo, gli attuali metodi in silico devono solitamente scambiare la velocit\u00e0 con l'accuratezza; ad esempio, utilizzare metodi rapidi di docking delle proteine invece di calcoli dell'energia libera costosi dal punto di vista computazionale.", "token2charspan": [[0, 1], [2, 7], [8, 11], [12, 18], [19, 24], [25, 32], [33, 35], [36, 43], [43, 44], [45, 48], [49, 56], [57, 63], [64, 66], [67, 73], [74, 80], [81, 92], [93, 102], [103, 105], [106, 114], [115, 118], [119, 121], [121, 132], [132, 133], [134, 136], [137, 144], [144, 145], [146, 156], [157, 163], [164, 170], [171, 173], [174, 181], [182, 187], [188, 196], [197, 203], [204, 206], [207, 214], [215, 220], [220, 227], [228, 234], [235, 242], [243, 246], [247, 252], [253, 255], [256, 261], [262, 276], [276, 277]]}
{"doc_key": "ai-dev-50", "ner": [[5, 6, "country"], [9, 9, "country"], [11, 11, "country"], [13, 13, "country"], [15, 15, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Aveva", "oltre", "30", "sedi", "negli", "Stati", "Uniti", ",", "in", "Canada", ",", "Messico", ",", "Brasile", "e", "Argentina", "."], "sentence-detokenized": "Aveva oltre 30 sedi negli Stati Uniti, in Canada, Messico, Brasile e Argentina.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 19], [20, 25], [26, 31], [32, 37], [37, 38], [39, 41], [42, 48], [48, 49], [50, 57], [57, 58], [59, 66], [67, 68], [69, 78], [78, 79]]}
{"doc_key": "ai-dev-51", "ner": [[9, 10, "field"], [13, 16, "product"], [19, 21, "algorithm"], [30, 34, "task"], [37, 39, "task"], [44, 44, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 16, 9, 10, "part-of", "", false, false], [13, 16, 19, 21, "usage", "", false, false], [30, 34, 9, 10, "part-of", "task_part_of_field", false, false], [30, 34, 44, 44, "related-to", "performs", false, false], [37, 39, 9, 10, "part-of", "task_part_of_field", false, false], [37, 39, 44, 44, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Un", "esempio", "di", "una", "tipica", "pipeline", "di", "calcolo", "di", "computer", "vision", "per", "un", "sistema", "di", "riconoscimento", "facciale", "che", "utilizza", "k", "-", "NN", ",", "comprese", "le", "fasi", "di", "pre", "-", "processing", "per", "l'", "estrazione", "delle", "caratteristiche", "e", "la", "riduzione", "delle", "dimensioni", "(", "solitamente", "implementate", "con", "OpenCV", ")", ":"], "sentence-detokenized": "Un esempio di una tipica pipeline di calcolo di computer vision per un sistema di riconoscimento facciale che utilizza k -NN, comprese le fasi di pre-processing per l'estrazione delle caratteristiche e la riduzione delle dimensioni (solitamente implementate con OpenCV):", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 17], [18, 24], [25, 33], [34, 36], [37, 44], [45, 47], [48, 56], [57, 63], [64, 67], [68, 70], [71, 78], [79, 81], [82, 96], [97, 105], [106, 109], [110, 118], [119, 120], [121, 122], [122, 124], [124, 125], [126, 134], [135, 137], [138, 142], [143, 145], [146, 149], [149, 150], [150, 160], [161, 164], [165, 167], [167, 177], [178, 183], [184, 199], [200, 201], [202, 204], [205, 214], [215, 220], [221, 231], [232, 233], [233, 244], [245, 257], [258, 261], [262, 268], [268, 269], [269, 270]]}
{"doc_key": "ai-dev-52", "ner": [[11, 14, "algorithm"], [16, 16, "misc"], [18, 19, "misc"], [23, 23, "programlang"], [25, 25, "product"], [29, 30, "algorithm"], [33, 34, "misc"], [36, 36, "misc"], [38, 38, "misc"], [40, 40, "misc"], [50, 50, "misc"], [52, 55, "misc"], [54, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [], "relations_mapping_to_source": [], "sentence": ["Dispone", "di", "un", "ricco", "insieme", "di", "funzionalit\u00e0", ",", "librerie", "per", "la", "programmazione", "logica", "a", "vincoli", ",", "multithreading", ",", "test", "unitari", ",", "interfacciamento", "con", "Java", ",", "ODBC", "e", "altri", ",", "programmazione", "letterale", ",", "un", "server", "web", ",", "SGML", ",", "RDF", ",", "RDFS", ",", "strumenti", "per", "gli", "sviluppatori", "(", "tra", "cui", "un", "IDE", "con", "debugger", "e", "profiler", "GUI", ")", "e", "un'", "ampia", "documentazione", "."], "sentence-detokenized": "Dispone di un ricco insieme di funzionalit\u00e0, librerie per la programmazione logica a vincoli, multithreading, test unitari, interfacciamento con Java, ODBC e altri, programmazione letterale, un server web, SGML, RDF, RDFS, strumenti per gli sviluppatori (tra cui un IDE con debugger e profiler GUI) e un'ampia documentazione.", "token2charspan": [[0, 7], [8, 10], [11, 13], [14, 19], [20, 27], [28, 30], [31, 43], [43, 44], [45, 53], [54, 57], [58, 60], [61, 75], [76, 82], [83, 84], [85, 92], [92, 93], [94, 108], [108, 109], [110, 114], [115, 122], [122, 123], [124, 140], [141, 144], [145, 149], [149, 150], [151, 155], [156, 157], [158, 163], [163, 164], [165, 179], [180, 189], [189, 190], [191, 193], [194, 200], [201, 204], [204, 205], [206, 210], [210, 211], [212, 215], [215, 216], [217, 221], [221, 222], [223, 232], [233, 236], [237, 240], [241, 253], [254, 255], [255, 258], [259, 262], [263, 265], [266, 269], [270, 273], [274, 282], [283, 284], [285, 293], [294, 297], [297, 298], [299, 300], [301, 304], [304, 309], [310, 324], [324, 325]]}
{"doc_key": "ai-dev-53", "ner": [[1, 2, "field"], [5, 7, "field"], [12, 16, "misc"], [19, 22, "misc"], [25, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 16, 1, 2, "part-of", "", true, false], [12, 16, 5, 7, "part-of", "", false, false], [12, 16, 25, 27, "type-of", "", false, false], [19, 22, 1, 2, "part-of", "", false, false], [19, 22, 5, 7, "part-of", "", false, false], [19, 22, 25, 27, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Nella", "visione", "computerizzata", "e", "nell'", "elaborazione", "delle", "immagini", ",", "la", "nozione", "di", "rappresentazione", "dello", "spazio", "di", "scala", "e", "gli", "operatori", "di", "derivazione", "gaussiana", "sono", "una", "rappresentazione", "multiscala", "canonica", "."], "sentence-detokenized": "Nella visione computerizzata e nell'elaborazione delle immagini, la nozione di rappresentazione dello spazio di scala e gli operatori di derivazione gaussiana sono una rappresentazione multiscala canonica.", "token2charspan": [[0, 5], [6, 13], [14, 28], [29, 30], [31, 36], [36, 48], [49, 54], [55, 63], [63, 64], [65, 67], [68, 75], [76, 78], [79, 95], [96, 101], [102, 108], [109, 111], [112, 117], [118, 119], [120, 123], [124, 133], [134, 136], [137, 148], [149, 158], [159, 163], [164, 167], [168, 184], [185, 195], [196, 204], [204, 205]]}
{"doc_key": "ai-dev-54", "ner": [[4, 8, "organisation"], [19, 27, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 8, 19, 27, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["\u00c8", "anche", "presidente", "della", "Neural", "Information", "Processing", "Systems", "Foundation", ",", "un'", "organizzazione", "senza", "scopo", "di", "lucro", "che", "supervisiona", "la", "conferenza", "annuale", "sui", "sistemi", "di", "elaborazione", "dell'", "informazione", "neurale", "."], "sentence-detokenized": "\u00c8 anche presidente della Neural Information Processing Systems Foundation, un'organizzazione senza scopo di lucro che supervisiona la conferenza annuale sui sistemi di elaborazione dell'informazione neurale.", "token2charspan": [[0, 1], [2, 7], [8, 18], [19, 24], [25, 31], [32, 43], [44, 54], [55, 62], [63, 73], [73, 74], [75, 78], [78, 92], [93, 98], [99, 104], [105, 107], [108, 113], [114, 117], [118, 130], [131, 133], [134, 144], [145, 152], [153, 156], [157, 164], [165, 167], [168, 180], [181, 186], [186, 198], [199, 206], [206, 207]]}
{"doc_key": "ai-dev-55", "ner": [[3, 6, "task"], [11, 12, "metrics"], [14, 16, "misc"], [21, 21, "task"], [26, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 6, 11, 12, "usage", "", false, false], [11, 12, 14, 16, "type-of", "", false, false], [21, 21, 26, 27, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Per", "i", "problemi", "di", "analisi", "della", "regressione", "si", "pu\u00f2", "utilizzare", "l'", "errore", "quadratico", "come", "funzione", "di", "perdita", ",", "mentre", "per", "la", "classificazione", "si", "pu\u00f2", "utilizzare", "l'", "entropia", "incrociata", "."], "sentence-detokenized": "Per i problemi di analisi della regressione si pu\u00f2 utilizzare l'errore quadratico come funzione di perdita, mentre per la classificazione si pu\u00f2 utilizzare l'entropia incrociata.", "token2charspan": [[0, 3], [4, 5], [6, 14], [15, 17], [18, 25], [26, 31], [32, 43], [44, 46], [47, 50], [51, 61], [62, 64], [64, 70], [71, 81], [82, 86], [87, 95], [96, 98], [99, 106], [106, 107], [108, 114], [115, 118], [119, 121], [122, 137], [138, 140], [141, 144], [145, 155], [156, 158], [158, 166], [167, 177], [177, 178]]}
{"doc_key": "ai-dev-56", "ner": [[0, 1, "researcher"], [26, 29, "conference"], [31, 38, "conference"], [55, 55, "university"], [52, 53, "field"], [62, 66, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 26, 29, "role", "", false, false], [0, 1, 55, 55, "physical", "", false, false], [0, 1, 55, 55, "role", "", false, false], [0, 1, 62, 66, "role", "", false, false], [26, 29, 31, 38, "named", "same", false, false], [55, 55, 52, 53, "related-to", "subject_of_study_at", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Lafferty", "ha", "ricoperto", "molti", "incarichi", "prestigiosi", ",", "tra", "cui", ":", "1", ")", "co", "-", "presidente", "del", "programma", "e", "co", "-", "presidente", "generale", "delle", "conferenze", "della", "Fondazione", "Neural", "Information", "Processing", "Systems", "(", "Conferenza", "sui", "sistemi", "di", "elaborazione", "dell'", "informazione", "neurale", ")", ";", "2", ")", "co", "-", "direttore", "del", "nuovo", "programma", "di", "dottorato", "in", "Machine", "Learning", "della", "CMU", ";", "3", ")", "redattore", "associato", "del", "Journal", "of", "Machine", "Learning", "Research", "."], "sentence-detokenized": "Lafferty ha ricoperto molti incarichi prestigiosi, tra cui: 1) co-presidente del programma e co-presidente generale delle conferenze della Fondazione Neural Information Processing Systems (Conferenza sui sistemi di elaborazione dell'informazione neurale); 2) co-direttore del nuovo programma di dottorato in Machine Learning della CMU; 3) redattore associato del Journal of Machine Learning Research.", "token2charspan": [[0, 8], [9, 11], [12, 21], [22, 27], [28, 37], [38, 49], [49, 50], [51, 54], [55, 58], [58, 59], [60, 61], [61, 62], [63, 65], [65, 66], [66, 76], [77, 80], [81, 90], [91, 92], [93, 95], [95, 96], [96, 106], [107, 115], [116, 121], [122, 132], [133, 138], [139, 149], [150, 156], [157, 168], [169, 179], [180, 187], [188, 189], [189, 199], [200, 203], [204, 211], [212, 214], [215, 227], [228, 233], [233, 245], [246, 253], [253, 254], [254, 255], [256, 257], [257, 258], [259, 261], [261, 262], [262, 271], [272, 275], [276, 281], [282, 291], [292, 294], [295, 304], [305, 307], [308, 315], [316, 324], [325, 330], [331, 334], [334, 335], [336, 337], [337, 338], [339, 348], [349, 358], [359, 362], [363, 370], [371, 373], [374, 381], [382, 390], [391, 399], [399, 400]]}
{"doc_key": "ai-dev-57", "ner": [[0, 2, "misc"], [5, 5, "algorithm"], [7, 7, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 0, 2, "type-of", "", false, false], [7, 7, 0, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Gli", "algoritmi", "convessi", ",", "come", "AdaBoost", "e", "LogitBoost", ",", "possono", "essere", "sconfitti", "dal", "rumore", "casuale", ",", "per", "cui", "non", "sono", "in", "grado", "di", "apprendere", "combinazioni", "fondamentali", "e", "apprendibili", "di", "ipotesi", "deboli", "."], "sentence-detokenized": "Gli algoritmi convessi, come AdaBoost e LogitBoost, possono essere sconfitti dal rumore casuale, per cui non sono in grado di apprendere combinazioni fondamentali e apprendibili di ipotesi deboli.", "token2charspan": [[0, 3], [4, 13], [14, 22], [22, 23], [24, 28], [29, 37], [38, 39], [40, 50], [50, 51], [52, 59], [60, 66], [67, 76], [77, 80], [81, 87], [88, 95], [95, 96], [97, 100], [101, 104], [105, 108], [109, 113], [114, 116], [117, 122], [123, 125], [126, 136], [137, 149], [150, 162], [163, 164], [165, 177], [178, 180], [181, 188], [189, 195], [195, 196]]}
{"doc_key": "ai-dev-58", "ner": [[0, 0, "product"], [3, 9, "product"], [12, 15, "algorithm"], [22, 25, "algorithm"], [28, 32, "task"], [35, 39, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 3, 9, "type-of", "", false, false], [0, 0, 12, 15, "usage", "", false, false], [0, 0, 22, 25, "usage", "", false, false], [22, 25, 28, 32, "related-to", "used_for", true, false], [22, 25, 35, 39, "related-to", "used_for", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Apertium", "\u00e8", "un", "sistema", "di", "traduzione", "automatica", "a", "trasferimento", "superficiale", "che", "utilizza", "trasduttori", "a", "stati", "finiti", "per", "tutte", "le", "trasformazioni", "lessicali", "e", "modelli", "di", "Markov", "nascosti", "per", "il", "tagging", "part", "-", "of-", "speech", "o", "la", "disambiguazione", "delle", "categorie", "di", "parole", "."], "sentence-detokenized": "Apertium \u00e8 un sistema di traduzione automatica a trasferimento superficiale che utilizza trasduttori a stati finiti per tutte le trasformazioni lessicali e modelli di Markov nascosti per il tagging part-of-speech o la disambiguazione delle categorie di parole.", "token2charspan": [[0, 8], [9, 10], [11, 13], [14, 21], [22, 24], [25, 35], [36, 46], [47, 48], [49, 62], [63, 75], [76, 79], [80, 88], [89, 100], [101, 102], [103, 108], [109, 115], [116, 119], [120, 125], [126, 128], [129, 143], [144, 153], [154, 155], [156, 163], [164, 166], [167, 173], [174, 182], [183, 186], [187, 189], [190, 197], [198, 202], [202, 203], [203, 206], [206, 212], [213, 214], [215, 217], [218, 233], [234, 239], [240, 249], [250, 252], [253, 259], [259, 260]]}
{"doc_key": "ai-dev-59", "ner": [[1, 2, "misc"], [14, 18, "metrics"], [33, 34, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 14, 18, "related-to", "", true, false], [14, 18, 33, 34, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Il", "gradiente", "naturale", "di", "mathE", "f", "(", "x", ")", "/", "math", ",", "conforme", "alla", "metrica", "dell'", "informazione", "di", "Fisher", "(", "una", "misura", "di", "distanza", "informativa", "tra", "distribuzioni", "di", "probabilit\u00e0", "e", "la", "curvatura", "dell'", "entropia", "relativa", ")", ",", "ora", "recita"], "sentence-detokenized": "Il gradiente naturale di mathE f (x) / math, conforme alla metrica dell'informazione di Fisher (una misura di distanza informativa tra distribuzioni di probabilit\u00e0 e la curvatura dell'entropia relativa), ora recita", "token2charspan": [[0, 2], [3, 12], [13, 21], [22, 24], [25, 30], [31, 32], [33, 34], [34, 35], [35, 36], [37, 38], [39, 43], [43, 44], [45, 53], [54, 58], [59, 66], [67, 72], [72, 84], [85, 87], [88, 94], [95, 96], [96, 99], [100, 106], [107, 109], [110, 118], [119, 130], [131, 134], [135, 148], [149, 151], [152, 163], [164, 165], [166, 168], [169, 178], [179, 184], [184, 192], [193, 201], [201, 202], [202, 203], [204, 207], [208, 214]]}
{"doc_key": "ai-dev-60", "ner": [[1, 5, "programlang"], [9, 12, "product"], [14, 14, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 12, 1, 5, "origin", "", false, false], [14, 14, 1, 5, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Il", "linguaggio", "di", "programmazione", "S", "ha", "ispirato", "i", "sistemi", "S", "'", "-", "PLUS", "e", "R."], "sentence-detokenized": "Il linguaggio di programmazione S ha ispirato i sistemi S '-PLUS e R.", "token2charspan": [[0, 2], [3, 13], [14, 16], [17, 31], [32, 33], [34, 36], [37, 45], [46, 47], [48, 55], [56, 57], [58, 59], [59, 60], [60, 64], [65, 66], [67, 69]]}
{"doc_key": "ai-dev-61", "ner": [[5, 5, "product"], [11, 11, "product"], [14, 16, "product"], [20, 22, "researcher"], [24, 25, "researcher"], [27, 28, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 5, 11, 11, "named", "same", false, false], [14, 16, 11, 11, "origin", "derived_from", false, false], [14, 16, 20, 22, "origin", "", false, false], [14, 16, 24, 25, "origin", "", false, false], [14, 16, 27, 28, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["L'", "implementazione", "pi\u00f9", "influente", "di", "Planner", "\u00e8", "stato", "il", "sottoinsieme", "di", "Planner", ",", "chiamato", "Micro", "-", "Planner", ",", "realizzato", "da", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "e", "Terry", "Winograd", "."], "sentence-detokenized": "L'implementazione pi\u00f9 influente di Planner \u00e8 stato il sottoinsieme di Planner, chiamato Micro-Planner, realizzato da Gerald Jay Sussman, Eugene Charniak e Terry Winograd.", "token2charspan": [[0, 2], [2, 17], [18, 21], [22, 31], [32, 34], [35, 42], [43, 44], [45, 50], [51, 53], [54, 66], [67, 69], [70, 77], [77, 78], [79, 87], [88, 93], [93, 94], [94, 101], [101, 102], [103, 113], [114, 116], [117, 123], [124, 127], [128, 135], [135, 136], [137, 143], [144, 152], [153, 154], [155, 160], [161, 169], [169, 170]]}
{"doc_key": "ai-dev-62", "ner": [[4, 6, "country"], [7, 9, "researcher"], [21, 21, "misc"], [19, 26, "university"], [32, 33, "misc"], [41, 43, "misc"], [49, 51, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "relations": [[7, 9, 4, 6, "general-affiliation", "from_country", false, false], [19, 26, 21, 21, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["Nel", "1779", "lo", "scienziato", "tedesco", "-", "danese", "Christian", "Gottlieb", "Kratzenstein", "vinse", "il", "primo", "premio", "di", "un", "concorso", "indetto", "dall'", "Accademia", "Imperiale", "Russa", "delle", "Scienze", "e", "delle", "Arti", "per", "i", "modelli", "costruiti", "del", "tratto", "vocale", "umano", "in", "grado", "di", "produrre", "i", "cinque", "suoni", "delle", "vocali", "lunghe", "(", "nella", "notazione", "dell'", "Alfabeto", "Fonetico", "Internazionale", ":"], "sentence-detokenized": "Nel 1779 lo scienziato tedesco-danese Christian Gottlieb Kratzenstein vinse il primo premio di un concorso indetto dall'Accademia Imperiale Russa delle Scienze e delle Arti per i modelli costruiti del tratto vocale umano in grado di produrre i cinque suoni delle vocali lunghe (nella notazione dell'Alfabeto Fonetico Internazionale:", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 22], [23, 30], [30, 31], [31, 37], [38, 47], [48, 56], [57, 69], [70, 75], [76, 78], [79, 84], [85, 91], [92, 94], [95, 97], [98, 106], [107, 114], [115, 120], [120, 129], [130, 139], [140, 145], [146, 151], [152, 159], [160, 161], [162, 167], [168, 172], [173, 176], [177, 178], [179, 186], [187, 196], [197, 200], [201, 207], [208, 214], [215, 220], [221, 223], [224, 229], [230, 232], [233, 241], [242, 243], [244, 250], [251, 256], [257, 262], [263, 269], [270, 276], [277, 278], [278, 283], [284, 293], [294, 299], [299, 307], [308, 316], [317, 331], [331, 332]]}
{"doc_key": "ai-dev-63", "ner": [[5, 6, "product"], [10, 11, "misc"], [14, 19, "misc"], [42, 46, "misc"], [71, 73, "task"], [77, 78, "product"], [80, 80, "product"], [85, 88, "task"], [91, 91, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 6, 77, 78, "related-to", "supports_program", false, false], [5, 6, 80, 80, "related-to", "supports_program", false, false], [10, 11, 5, 6, "part-of", "", false, false], [14, 19, 5, 6, "part-of", "", false, false], [42, 46, 5, 6, "part-of", "", false, false], [71, 73, 5, 6, "part-of", "", false, false], [85, 88, 5, 6, "part-of", "", false, false], [91, 91, 5, 6, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Tra", "le", "nuove", "caratteristiche", "di", "Office", "XP", "vi", "sono", "gli", "smart", "tag", ",", "una", "funzione", "di", "ricerca", "basata", "sulla", "selezione", "che", "riconosce", "i", "diversi", "tipi", "di", "testo", "presenti", "in", "un", "documento", "in", "modo", "che", "gli", "utenti", "possano", "eseguire", "azioni", "aggiuntive", ";", "un'", "interfaccia", "del", "riquadro", "delle", "attivit\u00e0", "che", "consolida", "i", "comandi", "pi\u00f9", "diffusi", "della", "barra", "dei", "menu", "sul", "lato", "destro", "dello", "schermo", "per", "facilitarne", "l'", "accesso", "rapido", ";", "nuove", "funzionalit\u00e0", "di", "collaborazione", "tra", "documenti", ",", "supporto", "per", "MSN", "Groups", "e", "SharePoint", ";", "e", "funzionalit\u00e0", "integrate", "di", "riconoscimento", "della", "scrittura", "e", "del", "parlato", "."], "sentence-detokenized": "Tra le nuove caratteristiche di Office XP vi sono gli smart tag, una funzione di ricerca basata sulla selezione che riconosce i diversi tipi di testo presenti in un documento in modo che gli utenti possano eseguire azioni aggiuntive; un'interfaccia del riquadro delle attivit\u00e0 che consolida i comandi pi\u00f9 diffusi della barra dei menu sul lato destro dello schermo per facilitarne l'accesso rapido; nuove funzionalit\u00e0 di collaborazione tra documenti, supporto per MSN Groups e SharePoint; e funzionalit\u00e0 integrate di riconoscimento della scrittura e del parlato.", "token2charspan": [[0, 3], [4, 6], [7, 12], [13, 28], [29, 31], [32, 38], [39, 41], [42, 44], [45, 49], [50, 53], [54, 59], [60, 63], [63, 64], [65, 68], [69, 77], [78, 80], [81, 88], [89, 95], [96, 101], [102, 111], [112, 115], [116, 125], [126, 127], [128, 135], [136, 140], [141, 143], [144, 149], [150, 158], [159, 161], [162, 164], [165, 174], [175, 177], [178, 182], [183, 186], [187, 190], [191, 197], [198, 205], [206, 214], [215, 221], [222, 232], [232, 233], [234, 237], [237, 248], [249, 252], [253, 261], [262, 267], [268, 276], [277, 280], [281, 290], [291, 292], [293, 300], [301, 304], [305, 312], [313, 318], [319, 324], [325, 328], [329, 333], [334, 337], [338, 342], [343, 349], [350, 355], [356, 363], [364, 367], [368, 379], [380, 382], [382, 389], [390, 396], [396, 397], [398, 403], [404, 416], [417, 419], [420, 434], [435, 438], [439, 448], [448, 449], [450, 458], [459, 462], [463, 466], [467, 473], [474, 475], [476, 486], [486, 487], [488, 489], [490, 502], [503, 512], [513, 515], [516, 530], [531, 536], [537, 546], [547, 548], [549, 552], [553, 560], [560, 561]]}
{"doc_key": "ai-dev-64", "ner": [[10, 11, "algorithm"], [13, 15, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 11, 13, 15, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "molte", "applicazioni", "le", "unit\u00e0", "di", "queste", "reti", "applicano", "una", "funzione", "sigmoide", "come", "funzione", "di", "attivazione", "."], "sentence-detokenized": "In molte applicazioni le unit\u00e0 di queste reti applicano una funzione sigmoide come funzione di attivazione.", "token2charspan": [[0, 2], [3, 8], [9, 21], [22, 24], [25, 30], [31, 33], [34, 40], [41, 45], [46, 55], [56, 59], [60, 68], [69, 77], [78, 82], [83, 91], [92, 94], [95, 106], [106, 107]]}
{"doc_key": "ai-dev-65", "ner": [[2, 2, "researcher"], [10, 15, "organisation"], [24, 30, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 10, 15, "role", "", false, false], [2, 2, 24, 30, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Nel", "2001", "Mehler", "\u00e8", "stato", "eletto", "membro", "onorario", "straniero", "dell'", "American", "Academy", "of", "Arts", "and", "Sciences", "e", "nel", "2003", "\u00e8", "stato", "eletto", "Fellow", "dell'", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "Nel 2001 Mehler \u00e8 stato eletto membro onorario straniero dell'American Academy of Arts and Sciences e nel 2003 \u00e8 stato eletto Fellow dell'American Association for the Advancement of Science.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 17], [18, 23], [24, 30], [31, 37], [38, 46], [47, 56], [57, 62], [62, 70], [71, 78], [79, 81], [82, 86], [87, 90], [91, 99], [100, 101], [102, 105], [106, 110], [111, 112], [113, 118], [119, 125], [126, 132], [133, 138], [138, 146], [147, 158], [159, 162], [163, 166], [167, 178], [179, 181], [182, 189], [189, 190]]}
{"doc_key": "ai-dev-66", "ner": [[6, 8, "task"], [11, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 11, 13, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["L'", "estensione", "di", "questo", "concetto", "a", "classificazioni", "non", "binarie", "produce", "la", "matrice", "di", "confusione", "."], "sentence-detokenized": "L'estensione di questo concetto a classificazioni non binarie produce la matrice di confusione.", "token2charspan": [[0, 2], [2, 12], [13, 15], [16, 22], [23, 31], [32, 33], [34, 49], [50, 53], [54, 61], [62, 69], [70, 72], [73, 80], [81, 83], [84, 94], [94, 95]]}
{"doc_key": "ai-dev-67", "ner": [[15, 16, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Una", "stima", "aggiornata", "della", "varianza", "del", "rumore", "di", "misura", "pu\u00f2", "essere", "ottenuta", "dal", "calcolo", "della", "massima", "verosimiglianza"], "sentence-detokenized": "Una stima aggiornata della varianza del rumore di misura pu\u00f2 essere ottenuta dal calcolo della massima verosimiglianza", "token2charspan": [[0, 3], [4, 9], [10, 20], [21, 26], [27, 35], [36, 39], [40, 46], [47, 49], [50, 56], [57, 60], [61, 67], [68, 76], [77, 80], [81, 88], [89, 94], [95, 102], [103, 118]]}
{"doc_key": "ai-dev-68", "ner": [[1, 2, "field"], [5, 5, "algorithm"], [11, 12, "field"], [14, 15, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 11, 12, "usage", "", true, false], [5, 5, 14, 15, "related-to", "", true, false], [11, 12, 1, 2, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Nell'", "apprendimento", "automatico", ",", "il", "percettrone", "\u00e8", "un", "algoritmo", "per", "l'", "apprendimento", "supervisionato", "della", "classificazione", "binaria", "."], "sentence-detokenized": "Nell'apprendimento automatico, il percettrone \u00e8 un algoritmo per l'apprendimento supervisionato della classificazione binaria.", "token2charspan": [[0, 5], [5, 18], [19, 29], [29, 30], [31, 33], [34, 45], [46, 47], [48, 50], [51, 60], [61, 64], [65, 67], [67, 80], [81, 95], [96, 101], [102, 117], [118, 125], [125, 126]]}
{"doc_key": "ai-dev-69", "ner": [[10, 11, "field"], [14, 14, "field"], [19, 24, "conference"], [27, 31, "conference"], [34, 40, "conference"], [43, 47, "conference"], [50, 54, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[19, 24, 10, 11, "topic", "", false, false], [19, 24, 14, 14, "topic", "", false, false], [27, 31, 10, 11, "topic", "", false, false], [27, 31, 14, 14, "topic", "", false, false], [34, 40, 10, 11, "topic", "", false, false], [34, 40, 14, 14, "topic", "", false, false], [43, 47, 10, 11, "topic", "", false, false], [43, 47, 14, 14, "topic", "", false, false], [50, 54, 10, 11, "topic", "", false, false], [50, 54, 14, 14, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["\u00c8", "stata", "inoltre", "presidente", "di", "area", "di", "diverse", "conferenze", "sull'", "apprendimento", "automatico", "e", "sulla", "visione", ",", "tra", "cui", "la", "Conference", "on", "Neural", "Information", "Processing", "Systems", ",", "la", "International", "Conference", "on", "Learning", "Representations", ",", "la", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "la", "International", "Conference", "on", "Computer", "Vision", "e", "la", "European", "Conference", "on", "Computer", "Vision", "."], "sentence-detokenized": "\u00c8 stata inoltre presidente di area di diverse conferenze sull'apprendimento automatico e sulla visione, tra cui la Conference on Neural Information Processing Systems, la International Conference on Learning Representations, la Conference on Computer Vision and Pattern Recognition, la International Conference on Computer Vision e la European Conference on Computer Vision.", "token2charspan": [[0, 1], [2, 7], [8, 15], [16, 26], [27, 29], [30, 34], [35, 37], [38, 45], [46, 56], [57, 62], [62, 75], [76, 86], [87, 88], [89, 94], [95, 102], [102, 103], [104, 107], [108, 111], [112, 114], [115, 125], [126, 128], [129, 135], [136, 147], [148, 158], [159, 166], [166, 167], [168, 170], [171, 184], [185, 195], [196, 198], [199, 207], [208, 223], [223, 224], [225, 227], [228, 238], [239, 241], [242, 250], [251, 257], [258, 261], [262, 269], [270, 281], [281, 282], [283, 285], [286, 299], [300, 310], [311, 313], [314, 322], [323, 329], [330, 331], [332, 334], [335, 343], [344, 354], [355, 357], [358, 366], [367, 373], [373, 374]]}
{"doc_key": "ai-dev-70", "ner": [[1, 3, "algorithm"], [10, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 13, 1, 3, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["L'", "algoritmo", "di", "condensazione", "\u00e8", "stato", "utilizzato", "anche", "per", "il", "sistema", "di", "riconoscimento", "facciale", "in", "una", "sequenza", "video", "."], "sentence-detokenized": "L'algoritmo di condensazione \u00e8 stato utilizzato anche per il sistema di riconoscimento facciale in una sequenza video.", "token2charspan": [[0, 2], [2, 11], [12, 14], [15, 28], [29, 30], [31, 36], [37, 47], [48, 53], [54, 57], [58, 60], [61, 68], [69, 71], [72, 86], [87, 95], [96, 98], [99, 102], [103, 111], [112, 117], [117, 118]]}
{"doc_key": "ai-dev-71", "ner": [[2, 4, "task"], [10, 10, "organisation"], [19, 19, "conference"], [22, 27, "academicjournal"], [30, 30, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 19, 2, 4, "topic", "", false, false], [19, 19, 10, 10, "origin", "", false, false], [22, 27, 2, 4, "topic", "", false, false], [22, 27, 10, 10, "origin", "", true, false], [30, 30, 22, 27, "role", "edited_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Anche", "la", "diffusione", "delle", "informazioni", "fa", "parte", "delle", "missioni", "di", "ELRA", ",", "che", "si", "concretizza", "nell'", "organizzazione", "della", "conferenza", "LREC", "e", "della", "rivista", "Language", "Resources", "and", "Evaluation", "Journal", "edita", "da", "Springer", "."], "sentence-detokenized": "Anche la diffusione delle informazioni fa parte delle missioni di ELRA, che si concretizza nell'organizzazione della conferenza LREC e della rivista Language Resources and Evaluation Journal edita da Springer.", "token2charspan": [[0, 5], [6, 8], [9, 19], [20, 25], [26, 38], [39, 41], [42, 47], [48, 53], [54, 62], [63, 65], [66, 70], [70, 71], [72, 75], [76, 78], [79, 90], [91, 96], [96, 110], [111, 116], [117, 127], [128, 132], [133, 134], [135, 140], [141, 148], [149, 157], [158, 167], [168, 171], [172, 182], [183, 190], [191, 196], [197, 199], [200, 208], [208, 209]]}
{"doc_key": "ai-dev-72", "ner": [[1, 9, "field"], [13, 15, "field"], [18, 21, "field"], [24, 26, "field"], [64, 65, "field"], [72, 72, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 9, 64, 65, "named", "", false, false], [18, 21, 1, 9, "named", "", false, false], [72, 72, 13, 15, "part-of", "", true, false], [72, 72, 18, 21, "part-of", "", true, false], [72, 72, 64, 65, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Nella", "teoria", "dei", "sistemi", "lineari", "tempo", "-", "invarianti", "(", "LTI", ")", ",", "nella", "teoria", "del", "controllo", "e", "nell'", "elaborazione", "dei", "segnali", "digitali", "o", "nell'", "elaborazione", "dei", "segnali", ",", "la", "relazione", "tra", "il", "segnale", "di", "ingresso", ",", "math", "\\", "displaystyle", "x", "(", "t", ")", "/", "math", ",", "e", "il", "segnale", "di", "uscita", ",", "math", "\\", "displaystyle", "y", "(", "t", ")", "/", "math", ",", "di", "un", "sistema", "LTI", "\u00e8", "governata", "da", "un'", "operazione", "di", "convoluzione", ":"], "sentence-detokenized": "Nella teoria dei sistemi lineari tempo-invarianti (LTI), nella teoria del controllo e nell'elaborazione dei segnali digitali o nell'elaborazione dei segnali, la relazione tra il segnale di ingresso, math\\ displaystyle x (t) / math, e il segnale di uscita, math\\ displaystyle y (t) / math, di un sistema LTI \u00e8 governata da un'operazione di convoluzione:", "token2charspan": [[0, 5], [6, 12], [13, 16], [17, 24], [25, 32], [33, 38], [38, 39], [39, 49], [50, 51], [51, 54], [54, 55], [55, 56], [57, 62], [63, 69], [70, 73], [74, 83], [84, 85], [86, 91], [91, 103], [104, 107], [108, 115], [116, 124], [125, 126], [127, 132], [132, 144], [145, 148], [149, 156], [156, 157], [158, 160], [161, 170], [171, 174], [175, 177], [178, 185], [186, 188], [189, 197], [197, 198], [199, 203], [203, 204], [205, 217], [218, 219], [220, 221], [221, 222], [222, 223], [224, 225], [226, 230], [230, 231], [232, 233], [234, 236], [237, 244], [245, 247], [248, 254], [254, 255], [256, 260], [260, 261], [262, 274], [275, 276], [277, 278], [278, 279], [279, 280], [281, 282], [283, 287], [287, 288], [289, 291], [292, 294], [295, 302], [303, 306], [307, 308], [309, 318], [319, 321], [322, 325], [325, 335], [336, 338], [339, 351], [351, 352]]}
{"doc_key": "ai-dev-73", "ner": [[16, 18, "field"], [21, 23, "field"], [26, 27, "field"], [30, 32, "field"], [35, 38, "field"], [41, 44, "product"], [47, 49, "field"], [52, 52, "field"], [55, 56, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Grazie", "alla", "sua", "generalit\u00e0", ",", "questo", "campo", "viene", "studiato", "in", "molte", "altre", "discipline", ",", "come", "la", "teoria", "dei", "giochi", ",", "la", "teoria", "del", "controllo", ",", "la", "ricerca", "operativa", ",", "la", "teoria", "dell'", "informazione", ",", "l'", "ottimizzazione", "basata", "sulla", "simulazione", ",", "i", "sistemi", "multi", "-", "agente", ",", "l'", "intelligenza", "degli", "sciami", ",", "la", "statistica", "e", "gli", "algoritmi", "genetici", "."], "sentence-detokenized": "Grazie alla sua generalit\u00e0, questo campo viene studiato in molte altre discipline, come la teoria dei giochi, la teoria del controllo, la ricerca operativa, la teoria dell'informazione, l'ottimizzazione basata sulla simulazione, i sistemi multi-agente, l'intelligenza degli sciami, la statistica e gli algoritmi genetici.", "token2charspan": [[0, 6], [7, 11], [12, 15], [16, 26], [26, 27], [28, 34], [35, 40], [41, 46], [47, 55], [56, 58], [59, 64], [65, 70], [71, 81], [81, 82], [83, 87], [88, 90], [91, 97], [98, 101], [102, 108], [108, 109], [110, 112], [113, 119], [120, 123], [124, 133], [133, 134], [135, 137], [138, 145], [146, 155], [155, 156], [157, 159], [160, 166], [167, 172], [172, 184], [184, 185], [186, 188], [188, 202], [203, 209], [210, 215], [216, 227], [227, 228], [229, 230], [231, 238], [239, 244], [244, 245], [245, 251], [251, 252], [253, 255], [255, 267], [268, 273], [274, 280], [280, 281], [282, 284], [285, 295], [296, 297], [298, 301], [302, 311], [312, 320], [320, 321]]}
{"doc_key": "ai-dev-74", "ner": [[0, 4, "algorithm"], [19, 20, "field"], [25, 28, "algorithm"], [34, 35, "algorithm"], [43, 44, "algorithm"], [48, 49, "algorithm"], [48, 51, "researcher"], [53, 54, "researcher"], [56, 58, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[19, 20, 0, 4, "usage", "", true, false], [25, 28, 19, 20, "part-of", "", true, false], [34, 35, 19, 20, "part-of", "", true, false], [43, 44, 19, 20, "part-of", "", true, false], [48, 49, 19, 20, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["La", "discesa", "stocastica", "del", "gradiente", "\u00e8", "un", "algoritmo", "popolare", "per", "l'", "addestramento", "di", "un'", "ampia", "gamma", "di", "modelli", "nell'", "apprendimento", "automatico", ",", "tra", "cui", "le", "macchine", "vettoriali", "di", "supporto", "(", "lineari", ")", ",", "la", "regressione", "logistica", "(", "si", "veda", ",", "ad", "esempio", ",", "Vowpal", "Wabbit", ")", "e", "i", "modelli", "grafici.Jenny", "Rose", "Finkel", ",", "Alex", "Kleeman", ",", "Christopher", "D.", "Manning", "(", "2008", ")", "."], "sentence-detokenized": "La discesa stocastica del gradiente \u00e8 un algoritmo popolare per l'addestramento di un'ampia gamma di modelli nell'apprendimento automatico, tra cui le macchine vettoriali di supporto (lineari), la regressione logistica (si veda, ad esempio, Vowpal Wabbit) e i modelli grafici.Jenny Rose Finkel, Alex Kleeman, Christopher D. Manning (2008).", "token2charspan": [[0, 2], [3, 10], [11, 21], [22, 25], [26, 35], [36, 37], [38, 40], [41, 50], [51, 59], [60, 63], [64, 66], [66, 79], [80, 82], [83, 86], [86, 91], [92, 97], [98, 100], [101, 108], [109, 114], [114, 127], [128, 138], [138, 139], [140, 143], [144, 147], [148, 150], [151, 159], [160, 170], [171, 173], [174, 182], [183, 184], [184, 191], [191, 192], [192, 193], [194, 196], [197, 208], [209, 218], [219, 220], [220, 222], [223, 227], [227, 228], [229, 231], [232, 239], [239, 240], [241, 247], [248, 254], [254, 255], [256, 257], [258, 259], [260, 267], [268, 281], [282, 286], [287, 293], [293, 294], [295, 299], [300, 307], [307, 308], [309, 320], [321, 323], [324, 331], [332, 333], [333, 337], [337, 338], [338, 339]]}
{"doc_key": "ai-dev-75", "ner": [[7, 7, "organisation"], [11, 12, "product"], [18, 18, "country"], [21, 24, "university"], [26, 26, "location"], [29, 31, "university"], [33, 33, "location"], [36, 37, "university"], [39, 39, "location"], [42, 44, "university"], [46, 46, "location"], [49, 50, "university"], [52, 52, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[7, 7, 21, 24, "role", "donates_to", false, false], [7, 7, 29, 31, "role", "donates_to", false, false], [7, 7, 36, 37, "role", "donates_to", false, false], [7, 7, 42, 44, "role", "donates_to", false, false], [7, 7, 49, 50, "role", "donates_to", false, false], [11, 12, 7, 7, "origin", "donates", true, false], [21, 24, 26, 26, "physical", "", false, false], [26, 26, 18, 18, "physical", "", false, false], [29, 31, 33, 33, "physical", "", false, false], [33, 33, 18, 18, "physical", "", false, false], [36, 37, 39, 39, "physical", "", false, false], [39, 39, 18, 18, "physical", "", false, false], [42, 44, 46, 46, "physical", "", false, false], [46, 46, 18, 18, "physical", "", false, false], [49, 50, 52, 52, "physical", "", false, false], [52, 52, 18, 18, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "sentence": ["Nell'", "agosto", "2011", "\u00e8", "stato", "annunciato", "che", "Hitachi", "avrebbe", "donato", "un", "microscopio", "elettronico", "a", "ciascuna", "delle", "cinque", "universit\u00e0", "indonesiane", "(", "l'", "Universit\u00e0", "di", "North", "Sumatra", "a", "Medan", ",", "l'", "Universit\u00e0", "Cristiana", "Indonesiana", "a", "Jakarta", ",", "l'", "Universit\u00e0", "Padjadjaran", "a", "Bandung", ",", "l'", "Universit\u00e0", "Jenderal", "Soedirman", "a", "Purwokerto", "e", "l'", "Universit\u00e0", "Muhammadiyah", "a", "Malang", ")", "."], "sentence-detokenized": "Nell'agosto 2011 \u00e8 stato annunciato che Hitachi avrebbe donato un microscopio elettronico a ciascuna delle cinque universit\u00e0 indonesiane (l'Universit\u00e0 di North Sumatra a Medan, l'Universit\u00e0 Cristiana Indonesiana a Jakarta, l'Universit\u00e0 Padjadjaran a Bandung, l'Universit\u00e0 Jenderal Soedirman a Purwokerto e l'Universit\u00e0 Muhammadiyah a Malang).", "token2charspan": [[0, 5], [5, 11], [12, 16], [17, 18], [19, 24], [25, 35], [36, 39], [40, 47], [48, 55], [56, 62], [63, 65], [66, 77], [78, 89], [90, 91], [92, 100], [101, 106], [107, 113], [114, 124], [125, 136], [137, 138], [138, 140], [140, 150], [151, 153], [154, 159], [160, 167], [168, 169], [170, 175], [175, 176], [177, 179], [179, 189], [190, 199], [200, 211], [212, 213], [214, 221], [221, 222], [223, 225], [225, 235], [236, 247], [248, 249], [250, 257], [257, 258], [259, 261], [261, 271], [272, 280], [281, 290], [291, 292], [293, 303], [304, 305], [306, 308], [308, 318], [319, 331], [332, 333], [334, 340], [340, 341], [341, 342]]}
{"doc_key": "ai-dev-76", "ner": [[2, 3, "field"], [5, 6, "field"], [10, 11, "algorithm"], [14, 15, "algorithm"], [25, 27, "field"], [35, 36, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 5, 6, "part-of", "", false, false], [2, 3, 25, 27, "related-to", "", true, false], [2, 3, 35, 36, "related-to", "", true, false], [10, 11, 2, 3, "type-of", "", false, false], [14, 15, 2, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Le", "tecniche", "di", "ottimizzazione", "della", "ricerca", "operativa", ",", "come", "la", "programmazione", "lineare", "o", "la", "programmazione", "dinamica", ",", "sono", "spesso", "poco", "pratiche", "per", "i", "problemi", "di", "ingegneria", "del", "software", "su", "larga", "scala", "a", "causa", "della", "loro", "complessit\u00e0", "computazionale", "."], "sentence-detokenized": "Le tecniche di ottimizzazione della ricerca operativa, come la programmazione lineare o la programmazione dinamica, sono spesso poco pratiche per i problemi di ingegneria del software su larga scala a causa della loro complessit\u00e0 computazionale.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 29], [30, 35], [36, 43], [44, 53], [53, 54], [55, 59], [60, 62], [63, 77], [78, 85], [86, 87], [88, 90], [91, 105], [106, 114], [114, 115], [116, 120], [121, 127], [128, 132], [133, 141], [142, 145], [146, 147], [148, 156], [157, 159], [160, 170], [171, 174], [175, 183], [184, 186], [187, 192], [193, 198], [199, 200], [201, 206], [207, 212], [213, 217], [218, 229], [230, 244], [244, 245]]}
{"doc_key": "ai-dev-77", "ner": [[0, 1, "metrics"], [8, 8, "metrics"], [11, 13, "metrics"], [18, 19, "metrics"], [24, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 8, 8, "compare", "", false, false], [0, 1, 11, 13, "compare", "", false, false], [18, 19, 11, 13, "part-of", "", false, false], [24, 27, 11, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["La", "sensibilit\u00e0", "non", "\u00e8", "la", "stessa", "cosa", "della", "precisione", "o", "del", "valore", "predittivo", "positivo", "(", "rapporto", "tra", "i", "VERI", "positivi", "e", "la", "combinazione", "di", "VERI", "e", "FALSI", "positivi", ")", ",", "che", "\u00e8", "un'", "affermazione", "sulla", "proporzione", "di", "positivi", "effettivi", "nella", "popolazione", "esaminata", ",", "oltre", "che", "sul", "test."], "sentence-detokenized": "La sensibilit\u00e0 non \u00e8 la stessa cosa della precisione o del valore predittivo positivo (rapporto tra i VERI positivi e la combinazione di VERI e FALSI positivi), che \u00e8 un'affermazione sulla proporzione di positivi effettivi nella popolazione esaminata, oltre che sul test.", "token2charspan": [[0, 2], [3, 14], [15, 18], [19, 20], [21, 23], [24, 30], [31, 35], [36, 41], [42, 52], [53, 54], [55, 58], [59, 65], [66, 76], [77, 85], [86, 87], [87, 95], [96, 99], [100, 101], [102, 106], [107, 115], [116, 117], [118, 120], [121, 133], [134, 136], [137, 141], [142, 143], [144, 149], [150, 158], [158, 159], [159, 160], [161, 164], [165, 166], [167, 170], [170, 182], [183, 188], [189, 200], [201, 203], [204, 212], [213, 222], [223, 228], [229, 240], [241, 250], [250, 251], [252, 257], [258, 261], [262, 265], [266, 271]]}
{"doc_key": "ai-dev-78", "ner": [[3, 4, "person"], [11, 11, "product"], [18, 18, "person"], [30, 30, "person"], [38, 39, "person"], [45, 45, "person"], [50, 51, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 4, 45, 45, "named", "same", false, false], [11, 11, 3, 4, "artifact", "", false, false], [38, 39, 50, 51, "role", "convinces", false, false], [50, 51, 11, 11, "role", "producer", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["La", "sceneggiatura", "di", "Hampton", "Fancher", "!", "-", "-", "Inizialmente", "non", "intitolata", "Android", "-", "per", "la", "spiegazione", "si", "veda", "Sammon", ",", "pp.", "32", "e", "38", "-", "fu", "opzionata", "nel", "1977", ".", "Sammon", ",", "pp.", "23", "-", "30", "Il", "produttore", "Michael", "Deeley", "si", "interess\u00f2", "alla", "bozza", "di", "Fancher", "e", "convinse", "il", "regista", "Ridley", "Scott", "a", "girarla", "."], "sentence-detokenized": "La sceneggiatura di Hampton Fancher! -- Inizialmente non intitolata Android - per la spiegazione si veda Sammon, pp. 32 e 38 - fu opzionata nel 1977. Sammon, pp. 23-30 Il produttore Michael Deeley si interess\u00f2 alla bozza di Fancher e convinse il regista Ridley Scott a girarla.", "token2charspan": [[0, 2], [3, 16], [17, 19], [20, 27], [28, 35], [35, 36], [37, 38], [38, 39], [40, 52], [53, 56], [57, 67], [68, 75], [76, 77], [78, 81], [82, 84], [85, 96], [97, 99], [100, 104], [105, 111], [111, 112], [113, 116], [117, 119], [120, 121], [122, 124], [125, 126], [127, 129], [130, 139], [140, 143], [144, 148], [148, 149], [150, 156], [156, 157], [158, 161], [162, 164], [164, 165], [165, 167], [168, 170], [171, 181], [182, 189], [190, 196], [197, 199], [200, 209], [210, 214], [215, 220], [221, 223], [224, 231], [232, 233], [234, 242], [243, 245], [246, 253], [254, 260], [261, 266], [267, 268], [269, 276], [276, 277]]}
{"doc_key": "ai-dev-79", "ner": [[0, 3, "field"], [6, 8, "task"], [11, 12, "task"], [16, 20, "misc"], [23, 25, "field"], [28, 30, "task"], [33, 35, "task"], [39, 41, "field"], [46, 51, "task"], [54, 54, "task"], [57, 58, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[6, 8, 0, 3, "part-of", "", false, false], [11, 12, 0, 3, "part-of", "", false, false], [16, 20, 0, 3, "part-of", "", false, false], [23, 25, 0, 3, "part-of", "", false, false], [28, 30, 0, 3, "part-of", "", false, false], [33, 35, 0, 3, "part-of", "", false, false], [39, 41, 0, 3, "part-of", "", false, false], [46, 51, 0, 3, "part-of", "", false, false], [54, 54, 0, 3, "part-of", "", false, false], [57, 58, 0, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["L'", "analisi", "del", "testo", "comprende", "il", "reperimento", "delle", "informazioni", ",", "l'", "analisi", "lessicale", "per", "studiare", "le", "distribuzioni", "di", "frequenza", "delle", "parole", ",", "il", "riconoscimento", "dei", "modelli", ",", "l'", "etichettatura", "/", "annotazione", ",", "l'", "estrazione", "delle", "informazioni", ",", "le", "tecniche", "di", "data", "mining", ",", "tra", "cui", "l'", "analisi", "dei", "collegamenti", "e", "delle", "associazioni", ",", "la", "visualizzazione", "e", "l'", "analisi", "predittiva", "."], "sentence-detokenized": "L'analisi del testo comprende il reperimento delle informazioni, l'analisi lessicale per studiare le distribuzioni di frequenza delle parole, il riconoscimento dei modelli, l'etichettatura/annotazione, l'estrazione delle informazioni, le tecniche di data mining, tra cui l'analisi dei collegamenti e delle associazioni, la visualizzazione e l'analisi predittiva.", "token2charspan": [[0, 2], [2, 9], [10, 13], [14, 19], [20, 29], [30, 32], [33, 44], [45, 50], [51, 63], [63, 64], [65, 67], [67, 74], [75, 84], [85, 88], [89, 97], [98, 100], [101, 114], [115, 117], [118, 127], [128, 133], [134, 140], [140, 141], [142, 144], [145, 159], [160, 163], [164, 171], [171, 172], [173, 175], [175, 188], [188, 189], [189, 200], [200, 201], [202, 204], [204, 214], [215, 220], [221, 233], [233, 234], [235, 237], [238, 246], [247, 249], [250, 254], [255, 261], [261, 262], [263, 266], [267, 270], [271, 273], [273, 280], [281, 284], [285, 297], [298, 299], [300, 305], [306, 318], [318, 319], [320, 322], [323, 338], [339, 340], [341, 343], [343, 350], [351, 361], [361, 362]]}
{"doc_key": "ai-dev-80", "ner": [[3, 3, "product"], [9, 10, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 10, 3, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Diverse", "metriche", "utilizzano", "WordNet", ",", "un", "database", "lessicale", "di", "parole", "inglesi", "costruito", "manualmente", "."], "sentence-detokenized": "Diverse metriche utilizzano WordNet, un database lessicale di parole inglesi costruito manualmente.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 35], [35, 36], [37, 39], [40, 48], [49, 58], [59, 61], [62, 68], [69, 76], [77, 86], [87, 98], [98, 99]]}
{"doc_key": "ai-dev-81", "ner": [[8, 9, "field"], [11, 13, "task"], [15, 21, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Il", "sistema", "utilizza", "una", "combinazione", "di", "tecniche", "di", "linguistica", "computazionale", ",", "recupero", "di", "informazioni", "e", "rappresentazione", "della", "conoscenza", "per", "trovare", "le", "risposte", "."], "sentence-detokenized": "Il sistema utilizza una combinazione di tecniche di linguistica computazionale, recupero di informazioni e rappresentazione della conoscenza per trovare le risposte.", "token2charspan": [[0, 2], [3, 10], [11, 19], [20, 23], [24, 36], [37, 39], [40, 48], [49, 51], [52, 63], [64, 78], [78, 79], [80, 88], [89, 91], [92, 104], [105, 106], [107, 123], [124, 129], [130, 140], [141, 144], [145, 152], [153, 155], [156, 164], [164, 165]]}
{"doc_key": "ai-dev-82", "ner": [[6, 8, "metrics"], [16, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 16, 16, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Come", "metrica", "di", "prestazione", ",", "il", "coefficiente", "di", "incertezza", "ha", "il", "vantaggio", ",", "rispetto", "alla", "semplice", "accuratezza", ",", "di", "non", "essere", "influenzato", "dalle", "dimensioni", "relative", "delle", "diverse", "classi", "."], "sentence-detokenized": "Come metrica di prestazione, il coefficiente di incertezza ha il vantaggio, rispetto alla semplice accuratezza, di non essere influenzato dalle dimensioni relative delle diverse classi.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 27], [27, 28], [29, 31], [32, 44], [45, 47], [48, 58], [59, 61], [62, 64], [65, 74], [74, 75], [76, 84], [85, 89], [90, 98], [99, 110], [110, 111], [112, 114], [115, 118], [119, 125], [126, 137], [138, 143], [144, 154], [155, 163], [164, 169], [170, 177], [178, 184], [184, 185]]}
{"doc_key": "ai-dev-83", "ner": [[10, 11, "algorithm"], [14, 16, "algorithm"], [21, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["I", "ricercatori", "hanno", "tentato", "una", "serie", "di", "metodi", "come", "il", "flusso", "ottico", ",", "il", "filtraggio", "di", "Kalman", ",", "i", "modelli", "di", "Hidden", "Markov", ",", "ecc", "."], "sentence-detokenized": "I ricercatori hanno tentato una serie di metodi come il flusso ottico, il filtraggio di Kalman, i modelli di Hidden Markov, ecc.", "token2charspan": [[0, 1], [2, 13], [14, 19], [20, 27], [28, 31], [32, 37], [38, 40], [41, 47], [48, 52], [53, 55], [56, 62], [63, 69], [69, 70], [71, 73], [74, 84], [85, 87], [88, 94], [94, 95], [96, 97], [98, 105], [106, 108], [109, 115], [116, 122], [122, 123], [124, 127], [127, 128]]}
{"doc_key": "ai-dev-84", "ner": [[13, 16, "conference"], [32, 34, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ha", "ricoperto", "le", "cariche", "di", "presidente", ",", "vicepresidente", "e", "segretario", "-", "tesoriere", "dell'", "Association", "for", "Computational", "Linguistics", "ed", "\u00e8", "stata", "membro", "del", "consiglio", "di", "amministrazione", "e", "segretario", "del", "consiglio", "di", "amministrazione", "della", "Computing", "Research", "Association", "."], "sentence-detokenized": "Ha ricoperto le cariche di presidente, vicepresidente e segretario-tesoriere dell'Association for Computational Linguistics ed \u00e8 stata membro del consiglio di amministrazione e segretario del consiglio di amministrazione della Computing Research Association.", "token2charspan": [[0, 2], [3, 12], [13, 15], [16, 23], [24, 26], [27, 37], [37, 38], [39, 53], [54, 55], [56, 66], [66, 67], [67, 76], [77, 82], [82, 93], [94, 97], [98, 111], [112, 123], [124, 126], [127, 128], [129, 134], [135, 141], [142, 145], [146, 155], [156, 158], [159, 174], [175, 176], [177, 187], [188, 191], [192, 201], [202, 204], [205, 220], [221, 226], [227, 236], [237, 245], [246, 257], [257, 258]]}
{"doc_key": "ai-dev-85", "ner": [[6, 6, "programlang"], [8, 8, "product"], [10, 10, "programlang"], [13, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 10, 10, "compare", "", false, false], [6, 6, 13, 15, "related-to", "supports", false, false], [8, 8, 10, 10, "compare", "", false, false], [8, 8, 13, 15, "related-to", "supports", false, false], [10, 10, 13, 15, "related-to", "supports", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Come", "altri", "linguaggi", "simili", ",", "quali", "APL", "e", "MATLAB", ",", "R", "supporta", "l'", "aritmetica", "delle", "matrici", "."], "sentence-detokenized": "Come altri linguaggi simili, quali APL e MATLAB, R supporta l'aritmetica delle matrici.", "token2charspan": [[0, 4], [5, 10], [11, 20], [21, 27], [27, 28], [29, 34], [35, 38], [39, 40], [41, 47], [47, 48], [49, 50], [51, 59], [60, 62], [62, 72], [73, 78], [79, 86], [86, 87]]}
{"doc_key": "ai-dev-86", "ner": [[9, 11, "misc"], [13, 14, "organisation"], [18, 19, "researcher"], [21, 23, "university"], [27, 32, "misc"], [34, 34, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 11, 13, 14, "physical", "", false, false], [9, 11, 27, 32, "temporal", "", false, false], [18, 19, 9, 11, "role", "arranges", false, false], [18, 19, 21, 23, "role", "works_for", false, false], [34, 34, 9, 11, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Il", "7", "giugno", "2014", ",", "in", "una", "gara", "di", "test", "di", "Turing", "alla", "Royal", "Society", ",", "organizzata", "da", "Kevin", "Warwick", "dell'", "Universit\u00e0", "di", "Reading", "in", "occasione", "del", "60\u00b0", "anniversario", "della", "morte", "di", "Turing", ",", "Goostman", "ha", "vinto", "dopo", "che", "il", "33", "%", "dei", "giudici", "era", "convinto", "che", "il", "bot", "fosse", "umano", "."], "sentence-detokenized": "Il 7 giugno 2014, in una gara di test di Turing alla Royal Society, organizzata da Kevin Warwick dell'Universit\u00e0 di Reading in occasione del 60\u00b0 anniversario della morte di Turing, Goostman ha vinto dopo che il 33% dei giudici era convinto che il bot fosse umano.", "token2charspan": [[0, 2], [3, 4], [5, 11], [12, 16], [16, 17], [18, 20], [21, 24], [25, 29], [30, 32], [33, 37], [38, 40], [41, 47], [48, 52], [53, 58], [59, 66], [66, 67], [68, 79], [80, 82], [83, 88], [89, 96], [97, 102], [102, 112], [113, 115], [116, 123], [124, 126], [127, 136], [137, 140], [141, 144], [145, 157], [158, 163], [164, 169], [170, 172], [173, 179], [179, 180], [181, 189], [190, 192], [193, 198], [199, 203], [204, 207], [208, 210], [211, 213], [213, 214], [215, 218], [219, 226], [227, 230], [231, 239], [240, 243], [244, 246], [247, 250], [251, 256], [257, 262], [262, 263]]}
{"doc_key": "ai-dev-87", "ner": [[1, 2, "product"], [4, 4, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 1, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Un", "robot", "collaborativo", "o", "cobot", "\u00e8", "un", "robot", "in", "grado", "di", "interagire", "in", "modo", "sicuro", "ed", "efficace", "con", "i", "lavoratori", "umani", "durante", "l'", "esecuzione", "di", "semplici", "compiti", "industriali", "."], "sentence-detokenized": "Un robot collaborativo o cobot \u00e8 un robot in grado di interagire in modo sicuro ed efficace con i lavoratori umani durante l'esecuzione di semplici compiti industriali.", "token2charspan": [[0, 2], [3, 8], [9, 22], [23, 24], [25, 30], [31, 32], [33, 35], [36, 41], [42, 44], [45, 50], [51, 53], [54, 64], [65, 67], [68, 72], [73, 79], [80, 82], [83, 91], [92, 95], [96, 97], [98, 108], [109, 114], [115, 122], [123, 125], [125, 135], [136, 138], [139, 147], [148, 155], [156, 167], [167, 168]]}
{"doc_key": "ai-dev-88", "ner": [[13, 14, "field"], [19, 21, "task"], [24, 26, "task"], [29, 31, "task"], [34, 36, "task"], [39, 41, "task"], [44, 48, "task"], [51, 53, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[19, 21, 13, 14, "part-of", "task_part_of_field", false, false], [24, 26, 13, 14, "part-of", "task_part_of_field", false, false], [29, 31, 13, 14, "part-of", "task_part_of_field", false, false], [34, 36, 13, 14, "part-of", "task_part_of_field", false, false], [39, 41, 13, 14, "part-of", "task_part_of_field", false, false], [44, 48, 13, 14, "part-of", "task_part_of_field", false, false], [51, 53, 13, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Questa", "struttura", "generale", "\u00e8", "stata", "applicata", "a", "una", "grande", "variet\u00e0", "di", "problemi", "di", "computer", "vision", ",", "tra", "cui", "il", "rilevamento", "di", "caratteristiche", ",", "la", "classificazione", "di", "caratteristiche", ",", "la", "segmentazione", "di", "immagini", ",", "la", "corrispondenza", "di", "immagini", ",", "la", "stima", "del", "movimento", ",", "il", "calcolo", "di", "spunti", "di", "forma", "e", "il", "riconoscimento", "di", "oggetti", "."], "sentence-detokenized": "Questa struttura generale \u00e8 stata applicata a una grande variet\u00e0 di problemi di computer vision, tra cui il rilevamento di caratteristiche, la classificazione di caratteristiche, la segmentazione di immagini, la corrispondenza di immagini, la stima del movimento, il calcolo di spunti di forma e il riconoscimento di oggetti.", "token2charspan": [[0, 6], [7, 16], [17, 25], [26, 27], [28, 33], [34, 43], [44, 45], [46, 49], [50, 56], [57, 64], [65, 67], [68, 76], [77, 79], [80, 88], [89, 95], [95, 96], [97, 100], [101, 104], [105, 107], [108, 119], [120, 122], [123, 138], [138, 139], [140, 142], [143, 158], [159, 161], [162, 177], [177, 178], [179, 181], [182, 195], [196, 198], [199, 207], [207, 208], [209, 211], [212, 226], [227, 229], [230, 238], [238, 239], [240, 242], [243, 248], [249, 252], [253, 262], [262, 263], [264, 266], [267, 274], [275, 277], [278, 284], [285, 287], [288, 293], [294, 295], [296, 298], [299, 313], [314, 316], [317, 324], [324, 325]]}
{"doc_key": "ai-dev-89", "ner": [[6, 8, "task"], [11, 13, "algorithm"], [18, 19, "algorithm"], [31, 32, "algorithm"], [36, 37, "algorithm"], [40, 41, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 8, 11, 13, "part-of", "", false, false], [6, 8, 18, 19, "usage", "", false, false], [11, 13, 31, 32, "named", "same", false, false], [31, 32, 36, 37, "related-to", "", false, false], [31, 32, 40, 41, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "molte", "applicazioni", "pratiche", ",", "la", "stima", "dei", "parametri", "per", "i", "modelli", "Bayes", "ingenui", "utilizza", "il", "metodo", "della", "massima", "verosimiglianza", ";", "in", "altre", "parole", ",", "si", "pu\u00f2", "lavorare", "con", "il", "modello", "Bayes", "ingenuo", "senza", "accettare", "la", "probabilit\u00e0", "bayesiana", "o", "utilizzare", "metodi", "bayesiani", "."], "sentence-detokenized": "In molte applicazioni pratiche, la stima dei parametri per i modelli Bayes ingenui utilizza il metodo della massima verosimiglianza; in altre parole, si pu\u00f2 lavorare con il modello Bayes ingenuo senza accettare la probabilit\u00e0 bayesiana o utilizzare metodi bayesiani.", "token2charspan": [[0, 2], [3, 8], [9, 21], [22, 30], [30, 31], [32, 34], [35, 40], [41, 44], [45, 54], [55, 58], [59, 60], [61, 68], [69, 74], [75, 82], [83, 91], [92, 94], [95, 101], [102, 107], [108, 115], [116, 131], [131, 132], [133, 135], [136, 141], [142, 148], [148, 149], [150, 152], [153, 156], [157, 165], [166, 169], [170, 172], [173, 180], [181, 186], [187, 194], [195, 200], [201, 210], [211, 213], [214, 225], [226, 235], [236, 237], [238, 248], [249, 255], [256, 265], [265, 266]]}
{"doc_key": "ai-dev-90", "ner": [[2, 4, "researcher"], [6, 7, "misc"], [11, 14, "university"], [16, 18, "researcher"], [20, 21, "misc"], [27, 27, "university"], [29, 29, "university"], [31, 31, "misc"], [38, 42, "university"], [47, 50, "misc"], [52, 55, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[2, 4, 11, 14, "physical", "", false, false], [2, 4, 11, 14, "role", "", false, false], [2, 4, 16, 18, "social", "brothers", false, false], [6, 7, 2, 4, "named", "", false, false], [16, 18, 27, 27, "physical", "", false, false], [16, 18, 27, 27, "role", "", false, false], [16, 18, 29, 29, "physical", "", false, false], [16, 18, 29, 29, "role", "", false, false], [16, 18, 38, 42, "physical", "", false, false], [16, 18, 38, 42, "role", "", false, false], [20, 21, 16, 18, "named", "", false, false], [31, 31, 16, 18, "origin", "", false, false], [47, 50, 16, 18, "artifact", "", false, false], [47, 50, 52, 55, "part-of", "part", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Fratelli", "-", "Victor", "Gershevich", "Katz", ",", "matematico", "americano", ",", "professore", "al", "Massachusetts", "Institute", "of", "Technology", ";", "Mikhail", "Gershevich", "Katz", ",", "matematico", "israeliano", ",", "laureato", "alle", "universit\u00e0", "di", "Harvard", "e", "Columbia", "(", "Ph.D.", ",", "1984", ")", ",", "professore", "all'", "Universit\u00e0", "di", "Bar", "-", "Ilan", ",", "autore", "della", "monografia", "Systolic", "Geometry", "and", "Topology", "(", "Mathematical", "Surveys", "and", "Monographs", ",", "vol", "."], "sentence-detokenized": "Fratelli - Victor Gershevich Katz, matematico americano, professore al Massachusetts Institute of Technology; Mikhail Gershevich Katz, matematico israeliano, laureato alle universit\u00e0 di Harvard e Columbia (Ph.D., 1984), professore all'Universit\u00e0 di Bar-Ilan, autore della monografia Systolic Geometry and Topology (Mathematical Surveys and Monographs, vol.", "token2charspan": [[0, 8], [9, 10], [11, 17], [18, 28], [29, 33], [33, 34], [35, 45], [46, 55], [55, 56], [57, 67], [68, 70], [71, 84], [85, 94], [95, 97], [98, 108], [108, 109], [110, 117], [118, 128], [129, 133], [133, 134], [135, 145], [146, 156], [156, 157], [158, 166], [167, 171], [172, 182], [183, 185], [186, 193], [194, 195], [196, 204], [205, 206], [206, 211], [211, 212], [213, 217], [217, 218], [218, 219], [220, 230], [231, 235], [235, 245], [246, 248], [249, 252], [252, 253], [253, 257], [257, 258], [259, 265], [266, 271], [272, 282], [283, 291], [292, 300], [301, 304], [305, 313], [314, 315], [315, 327], [328, 335], [336, 339], [340, 350], [350, 351], [352, 355], [355, 356]]}
{"doc_key": "ai-dev-91", "ner": [[2, 3, "person"], [8, 9, "conference"], [13, 17, "organisation"], [19, 26, "location"], [30, 30, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 8, 9, "physical", "", false, false], [2, 3, 8, 9, "role", "", false, false], [2, 3, 13, 17, "role", "", false, false], [13, 17, 19, 26, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Nel", "2000", "Manuel", "Toharia", ",", "relatore", "di", "precedenti", "Campus", "Party", "e", "direttore", "del", "Museo", "delle", "Scienze", "Principe", "Felipe", "nella", "Citt\u00e0", "delle", "Arti", "e", "delle", "Scienze", "di", "Valencia", ",", "sugger\u00ec", "a", "Ragageles", "di", "ampliare", "e", "rendere", "pi\u00f9", "internazionale", "l'", "evento", "trasferendolo", "nel", "famoso", "museo", "."], "sentence-detokenized": "Nel 2000 Manuel Toharia, relatore di precedenti Campus Party e direttore del Museo delle Scienze Principe Felipe nella Citt\u00e0 delle Arti e delle Scienze di Valencia, sugger\u00ec a Ragageles di ampliare e rendere pi\u00f9 internazionale l'evento trasferendolo nel famoso museo.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 23], [23, 24], [25, 33], [34, 36], [37, 47], [48, 54], [55, 60], [61, 62], [63, 72], [73, 76], [77, 82], [83, 88], [89, 96], [97, 105], [106, 112], [113, 118], [119, 124], [125, 130], [131, 135], [136, 137], [138, 143], [144, 151], [152, 154], [155, 163], [163, 164], [165, 172], [173, 174], [175, 184], [185, 187], [188, 196], [197, 198], [199, 206], [207, 210], [211, 225], [226, 228], [228, 234], [235, 248], [249, 252], [253, 259], [260, 265], [265, 266]]}
{"doc_key": "ai-dev-92", "ner": [[5, 8, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "20", "minuti", ",", "un", "sistema", "di", "riconoscimento", "facciale", "identifica", "le", "informazioni", "personali", ",", "tra", "cui", "il", "nome", "della", "famiglia", ",", "il", "numero", "di", "carta", "d'", "identit\u00e0", "e", "l'", "indirizzo", ",", "che", "vengono", "visualizzati", "in", "strada", "su", "uno", "schermo", "pubblicitario", "."], "sentence-detokenized": "In 20 minuti, un sistema di riconoscimento facciale identifica le informazioni personali, tra cui il nome della famiglia, il numero di carta d'identit\u00e0 e l'indirizzo, che vengono visualizzati in strada su uno schermo pubblicitario.", "token2charspan": [[0, 2], [3, 5], [6, 12], [12, 13], [14, 16], [17, 24], [25, 27], [28, 42], [43, 51], [52, 62], [63, 65], [66, 78], [79, 88], [88, 89], [90, 93], [94, 97], [98, 100], [101, 105], [106, 111], [112, 120], [120, 121], [122, 124], [125, 131], [132, 134], [135, 140], [141, 143], [143, 151], [152, 153], [154, 156], [156, 165], [165, 166], [167, 170], [171, 178], [179, 191], [192, 194], [195, 201], [202, 204], [205, 208], [209, 216], [217, 230], [230, 231]]}
{"doc_key": "ai-dev-93", "ner": [[11, 13, "field"], [15, 17, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "ricerca", "recente", "si", "\u00e8", "sempre", "pi\u00f9", "concentrata", "sugli", "algoritmi", "di", "apprendimento", "non", "supervisionato", "e", "semi", "-", "supervisionato", "."], "sentence-detokenized": "La ricerca recente si \u00e8 sempre pi\u00f9 concentrata sugli algoritmi di apprendimento non supervisionato e semi-supervisionato.", "token2charspan": [[0, 2], [3, 10], [11, 18], [19, 21], [22, 23], [24, 30], [31, 34], [35, 46], [47, 52], [53, 62], [63, 65], [66, 79], [80, 83], [84, 98], [99, 100], [101, 105], [105, 106], [106, 120], [120, 121]]}
{"doc_key": "ai-dev-94", "ner": [[7, 7, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Calcolo", "di", "questo", "esempio", "utilizzando", "il", "codice", "Python", ":"], "sentence-detokenized": "Calcolo di questo esempio utilizzando il codice Python:", "token2charspan": [[0, 7], [8, 10], [11, 17], [18, 25], [26, 37], [38, 40], [41, 47], [48, 54], [54, 55]]}
{"doc_key": "ai-dev-95", "ner": [[7, 8, "task"], [18, 19, "field"], [21, 23, "algorithm"], [25, 25, "algorithm"], [29, 31, "algorithm"], [34, 35, "researcher"], [37, 38, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[21, 23, 18, 19, "part-of", "", false, false], [21, 23, 29, 31, "type-of", "", false, false], [21, 23, 34, 35, "origin", "", false, false], [21, 23, 37, 38, "origin", "", false, false], [25, 25, 21, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Oggi", ",", "tuttavia", ",", "molti", "aspetti", "del", "riconoscimento", "vocale", "sono", "stati", "presi", "in", "considerazione", "da", "un", "metodo", "di", "apprendimento", "profondo", "chiamato", "Long", "short-term", "memory", "(", "LSTM", ")", ",", "una", "rete", "neurale", "ricorrente", "pubblicata", "da", "Sepp", "Hochreiter", "e", "J\u00fcrgen", "Schmidhuber", "nel", "1997", "."], "sentence-detokenized": "Oggi, tuttavia, molti aspetti del riconoscimento vocale sono stati presi in considerazione da un metodo di apprendimento profondo chiamato Long short-term memory (LSTM), una rete neurale ricorrente pubblicata da Sepp Hochreiter e J\u00fcrgen Schmidhuber nel 1997.", "token2charspan": [[0, 4], [4, 5], [6, 14], [14, 15], [16, 21], [22, 29], [30, 33], [34, 48], [49, 55], [56, 60], [61, 66], [67, 72], [73, 75], [76, 90], [91, 93], [94, 96], [97, 103], [104, 106], [107, 120], [121, 129], [130, 138], [139, 143], [144, 154], [155, 161], [162, 163], [163, 167], [167, 168], [168, 169], [170, 173], [174, 178], [179, 186], [187, 197], [198, 208], [209, 211], [212, 216], [217, 227], [228, 229], [230, 236], [237, 248], [249, 252], [253, 257], [257, 258]]}
{"doc_key": "ai-dev-96", "ner": [[10, 10, "algorithm"], [18, 18, "algorithm"], [22, 25, "algorithm"], [29, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 10, 18, 18, "compare", "", false, false], [10, 10, 29, 29, "named", "same", false, false], [22, 25, 29, 29, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Nei", "risultati", "sperimentali", "preliminari", "con", "set", "di", "dati", "rumorosi", ",", "BrownBoost", "ha", "superato", "l'", "errore", "di", "generalizzazione", "di", "AdaBoost", ";", "tuttavia", ",", "LogitBoost", "ha", "ottenuto", "le", "stesse", "prestazioni", "di", "BrownBoost."], "sentence-detokenized": "Nei risultati sperimentali preliminari con set di dati rumorosi, BrownBoost ha superato l'errore di generalizzazione di AdaBoost; tuttavia, LogitBoost ha ottenuto le stesse prestazioni di BrownBoost.", "token2charspan": [[0, 3], [4, 13], [14, 26], [27, 38], [39, 42], [43, 46], [47, 49], [50, 54], [55, 63], [63, 64], [65, 75], [76, 78], [79, 87], [88, 90], [90, 96], [97, 99], [100, 116], [117, 119], [120, 128], [128, 129], [130, 138], [138, 139], [140, 150], [151, 153], [154, 162], [163, 165], [166, 172], [173, 184], [185, 187], [188, 199]]}
{"doc_key": "ai-dev-97", "ner": [[0, 2, "algorithm"], [7, 10, "researcher"], [12, 13, "country"], [16, 19, "researcher"], [24, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 7, 10, "part-of", "", false, false], [7, 10, 12, 13, "physical", "", false, false], [24, 25, 16, 19, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "programmazione", "evolutiva", "\u00e8", "stata", "introdotta", "da", "Lawrence", "J", ".", "Fogel", "negli", "Stati", "Uniti", ",", "mentre", "John", "Henry", "Holland", "ha", "chiamato", "il", "suo", "metodo", "algoritmo", "genetico", "."], "sentence-detokenized": "La programmazione evolutiva \u00e8 stata introdotta da Lawrence J. Fogel negli Stati Uniti, mentre John Henry Holland ha chiamato il suo metodo algoritmo genetico.", "token2charspan": [[0, 2], [3, 17], [18, 27], [28, 29], [30, 35], [36, 46], [47, 49], [50, 58], [59, 60], [60, 61], [62, 67], [68, 73], [74, 79], [80, 85], [85, 86], [87, 93], [94, 98], [99, 104], [105, 112], [113, 115], [116, 124], [125, 127], [128, 131], [132, 138], [139, 148], [149, 157], [157, 158]]}
{"doc_key": "ai-dev-98", "ner": [[4, 4, "researcher"], [6, 6, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 4, 14, 15, "role", "", false, false], [4, 4, 17, 18, "role", "", false, false], [4, 4, 20, 21, "role", "", false, false], [4, 4, 23, 24, "role", "", false, false], [6, 6, 14, 15, "role", "", false, false], [6, 6, 17, 18, "role", "", false, false], [6, 6, 20, 21, "role", "", false, false], [6, 6, 23, 24, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["I", "calcoli", "fatti", "da", "Doug", ",", "Alan", "e", "dai", "loro", "colleghi", "(", "tra", "cui", "Marvin", "Minsky", ",", "Allen", "Newell", ",", "Edward", "Feigenbaum", "e", "John", "McCarthy", ")", "indicavano", "che", "questo", "sforzo", "avrebbe", "richiesto", "tra", "i", "1.000", "e", "i", "3.000", "anni", "di", "lavoro", ",", "ben", "oltre", "il", "modello", "di", "progetto", "accademico", "standard", "."], "sentence-detokenized": "I calcoli fatti da Doug, Alan e dai loro colleghi (tra cui Marvin Minsky, Allen Newell, Edward Feigenbaum e John McCarthy) indicavano che questo sforzo avrebbe richiesto tra i 1.000 e i 3.000 anni di lavoro, ben oltre il modello di progetto accademico standard.", "token2charspan": [[0, 1], [2, 9], [10, 15], [16, 18], [19, 23], [23, 24], [25, 29], [30, 31], [32, 35], [36, 40], [41, 49], [50, 51], [51, 54], [55, 58], [59, 65], [66, 72], [72, 73], [74, 79], [80, 86], [86, 87], [88, 94], [95, 105], [106, 107], [108, 112], [113, 121], [121, 122], [123, 133], [134, 137], [138, 144], [145, 151], [152, 159], [160, 169], [170, 173], [174, 175], [176, 181], [182, 183], [184, 185], [186, 191], [192, 196], [197, 199], [200, 206], [206, 207], [208, 211], [212, 217], [218, 220], [221, 228], [229, 231], [232, 240], [241, 251], [252, 260], [260, 261]]}
{"doc_key": "ai-dev-99", "ner": [[7, 9, "metrics"], [12, 12, "metrics"], [15, 18, "metrics"], [21, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 9, 12, 12, "part-of", "implemented_in", false, false], [15, 18, 21, 21, "part-of", "implemented_in", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["I", "criteri", "comuni", "sono", "il", "criterio", "dell'", "errore", "quadratico", "medio", "implementato", "in", "MSECriterion", "e", "il", "criterio", "dell'", "entropia", "incrociata", "implementato", "in", "NLLCriterion", "."], "sentence-detokenized": "I criteri comuni sono il criterio dell'errore quadratico medio implementato in MSECriterion e il criterio dell'entropia incrociata implementato in NLLCriterion.", "token2charspan": [[0, 1], [2, 9], [10, 16], [17, 21], [22, 24], [25, 33], [34, 39], [39, 45], [46, 56], [57, 62], [63, 75], [76, 78], [79, 91], [92, 93], [94, 96], [97, 105], [106, 111], [111, 119], [120, 130], [131, 143], [144, 146], [147, 159], [159, 160]]}
{"doc_key": "ai-dev-100", "ner": [[0, 0, "researcher"], [12, 12, "organisation"], [15, 24, "misc"], [38, 41, "conference"], [44, 45, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 12, 12, "role", "", false, false], [0, 0, 38, 41, "role", "", false, false], [0, 0, 44, 45, "role", "", false, false], [15, 24, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Zurada", "ha", "servito", "la", "professione", "ingegneristica", "come", "volontario", "di", "lunga", "data", "dell'", "IEEE", ":", "nel", "2014", "\u00e8", "stato", "vicepresidente", "dell'", "IEEE", "per", "le", "attivit\u00e0", "tecniche", "(", "TAB", "Chair", ")", ",", "nel", "2004", "-", "05", "\u00e8", "stato", "presidente", "della", "IEEE", "Computational", "Intelligence", "Society", "e", "membro", "dell'", "ADCOM", "nel", "2009", "-", "14", ",", "2016", "-", "18", "e", "negli", "anni", "precedenti", "."], "sentence-detokenized": "Zurada ha servito la professione ingegneristica come volontario di lunga data dell'IEEE: nel 2014 \u00e8 stato vicepresidente dell'IEEE per le attivit\u00e0 tecniche (TAB Chair), nel 2004-05 \u00e8 stato presidente della IEEE Computational Intelligence Society e membro dell'ADCOM nel 2009-14, 2016-18 e negli anni precedenti.", "token2charspan": [[0, 6], [7, 9], [10, 17], [18, 20], [21, 32], [33, 47], [48, 52], [53, 63], [64, 66], [67, 72], [73, 77], [78, 83], [83, 87], [87, 88], [89, 92], [93, 97], [98, 99], [100, 105], [106, 120], [121, 126], [126, 130], [131, 134], [135, 137], [138, 146], [147, 155], [156, 157], [157, 160], [161, 166], [166, 167], [167, 168], [169, 172], [173, 177], [177, 178], [178, 180], [181, 182], [183, 188], [189, 199], [200, 205], [206, 210], [211, 224], [225, 237], [238, 245], [246, 247], [248, 254], [255, 260], [260, 265], [266, 269], [270, 274], [274, 275], [275, 277], [277, 278], [279, 283], [283, 284], [284, 286], [287, 288], [289, 294], [295, 299], [300, 310], [310, 311]]}
{"doc_key": "ai-dev-101", "ner": [[4, 5, "field"], [13, 13, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 13, 4, 5, "part-of", "", false, false], [17, 18, 4, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "generale", ",", "la", "linguistica", "computazionale", "si", "avvale", "del", "coinvolgimento", "di", "linguisti", ",", "informatici", ",", "esperti", "di", "intelligenza", "artificiale", ",", "matematici", ",", "logici", ",", "filosofi", ",", "scienziati", "cognitivi", ",", "psicologi", "cognitivi", ",", "psicolinguisti", ",", "antropologi", "e", "neuroscienziati", ",", "tra", "gli", "altri", "."], "sentence-detokenized": "In generale, la linguistica computazionale si avvale del coinvolgimento di linguisti, informatici, esperti di intelligenza artificiale, matematici, logici, filosofi, scienziati cognitivi, psicologi cognitivi, psicolinguisti, antropologi e neuroscienziati, tra gli altri.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 15], [16, 27], [28, 42], [43, 45], [46, 52], [53, 56], [57, 71], [72, 74], [75, 84], [84, 85], [86, 97], [97, 98], [99, 106], [107, 109], [110, 122], [123, 134], [134, 135], [136, 146], [146, 147], [148, 154], [154, 155], [156, 164], [164, 165], [166, 176], [177, 186], [186, 187], [188, 197], [198, 207], [207, 208], [209, 223], [223, 224], [225, 236], [237, 238], [239, 254], [254, 255], [256, 259], [260, 263], [264, 269], [269, 270]]}
{"doc_key": "ai-dev-102", "ner": [[13, 16, "algorithm"], [19, 21, "algorithm"], [24, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Per", "sfruttare", "le", "correlazioni", "tra", "i", "fotogrammi", "si", "utilizzano", "spesso", "tecniche", "come", "le", "reti", "di", "Markov", "dinamiche", ",", "le", "reti", "neurali", "convoluzionali", "e", "la", "memoria", "a", "breve", "termine", "."], "sentence-detokenized": "Per sfruttare le correlazioni tra i fotogrammi si utilizzano spesso tecniche come le reti di Markov dinamiche, le reti neurali convoluzionali e la memoria a breve termine.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 29], [30, 33], [34, 35], [36, 46], [47, 49], [50, 60], [61, 67], [68, 76], [77, 81], [82, 84], [85, 89], [90, 92], [93, 99], [100, 109], [109, 110], [111, 113], [114, 118], [119, 126], [127, 141], [142, 143], [144, 146], [147, 154], [155, 156], [157, 162], [163, 170], [170, 171]]}
{"doc_key": "ai-dev-103", "ner": [[0, 0, "product"], [5, 6, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 5, 6, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Unimate", "\u00e8", "stato", "il", "primo", "robot", "industriale", ","], "sentence-detokenized": "Unimate \u00e8 stato il primo robot industriale,", "token2charspan": [[0, 7], [8, 9], [10, 15], [16, 18], [19, 24], [25, 30], [31, 42], [42, 43]]}
{"doc_key": "ai-dev-104", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [12, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 12, 14, "win-defeat", "", false, false], [5, 6, 12, 14, "win-defeat", "", false, false], [8, 8, 12, 14, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Insieme", "a", "Geoffrey", "Hinton", "e", "Yann", "LeCun", ",", "Bengio", "ha", "vinto", "il", "Premio", "Turing", "2018", "."], "sentence-detokenized": "Insieme a Geoffrey Hinton e Yann LeCun, Bengio ha vinto il Premio Turing 2018.", "token2charspan": [[0, 7], [8, 9], [10, 18], [19, 25], [26, 27], [28, 32], [33, 38], [38, 39], [40, 46], [47, 49], [50, 55], [56, 58], [59, 65], [66, 72], [73, 77], [77, 78]]}
{"doc_key": "ai-dev-105", "ner": [[7, 9, "country"], [22, 25, "misc"], [28, 28, "country"], [31, 32, "organisation"], [36, 37, "person"], [39, 40, "person"], [48, 50, "misc"], [55, 56, "country"], [63, 63, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[22, 25, 7, 9, "physical", "filmed_in", false, false], [36, 37, 31, 32, "role", "host", false, false], [39, 40, 31, 32, "role", "reporter", false, false], [48, 50, 7, 9, "physical", "filmed_in", false, false], [48, 50, 55, 56, "physical", "distributed_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Altre", "serie", "sono", "state", "girate", "nella", "sede", "del", "Regno", "Unito", "per", "settori", "specifici", "del", "mercato", "globale", ",", "tra", "cui", "due", "serie", "di", "Robot", "Wars", "Extreme", "Warriors", "con", "concorrenti", "statunitensi", "per", "la", "rete", "TNN", "(", "condotte", "da", "Mick", "Foley", "e", "Rebecca", "Grant", "come", "pit", "reporter", ")", ",", "due", "di", "Dutch", "Robot", "Wars", "per", "la", "distribuzione", "nei", "Paesi", "Bassi", "e", "una", "singola", "serie", "per", "la", "Germania", "."], "sentence-detokenized": "Altre serie sono state girate nella sede del Regno Unito per settori specifici del mercato globale, tra cui due serie di Robot Wars Extreme Warriors con concorrenti statunitensi per la rete TNN (condotte da Mick Foley e Rebecca Grant come pit reporter), due di Dutch Robot Wars per la distribuzione nei Paesi Bassi e una singola serie per la Germania.", "token2charspan": [[0, 5], [6, 11], [12, 16], [17, 22], [23, 29], [30, 35], [36, 40], [41, 44], [45, 50], [51, 56], [57, 60], [61, 68], [69, 78], [79, 82], [83, 90], [91, 98], [98, 99], [100, 103], [104, 107], [108, 111], [112, 117], [118, 120], [121, 126], [127, 131], [132, 139], [140, 148], [149, 152], [153, 164], [165, 177], [178, 181], [182, 184], [185, 189], [190, 193], [194, 195], [195, 203], [204, 206], [207, 211], [212, 217], [218, 219], [220, 227], [228, 233], [234, 238], [239, 242], [243, 251], [251, 252], [252, 253], [254, 257], [258, 260], [261, 266], [267, 272], [273, 277], [278, 281], [282, 284], [285, 298], [299, 302], [303, 308], [309, 314], [315, 316], [317, 320], [321, 328], [329, 334], [335, 338], [339, 341], [342, 350], [350, 351]]}
{"doc_key": "ai-dev-106", "ner": [[9, 9, "researcher"], [15, 15, "product"], [30, 32, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 15, 15, "role", "", false, false], [30, 32, 15, 15, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Per", "molti", "anni", ",", "a", "partire", "dal", "1986", ",", "Miller", "ha", "diretto", "lo", "sviluppo", "di", "WordNet", ",", "un", "grande", "riferimento", "elettronico", "leggibile", "al", "computer", "e", "utilizzabile", "in", "applicazioni", "come", "i", "motori", "di", "ricerca", "."], "sentence-detokenized": "Per molti anni, a partire dal 1986, Miller ha diretto lo sviluppo di WordNet, un grande riferimento elettronico leggibile al computer e utilizzabile in applicazioni come i motori di ricerca.", "token2charspan": [[0, 3], [4, 9], [10, 14], [14, 15], [16, 17], [18, 25], [26, 29], [30, 34], [34, 35], [36, 42], [43, 45], [46, 53], [54, 56], [57, 65], [66, 68], [69, 76], [76, 77], [78, 80], [81, 87], [88, 99], [100, 111], [112, 121], [122, 124], [125, 133], [134, 135], [136, 148], [149, 151], [152, 164], [165, 169], [170, 171], [172, 178], [179, 181], [182, 189], [189, 190]]}
{"doc_key": "ai-dev-107", "ner": [[4, 6, "algorithm"], [9, 13, "algorithm"], [20, 21, "researcher"], [24, 29, "organisation"], [33, 36, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 20, 21, "origin", "", false, false], [4, 6, 33, 36, "win-defeat", "", false, false], [9, 13, 20, 21, "origin", "", false, false], [9, 13, 33, 36, "win-defeat", "", false, false], [20, 21, 24, 29, "physical", "", false, false], [20, 21, 24, 29, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Dal", "2009", ",", "le", "reti", "neurali", "ricorrenti", "e", "le", "reti", "neurali", "profonde", "a", "feedforward", "sviluppate", "dal", "gruppo", "di", "ricerca", "di", "J\u00fcrgen", "Schmidhuber", "presso", "il", "laboratorio", "svizzero", "di", "intelligenza", "artificiale", "IDSIA", "hanno", "vinto", "diversi", "concorsi", "internazionali", "di", "scrittura..", "."], "sentence-detokenized": "Dal 2009, le reti neurali ricorrenti e le reti neurali profonde a feedforward sviluppate dal gruppo di ricerca di J\u00fcrgen Schmidhuber presso il laboratorio svizzero di intelligenza artificiale IDSIA hanno vinto diversi concorsi internazionali di scrittura...", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 12], [13, 17], [18, 25], [26, 36], [37, 38], [39, 41], [42, 46], [47, 54], [55, 63], [64, 65], [66, 77], [78, 88], [89, 92], [93, 99], [100, 102], [103, 110], [111, 113], [114, 120], [121, 132], [133, 139], [140, 142], [143, 154], [155, 163], [164, 166], [167, 179], [180, 191], [192, 197], [198, 203], [204, 209], [210, 217], [218, 226], [227, 241], [242, 244], [245, 256], [256, 257]]}
{"doc_key": "ai-dev-108", "ner": [[5, 7, "programlang"], [13, 13, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Il", "software", "\u00e8", "implementato", "in", "C", "+", "+", "ed", "\u00e8", "stato", "confezionato", "per", "Python", "."], "sentence-detokenized": "Il software \u00e8 implementato in C ++ ed \u00e8 stato confezionato per Python.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 26], [27, 29], [30, 31], [32, 33], [33, 34], [35, 37], [38, 39], [40, 45], [46, 58], [59, 62], [63, 69], [69, 70]]}
{"doc_key": "ai-dev-109", "ner": [[6, 7, "country"], [12, 13, "misc"], [18, 19, "misc"], [32, 33, "misc"], [35, 35, "misc"], [38, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[18, 19, 6, 7, "temporal", "", false, false], [18, 19, 12, 13, "artifact", "", false, false], [18, 19, 38, 38, "physical", "", false, false], [35, 35, 32, 33, "named", "", false, false], [35, 35, 38, 38, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Nel", "1857", ",", "su", "richiesta", "dello", "shogunato", "Tokugawa", ",", "un", "gruppo", "di", "ingegneri", "olandesi", "inizi\u00f2", "a", "lavorare", "al", "Nagasaki", "Yotetsusho", ",", "una", "moderna", "fonderia", "e", "cantiere", "navale", "in", "stile", "occidentale", "vicino", "all'", "insediamento", "olandese", "di", "Dejima", ",", "a", "Nagasaki", "."], "sentence-detokenized": "Nel 1857, su richiesta dello shogunato Tokugawa, un gruppo di ingegneri olandesi inizi\u00f2 a lavorare al Nagasaki Yotetsusho, una moderna fonderia e cantiere navale in stile occidentale vicino all'insediamento olandese di Dejima, a Nagasaki.", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 12], [13, 22], [23, 28], [29, 38], [39, 47], [47, 48], [49, 51], [52, 58], [59, 61], [62, 71], [72, 80], [81, 87], [88, 89], [90, 98], [99, 101], [102, 110], [111, 121], [121, 122], [123, 126], [127, 134], [135, 143], [144, 145], [146, 154], [155, 161], [162, 164], [165, 170], [171, 182], [183, 189], [190, 194], [194, 206], [207, 215], [216, 218], [219, 225], [225, 226], [227, 228], [229, 237], [237, 238]]}
{"doc_key": "ai-dev-110", "ner": [[9, 11, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Per", "essere", "il", "pi\u00f9", "precisi", "possibile", ",", "misuriamo", "l'", "errore", "quadratico", "medio", "tra", "mathy", "/", "math", "e", "math", "\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", "/", "math", ":", "vogliamo", "che", "math", "(", "y", "-", "\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", ")", "^", "2", "/", "math", "sia", "minimo", ",", "sia", "per", "mathx", "_", "1", ",", "\\", "punti", ",", "x", "_n", "/", "math", "che", "per", "i", "punti", "al", "di", "fuori", "del", "nostro", "campione", "."], "sentence-detokenized": "Per essere il pi\u00f9 precisi possibile, misuriamo l'errore quadratico medio tra mathy / math e math\\ hat {f} (x; D) / math: vogliamo che math (y -\\ hat {f} (x; D)) ^ 2 / math sia minimo, sia per mathx _ 1,\\ punti, x _n / math che per i punti al di fuori del nostro campione.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 17], [18, 25], [26, 35], [35, 36], [37, 46], [47, 49], [49, 55], [56, 66], [67, 72], [73, 76], [77, 82], [83, 84], [85, 89], [90, 91], [92, 96], [96, 97], [98, 101], [102, 103], [103, 104], [104, 105], [106, 107], [107, 108], [108, 109], [110, 111], [111, 112], [113, 114], [115, 119], [119, 120], [121, 129], [130, 133], [134, 138], [139, 140], [140, 141], [142, 143], [143, 144], [145, 148], [149, 150], [150, 151], [151, 152], [153, 154], [154, 155], [155, 156], [157, 158], [158, 159], [159, 160], [161, 162], [163, 164], [165, 166], [167, 171], [172, 175], [176, 182], [182, 183], [184, 187], [188, 191], [192, 197], [198, 199], [200, 201], [201, 202], [202, 203], [204, 209], [209, 210], [211, 212], [213, 215], [216, 217], [218, 222], [223, 226], [227, 230], [231, 232], [233, 238], [239, 241], [242, 244], [245, 250], [251, 254], [255, 261], [262, 270], [270, 271]]}
{"doc_key": "ai-dev-111", "ner": [[7, 10, "researcher"], [16, 18, "organisation"], [22, 27, "product"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 10, 16, 18, "role", "", false, false], [22, 27, 16, 18, "temporal", "", false, false], [22, 27, 35, 36, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "seguito", ",", "nell'", "ottobre", "successivo", ",", "Wydner", "fu", "invitato", "a", "partecipare", "alla", "riunione", "annuale", "dell'", "American", "Translators", "Association", ",", "dove", "il", "sistema", "di", "traduzione", "automatica", "di", "Weidner", "fu", "salutato", "come", "un'", "auspicata", "svolta", "nella", "traduzione", "automatica", "."], "sentence-detokenized": "In seguito, nell'ottobre successivo, Wydner fu invitato a partecipare alla riunione annuale dell'American Translators Association, dove il sistema di traduzione automatica di Weidner fu salutato come un'auspicata svolta nella traduzione automatica.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 17], [17, 24], [25, 35], [35, 36], [37, 43], [44, 46], [47, 55], [56, 57], [58, 69], [70, 74], [75, 83], [84, 91], [92, 97], [97, 105], [106, 117], [118, 129], [129, 130], [131, 135], [136, 138], [139, 146], [147, 149], [150, 160], [161, 171], [172, 174], [175, 182], [183, 185], [186, 194], [195, 199], [200, 203], [203, 212], [213, 219], [220, 225], [226, 236], [237, 247], [247, 248]]}
{"doc_key": "ai-dev-112", "ner": [[3, 11, "conference"], [13, 13, "conference"], [19, 19, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 13, 3, 11, "named", "", false, false], [13, 13, 3, 11, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "occasione", "della", "Conferenza", "2018", "sui", "sistemi", "di", "elaborazione", "dell'", "informazione", "neurale", "(", "NeurIPS", ")", ",", "i", "ricercatori", "di", "Google", "hanno", "presentato", "il", "lavoro", "."], "sentence-detokenized": "In occasione della Conferenza 2018 sui sistemi di elaborazione dell'informazione neurale (NeurIPS), i ricercatori di Google hanno presentato il lavoro.", "token2charspan": [[0, 2], [3, 12], [13, 18], [19, 29], [30, 34], [35, 38], [39, 46], [47, 49], [50, 62], [63, 68], [68, 80], [81, 88], [89, 90], [90, 97], [97, 98], [98, 99], [100, 101], [102, 113], [114, 116], [117, 123], [124, 129], [130, 140], [141, 143], [144, 150], [150, 151]]}
{"doc_key": "ai-dev-113", "ner": [[1, 5, "algorithm"], [9, 10, "algorithm"], [14, 17, "metrics"], [22, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 5, 9, 10, "usage", "", false, false], [9, 10, 14, 17, "related-to", "", true, false], [14, 17, 22, 25, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["L'", "algoritmo", "di", "Baum", "-", "Welch", "utilizza", "il", "noto", "algoritmo", "EM", "per", "trovare", "la", "stima", "di", "massima", "verosimiglianza", "dei", "parametri", "di", "un", "modello", "di", "Markov", "nascosto", "dato", "un", "insieme", "di", "vettori", "di", "caratteristiche", "osservate", "."], "sentence-detokenized": "L'algoritmo di Baum-Welch utilizza il noto algoritmo EM per trovare la stima di massima verosimiglianza dei parametri di un modello di Markov nascosto dato un insieme di vettori di caratteristiche osservate.", "token2charspan": [[0, 2], [2, 11], [12, 14], [15, 19], [19, 20], [20, 25], [26, 34], [35, 37], [38, 42], [43, 52], [53, 55], [56, 59], [60, 67], [68, 70], [71, 76], [77, 79], [80, 87], [88, 103], [104, 107], [108, 117], [118, 120], [121, 123], [124, 131], [132, 134], [135, 141], [142, 150], [151, 155], [156, 158], [159, 166], [167, 169], [170, 177], [178, 180], [181, 196], [197, 206], [206, 207]]}
{"doc_key": "ai-dev-114", "ner": [[6, 6, "product"], [8, 8, "product"], [30, 32, "misc"], [37, 46, "product"], [51, 51, "programlang"], [48, 59, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 6, 8, 8, "compare", "", false, false], [30, 32, 8, 8, "part-of", "", false, false], [37, 46, 8, 8, "part-of", "", false, false], [48, 59, 8, 8, "part-of", "", false, false], [48, 59, 51, 51, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Oltre", "alle", "informazioni", "tassonomiche", "contenute", "in", "OpenCyc", ",", "ResearchCyc", "include", "un", "numero", "significativamente", "maggiore", "di", "conoscenze", "semantiche", "(", "cio\u00e8", "fatti", "e", "regole", "empiriche", "aggiuntive", ")", "relative", "ai", "concetti", "della", "sua", "base", "di", "conoscenza", ";", "include", "anche", "un", "ampio", "lessico", ",", "strumenti", "di", "parsing", "e", "generazione", "in", "inglese", "e", "interfacce", "basate", "su", "Java", "per", "la", "modifica", "e", "l'", "interrogazione", "della", "conoscenza", "."], "sentence-detokenized": "Oltre alle informazioni tassonomiche contenute in OpenCyc, ResearchCyc include un numero significativamente maggiore di conoscenze semantiche (cio\u00e8 fatti e regole empiriche aggiuntive) relative ai concetti della sua base di conoscenza; include anche un ampio lessico, strumenti di parsing e generazione in inglese e interfacce basate su Java per la modifica e l'interrogazione della conoscenza.", "token2charspan": [[0, 5], [6, 10], [11, 23], [24, 36], [37, 46], [47, 49], [50, 57], [57, 58], [59, 70], [71, 78], [79, 81], [82, 88], [89, 107], [108, 116], [117, 119], [120, 130], [131, 141], [142, 143], [143, 147], [148, 153], [154, 155], [156, 162], [163, 172], [173, 183], [183, 184], [185, 193], [194, 196], [197, 205], [206, 211], [212, 215], [216, 220], [221, 223], [224, 234], [234, 235], [236, 243], [244, 249], [250, 252], [253, 258], [259, 266], [266, 267], [268, 277], [278, 280], [281, 288], [289, 290], [291, 302], [303, 305], [306, 313], [314, 315], [316, 326], [327, 333], [334, 336], [337, 341], [342, 345], [346, 348], [349, 357], [358, 359], [360, 362], [362, 376], [377, 382], [383, 393], [393, 394]]}
{"doc_key": "ai-dev-115", "ner": [[0, 3, "algorithm"], [8, 10, "task"], [13, 15, "field"], [18, 19, "field"], [22, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 8, 10, "type-of", "", false, false], [8, 10, 13, 15, "part-of", "task_part_of_field", false, false], [8, 10, 18, 19, "part-of", "task_part_of_field", false, false], [8, 10, 22, 25, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["La", "trasformata", "di", "Hough", "\u00e8", "una", "tecnica", "di", "estrazione", "di", "caratteristiche", "utilizzata", "nell'", "analisi", "delle", "immagini", ",", "nella", "computer", "vision", "e", "nell'", "elaborazione", "delle", "immagini", "digitali", "."], "sentence-detokenized": "La trasformata di Hough \u00e8 una tecnica di estrazione di caratteristiche utilizzata nell'analisi delle immagini, nella computer vision e nell'elaborazione delle immagini digitali.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 23], [24, 25], [26, 29], [30, 37], [38, 40], [41, 51], [52, 54], [55, 70], [71, 81], [82, 87], [87, 94], [95, 100], [101, 109], [109, 110], [111, 116], [117, 125], [126, 132], [133, 134], [135, 140], [140, 152], [153, 158], [159, 167], [168, 176], [176, 177]]}
{"doc_key": "ai-dev-116", "ner": [[5, 5, "product"], [7, 11, "product"], [16, 16, "organisation"], [20, 20, "product"], [22, 23, "researcher"], [30, 31, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 5, 7, 11, "named", "", false, false], [5, 5, 16, 16, "artifact", "", false, false], [5, 5, 20, 20, "origin", "developed_from", false, false], [20, 20, 22, 23, "artifact", "", false, false], [30, 31, 16, 16, "role", "supported", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Nel", "1978", ",", "il", "robot", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", "fu", "sviluppato", "da", "Unimation", "a", "partire", "da", "Vicarm", "(", "Victor", "Scheinman", ")", "e", "con", "il", "supporto", "di", "General", "Motors", "."], "sentence-detokenized": "Nel 1978, il robot PUMA (Programmable Universal Machine for Assembly) fu sviluppato da Unimation a partire da Vicarm (Victor Scheinman) e con il supporto di General Motors.", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 12], [13, 18], [19, 23], [24, 25], [25, 37], [38, 47], [48, 55], [56, 59], [60, 68], [68, 69], [70, 72], [73, 83], [84, 86], [87, 96], [97, 98], [99, 106], [107, 109], [110, 116], [117, 118], [118, 124], [125, 134], [134, 135], [136, 137], [138, 141], [142, 144], [145, 153], [154, 156], [157, 164], [165, 171], [171, 172]]}
{"doc_key": "ai-dev-117", "ner": [[0, 0, "algorithm"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 7, 8, "origin", "", false, false], [0, 0, 10, 11, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["LSTM", "\u00e8", "stato", "proposto", "nel", "1997", "da", "Sepp", "Hochreiter", "e", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "LSTM \u00e8 stato proposto nel 1997 da Sepp Hochreiter e J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 6], [7, 12], [13, 21], [22, 25], [26, 30], [31, 33], [34, 38], [39, 49], [50, 51], [52, 58], [59, 70], [70, 71]]}
{"doc_key": "ai-dev-118", "ner": [[8, 10, "metrics"], [15, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["I", "quattro", "risultati", "possono", "essere", "formulati", "in", "una", "tabella", "di", "contingenza", "2", "\u00d7", "2", "o", "matrice", "di", "confusione", ",", "come", "segue", ":"], "sentence-detokenized": "I quattro risultati possono essere formulati in una tabella di contingenza 2 \u00d7 2 o matrice di confusione, come segue:", "token2charspan": [[0, 1], [2, 9], [10, 19], [20, 27], [28, 34], [35, 44], [45, 47], [48, 51], [52, 59], [60, 62], [63, 74], [75, 76], [77, 78], [79, 80], [81, 82], [83, 90], [91, 93], [94, 104], [104, 105], [106, 110], [111, 116], [116, 117]]}
{"doc_key": "ai-dev-119", "ner": [[7, 7, "conference"], [10, 11, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ha", "contribuito", "molto", "anche", "alla", "creazione", "dell'", "ELRA", "e", "della", "conferenza", "LREC", "."], "sentence-detokenized": "Ha contribuito molto anche alla creazione dell'ELRA e della conferenza LREC.", "token2charspan": [[0, 2], [3, 14], [15, 20], [21, 26], [27, 31], [32, 41], [42, 47], [47, 51], [52, 53], [54, 59], [60, 70], [71, 75], [75, 76]]}
{"doc_key": "ai-dev-120", "ner": [[12, 14, "misc"], [22, 23, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[22, 23, 12, 14, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Un'", "applicazione", "popolare", "per", "i", "robot", "seriali", "nell'", "industria", "odierna", "\u00e8", "il", "robot", "di", "assemblaggio", "pick", "-", "and", "-", "place", ",", "chiamato", "robot", "SCARA", ",", "che", "ha", "quattro", "gradi", "di", "libert\u00e0", "."], "sentence-detokenized": "Un'applicazione popolare per i robot seriali nell'industria odierna \u00e8 il robot di assemblaggio pick-and-place, chiamato robot SCARA, che ha quattro gradi di libert\u00e0.", "token2charspan": [[0, 3], [3, 15], [16, 24], [25, 28], [29, 30], [31, 36], [37, 44], [45, 50], [50, 59], [60, 67], [68, 69], [70, 72], [73, 78], [79, 81], [82, 94], [95, 99], [99, 100], [100, 103], [103, 104], [104, 109], [109, 110], [111, 119], [120, 125], [126, 131], [131, 132], [133, 136], [137, 139], [140, 147], [148, 153], [154, 156], [157, 164], [164, 165]]}
{"doc_key": "ai-dev-121", "ner": [[15, 21, "conference"], [23, 23, "conference"], [26, 29, "conference"], [37, 37, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 15, 21, "named", "", false, false], [37, 37, 26, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["\u00c8", "stato", "uno", "dei", "membri", "fondatori", "ed", "ex", "presidente", "(", "2006", "-", "2008", ")", "dello", "Special", "Interest", "Group", "on", "Web", "as", "Corpus", "(", "SIGWAC", ")", "dell'", "Association", "for", "Computational", "Linguistics", "e", "anche", "uno", "degli", "organizzatori", "fondatori", "di", "SENSEVAL", "."], "sentence-detokenized": "\u00c8 stato uno dei membri fondatori ed ex presidente (2006-2008) dello Special Interest Group on Web as Corpus (SIGWAC) dell'Association for Computational Linguistics e anche uno degli organizzatori fondatori di SENSEVAL.", "token2charspan": [[0, 1], [2, 7], [8, 11], [12, 15], [16, 22], [23, 32], [33, 35], [36, 38], [39, 49], [50, 51], [51, 55], [55, 56], [56, 60], [60, 61], [62, 67], [68, 75], [76, 84], [85, 90], [91, 93], [94, 97], [98, 100], [101, 107], [108, 109], [109, 115], [115, 116], [117, 122], [122, 133], [134, 137], [138, 151], [152, 163], [164, 165], [166, 171], [172, 175], [176, 181], [182, 195], [196, 205], [206, 208], [209, 217], [217, 218]]}
{"doc_key": "ai-dev-122", "ner": [[3, 3, "product"], [7, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 3, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Come", "piattaforma", ",", "LinguaStream", "offre", "un'", "ampia", "API", "Java", "."], "sentence-detokenized": "Come piattaforma, LinguaStream offre un'ampia API Java.", "token2charspan": [[0, 4], [5, 16], [16, 17], [18, 30], [31, 36], [37, 40], [40, 45], [46, 49], [50, 54], [54, 55]]}
{"doc_key": "ai-dev-123", "ner": [[11, 11, "programlang"], [14, 17, "misc"], [20, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 20, 23, "type-of", "", false, false], [14, 17, 20, 23, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Il", "kit", "robot", "\u00e8", "basato", "su", "Android", "e", "si", "programma", "utilizzando", "Java", ",", "l'", "interfaccia", "di", "programmazione", "Blocks", "o", "altri", "sistemi", "di", "programmazione", "Android", "."], "sentence-detokenized": "Il kit robot \u00e8 basato su Android e si programma utilizzando Java, l'interfaccia di programmazione Blocks o altri sistemi di programmazione Android.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 14], [15, 21], [22, 24], [25, 32], [33, 34], [35, 37], [38, 47], [48, 59], [60, 64], [64, 65], [66, 68], [68, 79], [80, 82], [83, 97], [98, 104], [105, 106], [107, 112], [113, 120], [121, 123], [124, 138], [139, 146], [146, 147]]}
{"doc_key": "ai-dev-124", "ner": [[12, 15, "algorithm"], [17, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Il", "metodo", "di", "definizione", "dell'", "elenco", "collegato", "specifica", "l'", "uso", "di", "una", "ricerca", "depth", "-", "first", "o", "breadth", "-", "first."], "sentence-detokenized": "Il metodo di definizione dell'elenco collegato specifica l'uso di una ricerca depth-first o breadth-first.", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 24], [25, 30], [30, 36], [37, 46], [47, 56], [57, 59], [59, 62], [63, 65], [66, 69], [70, 77], [78, 83], [83, 84], [84, 89], [90, 91], [92, 99], [99, 100], [100, 106]]}
{"doc_key": "ai-dev-125", "ner": [[20, 22, "task"], [27, 30, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Queste", "regioni", "potrebbero", "segnalare", "la", "presenza", "di", "oggetti", "o", "parti", "di", "oggetti", "nel", "dominio", "delle", "immagini", ",", "con", "applicazioni", "al", "riconoscimento", "di", "oggetti", "e", "/", "o", "al", "tracciamento", "video", "di", "oggetti", "."], "sentence-detokenized": "Queste regioni potrebbero segnalare la presenza di oggetti o parti di oggetti nel dominio delle immagini, con applicazioni al riconoscimento di oggetti e/o al tracciamento video di oggetti.", "token2charspan": [[0, 6], [7, 14], [15, 25], [26, 35], [36, 38], [39, 47], [48, 50], [51, 58], [59, 60], [61, 66], [67, 69], [70, 77], [78, 81], [82, 89], [90, 95], [96, 104], [104, 105], [106, 109], [110, 122], [123, 125], [126, 140], [141, 143], [144, 151], [152, 153], [153, 154], [154, 155], [156, 158], [159, 171], [172, 177], [178, 180], [181, 188], [188, 189]]}
{"doc_key": "ai-dev-126", "ner": [[3, 4, "algorithm"], [6, 6, "product"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 3, 4, "type-of", "", false, false], [6, 6, 12, 13, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Un", "esempio", "di", "rete", "semantica", "\u00e8", "WordNet", ",", "un", "database", "lessicale", "della", "lingua", "inglese", "."], "sentence-detokenized": "Un esempio di rete semantica \u00e8 WordNet, un database lessicale della lingua inglese.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 18], [19, 28], [29, 30], [31, 38], [38, 39], [40, 42], [43, 51], [52, 61], [62, 67], [68, 74], [75, 82], [82, 83]]}
{"doc_key": "ai-dev-127", "ner": [[0, 2, "task"], [8, 8, "field"], [11, 12, "field"], [21, 27, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 8, 8, "part-of", "", false, false], [0, 2, 11, 12, "named", "same", false, false], [0, 2, 11, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Il", "riconoscimento", "vocale", "\u00e8", "un", "sottocampo", "interdisciplinare", "dell'", "informatica", "e", "della", "linguistica", "computazionale", "che", "sviluppa", "metodologie", "e", "tecnologie", "che", "consentono", "il", "riconoscimento", "e", "la", "traduzione", "del", "linguaggio", "parlato", "in", "testo", "da", "parte", "dei", "computer", "."], "sentence-detokenized": "Il riconoscimento vocale \u00e8 un sottocampo interdisciplinare dell'informatica e della linguistica computazionale che sviluppa metodologie e tecnologie che consentono il riconoscimento e la traduzione del linguaggio parlato in testo da parte dei computer.", "token2charspan": [[0, 2], [3, 17], [18, 24], [25, 26], [27, 29], [30, 40], [41, 58], [59, 64], [64, 75], [76, 77], [78, 83], [84, 95], [96, 110], [111, 114], [115, 123], [124, 135], [136, 137], [138, 148], [149, 152], [153, 163], [164, 166], [167, 181], [182, 183], [184, 186], [187, 197], [198, 201], [202, 212], [213, 220], [221, 223], [224, 229], [230, 232], [233, 238], [239, 242], [243, 251], [251, 252]]}
{"doc_key": "ai-dev-128", "ner": [[0, 2, "field"], [12, 13, "misc"], [18, 21, "field"], [25, 25, "task"], [28, 30, "task"], [54, 54, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 54, 54, "named", "same", false, false], [18, 21, 0, 2, "part-of", "subfield", false, false], [25, 25, 0, 2, "part-of", "", false, false], [25, 25, 18, 21, "part-of", "", false, false], [28, 30, 18, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["L'", "intelligenza", "artificiale", "ha", "mantenuto", "la", "maggiore", "attenzione", "per", "quanto", "riguarda", "l'", "ontologia", "applicata", "in", "sottocampi", "come", "l'", "elaborazione", "del", "linguaggio", "naturale", "all'", "interno", "delle", "macchine", "e", "la", "rappresentazione", "della", "conoscenza", ",", "ma", "i", "redattori", "di", "ontologie", "vengono", "utilizzati", "spesso", "in", "una", "serie", "di", "campi", "come", "l'", "istruzione", "senza", "l'", "intento", "di", "contribuire", "all'", "IA", "."], "sentence-detokenized": "L'intelligenza artificiale ha mantenuto la maggiore attenzione per quanto riguarda l'ontologia applicata in sottocampi come l'elaborazione del linguaggio naturale all'interno delle macchine e la rappresentazione della conoscenza, ma i redattori di ontologie vengono utilizzati spesso in una serie di campi come l'istruzione senza l'intento di contribuire all'IA.", "token2charspan": [[0, 2], [2, 14], [15, 26], [27, 29], [30, 39], [40, 42], [43, 51], [52, 62], [63, 66], [67, 73], [74, 82], [83, 85], [85, 94], [95, 104], [105, 107], [108, 118], [119, 123], [124, 126], [126, 138], [139, 142], [143, 153], [154, 162], [163, 167], [167, 174], [175, 180], [181, 189], [190, 191], [192, 194], [195, 211], [212, 217], [218, 228], [228, 229], [230, 232], [233, 234], [235, 244], [245, 247], [248, 257], [258, 265], [266, 276], [277, 283], [284, 286], [287, 290], [291, 296], [297, 299], [300, 305], [306, 310], [311, 313], [313, 323], [324, 329], [330, 332], [332, 339], [340, 342], [343, 354], [355, 359], [359, 361], [361, 362]]}
{"doc_key": "ai-dev-129", "ner": [[9, 13, "algorithm"], [16, 17, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 13, 16, 17, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Questa", "regola", "di", "aggiornamento", "\u00e8", "di", "fatto", "l'", "aggiornamento", "stocastico", "della", "discesa", "del", "gradiente", "per", "la", "regressione", "lineare", "."], "sentence-detokenized": "Questa regola di aggiornamento \u00e8 di fatto l'aggiornamento stocastico della discesa del gradiente per la regressione lineare.", "token2charspan": [[0, 6], [7, 13], [14, 16], [17, 30], [31, 32], [33, 35], [36, 41], [42, 44], [44, 57], [58, 68], [69, 74], [75, 82], [83, 86], [87, 96], [97, 100], [101, 103], [104, 115], [116, 123], [123, 124]]}
{"doc_key": "ai-dev-130", "ner": [[4, 9, "organisation"], [12, 15, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["\u00c8", "stato", "eletto", "all'", "American", "Academy", "of", "Arts", "and", "Sciences", "e", "alla", "National", "Academy", "of", "Sciences", "e", "ha", "ricevuto", "una", "serie", "di", "premi", ":"], "sentence-detokenized": "\u00c8 stato eletto all'American Academy of Arts and Sciences e alla National Academy of Sciences e ha ricevuto una serie di premi:", "token2charspan": [[0, 1], [2, 7], [8, 14], [15, 19], [19, 27], [28, 35], [36, 38], [39, 43], [44, 47], [48, 56], [57, 58], [59, 63], [64, 72], [73, 80], [81, 83], [84, 92], [93, 94], [95, 97], [98, 106], [107, 110], [111, 116], [117, 119], [120, 125], [125, 126]]}
{"doc_key": "ai-dev-131", "ner": [[9, 9, "organisation"], [14, 15, "person"], [17, 20, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 14, 15, "related-to", "written_about_by", false, false], [9, 9, 17, 20, "related-to", "written_about_by", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "scuola", "di", "pensiero", "pi\u00f9", "recente", "sulla", "strategia", "di", "Honda", "\u00e8", "stata", "proposta", "da", "Gary", "Hamel", "e", "C.", "K", ".", "Prahalad", "nel", "1989", "."], "sentence-detokenized": "La scuola di pensiero pi\u00f9 recente sulla strategia di Honda \u00e8 stata proposta da Gary Hamel e C. K. Prahalad nel 1989.", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 21], [22, 25], [26, 33], [34, 39], [40, 49], [50, 52], [53, 58], [59, 60], [61, 66], [67, 75], [76, 78], [79, 83], [84, 89], [90, 91], [92, 94], [95, 96], [96, 97], [98, 106], [107, 110], [111, 115], [115, 116]]}
{"doc_key": "ai-dev-132", "ner": [[1, 1, "metrics"], [5, 5, "metrics"], [17, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 5, 5, "related-to", "calculates", true, false], [1, 1, 17, 18, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Mentre", "BLEU", "calcola", "semplicemente", "la", "precisione", "dei", "grafemi", "aggiungendo", "un", "peso", "uguale", "a", "ciascuno", "di", "essi", ",", "il", "NIST", "calcola", "anche", "quanto", "sia", "informativo", "un", "particolare", "grafema", "."], "sentence-detokenized": "Mentre BLEU calcola semplicemente la precisione dei grafemi aggiungendo un peso uguale a ciascuno di essi, il NIST calcola anche quanto sia informativo un particolare grafema.", "token2charspan": [[0, 6], [7, 11], [12, 19], [20, 33], [34, 36], [37, 47], [48, 51], [52, 59], [60, 71], [72, 74], [75, 79], [80, 86], [87, 88], [89, 97], [98, 100], [101, 105], [105, 106], [107, 109], [110, 114], [115, 122], [123, 128], [129, 135], [136, 139], [140, 151], [152, 154], [155, 166], [167, 174], [174, 175]]}
{"doc_key": "ai-dev-133", "ner": [[4, 8, "misc"], [9, 12, "conference"], [14, 14, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 8, 9, 12, "temporal", "", false, false], [14, 14, 9, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["\u00c8", "stato", "insignito", "del", "premio", "alla", "carriera", "2019", "dell'", "Association", "for", "Computational", "Linguistics", "(", "ACL", ")", "."], "sentence-detokenized": "\u00c8 stato insignito del premio alla carriera 2019 dell'Association for Computational Linguistics (ACL).", "token2charspan": [[0, 1], [2, 7], [8, 17], [18, 21], [22, 28], [29, 33], [34, 42], [43, 47], [48, 53], [53, 64], [65, 68], [69, 82], [83, 94], [95, 96], [96, 99], [99, 100], [100, 101]]}
{"doc_key": "ai-dev-134", "ner": [[0, 0, "researcher"], [4, 9, "organisation"], [11, 11, "organisation"], [16, 20, "conference"], [22, 22, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 4, 9, "role", "", false, false], [0, 0, 16, 20, "role", "", false, false], [11, 11, 4, 9, "named", "", false, false], [22, 22, 16, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sycara", "\u00e8", "Fellow", "dell'", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", "e", "Fellow", "dell'", "American", "Association", "for", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Sycara \u00e8 Fellow dell'Institute of Electrical and Electronics Engineers (IEEE) e Fellow dell'American Association for Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 8], [9, 15], [16, 21], [21, 30], [31, 33], [34, 44], [45, 48], [49, 60], [61, 70], [71, 72], [72, 76], [76, 77], [78, 79], [80, 86], [87, 92], [92, 100], [101, 112], [113, 116], [117, 127], [128, 140], [141, 142], [142, 146], [146, 147], [147, 148]]}
{"doc_key": "ai-dev-135", "ner": [[3, 3, "product"], [11, 15, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 11, 15, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Il", "seguente", "codice", "MATLAB", "mostra", "una", "soluzione", "concreta", "per", "risolvere", "il", "sistema", "di", "equazioni", "non", "lineari", "presentato", "nella", "sezione", "precedente", ":", "Vedere", "anche"], "sentence-detokenized": "Il seguente codice MATLAB mostra una soluzione concreta per risolvere il sistema di equazioni non lineari presentato nella sezione precedente: Vedere anche", "token2charspan": [[0, 2], [3, 11], [12, 18], [19, 25], [26, 32], [33, 36], [37, 46], [47, 55], [56, 59], [60, 69], [70, 72], [73, 80], [81, 83], [84, 93], [94, 97], [98, 105], [106, 116], [117, 122], [123, 130], [131, 141], [141, 142], [143, 149], [150, 155]]}
{"doc_key": "ai-dev-136", "ner": [[5, 9, "product"], [20, 21, "field"], [42, 44, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 9, 20, 21, "related-to", "trained_by", true, false], [5, 9, 42, 44, "related-to", "trained_by", true, false], [20, 21, 42, 44, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "molti", "casi", ",", "i", "sistemi", "di", "riconoscimento", "di", "pattern", "vengono", "addestrati", "a", "partire", "da", "dati", "di", "addestramento", "etichettati", "(", "apprendimento", "supervisionato", ")", ",", "ma", "quando", "non", "sono", "disponibili", "dati", "etichettati", "si", "possono", "utilizzare", "altri", "algoritmi", "per", "scoprire", "modelli", "precedentemente", "sconosciuti", "(", "apprendimento", "non", "supervisionato", ")", "."], "sentence-detokenized": "In molti casi, i sistemi di riconoscimento di pattern vengono addestrati a partire da dati di addestramento etichettati (apprendimento supervisionato), ma quando non sono disponibili dati etichettati si possono utilizzare altri algoritmi per scoprire modelli precedentemente sconosciuti (apprendimento non supervisionato).", "token2charspan": [[0, 2], [3, 8], [9, 13], [13, 14], [15, 16], [17, 24], [25, 27], [28, 42], [43, 45], [46, 53], [54, 61], [62, 72], [73, 74], [75, 82], [83, 85], [86, 90], [91, 93], [94, 107], [108, 119], [120, 121], [121, 134], [135, 149], [149, 150], [150, 151], [152, 154], [155, 161], [162, 165], [166, 170], [171, 182], [183, 187], [188, 199], [200, 202], [203, 210], [211, 221], [222, 227], [228, 237], [238, 241], [242, 250], [251, 258], [259, 274], [275, 286], [287, 288], [288, 301], [302, 305], [306, 320], [320, 321], [321, 322]]}
{"doc_key": "ai-dev-137", "ner": [[8, 11, "researcher"], [13, 14, "country"], [28, 29, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 11, 13, 14, "physical", "", false, false], [8, 11, 28, 29, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["\u00c8", "stata", "utilizzata", "per", "la", "prima", "volta", "da", "Lawrence", "J", ".", "Fogel", "negli", "Stati", "Uniti", "nel", "1960", "per", "utilizzare", "l'", "evoluzione", "simulata", "come", "processo", "di", "apprendimento", "per", "generare", "intelligenza", "artificiale", "."], "sentence-detokenized": "\u00c8 stata utilizzata per la prima volta da Lawrence J. Fogel negli Stati Uniti nel 1960 per utilizzare l'evoluzione simulata come processo di apprendimento per generare intelligenza artificiale.", "token2charspan": [[0, 1], [2, 7], [8, 18], [19, 22], [23, 25], [26, 31], [32, 37], [38, 40], [41, 49], [50, 51], [51, 52], [53, 58], [59, 64], [65, 70], [71, 76], [77, 80], [81, 85], [86, 89], [90, 100], [101, 103], [103, 113], [114, 122], [123, 127], [128, 136], [137, 139], [140, 153], [154, 157], [158, 166], [167, 179], [180, 191], [191, 192]]}
{"doc_key": "ai-dev-138", "ner": [[0, 3, "field"], [10, 12, "field"], [16, 17, "field"], [20, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 10, 12, "part-of", "", false, false], [16, 17, 10, 12, "part-of", "", false, false], [20, 22, 10, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["L'", "apprendimento", "per", "rinforzo", "\u00e8", "uno", "dei", "tre", "paradigmi", "fondamentali", "dell'", "apprendimento", "automatico", ",", "insieme", "all'", "apprendimento", "supervisionato", "e", "all'", "apprendimento", "non", "supervisionato", "."], "sentence-detokenized": "L'apprendimento per rinforzo \u00e8 uno dei tre paradigmi fondamentali dell'apprendimento automatico, insieme all'apprendimento supervisionato e all'apprendimento non supervisionato.", "token2charspan": [[0, 2], [2, 15], [16, 19], [20, 28], [29, 30], [31, 34], [35, 38], [39, 42], [43, 52], [53, 65], [66, 71], [71, 84], [85, 95], [95, 96], [97, 104], [105, 109], [109, 122], [123, 137], [138, 139], [140, 144], [144, 157], [158, 161], [162, 176], [176, 177]]}
{"doc_key": "ai-dev-139", "ner": [[5, 6, "field"], [14, 14, "programlang"], [38, 39, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 38, 39, "usage", "applies", false, false], [14, 14, 38, 39, "usage", "applies", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "questi", "casi", ",", "il", "cloud", "computing", "e", "il", "linguaggio", "di", "programmazione", "open", "source", "R", "possono", "aiutare", "le", "banche", "pi\u00f9", "piccole", "ad", "adottare", "l'", "analisi", "del", "rischio", "e", "a", "supportare", "il", "monitoraggio", "a", "livello", "di", "filiale", "applicando", "l'", "analisi", "predittiva", "."], "sentence-detokenized": "In questi casi, il cloud computing e il linguaggio di programmazione open source R possono aiutare le banche pi\u00f9 piccole ad adottare l'analisi del rischio e a supportare il monitoraggio a livello di filiale applicando l'analisi predittiva.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 18], [19, 24], [25, 34], [35, 36], [37, 39], [40, 50], [51, 53], [54, 68], [69, 73], [74, 80], [81, 82], [83, 90], [91, 98], [99, 101], [102, 108], [109, 112], [113, 120], [121, 123], [124, 132], [133, 135], [135, 142], [143, 146], [147, 154], [155, 156], [157, 158], [159, 169], [170, 172], [173, 185], [186, 187], [188, 195], [196, 198], [199, 206], [207, 217], [218, 220], [220, 227], [228, 238], [238, 239]]}
{"doc_key": "ai-dev-140", "ner": [[10, 11, "researcher"], [16, 21, "algorithm"], [23, 24, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 23, 24, "named", "same", false, false], [16, 21, 10, 11, "origin", "proves_function", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Una", "delle", "prime", "versioni", "del", "teorema", "\u00e8", "stata", "dimostrata", "da", "George", "Cybenko", "nel", "1989", "per", "le", "funzioni", "di", "attivazione", "a", "funzione", "sigmoide", ".", "Cybenko", "G.", "(", "1989", ")", ",", "2", "(", "4", ")", ",", "303", "-", "314", "."], "sentence-detokenized": "Una delle prime versioni del teorema \u00e8 stata dimostrata da George Cybenko nel 1989 per le funzioni di attivazione a funzione sigmoide. Cybenko G. (1989), 2 (4), 303-314.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 24], [25, 28], [29, 36], [37, 38], [39, 44], [45, 55], [56, 58], [59, 65], [66, 73], [74, 77], [78, 82], [83, 86], [87, 89], [90, 98], [99, 101], [102, 113], [114, 115], [116, 124], [125, 133], [133, 134], [135, 142], [143, 145], [146, 147], [147, 151], [151, 152], [152, 153], [154, 155], [156, 157], [157, 158], [158, 159], [159, 160], [161, 164], [164, 165], [165, 168], [168, 169]]}
{"doc_key": "ai-dev-141", "ner": [[6, 7, "algorithm"], [10, 10, "metrics"], [14, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 6, 7, "part-of", "", false, false], [14, 21, 10, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "questo", "processo", ",", "noto", "come", "convalida", "incrociata", ",", "l'", "MSE", "\u00e8", "spesso", "chiamato", "errore", "di", "predizione", "medio", "al", "quadrato", "ed", "\u00e8", "calcolato", "come"], "sentence-detokenized": "In questo processo, noto come convalida incrociata, l'MSE \u00e8 spesso chiamato errore di predizione medio al quadrato ed \u00e8 calcolato come", "token2charspan": [[0, 2], [3, 9], [10, 18], [18, 19], [20, 24], [25, 29], [30, 39], [40, 50], [50, 51], [52, 54], [54, 57], [58, 59], [60, 66], [67, 75], [76, 82], [83, 85], [86, 96], [97, 102], [103, 105], [106, 114], [115, 117], [118, 119], [120, 129], [130, 134]]}
{"doc_key": "ai-dev-142", "ner": [[0, 1, "task"], [6, 9, "task"], [11, 11, "task"], [24, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 6, 9, "compare", "", false, false], [6, 9, 24, 26, "part-of", "", false, false], [11, 11, 6, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["L'", "OMR", "si", "distingue", "generalmente", "dal", "riconoscimento", "ottico", "dei", "caratteri", "(", "OCR", ")", "per", "il", "fatto", "che", "non", "\u00e8", "necessario", "un", "complicato", "motore", "di", "riconoscimento", "dei", "modelli", "."], "sentence-detokenized": "L'OMR si distingue generalmente dal riconoscimento ottico dei caratteri (OCR) per il fatto che non \u00e8 necessario un complicato motore di riconoscimento dei modelli.", "token2charspan": [[0, 2], [2, 5], [6, 8], [9, 18], [19, 31], [32, 35], [36, 50], [51, 57], [58, 61], [62, 71], [72, 73], [73, 76], [76, 77], [78, 81], [82, 84], [85, 90], [91, 94], [95, 98], [99, 100], [101, 111], [112, 114], [115, 125], [126, 132], [133, 135], [136, 150], [151, 154], [155, 162], [162, 163]]}
{"doc_key": "ai-dev-143", "ner": [[11, 11, "location"], [14, 14, "location"], [16, 16, "location"], [20, 21, "location"], [24, 25, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 14, 16, 16, "physical", "", false, false], [20, 21, 14, 14, "physical", "", false, false], [24, 25, 14, 14, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Nel", "2018", "e", "nel", "2019", ",", "il", "campionato", "si", "terr\u00e0", "a", "Houston", "e", "a", "Detroit", ",", "Michigan", ",", "presso", "il", "TCF", "Center", "e", "il", "Ford", "Field", "."], "sentence-detokenized": "Nel 2018 e nel 2019, il campionato si terr\u00e0 a Houston e a Detroit, Michigan, presso il TCF Center e il Ford Field.", "token2charspan": [[0, 3], [4, 8], [9, 10], [11, 14], [15, 19], [19, 20], [21, 23], [24, 34], [35, 37], [38, 43], [44, 45], [46, 53], [54, 55], [56, 57], [58, 65], [65, 66], [67, 75], [75, 76], [77, 83], [84, 86], [87, 90], [91, 97], [98, 99], [100, 102], [103, 107], [108, 113], [113, 114]]}
{"doc_key": "ai-dev-144", "ner": [[0, 1, "task"], [11, 12, "task"], [15, 16, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 0, 1, "part-of", "", false, false], [15, 16, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "classificazione", "pu\u00f2", "essere", "considerata", "come", "due", "problemi", "distinti", ":", "la", "classificazione", "binaria", "e", "la", "classificazione", "multiclasse", "."], "sentence-detokenized": "La classificazione pu\u00f2 essere considerata come due problemi distinti: la classificazione binaria e la classificazione multiclasse.", "token2charspan": [[0, 2], [3, 18], [19, 22], [23, 29], [30, 41], [42, 46], [47, 50], [51, 59], [60, 68], [68, 69], [70, 72], [73, 88], [89, 96], [97, 98], [99, 101], [102, 117], [118, 129], [129, 130]]}
{"doc_key": "ai-dev-145", "ner": [[3, 4, "product"], [9, 10, "product"], [13, 14, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 3, 4, "type-of", "", false, false], [13, 14, 3, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Due", "esempi", "di", "robot", "paralleli", "molto", "diffusi", "sono", "la", "piattaforma", "Stewart", "e", "il", "robot", "Delta", "."], "sentence-detokenized": "Due esempi di robot paralleli molto diffusi sono la piattaforma Stewart e il robot Delta.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 29], [30, 35], [36, 43], [44, 48], [49, 51], [52, 63], [64, 71], [72, 73], [74, 76], [77, 82], [83, 88], [88, 89]]}
{"doc_key": "ai-dev-146", "ner": [[4, 7, "algorithm"], [24, 24, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 7, 24, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "Tuttavia", ",", "la", "funzione", "di", "attivazione", "ReLU", ",", "che", "non", "\u00e8", "differenziabile", "a", "0", ",", "\u00e8", "diventata", "molto", "popolare", ",", "ad", "esempio", "in", "AlexNet", ")", "."], "sentence-detokenized": "(Tuttavia, la funzione di attivazione ReLU, che non \u00e8 differenziabile a 0, \u00e8 diventata molto popolare, ad esempio in AlexNet).", "token2charspan": [[0, 1], [1, 9], [9, 10], [11, 13], [14, 22], [23, 25], [26, 37], [38, 42], [42, 43], [44, 47], [48, 51], [52, 53], [54, 69], [70, 71], [72, 73], [73, 74], [75, 76], [77, 86], [87, 92], [93, 101], [101, 102], [103, 105], [106, 113], [114, 116], [117, 124], [124, 125], [125, 126]]}
{"doc_key": "ai-dev-147", "ner": [[1, 2, "metrics"], [9, 10, "task"], [16, 16, "task"], [18, 20, "task"], [22, 24, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 10, 1, 2, "usage", "", true, false], [16, 16, 9, 10, "part-of", "", false, false], [18, 20, 9, 10, "part-of", "", false, false], [22, 24, 9, 10, "part-of", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4], "sentence": ["Il", "punteggio", "F", "\u00e8", "spesso", "utilizzato", "nel", "campo", "dell'", "information", "retrieval", "per", "misurare", "le", "prestazioni", "di", "ricerca", ",", "classificazione", "dei", "documenti", "e", "classificazione", "delle", "query", "."], "sentence-detokenized": "Il punteggio F \u00e8 spesso utilizzato nel campo dell'information retrieval per misurare le prestazioni di ricerca, classificazione dei documenti e classificazione delle query.", "token2charspan": [[0, 2], [3, 12], [13, 14], [15, 16], [17, 23], [24, 34], [35, 38], [39, 44], [45, 50], [50, 61], [62, 71], [72, 75], [76, 84], [85, 87], [88, 99], [100, 102], [103, 110], [110, 111], [112, 127], [128, 131], [132, 141], [142, 143], [144, 159], [160, 165], [166, 171], [171, 172]]}
{"doc_key": "ai-dev-148", "ner": [[15, 16, "algorithm"], [18, 18, "algorithm"], [22, 24, "algorithm"], [26, 26, "algorithm"], [30, 32, "algorithm"], [34, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[18, 18, 15, 16, "named", "", false, false], [26, 26, 22, 24, "named", "", false, false], [34, 34, 30, 32, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Ci\u00f2", "avviene", "modellando", "il", "segnale", "ricevuto", "e", "utilizzando", "un", "metodo", "di", "stima", "statistica", "come", "la", "massima", "verosimiglianza", "(", "ML", ")", ",", "il", "voto", "di", "maggioranza", "(", "MV", ")", "o", "il", "massimo", "a", "posteriori", "(", "MAP", ")", "per", "decidere", "quale", "bersaglio", "della", "libreria", "si", "adatta", "meglio", "al", "modello", "costruito", "con", "il", "segnale", "ricevuto", "."], "sentence-detokenized": "Ci\u00f2 avviene modellando il segnale ricevuto e utilizzando un metodo di stima statistica come la massima verosimiglianza (ML), il voto di maggioranza (MV) o il massimo a posteriori (MAP) per decidere quale bersaglio della libreria si adatta meglio al modello costruito con il segnale ricevuto.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 25], [26, 33], [34, 42], [43, 44], [45, 56], [57, 59], [60, 66], [67, 69], [70, 75], [76, 86], [87, 91], [92, 94], [95, 102], [103, 118], [119, 120], [120, 122], [122, 123], [123, 124], [125, 127], [128, 132], [133, 135], [136, 147], [148, 149], [149, 151], [151, 152], [153, 154], [155, 157], [158, 165], [166, 167], [168, 178], [179, 180], [180, 183], [183, 184], [185, 188], [189, 197], [198, 203], [204, 213], [214, 219], [220, 228], [229, 231], [232, 238], [239, 245], [246, 248], [249, 256], [257, 266], [267, 270], [271, 273], [274, 281], [282, 290], [290, 291]]}
{"doc_key": "ai-dev-149", "ner": [[0, 2, "researcher"], [4, 4, "misc"], [6, 6, "field"], [9, 12, "university"], [17, 17, "misc"], [20, 20, "field"], [23, 25, "university"], [30, 32, "misc"], [34, 34, "field"], [37, 39, "university"], [46, 55, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 2, 9, 12, "physical", "", false, false], [0, 2, 9, 12, "role", "", false, false], [0, 2, 23, 25, "physical", "", false, false], [0, 2, 23, 25, "role", "", false, false], [0, 2, 37, 39, "physical", "", false, false], [0, 2, 37, 39, "role", "", false, false], [4, 4, 0, 2, "origin", "", false, false], [4, 4, 6, 6, "topic", "", false, false], [17, 17, 0, 2, "origin", "", false, false], [17, 17, 20, 20, "topic", "", false, false], [30, 32, 0, 2, "origin", "", false, false], [30, 32, 34, 34, "topic", "", false, false], [46, 55, 30, 32, "named", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Sowa", "ha", "conseguito", "una", "laurea", "in", "matematica", "presso", "il", "Massachusetts", "Institute", "of", "Technology", "nel", "1962", ",", "un", "master", "in", "scienze", "applicate", "presso", "l'", "Universit\u00e0", "di", "Harvard", "nel", "1966", "e", "un", "dottorato", "di", "ricerca", "in", "informatica", "presso", "la", "Vrije", "Universiteit", "Brussel", "nel", "1999", "con", "una", "tesi", "intitolata", "Knowledge", "Representation", ":", "Logical", ",", "Philosophical", ",", "and", "Computational", "Foundations", "."], "sentence-detokenized": "Sowa ha conseguito una laurea in matematica presso il Massachusetts Institute of Technology nel 1962, un master in scienze applicate presso l'Universit\u00e0 di Harvard nel 1966 e un dottorato di ricerca in informatica presso la Vrije Universiteit Brussel nel 1999 con una tesi intitolata Knowledge Representation: Logical, Philosophical, and Computational Foundations.", "token2charspan": [[0, 4], [5, 7], [8, 18], [19, 22], [23, 29], [30, 32], [33, 43], [44, 50], [51, 53], [54, 67], [68, 77], [78, 80], [81, 91], [92, 95], [96, 100], [100, 101], [102, 104], [105, 111], [112, 114], [115, 122], [123, 132], [133, 139], [140, 142], [142, 152], [153, 155], [156, 163], [164, 167], [168, 172], [173, 174], [175, 177], [178, 187], [188, 190], [191, 198], [199, 201], [202, 213], [214, 220], [221, 223], [224, 229], [230, 242], [243, 250], [251, 254], [255, 259], [260, 263], [264, 267], [268, 272], [273, 283], [284, 293], [294, 308], [308, 309], [310, 317], [317, 318], [319, 332], [332, 333], [334, 337], [338, 351], [352, 363], [363, 364]]}
{"doc_key": "ai-dev-150", "ner": [[2, 4, "task"], [12, 12, "task"], [25, 25, "metrics"], [28, 29, "metrics"], [32, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 12, 12, "general-affiliation", "", false, false], [25, 25, 2, 4, "part-of", "", true, false], [28, 29, 2, 4, "part-of", "", true, false], [32, 33, 2, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Poich\u00e9", "il", "riconoscimento", "delle", "parafrasi", "pu\u00f2", "essere", "posto", "come", "un", "problema", "di", "classificazione", ",", "la", "maggior", "parte", "delle", "metriche", "di", "valutazione", "standard", ",", "come", "l'", "accuratezza", ",", "il", "punteggio", "f1", "o", "la", "curva", "ROC", ",", "si", "comportano", "relativamente", "bene", "."], "sentence-detokenized": "Poich\u00e9 il riconoscimento delle parafrasi pu\u00f2 essere posto come un problema di classificazione, la maggior parte delle metriche di valutazione standard, come l'accuratezza, il punteggio f1 o la curva ROC, si comportano relativamente bene.", "token2charspan": [[0, 6], [7, 9], [10, 24], [25, 30], [31, 40], [41, 44], [45, 51], [52, 57], [58, 62], [63, 65], [66, 74], [75, 77], [78, 93], [93, 94], [95, 97], [98, 105], [106, 111], [112, 117], [118, 126], [127, 129], [130, 141], [142, 150], [150, 151], [152, 156], [157, 159], [159, 170], [170, 171], [172, 174], [175, 184], [185, 187], [188, 189], [190, 192], [193, 198], [199, 202], [202, 203], [204, 206], [207, 217], [218, 231], [232, 236], [236, 237]]}
{"doc_key": "ai-dev-151", "ner": [[22, 22, "algorithm"], [35, 36, "algorithm"], [38, 39, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 22, 35, 36, "opposite", "not_suited_for", false, false], [22, 22, 38, 39, "opposite", "not_suited_for", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Ci\u00f2", "lo", "rende", "pratico", "per", "l'", "analisi", "di", "grandi", "insiemi", "di", "dati", "(", "centinaia", "o", "migliaia", "di", "taxa", ")", "e", "per", "il", "bootstrapping", ",", "per", "il", "quale", "altri", "mezzi", "di", "analisi", "(", "ad", "esempio", ",", "massima", "parsimonia", ",", "massima", "verosimiglianza", ")", "potrebbero", "essere", "proibitivi", "dal", "punto", "di", "vista", "computazionale", "."], "sentence-detokenized": "Ci\u00f2 lo rende pratico per l'analisi di grandi insiemi di dati (centinaia o migliaia di taxa) e per il bootstrapping, per il quale altri mezzi di analisi (ad esempio, massima parsimonia, massima verosimiglianza) potrebbero essere proibitivi dal punto di vista computazionale.", "token2charspan": [[0, 3], [4, 6], [7, 12], [13, 20], [21, 24], [25, 27], [27, 34], [35, 37], [38, 44], [45, 52], [53, 55], [56, 60], [61, 62], [62, 71], [72, 73], [74, 82], [83, 85], [86, 90], [90, 91], [92, 93], [94, 97], [98, 100], [101, 114], [114, 115], [116, 119], [120, 122], [123, 128], [129, 134], [135, 140], [141, 143], [144, 151], [152, 153], [153, 155], [156, 163], [163, 164], [165, 172], [173, 183], [183, 184], [185, 192], [193, 208], [208, 209], [210, 220], [221, 227], [228, 238], [239, 242], [243, 248], [249, 251], [252, 257], [258, 272], [272, 273]]}
{"doc_key": "ai-dev-152", "ner": [[6, 6, "programlang"], [8, 8, "programlang"], [10, 13, "organisation"], [15, 15, "organisation"], [25, 25, "programlang"], [28, 42, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 6, 25, 25, "named", "same", false, false], [15, 15, 10, 13, "named", "", false, false], [28, 42, 6, 6, "role", "submits", true, false], [28, 42, 8, 8, "role", "submits", true, false], [28, 42, 10, 13, "role", "submits_to", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["La", "presentazione", "nel", "2002", "del", "linguaggio", "DAML", "+", "OIL", "al", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", "\u00e8", "il", "frutto", "del", "lavoro", "svolto", "dai", "contraenti", "DAML", "e", "dal", "Comitato", "congiunto", "ad", "hoc", "sui", "linguaggi", "di", "markup", "dell'", "Unione", "europea", "e", "degli", "Stati", "Uniti", "."], "sentence-detokenized": "La presentazione nel 2002 del linguaggio DAML + OIL al World Wide Web Consortium (W3C) \u00e8 il frutto del lavoro svolto dai contraenti DAML e dal Comitato congiunto ad hoc sui linguaggi di markup dell'Unione europea e degli Stati Uniti.", "token2charspan": [[0, 2], [3, 16], [17, 20], [21, 25], [26, 29], [30, 40], [41, 45], [46, 47], [48, 51], [52, 54], [55, 60], [61, 65], [66, 69], [70, 80], [81, 82], [82, 85], [85, 86], [87, 88], [89, 91], [92, 98], [99, 102], [103, 109], [110, 116], [117, 120], [121, 131], [132, 136], [137, 138], [139, 142], [143, 151], [152, 161], [162, 164], [165, 168], [169, 172], [173, 182], [183, 185], [186, 192], [193, 198], [198, 204], [205, 212], [213, 214], [215, 220], [221, 226], [227, 232], [232, 233]]}
{"doc_key": "ai-dev-153", "ner": [[3, 5, "misc"], [10, 10, "misc"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 3, 5, "part-of", "", true, false], [13, 14, 3, 5, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Un", "esempio", "di", "normalizzazione", "non", "lineare", "si", "ha", "quando", "la", "normalizzazione", "segue", "una", "funzione", "sigmoide", ";", "in", "tal", "caso", ",", "l'", "immagine", "normalizzata", "viene", "calcolata", "secondo", "la", "formula"], "sentence-detokenized": "Un esempio di normalizzazione non lineare si ha quando la normalizzazione segue una funzione sigmoide; in tal caso, l'immagine normalizzata viene calcolata secondo la formula", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 29], [30, 33], [34, 41], [42, 44], [45, 47], [48, 54], [55, 57], [58, 73], [74, 79], [80, 83], [84, 92], [93, 101], [101, 102], [103, 105], [106, 109], [110, 114], [114, 115], [116, 118], [118, 126], [127, 139], [140, 145], [146, 155], [156, 163], [164, 166], [167, 174]]}
{"doc_key": "ai-dev-154", "ner": [[11, 11, "metrics"], [16, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 11, 16, 16, "related-to", "used_together", false, false]], "relations_mapping_to_source": [0], "sentence": ["Per", "ovviare", "a", "questo", "problema", ",", "\u00e8", "stato", "sottolineato", "che", "la", "precisione", "viene", "solitamente", "associata", "al", "richiamo", "."], "sentence-detokenized": "Per ovviare a questo problema, \u00e8 stato sottolineato che la precisione viene solitamente associata al richiamo.", "token2charspan": [[0, 3], [4, 11], [12, 13], [14, 20], [21, 29], [29, 30], [31, 32], [33, 38], [39, 51], [52, 55], [56, 58], [59, 69], [70, 75], [76, 87], [88, 97], [98, 100], [101, 109], [109, 110]]}
{"doc_key": "ai-dev-155", "ner": [[6, 8, "metrics"], [11, 13, "metrics"], [19, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 20, 11, 13, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Le", "metriche", "comunemente", "utilizzate", "sono", "l'", "errore", "quadratico", "medio", "e", "l'", "errore", "quadratico", "medio", ",", "quest'", "ultimo", "utilizzato", "nel", "Premio", "Netflix", "."], "sentence-detokenized": "Le metriche comunemente utilizzate sono l'errore quadratico medio e l'errore quadratico medio, quest'ultimo utilizzato nel Premio Netflix.", "token2charspan": [[0, 2], [3, 11], [12, 23], [24, 34], [35, 39], [40, 42], [42, 48], [49, 59], [60, 65], [66, 67], [68, 70], [70, 76], [77, 87], [88, 93], [93, 94], [95, 101], [101, 107], [108, 118], [119, 122], [123, 129], [130, 137], [137, 138]]}
{"doc_key": "ai-dev-156", "ner": [[12, 14, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Nell'", "agosto", "2016", "\u00e8", "stato", "annunciato", "un", "programma", "di", "ricerca", "con", "l'", "University", "College", "Hospital", "con", "l'", "obiettivo", "di", "sviluppare", "un", "algoritmo", "in", "grado", "di", "differenziare", "automaticamente", "i", "tessuti", "sani", "da", "quelli", "cancerosi", "nelle", "aree", "della", "testa", "e", "del", "collo", "."], "sentence-detokenized": "Nell'agosto 2016 \u00e8 stato annunciato un programma di ricerca con l'University College Hospital con l'obiettivo di sviluppare un algoritmo in grado di differenziare automaticamente i tessuti sani da quelli cancerosi nelle aree della testa e del collo.", "token2charspan": [[0, 5], [5, 11], [12, 16], [17, 18], [19, 24], [25, 35], [36, 38], [39, 48], [49, 51], [52, 59], [60, 63], [64, 66], [66, 76], [77, 84], [85, 93], [94, 97], [98, 100], [100, 109], [110, 112], [113, 123], [124, 126], [127, 136], [137, 139], [140, 145], [146, 148], [149, 162], [163, 178], [179, 180], [181, 188], [189, 193], [194, 196], [197, 203], [204, 213], [214, 219], [220, 224], [225, 230], [231, 236], [237, 238], [239, 242], [243, 248], [248, 249]]}
{"doc_key": "ai-dev-157", "ner": [[8, 8, "researcher"], [16, 18, "organisation"], [21, 24, "organisation"], [27, 30, "organisation"], [33, 38, "organisation"], [41, 47, "organisation"], [50, 53, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[8, 8, 16, 18, "role", "", false, false], [8, 8, 21, 24, "role", "", false, false], [8, 8, 27, 30, "role", "", false, false], [8, 8, 33, 38, "role", "", false, false], [8, 8, 41, 47, "role", "", false, false], [8, 8, 50, 53, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["L'", "impatto", "dei", "contributi", "teorici", "ed", "empirici", "di", "Posner", "\u00e8", "stato", "riconosciuto", "attraverso", "la", "partecipazione", "all'", "American", "Psychological", "Association", ",", "all'", "Association", "for", "Psychological", "Science", ",", "alla", "Society", "of", "Experimental", "Psychologists", ",", "all'", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "all'", "American", "Association", "for", "the", "Advancement", "of", "Science", "e", "alla", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "L'impatto dei contributi teorici ed empirici di Posner \u00e8 stato riconosciuto attraverso la partecipazione all'American Psychological Association, all'Association for Psychological Science, alla Society of Experimental Psychologists, all'American Academy of Arts and Sciences, all'American Association for the Advancement of Science e alla National Academy of Sciences.", "token2charspan": [[0, 2], [2, 9], [10, 13], [14, 24], [25, 32], [33, 35], [36, 44], [45, 47], [48, 54], [55, 56], [57, 62], [63, 75], [76, 86], [87, 89], [90, 104], [105, 109], [109, 117], [118, 131], [132, 143], [143, 144], [145, 149], [149, 160], [161, 164], [165, 178], [179, 186], [186, 187], [188, 192], [193, 200], [201, 203], [204, 216], [217, 230], [230, 231], [232, 236], [236, 244], [245, 252], [253, 255], [256, 260], [261, 264], [265, 273], [273, 274], [275, 279], [279, 287], [288, 299], [300, 303], [304, 307], [308, 319], [320, 322], [323, 330], [331, 332], [333, 337], [338, 346], [347, 354], [355, 357], [358, 366], [366, 367]]}
{"doc_key": "ai-dev-158", "ner": [[1, 1, "product"], [8, 9, "field"], [13, 15, "task"], [18, 21, "task"], [23, 23, "task"], [27, 30, "task"], [32, 32, "task"], [36, 37, "field"], [40, 41, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[1, 1, 8, 9, "usage", "", false, false], [13, 15, 8, 9, "part-of", "", false, false], [18, 21, 8, 9, "part-of", "", false, false], [23, 23, 18, 21, "named", "", false, false], [27, 30, 8, 9, "part-of", "", false, false], [32, 32, 27, 30, "named", "", false, false], [36, 37, 8, 9, "part-of", "", false, false], [40, 41, 8, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Questi", "chatbot", "intelligenti", "utilizzano", "tutti", "i", "tipi", "di", "intelligenza", "artificiale", ",", "come", "la", "moderazione", "delle", "immagini", "e", "la", "comprensione", "del", "linguaggio", "naturale", "(", "NLU", ")", ",", "la", "generazione", "del", "linguaggio", "naturale", "(", "NLG", ")", ",", "l'", "apprendimento", "automatico", "e", "l'", "apprendimento", "profondo", "."], "sentence-detokenized": "Questi chatbot intelligenti utilizzano tutti i tipi di intelligenza artificiale, come la moderazione delle immagini e la comprensione del linguaggio naturale (NLU), la generazione del linguaggio naturale (NLG), l'apprendimento automatico e l'apprendimento profondo.", "token2charspan": [[0, 6], [7, 14], [15, 27], [28, 38], [39, 44], [45, 46], [47, 51], [52, 54], [55, 67], [68, 79], [79, 80], [81, 85], [86, 88], [89, 100], [101, 106], [107, 115], [116, 117], [118, 120], [121, 133], [134, 137], [138, 148], [149, 157], [158, 159], [159, 162], [162, 163], [163, 164], [165, 167], [168, 179], [180, 183], [184, 194], [195, 203], [204, 205], [205, 208], [208, 209], [209, 210], [211, 213], [213, 226], [227, 237], [238, 239], [240, 242], [242, 255], [256, 264], [264, 265]]}
{"doc_key": "ai-dev-159", "ner": [[6, 8, "metrics"], [10, 10, "metrics"], [13, 13, "metrics"], [16, 22, "metrics"], [29, 32, "metrics"], [34, 34, "metrics"], [37, 43, "metrics"], [48, 50, "metrics"], [52, 52, "metrics"], [55, 61, "metrics"], [68, 71, "metrics"], [73, 73, "metrics"], [76, 81, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[10, 10, 6, 8, "named", "", false, false], [13, 13, 6, 8, "named", "", false, false], [16, 22, 6, 8, "named", "", false, false], [34, 34, 29, 32, "named", "", false, false], [37, 43, 29, 32, "named", "", false, false], [52, 52, 48, 50, "named", "", false, false], [55, 61, 48, 50, "named", "", false, false], [73, 73, 68, 71, "named", "", false, false], [76, 81, 68, 71, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["I", "rapporti", "di", "riga", "sono", "il", "Valore", "Predittivo", "Positivo", "(", "PPV", ",", "alias", "precisione", ")", "(", "TP", "/", "(", "TP", "+", "FP", ")", ")", ",", "con", "il", "complemento", "del", "Tasso", "di", "Scoperta", "FALSA", "(", "FDR", ")", "(", "FP", "/", "(", "TP", "+", "FP", ")", ")", ";", "e", "il", "Valore", "Predittivo", "Negativo", "(", "NPV", ")", "(", "TN", "/", "(", "TN", "+", "FN", ")", ")", ",", "con", "il", "complemento", "del", "Tasso", "di", "Omissione", "FALSA", "(", "FOR", ")", "(", "FN", "/", "(", "TN", "+", "FN", ")", ")", "."], "sentence-detokenized": "I rapporti di riga sono il Valore Predittivo Positivo (PPV, alias precisione) (TP / (TP + FP)), con il complemento del Tasso di Scoperta FALSA (FDR) (FP / (TP + FP)); e il Valore Predittivo Negativo (NPV) (TN / (TN + FN)), con il complemento del Tasso di Omissione FALSA (FOR) (FN / (TN + FN)).", "token2charspan": [[0, 1], [2, 10], [11, 13], [14, 18], [19, 23], [24, 26], [27, 33], [34, 44], [45, 53], [54, 55], [55, 58], [58, 59], [60, 65], [66, 76], [76, 77], [78, 79], [79, 81], [82, 83], [84, 85], [85, 87], [88, 89], [90, 92], [92, 93], [93, 94], [94, 95], [96, 99], [100, 102], [103, 114], [115, 118], [119, 124], [125, 127], [128, 136], [137, 142], [143, 144], [144, 147], [147, 148], [149, 150], [150, 152], [153, 154], [155, 156], [156, 158], [159, 160], [161, 163], [163, 164], [164, 165], [165, 166], [167, 168], [169, 171], [172, 178], [179, 189], [190, 198], [199, 200], [200, 203], [203, 204], [205, 206], [206, 208], [209, 210], [211, 212], [212, 214], [215, 216], [217, 219], [219, 220], [220, 221], [221, 222], [223, 226], [227, 229], [230, 241], [242, 245], [246, 251], [252, 254], [255, 264], [265, 270], [271, 272], [272, 275], [275, 276], [277, 278], [278, 280], [281, 282], [283, 284], [284, 286], [287, 288], [289, 291], [291, 292], [292, 293], [293, 294]]}
{"doc_key": "ai-dev-160", "ner": [[8, 8, "misc"], [14, 15, "algorithm"], [17, 17, "algorithm"], [21, 24, "algorithm"], [26, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[17, 17, 14, 15, "named", "", false, false], [26, 26, 21, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Le", "informazioni", "sono", "una", "miscela", "di", "sitemap", "e", "RSS", "e", "sono", "create", "utilizzando", "il", "Modello", "informativo", "(", "IM", ")", "e", "l'", "Ontologia", "delle", "risorse", "biomediche", "(", "BRO", ")", "."], "sentence-detokenized": "Le informazioni sono una miscela di sitemap e RSS e sono create utilizzando il Modello informativo (IM) e l'Ontologia delle risorse biomediche (BRO).", "token2charspan": [[0, 2], [3, 15], [16, 20], [21, 24], [25, 32], [33, 35], [36, 43], [44, 45], [46, 49], [50, 51], [52, 56], [57, 63], [64, 75], [76, 78], [79, 86], [87, 98], [99, 100], [100, 102], [102, 103], [104, 105], [106, 108], [108, 117], [118, 123], [124, 131], [132, 142], [143, 144], [144, 147], [147, 148], [148, 149]]}
{"doc_key": "ai-dev-161", "ner": [[2, 4, "task"], [9, 11, "algorithm"], [13, 16, "algorithm"], [22, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 4, 13, 16, "origin", "based_on", false, false], [13, 16, 9, 11, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Il", "recente", "riconoscimento", "del", "testo", "si", "basa", "su", "una", "rete", "neurale", "ricorrente", "(", "memoria", "a", "breve", "termine", ")", "e", "non", "richiede", "un", "modello", "linguistico", "."], "sentence-detokenized": "Il recente riconoscimento del testo si basa su una rete neurale ricorrente (memoria a breve termine) e non richiede un modello linguistico.", "token2charspan": [[0, 2], [3, 10], [11, 25], [26, 29], [30, 35], [36, 38], [39, 43], [44, 46], [47, 50], [51, 55], [56, 63], [64, 74], [75, 76], [76, 83], [84, 85], [86, 91], [92, 99], [99, 100], [101, 102], [103, 106], [107, 115], [116, 118], [119, 126], [127, 138], [138, 139]]}
{"doc_key": "ai-dev-162", "ner": [[2, 4, "misc"], [10, 11, "metrics"], [15, 16, "algorithm"], [20, 21, "metrics"], [25, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 11, 2, 4, "type-of", "", false, false], [15, 16, 10, 11, "related-to", "", true, false], [20, 21, 2, 4, "type-of", "", false, false], [25, 26, 20, 21, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Tra", "le", "funzioni", "di", "perdita", "pi\u00f9", "diffuse", "vi", "sono", "la", "hinge", "loss", "(", "per", "le", "SVM", "lineari", ")", "e", "la", "log", "loss", "(", "per", "la", "regressione", "logistica", ")", "."], "sentence-detokenized": "Tra le funzioni di perdita pi\u00f9 diffuse vi sono la hinge loss (per le SVM lineari) e la log loss (per la regressione logistica).", "token2charspan": [[0, 3], [4, 6], [7, 15], [16, 18], [19, 26], [27, 30], [31, 38], [39, 41], [42, 46], [47, 49], [50, 55], [56, 60], [61, 62], [62, 65], [66, 68], [69, 72], [73, 80], [80, 81], [82, 83], [84, 86], [87, 90], [91, 95], [96, 97], [97, 100], [101, 103], [104, 115], [116, 125], [125, 126], [126, 127]]}
{"doc_key": "ai-dev-163", "ner": [[0, 1, "metrics"], [13, 18, "metrics"], [20, 20, "metrics"], [24, 26, "metrics"], [28, 28, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 13, 18, "compare", "", false, false], [0, 1, 24, 26, "compare", "", false, false], [20, 20, 13, 18, "named", "", false, false], [28, 28, 24, 26, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Il", "SSIM", "\u00e8", "stato", "progettato", "per", "migliorare", "i", "metodi", "tradizionali", ",", "come", "il", "rapporto", "segnale", "-", "rumore", "di", "picco", "(", "PSNR", ")", "e", "l'", "errore", "quadratico", "medio", "(", "MSE", ")", "."], "sentence-detokenized": "Il SSIM \u00e8 stato progettato per migliorare i metodi tradizionali, come il rapporto segnale-rumore di picco (PSNR) e l'errore quadratico medio (MSE).", "token2charspan": [[0, 2], [3, 7], [8, 9], [10, 15], [16, 26], [27, 30], [31, 41], [42, 43], [44, 50], [51, 63], [63, 64], [65, 69], [70, 72], [73, 81], [82, 89], [89, 90], [90, 96], [97, 99], [100, 105], [106, 107], [107, 111], [111, 112], [113, 114], [115, 117], [117, 123], [124, 134], [135, 140], [141, 142], [142, 145], [145, 146], [146, 147]]}
{"doc_key": "ai-dev-164", "ner": [[13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Il", "suo", "lavoro", "ha", "ispirato", "le", "generazioni", "successive", "di", "ricercatori", "di", "robotica", "come", "Rodney", "Brooks", ",", "Hans", "Moravec", "e", "Mark", "Tilden", "."], "sentence-detokenized": "Il suo lavoro ha ispirato le generazioni successive di ricercatori di robotica come Rodney Brooks, Hans Moravec e Mark Tilden.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 16], [17, 25], [26, 28], [29, 40], [41, 51], [52, 54], [55, 66], [67, 69], [70, 78], [79, 83], [84, 90], [91, 97], [97, 98], [99, 103], [104, 111], [112, 113], [114, 118], [119, 125], [125, 126]]}
{"doc_key": "ai-dev-165", "ner": [[19, 19, "algorithm"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[23, 25, 19, 19, "origin", "based_on", false, false]], "relations_mapping_to_source": [0], "sentence": ["Inoltre", ",", "l'", "addestramento", "degli", "impulsi", "non", "\u00e8", "differenziabile", ",", "il", "che", "elimina", "i", "metodi", "di", "addestramento", "basati", "sulla", "retropropagazione", ",", "come", "la", "discesa", "del", "gradiente", "."], "sentence-detokenized": "Inoltre, l'addestramento degli impulsi non \u00e8 differenziabile, il che elimina i metodi di addestramento basati sulla retropropagazione, come la discesa del gradiente.", "token2charspan": [[0, 7], [7, 8], [9, 11], [11, 24], [25, 30], [31, 38], [39, 42], [43, 44], [45, 60], [60, 61], [62, 64], [65, 68], [69, 76], [77, 78], [79, 85], [86, 88], [89, 102], [103, 109], [110, 115], [116, 133], [133, 134], [135, 139], [140, 142], [143, 150], [151, 154], [155, 164], [164, 165]]}
{"doc_key": "ai-dev-166", "ner": [[8, 10, "metrics"], [17, 17, "metrics"], [22, 22, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 17, 17, "related-to", "describes", false, false], [17, 17, 22, 22, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Queste", "relazioni", "possono", "essere", "facilmente", "rappresentate", "con", "una", "matrice", "di", "confusione", ",", "una", "tabella", "che", "descrive", "l'", "accuratezza", "di", "un", "modello", "di", "classificazione", "."], "sentence-detokenized": "Queste relazioni possono essere facilmente rappresentate con una matrice di confusione, una tabella che descrive l'accuratezza di un modello di classificazione.", "token2charspan": [[0, 6], [7, 16], [17, 24], [25, 31], [32, 42], [43, 56], [57, 60], [61, 64], [65, 72], [73, 75], [76, 86], [86, 87], [88, 91], [92, 99], [100, 103], [104, 112], [113, 115], [115, 126], [127, 129], [130, 132], [133, 140], [141, 143], [144, 159], [159, 160]]}
{"doc_key": "ai-dev-167", "ner": [[3, 11, "conference"], [13, 13, "conference"], [19, 19, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 13, 3, 11, "named", "", false, false], [19, 19, 3, 11, "physical", "", false, false], [19, 19, 3, 11, "role", "", false, false], [19, 19, 3, 11, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "occasione", "della", "Conferenza", "2018", "sui", "sistemi", "di", "elaborazione", "delle", "informazioni", "neurali", "(", "NeurIPS", ")", ",", "i", "ricercatori", "di", "Google", "hanno", "presentato", "il", "lavoro"], "sentence-detokenized": "In occasione della Conferenza 2018 sui sistemi di elaborazione delle informazioni neurali (NeurIPS), i ricercatori di Google hanno presentato il lavoro", "token2charspan": [[0, 2], [3, 12], [13, 18], [19, 29], [30, 34], [35, 38], [39, 46], [47, 49], [50, 62], [63, 68], [69, 81], [82, 89], [90, 91], [91, 98], [98, 99], [99, 100], [101, 102], [103, 114], [115, 117], [118, 124], [125, 130], [131, 141], [142, 144], [145, 151]]}
{"doc_key": "ai-dev-168", "ner": [[5, 5, "university"], [15, 15, "product"], [21, 23, "misc"], [27, 27, "conference"], [32, 35, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 15, 21, 23, "win-defeat", "", false, false], [21, 23, 27, 27, "temporal", "", false, false], [32, 35, 27, 27, "part-of", "", false, false], [32, 35, 27, 27, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Durante", "la", "sua", "permanenza", "alla", "Duke", ",", "ha", "lavorato", "al", "risolutore", "automatico", "di", "parole", "crociate", "PROVERB", ",", "che", "ha", "vinto", "un", "Outstanding", "Paper", "Award", "nel", "1999", "dall'", "AAAI", "e", "ha", "partecipato", "all'", "American", "Crossword", "Puzzle", "Tournament."], "sentence-detokenized": "Durante la sua permanenza alla Duke, ha lavorato al risolutore automatico di parole crociate PROVERB, che ha vinto un Outstanding Paper Award nel 1999 dall'AAAI e ha partecipato all'American Crossword Puzzle Tournament.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 25], [26, 30], [31, 35], [35, 36], [37, 39], [40, 48], [49, 51], [52, 62], [63, 73], [74, 76], [77, 83], [84, 92], [93, 100], [100, 101], [102, 105], [106, 108], [109, 114], [115, 117], [118, 129], [130, 135], [136, 141], [142, 145], [146, 150], [151, 156], [156, 160], [161, 162], [163, 165], [166, 177], [178, 182], [182, 190], [191, 200], [201, 207], [208, 219]]}
{"doc_key": "ai-dev-169", "ner": [[4, 5, "location"], [7, 7, "location"], [16, 17, "country"], [20, 20, "country"], [22, 22, "country"], [24, 24, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 7, 7, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Con", "sede", "centrale", "a", "Rochester", "Hills", ",", "Michigan", ",", "l'", "azienda", "aveva", "10", "sedi", "regionali", "negli", "Stati", "Uniti", ",", "in", "Canada", ",", "Messico", "e", "Brasile", "."], "sentence-detokenized": "Con sede centrale a Rochester Hills, Michigan, l'azienda aveva 10 sedi regionali negli Stati Uniti, in Canada, Messico e Brasile.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 19], [20, 29], [30, 35], [35, 36], [37, 45], [45, 46], [47, 49], [49, 56], [57, 62], [63, 65], [66, 70], [71, 80], [81, 86], [87, 92], [93, 98], [98, 99], [100, 102], [103, 109], [109, 110], [111, 118], [119, 120], [121, 128], [128, 129]]}
{"doc_key": "ai-dev-170", "ner": [[13, 13, "product"], [16, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Si", "aggiunge", "a", "una", "collezione", "di", "robot", "storicamente", "importanti", "che", "comprende", "un", "primo", "Unimate", "e", "l'", "Odetics", "Odex", "1", "."], "sentence-detokenized": "Si aggiunge a una collezione di robot storicamente importanti che comprende un primo Unimate e l'Odetics Odex 1.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 17], [18, 28], [29, 31], [32, 37], [38, 50], [51, 61], [62, 65], [66, 75], [76, 78], [79, 84], [85, 92], [93, 94], [95, 97], [97, 104], [105, 109], [110, 111], [111, 112]]}
{"doc_key": "ai-dev-171", "ner": [[11, 11, "researcher"], [13, 13, "organisation"], [15, 16, "researcher"], [26, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 13, 13, "physical", "", false, false], [11, 11, 13, 13, "role", "", false, false], [15, 16, 13, 13, "physical", "", false, false], [15, 16, 13, 13, "role", "", false, false], [15, 16, 26, 30, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["L'", "editore", "ospite", "di", "quel", "numero", "sar\u00e0", "l'", "ex", "collega", "di", "David", "al", "NIST", ",", "Judah", "Levine", ",", "che", "\u00e8", "il", "pi\u00f9", "recente", "destinatario", "del", "premio", "I", ".", "I", ".", "Rabi", "."], "sentence-detokenized": "L'editore ospite di quel numero sar\u00e0 l'ex collega di David al NIST, Judah Levine, che \u00e8 il pi\u00f9 recente destinatario del premio I. I. Rabi.", "token2charspan": [[0, 2], [2, 9], [10, 16], [17, 19], [20, 24], [25, 31], [32, 36], [37, 39], [39, 41], [42, 49], [50, 52], [53, 58], [59, 61], [62, 66], [66, 67], [68, 73], [74, 80], [80, 81], [82, 85], [86, 87], [88, 90], [91, 94], [95, 102], [103, 115], [116, 119], [120, 126], [127, 128], [128, 129], [130, 131], [131, 132], [133, 137], [137, 138]]}
{"doc_key": "ai-dev-172", "ner": [[13, 15, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Questi", "possono", "essere", "organizzati", "in", "una", "tabella", "di", "contingenza", "2", "\u00d7", "2", "(", "matrice", "di", "confusione", ")", ",", "convenzionalmente", "con", "il", "risultato", "del", "test", "sull'", "asse", "verticale", "e", "la", "condizione", "effettiva", "sull'", "asse", "orizzontale", "."], "sentence-detokenized": "Questi possono essere organizzati in una tabella di contingenza 2 \u00d7 2 (matrice di confusione), convenzionalmente con il risultato del test sull'asse verticale e la condizione effettiva sull'asse orizzontale.", "token2charspan": [[0, 6], [7, 14], [15, 21], [22, 33], [34, 36], [37, 40], [41, 48], [49, 51], [52, 63], [64, 65], [66, 67], [68, 69], [70, 71], [71, 78], [79, 81], [82, 92], [92, 93], [93, 94], [95, 112], [113, 116], [117, 119], [120, 129], [130, 133], [134, 138], [139, 144], [144, 148], [149, 158], [159, 160], [161, 163], [164, 174], [175, 184], [185, 190], [190, 194], [195, 206], [206, 207]]}
{"doc_key": "ai-dev-173", "ner": [[1, 4, "product"], [7, 7, "product"], [9, 9, "product"], [11, 12, "product"], [17, 19, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 4, 7, 7, "part-of", "", false, false], [1, 4, 9, 9, "part-of", "", false, false], [1, 4, 11, 12, "part-of", "", false, false], [1, 4, 17, 19, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Il", "sistema", "operativo", "Apple", "iOS", "utilizzato", "su", "iPhone", ",", "iPad", "e", "iPod", "Touch", "utilizza", "l'", "accessibilit\u00e0", "della", "sintesi", "vocale", "VoiceOver", "."], "sentence-detokenized": "Il sistema operativo Apple iOS utilizzato su iPhone, iPad e iPod Touch utilizza l'accessibilit\u00e0 della sintesi vocale VoiceOver.", "token2charspan": [[0, 2], [3, 10], [11, 20], [21, 26], [27, 30], [31, 41], [42, 44], [45, 51], [51, 52], [53, 57], [58, 59], [60, 64], [65, 70], [71, 79], [80, 82], [82, 95], [96, 101], [102, 109], [110, 116], [117, 126], [126, 127]]}
{"doc_key": "ai-dev-174", "ner": [[9, 11, "conference"], [18, 19, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ad", "esempio", ",", "il", "miglior", "sistema", "che", "ha", "inserito", "MUC", "-", "7", "ha", "ottenuto", "il", "93,39", "%", "della", "misura", "F", ",", "mentre", "gli", "annotatori", "umani", "hanno", "ottenuto", "il", "97,6", "%", "e", "il", "96,95", "%", "."], "sentence-detokenized": "Ad esempio, il miglior sistema che ha inserito MUC-7 ha ottenuto il 93,39% della misura F, mentre gli annotatori umani hanno ottenuto il 97,6% e il 96,95%.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 14], [15, 22], [23, 30], [31, 34], [35, 37], [38, 46], [47, 50], [50, 51], [51, 52], [53, 55], [56, 64], [65, 67], [68, 73], [73, 74], [75, 80], [81, 87], [88, 89], [89, 90], [91, 97], [98, 101], [102, 112], [113, 118], [119, 124], [125, 133], [134, 136], [137, 141], [141, 142], [143, 144], [145, 147], [148, 153], [153, 154], [154, 155]]}
{"doc_key": "ai-dev-175", "ner": [[13, 16, "algorithm"], [18, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 18, 13, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Ci\u00f2", "avviene", "utilizzando", "algoritmi", "standard", "di", "addestramento", "delle", "reti", "neurali", ",", "come", "la", "discesa", "stocastica", "del", "gradiente", "con", "backpropagation", "."], "sentence-detokenized": "Ci\u00f2 avviene utilizzando algoritmi standard di addestramento delle reti neurali, come la discesa stocastica del gradiente con backpropagation.", "token2charspan": [[0, 3], [4, 11], [12, 23], [24, 33], [34, 42], [43, 45], [46, 59], [60, 65], [66, 70], [71, 78], [78, 79], [80, 84], [85, 87], [88, 95], [96, 106], [107, 110], [111, 120], [121, 124], [125, 140], [140, 141]]}
{"doc_key": "ai-dev-176", "ner": [[0, 1, "organisation"], [24, 25, "country"], [32, 32, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 24, 25, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Rotten", "Tomatoes", "\u00e8", "un", "sito", "top", "1000", ",", "che", "si", "posiziona", "intorno", "al", "n.", "400", "a", "livello", "globale", "e", "al", "n.", "150", "solo", "negli", "Stati", "Uniti", ",", "secondo", "il", "sito", "web", "ranker", "Alexa", "."], "sentence-detokenized": "Rotten Tomatoes \u00e8 un sito top 1000, che si posiziona intorno al n. 400 a livello globale e al n. 150 solo negli Stati Uniti, secondo il sito web ranker Alexa.", "token2charspan": [[0, 6], [7, 15], [16, 17], [18, 20], [21, 25], [26, 29], [30, 34], [34, 35], [36, 39], [40, 42], [43, 52], [53, 60], [61, 63], [64, 66], [67, 70], [71, 72], [73, 80], [81, 88], [89, 90], [91, 93], [94, 96], [97, 100], [101, 105], [106, 111], [112, 117], [118, 123], [123, 124], [125, 132], [133, 135], [136, 140], [141, 144], [145, 151], [152, 157], [157, 158]]}
{"doc_key": "ai-dev-177", "ner": [[16, 17, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "generale", ",", "tutto", "l'", "apprendimento", "mostra", "un", "cambiamento", "incrementale", "nel", "tempo", ",", "ma", "descrive", "una", "funzione", "sigmoide", "che", "ha", "aspetti", "diversi", "a", "seconda", "della", "scala", "temporale", "di", "osservazione", "."], "sentence-detokenized": "In generale, tutto l'apprendimento mostra un cambiamento incrementale nel tempo, ma descrive una funzione sigmoide che ha aspetti diversi a seconda della scala temporale di osservazione.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 18], [19, 21], [21, 34], [35, 41], [42, 44], [45, 56], [57, 69], [70, 73], [74, 79], [79, 80], [81, 83], [84, 92], [93, 96], [97, 105], [106, 114], [115, 118], [119, 121], [122, 129], [130, 137], [138, 139], [140, 147], [148, 153], [154, 159], [160, 169], [170, 172], [173, 185], [185, 186]]}
{"doc_key": "ai-dev-178", "ner": [[1, 1, "metrics"], [6, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 1, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["L'", "SSD", "\u00e8", "noto", "anche", "come", "errore", "quadratico", "medio", "."], "sentence-detokenized": "L'SSD \u00e8 noto anche come errore quadratico medio.", "token2charspan": [[0, 2], [2, 5], [6, 7], [8, 12], [13, 18], [19, 23], [24, 30], [31, 41], [42, 47], [47, 48]]}
{"doc_key": "ai-dev-179", "ner": [[0, 4, "algorithm"], [7, 8, "algorithm"], [11, 14, "algorithm"], [29, 30, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 4, 29, 30, "related-to", "can_be_related_to", true, false], [7, 8, 29, 30, "related-to", "can_be_related_to", true, false], [11, 14, 29, 30, "related-to", "can_be_related_to", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["L'", "apprendimento", "ad", "albero", "decisionale", ",", "le", "reti", "neurali", "o", "un", "classificatore", "di", "Bayes", "ingenuo", "possono", "essere", "utilizzati", "in", "combinazione", "con", "misure", "di", "qualit\u00e0", "del", "modello", ",", "come", "l'", "accuratezza", "bilanciata", "."], "sentence-detokenized": "L'apprendimento ad albero decisionale, le reti neurali o un classificatore di Bayes ingenuo possono essere utilizzati in combinazione con misure di qualit\u00e0 del modello, come l'accuratezza bilanciata.", "token2charspan": [[0, 2], [2, 15], [16, 18], [19, 25], [26, 37], [37, 38], [39, 41], [42, 46], [47, 54], [55, 56], [57, 59], [60, 74], [75, 77], [78, 83], [84, 91], [92, 99], [100, 106], [107, 117], [118, 120], [121, 133], [134, 137], [138, 144], [145, 147], [148, 155], [156, 159], [160, 167], [167, 168], [169, 173], [174, 176], [176, 187], [188, 198], [198, 199]]}
{"doc_key": "ai-dev-180", "ner": [[15, 15, "conference"], [22, 26, "conference"], [27, 29, "misc"], [35, 38, "product"], [43, 46, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[27, 29, 22, 26, "origin", "", false, false], [27, 29, 22, 26, "temporal", "", false, false], [35, 38, 27, 29, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["\u00c8", "un", "ex", "presidente", "(", "1979", ")", "e", "un", "Fellow", "inaugurale", "(", "2011", ")", "dell'", "ACL", ",", "un", "co", "-", "ricevente", "del", "1992", "Association", "for", "Computing", "Machinery", "Software", "Systems", "Award", "per", "il", "suo", "contributo", "al", "sistema", "di", "programmazione", "Interlisp", "e", "un", "Fellow", "dell'", "Association", "for", "Computing", "Machinery", "."], "sentence-detokenized": "\u00c8 un ex presidente (1979) e un Fellow inaugurale (2011) dell'ACL, un co-ricevente del 1992 Association for Computing Machinery Software Systems Award per il suo contributo al sistema di programmazione Interlisp e un Fellow dell'Association for Computing Machinery.", "token2charspan": [[0, 1], [2, 4], [5, 7], [8, 18], [19, 20], [20, 24], [24, 25], [26, 27], [28, 30], [31, 37], [38, 48], [49, 50], [50, 54], [54, 55], [56, 61], [61, 64], [64, 65], [66, 68], [69, 71], [71, 72], [72, 81], [82, 85], [86, 90], [91, 102], [103, 106], [107, 116], [117, 126], [127, 135], [136, 143], [144, 149], [150, 153], [154, 156], [157, 160], [161, 171], [172, 174], [175, 182], [183, 185], [186, 200], [201, 210], [211, 212], [213, 215], [216, 222], [223, 228], [228, 239], [240, 243], [244, 253], [254, 263], [263, 264]]}
{"doc_key": "ai-dev-181", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [12, 13, "researcher"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 23, 24, "related-to", "", false, false], [5, 6, 23, 24, "related-to", "", false, false], [8, 8, 23, 24, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Insieme", "a", "Geoffrey", "Hinton", "e", "Yann", "LeCun", ",", "Bengio", "\u00e8", "considerato", "da", "Cade", "Metz", "una", "delle", "tre", "persone", "maggiormente", "responsabili", "dell'", "avanzamento", "del", "deep", "learning", "negli", "anni", "'90", "e", "2000", "."], "sentence-detokenized": "Insieme a Geoffrey Hinton e Yann LeCun, Bengio \u00e8 considerato da Cade Metz una delle tre persone maggiormente responsabili dell'avanzamento del deep learning negli anni '90 e 2000.", "token2charspan": [[0, 7], [8, 9], [10, 18], [19, 25], [26, 27], [28, 32], [33, 38], [38, 39], [40, 46], [47, 48], [49, 60], [61, 63], [64, 68], [69, 73], [74, 77], [78, 83], [84, 87], [88, 95], [96, 108], [109, 121], [122, 127], [127, 138], [139, 142], [143, 147], [148, 156], [157, 162], [163, 167], [168, 171], [172, 173], [174, 178], [178, 179]]}
{"doc_key": "ai-dev-182", "ner": [[1, 3, "field"], [6, 6, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Nella", "teoria", "dell'", "informazione", "e", "nell'", "informatica", ",", "un", "codice", "\u00e8", "solitamente", "considerato", "come", "un", "algoritmo", "che", "rappresenta", "in", "modo", "univoco", "i", "simboli", "di", "un", "alfabeto", "di", "partenza", "con", "stringhe", "codificate", ",", "che", "possono", "essere", "in", "un", "altro", "alfabeto", "di", "arrivo", "."], "sentence-detokenized": "Nella teoria dell'informazione e nell'informatica, un codice \u00e8 solitamente considerato come un algoritmo che rappresenta in modo univoco i simboli di un alfabeto di partenza con stringhe codificate, che possono essere in un altro alfabeto di arrivo.", "token2charspan": [[0, 5], [6, 12], [13, 18], [18, 30], [31, 32], [33, 38], [38, 49], [49, 50], [51, 53], [54, 60], [61, 62], [63, 74], [75, 86], [87, 91], [92, 94], [95, 104], [105, 108], [109, 120], [121, 123], [124, 128], [129, 136], [137, 138], [139, 146], [147, 149], [150, 152], [153, 161], [162, 164], [165, 173], [174, 177], [178, 186], [187, 197], [197, 198], [199, 202], [203, 210], [211, 217], [218, 220], [221, 223], [224, 229], [230, 238], [239, 241], [242, 248], [248, 249]]}
{"doc_key": "ai-dev-183", "ner": [[7, 8, "algorithm"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 13, 7, 8, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Funzione", "non", "lineare", "abbastanza", "semplice", ",", "la", "funzione", "sigmoide", ",", "come", "la", "funzione", "logistica", ",", "ha", "anche", "una", "derivata", "facilmente", "calcolabile", ",", "che", "pu\u00f2", "essere", "importante", "per", "calcolare", "gli", "aggiornamenti", "dei", "pesi", "nella", "rete", "."], "sentence-detokenized": "Funzione non lineare abbastanza semplice, la funzione sigmoide, come la funzione logistica, ha anche una derivata facilmente calcolabile, che pu\u00f2 essere importante per calcolare gli aggiornamenti dei pesi nella rete.", "token2charspan": [[0, 8], [9, 12], [13, 20], [21, 31], [32, 40], [40, 41], [42, 44], [45, 53], [54, 62], [62, 63], [64, 68], [69, 71], [72, 80], [81, 90], [90, 91], [92, 94], [95, 100], [101, 104], [105, 113], [114, 124], [125, 136], [136, 137], [138, 141], [142, 145], [146, 152], [153, 163], [164, 167], [168, 177], [178, 181], [182, 195], [196, 199], [200, 204], [205, 210], [211, 215], [215, 216]]}
{"doc_key": "ai-dev-184", "ner": [[0, 0, "person"], [3, 3, "location"], [6, 6, "location"], [8, 8, "country"], [11, 11, "country"], [14, 15, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 3, 3, "physical", "", false, false], [3, 3, 6, 6, "physical", "", false, false], [6, 6, 8, 8, "physical", "", false, false], [6, 6, 11, 11, "physical", "", false, false], [6, 6, 14, 15, "physical", "", false, false], [11, 11, 8, 8, "origin", "", false, false], [14, 15, 11, 11, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["\u010capek", "nacque", "a", "Hronov", ",", "in", "Boemia", "(", "Austria-Ungheria", ",", "poi", "Cecoslovacchia", ",", "oggi", "Repubblica", "Ceca", ")", "nel", "1887", "."], "sentence-detokenized": "\u010capek nacque a Hronov, in Boemia (Austria-Ungheria, poi Cecoslovacchia, oggi Repubblica Ceca) nel 1887.", "token2charspan": [[0, 5], [6, 12], [13, 14], [15, 21], [21, 22], [23, 25], [26, 32], [33, 34], [34, 50], [50, 51], [52, 55], [56, 70], [70, 71], [72, 76], [77, 87], [88, 92], [92, 93], [94, 97], [98, 102], [102, 103]]}
{"doc_key": "ai-dev-185", "ner": [[6, 6, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Alcuni", "software", "specializzati", "possono", "narrare", "gli", "RSS."], "sentence-detokenized": "Alcuni software specializzati possono narrare gli RSS.", "token2charspan": [[0, 6], [7, 15], [16, 29], [30, 37], [38, 45], [46, 49], [50, 54]]}
{"doc_key": "ai-dev-186", "ner": [[10, 11, "task"], [15, 17, "task"], [20, 21, "task"], [23, 23, "task"], [25, 28, "task"], [35, 38, "task"], [42, 45, "task"], [49, 51, "task"], [53, 55, "product"], [57, 58, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[10, 11, 15, 17, "related-to", "", true, false], [10, 11, 20, 21, "related-to", "", true, false], [10, 11, 23, 23, "related-to", "", true, false], [42, 45, 35, 38, "usage", "", true, false], [53, 55, 49, 51, "type-of", "", false, false], [57, 58, 49, 51, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gli", "aspetti", "degli", "editor", "di", "ontologie", "includono", ":", "possibilit\u00e0", "di", "navigazione", "visiva", "all'", "interno", "del", "modello", "di", "conoscenza", ",", "motori", "di", "inferenza", "ed", "estrazione", ";", "supporto", "per", "i", "moduli", ";", "importazione", "ed", "esportazione", "di", "linguaggi", "di", "rappresentazione", "della", "conoscenza", "stranieri", "per", "la", "corrispondenza", "con", "l'", "ontologia", ";", "supporto", "di", "meta", "-", "ontologie", "come", "OWL", "-", "S", ",", "Dublin", "Core", ",", "ecc", "."], "sentence-detokenized": "Gli aspetti degli editor di ontologie includono: possibilit\u00e0 di navigazione visiva all'interno del modello di conoscenza, motori di inferenza ed estrazione; supporto per i moduli; importazione ed esportazione di linguaggi di rappresentazione della conoscenza stranieri per la corrispondenza con l'ontologia; supporto di meta-ontologie come OWL-S, Dublin Core, ecc.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 24], [25, 27], [28, 37], [38, 47], [47, 48], [49, 60], [61, 63], [64, 75], [76, 82], [83, 87], [87, 94], [95, 98], [99, 106], [107, 109], [110, 120], [120, 121], [122, 128], [129, 131], [132, 141], [142, 144], [145, 155], [155, 156], [157, 165], [166, 169], [170, 171], [172, 178], [178, 179], [180, 192], [193, 195], [196, 208], [209, 211], [212, 221], [222, 224], [225, 241], [242, 247], [248, 258], [259, 268], [269, 272], [273, 275], [276, 290], [291, 294], [295, 297], [297, 306], [306, 307], [308, 316], [317, 319], [320, 324], [324, 325], [325, 334], [335, 339], [340, 343], [343, 344], [344, 345], [345, 346], [347, 353], [354, 358], [358, 359], [360, 363], [363, 364]]}
{"doc_key": "ai-dev-187", "ner": [[1, 1, "organisation"], [7, 12, "misc"], [16, 17, "task"], [21, 22, "field"], [27, 28, "misc"], [31, 33, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 12, 1, 1, "origin", "", false, false], [16, 17, 7, 12, "part-of", "", false, false], [21, 22, 7, 12, "part-of", "", false, false], [27, 28, 21, 22, "type-of", "", false, false], [31, 33, 21, 22, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["L'", "FBI", "ha", "anche", "istituito", "il", "suo", "programma", "di", "identificazione", "di", "nuova", "generazione", "per", "includere", "il", "riconoscimento", "facciale", ",", "oltre", "ai", "dati", "biometrici", "pi\u00f9", "tradizionali", "come", "le", "impronte", "digitali", "e", "le", "scansioni", "dell'", "iride", ",", "che", "possono", "essere", "estratti", "da", "database", "sia", "penali", "che", "civili", "."], "sentence-detokenized": "L'FBI ha anche istituito il suo programma di identificazione di nuova generazione per includere il riconoscimento facciale, oltre ai dati biometrici pi\u00f9 tradizionali come le impronte digitali e le scansioni dell'iride, che possono essere estratti da database sia penali che civili.", "token2charspan": [[0, 2], [2, 5], [6, 8], [9, 14], [15, 24], [25, 27], [28, 31], [32, 41], [42, 44], [45, 60], [61, 63], [64, 69], [70, 81], [82, 85], [86, 95], [96, 98], [99, 113], [114, 122], [122, 123], [124, 129], [130, 132], [133, 137], [138, 148], [149, 152], [153, 165], [166, 170], [171, 173], [174, 182], [183, 191], [192, 193], [194, 196], [197, 206], [207, 212], [212, 217], [217, 218], [219, 222], [223, 230], [231, 237], [238, 246], [247, 249], [250, 258], [259, 262], [263, 269], [270, 273], [274, 280], [280, 281]]}
{"doc_key": "ai-dev-188", "ner": [[7, 8, "person"], [15, 16, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Per", "la", "stagione", "2016", "\u00e8", "stata", "aggiunta", "Samantha", "Ponder", "come", "conduttrice", ",", "in", "sostituzione", "di", "Molly", "McGrath", "."], "sentence-detokenized": "Per la stagione 2016 \u00e8 stata aggiunta Samantha Ponder come conduttrice, in sostituzione di Molly McGrath.", "token2charspan": [[0, 3], [4, 6], [7, 15], [16, 20], [21, 22], [23, 28], [29, 37], [38, 46], [47, 53], [54, 58], [59, 70], [70, 71], [72, 74], [75, 87], [88, 90], [91, 96], [97, 104], [104, 105]]}
{"doc_key": "ai-dev-189", "ner": [[4, 7, "algorithm"], [20, 23, "misc"], [25, 25, "misc"], [27, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Si", "tratta", "di", "un", "algoritmo", "di", "ricerca", "avversaria", "utilizzato", "comunemente", "per", "la", "riproduzione", "automatica", "di", "giochi", "a", "due", "giocatori", "(", "Tic", "-tac", "-", "toe", ",", "Scacchi", ",", "Go", ",", "ecc.", ")", "."], "sentence-detokenized": "Si tratta di un algoritmo di ricerca avversaria utilizzato comunemente per la riproduzione automatica di giochi a due giocatori (Tic-tac-toe, Scacchi, Go, ecc.).", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 15], [16, 25], [26, 28], [29, 36], [37, 47], [48, 58], [59, 70], [71, 74], [75, 77], [78, 90], [91, 101], [102, 104], [105, 111], [112, 113], [114, 117], [118, 127], [128, 129], [129, 132], [132, 136], [136, 137], [137, 140], [140, 141], [142, 149], [149, 150], [151, 153], [153, 154], [155, 159], [159, 160], [160, 161]]}
{"doc_key": "ai-dev-190", "ner": [[4, 5, "field"], [7, 8, "field"], [11, 12, "field"], [19, 21, "field"], [24, 25, "field"], [28, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Coinvolge", "i", "campi", "della", "computer", "vision", "o", "visione", "artificiale", "e", "dell'", "imaging", "medico", "e", "fa", "un", "uso", "intensivo", "del", "riconoscimento", "dei", "modelli", ",", "della", "geometria", "digitale", "e", "dell'", "elaborazione", "dei", "segnali", "."], "sentence-detokenized": "Coinvolge i campi della computer vision o visione artificiale e dell'imaging medico e fa un uso intensivo del riconoscimento dei modelli, della geometria digitale e dell'elaborazione dei segnali.", "token2charspan": [[0, 9], [10, 11], [12, 17], [18, 23], [24, 32], [33, 39], [40, 41], [42, 49], [50, 61], [62, 63], [64, 69], [69, 76], [77, 83], [84, 85], [86, 88], [89, 91], [92, 95], [96, 105], [106, 109], [110, 124], [125, 128], [129, 136], [136, 137], [138, 143], [144, 153], [154, 162], [163, 164], [165, 170], [170, 182], [183, 186], [187, 194], [194, 195]]}
{"doc_key": "ai-dev-191", "ner": [[1, 4, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Nel", "sistema", "di", "riconoscimento", "facciale", ",", "ad", "esempio", ",", "l'", "ingresso", "\u00e8", "costituito", "da", "un'", "immagine", "del", "volto", "di", "una", "persona", "e", "l'", "etichetta", "di", "uscita", "\u00e8", "il", "nome", "di", "quella", "persona", "."], "sentence-detokenized": "Nel sistema di riconoscimento facciale, ad esempio, l'ingresso \u00e8 costituito da un'immagine del volto di una persona e l'etichetta di uscita \u00e8 il nome di quella persona.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 29], [30, 38], [38, 39], [40, 42], [43, 50], [50, 51], [52, 54], [54, 62], [63, 64], [65, 75], [76, 78], [79, 82], [82, 90], [91, 94], [95, 100], [101, 103], [104, 107], [108, 115], [116, 117], [118, 120], [120, 129], [130, 132], [133, 139], [140, 141], [142, 144], [145, 149], [150, 152], [153, 159], [160, 167], [167, 168]]}
{"doc_key": "ai-dev-192", "ner": [[0, 3, "organisation"], [5, 6, "product"], [9, 10, "product"], [17, 18, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 5, 6, "artifact", "", false, false], [5, 6, 9, 10, "part-of", "", false, false], [9, 10, 5, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Apple", "Inc", ".", "ha", "introdotto", "Face", "ID", "sull'", "ammiraglia", "iPhone", "X", "come", "successore", "dell'", "autenticazione", "biometrica", "del", "Touch", "ID", ",", "un", "sistema", "basato", "sulle", "impronte", "digitali", "."], "sentence-detokenized": "Apple Inc. ha introdotto Face ID sull'ammiraglia iPhone X come successore dell'autenticazione biometrica del Touch ID, un sistema basato sulle impronte digitali.", "token2charspan": [[0, 5], [6, 9], [9, 10], [11, 13], [14, 24], [25, 29], [30, 32], [33, 38], [38, 48], [49, 55], [56, 57], [58, 62], [63, 73], [74, 79], [79, 93], [94, 104], [105, 108], [109, 114], [115, 117], [117, 118], [119, 121], [122, 129], [130, 136], [137, 142], [143, 151], [152, 160], [160, 161]]}
{"doc_key": "ai-dev-193", "ner": [[3, 4, "metrics"], [7, 8, "metrics"], [22, 25, "metrics"], [28, 30, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Oppure", "combinare", "la", "misura", "F", "con", "il", "quadrato", "R", "valutato", "per", "l'", "output", "del", "modello", "grezzo", "e", "l'", "obiettivo", ";", "o", "la", "matrice", "costi", "/", "guadagni", "con", "il", "coefficiente", "di", "correlazione", ",", "e", "cos\u00ec", "via", "."], "sentence-detokenized": "Oppure combinare la misura F con il quadrato R valutato per l'output del modello grezzo e l'obiettivo; o la matrice costi/guadagni con il coefficiente di correlazione, e cos\u00ec via.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 26], [27, 28], [29, 32], [33, 35], [36, 44], [45, 46], [47, 55], [56, 59], [60, 62], [62, 68], [69, 72], [73, 80], [81, 87], [88, 89], [90, 92], [92, 101], [101, 102], [103, 104], [105, 107], [108, 115], [116, 121], [121, 122], [122, 130], [131, 134], [135, 137], [138, 150], [151, 153], [154, 166], [166, 167], [168, 169], [170, 174], [175, 178], [178, 179]]}
{"doc_key": "ai-dev-194", "ner": [[1, 6, "conference"], [10, 12, "location"], [15, 15, "location"], [19, 23, "location"], [25, 25, "location"], [28, 28, "country"], [37, 41, "location"], [44, 49, "location"], [51, 51, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[1, 6, 10, 12, "physical", "", false, false], [1, 6, 19, 23, "physical", "", false, false], [1, 6, 37, 41, "physical", "", false, false], [1, 6, 44, 49, "physical", "", false, false], [10, 12, 15, 15, "physical", "", false, false], [19, 23, 25, 25, "physical", "", false, false], [25, 25, 28, 28, "physical", "", false, false], [37, 41, 51, 51, "physical", "", false, false], [44, 49, 51, 51, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["L'", "edizione", "spagnola", "di", "Campus", "Party", "si", "\u00e8", "tenuta", "al", "Colegio", "Miguel", "Hern\u00e1ndez", ",", "a", "Ceulaj", ",", "e", "alla", "Municipal", "Sport", "Arena", "di", "Benalm\u00e1dena", "a", "Malaga", ",", "in", "Spagna", ",", "e", "negli", "ultimi", "15", "anni", "sia", "alla", "Fiera", "della", "Contea", "di", "Valencia", "che", "alla", "Citt\u00e0", "delle", "Arti", "e", "delle", "Scienze", "di", "Valencia", "."], "sentence-detokenized": "L'edizione spagnola di Campus Party si \u00e8 tenuta al Colegio Miguel Hern\u00e1ndez, a Ceulaj, e alla Municipal Sport Arena di Benalm\u00e1dena a Malaga, in Spagna, e negli ultimi 15 anni sia alla Fiera della Contea di Valencia che alla Citt\u00e0 delle Arti e delle Scienze di Valencia.", "token2charspan": [[0, 2], [2, 10], [11, 19], [20, 22], [23, 29], [30, 35], [36, 38], [39, 40], [41, 47], [48, 50], [51, 58], [59, 65], [66, 75], [75, 76], [77, 78], [79, 85], [85, 86], [87, 88], [89, 93], [94, 103], [104, 109], [110, 115], [116, 118], [119, 130], [131, 132], [133, 139], [139, 140], [141, 143], [144, 150], [150, 151], [152, 153], [154, 159], [160, 166], [167, 169], [170, 174], [175, 178], [179, 183], [184, 189], [190, 195], [196, 202], [203, 205], [206, 214], [215, 218], [219, 223], [224, 229], [230, 235], [236, 240], [241, 242], [243, 248], [249, 256], [257, 259], [260, 268], [268, 269]]}
{"doc_key": "ai-dev-195", "ner": [[0, 0, "product"], [17, 17, "programlang"], [22, 22, "product"], [24, 24, "product"], [27, 27, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[17, 17, 0, 0, "general-affiliation", "", false, false], [22, 22, 17, 17, "part-of", "", false, false], [24, 24, 17, 17, "part-of", "", false, false], [27, 27, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["gnuplot", "pu\u00f2", "essere", "utilizzato", "da", "diversi", "linguaggi", "di", "programmazione", "per", "creare", "grafici", "di", "dati", ",", "tra", "cui", "Perl", "(", "tramite", "i", "pacchetti", "PDL", "e", "CPAN", ")", ",", "Python", "(", "tramite", ")", "."], "sentence-detokenized": "gnuplot pu\u00f2 essere utilizzato da diversi linguaggi di programmazione per creare grafici di dati, tra cui Perl (tramite i pacchetti PDL e CPAN), Python (tramite).", "token2charspan": [[0, 7], [8, 11], [12, 18], [19, 29], [30, 32], [33, 40], [41, 50], [51, 53], [54, 68], [69, 72], [73, 79], [80, 87], [88, 90], [91, 95], [95, 96], [97, 100], [101, 104], [105, 109], [110, 111], [111, 118], [119, 120], [121, 130], [131, 134], [135, 136], [137, 141], [141, 142], [142, 143], [144, 150], [151, 152], [152, 159], [159, 160], [160, 161]]}
{"doc_key": "ai-dev-196", "ner": [[3, 6, "product"], [20, 20, "conference"], [22, 22, "conference"], [35, 35, "conference"], [37, 37, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[20, 20, 3, 6, "topic", "", false, false], [22, 22, 3, 6, "topic", "", false, false], [35, 35, 3, 6, "topic", "", false, false], [37, 37, 3, 6, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Il", "campo", "dei", "sistemi", "di", "dialogo", "parlato", "\u00e8", "piuttosto", "vasto", "e", "comprende", "la", "ricerca", "(", "presentata", "in", "conferenze", "scientifiche", "come", "SIGdial", "e", "Interspeech", ")", "e", "un", "ampio", "settore", "industriale", "(", "con", "i", "propri", "incontri", "come", "SpeechTek", "e", "AVIOS", ")", "."], "sentence-detokenized": "Il campo dei sistemi di dialogo parlato \u00e8 piuttosto vasto e comprende la ricerca (presentata in conferenze scientifiche come SIGdial e Interspeech) e un ampio settore industriale (con i propri incontri come SpeechTek e AVIOS).", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 20], [21, 23], [24, 31], [32, 39], [40, 41], [42, 51], [52, 57], [58, 59], [60, 69], [70, 72], [73, 80], [81, 82], [82, 92], [93, 95], [96, 106], [107, 119], [120, 124], [125, 132], [133, 134], [135, 146], [146, 147], [148, 149], [150, 152], [153, 158], [159, 166], [167, 178], [179, 180], [180, 183], [184, 185], [186, 192], [193, 201], [202, 206], [207, 216], [217, 218], [219, 224], [224, 225], [225, 226]]}
{"doc_key": "ai-dev-197", "ner": [[3, 6, "field"], [10, 11, "task"], [14, 17, "task"], [20, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 11, 3, 6, "part-of", "task_part_of_field", false, false], [14, 17, 3, 6, "part-of", "task_part_of_field", false, false], [20, 23, 3, 6, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Le", "sfide", "nell'", "elaborazione", "del", "linguaggio", "naturale", "riguardano", "spesso", "il", "riconoscimento", "vocale", ",", "la", "comprensione", "del", "linguaggio", "naturale", "e", "la", "generazione", "del", "linguaggio", "naturale", "."], "sentence-detokenized": "Le sfide nell'elaborazione del linguaggio naturale riguardano spesso il riconoscimento vocale, la comprensione del linguaggio naturale e la generazione del linguaggio naturale.", "token2charspan": [[0, 2], [3, 8], [9, 14], [14, 26], [27, 30], [31, 41], [42, 50], [51, 61], [62, 68], [69, 71], [72, 86], [87, 93], [93, 94], [95, 97], [98, 110], [111, 114], [115, 125], [126, 134], [135, 136], [137, 139], [140, 151], [152, 155], [156, 166], [167, 175], [175, 176]]}
{"doc_key": "ai-dev-198", "ner": [[4, 4, "product"], [6, 8, "product"], [36, 37, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 6, 8, "part-of", "", false, false], [4, 4, 36, 37, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Questi", "sistemi", ",", "come", "Siri", "del", "sistema", "operativo", "iOS", ",", "funzionano", "con", "una", "tecnica", "di", "riconoscimento", "dei", "modelli", "simile", "a", "quella", "dei", "sistemi", "testuali", ",", "ma", "nel", "primo", "caso", "l'", "input", "dell'", "utente", "avviene", "attraverso", "il", "riconoscimento", "vocale", "."], "sentence-detokenized": "Questi sistemi, come Siri del sistema operativo iOS, funzionano con una tecnica di riconoscimento dei modelli simile a quella dei sistemi testuali, ma nel primo caso l'input dell'utente avviene attraverso il riconoscimento vocale.", "token2charspan": [[0, 6], [7, 14], [14, 15], [16, 20], [21, 25], [26, 29], [30, 37], [38, 47], [48, 51], [51, 52], [53, 63], [64, 67], [68, 71], [72, 79], [80, 82], [83, 97], [98, 101], [102, 109], [110, 116], [117, 118], [119, 125], [126, 129], [130, 137], [138, 146], [146, 147], [148, 150], [151, 154], [155, 160], [161, 165], [166, 168], [168, 173], [174, 179], [179, 185], [186, 193], [194, 204], [205, 207], [208, 222], [223, 229], [229, 230]]}
{"doc_key": "ai-dev-199", "ner": [[0, 4, "algorithm"], [16, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 4, 16, 17, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Funzioni", "di", "fitness", "pi\u00f9", "esotiche", "che", "esplorano", "la", "granularit\u00e0", "del", "modello", "includono", "l'", "area", "sotto", "la", "curva", "ROC", "e", "la", "misura", "di", "rango", "."], "sentence-detokenized": "Funzioni di fitness pi\u00f9 esotiche che esplorano la granularit\u00e0 del modello includono l'area sotto la curva ROC e la misura di rango.", "token2charspan": [[0, 8], [9, 11], [12, 19], [20, 23], [24, 32], [33, 36], [37, 46], [47, 49], [50, 61], [62, 65], [66, 73], [74, 83], [84, 86], [86, 90], [91, 96], [97, 99], [100, 105], [106, 109], [110, 111], [112, 114], [115, 121], [122, 124], [125, 130], [130, 131]]}
{"doc_key": "ai-dev-200", "ner": [[2, 3, "product"], [8, 11, "researcher"], [15, 17, "product"], [21, 24, "organisation"], [26, 26, "organisation"], [34, 39, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 8, 11, "origin", "", false, false], [8, 11, 21, 24, "role", "", false, false], [15, 17, 8, 11, "origin", "", false, false], [26, 26, 21, 24, "named", "", false, false], [34, 39, 21, 24, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Il", "termine", "Semantic", "Web", "\u00e8", "stato", "coniato", "da", "Tim", "Berners", "-", "Lee", ",", "inventore", "del", "World", "Wide", "Web", "e", "direttore", "del", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", ",", "che", "supervisiona", "lo", "sviluppo", "degli", "standard", "proposti", "per", "il", "Semantic", "Web", "."], "sentence-detokenized": "Il termine Semantic Web \u00e8 stato coniato da Tim Berners-Lee, inventore del World Wide Web e direttore del World Wide Web Consortium (W3C), che supervisiona lo sviluppo degli standard proposti per il Semantic Web.", "token2charspan": [[0, 2], [3, 10], [11, 19], [20, 23], [24, 25], [26, 31], [32, 39], [40, 42], [43, 46], [47, 54], [54, 55], [55, 58], [58, 59], [60, 69], [70, 73], [74, 79], [80, 84], [85, 88], [89, 90], [91, 100], [101, 104], [105, 110], [111, 115], [116, 119], [120, 130], [131, 132], [132, 135], [135, 136], [136, 137], [138, 141], [142, 154], [155, 157], [158, 166], [167, 172], [173, 181], [182, 190], [191, 194], [195, 197], [198, 206], [207, 210], [210, 211]]}
{"doc_key": "ai-dev-201", "ner": [[0, 2, "task"], [9, 9, "task"], [16, 19, "product"], [22, 26, "product"], [28, 28, "product"], [32, 33, "product"], [40, 41, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 16, 19, "opposite", "", false, false], [0, 2, 22, 26, "opposite", "", false, false], [0, 2, 32, 33, "opposite", "", false, false], [0, 2, 40, 41, "part-of", "", false, false], [9, 9, 0, 2, "named", "", false, false], [28, 28, 22, 26, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["La", "traduzione", "automatica", ",", "talvolta", "indicata", "con", "l'", "abbreviazione", "MT", "(", "da", "non", "confondere", "con", "la", "traduzione", "assistita", "da", "computer", ",", "la", "traduzione", "umana", "assistita", "da", "macchina", "(", "MAHT", ")", "o", "la", "traduzione", "interattiva", ")", ",", "\u00e8", "un", "sottocampo", "della", "linguistica", "computazionale", "che", "studia", "l'", "uso", "di", "software", "per", "tradurre", "testi", "o", "discorsi", "da", "una", "lingua", "all'", "altra", "."], "sentence-detokenized": "La traduzione automatica, talvolta indicata con l'abbreviazione MT (da non confondere con la traduzione assistita da computer, la traduzione umana assistita da macchina (MAHT) o la traduzione interattiva), \u00e8 un sottocampo della linguistica computazionale che studia l'uso di software per tradurre testi o discorsi da una lingua all'altra.", "token2charspan": [[0, 2], [3, 13], [14, 24], [24, 25], [26, 34], [35, 43], [44, 47], [48, 50], [50, 63], [64, 66], [67, 68], [68, 70], [71, 74], [75, 85], [86, 89], [90, 92], [93, 103], [104, 113], [114, 116], [117, 125], [125, 126], [127, 129], [130, 140], [141, 146], [147, 156], [157, 159], [160, 168], [169, 170], [170, 174], [174, 175], [176, 177], [178, 180], [181, 191], [192, 203], [203, 204], [204, 205], [206, 207], [208, 210], [211, 221], [222, 227], [228, 239], [240, 254], [255, 258], [259, 265], [266, 268], [268, 271], [272, 274], [275, 283], [284, 287], [288, 296], [297, 302], [303, 304], [305, 313], [314, 316], [317, 320], [321, 327], [328, 332], [332, 337], [337, 338]]}
{"doc_key": "ai-dev-202", "ner": [[2, 6, "product"], [12, 12, "university"], [17, 18, "researcher"], [20, 21, "researcher"], [47, 48, "location"], [50, 50, "location"], [54, 58, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 6, 17, 18, "artifact", "", false, false], [2, 6, 20, 21, "artifact", "", false, false], [17, 18, 12, 12, "physical", "", false, false], [17, 18, 12, 12, "role", "", false, false], [20, 21, 12, 12, "physical", "", false, false], [20, 21, 12, 12, "role", "", false, false], [47, 48, 50, 50, "physical", "", false, false], [54, 58, 47, 48, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["I", "primi", "sistemi", "di", "traduzione", "automatica", "interlinguistica", "sono", "stati", "realizzati", "anche", "a", "Stanford", "negli", "anni", "Settanta", "da", "Roger", "Schank", "e", "Yorick", "Wilks", ";", "il", "primo", "\u00e8", "diventato", "la", "base", "di", "un", "sistema", "commerciale", "per", "il", "trasferimento", "di", "fondi", ",", "mentre", "il", "codice", "del", "secondo", "\u00e8", "conservato", "al", "Computer", "Museum", "di", "Boston", "come", "il", "primo", "sistema", "di", "traduzione", "automatica", "interlinguistica", "."], "sentence-detokenized": "I primi sistemi di traduzione automatica interlinguistica sono stati realizzati anche a Stanford negli anni Settanta da Roger Schank e Yorick Wilks; il primo \u00e8 diventato la base di un sistema commerciale per il trasferimento di fondi, mentre il codice del secondo \u00e8 conservato al Computer Museum di Boston come il primo sistema di traduzione automatica interlinguistica.", "token2charspan": [[0, 1], [2, 7], [8, 15], [16, 18], [19, 29], [30, 40], [41, 57], [58, 62], [63, 68], [69, 79], [80, 85], [86, 87], [88, 96], [97, 102], [103, 107], [108, 116], [117, 119], [120, 125], [126, 132], [133, 134], [135, 141], [142, 147], [147, 148], [149, 151], [152, 157], [158, 159], [160, 169], [170, 172], [173, 177], [178, 180], [181, 183], [184, 191], [192, 203], [204, 207], [208, 210], [211, 224], [225, 227], [228, 233], [233, 234], [235, 241], [242, 244], [245, 251], [252, 255], [256, 263], [264, 265], [266, 276], [277, 279], [280, 288], [289, 295], [296, 298], [299, 305], [306, 310], [311, 313], [314, 319], [320, 327], [328, 330], [331, 341], [342, 352], [353, 369], [369, 370]]}
{"doc_key": "ai-dev-203", "ner": [[0, 0, "researcher"], [7, 12, "conference"], [14, 15, "conference"], [21, 26, "conference"], [28, 29, "conference"], [34, 39, "organisation"], [52, 52, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 7, 12, "role", "", false, false], [0, 0, 21, 26, "role", "", false, false], [0, 0, 34, 39, "role", "", false, false], [0, 0, 52, 52, "role", "", false, false], [14, 15, 7, 12, "named", "", false, false], [28, 29, 21, 26, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sycara", "\u00e8", "stato", "presidente", "del", "programma", "della", "seconda", "conferenza", "internazionale", "sul", "Web", "semantico", "(", "ISWC", "2003", ")", ";", "presidente", "generale", "della", "seconda", "conferenza", "internazionale", "sugli", "agenti", "autonomi", "(", "Agents", "98", ")", ";", "presidente", "del", "comitato", "direttivo", "della", "conferenza", "sugli", "agenti", "(", "1999", "-", "2001", ")", ";", "presidente", "della", "borsa", "di", "studio", "dell'", "AAAI", "(", "1993", "-", "1999", ")", ";"], "sentence-detokenized": "Sycara \u00e8 stato presidente del programma della seconda conferenza internazionale sul Web semantico (ISWC 2003); presidente generale della seconda conferenza internazionale sugli agenti autonomi (Agents 98); presidente del comitato direttivo della conferenza sugli agenti (1999-2001); presidente della borsa di studio dell'AAAI (1993-1999);", "token2charspan": [[0, 6], [7, 8], [9, 14], [15, 25], [26, 29], [30, 39], [40, 45], [46, 53], [54, 64], [65, 79], [80, 83], [84, 87], [88, 97], [98, 99], [99, 103], [104, 108], [108, 109], [109, 110], [111, 121], [122, 130], [131, 136], [137, 144], [145, 155], [156, 170], [171, 176], [177, 183], [184, 192], [193, 194], [194, 200], [201, 203], [203, 204], [204, 205], [206, 216], [217, 220], [221, 229], [230, 239], [240, 245], [246, 256], [257, 262], [263, 269], [270, 271], [271, 275], [275, 276], [276, 280], [280, 281], [281, 282], [283, 293], [294, 299], [300, 305], [306, 308], [309, 315], [316, 321], [321, 325], [326, 327], [327, 331], [331, 332], [332, 336], [336, 337], [337, 338]]}
{"doc_key": "ai-dev-204", "ner": [[9, 9, "conference"], [11, 14, "conference"], [8, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 14, 9, 9, "named", "", false, false], [8, 17, 9, 9, "part-of", "", false, false], [8, 17, 9, 9, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Nel", "2016", "\u00e8", "stata", "selezionata", "come", "vincitrice", "del", "premio", "ACL", "(", "Association", "for", "Computational", "Linguistics", ")", "alla", "carriera", "."], "sentence-detokenized": "Nel 2016 \u00e8 stata selezionata come vincitrice del premio ACL (Association for Computational Linguistics) alla carriera.", "token2charspan": [[0, 3], [4, 8], [9, 10], [11, 16], [17, 28], [29, 33], [34, 44], [45, 48], [49, 55], [56, 59], [60, 61], [61, 72], [73, 76], [77, 90], [91, 102], [102, 103], [104, 108], [109, 117], [117, 118]]}
{"doc_key": "ai-dev-205", "ner": [[0, 1, "researcher"], [3, 5, "researcher"], [7, 9, "researcher"], [11, 12, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sepp", "Hochreiter", ",", "Y", ".", "Bengio", ",", "P", ".", "Frasconi", "e", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Sepp Hochreiter, Y. Bengio, P. Frasconi e J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 15], [15, 16], [17, 18], [18, 19], [20, 26], [26, 27], [28, 29], [29, 30], [31, 39], [40, 41], [42, 48], [49, 60], [60, 61]]}
{"doc_key": "ai-dev-206", "ner": [[3, 3, "product"], [6, 8, "misc"], [10, 10, "programlang"], [18, 20, "product"], [33, 33, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 10, 10, "usage", "", false, false], [10, 10, 6, 8, "type-of", "", false, false], [10, 10, 18, 20, "related-to", "", false, false], [33, 33, 3, 3, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Ad", "esempio", ",", "A.L.I.C.E.", "utilizza", "un", "linguaggio", "di", "markup", "chiamato", "AIML", ",", "specifico", "per", "la", "sua", "funzione", "di", "sistema", "di", "dialogo", ",", "che", "\u00e8", "stato", "poi", "adottato", "da", "vari", "altri", "sviluppatori", "dei", "cosiddetti", "Alicebot", "."], "sentence-detokenized": "Ad esempio, A.L.I.C.E. utilizza un linguaggio di markup chiamato AIML, specifico per la sua funzione di sistema di dialogo, che \u00e8 stato poi adottato da vari altri sviluppatori dei cosiddetti Alicebot.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 22], [23, 31], [32, 34], [35, 45], [46, 48], [49, 55], [56, 64], [65, 69], [69, 70], [71, 80], [81, 84], [85, 87], [88, 91], [92, 100], [101, 103], [104, 111], [112, 114], [115, 122], [122, 123], [124, 127], [128, 129], [130, 135], [136, 139], [140, 148], [149, 151], [152, 156], [157, 162], [163, 175], [176, 179], [180, 190], [191, 199], [199, 200]]}
{"doc_key": "ai-dev-207", "ner": [[7, 13, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Nel", "2000", "\u00e8", "stata", "eletta", "Fellow", "dell'", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "Nel 2000 \u00e8 stata eletta Fellow dell'Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 3], [4, 8], [9, 10], [11, 16], [17, 23], [24, 30], [31, 36], [36, 47], [48, 51], [52, 55], [56, 67], [68, 70], [71, 81], [82, 94], [94, 95]]}
{"doc_key": "ai-dev-208", "ner": [[0, 4, "misc"], [6, 6, "misc"], [12, 18, "misc"], [29, 30, "algorithm"], [41, 42, "field"], [45, 47, "field"], [50, 52, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 4, 12, 18, "type-of", "", false, false], [0, 4, 41, 42, "related-to", "performs", true, false], [0, 4, 45, 47, "related-to", "performs", true, false], [0, 4, 50, 52, "related-to", "performs", true, false], [6, 6, 0, 4, "named", "", false, false], [29, 30, 12, 18, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["I", "sistemi", "classificatori", "di", "apprendimento", "(", "LCS", ")", "sono", "una", "famiglia", "di", "algoritmi", "di", "apprendimento", "automatico", "basati", "su", "regole", "che", "combinano", "una", "componente", "di", "scoperta", ",", "in", "genere", "un", "algoritmo", "genetico", ",", "con", "una", "componente", "di", "apprendimento", ",", "che", "esegue", "l'", "apprendimento", "supervisionato", ",", "l'", "apprendimento", "con", "rinforzo", "o", "l'", "apprendimento", "non", "supervisionato", "."], "sentence-detokenized": "I sistemi classificatori di apprendimento (LCS) sono una famiglia di algoritmi di apprendimento automatico basati su regole che combinano una componente di scoperta, in genere un algoritmo genetico, con una componente di apprendimento, che esegue l'apprendimento supervisionato, l'apprendimento con rinforzo o l'apprendimento non supervisionato.", "token2charspan": [[0, 1], [2, 9], [10, 24], [25, 27], [28, 41], [42, 43], [43, 46], [46, 47], [48, 52], [53, 56], [57, 65], [66, 68], [69, 78], [79, 81], [82, 95], [96, 106], [107, 113], [114, 116], [117, 123], [124, 127], [128, 137], [138, 141], [142, 152], [153, 155], [156, 164], [164, 165], [166, 168], [169, 175], [176, 178], [179, 188], [189, 197], [197, 198], [199, 202], [203, 206], [207, 217], [218, 220], [221, 234], [234, 235], [236, 239], [240, 246], [247, 249], [249, 262], [263, 277], [277, 278], [279, 281], [281, 294], [295, 298], [299, 307], [308, 309], [310, 312], [312, 325], [326, 329], [330, 344], [344, 345]]}
{"doc_key": "ai-dev-209", "ner": [[15, 17, "algorithm"], [19, 19, "algorithm"], [27, 28, "algorithm"], [32, 33, "misc"], [43, 47, "algorithm"], [54, 59, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[15, 17, 27, 28, "origin", "", false, false], [15, 17, 32, 33, "usage", "", false, false], [19, 19, 15, 17, "named", "", false, false], [43, 47, 32, 33, "type-of", "", false, false], [43, 47, 54, 59, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["I", "parametri", "sconosciuti", "in", "ogni", "vettore", "\u03b2subk", "/", "sub", "sono", "tipicamente", "stimati", "congiuntamente", "mediante", "stima", "a", "posteriori", "massima", "(", "MAP", ")", ",", "che", "\u00e8", "un'", "estensione", "della", "massima", "verosimiglianza", "che", "utilizza", "una", "regolarizzazione", "dei", "pesi", "per", "evitare", "soluzioni", "patologiche", "(", "di", "solito", "una", "funzione", "di", "regolarizzazione", "al", "quadrato", ",", "che", "equivale", "a", "porre", "una", "distribuzione", "gaussiana", "prioritaria", "a", "media", "zero", "sui", "pesi", ",", "ma", "sono", "possibili", "anche", "altre", "distribuzioni", ")", "."], "sentence-detokenized": "I parametri sconosciuti in ogni vettore \u03b2subk / sub sono tipicamente stimati congiuntamente mediante stima a posteriori massima (MAP), che \u00e8 un'estensione della massima verosimiglianza che utilizza una regolarizzazione dei pesi per evitare soluzioni patologiche (di solito una funzione di regolarizzazione al quadrato, che equivale a porre una distribuzione gaussiana prioritaria a media zero sui pesi, ma sono possibili anche altre distribuzioni).", "token2charspan": [[0, 1], [2, 11], [12, 23], [24, 26], [27, 31], [32, 39], [40, 45], [46, 47], [48, 51], [52, 56], [57, 68], [69, 76], [77, 91], [92, 100], [101, 106], [107, 108], [109, 119], [120, 127], [128, 129], [129, 132], [132, 133], [133, 134], [135, 138], [139, 140], [141, 144], [144, 154], [155, 160], [161, 168], [169, 184], [185, 188], [189, 197], [198, 201], [202, 218], [219, 222], [223, 227], [228, 231], [232, 239], [240, 249], [250, 261], [262, 263], [263, 265], [266, 272], [273, 276], [277, 285], [286, 288], [289, 305], [306, 308], [309, 317], [317, 318], [319, 322], [323, 331], [332, 333], [334, 339], [340, 343], [344, 357], [358, 367], [368, 379], [380, 381], [382, 387], [388, 392], [393, 396], [397, 401], [401, 402], [403, 405], [406, 410], [411, 420], [421, 426], [427, 432], [433, 446], [446, 447], [447, 448]]}
{"doc_key": "ai-dev-210", "ner": [[12, 13, "researcher"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 10, 12, 13, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["La", "struttura", "gerarchica", "delle", "parole", "\u00e8", "stata", "mappata", "esplicitamente", "nella", "Wordnet", "di", "George", "Miller", "."], "sentence-detokenized": "La struttura gerarchica delle parole \u00e8 stata mappata esplicitamente nella Wordnet di George Miller.", "token2charspan": [[0, 2], [3, 12], [13, 23], [24, 29], [30, 36], [37, 38], [39, 44], [45, 52], [53, 67], [68, 73], [74, 81], [82, 84], [85, 91], [92, 98], [98, 99]]}
{"doc_key": "ai-dev-211", "ner": [[8, 13, "conference"], [21, 26, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[21, 26, 8, 13, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Un'", "illustrazione", "delle", "loro", "capacit\u00e0", "\u00e8", "data", "dall'", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", ";", "si", "tratta", "di", "un", "benchmark", "nella", "classificazione", "e", "nel", "rilevamento", "degli", "oggetti", ",", "con", "milioni", "di", "immagini", "e", "centinaia", "di", "classi", "di", "oggetti", "."], "sentence-detokenized": "Un'illustrazione delle loro capacit\u00e0 \u00e8 data dall'ImageNet Large Scale Visual Recognition Challenge; si tratta di un benchmark nella classificazione e nel rilevamento degli oggetti, con milioni di immagini e centinaia di classi di oggetti.", "token2charspan": [[0, 3], [3, 16], [17, 22], [23, 27], [28, 36], [37, 38], [39, 43], [44, 49], [49, 57], [58, 63], [64, 69], [70, 76], [77, 88], [89, 98], [98, 99], [100, 102], [103, 109], [110, 112], [113, 115], [116, 125], [126, 131], [132, 147], [148, 149], [150, 153], [154, 165], [166, 171], [172, 179], [179, 180], [181, 184], [185, 192], [193, 195], [196, 204], [205, 206], [207, 216], [217, 219], [220, 226], [227, 229], [230, 237], [237, 238]]}
{"doc_key": "ai-dev-212", "ner": [[1, 1, "misc"], [25, 25, "misc"], [34, 36, "person"], [29, 29, "misc"], [47, 49, "person"], [40, 42, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[25, 25, 1, 1, "general-affiliation", "", false, false], [29, 29, 1, 1, "general-affiliation", "", false, false], [29, 29, 34, 36, "artifact", "", false, false], [40, 42, 1, 1, "general-affiliation", "", false, false], [40, 42, 47, 49, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Nella", "fantascienza", ",", "i", "robot", "di", "aspetto", "femminile", "sono", "spesso", "prodotti", "per", "essere", "utilizzati", "come", "domestici", "e", "schiavi", "sessuali", ",", "come", "si", "vede", "nel", "film", "Westworld", ",", "nel", "romanzo", "Fairyland", "(", "1995", ")", "di", "Paul", "J.", "McAuley", "e", "nel", "racconto", "Helen", "O'", "Loy", "(", "1938", ")", "di", "Lester", "del", "Rey", ",", "e", "talvolta", "come", "guerrieri", ",", "assassini", "o", "lavoratori", "."], "sentence-detokenized": "Nella fantascienza, i robot di aspetto femminile sono spesso prodotti per essere utilizzati come domestici e schiavi sessuali, come si vede nel film Westworld, nel romanzo Fairyland (1995) di Paul J. McAuley e nel racconto Helen O'Loy (1938) di Lester del Rey, e talvolta come guerrieri, assassini o lavoratori.", "token2charspan": [[0, 5], [6, 18], [18, 19], [20, 21], [22, 27], [28, 30], [31, 38], [39, 48], [49, 53], [54, 60], [61, 69], [70, 73], [74, 80], [81, 91], [92, 96], [97, 106], [107, 108], [109, 116], [117, 125], [125, 126], [127, 131], [132, 134], [135, 139], [140, 143], [144, 148], [149, 158], [158, 159], [160, 163], [164, 171], [172, 181], [182, 183], [183, 187], [187, 188], [189, 191], [192, 196], [197, 199], [200, 207], [208, 209], [210, 213], [214, 222], [223, 228], [229, 231], [231, 234], [235, 236], [236, 240], [240, 241], [242, 244], [245, 251], [252, 255], [256, 259], [259, 260], [261, 262], [263, 271], [272, 276], [277, 286], [286, 287], [288, 297], [298, 299], [300, 310], [310, 311]]}
{"doc_key": "ai-dev-213", "ner": [[0, 2, "task"], [4, 5, "task"], [7, 8, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["risposta", "alle", "domande", ",", "riconoscimento", "vocale", "e", "traduzione", "automatica", "."], "sentence-detokenized": "risposta alle domande, riconoscimento vocale e traduzione automatica.", "token2charspan": [[0, 8], [9, 13], [14, 21], [21, 22], [23, 37], [38, 44], [45, 46], [47, 57], [58, 68], [68, 69]]}
{"doc_key": "ai-dev-214", "ner": [[5, 6, "researcher"], [8, 12, "organisation"], [14, 17, "location"], [20, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 8, 12, "role", "", false, false], [8, 12, 14, 17, "physical", "", false, false], [14, 17, 20, 20, "physical", "", false, false], [20, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Nel", "suo", "lavoro", "fondamentale", ",", "Harry", "Blum", "degli", "Air", "Force", "Cambridge", "Research", "Laboratories", "della", "base", "aerea", "di", "Hanscom", ",", "a", "Bedford", ",", "Massachusetts", ",", "ha", "definito", "un", "asse", "mediano", "per", "calcolare", "lo", "scheletro", "di", "una", "forma", ",", "utilizzando", "un", "modello", "intuitivo", "di", "propagazione", "del", "fuoco", "su", "un", "campo", "d'", "erba", ",", "dove", "il", "campo", "ha", "la", "forma", "della", "forma", "data", "."], "sentence-detokenized": "Nel suo lavoro fondamentale, Harry Blum degli Air Force Cambridge Research Laboratories della base aerea di Hanscom, a Bedford, Massachusetts, ha definito un asse mediano per calcolare lo scheletro di una forma, utilizzando un modello intuitivo di propagazione del fuoco su un campo d'erba, dove il campo ha la forma della forma data.", "token2charspan": [[0, 3], [4, 7], [8, 14], [15, 27], [27, 28], [29, 34], [35, 39], [40, 45], [46, 49], [50, 55], [56, 65], [66, 74], [75, 87], [88, 93], [94, 98], [99, 104], [105, 107], [108, 115], [115, 116], [117, 118], [119, 126], [126, 127], [128, 141], [141, 142], [143, 145], [146, 154], [155, 157], [158, 162], [163, 170], [171, 174], [175, 184], [185, 187], [188, 197], [198, 200], [201, 204], [205, 210], [210, 211], [212, 223], [224, 226], [227, 234], [235, 244], [245, 247], [248, 260], [261, 264], [265, 270], [271, 273], [274, 276], [277, 282], [283, 285], [285, 289], [289, 290], [291, 295], [296, 298], [299, 304], [305, 307], [308, 310], [311, 316], [317, 322], [323, 328], [329, 333], [333, 334]]}
{"doc_key": "ai-dev-215", "ner": [[20, 20, "algorithm"], [22, 22, "algorithm"], [25, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[20, 20, 25, 25, "compare", "", false, false], [22, 22, 25, 25, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Tuttavia", ",", "a", "differenza", "degli", "algoritmi", "di", "boosting", "che", "minimizzano", "analiticamente", "una", "funzione", "di", "perdita", "convessa", "(", "ad", "esempio", ",", "AdaBoost", "e", "LogitBoost", ")", ",", "BrownBoost", "risolve", "un", "sistema", "di", "due", "equazioni", "e", "due", "incognite", "utilizzando", "metodi", "numerici", "standard", "."], "sentence-detokenized": "Tuttavia, a differenza degli algoritmi di boosting che minimizzano analiticamente una funzione di perdita convessa (ad esempio, AdaBoost e LogitBoost), BrownBoost risolve un sistema di due equazioni e due incognite utilizzando metodi numerici standard.", "token2charspan": [[0, 8], [8, 9], [10, 11], [12, 22], [23, 28], [29, 38], [39, 41], [42, 50], [51, 54], [55, 66], [67, 81], [82, 85], [86, 94], [95, 97], [98, 105], [106, 114], [115, 116], [116, 118], [119, 126], [126, 127], [128, 136], [137, 138], [139, 149], [149, 150], [150, 151], [152, 162], [163, 170], [171, 173], [174, 181], [182, 184], [185, 188], [189, 198], [199, 200], [201, 204], [205, 214], [215, 226], [227, 233], [234, 242], [243, 251], [251, 252]]}
{"doc_key": "ai-dev-216", "ner": [[0, 0, "researcher"], [11, 13, "misc"], [17, 22, "conference"], [24, 24, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 11, 13, "win-defeat", "", false, false], [0, 0, 17, 22, "role", "", false, false], [24, 24, 17, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Getoor", "ha", "ricevuto", "diversi", "premi", "per", "i", "migliori", "lavori", ",", "un", "NSF", "Career", "Award", "ed", "\u00e8", "un", "Association", "for", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "Fellow", "."], "sentence-detokenized": "Getoor ha ricevuto diversi premi per i migliori lavori, un NSF Career Award ed \u00e8 un Association for Advancement of Artificial Intelligence (AAAI) Fellow.", "token2charspan": [[0, 6], [7, 9], [10, 18], [19, 26], [27, 32], [33, 36], [37, 38], [39, 47], [48, 54], [54, 55], [56, 58], [59, 62], [63, 69], [70, 75], [76, 78], [79, 80], [81, 83], [84, 95], [96, 99], [100, 111], [112, 114], [115, 125], [126, 138], [139, 140], [140, 144], [144, 145], [146, 152], [152, 153]]}
{"doc_key": "ai-dev-217", "ner": [[0, 1, "misc"], [6, 10, "misc"], [15, 16, "misc"], [21, 25, "misc"], [30, 31, "misc"], [35, 39, "university"], [44, 52, "misc"], [57, 65, "misc"], [70, 74, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["ACM", "Fellow", "(", "2015", ")", "br", "Association", "for", "Computational", "Linguistics", "Fellow", "(", "2011", ")", "br", "AAAI", "Fellow", "(", "1994", ")", "br", "International", "Speech", "Communication", "Association", "Fellow", "(", "2011", ")", "br", "Dottorato", "onorario", "(", "Hedersdoktor", ")", "KTH", "Royal", "Institute", "of", "Technology", "(", "2007", ")", "br", "Columbia", "Engineering", "School", "Alumni", "Association", "Distinguished", "Faculty", "Teaching", "award", "(", "2009", ")", "br", "IEEE", "James", "L.", "Flanagan", "Speech", "and", "Audio", "Processing", "Award", "(", "2011", ")", "br", "ISCA", "Medal", "for", "Scientific", "Achievement", "(", "2011", ")"], "sentence-detokenized": "ACM Fellow (2015) br Association for Computational Linguistics Fellow (2011) br AAAI Fellow (1994) br International Speech Communication Association Fellow (2011) br Dottorato onorario (Hedersdoktor) KTH Royal Institute of Technology (2007) br Columbia Engineering School Alumni Association Distinguished Faculty Teaching award (2009) br IEEE James L. Flanagan Speech and Audio Processing Award (2011) br ISCA Medal for Scientific Achievement (2011)", "token2charspan": [[0, 3], [4, 10], [11, 12], [12, 16], [16, 17], [18, 20], [21, 32], [33, 36], [37, 50], [51, 62], [63, 69], [70, 71], [71, 75], [75, 76], [77, 79], [80, 84], [85, 91], [92, 93], [93, 97], [97, 98], [99, 101], [102, 115], [116, 122], [123, 136], [137, 148], [149, 155], [156, 157], [157, 161], [161, 162], [163, 165], [166, 175], [176, 184], [185, 186], [186, 198], [198, 199], [200, 203], [204, 209], [210, 219], [220, 222], [223, 233], [234, 235], [235, 239], [239, 240], [241, 243], [244, 252], [253, 264], [265, 271], [272, 278], [279, 290], [291, 304], [305, 312], [313, 321], [322, 327], [328, 329], [329, 333], [333, 334], [335, 337], [338, 342], [343, 348], [349, 351], [352, 360], [361, 367], [368, 371], [372, 377], [378, 388], [389, 394], [395, 396], [396, 400], [400, 401], [402, 404], [405, 409], [410, 415], [416, 419], [420, 430], [431, 442], [443, 444], [444, 448], [448, 449]]}
{"doc_key": "ai-dev-218", "ner": [[7, 7, "university"], [16, 20, "task"], [41, 42, "metrics"], [33, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[41, 42, 33, 35, "opposite", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Un", "risultato", "frustrante", "dello", "stesso", "studio", "di", "Stanford", "(", "e", "di", "altri", "tentativi", "di", "migliorare", "la", "traduzione", "del", "riconoscimento", "dei", "nomi", ")", "\u00e8", "che", "spesso", "l'", "inclusione", "di", "metodi", "per", "la", "traduzione", "di", "entit\u00e0", "nominate", "comporta", "una", "diminuzione", "dei", "punteggi", "della", "valutazione", "bilingue", "."], "sentence-detokenized": "Un risultato frustrante dello stesso studio di Stanford (e di altri tentativi di migliorare la traduzione del riconoscimento dei nomi) \u00e8 che spesso l'inclusione di metodi per la traduzione di entit\u00e0 nominate comporta una diminuzione dei punteggi della valutazione bilingue.", "token2charspan": [[0, 2], [3, 12], [13, 23], [24, 29], [30, 36], [37, 43], [44, 46], [47, 55], [56, 57], [57, 58], [59, 61], [62, 67], [68, 77], [78, 80], [81, 91], [92, 94], [95, 105], [106, 109], [110, 124], [125, 128], [129, 133], [133, 134], [135, 136], [137, 140], [141, 147], [148, 150], [150, 160], [161, 163], [164, 170], [171, 174], [175, 177], [178, 188], [189, 191], [192, 198], [199, 207], [208, 216], [217, 220], [221, 232], [233, 236], [237, 245], [246, 251], [252, 263], [264, 272], [272, 273]]}
{"doc_key": "ai-dev-219", "ner": [[0, 0, "organisation"], [12, 14, "organisation"], [17, 21, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 12, 14, "role", "works_with", false, false], [0, 0, 17, 21, "role", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Medtronic", "utilizza", "i", "dati", "PM", "raccolti", "e", "collabora", "con", "i", "ricercatori", "del", "Johns", "Hopkins", "Hospital", "e", "della", "Washington", "University", "School", "of", "Medicine", "per", "contribuire", "a", "rispondere", "a", "domande", "specifiche", "sulle", "malattie", "cardiache", ",", "come", "ad", "esempio", "se", "i", "cuori", "deboli", "causano", "aritmie", "o", "viceversa", "."], "sentence-detokenized": "Medtronic utilizza i dati PM raccolti e collabora con i ricercatori del Johns Hopkins Hospital e della Washington University School of Medicine per contribuire a rispondere a domande specifiche sulle malattie cardiache, come ad esempio se i cuori deboli causano aritmie o viceversa.", "token2charspan": [[0, 9], [10, 18], [19, 20], [21, 25], [26, 28], [29, 37], [38, 39], [40, 49], [50, 53], [54, 55], [56, 67], [68, 71], [72, 77], [78, 85], [86, 94], [95, 96], [97, 102], [103, 113], [114, 124], [125, 131], [132, 134], [135, 143], [144, 147], [148, 159], [160, 161], [162, 172], [173, 174], [175, 182], [183, 193], [194, 199], [200, 208], [209, 218], [218, 219], [220, 224], [225, 227], [228, 235], [236, 238], [239, 240], [241, 246], [247, 253], [254, 261], [262, 269], [270, 271], [272, 281], [281, 282]]}
{"doc_key": "ai-dev-220", "ner": [[5, 5, "organisation"], [7, 7, "misc"], [9, 10, "person"], [12, 13, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 5, 5, "artifact", "made_by_studio", false, false], [9, 10, 7, 7, "role", "", false, false], [12, 13, 7, 7, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Segue", "il", "primo", "film", "della", "Paramount", ",", "Sangaree", "con", "Fernando", "Lamas", "e", "Arlene", "Dahl", "."], "sentence-detokenized": "Segue il primo film della Paramount, Sangaree con Fernando Lamas e Arlene Dahl.", "token2charspan": [[0, 5], [6, 8], [9, 14], [15, 19], [20, 25], [26, 35], [35, 36], [37, 45], [46, 49], [50, 58], [59, 64], [65, 66], [67, 73], [74, 78], [78, 79]]}
{"doc_key": "ai-dev-221", "ner": [[0, 0, "programlang"], [11, 13, "researcher"], [15, 16, "researcher"], [19, 20, "organisation"], [23, 24, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 11, 13, "origin", "", false, false], [0, 0, 15, 16, "origin", "", false, false], [11, 13, 19, 20, "physical", "", false, false], [11, 13, 19, 20, "role", "", false, false], [15, 16, 23, 24, "physical", "", false, false], [15, 16, 23, 24, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["KRL", "\u00e8", "un", "linguaggio", "di", "rappresentazione", "della", "conoscenza", ",", "sviluppato", "da", "Daniel", "G.", "Bobrow", "e", "Terry", "Winograd", "rispettivamente", "allo", "Xerox", "PARC", "e", "alla", "Stanford", "University", "."], "sentence-detokenized": "KRL \u00e8 un linguaggio di rappresentazione della conoscenza, sviluppato da Daniel G. Bobrow e Terry Winograd rispettivamente allo Xerox PARC e alla Stanford University.", "token2charspan": [[0, 3], [4, 5], [6, 8], [9, 19], [20, 22], [23, 39], [40, 45], [46, 56], [56, 57], [58, 68], [69, 71], [72, 78], [79, 81], [82, 88], [89, 90], [91, 96], [97, 105], [106, 121], [122, 126], [127, 132], [133, 137], [138, 139], [140, 144], [145, 153], [154, 164], [164, 165]]}
{"doc_key": "ai-dev-222", "ner": [[4, 11, "conference"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 22, "researcher"], [24, 27, "researcher"], [38, 41, "task"], [44, 47, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 11, 38, 41, "topic", "", true, false], [13, 14, 4, 11, "physical", "", false, false], [13, 14, 4, 11, "role", "", false, false], [13, 14, 4, 11, "temporal", "", false, false], [16, 17, 4, 11, "physical", "", false, false], [16, 17, 4, 11, "role", "", false, false], [16, 17, 4, 11, "temporal", "", false, false], [19, 22, 4, 11, "physical", "", false, false], [19, 22, 4, 11, "role", "", false, false], [19, 22, 4, 11, "temporal", "", false, false], [24, 27, 4, 11, "physical", "", false, false], [24, 27, 4, 11, "role", "", false, false], [24, 27, 4, 11, "temporal", "", false, false], [38, 41, 44, 47, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Nel", "2006", ",", "alla", "IEEE", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "Qiang", "Zhu", ",", "Shai", "Avidan", ",", "Mei", "-", "Chen", "Yeh", "e", "Kwang", "-", "Ting", "Cheng", "hanno", "presentato", "un", "algoritmo", "per", "accelerare", "in", "modo", "significativo", "il", "rilevamento", "di", "esseri", "umani", "utilizzando", "i", "metodi", "dei", "descrittori", "HOG."], "sentence-detokenized": "Nel 2006, alla IEEE Conference on Computer Vision and Pattern Recognition, Qiang Zhu, Shai Avidan, Mei-Chen Yeh e Kwang-Ting Cheng hanno presentato un algoritmo per accelerare in modo significativo il rilevamento di esseri umani utilizzando i metodi dei descrittori HOG.", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 14], [15, 19], [20, 30], [31, 33], [34, 42], [43, 49], [50, 53], [54, 61], [62, 73], [73, 74], [75, 80], [81, 84], [84, 85], [86, 90], [91, 97], [97, 98], [99, 102], [102, 103], [103, 107], [108, 111], [112, 113], [114, 119], [119, 120], [120, 124], [125, 130], [131, 136], [137, 147], [148, 150], [151, 160], [161, 164], [165, 175], [176, 178], [179, 183], [184, 197], [198, 200], [201, 212], [213, 215], [216, 222], [223, 228], [229, 240], [241, 242], [243, 249], [250, 253], [254, 265], [266, 270]]}
{"doc_key": "ai-dev-223", "ner": [[0, 0, "researcher"], [5, 5, "conference"], [8, 10, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 5, 5, "role", "", false, false], [0, 0, 8, 10, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hayes", "\u00e8", "socio", "fondatore", "dell'", "AAAI", "e", "della", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Hayes \u00e8 socio fondatore dell'AAAI e della Cognitive Science Society.", "token2charspan": [[0, 5], [6, 7], [8, 13], [14, 23], [24, 29], [29, 33], [34, 35], [36, 41], [42, 51], [52, 59], [60, 67], [67, 68]]}
{"doc_key": "ai-dev-224", "ner": [[0, 2, "misc"], [6, 6, "field"], [9, 11, "field"], [14, 16, "field"], [19, 19, "field"], [22, 23, "field"], [26, 27, "field"], [30, 32, "field"], [35, 35, "field"], [38, 40, "field"], [43, 43, "field"], [46, 48, "field"], [59, 60, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[0, 2, 6, 6, "part-of", "", false, false], [0, 2, 6, 6, "usage", "", false, false], [0, 2, 9, 11, "part-of", "", false, false], [0, 2, 9, 11, "usage", "", false, false], [0, 2, 14, 16, "part-of", "", false, false], [0, 2, 14, 16, "usage", "", false, false], [0, 2, 19, 19, "part-of", "", false, false], [0, 2, 19, 19, "usage", "", false, false], [0, 2, 22, 23, "part-of", "", false, false], [0, 2, 22, 23, "usage", "", false, false], [0, 2, 26, 27, "part-of", "", false, false], [0, 2, 26, 27, "usage", "", false, false], [0, 2, 30, 32, "part-of", "", false, false], [0, 2, 30, 32, "usage", "", false, false], [0, 2, 35, 35, "part-of", "", false, false], [0, 2, 35, 35, "usage", "", false, false], [0, 2, 38, 40, "part-of", "", false, false], [0, 2, 38, 40, "usage", "", false, false], [0, 2, 43, 43, "part-of", "", false, false], [0, 2, 43, 43, "usage", "", false, false], [0, 2, 46, 48, "part-of", "", false, false], [0, 2, 46, 48, "usage", "", false, false], [0, 2, 59, 60, "part-of", "", false, false], [0, 2, 59, 60, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "sentence": ["Le", "serie", "temporali", "sono", "utilizzate", "nella", "statistica", ",", "nell'", "elaborazione", "dei", "segnali", ",", "nel", "riconoscimento", "dei", "modelli", ",", "nell'", "econometria", ",", "nella", "finanza", "matematica", ",", "nelle", "previsioni", "meteorologiche", ",", "nella", "previsione", "dei", "terremoti", ",", "nell'", "elettroencefalografia", ",", "nell'", "ingegneria", "del", "controllo", ",", "nell'", "astronomia", ",", "nell'", "ingegneria", "delle", "comunicazioni", "e", ",", "in", "generale", ",", "in", "tutti", "i", "settori", "della", "scienza", "applicata", "e", "dell'", "ingegneria", "che", "prevedono", "misurazioni", "temporali", "."], "sentence-detokenized": "Le serie temporali sono utilizzate nella statistica, nell'elaborazione dei segnali, nel riconoscimento dei modelli, nell'econometria, nella finanza matematica, nelle previsioni meteorologiche, nella previsione dei terremoti, nell'elettroencefalografia, nell'ingegneria del controllo, nell'astronomia, nell'ingegneria delle comunicazioni e, in generale, in tutti i settori della scienza applicata e dell'ingegneria che prevedono misurazioni temporali.", "token2charspan": [[0, 2], [3, 8], [9, 18], [19, 23], [24, 34], [35, 40], [41, 51], [51, 52], [53, 58], [58, 70], [71, 74], [75, 82], [82, 83], [84, 87], [88, 102], [103, 106], [107, 114], [114, 115], [116, 121], [121, 132], [132, 133], [134, 139], [140, 147], [148, 158], [158, 159], [160, 165], [166, 176], [177, 191], [191, 192], [193, 198], [199, 209], [210, 213], [214, 223], [223, 224], [225, 230], [230, 251], [251, 252], [253, 258], [258, 268], [269, 272], [273, 282], [282, 283], [284, 289], [289, 299], [299, 300], [301, 306], [306, 316], [317, 322], [323, 336], [337, 338], [338, 339], [340, 342], [343, 351], [351, 352], [353, 355], [356, 361], [362, 363], [364, 371], [372, 377], [378, 385], [386, 395], [396, 397], [398, 403], [403, 413], [414, 417], [418, 427], [428, 439], [440, 449], [449, 450]]}
{"doc_key": "ai-dev-225", "ner": [[18, 19, "metrics"], [42, 44, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "linea", "di", "principio", ",", "il", "recupero", "esatto", "pu\u00f2", "essere", "risolto", "nel", "suo", "intervallo", "di", "fattibilit\u00e0", "utilizzando", "la", "massima", "verosimiglianza", ",", "ma", "ci\u00f2", "equivale", "a", "risolvere", "un", "problema", "di", "taglio", "vincolato", "o", "regolarizzato", ",", "come", "la", "bisezione", "minima", ",", "che", "\u00e8", "tipicamente", "NP", "-", "completo", "."], "sentence-detokenized": "In linea di principio, il recupero esatto pu\u00f2 essere risolto nel suo intervallo di fattibilit\u00e0 utilizzando la massima verosimiglianza, ma ci\u00f2 equivale a risolvere un problema di taglio vincolato o regolarizzato, come la bisezione minima, che \u00e8 tipicamente NP-completo.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 21], [21, 22], [23, 25], [26, 34], [35, 41], [42, 45], [46, 52], [53, 60], [61, 64], [65, 68], [69, 79], [80, 82], [83, 94], [95, 106], [107, 109], [110, 117], [118, 133], [133, 134], [135, 137], [138, 141], [142, 150], [151, 152], [153, 162], [163, 165], [166, 174], [175, 177], [178, 184], [185, 194], [195, 196], [197, 210], [210, 211], [212, 216], [217, 219], [220, 229], [230, 236], [236, 237], [238, 241], [242, 243], [244, 255], [256, 258], [258, 259], [259, 267], [267, 268]]}
{"doc_key": "ai-dev-226", "ner": [[4, 6, "task"], [14, 14, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 14, 4, 6, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["nel", "loro", "lavoro", "di", "rilevamento", "dei", "pedoni", ",", "descritto", "per", "la", "prima", "volta", "al", "BMVC", "nel", "2009", "."], "sentence-detokenized": "nel loro lavoro di rilevamento dei pedoni, descritto per la prima volta al BMVC nel 2009.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 18], [19, 30], [31, 34], [35, 41], [41, 42], [43, 52], [53, 56], [57, 59], [60, 65], [66, 71], [72, 74], [75, 79], [80, 83], [84, 88], [88, 89]]}
{"doc_key": "ai-dev-227", "ner": [[6, 10, "conference"], [12, 13, "researcher"], [17, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 13, 6, 10, "physical", "", false, false], [12, 13, 6, 10, "role", "", false, false], [12, 13, 17, 24, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Nel", "2007", ",", "in", "occasione", "della", "Conferenza", "internazionale", "sulla", "visione", "artificiale", ",", "Terzopoulos", "ha", "ricevuto", "il", "premio", "inaugurale", "IEEE", "PAMI", "Computer", "Vision", "Distinguished", "Researcher", "Award", "per", "la", "ricerca", "pionieristica", "e", "sostenuta", "sui", "modelli", "deformabili", "e", "le", "loro", "applicazioni", "."], "sentence-detokenized": "Nel 2007, in occasione della Conferenza internazionale sulla visione artificiale, Terzopoulos ha ricevuto il premio inaugurale IEEE PAMI Computer Vision Distinguished Researcher Award per la ricerca pionieristica e sostenuta sui modelli deformabili e le loro applicazioni.", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 12], [13, 22], [23, 28], [29, 39], [40, 54], [55, 60], [61, 68], [69, 80], [80, 81], [82, 93], [94, 96], [97, 105], [106, 108], [109, 115], [116, 126], [127, 131], [132, 136], [137, 145], [146, 152], [153, 166], [167, 177], [178, 183], [184, 187], [188, 190], [191, 198], [199, 212], [213, 214], [215, 224], [225, 228], [229, 236], [237, 248], [249, 250], [251, 253], [254, 258], [259, 271], [271, 272]]}
{"doc_key": "ai-dev-228", "ner": [[0, 3, "task"], [5, 6, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 5, 6, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["L'", "analisi", "dei", "cluster", "o", "cluster", "analysis", "consiste", "nell'", "assegnare", "i", "punti", "di", "dati", "ai", "cluster", "in", "modo", "che", "gli", "elementi", "dello", "stesso", "cluster", "siano", "il", "pi\u00f9", "possibile", "simili", ",", "mentre", "gli", "elementi", "appartenenti", "a", "cluster", "diversi", "siano", "il", "pi\u00f9", "possibile", "dissimili", "."], "sentence-detokenized": "L'analisi dei cluster o cluster analysis consiste nell'assegnare i punti di dati ai cluster in modo che gli elementi dello stesso cluster siano il pi\u00f9 possibile simili, mentre gli elementi appartenenti a cluster diversi siano il pi\u00f9 possibile dissimili.", "token2charspan": [[0, 2], [2, 9], [10, 13], [14, 21], [22, 23], [24, 31], [32, 40], [41, 49], [50, 55], [55, 64], [65, 66], [67, 72], [73, 75], [76, 80], [81, 83], [84, 91], [92, 94], [95, 99], [100, 103], [104, 107], [108, 116], [117, 122], [123, 129], [130, 137], [138, 143], [144, 146], [147, 150], [151, 160], [161, 167], [167, 168], [169, 175], [176, 179], [180, 188], [189, 201], [202, 203], [204, 211], [212, 219], [220, 225], [226, 228], [229, 232], [233, 242], [243, 252], [252, 253]]}
{"doc_key": "ai-dev-229", "ner": [[9, 10, "field"], [14, 15, "field"], [17, 19, "task"], [22, 23, "field"], [26, 27, "field"], [30, 31, "field"], [35, 36, "field"], [38, 39, "task"], [41, 41, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[9, 10, 14, 15, "named", "", false, false], [9, 10, 22, 23, "named", "", false, false], [9, 10, 30, 31, "named", "", false, false], [17, 19, 14, 15, "part-of", "task_part_of_field", false, false], [26, 27, 22, 23, "part-of", "", false, false], [35, 36, 30, 31, "part-of", "", false, false], [38, 39, 35, 36, "part-of", "", false, false], [41, 41, 35, 36, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["(", "2005", ")", "possiamo", "distinguere", "tre", "diverse", "prospettive", "di", "text", "mining", ",", "ovvero", "il", "text", "mining", "come", "estrazione", "di", "informazioni", ",", "il", "text", "mining", "come", "text", "data", "mining", "e", "il", "text", "mining", "come", "processo", "di", "Data", "mining", "(", "Knowledge", "Discovery", "in", "Databases", ")", ".Hotho", ",", "A", ".", ",", "N\u00fcrnberger", ",", "A.", "e", "Paa\u00df", ",", "G.", "(", "2005", ")", "."], "sentence-detokenized": "(2005) possiamo distinguere tre diverse prospettive di text mining, ovvero il text mining come estrazione di informazioni, il text mining come text data mining e il text mining come processo di Data mining (Knowledge Discovery in Databases).Hotho, A., N\u00fcrnberger, A. e Paa\u00df, G. (2005).", "token2charspan": [[0, 1], [1, 5], [5, 6], [7, 15], [16, 27], [28, 31], [32, 39], [40, 51], [52, 54], [55, 59], [60, 66], [66, 67], [68, 74], [75, 77], [78, 82], [83, 89], [90, 94], [95, 105], [106, 108], [109, 121], [121, 122], [123, 125], [126, 130], [131, 137], [138, 142], [143, 147], [148, 152], [153, 159], [160, 161], [162, 164], [165, 169], [170, 176], [177, 181], [182, 190], [191, 193], [194, 198], [199, 205], [206, 207], [207, 216], [217, 226], [227, 229], [230, 239], [239, 240], [240, 246], [246, 247], [248, 249], [249, 250], [250, 251], [252, 262], [262, 263], [264, 266], [267, 268], [269, 273], [273, 274], [275, 277], [278, 279], [279, 283], [283, 284], [284, 285]]}
{"doc_key": "ai-dev-230", "ner": [[1, 2, "product"], [15, 20, "location"], [22, 22, "location"], [25, 25, "location"], [36, 37, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 15, 20, "related-to", "developed_for", false, false], [15, 20, 22, 22, "physical", "", false, false], [22, 22, 25, 25, "physical", "", false, false], [36, 37, 1, 2, "role", "buys", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Il", "Rancho", "Arm", "\u00e8", "stato", "sviluppato", "come", "braccio", "robotico", "per", "aiutare", "i", "pazienti", "disabili", "del", "Rancho", "Los", "Amigos", "National", "Rehabilitation", "Center", "di", "Downey", ",", "in", "California", ";", "questo", "braccio", "controllato", "da", "computer", "\u00e8", "stato", "acquistato", "dalla", "Stanford", "University", "nel", "1963", "."], "sentence-detokenized": "Il Rancho Arm \u00e8 stato sviluppato come braccio robotico per aiutare i pazienti disabili del Rancho Los Amigos National Rehabilitation Center di Downey, in California; questo braccio controllato da computer \u00e8 stato acquistato dalla Stanford University nel 1963.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 15], [16, 21], [22, 32], [33, 37], [38, 45], [46, 54], [55, 58], [59, 66], [67, 68], [69, 77], [78, 86], [87, 90], [91, 97], [98, 101], [102, 108], [109, 117], [118, 132], [133, 139], [140, 142], [143, 149], [149, 150], [151, 153], [154, 164], [164, 165], [166, 172], [173, 180], [181, 192], [193, 195], [196, 204], [205, 206], [207, 212], [213, 223], [224, 229], [230, 238], [239, 249], [250, 253], [254, 258], [258, 259]]}
{"doc_key": "ai-dev-231", "ner": [[1, 1, "university"], [3, 4, "researcher"], [9, 13, "organisation"], [19, 21, "organisation"], [25, 26, "researcher"], [28, 30, "researcher"], [44, 45, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 4, 1, 1, "physical", "", false, false], [3, 4, 1, 1, "role", "", false, false], [3, 4, 9, 13, "role", "founder", false, false], [3, 4, 19, 21, "role", "founder", false, false], [19, 21, 44, 45, "physical", "", false, false], [25, 26, 19, 21, "role", "founder", false, false], [28, 30, 19, 21, "role", "founder", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["All'", "UCSD", ",", "Norman", "\u00e8", "stato", "uno", "dei", "fondatori", "dell'", "Institute", "for", "Cognitive", "Science", "e", "uno", "degli", "organizzatori", "della", "Cognitive", "Science", "Society", "(", "insieme", "a", "Roger", "Schank", ",", "Allan", "M.", "Collins", "e", "altri", ")", ",", "che", "ha", "tenuto", "la", "sua", "prima", "riunione", "nel", "campus", "dell'", "UCSD", "nel", "1979", "."], "sentence-detokenized": "All'UCSD, Norman \u00e8 stato uno dei fondatori dell'Institute for Cognitive Science e uno degli organizzatori della Cognitive Science Society (insieme a Roger Schank, Allan M. Collins e altri), che ha tenuto la sua prima riunione nel campus dell'UCSD nel 1979.", "token2charspan": [[0, 4], [4, 8], [8, 9], [10, 16], [17, 18], [19, 24], [25, 28], [29, 32], [33, 42], [43, 48], [48, 57], [58, 61], [62, 71], [72, 79], [80, 81], [82, 85], [86, 91], [92, 105], [106, 111], [112, 121], [122, 129], [130, 137], [138, 139], [139, 146], [147, 148], [149, 154], [155, 161], [161, 162], [163, 168], [169, 171], [172, 179], [180, 181], [182, 187], [187, 188], [188, 189], [190, 193], [194, 196], [197, 203], [204, 206], [207, 210], [211, 216], [217, 225], [226, 229], [230, 236], [237, 242], [242, 246], [247, 250], [251, 255], [255, 256]]}
{"doc_key": "ai-dev-232", "ner": [[7, 8, "product"], [11, 12, "product"], [15, 17, "product"], [20, 23, "product"], [25, 27, "product"], [29, 34, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[25, 27, 20, 23, "type-of", "", false, false], [29, 34, 20, 23, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Le", "configurazioni", "robotiche", "pi\u00f9", "utilizzate", "sono", "i", "robot", "articolati", ",", "i", "robot", "SCARA", ",", "i", "robot", "a", "delta", "e", "i", "robot", "a", "coordinate", "cartesiane", "(", "robot", "a", "portale", "o", "robot", "x", "-", "y", "-", "z", ")", "."], "sentence-detokenized": "Le configurazioni robotiche pi\u00f9 utilizzate sono i robot articolati, i robot SCARA, i robot a delta e i robot a coordinate cartesiane (robot a portale o robot x-y-z).", "token2charspan": [[0, 2], [3, 17], [18, 27], [28, 31], [32, 42], [43, 47], [48, 49], [50, 55], [56, 66], [66, 67], [68, 69], [70, 75], [76, 81], [81, 82], [83, 84], [85, 90], [91, 92], [93, 98], [99, 100], [101, 102], [103, 108], [109, 110], [111, 121], [122, 132], [133, 134], [134, 139], [140, 141], [142, 149], [150, 151], [152, 157], [158, 159], [159, 160], [160, 161], [161, 162], [162, 163], [163, 164], [164, 165]]}
{"doc_key": "ai-dev-233", "ner": [[10, 10, "programlang"], [9, 11, "misc"], [16, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 11, 10, 10, "part-of", "", false, false], [16, 16, 9, 11, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "alternativa", ",", "pu\u00f2", "essere", "utilizzato", "direttamente", "con", "il", "modulo", "Perl", "TM", "(", "che", "supporta", "anche", "LTM", ")", "."], "sentence-detokenized": "In alternativa, pu\u00f2 essere utilizzato direttamente con il modulo Perl TM (che supporta anche LTM).", "token2charspan": [[0, 2], [3, 14], [14, 15], [16, 19], [20, 26], [27, 37], [38, 50], [51, 54], [55, 57], [58, 64], [65, 69], [70, 72], [73, 74], [74, 77], [78, 86], [87, 92], [93, 96], [96, 97], [97, 98]]}
{"doc_key": "ai-dev-234", "ner": [[8, 8, "country"], [10, 11, "organisation"], [17, 17, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 8, 8, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Il", "concorso", "\u00e8", "stato", "vinto", "da", "un", "team", "statunitense", "dei", "laboratori", "Newton", "ed", "\u00e8", "stato", "trasmesso", "dalla", "CNN."], "sentence-detokenized": "Il concorso \u00e8 stato vinto da un team statunitense dei laboratori Newton ed \u00e8 stato trasmesso dalla CNN.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 19], [20, 25], [26, 28], [29, 31], [32, 36], [37, 49], [50, 53], [54, 64], [65, 71], [72, 74], [75, 76], [77, 82], [83, 92], [93, 98], [99, 103]]}
{"doc_key": "ai-dev-235", "ner": [[0, 4, "misc"], [10, 11, "person"], [15, 16, "person"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 11, 0, 4, "role", "directs", false, false], [15, 16, 0, 4, "role", "acts_in", false, false], [18, 19, 0, 4, "role", "acts_in", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Butler", "'s", "in", "Love", ",", "un", "cortometraggio", "diretto", "da", "David", "Arquette", "e", "interpretato", "da", "Elizabeth", "Berkley", "e", "Thomas", "Jane", ",", "\u00e8", "uscito", "il", "23", "giugno", "2008", "."], "sentence-detokenized": "The Butler's in Love, un cortometraggio diretto da David Arquette e interpretato da Elizabeth Berkley e Thomas Jane, \u00e8 uscito il 23 giugno 2008.", "token2charspan": [[0, 3], [4, 10], [10, 12], [13, 15], [16, 20], [20, 21], [22, 24], [25, 39], [40, 47], [48, 50], [51, 56], [57, 65], [66, 67], [68, 80], [81, 83], [84, 93], [94, 101], [102, 103], [104, 110], [111, 115], [115, 116], [117, 118], [119, 125], [126, 128], [129, 131], [132, 138], [139, 143], [143, 144]]}
{"doc_key": "ai-dev-236", "ner": [[3, 3, "product"], [10, 10, "field"], [20, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 20, 20, "general-affiliation", "", false, false], [10, 10, 3, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Ad", "esempio", ",", "WordNet", "\u00e8", "una", "risorsa", "che", "comprende", "una", "tassonomia", ",", "i", "cui", "elementi", "sono", "i", "significati", "delle", "parole", "inglesi", "."], "sentence-detokenized": "Ad esempio, WordNet \u00e8 una risorsa che comprende una tassonomia, i cui elementi sono i significati delle parole inglesi.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 19], [20, 21], [22, 25], [26, 33], [34, 37], [38, 47], [48, 51], [52, 62], [62, 63], [64, 65], [66, 69], [70, 78], [79, 83], [84, 85], [86, 97], [98, 103], [104, 110], [111, 118], [118, 119]]}
{"doc_key": "ai-dev-237", "ner": [[0, 3, "product"], [7, 7, "product"], [9, 9, "product"], [17, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 0, 3, "type-of", "", false, false], [7, 7, 17, 17, "related-to", "ability_to", false, false], [9, 9, 0, 3, "type-of", "", false, false], [9, 9, 17, 17, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["I", "sistemi", "robotici", "umanoidi", "esistenti", ",", "come", "ASIMO", "e", "QRIO", ",", "utilizzano", "molti", "motori", "per", "ottenere", "la", "locomozione", "."], "sentence-detokenized": "I sistemi robotici umanoidi esistenti, come ASIMO e QRIO, utilizzano molti motori per ottenere la locomozione.", "token2charspan": [[0, 1], [2, 9], [10, 18], [19, 27], [28, 37], [37, 38], [39, 43], [44, 49], [50, 51], [52, 56], [56, 57], [58, 68], [69, 74], [75, 81], [82, 85], [86, 94], [95, 97], [98, 109], [109, 110]]}
{"doc_key": "ai-dev-238", "ner": [[0, 0, "metrics"], [8, 10, "metrics"], [12, 12, "metrics"], [14, 22, "misc"], [24, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 10, 0, 0, "part-of", "", false, false], [12, 12, 0, 0, "part-of", "", false, false], [14, 22, 0, 0, "part-of", "", false, false], [24, 24, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LEPOR", "\u00e8", "stato", "progettato", "con", "i", "fattori", "di", "penalizzazione", "della", "lunghezza", ",", "precisione", ",", "penalizzazione", "dell'", "ordine", "delle", "parole", "di", "n", "-", "grammi", "e", "richiamo", "."], "sentence-detokenized": "LEPOR \u00e8 stato progettato con i fattori di penalizzazione della lunghezza, precisione, penalizzazione dell'ordine delle parole di n-grammi e richiamo.", "token2charspan": [[0, 5], [6, 7], [8, 13], [14, 24], [25, 28], [29, 30], [31, 38], [39, 41], [42, 56], [57, 62], [63, 72], [72, 73], [74, 84], [84, 85], [86, 100], [101, 106], [106, 112], [113, 118], [119, 125], [126, 128], [129, 130], [130, 131], [131, 137], [138, 139], [140, 148], [148, 149]]}
{"doc_key": "ai-dev-239", "ner": [[3, 6, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Si", "basa", "sulla", "metrica", "di", "valutazione", "bilingue", ",", "ma", "con", "alcune", "modifiche", "."], "sentence-detokenized": "Si basa sulla metrica di valutazione bilingue, ma con alcune modifiche.", "token2charspan": [[0, 2], [3, 7], [8, 13], [14, 21], [22, 24], [25, 36], [37, 45], [45, 46], [47, 49], [50, 53], [54, 60], [61, 70], [70, 71]]}
{"doc_key": "ai-dev-240", "ner": [[7, 7, "product"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Questo", "\u00e8", "un", "esempio", "di", "implementazione", "in", "MATLAB", "/", "Octave", ":"], "sentence-detokenized": "Questo \u00e8 un esempio di implementazione in MATLAB / Octave:", "token2charspan": [[0, 6], [7, 8], [9, 11], [12, 19], [20, 22], [23, 38], [39, 41], [42, 48], [49, 50], [51, 57], [57, 58]]}
{"doc_key": "ai-dev-241", "ner": [[13, 13, "programlang"], [15, 15, "programlang"], [17, 17, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["\u00c8", "stato", "progettato", "per", "essere", "utilizzato", "con", "diversi", "linguaggi", "informatici", ",", "tra", "cui", "Python", ",", "Ruby", "e", "Scheme", "."], "sentence-detokenized": "\u00c8 stato progettato per essere utilizzato con diversi linguaggi informatici, tra cui Python, Ruby e Scheme.", "token2charspan": [[0, 1], [2, 7], [8, 18], [19, 22], [23, 29], [30, 40], [41, 44], [45, 52], [53, 62], [63, 74], [74, 75], [76, 79], [80, 83], [84, 90], [90, 91], [92, 96], [97, 98], [99, 105], [105, 106]]}
{"doc_key": "ai-dev-242", "ner": [[0, 0, "researcher"], [4, 5, "organisation"], [11, 11, "conference"], [16, 17, "academicjournal"], [21, 23, "organisation"], [27, 31, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 4, 5, "role", "", false, false], [0, 0, 11, 11, "role", "", false, false], [0, 0, 16, 17, "role", "", false, false], [0, 0, 21, 23, "role", "", false, false], [0, 0, 27, 31, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hayes", "\u00e8", "stato", "segretario", "dell'", "AISB", ",", "presidente", "e", "fiduciario", "dell'", "IJCAI", ",", "editore", "associato", "di", "Artificial", "Intelligence", ",", "governatore", "della", "Cognitive", "Science", "Society", "e", "presidente", "dell'", "American", "Association", "for", "Artificial", "Intelligence", "."], "sentence-detokenized": "Hayes \u00e8 stato segretario dell'AISB, presidente e fiduciario dell'IJCAI, editore associato di Artificial Intelligence, governatore della Cognitive Science Society e presidente dell'American Association for Artificial Intelligence.", "token2charspan": [[0, 5], [6, 7], [8, 13], [14, 24], [25, 30], [30, 34], [34, 35], [36, 46], [47, 48], [49, 59], [60, 65], [65, 70], [70, 71], [72, 79], [80, 89], [90, 92], [93, 103], [104, 116], [116, 117], [118, 129], [130, 135], [136, 145], [146, 153], [154, 161], [162, 163], [164, 174], [175, 180], [180, 188], [189, 200], [201, 204], [205, 215], [216, 228], [228, 229]]}
{"doc_key": "ai-dev-243", "ner": [[4, 14, "misc"], [16, 18, "misc"], [24, 25, "person"], [30, 34, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[24, 25, 4, 14, "role", "directed_by", false, false], [24, 25, 16, 18, "role", "directed_by", false, false], [24, 25, 30, 34, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Due", "di", "questi", ",", "Now", "is", "the", "Time", "(", "to", "Put", "On", "Your", "Glasses", ")", "e", "Around", "is", "Around", ",", "sono", "stati", "diretti", "da", "Norman", "McLaren", "nel", "1951", "per", "il", "National", "Film", "Board", "of", "Canada", "."], "sentence-detokenized": "Due di questi, Now is the Time (to Put On Your Glasses) e Around is Around, sono stati diretti da Norman McLaren nel 1951 per il National Film Board of Canada.", "token2charspan": [[0, 3], [4, 6], [7, 13], [13, 14], [15, 18], [19, 21], [22, 25], [26, 30], [31, 32], [32, 34], [35, 38], [39, 41], [42, 46], [47, 54], [54, 55], [56, 57], [58, 64], [65, 67], [68, 74], [74, 75], [76, 80], [81, 86], [87, 94], [95, 97], [98, 104], [105, 112], [113, 116], [117, 121], [122, 125], [126, 128], [129, 137], [138, 142], [143, 148], [149, 151], [152, 158], [158, 159]]}
{"doc_key": "ai-dev-244", "ner": [[1, 3, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Un", "sistema", "di", "raccomandazione", "ha", "lo", "scopo", "di", "prevedere", "la", "preferenza", "per", "un", "articolo", "di", "un", "utente", "target."], "sentence-detokenized": "Un sistema di raccomandazione ha lo scopo di prevedere la preferenza per un articolo di un utente target.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 29], [30, 32], [33, 35], [36, 41], [42, 44], [45, 54], [55, 57], [58, 68], [69, 72], [73, 75], [76, 84], [85, 87], [88, 90], [91, 97], [98, 105]]}
{"doc_key": "ai-dev-245", "ner": [[0, 1, "algorithm"], [7, 7, "field"], [10, 10, "field"], [13, 14, "field"], [17, 20, "field"], [23, 25, "field"], [27, 28, "field"], [31, 31, "field"], [34, 35, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 1, 7, 7, "part-of", "", true, false], [0, 1, 10, 10, "part-of", "", true, false], [0, 1, 13, 14, "part-of", "", true, false], [0, 1, 17, 20, "part-of", "", true, false], [0, 1, 23, 25, "part-of", "", true, false], [0, 1, 27, 28, "part-of", "", true, false], [0, 1, 31, 31, "part-of", "", true, false], [0, 1, 34, 35, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["La", "convoluzione", "ha", "applicazioni", "che", "includono", "la", "probabilit\u00e0", ",", "la", "statistica", ",", "la", "computer", "vision", ",", "l'", "elaborazione", "del", "linguaggio", "naturale", ",", "l'", "elaborazione", "delle", "immagini", "e", "dei", "segnali", ",", "l'", "ingegneria", "e", "le", "equazioni", "differenziali", "."], "sentence-detokenized": "La convoluzione ha applicazioni che includono la probabilit\u00e0, la statistica, la computer vision, l'elaborazione del linguaggio naturale, l'elaborazione delle immagini e dei segnali, l'ingegneria e le equazioni differenziali.", "token2charspan": [[0, 2], [3, 15], [16, 18], [19, 31], [32, 35], [36, 45], [46, 48], [49, 60], [60, 61], [62, 64], [65, 75], [75, 76], [77, 79], [80, 88], [89, 95], [95, 96], [97, 99], [99, 111], [112, 115], [116, 126], [127, 135], [135, 136], [137, 139], [139, 151], [152, 157], [158, 166], [167, 168], [169, 172], [173, 180], [180, 181], [182, 184], [184, 194], [195, 196], [197, 199], [200, 209], [210, 223], [223, 224]]}
{"doc_key": "ai-dev-246", "ner": [[3, 3, "field"], [6, 9, "task"], [12, 13, "task"], [17, 17, "task"], [18, 19, "task"], [16, 16, "task"], [22, 23, "task"], [26, 28, "task"], [31, 32, "task"], [35, 36, "task"], [39, 40, "task"], [43, 43, "field"], [46, 46, "field"], [49, 52, "field"], [55, 55, "field"], [58, 58, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[3, 3, 6, 9, "part-of", "", true, false], [3, 3, 12, 13, "part-of", "", true, false], [3, 3, 17, 17, "part-of", "", true, false], [3, 3, 18, 19, "part-of", "", true, false], [3, 3, 16, 16, "part-of", "", true, false], [3, 3, 22, 23, "part-of", "", true, false], [3, 3, 26, 28, "part-of", "", true, false], [3, 3, 31, 32, "part-of", "", true, false], [3, 3, 35, 36, "part-of", "", true, false], [3, 3, 39, 40, "part-of", "", true, false], [3, 3, 43, 43, "part-of", "", true, false], [3, 3, 46, 46, "part-of", "", true, false], [3, 3, 49, 52, "part-of", "", true, false], [3, 3, 55, 55, "part-of", "", true, false], [3, 3, 58, 58, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Le", "applicazioni", "del", "DSP", "comprendono", "l'", "elaborazione", "del", "segnale", "audio", ",", "la", "compressione", "audio", ",", "l'", "elaborazione", "digitale", "delle", "immagini", ",", "la", "compressione", "video", ",", "l'", "elaborazione", "del", "parlato", ",", "il", "riconoscimento", "vocale", ",", "le", "comunicazioni", "digitali", ",", "i", "sintetizzatori", "digitali", ",", "il", "radar", ",", "il", "sonar", ",", "l'", "elaborazione", "del", "segnale", "finanziario", ",", "la", "sismologia", "e", "la", "biomedicina", "."], "sentence-detokenized": "Le applicazioni del DSP comprendono l'elaborazione del segnale audio, la compressione audio, l'elaborazione digitale delle immagini, la compressione video, l'elaborazione del parlato, il riconoscimento vocale, le comunicazioni digitali, i sintetizzatori digitali, il radar, il sonar, l'elaborazione del segnale finanziario, la sismologia e la biomedicina.", "token2charspan": [[0, 2], [3, 15], [16, 19], [20, 23], [24, 35], [36, 38], [38, 50], [51, 54], [55, 62], [63, 68], [68, 69], [70, 72], [73, 85], [86, 91], [91, 92], [93, 95], [95, 107], [108, 116], [117, 122], [123, 131], [131, 132], [133, 135], [136, 148], [149, 154], [154, 155], [156, 158], [158, 170], [171, 174], [175, 182], [182, 183], [184, 186], [187, 201], [202, 208], [208, 209], [210, 212], [213, 226], [227, 235], [235, 236], [237, 238], [239, 253], [254, 262], [262, 263], [264, 266], [267, 272], [272, 273], [274, 276], [277, 282], [282, 283], [284, 286], [286, 298], [299, 302], [303, 310], [311, 322], [322, 323], [324, 326], [327, 337], [338, 339], [340, 342], [343, 354], [354, 355]]}
{"doc_key": "ai-dev-247", "ner": [[12, 13, "misc"], [20, 20, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["(", "20", "febbraio", "1912", "-", "11", "agosto", "2011", ")", "\u00e8", "stato", "un", "inventore", "americano", ",", "noto", "soprattutto", "per", "aver", "creato", "Unimate", ",", "il", "primo", "robot", "industriale", "."], "sentence-detokenized": "(20 febbraio 1912 - 11 agosto 2011) \u00e8 stato un inventore americano, noto soprattutto per aver creato Unimate, il primo robot industriale.", "token2charspan": [[0, 1], [1, 3], [4, 12], [13, 17], [18, 19], [20, 22], [23, 29], [30, 34], [34, 35], [36, 37], [38, 43], [44, 46], [47, 56], [57, 66], [66, 67], [68, 72], [73, 84], [85, 88], [89, 93], [94, 100], [101, 108], [108, 109], [110, 112], [113, 118], [119, 124], [125, 136], [136, 137]]}
{"doc_key": "ai-dev-248", "ner": [[1, 3, "researcher"], [5, 7, "researcher"], [9, 9, "researcher"], [26, 28, "algorithm"], [33, 35, "algorithm"], [42, 44, "task"], [46, 46, "algorithm"], [51, 52, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[1, 3, 26, 28, "related-to", "writes_about", true, false], [5, 7, 26, 28, "related-to", "writes_about", true, false], [9, 9, 26, 28, "related-to", "writes_about", true, false], [26, 28, 33, 35, "related-to", "", true, false], [42, 44, 46, 46, "related-to", "", true, false], [51, 52, 46, 46, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Con", "David", "E.", "Rumelhart", "e", "Ronald", "J.", "Williams", ",", "Hinton", "\u00e8", "stato", "coautore", "di", "un", "articolo", "molto", "citato", "pubblicato", "nel", "1986", "che", "ha", "reso", "popolare", "l'", "algoritmo", "di", "backpropagation", "per", "l'", "addestramento", "di", "reti", "neurali", "multistrato", ",", "la", "straordinaria", "pietra", "miliare", "nel", "riconoscimento", "delle", "immagini", "della", "AlexNet", "progettata", "dal", "suo", "studente", "Alex", "Krizhevsky", "{", "{", "cite", "web"], "sentence-detokenized": "Con David E. Rumelhart e Ronald J. Williams, Hinton \u00e8 stato coautore di un articolo molto citato pubblicato nel 1986 che ha reso popolare l'algoritmo di backpropagation per l'addestramento di reti neurali multistrato, la straordinaria pietra miliare nel riconoscimento delle immagini della AlexNet progettata dal suo studente Alex Krizhevsky {{cite web", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 22], [23, 24], [25, 31], [32, 34], [35, 43], [43, 44], [45, 51], [52, 53], [54, 59], [60, 68], [69, 71], [72, 74], [75, 83], [84, 89], [90, 96], [97, 107], [108, 111], [112, 116], [117, 120], [121, 123], [124, 128], [129, 137], [138, 140], [140, 149], [150, 152], [153, 168], [169, 172], [173, 175], [175, 188], [189, 191], [192, 196], [197, 204], [205, 216], [216, 217], [218, 220], [221, 234], [235, 241], [242, 249], [250, 253], [254, 268], [269, 274], [275, 283], [284, 289], [290, 297], [298, 308], [309, 312], [313, 316], [317, 325], [326, 330], [331, 341], [342, 343], [343, 344], [344, 348], [349, 352]]}
{"doc_key": "ai-dev-249", "ner": [[19, 21, "metrics"], [24, 26, "metrics"], [29, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Quando", "il", "valore", "da", "prevedere", "\u00e8", "distribuito", "in", "modo", "continuo", ",", "per", "riassumere", "gli", "errori", "si", "pu\u00f2", "utilizzare", "l'", "errore", "quadratico", "medio", ",", "l'", "errore", "quadratico", "medio", "o", "la", "deviazione", "assoluta", "mediana", "."], "sentence-detokenized": "Quando il valore da prevedere \u00e8 distribuito in modo continuo, per riassumere gli errori si pu\u00f2 utilizzare l'errore quadratico medio, l'errore quadratico medio o la deviazione assoluta mediana.", "token2charspan": [[0, 6], [7, 9], [10, 16], [17, 19], [20, 29], [30, 31], [32, 43], [44, 46], [47, 51], [52, 60], [60, 61], [62, 65], [66, 76], [77, 80], [81, 87], [88, 90], [91, 94], [95, 105], [106, 108], [108, 114], [115, 125], [126, 131], [131, 132], [133, 135], [135, 141], [142, 152], [153, 158], [159, 160], [161, 163], [164, 174], [175, 183], [184, 191], [191, 192]]}
{"doc_key": "ai-dev-250", "ner": [[0, 2, "algorithm"], [14, 15, "field"], [18, 20, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 14, 15, "part-of", "", true, false], [0, 2, 18, 20, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Il", "clustering", "concettuale", "si", "\u00e8", "sviluppato", "principalmente", "negli", "anni", "'80", ",", "come", "paradigma", "di", "apprendimento", "automatico", "per", "l'", "apprendimento", "non", "supervisionato", "."], "sentence-detokenized": "Il clustering concettuale si \u00e8 sviluppato principalmente negli anni '80, come paradigma di apprendimento automatico per l'apprendimento non supervisionato.", "token2charspan": [[0, 2], [3, 13], [14, 25], [26, 28], [29, 30], [31, 41], [42, 56], [57, 62], [63, 67], [68, 71], [71, 72], [73, 77], [78, 87], [88, 90], [91, 104], [105, 115], [116, 119], [120, 122], [122, 135], [136, 139], [140, 154], [154, 155]]}
{"doc_key": "ai-dev-251", "ner": [[9, 10, "product"], [27, 28, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Se", "le", "entit\u00e0", "nominate", "non", "possono", "essere", "riconosciute", "dal", "traduttore", "automatico", ",", "potrebbero", "essere", "erroneamente", "tradotte", "come", "sostantivi", "comuni", ",", "il", "che", "molto", "probabilmente", "non", "influirebbe", "sulla", "valutazione", "bilingue", "della", "traduzione", ",", "ma", "modificherebbe", "la", "leggibilit\u00e0", "umana", "del", "testo", "."], "sentence-detokenized": "Se le entit\u00e0 nominate non possono essere riconosciute dal traduttore automatico, potrebbero essere erroneamente tradotte come sostantivi comuni, il che molto probabilmente non influirebbe sulla valutazione bilingue della traduzione, ma modificherebbe la leggibilit\u00e0 umana del testo.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 21], [22, 25], [26, 33], [34, 40], [41, 53], [54, 57], [58, 68], [69, 79], [79, 80], [81, 91], [92, 98], [99, 111], [112, 120], [121, 125], [126, 136], [137, 143], [143, 144], [145, 147], [148, 151], [152, 157], [158, 171], [172, 175], [176, 187], [188, 193], [194, 205], [206, 214], [215, 220], [221, 231], [231, 232], [233, 235], [236, 250], [251, 253], [254, 265], [266, 271], [272, 275], [276, 281], [281, 282]]}
{"doc_key": "ai-dev-252", "ner": [[0, 1, "researcher"], [10, 11, "misc"], [12, 18, "conference"], [20, 22, "location"], [24, 24, "country"], [39, 40, "researcher"], [49, 49, "researcher"], [51, 53, "university"], [56, 57, "researcher"], [59, 60, "researcher"], [62, 63, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 11, "related-to", "writes_about", false, false], [0, 1, 12, 18, "temporal", "", true, false], [12, 18, 20, 22, "physical", "", false, false], [20, 22, 24, 24, "physical", "", false, false], [49, 49, 51, 53, "physical", "", false, false], [49, 49, 51, 53, "role", "", false, false], [56, 57, 51, 53, "physical", "", false, false], [56, 57, 51, 53, "role", "", false, false], [59, 60, 51, 53, "physical", "", false, false], [59, 60, 51, 53, "role", "", false, false], [62, 63, 51, 53, "physical", "", false, false], [62, 63, 51, 53, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Roger", "Schank", ",", "1969", ",", "A", "conceptual", "dependency", "parser", "for", "natural", "language", "Proceedings", "of", "the", "1969", "on", "Computational", "linguistics", ",", "S\u00e5ng", "-", "S\u00e4by", ",", "Sweden", ",", "pagg", ".", "1", "-", "3", "Questo", "modello", ",", "parzialmente", "influenzato", "dal", "lavoro", "di", "Sydney", "Lamb", ",", "\u00e8", "stato", "ampiamente", "utilizzato", "dagli", "studenti", "di", "Schank", "all'", "Universit\u00e0", "di", "Yale", ",", "come", "Robert", "Wilensky", ",", "Wendy", "Lehnert", "e", "Janet", "Kolodner", "."], "sentence-detokenized": "Roger Schank, 1969, A conceptual dependency parser for natural language Proceedings of the 1969 on Computational linguistics, S\u00e5ng-S\u00e4by, Sweden, pagg. 1-3 Questo modello, parzialmente influenzato dal lavoro di Sydney Lamb, \u00e8 stato ampiamente utilizzato dagli studenti di Schank all'Universit\u00e0 di Yale, come Robert Wilensky, Wendy Lehnert e Janet Kolodner.", "token2charspan": [[0, 5], [6, 12], [12, 13], [14, 18], [18, 19], [20, 21], [22, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 71], [72, 83], [84, 86], [87, 90], [91, 95], [96, 98], [99, 112], [113, 124], [124, 125], [126, 130], [130, 131], [131, 135], [135, 136], [137, 143], [143, 144], [145, 149], [149, 150], [151, 152], [152, 153], [153, 154], [155, 161], [162, 169], [169, 170], [171, 183], [184, 195], [196, 199], [200, 206], [207, 209], [210, 216], [217, 221], [221, 222], [223, 224], [225, 230], [231, 241], [242, 252], [253, 258], [259, 267], [268, 270], [271, 277], [278, 282], [282, 292], [293, 295], [296, 300], [300, 301], [302, 306], [307, 313], [314, 322], [322, 323], [324, 329], [330, 337], [338, 339], [340, 345], [346, 354], [354, 355]]}
{"doc_key": "ai-dev-253", "ner": [[0, 4, "algorithm"], [7, 7, "algorithm"], [15, 15, "algorithm"], [17, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 0, 4, "named", "", false, false], [15, 15, 0, 4, "named", "", false, false], [17, 18, 0, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Il", "metodo", "della", "massima", "verosimiglianza", "migliorata", "(", "IMLM", ")", "\u00e8", "una", "combinazione", "di", "due", "stimatori", "MLM", "(", "massima", "verosimiglianza", ")", "."], "sentence-detokenized": "Il metodo della massima verosimiglianza migliorata (IMLM) \u00e8 una combinazione di due stimatori MLM (massima verosimiglianza).", "token2charspan": [[0, 2], [3, 9], [10, 15], [16, 23], [24, 39], [40, 50], [51, 52], [52, 56], [56, 57], [58, 59], [60, 63], [64, 76], [77, 79], [80, 83], [84, 93], [94, 97], [98, 99], [99, 106], [107, 122], [122, 123], [123, 124]]}
{"doc_key": "ai-dev-254", "ner": [[22, 24, "metrics"], [27, 29, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[27, 29, 22, 24, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Questi", "metodi", "possono", "anche", "analizzare", "l'", "output", "di", "un", "programma", "e", "la", "sua", "utilit\u00e0", "e", "quindi", "possono", "comportare", "l'", "analisi", "della", "sua", "matrice", "di", "confusione", "(", "o", "tabella", "di", "confusione", ")", "."], "sentence-detokenized": "Questi metodi possono anche analizzare l'output di un programma e la sua utilit\u00e0 e quindi possono comportare l'analisi della sua matrice di confusione (o tabella di confusione).", "token2charspan": [[0, 6], [7, 13], [14, 21], [22, 27], [28, 38], [39, 41], [41, 47], [48, 50], [51, 53], [54, 63], [64, 65], [66, 68], [69, 72], [73, 80], [81, 82], [83, 89], [90, 97], [98, 108], [109, 111], [111, 118], [119, 124], [125, 128], [129, 136], [137, 139], [140, 150], [151, 152], [152, 153], [154, 161], [162, 164], [165, 175], [175, 176], [176, 177]]}
{"doc_key": "ai-dev-255", "ner": [[0, 0, "product"], [9, 10, "researcher"], [12, 13, "researcher"], [15, 17, "researcher"], [21, 27, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 9, 10, "origin", "", false, false], [0, 0, 12, 13, "origin", "", false, false], [0, 0, 15, 17, "origin", "", false, false], [0, 0, 21, 27, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SURF", "\u00e8", "stato", "pubblicato", "per", "la", "prima", "volta", "da", "Herbert", "Bay", ",", "Tinne", "Tuytelaars", "e", "Luc", "Van", "Gool", "e", "presentato", "alla", "European", "Conference", "on", "Computer", "Vision", "del", "2006", "."], "sentence-detokenized": "SURF \u00e8 stato pubblicato per la prima volta da Herbert Bay, Tinne Tuytelaars e Luc Van Gool e presentato alla European Conference on Computer Vision del 2006.", "token2charspan": [[0, 4], [5, 6], [7, 12], [13, 23], [24, 27], [28, 30], [31, 36], [37, 42], [43, 45], [46, 53], [54, 57], [57, 58], [59, 64], [65, 75], [76, 77], [78, 81], [82, 85], [86, 90], [91, 92], [93, 103], [104, 108], [109, 117], [118, 128], [129, 131], [132, 140], [141, 147], [148, 151], [152, 156], [156, 157]]}
{"doc_key": "ai-dev-256", "ner": [[0, 1, "task"], [10, 12, "field"], [15, 16, "field"], [19, 20, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 10, 12, "part-of", "", false, false], [0, 1, 15, 16, "part-of", "", false, false], [0, 1, 19, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["L'", "OCR", "\u00e8", "un", "campo", "di", "ricerca", "nel", "campo", "del", "riconoscimento", "dei", "modelli", ",", "dell'", "intelligenza", "artificiale", "e", "della", "visione", "artificiale", "."], "sentence-detokenized": "L'OCR \u00e8 un campo di ricerca nel campo del riconoscimento dei modelli, dell'intelligenza artificiale e della visione artificiale.", "token2charspan": [[0, 2], [2, 5], [6, 7], [8, 10], [11, 16], [17, 19], [20, 27], [28, 31], [32, 37], [38, 41], [42, 56], [57, 60], [61, 68], [68, 69], [70, 75], [75, 87], [88, 99], [100, 101], [102, 107], [108, 115], [116, 127], [127, 128]]}
{"doc_key": "ai-dev-257", "ner": [[5, 8, "metrics"], [11, 15, "algorithm"], [17, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 17, 11, 15, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Continuando", "l'", "esempio", "utilizzando", "lo", "stimatore", "di", "massima", "verosimiglianza", ",", "la", "funzione", "di", "densit\u00e0", "di", "probabilit\u00e0", "(", "pdf", ")", "del", "rumore", "per", "un", "campione", "mathwn", "/", "math", "\u00e8"], "sentence-detokenized": "Continuando l'esempio utilizzando lo stimatore di massima verosimiglianza, la funzione di densit\u00e0 di probabilit\u00e0 (pdf) del rumore per un campione mathwn / math \u00e8", "token2charspan": [[0, 11], [12, 14], [14, 21], [22, 33], [34, 36], [37, 46], [47, 49], [50, 57], [58, 73], [73, 74], [75, 77], [78, 86], [87, 89], [90, 97], [98, 100], [101, 112], [113, 114], [114, 117], [117, 118], [119, 122], [123, 129], [130, 133], [134, 136], [137, 145], [146, 152], [153, 154], [155, 159], [160, 161]]}
{"doc_key": "ai-dev-258", "ner": [[3, 4, "field"], [7, 9, "task"], [12, 14, "task"], [17, 18, "task"], [21, 23, "task"], [26, 29, "task"], [32, 32, "task"], [35, 35, "task"], [38, 40, "task"], [43, 44, "task"], [47, 50, "task"], [53, 55, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[7, 9, 3, 4, "part-of", "", false, false], [12, 14, 3, 4, "part-of", "", false, false], [17, 18, 3, 4, "part-of", "", false, false], [21, 23, 3, 4, "part-of", "", false, false], [26, 29, 3, 4, "part-of", "", false, false], [32, 32, 3, 4, "part-of", "", false, false], [35, 35, 3, 4, "part-of", "", false, false], [38, 40, 3, 4, "part-of", "", false, false], [43, 44, 3, 4, "part-of", "", false, false], [47, 50, 3, 4, "part-of", "", false, false], [53, 55, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["I", "sottodomini", "della", "computer", "vision", "includono", "la", "ricostruzione", "della", "scena", ",", "il", "rilevamento", "degli", "eventi", ",", "il", "tracciamento", "video", ",", "il", "riconoscimento", "degli", "oggetti", ",", "la", "stima", "della", "posa", "3D", ",", "l'", "apprendimento", ",", "l'", "indicizzazione", ",", "la", "stima", "del", "movimento", ",", "il", "servoassistenza", "visiva", ",", "la", "modellazione", "della", "scena", "3D", "e", "il", "restauro", "delle", "immagini", "."], "sentence-detokenized": "I sottodomini della computer vision includono la ricostruzione della scena, il rilevamento degli eventi, il tracciamento video, il riconoscimento degli oggetti, la stima della posa 3D, l'apprendimento, l'indicizzazione, la stima del movimento, il servoassistenza visiva, la modellazione della scena 3D e il restauro delle immagini.", "token2charspan": [[0, 1], [2, 13], [14, 19], [20, 28], [29, 35], [36, 45], [46, 48], [49, 62], [63, 68], [69, 74], [74, 75], [76, 78], [79, 90], [91, 96], [97, 103], [103, 104], [105, 107], [108, 120], [121, 126], [126, 127], [128, 130], [131, 145], [146, 151], [152, 159], [159, 160], [161, 163], [164, 169], [170, 175], [176, 180], [181, 183], [183, 184], [185, 187], [187, 200], [200, 201], [202, 204], [204, 218], [218, 219], [220, 222], [223, 228], [229, 232], [233, 242], [242, 243], [244, 246], [247, 262], [263, 269], [269, 270], [271, 273], [274, 286], [287, 292], [293, 298], [299, 301], [302, 303], [304, 306], [307, 315], [316, 321], [322, 330], [330, 331]]}
{"doc_key": "ai-dev-259", "ner": [[6, 10, "conference"], [12, 12, "researcher"], [17, 18, "misc"], [23, 26, "conference"], [28, 28, "researcher"], [30, 30, "researcher"], [32, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[6, 10, 23, 26, "named", "", false, false], [12, 12, 17, 18, "win-defeat", "", false, false], [12, 12, 32, 35, "related-to", "writes_about", true, false], [17, 18, 6, 10, "temporal", "", false, false], [28, 28, 17, 18, "win-defeat", "", false, true], [28, 28, 32, 35, "related-to", "writes_about", true, false], [30, 30, 17, 18, "win-defeat", "", false, true], [30, 30, 32, 35, "related-to", "writes_about", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Nel", "2013", ",", "in", "occasione", "dell'", "International", "Conference", "on", "Computer", "Vision", ",", "Terzopoulos", "\u00e8", "stato", "insignito", "del", "Premio", "Helmholtz", "per", "il", "suo", "articolo", "del", "1987", "dell'", "ICCV", "con", "Kass", "e", "Witkin", "sui", "modelli", "di", "contorno", "attivi", "."], "sentence-detokenized": "Nel 2013, in occasione dell'International Conference on Computer Vision, Terzopoulos \u00e8 stato insignito del Premio Helmholtz per il suo articolo del 1987 dell'ICCV con Kass e Witkin sui modelli di contorno attivi.", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 12], [13, 22], [23, 28], [28, 41], [42, 52], [53, 55], [56, 64], [65, 71], [71, 72], [73, 84], [85, 86], [87, 92], [93, 102], [103, 106], [107, 113], [114, 123], [124, 127], [128, 130], [131, 134], [135, 143], [144, 147], [148, 152], [153, 158], [158, 162], [163, 166], [167, 171], [172, 173], [174, 180], [181, 184], [185, 192], [193, 195], [196, 204], [205, 211], [211, 212]]}
{"doc_key": "ai-dev-260", "ner": [[20, 21, "task"], [24, 27, "algorithm"], [30, 32, "algorithm"], [33, 35, "algorithm"], [38, 40, "algorithm"], [44, 45, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 21, 24, 27, "usage", "", true, false], [20, 21, 30, 32, "usage", "", true, false], [20, 21, 33, 35, "usage", "", true, false], [20, 21, 38, 40, "usage", "", true, false], [20, 21, 44, 45, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Se", "la", "funzione", "di", "regolarizzazione", "esiste", "molti", "algoritmi", "per", "la", "risoluzione", "di", "tali", "problemi", ";", "quelli", "pi\u00f9", "diffusi", "per", "la", "classificazione", "lineare", "includono", "la", "discesa", "del", "gradiente", "stocastica", ",", "la", "discesa", "del", "gradiente", "L", "-", "BFGS", ",", "la", "discesa", "delle", "coordinate", "e", "i", "metodi", "di", "Newton", "."], "sentence-detokenized": "Se la funzione di regolarizzazione esiste molti algoritmi per la risoluzione di tali problemi; quelli pi\u00f9 diffusi per la classificazione lineare includono la discesa del gradiente stocastica, la discesa del gradiente L-BFGS, la discesa delle coordinate e i metodi di Newton.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 34], [35, 41], [42, 47], [48, 57], [58, 61], [62, 64], [65, 76], [77, 79], [80, 84], [85, 93], [93, 94], [95, 101], [102, 105], [106, 113], [114, 117], [118, 120], [121, 136], [137, 144], [145, 154], [155, 157], [158, 165], [166, 169], [170, 179], [180, 190], [190, 191], [192, 194], [195, 202], [203, 206], [207, 216], [217, 218], [218, 219], [219, 223], [223, 224], [225, 227], [228, 235], [236, 241], [242, 252], [253, 254], [255, 256], [257, 263], [264, 266], [267, 273], [273, 274]]}
{"doc_key": "ai-dev-261", "ner": [[3, 6, "algorithm"], [8, 8, "algorithm"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 6, 14, 15, "origin", "", false, false], [8, 8, 3, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Le", "reti", "di", "memoria", "a", "breve", "termine", "(", "LSTM", ")", "sono", "state", "inventate", "da", "Sepp", "Hochreiter", "e", "J\u00fcrgen", "Schmidhuber", "nel", "1997", "e", "hanno", "stabilito", "record", "di", "precisione", "in", "diversi", "campi", "di", "applicazione", "."], "sentence-detokenized": "Le reti di memoria a breve termine (LSTM) sono state inventate da Sepp Hochreiter e J\u00fcrgen Schmidhuber nel 1997 e hanno stabilito record di precisione in diversi campi di applicazione.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 18], [19, 20], [21, 26], [27, 34], [35, 36], [36, 40], [40, 41], [42, 46], [47, 52], [53, 62], [63, 65], [66, 70], [71, 81], [82, 83], [84, 90], [91, 102], [103, 106], [107, 111], [112, 113], [114, 119], [120, 129], [130, 136], [137, 139], [140, 150], [151, 153], [154, 161], [162, 167], [168, 170], [171, 183], [183, 184]]}
{"doc_key": "ai-dev-262", "ner": [[0, 1, "product"], [7, 9, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 7, 9, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Il", "TN", "\u00e8", "stato", "sviluppato", "presso", "il", "Massachusetts", "General", "Hospital", "ed", "\u00e8", "stato", "testato", "in", "diversi", "scenari", ",", "tra", "cui", "l'", "estrazione", "dello", "stato", "di", "fumatore", ",", "la", "storia", "familiare", "di", "malattia", "coronarica", "e", "l'", "identificazione", "di", "pazienti", "con", "disturbi", "del", "sonno", ","], "sentence-detokenized": "Il TN \u00e8 stato sviluppato presso il Massachusetts General Hospital ed \u00e8 stato testato in diversi scenari, tra cui l'estrazione dello stato di fumatore, la storia familiare di malattia coronarica e l'identificazione di pazienti con disturbi del sonno,", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 13], [14, 24], [25, 31], [32, 34], [35, 48], [49, 56], [57, 65], [66, 68], [69, 70], [71, 76], [77, 84], [85, 87], [88, 95], [96, 103], [103, 104], [105, 108], [109, 112], [113, 115], [115, 125], [126, 131], [132, 137], [138, 140], [141, 149], [149, 150], [151, 153], [154, 160], [161, 170], [171, 173], [174, 182], [183, 193], [194, 195], [196, 198], [198, 213], [214, 216], [217, 225], [226, 229], [230, 238], [239, 242], [243, 248], [248, 249]]}
{"doc_key": "ai-dev-263", "ner": [[3, 3, "researcher"], [9, 9, "product"], [17, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 9, 9, "role", "sells", false, false], [9, 9, 17, 18, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Nel", "1960", ",", "Devol", "vendette", "personalmente", "il", "primo", "robot", "Unimate", ",", "che", "fu", "spedito", "nel", "1961", "alla", "General", "Motors", "."], "sentence-detokenized": "Nel 1960, Devol vendette personalmente il primo robot Unimate, che fu spedito nel 1961 alla General Motors.", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 15], [16, 24], [25, 38], [39, 41], [42, 47], [48, 53], [54, 61], [61, 62], [63, 66], [67, 69], [70, 77], [78, 81], [82, 86], [87, 91], [92, 99], [100, 106], [106, 107]]}
{"doc_key": "ai-dev-264", "ner": [[1, 3, "conference"], [15, 16, "location"], [18, 18, "location"], [21, 21, "country"], [34, 35, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 3, 15, 16, "physical", "", false, false], [15, 16, 18, 18, "physical", "", false, false], [18, 18, 21, 21, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Il", "Campus", "Party", "Europe", "si", "\u00e8", "tenuto", "dal", "14", "al", "18", "aprile", "2010", "presso", "la", "Caja", "M\u00e1gica", "di", "Madrid", ",", "in", "Spagna", ",", "con", "800", "partecipanti", "provenienti", "da", "ciascuno", "dei", "27", "Stati", "membri", "dell'", "Unione", "Europea", "."], "sentence-detokenized": "Il Campus Party Europe si \u00e8 tenuto dal 14 al 18 aprile 2010 presso la Caja M\u00e1gica di Madrid, in Spagna, con 800 partecipanti provenienti da ciascuno dei 27 Stati membri dell'Unione Europea.", "token2charspan": [[0, 2], [3, 9], [10, 15], [16, 22], [23, 25], [26, 27], [28, 34], [35, 38], [39, 41], [42, 44], [45, 47], [48, 54], [55, 59], [60, 66], [67, 69], [70, 74], [75, 81], [82, 84], [85, 91], [91, 92], [93, 95], [96, 102], [102, 103], [104, 107], [108, 111], [112, 124], [125, 136], [137, 139], [140, 148], [149, 152], [153, 155], [156, 161], [162, 168], [169, 174], [174, 180], [181, 188], [188, 189]]}
{"doc_key": "ai-dev-265", "ner": [[9, 9, "organisation"], [12, 14, "organisation"], [17, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 23, 9, 9, "origin", "", false, false], [17, 23, 12, 14, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Nel", "luglio", "2016", "\u00e8", "stata", "annunciata", "una", "collaborazione", "tra", "DeepMind", "e", "il", "Moorfields", "Eye", "Hospital", "per", "sviluppare", "applicazioni", "di", "IA", "per", "l'", "assistenza", "sanitaria", "."], "sentence-detokenized": "Nel luglio 2016 \u00e8 stata annunciata una collaborazione tra DeepMind e il Moorfields Eye Hospital per sviluppare applicazioni di IA per l'assistenza sanitaria.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 17], [18, 23], [24, 34], [35, 38], [39, 53], [54, 57], [58, 66], [67, 68], [69, 71], [72, 82], [83, 86], [87, 95], [96, 99], [100, 110], [111, 123], [124, 126], [127, 129], [130, 133], [134, 136], [136, 146], [147, 156], [156, 157]]}
{"doc_key": "ai-dev-266", "ner": [[6, 6, "misc"], [14, 16, "university"], [18, 18, "university"], [20, 21, "university"], [23, 24, "university"], [26, 26, "university"], [28, 28, "university"], [30, 33, "university"], [35, 36, "university"], [38, 39, "university"], [41, 41, "university"], [43, 45, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[6, 6, 14, 16, "physical", "", false, false], [6, 6, 18, 18, "physical", "", false, false], [6, 6, 20, 21, "physical", "", false, false], [6, 6, 23, 24, "physical", "", false, false], [6, 6, 26, 26, "physical", "", false, false], [6, 6, 28, 28, "physical", "", false, false], [6, 6, 30, 33, "physical", "", false, false], [6, 6, 35, 36, "physical", "", false, false], [6, 6, 38, 39, "physical", "", false, false], [6, 6, 41, 41, "physical", "", false, false], [6, 6, 43, 45, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Alla", "fine", "sono", "stati", "assegnati", "undici", "PR2", "a", "diverse", "istituzioni", ",", "tra", "cui", "l'", "Universit\u00e0", "di", "Friburgo", ",", "Bosch", ",", "Georgia", "Tech", ",", "KU", "Leuven", ",", "MIT", ",", "Stanford", ",", "Universit\u00e0", "Tecnica", "di", "Monaco", ",", "UC", "Berkeley", ",", "U", "Penn", ",", "USC", "e", "Universit\u00e0", "di", "Tokyo", "."], "sentence-detokenized": "Alla fine sono stati assegnati undici PR2 a diverse istituzioni, tra cui l'Universit\u00e0 di Friburgo, Bosch, Georgia Tech, KU Leuven, MIT, Stanford, Universit\u00e0 Tecnica di Monaco, UC Berkeley, U Penn, USC e Universit\u00e0 di Tokyo.", "token2charspan": [[0, 4], [5, 9], [10, 14], [15, 20], [21, 30], [31, 37], [38, 41], [42, 43], [44, 51], [52, 63], [63, 64], [65, 68], [69, 72], [73, 75], [75, 85], [86, 88], [89, 97], [97, 98], [99, 104], [104, 105], [106, 113], [114, 118], [118, 119], [120, 122], [123, 129], [129, 130], [131, 134], [134, 135], [136, 144], [144, 145], [146, 156], [157, 164], [165, 167], [168, 174], [174, 175], [176, 178], [179, 187], [187, 188], [189, 190], [191, 195], [195, 196], [197, 200], [201, 202], [203, 213], [214, 216], [217, 222], [222, 223]]}
{"doc_key": "ai-dev-267", "ner": [[3, 3, "metrics"], [5, 5, "metrics"], [7, 7, "metrics"], [9, 9, "metrics"], [18, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 18, 20, "part-of", "", false, false], [5, 5, 18, 20, "part-of", "", false, false], [7, 7, 18, 20, "part-of", "", false, false], [9, 9, 18, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["I", "conteggi", "di", "TP", ",", "TN", ",", "FP", "e", "FN", "sono", "solitamente", "riportati", "in", "una", "tabella", "nota", "come", "matrice", "di", "confusione", "."], "sentence-detokenized": "I conteggi di TP, TN, FP e FN sono solitamente riportati in una tabella nota come matrice di confusione.", "token2charspan": [[0, 1], [2, 10], [11, 13], [14, 16], [16, 17], [18, 20], [20, 21], [22, 24], [25, 26], [27, 29], [30, 34], [35, 46], [47, 56], [57, 59], [60, 63], [64, 71], [72, 76], [77, 81], [82, 89], [90, 92], [93, 103], [103, 104]]}
{"doc_key": "ai-dev-268", "ner": [[10, 11, "metrics"], [14, 15, "metrics"], [18, 19, "metrics"], [22, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Come", "set", "di", "caratteristiche", ",", "di", "solito", "si", "utilizzano", "l'", "information", "gain", ",", "l'", "entropia", "incrociata", ",", "l'", "informazione", "reciproca", "e", "l'", "odds", "ratio", "."], "sentence-detokenized": "Come set di caratteristiche, di solito si utilizzano l'information gain, l'entropia incrociata, l'informazione reciproca e l'odds ratio.", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 27], [27, 28], [29, 31], [32, 38], [39, 41], [42, 52], [53, 55], [55, 66], [67, 71], [71, 72], [73, 75], [75, 83], [84, 94], [94, 95], [96, 98], [98, 110], [111, 120], [121, 122], [123, 125], [125, 129], [130, 135], [135, 136]]}
{"doc_key": "ai-dev-269", "ner": [[12, 14, "task"], [17, 19, "task"], [22, 22, "task"], [25, 25, "task"], [28, 28, "task"], [30, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[30, 30, 28, 28, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["\u00c8", "stato", "applicato", "con", "successo", "a", "vari", "problemi", ",", "tra", "cui", "il", "controllo", "dei", "robot", ",", "la", "programmazione", "degli", "ascensori", ",", "le", "telecomunicazioni", ",", "la", "dama", "e", "il", "Go", "(", "AlphaGo", ")", "."], "sentence-detokenized": "\u00c8 stato applicato con successo a vari problemi, tra cui il controllo dei robot, la programmazione degli ascensori, le telecomunicazioni, la dama e il Go (AlphaGo).", "token2charspan": [[0, 1], [2, 7], [8, 17], [18, 21], [22, 30], [31, 32], [33, 37], [38, 46], [46, 47], [48, 51], [52, 55], [56, 58], [59, 68], [69, 72], [73, 78], [78, 79], [80, 82], [83, 97], [98, 103], [104, 113], [113, 114], [115, 117], [118, 135], [135, 136], [137, 139], [140, 144], [145, 146], [147, 149], [150, 152], [153, 154], [154, 161], [161, 162], [162, 163]]}
{"doc_key": "ai-dev-270", "ner": [[10, 11, "misc"], [18, 21, "university"], [23, 23, "location"], [26, 26, "location"], [30, 33, "location"], [39, 42, "location"], [43, 43, "location"], [46, 46, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 11, 18, 21, "physical", "", false, false], [18, 21, 23, 23, "physical", "", false, false], [23, 23, 26, 26, "physical", "", false, false], [30, 33, 39, 42, "physical", "", false, false], [39, 42, 43, 43, "physical", "", false, false], [43, 43, 46, 46, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Nel", "2018", ",", "anno", "inaugurale", "della", "Missione", "8", ",", "la", "sede", "americana", "si", "\u00e8", "tenuta", "nel", "campus", "del", "Georgia", "Institute", "of", "Technology", "di", "Atlanta", ",", "in", "Georgia", ",", "mentre", "la", "sede", "Asia", "/", "Pacifico", "si", "\u00e8", "svolta", "presso", "il", "Beihang", "University", "Gymnasium", "di", "Pechino", ",", "in", "Cina", "."], "sentence-detokenized": "Nel 2018, anno inaugurale della Missione 8, la sede americana si \u00e8 tenuta nel campus del Georgia Institute of Technology di Atlanta, in Georgia, mentre la sede Asia/Pacifico si \u00e8 svolta presso il Beihang University Gymnasium di Pechino, in Cina.", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 14], [15, 25], [26, 31], [32, 40], [41, 42], [42, 43], [44, 46], [47, 51], [52, 61], [62, 64], [65, 66], [67, 73], [74, 77], [78, 84], [85, 88], [89, 96], [97, 106], [107, 109], [110, 120], [121, 123], [124, 131], [131, 132], [133, 135], [136, 143], [143, 144], [145, 151], [152, 154], [155, 159], [160, 164], [164, 165], [165, 173], [174, 176], [177, 178], [179, 185], [186, 192], [193, 195], [196, 203], [204, 214], [215, 224], [225, 227], [228, 235], [235, 236], [237, 239], [240, 244], [244, 245]]}
{"doc_key": "ai-dev-271", "ner": [[0, 2, "field"], [7, 9, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 7, 9, "origin", "", false, false], [0, 2, 7, 9, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["L'", "apprendimento", "automatico", "\u00e8", "fortemente", "legato", "al", "riconoscimento", "dei", "modelli", "e", "trae", "origine", "dall'", "intelligenza", "artificiale", "."], "sentence-detokenized": "L'apprendimento automatico \u00e8 fortemente legato al riconoscimento dei modelli e trae origine dall'intelligenza artificiale.", "token2charspan": [[0, 2], [2, 15], [16, 26], [27, 28], [29, 39], [40, 46], [47, 49], [50, 64], [65, 68], [69, 76], [77, 78], [79, 83], [84, 91], [92, 97], [97, 109], [110, 121], [121, 122]]}
{"doc_key": "ai-dev-272", "ner": [[5, 5, "programlang"], [15, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["\u00c8", "dotato", "di", "3", "giochi", "Java", "che", "vengono", "controllati", "con", "il", "telecomando", "e", "visualizzati", "sullo", "schermo", "LCD."], "sentence-detokenized": "\u00c8 dotato di 3 giochi Java che vengono controllati con il telecomando e visualizzati sullo schermo LCD.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 13], [14, 20], [21, 25], [26, 29], [30, 37], [38, 49], [50, 53], [54, 56], [57, 68], [69, 70], [71, 83], [84, 89], [90, 97], [98, 102]]}
{"doc_key": "ai-dev-273", "ner": [[3, 13, "task"], [23, 26, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[23, 26, 3, 13, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Una", "tecnica", "di", "stima", "della", "posa", "di", "un", "corpo", "articolato", "basata", "sulla", "computer", "vision", ",", "ma", "di", "grande", "successo", "commerciale", ",", "\u00e8", "la", "cattura", "ottica", "del", "movimento", "."], "sentence-detokenized": "Una tecnica di stima della posa di un corpo articolato basata sulla computer vision, ma di grande successo commerciale, \u00e8 la cattura ottica del movimento.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 20], [21, 26], [27, 31], [32, 34], [35, 37], [38, 43], [44, 54], [55, 61], [62, 67], [68, 76], [77, 83], [83, 84], [85, 87], [88, 90], [91, 97], [98, 106], [107, 118], [118, 119], [120, 121], [122, 124], [125, 132], [133, 139], [140, 143], [144, 153], [153, 154]]}
{"doc_key": "ai-dev-274", "ner": [[1, 1, "organisation"], [8, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 1, 8, 10, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["L'", "SMC", "\u00e8", "molto", "simile", "al", "pi\u00f9", "noto", "indice", "di", "Jaccard", "."], "sentence-detokenized": "L'SMC \u00e8 molto simile al pi\u00f9 noto indice di Jaccard.", "token2charspan": [[0, 2], [2, 5], [6, 7], [8, 13], [14, 20], [21, 23], [24, 27], [28, 32], [33, 39], [40, 42], [43, 50], [50, 51]]}
{"doc_key": "ai-dev-275", "ner": [[1, 1, "product"], [3, 7, "product"], [10, 13, "product"], [22, 23, "researcher"], [30, 30, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 10, 13, "named", "", false, false], [1, 1, 22, 23, "artifact", "", false, false], [1, 1, 30, 30, "artifact", "", false, false], [3, 7, 1, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Il", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ",", "o", "Programmable", "Universal", "Manipulation", "Arm", ")", "\u00e8", "un", "braccio", "robotico", "industriale", "sviluppato", "da", "Victor", "Scheinman", "presso", "l'", "azienda", "pionieristica", "di", "robot", "Unimation", "."], "sentence-detokenized": "Il PUMA (Programmable Universal Machine for Assembly, o Programmable Universal Manipulation Arm) \u00e8 un braccio robotico industriale sviluppato da Victor Scheinman presso l'azienda pionieristica di robot Unimation.", "token2charspan": [[0, 2], [3, 7], [8, 9], [9, 21], [22, 31], [32, 39], [40, 43], [44, 52], [52, 53], [54, 55], [56, 68], [69, 78], [79, 91], [92, 95], [95, 96], [97, 98], [99, 101], [102, 109], [110, 118], [119, 130], [131, 141], [142, 144], [145, 151], [152, 161], [162, 168], [169, 171], [171, 178], [179, 192], [193, 195], [196, 201], [202, 211], [211, 212]]}
{"doc_key": "ai-dev-276", "ner": [[3, 3, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["\u00c8", "scritto", "in", "Python", "."], "sentence-detokenized": "\u00c8 scritto in Python.", "token2charspan": [[0, 1], [2, 9], [10, 12], [13, 19], [19, 20]]}
{"doc_key": "ai-dev-277", "ner": [[0, 3, "misc"], [5, 5, "misc"], [17, 17, "field"], [20, 22, "field"], [25, 26, "field"], [29, 30, "field"], [33, 35, "field"], [38, 38, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 3, 5, 5, "related-to", "metric_for", true, false], [0, 3, 17, 17, "part-of", "", false, false], [0, 3, 20, 22, "part-of", "", false, false], [0, 3, 25, 26, "part-of", "", false, false], [0, 3, 29, 30, "part-of", "", false, false], [0, 3, 33, 35, "part-of", "", false, false], [0, 3, 38, 38, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["La", "larghezza", "di", "banda", "in", "hertz", "\u00e8", "un", "concetto", "centrale", "in", "molti", "campi", ",", "tra", "cui", "l'", "elettronica", ",", "la", "teoria", "dell'", "informazione", ",", "le", "comunicazioni", "digitali", ",", "le", "comunicazioni", "radio", ",", "l'", "elaborazione", "dei", "segnali", "e", "la", "spettroscopia", "ed", "\u00e8", "uno", "dei", "fattori", "determinanti", "della", "capacit\u00e0", "di", "un", "determinato", "canale", "di", "comunicazione", "."], "sentence-detokenized": "La larghezza di banda in hertz \u00e8 un concetto centrale in molti campi, tra cui l'elettronica, la teoria dell'informazione, le comunicazioni digitali, le comunicazioni radio, l'elaborazione dei segnali e la spettroscopia ed \u00e8 uno dei fattori determinanti della capacit\u00e0 di un determinato canale di comunicazione.", "token2charspan": [[0, 2], [3, 12], [13, 15], [16, 21], [22, 24], [25, 30], [31, 32], [33, 35], [36, 44], [45, 53], [54, 56], [57, 62], [63, 68], [68, 69], [70, 73], [74, 77], [78, 80], [80, 91], [91, 92], [93, 95], [96, 102], [103, 108], [108, 120], [120, 121], [122, 124], [125, 138], [139, 147], [147, 148], [149, 151], [152, 165], [166, 171], [171, 172], [173, 175], [175, 187], [188, 191], [192, 199], [200, 201], [202, 204], [205, 218], [219, 221], [222, 223], [224, 227], [228, 231], [232, 239], [240, 252], [253, 258], [259, 267], [268, 270], [271, 273], [274, 285], [286, 292], [293, 295], [296, 309], [309, 310]]}
{"doc_key": "ai-dev-278", "ner": [[9, 9, "algorithm"], [11, 11, "algorithm"], [17, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 17, 20, "part-of", "", false, false], [11, 11, 17, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Se", "si", "utilizza", "una", "perdita", "convessa", "(", "come", "in", "AdaBoost", ",", "LogitBoost", "e", "tutti", "i", "membri", "della", "famiglia", "di", "algoritmi", "AnyBoost", ")", ",", "un", "esempio", "con", "un", "margine", "maggiore", "ricever\u00e0", "un", "peso", "minore", "(", "o", "uguale", ")", "rispetto", "a", "un", "esempio", "con", "un", "margine", "minore", "."], "sentence-detokenized": "Se si utilizza una perdita convessa (come in AdaBoost, LogitBoost e tutti i membri della famiglia di algoritmi AnyBoost), un esempio con un margine maggiore ricever\u00e0 un peso minore (o uguale) rispetto a un esempio con un margine minore.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 18], [19, 26], [27, 35], [36, 37], [37, 41], [42, 44], [45, 53], [53, 54], [55, 65], [66, 67], [68, 73], [74, 75], [76, 82], [83, 88], [89, 97], [98, 100], [101, 110], [111, 119], [119, 120], [120, 121], [122, 124], [125, 132], [133, 136], [137, 139], [140, 147], [148, 156], [157, 165], [166, 168], [169, 173], [174, 180], [181, 182], [182, 183], [184, 190], [190, 191], [192, 200], [201, 202], [203, 205], [206, 213], [214, 217], [218, 220], [221, 228], [229, 235], [235, 236]]}
{"doc_key": "ai-dev-279", "ner": [[4, 5, "researcher"], [8, 9, "researcher"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 8, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Tesi", "di", "diploma", "di", "Sepp", "Hochreiter", "del", "1991", "Sepp", "Hochreiter", "."], "sentence-detokenized": "Tesi di diploma di Sepp Hochreiter del 1991 Sepp Hochreiter.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 23], [24, 34], [35, 38], [39, 43], [44, 48], [49, 59], [59, 60]]}
{"doc_key": "ai-dev-280", "ner": [[6, 7, "algorithm"], [9, 9, "algorithm"], [14, 17, "algorithm"], [19, 19, "algorithm"], [23, 25, "algorithm"], [27, 27, "algorithm"], [33, 35, "algorithm"], [39, 40, "algorithm"], [43, 44, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[9, 9, 6, 7, "named", "", false, false], [19, 19, 14, 17, "named", "", false, false], [23, 25, 33, 35, "related-to", "", true, false], [27, 27, 23, 25, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["I", "modelli", "discriminativi", "tipici", "includono", "la", "regressione", "logistica", "(", "LR", ")", ",", "le", "macchine", "a", "vettori", "di", "supporto", "(", "SVM", ")", ",", "i", "campi", "casuali", "condizionali", "(", "CRF", ")", "(", "specificati", "su", "un", "grafo", "non", "diretto", ")", ",", "gli", "alberi", "decisionali", ",", "le", "reti", "neurali", "e", "molti", "altri", "."], "sentence-detokenized": "I modelli discriminativi tipici includono la regressione logistica (LR), le macchine a vettori di supporto (SVM), i campi casuali condizionali (CRF) (specificati su un grafo non diretto), gli alberi decisionali, le reti neurali e molti altri.", "token2charspan": [[0, 1], [2, 9], [10, 24], [25, 31], [32, 41], [42, 44], [45, 56], [57, 66], [67, 68], [68, 70], [70, 71], [71, 72], [73, 75], [76, 84], [85, 86], [87, 94], [95, 97], [98, 106], [107, 108], [108, 111], [111, 112], [112, 113], [114, 115], [116, 121], [122, 129], [130, 142], [143, 144], [144, 147], [147, 148], [149, 150], [150, 161], [162, 164], [165, 167], [168, 173], [174, 177], [178, 185], [185, 186], [186, 187], [188, 191], [192, 198], [199, 210], [210, 211], [212, 214], [215, 219], [220, 227], [228, 229], [230, 235], [236, 241], [241, 242]]}
{"doc_key": "ai-dev-281", "ner": [[9, 11, "metrics"], [31, 33, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["\u00c8", "anche", "possibile", "utilizzare", "queste", "probabilit\u00e0", "e", "valutare", "l'", "errore", "quadratico", "medio", "(", "o", "qualche", "altra", "misura", "simile", ")", "tra", "le", "probabilit\u00e0", "e", "i", "valori", "effettivi", ",", "quindi", "combinarlo", "con", "la", "matrice", "di", "confusione", "per", "creare", "funzioni", "di", "fitness", "molto", "efficienti", "per", "la", "regressione", "logistica", "."], "sentence-detokenized": "\u00c8 anche possibile utilizzare queste probabilit\u00e0 e valutare l'errore quadratico medio (o qualche altra misura simile) tra le probabilit\u00e0 e i valori effettivi, quindi combinarlo con la matrice di confusione per creare funzioni di fitness molto efficienti per la regressione logistica.", "token2charspan": [[0, 1], [2, 7], [8, 17], [18, 28], [29, 35], [36, 47], [48, 49], [50, 58], [59, 61], [61, 67], [68, 78], [79, 84], [85, 86], [86, 87], [88, 95], [96, 101], [102, 108], [109, 115], [115, 116], [117, 120], [121, 123], [124, 135], [136, 137], [138, 139], [140, 146], [147, 156], [156, 157], [158, 164], [165, 175], [176, 179], [180, 182], [183, 190], [191, 193], [194, 204], [205, 208], [209, 215], [216, 224], [225, 227], [228, 235], [236, 241], [242, 252], [253, 256], [257, 259], [260, 271], [272, 281], [281, 282]]}
{"doc_key": "ai-dev-282", "ner": [[0, 0, "product"], [11, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 11, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VoiceOver", "\u00e8", "stato", "introdotto", "per", "la", "prima", "volta", "nel", "2005", "in", "Mac", "OS", "X", "Tiger", "(", "10.4", ")", "."], "sentence-detokenized": "VoiceOver \u00e8 stato introdotto per la prima volta nel 2005 in Mac OS X Tiger (10.4).", "token2charspan": [[0, 9], [10, 11], [12, 17], [18, 28], [29, 32], [33, 35], [36, 41], [42, 47], [48, 51], [52, 56], [57, 59], [60, 63], [64, 66], [67, 68], [69, 74], [75, 76], [76, 80], [80, 81], [81, 82]]}
{"doc_key": "ai-dev-283", "ner": [[13, 14, "algorithm"], [16, 18, "misc"], [25, 27, "metrics"], [30, 33, "algorithm"], [62, 65, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 14, 16, 18, "related-to", "applied_to", false, false], [25, 27, 16, 18, "type-of", "", false, false], [25, 27, 30, 33, "related-to", "used_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "pratica", ",", "gli", "algoritmi", "di", "apprendimento", "automatico", "affrontano", "questo", "problema", "impiegando", "un'", "approssimazione", "convessa", "alla", "funzione", "di", "perdita", "0", "-", "1", "(", "come", "la", "perdita", "di", "cerniera", "per", "la", "macchina", "vettoriale", "di", "supporto", ")", ",", "che", "\u00e8", "pi\u00f9", "facile", "da", "ottimizzare", ",", "o", "imponendo", "ipotesi", "sulla", "distribuzione", "mathP", "(", "x", ",", "y", ")", "/", "math", "(", "e", "quindi", "smettono", "di", "essere", "algoritmi", "di", "apprendimento", "agnostici", "a", "cui", "si", "applica", "il", "risultato", "di", "cui", "sopra", ")", "."], "sentence-detokenized": "In pratica, gli algoritmi di apprendimento automatico affrontano questo problema impiegando un'approssimazione convessa alla funzione di perdita 0-1 (come la perdita di cerniera per la macchina vettoriale di supporto), che \u00e8 pi\u00f9 facile da ottimizzare, o imponendo ipotesi sulla distribuzione mathP (x, y) / math (e quindi smettono di essere algoritmi di apprendimento agnostici a cui si applica il risultato di cui sopra).", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 25], [26, 28], [29, 42], [43, 53], [54, 64], [65, 71], [72, 80], [81, 91], [92, 95], [95, 110], [111, 119], [120, 124], [125, 133], [134, 136], [137, 144], [145, 146], [146, 147], [147, 148], [149, 150], [150, 154], [155, 157], [158, 165], [166, 168], [169, 177], [178, 181], [182, 184], [185, 193], [194, 204], [205, 207], [208, 216], [216, 217], [217, 218], [219, 222], [223, 224], [225, 228], [229, 235], [236, 238], [239, 250], [250, 251], [252, 253], [254, 263], [264, 271], [272, 277], [278, 291], [292, 297], [298, 299], [299, 300], [300, 301], [302, 303], [303, 304], [305, 306], [307, 311], [312, 313], [313, 314], [315, 321], [322, 330], [331, 333], [334, 340], [341, 350], [351, 353], [354, 367], [368, 377], [378, 379], [380, 383], [384, 386], [387, 394], [395, 397], [398, 407], [408, 410], [411, 414], [415, 420], [420, 421], [421, 422]]}
{"doc_key": "ai-dev-284", "ner": [[0, 0, "misc"], [12, 15, "field"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 12, 15, "usage", "", false, false], [0, 0, 24, 24, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Westworld", "(", "1973", ")", "\u00e8", "stato", "il", "primo", "lungometraggio", "a", "utilizzare", "l'", "elaborazione", "digitale", "delle", "immagini", "per", "simulare", "il", "punto", "di", "vista", "di", "un", "androide", "."], "sentence-detokenized": "Westworld (1973) \u00e8 stato il primo lungometraggio a utilizzare l'elaborazione digitale delle immagini per simulare il punto di vista di un androide.", "token2charspan": [[0, 9], [10, 11], [11, 15], [15, 16], [17, 18], [19, 24], [25, 27], [28, 33], [34, 48], [49, 50], [51, 61], [62, 64], [64, 76], [77, 85], [86, 91], [92, 100], [101, 104], [105, 113], [114, 116], [117, 122], [123, 125], [126, 131], [132, 134], [135, 137], [138, 146], [146, 147]]}
{"doc_key": "ai-dev-285", "ner": [[6, 7, "task"], [10, 11, "task"], [14, 14, "task"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["\u00c8", "ora", "comunemente", "utilizzato", "anche", "nel", "riconoscimento", "vocale", ",", "nella", "sintesi", "vocale", ",", "nella", "diarizzazione", ",", "Xavier", "Anguera", "et", "al", "."], "sentence-detokenized": "\u00c8 ora comunemente utilizzato anche nel riconoscimento vocale, nella sintesi vocale, nella diarizzazione, Xavier Anguera et al.", "token2charspan": [[0, 1], [2, 5], [6, 17], [18, 28], [29, 34], [35, 38], [39, 53], [54, 60], [60, 61], [62, 67], [68, 75], [76, 82], [82, 83], [84, 89], [90, 103], [103, 104], [105, 111], [112, 119], [120, 122], [123, 125], [125, 126]]}
{"doc_key": "ai-dev-286", "ner": [[9, 12, "algorithm"], [16, 17, "algorithm"], [20, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 17, 9, 12, "type-of", "", false, false], [20, 22, 9, 12, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Qui", ",", "math", "\\", "sigma", "/", "math", "\u00e8", "una", "funzione", "di", "attivazione", "elementare", ",", "come", "una", "funzione", "sigmoide", "o", "un'", "unit\u00e0", "lineare", "rettificata", "."], "sentence-detokenized": "Qui, math\\ sigma / math \u00e8 una funzione di attivazione elementare, come una funzione sigmoide o un'unit\u00e0 lineare rettificata.", "token2charspan": [[0, 3], [3, 4], [5, 9], [9, 10], [11, 16], [17, 18], [19, 23], [24, 25], [26, 29], [30, 38], [39, 41], [42, 53], [54, 64], [64, 65], [66, 70], [71, 74], [75, 83], [84, 92], [93, 94], [95, 98], [98, 103], [104, 111], [112, 123], [123, 124]]}
{"doc_key": "ai-dev-287", "ner": [[10, 16, "algorithm"], [26, 27, "misc"], [29, 29, "misc"], [25, 31, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Gli", "approcci", "tradizionali", "basati", "sulla", "fonetica", "(", "cio\u00e8", "tutti", "i", "modelli", "basati", "sul", "modello", "di", "Hidden", "Markov", ")", "richiedono", "componenti", "e", "addestramenti", "separati", "per", "il", "modello", "di", "pronuncia", ",", "acustico", "e", "linguistico", "."], "sentence-detokenized": "Gli approcci tradizionali basati sulla fonetica (cio\u00e8 tutti i modelli basati sul modello di Hidden Markov) richiedono componenti e addestramenti separati per il modello di pronuncia, acustico e linguistico.", "token2charspan": [[0, 3], [4, 12], [13, 25], [26, 32], [33, 38], [39, 47], [48, 49], [49, 53], [54, 59], [60, 61], [62, 69], [70, 76], [77, 80], [81, 88], [89, 91], [92, 98], [99, 105], [105, 106], [107, 117], [118, 128], [129, 130], [131, 144], [145, 153], [154, 157], [158, 160], [161, 168], [169, 171], [172, 181], [181, 182], [183, 191], [192, 193], [194, 205], [205, 206]]}
{"doc_key": "ai-dev-288", "ner": [[1, 5, "algorithm"], [9, 11, "field"], [14, 15, "field"], [18, 20, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 5, 18, 20, "related-to", "used_for", false, false], [9, 11, 1, 5, "usage", "", false, false], [14, 15, 1, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["L'", "operatore", "della", "croce", "di", "Roberts", "\u00e8", "utilizzato", "nell'", "elaborazione", "delle", "immagini", "e", "nella", "visione", "computerizzata", "per", "il", "rilevamento", "dei", "bordi", "."], "sentence-detokenized": "L'operatore della croce di Roberts \u00e8 utilizzato nell'elaborazione delle immagini e nella visione computerizzata per il rilevamento dei bordi.", "token2charspan": [[0, 2], [2, 11], [12, 17], [18, 23], [24, 26], [27, 34], [35, 36], [37, 47], [48, 53], [53, 65], [66, 71], [72, 80], [81, 82], [83, 88], [89, 96], [97, 111], [112, 115], [116, 118], [119, 130], [131, 134], [135, 140], [140, 141]]}
{"doc_key": "ai-dev-289", "ner": [[3, 3, "metrics"], [5, 5, "metrics"], [25, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 25, 25, "opposite", "", false, false], [5, 5, 25, 25, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["I", "valori", "di", "sensibilit\u00e0", "e", "specificit\u00e0", "non", "dipendono", "dalla", "percentuale", "di", "casi", "positivi", "nella", "popolazione", "di", "interesse", "(", "a", "differenza", ",", "ad", "esempio", ",", "della", "precisione", ")", "."], "sentence-detokenized": "I valori di sensibilit\u00e0 e specificit\u00e0 non dipendono dalla percentuale di casi positivi nella popolazione di interesse (a differenza, ad esempio, della precisione).", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 23], [24, 25], [26, 37], [38, 41], [42, 51], [52, 57], [58, 69], [70, 72], [73, 77], [78, 86], [87, 92], [93, 104], [105, 107], [108, 117], [118, 119], [119, 120], [121, 131], [131, 132], [133, 135], [136, 143], [143, 144], [145, 150], [151, 161], [161, 162], [162, 163]]}
{"doc_key": "ai-dev-290", "ner": [[2, 4, "algorithm"], [12, 12, "misc"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 12, 2, 4, "topic", "", false, false], [12, 12, 14, 15, "artifact", "", false, false], [12, 12, 17, 18, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Ma", "i", "modelli", "di", "percettroni", "sono", "stati", "resi", "molto", "impopolari", "dal", "libro", "Perceptrons", "di", "Marvin", "Minsky", "e", "Seymour", "Papert", ",", "pubblicato", "nel", "1969", "."], "sentence-detokenized": "Ma i modelli di percettroni sono stati resi molto impopolari dal libro Perceptrons di Marvin Minsky e Seymour Papert, pubblicato nel 1969.", "token2charspan": [[0, 2], [3, 4], [5, 12], [13, 15], [16, 27], [28, 32], [33, 38], [39, 43], [44, 49], [50, 60], [61, 64], [65, 70], [71, 82], [83, 85], [86, 92], [93, 99], [100, 101], [102, 109], [110, 116], [116, 117], [118, 128], [129, 132], [133, 137], [137, 138]]}
{"doc_key": "ai-dev-291", "ner": [[1, 3, "conference"], [8, 8, "organisation"], [24, 27, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 3, 24, 27, "topic", "", false, false], [8, 8, 1, 3, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Le", "Document", "Understanding", "Conferences", ",", "condotte", "annualmente", "dal", "NIST", ",", "hanno", "sviluppato", "criteri", "di", "valutazione", "sofisticati", "per", "le", "tecniche", "che", "accettano", "la", "sfida", "della", "sintesi", "di", "pi\u00f9", "documenti", "."], "sentence-detokenized": "Le Document Understanding Conferences, condotte annualmente dal NIST, hanno sviluppato criteri di valutazione sofisticati per le tecniche che accettano la sfida della sintesi di pi\u00f9 documenti.", "token2charspan": [[0, 2], [3, 11], [12, 25], [26, 37], [37, 38], [39, 47], [48, 59], [60, 63], [64, 68], [68, 69], [70, 75], [76, 86], [87, 94], [95, 97], [98, 109], [110, 121], [122, 125], [126, 128], [129, 137], [138, 141], [142, 151], [152, 154], [155, 160], [161, 166], [167, 174], [175, 177], [178, 181], [182, 191], [191, 192]]}
{"doc_key": "ai-dev-292", "ner": [[1, 2, "product"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 28, 29, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Un", "manipolatore", "parallelo", "\u00e8", "progettato", "in", "modo", "che", "ogni", "catena", "sia", "solitamente", "corta", ",", "semplice", "e", "possa", "quindi", "essere", "rigida", "contro", "i", "movimenti", "indesiderati", ",", "rispetto", "a", "un", "manipolatore", "seriale", "."], "sentence-detokenized": "Un manipolatore parallelo \u00e8 progettato in modo che ogni catena sia solitamente corta, semplice e possa quindi essere rigida contro i movimenti indesiderati, rispetto a un manipolatore seriale.", "token2charspan": [[0, 2], [3, 15], [16, 25], [26, 27], [28, 38], [39, 41], [42, 46], [47, 50], [51, 55], [56, 62], [63, 66], [67, 78], [79, 84], [84, 85], [86, 94], [95, 96], [97, 102], [103, 109], [110, 116], [117, 123], [124, 130], [131, 132], [133, 142], [143, 155], [155, 156], [157, 165], [166, 167], [168, 170], [171, 183], [184, 191], [191, 192]]}
{"doc_key": "ai-dev-293", "ner": [[26, 26, "misc"], [25, 30, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Il", "manipolatore", "\u00e8", "ci\u00f2", "che", "fa", "muovere", "il", "robot", "e", "la", "progettazione", "di", "questi", "sistemi", "pu\u00f2", "essere", "suddivisa", "in", "diversi", "tipi", "comuni", ",", "come", "i", "robot", "SCARA", "e", "a", "coordinate", "cartesiane", ",", "che", "utilizzano", "sistemi", "di", "coordinate", "diversi", "per", "dirigere", "i", "bracci", "della", "macchina", "."], "sentence-detokenized": "Il manipolatore \u00e8 ci\u00f2 che fa muovere il robot e la progettazione di questi sistemi pu\u00f2 essere suddivisa in diversi tipi comuni, come i robot SCARA e a coordinate cartesiane, che utilizzano sistemi di coordinate diversi per dirigere i bracci della macchina.", "token2charspan": [[0, 2], [3, 15], [16, 17], [18, 21], [22, 25], [26, 28], [29, 36], [37, 39], [40, 45], [46, 47], [48, 50], [51, 64], [65, 67], [68, 74], [75, 82], [83, 86], [87, 93], [94, 103], [104, 106], [107, 114], [115, 119], [120, 126], [126, 127], [128, 132], [133, 134], [135, 140], [141, 146], [147, 148], [149, 150], [151, 161], [162, 172], [172, 173], [174, 177], [178, 188], [189, 196], [197, 199], [200, 210], [211, 218], [219, 222], [223, 231], [232, 233], [234, 240], [241, 246], [247, 255], [255, 256]]}
{"doc_key": "ai-dev-294", "ner": [[1, 2, "country"], [6, 9, "organisation"], [12, 17, "organisation"], [20, 23, "organisation"], [26, 28, "organisation"], [31, 37, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 9, 1, 2, "physical", "", false, false], [12, 17, 1, 2, "physical", "", false, false], [20, 23, 1, 2, "physical", "", false, false], [26, 28, 1, 2, "physical", "", false, false], [31, 37, 1, 2, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Negli", "Stati", "Uniti", "\u00e8", "membro", "della", "National", "Academy", "of", "Sciences", ",", "dell'", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "della", "Linguistic", "Society", "of", "America", ",", "dell'", "American", "Philosophical", "Association", "e", "dell'", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "Negli Stati Uniti \u00e8 membro della National Academy of Sciences, dell'American Academy of Arts and Sciences, della Linguistic Society of America, dell'American Philosophical Association e dell'American Association for the Advancement of Science.", "token2charspan": [[0, 5], [6, 11], [12, 17], [18, 19], [20, 26], [27, 32], [33, 41], [42, 49], [50, 52], [53, 61], [61, 62], [63, 68], [68, 76], [77, 84], [85, 87], [88, 92], [93, 96], [97, 105], [105, 106], [107, 112], [113, 123], [124, 131], [132, 134], [135, 142], [142, 143], [144, 149], [149, 157], [158, 171], [172, 183], [184, 185], [186, 191], [191, 199], [200, 211], [212, 215], [216, 219], [220, 231], [232, 234], [235, 242], [242, 243]]}
{"doc_key": "ai-dev-295", "ner": [[8, 11, "algorithm"], [13, 13, "algorithm"], [25, 26, "algorithm"], [30, 31, "algorithm"], [36, 38, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 11, 25, 26, "named", "", false, false], [13, 13, 8, 11, "named", "", false, false], [25, 26, 30, 31, "compare", "", false, false], [25, 26, 36, 38, "related-to", "performs", false, false], [30, 31, 36, 38, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Sono", "saliti", "alla", "ribalta", "con", "la", "popolarit\u00e0", "della", "macchina", "vettoriale", "di", "supporto", "(", "SVM", ")", "negli", "anni", "'90", ",", "quando", "si", "\u00e8", "scoperto", "che", "la", "SVM", "era", "competitiva", "con", "le", "reti", "neurali", "in", "compiti", "come", "il", "riconoscimento", "della", "scrittura", "."], "sentence-detokenized": "Sono saliti alla ribalta con la popolarit\u00e0 della macchina vettoriale di supporto (SVM) negli anni '90, quando si \u00e8 scoperto che la SVM era competitiva con le reti neurali in compiti come il riconoscimento della scrittura.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 24], [25, 28], [29, 31], [32, 42], [43, 48], [49, 57], [58, 68], [69, 71], [72, 80], [81, 82], [82, 85], [85, 86], [87, 92], [93, 97], [98, 101], [101, 102], [103, 109], [110, 112], [113, 114], [115, 123], [124, 127], [128, 130], [131, 134], [135, 138], [139, 150], [151, 154], [155, 157], [158, 162], [163, 170], [171, 173], [174, 181], [182, 186], [187, 189], [190, 204], [205, 210], [211, 220], [220, 221]]}
{"doc_key": "ai-dev-296", "ner": [[1, 3, "misc"], [9, 9, "misc"], [16, 17, "algorithm"], [23, 25, "misc"], [34, 36, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 3, 9, 9, "usage", "", false, false], [1, 3, 23, 25, "usage", "", false, false], [9, 9, 16, 17, "origin", "result_of_algorithm", false, false], [23, 25, 34, 36, "origin", "result_of_algorithm", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Una", "trasformata", "di", "sbiancamento", "empirica", "si", "ottiene", "stimando", "la", "covarianza", "(", "ad", "esempio", ",", "mediante", "la", "massima", "verosimiglianza", ")", "e", "costruendo", "successivamente", "una", "matrice", "di", "sbiancamento", "stimata", "corrispondente", "(", "ad", "esempio", ",", "mediante", "la", "decomposizione", "di", "Cholesky", ")", "."], "sentence-detokenized": "Una trasformata di sbiancamento empirica si ottiene stimando la covarianza (ad esempio, mediante la massima verosimiglianza) e costruendo successivamente una matrice di sbiancamento stimata corrispondente (ad esempio, mediante la decomposizione di Cholesky).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 31], [32, 40], [41, 43], [44, 51], [52, 60], [61, 63], [64, 74], [75, 76], [76, 78], [79, 86], [86, 87], [88, 96], [97, 99], [100, 107], [108, 123], [123, 124], [125, 126], [127, 137], [138, 153], [154, 157], [158, 165], [166, 168], [169, 181], [182, 189], [190, 204], [205, 206], [206, 208], [209, 216], [216, 217], [218, 226], [227, 229], [230, 244], [245, 247], [248, 256], [256, 257], [257, 258]]}
{"doc_key": "ai-dev-297", "ner": [[0, 0, "organisation"], [9, 12, "product"], [19, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 12, 0, 0, "artifact", "", false, false], [19, 20, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["IAI", "\u00e8", "il", "pi\u00f9", "grande", "produttore", "al", "mondo", "di", "robot", "a", "coordinate", "cartesiane", "ed", "\u00e8", "un", "leader", "affermato", "nei", "robot", "SCARA", "a", "basso", "costo", "e", "ad", "alte", "prestazioni", "."], "sentence-detokenized": "IAI \u00e8 il pi\u00f9 grande produttore al mondo di robot a coordinate cartesiane ed \u00e8 un leader affermato nei robot SCARA a basso costo e ad alte prestazioni.", "token2charspan": [[0, 3], [4, 5], [6, 8], [9, 12], [13, 19], [20, 30], [31, 33], [34, 39], [40, 42], [43, 48], [49, 50], [51, 61], [62, 72], [73, 75], [76, 77], [78, 80], [81, 87], [88, 97], [98, 101], [102, 107], [108, 113], [114, 115], [116, 121], [122, 127], [128, 129], [130, 132], [133, 137], [138, 149], [149, 150]]}
{"doc_key": "ai-dev-298", "ner": [[12, 13, "field"], [16, 17, "field"], [20, 21, "field"], [24, 26, "field"], [29, 30, "field"], [33, 35, "field"], [38, 38, "field"], [41, 41, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [], "relations_mapping_to_source": [], "sentence": ["L'", "analisi", "formale", "dei", "concetti", "trova", "applicazione", "pratica", "in", "campi", "quali", "il", "data", "mining", ",", "il", "text", "mining", ",", "l'", "apprendimento", "automatico", ",", "la", "gestione", "della", "conoscenza", ",", "il", "web", "semantico", ",", "lo", "sviluppo", "di", "software", ",", "la", "chimica", "e", "la", "biologia", "."], "sentence-detokenized": "L'analisi formale dei concetti trova applicazione pratica in campi quali il data mining, il text mining, l'apprendimento automatico, la gestione della conoscenza, il web semantico, lo sviluppo di software, la chimica e la biologia.", "token2charspan": [[0, 2], [2, 9], [10, 17], [18, 21], [22, 30], [31, 36], [37, 49], [50, 57], [58, 60], [61, 66], [67, 72], [73, 75], [76, 80], [81, 87], [87, 88], [89, 91], [92, 96], [97, 103], [103, 104], [105, 107], [107, 120], [121, 131], [131, 132], [133, 135], [136, 144], [145, 150], [151, 161], [161, 162], [163, 165], [166, 169], [170, 179], [179, 180], [181, 183], [184, 192], [193, 195], [196, 204], [204, 205], [206, 208], [209, 216], [217, 218], [219, 221], [222, 230], [230, 231]]}
{"doc_key": "ai-dev-299", "ner": [[1, 1, "field"], [4, 7, "field"], [11, 13, "field"], [19, 20, "field"], [32, 33, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 7, 19, 20, "part-of", "", false, false], [4, 7, 32, 33, "topic", "", false, false], [11, 13, 4, 7, "named", "", false, false], [19, 20, 1, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "informatica", ",", "la", "teoria", "dell'", "apprendimento", "computazionale", "(", "o", "semplicemente", "teoria", "dell'", "apprendimento", ")", "\u00e8", "un", "sottocampo", "dell'", "intelligenza", "artificiale", "dedicato", "allo", "studio", "della", "progettazione", "e", "dell'", "analisi", "degli", "algoritmi", "di", "apprendimento", "automatico", "."], "sentence-detokenized": "In informatica, la teoria dell'apprendimento computazionale (o semplicemente teoria dell'apprendimento) \u00e8 un sottocampo dell'intelligenza artificiale dedicato allo studio della progettazione e dell'analisi degli algoritmi di apprendimento automatico.", "token2charspan": [[0, 2], [3, 14], [14, 15], [16, 18], [19, 25], [26, 31], [31, 44], [45, 59], [60, 61], [61, 62], [63, 76], [77, 83], [84, 89], [89, 102], [102, 103], [104, 105], [106, 108], [109, 119], [120, 125], [125, 137], [138, 149], [150, 158], [159, 163], [164, 170], [171, 176], [177, 190], [191, 192], [193, 198], [198, 205], [206, 211], [212, 221], [222, 224], [225, 238], [239, 249], [249, 250]]}
{"doc_key": "ai-dev-300", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [11, 13, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 0, 2, "named", "", false, false], [11, 13, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Il", "filtraggio", "collaborativo", "(", "CF", ")", "\u00e8", "una", "tecnica", "utilizzata", "dai", "sistemi", "di", "raccomandazione", "."], "sentence-detokenized": "Il filtraggio collaborativo (CF) \u00e8 una tecnica utilizzata dai sistemi di raccomandazione.", "token2charspan": [[0, 2], [3, 13], [14, 27], [28, 29], [29, 31], [31, 32], [33, 34], [35, 38], [39, 46], [47, 57], [58, 61], [62, 69], [70, 72], [73, 88], [88, 89]]}
{"doc_key": "ai-dev-301", "ner": [[1, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Il", "tasso", "di", "FALSO", "positivo", "\u00e8", "la", "proporzione", "di", "tutti", "i", "negativi", "che", "producono", "comunque", "risultati", "positivi", "del", "test", ",", "cio\u00e8", "la", "probabilit\u00e0", "condizionata", "di", "un", "risultato", "positivo", "del", "test", "dato", "un", "evento", "che", "non", "era", "presente", "."], "sentence-detokenized": "Il tasso di FALSO positivo \u00e8 la proporzione di tutti i negativi che producono comunque risultati positivi del test, cio\u00e8 la probabilit\u00e0 condizionata di un risultato positivo del test dato un evento che non era presente.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 17], [18, 26], [27, 28], [29, 31], [32, 43], [44, 46], [47, 52], [53, 54], [55, 63], [64, 67], [68, 77], [78, 86], [87, 96], [97, 105], [106, 109], [110, 114], [114, 115], [116, 120], [121, 123], [124, 135], [136, 148], [149, 151], [152, 154], [155, 164], [165, 173], [174, 177], [178, 182], [183, 187], [188, 190], [191, 197], [198, 201], [202, 205], [206, 209], [210, 218], [218, 219]]}
{"doc_key": "ai-dev-302", "ner": [[1, 14, "misc"], [39, 39, "metrics"], [44, 44, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 14, 39, 39, "topic", "", false, false], [1, 14, 44, 44, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "VLDB", "'", "8", ":", "Proceedings", "of", "34th", "International", "Conference", "on", "Very", "Large", "Data", "Bases", ",", "pagg.", "422", "-", "-", "433", ".", "ha", "mostrato", "che", "i", "valori", "dati", "per", "mathC", "/", "math", "e", "mathK", "/", "math", "implicano", "generalmente", "un'", "accuratezza", "relativamente", "bassa", "dei", "punteggi", "SimRank", "calcolati", "iterativamente", "."], "sentence-detokenized": "In VLDB '8: Proceedings of 34th International Conference on Very Large Data Bases, pagg. 422--433. ha mostrato che i valori dati per mathC / math e mathK / math implicano generalmente un'accuratezza relativamente bassa dei punteggi SimRank calcolati iterativamente.", "token2charspan": [[0, 2], [3, 7], [8, 9], [9, 10], [10, 11], [12, 23], [24, 26], [27, 31], [32, 45], [46, 56], [57, 59], [60, 64], [65, 70], [71, 75], [76, 81], [81, 82], [83, 88], [89, 92], [92, 93], [93, 94], [94, 97], [97, 98], [99, 101], [102, 110], [111, 114], [115, 116], [117, 123], [124, 128], [129, 132], [133, 138], [139, 140], [141, 145], [146, 147], [148, 153], [154, 155], [156, 160], [161, 170], [171, 183], [184, 187], [187, 198], [199, 212], [213, 218], [219, 222], [223, 231], [232, 239], [240, 249], [250, 264], [264, 265]]}
{"doc_key": "ai-dev-303", "ner": [[6, 7, "misc"], [8, 8, "misc"], [14, 14, "person"], [17, 19, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 6, 7, "general-affiliation", "", false, false], [8, 8, 14, 14, "artifact", "", false, false], [8, 8, 17, 19, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Nel", "giugno", "2015", "ha", "debuttato", "il", "dramma", "fantascientifico", "Sense8", ",", "scritto", "e", "prodotto", "dai", "Wachowski", "e", "da", "J.", "Michael", "Straczynski", "."], "sentence-detokenized": "Nel giugno 2015 ha debuttato il dramma fantascientifico Sense8, scritto e prodotto dai Wachowski e da J. Michael Straczynski.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 18], [19, 28], [29, 31], [32, 38], [39, 55], [56, 62], [62, 63], [64, 71], [72, 73], [74, 82], [83, 86], [87, 96], [97, 98], [99, 101], [102, 104], [105, 112], [113, 124], [124, 125]]}
{"doc_key": "ai-dev-304", "ner": [[1, 1, "misc"], [7, 10, "product"], [30, 32, "misc"], [40, 40, "country"], [42, 42, "country"], [44, 44, "country"], [46, 46, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 1, 7, 10, "topic", "", false, false], [40, 40, 30, 32, "type-of", "", false, false], [42, 42, 30, 32, "type-of", "", false, false], [44, 44, 30, 32, "type-of", "", false, false], [46, 46, 30, 32, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Sebbene", "Eurotra", "non", "abbia", "mai", "fornito", "un", "sistema", "di", "traduzione", "automatica", "funzionante", ",", "il", "progetto", "ha", "avuto", "un", "impatto", "a", "lungo", "termine", "di", "vasta", "portata", "sulle", "nascenti", "industrie", "linguistiche", "degli", "Stati", "membri", "europei", ",", "in", "particolare", "nei", "paesi", "meridionali", "di", "Grecia", ",", "Italia", ",", "Spagna", "e", "Portogallo", "."], "sentence-detokenized": "Sebbene Eurotra non abbia mai fornito un sistema di traduzione automatica funzionante, il progetto ha avuto un impatto a lungo termine di vasta portata sulle nascenti industrie linguistiche degli Stati membri europei, in particolare nei paesi meridionali di Grecia, Italia, Spagna e Portogallo.", "token2charspan": [[0, 7], [8, 15], [16, 19], [20, 25], [26, 29], [30, 37], [38, 40], [41, 48], [49, 51], [52, 62], [63, 73], [74, 85], [85, 86], [87, 89], [90, 98], [99, 101], [102, 107], [108, 110], [111, 118], [119, 120], [121, 126], [127, 134], [135, 137], [138, 143], [144, 151], [152, 157], [158, 166], [167, 176], [177, 189], [190, 195], [196, 201], [202, 208], [209, 216], [216, 217], [218, 220], [221, 232], [233, 236], [237, 242], [243, 254], [255, 257], [258, 264], [264, 265], [266, 272], [272, 273], [274, 280], [281, 282], [283, 293], [293, 294]]}
{"doc_key": "ai-dev-305", "ner": [[0, 1, "algorithm"], [8, 9, "task"], [16, 18, "task"], [20, 20, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 0, 1, "usage", "", true, false], [16, 18, 8, 9, "named", "", false, false], [20, 20, 16, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["L'", "autoencoder", "\u00e8", "stato", "applicato", "con", "successo", "alla", "traduzione", "automatica", "delle", "lingue", "umane", ",", "solitamente", "definita", "traduzione", "automatica", "neurale", "(", "NMT", ")", "."], "sentence-detokenized": "L'autoencoder \u00e8 stato applicato con successo alla traduzione automatica delle lingue umane, solitamente definita traduzione automatica neurale (NMT).", "token2charspan": [[0, 2], [2, 13], [14, 15], [16, 21], [22, 31], [32, 35], [36, 44], [45, 49], [50, 60], [61, 71], [72, 77], [78, 84], [85, 90], [90, 91], [92, 103], [104, 112], [113, 123], [124, 134], [135, 142], [143, 144], [144, 147], [147, 148], [148, 149]]}
{"doc_key": "ai-dev-306", "ner": [[11, 14, "metrics"], [17, 19, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Esempi", "popolari", "di", "funzioni", "di", "fitness", "basate", "sulle", "probabilit\u00e0", "sono", "la", "stima", "della", "massima", "verosimiglianza", "e", "la", "perdita", "per", "cerniera", "."], "sentence-detokenized": "Esempi popolari di funzioni di fitness basate sulle probabilit\u00e0 sono la stima della massima verosimiglianza e la perdita per cerniera.", "token2charspan": [[0, 6], [7, 15], [16, 18], [19, 27], [28, 30], [31, 38], [39, 45], [46, 51], [52, 63], [64, 68], [69, 71], [72, 77], [78, 83], [84, 91], [92, 107], [108, 109], [110, 112], [113, 120], [121, 124], [125, 133], [133, 134]]}
{"doc_key": "ai-dev-307", "ner": [[0, 2, "field"], [14, 17, "task"], [20, 22, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 17, 0, 2, "part-of", "", false, false], [20, 22, 0, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Il", "data", "mining", "\u00e8", "un", "campo", "di", "studio", "correlato", ",", "che", "si", "concentra", "sull'", "analisi", "esplorativa", "dei", "dati", "attraverso", "l'", "apprendimento", "non", "supervisionato", "."], "sentence-detokenized": "Il data mining \u00e8 un campo di studio correlato, che si concentra sull'analisi esplorativa dei dati attraverso l'apprendimento non supervisionato.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 16], [17, 19], [20, 25], [26, 28], [29, 35], [36, 45], [45, 46], [47, 50], [51, 53], [54, 63], [64, 69], [69, 76], [77, 88], [89, 92], [93, 97], [98, 108], [109, 111], [111, 124], [125, 128], [129, 143], [143, 144]]}
{"doc_key": "ai-dev-308", "ner": [[0, 2, "algorithm"], [13, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 13, 15, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Il", "filtraggio", "collaborativo", "comprende", "tecniche", "per", "abbinare", "persone", "con", "interessi", "simili", "e", "creare", "sistemi", "di", "raccomandazione", "su", "questa", "base", "."], "sentence-detokenized": "Il filtraggio collaborativo comprende tecniche per abbinare persone con interessi simili e creare sistemi di raccomandazione su questa base.", "token2charspan": [[0, 2], [3, 13], [14, 27], [28, 37], [38, 46], [47, 50], [51, 59], [60, 67], [68, 71], [72, 81], [82, 88], [89, 90], [91, 97], [98, 105], [106, 108], [109, 124], [125, 127], [128, 134], [135, 139], [139, 140]]}
{"doc_key": "ai-dev-309", "ner": [[3, 10, "algorithm"], [16, 16, "programlang"], [18, 21, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 21, 3, 10, "type-of", "", false, false], [18, 21, 16, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Una", "serie", "di", "algoritmi", "di", "similarit\u00e0", "delle", "parole", "basati", "su", "WordNet", "sono", "implementati", "in", "un", "pacchetto", "Perl", "chiamato", "WordNet", ":", ":", "Similarity", "."], "sentence-detokenized": "Una serie di algoritmi di similarit\u00e0 delle parole basati su WordNet sono implementati in un pacchetto Perl chiamato WordNet:: Similarity.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 22], [23, 25], [26, 36], [37, 42], [43, 49], [50, 56], [57, 59], [60, 67], [68, 72], [73, 85], [86, 88], [89, 91], [92, 101], [102, 106], [107, 115], [116, 123], [123, 124], [124, 125], [126, 136], [136, 137]]}
{"doc_key": "ai-dev-310", "ner": [[9, 9, "conference"], [11, 11, "conference"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 11, 9, 9, "named", "", false, false], [15, 16, 9, 9, "temporal", "", false, false], [18, 19, 9, 9, "temporal", "", false, false], [21, 22, 9, 9, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Verr\u00e0", "discusso", "anche", "un", "altro", "lavoro", ",", "presentato", "al", "CVPR", "(", "CVPR", ")", "2000", "da", "Erik", "Miller", ",", "Nicholas", "Matsakis", "e", "Paul", "Viola", "."], "sentence-detokenized": "Verr\u00e0 discusso anche un altro lavoro, presentato al CVPR (CVPR) 2000 da Erik Miller, Nicholas Matsakis e Paul Viola.", "token2charspan": [[0, 5], [6, 14], [15, 20], [21, 23], [24, 29], [30, 36], [36, 37], [38, 48], [49, 51], [52, 56], [57, 58], [58, 62], [62, 63], [64, 68], [69, 71], [72, 76], [77, 83], [83, 84], [85, 93], [94, 102], [103, 104], [105, 109], [110, 115], [115, 116]]}
{"doc_key": "ai-dev-311", "ner": [[0, 0, "algorithm"], [8, 10, "misc"], [16, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 16, 18, "compare", "", false, false], [16, 18, 8, 10, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["QC", "non", "\u00e8", "stato", "valutato", "rispetto", "ai", "tradizionali", "algoritmi", "di", "clustering", "moderni", ",", "a", "parte", "l'", "indice", "di", "Jaccard", "."], "sentence-detokenized": "QC non \u00e8 stato valutato rispetto ai tradizionali algoritmi di clustering moderni, a parte l'indice di Jaccard.", "token2charspan": [[0, 2], [3, 6], [7, 8], [9, 14], [15, 23], [24, 32], [33, 35], [36, 48], [49, 58], [59, 61], [62, 72], [73, 80], [80, 81], [82, 83], [84, 89], [90, 92], [92, 98], [99, 101], [102, 109], [109, 110]]}
{"doc_key": "ai-dev-312", "ner": [[2, 6, "misc"], [14, 16, "misc"], [9, 10, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 16, 2, 6, "physical", "", false, false], [14, 16, 9, 10, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Durante", "il", "Campionato", "mondiale", "di", "robotica", "VEX", ",", "nella", "Freedom", "Hall", "si", "tiene", "la", "Parata", "delle", "Nazioni", ",", "alla", "quale", "partecipano", "centinaia", "di", "studenti", "provenienti", "da", "oltre", "30", "Paesi", "."], "sentence-detokenized": "Durante il Campionato mondiale di robotica VEX, nella Freedom Hall si tiene la Parata delle Nazioni, alla quale partecipano centinaia di studenti provenienti da oltre 30 Paesi.", "token2charspan": [[0, 7], [8, 10], [11, 21], [22, 30], [31, 33], [34, 42], [43, 46], [46, 47], [48, 53], [54, 61], [62, 66], [67, 69], [70, 75], [76, 78], [79, 85], [86, 91], [92, 99], [99, 100], [101, 105], [106, 111], [112, 123], [124, 133], [134, 136], [137, 145], [146, 157], [158, 160], [161, 166], [167, 169], [170, 175], [175, 176]]}
{"doc_key": "ai-dev-313", "ner": [[6, 9, "metrics"], [11, 11, "metrics"], [15, 17, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 6, 9, "named", "", false, false], [19, 19, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Altre", "misure", "di", "precisione", "sono", "il", "Single", "Word", "Error", "Rate", "(", "SWER", ")", "e", "il", "Command", "Success", "Rate", "(", "CSR", ")", "."], "sentence-detokenized": "Altre misure di precisione sono il Single Word Error Rate (SWER) e il Command Success Rate (CSR).", "token2charspan": [[0, 5], [6, 12], [13, 15], [16, 26], [27, 31], [32, 34], [35, 41], [42, 46], [47, 52], [53, 57], [58, 59], [59, 63], [63, 64], [65, 66], [67, 69], [70, 77], [78, 85], [86, 90], [91, 92], [92, 95], [95, 96], [96, 97]]}
{"doc_key": "ai-dev-314", "ner": [[9, 10, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Hanno", "presentato", "il", "loro", "metodo", "e", "i", "risultati", "al", "SIGGRAPH", "2000", "."], "sentence-detokenized": "Hanno presentato il loro metodo e i risultati al SIGGRAPH 2000.", "token2charspan": [[0, 5], [6, 16], [17, 19], [20, 24], [25, 31], [32, 33], [34, 35], [36, 45], [46, 48], [49, 57], [58, 62], [62, 63]]}
{"doc_key": "ai-dev-315", "ner": [[0, 2, "conference"], [7, 7, "misc"], [9, 13, "misc"], [16, 17, "conference"], [21, 25, "researcher"], [34, 35, "researcher"], [39, 41, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 7, 7, "origin", "", false, false], [7, 7, 16, 17, "physical", "", false, false], [7, 7, 16, 17, "temporal", "", false, false], [7, 7, 21, 25, "origin", "", false, false], [7, 7, 34, 35, "origin", "", false, false], [9, 13, 7, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["La", "conferenza", "KDD", "\u00e8", "nata", "dai", "workshop", "KDD", "(", "Knowledge", "Discovery", "and", "Data", "Mining", ")", "delle", "conferenze", "AAAI", ",", "avviati", "da", "Gregory", "I", ".", "Piatetsky-", "Shapiro", "nel", "1989", ",", "1991", "e", "1993", "e", "da", "Usama", "Fayyad", "nel", "1994", ".", "Machinery", "|", "ACM."], "sentence-detokenized": "La conferenza KDD \u00e8 nata dai workshop KDD (Knowledge Discovery and Data Mining) delle conferenze AAAI, avviati da Gregory I. Piatetsky-Shapiro nel 1989, 1991 e 1993 e da Usama Fayyad nel 1994. Machinery | ACM.", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 19], [20, 24], [25, 28], [29, 37], [38, 41], [42, 43], [43, 52], [53, 62], [63, 66], [67, 71], [72, 78], [78, 79], [80, 85], [86, 96], [97, 101], [101, 102], [103, 110], [111, 113], [114, 121], [122, 123], [123, 124], [125, 135], [135, 142], [143, 146], [147, 151], [151, 152], [153, 157], [158, 159], [160, 164], [165, 166], [167, 169], [170, 175], [176, 182], [183, 186], [187, 191], [191, 192], [193, 202], [203, 204], [205, 209]]}
{"doc_key": "ai-dev-316", "ner": [[5, 8, "conference"], [10, 10, "conference"], [14, 19, "organisation"], [21, 21, "organisation"], [25, 29, "conference"], [31, 31, "conference"], [35, 41, "conference"], [43, 43, "conference"], [47, 52, "conference"], [54, 54, "conference"], [58, 63, "conference"], [65, 65, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[10, 10, 5, 8, "named", "", false, false], [21, 21, 14, 19, "named", "", false, false], [31, 31, 25, 29, "named", "", false, false], [43, 43, 35, 41, "named", "", false, false], [54, 54, 47, 52, "named", "", false, false], [65, 65, 58, 63, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["\u00c8", "stato", "eletto", "membro", "dell'", "Association", "for", "Computing", "Machinery", "(", "ACM", ")", ",", "dell'", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", ",", "dell'", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", ",", "dell'", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", ",", "dell'", "American", "Association", "for", "Advancement", "of", "Science", "(", "AAAS", ")", "e", "della", "Society", "for", "Optics", "and", "Photonics", "Technology", "(", "SPIE", ")", "."], "sentence-detokenized": "\u00c8 stato eletto membro dell'Association for Computing Machinery (ACM), dell'Institute of Electrical and Electronics Engineers (IEEE), dell'International Association for Pattern Recognition (IAPR), dell'Association for the Advancement of Artificial Intelligence (AAAI), dell'American Association for Advancement of Science (AAAS) e della Society for Optics and Photonics Technology (SPIE).", "token2charspan": [[0, 1], [2, 7], [8, 14], [15, 21], [22, 27], [27, 38], [39, 42], [43, 52], [53, 62], [63, 64], [64, 67], [67, 68], [68, 69], [70, 75], [75, 84], [85, 87], [88, 98], [99, 102], [103, 114], [115, 124], [125, 126], [126, 130], [130, 131], [131, 132], [133, 138], [138, 151], [152, 163], [164, 167], [168, 175], [176, 187], [188, 189], [189, 193], [193, 194], [194, 195], [196, 201], [201, 212], [213, 216], [217, 220], [221, 232], [233, 235], [236, 246], [247, 259], [260, 261], [261, 265], [265, 266], [266, 267], [268, 273], [273, 281], [282, 293], [294, 297], [298, 309], [310, 312], [313, 320], [321, 322], [322, 326], [326, 327], [328, 329], [330, 335], [336, 343], [344, 347], [348, 354], [355, 358], [359, 368], [369, 379], [380, 381], [381, 385], [385, 386], [386, 387]]}
{"doc_key": "ai-dev-317", "ner": [[0, 2, "field"], [5, 6, "field"], [22, 23, "field"], [40, 41, "field"], [62, 66, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 22, 23, "named", "", false, false], [5, 6, 40, 41, "named", "", false, false], [40, 41, 62, 66, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["L'", "apprendimento", "automatico", "e", "il", "data", "mining", "utilizzano", "spesso", "gli", "stessi", "metodi", "e", "si", "sovrappongono", "in", "modo", "significativo", ",", "ma", "mentre", "l'", "apprendimento", "automatico", "si", "concentra", "sulla", "previsione", ",", "basata", "su", "propriet\u00e0", "note", "apprese", "dai", "dati", "di", "addestramento", ",", "il", "data", "mining", "si", "concentra", "sulla", "scoperta", "di", "propriet\u00e0", "(", "precedentemente", ")", "sconosciute", "nei", "dati", "(", "questa", "\u00e8", "la", "fase", "di", "analisi", "della", "scoperta", "della", "conoscenza", "nei", "database", ")", "."], "sentence-detokenized": "L'apprendimento automatico e il data mining utilizzano spesso gli stessi metodi e si sovrappongono in modo significativo, ma mentre l'apprendimento automatico si concentra sulla previsione, basata su propriet\u00e0 note apprese dai dati di addestramento, il data mining si concentra sulla scoperta di propriet\u00e0 (precedentemente) sconosciute nei dati (questa \u00e8 la fase di analisi della scoperta della conoscenza nei database).", "token2charspan": [[0, 2], [2, 15], [16, 26], [27, 28], [29, 31], [32, 36], [37, 43], [44, 54], [55, 61], [62, 65], [66, 72], [73, 79], [80, 81], [82, 84], [85, 98], [99, 101], [102, 106], [107, 120], [120, 121], [122, 124], [125, 131], [132, 134], [134, 147], [148, 158], [159, 161], [162, 171], [172, 177], [178, 188], [188, 189], [190, 196], [197, 199], [200, 209], [210, 214], [215, 222], [223, 226], [227, 231], [232, 234], [235, 248], [248, 249], [250, 252], [253, 257], [258, 264], [265, 267], [268, 277], [278, 283], [284, 292], [293, 295], [296, 305], [306, 307], [307, 322], [322, 323], [324, 335], [336, 339], [340, 344], [345, 346], [346, 352], [353, 354], [355, 357], [358, 362], [363, 365], [366, 373], [374, 379], [380, 388], [389, 394], [395, 405], [406, 409], [410, 418], [418, 419], [419, 420]]}
{"doc_key": "ai-dev-318", "ner": [[0, 0, "product"], [4, 4, "programlang"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 4, "general-affiliation", "", false, false], [0, 0, 4, 4, "related-to", "runs_on", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Indy", "\u00e8", "scritto", "in", "Java", "e", "funziona", "quindi", "sulla", "maggior", "parte", "dei", "sistemi", "operativi", "moderni", "."], "sentence-detokenized": "Indy \u00e8 scritto in Java e funziona quindi sulla maggior parte dei sistemi operativi moderni.", "token2charspan": [[0, 4], [5, 6], [7, 14], [15, 17], [18, 22], [23, 24], [25, 33], [34, 40], [41, 46], [47, 54], [55, 60], [61, 64], [65, 72], [73, 82], [83, 90], [90, 91]]}
{"doc_key": "ai-dev-319", "ner": [[0, 3, "algorithm"], [6, 9, "algorithm"], [11, 11, "algorithm"], [17, 21, "algorithm"], [23, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 6, 9, "type-of", "", true, false], [11, 11, 6, 9, "named", "", false, false], [17, 21, 6, 9, "type-of", "", true, false], [23, 23, 17, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["L'", "NMF", "\u00e8", "un'", "istanza", "della", "programmazione", "quadratica", "non", "negativa", "(", "NQP", ")", ",", "proprio", "come", "la", "macchina", "a", "vettori", "di", "supporto", "(", "SVM", ")", "."], "sentence-detokenized": "L'NMF \u00e8 un'istanza della programmazione quadratica non negativa (NQP), proprio come la macchina a vettori di supporto (SVM).", "token2charspan": [[0, 2], [2, 5], [6, 7], [8, 11], [11, 18], [19, 24], [25, 39], [40, 50], [51, 54], [55, 63], [64, 65], [65, 68], [68, 69], [69, 70], [71, 78], [79, 83], [84, 86], [87, 95], [96, 97], [98, 105], [106, 108], [109, 117], [118, 119], [119, 122], [122, 123], [123, 124]]}
{"doc_key": "ai-dev-320", "ner": [[7, 8, "misc"], [13, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 13, 16, "usage", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Il", "metodo", "si", "basa", "sulla", "stima", "delle", "probabilit\u00e0", "condizionali", "utilizzando", "il", "metodo", "della", "massima", "verosimiglianza", "non", "parametrica", "che", "porta", "a"], "sentence-detokenized": "Il metodo si basa sulla stima delle probabilit\u00e0 condizionali utilizzando il metodo della massima verosimiglianza non parametrica che porta a", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 17], [18, 23], [24, 29], [30, 35], [36, 47], [48, 60], [61, 72], [73, 75], [76, 82], [83, 88], [89, 96], [97, 112], [113, 116], [117, 128], [129, 132], [133, 138], [139, 140]]}
{"doc_key": "ai-dev-321", "ner": [[9, 9, "algorithm"], [12, 17, "algorithm"], [20, 22, "metrics"], [25, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["I", "concetti", "di", "base", "della", "stima", "spettrale", "comprendono", "l'", "autocorrelazione", ",", "la", "trasformata", "di", "Fourier", "multi", "-", "D", ",", "l'", "errore", "quadratico", "medio", "e", "l'", "entropia", "."], "sentence-detokenized": "I concetti di base della stima spettrale comprendono l'autocorrelazione, la trasformata di Fourier multi-D, l'errore quadratico medio e l'entropia.", "token2charspan": [[0, 1], [2, 10], [11, 13], [14, 18], [19, 24], [25, 30], [31, 40], [41, 52], [53, 55], [55, 71], [71, 72], [73, 75], [76, 87], [88, 90], [91, 98], [99, 104], [104, 105], [105, 106], [106, 107], [108, 110], [110, 116], [117, 127], [128, 133], [134, 135], [136, 138], [138, 146], [146, 147]]}
{"doc_key": "ai-dev-322", "ner": [[5, 6, "algorithm"], [12, 12, "field"], [15, 15, "algorithm"], [18, 21, "algorithm"], [24, 25, "task"], [28, 28, "field"], [31, 31, "field"], [34, 36, "task"], [39, 41, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 6, 12, 12, "part-of", "", false, false], [5, 6, 15, 15, "part-of", "", false, false], [5, 6, 18, 21, "part-of", "", false, false], [5, 6, 24, 25, "part-of", "", false, false], [5, 6, 28, 28, "part-of", "", false, false], [5, 6, 31, 31, "part-of", "", false, false], [5, 6, 34, 36, "part-of", "", false, false], [5, 6, 39, 41, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Le", "aree", "di", "applicazione", "dei", "metodi", "kernel", "sono", "diverse", "e", "comprendono", "la", "geostatistica", ",", "il", "kriging", ",", "la", "ponderazione", "inversa", "della", "distanza", ",", "la", "ricostruzione", "3D", ",", "la", "bioinformatica", ",", "la", "chemioinformatica", ",", "l'", "estrazione", "di", "informazioni", "e", "il", "riconoscimento", "della", "scrittura", "."], "sentence-detokenized": "Le aree di applicazione dei metodi kernel sono diverse e comprendono la geostatistica, il kriging, la ponderazione inversa della distanza, la ricostruzione 3D, la bioinformatica, la chemioinformatica, l'estrazione di informazioni e il riconoscimento della scrittura.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 23], [24, 27], [28, 34], [35, 41], [42, 46], [47, 54], [55, 56], [57, 68], [69, 71], [72, 85], [85, 86], [87, 89], [90, 97], [97, 98], [99, 101], [102, 114], [115, 122], [123, 128], [129, 137], [137, 138], [139, 141], [142, 155], [156, 158], [158, 159], [160, 162], [163, 177], [177, 178], [179, 181], [182, 199], [199, 200], [201, 203], [203, 213], [214, 216], [217, 229], [230, 231], [232, 234], [235, 249], [250, 255], [256, 265], [265, 266]]}
{"doc_key": "ai-dev-323", "ner": [[23, 23, "organisation"], [16, 20, "product"], [14, 14, "product"], [27, 27, "organisation"], [28, 31, "product"], [25, 25, "product"], [36, 37, "product"], [40, 42, "product"], [45, 50, "product"], [53, 57, "product"], [60, 62, "product"], [67, 68, "product"], [70, 76, "product"], [80, 82, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[16, 20, 23, 23, "artifact", "", false, false], [16, 20, 36, 37, "compare", "", false, false], [16, 20, 40, 42, "compare", "", false, false], [16, 20, 45, 50, "compare", "", false, false], [16, 20, 53, 57, "compare", "", false, false], [16, 20, 60, 62, "compare", "", false, false], [16, 20, 67, 68, "compare", "", false, false], [16, 20, 70, 76, "compare", "", false, false], [16, 20, 80, 82, "compare", "", false, false], [14, 14, 16, 20, "named", "", false, false], [28, 31, 27, 27, "artifact", "", false, false], [28, 31, 36, 37, "compare", "", false, false], [28, 31, 40, 42, "compare", "", false, false], [28, 31, 45, 50, "compare", "", false, false], [28, 31, 53, 57, "compare", "", false, false], [28, 31, 60, 62, "compare", "", false, false], [28, 31, 67, 68, "compare", "", false, false], [28, 31, 70, 76, "compare", "", false, false], [28, 31, 80, 82, "compare", "", false, false], [25, 25, 28, 31, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "sentence": ["I", "robot", "possono", "essere", "autonomi", "o", "semi", "-", "autonomi", "e", "vanno", "dagli", "umanoidi", "come", "ASIMO", "(", "Advanced", "Step", "in", "Innovative", "Mobility", ")", "di", "Honda", "e", "TOPIO", "(", "TOSY", "Ping", "Pong", "Playing", "Robot", ")", "di", "TOSY", "ai", "robot", "industriali", ",", "ai", "robot", "operatori", "medici", ",", "ai", "robot", "per", "l'", "assistenza", "ai", "pazienti", ",", "ai", "robot", "per", "la", "terapia", "cinofila", ",", "agli", "sciami", "di", "robot", "programmati", "collettivamente", ",", "ai", "droni", "UAV", "come", "MQ", "-", "1", "Predator", "di", "General", "Atomics", "e", "persino", "ai", "nano", "robot", "microscopici", "."], "sentence-detokenized": "I robot possono essere autonomi o semi-autonomi e vanno dagli umanoidi come ASIMO (Advanced Step in Innovative Mobility) di Honda e TOPIO (TOSY Ping Pong Playing Robot) di TOSY ai robot industriali, ai robot operatori medici, ai robot per l'assistenza ai pazienti, ai robot per la terapia cinofila, agli sciami di robot programmati collettivamente, ai droni UAV come MQ-1 Predator di General Atomics e persino ai nano robot microscopici.", "token2charspan": [[0, 1], [2, 7], [8, 15], [16, 22], [23, 31], [32, 33], [34, 38], [38, 39], [39, 47], [48, 49], [50, 55], [56, 61], [62, 70], [71, 75], [76, 81], [82, 83], [83, 91], [92, 96], [97, 99], [100, 110], [111, 119], [119, 120], [121, 123], [124, 129], [130, 131], [132, 137], [138, 139], [139, 143], [144, 148], [149, 153], [154, 161], [162, 167], [167, 168], [169, 171], [172, 176], [177, 179], [180, 185], [186, 197], [197, 198], [199, 201], [202, 207], [208, 217], [218, 224], [224, 225], [226, 228], [229, 234], [235, 238], [239, 241], [241, 251], [252, 254], [255, 263], [263, 264], [265, 267], [268, 273], [274, 277], [278, 280], [281, 288], [289, 297], [297, 298], [299, 303], [304, 310], [311, 313], [314, 319], [320, 331], [332, 347], [347, 348], [349, 351], [352, 357], [358, 361], [362, 366], [367, 369], [369, 370], [370, 371], [372, 380], [381, 383], [384, 391], [392, 399], [400, 401], [402, 409], [410, 412], [413, 417], [418, 423], [424, 436], [436, 437]]}
{"doc_key": "ai-dev-324", "ner": [[0, 0, "product"], [2, 3, "product"], [9, 15, "university"], [17, 18, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 27, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 17, 18, "artifact", "", false, false], [0, 0, 20, 21, "artifact", "", false, false], [0, 0, 23, 24, "artifact", "", false, false], [0, 0, 26, 27, "artifact", "", false, false], [2, 3, 17, 18, "artifact", "", false, false], [2, 3, 20, 21, "artifact", "", false, false], [2, 3, 23, 24, "artifact", "", false, false], [2, 3, 26, 27, "artifact", "", false, false], [17, 18, 9, 15, "physical", "", false, false], [20, 21, 9, 15, "physical", "", false, false], [23, 24, 9, 15, "physical", "", false, false], [26, 27, 9, 15, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Freddy", "e", "Freddy", "II", "erano", "robot", "costruiti", "presso", "la", "Scuola", "di", "Informatica", "dell'", "Universit\u00e0", "di", "Edimburgo", "da", "Pat", "Ambler", ",", "Robin", "Popplestone", ",", "Austin", "Tate", "e", "Donald", "Mitchie", ",", "ed", "erano", "in", "grado", "di", "assemblare", "blocchi", "di", "legno", "in", "un", "periodo", "di", "diverse", "ore", "."], "sentence-detokenized": "Freddy e Freddy II erano robot costruiti presso la Scuola di Informatica dell'Universit\u00e0 di Edimburgo da Pat Ambler, Robin Popplestone, Austin Tate e Donald Mitchie, ed erano in grado di assemblare blocchi di legno in un periodo di diverse ore.", "token2charspan": [[0, 6], [7, 8], [9, 15], [16, 18], [19, 24], [25, 30], [31, 40], [41, 47], [48, 50], [51, 57], [58, 60], [61, 72], [73, 78], [78, 88], [89, 91], [92, 101], [102, 104], [105, 108], [109, 115], [115, 116], [117, 122], [123, 134], [134, 135], [136, 142], [143, 147], [148, 149], [150, 156], [157, 164], [164, 165], [166, 168], [169, 174], [175, 177], [178, 183], [184, 186], [187, 197], [198, 205], [206, 208], [209, 214], [215, 217], [218, 220], [221, 228], [229, 231], [232, 239], [240, 243], [243, 244]]}
{"doc_key": "ai-dev-325", "ner": [[7, 7, "location"], [10, 10, "country"], [19, 19, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 10, 10, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Ha", "trascorso", "gli", "anni", "dell'", "infanzia", "a", "Parigi", ",", "in", "Francia", ",", "dove", "i", "suoi", "genitori", "erano", "emigrati", "dalla", "Lituania", "nei", "primi", "anni", "Venti", "."], "sentence-detokenized": "Ha trascorso gli anni dell'infanzia a Parigi, in Francia, dove i suoi genitori erano emigrati dalla Lituania nei primi anni Venti.", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 21], [22, 27], [27, 35], [36, 37], [38, 44], [44, 45], [46, 48], [49, 56], [56, 57], [58, 62], [63, 64], [65, 69], [70, 78], [79, 84], [85, 93], [94, 99], [100, 108], [109, 112], [113, 118], [119, 123], [124, 129], [129, 130]]}
{"doc_key": "ai-dev-326", "ner": [[4, 6, "researcher"], [9, 15, "misc"], [18, 21, "organisation"], [23, 25, "university"], [33, 37, "university"], [44, 45, "university"], [48, 50, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 6, 9, 15, "role", "", false, false], [4, 6, 23, 25, "physical", "", false, false], [4, 6, 33, 37, "role", "", false, false], [4, 6, 44, 45, "role", "", false, false], [4, 6, 48, 50, "role", "", false, false], [9, 15, 18, 21, "part-of", "", false, false], [18, 21, 23, 25, "part-of", "", false, false], [44, 45, 33, 37, "part-of", "", false, false], [48, 50, 33, 37, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In", "precedenza", ",", "il", "dottor", "Paulos", "ha", "ricoperto", "la", "cattedra", "di", "professore", "associato", "Cooper", "-", "Siegel", "presso", "la", "School", "of", "Computer", "Science", "della", "Carnegie", "Mellon", "University", ",", "dove", "era", "docente", "all'", "interno", "dello", "Human", "-", "Computer", "Interaction", "Institute", "con", "incarichi", "di", "cortesia", "presso", "il", "Robotics", "Institute", "e", "l'", "Entertainment", "Technology", "Center", "."], "sentence-detokenized": "In precedenza, il dottor Paulos ha ricoperto la cattedra di professore associato Cooper-Siegel presso la School of Computer Science della Carnegie Mellon University, dove era docente all'interno dello Human-Computer Interaction Institute con incarichi di cortesia presso il Robotics Institute e l'Entertainment Technology Center.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 17], [18, 24], [25, 31], [32, 34], [35, 44], [45, 47], [48, 56], [57, 59], [60, 70], [71, 80], [81, 87], [87, 88], [88, 94], [95, 101], [102, 104], [105, 111], [112, 114], [115, 123], [124, 131], [132, 137], [138, 146], [147, 153], [154, 164], [164, 165], [166, 170], [171, 174], [175, 182], [183, 187], [187, 194], [195, 200], [201, 206], [206, 207], [207, 215], [216, 227], [228, 237], [238, 241], [242, 251], [252, 254], [255, 263], [264, 270], [271, 273], [274, 282], [283, 292], [293, 294], [295, 297], [297, 310], [311, 321], [322, 328], [328, 329]]}
{"doc_key": "ai-dev-327", "ner": [[2, 3, "researcher"], [5, 7, "university"], [10, 12, "product"], [15, 19, "product"], [27, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 5, 7, "physical", "", false, false], [2, 3, 5, 7, "role", "", false, false], [10, 12, 2, 3, "artifact", "", false, false], [10, 12, 15, 19, "type-of", "", false, false], [10, 12, 27, 29, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Nel", "1969", "Victor", "Scheinman", "dell'", "Universit\u00e0", "di", "Stanford", "invent\u00f2", "il", "braccio", "di", "Stanford", ",", "un", "robot", "articolato", "a", "6", "assi", "completamente", "elettrico", ",", "progettato", "per", "consentire", "una", "soluzione", "a", "braccio", "."], "sentence-detokenized": "Nel 1969 Victor Scheinman dell'Universit\u00e0 di Stanford invent\u00f2 il braccio di Stanford, un robot articolato a 6 assi completamente elettrico, progettato per consentire una soluzione a braccio.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 25], [26, 31], [31, 41], [42, 44], [45, 53], [54, 61], [62, 64], [65, 72], [73, 75], [76, 84], [84, 85], [86, 88], [89, 94], [95, 105], [106, 107], [108, 109], [110, 114], [115, 128], [129, 138], [138, 139], [140, 150], [151, 154], [155, 165], [166, 169], [170, 179], [180, 181], [182, 189], [189, 190]]}
{"doc_key": "ai-dev-328", "ner": [[6, 6, "product"], [19, 20, "field"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 19, 20, "related-to", "", false, false], [6, 6, 23, 24, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "creazione", "e", "l'", "implementazione", "di", "chatbot", "\u00e8", "ancora", "un'", "area", "in", "via", "di", "sviluppo", ",", "fortemente", "legata", "all'", "intelligenza", "artificiale", "e", "all'", "apprendimento", "automatico", ",", "per", "cui", "le", "soluzioni", "fornite", ",", "pur", "presentando", "evidenti", "vantaggi", ",", "hanno", "alcune", "importanti", "limitazioni", "in", "termini", "di", "funzionalit\u00e0", "e", "casi", "d'", "uso", "."], "sentence-detokenized": "La creazione e l'implementazione di chatbot \u00e8 ancora un'area in via di sviluppo, fortemente legata all'intelligenza artificiale e all'apprendimento automatico, per cui le soluzioni fornite, pur presentando evidenti vantaggi, hanno alcune importanti limitazioni in termini di funzionalit\u00e0 e casi d'uso.", "token2charspan": [[0, 2], [3, 12], [13, 14], [15, 17], [17, 32], [33, 35], [36, 43], [44, 45], [46, 52], [53, 56], [56, 60], [61, 63], [64, 67], [68, 70], [71, 79], [79, 80], [81, 91], [92, 98], [99, 103], [103, 115], [116, 127], [128, 129], [130, 134], [134, 147], [148, 158], [158, 159], [160, 163], [164, 167], [168, 170], [171, 180], [181, 188], [188, 189], [190, 193], [194, 205], [206, 214], [215, 223], [223, 224], [225, 230], [231, 237], [238, 248], [249, 260], [261, 263], [264, 271], [272, 274], [275, 287], [288, 289], [290, 294], [295, 297], [297, 300], [300, 301]]}
{"doc_key": "ai-dev-329", "ner": [[11, 13, "university"], [8, 9, "product"], [24, 25, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 11, 13, "part-of", "", true, false], [24, 25, 8, 9, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "termini", "di", "risorse", "liberamente", "disponibili", ",", "il", "toolkit", "Sphinx", "della", "Carnegie", "Mellon", "University", "\u00e8", "un", "punto", "di", "partenza", "per", "imparare", "a", "conoscere", "il", "riconoscimento", "vocale", "e", "iniziare", "a", "sperimentare", "."], "sentence-detokenized": "In termini di risorse liberamente disponibili, il toolkit Sphinx della Carnegie Mellon University \u00e8 un punto di partenza per imparare a conoscere il riconoscimento vocale e iniziare a sperimentare.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 21], [22, 33], [34, 45], [45, 46], [47, 49], [50, 57], [58, 64], [65, 70], [71, 79], [80, 86], [87, 97], [98, 99], [100, 102], [103, 108], [109, 111], [112, 120], [121, 124], [125, 133], [134, 135], [136, 145], [146, 148], [149, 163], [164, 170], [171, 172], [173, 181], [182, 183], [184, 196], [196, 197]]}
{"doc_key": "ai-dev-330", "ner": [[0, 3, "misc"], [13, 20, "misc"], [22, 22, "misc"], [26, 26, "university"], [28, 28, "location"], [31, 31, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 3, 13, 20, "temporal", "", false, false], [22, 22, 13, 20, "named", "", false, false], [22, 22, 28, 28, "physical", "", false, false], [26, 26, 22, 22, "role", "", false, false], [28, 28, 31, 31, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["La", "competizione", "formale", "RoboCup", "\u00e8", "stata", "preceduta", "dal", "(", "spesso", "misconosciuto", ")", "primo", "torneo", "internazionale", "di", "calcio", "Micro", "Robot", "World", "Cup", "(", "MIROSOT", ")", "tenuto", "dal", "KAIST", "a", "Taejon", ",", "in", "Corea", ",", "nel", "novembre", "1996", "."], "sentence-detokenized": "La competizione formale RoboCup \u00e8 stata preceduta dal (spesso misconosciuto) primo torneo internazionale di calcio Micro Robot World Cup (MIROSOT) tenuto dal KAIST a Taejon, in Corea, nel novembre 1996.", "token2charspan": [[0, 2], [3, 15], [16, 23], [24, 31], [32, 33], [34, 39], [40, 49], [50, 53], [54, 55], [55, 61], [62, 75], [75, 76], [77, 82], [83, 89], [90, 104], [105, 107], [108, 114], [115, 120], [121, 126], [127, 132], [133, 136], [137, 138], [138, 145], [145, 146], [147, 153], [154, 157], [158, 163], [164, 165], [166, 172], [172, 173], [174, 176], [177, 182], [182, 183], [184, 187], [188, 196], [197, 201], [201, 202]]}
{"doc_key": "ai-dev-331", "ner": [[2, 5, "metrics"], [25, 27, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Oltre", "alla", "perdita", "standard", "della", "cerniera", "matematica", "(", "1", "-yf", "(", "x", ")", ")", "_", "+", "/", "per", "i", "dati", "etichettati", ",", "viene", "introdotta", "una", "funzione", "di", "perdita", "math", "(", "-", "1", "|", "f", "(", "x", ")", "|", ")", "_", "+", "/", "matematica", "viene", "introdotta", "per", "i", "dati", "non", "etichettati", "lasciando", "che", "mathy", "=", "nome", "dell'", "operatore", "{", "sign", "}", "{", "f", "(", "x", ")", "}", "/", "math", "."], "sentence-detokenized": "Oltre alla perdita standard della cerniera matematica (1-yf (x)) _ + / per i dati etichettati, viene introdotta una funzione di perdita math (-1 | f (x) |) _ + / matematica viene introdotta per i dati non etichettati lasciando che mathy = nome dell'operatore {sign} {f (x)} / math.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 27], [28, 33], [34, 42], [43, 53], [54, 55], [55, 56], [56, 59], [60, 61], [61, 62], [62, 63], [63, 64], [65, 66], [67, 68], [69, 70], [71, 74], [75, 76], [77, 81], [82, 93], [93, 94], [95, 100], [101, 111], [112, 115], [116, 124], [125, 127], [128, 135], [136, 140], [141, 142], [142, 143], [143, 144], [145, 146], [147, 148], [149, 150], [150, 151], [151, 152], [153, 154], [154, 155], [156, 157], [158, 159], [160, 161], [162, 172], [173, 178], [179, 189], [190, 193], [194, 195], [196, 200], [201, 204], [205, 216], [217, 226], [227, 230], [231, 236], [237, 238], [239, 243], [244, 249], [249, 258], [259, 260], [260, 264], [264, 265], [266, 267], [267, 268], [269, 270], [270, 271], [271, 272], [272, 273], [274, 275], [276, 280], [280, 281]]}
{"doc_key": "ai-dev-332", "ner": [[3, 3, "misc"], [9, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 9, 11, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "particolare", ",", "RLS", "\u00e8", "progettato", "per", "minimizzare", "l'", "errore", "quadratico", "medio", "tra", "i", "valori", "previsti", "e", "le", "etichette", "VERE", ",", "soggetto", "a", "regolarizzazione", "."], "sentence-detokenized": "In particolare, RLS \u00e8 progettato per minimizzare l'errore quadratico medio tra i valori previsti e le etichette VERE, soggetto a regolarizzazione.", "token2charspan": [[0, 2], [3, 14], [14, 15], [16, 19], [20, 21], [22, 32], [33, 36], [37, 48], [49, 51], [51, 57], [58, 68], [69, 74], [75, 78], [79, 80], [81, 87], [88, 96], [97, 98], [99, 101], [102, 111], [112, 116], [116, 117], [118, 126], [127, 128], [129, 145], [145, 146]]}
{"doc_key": "ai-dev-333", "ner": [[5, 8, "algorithm"], [11, 13, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 8, 11, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "sostanza", ",", "combina", "la", "stima", "della", "massima", "verosimiglianza", "con", "una", "procedura", "di", "regolarizzazione", "che", "favorisce", "i", "modelli", "pi\u00f9", "semplici", "rispetto", "a", "quelli", "pi\u00f9", "complessi", "."], "sentence-detokenized": "In sostanza, combina la stima della massima verosimiglianza con una procedura di regolarizzazione che favorisce i modelli pi\u00f9 semplici rispetto a quelli pi\u00f9 complessi.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 20], [21, 23], [24, 29], [30, 35], [36, 43], [44, 59], [60, 63], [64, 67], [68, 77], [78, 80], [81, 97], [98, 101], [102, 111], [112, 113], [114, 121], [122, 125], [126, 134], [135, 143], [144, 145], [146, 152], [153, 156], [157, 166], [166, 167]]}
{"doc_key": "ai-dev-334", "ner": [[1, 4, "metrics"], [9, 9, "metrics"], [11, 11, "metrics"], [13, 15, "misc"], [18, 20, "misc"], [32, 35, "algorithm"], [37, 41, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 9, 1, 4, "named", "", false, false], [11, 11, 1, 4, "named", "", false, false], [13, 15, 18, 20, "related-to", "", false, false], [13, 15, 32, 35, "related-to", "ratio", false, false], [32, 35, 37, 41, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Il", "tasso", "di", "vero", "positivo", "\u00e8", "noto", "anche", "come", "sensibilit\u00e0", ",", "richiamo", "o", "probabilit\u00e0", "di", "rilevamento", "rispetto", "alla", "soglia", "di", "discriminazione", ")", "della", "probabilit\u00e0", "di", "rilevamento", "sull'", "asse", "delle", "ordinate", "rispetto", "alla", "funzione", "di", "distribuzione", "cumulativa", "della", "probabilit\u00e0", "di", "falso", "allarme", "sull'", "asse", "delle", "ascisse", "."], "sentence-detokenized": "Il tasso di vero positivo \u00e8 noto anche come sensibilit\u00e0, richiamo o probabilit\u00e0 di rilevamento rispetto alla soglia di discriminazione) della probabilit\u00e0 di rilevamento sull'asse delle ordinate rispetto alla funzione di distribuzione cumulativa della probabilit\u00e0 di falso allarme sull'asse delle ascisse.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 16], [17, 25], [26, 27], [28, 32], [33, 38], [39, 43], [44, 55], [55, 56], [57, 65], [66, 67], [68, 79], [80, 82], [83, 94], [95, 103], [104, 108], [109, 115], [116, 118], [119, 134], [134, 135], [136, 141], [142, 153], [154, 156], [157, 168], [169, 174], [174, 178], [179, 184], [185, 193], [194, 202], [203, 207], [208, 216], [217, 219], [220, 233], [234, 244], [245, 250], [251, 262], [263, 265], [266, 271], [272, 279], [280, 285], [285, 289], [290, 295], [296, 303], [303, 304]]}
{"doc_key": "ai-dev-335", "ner": [[1, 1, "misc"], [3, 3, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 1, 1, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "inglese", ",", "WordNet", "\u00e8", "un", "esempio", "di", "rete", "semantica", "."], "sentence-detokenized": "In inglese, WordNet \u00e8 un esempio di rete semantica.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 19], [20, 21], [22, 24], [25, 32], [33, 35], [36, 40], [41, 50], [50, 51]]}
{"doc_key": "ai-dev-336", "ner": [[4, 7, "product"], [11, 13, "product"], [29, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[29, 30, 4, 7, "usage", "", false, false], [29, 30, 11, 13, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["L'", "uso", "prolungato", "di", "software", "di", "riconoscimento", "vocale", "in", "combinazione", "con", "elaboratori", "di", "testi", "ha", "mostrato", "benefici", "per", "il", "rafforzamento", "della", "memoria", "a", "breve", "termine", "in", "pazienti", "affetti", "da", "MAV", "cerebrale", "trattati", "con", "resezione", "."], "sentence-detokenized": "L'uso prolungato di software di riconoscimento vocale in combinazione con elaboratori di testi ha mostrato benefici per il rafforzamento della memoria a breve termine in pazienti affetti da MAV cerebrale trattati con resezione.", "token2charspan": [[0, 2], [2, 5], [6, 16], [17, 19], [20, 28], [29, 31], [32, 46], [47, 53], [54, 56], [57, 69], [70, 73], [74, 85], [86, 88], [89, 94], [95, 97], [98, 106], [107, 115], [116, 119], [120, 122], [123, 136], [137, 142], [143, 150], [151, 152], [153, 158], [159, 166], [167, 169], [170, 178], [179, 186], [187, 189], [190, 193], [194, 203], [204, 212], [213, 216], [217, 226], [226, 227]]}
{"doc_key": "ai-dev-337", "ner": [[6, 7, "researcher"], [9, 10, "researcher"], [12, 13, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["I", "suoi", "caporedattori", "fondatori", "sono", "stati", "Ron", "Sun", ",", "Vasant", "Honavar", "e", "Gregg", "Oden", "(", "dal", "1999", "al", "2014", ")", "."], "sentence-detokenized": "I suoi caporedattori fondatori sono stati Ron Sun, Vasant Honavar e Gregg Oden (dal 1999 al 2014).", "token2charspan": [[0, 1], [2, 6], [7, 20], [21, 30], [31, 35], [36, 41], [42, 45], [46, 49], [49, 50], [51, 57], [58, 65], [66, 67], [68, 73], [74, 78], [79, 80], [80, 83], [84, 88], [89, 91], [92, 96], [96, 97], [97, 98]]}
{"doc_key": "ai-dev-338", "ner": [[10, 11, "product"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 11, 16, 17, "opposite", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["La", "loro", "distinzione", "\"", "parallela", "\"", ",", "rispetto", "a", "un", "manipolatore", "seriale", ",", "\u00e8", "che", "l'", "effettore", "finale", "(", "o", "\"", "mano", "\"", ")", "di", "questo", "collegamento", "(", "o", "\"", "braccio", "\"", ")", "\u00e8", "direttamente", "collegato", "alla", "sua", "base", "da", "una", "serie", "di", "collegamenti", "(", "di", "solito", "tre", "o", "sei", ")", "separati", "e", "indipendenti", "che", "lavorano", "simultaneamente", "."], "sentence-detokenized": "La loro distinzione \"parallela\", rispetto a un manipolatore seriale, \u00e8 che l'effettore finale (o \"mano\") di questo collegamento (o \"braccio\") \u00e8 direttamente collegato alla sua base da una serie di collegamenti (di solito tre o sei) separati e indipendenti che lavorano simultaneamente.", "token2charspan": [[0, 2], [3, 7], [8, 19], [20, 21], [21, 30], [30, 31], [31, 32], [33, 41], [42, 43], [44, 46], [47, 59], [60, 67], [67, 68], [69, 70], [71, 74], [75, 77], [77, 86], [87, 93], [94, 95], [95, 96], [97, 98], [98, 102], [102, 103], [103, 104], [105, 107], [108, 114], [115, 127], [128, 129], [129, 130], [131, 132], [132, 139], [139, 140], [140, 141], [142, 143], [144, 156], [157, 166], [167, 171], [172, 175], [176, 180], [181, 183], [184, 187], [188, 193], [194, 196], [197, 209], [210, 211], [211, 213], [214, 220], [221, 224], [225, 226], [227, 230], [230, 231], [232, 240], [241, 242], [243, 255], [256, 259], [260, 268], [269, 284], [284, 285]]}
{"doc_key": "ai-dev-339", "ner": [[7, 8, "researcher"], [23, 24, "researcher"], [25, 27, "researcher"], [29, 30, "researcher"], [32, 33, "researcher"], [35, 36, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Il", "suo", "relatore", "\u00e8", "stato", "il", "professor", "Cordell", "Green", ",", "e", "la", "sua", "commissione", "per", "la", "tesi", "e", "l'", "orale", "comprendeva", "i", "professori", "Edward", "Feigenbaum", ",", "Joshua", "Lederberg", ",", "Paul", "Cohen", ",", "Allen", "Newell", "e", "Herbert", "Simon", "."], "sentence-detokenized": "Il suo relatore \u00e8 stato il professor Cordell Green, e la sua commissione per la tesi e l'orale comprendeva i professori Edward Feigenbaum, Joshua Lederberg, Paul Cohen, Allen Newell e Herbert Simon.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 17], [18, 23], [24, 26], [27, 36], [37, 44], [45, 50], [50, 51], [52, 53], [54, 56], [57, 60], [61, 72], [73, 76], [77, 79], [80, 84], [85, 86], [87, 89], [89, 94], [95, 106], [107, 108], [109, 119], [120, 126], [127, 137], [137, 138], [139, 145], [146, 155], [155, 156], [157, 161], [162, 167], [167, 168], [169, 174], [175, 181], [182, 183], [184, 191], [192, 197], [197, 198]]}
{"doc_key": "ai-dev-340", "ner": [[4, 6, "metrics"], [9, 11, "metrics"], [14, 16, "metrics"], [19, 21, "metrics"], [24, 26, "metrics"], [29, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Tali", "funzioni", "includono", "l'", "errore", "quadratico", "medio", ",", "l'", "errore", "quadratico", "medio", ",", "l'", "errore", "assoluto", "medio", ",", "l'", "errore", "quadratico", "relativo", ",", "l'", "errore", "quadratico", "relativo", ",", "l'", "errore", "assoluto", "relativo", "e", "altri", "."], "sentence-detokenized": "Tali funzioni includono l'errore quadratico medio, l'errore quadratico medio, l'errore assoluto medio, l'errore quadratico relativo, l'errore quadratico relativo, l'errore assoluto relativo e altri.", "token2charspan": [[0, 4], [5, 13], [14, 23], [24, 26], [26, 32], [33, 43], [44, 49], [49, 50], [51, 53], [53, 59], [60, 70], [71, 76], [76, 77], [78, 80], [80, 86], [87, 95], [96, 101], [101, 102], [103, 105], [105, 111], [112, 122], [123, 131], [131, 132], [133, 135], [135, 141], [142, 152], [153, 161], [161, 162], [163, 165], [165, 171], [172, 180], [181, 189], [190, 191], [192, 197], [197, 198]]}
{"doc_key": "ai-dev-341", "ner": [[3, 3, "programlang"], [5, 5, "programlang"], [7, 7, "product"], [9, 9, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Esistono", "legami", "in", "Python", ",", "Java", "e", "MATLAB", "/", "OCTAVE."], "sentence-detokenized": "Esistono legami in Python, Java e MATLAB / OCTAVE.", "token2charspan": [[0, 8], [9, 15], [16, 18], [19, 25], [25, 26], [27, 31], [32, 33], [34, 40], [41, 42], [43, 50]]}
{"doc_key": "ai-dev-342", "ner": [[3, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Un'", "implementazione", "in", "MATLAB", "\u00e8", "disponibile", "sul", "sito", "."], "sentence-detokenized": "Un'implementazione in MATLAB \u00e8 disponibile sul sito.", "token2charspan": [[0, 3], [3, 18], [19, 21], [22, 28], [29, 30], [31, 42], [43, 46], [47, 51], [51, 52]]}
{"doc_key": "ai-dev-343", "ner": [[0, 1, "researcher"], [8, 9, "field"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 24, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 0, 1, "origin", "", false, false], [8, 9, 13, 14, "origin", "", false, false], [8, 9, 16, 17, "origin", "", false, false], [8, 9, 19, 20, "origin", "", false, false], [8, 9, 22, 24, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["John", "McCarthy", "\u00e8", "uno", "dei", "padri", "fondatori", "dell'", "intelligenza", "artificiale", ",", "insieme", "ad", "Alan", "Turing", ",", "Marvin", "Minsky", ",", "Allen", "Newell", "e", "Herbert", "A.", "Simon", "."], "sentence-detokenized": "John McCarthy \u00e8 uno dei padri fondatori dell'intelligenza artificiale, insieme ad Alan Turing, Marvin Minsky, Allen Newell e Herbert A. Simon.", "token2charspan": [[0, 4], [5, 13], [14, 15], [16, 19], [20, 23], [24, 29], [30, 39], [40, 45], [45, 57], [58, 69], [69, 70], [71, 78], [79, 81], [82, 86], [87, 93], [93, 94], [95, 101], [102, 108], [108, 109], [110, 115], [116, 122], [123, 124], [125, 132], [133, 135], [136, 141], [141, 142]]}
{"doc_key": "ai-dev-344", "ner": [[10, 11, "product"], [21, 22, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Un", "manipolatore", "parallelo", "\u00e8", "un", "sistema", "meccanico", "che", "utilizza", "diversi", "manipolatori", "seriali", "per", "supportare", "un'", "unica", "piattaforma", ",", "o", "un", "unico", "dispositivo", "finale", "."], "sentence-detokenized": "Un manipolatore parallelo \u00e8 un sistema meccanico che utilizza diversi manipolatori seriali per supportare un'unica piattaforma, o un unico dispositivo finale.", "token2charspan": [[0, 2], [3, 15], [16, 25], [26, 27], [28, 30], [31, 38], [39, 48], [49, 52], [53, 61], [62, 69], [70, 82], [83, 90], [91, 94], [95, 105], [106, 109], [109, 114], [115, 126], [126, 127], [128, 129], [130, 132], [133, 138], [139, 150], [151, 157], [157, 158]]}
{"doc_key": "ai-dev-345", "ner": [[0, 0, "product"], [5, 7, "task"], [9, 9, "product"], [11, 16, "product"], [26, 26, "misc"], [29, 29, "misc"], [32, 33, "misc"], [36, 41, "task"], [44, 47, "product"], [50, 51, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[9, 9, 0, 0, "part-of", "", false, false], [9, 9, 5, 7, "type-of", "", false, false], [11, 16, 9, 9, "named", "", false, false], [26, 26, 9, 9, "part-of", "", false, false], [29, 29, 9, 9, "part-of", "", false, false], [32, 33, 9, 9, "part-of", "", false, false], [36, 41, 9, 9, "part-of", "", false, false], [44, 47, 9, 9, "part-of", "", false, false], [50, 51, 9, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["GATE", "include", "un", "sistema", "di", "estrazione", "delle", "informazioni", "chiamato", "ANNIE", "(", "A", "Nearly-", "New", "Information", "Extraction", "System", ")", ",", "un", "insieme", "di", "moduli", "che", "comprende", "un", "tokenizer", ",", "un", "gazetteer", ",", "un", "sentence", "splitter", ",", "un", "Part", "-", "of", "-", "speech", "tagging", ",", "un", "Named", "entity", "recognition", "transducer", "e", "un", "coreference", "tagger", "."], "sentence-detokenized": "GATE include un sistema di estrazione delle informazioni chiamato ANNIE (A Nearly-New Information Extraction System), un insieme di moduli che comprende un tokenizer, un gazetteer, un sentence splitter, un Part-of-speech tagging, un Named entity recognition transducer e un coreference tagger.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 23], [24, 26], [27, 37], [38, 43], [44, 56], [57, 65], [66, 71], [72, 73], [73, 74], [75, 82], [82, 85], [86, 97], [98, 108], [109, 115], [115, 116], [116, 117], [118, 120], [121, 128], [129, 131], [132, 138], [139, 142], [143, 152], [153, 155], [156, 165], [165, 166], [167, 169], [170, 179], [179, 180], [181, 183], [184, 192], [193, 201], [201, 202], [203, 205], [206, 210], [210, 211], [211, 213], [213, 214], [214, 220], [221, 228], [228, 229], [230, 232], [233, 238], [239, 245], [246, 257], [258, 268], [269, 270], [271, 273], [274, 285], [286, 292], [292, 293]]}
{"doc_key": "ai-dev-346", "ner": [[4, 7, "university"], [18, 19, "country"], [25, 28, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Si", "\u00e8", "laureato", "all'", "Universit\u00e0", "Statale", "di", "Mosca", "e", ",", "nel", "novembre", "1978", ",", "\u00e8", "partito", "per", "gli", "Stati", "Uniti", "grazie", "all'", "intervento", "personale", "del", "senatore", "Edward", "M.", "Kennedy", "."], "sentence-detokenized": "Si \u00e8 laureato all'Universit\u00e0 Statale di Mosca e, nel novembre 1978, \u00e8 partito per gli Stati Uniti grazie all'intervento personale del senatore Edward M. Kennedy.", "token2charspan": [[0, 2], [3, 4], [5, 13], [14, 18], [18, 28], [29, 36], [37, 39], [40, 45], [46, 47], [47, 48], [49, 52], [53, 61], [62, 66], [66, 67], [68, 69], [70, 77], [78, 81], [82, 85], [86, 91], [92, 97], [98, 104], [105, 109], [109, 119], [120, 129], [130, 133], [134, 142], [143, 149], [150, 152], [153, 160], [160, 161]]}
{"doc_key": "ai-dev-347", "ner": [[4, 6, "organisation"], [10, 14, "misc"], [20, 20, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 10, 14, "win-defeat", "", false, false], [10, 14, 20, 20, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Nel", "2017", ",", "il", "team", "DeepMind", "AlphaGo", "ha", "ricevuto", "la", "medaglia", "inaugurale", "IJCAI", "Marvin", "Minsky", "per", "gli", "Outstanding", "Achievements", "in", "AI", "."], "sentence-detokenized": "Nel 2017, il team DeepMind AlphaGo ha ricevuto la medaglia inaugurale IJCAI Marvin Minsky per gli Outstanding Achievements in AI.", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 12], [13, 17], [18, 26], [27, 34], [35, 37], [38, 46], [47, 49], [50, 58], [59, 69], [70, 75], [76, 82], [83, 89], [90, 93], [94, 97], [98, 109], [110, 122], [123, 125], [126, 128], [128, 129]]}
{"doc_key": "ai-dev-348", "ner": [[6, 7, "misc"], [10, 10, "misc"], [15, 15, "misc"], [26, 26, "misc"], [32, 32, "misc"], [37, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 7, 10, 10, "related-to", "is_recorded_by", false, false], [10, 10, 15, 15, "cause-effect", "", false, false], [10, 10, 15, 15, "physical", "", false, false], [10, 10, 26, 26, "physical", "", false, false], [10, 10, 37, 37, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Altri", "modi", "in", "cui", "si", "registrano", "propagazioni", "anomale", "sono", "i", "troposcatter", "che", "causano", "irregolarit\u00e0", "nella", "troposfera", ",", "lo", "scattering", "dovuto", "alle", "meteore", ",", "la", "rifrazione", "nelle", "regioni", "e", "negli", "strati", "ionizzati", "della", "ionosfera", "e", "la", "riflessione", "dalla", "ionosfera", "."], "sentence-detokenized": "Altri modi in cui si registrano propagazioni anomale sono i troposcatter che causano irregolarit\u00e0 nella troposfera, lo scattering dovuto alle meteore, la rifrazione nelle regioni e negli strati ionizzati della ionosfera e la riflessione dalla ionosfera.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 17], [18, 20], [21, 31], [32, 44], [45, 52], [53, 57], [58, 59], [60, 72], [73, 76], [77, 84], [85, 97], [98, 103], [104, 114], [114, 115], [116, 118], [119, 129], [130, 136], [137, 141], [142, 149], [149, 150], [151, 153], [154, 164], [165, 170], [171, 178], [179, 180], [181, 186], [187, 193], [194, 203], [204, 209], [210, 219], [220, 221], [222, 224], [225, 236], [237, 242], [243, 252], [252, 253]]}
{"doc_key": "ai-dev-349", "ner": [[0, 4, "field"], [6, 6, "field"], [12, 12, "field"], [15, 15, "field"], [18, 20, "field"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 4, 12, 12, "part-of", "", false, false], [0, 4, 15, 15, "part-of", "", false, false], [0, 4, 18, 20, "part-of", "", false, false], [0, 4, 23, 24, "part-of", "", false, false], [6, 6, 0, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["L'", "elaborazione", "del", "linguaggio", "naturale", "(", "NLP", ")", "\u00e8", "un", "sottocampo", "della", "linguistica", ",", "dell'", "informatica", ",", "dell'", "ingegneria", "dell'", "informazione", "e", "dell'", "intelligenza", "artificiale", "che", "si", "occupa", "delle", "interazioni", "tra", "computer", "e", "linguaggi", "umani", "(", "naturali", ")", ",", "in", "particolare", "di", "come", "programmare", "i", "computer", "per", "elaborare", "e", "analizzare", "grandi", "quantit\u00e0", "di", "dati", "in", "linguaggio", "naturale", "."], "sentence-detokenized": "L'elaborazione del linguaggio naturale (NLP) \u00e8 un sottocampo della linguistica, dell'informatica, dell'ingegneria dell'informazione e dell'intelligenza artificiale che si occupa delle interazioni tra computer e linguaggi umani (naturali), in particolare di come programmare i computer per elaborare e analizzare grandi quantit\u00e0 di dati in linguaggio naturale.", "token2charspan": [[0, 2], [2, 14], [15, 18], [19, 29], [30, 38], [39, 40], [40, 43], [43, 44], [45, 46], [47, 49], [50, 60], [61, 66], [67, 78], [78, 79], [80, 85], [85, 96], [96, 97], [98, 103], [103, 113], [114, 119], [119, 131], [132, 133], [134, 139], [139, 151], [152, 163], [164, 167], [168, 170], [171, 177], [178, 183], [184, 195], [196, 199], [200, 208], [209, 210], [211, 220], [221, 226], [227, 228], [228, 236], [236, 237], [237, 238], [239, 241], [242, 253], [254, 256], [257, 261], [262, 273], [274, 275], [276, 284], [285, 288], [289, 298], [299, 300], [301, 311], [312, 318], [319, 327], [328, 330], [331, 335], [336, 338], [339, 349], [350, 358], [358, 359]]}
{"doc_key": "ai-dev-350", "ner": [[9, 10, "organisation"], [13, 14, "organisation"], [16, 16, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Altri", "gruppi", "attivi", "sul", "clima", "guidati", "da", "giovani", "sono", "Extinction", "Rebellion", ",", "il", "Sunrise", "Movement", ",", "SustainUS", "e", "altri", "che", "lavorano", "a", "livello", "transnazionale", "e", "locale", "."], "sentence-detokenized": "Altri gruppi attivi sul clima guidati da giovani sono Extinction Rebellion, il Sunrise Movement, SustainUS e altri che lavorano a livello transnazionale e locale.", "token2charspan": [[0, 5], [6, 12], [13, 19], [20, 23], [24, 29], [30, 37], [38, 40], [41, 48], [49, 53], [54, 64], [65, 74], [74, 75], [76, 78], [79, 86], [87, 95], [95, 96], [97, 106], [107, 108], [109, 114], [115, 118], [119, 127], [128, 129], [130, 137], [138, 152], [153, 154], [155, 161], [161, 162]]}
