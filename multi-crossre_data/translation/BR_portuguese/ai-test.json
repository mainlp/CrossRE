{"doc_key": "ai-test-1", "ner": [[7, 9, "algorithm"], [12, 14, "algorithm"], [16, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["As", "abordagens", "t\u00edpicas", "de", "modelos", "generativos", "incluem", "classificadores", "Bayes", "ing\u00eanuos", ",", "modelos", "de", "misturas", "Gaussianas", ",", "autoencoders", "variacionais", "e", "outros", "."], "sentence-detokenized": "As abordagens t\u00edpicas de modelos generativos incluem classificadores Bayes ing\u00eanuos, modelos de misturas Gaussianas, autoencoders variacionais e outros.", "token2charspan": [[0, 2], [3, 13], [14, 21], [22, 24], [25, 32], [33, 44], [45, 52], [53, 68], [69, 74], [75, 83], [83, 84], [85, 92], [93, 95], [96, 104], [105, 115], [115, 116], [117, 129], [130, 142], [143, 144], [145, 151], [151, 152]]}
{"doc_key": "ai-test-2", "ner": [[7, 8, "organisation"], [13, 13, "conference"], [16, 22, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 13, 13, "role", "", false, false], [16, 22, 13, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Finalmente", ",", "a", "cada", "dois", "anos", ",", "a", "ELRA", "organiza", "uma", "grande", "confer\u00eancia", "LREC", ",", "a", "Confer\u00eancia", "Internacional", "de", "Avalia\u00e7\u00e3o", "e", "Recursos", "Lingu\u00edsticos", "."], "sentence-detokenized": "Finalmente, a cada dois anos, a ELRA organiza uma grande confer\u00eancia LREC, a Confer\u00eancia Internacional de Avalia\u00e7\u00e3o e Recursos Lingu\u00edsticos.", "token2charspan": [[0, 10], [10, 11], [12, 13], [14, 18], [19, 23], [24, 28], [28, 29], [30, 31], [32, 36], [37, 45], [46, 49], [50, 56], [57, 68], [69, 73], [73, 74], [75, 76], [77, 88], [89, 102], [103, 105], [106, 115], [116, 117], [118, 126], [127, 139], [139, 140]]}
{"doc_key": "ai-test-3", "ner": [[6, 10, "algorithm"], [13, 13, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "tarefa", "geralmente", "\u00e9", "derivar", "a", "estimativa", "de", "m\u00e1xima", "probabilidade", "dos", "par\u00e2metros", "do", "HMM", ",", "dadas", "as", "seq\u00fc\u00eancias", "de", "sa\u00edda", "."], "sentence-detokenized": "A tarefa geralmente \u00e9 derivar a estimativa de m\u00e1xima probabilidade dos par\u00e2metros do HMM, dadas as seq\u00fc\u00eancias de sa\u00edda.", "token2charspan": [[0, 1], [2, 8], [9, 19], [20, 21], [22, 29], [30, 31], [32, 42], [43, 45], [46, 52], [53, 66], [67, 70], [71, 81], [82, 84], [85, 88], [88, 89], [90, 95], [96, 98], [99, 109], [110, 112], [113, 118], [118, 119]]}
{"doc_key": "ai-test-4", "ner": [[3, 4, "algorithm"], [7, 10, "algorithm"], [16, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 16, 16, "compare", "", false, false], [7, 10, 16, 16, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Ao", "contr\u00e1rio", "das", "redes", "neurais", "e", "da", "m\u00e1quina", "vetorial", "de", "suporte", ",", "o", "processo", "de", "treinamento", "AdaBoost", "seleciona", "apenas", "as", "caracter\u00edsticas", "conhecidas", "para", "melhorar", "o", "poder", "preditivo", "do", "modelo", ",", "reduzindo", "a", "dimensionalidade", "e", "melhorando", "potencialmente", "o", "tempo", "de", "execu\u00e7\u00e3o", ",", "pois", "as", "caracter\u00edsticas", "irrelevantes", "n\u00e3o", "precisam", "ser", "computadas", "."], "sentence-detokenized": "Ao contr\u00e1rio das redes neurais e da m\u00e1quina vetorial de suporte, o processo de treinamento AdaBoost seleciona apenas as caracter\u00edsticas conhecidas para melhorar o poder preditivo do modelo, reduzindo a dimensionalidade e melhorando potencialmente o tempo de execu\u00e7\u00e3o, pois as caracter\u00edsticas irrelevantes n\u00e3o precisam ser computadas.", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 22], [23, 30], [31, 32], [33, 35], [36, 43], [44, 52], [53, 55], [56, 63], [63, 64], [65, 66], [67, 75], [76, 78], [79, 90], [91, 99], [100, 109], [110, 116], [117, 119], [120, 135], [136, 146], [147, 151], [152, 160], [161, 162], [163, 168], [169, 178], [179, 181], [182, 188], [188, 189], [190, 199], [200, 201], [202, 218], [219, 220], [221, 231], [232, 246], [247, 248], [249, 254], [255, 257], [258, 266], [266, 267], [268, 272], [273, 275], [276, 291], [292, 304], [305, 308], [309, 317], [318, 321], [322, 332], [332, 333]]}
{"doc_key": "ai-test-5", "ner": [[0, 0, "misc"], [10, 11, "misc"], [13, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 10, 11, "part-of", "", false, false], [10, 11, 13, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Troponymy", "\u00e9", "uma", "das", "rela\u00e7\u00f5es", "poss\u00edveis", "entre", "os", "verbos", "na", "rede", "sem\u00e2ntica", "do", "banco", "de", "dados", "do", "WordNet", "."], "sentence-detokenized": "Troponymy \u00e9 uma das rela\u00e7\u00f5es poss\u00edveis entre os verbos na rede sem\u00e2ntica do banco de dados do WordNet.", "token2charspan": [[0, 9], [10, 11], [12, 15], [16, 19], [20, 28], [29, 38], [39, 44], [45, 47], [48, 54], [55, 57], [58, 62], [63, 72], [73, 75], [76, 81], [82, 84], [85, 90], [91, 93], [94, 101], [101, 102]]}
{"doc_key": "ai-test-6", "ner": [[10, 12, "task"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 12, 14, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Uma", "linguagem", "de", "enquadramento", "\u00e9", "uma", "tecnologia", "utilizada", "para", "a", "representa\u00e7\u00e3o", "do", "conhecimento", "em", "intelig\u00eancia", "artificial", "."], "sentence-detokenized": "Uma linguagem de enquadramento \u00e9 uma tecnologia utilizada para a representa\u00e7\u00e3o do conhecimento em intelig\u00eancia artificial.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 30], [31, 32], [33, 36], [37, 47], [48, 57], [58, 62], [63, 64], [65, 78], [79, 81], [82, 94], [95, 97], [98, 110], [111, 121], [121, 122]]}
{"doc_key": "ai-test-7", "ner": [[0, 1, "metrics"], [5, 6, "metrics"], [11, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 5, 6, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["O", "NIST", "tamb\u00e9m", "difere", "da", "avalia\u00e7\u00e3o", "bil\u00edngue", "em", "seu", "c\u00e1lculo", "da", "penalidade", "de", "brevidade", "na", "medida", "em", "que", "pequenas", "varia\u00e7\u00f5es", "no", "comprimento", "da", "tradu\u00e7\u00e3o", "n\u00e3o", "afetam", "tanto", "a", "pontua\u00e7\u00e3o", "geral", "."], "sentence-detokenized": "O NIST tamb\u00e9m difere da avalia\u00e7\u00e3o bil\u00edngue em seu c\u00e1lculo da penalidade de brevidade na medida em que pequenas varia\u00e7\u00f5es no comprimento da tradu\u00e7\u00e3o n\u00e3o afetam tanto a pontua\u00e7\u00e3o geral.", "token2charspan": [[0, 1], [2, 6], [7, 13], [14, 20], [21, 23], [24, 33], [34, 42], [43, 45], [46, 49], [50, 57], [58, 60], [61, 71], [72, 74], [75, 84], [85, 87], [88, 94], [95, 97], [98, 101], [102, 110], [111, 120], [121, 123], [124, 135], [136, 138], [139, 147], [148, 151], [152, 158], [159, 164], [165, 166], [167, 176], [177, 182], [182, 183]]}
{"doc_key": "ai-test-8", "ner": [[20, 21, "algorithm"], [24, 26, "algorithm"], [40, 41, "field"], [51, 53, "algorithm"], [55, 58, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[20, 21, 40, 41, "usage", "", false, false], [24, 26, 40, 41, "usage", "", false, false], [51, 53, 40, 41, "type-of", "", false, false], [55, 58, 40, 41, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["O", "modelo", "\u00e9", "inicialmente", "adequado", "a", "um", "conjunto", "de", "dados", "de", "treinamento", ",", "O", "modelo", "(", "por", "exemplo", ",", "uma", "rede", "neural", "ou", "um", "classificador", "Bayes", "ing\u00eanuo", ")", "\u00e9", "treinado", "no", "conjunto", "de", "dados", "de", "treinamento", "usando", "um", "m\u00e9todo", "de", "aprendizado", "supervisionado", ",", "por", "exemplo", ",", "usando", "m\u00e9todos", "de", "otimiza\u00e7\u00e3o", "como", "descida", "de", "gradiente", "ou", "descida", "de", "gradiente", "estoc\u00e1stico", "."], "sentence-detokenized": "O modelo \u00e9 inicialmente adequado a um conjunto de dados de treinamento, O modelo (por exemplo, uma rede neural ou um classificador Bayes ing\u00eanuo) \u00e9 treinado no conjunto de dados de treinamento usando um m\u00e9todo de aprendizado supervisionado, por exemplo, usando m\u00e9todos de otimiza\u00e7\u00e3o como descida de gradiente ou descida de gradiente estoc\u00e1stico.", "token2charspan": [[0, 1], [2, 8], [9, 10], [11, 23], [24, 32], [33, 34], [35, 37], [38, 46], [47, 49], [50, 55], [56, 58], [59, 70], [70, 71], [72, 73], [74, 80], [81, 82], [82, 85], [86, 93], [93, 94], [95, 98], [99, 103], [104, 110], [111, 113], [114, 116], [117, 130], [131, 136], [137, 144], [144, 145], [146, 147], [148, 156], [157, 159], [160, 168], [169, 171], [172, 177], [178, 180], [181, 192], [193, 199], [200, 202], [203, 209], [210, 212], [213, 224], [225, 239], [239, 240], [241, 244], [245, 252], [252, 253], [254, 260], [261, 268], [269, 271], [272, 282], [283, 287], [288, 295], [296, 298], [299, 308], [309, 311], [312, 319], [320, 322], [323, 332], [333, 344], [344, 345]]}
{"doc_key": "ai-test-9", "ner": [[0, 0, "product"], [7, 9, "task"], [11, 11, "task"], [13, 16, "task"], [18, 20, "task"], [29, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 9, 0, 0, "usage", "", true, false], [11, 11, 0, 0, "usage", "", true, false], [13, 16, 0, 0, "usage", "", true, false], [18, 20, 0, 0, "usage", "", true, false], [29, 32, 0, 0, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["FrameNet", "tem", "sido", "utilizado", "em", "aplica\u00e7\u00f5es", "como", "resposta", "a", "perguntas", ",", "par\u00e1frases", ",", "reconhecimento", "de", "vincula\u00e7\u00e3o", "textual", "e", "extra\u00e7\u00e3o", "de", "informa\u00e7\u00f5es", ",", "diretamente", "ou", "por", "meio", "de", "ferramentas", "de", "etiquetagem", "de", "papel", "sem\u00e2ntico", "."], "sentence-detokenized": "FrameNet tem sido utilizado em aplica\u00e7\u00f5es como resposta a perguntas, par\u00e1frases, reconhecimento de vincula\u00e7\u00e3o textual e extra\u00e7\u00e3o de informa\u00e7\u00f5es, diretamente ou por meio de ferramentas de etiquetagem de papel sem\u00e2ntico.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 27], [28, 30], [31, 41], [42, 46], [47, 55], [56, 57], [58, 67], [67, 68], [69, 79], [79, 80], [81, 95], [96, 98], [99, 109], [110, 117], [118, 119], [120, 128], [129, 131], [132, 143], [143, 144], [145, 156], [157, 159], [160, 163], [164, 168], [169, 171], [172, 183], [184, 186], [187, 198], [199, 201], [202, 207], [208, 217], [217, 218]]}
{"doc_key": "ai-test-10", "ner": [[4, 10, "field"], [12, 12, "misc"], [17, 17, "product"], [20, 22, "misc"], [27, 27, "product"], [30, 31, "field"], [36, 36, "product"], [39, 42, "misc"], [47, 47, "product"], [49, 49, "product"], [51, 51, "product"], [54, 55, "misc"], [60, 61, "product"], [63, 64, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[17, 17, 12, 12, "general-affiliation", "", false, false], [27, 27, 20, 22, "general-affiliation", "", false, false], [36, 36, 30, 31, "general-affiliation", "", false, false], [47, 47, 39, 42, "type-of", "", false, false], [49, 49, 39, 42, "type-of", "", false, false], [51, 51, 39, 42, "type-of", "", false, false], [60, 61, 54, 55, "general-affiliation", "", false, false], [63, 64, 54, 55, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Isso", "incluiria", "programas", "como", "an\u00e1lise", "e", "ferramentas", "de", "extra\u00e7\u00e3o", "de", "dados", ",", "planilhas", "(", "por", "exemplo", ",", "Excel", ")", ",", "bancos", "de", "dados", "(", "por", "exemplo", ",", "Access", ")", ",", "an\u00e1lise", "estat\u00edstica", "(", "por", "exemplo", ",", "SAS", ")", ",", "software", "de", "auditoria", "generalizada", "(", "por", "exemplo", ",", "ACL", ",", "Arbutus", ",", "EAS", ")", ",", "business", "intelligence", "(", "por", "exemplo", ",", "Crystal", "Reports", "e", "Business", "Objects", ")", ",", "etc", "."], "sentence-detokenized": "Isso incluiria programas como an\u00e1lise e ferramentas de extra\u00e7\u00e3o de dados, planilhas (por exemplo, Excel), bancos de dados (por exemplo, Access), an\u00e1lise estat\u00edstica (por exemplo, SAS), software de auditoria generalizada (por exemplo, ACL, Arbutus, EAS), business intelligence (por exemplo, Crystal Reports e Business Objects), etc.", "token2charspan": [[0, 4], [5, 14], [15, 24], [25, 29], [30, 37], [38, 39], [40, 51], [52, 54], [55, 63], [64, 66], [67, 72], [72, 73], [74, 83], [84, 85], [85, 88], [89, 96], [96, 97], [98, 103], [103, 104], [104, 105], [106, 112], [113, 115], [116, 121], [122, 123], [123, 126], [127, 134], [134, 135], [136, 142], [142, 143], [143, 144], [145, 152], [153, 164], [165, 166], [166, 169], [170, 177], [177, 178], [179, 182], [182, 183], [183, 184], [185, 193], [194, 196], [197, 206], [207, 219], [220, 221], [221, 224], [225, 232], [232, 233], [234, 237], [237, 238], [239, 246], [246, 247], [248, 251], [251, 252], [252, 253], [254, 262], [263, 275], [276, 277], [277, 280], [281, 288], [288, 289], [290, 297], [298, 305], [306, 307], [308, 316], [317, 324], [324, 325], [325, 326], [327, 330], [330, 331]]}
{"doc_key": "ai-test-11", "ner": [[0, 2, "organisation"], [6, 7, "researcher"], [11, 11, "organisation"], [15, 15, "product"], [23, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 6, 7, "origin", "", false, false], [6, 7, 11, 11, "role", "", false, false], [15, 15, 23, 24, "type-of", "", false, false], [23, 24, 6, 7, "origin", "introduced_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "Rethink", "Robotics", "-", "fundada", "por", "Rodney", "Brooks", ",", "anteriormente", "com", "iRobot", "-", "introduziu", "a", "Baxter", "em", "setembro", "de", "2012", ";", "como", "um", "rob\u00f4", "industrial", "projetado", "para", "interagir", "com", "seguran\u00e7a", "com", "trabalhadores", "humanos", "vizinhos", ",", "e", "ser", "program\u00e1vel", "para", "executar", "tarefas", "simples", "."], "sentence-detokenized": "A Rethink Robotics - fundada por Rodney Brooks, anteriormente com iRobot - introduziu a Baxter em setembro de 2012; como um rob\u00f4 industrial projetado para interagir com seguran\u00e7a com trabalhadores humanos vizinhos, e ser program\u00e1vel para executar tarefas simples.", "token2charspan": [[0, 1], [2, 9], [10, 18], [19, 20], [21, 28], [29, 32], [33, 39], [40, 46], [46, 47], [48, 61], [62, 65], [66, 72], [73, 74], [75, 85], [86, 87], [88, 94], [95, 97], [98, 106], [107, 109], [110, 114], [114, 115], [116, 120], [121, 123], [124, 128], [129, 139], [140, 149], [150, 154], [155, 164], [165, 168], [169, 178], [179, 182], [183, 196], [197, 204], [205, 213], [213, 214], [215, 216], [217, 220], [221, 232], [233, 237], [238, 246], [247, 254], [255, 262], [262, 263]]}
{"doc_key": "ai-test-12", "ner": [[4, 6, "field"], [8, 10, "task"], [12, 14, "task"], [16, 18, "task"], [20, 23, "task"], [25, 27, "task"], [29, 31, "task"], [33, 37, "task"], [46, 49, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[8, 10, 4, 6, "part-of", "task_part_of_field", false, false], [12, 14, 4, 6, "part-of", "task_part_of_field", false, false], [16, 18, 4, 6, "part-of", "task_part_of_field", false, false], [20, 23, 4, 6, "part-of", "task_part_of_field", false, false], [25, 27, 4, 6, "part-of", "task_part_of_field", false, false], [29, 31, 4, 6, "part-of", "task_part_of_field", false, false], [33, 37, 4, 6, "part-of", "task_part_of_field", false, false], [46, 49, 4, 6, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["As", "tarefas", "t\u00edpicas", "de", "minera\u00e7\u00e3o", "de", "texto", "incluem", "categoriza\u00e7\u00e3o", "de", "texto", ",", "agrupamento", "de", "textos", ",", "extra\u00e7\u00e3o", "de", "conceito/entidade", ",", "produ\u00e7\u00e3o", "de", "taxonomias", "granulares", ",", "an\u00e1lise", "de", "sentimentos", ",", "sumariza\u00e7\u00e3o", "de", "documentos", "e", "modelagem", "de", "rela\u00e7\u00f5es", "de", "entidade", "(", "ou", "seja", ",", "rela\u00e7\u00f5es", "de", "aprendizagem", "entre", "reconhecimento", "de", "entidade", "nomeada", ")", "."], "sentence-detokenized": "As tarefas t\u00edpicas de minera\u00e7\u00e3o de texto incluem categoriza\u00e7\u00e3o de texto, agrupamento de textos, extra\u00e7\u00e3o de conceito/entidade, produ\u00e7\u00e3o de taxonomias granulares, an\u00e1lise de sentimentos, sumariza\u00e7\u00e3o de documentos e modelagem de rela\u00e7\u00f5es de entidade (ou seja, rela\u00e7\u00f5es de aprendizagem entre reconhecimento de entidade nomeada).", "token2charspan": [[0, 2], [3, 10], [11, 18], [19, 21], [22, 31], [32, 34], [35, 40], [41, 48], [49, 62], [63, 65], [66, 71], [71, 72], [73, 84], [85, 87], [88, 94], [94, 95], [96, 104], [105, 107], [108, 125], [125, 126], [127, 135], [136, 138], [139, 149], [150, 160], [160, 161], [162, 169], [170, 172], [173, 184], [184, 185], [186, 197], [198, 200], [201, 211], [212, 213], [214, 223], [224, 226], [227, 235], [236, 238], [239, 247], [248, 249], [249, 251], [252, 256], [256, 257], [258, 266], [267, 269], [270, 282], [283, 288], [289, 303], [304, 306], [307, 315], [316, 323], [323, 324], [324, 325]]}
{"doc_key": "ai-test-13", "ner": [[7, 7, "metrics"], [11, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["No", "entanto", ",", "o", "corte", "reduz", "a", "precis\u00e3o", ",", "ou", "a", "VERDADEIRA", "taxa", "negativa", ",", "para", "tais", "sistemas", "."], "sentence-detokenized": "No entanto, o corte reduz a precis\u00e3o, ou a VERDADEIRA taxa negativa, para tais sistemas.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 13], [14, 19], [20, 25], [26, 27], [28, 36], [36, 37], [38, 40], [41, 42], [43, 53], [54, 58], [59, 67], [67, 68], [69, 73], [74, 78], [79, 87], [87, 88]]}
{"doc_key": "ai-test-14", "ner": [[4, 6, "task"], [11, 12, "misc"], [16, 17, "misc"], [25, 25, "product"], [27, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 12, 4, 6, "temporal", "", false, false], [16, 17, 11, 12, "named", "", false, false], [25, 25, 11, 12, "usage", "", false, false], [27, 27, 11, 12, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Um", "caso", "especial", "de", "detec\u00e7\u00e3o", "de", "palavras-chave", "\u00e9", "a", "detec\u00e7\u00e3o", "da", "palavra", "despertar", "(", "tamb\u00e9m", "chamada", "hot", "word", ")", "usada", "por", "assistentes", "digitais", "pessoais", "como", "Alexa", "ou", "Siri", "para", "acordar", "quando", "seu", "nome", "\u00e9", "falado", "."], "sentence-detokenized": "Um caso especial de detec\u00e7\u00e3o de palavras-chave \u00e9 a detec\u00e7\u00e3o da palavra despertar (tamb\u00e9m chamada hot word) usada por assistentes digitais pessoais como Alexa ou Siri para acordar quando seu nome \u00e9 falado.", "token2charspan": [[0, 2], [3, 7], [8, 16], [17, 19], [20, 28], [29, 31], [32, 46], [47, 48], [49, 50], [51, 59], [60, 62], [63, 70], [71, 80], [81, 82], [82, 88], [89, 96], [97, 100], [101, 105], [105, 106], [107, 112], [113, 116], [117, 128], [129, 137], [138, 146], [147, 151], [152, 157], [158, 160], [161, 165], [166, 170], [171, 178], [179, 185], [186, 189], [190, 194], [195, 196], [197, 203], [203, 204]]}
{"doc_key": "ai-test-15", "ner": [[0, 0, "programlang"], [11, 11, "programlang"], [13, 13, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 0, 0, "part-of", "", false, false], [13, 13, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prova", "\u00e9", "uma", "linguagem", "de", "programa\u00e7\u00e3o", "de", "c\u00f3digo", "aberto", "que", "combina", "Prolog", "com", "Java", "."], "sentence-detokenized": "Prova \u00e9 uma linguagem de programa\u00e7\u00e3o de c\u00f3digo aberto que combina Prolog com Java.", "token2charspan": [[0, 5], [6, 7], [8, 11], [12, 21], [22, 24], [25, 36], [37, 39], [40, 46], [47, 53], [54, 57], [58, 65], [66, 72], [73, 76], [77, 81], [81, 82]]}
{"doc_key": "ai-test-16", "ner": [[4, 5, "organisation"], [10, 10, "organisation"], [17, 18, "product"], [28, 29, "country"], [34, 34, "organisation"], [45, 46, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 10, 10, "part-of", "", false, false], [4, 5, 10, 10, "role", "sells", false, false], [4, 5, 28, 29, "role", "sells_to", false, false], [34, 34, 45, 46, "opposite", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Em", "1987", ",", "a", "Tocibai", "Machine", ",", "uma", "subsidi\u00e1ria", "da", "Toshiba", ",", "foi", "acusada", "de", "vender", "ilegalmente", "fresas", "CNC", "usadas", "para", "produzir", "h\u00e9lices", "submarinas", "muito", "silenciosas", "para", "a", "Uni\u00e3o", "Sovi\u00e9tica", ",", "violando", "o", "acordo", "CoCom", ",", "um", "embargo", "internacional", "de", "certos", "pa\u00edses", "para", "os", "pa\u00edses", "do", "COMECON", "."], "sentence-detokenized": "Em 1987, a Tocibai Machine, uma subsidi\u00e1ria da Toshiba, foi acusada de vender ilegalmente fresas CNC usadas para produzir h\u00e9lices submarinas muito silenciosas para a Uni\u00e3o Sovi\u00e9tica, violando o acordo CoCom, um embargo internacional de certos pa\u00edses para os pa\u00edses do COMECON.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 18], [19, 26], [26, 27], [28, 31], [32, 43], [44, 46], [47, 54], [54, 55], [56, 59], [60, 67], [68, 70], [71, 77], [78, 89], [90, 96], [97, 100], [101, 107], [108, 112], [113, 121], [122, 129], [130, 140], [141, 146], [147, 158], [159, 163], [164, 165], [166, 171], [172, 181], [181, 182], [183, 191], [192, 193], [194, 200], [201, 206], [206, 207], [208, 210], [211, 218], [219, 232], [233, 235], [236, 242], [243, 249], [250, 254], [255, 257], [258, 264], [265, 267], [268, 275], [275, 276]]}
{"doc_key": "ai-test-17", "ner": [[5, 5, "researcher"], [8, 11, "product"], [20, 24, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 11, 5, 5, "artifact", "", false, false], [8, 11, 20, 24, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "mais", "famosa", "co-inven\u00e7\u00e3o", "da", "Engelberger", ",", "o", "bra\u00e7o", "rob\u00f3tico", "industrial", "Unimate", ",", "foi", "um", "dos", "primeiros", "a", "entrar", "no", "Hall", "da", "Fama", "dos", "Rob\u00f4s", ",", "em", "2003", "."], "sentence-detokenized": "A mais famosa co-inven\u00e7\u00e3o da Engelberger, o bra\u00e7o rob\u00f3tico industrial Unimate, foi um dos primeiros a entrar no Hall da Fama dos Rob\u00f4s, em 2003.", "token2charspan": [[0, 1], [2, 6], [7, 13], [14, 25], [26, 28], [29, 40], [40, 41], [42, 43], [44, 49], [50, 58], [59, 69], [70, 77], [77, 78], [79, 82], [83, 85], [86, 89], [90, 99], [100, 101], [102, 108], [109, 111], [112, 116], [117, 119], [120, 124], [125, 128], [129, 134], [134, 135], [136, 138], [139, 143], [143, 144]]}
{"doc_key": "ai-test-18", "ner": [[5, 6, "misc"], [8, 8, "misc"], [13, 13, "person"], [24, 25, "field"], [22, 23, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 8, 8, "usage", "", false, false], [13, 13, 24, 25, "role", "", false, false], [24, 25, 22, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Originalmente", "controlado", "via", "p\u00e1ginas", "web", "html", "est\u00e1ticas", "usando", "CGI", ",", "o", "trabalho", "de", "Dalton", "viu", "a", "introdu\u00e7\u00e3o", "de", "uma", "interface", "baseada", "em", "Java", "de", "realidade", "aumentada", "que", "teve", "um", "sucesso", "limitado", "."], "sentence-detokenized": "Originalmente controlado via p\u00e1ginas web html est\u00e1ticas usando CGI, o trabalho de Dalton viu a introdu\u00e7\u00e3o de uma interface baseada em Java de realidade aumentada que teve um sucesso limitado.", "token2charspan": [[0, 13], [14, 24], [25, 28], [29, 36], [37, 40], [41, 45], [46, 55], [56, 62], [63, 66], [66, 67], [68, 69], [70, 78], [79, 81], [82, 88], [89, 92], [93, 94], [95, 105], [106, 108], [109, 112], [113, 122], [123, 130], [131, 133], [134, 138], [139, 141], [142, 151], [152, 161], [162, 165], [166, 170], [171, 173], [174, 181], [182, 190], [190, 191]]}
{"doc_key": "ai-test-19", "ner": [[5, 6, "task"], [12, 12, "organisation"], [29, 29, "conference"], [32, 32, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 12, 12, "origin", "", false, false], [29, 29, 32, 32, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "primeira", "publica\u00e7\u00e3o", "sobre", "a", "especifica\u00e7\u00e3o", "LMF", "tal", "como", "foi", "ratificada", "pela", "ISO", "(", "este", "documento", "tornou-se", "(", "em", "2015", ")", "o", "9\u00ba", "documento", "mais", "citado", "dentro", "das", "confer\u00eancias", "LREC", "dos", "documentos", "LREC", ")", ":"], "sentence-detokenized": "A primeira publica\u00e7\u00e3o sobre a especifica\u00e7\u00e3o LMF tal como foi ratificada pela ISO (este documento tornou-se (em 2015) o 9\u00ba documento mais citado dentro das confer\u00eancias LREC dos documentos LREC):", "token2charspan": [[0, 1], [2, 10], [11, 21], [22, 27], [28, 29], [30, 43], [44, 47], [48, 51], [52, 56], [57, 60], [61, 71], [72, 76], [77, 80], [81, 82], [82, 86], [87, 96], [97, 106], [107, 108], [108, 110], [111, 115], [115, 116], [117, 118], [119, 121], [122, 131], [132, 136], [137, 143], [144, 150], [151, 154], [155, 167], [168, 172], [173, 176], [177, 187], [188, 192], [192, 193], [193, 194]]}
{"doc_key": "ai-test-20", "ner": [[1, 3, "metrics"], [17, 18, "metrics"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 18, 1, 3, "usage", "", false, false], [17, 18, 19, 21, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Uma", "matriz", "de", "confus\u00e3o", "ou", "matriz", "de", "correspond\u00eancia", "\u00e9", "freq\u00fcentemente", "usada", "como", "uma", "ferramenta", "para", "validar", "a", "precis\u00e3o", "da", "classifica\u00e7\u00e3o", "k", "-NN", "."], "sentence-detokenized": "Uma matriz de confus\u00e3o ou matriz de correspond\u00eancia \u00e9 freq\u00fcentemente usada como uma ferramenta para validar a precis\u00e3o da classifica\u00e7\u00e3o k -NN.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 22], [23, 25], [26, 32], [33, 35], [36, 51], [52, 53], [54, 68], [69, 74], [75, 79], [80, 83], [84, 94], [95, 99], [100, 107], [108, 109], [110, 118], [119, 121], [122, 135], [136, 137], [138, 141], [141, 142]]}
{"doc_key": "ai-test-21", "ner": [[3, 5, "algorithm"], [15, 15, "field"], [17, 19, "field"], [21, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 5, 15, 15, "part-of", "", false, false], [3, 5, 17, 19, "part-of", "", false, false], [3, 5, 21, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "aprendizagem", "da", "\u00e1rvore", "de", "decis\u00e3o", "\u00e9", "uma", "das", "abordagens", "de", "modelagem", "preditiva", "utilizada", "em", "estat\u00edstica", ",", "minera\u00e7\u00e3o", "de", "dados", "e", "aprendizagem", "de", "m\u00e1quinas", "."], "sentence-detokenized": "A aprendizagem da \u00e1rvore de decis\u00e3o \u00e9 uma das abordagens de modelagem preditiva utilizada em estat\u00edstica, minera\u00e7\u00e3o de dados e aprendizagem de m\u00e1quinas.", "token2charspan": [[0, 1], [2, 14], [15, 17], [18, 24], [25, 27], [28, 35], [36, 37], [38, 41], [42, 45], [46, 56], [57, 59], [60, 69], [70, 79], [80, 89], [90, 92], [93, 104], [104, 105], [106, 115], [116, 118], [119, 124], [125, 126], [127, 139], [140, 142], [143, 151], [151, 152]]}
{"doc_key": "ai-test-22", "ner": [[6, 6, "misc"], [22, 28, "field"], [29, 31, "algorithm"], [33, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 22, 28, "related-to", "", true, false], [29, 31, 22, 28, "type-of", "", false, false], [33, 33, 22, 28, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Em", "tempo", "de", "execu\u00e7\u00e3o", ",", "a", "pros\u00f3dia", "alvo", "de", "uma", "frase", "\u00e9", "sobreposta", "a", "essas", "unidades", "m\u00ednimas", "por", "meio", "de", "t\u00e9cnicas", "de", "processamento", "de", "sinais", ",", "tais", "como", "a", "codifica\u00e7\u00e3o", "preditiva", "linear", ",", "PSOLA"], "sentence-detokenized": "Em tempo de execu\u00e7\u00e3o, a pros\u00f3dia alvo de uma frase \u00e9 sobreposta a essas unidades m\u00ednimas por meio de t\u00e9cnicas de processamento de sinais, tais como a codifica\u00e7\u00e3o preditiva linear, PSOLA", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 20], [20, 21], [22, 23], [24, 32], [33, 37], [38, 40], [41, 44], [45, 50], [51, 52], [53, 63], [64, 65], [66, 71], [72, 80], [81, 88], [89, 92], [93, 97], [98, 100], [101, 109], [110, 112], [113, 126], [127, 129], [130, 136], [136, 137], [138, 142], [143, 147], [148, 149], [150, 161], [162, 171], [172, 178], [178, 179], [180, 185]]}
{"doc_key": "ai-test-23", "ner": [[3, 4, "field"], [6, 8, "field"], [15, 16, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 16, 3, 4, "usage", "", true, false], [15, 16, 6, 8, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Esta", "abordagem", "utilizou", "intelig\u00eancia", "artificial", "e", "aprendizagem", "de", "m\u00e1quinas", "para", "permitir", "aos", "pesquisadores", "comparar", "visivelmente", "imagens", "faciais", "convencionais", "e", "t\u00e9rmicas", "."], "sentence-detokenized": "Esta abordagem utilizou intelig\u00eancia artificial e aprendizagem de m\u00e1quinas para permitir aos pesquisadores comparar visivelmente imagens faciais convencionais e t\u00e9rmicas.", "token2charspan": [[0, 4], [5, 14], [15, 23], [24, 36], [37, 47], [48, 49], [50, 62], [63, 65], [66, 74], [75, 79], [80, 88], [89, 92], [93, 106], [107, 115], [116, 128], [129, 136], [137, 144], [145, 158], [159, 160], [161, 169], [169, 170]]}
{"doc_key": "ai-test-24", "ner": [[1, 1, "field"], [4, 5, "algorithm"], [12, 13, "task"], [16, 17, "misc"], [23, 24, "field"], [26, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 1, 1, "part-of", "", false, false], [4, 5, 12, 13, "topic", "", false, false], [12, 13, 16, 17, "origin", "", false, false], [23, 24, 1, 1, "part-of", "", false, false], [23, 24, 4, 5, "topic", "", false, false], [26, 27, 1, 1, "part-of", "", false, false], [26, 27, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Na", "inform\u00e1tica", ",", "a", "computa\u00e7\u00e3o", "evolutiva", "\u00e9", "uma", "fam\u00edlia", "de", "algoritmos", "para", "otimiza\u00e7\u00e3o", "global", "inspirada", "na", "evolu\u00e7\u00e3o", "biol\u00f3gica", ",", "e", "o", "subcampo", "de", "intelig\u00eancia", "artificial", "e", "computa\u00e7\u00e3o", "suave", "que", "estuda", "estes", "algoritmos", "."], "sentence-detokenized": "Na inform\u00e1tica, a computa\u00e7\u00e3o evolutiva \u00e9 uma fam\u00edlia de algoritmos para otimiza\u00e7\u00e3o global inspirada na evolu\u00e7\u00e3o biol\u00f3gica, e o subcampo de intelig\u00eancia artificial e computa\u00e7\u00e3o suave que estuda estes algoritmos.", "token2charspan": [[0, 2], [3, 14], [14, 15], [16, 17], [18, 28], [29, 38], [39, 40], [41, 44], [45, 52], [53, 55], [56, 66], [67, 71], [72, 82], [83, 89], [90, 99], [100, 102], [103, 111], [112, 121], [121, 122], [123, 124], [125, 126], [127, 135], [136, 138], [139, 151], [152, 162], [163, 164], [165, 175], [176, 181], [182, 185], [186, 192], [193, 198], [199, 209], [209, 210]]}
{"doc_key": "ai-test-25", "ner": [[9, 11, "metrics"], [14, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Por", "exemplo", ",", "pode-se", "combinar", "alguma", "medida", "baseada", "na", "matriz", "de", "confus\u00e3o", "com", "o", "erro", "m\u00e9dio", "ao", "quadrado", "avaliado", "entre", "as", "sa\u00eddas", "do", "modelo", "bruto", "e", "os", "valores", "reais", "."], "sentence-detokenized": "Por exemplo, pode-se combinar alguma medida baseada na matriz de confus\u00e3o com o erro m\u00e9dio ao quadrado avaliado entre as sa\u00eddas do modelo bruto e os valores reais.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 20], [21, 29], [30, 36], [37, 43], [44, 51], [52, 54], [55, 61], [62, 64], [65, 73], [74, 77], [78, 79], [80, 84], [85, 90], [91, 93], [94, 102], [103, 111], [112, 117], [118, 120], [121, 127], [128, 130], [131, 137], [138, 143], [144, 145], [146, 148], [149, 156], [157, 162], [162, 163]]}
{"doc_key": "ai-test-26", "ner": [[5, 6, "product"], [9, 9, "researcher"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 9, 9, "origin", "", false, false], [5, 6, 15, 15, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "maioria", "s\u00e3o", "resultados", "do", "modelo", "word2vec", "desenvolvido", "por", "Mikolov", "et", "al", "ou", "variantes", "do", "word2vec", "."], "sentence-detokenized": "A maioria s\u00e3o resultados do modelo word2vec desenvolvido por Mikolov et al ou variantes do word2vec.", "token2charspan": [[0, 1], [2, 9], [10, 13], [14, 24], [25, 27], [28, 34], [35, 43], [44, 56], [57, 60], [61, 68], [69, 71], [72, 74], [75, 77], [78, 87], [88, 90], [91, 99], [99, 100]]}
{"doc_key": "ai-test-27", "ner": [[13, 13, "conference"], [16, 20, "conference"], [22, 22, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 22, 16, 20, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Foi", "durante", "este", "tempo", "que", "um", "total", "de", "43", "publica\u00e7\u00f5es", "foram", "reconhecidas", "pela", "CVPR", "e", "pela", "Confer\u00eancia", "Internacional", "sobre", "Vis\u00e3o", "Inform\u00e1tica", "(", "ICCV", ")", "."], "sentence-detokenized": "Foi durante este tempo que um total de 43 publica\u00e7\u00f5es foram reconhecidas pela CVPR e pela Confer\u00eancia Internacional sobre Vis\u00e3o Inform\u00e1tica (ICCV).", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 22], [23, 26], [27, 29], [30, 35], [36, 38], [39, 41], [42, 53], [54, 59], [60, 72], [73, 77], [78, 82], [83, 84], [85, 89], [90, 101], [102, 115], [116, 121], [122, 127], [128, 139], [140, 141], [141, 145], [145, 146], [146, 147]]}
{"doc_key": "ai-test-28", "ner": [[1, 1, "product"], [15, 16, "field"], [23, 25, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 15, 16, "general-affiliation", "platform_for_education_about", false, false], [23, 25, 1, 1, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "AIBO", "tem", "visto", "muito", "uso", "como", "uma", "plataforma", "barata", "para", "educa\u00e7\u00e3o", "e", "pesquisa", "de", "intelig\u00eancia", "artificial", ",", "porque", "integra", "um", "computador", ",", "vis\u00e3o", "de", "computador", "e", "articuladores", "em", "um", "pacote", "vastamente", "mais", "barato", "do", "que", "os", "rob\u00f4s", "de", "pesquisa", "convencionais", "."], "sentence-detokenized": "A AIBO tem visto muito uso como uma plataforma barata para educa\u00e7\u00e3o e pesquisa de intelig\u00eancia artificial, porque integra um computador, vis\u00e3o de computador e articuladores em um pacote vastamente mais barato do que os rob\u00f4s de pesquisa convencionais.", "token2charspan": [[0, 1], [2, 6], [7, 10], [11, 16], [17, 22], [23, 26], [27, 31], [32, 35], [36, 46], [47, 53], [54, 58], [59, 67], [68, 69], [70, 78], [79, 81], [82, 94], [95, 105], [105, 106], [107, 113], [114, 121], [122, 124], [125, 135], [135, 136], [137, 142], [143, 145], [146, 156], [157, 158], [159, 172], [173, 175], [176, 178], [179, 185], [186, 196], [197, 201], [202, 208], [209, 211], [212, 215], [216, 218], [219, 224], [225, 227], [228, 236], [237, 250], [250, 251]]}
{"doc_key": "ai-test-29", "ner": [[7, 13, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ela", "atuou", "como", "Presidente", "do", "Programa", "da", "Confer\u00eancia", "Internacional", "sobre", "Vis\u00e3o", "por", "Computador", "2021", "."], "sentence-detokenized": "Ela atuou como Presidente do Programa da Confer\u00eancia Internacional sobre Vis\u00e3o por Computador 2021.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 25], [26, 28], [29, 37], [38, 40], [41, 52], [53, 66], [67, 72], [73, 78], [79, 82], [83, 93], [94, 98], [98, 99]]}
{"doc_key": "ai-test-30", "ner": [[0, 0, "researcher"], [7, 7, "organisation"], [17, 17, "organisation"], [25, 26, "organisation"], [34, 38, "product"], [40, 40, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 7, 7, "role", "", false, false], [0, 0, 17, 17, "role", "", true, false], [17, 17, 25, 26, "role", "develops_with", false, false], [34, 38, 17, 17, "artifact", "", false, false], [40, 40, 34, 38, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Scheinman", ",", "ap\u00f3s", "receber", "uma", "bolsa", "da", "Unimation", "para", "desenvolver", "seus", "projetos", ",", "vendeu", "esses", "projetos", "\u00e0", "Unimation", "que", "os", "desenvolveu", "com", "o", "apoio", "da", "General", "Motors", "e", "mais", "tarde", "a", "comercializou", "como", "a", "M\u00e1quina", "Universal", "Program\u00e1vel", "para", "Montagem", "(", "PUMA", ")", "."], "sentence-detokenized": "Scheinman, ap\u00f3s receber uma bolsa da Unimation para desenvolver seus projetos, vendeu esses projetos \u00e0 Unimation que os desenvolveu com o apoio da General Motors e mais tarde a comercializou como a M\u00e1quina Universal Program\u00e1vel para Montagem (PUMA).", "token2charspan": [[0, 9], [9, 10], [11, 15], [16, 23], [24, 27], [28, 33], [34, 36], [37, 46], [47, 51], [52, 63], [64, 68], [69, 77], [77, 78], [79, 85], [86, 91], [92, 100], [101, 102], [103, 112], [113, 116], [117, 119], [120, 131], [132, 135], [136, 137], [138, 143], [144, 146], [147, 154], [155, 161], [162, 163], [164, 168], [169, 174], [175, 176], [177, 190], [191, 195], [196, 197], [198, 205], [206, 215], [216, 227], [228, 232], [233, 241], [242, 243], [243, 247], [247, 248], [248, 249]]}
{"doc_key": "ai-test-31", "ner": [[10, 11, "task"], [8, 14, "task"], [18, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 18, 10, 11, "general-affiliation", "works_with", false, false], [18, 18, 8, 14, "general-affiliation", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Uma", "vis\u00e3o", "geral", "dos", "m\u00e9todos", "de", "calibra\u00e7\u00e3o", "para", "tarefas", "de", "classifica\u00e7\u00e3o", "bin\u00e1ria", "e", "classifica\u00e7\u00e3o", "multiclasse", "\u00e9", "dada", "por", "Gebel", "(", "2009", ")"], "sentence-detokenized": "Uma vis\u00e3o geral dos m\u00e9todos de calibra\u00e7\u00e3o para tarefas de classifica\u00e7\u00e3o bin\u00e1ria e classifica\u00e7\u00e3o multiclasse \u00e9 dada por Gebel (2009)", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 19], [20, 27], [28, 30], [31, 41], [42, 46], [47, 54], [55, 57], [58, 71], [72, 79], [80, 81], [82, 95], [96, 107], [108, 109], [110, 114], [115, 118], [119, 124], [125, 126], [126, 130], [130, 131]]}
{"doc_key": "ai-test-32", "ner": [[6, 9, "task"], [11, 11, "task"], [14, 16, "task"], [20, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 6, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Ele", "est\u00e1", "envolvido", "em", "campos", "como", "reconhecimento", "\u00f3ptico", "de", "caracteres", "(", "OCR", ")", ",", "s\u00edntese", "de", "fala", ",", "tecnologia", "de", "reconhecimento", "de", "fala", "e", "instrumentos", "eletr\u00f4nicos", "de", "teclado", "."], "sentence-detokenized": "Ele est\u00e1 envolvido em campos como reconhecimento \u00f3ptico de caracteres (OCR), s\u00edntese de fala, tecnologia de reconhecimento de fala e instrumentos eletr\u00f4nicos de teclado.", "token2charspan": [[0, 3], [4, 8], [9, 18], [19, 21], [22, 28], [29, 33], [34, 48], [49, 55], [56, 58], [59, 69], [70, 71], [71, 74], [74, 75], [75, 76], [77, 84], [85, 87], [88, 92], [92, 93], [94, 104], [105, 107], [108, 122], [123, 125], [126, 130], [131, 132], [133, 145], [146, 157], [158, 160], [161, 168], [168, 169]]}
{"doc_key": "ai-test-33", "ner": [[9, 13, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Para", "t\u00e9cnicas", "mais", "recentes", "e", "de", "\u00faltima", "gera\u00e7\u00e3o", ",", "o", "kit", "de", "ferramentas", "Kaldi", "pode", "ser", "usado", "."], "sentence-detokenized": "Para t\u00e9cnicas mais recentes e de \u00faltima gera\u00e7\u00e3o, o kit de ferramentas Kaldi pode ser usado.", "token2charspan": [[0, 4], [5, 13], [14, 18], [19, 27], [28, 29], [30, 32], [33, 39], [40, 47], [47, 48], [49, 50], [51, 54], [55, 57], [58, 69], [70, 75], [76, 80], [81, 84], [85, 90], [90, 91]]}
{"doc_key": "ai-test-34", "ner": [[0, 0, "researcher"], [4, 6, "organisation"], [10, 11, "organisation"], [15, 16, "organisation"], [24, 25, "researcher"], [20, 23, "organisation"], [29, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 4, 6, "role", "", false, false], [0, 0, 10, 11, "role", "", false, false], [0, 0, 15, 16, "role", "", false, false], [0, 0, 20, 23, "role", "", false, false], [0, 0, 29, 32, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Johnson-Laird", "\u00e9", "membro", "da", "Sociedade", "Filos\u00f3fica", "Americana", ",", "membro", "da", "Sociedade", "Real", ",", "membro", "da", "Academia", "Brit\u00e2nica", ",", "membro", "da", "Associa\u00e7\u00e3o", "de", "Ci\u00eancias", "Psicol\u00f3gicas", "William", "James", "e", "membro", "da", "Sociedade", "de", "Ci\u00eancias", "Cognitivas", "."], "sentence-detokenized": "Johnson-Laird \u00e9 membro da Sociedade Filos\u00f3fica Americana, membro da Sociedade Real, membro da Academia Brit\u00e2nica, membro da Associa\u00e7\u00e3o de Ci\u00eancias Psicol\u00f3gicas William James e membro da Sociedade de Ci\u00eancias Cognitivas.", "token2charspan": [[0, 13], [14, 15], [16, 22], [23, 25], [26, 35], [36, 46], [47, 56], [56, 57], [58, 64], [65, 67], [68, 77], [78, 82], [82, 83], [84, 90], [91, 93], [94, 102], [103, 112], [112, 113], [114, 120], [121, 123], [124, 134], [135, 137], [138, 146], [147, 159], [160, 167], [168, 173], [174, 175], [176, 182], [183, 185], [186, 195], [196, 198], [199, 207], [208, 218], [218, 219]]}
{"doc_key": "ai-test-35", "ner": [[1, 7, "conference"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"], [21, 22, "algorithm"], [26, 31, "task"], [33, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 12, 1, 7, "physical", "", false, false], [11, 12, 1, 7, "temporal", "", false, false], [14, 15, 1, 7, "physical", "", false, false], [14, 15, 1, 7, "temporal", "", false, false], [17, 18, 1, 7, "physical", "", false, false], [17, 18, 1, 7, "temporal", "", false, false], [21, 22, 17, 18, "role", "extends", false, false], [26, 31, 17, 18, "role", "extends", false, false], [33, 33, 26, 31, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Na", "Confer\u00eancia", "Internacional", "IEEE", "sobre", "Processamento", "de", "Imagens", "em", "2010", ",", "Rui", "Hu", ",", "Mark", "Banard", "e", "John", "Collomosse", "estenderam", "o", "descritor", "HOG", "para", "uso", "na", "recupera\u00e7\u00e3o", "de", "imagens", "baseadas", "em", "esbo\u00e7os", "(", "SBIR", ")", "."], "sentence-detokenized": "Na Confer\u00eancia Internacional IEEE sobre Processamento de Imagens em 2010, Rui Hu, Mark Banard e John Collomosse estenderam o descritor HOG para uso na recupera\u00e7\u00e3o de imagens baseadas em esbo\u00e7os (SBIR).", "token2charspan": [[0, 2], [3, 14], [15, 28], [29, 33], [34, 39], [40, 53], [54, 56], [57, 64], [65, 67], [68, 72], [72, 73], [74, 77], [78, 80], [80, 81], [82, 86], [87, 93], [94, 95], [96, 100], [101, 111], [112, 122], [123, 124], [125, 134], [135, 138], [139, 143], [144, 147], [148, 150], [151, 162], [163, 165], [166, 173], [174, 182], [183, 185], [186, 193], [194, 195], [195, 199], [199, 200], [200, 201]]}
{"doc_key": "ai-test-36", "ner": [[0, 1, "metrics"], [7, 7, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 7, 7, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "BLEU", "usa", "uma", "forma", "modificada", "de", "precis\u00e3o", "para", "comparar", "uma", "tradu\u00e7\u00e3o", "candidata", "com", "m\u00faltiplas", "tradu\u00e7\u00f5es", "de", "refer\u00eancia", "."], "sentence-detokenized": "A BLEU usa uma forma modificada de precis\u00e3o para comparar uma tradu\u00e7\u00e3o candidata com m\u00faltiplas tradu\u00e7\u00f5es de refer\u00eancia.", "token2charspan": [[0, 1], [2, 6], [7, 10], [11, 14], [15, 20], [21, 31], [32, 34], [35, 43], [44, 48], [49, 57], [58, 61], [62, 70], [71, 80], [81, 84], [85, 94], [95, 104], [105, 107], [108, 118], [118, 119]]}
{"doc_key": "ai-test-37", "ner": [[33, 34, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Para", "o", "caso", "de", "um", "espa\u00e7o", "de", "base", "geral", "matem\u00e1tica", "(", "Y,\\B,nu", ")", "/", "matem\u00e1tica", "(", "isto", "\u00e9", ",", "um", "espa\u00e7o", "de", "base", "que", "n\u00e3o", "\u00e9", "contabiliz\u00e1vel", ")", ",", "normalmente", "se", "considera", "a", "entropia", "relativa", "."], "sentence-detokenized": "Para o caso de um espa\u00e7o de base geral matem\u00e1tica (Y,\\B,nu) / matem\u00e1tica (isto \u00e9, um espa\u00e7o de base que n\u00e3o \u00e9 contabiliz\u00e1vel), normalmente se considera a entropia relativa.", "token2charspan": [[0, 4], [5, 6], [7, 11], [12, 14], [15, 17], [18, 24], [25, 27], [28, 32], [33, 38], [39, 49], [50, 51], [51, 58], [58, 59], [60, 61], [62, 72], [73, 74], [74, 78], [79, 80], [80, 81], [82, 84], [85, 91], [92, 94], [95, 99], [100, 103], [104, 107], [108, 109], [110, 124], [124, 125], [125, 126], [127, 138], [139, 141], [142, 151], [152, 153], [154, 162], [163, 171], [171, 172]]}
{"doc_key": "ai-test-38", "ner": [[18, 19, "country"], [11, 13, "organisation"], [15, 15, "organisation"], [28, 29, "country"], [22, 23, "organisation"], [25, 25, "organisation"], [32, 34, "organisation"], [47, 47, "country"], [37, 42, "organisation"], [44, 44, "organisation"], [53, 53, "misc"], [54, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[11, 13, 18, 19, "physical", "", false, false], [15, 15, 11, 13, "named", "", false, false], [22, 23, 28, 29, "physical", "", false, false], [25, 25, 22, 23, "named", "", false, false], [37, 42, 47, 47, "physical", "", false, false], [44, 44, 37, 42, "named", "", false, false], [53, 53, 54, 54, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Em", "outubro", "de", "2011", ",", "as", "parcerias", "j\u00e1", "existentes", "com", "o", "National", "Park", "Service", "(", "NPS", ")", "dos", "Estados", "Unidos", ",", "o", "Historic", "Scotland", "(", "HS", ")", "do", "Reino", "Unido", ",", "o", "World", "Monuments", "Fund", "e", "o", "Instituto", "Nacional", "de", "Antropolog\u00eda", "y", "Historia", "(", "INAH", ")", "do", "M\u00e9xico", "haviam", "sido", "grandemente", "expandidas", ",", "CyArk", "website"], "sentence-detokenized": "Em outubro de 2011, as parcerias j\u00e1 existentes com o National Park Service (NPS) dos Estados Unidos, o Historic Scotland (HS) do Reino Unido, o World Monuments Fund e o Instituto Nacional de Antropolog\u00eda y Historia (INAH) do M\u00e9xico haviam sido grandemente expandidas, CyArk website", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 18], [18, 19], [20, 22], [23, 32], [33, 35], [36, 46], [47, 50], [51, 52], [53, 61], [62, 66], [67, 74], [75, 76], [76, 79], [79, 80], [81, 84], [85, 92], [93, 99], [99, 100], [101, 102], [103, 111], [112, 120], [121, 122], [122, 124], [124, 125], [126, 128], [129, 134], [135, 140], [140, 141], [142, 143], [144, 149], [150, 159], [160, 164], [165, 166], [167, 168], [169, 178], [179, 187], [188, 190], [191, 203], [204, 205], [206, 214], [215, 216], [216, 220], [220, 221], [222, 224], [225, 231], [232, 238], [239, 243], [244, 255], [256, 266], [266, 267], [268, 273], [274, 281]]}
{"doc_key": "ai-test-39", "ner": [[0, 2, "algorithm"], [11, 13, "field"], [16, 16, "product"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 16, 16, "part-of", "", false, false], [0, 2, 18, 18, "part-of", "", false, false], [16, 16, 11, 13, "general-affiliation", "", false, false], [18, 18, 11, 13, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Os", "Kernel", "SVMs", "est\u00e3o", "dispon\u00edveis", "em", "muitos", "kits", "de", "ferramentas", "de", "aprendizagem", "de", "m\u00e1quina", ",", "incluindo", "LIBSVM", ",", "MATLAB", ",", "e", "outros", "."], "sentence-detokenized": "Os Kernel SVMs est\u00e3o dispon\u00edveis em muitos kits de ferramentas de aprendizagem de m\u00e1quina, incluindo LIBSVM, MATLAB, e outros.", "token2charspan": [[0, 2], [3, 9], [10, 14], [15, 20], [21, 32], [33, 35], [36, 42], [43, 47], [48, 50], [51, 62], [63, 65], [66, 78], [79, 81], [82, 89], [89, 90], [91, 100], [101, 107], [107, 108], [109, 115], [115, 116], [117, 118], [119, 125], [125, 126]]}
{"doc_key": "ai-test-40", "ner": [[0, 4, "misc"], [15, 16, "location"], [18, 18, "location"], [19, 21, "country"], [25, 27, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 15, 16, "physical", "", false, false], [0, 4, 25, 27, "temporal", "", false, false], [15, 16, 18, 18, "physical", "", false, false], [18, 18, 19, 21, "physical", "", false, false], [25, 27, 15, 16, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["O", "Concurso", "do", "Pr\u00eamio", "Loebner", "2009", "foi", "realizado", "em", "6", "de", "setembro", "de", "2009", "no", "Brighton", "Centre", ",", "Brighton", "UK", ",", "em", "conjunto", "com", "a", "confer\u00eancia", "Interspeech", "2009", "."], "sentence-detokenized": "O Concurso do Pr\u00eamio Loebner 2009 foi realizado em 6 de setembro de 2009 no Brighton Centre, Brighton UK, em conjunto com a confer\u00eancia Interspeech 2009.", "token2charspan": [[0, 1], [2, 10], [11, 13], [14, 20], [21, 28], [29, 33], [34, 37], [38, 47], [48, 50], [51, 52], [53, 55], [56, 64], [65, 67], [68, 72], [73, 75], [76, 84], [85, 91], [91, 92], [93, 101], [102, 104], [104, 105], [106, 108], [109, 117], [118, 121], [122, 123], [124, 135], [136, 147], [148, 152], [152, 153]]}
{"doc_key": "ai-test-41", "ner": [[1, 3, "product"], [10, 10, "product"], [19, 19, "product"], [16, 20, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 20, 1, 3, "part-of", "", false, false], [16, 20, 10, 10, "part-of", "", false, false], [16, 20, 19, 19, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["O", "rob\u00f4", "human\u00f3ide", "QRIO", "foi", "projetado", "como", "o", "sucessor", "do", "AIBO", ",", "e", "opera", "o", "mesmo", "sistema", "operacional", "b\u00e1sico", "R-CODE", "Aperios", "."], "sentence-detokenized": "O rob\u00f4 human\u00f3ide QRIO foi projetado como o sucessor do AIBO, e opera o mesmo sistema operacional b\u00e1sico R-CODE Aperios.", "token2charspan": [[0, 1], [2, 6], [7, 16], [17, 21], [22, 25], [26, 35], [36, 40], [41, 42], [43, 51], [52, 54], [55, 59], [59, 60], [61, 62], [63, 68], [69, 70], [71, 76], [77, 84], [85, 96], [97, 103], [104, 110], [111, 118], [118, 119]]}
{"doc_key": "ai-test-42", "ner": [[0, 5, "misc"], [12, 16, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 16, 0, 5, "cause-effect", "", true, false], [19, 20, 0, 5, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "formas", "de", "onda", "de", "fala", "s\u00e3o", "geradas", "a", "partir", "dos", "pr\u00f3prios", "HMMs", ",", "com", "base", "no", "crit\u00e9rio", "de", "m\u00e1xima", "probabilidade", "."], "sentence-detokenized": "As formas de onda de fala s\u00e3o geradas a partir dos pr\u00f3prios HMMs, com base no crit\u00e9rio de m\u00e1xima probabilidade.", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 17], [18, 20], [21, 25], [26, 29], [30, 37], [38, 39], [40, 46], [47, 50], [51, 59], [60, 64], [64, 65], [66, 69], [70, 74], [75, 77], [78, 86], [87, 89], [90, 96], [97, 110], [110, 111]]}
{"doc_key": "ai-test-43", "ner": [[0, 1, "product"], [7, 10, "task"], [12, 14, "task"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 7, 10, "type-of", "", false, false], [0, 1, 12, 14, "type-of", "", false, false], [0, 1, 17, 17, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Google", "Translate", "\u00e9", "um", "servi\u00e7o", "gratuito", "de", "tradu\u00e7\u00e3o", "autom\u00e1tica", "estat\u00edstica", "multil\u00edng\u00fce", "e", "tradu\u00e7\u00e3o", "autom\u00e1tica", "neural", "desenvolvido", "pelo", "Google", ",", "para", "traduzir", "textos", "e", "websites", "de", "um", "idioma", "para", "outro", "."], "sentence-detokenized": "Google Translate \u00e9 um servi\u00e7o gratuito de tradu\u00e7\u00e3o autom\u00e1tica estat\u00edstica multil\u00edng\u00fce e tradu\u00e7\u00e3o autom\u00e1tica neural desenvolvido pelo Google, para traduzir textos e websites de um idioma para outro.", "token2charspan": [[0, 6], [7, 16], [17, 18], [19, 21], [22, 29], [30, 38], [39, 41], [42, 50], [51, 61], [62, 73], [74, 85], [86, 87], [88, 96], [97, 107], [108, 114], [115, 127], [128, 132], [133, 139], [139, 140], [141, 145], [146, 154], [155, 161], [162, 163], [164, 172], [173, 175], [176, 178], [179, 185], [186, 190], [191, 196], [196, 197]]}
{"doc_key": "ai-test-44", "ner": [[6, 7, "field"], [9, 11, "field"], [13, 15, "field"], [17, 20, "field"], [24, 27, "task"], [29, 32, "task"], [34, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[24, 27, 6, 7, "part-of", "", false, true], [24, 27, 9, 11, "part-of", "", false, true], [24, 27, 13, 15, "part-of", "", false, true], [29, 32, 6, 7, "part-of", "", false, true], [29, 32, 9, 11, "part-of", "", false, true], [29, 32, 13, 15, "part-of", "", false, true], [34, 37, 6, 7, "part-of", "", false, true], [34, 37, 9, 11, "part-of", "", false, true], [34, 37, 13, 15, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Os", "esqueletos", "s\u00e3o", "amplamente", "utilizados", "em", "vis\u00e3o", "computadorizada", ",", "an\u00e1lise", "de", "imagens", ",", "reconhecimento", "de", "padr\u00f5es", "e", "processamento", "digital", "de", "imagens", "para", "fins", "como", "reconhecimento", "\u00f3ptico", "de", "caracteres", ",", "reconhecimento", "de", "impress\u00f5es", "digitais", ",", "inspe\u00e7\u00e3o", "visual", "ou", "compress\u00e3o", "."], "sentence-detokenized": "Os esqueletos s\u00e3o amplamente utilizados em vis\u00e3o computadorizada, an\u00e1lise de imagens, reconhecimento de padr\u00f5es e processamento digital de imagens para fins como reconhecimento \u00f3ptico de caracteres, reconhecimento de impress\u00f5es digitais, inspe\u00e7\u00e3o visual ou compress\u00e3o.", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 28], [29, 39], [40, 42], [43, 48], [49, 64], [64, 65], [66, 73], [74, 76], [77, 84], [84, 85], [86, 100], [101, 103], [104, 111], [112, 113], [114, 127], [128, 135], [136, 138], [139, 146], [147, 151], [152, 156], [157, 161], [162, 176], [177, 183], [184, 186], [187, 197], [197, 198], [199, 213], [214, 216], [217, 227], [228, 236], [236, 237], [238, 246], [247, 253], [254, 256], [257, 267], [267, 268]]}
{"doc_key": "ai-test-45", "ner": [[1, 8, "conference"], [13, 17, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 8, 13, 17, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["O", "Desafio", "de", "Reconhecimento", "Visual", "em", "Grande", "Escala", "ImageNet", "\u00e9", "uma", "refer\u00eancia", "na", "classifica\u00e7\u00e3o", "e", "detec\u00e7\u00e3o", "de", "objetos", ",", "com", "milh\u00f5es", "de", "imagens", "e", "centenas", "de", "classes", "de", "objetos", "."], "sentence-detokenized": "O Desafio de Reconhecimento Visual em Grande Escala ImageNet \u00e9 uma refer\u00eancia na classifica\u00e7\u00e3o e detec\u00e7\u00e3o de objetos, com milh\u00f5es de imagens e centenas de classes de objetos.", "token2charspan": [[0, 1], [2, 9], [10, 12], [13, 27], [28, 34], [35, 37], [38, 44], [45, 51], [52, 60], [61, 62], [63, 66], [67, 77], [78, 80], [81, 94], [95, 96], [97, 105], [106, 108], [109, 116], [116, 117], [118, 121], [122, 129], [130, 132], [133, 140], [141, 142], [143, 151], [152, 154], [155, 162], [163, 165], [166, 173], [173, 174]]}
{"doc_key": "ai-test-46", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [16, 18, "misc"], [21, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 16, 18, "part-of", "", false, false], [0, 0, 21, 24, "part-of", "", false, false], [4, 5, 16, 18, "part-of", "", false, false], [4, 5, 21, 24, "part-of", "", false, false], [7, 8, 16, 18, "part-of", "", false, false], [7, 8, 21, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Bengio", ",", "junto", "com", "Geoffrey", "Hinton", "e", "Yann", "LeCun", ",", "s\u00e3o", "referidos", "por", "alguns", "como", "os", "Padrinhos", "da", "IA", "e", "os", "Padrinhos", "do", "Aprendizado", "Profundo", "."], "sentence-detokenized": "Bengio, junto com Geoffrey Hinton e Yann LeCun, s\u00e3o referidos por alguns como os Padrinhos da IA e os Padrinhos do Aprendizado Profundo.", "token2charspan": [[0, 6], [6, 7], [8, 13], [14, 17], [18, 26], [27, 33], [34, 35], [36, 40], [41, 46], [46, 47], [48, 51], [52, 61], [62, 65], [66, 72], [73, 77], [78, 80], [81, 90], [91, 93], [94, 96], [97, 98], [99, 101], [102, 111], [112, 114], [115, 126], [127, 135], [135, 136]]}
{"doc_key": "ai-test-47", "ner": [[6, 6, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ele", "\u00e9", "um", "Life", "Fellow", "do", "IEEE", "."], "sentence-detokenized": "Ele \u00e9 um Life Fellow do IEEE.", "token2charspan": [[0, 3], [4, 5], [6, 8], [9, 13], [14, 20], [21, 23], [24, 28], [28, 29]]}
{"doc_key": "ai-test-48", "ner": [[0, 2, "organisation"], [16, 21, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 16, 21, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "NSA", "Bethesda", "\u00e9", "respons\u00e1vel", "pelo", "apoio", "operacional", "de", "base", "para", "seu", "principal", "inquilino", ",", "o", "Centro", "M\u00e9dico", "Militar", "Nacional", "Walter", "Reed", "."], "sentence-detokenized": "A NSA Bethesda \u00e9 respons\u00e1vel pelo apoio operacional de base para seu principal inquilino, o Centro M\u00e9dico Militar Nacional Walter Reed.", "token2charspan": [[0, 1], [2, 5], [6, 14], [15, 16], [17, 28], [29, 33], [34, 39], [40, 51], [52, 54], [55, 59], [60, 64], [65, 68], [69, 78], [79, 88], [88, 89], [90, 91], [92, 98], [99, 105], [106, 113], [114, 122], [123, 129], [130, 134], [134, 135]]}
{"doc_key": "ai-test-49", "ner": [[8, 9, "field"], [12, 14, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Os", "tr\u00eas", "principais", "paradigmas", "de", "aprendizagem", "s\u00e3o", "a", "aprendizagem", "supervisionada", ",", "a", "aprendizagem", "n\u00e3o", "supervisionada", "e", "a", "aprendizagem", "refor\u00e7ada", "."], "sentence-detokenized": "Os tr\u00eas principais paradigmas de aprendizagem s\u00e3o a aprendizagem supervisionada, a aprendizagem n\u00e3o supervisionada e a aprendizagem refor\u00e7ada.", "token2charspan": [[0, 2], [3, 7], [8, 18], [19, 29], [30, 32], [33, 45], [46, 49], [50, 51], [52, 64], [65, 79], [79, 80], [81, 82], [83, 95], [96, 99], [100, 114], [115, 116], [117, 118], [119, 131], [132, 141], [141, 142]]}
{"doc_key": "ai-test-50", "ner": [[3, 3, "task"], [5, 7, "task"], [12, 18, "task"], [20, 22, "task"], [24, 27, "task"], [29, 31, "task"], [33, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Os", "exemplos", "incluem", "controle", ",", "planejamento", "e", "programa\u00e7\u00e3o", ",", "a", "capacidade", "de", "responder", "perguntas", "de", "diagn\u00f3stico", "e", "de", "consumo", ",", "reconhecimento", "da", "caligrafia", ",", "compreens\u00e3o", "da", "linguagem", "natural", ",", "reconhecimento", "da", "fala", "e", "reconhecimento", "facial", "."], "sentence-detokenized": "Os exemplos incluem controle, planejamento e programa\u00e7\u00e3o, a capacidade de responder perguntas de diagn\u00f3stico e de consumo, reconhecimento da caligrafia, compreens\u00e3o da linguagem natural, reconhecimento da fala e reconhecimento facial.", "token2charspan": [[0, 2], [3, 11], [12, 19], [20, 28], [28, 29], [30, 42], [43, 44], [45, 56], [56, 57], [58, 59], [60, 70], [71, 73], [74, 83], [84, 93], [94, 96], [97, 108], [109, 110], [111, 113], [114, 121], [121, 122], [123, 137], [138, 140], [141, 151], [151, 152], [153, 164], [165, 167], [168, 177], [178, 185], [185, 186], [187, 201], [202, 204], [205, 209], [210, 211], [212, 226], [227, 233], [233, 234]]}
{"doc_key": "ai-test-51", "ner": [[7, 13, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Em", "1991", "foi", "eleito", "como", "membro", "da", "Associa\u00e7\u00e3o", "para", "o", "Progresso", "da", "Intelig\u00eancia", "Artificial", "(", "1990", ",", "membro", "fundador", ")", "."], "sentence-detokenized": "Em 1991 foi eleito como membro da Associa\u00e7\u00e3o para o Progresso da Intelig\u00eancia Artificial (1990, membro fundador).", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 18], [19, 23], [24, 30], [31, 33], [34, 44], [45, 49], [50, 51], [52, 61], [62, 64], [65, 77], [78, 88], [89, 90], [90, 94], [94, 95], [96, 102], [103, 111], [111, 112], [112, 113]]}
{"doc_key": "ai-test-52", "ner": [[10, 11, "misc"], [15, 17, "algorithm"], [29, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Entretanto", ",", "formulando", "o", "problema", "como", "a", "solu\u00e7\u00e3o", "de", "uma", "matriz", "Toeplitz", "e", "utilizando", "a", "recorr\u00eancia", "de", "Levinson", ",", "podemos", "estimar", "com", "relativa", "rapidez", "um", "filtro", "com", "o", "menor", "erro", "quadr\u00e1tico", "m\u00e9dio", "poss\u00edvel", "."], "sentence-detokenized": "Entretanto, formulando o problema como a solu\u00e7\u00e3o de uma matriz Toeplitz e utilizando a recorr\u00eancia de Levinson, podemos estimar com relativa rapidez um filtro com o menor erro quadr\u00e1tico m\u00e9dio poss\u00edvel.", "token2charspan": [[0, 10], [10, 11], [12, 22], [23, 24], [25, 33], [34, 38], [39, 40], [41, 48], [49, 51], [52, 55], [56, 62], [63, 71], [72, 73], [74, 84], [85, 86], [87, 98], [99, 101], [102, 110], [110, 111], [112, 119], [120, 127], [128, 131], [132, 140], [141, 148], [149, 151], [152, 158], [159, 162], [163, 164], [165, 170], [171, 175], [176, 186], [187, 192], [193, 201], [201, 202]]}
{"doc_key": "ai-test-53", "ner": [[7, 15, "conference"], [16, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 15, 16, 20, "physical", "", false, false], [16, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Em", "julho", "de", "2011", "ser\u00e1", "realizada", "a", "15", "\u00aa", "edi\u00e7\u00e3o", "do", "Campus", "Party", "Espanha", ",", "na", "Cidade", "das", "Artes", "e", "Ci\u00eancias", "de", "Val\u00eancia", "."], "sentence-detokenized": "Em julho de 2011 ser\u00e1 realizada a 15\u00aa edi\u00e7\u00e3o do Campus Party Espanha, na Cidade das Artes e Ci\u00eancias de Val\u00eancia.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 16], [17, 21], [22, 31], [32, 33], [34, 36], [36, 37], [38, 44], [45, 47], [48, 54], [55, 60], [61, 68], [68, 69], [70, 72], [73, 79], [80, 83], [84, 89], [90, 91], [92, 100], [101, 103], [104, 112], [112, 113]]}
{"doc_key": "ai-test-54", "ner": [[13, 13, "product"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Muitas", "vezes", "isso", "geralmente", "s\u00f3", "\u00e9", "poss\u00edvel", "no", "final", "de", "jogos", "complicados", "como", "xadrez", "ou", "ir", ",", "j\u00e1", "que", "n\u00e3o", "\u00e9", "computacionalmente", "vi\u00e1vel", "olhar", "em", "frente", "at\u00e9", "a", "conclus\u00e3o", "do", "jogo", ",", "exceto", "no", "final", ",", "e", "em", "vez", "disso", ",", "as", "posi\u00e7\u00f5es", "recebem", "valores", "finitos", "como", "estimativas", "do", "grau", "de", "cren\u00e7a", "de", "que", "levar\u00e3o", "a", "uma", "vit\u00f3ria", "para", "um", "ou", "outro", "jogador", "."], "sentence-detokenized": "Muitas vezes isso geralmente s\u00f3 \u00e9 poss\u00edvel no final de jogos complicados como xadrez ou ir, j\u00e1 que n\u00e3o \u00e9 computacionalmente vi\u00e1vel olhar em frente at\u00e9 a conclus\u00e3o do jogo, exceto no final, e em vez disso, as posi\u00e7\u00f5es recebem valores finitos como estimativas do grau de cren\u00e7a de que levar\u00e3o a uma vit\u00f3ria para um ou outro jogador.", "token2charspan": [[0, 6], [7, 12], [13, 17], [18, 28], [29, 31], [32, 33], [34, 42], [43, 45], [46, 51], [52, 54], [55, 60], [61, 72], [73, 77], [78, 84], [85, 87], [88, 90], [90, 91], [92, 94], [95, 98], [99, 102], [103, 104], [105, 123], [124, 130], [131, 136], [137, 139], [140, 146], [147, 150], [151, 152], [153, 162], [163, 165], [166, 170], [170, 171], [172, 178], [179, 181], [182, 187], [187, 188], [189, 190], [191, 193], [194, 197], [198, 203], [203, 204], [205, 207], [208, 216], [217, 224], [225, 232], [233, 240], [241, 245], [246, 257], [258, 260], [261, 265], [266, 268], [269, 275], [276, 278], [279, 282], [283, 290], [291, 292], [293, 296], [297, 304], [305, 309], [310, 312], [313, 315], [316, 321], [322, 329], [329, 330]]}
{"doc_key": "ai-test-55", "ner": [[4, 6, "algorithm"], [25, 26, "algorithm"], [28, 31, "algorithm"], [33, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 25, 26, "compare", "", false, false], [4, 6, 28, 31, "compare", "", false, false], [4, 6, 33, 35, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "diferen\u00e7a", "entre", "o", "modelo", "logit", "multinomial", "e", "numerosos", "outros", "m\u00e9todos", ",", "modelos", ",", "algoritmos", ",", "etc", ".", "com", "a", "mesma", "configura\u00e7\u00e3o", "b\u00e1sica", "(", "o", "algoritmo", "perceptron", ",", "m\u00e1quinas", "vetoriais", "de", "suporte", ",", "an\u00e1lise", "linear", "discriminante", ",", "etc.", ")", "."], "sentence-detokenized": "A diferen\u00e7a entre o modelo logit multinomial e numerosos outros m\u00e9todos, modelos, algoritmos, etc. com a mesma configura\u00e7\u00e3o b\u00e1sica (o algoritmo perceptron, m\u00e1quinas vetoriais de suporte, an\u00e1lise linear discriminante, etc.).", "token2charspan": [[0, 1], [2, 11], [12, 17], [18, 19], [20, 26], [27, 32], [33, 44], [45, 46], [47, 56], [57, 63], [64, 71], [71, 72], [73, 80], [80, 81], [82, 92], [92, 93], [94, 97], [97, 98], [99, 102], [103, 104], [105, 110], [111, 123], [124, 130], [131, 132], [132, 133], [134, 143], [144, 154], [154, 155], [156, 164], [165, 174], [175, 177], [178, 185], [185, 186], [187, 194], [195, 201], [202, 215], [215, 216], [217, 221], [221, 222], [222, 223]]}
{"doc_key": "ai-test-56", "ner": [[0, 3, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Association", "for", "Computational", "Linguistics", ",", "publicado", "por"], "sentence-detokenized": "Association for Computational Linguistics, publicado por", "token2charspan": [[0, 11], [12, 15], [16, 29], [30, 41], [41, 42], [43, 52], [53, 56]]}
{"doc_key": "ai-test-57", "ner": [[1, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["No", "sistema", "informatizado", "de", "reconhecimento", "facial", ",", "cada", "rosto", "\u00e9", "representado", "por", "um", "grande", "n\u00famero", "de", "valores", "de", "pixel", "."], "sentence-detokenized": "No sistema informatizado de reconhecimento facial, cada rosto \u00e9 representado por um grande n\u00famero de valores de pixel.", "token2charspan": [[0, 2], [3, 10], [11, 24], [25, 27], [28, 42], [43, 49], [49, 50], [51, 55], [56, 61], [62, 63], [64, 76], [77, 80], [81, 83], [84, 90], [91, 97], [98, 100], [101, 108], [109, 111], [112, 117], [117, 118]]}
{"doc_key": "ai-test-58", "ner": [[6, 7, "person"], [11, 13, "organisation"], [20, 20, "country"], [23, 23, "person"], [34, 36, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 7, 11, 13, "role", "", false, false], [6, 7, 20, 20, "physical", "", false, false], [23, 23, 34, 36, "origin", "", false, false], [23, 23, 34, 36, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Em", "2002", ",", "seu", "filho", ",", "Daniel", "Pearl", ",", "jornalista", "do", "Wall", "Street", "Journal", ",", "foi", "seq\u00fcestrado", "e", "assassinado", "no", "Paquist\u00e3o", ",", "levando", "Judeia", "e", "outros", "membros", "da", "fam\u00edlia", "e", "amigos", "a", "criar", "a", "Funda\u00e7\u00e3o", "Daniel", "Pearl", "."], "sentence-detokenized": "Em 2002, seu filho, Daniel Pearl, jornalista do Wall Street Journal, foi seq\u00fcestrado e assassinado no Paquist\u00e3o, levando Judeia e outros membros da fam\u00edlia e amigos a criar a Funda\u00e7\u00e3o Daniel Pearl.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 18], [18, 19], [20, 26], [27, 32], [32, 33], [34, 44], [45, 47], [48, 52], [53, 59], [60, 67], [67, 68], [69, 72], [73, 84], [85, 86], [87, 98], [99, 101], [102, 111], [111, 112], [113, 120], [121, 127], [128, 129], [130, 136], [137, 144], [145, 147], [148, 155], [156, 157], [158, 164], [165, 166], [167, 172], [173, 174], [175, 183], [184, 190], [191, 196], [196, 197]]}
{"doc_key": "ai-test-59", "ner": [[8, 10, "organisation"], [21, 22, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 10, 21, 22, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "partir", "do", "final", "de", "2006", ",", "a", "Red", "Envelope", "Entertainment", "tamb\u00e9m", "se", "expandiu", "para", "produzir", "conte\u00fado", "original", "com", "cineastas", "como", "John", "Waters", "."], "sentence-detokenized": "A partir do final de 2006, a Red Envelope Entertainment tamb\u00e9m se expandiu para produzir conte\u00fado original com cineastas como John Waters.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 17], [18, 20], [21, 25], [25, 26], [27, 28], [29, 32], [33, 41], [42, 55], [56, 62], [63, 65], [66, 74], [75, 79], [80, 88], [89, 97], [98, 106], [107, 110], [111, 120], [121, 125], [126, 130], [131, 137], [137, 138]]}
{"doc_key": "ai-test-60", "ner": [[6, 12, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["O", "edif\u00edcio", "agora", "faz", "parte", "do", "Centro", "M\u00e9dico", "da", "Diaconisa", "de", "Beth", "Israel", "."], "sentence-detokenized": "O edif\u00edcio agora faz parte do Centro M\u00e9dico da Diaconisa de Beth Israel.", "token2charspan": [[0, 1], [2, 10], [11, 16], [17, 20], [21, 26], [27, 29], [30, 36], [37, 43], [44, 46], [47, 56], [57, 59], [60, 64], [65, 71], [71, 72]]}
{"doc_key": "ai-test-61", "ner": [[17, 18, "field"], [20, 22, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Um", "tema", "comum", "deste", "trabalho", "\u00e9", "a", "ado\u00e7\u00e3o", "de", "uma", "perspectiva", "te\u00f3rica", "de", "sinais", "sobre", "quest\u00f5es", "de", "intelig\u00eancia", "artificial", "e", "representa\u00e7\u00e3o", "do", "conhecimento", "."], "sentence-detokenized": "Um tema comum deste trabalho \u00e9 a ado\u00e7\u00e3o de uma perspectiva te\u00f3rica de sinais sobre quest\u00f5es de intelig\u00eancia artificial e representa\u00e7\u00e3o do conhecimento.", "token2charspan": [[0, 2], [3, 7], [8, 13], [14, 19], [20, 28], [29, 30], [31, 32], [33, 39], [40, 42], [43, 46], [47, 58], [59, 66], [67, 69], [70, 76], [77, 82], [83, 91], [92, 94], [95, 107], [108, 118], [119, 120], [121, 134], [135, 137], [138, 150], [150, 151]]}
{"doc_key": "ai-test-62", "ner": [[5, 7, "task"], [9, 9, "task"], [23, 24, "task"], [42, 44, "task"], [47, 49, "task"], [54, 56, "task"], [58, 58, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 7, 23, 24, "type-of", "", false, false], [5, 7, 54, 56, "compare", "", false, false], [5, 7, 54, 56, "opposite", "", false, false], [9, 9, 5, 7, "named", "", false, false], [42, 44, 54, 56, "part-of", "", false, false], [47, 49, 54, 56, "part-of", "", false, false], [54, 56, 23, 24, "type-of", "", false, false], [58, 58, 54, 56, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Por", "exemplo", ",", "o", "termo", "tradu\u00e7\u00e3o", "autom\u00e1tica", "neural", "(", "NMT", ")", "enfatiza", "o", "fato", "de", "que", "as", "abordagens", "profundas", "baseadas", "no", "aprendizado", "da", "tradu\u00e7\u00e3o", "autom\u00e1tica", "aprendem", "diretamente", "as", "transforma\u00e7\u00f5es", "de", "seq\u00fc\u00eancia", "a", "seq\u00fc\u00eancia", ",", "evitando", "a", "necessidade", "de", "etapas", "intermedi\u00e1rias", "como", "o", "alinhamento", "de", "palavras", "e", "a", "modelagem", "de", "linguagem", "que", "foi", "usada", "na", "tradu\u00e7\u00e3o", "autom\u00e1tica", "estat\u00edstica", "(", "SMT", ")", "."], "sentence-detokenized": "Por exemplo, o termo tradu\u00e7\u00e3o autom\u00e1tica neural (NMT) enfatiza o fato de que as abordagens profundas baseadas no aprendizado da tradu\u00e7\u00e3o autom\u00e1tica aprendem diretamente as transforma\u00e7\u00f5es de seq\u00fc\u00eancia a seq\u00fc\u00eancia, evitando a necessidade de etapas intermedi\u00e1rias como o alinhamento de palavras e a modelagem de linguagem que foi usada na tradu\u00e7\u00e3o autom\u00e1tica estat\u00edstica (SMT).", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 14], [15, 20], [21, 29], [30, 40], [41, 47], [48, 49], [49, 52], [52, 53], [54, 62], [63, 64], [65, 69], [70, 72], [73, 76], [77, 79], [80, 90], [91, 100], [101, 109], [110, 112], [113, 124], [125, 127], [128, 136], [137, 147], [148, 156], [157, 168], [169, 171], [172, 186], [187, 189], [190, 199], [200, 201], [202, 211], [211, 212], [213, 221], [222, 223], [224, 235], [236, 238], [239, 245], [246, 260], [261, 265], [266, 267], [268, 279], [280, 282], [283, 291], [292, 293], [294, 295], [296, 305], [306, 308], [309, 318], [319, 322], [323, 326], [327, 332], [333, 335], [336, 344], [345, 355], [356, 367], [368, 369], [369, 372], [372, 373], [373, 374]]}
{"doc_key": "ai-test-63", "ner": [[7, 7, "field"], [11, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 7, 11, 12, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "maioria", "das", "pesquisas", "no", "campo", "da", "WSD", "\u00e9", "realizada", "usando", "o", "WordNet", "como", "um", "invent\u00e1rio", "de", "senso", "de", "refer\u00eancia", "para", "."], "sentence-detokenized": "A maioria das pesquisas no campo da WSD \u00e9 realizada usando o WordNet como um invent\u00e1rio de senso de refer\u00eancia para.", "token2charspan": [[0, 1], [2, 9], [10, 13], [14, 23], [24, 26], [27, 32], [33, 35], [36, 39], [40, 41], [42, 51], [52, 58], [59, 60], [61, 68], [69, 73], [74, 76], [77, 87], [88, 90], [91, 96], [97, 99], [100, 110], [111, 115], [115, 116]]}
{"doc_key": "ai-test-64", "ner": [[4, 4, "misc"], [14, 15, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 15, 4, 4, "general-affiliation", "", false, true], [18, 19, 4, 4, "general-affiliation", "", false, true]], "relations_mapping_to_source": [0, 1], "sentence": ["Entre", "os", "ex-alunos", "de", "doutorado", "e", "pesquisadores", "de", "p\u00f3s-doutorado", "not\u00e1veis", "de", "seu", "grupo", "est\u00e3o", "Richard", "Zemel", ",", "e", "Zoubin", "Ghahramani", "."], "sentence-detokenized": "Entre os ex-alunos de doutorado e pesquisadores de p\u00f3s-doutorado not\u00e1veis de seu grupo est\u00e3o Richard Zemel, e Zoubin Ghahramani.", "token2charspan": [[0, 5], [6, 8], [9, 18], [19, 21], [22, 31], [32, 33], [34, 47], [48, 50], [51, 64], [65, 73], [74, 76], [77, 80], [81, 86], [87, 92], [93, 100], [101, 106], [106, 107], [108, 109], [110, 116], [117, 127], [127, 128]]}
{"doc_key": "ai-test-65", "ner": [[8, 10, "metrics"], [16, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 10, 16, 16, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cada", "resultado", "de", "previs\u00e3o", "ou", "inst\u00e2ncia", "de", "uma", "matriz", "de", "confus\u00e3o", "representa", "um", "ponto", "no", "espa\u00e7o", "ROC", "."], "sentence-detokenized": "Cada resultado de previs\u00e3o ou inst\u00e2ncia de uma matriz de confus\u00e3o representa um ponto no espa\u00e7o ROC.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 26], [27, 29], [30, 39], [40, 42], [43, 46], [47, 53], [54, 56], [57, 65], [66, 76], [77, 79], [80, 85], [86, 88], [89, 95], [96, 99], [99, 100]]}
{"doc_key": "ai-test-66", "ner": [[3, 3, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [15, 18, "product"], [21, 23, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 21, 23, "physical", "", false, false], [7, 8, 21, 23, "physical", "", false, false], [10, 11, 21, 23, "physical", "", false, false], [15, 18, 3, 3, "artifact", "", false, false], [15, 18, 7, 8, "artifact", "", false, false], [15, 18, 10, 11, "artifact", "", false, false], [15, 18, 21, 23, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Em", "1997", ",", "Thrun", "e", "seus", "colegas", "Wolfram", "Burgard", "e", "Dieter", "Fox", "desenvolveram", "o", "primeiro", "guia", "tur\u00edstico", "rob\u00f3tico", "do", "mundo", "no", "Deutsches", "Museum", "Bonn", "(", "1997", ")", "."], "sentence-detokenized": "Em 1997, Thrun e seus colegas Wolfram Burgard e Dieter Fox desenvolveram o primeiro guia tur\u00edstico rob\u00f3tico do mundo no Deutsches Museum Bonn (1997).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 16], [17, 21], [22, 29], [30, 37], [38, 45], [46, 47], [48, 54], [55, 58], [59, 72], [73, 74], [75, 83], [84, 88], [89, 98], [99, 107], [108, 110], [111, 116], [117, 119], [120, 129], [130, 136], [137, 141], [142, 143], [143, 147], [147, 148], [148, 149]]}
{"doc_key": "ai-test-67", "ner": [[0, 0, "product"], [8, 9, "misc"], [23, 27, "field"], [31, 32, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 0, 0, "part-of", "", false, false], [23, 27, 0, 0, "usage", "", false, false], [31, 32, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["WordNet", "\u00e9", "um", "banco", "de", "dados", "l\u00e9xico", "de", "rela\u00e7\u00f5es", "sem\u00e2nticas", "entre", "palavras", "em", "mais", "de", "200", "idiomas", ".", "seu", "uso", "principal", "\u00e9", "no", "processamento", "autom\u00e1tico", "de", "linguagem", "natural", "e", "aplica\u00e7\u00f5es", "de", "intelig\u00eancia", "artificial", "."], "sentence-detokenized": "WordNet \u00e9 um banco de dados l\u00e9xico de rela\u00e7\u00f5es sem\u00e2nticas entre palavras em mais de 200 idiomas. seu uso principal \u00e9 no processamento autom\u00e1tico de linguagem natural e aplica\u00e7\u00f5es de intelig\u00eancia artificial.", "token2charspan": [[0, 7], [8, 9], [10, 12], [13, 18], [19, 21], [22, 27], [28, 34], [35, 37], [38, 46], [47, 57], [58, 63], [64, 72], [73, 75], [76, 80], [81, 83], [84, 87], [88, 95], [95, 96], [97, 100], [101, 104], [105, 114], [115, 116], [117, 119], [120, 133], [134, 144], [145, 147], [148, 157], [158, 165], [166, 167], [168, 178], [179, 181], [182, 194], [195, 205], [205, 206]]}
{"doc_key": "ai-test-68", "ner": [[4, 7, "field"], [11, 14, "conference"], [16, 22, "conference"], [24, 24, "conference"], [27, 27, "conference"], [35, 37, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 14, 4, 7, "topic", "", false, false], [11, 14, 35, 37, "topic", "", false, false], [16, 22, 4, 7, "topic", "", false, false], [16, 22, 35, 37, "topic", "", false, false], [24, 24, 4, 7, "topic", "", false, false], [24, 24, 35, 37, "topic", "", false, false], [27, 27, 4, 7, "topic", "", false, false], [27, 27, 35, 37, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Confer\u00eancias", "na", "\u00e1rea", "de", "processamento", "de", "linguagem", "natural", ",", "como", "a", "Associa\u00e7\u00e3o", "para", "Lingu\u00edstica", "Computacional", ",", "Cap\u00edtulo", "Norte-Americano", "da", "Associa\u00e7\u00e3o", "para", "Lingu\u00edstica", "Computacional", ",", "EMNLP", ",", "e", "HLT", ",", "est\u00e3o", "come\u00e7ando", "a", "incluir", "trabalhos", "sobre", "processamento", "de", "fala", "."], "sentence-detokenized": "Confer\u00eancias na \u00e1rea de processamento de linguagem natural, como a Associa\u00e7\u00e3o para Lingu\u00edstica Computacional, Cap\u00edtulo Norte-Americano da Associa\u00e7\u00e3o para Lingu\u00edstica Computacional, EMNLP, e HLT, est\u00e3o come\u00e7ando a incluir trabalhos sobre processamento de fala.", "token2charspan": [[0, 12], [13, 15], [16, 20], [21, 23], [24, 37], [38, 40], [41, 50], [51, 58], [58, 59], [60, 64], [65, 66], [67, 77], [78, 82], [83, 94], [95, 108], [108, 109], [110, 118], [119, 134], [135, 137], [138, 148], [149, 153], [154, 165], [166, 179], [179, 180], [181, 186], [186, 187], [188, 189], [190, 193], [193, 194], [195, 200], [201, 210], [211, 212], [213, 220], [221, 230], [231, 236], [237, 250], [251, 253], [254, 258], [258, 259]]}
{"doc_key": "ai-test-69", "ner": [[4, 4, "programlang"], [21, 23, "misc"], [39, 41, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Um", "conjunto", "de", "programas", "Java", "utiliza", "o", "l\u00e9xico", "para", "trabalhar", "atrav\u00e9s", "das", "varia\u00e7\u00f5es", "dos", "textos", "biom\u00e9dicos", ",", "relacionando", "palavras", "por", "suas", "partes", "da", "fala", ",", "o", "que", "pode", "ser", "\u00fatil", "em", "buscas", "na", "web", "ou", "buscas", "atrav\u00e9s", "de", "um", "registro", "m\u00e9dico", "eletr\u00f4nico", "."], "sentence-detokenized": "Um conjunto de programas Java utiliza o l\u00e9xico para trabalhar atrav\u00e9s das varia\u00e7\u00f5es dos textos biom\u00e9dicos, relacionando palavras por suas partes da fala, o que pode ser \u00fatil em buscas na web ou buscas atrav\u00e9s de um registro m\u00e9dico eletr\u00f4nico.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 24], [25, 29], [30, 37], [38, 39], [40, 46], [47, 51], [52, 61], [62, 69], [70, 73], [74, 83], [84, 87], [88, 94], [95, 105], [105, 106], [107, 119], [120, 128], [129, 132], [133, 137], [138, 144], [145, 147], [148, 152], [152, 153], [154, 155], [156, 159], [160, 164], [165, 168], [169, 173], [174, 176], [177, 183], [184, 186], [187, 190], [191, 193], [194, 200], [201, 208], [209, 211], [212, 214], [215, 223], [224, 230], [231, 241], [241, 242]]}
{"doc_key": "ai-test-70", "ner": [[6, 6, "algorithm"], [8, 8, "algorithm"], [10, 10, "algorithm"], [12, 12, "algorithm"], [14, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["H\u00e1", "muitos", "algoritmos", "mais", "recentes", "como", "LPBoost", ",", "TotalBoost", ",", "BrownBoost", ",", "xgboost", ",", "MadaBoost", ",", "e", "outros", "."], "sentence-detokenized": "H\u00e1 muitos algoritmos mais recentes como LPBoost, TotalBoost, BrownBoost, xgboost, MadaBoost, e outros.", "token2charspan": [[0, 2], [3, 9], [10, 20], [21, 25], [26, 34], [35, 39], [40, 47], [47, 48], [49, 59], [59, 60], [61, 71], [71, 72], [73, 80], [80, 81], [82, 91], [91, 92], [93, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-test-71", "ner": [[7, 7, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Este", "\u00e9", "um", "exemplo", "de", "implementa\u00e7\u00e3o", "em", "Python", ":"], "sentence-detokenized": "Este \u00e9 um exemplo de implementa\u00e7\u00e3o em Python:", "token2charspan": [[0, 4], [5, 6], [7, 9], [10, 17], [18, 20], [21, 34], [35, 37], [38, 44], [44, 45]]}
{"doc_key": "ai-test-72", "ner": [[4, 4, "organisation"], [5, 5, "product"], [10, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 4, 4, "artifact", "made_by_company", false, false], [10, 13, 5, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["O", "console", "de", "jogos", "Mattel", "Intellivision", "ofereceu", "o", "m\u00f3dulo", "de", "S\u00edntese", "de", "Voz", "Intellivoice", "em", "1982", "."], "sentence-detokenized": "O console de jogos Mattel Intellivision ofereceu o m\u00f3dulo de S\u00edntese de Voz Intellivoice em 1982.", "token2charspan": [[0, 1], [2, 9], [10, 12], [13, 18], [19, 25], [26, 39], [40, 48], [49, 50], [51, 57], [58, 60], [61, 68], [69, 71], [72, 75], [76, 88], [89, 91], [92, 96], [96, 97]]}
{"doc_key": "ai-test-73", "ner": [[4, 5, "task"], [9, 15, "task"], [18, 19, "field"], [21, 23, "task"], [27, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 15, 4, 5, "part-of", "", false, false], [18, 19, 4, 5, "part-of", "", false, false], [21, 23, 4, 5, "part-of", "", false, false], [27, 31, 21, 23, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Ele", "tamb\u00e9m", "trabalhou", "na", "tradu\u00e7\u00e3o", "autom\u00e1tica", ",", "tanto", "na", "MT", "baseada", "no", "conhecimento", "de", "alta", "precis\u00e3o", "como", "no", "aprendizado", "autom\u00e1tico", "para", "tradu\u00e7\u00e3o", "autom\u00e1tica", "estat\u00edstica", "(", "como", "a", "MT", "baseada", "em", "exemplos", "generalizados", ")", "."], "sentence-detokenized": "Ele tamb\u00e9m trabalhou na tradu\u00e7\u00e3o autom\u00e1tica, tanto na MT baseada no conhecimento de alta precis\u00e3o como no aprendizado autom\u00e1tico para tradu\u00e7\u00e3o autom\u00e1tica estat\u00edstica (como a MT baseada em exemplos generalizados).", "token2charspan": [[0, 3], [4, 10], [11, 20], [21, 23], [24, 32], [33, 43], [43, 44], [45, 50], [51, 53], [54, 56], [57, 64], [65, 67], [68, 80], [81, 83], [84, 88], [89, 97], [98, 102], [103, 105], [106, 117], [118, 128], [129, 133], [134, 142], [143, 153], [154, 165], [166, 167], [167, 171], [172, 173], [174, 176], [177, 184], [185, 187], [188, 196], [197, 210], [210, 211], [211, 212]]}
{"doc_key": "ai-test-74", "ner": [[0, 2, "misc"], [7, 7, "misc"], [25, 26, "algorithm"], [28, 30, "field"], [32, 34, "field"], [36, 36, "field"], [38, 40, "field"], [42, 42, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 25, 26, "general-affiliation", "", false, false], [0, 2, 28, 30, "general-affiliation", "", false, false], [0, 2, 32, 34, "general-affiliation", "", false, false], [0, 2, 36, 36, "general-affiliation", "", false, false], [0, 2, 38, 40, "general-affiliation", "", false, false], [0, 2, 42, 42, "general-affiliation", "", false, false], [7, 7, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["O", "Wolfram", "Mathematica", "(", "normalmente", "chamado", "de", "Mathematica", ")", "\u00e9", "um", "moderno", "sistema", "de", "computa\u00e7\u00e3o", "t\u00e9cnica", "que", "abrange", "a", "maioria", "das", "\u00e1reas", "t\u00e9cnicas", "-", "incluindo", "redes", "neurais", ",", "aprendizagem", "de", "m\u00e1quinas", ",", "processamento", "de", "imagens", ",", "geometria", ",", "ci\u00eancia", "de", "dados", ",", "visualiza\u00e7\u00f5es", "e", "outras", "."], "sentence-detokenized": "O Wolfram Mathematica (normalmente chamado de Mathematica) \u00e9 um moderno sistema de computa\u00e7\u00e3o t\u00e9cnica que abrange a maioria das \u00e1reas t\u00e9cnicas - incluindo redes neurais, aprendizagem de m\u00e1quinas, processamento de imagens, geometria, ci\u00eancia de dados, visualiza\u00e7\u00f5es e outras.", "token2charspan": [[0, 1], [2, 9], [10, 21], [22, 23], [23, 34], [35, 42], [43, 45], [46, 57], [57, 58], [59, 60], [61, 63], [64, 71], [72, 79], [80, 82], [83, 93], [94, 101], [102, 105], [106, 113], [114, 115], [116, 123], [124, 127], [128, 133], [134, 142], [143, 144], [145, 154], [155, 160], [161, 168], [168, 169], [170, 182], [183, 185], [186, 194], [194, 195], [196, 209], [210, 212], [213, 220], [220, 221], [222, 231], [231, 232], [233, 240], [241, 243], [244, 249], [249, 250], [251, 264], [265, 266], [267, 273], [273, 274]]}
{"doc_key": "ai-test-75", "ner": [[2, 6, "product"], [10, 11, "researcher"], [19, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 19, 2, 6, "type-of", "", false, false], [19, 19, 10, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["O", "primeiro", "rob\u00f4", "operado", "digitalmente", "e", "program\u00e1vel", "foi", "inventado", "por", "George", "Devol", "em", "1954", "e", "acabou", "sendo", "chamado", "de", "Unimate", "."], "sentence-detokenized": "O primeiro rob\u00f4 operado digitalmente e program\u00e1vel foi inventado por George Devol em 1954 e acabou sendo chamado de Unimate.", "token2charspan": [[0, 1], [2, 10], [11, 15], [16, 23], [24, 36], [37, 38], [39, 50], [51, 54], [55, 64], [65, 68], [69, 75], [76, 81], [82, 84], [85, 89], [90, 91], [92, 98], [99, 104], [105, 112], [113, 115], [116, 123], [123, 124]]}
{"doc_key": "ai-test-76", "ner": [[2, 2, "algorithm"], [4, 5, "algorithm"], [18, 20, "task"], [22, 24, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 2, 4, 5, "compare", "", false, false], [4, 5, 18, 20, "general-affiliation", "", false, false], [4, 5, 22, 24, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Como", "os", "DBNs", ",", "os", "DBMs", "podem", "aprender", "representa\u00e7\u00f5es", "internas", "complexas", "e", "abstratas", "da", "entrada", "em", "tarefas", "como", "reconhecimento", "de", "objetos", "ou", "reconhecimento", "de", "fala", ",", "usando", "dados", "limitados", "e", "rotulados", "para", "afinar", "as", "representa\u00e7\u00f5es", "constru\u00eddas", "usando", "um", "grande", "conjunto", "de", "dados", "de", "entrada", "sensoriais", "n\u00e3o", "rotulados", "."], "sentence-detokenized": "Como os DBNs, os DBMs podem aprender representa\u00e7\u00f5es internas complexas e abstratas da entrada em tarefas como reconhecimento de objetos ou reconhecimento de fala, usando dados limitados e rotulados para afinar as representa\u00e7\u00f5es constru\u00eddas usando um grande conjunto de dados de entrada sensoriais n\u00e3o rotulados.", "token2charspan": [[0, 4], [5, 7], [8, 12], [12, 13], [14, 16], [17, 21], [22, 27], [28, 36], [37, 51], [52, 60], [61, 70], [71, 72], [73, 82], [83, 85], [86, 93], [94, 96], [97, 104], [105, 109], [110, 124], [125, 127], [128, 135], [136, 138], [139, 153], [154, 156], [157, 161], [161, 162], [163, 169], [170, 175], [176, 185], [186, 187], [188, 197], [198, 202], [203, 209], [210, 212], [213, 227], [228, 239], [240, 246], [247, 249], [250, 256], [257, 265], [266, 268], [269, 274], [275, 277], [278, 285], [286, 296], [297, 300], [301, 310], [310, 311]]}
{"doc_key": "ai-test-77", "ner": [[7, 12, "task"], [16, 16, "conference"], [18, 18, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 16, 7, 12, "topic", "", false, false], [18, 18, 7, 12, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "confer\u00eancias", "cient\u00edficas", "onde", "o", "trabalho", "de", "reconhecimento", "de", "atividades", "baseadas", "na", "vis\u00e3o", "freq\u00fcentemente", "aparece", "s\u00e3o", "ICCV", "e", "CVPR", "."], "sentence-detokenized": "As confer\u00eancias cient\u00edficas onde o trabalho de reconhecimento de atividades baseadas na vis\u00e3o freq\u00fcentemente aparece s\u00e3o ICCV e CVPR.", "token2charspan": [[0, 2], [3, 15], [16, 27], [28, 32], [33, 34], [35, 43], [44, 46], [47, 61], [62, 64], [65, 75], [76, 84], [85, 87], [88, 93], [94, 108], [109, 116], [117, 120], [121, 125], [126, 127], [128, 132], [132, 133]]}
{"doc_key": "ai-test-78", "ner": [[1, 1, "field"], [6, 6, "algorithm"], [8, 8, "algorithm"], [17, 18, "metrics"], [21, 23, "metrics"], [25, 25, "metrics"], [38, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[6, 6, 1, 1, "part-of", "", false, false], [6, 6, 17, 18, "related-to", "finds", false, false], [6, 6, 21, 23, "related-to", "finds", false, false], [6, 6, 38, 39, "related-to", "", false, false], [8, 8, 6, 6, "named", "", false, false], [25, 25, 21, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Em", "estat\u00edstica", ",", "um", "algoritmo", "de", "expectativa-maximiza\u00e7\u00e3o", "(", "EM", ")", "\u00e9", "um", "m\u00e9todo", "iterativo", "para", "encontrar", "a", "m\u00e1xima", "probabilidade", "ou", "estimativas", "m\u00e1ximas", "a", "posteriori", "(", "MAP", ")", "de", "par\u00e2metros", "em", "modelos", "estat\u00edsticos", ",", "onde", "o", "modelo", "depende", "de", "vari\u00e1veis", "latentes", "n\u00e3o", "observadas", "."], "sentence-detokenized": "Em estat\u00edstica, um algoritmo de expectativa-maximiza\u00e7\u00e3o (EM) \u00e9 um m\u00e9todo iterativo para encontrar a m\u00e1xima probabilidade ou estimativas m\u00e1ximas a posteriori (MAP) de par\u00e2metros em modelos estat\u00edsticos, onde o modelo depende de vari\u00e1veis latentes n\u00e3o observadas.", "token2charspan": [[0, 2], [3, 14], [14, 15], [16, 18], [19, 28], [29, 31], [32, 55], [56, 57], [57, 59], [59, 60], [61, 62], [63, 65], [66, 72], [73, 82], [83, 87], [88, 97], [98, 99], [100, 106], [107, 120], [121, 123], [124, 135], [136, 143], [144, 145], [146, 156], [157, 158], [158, 161], [161, 162], [163, 165], [166, 176], [177, 179], [180, 187], [188, 200], [200, 201], [202, 206], [207, 208], [209, 215], [216, 223], [224, 226], [227, 236], [237, 245], [246, 249], [250, 260], [260, 261]]}
{"doc_key": "ai-test-79", "ner": [[10, 12, "metrics"], [14, 14, "metrics"], [19, 21, "metrics"], [23, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 14, 10, 12, "named", "", false, false], [23, 23, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Da", "mesma", "forma", ",", "os", "investigadores", "\u00e0s", "vezes", "relatam", "a", "FALSE", "Positive", "Rate", "(", "FPR", ")", "bem", "como", "a", "FALSE", "Negative", "Rate", "(", "FNR", ")", "."], "sentence-detokenized": "Da mesma forma, os investigadores \u00e0s vezes relatam a FALSE Positive Rate (FPR) bem como a FALSE Negative Rate (FNR).", "token2charspan": [[0, 2], [3, 8], [9, 14], [14, 15], [16, 18], [19, 33], [34, 36], [37, 42], [43, 50], [51, 52], [53, 58], [59, 67], [68, 72], [73, 74], [74, 77], [77, 78], [79, 82], [83, 87], [88, 89], [90, 95], [96, 104], [105, 109], [110, 111], [111, 114], [114, 115], [115, 116]]}
{"doc_key": "ai-test-80", "ner": [[5, 6, "metrics"], [11, 11, "field"], [9, 13, "metrics"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 5, 6, "usage", "", false, false], [16, 17, 9, 13, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["O", "conceito", "\u00e9", "semelhante", "\u00e0", "rela\u00e7\u00e3o", "sinal/ru\u00eddo", "usada", "na", "matriz", "de", "ci\u00eancias", "e", "confus\u00e3o", "usada", "na", "intelig\u00eancia", "artificial", "."], "sentence-detokenized": "O conceito \u00e9 semelhante \u00e0 rela\u00e7\u00e3o sinal/ru\u00eddo usada na matriz de ci\u00eancias e confus\u00e3o usada na intelig\u00eancia artificial.", "token2charspan": [[0, 1], [2, 10], [11, 12], [13, 23], [24, 25], [26, 33], [34, 45], [46, 51], [52, 54], [55, 61], [62, 64], [65, 73], [74, 75], [76, 84], [85, 90], [91, 93], [94, 106], [107, 117], [117, 118]]}
{"doc_key": "ai-test-81", "ner": [[5, 6, "field"], [13, 14, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [32, 37, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 13, 14, "general-affiliation", "", false, false], [5, 6, 20, 21, "general-affiliation", "", false, false], [5, 6, 23, 24, "general-affiliation", "", false, false], [32, 37, 5, 6, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["O", "C\u00f3digo", "de", "\u00c9tica", "sobre", "Aumento", "Humano", ",", "que", "foi", "originalmente", "introduzido", "por", "Steve", "Mann", "em", "2004", "e", "refinado", "com", "Ray", "Kurzweil", "e", "Marvin", "Minsky", "em", "2013", ",", "foi", "finalmente", "ratificado", "na", "confer\u00eancia", "de", "Realidade", "Virtual", "de", "Toronto", "em", "25", "de", "junho", "de", "2017", "."], "sentence-detokenized": "O C\u00f3digo de \u00c9tica sobre Aumento Humano, que foi originalmente introduzido por Steve Mann em 2004 e refinado com Ray Kurzweil e Marvin Minsky em 2013, foi finalmente ratificado na confer\u00eancia de Realidade Virtual de Toronto em 25 de junho de 2017.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 17], [18, 23], [24, 31], [32, 38], [38, 39], [40, 43], [44, 47], [48, 61], [62, 73], [74, 77], [78, 83], [84, 88], [89, 91], [92, 96], [97, 98], [99, 107], [108, 111], [112, 115], [116, 124], [125, 126], [127, 133], [134, 140], [141, 143], [144, 148], [148, 149], [150, 153], [154, 164], [165, 175], [176, 178], [179, 190], [191, 193], [194, 203], [204, 211], [212, 214], [215, 222], [223, 225], [226, 228], [229, 231], [232, 237], [238, 240], [241, 245], [245, 246]]}
{"doc_key": "ai-test-82", "ner": [[3, 5, "person"], [11, 14, "organisation"], [20, 21, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 11, 14, "role", "directed_for", false, false], [3, 5, 20, 21, "role", "collaborator", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Em", "1913", ",", "Walter", "R.", "Booth", "dirigiu", "10", "filmes", "para", "o", "Kinoplastikon", "do", "Reino", "Unido", ",", "presumivelmente", "em", "colabora\u00e7\u00e3o", "com", "Cecil", "Hepworth", "."], "sentence-detokenized": "Em 1913, Walter R. Booth dirigiu 10 filmes para o Kinoplastikon do Reino Unido, presumivelmente em colabora\u00e7\u00e3o com Cecil Hepworth.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 18], [19, 24], [25, 32], [33, 35], [36, 42], [43, 47], [48, 49], [50, 63], [64, 66], [67, 72], [73, 78], [78, 79], [80, 95], [96, 98], [99, 110], [111, 114], [115, 120], [121, 129], [129, 130]]}
{"doc_key": "ai-test-83", "ner": [[15, 15, "location"], [12, 14, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 14, 15, 15, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Eles", "apresentaram", "seu", "novo", "rob\u00f4", "em", "1961", ",", "em", "uma", "feira", "no", "Cow", "Palace", "de", "Chicago", "."], "sentence-detokenized": "Eles apresentaram seu novo rob\u00f4 em 1961, em uma feira no Cow Palace de Chicago.", "token2charspan": [[0, 4], [5, 17], [18, 21], [22, 26], [27, 31], [32, 34], [35, 39], [39, 40], [41, 43], [44, 47], [48, 53], [54, 56], [57, 60], [61, 67], [68, 70], [71, 78], [78, 79]]}
{"doc_key": "ai-test-84", "ner": [[3, 3, "product"], [8, 10, "task"], [14, 17, "field"], [19, 20, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 8, 10, "usage", "", false, false], [3, 3, 14, 17, "usage", "", false, false], [3, 3, 19, 20, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Enquanto", "algumas", "aplica\u00e7\u00f5es", "chatbot", "usam", "extensos", "processos", "de", "classifica\u00e7\u00e3o", "de", "palavras", ",", "processadores", "de", "processamento", "de", "linguagem", "natural", "e", "intelig\u00eancia", "artificial", "sofisticada", ",", "outras", "simplesmente", "procuram", "palavras-chave", "gerais", "e", "geram", "respostas", "usando", "frases", "comuns", "obtidas", "de", "uma", "biblioteca", "ou", "banco", "de", "dados", "associado", "."], "sentence-detokenized": "Enquanto algumas aplica\u00e7\u00f5es chatbot usam extensos processos de classifica\u00e7\u00e3o de palavras, processadores de processamento de linguagem natural e intelig\u00eancia artificial sofisticada, outras simplesmente procuram palavras-chave gerais e geram respostas usando frases comuns obtidas de uma biblioteca ou banco de dados associado.", "token2charspan": [[0, 8], [9, 16], [17, 27], [28, 35], [36, 40], [41, 49], [50, 59], [60, 62], [63, 76], [77, 79], [80, 88], [88, 89], [90, 103], [104, 106], [107, 120], [121, 123], [124, 133], [134, 141], [142, 143], [144, 156], [157, 167], [168, 179], [179, 180], [181, 187], [188, 200], [201, 209], [210, 224], [225, 231], [232, 233], [234, 239], [240, 249], [250, 256], [257, 263], [264, 270], [271, 278], [279, 281], [282, 285], [286, 296], [297, 299], [300, 305], [306, 308], [309, 314], [315, 324], [324, 325]]}
{"doc_key": "ai-test-85", "ner": [[2, 2, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["O", "modelo", "WaveNet", "proposto", "em", "2016", "atinge", "um", "\u00f3timo", "desempenho", "na", "qualidade", "da", "fala", "."], "sentence-detokenized": "O modelo WaveNet proposto em 2016 atinge um \u00f3timo desempenho na qualidade da fala.", "token2charspan": [[0, 1], [2, 8], [9, 16], [17, 25], [26, 28], [29, 33], [34, 40], [41, 43], [44, 49], [50, 60], [61, 63], [64, 73], [74, 76], [77, 81], [81, 82]]}
{"doc_key": "ai-test-86", "ner": [[4, 5, "product"], [7, 9, "misc"], [11, 13, "misc"], [15, 16, "misc"], [18, 21, "misc"], [23, 25, "organisation"], [27, 27, "organisation"], [29, 34, "organisation"], [36, 36, "organisation"], [38, 41, "organisation"], [43, 44, "organisation"], [46, 48, "organisation"], [50, 52, "organisation"], [55, 55, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 5, 7, 9, "general-affiliation", "", false, false], [4, 5, 11, 13, "general-affiliation", "", false, false], [4, 5, 15, 16, "general-affiliation", "", false, false], [4, 5, 18, 21, "general-affiliation", "", false, false], [23, 25, 4, 5, "usage", "", false, false], [27, 27, 4, 5, "usage", "", false, false], [29, 34, 4, 5, "usage", "", false, false], [36, 36, 4, 5, "usage", "", false, false], [38, 41, 4, 5, "usage", "", false, false], [43, 44, 4, 5, "usage", "", false, false], [46, 48, 4, 5, "usage", "", false, false], [50, 52, 4, 5, "usage", "", false, false], [55, 55, 4, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Organiza\u00e7\u00f5es", "conhecidas", "por", "utilizar", "a", "ALE", "para", "gerenciamento", "de", "emerg\u00eancia", ",", "al\u00edvio", "de", "desastres", ",", "comunica\u00e7\u00e3o", "comum", "ou", "resposta", "a", "situa\u00e7\u00f5es", "extraordin\u00e1rias", ":", "Cruz", "Vermelha", "Americana", ",", "FEMA", ",", "Equipes", "de", "Assist\u00eancia", "M\u00e9dica", "em", "Cat\u00e1strofes", ",", "OTAN", ",", "Bureau", "Federal", "de", "Investiga\u00e7\u00e3o", ",", "Na\u00e7\u00f5es", "Unidas", ",", "AT", "&", "T", ",", "Patrulha", "A\u00e9rea", "Civil", ",", "(", "ARES", ")", "."], "sentence-detokenized": "Organiza\u00e7\u00f5es conhecidas por utilizar a ALE para gerenciamento de emerg\u00eancia, al\u00edvio de desastres, comunica\u00e7\u00e3o comum ou resposta a situa\u00e7\u00f5es extraordin\u00e1rias: Cruz Vermelha Americana, FEMA, Equipes de Assist\u00eancia M\u00e9dica em Cat\u00e1strofes, OTAN, Bureau Federal de Investiga\u00e7\u00e3o, Na\u00e7\u00f5es Unidas, AT & T, Patrulha A\u00e9rea Civil, (ARES).", "token2charspan": [[0, 12], [13, 23], [24, 27], [28, 36], [37, 38], [39, 42], [43, 47], [48, 61], [62, 64], [65, 75], [75, 76], [77, 83], [84, 86], [87, 96], [96, 97], [98, 109], [110, 115], [116, 118], [119, 127], [128, 129], [130, 139], [140, 155], [155, 156], [157, 161], [162, 170], [171, 180], [180, 181], [182, 186], [186, 187], [188, 195], [196, 198], [199, 210], [211, 217], [218, 220], [221, 232], [232, 233], [234, 238], [238, 239], [240, 246], [247, 254], [255, 257], [258, 270], [270, 271], [272, 278], [279, 285], [285, 286], [287, 289], [290, 291], [292, 293], [293, 294], [295, 303], [304, 309], [310, 315], [315, 316], [317, 318], [318, 322], [322, 323], [323, 324]]}
{"doc_key": "ai-test-87", "ner": [[3, 4, "algorithm"], [15, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Aqui", ",", "o", "delta", "Kronecker", "\u00e9", "usado", "para", "simplificar", "(", "cf.", "a", "derivada", "de", "uma", "fun\u00e7\u00e3o", "sigm\u00f3ide", ",", "sendo", "expressa", "atrav\u00e9s", "da", "pr\u00f3pria", "fun\u00e7\u00e3o", ")", "."], "sentence-detokenized": "Aqui, o delta Kronecker \u00e9 usado para simplificar (cf. a derivada de uma fun\u00e7\u00e3o sigm\u00f3ide, sendo expressa atrav\u00e9s da pr\u00f3pria fun\u00e7\u00e3o).", "token2charspan": [[0, 4], [4, 5], [6, 7], [8, 13], [14, 23], [24, 25], [26, 31], [32, 36], [37, 48], [49, 50], [50, 53], [54, 55], [56, 64], [65, 67], [68, 71], [72, 78], [79, 87], [87, 88], [89, 94], [95, 103], [104, 111], [112, 114], [115, 122], [123, 129], [129, 130], [130, 131]]}
{"doc_key": "ai-test-88", "ner": [[11, 12, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "teoria", "baseia-se", "em", "fundamentos", "filos\u00f3ficos", ",", "e", "foi", "fundada", "por", "Ray", "Solomonoff", "por", "volta", "de", "1960", ".", "Samuel", "Rathmanner", "e", "Marcus", "Hutter", "."], "sentence-detokenized": "A teoria baseia-se em fundamentos filos\u00f3ficos, e foi fundada por Ray Solomonoff por volta de 1960. Samuel Rathmanner e Marcus Hutter.", "token2charspan": [[0, 1], [2, 8], [9, 18], [19, 21], [22, 33], [34, 45], [45, 46], [47, 48], [49, 52], [53, 60], [61, 64], [65, 68], [69, 79], [80, 83], [84, 89], [90, 92], [93, 97], [97, 98], [99, 105], [106, 116], [117, 118], [119, 125], [126, 132], [132, 133]]}
{"doc_key": "ai-test-89", "ner": [[0, 0, "product"], [12, 13, "misc"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 12, 13, "type-of", "", false, false], [0, 0, 16, 17, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["WordNet", ",", "um", "banco", "de", "dados", "livremente", "dispon\u00edvel", "originalmente", "projetado", "como", "uma", "rede", "sem\u00e2ntica", "baseada", "em", "princ\u00edpios", "psicoling\u00fc\u00edsticos", ",", "foi", "ampliado", "com", "a", "adi\u00e7\u00e3o", "de", "defini\u00e7\u00f5es", "e", "agora", "tamb\u00e9m", "\u00e9", "visto", "como", "um", "dicion\u00e1rio", "."], "sentence-detokenized": "WordNet, um banco de dados livremente dispon\u00edvel originalmente projetado como uma rede sem\u00e2ntica baseada em princ\u00edpios psicoling\u00fc\u00edsticos, foi ampliado com a adi\u00e7\u00e3o de defini\u00e7\u00f5es e agora tamb\u00e9m \u00e9 visto como um dicion\u00e1rio.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 17], [18, 20], [21, 26], [27, 37], [38, 48], [49, 62], [63, 72], [73, 77], [78, 81], [82, 86], [87, 96], [97, 104], [105, 107], [108, 118], [119, 136], [136, 137], [138, 141], [142, 150], [151, 154], [155, 156], [157, 163], [164, 166], [167, 177], [178, 179], [180, 185], [186, 192], [193, 194], [195, 200], [201, 205], [206, 208], [209, 219], [219, 220]]}
{"doc_key": "ai-test-90", "ner": [[6, 7, "field"], [17, 20, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 20, 6, 7, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Avan\u00e7os", "no", "campo", "da", "pesquisa", "de", "imagem", "computacional", "s\u00e3o", "apresentados", "em", "v\u00e1rios", "locais", ",", "incluindo", "publica\u00e7\u00f5es", "da", "SIGGRAPH", "e", "do", "SIGGRAPH", "."], "sentence-detokenized": "Avan\u00e7os no campo da pesquisa de imagem computacional s\u00e3o apresentados em v\u00e1rios locais, incluindo publica\u00e7\u00f5es da SIGGRAPH e do SIGGRAPH.", "token2charspan": [[0, 7], [8, 10], [11, 16], [17, 19], [20, 28], [29, 31], [32, 38], [39, 52], [53, 56], [57, 69], [70, 72], [73, 79], [80, 86], [86, 87], [88, 97], [98, 109], [110, 112], [113, 121], [122, 123], [124, 126], [127, 135], [135, 136]]}
{"doc_key": "ai-test-91", "ner": [[0, 1, "task"], [10, 11, "task"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 0, 1, "part-of", "", false, false], [13, 14, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "classifica\u00e7\u00e3o", "pode", "ser", "pensada", "como", "dois", "problemas", "distintos", "-", "classifica\u00e7\u00e3o", "bin\u00e1ria", "e", "classifica\u00e7\u00e3o", "multiclasse", "."], "sentence-detokenized": "A classifica\u00e7\u00e3o pode ser pensada como dois problemas distintos - classifica\u00e7\u00e3o bin\u00e1ria e classifica\u00e7\u00e3o multiclasse.", "token2charspan": [[0, 1], [2, 15], [16, 20], [21, 24], [25, 32], [33, 37], [38, 42], [43, 52], [53, 62], [63, 64], [65, 78], [79, 86], [87, 88], [89, 102], [103, 114], [114, 115]]}
{"doc_key": "ai-test-92", "ner": [[13, 14, "algorithm"], [19, 21, "algorithm"], [23, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 21, 13, 14, "type-of", "", false, false], [23, 23, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Os", "pesquisadores", "de", "genes", "avan\u00e7ados", "para", "os", "genomas", "procari\u00f3tico", "e", "eucari\u00f3tico", "normalmente", "usam", "modelos", "probabil\u00edsticos", "complexos", ",", "tais", "como", "modelos", "Markov", "ocultos", "(", "HMMs", ")", "para", "combinar", "informa\u00e7\u00f5es", "de", "uma", "variedade", "de", "diferentes", "medi\u00e7\u00f5es", "de", "sinal", "e", "conte\u00fado", "."], "sentence-detokenized": "Os pesquisadores de genes avan\u00e7ados para os genomas procari\u00f3tico e eucari\u00f3tico normalmente usam modelos probabil\u00edsticos complexos, tais como modelos Markov ocultos (HMMs) para combinar informa\u00e7\u00f5es de uma variedade de diferentes medi\u00e7\u00f5es de sinal e conte\u00fado.", "token2charspan": [[0, 2], [3, 16], [17, 19], [20, 25], [26, 35], [36, 40], [41, 43], [44, 51], [52, 64], [65, 66], [67, 78], [79, 90], [91, 95], [96, 103], [104, 119], [120, 129], [129, 130], [131, 135], [136, 140], [141, 148], [149, 155], [156, 163], [164, 165], [165, 169], [169, 170], [171, 175], [176, 184], [185, 196], [197, 199], [200, 203], [204, 213], [214, 216], [217, 227], [228, 236], [237, 239], [240, 245], [246, 247], [248, 256], [256, 257]]}
{"doc_key": "ai-test-93", "ner": [[0, 1, "misc"], [4, 4, "misc"], [10, 11, "field"], [14, 15, "algorithm"], [18, 20, "algorithm"], [22, 22, "algorithm"], [32, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 10, 11, "part-of", "", false, false], [0, 1, 14, 15, "usage", "", false, false], [4, 4, 0, 1, "named", "", false, false], [18, 20, 0, 1, "origin", "", true, false], [22, 22, 18, 20, "named", "", false, false], [32, 33, 0, 1, "origin", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["A", "neuroevolu\u00e7\u00e3o", ",", "ou", "neuro-evolu\u00e7\u00e3o", ",", "\u00e9", "uma", "forma", "de", "intelig\u00eancia", "artificial", "que", "utiliza", "algoritmos", "evolutivos", "para", "gerar", "redes", "neurais", "artificiais", "(", "ANN", ")", ",", "par\u00e2metros", ",", "topologia", "e", "regras", ".", "e", "rob\u00f3tica", "evolutiva", "."], "sentence-detokenized": "A neuroevolu\u00e7\u00e3o, ou neuro-evolu\u00e7\u00e3o, \u00e9 uma forma de intelig\u00eancia artificial que utiliza algoritmos evolutivos para gerar redes neurais artificiais (ANN), par\u00e2metros, topologia e regras. e rob\u00f3tica evolutiva.", "token2charspan": [[0, 1], [2, 15], [15, 16], [17, 19], [20, 34], [34, 35], [36, 37], [38, 41], [42, 47], [48, 50], [51, 63], [64, 74], [75, 78], [79, 86], [87, 97], [98, 108], [109, 113], [114, 119], [120, 125], [126, 133], [134, 145], [146, 147], [147, 150], [150, 151], [151, 152], [153, 163], [163, 164], [165, 174], [175, 176], [177, 183], [183, 184], [185, 186], [187, 195], [196, 205], [205, 206]]}
{"doc_key": "ai-test-94", "ner": [[2, 3, "organisation"], [10, 10, "metrics"], [11, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 2, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Desde", "que", "a", "IBM", "prop\u00f4s", "e", "realizou", "o", "sistema", "de", "BLEU", "Papineni", "et", "al", "."], "sentence-detokenized": "Desde que a IBM prop\u00f4s e realizou o sistema de BLEU Papineni et al.", "token2charspan": [[0, 5], [6, 9], [10, 11], [12, 15], [16, 22], [23, 24], [25, 33], [34, 35], [36, 43], [44, 46], [47, 51], [52, 60], [61, 63], [64, 66], [66, 67]]}
{"doc_key": "ai-test-95", "ner": [[10, 16, "conference"], [18, 18, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 18, 10, 16, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Em", "2009", ",", "especialistas", "participaram", "de", "uma", "confer\u00eancia", "organizada", "pela", "Associa\u00e7\u00e3o", "para", "o", "Progresso", "da", "Intelig\u00eancia", "Artificial", "(", "AAAI", ")", "para", "discutir", "se", "computadores", "e", "rob\u00f4s", "poderiam", "adquirir", "alguma", "autonomia", ",", "e", "em", "que", "medida", "essas", "habilidades", "poderiam", "representar", "uma", "amea\u00e7a", "ou", "perigo", "."], "sentence-detokenized": "Em 2009, especialistas participaram de uma confer\u00eancia organizada pela Associa\u00e7\u00e3o para o Progresso da Intelig\u00eancia Artificial (AAAI) para discutir se computadores e rob\u00f4s poderiam adquirir alguma autonomia, e em que medida essas habilidades poderiam representar uma amea\u00e7a ou perigo.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 22], [23, 35], [36, 38], [39, 42], [43, 54], [55, 65], [66, 70], [71, 81], [82, 86], [87, 88], [89, 98], [99, 101], [102, 114], [115, 125], [126, 127], [127, 131], [131, 132], [133, 137], [138, 146], [147, 149], [150, 162], [163, 164], [165, 170], [171, 179], [180, 188], [189, 195], [196, 205], [205, 206], [207, 208], [209, 211], [212, 215], [216, 222], [223, 228], [229, 240], [241, 249], [250, 261], [262, 265], [266, 272], [273, 275], [276, 282], [282, 283]]}
{"doc_key": "ai-test-96", "ner": [[27, 29, "metrics"], [31, 32, "researcher"], [34, 35, "researcher"], [37, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[37, 40, 27, 29, "topic", "", false, false], [37, 40, 31, 32, "artifact", "", false, false], [37, 40, 34, 35, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Ap\u00f3s", "o", "refor\u00e7o", ",", "um", "classificador", "constru\u00eddo", "a", "partir", "de", "200", "caracter\u00edsticas", "pode", "render", "uma", "taxa", "de", "detec\u00e7\u00e3o", "de", "95%", "sob", "um", "^", "{", "-5", "}", "/", "taxa", "positiva", "FALSA", "matem\u00e1tica", ".P.", "Viola", ",", "M.", "Jones", ",", "Robust", "Real-time", "Object", "Detection", ",", "2001", "."], "sentence-detokenized": "Ap\u00f3s o refor\u00e7o, um classificador constru\u00eddo a partir de 200 caracter\u00edsticas pode render uma taxa de detec\u00e7\u00e3o de 95% sob um ^ {-5} / taxa positiva FALSA matem\u00e1tica .P. Viola, M. Jones, Robust Real-time Object Detection, 2001.", "token2charspan": [[0, 4], [5, 6], [7, 14], [14, 15], [16, 18], [19, 32], [33, 43], [44, 45], [46, 52], [53, 55], [56, 59], [60, 75], [76, 80], [81, 87], [88, 91], [92, 96], [97, 99], [100, 108], [109, 111], [112, 115], [116, 119], [120, 122], [123, 124], [125, 126], [126, 128], [128, 129], [130, 131], [132, 136], [137, 145], [146, 151], [152, 162], [163, 166], [167, 172], [172, 173], [174, 176], [177, 182], [182, 183], [184, 190], [191, 200], [201, 207], [208, 217], [217, 218], [219, 223], [223, 224]]}
{"doc_key": "ai-test-97", "ner": [[6, 6, "programlang"], [9, 10, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["O", "site", "foi", "originalmente", "baseado", "em", "Perl", ",", "mas", "o", "IMDb", "n\u00e3o", "revela", "mais", "que", "software", "usa", "por", "raz\u00f5es", "de", "seguran\u00e7a", "."], "sentence-detokenized": "O site foi originalmente baseado em Perl, mas o IMDb n\u00e3o revela mais que software usa por raz\u00f5es de seguran\u00e7a.", "token2charspan": [[0, 1], [2, 6], [7, 10], [11, 24], [25, 32], [33, 35], [36, 40], [40, 41], [42, 45], [46, 47], [48, 52], [53, 56], [57, 63], [64, 68], [69, 72], [73, 81], [82, 85], [86, 89], [90, 96], [97, 99], [100, 109], [109, 110]]}
{"doc_key": "ai-test-98", "ner": [[5, 6, "researcher"], [8, 9, "researcher"], [11, 12, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["O", "start-up", "foi", "fundado", "por", "Demis", "Hassabis", ",", "Shane", "Legg", "e", "Mustafa", "Suleyman", "em", "2010", "."], "sentence-detokenized": "O start-up foi fundado por Demis Hassabis, Shane Legg e Mustafa Suleyman em 2010.", "token2charspan": [[0, 1], [2, 10], [11, 14], [15, 22], [23, 26], [27, 32], [33, 41], [41, 42], [43, 48], [49, 53], [54, 55], [56, 63], [64, 72], [73, 75], [76, 80], [80, 81]]}
{"doc_key": "ai-test-99", "ner": [[1, 3, "misc"], [9, 11, "metrics"], [26, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 11, 1, 3, "type-of", "", false, false], [26, 27, 1, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Duas", "fun\u00e7\u00f5es", "de", "perda", "muito", "comumente", "usadas", "s\u00e3o", "o", "erro", "quadr\u00e1tico", "m\u00e9dio", ",", "matem\u00e1tica", "(", "a", ")", "=", "a", "^", "2", "/", "matem\u00e1tica", ",", "e", "a", "perda", "absoluta", ",", "matem\u00e1tica", "(", "a", ")", "=", "|", "a", "|", "a", "|", "/", "matem\u00e1tica", "."], "sentence-detokenized": "Duas fun\u00e7\u00f5es de perda muito comumente usadas s\u00e3o o erro quadr\u00e1tico m\u00e9dio, matem\u00e1tica (a) = a ^ 2 / matem\u00e1tica, e a perda absoluta, matem\u00e1tica (a) = | a | a | / matem\u00e1tica.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 21], [22, 27], [28, 37], [38, 44], [45, 48], [49, 50], [51, 55], [56, 66], [67, 72], [72, 73], [74, 84], [85, 86], [86, 87], [87, 88], [89, 90], [91, 92], [93, 94], [95, 96], [97, 98], [99, 109], [109, 110], [111, 112], [113, 114], [115, 120], [121, 129], [129, 130], [131, 141], [142, 143], [143, 144], [144, 145], [146, 147], [148, 149], [150, 151], [152, 153], [154, 155], [156, 157], [158, 159], [160, 170], [170, 171]]}
{"doc_key": "ai-test-100", "ner": [[1, 5, "algorithm"], [15, 18, "algorithm"], [20, 20, "algorithm"], [24, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 5, 15, 18, "type-of", "example_of", false, false], [15, 18, 24, 26, "related-to", "", false, false], [20, 20, 15, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "m\u00e1quina", "vetorial", "de", "suporte", "de", "margens", "macias", "descrita", "acima", "\u00e9", "um", "exemplo", "de", "uma", "minimiza\u00e7\u00e3o", "emp\u00edrica", "de", "risco", "(", "ERM", ")", "para", "a", "perda", "da", "dobradi\u00e7a", "."], "sentence-detokenized": "A m\u00e1quina vetorial de suporte de margens macias descrita acima \u00e9 um exemplo de uma minimiza\u00e7\u00e3o emp\u00edrica de risco (ERM) para a perda da dobradi\u00e7a.", "token2charspan": [[0, 1], [2, 9], [10, 18], [19, 21], [22, 29], [30, 32], [33, 40], [41, 47], [48, 56], [57, 62], [63, 64], [65, 67], [68, 75], [76, 78], [79, 82], [83, 94], [95, 103], [104, 106], [107, 112], [113, 114], [114, 117], [117, 118], [119, 123], [124, 125], [126, 131], [132, 134], [135, 144], [144, 145]]}
{"doc_key": "ai-test-101", "ner": [[4, 5, "field"], [7, 7, "task"], [10, 12, "task"], [21, 22, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 12, 4, 5, "origin", "", false, false], [10, 12, 7, 7, "type-of", "", false, false], [21, 22, 10, 12, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Uma", "abordagem", "baseada", "no", "aprendizado", "profundo", "da", "MT", ",", "a", "tradu\u00e7\u00e3o", "autom\u00e1tica", "neural", "fez", "r\u00e1pidos", "progressos", "nos", "\u00faltimos", "anos", ",", "e", "o", "Google", "anunciou", "que", "seus", "servi\u00e7os", "de", "tradu\u00e7\u00e3o", "est\u00e3o", "agora", "utilizando", "esta", "tecnologia", "em", "prefer\u00eancia", "a", "seus", "m\u00e9todos", "estat\u00edsticos", "anteriores", "."], "sentence-detokenized": "Uma abordagem baseada no aprendizado profundo da MT, a tradu\u00e7\u00e3o autom\u00e1tica neural fez r\u00e1pidos progressos nos \u00faltimos anos, e o Google anunciou que seus servi\u00e7os de tradu\u00e7\u00e3o est\u00e3o agora utilizando esta tecnologia em prefer\u00eancia a seus m\u00e9todos estat\u00edsticos anteriores.", "token2charspan": [[0, 3], [4, 13], [14, 21], [22, 24], [25, 36], [37, 45], [46, 48], [49, 51], [51, 52], [53, 54], [55, 63], [64, 74], [75, 81], [82, 85], [86, 93], [94, 104], [105, 108], [109, 116], [117, 121], [121, 122], [123, 124], [125, 126], [127, 133], [134, 142], [143, 146], [147, 151], [152, 160], [161, 163], [164, 172], [173, 178], [179, 184], [185, 195], [196, 200], [201, 211], [212, 214], [215, 226], [227, 228], [229, 233], [234, 241], [242, 254], [255, 265], [265, 266]]}
{"doc_key": "ai-test-102", "ner": [[17, 17, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Isto", "tende", "a", "gerar", "ganhos", "de", "desempenho", "muito", "grandes", "quando", "se", "trabalha", "com", "grandes", "corpora\u00e7\u00f5es", "como", "a", "WordNet", "."], "sentence-detokenized": "Isto tende a gerar ganhos de desempenho muito grandes quando se trabalha com grandes corpora\u00e7\u00f5es como a WordNet.", "token2charspan": [[0, 4], [5, 10], [11, 12], [13, 18], [19, 25], [26, 28], [29, 39], [40, 45], [46, 53], [54, 60], [61, 63], [64, 72], [73, 76], [77, 84], [85, 96], [97, 101], [102, 103], [104, 111], [111, 112]]}
{"doc_key": "ai-test-103", "ner": [[0, 2, "task"], [6, 6, "field"], [20, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 20, 23, "part-of", "", false, false], [20, 23, 6, 6, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "detec\u00e7\u00e3o", "facial", "\u00e9", "usada", "em", "biometria", ",", "muitas", "vezes", "como", "parte", "de", "(", "ou", "em", "conjunto", "com", ")", "um", "sistema", "de", "reconhecimento", "facial", "."], "sentence-detokenized": "A detec\u00e7\u00e3o facial \u00e9 usada em biometria, muitas vezes como parte de (ou em conjunto com) um sistema de reconhecimento facial.", "token2charspan": [[0, 1], [2, 10], [11, 17], [18, 19], [20, 25], [26, 28], [29, 38], [38, 39], [40, 46], [47, 52], [53, 57], [58, 63], [64, 66], [67, 68], [68, 70], [71, 73], [74, 82], [83, 86], [86, 87], [88, 90], [91, 98], [99, 101], [102, 116], [117, 123], [123, 124]]}
{"doc_key": "ai-test-104", "ner": [[2, 5, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["treinados", "pela", "estimativa", "de", "m\u00e1xima", "probabilidade", "."], "sentence-detokenized": "treinados pela estimativa de m\u00e1xima probabilidade.", "token2charspan": [[0, 9], [10, 14], [15, 25], [26, 28], [29, 35], [36, 49], [49, 50]]}
{"doc_key": "ai-test-105", "ner": [[8, 8, "country"], [0, 15, "organisation"], [19, 19, "location"], [21, 21, "country"], [23, 27, "organisation"], [29, 29, "country"], [36, 36, "organisation"], [41, 44, "organisation"], [46, 46, "country"], [58, 62, "organisation"], [64, 66, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 15, 19, 19, "physical", "", false, false], [19, 19, 21, 21, "physical", "", false, false], [23, 27, 29, 29, "physical", "", false, false], [41, 44, 46, 46, "physical", "", false, false], [58, 62, 64, 66, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["A", "Komatsu", "(", "Shanghai", ")", "Ltd", ".", "na", "Tail\u00e2ndia", ";", "Komatsu", "(", "Shanghai", ")", "Ltd", ".", "em", "1996", "em", "Shanghai", ",", "China", ";", "Industrial", "Power", "Alliance", "Ltd", ".", "no", "Jap\u00e3o", ",", "uma", "joint", "venture", "com", "a", "Cummins", ",", "em", "1998", ";", "L", "&", "T-Komatsu", "Limited", "na", "\u00cdndia", ",", "em", "1998", "(", "a\u00e7\u00f5es", "vendidas", "em", "2013", ")", ";", "e", "Komatsu", "Brasil", "International", "Ltda", ".", "no", "Brasil", ",", "em", "1998", "."], "sentence-detokenized": "A Komatsu (Shanghai) Ltd. na Tail\u00e2ndia; Komatsu (Shanghai) Ltd. em 1996 em Shanghai, China; Industrial Power Alliance Ltd. no Jap\u00e3o, uma joint venture com a Cummins, em 1998; L & T-Komatsu Limited na \u00cdndia, em 1998 (a\u00e7\u00f5es vendidas em 2013); e Komatsu Brasil International Ltda. no Brasil, em 1998.", "token2charspan": [[0, 1], [2, 9], [10, 11], [11, 19], [19, 20], [21, 24], [24, 25], [26, 28], [29, 38], [38, 39], [40, 47], [48, 49], [49, 57], [57, 58], [59, 62], [62, 63], [64, 66], [67, 71], [72, 74], [75, 83], [83, 84], [85, 90], [90, 91], [92, 102], [103, 108], [109, 117], [118, 121], [121, 122], [123, 125], [126, 131], [131, 132], [133, 136], [137, 142], [143, 150], [151, 154], [155, 156], [157, 164], [164, 165], [166, 168], [169, 173], [173, 174], [175, 176], [177, 178], [179, 188], [189, 196], [197, 199], [200, 205], [205, 206], [207, 209], [210, 214], [215, 216], [216, 221], [222, 230], [231, 233], [234, 238], [238, 239], [239, 240], [241, 242], [243, 250], [251, 257], [258, 271], [272, 276], [276, 277], [278, 280], [281, 287], [287, 288], [289, 291], [292, 296], [296, 297]]}
{"doc_key": "ai-test-106", "ner": [[0, 1, "organisation"], [5, 7, "misc"], [12, 12, "misc"], [14, 15, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 15, 0, 1, "physical", "", false, false], [14, 15, 5, 7, "general-affiliation", "", false, false], [14, 15, 12, 12, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "dgp", "tamb\u00e9m", "hospeda", "ocasionalmente", "artistas", "em", "resid\u00eancia", "(", "por", "exemplo", ",", "Oscar", "-winner", "Chris", "Landreth", "."], "sentence-detokenized": "A dgp tamb\u00e9m hospeda ocasionalmente artistas em resid\u00eancia (por exemplo, Oscar -winner Chris Landreth.", "token2charspan": [[0, 1], [2, 5], [6, 12], [13, 20], [21, 35], [36, 44], [45, 47], [48, 58], [59, 60], [60, 63], [64, 71], [71, 72], [73, 78], [79, 86], [87, 92], [93, 101], [101, 102]]}
{"doc_key": "ai-test-107", "ner": [[6, 8, "misc"], [11, 13, "misc"], [16, 19, "misc"], [24, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Atualmente", "inclui", "quatro", "sub-competi\u00e7\u00f5es", "-", "o", "RoboMaster", "Robotics", "Competition", ",", "o", "RoboMaster", "Technical", "Challenge", ",", "o", "ICRA", "RoboMaster", "AI", "Challenge", ",", "e", "o", "novo", "RoboMaster", "Youth", "Tournament", "."], "sentence-detokenized": "Atualmente inclui quatro sub-competi\u00e7\u00f5es - o RoboMaster Robotics Competition, o RoboMaster Technical Challenge, o ICRA RoboMaster AI Challenge, e o novo RoboMaster Youth Tournament.", "token2charspan": [[0, 10], [11, 17], [18, 24], [25, 40], [41, 42], [43, 44], [45, 55], [56, 64], [65, 76], [76, 77], [78, 79], [80, 90], [91, 100], [101, 110], [110, 111], [112, 113], [114, 118], [119, 129], [130, 132], [133, 142], [142, 143], [144, 145], [146, 147], [148, 152], [153, 163], [164, 169], [170, 180], [180, 181]]}
{"doc_key": "ai-test-108", "ner": [[10, 12, "field"], [17, 20, "algorithm"], [22, 23, "algorithm"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 12, 22, 23, "usage", "", false, false], [10, 12, 27, 28, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["No", "in\u00edcio", "dos", "anos", "2000", ",", "a", "estrat\u00e9gia", "dominante", "de", "processamento", "de", "fala", "come\u00e7ou", "a", "mudar", "do", "modelo", "de", "Markov", "Escondido", "para", "redes", "neurais", "mais", "modernas", "e", "aprendizado", "profundo", "."], "sentence-detokenized": "No in\u00edcio dos anos 2000, a estrat\u00e9gia dominante de processamento de fala come\u00e7ou a mudar do modelo de Markov Escondido para redes neurais mais modernas e aprendizado profundo.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 18], [19, 23], [23, 24], [25, 26], [27, 37], [38, 47], [48, 50], [51, 64], [65, 67], [68, 72], [73, 80], [81, 82], [83, 88], [89, 91], [92, 98], [99, 101], [102, 108], [109, 118], [119, 123], [124, 129], [130, 137], [138, 142], [143, 151], [152, 153], [154, 165], [166, 174], [174, 175]]}
{"doc_key": "ai-test-109", "ner": [[8, 10, "misc"], [15, 17, "metrics"], [20, 22, "metrics"], [31, 33, "metrics"], [36, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 17, 20, 22, "related-to", "equal", false, false], [31, 33, 36, 38, "related-to", "equal", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Outra", "express\u00e3o", "equivalente", ",", "no", "caso", "de", "uma", "taxa", "alvo", "bin\u00e1ria", ",", "\u00e9", "que", "a", "taxa", "VERDADEIRA", "positiva", "e", "a", "taxa", "FALSA", "positiva", "s\u00e3o", "iguais", "(", "e", ",", "portanto", ",", "a", "taxa", "FALSA", "negativa", "e", "a", "taxa", "VERDADEIRA", "negativa", "s\u00e3o", "iguais", ")", "para", "cada", "valor", "das", "caracter\u00edsticas", "sens\u00edveis", ":"], "sentence-detokenized": "Outra express\u00e3o equivalente, no caso de uma taxa alvo bin\u00e1ria, \u00e9 que a taxa VERDADEIRA positiva e a taxa FALSA positiva s\u00e3o iguais (e, portanto, a taxa FALSA negativa e a taxa VERDADEIRA negativa s\u00e3o iguais) para cada valor das caracter\u00edsticas sens\u00edveis:", "token2charspan": [[0, 5], [6, 15], [16, 27], [27, 28], [29, 31], [32, 36], [37, 39], [40, 43], [44, 48], [49, 53], [54, 61], [61, 62], [63, 64], [65, 68], [69, 70], [71, 75], [76, 86], [87, 95], [96, 97], [98, 99], [100, 104], [105, 110], [111, 119], [120, 123], [124, 130], [131, 132], [132, 133], [133, 134], [135, 143], [143, 144], [145, 146], [147, 151], [152, 157], [158, 166], [167, 168], [169, 170], [171, 175], [176, 186], [187, 195], [196, 199], [200, 206], [206, 207], [208, 212], [213, 217], [218, 223], [224, 227], [228, 243], [244, 253], [253, 254]]}
{"doc_key": "ai-test-110", "ner": [[2, 2, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "fun\u00e7\u00e3o", "MATLAB", ","], "sentence-detokenized": "A fun\u00e7\u00e3o MATLAB,", "token2charspan": [[0, 1], [2, 8], [9, 15], [15, 16]]}
{"doc_key": "ai-test-111", "ner": [[1, 2, "product"], [7, 8, "misc"], [19, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 1, 2, "part-of", "", false, false], [19, 20, 1, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Um", "rob\u00f4", "articulado", "\u00e9", "um", "rob\u00f4", "com", "juntas", "rotativas", "(", "por", "exemplo", ",", "um", "rob\u00f4", "com", "perneiras", "ou", "um", "rob\u00f4", "industrial", ")", "."], "sentence-detokenized": "Um rob\u00f4 articulado \u00e9 um rob\u00f4 com juntas rotativas (por exemplo, um rob\u00f4 com perneiras ou um rob\u00f4 industrial).", "token2charspan": [[0, 2], [3, 7], [8, 18], [19, 20], [21, 23], [24, 28], [29, 32], [33, 39], [40, 49], [50, 51], [51, 54], [55, 62], [62, 63], [64, 66], [67, 71], [72, 75], [76, 85], [86, 88], [89, 91], [92, 96], [97, 107], [107, 108], [108, 109]]}
{"doc_key": "ai-test-112", "ner": [[0, 0, "product"], [5, 6, "product"], [8, 9, "product"], [18, 18, "misc"], [13, 25, "product"], [34, 36, "misc"], [40, 40, "location"], [42, 42, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 18, 18, "general-affiliation", "nationality", false, false], [0, 0, 34, 36, "usage", "", false, false], [0, 0, 40, 40, "physical", "", false, false], [5, 6, 0, 0, "named", "", false, false], [8, 9, 0, 0, "named", "", false, false], [40, 40, 42, 42, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pandora", "(", "tamb\u00e9m", "conhecido", "como", "Pandora", "Media", "ou", "Pandora", "Radio", ")", "\u00e9", "um", "sistema", "de", "streaming", "de", "m\u00fasica", "americano", "e", "um", "sistema", "automatizado", "de", "recomenda\u00e7\u00e3o", "de", "servi\u00e7os", "de", "r\u00e1dio", "pela", "internet", ",", "alimentado", "pelo", "Projeto", "Genoma", "Musical", "e", "sediado", "em", "Oakland", ",", "Calif\u00f3rnia", "."], "sentence-detokenized": "Pandora (tamb\u00e9m conhecido como Pandora Media ou Pandora Radio) \u00e9 um sistema de streaming de m\u00fasica americano e um sistema automatizado de recomenda\u00e7\u00e3o de servi\u00e7os de r\u00e1dio pela internet, alimentado pelo Projeto Genoma Musical e sediado em Oakland, Calif\u00f3rnia.", "token2charspan": [[0, 7], [8, 9], [9, 15], [16, 25], [26, 30], [31, 38], [39, 44], [45, 47], [48, 55], [56, 61], [61, 62], [63, 64], [65, 67], [68, 75], [76, 78], [79, 88], [89, 91], [92, 98], [99, 108], [109, 110], [111, 113], [114, 121], [122, 134], [135, 137], [138, 150], [151, 153], [154, 162], [163, 165], [166, 171], [172, 176], [177, 185], [185, 186], [187, 197], [198, 202], [203, 210], [211, 217], [218, 225], [226, 227], [228, 235], [236, 238], [239, 246], [246, 247], [248, 258], [258, 259]]}
{"doc_key": "ai-test-113", "ner": [[6, 9, "organisation"], [14, 17, "organisation"], [24, 25, "conference"], [37, 37, "conference"], [39, 39, "conference"], [41, 41, "conference"], [43, 43, "conference"], [45, 45, "conference"], [47, 47, "conference"], [49, 49, "conference"], [51, 51, "conference"], [53, 53, "conference"], [55, 55, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ela", "\u00e9", "membro", "do", "conselho", "da", "International", "Machine", "Learning", "Society", ",", "foi", "membro", "do", "conselho", "executivo", "da", "AAAI", ",", "foi", "co-presidente", "de", "PC", "do", "ICML", "2011", ",", "e", "atuou", "como", "membro", "s\u00eanior", "de", "PC", "em", "confer\u00eancias", "incluindo", "AAAI", ",", "ICML", ",", "IJCAI", ",", "ISWC", ",", "KDD", ",", "SIGMOD", ",", "UAI", ",", "VLDB", ",", "WSDM", "e", "WWW."], "sentence-detokenized": "Ela \u00e9 membro do conselho da International Machine Learning Society, foi membro do conselho executivo da AAAI, foi co-presidente de PC do ICML 2011, e atuou como membro s\u00eanior de PC em confer\u00eancias incluindo AAAI, ICML, IJCAI, ISWC, KDD, SIGMOD, UAI, VLDB, WSDM e WWW.", "token2charspan": [[0, 3], [4, 5], [6, 12], [13, 15], [16, 24], [25, 27], [28, 41], [42, 49], [50, 58], [59, 66], [66, 67], [68, 71], [72, 78], [79, 81], [82, 90], [91, 100], [101, 103], [104, 108], [108, 109], [110, 113], [114, 127], [128, 130], [131, 133], [134, 136], [137, 141], [142, 146], [146, 147], [148, 149], [150, 155], [156, 160], [161, 167], [168, 174], [175, 177], [178, 180], [181, 183], [184, 196], [197, 206], [207, 211], [211, 212], [213, 217], [217, 218], [219, 224], [224, 225], [226, 230], [230, 231], [232, 235], [235, 236], [237, 243], [243, 244], [245, 248], [248, 249], [250, 254], [254, 255], [256, 260], [261, 262], [263, 267]]}
{"doc_key": "ai-test-114", "ner": [[0, 2, "researcher"], [4, 9, "organisation"], [11, 11, "organisation"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 4, 9, "role", "", false, false], [11, 11, 4, 9, "named", "", false, false], [15, 15, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["James", "S.", "Albus", "do", "National", "Institute", "of", "Standards", "and", "Technology", "(", "NIST", ")", "desenvolveu", "o", "Robocrane", ",", "onde", "a", "plataforma", "\u00e9", "pendurada", "por", "seis", "cabos", "em", "vez", "de", "ser", "apoiada", "por", "seis", "macacos", "."], "sentence-detokenized": "James S. Albus do National Institute of Standards and Technology (NIST) desenvolveu o Robocrane, onde a plataforma \u00e9 pendurada por seis cabos em vez de ser apoiada por seis macacos.", "token2charspan": [[0, 5], [6, 8], [9, 14], [15, 17], [18, 26], [27, 36], [37, 39], [40, 49], [50, 53], [54, 64], [65, 66], [66, 70], [70, 71], [72, 83], [84, 85], [86, 95], [95, 96], [97, 101], [102, 103], [104, 114], [115, 116], [117, 126], [127, 130], [131, 135], [136, 141], [142, 144], [145, 148], [149, 151], [152, 155], [156, 163], [164, 167], [168, 172], [173, 180], [180, 181]]}
{"doc_key": "ai-test-115", "ner": [[3, 6, "algorithm"], [10, 11, "algorithm"], [17, 18, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 3, 6, "type-of", "", false, false], [17, 18, 10, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Outra", "classe", "de", "algoritmos", "de", "busca", "direta", "s\u00e3o", "os", "v\u00e1rios", "algoritmos", "evolutivos", ",", "por", "exemplo", ",", "os", "algoritmos", "gen\u00e9ticos", "."], "sentence-detokenized": "Outra classe de algoritmos de busca direta s\u00e3o os v\u00e1rios algoritmos evolutivos, por exemplo, os algoritmos gen\u00e9ticos.", "token2charspan": [[0, 5], [6, 12], [13, 15], [16, 26], [27, 29], [30, 35], [36, 42], [43, 46], [47, 49], [50, 56], [57, 67], [68, 78], [78, 79], [80, 83], [84, 91], [91, 92], [93, 95], [96, 106], [107, 116], [116, 117]]}
{"doc_key": "ai-test-116", "ner": [[0, 1, "organisation"], [4, 5, "misc"], [7, 8, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 0, 1, "named", "", false, false], [7, 8, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "KUKA", "\u00e9", "um", "fabricante", "alem\u00e3o", "de", "rob\u00f4s", "industriais", "e", "solu\u00e7\u00f5es", "para", "automa\u00e7\u00e3o", "industrial", "."], "sentence-detokenized": "A KUKA \u00e9 um fabricante alem\u00e3o de rob\u00f4s industriais e solu\u00e7\u00f5es para automa\u00e7\u00e3o industrial.", "token2charspan": [[0, 1], [2, 6], [7, 8], [9, 11], [12, 22], [23, 29], [30, 32], [33, 38], [39, 50], [51, 52], [53, 61], [62, 66], [67, 76], [77, 87], [87, 88]]}
{"doc_key": "ai-test-117", "ner": [[10, 10, "misc"], [15, 16, "person"], [13, 22, "misc"], [24, 25, "person"], [26, 26, "misc"], [28, 29, "person"], [30, 31, "misc"], [33, 34, "person"], [36, 38, "misc"], [40, 42, "person"], [43, 46, "misc"], [48, 49, "person"], [50, 53, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[15, 16, 10, 10, "usage", "", false, false], [13, 22, 15, 16, "artifact", "", false, false], [24, 25, 10, 10, "usage", "", false, false], [26, 26, 24, 25, "artifact", "", false, false], [28, 29, 10, 10, "usage", "", false, false], [30, 31, 28, 29, "artifact", "", false, false], [33, 34, 10, 10, "usage", "", false, false], [36, 38, 33, 34, "artifact", "", false, false], [40, 42, 10, 10, "usage", "", false, false], [43, 46, 40, 42, "artifact", "", false, false], [48, 49, 10, 10, "usage", "", false, false], [50, 53, 48, 49, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Outros", "filmes", "capturados", "entre", "2016", "e", "2020", "com", "a", "c\u00e2mera", "IMAX", "foram", "o", "Batman", "de", "Zack", "Snyder", "versus", "Super-Homem", ":", "Dawn", "of", "Justice", ",", "Clint", "Eastwood's", "Sully", ",", "Damien", "Chazelle's", "First", "Man", ",", "Patty", "Jenkins", "'", "Wonder", "Woman", "1984", ",", "Cary", "Joji", "Fukunaga's", "No", "Time", "to", "Die", "e", "Joseph", "Kosinski's", "Top", "Gun", ":", "Maverick", "."], "sentence-detokenized": "Outros filmes capturados entre 2016 e 2020 com a c\u00e2mera IMAX foram o Batman de Zack Snyder versus Super-Homem: Dawn of Justice, Clint Eastwood's Sully, Damien Chazelle's First Man, Patty Jenkins' Wonder Woman 1984, Cary Joji Fukunaga's No Time to Die e Joseph Kosinski's Top Gun: Maverick.", "token2charspan": [[0, 6], [7, 13], [14, 24], [25, 30], [31, 35], [36, 37], [38, 42], [43, 46], [47, 48], [49, 55], [56, 60], [61, 66], [67, 68], [69, 75], [76, 78], [79, 83], [84, 90], [91, 97], [98, 109], [109, 110], [111, 115], [116, 118], [119, 126], [126, 127], [128, 133], [134, 144], [145, 150], [150, 151], [152, 158], [159, 169], [170, 175], [176, 179], [179, 180], [181, 186], [187, 194], [194, 195], [196, 202], [203, 208], [209, 213], [213, 214], [215, 219], [220, 224], [225, 235], [236, 238], [239, 243], [244, 246], [247, 250], [251, 252], [253, 259], [260, 270], [271, 274], [275, 278], [278, 279], [280, 288], [288, 289]]}
{"doc_key": "ai-test-118", "ner": [[4, 5, "misc"], [9, 12, "organisation"], [14, 14, "organisation"], [29, 29, "misc"], [34, 35, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 29, 29, "named", "", false, false], [9, 12, 4, 5, "usage", "", false, false], [9, 12, 34, 35, "physical", "", false, false], [14, 14, 9, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["O", "julgamento", "da", "fonte", "MICR", "E13B", "foi", "mostrado", "\u00e0", "Associa\u00e7\u00e3o", "Americana", "de", "Banqueiros", "(", "ABA", ")", "em", "julho", "de", "1956", ",", "que", "a", "adotou", "em", "1958", "como", "a", "norma", "MICR", "para", "documentos", "negoci\u00e1veis", "nos", "Estados", "Unidos", "."], "sentence-detokenized": "O julgamento da fonte MICR E13B foi mostrado \u00e0 Associa\u00e7\u00e3o Americana de Banqueiros (ABA) em julho de 1956, que a adotou em 1958 como a norma MICR para documentos negoci\u00e1veis nos Estados Unidos.", "token2charspan": [[0, 1], [2, 12], [13, 15], [16, 21], [22, 26], [27, 31], [32, 35], [36, 44], [45, 46], [47, 57], [58, 67], [68, 70], [71, 81], [82, 83], [83, 86], [86, 87], [88, 90], [91, 96], [97, 99], [100, 104], [104, 105], [106, 109], [110, 111], [112, 118], [119, 121], [122, 126], [127, 131], [132, 133], [134, 139], [140, 144], [145, 149], [150, 160], [161, 172], [173, 176], [177, 184], [185, 191], [191, 192]]}
{"doc_key": "ai-test-119", "ner": [[0, 4, "misc"], [17, 17, "field"], [20, 21, "field"], [24, 24, "field"], [26, 27, "field"], [29, 29, "field"], [31, 31, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[17, 17, 0, 4, "usage", "", false, false], [20, 21, 17, 17, "part-of", "", false, false], [24, 24, 0, 4, "usage", "", false, false], [26, 27, 0, 4, "usage", "", false, false], [29, 29, 0, 4, "usage", "", false, false], [31, 31, 0, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Os", "algoritmos", "de", "busca", "locais", "s\u00e3o", "amplamente", "aplicados", "a", "in\u00fameros", "problemas", "computacionais", "dif\u00edceis", ",", "incluindo", "problemas", "de", "inform\u00e1tica", "(", "particularmente", "intelig\u00eancia", "artificial", ")", ",", "matem\u00e1tica", ",", "pesquisa", "operacional", ",", "engenharia", "e", "bioinform\u00e1tica", "."], "sentence-detokenized": "Os algoritmos de busca locais s\u00e3o amplamente aplicados a in\u00fameros problemas computacionais dif\u00edceis, incluindo problemas de inform\u00e1tica (particularmente intelig\u00eancia artificial), matem\u00e1tica, pesquisa operacional, engenharia e bioinform\u00e1tica.", "token2charspan": [[0, 2], [3, 13], [14, 16], [17, 22], [23, 29], [30, 33], [34, 44], [45, 54], [55, 56], [57, 65], [66, 75], [76, 90], [91, 99], [99, 100], [101, 110], [111, 120], [121, 123], [124, 135], [136, 137], [137, 152], [153, 165], [166, 176], [176, 177], [177, 178], [179, 189], [189, 190], [191, 199], [200, 211], [211, 212], [213, 223], [224, 225], [226, 240], [240, 241]]}
{"doc_key": "ai-test-120", "ner": [[0, 1, "researcher"], [11, 11, "location"], [13, 13, "country"], [18, 18, "country"], [24, 25, "algorithm"], [28, 28, "algorithm"], [30, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 11, 11, "physical", "", false, false], [0, 1, 18, 18, "general-affiliation", "nationality", false, false], [0, 1, 24, 25, "general-affiliation", "topic_of_study", false, false], [0, 1, 28, 28, "general-affiliation", "topic_of_study", false, false], [11, 11, 13, 13, "physical", "", false, false], [28, 28, 30, 32, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gerd", "Gigerenzer", "(", "nascido", "em", "3", "de", "setembro", "de", "1947", ",", "Wallersdorf", ",", "Alemanha", ")", "\u00e9", "um", "psic\u00f3logo", "alem\u00e3o", "que", "estudou", "o", "uso", "da", "racionalidade", "limitada", "e", "da", "heur\u00edstica", "na", "tomada", "de", "decis\u00f5es", "."], "sentence-detokenized": "Gerd Gigerenzer (nascido em 3 de setembro de 1947, Wallersdorf, Alemanha) \u00e9 um psic\u00f3logo alem\u00e3o que estudou o uso da racionalidade limitada e da heur\u00edstica na tomada de decis\u00f5es.", "token2charspan": [[0, 4], [5, 15], [16, 17], [17, 24], [25, 27], [28, 29], [30, 32], [33, 41], [42, 44], [45, 49], [49, 50], [51, 62], [62, 63], [64, 72], [72, 73], [74, 75], [76, 78], [79, 88], [89, 95], [96, 99], [100, 107], [108, 109], [110, 113], [114, 116], [117, 130], [131, 139], [140, 141], [142, 144], [145, 155], [156, 158], [159, 165], [166, 168], [169, 177], [177, 178]]}
{"doc_key": "ai-test-121", "ner": [[3, 6, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["para", "minimizar", "o", "erro", "m\u00e9dio", "ao", "quadrado", "."], "sentence-detokenized": "para minimizar o erro m\u00e9dio ao quadrado.", "token2charspan": [[0, 4], [5, 14], [15, 16], [17, 21], [22, 27], [28, 30], [31, 39], [39, 40]]}
{"doc_key": "ai-test-122", "ner": [[13, 14, "misc"], [17, 18, "organisation"], [33, 36, "field"], [53, 54, "misc"], [63, 65, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 14, 17, 18, "origin", "", false, false], [53, 54, 63, 65, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Mas", "mesmo", "uma", "l\u00edngua", "oficial", "com", "uma", "academia", "de", "regulamenta\u00e7\u00e3o", ",", "como", "o", "franc\u00eas", "padr\u00e3o", "com", "a", "Acad\u00e9mie", "fran\u00e7aise", ",", "\u00e9", "classificada", "como", "uma", "l\u00edngua", "natural", "(", "por", "exemplo", ",", "no", "campo", "do", "processamento", "da", "l\u00edngua", "natural", ")", ",", "pois", "seus", "pontos", "normativos", "n\u00e3o", "a", "tornam", "suficientemente", "constru\u00edda", "para", "ser", "classificada", "como", "uma", "l\u00edngua", "constru\u00edda", "ou", "suficientemente", "controlada", "para", "ser", "classificada", "como", "uma", "l\u00edngua", "natural", "controlada", "."], "sentence-detokenized": "Mas mesmo uma l\u00edngua oficial com uma academia de regulamenta\u00e7\u00e3o, como o franc\u00eas padr\u00e3o com a Acad\u00e9mie fran\u00e7aise, \u00e9 classificada como uma l\u00edngua natural (por exemplo, no campo do processamento da l\u00edngua natural), pois seus pontos normativos n\u00e3o a tornam suficientemente constru\u00edda para ser classificada como uma l\u00edngua constru\u00edda ou suficientemente controlada para ser classificada como uma l\u00edngua natural controlada.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 20], [21, 28], [29, 32], [33, 36], [37, 45], [46, 48], [49, 63], [63, 64], [65, 69], [70, 71], [72, 79], [80, 86], [87, 90], [91, 92], [93, 101], [102, 111], [111, 112], [113, 114], [115, 127], [128, 132], [133, 136], [137, 143], [144, 151], [152, 153], [153, 156], [157, 164], [164, 165], [166, 168], [169, 174], [175, 177], [178, 191], [192, 194], [195, 201], [202, 209], [209, 210], [210, 211], [212, 216], [217, 221], [222, 228], [229, 239], [240, 243], [244, 245], [246, 252], [253, 268], [269, 279], [280, 284], [285, 288], [289, 301], [302, 306], [307, 310], [311, 317], [318, 328], [329, 331], [332, 347], [348, 358], [359, 363], [364, 367], [368, 380], [381, 385], [386, 389], [390, 396], [397, 404], [405, 415], [415, 416]]}
{"doc_key": "ai-test-123", "ner": [[10, 10, "metrics"], [12, 13, "metrics"], [15, 15, "metrics"], [35, 36, "metrics"], [38, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 15, 12, 13, "named", "", false, false], [38, 38, 35, 36, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["H\u00e1", "uma", "s\u00e9rie", "de", "outras", "m\u00e9tricas", ",", "mais", "simplesmente", "a", "precis\u00e3o", "ou", "Fra\u00e7\u00e3o", "Correta", "(", "FC", ")", ",", "que", "mede", "a", "fra\u00e7\u00e3o", "de", "todas", "as", "inst\u00e2ncias", "que", "est\u00e3o", "corretamente", "categorizadas", ";", "o", "complemento", "\u00e9", "a", "Fra\u00e7\u00e3o", "Incorreta", "(", "FiC", ")", "."], "sentence-detokenized": "H\u00e1 uma s\u00e9rie de outras m\u00e9tricas, mais simplesmente a precis\u00e3o ou Fra\u00e7\u00e3o Correta (FC), que mede a fra\u00e7\u00e3o de todas as inst\u00e2ncias que est\u00e3o corretamente categorizadas; o complemento \u00e9 a Fra\u00e7\u00e3o Incorreta (FiC).", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 22], [23, 31], [31, 32], [33, 37], [38, 50], [51, 52], [53, 61], [62, 64], [65, 71], [72, 79], [80, 81], [81, 83], [83, 84], [84, 85], [86, 89], [90, 94], [95, 96], [97, 103], [104, 106], [107, 112], [113, 115], [116, 126], [127, 130], [131, 136], [137, 149], [150, 163], [163, 164], [165, 166], [167, 178], [179, 180], [181, 182], [183, 189], [190, 199], [200, 201], [201, 204], [204, 205], [205, 206]]}
{"doc_key": "ai-test-124", "ner": [[0, 0, "researcher"], [4, 7, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 7, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cardie", "tornou-se", "membro", "da", "Associa\u00e7\u00e3o", "para", "Lingu\u00edstica", "Computacional", "em", "2016", "."], "sentence-detokenized": "Cardie tornou-se membro da Associa\u00e7\u00e3o para Lingu\u00edstica Computacional em 2016.", "token2charspan": [[0, 6], [7, 16], [17, 23], [24, 26], [27, 37], [38, 42], [43, 54], [55, 68], [69, 71], [72, 76], [76, 77]]}
{"doc_key": "ai-test-125", "ner": [[12, 15, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["O", "aprendizado", "dos", "par\u00e2metros", "matem\u00e1tica", "teta", "/", "matem\u00e1tica", "\u00e9", "geralmente", "feito", "pela", "m\u00e1xima", "probabilidade", "de", "aprendizado", "para", "matem\u00e1tica", "(", "Y", "_", "i", "|", "X", "_", "i;|", "theta", ")", "/", "matem\u00e1tica", "."], "sentence-detokenized": "O aprendizado dos par\u00e2metros matem\u00e1tica teta / matem\u00e1tica \u00e9 geralmente feito pela m\u00e1xima probabilidade de aprendizado para matem\u00e1tica (Y _ i | X _ i;| theta) / matem\u00e1tica.", "token2charspan": [[0, 1], [2, 13], [14, 17], [18, 28], [29, 39], [40, 44], [45, 46], [47, 57], [58, 59], [60, 70], [71, 76], [77, 81], [82, 88], [89, 102], [103, 105], [106, 117], [118, 122], [123, 133], [134, 135], [135, 136], [137, 138], [139, 140], [141, 142], [143, 144], [145, 146], [147, 150], [151, 156], [156, 157], [158, 159], [160, 170], [170, 171]]}
{"doc_key": "ai-test-126", "ner": [[0, 2, "task"], [4, 7, "algorithm"], [9, 10, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 2, "usage", "", true, false], [9, 10, 4, 7, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An\u00e1lise", "de", "agrupamento", "e", "factoriza\u00e7\u00e3o", "de", "matriz", "n\u00e3o-negativa", "para", "minera\u00e7\u00e3o", "descritiva", "."], "sentence-detokenized": "An\u00e1lise de agrupamento e factoriza\u00e7\u00e3o de matriz n\u00e3o-negativa para minera\u00e7\u00e3o descritiva.", "token2charspan": [[0, 7], [8, 10], [11, 22], [23, 24], [25, 37], [38, 40], [41, 47], [48, 60], [61, 65], [66, 75], [76, 86], [86, 87]]}
{"doc_key": "ai-test-127", "ner": [[1, 3, "field"], [6, 8, "field"], [27, 30, "field"], [32, 34, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[27, 30, 1, 3, "part-of", "", false, false], [27, 30, 6, 8, "part-of", "", false, false], [32, 34, 1, 3, "part-of", "", false, false], [32, 34, 6, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Na", "ci\u00eancia", "da", "computa\u00e7\u00e3o", "e", "na", "tecnologia", "da", "informa\u00e7\u00e3o", "que", "ela", "permite", ",", "tem", "sido", "um", "desafio", "a", "longo", "prazo", "para", "a", "capacidade", "dos", "computadores", "de", "fazer", "processamento", "de", "linguagem", "natural", "e", "aprendizagem", "de", "m\u00e1quinas", "."], "sentence-detokenized": "Na ci\u00eancia da computa\u00e7\u00e3o e na tecnologia da informa\u00e7\u00e3o que ela permite, tem sido um desafio a longo prazo para a capacidade dos computadores de fazer processamento de linguagem natural e aprendizagem de m\u00e1quinas.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 24], [25, 26], [27, 29], [30, 40], [41, 43], [44, 54], [55, 58], [59, 62], [63, 70], [70, 71], [72, 75], [76, 80], [81, 83], [84, 91], [92, 93], [94, 99], [100, 105], [106, 110], [111, 112], [113, 123], [124, 127], [128, 140], [141, 143], [144, 149], [150, 163], [164, 166], [167, 176], [177, 184], [185, 186], [187, 199], [200, 202], [203, 211], [211, 212]]}
{"doc_key": "ai-test-128", "ner": [[4, 5, "algorithm"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 9, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "O", "c\u00f3digo", "para", "Gabor", "extra\u00eddo", "de", "imagens", "em", "MATLAB", "pode", "ser", "encontrado", "em"], "sentence-detokenized": "(O c\u00f3digo para Gabor extra\u00eddo de imagens em MATLAB pode ser encontrado em", "token2charspan": [[0, 1], [1, 2], [3, 9], [10, 14], [15, 20], [21, 29], [30, 32], [33, 40], [41, 43], [44, 50], [51, 55], [56, 59], [60, 70], [71, 73]]}
{"doc_key": "ai-test-129", "ner": [[1, 1, "misc"], [19, 20, "algorithm"], [23, 23, "task"], [25, 25, "task"], [27, 29, "task"], [31, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 1, 19, 20, "general-affiliation", "", false, false], [1, 1, 23, 23, "related-to", "solves_problem_of_type", false, false], [1, 1, 25, 25, "related-to", "solves_problem_of_type", false, false], [1, 1, 27, 29, "related-to", "solves_problem_of_type", false, false], [1, 1, 31, 33, "related-to", "solves_problem_of_type", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["O", "NeuralExpert", "concentra", "as", "especifica\u00e7\u00f5es", "de", "projeto", "em", "torno", "do", "tipo", "de", "problema", "que", "o", "usu\u00e1rio", "gostaria", "que", "a", "rede", "neural", "resolvesse", "(", "Classifica\u00e7\u00e3o", ",", "Predi\u00e7\u00e3o", ",", "Aproxima\u00e7\u00e3o", "de", "Fun\u00e7\u00f5es", "ou", "An\u00e1lise", "de", "Cluster", ")", "."], "sentence-detokenized": "O NeuralExpert concentra as especifica\u00e7\u00f5es de projeto em torno do tipo de problema que o usu\u00e1rio gostaria que a rede neural resolvesse (Classifica\u00e7\u00e3o, Predi\u00e7\u00e3o, Aproxima\u00e7\u00e3o de Fun\u00e7\u00f5es ou An\u00e1lise de Cluster).", "token2charspan": [[0, 1], [2, 14], [15, 24], [25, 27], [28, 42], [43, 45], [46, 53], [54, 56], [57, 62], [63, 65], [66, 70], [71, 73], [74, 82], [83, 86], [87, 88], [89, 96], [97, 105], [106, 109], [110, 111], [112, 116], [117, 123], [124, 134], [135, 136], [136, 149], [149, 150], [151, 159], [159, 160], [161, 172], [173, 175], [176, 183], [184, 186], [187, 194], [195, 197], [198, 205], [205, 206], [206, 207]]}
{"doc_key": "ai-test-130", "ner": [[2, 6, "misc"], [28, 30, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Quando", "o", "tamanho", "do", "passo", "de", "quantiza\u00e7\u00e3o", "(", "\u0394", ")", "\u00e9", "pequeno", "em", "rela\u00e7\u00e3o", "\u00e0", "varia\u00e7\u00e3o", "do", "sinal", "a", "ser", "quantificado", ",", "\u00e9", "relativamente", "simples", "mostrar", "que", "o", "erro", "quadr\u00e1tico", "m\u00e9dio", "produzido", "por", "tal", "opera\u00e7\u00e3o", "de", "arredondamento", "ser\u00e1", "aproximadamente", "matem\u00e1tico", "^", "2", "/", "12", "/", "matem\u00e1tico"], "sentence-detokenized": "Quando o tamanho do passo de quantiza\u00e7\u00e3o (\u0394) \u00e9 pequeno em rela\u00e7\u00e3o \u00e0 varia\u00e7\u00e3o do sinal a ser quantificado, \u00e9 relativamente simples mostrar que o erro quadr\u00e1tico m\u00e9dio produzido por tal opera\u00e7\u00e3o de arredondamento ser\u00e1 aproximadamente matem\u00e1tico ^ 2 / 12 / matem\u00e1tico", "token2charspan": [[0, 6], [7, 8], [9, 16], [17, 19], [20, 25], [26, 28], [29, 40], [41, 42], [42, 43], [43, 44], [45, 46], [47, 54], [55, 57], [58, 65], [66, 67], [68, 76], [77, 79], [80, 85], [86, 87], [88, 91], [92, 104], [104, 105], [106, 107], [108, 121], [122, 129], [130, 137], [138, 141], [142, 143], [144, 148], [149, 159], [160, 165], [166, 175], [176, 179], [180, 183], [184, 192], [193, 195], [196, 210], [211, 215], [216, 231], [232, 242], [243, 244], [245, 246], [247, 248], [249, 251], [252, 253], [254, 264]]}
{"doc_key": "ai-test-131", "ner": [[20, 20, "product"], [28, 30, "researcher"], [32, 33, "researcher"], [35, 37, "researcher"], [39, 40, "researcher"], [42, 43, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "constru\u00e7\u00e3o", "de", "um", "l\u00e9xico", "rico", "com", "uma", "ontologia", "adequada", "requer", "um", "esfor\u00e7o", "significativo", ",", "por", "exemplo", ",", "o", "l\u00e9xico", "Wordnet", "exigiu", "muitos", "anos", "de", "esfor\u00e7o", "pessoal", ".", "G.", "A.", "Miller", ",", "R.", "Beckwith", ",", "C.", "D.", "Fellbaum", ",", "D.", "Gross", ",", "K.", "Miller", "."], "sentence-detokenized": "A constru\u00e7\u00e3o de um l\u00e9xico rico com uma ontologia adequada requer um esfor\u00e7o significativo, por exemplo, o l\u00e9xico Wordnet exigiu muitos anos de esfor\u00e7o pessoal. G. A. Miller, R. Beckwith, C. D. Fellbaum, D. Gross, K. Miller.", "token2charspan": [[0, 1], [2, 12], [13, 15], [16, 18], [19, 25], [26, 30], [31, 34], [35, 38], [39, 48], [49, 57], [58, 64], [65, 67], [68, 75], [76, 89], [89, 90], [91, 94], [95, 102], [102, 103], [104, 105], [106, 112], [113, 120], [121, 127], [128, 134], [135, 139], [140, 142], [143, 150], [151, 158], [158, 159], [160, 162], [163, 165], [166, 172], [172, 173], [174, 176], [177, 185], [185, 186], [187, 189], [190, 192], [193, 201], [201, 202], [203, 205], [206, 211], [211, 212], [213, 215], [216, 222], [222, 223]]}
{"doc_key": "ai-test-132", "ner": [[3, 3, "organisation"], [19, 20, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[19, 20, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["O", "portf\u00f3lio", "da", "Kawasaki", "tamb\u00e9m", "inclui", "telhados", "retr\u00e1teis", ",", "pisos", "e", "outras", "estruturas", "gigantes", ",", "a", "\"", "superf\u00edcie", "retr\u00e1til", "Sapporo", "Dome", "\"", "\u00e9", "um", "exemplo", "."], "sentence-detokenized": "O portf\u00f3lio da Kawasaki tamb\u00e9m inclui telhados retr\u00e1teis, pisos e outras estruturas gigantes, a \"superf\u00edcie retr\u00e1til Sapporo Dome\" \u00e9 um exemplo.", "token2charspan": [[0, 1], [2, 11], [12, 14], [15, 23], [24, 30], [31, 37], [38, 46], [47, 56], [56, 57], [58, 63], [64, 65], [66, 72], [73, 83], [84, 92], [92, 93], [94, 95], [96, 97], [97, 107], [108, 116], [117, 124], [125, 129], [129, 130], [131, 132], [133, 135], [136, 143], [143, 144]]}
{"doc_key": "ai-test-133", "ner": [[0, 2, "metrics"], [5, 7, "metrics"], [10, 12, "metrics"], [17, 21, "metrics"], [47, 47, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 17, 21, "related-to", "", false, false], [0, 2, 47, 47, "opposite", "alternative_to", false, false], [5, 7, 0, 2, "type-of", "", false, false], [10, 12, 0, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["As", "estat\u00edsticas", "Kappa", "como", "a", "kappa", "de", "Fleiss", "e", "a", "kappa", "de", "Cohen", "s\u00e3o", "m\u00e9todos", "para", "calcular", "a", "confiabilidade", "entre", "os", "avaliadores", "com", "base", "em", "diferentes", "suposi\u00e7\u00f5es", "sobre", "as", "distribui\u00e7\u00f5es", "marginais", "ou", "pr\u00e9vias", ",", "e", "s\u00e3o", "cada", "vez", "mais", "utilizadas", "como", "alternativas", "corrigidas", "por", "acaso", "para", "a", "precis\u00e3o", "em", "outros", "contextos", "."], "sentence-detokenized": "As estat\u00edsticas Kappa como a kappa de Fleiss e a kappa de Cohen s\u00e3o m\u00e9todos para calcular a confiabilidade entre os avaliadores com base em diferentes suposi\u00e7\u00f5es sobre as distribui\u00e7\u00f5es marginais ou pr\u00e9vias, e s\u00e3o cada vez mais utilizadas como alternativas corrigidas por acaso para a precis\u00e3o em outros contextos.", "token2charspan": [[0, 2], [3, 15], [16, 21], [22, 26], [27, 28], [29, 34], [35, 37], [38, 44], [45, 46], [47, 48], [49, 54], [55, 57], [58, 63], [64, 67], [68, 75], [76, 80], [81, 89], [90, 91], [92, 106], [107, 112], [113, 115], [116, 127], [128, 131], [132, 136], [137, 139], [140, 150], [151, 161], [162, 167], [168, 170], [171, 184], [185, 194], [195, 197], [198, 205], [205, 206], [207, 208], [209, 212], [213, 217], [218, 221], [222, 226], [227, 237], [238, 242], [243, 255], [256, 266], [267, 270], [271, 276], [277, 281], [282, 283], [284, 292], [293, 295], [296, 302], [303, 312], [312, 313]]}
{"doc_key": "ai-test-134", "ner": [[3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [12, 13, "researcher"], [17, 17, "researcher"], [28, 30, "algorithm"], [33, 37, "algorithm"], [39, 39, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 4, 17, 17, "role", "student_of", false, false], [6, 7, 17, 17, "role", "student_of", false, false], [9, 10, 17, 17, "role", "student_of", false, false], [12, 13, 17, 17, "role", "student_of", false, false], [33, 37, 3, 4, "origin", "", false, false], [33, 37, 6, 7, "origin", "", false, false], [33, 37, 9, 10, "origin", "", false, false], [33, 37, 12, 13, "origin", "", false, false], [33, 37, 17, 17, "origin", "", false, false], [33, 37, 28, 30, "type-of", "", false, false], [39, 39, 33, 37, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Com", "seus", "alunos", "Sepp", "Hochreiter", ",", "Felix", "Gers", ",", "Fred", "Cummins", ",", "Alex", "Graves", "e", "outros", ",", "Schmidhuber", "publicou", "vers\u00f5es", "cada", "vez", "mais", "sofisticadas", "de", "um", "tipo", "de", "rede", "neural", "recorrente", "chamada", "de", "mem\u00f3ria", "de", "curto", "prazo", "longo", "(", "LSTM", ")", "."], "sentence-detokenized": "Com seus alunos Sepp Hochreiter, Felix Gers, Fred Cummins, Alex Graves e outros, Schmidhuber publicou vers\u00f5es cada vez mais sofisticadas de um tipo de rede neural recorrente chamada de mem\u00f3ria de curto prazo longo (LSTM).", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 20], [21, 31], [31, 32], [33, 38], [39, 43], [43, 44], [45, 49], [50, 57], [57, 58], [59, 63], [64, 70], [71, 72], [73, 79], [79, 80], [81, 92], [93, 101], [102, 109], [110, 114], [115, 118], [119, 123], [124, 136], [137, 139], [140, 142], [143, 147], [148, 150], [151, 155], [156, 162], [163, 173], [174, 181], [182, 184], [185, 192], [193, 195], [196, 201], [202, 207], [208, 213], [214, 215], [215, 219], [219, 220], [220, 221]]}
{"doc_key": "ai-test-135", "ner": [[6, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2004", "-", "\u00c9", "lan\u00e7ada", "a", "primeira", "Cobot", "KUKA", "LBR", "3", "."], "sentence-detokenized": "2004 - \u00c9 lan\u00e7ada a primeira Cobot KUKA LBR 3.", "token2charspan": [[0, 4], [5, 6], [7, 8], [9, 16], [17, 18], [19, 27], [28, 33], [34, 38], [39, 42], [43, 44], [44, 45]]}
{"doc_key": "ai-test-136", "ner": [[11, 13, "algorithm"], [16, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Duas", "abordagens", "rasas", "utilizadas", "para", "treinar", "e", "depois", "desambiguar", "s\u00e3o", "a", "classificadora", "Naive", "Bayes", "e", "as", "\u00e1rvores", "de", "decis\u00e3o", "."], "sentence-detokenized": "Duas abordagens rasas utilizadas para treinar e depois desambiguar s\u00e3o a classificadora Naive Bayes e as \u00e1rvores de decis\u00e3o.", "token2charspan": [[0, 4], [5, 15], [16, 21], [22, 32], [33, 37], [38, 45], [46, 47], [48, 54], [55, 66], [67, 70], [71, 72], [73, 87], [88, 93], [94, 99], [100, 101], [102, 104], [105, 112], [113, 115], [116, 123], [123, 124]]}
{"doc_key": "ai-test-137", "ner": [[5, 5, "misc"], [13, 14, "person"], [16, 18, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 13, 14, "origin", "", false, false], [5, 5, 16, 18, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "primeiras", "formas", "pr\u00e1ticas", "de", "fotografia", "foram", "introduzidas", "em", "janeiro", "de", "1839", "por", "Louis", "Daguerre", "e", "Henry", "Fox", "Talbot", "."], "sentence-detokenized": "As primeiras formas pr\u00e1ticas de fotografia foram introduzidas em janeiro de 1839 por Louis Daguerre e Henry Fox Talbot.", "token2charspan": [[0, 2], [3, 12], [13, 19], [20, 28], [29, 31], [32, 42], [43, 48], [49, 61], [62, 64], [65, 72], [73, 75], [76, 80], [81, 84], [85, 90], [91, 99], [100, 101], [102, 107], [108, 111], [112, 118], [118, 119]]}
{"doc_key": "ai-test-138", "ner": [[4, 6, "task"], [11, 13, "task"], [25, 27, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 25, 27, "part-of", "task_part_of_field", false, false], [11, 13, 25, 27, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Por", "exemplo", ",", "a", "s\u00edntese", "da", "fala", ",", "combinada", "com", "o", "reconhecimento", "da", "fala", ",", "permite", "a", "intera\u00e7\u00e3o", "com", "dispositivos", "m\u00f3veis", "atrav\u00e9s", "de", "interfaces", "de", "processamento", "de", "linguagem", "."], "sentence-detokenized": "Por exemplo, a s\u00edntese da fala, combinada com o reconhecimento da fala, permite a intera\u00e7\u00e3o com dispositivos m\u00f3veis atrav\u00e9s de interfaces de processamento de linguagem.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 14], [15, 22], [23, 25], [26, 30], [30, 31], [32, 41], [42, 45], [46, 47], [48, 62], [63, 65], [66, 70], [70, 71], [72, 79], [80, 81], [82, 91], [92, 95], [96, 108], [109, 115], [116, 123], [124, 126], [127, 137], [138, 140], [141, 154], [155, 157], [158, 167], [167, 168]]}
{"doc_key": "ai-test-139", "ner": [[0, 1, "product"], [16, 16, "programlang"], [18, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 16, 16, "general-affiliation", "", false, false], [0, 1, 18, 19, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Os", "Phidgets", "podem", "ser", "programados", "usando", "uma", "variedade", "de", "softwares", "e", "linguagens", "de", "programa\u00e7\u00e3o", ",", "desde", "Java", "at\u00e9", "Microsoft", "Excel", "."], "sentence-detokenized": "Os Phidgets podem ser programados usando uma variedade de softwares e linguagens de programa\u00e7\u00e3o, desde Java at\u00e9 Microsoft Excel.", "token2charspan": [[0, 2], [3, 11], [12, 17], [18, 21], [22, 33], [34, 40], [41, 44], [45, 54], [55, 57], [58, 67], [68, 69], [70, 80], [81, 83], [84, 95], [95, 96], [97, 102], [103, 107], [108, 111], [112, 121], [122, 127], [127, 128]]}
{"doc_key": "ai-test-140", "ner": [[2, 4, "field"], [10, 11, "researcher"], [14, 15, "misc"], [21, 23, "field"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 10, 11, "origin", "", false, false], [10, 11, 21, 23, "general-affiliation", "topic_of_study", false, false], [10, 11, 25, 26, "general-affiliation", "topic_of_study", false, false], [14, 15, 10, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["O", "termo", "aprendizado", "por", "m\u00e1quina", "foi", "cunhado", "em", "1959", "por", "Arthur", "Samuel", ",", "um", "IBMer", "americano", "e", "pioneiro", "no", "campo", "de", "jogos", "de", "computador", "e", "intelig\u00eancia", "artificial", "."], "sentence-detokenized": "O termo aprendizado por m\u00e1quina foi cunhado em 1959 por Arthur Samuel, um IBMer americano e pioneiro no campo de jogos de computador e intelig\u00eancia artificial.", "token2charspan": [[0, 1], [2, 7], [8, 19], [20, 23], [24, 31], [32, 35], [36, 43], [44, 46], [47, 51], [52, 55], [56, 62], [63, 69], [69, 70], [71, 73], [74, 79], [80, 89], [90, 91], [92, 100], [101, 103], [104, 109], [110, 112], [113, 118], [119, 121], [122, 132], [133, 134], [135, 147], [148, 158], [158, 159]]}
{"doc_key": "ai-test-141", "ner": [[1, 2, "misc"], [3, 4, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 1, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["O", "poeta", "israelense", "David", "Avidan", ",", "que", "estava", "fascinado", "com", "as", "futuras", "tecnologias", "e", "sua", "rela\u00e7\u00e3o", "com", "a", "arte", ",", "desejava", "explorar", "o", "uso", "de", "computadores", "para", "escrever", "literatura", "."], "sentence-detokenized": "O poeta israelense David Avidan, que estava fascinado com as futuras tecnologias e sua rela\u00e7\u00e3o com a arte, desejava explorar o uso de computadores para escrever literatura.", "token2charspan": [[0, 1], [2, 7], [8, 18], [19, 24], [25, 31], [31, 32], [33, 36], [37, 43], [44, 53], [54, 57], [58, 60], [61, 68], [69, 80], [81, 82], [83, 86], [87, 94], [95, 98], [99, 100], [101, 105], [105, 106], [107, 115], [116, 124], [125, 126], [127, 130], [131, 133], [134, 146], [147, 151], [152, 160], [161, 171], [171, 172]]}
{"doc_key": "ai-test-142", "ner": [[3, 4, "misc"], [8, 9, "organisation"], [17, 17, "location"], [36, 36, "location"], [32, 35, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 9, 3, 4, "part-of", "", false, false], [32, 35, 36, 36, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Como", "parte", "do", "Projeto", "GATEway", "em", "2017", ",", "a", "Oxbotica", "testou", "sete", "\u00f4nibus", "\u00f4nibus", "\u00f4nibus", "aut\u00f4nomos", "em", "Greenwich", ",", "navegando", "por", "um", "caminho", "de", "duas", "milhas", "\u00e0", "beira", "do", "rio", "perto", "da", "The", "O2", "Arena", "de", "Londres", "em", "uma", "rota", "tamb\u00e9m", "utilizada", "por", "pedestres", "e", "ciclistas", "."], "sentence-detokenized": "Como parte do Projeto GATEway em 2017, a Oxbotica testou sete \u00f4nibus \u00f4nibus \u00f4nibus aut\u00f4nomos em Greenwich, navegando por um caminho de duas milhas \u00e0 beira do rio perto da The O2 Arena de Londres em uma rota tamb\u00e9m utilizada por pedestres e ciclistas.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 21], [22, 29], [30, 32], [33, 37], [37, 38], [39, 40], [41, 49], [50, 56], [57, 61], [62, 68], [69, 75], [76, 82], [83, 92], [93, 95], [96, 105], [105, 106], [107, 116], [117, 120], [121, 123], [124, 131], [132, 134], [135, 139], [140, 146], [147, 148], [149, 154], [155, 157], [158, 161], [162, 167], [168, 170], [171, 174], [175, 177], [178, 183], [184, 186], [187, 194], [195, 197], [198, 201], [202, 206], [207, 213], [214, 223], [224, 227], [228, 237], [238, 239], [240, 249], [249, 250]]}
{"doc_key": "ai-test-143", "ner": [[11, 13, "task"], [16, 16, "metrics"], [20, 21, "misc"], [27, 27, "metrics"], [29, 29, "metrics"], [31, 31, "metrics"], [33, 33, "metrics"], [35, 37, "metrics"], [40, 40, "metrics"], [42, 42, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[16, 16, 20, 21, "related-to", "is_a", false, false], [16, 16, 27, 27, "usage", "", false, false], [16, 16, 29, 29, "usage", "", false, false], [27, 27, 31, 31, "named", "same", false, false], [29, 29, 42, 42, "named", "same", false, false], [31, 31, 40, 40, "opposite", "", false, false], [31, 31, 42, 42, "opposite", "", false, false], [33, 33, 31, 31, "named", "", false, false], [35, 37, 31, 31, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Uma", "combina\u00e7\u00e3o", "n\u00e3o", "relacionada", "mas", "comumente", "utilizada", "de", "estat\u00edsticas", "b\u00e1sicas", "de", "recupera\u00e7\u00e3o", "de", "informa\u00e7\u00f5es", "\u00e9", "o", "F-score", ",", "sendo", "uma", "m\u00e9dia", "harm\u00f4nica", "(", "possivelmente", "ponderada", ")", "de", "recall", "e", "precis\u00e3o", "onde", "recall", "=", "sensibilidade", "=", "TRUE", "positive", "rate", ",", "mas", "especificidade", "e", "precis\u00e3o", "s\u00e3o", "medidas", "totalmente", "diferentes", "."], "sentence-detokenized": "Uma combina\u00e7\u00e3o n\u00e3o relacionada mas comumente utilizada de estat\u00edsticas b\u00e1sicas de recupera\u00e7\u00e3o de informa\u00e7\u00f5es \u00e9 o F-score, sendo uma m\u00e9dia harm\u00f4nica (possivelmente ponderada) de recall e precis\u00e3o onde recall = sensibilidade = TRUE positive rate, mas especificidade e precis\u00e3o s\u00e3o medidas totalmente diferentes.", "token2charspan": [[0, 3], [4, 14], [15, 18], [19, 30], [31, 34], [35, 44], [45, 54], [55, 57], [58, 70], [71, 78], [79, 81], [82, 93], [94, 96], [97, 108], [109, 110], [111, 112], [113, 120], [120, 121], [122, 127], [128, 131], [132, 137], [138, 147], [148, 149], [149, 162], [163, 172], [172, 173], [174, 176], [177, 183], [184, 185], [186, 194], [195, 199], [200, 206], [207, 208], [209, 222], [223, 224], [225, 229], [230, 238], [239, 243], [243, 244], [245, 248], [249, 263], [264, 265], [266, 274], [275, 278], [279, 286], [287, 297], [298, 308], [308, 309]]}
{"doc_key": "ai-test-144", "ner": [[0, 2, "field"], [11, 11, "field"], [13, 13, "field"], [15, 15, "field"], [17, 17, "field"], [19, 20, "field"], [29, 31, "product"], [33, 35, "product"], [37, 38, "product"], [40, 41, "product"], [54, 56, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 2, 11, 11, "origin", "takes_inspiration_from", false, false], [0, 2, 13, 13, "origin", "takes_inspiration_from", false, false], [0, 2, 15, 15, "origin", "takes_inspiration_from", false, false], [0, 2, 17, 17, "origin", "takes_inspiration_from", false, false], [0, 2, 19, 20, "origin", "takes_inspiration_from", false, false], [29, 31, 0, 2, "origin", "", false, false], [33, 35, 0, 2, "origin", "", false, false], [37, 38, 0, 2, "origin", "", false, false], [40, 41, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["A", "engenharia", "neurom\u00f3rfica", "\u00e9", "um", "assunto", "interdisciplinar", "que", "se", "inspira", "na", "biologia", ",", "f\u00edsica", ",", "matem\u00e1tica", ",", "inform\u00e1tica", "e", "engenharia", "eletr\u00f4nica", "para", "projetar", "sistemas", "neurais", "artificiais", ",", "tais", "como", "sistemas", "de", "vis\u00e3o", ",", "sistemas", "de", "cabe\u00e7a-olho", ",", "processadores", "auditivos", "e", "rob\u00f4s", "aut\u00f4nomos", ",", "cuja", "arquitetura", "f\u00edsica", "e", "princ\u00edpios", "de", "projeto", "se", "baseiam", "naqueles", "dos", "sistemas", "nervosos", "biol\u00f3gicos", "."], "sentence-detokenized": "A engenharia neurom\u00f3rfica \u00e9 um assunto interdisciplinar que se inspira na biologia, f\u00edsica, matem\u00e1tica, inform\u00e1tica e engenharia eletr\u00f4nica para projetar sistemas neurais artificiais, tais como sistemas de vis\u00e3o, sistemas de cabe\u00e7a-olho, processadores auditivos e rob\u00f4s aut\u00f4nomos, cuja arquitetura f\u00edsica e princ\u00edpios de projeto se baseiam naqueles dos sistemas nervosos biol\u00f3gicos.", "token2charspan": [[0, 1], [2, 12], [13, 25], [26, 27], [28, 30], [31, 38], [39, 55], [56, 59], [60, 62], [63, 70], [71, 73], [74, 82], [82, 83], [84, 90], [90, 91], [92, 102], [102, 103], [104, 115], [116, 117], [118, 128], [129, 139], [140, 144], [145, 153], [154, 162], [163, 170], [171, 182], [182, 183], [184, 188], [189, 193], [194, 202], [203, 205], [206, 211], [211, 212], [213, 221], [222, 224], [225, 236], [236, 237], [238, 251], [252, 261], [262, 263], [264, 269], [270, 279], [279, 280], [281, 285], [286, 297], [298, 304], [305, 306], [307, 317], [318, 320], [321, 328], [329, 331], [332, 339], [340, 348], [349, 352], [353, 361], [362, 370], [371, 381], [381, 382]]}
{"doc_key": "ai-test-145", "ner": [[5, 8, "metrics"], [12, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 12, 5, 8, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Para", "ser", "espec\u00edfico", ",", "o", "crit\u00e9rio", "de", "estabilidade", "BIBO", "exige", "que", "o", "ROC", "do", "sistema", "inclua", "o", "c\u00edrculo", "unit\u00e1rio", "."], "sentence-detokenized": "Para ser espec\u00edfico, o crit\u00e9rio de estabilidade BIBO exige que o ROC do sistema inclua o c\u00edrculo unit\u00e1rio.", "token2charspan": [[0, 4], [5, 8], [9, 19], [19, 20], [21, 22], [23, 31], [32, 34], [35, 47], [48, 52], [53, 58], [59, 62], [63, 64], [65, 68], [69, 71], [72, 79], [80, 86], [87, 88], [89, 96], [97, 105], [105, 106]]}
{"doc_key": "ai-test-146", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2", "O", "programa", "foi", "reescrito", "em", "Java", "a", "partir", "de", "1998", "."], "sentence-detokenized": "2 O programa foi reescrito em Java a partir de 1998.", "token2charspan": [[0, 1], [2, 3], [4, 12], [13, 16], [17, 26], [27, 29], [30, 34], [35, 36], [37, 43], [44, 46], [47, 51], [51, 52]]}
{"doc_key": "ai-test-147", "ner": [[1, 1, "metrics"], [9, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 1, 9, 11, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["O", "MCC", "pode", "ser", "calculado", "diretamente", "a", "partir", "da", "matriz", "de", "confus\u00e3o", "usando", "a", "f\u00f3rmula", ":"], "sentence-detokenized": "O MCC pode ser calculado diretamente a partir da matriz de confus\u00e3o usando a f\u00f3rmula:", "token2charspan": [[0, 1], [2, 5], [6, 10], [11, 14], [15, 24], [25, 36], [37, 38], [39, 45], [46, 48], [49, 55], [56, 58], [59, 67], [68, 74], [75, 76], [77, 84], [84, 85]]}
{"doc_key": "ai-test-148", "ner": [[6, 9, "organisation"], [16, 23, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 9, 16, 23, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Foi", "desenvolvido", "por", "uma", "equipe", "do", "MIT-IBM", "Watson", "AI", "Lab", "e", "apresentado", "pela", "primeira", "vez", "na", "Confer\u00eancia", "Internacional", "sobre", "Representa\u00e7\u00f5es", "de", "Aprendizagem", "de", "2018", "."], "sentence-detokenized": "Foi desenvolvido por uma equipe do MIT-IBM Watson AI Lab e apresentado pela primeira vez na Confer\u00eancia Internacional sobre Representa\u00e7\u00f5es de Aprendizagem de 2018.", "token2charspan": [[0, 3], [4, 16], [17, 20], [21, 24], [25, 31], [32, 34], [35, 42], [43, 49], [50, 52], [53, 56], [57, 58], [59, 70], [71, 75], [76, 84], [85, 88], [89, 91], [92, 103], [104, 117], [118, 123], [124, 138], [139, 141], [142, 154], [155, 157], [158, 162], [162, 163]]}
{"doc_key": "ai-test-149", "ner": [[2, 3, "metrics"], [14, 15, "metrics"], [17, 17, "metrics"], [43, 43, "metrics"], [45, 45, "metrics"], [52, 55, "metrics"], [58, 58, "metrics"], [60, 60, "metrics"], [62, 62, "metrics"], [67, 67, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[14, 15, 43, 43, "type-of", "", false, false], [14, 15, 52, 55, "related-to", "collapses_to_identity", false, false], [17, 17, 45, 45, "type-of", "", false, false], [17, 17, 52, 55, "related-to", "collapses_to_identity", false, false], [17, 17, 62, 62, "named", "same", false, false], [58, 58, 67, 67, "related-to", "collapses_to_identity", false, false], [60, 60, 67, 67, "related-to", "collapses_to_identity", false, false], [62, 62, 67, 67, "related-to", "collapses_to_identity", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Quando", "as", "preval\u00eancias", "VERDADEIRAS", "para", "as", "duas", "vari\u00e1veis", "positivas", "s\u00e3o", "iguais", "como", "assumidas", "em", "Fleiss", "kappa", "e", "F-score", ",", "ou", "seja", ",", "o", "n\u00famero", "de", "previs\u00f5es", "positivas", "corresponde", "ao", "n\u00famero", "de", "classes", "positivas", "no", "caso", "dicot\u00f4mico", "(", "duas", "classes", ")", ",", "as", "diferentes", "kappa", "e", "correla\u00e7\u00e3o", "medem", "o", "colapso", "da", "identidade", "com", "o", "J", "de", "Youden", ",", "e", "recall", ",", "precis\u00e3o", "e", "F-score", "s\u00e3o", "similarmente", "id\u00eanticos", "com", "precis\u00e3o", "."], "sentence-detokenized": "Quando as preval\u00eancias VERDADEIRAS para as duas vari\u00e1veis positivas s\u00e3o iguais como assumidas em Fleiss kappa e F-score, ou seja, o n\u00famero de previs\u00f5es positivas corresponde ao n\u00famero de classes positivas no caso dicot\u00f4mico (duas classes), as diferentes kappa e correla\u00e7\u00e3o medem o colapso da identidade com o J de Youden, e recall, precis\u00e3o e F-score s\u00e3o similarmente id\u00eanticos com precis\u00e3o.", "token2charspan": [[0, 6], [7, 9], [10, 22], [23, 34], [35, 39], [40, 42], [43, 47], [48, 57], [58, 67], [68, 71], [72, 78], [79, 83], [84, 93], [94, 96], [97, 103], [104, 109], [110, 111], [112, 119], [119, 120], [121, 123], [124, 128], [128, 129], [130, 131], [132, 138], [139, 141], [142, 151], [152, 161], [162, 173], [174, 176], [177, 183], [184, 186], [187, 194], [195, 204], [205, 207], [208, 212], [213, 223], [224, 225], [225, 229], [230, 237], [237, 238], [238, 239], [240, 242], [243, 253], [254, 259], [260, 261], [262, 272], [273, 278], [279, 280], [281, 288], [289, 291], [292, 302], [303, 306], [307, 308], [309, 310], [311, 313], [314, 320], [320, 321], [322, 323], [324, 330], [330, 331], [332, 340], [341, 342], [343, 350], [351, 354], [355, 367], [368, 377], [378, 381], [382, 390], [390, 391]]}
{"doc_key": "ai-test-150", "ner": [[1, 4, "misc"], [6, 6, "misc"], [9, 9, "conference"], [16, 20, "task"], [21, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 4, 9, 9, "part-of", "", false, false], [1, 4, 9, 9, "physical", "", false, false], [1, 4, 9, 9, "temporal", "", false, false], [6, 6, 1, 4, "named", "", false, false], [16, 20, 1, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["O", "workshop", "Building", "Educational", "Applications", "(", "BEA", ")", "na", "NAACL", "2013", "foi", "o", "anfitri\u00e3o", "da", "primeira", "tarefa", "compartilhada", "da", "NLI", ".", "Tetreault", "et", "al", ",", "2013", "A", "competi\u00e7\u00e3o", "resultou", "em", "29", "inscri\u00e7\u00f5es", "de", "equipes", "de", "todo", "o", "mundo", ",", "24", "das", "quais", "tamb\u00e9m", "publicaram", "um", "trabalho", "descrevendo", "seus", "sistemas", "e", "abordagens", "."], "sentence-detokenized": "O workshop Building Educational Applications (BEA) na NAACL 2013 foi o anfitri\u00e3o da primeira tarefa compartilhada da NLI. Tetreault et al, 2013 A competi\u00e7\u00e3o resultou em 29 inscri\u00e7\u00f5es de equipes de todo o mundo, 24 das quais tamb\u00e9m publicaram um trabalho descrevendo seus sistemas e abordagens.", "token2charspan": [[0, 1], [2, 10], [11, 19], [20, 31], [32, 44], [45, 46], [46, 49], [49, 50], [51, 53], [54, 59], [60, 64], [65, 68], [69, 70], [71, 80], [81, 83], [84, 92], [93, 99], [100, 113], [114, 116], [117, 120], [120, 121], [122, 131], [132, 134], [135, 137], [137, 138], [139, 143], [144, 145], [146, 156], [157, 165], [166, 168], [169, 171], [172, 182], [183, 185], [186, 193], [194, 196], [197, 201], [202, 203], [204, 209], [209, 210], [211, 213], [214, 217], [218, 223], [224, 230], [231, 241], [242, 244], [245, 253], [254, 265], [266, 270], [271, 279], [280, 281], [282, 292], [292, 293]]}
{"doc_key": "ai-test-151", "ner": [[1, 3, "algorithm"], [6, 9, "algorithm"], [17, 18, "misc"], [20, 22, "misc"], [37, 39, "misc"], [41, 43, "algorithm"], [45, 45, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 3, 6, 9, "type-of", "", false, false], [1, 3, 17, 18, "related-to", "finds", false, false], [20, 22, 17, 18, "type-of", "", false, false], [45, 45, 41, 43, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["O", "algoritmo", "de", "Viterbi", "\u00e9", "um", "algoritmo", "din\u00e2mico", "de", "programa\u00e7\u00e3o", "para", "encontrar", "a", "seq\u00fc\u00eancia", "mais", "prov\u00e1vel", "de", "estados", "ocultos", "chamada", "caminho", "de", "Viterbi", "que", "resulta", "em", "uma", "seq\u00fc\u00eancia", "de", "eventos", "observados", ",", "especialmente", "no", "contexto", "das", "fontes", "de", "informa\u00e7\u00e3o", "Markov", "e", "modelos", "Markov", "ocultos", "(", "HMM", ")", "."], "sentence-detokenized": "O algoritmo de Viterbi \u00e9 um algoritmo din\u00e2mico de programa\u00e7\u00e3o para encontrar a seq\u00fc\u00eancia mais prov\u00e1vel de estados ocultos chamada caminho de Viterbi que resulta em uma seq\u00fc\u00eancia de eventos observados, especialmente no contexto das fontes de informa\u00e7\u00e3o Markov e modelos Markov ocultos (HMM).", "token2charspan": [[0, 1], [2, 11], [12, 14], [15, 22], [23, 24], [25, 27], [28, 37], [38, 46], [47, 49], [50, 61], [62, 66], [67, 76], [77, 78], [79, 88], [89, 93], [94, 102], [103, 105], [106, 113], [114, 121], [122, 129], [130, 137], [138, 140], [141, 148], [149, 152], [153, 160], [161, 163], [164, 167], [168, 177], [178, 180], [181, 188], [189, 199], [199, 200], [201, 214], [215, 217], [218, 226], [227, 230], [231, 237], [238, 240], [241, 251], [252, 258], [259, 260], [261, 268], [269, 275], [276, 283], [284, 285], [285, 288], [288, 289], [289, 290]]}
{"doc_key": "ai-test-152", "ner": [[1, 1, "field"], [4, 6, "algorithm"], [9, 11, "misc"], [15, 16, "algorithm"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 1, 1, "part-of", "", false, false], [4, 6, 9, 11, "general-affiliation", "", false, false], [4, 6, 15, 16, "related-to", "generalizes_from", false, false], [4, 6, 18, 19, "related-to", "generalizes_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Em", "estat\u00edstica", ",", "a", "regress\u00e3o", "log\u00edstica", "multinomial", "\u00e9", "um", "m\u00e9todo", "de", "classifica\u00e7\u00e3o", "que", "generaliza", "a", "regress\u00e3o", "log\u00edstica", "\u00e0", "classifica\u00e7\u00e3o", "multiclasse", ",", "ou", "seja", ",", "com", "mais", "de", "dois", "poss\u00edveis", "resultados", "discretos", "."], "sentence-detokenized": "Em estat\u00edstica, a regress\u00e3o log\u00edstica multinomial \u00e9 um m\u00e9todo de classifica\u00e7\u00e3o que generaliza a regress\u00e3o log\u00edstica \u00e0 classifica\u00e7\u00e3o multiclasse, ou seja, com mais de dois poss\u00edveis resultados discretos.", "token2charspan": [[0, 2], [3, 14], [14, 15], [16, 17], [18, 27], [28, 37], [38, 49], [50, 51], [52, 54], [55, 61], [62, 64], [65, 78], [79, 82], [83, 93], [94, 95], [96, 105], [106, 115], [116, 117], [118, 131], [132, 143], [143, 144], [145, 147], [148, 152], [152, 153], [154, 157], [158, 162], [163, 165], [166, 170], [171, 180], [181, 191], [192, 201], [201, 202]]}
{"doc_key": "ai-test-153", "ner": [[0, 3, "algorithm"], [10, 12, "field"], [15, 18, "field"], [22, 22, "task"], [24, 26, "task"], [28, 30, "task"], [32, 33, "researcher"], [35, 36, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 3, 10, 12, "part-of", "", false, false], [0, 3, 15, 18, "part-of", "", false, false], [22, 22, 0, 3, "usage", "", true, false], [24, 26, 0, 3, "usage", "", true, false], [28, 30, 0, 3, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Os", "modelos", "Markov", "ocultos", "s\u00e3o", "conhecidos", "por", "suas", "aplica\u00e7\u00f5es", "para", "refor\u00e7ar", "a", "aprendizagem", "e", "o", "reconhecimento", "de", "padr\u00f5es", "temporais", ",", "tais", "como", "fala", ",", "reconhecimento", "da", "caligrafia", ",", "reconhecimento", "de", "gestos", ",", "Thad", "Starner", ",", "Alex", "Pentland", "."], "sentence-detokenized": "Os modelos Markov ocultos s\u00e3o conhecidos por suas aplica\u00e7\u00f5es para refor\u00e7ar a aprendizagem e o reconhecimento de padr\u00f5es temporais, tais como fala, reconhecimento da caligrafia, reconhecimento de gestos, Thad Starner, Alex Pentland.", "token2charspan": [[0, 2], [3, 10], [11, 17], [18, 25], [26, 29], [30, 40], [41, 44], [45, 49], [50, 60], [61, 65], [66, 74], [75, 76], [77, 89], [90, 91], [92, 93], [94, 108], [109, 111], [112, 119], [120, 129], [129, 130], [131, 135], [136, 140], [141, 145], [145, 146], [147, 161], [162, 164], [165, 175], [175, 176], [177, 191], [192, 194], [195, 201], [201, 202], [203, 207], [208, 215], [215, 216], [217, 221], [222, 230], [230, 231]]}
{"doc_key": "ai-test-154", "ner": [[7, 8, "misc"], [30, 33, "metrics"], [35, 35, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 35, 35, "named", "", false, false], [30, 33, 35, 35, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Essencialmente", ",", "isto", "significa", "que", "se", "o", "ent\u00e3o", "-grama", "foi", "visto", "mais", "de", "k", "vezes", "em", "treinamento", ",", "a", "probabilidade", "condicional", "de", "uma", "palavra", "dada", "sua", "hist\u00f3ria", "\u00e9", "proporcional", "\u00e0", "m\u00e1xima", "estimativa", "de", "probabilidade", "desse", "-grama", "."], "sentence-detokenized": "Essencialmente, isto significa que se o ent\u00e3o -grama foi visto mais de k vezes em treinamento, a probabilidade condicional de uma palavra dada sua hist\u00f3ria \u00e9 proporcional \u00e0 m\u00e1xima estimativa de probabilidade desse -grama.", "token2charspan": [[0, 14], [14, 15], [16, 20], [21, 30], [31, 34], [35, 37], [38, 39], [40, 45], [46, 52], [53, 56], [57, 62], [63, 67], [68, 70], [71, 72], [73, 78], [79, 81], [82, 93], [93, 94], [95, 96], [97, 110], [111, 122], [123, 125], [126, 129], [130, 137], [138, 142], [143, 146], [147, 155], [156, 157], [158, 170], [171, 172], [173, 179], [180, 190], [191, 193], [194, 207], [208, 213], [214, 220], [220, 221]]}
{"doc_key": "ai-test-155", "ner": [[4, 6, "task"], [9, 10, "task"], [13, 16, "task"], [24, 27, "task"], [36, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[36, 37, 24, 27, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Ele", "est\u00e1", "interessado", "na", "representa\u00e7\u00e3o", "do", "conhecimento", ",", "no", "racioc\u00ednio", "comum", "e", "na", "compreens\u00e3o", "da", "linguagem", "natural", ",", "acreditando", "que", ",", "atualmente", ",", "a", "compreens\u00e3o", "profunda", "da", "linguagem", "s\u00f3", "pode", "ser", "alcan\u00e7ada", "atrav\u00e9s", "de", "uma", "significativa", "engenharia", "manual", "de", "formalismos", "semanticamente", "ricos", "aliada", "a", "prefer\u00eancias", "estat\u00edsticas", "."], "sentence-detokenized": "Ele est\u00e1 interessado na representa\u00e7\u00e3o do conhecimento, no racioc\u00ednio comum e na compreens\u00e3o da linguagem natural, acreditando que, atualmente, a compreens\u00e3o profunda da linguagem s\u00f3 pode ser alcan\u00e7ada atrav\u00e9s de uma significativa engenharia manual de formalismos semanticamente ricos aliada a prefer\u00eancias estat\u00edsticas.", "token2charspan": [[0, 3], [4, 8], [9, 20], [21, 23], [24, 37], [38, 40], [41, 53], [53, 54], [55, 57], [58, 68], [69, 74], [75, 76], [77, 79], [80, 91], [92, 94], [95, 104], [105, 112], [112, 113], [114, 125], [126, 129], [129, 130], [131, 141], [141, 142], [143, 144], [145, 156], [157, 165], [166, 168], [169, 178], [179, 181], [182, 186], [187, 190], [191, 200], [201, 208], [209, 211], [212, 215], [216, 229], [230, 240], [241, 247], [248, 250], [251, 262], [263, 277], [278, 283], [284, 290], [291, 292], [293, 305], [306, 318], [318, 319]]}
{"doc_key": "ai-test-156", "ner": [[1, 1, "programlang"], [3, 3, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Em", "JavaScript", ",", "Python", "ou"], "sentence-detokenized": "Em JavaScript, Python ou", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 21], [22, 24]]}
{"doc_key": "ai-test-157", "ner": [[1, 2, "misc"], [6, 8, "misc"], [11, 11, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 6, 8, "part-of", "", false, false], [6, 8, 11, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Os", "Pr\u00eamios", "Newcomb", "s\u00e3o", "anunciados", "na", "revista", "AI", "Magazine", "publicada", "pela", "AAAI", "."], "sentence-detokenized": "Os Pr\u00eamios Newcomb s\u00e3o anunciados na revista AI Magazine publicada pela AAAI.", "token2charspan": [[0, 2], [3, 10], [11, 18], [19, 22], [23, 33], [34, 36], [37, 44], [45, 47], [48, 56], [57, 66], [67, 71], [72, 76], [76, 77]]}
{"doc_key": "ai-test-158", "ner": [[1, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["O", "erro", "m\u00e9dio", "ao", "quadrado", "em", "um", "conjunto", "de", "100", "exemplos", "\u00e9", "0,084", ",", "menor", "do", "que", "o", "erro", "n\u00e3o", "normalizado", "."], "sentence-detokenized": "O erro m\u00e9dio ao quadrado em um conjunto de 100 exemplos \u00e9 0,084, menor do que o erro n\u00e3o normalizado.", "token2charspan": [[0, 1], [2, 6], [7, 12], [13, 15], [16, 24], [25, 27], [28, 30], [31, 39], [40, 42], [43, 46], [47, 55], [56, 57], [58, 63], [63, 64], [65, 70], [71, 73], [74, 77], [78, 79], [80, 84], [85, 88], [89, 100], [100, 101]]}
{"doc_key": "ai-test-159", "ner": [[1, 1, "metrics"], [9, 12, "field"], [18, 21, "task"], [23, 23, "task"], [27, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 12, 1, 1, "usage", "", false, false], [18, 21, 9, 12, "part-of", "task_part_of_field", false, false], [23, 23, 18, 21, "named", "", false, false], [27, 29, 9, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["O", "F-score", "tem", "sido", "amplamente", "utilizado", "na", "literatura", "de", "processamento", "de", "linguagem", "natural", ",", "como", "a", "avalia\u00e7\u00e3o", "do", "reconhecimento", "de", "entidade", "nomeada", "(", "NER", ")", "e", "a", "segmenta\u00e7\u00e3o", "de", "palavras", "."], "sentence-detokenized": "O F-score tem sido amplamente utilizado na literatura de processamento de linguagem natural, como a avalia\u00e7\u00e3o do reconhecimento de entidade nomeada (NER) e a segmenta\u00e7\u00e3o de palavras.", "token2charspan": [[0, 1], [2, 9], [10, 13], [14, 18], [19, 29], [30, 39], [40, 42], [43, 53], [54, 56], [57, 70], [71, 73], [74, 83], [84, 91], [91, 92], [93, 97], [98, 99], [100, 109], [110, 112], [113, 127], [128, 130], [131, 139], [140, 147], [148, 149], [149, 152], [152, 153], [154, 155], [156, 157], [158, 169], [170, 172], [173, 181], [181, 182]]}
{"doc_key": "ai-test-160", "ner": [[0, 1, "product"], [6, 8, "product"], [18, 20, "misc"], [23, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 18, 20, "related-to", "performs_task", false, false], [0, 1, 23, 25, "related-to", "performs_task", false, false], [6, 8, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Os", "Chatbots", "s\u00e3o", "normalmente", "usados", "em", "sistemas", "de", "di\u00e1logo", "para", "v\u00e1rios", "prop\u00f3sitos", ",", "incluindo", "servi\u00e7o", "ao", "cliente", ",", "roteamento", "de", "pedidos", "ou", "para", "coleta", "de", "informa\u00e7\u00f5es", "."], "sentence-detokenized": "Os Chatbots s\u00e3o normalmente usados em sistemas de di\u00e1logo para v\u00e1rios prop\u00f3sitos, incluindo servi\u00e7o ao cliente, roteamento de pedidos ou para coleta de informa\u00e7\u00f5es.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 27], [28, 34], [35, 37], [38, 46], [47, 49], [50, 57], [58, 62], [63, 69], [70, 80], [80, 81], [82, 91], [92, 99], [100, 102], [103, 110], [110, 111], [112, 122], [123, 125], [126, 133], [134, 136], [137, 141], [142, 148], [149, 151], [152, 163], [163, 164]]}
{"doc_key": "ai-test-161", "ner": [[4, 10, "conference"], [15, 23, "conference"], [30, 40, "conference"], [49, 49, "conference"], [52, 55, "conference"], [58, 59, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[15, 23, 4, 10, "named", "", false, false], [30, 40, 4, 10, "named", "", false, false], [49, 49, 30, 40, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Revistas", "importantes", "incluem", "as", "IEEE", "Transactions", "on", "Speech", "and", "Audio", "Processing", "(", "mais", "tarde", "renomeadas", "IEEE", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "e", "desde", "setembro", "de", "2014", "renomeadas", "IEEE", "/", "ACM", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "-", "ap\u00f3s", "a", "fus\u00e3o", "com", "uma", "publica\u00e7\u00e3o", "da", "ACM", ")", ",", "Computer", "Speech", "and", "Language", ",", "e", "Speech", "Communication", "."], "sentence-detokenized": "Revistas importantes incluem as IEEE Transactions on Speech and Audio Processing (mais tarde renomeadas IEEE Transactions on Audio, Speech and Language Processing e desde setembro de 2014 renomeadas IEEE / ACM Transactions on Audio, Speech and Language Processing - ap\u00f3s a fus\u00e3o com uma publica\u00e7\u00e3o da ACM), Computer Speech and Language, e Speech Communication.", "token2charspan": [[0, 8], [9, 20], [21, 28], [29, 31], [32, 36], [37, 49], [50, 52], [53, 59], [60, 63], [64, 69], [70, 80], [81, 82], [82, 86], [87, 92], [93, 103], [104, 108], [109, 121], [122, 124], [125, 130], [130, 131], [132, 138], [139, 142], [143, 151], [152, 162], [163, 164], [165, 170], [171, 179], [180, 182], [183, 187], [188, 198], [199, 203], [204, 205], [206, 209], [210, 222], [223, 225], [226, 231], [231, 232], [233, 239], [240, 243], [244, 252], [253, 263], [264, 265], [266, 270], [271, 272], [273, 278], [279, 282], [283, 286], [287, 297], [298, 300], [301, 304], [304, 305], [305, 306], [307, 315], [316, 322], [323, 326], [327, 335], [335, 336], [337, 338], [339, 345], [346, 359], [359, 360]]}
{"doc_key": "ai-test-162", "ner": [[0, 1, "algorithm"], [6, 8, "task"], [10, 12, "field"], [14, 16, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 8, 0, 1, "usage", "", false, false], [6, 8, 10, 12, "part-of", "task_part_of_field", false, false], [6, 8, 14, 16, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["O", "EM", "\u00e9", "freq\u00fcentemente", "usado", "para", "agrupamento", "de", "dados", "na", "aprendizagem", "de", "m\u00e1quinas", "e", "vis\u00e3o", "por", "computador", "."], "sentence-detokenized": "O EM \u00e9 freq\u00fcentemente usado para agrupamento de dados na aprendizagem de m\u00e1quinas e vis\u00e3o por computador.", "token2charspan": [[0, 1], [2, 4], [5, 6], [7, 21], [22, 27], [28, 32], [33, 44], [45, 47], [48, 53], [54, 56], [57, 69], [70, 72], [73, 81], [82, 83], [84, 89], [90, 93], [94, 104], [104, 105]]}
{"doc_key": "ai-test-163", "ner": [[9, 11, "metrics"], [25, 30, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 25, 30, "related-to", "described_by", false, false]], "relations_mapping_to_source": [0], "sentence": ["Embora", "n\u00e3o", "exista", "uma", "maneira", "perfeita", "de", "descrever", "a", "matriz", "de", "confus\u00e3o", "de", "VERDADEIRO", "e", "FALSO", "positivo", "e", "negativo", "por", "um", "\u00fanico", "n\u00famero", ",", "o", "coeficiente", "de", "correla\u00e7\u00e3o", "de", "Matthews", "\u00e9", "geralmente", "considerado", "como", "sendo", "uma", "das", "melhores", "medidas", "desse", "tipo", "."], "sentence-detokenized": "Embora n\u00e3o exista uma maneira perfeita de descrever a matriz de confus\u00e3o de VERDADEIRO e FALSO positivo e negativo por um \u00fanico n\u00famero, o coeficiente de correla\u00e7\u00e3o de Matthews \u00e9 geralmente considerado como sendo uma das melhores medidas desse tipo.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 21], [22, 29], [30, 38], [39, 41], [42, 51], [52, 53], [54, 60], [61, 63], [64, 72], [73, 75], [76, 86], [87, 88], [89, 94], [95, 103], [104, 105], [106, 114], [115, 118], [119, 121], [122, 127], [128, 134], [134, 135], [136, 137], [138, 149], [150, 152], [153, 163], [164, 166], [167, 175], [176, 177], [178, 188], [189, 200], [201, 205], [206, 211], [212, 215], [216, 219], [220, 228], [229, 236], [237, 242], [243, 247], [247, 248]]}
{"doc_key": "ai-test-164", "ner": [[12, 14, "field"], [34, 36, "field"], [42, 44, "field"], [48, 49, "algorithm"], [51, 53, "task"], [55, 56, "algorithm"], [61, 65, "algorithm"], [67, 69, "algorithm"], [75, 78, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[42, 44, 34, 36, "part-of", "subfield", false, false], [48, 49, 42, 44, "part-of", "", false, true], [51, 53, 42, 44, "part-of", "", false, true], [55, 56, 42, 44, "part-of", "", false, true], [61, 65, 42, 44, "part-of", "", false, true], [67, 69, 42, 44, "part-of", "", false, true], [75, 78, 42, 44, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Como", "os", "conjuntos", "de", "dados", "cresceram", "em", "tamanho", "e", "complexidade", ",", "a", "an\u00e1lise", "de", "dados", "direta", "e", "pr\u00e1tica", "foi", "aumentada", "com", "o", "processamento", "de", "dados", "indireto", "e", "automatizado", ",", "auxiliado", "por", "outras", "descobertas", "na", "ci\u00eancia", "da", "computa\u00e7\u00e3o", ",", "especialmente", "no", "campo", "da", "aprendizagem", "de", "m\u00e1quinas", ",", "tais", "como", "redes", "neurais", ",", "an\u00e1lise", "de", "cluster", ",", "algoritmos", "gen\u00e9ticos", "(", "1950s", ")", ",", "aprendizagem", "em", "\u00e1rvore", "de", "decis\u00e3o", "e", "regras", "de", "decis\u00e3o", "(", "1960s", ")", ",", "e", "m\u00e1quinas", "vetoriais", "de", "suporte", "(", "1990s", ")", "."], "sentence-detokenized": "Como os conjuntos de dados cresceram em tamanho e complexidade, a an\u00e1lise de dados direta e pr\u00e1tica foi aumentada com o processamento de dados indireto e automatizado, auxiliado por outras descobertas na ci\u00eancia da computa\u00e7\u00e3o, especialmente no campo da aprendizagem de m\u00e1quinas, tais como redes neurais, an\u00e1lise de cluster, algoritmos gen\u00e9ticos (1950s), aprendizagem em \u00e1rvore de decis\u00e3o e regras de decis\u00e3o (1960s), e m\u00e1quinas vetoriais de suporte (1990s).", "token2charspan": [[0, 4], [5, 7], [8, 17], [18, 20], [21, 26], [27, 36], [37, 39], [40, 47], [48, 49], [50, 62], [62, 63], [64, 65], [66, 73], [74, 76], [77, 82], [83, 89], [90, 91], [92, 99], [100, 103], [104, 113], [114, 117], [118, 119], [120, 133], [134, 136], [137, 142], [143, 151], [152, 153], [154, 166], [166, 167], [168, 177], [178, 181], [182, 188], [189, 200], [201, 203], [204, 211], [212, 214], [215, 225], [225, 226], [227, 240], [241, 243], [244, 249], [250, 252], [253, 265], [266, 268], [269, 277], [277, 278], [279, 283], [284, 288], [289, 294], [295, 302], [302, 303], [304, 311], [312, 314], [315, 322], [322, 323], [324, 334], [335, 344], [345, 346], [346, 351], [351, 352], [352, 353], [354, 366], [367, 369], [370, 376], [377, 379], [380, 387], [388, 389], [390, 396], [397, 399], [400, 407], [408, 409], [409, 414], [414, 415], [415, 416], [417, 418], [419, 427], [428, 437], [438, 440], [441, 448], [449, 450], [450, 455], [455, 456], [456, 457]]}
{"doc_key": "ai-test-165", "ner": [[5, 5, "researcher"], [10, 11, "misc"], [21, 22, "researcher"], [24, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 11, 5, 5, "artifact", "", false, false], [10, 11, 21, 22, "artifact", "", false, false], [10, 11, 24, 25, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["No", "outono", "de", "2005", ",", "Thrun", "publicou", "um", "livro", "intitulado", "Rob\u00f3tica", "Probabil\u00edstica", "juntamente", "com", "seus", "colegas", "de", "trabalho", "de", "longo", "prazo", "Dieter", "Fox", "e", "Wolfram", "Burgard", "."], "sentence-detokenized": "No outono de 2005, Thrun publicou um livro intitulado Rob\u00f3tica Probabil\u00edstica juntamente com seus colegas de trabalho de longo prazo Dieter Fox e Wolfram Burgard.", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 17], [17, 18], [19, 24], [25, 33], [34, 36], [37, 42], [43, 53], [54, 62], [63, 77], [78, 88], [89, 92], [93, 97], [98, 105], [106, 108], [109, 117], [118, 120], [121, 126], [127, 132], [133, 139], [140, 143], [144, 145], [146, 153], [154, 161], [161, 162]]}
{"doc_key": "ai-test-166", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 7, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["John", "D.", "Lafferty", ",", "Andrew", "McCallum", "e", "Pereiramath", "como", "a", "seguir", ":"], "sentence-detokenized": "John D. Lafferty, Andrew McCallum e Pereiramath como a seguir:", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 24], [25, 33], [34, 35], [36, 47], [48, 52], [53, 54], [55, 61], [61, 62]]}
{"doc_key": "ai-test-167", "ner": [[0, 3, "task"], [5, 5, "task"], [11, 11, "field"], [16, 18, "field"], [20, 23, "field"], [25, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 3, 16, 18, "part-of", "task_part_of_field", false, false], [0, 3, 20, 23, "part-of", "task_part_of_field", false, false], [5, 5, 0, 3, "named", "", false, false], [16, 18, 11, 11, "part-of", "subfield", false, false], [20, 23, 11, 11, "part-of", "subfield", false, false], [25, 25, 20, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["A", "resposta", "a", "perguntas", "(", "QA", ")", "\u00e9", "uma", "disciplina", "de", "inform\u00e1tica", "dentro", "das", "\u00e1reas", "de", "recupera\u00e7\u00e3o", "de", "informa\u00e7\u00f5es", "e", "processamento", "de", "linguagem", "natural", "(", "PNL", ")", ",", "que", "se", "preocupa", "em", "construir", "sistemas", "que", "respondam", "automaticamente", "a", "perguntas", "feitas", "por", "humanos", "em", "uma", "linguagem", "natural", "."], "sentence-detokenized": "A resposta a perguntas (QA) \u00e9 uma disciplina de inform\u00e1tica dentro das \u00e1reas de recupera\u00e7\u00e3o de informa\u00e7\u00f5es e processamento de linguagem natural (PNL), que se preocupa em construir sistemas que respondam automaticamente a perguntas feitas por humanos em uma linguagem natural.", "token2charspan": [[0, 1], [2, 10], [11, 12], [13, 22], [23, 24], [24, 26], [26, 27], [28, 29], [30, 33], [34, 44], [45, 47], [48, 59], [60, 66], [67, 70], [71, 76], [77, 79], [80, 91], [92, 94], [95, 106], [107, 108], [109, 122], [123, 125], [126, 135], [136, 143], [144, 145], [145, 148], [148, 149], [149, 150], [151, 154], [155, 157], [158, 166], [167, 169], [170, 179], [180, 188], [189, 192], [193, 202], [203, 218], [219, 220], [221, 230], [231, 237], [238, 241], [242, 249], [250, 252], [253, 256], [257, 266], [267, 274], [274, 275]]}
{"doc_key": "ai-test-168", "ner": [[9, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Entretanto", ",", "na", "vers\u00e3o", "da", "m\u00e9trica", "utilizada", "pelas", "avalia\u00e7\u00f5es", "NIST", "anteriores", "a", "2009", ",", "a", "frase", "de", "refer\u00eancia", "mais", "curta", "havia", "sido", "utilizada", "em", "seu", "lugar", "."], "sentence-detokenized": "Entretanto, na vers\u00e3o da m\u00e9trica utilizada pelas avalia\u00e7\u00f5es NIST anteriores a 2009, a frase de refer\u00eancia mais curta havia sido utilizada em seu lugar.", "token2charspan": [[0, 10], [10, 11], [12, 14], [15, 21], [22, 24], [25, 32], [33, 42], [43, 48], [49, 59], [60, 64], [65, 75], [76, 77], [78, 82], [82, 83], [84, 85], [86, 91], [92, 94], [95, 105], [106, 110], [111, 116], [117, 122], [123, 127], [128, 137], [138, 140], [141, 144], [145, 150], [150, 151]]}
{"doc_key": "ai-test-169", "ner": [[7, 8, "person"], [21, 21, "organisation"], [18, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 18, 19, "related-to", "invests_in", false, false], [18, 19, 21, 21, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Em", "27", "de", "agosto", "de", "2018", ",", "a", "Toyota", "anunciou", "um", "investimento", "de", "500", "milh\u00f5es", "de", "d\u00f3lares", "nos", "autom\u00f3veis", "aut\u00f4nomos", "de", "Uber", "."], "sentence-detokenized": "Em 27 de agosto de 2018, a Toyota anunciou um investimento de 500 milh\u00f5es de d\u00f3lares nos autom\u00f3veis aut\u00f4nomos de Uber.", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 15], [16, 18], [19, 23], [23, 24], [25, 26], [27, 33], [34, 42], [43, 45], [46, 58], [59, 61], [62, 65], [66, 73], [74, 76], [77, 84], [85, 88], [89, 99], [100, 109], [110, 112], [113, 117], [117, 118]]}
{"doc_key": "ai-test-170", "ner": [[6, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "amostra", "m\u00e1xima", "\u00e9", "o", "m\u00e1ximo", "estimador", "de", "probabilidade", "para", "a", "popula\u00e7\u00e3o", "m\u00e1xima", ",", "mas", ",", "como", "discutido", "acima", ",", "\u00e9", "tendencioso", "."], "sentence-detokenized": "A amostra m\u00e1xima \u00e9 o m\u00e1ximo estimador de probabilidade para a popula\u00e7\u00e3o m\u00e1xima, mas, como discutido acima, \u00e9 tendencioso.", "token2charspan": [[0, 1], [2, 9], [10, 16], [17, 18], [19, 20], [21, 27], [28, 37], [38, 40], [41, 54], [55, 59], [60, 61], [62, 71], [72, 78], [78, 79], [80, 83], [83, 84], [85, 89], [90, 99], [100, 105], [105, 106], [107, 108], [109, 120], [120, 121]]}
{"doc_key": "ai-test-171", "ner": [[0, 1, "task"], [5, 6, "misc"], [10, 10, "metrics"], [18, 21, "algorithm"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 6, "related-to", "overcomes", false, false], [0, 1, 10, 10, "related-to", "increases", false, false], [5, 6, 18, 21, "opposite", "", false, false], [5, 6, 23, 25, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["O", "LSI", "ajuda", "a", "superar", "a", "sinon\u00edmia", "ao", "aumentar", "a", "recorda\u00e7\u00e3o", ",", "uma", "das", "restri\u00e7\u00f5es", "mais", "problem\u00e1ticas", "das", "consultas", "de", "palavras-chave", "booleanas", "e", "modelos", "espaciais", "vetoriais", "."], "sentence-detokenized": "O LSI ajuda a superar a sinon\u00edmia ao aumentar a recorda\u00e7\u00e3o, uma das restri\u00e7\u00f5es mais problem\u00e1ticas das consultas de palavras-chave booleanas e modelos espaciais vetoriais.", "token2charspan": [[0, 1], [2, 5], [6, 11], [12, 13], [14, 21], [22, 23], [24, 33], [34, 36], [37, 45], [46, 47], [48, 58], [58, 59], [60, 63], [64, 67], [68, 78], [79, 83], [84, 97], [98, 101], [102, 111], [112, 114], [115, 129], [130, 139], [140, 141], [142, 149], [150, 159], [160, 169], [169, 170]]}
{"doc_key": "ai-test-172", "ner": [[3, 5, "task"], [23, 23, "programlang"], [25, 25, "programlang"], [27, 27, "programlang"], [30, 31, "programlang"], [33, 34, "programlang"], [36, 36, "programlang"], [38, 38, "programlang"], [40, 40, "programlang"], [42, 42, "programlang"], [44, 44, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[3, 5, 23, 23, "general-affiliation", "", false, false], [3, 5, 25, 25, "general-affiliation", "", false, false], [3, 5, 27, 27, "general-affiliation", "", false, false], [3, 5, 30, 31, "general-affiliation", "", false, false], [3, 5, 33, 34, "general-affiliation", "", false, false], [3, 5, 36, 36, "general-affiliation", "", false, false], [3, 5, 38, 38, "general-affiliation", "", false, false], [3, 5, 40, 40, "general-affiliation", "", false, false], [3, 5, 42, 42, "general-affiliation", "", false, false], [3, 5, 44, 44, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["As", "aplica\u00e7\u00f5es", "de", "aquisi\u00e7\u00e3o", "de", "dados", "s\u00e3o", "geralmente", "controladas", "por", "programas", "de", "software", "desenvolvidos", "utilizando", "v\u00e1rias", "linguagens", "de", "programa\u00e7\u00e3o", "de", "prop\u00f3sito", "geral", "como", "Assembly", ",", "BASIC", ",", "C", ",", "C", "+", "+", ",", "C", "#", ",", "Fortran", ",", "Java", ",", "LabVIEW", ",", "Lisp", ",", "Pascal", ",", "etc", "."], "sentence-detokenized": "As aplica\u00e7\u00f5es de aquisi\u00e7\u00e3o de dados s\u00e3o geralmente controladas por programas de software desenvolvidos utilizando v\u00e1rias linguagens de programa\u00e7\u00e3o de prop\u00f3sito geral como Assembly, BASIC, C, C + +, C #, Fortran, Java, LabVIEW, Lisp, Pascal, etc.", "token2charspan": [[0, 2], [3, 13], [14, 16], [17, 26], [27, 29], [30, 35], [36, 39], [40, 50], [51, 62], [63, 66], [67, 76], [77, 79], [80, 88], [89, 102], [103, 113], [114, 120], [121, 131], [132, 134], [135, 146], [147, 149], [150, 159], [160, 165], [166, 170], [171, 179], [179, 180], [181, 186], [186, 187], [188, 189], [189, 190], [191, 192], [193, 194], [195, 196], [196, 197], [198, 199], [200, 201], [201, 202], [203, 210], [210, 211], [212, 216], [216, 217], [218, 225], [225, 226], [227, 231], [231, 232], [233, 239], [239, 240], [241, 244], [244, 245]]}
{"doc_key": "ai-test-173", "ner": [[3, 4, "organisation"], [8, 9, "product"], [11, 12, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 3, 4, "artifact", "", false, false], [8, 9, 11, 12, "physical", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Em", "2003", ",", "a", "Honda", "lan\u00e7ou", "seu", "an\u00fancio", "da", "Cog", "no", "Reino", "Unido", "e", "na", "Internet", "."], "sentence-detokenized": "Em 2003, a Honda lan\u00e7ou seu an\u00fancio da Cog no Reino Unido e na Internet.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 16], [17, 23], [24, 27], [28, 35], [36, 38], [39, 42], [43, 45], [46, 51], [52, 57], [58, 59], [60, 62], [63, 71], [71, 72]]}
{"doc_key": "ai-test-174", "ner": [[1, 4, "conference"], [6, 7, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 4, 6, 7, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "Associa\u00e7\u00e3o", "para", "Lingu\u00edstica", "Computacional", "define", "ling\u00fc\u00edstica", "computacional", "como", ":"], "sentence-detokenized": "A Associa\u00e7\u00e3o para Lingu\u00edstica Computacional define ling\u00fc\u00edstica computacional como:", "token2charspan": [[0, 1], [2, 12], [13, 17], [18, 29], [30, 43], [44, 50], [51, 62], [63, 76], [77, 81], [81, 82]]}
{"doc_key": "ai-test-175", "ner": [[0, 4, "algorithm"], [10, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 4, 10, 14, "related-to", "calculates", false, false]], "relations_mapping_to_source": [0], "sentence": ["Algoritmos", "de", "maximiza\u00e7\u00e3o", "de", "expectativa", "podem", "ser", "empregados", "para", "calcular", "estimativas", "aproximadas", "de", "m\u00e1xima", "probabilidade", "de", "par\u00e2metros", "desconhecidos", "de", "espa\u00e7o", "de", "estado", "dentro", "de", "filtros", "e", "suavizantes", "de", "varia\u00e7\u00e3o", "m\u00ednima", "."], "sentence-detokenized": "Algoritmos de maximiza\u00e7\u00e3o de expectativa podem ser empregados para calcular estimativas aproximadas de m\u00e1xima probabilidade de par\u00e2metros desconhecidos de espa\u00e7o de estado dentro de filtros e suavizantes de varia\u00e7\u00e3o m\u00ednima.", "token2charspan": [[0, 10], [11, 13], [14, 25], [26, 28], [29, 40], [41, 46], [47, 50], [51, 61], [62, 66], [67, 75], [76, 87], [88, 99], [100, 102], [103, 109], [110, 123], [124, 126], [127, 137], [138, 151], [152, 154], [155, 161], [162, 164], [165, 171], [172, 178], [179, 181], [182, 189], [190, 191], [192, 203], [204, 206], [207, 215], [216, 222], [222, 223]]}
{"doc_key": "ai-test-176", "ner": [[6, 7, "misc"], [8, 10, "person"], [12, 13, "person"], [15, 16, "person"], [19, 21, "misc"], [22, 23, "person"], [27, 28, "person"], [32, 32, "person"], [34, 35, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[8, 10, 6, 7, "role", "actor_in", false, false], [12, 13, 6, 7, "role", "actor_in", false, false], [15, 16, 6, 7, "role", "actor_in", false, false], [22, 23, 19, 21, "role", "model_for", false, false], [32, 32, 34, 35, "social", "family", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Entre", "os", "correspondentes", "estavam", "as", "ex-atrizes", "do", "Baywatch", "Donna", "D'", "Errico", ",", "Carmen", "Electra", "e", "Traci", "Bingham", ",", "a", "ex-jogadora", "da", "Playboy", "Heidi", "Mark", ",", "o", "comediante", "Arj", "Barker", "e", "g\u00eameos", "id\u00eanticos", "Randy", "e", "Jason", "Sklar", "."], "sentence-detokenized": "Entre os correspondentes estavam as ex-atrizes do Baywatch Donna D'Errico, Carmen Electra e Traci Bingham, a ex-jogadora da Playboy Heidi Mark, o comediante Arj Barker e g\u00eameos id\u00eanticos Randy e Jason Sklar.", "token2charspan": [[0, 5], [6, 8], [9, 24], [25, 32], [33, 35], [36, 46], [47, 49], [50, 58], [59, 64], [65, 67], [67, 73], [73, 74], [75, 81], [82, 89], [90, 91], [92, 97], [98, 105], [105, 106], [107, 108], [109, 120], [121, 123], [124, 131], [132, 137], [138, 142], [142, 143], [144, 145], [146, 156], [157, 160], [161, 167], [168, 169], [170, 176], [177, 186], [187, 192], [193, 194], [195, 200], [201, 206], [206, 207]]}
{"doc_key": "ai-test-177", "ner": [[7, 9, "task"], [11, 11, "task"], [18, 20, "product"], [23, 25, "task"], [27, 27, "task"], [34, 35, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 7, 9, "named", "", false, false], [18, 20, 7, 9, "general-affiliation", "", false, false], [27, 27, 23, 25, "named", "", false, false], [34, 35, 23, 25, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["\u00c9", "comumente", "usado", "para", "gerar", "representa\u00e7\u00f5es", "para", "reconhecimento", "de", "fala", "(", "ASR", ")", ",", "por", "exemplo", ",", "o", "sistema", "CMU", "Sphinx", ",", "e", "s\u00edntese", "de", "fala", "(", "TTS", ")", ",", "por", "exemplo", ",", "o", "sistema", "Festival", "."], "sentence-detokenized": "\u00c9 comumente usado para gerar representa\u00e7\u00f5es para reconhecimento de fala (ASR), por exemplo, o sistema CMU Sphinx, e s\u00edntese de fala (TTS), por exemplo, o sistema Festival.", "token2charspan": [[0, 1], [2, 11], [12, 17], [18, 22], [23, 28], [29, 43], [44, 48], [49, 63], [64, 66], [67, 71], [72, 73], [73, 76], [76, 77], [77, 78], [79, 82], [83, 90], [90, 91], [92, 93], [94, 101], [102, 105], [106, 112], [112, 113], [114, 115], [116, 123], [124, 126], [127, 131], [132, 133], [133, 136], [136, 137], [137, 138], [139, 142], [143, 150], [150, 151], [152, 153], [154, 161], [162, 170], [170, 171]]}
{"doc_key": "ai-test-178", "ner": [[0, 0, "metrics"], [2, 4, "metrics"], [6, 6, "metrics"], [12, 12, "metrics"], [26, 27, "metrics"], [29, 29, "metrics"], [40, 41, "metrics"], [43, 43, "metrics"], [45, 47, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 4, 0, 0, "named", "", false, false], [6, 6, 2, 4, "named", "", false, false], [12, 12, 0, 0, "named", "", false, false], [29, 29, 26, 27, "named", "", false, false], [43, 43, 40, 41, "named", "", false, false], [45, 47, 40, 41, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sensibilidade", "ou", "TRUE", "Positive", "Rate", "(", "TPR", ")", ",", "tamb\u00e9m", "conhecida", "como", "recall", ",", "\u00e9", "a", "propor\u00e7\u00e3o", "de", "pessoas", "que", "testaram", "positivo", "e", "s\u00e3o", "positivas", "(", "TRUE", "Positive", ",", "TP", ")", "de", "todas", "as", "pessoas", "que", "realmente", "s\u00e3o", "positivas", "(", "Condition", "Positive", ",", "CP", "=", "TP", "+", "FN", ")", "."], "sentence-detokenized": "Sensibilidade ou TRUE Positive Rate (TPR), tamb\u00e9m conhecida como recall, \u00e9 a propor\u00e7\u00e3o de pessoas que testaram positivo e s\u00e3o positivas (TRUE Positive, TP) de todas as pessoas que realmente s\u00e3o positivas (Condition Positive, CP = TP + FN).", "token2charspan": [[0, 13], [14, 16], [17, 21], [22, 30], [31, 35], [36, 37], [37, 40], [40, 41], [41, 42], [43, 49], [50, 59], [60, 64], [65, 71], [71, 72], [73, 74], [75, 76], [77, 86], [87, 89], [90, 97], [98, 101], [102, 110], [111, 119], [120, 121], [122, 125], [126, 135], [136, 137], [137, 141], [142, 150], [150, 151], [152, 154], [154, 155], [156, 158], [159, 164], [165, 167], [168, 175], [176, 179], [180, 189], [190, 193], [194, 203], [204, 205], [205, 214], [215, 223], [223, 224], [225, 227], [228, 229], [230, 232], [233, 234], [235, 237], [237, 238], [238, 239]]}
{"doc_key": "ai-test-179", "ner": [[4, 6, "task"], [14, 14, "conference"], [16, 17, "conference"], [19, 19, "conference"], [21, 21, "conference"], [23, 23, "conference"], [27, 28, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[14, 14, 4, 6, "topic", "", false, false], [16, 17, 4, 6, "topic", "", false, false], [19, 19, 4, 6, "topic", "", false, false], [21, 21, 4, 6, "topic", "", false, false], [23, 23, 4, 6, "topic", "", false, false], [27, 28, 4, 6, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["As", "confer\u00eancias", "populares", "de", "reconhecimento", "de", "discursos", "realizadas", "a", "cada", "ano", "ou", "duas", "incluem", "SpeechTEK", "e", "SpeechTEK", "Europe", ",", "ICASSP", ",", "Interspeech", "/", "Eurospeech", ",", "e", "o", "IEEE", "ASRU", "."], "sentence-detokenized": "As confer\u00eancias populares de reconhecimento de discursos realizadas a cada ano ou duas incluem SpeechTEK e SpeechTEK Europe, ICASSP, Interspeech / Eurospeech, e o IEEE ASRU.", "token2charspan": [[0, 2], [3, 15], [16, 25], [26, 28], [29, 43], [44, 46], [47, 56], [57, 67], [68, 69], [70, 74], [75, 78], [79, 81], [82, 86], [87, 94], [95, 104], [105, 106], [107, 116], [117, 123], [123, 124], [125, 131], [131, 132], [133, 144], [145, 146], [147, 157], [157, 158], [159, 160], [161, 162], [163, 167], [168, 172], [172, 173]]}
{"doc_key": "ai-test-180", "ner": [[0, 1, "researcher"], [4, 4, "researcher"], [17, 18, "product"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 22, 0, 1, "artifact", "", false, false], [22, 22, 4, 4, "artifact", "", false, false], [22, 22, 17, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "Devol", "colaborou", "com", "Engelberger", ",", "que", "foi", "presidente", "da", "empresa", ",", "para", "projetar", "e", "produzir", "um", "rob\u00f4", "industrial", "sob", "a", "marca", "Unimate", "."], "sentence-detokenized": "A Devol colaborou com Engelberger, que foi presidente da empresa, para projetar e produzir um rob\u00f4 industrial sob a marca Unimate.", "token2charspan": [[0, 1], [2, 7], [8, 17], [18, 21], [22, 33], [33, 34], [35, 38], [39, 42], [43, 53], [54, 56], [57, 64], [64, 65], [66, 70], [71, 79], [80, 81], [82, 90], [91, 93], [94, 98], [99, 109], [110, 113], [114, 115], [116, 121], [122, 129], [129, 130]]}
{"doc_key": "ai-test-181", "ner": [[1, 3, "algorithm"], [5, 5, "algorithm"], [9, 11, "algorithm"], [22, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 3, 9, 11, "general-affiliation", "", false, false], [5, 5, 1, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Um", "modelo", "Markov", "oculto", "(", "HMM", ")", "\u00e9", "um", "modelo", "Markov", "estat\u00edstico", "no", "qual", "o", "sistema", "sendo", "modelado", "\u00e9", "assumido", "como", "um", "processo", "Markov", "com", "estados", "n\u00e3o", "observados", "(", "ocultos", ")", "."], "sentence-detokenized": "Um modelo Markov oculto (HMM) \u00e9 um modelo Markov estat\u00edstico no qual o sistema sendo modelado \u00e9 assumido como um processo Markov com estados n\u00e3o observados (ocultos).", "token2charspan": [[0, 2], [3, 9], [10, 16], [17, 23], [24, 25], [25, 28], [28, 29], [30, 31], [32, 34], [35, 41], [42, 48], [49, 60], [61, 63], [64, 68], [69, 70], [71, 78], [79, 84], [85, 93], [94, 95], [96, 104], [105, 109], [110, 112], [113, 121], [122, 128], [129, 132], [133, 140], [141, 144], [145, 155], [156, 157], [157, 164], [164, 165], [165, 166]]}
{"doc_key": "ai-test-182", "ner": [[16, 18, "metrics"], [24, 24, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Esta", "propriedade", ",", "indesej\u00e1vel", "em", "muitas", "aplica\u00e7\u00f5es", ",", "levou", "os", "pesquisadores", "a", "utilizar", "alternativas", "como", "o", "erro", "m\u00e9dio", "absoluto", ",", "ou", "aquelas", "baseadas", "na", "mediana", "."], "sentence-detokenized": "Esta propriedade, indesej\u00e1vel em muitas aplica\u00e7\u00f5es, levou os pesquisadores a utilizar alternativas como o erro m\u00e9dio absoluto, ou aquelas baseadas na mediana.", "token2charspan": [[0, 4], [5, 16], [16, 17], [18, 29], [30, 32], [33, 39], [40, 50], [50, 51], [52, 57], [58, 60], [61, 74], [75, 76], [77, 85], [86, 98], [99, 103], [104, 105], [106, 110], [111, 116], [117, 125], [125, 126], [127, 129], [130, 137], [138, 146], [147, 149], [150, 157], [157, 158]]}
{"doc_key": "ai-test-183", "ner": [[19, 21, "algorithm"], [27, 29, "field"], [32, 36, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 21, 27, 29, "part-of", "", false, false], [19, 21, 32, 36, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Tal", "seq\u00fc\u00eancia", "(", "que", "depende", "do", "resultado", "da", "investiga\u00e7\u00e3o", "dos", "atributos", "anteriores", "em", "cada", "etapa", ")", "\u00e9", "chamada", "de", "\u00e1rvore", "de", "decis\u00e3o", "e", "aplicada", "na", "\u00e1rea", "de", "aprendizagem", "de", "m\u00e1quinas", "conhecida", "como", "aprendizagem", "em", "\u00e1rvore", "de", "decis\u00e3o", "."], "sentence-detokenized": "Tal seq\u00fc\u00eancia (que depende do resultado da investiga\u00e7\u00e3o dos atributos anteriores em cada etapa) \u00e9 chamada de \u00e1rvore de decis\u00e3o e aplicada na \u00e1rea de aprendizagem de m\u00e1quinas conhecida como aprendizagem em \u00e1rvore de decis\u00e3o.", "token2charspan": [[0, 3], [4, 13], [14, 15], [15, 18], [19, 26], [27, 29], [30, 39], [40, 42], [43, 55], [56, 59], [60, 69], [70, 80], [81, 83], [84, 88], [89, 94], [94, 95], [96, 97], [98, 105], [106, 108], [109, 115], [116, 118], [119, 126], [127, 128], [129, 137], [138, 140], [141, 145], [146, 148], [149, 161], [162, 164], [165, 173], [174, 183], [184, 188], [189, 201], [202, 204], [205, 211], [212, 214], [215, 222], [222, 223]]}
{"doc_key": "ai-test-184", "ner": [[2, 4, "task"], [7, 7, "algorithm"], [22, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 4, 7, 7, "compare", "", false, false], [22, 24, 7, 7, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Como", "na", "an\u00e1lise", "de", "fatores", ",", "a", "LCA", "tamb\u00e9m", "pode", "ser", "usada", "para", "classificar", "os", "casos", "de", "acordo", "com", "sua", "classe", "de", "m\u00e1xima", "probabilidade", "de", "associa\u00e7\u00e3o", "."], "sentence-detokenized": "Como na an\u00e1lise de fatores, a LCA tamb\u00e9m pode ser usada para classificar os casos de acordo com sua classe de m\u00e1xima probabilidade de associa\u00e7\u00e3o.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 26], [26, 27], [28, 29], [30, 33], [34, 40], [41, 45], [46, 49], [50, 55], [56, 60], [61, 72], [73, 75], [76, 81], [82, 84], [85, 91], [92, 95], [96, 99], [100, 106], [107, 109], [110, 116], [117, 130], [131, 133], [134, 144], [144, 145]]}
{"doc_key": "ai-test-185", "ner": [[0, 3, "algorithm"], [11, 13, "metrics"], [15, 15, "metrics"], [7, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 11, 13, "usage", "", false, false], [11, 13, 7, 10, "related-to", "", false, false], [15, 15, 11, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["As", "redes", "neurais", "supervisionadas", "que", "usam", "uma", "fun\u00e7\u00e3o", "de", "custo", "de", "erro", "quadr\u00e1tico", "m\u00e9dio", "(", "MSE", ")", "podem", "usar", "m\u00e9todos", "estat\u00edsticos", "formais", "para", "determinar", "a", "confian\u00e7a", "do", "modelo", "treinado", "."], "sentence-detokenized": "As redes neurais supervisionadas que usam uma fun\u00e7\u00e3o de custo de erro quadr\u00e1tico m\u00e9dio (MSE) podem usar m\u00e9todos estat\u00edsticos formais para determinar a confian\u00e7a do modelo treinado.", "token2charspan": [[0, 2], [3, 8], [9, 16], [17, 32], [33, 36], [37, 41], [42, 45], [46, 52], [53, 55], [56, 61], [62, 64], [65, 69], [70, 80], [81, 86], [87, 88], [88, 91], [91, 92], [93, 98], [99, 103], [104, 111], [112, 124], [125, 132], [133, 137], [138, 148], [149, 150], [151, 160], [161, 163], [164, 170], [171, 179], [179, 180]]}
{"doc_key": "ai-test-186", "ner": [[15, 17, "algorithm"], [20, 24, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 17, 20, 24, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Isto", "pode", "ser", "expresso", "diretamente", "como", "um", "programa", "linear", ",", "mas", "tamb\u00e9m", "\u00e9", "equivalente", "\u00e0", "regulariza\u00e7\u00e3o", "de", "Tikhonov", "com", "a", "fun\u00e7\u00e3o", "de", "perda", "de", "dobradi\u00e7as", ",", "VHV", "matem\u00e1tica", "(", "f", "(", "x", ")", ",", "y", ")", "=\\", "max", "(", "0", ",", "1", "-", "yf", "(", "x", ")", ")", "/", "matem\u00e1tica", ":"], "sentence-detokenized": "Isto pode ser expresso diretamente como um programa linear, mas tamb\u00e9m \u00e9 equivalente \u00e0 regulariza\u00e7\u00e3o de Tikhonov com a fun\u00e7\u00e3o de perda de dobradi\u00e7as, VHV matem\u00e1tica (f (x), y) =\\ max (0, 1 - yf (x)) / matem\u00e1tica:", "token2charspan": [[0, 4], [5, 9], [10, 13], [14, 22], [23, 34], [35, 39], [40, 42], [43, 51], [52, 58], [58, 59], [60, 63], [64, 70], [71, 72], [73, 84], [85, 86], [87, 100], [101, 103], [104, 112], [113, 116], [117, 118], [119, 125], [126, 128], [129, 134], [135, 137], [138, 148], [148, 149], [150, 153], [154, 164], [165, 166], [166, 167], [168, 169], [169, 170], [170, 171], [171, 172], [173, 174], [174, 175], [176, 178], [179, 182], [183, 184], [184, 185], [185, 186], [187, 188], [189, 190], [191, 193], [194, 195], [195, 196], [196, 197], [197, 198], [199, 200], [201, 211], [211, 212]]}
{"doc_key": "ai-test-187", "ner": [[9, 9, "researcher"], [14, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "seguinte", "t\u00e9cnica", "foi", "descrita", "no", "papel", "original", "de", "Breiman", "e", "est\u00e1", "implementada", "no", "pacote", "R", "randomForest", "."], "sentence-detokenized": "A seguinte t\u00e9cnica foi descrita no papel original de Breiman e est\u00e1 implementada no pacote R randomForest.", "token2charspan": [[0, 1], [2, 10], [11, 18], [19, 22], [23, 31], [32, 34], [35, 40], [41, 49], [50, 52], [53, 60], [61, 62], [63, 67], [68, 80], [81, 83], [84, 90], [91, 92], [93, 105], [105, 106]]}
{"doc_key": "ai-test-188", "ner": [[10, 10, "metrics"], [41, 41, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["As", "medidas", "tradicionais", "de", "qualidade", "de", "imagem", ",", "como", "a", "PSNR", ",", "s\u00e3o", "normalmente", "realizadas", "em", "imagens", "de", "resolu\u00e7\u00e3o", "fixa", "e", "n\u00e3o", "levam", "em", "conta", "alguns", "aspectos", "do", "sistema", "visual", "humano", ",", "como", "a", "mudan\u00e7a", "na", "resolu\u00e7\u00e3o", "espacial", "em", "toda", "a", "retina", "."], "sentence-detokenized": "As medidas tradicionais de qualidade de imagem, como a PSNR, s\u00e3o normalmente realizadas em imagens de resolu\u00e7\u00e3o fixa e n\u00e3o levam em conta alguns aspectos do sistema visual humano, como a mudan\u00e7a na resolu\u00e7\u00e3o espacial em toda a retina.", "token2charspan": [[0, 2], [3, 10], [11, 23], [24, 26], [27, 36], [37, 39], [40, 46], [46, 47], [48, 52], [53, 54], [55, 59], [59, 60], [61, 64], [65, 76], [77, 87], [88, 90], [91, 98], [99, 101], [102, 111], [112, 116], [117, 118], [119, 122], [123, 128], [129, 131], [132, 137], [138, 144], [145, 153], [154, 156], [157, 164], [165, 171], [172, 178], [178, 179], [180, 184], [185, 186], [187, 194], [195, 197], [198, 207], [208, 216], [217, 219], [220, 224], [225, 226], [227, 233], [233, 234]]}
{"doc_key": "ai-test-189", "ner": [[0, 1, "person"], [3, 4, "person"], [6, 7, "person"], [14, 15, "person"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 16, 17, "role", "", false, false], [3, 4, 16, 17, "role", "", false, false], [6, 7, 16, 17, "role", "", false, false], [16, 17, 14, 15, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["John", "Ireland", ",", "Joanne", "Dru", "e", "Macdonald", "Carey", "estrelaram", "na", "produ\u00e7\u00e3o", "de", "cores", "de", "Jack", "Broder", "Hannah", "Lee", ",", "que", "estreou", "em", "19", "de", "junho", "de", "1953", "."], "sentence-detokenized": "John Ireland, Joanne Dru e Macdonald Carey estrelaram na produ\u00e7\u00e3o de cores de Jack Broder Hannah Lee, que estreou em 19 de junho de 1953.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 20], [21, 24], [25, 26], [27, 36], [37, 42], [43, 53], [54, 56], [57, 65], [66, 68], [69, 74], [75, 77], [78, 82], [83, 89], [90, 96], [97, 100], [100, 101], [102, 105], [106, 113], [114, 116], [117, 119], [120, 122], [123, 128], [129, 131], [132, 136], [136, 137]]}
{"doc_key": "ai-test-190", "ner": [[5, 7, "task"], [14, 16, "field"], [23, 23, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 7, 14, 16, "usage", "", false, false], [23, 23, 14, 16, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Esse", "processo", "\u00e9", "chamado", "de", "registro", "de", "imagem", ",", "e", "utiliza", "diferentes", "m\u00e9todos", "de", "vis\u00e3o", "por", "computador", ",", "a", "maioria", "deles", "relacionados", "ao", "rastreamento", "."], "sentence-detokenized": "Esse processo \u00e9 chamado de registro de imagem, e utiliza diferentes m\u00e9todos de vis\u00e3o por computador, a maioria deles relacionados ao rastreamento.", "token2charspan": [[0, 4], [5, 13], [14, 15], [16, 23], [24, 26], [27, 35], [36, 38], [39, 45], [45, 46], [47, 48], [49, 56], [57, 67], [68, 75], [76, 78], [79, 84], [85, 88], [89, 99], [99, 100], [101, 102], [103, 110], [111, 116], [117, 129], [130, 132], [133, 145], [145, 146]]}
{"doc_key": "ai-test-191", "ner": [[17, 19, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Agora", "vamos", "come\u00e7ar", "a", "explicar", "as", "diferentes", "rela\u00e7\u00f5es", "poss\u00edveis", "entre", "o", "resultado", "previsto", "e", "o", "real", ":", "Matriz", "de", "confus\u00f5es"], "sentence-detokenized": "Agora vamos come\u00e7ar a explicar as diferentes rela\u00e7\u00f5es poss\u00edveis entre o resultado previsto e o real: Matriz de confus\u00f5es", "token2charspan": [[0, 5], [6, 11], [12, 19], [20, 21], [22, 30], [31, 33], [34, 44], [45, 53], [54, 63], [64, 69], [70, 71], [72, 81], [82, 90], [91, 92], [93, 94], [95, 99], [99, 100], [101, 107], [108, 110], [111, 120]]}
{"doc_key": "ai-test-192", "ner": [[8, 8, "product"], [1, 7, "misc"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 1, 7, "part-of", "", false, false], [8, 8, 1, 7, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "caixa", "de", "ferramentas", "de", "processamento", "de", "fala", "VOICEBOX", "para", "MATLAB", "implementa", "a", "convers\u00e3o", "e", "seu", "inverso", "como", ":"], "sentence-detokenized": "A caixa de ferramentas de processamento de fala VOICEBOX para MATLAB implementa a convers\u00e3o e seu inverso como:", "token2charspan": [[0, 1], [2, 7], [8, 10], [11, 22], [23, 25], [26, 39], [40, 42], [43, 47], [48, 56], [57, 61], [62, 68], [69, 79], [80, 81], [82, 91], [92, 93], [94, 97], [98, 105], [106, 110], [110, 111]]}
{"doc_key": "ai-test-193", "ner": [[0, 0, "programlang"], [9, 10, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 9, 10, "general-affiliation", "", false, false], [0, 0, 13, 14, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolog", "\u00e9", "uma", "linguagem", "de", "programa\u00e7\u00e3o", "l\u00f3gica", "associada", "\u00e0", "intelig\u00eancia", "artificial", "e", "\u00e0", "ling\u00fc\u00edstica", "computacional", "."], "sentence-detokenized": "Prolog \u00e9 uma linguagem de programa\u00e7\u00e3o l\u00f3gica associada \u00e0 intelig\u00eancia artificial e \u00e0 ling\u00fc\u00edstica computacional.", "token2charspan": [[0, 6], [7, 8], [9, 12], [13, 22], [23, 25], [26, 37], [38, 44], [45, 54], [55, 56], [57, 69], [70, 80], [81, 82], [83, 84], [85, 96], [97, 110], [110, 111]]}
{"doc_key": "ai-test-194", "ner": [[0, 0, "researcher"], [8, 8, "field"], [11, 11, "field"], [17, 20, "organisation"], [23, 26, "organisation"], [29, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 8, 8, "related-to", "works_with_topic", false, false], [0, 0, 11, 11, "related-to", "works_with_topic", false, false], [0, 0, 17, 20, "role", "", false, false], [0, 0, 23, 26, "role", "", false, false], [0, 0, 29, 32, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Milner", "recebeu", "in\u00fameros", "pr\u00eamios", "por", "suas", "contribui\u00e7\u00f5es", "\u00e0", "neuroci\u00eancia", "e", "\u00e0", "psicologia", ",", "incluindo", "a", "associa\u00e7\u00e3o", "\u00e0", "Royal", "Society", "of", "London", ",", "\u00e0", "Royal", "Society", "of", "Canada", "e", "\u00e0", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Milner recebeu in\u00fameros pr\u00eamios por suas contribui\u00e7\u00f5es \u00e0 neuroci\u00eancia e \u00e0 psicologia, incluindo a associa\u00e7\u00e3o \u00e0 Royal Society of London, \u00e0 Royal Society of Canada e \u00e0 National Academy of Sciences.", "token2charspan": [[0, 6], [7, 14], [15, 23], [24, 31], [32, 35], [36, 40], [41, 54], [55, 56], [57, 69], [70, 71], [72, 73], [74, 84], [84, 85], [86, 95], [96, 97], [98, 108], [109, 110], [111, 116], [117, 124], [125, 127], [128, 134], [134, 135], [136, 137], [138, 143], [144, 151], [152, 154], [155, 161], [162, 163], [164, 165], [166, 174], [175, 182], [183, 185], [186, 194], [194, 195]]}
{"doc_key": "ai-test-195", "ner": [[11, 13, "field"], [17, 19, "task"], [21, 23, "task"], [25, 27, "task"], [29, 31, "task"], [33, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[17, 19, 11, 13, "part-of", "task_part_of_field", false, false], [21, 23, 11, 13, "part-of", "task_part_of_field", false, false], [25, 27, 11, 13, "part-of", "task_part_of_field", false, false], [29, 31, 11, 13, "part-of", "task_part_of_field", false, false], [33, 33, 11, 13, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Ao", "combinar", "estes", "operadores", "pode-se", "obter", "algoritmos", "para", "muitas", "tarefas", "de", "processamento", "de", "imagem", ",", "tais", "como", "extra\u00e7\u00e3o", "de", "caracter\u00edsticas", ",", "segmenta\u00e7\u00e3o", "de", "imagem", ",", "nitidez", "de", "imagem", ",", "filtragem", "de", "imagem", "e", "classifica\u00e7\u00e3o", "."], "sentence-detokenized": "Ao combinar estes operadores pode-se obter algoritmos para muitas tarefas de processamento de imagem, tais como extra\u00e7\u00e3o de caracter\u00edsticas, segmenta\u00e7\u00e3o de imagem, nitidez de imagem, filtragem de imagem e classifica\u00e7\u00e3o.", "token2charspan": [[0, 2], [3, 11], [12, 17], [18, 28], [29, 36], [37, 42], [43, 53], [54, 58], [59, 65], [66, 73], [74, 76], [77, 90], [91, 93], [94, 100], [100, 101], [102, 106], [107, 111], [112, 120], [121, 123], [124, 139], [139, 140], [141, 152], [153, 155], [156, 162], [162, 163], [164, 171], [172, 174], [175, 181], [181, 182], [183, 192], [193, 195], [196, 202], [203, 204], [205, 218], [218, 219]]}
{"doc_key": "ai-test-196", "ner": [[7, 9, "university"], [17, 20, "organisation"], [22, 23, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 23, 17, 20, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Desde", "2017", ",", "ele", "\u00e9", "professor", "no", "Coll\u00e8ge", "de", "France", "e", ",", "desde", "1989", ",", "diretor", "da", "Unidade", "562", "do", "INSERM", ",", "Cognitive", "Neuroimaging", "."], "sentence-detokenized": "Desde 2017, ele \u00e9 professor no Coll\u00e8ge de France e, desde 1989, diretor da Unidade 562 do INSERM, Cognitive Neuroimaging.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 15], [16, 17], [18, 27], [28, 30], [31, 38], [39, 41], [42, 48], [49, 50], [50, 51], [52, 57], [58, 62], [62, 63], [64, 71], [72, 74], [75, 82], [83, 86], [87, 89], [90, 96], [96, 97], [98, 107], [108, 120], [120, 121]]}
{"doc_key": "ai-test-197", "ner": [[10, 13, "algorithm"], [15, 18, "algorithm"], [25, 25, "algorithm"], [27, 35, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[25, 25, 27, 35, "temporal", "", false, true]], "relations_mapping_to_source": [0], "sentence": ["H\u00e1", "muitas", "abordagens", "para", "aprender", "estas", "incorpora\u00e7\u00f5es", ",", "notadamente", "usando", "estruturas", "de", "agrupamento", "Bayesianas", "ou", "estruturas", "baseadas", "em", "energia", "e", ",", "mais", "recentemente", ",", "a", "TransE", "(", "Confer\u00eancia", "sobre", "Sistemas", "de", "Processamento", "de", "Informa\u00e7\u00f5es", "Neurais", "2013", ")", "."], "sentence-detokenized": "H\u00e1 muitas abordagens para aprender estas incorpora\u00e7\u00f5es, notadamente usando estruturas de agrupamento Bayesianas ou estruturas baseadas em energia e, mais recentemente, a TransE (Confer\u00eancia sobre Sistemas de Processamento de Informa\u00e7\u00f5es Neurais 2013).", "token2charspan": [[0, 2], [3, 9], [10, 20], [21, 25], [26, 34], [35, 40], [41, 54], [54, 55], [56, 67], [68, 74], [75, 85], [86, 88], [89, 100], [101, 111], [112, 114], [115, 125], [126, 134], [135, 137], [138, 145], [146, 147], [147, 148], [149, 153], [154, 166], [166, 167], [168, 169], [170, 176], [177, 178], [178, 189], [190, 195], [196, 204], [205, 207], [208, 221], [222, 224], [225, 236], [237, 244], [245, 249], [249, 250], [250, 251]]}
{"doc_key": "ai-test-198", "ner": [[4, 8, "metrics"], [10, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 12, 4, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["\u00c9", "uma", "alternativa", "\u00e0", "taxa", "de", "erro", "do", "Word", "(", "Word", "Error", "Rate", ")", "usada", "em", "v\u00e1rios", "pa\u00edses", "."], "sentence-detokenized": "\u00c9 uma alternativa \u00e0 taxa de erro do Word (Word Error Rate) usada em v\u00e1rios pa\u00edses.", "token2charspan": [[0, 1], [2, 5], [6, 17], [18, 19], [20, 24], [25, 27], [28, 32], [33, 35], [36, 40], [41, 42], [42, 46], [47, 52], [53, 57], [57, 58], [59, 64], [65, 67], [68, 74], [75, 81], [81, 82]]}
{"doc_key": "ai-test-199", "ner": [[0, 1, "algorithm"], [12, 14, "task"], [16, 18, "task"], [20, 21, "task"], [23, 26, "task"], [29, 33, "task"], [35, 36, "task"], [54, 54, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[12, 14, 0, 1, "usage", "", false, false], [16, 18, 0, 1, "usage", "", false, false], [20, 21, 0, 1, "usage", "", false, false], [23, 26, 0, 1, "usage", "", false, false], [29, 33, 0, 1, "usage", "", false, false], [35, 36, 0, 1, "usage", "", false, false], [54, 54, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["As", "ANNs", "t\u00eam", "sido", "utilizadas", "em", "uma", "variedade", "de", "tarefas", ",", "incluindo", "vis\u00e3o", "por", "computador", ",", "reconhecimento", "da", "fala", ",", "tradu\u00e7\u00e3o", "autom\u00e1tica", ",", "filtragem", "de", "redes", "sociais", ",", "jogos", "de", "tabuleiro", "e", "de", "v\u00eddeo", ",", "diagn\u00f3stico", "m\u00e9dico", ",", "e", "at\u00e9", "mesmo", "em", "atividades", "que", "tradicionalmente", "t\u00eam", "sido", "consideradas", "como", "reservadas", "aos", "humanos", ",", "como", "pintura", "."], "sentence-detokenized": "As ANNs t\u00eam sido utilizadas em uma variedade de tarefas, incluindo vis\u00e3o por computador, reconhecimento da fala, tradu\u00e7\u00e3o autom\u00e1tica, filtragem de redes sociais, jogos de tabuleiro e de v\u00eddeo, diagn\u00f3stico m\u00e9dico, e at\u00e9 mesmo em atividades que tradicionalmente t\u00eam sido consideradas como reservadas aos humanos, como pintura.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 16], [17, 27], [28, 30], [31, 34], [35, 44], [45, 47], [48, 55], [55, 56], [57, 66], [67, 72], [73, 76], [77, 87], [87, 88], [89, 103], [104, 106], [107, 111], [111, 112], [113, 121], [122, 132], [132, 133], [134, 143], [144, 146], [147, 152], [153, 160], [160, 161], [162, 167], [168, 170], [171, 180], [181, 182], [183, 185], [186, 191], [191, 192], [193, 204], [205, 211], [211, 212], [213, 214], [215, 218], [219, 224], [225, 227], [228, 238], [239, 242], [243, 259], [260, 263], [264, 268], [269, 281], [282, 286], [287, 297], [298, 301], [302, 309], [309, 310], [311, 315], [316, 323], [323, 324]]}
{"doc_key": "ai-test-200", "ner": [[0, 4, "product"], [6, 6, "product"], [22, 33, "field"], [35, 35, "field"], [39, 39, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 22, 33, "related-to", "", false, false], [0, 4, 39, 39, "general-affiliation", "", false, false], [6, 6, 0, 4, "named", "", false, false], [35, 35, 22, 33, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["O", "Modular", "Audio", "Recognition", "Framework", "(", "MARF", ")", "\u00e9", "uma", "plataforma", "de", "pesquisa", "de", "c\u00f3digo", "aberto", "e", "uma", "cole\u00e7\u00e3o", "de", "algoritmos", "de", "processamento", "de", "voz", ",", "som", ",", "fala", ",", "texto", "e", "linguagem", "natural", "(", "PNL", ")", "escritos", "em", "Java", "e", "dispostos", "em", "uma", "estrutura", "modular", "e", "extens\u00edvel", "que", "tenta", "facilitar", "a", "adi\u00e7\u00e3o", "de", "novos", "algoritmos", "."], "sentence-detokenized": "O Modular Audio Recognition Framework (MARF) \u00e9 uma plataforma de pesquisa de c\u00f3digo aberto e uma cole\u00e7\u00e3o de algoritmos de processamento de voz, som, fala, texto e linguagem natural (PNL) escritos em Java e dispostos em uma estrutura modular e extens\u00edvel que tenta facilitar a adi\u00e7\u00e3o de novos algoritmos.", "token2charspan": [[0, 1], [2, 9], [10, 15], [16, 27], [28, 37], [38, 39], [39, 43], [43, 44], [45, 46], [47, 50], [51, 61], [62, 64], [65, 73], [74, 76], [77, 83], [84, 90], [91, 92], [93, 96], [97, 104], [105, 107], [108, 118], [119, 121], [122, 135], [136, 138], [139, 142], [142, 143], [144, 147], [147, 148], [149, 153], [153, 154], [155, 160], [161, 162], [163, 172], [173, 180], [181, 182], [182, 185], [185, 186], [187, 195], [196, 198], [199, 203], [204, 205], [206, 215], [216, 218], [219, 222], [223, 232], [233, 240], [241, 242], [243, 253], [254, 257], [258, 263], [264, 273], [274, 275], [276, 282], [283, 285], [286, 291], [292, 302], [302, 303]]}
{"doc_key": "ai-test-201", "ner": [[14, 16, "organisation"], [22, 24, "country"], [27, 33, "organisation"], [36, 37, "organisation"], [42, 43, "task"], [65, 71, "organisation"], [62, 64, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[27, 33, 22, 24, "physical", "", false, false], [27, 33, 42, 43, "usage", "", false, false], [27, 33, 65, 71, "named", "", false, false], [36, 37, 22, 24, "physical", "", false, false], [36, 37, 42, 43, "usage", "", false, false], [65, 71, 62, 64, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Em", "2018", ",", "um", "relat\u00f3rio", "da", "organiza\u00e7\u00e3o", "de", "campanha", "pelas", "liberdades", "e", "direitos", "civis", "Big", "Brother", "Watch", "revelou", "que", "duas", "for\u00e7as", "policiais", "do", "Reino", "Unido", ",", "a", "Pol\u00edcia", "do", "Pa\u00eds", "de", "Gales", "do", "Sul", "e", "a", "Pol\u00edcia", "Metropolitana", ",", "estavam", "usando", "o", "reconhecimento", "facial", "ao", "vivo", "em", "eventos", "p\u00fablicos", "e", "em", "espa\u00e7os", "p\u00fablicos", ",", "em", "setembro", "de", "2019", ",", "o", "uso", "do", "reconhecimento", "facial", "pela", "Pol\u00edcia", "do", "Pa\u00eds", "de", "Gales", "do", "Sul", "foi", "considerado", "legal", "."], "sentence-detokenized": "Em 2018, um relat\u00f3rio da organiza\u00e7\u00e3o de campanha pelas liberdades e direitos civis Big Brother Watch revelou que duas for\u00e7as policiais do Reino Unido, a Pol\u00edcia do Pa\u00eds de Gales do Sul e a Pol\u00edcia Metropolitana, estavam usando o reconhecimento facial ao vivo em eventos p\u00fablicos e em espa\u00e7os p\u00fablicos, em setembro de 2019, o uso do reconhecimento facial pela Pol\u00edcia do Pa\u00eds de Gales do Sul foi considerado legal.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 21], [22, 24], [25, 36], [37, 39], [40, 48], [49, 54], [55, 65], [66, 67], [68, 76], [77, 82], [83, 86], [87, 94], [95, 100], [101, 108], [109, 112], [113, 117], [118, 124], [125, 134], [135, 137], [138, 143], [144, 149], [149, 150], [151, 152], [153, 160], [161, 163], [164, 168], [169, 171], [172, 177], [178, 180], [181, 184], [185, 186], [187, 188], [189, 196], [197, 210], [210, 211], [212, 219], [220, 226], [227, 228], [229, 243], [244, 250], [251, 253], [254, 258], [259, 261], [262, 269], [270, 278], [279, 280], [281, 283], [284, 291], [292, 300], [300, 301], [302, 304], [305, 313], [314, 316], [317, 321], [321, 322], [323, 324], [325, 328], [329, 331], [332, 346], [347, 353], [354, 358], [359, 366], [367, 369], [370, 374], [375, 377], [378, 383], [384, 386], [387, 390], [391, 394], [395, 406], [407, 412], [412, 413]]}
{"doc_key": "ai-test-202", "ner": [[0, 0, "product"], [4, 4, "programlang"], [13, 14, "field"], [16, 16, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 4, "general-affiliation", "", false, false], [0, 0, 13, 14, "related-to", "", false, false], [0, 0, 16, 16, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["ANIMAL", "foi", "portado", "para", "R", ",", "uma", "linguagem", "e", "ambiente", "livremente", "dispon\u00edveis", "para", "computa\u00e7\u00e3o", "estat\u00edstica", "e", "gr\u00e1fica", "."], "sentence-detokenized": "ANIMAL foi portado para R, uma linguagem e ambiente livremente dispon\u00edveis para computa\u00e7\u00e3o estat\u00edstica e gr\u00e1fica.", "token2charspan": [[0, 6], [7, 10], [11, 18], [19, 23], [24, 25], [25, 26], [27, 30], [31, 40], [41, 42], [43, 51], [52, 62], [63, 74], [75, 79], [80, 90], [91, 102], [103, 104], [105, 112], [112, 113]]}
{"doc_key": "ai-test-203", "ner": [[0, 6, "algorithm"], [8, 8, "algorithm"], [14, 16, "algorithm"], [18, 18, "algorithm"], [22, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 6, 14, 16, "opposite", "alternative to", false, false], [8, 8, 0, 6, "named", "", false, false], [18, 18, 14, 16, "named", "", false, false], [22, 25, 0, 6, "usage", "", false, false], [22, 25, 14, 16, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["O", "modelo", "Bernoulli", "oculto", "de", "tempo", "inomog\u00eaneo", "(", "TI-HBM", ")", "\u00e9", "uma", "alternativa", "ao", "modelo", "Markov", "oculto", "(", "HMM", ")", "para", "o", "reconhecimento", "autom\u00e1tico", "da", "fala", "."], "sentence-detokenized": "O modelo Bernoulli oculto de tempo inomog\u00eaneo (TI-HBM) \u00e9 uma alternativa ao modelo Markov oculto (HMM) para o reconhecimento autom\u00e1tico da fala.", "token2charspan": [[0, 1], [2, 8], [9, 18], [19, 25], [26, 28], [29, 34], [35, 45], [46, 47], [47, 53], [53, 54], [55, 56], [57, 60], [61, 72], [73, 75], [76, 82], [83, 89], [90, 96], [97, 98], [98, 101], [101, 102], [103, 107], [108, 109], [110, 124], [125, 135], [136, 138], [139, 143], [143, 144]]}
{"doc_key": "ai-test-204", "ner": [[5, 5, "organisation"], [9, 9, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 9, 9, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Em", "julho", "de", "2016", ",", "Nvidia", "demonstrou", "durante", "o", "SIGGRAPH", "um", "novo", "m\u00e9todo", "de", "renderiza\u00e7\u00e3o", "de", "foveated", "afirmado", "ser", "invis\u00edvel", "para", "os", "usu\u00e1rios", "."], "sentence-detokenized": "Em julho de 2016, Nvidia demonstrou durante o SIGGRAPH um novo m\u00e9todo de renderiza\u00e7\u00e3o de foveated afirmado ser invis\u00edvel para os usu\u00e1rios.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 16], [16, 17], [18, 24], [25, 35], [36, 43], [44, 45], [46, 54], [55, 57], [58, 62], [63, 69], [70, 72], [73, 85], [86, 88], [89, 97], [98, 106], [107, 110], [111, 120], [121, 125], [126, 128], [129, 137], [137, 138]]}
{"doc_key": "ai-test-205", "ner": [[4, 8, "misc"], [11, 13, "researcher"], [19, 20, "researcher"], [22, 23, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 8, 11, 13, "origin", "", false, false], [4, 8, 19, 20, "origin", "", false, false], [4, 8, 22, 23, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Ambos", "se", "baseiam", "na", "teoria", "dos", "atos", "de", "fala", "desenvolvida", "por", "John", "Searle", "nos", "anos", "60", "e", "aprimorada", "por", "Terry", "Winograd", "e", "Flores", "nos", "anos", "70", "."], "sentence-detokenized": "Ambos se baseiam na teoria dos atos de fala desenvolvida por John Searle nos anos 60 e aprimorada por Terry Winograd e Flores nos anos 70.", "token2charspan": [[0, 5], [6, 8], [9, 16], [17, 19], [20, 26], [27, 30], [31, 35], [36, 38], [39, 43], [44, 56], [57, 60], [61, 65], [66, 72], [73, 76], [77, 81], [82, 84], [85, 86], [87, 97], [98, 101], [102, 107], [108, 116], [117, 118], [119, 125], [126, 129], [130, 134], [135, 137], [137, 138]]}
{"doc_key": "ai-test-206", "ner": [[0, 4, "algorithm"], [27, 28, "researcher"], [25, 25, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 27, 28, "related-to", "", false, false], [25, 25, 27, 28, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Os", "modelos", "de", "redes", "neurais", "de", "forma\u00e7\u00e3o", "de", "conceitos", "e", "a", "estrutura", "do", "conhecimento", "abriram", "poderosos", "modelos", "hier\u00e1rquicos", "de", "organiza\u00e7\u00e3o", "do", "conhecimento", ",", "como", "o", "Wordnet", "de", "George", "Miller", "."], "sentence-detokenized": "Os modelos de redes neurais de forma\u00e7\u00e3o de conceitos e a estrutura do conhecimento abriram poderosos modelos hier\u00e1rquicos de organiza\u00e7\u00e3o do conhecimento, como o Wordnet de George Miller.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 19], [20, 27], [28, 30], [31, 39], [40, 42], [43, 52], [53, 54], [55, 56], [57, 66], [67, 69], [70, 82], [83, 90], [91, 100], [101, 108], [109, 121], [122, 124], [125, 136], [137, 139], [140, 152], [152, 153], [154, 158], [159, 160], [161, 168], [169, 171], [172, 178], [179, 185], [185, 186]]}
{"doc_key": "ai-test-207", "ner": [[0, 3, "algorithm"], [13, 14, "field"], [17, 20, "product"], [23, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 13, 14, "part-of", "", false, false], [0, 3, 23, 26, "part-of", "", false, false], [17, 20, 13, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "correspond\u00eancia", "de", "modelos", "tem", "v\u00e1rias", "aplica\u00e7\u00f5es", "e", "\u00e9", "utilizada", "em", "campos", "como", "reconhecimento", "facial", "(", "ver", "sistema", "de", "reconhecimento", "facial", ")", "e", "processamento", "de", "imagens", "m\u00e9dicas", "."], "sentence-detokenized": "A correspond\u00eancia de modelos tem v\u00e1rias aplica\u00e7\u00f5es e \u00e9 utilizada em campos como reconhecimento facial (ver sistema de reconhecimento facial) e processamento de imagens m\u00e9dicas.", "token2charspan": [[0, 1], [2, 17], [18, 20], [21, 28], [29, 32], [33, 39], [40, 50], [51, 52], [53, 54], [55, 64], [65, 67], [68, 74], [75, 79], [80, 94], [95, 101], [102, 103], [103, 106], [107, 114], [115, 117], [118, 132], [133, 139], [139, 140], [141, 142], [143, 156], [157, 159], [160, 167], [168, 175], [175, 176]]}
{"doc_key": "ai-test-208", "ner": [[10, 11, "researcher"], [13, 14, "researcher"], [18, 26, "organisation"], [28, 28, "organisation"], [37, 38, "algorithm"], [40, 48, "conference"], [50, 50, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 11, 18, 26, "role", "", false, false], [10, 11, 40, 48, "physical", "", false, false], [10, 11, 40, 48, "temporal", "", false, false], [10, 11, 50, 50, "physical", "", false, false], [13, 14, 18, 26, "role", "", false, false], [13, 14, 40, 48, "temporal", "", false, false], [28, 28, 18, 26, "named", "", false, false], [40, 48, 37, 38, "topic", "", false, false], [50, 50, 40, 48, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Entretanto", ",", "o", "uso", "s\u00f3", "se", "generalizou", "em", "2005", "quando", "Navneet", "Dalal", "e", "Bill", "Triggs", ",", "pesquisadores", "do", "Instituto", "Nacional", "Franc\u00eas", "de", "Pesquisa", "em", "Inform\u00e1tica", "e", "Automa\u00e7\u00e3o", "(", "INRIA", ")", ",", "apresentaram", "seu", "trabalho", "suplementar", "sobre", "os", "descritores", "HOG", "na", "Confer\u00eancia", "sobre", "Vis\u00e3o", "e", "Reconhecimento", "de", "Padr\u00f5es", "de", "Computador", "(", "CVPR", ")", "."], "sentence-detokenized": "Entretanto, o uso s\u00f3 se generalizou em 2005 quando Navneet Dalal e Bill Triggs, pesquisadores do Instituto Nacional Franc\u00eas de Pesquisa em Inform\u00e1tica e Automa\u00e7\u00e3o (INRIA), apresentaram seu trabalho suplementar sobre os descritores HOG na Confer\u00eancia sobre Vis\u00e3o e Reconhecimento de Padr\u00f5es de Computador (CVPR).", "token2charspan": [[0, 10], [10, 11], [12, 13], [14, 17], [18, 20], [21, 23], [24, 35], [36, 38], [39, 43], [44, 50], [51, 58], [59, 64], [65, 66], [67, 71], [72, 78], [78, 79], [80, 93], [94, 96], [97, 106], [107, 115], [116, 123], [124, 126], [127, 135], [136, 138], [139, 150], [151, 152], [153, 162], [163, 164], [164, 169], [169, 170], [170, 171], [172, 184], [185, 188], [189, 197], [198, 209], [210, 215], [216, 218], [219, 230], [231, 234], [235, 237], [238, 249], [250, 255], [256, 261], [262, 263], [264, 278], [279, 281], [282, 289], [290, 292], [293, 303], [304, 305], [305, 309], [309, 310], [310, 311]]}
{"doc_key": "ai-test-209", "ner": [[5, 5, "university"], [17, 20, "organisation"], [22, 23, "organisation"], [31, 31, "field"], [35, 37, "researcher"], [39, 41, "researcher"], [43, 45, "researcher"], [47, 52, "organisation"], [55, 59, "organisation"], [63, 64, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[22, 23, 31, 31, "related-to", "", false, false], [35, 37, 22, 23, "physical", "", false, false], [35, 37, 22, 23, "role", "", false, false], [39, 41, 22, 23, "physical", "", false, false], [39, 41, 22, 23, "role", "", false, false], [43, 45, 22, 23, "physical", "", false, false], [43, 45, 22, 23, "role", "", false, false], [63, 64, 55, 59, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Antes", "de", "ingressar", "na", "faculdade", "Penn", "em", "2002", ",", "ele", "passou", "uma", "d\u00e9cada", "(", "1991-2001", ")", "na", "AT", "&", "T", "Labs", "e", "Bell", "Labs", ",", "inclusive", "como", "chefe", "do", "departamento", "de", "IA", "com", "colegas", "como", "Michael", "L.", "Littman", ",", "David", "A.", "McAllester", "e", "Richard", "S.", "Sutton", ";", "departamento", "de", "Pesquisa", "de", "Sistemas", "Seguros", ";", "e", "departamento", "de", "Aprendizagem", "de", "M\u00e1quinas", "com", "membros", "como", "Michael", "Collins", "e", "o", "l\u00edder", ")", "."], "sentence-detokenized": "Antes de ingressar na faculdade Penn em 2002, ele passou uma d\u00e9cada (1991-2001) na AT & T Labs e Bell Labs, inclusive como chefe do departamento de IA com colegas como Michael L. Littman, David A. McAllester e Richard S. Sutton; departamento de Pesquisa de Sistemas Seguros; e departamento de Aprendizagem de M\u00e1quinas com membros como Michael Collins e o l\u00edder).", "token2charspan": [[0, 5], [6, 8], [9, 18], [19, 21], [22, 31], [32, 36], [37, 39], [40, 44], [44, 45], [46, 49], [50, 56], [57, 60], [61, 67], [68, 69], [69, 78], [78, 79], [80, 82], [83, 85], [86, 87], [88, 89], [90, 94], [95, 96], [97, 101], [102, 106], [106, 107], [108, 117], [118, 122], [123, 128], [129, 131], [132, 144], [145, 147], [148, 150], [151, 154], [155, 162], [163, 167], [168, 175], [176, 178], [179, 186], [186, 187], [188, 193], [194, 196], [197, 207], [208, 209], [210, 217], [218, 220], [221, 227], [227, 228], [229, 241], [242, 244], [245, 253], [254, 256], [257, 265], [266, 273], [273, 274], [275, 276], [277, 289], [290, 292], [293, 305], [306, 308], [309, 317], [318, 321], [322, 329], [330, 334], [335, 342], [343, 350], [351, 352], [353, 354], [355, 360], [360, 361], [361, 362]]}
{"doc_key": "ai-test-210", "ner": [[8, 9, "field"], [19, 21, "field"], [26, 28, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 19, 21, "compare", "", false, false], [26, 28, 19, 21, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Quando", "os", "dados", "n\u00e3o", "s\u00e3o", "rotulados", ",", "o", "aprendizado", "supervisionado", "n\u00e3o", "\u00e9", "poss\u00edvel", "e", "\u00e9", "necess\u00e1ria", "uma", "abordagem", "de", "aprendizado", "n\u00e3o", "supervisionado", "que", "tente", "encontrar", "uma", "an\u00e1lise", "de", "cluster", "natural", "para", "grupos", ",", "e", "ent\u00e3o", "mapear", "novos", "dados", "para", "esses", "grupos", "formados", "."], "sentence-detokenized": "Quando os dados n\u00e3o s\u00e3o rotulados, o aprendizado supervisionado n\u00e3o \u00e9 poss\u00edvel e \u00e9 necess\u00e1ria uma abordagem de aprendizado n\u00e3o supervisionado que tente encontrar uma an\u00e1lise de cluster natural para grupos, e ent\u00e3o mapear novos dados para esses grupos formados.", "token2charspan": [[0, 6], [7, 9], [10, 15], [16, 19], [20, 23], [24, 33], [33, 34], [35, 36], [37, 48], [49, 63], [64, 67], [68, 69], [70, 78], [79, 80], [81, 82], [83, 93], [94, 97], [98, 107], [108, 110], [111, 122], [123, 126], [127, 141], [142, 145], [146, 151], [152, 161], [162, 165], [166, 173], [174, 176], [177, 184], [185, 192], [193, 197], [198, 204], [204, 205], [206, 207], [208, 213], [214, 220], [221, 226], [227, 232], [233, 237], [238, 243], [244, 250], [251, 259], [259, 260]]}
{"doc_key": "ai-test-211", "ner": [[3, 4, "field"], [14, 16, "organisation"], [23, 24, "field"], [26, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 14, 16, "origin", "", false, false], [3, 4, 23, 24, "part-of", "", false, false], [3, 4, 26, 26, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Este", "campo", "da", "inform\u00e1tica", "foi", "desenvolvido", "nos", "anos", "50", "em", "institui\u00e7\u00f5es", "acad\u00eamicas", "como", "o", "Laborat\u00f3rio", "MIT", "A.I.", ",", "originalmente", "como", "um", "ramo", "de", "intelig\u00eancia", "artificial", "e", "rob\u00f3tica", "."], "sentence-detokenized": "Este campo da inform\u00e1tica foi desenvolvido nos anos 50 em institui\u00e7\u00f5es acad\u00eamicas como o Laborat\u00f3rio MIT A.I., originalmente como um ramo de intelig\u00eancia artificial e rob\u00f3tica.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 25], [26, 29], [30, 42], [43, 46], [47, 51], [52, 54], [55, 57], [58, 70], [71, 81], [82, 86], [87, 88], [89, 100], [101, 104], [105, 109], [109, 110], [111, 124], [125, 129], [130, 132], [133, 137], [138, 140], [141, 153], [154, 164], [165, 166], [167, 175], [175, 176]]}
{"doc_key": "ai-test-212", "ner": [[8, 10, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ela", "tamb\u00e9m", "poderia", "ser", "substitu\u00edda", "pela", "equa\u00e7\u00e3o", "de", "perda", "de", "log", "abaixo", ":"], "sentence-detokenized": "Ela tamb\u00e9m poderia ser substitu\u00edda pela equa\u00e7\u00e3o de perda de log abaixo:", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 22], [23, 34], [35, 39], [40, 47], [48, 50], [51, 56], [57, 59], [60, 63], [64, 70], [70, 71]]}
{"doc_key": "ai-test-213", "ner": [[1, 3, "organisation"], [6, 10, "organisation"], [13, 17, "university"], [19, 19, "university"], [21, 23, "university"], [25, 27, "university"], [30, 30, "country"], [38, 38, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[1, 3, 38, 38, "related-to", "research_leader_in_field", false, false], [6, 10, 1, 3, "named", "", false, false], [6, 10, 38, 38, "related-to", "research_leader_in_field", false, false], [13, 17, 38, 38, "related-to", "research_leader_in_field", false, false], [19, 19, 38, 38, "related-to", "research_leader_in_field", false, false], [21, 23, 38, 38, "related-to", "research_leader_in_field", false, false], [25, 27, 30, 30, "physical", "", false, false], [25, 27, 38, 38, "related-to", "research_leader_in_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["O", "Shirley", "Ryan", "AbilityLab", "(", "antigo", "Instituto", "de", "Reabilita\u00e7\u00e3o", "de", "Chicago", ")", ",", "Universidade", "da", "Calif\u00f3rnia", "em", "Berkeley", ",", "MIT", ",", "Universidade", "de", "Stanford", "e", "Universidade", "de", "Twente", ",", "na", "Holanda", ",", "s\u00e3o", "os", "l\u00edderes", "de", "pesquisa", "em", "biomecatr\u00f3nica", "."], "sentence-detokenized": "O Shirley Ryan AbilityLab (antigo Instituto de Reabilita\u00e7\u00e3o de Chicago), Universidade da Calif\u00f3rnia em Berkeley, MIT, Universidade de Stanford e Universidade de Twente, na Holanda, s\u00e3o os l\u00edderes de pesquisa em biomecatr\u00f3nica.", "token2charspan": [[0, 1], [2, 9], [10, 14], [15, 25], [26, 27], [27, 33], [34, 43], [44, 46], [47, 59], [60, 62], [63, 70], [70, 71], [71, 72], [73, 85], [86, 88], [89, 99], [100, 102], [103, 111], [111, 112], [113, 116], [116, 117], [118, 130], [131, 133], [134, 142], [143, 144], [145, 157], [158, 160], [161, 167], [167, 168], [169, 171], [172, 179], [179, 180], [181, 184], [185, 187], [188, 195], [196, 198], [199, 207], [208, 210], [211, 225], [225, 226]]}
{"doc_key": "ai-test-214", "ner": [[29, 34, "metrics"], [45, 47, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Dado", "um", "conjunto", "de", "valores", "previstos", "e", "um", "conjunto", "correspondente", "de", "valores", "reais", "para", "X", "durante", "v\u00e1rios", "per\u00edodos", "de", "tempo", ",", "uma", "t\u00e9cnica", "de", "avalia\u00e7\u00e3o", "comum", "\u00e9", "usar", "o", "erro", "m\u00e9dio", "de", "previs\u00e3o", "ao", "quadrado", ";", "outras", "medidas", "tamb\u00e9m", "est\u00e3o", "dispon\u00edveis", "(", "ver", "previs\u00e3o", "#", "precis\u00e3o", "da", "previs\u00e3o", ")", "."], "sentence-detokenized": "Dado um conjunto de valores previstos e um conjunto correspondente de valores reais para X durante v\u00e1rios per\u00edodos de tempo, uma t\u00e9cnica de avalia\u00e7\u00e3o comum \u00e9 usar o erro m\u00e9dio de previs\u00e3o ao quadrado; outras medidas tamb\u00e9m est\u00e3o dispon\u00edveis (ver previs\u00e3o # precis\u00e3o da previs\u00e3o).", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 19], [20, 27], [28, 37], [38, 39], [40, 42], [43, 51], [52, 66], [67, 69], [70, 77], [78, 83], [84, 88], [89, 90], [91, 98], [99, 105], [106, 114], [115, 117], [118, 123], [123, 124], [125, 128], [129, 136], [137, 139], [140, 149], [150, 155], [156, 157], [158, 162], [163, 164], [165, 169], [170, 175], [176, 178], [179, 187], [188, 190], [191, 199], [199, 200], [201, 207], [208, 215], [216, 222], [223, 228], [229, 240], [241, 242], [242, 245], [246, 254], [255, 256], [257, 265], [266, 268], [269, 277], [277, 278], [278, 279]]}
{"doc_key": "ai-test-215", "ner": [[13, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Outras", "medidas", ",", "como", "a", "propor\u00e7\u00e3o", "de", "previs\u00f5es", "corretas", "(", "tamb\u00e9m", "chamadas", "de", "exatid\u00e3o", ")", ",", "n\u00e3o", "s\u00e3o", "\u00fateis", "quando", "as", "duas", "classes", "s\u00e3o", "de", "tamanhos", "muito", "diferentes", "."], "sentence-detokenized": "Outras medidas, como a propor\u00e7\u00e3o de previs\u00f5es corretas (tamb\u00e9m chamadas de exatid\u00e3o), n\u00e3o s\u00e3o \u00fateis quando as duas classes s\u00e3o de tamanhos muito diferentes.", "token2charspan": [[0, 6], [7, 14], [14, 15], [16, 20], [21, 22], [23, 32], [33, 35], [36, 45], [46, 54], [55, 56], [56, 62], [63, 71], [72, 74], [75, 83], [83, 84], [84, 85], [86, 89], [90, 93], [94, 99], [100, 106], [107, 109], [110, 114], [115, 122], [123, 126], [127, 129], [130, 138], [139, 144], [145, 155], [155, 156]]}
{"doc_key": "ai-test-216", "ner": [[5, 5, "product"], [13, 18, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 13, 18, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "primeira", "vers\u00e3o", "alfa", "do", "OpenCV", "foi", "lan\u00e7ada", "ao", "p\u00fablico", "na", "Confer\u00eancia", "sobre", "Vis\u00e3o", "Computadorizada", "e", "Reconhecimento", "de", "Padr\u00f5es", "em", "2000", ",", "e", "cinco", "betas", "foram", "lan\u00e7ados", "entre", "2001", "e", "2005", "."], "sentence-detokenized": "A primeira vers\u00e3o alfa do OpenCV foi lan\u00e7ada ao p\u00fablico na Confer\u00eancia sobre Vis\u00e3o Computadorizada e Reconhecimento de Padr\u00f5es em 2000, e cinco betas foram lan\u00e7ados entre 2001 e 2005.", "token2charspan": [[0, 1], [2, 10], [11, 17], [18, 22], [23, 25], [26, 32], [33, 36], [37, 44], [45, 47], [48, 55], [56, 58], [59, 70], [71, 76], [77, 82], [83, 98], [99, 100], [101, 115], [116, 118], [119, 126], [127, 129], [130, 134], [134, 135], [136, 137], [138, 143], [144, 149], [150, 155], [156, 164], [165, 170], [171, 175], [176, 177], [178, 182], [182, 183]]}
{"doc_key": "ai-test-217", "ner": [[25, 25, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Foram", "apresentados", "resultados", "que", "d\u00e3o", "uma", "correla\u00e7\u00e3o", "de", "at\u00e9", "0,964", "com", "o", "julgamento", "humano", "em", "n\u00edvel", "de", "corpus", ",", "em", "compara\u00e7\u00e3o", "com", "a", "conquista", "da", "BLEU", "de", "0,817", "no", "mesmo", "conjunto", "de", "dados", "."], "sentence-detokenized": "Foram apresentados resultados que d\u00e3o uma correla\u00e7\u00e3o de at\u00e9 0,964 com o julgamento humano em n\u00edvel de corpus, em compara\u00e7\u00e3o com a conquista da BLEU de 0,817 no mesmo conjunto de dados.", "token2charspan": [[0, 5], [6, 18], [19, 29], [30, 33], [34, 37], [38, 41], [42, 52], [53, 55], [56, 59], [60, 65], [66, 69], [70, 71], [72, 82], [83, 89], [90, 92], [93, 98], [99, 101], [102, 108], [108, 109], [110, 112], [113, 123], [124, 127], [128, 129], [130, 139], [140, 142], [143, 147], [148, 150], [151, 156], [157, 159], [160, 165], [166, 174], [175, 177], [178, 183], [183, 184]]}
{"doc_key": "ai-test-218", "ner": [[4, 4, "metrics"], [19, 19, "metrics"], [21, 22, "metrics"], [24, 24, "metrics"], [35, 36, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 19, 19, "compare", "", false, false], [4, 4, 21, 22, "compare", "", false, false], [4, 4, 24, 24, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Uma", "vers\u00e3o", "inicial", "do", "VMAF", "foi", "mostrada", "para", "superar", "outras", "m\u00e9tricas", "de", "qualidade", "de", "imagem", "e", "v\u00eddeo", ",", "como", "SSIM", ",", "PSNR", "-HVS", "e", "VQM-VFD", "em", "tr\u00eas", "de", "quatro", "conjuntos", "de", "dados", "em", "termos", "de", "precis\u00e3o", "de", "previs\u00e3o", ",", "quando", "comparada", "com", "classifica\u00e7\u00f5es", "subjetivas", "."], "sentence-detokenized": "Uma vers\u00e3o inicial do VMAF foi mostrada para superar outras m\u00e9tricas de qualidade de imagem e v\u00eddeo, como SSIM, PSNR -HVS e VQM-VFD em tr\u00eas de quatro conjuntos de dados em termos de precis\u00e3o de previs\u00e3o, quando comparada com classifica\u00e7\u00f5es subjetivas.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 21], [22, 26], [27, 30], [31, 39], [40, 44], [45, 52], [53, 59], [60, 68], [69, 71], [72, 81], [82, 84], [85, 91], [92, 93], [94, 99], [99, 100], [101, 105], [106, 110], [110, 111], [112, 116], [117, 121], [122, 123], [124, 131], [132, 134], [135, 139], [140, 142], [143, 149], [150, 159], [160, 162], [163, 168], [169, 171], [172, 178], [179, 181], [182, 190], [191, 193], [194, 202], [202, 203], [204, 210], [211, 220], [221, 224], [225, 239], [240, 250], [250, 251]]}
{"doc_key": "ai-test-219", "ner": [[18, 19, "task"], [25, 27, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 19, 25, 27, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Por", "exemplo", ",", "a", "ambig\u00fcidade", "do", "\"", "mouse", "\"", "(", "animal", "ou", "dispositivo", ")", "n\u00e3o", "\u00e9", "relevante", "na", "tradu\u00e7\u00e3o", "autom\u00e1tica", ",", "mas", "\u00e9", "relevante", "na", "recupera\u00e7\u00e3o", "de", "informa\u00e7\u00f5es", "."], "sentence-detokenized": "Por exemplo, a ambig\u00fcidade do \"mouse\" (animal ou dispositivo) n\u00e3o \u00e9 relevante na tradu\u00e7\u00e3o autom\u00e1tica, mas \u00e9 relevante na recupera\u00e7\u00e3o de informa\u00e7\u00f5es.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 14], [15, 26], [27, 29], [30, 31], [31, 36], [36, 37], [38, 39], [39, 45], [46, 48], [49, 60], [60, 61], [62, 65], [66, 67], [68, 77], [78, 80], [81, 89], [90, 100], [100, 101], [102, 105], [106, 107], [108, 117], [118, 120], [121, 132], [133, 135], [136, 147], [147, 148]]}
{"doc_key": "ai-test-220", "ner": [[0, 2, "algorithm"], [7, 9, "field"], [12, 14, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 0, 2, "usage", "", false, false], [12, 14, 7, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["O", "hashing", "geom\u00e9trico", "foi", "originalmente", "sugerido", "na", "vis\u00e3o", "por", "computador", "para", "o", "reconhecimento", "de", "objetos", "em", "2D", "e", "3D", ","], "sentence-detokenized": "O hashing geom\u00e9trico foi originalmente sugerido na vis\u00e3o por computador para o reconhecimento de objetos em 2D e 3D,", "token2charspan": [[0, 1], [2, 9], [10, 20], [21, 24], [25, 38], [39, 47], [48, 50], [51, 56], [57, 60], [61, 71], [72, 76], [77, 78], [79, 93], [94, 96], [97, 104], [105, 107], [108, 110], [111, 112], [113, 115], [115, 116]]}
{"doc_key": "ai-test-221", "ner": [[8, 10, "field"], [15, 16, "field"], [19, 21, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 16, 8, 10, "part-of", "subfield", false, false], [19, 21, 8, 10, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Ela", "forma", "uma", "das", "tr\u00eas", "principais", "categorias", "de", "aprendizagem", "de", "m\u00e1quinas", ",", "juntamente", "com", "a", "aprendizagem", "supervisionada", "e", "a", "aprendizagem", "de", "refor\u00e7o", "."], "sentence-detokenized": "Ela forma uma das tr\u00eas principais categorias de aprendizagem de m\u00e1quinas, juntamente com a aprendizagem supervisionada e a aprendizagem de refor\u00e7o.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 17], [18, 22], [23, 33], [34, 44], [45, 47], [48, 60], [61, 63], [64, 72], [72, 73], [74, 84], [85, 88], [89, 90], [91, 103], [104, 118], [119, 120], [121, 122], [123, 135], [136, 138], [139, 146], [146, 147]]}
{"doc_key": "ai-test-222", "ner": [[0, 3, "field"], [19, 19, "field"], [21, 23, "field"], [25, 26, "field"], [28, 30, "field"], [32, 35, "field"], [37, 38, "field"], [40, 42, "field"], [44, 44, "field"], [46, 47, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 3, 19, 19, "part-of", "subfield", false, false], [0, 3, 21, 23, "part-of", "subfield", false, false], [0, 3, 25, 26, "part-of", "subfield", false, false], [0, 3, 28, 30, "part-of", "subfield", false, false], [0, 3, 32, 35, "part-of", "subfield", false, false], [0, 3, 37, 38, "part-of", "subfield", false, false], [0, 3, 40, 42, "part-of", "subfield", false, false], [0, 3, 44, 44, "part-of", "subfield", false, false], [0, 3, 46, 47, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["O", "aprendizado", "do", "refor\u00e7o", ",", "devido", "a", "sua", "generalidade", ",", "\u00e9", "estudado", "em", "muitas", "outras", "disciplinas", ",", "tais", "como", "jogo", ",", "teoria", "de", "controle", ",", "pesquisa", "operacional", ",", "teoria", "da", "informa\u00e7\u00e3o", ",", "otimiza\u00e7\u00e3o", "baseada", "em", "simula\u00e7\u00e3o", ",", "sistemas", "multi-agentes", ",", "intelig\u00eancia", "de", "enxame", ",", "estat\u00edstica", "e", "algoritmos", "gen\u00e9ticos", "."], "sentence-detokenized": "O aprendizado do refor\u00e7o, devido a sua generalidade, \u00e9 estudado em muitas outras disciplinas, tais como jogo, teoria de controle, pesquisa operacional, teoria da informa\u00e7\u00e3o, otimiza\u00e7\u00e3o baseada em simula\u00e7\u00e3o, sistemas multi-agentes, intelig\u00eancia de enxame, estat\u00edstica e algoritmos gen\u00e9ticos.", "token2charspan": [[0, 1], [2, 13], [14, 16], [17, 24], [24, 25], [26, 32], [33, 34], [35, 38], [39, 51], [51, 52], [53, 54], [55, 63], [64, 66], [67, 73], [74, 80], [81, 92], [92, 93], [94, 98], [99, 103], [104, 108], [108, 109], [110, 116], [117, 119], [120, 128], [128, 129], [130, 138], [139, 150], [150, 151], [152, 158], [159, 161], [162, 172], [172, 173], [174, 184], [185, 192], [193, 195], [196, 205], [205, 206], [207, 215], [216, 229], [229, 230], [231, 243], [244, 246], [247, 253], [253, 254], [255, 266], [267, 268], [269, 279], [280, 289], [289, 290]]}
{"doc_key": "ai-test-223", "ner": [[0, 3, "field"], [8, 9, "field"], [12, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 8, 9, "related-to", "", false, false], [0, 3, 12, 14, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["O", "reconhecimento", "de", "padr\u00f5es", "est\u00e1", "intimamente", "relacionado", "\u00e0", "intelig\u00eancia", "artificial", "e", "\u00e0", "aprendizagem", "de", "m\u00e1quinas", ","], "sentence-detokenized": "O reconhecimento de padr\u00f5es est\u00e1 intimamente relacionado \u00e0 intelig\u00eancia artificial e \u00e0 aprendizagem de m\u00e1quinas,", "token2charspan": [[0, 1], [2, 16], [17, 19], [20, 27], [28, 32], [33, 44], [45, 56], [57, 58], [59, 71], [72, 82], [83, 84], [85, 86], [87, 99], [100, 102], [103, 111], [111, 112]]}
{"doc_key": "ai-test-224", "ner": [[12, 13, "algorithm"], [15, 16, "field"], [18, 20, "field"], [32, 34, "task"], [36, 36, "task"], [38, 40, "task"], [42, 43, "algorithm"], [45, 48, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[12, 13, 15, 16, "related-to", "", false, false], [12, 13, 18, 20, "related-to", "", false, false], [32, 34, 12, 13, "usage", "", true, false], [36, 36, 12, 13, "usage", "", true, false], [38, 40, 12, 13, "usage", "", true, false], [42, 43, 12, 13, "usage", "", true, false], [45, 48, 12, 13, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["O", "software", "\u00e9", "usado", "para", "projetar", ",", "treinar", "e", "implantar", "modelos", "de", "rede", "neural", "(", "aprendizagem", "supervisionada", "e", "aprendizagem", "n\u00e3o", "supervisionada", ")", "para", "executar", "uma", "grande", "variedade", "de", "tarefas", ",", "tais", "como", "minera\u00e7\u00e3o", "de", "dados", ",", "classifica\u00e7\u00e3o", ",", "aproxima\u00e7\u00e3o", "de", "fun\u00e7\u00f5es", ",", "regress\u00e3o", "multivariada", "e", "previs\u00e3o", "de", "s\u00e9rie", "temporal", "."], "sentence-detokenized": "O software \u00e9 usado para projetar, treinar e implantar modelos de rede neural (aprendizagem supervisionada e aprendizagem n\u00e3o supervisionada) para executar uma grande variedade de tarefas, tais como minera\u00e7\u00e3o de dados, classifica\u00e7\u00e3o, aproxima\u00e7\u00e3o de fun\u00e7\u00f5es, regress\u00e3o multivariada e previs\u00e3o de s\u00e9rie temporal.", "token2charspan": [[0, 1], [2, 10], [11, 12], [13, 18], [19, 23], [24, 32], [32, 33], [34, 41], [42, 43], [44, 53], [54, 61], [62, 64], [65, 69], [70, 76], [77, 78], [78, 90], [91, 105], [106, 107], [108, 120], [121, 124], [125, 139], [139, 140], [141, 145], [146, 154], [155, 158], [159, 165], [166, 175], [176, 178], [179, 186], [186, 187], [188, 192], [193, 197], [198, 207], [208, 210], [211, 216], [216, 217], [218, 231], [231, 232], [233, 244], [245, 247], [248, 255], [255, 256], [257, 266], [267, 279], [280, 281], [282, 290], [291, 293], [294, 299], [300, 308], [308, 309]]}
{"doc_key": "ai-test-225", "ner": [[8, 14, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Em", "2016", ",", "ele", "foi", "eleito", "Fellow", "of", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "Em 2016, ele foi eleito Fellow of Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 23], [24, 30], [31, 33], [34, 45], [46, 49], [50, 53], [54, 65], [66, 68], [69, 79], [80, 92], [92, 93]]}
{"doc_key": "ai-test-226", "ner": [[5, 8, "organisation"], [14, 19, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ela", "atua", "como", "membro", "da", "Academia", "Nacional", "de", "Ci\u00eancias", "(", "desde", "2005", ")", ",", "Academia", "Americana", "de", "Artes", "e", "Ci\u00eancias", "(", "desde", "2009", ")", ","], "sentence-detokenized": "Ela atua como membro da Academia Nacional de Ci\u00eancias (desde 2005), Academia Americana de Artes e Ci\u00eancias (desde 2009),", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 20], [21, 23], [24, 32], [33, 41], [42, 44], [45, 53], [54, 55], [55, 60], [61, 65], [65, 66], [66, 67], [68, 76], [77, 86], [87, 89], [90, 95], [96, 97], [98, 106], [107, 108], [108, 113], [114, 118], [118, 119], [119, 120]]}
{"doc_key": "ai-test-227", "ner": [[2, 5, "misc"], [12, 13, "product"], [18, 18, "country"], [21, 21, "country"], [26, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 13, 2, 5, "temporal", "", false, false], [12, 13, 18, 18, "physical", "", false, false], [12, 13, 21, 21, "physical", "", false, false], [12, 13, 26, 27, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Durante", "a", "Guerra", "do", "Yom", "Kippur", "de", "1973", ",", "as", "baterias", "de", "m\u00edsseis", "terra-ar", "fornecidas", "pelos", "sovi\u00e9ticos", "no", "Egito", "e", "na", "S\u00edria", "causaram", "pesados", "danos", "aos", "ca\u00e7as", "israelenses", "."], "sentence-detokenized": "Durante a Guerra do Yom Kippur de 1973, as baterias de m\u00edsseis terra-ar fornecidas pelos sovi\u00e9ticos no Egito e na S\u00edria causaram pesados danos aos ca\u00e7as israelenses.", "token2charspan": [[0, 7], [8, 9], [10, 16], [17, 19], [20, 23], [24, 30], [31, 33], [34, 38], [38, 39], [40, 42], [43, 51], [52, 54], [55, 62], [63, 71], [72, 82], [83, 88], [89, 99], [100, 102], [103, 108], [109, 110], [111, 113], [114, 119], [120, 128], [129, 136], [137, 142], [143, 146], [147, 152], [153, 164], [164, 165]]}
{"doc_key": "ai-test-228", "ner": [[12, 13, "product"], [17, 20, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 20, 12, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Outro", "recurso", "(", "gratuito", ",", "mas", "com", "direitos", "autorais", ")", "\u00e9", "o", "livro", "HTK", "(", "e", "o", "conjunto", "de", "ferramentas", "HTK", "que", "o", "acompanha", ")", "."], "sentence-detokenized": "Outro recurso (gratuito, mas com direitos autorais) \u00e9 o livro HTK (e o conjunto de ferramentas HTK que o acompanha).", "token2charspan": [[0, 5], [6, 13], [14, 15], [15, 23], [23, 24], [25, 28], [29, 32], [33, 41], [42, 50], [50, 51], [52, 53], [54, 55], [56, 61], [62, 65], [66, 67], [67, 68], [69, 70], [71, 79], [80, 82], [83, 94], [95, 98], [99, 102], [103, 104], [105, 114], [114, 115], [115, 116]]}
{"doc_key": "ai-test-229", "ner": [[8, 10, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["-", "foram", "tomadas", "no", "Simp\u00f3sio", "da", "Primavera", "de", "2004", "da", "AAAI", ",", "onde", "ling\u00fcistas", ",", "cientistas", "da", "computa\u00e7\u00e3o", "e", "outros", "pesquisadores", "interessados", "primeiro", "alinharam", "interesses", "e", "propuseram", "tarefas", "compartilhadas", "e", "conjuntos", "de", "dados", "de", "refer\u00eancia", "para", "a", "pesquisa", "computacional", "sistem\u00e1tica", "sobre", "afeto", ",", "apelo", ",", "subjetividade", "e", "sentimento", "em", "texto", "."], "sentence-detokenized": "- foram tomadas no Simp\u00f3sio da Primavera de 2004 da AAAI, onde ling\u00fcistas, cientistas da computa\u00e7\u00e3o e outros pesquisadores interessados primeiro alinharam interesses e propuseram tarefas compartilhadas e conjuntos de dados de refer\u00eancia para a pesquisa computacional sistem\u00e1tica sobre afeto, apelo, subjetividade e sentimento em texto.", "token2charspan": [[0, 1], [2, 7], [8, 15], [16, 18], [19, 27], [28, 30], [31, 40], [41, 43], [44, 48], [49, 51], [52, 56], [56, 57], [58, 62], [63, 73], [73, 74], [75, 85], [86, 88], [89, 99], [100, 101], [102, 108], [109, 122], [123, 135], [136, 144], [145, 154], [155, 165], [166, 167], [168, 178], [179, 186], [187, 201], [202, 203], [204, 213], [214, 216], [217, 222], [223, 225], [226, 236], [237, 241], [242, 243], [244, 252], [253, 266], [267, 278], [279, 284], [285, 290], [290, 291], [292, 297], [297, 298], [299, 312], [313, 314], [315, 325], [326, 328], [329, 334], [334, 335]]}
{"doc_key": "ai-test-230", "ner": [[10, 11, "task"], [17, 19, "task"], [21, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Uma", "\u00fanica", "grade", "pode", "ser", "analisada", "tanto", "pelo", "conte\u00fado", "(", "inspe\u00e7\u00e3o", "ocular", ")", "quanto", "pela", "estrutura", "(", "an\u00e1lise", "de", "agrupamento", ",", "an\u00e1lise", "de", "componentes", "principais", ",", "e", "uma", "variedade", "de", "\u00edndices", "estruturais", "relacionados", "\u00e0", "complexidade", "e", "ao", "alcance", "das", "classifica\u00e7\u00f5es", "sendo", "as", "t\u00e9cnicas", "principais", "utilizadas", ")", "."], "sentence-detokenized": "Uma \u00fanica grade pode ser analisada tanto pelo conte\u00fado (inspe\u00e7\u00e3o ocular) quanto pela estrutura (an\u00e1lise de agrupamento, an\u00e1lise de componentes principais, e uma variedade de \u00edndices estruturais relacionados \u00e0 complexidade e ao alcance das classifica\u00e7\u00f5es sendo as t\u00e9cnicas principais utilizadas).", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 20], [21, 24], [25, 34], [35, 40], [41, 45], [46, 54], [55, 56], [56, 64], [65, 71], [71, 72], [73, 79], [80, 84], [85, 94], [95, 96], [96, 103], [104, 106], [107, 118], [118, 119], [120, 127], [128, 130], [131, 142], [143, 153], [153, 154], [155, 156], [157, 160], [161, 170], [171, 173], [174, 181], [182, 193], [194, 206], [207, 208], [209, 221], [222, 223], [224, 226], [227, 234], [235, 238], [239, 253], [254, 259], [260, 262], [263, 271], [272, 282], [283, 293], [293, 294], [294, 295]]}
{"doc_key": "ai-test-231", "ner": [[3, 5, "organisation"], [11, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Em", "2018", ",", "a", "Toyota", "era", "considerada", "como", "estando", "atrasada", "no", "carro", "que", "conduzia", "por", "conta", "pr\u00f3pria", "e", "necessitando", "de", "inova\u00e7\u00e3o", "."], "sentence-detokenized": "Em 2018, a Toyota era considerada como estando atrasada no carro que conduzia por conta pr\u00f3pria e necessitando de inova\u00e7\u00e3o.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 17], [18, 21], [22, 33], [34, 38], [39, 46], [47, 55], [56, 58], [59, 64], [65, 68], [69, 77], [78, 81], [82, 87], [88, 95], [96, 97], [98, 110], [111, 113], [114, 122], [122, 123]]}
{"doc_key": "ai-test-232", "ner": [[39, 41, "misc"], [43, 45, "misc"], [47, 52, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Tais", "alvos", "incluem", "objetos", "naturais", "como", "solo", ",", "mar", ",", "precipita\u00e7\u00e3o", "(", "como", "chuva", ",", "neve", "ou", "granizo", ")", ",", "tempestades", "de", "areia", ",", "animais", "(", "especialmente", "aves", ")", ",", "turbul\u00eancia", "atmosf\u00e9rica", "e", "outros", "efeitos", "atmosf\u00e9ricos", ",", "tais", "como", "reflexos", "da", "ionosfera", ",", "trilhas", "de", "meteoros", "e", "tr\u00eas", "espig\u00f5es", "de", "dispers\u00e3o", "de", "corpos", "."], "sentence-detokenized": "Tais alvos incluem objetos naturais como solo, mar, precipita\u00e7\u00e3o (como chuva, neve ou granizo), tempestades de areia, animais (especialmente aves), turbul\u00eancia atmosf\u00e9rica e outros efeitos atmosf\u00e9ricos, tais como reflexos da ionosfera, trilhas de meteoros e tr\u00eas espig\u00f5es de dispers\u00e3o de corpos.", "token2charspan": [[0, 4], [5, 10], [11, 18], [19, 26], [27, 35], [36, 40], [41, 45], [45, 46], [47, 50], [50, 51], [52, 64], [65, 66], [66, 70], [71, 76], [76, 77], [78, 82], [83, 85], [86, 93], [93, 94], [94, 95], [96, 107], [108, 110], [111, 116], [116, 117], [118, 125], [126, 127], [127, 140], [141, 145], [145, 146], [146, 147], [148, 159], [160, 171], [172, 173], [174, 180], [181, 188], [189, 201], [201, 202], [203, 207], [208, 212], [213, 221], [222, 224], [225, 234], [234, 235], [236, 243], [244, 246], [247, 255], [256, 257], [258, 262], [263, 271], [272, 274], [275, 284], [285, 287], [288, 294], [294, 295]]}
{"doc_key": "ai-test-233", "ner": [[19, 19, "product"], [40, 41, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["No", "planejamento", "e", "controle", ",", "a", "diferen\u00e7a", "essencial", "entre", "os", "human\u00f3ides", "e", "outros", "tipos", "de", "rob\u00f4s", "(", "como", "os", "industriais", ")", "\u00e9", "que", "o", "movimento", "do", "rob\u00f4", "deve", "ser", "semelhante", "ao", "humano", ",", "usando", "locomo\u00e7\u00e3o", "com", "pernas", ",", "especialmente", "a", "locomo\u00e7\u00e3o", "b\u00edpede", "."], "sentence-detokenized": "No planejamento e controle, a diferen\u00e7a essencial entre os human\u00f3ides e outros tipos de rob\u00f4s (como os industriais) \u00e9 que o movimento do rob\u00f4 deve ser semelhante ao humano, usando locomo\u00e7\u00e3o com pernas, especialmente a locomo\u00e7\u00e3o b\u00edpede.", "token2charspan": [[0, 2], [3, 15], [16, 17], [18, 26], [26, 27], [28, 29], [30, 39], [40, 49], [50, 55], [56, 58], [59, 69], [70, 71], [72, 78], [79, 84], [85, 87], [88, 93], [94, 95], [95, 99], [100, 102], [103, 114], [114, 115], [116, 117], [118, 121], [122, 123], [124, 133], [134, 136], [137, 141], [142, 146], [147, 150], [151, 161], [162, 164], [165, 171], [171, 172], [173, 179], [180, 189], [190, 193], [194, 200], [200, 201], [202, 215], [216, 217], [218, 227], [228, 234], [234, 235]]}
{"doc_key": "ai-test-234", "ner": [[1, 3, "algorithm"], [11, 12, "misc"], [15, 15, "metrics"], [20, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "descida", "de", "declive", "pode", "levar", "muitas", "itera\u00e7\u00f5es", "para", "calcular", "um", "m\u00ednimo", "local", "com", "a", "precis\u00e3o", "necess\u00e1ria", ",", "se", "a", "curvatura", "em", "diferentes", "dire\u00e7\u00f5es", "for", "muito", "diferente", "para", "a", "fun\u00e7\u00e3o", "em", "quest\u00e3o", "."], "sentence-detokenized": "A descida de declive pode levar muitas itera\u00e7\u00f5es para calcular um m\u00ednimo local com a precis\u00e3o necess\u00e1ria, se a curvatura em diferentes dire\u00e7\u00f5es for muito diferente para a fun\u00e7\u00e3o em quest\u00e3o.", "token2charspan": [[0, 1], [2, 9], [10, 12], [13, 20], [21, 25], [26, 31], [32, 38], [39, 48], [49, 53], [54, 62], [63, 65], [66, 72], [73, 78], [79, 82], [83, 84], [85, 93], [94, 104], [104, 105], [106, 108], [109, 110], [111, 120], [121, 123], [124, 134], [135, 143], [144, 147], [148, 153], [154, 163], [164, 168], [169, 170], [171, 177], [178, 180], [181, 188], [188, 189]]}
{"doc_key": "ai-test-235", "ner": [[1, 9, "misc"], [14, 14, "misc"], [20, 25, "conference"], [28, 28, "location"], [30, 30, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 9, 14, 14, "part-of", "", true, false], [20, 25, 28, 28, "physical", "", false, true], [28, 28, 30, 30, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "Liga", "de", "Simula\u00e7\u00e3o", "de", "Futebol", "RoboCup", "2D", "de", "1997", "foi", "a", "primeira", "competi\u00e7\u00e3o", "RoboCup", "promovida", "em", "conjunto", "com", "a", "Confer\u00eancia", "Internacional", "Conjunta", "de", "Intelig\u00eancia", "Artificial", "realizada", "em", "Nagoya", ",", "Jap\u00e3o", ",", "de", "23", "a", "29", "de", "agosto", "de", "1997", "."], "sentence-detokenized": "A Liga de Simula\u00e7\u00e3o de Futebol RoboCup 2D de 1997 foi a primeira competi\u00e7\u00e3o RoboCup promovida em conjunto com a Confer\u00eancia Internacional Conjunta de Intelig\u00eancia Artificial realizada em Nagoya, Jap\u00e3o, de 23 a 29 de agosto de 1997.", "token2charspan": [[0, 1], [2, 6], [7, 9], [10, 19], [20, 22], [23, 30], [31, 38], [39, 41], [42, 44], [45, 49], [50, 53], [54, 55], [56, 64], [65, 75], [76, 83], [84, 93], [94, 96], [97, 105], [106, 109], [110, 111], [112, 123], [124, 137], [138, 146], [147, 149], [150, 162], [163, 173], [174, 183], [184, 186], [187, 193], [193, 194], [195, 200], [200, 201], [202, 204], [205, 207], [208, 209], [210, 212], [213, 215], [216, 222], [223, 225], [226, 230], [230, 231]]}
{"doc_key": "ai-test-236", "ner": [[7, 7, "programlang"], [13, 13, "programlang"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Outras", "op\u00e7\u00f5es", "de", "programa\u00e7\u00e3o", "incluem", "um", "ambiente", "Python", "incorporado", ",", "e", "um", "Console", "R", "mais", "suporte", "para", "o", "Rserve", "."], "sentence-detokenized": "Outras op\u00e7\u00f5es de programa\u00e7\u00e3o incluem um ambiente Python incorporado, e um Console R mais suporte para o Rserve.", "token2charspan": [[0, 6], [7, 13], [14, 16], [17, 28], [29, 36], [37, 39], [40, 48], [49, 55], [56, 67], [67, 68], [69, 70], [71, 73], [74, 81], [82, 83], [84, 88], [89, 96], [97, 101], [102, 103], [104, 110], [110, 111]]}
{"doc_key": "ai-test-237", "ner": [[1, 1, "location"], [7, 8, "field"], [10, 10, "field"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [31, 33, "field"], [37, 38, "field"], [41, 43, "field"], [47, 48, "field"], [51, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[13, 14, 10, 10, "related-to", "contributes_to_field", true, false], [16, 17, 10, 10, "related-to", "contributes_to_field", true, false], [19, 20, 10, 10, "related-to", "contributes_to_field", true, false], [41, 43, 37, 38, "part-of", "", false, false], [47, 48, 41, 43, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["De", "Bonn", "ele", "contribuiu", "fundamentalmente", "para", "a", "intelig\u00eancia", "artificial", "e", "rob\u00f3tica", "(", "com", "Wolfram", "Burgard", ",", "Dieter", "Fox", ",", "Sebastian", "Thrun", "entre", "seus", "alunos", ")", ",", "e", "para", "o", "desenvolvimento", "da", "engenharia", "de", "software", ",", "particularmente", "na", "engenharia", "civil", ",", "e", "sistemas", "de", "informa\u00e7\u00e3o", ",", "particularmente", "nas", "geoci\u00eancias", ".", "ganhou", "o", "pr\u00eamio", "AAAI", "Classic", "Paper", "de", "2016.2014", "."], "sentence-detokenized": "De Bonn ele contribuiu fundamentalmente para a intelig\u00eancia artificial e rob\u00f3tica (com Wolfram Burgard, Dieter Fox, Sebastian Thrun entre seus alunos), e para o desenvolvimento da engenharia de software, particularmente na engenharia civil, e sistemas de informa\u00e7\u00e3o, particularmente nas geoci\u00eancias. ganhou o pr\u00eamio AAAI Classic Paper de 2016.2014.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 22], [23, 39], [40, 44], [45, 46], [47, 59], [60, 70], [71, 72], [73, 81], [82, 83], [83, 86], [87, 94], [95, 102], [102, 103], [104, 110], [111, 114], [114, 115], [116, 125], [126, 131], [132, 137], [138, 142], [143, 149], [149, 150], [150, 151], [152, 153], [154, 158], [159, 160], [161, 176], [177, 179], [180, 190], [191, 193], [194, 202], [202, 203], [204, 219], [220, 222], [223, 233], [234, 239], [239, 240], [241, 242], [243, 251], [252, 254], [255, 265], [265, 266], [267, 282], [283, 286], [287, 298], [298, 299], [300, 306], [307, 308], [309, 315], [316, 320], [321, 328], [329, 334], [335, 337], [338, 347], [347, 348]]}
{"doc_key": "ai-test-238", "ner": [[2, 8, "conference"], [16, 17, "location"], [19, 19, "location"], [21, 21, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 8, 16, 17, "physical", "", false, false], [16, 17, 19, 19, "physical", "", false, false], [19, 19, 21, 21, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "primeira", "edi\u00e7\u00e3o", "da", "Campus", "Party", "nos", "EUA", "ocorrer\u00e1", "de", "20", "a", "22", "de", "agosto", "no", "TCF", "Center", "em", "Detroit", ",", "Michigan", "."], "sentence-detokenized": "A primeira edi\u00e7\u00e3o da Campus Party nos EUA ocorrer\u00e1 de 20 a 22 de agosto no TCF Center em Detroit, Michigan.", "token2charspan": [[0, 1], [2, 10], [11, 17], [18, 20], [21, 27], [28, 33], [34, 37], [38, 41], [42, 50], [51, 53], [54, 56], [57, 58], [59, 61], [62, 64], [65, 71], [72, 74], [75, 78], [79, 85], [86, 88], [89, 96], [96, 97], [98, 106], [106, 107]]}
{"doc_key": "ai-test-239", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [11, 12, "misc"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 11, 12, "win-defeat", "", false, false], [5, 6, 11, 12, "win-defeat", "", false, false], [8, 8, 11, 12, "win-defeat", "", false, false], [11, 12, 23, 25, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Junto", "com", "Yann", "LeCun", "e", "Yoshua", "Bengio", ",", "Hinton", "ganhou", "o", "Turing", "Award", "2018", "por", "avan\u00e7os", "conceituais", "e", "de", "engenharia", "que", "fizeram", "das", "redes", "neurais", "profundas", "um", "componente", "cr\u00edtico", "da", "computa\u00e7\u00e3o", "."], "sentence-detokenized": "Junto com Yann LeCun e Yoshua Bengio, Hinton ganhou o Turing Award 2018 por avan\u00e7os conceituais e de engenharia que fizeram das redes neurais profundas um componente cr\u00edtico da computa\u00e7\u00e3o.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 20], [21, 22], [23, 29], [30, 36], [36, 37], [38, 44], [45, 51], [52, 53], [54, 60], [61, 66], [67, 71], [72, 75], [76, 83], [84, 95], [96, 97], [98, 100], [101, 111], [112, 115], [116, 123], [124, 127], [128, 133], [134, 141], [142, 151], [152, 154], [155, 165], [166, 173], [174, 176], [177, 187], [187, 188]]}
{"doc_key": "ai-test-240", "ner": [[0, 2, "product"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 9, 9, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Euler", "Math", "Toolbox", "usa", "uma", "linguagem", "matricial", "semelhante", "\u00e0", "MATLAB", ",", "um", "sistema", "que", "estava", "em", "desenvolvimento", "desde", "os", "anos", "70", "."], "sentence-detokenized": "Euler Math Toolbox usa uma linguagem matricial semelhante \u00e0 MATLAB, um sistema que estava em desenvolvimento desde os anos 70.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 22], [23, 26], [27, 36], [37, 46], [47, 57], [58, 59], [60, 66], [66, 67], [68, 70], [71, 78], [79, 82], [83, 89], [90, 92], [93, 108], [109, 114], [115, 117], [118, 122], [123, 125], [125, 126]]}
{"doc_key": "ai-test-241", "ner": [[12, 12, "programlang"], [14, 15, "programlang"], [17, 17, "programlang"], [19, 19, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Alguns", "idiomas", "tornam", "isso", "poss\u00edvel", "de", "forma", "port\u00e1til", "(", "por", "exemplo", ",", "Scheme", ",", "Common", "Lisp", ",", "Perl", "ou", "D", ")", "."], "sentence-detokenized": "Alguns idiomas tornam isso poss\u00edvel de forma port\u00e1til (por exemplo, Scheme, Common Lisp, Perl ou D).", "token2charspan": [[0, 6], [7, 14], [15, 21], [22, 26], [27, 35], [36, 38], [39, 44], [45, 53], [54, 55], [55, 58], [59, 66], [66, 67], [68, 74], [74, 75], [76, 82], [83, 87], [87, 88], [89, 93], [94, 96], [97, 98], [98, 99], [99, 100]]}
{"doc_key": "ai-test-242", "ner": [[7, 7, "misc"], [9, 10, "researcher"], [12, 13, "researcher"], [25, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 9, 10, "artifact", "", false, false], [7, 7, 12, 13, "artifact", "", false, false], [7, 7, 25, 26, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Em", "1969", ",", "um", "famoso", "livro", "intitulado", "Perceptrons", "de", "Marvin", "Minsky", "e", "Seymour", "Papert", "mostrou", "que", "era", "imposs\u00edvel", "para", "estas", "classes", "de", "rede", "aprender", "uma", "fun\u00e7\u00e3o", "XOR", "."], "sentence-detokenized": "Em 1969, um famoso livro intitulado Perceptrons de Marvin Minsky e Seymour Papert mostrou que era imposs\u00edvel para estas classes de rede aprender uma fun\u00e7\u00e3o XOR.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 18], [19, 24], [25, 35], [36, 47], [48, 50], [51, 57], [58, 64], [65, 66], [67, 74], [75, 81], [82, 89], [90, 93], [94, 97], [98, 108], [109, 113], [114, 119], [120, 127], [128, 130], [131, 135], [136, 144], [145, 148], [149, 155], [156, 159], [159, 160]]}
{"doc_key": "ai-test-243", "ner": [[3, 7, "misc"], [12, 14, "product"], [17, 22, "organisation"], [27, 33, "organisation"], [36, 39, "location"], [41, 41, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[17, 22, 12, 14, "usage", "", false, false], [17, 22, 36, 39, "physical", "", false, false], [27, 33, 17, 22, "named", "", false, false], [36, 39, 41, 41, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Grande", "n\u00famero", "de", "documentos", "cient\u00edficos", "e", "t\u00e9cnicos", "russos", "foram", "traduzidos", "usando", "o", "SYSTRAN", "sob", "os", "ausp\u00edcios", "da", "Divis\u00e3o", "de", "Tecnologia", "Estrangeira", "da", "USAF", "(", "mais", "tarde", "o", "Centro", "Nacional", "de", "Intelig\u00eancia", "A\u00e9rea", "e", "Espacial", ")", "na", "Base", "A\u00e9rea", "de", "Wright-Patterson", ",", "Ohio", "."], "sentence-detokenized": "Grande n\u00famero de documentos cient\u00edficos e t\u00e9cnicos russos foram traduzidos usando o SYSTRAN sob os ausp\u00edcios da Divis\u00e3o de Tecnologia Estrangeira da USAF (mais tarde o Centro Nacional de Intelig\u00eancia A\u00e9rea e Espacial) na Base A\u00e9rea de Wright-Patterson, Ohio.", "token2charspan": [[0, 6], [7, 13], [14, 16], [17, 27], [28, 39], [40, 41], [42, 50], [51, 57], [58, 63], [64, 74], [75, 81], [82, 83], [84, 91], [92, 95], [96, 98], [99, 108], [109, 111], [112, 119], [120, 122], [123, 133], [134, 145], [146, 148], [149, 153], [154, 155], [155, 159], [160, 165], [166, 167], [168, 174], [175, 183], [184, 186], [187, 199], [200, 205], [206, 207], [208, 216], [216, 217], [218, 220], [221, 225], [226, 231], [232, 234], [235, 251], [251, 252], [253, 257], [257, 258]]}
{"doc_key": "ai-test-244", "ner": [[0, 2, "field"], [7, 9, "field"], [20, 21, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "aprendizagem", "semi-supervisionada", "se", "situa", "entre", "a", "aprendizagem", "n\u00e3o", "supervisionada", "(", "sem", "nenhum", "dado", "de", "treinamento", "rotulado", ")", "e", "a", "aprendizagem", "supervisionada", "(", "com", "dados", "de", "treinamento", "completamente", "rotulados", ")", "."], "sentence-detokenized": "A aprendizagem semi-supervisionada se situa entre a aprendizagem n\u00e3o supervisionada (sem nenhum dado de treinamento rotulado) e a aprendizagem supervisionada (com dados de treinamento completamente rotulados).", "token2charspan": [[0, 1], [2, 14], [15, 34], [35, 37], [38, 43], [44, 49], [50, 51], [52, 64], [65, 68], [69, 83], [84, 85], [85, 88], [89, 95], [96, 100], [101, 103], [104, 115], [116, 124], [124, 125], [126, 127], [128, 129], [130, 142], [143, 157], [158, 159], [159, 162], [163, 168], [169, 171], [172, 183], [184, 197], [198, 207], [207, 208], [208, 209]]}
{"doc_key": "ai-test-245", "ner": [[0, 3, "algorithm"], [8, 11, "algorithm"], [30, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 8, 11, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["O", "modelo", "Ann", "-gram", "\u00e9", "um", "tipo", "de", "modelo", "de", "linguagem", "probabil\u00edstica", "para", "prever", "o", "pr\u00f3ximo", "item", "em", "tal", "seq\u00fc\u00eancia", "na", "forma", "de", "um", "(", "n", "-", "1", ")", "-", "modelo", "Markov", "de", "ordem", ".eficiente", "."], "sentence-detokenized": "O modelo Ann -gram \u00e9 um tipo de modelo de linguagem probabil\u00edstica para prever o pr\u00f3ximo item em tal seq\u00fc\u00eancia na forma de um (n - 1) - modelo Markov de ordem .eficiente.", "token2charspan": [[0, 1], [2, 8], [9, 12], [13, 18], [19, 20], [21, 23], [24, 28], [29, 31], [32, 38], [39, 41], [42, 51], [52, 66], [67, 71], [72, 78], [79, 80], [81, 88], [89, 93], [94, 96], [97, 100], [101, 110], [111, 113], [114, 119], [120, 122], [123, 125], [126, 127], [127, 128], [129, 130], [131, 132], [132, 133], [134, 135], [136, 142], [143, 149], [150, 152], [153, 158], [159, 169], [169, 170]]}
{"doc_key": "ai-test-246", "ner": [[1, 2, "organisation"], [5, 5, "product"], [9, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 5, 5, "usage", "", false, false], [9, 17, 1, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "Cl\u00ednica", "Cleveland", "tem", "usado", "Cyc", "para", "desenvolver", "uma", "interface", "de", "consulta", "em", "linguagem", "natural", "de", "informa\u00e7\u00f5es", "biom\u00e9dicas", ",", "abrangendo", "d\u00e9cadas", "de", "informa\u00e7\u00f5es", "sobre", "cirurgias", "cardiotor\u00e1cicas", "."], "sentence-detokenized": "A Cl\u00ednica Cleveland tem usado Cyc para desenvolver uma interface de consulta em linguagem natural de informa\u00e7\u00f5es biom\u00e9dicas, abrangendo d\u00e9cadas de informa\u00e7\u00f5es sobre cirurgias cardiotor\u00e1cicas.", "token2charspan": [[0, 1], [2, 9], [10, 19], [20, 23], [24, 29], [30, 33], [34, 38], [39, 50], [51, 54], [55, 64], [65, 67], [68, 76], [77, 79], [80, 89], [90, 97], [98, 100], [101, 112], [113, 123], [123, 124], [125, 135], [136, 143], [144, 146], [147, 158], [159, 164], [165, 174], [175, 190], [190, 191]]}
{"doc_key": "ai-test-247", "ner": [[7, 8, "country"], [11, 11, "country"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 11, 11, "opposite", "strained_relations", false, false]], "relations_mapping_to_source": [0], "sentence": ["O", "incidente", "tensionou", "as", "rela\u00e7\u00f5es", "entre", "os", "Estados", "Unidos", "e", "o", "Jap\u00e3o", "e", "resultou", "na", "pris\u00e3o", "e", "acusa\u00e7\u00e3o", "de", "dois", "altos", "executivos", ",", "bem", "como", "na", "imposi\u00e7\u00e3o", "de", "san\u00e7\u00f5es", "\u00e0", "empresa", "por", "ambos", "os", "pa\u00edses", "."], "sentence-detokenized": "O incidente tensionou as rela\u00e7\u00f5es entre os Estados Unidos e o Jap\u00e3o e resultou na pris\u00e3o e acusa\u00e7\u00e3o de dois altos executivos, bem como na imposi\u00e7\u00e3o de san\u00e7\u00f5es \u00e0 empresa por ambos os pa\u00edses.", "token2charspan": [[0, 1], [2, 11], [12, 21], [22, 24], [25, 33], [34, 39], [40, 42], [43, 50], [51, 57], [58, 59], [60, 61], [62, 67], [68, 69], [70, 78], [79, 81], [82, 88], [89, 90], [91, 99], [100, 102], [103, 107], [108, 113], [114, 124], [124, 125], [126, 129], [130, 134], [135, 137], [138, 147], [148, 150], [151, 158], [159, 160], [161, 168], [169, 172], [173, 178], [179, 181], [182, 188], [188, 189]]}
{"doc_key": "ai-test-248", "ner": [[7, 9, "algorithm"], [12, 14, "field"], [23, 23, "misc"], [35, 35, "misc"], [40, 41, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 9, 12, 14, "type-of", "", false, false], [23, 23, 12, 14, "part-of", "", true, false], [35, 35, 12, 14, "part-of", "", true, false], [40, 41, 12, 14, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Se", "a", "modelagem", "\u00e9", "feita", "por", "uma", "rede", "neural", "artificial", "ou", "outra", "aprendizagem", "de", "m\u00e1quina", ",", "a", "otimiza\u00e7\u00e3o", "dos", "par\u00e2metros", "\u00e9", "chamada", "de", "treinamento", ",", "enquanto", "a", "otimiza\u00e7\u00e3o", "dos", "hiperpar\u00e2metros", "do", "modelo", "\u00e9", "chamada", "de", "tuning", "e", "muitas", "vezes", "usa", "valida\u00e7\u00e3o", "cruzada", "."], "sentence-detokenized": "Se a modelagem \u00e9 feita por uma rede neural artificial ou outra aprendizagem de m\u00e1quina, a otimiza\u00e7\u00e3o dos par\u00e2metros \u00e9 chamada de treinamento, enquanto a otimiza\u00e7\u00e3o dos hiperpar\u00e2metros do modelo \u00e9 chamada de tuning e muitas vezes usa valida\u00e7\u00e3o cruzada.", "token2charspan": [[0, 2], [3, 4], [5, 14], [15, 16], [17, 22], [23, 26], [27, 30], [31, 35], [36, 42], [43, 53], [54, 56], [57, 62], [63, 75], [76, 78], [79, 86], [86, 87], [88, 89], [90, 100], [101, 104], [105, 115], [116, 117], [118, 125], [126, 128], [129, 140], [140, 141], [142, 150], [151, 152], [153, 163], [164, 167], [168, 183], [184, 186], [187, 193], [194, 195], [196, 203], [204, 206], [207, 213], [214, 215], [216, 222], [223, 228], [229, 232], [233, 242], [243, 250], [250, 251]]}
{"doc_key": "ai-test-249", "ner": [[7, 8, "country"], [10, 10, "country"], [12, 12, "country"], [19, 20, "organisation"], [22, 22, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 20, 22, 22, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "vers\u00f5es", "localizadas", "do", "site", "dispon\u00edveis", "no", "Reino", "Unido", ",", "\u00cdndia", "e", "Austr\u00e1lia", "foram", "descontinuadas", "ap\u00f3s", "a", "aquisi\u00e7\u00e3o", "dos", "tomates", "podres", "pela", "Fandango", "."], "sentence-detokenized": "As vers\u00f5es localizadas do site dispon\u00edveis no Reino Unido, \u00cdndia e Austr\u00e1lia foram descontinuadas ap\u00f3s a aquisi\u00e7\u00e3o dos tomates podres pela Fandango.", "token2charspan": [[0, 2], [3, 10], [11, 22], [23, 25], [26, 30], [31, 42], [43, 45], [46, 51], [52, 57], [57, 58], [59, 64], [65, 66], [67, 76], [77, 82], [83, 97], [98, 102], [103, 104], [105, 114], [115, 118], [119, 126], [127, 133], [134, 138], [139, 147], [147, 148]]}
{"doc_key": "ai-test-250", "ner": [[2, 2, "task"], [11, 11, "metrics"], [27, 29, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 11, 11, "related-to", "", false, false], [11, 11, 27, 29, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["O", "modelo", "NER", "\u00e9", "um", "dos", "v\u00e1rios", "m\u00e9todos", "para", "determinar", "a", "precis\u00e3o", "das", "legendas", "ao", "vivo", "em", "transmiss\u00f5es", "de", "televis\u00e3o", "e", "eventos", "que", "s\u00e3o", "produzidos", "usando", "o", "reconhecimento", "da", "fala", "."], "sentence-detokenized": "O modelo NER \u00e9 um dos v\u00e1rios m\u00e9todos para determinar a precis\u00e3o das legendas ao vivo em transmiss\u00f5es de televis\u00e3o e eventos que s\u00e3o produzidos usando o reconhecimento da fala.", "token2charspan": [[0, 1], [2, 8], [9, 12], [13, 14], [15, 17], [18, 21], [22, 28], [29, 36], [37, 41], [42, 52], [53, 54], [55, 63], [64, 67], [68, 76], [77, 79], [80, 84], [85, 87], [88, 100], [101, 103], [104, 113], [114, 115], [116, 123], [124, 127], [128, 131], [132, 142], [143, 149], [150, 151], [152, 166], [167, 169], [170, 174], [174, 175]]}
{"doc_key": "ai-test-251", "ner": [[0, 1, "researcher"], [4, 6, "university"], [9, 10, "university"], [12, 12, "location"], [15, 19, "university"], [22, 23, "university"], [25, 25, "location"], [29, 34, "university"], [36, 39, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 1, 4, 6, "physical", "", false, false], [0, 1, 4, 6, "role", "", false, false], [0, 1, 9, 10, "physical", "", false, false], [0, 1, 9, 10, "role", "", false, false], [0, 1, 15, 19, "physical", "", false, false], [0, 1, 15, 19, "role", "", false, false], [0, 1, 22, 23, "physical", "", false, false], [0, 1, 22, 23, "role", "", false, false], [0, 1, 29, 34, "physical", "", false, false], [0, 1, 29, 34, "role", "", false, false], [9, 10, 12, 12, "physical", "", false, false], [15, 19, 25, 25, "physical", "", false, false], [22, 23, 25, 25, "physical", "", false, false], [29, 34, 36, 39, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["A", "Atran", "lecionou", "na", "Universidade", "de", "Cambridge", ",", "na", "Universidade", "Hebraica", "em", "Jerusal\u00e9m", ",", "na", "\u00c9cole", "pratique", "des", "hautes", "\u00e9tudes", "e", "na", "\u00c9cole", "Polytechnique", "em", "Paris", ",", "e", "no", "John", "Jay", "College", "of", "Criminal", "Justice", "na", "cidade", "de", "Nova", "York", "."], "sentence-detokenized": "A Atran lecionou na Universidade de Cambridge, na Universidade Hebraica em Jerusal\u00e9m, na \u00c9cole pratique des hautes \u00e9tudes e na \u00c9cole Polytechnique em Paris, e no John Jay College of Criminal Justice na cidade de Nova York.", "token2charspan": [[0, 1], [2, 7], [8, 16], [17, 19], [20, 32], [33, 35], [36, 45], [45, 46], [47, 49], [50, 62], [63, 71], [72, 74], [75, 84], [84, 85], [86, 88], [89, 94], [95, 103], [104, 107], [108, 114], [115, 121], [122, 123], [124, 126], [127, 132], [133, 146], [147, 149], [150, 155], [155, 156], [157, 158], [159, 161], [162, 166], [167, 170], [171, 178], [179, 181], [182, 190], [191, 198], [199, 201], [202, 208], [209, 211], [212, 216], [217, 221], [221, 222]]}
{"doc_key": "ai-test-252", "ner": [[0, 0, "product"], [7, 10, "task"], [14, 15, "researcher"], [17, 17, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 7, 10, "origin", "", false, false], [0, 0, 7, 10, "related-to", "", false, false], [7, 10, 17, 17, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["SHRDLU", "foi", "um", "programa", "de", "computador", "de", "compreens\u00e3o", "da", "linguagem", "natural", ",", "desenvolvido", "por", "Terry", "Winograd", "no", "MIT", "em", "1968-1970"], "sentence-detokenized": "SHRDLU foi um programa de computador de compreens\u00e3o da linguagem natural, desenvolvido por Terry Winograd no MIT em 1968-1970", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 22], [23, 25], [26, 36], [37, 39], [40, 51], [52, 54], [55, 64], [65, 72], [72, 73], [74, 86], [87, 90], [91, 96], [97, 105], [106, 108], [109, 112], [113, 115], [116, 125]]}
{"doc_key": "ai-test-253", "ner": [[3, 3, "misc"], [5, 6, "field"], [8, 11, "university"], [13, 13, "location"], [15, 15, "country"], [24, 26, "university"], [29, 29, "misc"], [31, 34, "field"], [38, 39, "university"], [43, 43, "misc"], [45, 47, "field"], [53, 53, "misc"], [60, 62, "university"], [66, 67, "field"], [71, 72, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "relations": [[3, 3, 5, 6, "topic", "", false, false], [3, 3, 8, 11, "origin", "", false, false], [8, 11, 13, 13, "physical", "", false, false], [8, 11, 24, 26, "role", "affiliated_with", false, false], [13, 13, 15, 15, "physical", "", false, false], [29, 29, 31, 34, "topic", "", false, false], [29, 29, 38, 39, "origin", "", false, false], [43, 43, 45, 47, "topic", "", false, false], [53, 53, 60, 62, "origin", "", false, false], [53, 53, 66, 67, "topic", "", false, false], [71, 72, 60, 62, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Ele", "recebeu", "um", "B.E.", "em", "engenharia", "eletr\u00f4nica", "pelo", "B.M.S.", "College", "of", "Engineering", "em", "Bangalore", ",", "\u00cdndia", ",", "em", "1982", ",", "quando", "foi", "filiado", "\u00e0", "Universidade", "de", "Bangalore", ",", "um", "M.S.", "em", "engenharia", "el\u00e9trica", "e", "inform\u00e1tica", "em", "1984", "pela", "Universidade", "Drexel", ",", "e", "um", "M.S.", "em", "ci\u00eancia", "da", "computa\u00e7\u00e3o", "em", "1989", ",", "e", "um", "Ph.D.", "em", "1990", ",", "respectivamente", ",", "pela", "Universidade", "de", "Wisconsin-Madison", ",", "onde", "estudou", "Intelig\u00eancia", "Artificial", "e", "trabalhou", "com", "Leonard", "Uhr", "."], "sentence-detokenized": "Ele recebeu um B.E. em engenharia eletr\u00f4nica pelo B.M.S. College of Engineering em Bangalore, \u00cdndia, em 1982, quando foi filiado \u00e0 Universidade de Bangalore, um M.S. em engenharia el\u00e9trica e inform\u00e1tica em 1984 pela Universidade Drexel, e um M.S. em ci\u00eancia da computa\u00e7\u00e3o em 1989, e um Ph.D. em 1990, respectivamente, pela Universidade de Wisconsin-Madison, onde estudou Intelig\u00eancia Artificial e trabalhou com Leonard Uhr.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 19], [20, 22], [23, 33], [34, 44], [45, 49], [50, 56], [57, 64], [65, 67], [68, 79], [80, 82], [83, 92], [92, 93], [94, 99], [99, 100], [101, 103], [104, 108], [108, 109], [110, 116], [117, 120], [121, 128], [129, 130], [131, 143], [144, 146], [147, 156], [156, 157], [158, 160], [161, 165], [166, 168], [169, 179], [180, 188], [189, 190], [191, 202], [203, 205], [206, 210], [211, 215], [216, 228], [229, 235], [235, 236], [237, 238], [239, 241], [242, 246], [247, 249], [250, 257], [258, 260], [261, 271], [272, 274], [275, 279], [279, 280], [281, 282], [283, 285], [286, 291], [292, 294], [295, 299], [299, 300], [301, 316], [316, 317], [318, 322], [323, 335], [336, 338], [339, 356], [356, 357], [358, 362], [363, 370], [371, 383], [384, 394], [395, 396], [397, 406], [407, 410], [411, 418], [419, 422], [422, 423]]}
{"doc_key": "ai-test-254", "ner": [[7, 11, "metrics"], [13, 13, "metrics"], [23, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 13, 7, 11, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "precis\u00e3o", "\u00e9", "geralmente", "avaliada", "com", "a", "taxa", "de", "erro", "de", "palavras", "(", "WER", ")", ",", "enquanto", "a", "velocidade", "\u00e9", "medida", "com", "o", "fator", "tempo", "real", "."], "sentence-detokenized": "A precis\u00e3o \u00e9 geralmente avaliada com a taxa de erro de palavras (WER), enquanto a velocidade \u00e9 medida com o fator tempo real.", "token2charspan": [[0, 1], [2, 10], [11, 12], [13, 23], [24, 32], [33, 36], [37, 38], [39, 43], [44, 46], [47, 51], [52, 54], [55, 63], [64, 65], [65, 68], [68, 69], [69, 70], [71, 79], [80, 81], [82, 92], [93, 94], [95, 101], [102, 105], [106, 107], [108, 113], [114, 119], [120, 124], [124, 125]]}
{"doc_key": "ai-test-255", "ner": [[3, 4, "researcher"], [10, 13, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 10, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Em", "1971", ",", "Terry", "Winograd", "desenvolveu", "um", "mecanismo", "inicial", "de", "processamento", "de", "linguagem", "natural", "capaz", "de", "interpretar", "comandos", "escritos", "naturalmente", "dentro", "de", "um", "ambiente", "simples", "e", "governado", "por", "regras", "."], "sentence-detokenized": "Em 1971, Terry Winograd desenvolveu um mecanismo inicial de processamento de linguagem natural capaz de interpretar comandos escritos naturalmente dentro de um ambiente simples e governado por regras.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 35], [36, 38], [39, 48], [49, 56], [57, 59], [60, 73], [74, 76], [77, 86], [87, 94], [95, 100], [101, 103], [104, 115], [116, 124], [125, 133], [134, 146], [147, 153], [154, 156], [157, 159], [160, 168], [169, 176], [177, 178], [179, 188], [189, 192], [193, 199], [199, 200]]}
{"doc_key": "ai-test-256", "ner": [[1, 2, "field"], [4, 5, "researcher"], [7, 9, "researcher"], [11, 12, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 2, 4, 5, "related-to", "", false, false], [1, 2, 7, 9, "related-to", "", false, false], [1, 2, 11, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Na", "intelig\u00eancia", "artificial", ",", "Marvin", "Minsky", ",", "Herbert", "A.", "Simon", "e", "Allen", "Newell", "s\u00e3o", "proeminentes", "."], "sentence-detokenized": "Na intelig\u00eancia artificial, Marvin Minsky, Herbert A. Simon e Allen Newell s\u00e3o proeminentes.", "token2charspan": [[0, 2], [3, 15], [16, 26], [26, 27], [28, 34], [35, 41], [41, 42], [43, 50], [51, 53], [54, 59], [60, 61], [62, 67], [68, 74], [75, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-257", "ner": [[9, 10, "field"], [29, 30, "field"], [32, 34, "field"], [39, 42, "field"], [52, 53, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[29, 30, 9, 10, "origin", "", true, false], [29, 30, 9, 10, "part-of", "", false, false], [29, 30, 39, 42, "compare", "", false, false], [32, 34, 9, 10, "origin", "", true, false], [32, 34, 9, 10, "part-of", "", false, false], [32, 34, 39, 42, "compare", "", false, false], [39, 42, 9, 10, "origin", "", true, false], [39, 42, 9, 10, "part-of", "", false, false], [39, 42, 52, 53, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Na", "segunda", "metade", "do", "s\u00e9culo", "XX", ",", "a", "pr\u00f3pria", "engenharia", "el\u00e9trica", "se", "separou", "em", "v\u00e1rias", "disciplinas", ",", "especializando-se", "no", "projeto", "e", "an\u00e1lise", "de", "sistemas", "que", "manipulam", "sinais", "f\u00edsicos", ";", "engenharia", "eletr\u00f4nica", "e", "engenharia", "de", "computa\u00e7\u00e3o", "como", "exemplos", ";", "enquanto", "a", "engenharia", "de", "projeto", "se", "desenvolveu", "para", "lidar", "com", "o", "projeto", "funcional", "de", "interfaces", "usu\u00e1rio-m\u00e1quina", "."], "sentence-detokenized": "Na segunda metade do s\u00e9culo XX, a pr\u00f3pria engenharia el\u00e9trica se separou em v\u00e1rias disciplinas, especializando-se no projeto e an\u00e1lise de sistemas que manipulam sinais f\u00edsicos; engenharia eletr\u00f4nica e engenharia de computa\u00e7\u00e3o como exemplos; enquanto a engenharia de projeto se desenvolveu para lidar com o projeto funcional de interfaces usu\u00e1rio-m\u00e1quina.", "token2charspan": [[0, 2], [3, 10], [11, 17], [18, 20], [21, 27], [28, 30], [30, 31], [32, 33], [34, 41], [42, 52], [53, 61], [62, 64], [65, 72], [73, 75], [76, 82], [83, 94], [94, 95], [96, 113], [114, 116], [117, 124], [125, 126], [127, 134], [135, 137], [138, 146], [147, 150], [151, 160], [161, 167], [168, 175], [175, 176], [177, 187], [188, 198], [199, 200], [201, 211], [212, 214], [215, 225], [226, 230], [231, 239], [239, 240], [241, 249], [250, 251], [252, 262], [263, 265], [266, 273], [274, 276], [277, 288], [289, 293], [294, 299], [300, 303], [304, 305], [306, 313], [314, 323], [324, 326], [327, 337], [338, 353], [353, 354]]}
{"doc_key": "ai-test-258", "ner": [[7, 7, "metrics"], [9, 11, "metrics"], [13, 13, "metrics"], [49, 51, "metrics"], [58, 60, "metrics"], [64, 70, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 13, 9, 11, "named", "", false, false], [49, 51, 58, 60, "named", "", false, false], [58, 60, 64, 70, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Talvez", "a", "estat\u00edstica", "mais", "simples", "seja", "a", "precis\u00e3o", "ou", "Corre\u00e7\u00e3o", "de", "Fra\u00e7\u00e3o", "(", "FC", ")", ",", "que", "mede", "a", "fra\u00e7\u00e3o", "de", "todas", "as", "inst\u00e2ncias", "que", "est\u00e3o", "corretamente", "categorizadas", ";", "\u00e9", "a", "rela\u00e7\u00e3o", "entre", "o", "n\u00famero", "de", "classifica\u00e7\u00f5es", "corretas", "e", "o", "n\u00famero", "total", "de", "classifica\u00e7\u00f5es", "corretas", "ou", "incorretas", ":", "(", "TP", "+", "TN", ")", "/", "Popula\u00e7\u00e3o", "Total", "=", "(", "TP", "+", "TN", ")", "/", "(", "TP", "+", "TN", "+", "FP", "+", "FN", ")", "."], "sentence-detokenized": "Talvez a estat\u00edstica mais simples seja a precis\u00e3o ou Corre\u00e7\u00e3o de Fra\u00e7\u00e3o (FC), que mede a fra\u00e7\u00e3o de todas as inst\u00e2ncias que est\u00e3o corretamente categorizadas; \u00e9 a rela\u00e7\u00e3o entre o n\u00famero de classifica\u00e7\u00f5es corretas e o n\u00famero total de classifica\u00e7\u00f5es corretas ou incorretas: (TP + TN) / Popula\u00e7\u00e3o Total = (TP + TN) / (TP + TN + FP + FN).", "token2charspan": [[0, 6], [7, 8], [9, 20], [21, 25], [26, 33], [34, 38], [39, 40], [41, 49], [50, 52], [53, 61], [62, 64], [65, 71], [72, 73], [73, 75], [75, 76], [76, 77], [78, 81], [82, 86], [87, 88], [89, 95], [96, 98], [99, 104], [105, 107], [108, 118], [119, 122], [123, 128], [129, 141], [142, 155], [155, 156], [157, 158], [159, 160], [161, 168], [169, 174], [175, 176], [177, 183], [184, 186], [187, 201], [202, 210], [211, 212], [213, 214], [215, 221], [222, 227], [228, 230], [231, 245], [246, 254], [255, 257], [258, 268], [268, 269], [270, 271], [271, 273], [274, 275], [276, 278], [278, 279], [280, 281], [282, 291], [292, 297], [298, 299], [300, 301], [301, 303], [304, 305], [306, 308], [308, 309], [310, 311], [312, 313], [313, 315], [316, 317], [318, 320], [321, 322], [323, 325], [326, 327], [328, 330], [330, 331], [331, 332]]}
{"doc_key": "ai-test-259", "ner": [[15, 23, "conference"], [25, 25, "conference"], [30, 30, "location"], [34, 35, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 23, 30, 30, "physical", "", false, false], [25, 25, 15, 23, "named", "", false, false], [34, 35, 15, 23, "role", "sponsors", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Na", "comunidade", "acad\u00eamica", ",", "os", "principais", "f\u00f3runs", "de", "pesquisa", "come\u00e7aram", "em", "1995", ",", "quando", "a", "Primeira", "Confer\u00eancia", "Internacional", "de", "Descoberta", "de", "Dados", "e", "Conhecimento", "(", "KDD-95", ")", "foi", "iniciada", "em", "Montreal", "sob", "o", "patroc\u00ednio", "da", "AAAI", "."], "sentence-detokenized": "Na comunidade acad\u00eamica, os principais f\u00f3runs de pesquisa come\u00e7aram em 1995, quando a Primeira Confer\u00eancia Internacional de Descoberta de Dados e Conhecimento (KDD-95) foi iniciada em Montreal sob o patroc\u00ednio da AAAI.", "token2charspan": [[0, 2], [3, 13], [14, 23], [23, 24], [25, 27], [28, 38], [39, 45], [46, 48], [49, 57], [58, 67], [68, 70], [71, 75], [75, 76], [77, 83], [84, 85], [86, 94], [95, 106], [107, 120], [121, 123], [124, 134], [135, 137], [138, 143], [144, 145], [146, 158], [159, 160], [160, 166], [166, 167], [168, 171], [172, 180], [181, 183], [184, 192], [193, 196], [197, 198], [199, 209], [210, 212], [213, 217], [217, 218]]}
{"doc_key": "ai-test-260", "ner": [[11, 13, "field"], [15, 17, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Nesta", "abordagem", ",", "os", "modelos", "s\u00e3o", "desenvolvidos", "utilizando", "diferentes", "algoritmos", "de", "minera\u00e7\u00e3o", "de", "dados", ",", "aprendizagem", "de", "m\u00e1quinas", "para", "prever", "a", "classifica\u00e7\u00e3o", "dos", "usu\u00e1rios", "de", "itens", "n\u00e3o", "classificados", "."], "sentence-detokenized": "Nesta abordagem, os modelos s\u00e3o desenvolvidos utilizando diferentes algoritmos de minera\u00e7\u00e3o de dados, aprendizagem de m\u00e1quinas para prever a classifica\u00e7\u00e3o dos usu\u00e1rios de itens n\u00e3o classificados.", "token2charspan": [[0, 5], [6, 15], [15, 16], [17, 19], [20, 27], [28, 31], [32, 45], [46, 56], [57, 67], [68, 78], [79, 81], [82, 91], [92, 94], [95, 100], [100, 101], [102, 114], [115, 117], [118, 126], [127, 131], [132, 138], [139, 140], [141, 154], [155, 158], [159, 167], [168, 170], [171, 176], [177, 180], [181, 194], [194, 195]]}
{"doc_key": "ai-test-261", "ner": [[9, 9, "algorithm"], [13, 14, "algorithm"], [17, 19, "algorithm"], [25, 27, "misc"], [30, 32, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 9, 13, 14, "related-to", "equivalent", false, false], [13, 14, 17, 19, "usage", "", false, false], [17, 19, 30, 32, "usage", "", false, false], [30, 32, 25, 27, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["luz", "da", "discuss\u00e3o", "acima", ",", "vemos", "que", "a", "t\u00e9cnica", "SVM", "\u00e9", "equivalente", "ao", "risco", "emp\u00edrico", "com", "a", "regulariza\u00e7\u00e3o", "de", "Tikhonov", ",", "onde", "neste", "caso", "a", "fun\u00e7\u00e3o", "de", "perda", "\u00e9", "a", "perda", "da", "dobradi\u00e7a"], "sentence-detokenized": "luz da discuss\u00e3o acima, vemos que a t\u00e9cnica SVM \u00e9 equivalente ao risco emp\u00edrico com a regulariza\u00e7\u00e3o de Tikhonov, onde neste caso a fun\u00e7\u00e3o de perda \u00e9 a perda da dobradi\u00e7a", "token2charspan": [[0, 3], [4, 6], [7, 16], [17, 22], [22, 23], [24, 29], [30, 33], [34, 35], [36, 43], [44, 47], [48, 49], [50, 61], [62, 64], [65, 70], [71, 79], [80, 83], [84, 85], [86, 99], [100, 102], [103, 111], [111, 112], [113, 117], [118, 123], [124, 128], [129, 130], [131, 137], [138, 140], [141, 146], [147, 148], [149, 150], [151, 156], [157, 159], [160, 169]]}
{"doc_key": "ai-test-262", "ner": [[7, 8, "person"], [11, 12, "person"], [16, 17, "organisation"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[18, 19, 16, 17, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "edi\u00e7\u00e3o", "de", "2015", "foi", "organizada", "por", "Molly", "McGrath", ",", "com", "Chris", "Rose", "e", "o", "ex-combatente", "da", "UFC", "Kenny", "Florian", "como", "comentaristas", "."], "sentence-detokenized": "A edi\u00e7\u00e3o de 2015 foi organizada por Molly McGrath, com Chris Rose e o ex-combatente da UFC Kenny Florian como comentaristas.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 16], [17, 20], [21, 31], [32, 35], [36, 41], [42, 49], [49, 50], [51, 54], [55, 60], [61, 65], [66, 67], [68, 69], [70, 83], [84, 86], [87, 90], [91, 96], [97, 104], [105, 109], [110, 123], [123, 124]]}
{"doc_key": "ai-test-263", "ner": [[3, 3, "product"], [7, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"], [16, 16, "researcher"], [19, 19, "researcher"], [32, 32, "researcher"], [27, 31, "task"], [33, 33, "product"], [42, 43, "researcher"], [38, 40, "task"], [48, 49, "researcher"], [51, 52, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[3, 3, 7, 9, "origin", "", false, false], [3, 3, 11, 12, "origin", "", false, false], [3, 3, 14, 15, "origin", "", false, false], [3, 3, 16, 16, "origin", "", false, false], [11, 12, 42, 43, "named", "same", false, false], [14, 15, 19, 19, "named", "same", false, false], [14, 15, 32, 32, "named", "same", false, false], [27, 31, 33, 33, "related-to", "", false, false], [33, 33, 32, 32, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Um", "subconjunto", "chamado", "Micro-Planner", "foi", "implementado", "por", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "e", "Terry", "Winograd", "Sussman", ",", "e", "Winograd", "1971", "e", "foi", "usado", "no", "programa", "de", "compreens\u00e3o", "da", "linguagem", "natural", "de", "Winograd", "SHRDLU", ",", "no", "trabalho", "de", "compreens\u00e3o", "da", "hist\u00f3ria", "de", "Eugene", "Charniak", ",", "no", "trabalho", "de", "Thorne", "McCarty", "sobre", "racioc\u00ednio", "legal", ",", "e", "em", "alguns", "outros", "projetos", "."], "sentence-detokenized": "Um subconjunto chamado Micro-Planner foi implementado por Gerald Jay Sussman, Eugene Charniak e Terry Winograd Sussman, e Winograd 1971 e foi usado no programa de compreens\u00e3o da linguagem natural de Winograd SHRDLU, no trabalho de compreens\u00e3o da hist\u00f3ria de Eugene Charniak, no trabalho de Thorne McCarty sobre racioc\u00ednio legal, e em alguns outros projetos.", "token2charspan": [[0, 2], [3, 14], [15, 22], [23, 36], [37, 40], [41, 53], [54, 57], [58, 64], [65, 68], [69, 76], [76, 77], [78, 84], [85, 93], [94, 95], [96, 101], [102, 110], [111, 118], [118, 119], [120, 121], [122, 130], [131, 135], [136, 137], [138, 141], [142, 147], [148, 150], [151, 159], [160, 162], [163, 174], [175, 177], [178, 187], [188, 195], [196, 198], [199, 207], [208, 214], [214, 215], [216, 218], [219, 227], [228, 230], [231, 242], [243, 245], [246, 254], [255, 257], [258, 264], [265, 273], [273, 274], [275, 277], [278, 286], [287, 289], [290, 296], [297, 304], [305, 310], [311, 321], [322, 327], [327, 328], [329, 330], [331, 333], [334, 340], [341, 347], [348, 356], [356, 357]]}
{"doc_key": "ai-test-264", "ner": [[0, 1, "product"], [9, 11, "product"], [14, 18, "task"], [20, 22, "task"], [24, 27, "task"], [29, 30, "task"], [32, 33, "task"], [37, 41, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[9, 11, 0, 1, "usage", "", true, false], [14, 18, 9, 11, "part-of", "", true, false], [20, 22, 9, 11, "part-of", "", true, false], [24, 27, 9, 11, "part-of", "", true, false], [29, 30, 9, 11, "part-of", "", true, false], [32, 33, 9, 11, "part-of", "", true, false], [37, 41, 9, 11, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["O", "WordNet", "tem", "sido", "usado", "para", "diversos", "fins", "em", "sistemas", "de", "informa\u00e7\u00e3o", ",", "incluindo", "desambigua\u00e7\u00e3o", "de", "sentido", "de", "palavras", ",", "recupera\u00e7\u00e3o", "de", "informa\u00e7\u00f5es", ",", "classifica\u00e7\u00e3o", "autom\u00e1tica", "de", "texto", ",", "resumo", "autom\u00e1tico", ",", "tradu\u00e7\u00e3o", "autom\u00e1tica", "e", "at\u00e9", "mesmo", "gera\u00e7\u00e3o", "autom\u00e1tica", "de", "palavras", "cruzadas", "."], "sentence-detokenized": "O WordNet tem sido usado para diversos fins em sistemas de informa\u00e7\u00e3o, incluindo desambigua\u00e7\u00e3o de sentido de palavras, recupera\u00e7\u00e3o de informa\u00e7\u00f5es, classifica\u00e7\u00e3o autom\u00e1tica de texto, resumo autom\u00e1tico, tradu\u00e7\u00e3o autom\u00e1tica e at\u00e9 mesmo gera\u00e7\u00e3o autom\u00e1tica de palavras cruzadas.", "token2charspan": [[0, 1], [2, 9], [10, 13], [14, 18], [19, 24], [25, 29], [30, 38], [39, 43], [44, 46], [47, 55], [56, 58], [59, 69], [69, 70], [71, 80], [81, 94], [95, 97], [98, 105], [106, 108], [109, 117], [117, 118], [119, 130], [131, 133], [134, 145], [145, 146], [147, 160], [161, 171], [172, 174], [175, 180], [180, 181], [182, 188], [189, 199], [199, 200], [201, 209], [210, 220], [221, 222], [223, 226], [227, 232], [233, 240], [241, 251], [252, 254], [255, 263], [264, 272], [272, 273]]}
{"doc_key": "ai-test-265", "ner": [[0, 0, "researcher"], [6, 6, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 6, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Keutzer", "foi", "nomeado", "Fellow", "of", "the", "IEEE", "em", "1996", "."], "sentence-detokenized": "Keutzer foi nomeado Fellow of the IEEE em 1996.", "token2charspan": [[0, 7], [8, 11], [12, 19], [20, 26], [27, 29], [30, 33], [34, 38], [39, 41], [42, 46], [46, 47]]}
{"doc_key": "ai-test-266", "ner": [[8, 10, "algorithm"], [49, 51, "misc"], [60, 61, "algorithm"], [63, 64, "algorithm"], [66, 67, "algorithm"], [70, 71, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[60, 61, 49, 51, "type-of", "", false, false], [63, 64, 49, 51, "type-of", "", false, false], [66, 67, 49, 51, "type-of", "", false, false], [70, 71, 49, 51, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Um", "tipo", "de", "composi\u00e7\u00e3o", "amplamente", "utilizado", "\u00e9", "a", "soma", "n\u00e3o-linear", "ponderada", ",", "onde", "matem\u00e1tica", "f", "(", "x", ")", "=", "K\\", "esquerda", "(", "soma", "_", "i", "w", "_", "i", "g", "_", "i", "(", "x", ")", "\\", "direita", ")", "/", "matem\u00e1tica", ",", "onde", "matem\u00e1tica", "K\\", "/", "matem\u00e1tica", "(", "comumente", "chamada", "de", "fun\u00e7\u00e3o", "de", "ativa\u00e7\u00e3o", ")", "\u00e9", "alguma", "fun\u00e7\u00e3o", "predefinida", ",", "como", "a", "tangente", "hiperb\u00f3lica", ",", "fun\u00e7\u00e3o", "sigm\u00f3ide", ",", "fun\u00e7\u00e3o", "softmax", ",", "ou", "fun\u00e7\u00e3o", "retificadora", "."], "sentence-detokenized": "Um tipo de composi\u00e7\u00e3o amplamente utilizado \u00e9 a soma n\u00e3o-linear ponderada, onde matem\u00e1tica f (x) = K\\ esquerda (soma _ i w _ i g _ i (x)\\ direita) / matem\u00e1tica, onde matem\u00e1tica K\\ / matem\u00e1tica (comumente chamada de fun\u00e7\u00e3o de ativa\u00e7\u00e3o) \u00e9 alguma fun\u00e7\u00e3o predefinida, como a tangente hiperb\u00f3lica, fun\u00e7\u00e3o sigm\u00f3ide, fun\u00e7\u00e3o softmax, ou fun\u00e7\u00e3o retificadora.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 21], [22, 32], [33, 42], [43, 44], [45, 46], [47, 51], [52, 62], [63, 72], [72, 73], [74, 78], [79, 89], [90, 91], [92, 93], [93, 94], [94, 95], [96, 97], [98, 100], [101, 109], [110, 111], [111, 115], [116, 117], [118, 119], [120, 121], [122, 123], [124, 125], [126, 127], [128, 129], [130, 131], [132, 133], [133, 134], [134, 135], [135, 136], [137, 144], [144, 145], [146, 147], [148, 158], [158, 159], [160, 164], [165, 175], [176, 178], [179, 180], [181, 191], [192, 193], [193, 202], [203, 210], [211, 213], [214, 220], [221, 223], [224, 232], [232, 233], [234, 235], [236, 242], [243, 249], [250, 261], [261, 262], [263, 267], [268, 269], [270, 278], [279, 290], [290, 291], [292, 298], [299, 307], [307, 308], [309, 315], [316, 323], [323, 324], [325, 327], [328, 334], [335, 347], [347, 348]]}
{"doc_key": "ai-test-267", "ner": [[2, 2, "misc"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["No", "filme", "Westworld", ",", "rob\u00f4s", "f\u00eameas", "realmente", "se", "envolviam", "em", "rela\u00e7\u00f5es", "sexuais", "com", "homens", "humanos", "como", "parte", "do", "mundo", "do", "faz-de-conta", "de", "f\u00e9rias", "que", "clientes", "humanos", "pagavam", "para", "atender", "."], "sentence-detokenized": "No filme Westworld, rob\u00f4s f\u00eameas realmente se envolviam em rela\u00e7\u00f5es sexuais com homens humanos como parte do mundo do faz-de-conta de f\u00e9rias que clientes humanos pagavam para atender.", "token2charspan": [[0, 2], [3, 8], [9, 18], [18, 19], [20, 25], [26, 32], [33, 42], [43, 45], [46, 55], [56, 58], [59, 67], [68, 75], [76, 79], [80, 86], [87, 94], [95, 99], [100, 105], [106, 108], [109, 114], [115, 117], [118, 130], [131, 133], [134, 140], [141, 144], [145, 153], [154, 161], [162, 169], [170, 174], [175, 182], [182, 183]]}
{"doc_key": "ai-test-268", "ner": [[6, 8, "task"], [25, 29, "task"], [32, 34, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 8, 25, 29, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Normalmente", ",", "o", "processo", "come\u00e7a", "pela", "extra\u00e7\u00e3o", "de", "terminologia", "e", "conceitos", "ou", "frases", "de", "substantivos", "a", "partir", "de", "texto", "simples", "usando", "processadores", "ling\u00fc\u00edsticos", "como", "a", "etiquetagem", "de", "parte", "da", "fala", "e", "o", "agrupamento", "de", "frases", "."], "sentence-detokenized": "Normalmente, o processo come\u00e7a pela extra\u00e7\u00e3o de terminologia e conceitos ou frases de substantivos a partir de texto simples usando processadores ling\u00fc\u00edsticos como a etiquetagem de parte da fala e o agrupamento de frases.", "token2charspan": [[0, 11], [11, 12], [13, 14], [15, 23], [24, 30], [31, 35], [36, 44], [45, 47], [48, 60], [61, 62], [63, 72], [73, 75], [76, 82], [83, 85], [86, 98], [99, 100], [101, 107], [108, 110], [111, 116], [117, 124], [125, 131], [132, 145], [146, 158], [159, 163], [164, 165], [166, 177], [178, 180], [181, 186], [187, 189], [190, 194], [195, 196], [197, 198], [199, 210], [211, 213], [214, 220], [220, 221]]}
{"doc_key": "ai-test-269", "ner": [[15, 17, "field"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[21, 23, 15, 17, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0], "sentence": ["Eles", "demonstraram", "seu", "desempenho", "em", "uma", "s\u00e9rie", "de", "problemas", "de", "interesse", "para", "a", "comunidade", "de", "aprendizagem", "de", "m\u00e1quinas", ",", "incluindo", "o", "reconhecimento", "da", "caligrafia", "."], "sentence-detokenized": "Eles demonstraram seu desempenho em uma s\u00e9rie de problemas de interesse para a comunidade de aprendizagem de m\u00e1quinas, incluindo o reconhecimento da caligrafia.", "token2charspan": [[0, 4], [5, 17], [18, 21], [22, 32], [33, 35], [36, 39], [40, 45], [46, 48], [49, 58], [59, 61], [62, 71], [72, 76], [77, 78], [79, 89], [90, 92], [93, 105], [106, 108], [109, 117], [117, 118], [119, 128], [129, 130], [131, 145], [146, 148], [149, 159], [159, 160]]}
{"doc_key": "ai-test-270", "ner": [[3, 3, "university"], [5, 5, "researcher"], [11, 12, "researcher"], [17, 17, "product"], [21, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 5, 3, 3, "physical", "", false, false], [5, 5, 3, 3, "role", "", false, false], [17, 17, 11, 12, "origin", "", false, false], [17, 17, 21, 22, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Enquanto", "estudava", "em", "Stanford", ",", "Scheinman", "recebeu", "uma", "bolsa", "patrocinada", "por", "George", "Devol", ",", "o", "inventor", "do", "Unimate", ",", "o", "primeiro", "rob\u00f4", "industrial", "."], "sentence-detokenized": "Enquanto estudava em Stanford, Scheinman recebeu uma bolsa patrocinada por George Devol, o inventor do Unimate, o primeiro rob\u00f4 industrial.", "token2charspan": [[0, 8], [9, 17], [18, 20], [21, 29], [29, 30], [31, 40], [41, 48], [49, 52], [53, 58], [59, 70], [71, 74], [75, 81], [82, 87], [87, 88], [89, 90], [91, 99], [100, 102], [103, 110], [110, 111], [112, 113], [114, 122], [123, 127], [128, 138], [138, 139]]}
{"doc_key": "ai-test-271", "ner": [[5, 6, "task"], [9, 12, "metrics"], [14, 14, "metrics"], [24, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 9, 12, "usage", "", true, false], [14, 14, 9, 12, "named", "", false, false], [24, 28, 9, 12, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Embora", "originalmente", "usado", "para", "avaliar", "tradu\u00e7\u00f5es", "autom\u00e1ticas", ",", "o", "subestudo", "de", "avalia\u00e7\u00e3o", "bil\u00edng\u00fce", "(", "BLEU", ")", "tamb\u00e9m", "tem", "sido", "usado", "com", "sucesso", "para", "avaliar", "modelos", "de", "gera\u00e7\u00e3o", "de", "par\u00e1frases", "."], "sentence-detokenized": "Embora originalmente usado para avaliar tradu\u00e7\u00f5es autom\u00e1ticas, o subestudo de avalia\u00e7\u00e3o bil\u00edng\u00fce (BLEU) tamb\u00e9m tem sido usado com sucesso para avaliar modelos de gera\u00e7\u00e3o de par\u00e1frases.", "token2charspan": [[0, 6], [7, 20], [21, 26], [27, 31], [32, 39], [40, 49], [50, 61], [61, 62], [63, 64], [65, 74], [75, 77], [78, 87], [88, 96], [97, 98], [98, 102], [102, 103], [104, 110], [111, 114], [115, 119], [120, 125], [126, 129], [130, 137], [138, 142], [143, 150], [151, 158], [159, 161], [162, 169], [170, 172], [173, 183], [183, 184]]}
{"doc_key": "ai-test-272", "ner": [[0, 1, "organisation"], [7, 9, "organisation"], [12, 12, "organisation"], [16, 16, "product"], [18, 18, "country"], [21, 21, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 7, 9, "role", "licenses_to", false, false], [0, 1, 12, 12, "role", "licenses_to", false, false], [7, 9, 18, 18, "physical", "", false, false], [12, 12, 21, 21, "physical", "", false, false], [16, 16, 7, 9, "artifact", "produces", false, false], [16, 16, 12, 12, "artifact", "produces", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["A", "Unimation", "licenciou", "posteriormente", "sua", "tecnologia", "\u00e0", "Kawasaki", "Heavy", "Industries", "e", "\u00e0", "GKN", ",", "fabricando", "a", "Unimates", "no", "Jap\u00e3o", "e", "na", "Inglaterra", ",", "respectivamente", "."], "sentence-detokenized": "A Unimation licenciou posteriormente sua tecnologia \u00e0 Kawasaki Heavy Industries e \u00e0 GKN, fabricando a Unimates no Jap\u00e3o e na Inglaterra, respectivamente.", "token2charspan": [[0, 1], [2, 11], [12, 21], [22, 36], [37, 40], [41, 51], [52, 53], [54, 62], [63, 68], [69, 79], [80, 81], [82, 83], [84, 87], [87, 88], [89, 99], [100, 101], [102, 110], [111, 113], [114, 119], [120, 121], [122, 124], [125, 135], [135, 136], [137, 152], [152, 153]]}
{"doc_key": "ai-test-273", "ner": [[21, 22, "conference"], [38, 40, "field"], [60, 67, "field"], [69, 69, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[38, 40, 60, 67, "compare", "", false, false], [69, 69, 60, 67, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Grande", "parte", "da", "confus\u00e3o", "entre", "essas", "duas", "comunidades", "de", "pesquisa", "(", "que", "freq\u00fcentemente", "t\u00eam", "confer\u00eancias", "e", "revistas", "separadas", ",", "sendo", "o", "ECML", "PKDD", "uma", "grande", "exce\u00e7\u00e3o", ")", "vem", "das", "suposi\u00e7\u00f5es", "b\u00e1sicas", "com", "as", "quais", "elas", "trabalham", ":", "no", "aprendizado", "de", "m\u00e1quinas", ",", "o", "desempenho", "\u00e9", "geralmente", "avaliado", "com", "rela\u00e7\u00e3o", "\u00e0", "capacidade", "de", "reproduzir", "o", "conhecimento", "conhecido", ",", "enquanto", "que", "na", "descoberta", "do", "conhecimento", "e", "na", "minera\u00e7\u00e3o", "de", "dados", "(", "KDD", ")", "a", "tarefa", "principal", "\u00e9", "a", "descoberta", "de", "conhecimento", "previamente", "desconhecido", "."], "sentence-detokenized": "Grande parte da confus\u00e3o entre essas duas comunidades de pesquisa (que freq\u00fcentemente t\u00eam confer\u00eancias e revistas separadas, sendo o ECML PKDD uma grande exce\u00e7\u00e3o) vem das suposi\u00e7\u00f5es b\u00e1sicas com as quais elas trabalham: no aprendizado de m\u00e1quinas, o desempenho \u00e9 geralmente avaliado com rela\u00e7\u00e3o \u00e0 capacidade de reproduzir o conhecimento conhecido, enquanto que na descoberta do conhecimento e na minera\u00e7\u00e3o de dados (KDD) a tarefa principal \u00e9 a descoberta de conhecimento previamente desconhecido.", "token2charspan": [[0, 6], [7, 12], [13, 15], [16, 24], [25, 30], [31, 36], [37, 41], [42, 53], [54, 56], [57, 65], [66, 67], [67, 70], [71, 85], [86, 89], [90, 102], [103, 104], [105, 113], [114, 123], [123, 124], [125, 130], [131, 132], [133, 137], [138, 142], [143, 146], [147, 153], [154, 161], [161, 162], [163, 166], [167, 170], [171, 181], [182, 189], [190, 193], [194, 196], [197, 202], [203, 207], [208, 217], [217, 218], [219, 221], [222, 233], [234, 236], [237, 245], [245, 246], [247, 248], [249, 259], [260, 261], [262, 272], [273, 281], [282, 285], [286, 293], [294, 295], [296, 306], [307, 309], [310, 320], [321, 322], [323, 335], [336, 345], [345, 346], [347, 355], [356, 359], [360, 362], [363, 373], [374, 376], [377, 389], [390, 391], [392, 394], [395, 404], [405, 407], [408, 413], [414, 415], [415, 418], [418, 419], [420, 421], [422, 428], [429, 438], [439, 440], [441, 442], [443, 453], [454, 456], [457, 469], [470, 481], [482, 494], [494, 495]]}
{"doc_key": "ai-test-274", "ner": [[1, 3, "algorithm"], [11, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 3, 11, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Os", "modelos", "Markov", "ocultos", "s\u00e3o", "a", "base", "para", "a", "maioria", "dos", "sistemas", "modernos", "de", "reconhecimento", "autom\u00e1tico", "da", "fala", "."], "sentence-detokenized": "Os modelos Markov ocultos s\u00e3o a base para a maioria dos sistemas modernos de reconhecimento autom\u00e1tico da fala.", "token2charspan": [[0, 2], [3, 10], [11, 17], [18, 25], [26, 29], [30, 31], [32, 36], [37, 41], [42, 43], [44, 51], [52, 55], [56, 64], [65, 73], [74, 76], [77, 91], [92, 102], [103, 105], [106, 110], [110, 111]]}
{"doc_key": "ai-test-275", "ner": [[3, 3, "location"], [5, 7, "country"], [12, 14, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 5, 7, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "empresa", "em", "Bangalore", ",", "\u00cdndia", ",", "\u00e9", "especializada", "em", "software", "de", "reconhecimento", "de", "caligrafia", "online", "."], "sentence-detokenized": "A empresa em Bangalore, \u00cdndia, \u00e9 especializada em software de reconhecimento de caligrafia online.", "token2charspan": [[0, 1], [2, 9], [10, 12], [13, 22], [22, 23], [24, 29], [29, 30], [31, 32], [33, 46], [47, 49], [50, 58], [59, 61], [62, 76], [77, 79], [80, 90], [91, 97], [97, 98]]}
{"doc_key": "ai-test-276", "ner": [[25, 26, "misc"], [52, 52, "metrics"], [54, 56, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[52, 52, 54, 56, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "tradu\u00e7\u00f5es", "repetidas", "convergem", "em", "uma", "\u00fanica", "express\u00e3o", "em", "ambos", "os", "idiomas", "?", "Isto", "\u00e9", ",", "o", "m\u00e9todo", "de", "tradu\u00e7\u00e3o", "mostra", "estacionaridade", "ou", "produz", "uma", "forma", "can\u00f4nica", "?", "A", "tradu\u00e7\u00e3o", "se", "torna", "estacion\u00e1ria", "sem", "perder", "o", "significado", "original", "?", "Esta", "m\u00e9trica", "tem", "sido", "criticada", "como", "n\u00e3o", "estando", "bem", "correlacionada", "com", "a", "pontua\u00e7\u00e3o", "BLEU", "(", "BiLingual", "Evaluation", "Understudy", ")", "."], "sentence-detokenized": "As tradu\u00e7\u00f5es repetidas convergem em uma \u00fanica express\u00e3o em ambos os idiomas? Isto \u00e9, o m\u00e9todo de tradu\u00e7\u00e3o mostra estacionaridade ou produz uma forma can\u00f4nica? A tradu\u00e7\u00e3o se torna estacion\u00e1ria sem perder o significado original? Esta m\u00e9trica tem sido criticada como n\u00e3o estando bem correlacionada com a pontua\u00e7\u00e3o BLEU (BiLingual Evaluation Understudy).", "token2charspan": [[0, 2], [3, 12], [13, 22], [23, 32], [33, 35], [36, 39], [40, 45], [46, 55], [56, 58], [59, 64], [65, 67], [68, 75], [75, 76], [77, 81], [82, 83], [83, 84], [85, 86], [87, 93], [94, 96], [97, 105], [106, 112], [113, 128], [129, 131], [132, 138], [139, 142], [143, 148], [149, 157], [157, 158], [159, 160], [161, 169], [170, 172], [173, 178], [179, 191], [192, 195], [196, 202], [203, 204], [205, 216], [217, 225], [225, 226], [227, 231], [232, 239], [240, 243], [244, 248], [249, 258], [259, 263], [264, 267], [268, 275], [276, 279], [280, 294], [295, 298], [299, 300], [301, 310], [311, 315], [316, 317], [317, 326], [327, 337], [338, 348], [348, 349], [349, 350]]}
{"doc_key": "ai-test-277", "ner": [[4, 8, "organisation"], [11, 17, "organisation"], [19, 21, "university"], [25, 26, "university"], [27, 28, "field"], [31, 35, "organisation"], [38, 41, "organisation"], [48, 51, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 17, 19, 21, "part-of", "", false, false], [25, 26, 27, 28, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Ele", "tem", "bolsas", "na", "Associa\u00e7\u00e3o", "Americana", "de", "Intelig\u00eancia", "Artificial", ",", "no", "Centro", "de", "Estudos", "Avan\u00e7ados", "em", "Ci\u00eancias", "Comportamentais", "da", "Universidade", "de", "Stanford", ",", "no", "Centro", "MIT", "de", "Ci\u00eancias", "Cognitivas", ",", "no", "Instituto", "Canadense", "de", "Pesquisa", "Avan\u00e7ada", ",", "na", "Associa\u00e7\u00e3o", "Canadense", "de", "Psicologia", ",", "e", "foi", "eleito", "Fellow", "da", "Royal", "Society", "of", "Canada", "em", "1998", "."], "sentence-detokenized": "Ele tem bolsas na Associa\u00e7\u00e3o Americana de Intelig\u00eancia Artificial, no Centro de Estudos Avan\u00e7ados em Ci\u00eancias Comportamentais da Universidade de Stanford, no Centro MIT de Ci\u00eancias Cognitivas, no Instituto Canadense de Pesquisa Avan\u00e7ada, na Associa\u00e7\u00e3o Canadense de Psicologia, e foi eleito Fellow da Royal Society of Canada em 1998.", "token2charspan": [[0, 3], [4, 7], [8, 14], [15, 17], [18, 28], [29, 38], [39, 41], [42, 54], [55, 65], [65, 66], [67, 69], [70, 76], [77, 79], [80, 87], [88, 97], [98, 100], [101, 109], [110, 125], [126, 128], [129, 141], [142, 144], [145, 153], [153, 154], [155, 157], [158, 164], [165, 168], [169, 171], [172, 180], [181, 191], [191, 192], [193, 195], [196, 205], [206, 215], [216, 218], [219, 227], [228, 236], [236, 237], [238, 240], [241, 251], [252, 261], [262, 264], [265, 275], [275, 276], [277, 278], [279, 282], [283, 289], [290, 296], [297, 299], [300, 305], [306, 313], [314, 316], [317, 323], [324, 326], [327, 331], [331, 332]]}
{"doc_key": "ai-test-278", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [16, 18, "misc"], [21, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 16, 18, "part-of", "", false, false], [0, 0, 21, 24, "part-of", "", false, false], [4, 5, 16, 18, "part-of", "", false, false], [4, 5, 21, 24, "part-of", "", false, false], [7, 8, 16, 18, "part-of", "", false, false], [7, 8, 21, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Hinton", "-", "junto", "com", "Yoshua", "Bengio", "e", "Yann", "LeCun", "-", "s\u00e3o", "referidos", "por", "alguns", "como", "os", "Padrinhos", "da", "IA", "e", "os", "Padrinhos", "do", "Aprendizado", "Profundo", "."], "sentence-detokenized": "Hinton - junto com Yoshua Bengio e Yann LeCun - s\u00e3o referidos por alguns como os Padrinhos da IA e os Padrinhos do Aprendizado Profundo.", "token2charspan": [[0, 6], [7, 8], [9, 14], [15, 18], [19, 25], [26, 32], [33, 34], [35, 39], [40, 45], [46, 47], [48, 51], [52, 61], [62, 65], [66, 72], [73, 77], [78, 80], [81, 90], [91, 93], [94, 96], [97, 98], [99, 101], [102, 111], [112, 114], [115, 126], [127, 135], [135, 136]]}
{"doc_key": "ai-test-279", "ner": [[5, 5, "product"], [18, 18, "misc"], [20, 21, "misc"], [22, 22, "product"], [26, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 5, 18, 18, "related-to", "", false, false], [5, 5, 20, 21, "related-to", "", false, false], [18, 18, 22, 22, "named", "same", false, false], [26, 27, 22, 22, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["O", "projeto", "de", "fala", "leve", "eSpeak", ",", "que", "tem", "sua", "pr\u00f3pria", "abordagem", "de", "s\u00edntese", ",", "foi", "experimentado", "com", "mandarim", "e", "canton\u00eas", ".", "eSpeak", "foi", "usado", "pelo", "Google", "Translate", "a", "partir", "de", "maio", "de", "20102010", "."], "sentence-detokenized": "O projeto de fala leve eSpeak, que tem sua pr\u00f3pria abordagem de s\u00edntese, foi experimentado com mandarim e canton\u00eas. eSpeak foi usado pelo Google Translate a partir de maio de 20102010.", "token2charspan": [[0, 1], [2, 9], [10, 12], [13, 17], [18, 22], [23, 29], [29, 30], [31, 34], [35, 38], [39, 42], [43, 50], [51, 60], [61, 63], [64, 71], [71, 72], [73, 76], [77, 90], [91, 94], [95, 103], [104, 105], [106, 114], [114, 115], [116, 122], [123, 126], [127, 132], [133, 137], [138, 144], [145, 154], [155, 156], [157, 163], [164, 166], [167, 171], [172, 174], [175, 183], [183, 184]]}
{"doc_key": "ai-test-280", "ner": [[6, 8, "product"], [12, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 12, 16, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Tamb\u00e9m", "lan\u00e7ado", "em", "1982", ",", "o", "Software", "Boca", "Autom\u00e1tica", "foi", "o", "primeiro", "programa", "comercial", "de", "s\u00edntese", "de", "voz", "totalmente", "em", "software", "."], "sentence-detokenized": "Tamb\u00e9m lan\u00e7ado em 1982, o Software Boca Autom\u00e1tica foi o primeiro programa comercial de s\u00edntese de voz totalmente em software.", "token2charspan": [[0, 6], [7, 14], [15, 17], [18, 22], [22, 23], [24, 25], [26, 34], [35, 39], [40, 50], [51, 54], [55, 56], [57, 65], [66, 74], [75, 84], [85, 87], [88, 95], [96, 98], [99, 102], [103, 113], [114, 116], [117, 125], [125, 126]]}
{"doc_key": "ai-test-281", "ner": [[5, 7, "metrics"], [9, 9, "metrics"], [14, 14, "metrics"], [16, 16, "metrics"], [19, 25, "metrics"], [31, 33, "metrics"], [35, 35, "metrics"], [38, 44, "metrics"], [48, 50, "metrics"], [52, 52, "metrics"], [57, 57, "metrics"], [59, 59, "metrics"], [62, 68, "metrics"], [74, 76, "metrics"], [78, 78, "metrics"], [81, 87, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[9, 9, 5, 7, "named", "", false, false], [14, 14, 5, 7, "named", "", false, false], [16, 16, 5, 7, "named", "", false, false], [19, 25, 5, 7, "named", "", false, false], [35, 35, 31, 33, "named", "", false, false], [38, 44, 31, 33, "named", "", false, false], [52, 52, 48, 50, "named", "", false, false], [57, 57, 48, 50, "named", "", false, false], [59, 59, 48, 50, "named", "", false, false], [62, 68, 48, 50, "named", "", false, false], [78, 78, 74, 76, "named", "", false, false], [81, 87, 74, 76, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Os", "\u00edndices", "de", "coluna", "s\u00e3o", "TRUE", "Positive", "Rate", "(", "TPR", ",", "tamb\u00e9m", "conhecido", "como", "Sensibilidade", "ou", "recall", ")", "(", "TP", "/", "(", "TP", "+", "FN", ")", ")", ",", "com", "o", "complemento", "FALSE", "Negative", "Rate", "(", "FNR", ")", "(", "FN", "/", "(", "TP", "+", "FN", ")", ")", ";", "e", "TRUE", "Negative", "Rate", "(", "TNR", ",", "tamb\u00e9m", "conhecido", "como", "Especificidade", ",", "SPC", ")", "(", "TN", "/", "(", "TN", "+", "FP", ")", ")", ",", "com", "o", "complemento", "FALSE", "Positive", "Rate", "(", "FPR", ")", "(", "FP", "/", "(", "TN", "+", "FP", ")", ")", "."], "sentence-detokenized": "Os \u00edndices de coluna s\u00e3o TRUE Positive Rate (TPR, tamb\u00e9m conhecido como Sensibilidade ou recall) (TP / (TP + FN)), com o complemento FALSE Negative Rate (FNR) (FN / (TP + FN)); e TRUE Negative Rate (TNR, tamb\u00e9m conhecido como Especificidade, SPC) (TN / (TN + FP)), com o complemento FALSE Positive Rate (FPR) (FP / (TN + FP)).", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 20], [21, 24], [25, 29], [30, 38], [39, 43], [44, 45], [45, 48], [48, 49], [50, 56], [57, 66], [67, 71], [72, 85], [86, 88], [89, 95], [95, 96], [97, 98], [98, 100], [101, 102], [103, 104], [104, 106], [107, 108], [109, 111], [111, 112], [112, 113], [113, 114], [115, 118], [119, 120], [121, 132], [133, 138], [139, 147], [148, 152], [153, 154], [154, 157], [157, 158], [159, 160], [160, 162], [163, 164], [165, 166], [166, 168], [169, 170], [171, 173], [173, 174], [174, 175], [175, 176], [177, 178], [179, 183], [184, 192], [193, 197], [198, 199], [199, 202], [202, 203], [204, 210], [211, 220], [221, 225], [226, 240], [240, 241], [242, 245], [245, 246], [247, 248], [248, 250], [251, 252], [253, 254], [254, 256], [257, 258], [259, 261], [261, 262], [262, 263], [263, 264], [265, 268], [269, 270], [271, 282], [283, 288], [289, 297], [298, 302], [303, 304], [304, 307], [307, 308], [309, 310], [310, 312], [313, 314], [315, 316], [316, 318], [319, 320], [321, 323], [323, 324], [324, 325], [325, 326]]}
{"doc_key": "ai-test-282", "ner": [[0, 0, "person"], [2, 2, "person"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 16, 16, "role", "working_with", false, false], [2, 2, 16, 16, "role", "working_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Edsinger", "e", "Weber", "tamb\u00e9m", "colaboraram", "em", "muitos", "outros", "rob\u00f4s", ",", "e", "sua", "experi\u00eancia", "trabalhando", "com", "o", "Kismet"], "sentence-detokenized": "Edsinger e Weber tamb\u00e9m colaboraram em muitos outros rob\u00f4s, e sua experi\u00eancia trabalhando com o Kismet", "token2charspan": [[0, 8], [9, 10], [11, 16], [17, 23], [24, 35], [36, 38], [39, 45], [46, 52], [53, 58], [58, 59], [60, 61], [62, 65], [66, 77], [78, 89], [90, 93], [94, 95], [96, 102]]}
{"doc_key": "ai-test-283", "ner": [[2, 2, "programlang"], [15, 15, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 15, 15, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "funcionalidade", "R", "\u00e9", "acess\u00edvel", "a", "partir", "de", "v\u00e1rias", "linguagens", "de", "script", ",", "tais", "como", "Python", ",", "tamb\u00e9m", "est\u00e3o", "dispon\u00edveis", "."], "sentence-detokenized": "A funcionalidade R \u00e9 acess\u00edvel a partir de v\u00e1rias linguagens de script, tais como Python, tamb\u00e9m est\u00e3o dispon\u00edveis.", "token2charspan": [[0, 1], [2, 16], [17, 18], [19, 20], [21, 30], [31, 32], [33, 39], [40, 42], [43, 49], [50, 60], [61, 63], [64, 70], [70, 71], [72, 76], [77, 81], [82, 88], [88, 89], [90, 96], [97, 102], [103, 114], [114, 115]]}
{"doc_key": "ai-test-284", "ner": [[0, 1, "programlang"], [13, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 14, 0, 1, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["O", "VAL", "foi", "uma", "das", "primeiras", "linguagens", "de", "rob\u00f4s", "e", "foi", "usado", "em", "rob\u00f4s", "Unimate", "."], "sentence-detokenized": "O VAL foi uma das primeiras linguagens de rob\u00f4s e foi usado em rob\u00f4s Unimate.", "token2charspan": [[0, 1], [2, 5], [6, 9], [10, 13], [14, 17], [18, 27], [28, 38], [39, 41], [42, 47], [48, 49], [50, 53], [54, 59], [60, 62], [63, 68], [69, 76], [76, 77]]}
{"doc_key": "ai-test-285", "ner": [[13, 26, "conference"], [23, 23, "conference"], [28, 28, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 26, 28, 28, "physical", "", false, false], [23, 23, 13, 26, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Eles", "apresentaram", "seu", "banco", "de", "dados", "pela", "primeira", "vez", "como", "um", "p\u00f4ster", "na", "Confer\u00eancia", "sobre", "Vis\u00e3o", "e", "Reconhecimento", "de", "Padr\u00f5es", "de", "Computador", "(", "CVPR", ")", "de", "2009", "na", "Fl\u00f3rida", "."], "sentence-detokenized": "Eles apresentaram seu banco de dados pela primeira vez como um p\u00f4ster na Confer\u00eancia sobre Vis\u00e3o e Reconhecimento de Padr\u00f5es de Computador (CVPR) de 2009 na Fl\u00f3rida.", "token2charspan": [[0, 4], [5, 17], [18, 21], [22, 27], [28, 30], [31, 36], [37, 41], [42, 50], [51, 54], [55, 59], [60, 62], [63, 69], [70, 72], [73, 84], [85, 90], [91, 96], [97, 98], [99, 113], [114, 116], [117, 124], [125, 127], [128, 138], [139, 140], [140, 144], [144, 145], [146, 148], [149, 153], [154, 156], [157, 164], [164, 165]]}
{"doc_key": "ai-test-286", "ner": [[0, 3, "misc"], [13, 15, "task"], [17, 19, "field"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 15, 0, 3, "type-of", "", false, false], [17, 19, 0, 3, "type-of", "", false, false], [21, 23, 0, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["As", "tarefas", "de", "categoriza\u00e7\u00e3o", "nas", "quais", "n\u00e3o", "s\u00e3o", "fornecidas", "etiquetas", "s\u00e3o", "referidas", "como", "classifica\u00e7\u00e3o", "n\u00e3o", "supervisionada", ",", "aprendizagem", "n\u00e3o", "supervisionada", ",", "an\u00e1lise", "de", "agrupamento", "."], "sentence-detokenized": "As tarefas de categoriza\u00e7\u00e3o nas quais n\u00e3o s\u00e3o fornecidas etiquetas s\u00e3o referidas como classifica\u00e7\u00e3o n\u00e3o supervisionada, aprendizagem n\u00e3o supervisionada, an\u00e1lise de agrupamento.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 27], [28, 31], [32, 37], [38, 41], [42, 45], [46, 56], [57, 66], [67, 70], [71, 80], [81, 85], [86, 99], [100, 103], [104, 118], [118, 119], [120, 132], [133, 136], [137, 151], [151, 152], [153, 160], [161, 163], [164, 175], [175, 176]]}
{"doc_key": "ai-test-287", "ner": [[2, 4, "task"], [14, 16, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ela", "precisa", "objetivar", "o", "reconhecimento", ",", "reconhecer", "e", "localizar", "os", "seres", "humanos", "e", "mais", "reconhecimento", "das", "emo\u00e7\u00f5es", "."], "sentence-detokenized": "Ela precisa objetivar o reconhecimento, reconhecer e localizar os seres humanos e mais reconhecimento das emo\u00e7\u00f5es.", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 23], [24, 38], [38, 39], [40, 50], [51, 52], [53, 62], [63, 65], [66, 71], [72, 79], [80, 81], [82, 86], [87, 101], [102, 105], [106, 113], [113, 114]]}
{"doc_key": "ai-test-288", "ner": [[7, 7, "misc"], [10, 10, "misc"], [12, 12, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["O", "processo", "\u00e9", "complexo", "e", "cont\u00e9m", "a", "codifica\u00e7\u00e3o", "e", "a", "retirada", "ou", "recupera\u00e7\u00e3o", "."], "sentence-detokenized": "O processo \u00e9 complexo e cont\u00e9m a codifica\u00e7\u00e3o e a retirada ou recupera\u00e7\u00e3o.", "token2charspan": [[0, 1], [2, 10], [11, 12], [13, 21], [22, 23], [24, 30], [31, 32], [33, 44], [45, 46], [47, 48], [49, 57], [58, 60], [61, 72], [72, 73]]}
{"doc_key": "ai-test-289", "ner": [[7, 8, "product"], [12, 13, "product"], [30, 31, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 12, 13, "named", "", false, false], [7, 8, 30, 31, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Tamb\u00e9m", "conhecidos", "como", "rob\u00f4s", "paralelos", ",", "ou", "plataformas", "Stewart", "generalizadas", "(", "na", "plataforma", "Stewart", ",", "os", "atuadores", "s\u00e3o", "emparelhados", "tanto", "na", "base", "quanto", "na", "plataforma", ")", ",", "estes", "sistemas", "s\u00e3o", "rob\u00f4s", "articulados", "que", "utilizam", "mecanismos", "similares", "para", "o", "movimento", "do", "rob\u00f4", "em", "sua", "base", ",", "ou", "de", "um", "ou", "mais", "bra\u00e7os", "manipuladores", "."], "sentence-detokenized": "Tamb\u00e9m conhecidos como rob\u00f4s paralelos, ou plataformas Stewart generalizadas (na plataforma Stewart, os atuadores s\u00e3o emparelhados tanto na base quanto na plataforma), estes sistemas s\u00e3o rob\u00f4s articulados que utilizam mecanismos similares para o movimento do rob\u00f4 em sua base, ou de um ou mais bra\u00e7os manipuladores.", "token2charspan": [[0, 6], [7, 17], [18, 22], [23, 28], [29, 38], [38, 39], [40, 42], [43, 54], [55, 62], [63, 76], [77, 78], [78, 80], [81, 91], [92, 99], [99, 100], [101, 103], [104, 113], [114, 117], [118, 130], [131, 136], [137, 139], [140, 144], [145, 151], [152, 154], [155, 165], [165, 166], [166, 167], [168, 173], [174, 182], [183, 186], [187, 192], [193, 204], [205, 208], [209, 217], [218, 228], [229, 238], [239, 243], [244, 245], [246, 255], [256, 258], [259, 263], [264, 266], [267, 270], [271, 275], [275, 276], [277, 279], [280, 282], [283, 285], [286, 288], [289, 293], [294, 300], [301, 314], [314, 315]]}
{"doc_key": "ai-test-290", "ner": [[0, 2, "field"], [6, 8, "field"], [14, 15, "field"], [20, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 6, 8, "part-of", "subfield", false, false], [0, 2, 14, 15, "compare", "", false, false], [14, 15, 20, 22, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "vis\u00e3o", "mec\u00e2nica", "como", "disciplina", "de", "engenharia", "de", "sistemas", "pode", "ser", "considerada", "distinta", "da", "vis\u00e3o", "computacional", ",", "uma", "forma", "de", "ci\u00eancia", "da", "computa\u00e7\u00e3o", "."], "sentence-detokenized": "A vis\u00e3o mec\u00e2nica como disciplina de engenharia de sistemas pode ser considerada distinta da vis\u00e3o computacional, uma forma de ci\u00eancia da computa\u00e7\u00e3o.", "token2charspan": [[0, 1], [2, 7], [8, 16], [17, 21], [22, 32], [33, 35], [36, 46], [47, 49], [50, 58], [59, 63], [64, 67], [68, 79], [80, 88], [89, 91], [92, 97], [98, 111], [111, 112], [113, 116], [117, 122], [123, 125], [126, 133], [134, 136], [137, 147], [147, 148]]}
{"doc_key": "ai-test-291", "ner": [[5, 6, "algorithm"], [11, 13, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 11, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "fun\u00e7\u00e3o", "de", "ativa\u00e7\u00e3o", "dos", "port\u00f5es", "LSTM", "\u00e9", "muitas", "vezes", "a", "fun\u00e7\u00e3o", "sigm\u00f3ide", "log\u00edstica", "."], "sentence-detokenized": "A fun\u00e7\u00e3o de ativa\u00e7\u00e3o dos port\u00f5es LSTM \u00e9 muitas vezes a fun\u00e7\u00e3o sigm\u00f3ide log\u00edstica.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 20], [21, 24], [25, 32], [33, 37], [38, 39], [40, 46], [47, 52], [53, 54], [55, 61], [62, 70], [71, 80], [80, 81]]}
{"doc_key": "ai-test-292", "ner": [[5, 6, "metrics"], [21, 26, "metrics"], [28, 28, "metrics"], [35, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 21, 26, "named", "", false, false], [5, 6, 35, 38, "named", "", false, false], [28, 28, 21, 26, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Em", "outras", "palavras", ",", "a", "m\u00e9dia", "amostral", "\u00e9", "o", "estimador", "(", "necessariamente", "\u00fanico", ")", "eficiente", "e", ",", "portanto", ",", "tamb\u00e9m", "o", "estimador", "de", "vari\u00e2ncia", "m\u00ednima", "n\u00e3o", "tendenciosa", "(", "MVUE", ")", ",", "al\u00e9m", "de", "ser", "o", "estimador", "de", "m\u00e1xima", "probabilidade", "."], "sentence-detokenized": "Em outras palavras, a m\u00e9dia amostral \u00e9 o estimador (necessariamente \u00fanico) eficiente e, portanto, tamb\u00e9m o estimador de vari\u00e2ncia m\u00ednima n\u00e3o tendenciosa (MVUE), al\u00e9m de ser o estimador de m\u00e1xima probabilidade.", "token2charspan": [[0, 2], [3, 9], [10, 18], [18, 19], [20, 21], [22, 27], [28, 36], [37, 38], [39, 40], [41, 50], [51, 52], [52, 67], [68, 73], [73, 74], [75, 84], [85, 86], [86, 87], [88, 96], [96, 97], [98, 104], [105, 106], [107, 116], [117, 119], [120, 129], [130, 136], [137, 140], [141, 152], [153, 154], [154, 158], [158, 159], [159, 160], [161, 165], [166, 168], [169, 172], [173, 174], [175, 184], [185, 187], [188, 194], [195, 208], [208, 209]]}
{"doc_key": "ai-test-293", "ner": [[2, 4, "academicjournal"], [7, 7, "researcher"], [9, 10, "researcher"], [12, 13, "researcher"], [19, 19, "product"], [23, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 4, 19, 19, "topic", "", false, false], [2, 4, 23, 24, "topic", "", false, false], [7, 7, 2, 4, "role", "", false, false], [9, 10, 2, 4, "role", "", false, false], [12, 13, 2, 4, "role", "", false, false], [19, 19, 23, 24, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["O", "artigo", "cient\u00edfico", "americano", "de", "2001", "de", "Berners-Lee", ",", "James", "Hendler", "e", "Ora", "Lassila", "descreveu", "uma", "evolu\u00e7\u00e3o", "esperada", "da", "Web", "existente", "para", "uma", "Web", "Sem\u00e2ntica", "."], "sentence-detokenized": "O artigo cient\u00edfico americano de 2001 de Berners-Lee, James Hendler e Ora Lassila descreveu uma evolu\u00e7\u00e3o esperada da Web existente para uma Web Sem\u00e2ntica.", "token2charspan": [[0, 1], [2, 8], [9, 19], [20, 29], [30, 32], [33, 37], [38, 40], [41, 52], [52, 53], [54, 59], [60, 67], [68, 69], [70, 73], [74, 81], [82, 91], [92, 95], [96, 104], [105, 113], [114, 116], [117, 120], [121, 130], [131, 135], [136, 139], [140, 143], [144, 153], [153, 154]]}
{"doc_key": "ai-test-294", "ner": [[0, 1, "misc"], [11, 12, "person"], [14, 14, "person"], [26, 26, "person"], [34, 34, "person"], [39, 40, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 12, 0, 1, "role", "actor_in_work", false, false], [14, 14, 11, 12, "named", "", false, false], [14, 14, 11, 12, "origin", "", false, false], [26, 26, 14, 14, "part-of", "", false, false], [39, 40, 14, 14, "role", "auditioned_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Blade", "Runner", "usou", "uma", "s\u00e9rie", "de", "atores", "ent\u00e3o", "menos", "conhecidos", ":", "Sean", "Young", "retrata", "Rachael", ",", "um", "replicante", "experimental", "implantado", "com", "as", "mem\u00f3rias", "da", "sobrinha", "de", "Tyrell", ",", "fazendo-a", "acreditar", "que", "\u00e9", "humana", ";", "Sammon", ",", "pp", ".", "92-93", "Nina", "Axelrod", "fez", "uma", "audi\u00e7\u00e3o", "para", "o", "papel", "."], "sentence-detokenized": "Blade Runner usou uma s\u00e9rie de atores ent\u00e3o menos conhecidos: Sean Young retrata Rachael, um replicante experimental implantado com as mem\u00f3rias da sobrinha de Tyrell, fazendo-a acreditar que \u00e9 humana; Sammon, pp. 92-93 Nina Axelrod fez uma audi\u00e7\u00e3o para o papel.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 21], [22, 27], [28, 30], [31, 37], [38, 43], [44, 49], [50, 60], [60, 61], [62, 66], [67, 72], [73, 80], [81, 88], [88, 89], [90, 92], [93, 103], [104, 116], [117, 127], [128, 131], [132, 134], [135, 143], [144, 146], [147, 155], [156, 158], [159, 165], [165, 166], [167, 176], [177, 186], [187, 190], [191, 192], [193, 199], [199, 200], [201, 207], [207, 208], [209, 211], [211, 212], [213, 218], [219, 223], [224, 231], [232, 235], [236, 239], [240, 247], [248, 252], [253, 254], [255, 260], [260, 261]]}
{"doc_key": "ai-test-295", "ner": [[0, 1, "researcher"], [3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [13, 15, "university"], [22, 22, "product"], [24, 24, "product"], [44, 44, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 13, 15, "physical", "", false, false], [3, 4, 13, 15, "physical", "", false, false], [6, 7, 13, 15, "physical", "", false, false], [9, 10, 13, 15, "physical", "", false, false], [13, 15, 44, 44, "physical", "", true, false], [22, 22, 13, 15, "temporal", "", false, false], [24, 24, 13, 15, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Gerry", "Sussman", ",", "Eugene", "Charniak", ",", "Seymour", "Papert", "e", "Terry", "Winograd", "visitaram", "a", "Universidade", "de", "Edimburgo", "em", "1971", "divulgando", "as", "not\u00edcias", "sobre", "Micro-Planner", "e", "SHRDLU", "e", "lan\u00e7ando", "d\u00favidas", "sobre", "o", "procedimento", "de", "prova", "uniforme", "de", "resolu\u00e7\u00e3o", "que", "tinha", "sido", "a", "base", "da", "L\u00f3gica", "de", "Edimburgo", "."], "sentence-detokenized": "Gerry Sussman, Eugene Charniak, Seymour Papert e Terry Winograd visitaram a Universidade de Edimburgo em 1971 divulgando as not\u00edcias sobre Micro-Planner e SHRDLU e lan\u00e7ando d\u00favidas sobre o procedimento de prova uniforme de resolu\u00e7\u00e3o que tinha sido a base da L\u00f3gica de Edimburgo.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 21], [22, 30], [30, 31], [32, 39], [40, 46], [47, 48], [49, 54], [55, 63], [64, 73], [74, 75], [76, 88], [89, 91], [92, 101], [102, 104], [105, 109], [110, 120], [121, 123], [124, 132], [133, 138], [139, 152], [153, 154], [155, 161], [162, 163], [164, 172], [173, 180], [181, 186], [187, 188], [189, 201], [202, 204], [205, 210], [211, 219], [220, 222], [223, 232], [233, 236], [237, 242], [243, 247], [248, 249], [250, 254], [255, 257], [258, 264], [265, 267], [268, 277], [277, 278]]}
{"doc_key": "ai-test-296", "ner": [[3, 3, "researcher"], [10, 12, "field"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 13, 14, "role", "inspires", false, false], [3, 3, 16, 17, "role", "inspires", false, false], [3, 3, 19, 20, "role", "inspires", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["O", "trabalho", "de", "Walter", "inspirou", "gera\u00e7\u00f5es", "posteriores", "de", "pesquisadores", "de", "rob\u00f3tica", ",", "como", "Rodney", "Brooks", ",", "Hans", "Moravec", "e", "Mark", "Tilden", "."], "sentence-detokenized": "O trabalho de Walter inspirou gera\u00e7\u00f5es posteriores de pesquisadores de rob\u00f3tica, como Rodney Brooks, Hans Moravec e Mark Tilden.", "token2charspan": [[0, 1], [2, 10], [11, 13], [14, 20], [21, 29], [30, 38], [39, 50], [51, 53], [54, 67], [68, 70], [71, 79], [79, 80], [81, 85], [86, 92], [93, 99], [99, 100], [101, 105], [106, 113], [114, 115], [116, 120], [121, 127], [127, 128]]}
{"doc_key": "ai-test-297", "ner": [[3, 3, "algorithm"], [9, 10, "researcher"], [16, 24, "event"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 9, 10, "origin", "", false, false], [3, 3, 16, 24, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Posteriormente", ",", "uma", "CNN", "semelhante", "baseada", "em", "GPU", "por", "Alex", "Krizhevsky", "et", "al", ".", "ganhou", "o", "Desafio", "de", "Reconhecimento", "Visual", "em", "Grande", "Escala", "ImageNet", "2012", "."], "sentence-detokenized": "Posteriormente, uma CNN semelhante baseada em GPU por Alex Krizhevsky et al. ganhou o Desafio de Reconhecimento Visual em Grande Escala ImageNet 2012.", "token2charspan": [[0, 14], [14, 15], [16, 19], [20, 23], [24, 34], [35, 42], [43, 45], [46, 49], [50, 53], [54, 58], [59, 69], [70, 72], [73, 75], [75, 76], [77, 83], [84, 85], [86, 93], [94, 96], [97, 111], [112, 118], [119, 121], [122, 128], [129, 135], [136, 144], [145, 149], [149, 150]]}
{"doc_key": "ai-test-298", "ner": [[0, 3, "misc"], [11, 13, "metrics"], [16, 17, "metrics"], [22, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 13, 0, 3, "type-of", "", false, false], [16, 17, 0, 3, "type-of", "", false, false], [16, 17, 22, 26, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["As", "fun\u00e7\u00f5es", "de", "perda", "comumente", "usadas", "para", "classifica\u00e7\u00e3o", "probabil\u00edstica", "incluem", "a", "perda", "de", "log", "e", "a", "pontua\u00e7\u00e3o", "Brier", "entre", "a", "distribui\u00e7\u00e3o", "de", "probabilidade", "prevista", "e", "a", "VERDADEIRA", "."], "sentence-detokenized": "As fun\u00e7\u00f5es de perda comumente usadas para classifica\u00e7\u00e3o probabil\u00edstica incluem a perda de log e a pontua\u00e7\u00e3o Brier entre a distribui\u00e7\u00e3o de probabilidade prevista e a VERDADEIRA.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 19], [20, 29], [30, 36], [37, 41], [42, 55], [56, 70], [71, 78], [79, 80], [81, 86], [87, 89], [90, 93], [94, 95], [96, 97], [98, 107], [108, 113], [114, 119], [120, 121], [122, 134], [135, 137], [138, 151], [152, 160], [161, 162], [163, 164], [165, 175], [175, 176]]}
{"doc_key": "ai-test-299", "ner": [[5, 6, "organisation"], [14, 14, "field"], [16, 16, "organisation"], [20, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 14, 14, "general-affiliation", "field_of_study", false, false], [5, 6, 20, 21, "part-of", "", false, false], [16, 16, 5, 6, "role", "admits_E2_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Em", "maio", "de", "2016", ",", "o", "NtechLab", "foi", "admitido", "no", "teste", "oficial", "de", "tecnologia", "biom\u00e9trica", "pelo", "NIST", "entre", "as", "tr\u00eas", "empresas", "russas", "."], "sentence-detokenized": "Em maio de 2016, o NtechLab foi admitido no teste oficial de tecnologia biom\u00e9trica pelo NIST entre as tr\u00eas empresas russas.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 15], [15, 16], [17, 18], [19, 27], [28, 31], [32, 40], [41, 43], [44, 49], [50, 57], [58, 60], [61, 71], [72, 82], [83, 87], [88, 92], [93, 98], [99, 101], [102, 106], [107, 115], [116, 122], [122, 123]]}
{"doc_key": "ai-test-300", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["No", "entanto", ",", "os", "n\u00fameros", "de", "ponto", "flutuante", "t\u00eam", "apenas", "uma", "certa", "precis\u00e3o", "matem\u00e1tica", "."], "sentence-detokenized": "No entanto, os n\u00fameros de ponto flutuante t\u00eam apenas uma certa precis\u00e3o matem\u00e1tica.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 14], [15, 22], [23, 25], [26, 31], [32, 41], [42, 45], [46, 52], [53, 56], [57, 62], [63, 71], [72, 82], [82, 83]]}
{"doc_key": "ai-test-301", "ner": [[7, 7, "organisation"], [11, 18, "conference"], [20, 20, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 11, 18, "role", "contributes_to", false, false], [20, 20, 11, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Durante", "2015", ",", "muitos", "dos", "trabalhos", "do", "SenseTime", "foram", "aceitos", "na", "Confer\u00eancia", "sobre", "Vis\u00e3o", "Computadorizada", "e", "Reconhecimento", "de", "Padr\u00f5es", "(", "CVPR", ")", "."], "sentence-detokenized": "Durante 2015, muitos dos trabalhos do SenseTime foram aceitos na Confer\u00eancia sobre Vis\u00e3o Computadorizada e Reconhecimento de Padr\u00f5es (CVPR).", "token2charspan": [[0, 7], [8, 12], [12, 13], [14, 20], [21, 24], [25, 34], [35, 37], [38, 47], [48, 53], [54, 61], [62, 64], [65, 76], [77, 82], [83, 88], [89, 104], [105, 106], [107, 121], [122, 124], [125, 132], [133, 134], [134, 138], [138, 139], [139, 140]]}
{"doc_key": "ai-test-302", "ner": [[5, 7, "task"], [9, 9, "task"], [12, 13, "task"], [15, 18, "task"], [21, 21, "field"], [23, 26, "misc"], [28, 36, "conference"], [44, 46, "misc"], [48, 49, "conference"], [64, 67, "misc"], [69, 69, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[5, 7, 21, 21, "part-of", "task_part_of_field", false, false], [9, 9, 5, 7, "named", "", false, false], [12, 13, 21, 21, "part-of", "task_part_of_field", false, false], [15, 18, 12, 13, "named", "", false, false], [23, 26, 28, 36, "temporal", "", false, false], [44, 46, 48, 49, "temporal", "", false, false], [64, 67, 69, 69, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Ele", "co-desenvolveu", "algoritmos", "\u00f3timos", "para", "Estrutura", "do", "Movimento", "(", "SFM", ",", "ou", "Visual", "SLAM", ",", "localiza\u00e7\u00e3o", "e", "mapeamento", "simult\u00e2neos", ",", "em", "Rob\u00f3tica", ";", "Pr\u00eamio", "de", "Melhor", "Papel", "na", "Confer\u00eancia", "sobre", "Vis\u00e3o", "e", "Reconhecimento", "de", "Padr\u00f5es", "de", "Computador", "1998", ")", ",", "caracterizou", "suas", "ambig\u00fcidades", "(", "Pr\u00eamio", "David", "Marr", "no", "ICCV", "1999", ")", ",", "tamb\u00e9m", "caracterizou", "a", "identificabilidade", "e", "observabilidade", "da", "fus\u00e3o", "de", "sensores", "visuais-inerciais", "(", "Pr\u00eamio", "de", "Melhor", "Papel", "na", "Rob\u00f3tica", "2015", ")", "."], "sentence-detokenized": "Ele co-desenvolveu algoritmos \u00f3timos para Estrutura do Movimento (SFM, ou Visual SLAM, localiza\u00e7\u00e3o e mapeamento simult\u00e2neos, em Rob\u00f3tica; Pr\u00eamio de Melhor Papel na Confer\u00eancia sobre Vis\u00e3o e Reconhecimento de Padr\u00f5es de Computador 1998), caracterizou suas ambig\u00fcidades (Pr\u00eamio David Marr no ICCV 1999), tamb\u00e9m caracterizou a identificabilidade e observabilidade da fus\u00e3o de sensores visuais-inerciais (Pr\u00eamio de Melhor Papel na Rob\u00f3tica 2015).", "token2charspan": [[0, 3], [4, 18], [19, 29], [30, 36], [37, 41], [42, 51], [52, 54], [55, 64], [65, 66], [66, 69], [69, 70], [71, 73], [74, 80], [81, 85], [85, 86], [87, 98], [99, 100], [101, 111], [112, 123], [123, 124], [125, 127], [128, 136], [136, 137], [138, 144], [145, 147], [148, 154], [155, 160], [161, 163], [164, 175], [176, 181], [182, 187], [188, 189], [190, 204], [205, 207], [208, 215], [216, 218], [219, 229], [230, 234], [234, 235], [235, 236], [237, 249], [250, 254], [255, 267], [268, 269], [269, 275], [276, 281], [282, 286], [287, 289], [290, 294], [295, 299], [299, 300], [300, 301], [302, 308], [309, 321], [322, 323], [324, 342], [343, 344], [345, 360], [361, 363], [364, 369], [370, 372], [373, 381], [382, 399], [400, 401], [401, 407], [408, 410], [411, 417], [418, 423], [424, 426], [427, 435], [436, 440], [440, 441], [441, 442]]}
{"doc_key": "ai-test-303", "ner": [[0, 2, "researcher"], [3, 3, "organisation"], [5, 5, "organisation"], [7, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Stephen", "H.", "Muggleton", "FBCS", ",", "FIET", ",", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ","], "sentence-detokenized": "Stephen H. Muggleton FBCS, FIET, Association for the Advancement of Artificial Intelligence,", "token2charspan": [[0, 7], [8, 10], [11, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 44], [45, 48], [49, 52], [53, 64], [65, 67], [68, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-304", "ner": [[0, 3, "task"], [9, 11, "field"], [13, 14, "field"], [16, 17, "field"], [23, 25, "task"], [27, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 3, 9, 11, "part-of", "task_part_of_field", false, false], [0, 3, 13, 14, "part-of", "task_part_of_field", false, false], [0, 3, 16, 17, "part-of", "task_part_of_field", false, false], [0, 3, 23, 25, "part-of", "", false, false], [0, 3, 27, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["A", "detec\u00e7\u00e3o", "de", "bordas", "\u00e9", "uma", "ferramenta", "fundamental", "no", "processamento", "de", "imagens", ",", "vis\u00e3o", "mec\u00e2nica", "e", "vis\u00e3o", "computadorizada", ",", "particularmente", "nas", "\u00e1reas", "de", "detec\u00e7\u00e3o", "de", "caracter\u00edsticas", "e", "extra\u00e7\u00e3o", "de", "caracter\u00edsticas", "."], "sentence-detokenized": "A detec\u00e7\u00e3o de bordas \u00e9 uma ferramenta fundamental no processamento de imagens, vis\u00e3o mec\u00e2nica e vis\u00e3o computadorizada, particularmente nas \u00e1reas de detec\u00e7\u00e3o de caracter\u00edsticas e extra\u00e7\u00e3o de caracter\u00edsticas.", "token2charspan": [[0, 1], [2, 10], [11, 13], [14, 20], [21, 22], [23, 26], [27, 37], [38, 49], [50, 52], [53, 66], [67, 69], [70, 77], [77, 78], [79, 84], [85, 93], [94, 95], [96, 101], [102, 117], [117, 118], [119, 134], [135, 138], [139, 144], [145, 147], [148, 156], [157, 159], [160, 175], [176, 177], [178, 186], [187, 189], [190, 205], [205, 206]]}
{"doc_key": "ai-test-305", "ner": [[8, 9, "misc"], [27, 30, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Um", "exemplo", "disso", "seria", "uma", "vari\u00e1vel", "como", "a", "temperatura", "externa", "(", "temperatura", "matem\u00e1tica", "/", "matem\u00e1tica", ")", ",", "que", "em", "uma", "determinada", "aplica\u00e7\u00e3o", "poderia", "ser", "registrada", "com", "v\u00e1rias", "casas", "decimais", "de", "precis\u00e3o", "(", "dependendo", "do", "aparelho", "sensor", ")", "."], "sentence-detokenized": "Um exemplo disso seria uma vari\u00e1vel como a temperatura externa (temperatura matem\u00e1tica / matem\u00e1tica), que em uma determinada aplica\u00e7\u00e3o poderia ser registrada com v\u00e1rias casas decimais de precis\u00e3o (dependendo do aparelho sensor).", "token2charspan": [[0, 2], [3, 10], [11, 16], [17, 22], [23, 26], [27, 35], [36, 40], [41, 42], [43, 54], [55, 62], [63, 64], [64, 75], [76, 86], [87, 88], [89, 99], [99, 100], [100, 101], [102, 105], [106, 108], [109, 112], [113, 124], [125, 134], [135, 142], [143, 146], [147, 157], [158, 161], [162, 168], [169, 174], [175, 183], [184, 186], [187, 195], [196, 197], [197, 207], [208, 210], [211, 219], [220, 226], [226, 227], [227, 228]]}
{"doc_key": "ai-test-306", "ner": [[5, 6, "person"], [8, 9, "person"], [11, 12, "person"], [20, 21, "person"], [25, 25, "misc"], [29, 29, "misc"], [30, 31, "person"], [36, 36, "organisation"], [33, 35, "person"], [48, 48, "organisation"], [38, 39, "person"], [44, 44, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[30, 31, 25, 25, "part-of", "", false, false], [30, 31, 29, 29, "role", "", false, false], [33, 35, 36, 36, "role", "", false, false], [38, 39, 48, 48, "role", "youtuber", false, false], [44, 44, 38, 39, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Os", "ju\u00edzes", "que", "retornam", "s\u00e3o", "Fon", "Davis", ",", "Jessica", "Chobot", "e", "Leland", "Melvin", ",", "bem", "como", "o", "famoso", "ator", "convidado", "Clark", "Gregg", ",", "anfitri\u00e3o", "do", "MythBusters", "e", "ex-construtor", "do", "Battlebots", "Adam", "Savage", ",", "Vernon", "Davis", "da", "NFL", "e", "Michael", "Stevens", ",", "tamb\u00e9m", "conhecido", "como", "Vsauce", ",", "estrela", "do", "YouTube", "."], "sentence-detokenized": "Os ju\u00edzes que retornam s\u00e3o Fon Davis, Jessica Chobot e Leland Melvin, bem como o famoso ator convidado Clark Gregg, anfitri\u00e3o do MythBusters e ex-construtor do Battlebots Adam Savage, Vernon Davis da NFL e Michael Stevens, tamb\u00e9m conhecido como Vsauce, estrela do YouTube.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 22], [23, 26], [27, 30], [31, 36], [36, 37], [38, 45], [46, 52], [53, 54], [55, 61], [62, 68], [68, 69], [70, 73], [74, 78], [79, 80], [81, 87], [88, 92], [93, 102], [103, 108], [109, 114], [114, 115], [116, 125], [126, 128], [129, 140], [141, 142], [143, 156], [157, 159], [160, 170], [171, 175], [176, 182], [182, 183], [184, 190], [191, 196], [197, 199], [200, 203], [204, 205], [206, 213], [214, 221], [221, 222], [223, 229], [230, 239], [240, 244], [245, 251], [251, 252], [253, 260], [261, 263], [264, 271], [271, 272]]}
{"doc_key": "ai-test-307", "ner": [[8, 9, "algorithm"], [13, 15, "algorithm"], [17, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 17, 17, "part-of", "", false, false], [13, 15, 17, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Mas", "estes", "m\u00e9todos", "nunca", "conquistaram", "a", "tecnologia", "da", "mistura", "Gaussiana", "n\u00e3o", "uniforme", "/", "modelo", "Markov", "escondido", "(", "GMM-HMM", ")", "baseada", "em", "modelos", "generativos", "de", "fala", "treinados", "de", "forma", "discriminat\u00f3ria", "."], "sentence-detokenized": "Mas estes m\u00e9todos nunca conquistaram a tecnologia da mistura Gaussiana n\u00e3o uniforme / modelo Markov escondido (GMM-HMM) baseada em modelos generativos de fala treinados de forma discriminat\u00f3ria.", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 23], [24, 36], [37, 38], [39, 49], [50, 52], [53, 60], [61, 70], [71, 74], [75, 83], [84, 85], [86, 92], [93, 99], [100, 109], [110, 111], [111, 118], [118, 119], [120, 127], [128, 130], [131, 138], [139, 150], [151, 153], [154, 158], [159, 168], [169, 171], [172, 177], [178, 193], [193, 194]]}
{"doc_key": "ai-test-308", "ner": [[4, 4, "product"], [6, 7, "programlang"], [9, 9, "programlang"], [11, 11, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Pacotes", "de", "software", "como", "MATLAB", ",", "GNU", "Octave", ",", "Scilab", "e", "SciPy", "fornecem", "maneiras", "convenientes", "de", "aplicar", "estes", "diferentes", "m\u00e9todos", "."], "sentence-detokenized": "Pacotes de software como MATLAB, GNU Octave, Scilab e SciPy fornecem maneiras convenientes de aplicar estes diferentes m\u00e9todos.", "token2charspan": [[0, 7], [8, 10], [11, 19], [20, 24], [25, 31], [31, 32], [33, 36], [37, 43], [43, 44], [45, 51], [52, 53], [54, 59], [60, 68], [69, 77], [78, 90], [91, 93], [94, 101], [102, 107], [108, 118], [119, 126], [126, 127]]}
{"doc_key": "ai-test-309", "ner": [[0, 3, "algorithm"], [5, 5, "algorithm"], [11, 13, "task"], [21, 22, "researcher"], [24, 26, "university"], [28, 29, "researcher"], [31, 34, "organisation"], [36, 36, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 3, 11, 13, "related-to", "", false, false], [0, 3, 21, 22, "origin", "", false, false], [0, 3, 28, 29, "origin", "", false, false], [5, 5, 0, 3, "named", "", false, false], [21, 22, 24, 26, "physical", "", false, false], [21, 22, 24, 26, "role", "", false, false], [28, 29, 31, 34, "physical", "", false, false], [28, 29, 31, 34, "role", "", false, false], [36, 36, 31, 34, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["A", "codifica\u00e7\u00e3o", "preditiva", "linear", "(", "LPC", ")", ",", "um", "algoritmo", "de", "processamento", "de", "fala", ",", "foi", "proposta", "pela", "primeira", "vez", "por", "Fumitada", "Itakura", "da", "Universidade", "de", "Nagoya", "e", "Shuzo", "Saito", "da", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "em", "1966", "."], "sentence-detokenized": "A codifica\u00e7\u00e3o preditiva linear (LPC), um algoritmo de processamento de fala, foi proposta pela primeira vez por Fumitada Itakura da Universidade de Nagoya e Shuzo Saito da Nippon Telegraph and Telephone (NTT) em 1966.", "token2charspan": [[0, 1], [2, 13], [14, 23], [24, 30], [31, 32], [32, 35], [35, 36], [36, 37], [38, 40], [41, 50], [51, 53], [54, 67], [68, 70], [71, 75], [75, 76], [77, 80], [81, 89], [90, 94], [95, 103], [104, 107], [108, 111], [112, 120], [121, 128], [129, 131], [132, 144], [145, 147], [148, 154], [155, 156], [157, 162], [163, 168], [169, 171], [172, 178], [179, 188], [189, 192], [193, 202], [203, 204], [204, 207], [207, 208], [209, 211], [212, 216], [216, 217]]}
{"doc_key": "ai-test-310", "ner": [[15, 23, "conference"], [25, 25, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[25, 25, 15, 23, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Em", "2006", ",", "para", "o", "25\u00ba", "anivers\u00e1rio", "do", "algoritmo", ",", "foi", "organizado", "um", "workshop", "na", "Confer\u00eancia", "Internacional", "sobre", "Vis\u00e3o", "Computadorizada", "e", "Reconhecimento", "de", "Padr\u00f5es", "(", "CVPR", ")", "para", "resumir", "as", "mais", "recentes", "contribui\u00e7\u00f5es", "e", "varia\u00e7\u00f5es", "do", "algoritmo", "original", ",", "a", "fim", "de", "melhorar", "a", "velocidade", "do", "algoritmo", ",", "a", "robustez", "e", "precis\u00e3o", "da", "solu\u00e7\u00e3o", "estimada", "e", "para", "diminuir", "a", "depend\u00eancia", "das", "constantes", "definidas", "pelo", "usu\u00e1rio", "."], "sentence-detokenized": "Em 2006, para o 25\u00ba anivers\u00e1rio do algoritmo, foi organizado um workshop na Confer\u00eancia Internacional sobre Vis\u00e3o Computadorizada e Reconhecimento de Padr\u00f5es (CVPR) para resumir as mais recentes contribui\u00e7\u00f5es e varia\u00e7\u00f5es do algoritmo original, a fim de melhorar a velocidade do algoritmo, a robustez e precis\u00e3o da solu\u00e7\u00e3o estimada e para diminuir a depend\u00eancia das constantes definidas pelo usu\u00e1rio.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 13], [14, 15], [16, 19], [20, 31], [32, 34], [35, 44], [44, 45], [46, 49], [50, 60], [61, 63], [64, 72], [73, 75], [76, 87], [88, 101], [102, 107], [108, 113], [114, 129], [130, 131], [132, 146], [147, 149], [150, 157], [158, 159], [159, 163], [163, 164], [165, 169], [170, 177], [178, 180], [181, 185], [186, 194], [195, 208], [209, 210], [211, 220], [221, 223], [224, 233], [234, 242], [242, 243], [244, 245], [246, 249], [250, 252], [253, 261], [262, 263], [264, 274], [275, 277], [278, 287], [287, 288], [289, 290], [291, 299], [300, 301], [302, 310], [311, 313], [314, 321], [322, 330], [331, 332], [333, 337], [338, 346], [347, 348], [349, 360], [361, 364], [365, 375], [376, 385], [386, 390], [391, 398], [398, 399]]}
{"doc_key": "ai-test-311", "ner": [[4, 6, "university"], [9, 13, "organisation"], [16, 18, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Os", "membros", "frequentaram", "a", "Universidade", "de", "Debrecen", ",", "a", "Academia", "de", "Ci\u00eancias", "da", "Hungria", ",", "a", "Universidade", "E\u00f6tv\u00f6s", "Lor\u00e1nd", ",", "etc", "."], "sentence-detokenized": "Os membros frequentaram a Universidade de Debrecen, a Academia de Ci\u00eancias da Hungria, a Universidade E\u00f6tv\u00f6s Lor\u00e1nd, etc.", "token2charspan": [[0, 2], [3, 10], [11, 23], [24, 25], [26, 38], [39, 41], [42, 50], [50, 51], [52, 53], [54, 62], [63, 65], [66, 74], [75, 77], [78, 85], [85, 86], [87, 88], [89, 101], [102, 108], [109, 115], [115, 116], [117, 120], [120, 121]]}
{"doc_key": "ai-test-312", "ner": [[3, 3, "algorithm"], [17, 19, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 17, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Para", "estender", "a", "SVM", "aos", "casos", "em", "que", "os", "dados", "n\u00e3o", "s\u00e3o", "separ\u00e1veis", "linearmente", ",", "introduzimos", "a", "fun\u00e7\u00e3o", "de", "perda", ","], "sentence-detokenized": "Para estender a SVM aos casos em que os dados n\u00e3o s\u00e3o separ\u00e1veis linearmente, introduzimos a fun\u00e7\u00e3o de perda,", "token2charspan": [[0, 4], [5, 13], [14, 15], [16, 19], [20, 23], [24, 29], [30, 32], [33, 36], [37, 39], [40, 45], [46, 49], [50, 53], [54, 64], [65, 76], [76, 77], [78, 90], [91, 92], [93, 99], [100, 102], [103, 108], [108, 109]]}
{"doc_key": "ai-test-313", "ner": [[0, 1, "programlang"], [13, 14, "researcher"], [16, 17, "researcher"], [20, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 13, 14, "origin", "", false, false], [0, 1, 16, 17, "origin", "", false, false], [0, 1, 20, 21, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["O", "logotipo", "\u00e9", "uma", "linguagem", "de", "programa\u00e7\u00e3o", "educacional", ",", "projetada", "em", "1967", "por", "Wally", "Feurzeig", ",", "Seymour", "Papert", ",", "e", "Cynthia", "Solomon", "."], "sentence-detokenized": "O logotipo \u00e9 uma linguagem de programa\u00e7\u00e3o educacional, projetada em 1967 por Wally Feurzeig, Seymour Papert, e Cynthia Solomon.", "token2charspan": [[0, 1], [2, 10], [11, 12], [13, 16], [17, 26], [27, 29], [30, 41], [42, 53], [53, 54], [55, 64], [65, 67], [68, 72], [73, 76], [77, 82], [83, 91], [91, 92], [93, 100], [101, 107], [107, 108], [109, 110], [111, 118], [119, 126], [126, 127]]}
{"doc_key": "ai-test-314", "ner": [[0, 3, "organisation"], [8, 15, "organisation"], [17, 20, "location"], [24, 24, "location"], [26, 26, "location"], [36, 41, "product"], [47, 50, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 8, 15, "role", "works_for", false, false], [8, 15, 17, 20, "physical", "", false, false], [17, 20, 24, 24, "physical", "", false, false], [24, 24, 26, 26, "physical", "", false, false], [36, 41, 0, 3, "origin", "", false, false], [47, 50, 36, 41, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["O", "Eyring", "Research", "Institute", "foi", "fundamental", "para", "a", "Dire\u00e7\u00e3o", "de", "M\u00edsseis", "da", "For\u00e7a", "A\u00e9rea", "dos", "EUA", "na", "Base", "A\u00e9rea", "de", "Hill", ",", "perto", "de", "Ogden", ",", "Utah", ",", "para", "produzir", "em", "sigilo", "militar", "m\u00e1ximo", ",", "o", "Software", "de", "Tecnologia", "de", "Sistemas", "Inteligentes", "que", "foi", "fundado", "para", "o", "programa", "Reagan", "Star", "Wars", ",", "mais", "tarde", "nomeado", "."], "sentence-detokenized": "O Eyring Research Institute foi fundamental para a Dire\u00e7\u00e3o de M\u00edsseis da For\u00e7a A\u00e9rea dos EUA na Base A\u00e9rea de Hill, perto de Ogden, Utah, para produzir em sigilo militar m\u00e1ximo, o Software de Tecnologia de Sistemas Inteligentes que foi fundado para o programa Reagan Star Wars, mais tarde nomeado.", "token2charspan": [[0, 1], [2, 8], [9, 17], [18, 27], [28, 31], [32, 43], [44, 48], [49, 50], [51, 58], [59, 61], [62, 69], [70, 72], [73, 78], [79, 84], [85, 88], [89, 92], [93, 95], [96, 100], [101, 106], [107, 109], [110, 114], [114, 115], [116, 121], [122, 124], [125, 130], [130, 131], [132, 136], [136, 137], [138, 142], [143, 151], [152, 154], [155, 161], [162, 169], [170, 176], [176, 177], [178, 179], [180, 188], [189, 191], [192, 202], [203, 205], [206, 214], [215, 227], [228, 231], [232, 235], [236, 243], [244, 248], [249, 250], [251, 259], [260, 266], [267, 271], [272, 276], [276, 277], [278, 282], [283, 288], [289, 296], [296, 297]]}
{"doc_key": "ai-test-315", "ner": [[11, 13, "field"], [26, 28, "researcher"], [30, 31, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ao", "longo", "das", "d\u00e9cadas", "ele", "pesquisou", "e", "desenvolveu", "campos", "emergentes", "da", "ci\u00eancia", "da", "computa\u00e7\u00e3o", "a", "partir", "de", "compiladores", ",", "linguagens", "de", "programa\u00e7\u00e3o", "e", "arquitetura", "de", "sistemas", "John", "F.", "Sowa", "e", "John", "Zachman", "(", "1992", ")", "."], "sentence-detokenized": "Ao longo das d\u00e9cadas ele pesquisou e desenvolveu campos emergentes da ci\u00eancia da computa\u00e7\u00e3o a partir de compiladores, linguagens de programa\u00e7\u00e3o e arquitetura de sistemas John F. Sowa e John Zachman (1992).", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 20], [21, 24], [25, 34], [35, 36], [37, 48], [49, 55], [56, 66], [67, 69], [70, 77], [78, 80], [81, 91], [92, 93], [94, 100], [101, 103], [104, 116], [116, 117], [118, 128], [129, 131], [132, 143], [144, 145], [146, 157], [158, 160], [161, 169], [170, 174], [175, 177], [178, 182], [183, 184], [185, 189], [190, 197], [198, 199], [199, 203], [203, 204], [204, 205]]}
{"doc_key": "ai-test-316", "ner": [[1, 2, "algorithm"], [8, 9, "algorithm"], [11, 12, "algorithm"], [17, 19, "field"], [21, 22, "field"], [27, 31, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 1, 2, "named", "", false, false], [11, 12, 1, 2, "named", "", false, false], [17, 19, 1, 2, "usage", "", false, false], [21, 22, 1, 2, "usage", "", false, false], [27, 31, 1, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["O", "operador", "Sobel", ",", "\u00e0s", "vezes", "chamado", "de", "operador", "Sobel-Feldman", "ou", "filtro", "Sobel", ",", "\u00e9", "usado", "no", "processamento", "de", "imagens", "e", "vis\u00e3o", "computadorizada", ",", "particularmente", "dentro", "de", "algoritmos", "de", "detec\u00e7\u00e3o", "de", "bordas", ",", "onde", "cria", "uma", "imagem", "que", "enfatiza", "as", "bordas", "."], "sentence-detokenized": "O operador Sobel, \u00e0s vezes chamado de operador Sobel-Feldman ou filtro Sobel, \u00e9 usado no processamento de imagens e vis\u00e3o computadorizada, particularmente dentro de algoritmos de detec\u00e7\u00e3o de bordas, onde cria uma imagem que enfatiza as bordas.", "token2charspan": [[0, 1], [2, 10], [11, 16], [16, 17], [18, 20], [21, 26], [27, 34], [35, 37], [38, 46], [47, 60], [61, 63], [64, 70], [71, 76], [76, 77], [78, 79], [80, 85], [86, 88], [89, 102], [103, 105], [106, 113], [114, 115], [116, 121], [122, 137], [137, 138], [139, 154], [155, 161], [162, 164], [165, 175], [176, 178], [179, 187], [188, 190], [191, 197], [197, 198], [199, 203], [204, 208], [209, 212], [213, 219], [220, 223], [224, 232], [233, 235], [236, 242], [242, 243]]}
{"doc_key": "ai-test-317", "ner": [[0, 0, "algorithm"], [5, 6, "field"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 5, 6, "compare", "", false, false], [0, 0, 5, 6, "type-of", "", false, false], [0, 0, 15, 15, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["LDA", "\u00e9", "um", "algoritmo", "de", "aprendizado", "supervisionado", "que", "utiliza", "as", "etiquetas", "dos", "dados", ",", "enquanto", "PCA", "\u00e9", "um", "algoritmo", "de", "aprendizado", "que", "ignora", "as", "etiquetas", "."], "sentence-detokenized": "LDA \u00e9 um algoritmo de aprendizado supervisionado que utiliza as etiquetas dos dados, enquanto PCA \u00e9 um algoritmo de aprendizado que ignora as etiquetas.", "token2charspan": [[0, 3], [4, 5], [6, 8], [9, 18], [19, 21], [22, 33], [34, 48], [49, 52], [53, 60], [61, 63], [64, 73], [74, 77], [78, 83], [83, 84], [85, 93], [94, 97], [98, 99], [100, 102], [103, 112], [113, 115], [116, 127], [128, 131], [132, 138], [139, 141], [142, 151], [151, 152]]}
{"doc_key": "ai-test-318", "ner": [[6, 6, "algorithm"], [8, 11, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Outros", "algoritmos", "de", "classifica\u00e7\u00e3o", "linear", "incluem", "Winnow", ",", "m\u00e1quina", "vetorial", "de", "suporte", "e", "regress\u00e3o", "log\u00edstica", "."], "sentence-detokenized": "Outros algoritmos de classifica\u00e7\u00e3o linear incluem Winnow, m\u00e1quina vetorial de suporte e regress\u00e3o log\u00edstica.", "token2charspan": [[0, 6], [7, 17], [18, 20], [21, 34], [35, 41], [42, 49], [50, 56], [56, 57], [58, 65], [66, 74], [75, 77], [78, 85], [86, 87], [88, 97], [98, 107], [107, 108]]}
{"doc_key": "ai-test-319", "ner": [[0, 0, "product"], [7, 9, "programlang"], [18, 18, "product"], [20, 20, "programlang"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 7, 9, "general-affiliation", "", true, false], [0, 0, 18, 18, "general-affiliation", "", true, false], [0, 0, 20, 20, "general-affiliation", "", true, false], [0, 0, 22, 22, "general-affiliation", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["VTK", "consiste", "de", "uma", "biblioteca", "de", "classe", "C", "+", "+", "e", "v\u00e1rias", "camadas", "de", "interface", "interpretadas", ",", "incluindo", "Tcl/Tk", ",", "Java", "e", "Python", "."], "sentence-detokenized": "VTK consiste de uma biblioteca de classe C + + e v\u00e1rias camadas de interface interpretadas, incluindo Tcl/Tk, Java e Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 19], [20, 30], [31, 33], [34, 40], [41, 42], [43, 44], [45, 46], [47, 48], [49, 55], [56, 63], [64, 66], [67, 76], [77, 90], [90, 91], [92, 101], [102, 108], [108, 109], [110, 114], [115, 116], [117, 123], [123, 124]]}
{"doc_key": "ai-test-320", "ner": [[13, 16, "task"], [25, 28, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Al\u00e9m", "disso", ",", "o", "texto", "produzido", "pelo", "processamento", "de", "fala", "espont\u00e2nea", "usando", "o", "reconhecimento", "autom\u00e1tico", "da", "fala", "e", "o", "texto", "impresso", "ou", "manuscrito", "usando", "o", "reconhecimento", "\u00f3ptico", "de", "caracteres", "cont\u00e9m", "ru\u00eddo", "de", "processamento", "."], "sentence-detokenized": "Al\u00e9m disso, o texto produzido pelo processamento de fala espont\u00e2nea usando o reconhecimento autom\u00e1tico da fala e o texto impresso ou manuscrito usando o reconhecimento \u00f3ptico de caracteres cont\u00e9m ru\u00eddo de processamento.", "token2charspan": [[0, 4], [5, 10], [10, 11], [12, 13], [14, 19], [20, 29], [30, 34], [35, 48], [49, 51], [52, 56], [57, 67], [68, 74], [75, 76], [77, 91], [92, 102], [103, 105], [106, 110], [111, 112], [113, 114], [115, 120], [121, 129], [130, 132], [133, 143], [144, 150], [151, 152], [153, 167], [168, 174], [175, 177], [178, 188], [189, 195], [196, 201], [202, 204], [205, 218], [218, 219]]}
{"doc_key": "ai-test-321", "ner": [[0, 0, "researcher"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 9, 9, "role", "directs_development_of", false, false]], "relations_mapping_to_source": [0], "sentence": ["Miller", "escreveu", "v\u00e1rios", "livros", "e", "dirigiu", "o", "desenvolvimento", "do", "WordNet", ",", "um", "banco", "de", "dados", "on-line", "de", "links", "de", "palavras", "utiliz\u00e1vel", "por", "programas", "de", "computador", "."], "sentence-detokenized": "Miller escreveu v\u00e1rios livros e dirigiu o desenvolvimento do WordNet, um banco de dados on-line de links de palavras utiliz\u00e1vel por programas de computador.", "token2charspan": [[0, 6], [7, 15], [16, 22], [23, 29], [30, 31], [32, 39], [40, 41], [42, 57], [58, 60], [61, 68], [68, 69], [70, 72], [73, 78], [79, 81], [82, 87], [88, 95], [96, 98], [99, 104], [105, 107], [108, 116], [117, 127], [128, 131], [132, 141], [142, 144], [145, 155], [155, 156]]}
{"doc_key": "ai-test-322", "ner": [[0, 1, "field"], [8, 10, "organisation"], [12, 13, "country"], [15, 16, "person"], [18, 20, "person"], [22, 23, "person"], [25, 26, "person"], [28, 29, "country"], [31, 34, "location"], [36, 37, "misc"], [38, 39, "person"], [42, 43, "person"], [45, 45, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 10, 12, 13, "physical", "", false, false], [15, 16, 28, 29, "physical", "", false, false], [18, 20, 28, 29, "physical", "", false, false], [22, 23, 28, 29, "physical", "", false, false], [25, 26, 28, 29, "physical", "", false, false], [31, 34, 0, 1, "general-affiliation", "", false, false], [31, 34, 38, 39, "artifact", "", false, false], [36, 37, 38, 39, "named", "", false, false], [42, 43, 45, 45, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Os", "aut\u00f4matos", "contempor\u00e2neos", "s\u00e3o", "representados", "pelas", "obras", "do", "Cabaret", "Mechanical", "Theatre", "no", "Reino", "Unido", ",", "Dug", "North", "e", "Chomick", "+", "Meder", ",", "Arthur", "Ganson", ",", "Joe", "Jones", "nos", "Estados", "Unidos", ",", "Le", "D\u00e9fenseur", "du", "Temps", "do", "artista", "franc\u00eas", "Jacques", "Monestier", ",", "e", "Fran\u00e7ois", "Junod", "na", "Su\u00ed\u00e7a", "."], "sentence-detokenized": "Os aut\u00f4matos contempor\u00e2neos s\u00e3o representados pelas obras do Cabaret Mechanical Theatre no Reino Unido, Dug North e Chomick + Meder, Arthur Ganson, Joe Jones nos Estados Unidos, Le D\u00e9fenseur du Temps do artista franc\u00eas Jacques Monestier, e Fran\u00e7ois Junod na Su\u00ed\u00e7a.", "token2charspan": [[0, 2], [3, 12], [13, 27], [28, 31], [32, 45], [46, 51], [52, 57], [58, 60], [61, 68], [69, 79], [80, 87], [88, 90], [91, 96], [97, 102], [102, 103], [104, 107], [108, 113], [114, 115], [116, 123], [124, 125], [126, 131], [131, 132], [133, 139], [140, 146], [146, 147], [148, 151], [152, 157], [158, 161], [162, 169], [170, 176], [176, 177], [178, 180], [181, 190], [191, 193], [194, 199], [200, 202], [203, 210], [211, 218], [219, 226], [227, 236], [236, 237], [238, 239], [240, 248], [249, 254], [255, 257], [258, 263], [263, 264]]}
{"doc_key": "ai-test-323", "ner": [[0, 1, "product"], [23, 23, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 23, 23, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["O", "MATLAB", "inclui", "c\u00f3digos", "padr\u00e3o", "antes", "/", "c\u00f3digo", "e", "codificados", "/", "loops", "de", "c\u00f3digo", ",", "mas", "(", "como", "em", "outras", "aplica\u00e7\u00f5es", "similares", "como", "R", ")", ",", "o", "uso", "da", "nota\u00e7\u00e3o", "vetorizada", "\u00e9", "encorajado", "e", "muitas", "vezes", "\u00e9", "mais", "r\u00e1pido", "de", "executar", "."], "sentence-detokenized": "O MATLAB inclui c\u00f3digos padr\u00e3o antes / c\u00f3digo e codificados / loops de c\u00f3digo, mas (como em outras aplica\u00e7\u00f5es similares como R), o uso da nota\u00e7\u00e3o vetorizada \u00e9 encorajado e muitas vezes \u00e9 mais r\u00e1pido de executar.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 23], [24, 30], [31, 36], [37, 38], [39, 45], [46, 47], [48, 59], [60, 61], [62, 67], [68, 70], [71, 77], [77, 78], [79, 82], [83, 84], [84, 88], [89, 91], [92, 98], [99, 109], [110, 119], [120, 124], [125, 126], [126, 127], [127, 128], [129, 130], [131, 134], [135, 137], [138, 145], [146, 156], [157, 158], [159, 169], [170, 171], [172, 178], [179, 184], [185, 186], [187, 191], [192, 198], [199, 201], [202, 210], [210, 211]]}
{"doc_key": "ai-test-324", "ner": [[0, 0, "researcher"], [5, 8, "conference"], [15, 17, "field"], [20, 27, "misc"], [30, 41, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 20, 27, "win-defeat", "", false, false], [0, 0, 30, 41, "win-defeat", "", false, false], [20, 27, 5, 8, "temporal", "", false, false], [20, 27, 15, 17, "topic", "", false, false], [30, 41, 5, 8, "temporal", "", false, false], [30, 41, 15, 17, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pausch", "recebeu", "dois", "pr\u00eamios", "da", "Association", "for", "Computing", "Machinery", "em", "2007", "por", "suas", "realiza\u00e7\u00f5es", "na", "educa\u00e7\u00e3o", "em", "computa\u00e7\u00e3o", ":", "o", "Pr\u00eamio", "Karl", "V", ".", "Karlstrom", "de", "Educador", "Destacado", "e", "o", "Pr\u00eamio", "ACM", "SIGCSE", "por", "Contribui\u00e7\u00f5es", "Destacadas", "\u00e0", "Educa\u00e7\u00e3o", "em", "Ci\u00eancia", "da", "Computa\u00e7\u00e3o", "."], "sentence-detokenized": "Pausch recebeu dois pr\u00eamios da Association for Computing Machinery em 2007 por suas realiza\u00e7\u00f5es na educa\u00e7\u00e3o em computa\u00e7\u00e3o: o Pr\u00eamio Karl V. Karlstrom de Educador Destacado e o Pr\u00eamio ACM SIGCSE por Contribui\u00e7\u00f5es Destacadas \u00e0 Educa\u00e7\u00e3o em Ci\u00eancia da Computa\u00e7\u00e3o.", "token2charspan": [[0, 6], [7, 14], [15, 19], [20, 27], [28, 30], [31, 42], [43, 46], [47, 56], [57, 66], [67, 69], [70, 74], [75, 78], [79, 83], [84, 95], [96, 98], [99, 107], [108, 110], [111, 121], [121, 122], [123, 124], [125, 131], [132, 136], [137, 138], [138, 139], [140, 149], [150, 152], [153, 161], [162, 171], [172, 173], [174, 175], [176, 182], [183, 186], [187, 193], [194, 197], [198, 211], [212, 222], [223, 224], [225, 233], [234, 236], [237, 244], [245, 247], [248, 258], [258, 259]]}
{"doc_key": "ai-test-325", "ner": [[3, 4, "person"], [10, 10, "product"], [9, 9, "product"], [19, 20, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 10, 10, "role", "sells", false, false], [10, 10, 9, 9, "general-affiliation", "", false, false], [10, 10, 19, 20, "physical", "shipped_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Em", "1960", ",", "a", "Devol", "vendeu", "pessoalmente", "o", "primeiro", "rob\u00f4", "Unimate", ",", "que", "foi", "enviado", "em", "1961", "para", "a", "General", "Motors", "."], "sentence-detokenized": "Em 1960, a Devol vendeu pessoalmente o primeiro rob\u00f4 Unimate, que foi enviado em 1961 para a General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 16], [17, 23], [24, 36], [37, 38], [39, 47], [48, 52], [53, 60], [60, 61], [62, 65], [66, 69], [70, 77], [78, 80], [81, 85], [86, 90], [91, 92], [93, 100], [101, 107], [107, 108]]}
{"doc_key": "ai-test-326", "ner": [[0, 2, "algorithm"], [8, 14, "field"], [15, 17, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 17, 0, 2, "usage", "", false, false], [15, 17, 8, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "redes", "sem\u00e2nticas", "s\u00e3o", "utilizadas", "em", "aplica\u00e7\u00f5es", "de", "processamento", "de", "linguagem", "natural", ",", "tais", "como", "a", "an\u00e1lise", "sem\u00e2ntica", "."], "sentence-detokenized": "As redes sem\u00e2nticas s\u00e3o utilizadas em aplica\u00e7\u00f5es de processamento de linguagem natural, tais como a an\u00e1lise sem\u00e2ntica.", "token2charspan": [[0, 2], [3, 8], [9, 19], [20, 23], [24, 34], [35, 37], [38, 48], [49, 51], [52, 65], [66, 68], [69, 78], [79, 86], [86, 87], [88, 92], [93, 97], [98, 99], [100, 107], [108, 117], [117, 118]]}
{"doc_key": "ai-test-327", "ner": [[5, 6, "field"], [9, 10, "field"], [13, 15, "task"], [17, 18, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 28, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 10, 5, 6, "usage", "", false, false], [13, 15, 5, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Algumas", "aplica\u00e7\u00f5es", "bem", "sucedidas", "de", "aprendizagem", "profunda", "s\u00e3o", "a", "vis\u00e3o", "computacional", "e", "o", "reconhecimento", "da", "fala", ".", "Honglak", "Lee", ",", "Roger", "Grosse", ",", "Rajesh", "Ranganath", ",", "Andrew", "Y.", "Ng", "."], "sentence-detokenized": "Algumas aplica\u00e7\u00f5es bem sucedidas de aprendizagem profunda s\u00e3o a vis\u00e3o computacional e o reconhecimento da fala. Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng.", "token2charspan": [[0, 7], [8, 18], [19, 22], [23, 32], [33, 35], [36, 48], [49, 57], [58, 61], [62, 63], [64, 69], [70, 83], [84, 85], [86, 87], [88, 102], [103, 105], [106, 110], [110, 111], [112, 119], [120, 123], [123, 124], [125, 130], [131, 137], [137, 138], [139, 145], [146, 155], [155, 156], [157, 163], [164, 166], [167, 169], [169, 170]]}
{"doc_key": "ai-test-328", "ner": [[4, 9, "product"], [15, 15, "misc"], [18, 18, "misc"], [23, 23, "product"], [27, 29, "task"], [31, 33, "task"], [35, 36, "task"], [38, 41, "field"], [43, 44, "task"], [46, 48, "field"], [50, 51, "task"], [53, 54, "task"], [56, 59, "task"], [61, 63, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 9, 15, 15, "physical", "travels_to", false, false], [4, 9, 18, 18, "physical", "travels_to", false, false], [23, 23, 4, 9, "part-of", "", false, false], [23, 23, 4, 9, "role", "maintains", false, false], [23, 23, 27, 29, "related-to", "has_ability_to", false, false], [23, 23, 31, 33, "related-to", "has_ability_to", false, false], [23, 23, 35, 36, "related-to", "has_ability_to", false, false], [23, 23, 38, 41, "related-to", "has_ability_to", false, false], [23, 23, 43, 44, "related-to", "has_ability_to", false, false], [23, 23, 46, 48, "related-to", "has_ability_to", false, false], [23, 23, 50, 51, "related-to", "has_ability_to", false, false], [23, 23, 53, 54, "related-to", "has_ability_to", false, false], [23, 23, 56, 59, "related-to", "has_ability_to", false, false], [23, 23, 61, 63, "related-to", "has_ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Al\u00e9m", "de", "manter", "os", "sistemas", "da", "nave", "espacial", "Discovery", "One", "durante", "a", "miss\u00e3o", "interplanet\u00e1ria", "a", "J\u00fapiter", "(", "ou", "Saturno", "no", "romance", ")", ",", "HAL", "\u00e9", "capaz", "de", "s\u00edntese", "da", "fala", ",", "reconhecimento", "da", "fala", ",", "reconhecimento", "facial", ",", "processamento", "da", "linguagem", "natural", ",", "leitura", "labial", ",", "aprecia\u00e7\u00e3o", "da", "arte", ",", "computa\u00e7\u00e3o", "afetiva", ",", "racioc\u00ednio", "automatizado", ",", "pilotagem", "de", "naves", "espaciais", "e", "jogo", "de", "xadrez", "."], "sentence-detokenized": "Al\u00e9m de manter os sistemas da nave espacial Discovery One durante a miss\u00e3o interplanet\u00e1ria a J\u00fapiter (ou Saturno no romance), HAL \u00e9 capaz de s\u00edntese da fala, reconhecimento da fala, reconhecimento facial, processamento da linguagem natural, leitura labial, aprecia\u00e7\u00e3o da arte, computa\u00e7\u00e3o afetiva, racioc\u00ednio automatizado, pilotagem de naves espaciais e jogo de xadrez.", "token2charspan": [[0, 4], [5, 7], [8, 14], [15, 17], [18, 26], [27, 29], [30, 34], [35, 43], [44, 53], [54, 57], [58, 65], [66, 67], [68, 74], [75, 90], [91, 92], [93, 100], [101, 102], [102, 104], [105, 112], [113, 115], [116, 123], [123, 124], [124, 125], [126, 129], [130, 131], [132, 137], [138, 140], [141, 148], [149, 151], [152, 156], [156, 157], [158, 172], [173, 175], [176, 180], [180, 181], [182, 196], [197, 203], [203, 204], [205, 218], [219, 221], [222, 231], [232, 239], [239, 240], [241, 248], [249, 255], [255, 256], [257, 267], [268, 270], [271, 275], [275, 276], [277, 287], [288, 295], [295, 296], [297, 307], [308, 320], [320, 321], [322, 331], [332, 334], [335, 340], [341, 350], [351, 352], [353, 357], [358, 360], [361, 367], [367, 368]]}
{"doc_key": "ai-test-329", "ner": [[0, 3, "researcher"], [6, 6, "country"], [8, 10, "country"], [14, 15, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 6, 6, "physical", "", false, false], [0, 3, 8, 10, "physical", "", false, false], [0, 3, 14, 15, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["O", "Dr", ".", "Julesz", "emigrou", "da", "Hungria", "para", "os", "Estados", "Unidos", "ap\u00f3s", "a", "invas\u00e3o", "sovi\u00e9tica", "de", "1956", "."], "sentence-detokenized": "O Dr. Julesz emigrou da Hungria para os Estados Unidos ap\u00f3s a invas\u00e3o sovi\u00e9tica de 1956.", "token2charspan": [[0, 1], [2, 4], [4, 5], [6, 12], [13, 20], [21, 23], [24, 31], [32, 36], [37, 39], [40, 47], [48, 54], [55, 59], [60, 61], [62, 69], [70, 79], [80, 82], [83, 87], [87, 88]]}
{"doc_key": "ai-test-330", "ner": [[5, 6, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["As", "fun\u00e7\u00f5es", "de", "ativa\u00e7\u00e3o", "da", "fun\u00e7\u00e3o", "Sigmoid", "utilizam", "uma", "segunda", "n\u00e3o-linearidade", "para", "grandes", "entradas", ":", "matem\u00e1ticas", "phi", "(", "v", "_", "i", ")", "=", "(", "1", "+", ")", "exp", "(", "-v", "_", "i", ")", ")", "^", "^", "{", "-1", "}", "/", "matem\u00e1tica", "."], "sentence-detokenized": "As fun\u00e7\u00f5es de ativa\u00e7\u00e3o da fun\u00e7\u00e3o Sigmoid utilizam uma segunda n\u00e3o-linearidade para grandes entradas: matem\u00e1ticas phi (v _ i) = (1 +) exp (-v _ i)) ^ ^ {-1} / matem\u00e1tica.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 22], [23, 25], [26, 32], [33, 40], [41, 49], [50, 53], [54, 61], [62, 77], [78, 82], [83, 90], [91, 99], [99, 100], [101, 112], [113, 116], [117, 118], [118, 119], [120, 121], [122, 123], [123, 124], [125, 126], [127, 128], [128, 129], [130, 131], [131, 132], [133, 136], [137, 138], [138, 140], [141, 142], [143, 144], [144, 145], [145, 146], [147, 148], [149, 150], [151, 152], [152, 154], [154, 155], [156, 157], [158, 168], [168, 169]]}
{"doc_key": "ai-test-331", "ner": [[14, 17, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Estas", "probabilidades", "s\u00e3o", "usadas", "para", "determinar", "qual", "\u00e9", "o", "alvo", "que", "est\u00e1", "usando", "uma", "decis\u00e3o", "de", "m\u00e1xima", "probabilidade", "."], "sentence-detokenized": "Estas probabilidades s\u00e3o usadas para determinar qual \u00e9 o alvo que est\u00e1 usando uma decis\u00e3o de m\u00e1xima probabilidade.", "token2charspan": [[0, 5], [6, 20], [21, 24], [25, 31], [32, 36], [37, 47], [48, 52], [53, 54], [55, 56], [57, 61], [62, 65], [66, 70], [71, 77], [78, 81], [82, 89], [90, 92], [93, 99], [100, 113], [113, 114]]}
{"doc_key": "ai-test-332", "ner": [[7, 9, "university"], [15, 17, "university"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Em", "1984", "ele", "se", "mudou", "para", "a", "Universidade", "de", "Konstanz", "e", "em", "1990", "para", "a", "Universidade", "de", "Salzburg", "."], "sentence-detokenized": "Em 1984 ele se mudou para a Universidade de Konstanz e em 1990 para a Universidade de Salzburg.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 14], [15, 20], [21, 25], [26, 27], [28, 40], [41, 43], [44, 52], [53, 54], [55, 57], [58, 62], [63, 67], [68, 69], [70, 82], [83, 85], [86, 94], [94, 95]]}
{"doc_key": "ai-test-333", "ner": [[7, 9, "metrics"], [11, 13, "metrics"], [15, 17, "metrics"], [19, 20, "metrics"], [22, 23, "metrics"], [25, 28, "metrics"], [30, 34, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 13, 7, 9, "origin", "based_on", false, false], [15, 17, 7, 9, "origin", "based_on", false, false], [19, 20, 7, 9, "origin", "based_on", false, false], [22, 23, 7, 9, "origin", "based_on", false, false], [25, 28, 7, 9, "origin", "based_on", false, false], [30, 34, 7, 9, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Algumas", "fun\u00e7\u00f5es", "de", "aptid\u00e3o", "popular", "baseadas", "na", "matriz", "de", "confus\u00e3o", "incluem", "sensibilidade", "/", "especificidade", ",", "recall", "/", "precis\u00e3o", ",", "medida", "F", ",", "semelhan\u00e7a", "Jaccard", ",", "coeficiente", "de", "correla\u00e7\u00e3o", "Matthews", "e", "matriz", "de", "custo", "/", "ganho", "que", "combina", "os", "custos", "e", "ganhos", "atribu\u00eddos", "aos", "4", "tipos", "diferentes", "de", "classifica\u00e7\u00f5es", "."], "sentence-detokenized": "Algumas fun\u00e7\u00f5es de aptid\u00e3o popular baseadas na matriz de confus\u00e3o incluem sensibilidade / especificidade, recall / precis\u00e3o, medida F, semelhan\u00e7a Jaccard, coeficiente de correla\u00e7\u00e3o Matthews e matriz de custo / ganho que combina os custos e ganhos atribu\u00eddos aos 4 tipos diferentes de classifica\u00e7\u00f5es.", "token2charspan": [[0, 7], [8, 15], [16, 18], [19, 26], [27, 34], [35, 43], [44, 46], [47, 53], [54, 56], [57, 65], [66, 73], [74, 87], [88, 89], [90, 104], [104, 105], [106, 112], [113, 114], [115, 123], [123, 124], [125, 131], [132, 133], [133, 134], [135, 145], [146, 153], [153, 154], [155, 166], [167, 169], [170, 180], [181, 189], [190, 191], [192, 198], [199, 201], [202, 207], [208, 209], [210, 215], [216, 219], [220, 227], [228, 230], [231, 237], [238, 239], [240, 246], [247, 257], [258, 261], [262, 263], [264, 269], [270, 280], [281, 283], [284, 298], [298, 299]]}
{"doc_key": "ai-test-334", "ner": [[6, 6, "product"], [8, 8, "product"], [10, 10, "product"], [12, 12, "product"], [15, 16, "programlang"], [31, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[31, 34, 6, 6, "part-of", "", false, false], [31, 34, 8, 8, "part-of", "", false, false], [31, 34, 10, 10, "part-of", "", false, false], [31, 34, 12, 12, "part-of", "", false, false], [31, 34, 15, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Ambientes", "comuns", "de", "programa\u00e7\u00e3o", "num\u00e9rica", "como", "MATLAB", ",", "SciLab", ",", "NumPy", ",", "Sklearn", "e", "a", "linguagem", "R", "fornecem", "algumas", "das", "t\u00e9cnicas", "mais", "simples", "de", "extra\u00e7\u00e3o", "de", "recursos", "(", "por", "exemplo", ",", "an\u00e1lise", "de", "componentes", "principais", ")", "atrav\u00e9s", "de", "comandos", "embutidos", "."], "sentence-detokenized": "Ambientes comuns de programa\u00e7\u00e3o num\u00e9rica como MATLAB, SciLab, NumPy, Sklearn e a linguagem R fornecem algumas das t\u00e9cnicas mais simples de extra\u00e7\u00e3o de recursos (por exemplo, an\u00e1lise de componentes principais) atrav\u00e9s de comandos embutidos.", "token2charspan": [[0, 9], [10, 16], [17, 19], [20, 31], [32, 40], [41, 45], [46, 52], [52, 53], [54, 60], [60, 61], [62, 67], [67, 68], [69, 76], [77, 78], [79, 80], [81, 90], [91, 92], [93, 101], [102, 109], [110, 113], [114, 122], [123, 127], [128, 135], [136, 138], [139, 147], [148, 150], [151, 159], [160, 161], [161, 164], [165, 172], [172, 173], [174, 181], [182, 184], [185, 196], [197, 207], [207, 208], [209, 216], [217, 219], [220, 228], [229, 238], [238, 239]]}
{"doc_key": "ai-test-335", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Rob\u00f4s", "industriais", "t\u00eam", "sido", "implementados", "para", "colaborar", "com", "humanos", "na", "execu\u00e7\u00e3o", "de", "tarefas", "de", "fabrica\u00e7\u00e3o", "industrial", "."], "sentence-detokenized": "Rob\u00f4s industriais t\u00eam sido implementados para colaborar com humanos na execu\u00e7\u00e3o de tarefas de fabrica\u00e7\u00e3o industrial.", "token2charspan": [[0, 5], [6, 17], [18, 21], [22, 26], [27, 40], [41, 45], [46, 55], [56, 59], [60, 67], [68, 70], [71, 79], [80, 82], [83, 90], [91, 93], [94, 104], [105, 115], [115, 116]]}
{"doc_key": "ai-test-336", "ner": [[5, 5, "field"], [7, 10, "researcher"], [20, 21, "field"], [23, 25, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 5, 20, 21, "related-to", "", false, false], [5, 5, 23, 25, "related-to", "", false, false], [5, 5, 27, 28, "related-to", "", false, false], [7, 10, 5, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["No", "primeiro", "artigo", "publicado", "sobre", "CGs", ",", "John", "F", ".", "Sowa", "os", "aplicou", "a", "uma", "ampla", "gama", "de", "t\u00f3picos", "em", "intelig\u00eancia", "artificial", ",", "ci\u00eancia", "da", "computa\u00e7\u00e3o", "e", "ci\u00eancia", "cognitiva", "."], "sentence-detokenized": "No primeiro artigo publicado sobre CGs, John F. Sowa os aplicou a uma ampla gama de t\u00f3picos em intelig\u00eancia artificial, ci\u00eancia da computa\u00e7\u00e3o e ci\u00eancia cognitiva.", "token2charspan": [[0, 2], [3, 11], [12, 18], [19, 28], [29, 34], [35, 38], [38, 39], [40, 44], [45, 46], [46, 47], [48, 52], [53, 55], [56, 63], [64, 65], [66, 69], [70, 75], [76, 80], [81, 83], [84, 91], [92, 94], [95, 107], [108, 118], [118, 119], [120, 127], [128, 130], [131, 141], [142, 143], [144, 151], [152, 161], [161, 162]]}
{"doc_key": "ai-test-337", "ner": [[0, 1, "metrics"], [5, 5, "metrics"], [10, 12, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 5, 5, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["O", "NIST", "tamb\u00e9m", "difere", "do", "BLEU", "em", "seu", "c\u00e1lculo", "da", "penalidade", "por", "brevidade", ",", "na", "medida", "em", "que", "pequenas", "varia\u00e7\u00f5es", "no", "comprimento", "de", "tradu\u00e7\u00e3o", "n\u00e3o", "impactam", "tanto", "a", "pontua\u00e7\u00e3o", "total", "."], "sentence-detokenized": "O NIST tamb\u00e9m difere do BLEU em seu c\u00e1lculo da penalidade por brevidade, na medida em que pequenas varia\u00e7\u00f5es no comprimento de tradu\u00e7\u00e3o n\u00e3o impactam tanto a pontua\u00e7\u00e3o total.", "token2charspan": [[0, 1], [2, 6], [7, 13], [14, 20], [21, 23], [24, 28], [29, 31], [32, 35], [36, 43], [44, 46], [47, 57], [58, 61], [62, 71], [71, 72], [73, 75], [76, 82], [83, 85], [86, 89], [90, 98], [99, 108], [109, 111], [112, 123], [124, 126], [127, 135], [136, 139], [140, 148], [149, 154], [155, 156], [157, 166], [167, 172], [172, 173]]}
{"doc_key": "ai-test-338", "ner": [[1, 6, "misc"], [14, 14, "conference"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 6, 14, 14, "temporal", "", false, false], [1, 6, 18, 19, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["O", "Pr\u00eamio", "IJCAI", "de", "Excel\u00eancia", "em", "Pesquisa", "\u00e9", "um", "pr\u00eamio", "semestral", "concedido", "na", "confer\u00eancia", "IJCAI", "ao", "pesquisador", "em", "intelig\u00eancia", "artificial", "como", "um", "reconhecimento", "\u00e0", "excel\u00eancia", "de", "sua", "carreira", "."], "sentence-detokenized": "O Pr\u00eamio IJCAI de Excel\u00eancia em Pesquisa \u00e9 um pr\u00eamio semestral concedido na confer\u00eancia IJCAI ao pesquisador em intelig\u00eancia artificial como um reconhecimento \u00e0 excel\u00eancia de sua carreira.", "token2charspan": [[0, 1], [2, 8], [9, 14], [15, 17], [18, 28], [29, 31], [32, 40], [41, 42], [43, 45], [46, 52], [53, 62], [63, 72], [73, 75], [76, 87], [88, 93], [94, 96], [97, 108], [109, 111], [112, 124], [125, 135], [136, 140], [141, 143], [144, 158], [159, 160], [161, 171], [172, 174], [175, 178], [179, 187], [187, 188]]}
{"doc_key": "ai-test-339", "ner": [[0, 0, "researcher"], [7, 7, "conference"], [17, 25, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 7, 7, "role", "", false, false], [0, 0, 17, 25, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lenat", "foi", "um", "dos", "Fellows", "originais", "da", "AAAI", ",", "e", "\u00e9", "o", "\u00fanico", "indiv\u00edduo", "a", "ter", "nos", "Conselhos", "Consultivos", "Cient\u00edficos", "tanto", "da", "Microsoft", "como", "da", "Apple", "."], "sentence-detokenized": "Lenat foi um dos Fellows originais da AAAI, e \u00e9 o \u00fanico indiv\u00edduo a ter nos Conselhos Consultivos Cient\u00edficos tanto da Microsoft como da Apple.", "token2charspan": [[0, 5], [6, 9], [10, 12], [13, 16], [17, 24], [25, 34], [35, 37], [38, 42], [42, 43], [44, 45], [46, 47], [48, 49], [50, 55], [56, 65], [66, 67], [68, 71], [72, 75], [76, 85], [86, 97], [98, 109], [110, 115], [116, 118], [119, 128], [129, 133], [134, 136], [137, 142], [142, 143]]}
{"doc_key": "ai-test-340", "ner": [[0, 1, "algorithm"], [7, 9, "misc"], [13, 15, "metrics"], [22, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 7, 9, "related-to", "minimise", false, false], [13, 15, 7, 9, "type-of", "", false, false], [22, 22, 7, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Os", "autocodificadores", "s\u00e3o", "treinados", "para", "minimizar", "os", "erros", "de", "reconstru\u00e7\u00e3o", "(", "como", "o", "erro", "quadr\u00e1tico", "m\u00e9dio", ")", ",", "muitas", "vezes", "chamado", "de", "perda", ":"], "sentence-detokenized": "Os autocodificadores s\u00e3o treinados para minimizar os erros de reconstru\u00e7\u00e3o (como o erro quadr\u00e1tico m\u00e9dio), muitas vezes chamado de perda:", "token2charspan": [[0, 2], [3, 20], [21, 24], [25, 34], [35, 39], [40, 49], [50, 52], [53, 58], [59, 61], [62, 74], [75, 76], [76, 80], [81, 82], [83, 87], [88, 98], [99, 104], [104, 105], [105, 106], [107, 113], [114, 119], [120, 127], [128, 130], [131, 136], [136, 137]]}
{"doc_key": "ai-test-341", "ner": [[29, 32, "misc"], [36, 36, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[36, 36, 29, 32, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Uma", "alternativa", "para", "o", "uso", "das", "defini\u00e7\u00f5es", "\u00e9", "considerar", "a", "rela\u00e7\u00e3o", "palavra-sentido", "geral", "e", "calcular", "a", "similaridade", "de", "cada", "par", "de", "sentidos", "de", "palavras", "com", "base", "em", "uma", "determinada", "base", "de", "conhecimento", "lexical", ",", "como", "o", "WordNet", "."], "sentence-detokenized": "Uma alternativa para o uso das defini\u00e7\u00f5es \u00e9 considerar a rela\u00e7\u00e3o palavra-sentido geral e calcular a similaridade de cada par de sentidos de palavras com base em uma determinada base de conhecimento lexical, como o WordNet.", "token2charspan": [[0, 3], [4, 15], [16, 20], [21, 22], [23, 26], [27, 30], [31, 41], [42, 43], [44, 54], [55, 56], [57, 64], [65, 80], [81, 86], [87, 88], [89, 97], [98, 99], [100, 112], [113, 115], [116, 120], [121, 124], [125, 127], [128, 136], [137, 139], [140, 148], [149, 152], [153, 157], [158, 160], [161, 164], [165, 176], [177, 181], [182, 184], [185, 197], [198, 205], [205, 206], [207, 211], [212, 213], [214, 221], [221, 222]]}
{"doc_key": "ai-test-342", "ner": [[0, 0, "algorithm"], [8, 13, "researcher"], [23, 24, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 13, "origin", "", false, false], [8, 13, 23, 24, "role", "work_based_on_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["TD-Lambda", "\u00e9", "um", "algoritmo", "de", "aprendizado", "inventado", "por", "Richard", "S.", "Sutton", "com", "base", "no", "trabalho", "anterior", "sobre", "o", "aprendizado", "por", "diferen\u00e7a", "temporal", "de", "Arthur", "Samuel", "."], "sentence-detokenized": "TD-Lambda \u00e9 um algoritmo de aprendizado inventado por Richard S. Sutton com base no trabalho anterior sobre o aprendizado por diferen\u00e7a temporal de Arthur Samuel.", "token2charspan": [[0, 9], [10, 11], [12, 14], [15, 24], [25, 27], [28, 39], [40, 49], [50, 53], [54, 61], [62, 64], [65, 71], [72, 75], [76, 80], [81, 83], [84, 92], [93, 101], [102, 107], [108, 109], [110, 121], [122, 125], [126, 135], [136, 144], [145, 147], [148, 154], [155, 161], [161, 162]]}
{"doc_key": "ai-test-343", "ner": [[1, 3, "field"], [5, 5, "field"], [8, 9, "task"], [13, 16, "task"], [18, 18, "task"], [24, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 1, 3, "part-of", "task_part_of_field", false, false], [8, 9, 5, 5, "part-of", "task_part_of_field", false, false], [13, 16, 8, 9, "named", "", false, false], [18, 18, 8, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Na", "minera\u00e7\u00e3o", "de", "dados", "e", "estat\u00edstica", ",", "o", "agrupamento", "hier\u00e1rquico", "(", "tamb\u00e9m", "chamado", "an\u00e1lise", "hier\u00e1rquica", "de", "agrupamento", "ou", "HCA", ")", "\u00e9", "um", "m\u00e9todo", "de", "an\u00e1lise", "de", "agrupamento", "que", "procura", "construir", "uma", "hierarquia", "de", "agrupamentos", "."], "sentence-detokenized": "Na minera\u00e7\u00e3o de dados e estat\u00edstica, o agrupamento hier\u00e1rquico (tamb\u00e9m chamado an\u00e1lise hier\u00e1rquica de agrupamento ou HCA) \u00e9 um m\u00e9todo de an\u00e1lise de agrupamento que procura construir uma hierarquia de agrupamentos.", "token2charspan": [[0, 2], [3, 12], [13, 15], [16, 21], [22, 23], [24, 35], [35, 36], [37, 38], [39, 50], [51, 62], [63, 64], [64, 70], [71, 78], [79, 86], [87, 98], [99, 101], [102, 113], [114, 116], [117, 120], [120, 121], [122, 123], [124, 126], [127, 133], [134, 136], [137, 144], [145, 147], [148, 159], [160, 163], [164, 171], [172, 181], [182, 185], [186, 196], [197, 199], [200, 212], [212, 213]]}
{"doc_key": "ai-test-344", "ner": [[3, 3, "algorithm"], [10, 12, "field"], [14, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 10, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["O", "conceito", "de", "deconvolu\u00e7\u00e3o", "\u00e9", "amplamente", "utilizado", "nas", "t\u00e9cnicas", "de", "processamento", "de", "sinais", "e", "processamento", "de", "imagens", "."], "sentence-detokenized": "O conceito de deconvolu\u00e7\u00e3o \u00e9 amplamente utilizado nas t\u00e9cnicas de processamento de sinais e processamento de imagens.", "token2charspan": [[0, 1], [2, 10], [11, 13], [14, 26], [27, 28], [29, 39], [40, 49], [50, 53], [54, 62], [63, 65], [66, 79], [80, 82], [83, 89], [90, 91], [92, 105], [106, 108], [109, 116], [116, 117]]}
{"doc_key": "ai-test-345", "ner": [[0, 2, "algorithm"], [26, 27, "misc"], [31, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 26, 27, "related-to", "enhances", false, false], [0, 2, 26, 27, "related-to", "reduces", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Os", "mapas", "cognitivos", "servem", "\u00e0", "constru\u00e7\u00e3o", "e", "acumula\u00e7\u00e3o", "de", "conhecimento", "espacial", ",", "permitindo", "que", "o", "olho", "da", "mente", "visualize", "as", "imagens", "a", "fim", "de", "reduzir", "a", "carga", "cognitiva", ",", "melhorar", "a", "recorda\u00e7\u00e3o", "e", "o", "aprendizado", "da", "informa\u00e7\u00e3o", "."], "sentence-detokenized": "Os mapas cognitivos servem \u00e0 constru\u00e7\u00e3o e acumula\u00e7\u00e3o de conhecimento espacial, permitindo que o olho da mente visualize as imagens a fim de reduzir a carga cognitiva, melhorar a recorda\u00e7\u00e3o e o aprendizado da informa\u00e7\u00e3o.", "token2charspan": [[0, 2], [3, 8], [9, 19], [20, 26], [27, 28], [29, 39], [40, 41], [42, 52], [53, 55], [56, 68], [69, 77], [77, 78], [79, 89], [90, 93], [94, 95], [96, 100], [101, 103], [104, 109], [110, 119], [120, 122], [123, 130], [131, 132], [133, 136], [137, 139], [140, 147], [148, 149], [150, 155], [156, 165], [165, 166], [167, 175], [176, 177], [178, 188], [189, 190], [191, 192], [193, 204], [205, 207], [208, 218], [218, 219]]}
{"doc_key": "ai-test-346", "ner": [[1, 1, "programlang"], [3, 5, "programlang"], [7, 7, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["(", "Python", ",", "C", "+", "+", ",", "Java", ")", "."], "sentence-detokenized": "(Python, C + +, Java).", "token2charspan": [[0, 1], [1, 7], [7, 8], [9, 10], [11, 12], [13, 14], [14, 15], [16, 20], [20, 21], [21, 22]]}
{"doc_key": "ai-test-347", "ner": [[1, 2, "product"], [4, 4, "product"], [17, 19, "task"], [25, 27, "task"], [31, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 17, 19, "usage", "", false, false], [1, 2, 25, 27, "usage", "", false, false], [1, 2, 31, 34, "usage", "", false, false], [4, 4, 1, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Uma", "interface", "voz-usu\u00e1rio", "(", "VUI", ")", "torna", "poss\u00edvel", "a", "intera\u00e7\u00e3o", "humana", "falada", "com", "computadores", ",", "usando", "o", "reconhecimento", "da", "fala", "para", "entender", "comandos", "falados", "e", "respostas", "a", "perguntas", ",", "e", "tipicamente", "texto", "para", "a", "fala", "para", "reproduzir", "uma", "resposta", "."], "sentence-detokenized": "Uma interface voz-usu\u00e1rio (VUI) torna poss\u00edvel a intera\u00e7\u00e3o humana falada com computadores, usando o reconhecimento da fala para entender comandos falados e respostas a perguntas, e tipicamente texto para a fala para reproduzir uma resposta.", "token2charspan": [[0, 3], [4, 13], [14, 25], [26, 27], [27, 30], [30, 31], [32, 37], [38, 46], [47, 48], [49, 58], [59, 65], [66, 72], [73, 76], [77, 89], [89, 90], [91, 97], [98, 99], [100, 114], [115, 117], [118, 122], [123, 127], [128, 136], [137, 145], [146, 153], [154, 155], [156, 165], [166, 167], [168, 177], [177, 178], [179, 180], [181, 192], [193, 198], [199, 203], [204, 205], [206, 210], [211, 215], [216, 226], [227, 230], [231, 239], [239, 240]]}
{"doc_key": "ai-test-348", "ner": [[0, 0, "programlang"], [3, 5, "misc"], [9, 9, "programlang"], [14, 15, "researcher"], [17, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 5, "general-affiliation", "is_a", false, false], [0, 0, 9, 9, "general-affiliation", "made_with", false, false], [0, 0, 14, 15, "origin", "", false, false], [14, 15, 17, 18, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Jess", "\u00e9", "um", "mecanismo", "de", "regras", "para", "a", "plataforma", "Java", "que", "foi", "desenvolvido", "por", "Ernest", "Friedman-Hill", "of", "Sandia", "National", "."], "sentence-detokenized": "Jess \u00e9 um mecanismo de regras para a plataforma Java que foi desenvolvido por Ernest Friedman-Hill of Sandia National.", "token2charspan": [[0, 4], [5, 6], [7, 9], [10, 19], [20, 22], [23, 29], [30, 34], [35, 36], [37, 47], [48, 52], [53, 56], [57, 60], [61, 73], [74, 77], [78, 84], [85, 98], [99, 101], [102, 108], [109, 117], [117, 118]]}
{"doc_key": "ai-test-349", "ner": [[1, 2, "algorithm"], [19, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 19, 19, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Para", "perceptrons", "multicamadas", ",", "onde", "existe", "uma", "camada", "oculta", ",", "devem", "ser", "utilizados", "algoritmos", "mais", "sofisticados", ",", "como", "a", "retropropaga\u00e7\u00e3o", "."], "sentence-detokenized": "Para perceptrons multicamadas, onde existe uma camada oculta, devem ser utilizados algoritmos mais sofisticados, como a retropropaga\u00e7\u00e3o.", "token2charspan": [[0, 4], [5, 16], [17, 29], [29, 30], [31, 35], [36, 42], [43, 46], [47, 53], [54, 60], [60, 61], [62, 67], [68, 71], [72, 82], [83, 93], [94, 98], [99, 111], [111, 112], [113, 117], [118, 119], [120, 135], [135, 136]]}
{"doc_key": "ai-test-350", "ner": [[7, 8, "product"], [1, 5, "product"], [12, 17, "algorithm"], [22, 23, "field"], [28, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 5, 7, 8, "part-of", "", false, false], [1, 5, 12, 17, "usage", "", false, true], [12, 17, 22, 23, "related-to", "performs", false, false], [28, 33, 22, 23, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["O", "sistema", "de", "tradu\u00e7\u00e3o", "autom\u00e1tica", "neural", "do", "Google", "Translate", "usa", "uma", "grande", "rede", "neural", "artificial", "ponta", "a", "ponta", "que", "tenta", "realizar", "um", "aprendizado", "profundo", ",", "em", "particular", ",", "redes", "de", "mem\u00f3ria", "de", "longo", "prazo", "."], "sentence-detokenized": "O sistema de tradu\u00e7\u00e3o autom\u00e1tica neural do Google Translate usa uma grande rede neural artificial ponta a ponta que tenta realizar um aprendizado profundo, em particular, redes de mem\u00f3ria de longo prazo.", "token2charspan": [[0, 1], [2, 9], [10, 12], [13, 21], [22, 32], [33, 39], [40, 42], [43, 49], [50, 59], [60, 63], [64, 67], [68, 74], [75, 79], [80, 86], [87, 97], [98, 103], [104, 105], [106, 111], [112, 115], [116, 121], [122, 130], [131, 133], [134, 145], [146, 154], [154, 155], [156, 158], [159, 169], [169, 170], [171, 176], [177, 179], [180, 187], [188, 190], [191, 196], [197, 202], [202, 203]]}
{"doc_key": "ai-test-351", "ner": [[16, 16, "researcher"], [18, 18, "researcher"], [20, 20, "researcher"], [22, 23, "researcher"], [25, 26, "researcher"], [28, 28, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["V\u00e1rios", "m\u00e9todos", "para", "fazer", "isso", "foram", "desenvolvidos", "nos", "anos", "80", "e", "in\u00edcio", "dos", "anos", "90", "por", "Werbos", ",", "Williams", ",", "Robinson", ",", "J\u00fcrgen", "Schmidhuber", ",", "Sepp", "Hochreiter", ",", "Pearlmutter", "e", "outros", "."], "sentence-detokenized": "V\u00e1rios m\u00e9todos para fazer isso foram desenvolvidos nos anos 80 e in\u00edcio dos anos 90 por Werbos, Williams, Robinson, J\u00fcrgen Schmidhuber, Sepp Hochreiter, Pearlmutter e outros.", "token2charspan": [[0, 6], [7, 14], [15, 19], [20, 25], [26, 30], [31, 36], [37, 50], [51, 54], [55, 59], [60, 62], [63, 64], [65, 71], [72, 75], [76, 80], [81, 83], [84, 87], [88, 94], [94, 95], [96, 104], [104, 105], [106, 114], [114, 115], [116, 122], [123, 134], [134, 135], [136, 140], [141, 151], [151, 152], [153, 164], [165, 166], [167, 173], [173, 174]]}
{"doc_key": "ai-test-352", "ner": [[1, 1, "organisation"], [2, 3, "organisation"], [8, 8, "organisation"], [13, 15, "task"], [20, 20, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 8, 8, "role", "licenses_from", false, false], [2, 3, 1, 1, "named", "", false, false], [20, 20, 1, 1, "origin", "", false, false], [20, 20, 13, 15, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["|", "Apple", "Apple", "Inc", "software", "originalmente", "licenciado", "pela", "Nuance", "para", "fornecer", "capacidade", "de", "reconhecimento", "da", "fala", "a", "seu", "assistente", "digital", "Siri", "."], "sentence-detokenized": "| Apple Apple Inc software originalmente licenciado pela Nuance para fornecer capacidade de reconhecimento da fala a seu assistente digital Siri.", "token2charspan": [[0, 1], [2, 7], [8, 13], [14, 17], [18, 26], [27, 40], [41, 51], [52, 56], [57, 63], [64, 68], [69, 77], [78, 88], [89, 91], [92, 106], [107, 109], [110, 114], [115, 116], [117, 120], [121, 131], [132, 139], [140, 144], [144, 145]]}
{"doc_key": "ai-test-353", "ner": [[0, 0, "organisation"], [3, 4, "misc"], [7, 8, "person"], [12, 13, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 3, 4, "role", "releases_movies_in_genre", false, false], [7, 8, 0, 0, "role", "directs_for", false, false], [12, 13, 0, 0, "role", "directs_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Columbia", "lan\u00e7ou", "v\u00e1rios", "westerns", "3D", "produzidos", "por", "Sam", "Katzman", "e", "dirigidos", "por", "William", "Castle", "."], "sentence-detokenized": "Columbia lan\u00e7ou v\u00e1rios westerns 3D produzidos por Sam Katzman e dirigidos por William Castle.", "token2charspan": [[0, 8], [9, 15], [16, 22], [23, 31], [32, 34], [35, 45], [46, 49], [50, 53], [54, 61], [62, 63], [64, 73], [74, 77], [78, 85], [86, 92], [92, 93]]}
{"doc_key": "ai-test-354", "ner": [[8, 8, "field"], [10, 10, "field"], [12, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ela", "incorpora", "conhecimentos", "e", "pesquisas", "nas", "\u00e1reas", "de", "inform\u00e1tica", ",", "ling\u00fc\u00edstica", "e", "engenharia", "da", "computa\u00e7\u00e3o", "."], "sentence-detokenized": "Ela incorpora conhecimentos e pesquisas nas \u00e1reas de inform\u00e1tica, ling\u00fc\u00edstica e engenharia da computa\u00e7\u00e3o.", "token2charspan": [[0, 3], [4, 13], [14, 27], [28, 29], [30, 39], [40, 43], [44, 49], [50, 52], [53, 64], [64, 65], [66, 77], [78, 79], [80, 90], [91, 93], [94, 104], [104, 105]]}
{"doc_key": "ai-test-355", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Aqui", "est\u00e1", "um", "exemplo", "do", "c\u00f3digo", "R", ":"], "sentence-detokenized": "Aqui est\u00e1 um exemplo do c\u00f3digo R:", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 20], [21, 23], [24, 30], [31, 32], [32, 33]]}
{"doc_key": "ai-test-356", "ner": [[1, 2, "metrics"], [7, 9, "metrics"], [11, 11, "metrics"], [15, 17, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 7, 9, "part-of", "plotted_into", false, false], [1, 2, 15, 17, "part-of", "plotted_into", false, false], [11, 11, 7, 9, "named", "", false, false], [19, 19, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "curva", "ROC", "\u00e9", "criada", "tra\u00e7ando", "a", "TRUE", "positive", "rate", "(", "TPR", ")", "contra", "a", "FALSE", "positive", "rate", "(", "FPR", ")", "em", "v\u00e1rios", "ajustes", "de", "limiar", "."], "sentence-detokenized": "A curva ROC \u00e9 criada tra\u00e7ando a TRUE positive rate (TPR) contra a FALSE positive rate (FPR) em v\u00e1rios ajustes de limiar.", "token2charspan": [[0, 1], [2, 7], [8, 11], [12, 13], [14, 20], [21, 29], [30, 31], [32, 36], [37, 45], [46, 50], [51, 52], [52, 55], [55, 56], [57, 63], [64, 65], [66, 71], [72, 80], [81, 85], [86, 87], [87, 90], [90, 91], [92, 94], [95, 101], [102, 109], [110, 112], [113, 119], [119, 120]]}
{"doc_key": "ai-test-357", "ner": [[5, 7, "field"], [9, 10, "researcher"], [12, 13, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 5, 7, "related-to", "researches_field", false, false], [12, 13, 5, 7, "related-to", "researches_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pesquisa", "estagnada", "ap\u00f3s", "pesquisa", "de", "aprendizagem", "de", "m\u00e1quinas", "por", "Marvin", "Minsky", "e", "Seymour", "Papert", "(", "1969", ")", ","], "sentence-detokenized": "Pesquisa estagnada ap\u00f3s pesquisa de aprendizagem de m\u00e1quinas por Marvin Minsky e Seymour Papert (1969),", "token2charspan": [[0, 8], [9, 18], [19, 23], [24, 32], [33, 35], [36, 48], [49, 51], [52, 60], [61, 64], [65, 71], [72, 78], [79, 80], [81, 88], [89, 95], [96, 97], [97, 101], [101, 102], [102, 103]]}
{"doc_key": "ai-test-358", "ner": [[11, 11, "task"], [13, 15, "programlang"], [17, 20, "product"], [22, 23, "programlang"], [25, 25, "product"], [28, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 13, 15, "related-to", "used_to_build", false, false], [11, 11, 17, 20, "related-to", "used_to_build", false, false], [11, 11, 22, 23, "related-to", "used_to_build", false, false], [11, 11, 25, 25, "related-to", "used_to_build", false, false], [11, 11, 28, 28, "related-to", "used_to_build", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Outros", "ambientes", "de", "programa\u00e7\u00e3o", "que", "s\u00e3o", "usados", "para", "construir", "aplica\u00e7\u00f5es", "de", "DAQ", "incluem", "l\u00f3gica", "de", "escada", ",", "Visual", "C", "+", "+", ",", "Visual", "Basic", ",", "LabVIEW", ",", "e", "MATLAB", "."], "sentence-detokenized": "Outros ambientes de programa\u00e7\u00e3o que s\u00e3o usados para construir aplica\u00e7\u00f5es de DAQ incluem l\u00f3gica de escada, Visual C + +, Visual Basic, LabVIEW, e MATLAB.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 31], [32, 35], [36, 39], [40, 46], [47, 51], [52, 61], [62, 72], [73, 75], [76, 79], [80, 87], [88, 94], [95, 97], [98, 104], [104, 105], [106, 112], [113, 114], [115, 116], [117, 118], [118, 119], [120, 126], [127, 132], [132, 133], [134, 141], [141, 142], [143, 144], [145, 151], [151, 152]]}
{"doc_key": "ai-test-359", "ner": [[11, 12, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "m\u00e9trica", "foi", "projetada", "para", "corrigir", "alguns", "dos", "problemas", "encontrados", "na", "m\u00e9trica", "BLEU", "mais", "popular", ",", "e", "tamb\u00e9m", "produzir", "uma", "boa", "correla\u00e7\u00e3o", "com", "o", "julgamento", "humano", "no", "n\u00edvel", "da", "senten\u00e7a", "ou", "segmento", "."], "sentence-detokenized": "A m\u00e9trica foi projetada para corrigir alguns dos problemas encontrados na m\u00e9trica BLEU mais popular, e tamb\u00e9m produzir uma boa correla\u00e7\u00e3o com o julgamento humano no n\u00edvel da senten\u00e7a ou segmento.", "token2charspan": [[0, 1], [2, 9], [10, 13], [14, 23], [24, 28], [29, 37], [38, 44], [45, 48], [49, 58], [59, 70], [71, 73], [74, 81], [82, 86], [87, 91], [92, 99], [99, 100], [101, 102], [103, 109], [110, 118], [119, 122], [123, 126], [127, 137], [138, 141], [142, 143], [144, 154], [155, 161], [162, 164], [165, 170], [171, 173], [174, 182], [183, 185], [186, 194], [194, 195]]}
{"doc_key": "ai-test-360", "ner": [[2, 4, "algorithm"], [6, 8, "algorithm"], [10, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["T\u00e9cnicas", "como", "redes", "din\u00e2micas", "Markov", ",", "rede", "neural", "convolucional", "e", "mem\u00f3ria", "de", "longo", "prazo", "s\u00e3o", "freq\u00fcentemente", "empregadas", "para", "explorar", "as", "correla\u00e7\u00f5es", "sem\u00e2nticas", "entre", "quadros", "de", "v\u00eddeo", "consecutivos", "."], "sentence-detokenized": "T\u00e9cnicas como redes din\u00e2micas Markov, rede neural convolucional e mem\u00f3ria de longo prazo s\u00e3o freq\u00fcentemente empregadas para explorar as correla\u00e7\u00f5es sem\u00e2nticas entre quadros de v\u00eddeo consecutivos.", "token2charspan": [[0, 8], [9, 13], [14, 19], [20, 29], [30, 36], [36, 37], [38, 42], [43, 49], [50, 63], [64, 65], [66, 73], [74, 76], [77, 82], [83, 88], [89, 92], [93, 107], [108, 118], [119, 123], [124, 132], [133, 135], [136, 147], [148, 158], [159, 164], [165, 172], [173, 175], [176, 181], [182, 194], [194, 195]]}
{"doc_key": "ai-test-361", "ner": [[2, 4, "product"], [6, 6, "product"], [16, 17, "product"], [22, 22, "product"], [38, 38, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 16, 17, "artifact", "", false, false], [2, 4, 38, 38, "named", "", false, false], [6, 6, 2, 4, "named", "", false, false], [22, 22, 16, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["As", "placas", "de", "circuito", "impresso", "(", "PCBs", ")", "produzidas", "em", "massa", "s\u00e3o", "quase", "exclusivamente", "fabricadas", "por", "rob\u00f4s", "pick-and-place", ",", "normalmente", "com", "manipuladores", "SCARA", ",", "que", "removem", "min\u00fasculos", "componentes", "eletr\u00f4nicos", "de", "tiras", "ou", "bandejas", ",", "e", "os", "colocam", "em", "PCBs", "com", "grande", "precis\u00e3o", "."], "sentence-detokenized": "As placas de circuito impresso (PCBs) produzidas em massa s\u00e3o quase exclusivamente fabricadas por rob\u00f4s pick-and-place, normalmente com manipuladores SCARA, que removem min\u00fasculos componentes eletr\u00f4nicos de tiras ou bandejas, e os colocam em PCBs com grande precis\u00e3o.", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 21], [22, 30], [31, 32], [32, 36], [36, 37], [38, 48], [49, 51], [52, 57], [58, 61], [62, 67], [68, 82], [83, 93], [94, 97], [98, 103], [104, 118], [118, 119], [120, 131], [132, 135], [136, 149], [150, 155], [155, 156], [157, 160], [161, 168], [169, 179], [180, 191], [192, 203], [204, 206], [207, 212], [213, 215], [216, 224], [224, 225], [226, 227], [228, 230], [231, 238], [239, 241], [242, 246], [247, 250], [251, 257], [258, 266], [266, 267]]}
{"doc_key": "ai-test-362", "ner": [[3, 5, "field"], [15, 16, "algorithm"], [21, 22, "researcher"], [24, 25, "researcher"], [27, 29, "researcher"], [37, 38, "algorithm"], [41, 43, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 16, 3, 5, "part-of", "", false, false], [15, 16, 21, 22, "origin", "", false, false], [15, 16, 24, 25, "origin", "", false, false], [15, 16, 27, 29, "origin", "", false, false], [15, 16, 37, 38, "type-of", "", false, false], [37, 38, 41, 43, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["No", "contexto", "da", "aprendizagem", "de", "m\u00e1quinas", ",", "onde", "ela", "\u00e9", "mais", "amplamente", "aplicada", "atualmente", ",", "a", "LDA", "foi", "redescoberta", "independentemente", "por", "David", "Blei", ",", "Andrew", "Ng", "e", "Michael", "I.", "Jordan", "em", "2003", ",", "e", "apresentada", "como", "um", "modelo", "gr\u00e1fico", "para", "a", "descoberta", "de", "t\u00f3picos", "."], "sentence-detokenized": "No contexto da aprendizagem de m\u00e1quinas, onde ela \u00e9 mais amplamente aplicada atualmente, a LDA foi redescoberta independentemente por David Blei, Andrew Ng e Michael I. Jordan em 2003, e apresentada como um modelo gr\u00e1fico para a descoberta de t\u00f3picos.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 27], [28, 30], [31, 39], [39, 40], [41, 45], [46, 49], [50, 51], [52, 56], [57, 67], [68, 76], [77, 87], [87, 88], [89, 90], [91, 94], [95, 98], [99, 111], [112, 129], [130, 133], [134, 139], [140, 144], [144, 145], [146, 152], [153, 155], [156, 157], [158, 165], [166, 168], [169, 175], [176, 178], [179, 183], [183, 184], [185, 186], [187, 198], [199, 203], [204, 206], [207, 213], [214, 221], [222, 226], [227, 228], [229, 239], [240, 242], [243, 250], [250, 251]]}
{"doc_key": "ai-test-363", "ner": [[9, 9, "task"], [14, 14, "misc"], [17, 17, "metrics"], [19, 19, "metrics"], [22, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 9, 14, 14, "related-to", "task_across_domain", false, false]], "relations_mapping_to_source": [0], "sentence": ["O", "desempenho", "medido", "nos", "dados", "de", "teste", "de", "oito", "WSI", "ing\u00eanuos", "atrav\u00e9s", "de", "v\u00e1rias", "tauopatias", "resultou", "no", "recall", ",", "precis\u00e3o", "e", "uma", "pontua\u00e7\u00e3o", "F1", "de", "0,92", ",", "0,72", ",", "e", "0,81", ",", "respectivamente", "."], "sentence-detokenized": "O desempenho medido nos dados de teste de oito WSI ing\u00eanuos atrav\u00e9s de v\u00e1rias tauopatias resultou no recall, precis\u00e3o e uma pontua\u00e7\u00e3o F1 de 0,92, 0,72, e 0,81, respectivamente.", "token2charspan": [[0, 1], [2, 12], [13, 19], [20, 23], [24, 29], [30, 32], [33, 38], [39, 41], [42, 46], [47, 50], [51, 59], [60, 67], [68, 70], [71, 77], [78, 88], [89, 97], [98, 100], [101, 107], [107, 108], [109, 117], [118, 119], [120, 123], [124, 133], [134, 136], [137, 139], [140, 144], [144, 145], [146, 150], [150, 151], [152, 153], [154, 158], [158, 159], [160, 175], [175, 176]]}
{"doc_key": "ai-test-364", "ner": [[5, 5, "field"], [13, 15, "field"], [20, 20, "field"], [24, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 20, 20, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["Com", "a", "ajuda", "de", "tecnologias", "AR", "avan\u00e7adas", "(", "por", "exemplo", ",", "adi\u00e7\u00e3o", "de", "vis\u00e3o", "de", "computador", ",", "incorpora\u00e7\u00e3o", "de", "c\u00e2meras", "AR", "no", "smartphone", "e", "reconhecimento", "de", "objetos", ")", "as", "informa\u00e7\u00f5es", "sobre", "o", "mundo", "real", "ao", "redor", "do", "usu\u00e1rio", "se", "tornam", "interativas", "e", "manipuladas", "digitalmente", "."], "sentence-detokenized": "Com a ajuda de tecnologias AR avan\u00e7adas (por exemplo, adi\u00e7\u00e3o de vis\u00e3o de computador, incorpora\u00e7\u00e3o de c\u00e2meras AR no smartphone e reconhecimento de objetos) as informa\u00e7\u00f5es sobre o mundo real ao redor do usu\u00e1rio se tornam interativas e manipuladas digitalmente.", "token2charspan": [[0, 3], [4, 5], [6, 11], [12, 14], [15, 26], [27, 29], [30, 39], [40, 41], [41, 44], [45, 52], [52, 53], [54, 60], [61, 63], [64, 69], [70, 72], [73, 83], [83, 84], [85, 97], [98, 100], [101, 108], [109, 111], [112, 114], [115, 125], [126, 127], [128, 142], [143, 145], [146, 153], [153, 154], [155, 157], [158, 169], [170, 175], [176, 177], [178, 183], [184, 188], [189, 191], [192, 197], [198, 200], [201, 208], [209, 211], [212, 218], [219, 230], [231, 232], [233, 244], [245, 257], [257, 258]]}
{"doc_key": "ai-test-365", "ner": [[3, 4, "researcher"], [10, 10, "organisation"], [18, 19, "field"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 10, 10, "role", "forms_company", false, false], [10, 10, 18, 19, "related-to", "works_with", false, false], [10, 10, 28, 29, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Em", "2014", ",", "a", "Schmidhuber", "formou", "uma", "empresa", ",", "a", "Nnaisense", ",", "para", "trabalhar", "em", "aplica\u00e7\u00f5es", "comerciais", "de", "intelig\u00eancia", "artificial", "em", "campos", "como", "finan\u00e7as", ",", "ind\u00fastria", "pesada", "e", "autom\u00f3veis", "automotores", "."], "sentence-detokenized": "Em 2014, a Schmidhuber formou uma empresa, a Nnaisense, para trabalhar em aplica\u00e7\u00f5es comerciais de intelig\u00eancia artificial em campos como finan\u00e7as, ind\u00fastria pesada e autom\u00f3veis automotores.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 22], [23, 29], [30, 33], [34, 41], [41, 42], [43, 44], [45, 54], [54, 55], [56, 60], [61, 70], [71, 73], [74, 84], [85, 95], [96, 98], [99, 111], [112, 122], [123, 125], [126, 132], [133, 137], [138, 146], [146, 147], [148, 157], [158, 164], [165, 166], [167, 177], [178, 189], [189, 190]]}
{"doc_key": "ai-test-366", "ner": [[24, 26, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Isto", "n\u00e3o", "s\u00f3", "altera", "o", "desempenho", "de", "todos", "os", "testes", "subseq\u00fcentes", "no", "modelo", "explicativo", "retido", ",", "como", "tamb\u00e9m", "pode", "introduzir", "vi\u00e9s", "e", "alterar", "o", "erro", "quadr\u00e1tico", "m\u00e9dio", "na", "estimativa", "."], "sentence-detokenized": "Isto n\u00e3o s\u00f3 altera o desempenho de todos os testes subseq\u00fcentes no modelo explicativo retido, como tamb\u00e9m pode introduzir vi\u00e9s e alterar o erro quadr\u00e1tico m\u00e9dio na estimativa.", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 18], [19, 20], [21, 31], [32, 34], [35, 40], [41, 43], [44, 50], [51, 63], [64, 66], [67, 73], [74, 85], [86, 92], [92, 93], [94, 98], [99, 105], [106, 110], [111, 121], [122, 126], [127, 128], [129, 136], [137, 138], [139, 143], [144, 154], [155, 160], [161, 163], [164, 174], [174, 175]]}
{"doc_key": "ai-test-367", "ner": [[0, 1, "misc"], [5, 7, "algorithm"], [12, 14, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 7, 0, 1, "usage", "", false, false], [5, 7, 12, 14, "topic", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Os", "bigrams", "s\u00e3o", "usados", "nos", "modelos", "lingu\u00edsticos", "de", "maior", "sucesso", "para", "o", "reconhecimento", "da", "fala", "."], "sentence-detokenized": "Os bigrams s\u00e3o usados nos modelos lingu\u00edsticos de maior sucesso para o reconhecimento da fala.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 21], [22, 25], [26, 33], [34, 46], [47, 49], [50, 55], [56, 63], [64, 68], [69, 70], [71, 85], [86, 88], [89, 93], [93, 94]]}
{"doc_key": "ai-test-368", "ner": [[3, 4, "field"], [7, 9, "misc"], [15, 17, "misc"], [21, 24, "organisation"], [27, 30, "misc"], [35, 38, "organisation"], [41, 43, "misc"], [48, 51, "organisation"], [54, 56, "misc"], [61, 64, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[7, 9, 3, 4, "topic", "", false, false], [15, 17, 21, 24, "origin", "", false, false], [27, 30, 35, 38, "origin", "", false, false], [41, 43, 48, 51, "origin", "", false, false], [54, 56, 61, 64, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Sua", "pesquisa", "em", "psicologia", "cognitiva", "ganhou", "o", "Pr\u00eamio", "Early", "Career", "(", "1984", ")", "e", "o", "Pr\u00eamio", "Boyd", "McCandless", "1986", ")", "da", "Associa\u00e7\u00e3o", "Americana", "de", "Psicologia", ",", "o", "Pr\u00eamio", "Troland", "de", "Pesquisa", "(", "1993", ")", "da", "Academia", "Nacional", "de", "Ci\u00eancias", ",", "o", "Pr\u00eamio", "Henry", "Dale", "(", "2004", ")", "da", "Institui\u00e7\u00e3o", "Real", "da", "Gr\u00e3-Bretanha", "e", "o", "Pr\u00eamio", "George", "Miller", "(", "2010", ")", "da", "Sociedade", "de", "Neuroci\u00eancia", "Cognitiva", "."], "sentence-detokenized": "Sua pesquisa em psicologia cognitiva ganhou o Pr\u00eamio Early Career (1984) e o Pr\u00eamio Boyd McCandless 1986) da Associa\u00e7\u00e3o Americana de Psicologia, o Pr\u00eamio Troland de Pesquisa (1993) da Academia Nacional de Ci\u00eancias, o Pr\u00eamio Henry Dale (2004) da Institui\u00e7\u00e3o Real da Gr\u00e3-Bretanha e o Pr\u00eamio George Miller (2010) da Sociedade de Neuroci\u00eancia Cognitiva.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 26], [27, 36], [37, 43], [44, 45], [46, 52], [53, 58], [59, 65], [66, 67], [67, 71], [71, 72], [73, 74], [75, 76], [77, 83], [84, 88], [89, 99], [100, 104], [104, 105], [106, 108], [109, 119], [120, 129], [130, 132], [133, 143], [143, 144], [145, 146], [147, 153], [154, 161], [162, 164], [165, 173], [174, 175], [175, 179], [179, 180], [181, 183], [184, 192], [193, 201], [202, 204], [205, 213], [213, 214], [215, 216], [217, 223], [224, 229], [230, 234], [235, 236], [236, 240], [240, 241], [242, 244], [245, 256], [257, 261], [262, 264], [265, 277], [278, 279], [280, 281], [282, 288], [289, 295], [296, 302], [303, 304], [304, 308], [308, 309], [310, 312], [313, 322], [323, 325], [326, 338], [339, 348], [348, 349]]}
{"doc_key": "ai-test-369", "ner": [[1, 2, "misc"], [13, 13, "misc"], [9, 12, "product"], [17, 17, "researcher"], [19, 19, "researcher"], [26, 27, "researcher"], [29, 30, "researcher"], [32, 33, "task"], [35, 38, "researcher"], [40, 44, "researcher"], [45, 46, "task"], [53, 53, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[1, 2, 13, 13, "named", "", false, false], [1, 2, 53, 53, "named", "", false, false], [13, 13, 17, 17, "origin", "", false, false], [13, 13, 19, 19, "origin", "", false, false], [13, 13, 32, 33, "related-to", "used_for", false, false], [9, 12, 13, 13, "usage", "", false, false], [9, 12, 45, 46, "named", "", false, false], [26, 27, 13, 13, "usage", "", false, false], [26, 27, 35, 38, "named", "same", false, false], [29, 30, 13, 13, "usage", "", false, false], [29, 30, 40, 44, "named", "same", false, false], [45, 46, 53, 53, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Um", "rosto", "pr\u00f3prio", "(", "A", "abordagem", "de", "utilizar", "o", "sistema", "de", "reconhecimento", "facial", "eigenface", "foi", "desenvolvida", "por", "Sirovich", "e", "Kirby", "(", "1987", ")", "e", "utilizada", "por", "Matthew", "Turk", "e", "Alex", "Pentland", "na", "classifica\u00e7\u00e3o", "facial", ".", "Turk", ",", "Matthew", "A", "e", "Pentland", ",", "Alex", "P", ".", "Reconhecimento", "facial", "usando", "o", "sistema", "de", "reconhecimento", "facial", "eigenface", "."], "sentence-detokenized": "Um rosto pr\u00f3prio (A abordagem de utilizar o sistema de reconhecimento facial eigenface foi desenvolvida por Sirovich e Kirby (1987) e utilizada por Matthew Turk e Alex Pentland na classifica\u00e7\u00e3o facial. Turk, Matthew A e Pentland, Alex P. Reconhecimento facial usando o sistema de reconhecimento facial eigenface.", "token2charspan": [[0, 2], [3, 8], [9, 16], [17, 18], [18, 19], [20, 29], [30, 32], [33, 41], [42, 43], [44, 51], [52, 54], [55, 69], [70, 76], [77, 86], [87, 90], [91, 103], [104, 107], [108, 116], [117, 118], [119, 124], [125, 126], [126, 130], [130, 131], [132, 133], [134, 143], [144, 147], [148, 155], [156, 160], [161, 162], [163, 167], [168, 176], [177, 179], [180, 193], [194, 200], [200, 201], [202, 206], [206, 207], [208, 215], [216, 217], [218, 219], [220, 228], [228, 229], [230, 234], [235, 236], [236, 237], [238, 252], [253, 259], [260, 266], [267, 268], [269, 276], [277, 279], [280, 294], [295, 301], [302, 311], [311, 312]]}
{"doc_key": "ai-test-370", "ner": [[5, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Um", "dicion\u00e1rio", "lexical", "como", "o", "WordNet", "pode", "ent\u00e3o", "ser", "usado", "para", "entender", "o", "contexto", "."], "sentence-detokenized": "Um dicion\u00e1rio lexical como o WordNet pode ent\u00e3o ser usado para entender o contexto.", "token2charspan": [[0, 2], [3, 13], [14, 21], [22, 26], [27, 28], [29, 36], [37, 41], [42, 47], [48, 51], [52, 57], [58, 62], [63, 71], [72, 73], [74, 82], [82, 83]]}
{"doc_key": "ai-test-371", "ner": [[0, 1, "misc"], [10, 10, "misc"], [20, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 10, 10, "part-of", "", false, false], [10, 10, 20, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "hipon\u00edmia", "\u00e9", "a", "rela\u00e7\u00e3o", "mais", "freq\u00fcentemente", "codificada", "entre", "os", "sistemas", "utilizados", "em", "bancos", "de", "dados", "lexicais", ",", "como", "o", "WordNet", "."], "sentence-detokenized": "A hipon\u00edmia \u00e9 a rela\u00e7\u00e3o mais freq\u00fcentemente codificada entre os sistemas utilizados em bancos de dados lexicais, como o WordNet.", "token2charspan": [[0, 1], [2, 11], [12, 13], [14, 15], [16, 23], [24, 28], [29, 43], [44, 54], [55, 60], [61, 63], [64, 72], [73, 83], [84, 86], [87, 93], [94, 96], [97, 102], [103, 111], [111, 112], [113, 117], [118, 119], [120, 127], [127, 128]]}
{"doc_key": "ai-test-372", "ner": [[0, 0, "organisation"], [7, 9, "programlang"], [11, 11, "programlang"], [40, 40, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 7, 9, "general-affiliation", "", false, false], [0, 0, 11, 11, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["OPeNDAP", "oferece", "bibliotecas", "de", "c\u00f3digo", "aberto", "em", "C", "+", "+", "e", "Java", ",", "mas", "muitos", "clientes", "dependem", "de", "bibliotecas", "desenvolvidas", "pela", "comunidade", ",", "tais", "como", "bibliotecas", "que", "incluem", "recursos", "incorporados", "para", "recupera\u00e7\u00e3o", "(", "estilo", "array-style", ")", "de", "dados", "de", "servidores", "DAP", "."], "sentence-detokenized": "OPeNDAP oferece bibliotecas de c\u00f3digo aberto em C + + e Java, mas muitos clientes dependem de bibliotecas desenvolvidas pela comunidade, tais como bibliotecas que incluem recursos incorporados para recupera\u00e7\u00e3o (estilo array-style) de dados de servidores DAP.", "token2charspan": [[0, 7], [8, 15], [16, 27], [28, 30], [31, 37], [38, 44], [45, 47], [48, 49], [50, 51], [52, 53], [54, 55], [56, 60], [60, 61], [62, 65], [66, 72], [73, 81], [82, 90], [91, 93], [94, 105], [106, 119], [120, 124], [125, 135], [135, 136], [137, 141], [142, 146], [147, 158], [159, 162], [163, 170], [171, 179], [180, 192], [193, 197], [198, 209], [210, 211], [211, 217], [218, 229], [229, 230], [231, 233], [234, 239], [240, 242], [243, 253], [254, 257], [257, 258]]}
{"doc_key": "ai-test-373", "ner": [[3, 4, "misc"], [7, 7, "product"], [19, 19, "country"], [31, 32, "misc"], [48, 48, "organisation"], [46, 47, "product"], [54, 54, "organisation"], [51, 52, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 4, 19, 19, "opposite", "", false, false], [7, 7, 19, 19, "artifact", "", false, false], [31, 32, 7, 7, "part-of", "", false, false], [46, 47, 48, 48, "artifact", "", false, false], [51, 52, 54, 54, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Nessa", "p\u00e1gina", ",", "Samurai", "Damashii", "exagerou", "o", "Senkousha", "como", "a", "cristaliza\u00e7\u00e3o", "dos", "quatro", "mil", "anos", "de", "conhecimento", "cient\u00edfico", "da", "China", ",", "comentou", "sobre", "o", "design", "bruto", "(", "por", "exemplo", ",", "o", "Canh\u00e3o", "chin\u00eas", "em", "suas", "virilhas", ")", ",", "e", "colocou", "sua", "imagem", "entre", "as", "imagens", "do", "ASIMO", "da", "Honda", "e", "do", "QRIO", "SDR-3X", "da", "Sony", "por", "justaposi\u00e7\u00e3o", "."], "sentence-detokenized": "Nessa p\u00e1gina, Samurai Damashii exagerou o Senkousha como a cristaliza\u00e7\u00e3o dos quatro mil anos de conhecimento cient\u00edfico da China, comentou sobre o design bruto (por exemplo, o Canh\u00e3o chin\u00eas em suas virilhas), e colocou sua imagem entre as imagens do ASIMO da Honda e do QRIO SDR-3X da Sony por justaposi\u00e7\u00e3o.", "token2charspan": [[0, 5], [6, 12], [12, 13], [14, 21], [22, 30], [31, 39], [40, 41], [42, 51], [52, 56], [57, 58], [59, 72], [73, 76], [77, 83], [84, 87], [88, 92], [93, 95], [96, 108], [109, 119], [120, 122], [123, 128], [128, 129], [130, 138], [139, 144], [145, 146], [147, 153], [154, 159], [160, 161], [161, 164], [165, 172], [172, 173], [174, 175], [176, 182], [183, 189], [190, 192], [193, 197], [198, 206], [206, 207], [207, 208], [209, 210], [211, 218], [219, 222], [223, 229], [230, 235], [236, 238], [239, 246], [247, 249], [250, 255], [256, 258], [259, 264], [265, 266], [267, 269], [270, 274], [275, 281], [282, 284], [285, 289], [290, 293], [294, 306], [306, 307]]}
{"doc_key": "ai-test-374", "ner": [[10, 11, "algorithm"], [22, 22, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 22, 22, "part-of", "includes_functionality_of", false, false], [10, 11, 24, 24, "part-of", "includes_functionality_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["H\u00e1", "tamb\u00e9m", "muitas", "bibliotecas", "de", "programa\u00e7\u00e3o", "que", "cont\u00eam", "funcionalidades", "de", "redes", "neurais", "e", "que", "podem", "ser", "usadas", "em", "implementa\u00e7\u00f5es", "personalizadas", "(", "como", "TensorFlow", ",", "Theano", ",", "etc.", ")", "."], "sentence-detokenized": "H\u00e1 tamb\u00e9m muitas bibliotecas de programa\u00e7\u00e3o que cont\u00eam funcionalidades de redes neurais e que podem ser usadas em implementa\u00e7\u00f5es personalizadas (como TensorFlow, Theano, etc.).", "token2charspan": [[0, 2], [3, 9], [10, 16], [17, 28], [29, 31], [32, 43], [44, 47], [48, 54], [55, 70], [71, 73], [74, 79], [80, 87], [88, 89], [90, 93], [94, 99], [100, 103], [104, 110], [111, 113], [114, 128], [129, 143], [144, 145], [145, 149], [150, 160], [160, 161], [162, 168], [168, 169], [170, 174], [174, 175], [175, 176]]}
{"doc_key": "ai-test-375", "ner": [[4, 7, "conference"], [9, 9, "organisation"], [11, 17, "conference"], [19, 19, "conference"], [21, 21, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ele", "\u00e9", "membro", "da", "Association", "for", "Computing", "Machinery", ",", "IEEE", ",", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "IAPR", "e", "SPIE", "."], "sentence-detokenized": "Ele \u00e9 membro da Association for Computing Machinery, IEEE, American Association for the Advancement of Science, IAPR e SPIE.", "token2charspan": [[0, 3], [4, 5], [6, 12], [13, 15], [16, 27], [28, 31], [32, 41], [42, 51], [51, 52], [53, 57], [57, 58], [59, 67], [68, 79], [80, 83], [84, 87], [88, 99], [100, 102], [103, 110], [110, 111], [112, 116], [117, 118], [119, 123], [123, 124]]}
{"doc_key": "ai-test-376", "ner": [[3, 3, "organisation"], [9, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 9, 12, "related-to", "runs_trials_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["Um", "julgamento", "pela", "RET", "em", "2011", "com", "c\u00e2meras", "de", "sistema", "de", "reconhecimento", "facial", "montadas", "nos", "bondes", "fez", "com", "que", "as", "pessoas", "fossem", "banidas", "dos", "bondes", "da", "cidade", ",", "de", "qualquer", "forma", ",", "n\u00e3o", "se", "esgueirassem", "."], "sentence-detokenized": "Um julgamento pela RET em 2011 com c\u00e2meras de sistema de reconhecimento facial montadas nos bondes fez com que as pessoas fossem banidas dos bondes da cidade, de qualquer forma, n\u00e3o se esgueirassem.", "token2charspan": [[0, 2], [3, 13], [14, 18], [19, 22], [23, 25], [26, 30], [31, 34], [35, 42], [43, 45], [46, 53], [54, 56], [57, 71], [72, 78], [79, 87], [88, 91], [92, 98], [99, 102], [103, 106], [107, 110], [111, 113], [114, 121], [122, 128], [129, 136], [137, 140], [141, 147], [148, 150], [151, 157], [157, 158], [159, 161], [162, 170], [171, 176], [176, 177], [178, 181], [182, 184], [185, 197], [197, 198]]}
{"doc_key": "ai-test-377", "ner": [[7, 8, "person"], [9, 9, "organisation"], [17, 18, "person"], [20, 21, "person"], [28, 29, "person"], [31, 32, "person"], [34, 35, "person"], [37, 38, "person"], [40, 41, "person"], [43, 44, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[7, 8, 9, 9, "role", "works_for", false, false], [17, 18, 9, 9, "role", "works_for", false, false], [20, 21, 9, 9, "role", "works_for", false, false], [28, 29, 9, 9, "role", "works_for", false, false], [31, 32, 9, 9, "role", "works_for", false, false], [34, 35, 9, 9, "role", "works_for", false, false], [37, 38, 9, 9, "role", "works_for", false, false], [40, 41, 9, 9, "role", "works_for", false, false], [43, 44, 9, 9, "role", "works_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["O", "filme", ",", "adaptado", "do", "popular", "musical", "Cole", "Porter", "Broadway", ",", "estrelou", "a", "equipe", "MGM", "songbird", "de", "Howard", "Keel", "e", "Kathryn", "Grayson", "como", "os", "l\u00edderes", ",", "apoiado", "por", "Ann", "Miller", ",", "Keenan", "Wynn", ",", "Bobby", "Van", ",", "James", "Whitmore", ",", "Kurt", "Kasznar", "e", "Tommy", "Rall", "."], "sentence-detokenized": "O filme, adaptado do popular musical Cole Porter Broadway, estrelou a equipe MGM songbird de Howard Keel e Kathryn Grayson como os l\u00edderes, apoiado por Ann Miller, Keenan Wynn, Bobby Van, James Whitmore, Kurt Kasznar e Tommy Rall.", "token2charspan": [[0, 1], [2, 7], [7, 8], [9, 17], [18, 20], [21, 28], [29, 36], [37, 41], [42, 48], [49, 57], [57, 58], [59, 67], [68, 69], [70, 76], [77, 80], [81, 89], [90, 92], [93, 99], [100, 104], [105, 106], [107, 114], [115, 122], [123, 127], [128, 130], [131, 138], [138, 139], [140, 147], [148, 151], [152, 155], [156, 162], [162, 163], [164, 170], [171, 175], [175, 176], [177, 182], [183, 186], [186, 187], [188, 193], [194, 202], [202, 203], [204, 208], [209, 216], [217, 218], [219, 224], [225, 229], [229, 230]]}
{"doc_key": "ai-test-378", "ner": [[20, 25, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Tais", "aplica\u00e7\u00f5es", "devem", "racionalizar", "os", "fluxos", "de", "chamadas", ",", "minimizar", "as", "solicita\u00e7\u00f5es", ",", "eliminar", "itera\u00e7\u00f5es", "desnecess\u00e1rias", "e", "permitir", "um", "elaborado", "sistema", "de", "di\u00e1logo", "de", "iniciativa", "mista", ",", "que", "permite", "que", "os", "chamadores", "digitem", "v\u00e1rias", "informa\u00e7\u00f5es", "em", "uma", "\u00fanica", "frase", "e", "em", "qualquer", "ordem", "ou", "combina\u00e7\u00e3o", "."], "sentence-detokenized": "Tais aplica\u00e7\u00f5es devem racionalizar os fluxos de chamadas, minimizar as solicita\u00e7\u00f5es, eliminar itera\u00e7\u00f5es desnecess\u00e1rias e permitir um elaborado sistema de di\u00e1logo de iniciativa mista, que permite que os chamadores digitem v\u00e1rias informa\u00e7\u00f5es em uma \u00fanica frase e em qualquer ordem ou combina\u00e7\u00e3o.", "token2charspan": [[0, 4], [5, 15], [16, 21], [22, 34], [35, 37], [38, 44], [45, 47], [48, 56], [56, 57], [58, 67], [68, 70], [71, 83], [83, 84], [85, 93], [94, 103], [104, 118], [119, 120], [121, 129], [130, 132], [133, 142], [143, 150], [151, 153], [154, 161], [162, 164], [165, 175], [176, 181], [181, 182], [183, 186], [187, 194], [195, 198], [199, 201], [202, 212], [213, 220], [221, 227], [228, 239], [240, 242], [243, 246], [247, 252], [253, 258], [259, 260], [261, 263], [264, 272], [273, 278], [279, 281], [282, 292], [292, 293]]}
{"doc_key": "ai-test-379", "ner": [[7, 9, "algorithm"], [12, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 15, 7, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Como", "tal", ",", "os", "m\u00e9todos", "tradicionais", "de", "descida", "de", "gradiente", "(", "ou", "descida", "de", "gradiente", "estoc\u00e1stico", ")", "podem", "ser", "adaptados", ",", "onde", "de", "se", "dar", "um", "passo", "na", "dire\u00e7\u00e3o", "do", "gradiente", "da", "fun\u00e7\u00e3o", ",", "um", "passo", "\u00e9", "dado", "na", "dire\u00e7\u00e3o", "de", "um", "vetor", "selecionado", "a", "partir", "do", "subgradiente", "da", "fun\u00e7\u00e3o", "."], "sentence-detokenized": "Como tal, os m\u00e9todos tradicionais de descida de gradiente (ou descida de gradiente estoc\u00e1stico) podem ser adaptados, onde de se dar um passo na dire\u00e7\u00e3o do gradiente da fun\u00e7\u00e3o, um passo \u00e9 dado na dire\u00e7\u00e3o de um vetor selecionado a partir do subgradiente da fun\u00e7\u00e3o.", "token2charspan": [[0, 4], [5, 8], [8, 9], [10, 12], [13, 20], [21, 33], [34, 36], [37, 44], [45, 47], [48, 57], [58, 59], [59, 61], [62, 69], [70, 72], [73, 82], [83, 94], [94, 95], [96, 101], [102, 105], [106, 115], [115, 116], [117, 121], [122, 124], [125, 127], [128, 131], [132, 134], [135, 140], [141, 143], [144, 151], [152, 154], [155, 164], [165, 167], [168, 174], [174, 175], [176, 178], [179, 184], [185, 186], [187, 191], [192, 194], [195, 202], [203, 205], [206, 208], [209, 214], [215, 226], [227, 228], [229, 235], [236, 238], [239, 251], [252, 254], [255, 261], [261, 262]]}
{"doc_key": "ai-test-380", "ner": [[9, 12, "metrics"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Se", "for", "assumido", "que", "a", "distor\u00e7\u00e3o", "\u00e9", "medida", "por", "erro", "m\u00e9dio", "ao", "quadrado", ",", "a", "distor\u00e7\u00e3o", "D", ",", "\u00e9", "dada", "por", ":"], "sentence-detokenized": "Se for assumido que a distor\u00e7\u00e3o \u00e9 medida por erro m\u00e9dio ao quadrado, a distor\u00e7\u00e3o D, \u00e9 dada por:", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 19], [20, 21], [22, 31], [32, 33], [34, 40], [41, 44], [45, 49], [50, 55], [56, 58], [59, 67], [67, 68], [69, 70], [71, 80], [81, 82], [82, 83], [84, 85], [86, 90], [91, 94], [94, 95]]}
{"doc_key": "ai-test-381", "ner": [[0, 1, "algorithm"], [7, 10, "field"], [20, 22, "task"], [24, 26, "task"], [30, 31, "task"], [33, 34, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 7, 10, "part-of", "", false, false], [20, 22, 0, 1, "part-of", "", false, false], [24, 26, 0, 1, "part-of", "", false, false], [30, 31, 0, 1, "part-of", "", false, false], [33, 34, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Os", "MLPs", "foram", "uma", "solu\u00e7\u00e3o", "popular", "de", "aprendizagem", "de", "m\u00e1quinas", "nos", "anos", "80", ",", "encontrando", "aplica\u00e7\u00f5es", "em", "diversos", "campos", "como", "reconhecimento", "de", "voz", ",", "reconhecimento", "de", "imagem", "e", "software", "de", "tradu\u00e7\u00e3o", "autom\u00e1tica", ",", "redes", "neurais", "."], "sentence-detokenized": "Os MLPs foram uma solu\u00e7\u00e3o popular de aprendizagem de m\u00e1quinas nos anos 80, encontrando aplica\u00e7\u00f5es em diversos campos como reconhecimento de voz, reconhecimento de imagem e software de tradu\u00e7\u00e3o autom\u00e1tica, redes neurais.", "token2charspan": [[0, 2], [3, 7], [8, 13], [14, 17], [18, 25], [26, 33], [34, 36], [37, 49], [50, 52], [53, 61], [62, 65], [66, 70], [71, 73], [73, 74], [75, 86], [87, 97], [98, 100], [101, 109], [110, 116], [117, 121], [122, 136], [137, 139], [140, 143], [143, 144], [145, 159], [160, 162], [163, 169], [170, 171], [172, 180], [181, 183], [184, 192], [193, 203], [203, 204], [205, 210], [211, 218], [218, 219]]}
{"doc_key": "ai-test-382", "ner": [[0, 0, "researcher"], [3, 3, "misc"], [5, 7, "university"], [15, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 7, "physical", "", false, false], [0, 0, 5, 7, "role", "", false, false], [3, 3, 0, 0, "origin", "", false, false], [15, 17, 0, 0, "role", "supervised", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Allen", "recebeu", "seu", "Ph.D.", "da", "Universidade", "de", "Toronto", "em", "1979", ",", "sob", "a", "supervis\u00e3o", "de", "C.", "Raymond", "Perrault", ","], "sentence-detokenized": "Allen recebeu seu Ph.D. da Universidade de Toronto em 1979, sob a supervis\u00e3o de C. Raymond Perrault,", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 23], [24, 26], [27, 39], [40, 42], [43, 50], [51, 53], [54, 58], [58, 59], [60, 63], [64, 65], [66, 76], [77, 79], [80, 82], [83, 90], [91, 99], [99, 100]]}
{"doc_key": "ai-test-383", "ner": [[0, 1, "product"], [6, 9, "field"], [11, 11, "product"], [13, 13, "product"], [15, 15, "product"], [22, 22, "product"], [25, 25, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 6, 9, "related-to", "supports", false, false], [11, 11, 6, 9, "type-of", "", true, false], [13, 13, 6, 9, "type-of", "", true, false], [15, 15, 6, 9, "type-of", "", true, false], [15, 15, 22, 22, "related-to", "converting_to", true, false], [25, 25, 6, 9, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["O", "OpenCV", "suporta", "alguns", "modelos", "de", "estruturas", "de", "aprendizagem", "profunda", "como", "TensorFlow", ",", "Torch", ",", "PyTorch", "(", "ap\u00f3s", "convers\u00e3o", "para", "um", "modelo", "ONNX", ")", "e", "Caffe", "de", "acordo", "com", "uma", "lista", "definida", "de", "camadas", "suportadas", "."], "sentence-detokenized": "O OpenCV suporta alguns modelos de estruturas de aprendizagem profunda como TensorFlow, Torch, PyTorch (ap\u00f3s convers\u00e3o para um modelo ONNX) e Caffe de acordo com uma lista definida de camadas suportadas.", "token2charspan": [[0, 1], [2, 8], [9, 16], [17, 23], [24, 31], [32, 34], [35, 45], [46, 48], [49, 61], [62, 70], [71, 75], [76, 86], [86, 87], [88, 93], [93, 94], [95, 102], [103, 104], [104, 108], [109, 118], [119, 123], [124, 126], [127, 133], [134, 138], [138, 139], [140, 141], [142, 147], [148, 150], [151, 157], [158, 161], [162, 165], [166, 171], [172, 180], [181, 183], [184, 191], [192, 202], [202, 203]]}
{"doc_key": "ai-test-384", "ner": [[2, 2, "researcher"], [8, 13, "organisation"], [15, 15, "organisation"], [22, 26, "organisation"], [28, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 8, 13, "role", "", false, false], [2, 2, 22, 26, "role", "", false, false], [2, 2, 28, 28, "related-to", "lectures_in", false, false], [15, 15, 8, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Anteriormente", ",", "Christensen", "foi", "a", "Presidente", "Fundadora", "da", "Rede", "Europ\u00e9ia", "de", "Pesquisa", "em", "Rob\u00f3tica", "(", "EURON", ")", "e", "uma", "Conferencista", "Distinta", "da", "IEEE", "Robotics", "and", "Automation", "Society", "em", "Rob\u00f3tica", "."], "sentence-detokenized": "Anteriormente, Christensen foi a Presidente Fundadora da Rede Europ\u00e9ia de Pesquisa em Rob\u00f3tica (EURON) e uma Conferencista Distinta da IEEE Robotics and Automation Society em Rob\u00f3tica.", "token2charspan": [[0, 13], [13, 14], [15, 26], [27, 30], [31, 32], [33, 43], [44, 53], [54, 56], [57, 61], [62, 70], [71, 73], [74, 82], [83, 85], [86, 94], [95, 96], [96, 101], [101, 102], [103, 104], [105, 108], [109, 122], [123, 131], [132, 134], [135, 139], [140, 148], [149, 152], [153, 163], [164, 171], [172, 174], [175, 183], [183, 184]]}
{"doc_key": "ai-test-385", "ner": [[5, 5, "field"], [7, 10, "university"], [12, 12, "location"], [14, 17, "country"], [21, 21, "misc"], [23, 23, "field"], [25, 29, "organisation"], [31, 31, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[7, 10, 12, 12, "physical", "", false, false], [12, 12, 14, 17, "physical", "", false, false], [21, 21, 23, 23, "topic", "", false, false], [25, 29, 31, 31, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Ele", "recebeu", "seu", "mestrado", "em", "matem\u00e1tica", "da", "Universidade", "Estadual", "de", "Samarkand", ",", "Samarkand", ",", "Rep\u00fablica", "Socialista", "Sovi\u00e9tica", "Uzbeque", "em", "1958", "e", "doutorado", "em", "estat\u00edstica", "no", "Instituto", "de", "Ci\u00eancias", "de", "Controle", ",", "Moscou", "em", "1964", "."], "sentence-detokenized": "Ele recebeu seu mestrado em matem\u00e1tica da Universidade Estadual de Samarkand, Samarkand, Rep\u00fablica Socialista Sovi\u00e9tica Uzbeque em 1958 e doutorado em estat\u00edstica no Instituto de Ci\u00eancias de Controle, Moscou em 1964.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 24], [25, 27], [28, 38], [39, 41], [42, 54], [55, 63], [64, 66], [67, 76], [76, 77], [78, 87], [87, 88], [89, 98], [99, 109], [110, 119], [120, 127], [128, 130], [131, 135], [136, 137], [138, 147], [148, 150], [151, 162], [163, 165], [166, 175], [176, 178], [179, 187], [188, 190], [191, 199], [199, 200], [201, 207], [208, 210], [211, 215], [215, 216]]}
{"doc_key": "ai-test-386", "ner": [[9, 9, "organisation"], [13, 14, "product"], [39, 41, "field"], [44, 47, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 39, 41, "usage", "", false, false], [9, 9, 44, 47, "usage", "", false, false], [13, 14, 9, 9, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Cada", "vez", "mais", ",", "por\u00e9m", ",", "o", "trabalho", "na", "Cycorp", "envolve", "dar", "ao", "sistema", "Cycorp", "a", "capacidade", "de", "se", "comunicar", "com", "os", "usu\u00e1rios", "finais", "em", "linguagem", "natural", ",", "e", "ajudar", "no", "processo", "de", "forma\u00e7\u00e3o", "cont\u00ednua", "de", "conhecimento", "atrav\u00e9s", "da", "aprendizagem", "de", "m\u00e1quinas", "e", "da", "compreens\u00e3o", "da", "linguagem", "natural", "."], "sentence-detokenized": "Cada vez mais, por\u00e9m, o trabalho na Cycorp envolve dar ao sistema Cycorp a capacidade de se comunicar com os usu\u00e1rios finais em linguagem natural, e ajudar no processo de forma\u00e7\u00e3o cont\u00ednua de conhecimento atrav\u00e9s da aprendizagem de m\u00e1quinas e da compreens\u00e3o da linguagem natural.", "token2charspan": [[0, 4], [5, 8], [9, 13], [13, 14], [15, 20], [20, 21], [22, 23], [24, 32], [33, 35], [36, 42], [43, 50], [51, 54], [55, 57], [58, 65], [66, 72], [73, 74], [75, 85], [86, 88], [89, 91], [92, 101], [102, 105], [106, 108], [109, 117], [118, 124], [125, 127], [128, 137], [138, 145], [145, 146], [147, 148], [149, 155], [156, 158], [159, 167], [168, 170], [171, 179], [180, 188], [189, 191], [192, 204], [205, 212], [213, 215], [216, 228], [229, 231], [232, 240], [241, 242], [243, 245], [246, 257], [258, 260], [261, 270], [271, 278], [278, 279]]}
{"doc_key": "ai-test-387", "ner": [[64, 64, "metrics"], [66, 66, "metrics"], [68, 68, "metrics"], [70, 71, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Por", "exemplo", ",", "se", "for", "procurado", "o", "classificador", "mais", "adequado", "para", "o", "problema", ",", "o", "conjunto", "de", "dados", "de", "treinamento", "\u00e9", "usado", "para", "treinar", "os", "algoritmos", "candidatos", ",", "o", "conjunto", "de", "dados", "de", "valida\u00e7\u00e3o", "\u00e9", "usado", "para", "comparar", "seus", "desempenhos", "e", "decidir", "qual", "deles", "tomar", "e", ",", "finalmente", ",", "o", "conjunto", "de", "dados", "de", "teste", "\u00e9", "usado", "para", "obter", "as", "caracter\u00edsticas", "de", "desempenho", "como", "precis\u00e3o", ",", "sensibilidade", ",", "especificidade", ",", "medida", "F", ",", "e", "assim", "por", "diante", "."], "sentence-detokenized": "Por exemplo, se for procurado o classificador mais adequado para o problema, o conjunto de dados de treinamento \u00e9 usado para treinar os algoritmos candidatos, o conjunto de dados de valida\u00e7\u00e3o \u00e9 usado para comparar seus desempenhos e decidir qual deles tomar e, finalmente, o conjunto de dados de teste \u00e9 usado para obter as caracter\u00edsticas de desempenho como precis\u00e3o, sensibilidade, especificidade, medida F, e assim por diante.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 19], [20, 29], [30, 31], [32, 45], [46, 50], [51, 59], [60, 64], [65, 66], [67, 75], [75, 76], [77, 78], [79, 87], [88, 90], [91, 96], [97, 99], [100, 111], [112, 113], [114, 119], [120, 124], [125, 132], [133, 135], [136, 146], [147, 157], [157, 158], [159, 160], [161, 169], [170, 172], [173, 178], [179, 181], [182, 191], [192, 193], [194, 199], [200, 204], [205, 213], [214, 218], [219, 230], [231, 232], [233, 240], [241, 245], [246, 251], [252, 257], [258, 259], [259, 260], [261, 271], [271, 272], [273, 274], [275, 283], [284, 286], [287, 292], [293, 295], [296, 301], [302, 303], [304, 309], [310, 314], [315, 320], [321, 323], [324, 339], [340, 342], [343, 353], [354, 358], [359, 367], [367, 368], [369, 382], [382, 383], [384, 398], [398, 399], [400, 406], [407, 408], [408, 409], [410, 411], [412, 417], [418, 421], [422, 428], [428, 429]]}
{"doc_key": "ai-test-388", "ner": [[1, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["O", "erro", "m\u00e9dio", "ao", "quadrado", "\u00e9", "0,15", "."], "sentence-detokenized": "O erro m\u00e9dio ao quadrado \u00e9 0,15.", "token2charspan": [[0, 1], [2, 6], [7, 12], [13, 15], [16, 24], [25, 26], [27, 31], [31, 32]]}
{"doc_key": "ai-test-389", "ner": [[4, 5, "misc"], [9, 9, "organisation"], [15, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 4, 5, "role", "", false, false], [15, 15, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Em", "1979", ",", "um", "concurso", "Micromouse", "foi", "organizado", "pelo", "IEEE", ",", "como", "mostrado", "na", "revista", "Spectrum", "."], "sentence-detokenized": "Em 1979, um concurso Micromouse foi organizado pelo IEEE, como mostrado na revista Spectrum.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 20], [21, 31], [32, 35], [36, 46], [47, 51], [52, 56], [56, 57], [58, 62], [63, 71], [72, 74], [75, 82], [83, 91], [91, 92]]}
{"doc_key": "ai-test-390", "ner": [[1, 2, "algorithm"], [9, 12, "field"], [13, 16, "task"], [18, 20, "task"], [22, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 9, 12, "part-of", "", false, false], [13, 16, 9, 12, "part-of", "task_part_of_field", false, false], [18, 20, 9, 12, "part-of", "task_part_of_field", false, false], [22, 25, 9, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["O", "espa\u00e7o", "Gabor", "\u00e9", "muito", "\u00fatil", "em", "aplica\u00e7\u00f5es", "de", "processamento", "de", "imagens", "como", "reconhecimento", "\u00f3ptico", "de", "caracteres", ",", "reconhecimento", "da", "\u00edris", "e", "reconhecimento", "de", "impress\u00f5es", "digitais", "."], "sentence-detokenized": "O espa\u00e7o Gabor \u00e9 muito \u00fatil em aplica\u00e7\u00f5es de processamento de imagens como reconhecimento \u00f3ptico de caracteres, reconhecimento da \u00edris e reconhecimento de impress\u00f5es digitais.", "token2charspan": [[0, 1], [2, 8], [9, 14], [15, 16], [17, 22], [23, 27], [28, 30], [31, 41], [42, 44], [45, 58], [59, 61], [62, 69], [70, 74], [75, 89], [90, 96], [97, 99], [100, 110], [110, 111], [112, 126], [127, 129], [130, 134], [135, 136], [137, 151], [152, 154], [155, 165], [166, 174], [174, 175]]}
{"doc_key": "ai-test-391", "ner": [[8, 8, "programlang"], [10, 10, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["ou", "atrav\u00e9s", "de", "interfaces", "de", "alto", "n\u00edvel", "para", "Java", "e", "Tcl", "."], "sentence-detokenized": "ou atrav\u00e9s de interfaces de alto n\u00edvel para Java e Tcl.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 24], [25, 27], [28, 32], [33, 38], [39, 43], [44, 48], [49, 50], [51, 54], [54, 55]]}
{"doc_key": "ai-test-392", "ner": [[11, 14, "algorithm"], [21, 21, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 14, 21, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Em", "pesquisas", "recentes", ",", "m\u00e9todos", "baseados", "em", "kernel", ",", "tais", "como", "m\u00e1quinas", "vetoriais", "de", "suporte", ",", "t\u00eam", "demonstrado", "desempenho", "superior", "em", "supervis\u00e3o", "."], "sentence-detokenized": "Em pesquisas recentes, m\u00e9todos baseados em kernel, tais como m\u00e1quinas vetoriais de suporte, t\u00eam demonstrado desempenho superior em supervis\u00e3o.", "token2charspan": [[0, 2], [3, 12], [13, 21], [21, 22], [23, 30], [31, 39], [40, 42], [43, 49], [49, 50], [51, 55], [56, 60], [61, 69], [70, 79], [80, 82], [83, 90], [90, 91], [92, 95], [96, 107], [108, 118], [119, 127], [128, 130], [131, 141], [141, 142]]}
{"doc_key": "ai-test-393", "ner": [[16, 16, "misc"], [22, 22, "researcher"], [24, 24, "researcher"], [32, 32, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 22, 32, 32, "usage", "", false, false], [24, 24, 32, 32, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Para", "ilustrar", "os", "princ\u00edpios", "b\u00e1sicos", "de", "ensacamento", ",", "abaixo", "est\u00e1", "uma", "an\u00e1lise", "sobre", "a", "rela\u00e7\u00e3o", "entre", "oz\u00f4nio", "e", "temperatura", "(", "dados", "de", "Rousseeuw", "e", "Leroy", "(", "1986", ")", ",", "an\u00e1lise", "feita", "em", "R", ")", "."], "sentence-detokenized": "Para ilustrar os princ\u00edpios b\u00e1sicos de ensacamento, abaixo est\u00e1 uma an\u00e1lise sobre a rela\u00e7\u00e3o entre oz\u00f4nio e temperatura (dados de Rousseeuw e Leroy (1986), an\u00e1lise feita em R).", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 27], [28, 35], [36, 38], [39, 50], [50, 51], [52, 58], [59, 63], [64, 67], [68, 75], [76, 81], [82, 83], [84, 91], [92, 97], [98, 104], [105, 106], [107, 118], [119, 120], [120, 125], [126, 128], [129, 138], [139, 140], [141, 146], [147, 148], [148, 152], [152, 153], [153, 154], [155, 162], [163, 168], [169, 171], [172, 173], [173, 174], [174, 175]]}
{"doc_key": "ai-test-394", "ner": [[0, 2, "organisation"], [14, 17, "product"], [23, 24, "product"], [26, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 17, 0, 2, "artifact", "", false, false], [23, 24, 0, 2, "artifact", "", false, false], [26, 28, 0, 2, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "Denso", "Wave", "\u00e9", "uma", "subsidi\u00e1ria", "que", "produz", "produtos", "de", "identifica\u00e7\u00e3o", "autom\u00e1tica", "(", "leitores", "de", "c\u00f3digo", "de", "barras", "e", "produtos", "relacionados", ")", ",", "rob\u00f4s", "industriais", "e", "controladores", "l\u00f3gicos", "program\u00e1veis", "."], "sentence-detokenized": "A Denso Wave \u00e9 uma subsidi\u00e1ria que produz produtos de identifica\u00e7\u00e3o autom\u00e1tica (leitores de c\u00f3digo de barras e produtos relacionados), rob\u00f4s industriais e controladores l\u00f3gicos program\u00e1veis.", "token2charspan": [[0, 1], [2, 7], [8, 12], [13, 14], [15, 18], [19, 30], [31, 34], [35, 41], [42, 50], [51, 53], [54, 67], [68, 78], [79, 80], [80, 88], [89, 91], [92, 98], [99, 101], [102, 108], [109, 110], [111, 119], [120, 132], [132, 133], [133, 134], [135, 140], [141, 152], [153, 154], [155, 168], [169, 176], [177, 189], [189, 190]]}
{"doc_key": "ai-test-395", "ner": [[2, 3, "metrics"], [7, 8, "metrics"], [17, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 3, 17, 18, "compare", "", false, false], [7, 8, 2, 3, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Onde", "a", "avalia\u00e7\u00e3o", "bil\u00edng\u00fce", "simplesmente", "calcula", "a", "precis\u00e3o", "do", "programa", "adicionando", "peso", "igual", "a", "cada", "um", ",", "o", "NIST", "tamb\u00e9m", "calcula", "o", "qu\u00e3o", "informativo", "\u00e9", "um", "determinado", "programa", "."], "sentence-detokenized": "Onde a avalia\u00e7\u00e3o bil\u00edng\u00fce simplesmente calcula a precis\u00e3o do programa adicionando peso igual a cada um, o NIST tamb\u00e9m calcula o qu\u00e3o informativo \u00e9 um determinado programa.", "token2charspan": [[0, 4], [5, 6], [7, 16], [17, 25], [26, 38], [39, 46], [47, 48], [49, 57], [58, 60], [61, 69], [70, 81], [82, 86], [87, 92], [93, 94], [95, 99], [100, 102], [102, 103], [104, 105], [106, 110], [111, 117], [118, 125], [126, 127], [128, 132], [133, 144], [145, 146], [147, 149], [150, 161], [162, 170], [170, 171]]}
{"doc_key": "ai-test-396", "ner": [[16, 16, "algorithm"], [20, 21, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Em", "particular", ",", "eles", "s\u00e3o", "usados", "durante", "o", "c\u00e1lculo", "da", "probabilidade", "de", "uma", "\u00e1rvore", "(", "em", "Bayesian", "e", "aproxima\u00e7\u00f5es", "de", "m\u00e1xima", "probabilidade", "\u00e0", "estimativa", "de", "\u00e1rvore", ")", "e", "s\u00e3o", "usados", "para", "estimar", "a", "dist\u00e2ncia", "evolutiva", "entre", "seq\u00fc\u00eancias", "a", "partir", "das", "diferen\u00e7as", "observadas", "entre", "as", "seq\u00fc\u00eancias", "."], "sentence-detokenized": "Em particular, eles s\u00e3o usados durante o c\u00e1lculo da probabilidade de uma \u00e1rvore (em Bayesian e aproxima\u00e7\u00f5es de m\u00e1xima probabilidade \u00e0 estimativa de \u00e1rvore) e s\u00e3o usados para estimar a dist\u00e2ncia evolutiva entre seq\u00fc\u00eancias a partir das diferen\u00e7as observadas entre as seq\u00fc\u00eancias.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 19], [20, 23], [24, 30], [31, 38], [39, 40], [41, 48], [49, 51], [52, 65], [66, 68], [69, 72], [73, 79], [80, 81], [81, 83], [84, 92], [93, 94], [95, 107], [108, 110], [111, 117], [118, 131], [132, 133], [134, 144], [145, 147], [148, 154], [154, 155], [156, 157], [158, 161], [162, 168], [169, 173], [174, 181], [182, 183], [184, 193], [194, 203], [204, 209], [210, 220], [221, 222], [223, 229], [230, 233], [234, 244], [245, 255], [256, 261], [262, 264], [265, 275], [275, 276]]}
{"doc_key": "ai-test-397", "ner": [[1, 3, "conference"], [25, 26, "misc"], [28, 28, "misc"], [55, 56, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[28, 28, 25, 26, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "Audio", "Engineering", "Society", "recomenda", "uma", "taxa", "de", "amostragem", "de", "48", "kHz", "para", "a", "maioria", "das", "aplica\u00e7\u00f5es", ",", "mas", "d\u00e1", "reconhecimento", "a", "44,1", "kHz", "para", "discos", "compactos", "(", "CD", ")", "e", "outros", "usos", "do", "consumidor", ",", "32", "kHz", "para", "aplica\u00e7\u00f5es", "relacionadas", "\u00e0", "transmiss\u00e3o", ",", "e", "96", "kHz", "para", "uma", "maior", "largura", "de", "banda", "ou", "um", "filtro", "anti-serrilhamento", "relaxado", "."], "sentence-detokenized": "A Audio Engineering Society recomenda uma taxa de amostragem de 48 kHz para a maioria das aplica\u00e7\u00f5es, mas d\u00e1 reconhecimento a 44,1 kHz para discos compactos (CD) e outros usos do consumidor, 32 kHz para aplica\u00e7\u00f5es relacionadas \u00e0 transmiss\u00e3o, e 96 kHz para uma maior largura de banda ou um filtro anti-serrilhamento relaxado.", "token2charspan": [[0, 1], [2, 7], [8, 19], [20, 27], [28, 37], [38, 41], [42, 46], [47, 49], [50, 60], [61, 63], [64, 66], [67, 70], [71, 75], [76, 77], [78, 85], [86, 89], [90, 100], [100, 101], [102, 105], [106, 108], [109, 123], [124, 125], [126, 130], [131, 134], [135, 139], [140, 146], [147, 156], [157, 158], [158, 160], [160, 161], [162, 163], [164, 170], [171, 175], [176, 178], [179, 189], [189, 190], [191, 193], [194, 197], [198, 202], [203, 213], [214, 226], [227, 228], [229, 240], [240, 241], [242, 243], [244, 246], [247, 250], [251, 255], [256, 259], [260, 265], [266, 273], [274, 276], [277, 282], [283, 285], [286, 288], [289, 295], [296, 314], [315, 323], [323, 324]]}
{"doc_key": "ai-test-398", "ner": [[10, 10, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Recursos", "para", "afetividade", "de", "palavras", "e", "conceitos", "foram", "feitos", "para", "WordNet", "{", "{", "{", "cite", "journal"], "sentence-detokenized": "Recursos para afetividade de palavras e conceitos foram feitos para WordNet {{{cite journal", "token2charspan": [[0, 8], [9, 13], [14, 25], [26, 28], [29, 37], [38, 39], [40, 49], [50, 55], [56, 62], [63, 67], [68, 75], [76, 77], [77, 78], [78, 79], [79, 83], [84, 91]]}
{"doc_key": "ai-test-399", "ner": [[1, 2, "misc"], [22, 23, "person"], [28, 30, "person"], [35, 37, "person"], [43, 44, "organisation"], [63, 65, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[28, 30, 35, 37, "role", "acts_in", false, false], [43, 44, 35, 37, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["No", "an\u00e1glifo", "vermelho-verde", ",", "foram", "apresentadas", "ao", "p\u00fablico", "tr\u00eas", "bobinas", "de", "testes", ",", "que", "inclu\u00edram", "cenas", "rurais", ",", "tiros", "de", "teste", "de", "Marie", "Doro", ",", "um", "segmento", "de", "John", "B.", "Mason", "interpretando", "v\u00e1rias", "passagens", "de", "Jim", "the", "Penman", "(", "um", "filme", "lan\u00e7ado", "por", "Famous", "Players-Lasky", "naquele", "ano", ",", "mas", "n\u00e3o", "em", "3D", ")", ",", "dan\u00e7arinos", "orientais", ",", "e", "uma", "bobina", "de", "filmagens", "das", "Cataratas", "do", "Ni\u00e1gara", "."], "sentence-detokenized": "No an\u00e1glifo vermelho-verde, foram apresentadas ao p\u00fablico tr\u00eas bobinas de testes, que inclu\u00edram cenas rurais, tiros de teste de Marie Doro, um segmento de John B. Mason interpretando v\u00e1rias passagens de Jim the Penman (um filme lan\u00e7ado por Famous Players-Lasky naquele ano, mas n\u00e3o em 3D), dan\u00e7arinos orientais, e uma bobina de filmagens das Cataratas do Ni\u00e1gara.", "token2charspan": [[0, 2], [3, 11], [12, 26], [26, 27], [28, 33], [34, 46], [47, 49], [50, 57], [58, 62], [63, 70], [71, 73], [74, 80], [80, 81], [82, 85], [86, 95], [96, 101], [102, 108], [108, 109], [110, 115], [116, 118], [119, 124], [125, 127], [128, 133], [134, 138], [138, 139], [140, 142], [143, 151], [152, 154], [155, 159], [160, 162], [163, 168], [169, 182], [183, 189], [190, 199], [200, 202], [203, 206], [207, 210], [211, 217], [218, 219], [219, 221], [222, 227], [228, 235], [236, 239], [240, 246], [247, 260], [261, 268], [269, 272], [272, 273], [274, 277], [278, 281], [282, 284], [285, 287], [287, 288], [288, 289], [290, 300], [301, 310], [310, 311], [312, 313], [314, 317], [318, 324], [325, 327], [328, 337], [338, 341], [342, 351], [352, 354], [355, 362], [362, 363]]}
{"doc_key": "ai-test-400", "ner": [[8, 11, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Esta", "\u00e9", "uma", "forma", "particular", "de", "implementar", "a", "estimativa", "de", "m\u00e1xima", "probabilidade", "para", "este", "problema", "."], "sentence-detokenized": "Esta \u00e9 uma forma particular de implementar a estimativa de m\u00e1xima probabilidade para este problema.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 16], [17, 27], [28, 30], [31, 42], [43, 44], [45, 55], [56, 58], [59, 65], [66, 79], [80, 84], [85, 89], [90, 98], [98, 99]]}
{"doc_key": "ai-test-401", "ner": [[0, 4, "product"], [14, 14, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Servidores", "Web", "amig\u00e1veis", "ao", "rastreamento", ",", "e", "integra", "as", "caracter\u00edsticas", "de", "sitesmaps", "e", "feeds", "RSS", "em", "um", "mecanismo", "descentralizado", "para", "bi\u00f3logos", "computacionais", "e", "bioinform\u00e1ticos", "transmitirem", "e", "recuperarem", "meta-dados", "sobre", "recursos", "biom\u00e9dicos", "."], "sentence-detokenized": "Servidores Web amig\u00e1veis ao rastreamento, e integra as caracter\u00edsticas de sitesmaps e feeds RSS em um mecanismo descentralizado para bi\u00f3logos computacionais e bioinform\u00e1ticos transmitirem e recuperarem meta-dados sobre recursos biom\u00e9dicos.", "token2charspan": [[0, 10], [11, 14], [15, 24], [25, 27], [28, 40], [40, 41], [42, 43], [44, 51], [52, 54], [55, 70], [71, 73], [74, 83], [84, 85], [86, 91], [92, 95], [96, 98], [99, 101], [102, 111], [112, 127], [128, 132], [133, 141], [142, 156], [157, 158], [159, 174], [175, 187], [188, 189], [190, 201], [202, 212], [213, 218], [219, 227], [228, 238], [238, 239]]}
{"doc_key": "ai-test-402", "ner": [[3, 10, "misc"], [14, 19, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["\u00c9", "coberto", "pelo", "American", "National", "Standards", "Institute", "/", "NISO", "standard", "Z39.50", ",", "e", "pela", "International", "Organization", "for", "Standardization", "standard", "23950", "."], "sentence-detokenized": "\u00c9 coberto pelo American National Standards Institute / NISO standard Z39.50, e pela International Organization for Standardization standard 23950.", "token2charspan": [[0, 1], [2, 9], [10, 14], [15, 23], [24, 32], [33, 42], [43, 52], [53, 54], [55, 59], [60, 68], [69, 75], [75, 76], [77, 78], [79, 83], [84, 97], [98, 110], [111, 114], [115, 130], [131, 139], [140, 145], [145, 146]]}
{"doc_key": "ai-test-403", "ner": [[14, 16, "misc"], [21, 22, "metrics"], [26, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["O", "codificador", "e", "o", "decodificador", "s\u00e3o", "treinados", "para", "pegar", "uma", "frase", "e", "reproduzir", "a", "distribui\u00e7\u00e3o", "de", "uma", "par\u00e1frase", "correspondente", ",", "minimizando", "a", "perplexidade", "usando", "uma", "simples", "descida", "de", "gradiente", "estoc\u00e1stico", "."], "sentence-detokenized": "O codificador e o decodificador s\u00e3o treinados para pegar uma frase e reproduzir a distribui\u00e7\u00e3o de uma par\u00e1frase correspondente, minimizando a perplexidade usando uma simples descida de gradiente estoc\u00e1stico.", "token2charspan": [[0, 1], [2, 13], [14, 15], [16, 17], [18, 31], [32, 35], [36, 45], [46, 50], [51, 56], [57, 60], [61, 66], [67, 68], [69, 79], [80, 81], [82, 94], [95, 97], [98, 101], [102, 111], [112, 126], [126, 127], [128, 139], [140, 141], [142, 154], [155, 161], [162, 165], [166, 173], [174, 181], [182, 184], [185, 194], [195, 206], [206, 207]]}
{"doc_key": "ai-test-404", "ner": [[6, 8, "field"], [11, 14, "task"], [17, 22, "task"], [37, 42, "task"], [45, 51, "task"], [55, 64, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 14, 6, 8, "part-of", "task_part_of_field", false, false], [17, 22, 6, 8, "part-of", "task_part_of_field", false, false], [37, 42, 6, 8, "part-of", "task_part_of_field", false, false], [45, 51, 6, 8, "part-of", "task_part_of_field", false, false], [55, 64, 6, 8, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Outras", "aplica\u00e7\u00f5es", "t\u00edpicas", "das", "t\u00e9cnicas", "de", "reconhecimento", "de", "padr\u00f5es", "s\u00e3o", "o", "reconhecimento", "autom\u00e1tico", "da", "fala", ",", "a", "classifica\u00e7\u00e3o", "do", "texto", "em", "v\u00e1rias", "categorias", "(", "por", "exemplo", ",", "mensagens", "de", "e-mail", "spam", "/", "n\u00e3o", "spam", ")", ",", "o", "reconhecimento", "da", "caligrafia", "em", "envelopes", "postais", ",", "o", "reconhecimento", "autom\u00e1tico", "de", "imagens", "de", "rostos", "humanos", ",", "ou", "a", "extra\u00e7\u00e3o", "de", "imagens", "da", "caligrafia", "a", "partir", "de", "formul\u00e1rios", "m\u00e9dicos", "."], "sentence-detokenized": "Outras aplica\u00e7\u00f5es t\u00edpicas das t\u00e9cnicas de reconhecimento de padr\u00f5es s\u00e3o o reconhecimento autom\u00e1tico da fala, a classifica\u00e7\u00e3o do texto em v\u00e1rias categorias (por exemplo, mensagens de e-mail spam / n\u00e3o spam), o reconhecimento da caligrafia em envelopes postais, o reconhecimento autom\u00e1tico de imagens de rostos humanos, ou a extra\u00e7\u00e3o de imagens da caligrafia a partir de formul\u00e1rios m\u00e9dicos.", "token2charspan": [[0, 6], [7, 17], [18, 25], [26, 29], [30, 38], [39, 41], [42, 56], [57, 59], [60, 67], [68, 71], [72, 73], [74, 88], [89, 99], [100, 102], [103, 107], [107, 108], [109, 110], [111, 124], [125, 127], [128, 133], [134, 136], [137, 143], [144, 154], [155, 156], [156, 159], [160, 167], [167, 168], [169, 178], [179, 181], [182, 188], [189, 193], [194, 195], [196, 199], [200, 204], [204, 205], [205, 206], [207, 208], [209, 223], [224, 226], [227, 237], [238, 240], [241, 250], [251, 258], [258, 259], [260, 261], [262, 276], [277, 287], [288, 290], [291, 298], [299, 301], [302, 308], [309, 316], [316, 317], [318, 320], [321, 322], [323, 331], [332, 334], [335, 342], [343, 345], [346, 356], [357, 358], [359, 365], [366, 368], [369, 380], [381, 388], [388, 389]]}
{"doc_key": "ai-test-405", "ner": [[0, 3, "algorithm"], [14, 16, "field"], [18, 20, "task"], [22, 23, "task"], [25, 28, "task"], [31, 35, "task"], [37, 38, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[14, 16, 0, 3, "usage", "", false, false], [18, 20, 0, 3, "usage", "", false, false], [22, 23, 0, 3, "usage", "", false, false], [25, 28, 0, 3, "usage", "", false, false], [31, 35, 0, 3, "usage", "", false, false], [37, 38, 0, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["As", "redes", "neurais", "artificiais", "t\u00eam", "sido", "usadas", "em", "uma", "variedade", "de", "tarefas", ",", "incluindo", "vis\u00e3o", "por", "computador", ",", "reconhecimento", "da", "fala", ",", "tradu\u00e7\u00e3o", "autom\u00e1tica", ",", "filtragem", "de", "redes", "sociais", ",", "jogos", "de", "tabuleiro", "e", "de", "v\u00eddeo", "e", "diagn\u00f3stico", "m\u00e9dico", "."], "sentence-detokenized": "As redes neurais artificiais t\u00eam sido usadas em uma variedade de tarefas, incluindo vis\u00e3o por computador, reconhecimento da fala, tradu\u00e7\u00e3o autom\u00e1tica, filtragem de redes sociais, jogos de tabuleiro e de v\u00eddeo e diagn\u00f3stico m\u00e9dico.", "token2charspan": [[0, 2], [3, 8], [9, 16], [17, 28], [29, 32], [33, 37], [38, 44], [45, 47], [48, 51], [52, 61], [62, 64], [65, 72], [72, 73], [74, 83], [84, 89], [90, 93], [94, 104], [104, 105], [106, 120], [121, 123], [124, 128], [128, 129], [130, 138], [139, 149], [149, 150], [151, 160], [161, 163], [164, 169], [170, 177], [177, 178], [179, 184], [185, 187], [188, 197], [198, 199], [200, 202], [203, 208], [209, 210], [211, 222], [223, 229], [229, 230]]}
{"doc_key": "ai-test-406", "ner": [[2, 3, "organisation"], [4, 4, "product"], [15, 15, "product"], [18, 18, "organisation"], [19, 20, "product"], [22, 22, "product"], [24, 26, "product"], [28, 28, "product"], [30, 30, "programlang"], [40, 41, "field"], [47, 47, "product"], [51, 51, "algorithm"], [53, 53, "algorithm"], [56, 56, "algorithm"], [59, 59, "product"], [64, 66, "task"], [77, 79, "algorithm"], [82, 82, "product"], [84, 84, "product"], [89, 91, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "relations": [[4, 4, 2, 3, "origin", "", false, false], [4, 4, 15, 15, "named", "same", false, false], [4, 4, 47, 47, "named", "same", false, false], [30, 30, 40, 41, "related-to", "used_for", false, false], [51, 51, 30, 30, "part-of", "", true, false], [51, 51, 47, 47, "origin", "", true, false], [53, 53, 30, 30, "part-of", "", true, false], [53, 53, 47, 47, "origin", "", true, false], [56, 56, 30, 30, "part-of", "", true, false], [56, 56, 47, 47, "origin", "", true, false], [59, 59, 64, 66, "related-to", "used_for", false, false], [77, 79, 59, 59, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Exemplos", "incluem", "Salford", "Systems", "CART", "(", "que", "licenciou", "o", "c\u00f3digo", "propriet\u00e1rio", "dos", "autores", "originais", "do", "CART", ")", ",", "IBM", "SPSS", "Modeler", ",", "RapidMiner", ",", "SAS", "Enterprise", "Miner", ",", "Matlab", ",", "R", "(", "um", "ambiente", "de", "software", "de", "c\u00f3digo", "aberto", "para", "computa\u00e7\u00e3o", "estat\u00edstica", ",", "que", "inclui", "v\u00e1rias", "implementa\u00e7\u00f5es", "CART", ",", "tais", "como", "rpart", ",", "party", "e", "pacotes", "randomForest", ")", ",", "Weka", "(", "uma", "su\u00edte", "de", "minera\u00e7\u00e3o", "de", "dados", "livre", "e", "de", "c\u00f3digo", "aberto", ",", "cont\u00e9m", "muitos", "algoritmos", "de", "\u00e1rvore", "de", "decis\u00e3o", ")", ",", "Orange", ",", "KNIME", ",", "linguagem", "de", "programa\u00e7\u00e3o", "Microsoft", "SQL", "Server", ")", "."], "sentence-detokenized": "Exemplos incluem Salford Systems CART (que licenciou o c\u00f3digo propriet\u00e1rio dos autores originais do CART), IBM SPSS Modeler, RapidMiner, SAS Enterprise Miner, Matlab, R (um ambiente de software de c\u00f3digo aberto para computa\u00e7\u00e3o estat\u00edstica, que inclui v\u00e1rias implementa\u00e7\u00f5es CART, tais como rpart, party e pacotes randomForest), Weka (uma su\u00edte de minera\u00e7\u00e3o de dados livre e de c\u00f3digo aberto, cont\u00e9m muitos algoritmos de \u00e1rvore de decis\u00e3o), Orange, KNIME, linguagem de programa\u00e7\u00e3o Microsoft SQL Server).", "token2charspan": [[0, 8], [9, 16], [17, 24], [25, 32], [33, 37], [38, 39], [39, 42], [43, 52], [53, 54], [55, 61], [62, 74], [75, 78], [79, 86], [87, 96], [97, 99], [100, 104], [104, 105], [105, 106], [107, 110], [111, 115], [116, 123], [123, 124], [125, 135], [135, 136], [137, 140], [141, 151], [152, 157], [157, 158], [159, 165], [165, 166], [167, 168], [169, 170], [170, 172], [173, 181], [182, 184], [185, 193], [194, 196], [197, 203], [204, 210], [211, 215], [216, 226], [227, 238], [238, 239], [240, 243], [244, 250], [251, 257], [258, 272], [273, 277], [277, 278], [279, 283], [284, 288], [289, 294], [294, 295], [296, 301], [302, 303], [304, 311], [312, 324], [324, 325], [325, 326], [327, 331], [332, 333], [333, 336], [337, 342], [343, 345], [346, 355], [356, 358], [359, 364], [365, 370], [371, 372], [373, 375], [376, 382], [383, 389], [389, 390], [391, 397], [398, 404], [405, 415], [416, 418], [419, 425], [426, 428], [429, 436], [436, 437], [437, 438], [439, 445], [445, 446], [447, 452], [452, 453], [454, 463], [464, 466], [467, 478], [479, 488], [489, 492], [493, 499], [499, 500], [500, 501]]}
{"doc_key": "ai-test-407", "ner": [[0, 3, "algorithm"], [5, 5, "algorithm"], [11, 12, "researcher"], [14, 16, "university"], [18, 19, "researcher"], [21, 24, "organisation"], [26, 26, "organisation"], [35, 37, "researcher"], [39, 41, "researcher"], [43, 44, "organisation"], [58, 62, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 3, 11, 12, "origin", "", false, false], [0, 3, 18, 19, "origin", "", false, false], [0, 3, 35, 37, "origin", "", false, false], [0, 3, 39, 41, "origin", "", false, false], [5, 5, 0, 3, "named", "", false, false], [11, 12, 14, 16, "physical", "", false, false], [11, 12, 14, 16, "role", "", false, false], [18, 19, 21, 24, "physical", "", false, false], [18, 19, 21, 24, "role", "", false, false], [26, 26, 21, 24, "named", "", false, false], [35, 37, 43, 44, "physical", "", false, false], [35, 37, 43, 44, "role", "", false, false], [39, 41, 43, 44, "physical", "", false, false], [39, 41, 43, 44, "role", "", false, false], [58, 62, 0, 3, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["A", "codifica\u00e7\u00e3o", "preditiva", "linear", "(", "LPC", ")", "foi", "inicialmente", "desenvolvida", "por", "Fumitada", "Itakura", "da", "Universidade", "de", "Nagoya", "e", "Shuzo", "Saito", "da", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "em", "1966", ",", "e", "depois", "desenvolvida", "por", "Bishnu", "S.", "Atal", "e", "Manfred", "R.", "Schroeder", "no", "Bell", "Labs", "durante", "o", "in\u00edcio", "dos", "anos", "70", ",", "tornando-se", "a", "base", "para", "o", "primeiro", "sintetizador", "de", "fala", "DSP", "chips", "no", "final", "dos", "anos", "70", "."], "sentence-detokenized": "A codifica\u00e7\u00e3o preditiva linear (LPC) foi inicialmente desenvolvida por Fumitada Itakura da Universidade de Nagoya e Shuzo Saito da Nippon Telegraph and Telephone (NTT) em 1966, e depois desenvolvida por Bishnu S. Atal e Manfred R. Schroeder no Bell Labs durante o in\u00edcio dos anos 70, tornando-se a base para o primeiro sintetizador de fala DSP chips no final dos anos 70.", "token2charspan": [[0, 1], [2, 13], [14, 23], [24, 30], [31, 32], [32, 35], [35, 36], [37, 40], [41, 53], [54, 66], [67, 70], [71, 79], [80, 87], [88, 90], [91, 103], [104, 106], [107, 113], [114, 115], [116, 121], [122, 127], [128, 130], [131, 137], [138, 147], [148, 151], [152, 161], [162, 163], [163, 166], [166, 167], [168, 170], [171, 175], [175, 176], [177, 178], [179, 185], [186, 198], [199, 202], [203, 209], [210, 212], [213, 217], [218, 219], [220, 227], [228, 230], [231, 240], [241, 243], [244, 248], [249, 253], [254, 261], [262, 263], [264, 270], [271, 274], [275, 279], [280, 282], [282, 283], [284, 295], [296, 297], [298, 302], [303, 307], [308, 309], [310, 318], [319, 331], [332, 334], [335, 339], [340, 343], [344, 349], [350, 352], [353, 358], [359, 362], [363, 367], [368, 370], [370, 371]]}
{"doc_key": "ai-test-408", "ner": [[1, 1, "metrics"], [6, 6, "metrics"], [9, 9, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 1, 1, "part-of", "", false, false], [9, 9, 1, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Um", "F-score", "\u00e9", "uma", "combina\u00e7\u00e3o", "da", "precis\u00e3o", "e", "do", "recall", ",", "fornecendo", "uma", "\u00fanica", "pontua\u00e7\u00e3o", "."], "sentence-detokenized": "Um F-score \u00e9 uma combina\u00e7\u00e3o da precis\u00e3o e do recall, fornecendo uma \u00fanica pontua\u00e7\u00e3o.", "token2charspan": [[0, 2], [3, 10], [11, 12], [13, 16], [17, 27], [28, 30], [31, 39], [40, 41], [42, 44], [45, 51], [51, 52], [53, 63], [64, 67], [68, 73], [74, 83], [83, 84]]}
{"doc_key": "ai-test-409", "ner": [[3, 5, "field"], [12, 18, "task"], [24, 27, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 18, 3, 5, "part-of", "task_part_of_field", false, false], [24, 27, 3, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "tarefas", "de", "an\u00e1lise", "de", "imagens", "podem", "ser", "t\u00e3o", "simples", "como", "a", "leitura", "de", "c\u00f3digos", "de", "barras", "d", "tags", "ou", "t\u00e3o", "sofisticadas", "como", "o", "sistema", "de", "reconhecimento", "facial", "."], "sentence-detokenized": "As tarefas de an\u00e1lise de imagens podem ser t\u00e3o simples como a leitura de c\u00f3digos de barras d tags ou t\u00e3o sofisticadas como o sistema de reconhecimento facial.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 21], [22, 24], [25, 32], [33, 38], [39, 42], [43, 46], [47, 54], [55, 59], [60, 61], [62, 69], [70, 72], [73, 80], [81, 83], [84, 90], [91, 92], [93, 97], [98, 100], [101, 104], [105, 117], [118, 122], [123, 124], [125, 132], [133, 135], [136, 150], [151, 157], [157, 158]]}
{"doc_key": "ai-test-410", "ner": [[4, 7, "algorithm"], [25, 26, "algorithm"], [34, 37, "algorithm"], [42, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[34, 37, 25, 26, "type-of", "", false, false], [42, 42, 34, 37, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["O", "caso", "especial", "das", "m\u00e1quinas", "de", "suporte", "linear-vetor", "pode", "ser", "resolvido", "mais", "eficientemente", "pelo", "mesmo", "tipo", "de", "algoritmos", "para", "otimizar", "sua", "prima", "pr\u00f3xima", ",", "a", "regress\u00e3o", "log\u00edstica", ";", "esta", "classe", "de", "algoritmos", "inclui", "a", "descida", "de", "gradiente", "estoc\u00e1stico", "(", "por", "exemplo", ",", "PEGASOS", ")", "."], "sentence-detokenized": "O caso especial das m\u00e1quinas de suporte linear-vetor pode ser resolvido mais eficientemente pelo mesmo tipo de algoritmos para otimizar sua prima pr\u00f3xima, a regress\u00e3o log\u00edstica; esta classe de algoritmos inclui a descida de gradiente estoc\u00e1stico (por exemplo, PEGASOS).", "token2charspan": [[0, 1], [2, 6], [7, 15], [16, 19], [20, 28], [29, 31], [32, 39], [40, 52], [53, 57], [58, 61], [62, 71], [72, 76], [77, 91], [92, 96], [97, 102], [103, 107], [108, 110], [111, 121], [122, 126], [127, 135], [136, 139], [140, 145], [146, 153], [153, 154], [155, 156], [157, 166], [167, 176], [176, 177], [178, 182], [183, 189], [190, 192], [193, 203], [204, 210], [211, 212], [213, 220], [221, 223], [224, 233], [234, 245], [246, 247], [247, 250], [251, 258], [258, 259], [260, 267], [267, 268], [268, 269]]}
{"doc_key": "ai-test-411", "ner": [[4, 4, "product"], [8, 8, "product"], [26, 26, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 8, 8, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Quando", "se", "pergunta", "a", "Siri", "sobre", "um", "dispositivo", "iOS", "Voc\u00ea", "tem", "um", "animal", "de", "estima\u00e7\u00e3o", "?", ",", "uma", "das", "respostas", "\u00e9", "que", "eu", "costumava", "ter", "um", "AIBO", "."], "sentence-detokenized": "Quando se pergunta a Siri sobre um dispositivo iOS Voc\u00ea tem um animal de estima\u00e7\u00e3o?, uma das respostas \u00e9 que eu costumava ter um AIBO.", "token2charspan": [[0, 6], [7, 9], [10, 18], [19, 20], [21, 25], [26, 31], [32, 34], [35, 46], [47, 50], [51, 55], [56, 59], [60, 62], [63, 69], [70, 72], [73, 82], [82, 83], [83, 84], [85, 88], [89, 92], [93, 102], [103, 104], [105, 108], [109, 111], [112, 121], [122, 125], [126, 128], [129, 133], [133, 134]]}
{"doc_key": "ai-test-412", "ner": [[1, 3, "task"], [6, 8, "metrics"], [12, 12, "metrics"], [16, 16, "metrics"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 8, 1, 3, "part-of", "", false, false], [12, 12, 6, 8, "named", "", false, false], [16, 16, 1, 3, "part-of", "", false, false], [20, 20, 16, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Na", "recupera\u00e7\u00e3o", "de", "informa\u00e7\u00f5es", ",", "o", "valor", "preditivo", "positivo", "\u00e9", "chamado", "de", "precis\u00e3o", ",", "e", "a", "sensibilidade", "\u00e9", "chamada", "de", "recall", "."], "sentence-detokenized": "Na recupera\u00e7\u00e3o de informa\u00e7\u00f5es, o valor preditivo positivo \u00e9 chamado de precis\u00e3o, e a sensibilidade \u00e9 chamada de recall.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 29], [29, 30], [31, 32], [33, 38], [39, 48], [49, 57], [58, 59], [60, 67], [68, 70], [71, 79], [79, 80], [81, 82], [83, 84], [85, 98], [99, 100], [101, 108], [109, 111], [112, 118], [118, 119]]}
{"doc_key": "ai-test-413", "ner": [[9, 11, "field"], [13, 13, "task"], [15, 15, "task"], [17, 19, "task"], [40, 42, "task"], [44, 45, "task"], [47, 52, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 13, 9, 11, "part-of", "task_part_of_field", false, false], [15, 15, 9, 11, "part-of", "task_part_of_field", false, false], [17, 19, 9, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Em", "particular", ",", "sua", "pesquisa", "concentrou-se", "em", "\u00e1reas", "como", "minera\u00e7\u00e3o", "de", "texto", "(", "extra\u00e7\u00e3o", ",", "categoriza\u00e7\u00e3o", ",", "detec\u00e7\u00e3o", "de", "novidade", ")", "e", "em", "novas", "estruturas", "te\u00f3ricas", ",", "como", "uma", "teoria", "unificada", "baseada", "em", "utilidades", "que", "faz", "a", "ponte", "entre", "a", "recupera\u00e7\u00e3o", "de", "informa\u00e7\u00f5es", ",", "sumariza\u00e7\u00e3o", "autom\u00e1tica", ",", "resposta", "a", "perguntas", "de", "texto", "livre", "e", "tarefas", "relacionadas", "."], "sentence-detokenized": "Em particular, sua pesquisa concentrou-se em \u00e1reas como minera\u00e7\u00e3o de texto (extra\u00e7\u00e3o, categoriza\u00e7\u00e3o, detec\u00e7\u00e3o de novidade) e em novas estruturas te\u00f3ricas, como uma teoria unificada baseada em utilidades que faz a ponte entre a recupera\u00e7\u00e3o de informa\u00e7\u00f5es, sumariza\u00e7\u00e3o autom\u00e1tica, resposta a perguntas de texto livre e tarefas relacionadas.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 27], [28, 41], [42, 44], [45, 50], [51, 55], [56, 65], [66, 68], [69, 74], [75, 76], [76, 84], [84, 85], [86, 99], [99, 100], [101, 109], [110, 112], [113, 121], [121, 122], [123, 124], [125, 127], [128, 133], [134, 144], [145, 153], [153, 154], [155, 159], [160, 163], [164, 170], [171, 180], [181, 188], [189, 191], [192, 202], [203, 206], [207, 210], [211, 212], [213, 218], [219, 224], [225, 226], [227, 238], [239, 241], [242, 253], [253, 254], [255, 266], [267, 277], [277, 278], [279, 287], [288, 289], [290, 299], [300, 302], [303, 308], [309, 314], [315, 316], [317, 324], [325, 337], [337, 338]]}
{"doc_key": "ai-test-414", "ner": [[0, 2, "product"], [4, 5, "product"], [12, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 0, 2, "part-of", "", false, false], [12, 17, 0, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Os", "rob\u00f4s", "Delta", "possuem", "atuadores", "rotativos", "montados", "em", "base", "que", "movem", "um", "bra\u00e7o", "leve", ",", "r\u00edgido", "e", "paralelogramo", "."], "sentence-detokenized": "Os rob\u00f4s Delta possuem atuadores rotativos montados em base que movem um bra\u00e7o leve, r\u00edgido e paralelogramo.", "token2charspan": [[0, 2], [3, 8], [9, 14], [15, 22], [23, 32], [33, 42], [43, 51], [52, 54], [55, 59], [60, 63], [64, 69], [70, 72], [73, 78], [79, 83], [83, 84], [85, 91], [92, 93], [94, 107], [107, 108]]}
{"doc_key": "ai-test-415", "ner": [[8, 13, "metrics"], [15, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Os", "quatro", "resultados", "podem", "ser", "formulados", "em", "uma", "tabela", "de", "conting\u00eancia", "2", "\u00d7", "2", "ou", "matriz", "de", "confus\u00e3o", ",", "como", "se", "segue", ":"], "sentence-detokenized": "Os quatro resultados podem ser formulados em uma tabela de conting\u00eancia 2 \u00d7 2 ou matriz de confus\u00e3o, como se segue:", "token2charspan": [[0, 2], [3, 9], [10, 20], [21, 26], [27, 30], [31, 41], [42, 44], [45, 48], [49, 55], [56, 58], [59, 71], [72, 73], [74, 75], [76, 77], [78, 80], [81, 87], [88, 90], [91, 99], [99, 100], [101, 105], [106, 108], [109, 114], [114, 115]]}
{"doc_key": "ai-test-416", "ner": [[4, 6, "field"], [33, 35, "task"], [41, 43, "task"], [48, 52, "task"], [54, 57, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[33, 35, 4, 6, "part-of", "task_part_of_field", false, false], [41, 43, 4, 6, "part-of", "task_part_of_field", false, false], [48, 52, 4, 6, "part-of", "task_part_of_field", false, false], [54, 57, 4, 6, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "tarefa", "real", "de", "minera\u00e7\u00e3o", "de", "dados", "\u00e9", "a", "an\u00e1lise", "semi-autom\u00e1tica", "ou", "autom\u00e1tica", "de", "grandes", "quantidades", "de", "dados", "para", "extrair", "padr\u00f5es", "desconhecidos", "e", "interessantes", ",", "tais", "como", "grupos", "de", "registros", "de", "dados", "(", "an\u00e1lise", "de", "agrupamento", ")", ",", "registros", "incomuns", "(", "detec\u00e7\u00e3o", "de", "anomalias", ")", "e", "depend\u00eancias", "(", "minera\u00e7\u00e3o", "de", "regras", "de", "associa\u00e7\u00e3o", ",", "minera\u00e7\u00e3o", "de", "padr\u00f5es", "seq\u00fcenciais", ")", "."], "sentence-detokenized": "A tarefa real de minera\u00e7\u00e3o de dados \u00e9 a an\u00e1lise semi-autom\u00e1tica ou autom\u00e1tica de grandes quantidades de dados para extrair padr\u00f5es desconhecidos e interessantes, tais como grupos de registros de dados (an\u00e1lise de agrupamento), registros incomuns (detec\u00e7\u00e3o de anomalias) e depend\u00eancias (minera\u00e7\u00e3o de regras de associa\u00e7\u00e3o, minera\u00e7\u00e3o de padr\u00f5es seq\u00fcenciais).", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 16], [17, 26], [27, 29], [30, 35], [36, 37], [38, 39], [40, 47], [48, 63], [64, 66], [67, 77], [78, 80], [81, 88], [89, 100], [101, 103], [104, 109], [110, 114], [115, 122], [123, 130], [131, 144], [145, 146], [147, 160], [160, 161], [162, 166], [167, 171], [172, 178], [179, 181], [182, 191], [192, 194], [195, 200], [201, 202], [202, 209], [210, 212], [213, 224], [224, 225], [225, 226], [227, 236], [237, 245], [246, 247], [247, 255], [256, 258], [259, 268], [268, 269], [270, 271], [272, 284], [285, 286], [286, 295], [296, 298], [299, 305], [306, 308], [309, 319], [319, 320], [321, 330], [331, 333], [334, 341], [342, 353], [353, 354], [354, 355]]}
{"doc_key": "ai-test-417", "ner": [[2, 4, "product"], [7, 9, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 4, 7, 9, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Para", "um", "sistema", "de", "recomenda\u00e7\u00e3o", ",", "a", "an\u00e1lise", "dos", "sentimentos", "provou", "ser", "uma", "t\u00e9cnica", "valiosa", "."], "sentence-detokenized": "Para um sistema de recomenda\u00e7\u00e3o, a an\u00e1lise dos sentimentos provou ser uma t\u00e9cnica valiosa.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 31], [31, 32], [33, 34], [35, 42], [43, 46], [47, 58], [59, 65], [66, 69], [70, 73], [74, 81], [82, 89], [89, 90]]}
{"doc_key": "ai-test-418", "ner": [[4, 4, "misc"], [15, 15, "product"], [38, 38, "organisation"], [40, 42, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 15, 15, "usage", "", false, false], [38, 38, 40, 42, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Por", "acaso", ",", "os", "alem\u00e3es", "tinham", "escolhido", "muito", "mal", "a", "freq\u00fc\u00eancia", "de", "opera\u00e7\u00e3o", "do", "sistema", "Wotan", ";", "ele", "operava", "em", "45", "MHz", ",", "que", "por", "acaso", "era", "a", "freq\u00fc\u00eancia", "do", "potente", ",", "mas", "dormente", ",", "transmissor", "de", "televis\u00e3o", "BBC", "no", "Pal\u00e1cio", "de", "Alexandra", "."], "sentence-detokenized": "Por acaso, os alem\u00e3es tinham escolhido muito mal a freq\u00fc\u00eancia de opera\u00e7\u00e3o do sistema Wotan; ele operava em 45 MHz, que por acaso era a freq\u00fc\u00eancia do potente, mas dormente, transmissor de televis\u00e3o BBC no Pal\u00e1cio de Alexandra.", "token2charspan": [[0, 3], [4, 9], [9, 10], [11, 13], [14, 21], [22, 28], [29, 38], [39, 44], [45, 48], [49, 50], [51, 61], [62, 64], [65, 73], [74, 76], [77, 84], [85, 90], [90, 91], [92, 95], [96, 103], [104, 106], [107, 109], [110, 113], [113, 114], [115, 118], [119, 122], [123, 128], [129, 132], [133, 134], [135, 145], [146, 148], [149, 156], [156, 157], [158, 161], [162, 170], [170, 171], [172, 183], [184, 186], [187, 196], [197, 200], [201, 203], [204, 211], [212, 214], [215, 224], [224, 225]]}
{"doc_key": "ai-test-419", "ner": [[8, 13, "metrics"], [15, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Os", "quatro", "resultados", "podem", "ser", "formulados", "em", "uma", "tabela", "de", "conting\u00eancia", "2", "\u00d7", "2", "ou", "matriz", "de", "confus\u00e3o", ",", "como", "se", "segue", ":"], "sentence-detokenized": "Os quatro resultados podem ser formulados em uma tabela de conting\u00eancia 2 \u00d7 2 ou matriz de confus\u00e3o, como se segue:", "token2charspan": [[0, 2], [3, 9], [10, 20], [21, 26], [27, 30], [31, 41], [42, 44], [45, 48], [49, 55], [56, 58], [59, 71], [72, 73], [74, 75], [76, 77], [78, 80], [81, 87], [88, 90], [91, 99], [99, 100], [101, 105], [106, 108], [109, 114], [114, 115]]}
{"doc_key": "ai-test-420", "ner": [[1, 4, "misc"], [12, 12, "misc"], [14, 14, "product"], [16, 16, "product"], [18, 20, "product"], [30, 30, "misc"], [45, 47, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[14, 14, 12, 12, "usage", "", false, false], [16, 16, 12, 12, "usage", "", false, false], [18, 20, 16, 16, "named", "", false, false], [30, 30, 12, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Em", "aplica\u00e7\u00f5es", "da", "Web", "Sem\u00e2ntica", ",", "e", "em", "aplica\u00e7\u00f5es", "relativamente", "populares", "de", "RDF", "como", "RSS", "e", "FOAF", "(", "Friend", "a", "Friend", ")", ",", "os", "recursos", "tendem", "a", "ser", "representados", "por", "URIs", "que", "intencionalmente", "denotam", ",", "e", "podem", "ser", "usados", "para", "acessar", ",", "dados", "reais", "na", "World", "Wide", "Web", "."], "sentence-detokenized": "Em aplica\u00e7\u00f5es da Web Sem\u00e2ntica, e em aplica\u00e7\u00f5es relativamente populares de RDF como RSS e FOAF (Friend a Friend), os recursos tendem a ser representados por URIs que intencionalmente denotam, e podem ser usados para acessar, dados reais na World Wide Web.", "token2charspan": [[0, 2], [3, 13], [14, 16], [17, 20], [21, 30], [30, 31], [32, 33], [34, 36], [37, 47], [48, 61], [62, 71], [72, 74], [75, 78], [79, 83], [84, 87], [88, 89], [90, 94], [95, 96], [96, 102], [103, 104], [105, 111], [111, 112], [112, 113], [114, 116], [117, 125], [126, 132], [133, 134], [135, 138], [139, 152], [153, 156], [157, 161], [162, 165], [166, 182], [183, 190], [190, 191], [192, 193], [194, 199], [200, 203], [204, 210], [211, 215], [216, 223], [223, 224], [225, 230], [231, 236], [237, 239], [240, 245], [246, 250], [251, 254], [254, 255]]}
{"doc_key": "ai-test-421", "ner": [[1, 7, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "Associa\u00e7\u00e3o", "para", "o", "Progresso", "da", "Intelig\u00eancia", "Artificial", "estudou", "este", "t\u00f3pico", "em", "profundidade"], "sentence-detokenized": "A Associa\u00e7\u00e3o para o Progresso da Intelig\u00eancia Artificial estudou este t\u00f3pico em profundidade", "token2charspan": [[0, 1], [2, 12], [13, 17], [18, 19], [20, 29], [30, 32], [33, 45], [46, 56], [57, 64], [65, 69], [70, 76], [77, 79], [80, 92]]}
{"doc_key": "ai-test-422", "ner": [[6, 11, "product"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 18, 6, 11, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Come\u00e7ando", "como", "uma", "curiosidade", ",", "o", "sistema", "de", "fala", "da", "Apple", "Macintosh", "evoluiu", "para", "um", "programa", "totalmente", "apoiado", "PlainTalk", ",", "para", "pessoas", "com", "problemas", "de", "vis\u00e3o", "."], "sentence-detokenized": "Come\u00e7ando como uma curiosidade, o sistema de fala da Apple Macintosh evoluiu para um programa totalmente apoiado PlainTalk, para pessoas com problemas de vis\u00e3o.", "token2charspan": [[0, 9], [10, 14], [15, 18], [19, 30], [30, 31], [32, 33], [34, 41], [42, 44], [45, 49], [50, 52], [53, 58], [59, 68], [69, 76], [77, 81], [82, 84], [85, 93], [94, 104], [105, 112], [113, 122], [122, 123], [124, 128], [129, 136], [137, 140], [141, 150], [151, 153], [154, 159], [159, 160]]}
{"doc_key": "ai-test-423", "ner": [[8, 8, "field"], [11, 13, "task"], [15, 17, "task"], [19, 20, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 13, 8, 8, "part-of", "task_part_of_field", false, false], [15, 17, 8, 8, "part-of", "task_part_of_field", false, false], [19, 20, 8, 8, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Outras", "\u00e1reas", "de", "uso", "para", "ontologias", "dentro", "da", "PNL", "incluem", "a", "recupera\u00e7\u00e3o", "de", "informa\u00e7\u00f5es", ",", "extra\u00e7\u00e3o", "de", "informa\u00e7\u00f5es", "e", "resumo", "autom\u00e1tico", "."], "sentence-detokenized": "Outras \u00e1reas de uso para ontologias dentro da PNL incluem a recupera\u00e7\u00e3o de informa\u00e7\u00f5es, extra\u00e7\u00e3o de informa\u00e7\u00f5es e resumo autom\u00e1tico.", "token2charspan": [[0, 6], [7, 12], [13, 15], [16, 19], [20, 24], [25, 35], [36, 42], [43, 45], [46, 49], [50, 57], [58, 59], [60, 71], [72, 74], [75, 86], [86, 87], [88, 96], [97, 99], [100, 111], [112, 113], [114, 120], [121, 131], [131, 132]]}
{"doc_key": "ai-test-424", "ner": [[7, 14, "organisation"], [17, 22, "organisation"], [25, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["O", "Instituto", "tem", "colaborado", "estreitamente", "com", "o", "Campus", "Fazenda", "Janelia", "do", "Instituto", "M\u00e9dico", "Howard", "Hughes", ",", "o", "Instituto", "Allen", "de", "Ci\u00eancia", "do", "C\u00e9rebro", "e", "os", "Institutos", "Nacionais", "de", "Sa\u00fade", "para", "desenvolver", "melhores", "m\u00e9todos", "de", "reconstru\u00e7\u00e3o", "de", "arquiteturas", "neuronais", "."], "sentence-detokenized": "O Instituto tem colaborado estreitamente com o Campus Fazenda Janelia do Instituto M\u00e9dico Howard Hughes, o Instituto Allen de Ci\u00eancia do C\u00e9rebro e os Institutos Nacionais de Sa\u00fade para desenvolver melhores m\u00e9todos de reconstru\u00e7\u00e3o de arquiteturas neuronais.", "token2charspan": [[0, 1], [2, 11], [12, 15], [16, 26], [27, 40], [41, 44], [45, 46], [47, 53], [54, 61], [62, 69], [70, 72], [73, 82], [83, 89], [90, 96], [97, 103], [103, 104], [105, 106], [107, 116], [117, 122], [123, 125], [126, 133], [134, 136], [137, 144], [145, 146], [147, 149], [150, 160], [161, 170], [171, 173], [174, 179], [180, 184], [185, 196], [197, 205], [206, 213], [214, 216], [217, 229], [230, 232], [233, 245], [246, 255], [255, 256]]}
{"doc_key": "ai-test-425", "ner": [[2, 3, "organisation"], [6, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 2, 3, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Recentemente", ",", "o", "Google", "anunciou", "que", "o", "Google", "Translate", "traduz", "aproximadamente", "o", "texto", "suficiente", "para", "preencher", "1", "milh\u00e3o", "de", "livros", "em", "um", "dia", "(", "2012", ")", "."], "sentence-detokenized": "Recentemente, o Google anunciou que o Google Translate traduz aproximadamente o texto suficiente para preencher 1 milh\u00e3o de livros em um dia (2012).", "token2charspan": [[0, 12], [12, 13], [14, 15], [16, 22], [23, 31], [32, 35], [36, 37], [38, 44], [45, 54], [55, 61], [62, 77], [78, 79], [80, 85], [86, 96], [97, 101], [102, 111], [112, 113], [114, 120], [121, 123], [124, 130], [131, 133], [134, 136], [137, 140], [141, 142], [142, 146], [146, 147], [147, 148]]}
{"doc_key": "ai-test-426", "ner": [[13, 14, "country"], [16, 17, "country"], [19, 19, "country"], [21, 21, "country"], [23, 23, "country"], [25, 27, "country"], [39, 40, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Os", "eventos", "s\u00e3o", "realizados", "em", "todo", "o", "mundo", "e", "s\u00e3o", "mais", "populares", "no", "Reino", "Unido", ",", "Estados", "Unidos", ",", "Jap\u00e3o", ",", "Cingapura", ",", "\u00cdndia", ",", "Cor\u00e9ia", "do", "Sul", "e", "est\u00e3o", "se", "tornando", "populares", "em", "pa\u00edses", "do", "subcontinente", "como", "o", "Sri", "Lanka", "."], "sentence-detokenized": "Os eventos s\u00e3o realizados em todo o mundo e s\u00e3o mais populares no Reino Unido, Estados Unidos, Jap\u00e3o, Cingapura, \u00cdndia, Cor\u00e9ia do Sul e est\u00e3o se tornando populares em pa\u00edses do subcontinente como o Sri Lanka.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 25], [26, 28], [29, 33], [34, 35], [36, 41], [42, 43], [44, 47], [48, 52], [53, 62], [63, 65], [66, 71], [72, 77], [77, 78], [79, 86], [87, 93], [93, 94], [95, 100], [100, 101], [102, 111], [111, 112], [113, 118], [118, 119], [120, 126], [127, 129], [130, 133], [134, 135], [136, 141], [142, 144], [145, 153], [154, 163], [164, 166], [167, 173], [174, 176], [177, 190], [191, 195], [196, 197], [198, 201], [202, 207], [207, 208]]}
{"doc_key": "ai-test-427", "ner": [[6, 6, "programlang"], [12, 12, "programlang"], [14, 14, "programlang"], [16, 18, "programlang"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Estes", "pacotes", "s\u00e3o", "desenvolvidos", "principalmente", "em", "R", ",", "e", "\u00e0s", "vezes", "em", "Java", ",", "C", ",", "C", "+", "+", ",", "e", "Fortran", "."], "sentence-detokenized": "Estes pacotes s\u00e3o desenvolvidos principalmente em R, e \u00e0s vezes em Java, C, C + +, e Fortran.", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 31], [32, 46], [47, 49], [50, 51], [51, 52], [53, 54], [55, 57], [58, 63], [64, 66], [67, 71], [71, 72], [73, 74], [74, 75], [76, 77], [78, 79], [80, 81], [81, 82], [83, 84], [85, 92], [92, 93]]}
{"doc_key": "ai-test-428", "ner": [[3, 10, "conference"], [12, 12, "conference"], [15, 15, "researcher"], [17, 17, "researcher"], [21, 22, "researcher"], [25, 26, "algorithm"], [30, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 12, 3, 10, "named", "", false, false], [15, 15, 3, 10, "physical", "", false, false], [15, 15, 3, 10, "role", "", false, false], [15, 15, 21, 22, "role", "teams_up_with", false, false], [15, 15, 25, 26, "usage", "", false, false], [17, 17, 3, 10, "physical", "", false, false], [17, 17, 3, 10, "role", "", false, false], [17, 17, 21, 22, "role", "teams_up_with", false, false], [17, 17, 25, 26, "usage", "", false, false], [21, 22, 3, 10, "physical", "", false, false], [21, 22, 3, 10, "role", "", false, false], [21, 22, 25, 26, "usage", "", false, false], [25, 26, 30, 35, "related-to", "used_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Como", "parte", "da", "Confer\u00eancia", "Europ\u00e9ia", "de", "2006", "sobre", "Vis\u00e3o", "por", "Computador", "(", "ECCV", ")", ",", "Dalal", "e", "Triggs", "se", "uniram", "a", "Cordelia", "Schmid", "para", "aplicar", "detectores", "HOG", "ao", "problema", "da", "detec\u00e7\u00e3o", "humana", "em", "filmes", "e", "v\u00eddeos", "."], "sentence-detokenized": "Como parte da Confer\u00eancia Europ\u00e9ia de 2006 sobre Vis\u00e3o por Computador (ECCV), Dalal e Triggs se uniram a Cordelia Schmid para aplicar detectores HOG ao problema da detec\u00e7\u00e3o humana em filmes e v\u00eddeos.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 25], [26, 34], [35, 37], [38, 42], [43, 48], [49, 54], [55, 58], [59, 69], [70, 71], [71, 75], [75, 76], [76, 77], [78, 83], [84, 85], [86, 92], [93, 95], [96, 102], [103, 104], [105, 113], [114, 120], [121, 125], [126, 133], [134, 144], [145, 148], [149, 151], [152, 160], [161, 163], [164, 172], [173, 179], [180, 182], [183, 189], [190, 191], [192, 198], [198, 199]]}
{"doc_key": "ai-test-429", "ner": [[2, 2, "metrics"], [4, 4, "metrics"], [12, 13, "task"], [18, 20, "metrics"], [22, 22, "metrics"], [28, 28, "metrics"], [31, 33, "metrics"], [35, 35, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[2, 2, 12, 13, "related-to", "measured_with", false, false], [4, 4, 12, 13, "related-to", "measured_with", false, false], [18, 20, 12, 13, "related-to", "measured_with", false, false], [22, 22, 18, 20, "named", "", false, false], [28, 28, 18, 20, "named", "", false, false], [35, 35, 31, 33, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Al\u00e9m", "da", "sensibilidade", "e", "especificidade", ",", "o", "desempenho", "de", "um", "teste", "de", "classifica\u00e7\u00e3o", "bin\u00e1ria", "pode", "ser", "medido", "com", "valor", "preditivo", "positivo", "(", "VPP", ")", ",", "tamb\u00e9m", "conhecido", "como", "precis\u00e3o", ",", "e", "valor", "preditivo", "negativo", "(", "VPL", ")", "."], "sentence-detokenized": "Al\u00e9m da sensibilidade e especificidade, o desempenho de um teste de classifica\u00e7\u00e3o bin\u00e1ria pode ser medido com valor preditivo positivo (VPP), tamb\u00e9m conhecido como precis\u00e3o, e valor preditivo negativo (VPL).", "token2charspan": [[0, 4], [5, 7], [8, 21], [22, 23], [24, 38], [38, 39], [40, 41], [42, 52], [53, 55], [56, 58], [59, 64], [65, 67], [68, 81], [82, 89], [90, 94], [95, 98], [99, 105], [106, 109], [110, 115], [116, 125], [126, 134], [135, 136], [136, 139], [139, 140], [140, 141], [142, 148], [149, 158], [159, 163], [164, 172], [172, 173], [174, 175], [176, 181], [182, 191], [192, 200], [201, 202], [202, 205], [205, 206], [206, 207]]}
{"doc_key": "ai-test-430", "ner": [[14, 17, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Tais", "modelos", "podem", "dar", "cr\u00e9dito", "parcial", "por", "partidas", "sobrepostas", "(", "como", "a", "utiliza\u00e7\u00e3o", "do", "crit\u00e9rio", "do", "\u00edndice", "Jaccard", ")", "."], "sentence-detokenized": "Tais modelos podem dar cr\u00e9dito parcial por partidas sobrepostas (como a utiliza\u00e7\u00e3o do crit\u00e9rio do \u00edndice Jaccard).", "token2charspan": [[0, 4], [5, 12], [13, 18], [19, 22], [23, 30], [31, 38], [39, 42], [43, 51], [52, 63], [64, 65], [65, 69], [70, 71], [72, 82], [83, 85], [86, 94], [95, 97], [98, 104], [105, 112], [112, 113], [113, 114]]}
{"doc_key": "ai-test-431", "ner": [[22, 29, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Al\u00e9m", "disso", ",", "no", "caso", "de", "estimativa", "baseada", "em", "uma", "\u00fanica", "amostra", ",", "demonstra", "quest\u00f5es", "filos\u00f3ficas", "e", "poss\u00edveis", "mal-entendidos", "no", "uso", "de", "estimadores", "de", "m\u00e1xima", "verosimilhan\u00e7a", "e", "fun\u00e7\u00f5es", "de", "verosimilhan\u00e7a", "."], "sentence-detokenized": "Al\u00e9m disso, no caso de estimativa baseada em uma \u00fanica amostra, demonstra quest\u00f5es filos\u00f3ficas e poss\u00edveis mal-entendidos no uso de estimadores de m\u00e1xima verosimilhan\u00e7a e fun\u00e7\u00f5es de verosimilhan\u00e7a.", "token2charspan": [[0, 4], [5, 10], [10, 11], [12, 14], [15, 19], [20, 22], [23, 33], [34, 41], [42, 44], [45, 48], [49, 54], [55, 62], [62, 63], [64, 73], [74, 82], [83, 94], [95, 96], [97, 106], [107, 121], [122, 124], [125, 128], [129, 131], [132, 143], [144, 146], [147, 153], [154, 168], [169, 170], [171, 178], [179, 181], [182, 196], [196, 197]]}
