{"doc_key": "ai-train-1", "ner": [[4, 9, "product"], [15, 17, "field"], [19, 21, "task"], [23, 25, "task"], [29, 32, "task"], [35, 36, "field"], [37, 38, "researcher"], [40, 41, "researcher"], [43, 45, "researcher"], [47, 49, "researcher"], [51, 52, "researcher"], [54, 56, "researcher"], [58, 59, "researcher"], [61, 62, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 9, 15, 17, "part-of", "", false, false], [4, 9, 15, 17, "usage", "", false, false], [4, 9, 19, 21, "part-of", "", false, false], [4, 9, 19, 21, "usage", "", false, false], [4, 9, 23, 25, "part-of", "", false, false], [4, 9, 23, 25, "usage", "", false, false], [4, 9, 35, 36, "part-of", "", false, false], [4, 9, 35, 36, "usage", "", false, false], [29, 32, 23, 25, "part-of", "", false, false], [29, 32, 23, 25, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["As", "abordagens", "populares", "do", "sistema", "de", "recomenda\u00e7\u00e3o", "baseado", "em", "opini\u00f5es", "utilizam", "v\u00e1rias", "t\u00e9cnicas", ",", "incluindo", "minera\u00e7\u00e3o", "de", "textos", ",", "recupera\u00e7\u00e3o", "de", "informa\u00e7\u00f5es", ",", "an\u00e1lise", "de", "sentimentos", "(", "ver", "tamb\u00e9m", "An\u00e1lise", "multimodal", "de", "sentimentos", ")", "e", "aprendizagem", "profunda", "X.Y.", "Feng", ",", "H.", "Zhang", ",", "Y.J", ".", "Ren", ",", "P.H", ".", "Shang", ",", "Y.", "Zhu", ",", "Y.C", ".", "Liang", ",", "R.C.", "Guan", ",", "D.", "Xu", ",", "(", "2019", ")", ",", "21", "(", "5", ")", ":", "e12957", "."], "sentence-detokenized": "As abordagens populares do sistema de recomenda\u00e7\u00e3o baseado em opini\u00f5es utilizam v\u00e1rias t\u00e9cnicas, incluindo minera\u00e7\u00e3o de textos, recupera\u00e7\u00e3o de informa\u00e7\u00f5es, an\u00e1lise de sentimentos (ver tamb\u00e9m An\u00e1lise multimodal de sentimentos) e aprendizagem profunda X.Y. Feng, H. Zhang, Y.J. Ren, P.H. Shang, Y. Zhu, Y.C. Liang, R.C. Guan, D. Xu, (2019), 21 (5): e12957.", "token2charspan": [[0, 2], [3, 13], [14, 23], [24, 26], [27, 34], [35, 37], [38, 50], [51, 58], [59, 61], [62, 70], [71, 79], [80, 86], [87, 95], [95, 96], [97, 106], [107, 116], [117, 119], [120, 126], [126, 127], [128, 139], [140, 142], [143, 154], [154, 155], [156, 163], [164, 166], [167, 178], [179, 180], [180, 183], [184, 190], [191, 198], [199, 209], [210, 212], [213, 224], [224, 225], [226, 227], [228, 240], [241, 249], [250, 254], [255, 259], [259, 260], [261, 263], [264, 269], [269, 270], [271, 274], [274, 275], [276, 279], [279, 280], [281, 284], [284, 285], [286, 291], [291, 292], [293, 295], [296, 299], [299, 300], [301, 304], [304, 305], [306, 311], [311, 312], [313, 317], [318, 322], [322, 323], [324, 326], [327, 329], [329, 330], [331, 332], [332, 336], [336, 337], [337, 338], [339, 341], [342, 343], [343, 344], [344, 345], [345, 346], [347, 353], [353, 354]]}
{"doc_key": "ai-train-2", "ner": [[9, 9, "university"], [15, 16, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 16, 9, 9, "physical", "", false, false], [15, 16, 9, 9, "role", "", false, false], [18, 19, 9, 9, "physical", "", false, false], [18, 19, 9, 9, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Os", "defensores", "das", "representa\u00e7\u00f5es", "processuais", "estavam", "concentrados", "principalmente", "no", "MIT", ",", "sob", "a", "lideran\u00e7a", "de", "Marvin", "Minsky", "e", "Seymour", "Papert", "."], "sentence-detokenized": "Os defensores das representa\u00e7\u00f5es processuais estavam concentrados principalmente no MIT, sob a lideran\u00e7a de Marvin Minsky e Seymour Papert.", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 32], [33, 44], [45, 52], [53, 65], [66, 80], [81, 83], [84, 87], [87, 88], [89, 92], [93, 94], [95, 104], [105, 107], [108, 114], [115, 121], [122, 123], [124, 131], [132, 138], [138, 139]]}
{"doc_key": "ai-train-3", "ner": [[11, 11, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "interface", "padr\u00e3o", "e", "a", "interface", "da", "calculadora", "s\u00e3o", "escritas", "em", "Java", "."], "sentence-detokenized": "A interface padr\u00e3o e a interface da calculadora s\u00e3o escritas em Java.", "token2charspan": [[0, 1], [2, 11], [12, 18], [19, 20], [21, 22], [23, 32], [33, 35], [36, 47], [48, 51], [52, 60], [61, 63], [64, 68], [68, 69]]}
{"doc_key": "ai-train-4", "ner": [[0, 0, "product"], [31, 31, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 31, 31, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["Octave", "ajuda", "na", "solu\u00e7\u00e3o", "num\u00e9rica", "de", "problemas", "lineares", "e", "n\u00e3o", "lineares", ",", "e", "para", "a", "realiza\u00e7\u00e3o", "de", "outros", "experimentos", "num\u00e9ricos", "usando", "um", "que", "\u00e9", "na", "maioria", "das", "vezes", "compat\u00edvel", "com", "o", "MATLAB", "."], "sentence-detokenized": "Octave ajuda na solu\u00e7\u00e3o num\u00e9rica de problemas lineares e n\u00e3o lineares, e para a realiza\u00e7\u00e3o de outros experimentos num\u00e9ricos usando um que \u00e9 na maioria das vezes compat\u00edvel com o MATLAB.", "token2charspan": [[0, 6], [7, 12], [13, 15], [16, 23], [24, 32], [33, 35], [36, 45], [46, 54], [55, 56], [57, 60], [61, 69], [69, 70], [71, 72], [73, 77], [78, 79], [80, 90], [91, 93], [94, 100], [101, 113], [114, 123], [124, 130], [131, 133], [134, 137], [138, 139], [140, 142], [143, 150], [151, 154], [155, 160], [161, 171], [172, 175], [176, 177], [178, 184], [184, 185]]}
{"doc_key": "ai-train-5", "ner": [[2, 6, "algorithm"], [8, 10, "misc"], [12, 13, "researcher"], [17, 19, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 6, 12, 13, "origin", "", false, false], [8, 10, 12, 13, "origin", "", false, false], [12, 13, 17, 19, "physical", "", false, false], [12, 13, 17, 19, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Variantes", "do", "algoritmo", "de", "retropropaga\u00e7\u00e3o", ",", "bem", "como", "m\u00e9todos", "n\u00e3o", "supervisionados", "por", "Geoff", "Hinton", "e", "colegas", "da", "Universidade", "de", "Toronto", "podem", "ser", "usados", "para", "treinar", "arquiteturas", "neurais", "profundas", "e", "altamente", "n\u00e3o", "lineares", ",", "{", "{", "{", "cito", "journal"], "sentence-detokenized": "Variantes do algoritmo de retropropaga\u00e7\u00e3o, bem como m\u00e9todos n\u00e3o supervisionados por Geoff Hinton e colegas da Universidade de Toronto podem ser usados para treinar arquiteturas neurais profundas e altamente n\u00e3o lineares, {{{cito journal", "token2charspan": [[0, 9], [10, 12], [13, 22], [23, 25], [26, 41], [41, 42], [43, 46], [47, 51], [52, 59], [60, 63], [64, 79], [80, 83], [84, 89], [90, 96], [97, 98], [99, 106], [107, 109], [110, 122], [123, 125], [126, 133], [134, 139], [140, 143], [144, 150], [151, 155], [156, 163], [164, 176], [177, 184], [185, 194], [195, 196], [197, 206], [207, 210], [211, 219], [219, 220], [221, 222], [222, 223], [223, 224], [224, 228], [229, 236]]}
{"doc_key": "ai-train-6", "ner": [[5, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["ou", "equivalente", "usando", "a", "nota\u00e7\u00e3o", "DCG", ":"], "sentence-detokenized": "ou equivalente usando a nota\u00e7\u00e3o DCG:", "token2charspan": [[0, 2], [3, 14], [15, 21], [22, 23], [24, 31], [32, 35], [35, 36]]}
{"doc_key": "ai-train-7", "ner": [[0, 2, "algorithm"], [6, 8, "algorithm"], [11, 13, "algorithm"], [16, 20, "algorithm"], [24, 24, "algorithm"], [26, 27, "algorithm"], [44, 45, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 6, 8, "type-of", "", false, false], [0, 2, 11, 13, "usage", "part-of?", true, false], [11, 13, 16, 20, "compare", "", false, false], [24, 24, 16, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Os", "mapas", "auto-organizados", "diferem", "de", "outras", "redes", "neurais", "artificiais", "por", "aplicarem", "aprendizagem", "competitiva", "em", "oposi\u00e7\u00e3o", "\u00e0", "aprendizagem", "de", "corre\u00e7\u00e3o", "de", "erros", ",", "como", "a", "retropropaga\u00e7\u00e3o", "com", "descida", "gradiente", ")", ",", "e", "no", "sentido", "de", "que", "eles", "usam", "uma", "fun\u00e7\u00e3o", "de", "vizinhan\u00e7a", "para", "preservar", "as", "propriedades", "topol\u00f3gicas", "do", "espa\u00e7o", "de", "entrada", "."], "sentence-detokenized": "Os mapas auto-organizados diferem de outras redes neurais artificiais por aplicarem aprendizagem competitiva em oposi\u00e7\u00e3o \u00e0 aprendizagem de corre\u00e7\u00e3o de erros, como a retropropaga\u00e7\u00e3o com descida gradiente), e no sentido de que eles usam uma fun\u00e7\u00e3o de vizinhan\u00e7a para preservar as propriedades topol\u00f3gicas do espa\u00e7o de entrada.", "token2charspan": [[0, 2], [3, 8], [9, 25], [26, 33], [34, 36], [37, 43], [44, 49], [50, 57], [58, 69], [70, 73], [74, 83], [84, 96], [97, 108], [109, 111], [112, 120], [121, 122], [123, 135], [136, 138], [139, 147], [148, 150], [151, 156], [156, 157], [158, 162], [163, 164], [165, 180], [181, 184], [185, 192], [193, 202], [202, 203], [203, 204], [205, 206], [207, 209], [210, 217], [218, 220], [221, 224], [225, 229], [230, 234], [235, 238], [239, 245], [246, 248], [249, 259], [260, 264], [265, 274], [275, 277], [278, 290], [291, 302], [303, 305], [306, 312], [313, 315], [316, 323], [323, 324]]}
{"doc_key": "ai-train-8", "ner": [[16, 20, "organisation"], [32, 34, "misc"], [42, 46, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Desde", "o", "in\u00edcio", "dos", "anos", "90", ",", "tem", "sido", "recomendado", "por", "v\u00e1rias", "autoridades", ",", "incluindo", "a", "Sociedade", "de", "Engenharia", "de", "\u00c1udio", ",", "que", "as", "medi\u00e7\u00f5es", "de", "faixa", "din\u00e2mica", "sejam", "feitas", "com", "um", "sinal", "de", "\u00e1udio", "presente", ",", "que", "\u00e9", "ent\u00e3o", "filtrado", "na", "medi\u00e7\u00e3o", "do", "piso", "de", "ru\u00eddo", "usado", "na", "determina\u00e7\u00e3o", "da", "faixa", "din\u00e2mica", ".", "Isto", "evita", "medi\u00e7\u00f5es", "question\u00e1veis", "baseadas", "no", "uso", "de", "m\u00eddia", "em", "branco", ",", "ou", "circuitos", "mutantes", "."], "sentence-detokenized": "Desde o in\u00edcio dos anos 90, tem sido recomendado por v\u00e1rias autoridades, incluindo a Sociedade de Engenharia de \u00c1udio, que as medi\u00e7\u00f5es de faixa din\u00e2mica sejam feitas com um sinal de \u00e1udio presente, que \u00e9 ent\u00e3o filtrado na medi\u00e7\u00e3o do piso de ru\u00eddo usado na determina\u00e7\u00e3o da faixa din\u00e2mica. Isto evita medi\u00e7\u00f5es question\u00e1veis baseadas no uso de m\u00eddia em branco, ou circuitos mutantes.", "token2charspan": [[0, 5], [6, 7], [8, 14], [15, 18], [19, 23], [24, 26], [26, 27], [28, 31], [32, 36], [37, 48], [49, 52], [53, 59], [60, 71], [71, 72], [73, 82], [83, 84], [85, 94], [95, 97], [98, 108], [109, 111], [112, 117], [117, 118], [119, 122], [123, 125], [126, 134], [135, 137], [138, 143], [144, 152], [153, 158], [159, 165], [166, 169], [170, 172], [173, 178], [179, 181], [182, 187], [188, 196], [196, 197], [198, 201], [202, 203], [204, 209], [210, 218], [219, 221], [222, 229], [230, 232], [233, 237], [238, 240], [241, 246], [247, 252], [253, 255], [256, 268], [269, 271], [272, 277], [278, 286], [286, 287], [288, 292], [293, 298], [299, 307], [308, 321], [322, 330], [331, 333], [334, 337], [338, 340], [341, 346], [347, 349], [350, 356], [356, 357], [358, 360], [361, 370], [371, 379], [379, 380]]}
{"doc_key": "ai-train-9", "ner": [[6, 7, "misc"], [18, 19, "task"], [21, 23, "task"], [25, 26, "task"], [28, 30, "task"], [34, 36, "task"], [32, 40, "task"], [42, 45, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[6, 7, 18, 19, "part-of", "concept_used_in", true, false], [6, 7, 21, 23, "part-of", "concept_used_in", false, false], [6, 7, 25, 26, "part-of", "concept_used_in", false, false], [6, 7, 28, 30, "part-of", "concept_used_in", false, false], [6, 7, 34, 36, "part-of", "concept_used_in", false, false], [6, 7, 32, 40, "part-of", "concept_used_in", false, false], [6, 7, 42, 45, "part-of", "concept_used_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["A", "t\u00e9cnica", "utilizada", "na", "cria\u00e7\u00e3o", "de", "faces", "pr\u00f3prias", "e", "sua", "utiliza\u00e7\u00e3o", "para", "reconhecimento", "tamb\u00e9m", "\u00e9", "utilizada", "fora", "do", "reconhecimento", "facial", ":", "reconhecimento", "de", "caligrafia", ",", "leitura", "labial", ",", "reconhecimento", "de", "voz", ",", "interpreta\u00e7\u00e3o", "de", "linguagem", "de", "sinais", "/", "gestos", "de", "m\u00e3o", "e", "an\u00e1lise", "de", "imagens", "m\u00e9dicas", "."], "sentence-detokenized": "A t\u00e9cnica utilizada na cria\u00e7\u00e3o de faces pr\u00f3prias e sua utiliza\u00e7\u00e3o para reconhecimento tamb\u00e9m \u00e9 utilizada fora do reconhecimento facial: reconhecimento de caligrafia, leitura labial, reconhecimento de voz, interpreta\u00e7\u00e3o de linguagem de sinais / gestos de m\u00e3o e an\u00e1lise de imagens m\u00e9dicas.", "token2charspan": [[0, 1], [2, 9], [10, 19], [20, 22], [23, 30], [31, 33], [34, 39], [40, 48], [49, 50], [51, 54], [55, 65], [66, 70], [71, 85], [86, 92], [93, 94], [95, 104], [105, 109], [110, 112], [113, 127], [128, 134], [134, 135], [136, 150], [151, 153], [154, 164], [164, 165], [166, 173], [174, 180], [180, 181], [182, 196], [197, 199], [200, 203], [203, 204], [205, 218], [219, 221], [222, 231], [232, 234], [235, 241], [242, 243], [244, 250], [251, 253], [254, 257], [258, 259], [260, 267], [268, 270], [271, 278], [279, 286], [286, 287]]}
{"doc_key": "ai-train-10", "ner": [[1, 3, "organisation"], [9, 13, "organisation"], [15, 15, "organisation"], [19, 23, "organisation"], [26, 31, "organisation"], [34, 38, "organisation"], [42, 45, "organisation"], [47, 47, "organisation"], [52, 55, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[9, 13, 1, 3, "part-of", "", false, false], [15, 15, 9, 13, "named", "", false, false], [19, 23, 1, 3, "part-of", "", false, false], [26, 31, 1, 3, "part-of", "", false, false], [34, 38, 1, 3, "part-of", "", false, false], [42, 45, 1, 3, "part-of", "", false, false], [47, 47, 42, 45, "named", "", false, false], [52, 55, 1, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["A", "National", "Science", "Foundation", "foi", "um", "guarda-chuva", "para", "a", "National", "Aeronautics", "and", "Space", "Administration", "(", "NASA", ")", ",", "o", "Departamento", "de", "Energia", "dos", "EUA", ",", "o", "Departamento", "de", "Com\u00e9rcio", "dos", "EUA", "NIST", ",", "o", "Departamento", "de", "Defesa", "dos", "EUA", ",", "a", "Defense", "Advanced", "Research", "Projects", "Agency", "(", "DARPA", ")", ",", "e", "o", "Office", "of", "Naval", "Research", "coordenaram", "estudos", "para", "informar", "os", "planejadores", "estrat\u00e9gicos", "em", "suas", "delibera\u00e7\u00f5es", "."], "sentence-detokenized": "A National Science Foundation foi um guarda-chuva para a National Aeronautics and Space Administration (NASA), o Departamento de Energia dos EUA, o Departamento de Com\u00e9rcio dos EUA NIST, o Departamento de Defesa dos EUA, a Defense Advanced Research Projects Agency (DARPA), e o Office of Naval Research coordenaram estudos para informar os planejadores estrat\u00e9gicos em suas delibera\u00e7\u00f5es.", "token2charspan": [[0, 1], [2, 10], [11, 18], [19, 29], [30, 33], [34, 36], [37, 49], [50, 54], [55, 56], [57, 65], [66, 77], [78, 81], [82, 87], [88, 102], [103, 104], [104, 108], [108, 109], [109, 110], [111, 112], [113, 125], [126, 128], [129, 136], [137, 140], [141, 144], [144, 145], [146, 147], [148, 160], [161, 163], [164, 172], [173, 176], [177, 180], [181, 185], [185, 186], [187, 188], [189, 201], [202, 204], [205, 211], [212, 215], [216, 219], [219, 220], [221, 222], [223, 230], [231, 239], [240, 248], [249, 257], [258, 264], [265, 266], [266, 271], [271, 272], [272, 273], [274, 275], [276, 277], [278, 284], [285, 287], [288, 293], [294, 302], [303, 314], [315, 322], [323, 327], [328, 336], [337, 339], [340, 352], [353, 365], [366, 368], [369, 373], [374, 386], [386, 387]]}
{"doc_key": "ai-train-11", "ner": [[7, 8, "metrics"], [11, 12, "algorithm"], [16, 17, "researcher"], [24, 24, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 11, 12, "part-of", "", false, false], [16, 17, 24, 24, "related-to", "added_appendix_to_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Um", "m\u00e9todo", "r\u00e1pido", "para", "calcular", "estimativas", "de", "m\u00e1xima", "probabilidade", "para", "o", "modelo", "probit", "foi", "proposto", "por", "Ronald", "Fisher", "como", "um", "ap\u00eandice", "do", "trabalho", "de", "Bliss", "em", "1935", "."], "sentence-detokenized": "Um m\u00e9todo r\u00e1pido para calcular estimativas de m\u00e1xima probabilidade para o modelo probit foi proposto por Ronald Fisher como um ap\u00eandice do trabalho de Bliss em 1935.", "token2charspan": [[0, 2], [3, 9], [10, 16], [17, 21], [22, 30], [31, 42], [43, 45], [46, 52], [53, 66], [67, 71], [72, 73], [74, 80], [81, 87], [88, 91], [92, 100], [101, 104], [105, 111], [112, 118], [119, 123], [124, 126], [127, 135], [136, 138], [139, 147], [148, 150], [151, 156], [157, 159], [160, 164], [164, 165]]}
{"doc_key": "ai-train-12", "ner": [[9, 10, "product"], [13, 14, "product"], [20, 20, "organisation"], [18, 19, "product"], [25, 25, "organisation"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[18, 19, 13, 14, "usage", "uses_software", false, false], [18, 19, 20, 20, "artifact", "", false, false], [18, 19, 23, 23, "named", "", false, false], [23, 23, 25, 25, "artifact", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["V\u00e1rios", "desses", "programas", "est\u00e3o", "dispon\u00edveis", "online", ",", "como", "o", "Google", "Translate", "e", "o", "sistema", "SYSTRAN", "que", "alimenta", "o", "BabelFish", "do", "AltaVista", "(", "agora", "Babelfish", "do", "Yahoo", "a", "partir", "de", "9", "de", "maio", "de", "2008", ")", "."], "sentence-detokenized": "V\u00e1rios desses programas est\u00e3o dispon\u00edveis online, como o Google Translate e o sistema SYSTRAN que alimenta o BabelFish do AltaVista (agora Babelfish do Yahoo a partir de 9 de maio de 2008).", "token2charspan": [[0, 6], [7, 13], [14, 23], [24, 29], [30, 41], [42, 48], [48, 49], [50, 54], [55, 56], [57, 63], [64, 73], [74, 75], [76, 77], [78, 85], [86, 93], [94, 97], [98, 106], [107, 108], [109, 118], [119, 121], [122, 131], [132, 133], [133, 138], [139, 148], [149, 151], [152, 157], [158, 159], [160, 166], [167, 169], [170, 171], [172, 174], [175, 179], [180, 182], [183, 187], [187, 188], [188, 189]]}
{"doc_key": "ai-train-13", "ner": [[2, 2, "researcher"], [5, 6, "researcher"], [8, 9, "researcher"], [18, 20, "field"], [23, 24, "misc"], [27, 29, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 18, 20, "related-to", "", true, false], [2, 2, 23, 24, "related-to", "", true, false], [2, 2, 27, 29, "related-to", "", true, false], [5, 6, 18, 20, "related-to", "", true, false], [5, 6, 23, 24, "related-to", "", true, false], [5, 6, 27, 29, "related-to", "", true, false], [8, 9, 18, 20, "related-to", "", true, false], [8, 9, 23, 24, "related-to", "", true, false], [8, 9, 27, 29, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Em", "2002", "Hutter", ",", "com", "J\u00fcrgen", "Schmidhuber", "e", "Shane", "Legg", ",", "desenvolveu", "e", "publicou", "uma", "teoria", "matem\u00e1tica", "de", "intelig\u00eancia", "geral", "artificial", "baseada", "em", "agentes", "inteligentes", "idealizados", "e", "aprendizagem", "de", "refor\u00e7o", "com", "motiva\u00e7\u00e3o", "para", "a", "guerra", "."], "sentence-detokenized": "Em 2002 Hutter, com J\u00fcrgen Schmidhuber e Shane Legg, desenvolveu e publicou uma teoria matem\u00e1tica de intelig\u00eancia geral artificial baseada em agentes inteligentes idealizados e aprendizagem de refor\u00e7o com motiva\u00e7\u00e3o para a guerra.", "token2charspan": [[0, 2], [3, 7], [8, 14], [14, 15], [16, 19], [20, 26], [27, 38], [39, 40], [41, 46], [47, 51], [51, 52], [53, 64], [65, 66], [67, 75], [76, 79], [80, 86], [87, 97], [98, 100], [101, 113], [114, 119], [120, 130], [131, 138], [139, 141], [142, 149], [150, 162], [163, 174], [175, 176], [177, 189], [190, 192], [193, 200], [201, 204], [205, 214], [215, 219], [220, 221], [222, 228], [228, 229]]}
{"doc_key": "ai-train-14", "ner": [[9, 9, "metrics"], [11, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 9, 11, 15, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "maneira", "mais", "comum", "\u00e9", "usar", "a", "chamada", "medida", "ROUGE", "(", "Recall-Oriented", "Understudy", "for", "Gisting", "Evaluation", ")", "."], "sentence-detokenized": "A maneira mais comum \u00e9 usar a chamada medida ROUGE (Recall-Oriented Understudy for Gisting Evaluation).", "token2charspan": [[0, 1], [2, 9], [10, 14], [15, 20], [21, 22], [23, 27], [28, 29], [30, 37], [38, 44], [45, 50], [51, 52], [52, 67], [68, 78], [79, 82], [83, 90], [91, 101], [101, 102], [102, 103]]}
{"doc_key": "ai-train-15", "ner": [[0, 0, "product"], [15, 15, "programlang"], [17, 17, "programlang"], [19, 20, "researcher"], [22, 23, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 15, 15, "related-to", "", false, false], [0, 0, 17, 17, "related-to", "", false, false], [19, 20, 22, 23, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["RapidMiner", "fornece", "esquemas", "de", "aprendizagem", ",", "modelos", "e", "algoritmos", "e", "pode", "ser", "estendido", "usando", "scripts", "R", "e", "Python", ".", "David", "Norris", ",", "Bloor", "Research", ",", "13", "de", "novembro", "de", "2013", "."], "sentence-detokenized": "RapidMiner fornece esquemas de aprendizagem, modelos e algoritmos e pode ser estendido usando scripts R e Python. David Norris, Bloor Research, 13 de novembro de 2013.", "token2charspan": [[0, 10], [11, 18], [19, 27], [28, 30], [31, 43], [43, 44], [45, 52], [53, 54], [55, 65], [66, 67], [68, 72], [73, 76], [77, 86], [87, 93], [94, 101], [102, 103], [104, 105], [106, 112], [112, 113], [114, 119], [120, 126], [126, 127], [128, 133], [134, 142], [142, 143], [144, 146], [147, 149], [150, 158], [159, 161], [162, 166], [166, 167]]}
{"doc_key": "ai-train-16", "ner": [[8, 8, "programlang"], [10, 11, "product"]], "ner_mapping_to_source": [4, 5], "relations": [[10, 11, 8, 8, "general-affiliation", "", true, false]], "relations_mapping_to_source": [4], "sentence": ["mas", "a", "mais", "recente", "vers\u00e3o", "totalmente", "baseada", "em", "Java", "(", "Weka", "3", ")", ",", "cujo", "desenvolvimento", "come\u00e7ou", "em", "1997", ",", "\u00e9", "agora", "utilizada", "em", "muitas", "\u00e1reas", "de", "aplica\u00e7\u00e3o", "diferentes", ",", "em", "particular", "para", "fins", "educacionais", "e", "de", "pesquisa", "."], "sentence-detokenized": "mas a mais recente vers\u00e3o totalmente baseada em Java (Weka 3), cujo desenvolvimento come\u00e7ou em 1997, \u00e9 agora utilizada em muitas \u00e1reas de aplica\u00e7\u00e3o diferentes, em particular para fins educacionais e de pesquisa.", "token2charspan": [[0, 3], [4, 5], [6, 10], [11, 18], [19, 25], [26, 36], [37, 44], [45, 47], [48, 52], [53, 54], [54, 58], [59, 60], [60, 61], [61, 62], [63, 67], [68, 83], [84, 91], [92, 94], [95, 99], [99, 100], [101, 102], [103, 108], [109, 118], [119, 121], [122, 128], [129, 134], [135, 137], [138, 147], [148, 158], [158, 159], [160, 162], [163, 173], [174, 178], [179, 183], [184, 196], [197, 198], [199, 201], [202, 210], [210, 211]]}
{"doc_key": "ai-train-17", "ner": [[0, 1, "product"], [15, 22, "misc"], [25, 28, "misc"], [30, 38, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 22, 0, 1, "topic", "", false, false], [15, 22, 25, 28, "win-defeat", "", false, false], [25, 28, 30, 38, "temporal", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "Eurisko", "fez", "muitas", "descobertas", "interessantes", "e", "desfrutou", "de", "aclama\u00e7\u00e3o", "significativa", ",", "com", "seu", "papel", "Heuretics", ":", "Te\u00f3rico", "e", "Estudo", "das", "Regras", "Heur\u00edsticas", "ganhando", "o", "pr\u00eamio", "de", "Melhor", "Papel", "na", "Associa\u00e7\u00e3o", "para", "o", "Progresso", "da", "Intelig\u00eancia", "Artificial", "de", "1982", "."], "sentence-detokenized": "A Eurisko fez muitas descobertas interessantes e desfrutou de aclama\u00e7\u00e3o significativa, com seu papel Heuretics: Te\u00f3rico e Estudo das Regras Heur\u00edsticas ganhando o pr\u00eamio de Melhor Papel na Associa\u00e7\u00e3o para o Progresso da Intelig\u00eancia Artificial de 1982.", "token2charspan": [[0, 1], [2, 9], [10, 13], [14, 20], [21, 32], [33, 46], [47, 48], [49, 58], [59, 61], [62, 71], [72, 85], [85, 86], [87, 90], [91, 94], [95, 100], [101, 110], [110, 111], [112, 119], [120, 121], [122, 128], [129, 132], [133, 139], [140, 151], [152, 160], [161, 162], [163, 169], [170, 172], [173, 179], [180, 185], [186, 188], [189, 199], [200, 204], [205, 206], [207, 216], [217, 219], [220, 232], [233, 243], [244, 246], [247, 251], [251, 252]]}
{"doc_key": "ai-train-18", "ner": [[6, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Para", "permitir", "m\u00faltiplas", "entidades", ",", "uma", "perda", "de", "dobradi\u00e7a", "separada", "\u00e9", "computada", "para", "cada", "c\u00e1psula", "."], "sentence-detokenized": "Para permitir m\u00faltiplas entidades, uma perda de dobradi\u00e7a separada \u00e9 computada para cada c\u00e1psula.", "token2charspan": [[0, 4], [5, 13], [14, 23], [24, 33], [33, 34], [35, 38], [39, 44], [45, 47], [48, 57], [58, 66], [67, 68], [69, 78], [79, 83], [84, 88], [89, 96], [96, 97]]}
{"doc_key": "ai-train-19", "ner": [[9, 11, "product"], [14, 15, "product"], [18, 19, "product"], [22, 23, "product"], [26, 28, "product"], [31, 33, "product"], [43, 48, "product"], [52, 53, "product"], [56, 57, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[9, 11, 31, 33, "type-of", "", false, false], [14, 15, 31, 33, "type-of", "", false, false], [18, 19, 31, 33, "type-of", "", false, false], [22, 23, 31, 33, "type-of", "", false, false], [26, 28, 31, 33, "type-of", "", false, false], [52, 53, 43, 48, "type-of", "", false, false], [56, 57, 43, 48, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Com", "o", "surgimento", "de", "assistentes", "de", "conversa\u00e7\u00e3o", "como", "o", "Siri", "da", "Apple", ",", "o", "Amazon", "Alexa", ",", "o", "Google", "Assistant", ",", "o", "Microsoft", "Cortana", "e", "o", "Bixby", "da", "Samsung", ",", "os", "Portais", "de", "Voz", "podem", "agora", "ser", "acessados", "atrav\u00e9s", "de", "dispositivos", "m\u00f3veis", "e", "alto-falantes", "inteligentes", "de", "voz", "Far", "Field", ",", "como", "o", "Amazon", "Echo", "e", "o", "Google", "Home", "."], "sentence-detokenized": "Com o surgimento de assistentes de conversa\u00e7\u00e3o como o Siri da Apple, o Amazon Alexa, o Google Assistant, o Microsoft Cortana e o Bixby da Samsung, os Portais de Voz podem agora ser acessados atrav\u00e9s de dispositivos m\u00f3veis e alto-falantes inteligentes de voz Far Field, como o Amazon Echo e o Google Home.", "token2charspan": [[0, 3], [4, 5], [6, 16], [17, 19], [20, 31], [32, 34], [35, 46], [47, 51], [52, 53], [54, 58], [59, 61], [62, 67], [67, 68], [69, 70], [71, 77], [78, 83], [83, 84], [85, 86], [87, 93], [94, 103], [103, 104], [105, 106], [107, 116], [117, 124], [125, 126], [127, 128], [129, 134], [135, 137], [138, 145], [145, 146], [147, 149], [150, 157], [158, 160], [161, 164], [165, 170], [171, 176], [177, 180], [181, 190], [191, 198], [199, 201], [202, 214], [215, 221], [222, 223], [224, 237], [238, 250], [251, 253], [254, 257], [258, 261], [262, 267], [267, 268], [269, 273], [274, 275], [276, 282], [283, 287], [288, 289], [290, 291], [292, 298], [299, 303], [303, 304]]}
{"doc_key": "ai-train-20", "ner": [[2, 3, "field"], [5, 7, "algorithm"], [9, 12, "algorithm"], [14, 16, "algorithm"], [19, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 7, 2, 3, "type-of", "", false, false], [9, 12, 2, 3, "type-of", "", false, false], [14, 16, 2, 3, "type-of", "", false, false], [19, 19, 2, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Exemplos", "de", "aprendizagem", "supervisionada", "s\u00e3o", "Naive", "Bayes", "classificadora", ",", "m\u00e1quina", "vetorial", "de", "suporte", ",", "misturas", "de", "gaussianos", ",", "e", "rede", "."], "sentence-detokenized": "Exemplos de aprendizagem supervisionada s\u00e3o Naive Bayes classificadora, m\u00e1quina vetorial de suporte, misturas de gaussianos, e rede.", "token2charspan": [[0, 8], [9, 11], [12, 24], [25, 39], [40, 43], [44, 49], [50, 55], [56, 70], [70, 71], [72, 79], [80, 88], [89, 91], [92, 99], [99, 100], [101, 109], [110, 112], [113, 123], [123, 124], [125, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-train-21", "ner": [[3, 4, "algorithm"], [23, 26, "algorithm"], [28, 28, "task"], [33, 35, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 23, 26, "part-of", "", true, false], [33, 35, 28, 28, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pode-se", "usar", "o", "algoritmo", "OSD", "para", "derivar", "a", "matem\u00e1tica", "O", "(", "sqrt", "{", "T", "}", ")", "/", "matem\u00e1tica", "para", "a", "vers\u00e3o", "on-line", "da", "m\u00e1quina", "vetorial", "de", "suporte", "para", "classifica\u00e7\u00e3o", ",", "que", "usa", "a", "dobradi\u00e7a", "de", "perda", "matem\u00e1tica", "v", "_t", "(", "w", ")", "==", "m\u00e1x", ".", "/", "matem\u00e1tica"], "sentence-detokenized": "Pode-se usar o algoritmo OSD para derivar a matem\u00e1tica O (sqrt {T}) / matem\u00e1tica para a vers\u00e3o on-line da m\u00e1quina vetorial de suporte para classifica\u00e7\u00e3o, que usa a dobradi\u00e7a de perda matem\u00e1tica v _t (w) == m\u00e1x. / matem\u00e1tica", "token2charspan": [[0, 7], [8, 12], [13, 14], [15, 24], [25, 28], [29, 33], [34, 41], [42, 43], [44, 54], [55, 56], [57, 58], [58, 62], [63, 64], [64, 65], [65, 66], [66, 67], [68, 69], [70, 80], [81, 85], [86, 87], [88, 94], [95, 102], [103, 105], [106, 113], [114, 122], [123, 125], [126, 133], [134, 138], [139, 152], [152, 153], [154, 157], [158, 161], [162, 163], [164, 173], [174, 176], [177, 182], [183, 193], [194, 195], [196, 198], [199, 200], [200, 201], [201, 202], [203, 205], [206, 209], [209, 210], [211, 212], [213, 223]]}
{"doc_key": "ai-train-22", "ner": [[3, 5, "task"], [7, 10, "task"], [9, 9, "task"], [12, 14, "task"], [16, 17, "task"], [19, 21, "task"], [23, 25, "task"], [27, 31, "task"], [33, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["As", "aplica\u00e7\u00f5es", "incluem", "reconhecimento", "de", "objetos", ",", "mapeamento", "e", "navega\u00e7\u00e3o", "rob\u00f3tica", ",", "costura", "de", "imagens", ",", "modelagem", "3D", ",", "reconhecimento", "de", "gestos", ",", "rastreamento", "de", "v\u00eddeo", ",", "identifica\u00e7\u00e3o", "individual", "de", "vida", "selvagem", "e", "movimento", "de", "f\u00f3sforos", "."], "sentence-detokenized": "As aplica\u00e7\u00f5es incluem reconhecimento de objetos, mapeamento e navega\u00e7\u00e3o rob\u00f3tica, costura de imagens, modelagem 3D, reconhecimento de gestos, rastreamento de v\u00eddeo, identifica\u00e7\u00e3o individual de vida selvagem e movimento de f\u00f3sforos.", "token2charspan": [[0, 2], [3, 13], [14, 21], [22, 36], [37, 39], [40, 47], [47, 48], [49, 59], [60, 61], [62, 71], [72, 80], [80, 81], [82, 89], [90, 92], [93, 100], [100, 101], [102, 111], [112, 114], [114, 115], [116, 130], [131, 133], [134, 140], [140, 141], [142, 154], [155, 157], [158, 163], [163, 164], [165, 178], [179, 189], [190, 192], [193, 197], [198, 206], [207, 208], [209, 218], [219, 221], [222, 230], [230, 231]]}
{"doc_key": "ai-train-23", "ner": [[6, 8, "task"], [13, 14, "university"], [16, 18, "university"], [20, 21, "university"], [23, 25, "university"], [27, 32, "university"], [34, 36, "university"], [38, 40, "university"], [42, 43, "university"], [45, 50, "university"], [52, 52, "university"], [56, 60, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[6, 8, 13, 14, "related-to", "", true, false], [6, 8, 16, 18, "related-to", "", true, false], [6, 8, 20, 21, "related-to", "", true, false], [6, 8, 23, 25, "related-to", "", true, false], [6, 8, 27, 32, "related-to", "", true, false], [6, 8, 34, 36, "related-to", "", true, false], [6, 8, 38, 40, "related-to", "", true, false], [6, 8, 42, 43, "related-to", "", true, false], [6, 8, 45, 50, "related-to", "", true, false], [6, 8, 52, 52, "related-to", "", true, false], [6, 8, 56, 60, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["V\u00e1rios", "grupos", "e", "empresas", "est\u00e3o", "pesquisando", "estimativa", "de", "pose", ",", "incluindo", "grupos", "na", "Universidade", "Brown", ",", "Carnegie", "Mellon", "University", ",", "MPI", "Saarbruecken", ",", "Universidade", "de", "Stanford", ",", "Universidade", "da", "Calif\u00f3rnia", ",", "San", "Diego", ",", "Universidade", "de", "Toronto", ",", "\u00c9cole", "Centrale", "Paris", ",", "ETH", "Zurich", ",", "Universidade", "Nacional", "de", "Ci\u00eancias", "e", "Tecnologia", "(", "NUST", ")", ",", "e", "Universidade", "da", "Calif\u00f3rnia", ",", "Irvine", "."], "sentence-detokenized": "V\u00e1rios grupos e empresas est\u00e3o pesquisando estimativa de pose, incluindo grupos na Universidade Brown, Carnegie Mellon University, MPI Saarbruecken, Universidade de Stanford, Universidade da Calif\u00f3rnia, San Diego, Universidade de Toronto, \u00c9cole Centrale Paris, ETH Zurich, Universidade Nacional de Ci\u00eancias e Tecnologia (NUST), e Universidade da Calif\u00f3rnia, Irvine.", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 24], [25, 30], [31, 42], [43, 53], [54, 56], [57, 61], [61, 62], [63, 72], [73, 79], [80, 82], [83, 95], [96, 101], [101, 102], [103, 111], [112, 118], [119, 129], [129, 130], [131, 134], [135, 147], [147, 148], [149, 161], [162, 164], [165, 173], [173, 174], [175, 187], [188, 190], [191, 201], [201, 202], [203, 206], [207, 212], [212, 213], [214, 226], [227, 229], [230, 237], [237, 238], [239, 244], [245, 253], [254, 259], [259, 260], [261, 264], [265, 271], [271, 272], [273, 285], [286, 294], [295, 297], [298, 306], [307, 308], [309, 319], [320, 321], [321, 325], [325, 326], [326, 327], [328, 329], [330, 342], [343, 345], [346, 356], [356, 357], [358, 364], [364, 365]]}
{"doc_key": "ai-train-24", "ner": [[0, 6, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Fun\u00e7\u00e3o", "Sigmoid", "A", "perda", "de", "entropia", "cruzada", "\u00e9", "usada", "para", "prever", "valores", "de", "probabilidade", "K", "independentes", "em", "matem\u00e1tica", "0,1", "/", "matem\u00e1tica", "."], "sentence-detokenized": "Fun\u00e7\u00e3o Sigmoid A perda de entropia cruzada \u00e9 usada para prever valores de probabilidade K independentes em matem\u00e1tica 0,1 / matem\u00e1tica.", "token2charspan": [[0, 6], [7, 14], [15, 16], [17, 22], [23, 25], [26, 34], [35, 42], [43, 44], [45, 50], [51, 55], [56, 62], [63, 70], [71, 73], [74, 87], [88, 89], [90, 103], [104, 106], [107, 117], [118, 121], [122, 123], [124, 134], [134, 135]]}
{"doc_key": "ai-train-25", "ner": [[3, 5, "misc"], [7, 7, "field"], [9, 9, "field"], [11, 13, "university"], [16, 16, "country"], [20, 22, "misc"], [24, 28, "university"], [31, 31, "country"], [39, 39, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 5, 7, 7, "topic", "", false, false], [3, 5, 9, 9, "topic", "", false, false], [3, 5, 11, 13, "physical", "", true, false], [11, 13, 16, 16, "physical", "", false, false], [20, 22, 24, 28, "physical", "", true, false], [24, 28, 31, 31, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Ele", "ocupou", "a", "C\u00e1tedra", "Johann", "Bernoulli", "de", "Matem\u00e1tica", "e", "Inform\u00e1tica", "na", "Universidade", "de", "Groningen", ",", "na", "Holanda", ",", "e", "a", "C\u00e1tedra", "Toshiba", "Endowed", "no", "Instituto", "de", "Tecnologia", "de", "T\u00f3quio", ",", "no", "Jap\u00e3o", ",", "antes", "de", "se", "tornar", "Professor", "em", "Cambridge", "."], "sentence-detokenized": "Ele ocupou a C\u00e1tedra Johann Bernoulli de Matem\u00e1tica e Inform\u00e1tica na Universidade de Groningen, na Holanda, e a C\u00e1tedra Toshiba Endowed no Instituto de Tecnologia de T\u00f3quio, no Jap\u00e3o, antes de se tornar Professor em Cambridge.", "token2charspan": [[0, 3], [4, 10], [11, 12], [13, 20], [21, 27], [28, 37], [38, 40], [41, 51], [52, 53], [54, 65], [66, 68], [69, 81], [82, 84], [85, 94], [94, 95], [96, 98], [99, 106], [106, 107], [108, 109], [110, 111], [112, 119], [120, 127], [128, 135], [136, 138], [139, 148], [149, 151], [152, 162], [163, 165], [166, 172], [172, 173], [174, 176], [177, 182], [182, 183], [184, 189], [190, 192], [193, 195], [196, 202], [203, 212], [213, 215], [216, 225], [225, 226]]}
{"doc_key": "ai-train-26", "ner": [[5, 7, "algorithm"], [12, 15, "algorithm"], [17, 17, "algorithm"], [22, 23, "researcher"], [25, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 7, 12, 15, "usage", "", true, false], [12, 15, 22, 23, "origin", "", false, false], [12, 15, 25, 26, "origin", "", false, false], [17, 17, 12, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Outra", "t\u00e9cnica", "particularmente", "utilizada", "para", "redes", "neurais", "recorrentes", "\u00e9", "a", "rede", "de", "mem\u00f3ria", "de", "longo", "prazo", "(", "LSTM", ")", "de", "1997", "por", "Sepp", "Hochreiter", "&", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Outra t\u00e9cnica particularmente utilizada para redes neurais recorrentes \u00e9 a rede de mem\u00f3ria de longo prazo (LSTM) de 1997 por Sepp Hochreiter & J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 5], [6, 13], [14, 29], [30, 39], [40, 44], [45, 50], [51, 58], [59, 70], [71, 72], [73, 74], [75, 79], [80, 82], [83, 90], [91, 93], [94, 99], [100, 105], [106, 107], [107, 111], [111, 112], [113, 115], [116, 120], [121, 124], [125, 129], [130, 140], [141, 142], [143, 149], [150, 161], [161, 162]]}
{"doc_key": "ai-train-27", "ner": [[5, 7, "programlang"], [9, 9, "product"], [15, 16, "product"], [46, 46, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 5, 7, "general-affiliation", "", false, false], [9, 9, 15, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "inclus\u00e3o", "de", "um", "interpretador", "C", "+", "+", "(", "CINT", "at\u00e9", "a", "vers\u00e3o", "5.34", ",", "Cling", "a", "partir", "da", "vers\u00e3o", "6", ")", "torna", "este", "pacote", "muito", "vers\u00e1til", ",", "pois", "pode", "ser", "usado", "nos", "modos", "interativo", ",", "roteirizado", "e", "compilado", "de", "maneira", "semelhante", "aos", "produtos", "comerciais", "como", "MATLAB", "."], "sentence-detokenized": "A inclus\u00e3o de um interpretador C + + (CINT at\u00e9 a vers\u00e3o 5.34, Cling a partir da vers\u00e3o 6) torna este pacote muito vers\u00e1til, pois pode ser usado nos modos interativo, roteirizado e compilado de maneira semelhante aos produtos comerciais como MATLAB.", "token2charspan": [[0, 1], [2, 10], [11, 13], [14, 16], [17, 30], [31, 32], [33, 34], [35, 36], [37, 38], [38, 42], [43, 46], [47, 48], [49, 55], [56, 60], [60, 61], [62, 67], [68, 69], [70, 76], [77, 79], [80, 86], [87, 88], [88, 89], [90, 95], [96, 100], [101, 107], [108, 113], [114, 122], [122, 123], [124, 128], [129, 133], [134, 137], [138, 143], [144, 147], [148, 153], [154, 164], [164, 165], [166, 177], [178, 179], [180, 189], [190, 192], [193, 200], [201, 211], [212, 215], [216, 224], [225, 235], [236, 240], [241, 247], [247, 248]]}
{"doc_key": "ai-train-28", "ner": [[0, 5, "product"], [29, 32, "field"], [34, 36, "task"], [38, 40, "task"], [42, 44, "task"], [46, 48, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 5, 29, 32, "related-to", "", false, false], [34, 36, 29, 32, "part-of", "", false, false], [38, 40, 29, 32, "part-of", "", false, false], [42, 44, 29, 32, "part-of", "", false, false], [46, 48, 29, 32, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["As", "interfaces", "de", "usu\u00e1rio", "de", "voz", "que", "interpretam", "e", "gerenciam", "o", "estado", "de", "conversa\u00e7\u00e3o", "s\u00e3o", "um", "desafio", "para", "o", "projeto", "devido", "\u00e0", "dificuldade", "inerente", "de", "integrar", "tarefas", "complexas", "de", "processamento", "de", "linguagem", "natural", "como", "resolu\u00e7\u00e3o", "de", "refer\u00eancia", ",", "reconhecimento", "de", "identidade", ",", "recupera\u00e7\u00e3o", "de", "informa\u00e7\u00f5es", "e", "gerenciamento", "de", "di\u00e1logo", "."], "sentence-detokenized": "As interfaces de usu\u00e1rio de voz que interpretam e gerenciam o estado de conversa\u00e7\u00e3o s\u00e3o um desafio para o projeto devido \u00e0 dificuldade inerente de integrar tarefas complexas de processamento de linguagem natural como resolu\u00e7\u00e3o de refer\u00eancia, reconhecimento de identidade, recupera\u00e7\u00e3o de informa\u00e7\u00f5es e gerenciamento de di\u00e1logo.", "token2charspan": [[0, 2], [3, 13], [14, 16], [17, 24], [25, 27], [28, 31], [32, 35], [36, 47], [48, 49], [50, 59], [60, 61], [62, 68], [69, 71], [72, 83], [84, 87], [88, 90], [91, 98], [99, 103], [104, 105], [106, 113], [114, 120], [121, 122], [123, 134], [135, 143], [144, 146], [147, 155], [156, 163], [164, 173], [174, 176], [177, 190], [191, 193], [194, 203], [204, 211], [212, 216], [217, 226], [227, 229], [230, 240], [240, 241], [242, 256], [257, 259], [260, 270], [270, 271], [272, 283], [284, 286], [287, 298], [299, 300], [301, 314], [315, 317], [318, 325], [325, 326]]}
{"doc_key": "ai-train-29", "ner": [[6, 8, "algorithm"], [11, 15, "algorithm"], [22, 23, "researcher"], [25, 28, "organisation"], [34, 36, "field"], [38, 40, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 8, 22, 23, "origin", "", false, false], [6, 8, 34, 36, "part-of", "", false, false], [6, 8, 38, 40, "part-of", "", false, false], [11, 15, 22, 23, "origin", "", false, false], [11, 15, 34, 36, "part-of", "", false, false], [11, 15, 38, 40, "part-of", "", false, false], [22, 23, 25, 28, "physical", "", false, false], [22, 23, 25, 28, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Entre", "2009", "e", "2012", ",", "as", "redes", "neurais", "recorrentes", "e", "as", "redes", "neurais", "de", "alimenta\u00e7\u00e3o", "profunda", "desenvolvidas", "no", "grupo", "de", "pesquisa", "de", "J\u00fcrgen", "Schmidhuber", "no", "Swiss", "AI", "Lab", "IDSIA", "ganharam", "oito", "competi\u00e7\u00f5es", "internacionais", "de", "reconhecimento", "de", "padr\u00f5es", "e", "aprendizagem", "de", "m\u00e1quinas", "."], "sentence-detokenized": "Entre 2009 e 2012, as redes neurais recorrentes e as redes neurais de alimenta\u00e7\u00e3o profunda desenvolvidas no grupo de pesquisa de J\u00fcrgen Schmidhuber no Swiss AI Lab IDSIA ganharam oito competi\u00e7\u00f5es internacionais de reconhecimento de padr\u00f5es e aprendizagem de m\u00e1quinas.", "token2charspan": [[0, 5], [6, 10], [11, 12], [13, 17], [17, 18], [19, 21], [22, 27], [28, 35], [36, 47], [48, 49], [50, 52], [53, 58], [59, 66], [67, 69], [70, 81], [82, 90], [91, 104], [105, 107], [108, 113], [114, 116], [117, 125], [126, 128], [129, 135], [136, 147], [148, 150], [151, 156], [157, 159], [160, 163], [164, 169], [170, 178], [179, 183], [184, 195], [196, 210], [211, 213], [214, 228], [229, 231], [232, 239], [240, 241], [242, 254], [255, 257], [258, 266], [266, 267]]}
{"doc_key": "ai-train-30", "ner": [[2, 4, "product"], [9, 10, "product"], [12, 13, "product"], [17, 19, "task"], [22, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 9, 10, "usage", "", false, false], [2, 4, 12, 13, "usage", "", false, false], [2, 4, 17, 19, "usage", "", true, false], [2, 4, 22, 22, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Os", "modernos", "sistemas", "desktop", "Windows", "podem", "usar", "os", "componentes", "SAPI", "4", "e", "SAPI", "5", "para", "suportar", "a", "s\u00edntese", "de", "voz", "e", "a", "fala", "."], "sentence-detokenized": "Os modernos sistemas desktop Windows podem usar os componentes SAPI 4 e SAPI 5 para suportar a s\u00edntese de voz e a fala.", "token2charspan": [[0, 2], [3, 11], [12, 20], [21, 28], [29, 36], [37, 42], [43, 47], [48, 50], [51, 62], [63, 67], [68, 69], [70, 71], [72, 76], [77, 78], [79, 83], [84, 92], [93, 94], [95, 102], [103, 105], [106, 109], [110, 111], [112, 113], [114, 118], [118, 119]]}
{"doc_key": "ai-train-31", "ner": [[7, 12, "misc"], [14, 14, "field"], [16, 18, "university"], [25, 28, "field"], [30, 33, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 12, 14, 14, "topic", "topic_of_award", false, false], [7, 12, 16, 18, "origin", "", true, false], [25, 28, 30, 33, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Ele", "recebeu", "dois", "t\u00edtulos", "honor\u00edficos", ",", "um", "S.", "V.", "della", "laurea", "ad", "honorem", "em", "Psicologia", "pela", "Universidade", "de", "P\u00e1dua", "em", "1995", "e", "um", "doutorado", "em", "Desenho", "e", "Engenharia", "Industrial", "pela", "Delft", "University", "of", "Technology", "."], "sentence-detokenized": "Ele recebeu dois t\u00edtulos honor\u00edficos, um S. V. della laurea ad honorem em Psicologia pela Universidade de P\u00e1dua em 1995 e um doutorado em Desenho e Engenharia Industrial pela Delft University of Technology.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 24], [25, 36], [36, 37], [38, 40], [41, 43], [44, 46], [47, 52], [53, 59], [60, 62], [63, 70], [71, 73], [74, 84], [85, 89], [90, 102], [103, 105], [106, 111], [112, 114], [115, 119], [120, 121], [122, 124], [125, 134], [135, 137], [138, 145], [146, 147], [148, 158], [159, 169], [170, 174], [175, 180], [181, 191], [192, 194], [195, 205], [205, 206]]}
{"doc_key": "ai-train-32", "ner": [[6, 7, "researcher"], [11, 12, "organisation"], [14, 14, "location"], [16, 16, "researcher"], [26, 27, "misc"], [41, 43, "misc"], [60, 61, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[6, 7, 11, 12, "physical", "", false, false], [6, 7, 11, 12, "role", "", false, false], [11, 12, 14, 14, "physical", "", false, false], [16, 16, 26, 27, "related-to", "works_with", true, false], [16, 16, 41, 43, "related-to", "works_with", true, false], [16, 16, 60, 61, "related-to", "works_with", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Com", "o", "colaborador", "de", "longa", "data", "Laurent", "Cohen", ",", "neurologista", "do", "Hospital", "Piti\u00e9-Salp\u00eatri\u00e8re", "em", "Paris", ",", "Dehaene", "tamb\u00e9m", "identificou", "pacientes", "com", "les\u00f5es", "em", "diferentes", "regi\u00f5es", "do", "lobo", "parietal", "com", "multiplica\u00e7\u00e3o", "deficiente", ",", "mas", "com", "subtra\u00e7\u00e3o", "preservada", "(", "associada", "a", "les\u00f5es", "do", "lobo", "parietal", "inferior", ")", "e", "outros", "com", "subtra\u00e7\u00e3o", "deficiente", ",", "mas", "com", "multiplica\u00e7\u00e3o", "preservada", "(", "associada", "a", "les\u00f5es", "do", "sulco", "intraparietal", ")", "."], "sentence-detokenized": "Com o colaborador de longa data Laurent Cohen, neurologista do Hospital Piti\u00e9-Salp\u00eatri\u00e8re em Paris, Dehaene tamb\u00e9m identificou pacientes com les\u00f5es em diferentes regi\u00f5es do lobo parietal com multiplica\u00e7\u00e3o deficiente, mas com subtra\u00e7\u00e3o preservada (associada a les\u00f5es do lobo parietal inferior) e outros com subtra\u00e7\u00e3o deficiente, mas com multiplica\u00e7\u00e3o preservada (associada a les\u00f5es do sulco intraparietal).", "token2charspan": [[0, 3], [4, 5], [6, 17], [18, 20], [21, 26], [27, 31], [32, 39], [40, 45], [45, 46], [47, 59], [60, 62], [63, 71], [72, 89], [90, 92], [93, 98], [98, 99], [100, 107], [108, 114], [115, 126], [127, 136], [137, 140], [141, 147], [148, 150], [151, 161], [162, 169], [170, 172], [173, 177], [178, 186], [187, 190], [191, 204], [205, 215], [215, 216], [217, 220], [221, 224], [225, 234], [235, 245], [246, 247], [247, 256], [257, 258], [259, 265], [266, 268], [269, 273], [274, 282], [283, 291], [291, 292], [293, 294], [295, 301], [302, 305], [306, 315], [316, 326], [326, 327], [328, 331], [332, 335], [336, 349], [350, 360], [361, 362], [362, 371], [372, 373], [374, 380], [381, 383], [384, 389], [390, 403], [403, 404], [404, 405]]}
{"doc_key": "ai-train-33", "ner": [[6, 8, "product"], [12, 15, "misc"], [17, 18, "misc"], [28, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 15, 6, 8, "topic", "", false, false], [17, 18, 6, 8, "topic", "", false, false], [28, 28, 6, 8, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Mais", "recentemente", ",", "representa\u00e7\u00f5es", "fict\u00edcias", "de", "rob\u00f4s", "artificialmente", "inteligentes", "em", "filmes", "como", "A.I", ".", "Artificial", "Intelligence", "e", "Ex", "Machina", "e", "a", "adapta\u00e7\u00e3o", "para", "a", "TV", "de", "2016", "do", "Westworld", "t\u00eam", "despertado", "a", "simpatia", "do", "p\u00fablico", "para", "os", "pr\u00f3prios", "rob\u00f4s", "."], "sentence-detokenized": "Mais recentemente, representa\u00e7\u00f5es fict\u00edcias de rob\u00f4s artificialmente inteligentes em filmes como A.I. Artificial Intelligence e Ex Machina e a adapta\u00e7\u00e3o para a TV de 2016 do Westworld t\u00eam despertado a simpatia do p\u00fablico para os pr\u00f3prios rob\u00f4s.", "token2charspan": [[0, 4], [5, 17], [17, 18], [19, 33], [34, 43], [44, 46], [47, 52], [53, 68], [69, 81], [82, 84], [85, 91], [92, 96], [97, 100], [100, 101], [102, 112], [113, 125], [126, 127], [128, 130], [131, 138], [139, 140], [141, 142], [143, 152], [153, 157], [158, 159], [160, 162], [163, 165], [166, 170], [171, 173], [174, 183], [184, 187], [188, 198], [199, 200], [201, 209], [210, 212], [213, 220], [221, 225], [226, 228], [229, 237], [238, 243], [243, 244]]}
{"doc_key": "ai-train-34", "ner": [[6, 8, "field"], [11, 14, "algorithm"], [17, 19, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 14, 6, 8, "part-of", "", false, false], [17, 19, 6, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Dois", "dos", "principais", "m\u00e9todos", "usados", "na", "aprendizagem", "n\u00e3o", "supervisionada", "s\u00e3o", "a", "an\u00e1lise", "de", "componentes", "principais", "e", "a", "an\u00e1lise", "de", "agrupamento", "."], "sentence-detokenized": "Dois dos principais m\u00e9todos usados na aprendizagem n\u00e3o supervisionada s\u00e3o a an\u00e1lise de componentes principais e a an\u00e1lise de agrupamento.", "token2charspan": [[0, 4], [5, 8], [9, 19], [20, 27], [28, 34], [35, 37], [38, 50], [51, 54], [55, 69], [70, 73], [74, 75], [76, 83], [84, 86], [87, 98], [99, 109], [110, 111], [112, 113], [114, 121], [122, 124], [125, 136], [136, 137]]}
{"doc_key": "ai-train-35", "ner": [[0, 3, "organisation"], [25, 26, "misc"], [31, 32, "misc"], [34, 36, "person"], [42, 43, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[25, 26, 0, 3, "artifact", "", false, false], [31, 32, 0, 3, "artifact", "", false, false], [31, 32, 34, 36, "role", "director_of", false, false], [31, 32, 42, 43, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "Walt", "Disney", "Company", "tamb\u00e9m", "iniciou", "o", "uso", "mais", "proeminente", "de", "filmes", "3D", "em", "locais", "especiais", "para", "impressionar", "o", "p\u00fablico", ",", "sendo", "exemplos", "not\u00e1veis", "as", "Magic", "Journeys", "(", "1982", ")", "e", "Captain", "EO", "(", "Francis", "Ford", "Coppola", ",", "1986", ",", "estrelado", "por", "Michael", "Jackson", ")", "."], "sentence-detokenized": "A Walt Disney Company tamb\u00e9m iniciou o uso mais proeminente de filmes 3D em locais especiais para impressionar o p\u00fablico, sendo exemplos not\u00e1veis as Magic Journeys (1982) e Captain EO (Francis Ford Coppola, 1986, estrelado por Michael Jackson).", "token2charspan": [[0, 1], [2, 6], [7, 13], [14, 21], [22, 28], [29, 36], [37, 38], [39, 42], [43, 47], [48, 59], [60, 62], [63, 69], [70, 72], [73, 75], [76, 82], [83, 92], [93, 97], [98, 110], [111, 112], [113, 120], [120, 121], [122, 127], [128, 136], [137, 145], [146, 148], [149, 154], [155, 163], [164, 165], [165, 169], [169, 170], [171, 172], [173, 180], [181, 183], [184, 185], [185, 192], [193, 197], [198, 205], [205, 206], [207, 211], [211, 212], [213, 222], [223, 226], [227, 234], [235, 242], [242, 243], [243, 244]]}
{"doc_key": "ai-train-36", "ner": [[12, 15, "field"], [20, 24, "task"], [27, 28, "task"], [30, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[20, 24, 12, 15, "part-of", "", false, false], [27, 28, 12, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Desde", "2002", ",", "o", "treinamento", "de", "perceptron", "tornou-se", "popular", "no", "campo", "do", "processamento", "de", "linguagem", "natural", "para", "tarefas", "como", "a", "etiquetagem", "de", "parte", "da", "fala", "e", "a", "an\u00e1lise", "sint\u00e1tica", "(", "Collins", ",", "2002", ")", "."], "sentence-detokenized": "Desde 2002, o treinamento de perceptron tornou-se popular no campo do processamento de linguagem natural para tarefas como a etiquetagem de parte da fala e a an\u00e1lise sint\u00e1tica (Collins, 2002).", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 13], [14, 25], [26, 28], [29, 39], [40, 49], [50, 57], [58, 60], [61, 66], [67, 69], [70, 83], [84, 86], [87, 96], [97, 104], [105, 109], [110, 117], [118, 122], [123, 124], [125, 136], [137, 139], [140, 145], [146, 148], [149, 153], [154, 155], [156, 157], [158, 165], [166, 175], [176, 177], [177, 184], [184, 185], [186, 190], [190, 191], [191, 192]]}
{"doc_key": "ai-train-37", "ner": [[2, 3, "product"], [9, 13, "organisation"], [15, 16, "organisation"], [18, 18, "country"], [22, 26, "product"], [30, 31, "researcher"], [41, 41, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 13, 2, 3, "role", "introduces_to_market", true, false], [15, 16, 2, 3, "role", "introduces_to_market", true, false], [15, 16, 18, 18, "physical", "", false, false], [22, 26, 41, 41, "related-to", "sold_to", true, false], [30, 31, 22, 26, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["O", "primeiro", "rob\u00f4", "paletizador", "foi", "introduzido", "em", "1963", "pela", "Fuji", "Yusoki", "Kogyo", "Company", ".", "pela", "rob\u00f3tica", "KUKA", "na", "Alemanha", ",", "e", "a", "M\u00e1quina", "Universal", "Program\u00e1vel", "para", "Montagem", "foi", "inventada", "por", "Victor", "Scheinman", "em", "1976", ",", "e", "o", "projeto", "foi", "vendido", "\u00e0", "Unimation", "."], "sentence-detokenized": "O primeiro rob\u00f4 paletizador foi introduzido em 1963 pela Fuji Yusoki Kogyo Company. pela rob\u00f3tica KUKA na Alemanha, e a M\u00e1quina Universal Program\u00e1vel para Montagem foi inventada por Victor Scheinman em 1976, e o projeto foi vendido \u00e0 Unimation.", "token2charspan": [[0, 1], [2, 10], [11, 15], [16, 27], [28, 31], [32, 43], [44, 46], [47, 51], [52, 56], [57, 61], [62, 68], [69, 74], [75, 82], [82, 83], [84, 88], [89, 97], [98, 102], [103, 105], [106, 114], [114, 115], [116, 117], [118, 119], [120, 127], [128, 137], [138, 149], [150, 154], [155, 163], [164, 167], [168, 177], [178, 181], [182, 188], [189, 198], [199, 201], [202, 206], [206, 207], [208, 209], [210, 211], [212, 219], [220, 223], [224, 231], [232, 233], [234, 243], [243, 244]]}
{"doc_key": "ai-train-38", "ner": [[11, 11, "conference"], [13, 13, "researcher"], [22, 22, "field"], [40, 41, "researcher"], [50, 51, "researcher"], [64, 64, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 13, 11, 11, "role", "president_of", false, false], [13, 13, 40, 41, "role", "colleagues", false, false], [22, 22, 64, 64, "named", "same", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Em", "meados", "dos", "anos", "90", ",", "enquanto", "servia", "como", "presidente", "da", "AAAI", ",", "Hayes", "iniciou", "uma", "s\u00e9rie", "de", "ataques", "aos", "cr\u00edticos", "da", "IA", ",", "na", "maioria", "das", "vezes", "formulados", "sob", "uma", "luz", "ir\u00f4nica", ",", "e", "(", "juntamente", "com", "seu", "colega", "Kenneth", "Ford", ")", "inventou", "um", "pr\u00eamio", "com", "o", "nome", "de", "Simon", "Newcomb", "para", "ser", "dado", "pelo", "argumento", "mais", "rid\u00edculo", "que", "refutava", "a", "possibilidade", "da", "IA", "."], "sentence-detokenized": "Em meados dos anos 90, enquanto servia como presidente da AAAI, Hayes iniciou uma s\u00e9rie de ataques aos cr\u00edticos da IA, na maioria das vezes formulados sob uma luz ir\u00f4nica, e (juntamente com seu colega Kenneth Ford) inventou um pr\u00eamio com o nome de Simon Newcomb para ser dado pelo argumento mais rid\u00edculo que refutava a possibilidade da IA.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 18], [19, 21], [21, 22], [23, 31], [32, 38], [39, 43], [44, 54], [55, 57], [58, 62], [62, 63], [64, 69], [70, 77], [78, 81], [82, 87], [88, 90], [91, 98], [99, 102], [103, 111], [112, 114], [115, 117], [117, 118], [119, 121], [122, 129], [130, 133], [134, 139], [140, 150], [151, 154], [155, 158], [159, 162], [163, 170], [170, 171], [172, 173], [174, 175], [175, 185], [186, 189], [190, 193], [194, 200], [201, 208], [209, 213], [213, 214], [215, 223], [224, 226], [227, 233], [234, 237], [238, 239], [240, 244], [245, 247], [248, 253], [254, 261], [262, 266], [267, 270], [271, 275], [276, 280], [281, 290], [291, 295], [296, 304], [305, 308], [309, 317], [318, 319], [320, 333], [334, 336], [337, 339], [339, 340]]}
{"doc_key": "ai-train-39", "ner": [[13, 17, "algorithm"], [41, 43, "algorithm"], [54, 58, "algorithm"], [61, 64, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 17, 41, 43, "named", "same", false, false], [54, 58, 13, 17, "type-of", "", false, false], [61, 64, 13, 17, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Um", "valor", "\u00f3timo", "para", "matem\u00e1tica", "alfa", "/", "matem\u00e1tica", "pode", "ser", "encontrado", "usando", "um", "algoritmo", "de", "busca", "de", "linha", ",", "ou", "seja", ",", "a", "magnitude", "da", "matem\u00e1tica", "alfa", "/", "matem\u00e1tica", "\u00e9", "determinada", "encontrando", "o", "valor", "que", "minimiza", "S", ",", "geralmente", "usando", "uma", "busca", "de", "linha", "no", "intervalo", "matem\u00e1tica", "0", "alfa", "1", "/", "matem\u00e1tica", "ou", "uma", "busca", "de", "linha", "de", "retaguarda", "como", "a", "busca", "de", "linha", "Armijo-line", "."], "sentence-detokenized": "Um valor \u00f3timo para matem\u00e1tica alfa / matem\u00e1tica pode ser encontrado usando um algoritmo de busca de linha, ou seja, a magnitude da matem\u00e1tica alfa / matem\u00e1tica \u00e9 determinada encontrando o valor que minimiza S, geralmente usando uma busca de linha no intervalo matem\u00e1tica 0 alfa 1 / matem\u00e1tica ou uma busca de linha de retaguarda como a busca de linha Armijo-line.", "token2charspan": [[0, 2], [3, 8], [9, 14], [15, 19], [20, 30], [31, 35], [36, 37], [38, 48], [49, 53], [54, 57], [58, 68], [69, 75], [76, 78], [79, 88], [89, 91], [92, 97], [98, 100], [101, 106], [106, 107], [108, 110], [111, 115], [115, 116], [117, 118], [119, 128], [129, 131], [132, 142], [143, 147], [148, 149], [150, 160], [161, 162], [163, 174], [175, 186], [187, 188], [189, 194], [195, 198], [199, 207], [208, 209], [209, 210], [211, 221], [222, 228], [229, 232], [233, 238], [239, 241], [242, 247], [248, 250], [251, 260], [261, 271], [272, 273], [274, 278], [279, 280], [281, 282], [283, 293], [294, 296], [297, 300], [301, 306], [307, 309], [310, 315], [316, 318], [319, 329], [330, 334], [335, 336], [337, 342], [343, 345], [346, 351], [352, 363], [363, 364]]}
{"doc_key": "ai-train-40", "ner": [[4, 5, "algorithm"], [7, 7, "algorithm"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ele", "discute", "t\u00e9cnicas", "de", "busca", "Breadth-first", "e", "Depth-first", ",", "mas", "eventualmente", "conclui", "que", "os", "resultados", "representam", "sistemas", "especializados", "que", "encarnam", "muito", "conhecimento", "t\u00e9cnico", ",", "mas", "que", "n\u00e3o", "iluminam", "muito", "os", "processos", "mentais", "que", "os", "humanos", "usam", "para", "resolver", "tais", "enigmas", "."], "sentence-detokenized": "Ele discute t\u00e9cnicas de busca Breadth-first e Depth-first, mas eventualmente conclui que os resultados representam sistemas especializados que encarnam muito conhecimento t\u00e9cnico, mas que n\u00e3o iluminam muito os processos mentais que os humanos usam para resolver tais enigmas.", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 23], [24, 29], [30, 43], [44, 45], [46, 57], [57, 58], [59, 62], [63, 76], [77, 84], [85, 88], [89, 91], [92, 102], [103, 114], [115, 123], [124, 138], [139, 142], [143, 151], [152, 157], [158, 170], [171, 178], [178, 179], [180, 183], [184, 187], [188, 191], [192, 200], [201, 206], [207, 209], [210, 219], [220, 227], [228, 231], [232, 234], [235, 242], [243, 247], [248, 252], [253, 261], [262, 266], [267, 274], [274, 275]]}
{"doc_key": "ai-train-41", "ner": [[0, 3, "task"], [6, 8, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["O", "reconhecimento", "da", "fala", "e", "a", "s\u00edntese", "da", "fala", "tratam", "de", "como", "a", "linguagem", "falada", "pode", "ser", "compreendida", "ou", "criada", "usando", "computadores", "."], "sentence-detokenized": "O reconhecimento da fala e a s\u00edntese da fala tratam de como a linguagem falada pode ser compreendida ou criada usando computadores.", "token2charspan": [[0, 1], [2, 16], [17, 19], [20, 24], [25, 26], [27, 28], [29, 36], [37, 39], [40, 44], [45, 51], [52, 54], [55, 59], [60, 61], [62, 71], [72, 78], [79, 83], [84, 87], [88, 100], [101, 103], [104, 110], [111, 117], [118, 130], [130, 131]]}
{"doc_key": "ai-train-42", "ner": [[14, 15, "algorithm"], [34, 36, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Esta", "matem\u00e1tica", "teta", "^", "^", "/", "matem\u00e1tica", "\u00e9", "normalmente", "estimada", "usando", "um", "procedimento", "de", "M\u00e1xima", "Probabilidade", "(", "matem\u00e1tica", "theta", "^", "^", "{", "*", "}", "==", "theta", "^", "{", "ML", "}", "/", "matem\u00e1tica", ")", "ou", "M\u00e1xima", "A", "Posteriori", "(", "matem\u00e1tica", "theta", "^", "{", "*", "}", "==", "theta", "^", "^", "{", "MAP", "}", "/", "matem\u00e1tica", ")", "."], "sentence-detokenized": "Esta matem\u00e1tica teta ^ ^ / matem\u00e1tica \u00e9 normalmente estimada usando um procedimento de M\u00e1xima Probabilidade (matem\u00e1tica theta ^ ^ {*} == theta ^ {ML} / matem\u00e1tica) ou M\u00e1xima A Posteriori (matem\u00e1tica theta ^ {*} == theta ^ ^ {MAP} / matem\u00e1tica).", "token2charspan": [[0, 4], [5, 15], [16, 20], [21, 22], [23, 24], [25, 26], [27, 37], [38, 39], [40, 51], [52, 60], [61, 67], [68, 70], [71, 83], [84, 86], [87, 93], [94, 107], [108, 109], [109, 119], [120, 125], [126, 127], [128, 129], [130, 131], [131, 132], [132, 133], [134, 136], [137, 142], [143, 144], [145, 146], [146, 148], [148, 149], [150, 151], [152, 162], [162, 163], [164, 166], [167, 173], [174, 175], [176, 186], [187, 188], [188, 198], [199, 204], [205, 206], [207, 208], [208, 209], [209, 210], [211, 213], [214, 219], [220, 221], [222, 223], [224, 225], [225, 228], [228, 229], [230, 231], [232, 242], [242, 243], [243, 244]]}
{"doc_key": "ai-train-43", "ner": [[6, 8, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Algumas", "l\u00ednguas", "menos", "faladas", "utilizam", "o", "sintetizador", "eSpeak", "de", "c\u00f3digo", "aberto", "para", "sua", "fala", ";", "produzindo", "uma", "voz", "rob\u00f3tica", "e", "inc\u00f4moda", "que", "pode", "ser", "dif\u00edcil", "de", "entender", "."], "sentence-detokenized": "Algumas l\u00ednguas menos faladas utilizam o sintetizador eSpeak de c\u00f3digo aberto para sua fala; produzindo uma voz rob\u00f3tica e inc\u00f4moda que pode ser dif\u00edcil de entender.", "token2charspan": [[0, 7], [8, 15], [16, 21], [22, 29], [30, 38], [39, 40], [41, 53], [54, 60], [61, 63], [64, 70], [71, 77], [78, 82], [83, 86], [87, 91], [91, 92], [93, 103], [104, 107], [108, 111], [112, 120], [121, 122], [123, 131], [132, 135], [136, 140], [141, 144], [145, 152], [153, 155], [156, 164], [164, 165]]}
{"doc_key": "ai-train-44", "ner": [[20, 20, "programlang"], [41, 42, "programlang"], [44, 44, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[20, 20, 41, 42, "compare", "", false, false], [20, 20, 44, 44, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Embora", "usado", "principalmente", "por", "estat\u00edsticos", "e", "outros", "profissionais", "que", "requerem", "um", "ambiente", "para", "computa\u00e7\u00e3o", "estat\u00edstica", "e", "desenvolvimento", "de", "software", ",", "R", "tamb\u00e9m", "pode", "operar", "como", "uma", "caixa", "de", "ferramentas", "de", "c\u00e1lculo", "de", "matriz", "geral", "-", "com", "padr\u00f5es", "de", "desempenho", "compar\u00e1veis", "ao", "GNU", "Octave", "ou", "MATLAB", "."], "sentence-detokenized": "Embora usado principalmente por estat\u00edsticos e outros profissionais que requerem um ambiente para computa\u00e7\u00e3o estat\u00edstica e desenvolvimento de software, R tamb\u00e9m pode operar como uma caixa de ferramentas de c\u00e1lculo de matriz geral - com padr\u00f5es de desempenho compar\u00e1veis ao GNU Octave ou MATLAB.", "token2charspan": [[0, 6], [7, 12], [13, 27], [28, 31], [32, 44], [45, 46], [47, 53], [54, 67], [68, 71], [72, 80], [81, 83], [84, 92], [93, 97], [98, 108], [109, 120], [121, 122], [123, 138], [139, 141], [142, 150], [150, 151], [152, 153], [154, 160], [161, 165], [166, 172], [173, 177], [178, 181], [182, 187], [188, 190], [191, 202], [203, 205], [206, 213], [214, 216], [217, 223], [224, 229], [230, 231], [232, 235], [236, 243], [244, 246], [247, 257], [258, 269], [270, 272], [273, 276], [277, 283], [284, 286], [287, 293], [293, 294]]}
{"doc_key": "ai-train-45", "ner": [[0, 0, "algorithm"], [5, 7, "field"], [10, 11, "misc"], [12, 13, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 7, "part-of", "", false, false], [0, 0, 12, 13, "origin", "", false, false], [10, 11, 12, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Heterodyning", "\u00e9", "uma", "t\u00e9cnica", "de", "processamento", "de", "sinais", "inventada", "pelo", "inventor-engenheiro", "canadense", "Reginald", "Fessenden", "que", "cria", "novas", "freq\u00fc\u00eancias", "ao", "combinar", "duas", "freq\u00fc\u00eancias", "."], "sentence-detokenized": "Heterodyning \u00e9 uma t\u00e9cnica de processamento de sinais inventada pelo inventor-engenheiro canadense Reginald Fessenden que cria novas freq\u00fc\u00eancias ao combinar duas freq\u00fc\u00eancias.", "token2charspan": [[0, 12], [13, 14], [15, 18], [19, 26], [27, 29], [30, 43], [44, 46], [47, 53], [54, 63], [64, 68], [69, 88], [89, 98], [99, 107], [108, 117], [118, 121], [122, 126], [127, 132], [133, 144], [145, 147], [148, 156], [157, 161], [162, 173], [173, 174]]}
{"doc_key": "ai-train-46", "ner": [[18, 19, "person"], [20, 20, "misc"], [24, 26, "organisation"], [34, 34, "organisation"], [30, 32, "misc"], [36, 37, "person"], [45, 45, "organisation"], [41, 44, "misc"], [47, 48, "person"], [50, 51, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[18, 19, 20, 20, "role", "actor_in", false, false], [20, 20, 24, 26, "artifact", "", false, false], [30, 32, 34, 34, "artifact", "", false, false], [36, 37, 30, 32, "role", "actor_in", false, false], [41, 44, 45, 45, "artifact", "", false, false], [47, 48, 41, 44, "role", "actor_in", false, false], [50, 51, 41, 44, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["V\u00e1rias", "outras", "caracter\u00edsticas", "que", "ajudaram", "a", "colocar", "o", "3D", "de", "volta", "no", "mapa", "naquele", "m\u00eas", "foram", "a", "caracter\u00edstica", "John", "Wayne", "Hondo", "(", "distribu\u00edda", "pela", "Warner", "Bros", ".", ")", ",", "a", "Miss", "Sadie", "Thompson", "da", "Columbia", "com", "Rita", "Hayworth", ",", "e", "o", "Money", "From", "Home", "da", "Paramount", "com", "Dean", "Martin", "e", "Jerry", "Lewis", "."], "sentence-detokenized": "V\u00e1rias outras caracter\u00edsticas que ajudaram a colocar o 3D de volta no mapa naquele m\u00eas foram a caracter\u00edstica John Wayne Hondo (distribu\u00edda pela Warner Bros. ), a Miss Sadie Thompson da Columbia com Rita Hayworth, e o Money From Home da Paramount com Dean Martin e Jerry Lewis.", "token2charspan": [[0, 6], [7, 13], [14, 29], [30, 33], [34, 42], [43, 44], [45, 52], [53, 54], [55, 57], [58, 60], [61, 66], [67, 69], [70, 74], [75, 82], [83, 86], [87, 92], [93, 94], [95, 109], [110, 114], [115, 120], [121, 126], [127, 128], [128, 139], [140, 144], [145, 151], [152, 156], [156, 157], [158, 159], [159, 160], [161, 162], [163, 167], [168, 173], [174, 182], [183, 185], [186, 194], [195, 198], [199, 203], [204, 212], [212, 213], [214, 215], [216, 217], [218, 223], [224, 228], [229, 233], [234, 236], [237, 246], [247, 250], [251, 255], [256, 262], [263, 264], [265, 270], [271, 276], [276, 277]]}
{"doc_key": "ai-train-47", "ner": [[0, 0, "product"], [8, 9, "field"], [5, 7, "task"], [17, 17, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 7, "general-affiliation", "", false, false], [0, 0, 17, 17, "artifact", "", false, false], [5, 7, 8, 9, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["DeepFace", "\u00e9", "um", "sistema", "de", "reconhecimento", "facial", "de", "aprendizagem", "profunda", "criado", "por", "um", "grupo", "de", "pesquisa", "no", "Facebook", "."], "sentence-detokenized": "DeepFace \u00e9 um sistema de reconhecimento facial de aprendizagem profunda criado por um grupo de pesquisa no Facebook.", "token2charspan": [[0, 8], [9, 10], [11, 13], [14, 21], [22, 24], [25, 39], [40, 46], [47, 49], [50, 62], [63, 71], [72, 78], [79, 82], [83, 85], [86, 91], [92, 94], [95, 103], [104, 106], [107, 115], [115, 116]]}
{"doc_key": "ai-train-48", "ner": [[0, 3, "field"], [11, 11, "conference"], [18, 19, "field"], [26, 31, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 18, 19, "part-of", "subfield", false, false], [11, 11, 0, 3, "topic", "", false, false], [26, 31, 0, 3, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["O", "processamento", "de", "geometria", "\u00e9", "um", "t\u00f3pico", "comum", "de", "pesquisa", "no", "SIGGRAPH", ",", "a", "principal", "confer\u00eancia", "acad\u00eamica", "de", "computa\u00e7\u00e3o", "gr\u00e1fica", ",", "e", "o", "principal", "t\u00f3pico", "do", "Simp\u00f3sio", "anual", "sobre", "Processamento", "de", "Geometria", "."], "sentence-detokenized": "O processamento de geometria \u00e9 um t\u00f3pico comum de pesquisa no SIGGRAPH, a principal confer\u00eancia acad\u00eamica de computa\u00e7\u00e3o gr\u00e1fica, e o principal t\u00f3pico do Simp\u00f3sio anual sobre Processamento de Geometria.", "token2charspan": [[0, 1], [2, 15], [16, 18], [19, 28], [29, 30], [31, 33], [34, 40], [41, 46], [47, 49], [50, 58], [59, 61], [62, 70], [70, 71], [72, 73], [74, 83], [84, 95], [96, 105], [106, 108], [109, 119], [120, 127], [127, 128], [129, 130], [131, 132], [133, 142], [143, 149], [150, 152], [153, 161], [162, 167], [168, 173], [174, 187], [188, 190], [191, 200], [200, 201]]}
{"doc_key": "ai-train-49", "ner": [[0, 3, "task"], [6, 8, "task"], [18, 21, "algorithm"], [23, 23, "algorithm"], [26, 28, "algorithm"], [30, 30, "algorithm"], [35, 38, "algorithm"], [40, 40, "algorithm"], [46, 46, "misc"], [52, 53, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[18, 21, 46, 46, "general-affiliation", "", false, false], [23, 23, 18, 21, "named", "", false, false], [26, 28, 46, 46, "general-affiliation", "", false, false], [30, 30, 26, 28, "named", "", false, false], [35, 38, 46, 46, "general-affiliation", "", false, false], [40, 40, 35, 38, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["A", "extra\u00e7\u00e3o", "de", "caracter\u00edsticas", "e", "a", "redu\u00e7\u00e3o", "de", "dimens\u00f5es", "podem", "ser", "combinadas", "em", "uma", "\u00fanica", "etapa", "usando", "a", "An\u00e1lise", "de", "Componentes", "Principais", "(", "PCA", ")", ",", "an\u00e1lise", "linear", "discriminante", "(", "LDA", ")", "ou", "t\u00e9cnicas", "de", "an\u00e1lise", "de", "correla\u00e7\u00e3o", "can\u00f4nica", "(", "CCA", ")", "como", "uma", "etapa", "de", "pr\u00e9-processamento", ",", "seguida", "de", "agrupamento", "por", "k", "-NN", "em", "vetores", "de", "caracter\u00edsticas", "em", "espa\u00e7o", "de", "dimens\u00f5es", "reduzidas", "."], "sentence-detokenized": "A extra\u00e7\u00e3o de caracter\u00edsticas e a redu\u00e7\u00e3o de dimens\u00f5es podem ser combinadas em uma \u00fanica etapa usando a An\u00e1lise de Componentes Principais (PCA), an\u00e1lise linear discriminante (LDA) ou t\u00e9cnicas de an\u00e1lise de correla\u00e7\u00e3o can\u00f4nica (CCA) como uma etapa de pr\u00e9-processamento, seguida de agrupamento por k -NN em vetores de caracter\u00edsticas em espa\u00e7o de dimens\u00f5es reduzidas.", "token2charspan": [[0, 1], [2, 10], [11, 13], [14, 29], [30, 31], [32, 33], [34, 41], [42, 44], [45, 54], [55, 60], [61, 64], [65, 75], [76, 78], [79, 82], [83, 88], [89, 94], [95, 101], [102, 103], [104, 111], [112, 114], [115, 126], [127, 137], [138, 139], [139, 142], [142, 143], [143, 144], [145, 152], [153, 159], [160, 173], [174, 175], [175, 178], [178, 179], [180, 182], [183, 191], [192, 194], [195, 202], [203, 205], [206, 216], [217, 225], [226, 227], [227, 230], [230, 231], [232, 236], [237, 240], [241, 246], [247, 249], [250, 267], [267, 268], [269, 276], [277, 279], [280, 291], [292, 295], [296, 297], [298, 301], [302, 304], [305, 312], [313, 315], [316, 331], [332, 334], [335, 341], [342, 344], [345, 354], [355, 364], [364, 365]]}
{"doc_key": "ai-train-50", "ner": [[0, 3, "algorithm"], [11, 13, "field"], [16, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 11, 13, "related-to", "good_at", true, false], [0, 3, 16, 18, "related-to", "good_at", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "redes", "neurais", "artificiais", "s\u00e3o", "modelos", "computacionais", "que", "se", "destacam", "na", "aprendizagem", "de", "m\u00e1quinas", "e", "no", "reconhecimento", "de", "padr\u00f5es", "."], "sentence-detokenized": "As redes neurais artificiais s\u00e3o modelos computacionais que se destacam na aprendizagem de m\u00e1quinas e no reconhecimento de padr\u00f5es.", "token2charspan": [[0, 2], [3, 8], [9, 16], [17, 28], [29, 32], [33, 40], [41, 55], [56, 59], [60, 62], [63, 71], [72, 74], [75, 87], [88, 90], [91, 99], [100, 101], [102, 104], [105, 119], [120, 122], [123, 130], [130, 131]]}
{"doc_key": "ai-train-51", "ner": [[0, 2, "researcher"], [4, 6, "researcher"], [8, 12, "misc"], [14, 18, "conference"], [20, 20, "conference"], [34, 37, "algorithm"], [38, 39, "researcher"], [41, 42, "researcher"], [44, 50, "misc"], [52, 61, "conference"], [63, 63, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[8, 12, 0, 2, "artifact", "", false, false], [8, 12, 4, 6, "artifact", "", false, false], [8, 12, 14, 18, "temporal", "", false, false], [20, 20, 14, 18, "named", "", false, false], [44, 50, 34, 37, "topic", "", false, false], [44, 50, 38, 39, "artifact", "", false, false], [44, 50, 41, 42, "artifact", "", false, false], [44, 50, 52, 61, "temporal", "", false, false], [63, 63, 52, 61, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["C", ".", "Papageorgiou", "e", "T", ".", "Poggio", ",", "A", "Trainable", "Pedestrian", "Detection", "system", ",", "International", "Journal", "of", "Computer", "Vision", "(", "IJCV", ")", ",", "p\u00e1ginas", "1", ":", "15-33", ",", "2000", "outros", "usam", "caracter\u00edsticas", "locais", "como", "histograma", "de", "gradientes", "orientados", "N.", "Dalal", ",", "B.", "Triggs", ",", "Histograms", "of", "oriented", "gradients", "for", "human", "detection", ",", "IEEE", "Computer", "Society", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", ",", "p\u00e1ginas", "1", ":", "886-893", ",", "2005", "descriptors", "."], "sentence-detokenized": "C. Papageorgiou e T. Poggio, A Trainable Pedestrian Detection system, International Journal of Computer Vision (IJCV), p\u00e1ginas 1: 15-33, 2000 outros usam caracter\u00edsticas locais como histograma de gradientes orientados N. Dalal, B. Triggs, Histograms of oriented gradients for human detection, IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), p\u00e1ginas 1: 886-893, 2005 descriptors.", "token2charspan": [[0, 1], [1, 2], [3, 15], [16, 17], [18, 19], [19, 20], [21, 27], [27, 28], [29, 30], [31, 40], [41, 51], [52, 61], [62, 68], [68, 69], [70, 83], [84, 91], [92, 94], [95, 103], [104, 110], [111, 112], [112, 116], [116, 117], [117, 118], [119, 126], [127, 128], [128, 129], [130, 135], [135, 136], [137, 141], [142, 148], [149, 153], [154, 169], [170, 176], [177, 181], [182, 192], [193, 195], [196, 206], [207, 217], [218, 220], [221, 226], [226, 227], [228, 230], [231, 237], [237, 238], [239, 249], [250, 252], [253, 261], [262, 271], [272, 275], [276, 281], [282, 291], [291, 292], [293, 297], [298, 306], [307, 314], [315, 325], [326, 328], [329, 337], [338, 344], [345, 348], [349, 356], [357, 368], [369, 370], [370, 374], [374, 375], [375, 376], [377, 384], [385, 386], [386, 387], [388, 395], [395, 396], [397, 401], [402, 413], [413, 414]]}
{"doc_key": "ai-train-52", "ner": [[1, 1, "algorithm"], [6, 8, "algorithm"], [12, 14, "task"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 6, 8, "type-of", "", false, false], [12, 14, 1, 1, "usage", "", true, false], [12, 14, 18, 19, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Um", "autocodificador", "\u00e9", "um", "tipo", "de", "rede", "neural", "artificial", "usado", "para", "aprender", "Aprendizagem", "de", "recursos", "de", "uma", "forma", "n\u00e3o", "supervisionada", "."], "sentence-detokenized": "Um autocodificador \u00e9 um tipo de rede neural artificial usado para aprender Aprendizagem de recursos de uma forma n\u00e3o supervisionada.", "token2charspan": [[0, 2], [3, 18], [19, 20], [21, 23], [24, 28], [29, 31], [32, 36], [37, 43], [44, 54], [55, 60], [61, 65], [66, 74], [75, 87], [88, 90], [91, 99], [100, 102], [103, 106], [107, 112], [113, 116], [117, 131], [131, 132]]}
{"doc_key": "ai-train-53", "ner": [[0, 0, "researcher"], [5, 5, "organisation"], [10, 11, "field"], [13, 15, "field"], [20, 26, "organisation"], [28, 28, "organisation"], [34, 36, "field"], [38, 40, "field"], [46, 46, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 5, 5, "role", "fellow_of", false, false], [0, 0, 10, 11, "related-to", "contributes_to", false, false], [0, 0, 13, 15, "related-to", "contributes_to", false, false], [0, 0, 20, 26, "role", "fellow_of", false, false], [0, 0, 34, 36, "related-to", "contributes_to", false, false], [0, 0, 38, 40, "related-to", "contributes_to", false, false], [28, 28, 20, 26, "named", "", false, false], [46, 46, 20, 26, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Haralick", "\u00e9", "um", "Fellow", "do", "IEEE", "por", "suas", "contribui\u00e7\u00f5es", "em", "vis\u00e3o", "computadorizada", "e", "processamento", "de", "imagem", "e", "um", "Fellow", "da", "Associa\u00e7\u00e3o", "Internacional", "para", "o", "Reconhecimento", "de", "Padr\u00f5es", "(", "IAPR", ")", "por", "suas", "contribui\u00e7\u00f5es", "em", "reconhecimento", "de", "padr\u00f5es", ",", "processamento", "de", "imagem", ",", "e", "pelo", "servi\u00e7o", "ao", "IAPR", "."], "sentence-detokenized": "Haralick \u00e9 um Fellow do IEEE por suas contribui\u00e7\u00f5es em vis\u00e3o computadorizada e processamento de imagem e um Fellow da Associa\u00e7\u00e3o Internacional para o Reconhecimento de Padr\u00f5es (IAPR) por suas contribui\u00e7\u00f5es em reconhecimento de padr\u00f5es, processamento de imagem, e pelo servi\u00e7o ao IAPR.", "token2charspan": [[0, 8], [9, 10], [11, 13], [14, 20], [21, 23], [24, 28], [29, 32], [33, 37], [38, 51], [52, 54], [55, 60], [61, 76], [77, 78], [79, 92], [93, 95], [96, 102], [103, 104], [105, 107], [108, 114], [115, 117], [118, 128], [129, 142], [143, 147], [148, 149], [150, 164], [165, 167], [168, 175], [176, 177], [177, 181], [181, 182], [183, 186], [187, 191], [192, 205], [206, 208], [209, 223], [224, 226], [227, 234], [234, 235], [236, 249], [250, 252], [253, 259], [259, 260], [261, 262], [263, 267], [268, 275], [276, 278], [279, 283], [283, 284]]}
{"doc_key": "ai-train-54", "ner": [[4, 8, "task"], [15, 17, "algorithm"], [19, 19, "algorithm"], [23, 24, "researcher"], [26, 27, "organisation"], [29, 30, "researcher"], [32, 34, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 8, 15, 17, "usage", "", false, false], [15, 17, 23, 24, "origin", "", true, false], [15, 17, 29, 30, "origin", "", true, false], [19, 19, 15, 17, "named", "", false, false], [23, 24, 26, 27, "physical", "", false, false], [23, 24, 26, 27, "role", "", false, false], [29, 30, 32, 34, "physical", "", false, false], [29, 30, 32, 34, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["A", "primeira", "tentativa", "de", "ASR", "de", "ponta", "a", "ponta", "foi", "com", "os", "sistemas", "baseados", "na", "Classifica\u00e7\u00e3o", "Temporal", "Connectionist", "(", "CTC", ")", "introduzidos", "por", "Alex", "Graves", "do", "Google", "DeepMind", "e", "Navdeep", "Jaitly", "da", "Universidade", "de", "Toronto", "em", "2014", "."], "sentence-detokenized": "A primeira tentativa de ASR de ponta a ponta foi com os sistemas baseados na Classifica\u00e7\u00e3o Temporal Connectionist (CTC) introduzidos por Alex Graves do Google DeepMind e Navdeep Jaitly da Universidade de Toronto em 2014.", "token2charspan": [[0, 1], [2, 10], [11, 20], [21, 23], [24, 27], [28, 30], [31, 36], [37, 38], [39, 44], [45, 48], [49, 52], [53, 55], [56, 64], [65, 73], [74, 76], [77, 90], [91, 99], [100, 113], [114, 115], [115, 118], [118, 119], [120, 132], [133, 136], [137, 141], [142, 148], [149, 151], [152, 158], [159, 167], [168, 169], [170, 177], [178, 184], [185, 187], [188, 200], [201, 203], [204, 211], [212, 214], [215, 219], [219, 220]]}
{"doc_key": "ai-train-55", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [10, 11, "algorithm"], [13, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 0, 2, "named", "", false, false], [10, 11, 0, 2, "type-of", "", false, false], [13, 13, 10, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "programa\u00e7\u00e3o", "linear-fracional", "(", "LFP", ")", "\u00e9", "uma", "generaliza\u00e7\u00e3o", "da", "programa\u00e7\u00e3o", "linear", "(", "LP", ")", "."], "sentence-detokenized": "A programa\u00e7\u00e3o linear-fracional (LFP) \u00e9 uma generaliza\u00e7\u00e3o da programa\u00e7\u00e3o linear (LP).", "token2charspan": [[0, 1], [2, 13], [14, 30], [31, 32], [32, 35], [35, 36], [37, 38], [39, 42], [43, 56], [57, 59], [60, 71], [72, 78], [79, 80], [80, 82], [82, 83], [83, 84]]}
{"doc_key": "ai-train-56", "ner": [[0, 0, "researcher"], [7, 8, "misc"], [10, 18, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 7, 8, "win-defeat", "", false, false], [7, 8, 10, 18, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lafferty", "recebeu", "in\u00fameros", "pr\u00eamios", ",", "incluindo", "dois", "pr\u00eamios", "Test-of-Time", "na", "Confer\u00eancia", "Internacional", "sobre", "Aprendizagem", "de", "M\u00e1quinas", "2011", "&", "2012", ","], "sentence-detokenized": "Lafferty recebeu in\u00fameros pr\u00eamios, incluindo dois pr\u00eamios Test-of-Time na Confer\u00eancia Internacional sobre Aprendizagem de M\u00e1quinas 2011 & 2012,", "token2charspan": [[0, 8], [9, 16], [17, 25], [26, 33], [33, 34], [35, 44], [45, 49], [50, 57], [58, 70], [71, 73], [74, 85], [86, 99], [100, 105], [106, 118], [119, 121], [122, 130], [131, 135], [136, 137], [138, 142], [142, 143]]}
{"doc_key": "ai-train-57", "ner": [[9, 9, "product"], [11, 11, "programlang"], [25, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Com", "o", "advento", "de", "estruturas", "baseadas", "em", "componentes", "como", ".NET", "e", "Java", ",", "os", "ambientes", "de", "desenvolvimento", "baseados", "em", "componentes", "s\u00e3o", "capazes", "de", "implantar", "a", "rede", "neural", "desenvolvida", "para", "essas", "estruturas", "como", "componentes", "heredit\u00e1rios", "."], "sentence-detokenized": "Com o advento de estruturas baseadas em componentes como .NET e Java, os ambientes de desenvolvimento baseados em componentes s\u00e3o capazes de implantar a rede neural desenvolvida para essas estruturas como componentes heredit\u00e1rios.", "token2charspan": [[0, 3], [4, 5], [6, 13], [14, 16], [17, 27], [28, 36], [37, 39], [40, 51], [52, 56], [57, 61], [62, 63], [64, 68], [68, 69], [70, 72], [73, 82], [83, 85], [86, 101], [102, 110], [111, 113], [114, 125], [126, 129], [130, 137], [138, 140], [141, 150], [151, 152], [153, 157], [158, 164], [165, 177], [178, 182], [183, 188], [189, 199], [200, 204], [205, 216], [217, 229], [229, 230]]}
{"doc_key": "ai-train-58", "ner": [[2, 2, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Como", "no", "BLEU", ",", "a", "unidade", "b\u00e1sica", "de", "avalia\u00e7\u00e3o", "\u00e9", "a", "frase", ",", "o", "algoritmo", "primeiro", "cria", "um", "alinhamento", "(", "veja", "ilustra\u00e7\u00f5es", ")", "entre", "duas", "frases", ",", "a", "cadeia", "de", "tradu\u00e7\u00e3o", "candidata", ",", "e", "a", "cadeia", "de", "tradu\u00e7\u00e3o", "de", "refer\u00eancia", "."], "sentence-detokenized": "Como no BLEU, a unidade b\u00e1sica de avalia\u00e7\u00e3o \u00e9 a frase, o algoritmo primeiro cria um alinhamento (veja ilustra\u00e7\u00f5es) entre duas frases, a cadeia de tradu\u00e7\u00e3o candidata, e a cadeia de tradu\u00e7\u00e3o de refer\u00eancia.", "token2charspan": [[0, 4], [5, 7], [8, 12], [12, 13], [14, 15], [16, 23], [24, 30], [31, 33], [34, 43], [44, 45], [46, 47], [48, 53], [53, 54], [55, 56], [57, 66], [67, 75], [76, 80], [81, 83], [84, 95], [96, 97], [97, 101], [102, 113], [113, 114], [115, 120], [121, 125], [126, 132], [132, 133], [134, 135], [136, 142], [143, 145], [146, 154], [155, 164], [164, 165], [166, 167], [168, 169], [170, 176], [177, 179], [180, 188], [189, 191], [192, 202], [202, 203]]}
{"doc_key": "ai-train-59", "ner": [[5, 12, "conference"], [26, 26, "task"], [24, 29, "task"], [33, 34, "metrics"], [36, 40, "metrics"], [45, 48, "conference"], [50, 50, "conference"], [53, 53, "location"], [55, 55, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 12, 26, 26, "related-to", "subject_at", false, false], [5, 12, 24, 29, "related-to", "subject_at", false, false], [33, 34, 5, 12, "temporal", "", false, false], [36, 40, 33, 34, "named", "", true, false], [50, 50, 45, 48, "named", "", false, false], [53, 53, 55, 55, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Uma", "das", "m\u00e9tricas", "utilizadas", "nas", "Confer\u00eancias", "anuais", "de", "Entendimento", "de", "Documentos", "do", "NIST", ",", "nas", "quais", "grupos", "de", "pesquisa", "submetem", "seus", "sistemas", "tanto", "para", "tarefas", "de", "resumo", "como", "de", "tradu\u00e7\u00e3o", ",", "\u00e9", "a", "m\u00e9trica", "ROUGE", "(", "Recall-Oriented", "Understudy", "for", "Gisting", "Evaluation", ",", "In", "Advances", "of", "Neural", "Information", "Processing", "Systems", "(", "NIPS", ")", ",", "Montreal", ",", "Canad\u00e1", ",", "dezembro", "-", "2014", "."], "sentence-detokenized": "Uma das m\u00e9tricas utilizadas nas Confer\u00eancias anuais de Entendimento de Documentos do NIST, nas quais grupos de pesquisa submetem seus sistemas tanto para tarefas de resumo como de tradu\u00e7\u00e3o, \u00e9 a m\u00e9trica ROUGE (Recall-Oriented Understudy for Gisting Evaluation, In Advances of Neural Information Processing Systems (NIPS), Montreal, Canad\u00e1, dezembro - 2014.", "token2charspan": [[0, 3], [4, 7], [8, 16], [17, 27], [28, 31], [32, 44], [45, 51], [52, 54], [55, 67], [68, 70], [71, 81], [82, 84], [85, 89], [89, 90], [91, 94], [95, 100], [101, 107], [108, 110], [111, 119], [120, 128], [129, 133], [134, 142], [143, 148], [149, 153], [154, 161], [162, 164], [165, 171], [172, 176], [177, 179], [180, 188], [188, 189], [190, 191], [192, 193], [194, 201], [202, 207], [208, 209], [209, 224], [225, 235], [236, 239], [240, 247], [248, 258], [258, 259], [260, 262], [263, 271], [272, 274], [275, 281], [282, 293], [294, 304], [305, 312], [313, 314], [314, 318], [318, 319], [319, 320], [321, 329], [329, 330], [331, 337], [337, 338], [339, 347], [348, 349], [350, 354], [354, 355]]}
{"doc_key": "ai-train-60", "ner": [[7, 7, "programlang"], [9, 9, "product"], [11, 12, "programlang"], [16, 16, "product"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 7, 11, 12, "type-of", "", false, false], [7, 7, 22, 22, "named", "", false, false], [9, 9, 11, 12, "part-of", "", false, false], [9, 9, 16, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "mesma", "implementa\u00e7\u00e3o", ",", "para", "rodar", "em", "Java", "com", "JShell", "(", "Java", "9", "m\u00ednimo", ")", ":", "codejshell", "scriptfile", "/", "codesyntaxhighlight", "lang", "=", "java"], "sentence-detokenized": "A mesma implementa\u00e7\u00e3o, para rodar em Java com JShell (Java 9 m\u00ednimo): codejshell scriptfile / codesyntaxhighlight lang = java", "token2charspan": [[0, 1], [2, 7], [8, 21], [21, 22], [23, 27], [28, 33], [34, 36], [37, 41], [42, 45], [46, 52], [53, 54], [54, 58], [59, 60], [61, 67], [67, 68], [68, 69], [70, 80], [81, 91], [92, 93], [94, 113], [114, 118], [119, 120], [121, 125]]}
{"doc_key": "ai-train-61", "ner": [[1, 2, "metrics"], [6, 7, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 6, 7, "origin", "based_on", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "m\u00e9trica", "NIST", "\u00e9", "baseada", "na", "m\u00e9trica", "BLEU", ",", "mas", "com", "algumas", "altera\u00e7\u00f5es", "."], "sentence-detokenized": "A m\u00e9trica NIST \u00e9 baseada na m\u00e9trica BLEU, mas com algumas altera\u00e7\u00f5es.", "token2charspan": [[0, 1], [2, 9], [10, 14], [15, 16], [17, 24], [25, 27], [28, 35], [36, 40], [40, 41], [42, 45], [46, 49], [50, 57], [58, 68], [68, 69]]}
{"doc_key": "ai-train-62", "ner": [[8, 8, "country"], [10, 12, "university"], [14, 16, "university"], [23, 25, "product"], [29, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 12, 8, 8, "physical", "", false, false], [14, 16, 8, 8, "physical", "", false, false], [23, 25, 10, 12, "origin", "", false, false], [23, 25, 14, 16, "origin", "", false, false], [23, 25, 29, 30, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["No", "final", "dos", "anos", "80", ",", "duas", "universidades", "holandesas", ",", "Universidade", "de", "Groningen", "e", "Universidade", "de", "Twente", ",", "iniciaram", "conjuntamente", "um", "projeto", "chamado", "Gr\u00e1ficos", "do", "Conhecimento", ",", "que", "s\u00e3o", "redes", "sem\u00e2nticas", ",", "mas", "com", "a", "restri\u00e7\u00e3o", "adicional", "de", "que", "as", "bordas", "s\u00e3o", "restritas", "a", "ser", "de", "um", "conjunto", "limitado", "de", "rela\u00e7\u00f5es", "poss\u00edveis", ",", "para", "facilitar", "as", "algebras", "no", "gr\u00e1fico", "."], "sentence-detokenized": "No final dos anos 80, duas universidades holandesas, Universidade de Groningen e Universidade de Twente, iniciaram conjuntamente um projeto chamado Gr\u00e1ficos do Conhecimento, que s\u00e3o redes sem\u00e2nticas, mas com a restri\u00e7\u00e3o adicional de que as bordas s\u00e3o restritas a ser de um conjunto limitado de rela\u00e7\u00f5es poss\u00edveis, para facilitar as algebras no gr\u00e1fico.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 17], [18, 20], [20, 21], [22, 26], [27, 40], [41, 51], [51, 52], [53, 65], [66, 68], [69, 78], [79, 80], [81, 93], [94, 96], [97, 103], [103, 104], [105, 114], [115, 128], [129, 131], [132, 139], [140, 147], [148, 156], [157, 159], [160, 172], [172, 173], [174, 177], [178, 181], [182, 187], [188, 198], [198, 199], [200, 203], [204, 207], [208, 209], [210, 219], [220, 229], [230, 232], [233, 236], [237, 239], [240, 246], [247, 250], [251, 260], [261, 262], [263, 266], [267, 269], [270, 272], [273, 281], [282, 290], [291, 293], [294, 302], [303, 312], [312, 313], [314, 318], [319, 328], [329, 331], [332, 340], [341, 343], [344, 351], [351, 352]]}
{"doc_key": "ai-train-63", "ner": [[0, 2, "product"], [17, 19, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 17, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Os", "verificadores", "gramaticais", "s\u00e3o", "mais", "freq\u00fcentemente", "implementados", "como", "uma", "caracter\u00edstica", "de", "um", "programa", "maior", ",", "como", "um", "processador", "de", "texto", ",", "mas", "tamb\u00e9m", "est\u00e3o", "dispon\u00edveis", "como", "uma", "aplica\u00e7\u00e3o", "independente", "que", "pode", "ser", "ativada", "de", "dentro", "de", "programas", "que", "funcionam", "com", "texto", "edit\u00e1vel", "."], "sentence-detokenized": "Os verificadores gramaticais s\u00e3o mais freq\u00fcentemente implementados como uma caracter\u00edstica de um programa maior, como um processador de texto, mas tamb\u00e9m est\u00e3o dispon\u00edveis como uma aplica\u00e7\u00e3o independente que pode ser ativada de dentro de programas que funcionam com texto edit\u00e1vel.", "token2charspan": [[0, 2], [3, 16], [17, 28], [29, 32], [33, 37], [38, 52], [53, 66], [67, 71], [72, 75], [76, 90], [91, 93], [94, 96], [97, 105], [106, 111], [111, 112], [113, 117], [118, 120], [121, 132], [133, 135], [136, 141], [141, 142], [143, 146], [147, 153], [154, 159], [160, 171], [172, 176], [177, 180], [181, 190], [191, 203], [204, 207], [208, 212], [213, 216], [217, 224], [225, 227], [228, 234], [235, 237], [238, 247], [248, 251], [252, 261], [262, 265], [266, 271], [272, 280], [280, 281]]}
{"doc_key": "ai-train-64", "ner": [[4, 10, "organisation"], [12, 18, "conference"], [20, 23, "organisation"], [28, 30, "conference"], [32, 34, "conference"], [36, 38, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ele", "\u00e9", "membro", "da", "Associa\u00e7\u00e3o", "Americana", "para", "o", "Progresso", "da", "Ci\u00eancia", ",", "Associa\u00e7\u00e3o", "para", "o", "Progresso", "da", "Intelig\u00eancia", "Artificial", "e", "Sociedade", "de", "Ci\u00eancia", "Cognitiva", ",", "e", "editor", "da", "J.", "Automated", "Reasoning", ",", "J.", "Learning", "Sciences", "e", "J.", "Applied", "Ontology", "."], "sentence-detokenized": "Ele \u00e9 membro da Associa\u00e7\u00e3o Americana para o Progresso da Ci\u00eancia, Associa\u00e7\u00e3o para o Progresso da Intelig\u00eancia Artificial e Sociedade de Ci\u00eancia Cognitiva, e editor da J. Automated Reasoning, J. Learning Sciences e J. Applied Ontology.", "token2charspan": [[0, 3], [4, 5], [6, 12], [13, 15], [16, 26], [27, 36], [37, 41], [42, 43], [44, 53], [54, 56], [57, 64], [64, 65], [66, 76], [77, 81], [82, 83], [84, 93], [94, 96], [97, 109], [110, 120], [121, 122], [123, 132], [133, 135], [136, 143], [144, 153], [153, 154], [155, 156], [157, 163], [164, 166], [167, 169], [170, 179], [180, 189], [189, 190], [191, 193], [194, 202], [203, 211], [212, 213], [214, 216], [217, 224], [225, 233], [233, 234]]}
{"doc_key": "ai-train-65", "ner": [[0, 3, "algorithm"], [5, 5, "algorithm"], [11, 13, "task"], [22, 23, "researcher"], [25, 27, "university"], [29, 30, "researcher"], [32, 35, "organisation"], [37, 37, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 3, 11, 13, "type-of", "", false, false], [0, 3, 22, 23, "origin", "", false, false], [0, 3, 29, 30, "origin", "", false, false], [5, 5, 0, 3, "named", "", false, false], [22, 23, 25, 27, "physical", "", false, false], [22, 23, 25, 27, "role", "", false, false], [29, 30, 32, 35, "role", "", false, false], [37, 37, 32, 35, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["A", "codifica\u00e7\u00e3o", "preditiva", "linear", "(", "LPC", ")", ",", "uma", "forma", "de", "codifica\u00e7\u00e3o", "de", "fala", ",", "come\u00e7ou", "a", "ser", "desenvolvida", "com", "o", "trabalho", "Fumitada", "Itakura", "da", "Universidade", "de", "Nagoya", "e", "Shuzo", "Saito", "da", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "em", "1966", "."], "sentence-detokenized": "A codifica\u00e7\u00e3o preditiva linear (LPC), uma forma de codifica\u00e7\u00e3o de fala, come\u00e7ou a ser desenvolvida com o trabalho Fumitada Itakura da Universidade de Nagoya e Shuzo Saito da Nippon Telegraph and Telephone (NTT) em 1966.", "token2charspan": [[0, 1], [2, 13], [14, 23], [24, 30], [31, 32], [32, 35], [35, 36], [36, 37], [38, 41], [42, 47], [48, 50], [51, 62], [63, 65], [66, 70], [70, 71], [72, 79], [80, 81], [82, 85], [86, 98], [99, 102], [103, 104], [105, 113], [114, 122], [123, 130], [131, 133], [134, 146], [147, 149], [150, 156], [157, 158], [159, 164], [165, 170], [171, 173], [174, 180], [181, 190], [191, 194], [195, 204], [205, 206], [206, 209], [209, 210], [211, 213], [214, 218], [218, 219]]}
{"doc_key": "ai-train-66", "ner": [[60, 62, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Se", "o", "sinal", "for", "mais", "erg\u00f3dico", ",", "todos", "os", "caminhos", "de", "amostra", "exibem", "a", "mesma", "m\u00e9dia", "de", "tempo", "e", ",", "portanto", ",", "matem\u00e1tica", "_", "x", "^", "{", "n", "/", "T", "_", "0", "}", "(", "tau", ")", "=", "}", "widehat", "{", "R", "}", "_", "x", "^", "{", "n", "/", "T", "_", "0", "}", "(", "tau", ")", "/", "matem\u00e1tica", "em", "sentido", "de", "erro", "quadr\u00e1tico", "m\u00e9dio", "."], "sentence-detokenized": "Se o sinal for mais erg\u00f3dico, todos os caminhos de amostra exibem a mesma m\u00e9dia de tempo e, portanto, matem\u00e1tica _ x ^ {n / T _ 0} (tau) =} widehat {R} _ x ^ {n / T _ 0} (tau) / matem\u00e1tica em sentido de erro quadr\u00e1tico m\u00e9dio.", "token2charspan": [[0, 2], [3, 4], [5, 10], [11, 14], [15, 19], [20, 28], [28, 29], [30, 35], [36, 38], [39, 47], [48, 50], [51, 58], [59, 65], [66, 67], [68, 73], [74, 79], [80, 82], [83, 88], [89, 90], [90, 91], [92, 100], [100, 101], [102, 112], [113, 114], [115, 116], [117, 118], [119, 120], [120, 121], [122, 123], [124, 125], [126, 127], [128, 129], [129, 130], [131, 132], [132, 135], [135, 136], [137, 138], [138, 139], [140, 147], [148, 149], [149, 150], [150, 151], [152, 153], [154, 155], [156, 157], [158, 159], [159, 160], [161, 162], [163, 164], [165, 166], [167, 168], [168, 169], [170, 171], [171, 174], [174, 175], [176, 177], [178, 188], [189, 191], [192, 199], [200, 202], [203, 207], [208, 218], [219, 224], [224, 225]]}
{"doc_key": "ai-train-67", "ner": [[0, 3, "task"], [6, 8, "task"], [17, 20, "algorithm"], [22, 22, "algorithm"], [25, 27, "algorithm"], [29, 29, "algorithm"], [32, 35, "algorithm"], [37, 37, "algorithm"], [42, 46, "algorithm"], [48, 48, "algorithm"], [52, 54, "misc"], [59, 59, "algorithm"], [61, 63, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[17, 20, 52, 54, "related-to", "", false, false], [22, 22, 17, 20, "named", "", false, false], [25, 27, 52, 54, "related-to", "", false, false], [29, 29, 25, 27, "named", "", false, false], [32, 35, 52, 54, "related-to", "", false, false], [37, 37, 32, 35, "named", "", false, false], [42, 46, 52, 54, "related-to", "", false, false], [48, 48, 42, 46, "named", "", false, false], [59, 59, 61, 63, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["A", "extra\u00e7\u00e3o", "de", "caracter\u00edsticas", "e", "a", "redu\u00e7\u00e3o", "de", "dimens\u00f5es", "podem", "ser", "combinadas", "em", "uma", "\u00fanica", "etapa", "usando", "an\u00e1lise", "de", "componentes", "principais", "(", "PCA", ")", ",", "an\u00e1lise", "linear", "discriminante", "(", "LDA", ")", ",", "an\u00e1lise", "de", "correla\u00e7\u00e3o", "can\u00f4nica", "(", "CCA", ")", "ou", "t\u00e9cnicas", "de", "factoriza\u00e7\u00e3o", "de", "matriz", "n\u00e3o", "negativa", "(", "NMF", ")", "como", "uma", "etapa", "de", "pr\u00e9-processamento", "seguida", "de", "agrupamento", "por", "K-NN", "em", "vetores", "de", "caracter\u00edsticas", "em", "espa\u00e7o", "de", "dimens\u00f5es", "reduzidas", "."], "sentence-detokenized": "A extra\u00e7\u00e3o de caracter\u00edsticas e a redu\u00e7\u00e3o de dimens\u00f5es podem ser combinadas em uma \u00fanica etapa usando an\u00e1lise de componentes principais (PCA), an\u00e1lise linear discriminante (LDA), an\u00e1lise de correla\u00e7\u00e3o can\u00f4nica (CCA) ou t\u00e9cnicas de factoriza\u00e7\u00e3o de matriz n\u00e3o negativa (NMF) como uma etapa de pr\u00e9-processamento seguida de agrupamento por K-NN em vetores de caracter\u00edsticas em espa\u00e7o de dimens\u00f5es reduzidas.", "token2charspan": [[0, 1], [2, 10], [11, 13], [14, 29], [30, 31], [32, 33], [34, 41], [42, 44], [45, 54], [55, 60], [61, 64], [65, 75], [76, 78], [79, 82], [83, 88], [89, 94], [95, 101], [102, 109], [110, 112], [113, 124], [125, 135], [136, 137], [137, 140], [140, 141], [141, 142], [143, 150], [151, 157], [158, 171], [172, 173], [173, 176], [176, 177], [177, 178], [179, 186], [187, 189], [190, 200], [201, 209], [210, 211], [211, 214], [214, 215], [216, 218], [219, 227], [228, 230], [231, 243], [244, 246], [247, 253], [254, 257], [258, 266], [267, 268], [268, 271], [271, 272], [273, 277], [278, 281], [282, 287], [288, 290], [291, 308], [309, 316], [317, 319], [320, 331], [332, 335], [336, 340], [341, 343], [344, 351], [352, 354], [355, 370], [371, 373], [374, 380], [381, 383], [384, 393], [394, 403], [403, 404]]}
{"doc_key": "ai-train-68", "ner": [[4, 4, "programlang"], [6, 6, "programlang"], [8, 8, "programlang"], [10, 10, "programlang"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[16, 16, 4, 4, "related-to", "program_type_compatible_with", false, false], [16, 16, 6, 6, "related-to", "program_type_compatible_with", false, false], [16, 16, 8, 8, "related-to", "program_type_compatible_with", false, false], [16, 16, 10, 10, "related-to", "program_type_compatible_with", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["As", "bibliotecas", "escritas", "em", "Perl", ",", "Java", ",", "ActiveX", "ou", ".NET", "podem", "ser", "chamadas", "diretamente", "da", "MATLAB", ","], "sentence-detokenized": "As bibliotecas escritas em Perl, Java, ActiveX ou .NET podem ser chamadas diretamente da MATLAB,", "token2charspan": [[0, 2], [3, 14], [15, 23], [24, 26], [27, 31], [31, 32], [33, 37], [37, 38], [39, 46], [47, 49], [50, 54], [55, 60], [61, 64], [65, 73], [74, 85], [86, 88], [89, 95], [95, 96]]}
{"doc_key": "ai-train-69", "ner": [[3, 7, "task"], [9, 12, "task"], [30, 31, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 7, 9, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "tarefa", "de", "reconhecer", "entidades", "nomeadas", "no", "texto", "\u00e9", "Reconhecimento", "de", "Entidade", "Nomeada", ",", "enquanto", "a", "tarefa", "de", "determinar", "a", "identidade", "das", "entidades", "nomeadas", "mencionadas", "no", "texto", "\u00e9", "chamada", "de", "Entidade", "Vinculada", "."], "sentence-detokenized": "A tarefa de reconhecer entidades nomeadas no texto \u00e9 Reconhecimento de Entidade Nomeada, enquanto a tarefa de determinar a identidade das entidades nomeadas mencionadas no texto \u00e9 chamada de Entidade Vinculada.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 22], [23, 32], [33, 41], [42, 44], [45, 50], [51, 52], [53, 67], [68, 70], [71, 79], [80, 87], [87, 88], [89, 97], [98, 99], [100, 106], [107, 109], [110, 120], [121, 122], [123, 133], [134, 137], [138, 147], [148, 156], [157, 168], [169, 171], [172, 177], [178, 179], [180, 187], [188, 190], [191, 199], [200, 209], [209, 210]]}
{"doc_key": "ai-train-70", "ner": [[1, 2, "algorithm"], [27, 27, "programlang"], [26, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 26, 26, "part-of", "", true, false], [26, 26, 27, 27, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "fun\u00e7\u00f5es", "sigmoid", "e", "derivados", "utilizados", "no", "pacote", "foram", "originalmente", "inclu\u00eddos", "no", "pacote", ",", "a", "partir", "da", "vers\u00e3o", "0.8.0", ",", "estes", "foram", "lan\u00e7ados", "em", "um", "pacote", "sigmoid", "R", "separado", ",", "com", "a", "inten\u00e7\u00e3o", "de", "permitir", "um", "uso", "mais", "geral", "."], "sentence-detokenized": "As fun\u00e7\u00f5es sigmoid e derivados utilizados no pacote foram originalmente inclu\u00eddos no pacote, a partir da vers\u00e3o 0.8.0, estes foram lan\u00e7ados em um pacote sigmoid R separado, com a inten\u00e7\u00e3o de permitir um uso mais geral.", "token2charspan": [[0, 2], [3, 10], [11, 18], [19, 20], [21, 30], [31, 41], [42, 44], [45, 51], [52, 57], [58, 71], [72, 81], [82, 84], [85, 91], [91, 92], [93, 94], [95, 101], [102, 104], [105, 111], [112, 117], [117, 118], [119, 124], [125, 130], [131, 139], [140, 142], [143, 145], [146, 152], [153, 160], [161, 162], [163, 171], [171, 172], [173, 176], [177, 178], [179, 187], [188, 190], [191, 199], [200, 202], [203, 206], [207, 211], [212, 217], [217, 218]]}
{"doc_key": "ai-train-71", "ner": [[0, 1, "programlang"], [7, 11, "organisation"], [13, 13, "organisation"], [21, 21, "location"], [23, 23, "location"], [26, 27, "researcher"], [29, 30, "researcher"], [32, 33, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 26, 27, "artifact", "", true, false], [0, 1, 29, 30, "artifact", "", true, false], [0, 1, 32, 33, "artifact", "", true, false], [13, 13, 7, 11, "named", "", false, false], [13, 13, 21, 21, "physical", "", false, false], [21, 21, 23, 23, "physical", "", false, false], [26, 27, 7, 11, "role", "", false, false], [29, 30, 7, 11, "role", "", false, false], [32, 33, 7, 11, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["O", "logotipo", "foi", "criado", "em", "1967", "na", "Bolt", ",", "Beranek", "e", "Newman", "(", "BBN", ")", ",", "uma", "empresa", "de", "pesquisa", "de", "Cambridge", ",", "Massachusetts", ",", "por", "Wally", "Feurzeig", ",", "Cynthia", "Solomon", "e", "Seymour", "Papert", "."], "sentence-detokenized": "O logotipo foi criado em 1967 na Bolt, Beranek e Newman (BBN), uma empresa de pesquisa de Cambridge, Massachusetts, por Wally Feurzeig, Cynthia Solomon e Seymour Papert.", "token2charspan": [[0, 1], [2, 10], [11, 14], [15, 21], [22, 24], [25, 29], [30, 32], [33, 37], [37, 38], [39, 46], [47, 48], [49, 55], [56, 57], [57, 60], [60, 61], [61, 62], [63, 66], [67, 74], [75, 77], [78, 86], [87, 89], [90, 99], [99, 100], [101, 114], [114, 115], [116, 119], [120, 125], [126, 134], [134, 135], [136, 143], [144, 151], [152, 153], [154, 161], [162, 168], [168, 169]]}
{"doc_key": "ai-train-72", "ner": [[0, 1, "misc"], [10, 12, "field"], [23, 24, "field"], [27, 28, "algorithm"], [31, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 10, 12, "part-of", "", false, false], [0, 1, 23, 24, "compare", "", false, false], [27, 28, 23, 24, "part-of", "", false, false], [31, 32, 23, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "neuroevolu\u00e7\u00e3o", "\u00e9", "comumente", "usada", "como", "parte", "do", "paradigma", "de", "aprendizagem", "de", "refor\u00e7o", ",", "e", "pode", "ser", "contrastada", "com", "as", "t\u00e9cnicas", "convencionais", "de", "aprendizagem", "profunda", "que", "utilizam", "descida", "gradual", "em", "uma", "rede", "neural", "com", "uma", "topologia", "fixa", "."], "sentence-detokenized": "A neuroevolu\u00e7\u00e3o \u00e9 comumente usada como parte do paradigma de aprendizagem de refor\u00e7o, e pode ser contrastada com as t\u00e9cnicas convencionais de aprendizagem profunda que utilizam descida gradual em uma rede neural com uma topologia fixa.", "token2charspan": [[0, 1], [2, 15], [16, 17], [18, 27], [28, 33], [34, 38], [39, 44], [45, 47], [48, 57], [58, 60], [61, 73], [74, 76], [77, 84], [84, 85], [86, 87], [88, 92], [93, 96], [97, 108], [109, 112], [113, 115], [116, 124], [125, 138], [139, 141], [142, 154], [155, 163], [164, 167], [168, 176], [177, 184], [185, 192], [193, 195], [196, 199], [200, 204], [205, 211], [212, 215], [216, 219], [220, 229], [230, 234], [234, 235]]}
{"doc_key": "ai-train-73", "ner": [[2, 3, "algorithm"], [52, 54, "metrics"], [56, 56, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[56, 56, 52, 54, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Se", "usarmos", "quadrados", "m\u00ednimos", "para", "caber", "uma", "fun\u00e7\u00e3o", "na", "forma", "de", "um", "hiperplano", "\u0177", "=", "a", "+", "\u03b2", "supT", "/", "sup", "x", "aos", "dados", "(", "x", "sub", "i", "/", "sub", ",", "y", "sub", "i", "/", "sub", ")", "sub", "1", "\u2264", "i", "\u2264n", "/", "sub", ",", "poder\u00edamos", "ent\u00e3o", "avaliar", "o", "ajuste", "usando", "o", "erro", "quadr\u00e1tico", "m\u00e9dio", "(", "MSE", ")", "."], "sentence-detokenized": "Se usarmos quadrados m\u00ednimos para caber uma fun\u00e7\u00e3o na forma de um hiperplano \u0177 = a + \u03b2 supT / sup x aos dados (x sub i / sub, y sub i / sub) sub 1 \u2264 i \u2264n / sub, poder\u00edamos ent\u00e3o avaliar o ajuste usando o erro quadr\u00e1tico m\u00e9dio (MSE).", "token2charspan": [[0, 2], [3, 10], [11, 20], [21, 28], [29, 33], [34, 39], [40, 43], [44, 50], [51, 53], [54, 59], [60, 62], [63, 65], [66, 76], [77, 78], [79, 80], [81, 82], [83, 84], [85, 86], [87, 91], [92, 93], [94, 97], [98, 99], [100, 103], [104, 109], [110, 111], [111, 112], [113, 116], [117, 118], [119, 120], [121, 124], [124, 125], [126, 127], [128, 131], [132, 133], [134, 135], [136, 139], [139, 140], [141, 144], [145, 146], [147, 148], [149, 150], [151, 153], [154, 155], [156, 159], [159, 160], [161, 171], [172, 177], [178, 185], [186, 187], [188, 194], [195, 201], [202, 203], [204, 208], [209, 219], [220, 225], [226, 227], [227, 230], [230, 231], [231, 232]]}
{"doc_key": "ai-train-74", "ner": [[6, 6, "country"], [8, 8, "country"], [10, 10, "country"], [12, 12, "country"], [14, 14, "country"], [16, 16, "country"], [18, 18, "country"], [20, 20, "country"], [22, 22, "country"], [24, 24, "country"], [26, 26, "country"], [28, 28, "country"], [30, 30, "country"], [32, 32, "country"], [34, 34, "country"], [36, 38, "country"], [40, 40, "country"], [42, 42, "country"], [44, 44, "country"], [46, 46, "country"], [48, 49, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "empresa", "tem", "localiza\u00e7\u00f5es", "internacionais", "na", "Austr\u00e1lia", ",", "Brasil", ",", "Canad\u00e1", ",", "China", ",", "Alemanha", ",", "\u00cdndia", ",", "It\u00e1lia", ",", "Jap\u00e3o", ",", "Cor\u00e9ia", ",", "Litu\u00e2nia", ",", "Pol\u00f4nia", ",", "Mal\u00e1sia", ",", "Filipinas", ",", "R\u00fassia", ",", "Singapura", ",", "\u00c1frica", "do", "Sul", ",", "Espanha", ",", "Taiwan", ",", "Tail\u00e2ndia", ",", "Turquia", "e", "Reino", "Unido", "."], "sentence-detokenized": "A empresa tem localiza\u00e7\u00f5es internacionais na Austr\u00e1lia, Brasil, Canad\u00e1, China, Alemanha, \u00cdndia, It\u00e1lia, Jap\u00e3o, Cor\u00e9ia, Litu\u00e2nia, Pol\u00f4nia, Mal\u00e1sia, Filipinas, R\u00fassia, Singapura, \u00c1frica do Sul, Espanha, Taiwan, Tail\u00e2ndia, Turquia e Reino Unido.", "token2charspan": [[0, 1], [2, 9], [10, 13], [14, 26], [27, 41], [42, 44], [45, 54], [54, 55], [56, 62], [62, 63], [64, 70], [70, 71], [72, 77], [77, 78], [79, 87], [87, 88], [89, 94], [94, 95], [96, 102], [102, 103], [104, 109], [109, 110], [111, 117], [117, 118], [119, 127], [127, 128], [129, 136], [136, 137], [138, 145], [145, 146], [147, 156], [156, 157], [158, 164], [164, 165], [166, 175], [175, 176], [177, 183], [184, 186], [187, 190], [190, 191], [192, 199], [199, 200], [201, 207], [207, 208], [209, 218], [218, 219], [220, 227], [228, 229], [230, 235], [236, 241], [241, 242]]}
{"doc_key": "ai-train-75", "ner": [[2, 2, "misc"], [4, 7, "field"], [12, 12, "organisation"], [15, 19, "university"], [26, 28, "organisation"], [30, 36, "university"], [41, 42, "university"], [44, 46, "university"], [48, 50, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 2, 4, 7, "topic", "", false, false], [2, 2, 12, 12, "origin", "", false, false], [2, 2, 15, 19, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Ele", "\u00e9", "formado", "em", "engenharia", "el\u00e9trica", "e", "inform\u00e1tica", "(", "2000", ")", "pela", "Inria", "e", "pela", "Universidade", "de", "Nice", "Sophia", "Antipolis", ",", "e", "ocupou", "posi\u00e7\u00f5es", "permanentes", "na", "Siemens", "Corporate", "Technology", ",", "\u00c9cole", "des", "ponts", "ParisTech", ",", "bem", "como", "posi\u00e7\u00f5es", "de", "visita", "na", "Rutgers", "University", ",", "Universidade", "de", "Yale", "e", "Universidade", "de", "Houston", "."], "sentence-detokenized": "Ele \u00e9 formado em engenharia el\u00e9trica e inform\u00e1tica (2000) pela Inria e pela Universidade de Nice Sophia Antipolis, e ocupou posi\u00e7\u00f5es permanentes na Siemens Corporate Technology, \u00c9cole des ponts ParisTech, bem como posi\u00e7\u00f5es de visita na Rutgers University, Universidade de Yale e Universidade de Houston.", "token2charspan": [[0, 3], [4, 5], [6, 13], [14, 16], [17, 27], [28, 36], [37, 38], [39, 50], [51, 52], [52, 56], [56, 57], [58, 62], [63, 68], [69, 70], [71, 75], [76, 88], [89, 91], [92, 96], [97, 103], [104, 113], [113, 114], [115, 116], [117, 123], [124, 132], [133, 144], [145, 147], [148, 155], [156, 165], [166, 176], [176, 177], [178, 183], [184, 187], [188, 193], [194, 203], [203, 204], [205, 208], [209, 213], [214, 222], [223, 225], [226, 232], [233, 235], [236, 243], [244, 254], [254, 255], [256, 268], [269, 271], [272, 276], [277, 278], [279, 291], [292, 294], [295, 302], [302, 303]]}
{"doc_key": "ai-train-76", "ner": [[7, 8, "researcher"], [11, 11, "researcher"], [15, 16, "product"], [18, 19, "country"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 11, 7, 8, "role", "licensing_patent_to", false, false], [11, 11, 18, 19, "physical", "", false, false], [22, 22, 11, 11, "artifact", "", false, false], [22, 22, 15, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Licenciando", "a", "patente", "original", "concedida", "ao", "inventor", "George", "Devol", ",", "a", "Engelberger", "desenvolveu", "o", "primeiro", "rob\u00f4", "industrial", "nos", "Estados", "Unidos", ",", "o", "Unimate", ",", "nos", "anos", "50", "."], "sentence-detokenized": "Licenciando a patente original concedida ao inventor George Devol, a Engelberger desenvolveu o primeiro rob\u00f4 industrial nos Estados Unidos, o Unimate, nos anos 50.", "token2charspan": [[0, 11], [12, 13], [14, 21], [22, 30], [31, 40], [41, 43], [44, 52], [53, 59], [60, 65], [65, 66], [67, 68], [69, 80], [81, 92], [93, 94], [95, 103], [104, 108], [109, 119], [120, 123], [124, 131], [132, 138], [138, 139], [140, 141], [142, 149], [149, 150], [151, 154], [155, 159], [160, 162], [162, 163]]}
{"doc_key": "ai-train-77", "ner": [[4, 6, "task"], [12, 14, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "entrada", "\u00e9", "chamada", "reconhecimento", "da", "fala", "e", "a", "sa\u00edda", "\u00e9", "chamada", "s\u00edntese", "da", "fala", "."], "sentence-detokenized": "A entrada \u00e9 chamada reconhecimento da fala e a sa\u00edda \u00e9 chamada s\u00edntese da fala.", "token2charspan": [[0, 1], [2, 9], [10, 11], [12, 19], [20, 34], [35, 37], [38, 42], [43, 44], [45, 46], [47, 52], [53, 54], [55, 62], [63, 70], [71, 73], [74, 78], [78, 79]]}
{"doc_key": "ai-train-78", "ner": [[4, 4, "programlang"], [6, 6, "programlang"], [13, 13, "programlang"], [16, 16, "programlang"], [28, 28, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 13, 13, "named", "", false, false], [6, 6, 4, 4, "origin", "descendant_of", false, false], [6, 6, 16, 16, "general-affiliation", "", false, false], [6, 6, 28, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Os", "descendentes", "da", "linguagem", "CLIPS", "incluem", "Jess", "(", "parte", "baseada", "em", "regras", "do", "CLIPS", "reescrita", "em", "Java", ",", "que", "mais", "tarde", "cresceu", "em", "uma", "dire\u00e7\u00e3o", "diferente", ")", ",", "JESS", "foi", "originalmente", "inspirado"], "sentence-detokenized": "Os descendentes da linguagem CLIPS incluem Jess (parte baseada em regras do CLIPS reescrita em Java, que mais tarde cresceu em uma dire\u00e7\u00e3o diferente), JESS foi originalmente inspirado", "token2charspan": [[0, 2], [3, 15], [16, 18], [19, 28], [29, 34], [35, 42], [43, 47], [48, 49], [49, 54], [55, 62], [63, 65], [66, 72], [73, 75], [76, 81], [82, 91], [92, 94], [95, 99], [99, 100], [101, 104], [105, 109], [110, 115], [116, 123], [124, 126], [127, 130], [131, 138], [139, 148], [148, 149], [149, 150], [151, 155], [156, 159], [160, 173], [174, 183]]}
{"doc_key": "ai-train-79", "ner": [[5, 5, "product"], [9, 13, "product"], [16, 17, "organisation"], [21, 22, "product"], [40, 42, "product"], [44, 47, "product"], [67, 69, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 13, 5, 5, "type-of", "", false, false], [16, 17, 9, 13, "usage", "", false, false], [21, 22, 16, 17, "artifact", "", false, false], [40, 42, 16, 17, "origin", "", true, false], [40, 42, 67, 69, "related-to", "", true, false], [44, 47, 16, 17, "origin", "", true, false], [44, 47, 67, 69, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Tamb\u00e9m", "criou", "aplica\u00e7\u00f5es", "flex\u00edveis", "inteligentes", "AGV", ",", "projetando", "o", "sistema", "de", "controle", "de", "motividade", "usado", "pela", "RMT", "Rob\u00f3tica", "para", "desenvolver", "seu", "ADAM", "iAGV", "(", "Self-Guided", "Vehicle", ")", ",", "usado", "para", "opera\u00e7\u00f5es", "complexas", "de", "pick", "and", "place", ",", "em", "conjunto", "com", "sistemas", "de", "p\u00f3rtico", "e", "bra\u00e7os", "de", "rob\u00f4s", "industriais", ",", "usados", "em", "f\u00e1bricas", "de", "abastecimento", "de", "autom\u00f3veis", "de", "primeira", "linha", "para", "mover", "produtos", "de", "processo", "para", "processo", "em", "layouts", "n\u00e3o", "lineares", "."], "sentence-detokenized": "Tamb\u00e9m criou aplica\u00e7\u00f5es flex\u00edveis inteligentes AGV, projetando o sistema de controle de motividade usado pela RMT Rob\u00f3tica para desenvolver seu ADAM iAGV (Self-Guided Vehicle), usado para opera\u00e7\u00f5es complexas de pick and place, em conjunto com sistemas de p\u00f3rtico e bra\u00e7os de rob\u00f4s industriais, usados em f\u00e1bricas de abastecimento de autom\u00f3veis de primeira linha para mover produtos de processo para processo em layouts n\u00e3o lineares.", "token2charspan": [[0, 6], [7, 12], [13, 23], [24, 33], [34, 46], [47, 50], [50, 51], [52, 62], [63, 64], [65, 72], [73, 75], [76, 84], [85, 87], [88, 98], [99, 104], [105, 109], [110, 113], [114, 122], [123, 127], [128, 139], [140, 143], [144, 148], [149, 153], [154, 155], [155, 166], [167, 174], [174, 175], [175, 176], [177, 182], [183, 187], [188, 197], [198, 207], [208, 210], [211, 215], [216, 219], [220, 225], [225, 226], [227, 229], [230, 238], [239, 242], [243, 251], [252, 254], [255, 262], [263, 264], [265, 271], [272, 274], [275, 280], [281, 292], [292, 293], [294, 300], [301, 303], [304, 312], [313, 315], [316, 329], [330, 332], [333, 343], [344, 346], [347, 355], [356, 361], [362, 366], [367, 372], [373, 381], [382, 384], [385, 393], [394, 398], [399, 407], [408, 410], [411, 418], [419, 422], [423, 431], [431, 432]]}
{"doc_key": "ai-train-80", "ner": [[7, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Os", "par\u00e2metros", "\u03b2", "s\u00e3o", "tipicamente", "estimados", "pela", "m\u00e1xima", "probabilidade", "."], "sentence-detokenized": "Os par\u00e2metros \u03b2 s\u00e3o tipicamente estimados pela m\u00e1xima probabilidade.", "token2charspan": [[0, 2], [3, 13], [14, 15], [16, 19], [20, 31], [32, 41], [42, 46], [47, 53], [54, 67], [67, 68]]}
{"doc_key": "ai-train-81", "ner": [[3, 7, "task"], [8, 8, "metrics"], [10, 10, "metrics"], [12, 12, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 3, 7, "part-of", "", false, false], [10, 10, 3, 7, "part-of", "", false, false], [12, 12, 3, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["As", "m\u00e9tricas", "de", "recupera\u00e7\u00e3o", "de", "informa\u00e7\u00f5es", ",", "como", "precis\u00e3o", "e", "recall", "ou", "DCG", ",", "s\u00e3o", "\u00fateis", "para", "avaliar", "a", "qualidade", "de", "um", "m\u00e9todo", "de", "recomenda\u00e7\u00e3o", "."], "sentence-detokenized": "As m\u00e9tricas de recupera\u00e7\u00e3o de informa\u00e7\u00f5es, como precis\u00e3o e recall ou DCG, s\u00e3o \u00fateis para avaliar a qualidade de um m\u00e9todo de recomenda\u00e7\u00e3o.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 29], [30, 41], [41, 42], [43, 47], [48, 56], [57, 58], [59, 65], [66, 68], [69, 72], [72, 73], [74, 77], [78, 83], [84, 88], [89, 96], [97, 98], [99, 108], [109, 111], [112, 114], [115, 121], [122, 124], [125, 137], [137, 138]]}
{"doc_key": "ai-train-82", "ner": [[6, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Uma", "f\u00e1brica", "t\u00edpica", "cont\u00e9m", "centenas", "de", "rob\u00f4s", "industriais", "que", "trabalham", "em", "linhas", "de", "produ\u00e7\u00e3o", "totalmente", "automatizadas", ",", "com", "um", "rob\u00f4", "para", "cada", "dez", "trabalhadores", "humanos", "."], "sentence-detokenized": "Uma f\u00e1brica t\u00edpica cont\u00e9m centenas de rob\u00f4s industriais que trabalham em linhas de produ\u00e7\u00e3o totalmente automatizadas, com um rob\u00f4 para cada dez trabalhadores humanos.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 25], [26, 34], [35, 37], [38, 43], [44, 55], [56, 59], [60, 69], [70, 72], [73, 79], [80, 82], [83, 91], [92, 102], [103, 116], [116, 117], [118, 121], [122, 124], [125, 129], [130, 134], [135, 139], [140, 143], [144, 157], [158, 165], [165, 166]]}
{"doc_key": "ai-train-83", "ner": [[5, 6, "product"], [16, 18, "field"], [22, 24, "task"], [26, 28, "task"], [30, 32, "task"], [34, 36, "task"], [38, 40, "task"], [42, 44, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[16, 18, 5, 6, "usage", "", false, true], [22, 24, 16, 18, "part-of", "", false, false], [26, 28, 16, 18, "part-of", "", false, false], [30, 32, 16, 18, "part-of", "", false, false], [34, 36, 16, 18, "part-of", "", false, false], [38, 40, 16, 18, "part-of", "", false, false], [42, 44, 16, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Durante", "a", "\u00faltima", "d\u00e9cada", ",", "os", "PCNNs", "t\u00eam", "sido", "usados", "em", "uma", "variedade", "de", "aplica\u00e7\u00f5es", "de", "processamento", "de", "imagem", ",", "incluindo", ":", "segmenta\u00e7\u00e3o", "de", "imagem", ",", "gera\u00e7\u00e3o", "de", "caracter\u00edsticas", ",", "extra\u00e7\u00e3o", "de", "rosto", ",", "detec\u00e7\u00e3o", "de", "movimento", ",", "crescimento", "da", "regi\u00e3o", "e", "redu\u00e7\u00e3o", "de", "ru\u00eddo", "."], "sentence-detokenized": "Durante a \u00faltima d\u00e9cada, os PCNNs t\u00eam sido usados em uma variedade de aplica\u00e7\u00f5es de processamento de imagem, incluindo: segmenta\u00e7\u00e3o de imagem, gera\u00e7\u00e3o de caracter\u00edsticas, extra\u00e7\u00e3o de rosto, detec\u00e7\u00e3o de movimento, crescimento da regi\u00e3o e redu\u00e7\u00e3o de ru\u00eddo.", "token2charspan": [[0, 7], [8, 9], [10, 16], [17, 23], [23, 24], [25, 27], [28, 33], [34, 37], [38, 42], [43, 49], [50, 52], [53, 56], [57, 66], [67, 69], [70, 80], [81, 83], [84, 97], [98, 100], [101, 107], [107, 108], [109, 118], [118, 119], [120, 131], [132, 134], [135, 141], [141, 142], [143, 150], [151, 153], [154, 169], [169, 170], [171, 179], [180, 182], [183, 188], [188, 189], [190, 198], [199, 201], [202, 211], [211, 212], [213, 224], [225, 227], [228, 234], [235, 236], [237, 244], [245, 247], [248, 253], [253, 254]]}
{"doc_key": "ai-train-84", "ner": [[0, 1, "researcher"], [16, 17, "field"], [21, 24, "misc"], [26, 32, "conference"], [34, 34, "conference"], [39, 42, "misc"], [44, 50, "conference"], [51, 52, "conference"], [54, 58, "conference"], [60, 60, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 1, 16, 17, "related-to", "contributes_to", false, false], [0, 1, 21, 24, "win-defeat", "", false, false], [0, 1, 39, 42, "win-defeat", "", false, false], [21, 24, 26, 32, "temporal", "", false, false], [34, 34, 26, 32, "named", "", false, false], [39, 42, 44, 50, "temporal", "", false, false], [39, 42, 54, 58, "temporal", "", false, false], [51, 52, 44, 50, "named", "", false, false], [60, 60, 54, 58, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["A", "Xu", "publicou", "mais", "de", "50", "trabalhos", "em", "confer\u00eancias", "internacionais", "e", "em", "revistas", "no", "campo", "da", "vis\u00e3o", "computacional", "e", "ganhou", "o", "Pr\u00eamio", "de", "Melhor", "Trabalho", "na", "confer\u00eancia", "internacional", "sobre", "Renderiza\u00e7\u00e3o", "N\u00e3o-Photorealista", "e", "Anima\u00e7\u00e3o", "(", "NPAR", ")", "2012", "e", "o", "Pr\u00eamio", "de", "Melhor", "Revisor", "nas", "confer\u00eancias", "internacionais", "Asian", "Conference", "on", "Computer", "Vision", "ACCV", "2012", "e", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "2015", "."], "sentence-detokenized": "A Xu publicou mais de 50 trabalhos em confer\u00eancias internacionais e em revistas no campo da vis\u00e3o computacional e ganhou o Pr\u00eamio de Melhor Trabalho na confer\u00eancia internacional sobre Renderiza\u00e7\u00e3o N\u00e3o-Photorealista e Anima\u00e7\u00e3o (NPAR) 2012 e o Pr\u00eamio de Melhor Revisor nas confer\u00eancias internacionais Asian Conference on Computer Vision ACCV 2012 e International Conference on Computer Vision (ICCV) 2015.", "token2charspan": [[0, 1], [2, 4], [5, 13], [14, 18], [19, 21], [22, 24], [25, 34], [35, 37], [38, 50], [51, 65], [66, 67], [68, 70], [71, 79], [80, 82], [83, 88], [89, 91], [92, 97], [98, 111], [112, 113], [114, 120], [121, 122], [123, 129], [130, 132], [133, 139], [140, 148], [149, 151], [152, 163], [164, 177], [178, 183], [184, 196], [197, 214], [215, 216], [217, 225], [226, 227], [227, 231], [231, 232], [233, 237], [238, 239], [240, 241], [242, 248], [249, 251], [252, 258], [259, 266], [267, 270], [271, 283], [284, 298], [299, 304], [305, 315], [316, 318], [319, 327], [328, 334], [335, 339], [340, 344], [345, 346], [347, 360], [361, 371], [372, 374], [375, 383], [384, 390], [391, 392], [392, 396], [396, 397], [398, 402], [402, 403]]}
{"doc_key": "ai-train-85", "ner": [[0, 0, "programlang"], [2, 4, "field"], [6, 7, "field"], [10, 11, "misc"], [18, 19, "researcher"], [14, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 2, 4, "part-of", "", false, false], [0, 0, 6, 7, "part-of", "", false, false], [0, 0, 10, 11, "type-of", "", false, false], [14, 16, 0, 0, "usage", "", false, false], [14, 16, 18, 19, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["CycL", "em", "ci\u00eancia", "da", "computa\u00e7\u00e3o", "e", "intelig\u00eancia", "artificial", "\u00e9", "uma", "linguagem", "ontol\u00f3gica", "usada", "pelo", "projeto", "Cyc", "artificial", "de", "Doug", "Lenat", "."], "sentence-detokenized": "CycL em ci\u00eancia da computa\u00e7\u00e3o e intelig\u00eancia artificial \u00e9 uma linguagem ontol\u00f3gica usada pelo projeto Cyc artificial de Doug Lenat.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 29], [30, 31], [32, 44], [45, 55], [56, 57], [58, 61], [62, 71], [72, 82], [83, 88], [89, 93], [94, 101], [102, 105], [106, 116], [117, 119], [120, 124], [125, 130], [130, 131]]}
{"doc_key": "ai-train-86", "ner": [[2, 4, "task"], [7, 9, "metrics"], [14, 18, "metrics"], [20, 25, "metrics"], [34, 36, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 9, 2, 4, "part-of", "", false, false], [14, 18, 7, 9, "named", "", false, false], [20, 25, 7, 9, "named", "", false, false], [34, 36, 7, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Tamb\u00e9m", "na", "an\u00e1lise", "de", "regress\u00e3o", ",", "o", "erro", "quadr\u00e1tico", "m\u00e9dio", ",", "freq\u00fcentemente", "referido", "como", "erro", "de", "previs\u00e3o", "quadr\u00e1tico", "m\u00e9dio", "ou", "erro", "quadr\u00e1tico", "m\u00e9dio", "fora", "da", "amostra", ",", "pode", "se", "referir", "ao", "valor", "m\u00e9dio", "dos", "desvios", "quadr\u00e1ticos", "das", "previs\u00f5es", "em", "rela\u00e7\u00e3o", "aos", "valores", "VERDADEIROS", ",", "sobre", "um", "espa\u00e7o", "de", "teste", "fora", "da", "amostra", ",", "gerado", "por", "um", "modelo", "estimado", "sobre", "um", "determinado", "espa\u00e7o", "de", "amostra", "."], "sentence-detokenized": "Tamb\u00e9m na an\u00e1lise de regress\u00e3o, o erro quadr\u00e1tico m\u00e9dio, freq\u00fcentemente referido como erro de previs\u00e3o quadr\u00e1tico m\u00e9dio ou erro quadr\u00e1tico m\u00e9dio fora da amostra, pode se referir ao valor m\u00e9dio dos desvios quadr\u00e1ticos das previs\u00f5es em rela\u00e7\u00e3o aos valores VERDADEIROS, sobre um espa\u00e7o de teste fora da amostra, gerado por um modelo estimado sobre um determinado espa\u00e7o de amostra.", "token2charspan": [[0, 6], [7, 9], [10, 17], [18, 20], [21, 30], [30, 31], [32, 33], [34, 38], [39, 49], [50, 55], [55, 56], [57, 71], [72, 80], [81, 85], [86, 90], [91, 93], [94, 102], [103, 113], [114, 119], [120, 122], [123, 127], [128, 138], [139, 144], [145, 149], [150, 152], [153, 160], [160, 161], [162, 166], [167, 169], [170, 177], [178, 180], [181, 186], [187, 192], [193, 196], [197, 204], [205, 216], [217, 220], [221, 230], [231, 233], [234, 241], [242, 245], [246, 253], [254, 265], [265, 266], [267, 272], [273, 275], [276, 282], [283, 285], [286, 291], [292, 296], [297, 299], [300, 307], [307, 308], [309, 315], [316, 319], [320, 322], [323, 329], [330, 338], [339, 344], [345, 347], [348, 359], [360, 366], [367, 369], [370, 377], [377, 378]]}
{"doc_key": "ai-train-87", "ner": [[8, 8, "algorithm"], [10, 10, "algorithm"], [18, 19, "algorithm"], [31, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 10, 10, "compare", "", false, false], [8, 8, 18, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Quanto", "aos", "resultados", ",", "os", "descritores", "de", "blocos", "C-HOG", "e", "R-HOG", "t\u00eam", "um", "desempenho", "compar\u00e1vel", ",", "com", "os", "descritores", "C-HOG", "mantendo", "uma", "ligeira", "vantagem", "na", "taxa", "de", "falhas", "de", "detec\u00e7\u00e3o", "com", "taxas", "positivas", "FALSO", "fixas", "em", "ambos", "os", "conjuntos", "de", "dados", "."], "sentence-detokenized": "Quanto aos resultados, os descritores de blocos C-HOG e R-HOG t\u00eam um desempenho compar\u00e1vel, com os descritores C-HOG mantendo uma ligeira vantagem na taxa de falhas de detec\u00e7\u00e3o com taxas positivas FALSO fixas em ambos os conjuntos de dados.", "token2charspan": [[0, 6], [7, 10], [11, 21], [21, 22], [23, 25], [26, 37], [38, 40], [41, 47], [48, 53], [54, 55], [56, 61], [62, 65], [66, 68], [69, 79], [80, 90], [90, 91], [92, 95], [96, 98], [99, 110], [111, 116], [117, 125], [126, 129], [130, 137], [138, 146], [147, 149], [150, 154], [155, 157], [158, 164], [165, 167], [168, 176], [177, 180], [181, 186], [187, 196], [197, 202], [203, 208], [209, 211], [212, 217], [218, 220], [221, 230], [231, 233], [234, 239], [239, 240]]}
{"doc_key": "ai-train-88", "ner": [[7, 10, "algorithm"], [12, 13, "misc"], [15, 17, "algorithm"], [19, 20, "algorithm"], [23, 24, "algorithm"], [27, 29, "algorithm"], [32, 34, "algorithm"], [36, 37, "misc"], [41, 44, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[7, 10, 12, 13, "usage", "", false, false], [15, 17, 36, 37, "usage", "", false, false], [19, 20, 36, 37, "usage", "", false, false], [23, 24, 36, 37, "usage", "", false, false], [27, 29, 36, 37, "usage", "", false, false], [32, 34, 36, 37, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Os", "algoritmos", "populares", "de", "reconhecimento", "incluem", "a", "an\u00e1lise", "de", "componentes", "principais", "usando", "interfaces", "pr\u00f3prias", ",", "an\u00e1lise", "linear", "discriminante", ",", "correspond\u00eancia", "el\u00e1stica", "usando", "o", "algoritmo", "Fisherface", ",", "o", "modelo", "Markov", "oculto", ",", "o", "aprendizado", "subespacial", "multilinear", "usando", "representa\u00e7\u00e3o", "tensorial", ",", "e", "a", "correspond\u00eancia", "din\u00e2mica", "de", "liga\u00e7\u00e3o", "neuronal", "motivada", "."], "sentence-detokenized": "Os algoritmos populares de reconhecimento incluem a an\u00e1lise de componentes principais usando interfaces pr\u00f3prias, an\u00e1lise linear discriminante, correspond\u00eancia el\u00e1stica usando o algoritmo Fisherface, o modelo Markov oculto, o aprendizado subespacial multilinear usando representa\u00e7\u00e3o tensorial, e a correspond\u00eancia din\u00e2mica de liga\u00e7\u00e3o neuronal motivada.", "token2charspan": [[0, 2], [3, 13], [14, 23], [24, 26], [27, 41], [42, 49], [50, 51], [52, 59], [60, 62], [63, 74], [75, 85], [86, 92], [93, 103], [104, 112], [112, 113], [114, 121], [122, 128], [129, 142], [142, 143], [144, 159], [160, 168], [169, 175], [176, 177], [178, 187], [188, 198], [198, 199], [200, 201], [202, 208], [209, 215], [216, 222], [222, 223], [224, 225], [226, 237], [238, 249], [250, 261], [262, 268], [269, 282], [283, 292], [292, 293], [294, 295], [296, 297], [298, 313], [314, 322], [323, 325], [326, 333], [334, 342], [343, 351], [351, 352]]}
{"doc_key": "ai-train-89", "ner": [[3, 10, "misc"], [18, 20, "location"], [37, 39, "location"], [52, 52, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[18, 20, 3, 10, "temporal", "", false, false], [37, 39, 3, 10, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "partir", "do", "Festival", "Internacional", "de", "Cinema", "de", "Toronto", "de", "2019", ",", "os", "filmes", "podem", "ser", "exibidos", "no", "Scotiabank", "Theatre", "Toronto", "-", "um", "dos", "principais", "locais", "do", "festival", "-", "e", "exibidos", "em", "outros", "lugares", "(", "como", "o", "TIFF", "Bell", "Lightbox", "e", "outros", "cinemas", "locais", ")", "se", "distribu\u00eddos", "por", "um", "servi\u00e7o", "como", "o", "Netflix", "."], "sentence-detokenized": "A partir do Festival Internacional de Cinema de Toronto de 2019, os filmes podem ser exibidos no Scotiabank Theatre Toronto - um dos principais locais do festival - e exibidos em outros lugares (como o TIFF Bell Lightbox e outros cinemas locais) se distribu\u00eddos por um servi\u00e7o como o Netflix.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 20], [21, 34], [35, 37], [38, 44], [45, 47], [48, 55], [56, 58], [59, 63], [63, 64], [65, 67], [68, 74], [75, 80], [81, 84], [85, 93], [94, 96], [97, 107], [108, 115], [116, 123], [124, 125], [126, 128], [129, 132], [133, 143], [144, 150], [151, 153], [154, 162], [163, 164], [165, 166], [167, 175], [176, 178], [179, 185], [186, 193], [194, 195], [195, 199], [200, 201], [202, 206], [207, 211], [212, 220], [221, 222], [223, 229], [230, 237], [238, 244], [244, 245], [246, 248], [249, 261], [262, 265], [266, 268], [269, 276], [277, 281], [282, 283], [284, 291], [291, 292]]}
{"doc_key": "ai-train-90", "ner": [[0, 1, "organisation"], [4, 5, "researcher"], [6, 8, "organisation"], [17, 17, "researcher"], [27, 31, "product"], [48, 48, "researcher"], [43, 47, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 6, 8, "related-to", "purchases", false, false], [4, 5, 17, 17, "named", "same", false, false], [4, 5, 48, 48, "named", "same", false, false], [6, 8, 4, 5, "origin", "founded_by", false, false], [27, 31, 0, 1, "artifact", "", false, false], [43, 47, 48, 48, "artifact", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["A", "Unimation", "adquiriu", "a", "Victor", "Scheinman's", "Vicarm", "Inc", ".", "em", "1977", ",", "e", "com", "a", "ajuda", "de", "Scheinman", ",", "a", "empresa", "criou", "e", "come\u00e7ou", "a", "produzir", "a", "Programmable", "Universal", "Machine", "for", "Assembly", ",", "um", "novo", "modelo", "de", "bra\u00e7o", "rob\u00f3tico", ",", "e", "utilizando", "a", "linguagem", "de", "programa\u00e7\u00e3o", "VAL", "de", "Scheinman", "de", "\u00faltima", "gera\u00e7\u00e3o", "."], "sentence-detokenized": "A Unimation adquiriu a Victor Scheinman's Vicarm Inc. em 1977, e com a ajuda de Scheinman, a empresa criou e come\u00e7ou a produzir a Programmable Universal Machine for Assembly, um novo modelo de bra\u00e7o rob\u00f3tico, e utilizando a linguagem de programa\u00e7\u00e3o VAL de Scheinman de \u00faltima gera\u00e7\u00e3o.", "token2charspan": [[0, 1], [2, 11], [12, 20], [21, 22], [23, 29], [30, 41], [42, 48], [49, 52], [52, 53], [54, 56], [57, 61], [61, 62], [63, 64], [65, 68], [69, 70], [71, 76], [77, 79], [80, 89], [89, 90], [91, 92], [93, 100], [101, 106], [107, 108], [109, 116], [117, 118], [119, 127], [128, 129], [130, 142], [143, 152], [153, 160], [161, 164], [165, 173], [173, 174], [175, 177], [178, 182], [183, 189], [190, 192], [193, 198], [199, 207], [207, 208], [209, 210], [211, 221], [222, 223], [224, 233], [234, 236], [237, 248], [249, 252], [253, 255], [256, 265], [266, 268], [269, 275], [276, 283], [283, 284]]}
{"doc_key": "ai-train-91", "ner": [[0, 0, "product"], [4, 5, "programlang"], [9, 11, "algorithm"], [12, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 5, "general-affiliation", "", false, false], [0, 0, 9, 11, "origin", "implementation_of", false, false], [0, 0, 12, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["J48", "\u00e9", "uma", "implementa\u00e7\u00e3o", "Java", "de", "c\u00f3digo", "aberto", "do", "algoritmo", "C4.5", "na", "ferramenta", "de", "minera\u00e7\u00e3o", "de", "dados", "Weka", "."], "sentence-detokenized": "J48 \u00e9 uma implementa\u00e7\u00e3o Java de c\u00f3digo aberto do algoritmo C4.5 na ferramenta de minera\u00e7\u00e3o de dados Weka.", "token2charspan": [[0, 3], [4, 5], [6, 9], [10, 23], [24, 28], [29, 31], [32, 38], [39, 45], [46, 48], [49, 58], [59, 63], [64, 66], [67, 77], [78, 80], [81, 90], [91, 93], [94, 99], [100, 104], [104, 105]]}
{"doc_key": "ai-train-92", "ner": [[2, 2, "metrics"], [14, 15, "product"], [21, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 14, 15, "win-defeat", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["O", "documento", "SSIM", "2004", "foi", "citado", "mais", "de", "20.000", "vezes", "de", "acordo", "com", "o", "Google", "Scholar", ",", "Ele", "tamb\u00e9m", "recebeu", "o", "IEEE", "Signal", "Processing", "Society", "Sustained", "Impact", "Award", "para", "2016", ",", "indicativo", "de", "um", "documento", "com", "um", "impacto", "excepcionalmente", "alto", "por", "pelo", "menos", "10", "anos", "ap\u00f3s", "sua", "publica\u00e7\u00e3o", "."], "sentence-detokenized": "O documento SSIM 2004 foi citado mais de 20.000 vezes de acordo com o Google Scholar, Ele tamb\u00e9m recebeu o IEEE Signal Processing Society Sustained Impact Award para 2016, indicativo de um documento com um impacto excepcionalmente alto por pelo menos 10 anos ap\u00f3s sua publica\u00e7\u00e3o.", "token2charspan": [[0, 1], [2, 11], [12, 16], [17, 21], [22, 25], [26, 32], [33, 37], [38, 40], [41, 47], [48, 53], [54, 56], [57, 63], [64, 67], [68, 69], [70, 76], [77, 84], [84, 85], [86, 89], [90, 96], [97, 104], [105, 106], [107, 111], [112, 118], [119, 129], [130, 137], [138, 147], [148, 154], [155, 160], [161, 165], [166, 170], [170, 171], [172, 182], [183, 185], [186, 188], [189, 198], [199, 202], [203, 205], [206, 213], [214, 230], [231, 235], [236, 239], [240, 244], [245, 250], [251, 253], [254, 258], [259, 263], [264, 267], [268, 278], [278, 279]]}
{"doc_key": "ai-train-93", "ner": [[1, 3, "task"], [26, 27, "product"], [36, 38, "product"], [41, 41, "organisation"], [42, 42, "product"], [47, 47, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 3, 41, 41, "artifact", "", false, false], [26, 27, 1, 3, "related-to", "performs", false, false], [26, 27, 36, 38, "part-of", "", false, false], [41, 41, 47, 47, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "s\u00edntese", "da", "fala", "est\u00e1", "prestes", "a", "ser", "completamente", "indistingu\u00edvel", "de", "uma", "voz", "humana", "real", "com", "a", "introdu\u00e7\u00e3o", "do", "software", "de", "edi\u00e7\u00e3o", "e", "gera\u00e7\u00e3o", "de", "voz", "Adobe", "Voco", ",", "um", "prot\u00f3tipo", "previsto", "para", "fazer", "parte", "do", "Adobe", "Creative", "Suite", "e", "do", "DeepMind", "WaveNet", ",", "um", "prot\u00f3tipo", "do", "Google", "."], "sentence-detokenized": "A s\u00edntese da fala est\u00e1 prestes a ser completamente indistingu\u00edvel de uma voz humana real com a introdu\u00e7\u00e3o do software de edi\u00e7\u00e3o e gera\u00e7\u00e3o de voz Adobe Voco, um prot\u00f3tipo previsto para fazer parte do Adobe Creative Suite e do DeepMind WaveNet, um prot\u00f3tipo do Google.", "token2charspan": [[0, 1], [2, 9], [10, 12], [13, 17], [18, 22], [23, 30], [31, 32], [33, 36], [37, 50], [51, 65], [66, 68], [69, 72], [73, 76], [77, 83], [84, 88], [89, 92], [93, 94], [95, 105], [106, 108], [109, 117], [118, 120], [121, 127], [128, 129], [130, 137], [138, 140], [141, 144], [145, 150], [151, 155], [155, 156], [157, 159], [160, 169], [170, 178], [179, 183], [184, 189], [190, 195], [196, 198], [199, 204], [205, 213], [214, 219], [220, 221], [222, 224], [225, 233], [234, 241], [241, 242], [243, 245], [246, 255], [256, 258], [259, 265], [265, 266]]}
{"doc_key": "ai-train-94", "ner": [[0, 0, "researcher"], [5, 9, "organisation"], [13, 18, "organisation"], [23, 23, "conference"], [28, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 9, "role", "", false, false], [0, 0, 13, 18, "role", "", false, false], [0, 0, 23, 23, "role", "", false, false], [0, 0, 28, 32, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Poggio", "\u00e9", "membro", "honor\u00e1rio", "do", "Programa", "de", "Pesquisa", "em", "Neuroci\u00eancia", ",", "membro", "da", "Academia", "Americana", "de", "Artes", "e", "Ci\u00eancias", "e", "membro", "fundador", "da", "AAAI", "e", "membro", "fundador", "do", "McGovern", "Institute", "for", "Brain", "Research", "."], "sentence-detokenized": "Poggio \u00e9 membro honor\u00e1rio do Programa de Pesquisa em Neuroci\u00eancia, membro da Academia Americana de Artes e Ci\u00eancias e membro fundador da AAAI e membro fundador do McGovern Institute for Brain Research.", "token2charspan": [[0, 6], [7, 8], [9, 15], [16, 25], [26, 28], [29, 37], [38, 40], [41, 49], [50, 52], [53, 65], [65, 66], [67, 73], [74, 76], [77, 85], [86, 95], [96, 98], [99, 104], [105, 106], [107, 115], [116, 117], [118, 124], [125, 133], [134, 136], [137, 141], [142, 143], [144, 150], [151, 159], [160, 162], [163, 171], [172, 181], [182, 185], [186, 191], [192, 200], [200, 201]]}
{"doc_key": "ai-train-95", "ner": [[9, 9, "task"], [11, 13, "task"], [19, 21, "task"], [28, 28, "misc"], [26, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 9, 19, 21, "cause-effect", "", false, false], [11, 13, 19, 21, "cause-effect", "", false, false], [26, 27, 19, 21, "topic", "", false, false], [26, 27, 28, 28, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Durante", "os", "anos", "90", ",", "encorajados", "pelos", "sucessos", "no", "reconhecimento", "e", "s\u00edntese", "da", "fala", ",", "come\u00e7aram", "as", "pesquisas", "sobre", "tradu\u00e7\u00e3o", "da", "fala", "com", "o", "desenvolvimento", "do", "projeto", "Verbmobil", "alem\u00e3o", "."], "sentence-detokenized": "Durante os anos 90, encorajados pelos sucessos no reconhecimento e s\u00edntese da fala, come\u00e7aram as pesquisas sobre tradu\u00e7\u00e3o da fala com o desenvolvimento do projeto Verbmobil alem\u00e3o.", "token2charspan": [[0, 7], [8, 10], [11, 15], [16, 18], [18, 19], [20, 31], [32, 37], [38, 46], [47, 49], [50, 64], [65, 66], [67, 74], [75, 77], [78, 82], [82, 83], [84, 93], [94, 96], [97, 106], [107, 112], [113, 121], [122, 124], [125, 129], [130, 133], [134, 135], [136, 151], [152, 154], [155, 162], [163, 172], [173, 179], [179, 180]]}
{"doc_key": "ai-train-96", "ner": [[3, 4, "researcher"], [8, 9, "researcher"], [11, 12, "researcher"], [15, 17, "algorithm"], [21, 22, "algorithm"], [26, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 8, 9, "role", "", false, false], [15, 17, 3, 4, "origin", "", false, false], [15, 17, 8, 9, "origin", "", false, false], [15, 17, 11, 12, "origin", "", false, false], [15, 17, 26, 26, "part-of", "", false, false], [21, 22, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Em", "1999", ",", "Felix", "Gers", "e", "seu", "conselheiro", "J\u00fcrgen", "Schmidhuber", "e", "Fred", "Cummins", "introduziram", "o", "port\u00e3o", "do", "esquecimento", "(", "tamb\u00e9m", "chamado", "keep", "gate", ")", "na", "arquitetura", "LSTM", ","], "sentence-detokenized": "Em 1999, Felix Gers e seu conselheiro J\u00fcrgen Schmidhuber e Fred Cummins introduziram o port\u00e3o do esquecimento (tamb\u00e9m chamado keep gate) na arquitetura LSTM,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 19], [20, 21], [22, 25], [26, 37], [38, 44], [45, 56], [57, 58], [59, 63], [64, 71], [72, 84], [85, 86], [87, 93], [94, 96], [97, 109], [110, 111], [111, 117], [118, 125], [126, 130], [131, 135], [135, 136], [137, 139], [140, 151], [152, 156], [156, 157]]}
{"doc_key": "ai-train-97", "ner": [[3, 6, "field"], [1, 9, "field"], [12, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 14, 3, 6, "part-of", "", false, false], [12, 14, 1, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Na", "teoria", "do", "processamento", "de", "sinais", "digitais", "e", "da", "informa\u00e7\u00e3o", ",", "a", "fun\u00e7\u00e3o", "sinc", "normalizada", "\u00e9", "comumente", "definida", "por"], "sentence-detokenized": "Na teoria do processamento de sinais digitais e da informa\u00e7\u00e3o, a fun\u00e7\u00e3o sinc normalizada \u00e9 comumente definida por", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 26], [27, 29], [30, 36], [37, 45], [46, 47], [48, 50], [51, 61], [61, 62], [63, 64], [65, 71], [72, 76], [77, 88], [89, 90], [91, 100], [101, 109], [110, 113]]}
{"doc_key": "ai-train-98", "ner": [[3, 4, "field"], [11, 12, "researcher"], [18, 21, "conference"], [24, 28, "organisation"], [30, 30, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 11, 12, "origin", "coined_term", false, false], [11, 12, 18, 21, "role", "", false, false], [11, 12, 24, 28, "role", "", false, false], [30, 30, 24, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["O", "pr\u00f3prio", "termo", "ling\u00fc\u00edstica", "computacional", "foi", "cunhado", "pela", "primeira", "vez", "por", "David", "Hays", ",", "membro", "fundador", "tanto", "da", "Associa\u00e7\u00e3o", "de", "Lingu\u00edstica", "Computacional", "quanto", "do", "Comit\u00ea", "Internacional", "de", "Lingu\u00edstica", "Computacional", "(", "ICCL", ")", "."], "sentence-detokenized": "O pr\u00f3prio termo ling\u00fc\u00edstica computacional foi cunhado pela primeira vez por David Hays, membro fundador tanto da Associa\u00e7\u00e3o de Lingu\u00edstica Computacional quanto do Comit\u00ea Internacional de Lingu\u00edstica Computacional (ICCL).", "token2charspan": [[0, 1], [2, 9], [10, 15], [16, 27], [28, 41], [42, 45], [46, 53], [54, 58], [59, 67], [68, 71], [72, 75], [76, 81], [82, 86], [86, 87], [88, 94], [95, 103], [104, 109], [110, 112], [113, 123], [124, 126], [127, 138], [139, 152], [153, 159], [160, 162], [163, 169], [170, 183], [184, 186], [187, 198], [199, 212], [213, 214], [214, 218], [218, 219], [219, 220]]}
{"doc_key": "ai-train-99", "ner": [[12, 14, "misc"], [10, 11, "misc"], [35, 37, "metrics"], [39, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[39, 39, 35, 37, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["59", ",", "pp", ".", "2547-2553", ",", "Out", ".", "2011", "Em", "DPD", "de", "mem\u00f3ria", "polinomial", "unidimensional", "(", "ou", "sem", "mem\u00f3ria", ")", ",", "a", "fim", "de", "resolver", "para", "os", "coeficientes", "polinomiais", "do", "pr\u00e9-distorcedor", "digital", "e", "minimizar", "o", "erro", "quadr\u00e1tico", "m\u00e9dio", "(", "MSE", ")", ",", "a", "sa\u00edda", "distorcida", "do", "sistema", "n\u00e3o-linear", "deve", "ser", "super", "amostrada", "a", "uma", "taxa", "que", "permita", "a", "captura", "dos", "produtos", "n\u00e3o-lineares", "da", "ordem", "do", "pr\u00e9-distorcedor", "digital", "."], "sentence-detokenized": "59, pp. 2547-2553, Out. 2011 Em DPD de mem\u00f3ria polinomial unidimensional (ou sem mem\u00f3ria), a fim de resolver para os coeficientes polinomiais do pr\u00e9-distorcedor digital e minimizar o erro quadr\u00e1tico m\u00e9dio (MSE), a sa\u00edda distorcida do sistema n\u00e3o-linear deve ser super amostrada a uma taxa que permita a captura dos produtos n\u00e3o-lineares da ordem do pr\u00e9-distorcedor digital.", "token2charspan": [[0, 2], [2, 3], [4, 6], [6, 7], [8, 17], [17, 18], [19, 22], [22, 23], [24, 28], [29, 31], [32, 35], [36, 38], [39, 46], [47, 57], [58, 72], [73, 74], [74, 76], [77, 80], [81, 88], [88, 89], [89, 90], [91, 92], [93, 96], [97, 99], [100, 108], [109, 113], [114, 116], [117, 129], [130, 141], [142, 144], [145, 160], [161, 168], [169, 170], [171, 180], [181, 182], [183, 187], [188, 198], [199, 204], [205, 206], [206, 209], [209, 210], [210, 211], [212, 213], [214, 219], [220, 230], [231, 233], [234, 241], [242, 252], [253, 257], [258, 261], [262, 267], [268, 277], [278, 279], [280, 283], [284, 288], [289, 292], [293, 300], [301, 302], [303, 310], [311, 314], [315, 323], [324, 336], [337, 339], [340, 345], [346, 348], [349, 364], [365, 372], [372, 373]]}
{"doc_key": "ai-train-100", "ner": [[0, 1, "researcher"], [14, 15, "location"], [17, 18, "country"], [24, 24, "country"], [39, 45, "organisation"], [47, 50, "organisation"], [52, 52, "location"], [56, 57, "organisation"]], "ner_mapping_to_source": [0, 2, 3, 5, 6, 7, 8, 9], "relations": [[0, 1, 47, 50, "physical", "", false, false], [0, 1, 56, 57, "role", "", false, false], [14, 15, 17, 18, "physical", "", false, false], [39, 45, 47, 50, "part-of", "", false, false], [47, 50, 52, 52, "physical", "", false, false], [56, 57, 39, 45, "part-of", "", false, false]], "relations_mapping_to_source": [1, 2, 4, 5, 6, 7], "sentence": ["Boris", "Katz", ",", "(", "nascido", "em", "5", "de", "outubro", "de", "1947", ",", "Chi\u0219in\u0103u", ",", "Moldavian", "SSR", ",", "Uni\u00e3o", "Sovi\u00e9tica", ",", "(", "agora", "Chi\u0219in\u0103u", ",", "Mold\u00e1via", ")", ")", "\u00e9", "o", "principal", "cientista", "pesquisador", "americano", "(", "cientista", "da", "computa\u00e7\u00e3o", ")", "no", "MIT", "Computer", "Science", "and", "Artificial", "Intelligence", "Laboratory", "do", "Massachusetts", "Institute", "of", "Technology", "em", "Cambridge", "e", "chefe", "do", "Grupo", "InfoLab", "do", "Laborat\u00f3rio", "."], "sentence-detokenized": "Boris Katz, (nascido em 5 de outubro de 1947, Chi\u0219in\u0103u, Moldavian SSR, Uni\u00e3o Sovi\u00e9tica, (agora Chi\u0219in\u0103u, Mold\u00e1via)) \u00e9 o principal cientista pesquisador americano (cientista da computa\u00e7\u00e3o) no MIT Computer Science and Artificial Intelligence Laboratory do Massachusetts Institute of Technology em Cambridge e chefe do Grupo InfoLab do Laborat\u00f3rio.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 13], [13, 20], [21, 23], [24, 25], [26, 28], [29, 36], [37, 39], [40, 44], [44, 45], [46, 54], [54, 55], [56, 65], [66, 69], [69, 70], [71, 76], [77, 86], [86, 87], [88, 89], [89, 94], [95, 103], [103, 104], [105, 113], [113, 114], [114, 115], [116, 117], [118, 119], [120, 129], [130, 139], [140, 151], [152, 161], [162, 163], [163, 172], [173, 175], [176, 186], [186, 187], [188, 190], [191, 194], [195, 203], [204, 211], [212, 215], [216, 226], [227, 239], [240, 250], [251, 253], [254, 267], [268, 277], [278, 280], [281, 291], [292, 294], [295, 304], [305, 306], [307, 312], [313, 315], [316, 321], [322, 329], [330, 332], [333, 344], [344, 345]]}
