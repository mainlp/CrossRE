{"doc_key": "ai-test-1", "ner": [[8, 11, "algorithm"], [15, 17, "algorithm"], [20, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Les", "approches", "typiques", "des", "mod\u00e8les", "g\u00e9n\u00e9ratifs", "comprennent", "les", "classificateurs", "de", "Bayes", "na\u00effs", ",", "les", "mod\u00e8les", "de", "m\u00e9lange", "gaussien", ",", "les", "autoencodeurs", "variationnels", "et", "autres", "."], "sentence-detokenized": "Les approches typiques des mod\u00e8les g\u00e9n\u00e9ratifs comprennent les classificateurs de Bayes na\u00effs, les mod\u00e8les de m\u00e9lange gaussien, les autoencodeurs variationnels et autres.", "token2charspan": [[0, 3], [4, 13], [14, 22], [23, 26], [27, 34], [35, 45], [46, 57], [58, 61], [62, 77], [78, 80], [81, 86], [87, 92], [92, 93], [94, 97], [98, 105], [106, 108], [109, 116], [117, 125], [125, 126], [127, 130], [131, 144], [145, 158], [159, 161], [162, 168], [168, 169]]}
{"doc_key": "ai-test-2", "ner": [[8, 8, "organisation"], [13, 13, "conference"], [16, 24, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 13, 13, "role", "", false, false], [16, 24, 13, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Enfin", ",", "tous", "les", "deux", "ans", ",", "l'", "ELRA", "organise", "une", "grande", "conf\u00e9rence", "LREC", ",", "la", "Conf\u00e9rence", "internationale", "sur", "les", "ressources", "linguistiques", "et", "l'", "\u00e9valuation", "."], "sentence-detokenized": "Enfin, tous les deux ans, l'ELRA organise une grande conf\u00e9rence LREC, la Conf\u00e9rence internationale sur les ressources linguistiques et l'\u00e9valuation.", "token2charspan": [[0, 5], [5, 6], [7, 11], [12, 15], [16, 20], [21, 24], [24, 25], [26, 28], [28, 32], [33, 41], [42, 45], [46, 52], [53, 63], [64, 68], [68, 69], [70, 72], [73, 83], [84, 98], [99, 102], [103, 106], [107, 117], [118, 131], [132, 134], [135, 137], [137, 147], [147, 148]]}
{"doc_key": "ai-test-3", "ner": [[7, 11, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "t\u00e2che", "consiste", "g\u00e9n\u00e9ralement", "\u00e0", "d\u00e9river", "l'", "estimation", "du", "maximum", "de", "vraisemblance", "des", "param\u00e8tres", "du", "HMM", "\u00e9tant", "donn\u00e9", "les", "s\u00e9quences", "de", "sortie", "."], "sentence-detokenized": "La t\u00e2che consiste g\u00e9n\u00e9ralement \u00e0 d\u00e9river l'estimation du maximum de vraisemblance des param\u00e8tres du HMM \u00e9tant donn\u00e9 les s\u00e9quences de sortie.", "token2charspan": [[0, 2], [3, 8], [9, 17], [18, 30], [31, 32], [33, 40], [41, 43], [43, 53], [54, 56], [57, 64], [65, 67], [68, 81], [82, 85], [86, 96], [97, 99], [100, 103], [104, 109], [110, 115], [116, 119], [120, 129], [130, 132], [133, 139], [139, 140]]}
{"doc_key": "ai-test-4", "ner": [[2, 3, "algorithm"], [6, 10, "algorithm"], [17, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 3, 17, 17, "compare", "", false, false], [6, 10, 17, 17, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Contrairement", "aux", "r\u00e9seaux", "neuronaux", "et", "aux", "machines", "\u00e0", "vecteurs", "de", "support", ",", "le", "processus", "de", "formation", "d'", "AdaBoost", "ne", "s\u00e9lectionne", "que", "les", "caract\u00e9ristiques", "connues", "pour", "am\u00e9liorer", "le", "pouvoir", "pr\u00e9dictif", "du", "mod\u00e8le", ",", "ce", "qui", "r\u00e9duit", "la", "dimensionnalit\u00e9", "et", "am\u00e9liore", "potentiellement", "le", "temps", "d'", "ex\u00e9cution", "puisque", "les", "caract\u00e9ristiques", "non", "pertinentes", "ne", "doivent", "pas", "\u00eatre", "calcul\u00e9es", "."], "sentence-detokenized": "Contrairement aux r\u00e9seaux neuronaux et aux machines \u00e0 vecteurs de support, le processus de formation d'AdaBoost ne s\u00e9lectionne que les caract\u00e9ristiques connues pour am\u00e9liorer le pouvoir pr\u00e9dictif du mod\u00e8le, ce qui r\u00e9duit la dimensionnalit\u00e9 et am\u00e9liore potentiellement le temps d'ex\u00e9cution puisque les caract\u00e9ristiques non pertinentes ne doivent pas \u00eatre calcul\u00e9es.", "token2charspan": [[0, 13], [14, 17], [18, 25], [26, 35], [36, 38], [39, 42], [43, 51], [52, 53], [54, 62], [63, 65], [66, 73], [73, 74], [75, 77], [78, 87], [88, 90], [91, 100], [101, 103], [103, 111], [112, 114], [115, 126], [127, 130], [131, 134], [135, 151], [152, 159], [160, 164], [165, 174], [175, 177], [178, 185], [186, 195], [196, 198], [199, 205], [205, 206], [207, 209], [210, 213], [214, 220], [221, 223], [224, 239], [240, 242], [243, 251], [252, 267], [268, 270], [271, 276], [277, 279], [279, 288], [289, 296], [297, 300], [301, 317], [318, 321], [322, 333], [334, 336], [337, 344], [345, 348], [349, 353], [354, 363], [363, 364]]}
{"doc_key": "ai-test-5", "ner": [[0, 1, "misc"], [13, 14, "misc"], [17, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 13, 14, "part-of", "", false, false], [13, 14, 17, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "troponymie", "est", "l'", "une", "des", "relations", "possibles", "entre", "les", "verbes", "dans", "le", "r\u00e9seau", "s\u00e9mantique", "de", "la", "base", "de", "donn\u00e9es", "WordNet", "."], "sentence-detokenized": "La troponymie est l'une des relations possibles entre les verbes dans le r\u00e9seau s\u00e9mantique de la base de donn\u00e9es WordNet.", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 20], [20, 23], [24, 27], [28, 37], [38, 47], [48, 53], [54, 57], [58, 64], [65, 69], [70, 72], [73, 79], [80, 90], [91, 93], [94, 96], [97, 101], [102, 104], [105, 112], [113, 120], [120, 121]]}
{"doc_key": "ai-test-6", "ner": [[9, 11, "task"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 13, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Un", "langage", "cadre", "est", "une", "technologie", "utilis\u00e9e", "pour", "la", "repr\u00e9sentation", "des", "connaissances", "en", "intelligence", "artificielle", "."], "sentence-detokenized": "Un langage cadre est une technologie utilis\u00e9e pour la repr\u00e9sentation des connaissances en intelligence artificielle.", "token2charspan": [[0, 2], [3, 10], [11, 16], [17, 20], [21, 24], [25, 36], [37, 45], [46, 50], [51, 53], [54, 68], [69, 72], [73, 86], [87, 89], [90, 102], [103, 115], [115, 116]]}
{"doc_key": "ai-test-7", "ner": [[0, 1, "metrics"], [6, 10, "metrics"], [16, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 10, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Le", "NIST", "diff\u00e8re", "\u00e9galement", "de", "la", "doublure", "de", "l'", "\u00e9valuation", "bilingue", "dans", "son", "calcul", "de", "la", "p\u00e9nalit\u00e9", "de", "bri\u00e8vet\u00e9", "dans", "la", "mesure", "o\u00f9", "de", "petites", "variations", "de", "la", "longueur", "de", "la", "traduction", "n'", "ont", "pas", "autant", "d'", "impact", "sur", "le", "score", "global", "."], "sentence-detokenized": "Le NIST diff\u00e8re \u00e9galement de la doublure de l'\u00e9valuation bilingue dans son calcul de la p\u00e9nalit\u00e9 de bri\u00e8vet\u00e9 dans la mesure o\u00f9 de petites variations de la longueur de la traduction n'ont pas autant d'impact sur le score global.", "token2charspan": [[0, 2], [3, 7], [8, 15], [16, 25], [26, 28], [29, 31], [32, 40], [41, 43], [44, 46], [46, 56], [57, 65], [66, 70], [71, 74], [75, 81], [82, 84], [85, 87], [88, 96], [97, 99], [100, 108], [109, 113], [114, 116], [117, 123], [124, 126], [127, 129], [130, 137], [138, 148], [149, 151], [152, 154], [155, 163], [164, 166], [167, 169], [170, 180], [181, 183], [183, 186], [187, 190], [191, 197], [198, 200], [200, 206], [207, 210], [211, 213], [214, 219], [220, 226], [226, 227]]}
{"doc_key": "ai-test-8", "ner": [[19, 20, "algorithm"], [23, 25, "algorithm"], [43, 44, "field"], [58, 60, "algorithm"], [63, 66, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 20, 43, 44, "usage", "", false, false], [23, 25, 43, 44, "usage", "", false, false], [58, 60, 43, 44, "type-of", "", false, false], [63, 66, 43, 44, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Le", "mod\u00e8le", "est", "initialement", "ajust\u00e9", "sur", "un", "ensemble", "de", "donn\u00e9es", "d'", "apprentissage", ",", "Le", "mod\u00e8le", "(", "par", "exemple", "un", "r\u00e9seau", "neuronal", "ou", "un", "classificateur", "Bayes", "na\u00eff", ")", "est", "entra\u00een\u00e9", "sur", "l'", "ensemble", "de", "donn\u00e9es", "d'", "apprentissage", "\u00e0", "l'", "aide", "d'", "une", "m\u00e9thode", "d'", "apprentissage", "supervis\u00e9e", ",", "par", "exemple", "\u00e0", "l'", "aide", "de", "m\u00e9thodes", "d'", "optimisation", "telles", "que", "la", "descente", "de", "gradient", "ou", "la", "descente", "de", "gradient", "stochastique", "."], "sentence-detokenized": "Le mod\u00e8le est initialement ajust\u00e9 sur un ensemble de donn\u00e9es d'apprentissage, Le mod\u00e8le (par exemple un r\u00e9seau neuronal ou un classificateur Bayes na\u00eff) est entra\u00een\u00e9 sur l'ensemble de donn\u00e9es d'apprentissage \u00e0 l'aide d'une m\u00e9thode d'apprentissage supervis\u00e9e, par exemple \u00e0 l'aide de m\u00e9thodes d'optimisation telles que la descente de gradient ou la descente de gradient stochastique.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 26], [27, 33], [34, 37], [38, 40], [41, 49], [50, 52], [53, 60], [61, 63], [63, 76], [76, 77], [78, 80], [81, 87], [88, 89], [89, 92], [93, 100], [101, 103], [104, 110], [111, 119], [120, 122], [123, 125], [126, 140], [141, 146], [147, 151], [151, 152], [153, 156], [157, 165], [166, 169], [170, 172], [172, 180], [181, 183], [184, 191], [192, 194], [194, 207], [208, 209], [210, 212], [212, 216], [217, 219], [219, 222], [223, 230], [231, 233], [233, 246], [247, 257], [257, 258], [259, 262], [263, 270], [271, 272], [273, 275], [275, 279], [280, 282], [283, 291], [292, 294], [294, 306], [307, 313], [314, 317], [318, 320], [321, 329], [330, 332], [333, 341], [342, 344], [345, 347], [348, 356], [357, 359], [360, 368], [369, 381], [381, 382]]}
{"doc_key": "ai-test-9", "ner": [[0, 0, "product"], [10, 12, "task"], [15, 15, "task"], [18, 22, "task"], [25, 27, "task"], [38, 41, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 12, 0, 0, "usage", "", true, false], [15, 15, 0, 0, "usage", "", true, false], [18, 22, 0, 0, "usage", "", true, false], [25, 27, 0, 0, "usage", "", true, false], [38, 41, 0, 0, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["FrameNet", "a", "\u00e9t\u00e9", "utilis\u00e9", "dans", "des", "applications", "telles", "que", "la", "r\u00e9ponse", "aux", "questions", ",", "la", "paraphrase", ",", "la", "reconnaissance", "de", "l'", "implication", "textuelle", "et", "l'", "extraction", "d'", "informations", ",", "soit", "directement", ",", "soit", "au", "moyen", "d'", "outils", "d'", "\u00e9tiquetage", "s\u00e9mantique", "des", "r\u00f4les", "."], "sentence-detokenized": "FrameNet a \u00e9t\u00e9 utilis\u00e9 dans des applications telles que la r\u00e9ponse aux questions, la paraphrase, la reconnaissance de l'implication textuelle et l'extraction d'informations, soit directement, soit au moyen d'outils d'\u00e9tiquetage s\u00e9mantique des r\u00f4les.", "token2charspan": [[0, 8], [9, 10], [11, 14], [15, 22], [23, 27], [28, 31], [32, 44], [45, 51], [52, 55], [56, 58], [59, 66], [67, 70], [71, 80], [80, 81], [82, 84], [85, 95], [95, 96], [97, 99], [100, 114], [115, 117], [118, 120], [120, 131], [132, 141], [142, 144], [145, 147], [147, 157], [158, 160], [160, 172], [172, 173], [174, 178], [179, 190], [190, 191], [192, 196], [197, 199], [200, 205], [206, 208], [208, 214], [215, 217], [217, 227], [228, 238], [239, 242], [243, 248], [248, 249]]}
{"doc_key": "ai-test-10", "ner": [[10, 15, "field"], [18, 18, "misc"], [22, 22, "product"], [26, 28, "misc"], [32, 32, "product"], [36, 37, "field"], [41, 41, "product"], [45, 48, "misc"], [52, 52, "product"], [54, 54, "product"], [56, 56, "product"], [60, 63, "misc"], [65, 66, "product"], [68, 69, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[22, 22, 18, 18, "general-affiliation", "", false, false], [32, 32, 26, 28, "general-affiliation", "", false, false], [41, 41, 36, 37, "general-affiliation", "", false, false], [52, 52, 45, 48, "type-of", "", false, false], [54, 54, 45, 48, "type-of", "", false, false], [56, 56, 45, 48, "type-of", "", false, false], [65, 66, 60, 63, "general-affiliation", "", false, false], [68, 69, 60, 63, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Il", "s'", "agit", "de", "programmes", "tels", "que", "les", "outils", "d'", "analyse", "et", "d'", "extraction", "de", "donn\u00e9es", ",", "les", "tableurs", "(", "par", "exemple", "Excel", ")", ",", "les", "bases", "de", "donn\u00e9es", "(", "par", "exemple", "Access", ")", ",", "l'", "analyse", "statistique", "(", "par", "exemple", "SAS", ")", ",", "les", "logiciels", "d'", "audit", "g\u00e9n\u00e9ralis\u00e9", "(", "par", "exemple", "ACL", ",", "Arbutus", ",", "EAS", ")", ",", "la", "veille", "\u00e9conomique", "(", "par", "exemple", "Crystal", "Reports", "et", "Business", "Objects", ")", ",", "etc."], "sentence-detokenized": "Il s'agit de programmes tels que les outils d'analyse et d'extraction de donn\u00e9es, les tableurs (par exemple Excel), les bases de donn\u00e9es (par exemple Access), l'analyse statistique (par exemple SAS), les logiciels d'audit g\u00e9n\u00e9ralis\u00e9 (par exemple ACL, Arbutus, EAS), la veille \u00e9conomique (par exemple Crystal Reports et Business Objects), etc.", "token2charspan": [[0, 2], [3, 5], [5, 9], [10, 12], [13, 23], [24, 28], [29, 32], [33, 36], [37, 43], [44, 46], [46, 53], [54, 56], [57, 59], [59, 69], [70, 72], [73, 80], [80, 81], [82, 85], [86, 94], [95, 96], [96, 99], [100, 107], [108, 113], [113, 114], [114, 115], [116, 119], [120, 125], [126, 128], [129, 136], [137, 138], [138, 141], [142, 149], [150, 156], [156, 157], [157, 158], [159, 161], [161, 168], [169, 180], [181, 182], [182, 185], [186, 193], [194, 197], [197, 198], [198, 199], [200, 203], [204, 213], [214, 216], [216, 221], [222, 232], [233, 234], [234, 237], [238, 245], [246, 249], [249, 250], [251, 258], [258, 259], [260, 263], [263, 264], [264, 265], [266, 268], [269, 275], [276, 286], [287, 288], [288, 291], [292, 299], [300, 307], [308, 315], [316, 318], [319, 327], [328, 335], [335, 336], [336, 337], [338, 342]]}
{"doc_key": "ai-test-11", "ner": [[0, 1, "organisation"], [5, 6, "researcher"], [12, 12, "organisation"], [16, 16, "product"], [26, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 6, "origin", "", false, false], [5, 6, 12, 12, "role", "", false, false], [16, 16, 26, 27, "type-of", "", false, false], [26, 27, 5, 6, "origin", "introduced_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Rethink", "Robotics", ",", "fond\u00e9e", "par", "Rodney", "Brooks", ",", "qui", "travaillait", "auparavant", "pour", "iRobot", ",", "a", "pr\u00e9sent\u00e9", "Baxter", "en", "septembre", "2012", ".", "Il", "s'", "agit", "d'", "un", "robot", "industriel", "con\u00e7u", "pour", "interagir", "en", "toute", "s\u00e9curit\u00e9", "avec", "les", "travailleurs", "humains", "voisins", "et", "programmable", "pour", "effectuer", "des", "t\u00e2ches", "simples", "."], "sentence-detokenized": "Rethink Robotics, fond\u00e9e par Rodney Brooks, qui travaillait auparavant pour iRobot, a pr\u00e9sent\u00e9 Baxter en septembre 2012. Il s'agit d'un robot industriel con\u00e7u pour interagir en toute s\u00e9curit\u00e9 avec les travailleurs humains voisins et programmable pour effectuer des t\u00e2ches simples.", "token2charspan": [[0, 7], [8, 16], [16, 17], [18, 24], [25, 28], [29, 35], [36, 42], [42, 43], [44, 47], [48, 59], [60, 70], [71, 75], [76, 82], [82, 83], [84, 85], [86, 94], [95, 101], [102, 104], [105, 114], [115, 119], [119, 120], [121, 123], [124, 126], [126, 130], [131, 133], [133, 135], [136, 141], [142, 152], [153, 158], [159, 163], [164, 173], [174, 176], [177, 182], [183, 191], [192, 196], [197, 200], [201, 213], [214, 221], [222, 229], [230, 232], [233, 245], [246, 250], [251, 260], [261, 264], [265, 271], [272, 279], [279, 280]]}
{"doc_key": "ai-test-12", "ner": [[4, 6, "field"], [9, 11, "task"], [14, 16, "task"], [19, 23, "task"], [26, 29, "task"], [32, 34, "task"], [37, 39, "task"], [42, 46, "task"], [55, 58, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[9, 11, 4, 6, "part-of", "task_part_of_field", false, false], [14, 16, 4, 6, "part-of", "task_part_of_field", false, false], [19, 23, 4, 6, "part-of", "task_part_of_field", false, false], [26, 29, 4, 6, "part-of", "task_part_of_field", false, false], [32, 34, 4, 6, "part-of", "task_part_of_field", false, false], [37, 39, 4, 6, "part-of", "task_part_of_field", false, false], [42, 46, 4, 6, "part-of", "task_part_of_field", false, false], [55, 58, 4, 6, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Les", "t\u00e2ches", "typiques", "de", "fouille", "de", "textes", "comprennent", "la", "cat\u00e9gorisation", "de", "textes", ",", "le", "regroupement", "de", "textes", ",", "l'", "extraction", "de", "concepts", "/", "entit\u00e9s", ",", "la", "production", "de", "taxonomies", "granulaires", ",", "l'", "analyse", "de", "sentiments", ",", "le", "r\u00e9sum\u00e9", "de", "documents", "et", "la", "mod\u00e9lisation", "des", "relations", "entre", "entit\u00e9s", "(", "c'est-\u00e0-dire", "l'", "apprentissage", "des", "relations", "entre", "la", "reconnaissance", "des", "entit\u00e9s", "nomm\u00e9es", ")", "."], "sentence-detokenized": "Les t\u00e2ches typiques de fouille de textes comprennent la cat\u00e9gorisation de textes, le regroupement de textes, l'extraction de concepts/entit\u00e9s, la production de taxonomies granulaires, l'analyse de sentiments, le r\u00e9sum\u00e9 de documents et la mod\u00e9lisation des relations entre entit\u00e9s (c'est-\u00e0-dire l'apprentissage des relations entre la reconnaissance des entit\u00e9s nomm\u00e9es).", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 22], [23, 30], [31, 33], [34, 40], [41, 52], [53, 55], [56, 70], [71, 73], [74, 80], [80, 81], [82, 84], [85, 97], [98, 100], [101, 107], [107, 108], [109, 111], [111, 121], [122, 124], [125, 133], [133, 134], [134, 141], [141, 142], [143, 145], [146, 156], [157, 159], [160, 170], [171, 182], [182, 183], [184, 186], [186, 193], [194, 196], [197, 207], [207, 208], [209, 211], [212, 218], [219, 221], [222, 231], [232, 234], [235, 237], [238, 250], [251, 254], [255, 264], [265, 270], [271, 278], [279, 280], [280, 292], [293, 295], [295, 308], [309, 312], [313, 322], [323, 328], [329, 331], [332, 346], [347, 350], [351, 358], [359, 366], [366, 367], [367, 368]]}
{"doc_key": "ai-test-13", "ner": [[6, 6, "metrics"], [10, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["N\u00e9anmoins", ",", "le", "stemming", "r\u00e9duit", "la", "pr\u00e9cision", ",", "ou", "le", "taux", "de", "VRAI", "n\u00e9gatif", ",", "pour", "ces", "syst\u00e8mes", "."], "sentence-detokenized": "N\u00e9anmoins, le stemming r\u00e9duit la pr\u00e9cision, ou le taux de VRAI n\u00e9gatif, pour ces syst\u00e8mes.", "token2charspan": [[0, 9], [9, 10], [11, 13], [14, 22], [23, 29], [30, 32], [33, 42], [42, 43], [44, 46], [47, 49], [50, 54], [55, 57], [58, 62], [63, 70], [70, 71], [72, 76], [77, 80], [81, 89], [89, 90]]}
{"doc_key": "ai-test-14", "ner": [[4, 6, "task"], [11, 13, "misc"], [17, 18, "misc"], [28, 28, "product"], [30, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 13, 4, 6, "temporal", "", false, false], [17, 18, 11, 13, "named", "", false, false], [28, 28, 11, 13, "usage", "", false, false], [30, 30, 11, 13, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Un", "cas", "particulier", "de", "rep\u00e9rage", "de", "mots-cl\u00e9s", "est", "la", "d\u00e9tection", "de", "mots", "d'", "\u00e9veil", "(", "\u00e9galement", "appel\u00e9s", "mots", "chauds", ")", "utilis\u00e9e", "par", "les", "assistants", "num\u00e9riques", "personnels", "tels", "qu'", "Alexa", "ou", "Siri", "pour", "se", "r\u00e9veiller", "lorsque", "leur", "nom", "est", "prononc\u00e9", "."], "sentence-detokenized": "Un cas particulier de rep\u00e9rage de mots-cl\u00e9s est la d\u00e9tection de mots d'\u00e9veil (\u00e9galement appel\u00e9s mots chauds) utilis\u00e9e par les assistants num\u00e9riques personnels tels qu'Alexa ou Siri pour se r\u00e9veiller lorsque leur nom est prononc\u00e9.", "token2charspan": [[0, 2], [3, 6], [7, 18], [19, 21], [22, 30], [31, 33], [34, 43], [44, 47], [48, 50], [51, 60], [61, 63], [64, 68], [69, 71], [71, 76], [77, 78], [78, 87], [88, 95], [96, 100], [101, 107], [107, 108], [109, 117], [118, 121], [122, 125], [126, 136], [137, 147], [148, 158], [159, 163], [164, 167], [167, 172], [173, 175], [176, 180], [181, 185], [186, 188], [189, 198], [199, 206], [207, 211], [212, 215], [216, 219], [220, 228], [228, 229]]}
{"doc_key": "ai-test-15", "ner": [[0, 0, "programlang"], [10, 10, "programlang"], [12, 12, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 0, 0, "part-of", "", false, false], [12, 12, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prova", "est", "un", "langage", "de", "programmation", "open", "source", "qui", "combine", "Prolog", "et", "Java", "."], "sentence-detokenized": "Prova est un langage de programmation open source qui combine Prolog et Java.", "token2charspan": [[0, 5], [6, 9], [10, 12], [13, 20], [21, 23], [24, 37], [38, 42], [43, 49], [50, 53], [54, 61], [62, 68], [69, 71], [72, 76], [76, 77]]}
{"doc_key": "ai-test-16", "ner": [[3, 4, "organisation"], [9, 9, "organisation"], [22, 23, "product"], [19, 20, "country"], [39, 39, "organisation"], [53, 53, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 9, 9, "part-of", "", false, false], [3, 4, 9, 9, "role", "sells", false, false], [3, 4, 19, 20, "role", "sells_to", false, false], [39, 39, 53, 53, "opposite", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["En", "1987", ",", "Tocibai", "Machine", ",", "une", "filiale", "de", "Toshiba", ",", "a", "\u00e9t\u00e9", "accus\u00e9e", "de", "vendre", "ill\u00e9galement", "\u00e0", "l'", "Union", "sovi\u00e9tique", "des", "fraisages", "CNC", "utilis\u00e9s", "pour", "produire", "des", "h\u00e9lices", "de", "sous-marins", "tr\u00e8s", "silencieuses", ",", "en", "violation", "de", "l'", "accord", "CoCom", ",", "un", "embargo", "international", "impos\u00e9", "\u00e0", "certains", "pays", "\u00e0", "destination", "des", "pays", "du", "COMECON", "."], "sentence-detokenized": "En 1987, Tocibai Machine, une filiale de Toshiba, a \u00e9t\u00e9 accus\u00e9e de vendre ill\u00e9galement \u00e0 l'Union sovi\u00e9tique des fraisages CNC utilis\u00e9s pour produire des h\u00e9lices de sous-marins tr\u00e8s silencieuses, en violation de l'accord CoCom, un embargo international impos\u00e9 \u00e0 certains pays \u00e0 destination des pays du COMECON.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 24], [24, 25], [26, 29], [30, 37], [38, 40], [41, 48], [48, 49], [50, 51], [52, 55], [56, 63], [64, 66], [67, 73], [74, 86], [87, 88], [89, 91], [91, 96], [97, 107], [108, 111], [112, 121], [122, 125], [126, 134], [135, 139], [140, 148], [149, 152], [153, 160], [161, 163], [164, 175], [176, 180], [181, 193], [193, 194], [195, 197], [198, 207], [208, 210], [211, 213], [213, 219], [220, 225], [225, 226], [227, 229], [230, 237], [238, 251], [252, 258], [259, 260], [261, 269], [270, 274], [275, 276], [277, 288], [289, 292], [293, 297], [298, 300], [301, 308], [308, 309]]}
{"doc_key": "ai-test-17", "ner": [[6, 6, "researcher"], [9, 12, "product"], [21, 24, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 12, 6, 6, "artifact", "", false, false], [9, 12, 21, 24, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "co-invention", "la", "plus", "c\u00e9l\u00e8bre", "d'", "Engelberger", ",", "le", "bras", "robotique", "industriel", "Unimate", ",", "a", "fait", "partie", "des", "premiers", "intronis\u00e9s", "au", "Robot", "Hall", "of", "Fame", "en", "2003", "."], "sentence-detokenized": "La co-invention la plus c\u00e9l\u00e8bre d'Engelberger, le bras robotique industriel Unimate, a fait partie des premiers intronis\u00e9s au Robot Hall of Fame en 2003.", "token2charspan": [[0, 2], [3, 15], [16, 18], [19, 23], [24, 31], [32, 34], [34, 45], [45, 46], [47, 49], [50, 54], [55, 64], [65, 75], [76, 83], [83, 84], [85, 86], [87, 91], [92, 98], [99, 102], [103, 111], [112, 122], [123, 125], [126, 131], [132, 136], [137, 139], [140, 144], [145, 147], [148, 152], [152, 153]]}
{"doc_key": "ai-test-18", "ner": [[6, 7, "misc"], [10, 10, "misc"], [15, 16, "person"], [25, 26, "field"], [23, 23, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 7, 10, 10, "usage", "", false, false], [15, 16, 25, 26, "role", "", false, false], [25, 26, 23, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Initialement", "contr\u00f4l\u00e9", "par", "des", "pages", "web", "html", "statiques", "utilisant", "des", "CGI", ",", "le", "travail", "de", "Dalton", "a", "vu", "l'", "introduction", "d'", "une", "interface", "Java", "\u00e0", "r\u00e9alit\u00e9", "augment\u00e9e", "qui", "a", "rencontr\u00e9", "un", "succ\u00e8s", "limit\u00e9", "."], "sentence-detokenized": "Initialement contr\u00f4l\u00e9 par des pages web html statiques utilisant des CGI, le travail de Dalton a vu l'introduction d'une interface Java \u00e0 r\u00e9alit\u00e9 augment\u00e9e qui a rencontr\u00e9 un succ\u00e8s limit\u00e9.", "token2charspan": [[0, 12], [13, 21], [22, 25], [26, 29], [30, 35], [36, 39], [40, 44], [45, 54], [55, 64], [65, 68], [69, 72], [72, 73], [74, 76], [77, 84], [85, 87], [88, 94], [95, 96], [97, 99], [100, 102], [102, 114], [115, 117], [117, 120], [121, 130], [131, 135], [136, 137], [138, 145], [146, 155], [156, 159], [160, 161], [162, 171], [172, 174], [175, 181], [182, 188], [188, 189]]}
{"doc_key": "ai-test-19", "ner": [[5, 6, "task"], [15, 15, "organisation"], [35, 35, "conference"], [39, 39, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 15, 15, "origin", "", false, false], [35, 35, 39, 39, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "premi\u00e8re", "publication", "sur", "la", "sp\u00e9cification", "LMF", "telle", "qu'", "elle", "a", "\u00e9t\u00e9", "ratifi\u00e9e", "par", "l'", "ISO", "(", "cet", "article", "est", "devenu", "(", "en", "2015", ")", "le", "9e", "article", "le", "plus", "cit\u00e9", "au", "sein", "des", "conf\u00e9rences", "LREC", "parmi", "les", "articles", "LREC", ")", ":"], "sentence-detokenized": "La premi\u00e8re publication sur la sp\u00e9cification LMF telle qu'elle a \u00e9t\u00e9 ratifi\u00e9e par l'ISO (cet article est devenu (en 2015) le 9e article le plus cit\u00e9 au sein des conf\u00e9rences LREC parmi les articles LREC) :", "token2charspan": [[0, 2], [3, 11], [12, 23], [24, 27], [28, 30], [31, 44], [45, 48], [49, 54], [55, 58], [58, 62], [63, 64], [65, 68], [69, 77], [78, 81], [82, 84], [84, 87], [88, 89], [89, 92], [93, 100], [101, 104], [105, 111], [112, 113], [113, 115], [116, 120], [120, 121], [122, 124], [125, 127], [128, 135], [136, 138], [139, 143], [144, 148], [149, 151], [152, 156], [157, 160], [161, 172], [173, 177], [178, 183], [184, 187], [188, 196], [197, 201], [201, 202], [203, 204]]}
{"doc_key": "ai-test-20", "ner": [[1, 3, "metrics"], [16, 16, "metrics"], [19, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 16, 1, 3, "usage", "", false, false], [16, 16, 19, 22, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Une", "matrice", "de", "confusion", "ou", "matrice", "de", "correspondance", "est", "souvent", "utilis\u00e9e", "comme", "outil", "pour", "valider", "la", "pr\u00e9cision", "de", "la", "classification", "k", "-", "NN", "."], "sentence-detokenized": "Une matrice de confusion ou matrice de correspondance est souvent utilis\u00e9e comme outil pour valider la pr\u00e9cision de la classification k -NN.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 24], [25, 27], [28, 35], [36, 38], [39, 53], [54, 57], [58, 65], [66, 74], [75, 80], [81, 86], [87, 91], [92, 99], [100, 102], [103, 112], [113, 115], [116, 118], [119, 133], [134, 135], [136, 137], [137, 139], [139, 140]]}
{"doc_key": "ai-test-21", "ner": [[3, 5, "algorithm"], [16, 16, "field"], [19, 21, "field"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 5, 16, 16, "part-of", "", false, false], [3, 5, 19, 21, "part-of", "", false, false], [3, 5, 24, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["L'", "apprentissage", "par", "arbre", "de", "d\u00e9cision", "est", "l'", "une", "des", "approches", "de", "mod\u00e9lisation", "pr\u00e9dictive", "utilis\u00e9es", "en", "statistique", ",", "en", "exploration", "de", "donn\u00e9es", "et", "en", "apprentissage", "automatique", "."], "sentence-detokenized": "L'apprentissage par arbre de d\u00e9cision est l'une des approches de mod\u00e9lisation pr\u00e9dictive utilis\u00e9es en statistique, en exploration de donn\u00e9es et en apprentissage automatique.", "token2charspan": [[0, 2], [2, 15], [16, 19], [20, 25], [26, 28], [29, 37], [38, 41], [42, 44], [44, 47], [48, 51], [52, 61], [62, 64], [65, 77], [78, 88], [89, 98], [99, 101], [102, 113], [113, 114], [115, 117], [118, 129], [130, 132], [133, 140], [141, 143], [144, 146], [147, 160], [161, 172], [172, 173]]}
{"doc_key": "ai-test-22", "ner": [[7, 7, "misc"], [23, 25, "field"], [29, 31, "algorithm"], [33, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 23, 25, "related-to", "", true, false], [29, 31, 23, 25, "type-of", "", false, false], [33, 33, 23, 25, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Au", "moment", "de", "l'", "ex\u00e9cution", ",", "la", "prosodie", "cible", "d'", "une", "phrase", "est", "superpos\u00e9e", "\u00e0", "ces", "unit\u00e9s", "minimales", "au", "moyen", "de", "techniques", "de", "traitement", "du", "signal", "telles", "que", "le", "codage", "pr\u00e9dictif", "lin\u00e9aire", ",", "PSOLA"], "sentence-detokenized": "Au moment de l'ex\u00e9cution, la prosodie cible d'une phrase est superpos\u00e9e \u00e0 ces unit\u00e9s minimales au moyen de techniques de traitement du signal telles que le codage pr\u00e9dictif lin\u00e9aire, PSOLA", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 15], [15, 24], [24, 25], [26, 28], [29, 37], [38, 43], [44, 46], [46, 49], [50, 56], [57, 60], [61, 71], [72, 73], [74, 77], [78, 84], [85, 94], [95, 97], [98, 103], [104, 106], [107, 117], [118, 120], [121, 131], [132, 134], [135, 141], [142, 148], [149, 152], [153, 155], [156, 162], [163, 172], [173, 181], [181, 182], [183, 188]]}
{"doc_key": "ai-test-23", "ner": [[7, 8, "field"], [12, 13, "field"], [22, 23, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 23, 7, 8, "usage", "", true, false], [22, 23, 12, 13, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cette", "approche", "a", "fait", "appel", "\u00e0", "l'", "intelligence", "artificielle", "et", "\u00e0", "l'", "apprentissage", "automatique", "pour", "permettre", "aux", "chercheurs", "de", "comparer", "visiblement", "l'", "imagerie", "faciale", "conventionnelle", "et", "thermique", "."], "sentence-detokenized": "Cette approche a fait appel \u00e0 l'intelligence artificielle et \u00e0 l'apprentissage automatique pour permettre aux chercheurs de comparer visiblement l'imagerie faciale conventionnelle et thermique.", "token2charspan": [[0, 5], [6, 14], [15, 16], [17, 21], [22, 27], [28, 29], [30, 32], [32, 44], [45, 57], [58, 60], [61, 62], [63, 65], [65, 78], [79, 90], [91, 95], [96, 105], [106, 109], [110, 120], [121, 123], [124, 132], [133, 144], [145, 147], [147, 155], [156, 163], [164, 179], [180, 182], [183, 192], [192, 193]]}
{"doc_key": "ai-test-24", "ner": [[1, 1, "field"], [4, 5, "algorithm"], [12, 13, "task"], [17, 18, "misc"], [25, 26, "field"], [30, 31, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 1, 1, "part-of", "", false, false], [4, 5, 12, 13, "topic", "", false, false], [12, 13, 17, 18, "origin", "", false, false], [25, 26, 1, 1, "part-of", "", false, false], [25, 26, 4, 5, "topic", "", false, false], [30, 31, 1, 1, "part-of", "", false, false], [30, 31, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["En", "informatique", ",", "le", "calcul", "\u00e9volutionnaire", "est", "une", "famille", "d'", "algorithmes", "d'", "optimisation", "globale", "inspir\u00e9e", "de", "l'", "\u00e9volution", "biologique", ",", "et", "le", "sous-domaine", "de", "l'", "intelligence", "artificielle", "et", "de", "l'", "informatique", "douce", "qui", "\u00e9tudie", "ces", "algorithmes", "."], "sentence-detokenized": "En informatique, le calcul \u00e9volutionnaire est une famille d'algorithmes d'optimisation globale inspir\u00e9e de l'\u00e9volution biologique, et le sous-domaine de l'intelligence artificielle et de l'informatique douce qui \u00e9tudie ces algorithmes.", "token2charspan": [[0, 2], [3, 15], [15, 16], [17, 19], [20, 26], [27, 41], [42, 45], [46, 49], [50, 57], [58, 60], [60, 71], [72, 74], [74, 86], [87, 94], [95, 103], [104, 106], [107, 109], [109, 118], [119, 129], [129, 130], [131, 133], [134, 136], [137, 149], [150, 152], [153, 155], [155, 167], [168, 180], [181, 183], [184, 186], [187, 189], [189, 201], [202, 207], [208, 211], [212, 218], [219, 222], [223, 234], [234, 235]]}
{"doc_key": "ai-test-25", "ner": [[11, 13, "metrics"], [16, 18, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Par", "exemple", ",", "on", "peut", "combiner", "une", "mesure", "bas\u00e9e", "sur", "la", "matrice", "de", "confusion", "avec", "l'", "erreur", "quadratique", "moyenne", "\u00e9valu\u00e9e", "entre", "les", "sorties", "brutes", "du", "mod\u00e8le", "et", "les", "valeurs", "r\u00e9elles", "."], "sentence-detokenized": "Par exemple, on peut combiner une mesure bas\u00e9e sur la matrice de confusion avec l'erreur quadratique moyenne \u00e9valu\u00e9e entre les sorties brutes du mod\u00e8le et les valeurs r\u00e9elles.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 20], [21, 29], [30, 33], [34, 40], [41, 46], [47, 50], [51, 53], [54, 61], [62, 64], [65, 74], [75, 79], [80, 82], [82, 88], [89, 100], [101, 108], [109, 116], [117, 122], [123, 126], [127, 134], [135, 141], [142, 144], [145, 151], [152, 154], [155, 158], [159, 166], [167, 174], [174, 175]]}
{"doc_key": "ai-test-26", "ner": [[6, 7, "product"], [10, 10, "researcher"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 10, 10, "origin", "", false, false], [6, 7, 17, 17, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "majorit\u00e9", "sont", "des", "r\u00e9sultats", "du", "mod\u00e8le", "word2vec", "d\u00e9velopp\u00e9", "par", "Mikolov", "et", "al", "ou", "des", "variantes", "de", "word2vec", "."], "sentence-detokenized": "La majorit\u00e9 sont des r\u00e9sultats du mod\u00e8le word2vec d\u00e9velopp\u00e9 par Mikolov et al ou des variantes de word2vec.", "token2charspan": [[0, 2], [3, 11], [12, 16], [17, 20], [21, 30], [31, 33], [34, 40], [41, 49], [50, 59], [60, 63], [64, 71], [72, 74], [75, 77], [78, 80], [81, 84], [85, 94], [95, 97], [98, 106], [106, 107]]}
{"doc_key": "ai-test-27", "ner": [[18, 18, "conference"], [21, 25, "conference"], [27, 27, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[27, 27, 21, 25, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["C'", "est", "au", "cours", "de", "cette", "p\u00e9riode", "qu'", "un", "total", "de", "43", "publications", "ont", "\u00e9t\u00e9", "reconnues", "par", "la", "CVPR", "et", "l'", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "."], "sentence-detokenized": "C'est au cours de cette p\u00e9riode qu'un total de 43 publications ont \u00e9t\u00e9 reconnues par la CVPR et l'International Conference on Computer Vision (ICCV).", "token2charspan": [[0, 2], [2, 5], [6, 8], [9, 14], [15, 17], [18, 23], [24, 31], [32, 35], [35, 37], [38, 43], [44, 46], [47, 49], [50, 62], [63, 66], [67, 70], [71, 80], [81, 84], [85, 87], [88, 92], [93, 95], [96, 98], [98, 111], [112, 122], [123, 125], [126, 134], [135, 141], [142, 143], [143, 147], [147, 148], [148, 149]]}
{"doc_key": "ai-test-28", "ner": [[0, 1, "product"], [17, 18, "field"], [27, 31, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 17, 18, "general-affiliation", "platform_for_education_about", false, false], [27, 31, 0, 1, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["L'", "AIBO", "a", "\u00e9t\u00e9", "tr\u00e8s", "utilis\u00e9", "comme", "plateforme", "peu", "co\u00fbteuse", "pour", "l'", "enseignement", "et", "la", "recherche", "en", "intelligence", "artificielle", ",", "car", "il", "int\u00e8gre", "un", "ordinateur", ",", "un", "syst\u00e8me", "de", "vision", "par", "ordinateur", "et", "des", "articulateurs", "dans", "un", "ensemble", "beaucoup", "moins", "cher", "que", "les", "robots", "de", "recherche", "conventionnels", "."], "sentence-detokenized": "L'AIBO a \u00e9t\u00e9 tr\u00e8s utilis\u00e9 comme plateforme peu co\u00fbteuse pour l'enseignement et la recherche en intelligence artificielle, car il int\u00e8gre un ordinateur, un syst\u00e8me de vision par ordinateur et des articulateurs dans un ensemble beaucoup moins cher que les robots de recherche conventionnels.", "token2charspan": [[0, 2], [2, 6], [7, 8], [9, 12], [13, 17], [18, 25], [26, 31], [32, 42], [43, 46], [47, 55], [56, 60], [61, 63], [63, 75], [76, 78], [79, 81], [82, 91], [92, 94], [95, 107], [108, 120], [120, 121], [122, 125], [126, 128], [129, 136], [137, 139], [140, 150], [150, 151], [152, 154], [155, 162], [163, 165], [166, 172], [173, 176], [177, 187], [188, 190], [191, 194], [195, 208], [209, 213], [214, 216], [217, 225], [226, 234], [235, 240], [241, 245], [246, 249], [250, 253], [254, 260], [261, 263], [264, 273], [274, 288], [288, 289]]}
{"doc_key": "ai-test-29", "ner": [[8, 13, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Elle", "a", "\u00e9t\u00e9", "pr\u00e9sidente", "du", "programme", "de", "l'", "International", "Conference", "on", "Computer", "Vision", "2021", "."], "sentence-detokenized": "Elle a \u00e9t\u00e9 pr\u00e9sidente du programme de l'International Conference on Computer Vision 2021.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 21], [22, 24], [25, 34], [35, 37], [38, 40], [40, 53], [54, 64], [65, 67], [68, 76], [77, 83], [84, 88], [88, 89]]}
{"doc_key": "ai-test-30", "ner": [[0, 0, "researcher"], [8, 8, "organisation"], [19, 19, "organisation"], [28, 29, "organisation"], [40, 45, "product"], [47, 47, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 8, 8, "role", "", false, false], [0, 0, 19, 19, "role", "", true, false], [19, 19, 28, 29, "role", "develops_with", false, false], [40, 45, 19, 19, "artifact", "", false, false], [47, 47, 40, 45, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Scheinman", ",", "apr\u00e8s", "avoir", "re\u00e7u", "une", "bourse", "d'", "Unimation", "pour", "d\u00e9velopper", "ses", "conceptions", ",", "a", "vendu", "ces", "conceptions", "\u00e0", "Unimation", "qui", "les", "a", "d\u00e9velopp\u00e9es", "avec", "le", "soutien", "de", "General", "Motors", "et", "les", "a", "commercialis\u00e9es", "plus", "tard", "sous", "le", "nom", "de", "machine", "universelle", "programmable", "pour", "l'", "assemblage", "(", "PUMA", ")", "."], "sentence-detokenized": "Scheinman, apr\u00e8s avoir re\u00e7u une bourse d'Unimation pour d\u00e9velopper ses conceptions, a vendu ces conceptions \u00e0 Unimation qui les a d\u00e9velopp\u00e9es avec le soutien de General Motors et les a commercialis\u00e9es plus tard sous le nom de machine universelle programmable pour l'assemblage (PUMA).", "token2charspan": [[0, 9], [9, 10], [11, 16], [17, 22], [23, 27], [28, 31], [32, 38], [39, 41], [41, 50], [51, 55], [56, 66], [67, 70], [71, 82], [82, 83], [84, 85], [86, 91], [92, 95], [96, 107], [108, 109], [110, 119], [120, 123], [124, 127], [128, 129], [130, 141], [142, 146], [147, 149], [150, 157], [158, 160], [161, 168], [169, 175], [176, 178], [179, 182], [183, 184], [185, 200], [201, 205], [206, 210], [211, 215], [216, 218], [219, 222], [223, 225], [226, 233], [234, 245], [246, 258], [259, 263], [264, 266], [266, 276], [277, 278], [278, 282], [282, 283], [283, 284]]}
{"doc_key": "ai-test-31", "ner": [[10, 11, "task"], [8, 15, "task"], [19, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 19, 10, 11, "general-affiliation", "works_with", false, false], [19, 19, 8, 15, "general-affiliation", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Un", "aper\u00e7u", "des", "m\u00e9thodes", "de", "calibration", "pour", "les", "t\u00e2ches", "de", "classification", "binaire", "et", "de", "classification", "multiclasse", "est", "donn\u00e9", "par", "Gebel", "(", "2009", ")"], "sentence-detokenized": "Un aper\u00e7u des m\u00e9thodes de calibration pour les t\u00e2ches de classification binaire et de classification multiclasse est donn\u00e9 par Gebel (2009)", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 22], [23, 25], [26, 37], [38, 42], [43, 46], [47, 53], [54, 56], [57, 71], [72, 79], [80, 82], [83, 85], [86, 100], [101, 112], [113, 116], [117, 122], [123, 126], [127, 132], [133, 134], [134, 138], [138, 139]]}
{"doc_key": "ai-test-32", "ner": [[9, 12, "task"], [14, 14, "task"], [18, 19, "task"], [24, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 14, 9, 12, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Il", "est", "impliqu\u00e9", "dans", "des", "domaines", "tels", "que", "la", "reconnaissance", "optique", "de", "caract\u00e8res", "(", "OCR", ")", ",", "la", "synth\u00e8se", "vocale", ",", "la", "technologie", "de", "reconnaissance", "vocale", "et", "les", "instruments", "\u00e0", "clavier", "\u00e9lectronique", "."], "sentence-detokenized": "Il est impliqu\u00e9 dans des domaines tels que la reconnaissance optique de caract\u00e8res (OCR), la synth\u00e8se vocale, la technologie de reconnaissance vocale et les instruments \u00e0 clavier \u00e9lectronique.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 20], [21, 24], [25, 33], [34, 38], [39, 42], [43, 45], [46, 60], [61, 68], [69, 71], [72, 82], [83, 84], [84, 87], [87, 88], [88, 89], [90, 92], [93, 101], [102, 108], [108, 109], [110, 112], [113, 124], [125, 127], [128, 142], [143, 149], [150, 152], [153, 156], [157, 168], [169, 170], [171, 178], [179, 191], [191, 192]]}
{"doc_key": "ai-test-33", "ner": [[13, 16, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Pour", "les", "techniques", "plus", "r\u00e9centes", "et", "\u00e0", "la", "pointe", "du", "progr\u00e8s", ",", "la", "bo\u00eete", "\u00e0", "outils", "Kaldi", "peut", "\u00eatre", "utilis\u00e9e", "."], "sentence-detokenized": "Pour les techniques plus r\u00e9centes et \u00e0 la pointe du progr\u00e8s, la bo\u00eete \u00e0 outils Kaldi peut \u00eatre utilis\u00e9e.", "token2charspan": [[0, 4], [5, 8], [9, 19], [20, 24], [25, 33], [34, 36], [37, 38], [39, 41], [42, 48], [49, 51], [52, 59], [59, 60], [61, 63], [64, 69], [70, 71], [72, 78], [79, 84], [85, 89], [90, 94], [95, 103], [103, 104]]}
{"doc_key": "ai-test-34", "ner": [[0, 1, "researcher"], [6, 8, "organisation"], [12, 13, "organisation"], [17, 18, "organisation"], [27, 28, "researcher"], [22, 25, "organisation"], [33, 35, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 6, 8, "role", "", false, false], [0, 1, 12, 13, "role", "", false, false], [0, 1, 17, 18, "role", "", false, false], [0, 1, 22, 25, "role", "", false, false], [0, 1, 33, 35, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Mme", "Johnson-Laird", "est", "membre", "de", "l'", "American", "Philosophical", "Society", ",", "de", "la", "Royal", "Society", ",", "de", "la", "British", "Academy", ",", "de", "l'", "Association", "for", "Psychological", "Science", "(", "William", "James", ")", "et", "de", "la", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Mme Johnson-Laird est membre de l'American Philosophical Society, de la Royal Society, de la British Academy, de l'Association for Psychological Science (William James) et de la Cognitive Science Society.", "token2charspan": [[0, 3], [4, 17], [18, 21], [22, 28], [29, 31], [32, 34], [34, 42], [43, 56], [57, 64], [64, 65], [66, 68], [69, 71], [72, 77], [78, 85], [85, 86], [87, 89], [90, 92], [93, 100], [101, 108], [108, 109], [110, 112], [113, 115], [115, 126], [127, 130], [131, 144], [145, 152], [153, 154], [154, 161], [162, 167], [167, 168], [169, 171], [172, 174], [175, 177], [178, 187], [188, 195], [196, 203], [203, 204]]}
{"doc_key": "ai-test-35", "ner": [[3, 12, "conference"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 23, "researcher"], [27, 28, "algorithm"], [34, 40, "task"], [42, 42, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[16, 17, 3, 12, "physical", "", false, false], [16, 17, 3, 12, "temporal", "", false, false], [19, 20, 3, 12, "physical", "", false, false], [19, 20, 3, 12, "temporal", "", false, false], [22, 23, 3, 12, "physical", "", false, false], [22, 23, 3, 12, "temporal", "", false, false], [27, 28, 22, 23, "role", "extends", false, false], [34, 40, 22, 23, "role", "extends", false, false], [42, 42, 34, 40, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Lors", "de", "la", "conf\u00e9rence", "internationale", "de", "l'", "IEEE", "sur", "le", "traitement", "des", "images", "en", "2010", ",", "Rui", "Hu", ",", "Mark", "Banard", "et", "John", "Collomosse", "ont", "\u00e9tendu", "le", "descripteur", "HOG", "pour", "l'", "utiliser", "dans", "la", "recherche", "d'", "images", "bas\u00e9e", "sur", "des", "croquis", "(", "SBIR", ")", "."], "sentence-detokenized": "Lors de la conf\u00e9rence internationale de l'IEEE sur le traitement des images en 2010, Rui Hu, Mark Banard et John Collomosse ont \u00e9tendu le descripteur HOG pour l'utiliser dans la recherche d'images bas\u00e9e sur des croquis (SBIR).", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 21], [22, 36], [37, 39], [40, 42], [42, 46], [47, 50], [51, 53], [54, 64], [65, 68], [69, 75], [76, 78], [79, 83], [83, 84], [85, 88], [89, 91], [91, 92], [93, 97], [98, 104], [105, 107], [108, 112], [113, 123], [124, 127], [128, 134], [135, 137], [138, 149], [150, 153], [154, 158], [159, 161], [161, 169], [170, 174], [175, 177], [178, 187], [188, 190], [190, 196], [197, 202], [203, 206], [207, 210], [211, 218], [219, 220], [220, 224], [224, 225], [225, 226]]}
{"doc_key": "ai-test-36", "ner": [[0, 1, "metrics"], [7, 7, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 7, 7, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Le", "BLEU", "utilise", "une", "forme", "modifi\u00e9e", "de", "pr\u00e9cision", "pour", "comparer", "une", "traduction", "candidate", "\u00e0", "plusieurs", "traductions", "de", "r\u00e9f\u00e9rence", "."], "sentence-detokenized": "Le BLEU utilise une forme modifi\u00e9e de pr\u00e9cision pour comparer une traduction candidate \u00e0 plusieurs traductions de r\u00e9f\u00e9rence.", "token2charspan": [[0, 2], [3, 7], [8, 15], [16, 19], [20, 25], [26, 34], [35, 37], [38, 47], [48, 52], [53, 61], [62, 65], [66, 76], [77, 86], [87, 88], [89, 98], [99, 110], [111, 113], [114, 123], [123, 124]]}
{"doc_key": "ai-test-37", "ner": [[39, 40, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Pour", "le", "cas", "d'", "un", "espace", "de", "base", "g\u00e9n\u00e9ral", "math", "(", "Y", ",", "\\", "mathcal", "{B}", ",", "\\", "nu", ")", "/", "math", "(", "c'est-\u00e0-dire", "un", "espace", "de", "base", "qui", "n'", "est", "pas", "d\u00e9nombrable", ")", ",", "on", "consid\u00e8re", "typiquement", "l'", "entropie", "relative", "."], "sentence-detokenized": "Pour le cas d'un espace de base g\u00e9n\u00e9ral math (Y,\\ mathcal {B},\\ nu) / math (c'est-\u00e0-dire un espace de base qui n'est pas d\u00e9nombrable), on consid\u00e8re typiquement l'entropie relative.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 14], [14, 16], [17, 23], [24, 26], [27, 31], [32, 39], [40, 44], [45, 46], [46, 47], [47, 48], [48, 49], [50, 57], [58, 61], [61, 62], [62, 63], [64, 66], [66, 67], [68, 69], [70, 74], [75, 76], [76, 88], [89, 91], [92, 98], [99, 101], [102, 106], [107, 110], [111, 113], [113, 116], [117, 120], [121, 132], [132, 133], [133, 134], [135, 137], [138, 147], [148, 159], [160, 162], [162, 170], [171, 179], [179, 180]]}
{"doc_key": "ai-test-38", "ner": [[17, 17, "country"], [10, 12, "organisation"], [14, 14, "organisation"], [25, 25, "country"], [19, 20, "organisation"], [22, 22, "organisation"], [27, 29, "organisation"], [42, 43, "country"], [32, 37, "organisation"], [39, 39, "organisation"], [41, 41, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11], "relations": [[10, 12, 17, 17, "physical", "", false, false], [14, 14, 10, 12, "named", "", false, false], [19, 20, 25, 25, "physical", "", false, false], [22, 22, 19, 20, "named", "", false, false], [32, 37, 42, 43, "physical", "", false, false], [39, 39, 32, 37, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["En", "octobre", "2011", ",", "les", "partenariats", "d\u00e9j\u00e0", "existants", "avec", "le", "National", "Park", "Service", "(", "NPS", ")", "des", "\u00c9tats-Unis", ",", "Historic", "Scotland", "(", "HS", ")", "du", "Royaume-Uni", ",", "World", "Monuments", "Fund", "et", "l'", "Instituto", "Nacional", "de", "Antropolog\u00eda", "y", "Historia", "(", "INAH", ")", "du", "Mexique", "ont", "\u00e9t\u00e9", "consid\u00e9rablement", "\u00e9largis", "."], "sentence-detokenized": "En octobre 2011, les partenariats d\u00e9j\u00e0 existants avec le National Park Service (NPS) des \u00c9tats-Unis, Historic Scotland (HS) du Royaume-Uni, World Monuments Fund et l'Instituto Nacional de Antropolog\u00eda y Historia (INAH) du Mexique ont \u00e9t\u00e9 consid\u00e9rablement \u00e9largis.", "token2charspan": [[0, 2], [3, 10], [11, 15], [15, 16], [17, 20], [21, 33], [34, 38], [39, 48], [49, 53], [54, 56], [57, 65], [66, 70], [71, 78], [79, 80], [80, 83], [83, 84], [85, 88], [89, 99], [99, 100], [101, 109], [110, 118], [119, 120], [120, 122], [122, 123], [124, 126], [127, 138], [138, 139], [140, 145], [146, 155], [156, 160], [161, 163], [164, 166], [166, 175], [176, 184], [185, 187], [188, 200], [201, 202], [203, 211], [212, 213], [213, 217], [217, 218], [219, 221], [222, 229], [230, 233], [234, 237], [238, 254], [255, 262], [262, 263]]}
{"doc_key": "ai-test-39", "ner": [[0, 3, "algorithm"], [13, 14, "field"], [17, 17, "product"], [19, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 17, 17, "part-of", "", false, false], [0, 3, 19, 21, "part-of", "", false, false], [17, 17, 13, 14, "general-affiliation", "", false, false], [19, 21, 13, 14, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Les", "SVM", "\u00e0", "noyau", "sont", "disponibles", "dans", "de", "nombreuses", "bo\u00eetes", "\u00e0", "outils", "d'", "apprentissage", "automatique", ",", "notamment", "LIBSVM", ",", "MATLAB", "et", "d'", "autres", "."], "sentence-detokenized": "Les SVM \u00e0 noyau sont disponibles dans de nombreuses bo\u00eetes \u00e0 outils d'apprentissage automatique, notamment LIBSVM, MATLAB et d'autres.", "token2charspan": [[0, 3], [4, 7], [8, 9], [10, 15], [16, 20], [21, 32], [33, 37], [38, 40], [41, 51], [52, 58], [59, 60], [61, 67], [68, 70], [70, 83], [84, 95], [95, 96], [97, 106], [107, 113], [113, 114], [115, 121], [122, 124], [125, 127], [127, 133], [133, 134]]}
{"doc_key": "ai-test-40", "ner": [[0, 4, "misc"], [14, 15, "location"], [18, 18, "location"], [19, 20, "country"], [27, 29, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 14, 15, "physical", "", false, false], [0, 4, 27, 29, "temporal", "", false, false], [14, 15, 18, 18, "physical", "", false, false], [18, 18, 19, 20, "physical", "", false, false], [27, 29, 14, 15, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Le", "concours", "du", "prix", "Loebner", "2009", "s'", "est", "tenu", "le", "6", "septembre", "2009", "au", "Brighton", "Centre", ",", "\u00e0", "Brighton", "(", "Royaume-Uni", ")", ",", "en", "marge", "de", "la", "conf\u00e9rence", "Interspeech", "2009", "."], "sentence-detokenized": "Le concours du prix Loebner 2009 s'est tenu le 6 septembre 2009 au Brighton Centre, \u00e0 Brighton (Royaume-Uni), en marge de la conf\u00e9rence Interspeech 2009.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 19], [20, 27], [28, 32], [33, 35], [35, 38], [39, 43], [44, 46], [47, 48], [49, 58], [59, 63], [64, 66], [67, 75], [76, 82], [82, 83], [84, 85], [86, 94], [95, 96], [96, 107], [107, 108], [108, 109], [110, 112], [113, 118], [119, 121], [122, 124], [125, 135], [136, 147], [148, 152], [152, 153]]}
{"doc_key": "ai-test-41", "ner": [[0, 3, "product"], [11, 11, "product"], [21, 21, "product"], [17, 20, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[17, 20, 0, 3, "part-of", "", false, false], [17, 20, 11, 11, "part-of", "", false, false], [17, 20, 21, 21, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Le", "robot", "humano\u00efde", "QRIO", "a", "\u00e9t\u00e9", "con\u00e7u", "comme", "le", "successeur", "d'", "AIBO", "et", "fonctionne", "avec", "le", "m\u00eame", "syst\u00e8me", "d'", "exploitation", "Aperios", "R-CODE", "."], "sentence-detokenized": "Le robot humano\u00efde QRIO a \u00e9t\u00e9 con\u00e7u comme le successeur d'AIBO et fonctionne avec le m\u00eame syst\u00e8me d'exploitation Aperios R-CODE.", "token2charspan": [[0, 2], [3, 8], [9, 18], [19, 23], [24, 25], [26, 29], [30, 35], [36, 41], [42, 44], [45, 55], [56, 58], [58, 62], [63, 65], [66, 76], [77, 81], [82, 84], [85, 89], [90, 97], [98, 100], [100, 112], [113, 120], [121, 127], [127, 128]]}
{"doc_key": "ai-test-42", "ner": [[0, 4, "misc"], [10, 10, "algorithm"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 0, 4, "cause-effect", "", true, false], [19, 21, 0, 4, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Les", "formes", "d'", "onde", "vocales", "sont", "g\u00e9n\u00e9r\u00e9es", "\u00e0", "partir", "des", "HMM", "eux-m\u00eames", ",", "sur", "la", "base", "du", "crit\u00e8re", "du", "maximum", "de", "vraisemblance", "."], "sentence-detokenized": "Les formes d'onde vocales sont g\u00e9n\u00e9r\u00e9es \u00e0 partir des HMM eux-m\u00eames, sur la base du crit\u00e8re du maximum de vraisemblance.", "token2charspan": [[0, 3], [4, 10], [11, 13], [13, 17], [18, 25], [26, 30], [31, 39], [40, 41], [42, 48], [49, 52], [53, 56], [57, 66], [66, 67], [68, 71], [72, 74], [75, 79], [80, 82], [83, 90], [91, 93], [94, 101], [102, 104], [105, 118], [118, 119]]}
{"doc_key": "ai-test-43", "ner": [[0, 3, "product"], [7, 15, "task"], [12, 14, "task"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 7, 15, "type-of", "", false, false], [0, 3, 12, 14, "type-of", "", false, false], [0, 3, 18, 18, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Google", "Translate", "est", "un", "service", "gratuit", "de", "traduction", "automatique", "statistique", "et", "de", "traduction", "automatique", "neuronale", "multilingue", "d\u00e9velopp\u00e9", "par", "Google", ",", "qui", "permet", "de", "traduire", "des", "textes", "et", "des", "sites", "Web", "d'", "une", "langue", "\u00e0", "une", "autre", "."], "sentence-detokenized": "Google Translate est un service gratuit de traduction automatique statistique et de traduction automatique neuronale multilingue d\u00e9velopp\u00e9 par Google, qui permet de traduire des textes et des sites Web d'une langue \u00e0 une autre.", "token2charspan": [[0, 6], [7, 16], [17, 20], [21, 23], [24, 31], [32, 39], [40, 42], [43, 53], [54, 65], [66, 77], [78, 80], [81, 83], [84, 94], [95, 106], [107, 116], [117, 128], [129, 138], [139, 142], [143, 149], [149, 150], [151, 154], [155, 161], [162, 164], [165, 173], [174, 177], [178, 184], [185, 187], [188, 191], [192, 197], [198, 201], [202, 204], [204, 207], [208, 214], [215, 216], [217, 220], [221, 226], [226, 227]]}
{"doc_key": "ai-test-44", "ner": [[10, 12, "field"], [16, 18, "field"], [22, 24, "field"], [27, 30, "field"], [37, 40, "task"], [43, 46, "task"], [49, 53, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[37, 40, 10, 12, "part-of", "", false, true], [37, 40, 16, 18, "part-of", "", false, true], [37, 40, 22, 24, "part-of", "", false, true], [43, 46, 10, 12, "part-of", "", false, true], [43, 46, 16, 18, "part-of", "", false, true], [43, 46, 22, 24, "part-of", "", false, true], [49, 53, 10, 12, "part-of", "", false, true], [49, 53, 16, 18, "part-of", "", false, true], [49, 53, 22, 24, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Les", "squelettes", "sont", "largement", "utilis\u00e9s", "dans", "les", "domaines", "de", "la", "vision", "par", "ordinateur", ",", "de", "l'", "analyse", "d'", "images", ",", "de", "la", "reconnaissance", "des", "formes", "et", "du", "traitement", "des", "images", "num\u00e9riques", "\u00e0", "des", "fins", "telles", "que", "la", "reconnaissance", "optique", "des", "caract\u00e8res", ",", "la", "reconnaissance", "des", "empreintes", "digitales", ",", "l'", "inspection", "visuelle", "ou", "la", "compression", "."], "sentence-detokenized": "Les squelettes sont largement utilis\u00e9s dans les domaines de la vision par ordinateur, de l'analyse d'images, de la reconnaissance des formes et du traitement des images num\u00e9riques \u00e0 des fins telles que la reconnaissance optique des caract\u00e8res, la reconnaissance des empreintes digitales, l'inspection visuelle ou la compression.", "token2charspan": [[0, 3], [4, 14], [15, 19], [20, 29], [30, 38], [39, 43], [44, 47], [48, 56], [57, 59], [60, 62], [63, 69], [70, 73], [74, 84], [84, 85], [86, 88], [89, 91], [91, 98], [99, 101], [101, 107], [107, 108], [109, 111], [112, 114], [115, 129], [130, 133], [134, 140], [141, 143], [144, 146], [147, 157], [158, 161], [162, 168], [169, 179], [180, 181], [182, 185], [186, 190], [191, 197], [198, 201], [202, 204], [205, 219], [220, 227], [228, 231], [232, 242], [242, 243], [244, 246], [247, 261], [262, 265], [266, 276], [277, 286], [286, 287], [288, 290], [290, 300], [301, 309], [310, 312], [313, 315], [316, 327], [327, 328]]}
{"doc_key": "ai-test-45", "ner": [[1, 6, "conference"], [13, 18, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 6, 13, 18, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["L'", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "est", "une", "r\u00e9f\u00e9rence", "en", "mati\u00e8re", "de", "classification", "et", "de", "d\u00e9tection", "d'", "objets", ",", "avec", "des", "millions", "d'", "images", "et", "des", "centaines", "de", "classes", "d'", "objets", "."], "sentence-detokenized": "L'ImageNet Large Scale Visual Recognition Challenge est une r\u00e9f\u00e9rence en mati\u00e8re de classification et de d\u00e9tection d'objets, avec des millions d'images et des centaines de classes d'objets.", "token2charspan": [[0, 2], [2, 10], [11, 16], [17, 22], [23, 29], [30, 41], [42, 51], [52, 55], [56, 59], [60, 69], [70, 72], [73, 80], [81, 83], [84, 98], [99, 101], [102, 104], [105, 114], [115, 117], [117, 123], [123, 124], [125, 129], [130, 133], [134, 142], [143, 145], [145, 151], [152, 154], [155, 158], [159, 168], [169, 171], [172, 179], [180, 182], [182, 188], [188, 189]]}
{"doc_key": "ai-test-46", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [16, 19, "misc"], [22, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 16, 19, "part-of", "", false, false], [0, 0, 22, 26, "part-of", "", false, false], [4, 5, 16, 19, "part-of", "", false, false], [4, 5, 22, 26, "part-of", "", false, false], [7, 8, 16, 19, "part-of", "", false, false], [7, 8, 22, 26, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Bengio", ",", "ainsi", "que", "Geoffrey", "Hinton", "et", "Yann", "LeCun", ",", "sont", "consid\u00e9r\u00e9s", "par", "certains", "comme", "les", "parrains", "de", "l'", "IA", "et", "les", "parrains", "de", "l'", "apprentissage", "profond", "."], "sentence-detokenized": "Bengio, ainsi que Geoffrey Hinton et Yann LeCun, sont consid\u00e9r\u00e9s par certains comme les parrains de l'IA et les parrains de l'apprentissage profond.", "token2charspan": [[0, 6], [6, 7], [8, 13], [14, 17], [18, 26], [27, 33], [34, 36], [37, 41], [42, 47], [47, 48], [49, 53], [54, 64], [65, 68], [69, 77], [78, 83], [84, 87], [88, 96], [97, 99], [100, 102], [102, 104], [105, 107], [108, 111], [112, 120], [121, 123], [124, 126], [126, 139], [140, 147], [147, 148]]}
{"doc_key": "ai-test-47", "ner": [[7, 7, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Il", "est", "membre", "\u00e0", "vie", "de", "l'", "IEEE", "."], "sentence-detokenized": "Il est membre \u00e0 vie de l'IEEE.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 15], [16, 19], [20, 22], [23, 25], [25, 29], [29, 30]]}
{"doc_key": "ai-test-48", "ner": [[0, 2, "organisation"], [17, 22, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 17, 22, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["La", "NSA", "Bethesda", "est", "responsable", "du", "soutien", "op\u00e9rationnel", "de", "la", "base", "pour", "son", "principal", "locataire", ",", "le", "Walter", "Reed", "National", "Military", "Medical", "Center", "."], "sentence-detokenized": "La NSA Bethesda est responsable du soutien op\u00e9rationnel de la base pour son principal locataire, le Walter Reed National Military Medical Center.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 19], [20, 31], [32, 34], [35, 42], [43, 55], [56, 58], [59, 61], [62, 66], [67, 71], [72, 75], [76, 85], [86, 95], [95, 96], [97, 99], [100, 106], [107, 111], [112, 120], [121, 129], [130, 137], [138, 144], [144, 145]]}
{"doc_key": "ai-test-49", "ner": [[8, 9, "field"], [12, 14, "field"], [17, 19, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Les", "trois", "principaux", "paradigmes", "d'", "apprentissage", "sont", "l'", "apprentissage", "supervis\u00e9", ",", "l'", "apprentissage", "non", "supervis\u00e9", "et", "l'", "apprentissage", "par", "renforcement", "."], "sentence-detokenized": "Les trois principaux paradigmes d'apprentissage sont l'apprentissage supervis\u00e9, l'apprentissage non supervis\u00e9 et l'apprentissage par renforcement.", "token2charspan": [[0, 3], [4, 9], [10, 20], [21, 31], [32, 34], [34, 47], [48, 52], [53, 55], [55, 68], [69, 78], [78, 79], [80, 82], [82, 95], [96, 99], [100, 109], [110, 112], [113, 115], [115, 128], [129, 132], [133, 145], [145, 146]]}
{"doc_key": "ai-test-50", "ner": [[6, 6, "task"], [9, 12, "task"], [17, 25, "task"], [28, 32, "task"], [35, 38, "task"], [41, 42, "task"], [45, 46, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Parmi", "les", "exemples", ",", "citons", "le", "contr\u00f4le", ",", "la", "planification", "et", "l'", "ordonnancement", ",", "la", "capacit\u00e9", "de", "r\u00e9pondre", "\u00e0", "des", "questions", "de", "diagnostic", "et", "de", "consommation", ",", "la", "reconnaissance", "de", "l'", "\u00e9criture", "manuscrite", ",", "la", "compr\u00e9hension", "du", "langage", "naturel", ",", "la", "reconnaissance", "vocale", "et", "la", "reconnaissance", "faciale", "."], "sentence-detokenized": "Parmi les exemples, citons le contr\u00f4le, la planification et l'ordonnancement, la capacit\u00e9 de r\u00e9pondre \u00e0 des questions de diagnostic et de consommation, la reconnaissance de l'\u00e9criture manuscrite, la compr\u00e9hension du langage naturel, la reconnaissance vocale et la reconnaissance faciale.", "token2charspan": [[0, 5], [6, 9], [10, 18], [18, 19], [20, 26], [27, 29], [30, 38], [38, 39], [40, 42], [43, 56], [57, 59], [60, 62], [62, 76], [76, 77], [78, 80], [81, 89], [90, 92], [93, 101], [102, 103], [104, 107], [108, 117], [118, 120], [121, 131], [132, 134], [135, 137], [138, 150], [150, 151], [152, 154], [155, 169], [170, 172], [173, 175], [175, 183], [184, 194], [194, 195], [196, 198], [199, 212], [213, 215], [216, 223], [224, 231], [231, 232], [233, 235], [236, 250], [251, 257], [258, 260], [261, 263], [264, 278], [279, 286], [286, 287]]}
{"doc_key": "ai-test-51", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["En", "1991", ",", "il", "a", "\u00e9t\u00e9", "\u00e9lu", "membre", "de", "l'", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "1990", ",", "membre", "fondateur", ")", "."], "sentence-detokenized": "En 1991, il a \u00e9t\u00e9 \u00e9lu membre de l'Association for the Advancement of Artificial Intelligence (1990, membre fondateur).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 13], [14, 17], [18, 21], [22, 28], [29, 31], [32, 34], [34, 45], [46, 49], [50, 53], [54, 65], [66, 68], [69, 79], [80, 92], [93, 94], [94, 98], [98, 99], [100, 106], [107, 116], [116, 117], [117, 118]]}
{"doc_key": "ai-test-52", "ner": [[11, 12, "misc"], [17, 19, "algorithm"], [32, 34, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Cependant", ",", "en", "formulant", "le", "probl\u00e8me", "comme", "la", "solution", "d'", "une", "matrice", "Toeplitz", "et", "en", "utilisant", "la", "r\u00e9cursion", "de", "Levinson", ",", "nous", "pouvons", "relativement", "rapidement", "estimer", "un", "filtre", "avec", "la", "plus", "petite", "erreur", "quadratique", "moyenne", "possible", "."], "sentence-detokenized": "Cependant, en formulant le probl\u00e8me comme la solution d'une matrice Toeplitz et en utilisant la r\u00e9cursion de Levinson, nous pouvons relativement rapidement estimer un filtre avec la plus petite erreur quadratique moyenne possible.", "token2charspan": [[0, 9], [9, 10], [11, 13], [14, 23], [24, 26], [27, 35], [36, 41], [42, 44], [45, 53], [54, 56], [56, 59], [60, 67], [68, 76], [77, 79], [80, 82], [83, 92], [93, 95], [96, 105], [106, 108], [109, 117], [117, 118], [119, 123], [124, 131], [132, 144], [145, 155], [156, 163], [164, 166], [167, 173], [174, 178], [179, 181], [182, 186], [187, 193], [194, 200], [201, 212], [213, 220], [221, 229], [229, 230]]}
{"doc_key": "ai-test-53", "ner": [[5, 11, "conference"], [16, 21, "location"], [23, 23, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 11, 16, 21, "physical", "", false, false], [16, 21, 23, 23, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["En", "juillet", "2011", ",", "la", "15e", "\u00e9dition", "de", "la", "Campus", "Party", "Espagne", "se", "tiendra", "\u00e0", "la", "Cit\u00e9", "des", "Arts", "et", "des", "Sciences", "de", "Valence", "."], "sentence-detokenized": "En juillet 2011, la 15e \u00e9dition de la Campus Party Espagne se tiendra \u00e0 la Cit\u00e9 des Arts et des Sciences de Valence.", "token2charspan": [[0, 2], [3, 10], [11, 15], [15, 16], [17, 19], [20, 23], [24, 31], [32, 34], [35, 37], [38, 44], [45, 50], [51, 58], [59, 61], [62, 69], [70, 71], [72, 74], [75, 79], [80, 83], [84, 88], [89, 91], [92, 95], [96, 104], [105, 107], [108, 115], [115, 116]]}
{"doc_key": "ai-test-54", "ner": [[17, 17, "product"], [20, 20, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Souvent", ",", "cela", "n'", "est", "possible", "qu'", "\u00e0", "la", "toute", "fin", "de", "jeux", "compliqu\u00e9s", "tels", "que", "les", "\u00e9checs", "ou", "le", "go", ",", "car", "il", "n'", "est", "pas", "possible", ",", "d'", "un", "point", "de", "vue", "informatique", ",", "de", "se", "projeter", "jusqu'", "\u00e0", "la", "fin", "du", "jeu", ",", "sauf", "vers", "la", "fin", ",", "et", "\u00e0", "la", "place", ",", "les", "positions", "re\u00e7oivent", "des", "valeurs", "finies", "comme", "estimations", "du", "degr\u00e9", "de", "croyance", "qu'", "elles", "m\u00e8neront", "\u00e0", "une", "victoire", "pour", "un", "joueur", "ou", "un", "autre", "."], "sentence-detokenized": "Souvent, cela n'est possible qu'\u00e0 la toute fin de jeux compliqu\u00e9s tels que les \u00e9checs ou le go, car il n'est pas possible, d'un point de vue informatique, de se projeter jusqu'\u00e0 la fin du jeu, sauf vers la fin, et \u00e0 la place, les positions re\u00e7oivent des valeurs finies comme estimations du degr\u00e9 de croyance qu'elles m\u00e8neront \u00e0 une victoire pour un joueur ou un autre.", "token2charspan": [[0, 7], [7, 8], [9, 13], [14, 16], [16, 19], [20, 28], [29, 32], [32, 33], [34, 36], [37, 42], [43, 46], [47, 49], [50, 54], [55, 65], [66, 70], [71, 74], [75, 78], [79, 85], [86, 88], [89, 91], [92, 94], [94, 95], [96, 99], [100, 102], [103, 105], [105, 108], [109, 112], [113, 121], [121, 122], [123, 125], [125, 127], [128, 133], [134, 136], [137, 140], [141, 153], [153, 154], [155, 157], [158, 160], [161, 169], [170, 176], [176, 177], [178, 180], [181, 184], [185, 187], [188, 191], [191, 192], [193, 197], [198, 202], [203, 205], [206, 209], [209, 210], [211, 213], [214, 215], [216, 218], [219, 224], [224, 225], [226, 229], [230, 239], [240, 249], [250, 253], [254, 261], [262, 268], [269, 274], [275, 286], [287, 289], [290, 295], [296, 298], [299, 307], [308, 311], [311, 316], [317, 325], [326, 327], [328, 331], [332, 340], [341, 345], [346, 348], [349, 355], [356, 358], [359, 361], [362, 367], [367, 368]]}
{"doc_key": "ai-test-55", "ner": [[4, 6, "algorithm"], [25, 27, "algorithm"], [30, 33, "algorithm"], [35, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 25, 27, "compare", "", false, false], [4, 6, 30, 33, "compare", "", false, false], [4, 6, 35, 37, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "diff\u00e9rence", "entre", "le", "mod\u00e8le", "logit", "multinomial", "et", "de", "nombreuses", "autres", "m\u00e9thodes", ",", "mod\u00e8les", ",", "algorithmes", ",", "etc.", "ayant", "la", "m\u00eame", "configuration", "de", "base", "(", "algorithme", "du", "perceptron", ",", "machines", "\u00e0", "vecteurs", "de", "support", ",", "analyse", "discriminante", "lin\u00e9aire", ",", "etc."], "sentence-detokenized": "La diff\u00e9rence entre le mod\u00e8le logit multinomial et de nombreuses autres m\u00e9thodes, mod\u00e8les, algorithmes, etc. ayant la m\u00eame configuration de base (algorithme du perceptron, machines \u00e0 vecteurs de support, analyse discriminante lin\u00e9aire, etc.", "token2charspan": [[0, 2], [3, 13], [14, 19], [20, 22], [23, 29], [30, 35], [36, 47], [48, 50], [51, 53], [54, 64], [65, 71], [72, 80], [80, 81], [82, 89], [89, 90], [91, 102], [102, 103], [104, 108], [109, 114], [115, 117], [118, 122], [123, 136], [137, 139], [140, 144], [145, 146], [146, 156], [157, 159], [160, 170], [170, 171], [172, 180], [181, 182], [183, 191], [192, 194], [195, 202], [202, 203], [204, 211], [212, 225], [226, 234], [234, 235], [236, 240]]}
{"doc_key": "ai-test-56", "ner": [[0, 3, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Association", "for", "Computational", "Linguistics", ",", "publi\u00e9", "par"], "sentence-detokenized": "Association for Computational Linguistics, publi\u00e9 par", "token2charspan": [[0, 11], [12, 15], [16, 29], [30, 41], [41, 42], [43, 49], [50, 53]]}
{"doc_key": "ai-test-57", "ner": [[2, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Dans", "un", "syst\u00e8me", "de", "reconnaissance", "faciale", "informatis\u00e9", ",", "chaque", "visage", "est", "repr\u00e9sent\u00e9", "par", "un", "grand", "nombre", "de", "valeurs", "de", "pixels", "."], "sentence-detokenized": "Dans un syst\u00e8me de reconnaissance faciale informatis\u00e9, chaque visage est repr\u00e9sent\u00e9 par un grand nombre de valeurs de pixels.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 33], [34, 41], [42, 53], [53, 54], [55, 61], [62, 68], [69, 72], [73, 83], [84, 87], [88, 90], [91, 96], [97, 103], [104, 106], [107, 114], [115, 117], [118, 124], [124, 125]]}
{"doc_key": "ai-test-58", "ner": [[6, 7, "person"], [14, 16, "organisation"], [24, 24, "country"], [30, 30, "person"], [43, 45, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 7, 14, 16, "role", "", false, false], [6, 7, 24, 24, "physical", "", false, false], [30, 30, 43, 45, "origin", "", false, false], [30, 30, 43, 45, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["En", "2002", ",", "son", "fils", ",", "Daniel", "Pearl", ",", "un", "journaliste", "travaillant", "pour", "le", "Wall", "Street", "Journal", ",", "a", "\u00e9t\u00e9", "enlev\u00e9", "et", "assassin\u00e9", "au", "Pakistan", ",", "ce", "qui", "a", "conduit", "Judea", "et", "les", "autres", "membres", "de", "la", "famille", "et", "amis", "\u00e0", "cr\u00e9er", "la", "Fondation", "Daniel", "Pearl", "."], "sentence-detokenized": "En 2002, son fils, Daniel Pearl, un journaliste travaillant pour le Wall Street Journal, a \u00e9t\u00e9 enlev\u00e9 et assassin\u00e9 au Pakistan, ce qui a conduit Judea et les autres membres de la famille et amis \u00e0 cr\u00e9er la Fondation Daniel Pearl.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 17], [17, 18], [19, 25], [26, 31], [31, 32], [33, 35], [36, 47], [48, 59], [60, 64], [65, 67], [68, 72], [73, 79], [80, 87], [87, 88], [89, 90], [91, 94], [95, 101], [102, 104], [105, 114], [115, 117], [118, 126], [126, 127], [128, 130], [131, 134], [135, 136], [137, 144], [145, 150], [151, 153], [154, 157], [158, 164], [165, 172], [173, 175], [176, 178], [179, 186], [187, 189], [190, 194], [195, 196], [197, 202], [203, 205], [206, 215], [216, 222], [223, 228], [228, 229]]}
{"doc_key": "ai-test-59", "ner": [[4, 6, "organisation"], [22, 23, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 22, 23, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Depuis", "fin", "2006", ",", "Red", "Envelope", "Entertainment", "s'", "est", "\u00e9galement", "lanc\u00e9", "dans", "la", "production", "de", "contenus", "originaux", "avec", "des", "r\u00e9alisateurs", "tels", "que", "John", "Waters", "."], "sentence-detokenized": "Depuis fin 2006, Red Envelope Entertainment s'est \u00e9galement lanc\u00e9 dans la production de contenus originaux avec des r\u00e9alisateurs tels que John Waters.", "token2charspan": [[0, 6], [7, 10], [11, 15], [15, 16], [17, 20], [21, 29], [30, 43], [44, 46], [46, 49], [50, 59], [60, 65], [66, 70], [71, 73], [74, 84], [85, 87], [88, 96], [97, 106], [107, 111], [112, 115], [116, 128], [129, 133], [134, 137], [138, 142], [143, 149], [149, 150]]}
{"doc_key": "ai-test-60", "ner": [[6, 10, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Le", "b\u00e2timent", "fait", "maintenant", "partie", "du", "Beth", "Israel", "Deaconess", "Medical", "Center", "."], "sentence-detokenized": "Le b\u00e2timent fait maintenant partie du Beth Israel Deaconess Medical Center.", "token2charspan": [[0, 2], [3, 11], [12, 16], [17, 27], [28, 34], [35, 37], [38, 42], [43, 49], [50, 59], [60, 67], [68, 74], [74, 75]]}
{"doc_key": "ai-test-61", "ner": [[21, 22, "field"], [25, 27, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Un", "th\u00e8me", "commun", "\u00e0", "ces", "travaux", "est", "l'", "adoption", "d'", "une", "perspective", "de", "la", "th\u00e9orie", "des", "signes", "sur", "les", "questions", "d'", "intelligence", "artificielle", "et", "de", "repr\u00e9sentation", "des", "connaissances", "."], "sentence-detokenized": "Un th\u00e8me commun \u00e0 ces travaux est l'adoption d'une perspective de la th\u00e9orie des signes sur les questions d'intelligence artificielle et de repr\u00e9sentation des connaissances.", "token2charspan": [[0, 2], [3, 8], [9, 15], [16, 17], [18, 21], [22, 29], [30, 33], [34, 36], [36, 44], [45, 47], [47, 50], [51, 62], [63, 65], [66, 68], [69, 76], [77, 80], [81, 87], [88, 91], [92, 95], [96, 105], [106, 108], [108, 120], [121, 133], [134, 136], [137, 139], [140, 154], [155, 158], [159, 172], [172, 173]]}
{"doc_key": "ai-test-62", "ner": [[6, 8, "task"], [11, 11, "task"], [21, 22, "task"], [48, 50, "task"], [53, 55, "task"], [61, 63, "task"], [65, 65, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[6, 8, 21, 22, "type-of", "", false, false], [6, 8, 61, 63, "compare", "", false, false], [6, 8, 61, 63, "opposite", "", false, false], [11, 11, 6, 8, "named", "", false, false], [48, 50, 61, 63, "part-of", "", false, false], [53, 55, 61, 63, "part-of", "", false, false], [61, 63, 21, 22, "type-of", "", false, false], [65, 65, 61, 63, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Par", "exemple", ",", "le", "terme", "\"", "traduction", "automatique", "neuronale", "\"", "(", "NMT", ")", "souligne", "le", "fait", "que", "les", "approches", "de", "la", "traduction", "automatique", "bas\u00e9es", "sur", "l'", "apprentissage", "profond", "apprennent", "directement", "les", "transformations", "de", "s\u00e9quence", "\u00e0", "s\u00e9quence", ",", "\u00e9vitant", "ainsi", "le", "recours", "\u00e0", "des", "\u00e9tapes", "interm\u00e9diaires", "telles", "que", "l'", "alignement", "des", "mots", "et", "la", "mod\u00e9lisation", "du", "langage", "qui", "\u00e9taient", "utilis\u00e9es", "dans", "la", "traduction", "automatique", "statistique", "(", "SMT", ")", "."], "sentence-detokenized": "Par exemple, le terme \"traduction automatique neuronale\" (NMT) souligne le fait que les approches de la traduction automatique bas\u00e9es sur l'apprentissage profond apprennent directement les transformations de s\u00e9quence \u00e0 s\u00e9quence, \u00e9vitant ainsi le recours \u00e0 des \u00e9tapes interm\u00e9diaires telles que l'alignement des mots et la mod\u00e9lisation du langage qui \u00e9taient utilis\u00e9es dans la traduction automatique statistique (SMT).", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 21], [22, 23], [23, 33], [34, 45], [46, 55], [55, 56], [57, 58], [58, 61], [61, 62], [63, 71], [72, 74], [75, 79], [80, 83], [84, 87], [88, 97], [98, 100], [101, 103], [104, 114], [115, 126], [127, 133], [134, 137], [138, 140], [140, 153], [154, 161], [162, 172], [173, 184], [185, 188], [189, 204], [205, 207], [208, 216], [217, 218], [219, 227], [227, 228], [229, 236], [237, 242], [243, 245], [246, 253], [254, 255], [256, 259], [260, 266], [267, 281], [282, 288], [289, 292], [293, 295], [295, 305], [306, 309], [310, 314], [315, 317], [318, 320], [321, 333], [334, 336], [337, 344], [345, 348], [349, 356], [357, 366], [367, 371], [372, 374], [375, 385], [386, 397], [398, 409], [410, 411], [411, 414], [414, 415], [415, 416]]}
{"doc_key": "ai-test-63", "ner": [[9, 9, "field"], [14, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 9, 14, 14, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["La", "plupart", "des", "recherches", "dans", "le", "domaine", "de", "la", "WSD", "sont", "effectu\u00e9es", "en", "utilisant", "WordNet", "comme", "inventaire", "de", "sens", "de", "r\u00e9f\u00e9rence", "."], "sentence-detokenized": "La plupart des recherches dans le domaine de la WSD sont effectu\u00e9es en utilisant WordNet comme inventaire de sens de r\u00e9f\u00e9rence.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 25], [26, 30], [31, 33], [34, 41], [42, 44], [45, 47], [48, 51], [52, 56], [57, 67], [68, 70], [71, 80], [81, 88], [89, 94], [95, 105], [106, 108], [109, 113], [114, 116], [117, 126], [126, 127]]}
{"doc_key": "ai-test-64", "ner": [[3, 3, "misc"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 15, 3, 3, "general-affiliation", "", false, true], [17, 18, 3, 3, "general-affiliation", "", false, true]], "relations_mapping_to_source": [0, 1], "sentence": ["Parmi", "les", "anciens", "doctorants", "et", "chercheurs", "postdoctoraux", "de", "son", "groupe", ",", "on", "peut", "citer", "Richard", "Zemel", "et", "Zoubin", "Ghahramani", "."], "sentence-detokenized": "Parmi les anciens doctorants et chercheurs postdoctoraux de son groupe, on peut citer Richard Zemel et Zoubin Ghahramani.", "token2charspan": [[0, 5], [6, 9], [10, 17], [18, 28], [29, 31], [32, 42], [43, 56], [57, 59], [60, 63], [64, 70], [70, 71], [72, 74], [75, 79], [80, 85], [86, 93], [94, 99], [100, 102], [103, 109], [110, 120], [120, 121]]}
{"doc_key": "ai-test-65", "ner": [[8, 10, "metrics"], [17, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 10, 17, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Chaque", "r\u00e9sultat", "de", "pr\u00e9diction", "ou", "instance", "d'", "une", "matrice", "de", "confusion", "repr\u00e9sente", "un", "point", "dans", "l'", "espace", "ROC", "."], "sentence-detokenized": "Chaque r\u00e9sultat de pr\u00e9diction ou instance d'une matrice de confusion repr\u00e9sente un point dans l'espace ROC.", "token2charspan": [[0, 6], [7, 15], [16, 18], [19, 29], [30, 32], [33, 41], [42, 44], [44, 47], [48, 55], [56, 58], [59, 68], [69, 79], [80, 82], [83, 88], [89, 93], [94, 96], [96, 102], [103, 106], [106, 107]]}
{"doc_key": "ai-test-66", "ner": [[3, 3, "researcher"], [7, 8, "researcher"], [10, 12, "researcher"], [16, 18, "product"], [22, 24, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 22, 24, "physical", "", false, false], [7, 8, 22, 24, "physical", "", false, false], [10, 12, 22, 24, "physical", "", false, false], [16, 18, 3, 3, "artifact", "", false, false], [16, 18, 7, 8, "artifact", "", false, false], [16, 18, 10, 12, "artifact", "", false, false], [16, 18, 22, 24, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["En", "1997", ",", "Thrun", "et", "ses", "coll\u00e8gues", "Wolfram", "Burgard", "et", "Dieter", "Fox", "ont", "d\u00e9velopp\u00e9", "le", "premier", "guide", "touristique", "robotis\u00e9", "au", "monde", "au", "Deutsches", "Museum", "Bonn", "(", "1997", ")", "."], "sentence-detokenized": "En 1997, Thrun et ses coll\u00e8gues Wolfram Burgard et Dieter Fox ont d\u00e9velopp\u00e9 le premier guide touristique robotis\u00e9 au monde au Deutsches Museum Bonn (1997).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 17], [18, 21], [22, 31], [32, 39], [40, 47], [48, 50], [51, 57], [58, 61], [62, 65], [66, 75], [76, 78], [79, 86], [87, 92], [93, 104], [105, 113], [114, 116], [117, 122], [123, 125], [126, 135], [136, 142], [143, 147], [148, 149], [149, 153], [153, 154], [154, 155]]}
{"doc_key": "ai-test-67", "ner": [[0, 0, "product"], [8, 9, "misc"], [24, 28, "field"], [33, 34, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 0, 0, "part-of", "", false, false], [24, 28, 0, 0, "usage", "", false, false], [33, 34, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["WordNet", "est", "une", "base", "de", "donn\u00e9es", "lexicale", "de", "relations", "s\u00e9mantiques", "entre", "les", "mots", "dans", "plus", "de", "200", "langues", ".", "Son", "utilisation", "principale", "est", "le", "traitement", "automatique", "du", "langage", "naturel", "et", "les", "applications", "d'", "intelligence", "artificielle", "."], "sentence-detokenized": "WordNet est une base de donn\u00e9es lexicale de relations s\u00e9mantiques entre les mots dans plus de 200 langues. Son utilisation principale est le traitement automatique du langage naturel et les applications d'intelligence artificielle.", "token2charspan": [[0, 7], [8, 11], [12, 15], [16, 20], [21, 23], [24, 31], [32, 40], [41, 43], [44, 53], [54, 65], [66, 71], [72, 75], [76, 80], [81, 85], [86, 90], [91, 93], [94, 97], [98, 105], [105, 106], [107, 110], [111, 122], [123, 133], [134, 137], [138, 140], [141, 151], [152, 163], [164, 166], [167, 174], [175, 182], [183, 185], [186, 189], [190, 202], [203, 205], [205, 217], [218, 230], [230, 231]]}
{"doc_key": "ai-test-68", "ner": [[6, 9, "field"], [14, 17, "conference"], [20, 27, "conference"], [29, 29, "conference"], [31, 31, "conference"], [40, 43, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 17, 6, 9, "topic", "", false, false], [14, 17, 40, 43, "topic", "", false, false], [20, 27, 6, 9, "topic", "", false, false], [20, 27, 40, 43, "topic", "", false, false], [29, 29, 6, 9, "topic", "", false, false], [29, 29, 40, 43, "topic", "", false, false], [31, 31, 6, 9, "topic", "", false, false], [31, 31, 40, 43, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Les", "conf\u00e9rences", "dans", "le", "domaine", "du", "traitement", "du", "langage", "naturel", ",", "telles", "que", "l'", "Association", "for", "Computational", "Linguistics", ",", "le", "chapitre", "nord-am\u00e9ricain", "de", "l'", "Association", "for", "Computational", "Linguistics", ",", "EMNLP", "et", "HLT", ",", "commencent", "\u00e0", "inclure", "des", "articles", "sur", "le", "traitement", "de", "la", "parole", "."], "sentence-detokenized": "Les conf\u00e9rences dans le domaine du traitement du langage naturel, telles que l'Association for Computational Linguistics, le chapitre nord-am\u00e9ricain de l'Association for Computational Linguistics, EMNLP et HLT, commencent \u00e0 inclure des articles sur le traitement de la parole.", "token2charspan": [[0, 3], [4, 15], [16, 20], [21, 23], [24, 31], [32, 34], [35, 45], [46, 48], [49, 56], [57, 64], [64, 65], [66, 72], [73, 76], [77, 79], [79, 90], [91, 94], [95, 108], [109, 120], [120, 121], [122, 124], [125, 133], [134, 148], [149, 151], [152, 154], [154, 165], [166, 169], [170, 183], [184, 195], [195, 196], [197, 202], [203, 205], [206, 209], [209, 210], [211, 221], [222, 223], [224, 231], [232, 235], [236, 244], [245, 248], [249, 251], [252, 262], [263, 265], [266, 268], [269, 275], [275, 276]]}
{"doc_key": "ai-test-69", "ner": [[4, 4, "programlang"], [26, 28, "misc"], [44, 46, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Un", "ensemble", "de", "programmes", "Java", "utilise", "le", "lexique", "pour", "se", "frayer", "un", "chemin", "\u00e0", "travers", "les", "variations", "des", "textes", "biom\u00e9dicaux", "en", "reliant", "les", "mots", "par", "leurs", "parties", "du", "discours", ",", "ce", "qui", "peut", "\u00eatre", "utile", "pour", "les", "recherches", "sur", "le", "web", "ou", "dans", "un", "dossier", "m\u00e9dical", "\u00e9lectronique", "."], "sentence-detokenized": "Un ensemble de programmes Java utilise le lexique pour se frayer un chemin \u00e0 travers les variations des textes biom\u00e9dicaux en reliant les mots par leurs parties du discours, ce qui peut \u00eatre utile pour les recherches sur le web ou dans un dossier m\u00e9dical \u00e9lectronique.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 25], [26, 30], [31, 38], [39, 41], [42, 49], [50, 54], [55, 57], [58, 64], [65, 67], [68, 74], [75, 76], [77, 84], [85, 88], [89, 99], [100, 103], [104, 110], [111, 122], [123, 125], [126, 133], [134, 137], [138, 142], [143, 146], [147, 152], [153, 160], [161, 163], [164, 172], [172, 173], [174, 176], [177, 180], [181, 185], [186, 190], [191, 196], [197, 201], [202, 205], [206, 216], [217, 220], [221, 223], [224, 227], [228, 230], [231, 235], [236, 238], [239, 246], [247, 254], [255, 267], [267, 268]]}
{"doc_key": "ai-test-70", "ner": [[9, 9, "algorithm"], [11, 11, "algorithm"], [13, 13, "algorithm"], [15, 15, "algorithm"], [17, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Il", "existe", "de", "nombreux", "algorithmes", "plus", "r\u00e9cents", "tels", "que", "LPBoost", ",", "TotalBoost", ",", "BrownBoost", ",", "xgboost", ",", "MadaBoost", ",", "et", "d'", "autres", "."], "sentence-detokenized": "Il existe de nombreux algorithmes plus r\u00e9cents tels que LPBoost, TotalBoost, BrownBoost, xgboost, MadaBoost, et d'autres.", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 21], [22, 33], [34, 38], [39, 46], [47, 51], [52, 55], [56, 63], [63, 64], [65, 75], [75, 76], [77, 87], [87, 88], [89, 96], [96, 97], [98, 107], [107, 108], [109, 111], [112, 114], [114, 120], [120, 121]]}
{"doc_key": "ai-test-71", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Voici", "un", "exemple", "d'", "impl\u00e9mentation", "en", "Python", ":"], "sentence-detokenized": "Voici un exemple d'impl\u00e9mentation en Python :", "token2charspan": [[0, 5], [6, 8], [9, 16], [17, 19], [19, 33], [34, 36], [37, 43], [44, 45]]}
{"doc_key": "ai-test-72", "ner": [[4, 4, "organisation"], [5, 5, "product"], [10, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 4, 4, "artifact", "made_by_company", false, false], [10, 12, 5, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "console", "de", "jeu", "Mattel", "Intellivision", "proposait", "le", "module", "de", "synth\u00e8se", "vocale", "Intellivoice", "en", "1982", "."], "sentence-detokenized": "La console de jeu Mattel Intellivision proposait le module de synth\u00e8se vocale Intellivoice en 1982.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 17], [18, 24], [25, 38], [39, 48], [49, 51], [52, 58], [59, 61], [62, 70], [71, 77], [78, 90], [91, 93], [94, 98], [98, 99]]}
{"doc_key": "ai-test-73", "ner": [[6, 7, "task"], [14, 21, "task"], [25, 26, "field"], [29, 31, "task"], [35, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 21, 6, 7, "part-of", "", false, false], [25, 26, 6, 7, "part-of", "", false, false], [29, 31, 6, 7, "part-of", "", false, false], [35, 40, 29, 31, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Il", "a", "\u00e9galement", "travaill\u00e9", "sur", "la", "traduction", "automatique", ",", "\u00e0", "la", "fois", "sur", "la", "TA", "bas\u00e9e", "sur", "la", "connaissance", "\u00e0", "haute", "pr\u00e9cision", "et", "sur", "l'", "apprentissage", "automatique", "pour", "la", "traduction", "automatique", "statistique", "(", "comme", "la", "TA", "bas\u00e9e", "sur", "les", "exemples", "g\u00e9n\u00e9ralis\u00e9s", ")", "."], "sentence-detokenized": "Il a \u00e9galement travaill\u00e9 sur la traduction automatique, \u00e0 la fois sur la TA bas\u00e9e sur la connaissance \u00e0 haute pr\u00e9cision et sur l'apprentissage automatique pour la traduction automatique statistique (comme la TA bas\u00e9e sur les exemples g\u00e9n\u00e9ralis\u00e9s).", "token2charspan": [[0, 2], [3, 4], [5, 14], [15, 24], [25, 28], [29, 31], [32, 42], [43, 54], [54, 55], [56, 57], [58, 60], [61, 65], [66, 69], [70, 72], [73, 75], [76, 81], [82, 85], [86, 88], [89, 101], [102, 103], [104, 109], [110, 119], [120, 122], [123, 126], [127, 129], [129, 142], [143, 154], [155, 159], [160, 162], [163, 173], [174, 185], [186, 197], [198, 199], [199, 204], [205, 207], [208, 210], [211, 216], [217, 220], [221, 224], [225, 233], [234, 245], [245, 246], [246, 247]]}
{"doc_key": "ai-test-74", "ner": [[0, 1, "misc"], [5, 5, "misc"], [24, 25, "algorithm"], [28, 29, "field"], [32, 34, "field"], [37, 37, "field"], [40, 42, "field"], [45, 45, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 24, 25, "general-affiliation", "", false, false], [0, 1, 28, 29, "general-affiliation", "", false, false], [0, 1, 32, 34, "general-affiliation", "", false, false], [0, 1, 37, 37, "general-affiliation", "", false, false], [0, 1, 40, 42, "general-affiliation", "", false, false], [0, 1, 45, 45, "general-affiliation", "", false, false], [5, 5, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Wolfram", "Mathematica", "(", "g\u00e9n\u00e9ralement", "appel\u00e9", "Mathematica", ")", "est", "un", "syst\u00e8me", "de", "calcul", "technique", "moderne", "couvrant", "la", "plupart", "des", "domaines", "techniques", "-", "y", "compris", "les", "r\u00e9seaux", "neuronaux", ",", "l'", "apprentissage", "automatique", ",", "le", "traitement", "des", "images", ",", "la", "g\u00e9om\u00e9trie", ",", "la", "science", "des", "donn\u00e9es", ",", "les", "visualisations", ",", "etc."], "sentence-detokenized": "Wolfram Mathematica (g\u00e9n\u00e9ralement appel\u00e9 Mathematica) est un syst\u00e8me de calcul technique moderne couvrant la plupart des domaines techniques - y compris les r\u00e9seaux neuronaux, l'apprentissage automatique, le traitement des images, la g\u00e9om\u00e9trie, la science des donn\u00e9es, les visualisations, etc.", "token2charspan": [[0, 7], [8, 19], [20, 21], [21, 33], [34, 40], [41, 52], [52, 53], [54, 57], [58, 60], [61, 68], [69, 71], [72, 78], [79, 88], [89, 96], [97, 105], [106, 108], [109, 116], [117, 120], [121, 129], [130, 140], [141, 142], [143, 144], [145, 152], [153, 156], [157, 164], [165, 174], [174, 175], [176, 178], [178, 191], [192, 203], [203, 204], [205, 207], [208, 218], [219, 222], [223, 229], [229, 230], [231, 233], [234, 243], [243, 244], [245, 247], [248, 255], [256, 259], [260, 267], [267, 268], [269, 272], [273, 287], [287, 288], [289, 293]]}
{"doc_key": "ai-test-75", "ner": [[2, 7, "product"], [12, 13, "researcher"], [20, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[20, 20, 2, 7, "type-of", "", false, false], [20, 20, 12, 13, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Le", "premier", "robot", "\u00e0", "commande", "num\u00e9rique", "et", "programmable", "a", "\u00e9t\u00e9", "invent\u00e9", "par", "George", "Devol", "en", "1954", "et", "a", "\u00e9t\u00e9", "appel\u00e9", "Unimate", "."], "sentence-detokenized": "Le premier robot \u00e0 commande num\u00e9rique et programmable a \u00e9t\u00e9 invent\u00e9 par George Devol en 1954 et a \u00e9t\u00e9 appel\u00e9 Unimate.", "token2charspan": [[0, 2], [3, 10], [11, 16], [17, 18], [19, 27], [28, 37], [38, 40], [41, 53], [54, 55], [56, 59], [60, 67], [68, 71], [72, 78], [79, 84], [85, 87], [88, 92], [93, 95], [96, 97], [98, 101], [102, 108], [109, 116], [116, 117]]}
{"doc_key": "ai-test-76", "ner": [[2, 2, "algorithm"], [5, 5, "algorithm"], [23, 25, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 2, 5, 5, "compare", "", false, false], [5, 5, 23, 25, "general-affiliation", "", false, false], [5, 5, 28, 29, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Comme", "les", "DBN", ",", "les", "DBM", "peuvent", "apprendre", "des", "repr\u00e9sentations", "internes", "complexes", "et", "abstraites", "de", "l'", "entr\u00e9e", "dans", "des", "t\u00e2ches", "telles", "que", "la", "reconnaissance", "des", "objets", "ou", "la", "reconnaissance", "vocale", ",", "en", "utilisant", "des", "donn\u00e9es", "limit\u00e9es", "et", "\u00e9tiquet\u00e9es", "pour", "affiner", "les", "repr\u00e9sentations", "construites", "\u00e0", "l'", "aide", "d'", "un", "grand", "ensemble", "de", "donn\u00e9es", "d'", "entr\u00e9e", "sensorielles", "non", "\u00e9tiquet\u00e9es", "."], "sentence-detokenized": "Comme les DBN, les DBM peuvent apprendre des repr\u00e9sentations internes complexes et abstraites de l'entr\u00e9e dans des t\u00e2ches telles que la reconnaissance des objets ou la reconnaissance vocale, en utilisant des donn\u00e9es limit\u00e9es et \u00e9tiquet\u00e9es pour affiner les repr\u00e9sentations construites \u00e0 l'aide d'un grand ensemble de donn\u00e9es d'entr\u00e9e sensorielles non \u00e9tiquet\u00e9es.", "token2charspan": [[0, 5], [6, 9], [10, 13], [13, 14], [15, 18], [19, 22], [23, 30], [31, 40], [41, 44], [45, 60], [61, 69], [70, 79], [80, 82], [83, 93], [94, 96], [97, 99], [99, 105], [106, 110], [111, 114], [115, 121], [122, 128], [129, 132], [133, 135], [136, 150], [151, 154], [155, 161], [162, 164], [165, 167], [168, 182], [183, 189], [189, 190], [191, 193], [194, 203], [204, 207], [208, 215], [216, 224], [225, 227], [228, 238], [239, 243], [244, 251], [252, 255], [256, 271], [272, 283], [284, 285], [286, 288], [288, 292], [293, 295], [295, 297], [298, 303], [304, 312], [313, 315], [316, 323], [324, 326], [326, 332], [333, 345], [346, 349], [350, 360], [360, 361]]}
{"doc_key": "ai-test-77", "ner": [[7, 13, "task"], [18, 18, "conference"], [21, 21, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 18, 7, 13, "topic", "", false, false], [21, 21, 7, 13, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Les", "conf\u00e9rences", "scientifiques", "o\u00f9", "les", "travaux", "de", "reconnaissance", "d'", "activit\u00e9", "bas\u00e9s", "sur", "la", "vision", "apparaissent", "souvent", "sont", "l'", "ICCV", "et", "le", "CVPR", "."], "sentence-detokenized": "Les conf\u00e9rences scientifiques o\u00f9 les travaux de reconnaissance d'activit\u00e9 bas\u00e9s sur la vision apparaissent souvent sont l'ICCV et le CVPR.", "token2charspan": [[0, 3], [4, 15], [16, 29], [30, 32], [33, 36], [37, 44], [45, 47], [48, 62], [63, 65], [65, 73], [74, 79], [80, 83], [84, 86], [87, 93], [94, 106], [107, 114], [115, 119], [120, 122], [122, 126], [127, 129], [130, 132], [133, 137], [137, 138]]}
{"doc_key": "ai-test-78", "ner": [[1, 1, "field"], [6, 6, "algorithm"], [8, 8, "algorithm"], [20, 22, "metrics"], [25, 27, "metrics"], [29, 29, "metrics"], [43, 44, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[6, 6, 1, 1, "part-of", "", false, false], [6, 6, 20, 22, "related-to", "finds", false, false], [6, 6, 25, 27, "related-to", "finds", false, false], [6, 6, 43, 44, "related-to", "", false, false], [8, 8, 6, 6, "named", "", false, false], [29, 29, 25, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["En", "statistique", ",", "un", "algorithme", "d'", "esp\u00e9rance-maximisation", "(", "EM", ")", "est", "une", "m\u00e9thode", "it\u00e9rative", "permettant", "de", "trouver", "des", "estimations", "du", "maximum", "de", "vraisemblance", "ou", "du", "maximum", "a", "posteriori", "(", "MAP", ")", "des", "param\u00e8tres", "dans", "les", "mod\u00e8les", "statistiques", ",", "o\u00f9", "le", "mod\u00e8le", "d\u00e9pend", "de", "variables", "latentes", "non", "observ\u00e9es", "."], "sentence-detokenized": "En statistique, un algorithme d'esp\u00e9rance-maximisation (EM) est une m\u00e9thode it\u00e9rative permettant de trouver des estimations du maximum de vraisemblance ou du maximum a posteriori (MAP) des param\u00e8tres dans les mod\u00e8les statistiques, o\u00f9 le mod\u00e8le d\u00e9pend de variables latentes non observ\u00e9es.", "token2charspan": [[0, 2], [3, 14], [14, 15], [16, 18], [19, 29], [30, 32], [32, 54], [55, 56], [56, 58], [58, 59], [60, 63], [64, 67], [68, 75], [76, 85], [86, 96], [97, 99], [100, 107], [108, 111], [112, 123], [124, 126], [127, 134], [135, 137], [138, 151], [152, 154], [155, 157], [158, 165], [166, 167], [168, 178], [179, 180], [180, 183], [183, 184], [185, 188], [189, 199], [200, 204], [205, 208], [209, 216], [217, 229], [229, 230], [231, 233], [234, 236], [237, 243], [244, 250], [251, 253], [254, 263], [264, 272], [273, 276], [277, 286], [286, 287]]}
{"doc_key": "ai-test-79", "ner": [[8, 11, "metrics"], [13, 17, "metrics"], [18, 21, "metrics"], [23, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 17, 8, 11, "named", "", false, false], [23, 23, 18, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["De", "m\u00eame", ",", "les", "enqu\u00eateurs", "rapportent", "parfois", "le", "taux", "de", "FAUX", "positifs", "(", "FPR", ")", "ainsi", "que", "le", "taux", "de", "FAUX", "n\u00e9gatifs", "(", "FNR", ")", "."], "sentence-detokenized": "De m\u00eame, les enqu\u00eateurs rapportent parfois le taux de FAUX positifs (FPR) ainsi que le taux de FAUX n\u00e9gatifs (FNR).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 23], [24, 34], [35, 42], [43, 45], [46, 50], [51, 53], [54, 58], [59, 67], [68, 69], [69, 72], [72, 73], [74, 79], [80, 83], [84, 86], [87, 91], [92, 94], [95, 99], [100, 108], [109, 110], [110, 113], [113, 114], [114, 115]]}
{"doc_key": "ai-test-80", "ner": [[5, 8, "metrics"], [12, 12, "field"], [16, 18, "metrics"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 12, 5, 8, "usage", "", false, false], [21, 22, 16, 18, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Ce", "concept", "est", "similaire", "au", "rapport", "signal", "/", "bruit", "utilis\u00e9", "dans", "les", "sciences", "et", "\u00e0", "la", "matrice", "de", "confusion", "utilis\u00e9e", "en", "intelligence", "artificielle", "."], "sentence-detokenized": "Ce concept est similaire au rapport signal/bruit utilis\u00e9 dans les sciences et \u00e0 la matrice de confusion utilis\u00e9e en intelligence artificielle.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 24], [25, 27], [28, 35], [36, 42], [42, 43], [43, 48], [49, 56], [57, 61], [62, 65], [66, 74], [75, 77], [78, 79], [80, 82], [83, 90], [91, 93], [94, 103], [104, 112], [113, 115], [116, 128], [129, 141], [141, 142]]}
{"doc_key": "ai-test-81", "ner": [[6, 7, "field"], [12, 13, "researcher"], [19, 20, "researcher"], [22, 23, "researcher"], [34, 37, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 7, 12, 13, "general-affiliation", "", false, false], [6, 7, 19, 20, "general-affiliation", "", false, false], [6, 7, 22, 23, "general-affiliation", "", false, false], [34, 37, 6, 7, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Le", "code", "d'", "\u00e9thique", "sur", "l'", "augmentation", "humaine", ",", "initialement", "pr\u00e9sent\u00e9", "par", "Steve", "Mann", "en", "2004", "et", "affin\u00e9", "avec", "Ray", "Kurzweil", "et", "Marvin", "Minsky", "en", "2013", ",", "a", "finalement", "\u00e9t\u00e9", "ratifi\u00e9", "lors", "de", "la", "conf\u00e9rence", "Virtual", "Reality", "Toronto", "le", "25", "juin", "2017", "."], "sentence-detokenized": "Le code d'\u00e9thique sur l'augmentation humaine, initialement pr\u00e9sent\u00e9 par Steve Mann en 2004 et affin\u00e9 avec Ray Kurzweil et Marvin Minsky en 2013, a finalement \u00e9t\u00e9 ratifi\u00e9 lors de la conf\u00e9rence Virtual Reality Toronto le 25 juin 2017.", "token2charspan": [[0, 2], [3, 7], [8, 10], [10, 17], [18, 21], [22, 24], [24, 36], [37, 44], [44, 45], [46, 58], [59, 67], [68, 71], [72, 77], [78, 82], [83, 85], [86, 90], [91, 93], [94, 100], [101, 105], [106, 109], [110, 118], [119, 121], [122, 128], [129, 135], [136, 138], [139, 143], [143, 144], [145, 146], [147, 157], [158, 161], [162, 169], [170, 174], [175, 177], [178, 180], [181, 191], [192, 199], [200, 207], [208, 215], [216, 218], [219, 221], [222, 226], [227, 231], [231, 232]]}
{"doc_key": "ai-test-82", "ner": [[3, 6, "person"], [12, 13, "organisation"], [19, 20, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 6, 12, 13, "role", "directed_for", false, false], [3, 6, 19, 20, "role", "collaborator", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["En", "1913", ",", "Walter", "R.", "Booth", "a", "r\u00e9alis\u00e9", "10", "films", "pour", "le", "Kinoplastikon", "britannique", ",", "vraisemblablement", "en", "collaboration", "avec", "Cecil", "Hepworth", "."], "sentence-detokenized": "En 1913, Walter R. Booth a r\u00e9alis\u00e9 10 films pour le Kinoplastikon britannique, vraisemblablement en collaboration avec Cecil Hepworth.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 18], [19, 24], [25, 26], [27, 34], [35, 37], [38, 43], [44, 48], [49, 51], [52, 65], [66, 77], [77, 78], [79, 96], [97, 99], [100, 113], [114, 118], [119, 124], [125, 133], [133, 134]]}
{"doc_key": "ai-test-83", "ner": [[17, 17, "location"], [14, 15, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 15, 17, 17, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Ils", "ont", "pr\u00e9sent\u00e9", "leur", "nouveau", "robot", "en", "1961", "lors", "d'", "un", "salon", "professionnel", "au", "Cow", "Palace", "de", "Chicago", "."], "sentence-detokenized": "Ils ont pr\u00e9sent\u00e9 leur nouveau robot en 1961 lors d'un salon professionnel au Cow Palace de Chicago.", "token2charspan": [[0, 3], [4, 7], [8, 16], [17, 21], [22, 29], [30, 35], [36, 38], [39, 43], [44, 48], [49, 51], [51, 53], [54, 59], [60, 73], [74, 76], [77, 80], [81, 87], [88, 90], [91, 98], [98, 99]]}
{"doc_key": "ai-test-84", "ner": [[5, 5, "product"], [10, 12, "task"], [17, 20, "field"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 10, 12, "usage", "", false, false], [5, 5, 17, 20, "usage", "", false, false], [5, 5, 23, 24, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Alors", "que", "certaines", "applications", "de", "chatbot", "utilisent", "des", "processus", "de", "classification", "des", "mots", ",", "des", "processeurs", "de", "traitement", "du", "langage", "naturel", "et", "une", "intelligence", "artificielle", "sophistiqu\u00e9e", ",", "d'", "autres", "se", "contentent", "de", "rechercher", "des", "mots-cl\u00e9s", "g\u00e9n\u00e9raux", "et", "de", "g\u00e9n\u00e9rer", "des", "r\u00e9ponses", "\u00e0", "l'", "aide", "d'", "expressions", "courantes", "obtenues", "\u00e0", "partir", "d'", "une", "biblioth\u00e8que", "ou", "d'", "une", "base", "de", "donn\u00e9es", "associ\u00e9e", "."], "sentence-detokenized": "Alors que certaines applications de chatbot utilisent des processus de classification des mots, des processeurs de traitement du langage naturel et une intelligence artificielle sophistiqu\u00e9e, d'autres se contentent de rechercher des mots-cl\u00e9s g\u00e9n\u00e9raux et de g\u00e9n\u00e9rer des r\u00e9ponses \u00e0 l'aide d'expressions courantes obtenues \u00e0 partir d'une biblioth\u00e8que ou d'une base de donn\u00e9es associ\u00e9e.", "token2charspan": [[0, 5], [6, 9], [10, 19], [20, 32], [33, 35], [36, 43], [44, 53], [54, 57], [58, 67], [68, 70], [71, 85], [86, 89], [90, 94], [94, 95], [96, 99], [100, 111], [112, 114], [115, 125], [126, 128], [129, 136], [137, 144], [145, 147], [148, 151], [152, 164], [165, 177], [178, 190], [190, 191], [192, 194], [194, 200], [201, 203], [204, 214], [215, 217], [218, 228], [229, 232], [233, 242], [243, 251], [252, 254], [255, 257], [258, 265], [266, 269], [270, 278], [279, 280], [281, 283], [283, 287], [288, 290], [290, 301], [302, 311], [312, 320], [321, 322], [323, 329], [330, 332], [332, 335], [336, 348], [349, 351], [352, 354], [354, 357], [358, 362], [363, 365], [366, 373], [374, 382], [382, 383]]}
{"doc_key": "ai-test-85", "ner": [[2, 2, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Le", "mod\u00e8le", "WaveNet", "propos\u00e9", "en", "2016", "atteint", "de", "grandes", "performances", "sur", "la", "qualit\u00e9", "de", "la", "parole", "."], "sentence-detokenized": "Le mod\u00e8le WaveNet propos\u00e9 en 2016 atteint de grandes performances sur la qualit\u00e9 de la parole.", "token2charspan": [[0, 2], [3, 9], [10, 17], [18, 25], [26, 28], [29, 33], [34, 41], [42, 44], [45, 52], [53, 65], [66, 69], [70, 72], [73, 80], [81, 83], [84, 86], [87, 93], [93, 94]]}
{"doc_key": "ai-test-86", "ner": [[5, 5, "product"], [8, 10, "misc"], [13, 17, "misc"], [20, 21, "misc"], [24, 28, "misc"], [30, 31, "organisation"], [33, 33, "organisation"], [35, 42, "organisation"], [44, 44, "organisation"], [46, 49, "organisation"], [51, 52, "organisation"], [54, 56, "organisation"], [58, 60, "organisation"], [63, 63, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[5, 5, 8, 10, "general-affiliation", "", false, false], [5, 5, 13, 17, "general-affiliation", "", false, false], [5, 5, 20, 21, "general-affiliation", "", false, false], [5, 5, 24, 28, "general-affiliation", "", false, false], [30, 31, 5, 5, "usage", "", false, false], [33, 33, 5, 5, "usage", "", false, false], [35, 42, 5, 5, "usage", "", false, false], [44, 44, 5, 5, "usage", "", false, false], [46, 49, 5, 5, "usage", "", false, false], [51, 52, 5, 5, "usage", "", false, false], [54, 56, 5, 5, "usage", "", false, false], [58, 60, 5, 5, "usage", "", false, false], [63, 63, 5, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Organisations", "connues", "pour", "utiliser", "l'", "ALE", "pour", "la", "gestion", "des", "urgences", ",", "les", "secours", "en", "cas", "de", "catastrophe", ",", "la", "communication", "ordinaire", "ou", "la", "r\u00e9ponse", "\u00e0", "des", "situations", "extraordinaires", ":", "Croix-Rouge", "am\u00e9ricaine", ",", "FEMA", ",", "\u00e9quipes", "d'", "assistance", "m\u00e9dicale", "en", "cas", "de", "catastrophe", ",", "OTAN", ",", "Federal", "Bureau", "of", "Investigation", ",", "Nations", "Unies", ",", "AT", "&", "T", ",", "Civil", "Air", "Patrol", ",", "(", "ARES", ")", "."], "sentence-detokenized": "Organisations connues pour utiliser l'ALE pour la gestion des urgences, les secours en cas de catastrophe, la communication ordinaire ou la r\u00e9ponse \u00e0 des situations extraordinaires : Croix-Rouge am\u00e9ricaine, FEMA, \u00e9quipes d'assistance m\u00e9dicale en cas de catastrophe, OTAN, Federal Bureau of Investigation, Nations Unies, AT & T, Civil Air Patrol, (ARES).", "token2charspan": [[0, 13], [14, 21], [22, 26], [27, 35], [36, 38], [38, 41], [42, 46], [47, 49], [50, 57], [58, 61], [62, 70], [70, 71], [72, 75], [76, 83], [84, 86], [87, 90], [91, 93], [94, 105], [105, 106], [107, 109], [110, 123], [124, 133], [134, 136], [137, 139], [140, 147], [148, 149], [150, 153], [154, 164], [165, 180], [181, 182], [183, 194], [195, 205], [205, 206], [207, 211], [211, 212], [213, 220], [221, 223], [223, 233], [234, 242], [243, 245], [246, 249], [250, 252], [253, 264], [264, 265], [266, 270], [270, 271], [272, 279], [280, 286], [287, 289], [290, 303], [303, 304], [305, 312], [313, 318], [318, 319], [320, 322], [323, 324], [325, 326], [326, 327], [328, 333], [334, 337], [338, 344], [344, 345], [346, 347], [347, 351], [351, 352], [352, 353]]}
{"doc_key": "ai-test-87", "ner": [[3, 5, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ici", ",", "le", "delta", "de", "Kronecker", "est", "utilis\u00e9", "pour", "des", "raisons", "de", "simplicit\u00e9", "(", "cf.", "la", "d\u00e9riv\u00e9e", "d'", "une", "fonction", "sigmo\u00efde", ",", "s'", "exprimant", "par", "la", "fonction", "elle-m\u00eame", ")", "."], "sentence-detokenized": "Ici, le delta de Kronecker est utilis\u00e9 pour des raisons de simplicit\u00e9 (cf. la d\u00e9riv\u00e9e d'une fonction sigmo\u00efde, s'exprimant par la fonction elle-m\u00eame).", "token2charspan": [[0, 3], [3, 4], [5, 7], [8, 13], [14, 16], [17, 26], [27, 30], [31, 38], [39, 43], [44, 47], [48, 55], [56, 58], [59, 69], [70, 71], [71, 74], [75, 77], [78, 85], [86, 88], [88, 91], [92, 100], [101, 109], [109, 110], [111, 113], [113, 122], [123, 126], [127, 129], [130, 138], [139, 148], [148, 149], [149, 150]]}
{"doc_key": "ai-test-88", "ner": [[13, 14, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "th\u00e9orie", "repose", "sur", "des", "fondements", "philosophiques", ",", "et", "a", "\u00e9t\u00e9", "fond\u00e9e", "par", "Ray", "Solomonoff", "vers", "1960", ".", "Samuel", "Rathmanner", "et", "Marcus", "Hutter", "."], "sentence-detokenized": "La th\u00e9orie repose sur des fondements philosophiques, et a \u00e9t\u00e9 fond\u00e9e par Ray Solomonoff vers 1960. Samuel Rathmanner et Marcus Hutter.", "token2charspan": [[0, 2], [3, 10], [11, 17], [18, 21], [22, 25], [26, 36], [37, 51], [51, 52], [53, 55], [56, 57], [58, 61], [62, 68], [69, 72], [73, 76], [77, 87], [88, 92], [93, 97], [97, 98], [99, 105], [106, 116], [117, 119], [120, 126], [127, 133], [133, 134]]}
{"doc_key": "ai-test-89", "ner": [[0, 0, "product"], [15, 16, "misc"], [20, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 15, 16, "type-of", "", false, false], [0, 0, 20, 21, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["WordNet", ",", "une", "base", "de", "donn\u00e9es", "disponible", "gratuitement", ",", "con\u00e7ue", "\u00e0", "l'", "origine", "comme", "un", "r\u00e9seau", "s\u00e9mantique", "bas\u00e9", "sur", "des", "principes", "psycholinguistiques", ",", "a", "\u00e9t\u00e9", "enrichie", "par", "l'", "ajout", "de", "d\u00e9finitions", "et", "est", "d\u00e9sormais", "\u00e9galement", "consid\u00e9r\u00e9e", "comme", "un", "dictionnaire", "."], "sentence-detokenized": "WordNet, une base de donn\u00e9es disponible gratuitement, con\u00e7ue \u00e0 l'origine comme un r\u00e9seau s\u00e9mantique bas\u00e9 sur des principes psycholinguistiques, a \u00e9t\u00e9 enrichie par l'ajout de d\u00e9finitions et est d\u00e9sormais \u00e9galement consid\u00e9r\u00e9e comme un dictionnaire.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 17], [18, 20], [21, 28], [29, 39], [40, 52], [52, 53], [54, 60], [61, 62], [63, 65], [65, 72], [73, 78], [79, 81], [82, 88], [89, 99], [100, 104], [105, 108], [109, 112], [113, 122], [123, 142], [142, 143], [144, 145], [146, 149], [150, 158], [159, 162], [163, 165], [165, 170], [171, 173], [174, 185], [186, 188], [189, 192], [193, 202], [203, 212], [213, 223], [224, 229], [230, 232], [233, 245], [245, 246]]}
{"doc_key": "ai-test-90", "ner": [[11, 12, "field"], [24, 24, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[24, 24, 11, 12, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Les", "progr\u00e8s", "r\u00e9alis\u00e9s", "dans", "le", "domaine", "de", "la", "recherche", "sur", "l'", "imagerie", "informatique", "sont", "pr\u00e9sent\u00e9s", "\u00e0", "plusieurs", "occasions", ",", "notamment", "dans", "les", "publications", "du", "SIGGRAPH", "et", "de", "la", "..."], "sentence-detokenized": "Les progr\u00e8s r\u00e9alis\u00e9s dans le domaine de la recherche sur l'imagerie informatique sont pr\u00e9sent\u00e9s \u00e0 plusieurs occasions, notamment dans les publications du SIGGRAPH et de la...", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 25], [26, 28], [29, 36], [37, 39], [40, 42], [43, 52], [53, 56], [57, 59], [59, 67], [68, 80], [81, 85], [86, 95], [96, 97], [98, 107], [108, 117], [117, 118], [119, 128], [129, 133], [134, 137], [138, 150], [151, 153], [154, 162], [163, 165], [166, 168], [169, 171], [171, 174]]}
{"doc_key": "ai-test-91", "ner": [[0, 1, "task"], [11, 12, "task"], [15, 16, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 0, 1, "part-of", "", false, false], [15, 16, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "classification", "peut", "\u00eatre", "consid\u00e9r\u00e9e", "comme", "deux", "probl\u00e8mes", "distincts", ":", "la", "classification", "binaire", "et", "la", "classification", "multi-classes", "."], "sentence-detokenized": "La classification peut \u00eatre consid\u00e9r\u00e9e comme deux probl\u00e8mes distincts : la classification binaire et la classification multi-classes.", "token2charspan": [[0, 2], [3, 17], [18, 22], [23, 27], [28, 38], [39, 44], [45, 49], [50, 59], [60, 69], [70, 71], [72, 74], [75, 89], [90, 97], [98, 100], [101, 103], [104, 118], [119, 132], [132, 133]]}
{"doc_key": "ai-test-92", "ner": [[14, 15, "algorithm"], [22, 24, "algorithm"], [26, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 24, 14, 15, "type-of", "", false, false], [26, 26, 22, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Les", "chercheurs", "de", "g\u00e8nes", "avanc\u00e9s", "pour", "les", "g\u00e9nomes", "procaryotes", "et", "eucaryotes", "utilisent", "g\u00e9n\u00e9ralement", "des", "mod\u00e8les", "probabilistes", "complexes", ",", "tels", "que", "les", "mod\u00e8les", "de", "Markov", "cach\u00e9s", "(", "HMM", ")", ",", "pour", "combiner", "les", "informations", "provenant", "d'", "une", "vari\u00e9t\u00e9", "de", "mesures", "diff\u00e9rentes", "du", "signal", "et", "du", "contenu", "."], "sentence-detokenized": "Les chercheurs de g\u00e8nes avanc\u00e9s pour les g\u00e9nomes procaryotes et eucaryotes utilisent g\u00e9n\u00e9ralement des mod\u00e8les probabilistes complexes, tels que les mod\u00e8les de Markov cach\u00e9s (HMM), pour combiner les informations provenant d'une vari\u00e9t\u00e9 de mesures diff\u00e9rentes du signal et du contenu.", "token2charspan": [[0, 3], [4, 14], [15, 17], [18, 23], [24, 31], [32, 36], [37, 40], [41, 48], [49, 60], [61, 63], [64, 74], [75, 84], [85, 97], [98, 101], [102, 109], [110, 123], [124, 133], [133, 134], [135, 139], [140, 143], [144, 147], [148, 155], [156, 158], [159, 165], [166, 172], [173, 174], [174, 177], [177, 178], [178, 179], [180, 184], [185, 193], [194, 197], [198, 210], [211, 220], [221, 223], [223, 226], [227, 234], [235, 237], [238, 245], [246, 257], [258, 260], [261, 267], [268, 270], [271, 273], [274, 281], [281, 282]]}
{"doc_key": "ai-test-93", "ner": [[0, 1, "misc"], [4, 4, "misc"], [10, 11, "field"], [15, 16, "algorithm"], [20, 22, "algorithm"], [24, 24, "algorithm"], [38, 39, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 10, 11, "part-of", "", false, false], [0, 1, 15, 16, "usage", "", false, false], [4, 4, 0, 1, "named", "", false, false], [20, 22, 0, 1, "origin", "", true, false], [24, 24, 20, 22, "named", "", false, false], [38, 39, 0, 1, "origin", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["La", "neuro\u00e9volution", ",", "ou", "neuro-\u00e9volution", ",", "est", "une", "forme", "d'", "intelligence", "artificielle", "qui", "utilise", "des", "algorithmes", "\u00e9volutionnaires", "pour", "g\u00e9n\u00e9rer", "des", "r\u00e9seaux", "neuronaux", "artificiels", "(", "ANN", ")", ",", "des", "param\u00e8tres", ",", "une", "topologie", "et", "des", "r\u00e8gles", ".", "et", "la", "robotique", "\u00e9volutionnaire", "."], "sentence-detokenized": "La neuro\u00e9volution, ou neuro-\u00e9volution, est une forme d'intelligence artificielle qui utilise des algorithmes \u00e9volutionnaires pour g\u00e9n\u00e9rer des r\u00e9seaux neuronaux artificiels (ANN), des param\u00e8tres, une topologie et des r\u00e8gles. et la robotique \u00e9volutionnaire.", "token2charspan": [[0, 2], [3, 17], [17, 18], [19, 21], [22, 37], [37, 38], [39, 42], [43, 46], [47, 52], [53, 55], [55, 67], [68, 80], [81, 84], [85, 92], [93, 96], [97, 108], [109, 124], [125, 129], [130, 137], [138, 141], [142, 149], [150, 159], [160, 171], [172, 173], [173, 176], [176, 177], [177, 178], [179, 182], [183, 193], [193, 194], [195, 198], [199, 208], [209, 211], [212, 215], [216, 222], [222, 223], [224, 226], [227, 229], [230, 239], [240, 254], [254, 255]]}
{"doc_key": "ai-test-94", "ner": [[2, 2, "organisation"], [10, 10, "metrics"], [11, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 2, 2, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Depuis", "qu'", "IBM", "a", "propos\u00e9", "et", "r\u00e9alis\u00e9", "le", "syst\u00e8me", "de", "BLEU", "Papineni", "et", "al", "."], "sentence-detokenized": "Depuis qu'IBM a propos\u00e9 et r\u00e9alis\u00e9 le syst\u00e8me de BLEU Papineni et al.", "token2charspan": [[0, 6], [7, 10], [10, 13], [14, 15], [16, 23], [24, 26], [27, 34], [35, 37], [38, 45], [46, 48], [49, 53], [54, 62], [63, 65], [66, 68], [68, 69]]}
{"doc_key": "ai-test-95", "ner": [[13, 19, "conference"], [21, 21, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[21, 21, 13, 19, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["En", "2009", ",", "des", "experts", "ont", "particip\u00e9", "\u00e0", "une", "conf\u00e9rence", "organis\u00e9e", "par", "l'", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "pour", "discuter", "de", "la", "question", "de", "savoir", "si", "les", "ordinateurs", "et", "les", "robots", "pourraient", "acqu\u00e9rir", "une", "certaine", "autonomie", "et", "dans", "quelle", "mesure", "ces", "capacit\u00e9s", "pourraient", "constituer", "une", "menace", "ou", "un", "danger", "."], "sentence-detokenized": "En 2009, des experts ont particip\u00e9 \u00e0 une conf\u00e9rence organis\u00e9e par l'Association for the Advancement of Artificial Intelligence (AAAI) pour discuter de la question de savoir si les ordinateurs et les robots pourraient acqu\u00e9rir une certaine autonomie et dans quelle mesure ces capacit\u00e9s pourraient constituer une menace ou un danger.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 20], [21, 24], [25, 34], [35, 36], [37, 40], [41, 51], [52, 61], [62, 65], [66, 68], [68, 79], [80, 83], [84, 87], [88, 99], [100, 102], [103, 113], [114, 126], [127, 128], [128, 132], [132, 133], [134, 138], [139, 147], [148, 150], [151, 153], [154, 162], [163, 165], [166, 172], [173, 175], [176, 179], [180, 191], [192, 194], [195, 198], [199, 205], [206, 216], [217, 225], [226, 229], [230, 238], [239, 248], [249, 251], [252, 256], [257, 263], [264, 270], [271, 274], [275, 284], [285, 295], [296, 306], [307, 310], [311, 317], [318, 320], [321, 323], [324, 330], [330, 331]]}
{"doc_key": "ai-test-96", "ner": [[34, 36, "metrics"], [37, 38, "researcher"], [40, 41, "researcher"], [43, 46, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[43, 46, 34, 36, "topic", "", false, false], [43, 46, 37, 38, "artifact", "", false, false], [43, 46, 40, 41, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Apr\u00e8s", "boosting", ",", "un", "classificateur", "construit", "\u00e0", "partir", "de", "200", "caract\u00e9ristiques", "pourrait", "donner", "un", "taux", "de", "d\u00e9tection", "de", "95", "%", "avec", "un", "^", "{", "-", "5}", "/", "math", "FALSE", "taux", "positif", ".", "/", "math", "FALSE", "positive", "rate", ".P.", "Viola", ",", "M.", "Jones", ",", "Robust", "Real-time", "Object", "Detection", ",", "2001", "."], "sentence-detokenized": "Apr\u00e8s boosting, un classificateur construit \u00e0 partir de 200 caract\u00e9ristiques pourrait donner un taux de d\u00e9tection de 95% avec un ^ {-5} / math FALSE taux positif. / math FALSE positive rate .P. Viola, M. Jones, Robust Real-time Object Detection, 2001.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 18], [19, 33], [34, 43], [44, 45], [46, 52], [53, 55], [56, 59], [60, 76], [77, 85], [86, 92], [93, 95], [96, 100], [101, 103], [104, 113], [114, 116], [117, 119], [119, 120], [121, 125], [126, 128], [129, 130], [131, 132], [132, 133], [133, 135], [136, 137], [138, 142], [143, 148], [149, 153], [154, 161], [161, 162], [163, 164], [165, 169], [170, 175], [176, 184], [185, 189], [190, 193], [194, 199], [199, 200], [201, 203], [204, 209], [209, 210], [211, 217], [218, 227], [228, 234], [235, 244], [244, 245], [246, 250], [250, 251]]}
{"doc_key": "ai-test-97", "ner": [[9, 9, "programlang"], [12, 12, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Le", "site", "web", "\u00e9tait", "\u00e0", "l'", "origine", "bas\u00e9", "sur", "Perl", ",", "mais", "IMDb", "ne", "divulgue", "plus", "le", "logiciel", "qu'", "il", "utilise", "pour", "des", "raisons", "de", "s\u00e9curit\u00e9", "."], "sentence-detokenized": "Le site web \u00e9tait \u00e0 l'origine bas\u00e9 sur Perl, mais IMDb ne divulgue plus le logiciel qu'il utilise pour des raisons de s\u00e9curit\u00e9.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 17], [18, 19], [20, 22], [22, 29], [30, 34], [35, 38], [39, 43], [43, 44], [45, 49], [50, 54], [55, 57], [58, 66], [67, 71], [72, 74], [75, 83], [84, 87], [87, 89], [90, 97], [98, 102], [103, 106], [107, 114], [115, 117], [118, 126], [126, 127]]}
{"doc_key": "ai-test-98", "ner": [[7, 8, "researcher"], [10, 11, "researcher"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "start", "-up", "a", "\u00e9t\u00e9", "fond\u00e9e", "par", "Demis", "Hassabis", ",", "Shane", "Legg", "et", "Mustafa", "Suleyman", "en", "2010", "."], "sentence-detokenized": "La start-up a \u00e9t\u00e9 fond\u00e9e par Demis Hassabis, Shane Legg et Mustafa Suleyman en 2010.", "token2charspan": [[0, 2], [3, 8], [8, 11], [12, 13], [14, 17], [18, 24], [25, 28], [29, 34], [35, 43], [43, 44], [45, 50], [51, 55], [56, 58], [59, 66], [67, 75], [76, 78], [79, 83], [83, 84]]}
{"doc_key": "ai-test-99", "ner": [[1, 3, "misc"], [9, 11, "metrics"], [26, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 11, 1, 3, "type-of", "", false, false], [26, 27, 1, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Deux", "fonctions", "de", "perte", "tr\u00e8s", "couramment", "utilis\u00e9es", "sont", "l'", "erreur", "quadratique", "moyenne", ",", "mathL", "(", "a", ")", "=", "a", "^", "2", "/", "math", ",", "et", "la", "perte", "absolue", ",", "mathL", "(", "a", ")", "=", "|", "a", "|", "/", "math", "."], "sentence-detokenized": "Deux fonctions de perte tr\u00e8s couramment utilis\u00e9es sont l'erreur quadratique moyenne, mathL (a) = a ^ 2 / math, et la perte absolue, mathL (a) = | a | / math.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 23], [24, 28], [29, 39], [40, 49], [50, 54], [55, 57], [57, 63], [64, 75], [76, 83], [83, 84], [85, 90], [91, 92], [92, 93], [93, 94], [95, 96], [97, 98], [99, 100], [101, 102], [103, 104], [105, 109], [109, 110], [111, 113], [114, 116], [117, 122], [123, 130], [130, 131], [132, 137], [138, 139], [139, 140], [140, 141], [142, 143], [144, 145], [146, 147], [148, 149], [150, 151], [152, 156], [156, 157]]}
{"doc_key": "ai-test-100", "ner": [[0, 6, "algorithm"], [15, 18, "algorithm"], [20, 20, "algorithm"], [24, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 6, 15, 18, "type-of", "example_of", false, false], [15, 18, 24, 27, "related-to", "", false, false], [20, 20, 15, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "machine", "\u00e0", "vecteurs", "de", "support", "\u00e0", "marge", "douce", "d\u00e9crite", "ci-dessus", "est", "un", "exemple", "de", "minimisation", "empirique", "du", "risque", "(", "ERM", ")", "pour", "la", "perte", "de", "la", "charni\u00e8re", "."], "sentence-detokenized": "La machine \u00e0 vecteurs de support \u00e0 marge douce d\u00e9crite ci-dessus est un exemple de minimisation empirique du risque (ERM) pour la perte de la charni\u00e8re.", "token2charspan": [[0, 2], [3, 10], [11, 12], [13, 21], [22, 24], [25, 32], [33, 34], [35, 40], [41, 46], [47, 54], [55, 64], [65, 68], [69, 71], [72, 79], [80, 82], [83, 95], [96, 105], [106, 108], [109, 115], [116, 117], [117, 120], [120, 121], [122, 126], [127, 129], [130, 135], [136, 138], [139, 141], [142, 151], [151, 152]]}
{"doc_key": "ai-test-101", "ner": [[8, 9, "field"], [3, 4, "task"], [12, 14, "task"], [25, 25, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 14, 8, 9, "origin", "", false, false], [12, 14, 3, 4, "type-of", "", false, false], [25, 25, 12, 14, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Approche", "de", "la", "traduction", "automatique", "bas\u00e9e", "sur", "l'", "apprentissage", "profond", ",", "la", "traduction", "automatique", "neuronale", "a", "fait", "des", "progr\u00e8s", "rapides", "ces", "derni\u00e8res", "ann\u00e9es", ",", "et", "Google", "a", "annonc\u00e9", "que", "ses", "services", "de", "traduction", "utilisaient", "d\u00e9sormais", "cette", "technologie", "de", "pr\u00e9f\u00e9rence", "\u00e0", "ses", "anciennes", "m\u00e9thodes", "statistiques", "."], "sentence-detokenized": "Approche de la traduction automatique bas\u00e9e sur l'apprentissage profond, la traduction automatique neuronale a fait des progr\u00e8s rapides ces derni\u00e8res ann\u00e9es, et Google a annonc\u00e9 que ses services de traduction utilisaient d\u00e9sormais cette technologie de pr\u00e9f\u00e9rence \u00e0 ses anciennes m\u00e9thodes statistiques.", "token2charspan": [[0, 8], [9, 11], [12, 14], [15, 25], [26, 37], [38, 43], [44, 47], [48, 50], [50, 63], [64, 71], [71, 72], [73, 75], [76, 86], [87, 98], [99, 108], [109, 110], [111, 115], [116, 119], [120, 127], [128, 135], [136, 139], [140, 149], [150, 156], [156, 157], [158, 160], [161, 167], [168, 169], [170, 177], [178, 181], [182, 185], [186, 194], [195, 197], [198, 208], [209, 220], [221, 230], [231, 236], [237, 248], [249, 251], [252, 262], [263, 264], [265, 268], [269, 278], [279, 287], [288, 300], [300, 301]]}
{"doc_key": "ai-test-102", "ner": [[20, 20, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Cela", "permet", "d'", "obtenir", "des", "gains", "de", "performance", "tr\u00e8s", "importants", "lorsque", "l'", "on", "travaille", "avec", "de", "grands", "corpus", "tels", "que", "WordNet", "."], "sentence-detokenized": "Cela permet d'obtenir des gains de performance tr\u00e8s importants lorsque l'on travaille avec de grands corpus tels que WordNet.", "token2charspan": [[0, 4], [5, 11], [12, 14], [14, 21], [22, 25], [26, 31], [32, 34], [35, 46], [47, 51], [52, 62], [63, 70], [71, 73], [73, 75], [76, 85], [86, 90], [91, 93], [94, 100], [101, 107], [108, 112], [113, 116], [117, 124], [124, 125]]}
{"doc_key": "ai-test-103", "ner": [[0, 3, "task"], [7, 7, "field"], [15, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 15, 18, "part-of", "", false, false], [15, 18, 7, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "d\u00e9tection", "des", "visages", "est", "utilis\u00e9e", "en", "biom\u00e9trie", ",", "souvent", "dans", "le", "cadre", "d'", "un", "syst\u00e8me", "de", "reconnaissance", "faciale", "(", "ou", "conjointement", "avec", "celui-ci", ")", "."], "sentence-detokenized": "La d\u00e9tection des visages est utilis\u00e9e en biom\u00e9trie, souvent dans le cadre d'un syst\u00e8me de reconnaissance faciale (ou conjointement avec celui-ci).", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 24], [25, 28], [29, 37], [38, 40], [41, 50], [50, 51], [52, 59], [60, 64], [65, 67], [68, 73], [74, 76], [76, 78], [79, 86], [87, 89], [90, 104], [105, 112], [113, 114], [114, 116], [117, 130], [131, 135], [136, 144], [144, 145], [145, 146]]}
{"doc_key": "ai-test-104", "ner": [[2, 6, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["form\u00e9s", "par", "estimation", "du", "maximum", "de", "vraisemblance", "."], "sentence-detokenized": "form\u00e9s par estimation du maximum de vraisemblance.", "token2charspan": [[0, 6], [7, 10], [11, 21], [22, 24], [25, 32], [33, 35], [36, 49], [49, 50]]}
{"doc_key": "ai-test-105", "ner": [[2, 2, "country"], [4, 8, "organisation"], [12, 12, "location"], [15, 15, "country"], [17, 20, "organisation"], [22, 22, "country"], [27, 27, "organisation"], [32, 35, "organisation"], [37, 37, "country"], [48, 51, "organisation"], [53, 53, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[4, 8, 12, 12, "physical", "", false, false], [12, 12, 15, 15, "physical", "", false, false], [17, 20, 22, 22, "physical", "", false, false], [32, 35, 37, 37, "physical", "", false, false], [48, 51, 53, 53, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Ltd.", "en", "Tha\u00eflande", ";", "Komatsu", "(", "Shanghai", ")", "Ltd.", "en", "1996", "\u00e0", "Shanghai", ",", "en", "Chine", ";", "Industrial", "Power", "Alliance", "Ltd.", "au", "Japon", ",", "une", "coentreprise", "avec", "Cummins", ",", "en", "1998", ";", "L", "&", "T-Komatsu", "Limited", "en", "Inde", "en", "1998", "(", "actions", "vendues", "en", "2013", ")", ";", "et", "Komatsu", "Brasil", "International", "Ltda.", "au", "Br\u00e9sil", "en", "1998", "."], "sentence-detokenized": "Ltd. en Tha\u00eflande ; Komatsu (Shanghai) Ltd. en 1996 \u00e0 Shanghai, en Chine ; Industrial Power Alliance Ltd. au Japon, une coentreprise avec Cummins, en 1998 ; L & T-Komatsu Limited en Inde en 1998 (actions vendues en 2013) ; et Komatsu Brasil International Ltda. au Br\u00e9sil en 1998.", "token2charspan": [[0, 4], [5, 7], [8, 17], [18, 19], [20, 27], [28, 29], [29, 37], [37, 38], [39, 43], [44, 46], [47, 51], [52, 53], [54, 62], [62, 63], [64, 66], [67, 72], [73, 74], [75, 85], [86, 91], [92, 100], [101, 105], [106, 108], [109, 114], [114, 115], [116, 119], [120, 132], [133, 137], [138, 145], [145, 146], [147, 149], [150, 154], [155, 156], [157, 158], [159, 160], [161, 170], [171, 178], [179, 181], [182, 186], [187, 189], [190, 194], [195, 196], [196, 203], [204, 211], [212, 214], [215, 219], [219, 220], [221, 222], [223, 225], [226, 233], [234, 240], [241, 254], [255, 260], [261, 263], [264, 270], [271, 273], [274, 278], [278, 279]]}
{"doc_key": "ai-test-106", "ner": [[0, 1, "organisation"], [6, 8, "misc"], [19, 19, "misc"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 14, 0, 1, "physical", "", false, false], [13, 14, 6, 8, "general-affiliation", "", false, false], [13, 14, 19, 19, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "dgp", "accueille", "aussi", "occasionnellement", "des", "artistes", "en", "r\u00e9sidence", "(", "par", "exemple", ",", "Chris", "Landreth", ",", "laur\u00e9at", "d'", "un", "Oscar", ")", "."], "sentence-detokenized": "La dgp accueille aussi occasionnellement des artistes en r\u00e9sidence (par exemple, Chris Landreth, laur\u00e9at d'un Oscar).", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 22], [23, 40], [41, 44], [45, 53], [54, 56], [57, 66], [67, 68], [68, 71], [72, 79], [79, 80], [81, 86], [87, 95], [95, 96], [97, 104], [105, 107], [107, 109], [110, 115], [115, 116], [116, 117]]}
{"doc_key": "ai-test-107", "ner": [[7, 10, "misc"], [13, 15, "misc"], [18, 21, "misc"], [25, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Il", "comprend", "actuellement", "quatre", "sous-comp\u00e9titions", ":", "le", "concours", "de", "robotique", "RoboMaster", ",", "le", "d\u00e9fi", "technique", "RoboMaster", ",", "le", "d\u00e9fi", "AI", "ICRA", "RoboMaster", "et", "le", "nouveau", "tournoi", "RoboMaster", "pour", "les", "jeunes", "."], "sentence-detokenized": "Il comprend actuellement quatre sous-comp\u00e9titions : le concours de robotique RoboMaster, le d\u00e9fi technique RoboMaster, le d\u00e9fi AI ICRA RoboMaster et le nouveau tournoi RoboMaster pour les jeunes.", "token2charspan": [[0, 2], [3, 11], [12, 24], [25, 31], [32, 49], [50, 51], [52, 54], [55, 63], [64, 66], [67, 76], [77, 87], [87, 88], [89, 91], [92, 96], [97, 106], [107, 117], [117, 118], [119, 121], [122, 126], [127, 129], [130, 134], [135, 145], [146, 148], [149, 151], [152, 159], [160, 167], [168, 178], [179, 183], [184, 187], [188, 194], [194, 195]]}
{"doc_key": "ai-test-108", "ner": [[10, 13, "field"], [20, 23, "algorithm"], [29, 30, "algorithm"], [35, 36, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 13, 29, 30, "usage", "", false, false], [10, 13, 35, 36, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Au", "d\u00e9but", "des", "ann\u00e9es", "2000", ",", "la", "strat\u00e9gie", "dominante", "de", "traitement", "de", "la", "parole", "a", "commenc\u00e9", "\u00e0", "s'", "\u00e9loigner", "du", "mod\u00e8le", "de", "Markov", "cach\u00e9", "pour", "s'", "orienter", "vers", "des", "r\u00e9seaux", "neuronaux", "plus", "modernes", "et", "l'", "apprentissage", "profond", "."], "sentence-detokenized": "Au d\u00e9but des ann\u00e9es 2000, la strat\u00e9gie dominante de traitement de la parole a commenc\u00e9 \u00e0 s'\u00e9loigner du mod\u00e8le de Markov cach\u00e9 pour s'orienter vers des r\u00e9seaux neuronaux plus modernes et l'apprentissage profond.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 19], [20, 24], [24, 25], [26, 28], [29, 38], [39, 48], [49, 51], [52, 62], [63, 65], [66, 68], [69, 75], [76, 77], [78, 86], [87, 88], [89, 91], [91, 99], [100, 102], [103, 109], [110, 112], [113, 119], [120, 125], [126, 130], [131, 133], [133, 141], [142, 146], [147, 150], [151, 158], [159, 168], [169, 173], [174, 182], [183, 185], [186, 188], [188, 201], [202, 209], [209, 210]]}
{"doc_key": "ai-test-109", "ner": [[10, 12, "misc"], [17, 20, "metrics"], [23, 26, "metrics"], [33, 36, "metrics"], [39, 42, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[17, 20, 23, 26, "related-to", "equal", false, false], [33, 36, 39, 42, "related-to", "equal", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Une", "autre", "expression", "\u00e9quivalente", ",", "dans", "le", "cas", "d'", "un", "taux", "cible", "binaire", ",", "est", "que", "le", "taux", "de", "VRAI", "positif", "et", "le", "taux", "de", "FAUX", "positif", "sont", "\u00e9gaux", "(", "et", "donc", "le", "taux", "de", "FAUX", "n\u00e9gatif", "et", "le", "taux", "de", "VRAI", "n\u00e9gatif", "sont", "\u00e9gaux", ")", "pour", "chaque", "valeur", "des", "caract\u00e9ristiques", "sensibles", ":"], "sentence-detokenized": "Une autre expression \u00e9quivalente, dans le cas d'un taux cible binaire, est que le taux de VRAI positif et le taux de FAUX positif sont \u00e9gaux (et donc le taux de FAUX n\u00e9gatif et le taux de VRAI n\u00e9gatif sont \u00e9gaux) pour chaque valeur des caract\u00e9ristiques sensibles :", "token2charspan": [[0, 3], [4, 9], [10, 20], [21, 32], [32, 33], [34, 38], [39, 41], [42, 45], [46, 48], [48, 50], [51, 55], [56, 61], [62, 69], [69, 70], [71, 74], [75, 78], [79, 81], [82, 86], [87, 89], [90, 94], [95, 102], [103, 105], [106, 108], [109, 113], [114, 116], [117, 121], [122, 129], [130, 134], [135, 140], [141, 142], [142, 144], [145, 149], [150, 152], [153, 157], [158, 160], [161, 165], [166, 173], [174, 176], [177, 179], [180, 184], [185, 187], [188, 192], [193, 200], [201, 205], [206, 211], [211, 212], [213, 217], [218, 224], [225, 231], [232, 235], [236, 252], [253, 262], [263, 264]]}
{"doc_key": "ai-test-110", "ner": [[2, 2, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "fonction", "MATLAB", ","], "sentence-detokenized": "La fonction MATLAB,", "token2charspan": [[0, 2], [3, 11], [12, 18], [18, 19]]}
{"doc_key": "ai-test-111", "ner": [[1, 2, "product"], [8, 9, "misc"], [20, 21, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 1, 2, "part-of", "", false, false], [20, 21, 1, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Un", "robot", "articul\u00e9", "est", "un", "robot", "dot\u00e9", "d'", "articulations", "rotatives", "(", "par", "exemple", ",", "un", "robot", "\u00e0", "pattes", "ou", "un", "robot", "industriel", ")", "."], "sentence-detokenized": "Un robot articul\u00e9 est un robot dot\u00e9 d'articulations rotatives (par exemple, un robot \u00e0 pattes ou un robot industriel).", "token2charspan": [[0, 2], [3, 8], [9, 17], [18, 21], [22, 24], [25, 30], [31, 35], [36, 38], [38, 51], [52, 61], [62, 63], [63, 66], [67, 74], [74, 75], [76, 78], [79, 84], [85, 86], [87, 93], [94, 96], [97, 99], [100, 105], [106, 116], [116, 117], [117, 118]]}
{"doc_key": "ai-test-112", "ner": [[0, 0, "product"], [8, 9, "product"], [11, 12, "product"], [20, 21, "misc"], [29, 32, "product"], [37, 39, "misc"], [48, 48, "location"], [51, 51, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 20, 21, "general-affiliation", "nationality", false, false], [0, 0, 37, 39, "usage", "", false, false], [0, 0, 48, 48, "physical", "", false, false], [8, 9, 0, 0, "named", "", false, false], [11, 12, 0, 0, "named", "", false, false], [48, 48, 51, 51, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pandora", "(", "\u00e9galement", "connu", "sous", "le", "nom", "de", "Pandora", "Media", "ou", "Pandora", "Radio", ")", "est", "un", "service", "de", "radio", "Internet", "am\u00e9ricain", "de", "diffusion", "de", "musique", "en", "continu", "et", "de", "syst\u00e8me", "de", "recommandation", "automatis\u00e9", ",", "aliment\u00e9", "par", "le", "Music", "Genome", "Project", "et", "dont", "le", "si\u00e8ge", "social", "se", "trouve", "\u00e0", "Oakland", ",", "en", "Californie", "."], "sentence-detokenized": "Pandora (\u00e9galement connu sous le nom de Pandora Media ou Pandora Radio) est un service de radio Internet am\u00e9ricain de diffusion de musique en continu et de syst\u00e8me de recommandation automatis\u00e9, aliment\u00e9 par le Music Genome Project et dont le si\u00e8ge social se trouve \u00e0 Oakland, en Californie.", "token2charspan": [[0, 7], [8, 9], [9, 18], [19, 24], [25, 29], [30, 32], [33, 36], [37, 39], [40, 47], [48, 53], [54, 56], [57, 64], [65, 70], [70, 71], [72, 75], [76, 78], [79, 86], [87, 89], [90, 95], [96, 104], [105, 114], [115, 117], [118, 127], [128, 130], [131, 138], [139, 141], [142, 149], [150, 152], [153, 155], [156, 163], [164, 166], [167, 181], [182, 192], [192, 193], [194, 202], [203, 206], [207, 209], [210, 215], [216, 222], [223, 230], [231, 233], [234, 238], [239, 241], [242, 247], [248, 254], [255, 257], [258, 264], [265, 266], [267, 274], [274, 275], [276, 278], [279, 289], [289, 290]]}
{"doc_key": "ai-test-113", "ner": [[9, 12, "organisation"], [18, 22, "organisation"], [29, 33, "conference"], [45, 45, "conference"], [48, 48, "conference"], [51, 51, "conference"], [54, 54, "conference"], [57, 57, "conference"], [60, 60, "conference"], [63, 63, "conference"], [66, 66, "conference"], [69, 69, "conference"], [72, 72, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [], "relations_mapping_to_source": [], "sentence": ["Elle", "est", "membre", "du", "conseil", "d'", "administration", "de", "l'", "International", "Machine", "Learning", "Society", ",", "a", "\u00e9t\u00e9", "membre", "du", "conseil", "ex\u00e9cutif", "de", "l'", "AAAI", ",", "a", "\u00e9t\u00e9", "copr\u00e9sidente", "de", "l'", "ICML", "2011", "et", "a", "\u00e9t\u00e9", "membre", "senior", "du", "conseil", "d'", "administration", "de", "conf\u00e9rences", "telles", "que", "l'", "AAAI", ",", "l'", "ICML", ",", "l'", "IJCAI", ",", "l'", "ISWC", ",", "le", "KDD", ",", "le", "SIGMOD", ",", "l'", "UAI", ",", "le", "VLDB", ",", "le", "WSDM", "et", "le", "WWW", "."], "sentence-detokenized": "Elle est membre du conseil d'administration de l'International Machine Learning Society, a \u00e9t\u00e9 membre du conseil ex\u00e9cutif de l'AAAI, a \u00e9t\u00e9 copr\u00e9sidente de l'ICML 2011 et a \u00e9t\u00e9 membre senior du conseil d'administration de conf\u00e9rences telles que l'AAAI, l'ICML, l'IJCAI, l'ISWC, le KDD, le SIGMOD, l'UAI, le VLDB, le WSDM et le WWW.", "token2charspan": [[0, 4], [5, 8], [9, 15], [16, 18], [19, 26], [27, 29], [29, 43], [44, 46], [47, 49], [49, 62], [63, 70], [71, 79], [80, 87], [87, 88], [89, 90], [91, 94], [95, 101], [102, 104], [105, 112], [113, 121], [122, 124], [125, 127], [127, 131], [131, 132], [133, 134], [135, 138], [139, 151], [152, 154], [155, 157], [157, 161], [162, 166], [167, 169], [170, 171], [172, 175], [176, 182], [183, 189], [190, 192], [193, 200], [201, 203], [203, 217], [218, 220], [221, 232], [233, 239], [240, 243], [244, 246], [246, 250], [250, 251], [252, 254], [254, 258], [258, 259], [260, 262], [262, 267], [267, 268], [269, 271], [271, 275], [275, 276], [277, 279], [280, 283], [283, 284], [285, 287], [288, 294], [294, 295], [296, 298], [298, 301], [301, 302], [303, 305], [306, 310], [310, 311], [312, 314], [315, 319], [320, 322], [323, 325], [326, 329], [329, 330]]}
{"doc_key": "ai-test-114", "ner": [[0, 2, "researcher"], [5, 10, "organisation"], [12, 12, "organisation"], [20, 20, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 10, "role", "", false, false], [12, 12, 5, 10, "named", "", false, false], [20, 20, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["James", "S.", "Albus", ",", "du", "National", "Institute", "of", "Standards", "and", "Technology", "(", "NIST", ")", ",", "a", "mis", "au", "point", "la", "Robocrane", ",", "o\u00f9", "la", "plate-forme", "est", "suspendue", "\u00e0", "six", "c\u00e2bles", "au", "lieu", "d'", "\u00eatre", "soutenue", "par", "six", "v\u00e9rins", "."], "sentence-detokenized": "James S. Albus, du National Institute of Standards and Technology (NIST), a mis au point la Robocrane, o\u00f9 la plate-forme est suspendue \u00e0 six c\u00e2bles au lieu d'\u00eatre soutenue par six v\u00e9rins.", "token2charspan": [[0, 5], [6, 8], [9, 14], [14, 15], [16, 18], [19, 27], [28, 37], [38, 40], [41, 50], [51, 54], [55, 65], [66, 67], [67, 71], [71, 72], [72, 73], [74, 75], [76, 79], [80, 82], [83, 88], [89, 91], [92, 101], [101, 102], [103, 105], [106, 108], [109, 120], [121, 124], [125, 134], [135, 136], [137, 140], [141, 147], [148, 150], [151, 155], [156, 158], [158, 162], [163, 171], [172, 175], [176, 179], [180, 186], [186, 187]]}
{"doc_key": "ai-test-115", "ner": [[4, 7, "algorithm"], [13, 14, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 14, 4, 7, "type-of", "", false, false], [19, 20, 13, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Une", "autre", "classe", "d'", "algorithmes", "de", "recherche", "directe", "est", "constitu\u00e9e", "par", "les", "divers", "algorithmes", "\u00e9volutionnaires", ",", "par", "exemple", "les", "algorithmes", "g\u00e9n\u00e9tiques", "."], "sentence-detokenized": "Une autre classe d'algorithmes de recherche directe est constitu\u00e9e par les divers algorithmes \u00e9volutionnaires, par exemple les algorithmes g\u00e9n\u00e9tiques.", "token2charspan": [[0, 3], [4, 9], [10, 16], [17, 19], [19, 30], [31, 33], [34, 43], [44, 51], [52, 55], [56, 66], [67, 70], [71, 74], [75, 81], [82, 93], [94, 109], [109, 110], [111, 114], [115, 122], [123, 126], [127, 138], [139, 149], [149, 150]]}
{"doc_key": "ai-test-116", "ner": [[0, 0, "organisation"], [3, 4, "misc"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 0, 0, "named", "", false, false], [6, 7, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["KUKA", "est", "un", "fabricant", "allemand", "de", "robots", "industriels", "et", "de", "solutions", "pour", "l'", "automatisation", "des", "usines", "."], "sentence-detokenized": "KUKA est un fabricant allemand de robots industriels et de solutions pour l'automatisation des usines.", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 21], [22, 30], [31, 33], [34, 40], [41, 52], [53, 55], [56, 58], [59, 68], [69, 73], [74, 76], [76, 90], [91, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-test-117", "ner": [[11, 11, "misc"], [21, 22, "person"], [13, 19, "misc"], [26, 27, "person"], [24, 24, "misc"], [32, 33, "person"], [29, 30, "misc"], [39, 40, "person"], [35, 37, "misc"], [47, 49, "person"], [42, 45, "misc"], [54, 55, "person"], [51, 60, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[21, 22, 11, 11, "usage", "", false, false], [13, 19, 21, 22, "artifact", "", false, false], [26, 27, 11, 11, "usage", "", false, false], [24, 24, 26, 27, "artifact", "", false, false], [32, 33, 11, 11, "usage", "", false, false], [29, 30, 32, 33, "artifact", "", false, false], [39, 40, 11, 11, "usage", "", false, false], [35, 37, 39, 40, "artifact", "", false, false], [47, 49, 11, 11, "usage", "", false, false], [42, 45, 47, 49, "artifact", "", false, false], [54, 55, 11, 11, "usage", "", false, false], [51, 60, 54, 55, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["D'", "autres", "films", "r\u00e9alis\u00e9s", "entre", "2016", "et", "2020", "avec", "des", "cam\u00e9ras", "IMAX", "sont", "Batman", "v", "Superman", ":", "Dawn", "of", "Justice", "de", "Zack", "Snyder", ",", "Sully", "de", "Clint", "Eastwood", ",", "First", "Man", "de", "Damien", "Chazelle", ",", "Wonder", "Woman", "1984", "de", "Patty", "Jenkins", ",", "No", "Time", "to", "Die", "de", "Cary", "Joji", "Fukunaga", "et", "Top", "Gun", "de", "Joseph", "Kosinski", ":", "Maverick", "de", "Joseph", "Kosinski", "."], "sentence-detokenized": "D'autres films r\u00e9alis\u00e9s entre 2016 et 2020 avec des cam\u00e9ras IMAX sont Batman v Superman : Dawn of Justice de Zack Snyder, Sully de Clint Eastwood, First Man de Damien Chazelle, Wonder Woman 1984 de Patty Jenkins, No Time to Die de Cary Joji Fukunaga et Top Gun de Joseph Kosinski : Maverick de Joseph Kosinski.", "token2charspan": [[0, 2], [2, 8], [9, 14], [15, 23], [24, 29], [30, 34], [35, 37], [38, 42], [43, 47], [48, 51], [52, 59], [60, 64], [65, 69], [70, 76], [77, 78], [79, 87], [88, 89], [90, 94], [95, 97], [98, 105], [106, 108], [109, 113], [114, 120], [120, 121], [122, 127], [128, 130], [131, 136], [137, 145], [145, 146], [147, 152], [153, 156], [157, 159], [160, 166], [167, 175], [175, 176], [177, 183], [184, 189], [190, 194], [195, 197], [198, 203], [204, 211], [211, 212], [213, 215], [216, 220], [221, 223], [224, 227], [228, 230], [231, 235], [236, 240], [241, 249], [250, 252], [253, 256], [257, 260], [261, 263], [264, 270], [271, 279], [280, 281], [282, 290], [291, 293], [294, 300], [301, 309], [309, 310]]}
{"doc_key": "ai-test-118", "ner": [[5, 6, "misc"], [12, 14, "organisation"], [16, 16, "organisation"], [30, 30, "misc"], [36, 36, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 30, 30, "named", "", false, false], [12, 14, 5, 6, "usage", "", false, false], [12, 14, 36, 36, "physical", "", false, false], [16, 16, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["L'", "essai", "de", "la", "police", "MICR", "E13B", "a", "\u00e9t\u00e9", "pr\u00e9sent\u00e9", "\u00e0", "l'", "American", "Bankers", "Association", "(", "ABA", ")", "en", "juillet", "1956", ",", "qui", "l'", "a", "adopt\u00e9e", "en", "1958", "comme", "norme", "MICR", "pour", "les", "documents", "n\u00e9gociables", "aux", "\u00c9tats-Unis", "."], "sentence-detokenized": "L'essai de la police MICR E13B a \u00e9t\u00e9 pr\u00e9sent\u00e9 \u00e0 l'American Bankers Association (ABA) en juillet 1956, qui l'a adopt\u00e9e en 1958 comme norme MICR pour les documents n\u00e9gociables aux \u00c9tats-Unis.", "token2charspan": [[0, 2], [2, 7], [8, 10], [11, 13], [14, 20], [21, 25], [26, 30], [31, 32], [33, 36], [37, 45], [46, 47], [48, 50], [50, 58], [59, 66], [67, 78], [79, 80], [80, 83], [83, 84], [85, 87], [88, 95], [96, 100], [100, 101], [102, 105], [106, 108], [108, 109], [110, 117], [118, 120], [121, 125], [126, 131], [132, 137], [138, 142], [143, 147], [148, 151], [152, 161], [162, 173], [174, 177], [178, 188], [188, 189]]}
{"doc_key": "ai-test-119", "ner": [[1, 4, "misc"], [20, 20, "field"], [25, 26, "field"], [30, 30, "field"], [33, 34, "field"], [37, 37, "field"], [40, 40, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[20, 20, 1, 4, "usage", "", false, false], [25, 26, 20, 20, "part-of", "", false, false], [30, 30, 1, 4, "usage", "", false, false], [33, 34, 1, 4, "usage", "", false, false], [37, 37, 1, 4, "usage", "", false, false], [40, 40, 1, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Les", "algorithmes", "de", "recherche", "locale", "sont", "largement", "appliqu\u00e9s", "\u00e0", "de", "nombreux", "probl\u00e8mes", "de", "calcul", "difficiles", ",", "notamment", "des", "probl\u00e8mes", "d'", "informatique", "(", "en", "particulier", "d'", "intelligence", "artificielle", ")", ",", "de", "math\u00e9matiques", ",", "de", "recherche", "op\u00e9rationnelle", ",", "d'", "ing\u00e9nierie", "et", "de", "bioinformatique", "."], "sentence-detokenized": "Les algorithmes de recherche locale sont largement appliqu\u00e9s \u00e0 de nombreux probl\u00e8mes de calcul difficiles, notamment des probl\u00e8mes d'informatique (en particulier d'intelligence artificielle), de math\u00e9matiques, de recherche op\u00e9rationnelle, d'ing\u00e9nierie et de bioinformatique.", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 28], [29, 35], [36, 40], [41, 50], [51, 60], [61, 62], [63, 65], [66, 74], [75, 84], [85, 87], [88, 94], [95, 105], [105, 106], [107, 116], [117, 120], [121, 130], [131, 133], [133, 145], [146, 147], [147, 149], [150, 161], [162, 164], [164, 176], [177, 189], [189, 190], [190, 191], [192, 194], [195, 208], [208, 209], [210, 212], [213, 222], [223, 237], [237, 238], [239, 241], [241, 251], [252, 254], [255, 257], [258, 273], [273, 274]]}
{"doc_key": "ai-test-120", "ner": [[0, 1, "researcher"], [9, 9, "location"], [12, 12, "country"], [17, 17, "country"], [25, 26, "algorithm"], [30, 30, "algorithm"], [33, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 9, 9, "physical", "", false, false], [0, 1, 17, 17, "general-affiliation", "nationality", false, false], [0, 1, 25, 26, "general-affiliation", "topic_of_study", false, false], [0, 1, 30, 30, "general-affiliation", "topic_of_study", false, false], [9, 9, 12, 12, "physical", "", false, false], [30, 30, 33, 35, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gerd", "Gigerenzer", "(", "n\u00e9", "le", "3", "septembre", "1947", "\u00e0", "Wallersdorf", ",", "en", "Allemagne", ")", "est", "un", "psychologue", "allemand", "qui", "a", "\u00e9tudi\u00e9", "l'", "utilisation", "de", "la", "rationalit\u00e9", "limit\u00e9e", "et", "de", "l'", "heuristique", "dans", "la", "prise", "de", "d\u00e9cision", "."], "sentence-detokenized": "Gerd Gigerenzer (n\u00e9 le 3 septembre 1947 \u00e0 Wallersdorf, en Allemagne) est un psychologue allemand qui a \u00e9tudi\u00e9 l'utilisation de la rationalit\u00e9 limit\u00e9e et de l'heuristique dans la prise de d\u00e9cision.", "token2charspan": [[0, 4], [5, 15], [16, 17], [17, 19], [20, 22], [23, 24], [25, 34], [35, 39], [40, 41], [42, 53], [53, 54], [55, 57], [58, 67], [67, 68], [69, 72], [73, 75], [76, 87], [88, 96], [97, 100], [101, 102], [103, 109], [110, 112], [112, 123], [124, 126], [127, 129], [130, 141], [142, 149], [150, 152], [153, 155], [156, 158], [158, 169], [170, 174], [175, 177], [178, 183], [184, 186], [187, 195], [195, 196]]}
{"doc_key": "ai-test-121", "ner": [[3, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["pour", "minimiser", "l'", "erreur", "quadratique", "moyenne", "."], "sentence-detokenized": "pour minimiser l'erreur quadratique moyenne.", "token2charspan": [[0, 4], [5, 14], [15, 17], [17, 23], [24, 35], [36, 43], [43, 44]]}
{"doc_key": "ai-test-122", "ner": [[12, 13, "misc"], [16, 17, "organisation"], [33, 36, "field"], [55, 56, "misc"], [66, 68, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 13, 16, 17, "origin", "", false, false], [55, 56, 66, 68, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Mais", "m\u00eame", "une", "langue", "officielle", "avec", "une", "acad\u00e9mie", "r\u00e9gulatrice", ",", "comme", "le", "fran\u00e7ais", "standard", "avec", "l'", "Acad\u00e9mie", "fran\u00e7aise", ",", "est", "class\u00e9e", "comme", "une", "langue", "naturelle", "(", "par", "exemple", ",", "dans", "le", "domaine", "du", "traitement", "des", "langues", "naturelles", ")", ",", "car", "ses", "points", "de", "prescription", "ne", "la", "rendent", "ni", "assez", "construite", "pour", "\u00eatre", "class\u00e9e", "comme", "une", "langue", "construite", ",", "ni", "assez", "contr\u00f4l\u00e9e", "pour", "\u00eatre", "class\u00e9e", "comme", "une", "langue", "naturelle", "contr\u00f4l\u00e9e", "."], "sentence-detokenized": "Mais m\u00eame une langue officielle avec une acad\u00e9mie r\u00e9gulatrice, comme le fran\u00e7ais standard avec l'Acad\u00e9mie fran\u00e7aise, est class\u00e9e comme une langue naturelle (par exemple, dans le domaine du traitement des langues naturelles), car ses points de prescription ne la rendent ni assez construite pour \u00eatre class\u00e9e comme une langue construite, ni assez contr\u00f4l\u00e9e pour \u00eatre class\u00e9e comme une langue naturelle contr\u00f4l\u00e9e.", "token2charspan": [[0, 4], [5, 9], [10, 13], [14, 20], [21, 31], [32, 36], [37, 40], [41, 49], [50, 61], [61, 62], [63, 68], [69, 71], [72, 80], [81, 89], [90, 94], [95, 97], [97, 105], [106, 115], [115, 116], [117, 120], [121, 128], [129, 134], [135, 138], [139, 145], [146, 155], [156, 157], [157, 160], [161, 168], [168, 169], [170, 174], [175, 177], [178, 185], [186, 188], [189, 199], [200, 203], [204, 211], [212, 222], [222, 223], [223, 224], [225, 228], [229, 232], [233, 239], [240, 242], [243, 255], [256, 258], [259, 261], [262, 269], [270, 272], [273, 278], [279, 289], [290, 294], [295, 299], [300, 307], [308, 313], [314, 317], [318, 324], [325, 335], [335, 336], [337, 339], [340, 345], [346, 355], [356, 360], [361, 365], [366, 373], [374, 379], [380, 383], [384, 390], [391, 400], [401, 410], [410, 411]]}
{"doc_key": "ai-test-123", "ner": [[14, 14, "metrics"], [16, 17, "metrics"], [19, 19, "metrics"], [39, 40, "metrics"], [42, 42, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 19, 16, 17, "named", "", false, false], [42, 42, 39, 40, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Il", "existe", "un", "certain", "nombre", "d'", "autres", "m\u00e9triques", ",", "la", "plus", "simple", "\u00e9tant", "la", "pr\u00e9cision", "ou", "Fraction", "Correcte", "(", "FC", ")", ",", "qui", "mesure", "la", "fraction", "de", "toutes", "les", "instances", "qui", "sont", "correctement", "cat\u00e9goris\u00e9es", ";", "le", "compl\u00e9ment", "est", "la", "Fraction", "Incorrecte", "(", "FiC", ")", "."], "sentence-detokenized": "Il existe un certain nombre d'autres m\u00e9triques, la plus simple \u00e9tant la pr\u00e9cision ou Fraction Correcte (FC), qui mesure la fraction de toutes les instances qui sont correctement cat\u00e9goris\u00e9es ; le compl\u00e9ment est la Fraction Incorrecte (FiC).", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 20], [21, 27], [28, 30], [30, 36], [37, 46], [46, 47], [48, 50], [51, 55], [56, 62], [63, 68], [69, 71], [72, 81], [82, 84], [85, 93], [94, 102], [103, 104], [104, 106], [106, 107], [107, 108], [109, 112], [113, 119], [120, 122], [123, 131], [132, 134], [135, 141], [142, 145], [146, 155], [156, 159], [160, 164], [165, 177], [178, 190], [191, 192], [193, 195], [196, 206], [207, 210], [211, 213], [214, 222], [223, 233], [234, 235], [235, 238], [238, 239], [239, 240]]}
{"doc_key": "ai-test-124", "ner": [[0, 0, "researcher"], [6, 9, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 9, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cardie", "est", "devenu", "membre", "de", "l'", "Association", "for", "Computational", "Linguistics", "en", "2016", "."], "sentence-detokenized": "Cardie est devenu membre de l'Association for Computational Linguistics en 2016.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 24], [25, 27], [28, 30], [30, 41], [42, 45], [46, 59], [60, 71], [72, 74], [75, 79], [79, 80]]}
{"doc_key": "ai-test-125", "ner": [[11, 15, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["L'", "apprentissage", "des", "param\u00e8tres", "th\u00eata", "/", "math", "se", "fait", "g\u00e9n\u00e9ralement", "par", "apprentissage", "du", "maximum", "de", "vraisemblance", "pour", "mathp", "(", "Y", "_", "i", "|", "X", "_", "i", ";", "\\", "th\u00eata", ")", "/", "math", "."], "sentence-detokenized": "L'apprentissage des param\u00e8tres th\u00eata / math se fait g\u00e9n\u00e9ralement par apprentissage du maximum de vraisemblance pour mathp (Y _ i | X _ i;\\ th\u00eata) / math.", "token2charspan": [[0, 2], [2, 15], [16, 19], [20, 30], [31, 36], [37, 38], [39, 43], [44, 46], [47, 51], [52, 64], [65, 68], [69, 82], [83, 85], [86, 93], [94, 96], [97, 110], [111, 115], [116, 121], [122, 123], [123, 124], [125, 126], [127, 128], [129, 130], [131, 132], [133, 134], [135, 136], [136, 137], [137, 138], [139, 144], [144, 145], [146, 147], [148, 152], [152, 153]]}
{"doc_key": "ai-test-126", "ner": [[0, 2, "task"], [5, 10, "algorithm"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 14, 0, 2, "usage", "", true, false], [13, 14, 5, 10, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Analyse", "en", "grappes", ",", "et", "factorisation", "de", "la", "matrice", "non", "n\u00e9gative", "pour", "l'", "exploration", "descriptive", "."], "sentence-detokenized": "Analyse en grappes, et factorisation de la matrice non n\u00e9gative pour l'exploration descriptive.", "token2charspan": [[0, 7], [8, 10], [11, 18], [18, 19], [20, 22], [23, 36], [37, 39], [40, 42], [43, 50], [51, 54], [55, 63], [64, 68], [69, 71], [71, 82], [83, 94], [94, 95]]}
{"doc_key": "ai-test-127", "ner": [[5, 5, "field"], [8, 11, "field"], [23, 26, "field"], [29, 32, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 26, 5, 5, "part-of", "", false, false], [23, 26, 8, 11, "part-of", "", false, false], [29, 32, 5, 5, "part-of", "", false, false], [29, 32, 8, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Dans", "le", "domaine", "de", "l'", "informatique", "et", "des", "technologies", "de", "l'", "information", "qu'", "elle", "permet", ",", "la", "capacit\u00e9", "des", "ordinateurs", "\u00e0", "effectuer", "le", "traitement", "du", "langage", "naturel", "et", "l'", "apprentissage", "automatique", "a", "\u00e9t\u00e9", "un", "d\u00e9fi", "de", "longue", "haleine", "."], "sentence-detokenized": "Dans le domaine de l'informatique et des technologies de l'information qu'elle permet, la capacit\u00e9 des ordinateurs \u00e0 effectuer le traitement du langage naturel et l'apprentissage automatique a \u00e9t\u00e9 un d\u00e9fi de longue haleine.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 21], [21, 33], [34, 36], [37, 40], [41, 53], [54, 56], [57, 59], [59, 70], [71, 74], [74, 78], [79, 85], [85, 86], [87, 89], [90, 98], [99, 102], [103, 114], [115, 116], [117, 126], [127, 129], [130, 140], [141, 143], [144, 151], [152, 159], [160, 162], [163, 165], [165, 178], [179, 190], [191, 192], [193, 196], [197, 199], [200, 204], [205, 207], [208, 214], [215, 222], [222, 223]]}
{"doc_key": "ai-test-128", "ner": [[5, 10, "algorithm"], [15, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 10, 15, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "Le", "code", "pour", "l'", "extraction", "de", "caract\u00e9ristiques", "de", "Gabor", "\u00e0", "partir", "d'", "images", "dans", "MATLAB", "se", "trouve", "\u00e0", "l'", "adresse", "suivante"], "sentence-detokenized": "(Le code pour l'extraction de caract\u00e9ristiques de Gabor \u00e0 partir d'images dans MATLAB se trouve \u00e0 l'adresse suivante", "token2charspan": [[0, 1], [1, 3], [4, 8], [9, 13], [14, 16], [16, 26], [27, 29], [30, 46], [47, 49], [50, 55], [56, 57], [58, 64], [65, 67], [67, 73], [74, 78], [79, 85], [86, 88], [89, 95], [96, 97], [98, 100], [100, 107], [108, 116]]}
{"doc_key": "ai-test-129", "ner": [[0, 0, "misc"], [19, 20, "algorithm"], [22, 22, "task"], [24, 24, "task"], [26, 28, "task"], [30, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 19, 20, "general-affiliation", "", false, false], [0, 0, 22, 22, "related-to", "solves_problem_of_type", false, false], [0, 0, 24, 24, "related-to", "solves_problem_of_type", false, false], [0, 0, 26, 28, "related-to", "solves_problem_of_type", false, false], [0, 0, 30, 32, "related-to", "solves_problem_of_type", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["NeuralExpert", "centre", "les", "sp\u00e9cifications", "de", "conception", "sur", "le", "type", "de", "probl\u00e8me", "que", "l'", "utilisateur", "souhaite", "voir", "r\u00e9soudre", "par", "le", "r\u00e9seau", "neuronal", "(", "classification", ",", "pr\u00e9diction", ",", "approximation", "de", "fonction", "ou", "analyse", "en", "grappes", ")", "."], "sentence-detokenized": "NeuralExpert centre les sp\u00e9cifications de conception sur le type de probl\u00e8me que l'utilisateur souhaite voir r\u00e9soudre par le r\u00e9seau neuronal (classification, pr\u00e9diction, approximation de fonction ou analyse en grappes).", "token2charspan": [[0, 12], [13, 19], [20, 23], [24, 38], [39, 41], [42, 52], [53, 56], [57, 59], [60, 64], [65, 67], [68, 76], [77, 80], [81, 83], [83, 94], [95, 103], [104, 108], [109, 117], [118, 121], [122, 124], [125, 131], [132, 140], [141, 142], [142, 156], [156, 157], [158, 168], [168, 169], [170, 183], [184, 186], [187, 195], [196, 198], [199, 206], [207, 209], [210, 217], [217, 218], [218, 219]]}
{"doc_key": "ai-test-130", "ner": [[2, 6, "misc"], [29, 31, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Lorsque", "la", "taille", "du", "pas", "de", "quantification", "(", "\u0394", ")", "est", "faible", "par", "rapport", "\u00e0", "la", "variation", "du", "signal", "quantifi\u00e9", ",", "il", "est", "relativement", "simple", "de", "montrer", "que", "l'", "erreur", "quadratique", "moyenne", "produite", "par", "une", "telle", "op\u00e9ration", "d'", "arrondi", "sera", "approximativement", "\u00e9gale", "\u00e0", "Delta", "^", "2", "/", "12", "/", "math.math", "."], "sentence-detokenized": "Lorsque la taille du pas de quantification (\u0394) est faible par rapport \u00e0 la variation du signal quantifi\u00e9, il est relativement simple de montrer que l'erreur quadratique moyenne produite par une telle op\u00e9ration d'arrondi sera approximativement \u00e9gale \u00e0 Delta ^ 2 / 12 / math.math.", "token2charspan": [[0, 7], [8, 10], [11, 17], [18, 20], [21, 24], [25, 27], [28, 42], [43, 44], [44, 45], [45, 46], [47, 50], [51, 57], [58, 61], [62, 69], [70, 71], [72, 74], [75, 84], [85, 87], [88, 94], [95, 104], [104, 105], [106, 108], [109, 112], [113, 125], [126, 132], [133, 135], [136, 143], [144, 147], [148, 150], [150, 156], [157, 168], [169, 176], [177, 185], [186, 189], [190, 193], [194, 199], [200, 209], [210, 212], [212, 219], [220, 224], [225, 242], [243, 248], [249, 250], [251, 256], [257, 258], [259, 260], [261, 262], [263, 265], [266, 267], [268, 277], [277, 278]]}
{"doc_key": "ai-test-131", "ner": [[20, 20, "product"], [28, 30, "researcher"], [32, 33, "researcher"], [35, 37, "researcher"], [39, 40, "researcher"], [42, 43, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "construction", "d'", "un", "lexique", "riche", "avec", "une", "ontologie", "appropri\u00e9e", "n\u00e9cessite", "un", "effort", "important", ",", "par", "exemple", ",", "le", "lexique", "Wordnet", "a", "n\u00e9cessit\u00e9", "de", "nombreuses", "ann\u00e9es-personnes", "d'", "effort.", "G.", "A.", "Miller", ",", "R.", "Beckwith", ",", "C.", "D.", "Fellbaum", ",", "D.", "Gross", ",", "K.", "Miller", "."], "sentence-detokenized": "La construction d'un lexique riche avec une ontologie appropri\u00e9e n\u00e9cessite un effort important, par exemple, le lexique Wordnet a n\u00e9cessit\u00e9 de nombreuses ann\u00e9es-personnes d'effort. G. A. Miller, R. Beckwith, C. D. Fellbaum, D. Gross, K. Miller.", "token2charspan": [[0, 2], [3, 15], [16, 18], [18, 20], [21, 28], [29, 34], [35, 39], [40, 43], [44, 53], [54, 64], [65, 74], [75, 77], [78, 84], [85, 94], [94, 95], [96, 99], [100, 107], [107, 108], [109, 111], [112, 119], [120, 127], [128, 129], [130, 139], [140, 142], [143, 153], [154, 170], [171, 173], [173, 180], [181, 183], [184, 186], [187, 193], [193, 194], [195, 197], [198, 206], [206, 207], [208, 210], [211, 213], [214, 222], [222, 223], [224, 226], [227, 232], [232, 233], [234, 236], [237, 243], [243, 244]]}
{"doc_key": "ai-test-132", "ner": [[3, 3, "organisation"], [25, 27, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[25, 27, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Le", "portefeuille", "de", "Kawasaki", "comprend", "\u00e9galement", "des", "toits", "r\u00e9tractables", ",", "des", "planchers", "et", "d'", "autres", "structures", "g\u00e9antes", ",", "comme", "par", "exemple", "la", "surface", "r\u00e9tractable", "du", "D\u00f4me", "de", "Sapporo", "."], "sentence-detokenized": "Le portefeuille de Kawasaki comprend \u00e9galement des toits r\u00e9tractables, des planchers et d'autres structures g\u00e9antes, comme par exemple la surface r\u00e9tractable du D\u00f4me de Sapporo.", "token2charspan": [[0, 2], [3, 15], [16, 18], [19, 27], [28, 36], [37, 46], [47, 50], [51, 56], [57, 69], [69, 70], [71, 74], [75, 84], [85, 87], [88, 90], [90, 96], [97, 107], [108, 115], [115, 116], [117, 122], [123, 126], [127, 134], [135, 137], [138, 145], [146, 157], [158, 160], [161, 165], [166, 168], [169, 176], [176, 177]]}
{"doc_key": "ai-test-133", "ner": [[0, 2, "metrics"], [6, 8, "metrics"], [11, 13, "metrics"], [21, 22, "metrics"], [48, 48, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 21, 22, "related-to", "", false, false], [0, 2, 48, 48, "opposite", "alternative_to", false, false], [6, 8, 0, 2, "type-of", "", false, false], [11, 13, 0, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Les", "statistiques", "Kappa", "telles", "que", "le", "kappa", "de", "Fleiss", "et", "le", "kappa", "de", "Cohen", "sont", "des", "m\u00e9thodes", "de", "calcul", "de", "la", "fiabilit\u00e9", "inter-juges", "bas\u00e9es", "sur", "diff\u00e9rentes", "hypoth\u00e8ses", "concernant", "les", "distributions", "marginales", "ou", "ant\u00e9rieures", ",", "et", "sont", "de", "plus", "en", "plus", "utilis\u00e9es", "comme", "alternatives", "corrig\u00e9es", "du", "hasard", "\u00e0", "la", "pr\u00e9cision", "dans", "d'", "autres", "contextes", "."], "sentence-detokenized": "Les statistiques Kappa telles que le kappa de Fleiss et le kappa de Cohen sont des m\u00e9thodes de calcul de la fiabilit\u00e9 inter-juges bas\u00e9es sur diff\u00e9rentes hypoth\u00e8ses concernant les distributions marginales ou ant\u00e9rieures, et sont de plus en plus utilis\u00e9es comme alternatives corrig\u00e9es du hasard \u00e0 la pr\u00e9cision dans d'autres contextes.", "token2charspan": [[0, 3], [4, 16], [17, 22], [23, 29], [30, 33], [34, 36], [37, 42], [43, 45], [46, 52], [53, 55], [56, 58], [59, 64], [65, 67], [68, 73], [74, 78], [79, 82], [83, 91], [92, 94], [95, 101], [102, 104], [105, 107], [108, 117], [118, 129], [130, 136], [137, 140], [141, 152], [153, 163], [164, 174], [175, 178], [179, 192], [193, 203], [204, 206], [207, 218], [218, 219], [220, 222], [223, 227], [228, 230], [231, 235], [236, 238], [239, 243], [244, 253], [254, 259], [260, 272], [273, 282], [283, 285], [286, 292], [293, 294], [295, 297], [298, 307], [308, 312], [313, 315], [315, 321], [322, 331], [331, 332]]}
{"doc_key": "ai-test-134", "ner": [[3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [12, 13, "researcher"], [18, 19, "researcher"], [32, 34, "algorithm"], [36, 39, "algorithm"], [41, 41, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 4, 18, 19, "role", "student_of", false, false], [6, 7, 18, 19, "role", "student_of", false, false], [9, 10, 18, 19, "role", "student_of", false, false], [12, 13, 18, 19, "role", "student_of", false, false], [36, 39, 3, 4, "origin", "", false, false], [36, 39, 6, 7, "origin", "", false, false], [36, 39, 9, 10, "origin", "", false, false], [36, 39, 12, 13, "origin", "", false, false], [36, 39, 18, 19, "origin", "", false, false], [36, 39, 32, 34, "type-of", "", false, false], [41, 41, 36, 39, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Avec", "ses", "\u00e9tudiants", "Sepp", "Hochreiter", ",", "Felix", "Gers", ",", "Fred", "Cummins", ",", "Alex", "Graves", "et", "d'", "autres", ",", "Schmidhuber", "a", "publi\u00e9", "des", "versions", "de", "plus", "en", "plus", "sophistiqu\u00e9es", "d'", "un", "type", "de", "r\u00e9seau", "neuronal", "r\u00e9current", "appel\u00e9", "m\u00e9moire", "\u00e0", "long", "terme", "(", "LSTM", ")", "."], "sentence-detokenized": "Avec ses \u00e9tudiants Sepp Hochreiter, Felix Gers, Fred Cummins, Alex Graves et d'autres, Schmidhuber a publi\u00e9 des versions de plus en plus sophistiqu\u00e9es d'un type de r\u00e9seau neuronal r\u00e9current appel\u00e9 m\u00e9moire \u00e0 long terme (LSTM).", "token2charspan": [[0, 4], [5, 8], [9, 18], [19, 23], [24, 34], [34, 35], [36, 41], [42, 46], [46, 47], [48, 52], [53, 60], [60, 61], [62, 66], [67, 73], [74, 76], [77, 79], [79, 85], [85, 86], [87, 98], [99, 100], [101, 107], [108, 111], [112, 120], [121, 123], [124, 128], [129, 131], [132, 136], [137, 150], [151, 153], [153, 155], [156, 160], [161, 163], [164, 170], [171, 179], [180, 189], [190, 196], [197, 204], [205, 206], [207, 211], [212, 217], [218, 219], [219, 223], [223, 224], [224, 225]]}
{"doc_key": "ai-test-135", "ner": [[4, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2004", "-", "Le", "premier", "Cobot", "KUKA", "LBR", "3", "est", "mis", "sur", "le", "march\u00e9", "."], "sentence-detokenized": "2004 - Le premier Cobot KUKA LBR 3 est mis sur le march\u00e9.", "token2charspan": [[0, 4], [5, 6], [7, 9], [10, 17], [18, 23], [24, 28], [29, 32], [33, 34], [35, 38], [39, 42], [43, 46], [47, 49], [50, 56], [56, 57]]}
{"doc_key": "ai-test-136", "ner": [[11, 13, "algorithm"], [16, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Deux", "approches", "superficielles", "utilis\u00e9es", "pour", "former", "et", "ensuite", "d\u00e9sambigu\u00efser", "sont", "le", "classificateur", "Naive", "Bayes", "et", "les", "arbres", "de", "d\u00e9cision", "."], "sentence-detokenized": "Deux approches superficielles utilis\u00e9es pour former et ensuite d\u00e9sambigu\u00efser sont le classificateur Naive Bayes et les arbres de d\u00e9cision.", "token2charspan": [[0, 4], [5, 14], [15, 29], [30, 39], [40, 44], [45, 51], [52, 54], [55, 62], [63, 76], [77, 81], [82, 84], [85, 99], [100, 105], [106, 111], [112, 114], [115, 118], [119, 125], [126, 128], [129, 137], [137, 138]]}
{"doc_key": "ai-test-137", "ner": [[5, 5, "misc"], [13, 14, "person"], [16, 18, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 13, 14, "origin", "", false, false], [5, 5, 16, 18, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Les", "premi\u00e8res", "formes", "pratiques", "de", "photographie", "ont", "\u00e9t\u00e9", "introduites", "en", "janvier", "1839", "par", "Louis", "Daguerre", "et", "Henry", "Fox", "Talbot", "."], "sentence-detokenized": "Les premi\u00e8res formes pratiques de photographie ont \u00e9t\u00e9 introduites en janvier 1839 par Louis Daguerre et Henry Fox Talbot.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 30], [31, 33], [34, 46], [47, 50], [51, 54], [55, 66], [67, 69], [70, 77], [78, 82], [83, 86], [87, 92], [93, 101], [102, 104], [105, 110], [111, 114], [115, 121], [121, 122]]}
{"doc_key": "ai-test-138", "ner": [[4, 5, "task"], [10, 11, "task"], [24, 26, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 24, 26, "part-of", "task_part_of_field", false, false], [10, 11, 24, 26, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Par", "exemple", ",", "la", "synth\u00e8se", "vocale", ",", "combin\u00e9e", "\u00e0", "la", "reconnaissance", "vocale", ",", "permet", "d'", "interagir", "avec", "des", "dispositifs", "mobiles", "via", "des", "interfaces", "de", "traitement", "du", "langage", "."], "sentence-detokenized": "Par exemple, la synth\u00e8se vocale, combin\u00e9e \u00e0 la reconnaissance vocale, permet d'interagir avec des dispositifs mobiles via des interfaces de traitement du langage.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 24], [25, 31], [31, 32], [33, 41], [42, 43], [44, 46], [47, 61], [62, 68], [68, 69], [70, 76], [77, 79], [79, 88], [89, 93], [94, 97], [98, 109], [110, 117], [118, 121], [122, 125], [126, 136], [137, 139], [140, 150], [151, 153], [154, 161], [161, 162]]}
{"doc_key": "ai-test-139", "ner": [[0, 1, "product"], [18, 18, "programlang"], [20, 21, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 18, 18, "general-affiliation", "", false, false], [0, 1, 20, 21, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Les", "Phidgets", "peuvent", "\u00eatre", "programm\u00e9s", "\u00e0", "l'", "aide", "de", "divers", "logiciels", "et", "langages", "de", "programmation", ",", "allant", "de", "Java", "\u00e0", "Microsoft", "Excel", "."], "sentence-detokenized": "Les Phidgets peuvent \u00eatre programm\u00e9s \u00e0 l'aide de divers logiciels et langages de programmation, allant de Java \u00e0 Microsoft Excel.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 25], [26, 36], [37, 38], [39, 41], [41, 45], [46, 48], [49, 55], [56, 65], [66, 68], [69, 77], [78, 80], [81, 94], [94, 95], [96, 102], [103, 105], [106, 110], [111, 112], [113, 122], [123, 128], [128, 129]]}
{"doc_key": "ai-test-140", "ner": [[3, 7, "field"], [12, 13, "researcher"], [16, 18, "misc"], [26, 27, "field"], [31, 32, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 7, 12, 13, "origin", "", false, false], [12, 13, 26, 27, "general-affiliation", "topic_of_study", false, false], [12, 13, 31, 32, "general-affiliation", "topic_of_study", false, false], [16, 18, 12, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Le", "terme", "\"", "apprentissage", "automatique", "\"", "a", "\u00e9t\u00e9", "invent\u00e9", "en", "1959", "par", "Arthur", "Samuel", ",", "un", "Am\u00e9ricain", "d'", "IBM", "et", "un", "pionnier", "dans", "le", "domaine", "des", "jeux", "vid\u00e9o", "et", "de", "l'", "intelligence", "artificielle", "."], "sentence-detokenized": "Le terme \"apprentissage automatique\" a \u00e9t\u00e9 invent\u00e9 en 1959 par Arthur Samuel, un Am\u00e9ricain d'IBM et un pionnier dans le domaine des jeux vid\u00e9o et de l'intelligence artificielle.", "token2charspan": [[0, 2], [3, 8], [9, 10], [10, 23], [24, 35], [35, 36], [37, 38], [39, 42], [43, 50], [51, 53], [54, 58], [59, 62], [63, 69], [70, 76], [76, 77], [78, 80], [81, 90], [91, 93], [93, 96], [97, 99], [100, 102], [103, 111], [112, 116], [117, 119], [120, 127], [128, 131], [132, 136], [137, 142], [143, 145], [146, 148], [149, 151], [151, 163], [164, 176], [176, 177]]}
{"doc_key": "ai-test-141", "ner": [[1, 2, "misc"], [3, 4, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 1, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Le", "po\u00e8te", "isra\u00e9lien", "David", "Avidan", ",", "fascin\u00e9", "par", "les", "technologies", "futures", "et", "leur", "relation", "avec", "l'", "art", ",", "a", "souhait\u00e9", "explorer", "l'", "utilisation", "des", "ordinateurs", "pour", "l'", "\u00e9criture", "de", "la", "litt\u00e9rature", "."], "sentence-detokenized": "Le po\u00e8te isra\u00e9lien David Avidan, fascin\u00e9 par les technologies futures et leur relation avec l'art, a souhait\u00e9 explorer l'utilisation des ordinateurs pour l'\u00e9criture de la litt\u00e9rature.", "token2charspan": [[0, 2], [3, 8], [9, 18], [19, 24], [25, 31], [31, 32], [33, 40], [41, 44], [45, 48], [49, 61], [62, 69], [70, 72], [73, 77], [78, 86], [87, 91], [92, 94], [94, 97], [97, 98], [99, 100], [101, 109], [110, 118], [119, 121], [121, 132], [133, 136], [137, 148], [149, 153], [154, 156], [156, 164], [165, 167], [168, 170], [171, 182], [182, 183]]}
{"doc_key": "ai-test-142", "ner": [[0, 5, "misc"], [9, 10, "organisation"], [16, 16, "location"], [35, 35, "location"], [32, 33, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 10, 0, 5, "part-of", "", false, false], [32, 33, 35, 35, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Dans", "le", "cadre", "du", "projet", "GATEway", "en", "2017", ",", "Oxbotica", "a", "test\u00e9", "sept", "navettes", "autonomes", "\u00e0", "Greenwich", ",", "naviguant", "sur", "un", "chemin", "de", "deux", "miles", "en", "bordure", "de", "rivi\u00e8re", "pr\u00e8s", "de", "l'", "O2", "Arena", "de", "Londres", ",", "sur", "un", "itin\u00e9raire", "\u00e9galement", "utilis\u00e9", "par", "les", "pi\u00e9tons", "et", "les", "cyclistes", "."], "sentence-detokenized": "Dans le cadre du projet GATEway en 2017, Oxbotica a test\u00e9 sept navettes autonomes \u00e0 Greenwich, naviguant sur un chemin de deux miles en bordure de rivi\u00e8re pr\u00e8s de l'O2 Arena de Londres, sur un itin\u00e9raire \u00e9galement utilis\u00e9 par les pi\u00e9tons et les cyclistes.", "token2charspan": [[0, 4], [5, 7], [8, 13], [14, 16], [17, 23], [24, 31], [32, 34], [35, 39], [39, 40], [41, 49], [50, 51], [52, 57], [58, 62], [63, 71], [72, 81], [82, 83], [84, 93], [93, 94], [95, 104], [105, 108], [109, 111], [112, 118], [119, 121], [122, 126], [127, 132], [133, 135], [136, 143], [144, 146], [147, 154], [155, 159], [160, 162], [163, 165], [165, 167], [168, 173], [174, 176], [177, 184], [184, 185], [186, 189], [190, 192], [193, 203], [204, 213], [214, 221], [222, 225], [226, 229], [230, 237], [238, 240], [241, 244], [245, 254], [254, 255]]}
{"doc_key": "ai-test-143", "ner": [[8, 10, "task"], [20, 21, "metrics"], [26, 27, "misc"], [33, 33, "metrics"], [37, 37, "metrics"], [40, 40, "metrics"], [42, 42, "metrics"], [44, 47, "metrics"], [51, 51, "metrics"], [53, 53, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[20, 21, 26, 27, "related-to", "is_a", false, false], [20, 21, 33, 33, "usage", "", false, false], [20, 21, 37, 37, "usage", "", false, false], [33, 33, 40, 40, "named", "same", false, false], [37, 37, 53, 53, "named", "same", false, false], [40, 40, 51, 51, "opposite", "", false, false], [40, 40, 53, 53, "opposite", "", false, false], [42, 42, 40, 40, "named", "", false, false], [44, 47, 40, 40, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Une", "combinaison", "de", "statistiques", "de", "base", "de", "la", "recherche", "d'", "informations", ",", "sans", "rapport", "mais", "couramment", "utilis\u00e9e", ",", "est", "le", "score", "F", ",", "qui", "est", "une", "moyenne", "harmonique", "(", "\u00e9ventuellement", "pond\u00e9r\u00e9e", ")", "du", "rappel", "et", "de", "la", "pr\u00e9cision", ",", "o\u00f9", "rappel", "=", "sensibilit\u00e9", "=", "taux", "de", "VRAIS", "positifs", ",", "mais", "o\u00f9", "sp\u00e9cificit\u00e9", "et", "pr\u00e9cision", "sont", "des", "mesures", "totalement", "diff\u00e9rentes", "."], "sentence-detokenized": "Une combinaison de statistiques de base de la recherche d'informations, sans rapport mais couramment utilis\u00e9e, est le score F, qui est une moyenne harmonique (\u00e9ventuellement pond\u00e9r\u00e9e) du rappel et de la pr\u00e9cision, o\u00f9 rappel = sensibilit\u00e9 = taux de VRAIS positifs, mais o\u00f9 sp\u00e9cificit\u00e9 et pr\u00e9cision sont des mesures totalement diff\u00e9rentes.", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 31], [32, 34], [35, 39], [40, 42], [43, 45], [46, 55], [56, 58], [58, 70], [70, 71], [72, 76], [77, 84], [85, 89], [90, 100], [101, 109], [109, 110], [111, 114], [115, 117], [118, 123], [124, 125], [125, 126], [127, 130], [131, 134], [135, 138], [139, 146], [147, 157], [158, 159], [159, 173], [174, 182], [182, 183], [184, 186], [187, 193], [194, 196], [197, 199], [200, 202], [203, 212], [212, 213], [214, 216], [217, 223], [224, 225], [226, 237], [238, 239], [240, 244], [245, 247], [248, 253], [254, 262], [262, 263], [264, 268], [269, 271], [272, 283], [284, 286], [287, 296], [297, 301], [302, 305], [306, 313], [314, 324], [325, 336], [336, 337]]}
{"doc_key": "ai-test-144", "ner": [[0, 2, "field"], [12, 12, "field"], [16, 16, "field"], [19, 19, "field"], [23, 23, "field"], [27, 28, "field"], [39, 41, "product"], [44, 45, "product"], [48, 49, "product"], [52, 53, "product"], [69, 71, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 2, 12, 12, "origin", "takes_inspiration_from", false, false], [0, 2, 16, 16, "origin", "takes_inspiration_from", false, false], [0, 2, 19, 19, "origin", "takes_inspiration_from", false, false], [0, 2, 23, 23, "origin", "takes_inspiration_from", false, false], [0, 2, 27, 28, "origin", "takes_inspiration_from", false, false], [39, 41, 0, 2, "origin", "", false, false], [44, 45, 0, 2, "origin", "", false, false], [48, 49, 0, 2, "origin", "", false, false], [52, 53, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["L'", "ing\u00e9nierie", "neuromorphique", "est", "une", "discipline", "interdisciplinaire", "qui", "s'", "inspire", "de", "la", "biologie", ",", "de", "la", "physique", ",", "des", "math\u00e9matiques", ",", "de", "l'", "informatique", "et", "de", "l'", "ing\u00e9nierie", "\u00e9lectronique", "pour", "concevoir", "des", "syst\u00e8mes", "neuronaux", "artificiels", ",", "tels", "que", "des", "syst\u00e8mes", "de", "vision", ",", "des", "syst\u00e8mes", "t\u00eate-\u0153il", ",", "des", "processeurs", "auditifs", "et", "des", "robots", "autonomes", ",", "dont", "l'", "architecture", "physique", "et", "les", "principes", "de", "conception", "sont", "bas\u00e9s", "sur", "ceux", "des", "syst\u00e8mes", "nerveux", "biologiques", "."], "sentence-detokenized": "L'ing\u00e9nierie neuromorphique est une discipline interdisciplinaire qui s'inspire de la biologie, de la physique, des math\u00e9matiques, de l'informatique et de l'ing\u00e9nierie \u00e9lectronique pour concevoir des syst\u00e8mes neuronaux artificiels, tels que des syst\u00e8mes de vision, des syst\u00e8mes t\u00eate-\u0153il, des processeurs auditifs et des robots autonomes, dont l'architecture physique et les principes de conception sont bas\u00e9s sur ceux des syst\u00e8mes nerveux biologiques.", "token2charspan": [[0, 2], [2, 12], [13, 27], [28, 31], [32, 35], [36, 46], [47, 65], [66, 69], [70, 72], [72, 79], [80, 82], [83, 85], [86, 94], [94, 95], [96, 98], [99, 101], [102, 110], [110, 111], [112, 115], [116, 129], [129, 130], [131, 133], [134, 136], [136, 148], [149, 151], [152, 154], [155, 157], [157, 167], [168, 180], [181, 185], [186, 195], [196, 199], [200, 208], [209, 218], [219, 230], [230, 231], [232, 236], [237, 240], [241, 244], [245, 253], [254, 256], [257, 263], [263, 264], [265, 268], [269, 277], [278, 286], [286, 287], [288, 291], [292, 303], [304, 312], [313, 315], [316, 319], [320, 326], [327, 336], [336, 337], [338, 342], [343, 345], [345, 357], [358, 366], [367, 369], [370, 373], [374, 383], [384, 386], [387, 397], [398, 402], [403, 408], [409, 412], [413, 417], [418, 421], [422, 430], [431, 438], [439, 450], [450, 451]]}
{"doc_key": "ai-test-145", "ner": [[6, 9, "metrics"], [13, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 13, 6, 9, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Pour", "\u00eatre", "plus", "pr\u00e9cis", ",", "le", "crit\u00e8re", "de", "stabilit\u00e9", "BIBO", "exige", "que", "le", "ROC", "du", "syst\u00e8me", "comprenne", "le", "cercle", "unitaire", "."], "sentence-detokenized": "Pour \u00eatre plus pr\u00e9cis, le crit\u00e8re de stabilit\u00e9 BIBO exige que le ROC du syst\u00e8me comprenne le cercle unitaire.", "token2charspan": [[0, 4], [5, 9], [10, 14], [15, 21], [21, 22], [23, 25], [26, 33], [34, 36], [37, 46], [47, 51], [52, 57], [58, 61], [62, 64], [65, 68], [69, 71], [72, 79], [80, 89], [90, 92], [93, 99], [100, 108], [108, 109]]}
{"doc_key": "ai-test-146", "ner": [[7, 7, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2", "Le", "programme", "a", "\u00e9t\u00e9", "r\u00e9\u00e9crit", "en", "Java", "\u00e0", "partir", "de", "1998", "."], "sentence-detokenized": "2 Le programme a \u00e9t\u00e9 r\u00e9\u00e9crit en Java \u00e0 partir de 1998.", "token2charspan": [[0, 1], [2, 4], [5, 14], [15, 16], [17, 20], [21, 28], [29, 31], [32, 36], [37, 38], [39, 45], [46, 48], [49, 53], [53, 54]]}
{"doc_key": "ai-test-147", "ner": [[0, 1, "metrics"], [10, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 10, 12, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["La", "MCC", "peut", "\u00eatre", "calcul\u00e9e", "directement", "\u00e0", "partir", "de", "la", "matrice", "de", "confusion", "en", "utilisant", "la", "formule", ":"], "sentence-detokenized": "La MCC peut \u00eatre calcul\u00e9e directement \u00e0 partir de la matrice de confusion en utilisant la formule :", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 25], [26, 37], [38, 39], [40, 46], [47, 49], [50, 52], [53, 60], [61, 63], [64, 73], [74, 76], [77, 86], [87, 89], [90, 97], [98, 99]]}
{"doc_key": "ai-test-148", "ner": [[8, 12, "organisation"], [22, 29, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 12, 22, 29, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Il", "a", "\u00e9t\u00e9", "d\u00e9velopp\u00e9", "par", "une", "\u00e9quipe", "du", "laboratoire", "d'", "IA", "MIT-IBM", "Watson", "et", "pr\u00e9sent\u00e9", "pour", "la", "premi\u00e8re", "fois", "lors", "de", "la", "conf\u00e9rence", "internationale", "2018", "sur", "les", "repr\u00e9sentations", "d'", "apprentissage", "."], "sentence-detokenized": "Il a \u00e9t\u00e9 d\u00e9velopp\u00e9 par une \u00e9quipe du laboratoire d'IA MIT-IBM Watson et pr\u00e9sent\u00e9 pour la premi\u00e8re fois lors de la conf\u00e9rence internationale 2018 sur les repr\u00e9sentations d'apprentissage.", "token2charspan": [[0, 2], [3, 4], [5, 8], [9, 18], [19, 22], [23, 26], [27, 33], [34, 36], [37, 48], [49, 51], [51, 53], [54, 61], [62, 68], [69, 71], [72, 80], [81, 85], [86, 88], [89, 97], [98, 102], [103, 107], [108, 110], [111, 113], [114, 124], [125, 139], [140, 144], [145, 148], [149, 152], [153, 168], [169, 171], [171, 184], [184, 185]]}
{"doc_key": "ai-test-149", "ner": [[2, 3, "metrics"], [15, 21, "metrics"], [18, 20, "metrics"], [49, 49, "metrics"], [52, 52, "metrics"], [57, 59, "metrics"], [63, 63, "metrics"], [66, 66, "metrics"], [69, 70, "metrics"], [76, 76, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[15, 21, 49, 49, "type-of", "", false, false], [15, 21, 57, 59, "related-to", "collapses_to_identity", false, false], [18, 20, 52, 52, "type-of", "", false, false], [18, 20, 57, 59, "related-to", "collapses_to_identity", false, false], [18, 20, 69, 70, "named", "same", false, false], [63, 63, 76, 76, "related-to", "collapses_to_identity", false, false], [66, 66, 76, 76, "related-to", "collapses_to_identity", false, false], [69, 70, 76, 76, "related-to", "collapses_to_identity", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Lorsque", "les", "pr\u00e9valences", "VRAIES", "des", "deux", "variables", "positives", "sont", "\u00e9gales", ",", "comme", "le", "supposent", "le", "kappa", "et", "le", "score", "F", "de", "Fleiss", ",", "c'est-\u00e0-dire", "que", "le", "nombre", "de", "pr\u00e9dictions", "positives", "correspond", "au", "nombre", "de", "classes", "positives", "dans", "le", "cas", "dichotomique", "(", "deux", "classes", ")", ",", "les", "diff\u00e9rentes", "mesures", "de", "kappa", "et", "de", "corr\u00e9lation", "se", "confondent", "avec", "le", "J", "de", "Youden", ",", "et", "le", "rappel", ",", "la", "pr\u00e9cision", "et", "le", "score", "F", "sont", "pareillement", "identiques", "\u00e0", "la", "pr\u00e9cision", "."], "sentence-detokenized": "Lorsque les pr\u00e9valences VRAIES des deux variables positives sont \u00e9gales, comme le supposent le kappa et le score F de Fleiss, c'est-\u00e0-dire que le nombre de pr\u00e9dictions positives correspond au nombre de classes positives dans le cas dichotomique (deux classes), les diff\u00e9rentes mesures de kappa et de corr\u00e9lation se confondent avec le J de Youden, et le rappel, la pr\u00e9cision et le score F sont pareillement identiques \u00e0 la pr\u00e9cision.", "token2charspan": [[0, 7], [8, 11], [12, 23], [24, 30], [31, 34], [35, 39], [40, 49], [50, 59], [60, 64], [65, 71], [71, 72], [73, 78], [79, 81], [82, 91], [92, 94], [95, 100], [101, 103], [104, 106], [107, 112], [113, 114], [115, 117], [118, 124], [124, 125], [126, 138], [139, 142], [143, 145], [146, 152], [153, 155], [156, 167], [168, 177], [178, 188], [189, 191], [192, 198], [199, 201], [202, 209], [210, 219], [220, 224], [225, 227], [228, 231], [232, 244], [245, 246], [246, 250], [251, 258], [258, 259], [259, 260], [261, 264], [265, 276], [277, 284], [285, 287], [288, 293], [294, 296], [297, 299], [300, 311], [312, 314], [315, 325], [326, 330], [331, 333], [334, 335], [336, 338], [339, 345], [345, 346], [347, 349], [350, 352], [353, 359], [359, 360], [361, 363], [364, 373], [374, 376], [377, 379], [380, 385], [386, 387], [388, 392], [393, 405], [406, 416], [417, 418], [419, 421], [422, 431], [431, 432]]}
{"doc_key": "ai-test-150", "ner": [[1, 4, "misc"], [6, 6, "misc"], [10, 10, "conference"], [16, 21, "task"], [22, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 4, 10, 10, "part-of", "", false, false], [1, 4, 10, 10, "physical", "", false, false], [1, 4, 10, 10, "temporal", "", false, false], [6, 6, 1, 4, "named", "", false, false], [16, 21, 1, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["L'", "atelier", "Building", "Educational", "Applications", "(", "BEA", ")", "de", "la", "NAACL", "2013", "a", "accueilli", "la", "premi\u00e8re", "t\u00e2che", "partag\u00e9e", "de", "la", "NLI", ".", "Tetreault", "et", "al", ",", "2013", "Le", "concours", "a", "donn\u00e9", "lieu", "\u00e0", "29", "participations", "d'", "\u00e9quipes", "du", "monde", "entier", ",", "dont", "24", "ont", "\u00e9galement", "publi\u00e9", "un", "article", "d\u00e9crivant", "leurs", "syst\u00e8mes", "et", "leurs", "approches", "."], "sentence-detokenized": "L'atelier Building Educational Applications (BEA) de la NAACL 2013 a accueilli la premi\u00e8re t\u00e2che partag\u00e9e de la NLI. Tetreault et al, 2013 Le concours a donn\u00e9 lieu \u00e0 29 participations d'\u00e9quipes du monde entier, dont 24 ont \u00e9galement publi\u00e9 un article d\u00e9crivant leurs syst\u00e8mes et leurs approches.", "token2charspan": [[0, 2], [2, 9], [10, 18], [19, 30], [31, 43], [44, 45], [45, 48], [48, 49], [50, 52], [53, 55], [56, 61], [62, 66], [67, 68], [69, 78], [79, 81], [82, 90], [91, 96], [97, 105], [106, 108], [109, 111], [112, 115], [115, 116], [117, 126], [127, 129], [130, 132], [132, 133], [134, 138], [139, 141], [142, 150], [151, 152], [153, 158], [159, 163], [164, 165], [166, 168], [169, 183], [184, 186], [186, 193], [194, 196], [197, 202], [203, 209], [209, 210], [211, 215], [216, 218], [219, 222], [223, 232], [233, 239], [240, 242], [243, 250], [251, 260], [261, 266], [267, 275], [276, 278], [279, 284], [285, 294], [294, 295]]}
{"doc_key": "ai-test-151", "ner": [[0, 3, "algorithm"], [6, 9, "algorithm"], [19, 20, "misc"], [23, 25, "misc"], [43, 45, "misc"], [49, 51, "algorithm"], [53, 53, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 6, 9, "type-of", "", false, false], [0, 3, 19, 20, "related-to", "finds", false, false], [23, 25, 19, 20, "type-of", "", false, false], [53, 53, 49, 51, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["L'", "algorithme", "de", "Viterbi", "est", "un", "algorithme", "de", "programmation", "dynamique", "permettant", "de", "trouver", "la", "s\u00e9quence", "la", "plus", "probable", "d'", "\u00e9tats", "cach\u00e9s", ",", "appel\u00e9e", "chemin", "de", "Viterbi", ",", "qui", "r\u00e9sulte", "en", "une", "s\u00e9quence", "d'", "\u00e9v\u00e9nements", "observ\u00e9s", ",", "notamment", "dans", "le", "contexte", "des", "sources", "d'", "information", "de", "Markov", "et", "des", "mod\u00e8les", "de", "Markov", "cach\u00e9s", "(", "HMM", ")", "."], "sentence-detokenized": "L'algorithme de Viterbi est un algorithme de programmation dynamique permettant de trouver la s\u00e9quence la plus probable d'\u00e9tats cach\u00e9s, appel\u00e9e chemin de Viterbi, qui r\u00e9sulte en une s\u00e9quence d'\u00e9v\u00e9nements observ\u00e9s, notamment dans le contexte des sources d'information de Markov et des mod\u00e8les de Markov cach\u00e9s (HMM).", "token2charspan": [[0, 2], [2, 12], [13, 15], [16, 23], [24, 27], [28, 30], [31, 41], [42, 44], [45, 58], [59, 68], [69, 79], [80, 82], [83, 90], [91, 93], [94, 102], [103, 105], [106, 110], [111, 119], [120, 122], [122, 127], [128, 134], [134, 135], [136, 143], [144, 150], [151, 153], [154, 161], [161, 162], [163, 166], [167, 174], [175, 177], [178, 181], [182, 190], [191, 193], [193, 203], [204, 212], [212, 213], [214, 223], [224, 228], [229, 231], [232, 240], [241, 244], [245, 252], [253, 255], [255, 266], [267, 269], [270, 276], [277, 279], [280, 283], [284, 291], [292, 294], [295, 301], [302, 308], [309, 310], [310, 313], [313, 314], [314, 315]]}
{"doc_key": "ai-test-152", "ner": [[1, 1, "field"], [4, 6, "algorithm"], [9, 11, "misc"], [15, 16, "algorithm"], [19, 20, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 1, 1, "part-of", "", false, false], [4, 6, 9, 11, "general-affiliation", "", false, false], [4, 6, 15, 16, "related-to", "generalizes_from", false, false], [4, 6, 19, 20, "related-to", "generalizes_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["En", "statistique", ",", "la", "r\u00e9gression", "logistique", "multinomiale", "est", "une", "m\u00e9thode", "de", "classification", "qui", "g\u00e9n\u00e9ralise", "la", "r\u00e9gression", "logistique", "\u00e0", "la", "classification", "multiclasse", ",", "c'est-\u00e0-dire", "avec", "plus", "de", "deux", "r\u00e9sultats", "discrets", "possibles", "."], "sentence-detokenized": "En statistique, la r\u00e9gression logistique multinomiale est une m\u00e9thode de classification qui g\u00e9n\u00e9ralise la r\u00e9gression logistique \u00e0 la classification multiclasse, c'est-\u00e0-dire avec plus de deux r\u00e9sultats discrets possibles.", "token2charspan": [[0, 2], [3, 14], [14, 15], [16, 18], [19, 29], [30, 40], [41, 53], [54, 57], [58, 61], [62, 69], [70, 72], [73, 87], [88, 91], [92, 102], [103, 105], [106, 116], [117, 127], [128, 129], [130, 132], [133, 147], [148, 159], [159, 160], [161, 173], [174, 178], [179, 183], [184, 186], [187, 191], [192, 201], [202, 210], [211, 220], [220, 221]]}
{"doc_key": "ai-test-153", "ner": [[0, 4, "algorithm"], [12, 14, "field"], [18, 21, "field"], [25, 25, "task"], [28, 32, "task"], [35, 37, "task"], [39, 40, "researcher"], [42, 43, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 4, 12, 14, "part-of", "", false, false], [0, 4, 18, 21, "part-of", "", false, false], [25, 25, 0, 4, "usage", "", true, false], [28, 32, 0, 4, "usage", "", true, false], [35, 37, 0, 4, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Les", "mod\u00e8les", "de", "Markov", "cach\u00e9s", "sont", "connus", "pour", "leurs", "applications", "\u00e0", "l'", "apprentissage", "par", "renforcement", "et", "\u00e0", "la", "reconnaissance", "des", "formes", "temporelles", "telles", "que", "la", "parole", ",", "la", "reconnaissance", "de", "l'", "\u00e9criture", "manuscrite", ",", "la", "reconnaissance", "des", "gestes", ",", "Thad", "Starner", ",", "Alex", "Pentland", "."], "sentence-detokenized": "Les mod\u00e8les de Markov cach\u00e9s sont connus pour leurs applications \u00e0 l'apprentissage par renforcement et \u00e0 la reconnaissance des formes temporelles telles que la parole, la reconnaissance de l'\u00e9criture manuscrite, la reconnaissance des gestes, Thad Starner, Alex Pentland.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 21], [22, 28], [29, 33], [34, 40], [41, 45], [46, 51], [52, 64], [65, 66], [67, 69], [69, 82], [83, 86], [87, 99], [100, 102], [103, 104], [105, 107], [108, 122], [123, 126], [127, 133], [134, 145], [146, 152], [153, 156], [157, 159], [160, 166], [166, 167], [168, 170], [171, 185], [186, 188], [189, 191], [191, 199], [200, 210], [210, 211], [212, 214], [215, 229], [230, 233], [234, 240], [240, 241], [242, 246], [247, 254], [254, 255], [256, 260], [261, 269], [269, 270]]}
{"doc_key": "ai-test-154", "ner": [[7, 8, "misc"], [35, 39, "metrics"], [42, 43, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 42, 43, "named", "", false, false], [35, 39, 42, 43, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Essentiellement", ",", "cela", "signifie", "que", "si", "le", "n-gramme", "a", "\u00e9t\u00e9", "vu", "plus", "de", "k", "fois", "lors", "de", "la", "formation", ",", "la", "probabilit\u00e9", "conditionnelle", "d'", "un", "mot", "compte", "tenu", "de", "son", "historique", "est", "proportionnelle", "\u00e0", "l'", "estimation", "du", "maximum", "de", "vraisemblance", "de", "ce", "n-", "gramme", "."], "sentence-detokenized": "Essentiellement, cela signifie que si le n-gramme a \u00e9t\u00e9 vu plus de k fois lors de la formation, la probabilit\u00e9 conditionnelle d'un mot compte tenu de son historique est proportionnelle \u00e0 l'estimation du maximum de vraisemblance de ce n-gramme.", "token2charspan": [[0, 15], [15, 16], [17, 21], [22, 30], [31, 34], [35, 37], [38, 40], [41, 49], [50, 51], [52, 55], [56, 58], [59, 63], [64, 66], [67, 68], [69, 73], [74, 78], [79, 81], [82, 84], [85, 94], [94, 95], [96, 98], [99, 110], [111, 125], [126, 128], [128, 130], [131, 134], [135, 141], [142, 146], [147, 149], [150, 153], [154, 164], [165, 168], [169, 184], [185, 186], [187, 189], [189, 199], [200, 202], [203, 210], [211, 213], [214, 227], [228, 230], [231, 233], [234, 236], [236, 242], [242, 243]]}
{"doc_key": "ai-test-155", "ner": [[5, 7, "task"], [10, 15, "task"], [19, 22, "task"], [27, 30, "task"], [40, 41, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[40, 41, 27, 30, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Il", "s'", "int\u00e9resse", "\u00e0", "la", "repr\u00e9sentation", "des", "connaissances", ",", "au", "raisonnement", "fond\u00e9", "sur", "le", "bon", "sens", "et", "\u00e0", "la", "compr\u00e9hension", "du", "langage", "naturel", ",", "estimant", "que", "la", "compr\u00e9hension", "profonde", "du", "langage", "ne", "peut", "actuellement", "\u00eatre", "obtenue", "que", "par", "une", "importante", "ing\u00e9nierie", "manuelle", "de", "formalismes", "riches", "en", "s\u00e9mantique", ",", "associ\u00e9e", "\u00e0", "des", "pr\u00e9f\u00e9rences", "statistiques", "."], "sentence-detokenized": "Il s'int\u00e9resse \u00e0 la repr\u00e9sentation des connaissances, au raisonnement fond\u00e9 sur le bon sens et \u00e0 la compr\u00e9hension du langage naturel, estimant que la compr\u00e9hension profonde du langage ne peut actuellement \u00eatre obtenue que par une importante ing\u00e9nierie manuelle de formalismes riches en s\u00e9mantique, associ\u00e9e \u00e0 des pr\u00e9f\u00e9rences statistiques.", "token2charspan": [[0, 2], [3, 5], [5, 14], [15, 16], [17, 19], [20, 34], [35, 38], [39, 52], [52, 53], [54, 56], [57, 69], [70, 75], [76, 79], [80, 82], [83, 86], [87, 91], [92, 94], [95, 96], [97, 99], [100, 113], [114, 116], [117, 124], [125, 132], [132, 133], [134, 142], [143, 146], [147, 149], [150, 163], [164, 172], [173, 175], [176, 183], [184, 186], [187, 191], [192, 204], [205, 209], [210, 217], [218, 221], [222, 225], [226, 229], [230, 240], [241, 251], [252, 260], [261, 263], [264, 275], [276, 282], [283, 285], [286, 296], [296, 297], [298, 306], [307, 308], [309, 312], [313, 324], [325, 337], [337, 338]]}
{"doc_key": "ai-test-156", "ner": [[1, 1, "programlang"], [3, 3, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["En", "JavaScript", ",", "Python", "ou"], "sentence-detokenized": "En JavaScript, Python ou", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 21], [22, 24]]}
{"doc_key": "ai-test-157", "ner": [[1, 2, "misc"], [7, 8, "misc"], [12, 12, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 7, 8, "part-of", "", false, false], [7, 8, 12, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Les", "prix", "Newcomb", "sont", "annonc\u00e9s", "dans", "le", "AI", "Magazine", "publi\u00e9", "par", "l'", "AAAI", "."], "sentence-detokenized": "Les prix Newcomb sont annonc\u00e9s dans le AI Magazine publi\u00e9 par l'AAAI.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 21], [22, 30], [31, 35], [36, 38], [39, 41], [42, 50], [51, 57], [58, 61], [62, 64], [64, 68], [68, 69]]}
{"doc_key": "ai-test-158", "ner": [[1, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["L'", "erreur", "quadratique", "moyenne", "sur", "un", "ensemble", "de", "test", "de", "100", "exemples", "est", "de", "0,084", ",", "plus", "petite", "que", "l'", "erreur", "non", "normalis\u00e9e", "."], "sentence-detokenized": "L'erreur quadratique moyenne sur un ensemble de test de 100 exemples est de 0,084, plus petite que l'erreur non normalis\u00e9e.", "token2charspan": [[0, 2], [2, 8], [9, 20], [21, 28], [29, 32], [33, 35], [36, 44], [45, 47], [48, 52], [53, 55], [56, 59], [60, 68], [69, 72], [73, 75], [76, 81], [81, 82], [83, 87], [88, 94], [95, 98], [99, 101], [101, 107], [108, 111], [112, 122], [122, 123]]}
{"doc_key": "ai-test-159", "ner": [[0, 2, "metrics"], [12, 15, "field"], [23, 26, "task"], [28, 28, "task"], [33, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 15, 0, 2, "usage", "", false, false], [23, 26, 12, 15, "part-of", "task_part_of_field", false, false], [28, 28, 23, 26, "named", "", false, false], [33, 35, 12, 15, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Le", "score", "F", "a", "\u00e9t\u00e9", "largement", "utilis\u00e9", "dans", "la", "litt\u00e9rature", "sur", "le", "traitement", "du", "langage", "naturel", ",", "notamment", "pour", "l'", "\u00e9valuation", "de", "la", "reconnaissance", "des", "entit\u00e9s", "nomm\u00e9es", "(", "NER", ")", "et", "de", "la", "segmentation", "des", "mots", "."], "sentence-detokenized": "Le score F a \u00e9t\u00e9 largement utilis\u00e9 dans la litt\u00e9rature sur le traitement du langage naturel, notamment pour l'\u00e9valuation de la reconnaissance des entit\u00e9s nomm\u00e9es (NER) et de la segmentation des mots.", "token2charspan": [[0, 2], [3, 8], [9, 10], [11, 12], [13, 16], [17, 26], [27, 34], [35, 39], [40, 42], [43, 54], [55, 58], [59, 61], [62, 72], [73, 75], [76, 83], [84, 91], [91, 92], [93, 102], [103, 107], [108, 110], [110, 120], [121, 123], [124, 126], [127, 141], [142, 145], [146, 153], [154, 161], [162, 163], [163, 166], [166, 167], [168, 170], [171, 173], [174, 176], [177, 189], [190, 193], [194, 198], [198, 199]]}
{"doc_key": "ai-test-160", "ner": [[0, 1, "product"], [7, 9, "product"], [22, 24, "misc"], [27, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 22, 24, "related-to", "performs_task", false, false], [0, 1, 27, 29, "related-to", "performs_task", false, false], [7, 9, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Les", "chatbots", "sont", "g\u00e9n\u00e9ralement", "utilis\u00e9s", "dans", "des", "syst\u00e8mes", "de", "dialogue", "\u00e0", "des", "fins", "diverses", ",", "notamment", "pour", "le", "service", "client\u00e8le", ",", "l'", "acheminement", "des", "demandes", "ou", "la", "collecte", "d'", "informations", "."], "sentence-detokenized": "Les chatbots sont g\u00e9n\u00e9ralement utilis\u00e9s dans des syst\u00e8mes de dialogue \u00e0 des fins diverses, notamment pour le service client\u00e8le, l'acheminement des demandes ou la collecte d'informations.", "token2charspan": [[0, 3], [4, 12], [13, 17], [18, 30], [31, 39], [40, 44], [45, 48], [49, 57], [58, 60], [61, 69], [70, 71], [72, 75], [76, 80], [81, 89], [89, 90], [91, 100], [101, 105], [106, 108], [109, 116], [117, 126], [126, 127], [128, 130], [130, 142], [143, 146], [147, 155], [156, 158], [159, 161], [162, 170], [171, 173], [173, 185], [185, 186]]}
{"doc_key": "ai-test-161", "ner": [[6, 12, "conference"], [18, 26, "conference"], [33, 43, "conference"], [51, 51, "conference"], [54, 57, "conference"], [59, 60, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[18, 26, 6, 12, "named", "", false, false], [33, 43, 6, 12, "named", "", false, false], [51, 51, 33, 43, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Parmi", "les", "revues", "importantes", ",", "citons", "IEEE", "Transactions", "on", "Speech", "and", "Audio", "Processing", "(", "rebaptis\u00e9", "par", "la", "suite", "IEEE", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "et", ",", "depuis", "septembre", "2014", ",", "IEEE", "/", "ACM", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "-", "apr\u00e8s", "avoir", "fusionn\u00e9", "avec", "une", "publication", "ACM", ")", ",", "Computer", "Speech", "and", "Language", "et", "Speech", "Communication", "."], "sentence-detokenized": "Parmi les revues importantes, citons IEEE Transactions on Speech and Audio Processing (rebaptis\u00e9 par la suite IEEE Transactions on Audio, Speech and Language Processing et, depuis septembre 2014, IEEE / ACM Transactions on Audio, Speech and Language Processing - apr\u00e8s avoir fusionn\u00e9 avec une publication ACM), Computer Speech and Language et Speech Communication.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 28], [28, 29], [30, 36], [37, 41], [42, 54], [55, 57], [58, 64], [65, 68], [69, 74], [75, 85], [86, 87], [87, 96], [97, 100], [101, 103], [104, 109], [110, 114], [115, 127], [128, 130], [131, 136], [136, 137], [138, 144], [145, 148], [149, 157], [158, 168], [169, 171], [171, 172], [173, 179], [180, 189], [190, 194], [194, 195], [196, 200], [201, 202], [203, 206], [207, 219], [220, 222], [223, 228], [228, 229], [230, 236], [237, 240], [241, 249], [250, 260], [261, 262], [263, 268], [269, 274], [275, 283], [284, 288], [289, 292], [293, 304], [305, 308], [308, 309], [309, 310], [311, 319], [320, 326], [327, 330], [331, 339], [340, 342], [343, 349], [350, 363], [363, 364]]}
{"doc_key": "ai-test-162", "ner": [[0, 0, "algorithm"], [6, 8, "task"], [11, 12, "field"], [15, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 8, 0, 0, "usage", "", false, false], [6, 8, 11, 12, "part-of", "task_part_of_field", false, false], [6, 8, 15, 17, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["EM", "est", "fr\u00e9quemment", "utilis\u00e9", "pour", "le", "regroupement", "de", "donn\u00e9es", "dans", "l'", "apprentissage", "automatique", "et", "la", "vision", "par", "ordinateur", "."], "sentence-detokenized": "EM est fr\u00e9quemment utilis\u00e9 pour le regroupement de donn\u00e9es dans l'apprentissage automatique et la vision par ordinateur.", "token2charspan": [[0, 2], [3, 6], [7, 18], [19, 26], [27, 31], [32, 34], [35, 47], [48, 50], [51, 58], [59, 63], [64, 66], [66, 79], [80, 91], [92, 94], [95, 97], [98, 104], [105, 108], [109, 119], [119, 120]]}
{"doc_key": "ai-test-163", "ner": [[12, 14, "metrics"], [28, 32, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 14, 28, 32, "related-to", "described_by", false, false]], "relations_mapping_to_source": [0], "sentence": ["Bien", "qu'", "il", "n'", "existe", "pas", "de", "moyen", "parfait", "de", "d\u00e9crire", "la", "matrice", "de", "confusion", "des", "VRAIS", "et", "FAUX", "positifs", "et", "n\u00e9gatifs", "par", "un", "seul", "chiffre", ",", "le", "coefficient", "de", "corr\u00e9lation", "de", "Matthews", "est", "g\u00e9n\u00e9ralement", "consid\u00e9r\u00e9", "comme", "l'", "une", "des", "meilleures", "mesures", "de", "ce", "type", "."], "sentence-detokenized": "Bien qu'il n'existe pas de moyen parfait de d\u00e9crire la matrice de confusion des VRAIS et FAUX positifs et n\u00e9gatifs par un seul chiffre, le coefficient de corr\u00e9lation de Matthews est g\u00e9n\u00e9ralement consid\u00e9r\u00e9 comme l'une des meilleures mesures de ce type.", "token2charspan": [[0, 4], [5, 8], [8, 10], [11, 13], [13, 19], [20, 23], [24, 26], [27, 32], [33, 40], [41, 43], [44, 51], [52, 54], [55, 62], [63, 65], [66, 75], [76, 79], [80, 85], [86, 88], [89, 93], [94, 102], [103, 105], [106, 114], [115, 118], [119, 121], [122, 126], [127, 134], [134, 135], [136, 138], [139, 150], [151, 153], [154, 165], [166, 168], [169, 177], [178, 181], [182, 194], [195, 204], [205, 210], [211, 213], [213, 216], [217, 220], [221, 231], [232, 239], [240, 242], [243, 245], [246, 250], [250, 251]]}
{"doc_key": "ai-test-164", "ner": [[16, 20, "field"], [38, 38, "field"], [47, 48, "field"], [52, 53, "algorithm"], [56, 58, "task"], [61, 62, "algorithm"], [69, 73, "algorithm"], [76, 78, "algorithm"], [86, 90, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[47, 48, 38, 38, "part-of", "subfield", false, false], [52, 53, 47, 48, "part-of", "", false, true], [56, 58, 47, 48, "part-of", "", false, true], [61, 62, 47, 48, "part-of", "", false, true], [69, 73, 47, 48, "part-of", "", false, true], [76, 78, 47, 48, "part-of", "", false, true], [86, 90, 47, 48, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["\u00c0", "mesure", "que", "la", "taille", "et", "la", "complexit\u00e9", "des", "ensembles", "de", "donn\u00e9es", "ont", "augment\u00e9", ",", "l'", "analyse", "directe", "des", "donn\u00e9es", "a", "\u00e9t\u00e9", "compl\u00e9t\u00e9e", "par", "un", "traitement", "indirect", "et", "automatis\u00e9", "des", "donn\u00e9es", ",", "aid\u00e9", "par", "d'", "autres", "d\u00e9couvertes", "en", "informatique", ",", "en", "particulier", "dans", "le", "domaine", "de", "l'", "apprentissage", "automatique", ",", "comme", "les", "r\u00e9seaux", "neuronaux", ",", "l'", "analyse", "par", "grappes", ",", "les", "algorithmes", "g\u00e9n\u00e9tiques", "(", "ann\u00e9es", "1950", ")", ",", "l'", "apprentissage", "par", "arbre", "de", "d\u00e9cision", "et", "les", "r\u00e8gles", "de", "d\u00e9cision", "(", "ann\u00e9es", "1960", ")", ",", "et", "les", "machines", "\u00e0", "vecteurs", "de", "support", "(", "ann\u00e9es", "1990", ")", "."], "sentence-detokenized": "\u00c0 mesure que la taille et la complexit\u00e9 des ensembles de donn\u00e9es ont augment\u00e9, l'analyse directe des donn\u00e9es a \u00e9t\u00e9 compl\u00e9t\u00e9e par un traitement indirect et automatis\u00e9 des donn\u00e9es, aid\u00e9 par d'autres d\u00e9couvertes en informatique, en particulier dans le domaine de l'apprentissage automatique, comme les r\u00e9seaux neuronaux, l'analyse par grappes, les algorithmes g\u00e9n\u00e9tiques (ann\u00e9es 1950), l'apprentissage par arbre de d\u00e9cision et les r\u00e8gles de d\u00e9cision (ann\u00e9es 1960), et les machines \u00e0 vecteurs de support (ann\u00e9es 1990).", "token2charspan": [[0, 1], [2, 8], [9, 12], [13, 15], [16, 22], [23, 25], [26, 28], [29, 39], [40, 43], [44, 53], [54, 56], [57, 64], [65, 68], [69, 77], [77, 78], [79, 81], [81, 88], [89, 96], [97, 100], [101, 108], [109, 110], [111, 114], [115, 124], [125, 128], [129, 131], [132, 142], [143, 151], [152, 154], [155, 165], [166, 169], [170, 177], [177, 178], [179, 183], [184, 187], [188, 190], [190, 196], [197, 208], [209, 211], [212, 224], [224, 225], [226, 228], [229, 240], [241, 245], [246, 248], [249, 256], [257, 259], [260, 262], [262, 275], [276, 287], [287, 288], [289, 294], [295, 298], [299, 306], [307, 316], [316, 317], [318, 320], [320, 327], [328, 331], [332, 339], [339, 340], [341, 344], [345, 356], [357, 367], [368, 369], [369, 375], [376, 380], [380, 381], [381, 382], [383, 385], [385, 398], [399, 402], [403, 408], [409, 411], [412, 420], [421, 423], [424, 427], [428, 434], [435, 437], [438, 446], [447, 448], [448, 454], [455, 459], [459, 460], [460, 461], [462, 464], [465, 468], [469, 477], [478, 479], [480, 488], [489, 491], [492, 499], [500, 501], [501, 507], [508, 512], [512, 513], [513, 514]]}
{"doc_key": "ai-test-165", "ner": [[5, 7, "researcher"], [12, 16, "misc"], [25, 26, "researcher"], [28, 29, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 16, 5, 7, "artifact", "", false, false], [12, 16, 25, 26, "artifact", "", false, false], [12, 16, 28, 29, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["\u00c0", "l'", "automne", "2005", ",", "M.", "Thrun", "a", "publi\u00e9", "un", "manuel", "intitul\u00e9", "Probabilistic", "Robotics", "(", "Robotique", "probabiliste", ")", "avec", "ses", "collaborateurs", "de", "longue", "date", ",", "Dieter", "Fox", "et", "Wolfram", "Burgard", "."], "sentence-detokenized": "\u00c0 l'automne 2005, M. Thrun a publi\u00e9 un manuel intitul\u00e9 Probabilistic Robotics (Robotique probabiliste) avec ses collaborateurs de longue date, Dieter Fox et Wolfram Burgard.", "token2charspan": [[0, 1], [2, 4], [4, 11], [12, 16], [16, 17], [18, 20], [21, 26], [27, 28], [29, 35], [36, 38], [39, 45], [46, 54], [55, 68], [69, 77], [78, 79], [79, 88], [89, 101], [101, 102], [103, 107], [108, 111], [112, 126], [127, 129], [130, 136], [137, 141], [141, 142], [143, 149], [150, 153], [154, 156], [157, 164], [165, 172], [172, 173]]}
{"doc_key": "ai-test-166", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 7, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["John", "D.", "Lafferty", ",", "Andrew", "McCallum", "et", "Pereiramath", "comme", "suit", ":"], "sentence-detokenized": "John D. Lafferty, Andrew McCallum et Pereiramath comme suit :", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 24], [25, 33], [34, 36], [37, 48], [49, 54], [55, 59], [60, 61]]}
{"doc_key": "ai-test-167", "ner": [[0, 3, "task"], [5, 5, "task"], [10, 10, "field"], [16, 18, "field"], [21, 24, "field"], [26, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 3, 16, 18, "part-of", "task_part_of_field", false, false], [0, 3, 21, 24, "part-of", "task_part_of_field", false, false], [5, 5, 0, 3, "named", "", false, false], [16, 18, 10, 10, "part-of", "subfield", false, false], [21, 24, 10, 10, "part-of", "subfield", false, false], [26, 26, 21, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["La", "r\u00e9ponse", "aux", "questions", "(", "QA", ")", "est", "une", "discipline", "informatique", "dans", "les", "domaines", "de", "la", "recherche", "d'", "information", "et", "du", "traitement", "du", "langage", "naturel", "(", "NLP", ")", ",", "qui", "vise", "\u00e0", "construire", "des", "syst\u00e8mes", "qui", "r\u00e9pondent", "automatiquement", "aux", "questions", "pos\u00e9es", "par", "les", "humains", "dans", "un", "langage", "naturel", "."], "sentence-detokenized": "La r\u00e9ponse aux questions (QA) est une discipline informatique dans les domaines de la recherche d'information et du traitement du langage naturel (NLP), qui vise \u00e0 construire des syst\u00e8mes qui r\u00e9pondent automatiquement aux questions pos\u00e9es par les humains dans un langage naturel.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 24], [25, 26], [26, 28], [28, 29], [30, 33], [34, 37], [38, 48], [49, 61], [62, 66], [67, 70], [71, 79], [80, 82], [83, 85], [86, 95], [96, 98], [98, 109], [110, 112], [113, 115], [116, 126], [127, 129], [130, 137], [138, 145], [146, 147], [147, 150], [150, 151], [151, 152], [153, 156], [157, 161], [162, 163], [164, 174], [175, 178], [179, 187], [188, 191], [192, 201], [202, 217], [218, 221], [222, 231], [232, 238], [239, 242], [243, 246], [247, 254], [255, 259], [260, 262], [263, 270], [271, 278], [278, 279]]}
{"doc_key": "ai-test-168", "ner": [[13, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Cependant", ",", "dans", "la", "version", "de", "la", "m\u00e9trique", "utilis\u00e9e", "par", "les", "\u00e9valuations", "du", "NIST", "avant", "2009", ",", "la", "phrase", "de", "r\u00e9f\u00e9rence", "la", "plus", "courte", "\u00e9tait", "utilis\u00e9e", "\u00e0", "la", "place", "."], "sentence-detokenized": "Cependant, dans la version de la m\u00e9trique utilis\u00e9e par les \u00e9valuations du NIST avant 2009, la phrase de r\u00e9f\u00e9rence la plus courte \u00e9tait utilis\u00e9e \u00e0 la place.", "token2charspan": [[0, 9], [9, 10], [11, 15], [16, 18], [19, 26], [27, 29], [30, 32], [33, 41], [42, 50], [51, 54], [55, 58], [59, 70], [71, 73], [74, 78], [79, 84], [85, 89], [89, 90], [91, 93], [94, 100], [101, 103], [104, 113], [114, 116], [117, 121], [122, 128], [129, 134], [135, 143], [144, 145], [146, 148], [149, 154], [154, 155]]}
{"doc_key": "ai-test-169", "ner": [[5, 6, "person"], [20, 20, "organisation"], [17, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 17, 18, "related-to", "invests_in", false, false], [17, 18, 20, 20, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Le", "27", "ao\u00fbt", "2018", ",", "Toyota", "a", "annonc\u00e9", "un", "investissement", "de", "500", "millions", "de", "dollars", "dans", "les", "voitures", "autonomes", "d'", "Uber", "."], "sentence-detokenized": "Le 27 ao\u00fbt 2018, Toyota a annonc\u00e9 un investissement de 500 millions de dollars dans les voitures autonomes d'Uber.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 15], [15, 16], [17, 23], [24, 25], [26, 33], [34, 36], [37, 51], [52, 54], [55, 58], [59, 67], [68, 70], [71, 78], [79, 83], [84, 87], [88, 96], [97, 106], [107, 109], [109, 113], [113, 114]]}
{"doc_key": "ai-test-170", "ner": [[7, 11, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Le", "maximum", "de", "l'", "\u00e9chantillon", "est", "l'", "estimateur", "du", "maximum", "de", "vraisemblance", "pour", "le", "maximum", "de", "la", "population", ",", "mais", ",", "comme", "nous", "l'", "avons", "vu", "plus", "haut", ",", "il", "est", "biais\u00e9", "."], "sentence-detokenized": "Le maximum de l'\u00e9chantillon est l'estimateur du maximum de vraisemblance pour le maximum de la population, mais, comme nous l'avons vu plus haut, il est biais\u00e9.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 16], [16, 27], [28, 31], [32, 34], [34, 44], [45, 47], [48, 55], [56, 58], [59, 72], [73, 77], [78, 80], [81, 88], [89, 91], [92, 94], [95, 105], [105, 106], [107, 111], [111, 112], [113, 118], [119, 123], [124, 126], [126, 131], [132, 134], [135, 139], [140, 144], [144, 145], [146, 148], [149, 152], [153, 159], [159, 160]]}
{"doc_key": "ai-test-171", "ner": [[0, 0, "task"], [5, 5, "misc"], [9, 9, "metrics"], [19, 22, "algorithm"], [25, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 5, "related-to", "overcomes", false, false], [0, 0, 9, 9, "related-to", "increases", false, false], [5, 5, 19, 22, "opposite", "", false, false], [5, 5, 25, 28, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LSI", "aide", "\u00e0", "surmonter", "la", "synonymie", "en", "augmentant", "le", "rappel", ",", "l'", "une", "des", "contraintes", "les", "plus", "probl\u00e9matiques", "des", "requ\u00eates", "bool\u00e9ennes", "par", "mots-cl\u00e9s", "et", "des", "mod\u00e8les", "d'", "espace", "vectoriel", "."], "sentence-detokenized": "LSI aide \u00e0 surmonter la synonymie en augmentant le rappel, l'une des contraintes les plus probl\u00e9matiques des requ\u00eates bool\u00e9ennes par mots-cl\u00e9s et des mod\u00e8les d'espace vectoriel.", "token2charspan": [[0, 3], [4, 8], [9, 10], [11, 20], [21, 23], [24, 33], [34, 36], [37, 47], [48, 50], [51, 57], [57, 58], [59, 61], [61, 64], [65, 68], [69, 80], [81, 84], [85, 89], [90, 104], [105, 108], [109, 117], [118, 128], [129, 132], [133, 142], [143, 145], [146, 149], [150, 157], [158, 160], [160, 166], [167, 176], [176, 177]]}
{"doc_key": "ai-test-172", "ner": [[3, 5, "task"], [27, 27, "programlang"], [29, 29, "programlang"], [31, 31, "programlang"], [33, 35, "programlang"], [37, 38, "programlang"], [40, 40, "programlang"], [42, 42, "programlang"], [44, 44, "programlang"], [46, 46, "programlang"], [48, 48, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[3, 5, 27, 27, "general-affiliation", "", false, false], [3, 5, 29, 29, "general-affiliation", "", false, false], [3, 5, 31, 31, "general-affiliation", "", false, false], [3, 5, 33, 35, "general-affiliation", "", false, false], [3, 5, 37, 38, "general-affiliation", "", false, false], [3, 5, 40, 40, "general-affiliation", "", false, false], [3, 5, 42, 42, "general-affiliation", "", false, false], [3, 5, 44, 44, "general-affiliation", "", false, false], [3, 5, 46, 46, "general-affiliation", "", false, false], [3, 5, 48, 48, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Les", "applications", "d'", "acquisition", "de", "donn\u00e9es", "sont", "g\u00e9n\u00e9ralement", "contr\u00f4l\u00e9es", "par", "des", "programmes", "logiciels", "d\u00e9velopp\u00e9s", "\u00e0", "l'", "aide", "de", "divers", "langages", "de", "programmation", "\u00e0", "usage", "g\u00e9n\u00e9ral", "tels", "que", "Assembleur", ",", "BASIC", ",", "C", ",", "C", "+", "+", ",", "C", "#", ",", "Fortran", ",", "Java", ",", "LabVIEW", ",", "Lisp", ",", "Pascal", ",", "etc."], "sentence-detokenized": "Les applications d'acquisition de donn\u00e9es sont g\u00e9n\u00e9ralement contr\u00f4l\u00e9es par des programmes logiciels d\u00e9velopp\u00e9s \u00e0 l'aide de divers langages de programmation \u00e0 usage g\u00e9n\u00e9ral tels que Assembleur, BASIC, C, C + +, C #, Fortran, Java, LabVIEW, Lisp, Pascal, etc.", "token2charspan": [[0, 3], [4, 16], [17, 19], [19, 30], [31, 33], [34, 41], [42, 46], [47, 59], [60, 70], [71, 74], [75, 78], [79, 89], [90, 99], [100, 110], [111, 112], [113, 115], [115, 119], [120, 122], [123, 129], [130, 138], [139, 141], [142, 155], [156, 157], [158, 163], [164, 171], [172, 176], [177, 180], [181, 191], [191, 192], [193, 198], [198, 199], [200, 201], [201, 202], [203, 204], [205, 206], [207, 208], [208, 209], [210, 211], [212, 213], [213, 214], [215, 222], [222, 223], [224, 228], [228, 229], [230, 237], [237, 238], [239, 243], [243, 244], [245, 251], [251, 252], [253, 257]]}
{"doc_key": "ai-test-173", "ner": [[3, 4, "organisation"], [8, 9, "product"], [10, 10, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 3, 4, "artifact", "", false, false], [8, 9, 10, 10, "physical", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["En", "2003", ",", "Honda", "a", "diffus\u00e9", "sa", "publicit\u00e9", "Cog", "au", "Royaume-Uni", "et", "sur", "Internet", "."], "sentence-detokenized": "En 2003, Honda a diffus\u00e9 sa publicit\u00e9 Cog au Royaume-Uni et sur Internet.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 16], [17, 24], [25, 27], [28, 37], [38, 41], [42, 44], [45, 56], [57, 59], [60, 63], [64, 72], [72, 73]]}
{"doc_key": "ai-test-174", "ner": [[1, 4, "conference"], [7, 8, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 4, 7, 8, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["L'", "Association", "for", "Computational", "Linguistics", "d\u00e9finit", "la", "linguistique", "informatique", "comme", "suit", ":"], "sentence-detokenized": "L'Association for Computational Linguistics d\u00e9finit la linguistique informatique comme suit :", "token2charspan": [[0, 2], [2, 13], [14, 17], [18, 31], [32, 43], [44, 51], [52, 54], [55, 67], [68, 80], [81, 86], [87, 91], [92, 93]]}
{"doc_key": "ai-test-175", "ner": [[1, 6, "algorithm"], [13, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 6, 13, 18, "related-to", "calculates", false, false]], "relations_mapping_to_source": [0], "sentence": ["Des", "algorithmes", "de", "maximisation", "de", "l'", "esp\u00e9rance", "peuvent", "\u00eatre", "utilis\u00e9s", "pour", "calculer", "des", "estimations", "approximatives", "du", "maximum", "de", "vraisemblance", "des", "param\u00e8tres", "inconnus", "de", "l'", "espace", "d'", "\u00e9tat", "dans", "les", "filtres", "et", "les", "lisseurs", "\u00e0", "variance", "minimale", "."], "sentence-detokenized": "Des algorithmes de maximisation de l'esp\u00e9rance peuvent \u00eatre utilis\u00e9s pour calculer des estimations approximatives du maximum de vraisemblance des param\u00e8tres inconnus de l'espace d'\u00e9tat dans les filtres et les lisseurs \u00e0 variance minimale.", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 31], [32, 34], [35, 37], [37, 46], [47, 54], [55, 59], [60, 68], [69, 73], [74, 82], [83, 86], [87, 98], [99, 113], [114, 116], [117, 124], [125, 127], [128, 141], [142, 145], [146, 156], [157, 165], [166, 168], [169, 171], [171, 177], [178, 180], [180, 184], [185, 189], [190, 193], [194, 201], [202, 204], [205, 208], [209, 217], [218, 219], [220, 228], [229, 237], [237, 238]]}
{"doc_key": "ai-test-176", "ner": [[8, 8, "misc"], [9, 11, "person"], [13, 14, "person"], [16, 17, "person"], [21, 21, "misc"], [22, 23, "person"], [27, 28, "person"], [33, 33, "person"], [35, 36, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[9, 11, 8, 8, "role", "actor_in", false, false], [13, 14, 8, 8, "role", "actor_in", false, false], [16, 17, 8, 8, "role", "actor_in", false, false], [22, 23, 21, 21, "role", "model_for", false, false], [33, 33, 35, 36, "social", "family", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Parmi", "les", "correspondants", "figuraient", "les", "anciennes", "actrices", "de", "Baywatch", "Donna", "D'", "Errico", ",", "Carmen", "Electra", "et", "Traci", "Bingham", ",", "l'", "ancienne", "Playmate", "Heidi", "Mark", ",", "le", "com\u00e9dien", "Arj", "Barker", "et", "les", "jumeaux", "identiques", "Randy", "et", "Jason", "Sklar", "."], "sentence-detokenized": "Parmi les correspondants figuraient les anciennes actrices de Baywatch Donna D'Errico, Carmen Electra et Traci Bingham, l'ancienne Playmate Heidi Mark, le com\u00e9dien Arj Barker et les jumeaux identiques Randy et Jason Sklar.", "token2charspan": [[0, 5], [6, 9], [10, 24], [25, 35], [36, 39], [40, 49], [50, 58], [59, 61], [62, 70], [71, 76], [77, 79], [79, 85], [85, 86], [87, 93], [94, 101], [102, 104], [105, 110], [111, 118], [118, 119], [120, 122], [122, 130], [131, 139], [140, 145], [146, 150], [150, 151], [152, 154], [155, 163], [164, 167], [168, 174], [175, 177], [178, 181], [182, 189], [190, 200], [201, 206], [207, 209], [210, 215], [216, 221], [221, 222]]}
{"doc_key": "ai-test-177", "ner": [[10, 11, "task"], [13, 13, "task"], [19, 22, "product"], [26, 27, "task"], [29, 29, "task"], [35, 36, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 13, 10, 11, "named", "", false, false], [19, 22, 10, 11, "general-affiliation", "", false, false], [29, 29, 26, 27, "named", "", false, false], [35, 36, 26, 27, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Il", "est", "couramment", "utilis\u00e9", "pour", "g\u00e9n\u00e9rer", "des", "repr\u00e9sentations", "pour", "la", "reconnaissance", "vocale", "(", "ASR", ")", ",", "par", "exemple", "le", "syst\u00e8me", "Sphinx", "de", "CMU", ",", "et", "la", "synth\u00e8se", "vocale", "(", "TTS", ")", ",", "par", "exemple", "le", "syst\u00e8me", "Festival", "."], "sentence-detokenized": "Il est couramment utilis\u00e9 pour g\u00e9n\u00e9rer des repr\u00e9sentations pour la reconnaissance vocale (ASR), par exemple le syst\u00e8me Sphinx de CMU, et la synth\u00e8se vocale (TTS), par exemple le syst\u00e8me Festival.", "token2charspan": [[0, 2], [3, 6], [7, 17], [18, 25], [26, 30], [31, 38], [39, 42], [43, 58], [59, 63], [64, 66], [67, 81], [82, 88], [89, 90], [90, 93], [93, 94], [94, 95], [96, 99], [100, 107], [108, 110], [111, 118], [119, 125], [126, 128], [129, 132], [132, 133], [134, 136], [137, 139], [140, 148], [149, 155], [156, 157], [157, 160], [160, 161], [161, 162], [163, 166], [167, 174], [175, 177], [178, 185], [186, 194], [194, 195]]}
{"doc_key": "ai-test-178", "ner": [[0, 1, "metrics"], [4, 7, "metrics"], [9, 9, "metrics"], [18, 18, "metrics"], [35, 36, "metrics"], [38, 38, "metrics"], [51, 52, "metrics"], [54, 54, "metrics"], [56, 58, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[4, 7, 0, 1, "named", "", false, false], [9, 9, 4, 7, "named", "", false, false], [18, 18, 0, 1, "named", "", false, false], [38, 38, 35, 36, "named", "", false, false], [54, 54, 51, 52, "named", "", false, false], [56, 58, 51, 52, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["La", "sensibilit\u00e9", "ou", "le", "taux", "de", "Vrais", "Positifs", "(", "TPR", ")", ",", "\u00e9galement", "connu", "sous", "le", "nom", "de", "rappel", ",", "est", "la", "proportion", "de", "personnes", "dont", "le", "test", "est", "positif", "et", "qui", "sont", "positives", "(", "Vrai", "Positif", ",", "TP", ")", "par", "rapport", "\u00e0", "toutes", "les", "personnes", "qui", "sont", "r\u00e9ellement", "positives", "(", "Condition", "Positive", ",", "CP", "=", "TP", "+", "FN", ")", "."], "sentence-detokenized": "La sensibilit\u00e9 ou le taux de Vrais Positifs (TPR), \u00e9galement connu sous le nom de rappel, est la proportion de personnes dont le test est positif et qui sont positives (Vrai Positif, TP) par rapport \u00e0 toutes les personnes qui sont r\u00e9ellement positives (Condition Positive, CP = TP + FN).", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 20], [21, 25], [26, 28], [29, 34], [35, 43], [44, 45], [45, 48], [48, 49], [49, 50], [51, 60], [61, 66], [67, 71], [72, 74], [75, 78], [79, 81], [82, 88], [88, 89], [90, 93], [94, 96], [97, 107], [108, 110], [111, 120], [121, 125], [126, 128], [129, 133], [134, 137], [138, 145], [146, 148], [149, 152], [153, 157], [158, 167], [168, 169], [169, 173], [174, 181], [181, 182], [183, 185], [185, 186], [187, 190], [191, 198], [199, 200], [201, 207], [208, 211], [212, 221], [222, 225], [226, 230], [231, 241], [242, 251], [252, 253], [253, 262], [263, 271], [271, 272], [273, 275], [276, 277], [278, 280], [281, 282], [283, 285], [285, 286], [286, 287]]}
{"doc_key": "ai-test-179", "ner": [[4, 6, "task"], [19, 19, "conference"], [21, 22, "conference"], [24, 24, "conference"], [26, 26, "conference"], [28, 28, "conference"], [32, 33, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[19, 19, 4, 6, "topic", "", false, false], [21, 22, 4, 6, "topic", "", false, false], [24, 24, 4, 6, "topic", "", false, false], [26, 26, 4, 6, "topic", "", false, false], [28, 28, 4, 6, "topic", "", false, false], [32, 33, 4, 6, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Les", "conf\u00e9rences", "populaires", "sur", "la", "reconnaissance", "vocale", "qui", "se", "tiennent", "tous", "les", "ans", "ou", "tous", "les", "deux", "ans", "comprennent", "SpeechTEK", "et", "SpeechTEK", "Europe", ",", "ICASSP", ",", "Interspeech", "/", "Eurospeech", ",", "et", "l'", "IEEE", "ASRU", "."], "sentence-detokenized": "Les conf\u00e9rences populaires sur la reconnaissance vocale qui se tiennent tous les ans ou tous les deux ans comprennent SpeechTEK et SpeechTEK Europe, ICASSP, Interspeech / Eurospeech, et l'IEEE ASRU.", "token2charspan": [[0, 3], [4, 15], [16, 26], [27, 30], [31, 33], [34, 48], [49, 55], [56, 59], [60, 62], [63, 71], [72, 76], [77, 80], [81, 84], [85, 87], [88, 92], [93, 96], [97, 101], [102, 105], [106, 117], [118, 127], [128, 130], [131, 140], [141, 147], [147, 148], [149, 155], [155, 156], [157, 168], [169, 170], [171, 181], [181, 182], [183, 185], [186, 188], [188, 192], [193, 197], [197, 198]]}
{"doc_key": "ai-test-180", "ner": [[0, 0, "researcher"], [4, 4, "researcher"], [19, 22, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[24, 24, 0, 0, "artifact", "", false, false], [24, 24, 4, 4, "artifact", "", false, false], [24, 24, 19, 22, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Devol", "a", "collabor\u00e9", "avec", "Engelberger", ",", "qui", "\u00e9tait", "le", "pr\u00e9sident", "de", "la", "soci\u00e9t\u00e9", ",", "pour", "concevoir", "et", "produire", "un", "robot", "industriel", "sous", "la", "marque", "Unimate", "."], "sentence-detokenized": "Devol a collabor\u00e9 avec Engelberger, qui \u00e9tait le pr\u00e9sident de la soci\u00e9t\u00e9, pour concevoir et produire un robot industriel sous la marque Unimate.", "token2charspan": [[0, 5], [6, 7], [8, 17], [18, 22], [23, 34], [34, 35], [36, 39], [40, 45], [46, 48], [49, 58], [59, 61], [62, 64], [65, 72], [72, 73], [74, 78], [79, 88], [89, 91], [92, 100], [101, 103], [104, 109], [110, 120], [121, 125], [126, 128], [129, 135], [136, 143], [143, 144]]}
{"doc_key": "ai-test-181", "ner": [[1, 4, "algorithm"], [6, 6, "algorithm"], [10, 13, "algorithm"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 4, 10, 13, "general-affiliation", "", false, false], [6, 6, 1, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Un", "mod\u00e8le", "de", "Markov", "cach\u00e9", "(", "HMM", ")", "est", "un", "mod\u00e8le", "de", "Markov", "statistique", "dans", "lequel", "le", "syst\u00e8me", "mod\u00e9lis\u00e9", "est", "suppos\u00e9", "\u00eatre", "un", "processus", "de", "Markov", "avec", "des", "\u00e9tats", "non", "observ\u00e9s", "(", "cach\u00e9s", ")", "."], "sentence-detokenized": "Un mod\u00e8le de Markov cach\u00e9 (HMM) est un mod\u00e8le de Markov statistique dans lequel le syst\u00e8me mod\u00e9lis\u00e9 est suppos\u00e9 \u00eatre un processus de Markov avec des \u00e9tats non observ\u00e9s (cach\u00e9s).", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 19], [20, 25], [26, 27], [27, 30], [30, 31], [32, 35], [36, 38], [39, 45], [46, 48], [49, 55], [56, 67], [68, 72], [73, 79], [80, 82], [83, 90], [91, 99], [100, 103], [104, 111], [112, 116], [117, 119], [120, 129], [130, 132], [133, 139], [140, 144], [145, 148], [149, 154], [155, 158], [159, 167], [168, 169], [169, 175], [175, 176], [176, 177]]}
{"doc_key": "ai-test-182", "ner": [[20, 22, "metrics"], [29, 29, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Cette", "propri\u00e9t\u00e9", ",", "ind\u00e9sirable", "dans", "de", "nombreuses", "applications", ",", "a", "conduit", "les", "chercheurs", "\u00e0", "utiliser", "des", "alternatives", "telles", "que", "l'", "erreur", "absolue", "moyenne", ",", "ou", "celles", "bas\u00e9es", "sur", "la", "m\u00e9diane", "."], "sentence-detokenized": "Cette propri\u00e9t\u00e9, ind\u00e9sirable dans de nombreuses applications, a conduit les chercheurs \u00e0 utiliser des alternatives telles que l'erreur absolue moyenne, ou celles bas\u00e9es sur la m\u00e9diane.", "token2charspan": [[0, 5], [6, 15], [15, 16], [17, 28], [29, 33], [34, 36], [37, 47], [48, 60], [60, 61], [62, 63], [64, 71], [72, 75], [76, 86], [87, 88], [89, 97], [98, 101], [102, 114], [115, 121], [122, 125], [126, 128], [128, 134], [135, 142], [143, 150], [150, 151], [152, 154], [155, 161], [162, 168], [169, 172], [173, 175], [176, 183], [183, 184]]}
{"doc_key": "ai-test-183", "ner": [[21, 23, "algorithm"], [32, 33, "field"], [39, 43, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[21, 23, 32, 33, "part-of", "", false, false], [21, 23, 39, 43, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Une", "telle", "s\u00e9quence", "(", "qui", "d\u00e9pend", "du", "r\u00e9sultat", "de", "l'", "\u00e9tude", "des", "attributs", "pr\u00e9c\u00e9dents", "\u00e0", "chaque", "\u00e9tape", ")", "est", "appel\u00e9e", "un", "arbre", "de", "d\u00e9cision", "et", "est", "appliqu\u00e9e", "dans", "le", "domaine", "de", "l'", "apprentissage", "automatique", "connu", "sous", "le", "nom", "d'", "apprentissage", "par", "arbre", "de", "d\u00e9cision", "."], "sentence-detokenized": "Une telle s\u00e9quence (qui d\u00e9pend du r\u00e9sultat de l'\u00e9tude des attributs pr\u00e9c\u00e9dents \u00e0 chaque \u00e9tape) est appel\u00e9e un arbre de d\u00e9cision et est appliqu\u00e9e dans le domaine de l'apprentissage automatique connu sous le nom d'apprentissage par arbre de d\u00e9cision.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 20], [20, 23], [24, 30], [31, 33], [34, 42], [43, 45], [46, 48], [48, 53], [54, 57], [58, 67], [68, 78], [79, 80], [81, 87], [88, 93], [93, 94], [95, 98], [99, 106], [107, 109], [110, 115], [116, 118], [119, 127], [128, 130], [131, 134], [135, 144], [145, 149], [150, 152], [153, 160], [161, 163], [164, 166], [166, 179], [180, 191], [192, 197], [198, 202], [203, 205], [206, 209], [210, 212], [212, 225], [226, 229], [230, 235], [236, 238], [239, 247], [247, 248]]}
{"doc_key": "ai-test-184", "ner": [[3, 4, "task"], [7, 7, "algorithm"], [24, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 7, 7, "compare", "", false, false], [24, 27, 7, 7, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Comme", "dans", "l'", "analyse", "factorielle", ",", "l'", "ACV", "peut", "\u00e9galement", "\u00eatre", "utilis\u00e9e", "pour", "classer", "les", "cas", "en", "fonction", "de", "leur", "appartenance", "\u00e0", "une", "classe", "selon", "la", "probabilit\u00e9", "maximale", "."], "sentence-detokenized": "Comme dans l'analyse factorielle, l'ACV peut \u00e9galement \u00eatre utilis\u00e9e pour classer les cas en fonction de leur appartenance \u00e0 une classe selon la probabilit\u00e9 maximale.", "token2charspan": [[0, 5], [6, 10], [11, 13], [13, 20], [21, 32], [32, 33], [34, 36], [36, 39], [40, 44], [45, 54], [55, 59], [60, 68], [69, 73], [74, 81], [82, 85], [86, 89], [90, 92], [93, 101], [102, 104], [105, 109], [110, 122], [123, 124], [125, 128], [129, 135], [136, 141], [142, 144], [145, 156], [157, 165], [165, 166]]}
{"doc_key": "ai-test-185", "ner": [[0, 3, "algorithm"], [11, 13, "metrics"], [15, 15, "metrics"], [7, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 11, 13, "usage", "", false, false], [11, 13, 7, 10, "related-to", "", false, false], [15, 15, 11, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Les", "r\u00e9seaux", "neuronaux", "supervis\u00e9s", "qui", "utilisent", "une", "fonction", "de", "co\u00fbt", "d'", "erreur", "quadratique", "moyenne", "(", "EQM", ")", "peuvent", "utiliser", "des", "m\u00e9thodes", "statistiques", "formelles", "pour", "d\u00e9terminer", "la", "confiance", "du", "mod\u00e8le", "form\u00e9", "."], "sentence-detokenized": "Les r\u00e9seaux neuronaux supervis\u00e9s qui utilisent une fonction de co\u00fbt d'erreur quadratique moyenne (EQM) peuvent utiliser des m\u00e9thodes statistiques formelles pour d\u00e9terminer la confiance du mod\u00e8le form\u00e9.", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 32], [33, 36], [37, 46], [47, 50], [51, 59], [60, 62], [63, 67], [68, 70], [70, 76], [77, 88], [89, 96], [97, 98], [98, 101], [101, 102], [103, 110], [111, 119], [120, 123], [124, 132], [133, 145], [146, 155], [156, 160], [161, 171], [172, 174], [175, 184], [185, 187], [188, 194], [195, 200], [200, 201]]}
{"doc_key": "ai-test-186", "ner": [[17, 19, "algorithm"], [22, 25, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 19, 22, 25, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Ceci", "peut", "\u00eatre", "directement", "exprim\u00e9", "comme", "un", "programme", "lin\u00e9aire", ",", "mais", "il", "est", "\u00e9galement", "\u00e9quivalent", "\u00e0", "une", "r\u00e9gularisation", "de", "Tikhonov", "avec", "la", "fonction", "de", "perte", "charni\u00e8re", ",", "mathV", "(", "f", "(", "x", ")", ",", "y", ")", "=", "\\", "max", "(", "0", ",", "1", "-", "yf", "(", "x", ")", ")", "/", "math", ":"], "sentence-detokenized": "Ceci peut \u00eatre directement exprim\u00e9 comme un programme lin\u00e9aire, mais il est \u00e9galement \u00e9quivalent \u00e0 une r\u00e9gularisation de Tikhonov avec la fonction de perte charni\u00e8re, mathV (f (x), y) =\\ max (0, 1 - yf (x)) / math :", "token2charspan": [[0, 4], [5, 9], [10, 14], [15, 26], [27, 34], [35, 40], [41, 43], [44, 53], [54, 62], [62, 63], [64, 68], [69, 71], [72, 75], [76, 85], [86, 96], [97, 98], [99, 102], [103, 117], [118, 120], [121, 129], [130, 134], [135, 137], [138, 146], [147, 149], [150, 155], [156, 165], [165, 166], [167, 172], [173, 174], [174, 175], [176, 177], [177, 178], [178, 179], [179, 180], [181, 182], [182, 183], [184, 185], [185, 186], [187, 190], [191, 192], [192, 193], [193, 194], [195, 196], [197, 198], [199, 201], [202, 203], [203, 204], [204, 205], [205, 206], [207, 208], [209, 213], [214, 215]]}
{"doc_key": "ai-test-187", "ner": [[11, 11, "researcher"], [19, 21, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "technique", "suivante", "a", "\u00e9t\u00e9", "d\u00e9crite", "dans", "l'", "article", "original", "de", "Breiman", "et", "est", "mise", "en", "\u0153uvre", "dans", "le", "paquetage", "R", "randomForest", "."], "sentence-detokenized": "La technique suivante a \u00e9t\u00e9 d\u00e9crite dans l'article original de Breiman et est mise en \u0153uvre dans le paquetage R randomForest.", "token2charspan": [[0, 2], [3, 12], [13, 21], [22, 23], [24, 27], [28, 35], [36, 40], [41, 43], [43, 50], [51, 59], [60, 62], [63, 70], [71, 73], [74, 77], [78, 82], [83, 85], [86, 91], [92, 96], [97, 99], [100, 109], [110, 111], [112, 124], [124, 125]]}
{"doc_key": "ai-test-188", "ner": [[11, 11, "metrics"], [43, 43, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Les", "mesures", "traditionnelles", "de", "la", "qualit\u00e9", "des", "images", ",", "comme", "le", "PSNR", ",", "sont", "g\u00e9n\u00e9ralement", "effectu\u00e9es", "sur", "des", "images", "\u00e0", "r\u00e9solution", "fixe", "et", "ne", "tiennent", "pas", "compte", "de", "certains", "aspects", "du", "syst\u00e8me", "visuel", "humain", ",", "comme", "le", "changement", "de", "r\u00e9solution", "spatiale", "sur", "la", "r\u00e9tine", "."], "sentence-detokenized": "Les mesures traditionnelles de la qualit\u00e9 des images, comme le PSNR, sont g\u00e9n\u00e9ralement effectu\u00e9es sur des images \u00e0 r\u00e9solution fixe et ne tiennent pas compte de certains aspects du syst\u00e8me visuel humain, comme le changement de r\u00e9solution spatiale sur la r\u00e9tine.", "token2charspan": [[0, 3], [4, 11], [12, 27], [28, 30], [31, 33], [34, 41], [42, 45], [46, 52], [52, 53], [54, 59], [60, 62], [63, 67], [67, 68], [69, 73], [74, 86], [87, 97], [98, 101], [102, 105], [106, 112], [113, 114], [115, 125], [126, 130], [131, 133], [134, 136], [137, 145], [146, 149], [150, 156], [157, 159], [160, 168], [169, 176], [177, 179], [180, 187], [188, 194], [195, 201], [201, 202], [203, 208], [209, 211], [212, 222], [223, 225], [226, 236], [237, 245], [246, 249], [250, 252], [253, 259], [259, 260]]}
{"doc_key": "ai-test-189", "ner": [[0, 1, "person"], [3, 4, "person"], [6, 7, "person"], [15, 16, "person"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 18, 19, "role", "", false, false], [3, 4, 18, 19, "role", "", false, false], [6, 7, 18, 19, "role", "", false, false], [18, 19, 15, 16, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["John", "Ireland", ",", "Joanne", "Dru", "et", "Macdonald", "Carey", "ont", "jou\u00e9", "dans", "la", "production", "couleur", "de", "Jack", "Broder", ",", "Hannah", "Lee", ",", "dont", "la", "premi\u00e8re", "a", "eu", "lieu", "le", "19", "juin", "1953", "."], "sentence-detokenized": "John Ireland, Joanne Dru et Macdonald Carey ont jou\u00e9 dans la production couleur de Jack Broder, Hannah Lee, dont la premi\u00e8re a eu lieu le 19 juin 1953.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 20], [21, 24], [25, 27], [28, 37], [38, 43], [44, 47], [48, 52], [53, 57], [58, 60], [61, 71], [72, 79], [80, 82], [83, 87], [88, 94], [94, 95], [96, 102], [103, 106], [106, 107], [108, 112], [113, 115], [116, 124], [125, 126], [127, 129], [130, 134], [135, 137], [138, 140], [141, 145], [146, 150], [150, 151]]}
{"doc_key": "ai-test-190", "ner": [[5, 7, "task"], [15, 16, "field"], [21, 21, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 7, 15, 16, "usage", "", false, false], [21, 21, 15, 16, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Ce", "processus", "s'", "appelle", "l'", "enregistrement", "d'", "images", "et", "fait", "appel", "\u00e0", "diff\u00e9rentes", "m\u00e9thodes", "de", "vision", "informatique", ",", "principalement", "li\u00e9es", "au", "suivi", "."], "sentence-detokenized": "Ce processus s'appelle l'enregistrement d'images et fait appel \u00e0 diff\u00e9rentes m\u00e9thodes de vision informatique, principalement li\u00e9es au suivi.", "token2charspan": [[0, 2], [3, 12], [13, 15], [15, 22], [23, 25], [25, 39], [40, 42], [42, 48], [49, 51], [52, 56], [57, 62], [63, 64], [65, 76], [77, 85], [86, 88], [89, 95], [96, 108], [108, 109], [110, 124], [125, 130], [131, 133], [134, 139], [139, 140]]}
{"doc_key": "ai-test-191", "ner": [[17, 19, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Commen\u00e7ons", "maintenant", "\u00e0", "expliquer", "les", "diff\u00e9rentes", "relations", "possibles", "entre", "le", "r\u00e9sultat", "pr\u00e9dit", "et", "le", "r\u00e9sultat", "r\u00e9el", ":", "Matrice", "de", "confusion"], "sentence-detokenized": "Commen\u00e7ons maintenant \u00e0 expliquer les diff\u00e9rentes relations possibles entre le r\u00e9sultat pr\u00e9dit et le r\u00e9sultat r\u00e9el : Matrice de confusion", "token2charspan": [[0, 10], [11, 21], [22, 23], [24, 33], [34, 37], [38, 49], [50, 59], [60, 69], [70, 75], [76, 78], [79, 87], [88, 94], [95, 97], [98, 100], [101, 109], [110, 114], [115, 116], [117, 124], [125, 127], [128, 137]]}
{"doc_key": "ai-test-192", "ner": [[9, 9, "product"], [1, 8, "misc"], [11, 11, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 1, 8, "part-of", "", false, false], [9, 9, 1, 8, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "bo\u00eete", "\u00e0", "outils", "de", "traitement", "de", "la", "parole", "VOICEBOX", "pour", "MATLAB", "met", "en", "\u0153uvre", "la", "conversion", "et", "son", "inverse", "comme", ":"], "sentence-detokenized": "La bo\u00eete \u00e0 outils de traitement de la parole VOICEBOX pour MATLAB met en \u0153uvre la conversion et son inverse comme :", "token2charspan": [[0, 2], [3, 8], [9, 10], [11, 17], [18, 20], [21, 31], [32, 34], [35, 37], [38, 44], [45, 53], [54, 58], [59, 65], [66, 69], [70, 72], [73, 78], [79, 81], [82, 92], [93, 95], [96, 99], [100, 107], [108, 113], [114, 115]]}
{"doc_key": "ai-test-193", "ner": [[0, 0, "programlang"], [10, 11, "field"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 10, 11, "general-affiliation", "", false, false], [0, 0, 15, 16, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolog", "est", "un", "langage", "de", "programmation", "logique", "associ\u00e9", "\u00e0", "l'", "intelligence", "artificielle", "et", "\u00e0", "la", "linguistique", "informatique", "."], "sentence-detokenized": "Prolog est un langage de programmation logique associ\u00e9 \u00e0 l'intelligence artificielle et \u00e0 la linguistique informatique.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 21], [22, 24], [25, 38], [39, 46], [47, 54], [55, 56], [57, 59], [59, 71], [72, 84], [85, 87], [88, 89], [90, 92], [93, 105], [106, 118], [118, 119]]}
{"doc_key": "ai-test-194", "ner": [[0, 2, "researcher"], [11, 11, "field"], [15, 15, "field"], [23, 26, "organisation"], [30, 33, "organisation"], [37, 40, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 11, 11, "related-to", "works_with_topic", false, false], [0, 2, 15, 15, "related-to", "works_with_topic", false, false], [0, 2, 23, 26, "role", "", false, false], [0, 2, 30, 33, "role", "", false, false], [0, 2, 37, 40, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Mme", "Milner", "a", "re\u00e7u", "de", "nombreux", "prix", "pour", "ses", "contributions", "aux", "neurosciences", "et", "\u00e0", "la", "psychologie", ".", "Elle", "est", "notamment", "membre", "de", "la", "Royal", "Society", "of", "London", ",", "de", "la", "Royal", "Society", "of", "Canada", "et", "de", "la", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Mme Milner a re\u00e7u de nombreux prix pour ses contributions aux neurosciences et \u00e0 la psychologie. Elle est notamment membre de la Royal Society of London, de la Royal Society of Canada et de la National Academy of Sciences.", "token2charspan": [[0, 3], [4, 10], [11, 12], [13, 17], [18, 20], [21, 29], [30, 34], [35, 39], [40, 43], [44, 57], [58, 61], [62, 75], [76, 78], [79, 80], [81, 83], [84, 95], [95, 96], [97, 101], [102, 105], [106, 115], [116, 122], [123, 125], [126, 128], [129, 134], [135, 142], [143, 145], [146, 152], [152, 153], [154, 156], [157, 159], [160, 165], [166, 173], [174, 176], [177, 183], [184, 186], [187, 189], [190, 192], [193, 201], [202, 209], [210, 212], [213, 221], [221, 222]]}
{"doc_key": "ai-test-195", "ner": [[15, 17, "field"], [22, 24, "task"], [27, 29, "task"], [32, 34, "task"], [37, 39, "task"], [42, 42, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[22, 24, 15, 17, "part-of", "task_part_of_field", false, false], [27, 29, 15, 17, "part-of", "task_part_of_field", false, false], [32, 34, 15, 17, "part-of", "task_part_of_field", false, false], [37, 39, 15, 17, "part-of", "task_part_of_field", false, false], [42, 42, 15, 17, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["En", "combinant", "ces", "op\u00e9rateurs", ",", "on", "peut", "obtenir", "des", "algorithmes", "pour", "de", "nombreuses", "t\u00e2ches", "de", "traitement", "d'", "images", ",", "telles", "que", "l'", "extraction", "de", "caract\u00e9ristiques", ",", "la", "segmentation", "d'", "images", ",", "l'", "accentuation", "d'", "images", ",", "le", "filtrage", "d'", "images", "et", "la", "classification", "."], "sentence-detokenized": "En combinant ces op\u00e9rateurs, on peut obtenir des algorithmes pour de nombreuses t\u00e2ches de traitement d'images, telles que l'extraction de caract\u00e9ristiques, la segmentation d'images, l'accentuation d'images, le filtrage d'images et la classification.", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 27], [27, 28], [29, 31], [32, 36], [37, 44], [45, 48], [49, 60], [61, 65], [66, 68], [69, 79], [80, 86], [87, 89], [90, 100], [101, 103], [103, 109], [109, 110], [111, 117], [118, 121], [122, 124], [124, 134], [135, 137], [138, 154], [154, 155], [156, 158], [159, 171], [172, 174], [174, 180], [180, 181], [182, 184], [184, 196], [197, 199], [199, 205], [205, 206], [207, 209], [210, 218], [219, 221], [221, 227], [228, 230], [231, 233], [234, 248], [248, 249]]}
{"doc_key": "ai-test-196", "ner": [[7, 9, "university"], [18, 20, "organisation"], [22, 23, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 23, 18, 20, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Depuis", "2017", ",", "il", "est", "professeur", "au", "Coll\u00e8ge", "de", "France", "et", ",", "depuis", "1989", ",", "directeur", "de", "l'", "unit\u00e9", "INSERM", "562", ",", "Neuroimagerie", "cognitive", "."], "sentence-detokenized": "Depuis 2017, il est professeur au Coll\u00e8ge de France et, depuis 1989, directeur de l'unit\u00e9 INSERM 562, Neuroimagerie cognitive.", "token2charspan": [[0, 6], [7, 11], [11, 12], [13, 15], [16, 19], [20, 30], [31, 33], [34, 41], [42, 44], [45, 51], [52, 54], [54, 55], [56, 62], [63, 67], [67, 68], [69, 78], [79, 81], [82, 84], [84, 89], [90, 96], [97, 100], [100, 101], [102, 115], [116, 125], [125, 126]]}
{"doc_key": "ai-test-197", "ner": [[14, 17, "algorithm"], [20, 24, "algorithm"], [30, 30, "algorithm"], [32, 38, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[30, 30, 32, 38, "temporal", "", false, true]], "relations_mapping_to_source": [0], "sentence": ["Il", "existe", "de", "nombreuses", "approches", "pour", "apprendre", "ces", "encastrements", ",", "notamment", "en", "utilisant", "des", "cadres", "de", "clustering", "bay\u00e9sien", "ou", "des", "cadres", "bas\u00e9s", "sur", "l'", "\u00e9nergie", ",", "et", "plus", "r\u00e9cemment", ",", "TransE", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", "2013", ")", "."], "sentence-detokenized": "Il existe de nombreuses approches pour apprendre ces encastrements, notamment en utilisant des cadres de clustering bay\u00e9sien ou des cadres bas\u00e9s sur l'\u00e9nergie, et plus r\u00e9cemment, TransE (Conference on Neural Information Processing Systems 2013).", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 23], [24, 33], [34, 38], [39, 48], [49, 52], [53, 66], [66, 67], [68, 77], [78, 80], [81, 90], [91, 94], [95, 101], [102, 104], [105, 115], [116, 124], [125, 127], [128, 131], [132, 138], [139, 144], [145, 148], [149, 151], [151, 158], [158, 159], [160, 162], [163, 167], [168, 177], [177, 178], [179, 185], [186, 187], [187, 197], [198, 200], [201, 207], [208, 219], [220, 230], [231, 238], [239, 243], [243, 244], [244, 245]]}
{"doc_key": "ai-test-198", "ner": [[7, 13, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 15, 7, 13, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Il", "s'", "agit", "d'", "une", "alternative", "au", "taux", "d'", "erreur", "de", "mots", "(", "Word", "Error", "Rate", ")", "utilis\u00e9", "dans", "plusieurs", "pays", "."], "sentence-detokenized": "Il s'agit d'une alternative au taux d'erreur de mots (Word Error Rate) utilis\u00e9 dans plusieurs pays.", "token2charspan": [[0, 2], [3, 5], [5, 9], [10, 12], [12, 15], [16, 27], [28, 30], [31, 35], [36, 38], [38, 44], [45, 47], [48, 52], [53, 54], [54, 58], [59, 64], [65, 69], [69, 70], [71, 78], [79, 83], [84, 93], [94, 98], [98, 99]]}
{"doc_key": "ai-test-199", "ner": [[0, 1, "algorithm"], [11, 13, "task"], [16, 17, "task"], [20, 21, "task"], [24, 27, "task"], [32, 36, "task"], [39, 40, "task"], [56, 56, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 13, 0, 1, "usage", "", false, false], [16, 17, 0, 1, "usage", "", false, false], [20, 21, 0, 1, "usage", "", false, false], [24, 27, 0, 1, "usage", "", false, false], [32, 36, 0, 1, "usage", "", false, false], [39, 40, 0, 1, "usage", "", false, false], [56, 56, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Les", "ANN", "ont", "\u00e9t\u00e9", "utilis\u00e9s", "pour", "diverses", "t\u00e2ches", ",", "notamment", "la", "vision", "par", "ordinateur", ",", "la", "reconnaissance", "vocale", ",", "la", "traduction", "automatique", ",", "le", "filtrage", "des", "r\u00e9seaux", "sociaux", ",", "les", "jeux", "de", "soci\u00e9t\u00e9", "et", "les", "jeux", "vid\u00e9o", ",", "le", "diagnostic", "m\u00e9dical", ",", "et", "m\u00eame", "pour", "des", "activit\u00e9s", "traditionnellement", "consid\u00e9r\u00e9es", "comme", "r\u00e9serv\u00e9es", "aux", "humains", ",", "comme", "la", "peinture", "."], "sentence-detokenized": "Les ANN ont \u00e9t\u00e9 utilis\u00e9s pour diverses t\u00e2ches, notamment la vision par ordinateur, la reconnaissance vocale, la traduction automatique, le filtrage des r\u00e9seaux sociaux, les jeux de soci\u00e9t\u00e9 et les jeux vid\u00e9o, le diagnostic m\u00e9dical, et m\u00eame pour des activit\u00e9s traditionnellement consid\u00e9r\u00e9es comme r\u00e9serv\u00e9es aux humains, comme la peinture.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 15], [16, 24], [25, 29], [30, 38], [39, 45], [45, 46], [47, 56], [57, 59], [60, 66], [67, 70], [71, 81], [81, 82], [83, 85], [86, 100], [101, 107], [107, 108], [109, 111], [112, 122], [123, 134], [134, 135], [136, 138], [139, 147], [148, 151], [152, 159], [160, 167], [167, 168], [169, 172], [173, 177], [178, 180], [181, 188], [189, 191], [192, 195], [196, 200], [201, 206], [206, 207], [208, 210], [211, 221], [222, 229], [229, 230], [231, 233], [234, 238], [239, 243], [244, 247], [248, 257], [258, 276], [277, 288], [289, 294], [295, 304], [305, 308], [309, 316], [316, 317], [318, 323], [324, 326], [327, 335], [335, 336]]}
{"doc_key": "ai-test-200", "ner": [[0, 3, "product"], [5, 5, "product"], [22, 39, "field"], [41, 41, "field"], [45, 45, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 22, 39, "related-to", "", false, false], [0, 3, 45, 45, "general-affiliation", "", false, false], [5, 5, 0, 3, "named", "", false, false], [41, 41, 22, 39, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Modular", "Audio", "Recognition", "Framework", "(", "MARF", ")", "est", "une", "plateforme", "de", "recherche", "\u00e0", "code", "source", "ouvert", "et", "une", "collection", "d'", "algorithmes", "de", "traitement", "de", "la", "voix", ",", "du", "son", ",", "de", "la", "parole", ",", "du", "texte", "et", "du", "langage", "naturel", "(", "NLP", ")", "\u00e9crits", "en", "Java", "et", "dispos\u00e9s", "dans", "un", "cadre", "modulaire", "et", "extensible", "qui", "tente", "de", "faciliter", "l'", "ajout", "de", "nouveaux", "algorithmes", "."], "sentence-detokenized": "Modular Audio Recognition Framework (MARF) est une plateforme de recherche \u00e0 code source ouvert et une collection d'algorithmes de traitement de la voix, du son, de la parole, du texte et du langage naturel (NLP) \u00e9crits en Java et dispos\u00e9s dans un cadre modulaire et extensible qui tente de faciliter l'ajout de nouveaux algorithmes.", "token2charspan": [[0, 7], [8, 13], [14, 25], [26, 35], [36, 37], [37, 41], [41, 42], [43, 46], [47, 50], [51, 61], [62, 64], [65, 74], [75, 76], [77, 81], [82, 88], [89, 95], [96, 98], [99, 102], [103, 113], [114, 116], [116, 127], [128, 130], [131, 141], [142, 144], [145, 147], [148, 152], [152, 153], [154, 156], [157, 160], [160, 161], [162, 164], [165, 167], [168, 174], [174, 175], [176, 178], [179, 184], [185, 187], [188, 190], [191, 198], [199, 206], [207, 208], [208, 211], [211, 212], [213, 219], [220, 222], [223, 227], [228, 230], [231, 239], [240, 244], [245, 247], [248, 253], [254, 263], [264, 266], [267, 277], [278, 281], [282, 287], [288, 290], [291, 300], [301, 303], [303, 308], [309, 311], [312, 320], [321, 332], [332, 333]]}
{"doc_key": "ai-test-201", "ner": [[16, 19, "organisation"], [30, 36, "organisation"], [39, 40, "organisation"], [44, 45, "task"], [67, 74, "organisation"], [64, 66, "task"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6], "relations": [[30, 36, 44, 45, "usage", "", false, false], [30, 36, 67, 74, "named", "", false, false], [39, 40, 44, 45, "usage", "", false, false], [67, 74, 64, 66, "usage", "", false, false]], "relations_mapping_to_source": [1, 2, 4, 5], "sentence": ["En", "2018", ",", "un", "rapport", "de", "l'", "organisation", "de", "d\u00e9fense", "des", "libert\u00e9s", "civiles", "et", "des", "droits", "Big", "Brother", "Watch", "a", "r\u00e9v\u00e9l\u00e9", "que", "deux", "forces", "de", "police", "du", "Royaume-Uni", ",", "la", "police", "du", "sud", "du", "Pays", "de", "Galles", "et", "la", "police", "m\u00e9tropolitaine", ",", "utilisaient", "la", "reconnaissance", "faciale", "en", "direct", "lors", "d'", "\u00e9v\u00e9nements", "publics", "et", "dans", "des", "espaces", "publics.En", "septembre", "2019", ",", "l'", "utilisation", "de", "la", "reconnaissance", "faciale", "par", "la", "police", "du", "sud", "du", "Pays", "de", "Galles", "a", "\u00e9t\u00e9", "jug\u00e9e", "l\u00e9gale", "."], "sentence-detokenized": "En 2018, un rapport de l'organisation de d\u00e9fense des libert\u00e9s civiles et des droits Big Brother Watch a r\u00e9v\u00e9l\u00e9 que deux forces de police du Royaume-Uni, la police du sud du Pays de Galles et la police m\u00e9tropolitaine, utilisaient la reconnaissance faciale en direct lors d'\u00e9v\u00e9nements publics et dans des espaces publics.En septembre 2019, l'utilisation de la reconnaissance faciale par la police du sud du Pays de Galles a \u00e9t\u00e9 jug\u00e9e l\u00e9gale.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 19], [20, 22], [23, 25], [25, 37], [38, 40], [41, 48], [49, 52], [53, 61], [62, 69], [70, 72], [73, 76], [77, 83], [84, 87], [88, 95], [96, 101], [102, 103], [104, 110], [111, 114], [115, 119], [120, 126], [127, 129], [130, 136], [137, 139], [140, 151], [151, 152], [153, 155], [156, 162], [163, 165], [166, 169], [170, 172], [173, 177], [178, 180], [181, 187], [188, 190], [191, 193], [194, 200], [201, 215], [215, 216], [217, 228], [229, 231], [232, 246], [247, 254], [255, 257], [258, 264], [265, 269], [270, 272], [272, 282], [283, 290], [291, 293], [294, 298], [299, 302], [303, 310], [311, 321], [322, 331], [332, 336], [336, 337], [338, 340], [340, 351], [352, 354], [355, 357], [358, 372], [373, 380], [381, 384], [385, 387], [388, 394], [395, 397], [398, 401], [402, 404], [405, 409], [410, 412], [413, 419], [420, 421], [422, 425], [426, 431], [432, 438], [438, 439]]}
{"doc_key": "ai-test-202", "ner": [[0, 0, "product"], [5, 5, "programlang"], [16, 17, "field"], [20, 20, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 5, "general-affiliation", "", false, false], [0, 0, 16, 17, "related-to", "", false, false], [0, 0, 20, 20, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["ANIMAL", "a", "\u00e9t\u00e9", "port\u00e9", "vers", "R", ",", "un", "langage", "et", "un", "environnement", "librement", "disponibles", "pour", "le", "calcul", "statistique", "et", "les", "graphiques", "."], "sentence-detokenized": "ANIMAL a \u00e9t\u00e9 port\u00e9 vers R, un langage et un environnement librement disponibles pour le calcul statistique et les graphiques.", "token2charspan": [[0, 6], [7, 8], [9, 12], [13, 18], [19, 23], [24, 25], [25, 26], [27, 29], [30, 37], [38, 40], [41, 43], [44, 57], [58, 67], [68, 79], [80, 84], [85, 87], [88, 94], [95, 106], [107, 109], [110, 113], [114, 124], [124, 125]]}
{"doc_key": "ai-test-203", "ner": [[0, 9, "algorithm"], [11, 11, "algorithm"], [17, 20, "algorithm"], [22, 22, "algorithm"], [26, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 9, 17, 20, "opposite", "alternative to", false, false], [11, 11, 0, 9, "named", "", false, false], [22, 22, 17, 20, "named", "", false, false], [26, 30, 0, 9, "usage", "", false, false], [26, 30, 17, 20, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Le", "mod\u00e8le", "de", "Bernoulli", "cach\u00e9", "et", "homog\u00e8ne", "dans", "le", "temps", "(", "TI-HBM", ")", "est", "une", "alternative", "au", "mod\u00e8le", "de", "Markov", "cach\u00e9", "(", "HMM", ")", "pour", "la", "reconnaissance", "automatique", "de", "la", "parole", "."], "sentence-detokenized": "Le mod\u00e8le de Bernoulli cach\u00e9 et homog\u00e8ne dans le temps (TI-HBM) est une alternative au mod\u00e8le de Markov cach\u00e9 (HMM) pour la reconnaissance automatique de la parole.", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 22], [23, 28], [29, 31], [32, 40], [41, 45], [46, 48], [49, 54], [55, 56], [56, 62], [62, 63], [64, 67], [68, 71], [72, 83], [84, 86], [87, 93], [94, 96], [97, 103], [104, 109], [110, 111], [111, 114], [114, 115], [116, 120], [121, 123], [124, 138], [139, 150], [151, 153], [154, 156], [157, 163], [163, 164]]}
{"doc_key": "ai-test-204", "ner": [[4, 5, "organisation"], [12, 14, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 12, 14, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["En", "juillet", "2016", ",", "Nvidia", "a", "fait", "la", "d\u00e9monstration", ",", "lors", "du", "SIGGRAPH", ",", "d'", "une", "nouvelle", "m\u00e9thode", "de", "rendu", "fov\u00e9al", "pr\u00e9tendument", "invisible", "pour", "les", "utilisateurs", "."], "sentence-detokenized": "En juillet 2016, Nvidia a fait la d\u00e9monstration, lors du SIGGRAPH, d'une nouvelle m\u00e9thode de rendu fov\u00e9al pr\u00e9tendument invisible pour les utilisateurs.", "token2charspan": [[0, 2], [3, 10], [11, 15], [15, 16], [17, 23], [24, 25], [26, 30], [31, 33], [34, 47], [47, 48], [49, 53], [54, 56], [57, 65], [65, 66], [67, 69], [69, 72], [73, 81], [82, 89], [90, 92], [93, 98], [99, 105], [106, 118], [119, 128], [129, 133], [134, 137], [138, 150], [150, 151]]}
{"doc_key": "ai-test-205", "ner": [[6, 10, "misc"], [13, 14, "researcher"], [22, 23, "researcher"], [25, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 10, 13, 14, "origin", "", false, false], [6, 10, 22, 23, "origin", "", false, false], [6, 10, 25, 25, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Tous", "deux", "s'", "appuient", "sur", "la", "th\u00e9orie", "des", "actes", "de", "parole", "d\u00e9velopp\u00e9e", "par", "John", "Searle", "dans", "les", "ann\u00e9es", "1960", "et", "am\u00e9lior\u00e9e", "par", "Terry", "Winograd", "et", "Flores", "dans", "les", "ann\u00e9es", "1970", "."], "sentence-detokenized": "Tous deux s'appuient sur la th\u00e9orie des actes de parole d\u00e9velopp\u00e9e par John Searle dans les ann\u00e9es 1960 et am\u00e9lior\u00e9e par Terry Winograd et Flores dans les ann\u00e9es 1970.", "token2charspan": [[0, 4], [5, 9], [10, 12], [12, 20], [21, 24], [25, 27], [28, 35], [36, 39], [40, 45], [46, 48], [49, 55], [56, 66], [67, 70], [71, 75], [76, 82], [83, 87], [88, 91], [92, 98], [99, 103], [104, 106], [107, 116], [117, 120], [121, 126], [127, 135], [136, 138], [139, 145], [146, 150], [151, 154], [155, 161], [162, 166], [166, 167]]}
{"doc_key": "ai-test-206", "ner": [[0, 4, "algorithm"], [35, 36, "researcher"], [33, 33, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 35, 36, "related-to", "", false, false], [33, 33, 35, 36, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Les", "mod\u00e8les", "de", "r\u00e9seaux", "neuronaux", "de", "la", "formation", "des", "concepts", "et", "de", "la", "structure", "des", "connaissances", "ont", "ouvert", "la", "voie", "\u00e0", "de", "puissants", "mod\u00e8les", "hi\u00e9rarchiques", "d'", "organisation", "des", "connaissances", ",", "tels", "que", "le", "Wordnet", "de", "George", "Miller", "."], "sentence-detokenized": "Les mod\u00e8les de r\u00e9seaux neuronaux de la formation des concepts et de la structure des connaissances ont ouvert la voie \u00e0 de puissants mod\u00e8les hi\u00e9rarchiques d'organisation des connaissances, tels que le Wordnet de George Miller.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 32], [33, 35], [36, 38], [39, 48], [49, 52], [53, 61], [62, 64], [65, 67], [68, 70], [71, 80], [81, 84], [85, 98], [99, 102], [103, 109], [110, 112], [113, 117], [118, 119], [120, 122], [123, 132], [133, 140], [141, 154], [155, 157], [157, 169], [170, 173], [174, 187], [187, 188], [189, 193], [194, 197], [198, 200], [201, 208], [209, 211], [212, 218], [219, 225], [225, 226]]}
{"doc_key": "ai-test-207", "ner": [[0, 3, "algorithm"], [16, 18, "field"], [21, 24, "product"], [28, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 16, 18, "part-of", "", false, false], [0, 3, 28, 31, "part-of", "", false, false], [21, 24, 16, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "comparaison", "de", "mod\u00e8les", "a", "diverses", "applications", "et", "est", "utilis\u00e9e", "dans", "des", "domaines", "tels", "que", "la", "reconnaissance", "des", "visages", "(", "voir", "syst\u00e8me", "de", "reconnaissance", "faciale", ")", "et", "le", "traitement", "des", "images", "m\u00e9dicales", "."], "sentence-detokenized": "La comparaison de mod\u00e8les a diverses applications et est utilis\u00e9e dans des domaines tels que la reconnaissance des visages (voir syst\u00e8me de reconnaissance faciale) et le traitement des images m\u00e9dicales.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 25], [26, 27], [28, 36], [37, 49], [50, 52], [53, 56], [57, 65], [66, 70], [71, 74], [75, 83], [84, 88], [89, 92], [93, 95], [96, 110], [111, 114], [115, 122], [123, 124], [124, 128], [129, 136], [137, 139], [140, 154], [155, 162], [162, 163], [164, 166], [167, 169], [170, 180], [181, 184], [185, 191], [192, 201], [201, 202]]}
{"doc_key": "ai-test-208", "ner": [[13, 14, "researcher"], [16, 17, "researcher"], [22, 30, "organisation"], [32, 32, "organisation"], [42, 43, "algorithm"], [46, 56, "conference"], [58, 58, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 14, 22, 30, "role", "", false, false], [13, 14, 46, 56, "physical", "", false, false], [13, 14, 46, 56, "temporal", "", false, false], [13, 14, 58, 58, "physical", "", false, false], [16, 17, 22, 30, "role", "", false, false], [16, 17, 46, 56, "temporal", "", false, false], [32, 32, 22, 30, "named", "", false, false], [46, 56, 42, 43, "topic", "", false, false], [58, 58, 46, 56, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Toutefois", ",", "son", "utilisation", "ne", "s'", "est", "g\u00e9n\u00e9ralis\u00e9e", "qu'", "en", "2005", ",", "lorsque", "Navneet", "Dalal", "et", "Bill", "Triggs", ",", "chercheurs", "de", "l'", "Institut", "national", "de", "recherche", "en", "informatique", "et", "en", "automatique", "(", "INRIA", ")", ",", "ont", "pr\u00e9sent\u00e9", "leurs", "travaux", "compl\u00e9mentaires", "sur", "les", "descripteurs", "HOG", "\u00e0", "la", "conf\u00e9rence", "sur", "la", "vision", "par", "ordinateur", "et", "la", "reconnaissance", "des", "formes", "(", "CVPR", ")", "."], "sentence-detokenized": "Toutefois, son utilisation ne s'est g\u00e9n\u00e9ralis\u00e9e qu'en 2005, lorsque Navneet Dalal et Bill Triggs, chercheurs de l'Institut national de recherche en informatique et en automatique (INRIA), ont pr\u00e9sent\u00e9 leurs travaux compl\u00e9mentaires sur les descripteurs HOG \u00e0 la conf\u00e9rence sur la vision par ordinateur et la reconnaissance des formes (CVPR).", "token2charspan": [[0, 9], [9, 10], [11, 14], [15, 26], [27, 29], [30, 32], [32, 35], [36, 47], [48, 51], [51, 53], [54, 58], [58, 59], [60, 67], [68, 75], [76, 81], [82, 84], [85, 89], [90, 96], [96, 97], [98, 108], [109, 111], [112, 114], [114, 122], [123, 131], [132, 134], [135, 144], [145, 147], [148, 160], [161, 163], [164, 166], [167, 178], [179, 180], [180, 185], [185, 186], [186, 187], [188, 191], [192, 200], [201, 206], [207, 214], [215, 230], [231, 234], [235, 238], [239, 251], [252, 255], [256, 257], [258, 260], [261, 271], [272, 275], [276, 278], [279, 285], [286, 289], [290, 300], [301, 303], [304, 306], [307, 321], [322, 325], [326, 332], [333, 334], [334, 338], [338, 339], [339, 340]]}
{"doc_key": "ai-test-209", "ner": [[6, 6, "university"], [19, 22, "organisation"], [24, 25, "organisation"], [35, 35, "field"], [41, 43, "researcher"], [45, 47, "researcher"], [49, 51, "researcher"], [54, 60, "organisation"], [63, 66, "organisation"], [72, 73, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[24, 25, 35, 35, "related-to", "", false, false], [41, 43, 24, 25, "physical", "", false, false], [41, 43, 24, 25, "role", "", false, false], [45, 47, 24, 25, "physical", "", false, false], [45, 47, 24, 25, "role", "", false, false], [49, 51, 24, 25, "physical", "", false, false], [49, 51, 24, 25, "role", "", false, false], [72, 73, 63, 66, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Avant", "de", "rejoindre", "la", "facult\u00e9", "de", "Penn", "en", "2002", ",", "il", "a", "pass\u00e9", "une", "d\u00e9cennie", "(", "1991-2001", ")", "\u00e0", "AT", "&", "T", "Labs", "et", "Bell", "Labs", ",", "notamment", "en", "tant", "que", "chef", "du", "d\u00e9partement", "d'", "IA", "avec", "des", "coll\u00e8gues", "tels", "que", "Michael", "L.", "Littman", ",", "David", "A.", "McAllester", "et", "Richard", "S.", "Sutton", ",", "du", "d\u00e9partement", "de", "recherche", "sur", "les", "syst\u00e8mes", "s\u00e9curis\u00e9s", "et", "du", "d\u00e9partement", "d'", "apprentissage", "automatique", "avec", "des", "membres", "tels", "que", "Michael", "Collins", "et", "le", "chef", ")", "."], "sentence-detokenized": "Avant de rejoindre la facult\u00e9 de Penn en 2002, il a pass\u00e9 une d\u00e9cennie (1991-2001) \u00e0 AT & T Labs et Bell Labs, notamment en tant que chef du d\u00e9partement d'IA avec des coll\u00e8gues tels que Michael L. Littman, David A. McAllester et Richard S. Sutton, du d\u00e9partement de recherche sur les syst\u00e8mes s\u00e9curis\u00e9s et du d\u00e9partement d'apprentissage automatique avec des membres tels que Michael Collins et le chef).", "token2charspan": [[0, 5], [6, 8], [9, 18], [19, 21], [22, 29], [30, 32], [33, 37], [38, 40], [41, 45], [45, 46], [47, 49], [50, 51], [52, 57], [58, 61], [62, 70], [71, 72], [72, 81], [81, 82], [83, 84], [85, 87], [88, 89], [90, 91], [92, 96], [97, 99], [100, 104], [105, 109], [109, 110], [111, 120], [121, 123], [124, 128], [129, 132], [133, 137], [138, 140], [141, 152], [153, 155], [155, 157], [158, 162], [163, 166], [167, 176], [177, 181], [182, 185], [186, 193], [194, 196], [197, 204], [204, 205], [206, 211], [212, 214], [215, 225], [226, 228], [229, 236], [237, 239], [240, 246], [246, 247], [248, 250], [251, 262], [263, 265], [266, 275], [276, 279], [280, 283], [284, 292], [293, 302], [303, 305], [306, 308], [309, 320], [321, 323], [323, 336], [337, 348], [349, 353], [354, 357], [358, 365], [366, 370], [371, 374], [375, 382], [383, 390], [391, 393], [394, 396], [397, 401], [401, 402], [402, 403]]}
{"doc_key": "ai-test-210", "ner": [[9, 10, "field"], [20, 22, "field"], [30, 30, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 20, 22, "compare", "", false, false], [30, 30, 20, 22, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lorsque", "les", "donn\u00e9es", "ne", "sont", "pas", "\u00e9tiquet\u00e9es", ",", "l'", "apprentissage", "supervis\u00e9", "n'", "est", "pas", "possible", ",", "et", "une", "approche", "d'", "apprentissage", "non", "supervis\u00e9", "est", "n\u00e9cessaire", "pour", "tenter", "de", "trouver", "une", "analyse", "naturelle", "en", "groupes", ",", "puis", "de", "faire", "correspondre", "les", "nouvelles", "donn\u00e9es", "\u00e0", "ces", "groupes", "form\u00e9s", "."], "sentence-detokenized": "Lorsque les donn\u00e9es ne sont pas \u00e9tiquet\u00e9es, l'apprentissage supervis\u00e9 n'est pas possible, et une approche d'apprentissage non supervis\u00e9 est n\u00e9cessaire pour tenter de trouver une analyse naturelle en groupes, puis de faire correspondre les nouvelles donn\u00e9es \u00e0 ces groupes form\u00e9s.", "token2charspan": [[0, 7], [8, 11], [12, 19], [20, 22], [23, 27], [28, 31], [32, 42], [42, 43], [44, 46], [46, 59], [60, 69], [70, 72], [72, 75], [76, 79], [80, 88], [88, 89], [90, 92], [93, 96], [97, 105], [106, 108], [108, 121], [122, 125], [126, 135], [136, 139], [140, 150], [151, 155], [156, 162], [163, 165], [166, 173], [174, 177], [178, 185], [186, 195], [196, 198], [199, 206], [206, 207], [208, 212], [213, 215], [216, 221], [222, 234], [235, 238], [239, 248], [249, 256], [257, 258], [259, 262], [263, 270], [271, 277], [277, 278]]}
{"doc_key": "ai-test-211", "ner": [[4, 4, "field"], [19, 21, "organisation"], [31, 32, "field"], [36, 36, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 19, 21, "origin", "", false, false], [4, 4, 31, 32, "part-of", "", false, false], [4, 4, 36, 36, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Ce", "domaine", "de", "l'", "informatique", "s'", "est", "d\u00e9velopp\u00e9", "dans", "les", "ann\u00e9es", "1950", "dans", "des", "institutions", "universitaires", "telles", "que", "le", "MIT", "A.I.", "Lab", ",", "\u00e0", "l'", "origine", "comme", "une", "branche", "de", "l'", "intelligence", "artificielle", "et", "de", "la", "robotique", "."], "sentence-detokenized": "Ce domaine de l'informatique s'est d\u00e9velopp\u00e9 dans les ann\u00e9es 1950 dans des institutions universitaires telles que le MIT A.I. Lab, \u00e0 l'origine comme une branche de l'intelligence artificielle et de la robotique.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 16], [16, 28], [29, 31], [31, 34], [35, 44], [45, 49], [50, 53], [54, 60], [61, 65], [66, 70], [71, 74], [75, 87], [88, 102], [103, 109], [110, 113], [114, 116], [117, 120], [121, 125], [126, 129], [129, 130], [131, 132], [133, 135], [135, 142], [143, 148], [149, 152], [153, 160], [161, 163], [164, 166], [166, 178], [179, 191], [192, 194], [195, 197], [198, 200], [201, 210], [210, 211]]}
{"doc_key": "ai-test-212", "ner": [[9, 11, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Elle", "pourrait", "\u00e9galement", "\u00eatre", "remplac\u00e9e", "par", "l'", "\u00e9quation", "de", "perte", "de", "logarithme", "ci-dessous", ":"], "sentence-detokenized": "Elle pourrait \u00e9galement \u00eatre remplac\u00e9e par l'\u00e9quation de perte de logarithme ci-dessous :", "token2charspan": [[0, 4], [5, 13], [14, 23], [24, 28], [29, 38], [39, 42], [43, 45], [45, 53], [54, 56], [57, 62], [63, 65], [66, 76], [77, 87], [88, 89]]}
{"doc_key": "ai-test-213", "ner": [[1, 3, "organisation"], [7, 10, "organisation"], [14, 18, "university"], [21, 21, "university"], [24, 26, "university"], [29, 31, "university"], [33, 33, "country"], [41, 41, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[1, 3, 41, 41, "related-to", "research_leader_in_field", false, false], [7, 10, 1, 3, "named", "", false, false], [7, 10, 41, 41, "related-to", "research_leader_in_field", false, false], [14, 18, 41, 41, "related-to", "research_leader_in_field", false, false], [21, 21, 41, 41, "related-to", "research_leader_in_field", false, false], [24, 26, 41, 41, "related-to", "research_leader_in_field", false, false], [29, 31, 33, 33, "physical", "", false, false], [29, 31, 41, 41, "related-to", "research_leader_in_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Le", "Shirley", "Ryan", "AbilityLab", "(", "anciennement", "le", "Rehabilitation", "Institute", "of", "Chicago", ")", ",", "l'", "universit\u00e9", "de", "Californie", "\u00e0", "Berkeley", ",", "le", "MIT", ",", "l'", "universit\u00e9", "de", "Stanford", "et", "l'", "universit\u00e9", "de", "Twente", "aux", "Pays-Bas", "sont", "les", "leaders", "de", "la", "recherche", "en", "biom\u00e9catronique", "."], "sentence-detokenized": "Le Shirley Ryan AbilityLab (anciennement le Rehabilitation Institute of Chicago), l'universit\u00e9 de Californie \u00e0 Berkeley, le MIT, l'universit\u00e9 de Stanford et l'universit\u00e9 de Twente aux Pays-Bas sont les leaders de la recherche en biom\u00e9catronique.", "token2charspan": [[0, 2], [3, 10], [11, 15], [16, 26], [27, 28], [28, 40], [41, 43], [44, 58], [59, 68], [69, 71], [72, 79], [79, 80], [80, 81], [82, 84], [84, 94], [95, 97], [98, 108], [109, 110], [111, 119], [119, 120], [121, 123], [124, 127], [127, 128], [129, 131], [131, 141], [142, 144], [145, 153], [154, 156], [157, 159], [159, 169], [170, 172], [173, 179], [180, 183], [184, 192], [193, 197], [198, 201], [202, 209], [210, 212], [213, 215], [216, 225], [226, 228], [229, 244], [244, 245]]}
{"doc_key": "ai-test-214", "ner": [[29, 33, "metrics"], [45, 46, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["\u00c9tant", "donn\u00e9", "un", "ensemble", "de", "valeurs", "pr\u00e9dites", "et", "un", "ensemble", "correspondant", "de", "valeurs", "r\u00e9elles", "pour", "X", "pour", "diverses", "p\u00e9riodes", ",", "une", "technique", "d'", "\u00e9valuation", "courante", "consiste", "\u00e0", "utiliser", "l'", "erreur", "quadratique", "moyenne", "de", "pr\u00e9diction", ";", "d'", "autres", "mesures", "sont", "\u00e9galement", "disponibles", "(", "voir", "forecasting", "#", "forecasting", "accuracy", ")", "."], "sentence-detokenized": "\u00c9tant donn\u00e9 un ensemble de valeurs pr\u00e9dites et un ensemble correspondant de valeurs r\u00e9elles pour X pour diverses p\u00e9riodes, une technique d'\u00e9valuation courante consiste \u00e0 utiliser l'erreur quadratique moyenne de pr\u00e9diction ; d'autres mesures sont \u00e9galement disponibles (voir forecasting # forecasting accuracy).", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 23], [24, 26], [27, 34], [35, 43], [44, 46], [47, 49], [50, 58], [59, 72], [73, 75], [76, 83], [84, 91], [92, 96], [97, 98], [99, 103], [104, 112], [113, 121], [121, 122], [123, 126], [127, 136], [137, 139], [139, 149], [150, 158], [159, 167], [168, 169], [170, 178], [179, 181], [181, 187], [188, 199], [200, 207], [208, 210], [211, 221], [222, 223], [224, 226], [226, 232], [233, 240], [241, 245], [246, 255], [256, 267], [268, 269], [269, 273], [274, 285], [286, 287], [288, 299], [300, 308], [308, 309], [309, 310]]}
{"doc_key": "ai-test-215", "ner": [[14, 14, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["D'", "autres", "mesures", ",", "telles", "que", "la", "proportion", "de", "pr\u00e9dictions", "correctes", "(", "\u00e9galement", "appel\u00e9e", "pr\u00e9cision", ")", ",", "ne", "sont", "pas", "utiles", "lorsque", "les", "deux", "classes", "sont", "de", "tailles", "tr\u00e8s", "diff\u00e9rentes", "."], "sentence-detokenized": "D'autres mesures, telles que la proportion de pr\u00e9dictions correctes (\u00e9galement appel\u00e9e pr\u00e9cision), ne sont pas utiles lorsque les deux classes sont de tailles tr\u00e8s diff\u00e9rentes.", "token2charspan": [[0, 2], [2, 8], [9, 16], [16, 17], [18, 24], [25, 28], [29, 31], [32, 42], [43, 45], [46, 57], [58, 67], [68, 69], [69, 78], [79, 86], [87, 96], [96, 97], [97, 98], [99, 101], [102, 106], [107, 110], [111, 117], [118, 125], [126, 129], [130, 134], [135, 142], [143, 147], [148, 150], [151, 158], [159, 163], [164, 175], [175, 176]]}
{"doc_key": "ai-test-216", "ner": [[5, 5, "product"], [16, 22, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 16, 22, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["La", "premi\u00e8re", "version", "alpha", "d'", "OpenCV", "a", "\u00e9t\u00e9", "rendue", "publique", "lors", "de", "la", "Conf\u00e9rence", "sur", "la", "vision", "informatique", "et", "la", "reconnaissance", "des", "formes", "en", "2000", ",", "et", "cinq", "versions", "b\u00eata", "ont", "\u00e9t\u00e9", "publi\u00e9es", "entre", "2001", "et", "2005", "."], "sentence-detokenized": "La premi\u00e8re version alpha d'OpenCV a \u00e9t\u00e9 rendue publique lors de la Conf\u00e9rence sur la vision informatique et la reconnaissance des formes en 2000, et cinq versions b\u00eata ont \u00e9t\u00e9 publi\u00e9es entre 2001 et 2005.", "token2charspan": [[0, 2], [3, 11], [12, 19], [20, 25], [26, 28], [28, 34], [35, 36], [37, 40], [41, 47], [48, 56], [57, 61], [62, 64], [65, 67], [68, 78], [79, 82], [83, 85], [86, 92], [93, 105], [106, 108], [109, 111], [112, 126], [127, 130], [131, 137], [138, 140], [141, 145], [145, 146], [147, 149], [150, 154], [155, 163], [164, 168], [169, 172], [173, 176], [177, 185], [186, 191], [192, 196], [197, 199], [200, 204], [204, 205]]}
{"doc_key": "ai-test-217", "ner": [[24, 25, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Les", "r\u00e9sultats", "pr\u00e9sent\u00e9s", "donnent", "une", "corr\u00e9lation", "allant", "jusqu'", "\u00e0", "0,964", "avec", "le", "jugement", "humain", "au", "niveau", "du", "corpus", ",", "compar\u00e9", "\u00e0", "la", "performance", "de", "BLEU", "de", "0,817", "sur", "le", "m\u00eame", "ensemble", "de", "donn\u00e9es", "."], "sentence-detokenized": "Les r\u00e9sultats pr\u00e9sent\u00e9s donnent une corr\u00e9lation allant jusqu'\u00e0 0,964 avec le jugement humain au niveau du corpus, compar\u00e9 \u00e0 la performance de BLEU de 0,817 sur le m\u00eame ensemble de donn\u00e9es.", "token2charspan": [[0, 3], [4, 13], [14, 23], [24, 31], [32, 35], [36, 47], [48, 54], [55, 61], [61, 62], [63, 68], [69, 73], [74, 76], [77, 85], [86, 92], [93, 95], [96, 102], [103, 105], [106, 112], [112, 113], [114, 121], [122, 123], [124, 126], [127, 138], [139, 141], [142, 146], [147, 149], [150, 155], [156, 159], [160, 162], [163, 167], [168, 176], [177, 179], [180, 187], [187, 188]]}
{"doc_key": "ai-test-218", "ner": [[4, 4, "metrics"], [23, 23, "metrics"], [25, 27, "metrics"], [29, 29, "metrics"], [40, 41, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 23, 23, "compare", "", false, false], [4, 4, 25, 27, "compare", "", false, false], [4, 4, 29, 29, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Une", "premi\u00e8re", "version", "du", "VMAF", "s'", "est", "av\u00e9r\u00e9e", "plus", "performante", "que", "d'", "autres", "mesures", "de", "qualit\u00e9", "d'", "image", "et", "de", "vid\u00e9o", "telles", "que", "SSIM", ",", "PSNR", "-", "HVS", "et", "VQM-VFD", "sur", "trois", "des", "quatre", "ensembles", "de", "donn\u00e9es", "en", "termes", "de", "pr\u00e9cision", "de", "pr\u00e9diction", ",", "par", "rapport", "aux", "\u00e9valuations", "subjectives", "."], "sentence-detokenized": "Une premi\u00e8re version du VMAF s'est av\u00e9r\u00e9e plus performante que d'autres mesures de qualit\u00e9 d'image et de vid\u00e9o telles que SSIM, PSNR -HVS et VQM-VFD sur trois des quatre ensembles de donn\u00e9es en termes de pr\u00e9cision de pr\u00e9diction, par rapport aux \u00e9valuations subjectives.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 23], [24, 28], [29, 31], [31, 34], [35, 41], [42, 46], [47, 58], [59, 62], [63, 65], [65, 71], [72, 79], [80, 82], [83, 90], [91, 93], [93, 98], [99, 101], [102, 104], [105, 110], [111, 117], [118, 121], [122, 126], [126, 127], [128, 132], [133, 134], [134, 137], [138, 140], [141, 148], [149, 152], [153, 158], [159, 162], [163, 169], [170, 179], [180, 182], [183, 190], [191, 193], [194, 200], [201, 203], [204, 213], [214, 216], [217, 227], [227, 228], [229, 232], [233, 240], [241, 244], [245, 256], [257, 268], [268, 269]]}
{"doc_key": "ai-test-219", "ner": [[21, 22, "task"], [29, 31, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[21, 22, 29, 31, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Par", "exemple", ",", "l'", "ambigu\u00eft\u00e9", "du", "mot", "\"", "souris", "\"", "(", "animal", "ou", "dispositif", ")", "n'", "est", "pas", "pertinente", "pour", "la", "traduction", "automatique", ",", "mais", "l'", "est", "pour", "la", "recherche", "d'", "informations", "."], "sentence-detokenized": "Par exemple, l'ambigu\u00eft\u00e9 du mot \"souris\" (animal ou dispositif) n'est pas pertinente pour la traduction automatique, mais l'est pour la recherche d'informations.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [15, 24], [25, 27], [28, 31], [32, 33], [33, 39], [39, 40], [41, 42], [42, 48], [49, 51], [52, 62], [62, 63], [64, 66], [66, 69], [70, 73], [74, 84], [85, 89], [90, 92], [93, 103], [104, 115], [115, 116], [117, 121], [122, 124], [124, 127], [128, 132], [133, 135], [136, 145], [146, 148], [148, 160], [160, 161]]}
{"doc_key": "ai-test-220", "ner": [[0, 2, "algorithm"], [10, 12, "field"], [15, 17, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 12, 0, 2, "usage", "", false, false], [15, 17, 10, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Le", "hachage", "g\u00e9om\u00e9trique", "a", "\u00e9t\u00e9", "propos\u00e9", "\u00e0", "l'", "origine", "en", "vision", "par", "ordinateur", "pour", "la", "reconnaissance", "d'", "objets", "en", "2D", "et", "3D", ","], "sentence-detokenized": "Le hachage g\u00e9om\u00e9trique a \u00e9t\u00e9 propos\u00e9 \u00e0 l'origine en vision par ordinateur pour la reconnaissance d'objets en 2D et 3D,", "token2charspan": [[0, 2], [3, 10], [11, 22], [23, 24], [25, 28], [29, 36], [37, 38], [39, 41], [41, 48], [49, 51], [52, 58], [59, 62], [63, 73], [74, 78], [79, 81], [82, 96], [97, 99], [99, 105], [106, 108], [109, 111], [112, 114], [115, 117], [117, 118]]}
{"doc_key": "ai-test-221", "ner": [[9, 10, "field"], [14, 15, "field"], [18, 20, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 15, 9, 10, "part-of", "subfield", false, false], [18, 20, 9, 10, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Elle", "constitue", "l'", "une", "des", "trois", "principales", "cat\u00e9gories", "d'", "apprentissage", "automatique", ",", "avec", "l'", "apprentissage", "supervis\u00e9", "et", "l'", "apprentissage", "par", "renforcement", "."], "sentence-detokenized": "Elle constitue l'une des trois principales cat\u00e9gories d'apprentissage automatique, avec l'apprentissage supervis\u00e9 et l'apprentissage par renforcement.", "token2charspan": [[0, 4], [5, 14], [15, 17], [17, 20], [21, 24], [25, 30], [31, 42], [43, 53], [54, 56], [56, 69], [70, 81], [81, 82], [83, 87], [88, 90], [90, 103], [104, 113], [114, 116], [117, 119], [119, 132], [133, 136], [137, 149], [149, 150]]}
{"doc_key": "ai-test-222", "ner": [[0, 3, "field"], [22, 22, "field"], [25, 27, "field"], [30, 31, "field"], [34, 37, "field"], [40, 44, "field"], [47, 48, "field"], [51, 52, "field"], [55, 55, "field"], [58, 59, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 3, 22, 22, "part-of", "subfield", false, false], [0, 3, 25, 27, "part-of", "subfield", false, false], [0, 3, 30, 31, "part-of", "subfield", false, false], [0, 3, 34, 37, "part-of", "subfield", false, false], [0, 3, 40, 44, "part-of", "subfield", false, false], [0, 3, 47, 48, "part-of", "subfield", false, false], [0, 3, 51, 52, "part-of", "subfield", false, false], [0, 3, 55, 55, "part-of", "subfield", false, false], [0, 3, 58, 59, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["L'", "apprentissage", "par", "renforcement", ",", "en", "raison", "de", "sa", "g\u00e9n\u00e9ralit\u00e9", ",", "est", "\u00e9tudi\u00e9", "dans", "de", "nombreuses", "autres", "disciplines", ",", "telles", "que", "le", "jeu", ",", "la", "th\u00e9orie", "du", "contr\u00f4le", ",", "la", "recherche", "op\u00e9rationnelle", ",", "la", "th\u00e9orie", "de", "l'", "information", ",", "l'", "optimisation", "bas\u00e9e", "sur", "la", "simulation", ",", "les", "syst\u00e8mes", "multi-agents", ",", "l'", "intelligence", "artificielle", ",", "les", "statistiques", "et", "les", "algorithmes", "g\u00e9n\u00e9tiques", "."], "sentence-detokenized": "L'apprentissage par renforcement, en raison de sa g\u00e9n\u00e9ralit\u00e9, est \u00e9tudi\u00e9 dans de nombreuses autres disciplines, telles que le jeu, la th\u00e9orie du contr\u00f4le, la recherche op\u00e9rationnelle, la th\u00e9orie de l'information, l'optimisation bas\u00e9e sur la simulation, les syst\u00e8mes multi-agents, l'intelligence artificielle, les statistiques et les algorithmes g\u00e9n\u00e9tiques.", "token2charspan": [[0, 2], [2, 15], [16, 19], [20, 32], [32, 33], [34, 36], [37, 43], [44, 46], [47, 49], [50, 60], [60, 61], [62, 65], [66, 72], [73, 77], [78, 80], [81, 91], [92, 98], [99, 110], [110, 111], [112, 118], [119, 122], [123, 125], [126, 129], [129, 130], [131, 133], [134, 141], [142, 144], [145, 153], [153, 154], [155, 157], [158, 167], [168, 182], [182, 183], [184, 186], [187, 194], [195, 197], [198, 200], [200, 211], [211, 212], [213, 215], [215, 227], [228, 233], [234, 237], [238, 240], [241, 251], [251, 252], [253, 256], [257, 265], [266, 278], [278, 279], [280, 282], [282, 294], [295, 307], [307, 308], [309, 312], [313, 325], [326, 328], [329, 332], [333, 344], [345, 355], [355, 356]]}
{"doc_key": "ai-test-223", "ner": [[0, 3, "field"], [9, 10, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 9, 10, "related-to", "", false, false], [0, 3, 14, 15, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "reconnaissance", "des", "formes", "est", "\u00e9troitement", "li\u00e9e", "\u00e0", "l'", "intelligence", "artificielle", "et", "\u00e0", "l'", "apprentissage", "automatique", ","], "sentence-detokenized": "La reconnaissance des formes est \u00e9troitement li\u00e9e \u00e0 l'intelligence artificielle et \u00e0 l'apprentissage automatique,", "token2charspan": [[0, 2], [3, 17], [18, 21], [22, 28], [29, 32], [33, 44], [45, 49], [50, 51], [52, 54], [54, 66], [67, 79], [80, 82], [83, 84], [85, 87], [87, 100], [101, 112], [112, 113]]}
{"doc_key": "ai-test-224", "ner": [[13, 14, "algorithm"], [16, 17, "field"], [19, 21, "field"], [34, 36, "task"], [39, 39, "task"], [42, 44, "task"], [47, 48, "algorithm"], [51, 54, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[13, 14, 16, 17, "related-to", "", false, false], [13, 14, 19, 21, "related-to", "", false, false], [34, 36, 13, 14, "usage", "", true, false], [39, 39, 13, 14, "usage", "", true, false], [42, 44, 13, 14, "usage", "", true, false], [47, 48, 13, 14, "usage", "", true, false], [51, 54, 13, 14, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Le", "logiciel", "est", "utilis\u00e9", "pour", "concevoir", ",", "former", "et", "d\u00e9ployer", "des", "mod\u00e8les", "de", "r\u00e9seaux", "neuronaux", "(", "apprentissage", "supervis\u00e9", "et", "apprentissage", "non", "supervis\u00e9", ")", "afin", "d'", "effectuer", "une", "grande", "vari\u00e9t\u00e9", "de", "t\u00e2ches", "telles", "que", "l'", "exploration", "de", "donn\u00e9es", ",", "la", "classification", ",", "l'", "approximation", "de", "fonctions", ",", "la", "r\u00e9gression", "multivari\u00e9e", "et", "la", "pr\u00e9diction", "de", "s\u00e9ries", "chronologiques", "."], "sentence-detokenized": "Le logiciel est utilis\u00e9 pour concevoir, former et d\u00e9ployer des mod\u00e8les de r\u00e9seaux neuronaux (apprentissage supervis\u00e9 et apprentissage non supervis\u00e9) afin d'effectuer une grande vari\u00e9t\u00e9 de t\u00e2ches telles que l'exploration de donn\u00e9es, la classification, l'approximation de fonctions, la r\u00e9gression multivari\u00e9e et la pr\u00e9diction de s\u00e9ries chronologiques.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 23], [24, 28], [29, 38], [38, 39], [40, 46], [47, 49], [50, 58], [59, 62], [63, 70], [71, 73], [74, 81], [82, 91], [92, 93], [93, 106], [107, 116], [117, 119], [120, 133], [134, 137], [138, 147], [147, 148], [149, 153], [154, 156], [156, 165], [166, 169], [170, 176], [177, 184], [185, 187], [188, 194], [195, 201], [202, 205], [206, 208], [208, 219], [220, 222], [223, 230], [230, 231], [232, 234], [235, 249], [249, 250], [251, 253], [253, 266], [267, 269], [270, 279], [279, 280], [281, 283], [284, 294], [295, 306], [307, 309], [310, 312], [313, 323], [324, 326], [327, 333], [334, 348], [348, 349]]}
{"doc_key": "ai-test-225", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["En", "2016", ",", "il", "a", "\u00e9t\u00e9", "\u00e9lu", "membre", "de", "l'", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "En 2016, il a \u00e9t\u00e9 \u00e9lu membre de l'Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 13], [14, 17], [18, 21], [22, 28], [29, 31], [32, 34], [34, 45], [46, 49], [50, 53], [54, 65], [66, 68], [69, 79], [80, 92], [92, 93]]}
{"doc_key": "ai-test-226", "ner": [[5, 8, "organisation"], [16, 21, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Elle", "est", "membre", "de", "la", "National", "Academy", "of", "Sciences", "(", "depuis", "2005", ")", ",", "de", "l'", "American", "Academy", "of", "Arts", "and", "Sciences", "(", "depuis", "2009", ")", ","], "sentence-detokenized": "Elle est membre de la National Academy of Sciences (depuis 2005), de l'American Academy of Arts and Sciences (depuis 2009),", "token2charspan": [[0, 4], [5, 8], [9, 15], [16, 18], [19, 21], [22, 30], [31, 38], [39, 41], [42, 50], [51, 52], [52, 58], [59, 63], [63, 64], [64, 65], [66, 68], [69, 71], [71, 79], [80, 87], [88, 90], [91, 95], [96, 99], [100, 108], [109, 110], [110, 116], [117, 121], [121, 122], [122, 123]]}
{"doc_key": "ai-test-227", "ner": [[2, 5, "misc"], [11, 12, "product"], [19, 19, "country"], [22, 23, "country"], [29, 32, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 12, 2, 5, "temporal", "", false, false], [11, 12, 19, 19, "physical", "", false, false], [11, 12, 22, 23, "physical", "", false, false], [11, 12, 29, 32, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Pendant", "la", "guerre", "du", "Kippour", "en", "1973", ",", "les", "batteries", "de", "missiles", "sol-air", "fournies", "par", "l'", "Union", "sovi\u00e9tique", "en", "\u00c9gypte", "et", "en", "Syrie", "ont", "caus\u00e9", "de", "lourds", "dommages", "aux", "avions", "de", "chasse", "isra\u00e9liens", "."], "sentence-detokenized": "Pendant la guerre du Kippour en 1973, les batteries de missiles sol-air fournies par l'Union sovi\u00e9tique en \u00c9gypte et en Syrie ont caus\u00e9 de lourds dommages aux avions de chasse isra\u00e9liens.", "token2charspan": [[0, 7], [8, 10], [11, 17], [18, 20], [21, 28], [29, 31], [32, 36], [36, 37], [38, 41], [42, 51], [52, 54], [55, 63], [64, 71], [72, 80], [81, 84], [85, 87], [87, 92], [93, 103], [104, 106], [107, 113], [114, 116], [117, 119], [120, 125], [126, 129], [130, 135], [136, 138], [139, 145], [146, 154], [155, 158], [159, 165], [166, 168], [169, 175], [176, 186], [186, 187]]}
{"doc_key": "ai-test-228", "ner": [[15, 16, "product"], [20, 23, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 23, 15, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Une", "autre", "ressource", "(", "gratuite", "mais", "prot\u00e9g\u00e9e", "par", "des", "droits", "d'", "auteur", ")", "est", "le", "livre", "HTK", "(", "et", "la", "bo\u00eete", "\u00e0", "outils", "HTK", "qui", "l'", "accompagne", ")", "."], "sentence-detokenized": "Une autre ressource (gratuite mais prot\u00e9g\u00e9e par des droits d'auteur) est le livre HTK (et la bo\u00eete \u00e0 outils HTK qui l'accompagne).", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 21], [21, 29], [30, 34], [35, 43], [44, 47], [48, 51], [52, 58], [59, 61], [61, 67], [67, 68], [69, 72], [73, 75], [76, 81], [82, 85], [86, 87], [87, 89], [90, 92], [93, 98], [99, 100], [101, 107], [108, 111], [112, 115], [116, 118], [118, 128], [128, 129], [129, 130]]}
{"doc_key": "ai-test-229", "ner": [[9, 12, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["-", "ont", "\u00e9t\u00e9", "prises", "lors", "du", "symposium", "de", "printemps", "2004", "de", "l'", "AAAI", ",", "au", "cours", "duquel", "des", "linguistes", ",", "des", "informaticiens", "et", "d'", "autres", "chercheurs", "int\u00e9ress\u00e9s", "ont", "pour", "la", "premi\u00e8re", "fois", "align\u00e9", "leurs", "int\u00e9r\u00eats", "et", "propos\u00e9", "des", "t\u00e2ches", "partag\u00e9es", "et", "des", "ensembles", "de", "donn\u00e9es", "de", "r\u00e9f\u00e9rence", "pour", "la", "recherche", "informatique", "syst\u00e9matique", "sur", "l'", "affect", ",", "l'", "attrait", ",", "la", "subjectivit\u00e9", "et", "le", "sentiment", "dans", "les", "textes", "."], "sentence-detokenized": "- ont \u00e9t\u00e9 prises lors du symposium de printemps 2004 de l'AAAI, au cours duquel des linguistes, des informaticiens et d'autres chercheurs int\u00e9ress\u00e9s ont pour la premi\u00e8re fois align\u00e9 leurs int\u00e9r\u00eats et propos\u00e9 des t\u00e2ches partag\u00e9es et des ensembles de donn\u00e9es de r\u00e9f\u00e9rence pour la recherche informatique syst\u00e9matique sur l'affect, l'attrait, la subjectivit\u00e9 et le sentiment dans les textes.", "token2charspan": [[0, 1], [2, 5], [6, 9], [10, 16], [17, 21], [22, 24], [25, 34], [35, 37], [38, 47], [48, 52], [53, 55], [56, 58], [58, 62], [62, 63], [64, 66], [67, 72], [73, 79], [80, 83], [84, 94], [94, 95], [96, 99], [100, 114], [115, 117], [118, 120], [120, 126], [127, 137], [138, 148], [149, 152], [153, 157], [158, 160], [161, 169], [170, 174], [175, 181], [182, 187], [188, 196], [197, 199], [200, 207], [208, 211], [212, 218], [219, 228], [229, 231], [232, 235], [236, 245], [246, 248], [249, 256], [257, 259], [260, 269], [270, 274], [275, 277], [278, 287], [288, 300], [301, 313], [314, 317], [318, 320], [320, 326], [326, 327], [328, 330], [330, 337], [337, 338], [339, 341], [342, 354], [355, 357], [358, 360], [361, 370], [371, 375], [376, 379], [380, 386], [386, 387]]}
{"doc_key": "ai-test-230", "ner": [[15, 16, "task"], [24, 26, "task"], [29, 32, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Une", "seule", "grille", "peut", "\u00eatre", "analys\u00e9e", "\u00e0", "la", "fois", "sur", "le", "plan", "du", "contenu", "(", "inspection", "visuelle", ")", "et", "de", "la", "structure", "(", "l'", "analyse", "en", "grappes", ",", "l'", "analyse", "en", "composantes", "principales", "et", "divers", "indices", "structurels", "relatifs", "\u00e0", "la", "complexit\u00e9", "et", "\u00e0", "l'", "\u00e9tendue", "des", "\u00e9valuations", "\u00e9tant", "les", "principales", "techniques", "utilis\u00e9es", ")", "."], "sentence-detokenized": "Une seule grille peut \u00eatre analys\u00e9e \u00e0 la fois sur le plan du contenu (inspection visuelle) et de la structure (l'analyse en grappes, l'analyse en composantes principales et divers indices structurels relatifs \u00e0 la complexit\u00e9 et \u00e0 l'\u00e9tendue des \u00e9valuations \u00e9tant les principales techniques utilis\u00e9es).", "token2charspan": [[0, 3], [4, 9], [10, 16], [17, 21], [22, 26], [27, 35], [36, 37], [38, 40], [41, 45], [46, 49], [50, 52], [53, 57], [58, 60], [61, 68], [69, 70], [70, 80], [81, 89], [89, 90], [91, 93], [94, 96], [97, 99], [100, 109], [110, 111], [111, 113], [113, 120], [121, 123], [124, 131], [131, 132], [133, 135], [135, 142], [143, 145], [146, 157], [158, 169], [170, 172], [173, 179], [180, 187], [188, 199], [200, 208], [209, 210], [211, 213], [214, 224], [225, 227], [228, 229], [230, 232], [232, 239], [240, 243], [244, 255], [256, 261], [262, 265], [266, 277], [278, 288], [289, 298], [298, 299], [299, 300]]}
{"doc_key": "ai-test-231", "ner": [[3, 3, "organisation"], [15, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["En", "2018", ",", "Toyota", "\u00e9tait", "consid\u00e9r\u00e9", "comme", "\u00e9tant", "en", "retard", "dans", "le", "domaine", "de", "la", "voiture", "\u00e0", "conduite", "autonome", "et", "ayant", "besoin", "d'", "innovation", "."], "sentence-detokenized": "En 2018, Toyota \u00e9tait consid\u00e9r\u00e9 comme \u00e9tant en retard dans le domaine de la voiture \u00e0 conduite autonome et ayant besoin d'innovation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 21], [22, 31], [32, 37], [38, 43], [44, 46], [47, 53], [54, 58], [59, 61], [62, 69], [70, 72], [73, 75], [76, 83], [84, 85], [86, 94], [95, 103], [104, 106], [107, 112], [113, 119], [120, 122], [122, 132], [132, 133]]}
{"doc_key": "ai-test-232", "ner": [[55, 58, "misc"], [61, 63, "misc"], [66, 71, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ces", "cibles", "comprennent", "des", "objets", "naturels", "tels", "que", "le", "sol", ",", "la", "mer", ",", "les", "pr\u00e9cipitations", "(", "telles", "que", "la", "pluie", ",", "la", "neige", "ou", "la", "gr\u00eale", ")", ",", "les", "temp\u00eates", "de", "sable", ",", "les", "animaux", "(", "en", "particulier", "les", "oiseaux", ")", ",", "les", "turbulences", "atmosph\u00e9riques", "et", "d'", "autres", "effets", "atmosph\u00e9riques", ",", "tels", "que", "les", "r\u00e9flexions", "de", "l'", "ionosph\u00e8re", ",", "les", "tra\u00een\u00e9es", "de", "m\u00e9t\u00e9ores", "et", "le", "pic", "de", "diffusion", "\u00e0", "trois", "corps", "."], "sentence-detokenized": "Ces cibles comprennent des objets naturels tels que le sol, la mer, les pr\u00e9cipitations (telles que la pluie, la neige ou la gr\u00eale), les temp\u00eates de sable, les animaux (en particulier les oiseaux), les turbulences atmosph\u00e9riques et d'autres effets atmosph\u00e9riques, tels que les r\u00e9flexions de l'ionosph\u00e8re, les tra\u00een\u00e9es de m\u00e9t\u00e9ores et le pic de diffusion \u00e0 trois corps.", "token2charspan": [[0, 3], [4, 10], [11, 22], [23, 26], [27, 33], [34, 42], [43, 47], [48, 51], [52, 54], [55, 58], [58, 59], [60, 62], [63, 66], [66, 67], [68, 71], [72, 86], [87, 88], [88, 94], [95, 98], [99, 101], [102, 107], [107, 108], [109, 111], [112, 117], [118, 120], [121, 123], [124, 129], [129, 130], [130, 131], [132, 135], [136, 144], [145, 147], [148, 153], [153, 154], [155, 158], [159, 166], [167, 168], [168, 170], [171, 182], [183, 186], [187, 194], [194, 195], [195, 196], [197, 200], [201, 212], [213, 227], [228, 230], [231, 233], [233, 239], [240, 246], [247, 261], [261, 262], [263, 267], [268, 271], [272, 275], [276, 286], [287, 289], [290, 292], [292, 302], [302, 303], [304, 307], [308, 316], [317, 319], [320, 328], [329, 331], [332, 334], [335, 338], [339, 341], [342, 351], [352, 353], [354, 359], [360, 365], [365, 366]]}
{"doc_key": "ai-test-233", "ner": [[24, 24, "product"], [51, 52, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["En", "mati\u00e8re", "de", "planification", "et", "de", "contr\u00f4le", ",", "la", "diff\u00e9rence", "essentielle", "entre", "les", "humano\u00efdes", "et", "les", "autres", "types", "de", "robots", "(", "comme", "les", "robots", "industriels", ")", "est", "que", "le", "mouvement", "du", "robot", "doit", "\u00eatre", "semblable", "\u00e0", "celui", "de", "l'", "homme", ",", "en", "utilisant", "la", "locomotion", "des", "jambes", ",", "en", "particulier", "la", "d\u00e9marche", "bip\u00e8de", "."], "sentence-detokenized": "En mati\u00e8re de planification et de contr\u00f4le, la diff\u00e9rence essentielle entre les humano\u00efdes et les autres types de robots (comme les robots industriels) est que le mouvement du robot doit \u00eatre semblable \u00e0 celui de l'homme, en utilisant la locomotion des jambes, en particulier la d\u00e9marche bip\u00e8de.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 27], [28, 30], [31, 33], [34, 42], [42, 43], [44, 46], [47, 57], [58, 69], [70, 75], [76, 79], [80, 90], [91, 93], [94, 97], [98, 104], [105, 110], [111, 113], [114, 120], [121, 122], [122, 127], [128, 131], [132, 138], [139, 150], [150, 151], [152, 155], [156, 159], [160, 162], [163, 172], [173, 175], [176, 181], [182, 186], [187, 191], [192, 201], [202, 203], [204, 209], [210, 212], [213, 215], [215, 220], [220, 221], [222, 224], [225, 234], [235, 237], [238, 248], [249, 252], [253, 259], [259, 260], [261, 263], [264, 275], [276, 278], [279, 287], [288, 294], [294, 295]]}
{"doc_key": "ai-test-234", "ner": [[1, 3, "algorithm"], [12, 13, "misc"], [16, 16, "metrics"], [21, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "descente", "de", "gradient", "peut", "prendre", "de", "nombreuses", "it\u00e9rations", "pour", "calculer", "un", "minimum", "local", "avec", "la", "pr\u00e9cision", "requise", ",", "si", "la", "courbure", "dans", "les", "diff\u00e9rentes", "directions", "est", "tr\u00e8s", "diff\u00e9rente", "pour", "la", "fonction", "donn\u00e9e", "."], "sentence-detokenized": "La descente de gradient peut prendre de nombreuses it\u00e9rations pour calculer un minimum local avec la pr\u00e9cision requise, si la courbure dans les diff\u00e9rentes directions est tr\u00e8s diff\u00e9rente pour la fonction donn\u00e9e.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 23], [24, 28], [29, 36], [37, 39], [40, 50], [51, 61], [62, 66], [67, 75], [76, 78], [79, 86], [87, 92], [93, 97], [98, 100], [101, 110], [111, 118], [118, 119], [120, 122], [123, 125], [126, 134], [135, 139], [140, 143], [144, 155], [156, 166], [167, 170], [171, 175], [176, 186], [187, 191], [192, 194], [195, 203], [204, 210], [210, 211]]}
{"doc_key": "ai-test-235", "ner": [[1, 6, "misc"], [12, 12, "misc"], [19, 24, "conference"], [30, 30, "location"], [33, 33, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 6, 12, 12, "part-of", "", true, false], [19, 24, 30, 30, "physical", "", false, true], [30, 30, 33, 33, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "RoboCup", "2D", "Soccer", "Simulation", "League", "1997", "a", "\u00e9t\u00e9", "la", "premi\u00e8re", "comp\u00e9tition", "RoboCup", "organis\u00e9e", "dans", "le", "cadre", "de", "l'", "International", "Joint", "Conference", "on", "Artificial", "Intelligence", "qui", "s'", "est", "tenue", "\u00e0", "Nagoya", ",", "au", "Japon", ",", "du", "23", "au", "29", "ao\u00fbt", "1997", "."], "sentence-detokenized": "La RoboCup 2D Soccer Simulation League 1997 a \u00e9t\u00e9 la premi\u00e8re comp\u00e9tition RoboCup organis\u00e9e dans le cadre de l'International Joint Conference on Artificial Intelligence qui s'est tenue \u00e0 Nagoya, au Japon, du 23 au 29 ao\u00fbt 1997.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 20], [21, 31], [32, 38], [39, 43], [44, 45], [46, 49], [50, 52], [53, 61], [62, 73], [74, 81], [82, 91], [92, 96], [97, 99], [100, 105], [106, 108], [109, 111], [111, 124], [125, 130], [131, 141], [142, 144], [145, 155], [156, 168], [169, 172], [173, 175], [175, 178], [179, 184], [185, 186], [187, 193], [193, 194], [195, 197], [198, 203], [203, 204], [205, 207], [208, 210], [211, 213], [214, 216], [217, 221], [222, 226], [226, 227]]}
{"doc_key": "ai-test-236", "ner": [[8, 8, "programlang"], [13, 13, "programlang"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Les", "autres", "options", "de", "programmation", "comprennent", "un", "environnement", "Python", "int\u00e9gr\u00e9", "et", "une", "console", "R", ",", "ainsi", "que", "la", "prise", "en", "charge", "de", "Rserve", "."], "sentence-detokenized": "Les autres options de programmation comprennent un environnement Python int\u00e9gr\u00e9 et une console R, ainsi que la prise en charge de Rserve.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 21], [22, 35], [36, 47], [48, 50], [51, 64], [65, 71], [72, 79], [80, 82], [83, 86], [87, 94], [95, 96], [96, 97], [98, 103], [104, 107], [108, 110], [111, 116], [117, 119], [120, 126], [127, 129], [130, 136], [136, 137]]}
{"doc_key": "ai-test-237", "ner": [[1, 1, "location"], [11, 12, "field"], [16, 16, "field"], [19, 20, "researcher"], [22, 23, "researcher"], [25, 26, "researcher"], [37, 38, "field"], [46, 47, "field"], [51, 53, "field"], [61, 62, "field"], [66, 69, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[19, 20, 16, 16, "related-to", "contributes_to_field", true, false], [22, 23, 16, 16, "related-to", "contributes_to_field", true, false], [25, 26, 16, 16, "related-to", "contributes_to_field", true, false], [51, 53, 46, 47, "part-of", "", false, false], [61, 62, 51, 53, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Depuis", "Bonn", ",", "il", "a", "apport\u00e9", "une", "contribution", "fondamentale", "\u00e0", "l'", "intelligence", "artificielle", "et", "\u00e0", "la", "robotique", "(", "avec", "Wolfram", "Burgard", ",", "Dieter", "Fox", ",", "Sebastian", "Thrun", "parmi", "ses", "\u00e9tudiants", ")", ",", "ainsi", "qu'", "au", "d\u00e9veloppement", "du", "g\u00e9nie", "logiciel", ",", "en", "particulier", "dans", "le", "domaine", "du", "g\u00e9nie", "civil", ",", "et", "des", "syst\u00e8mes", "d'", "information", ",", "en", "particulier", "dans", "le", "domaine", "des", "g\u00e9osciences", ".", "a", "remport\u00e9", "le", "prix", "AAAI", "Classic", "Paper", "de", "2016.2014", "."], "sentence-detokenized": "Depuis Bonn, il a apport\u00e9 une contribution fondamentale \u00e0 l'intelligence artificielle et \u00e0 la robotique (avec Wolfram Burgard, Dieter Fox, Sebastian Thrun parmi ses \u00e9tudiants), ainsi qu'au d\u00e9veloppement du g\u00e9nie logiciel, en particulier dans le domaine du g\u00e9nie civil, et des syst\u00e8mes d'information, en particulier dans le domaine des g\u00e9osciences. a remport\u00e9 le prix AAAI Classic Paper de 2016.2014.", "token2charspan": [[0, 6], [7, 11], [11, 12], [13, 15], [16, 17], [18, 25], [26, 29], [30, 42], [43, 55], [56, 57], [58, 60], [60, 72], [73, 85], [86, 88], [89, 90], [91, 93], [94, 103], [104, 105], [105, 109], [110, 117], [118, 125], [125, 126], [127, 133], [134, 137], [137, 138], [139, 148], [149, 154], [155, 160], [161, 164], [165, 174], [174, 175], [175, 176], [177, 182], [183, 186], [186, 188], [189, 202], [203, 205], [206, 211], [212, 220], [220, 221], [222, 224], [225, 236], [237, 241], [242, 244], [245, 252], [253, 255], [256, 261], [262, 267], [267, 268], [269, 271], [272, 275], [276, 284], [285, 287], [287, 298], [298, 299], [300, 302], [303, 314], [315, 319], [320, 322], [323, 330], [331, 334], [335, 346], [346, 347], [348, 349], [350, 358], [359, 361], [362, 366], [367, 371], [372, 379], [380, 385], [386, 388], [389, 398], [398, 399]]}
{"doc_key": "ai-test-238", "ner": [[2, 8, "conference"], [16, 17, "location"], [19, 19, "location"], [23, 23, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 8, 16, 17, "physical", "", false, false], [16, 17, 19, 19, "physical", "", false, false], [19, 19, 23, 23, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "premi\u00e8re", "\u00e9dition", "am\u00e9ricaine", "de", "la", "Campus", "Party", "aura", "lieu", "du", "20", "au", "22", "ao\u00fbt", "au", "TCF", "Center", "de", "D\u00e9troit", ",", "dans", "le", "Michigan", "."], "sentence-detokenized": "La premi\u00e8re \u00e9dition am\u00e9ricaine de la Campus Party aura lieu du 20 au 22 ao\u00fbt au TCF Center de D\u00e9troit, dans le Michigan.", "token2charspan": [[0, 2], [3, 11], [12, 19], [20, 30], [31, 33], [34, 36], [37, 43], [44, 49], [50, 54], [55, 59], [60, 62], [63, 65], [66, 68], [69, 71], [72, 76], [77, 79], [80, 83], [84, 90], [91, 93], [94, 101], [101, 102], [103, 107], [108, 110], [111, 119], [119, 120]]}
{"doc_key": "ai-test-239", "ner": [[1, 2, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [12, 13, "misc"], [25, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 12, 13, "win-defeat", "", false, false], [5, 6, 12, 13, "win-defeat", "", false, false], [8, 8, 12, 13, "win-defeat", "", false, false], [12, 13, 25, 27, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Avec", "Yann", "LeCun", ",", "et", "Yoshua", "Bengio", ",", "Hinton", "a", "remport\u00e9", "le", "prix", "Turing", "2018", "pour", "les", "perc\u00e9es", "conceptuelles", "et", "techniques", "qui", "ont", "fait", "des", "r\u00e9seaux", "neuronaux", "profonds", "une", "composante", "essentielle", "de", "l'", "informatique", "."], "sentence-detokenized": "Avec Yann LeCun, et Yoshua Bengio, Hinton a remport\u00e9 le prix Turing 2018 pour les perc\u00e9es conceptuelles et techniques qui ont fait des r\u00e9seaux neuronaux profonds une composante essentielle de l'informatique.", "token2charspan": [[0, 4], [5, 9], [10, 15], [15, 16], [17, 19], [20, 26], [27, 33], [33, 34], [35, 41], [42, 43], [44, 52], [53, 55], [56, 60], [61, 67], [68, 72], [73, 77], [78, 81], [82, 89], [90, 103], [104, 106], [107, 117], [118, 121], [122, 125], [126, 130], [131, 134], [135, 142], [143, 152], [153, 161], [162, 165], [166, 176], [177, 188], [189, 191], [192, 194], [194, 206], [206, 207]]}
{"doc_key": "ai-test-240", "ner": [[0, 2, "product"], [11, 11, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 11, 11, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Euler", "Math", "Toolbox", "utilise", "un", "langage", "matriciel", "similaire", "\u00e0", "celui", "de", "MATLAB", ",", "un", "syst\u00e8me", "qui", "\u00e9tait", "en", "cours", "de", "d\u00e9veloppement", "depuis", "les", "ann\u00e9es", "1970", "."], "sentence-detokenized": "Euler Math Toolbox utilise un langage matriciel similaire \u00e0 celui de MATLAB, un syst\u00e8me qui \u00e9tait en cours de d\u00e9veloppement depuis les ann\u00e9es 1970.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 26], [27, 29], [30, 37], [38, 47], [48, 57], [58, 59], [60, 65], [66, 68], [69, 75], [75, 76], [77, 79], [80, 87], [88, 91], [92, 97], [98, 100], [101, 106], [107, 109], [110, 123], [124, 130], [131, 134], [135, 141], [142, 146], [146, 147]]}
{"doc_key": "ai-test-241", "ner": [[10, 10, "programlang"], [12, 13, "programlang"], [15, 15, "programlang"], [17, 17, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Certains", "langages", "le", "permettent", "de", "mani\u00e8re", "portative", "(", "par", "exemple", "Scheme", ",", "Common", "Lisp", ",", "Perl", "ou", "D", ")", "."], "sentence-detokenized": "Certains langages le permettent de mani\u00e8re portative (par exemple Scheme, Common Lisp, Perl ou D).", "token2charspan": [[0, 8], [9, 17], [18, 20], [21, 31], [32, 34], [35, 42], [43, 52], [53, 54], [54, 57], [58, 65], [66, 72], [72, 73], [74, 80], [81, 85], [85, 86], [87, 91], [92, 94], [95, 96], [96, 97], [97, 98]]}
{"doc_key": "ai-test-242", "ner": [[7, 7, "misc"], [9, 10, "researcher"], [12, 14, "researcher"], [28, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 9, 10, "artifact", "", false, false], [7, 7, 12, 14, "artifact", "", false, false], [7, 7, 28, 29, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["En", "1969", ",", "un", "livre", "c\u00e9l\u00e8bre", "intitul\u00e9", "Perceptrons", "de", "Marvin", "Minsky", "et", "Seymour", "Papert", "a", "montr\u00e9", "qu'", "il", "\u00e9tait", "impossible", "pour", "ces", "classes", "de", "r\u00e9seaux", "d'", "apprendre", "une", "fonction", "XOR", "."], "sentence-detokenized": "En 1969, un livre c\u00e9l\u00e8bre intitul\u00e9 Perceptrons de Marvin Minsky et Seymour Papert a montr\u00e9 qu'il \u00e9tait impossible pour ces classes de r\u00e9seaux d'apprendre une fonction XOR.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 17], [18, 25], [26, 34], [35, 46], [47, 49], [50, 56], [57, 63], [64, 66], [67, 74], [75, 81], [82, 83], [84, 90], [91, 94], [94, 96], [97, 102], [103, 113], [114, 118], [119, 122], [123, 130], [131, 133], [134, 141], [142, 144], [144, 153], [154, 157], [158, 166], [167, 170], [170, 171]]}
{"doc_key": "ai-test-243", "ner": [[4, 8, "misc"], [16, 18, "product"], [22, 28, "organisation"], [33, 38, "organisation"], [42, 45, "location"], [49, 49, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[22, 28, 16, 18, "usage", "", false, false], [22, 28, 42, 45, "physical", "", false, false], [33, 38, 22, 28, "named", "", false, false], [42, 45, 49, 49, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Un", "grand", "nombre", "de", "documents", "scientifiques", "et", "techniques", "russes", "ont", "\u00e9t\u00e9", "traduits", "\u00e0", "l'", "aide", "de", "SYSTRAN", "sous", "les", "auspices", "de", "la", "division", "des", "technologies", "\u00e9trang\u00e8res", "de", "l'", "USAF", "(", "plus", "tard", "le", "National", "Air", "and", "Space", "Intelligence", "Center", ")", "\u00e0", "la", "base", "a\u00e9rienne", "de", "Wright-Patterson", ",", "dans", "l'", "Ohio", "."], "sentence-detokenized": "Un grand nombre de documents scientifiques et techniques russes ont \u00e9t\u00e9 traduits \u00e0 l'aide de SYSTRAN sous les auspices de la division des technologies \u00e9trang\u00e8res de l'USAF (plus tard le National Air and Space Intelligence Center) \u00e0 la base a\u00e9rienne de Wright-Patterson, dans l'Ohio.", "token2charspan": [[0, 2], [3, 8], [9, 15], [16, 18], [19, 28], [29, 42], [43, 45], [46, 56], [57, 63], [64, 67], [68, 71], [72, 80], [81, 82], [83, 85], [85, 89], [90, 92], [93, 100], [101, 105], [106, 109], [110, 118], [119, 121], [122, 124], [125, 133], [134, 137], [138, 150], [151, 161], [162, 164], [165, 167], [167, 171], [172, 173], [173, 177], [178, 182], [183, 185], [186, 194], [195, 198], [199, 202], [203, 208], [209, 221], [222, 228], [228, 229], [230, 231], [232, 234], [235, 239], [240, 248], [249, 251], [252, 268], [268, 269], [270, 274], [275, 277], [277, 281], [281, 282]]}
{"doc_key": "ai-test-244", "ner": [[0, 2, "field"], [7, 9, "field"], [20, 21, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["L'", "apprentissage", "semi-supervis\u00e9", "se", "situe", "entre", "l'", "apprentissage", "non", "supervis\u00e9", "(", "sans", "aucune", "donn\u00e9e", "d'", "entra\u00eenement", "\u00e9tiquet\u00e9e", ")", "et", "l'", "apprentissage", "supervis\u00e9", "(", "avec", "des", "donn\u00e9es", "d'", "entra\u00eenement", "compl\u00e8tement", "\u00e9tiquet\u00e9es", ")", "."], "sentence-detokenized": "L'apprentissage semi-supervis\u00e9 se situe entre l'apprentissage non supervis\u00e9 (sans aucune donn\u00e9e d'entra\u00eenement \u00e9tiquet\u00e9e) et l'apprentissage supervis\u00e9 (avec des donn\u00e9es d'entra\u00eenement compl\u00e8tement \u00e9tiquet\u00e9es).", "token2charspan": [[0, 2], [2, 15], [16, 30], [31, 33], [34, 39], [40, 45], [46, 48], [48, 61], [62, 65], [66, 75], [76, 77], [77, 81], [82, 88], [89, 95], [96, 98], [98, 110], [111, 120], [120, 121], [122, 124], [125, 127], [127, 140], [141, 150], [151, 152], [152, 156], [157, 160], [161, 168], [169, 171], [171, 183], [184, 196], [197, 207], [207, 208], [208, 209]]}
{"doc_key": "ai-test-245", "ner": [[0, 3, "algorithm"], [8, 11, "algorithm"], [27, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 8, 11, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Le", "mod\u00e8le", "Ann", "-gram", "est", "un", "type", "de", "mod\u00e8le", "de", "langage", "probabiliste", "permettant", "de", "pr\u00e9dire", "l'", "\u00e9l\u00e9ment", "suivant", "d'", "une", "telle", "s\u00e9quence", "sous", "la", "forme", "d'", "un", "mod\u00e8le", "de", "Markov", "d'", "ordre", "(", "n", "-", "1", ")", "de", "mani\u00e8re", "efficace", "."], "sentence-detokenized": "Le mod\u00e8le Ann -gram est un type de mod\u00e8le de langage probabiliste permettant de pr\u00e9dire l'\u00e9l\u00e9ment suivant d'une telle s\u00e9quence sous la forme d'un mod\u00e8le de Markov d'ordre (n - 1) de mani\u00e8re efficace.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 19], [20, 23], [24, 26], [27, 31], [32, 34], [35, 41], [42, 44], [45, 52], [53, 65], [66, 76], [77, 79], [80, 87], [88, 90], [90, 97], [98, 105], [106, 108], [108, 111], [112, 117], [118, 126], [127, 131], [132, 134], [135, 140], [141, 143], [143, 145], [146, 152], [153, 155], [156, 162], [163, 165], [165, 170], [171, 172], [172, 173], [174, 175], [176, 177], [177, 178], [179, 181], [182, 189], [190, 198], [198, 199]]}
{"doc_key": "ai-test-246", "ner": [[1, 2, "organisation"], [5, 5, "product"], [9, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 5, 5, "usage", "", false, false], [9, 17, 1, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "Cleveland", "Clinic", "a", "utilis\u00e9", "Cyc", "pour", "d\u00e9velopper", "une", "interface", "de", "requ\u00eate", "en", "langage", "naturel", "d'", "informations", "biom\u00e9dicales", ",", "couvrant", "des", "d\u00e9cennies", "d'", "informations", "sur", "les", "chirurgies", "cardiothoraciques", "."], "sentence-detokenized": "La Cleveland Clinic a utilis\u00e9 Cyc pour d\u00e9velopper une interface de requ\u00eate en langage naturel d'informations biom\u00e9dicales, couvrant des d\u00e9cennies d'informations sur les chirurgies cardiothoraciques.", "token2charspan": [[0, 2], [3, 12], [13, 19], [20, 21], [22, 29], [30, 33], [34, 38], [39, 49], [50, 53], [54, 63], [64, 66], [67, 74], [75, 77], [78, 85], [86, 93], [94, 96], [96, 108], [109, 121], [121, 122], [123, 131], [132, 135], [136, 145], [146, 148], [148, 160], [161, 164], [165, 168], [169, 179], [180, 197], [197, 198]]}
{"doc_key": "ai-test-247", "ner": [[8, 8, "country"], [11, 11, "country"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 8, 11, 11, "opposite", "strained_relations", false, false]], "relations_mapping_to_source": [0], "sentence": ["L'", "incident", "a", "tendu", "les", "relations", "entre", "les", "\u00c9tats-Unis", "et", "le", "Japon", ",", "et", "a", "entra\u00een\u00e9", "l'", "arrestation", "et", "la", "poursuite", "en", "justice", "de", "deux", "cadres", "sup\u00e9rieurs", ",", "ainsi", "que", "l'", "imposition", "de", "sanctions", "\u00e0", "la", "soci\u00e9t\u00e9", "par", "les", "deux", "pays", "."], "sentence-detokenized": "L'incident a tendu les relations entre les \u00c9tats-Unis et le Japon, et a entra\u00een\u00e9 l'arrestation et la poursuite en justice de deux cadres sup\u00e9rieurs, ainsi que l'imposition de sanctions \u00e0 la soci\u00e9t\u00e9 par les deux pays.", "token2charspan": [[0, 2], [2, 10], [11, 12], [13, 18], [19, 22], [23, 32], [33, 38], [39, 42], [43, 53], [54, 56], [57, 59], [60, 65], [65, 66], [67, 69], [70, 71], [72, 80], [81, 83], [83, 94], [95, 97], [98, 100], [101, 110], [111, 113], [114, 121], [122, 124], [125, 129], [130, 136], [137, 147], [147, 148], [149, 154], [155, 158], [159, 161], [161, 171], [172, 174], [175, 184], [185, 186], [187, 189], [190, 197], [198, 201], [202, 205], [206, 210], [211, 215], [215, 216]]}
{"doc_key": "ai-test-248", "ner": [[7, 9, "algorithm"], [15, 16, "field"], [24, 24, "misc"], [36, 36, "misc"], [41, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 9, 15, 16, "type-of", "", false, false], [24, 24, 15, 16, "part-of", "", true, false], [36, 36, 15, 16, "part-of", "", true, false], [41, 42, 15, 16, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Si", "la", "mod\u00e9lisation", "est", "effectu\u00e9e", "par", "un", "r\u00e9seau", "neuronal", "artificiel", "ou", "un", "autre", "type", "d'", "apprentissage", "automatique", ",", "l'", "optimisation", "des", "param\u00e8tres", "est", "appel\u00e9e", "formation", ",", "tandis", "que", "l'", "optimisation", "des", "hyperparam\u00e8tres", "du", "mod\u00e8le", "est", "appel\u00e9e", "r\u00e9glage", "et", "utilise", "souvent", "la", "validation", "crois\u00e9e", "."], "sentence-detokenized": "Si la mod\u00e9lisation est effectu\u00e9e par un r\u00e9seau neuronal artificiel ou un autre type d'apprentissage automatique, l'optimisation des param\u00e8tres est appel\u00e9e formation, tandis que l'optimisation des hyperparam\u00e8tres du mod\u00e8le est appel\u00e9e r\u00e9glage et utilise souvent la validation crois\u00e9e .", "token2charspan": [[0, 2], [3, 5], [6, 18], [19, 22], [23, 32], [33, 36], [37, 39], [40, 46], [47, 55], [56, 66], [67, 69], [70, 72], [73, 78], [79, 83], [84, 86], [86, 99], [100, 111], [111, 112], [113, 115], [115, 127], [128, 131], [132, 142], [143, 146], [147, 154], [155, 164], [164, 165], [166, 172], [173, 176], [177, 179], [179, 191], [192, 195], [196, 211], [212, 214], [215, 221], [222, 225], [226, 233], [234, 241], [242, 244], [245, 252], [253, 260], [261, 263], [264, 274], [275, 282], [283, 284]]}
{"doc_key": "ai-test-249", "ner": [[7, 7, "country"], [10, 10, "country"], [13, 13, "country"], [21, 22, "organisation"], [24, 24, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[21, 22, 24, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Les", "versions", "localis\u00e9es", "du", "site", "disponibles", "au", "Royaume-Uni", ",", "en", "Inde", "et", "en", "Australie", "ont", "\u00e9t\u00e9", "abandonn\u00e9es", "apr\u00e8s", "l'", "acquisition", "de", "Rotten", "Tomatoes", "par", "Fandango", "."], "sentence-detokenized": "Les versions localis\u00e9es du site disponibles au Royaume-Uni, en Inde et en Australie ont \u00e9t\u00e9 abandonn\u00e9es apr\u00e8s l'acquisition de Rotten Tomatoes par Fandango.", "token2charspan": [[0, 3], [4, 12], [13, 23], [24, 26], [27, 31], [32, 43], [44, 46], [47, 58], [58, 59], [60, 62], [63, 67], [68, 70], [71, 73], [74, 83], [84, 87], [88, 91], [92, 103], [104, 109], [110, 112], [112, 123], [124, 126], [127, 133], [134, 142], [143, 146], [147, 155], [155, 156]]}
{"doc_key": "ai-test-250", "ner": [[2, 2, "task"], [13, 13, "metrics"], [30, 31, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 13, 13, "related-to", "", false, false], [13, 13, 30, 31, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Le", "mod\u00e8le", "NER", "est", "l'", "une", "des", "nombreuses", "m\u00e9thodes", "permettant", "de", "d\u00e9terminer", "la", "pr\u00e9cision", "des", "sous-titres", "en", "direct", "des", "\u00e9missions", "t\u00e9l\u00e9vis\u00e9es", "et", "des", "\u00e9v\u00e9nements", "produits", "\u00e0", "l'", "aide", "de", "la", "reconnaissance", "vocale", "."], "sentence-detokenized": "Le mod\u00e8le NER est l'une des nombreuses m\u00e9thodes permettant de d\u00e9terminer la pr\u00e9cision des sous-titres en direct des \u00e9missions t\u00e9l\u00e9vis\u00e9es et des \u00e9v\u00e9nements produits \u00e0 l'aide de la reconnaissance vocale.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 17], [18, 20], [20, 23], [24, 27], [28, 38], [39, 47], [48, 58], [59, 61], [62, 72], [73, 75], [76, 85], [86, 89], [90, 101], [102, 104], [105, 111], [112, 115], [116, 125], [126, 136], [137, 139], [140, 143], [144, 154], [155, 163], [164, 165], [166, 168], [168, 172], [173, 175], [176, 178], [179, 193], [194, 200], [200, 201]]}
{"doc_key": "ai-test-251", "ner": [[0, 1, "researcher"], [6, 8, "university"], [12, 13, "university"], [15, 15, "location"], [19, 23, "university"], [27, 28, "university"], [30, 30, "location"], [35, 40, "university"], [42, 43, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 1, 6, 8, "physical", "", false, false], [0, 1, 6, 8, "role", "", false, false], [0, 1, 12, 13, "physical", "", false, false], [0, 1, 12, 13, "role", "", false, false], [0, 1, 19, 23, "physical", "", false, false], [0, 1, 19, 23, "role", "", false, false], [0, 1, 27, 28, "physical", "", false, false], [0, 1, 27, 28, "role", "", false, false], [0, 1, 35, 40, "physical", "", false, false], [0, 1, 35, 40, "role", "", false, false], [12, 13, 15, 15, "physical", "", false, false], [19, 23, 30, 30, "physical", "", false, false], [27, 28, 30, 30, "physical", "", false, false], [35, 40, 42, 43, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["M.", "Atran", "a", "enseign\u00e9", "\u00e0", "l'", "universit\u00e9", "de", "Cambridge", ",", "\u00e0", "l'", "universit\u00e9", "h\u00e9bra\u00efque", "de", "J\u00e9rusalem", ",", "\u00e0", "l'", "\u00c9cole", "pratique", "des", "hautes", "\u00e9tudes", "et", "\u00e0", "l'", "\u00c9cole", "polytechnique", "de", "Paris", ",", "ainsi", "qu'", "au", "John", "Jay", "College", "of", "Criminal", "Justice", "de", "New", "York", "."], "sentence-detokenized": "M. Atran a enseign\u00e9 \u00e0 l'universit\u00e9 de Cambridge, \u00e0 l'universit\u00e9 h\u00e9bra\u00efque de J\u00e9rusalem, \u00e0 l'\u00c9cole pratique des hautes \u00e9tudes et \u00e0 l'\u00c9cole polytechnique de Paris, ainsi qu'au John Jay College of Criminal Justice de New York.", "token2charspan": [[0, 2], [3, 8], [9, 10], [11, 19], [20, 21], [22, 24], [24, 34], [35, 37], [38, 47], [47, 48], [49, 50], [51, 53], [53, 63], [64, 73], [74, 76], [77, 86], [86, 87], [88, 89], [90, 92], [92, 97], [98, 106], [107, 110], [111, 117], [118, 124], [125, 127], [128, 129], [130, 132], [132, 137], [138, 151], [152, 154], [155, 160], [160, 161], [162, 167], [168, 171], [171, 173], [174, 178], [179, 182], [183, 190], [191, 193], [194, 202], [203, 210], [211, 213], [214, 217], [218, 222], [222, 223]]}
{"doc_key": "ai-test-252", "ner": [[0, 2, "product"], [8, 11, "task"], [15, 16, "researcher"], [18, 18, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 8, 11, "origin", "", false, false], [0, 2, 8, 11, "related-to", "", false, false], [8, 11, 18, 18, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["SHRDLU", "\u00e9tait", "un", "des", "premiers", "programmes", "informatiques", "de", "compr\u00e9hension", "du", "langage", "naturel", ",", "d\u00e9velopp\u00e9", "par", "Terry", "Winograd", "au", "MIT", "en", "1968-1970", "."], "sentence-detokenized": "SHRDLU \u00e9tait un des premiers programmes informatiques de compr\u00e9hension du langage naturel, d\u00e9velopp\u00e9 par Terry Winograd au MIT en 1968-1970.", "token2charspan": [[0, 6], [7, 12], [13, 15], [16, 19], [20, 28], [29, 39], [40, 53], [54, 56], [57, 70], [71, 73], [74, 81], [82, 89], [89, 90], [91, 100], [101, 104], [105, 110], [111, 119], [120, 122], [123, 126], [127, 129], [130, 139], [139, 140]]}
{"doc_key": "ai-test-253", "ner": [[4, 4, "misc"], [6, 7, "field"], [9, 12, "university"], [14, 14, "location"], [17, 17, "country"], [29, 31, "university"], [34, 34, "misc"], [36, 39, "field"], [44, 46, "university"], [50, 50, "misc"], [52, 52, "field"], [58, 59, "misc"], [66, 68, "university"], [75, 76, "field"], [80, 81, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "relations": [[4, 4, 6, 7, "topic", "", false, false], [4, 4, 9, 12, "origin", "", false, false], [9, 12, 14, 14, "physical", "", false, false], [9, 12, 29, 31, "role", "affiliated_with", false, false], [14, 14, 17, 17, "physical", "", false, false], [34, 34, 36, 39, "topic", "", false, false], [34, 34, 44, 46, "origin", "", false, false], [50, 50, 52, 52, "topic", "", false, false], [58, 59, 66, 68, "origin", "", false, false], [58, 59, 75, 76, "topic", "", false, false], [80, 81, 66, 68, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Il", "a", "obtenu", "un", "B.E.", "en", "g\u00e9nie", "\u00e9lectronique", "au", "B.M.S.", "College", "of", "Engineering", "de", "Bangalore", ",", "en", "Inde", ",", "en", "1982", ",", "alors", "qu'", "il", "\u00e9tait", "affili\u00e9", "\u00e0", "l'", "universit\u00e9", "de", "Bangalore", ",", "un", "M.S.", "en", "g\u00e9nie", "\u00e9lectrique", "et", "informatique", "en", "1984", "\u00e0", "l'", "universit\u00e9", "de", "Drexel", ",", "et", "un", "M.S.", "en", "informatique", "en", "1989", ",", "et", "un", "doctorat", "en", "1990", ",", "respectivement", ",", "\u00e0", "l'", "universit\u00e9", "du", "Wisconsin-Madison", ",", "o\u00f9", "il", "a", "\u00e9tudi\u00e9", "l'", "intelligence", "artificielle", "et", "travaill\u00e9", "avec", "Leonard", "Uhr", "."], "sentence-detokenized": "Il a obtenu un B.E. en g\u00e9nie \u00e9lectronique au B.M.S. College of Engineering de Bangalore, en Inde, en 1982, alors qu'il \u00e9tait affili\u00e9 \u00e0 l'universit\u00e9 de Bangalore, un M.S. en g\u00e9nie \u00e9lectrique et informatique en 1984 \u00e0 l'universit\u00e9 de Drexel, et un M.S. en informatique en 1989, et un doctorat en 1990, respectivement, \u00e0 l'universit\u00e9 du Wisconsin-Madison, o\u00f9 il a \u00e9tudi\u00e9 l'intelligence artificielle et travaill\u00e9 avec Leonard Uhr.", "token2charspan": [[0, 2], [3, 4], [5, 11], [12, 14], [15, 19], [20, 22], [23, 28], [29, 41], [42, 44], [45, 51], [52, 59], [60, 62], [63, 74], [75, 77], [78, 87], [87, 88], [89, 91], [92, 96], [96, 97], [98, 100], [101, 105], [105, 106], [107, 112], [113, 116], [116, 118], [119, 124], [125, 132], [133, 134], [135, 137], [137, 147], [148, 150], [151, 160], [160, 161], [162, 164], [165, 169], [170, 172], [173, 178], [179, 189], [190, 192], [193, 205], [206, 208], [209, 213], [214, 215], [216, 218], [218, 228], [229, 231], [232, 238], [238, 239], [240, 242], [243, 245], [246, 250], [251, 253], [254, 266], [267, 269], [270, 274], [274, 275], [276, 278], [279, 281], [282, 290], [291, 293], [294, 298], [298, 299], [300, 314], [314, 315], [316, 317], [318, 320], [320, 330], [331, 333], [334, 351], [351, 352], [353, 355], [356, 358], [359, 360], [361, 367], [368, 370], [370, 382], [383, 395], [396, 398], [399, 408], [409, 413], [414, 421], [422, 425], [425, 426]]}
{"doc_key": "ai-test-254", "ner": [[8, 12, "metrics"], [14, 14, "metrics"], [26, 28, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 8, 12, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["La", "pr\u00e9cision", "est", "g\u00e9n\u00e9ralement", "\u00e9valu\u00e9e", "en", "fonction", "du", "taux", "d'", "erreur", "de", "mot", "(", "WER", ")", ",", "tandis", "que", "la", "vitesse", "est", "mesur\u00e9e", "en", "fonction", "du", "facteur", "temps", "r\u00e9el", "."], "sentence-detokenized": "La pr\u00e9cision est g\u00e9n\u00e9ralement \u00e9valu\u00e9e en fonction du taux d'erreur de mot (WER), tandis que la vitesse est mesur\u00e9e en fonction du facteur temps r\u00e9el.", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 29], [30, 37], [38, 40], [41, 49], [50, 52], [53, 57], [58, 60], [60, 66], [67, 69], [70, 73], [74, 75], [75, 78], [78, 79], [79, 80], [81, 87], [88, 91], [92, 94], [95, 102], [103, 106], [107, 114], [115, 117], [118, 126], [127, 129], [130, 137], [138, 143], [144, 148], [148, 149]]}
{"doc_key": "ai-test-255", "ner": [[3, 5, "researcher"], [11, 14, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 5, 11, 14, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["En", "1971", ",", "Terry", "Winograd", "a", "d\u00e9velopp\u00e9", "un", "premier", "moteur", "de", "traitement", "du", "langage", "naturel", "capable", "d'", "interpr\u00e9ter", "des", "commandes", "\u00e9crites", "naturellement", "dans", "un", "environnement", "simple", "r\u00e9gi", "par", "des", "r\u00e8gles", "."], "sentence-detokenized": "En 1971, Terry Winograd a d\u00e9velopp\u00e9 un premier moteur de traitement du langage naturel capable d'interpr\u00e9ter des commandes \u00e9crites naturellement dans un environnement simple r\u00e9gi par des r\u00e8gles.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 25], [26, 35], [36, 38], [39, 46], [47, 53], [54, 56], [57, 67], [68, 70], [71, 78], [79, 86], [87, 94], [95, 97], [97, 108], [109, 112], [113, 122], [123, 130], [131, 144], [145, 149], [150, 152], [153, 166], [167, 173], [174, 178], [179, 182], [183, 186], [187, 193], [193, 194]]}
{"doc_key": "ai-test-256", "ner": [[5, 6, "field"], [8, 9, "researcher"], [11, 13, "researcher"], [15, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 8, 9, "related-to", "", false, false], [5, 6, 11, 13, "related-to", "", false, false], [5, 6, 15, 18, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dans", "le", "domaine", "de", "l'", "intelligence", "artificielle", ",", "Marvin", "Minsky", ",", "Herbert", "A.", "Simon", "et", "Allen", "Newell", "occupent", "une", "place", "importante", "."], "sentence-detokenized": "Dans le domaine de l'intelligence artificielle, Marvin Minsky, Herbert A. Simon et Allen Newell occupent une place importante.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 21], [21, 33], [34, 46], [46, 47], [48, 54], [55, 61], [61, 62], [63, 70], [71, 73], [74, 79], [80, 82], [83, 88], [89, 95], [96, 104], [105, 108], [109, 114], [115, 125], [125, 126]]}
{"doc_key": "ai-test-257", "ner": [[9, 10, "field"], [35, 36, "field"], [39, 40, "field"], [49, 52, "field"], [63, 64, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[35, 36, 9, 10, "origin", "", true, false], [35, 36, 9, 10, "part-of", "", false, false], [35, 36, 49, 52, "compare", "", false, false], [39, 40, 9, 10, "origin", "", true, false], [39, 40, 9, 10, "part-of", "", false, false], [39, 40, 49, 52, "compare", "", false, false], [49, 52, 9, 10, "origin", "", true, false], [49, 52, 9, 10, "part-of", "", false, false], [49, 52, 63, 64, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Dans", "la", "seconde", "moiti\u00e9", "du", "20e", "si\u00e8cle", ",", "le", "g\u00e9nie", "\u00e9lectrique", "lui-m\u00eame", "s'", "est", "s\u00e9par\u00e9", "en", "plusieurs", "disciplines", ",", "sp\u00e9cialis\u00e9es", "dans", "la", "conception", "et", "l'", "analyse", "de", "syst\u00e8mes", "qui", "manipulent", "des", "signaux", "physiques", ";", "le", "g\u00e9nie", "\u00e9lectronique", "et", "le", "g\u00e9nie", "informatique", "en", "sont", "des", "exemples", ";", "tandis", "que", "le", "g\u00e9nie", "de", "la", "conception", "s'", "est", "d\u00e9velopp\u00e9", "pour", "traiter", "de", "la", "conception", "fonctionnelle", "des", "interfaces", "utilisateur-machine", "."], "sentence-detokenized": "Dans la seconde moiti\u00e9 du 20e si\u00e8cle, le g\u00e9nie \u00e9lectrique lui-m\u00eame s'est s\u00e9par\u00e9 en plusieurs disciplines, sp\u00e9cialis\u00e9es dans la conception et l'analyse de syst\u00e8mes qui manipulent des signaux physiques ; le g\u00e9nie \u00e9lectronique et le g\u00e9nie informatique en sont des exemples ; tandis que le g\u00e9nie de la conception s'est d\u00e9velopp\u00e9 pour traiter de la conception fonctionnelle des interfaces utilisateur-machine.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 22], [23, 25], [26, 29], [30, 36], [36, 37], [38, 40], [41, 46], [47, 57], [58, 66], [67, 69], [69, 72], [73, 79], [80, 82], [83, 92], [93, 104], [104, 105], [106, 118], [119, 123], [124, 126], [127, 137], [138, 140], [141, 143], [143, 150], [151, 153], [154, 162], [163, 166], [167, 177], [178, 181], [182, 189], [190, 199], [200, 201], [202, 204], [205, 210], [211, 223], [224, 226], [227, 229], [230, 235], [236, 248], [249, 251], [252, 256], [257, 260], [261, 269], [270, 271], [272, 278], [279, 282], [283, 285], [286, 291], [292, 294], [295, 297], [298, 308], [309, 311], [311, 314], [315, 324], [325, 329], [330, 337], [338, 340], [341, 343], [344, 354], [355, 368], [369, 372], [373, 383], [384, 403], [403, 404]]}
{"doc_key": "ai-test-258", "ner": [[8, 8, "metrics"], [10, 11, "metrics"], [13, 13, "metrics"], [50, 52, "metrics"], [59, 61, "metrics"], [65, 71, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 13, 10, 11, "named", "", false, false], [50, 52, 59, 61, "named", "", false, false], [59, 61, 65, 71, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "statistique", "la", "plus", "simple", "est", "peut-\u00eatre", "la", "pr\u00e9cision", "ou", "Fraction", "Correcte", "(", "FC", ")", ",", "qui", "mesure", "la", "fraction", "de", "toutes", "les", "instances", "qui", "sont", "correctement", "cat\u00e9goris\u00e9es", ";", "c'", "est", "le", "rapport", "entre", "le", "nombre", "de", "classifications", "correctes", "et", "le", "nombre", "total", "de", "classifications", "correctes", "ou", "incorrectes", ":", "(", "TP", "+", "TN", ")", "/", "Population", "totale", "=", "(", "TP", "+", "TN", ")", "/", "(", "TP", "+", "TN", "+", "FP", "+", "FN", ")", "."], "sentence-detokenized": "La statistique la plus simple est peut-\u00eatre la pr\u00e9cision ou Fraction Correcte (FC), qui mesure la fraction de toutes les instances qui sont correctement cat\u00e9goris\u00e9es ; c'est le rapport entre le nombre de classifications correctes et le nombre total de classifications correctes ou incorrectes : (TP + TN) / Population totale = (TP + TN) / (TP + TN + FP + FN).", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 22], [23, 29], [30, 33], [34, 43], [44, 46], [47, 56], [57, 59], [60, 68], [69, 77], [78, 79], [79, 81], [81, 82], [82, 83], [84, 87], [88, 94], [95, 97], [98, 106], [107, 109], [110, 116], [117, 120], [121, 130], [131, 134], [135, 139], [140, 152], [153, 165], [166, 167], [168, 170], [170, 173], [174, 176], [177, 184], [185, 190], [191, 193], [194, 200], [201, 203], [204, 219], [220, 229], [230, 232], [233, 235], [236, 242], [243, 248], [249, 251], [252, 267], [268, 277], [278, 280], [281, 292], [293, 294], [295, 296], [296, 298], [299, 300], [301, 303], [303, 304], [305, 306], [307, 317], [318, 324], [325, 326], [327, 328], [328, 330], [331, 332], [333, 335], [335, 336], [337, 338], [339, 340], [340, 342], [343, 344], [345, 347], [348, 349], [350, 352], [353, 354], [355, 357], [357, 358], [358, 359]]}
{"doc_key": "ai-test-259", "ner": [[17, 29, "conference"], [31, 31, "conference"], [37, 37, "location"], [43, 43, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[17, 29, 37, 37, "physical", "", false, false], [31, 31, 17, 29, "named", "", false, false], [43, 43, 17, 29, "role", "sponsors", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dans", "la", "communaut\u00e9", "universitaire", ",", "les", "principaux", "forums", "de", "recherche", "ont", "commenc\u00e9", "en", "1995", ",", "lorsque", "la", "premi\u00e8re", "conf\u00e9rence", "internationale", "sur", "l'", "extraction", "de", "donn\u00e9es", "et", "la", "d\u00e9couverte", "de", "connaissances", "(", "KDD-95", ")", "a", "\u00e9t\u00e9", "lanc\u00e9e", "\u00e0", "Montr\u00e9al", "sous", "le", "parrainage", "de", "l'", "AAAI", "."], "sentence-detokenized": "Dans la communaut\u00e9 universitaire, les principaux forums de recherche ont commenc\u00e9 en 1995, lorsque la premi\u00e8re conf\u00e9rence internationale sur l'extraction de donn\u00e9es et la d\u00e9couverte de connaissances (KDD-95) a \u00e9t\u00e9 lanc\u00e9e \u00e0 Montr\u00e9al sous le parrainage de l'AAAI.", "token2charspan": [[0, 4], [5, 7], [8, 18], [19, 32], [32, 33], [34, 37], [38, 48], [49, 55], [56, 58], [59, 68], [69, 72], [73, 81], [82, 84], [85, 89], [89, 90], [91, 98], [99, 101], [102, 110], [111, 121], [122, 136], [137, 140], [141, 143], [143, 153], [154, 156], [157, 164], [165, 167], [168, 170], [171, 181], [182, 184], [185, 198], [199, 200], [200, 206], [206, 207], [208, 209], [210, 213], [214, 220], [221, 222], [223, 231], [232, 236], [237, 239], [240, 250], [251, 253], [254, 256], [256, 260], [260, 261]]}
{"doc_key": "ai-test-260", "ner": [[15, 17, "field"], [20, 21, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Dans", "cette", "approche", ",", "des", "mod\u00e8les", "sont", "d\u00e9velopp\u00e9s", "\u00e0", "l'", "aide", "de", "diff\u00e9rents", "algorithmes", "d'", "exploration", "de", "donn\u00e9es", "et", "d'", "apprentissage", "automatique", "pour", "pr\u00e9dire", "l'", "\u00e9valuation", "par", "les", "utilisateurs", "d'", "articles", "non", "\u00e9valu\u00e9s", "."], "sentence-detokenized": "Dans cette approche, des mod\u00e8les sont d\u00e9velopp\u00e9s \u00e0 l'aide de diff\u00e9rents algorithmes d'exploration de donn\u00e9es et d'apprentissage automatique pour pr\u00e9dire l'\u00e9valuation par les utilisateurs d'articles non \u00e9valu\u00e9s.", "token2charspan": [[0, 4], [5, 10], [11, 19], [19, 20], [21, 24], [25, 32], [33, 37], [38, 48], [49, 50], [51, 53], [53, 57], [58, 60], [61, 71], [72, 83], [84, 86], [86, 97], [98, 100], [101, 108], [109, 111], [112, 114], [114, 127], [128, 139], [140, 144], [145, 152], [153, 155], [155, 165], [166, 169], [170, 173], [174, 186], [187, 189], [189, 197], [198, 201], [202, 209], [209, 210]]}
{"doc_key": "ai-test-261", "ner": [[13, 13, "algorithm"], [17, 18, "algorithm"], [20, 22, "algorithm"], [29, 31, "misc"], [34, 35, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 13, 17, 18, "related-to", "equivalent", false, false], [17, 18, 20, 22, "usage", "", false, false], [20, 22, 34, 35, "usage", "", false, false], [34, 35, 29, 31, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["\u00c0", "la", "lumi\u00e8re", "de", "la", "discussion", "ci-dessus", ",", "nous", "voyons", "que", "la", "technique", "SVM", "est", "\u00e9quivalente", "au", "risque", "empirique", "avec", "r\u00e9gularisation", "de", "Tikhonov", ",", "o\u00f9", "dans", "ce", "cas", "la", "fonction", "de", "perte", "est", "la", "perte", "charni\u00e8re"], "sentence-detokenized": "\u00c0 la lumi\u00e8re de la discussion ci-dessus, nous voyons que la technique SVM est \u00e9quivalente au risque empirique avec r\u00e9gularisation de Tikhonov, o\u00f9 dans ce cas la fonction de perte est la perte charni\u00e8re", "token2charspan": [[0, 1], [2, 4], [5, 12], [13, 15], [16, 18], [19, 29], [30, 39], [39, 40], [41, 45], [46, 52], [53, 56], [57, 59], [60, 69], [70, 73], [74, 77], [78, 89], [90, 92], [93, 99], [100, 109], [110, 114], [115, 129], [130, 132], [133, 141], [141, 142], [143, 145], [146, 150], [151, 153], [154, 157], [158, 160], [161, 169], [170, 172], [173, 178], [179, 182], [183, 185], [186, 191], [192, 201]]}
{"doc_key": "ai-test-262", "ner": [[6, 7, "person"], [10, 11, "person"], [17, 18, "organisation"], [19, 20, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[19, 20, 17, 18, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["L'", "\u00e9dition", "2015", "\u00e9tait", "anim\u00e9e", "par", "Molly", "McGrath", ",", "avec", "Chris", "Rose", "et", "l'", "ancien", "combattant", "de", "l'", "UFC", "Kenny", "Florian", "comme", "commentateurs", "."], "sentence-detokenized": "L'\u00e9dition 2015 \u00e9tait anim\u00e9e par Molly McGrath, avec Chris Rose et l'ancien combattant de l'UFC Kenny Florian comme commentateurs.", "token2charspan": [[0, 2], [2, 9], [10, 14], [15, 20], [21, 27], [28, 31], [32, 37], [38, 45], [45, 46], [47, 51], [52, 57], [58, 62], [63, 65], [66, 68], [68, 74], [75, 85], [86, 88], [89, 91], [91, 94], [95, 100], [101, 108], [109, 114], [115, 128], [128, 129]]}
{"doc_key": "ai-test-263", "ner": [[3, 3, "product"], [10, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"], [19, 19, "researcher"], [22, 22, "researcher"], [38, 38, "researcher"], [32, 35, "task"], [36, 36, "product"], [47, 48, "researcher"], [43, 46, "task"], [53, 54, "researcher"], [57, 58, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[3, 3, 10, 12, "origin", "", false, false], [3, 3, 14, 15, "origin", "", false, false], [3, 3, 17, 18, "origin", "", false, false], [3, 3, 19, 19, "origin", "", false, false], [14, 15, 47, 48, "named", "same", false, false], [17, 18, 22, 22, "named", "same", false, false], [17, 18, 38, 38, "named", "same", false, false], [32, 35, 36, 36, "related-to", "", false, false], [36, 36, 38, 38, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Un", "sous-ensemble", "appel\u00e9", "Micro-Planner", "a", "\u00e9t\u00e9", "mis", "en", "\u0153uvre", "par", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "et", "Terry", "Winograd", "Sussman", ",", "et", "Winograd", "1971", "et", "a", "\u00e9t\u00e9", "utilis\u00e9", "dans", "le", "programme", "de", "compr\u00e9hension", "du", "langage", "naturel", "SHRDLU", "de", "Winograd", ",", "le", "travail", "de", "compr\u00e9hension", "des", "histoires", "d'", "Eugene", "Charniak", ",", "le", "travail", "de", "Thorne", "McCarty", "sur", "le", "raisonnement", "juridique", ",", "et", "quelques", "autres", "projets", "."], "sentence-detokenized": "Un sous-ensemble appel\u00e9 Micro-Planner a \u00e9t\u00e9 mis en \u0153uvre par Gerald Jay Sussman, Eugene Charniak et Terry Winograd Sussman, et Winograd 1971 et a \u00e9t\u00e9 utilis\u00e9 dans le programme de compr\u00e9hension du langage naturel SHRDLU de Winograd, le travail de compr\u00e9hension des histoires d'Eugene Charniak, le travail de Thorne McCarty sur le raisonnement juridique, et quelques autres projets.", "token2charspan": [[0, 2], [3, 16], [17, 23], [24, 37], [38, 39], [40, 43], [44, 47], [48, 50], [51, 56], [57, 60], [61, 67], [68, 71], [72, 79], [79, 80], [81, 87], [88, 96], [97, 99], [100, 105], [106, 114], [115, 122], [122, 123], [124, 126], [127, 135], [136, 140], [141, 143], [144, 145], [146, 149], [150, 157], [158, 162], [163, 165], [166, 175], [176, 178], [179, 192], [193, 195], [196, 203], [204, 211], [212, 218], [219, 221], [222, 230], [230, 231], [232, 234], [235, 242], [243, 245], [246, 259], [260, 263], [264, 273], [274, 276], [276, 282], [283, 291], [291, 292], [293, 295], [296, 303], [304, 306], [307, 313], [314, 321], [322, 325], [326, 328], [329, 341], [342, 351], [351, 352], [353, 355], [356, 364], [365, 371], [372, 379], [379, 380]]}
{"doc_key": "ai-test-264", "ner": [[0, 0, "product"], [10, 12, "product"], [17, 21, "task"], [24, 26, "task"], [29, 32, "task"], [35, 36, "task"], [39, 40, "task"], [44, 48, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 12, 0, 0, "usage", "", true, false], [17, 21, 10, 12, "part-of", "", true, false], [24, 26, 10, 12, "part-of", "", true, false], [29, 32, 10, 12, "part-of", "", true, false], [35, 36, 10, 12, "part-of", "", true, false], [39, 40, 10, 12, "part-of", "", true, false], [44, 48, 10, 12, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["WordNet", "a", "\u00e9t\u00e9", "utilis\u00e9", "\u00e0", "de", "nombreuses", "fins", "dans", "les", "syst\u00e8mes", "d'", "information", ",", "notamment", "pour", "la", "d\u00e9sambigu\u00efsation", "des", "sens", "des", "mots", ",", "la", "recherche", "d'", "informations", ",", "la", "classification", "automatique", "de", "textes", ",", "le", "r\u00e9sum\u00e9", "automatique", ",", "la", "traduction", "automatique", "et", "m\u00eame", "la", "g\u00e9n\u00e9ration", "automatique", "de", "mots", "crois\u00e9s", "."], "sentence-detokenized": "WordNet a \u00e9t\u00e9 utilis\u00e9 \u00e0 de nombreuses fins dans les syst\u00e8mes d'information, notamment pour la d\u00e9sambigu\u00efsation des sens des mots, la recherche d'informations, la classification automatique de textes, le r\u00e9sum\u00e9 automatique, la traduction automatique et m\u00eame la g\u00e9n\u00e9ration automatique de mots crois\u00e9s.", "token2charspan": [[0, 7], [8, 9], [10, 13], [14, 21], [22, 23], [24, 26], [27, 37], [38, 42], [43, 47], [48, 51], [52, 60], [61, 63], [63, 74], [74, 75], [76, 85], [86, 90], [91, 93], [94, 110], [111, 114], [115, 119], [120, 123], [124, 128], [128, 129], [130, 132], [133, 142], [143, 145], [145, 157], [157, 158], [159, 161], [162, 176], [177, 188], [189, 191], [192, 198], [198, 199], [200, 202], [203, 209], [210, 221], [221, 222], [223, 225], [226, 236], [237, 248], [249, 251], [252, 256], [257, 259], [260, 270], [271, 282], [283, 285], [286, 290], [291, 298], [298, 299]]}
{"doc_key": "ai-test-265", "ner": [[0, 1, "researcher"], [7, 7, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 7, 7, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Keutzer", "a", "\u00e9t\u00e9", "nomm\u00e9", "Fellow", "de", "l'", "IEEE", "en", "1996", "."], "sentence-detokenized": "Keutzer a \u00e9t\u00e9 nomm\u00e9 Fellow de l'IEEE en 1996.", "token2charspan": [[0, 7], [8, 9], [10, 13], [14, 19], [20, 26], [27, 29], [30, 32], [32, 36], [37, 39], [40, 44], [44, 45]]}
{"doc_key": "ai-test-266", "ner": [[8, 11, "algorithm"], [55, 57, "misc"], [67, 68, "algorithm"], [71, 72, "algorithm"], [75, 76, "algorithm"], [79, 81, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[67, 68, 55, 57, "type-of", "", false, false], [71, 72, 55, 57, "type-of", "", false, false], [75, 76, 55, 57, "type-of", "", false, false], [79, 81, 55, 57, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Un", "type", "de", "composition", "largement", "utilis\u00e9", "est", "la", "somme", "pond\u00e9r\u00e9e", "non", "lin\u00e9aire", ",", "o\u00f9", "math", "\\", "textstyle", "f", "(", "x", ")", "=", "K", "\\", "left", "(", "\\", "sum", "_", "i", "w", "_", "i", "g", "_", "i", "(", "x", ")", "\\", "right", ")", "/", "math", ",", "o\u00f9", "math", "\\", "textstyle", "K", "/", "math", "(", "commun\u00e9ment", "appel\u00e9e", "fonction", "d'", "activation", ")", "est", "une", "fonction", "pr\u00e9d\u00e9finie", ",", "telle", "que", "la", "tangente", "hyperbolique", ",", "la", "fonction", "sigmo\u00efde", ",", "la", "fonction", "softmax", "ou", "la", "fonction", "de", "redressement", "."], "sentence-detokenized": "Un type de composition largement utilis\u00e9 est la somme pond\u00e9r\u00e9e non lin\u00e9aire, o\u00f9 math\\ textstyle f (x) = K\\ left (\\ sum _ i w _ i g _ i (x)\\ right) / math, o\u00f9 math\\ textstyle K / math (commun\u00e9ment appel\u00e9e fonction d'activation) est une fonction pr\u00e9d\u00e9finie, telle que la tangente hyperbolique, la fonction sigmo\u00efde, la fonction softmax ou la fonction de redressement.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 22], [23, 32], [33, 40], [41, 44], [45, 47], [48, 53], [54, 62], [63, 66], [67, 75], [75, 76], [77, 79], [80, 84], [84, 85], [86, 95], [96, 97], [98, 99], [99, 100], [100, 101], [102, 103], [104, 105], [105, 106], [107, 111], [112, 113], [113, 114], [115, 118], [119, 120], [121, 122], [123, 124], [125, 126], [127, 128], [129, 130], [131, 132], [133, 134], [135, 136], [136, 137], [137, 138], [138, 139], [140, 145], [145, 146], [147, 148], [149, 153], [153, 154], [155, 157], [158, 162], [162, 163], [164, 173], [174, 175], [176, 177], [178, 182], [183, 184], [184, 195], [196, 203], [204, 212], [213, 215], [215, 225], [225, 226], [227, 230], [231, 234], [235, 243], [244, 254], [254, 255], [256, 261], [262, 265], [266, 268], [269, 277], [278, 290], [290, 291], [292, 294], [295, 303], [304, 312], [312, 313], [314, 316], [317, 325], [326, 333], [334, 336], [337, 339], [340, 348], [349, 351], [352, 364], [364, 365]]}
{"doc_key": "ai-test-267", "ner": [[3, 3, "misc"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Dans", "le", "film", "Westworld", ",", "des", "robots", "f\u00e9minins", "ont", "eu", "des", "rapports", "sexuels", "avec", "des", "hommes", "dans", "le", "cadre", "de", "vacances", "fictives", "auxquelles", "les", "clients", "humains", "ont", "pay\u00e9", "pour", "participer", "."], "sentence-detokenized": "Dans le film Westworld, des robots f\u00e9minins ont eu des rapports sexuels avec des hommes dans le cadre de vacances fictives auxquelles les clients humains ont pay\u00e9 pour participer.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 22], [22, 23], [24, 27], [28, 34], [35, 43], [44, 47], [48, 50], [51, 54], [55, 63], [64, 71], [72, 76], [77, 80], [81, 87], [88, 92], [93, 95], [96, 101], [102, 104], [105, 113], [114, 122], [123, 133], [134, 137], [138, 145], [146, 153], [154, 157], [158, 162], [163, 167], [168, 178], [178, 179]]}
{"doc_key": "ai-test-268", "ner": [[8, 11, "task"], [31, 37, "task"], [40, 42, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 11, 31, 37, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["En", "g\u00e9n\u00e9ral", ",", "le", "processus", "commence", "par", "l'", "extraction", "de", "la", "terminologie", "et", "des", "concepts", "ou", "des", "phrases", "nominales", "du", "texte", "brut", "\u00e0", "l'", "aide", "de", "processeurs", "linguistiques", "tels", "que", "le", "marquage", "de", "la", "partie", "de", "la", "parole", "et", "le", "d\u00e9coupage", "des", "phrases", "."], "sentence-detokenized": "En g\u00e9n\u00e9ral, le processus commence par l'extraction de la terminologie et des concepts ou des phrases nominales du texte brut \u00e0 l'aide de processeurs linguistiques tels que le marquage de la partie de la parole et le d\u00e9coupage des phrases.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 14], [15, 24], [25, 33], [34, 37], [38, 40], [40, 50], [51, 53], [54, 56], [57, 69], [70, 72], [73, 76], [77, 85], [86, 88], [89, 92], [93, 100], [101, 110], [111, 113], [114, 119], [120, 124], [125, 126], [127, 129], [129, 133], [134, 136], [137, 148], [149, 162], [163, 167], [168, 171], [172, 174], [175, 183], [184, 186], [187, 189], [190, 196], [197, 199], [200, 202], [203, 209], [210, 212], [213, 215], [216, 225], [226, 229], [230, 237], [237, 238]]}
{"doc_key": "ai-test-269", "ner": [[16, 17, "field"], [21, 25, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[21, 25, 16, 17, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0], "sentence": ["Ils", "ont", "d\u00e9montr\u00e9", "ses", "performances", "sur", "un", "certain", "nombre", "de", "probl\u00e8mes", "int\u00e9ressant", "la", "communaut\u00e9", "de", "l'", "apprentissage", "automatique", ",", "notamment", "la", "reconnaissance", "de", "l'", "\u00e9criture", "manuscrite", "."], "sentence-detokenized": "Ils ont d\u00e9montr\u00e9 ses performances sur un certain nombre de probl\u00e8mes int\u00e9ressant la communaut\u00e9 de l'apprentissage automatique, notamment la reconnaissance de l'\u00e9criture manuscrite.", "token2charspan": [[0, 3], [4, 7], [8, 16], [17, 20], [21, 33], [34, 37], [38, 40], [41, 48], [49, 55], [56, 58], [59, 68], [69, 80], [81, 83], [84, 94], [95, 97], [98, 100], [100, 113], [114, 125], [125, 126], [127, 136], [137, 139], [140, 154], [155, 157], [158, 160], [160, 168], [169, 179], [179, 180]]}
{"doc_key": "ai-test-270", "ner": [[4, 4, "university"], [6, 7, "researcher"], [13, 14, "researcher"], [20, 20, "product"], [24, 25, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 7, 4, 4, "physical", "", false, false], [6, 7, 4, 4, "role", "", false, false], [20, 20, 13, 14, "origin", "", false, false], [20, 20, 24, 25, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Pendant", "ses", "\u00e9tudes", "\u00e0", "Stanford", ",", "Scheinman", "a", "obtenu", "une", "bourse", "parrain\u00e9e", "par", "George", "Devol", ",", "l'", "inventeur", "de", "l'", "Unimate", ",", "le", "premier", "robot", "industriel", "."], "sentence-detokenized": "Pendant ses \u00e9tudes \u00e0 Stanford, Scheinman a obtenu une bourse parrain\u00e9e par George Devol, l'inventeur de l'Unimate, le premier robot industriel.", "token2charspan": [[0, 7], [8, 11], [12, 18], [19, 20], [21, 29], [29, 30], [31, 40], [41, 42], [43, 49], [50, 53], [54, 60], [61, 70], [71, 74], [75, 81], [82, 87], [87, 88], [89, 91], [91, 100], [101, 103], [104, 106], [106, 113], [113, 114], [115, 117], [118, 125], [126, 131], [132, 142], [142, 143]]}
{"doc_key": "ai-test-271", "ner": [[12, 13, "task"], [16, 17, "metrics"], [19, 22, "metrics"], [30, 34, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 13, 16, 17, "usage", "", true, false], [19, 22, 16, 17, "named", "", false, false], [30, 34, 16, 17, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Bien", "qu'", "elle", "ait", "\u00e9t\u00e9", "utilis\u00e9e", "\u00e0", "l'", "origine", "pour", "\u00e9valuer", "les", "traductions", "automatiques", ",", "la", "sous-\u00e9valuation", "bilingue", "(", "BLEU", ")", "a", "\u00e9galement", "\u00e9t\u00e9", "utilis\u00e9e", "avec", "succ\u00e8s", "pour", "\u00e9valuer", "les", "mod\u00e8les", "de", "g\u00e9n\u00e9ration", "de", "paraphrases", "."], "sentence-detokenized": "Bien qu'elle ait \u00e9t\u00e9 utilis\u00e9e \u00e0 l'origine pour \u00e9valuer les traductions automatiques, la sous-\u00e9valuation bilingue (BLEU) a \u00e9galement \u00e9t\u00e9 utilis\u00e9e avec succ\u00e8s pour \u00e9valuer les mod\u00e8les de g\u00e9n\u00e9ration de paraphrases.", "token2charspan": [[0, 4], [5, 8], [8, 12], [13, 16], [17, 20], [21, 29], [30, 31], [32, 34], [34, 41], [42, 46], [47, 54], [55, 58], [59, 70], [71, 83], [83, 84], [85, 87], [88, 103], [104, 112], [113, 114], [114, 118], [118, 119], [120, 121], [122, 131], [132, 135], [136, 144], [145, 149], [150, 156], [157, 161], [162, 169], [170, 173], [174, 181], [182, 184], [185, 195], [196, 198], [199, 210], [210, 211]]}
{"doc_key": "ai-test-272", "ner": [[0, 1, "organisation"], [10, 12, "organisation"], [14, 14, "organisation"], [20, 20, "product"], [22, 22, "country"], [25, 25, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 10, 12, "role", "licenses_to", false, false], [0, 1, 14, 14, "role", "licenses_to", false, false], [10, 12, 22, 22, "physical", "", false, false], [14, 14, 25, 25, "physical", "", false, false], [20, 20, 10, 12, "artifact", "produces", false, false], [20, 20, 14, 14, "artifact", "produces", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Unimation", "a", "ensuite", "accord\u00e9", "une", "licence", "pour", "sa", "technologie", "\u00e0", "Kawasaki", "Heavy", "Industries", "et", "GKN", ",", "qui", "ont", "fabriqu\u00e9", "des", "Unimates", "au", "Japon", "et", "en", "Angleterre", "respectivement", "."], "sentence-detokenized": "Unimation a ensuite accord\u00e9 une licence pour sa technologie \u00e0 Kawasaki Heavy Industries et GKN, qui ont fabriqu\u00e9 des Unimates au Japon et en Angleterre respectivement.", "token2charspan": [[0, 9], [10, 11], [12, 19], [20, 27], [28, 31], [32, 39], [40, 44], [45, 47], [48, 59], [60, 61], [62, 70], [71, 76], [77, 87], [88, 90], [91, 94], [94, 95], [96, 99], [100, 103], [104, 112], [113, 116], [117, 125], [126, 128], [129, 134], [135, 137], [138, 140], [141, 151], [152, 166], [166, 167]]}
{"doc_key": "ai-test-273", "ner": [[24, 25, "conference"], [43, 44, "field"], [66, 73, "field"], [75, 75, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[43, 44, 66, 73, "compare", "", false, false], [75, 75, 66, 73, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Une", "grande", "partie", "de", "la", "confusion", "entre", "ces", "deux", "communaut\u00e9s", "de", "recherche", "(", "qui", "ont", "souvent", "des", "conf\u00e9rences", "et", "des", "revues", "distinctes", ",", "le", "CELV", "PKDD", "\u00e9tant", "une", "exception", "majeure", ")", "provient", "des", "hypoth\u00e8ses", "de", "base", "avec", "lesquelles", "elles", "travaillent", ":", "dans", "l'", "apprentissage", "automatique", ",", "la", "performance", "est", "g\u00e9n\u00e9ralement", "\u00e9valu\u00e9e", "par", "rapport", "\u00e0", "la", "capacit\u00e9", "de", "reproduire", "des", "connaissances", "connues", ",", "alors", "que", "dans", "la", "d\u00e9couverte", "de", "connaissances", "et", "l'", "exploration", "de", "donn\u00e9es", "(", "KDD", ")", ",", "la", "t\u00e2che", "principale", "est", "la", "d\u00e9couverte", "de", "connaissances", "pr\u00e9c\u00e9demment", "inconnues", "."], "sentence-detokenized": "Une grande partie de la confusion entre ces deux communaut\u00e9s de recherche (qui ont souvent des conf\u00e9rences et des revues distinctes, le CELV PKDD \u00e9tant une exception majeure) provient des hypoth\u00e8ses de base avec lesquelles elles travaillent : dans l'apprentissage automatique, la performance est g\u00e9n\u00e9ralement \u00e9valu\u00e9e par rapport \u00e0 la capacit\u00e9 de reproduire des connaissances connues, alors que dans la d\u00e9couverte de connaissances et l'exploration de donn\u00e9es (KDD), la t\u00e2che principale est la d\u00e9couverte de connaissances pr\u00e9c\u00e9demment inconnues.", "token2charspan": [[0, 3], [4, 10], [11, 17], [18, 20], [21, 23], [24, 33], [34, 39], [40, 43], [44, 48], [49, 60], [61, 63], [64, 73], [74, 75], [75, 78], [79, 82], [83, 90], [91, 94], [95, 106], [107, 109], [110, 113], [114, 120], [121, 131], [131, 132], [133, 135], [136, 140], [141, 145], [146, 151], [152, 155], [156, 165], [166, 173], [173, 174], [175, 183], [184, 187], [188, 198], [199, 201], [202, 206], [207, 211], [212, 222], [223, 228], [229, 240], [241, 242], [243, 247], [248, 250], [250, 263], [264, 275], [275, 276], [277, 279], [280, 291], [292, 295], [296, 308], [309, 316], [317, 320], [321, 328], [329, 330], [331, 333], [334, 342], [343, 345], [346, 356], [357, 360], [361, 374], [375, 382], [382, 383], [384, 389], [390, 393], [394, 398], [399, 401], [402, 412], [413, 415], [416, 429], [430, 432], [433, 435], [435, 446], [447, 449], [450, 457], [458, 459], [459, 462], [462, 463], [463, 464], [465, 467], [468, 473], [474, 484], [485, 488], [489, 491], [492, 502], [503, 505], [506, 519], [520, 532], [533, 542], [542, 543]]}
{"doc_key": "ai-test-274", "ner": [[2, 4, "algorithm"], [12, 19, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 4, 12, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Les", "mod\u00e8les", "de", "Markov", "cach\u00e9s", "constituent", "la", "base", "de", "la", "plupart", "des", "syst\u00e8mes", "modernes", "de", "reconnaissance", "automatique", "de", "la", "parole", "."], "sentence-detokenized": "Les mod\u00e8les de Markov cach\u00e9s constituent la base de la plupart des syst\u00e8mes modernes de reconnaissance automatique de la parole.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 21], [22, 28], [29, 40], [41, 43], [44, 48], [49, 51], [52, 54], [55, 62], [63, 66], [67, 75], [76, 84], [85, 87], [88, 102], [103, 114], [115, 117], [118, 120], [121, 127], [127, 128]]}
{"doc_key": "ai-test-275", "ner": [[3, 3, "location"], [6, 6, "country"], [13, 17, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 6, 6, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["une", "entreprise", "de", "Bangalore", ",", "en", "Inde", ",", "sp\u00e9cialis\u00e9e", "dans", "les", "logiciels", "de", "reconnaissance", "de", "l'", "\u00e9criture", "manuscrite", "en", "ligne", "."], "sentence-detokenized": "une entreprise de Bangalore, en Inde, sp\u00e9cialis\u00e9e dans les logiciels de reconnaissance de l'\u00e9criture manuscrite en ligne.", "token2charspan": [[0, 3], [4, 14], [15, 17], [18, 27], [27, 28], [29, 31], [32, 36], [36, 37], [38, 49], [50, 54], [55, 58], [59, 68], [69, 71], [72, 86], [87, 89], [90, 92], [92, 100], [101, 111], [112, 114], [115, 120], [120, 121]]}
{"doc_key": "ai-test-276", "ner": [[30, 31, "misc"], [59, 59, "metrics"], [61, 63, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[59, 59, 61, 63, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Les", "traductions", "r\u00e9p\u00e9t\u00e9es", "convergent", "-elles", "vers", "une", "seule", "expression", "dans", "les", "deux", "langues", "?", "En", "d'", "autres", "termes", ",", "la", "m\u00e9thode", "de", "traduction", "est", "-elle", "stationnaire", "ou", "produit", "-elle", "une", "forme", "canonique", "?", "La", "traduction", "devient", "-elle", "stationnaire", "sans", "perdre", "le", "sens", "original", "?", "Cette", "m\u00e9trique", "a", "\u00e9t\u00e9", "critiqu\u00e9e", "car", "elle", "n'", "est", "pas", "bien", "corr\u00e9l\u00e9e", "avec", "les", "scores", "BLEU", "(", "BiLingual", "Evaluation", "Understudy", ")", "."], "sentence-detokenized": "Les traductions r\u00e9p\u00e9t\u00e9es convergent-elles vers une seule expression dans les deux langues ? En d'autres termes, la m\u00e9thode de traduction est-elle stationnaire ou produit-elle une forme canonique ? La traduction devient-elle stationnaire sans perdre le sens original ? Cette m\u00e9trique a \u00e9t\u00e9 critiqu\u00e9e car elle n'est pas bien corr\u00e9l\u00e9e avec les scores BLEU (BiLingual Evaluation Understudy).", "token2charspan": [[0, 3], [4, 15], [16, 24], [25, 35], [35, 41], [42, 46], [47, 50], [51, 56], [57, 67], [68, 72], [73, 76], [77, 81], [82, 89], [90, 91], [92, 94], [95, 97], [97, 103], [104, 110], [110, 111], [112, 114], [115, 122], [123, 125], [126, 136], [137, 140], [140, 145], [146, 158], [159, 161], [162, 169], [169, 174], [175, 178], [179, 184], [185, 194], [195, 196], [197, 199], [200, 210], [211, 218], [218, 223], [224, 236], [237, 241], [242, 248], [249, 251], [252, 256], [257, 265], [266, 267], [268, 273], [274, 282], [283, 284], [285, 288], [289, 298], [299, 302], [303, 307], [308, 310], [310, 313], [314, 317], [318, 322], [323, 331], [332, 336], [337, 340], [341, 347], [348, 352], [353, 354], [354, 363], [364, 374], [375, 385], [385, 386], [386, 387]]}
{"doc_key": "ai-test-277", "ner": [[5, 9, "organisation"], [12, 19, "organisation"], [22, 24, "university"], [32, 32, "university"], [29, 31, "field"], [36, 40, "organisation"], [44, 47, "organisation"], [55, 58, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[12, 19, 22, 24, "part-of", "", false, false], [32, 32, 29, 31, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Il", "est", "membre", "de", "l'", "American", "Association", "for", "Artificial", "Intelligence", ",", "du", "Center", "for", "Advanced", "Study", "in", "the", "Behavioral", "Sciences", "de", "l'", "universit\u00e9", "de", "Stanford", ",", "du", "Center", "for", "Cognitive", "Science", "du", "MIT", ",", "de", "l'", "Institut", "canadien", "de", "recherches", "avanc\u00e9es", ",", "de", "la", "Soci\u00e9t\u00e9", "canadienne", "de", "psychologie", "et", "a", "\u00e9t\u00e9", "\u00e9lu", "membre", "de", "la", "Soci\u00e9t\u00e9", "royale", "du", "Canada", "en", "1998", "."], "sentence-detokenized": "Il est membre de l'American Association for Artificial Intelligence, du Center for Advanced Study in the Behavioral Sciences de l'universit\u00e9 de Stanford, du Center for Cognitive Science du MIT, de l'Institut canadien de recherches avanc\u00e9es, de la Soci\u00e9t\u00e9 canadienne de psychologie et a \u00e9t\u00e9 \u00e9lu membre de la Soci\u00e9t\u00e9 royale du Canada en 1998.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 16], [17, 19], [19, 27], [28, 39], [40, 43], [44, 54], [55, 67], [67, 68], [69, 71], [72, 78], [79, 82], [83, 91], [92, 97], [98, 100], [101, 104], [105, 115], [116, 124], [125, 127], [128, 130], [130, 140], [141, 143], [144, 152], [152, 153], [154, 156], [157, 163], [164, 167], [168, 177], [178, 185], [186, 188], [189, 192], [192, 193], [194, 196], [197, 199], [199, 207], [208, 216], [217, 219], [220, 230], [231, 239], [239, 240], [241, 243], [244, 246], [247, 254], [255, 265], [266, 268], [269, 280], [281, 283], [284, 285], [286, 289], [290, 293], [294, 300], [301, 303], [304, 306], [307, 314], [315, 321], [322, 324], [325, 331], [332, 334], [335, 339], [339, 340]]}
{"doc_key": "ai-test-278", "ner": [[0, 1, "researcher"], [5, 6, "researcher"], [8, 9, "researcher"], [17, 20, "misc"], [23, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 17, 20, "part-of", "", false, false], [0, 1, 23, 27, "part-of", "", false, false], [5, 6, 17, 20, "part-of", "", false, false], [5, 6, 23, 27, "part-of", "", false, false], [8, 9, 17, 20, "part-of", "", false, false], [8, 9, 23, 27, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["M.", "Hinton", "-", "ainsi", "que", "Yoshua", "Bengio", "et", "Yann", "LeCun", "-", "sont", "consid\u00e9r\u00e9s", "par", "certains", "comme", "les", "parrains", "de", "l'", "IA", "et", "les", "parrains", "de", "l'", "apprentissage", "profond", "."], "sentence-detokenized": "M. Hinton - ainsi que Yoshua Bengio et Yann LeCun - sont consid\u00e9r\u00e9s par certains comme les parrains de l'IA et les parrains de l'apprentissage profond.", "token2charspan": [[0, 2], [3, 9], [10, 11], [12, 17], [18, 21], [22, 28], [29, 35], [36, 38], [39, 43], [44, 49], [50, 51], [52, 56], [57, 67], [68, 71], [72, 80], [81, 86], [87, 90], [91, 99], [100, 102], [103, 105], [105, 107], [108, 110], [111, 114], [115, 123], [124, 126], [127, 129], [129, 142], [143, 150], [150, 151]]}
{"doc_key": "ai-test-279", "ner": [[7, 7, "product"], [21, 21, "misc"], [24, 25, "misc"], [26, 26, "product"], [31, 32, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 7, 21, 21, "related-to", "", false, false], [7, 7, 24, 25, "related-to", "", false, false], [21, 21, 26, 26, "named", "same", false, false], [31, 32, 26, 26, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Le", "projet", "de", "synth\u00e8se", "vocale", "open-source", "l\u00e9ger", "eSpeak", ",", "qui", "a", "sa", "propre", "approche", "de", "la", "synth\u00e8se", ",", "a", "exp\u00e9riment\u00e9", "le", "mandarin", "et", "le", "cantonais", ".", "eSpeak", "a", "\u00e9t\u00e9", "utilis\u00e9", "par", "Google", "Translate", "de", "mai", "2010", "\u00e0", "2010", "."], "sentence-detokenized": "Le projet de synth\u00e8se vocale open-source l\u00e9ger eSpeak, qui a sa propre approche de la synth\u00e8se, a exp\u00e9riment\u00e9 le mandarin et le cantonais. eSpeak a \u00e9t\u00e9 utilis\u00e9 par Google Translate de mai 2010 \u00e0 2010.", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 21], [22, 28], [29, 40], [41, 46], [47, 53], [53, 54], [55, 58], [59, 60], [61, 63], [64, 70], [71, 79], [80, 82], [83, 85], [86, 94], [94, 95], [96, 97], [98, 109], [110, 112], [113, 121], [122, 124], [125, 127], [128, 137], [137, 138], [139, 145], [146, 147], [148, 151], [152, 159], [160, 163], [164, 170], [171, 180], [181, 183], [184, 187], [188, 192], [193, 194], [195, 199], [199, 200]]}
{"doc_key": "ai-test-280", "ner": [[5, 7, "product"], [13, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 13, 14, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["\u00c9galement", "publi\u00e9", "en", "1982", ",", "Software", "Automatic", "Mouth", "\u00e9tait", "le", "premier", "programme", "commercial", "de", "synth\u00e8se", "vocale", "enti\u00e8rement", "logiciel", "."], "sentence-detokenized": "\u00c9galement publi\u00e9 en 1982, Software Automatic Mouth \u00e9tait le premier programme commercial de synth\u00e8se vocale enti\u00e8rement logiciel.", "token2charspan": [[0, 9], [10, 16], [17, 19], [20, 24], [24, 25], [26, 34], [35, 44], [45, 50], [51, 56], [57, 59], [60, 67], [68, 77], [78, 88], [89, 91], [92, 100], [101, 107], [108, 119], [120, 128], [128, 129]]}
{"doc_key": "ai-test-281", "ner": [[6, 8, "metrics"], [10, 10, "metrics"], [13, 13, "metrics"], [15, 15, "metrics"], [18, 24, "metrics"], [31, 33, "metrics"], [35, 35, "metrics"], [38, 44, "metrics"], [49, 51, "metrics"], [53, 53, "metrics"], [56, 56, "metrics"], [58, 58, "metrics"], [61, 67, "metrics"], [74, 76, "metrics"], [78, 78, "metrics"], [81, 87, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[10, 10, 6, 8, "named", "", false, false], [13, 13, 6, 8, "named", "", false, false], [15, 15, 6, 8, "named", "", false, false], [18, 24, 6, 8, "named", "", false, false], [35, 35, 31, 33, "named", "", false, false], [38, 44, 31, 33, "named", "", false, false], [53, 53, 49, 51, "named", "", false, false], [56, 56, 49, 51, "named", "", false, false], [58, 58, 49, 51, "named", "", false, false], [61, 67, 49, 51, "named", "", false, false], [78, 78, 74, 76, "named", "", false, false], [81, 87, 74, 76, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Les", "ratios", "des", "colonnes", "sont", "le", "Vrai", "Taux", "Positif", "(", "TPR", ",", "alias", "Sensibilit\u00e9", "ou", "rappel", ")", "(", "TP", "/", "(", "TP", "+", "FN", ")", ")", ",", "avec", "en", "compl\u00e9ment", "le", "Faux", "Taux", "N\u00e9gatif", "(", "FNR", ")", "(", "FN", "/", "(", "TP", "+", "FN", ")", ")", ";", "et", "le", "Vrai", "Taux", "N\u00e9gatif", "(", "TNR", ",", "alias", "Sp\u00e9cificit\u00e9", ",", "SPC", ")", "(", "TN", "/", "(", "TN", "+", "FP", ")", ")", ",", "avec", "en", "compl\u00e9ment", "le", "Faux", "Taux", "Positif", "(", "FPR", ")", "(", "FP", "/", "(", "TN", "+", "FP", ")", ")", "."], "sentence-detokenized": "Les ratios des colonnes sont le Vrai Taux Positif (TPR, alias Sensibilit\u00e9 ou rappel) (TP / (TP + FN)), avec en compl\u00e9ment le Faux Taux N\u00e9gatif (FNR) (FN / (TP + FN)) ; et le Vrai Taux N\u00e9gatif (TNR, alias Sp\u00e9cificit\u00e9, SPC) (TN / (TN + FP)), avec en compl\u00e9ment le Faux Taux Positif (FPR) (FP / (TN + FP)).", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 28], [29, 31], [32, 36], [37, 41], [42, 49], [50, 51], [51, 54], [54, 55], [56, 61], [62, 73], [74, 76], [77, 83], [83, 84], [85, 86], [86, 88], [89, 90], [91, 92], [92, 94], [95, 96], [97, 99], [99, 100], [100, 101], [101, 102], [103, 107], [108, 110], [111, 121], [122, 124], [125, 129], [130, 134], [135, 142], [143, 144], [144, 147], [147, 148], [149, 150], [150, 152], [153, 154], [155, 156], [156, 158], [159, 160], [161, 163], [163, 164], [164, 165], [166, 167], [168, 170], [171, 173], [174, 178], [179, 183], [184, 191], [192, 193], [193, 196], [196, 197], [198, 203], [204, 215], [215, 216], [217, 220], [220, 221], [222, 223], [223, 225], [226, 227], [228, 229], [229, 231], [232, 233], [234, 236], [236, 237], [237, 238], [238, 239], [240, 244], [245, 247], [248, 258], [259, 261], [262, 266], [267, 271], [272, 279], [280, 281], [281, 284], [284, 285], [286, 287], [287, 289], [290, 291], [292, 293], [293, 295], [296, 297], [298, 300], [300, 301], [301, 302], [302, 303]]}
{"doc_key": "ai-test-282", "ner": [[0, 0, "person"], [2, 2, "person"], [19, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 19, 19, "role", "working_with", false, false], [2, 2, 19, 19, "role", "working_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Edsinger", "et", "Weber", "ont", "\u00e9galement", "collabor\u00e9", "sur", "de", "nombreux", "autres", "robots", ",", "et", "leur", "exp\u00e9rience", "du", "travail", "avec", "le", "Kismet"], "sentence-detokenized": "Edsinger et Weber ont \u00e9galement collabor\u00e9 sur de nombreux autres robots, et leur exp\u00e9rience du travail avec le Kismet", "token2charspan": [[0, 8], [9, 11], [12, 17], [18, 21], [22, 31], [32, 41], [42, 45], [46, 48], [49, 57], [58, 64], [65, 71], [71, 72], [73, 75], [76, 80], [81, 91], [92, 94], [95, 102], [103, 107], [108, 110], [111, 117]]}
{"doc_key": "ai-test-283", "ner": [[2, 2, "programlang"], [15, 15, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 15, 15, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["La", "fonctionnalit\u00e9", "R", "est", "accessible", "\u00e0", "partir", "de", "plusieurs", "langages", "de", "script", ",", "tels", "que", "Python", ",", "sont", "\u00e9galement", "disponibles", "."], "sentence-detokenized": "La fonctionnalit\u00e9 R est accessible \u00e0 partir de plusieurs langages de script, tels que Python, sont \u00e9galement disponibles.", "token2charspan": [[0, 2], [3, 17], [18, 19], [20, 23], [24, 34], [35, 36], [37, 43], [44, 46], [47, 56], [57, 65], [66, 68], [69, 75], [75, 76], [77, 81], [82, 85], [86, 92], [92, 93], [94, 98], [99, 108], [109, 120], [120, 121]]}
{"doc_key": "ai-test-284", "ner": [[0, 0, "programlang"], [14, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 15, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VAL", "\u00e9tait", "l'", "un", "des", "premiers", "langages", "pour", "robots", "et", "\u00e9tait", "utilis\u00e9", "dans", "les", "robots", "Unimate", "."], "sentence-detokenized": "VAL \u00e9tait l'un des premiers langages pour robots et \u00e9tait utilis\u00e9 dans les robots Unimate.", "token2charspan": [[0, 3], [4, 9], [10, 12], [12, 14], [15, 18], [19, 27], [28, 36], [37, 41], [42, 48], [49, 51], [52, 57], [58, 65], [66, 70], [71, 74], [75, 81], [82, 89], [89, 90]]}
{"doc_key": "ai-test-285", "ner": [[18, 28, "conference"], [30, 30, "conference"], [33, 33, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 28, 33, 33, "physical", "", false, false], [30, 30, 18, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Ils", "ont", "pr\u00e9sent\u00e9", "leur", "base", "de", "donn\u00e9es", "pour", "la", "premi\u00e8re", "fois", "sous", "forme", "de", "poster", "lors", "de", "la", "Conf\u00e9rence", "2009", "sur", "la", "vision", "informatique", "et", "la", "reconnaissance", "des", "formes", "(", "CVPR", ")", "en", "Floride", "."], "sentence-detokenized": "Ils ont pr\u00e9sent\u00e9 leur base de donn\u00e9es pour la premi\u00e8re fois sous forme de poster lors de la Conf\u00e9rence 2009 sur la vision informatique et la reconnaissance des formes (CVPR) en Floride.", "token2charspan": [[0, 3], [4, 7], [8, 16], [17, 21], [22, 26], [27, 29], [30, 37], [38, 42], [43, 45], [46, 54], [55, 59], [60, 64], [65, 70], [71, 73], [74, 80], [81, 85], [86, 88], [89, 91], [92, 102], [103, 107], [108, 111], [112, 114], [115, 121], [122, 134], [135, 137], [138, 140], [141, 155], [156, 159], [160, 166], [167, 168], [168, 172], [172, 173], [174, 176], [177, 184], [184, 185]]}
{"doc_key": "ai-test-286", "ner": [[0, 3, "misc"], [13, 15, "task"], [17, 19, "field"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 15, 0, 3, "type-of", "", false, false], [17, 19, 0, 3, "type-of", "", false, false], [21, 23, 0, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Les", "t\u00e2ches", "de", "cat\u00e9gorisation", "dans", "lesquelles", "aucune", "\u00e9tiquette", "n'", "est", "fournie", "sont", "appel\u00e9es", "classification", "non", "supervis\u00e9e", ",", "apprentissage", "non", "supervis\u00e9", ",", "analyse", "en", "grappes", "."], "sentence-detokenized": "Les t\u00e2ches de cat\u00e9gorisation dans lesquelles aucune \u00e9tiquette n'est fournie sont appel\u00e9es classification non supervis\u00e9e, apprentissage non supervis\u00e9, analyse en grappes.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 28], [29, 33], [34, 44], [45, 51], [52, 61], [62, 64], [64, 67], [68, 75], [76, 80], [81, 89], [90, 104], [105, 108], [109, 119], [119, 120], [121, 134], [135, 138], [139, 148], [148, 149], [150, 157], [158, 160], [161, 168], [168, 169]]}
{"doc_key": "ai-test-287", "ner": [[2, 4, "task"], [14, 16, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Il", "doit", "reconna\u00eetre", "les", "objets", ",", "reconna\u00eetre", "et", "localiser", "les", "humains", "et", "poursuivre", "la", "reconnaissance", "des", "\u00e9motions", "."], "sentence-detokenized": "Il doit reconna\u00eetre les objets, reconna\u00eetre et localiser les humains et poursuivre la reconnaissance des \u00e9motions.", "token2charspan": [[0, 2], [3, 7], [8, 19], [20, 23], [24, 30], [30, 31], [32, 43], [44, 46], [47, 56], [57, 60], [61, 68], [69, 71], [72, 82], [83, 85], [86, 100], [101, 104], [105, 113], [113, 114]]}
{"doc_key": "ai-test-288", "ner": [[7, 7, "misc"], [10, 10, "misc"], [13, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Le", "processus", "est", "complexe", "et", "comprend", "l'", "encodage", "et", "le", "rappel", "ou", "la", "r\u00e9cup\u00e9ration", "."], "sentence-detokenized": "Le processus est complexe et comprend l'encodage et le rappel ou la r\u00e9cup\u00e9ration.", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 25], [26, 28], [29, 37], [38, 40], [40, 48], [49, 51], [52, 54], [55, 61], [62, 64], [65, 67], [68, 80], [80, 81]]}
{"doc_key": "ai-test-289", "ner": [[10, 12, "product"], [17, 19, "product"], [41, 42, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 12, 17, 19, "named", "", false, false], [10, 12, 41, 42, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["\u00c9galement", "connus", "sous", "le", "nom", "de", "robots", "parall\u00e8les", "ou", "de", "plates-formes", "de", "Stewart", "g\u00e9n\u00e9ralis\u00e9es", "(", "dans", "la", "plate-forme", "de", "Stewart", ",", "les", "actionneurs", "sont", "appari\u00e9s", "\u00e0", "la", "fois", "sur", "la", "base", "et", "sur", "la", "plate-forme", ")", ",", "ces", "syst\u00e8mes", "sont", "des", "robots", "articul\u00e9s", "qui", "utilisent", "des", "m\u00e9canismes", "similaires", "pour", "le", "mouvement", "soit", "du", "robot", "sur", "sa", "base", ",", "soit", "d'", "un", "ou", "plusieurs", "bras", "manipulateurs", "."], "sentence-detokenized": "\u00c9galement connus sous le nom de robots parall\u00e8les ou de plates-formes de Stewart g\u00e9n\u00e9ralis\u00e9es (dans la plate-forme de Stewart, les actionneurs sont appari\u00e9s \u00e0 la fois sur la base et sur la plate-forme), ces syst\u00e8mes sont des robots articul\u00e9s qui utilisent des m\u00e9canismes similaires pour le mouvement soit du robot sur sa base, soit d'un ou plusieurs bras manipulateurs.", "token2charspan": [[0, 9], [10, 16], [17, 21], [22, 24], [25, 28], [29, 31], [32, 38], [39, 49], [50, 52], [53, 55], [56, 69], [70, 72], [73, 80], [81, 93], [94, 95], [95, 99], [100, 102], [103, 114], [115, 117], [118, 125], [125, 126], [127, 130], [131, 142], [143, 147], [148, 156], [157, 158], [159, 161], [162, 166], [167, 170], [171, 173], [174, 178], [179, 181], [182, 185], [186, 188], [189, 200], [200, 201], [201, 202], [203, 206], [207, 215], [216, 220], [221, 224], [225, 231], [232, 241], [242, 245], [246, 255], [256, 259], [260, 270], [271, 281], [282, 286], [287, 289], [290, 299], [300, 304], [305, 307], [308, 313], [314, 317], [318, 320], [321, 325], [325, 326], [327, 331], [332, 334], [334, 336], [337, 339], [340, 349], [350, 354], [355, 368], [368, 369]]}
{"doc_key": "ai-test-290", "ner": [[0, 2, "field"], [9, 11, "field"], [20, 22, "field"], [27, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 9, 11, "part-of", "subfield", false, false], [0, 2, 20, 22, "compare", "", false, false], [20, 22, 27, 27, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "vision", "industrielle", ",", "en", "tant", "que", "discipline", "d'", "ing\u00e9nierie", "des", "syst\u00e8mes", ",", "peut", "\u00eatre", "consid\u00e9r\u00e9e", "comme", "distincte", "de", "la", "vision", "par", "ordinateur", ",", "une", "forme", "d'", "informatique", "."], "sentence-detokenized": "La vision industrielle, en tant que discipline d'ing\u00e9nierie des syst\u00e8mes, peut \u00eatre consid\u00e9r\u00e9e comme distincte de la vision par ordinateur, une forme d'informatique.", "token2charspan": [[0, 2], [3, 9], [10, 22], [22, 23], [24, 26], [27, 31], [32, 35], [36, 46], [47, 49], [49, 59], [60, 63], [64, 72], [72, 73], [74, 78], [79, 83], [84, 94], [95, 100], [101, 110], [111, 113], [114, 116], [117, 123], [124, 127], [128, 138], [138, 139], [140, 143], [144, 149], [150, 152], [152, 164], [164, 165]]}
{"doc_key": "ai-test-291", "ner": [[5, 6, "algorithm"], [10, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 10, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["La", "fonction", "d'", "activation", "des", "portes", "LSTM", "est", "souvent", "la", "fonction", "sigmo\u00efde", "logistique", "."], "sentence-detokenized": "La fonction d'activation des portes LSTM est souvent la fonction sigmo\u00efde logistique.", "token2charspan": [[0, 2], [3, 11], [12, 14], [14, 24], [25, 28], [29, 35], [36, 40], [41, 44], [45, 52], [53, 55], [56, 64], [65, 73], [74, 84], [84, 85]]}
{"doc_key": "ai-test-292", "ner": [[6, 9, "metrics"], [23, 28, "metrics"], [30, 30, "metrics"], [38, 41, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 9, 23, 28, "named", "", false, false], [6, 9, 38, 41, "named", "", false, false], [30, 30, 23, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["En", "d'", "autres", "termes", ",", "la", "moyenne", "de", "l'", "\u00e9chantillon", "est", "l'", "estimateur", "efficace", "(", "n\u00e9cessairement", "unique", ")", ",", "et", "donc", "aussi", "l'", "estimateur", "sans", "biais", "\u00e0", "variance", "minimale", "(", "MVUE", ")", ",", "en", "plus", "d'", "\u00eatre", "l'", "estimateur", "\u00e0", "vraisemblance", "maximale", "."], "sentence-detokenized": "En d'autres termes, la moyenne de l'\u00e9chantillon est l'estimateur efficace (n\u00e9cessairement unique), et donc aussi l'estimateur sans biais \u00e0 variance minimale (MVUE), en plus d'\u00eatre l'estimateur \u00e0 vraisemblance maximale.", "token2charspan": [[0, 2], [3, 5], [5, 11], [12, 18], [18, 19], [20, 22], [23, 30], [31, 33], [34, 36], [36, 47], [48, 51], [52, 54], [54, 64], [65, 73], [74, 75], [75, 89], [90, 96], [96, 97], [97, 98], [99, 101], [102, 106], [107, 112], [113, 115], [115, 125], [126, 130], [131, 136], [137, 138], [139, 147], [148, 156], [157, 158], [158, 162], [162, 163], [163, 164], [165, 167], [168, 172], [173, 175], [175, 179], [180, 182], [182, 192], [193, 194], [195, 208], [209, 217], [217, 218]]}
{"doc_key": "ai-test-293", "ner": [[16, 17, "academicjournal"], [5, 5, "researcher"], [7, 8, "researcher"], [10, 15, "researcher"], [24, 24, "product"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[16, 17, 24, 24, "topic", "", false, false], [16, 17, 28, 29, "topic", "", false, false], [5, 5, 16, 17, "role", "", false, false], [7, 8, 16, 17, "role", "", false, false], [10, 15, 16, 17, "role", "", false, false], [24, 24, 28, 29, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["L'", "article", "de", "2001", "de", "Berners-Lee", ",", "James", "Hendler", "et", "Ora", "Lassila", ",", "paru", "dans", "le", "Scientific", "American", ",", "d\u00e9crivait", "l'", "\u00e9volution", "pr\u00e9vue", "du", "Web", "existant", "vers", "un", "Web", "s\u00e9mantique", "."], "sentence-detokenized": "L'article de 2001 de Berners-Lee, James Hendler et Ora Lassila, paru dans le Scientific American, d\u00e9crivait l'\u00e9volution pr\u00e9vue du Web existant vers un Web s\u00e9mantique.", "token2charspan": [[0, 2], [2, 9], [10, 12], [13, 17], [18, 20], [21, 32], [32, 33], [34, 39], [40, 47], [48, 50], [51, 54], [55, 62], [62, 63], [64, 68], [69, 73], [74, 76], [77, 87], [88, 96], [96, 97], [98, 107], [108, 110], [110, 119], [120, 126], [127, 129], [130, 133], [134, 142], [143, 147], [148, 150], [151, 154], [155, 165], [165, 166]]}
{"doc_key": "ai-test-294", "ner": [[0, 1, "misc"], [15, 16, "person"], [18, 18, "person"], [33, 33, "person"], [45, 45, "person"], [49, 50, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[15, 16, 0, 1, "role", "actor_in_work", false, false], [18, 18, 15, 16, "named", "", false, false], [18, 18, 15, 16, "origin", "", false, false], [33, 33, 18, 18, "part-of", "", false, false], [49, 50, 18, 18, "role", "auditioned_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Blade", "Runner", "a", "fait", "appel", "\u00e0", "un", "certain", "nombre", "d'", "acteurs", "alors", "moins", "connus", ":", "Sean", "Young", "incarne", "Rachael", ",", "un", "r\u00e9plicant", "exp\u00e9rimental", "auquel", "on", "a", "implant\u00e9", "les", "souvenirs", "de", "la", "ni\u00e8ce", "de", "Tyrell", ",", "ce", "qui", "lui", "fait", "croire", "qu'", "elle", "est", "humaine", ";", "Sammon", ",", "pp.", "92-93", "Nina", "Axelrod", "a", "auditionn\u00e9", "pour", "le", "r\u00f4le", "."], "sentence-detokenized": "Blade Runner a fait appel \u00e0 un certain nombre d'acteurs alors moins connus : Sean Young incarne Rachael, un r\u00e9plicant exp\u00e9rimental auquel on a implant\u00e9 les souvenirs de la ni\u00e8ce de Tyrell, ce qui lui fait croire qu'elle est humaine ; Sammon, pp. 92-93 Nina Axelrod a auditionn\u00e9 pour le r\u00f4le.", "token2charspan": [[0, 5], [6, 12], [13, 14], [15, 19], [20, 25], [26, 27], [28, 30], [31, 38], [39, 45], [46, 48], [48, 55], [56, 61], [62, 67], [68, 74], [75, 76], [77, 81], [82, 87], [88, 95], [96, 103], [103, 104], [105, 107], [108, 117], [118, 130], [131, 137], [138, 140], [141, 142], [143, 151], [152, 155], [156, 165], [166, 168], [169, 171], [172, 177], [178, 180], [181, 187], [187, 188], [189, 191], [192, 195], [196, 199], [200, 204], [205, 211], [212, 215], [215, 219], [220, 223], [224, 231], [232, 233], [234, 240], [240, 241], [242, 245], [246, 251], [252, 256], [257, 264], [265, 266], [267, 277], [278, 282], [283, 285], [286, 290], [290, 291]]}
{"doc_key": "ai-test-295", "ner": [[0, 1, "researcher"], [3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [16, 18, "university"], [24, 24, "product"], [26, 26, "product"], [49, 49, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 16, 18, "physical", "", false, false], [3, 4, 16, 18, "physical", "", false, false], [6, 7, 16, 18, "physical", "", false, false], [9, 10, 16, 18, "physical", "", false, false], [16, 18, 49, 49, "physical", "", true, false], [24, 24, 16, 18, "temporal", "", false, false], [26, 26, 16, 18, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Gerry", "Sussman", ",", "Eugene", "Charniak", ",", "Seymour", "Papert", "et", "Terry", "Winograd", "se", "sont", "rendus", "\u00e0", "l'", "universit\u00e9", "d'", "\u00c9dimbourg", "en", "1971", "pour", "faire", "conna\u00eetre", "Micro-Planner", "et", "SHRDLU", "et", "mettre", "en", "doute", "l'", "approche", "de", "la", "proc\u00e9dure", "de", "preuve", "uniforme", "par", "r\u00e9solution", "qui", "avait", "\u00e9t\u00e9", "le", "pilier", "des", "logiciens", "d'", "\u00c9dimbourg", "."], "sentence-detokenized": "Gerry Sussman, Eugene Charniak, Seymour Papert et Terry Winograd se sont rendus \u00e0 l'universit\u00e9 d'\u00c9dimbourg en 1971 pour faire conna\u00eetre Micro-Planner et SHRDLU et mettre en doute l'approche de la proc\u00e9dure de preuve uniforme par r\u00e9solution qui avait \u00e9t\u00e9 le pilier des logiciens d'\u00c9dimbourg.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 21], [22, 30], [30, 31], [32, 39], [40, 46], [47, 49], [50, 55], [56, 64], [65, 67], [68, 72], [73, 79], [80, 81], [82, 84], [84, 94], [95, 97], [97, 106], [107, 109], [110, 114], [115, 119], [120, 125], [126, 135], [136, 149], [150, 152], [153, 159], [160, 162], [163, 169], [170, 172], [173, 178], [179, 181], [181, 189], [190, 192], [193, 195], [196, 205], [206, 208], [209, 215], [216, 224], [225, 228], [229, 239], [240, 243], [244, 249], [250, 253], [254, 256], [257, 263], [264, 267], [268, 277], [278, 280], [280, 289], [289, 290]]}
{"doc_key": "ai-test-296", "ner": [[3, 3, "researcher"], [12, 12, "field"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 15, 16, "role", "inspires", false, false], [3, 3, 18, 19, "role", "inspires", false, false], [3, 3, 21, 22, "role", "inspires", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Les", "travaux", "de", "Walter", "ont", "inspir\u00e9", "les", "g\u00e9n\u00e9rations", "suivantes", "de", "chercheurs", "en", "robotique", ",", "comme", "Rodney", "Brooks", ",", "Hans", "Moravec", "et", "Mark", "Tilden", "."], "sentence-detokenized": "Les travaux de Walter ont inspir\u00e9 les g\u00e9n\u00e9rations suivantes de chercheurs en robotique, comme Rodney Brooks, Hans Moravec et Mark Tilden.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 21], [22, 25], [26, 33], [34, 37], [38, 49], [50, 59], [60, 62], [63, 73], [74, 76], [77, 86], [86, 87], [88, 93], [94, 100], [101, 107], [107, 108], [109, 113], [114, 121], [122, 124], [125, 129], [130, 136], [136, 137]]}
{"doc_key": "ai-test-297", "ner": [[5, 5, "algorithm"], [14, 15, "researcher"], [23, 30, "event"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 14, 15, "origin", "", false, false], [5, 5, 23, 30, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Par", "la", "suite", ",", "un", "CNN", "similaire", "bas\u00e9", "sur", "le", "GPU", ",", "r\u00e9alis\u00e9", "par", "Alex", "Krizhevsky", "et", "al", ".", ",", "a", "remport\u00e9", "le", "concours", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "2012", "."], "sentence-detokenized": "Par la suite, un CNN similaire bas\u00e9 sur le GPU, r\u00e9alis\u00e9 par Alex Krizhevsky et al., a remport\u00e9 le concours ImageNet Large Scale Visual Recognition Challenge 2012.", "token2charspan": [[0, 3], [4, 6], [7, 12], [12, 13], [14, 16], [17, 20], [21, 30], [31, 35], [36, 39], [40, 42], [43, 46], [46, 47], [48, 55], [56, 59], [60, 64], [65, 75], [76, 78], [79, 81], [81, 82], [82, 83], [84, 85], [86, 94], [95, 97], [98, 106], [107, 115], [116, 121], [122, 127], [128, 134], [135, 146], [147, 156], [157, 161], [161, 162]]}
{"doc_key": "ai-test-298", "ner": [[0, 3, "misc"], [12, 13, "metrics"], [16, 18, "metrics"], [23, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 13, 0, 3, "type-of", "", false, false], [16, 18, 0, 3, "type-of", "", false, false], [16, 18, 23, 26, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Les", "fonctions", "de", "perte", "couramment", "utilis\u00e9es", "pour", "la", "classification", "probabiliste", "comprennent", "la", "perte", "logarithmique", "et", "le", "score", "de", "Brier", "entre", "les", "distributions", "de", "probabilit\u00e9", "pr\u00e9dite", "et", "VRAIE", "."], "sentence-detokenized": "Les fonctions de perte couramment utilis\u00e9es pour la classification probabiliste comprennent la perte logarithmique et le score de Brier entre les distributions de probabilit\u00e9 pr\u00e9dite et VRAIE.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 22], [23, 33], [34, 43], [44, 48], [49, 51], [52, 66], [67, 79], [80, 91], [92, 94], [95, 100], [101, 114], [115, 117], [118, 120], [121, 126], [127, 129], [130, 135], [136, 141], [142, 145], [146, 159], [160, 162], [163, 174], [175, 182], [183, 185], [186, 191], [191, 192]]}
{"doc_key": "ai-test-299", "ner": [[4, 4, "organisation"], [14, 14, "field"], [17, 17, "organisation"], [21, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 14, 14, "general-affiliation", "field_of_study", false, false], [4, 4, 21, 22, "part-of", "", false, false], [17, 17, 4, 4, "role", "admits_E2_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["En", "mai", "2016", ",", "NtechLab", "a", "\u00e9t\u00e9", "admise", "au", "test", "officiel", "de", "la", "technologie", "biom\u00e9trique", "par", "le", "NIST", "parmi", "les", "trois", "entreprises", "russes", "."], "sentence-detokenized": "En mai 2016, NtechLab a \u00e9t\u00e9 admise au test officiel de la technologie biom\u00e9trique par le NIST parmi les trois entreprises russes.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [13, 21], [22, 23], [24, 27], [28, 34], [35, 37], [38, 42], [43, 51], [52, 54], [55, 57], [58, 69], [70, 81], [82, 85], [86, 88], [89, 93], [94, 99], [100, 103], [104, 109], [110, 121], [122, 128], [128, 129]]}
{"doc_key": "ai-test-300", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["Cependant", ",", "les", "nombres", "\u00e0", "virgule", "flottante", "n'", "ont", "qu'", "une", "certaine", "pr\u00e9cision", "math\u00e9matique", "."], "sentence-detokenized": "Cependant, les nombres \u00e0 virgule flottante n'ont qu'une certaine pr\u00e9cision math\u00e9matique.", "token2charspan": [[0, 9], [9, 10], [11, 14], [15, 22], [23, 24], [25, 32], [33, 42], [43, 45], [45, 48], [49, 52], [52, 55], [56, 64], [65, 74], [75, 87], [87, 88]]}
{"doc_key": "ai-test-301", "ner": [[11, 11, "organisation"], [17, 26, "conference"], [28, 28, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 17, 26, "role", "contributes_to", false, false], [28, 28, 17, 26, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Au", "cours", "de", "l'", "ann\u00e9e", "2015", ",", "de", "nombreux", "articles", "de", "SenseTime", "ont", "\u00e9t\u00e9", "accept\u00e9s", "\u00e0", "la", "Conf\u00e9rence", "sur", "la", "vision", "informatique", "et", "la", "reconnaissance", "des", "formes", "(", "CVPR", ")", "."], "sentence-detokenized": "Au cours de l'ann\u00e9e 2015, de nombreux articles de SenseTime ont \u00e9t\u00e9 accept\u00e9s \u00e0 la Conf\u00e9rence sur la vision informatique et la reconnaissance des formes (CVPR).", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 14], [14, 19], [20, 24], [24, 25], [26, 28], [29, 37], [38, 46], [47, 49], [50, 59], [60, 63], [64, 67], [68, 76], [77, 78], [79, 81], [82, 92], [93, 96], [97, 99], [100, 106], [107, 119], [120, 122], [123, 125], [126, 140], [141, 144], [145, 151], [152, 153], [153, 157], [157, 158], [158, 159]]}
{"doc_key": "ai-test-302", "ner": [[7, 9, "task"], [11, 11, "task"], [14, 15, "task"], [17, 20, "task"], [23, 23, "field"], [25, 28, "misc"], [31, 37, "conference"], [46, 48, "misc"], [51, 52, "conference"], [72, 75, "misc"], [77, 77, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[7, 9, 23, 23, "part-of", "task_part_of_field", false, false], [11, 11, 7, 9, "named", "", false, false], [14, 15, 23, 23, "part-of", "task_part_of_field", false, false], [17, 20, 14, 15, "named", "", false, false], [25, 28, 31, 37, "temporal", "", false, false], [46, 48, 51, 52, "temporal", "", false, false], [72, 75, 77, 77, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Il", "a", "co-d\u00e9velopp\u00e9", "des", "algorithmes", "optimaux", "pour", "Structure", "From", "Motion", "(", "SFM", ",", "ou", "Visual", "SLAM", ",", "localisation", "et", "cartographie", "simultan\u00e9es", ",", "en", "robotique", ";", "prix", "du", "meilleur", "article", "\u00e0", "la", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "1998", ")", ",", "a", "caract\u00e9ris\u00e9", "ses", "ambigu\u00eft\u00e9s", "(", "prix", "David", "Marr", "\u00e0", "l'", "ICCV", "1999", ")", ",", "a", "\u00e9galement", "caract\u00e9ris\u00e9", "l'", "identifiabilit\u00e9", "et", "l'", "observabilit\u00e9", "de", "la", "fusion", "de", "capteurs", "visuels", "et", "inertiels", "(", "prix", "du", "meilleur", "article", "\u00e0", "Robotics", "2015", ")", "."], "sentence-detokenized": "Il a co-d\u00e9velopp\u00e9 des algorithmes optimaux pour Structure From Motion (SFM, ou Visual SLAM, localisation et cartographie simultan\u00e9es, en robotique ; prix du meilleur article \u00e0 la Conference on Computer Vision and Pattern Recognition 1998), a caract\u00e9ris\u00e9 ses ambigu\u00eft\u00e9s (prix David Marr \u00e0 l'ICCV 1999), a \u00e9galement caract\u00e9ris\u00e9 l'identifiabilit\u00e9 et l'observabilit\u00e9 de la fusion de capteurs visuels et inertiels (prix du meilleur article \u00e0 Robotics 2015).", "token2charspan": [[0, 2], [3, 4], [5, 17], [18, 21], [22, 33], [34, 42], [43, 47], [48, 57], [58, 62], [63, 69], [70, 71], [71, 74], [74, 75], [76, 78], [79, 85], [86, 90], [90, 91], [92, 104], [105, 107], [108, 120], [121, 132], [132, 133], [134, 136], [137, 146], [147, 148], [149, 153], [154, 156], [157, 165], [166, 173], [174, 175], [176, 178], [179, 189], [190, 192], [193, 201], [202, 208], [209, 212], [213, 220], [221, 232], [233, 237], [237, 238], [238, 239], [240, 241], [242, 253], [254, 257], [258, 268], [269, 270], [270, 274], [275, 280], [281, 285], [286, 287], [288, 290], [290, 294], [295, 299], [299, 300], [300, 301], [302, 303], [304, 313], [314, 325], [326, 328], [328, 343], [344, 346], [347, 349], [349, 362], [363, 365], [366, 368], [369, 375], [376, 378], [379, 387], [388, 395], [396, 398], [399, 408], [409, 410], [410, 414], [415, 417], [418, 426], [427, 434], [435, 436], [437, 445], [446, 450], [450, 451], [451, 452]]}
{"doc_key": "ai-test-303", "ner": [[0, 2, "researcher"], [3, 3, "organisation"], [5, 5, "organisation"], [7, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Stephen", "H.", "Muggleton", "FBCS", ",", "FIET", ",", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ","], "sentence-detokenized": "Stephen H. Muggleton FBCS, FIET, Association for the Advancement of Artificial Intelligence,", "token2charspan": [[0, 7], [8, 10], [11, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 44], [45, 48], [49, 52], [53, 64], [65, 67], [68, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-304", "ner": [[0, 3, "task"], [10, 12, "field"], [15, 16, "field"], [19, 21, "field"], [30, 36, "task"], [34, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 3, 10, 12, "part-of", "task_part_of_field", false, false], [0, 3, 15, 16, "part-of", "task_part_of_field", false, false], [0, 3, 19, 21, "part-of", "task_part_of_field", false, false], [0, 3, 30, 36, "part-of", "", false, false], [0, 3, 34, 35, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["La", "d\u00e9tection", "des", "contours", "est", "un", "outil", "fondamental", "dans", "le", "traitement", "des", "images", ",", "la", "vision", "industrielle", "et", "la", "vision", "par", "ordinateur", ",", "en", "particulier", "dans", "les", "domaines", "de", "la", "d\u00e9tection", "et", "de", "l'", "extraction", "de", "caract\u00e9ristiques", "."], "sentence-detokenized": "La d\u00e9tection des contours est un outil fondamental dans le traitement des images, la vision industrielle et la vision par ordinateur, en particulier dans les domaines de la d\u00e9tection et de l'extraction de caract\u00e9ristiques.", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 25], [26, 29], [30, 32], [33, 38], [39, 50], [51, 55], [56, 58], [59, 69], [70, 73], [74, 80], [80, 81], [82, 84], [85, 91], [92, 104], [105, 107], [108, 110], [111, 117], [118, 121], [122, 132], [132, 133], [134, 136], [137, 148], [149, 153], [154, 157], [158, 166], [167, 169], [170, 172], [173, 182], [183, 185], [186, 188], [189, 191], [191, 201], [202, 204], [205, 221], [221, 222]]}
{"doc_key": "ai-test-305", "ner": [[11, 12, "misc"], [31, 34, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Il", "s'", "agit", "par", "exemple", "d'", "une", "variable", "telle", "que", "la", "temp\u00e9rature", "ext\u00e9rieure", "(", "mathtemp", "/", "math", ")", ",", "qui", ",", "dans", "une", "application", "donn\u00e9e", ",", "peut", "\u00eatre", "enregistr\u00e9e", "avec", "une", "pr\u00e9cision", "de", "plusieurs", "d\u00e9cimales", "(", "selon", "l'", "appareil", "de", "d\u00e9tection", ")", "."], "sentence-detokenized": "Il s'agit par exemple d'une variable telle que la temp\u00e9rature ext\u00e9rieure (mathtemp / math), qui, dans une application donn\u00e9e, peut \u00eatre enregistr\u00e9e avec une pr\u00e9cision de plusieurs d\u00e9cimales (selon l'appareil de d\u00e9tection).", "token2charspan": [[0, 2], [3, 5], [5, 9], [10, 13], [14, 21], [22, 24], [24, 27], [28, 36], [37, 42], [43, 46], [47, 49], [50, 61], [62, 72], [73, 74], [74, 82], [83, 84], [85, 89], [89, 90], [90, 91], [92, 95], [95, 96], [97, 101], [102, 105], [106, 117], [118, 124], [124, 125], [126, 130], [131, 135], [136, 147], [148, 152], [153, 156], [157, 166], [167, 169], [170, 179], [180, 189], [190, 191], [191, 196], [197, 199], [199, 207], [208, 210], [211, 220], [220, 221], [221, 222]]}
{"doc_key": "ai-test-306", "ner": [[5, 6, "person"], [8, 9, "person"], [11, 12, "person"], [23, 24, "person"], [29, 29, "misc"], [35, 35, "misc"], [36, 37, "person"], [44, 45, "organisation"], [41, 43, "person"], [50, 50, "organisation"], [51, 52, "person"], [55, 55, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[36, 37, 29, 29, "part-of", "", false, false], [36, 37, 35, 35, "role", "", false, false], [41, 43, 44, 45, "role", "", false, false], [51, 52, 50, 50, "role", "youtuber", false, false], [55, 55, 51, 52, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Les", "juges", "de", "retour", "sont", "Fon", "Davis", ",", "Jessica", "Chobot", "et", "Leland", "Melvin", ",", "ainsi", "que", "des", "juges", "invit\u00e9s", "c\u00e9l\u00e8bres", ":", "l'", "acteur", "Clark", "Gregg", ",", "l'", "animateur", "de", "MythBusters", "et", "l'", "ancien", "constructeur", "de", "Battlebots", "Adam", "Savage", ",", "le", "tightend", "Vernon", "Davis", "de", "la", "NFL", "et", "la", "star", "de", "YouTube", "Michael", "Stevens", "a.k.a", ".", "Vsauce", "."], "sentence-detokenized": "Les juges de retour sont Fon Davis, Jessica Chobot et Leland Melvin, ainsi que des juges invit\u00e9s c\u00e9l\u00e8bres : l'acteur Clark Gregg, l'animateur de MythBusters et l'ancien constructeur de Battlebots Adam Savage, le tightend Vernon Davis de la NFL et la star de YouTube Michael Stevens a.k.a. Vsauce.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 19], [20, 24], [25, 28], [29, 34], [34, 35], [36, 43], [44, 50], [51, 53], [54, 60], [61, 67], [67, 68], [69, 74], [75, 78], [79, 82], [83, 88], [89, 96], [97, 105], [106, 107], [108, 110], [110, 116], [117, 122], [123, 128], [128, 129], [130, 132], [132, 141], [142, 144], [145, 156], [157, 159], [160, 162], [162, 168], [169, 181], [182, 184], [185, 195], [196, 200], [201, 207], [207, 208], [209, 211], [212, 220], [221, 227], [228, 233], [234, 236], [237, 239], [240, 243], [244, 246], [247, 249], [250, 254], [255, 257], [258, 265], [266, 273], [274, 281], [282, 287], [287, 288], [289, 295], [295, 296]]}
{"doc_key": "ai-test-307", "ner": [[15, 18, "algorithm"], [20, 23, "algorithm"], [25, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 18, 25, 27, "part-of", "", false, false], [20, 23, 25, 27, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Mais", "ces", "m\u00e9thodes", "n'", "ont", "jamais", "r\u00e9ussi", "\u00e0", "s'", "imposer", "face", "\u00e0", "la", "technologie", "des", "mod\u00e8les", "de", "m\u00e9lange", "gaussien", "/", "mod\u00e8les", "de", "Markov", "cach\u00e9s", "(", "GMM-HMM", ")", "bas\u00e9s", "sur", "des", "mod\u00e8les", "g\u00e9n\u00e9ratifs", "de", "la", "parole", "entra\u00een\u00e9s", "de", "mani\u00e8re", "discriminante", "."], "sentence-detokenized": "Mais ces m\u00e9thodes n'ont jamais r\u00e9ussi \u00e0 s'imposer face \u00e0 la technologie des mod\u00e8les de m\u00e9lange gaussien / mod\u00e8les de Markov cach\u00e9s (GMM-HMM) bas\u00e9s sur des mod\u00e8les g\u00e9n\u00e9ratifs de la parole entra\u00een\u00e9s de mani\u00e8re discriminante.", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 20], [20, 23], [24, 30], [31, 37], [38, 39], [40, 42], [42, 49], [50, 54], [55, 56], [57, 59], [60, 71], [72, 75], [76, 83], [84, 86], [87, 94], [95, 103], [104, 105], [106, 113], [114, 116], [117, 123], [124, 130], [131, 132], [132, 139], [139, 140], [141, 146], [147, 150], [151, 154], [155, 162], [163, 173], [174, 176], [177, 179], [180, 186], [187, 196], [197, 199], [200, 207], [208, 221], [221, 222]]}
{"doc_key": "ai-test-308", "ner": [[3, 3, "product"], [5, 6, "programlang"], [8, 8, "programlang"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Des", "progiciels", "comme", "MATLAB", ",", "GNU", "Octave", ",", "Scilab", "et", "SciPy", "offrent", "des", "moyens", "pratiques", "d'", "appliquer", "ces", "diff\u00e9rentes", "m\u00e9thodes", "."], "sentence-detokenized": "Des progiciels comme MATLAB, GNU Octave, Scilab et SciPy offrent des moyens pratiques d'appliquer ces diff\u00e9rentes m\u00e9thodes.", "token2charspan": [[0, 3], [4, 14], [15, 20], [21, 27], [27, 28], [29, 32], [33, 39], [39, 40], [41, 47], [48, 50], [51, 56], [57, 64], [65, 68], [69, 75], [76, 85], [86, 88], [88, 97], [98, 101], [102, 113], [114, 122], [122, 123]]}
{"doc_key": "ai-test-309", "ner": [[0, 3, "algorithm"], [5, 5, "algorithm"], [11, 14, "task"], [24, 25, "researcher"], [28, 30, "university"], [32, 33, "researcher"], [35, 38, "organisation"], [40, 40, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 3, 11, 14, "related-to", "", false, false], [0, 3, 24, 25, "origin", "", false, false], [0, 3, 32, 33, "origin", "", false, false], [5, 5, 0, 3, "named", "", false, false], [24, 25, 28, 30, "physical", "", false, false], [24, 25, 28, 30, "role", "", false, false], [32, 33, 35, 38, "physical", "", false, false], [32, 33, 35, 38, "role", "", false, false], [40, 40, 35, 38, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Le", "codage", "pr\u00e9dictif", "lin\u00e9aire", "(", "LPC", ")", ",", "un", "algorithme", "de", "traitement", "de", "la", "parole", ",", "a", "\u00e9t\u00e9", "propos\u00e9", "pour", "la", "premi\u00e8re", "fois", "par", "Fumitada", "Itakura", "de", "l'", "universit\u00e9", "de", "Nagoya", "et", "Shuzo", "Saito", "de", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "en", "1966", "."], "sentence-detokenized": "Le codage pr\u00e9dictif lin\u00e9aire (LPC), un algorithme de traitement de la parole, a \u00e9t\u00e9 propos\u00e9 pour la premi\u00e8re fois par Fumitada Itakura de l'universit\u00e9 de Nagoya et Shuzo Saito de Nippon Telegraph and Telephone (NTT) en 1966.", "token2charspan": [[0, 2], [3, 9], [10, 19], [20, 28], [29, 30], [30, 33], [33, 34], [34, 35], [36, 38], [39, 49], [50, 52], [53, 63], [64, 66], [67, 69], [70, 76], [76, 77], [78, 79], [80, 83], [84, 91], [92, 96], [97, 99], [100, 108], [109, 113], [114, 117], [118, 126], [127, 134], [135, 137], [138, 140], [140, 150], [151, 153], [154, 160], [161, 163], [164, 169], [170, 175], [176, 178], [179, 185], [186, 195], [196, 199], [200, 209], [210, 211], [211, 214], [214, 215], [216, 218], [219, 223], [223, 224]]}
{"doc_key": "ai-test-310", "ner": [[23, 34, "conference"], [36, 36, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[36, 36, 23, 34, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["En", "2006", ",", "\u00e0", "l'", "occasion", "du", "25e", "anniversaire", "de", "l'", "algorithme", ",", "un", "atelier", "a", "\u00e9t\u00e9", "organis\u00e9", "dans", "le", "cadre", "de", "la", "Conf\u00e9rence", "internationale", "sur", "la", "vision", "par", "ordinateur", "et", "la", "reconnaissance", "des", "formes", "(", "CVPR", ")", "afin", "de", "r\u00e9sumer", "les", "contributions", "et", "les", "variations", "les", "plus", "r\u00e9centes", "de", "l'", "algorithme", "original", ",", "principalement", "destin\u00e9es", "\u00e0", "am\u00e9liorer", "la", "vitesse", "de", "l'", "algorithme", ",", "la", "robustesse", "et", "la", "pr\u00e9cision", "de", "la", "solution", "estim\u00e9e", "et", "\u00e0", "r\u00e9duire", "la", "d\u00e9pendance", "vis-\u00e0-vis", "des", "constantes", "d\u00e9finies", "par", "l'", "utilisateur", "."], "sentence-detokenized": "En 2006, \u00e0 l'occasion du 25e anniversaire de l'algorithme, un atelier a \u00e9t\u00e9 organis\u00e9 dans le cadre de la Conf\u00e9rence internationale sur la vision par ordinateur et la reconnaissance des formes (CVPR) afin de r\u00e9sumer les contributions et les variations les plus r\u00e9centes de l'algorithme original, principalement destin\u00e9es \u00e0 am\u00e9liorer la vitesse de l'algorithme, la robustesse et la pr\u00e9cision de la solution estim\u00e9e et \u00e0 r\u00e9duire la d\u00e9pendance vis-\u00e0-vis des constantes d\u00e9finies par l'utilisateur.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 13], [13, 21], [22, 24], [25, 28], [29, 41], [42, 44], [45, 47], [47, 57], [57, 58], [59, 61], [62, 69], [70, 71], [72, 75], [76, 84], [85, 89], [90, 92], [93, 98], [99, 101], [102, 104], [105, 115], [116, 130], [131, 134], [135, 137], [138, 144], [145, 148], [149, 159], [160, 162], [163, 165], [166, 180], [181, 184], [185, 191], [192, 193], [193, 197], [197, 198], [199, 203], [204, 206], [207, 214], [215, 218], [219, 232], [233, 235], [236, 239], [240, 250], [251, 254], [255, 259], [260, 268], [269, 271], [272, 274], [274, 284], [285, 293], [293, 294], [295, 309], [310, 319], [320, 321], [322, 331], [332, 334], [335, 342], [343, 345], [346, 348], [348, 358], [358, 359], [360, 362], [363, 373], [374, 376], [377, 379], [380, 389], [390, 392], [393, 395], [396, 404], [405, 412], [413, 415], [416, 417], [418, 425], [426, 428], [429, 439], [440, 449], [450, 453], [454, 464], [465, 473], [474, 477], [478, 480], [480, 491], [491, 492]]}
{"doc_key": "ai-test-311", "ner": [[5, 7, "university"], [10, 13, "organisation"], [16, 18, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Les", "membres", "ont", "fr\u00e9quent\u00e9", "l'", "Universit\u00e9", "de", "Debrecen", ",", "l'", "Acad\u00e9mie", "hongroise", "des", "sciences", ",", "l'", "Universit\u00e9", "E\u00f6tv\u00f6s", "Lor\u00e1nd", ",", "etc."], "sentence-detokenized": "Les membres ont fr\u00e9quent\u00e9 l'Universit\u00e9 de Debrecen, l'Acad\u00e9mie hongroise des sciences, l'Universit\u00e9 E\u00f6tv\u00f6s Lor\u00e1nd, etc.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 25], [26, 28], [28, 38], [39, 41], [42, 50], [50, 51], [52, 54], [54, 62], [63, 72], [73, 76], [77, 85], [85, 86], [87, 89], [89, 99], [100, 106], [107, 113], [113, 114], [115, 119]]}
{"doc_key": "ai-test-312", "ner": [[3, 3, "algorithm"], [18, 20, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 18, 20, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Pour", "\u00e9tendre", "le", "SVM", "aux", "cas", "o\u00f9", "les", "donn\u00e9es", "ne", "sont", "pas", "lin\u00e9airement", "s\u00e9parables", ",", "nous", "introduisons", "la", "fonction", "de", "perte", ","], "sentence-detokenized": "Pour \u00e9tendre le SVM aux cas o\u00f9 les donn\u00e9es ne sont pas lin\u00e9airement s\u00e9parables, nous introduisons la fonction de perte,", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 19], [20, 23], [24, 27], [28, 30], [31, 34], [35, 42], [43, 45], [46, 50], [51, 54], [55, 67], [68, 78], [78, 79], [80, 84], [85, 97], [98, 100], [101, 109], [110, 112], [113, 118], [118, 119]]}
{"doc_key": "ai-test-313", "ner": [[0, 2, "programlang"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 12, 13, "origin", "", false, false], [0, 2, 15, 16, "origin", "", false, false], [0, 2, 18, 19, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Logo", "est", "un", "langage", "de", "programmation", "\u00e9ducatif", ",", "con\u00e7u", "en", "1967", "par", "Wally", "Feurzeig", ",", "Seymour", "Papert", "et", "Cynthia", "Solomon", "."], "sentence-detokenized": "Logo est un langage de programmation \u00e9ducatif, con\u00e7u en 1967 par Wally Feurzeig, Seymour Papert et Cynthia Solomon.", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 19], [20, 22], [23, 36], [37, 45], [45, 46], [47, 52], [53, 55], [56, 60], [61, 64], [65, 70], [71, 79], [79, 80], [81, 88], [89, 95], [96, 98], [99, 106], [107, 114], [114, 115]]}
{"doc_key": "ai-test-314", "ner": [[0, 3, "organisation"], [11, 20, "organisation"], [23, 26, "location"], [30, 30, "location"], [34, 34, "location"], [47, 52, "product"], [59, 64, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 11, 20, "role", "works_for", false, false], [11, 20, 23, 26, "physical", "", false, false], [23, 26, 30, 30, "physical", "", false, false], [30, 30, 34, 34, "physical", "", false, false], [47, 52, 0, 3, "origin", "", false, false], [59, 64, 47, 52, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["L'", "Eyring", "Research", "Institute", "a", "jou\u00e9", "un", "r\u00f4le", "d\u00e9terminant", "pour", "la", "direction", "des", "missiles", "de", "l'", "arm\u00e9e", "de", "l'", "air", "am\u00e9ricaine", "\u00e0", "la", "base", "a\u00e9rienne", "de", "Hill", ",", "pr\u00e8s", "d'", "Ogden", ",", "dans", "l'", "Utah", ",", "en", "produisant", ",", "dans", "le", "plus", "grand", "secret", "militaire", ",", "le", "logiciel", "de", "technologie", "des", "syst\u00e8mes", "intelligents", "qui", "\u00e9tait", "\u00e0", "la", "base", "du", "programme", "Reagan", "de", "guerre", "des", "\u00e9toiles", "."], "sentence-detokenized": "L'Eyring Research Institute a jou\u00e9 un r\u00f4le d\u00e9terminant pour la direction des missiles de l'arm\u00e9e de l'air am\u00e9ricaine \u00e0 la base a\u00e9rienne de Hill, pr\u00e8s d'Ogden, dans l'Utah, en produisant, dans le plus grand secret militaire, le logiciel de technologie des syst\u00e8mes intelligents qui \u00e9tait \u00e0 la base du programme Reagan de guerre des \u00e9toiles.", "token2charspan": [[0, 2], [2, 8], [9, 17], [18, 27], [28, 29], [30, 34], [35, 37], [38, 42], [43, 54], [55, 59], [60, 62], [63, 72], [73, 76], [77, 85], [86, 88], [89, 91], [91, 96], [97, 99], [100, 102], [102, 105], [106, 116], [117, 118], [119, 121], [122, 126], [127, 135], [136, 138], [139, 143], [143, 144], [145, 149], [150, 152], [152, 157], [157, 158], [159, 163], [164, 166], [166, 170], [170, 171], [172, 174], [175, 185], [185, 186], [187, 191], [192, 194], [195, 199], [200, 205], [206, 212], [213, 222], [222, 223], [224, 226], [227, 235], [236, 238], [239, 250], [251, 254], [255, 263], [264, 276], [277, 280], [281, 286], [287, 288], [289, 291], [292, 296], [297, 299], [300, 309], [310, 316], [317, 319], [320, 326], [327, 330], [331, 338], [338, 339]]}
{"doc_key": "ai-test-315", "ner": [[17, 17, "field"], [32, 34, "researcher"], [36, 37, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Au", "fil", "des", "d\u00e9cennies", ",", "il", "a", "men\u00e9", "des", "recherches", "et", "d\u00e9velopp\u00e9", "des", "domaines", "\u00e9mergents", "de", "l'", "informatique", ",", "depuis", "les", "compilateurs", ",", "les", "langages", "de", "programmation", "et", "l'", "architecture", "des", "syst\u00e8mes", "John", "F.", "Sowa", "et", "John", "Zachman", "(", "1992", ")", "."], "sentence-detokenized": "Au fil des d\u00e9cennies, il a men\u00e9 des recherches et d\u00e9velopp\u00e9 des domaines \u00e9mergents de l'informatique, depuis les compilateurs, les langages de programmation et l'architecture des syst\u00e8mes John F. Sowa et John Zachman (1992).", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 20], [20, 21], [22, 24], [25, 26], [27, 31], [32, 35], [36, 46], [47, 49], [50, 59], [60, 63], [64, 72], [73, 82], [83, 85], [86, 88], [88, 100], [100, 101], [102, 108], [109, 112], [113, 125], [125, 126], [127, 130], [131, 139], [140, 142], [143, 156], [157, 159], [160, 162], [162, 174], [175, 178], [179, 187], [188, 192], [193, 195], [196, 200], [201, 203], [204, 208], [209, 216], [217, 218], [218, 222], [222, 223], [223, 224]]}
{"doc_key": "ai-test-316", "ner": [[0, 3, "algorithm"], [7, 9, "algorithm"], [11, 13, "algorithm"], [19, 22, "field"], [25, 27, "field"], [33, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 9, 0, 3, "named", "", false, false], [11, 13, 0, 3, "named", "", false, false], [19, 22, 0, 3, "usage", "", false, false], [25, 27, 0, 3, "usage", "", false, false], [33, 37, 0, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["L'", "op\u00e9rateur", "de", "Sobel", ",", "parfois", "appel\u00e9", "op\u00e9rateur", "de", "Sobel-Feldman", "ou", "filtre", "de", "Sobel", ",", "est", "utilis\u00e9", "dans", "le", "traitement", "de", "l'", "image", "et", "la", "vision", "par", "ordinateur", ",", "en", "particulier", "dans", "les", "algorithmes", "de", "d\u00e9tection", "des", "bords", ",", "o\u00f9", "il", "cr\u00e9e", "une", "image", "mettant", "en", "valeur", "les", "bords", "."], "sentence-detokenized": "L'op\u00e9rateur de Sobel, parfois appel\u00e9 op\u00e9rateur de Sobel-Feldman ou filtre de Sobel, est utilis\u00e9 dans le traitement de l'image et la vision par ordinateur, en particulier dans les algorithmes de d\u00e9tection des bords, o\u00f9 il cr\u00e9e une image mettant en valeur les bords.", "token2charspan": [[0, 2], [2, 11], [12, 14], [15, 20], [20, 21], [22, 29], [30, 36], [37, 46], [47, 49], [50, 63], [64, 66], [67, 73], [74, 76], [77, 82], [82, 83], [84, 87], [88, 95], [96, 100], [101, 103], [104, 114], [115, 117], [118, 120], [120, 125], [126, 128], [129, 131], [132, 138], [139, 142], [143, 153], [153, 154], [155, 157], [158, 169], [170, 174], [175, 178], [179, 190], [191, 193], [194, 203], [204, 207], [208, 213], [213, 214], [215, 217], [218, 220], [221, 225], [226, 229], [230, 235], [236, 243], [244, 246], [247, 253], [254, 257], [258, 263], [263, 264]]}
{"doc_key": "ai-test-317", "ner": [[0, 0, "algorithm"], [5, 6, "field"], [16, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 5, 6, "compare", "", false, false], [0, 0, 5, 6, "type-of", "", false, false], [0, 0, 16, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["LDA", "est", "un", "algorithme", "d'", "apprentissage", "supervis\u00e9", "qui", "utilise", "les", "\u00e9tiquettes", "des", "donn\u00e9es", ",", "tandis", "que", "PCA", "est", "un", "algorithme", "d'", "apprentissage", "qui", "ignore", "les", "\u00e9tiquettes", "."], "sentence-detokenized": "LDA est un algorithme d'apprentissage supervis\u00e9 qui utilise les \u00e9tiquettes des donn\u00e9es, tandis que PCA est un algorithme d'apprentissage qui ignore les \u00e9tiquettes.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 21], [22, 24], [24, 37], [38, 47], [48, 51], [52, 59], [60, 63], [64, 74], [75, 78], [79, 86], [86, 87], [88, 94], [95, 98], [99, 102], [103, 106], [107, 109], [110, 120], [121, 123], [123, 136], [137, 140], [141, 147], [148, 151], [152, 162], [162, 163]]}
{"doc_key": "ai-test-318", "ner": [[9, 9, "algorithm"], [12, 16, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Parmi", "les", "autres", "algorithmes", "de", "classification", "lin\u00e9aire", ",", "citons", "Winnow", ",", "la", "machine", "\u00e0", "vecteurs", "de", "support", "et", "la", "r\u00e9gression", "logistique", "."], "sentence-detokenized": "Parmi les autres algorithmes de classification lin\u00e9aire, citons Winnow, la machine \u00e0 vecteurs de support et la r\u00e9gression logistique.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 28], [29, 31], [32, 46], [47, 55], [55, 56], [57, 63], [64, 70], [70, 71], [72, 74], [75, 82], [83, 84], [85, 93], [94, 96], [97, 104], [105, 107], [108, 110], [111, 121], [122, 132], [132, 133]]}
{"doc_key": "ai-test-319", "ner": [[0, 0, "product"], [8, 10, "programlang"], [20, 22, "product"], [24, 24, "programlang"], [26, 26, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 10, "general-affiliation", "", true, false], [0, 0, 20, 22, "general-affiliation", "", true, false], [0, 0, 24, 24, "general-affiliation", "", true, false], [0, 0, 26, 26, "general-affiliation", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["VTK", "se", "compose", "d'", "une", "biblioth\u00e8que", "de", "classes", "C", "+", "+", "et", "de", "plusieurs", "couches", "d'", "interfaces", "interpr\u00e9t\u00e9es", ",", "notamment", "Tcl", "/", "Tk", ",", "Java", "et", "Python", "."], "sentence-detokenized": "VTK se compose d'une biblioth\u00e8que de classes C + + et de plusieurs couches d'interfaces interpr\u00e9t\u00e9es, notamment Tcl / Tk, Java et Python.", "token2charspan": [[0, 3], [4, 6], [7, 14], [15, 17], [17, 20], [21, 33], [34, 36], [37, 44], [45, 46], [47, 48], [49, 50], [51, 53], [54, 56], [57, 66], [67, 74], [75, 77], [77, 87], [88, 100], [100, 101], [102, 111], [112, 115], [116, 117], [118, 120], [120, 121], [122, 126], [127, 129], [130, 136], [136, 137]]}
{"doc_key": "ai-test-320", "ner": [[18, 22, "task"], [34, 37, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["De", "m\u00eame", ",", "le", "texte", "produit", "par", "le", "traitement", "de", "la", "parole", "spontan\u00e9e", "\u00e0", "l'", "aide", "de", "la", "reconnaissance", "automatique", "de", "la", "parole", "et", "le", "texte", "imprim\u00e9", "ou", "manuscrit", "\u00e0", "l'", "aide", "de", "la", "reconnaissance", "optique", "des", "caract\u00e8res", "contient", "du", "bruit", "de", "traitement", "."], "sentence-detokenized": "De m\u00eame, le texte produit par le traitement de la parole spontan\u00e9e \u00e0 l'aide de la reconnaissance automatique de la parole et le texte imprim\u00e9 ou manuscrit \u00e0 l'aide de la reconnaissance optique des caract\u00e8res contient du bruit de traitement.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 17], [18, 25], [26, 29], [30, 32], [33, 43], [44, 46], [47, 49], [50, 56], [57, 66], [67, 68], [69, 71], [71, 75], [76, 78], [79, 81], [82, 96], [97, 108], [109, 111], [112, 114], [115, 121], [122, 124], [125, 127], [128, 133], [134, 141], [142, 144], [145, 154], [155, 156], [157, 159], [159, 163], [164, 166], [167, 169], [170, 184], [185, 192], [193, 196], [197, 207], [208, 216], [217, 219], [220, 225], [226, 228], [229, 239], [239, 240]]}
{"doc_key": "ai-test-321", "ner": [[0, 1, "researcher"], [11, 11, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 11, 11, "role", "directs_development_of", false, false]], "relations_mapping_to_source": [0], "sentence": ["Miller", "a", "\u00e9crit", "plusieurs", "livres", "et", "a", "dirig\u00e9", "le", "d\u00e9veloppement", "de", "WordNet", ",", "une", "base", "de", "donn\u00e9es", "en", "ligne", "de", "liens", "entre", "les", "mots", ",", "utilisable", "par", "les", "programmes", "informatiques", "."], "sentence-detokenized": "Miller a \u00e9crit plusieurs livres et a dirig\u00e9 le d\u00e9veloppement de WordNet, une base de donn\u00e9es en ligne de liens entre les mots, utilisable par les programmes informatiques.", "token2charspan": [[0, 6], [7, 8], [9, 14], [15, 24], [25, 31], [32, 34], [35, 36], [37, 43], [44, 46], [47, 60], [61, 63], [64, 71], [71, 72], [73, 76], [77, 81], [82, 84], [85, 92], [93, 95], [96, 101], [102, 104], [105, 110], [111, 116], [117, 120], [121, 125], [125, 126], [127, 137], [138, 141], [142, 145], [146, 156], [157, 170], [170, 171]]}
{"doc_key": "ai-test-322", "ner": [[0, 1, "field"], [9, 11, "organisation"], [13, 13, "country"], [15, 16, "person"], [18, 20, "person"], [22, 23, "person"], [25, 26, "person"], [28, 28, "country"], [30, 33, "location"], [36, 37, "misc"], [38, 39, "person"], [42, 43, "person"], [45, 45, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[9, 11, 13, 13, "physical", "", false, false], [15, 16, 28, 28, "physical", "", false, false], [18, 20, 28, 28, "physical", "", false, false], [22, 23, 28, 28, "physical", "", false, false], [25, 26, 28, 28, "physical", "", false, false], [30, 33, 0, 1, "general-affiliation", "", false, false], [30, 33, 38, 39, "artifact", "", false, false], [36, 37, 38, 39, "named", "", false, false], [42, 43, 45, 45, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Les", "automates", "contemporains", "sont", "repr\u00e9sent\u00e9s", "par", "les", "\u0153uvres", "de", "Cabaret", "Mechanical", "Theatre", "au", "Royaume-Uni", ",", "Dug", "North", "et", "Chomick", "+", "Meder", ",", "Arthur", "Ganson", ",", "Joe", "Jones", "aux", "\u00c9tats-Unis", ",", "Le", "D\u00e9fenseur", "du", "Temps", "de", "l'", "artiste", "fran\u00e7ais", "Jacques", "Monestier", ",", "et", "Fran\u00e7ois", "Junod", "en", "Suisse", "."], "sentence-detokenized": "Les automates contemporains sont repr\u00e9sent\u00e9s par les \u0153uvres de Cabaret Mechanical Theatre au Royaume-Uni, Dug North et Chomick + Meder, Arthur Ganson, Joe Jones aux \u00c9tats-Unis, Le D\u00e9fenseur du Temps de l'artiste fran\u00e7ais Jacques Monestier, et Fran\u00e7ois Junod en Suisse.", "token2charspan": [[0, 3], [4, 13], [14, 27], [28, 32], [33, 44], [45, 48], [49, 52], [53, 59], [60, 62], [63, 70], [71, 81], [82, 89], [90, 92], [93, 104], [104, 105], [106, 109], [110, 115], [116, 118], [119, 126], [127, 128], [129, 134], [134, 135], [136, 142], [143, 149], [149, 150], [151, 154], [155, 160], [161, 164], [165, 175], [175, 176], [177, 179], [180, 189], [190, 192], [193, 198], [199, 201], [202, 204], [204, 211], [212, 220], [221, 228], [229, 238], [238, 239], [240, 242], [243, 251], [252, 257], [258, 260], [261, 267], [267, 268]]}
{"doc_key": "ai-test-323", "ner": [[0, 0, "product"], [23, 23, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 23, 23, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MATLAB", "comprend", "des", "boucles", "standard", "codefor", "/", "code", "et", "codewhile", "/", "code", ",", "mais", "(", "comme", "dans", "d'", "autres", "applications", "similaires", "telles", "que", "R", ")", ",", "l'", "utilisation", "de", "la", "notation", "vectorielle", "est", "encourag\u00e9e", "et", "est", "souvent", "plus", "rapide", "\u00e0", "ex\u00e9cuter", "."], "sentence-detokenized": "MATLAB comprend des boucles standard codefor / code et codewhile / code, mais (comme dans d'autres applications similaires telles que R), l'utilisation de la notation vectorielle est encourag\u00e9e et est souvent plus rapide \u00e0 ex\u00e9cuter.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 27], [28, 36], [37, 44], [45, 46], [47, 51], [52, 54], [55, 64], [65, 66], [67, 71], [71, 72], [73, 77], [78, 79], [79, 84], [85, 89], [90, 92], [92, 98], [99, 111], [112, 122], [123, 129], [130, 133], [134, 135], [135, 136], [136, 137], [138, 140], [140, 151], [152, 154], [155, 157], [158, 166], [167, 178], [179, 182], [183, 193], [194, 196], [197, 200], [201, 208], [209, 213], [214, 220], [221, 222], [223, 231], [231, 232]]}
{"doc_key": "ai-test-324", "ner": [[0, 2, "researcher"], [8, 11, "conference"], [21, 25, "field"], [28, 33, "misc"], [36, 45, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 28, 33, "win-defeat", "", false, false], [0, 2, 36, 45, "win-defeat", "", false, false], [28, 33, 8, 11, "temporal", "", false, false], [28, 33, 21, 25, "topic", "", false, false], [36, 45, 8, 11, "temporal", "", false, false], [36, 45, 21, 25, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["M.", "Pausch", "a", "re\u00e7u", "deux", "prix", "de", "l'", "Association", "for", "Computing", "Machinery", "en", "2007", "pour", "ses", "r\u00e9alisations", "dans", "le", "domaine", "de", "l'", "enseignement", "de", "l'", "informatique", ":", "le", "Karl", "V.", "Karlstrom", "Outstanding", "Educator", "Award", "et", "l'", "ACM", "SIGCSE", "Award", "for", "Outstanding", "Contributions", "to", "Computer", "Science", "Education", "."], "sentence-detokenized": "M. Pausch a re\u00e7u deux prix de l'Association for Computing Machinery en 2007 pour ses r\u00e9alisations dans le domaine de l'enseignement de l'informatique : le Karl V. Karlstrom Outstanding Educator Award et l'ACM SIGCSE Award for Outstanding Contributions to Computer Science Education.", "token2charspan": [[0, 2], [3, 9], [10, 11], [12, 16], [17, 21], [22, 26], [27, 29], [30, 32], [32, 43], [44, 47], [48, 57], [58, 67], [68, 70], [71, 75], [76, 80], [81, 84], [85, 97], [98, 102], [103, 105], [106, 113], [114, 116], [117, 119], [119, 131], [132, 134], [135, 137], [137, 149], [150, 151], [152, 154], [155, 159], [160, 162], [163, 172], [173, 184], [185, 193], [194, 199], [200, 202], [203, 205], [205, 208], [209, 215], [216, 221], [222, 225], [226, 237], [238, 251], [252, 254], [255, 263], [264, 271], [272, 281], [281, 282]]}
{"doc_key": "ai-test-325", "ner": [[3, 4, "person"], [10, 10, "product"], [9, 9, "product"], [19, 20, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 10, 10, "role", "sells", false, false], [10, 10, 9, 9, "general-affiliation", "", false, false], [10, 10, 19, 20, "physical", "shipped_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["En", "1960", ",", "Devol", "a", "personnellement", "vendu", "le", "premier", "robot", "Unimate", ",", "qui", "a", "\u00e9t\u00e9", "exp\u00e9di\u00e9", "en", "1961", "\u00e0", "General", "Motors", "."], "sentence-detokenized": "En 1960, Devol a personnellement vendu le premier robot Unimate, qui a \u00e9t\u00e9 exp\u00e9di\u00e9 en 1961 \u00e0 General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 16], [17, 32], [33, 38], [39, 41], [42, 49], [50, 55], [56, 63], [63, 64], [65, 68], [69, 70], [71, 74], [75, 82], [83, 85], [86, 90], [91, 92], [93, 100], [101, 107], [107, 108]]}
{"doc_key": "ai-test-326", "ner": [[0, 2, "algorithm"], [9, 12, "field"], [16, 17, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 17, 0, 2, "usage", "", false, false], [16, 17, 9, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Les", "r\u00e9seaux", "s\u00e9mantiques", "sont", "utilis\u00e9s", "dans", "des", "applications", "de", "traitement", "du", "langage", "naturel", "telles", "que", "l'", "analyse", "s\u00e9mantique", "."], "sentence-detokenized": "Les r\u00e9seaux s\u00e9mantiques sont utilis\u00e9s dans des applications de traitement du langage naturel telles que l'analyse s\u00e9mantique.", "token2charspan": [[0, 3], [4, 11], [12, 23], [24, 28], [29, 37], [38, 42], [43, 46], [47, 59], [60, 62], [63, 73], [74, 76], [77, 84], [85, 92], [93, 99], [100, 103], [104, 106], [106, 113], [114, 124], [124, 125]]}
{"doc_key": "ai-test-327", "ner": [[5, 6, "field"], [9, 11, "field"], [14, 15, "task"], [17, 18, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 28, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 11, 5, 6, "usage", "", false, false], [14, 15, 5, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Certaines", "applications", "r\u00e9ussies", "de", "l'", "apprentissage", "profond", "sont", "la", "vision", "par", "ordinateur", "et", "la", "reconnaissance", "vocale", ".", "Honglak", "Lee", ",", "Roger", "Grosse", ",", "Rajesh", "Ranganath", ",", "Andrew", "Y.", "Ng", "."], "sentence-detokenized": "Certaines applications r\u00e9ussies de l'apprentissage profond sont la vision par ordinateur et la reconnaissance vocale. Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng.", "token2charspan": [[0, 9], [10, 22], [23, 31], [32, 34], [35, 37], [37, 50], [51, 58], [59, 63], [64, 66], [67, 73], [74, 77], [78, 88], [89, 91], [92, 94], [95, 109], [110, 116], [116, 117], [118, 125], [126, 129], [129, 130], [131, 136], [137, 143], [143, 144], [145, 151], [152, 161], [161, 162], [163, 169], [170, 172], [173, 175], [175, 176]]}
{"doc_key": "ai-test-328", "ner": [[4, 9, "product"], [15, 15, "misc"], [18, 18, "misc"], [24, 24, "product"], [28, 30, "task"], [33, 35, "task"], [38, 40, "task"], [43, 46, "field"], [49, 52, "task"], [55, 57, "field"], [60, 61, "task"], [64, 65, "task"], [68, 71, "task"], [74, 76, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 9, 15, 15, "physical", "travels_to", false, false], [4, 9, 18, 18, "physical", "travels_to", false, false], [24, 24, 4, 9, "part-of", "", false, false], [24, 24, 4, 9, "role", "maintains", false, false], [24, 24, 28, 30, "related-to", "has_ability_to", false, false], [24, 24, 33, 35, "related-to", "has_ability_to", false, false], [24, 24, 38, 40, "related-to", "has_ability_to", false, false], [24, 24, 43, 46, "related-to", "has_ability_to", false, false], [24, 24, 49, 52, "related-to", "has_ability_to", false, false], [24, 24, 55, 57, "related-to", "has_ability_to", false, false], [24, 24, 60, 61, "related-to", "has_ability_to", false, false], [24, 24, 64, 65, "related-to", "has_ability_to", false, false], [24, 24, 68, 71, "related-to", "has_ability_to", false, false], [24, 24, 74, 76, "related-to", "has_ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Outre", "la", "maintenance", "des", "syst\u00e8mes", "du", "vaisseau", "spatial", "Discovery", "One", "pendant", "la", "mission", "interplan\u00e9taire", "vers", "Jupiter", "(", "ou", "Saturne", "dans", "le", "roman", ")", ",", "HAL", "est", "capable", "de", "synth\u00e9tiser", "la", "parole", ",", "de", "reconna\u00eetre", "la", "parole", ",", "de", "reconna\u00eetre", "le", "visage", ",", "de", "traiter", "le", "langage", "naturel", ",", "de", "lire", "sur", "les", "l\u00e8vres", ",", "d'", "appr\u00e9cier", "l'", "art", ",", "l'", "informatique", "affective", ",", "le", "raisonnement", "automatis\u00e9", ",", "de", "piloter", "un", "vaisseau", "spatial", "et", "de", "jouer", "aux", "\u00e9checs", "."], "sentence-detokenized": "Outre la maintenance des syst\u00e8mes du vaisseau spatial Discovery One pendant la mission interplan\u00e9taire vers Jupiter (ou Saturne dans le roman), HAL est capable de synth\u00e9tiser la parole, de reconna\u00eetre la parole, de reconna\u00eetre le visage, de traiter le langage naturel, de lire sur les l\u00e8vres, d'appr\u00e9cier l'art, l'informatique affective, le raisonnement automatis\u00e9, de piloter un vaisseau spatial et de jouer aux \u00e9checs.", "token2charspan": [[0, 5], [6, 8], [9, 20], [21, 24], [25, 33], [34, 36], [37, 45], [46, 53], [54, 63], [64, 67], [68, 75], [76, 78], [79, 86], [87, 102], [103, 107], [108, 115], [116, 117], [117, 119], [120, 127], [128, 132], [133, 135], [136, 141], [141, 142], [142, 143], [144, 147], [148, 151], [152, 159], [160, 162], [163, 174], [175, 177], [178, 184], [184, 185], [186, 188], [189, 200], [201, 203], [204, 210], [210, 211], [212, 214], [215, 226], [227, 229], [230, 236], [236, 237], [238, 240], [241, 248], [249, 251], [252, 259], [260, 267], [267, 268], [269, 271], [272, 276], [277, 280], [281, 284], [285, 291], [291, 292], [293, 295], [295, 304], [305, 307], [307, 310], [310, 311], [312, 314], [314, 326], [327, 336], [336, 337], [338, 340], [341, 353], [354, 364], [364, 365], [366, 368], [369, 376], [377, 379], [380, 388], [389, 396], [397, 399], [400, 402], [403, 408], [409, 412], [413, 419], [419, 420]]}
{"doc_key": "ai-test-329", "ner": [[0, 3, "researcher"], [6, 6, "country"], [9, 9, "country"], [13, 14, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 6, 6, "physical", "", false, false], [0, 3, 9, 9, "physical", "", false, false], [0, 3, 13, 14, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Le", "Dr", "Julesz", "a", "\u00e9migr\u00e9", "de", "Hongrie", "vers", "les", "\u00c9tats-Unis", "apr\u00e8s", "l'", "invasion", "sovi\u00e9tique", "de", "1956", "."], "sentence-detokenized": "Le Dr Julesz a \u00e9migr\u00e9 de Hongrie vers les \u00c9tats-Unis apr\u00e8s l'invasion sovi\u00e9tique de 1956.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 14], [15, 21], [22, 24], [25, 32], [33, 37], [38, 41], [42, 52], [53, 58], [59, 61], [61, 69], [70, 80], [81, 83], [84, 88], [88, 89]]}
{"doc_key": "ai-test-330", "ner": [[5, 7, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Les", "fonctions", "d'", "activation", "de", "la", "fonction", "sigmo\u00efde", "utilisent", "une", "seconde", "non-lin\u00e9arit\u00e9", "pour", "les", "grandes", "entr\u00e9es", ":", "math", "\\", "phi", "(", "v", "_", "i", ")", "=", "(", "1", "+", "\\", "exp", "(", "-v", "_", "i", ")", ")", "^", "{", "-1}", "/", "math", "."], "sentence-detokenized": "Les fonctions d'activation de la fonction sigmo\u00efde utilisent une seconde non-lin\u00e9arit\u00e9 pour les grandes entr\u00e9es : math\\ phi (v _ i) = (1 +\\ exp (-v _ i)) ^ {-1} / math.", "token2charspan": [[0, 3], [4, 13], [14, 16], [16, 26], [27, 29], [30, 32], [33, 41], [42, 50], [51, 60], [61, 64], [65, 72], [73, 86], [87, 91], [92, 95], [96, 103], [104, 111], [112, 113], [114, 118], [118, 119], [120, 123], [124, 125], [125, 126], [127, 128], [129, 130], [130, 131], [132, 133], [134, 135], [135, 136], [137, 138], [138, 139], [140, 143], [144, 145], [145, 147], [148, 149], [150, 151], [151, 152], [152, 153], [154, 155], [156, 157], [157, 160], [161, 162], [163, 167], [167, 168]]}
{"doc_key": "ai-test-331", "ner": [[14, 18, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ces", "probabilit\u00e9s", "sont", "utilis\u00e9es", "pour", "d\u00e9terminer", "ce", "qu'", "est", "la", "cible", "en", "utilisant", "une", "d\u00e9cision", "de", "maximum", "de", "vraisemblance", "."], "sentence-detokenized": "Ces probabilit\u00e9s sont utilis\u00e9es pour d\u00e9terminer ce qu'est la cible en utilisant une d\u00e9cision de maximum de vraisemblance.", "token2charspan": [[0, 3], [4, 16], [17, 21], [22, 31], [32, 36], [37, 47], [48, 50], [51, 54], [54, 57], [58, 60], [61, 66], [67, 69], [70, 79], [80, 83], [84, 92], [93, 95], [96, 103], [104, 106], [107, 120], [120, 121]]}
{"doc_key": "ai-test-332", "ner": [[8, 10, "university"], [16, 18, "university"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["En", "1984", ",", "il", "est", "pass\u00e9", "\u00e0", "l'", "universit\u00e9", "de", "Constance", "et", "en", "1990", "\u00e0", "l'", "universit\u00e9", "de", "Salzbourg", "."], "sentence-detokenized": "En 1984, il est pass\u00e9 \u00e0 l'universit\u00e9 de Constance et en 1990 \u00e0 l'universit\u00e9 de Salzbourg.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 21], [22, 23], [24, 26], [26, 36], [37, 39], [40, 49], [50, 52], [53, 55], [56, 60], [61, 62], [63, 65], [65, 75], [76, 78], [79, 88], [88, 89]]}
{"doc_key": "ai-test-333", "ner": [[9, 11, "metrics"], [14, 16, "metrics"], [19, 21, "metrics"], [24, 25, "metrics"], [28, 30, "metrics"], [33, 37, "metrics"], [40, 44, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[14, 16, 9, 11, "origin", "based_on", false, false], [19, 21, 9, 11, "origin", "based_on", false, false], [24, 25, 9, 11, "origin", "based_on", false, false], [28, 30, 9, 11, "origin", "based_on", false, false], [33, 37, 9, 11, "origin", "based_on", false, false], [40, 44, 9, 11, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Parmi", "les", "fonctions", "d'", "aptitude", "populaires", "bas\u00e9es", "sur", "la", "matrice", "de", "confusion", "figurent", "la", "sensibilit\u00e9", "/", "sp\u00e9cificit\u00e9", ",", "le", "rappel", "/", "pr\u00e9cision", ",", "la", "mesure", "F", ",", "la", "similarit\u00e9", "de", "Jaccard", ",", "le", "coefficient", "de", "corr\u00e9lation", "de", "Matthews", "et", "la", "matrice", "des", "co\u00fbts", "/", "gains", "qui", "combine", "les", "co\u00fbts", "et", "les", "gains", "attribu\u00e9s", "aux", "4", "diff\u00e9rents", "types", "de", "classifications", "."], "sentence-detokenized": "Parmi les fonctions d'aptitude populaires bas\u00e9es sur la matrice de confusion figurent la sensibilit\u00e9/sp\u00e9cificit\u00e9, le rappel/pr\u00e9cision, la mesure F, la similarit\u00e9 de Jaccard, le coefficient de corr\u00e9lation de Matthews et la matrice des co\u00fbts/gains qui combine les co\u00fbts et les gains attribu\u00e9s aux 4 diff\u00e9rents types de classifications.", "token2charspan": [[0, 5], [6, 9], [10, 19], [20, 22], [22, 30], [31, 41], [42, 48], [49, 52], [53, 55], [56, 63], [64, 66], [67, 76], [77, 85], [86, 88], [89, 100], [100, 101], [101, 112], [112, 113], [114, 116], [117, 123], [123, 124], [124, 133], [133, 134], [135, 137], [138, 144], [145, 146], [146, 147], [148, 150], [151, 161], [162, 164], [165, 172], [172, 173], [174, 176], [177, 188], [189, 191], [192, 203], [204, 206], [207, 215], [216, 218], [219, 221], [222, 229], [230, 233], [234, 239], [239, 240], [240, 245], [246, 249], [250, 257], [258, 261], [262, 267], [268, 270], [271, 274], [275, 280], [281, 290], [291, 294], [295, 296], [297, 307], [308, 313], [314, 316], [317, 332], [332, 333]]}
{"doc_key": "ai-test-334", "ner": [[8, 8, "product"], [10, 10, "product"], [12, 12, "product"], [14, 14, "product"], [17, 18, "programlang"], [35, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[35, 38, 8, 8, "part-of", "", false, false], [35, 38, 10, 10, "part-of", "", false, false], [35, 38, 12, 12, "part-of", "", false, false], [35, 38, 14, 14, "part-of", "", false, false], [35, 38, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Les", "environnements", "de", "programmation", "num\u00e9rique", "courants", "tels", "que", "MATLAB", ",", "SciLab", ",", "NumPy", ",", "Sklearn", "et", "le", "langage", "R", "fournissent", "certaines", "des", "techniques", "d'", "extraction", "de", "caract\u00e9ristiques", "les", "plus", "simples", "(", "par", "exemple", ",", "l'", "analyse", "en", "composantes", "principales", ")", "via", "des", "commandes", "int\u00e9gr\u00e9es", "."], "sentence-detokenized": "Les environnements de programmation num\u00e9rique courants tels que MATLAB, SciLab, NumPy, Sklearn et le langage R fournissent certaines des techniques d'extraction de caract\u00e9ristiques les plus simples (par exemple, l'analyse en composantes principales) via des commandes int\u00e9gr\u00e9es.", "token2charspan": [[0, 3], [4, 18], [19, 21], [22, 35], [36, 45], [46, 54], [55, 59], [60, 63], [64, 70], [70, 71], [72, 78], [78, 79], [80, 85], [85, 86], [87, 94], [95, 97], [98, 100], [101, 108], [109, 110], [111, 122], [123, 132], [133, 136], [137, 147], [148, 150], [150, 160], [161, 163], [164, 180], [181, 184], [185, 189], [190, 197], [198, 199], [199, 202], [203, 210], [210, 211], [212, 214], [214, 221], [222, 224], [225, 236], [237, 248], [248, 249], [250, 253], [254, 257], [258, 267], [268, 277], [277, 278]]}
{"doc_key": "ai-test-335", "ner": [[0, 2, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Les", "robots", "industriels", "ont", "\u00e9t\u00e9", "mis", "en", "\u0153uvre", "pour", "collaborer", "avec", "les", "humains", "afin", "d'", "effectuer", "des", "t\u00e2ches", "de", "fabrication", "industrielle", "."], "sentence-detokenized": "Les robots industriels ont \u00e9t\u00e9 mis en \u0153uvre pour collaborer avec les humains afin d'effectuer des t\u00e2ches de fabrication industrielle.", "token2charspan": [[0, 3], [4, 10], [11, 22], [23, 26], [27, 30], [31, 34], [35, 37], [38, 43], [44, 48], [49, 59], [60, 64], [65, 68], [69, 76], [77, 81], [82, 84], [84, 93], [94, 97], [98, 104], [105, 107], [108, 119], [120, 132], [132, 133]]}
{"doc_key": "ai-test-336", "ner": [[7, 7, "field"], [9, 11, "researcher"], [22, 23, "field"], [26, 26, "field"], [29, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 7, 22, 23, "related-to", "", false, false], [7, 7, 26, 26, "related-to", "", false, false], [7, 7, 29, 30, "related-to", "", false, false], [9, 11, 7, 7, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Dans", "le", "premier", "article", "publi\u00e9", "sur", "les", "CG", ",", "John", "F.", "Sowa", "les", "a", "appliqu\u00e9es", "\u00e0", "un", "large", "\u00e9ventail", "de", "sujets", "en", "intelligence", "artificielle", ",", "en", "informatique", "et", "en", "sciences", "cognitives", "."], "sentence-detokenized": "Dans le premier article publi\u00e9 sur les CG, John F. Sowa les a appliqu\u00e9es \u00e0 un large \u00e9ventail de sujets en intelligence artificielle, en informatique et en sciences cognitives.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 23], [24, 30], [31, 34], [35, 38], [39, 41], [41, 42], [43, 47], [48, 50], [51, 55], [56, 59], [60, 61], [62, 72], [73, 74], [75, 77], [78, 83], [84, 92], [93, 95], [96, 102], [103, 105], [106, 118], [119, 131], [131, 132], [133, 135], [136, 148], [149, 151], [152, 154], [155, 163], [164, 174], [174, 175]]}
{"doc_key": "ai-test-337", "ner": [[0, 1, "metrics"], [5, 5, "metrics"], [11, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 5, 5, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Le", "NIST", "diff\u00e8re", "\u00e9galement", "du", "BLEU", "dans", "son", "calcul", "de", "la", "p\u00e9nalit\u00e9", "de", "bri\u00e8vet\u00e9", ",", "dans", "la", "mesure", "o\u00f9", "de", "petites", "variations", "de", "la", "longueur", "de", "la", "traduction", "n'", "ont", "pas", "un", "impact", "aussi", "important", "sur", "le", "score", "global", "."], "sentence-detokenized": "Le NIST diff\u00e8re \u00e9galement du BLEU dans son calcul de la p\u00e9nalit\u00e9 de bri\u00e8vet\u00e9, dans la mesure o\u00f9 de petites variations de la longueur de la traduction n'ont pas un impact aussi important sur le score global.", "token2charspan": [[0, 2], [3, 7], [8, 15], [16, 25], [26, 28], [29, 33], [34, 38], [39, 42], [43, 49], [50, 52], [53, 55], [56, 64], [65, 67], [68, 76], [76, 77], [78, 82], [83, 85], [86, 92], [93, 95], [96, 98], [99, 106], [107, 117], [118, 120], [121, 123], [124, 132], [133, 135], [136, 138], [139, 149], [150, 152], [152, 155], [156, 159], [160, 162], [163, 169], [170, 175], [176, 185], [186, 189], [190, 192], [193, 198], [199, 205], [205, 206]]}
{"doc_key": "ai-test-338", "ner": [[0, 9, "misc"], [21, 21, "conference"], [26, 27, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 9, 21, 21, "temporal", "", false, false], [0, 9, 26, 27, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Le", "prix", "d'", "excellence", "de", "la", "recherche", "de", "l'", "IJCAI", "est", "un", "prix", "semestriel", "d\u00e9cern\u00e9", "lors", "de", "la", "conf\u00e9rence", "de", "l'", "IJCAI", "\u00e0", "des", "chercheurs", "en", "intelligence", "artificielle", "en", "reconnaissance", "de", "l'", "excellence", "de", "leur", "carri\u00e8re", "."], "sentence-detokenized": "Le prix d'excellence de la recherche de l'IJCAI est un prix semestriel d\u00e9cern\u00e9 lors de la conf\u00e9rence de l'IJCAI \u00e0 des chercheurs en intelligence artificielle en reconnaissance de l'excellence de leur carri\u00e8re.", "token2charspan": [[0, 2], [3, 7], [8, 10], [10, 20], [21, 23], [24, 26], [27, 36], [37, 39], [40, 42], [42, 47], [48, 51], [52, 54], [55, 59], [60, 70], [71, 78], [79, 83], [84, 86], [87, 89], [90, 100], [101, 103], [104, 106], [106, 111], [112, 113], [114, 117], [118, 128], [129, 131], [132, 144], [145, 157], [158, 160], [161, 175], [176, 178], [179, 181], [181, 191], [192, 194], [195, 199], [200, 208], [208, 209]]}
{"doc_key": "ai-test-339", "ner": [[0, 2, "researcher"], [11, 13, "conference"], [21, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 11, 13, "role", "", false, false], [0, 2, 21, 28, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["M.", "Lenat", "a", "\u00e9t\u00e9", "l'", "un", "des", "premiers", "membres", "de", "l'", "AAAI", "et", "est", "la", "seule", "personne", "\u00e0", "avoir", "si\u00e9g\u00e9", "aux", "conseils", "consultatifs", "scientifiques", "de", "Microsoft", "et", "d'", "Apple", "."], "sentence-detokenized": "M. Lenat a \u00e9t\u00e9 l'un des premiers membres de l'AAAI et est la seule personne \u00e0 avoir si\u00e9g\u00e9 aux conseils consultatifs scientifiques de Microsoft et d'Apple.", "token2charspan": [[0, 2], [3, 8], [9, 10], [11, 14], [15, 17], [17, 19], [20, 23], [24, 32], [33, 40], [41, 43], [44, 46], [46, 50], [51, 53], [54, 57], [58, 60], [61, 66], [67, 75], [76, 77], [78, 83], [84, 89], [90, 93], [94, 102], [103, 115], [116, 129], [130, 132], [133, 142], [143, 145], [146, 148], [148, 153], [153, 154]]}
{"doc_key": "ai-test-340", "ner": [[1, 1, "algorithm"], [7, 9, "misc"], [14, 16, "metrics"], [21, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 7, 9, "related-to", "minimise", false, false], [14, 16, 7, 9, "type-of", "", false, false], [21, 21, 7, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Les", "autoencodeurs", "sont", "entra\u00een\u00e9s", "\u00e0", "minimiser", "les", "erreurs", "de", "reconstruction", "(", "telles", "que", "l'", "erreur", "quadratique", "moyenne", ")", ",", "souvent", "appel\u00e9es", "pertes", ":"], "sentence-detokenized": "Les autoencodeurs sont entra\u00een\u00e9s \u00e0 minimiser les erreurs de reconstruction (telles que l'erreur quadratique moyenne), souvent appel\u00e9es pertes :", "token2charspan": [[0, 3], [4, 17], [18, 22], [23, 32], [33, 34], [35, 44], [45, 48], [49, 56], [57, 59], [60, 74], [75, 76], [76, 82], [83, 86], [87, 89], [89, 95], [96, 107], [108, 115], [115, 116], [116, 117], [118, 125], [126, 134], [135, 141], [142, 143]]}
{"doc_key": "ai-test-341", "ner": [[35, 38, "misc"], [42, 42, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[42, 42, 35, 38, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Une", "alternative", "\u00e0", "l'", "utilisation", "des", "d\u00e9finitions", "est", "de", "consid\u00e9rer", "la", "parent\u00e9", "g\u00e9n\u00e9rale", "entre", "les", "sens", "des", "mots", "et", "de", "calculer", "la", "similarit\u00e9", "de", "chaque", "paire", "de", "sens", "de", "mots", "en", "se", "basant", "sur", "une", "base", "de", "connaissances", "lexicales", "donn\u00e9e", "telle", "que", "WordNet", "."], "sentence-detokenized": "Une alternative \u00e0 l'utilisation des d\u00e9finitions est de consid\u00e9rer la parent\u00e9 g\u00e9n\u00e9rale entre les sens des mots et de calculer la similarit\u00e9 de chaque paire de sens de mots en se basant sur une base de connaissances lexicales donn\u00e9e telle que WordNet.", "token2charspan": [[0, 3], [4, 15], [16, 17], [18, 20], [20, 31], [32, 35], [36, 47], [48, 51], [52, 54], [55, 65], [66, 68], [69, 76], [77, 85], [86, 91], [92, 95], [96, 100], [101, 104], [105, 109], [110, 112], [113, 115], [116, 124], [125, 127], [128, 138], [139, 141], [142, 148], [149, 154], [155, 157], [158, 162], [163, 165], [166, 170], [171, 173], [174, 176], [177, 183], [184, 187], [188, 191], [192, 196], [197, 199], [200, 213], [214, 223], [224, 230], [231, 236], [237, 240], [241, 248], [248, 249]]}
{"doc_key": "ai-test-342", "ner": [[0, 0, "algorithm"], [8, 12, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 12, "origin", "", false, false], [8, 12, 18, 19, "role", "work_based_on_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["TD-Lambda", "est", "un", "algorithme", "d'", "apprentissage", "invent\u00e9", "par", "Richard", "S.", "Sutton", "sur", "la", "base", "de", "travaux", "ant\u00e9rieurs", "d'", "Arthur", "Samuel", "sur", "l'", "apprentissage", "par", "diff\u00e9rence", "temporelle", "."], "sentence-detokenized": "TD-Lambda est un algorithme d'apprentissage invent\u00e9 par Richard S. Sutton sur la base de travaux ant\u00e9rieurs d'Arthur Samuel sur l'apprentissage par diff\u00e9rence temporelle.", "token2charspan": [[0, 9], [10, 13], [14, 16], [17, 27], [28, 30], [30, 43], [44, 51], [52, 55], [56, 63], [64, 66], [67, 73], [74, 77], [78, 80], [81, 85], [86, 88], [89, 96], [97, 107], [108, 110], [110, 116], [117, 123], [124, 127], [128, 130], [130, 143], [144, 147], [148, 158], [159, 169], [169, 170]]}
{"doc_key": "ai-test-343", "ner": [[5, 7, "field"], [10, 10, "field"], [13, 14, "task"], [18, 21, "task"], [23, 23, "task"], [29, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 14, 5, 7, "part-of", "task_part_of_field", false, false], [13, 14, 10, 10, "part-of", "task_part_of_field", false, false], [18, 21, 13, 14, "named", "", false, false], [23, 23, 13, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Dans", "le", "domaine", "de", "l'", "extraction", "de", "donn\u00e9es", "et", "des", "statistiques", ",", "le", "regroupement", "hi\u00e9rarchique", "(", "\u00e9galement", "appel\u00e9", "analyse", "hi\u00e9rarchique", "des", "clusters", "ou", "HCA", ")", "est", "une", "m\u00e9thode", "d'", "analyse", "des", "clusters", "qui", "vise", "\u00e0", "construire", "une", "hi\u00e9rarchie", "de", "clusters", "."], "sentence-detokenized": "Dans le domaine de l'extraction de donn\u00e9es et des statistiques, le regroupement hi\u00e9rarchique (\u00e9galement appel\u00e9 analyse hi\u00e9rarchique des clusters ou HCA) est une m\u00e9thode d'analyse des clusters qui vise \u00e0 construire une hi\u00e9rarchie de clusters.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 21], [21, 31], [32, 34], [35, 42], [43, 45], [46, 49], [50, 62], [62, 63], [64, 66], [67, 79], [80, 92], [93, 94], [94, 103], [104, 110], [111, 118], [119, 131], [132, 135], [136, 144], [145, 147], [148, 151], [151, 152], [153, 156], [157, 160], [161, 168], [169, 171], [171, 178], [179, 182], [183, 191], [192, 195], [196, 200], [201, 202], [203, 213], [214, 217], [218, 228], [229, 231], [232, 240], [240, 241]]}
{"doc_key": "ai-test-344", "ner": [[3, 3, "algorithm"], [11, 13, "field"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 11, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Le", "concept", "de", "d\u00e9convolution", "est", "largement", "utilis\u00e9", "dans", "les", "techniques", "de", "traitement", "du", "signal", "et", "des", "images", "."], "sentence-detokenized": "Le concept de d\u00e9convolution est largement utilis\u00e9 dans les techniques de traitement du signal et des images.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 27], [28, 31], [32, 41], [42, 49], [50, 54], [55, 58], [59, 69], [70, 72], [73, 83], [84, 86], [87, 93], [94, 96], [97, 100], [101, 107], [107, 108]]}
{"doc_key": "ai-test-345", "ner": [[0, 2, "algorithm"], [30, 31, "misc"], [36, 36, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 30, 31, "related-to", "enhances", false, false], [0, 2, 30, 31, "related-to", "reduces", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Les", "cartes", "cognitives", "servent", "\u00e0", "la", "construction", "et", "\u00e0", "l'", "accumulation", "de", "connaissances", "spatiales", ",", "permettant", "\u00e0", "l'", "\u0153il", "de", "l'", "esprit", "de", "visualiser", "des", "images", "afin", "de", "r\u00e9duire", "la", "charge", "cognitive", ",", "d'", "am\u00e9liorer", "le", "rappel", "et", "l'", "apprentissage", "des", "informations", "."], "sentence-detokenized": "Les cartes cognitives servent \u00e0 la construction et \u00e0 l'accumulation de connaissances spatiales, permettant \u00e0 l'\u0153il de l'esprit de visualiser des images afin de r\u00e9duire la charge cognitive, d'am\u00e9liorer le rappel et l'apprentissage des informations.", "token2charspan": [[0, 3], [4, 10], [11, 21], [22, 29], [30, 31], [32, 34], [35, 47], [48, 50], [51, 52], [53, 55], [55, 67], [68, 70], [71, 84], [85, 94], [94, 95], [96, 106], [107, 108], [109, 111], [111, 114], [115, 117], [118, 120], [120, 126], [127, 129], [130, 140], [141, 144], [145, 151], [152, 156], [157, 159], [160, 167], [168, 170], [171, 177], [178, 187], [187, 188], [189, 191], [191, 200], [201, 203], [204, 210], [211, 213], [214, 216], [216, 229], [230, 233], [234, 246], [246, 247]]}
{"doc_key": "ai-test-346", "ner": [[11, 11, "programlang"], [13, 15, "programlang"], [17, 17, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["(", "qui", "fournit", "g\u00e9n\u00e9ralement", "des", "liaisons", "avec", "des", "langages", "tels", "que", "Python", ",", "C", "+", "+", ",", "Java", ")", "."], "sentence-detokenized": "(qui fournit g\u00e9n\u00e9ralement des liaisons avec des langages tels que Python, C + +, Java).", "token2charspan": [[0, 1], [1, 4], [5, 12], [13, 25], [26, 29], [30, 38], [39, 43], [44, 47], [48, 56], [57, 61], [62, 65], [66, 72], [72, 73], [74, 75], [76, 77], [78, 79], [79, 80], [81, 85], [85, 86], [86, 87]]}
{"doc_key": "ai-test-347", "ner": [[1, 3, "product"], [5, 5, "product"], [22, 23, "task"], [31, 33, "task"], [38, 39, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 3, 22, 23, "usage", "", false, false], [1, 3, 31, 33, "usage", "", false, false], [1, 3, 38, 39, "usage", "", false, false], [5, 5, 1, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Une", "interface", "utilisateur", "vocale", "(", "VUI", ")", "rend", "possible", "l'", "interaction", "orale", "entre", "l'", "homme", "et", "l'", "ordinateur", ",", "en", "utilisant", "la", "reconnaissance", "vocale", "pour", "comprendre", "les", "commandes", "vocales", "et", "les", "r\u00e9ponses", "aux", "questions", ",", "et", "g\u00e9n\u00e9ralement", "la", "synth\u00e8se", "vocale", "pour", "lire", "une", "r\u00e9ponse", "."], "sentence-detokenized": "Une interface utilisateur vocale (VUI) rend possible l'interaction orale entre l'homme et l'ordinateur, en utilisant la reconnaissance vocale pour comprendre les commandes vocales et les r\u00e9ponses aux questions, et g\u00e9n\u00e9ralement la synth\u00e8se vocale pour lire une r\u00e9ponse.", "token2charspan": [[0, 3], [4, 13], [14, 25], [26, 32], [33, 34], [34, 37], [37, 38], [39, 43], [44, 52], [53, 55], [55, 66], [67, 72], [73, 78], [79, 81], [81, 86], [87, 89], [90, 92], [92, 102], [102, 103], [104, 106], [107, 116], [117, 119], [120, 134], [135, 141], [142, 146], [147, 157], [158, 161], [162, 171], [172, 179], [180, 182], [183, 186], [187, 195], [196, 199], [200, 209], [209, 210], [211, 213], [214, 226], [227, 229], [230, 238], [239, 245], [246, 250], [251, 255], [256, 259], [260, 267], [267, 268]]}
{"doc_key": "ai-test-348", "ner": [[0, 0, "programlang"], [3, 5, "misc"], [9, 9, "programlang"], [15, 16, "researcher"], [18, 19, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 5, "general-affiliation", "is_a", false, false], [0, 0, 9, 9, "general-affiliation", "made_with", false, false], [0, 0, 15, 16, "origin", "", false, false], [15, 16, 18, 19, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Jess", "est", "un", "moteur", "de", "r\u00e8gles", "pour", "la", "plate-forme", "Java", "qui", "a", "\u00e9t\u00e9", "d\u00e9velopp\u00e9", "par", "Ernest", "Friedman-Hill", "de", "Sandia", "National", "."], "sentence-detokenized": "Jess est un moteur de r\u00e8gles pour la plate-forme Java qui a \u00e9t\u00e9 d\u00e9velopp\u00e9 par Ernest Friedman-Hill de Sandia National.", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 18], [19, 21], [22, 28], [29, 33], [34, 36], [37, 48], [49, 53], [54, 57], [58, 59], [60, 63], [64, 73], [74, 77], [78, 84], [85, 98], [99, 101], [102, 108], [109, 117], [117, 118]]}
{"doc_key": "ai-test-349", "ner": [[2, 3, "algorithm"], [19, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 19, 19, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Pour", "les", "perceptrons", "multicouches", ",", "o\u00f9", "il", "existe", "une", "couche", "cach\u00e9e", ",", "des", "algorithmes", "plus", "sophistiqu\u00e9s", "tels", "que", "la", "r\u00e9tropropagation", "doivent", "\u00eatre", "utilis\u00e9s", "."], "sentence-detokenized": "Pour les perceptrons multicouches, o\u00f9 il existe une couche cach\u00e9e, des algorithmes plus sophistiqu\u00e9s tels que la r\u00e9tropropagation doivent \u00eatre utilis\u00e9s.", "token2charspan": [[0, 4], [5, 8], [9, 20], [21, 33], [33, 34], [35, 37], [38, 40], [41, 47], [48, 51], [52, 58], [59, 65], [65, 66], [67, 70], [71, 82], [83, 87], [88, 100], [101, 105], [106, 109], [110, 112], [113, 129], [130, 137], [138, 142], [143, 151], [151, 152]]}
{"doc_key": "ai-test-350", "ner": [[7, 8, "product"], [1, 6, "product"], [12, 18, "algorithm"], [24, 25, "field"], [30, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 6, 7, 8, "part-of", "", false, false], [1, 6, 12, 18, "usage", "", false, true], [12, 18, 24, 25, "related-to", "performs", false, false], [30, 35, 24, 25, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Le", "syst\u00e8me", "de", "traduction", "automatique", "neuronal", "de", "Google", "Translate", "utilise", "un", "vaste", "r\u00e9seau", "neuronal", "artificiel", "de", "bout", "en", "bout", "qui", "tente", "de", "r\u00e9aliser", "un", "apprentissage", "profond", ",", "en", "particulier", "des", "r\u00e9seaux", "\u00e0", "m\u00e9moire", "\u00e0", "long", "terme", "."], "sentence-detokenized": "Le syst\u00e8me de traduction automatique neuronal de Google Translate utilise un vaste r\u00e9seau neuronal artificiel de bout en bout qui tente de r\u00e9aliser un apprentissage profond, en particulier des r\u00e9seaux \u00e0 m\u00e9moire \u00e0 long terme.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 24], [25, 36], [37, 45], [46, 48], [49, 55], [56, 65], [66, 73], [74, 76], [77, 82], [83, 89], [90, 98], [99, 109], [110, 112], [113, 117], [118, 120], [121, 125], [126, 129], [130, 135], [136, 138], [139, 147], [148, 150], [151, 164], [165, 172], [172, 173], [174, 176], [177, 188], [189, 192], [193, 200], [201, 202], [203, 210], [211, 212], [213, 217], [218, 223], [223, 224]]}
{"doc_key": "ai-test-351", "ner": [[19, 19, "researcher"], [21, 21, "researcher"], [23, 23, "researcher"], [25, 26, "researcher"], [28, 29, "researcher"], [31, 31, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Diverses", "m\u00e9thodes", "pour", "ce", "faire", "ont", "\u00e9t\u00e9", "d\u00e9velopp\u00e9es", "dans", "les", "ann\u00e9es", "1980", "et", "au", "d\u00e9but", "des", "ann\u00e9es", "1990", "par", "Werbos", ",", "Williams", ",", "Robinson", ",", "J\u00fcrgen", "Schmidhuber", ",", "Sepp", "Hochreiter", ",", "Pearlmutter", "et", "d'", "autres", "."], "sentence-detokenized": "Diverses m\u00e9thodes pour ce faire ont \u00e9t\u00e9 d\u00e9velopp\u00e9es dans les ann\u00e9es 1980 et au d\u00e9but des ann\u00e9es 1990 par Werbos, Williams, Robinson, J\u00fcrgen Schmidhuber, Sepp Hochreiter, Pearlmutter et d'autres.", "token2charspan": [[0, 8], [9, 17], [18, 22], [23, 25], [26, 31], [32, 35], [36, 39], [40, 51], [52, 56], [57, 60], [61, 67], [68, 72], [73, 75], [76, 78], [79, 84], [85, 88], [89, 95], [96, 100], [101, 104], [105, 111], [111, 112], [113, 121], [121, 122], [123, 131], [131, 132], [133, 139], [140, 151], [151, 152], [153, 157], [158, 168], [168, 169], [170, 181], [182, 184], [185, 187], [187, 193], [193, 194]]}
{"doc_key": "ai-test-352", "ner": [[5, 7, "organisation"], [12, 13, "organisation"], [18, 19, "task"], [24, 24, "product"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [[24, 24, 18, 19, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [3], "sentence": ["|", "\u00c0", "l'", "origine", ",", "Apple", "Inc.", "a", "acquis", "une", "licence", "de", "Nuance", "pour", "fournir", "une", "fonction", "de", "reconnaissance", "vocale", "\u00e0", "son", "assistant", "num\u00e9rique", "Siri", "."], "sentence-detokenized": "| \u00c0 l'origine, Apple Inc. a acquis une licence de Nuance pour fournir une fonction de reconnaissance vocale \u00e0 son assistant num\u00e9rique Siri.", "token2charspan": [[0, 1], [2, 3], [4, 6], [6, 13], [13, 14], [15, 20], [21, 25], [26, 27], [28, 34], [35, 38], [39, 46], [47, 49], [50, 56], [57, 61], [62, 69], [70, 73], [74, 82], [83, 85], [86, 100], [101, 107], [108, 109], [110, 113], [114, 123], [124, 133], [134, 138], [138, 139]]}
{"doc_key": "ai-test-353", "ner": [[0, 0, "organisation"], [4, 6, "misc"], [9, 10, "person"], [14, 15, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 6, "role", "releases_movies_in_genre", false, false], [9, 10, 0, 0, "role", "directs_for", false, false], [14, 15, 0, 0, "role", "directs_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Columbia", "a", "sorti", "plusieurs", "westerns", "en", "3D", "produits", "par", "Sam", "Katzman", "et", "r\u00e9alis\u00e9s", "par", "William", "Castle", "."], "sentence-detokenized": "Columbia a sorti plusieurs westerns en 3D produits par Sam Katzman et r\u00e9alis\u00e9s par William Castle.", "token2charspan": [[0, 8], [9, 10], [11, 16], [17, 26], [27, 35], [36, 38], [39, 41], [42, 50], [51, 54], [55, 58], [59, 66], [67, 69], [70, 78], [79, 82], [83, 90], [91, 97], [97, 98]]}
{"doc_key": "ai-test-354", "ner": [[12, 12, "field"], [16, 16, "field"], [19, 20, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Il", "int\u00e8gre", "des", "connaissances", "et", "des", "recherches", "dans", "les", "domaines", "de", "l'", "informatique", ",", "de", "la", "linguistique", "et", "du", "g\u00e9nie", "informatique", "."], "sentence-detokenized": "Il int\u00e8gre des connaissances et des recherches dans les domaines de l'informatique, de la linguistique et du g\u00e9nie informatique.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 28], [29, 31], [32, 35], [36, 46], [47, 51], [52, 55], [56, 64], [65, 67], [68, 70], [70, 82], [82, 83], [84, 86], [87, 89], [90, 102], [103, 105], [106, 108], [109, 114], [115, 127], [127, 128]]}
{"doc_key": "ai-test-355", "ner": [[5, 5, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Voici", "un", "exemple", "de", "code", "R", ":"], "sentence-detokenized": "Voici un exemple de code R :", "token2charspan": [[0, 5], [6, 8], [9, 16], [17, 19], [20, 24], [25, 26], [27, 28]]}
{"doc_key": "ai-test-356", "ner": [[0, 2, "metrics"], [8, 11, "metrics"], [13, 13, "metrics"], [18, 21, "metrics"], [23, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 8, 11, "part-of", "plotted_into", false, false], [0, 2, 18, 21, "part-of", "plotted_into", false, false], [13, 13, 8, 11, "named", "", false, false], [23, 23, 18, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["La", "courbe", "ROC", "est", "cr\u00e9\u00e9e", "en", "tra\u00e7ant", "le", "taux", "de", "VRAIS", "positifs", "(", "TPR", ")", "par", "rapport", "au", "taux", "de", "FAUX", "positifs", "(", "FPR", ")", "\u00e0", "diff\u00e9rents", "seuils", "."], "sentence-detokenized": "La courbe ROC est cr\u00e9\u00e9e en tra\u00e7ant le taux de VRAIS positifs (TPR) par rapport au taux de FAUX positifs (FPR) \u00e0 diff\u00e9rents seuils.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 17], [18, 23], [24, 26], [27, 34], [35, 37], [38, 42], [43, 45], [46, 51], [52, 60], [61, 62], [62, 65], [65, 66], [67, 70], [71, 78], [79, 81], [82, 86], [87, 89], [90, 94], [95, 103], [104, 105], [105, 108], [108, 109], [110, 111], [112, 122], [123, 129], [129, 130]]}
{"doc_key": "ai-test-357", "ner": [[9, 10, "field"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 14, 9, 10, "related-to", "researches_field", false, false], [16, 17, 9, 10, "related-to", "researches_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "recherche", "a", "stagn\u00e9", "apr\u00e8s", "les", "recherches", "sur", "l'", "apprentissage", "automatique", "men\u00e9es", "par", "Marvin", "Minsky", "et", "Seymour", "Papert", "(", "1969", ")", ","], "sentence-detokenized": "La recherche a stagn\u00e9 apr\u00e8s les recherches sur l'apprentissage automatique men\u00e9es par Marvin Minsky et Seymour Papert (1969),", "token2charspan": [[0, 2], [3, 12], [13, 14], [15, 21], [22, 27], [28, 31], [32, 42], [43, 46], [47, 49], [49, 62], [63, 74], [75, 81], [82, 85], [86, 92], [93, 99], [100, 102], [103, 110], [111, 117], [118, 119], [119, 123], [123, 124], [124, 125]]}
{"doc_key": "ai-test-358", "ner": [[11, 11, "task"], [15, 16, "programlang"], [18, 21, "product"], [23, 24, "programlang"], [26, 26, "product"], [28, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 15, 16, "related-to", "used_to_build", false, false], [11, 11, 18, 21, "related-to", "used_to_build", false, false], [11, 11, 23, 24, "related-to", "used_to_build", false, false], [11, 11, 26, 26, "related-to", "used_to_build", false, false], [11, 11, 28, 28, "related-to", "used_to_build", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["D'", "autres", "environnements", "de", "programmation", "sont", "utilis\u00e9s", "pour", "cr\u00e9er", "des", "applications", "DAQ", ",", "notamment", "la", "logique", "Ladder", ",", "Visual", "C", "+", "+", ",", "Visual", "Basic", ",", "LabVIEW", "et", "MATLAB", "."], "sentence-detokenized": "D'autres environnements de programmation sont utilis\u00e9s pour cr\u00e9er des applications DAQ, notamment la logique Ladder, Visual C + +, Visual Basic, LabVIEW et MATLAB.", "token2charspan": [[0, 2], [2, 8], [9, 23], [24, 26], [27, 40], [41, 45], [46, 54], [55, 59], [60, 65], [66, 69], [70, 82], [83, 86], [86, 87], [88, 97], [98, 100], [101, 108], [109, 115], [115, 116], [117, 123], [124, 125], [126, 127], [128, 129], [129, 130], [131, 137], [138, 143], [143, 144], [145, 152], [153, 155], [156, 162], [162, 163]]}
{"doc_key": "ai-test-359", "ner": [[13, 14, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Cette", "m\u00e9trique", "a", "\u00e9t\u00e9", "con\u00e7ue", "pour", "r\u00e9soudre", "certains", "des", "probl\u00e8mes", "rencontr\u00e9s", "dans", "la", "m\u00e9trique", "BLEU", ",", "plus", "populaire", ",", "et", "pour", "produire", "une", "bonne", "corr\u00e9lation", "avec", "le", "jugement", "humain", "au", "niveau", "de", "la", "phrase", "ou", "du", "segment", "."], "sentence-detokenized": "Cette m\u00e9trique a \u00e9t\u00e9 con\u00e7ue pour r\u00e9soudre certains des probl\u00e8mes rencontr\u00e9s dans la m\u00e9trique BLEU, plus populaire, et pour produire une bonne corr\u00e9lation avec le jugement humain au niveau de la phrase ou du segment.", "token2charspan": [[0, 5], [6, 14], [15, 16], [17, 20], [21, 27], [28, 32], [33, 41], [42, 50], [51, 54], [55, 64], [65, 75], [76, 80], [81, 83], [84, 92], [93, 97], [97, 98], [99, 103], [104, 113], [113, 114], [115, 117], [118, 122], [123, 131], [132, 135], [136, 141], [142, 153], [154, 158], [159, 161], [162, 170], [171, 177], [178, 180], [181, 187], [188, 190], [191, 193], [194, 200], [201, 203], [204, 206], [207, 214], [214, 215]]}
{"doc_key": "ai-test-360", "ner": [[5, 8, "algorithm"], [11, 13, "algorithm"], [16, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Des", "techniques", "telles", "que", "les", "r\u00e9seaux", "de", "Markov", "dynamiques", ",", "les", "r\u00e9seaux", "neuronaux", "convolutionnels", "et", "la", "m\u00e9moire", "\u00e0", "long", "terme", "sont", "souvent", "utilis\u00e9es", "pour", "exploiter", "les", "corr\u00e9lations", "s\u00e9mantiques", "entre", "des", "images", "vid\u00e9o", "cons\u00e9cutives", "."], "sentence-detokenized": "Des techniques telles que les r\u00e9seaux de Markov dynamiques, les r\u00e9seaux neuronaux convolutionnels et la m\u00e9moire \u00e0 long terme sont souvent utilis\u00e9es pour exploiter les corr\u00e9lations s\u00e9mantiques entre des images vid\u00e9o cons\u00e9cutives.", "token2charspan": [[0, 3], [4, 14], [15, 21], [22, 25], [26, 29], [30, 37], [38, 40], [41, 47], [48, 58], [58, 59], [60, 63], [64, 71], [72, 81], [82, 97], [98, 100], [101, 103], [104, 111], [112, 113], [114, 118], [119, 124], [125, 129], [130, 137], [138, 147], [148, 152], [153, 162], [163, 166], [167, 179], [180, 191], [192, 197], [198, 201], [202, 208], [209, 214], [215, 227], [227, 228]]}
{"doc_key": "ai-test-361", "ner": [[2, 4, "product"], [6, 6, "product"], [17, 18, "product"], [24, 24, "product"], [43, 43, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 17, 18, "artifact", "", false, false], [2, 4, 43, 43, "named", "", false, false], [6, 6, 2, 4, "named", "", false, false], [24, 24, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Les", "cartes", "de", "circuits", "imprim\u00e9s", "(", "PCB", ")", "produites", "en", "masse", "sont", "presque", "exclusivement", "fabriqu\u00e9es", "par", "des", "robots", "pick-and-place", ",", "g\u00e9n\u00e9ralement", "\u00e9quip\u00e9s", "de", "manipulateurs", "SCARA", ",", "qui", "pr\u00e9l\u00e8vent", "de", "minuscules", "composants", "\u00e9lectroniques", "sur", "des", "bandes", "ou", "des", "plateaux", "et", "les", "placent", "sur", "les", "PCB", "avec", "une", "grande", "pr\u00e9cision", "."], "sentence-detokenized": "Les cartes de circuits imprim\u00e9s (PCB) produites en masse sont presque exclusivement fabriqu\u00e9es par des robots pick-and-place, g\u00e9n\u00e9ralement \u00e9quip\u00e9s de manipulateurs SCARA, qui pr\u00e9l\u00e8vent de minuscules composants \u00e9lectroniques sur des bandes ou des plateaux et les placent sur les PCB avec une grande pr\u00e9cision.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 22], [23, 31], [32, 33], [33, 36], [36, 37], [38, 47], [48, 50], [51, 56], [57, 61], [62, 69], [70, 83], [84, 94], [95, 98], [99, 102], [103, 109], [110, 124], [124, 125], [126, 138], [139, 146], [147, 149], [150, 163], [164, 169], [169, 170], [171, 174], [175, 184], [185, 187], [188, 198], [199, 209], [210, 223], [224, 227], [228, 231], [232, 238], [239, 241], [242, 245], [246, 254], [255, 257], [258, 261], [262, 269], [270, 273], [274, 277], [278, 281], [282, 286], [287, 290], [291, 297], [298, 307], [307, 308]]}
{"doc_key": "ai-test-362", "ner": [[5, 6, "field"], [18, 18, "algorithm"], [24, 25, "researcher"], [27, 28, "researcher"], [30, 32, "researcher"], [40, 41, "algorithm"], [44, 46, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[18, 18, 5, 6, "part-of", "", false, false], [18, 18, 24, 25, "origin", "", false, false], [18, 18, 27, 28, "origin", "", false, false], [18, 18, 30, 32, "origin", "", false, false], [18, 18, 40, 41, "type-of", "", false, false], [40, 41, 44, 46, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Dans", "le", "contexte", "de", "l'", "apprentissage", "automatique", ",", "o\u00f9", "il", "est", "le", "plus", "largement", "appliqu\u00e9", "aujourd'hui", ",", "le", "LDA", "a", "\u00e9t\u00e9", "red\u00e9couvert", "ind\u00e9pendamment", "par", "David", "Blei", ",", "Andrew", "Ng", "et", "Michael", "I.", "Jordan", "en", "2003", ",", "et", "pr\u00e9sent\u00e9", "comme", "un", "mod\u00e8le", "graphique", "pour", "la", "d\u00e9couverte", "de", "sujets", "."], "sentence-detokenized": "Dans le contexte de l'apprentissage automatique, o\u00f9 il est le plus largement appliqu\u00e9 aujourd'hui, le LDA a \u00e9t\u00e9 red\u00e9couvert ind\u00e9pendamment par David Blei, Andrew Ng et Michael I. Jordan en 2003, et pr\u00e9sent\u00e9 comme un mod\u00e8le graphique pour la d\u00e9couverte de sujets.", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 19], [20, 22], [22, 35], [36, 47], [47, 48], [49, 51], [52, 54], [55, 58], [59, 61], [62, 66], [67, 76], [77, 85], [86, 97], [97, 98], [99, 101], [102, 105], [106, 107], [108, 111], [112, 123], [124, 138], [139, 142], [143, 148], [149, 153], [153, 154], [155, 161], [162, 164], [165, 167], [168, 175], [176, 178], [179, 185], [186, 188], [189, 193], [193, 194], [195, 197], [198, 206], [207, 212], [213, 215], [216, 222], [223, 232], [233, 237], [238, 240], [241, 251], [252, 254], [255, 261], [261, 262]]}
{"doc_key": "ai-test-363", "ner": [[10, 10, "task"], [14, 15, "misc"], [18, 18, "metrics"], [21, 21, "metrics"], [24, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 10, 14, 15, "related-to", "task_across_domain", false, false]], "relations_mapping_to_source": [0], "sentence": ["Les", "performances", "mesur\u00e9es", "sur", "les", "donn\u00e9es", "de", "test", "de", "huit", "WSI", "na\u00effs", "pour", "diverses", "tauopathies", "ont", "donn\u00e9", "un", "rappel", ",", "une", "pr\u00e9cision", "et", "un", "score", "F1", "de", "0,92", ",", "0,72", "et", "0,81", ",", "respectivement", "."], "sentence-detokenized": "Les performances mesur\u00e9es sur les donn\u00e9es de test de huit WSI na\u00effs pour diverses tauopathies ont donn\u00e9 un rappel, une pr\u00e9cision et un score F1 de 0,92, 0,72 et 0,81, respectivement.", "token2charspan": [[0, 3], [4, 16], [17, 25], [26, 29], [30, 33], [34, 41], [42, 44], [45, 49], [50, 52], [53, 57], [58, 61], [62, 67], [68, 72], [73, 81], [82, 93], [94, 97], [98, 103], [104, 106], [107, 113], [113, 114], [115, 118], [119, 128], [129, 131], [132, 134], [135, 140], [141, 143], [144, 146], [147, 151], [151, 152], [153, 157], [158, 160], [161, 165], [165, 166], [167, 181], [181, 182]]}
{"doc_key": "ai-test-364", "ner": [[5, 5, "field"], [14, 16, "field"], [22, 22, "field"], [28, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 22, 22, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["Gr\u00e2ce", "aux", "technologies", "avanc\u00e9es", "de", "RA", "(", "par", "exemple", ",", "l'", "ajout", "de", "la", "vision", "par", "ordinateur", ",", "l'", "int\u00e9gration", "de", "cam\u00e9ras", "RA", "dans", "les", "smartphones", "et", "la", "reconnaissance", "d'", "objets", ")", ",", "les", "informations", "sur", "le", "monde", "r\u00e9el", "environnant", "de", "l'", "utilisateur", "deviennent", "interactives", "et", "peuvent", "\u00eatre", "manipul\u00e9es", "num\u00e9riquement", "."], "sentence-detokenized": "Gr\u00e2ce aux technologies avanc\u00e9es de RA (par exemple, l'ajout de la vision par ordinateur, l'int\u00e9gration de cam\u00e9ras RA dans les smartphones et la reconnaissance d'objets), les informations sur le monde r\u00e9el environnant de l'utilisateur deviennent interactives et peuvent \u00eatre manipul\u00e9es num\u00e9riquement.", "token2charspan": [[0, 5], [6, 9], [10, 22], [23, 31], [32, 34], [35, 37], [38, 39], [39, 42], [43, 50], [50, 51], [52, 54], [54, 59], [60, 62], [63, 65], [66, 72], [73, 76], [77, 87], [87, 88], [89, 91], [91, 102], [103, 105], [106, 113], [114, 116], [117, 121], [122, 125], [126, 137], [138, 140], [141, 143], [144, 158], [159, 161], [161, 167], [167, 168], [168, 169], [170, 173], [174, 186], [187, 190], [191, 193], [194, 199], [200, 204], [205, 216], [217, 219], [220, 222], [222, 233], [234, 244], [245, 257], [258, 260], [261, 268], [269, 273], [274, 284], [285, 298], [298, 299]]}
{"doc_key": "ai-test-365", "ner": [[3, 4, "researcher"], [9, 9, "organisation"], [19, 20, "field"], [34, 37, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 9, 9, "role", "forms_company", false, false], [9, 9, 19, 20, "related-to", "works_with", false, false], [9, 9, 34, 37, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["En", "2014", ",", "Schmidhuber", "a", "cr\u00e9\u00e9", "une", "soci\u00e9t\u00e9", ",", "Nnaisense", ",", "pour", "travailler", "sur", "les", "applications", "commerciales", "de", "l'", "intelligence", "artificielle", "dans", "des", "domaines", "tels", "que", "la", "finance", ",", "l'", "industrie", "lourde", "et", "les", "voitures", "\u00e0", "conduite", "autonome", "."], "sentence-detokenized": "En 2014, Schmidhuber a cr\u00e9\u00e9 une soci\u00e9t\u00e9, Nnaisense, pour travailler sur les applications commerciales de l'intelligence artificielle dans des domaines tels que la finance, l'industrie lourde et les voitures \u00e0 conduite autonome.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 22], [23, 27], [28, 31], [32, 39], [39, 40], [41, 50], [50, 51], [52, 56], [57, 67], [68, 71], [72, 75], [76, 88], [89, 101], [102, 104], [105, 107], [107, 119], [120, 132], [133, 137], [138, 141], [142, 150], [151, 155], [156, 159], [160, 162], [163, 170], [170, 171], [172, 174], [174, 183], [184, 190], [191, 193], [194, 197], [198, 206], [207, 208], [209, 217], [218, 226], [226, 227]]}
{"doc_key": "ai-test-366", "ner": [[26, 29, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Non", "seulement", "cela", "alt\u00e8re", "la", "performance", "de", "tous", "les", "tests", "ult\u00e9rieurs", "sur", "le", "mod\u00e8le", "explicatif", "retenu", ",", "mais", "cela", "peut", "introduire", "un", "biais", "et", "modifier", "l'", "erreur", "quadratique", "moyenne", "de", "l'", "estimation", "."], "sentence-detokenized": "Non seulement cela alt\u00e8re la performance de tous les tests ult\u00e9rieurs sur le mod\u00e8le explicatif retenu, mais cela peut introduire un biais et modifier l'erreur quadratique moyenne de l'estimation.", "token2charspan": [[0, 3], [4, 13], [14, 18], [19, 25], [26, 28], [29, 40], [41, 43], [44, 48], [49, 52], [53, 58], [59, 69], [70, 73], [74, 76], [77, 83], [84, 94], [95, 101], [101, 102], [103, 107], [108, 112], [113, 117], [118, 128], [129, 131], [132, 137], [138, 140], [141, 149], [150, 152], [152, 158], [159, 170], [171, 178], [179, 181], [182, 184], [184, 194], [194, 195]]}
{"doc_key": "ai-test-367", "ner": [[0, 1, "misc"], [7, 8, "algorithm"], [14, 15, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 0, 1, "usage", "", false, false], [7, 8, 14, 15, "topic", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Les", "bigrammes", "sont", "utilis\u00e9s", "dans", "les", "mod\u00e8les", "de", "langage", "les", "plus", "performants", "pour", "la", "reconnaissance", "vocale", "."], "sentence-detokenized": "Les bigrammes sont utilis\u00e9s dans les mod\u00e8les de langage les plus performants pour la reconnaissance vocale.", "token2charspan": [[0, 3], [4, 13], [14, 18], [19, 27], [28, 32], [33, 36], [37, 44], [45, 47], [48, 55], [56, 59], [60, 64], [65, 76], [77, 81], [82, 84], [85, 99], [100, 106], [106, 107]]}
{"doc_key": "ai-test-368", "ner": [[3, 5, "field"], [9, 11, "misc"], [17, 19, "misc"], [25, 27, "organisation"], [30, 32, "misc"], [38, 41, "organisation"], [44, 46, "misc"], [52, 56, "organisation"], [59, 61, "misc"], [67, 69, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[9, 11, 3, 5, "topic", "", false, false], [17, 19, 25, 27, "origin", "", false, false], [30, 32, 38, 41, "origin", "", false, false], [44, 46, 52, 56, "origin", "", false, false], [59, 61, 67, 69, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Ses", "recherches", "en", "psychologie", "cognitive", "lui", "ont", "valu", "le", "Early", "Career", "Award", "(", "1984", ")", "et", "le", "Boyd", "McCandless", "Award", "(", "1986", ")", "de", "l'", "American", "Psychological", "Association", ",", "le", "Troland", "Research", "Award", "(", "1993", ")", "de", "la", "National", "Academy", "of", "Sciences", ",", "le", "Henry", "Dale", "Prize", "(", "2004", ")", "de", "la", "Royal", "Institution", "of", "Great", "Britain", "et", "le", "George", "Miller", "Prize", "(", "2010", ")", "de", "la", "Cognitive", "Neuroscience", "Society", "."], "sentence-detokenized": "Ses recherches en psychologie cognitive lui ont valu le Early Career Award (1984) et le Boyd McCandless Award (1986) de l'American Psychological Association, le Troland Research Award (1993) de la National Academy of Sciences, le Henry Dale Prize (2004) de la Royal Institution of Great Britain et le George Miller Prize (2010) de la Cognitive Neuroscience Society.", "token2charspan": [[0, 3], [4, 14], [15, 17], [18, 29], [30, 39], [40, 43], [44, 47], [48, 52], [53, 55], [56, 61], [62, 68], [69, 74], [75, 76], [76, 80], [80, 81], [82, 84], [85, 87], [88, 92], [93, 103], [104, 109], [110, 111], [111, 115], [115, 116], [117, 119], [120, 122], [122, 130], [131, 144], [145, 156], [156, 157], [158, 160], [161, 168], [169, 177], [178, 183], [184, 185], [185, 189], [189, 190], [191, 193], [194, 196], [197, 205], [206, 213], [214, 216], [217, 225], [225, 226], [227, 229], [230, 235], [236, 240], [241, 246], [247, 248], [248, 252], [252, 253], [254, 256], [257, 259], [260, 265], [266, 277], [278, 280], [281, 286], [287, 294], [295, 297], [298, 300], [301, 307], [308, 314], [315, 320], [321, 322], [322, 326], [326, 327], [328, 330], [331, 333], [334, 343], [344, 356], [357, 364], [364, 365]]}
{"doc_key": "ai-test-369", "ner": [[1, 2, "misc"], [10, 11, "misc"], [14, 17, "product"], [22, 22, "researcher"], [24, 24, "researcher"], [31, 32, "researcher"], [34, 35, "researcher"], [38, 40, "task"], [42, 45, "researcher"], [47, 50, "researcher"], [51, 52, "task"], [54, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[1, 2, 10, 11, "named", "", false, false], [1, 2, 54, 54, "named", "", false, false], [10, 11, 22, 22, "origin", "", false, false], [10, 11, 24, 24, "origin", "", false, false], [10, 11, 38, 40, "related-to", "used_for", false, false], [14, 17, 10, 11, "usage", "", false, false], [14, 17, 51, 52, "named", "", false, false], [31, 32, 10, 11, "usage", "", false, false], [31, 32, 42, 45, "named", "same", false, false], [34, 35, 10, 11, "usage", "", false, false], [34, 35, 47, 50, "named", "same", false, false], [51, 52, 54, 54, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Une", "face", "propre", "(", "L'", "approche", "consistant", "\u00e0", "utiliser", "des", "faces", "propres", "pour", "un", "syst\u00e8me", "de", "reconnaissance", "faciale", "a", "\u00e9t\u00e9", "d\u00e9velopp\u00e9e", "par", "Sirovich", "et", "Kirby", "(", "1987", ")", "et", "utilis\u00e9e", "par", "Matthew", "Turk", "et", "Alex", "Pentland", "dans", "la", "classification", "des", "visages", ".", "Turk", ",", "Matthew", "A", "et", "Pentland", ",", "Alex", "P.", "Face", "recognition", "using", "eigenfaces", "."], "sentence-detokenized": "Une face propre (L'approche consistant \u00e0 utiliser des faces propres pour un syst\u00e8me de reconnaissance faciale a \u00e9t\u00e9 d\u00e9velopp\u00e9e par Sirovich et Kirby (1987) et utilis\u00e9e par Matthew Turk et Alex Pentland dans la classification des visages. Turk, Matthew A et Pentland, Alex P. Face recognition using eigenfaces.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 17], [17, 19], [19, 27], [28, 38], [39, 40], [41, 49], [50, 53], [54, 59], [60, 67], [68, 72], [73, 75], [76, 83], [84, 86], [87, 101], [102, 109], [110, 111], [112, 115], [116, 126], [127, 130], [131, 139], [140, 142], [143, 148], [149, 150], [150, 154], [154, 155], [156, 158], [159, 167], [168, 171], [172, 179], [180, 184], [185, 187], [188, 192], [193, 201], [202, 206], [207, 209], [210, 224], [225, 228], [229, 236], [236, 237], [238, 242], [242, 243], [244, 251], [252, 253], [254, 256], [257, 265], [265, 266], [267, 271], [272, 274], [275, 279], [280, 291], [292, 297], [298, 308], [308, 309]]}
{"doc_key": "ai-test-370", "ner": [[5, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Un", "dictionnaire", "lexical", "tel", "que", "WordNet", "peut", "alors", "\u00eatre", "utilis\u00e9", "pour", "comprendre", "le", "contexte", "."], "sentence-detokenized": "Un dictionnaire lexical tel que WordNet peut alors \u00eatre utilis\u00e9 pour comprendre le contexte.", "token2charspan": [[0, 2], [3, 15], [16, 23], [24, 27], [28, 31], [32, 39], [40, 44], [45, 50], [51, 55], [56, 63], [64, 68], [69, 79], [80, 82], [83, 91], [91, 92]]}
{"doc_key": "ai-test-371", "ner": [[0, 1, "misc"], [11, 11, "misc"], [21, 21, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 11, 11, "part-of", "", false, false], [11, 11, 21, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["L'", "hyponymie", "est", "la", "relation", "la", "plus", "fr\u00e9quemment", "cod\u00e9e", "entre", "les", "synsets", "utilis\u00e9s", "dans", "les", "bases", "de", "donn\u00e9es", "lexicales", "telles", "que", "WordNet", "."], "sentence-detokenized": "L'hyponymie est la relation la plus fr\u00e9quemment cod\u00e9e entre les synsets utilis\u00e9s dans les bases de donn\u00e9es lexicales telles que WordNet.", "token2charspan": [[0, 2], [2, 11], [12, 15], [16, 18], [19, 27], [28, 30], [31, 35], [36, 47], [48, 53], [54, 59], [60, 63], [64, 71], [72, 80], [81, 85], [86, 89], [90, 95], [96, 98], [99, 106], [107, 116], [117, 123], [124, 127], [128, 135], [135, 136]]}
{"doc_key": "ai-test-372", "ner": [[0, 0, "organisation"], [6, 8, "programlang"], [10, 10, "programlang"], [48, 48, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 8, "general-affiliation", "", false, false], [0, 0, 10, 10, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["OPeNDAP", "propose", "des", "biblioth\u00e8ques", "open-source", "en", "C", "+", "+", "et", "Java", ",", "mais", "de", "nombreux", "clients", "s'", "appuient", "sur", "des", "biblioth\u00e8ques", "d\u00e9velopp\u00e9es", "par", "la", "communaut\u00e9", ",", "telles", "que", "les", "biblioth\u00e8ques", "qui", "incluent", "des", "capacit\u00e9s", "int\u00e9gr\u00e9es", "pour", "r\u00e9cup\u00e9rer", "des", "donn\u00e9es", "(", "de", "type", "tableau", ")", "\u00e0", "partir", "des", "serveurs", "DAP", "."], "sentence-detokenized": "OPeNDAP propose des biblioth\u00e8ques open-source en C + + et Java, mais de nombreux clients s'appuient sur des biblioth\u00e8ques d\u00e9velopp\u00e9es par la communaut\u00e9, telles que les biblioth\u00e8ques qui incluent des capacit\u00e9s int\u00e9gr\u00e9es pour r\u00e9cup\u00e9rer des donn\u00e9es (de type tableau) \u00e0 partir des serveurs DAP.", "token2charspan": [[0, 7], [8, 15], [16, 19], [20, 33], [34, 45], [46, 48], [49, 50], [51, 52], [53, 54], [55, 57], [58, 62], [62, 63], [64, 68], [69, 71], [72, 80], [81, 88], [89, 91], [91, 99], [100, 103], [104, 107], [108, 121], [122, 133], [134, 137], [138, 140], [141, 151], [151, 152], [153, 159], [160, 163], [164, 167], [168, 181], [182, 185], [186, 194], [195, 198], [199, 208], [209, 218], [219, 223], [224, 233], [234, 237], [238, 245], [246, 247], [247, 249], [250, 254], [255, 262], [262, 263], [264, 265], [266, 272], [273, 276], [277, 285], [286, 289], [289, 290]]}
{"doc_key": "ai-test-373", "ner": [[4, 5, "misc"], [8, 8, "product"], [24, 24, "country"], [35, 36, "misc"], [51, 51, "organisation"], [49, 49, "product"], [57, 57, "organisation"], [54, 56, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 24, 24, "opposite", "", false, false], [8, 8, 24, 24, "artifact", "", false, false], [35, 36, 8, 8, "part-of", "", false, false], [49, 49, 51, 51, "artifact", "", false, false], [54, 56, 57, 57, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Dans", "cette", "page", ",", "Samurai", "Damashii", "exag\u00e9rait", "le", "Senkousha", "en", "le", "pr\u00e9sentant", "comme", "la", "cristallisation", "des", "quatre", "mille", "ans", "de", "connaissances", "scientifiques", "de", "la", "Chine", ",", "commentait", "son", "design", "rudimentaire", "(", "par", "exemple", ",", "le", "canon", "chinois", "sur", "son", "entrejambe", ")", "et", "pla\u00e7ait", "son", "image", "parmi", "celles", "de", "l'", "ASIMO", "de", "Honda", "et", "du", "QRIO", "SDR-3X", "de", "Sony", "pour", "les", "juxtaposer", "."], "sentence-detokenized": "Dans cette page, Samurai Damashii exag\u00e9rait le Senkousha en le pr\u00e9sentant comme la cristallisation des quatre mille ans de connaissances scientifiques de la Chine, commentait son design rudimentaire (par exemple, le canon chinois sur son entrejambe) et pla\u00e7ait son image parmi celles de l'ASIMO de Honda et du QRIO SDR-3X de Sony pour les juxtaposer.", "token2charspan": [[0, 4], [5, 10], [11, 15], [15, 16], [17, 24], [25, 33], [34, 43], [44, 46], [47, 56], [57, 59], [60, 62], [63, 73], [74, 79], [80, 82], [83, 98], [99, 102], [103, 109], [110, 115], [116, 119], [120, 122], [123, 136], [137, 150], [151, 153], [154, 156], [157, 162], [162, 163], [164, 174], [175, 178], [179, 185], [186, 198], [199, 200], [200, 203], [204, 211], [211, 212], [213, 215], [216, 221], [222, 229], [230, 233], [234, 237], [238, 248], [248, 249], [250, 252], [253, 260], [261, 264], [265, 270], [271, 276], [277, 283], [284, 286], [287, 289], [289, 294], [295, 297], [298, 303], [304, 306], [307, 309], [310, 314], [315, 321], [322, 324], [325, 329], [330, 334], [335, 338], [339, 349], [349, 350]]}
{"doc_key": "ai-test-374", "ner": [[13, 14, "algorithm"], [26, 26, "product"], [28, 28, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 14, 26, 26, "part-of", "includes_functionality_of", false, false], [13, 14, 28, 28, "part-of", "includes_functionality_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Il", "existe", "\u00e9galement", "de", "nombreuses", "biblioth\u00e8ques", "de", "programmation", "qui", "contiennent", "des", "fonctionnalit\u00e9s", "de", "r\u00e9seaux", "neuronaux", "et", "qui", "peuvent", "\u00eatre", "utilis\u00e9es", "dans", "des", "impl\u00e9mentations", "personnalis\u00e9es", "(", "comme", "TensorFlow", ",", "Theano", ",", "etc.", ")", "."], "sentence-detokenized": "Il existe \u00e9galement de nombreuses biblioth\u00e8ques de programmation qui contiennent des fonctionnalit\u00e9s de r\u00e9seaux neuronaux et qui peuvent \u00eatre utilis\u00e9es dans des impl\u00e9mentations personnalis\u00e9es (comme TensorFlow, Theano, etc.).", "token2charspan": [[0, 2], [3, 9], [10, 19], [20, 22], [23, 33], [34, 47], [48, 50], [51, 64], [65, 68], [69, 80], [81, 84], [85, 100], [101, 103], [104, 111], [112, 121], [122, 124], [125, 128], [129, 136], [137, 141], [142, 151], [152, 156], [157, 160], [161, 176], [177, 191], [192, 193], [193, 198], [199, 209], [209, 210], [211, 217], [217, 218], [219, 223], [223, 224], [224, 225]]}
{"doc_key": "ai-test-375", "ner": [[5, 8, "conference"], [12, 12, "organisation"], [16, 22, "conference"], [26, 26, "conference"], [30, 30, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Il", "est", "membre", "de", "l'", "Association", "for", "Computing", "Machinery", ",", "de", "l'", "IEEE", ",", "de", "l'", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "de", "l'", "IAPR", "et", "de", "la", "SPIE", "."], "sentence-detokenized": "Il est membre de l'Association for Computing Machinery, de l'IEEE, de l'American Association for the Advancement of Science, de l'IAPR et de la SPIE.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 16], [17, 19], [19, 30], [31, 34], [35, 44], [45, 54], [54, 55], [56, 58], [59, 61], [61, 65], [65, 66], [67, 69], [70, 72], [72, 80], [81, 92], [93, 96], [97, 100], [101, 112], [113, 115], [116, 123], [123, 124], [125, 127], [128, 130], [130, 134], [135, 137], [138, 140], [141, 143], [144, 148], [148, 149]]}
{"doc_key": "ai-test-376", "ner": [[5, 5, "organisation"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 12, 13, "related-to", "runs_trials_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["Un", "essai", "r\u00e9alis\u00e9", "par", "la", "RET", "en", "2011", "avec", "des", "cam\u00e9ras", "de", "reconnaissance", "faciale", "mont\u00e9es", "sur", "les", "trams", "a", "permis", "de", "s'", "assurer", "que", "les", "personnes", "interdites", "de", "trams", "dans", "la", "ville", "ne", "se", "faufilaient", "pas", "quand", "m\u00eame", "."], "sentence-detokenized": "Un essai r\u00e9alis\u00e9 par la RET en 2011 avec des cam\u00e9ras de reconnaissance faciale mont\u00e9es sur les trams a permis de s'assurer que les personnes interdites de trams dans la ville ne se faufilaient pas quand m\u00eame.", "token2charspan": [[0, 2], [3, 8], [9, 16], [17, 20], [21, 23], [24, 27], [28, 30], [31, 35], [36, 40], [41, 44], [45, 52], [53, 55], [56, 70], [71, 78], [79, 86], [87, 90], [91, 94], [95, 100], [101, 102], [103, 109], [110, 112], [113, 115], [115, 122], [123, 126], [127, 130], [131, 140], [141, 151], [152, 154], [155, 160], [161, 165], [166, 168], [169, 174], [175, 177], [178, 180], [181, 192], [193, 196], [197, 202], [203, 207], [207, 208]]}
{"doc_key": "ai-test-377", "ner": [[10, 11, "person"], [12, 13, "organisation"], [27, 28, "person"], [30, 31, "person"], [39, 40, "person"], [42, 43, "person"], [45, 46, "person"], [48, 49, "person"], [51, 52, "person"], [54, 55, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[10, 11, 12, 13, "role", "works_for", false, false], [27, 28, 12, 13, "role", "works_for", false, false], [30, 31, 12, 13, "role", "works_for", false, false], [39, 40, 12, 13, "role", "works_for", false, false], [42, 43, 12, 13, "role", "works_for", false, false], [45, 46, 12, 13, "role", "works_for", false, false], [48, 49, 12, 13, "role", "works_for", false, false], [51, 52, 12, 13, "role", "works_for", false, false], [54, 55, 12, 13, "role", "works_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Le", "film", ",", "adapt\u00e9", "de", "la", "populaire", "com\u00e9die", "musicale", "de", "Cole", "Porter", "\u00e0", "Broadway", ",", "mettait", "en", "vedette", "l'", "\u00e9quipe", "de", "chanteurs", "de", "la", "MGM", "compos\u00e9e", "de", "Howard", "Keel", "et", "Kathryn", "Grayson", "dans", "les", "r\u00f4les", "principaux", ",", "soutenus", "par", "Ann", "Miller", ",", "Keenan", "Wynn", ",", "Bobby", "Van", ",", "James", "Whitmore", ",", "Kurt", "Kasznar", "et", "Tommy", "Rall", "."], "sentence-detokenized": "Le film, adapt\u00e9 de la populaire com\u00e9die musicale de Cole Porter \u00e0 Broadway, mettait en vedette l'\u00e9quipe de chanteurs de la MGM compos\u00e9e de Howard Keel et Kathryn Grayson dans les r\u00f4les principaux, soutenus par Ann Miller, Keenan Wynn, Bobby Van, James Whitmore, Kurt Kasznar et Tommy Rall.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 18], [19, 21], [22, 31], [32, 39], [40, 48], [49, 51], [52, 56], [57, 63], [64, 65], [66, 74], [74, 75], [76, 83], [84, 86], [87, 94], [95, 97], [97, 103], [104, 106], [107, 116], [117, 119], [120, 122], [123, 126], [127, 135], [136, 138], [139, 145], [146, 150], [151, 153], [154, 161], [162, 169], [170, 174], [175, 178], [179, 184], [185, 195], [195, 196], [197, 205], [206, 209], [210, 213], [214, 220], [220, 221], [222, 228], [229, 233], [233, 234], [235, 240], [241, 244], [244, 245], [246, 251], [252, 260], [260, 261], [262, 266], [267, 274], [275, 277], [278, 283], [284, 288], [288, 289]]}
{"doc_key": "ai-test-378", "ner": [[22, 27, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ces", "applications", "devraient", "rationaliser", "les", "flux", "d'", "appels", ",", "minimiser", "les", "invites", ",", "\u00e9liminer", "les", "it\u00e9rations", "inutiles", "et", "permettre", "l'", "\u00e9laboration", "de", "syst\u00e8mes", "de", "dialogue", "\u00e0", "initiative", "mixte", ",", "qui", "permettent", "aux", "appelants", "de", "saisir", "plusieurs", "\u00e9l\u00e9ments", "d'", "information", "en", "une", "seule", "fois", "et", "dans", "n'", "importe", "quel", "ordre", "ou", "combinaison", "."], "sentence-detokenized": "Ces applications devraient rationaliser les flux d'appels, minimiser les invites, \u00e9liminer les it\u00e9rations inutiles et permettre l'\u00e9laboration de syst\u00e8mes de dialogue \u00e0 initiative mixte, qui permettent aux appelants de saisir plusieurs \u00e9l\u00e9ments d'information en une seule fois et dans n'importe quel ordre ou combinaison.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 39], [40, 43], [44, 48], [49, 51], [51, 57], [57, 58], [59, 68], [69, 72], [73, 80], [80, 81], [82, 90], [91, 94], [95, 105], [106, 114], [115, 117], [118, 127], [128, 130], [130, 141], [142, 144], [145, 153], [154, 156], [157, 165], [166, 167], [168, 178], [179, 184], [184, 185], [186, 189], [190, 200], [201, 204], [205, 214], [215, 217], [218, 224], [225, 234], [235, 243], [244, 246], [246, 257], [258, 260], [261, 264], [265, 270], [271, 275], [276, 278], [279, 283], [284, 286], [286, 293], [294, 298], [299, 304], [305, 307], [308, 319], [319, 320]]}
{"doc_key": "ai-test-379", "ner": [[6, 8, "algorithm"], [12, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 15, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Ainsi", ",", "les", "m\u00e9thodes", "traditionnelles", "de", "descente", "de", "gradient", "(", "ou", "de", "descente", "de", "gradient", "stochastique", ")", "peuvent", "\u00eatre", "adapt\u00e9es", ",", "o\u00f9", "au", "lieu", "de", "faire", "un", "pas", "dans", "la", "direction", "du", "gradient", "de", "la", "fonction", ",", "un", "pas", "est", "fait", "dans", "la", "direction", "d'", "un", "vecteur", "s\u00e9lectionn\u00e9", "\u00e0", "partir", "du", "sous-gradient", "de", "la", "fonction", "."], "sentence-detokenized": "Ainsi, les m\u00e9thodes traditionnelles de descente de gradient (ou de descente de gradient stochastique) peuvent \u00eatre adapt\u00e9es, o\u00f9 au lieu de faire un pas dans la direction du gradient de la fonction, un pas est fait dans la direction d'un vecteur s\u00e9lectionn\u00e9 \u00e0 partir du sous-gradient de la fonction.", "token2charspan": [[0, 5], [5, 6], [7, 10], [11, 19], [20, 35], [36, 38], [39, 47], [48, 50], [51, 59], [60, 61], [61, 63], [64, 66], [67, 75], [76, 78], [79, 87], [88, 100], [100, 101], [102, 109], [110, 114], [115, 123], [123, 124], [125, 127], [128, 130], [131, 135], [136, 138], [139, 144], [145, 147], [148, 151], [152, 156], [157, 159], [160, 169], [170, 172], [173, 181], [182, 184], [185, 187], [188, 196], [196, 197], [198, 200], [201, 204], [205, 208], [209, 213], [214, 218], [219, 221], [222, 231], [232, 234], [234, 236], [237, 244], [245, 256], [257, 258], [259, 265], [266, 268], [269, 282], [283, 285], [286, 288], [289, 297], [297, 298]]}
{"doc_key": "ai-test-380", "ner": [[11, 13, "metrics"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Si", "l'", "on", "suppose", "que", "la", "distorsion", "est", "mesur\u00e9e", "par", "l'", "erreur", "quadratique", "moyenne", ",", "la", "distorsion", "D", ",", "est", "donn\u00e9e", "par", ":"], "sentence-detokenized": "Si l'on suppose que la distorsion est mesur\u00e9e par l'erreur quadratique moyenne, la distorsion D, est donn\u00e9e par :", "token2charspan": [[0, 2], [3, 5], [5, 7], [8, 15], [16, 19], [20, 22], [23, 33], [34, 37], [38, 45], [46, 49], [50, 52], [52, 58], [59, 70], [71, 78], [78, 79], [80, 82], [83, 93], [94, 95], [95, 96], [97, 100], [101, 107], [108, 111], [112, 113]]}
{"doc_key": "ai-test-381", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [23, 24, "task"], [27, 29, "task"], [34, 35, "task"], [38, 39, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 6, 7, "part-of", "", false, false], [23, 24, 0, 1, "part-of", "", false, false], [27, 29, 0, 1, "part-of", "", false, false], [34, 35, 0, 1, "part-of", "", false, false], [38, 39, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Les", "MLP", "\u00e9taient", "une", "solution", "d'", "apprentissage", "automatique", "populaire", "dans", "les", "ann\u00e9es", "1980", ",", "trouvant", "des", "applications", "dans", "divers", "domaines", "tels", "que", "la", "reconnaissance", "vocale", ",", "la", "reconnaissance", "d'", "images", "et", "les", "logiciels", "de", "traduction", "automatique", ",", "les", "r\u00e9seaux", "neuronaux", "."], "sentence-detokenized": "Les MLP \u00e9taient une solution d'apprentissage automatique populaire dans les ann\u00e9es 1980, trouvant des applications dans divers domaines tels que la reconnaissance vocale, la reconnaissance d'images et les logiciels de traduction automatique, les r\u00e9seaux neuronaux.", "token2charspan": [[0, 3], [4, 7], [8, 15], [16, 19], [20, 28], [29, 31], [31, 44], [45, 56], [57, 66], [67, 71], [72, 75], [76, 82], [83, 87], [87, 88], [89, 97], [98, 101], [102, 114], [115, 119], [120, 126], [127, 135], [136, 140], [141, 144], [145, 147], [148, 162], [163, 169], [169, 170], [171, 173], [174, 188], [189, 191], [191, 197], [198, 200], [201, 204], [205, 214], [215, 217], [218, 228], [229, 240], [240, 241], [242, 245], [246, 253], [254, 263], [263, 264]]}
{"doc_key": "ai-test-382", "ner": [[0, 1, "researcher"], [4, 4, "misc"], [7, 9, "university"], [17, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 7, 9, "physical", "", false, false], [0, 1, 7, 9, "role", "", false, false], [4, 4, 0, 1, "origin", "", false, false], [17, 19, 0, 1, "role", "supervised", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Allen", "a", "obtenu", "son", "doctorat", "de", "l'", "Universit\u00e9", "de", "Toronto", "en", "1979", ",", "sous", "la", "direction", "de", "C.", "Raymond", "Perrault", ","], "sentence-detokenized": "Allen a obtenu son doctorat de l'Universit\u00e9 de Toronto en 1979, sous la direction de C. Raymond Perrault,", "token2charspan": [[0, 5], [6, 7], [8, 14], [15, 18], [19, 27], [28, 30], [31, 33], [33, 43], [44, 46], [47, 54], [55, 57], [58, 62], [62, 63], [64, 68], [69, 71], [72, 81], [82, 84], [85, 87], [88, 95], [96, 104], [104, 105]]}
{"doc_key": "ai-test-383", "ner": [[0, 0, "product"], [5, 8, "field"], [10, 10, "product"], [12, 12, "product"], [14, 14, "product"], [21, 21, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 5, 8, "related-to", "supports", false, false], [10, 10, 5, 8, "type-of", "", true, false], [12, 12, 5, 8, "type-of", "", true, false], [14, 14, 5, 8, "type-of", "", true, false], [14, 14, 21, 21, "related-to", "converting_to", true, false], [24, 24, 5, 8, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["OpenCV", "supporte", "certains", "mod\u00e8les", "de", "cadres", "d'", "apprentissage", "profond", "comme", "TensorFlow", ",", "Torch", ",", "PyTorch", "(", "apr\u00e8s", "conversion", "en", "un", "mod\u00e8le", "ONNX", ")", "et", "Caffe", "selon", "une", "liste", "d\u00e9finie", "de", "couches", "support\u00e9es", "."], "sentence-detokenized": "OpenCV supporte certains mod\u00e8les de cadres d'apprentissage profond comme TensorFlow, Torch, PyTorch (apr\u00e8s conversion en un mod\u00e8le ONNX) et Caffe selon une liste d\u00e9finie de couches support\u00e9es.", "token2charspan": [[0, 6], [7, 15], [16, 24], [25, 32], [33, 35], [36, 42], [43, 45], [45, 58], [59, 66], [67, 72], [73, 83], [83, 84], [85, 90], [90, 91], [92, 99], [100, 101], [101, 106], [107, 117], [118, 120], [121, 123], [124, 130], [131, 135], [135, 136], [137, 139], [140, 145], [146, 151], [152, 155], [156, 161], [162, 169], [170, 172], [173, 180], [181, 191], [191, 192]]}
{"doc_key": "ai-test-384", "ner": [[2, 3, "researcher"], [9, 14, "organisation"], [16, 16, "organisation"], [24, 30, "organisation"], [32, 32, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 9, 14, "role", "", false, false], [2, 3, 24, 30, "role", "", false, false], [2, 3, 32, 32, "related-to", "lectures_in", false, false], [16, 16, 9, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Auparavant", ",", "M.", "Christensen", "\u00e9tait", "le", "pr\u00e9sident", "fondateur", "du", "r\u00e9seau", "europ\u00e9en", "de", "recherche", "en", "robotique", "(", "EURON", ")", "et", "un", "conf\u00e9rencier", "distingu\u00e9", "de", "la", "soci\u00e9t\u00e9", "de", "robotique", "et", "d'", "automatisation", "IEEE", "en", "robotique", "."], "sentence-detokenized": "Auparavant, M. Christensen \u00e9tait le pr\u00e9sident fondateur du r\u00e9seau europ\u00e9en de recherche en robotique (EURON) et un conf\u00e9rencier distingu\u00e9 de la soci\u00e9t\u00e9 de robotique et d'automatisation IEEE en robotique.", "token2charspan": [[0, 10], [10, 11], [12, 14], [15, 26], [27, 32], [33, 35], [36, 45], [46, 55], [56, 58], [59, 65], [66, 74], [75, 77], [78, 87], [88, 90], [91, 100], [101, 102], [102, 107], [107, 108], [109, 111], [112, 114], [115, 127], [128, 137], [138, 140], [141, 143], [144, 151], [152, 154], [155, 164], [165, 167], [168, 170], [170, 184], [185, 189], [190, 192], [193, 202], [202, 203]]}
{"doc_key": "ai-test-385", "ner": [[6, 6, "field"], [9, 13, "university"], [15, 15, "location"], [17, 21, "country"], [26, 26, "misc"], [28, 28, "field"], [31, 35, "organisation"], [37, 37, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[9, 13, 15, 15, "physical", "", false, false], [15, 15, 17, 21, "physical", "", false, false], [26, 26, 28, 28, "topic", "", false, false], [31, 35, 37, 37, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Il", "a", "obtenu", "sa", "ma\u00eetrise", "en", "math\u00e9matiques", "\u00e0", "l'", "universit\u00e9", "d'", "\u00c9tat", "de", "Samarkand", ",", "Samarkand", ",", "R\u00e9publique", "socialiste", "sovi\u00e9tique", "d'", "Ouzb\u00e9kistan", "en", "1958", "et", "son", "doctorat", "en", "statistiques", "\u00e0", "l'", "Institut", "des", "sciences", "du", "contr\u00f4le", ",", "Moscou", "en", "1964", "."], "sentence-detokenized": "Il a obtenu sa ma\u00eetrise en math\u00e9matiques \u00e0 l'universit\u00e9 d'\u00c9tat de Samarkand, Samarkand, R\u00e9publique socialiste sovi\u00e9tique d'Ouzb\u00e9kistan en 1958 et son doctorat en statistiques \u00e0 l'Institut des sciences du contr\u00f4le, Moscou en 1964.", "token2charspan": [[0, 2], [3, 4], [5, 11], [12, 14], [15, 23], [24, 26], [27, 40], [41, 42], [43, 45], [45, 55], [56, 58], [58, 62], [63, 65], [66, 75], [75, 76], [77, 86], [86, 87], [88, 98], [99, 109], [110, 120], [121, 123], [123, 134], [135, 137], [138, 142], [143, 145], [146, 149], [150, 158], [159, 161], [162, 174], [175, 176], [177, 179], [179, 187], [188, 191], [192, 200], [201, 203], [204, 212], [212, 213], [214, 220], [221, 223], [224, 228], [228, 229]]}
{"doc_key": "ai-test-386", "ner": [[5, 5, "organisation"], [14, 15, "product"], [39, 40, "field"], [43, 46, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 39, 40, "usage", "", false, false], [5, 5, 43, 46, "usage", "", false, false], [14, 15, 5, 5, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Cependant", ",", "le", "travail", "de", "Cycorp", "consiste", "de", "plus", "en", "plus", "\u00e0", "donner", "au", "syst\u00e8me", "Cyc", "la", "capacit\u00e9", "de", "communiquer", "avec", "les", "utilisateurs", "finaux", "en", "langage", "naturel", "et", "de", "contribuer", "au", "processus", "de", "formation", "continue", "des", "connaissances", "par", "l'", "apprentissage", "automatique", "et", "la", "compr\u00e9hension", "du", "langage", "naturel", "."], "sentence-detokenized": "Cependant, le travail de Cycorp consiste de plus en plus \u00e0 donner au syst\u00e8me Cyc la capacit\u00e9 de communiquer avec les utilisateurs finaux en langage naturel et de contribuer au processus de formation continue des connaissances par l'apprentissage automatique et la compr\u00e9hension du langage naturel.", "token2charspan": [[0, 9], [9, 10], [11, 13], [14, 21], [22, 24], [25, 31], [32, 40], [41, 43], [44, 48], [49, 51], [52, 56], [57, 58], [59, 65], [66, 68], [69, 76], [77, 80], [81, 83], [84, 92], [93, 95], [96, 107], [108, 112], [113, 116], [117, 129], [130, 136], [137, 139], [140, 147], [148, 155], [156, 158], [159, 161], [162, 172], [173, 175], [176, 185], [186, 188], [189, 198], [199, 207], [208, 211], [212, 225], [226, 229], [230, 232], [232, 245], [246, 257], [258, 260], [261, 263], [264, 277], [278, 280], [281, 288], [289, 296], [296, 297]]}
{"doc_key": "ai-test-387", "ner": [[66, 66, "metrics"], [69, 69, "metrics"], [72, 72, "metrics"], [75, 76, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Par", "exemple", ",", "si", "l'", "on", "recherche", "le", "classificateur", "le", "plus", "adapt\u00e9", "au", "probl\u00e8me", ",", "l'", "ensemble", "de", "donn\u00e9es", "d'", "apprentissage", "est", "utilis\u00e9", "pour", "entra\u00eener", "les", "algorithmes", "candidats", ",", "l'", "ensemble", "de", "donn\u00e9es", "de", "validation", "est", "utilis\u00e9", "pour", "comparer", "leurs", "performances", "et", "d\u00e9cider", "lequel", "prendre", "et", ",", "enfin", ",", "l'", "ensemble", "de", "donn\u00e9es", "de", "test", "est", "utilis\u00e9", "pour", "obtenir", "les", "caract\u00e9ristiques", "de", "performance", "telles", "que", "la", "pr\u00e9cision", ",", "la", "sensibilit\u00e9", ",", "la", "sp\u00e9cificit\u00e9", ",", "la", "mesure", "F", ",", "etc."], "sentence-detokenized": "Par exemple, si l'on recherche le classificateur le plus adapt\u00e9 au probl\u00e8me, l'ensemble de donn\u00e9es d'apprentissage est utilis\u00e9 pour entra\u00eener les algorithmes candidats, l'ensemble de donn\u00e9es de validation est utilis\u00e9 pour comparer leurs performances et d\u00e9cider lequel prendre et, enfin, l'ensemble de donn\u00e9es de test est utilis\u00e9 pour obtenir les caract\u00e9ristiques de performance telles que la pr\u00e9cision, la sensibilit\u00e9, la sp\u00e9cificit\u00e9, la mesure F, etc.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 18], [18, 20], [21, 30], [31, 33], [34, 48], [49, 51], [52, 56], [57, 63], [64, 66], [67, 75], [75, 76], [77, 79], [79, 87], [88, 90], [91, 98], [99, 101], [101, 114], [115, 118], [119, 126], [127, 131], [132, 141], [142, 145], [146, 157], [158, 167], [167, 168], [169, 171], [171, 179], [180, 182], [183, 190], [191, 193], [194, 204], [205, 208], [209, 216], [217, 221], [222, 230], [231, 236], [237, 249], [250, 252], [253, 260], [261, 267], [268, 275], [276, 278], [278, 279], [280, 285], [285, 286], [287, 289], [289, 297], [298, 300], [301, 308], [309, 311], [312, 316], [317, 320], [321, 328], [329, 333], [334, 341], [342, 345], [346, 362], [363, 365], [366, 377], [378, 384], [385, 388], [389, 391], [392, 401], [401, 402], [403, 405], [406, 417], [417, 418], [419, 421], [422, 433], [433, 434], [435, 437], [438, 444], [445, 446], [446, 447], [448, 452]]}
{"doc_key": "ai-test-388", "ner": [[1, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["L'", "erreur", "quadratique", "moyenne", "est", "de", "0,15", "."], "sentence-detokenized": "L'erreur quadratique moyenne est de 0,15.", "token2charspan": [[0, 2], [2, 8], [9, 20], [21, 28], [29, 32], [33, 35], [36, 40], [40, 41]]}
{"doc_key": "ai-test-389", "ner": [[4, 5, "misc"], [11, 11, "organisation"], [18, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 4, 5, "role", "", false, false], [18, 18, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["En", "1979", ",", "une", "comp\u00e9tition", "Micromouse", "a", "\u00e9t\u00e9", "organis\u00e9e", "par", "l'", "IEEE", ",", "comme", "le", "montre", "le", "magazine", "Spectrum", "."], "sentence-detokenized": "En 1979, une comp\u00e9tition Micromouse a \u00e9t\u00e9 organis\u00e9e par l'IEEE, comme le montre le magazine Spectrum.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 24], [25, 35], [36, 37], [38, 41], [42, 51], [52, 55], [56, 58], [58, 62], [62, 63], [64, 69], [70, 72], [73, 79], [80, 82], [83, 91], [92, 100], [100, 101]]}
{"doc_key": "ai-test-390", "ner": [[0, 3, "algorithm"], [11, 13, "field"], [17, 20, "task"], [23, 26, "task"], [29, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 11, 13, "part-of", "", false, false], [17, 20, 11, 13, "part-of", "task_part_of_field", false, false], [23, 26, 11, 13, "part-of", "task_part_of_field", false, false], [29, 32, 11, 13, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["L'", "espace", "de", "Gabor", "est", "tr\u00e8s", "utile", "dans", "les", "applications", "de", "traitement", "d'", "images", "telles", "que", "la", "reconnaissance", "optique", "des", "caract\u00e8res", ",", "la", "reconnaissance", "de", "l'", "iris", "et", "la", "reconnaissance", "des", "empreintes", "digitales", "."], "sentence-detokenized": "L'espace de Gabor est tr\u00e8s utile dans les applications de traitement d'images telles que la reconnaissance optique des caract\u00e8res, la reconnaissance de l'iris et la reconnaissance des empreintes digitales.", "token2charspan": [[0, 2], [2, 8], [9, 11], [12, 17], [18, 21], [22, 26], [27, 32], [33, 37], [38, 41], [42, 54], [55, 57], [58, 68], [69, 71], [71, 77], [78, 84], [85, 88], [89, 91], [92, 106], [107, 114], [115, 118], [119, 129], [129, 130], [131, 133], [134, 148], [149, 151], [152, 154], [154, 158], [159, 161], [162, 164], [165, 179], [180, 183], [184, 194], [195, 204], [204, 205]]}
{"doc_key": "ai-test-391", "ner": [[8, 8, "programlang"], [10, 10, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["ou", "via", "des", "interfaces", "de", "haut", "niveau", "vers", "Java", "et", "Tcl", "."], "sentence-detokenized": "ou via des interfaces de haut niveau vers Java et Tcl.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 21], [22, 24], [25, 29], [30, 36], [37, 41], [42, 46], [47, 49], [50, 53], [53, 54]]}
{"doc_key": "ai-test-392", "ner": [[16, 19, "algorithm"], [29, 29, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 19, 29, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Dans", "des", "recherches", "r\u00e9centes", ",", "les", "m\u00e9thodes", "bas\u00e9es", "sur", "les", "noyaux", ",", "telles", "que", "les", "machines", "\u00e0", "vecteurs", "de", "support", ",", "ont", "montr\u00e9", "des", "performances", "sup\u00e9rieures", "dans", "les", "applications", "supervis\u00e9es", "."], "sentence-detokenized": "Dans des recherches r\u00e9centes, les m\u00e9thodes bas\u00e9es sur les noyaux, telles que les machines \u00e0 vecteurs de support, ont montr\u00e9 des performances sup\u00e9rieures dans les applications supervis\u00e9es.", "token2charspan": [[0, 4], [5, 8], [9, 19], [20, 28], [28, 29], [30, 33], [34, 42], [43, 49], [50, 53], [54, 57], [58, 64], [64, 65], [66, 72], [73, 76], [77, 80], [81, 89], [90, 91], [92, 100], [101, 103], [104, 111], [111, 112], [113, 116], [117, 123], [124, 127], [128, 140], [141, 152], [153, 157], [158, 161], [162, 174], [175, 186], [186, 187]]}
{"doc_key": "ai-test-393", "ner": [[20, 20, "misc"], [27, 27, "researcher"], [29, 29, "researcher"], [37, 37, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[27, 27, 37, 37, "usage", "", false, false], [29, 29, 37, 37, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pour", "illustrer", "les", "principes", "de", "base", "de", "la", "mise", "en", "sac", ",", "voici", "une", "analyse", "sur", "la", "relation", "entre", "l'", "ozone", "et", "la", "temp\u00e9rature", "(", "donn\u00e9es", "de", "Rousseeuw", "et", "Leroy", "(", "1986", ")", ",", "analyse", "faite", "en", "R", ")", "."], "sentence-detokenized": "Pour illustrer les principes de base de la mise en sac, voici une analyse sur la relation entre l'ozone et la temp\u00e9rature (donn\u00e9es de Rousseeuw et Leroy (1986), analyse faite en R).", "token2charspan": [[0, 4], [5, 14], [15, 18], [19, 28], [29, 31], [32, 36], [37, 39], [40, 42], [43, 47], [48, 50], [51, 54], [54, 55], [56, 61], [62, 65], [66, 73], [74, 77], [78, 80], [81, 89], [90, 95], [96, 98], [98, 103], [104, 106], [107, 109], [110, 121], [122, 123], [123, 130], [131, 133], [134, 143], [144, 146], [147, 152], [153, 154], [154, 158], [158, 159], [159, 160], [161, 168], [169, 174], [175, 177], [178, 179], [179, 180], [180, 181]]}
{"doc_key": "ai-test-394", "ner": [[0, 1, "organisation"], [14, 17, "product"], [24, 25, "product"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 17, 0, 1, "artifact", "", false, false], [24, 25, 0, 1, "artifact", "", false, false], [28, 29, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Denso", "Wave", "est", "une", "filiale", "qui", "fabrique", "des", "produits", "d'", "identification", "automatique", "(", "lecteurs", "de", "codes", "\u00e0", "barres", "et", "produits", "connexes", ")", ",", "des", "robots", "industriels", "et", "des", "automates", "programmables", "."], "sentence-detokenized": "Denso Wave est une filiale qui fabrique des produits d'identification automatique (lecteurs de codes \u00e0 barres et produits connexes), des robots industriels et des automates programmables.", "token2charspan": [[0, 5], [6, 10], [11, 14], [15, 18], [19, 26], [27, 30], [31, 39], [40, 43], [44, 52], [53, 55], [55, 69], [70, 81], [82, 83], [83, 91], [92, 94], [95, 100], [101, 102], [103, 109], [110, 112], [113, 121], [122, 130], [130, 131], [131, 132], [133, 136], [137, 143], [144, 155], [156, 158], [159, 162], [163, 172], [173, 186], [186, 187]]}
{"doc_key": "ai-test-395", "ner": [[3, 7, "metrics"], [11, 12, "metrics"], [24, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 7, 24, 24, "compare", "", false, false], [11, 12, 3, 7, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Alors", "que", "la", "compr\u00e9hension", "de", "l'", "\u00e9valuation", "bilingue", "calcule", "simplement", "la", "pr\u00e9cision", "d'", "un", "gramme", "en", "ajoutant", "un", "poids", "\u00e9gal", "\u00e0", "chacun", ",", "le", "NIST", "calcule", "\u00e9galement", "le", "degr\u00e9", "d'", "information", "d'", "un", "gramme", "particulier", "."], "sentence-detokenized": "Alors que la compr\u00e9hension de l'\u00e9valuation bilingue calcule simplement la pr\u00e9cision d'un gramme en ajoutant un poids \u00e9gal \u00e0 chacun, le NIST calcule \u00e9galement le degr\u00e9 d'information d'un gramme particulier.", "token2charspan": [[0, 5], [6, 9], [10, 12], [13, 26], [27, 29], [30, 32], [32, 42], [43, 51], [52, 59], [60, 70], [71, 73], [74, 83], [84, 86], [86, 88], [89, 95], [96, 98], [99, 107], [108, 110], [111, 116], [117, 121], [122, 123], [124, 130], [130, 131], [132, 134], [135, 139], [140, 147], [148, 157], [158, 160], [161, 166], [167, 169], [169, 180], [181, 183], [183, 185], [186, 192], [193, 204], [204, 205]]}
{"doc_key": "ai-test-396", "ner": [[19, 19, "algorithm"], [22, 24, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["En", "particulier", ",", "ils", "sont", "utilis\u00e9s", "lors", "du", "calcul", "de", "la", "vraisemblance", "d'", "un", "arbre", "(", "dans", "les", "approches", "bay\u00e9siennes", "et", "de", "vraisemblance", "maximale", "de", "l'", "estimation", "des", "arbres", ")", "et", "ils", "sont", "utilis\u00e9s", "pour", "estimer", "la", "distance", "\u00e9volutive", "entre", "les", "s\u00e9quences", "\u00e0", "partir", "des", "diff\u00e9rences", "observ\u00e9es", "entre", "les", "s\u00e9quences", "."], "sentence-detokenized": "En particulier, ils sont utilis\u00e9s lors du calcul de la vraisemblance d'un arbre (dans les approches bay\u00e9siennes et de vraisemblance maximale de l'estimation des arbres) et ils sont utilis\u00e9s pour estimer la distance \u00e9volutive entre les s\u00e9quences \u00e0 partir des diff\u00e9rences observ\u00e9es entre les s\u00e9quences.", "token2charspan": [[0, 2], [3, 14], [14, 15], [16, 19], [20, 24], [25, 33], [34, 38], [39, 41], [42, 48], [49, 51], [52, 54], [55, 68], [69, 71], [71, 73], [74, 79], [80, 81], [81, 85], [86, 89], [90, 99], [100, 111], [112, 114], [115, 117], [118, 131], [132, 140], [141, 143], [144, 146], [146, 156], [157, 160], [161, 167], [167, 168], [169, 171], [172, 175], [176, 180], [181, 189], [190, 194], [195, 202], [203, 205], [206, 214], [215, 224], [225, 230], [231, 234], [235, 244], [245, 246], [247, 253], [254, 257], [258, 269], [270, 279], [280, 285], [286, 289], [290, 299], [299, 300]]}
{"doc_key": "ai-test-397", "ner": [[1, 3, "conference"], [30, 31, "misc"], [33, 33, "misc"], [66, 67, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[33, 33, 30, 31, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["L'", "Audio", "Engineering", "Society", "recommande", "une", "fr\u00e9quence", "d'", "\u00e9chantillonnage", "de", "48", "kHz", "pour", "la", "plupart", "des", "applications", ",", "mais", "reconna\u00eet", "la", "validit\u00e9", "de", "la", "fr\u00e9quence", "de", "44,1", "kHz", "pour", "les", "disques", "compacts", "(", "CD", ")", "et", "d'", "autres", "utilisations", "grand", "public", ",", "de", "32", "kHz", "pour", "les", "applications", "li\u00e9es", "\u00e0", "la", "transmission", "et", "de", "96", "kHz", "pour", "les", "bandes", "passantes", "plus", "larges", "ou", "l'", "utilisation", "de", "filtres", "anti-repliement", "."], "sentence-detokenized": "L'Audio Engineering Society recommande une fr\u00e9quence d'\u00e9chantillonnage de 48 kHz pour la plupart des applications, mais reconna\u00eet la validit\u00e9 de la fr\u00e9quence de 44,1 kHz pour les disques compacts (CD) et d'autres utilisations grand public, de 32 kHz pour les applications li\u00e9es \u00e0 la transmission et de 96 kHz pour les bandes passantes plus larges ou l'utilisation de filtres anti-repliement.", "token2charspan": [[0, 2], [2, 7], [8, 19], [20, 27], [28, 38], [39, 42], [43, 52], [53, 55], [55, 70], [71, 73], [74, 76], [77, 80], [81, 85], [86, 88], [89, 96], [97, 100], [101, 113], [113, 114], [115, 119], [120, 129], [130, 132], [133, 141], [142, 144], [145, 147], [148, 157], [158, 160], [161, 165], [166, 169], [170, 174], [175, 178], [179, 186], [187, 195], [196, 197], [197, 199], [199, 200], [201, 203], [204, 206], [206, 212], [213, 225], [226, 231], [232, 238], [238, 239], [240, 242], [243, 245], [246, 249], [250, 254], [255, 258], [259, 271], [272, 277], [278, 279], [280, 282], [283, 295], [296, 298], [299, 301], [302, 304], [305, 308], [309, 313], [314, 317], [318, 324], [325, 334], [335, 339], [340, 346], [347, 349], [350, 352], [352, 363], [364, 366], [367, 374], [375, 390], [390, 391]]}
{"doc_key": "ai-test-398", "ner": [[14, 14, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Des", "ressources", "pour", "l'", "affectivit\u00e9", "des", "mots", "et", "des", "concepts", "ont", "\u00e9t\u00e9", "r\u00e9alis\u00e9es", "pour", "WordNet", "{{cite", "journal"], "sentence-detokenized": "Des ressources pour l'affectivit\u00e9 des mots et des concepts ont \u00e9t\u00e9 r\u00e9alis\u00e9es pour WordNet {{cite journal", "token2charspan": [[0, 3], [4, 14], [15, 19], [20, 22], [22, 33], [34, 37], [38, 42], [43, 45], [46, 49], [50, 58], [59, 62], [63, 66], [67, 76], [77, 81], [82, 89], [90, 96], [97, 104]]}
{"doc_key": "ai-test-399", "ner": [[1, 2, "misc"], [23, 24, "person"], [29, 31, "person"], [36, 38, "person"], [44, 45, "organisation"], [65, 67, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[29, 31, 36, 38, "role", "acts_in", false, false], [44, 45, 36, 38, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["En", "anaglyphe", "rouge-vert", ",", "le", "public", "se", "voit", "pr\u00e9senter", "trois", "bobines", "de", "tests", ",", "qui", "comprennent", "des", "sc\u00e8nes", "rurales", ",", "des", "essais", "de", "Marie", "Doro", ",", "une", "s\u00e9quence", "de", "John", "B.", "Mason", "jouant", "plusieurs", "passages", "de", "Jim", "the", "Penman", "(", "un", "film", "sorti", "par", "Famous", "Players-Lasky", "cette", "ann\u00e9e", "-l\u00e0", ",", "mais", "pas", "en", "3D", ")", ",", "des", "danseurs", "orientaux", "et", "une", "bobine", "de", "s\u00e9quences", "des", "chutes", "du", "Niagara", "."], "sentence-detokenized": "En anaglyphe rouge-vert, le public se voit pr\u00e9senter trois bobines de tests, qui comprennent des sc\u00e8nes rurales, des essais de Marie Doro, une s\u00e9quence de John B. Mason jouant plusieurs passages de Jim the Penman (un film sorti par Famous Players-Lasky cette ann\u00e9e-l\u00e0, mais pas en 3D), des danseurs orientaux et une bobine de s\u00e9quences des chutes du Niagara.", "token2charspan": [[0, 2], [3, 12], [13, 23], [23, 24], [25, 27], [28, 34], [35, 37], [38, 42], [43, 52], [53, 58], [59, 66], [67, 69], [70, 75], [75, 76], [77, 80], [81, 92], [93, 96], [97, 103], [104, 111], [111, 112], [113, 116], [117, 123], [124, 126], [127, 132], [133, 137], [137, 138], [139, 142], [143, 151], [152, 154], [155, 159], [160, 162], [163, 168], [169, 175], [176, 185], [186, 194], [195, 197], [198, 201], [202, 205], [206, 212], [213, 214], [214, 216], [217, 221], [222, 227], [228, 231], [232, 238], [239, 252], [253, 258], [259, 264], [264, 267], [267, 268], [269, 273], [274, 277], [278, 280], [281, 283], [283, 284], [284, 285], [286, 289], [290, 298], [299, 308], [309, 311], [312, 315], [316, 322], [323, 325], [326, 335], [336, 339], [340, 346], [347, 349], [350, 357], [357, 358]]}
{"doc_key": "ai-test-400", "ner": [[12, 16, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Il", "s'", "agit", "d'", "une", "fa\u00e7on", "particuli\u00e8re", "de", "mettre", "en", "\u0153uvre", "l'", "estimation", "du", "maximum", "de", "vraisemblance", "pour", "ce", "probl\u00e8me", "."], "sentence-detokenized": "Il s'agit d'une fa\u00e7on particuli\u00e8re de mettre en \u0153uvre l'estimation du maximum de vraisemblance pour ce probl\u00e8me.", "token2charspan": [[0, 2], [3, 5], [5, 9], [10, 12], [12, 15], [16, 21], [22, 34], [35, 37], [38, 44], [45, 47], [48, 53], [54, 56], [56, 66], [67, 69], [70, 77], [78, 80], [81, 94], [95, 99], [100, 102], [103, 111], [111, 112]]}
{"doc_key": "ai-test-401", "ner": [[0, 2, "product"], [14, 14, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Crawler-friendly", "Web", "Servers", ",", "et", "il", "int\u00e8gre", "les", "caract\u00e9ristiques", "des", "sitemaps", "et", "des", "flux", "RSS", "dans", "un", "m\u00e9canisme", "d\u00e9centralis\u00e9", "permettant", "aux", "biologistes", "informatiques", "et", "aux", "bio-informaticiens", "de", "diffuser", "et", "de", "r\u00e9cup\u00e9rer", "ouvertement", "des", "m\u00e9tadonn\u00e9es", "sur", "les", "ressources", "biom\u00e9dicales", "."], "sentence-detokenized": "Crawler-friendly Web Servers, et il int\u00e8gre les caract\u00e9ristiques des sitemaps et des flux RSS dans un m\u00e9canisme d\u00e9centralis\u00e9 permettant aux biologistes informatiques et aux bio-informaticiens de diffuser et de r\u00e9cup\u00e9rer ouvertement des m\u00e9tadonn\u00e9es sur les ressources biom\u00e9dicales.", "token2charspan": [[0, 16], [17, 20], [21, 28], [28, 29], [30, 32], [33, 35], [36, 43], [44, 47], [48, 64], [65, 68], [69, 77], [78, 80], [81, 84], [85, 89], [90, 93], [94, 98], [99, 101], [102, 111], [112, 124], [125, 135], [136, 139], [140, 151], [152, 165], [166, 168], [169, 172], [173, 191], [192, 194], [195, 203], [204, 206], [207, 209], [210, 219], [220, 231], [232, 235], [236, 247], [248, 251], [252, 255], [256, 266], [267, 279], [279, 280]]}
{"doc_key": "ai-test-402", "ner": [[5, 14, "misc"], [18, 25, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Il", "est", "couvert", "par", "la", "norme", "Z39.50", "de", "l'", "American", "National", "Standards", "Institute", "/", "NISO", "et", "par", "la", "norme", "23950", "de", "l'", "Organisation", "internationale", "de", "normalisation", "."], "sentence-detokenized": "Il est couvert par la norme Z39.50 de l'American National Standards Institute / NISO et par la norme 23950 de l'Organisation internationale de normalisation.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 18], [19, 21], [22, 27], [28, 34], [35, 37], [38, 40], [40, 48], [49, 57], [58, 67], [68, 77], [78, 79], [80, 84], [85, 87], [88, 91], [92, 94], [95, 100], [101, 106], [107, 109], [110, 112], [112, 124], [125, 139], [140, 142], [143, 156], [156, 157]]}
{"doc_key": "ai-test-403", "ner": [[15, 19, "misc"], [26, 28, "metrics"], [33, 36, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Le", "codeur", "et", "le", "d\u00e9codeur", "sont", "entra\u00een\u00e9s", "\u00e0", "prendre", "une", "phrase", "et", "\u00e0", "reproduire", "la", "distribution", "\u00e0", "un", "coup", "de", "la", "paraphrase", "correspondante", "en", "minimisant", "la", "perplexit\u00e9", "\u00e0", "l'", "aide", "d'", "une", "simple", "descente", "de", "gradient", "stochastique", "."], "sentence-detokenized": "Le codeur et le d\u00e9codeur sont entra\u00een\u00e9s \u00e0 prendre une phrase et \u00e0 reproduire la distribution \u00e0 un coup de la paraphrase correspondante en minimisant la perplexit\u00e9 \u00e0 l'aide d'une simple descente de gradient stochastique.", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 15], [16, 24], [25, 29], [30, 39], [40, 41], [42, 49], [50, 53], [54, 60], [61, 63], [64, 65], [66, 76], [77, 79], [80, 92], [93, 94], [95, 97], [98, 102], [103, 105], [106, 108], [109, 119], [120, 134], [135, 137], [138, 148], [149, 151], [152, 162], [163, 164], [165, 167], [167, 171], [172, 174], [174, 177], [178, 184], [185, 193], [194, 196], [197, 205], [206, 218], [218, 219]]}
{"doc_key": "ai-test-404", "ner": [[7, 9, "field"], [12, 16, "task"], [19, 24, "task"], [38, 46, "task"], [49, 55, "task"], [59, 69, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 16, 7, 9, "part-of", "task_part_of_field", false, false], [19, 24, 7, 9, "part-of", "task_part_of_field", false, false], [38, 46, 7, 9, "part-of", "task_part_of_field", false, false], [49, 55, 7, 9, "part-of", "task_part_of_field", false, false], [59, 69, 7, 9, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["D'", "autres", "applications", "typiques", "des", "techniques", "de", "reconnaissance", "des", "formes", "sont", "la", "reconnaissance", "automatique", "de", "la", "parole", ",", "la", "classification", "de", "textes", "en", "plusieurs", "cat\u00e9gories", "(", "par", "exemple", ",", "les", "messages", "\u00e9lectroniques", "spam", "/", "non-spam", ")", ",", "la", "reconnaissance", "de", "l'", "\u00e9criture", "manuscrite", "sur", "les", "enveloppes", "postales", ",", "la", "reconnaissance", "automatique", "d'", "images", "de", "visages", "humains", ",", "ou", "l'", "extraction", "d'", "images", "d'", "\u00e9criture", "manuscrite", "\u00e0", "partir", "de", "formulaires", "m\u00e9dicaux", "."], "sentence-detokenized": "D'autres applications typiques des techniques de reconnaissance des formes sont la reconnaissance automatique de la parole, la classification de textes en plusieurs cat\u00e9gories (par exemple, les messages \u00e9lectroniques spam / non-spam), la reconnaissance de l'\u00e9criture manuscrite sur les enveloppes postales, la reconnaissance automatique d'images de visages humains, ou l'extraction d'images d'\u00e9criture manuscrite \u00e0 partir de formulaires m\u00e9dicaux.", "token2charspan": [[0, 2], [2, 8], [9, 21], [22, 30], [31, 34], [35, 45], [46, 48], [49, 63], [64, 67], [68, 74], [75, 79], [80, 82], [83, 97], [98, 109], [110, 112], [113, 115], [116, 122], [122, 123], [124, 126], [127, 141], [142, 144], [145, 151], [152, 154], [155, 164], [165, 175], [176, 177], [177, 180], [181, 188], [188, 189], [190, 193], [194, 202], [203, 216], [217, 221], [222, 223], [224, 232], [232, 233], [233, 234], [235, 237], [238, 252], [253, 255], [256, 258], [258, 266], [267, 277], [278, 281], [282, 285], [286, 296], [297, 305], [305, 306], [307, 309], [310, 324], [325, 336], [337, 339], [339, 345], [346, 348], [349, 356], [357, 364], [364, 365], [366, 368], [369, 371], [371, 381], [382, 384], [384, 390], [391, 393], [393, 401], [402, 412], [413, 414], [415, 421], [422, 424], [425, 436], [437, 445], [445, 446]]}
{"doc_key": "ai-test-405", "ner": [[0, 4, "algorithm"], [14, 16, "field"], [19, 20, "task"], [23, 24, "task"], [27, 30, "task"], [33, 39, "task"], [44, 45, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[14, 16, 0, 4, "usage", "", false, false], [19, 20, 0, 4, "usage", "", false, false], [23, 24, 0, 4, "usage", "", false, false], [27, 30, 0, 4, "usage", "", false, false], [33, 39, 0, 4, "usage", "", false, false], [44, 45, 0, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Les", "r\u00e9seaux", "de", "neurones", "artificiels", "ont", "\u00e9t\u00e9", "utilis\u00e9s", "pour", "diverses", "t\u00e2ches", ",", "notamment", "la", "vision", "par", "ordinateur", ",", "la", "reconnaissance", "vocale", ",", "la", "traduction", "automatique", ",", "le", "filtrage", "des", "r\u00e9seaux", "sociaux", ",", "le", "jeu", "de", "soci\u00e9t\u00e9", "et", "les", "jeux", "vid\u00e9o", ",", "ainsi", "que", "le", "diagnostic", "m\u00e9dical", "."], "sentence-detokenized": "Les r\u00e9seaux de neurones artificiels ont \u00e9t\u00e9 utilis\u00e9s pour diverses t\u00e2ches, notamment la vision par ordinateur, la reconnaissance vocale, la traduction automatique, le filtrage des r\u00e9seaux sociaux, le jeu de soci\u00e9t\u00e9 et les jeux vid\u00e9o, ainsi que le diagnostic m\u00e9dical.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 23], [24, 35], [36, 39], [40, 43], [44, 52], [53, 57], [58, 66], [67, 73], [73, 74], [75, 84], [85, 87], [88, 94], [95, 98], [99, 109], [109, 110], [111, 113], [114, 128], [129, 135], [135, 136], [137, 139], [140, 150], [151, 162], [162, 163], [164, 166], [167, 175], [176, 179], [180, 187], [188, 195], [195, 196], [197, 199], [200, 203], [204, 206], [207, 214], [215, 217], [218, 221], [222, 226], [227, 232], [232, 233], [234, 239], [240, 243], [244, 246], [247, 257], [258, 265], [265, 266]]}
{"doc_key": "ai-test-406", "ner": [[5, 6, "organisation"], [7, 7, "product"], [22, 22, "product"], [25, 25, "organisation"], [26, 27, "product"], [29, 29, "product"], [31, 33, "product"], [35, 35, "product"], [37, 37, "programlang"], [45, 46, "field"], [53, 53, "product"], [58, 58, "algorithm"], [60, 60, "algorithm"], [62, 62, "algorithm"], [65, 65, "product"], [73, 75, "task"], [83, 85, "algorithm"], [88, 88, "product"], [90, 90, "product"], [96, 98, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "relations": [[7, 7, 5, 6, "origin", "", false, false], [7, 7, 22, 22, "named", "same", false, false], [7, 7, 53, 53, "named", "same", false, false], [37, 37, 45, 46, "related-to", "used_for", false, false], [58, 58, 37, 37, "part-of", "", true, false], [58, 58, 53, 53, "origin", "", true, false], [60, 60, 37, 37, "part-of", "", true, false], [60, 60, 53, 53, "origin", "", true, false], [62, 62, 37, 37, "part-of", "", true, false], [62, 62, 53, 53, "origin", "", true, false], [65, 65, 73, 75, "related-to", "used_for", false, false], [83, 85, 65, 65, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Parmi", "les", "exemples", ",", "citons", "Salford", "Systems", "CART", "(", "qui", "a", "obtenu", "une", "licence", "pour", "le", "code", "propri\u00e9taire", "des", "auteurs", "originaux", "de", "CART", ")", ",", "IBM", "SPSS", "Modeler", ",", "RapidMiner", ",", "SAS", "Enterprise", "Miner", ",", "Matlab", ",", "R", "(", "un", "environnement", "logiciel", "libre", "pour", "le", "calcul", "statistique", ",", "qui", "comprend", "plusieurs", "impl\u00e9mentations", "de", "CART", "telles", "que", "les", "paquets", "rpart", ",", "party", "et", "randomForest", ")", ",", "Weka", "(", "une", "suite", "gratuite", "et", "libre", "d'", "exploration", "de", "donn\u00e9es", ",", "qui", "contient", "de", "nombreux", "algorithmes", "d'", "arbres", "de", "d\u00e9cision", ")", ",", "Orange", ",", "KNIME", ",", "le", "langage", "de", "programmation", "Microsoft", "SQL", "Server", ")", "."], "sentence-detokenized": "Parmi les exemples, citons Salford Systems CART (qui a obtenu une licence pour le code propri\u00e9taire des auteurs originaux de CART), IBM SPSS Modeler, RapidMiner, SAS Enterprise Miner, Matlab, R (un environnement logiciel libre pour le calcul statistique, qui comprend plusieurs impl\u00e9mentations de CART telles que les paquets rpart, party et randomForest), Weka (une suite gratuite et libre d'exploration de donn\u00e9es, qui contient de nombreux algorithmes d'arbres de d\u00e9cision), Orange, KNIME, le langage de programmation Microsoft SQL Server).", "token2charspan": [[0, 5], [6, 9], [10, 18], [18, 19], [20, 26], [27, 34], [35, 42], [43, 47], [48, 49], [49, 52], [53, 54], [55, 61], [62, 65], [66, 73], [74, 78], [79, 81], [82, 86], [87, 99], [100, 103], [104, 111], [112, 121], [122, 124], [125, 129], [129, 130], [130, 131], [132, 135], [136, 140], [141, 148], [148, 149], [150, 160], [160, 161], [162, 165], [166, 176], [177, 182], [182, 183], [184, 190], [190, 191], [192, 193], [194, 195], [195, 197], [198, 211], [212, 220], [221, 226], [227, 231], [232, 234], [235, 241], [242, 253], [253, 254], [255, 258], [259, 267], [268, 277], [278, 293], [294, 296], [297, 301], [302, 308], [309, 312], [313, 316], [317, 324], [325, 330], [330, 331], [332, 337], [338, 340], [341, 353], [353, 354], [354, 355], [356, 360], [361, 362], [362, 365], [366, 371], [372, 380], [381, 383], [384, 389], [390, 392], [392, 403], [404, 406], [407, 414], [414, 415], [416, 419], [420, 428], [429, 431], [432, 440], [441, 452], [453, 455], [455, 461], [462, 464], [465, 473], [473, 474], [474, 475], [476, 482], [482, 483], [484, 489], [489, 490], [491, 493], [494, 501], [502, 504], [505, 518], [519, 528], [529, 532], [533, 539], [539, 540], [540, 541]]}
{"doc_key": "ai-test-407", "ner": [[0, 3, "algorithm"], [5, 5, "algorithm"], [15, 16, "researcher"], [19, 21, "university"], [23, 24, "researcher"], [26, 29, "organisation"], [31, 31, "organisation"], [38, 40, "researcher"], [42, 44, "researcher"], [46, 47, "organisation"], [65, 69, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 3, 15, 16, "origin", "", false, false], [0, 3, 23, 24, "origin", "", false, false], [0, 3, 38, 40, "origin", "", false, false], [0, 3, 42, 44, "origin", "", false, false], [5, 5, 0, 3, "named", "", false, false], [15, 16, 19, 21, "physical", "", false, false], [15, 16, 19, 21, "role", "", false, false], [23, 24, 26, 29, "physical", "", false, false], [23, 24, 26, 29, "role", "", false, false], [31, 31, 26, 29, "named", "", false, false], [38, 40, 46, 47, "physical", "", false, false], [38, 40, 46, 47, "role", "", false, false], [42, 44, 46, 47, "physical", "", false, false], [42, 44, 46, 47, "role", "", false, false], [65, 69, 0, 3, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Le", "codage", "pr\u00e9dictif", "lin\u00e9aire", "(", "LPC", ")", "a", "\u00e9t\u00e9", "d\u00e9velopp\u00e9", "pour", "la", "premi\u00e8re", "fois", "par", "Fumitada", "Itakura", "de", "l'", "universit\u00e9", "de", "Nagoya", "et", "Shuzo", "Saito", "de", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "en", "1966", ",", "puis", "par", "Bishnu", "S.", "Atal", "et", "Manfred", "R.", "Schroeder", "aux", "Bell", "Labs", "entre", "le", "d\u00e9but", "et", "le", "milieu", "des", "ann\u00e9es", "1970", ".", "Il", "est", "devenu", "la", "base", "des", "premi\u00e8res", "puces", "DSP", "de", "synth\u00e8se", "vocale", "\u00e0", "la", "fin", "des", "ann\u00e9es", "1970", "."], "sentence-detokenized": "Le codage pr\u00e9dictif lin\u00e9aire (LPC) a \u00e9t\u00e9 d\u00e9velopp\u00e9 pour la premi\u00e8re fois par Fumitada Itakura de l'universit\u00e9 de Nagoya et Shuzo Saito de Nippon Telegraph and Telephone (NTT) en 1966, puis par Bishnu S. Atal et Manfred R. Schroeder aux Bell Labs entre le d\u00e9but et le milieu des ann\u00e9es 1970. Il est devenu la base des premi\u00e8res puces DSP de synth\u00e8se vocale \u00e0 la fin des ann\u00e9es 1970.", "token2charspan": [[0, 2], [3, 9], [10, 19], [20, 28], [29, 30], [30, 33], [33, 34], [35, 36], [37, 40], [41, 50], [51, 55], [56, 58], [59, 67], [68, 72], [73, 76], [77, 85], [86, 93], [94, 96], [97, 99], [99, 109], [110, 112], [113, 119], [120, 122], [123, 128], [129, 134], [135, 137], [138, 144], [145, 154], [155, 158], [159, 168], [169, 170], [170, 173], [173, 174], [175, 177], [178, 182], [182, 183], [184, 188], [189, 192], [193, 199], [200, 202], [203, 207], [208, 210], [211, 218], [219, 221], [222, 231], [232, 235], [236, 240], [241, 245], [246, 251], [252, 254], [255, 260], [261, 263], [264, 266], [267, 273], [274, 277], [278, 284], [285, 289], [289, 290], [291, 293], [294, 297], [298, 304], [305, 307], [308, 312], [313, 316], [317, 326], [327, 332], [333, 336], [337, 339], [340, 348], [349, 355], [356, 357], [358, 360], [361, 364], [365, 368], [369, 375], [376, 380], [380, 381]]}
{"doc_key": "ai-test-408", "ner": [[1, 4, "metrics"], [8, 8, "metrics"], [11, 11, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 1, 4, "part-of", "", false, false], [11, 11, 1, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Un", "score", "F", "est", "une", "combinaison", "de", "la", "pr\u00e9cision", "et", "du", "rappel", ",", "fournissant", "un", "score", "unique", "."], "sentence-detokenized": "Un score F est une combinaison de la pr\u00e9cision et du rappel, fournissant un score unique.", "token2charspan": [[0, 2], [3, 8], [9, 10], [11, 14], [15, 18], [19, 30], [31, 33], [34, 36], [37, 46], [47, 49], [50, 52], [53, 59], [59, 60], [61, 72], [73, 75], [76, 81], [82, 88], [88, 89]]}
{"doc_key": "ai-test-409", "ner": [[3, 5, "field"], [12, 16, "task"], [22, 25, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 16, 3, 5, "part-of", "task_part_of_field", false, false], [22, 25, 3, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Les", "t\u00e2ches", "d'", "analyse", "d'", "images", "peuvent", "\u00eatre", "aussi", "simples", "que", "la", "lecture", "d'", "\u00e9tiquettes", "\u00e0", "code-barres", "ou", "aussi", "sophistiqu\u00e9es", "qu'", "un", "syst\u00e8me", "de", "reconnaissance", "faciale", "."], "sentence-detokenized": "Les t\u00e2ches d'analyse d'images peuvent \u00eatre aussi simples que la lecture d'\u00e9tiquettes \u00e0 code-barres ou aussi sophistiqu\u00e9es qu'un syst\u00e8me de reconnaissance faciale.", "token2charspan": [[0, 3], [4, 10], [11, 13], [13, 20], [21, 23], [23, 29], [30, 37], [38, 42], [43, 48], [49, 56], [57, 60], [61, 63], [64, 71], [72, 74], [74, 84], [85, 86], [87, 98], [99, 101], [102, 107], [108, 121], [122, 125], [125, 127], [128, 135], [136, 138], [139, 153], [154, 161], [161, 162]]}
{"doc_key": "ai-test-410", "ner": [[4, 8, "algorithm"], [31, 32, "algorithm"], [40, 43, "algorithm"], [48, 48, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[40, 43, 31, 32, "type-of", "", false, false], [48, 48, 40, 43, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Le", "cas", "particulier", "des", "machines", "\u00e0", "vecteurs", "de", "support", "lin\u00e9aires", "peut", "\u00eatre", "r\u00e9solu", "plus", "efficacement", "par", "le", "m\u00eame", "type", "d'", "algorithmes", "que", "ceux", "utilis\u00e9s", "pour", "optimiser", "sa", "proche", "cousine", ",", "la", "r\u00e9gression", "logistique", ";", "cette", "classe", "d'", "algorithmes", "comprend", "la", "descente", "de", "gradient", "stochastique", "(", "par", "exemple", ",", "PEGASOS", ")", "."], "sentence-detokenized": "Le cas particulier des machines \u00e0 vecteurs de support lin\u00e9aires peut \u00eatre r\u00e9solu plus efficacement par le m\u00eame type d'algorithmes que ceux utilis\u00e9s pour optimiser sa proche cousine, la r\u00e9gression logistique ; cette classe d'algorithmes comprend la descente de gradient stochastique (par exemple, PEGASOS).", "token2charspan": [[0, 2], [3, 6], [7, 18], [19, 22], [23, 31], [32, 33], [34, 42], [43, 45], [46, 53], [54, 63], [64, 68], [69, 73], [74, 80], [81, 85], [86, 98], [99, 102], [103, 105], [106, 110], [111, 115], [116, 118], [118, 129], [130, 133], [134, 138], [139, 147], [148, 152], [153, 162], [163, 165], [166, 172], [173, 180], [180, 181], [182, 184], [185, 195], [196, 206], [207, 208], [209, 214], [215, 221], [222, 224], [224, 235], [236, 244], [245, 247], [248, 256], [257, 259], [260, 268], [269, 281], [282, 283], [283, 286], [287, 294], [294, 295], [296, 303], [303, 304], [304, 305]]}
{"doc_key": "ai-test-411", "ner": [[4, 4, "product"], [9, 9, "product"], [29, 29, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 9, 9, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Lorsqu'", "on", "demande", "\u00e0", "Siri", ",", "sur", "un", "appareil", "iOS", ",", "\"", "Avez-vous", "un", "animal", "de", "compagnie", "?", "\"", ",", "l'", "une", "des", "r\u00e9ponses", "est", "\"", "J'", "avais", "un", "AIBO", "\"", "."], "sentence-detokenized": "Lorsqu'on demande \u00e0 Siri, sur un appareil iOS, \"Avez-vous un animal de compagnie ?\", l'une des r\u00e9ponses est \"J'avais un AIBO\".", "token2charspan": [[0, 7], [7, 9], [10, 17], [18, 19], [20, 24], [24, 25], [26, 29], [30, 32], [33, 41], [42, 45], [45, 46], [47, 48], [48, 57], [58, 60], [61, 67], [68, 70], [71, 80], [81, 82], [82, 83], [83, 84], [85, 87], [87, 90], [91, 94], [95, 103], [104, 107], [108, 109], [109, 111], [111, 116], [117, 119], [120, 124], [124, 125], [125, 126]]}
{"doc_key": "ai-test-412", "ner": [[2, 4, "task"], [7, 9, "metrics"], [12, 12, "metrics"], [16, 16, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 9, 2, 4, "part-of", "", false, false], [12, 12, 7, 9, "named", "", false, false], [16, 16, 2, 4, "part-of", "", false, false], [19, 19, 16, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Dans", "la", "recherche", "d'", "informations", ",", "la", "valeur", "pr\u00e9dictive", "positive", "est", "appel\u00e9e", "pr\u00e9cision", ",", "et", "la", "sensibilit\u00e9", "est", "appel\u00e9e", "rappel", "."], "sentence-detokenized": "Dans la recherche d'informations, la valeur pr\u00e9dictive positive est appel\u00e9e pr\u00e9cision, et la sensibilit\u00e9 est appel\u00e9e rappel.", "token2charspan": [[0, 4], [5, 7], [8, 17], [18, 20], [20, 32], [32, 33], [34, 36], [37, 43], [44, 54], [55, 63], [64, 67], [68, 75], [76, 85], [85, 86], [87, 89], [90, 92], [93, 104], [105, 108], [109, 116], [117, 123], [123, 124]]}
{"doc_key": "ai-test-413", "ner": [[14, 16, "field"], [18, 18, "task"], [20, 20, "task"], [22, 25, "task"], [46, 48, "task"], [51, 52, "task"], [55, 60, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[18, 18, 14, 16, "part-of", "task_part_of_field", false, false], [20, 20, 14, 16, "part-of", "task_part_of_field", false, false], [22, 25, 14, 16, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["En", "particulier", ",", "ses", "recherches", "se", "sont", "concentr\u00e9es", "sur", "des", "domaines", "tels", "que", "l'", "exploration", "de", "textes", "(", "extraction", ",", "cat\u00e9gorisation", ",", "d\u00e9tection", "de", "la", "nouveaut\u00e9", ")", "et", "sur", "de", "nouveaux", "cadres", "th\u00e9oriques", "tels", "qu'", "une", "th\u00e9orie", "unifi\u00e9e", "bas\u00e9e", "sur", "l'", "utilit\u00e9", ",", "qui", "relie", "la", "recherche", "d'", "information", ",", "le", "r\u00e9sum\u00e9", "automatique", ",", "la", "r\u00e9ponse", "aux", "questions", "en", "texte", "libre", "et", "les", "t\u00e2ches", "connexes", "."], "sentence-detokenized": "En particulier, ses recherches se sont concentr\u00e9es sur des domaines tels que l'exploration de textes (extraction, cat\u00e9gorisation, d\u00e9tection de la nouveaut\u00e9) et sur de nouveaux cadres th\u00e9oriques tels qu'une th\u00e9orie unifi\u00e9e bas\u00e9e sur l'utilit\u00e9, qui relie la recherche d'information, le r\u00e9sum\u00e9 automatique, la r\u00e9ponse aux questions en texte libre et les t\u00e2ches connexes.", "token2charspan": [[0, 2], [3, 14], [14, 15], [16, 19], [20, 30], [31, 33], [34, 38], [39, 50], [51, 54], [55, 58], [59, 67], [68, 72], [73, 76], [77, 79], [79, 90], [91, 93], [94, 100], [101, 102], [102, 112], [112, 113], [114, 128], [128, 129], [130, 139], [140, 142], [143, 145], [146, 155], [155, 156], [157, 159], [160, 163], [164, 166], [167, 175], [176, 182], [183, 193], [194, 198], [199, 202], [202, 205], [206, 213], [214, 221], [222, 227], [228, 231], [232, 234], [234, 241], [241, 242], [243, 246], [247, 252], [253, 255], [256, 265], [266, 268], [268, 279], [279, 280], [281, 283], [284, 290], [291, 302], [302, 303], [304, 306], [307, 314], [315, 318], [319, 328], [329, 331], [332, 337], [338, 343], [344, 346], [347, 350], [351, 357], [358, 366], [366, 367]]}
{"doc_key": "ai-test-414", "ner": [[1, 2, "product"], [6, 7, "product"], [15, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 1, 2, "part-of", "", false, false], [15, 23, 1, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Les", "robots", "Delta", "sont", "dot\u00e9s", "d'", "actionneurs", "rotatifs", "mont\u00e9s", "sur", "la", "base", "qui", "d\u00e9placent", "un", "bras", "l\u00e9ger", ",", "rigide", "et", "en", "forme", "de", "parall\u00e9logramme", "."], "sentence-detokenized": "Les robots Delta sont dot\u00e9s d'actionneurs rotatifs mont\u00e9s sur la base qui d\u00e9placent un bras l\u00e9ger, rigide et en forme de parall\u00e9logramme.", "token2charspan": [[0, 3], [4, 10], [11, 16], [17, 21], [22, 27], [28, 30], [30, 41], [42, 50], [51, 57], [58, 61], [62, 64], [65, 69], [70, 73], [74, 83], [84, 86], [87, 91], [92, 97], [97, 98], [99, 105], [106, 108], [109, 111], [112, 117], [118, 120], [121, 136], [136, 137]]}
{"doc_key": "ai-test-415", "ner": [[8, 13, "metrics"], [16, 18, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Les", "quatre", "r\u00e9sultats", "peuvent", "\u00eatre", "formul\u00e9s", "dans", "un", "tableau", "de", "contingence", "2", "\u00d7", "2", "ou", "une", "matrice", "de", "confusion", ",", "comme", "suit", ":"], "sentence-detokenized": "Les quatre r\u00e9sultats peuvent \u00eatre formul\u00e9s dans un tableau de contingence 2 \u00d7 2 ou une matrice de confusion, comme suit :", "token2charspan": [[0, 3], [4, 10], [11, 20], [21, 28], [29, 33], [34, 42], [43, 47], [48, 50], [51, 58], [59, 61], [62, 73], [74, 75], [76, 77], [78, 79], [80, 82], [83, 86], [87, 94], [95, 97], [98, 107], [107, 108], [109, 114], [115, 119], [120, 121]]}
{"doc_key": "ai-test-416", "ner": [[4, 6, "field"], [35, 37, "task"], [44, 46, "task"], [52, 56, "task"], [58, 61, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[35, 37, 4, 6, "part-of", "task_part_of_field", false, false], [44, 46, 4, 6, "part-of", "task_part_of_field", false, false], [52, 56, 4, 6, "part-of", "task_part_of_field", false, false], [58, 61, 4, 6, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["La", "t\u00e2che", "r\u00e9elle", "d'", "exploration", "de", "donn\u00e9es", "est", "l'", "analyse", "semi-automatique", "ou", "automatique", "de", "grandes", "quantit\u00e9s", "de", "donn\u00e9es", "afin", "d'", "extraire", "des", "mod\u00e8les", "inconnus", "et", "int\u00e9ressants", "tels", "que", "des", "groupes", "d'", "enregistrements", "de", "donn\u00e9es", "(", "analyse", "en", "grappes", ")", ",", "des", "enregistrements", "inhabituels", "(", "d\u00e9tection", "d'", "anomalies", ")", "et", "des", "d\u00e9pendances", "(", "exploration", "de", "r\u00e8gles", "d'", "association", ",", "exploration", "de", "mod\u00e8les", "s\u00e9quentiels", ")", "."], "sentence-detokenized": "La t\u00e2che r\u00e9elle d'exploration de donn\u00e9es est l'analyse semi-automatique ou automatique de grandes quantit\u00e9s de donn\u00e9es afin d'extraire des mod\u00e8les inconnus et int\u00e9ressants tels que des groupes d'enregistrements de donn\u00e9es (analyse en grappes), des enregistrements inhabituels (d\u00e9tection d'anomalies) et des d\u00e9pendances (exploration de r\u00e8gles d'association, exploration de mod\u00e8les s\u00e9quentiels).", "token2charspan": [[0, 2], [3, 8], [9, 15], [16, 18], [18, 29], [30, 32], [33, 40], [41, 44], [45, 47], [47, 54], [55, 71], [72, 74], [75, 86], [87, 89], [90, 97], [98, 107], [108, 110], [111, 118], [119, 123], [124, 126], [126, 134], [135, 138], [139, 146], [147, 155], [156, 158], [159, 171], [172, 176], [177, 180], [181, 184], [185, 192], [193, 195], [195, 210], [211, 213], [214, 221], [222, 223], [223, 230], [231, 233], [234, 241], [241, 242], [242, 243], [244, 247], [248, 263], [264, 275], [276, 277], [277, 286], [287, 289], [289, 298], [298, 299], [300, 302], [303, 306], [307, 318], [319, 320], [320, 331], [332, 334], [335, 341], [342, 344], [344, 355], [355, 356], [357, 368], [369, 371], [372, 379], [380, 391], [391, 392], [392, 393]]}
{"doc_key": "ai-test-417", "ner": [[2, 4, "product"], [7, 10, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 4, 7, 10, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Pour", "un", "syst\u00e8me", "de", "recommandation", ",", "l'", "analyse", "des", "sentiments", "s'", "est", "av\u00e9r\u00e9e", "\u00eatre", "une", "technique", "pr\u00e9cieuse", "."], "sentence-detokenized": "Pour un syst\u00e8me de recommandation, l'analyse des sentiments s'est av\u00e9r\u00e9e \u00eatre une technique pr\u00e9cieuse.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 33], [33, 34], [35, 37], [37, 44], [45, 48], [49, 59], [60, 62], [62, 65], [66, 72], [73, 77], [78, 81], [82, 91], [92, 101], [101, 102]]}
{"doc_key": "ai-test-418", "ner": [[4, 4, "misc"], [15, 15, "product"], [38, 38, "organisation"], [40, 41, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 15, 15, "usage", "", false, false], [38, 38, 40, 41, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Par", "hasard", ",", "les", "Allemands", "avaient", "tr\u00e8s", "mal", "choisi", "la", "fr\u00e9quence", "de", "fonctionnement", "du", "syst\u00e8me", "Wotan", ";", "il", "fonctionnait", "sur", "45", "MHz", ",", "qui", "se", "trouvait", "\u00eatre", "la", "fr\u00e9quence", "du", "puissant", "mais", "inactif", "\u00e9metteur", "de", "t\u00e9l\u00e9vision", "de", "la", "BBC", "\u00e0", "Alexandra", "Palace", "."], "sentence-detokenized": "Par hasard, les Allemands avaient tr\u00e8s mal choisi la fr\u00e9quence de fonctionnement du syst\u00e8me Wotan ; il fonctionnait sur 45 MHz, qui se trouvait \u00eatre la fr\u00e9quence du puissant mais inactif \u00e9metteur de t\u00e9l\u00e9vision de la BBC \u00e0 Alexandra Palace.", "token2charspan": [[0, 3], [4, 10], [10, 11], [12, 15], [16, 25], [26, 33], [34, 38], [39, 42], [43, 49], [50, 52], [53, 62], [63, 65], [66, 80], [81, 83], [84, 91], [92, 97], [98, 99], [100, 102], [103, 115], [116, 119], [120, 122], [123, 126], [126, 127], [128, 131], [132, 134], [135, 143], [144, 148], [149, 151], [152, 161], [162, 164], [165, 173], [174, 178], [179, 186], [187, 195], [196, 198], [199, 209], [210, 212], [213, 215], [216, 219], [220, 221], [222, 231], [232, 238], [238, 239]]}
{"doc_key": "ai-test-419", "ner": [[8, 13, "metrics"], [16, 18, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Les", "quatre", "r\u00e9sultats", "peuvent", "\u00eatre", "formul\u00e9s", "dans", "un", "tableau", "de", "contingence", "2", "\u00d7", "2", "ou", "une", "matrice", "de", "confusion", ",", "comme", "suit", ":"], "sentence-detokenized": "Les quatre r\u00e9sultats peuvent \u00eatre formul\u00e9s dans un tableau de contingence 2 \u00d7 2 ou une matrice de confusion, comme suit :", "token2charspan": [[0, 3], [4, 10], [11, 20], [21, 28], [29, 33], [34, 42], [43, 47], [48, 50], [51, 58], [59, 61], [62, 73], [74, 75], [76, 77], [78, 79], [80, 82], [83, 86], [87, 94], [95, 97], [98, 107], [107, 108], [109, 114], [115, 119], [120, 121]]}
{"doc_key": "ai-test-420", "ner": [[2, 5, "misc"], [14, 14, "misc"], [16, 16, "product"], [18, 18, "product"], [20, 22, "product"], [33, 33, "misc"], [42, 44, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[16, 16, 14, 14, "usage", "", false, false], [18, 18, 14, 14, "usage", "", false, false], [20, 22, 18, 18, "named", "", false, false], [33, 33, 14, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Dans", "les", "applications", "du", "Web", "s\u00e9mantique", ",", "et", "dans", "les", "applications", "relativement", "populaires", "de", "RDF", "comme", "RSS", "et", "FOAF", "(", "Friend", "a", "Friend", ")", ",", "les", "ressources", "tendent", "\u00e0", "\u00eatre", "repr\u00e9sent\u00e9es", "par", "des", "URI", "qui", "d\u00e9signent", "intentionnellement", "des", "donn\u00e9es", "r\u00e9elles", "sur", "le", "World", "Wide", "Web", "et", "peuvent", "\u00eatre", "utilis\u00e9es", "pour", "y", "acc\u00e9der", "."], "sentence-detokenized": "Dans les applications du Web s\u00e9mantique, et dans les applications relativement populaires de RDF comme RSS et FOAF (Friend a Friend), les ressources tendent \u00e0 \u00eatre repr\u00e9sent\u00e9es par des URI qui d\u00e9signent intentionnellement des donn\u00e9es r\u00e9elles sur le World Wide Web et peuvent \u00eatre utilis\u00e9es pour y acc\u00e9der.", "token2charspan": [[0, 4], [5, 8], [9, 21], [22, 24], [25, 28], [29, 39], [39, 40], [41, 43], [44, 48], [49, 52], [53, 65], [66, 78], [79, 89], [90, 92], [93, 96], [97, 102], [103, 106], [107, 109], [110, 114], [115, 116], [116, 122], [123, 124], [125, 131], [131, 132], [132, 133], [134, 137], [138, 148], [149, 156], [157, 158], [159, 163], [164, 176], [177, 180], [181, 184], [185, 188], [189, 192], [193, 202], [203, 221], [222, 225], [226, 233], [234, 241], [242, 245], [246, 248], [249, 254], [255, 259], [260, 263], [264, 266], [267, 274], [275, 279], [280, 289], [290, 294], [295, 296], [297, 304], [304, 305]]}
{"doc_key": "ai-test-421", "ner": [[1, 7, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["L'", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "a", "\u00e9tudi\u00e9", "ce", "sujet", "en", "profondeur", "."], "sentence-detokenized": "L'Association for the Advancement of Artificial Intelligence a \u00e9tudi\u00e9 ce sujet en profondeur.", "token2charspan": [[0, 2], [2, 13], [14, 17], [18, 21], [22, 33], [34, 36], [37, 47], [48, 60], [61, 62], [63, 69], [70, 72], [73, 78], [79, 81], [82, 92], [92, 93]]}
{"doc_key": "ai-test-422", "ner": [[6, 11, "product"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[23, 23, 6, 11, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Parti", "d'", "une", "curiosit\u00e9", ",", "le", "syst\u00e8me", "vocal", "du", "Macintosh", "d'", "Apple", "a", "\u00e9volu\u00e9", "pour", "devenir", "un", "programme", "enti\u00e8rement", "pris", "en", "charge", ",", "PlainTalk", ",", "destin\u00e9", "aux", "personnes", "souffrant", "de", "probl\u00e8mes", "de", "vue", "."], "sentence-detokenized": "Parti d'une curiosit\u00e9, le syst\u00e8me vocal du Macintosh d'Apple a \u00e9volu\u00e9 pour devenir un programme enti\u00e8rement pris en charge, PlainTalk, destin\u00e9 aux personnes souffrant de probl\u00e8mes de vue.", "token2charspan": [[0, 5], [6, 8], [8, 11], [12, 21], [21, 22], [23, 25], [26, 33], [34, 39], [40, 42], [43, 52], [53, 55], [55, 60], [61, 62], [63, 69], [70, 74], [75, 82], [83, 85], [86, 95], [96, 107], [108, 112], [113, 115], [116, 122], [122, 123], [124, 133], [133, 134], [135, 142], [143, 146], [147, 156], [157, 166], [167, 169], [170, 179], [180, 182], [183, 186], [186, 187]]}
{"doc_key": "ai-test-423", "ner": [[10, 10, "field"], [13, 15, "task"], [18, 20, "task"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 15, 10, 10, "part-of", "task_part_of_field", false, false], [18, 20, 10, 10, "part-of", "task_part_of_field", false, false], [23, 24, 10, 10, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["D'", "autres", "domaines", "d'", "utilisation", "des", "ontologies", "au", "sein", "du", "PNL", "incluent", "la", "recherche", "d'", "informations", ",", "l'", "extraction", "d'", "informations", "et", "le", "r\u00e9sum\u00e9", "automatique", "."], "sentence-detokenized": "D'autres domaines d'utilisation des ontologies au sein du PNL incluent la recherche d'informations, l'extraction d'informations et le r\u00e9sum\u00e9 automatique.", "token2charspan": [[0, 2], [2, 8], [9, 17], [18, 20], [20, 31], [32, 35], [36, 46], [47, 49], [50, 54], [55, 57], [58, 61], [62, 70], [71, 73], [74, 83], [84, 86], [86, 98], [98, 99], [100, 102], [102, 112], [113, 115], [115, 127], [128, 130], [131, 133], [134, 140], [141, 152], [152, 153]]}
{"doc_key": "ai-test-424", "ner": [[7, 14, "organisation"], [17, 21, "organisation"], [24, 27, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["L'", "institut", "a", "collabor\u00e9", "\u00e9troitement", "avec", "le", "campus", "Janelia", "Farm", "du", "Howard", "Hughes", "Medical", "Institute", ",", "l'", "Allen", "Institute", "for", "Brain", "Science", "et", "les", "National", "Institutes", "of", "Health", "pour", "d\u00e9velopper", "de", "meilleures", "m\u00e9thodes", "de", "reconstruction", "des", "architectures", "neuronales", "."], "sentence-detokenized": "L'institut a collabor\u00e9 \u00e9troitement avec le campus Janelia Farm du Howard Hughes Medical Institute, l'Allen Institute for Brain Science et les National Institutes of Health pour d\u00e9velopper de meilleures m\u00e9thodes de reconstruction des architectures neuronales.", "token2charspan": [[0, 2], [2, 10], [11, 12], [13, 22], [23, 34], [35, 39], [40, 42], [43, 49], [50, 57], [58, 62], [63, 65], [66, 72], [73, 79], [80, 87], [88, 97], [97, 98], [99, 101], [101, 106], [107, 116], [117, 120], [121, 126], [127, 134], [135, 137], [138, 141], [142, 150], [151, 161], [162, 164], [165, 171], [172, 176], [177, 187], [188, 190], [191, 201], [202, 210], [211, 213], [214, 228], [229, 232], [233, 246], [247, 257], [257, 258]]}
{"doc_key": "ai-test-425", "ner": [[2, 2, "organisation"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 2, 2, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["R\u00e9cemment", ",", "Google", "a", "annonc\u00e9", "que", "Google", "Translate", "traduisait", "\u00e0", "peu", "pr\u00e8s", "assez", "de", "texte", "pour", "remplir", "1", "million", "de", "livres", "en", "une", "journ\u00e9e", "(", "2012", ")", "."], "sentence-detokenized": "R\u00e9cemment, Google a annonc\u00e9 que Google Translate traduisait \u00e0 peu pr\u00e8s assez de texte pour remplir 1 million de livres en une journ\u00e9e (2012).", "token2charspan": [[0, 9], [9, 10], [11, 17], [18, 19], [20, 27], [28, 31], [32, 38], [39, 48], [49, 59], [60, 61], [62, 65], [66, 70], [71, 76], [77, 79], [80, 85], [86, 90], [91, 98], [99, 100], [101, 108], [109, 111], [112, 118], [119, 121], [122, 125], [126, 133], [134, 135], [135, 139], [139, 140], [140, 141]]}
{"doc_key": "ai-test-426", "ner": [[15, 15, "country"], [18, 18, "country"], [21, 21, "country"], [24, 24, "country"], [27, 27, "country"], [30, 32, "country"], [43, 44, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Les", "\u00e9v\u00e9nements", "ont", "lieu", "dans", "le", "monde", "entier", ",", "et", "sont", "les", "plus", "populaires", "au", "Royaume-Uni", ",", "aux", "\u00c9tats-Unis", ",", "au", "Japon", ",", "\u00e0", "Singapour", ",", "en", "Inde", ",", "en", "Cor\u00e9e", "du", "Sud", "et", "deviennent", "populaires", "dans", "les", "pays", "du", "sous-continent", "comme", "le", "Sri", "Lanka", "."], "sentence-detokenized": "Les \u00e9v\u00e9nements ont lieu dans le monde entier, et sont les plus populaires au Royaume-Uni, aux \u00c9tats-Unis, au Japon, \u00e0 Singapour, en Inde, en Cor\u00e9e du Sud et deviennent populaires dans les pays du sous-continent comme le Sri Lanka.", "token2charspan": [[0, 3], [4, 14], [15, 18], [19, 23], [24, 28], [29, 31], [32, 37], [38, 44], [44, 45], [46, 48], [49, 53], [54, 57], [58, 62], [63, 73], [74, 76], [77, 88], [88, 89], [90, 93], [94, 104], [104, 105], [106, 108], [109, 114], [114, 115], [116, 117], [118, 127], [127, 128], [129, 131], [132, 136], [136, 137], [138, 140], [141, 146], [147, 149], [150, 153], [154, 156], [157, 167], [168, 178], [179, 183], [184, 187], [188, 192], [193, 195], [196, 210], [211, 216], [217, 219], [220, 223], [224, 229], [229, 230]]}
{"doc_key": "ai-test-427", "ner": [[6, 6, "programlang"], [11, 11, "programlang"], [13, 13, "programlang"], [15, 17, "programlang"], [20, 20, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ces", "paquets", "sont", "d\u00e9velopp\u00e9s", "principalement", "en", "R", ",", "et", "parfois", "en", "Java", ",", "C", ",", "C", "+", "+", ",", "et", "Fortran", "."], "sentence-detokenized": "Ces paquets sont d\u00e9velopp\u00e9s principalement en R, et parfois en Java, C, C + +, et Fortran.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 27], [28, 42], [43, 45], [46, 47], [47, 48], [49, 51], [52, 59], [60, 62], [63, 67], [67, 68], [69, 70], [70, 71], [72, 73], [74, 75], [76, 77], [77, 78], [79, 81], [82, 89], [89, 90]]}
{"doc_key": "ai-test-428", "ner": [[5, 15, "conference"], [13, 13, "conference"], [17, 17, "researcher"], [19, 19, "researcher"], [24, 25, "researcher"], [29, 30, "algorithm"], [35, 42, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 13, 5, 15, "named", "", false, false], [17, 17, 5, 15, "physical", "", false, false], [17, 17, 5, 15, "role", "", false, false], [17, 17, 24, 25, "role", "teams_up_with", false, false], [17, 17, 29, 30, "usage", "", false, false], [19, 19, 5, 15, "physical", "", false, false], [19, 19, 5, 15, "role", "", false, false], [19, 19, 24, 25, "role", "teams_up_with", false, false], [19, 19, 29, 30, "usage", "", false, false], [24, 25, 5, 15, "physical", "", false, false], [24, 25, 5, 15, "role", "", false, false], [24, 25, 29, 30, "usage", "", false, false], [29, 30, 35, 42, "related-to", "used_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Dans", "le", "cadre", "de", "la", "Conf\u00e9rence", "europ\u00e9enne", "sur", "la", "vision", "par", "ordinateur", "(", "ECCV", ")", "2006", ",", "Dalal", "et", "Triggs", "ont", "fait", "\u00e9quipe", "avec", "Cordelia", "Schmid", "pour", "appliquer", "les", "d\u00e9tecteurs", "HOG", "au", "probl\u00e8me", "de", "la", "d\u00e9tection", "humaine", "dans", "les", "films", "et", "les", "vid\u00e9os", "."], "sentence-detokenized": "Dans le cadre de la Conf\u00e9rence europ\u00e9enne sur la vision par ordinateur (ECCV) 2006, Dalal et Triggs ont fait \u00e9quipe avec Cordelia Schmid pour appliquer les d\u00e9tecteurs HOG au probl\u00e8me de la d\u00e9tection humaine dans les films et les vid\u00e9os.", "token2charspan": [[0, 4], [5, 7], [8, 13], [14, 16], [17, 19], [20, 30], [31, 41], [42, 45], [46, 48], [49, 55], [56, 59], [60, 70], [71, 72], [72, 76], [76, 77], [78, 82], [82, 83], [84, 89], [90, 92], [93, 99], [100, 103], [104, 108], [109, 115], [116, 120], [121, 129], [130, 136], [137, 141], [142, 151], [152, 155], [156, 166], [167, 170], [171, 173], [174, 182], [183, 185], [186, 188], [189, 198], [199, 206], [207, 211], [212, 215], [216, 221], [222, 224], [225, 228], [229, 235], [235, 236]]}
{"doc_key": "ai-test-429", "ner": [[2, 2, "metrics"], [5, 5, "metrics"], [13, 14, "task"], [20, 22, "metrics"], [24, 24, "metrics"], [29, 29, "metrics"], [33, 35, "metrics"], [37, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[2, 2, 13, 14, "related-to", "measured_with", false, false], [5, 5, 13, 14, "related-to", "measured_with", false, false], [20, 22, 13, 14, "related-to", "measured_with", false, false], [24, 24, 20, 22, "named", "", false, false], [29, 29, 20, 22, "named", "", false, false], [37, 37, 33, 35, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Outre", "la", "sensibilit\u00e9", "et", "la", "sp\u00e9cificit\u00e9", ",", "la", "performance", "d'", "un", "test", "de", "classification", "binaire", "peut", "\u00eatre", "mesur\u00e9e", "par", "la", "valeur", "pr\u00e9dictive", "positive", "(", "VPP", ")", ",", "\u00e9galement", "appel\u00e9e", "pr\u00e9cision", ",", "et", "la", "valeur", "pr\u00e9dictive", "n\u00e9gative", "(", "VPN", ")", "."], "sentence-detokenized": "Outre la sensibilit\u00e9 et la sp\u00e9cificit\u00e9, la performance d'un test de classification binaire peut \u00eatre mesur\u00e9e par la valeur pr\u00e9dictive positive (VPP), \u00e9galement appel\u00e9e pr\u00e9cision, et la valeur pr\u00e9dictive n\u00e9gative (VPN).", "token2charspan": [[0, 5], [6, 8], [9, 20], [21, 23], [24, 26], [27, 38], [38, 39], [40, 42], [43, 54], [55, 57], [57, 59], [60, 64], [65, 67], [68, 82], [83, 90], [91, 95], [96, 100], [101, 108], [109, 112], [113, 115], [116, 122], [123, 133], [134, 142], [143, 144], [144, 147], [147, 148], [148, 149], [150, 159], [160, 167], [168, 177], [177, 178], [179, 181], [182, 184], [185, 191], [192, 202], [203, 211], [212, 213], [213, 216], [216, 217], [217, 218]]}
{"doc_key": "ai-test-430", "ner": [[18, 23, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ces", "mod\u00e8les", "peuvent", "accorder", "un", "cr\u00e9dit", "partiel", "aux", "correspondances", "qui", "se", "chevauchent", "(", "par", "exemple", "en", "utilisant", "le", "crit\u00e8re", "de", "l'", "indice", "de", "Jaccard", "."], "sentence-detokenized": "Ces mod\u00e8les peuvent accorder un cr\u00e9dit partiel aux correspondances qui se chevauchent (par exemple en utilisant le crit\u00e8re de l'indice de Jaccard.", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 28], [29, 31], [32, 38], [39, 46], [47, 50], [51, 66], [67, 70], [71, 73], [74, 85], [86, 87], [87, 90], [91, 98], [99, 101], [102, 111], [112, 114], [115, 122], [123, 125], [126, 128], [128, 134], [135, 137], [138, 145], [145, 146]]}
{"doc_key": "ai-test-431", "ner": [[28, 36, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["En", "outre", ",", "dans", "le", "cas", "de", "l'", "estimation", "bas\u00e9e", "sur", "un", "seul", "\u00e9chantillon", ",", "il", "d\u00e9montre", "les", "questions", "philosophiques", "et", "les", "malentendus", "possibles", "dans", "l'", "utilisation", "des", "estimateurs", "de", "vraisemblance", "maximale", "et", "des", "fonctions", "de", "vraisemblance", "."], "sentence-detokenized": "En outre, dans le cas de l'estimation bas\u00e9e sur un seul \u00e9chantillon, il d\u00e9montre les questions philosophiques et les malentendus possibles dans l'utilisation des estimateurs de vraisemblance maximale et des fonctions de vraisemblance.", "token2charspan": [[0, 2], [3, 8], [8, 9], [10, 14], [15, 17], [18, 21], [22, 24], [25, 27], [27, 37], [38, 43], [44, 47], [48, 50], [51, 55], [56, 67], [67, 68], [69, 71], [72, 80], [81, 84], [85, 94], [95, 109], [110, 112], [113, 116], [117, 128], [129, 138], [139, 143], [144, 146], [146, 157], [158, 161], [162, 173], [174, 176], [177, 190], [191, 199], [200, 202], [203, 206], [207, 216], [217, 219], [220, 233], [233, 234]]}
