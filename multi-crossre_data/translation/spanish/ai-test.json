{"doc_key": "ai-test-1", "ner": [[9, 12, "algorithm"], [16, 18, "algorithm"], [20, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Los", "enfoques", "t\u00edpicos", "de", "los", "modelos", "generativos", "incluyen", "los", "clasificadores", "ingenuos", "de", "Bayes", ",", "los", "modelos", "de", "mezcla", "gaussiana", ",", "los", "autocodificadores", "variacionales", "y", "otros", "."], "sentence-detokenized": "Los enfoques t\u00edpicos de los modelos generativos incluyen los clasificadores ingenuos de Bayes, los modelos de mezcla gaussiana, los autocodificadores variacionales y otros.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 23], [24, 27], [28, 35], [36, 47], [48, 56], [57, 60], [61, 75], [76, 84], [85, 87], [88, 93], [93, 94], [95, 98], [99, 106], [107, 109], [110, 116], [117, 126], [126, 127], [128, 131], [132, 149], [150, 163], [164, 165], [166, 171], [171, 172]]}
{"doc_key": "ai-test-2", "ner": [[7, 8, "organisation"], [13, 13, "conference"], [16, 22, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 13, 13, "role", "", false, false], [16, 22, 13, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Por", "\u00faltimo", ",", "cada", "dos", "a\u00f1os", ",", "la", "ELRA", "organiza", "una", "importante", "conferencia", "LREC", ",", "la", "Conferencia", "Internacional", "de", "Recursos", "Ling\u00fc\u00edsticos", "y", "Evaluaci\u00f3n", "."], "sentence-detokenized": "Por \u00faltimo, cada dos a\u00f1os, la ELRA organiza una importante conferencia LREC, la Conferencia Internacional de Recursos Ling\u00fc\u00edsticos y Evaluaci\u00f3n.", "token2charspan": [[0, 3], [4, 10], [10, 11], [12, 16], [17, 20], [21, 25], [25, 26], [27, 29], [30, 34], [35, 43], [44, 47], [48, 58], [59, 70], [71, 75], [75, 76], [77, 79], [80, 91], [92, 105], [106, 108], [109, 117], [118, 130], [131, 132], [133, 143], [143, 144]]}
{"doc_key": "ai-test-3", "ner": [[7, 10, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "tarea", "suele", "consistir", "en", "derivar", "la", "estimaci\u00f3n", "de", "m\u00e1xima", "verosimilitud", "de", "los", "par\u00e1metros", "del", "HMM", "dadas", "las", "secuencias", "de", "salida", "."], "sentence-detokenized": "La tarea suele consistir en derivar la estimaci\u00f3n de m\u00e1xima verosimilitud de los par\u00e1metros del HMM dadas las secuencias de salida.", "token2charspan": [[0, 2], [3, 8], [9, 14], [15, 24], [25, 27], [28, 35], [36, 38], [39, 49], [50, 52], [53, 59], [60, 73], [74, 76], [77, 80], [81, 91], [92, 95], [96, 99], [100, 105], [106, 109], [110, 120], [121, 123], [124, 130], [130, 131]]}
{"doc_key": "ai-test-4", "ner": [[4, 5, "algorithm"], [8, 12, "algorithm"], [18, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 18, 19, "compare", "", false, false], [8, 12, 18, 19, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "diferencia", "de", "las", "redes", "neuronales", "y", "las", "m\u00e1quinas", "de", "vectores", "de", "apoyo", ",", "el", "proceso", "de", "entrenamiento", "de", "AdaBoost", "selecciona", "s\u00f3lo", "aquellas", "caracter\u00edsticas", "que", "se", "sabe", "que", "mejoran", "el", "poder", "predictivo", "del", "modelo", ",", "reduciendo", "la", "dimensionalidad", "y", "mejorando", "potencialmente", "el", "tiempo", "de", "ejecuci\u00f3n", ",", "ya", "que", "no", "es", "necesario", "calcular", "las", "caracter\u00edsticas", "irrelevantes", "."], "sentence-detokenized": "A diferencia de las redes neuronales y las m\u00e1quinas de vectores de apoyo, el proceso de entrenamiento de AdaBoost selecciona s\u00f3lo aquellas caracter\u00edsticas que se sabe que mejoran el poder predictivo del modelo, reduciendo la dimensionalidad y mejorando potencialmente el tiempo de ejecuci\u00f3n, ya que no es necesario calcular las caracter\u00edsticas irrelevantes.", "token2charspan": [[0, 1], [2, 12], [13, 15], [16, 19], [20, 25], [26, 36], [37, 38], [39, 42], [43, 51], [52, 54], [55, 63], [64, 66], [67, 72], [72, 73], [74, 76], [77, 84], [85, 87], [88, 101], [102, 104], [105, 113], [114, 124], [125, 129], [130, 138], [139, 154], [155, 158], [159, 161], [162, 166], [167, 170], [171, 178], [179, 181], [182, 187], [188, 198], [199, 202], [203, 209], [209, 210], [211, 221], [222, 224], [225, 240], [241, 242], [243, 252], [253, 267], [268, 270], [271, 277], [278, 280], [281, 290], [290, 291], [292, 294], [295, 298], [299, 301], [302, 304], [305, 314], [315, 323], [324, 327], [328, 343], [344, 356], [356, 357]]}
{"doc_key": "ai-test-5", "ner": [[0, 1, "misc"], [12, 14, "misc"], [16, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 12, 14, "part-of", "", false, false], [12, 14, 16, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "troponimia", "es", "una", "de", "las", "posibles", "relaciones", "entre", "verbos", "en", "la", "red", "sem\u00e1ntica", "de", "la", "base", "de", "datos", "WordNet", "."], "sentence-detokenized": "La troponimia es una de las posibles relaciones entre verbos en la red sem\u00e1ntica de la base de datos WordNet.", "token2charspan": [[0, 2], [3, 13], [14, 16], [17, 20], [21, 23], [24, 27], [28, 36], [37, 47], [48, 53], [54, 60], [61, 63], [64, 66], [67, 70], [71, 80], [81, 83], [84, 86], [87, 91], [92, 94], [95, 100], [101, 108], [108, 109]]}
{"doc_key": "ai-test-6", "ner": [[9, 11, "task"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 14, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Un", "lenguaje", "marco", "es", "una", "tecnolog\u00eda", "utilizada", "para", "la", "representaci\u00f3n", "del", "conocimiento", "en", "la", "inteligencia", "artificial", "."], "sentence-detokenized": "Un lenguaje marco es una tecnolog\u00eda utilizada para la representaci\u00f3n del conocimiento en la inteligencia artificial.", "token2charspan": [[0, 2], [3, 11], [12, 17], [18, 20], [21, 24], [25, 35], [36, 45], [46, 50], [51, 53], [54, 68], [69, 72], [73, 85], [86, 88], [89, 91], [92, 104], [105, 115], [115, 116]]}
{"doc_key": "ai-test-7", "ner": [[0, 1, "metrics"], [6, 7, "metrics"], [13, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["El", "NIST", "tambi\u00e9n", "difiere", "de", "la", "evaluaci\u00f3n", "biling\u00fce", "en", "su", "c\u00e1lculo", "de", "la", "penalizaci\u00f3n", "por", "brevedad", "en", "la", "medida", "en", "que", "las", "peque\u00f1as", "variaciones", "en", "la", "longitud", "de", "la", "traducci\u00f3n", "no", "afectan", "tanto", "a", "la", "puntuaci\u00f3n", "global", "."], "sentence-detokenized": "El NIST tambi\u00e9n difiere de la evaluaci\u00f3n biling\u00fce en su c\u00e1lculo de la penalizaci\u00f3n por brevedad en la medida en que las peque\u00f1as variaciones en la longitud de la traducci\u00f3n no afectan tanto a la puntuaci\u00f3n global.", "token2charspan": [[0, 2], [3, 7], [8, 15], [16, 23], [24, 26], [27, 29], [30, 40], [41, 49], [50, 52], [53, 55], [56, 63], [64, 66], [67, 69], [70, 82], [83, 86], [87, 95], [96, 98], [99, 101], [102, 108], [109, 111], [112, 115], [116, 119], [120, 128], [129, 140], [141, 143], [144, 146], [147, 155], [156, 158], [159, 161], [162, 172], [173, 175], [176, 183], [184, 189], [190, 191], [192, 194], [195, 205], [206, 212], [212, 213]]}
{"doc_key": "ai-test-8", "ner": [[7, 8, "algorithm"], [11, 13, "algorithm"], [28, 31, "field"], [40, 42, "algorithm"], [45, 48, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 8, 28, 31, "usage", "", false, false], [11, 13, 28, 31, "usage", "", false, false], [40, 42, 28, 31, "type-of", "", false, false], [45, 48, 28, 31, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["El", "modelo", "(", "por", "ejemplo", ",", "una", "red", "neuronal", "o", "un", "clasificador", "Bayes", "ingenuo", ")", "se", "entrena", "en", "el", "conjunto", "de", "datos", "de", "entrenamiento", "utilizando", "un", "m\u00e9todo", "de", "aprendizaje", "supervisado", ",", "por", "ejemplo", ",", "utilizando", "m\u00e9todos", "de", "optimizaci\u00f3n", "como", "el", "descenso", "de", "gradiente", "o", "el", "descenso", "de", "gradiente", "estoc\u00e1stico", "."], "sentence-detokenized": "El modelo (por ejemplo, una red neuronal o un clasificador Bayes ingenuo) se entrena en el conjunto de datos de entrenamiento utilizando un m\u00e9todo de aprendizaje supervisado, por ejemplo, utilizando m\u00e9todos de optimizaci\u00f3n como el descenso de gradiente o el descenso de gradiente estoc\u00e1stico.", "token2charspan": [[0, 2], [3, 9], [10, 11], [11, 14], [15, 22], [22, 23], [24, 27], [28, 31], [32, 40], [41, 42], [43, 45], [46, 58], [59, 64], [65, 72], [72, 73], [74, 76], [77, 84], [85, 87], [88, 90], [91, 99], [100, 102], [103, 108], [109, 111], [112, 125], [126, 136], [137, 139], [140, 146], [147, 149], [150, 161], [162, 173], [173, 174], [175, 178], [179, 186], [186, 187], [188, 198], [199, 206], [207, 209], [210, 222], [223, 227], [228, 230], [231, 239], [240, 242], [243, 252], [253, 254], [255, 257], [258, 266], [267, 269], [270, 279], [280, 291], [291, 292]]}
{"doc_key": "ai-test-9", "ner": [[0, 2, "product"], [8, 10, "task"], [13, 13, "task"], [16, 20, "task"], [23, 25, "task"], [34, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 10, 0, 2, "usage", "", true, false], [13, 13, 0, 2, "usage", "", true, false], [16, 20, 0, 2, "usage", "", true, false], [23, 25, 0, 2, "usage", "", true, false], [34, 37, 0, 2, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["FrameNet", "se", "ha", "utilizado", "en", "aplicaciones", "como", "la", "respuesta", "a", "preguntas", ",", "la", "par\u00e1frasis", ",", "el", "reconocimiento", "de", "la", "vinculaci\u00f3n", "textual", "y", "la", "extracci\u00f3n", "de", "informaci\u00f3n", ",", "ya", "sea", "directamente", "o", "mediante", "herramientas", "de", "etiquetado", "sem\u00e1ntico", "de", "roles", "."], "sentence-detokenized": "FrameNet se ha utilizado en aplicaciones como la respuesta a preguntas, la par\u00e1frasis, el reconocimiento de la vinculaci\u00f3n textual y la extracci\u00f3n de informaci\u00f3n, ya sea directamente o mediante herramientas de etiquetado sem\u00e1ntico de roles.", "token2charspan": [[0, 8], [9, 11], [12, 14], [15, 24], [25, 27], [28, 40], [41, 45], [46, 48], [49, 58], [59, 60], [61, 70], [70, 71], [72, 74], [75, 85], [85, 86], [87, 89], [90, 104], [105, 107], [108, 110], [111, 122], [123, 130], [131, 132], [133, 135], [136, 146], [147, 149], [150, 161], [161, 162], [163, 165], [166, 169], [170, 182], [183, 184], [185, 193], [194, 206], [207, 209], [210, 220], [221, 230], [231, 233], [234, 239], [239, 240]]}
{"doc_key": "ai-test-10", "ner": [[6, 10, "field"], [12, 16, "misc"], [19, 19, "product"], [22, 26, "misc"], [29, 29, "product"], [32, 35, "field"], [38, 38, "product"], [41, 44, "misc"], [49, 49, "product"], [51, 51, "product"], [53, 53, "product"], [56, 59, "misc"], [62, 63, "product"], [65, 66, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[19, 19, 12, 16, "general-affiliation", "", false, false], [29, 29, 22, 26, "general-affiliation", "", false, false], [38, 38, 32, 35, "general-affiliation", "", false, false], [49, 49, 41, 44, "type-of", "", false, false], [51, 51, 41, 44, "type-of", "", false, false], [53, 53, 41, 44, "type-of", "", false, false], [62, 63, 56, 59, "general-affiliation", "", false, false], [65, 66, 56, 59, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Esto", "incluir\u00eda", "programas", "como", "herramientas", "de", "an\u00e1lisis", "y", "extracci\u00f3n", "de", "datos", ",", "hojas", "de", "c\u00e1lculo", "(", "por", "ejemplo", ",", "Excel", ")", ",", "bases", "de", "datos", "(", "por", "ejemplo", ",", "Access", ")", ",", "an\u00e1lisis", "estad\u00edstico", "(", "por", "ejemplo", ",", "SAS", ")", ",", "software", "de", "auditor\u00eda", "generalizada", "(", "por", "ejemplo", ",", "ACL", ",", "Arbutus", ",", "EAS", ")", ",", "inteligencia", "empresarial", "(", "por", "ejemplo", ",", "Crystal", "Reports", "y", "Business", "Objects", ")", ",", "etc", "."], "sentence-detokenized": "Esto incluir\u00eda programas como herramientas de an\u00e1lisis y extracci\u00f3n de datos, hojas de c\u00e1lculo (por ejemplo, Excel), bases de datos (por ejemplo, Access), an\u00e1lisis estad\u00edstico (por ejemplo, SAS), software de auditor\u00eda generalizada (por ejemplo, ACL, Arbutus, EAS), inteligencia empresarial (por ejemplo, Crystal Reports y Business Objects), etc.", "token2charspan": [[0, 4], [5, 14], [15, 24], [25, 29], [30, 42], [43, 45], [46, 54], [55, 56], [57, 67], [68, 70], [71, 76], [76, 77], [78, 83], [84, 86], [87, 94], [95, 96], [96, 99], [100, 107], [107, 108], [109, 114], [114, 115], [115, 116], [117, 122], [123, 125], [126, 131], [132, 133], [133, 136], [137, 144], [144, 145], [146, 152], [152, 153], [153, 154], [155, 163], [164, 175], [176, 177], [177, 180], [181, 188], [188, 189], [190, 193], [193, 194], [194, 195], [196, 204], [205, 207], [208, 217], [218, 230], [231, 232], [232, 235], [236, 243], [243, 244], [245, 248], [248, 249], [250, 257], [257, 258], [259, 262], [262, 263], [263, 264], [265, 277], [278, 289], [290, 291], [291, 294], [295, 302], [302, 303], [304, 311], [312, 319], [320, 321], [322, 330], [331, 338], [338, 339], [339, 340], [341, 344], [344, 345]]}
{"doc_key": "ai-test-11", "ner": [[0, 1, "organisation"], [4, 5, "researcher"], [12, 12, "product"], [20, 21, "product"]], "ner_mapping_to_source": [0, 1, 3, 4], "relations": [[0, 1, 4, 5, "origin", "", false, false], [12, 12, 20, 21, "type-of", "", false, false], [20, 21, 4, 5, "origin", "introduced_by", false, false]], "relations_mapping_to_source": [0, 2, 3], "sentence": ["Rethink", "Robotics", "-fundada", "por", "Rodney", "Brooks", ",", "anteriormente", "en", "iRobot-", "present\u00f3", "a", "Baxter", "en", "septiembre", "de", "2012", ";", "como", "un", "robot", "industrial", "dise\u00f1ado", "para", "interactuar", "de", "forma", "segura", "con", "los", "trabajadores", "humanos", "cercanos", ",", "y", "ser", "programable", "para", "realizar", "tareas", "sencillas", "."], "sentence-detokenized": "Rethink Robotics -fundada por Rodney Brooks, anteriormente en iRobot- present\u00f3 a Baxter en septiembre de 2012; como un robot industrial dise\u00f1ado para interactuar de forma segura con los trabajadores humanos cercanos, y ser programable para realizar tareas sencillas.", "token2charspan": [[0, 7], [8, 16], [17, 25], [26, 29], [30, 36], [37, 43], [43, 44], [45, 58], [59, 61], [62, 69], [70, 78], [79, 80], [81, 87], [88, 90], [91, 101], [102, 104], [105, 109], [109, 110], [111, 115], [116, 118], [119, 124], [125, 135], [136, 144], [145, 149], [150, 161], [162, 164], [165, 170], [171, 177], [178, 181], [182, 185], [186, 198], [199, 206], [207, 215], [215, 216], [217, 218], [219, 222], [223, 234], [235, 239], [240, 248], [249, 255], [256, 265], [265, 266]]}
{"doc_key": "ai-test-12", "ner": [[5, 7, "field"], [10, 12, "task"], [15, 17, "task"], [20, 22, "task"], [25, 28, "task"], [31, 33, "task"], [36, 38, "task"], [41, 45, "task"], [56, 60, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[10, 12, 5, 7, "part-of", "task_part_of_field", false, false], [15, 17, 5, 7, "part-of", "task_part_of_field", false, false], [20, 22, 5, 7, "part-of", "task_part_of_field", false, false], [25, 28, 5, 7, "part-of", "task_part_of_field", false, false], [31, 33, 5, 7, "part-of", "task_part_of_field", false, false], [36, 38, 5, 7, "part-of", "task_part_of_field", false, false], [41, 45, 5, 7, "part-of", "task_part_of_field", false, false], [56, 60, 5, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Las", "tareas", "t\u00edpicas", "de", "la", "miner\u00eda", "de", "textos", "incluyen", "la", "categorizaci\u00f3n", "de", "textos", ",", "la", "agrupaci\u00f3n", "de", "textos", ",", "la", "extracci\u00f3n", "de", "conceptos/entidades", ",", "la", "producci\u00f3n", "de", "taxonom\u00edas", "granulares", ",", "el", "an\u00e1lisis", "de", "sentimientos", ",", "el", "resumen", "de", "documentos", "y", "el", "modelado", "de", "relaciones", "de", "entidades", "(", "es", "decir", ",", "el", "aprendizaje", "de", "relaciones", "entre", "el", "reconocimiento", "de", "entidades", "con", "nombre", ")", "."], "sentence-detokenized": "Las tareas t\u00edpicas de la miner\u00eda de textos incluyen la categorizaci\u00f3n de textos, la agrupaci\u00f3n de textos, la extracci\u00f3n de conceptos/entidades, la producci\u00f3n de taxonom\u00edas granulares, el an\u00e1lisis de sentimientos, el resumen de documentos y el modelado de relaciones de entidades (es decir, el aprendizaje de relaciones entre el reconocimiento de entidades con nombre).", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 21], [22, 24], [25, 32], [33, 35], [36, 42], [43, 51], [52, 54], [55, 69], [70, 72], [73, 79], [79, 80], [81, 83], [84, 94], [95, 97], [98, 104], [104, 105], [106, 108], [109, 119], [120, 122], [123, 142], [142, 143], [144, 146], [147, 157], [158, 160], [161, 171], [172, 182], [182, 183], [184, 186], [187, 195], [196, 198], [199, 211], [211, 212], [213, 215], [216, 223], [224, 226], [227, 237], [238, 239], [240, 242], [243, 251], [252, 254], [255, 265], [266, 268], [269, 278], [279, 280], [280, 282], [283, 288], [288, 289], [290, 292], [293, 304], [305, 307], [308, 318], [319, 324], [325, 327], [328, 342], [343, 345], [346, 355], [356, 359], [360, 366], [366, 367], [367, 368]]}
{"doc_key": "ai-test-13", "ner": [[7, 7, "metrics"], [11, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sin", "embargo", ",", "el", "stemming", "reduce", "la", "precisi\u00f3n", ",", "o", "la", "tasa", "de", "verdaderos", "negativos", ",", "en", "estos", "sistemas", "."], "sentence-detokenized": "Sin embargo, el stemming reduce la precisi\u00f3n, o la tasa de verdaderos negativos, en estos sistemas.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 24], [25, 31], [32, 34], [35, 44], [44, 45], [46, 47], [48, 50], [51, 55], [56, 58], [59, 69], [70, 79], [79, 80], [81, 83], [84, 89], [90, 98], [98, 99]]}
{"doc_key": "ai-test-14", "ner": [[4, 7, "task"], [12, 14, "misc"], [18, 21, "misc"], [28, 28, "product"], [30, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 14, 4, 7, "temporal", "", false, false], [18, 21, 12, 14, "named", "", false, false], [28, 28, 12, 14, "usage", "", false, false], [30, 30, 12, 14, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Un", "caso", "especial", "de", "detecci\u00f3n", "de", "palabras", "clave", "es", "la", "detecci\u00f3n", "de", "palabras", "de", "despertador", "(", "tambi\u00e9n", "llamada", "palabra", "caliente", ")", "que", "utilizan", "los", "asistentes", "digitales", "personales", "como", "Alexa", "o", "Siri", "para", "despertarse", "cuando", "se", "pronuncia", "su", "nombre", "."], "sentence-detokenized": "Un caso especial de detecci\u00f3n de palabras clave es la detecci\u00f3n de palabras de despertador (tambi\u00e9n llamada palabra caliente) que utilizan los asistentes digitales personales como Alexa o Siri para despertarse cuando se pronuncia su nombre.", "token2charspan": [[0, 2], [3, 7], [8, 16], [17, 19], [20, 29], [30, 32], [33, 41], [42, 47], [48, 50], [51, 53], [54, 63], [64, 66], [67, 75], [76, 78], [79, 90], [91, 92], [92, 99], [100, 107], [108, 115], [116, 124], [124, 125], [126, 129], [130, 138], [139, 142], [143, 153], [154, 163], [164, 174], [175, 179], [180, 185], [186, 187], [188, 192], [193, 197], [198, 209], [210, 216], [217, 219], [220, 229], [230, 232], [233, 239], [239, 240]]}
{"doc_key": "ai-test-15", "ner": [[0, 0, "programlang"], [11, 11, "programlang"], [13, 13, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 0, 0, "part-of", "", false, false], [13, 13, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prova", "es", "un", "lenguaje", "de", "programaci\u00f3n", "de", "c\u00f3digo", "abierto", "que", "combina", "Prolog", "con", "Java", "."], "sentence-detokenized": "Prova es un lenguaje de programaci\u00f3n de c\u00f3digo abierto que combina Prolog con Java.", "token2charspan": [[0, 5], [6, 8], [9, 11], [12, 20], [21, 23], [24, 36], [37, 39], [40, 46], [47, 54], [55, 58], [59, 66], [67, 73], [74, 77], [78, 82], [82, 83]]}
{"doc_key": "ai-test-16", "ner": [[3, 4, "organisation"], [9, 9, "organisation"], [20, 21, "product"], [18, 19, "country"], [35, 35, "organisation"], [46, 47, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 9, 9, "part-of", "", false, false], [3, 4, 9, 9, "role", "sells", false, false], [3, 4, 18, 19, "role", "sells_to", false, false], [35, 35, 46, 47, "opposite", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["En", "1987", ",", "Tocibai", "Machine", ",", "una", "filial", "de", "Toshiba", ",", "fue", "acusada", "de", "vender", "ilegalmente", "a", "la", "Uni\u00f3n", "Sovi\u00e9tica", "fresados", "CNC", "utilizados", "para", "fabricar", "h\u00e9lices", "de", "submarinos", "muy", "silenciosas", ",", "en", "violaci\u00f3n", "del", "acuerdo", "CoCom", ",", "un", "embargo", "internacional", "a", "determinados", "pa\u00edses", "a", "los", "pa\u00edses", "del", "COMECON", "."], "sentence-detokenized": "En 1987, Tocibai Machine, una filial de Toshiba, fue acusada de vender ilegalmente a la Uni\u00f3n Sovi\u00e9tica fresados CNC utilizados para fabricar h\u00e9lices de submarinos muy silenciosas, en violaci\u00f3n del acuerdo CoCom, un embargo internacional a determinados pa\u00edses a los pa\u00edses del COMECON.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 24], [24, 25], [26, 29], [30, 36], [37, 39], [40, 47], [47, 48], [49, 52], [53, 60], [61, 63], [64, 70], [71, 82], [83, 84], [85, 87], [88, 93], [94, 103], [104, 112], [113, 116], [117, 127], [128, 132], [133, 141], [142, 149], [150, 152], [153, 163], [164, 167], [168, 179], [179, 180], [181, 183], [184, 193], [194, 197], [198, 205], [206, 211], [211, 212], [213, 215], [216, 223], [224, 237], [238, 239], [240, 252], [253, 259], [260, 261], [262, 265], [266, 272], [273, 276], [277, 284], [284, 285]]}
{"doc_key": "ai-test-17", "ner": [[5, 5, "researcher"], [8, 11, "product"], [22, 28, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 11, 5, 5, "artifact", "", false, false], [8, 11, 22, 28, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["El", "invento", "m\u00e1s", "famoso", "de", "Engelberger", ",", "el", "brazo", "rob\u00f3tico", "industrial", "Unimate", ",", "fue", "uno", "de", "los", "primeros", "en", "entrar", "en", "el", "Sal\u00f3n", "de", "la", "Fama", "de", "los", "Robots", "en", "2003", "."], "sentence-detokenized": "El invento m\u00e1s famoso de Engelberger, el brazo rob\u00f3tico industrial Unimate, fue uno de los primeros en entrar en el Sal\u00f3n de la Fama de los Robots en 2003.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 21], [22, 24], [25, 36], [36, 37], [38, 40], [41, 46], [47, 55], [56, 66], [67, 74], [74, 75], [76, 79], [80, 83], [84, 86], [87, 90], [91, 99], [100, 102], [103, 109], [110, 112], [113, 115], [116, 121], [122, 124], [125, 127], [128, 132], [133, 135], [136, 139], [140, 146], [147, 149], [150, 154], [154, 155]]}
{"doc_key": "ai-test-18", "ner": [[9, 10, "misc"], [13, 13, "misc"], [18, 18, "person"], [26, 27, "field"], [30, 30, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 10, 13, 13, "usage", "", false, false], [18, 18, 26, 27, "role", "", false, false], [26, 27, 30, 30, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Aunque", "en", "un", "principio", "se", "controlaba", "mediante", "p\u00e1ginas", "web", "html", "est\u00e1ticas", "que", "utilizaban", "CGI", ",", "el", "trabajo", "de", "Dalton", "supuso", "la", "introducci\u00f3n", "de", "una", "interfaz", "de", "realidad", "aumentada", "basada", "en", "Java", "que", "tuvo", "un", "\u00e9xito", "limitado", "."], "sentence-detokenized": "Aunque en un principio se controlaba mediante p\u00e1ginas web html est\u00e1ticas que utilizaban CGI, el trabajo de Dalton supuso la introducci\u00f3n de una interfaz de realidad aumentada basada en Java que tuvo un \u00e9xito limitado.", "token2charspan": [[0, 6], [7, 9], [10, 12], [13, 22], [23, 25], [26, 36], [37, 45], [46, 53], [54, 57], [58, 62], [63, 72], [73, 76], [77, 87], [88, 91], [91, 92], [93, 95], [96, 103], [104, 106], [107, 113], [114, 120], [121, 123], [124, 136], [137, 139], [140, 143], [144, 152], [153, 155], [156, 164], [165, 174], [175, 181], [182, 184], [185, 189], [190, 193], [194, 198], [199, 201], [202, 207], [208, 216], [216, 217]]}
{"doc_key": "ai-test-19", "ner": [[5, 6, "task"], [14, 15, "organisation"], [35, 35, "conference"], [39, 39, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 14, 15, "origin", "", false, false], [35, 35, 39, 39, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "primera", "publicaci\u00f3n", "sobre", "la", "especificaci\u00f3n", "LMF", "tal", "y", "como", "ha", "sido", "ratificada", "por", "la", "ISO", "(", "este", "art\u00edculo", "se", "convirti\u00f3", "(", "en", "2015", ")", "en", "el", "noveno", "art\u00edculo", "m\u00e1s", "citado", "dentro", "de", "las", "conferencias", "LREC", "de", "los", "art\u00edculos", "LREC", ")", ":"], "sentence-detokenized": "La primera publicaci\u00f3n sobre la especificaci\u00f3n LMF tal y como ha sido ratificada por la ISO (este art\u00edculo se convirti\u00f3 (en 2015) en el noveno art\u00edculo m\u00e1s citado dentro de las conferencias LREC de los art\u00edculos LREC):", "token2charspan": [[0, 2], [3, 10], [11, 22], [23, 28], [29, 31], [32, 46], [47, 50], [51, 54], [55, 56], [57, 61], [62, 64], [65, 69], [70, 80], [81, 84], [85, 87], [88, 91], [92, 93], [93, 97], [98, 106], [107, 109], [110, 119], [120, 121], [121, 123], [124, 128], [128, 129], [130, 132], [133, 135], [136, 142], [143, 151], [152, 155], [156, 162], [163, 169], [170, 172], [173, 176], [177, 189], [190, 194], [195, 197], [198, 201], [202, 211], [212, 216], [216, 217], [217, 218]]}
{"doc_key": "ai-test-20", "ner": [[1, 3, "metrics"], [17, 19, "metrics"], [20, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 19, 1, 3, "usage", "", false, false], [17, 19, 20, 22, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Una", "matriz", "de", "confusi\u00f3n", "o", "matriz", "de", "coincidencia", "se", "utiliza", "a", "menudo", "como", "herramienta", "para", "validar", "la", "precisi\u00f3n", "de", "la", "clasificaci\u00f3n", "k", "-NN", "."], "sentence-detokenized": "Una matriz de confusi\u00f3n o matriz de coincidencia se utiliza a menudo como herramienta para validar la precisi\u00f3n de la clasificaci\u00f3n k -NN.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 23], [24, 25], [26, 32], [33, 35], [36, 48], [49, 51], [52, 59], [60, 61], [62, 68], [69, 73], [74, 85], [86, 90], [91, 98], [99, 101], [102, 111], [112, 114], [115, 117], [118, 131], [132, 133], [134, 137], [137, 138]]}
{"doc_key": "ai-test-21", "ner": [[3, 5, "algorithm"], [16, 16, "field"], [18, 20, "field"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 5, 16, 16, "part-of", "", false, false], [3, 5, 18, 20, "part-of", "", false, false], [3, 5, 22, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["El", "aprendizaje", "de", "\u00e1rboles", "de", "decisi\u00f3n", "es", "uno", "de", "los", "enfoques", "de", "modelado", "predictivo", "utilizados", "en", "estad\u00edstica", ",", "miner\u00eda", "de", "datos", "y", "aprendizaje", "autom\u00e1tico", "."], "sentence-detokenized": "El aprendizaje de \u00e1rboles de decisi\u00f3n es uno de los enfoques de modelado predictivo utilizados en estad\u00edstica, miner\u00eda de datos y aprendizaje autom\u00e1tico.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 25], [26, 28], [29, 37], [38, 40], [41, 44], [45, 47], [48, 51], [52, 60], [61, 63], [64, 72], [73, 83], [84, 94], [95, 97], [98, 109], [109, 110], [111, 118], [119, 121], [122, 127], [128, 129], [130, 141], [142, 152], [152, 153]]}
{"doc_key": "ai-test-22", "ner": [[6, 6, "misc"], [20, 24, "field"], [25, 27, "algorithm"], [29, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 20, 24, "related-to", "", true, false], [25, 27, 20, 24, "type-of", "", false, false], [29, 29, 20, 24, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["En", "tiempo", "de", "ejecuci\u00f3n", ",", "la", "prosodia", "objetivo", "de", "una", "frase", "se", "superpone", "a", "estas", "unidades", "m\u00ednimas", "mediante", "t\u00e9cnicas", "de", "procesamiento", "de", "se\u00f1ales", "como", "la", "codificaci\u00f3n", "predictiva", "lineal", ",", "PSOLA"], "sentence-detokenized": "En tiempo de ejecuci\u00f3n, la prosodia objetivo de una frase se superpone a estas unidades m\u00ednimas mediante t\u00e9cnicas de procesamiento de se\u00f1ales como la codificaci\u00f3n predictiva lineal, PSOLA", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 22], [22, 23], [24, 26], [27, 35], [36, 44], [45, 47], [48, 51], [52, 57], [58, 60], [61, 70], [71, 72], [73, 78], [79, 87], [88, 95], [96, 104], [105, 113], [114, 116], [117, 130], [131, 133], [134, 141], [142, 146], [147, 149], [150, 162], [163, 173], [174, 180], [180, 181], [182, 187]]}
{"doc_key": "ai-test-23", "ner": [[4, 5, "field"], [8, 9, "field"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 19, 4, 5, "usage", "", true, false], [18, 19, 8, 9, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Este", "enfoque", "utiliza", "la", "inteligencia", "artificial", "y", "el", "aprendizaje", "autom\u00e1tico", "para", "permitir", "a", "los", "investigadores", "comparar", "visiblemente", "las", "im\u00e1genes", "faciales", "convencionales", "y", "las", "t\u00e9rmicas", "."], "sentence-detokenized": "Este enfoque utiliza la inteligencia artificial y el aprendizaje autom\u00e1tico para permitir a los investigadores comparar visiblemente las im\u00e1genes faciales convencionales y las t\u00e9rmicas.", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 23], [24, 36], [37, 47], [48, 49], [50, 52], [53, 64], [65, 75], [76, 80], [81, 89], [90, 91], [92, 95], [96, 110], [111, 119], [120, 132], [133, 136], [137, 145], [146, 154], [155, 169], [170, 171], [172, 175], [176, 184], [184, 185]]}
{"doc_key": "ai-test-24", "ner": [[1, 1, "field"], [4, 5, "algorithm"], [13, 14, "task"], [18, 19, "misc"], [26, 27, "field"], [30, 31, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 1, 1, "part-of", "", false, false], [4, 5, 13, 14, "topic", "", false, false], [13, 14, 18, 19, "origin", "", false, false], [26, 27, 1, 1, "part-of", "", false, false], [26, 27, 4, 5, "topic", "", false, false], [30, 31, 1, 1, "part-of", "", false, false], [30, 31, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["En", "inform\u00e1tica", ",", "la", "computaci\u00f3n", "evolutiva", "es", "una", "familia", "de", "algoritmos", "para", "la", "optimizaci\u00f3n", "global", "inspirada", "en", "la", "evoluci\u00f3n", "biol\u00f3gica", ",", "y", "el", "subcampo", "de", "la", "inteligencia", "artificial", "y", "la", "computaci\u00f3n", "blanda", "que", "estudia", "estos", "algoritmos", "."], "sentence-detokenized": "En inform\u00e1tica, la computaci\u00f3n evolutiva es una familia de algoritmos para la optimizaci\u00f3n global inspirada en la evoluci\u00f3n biol\u00f3gica, y el subcampo de la inteligencia artificial y la computaci\u00f3n blanda que estudia estos algoritmos.", "token2charspan": [[0, 2], [3, 14], [14, 15], [16, 18], [19, 30], [31, 40], [41, 43], [44, 47], [48, 55], [56, 58], [59, 69], [70, 74], [75, 77], [78, 90], [91, 97], [98, 107], [108, 110], [111, 113], [114, 123], [124, 133], [133, 134], [135, 136], [137, 139], [140, 148], [149, 151], [152, 154], [155, 167], [168, 178], [179, 180], [181, 183], [184, 195], [196, 202], [203, 206], [207, 214], [215, 220], [221, 231], [231, 232]]}
{"doc_key": "ai-test-25", "ner": [[11, 13, "metrics"], [16, 18, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Por", "ejemplo", ",", "se", "puede", "combinar", "alguna", "medida", "basada", "en", "la", "matriz", "de", "confusi\u00f3n", "con", "el", "error", "cuadr\u00e1tico", "medio", "evaluado", "entre", "los", "resultados", "brutos", "del", "modelo", "y", "los", "valores", "reales", "."], "sentence-detokenized": "Por ejemplo, se puede combinar alguna medida basada en la matriz de confusi\u00f3n con el error cuadr\u00e1tico medio evaluado entre los resultados brutos del modelo y los valores reales.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 21], [22, 30], [31, 37], [38, 44], [45, 51], [52, 54], [55, 57], [58, 64], [65, 67], [68, 77], [78, 81], [82, 84], [85, 90], [91, 101], [102, 107], [108, 116], [117, 122], [123, 126], [127, 137], [138, 144], [145, 148], [149, 155], [156, 157], [158, 161], [162, 169], [170, 176], [176, 177]]}
{"doc_key": "ai-test-26", "ner": [[5, 5, "product"], [9, 9, "researcher"], [6, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 9, 9, "origin", "", false, false], [5, 5, 6, 15, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "mayor\u00eda", "son", "resultados", "del", "modelo", "word2vec", "desarrollado", "por", "Mikolov", "et", "al", "o", "variantes", "de", "word2vec", "."], "sentence-detokenized": "La mayor\u00eda son resultados del modelo word2vec desarrollado por Mikolov et al o variantes de word2vec.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 25], [26, 29], [30, 36], [37, 45], [46, 58], [59, 62], [63, 70], [71, 73], [74, 76], [77, 78], [79, 88], [89, 91], [92, 100], [100, 101]]}
{"doc_key": "ai-test-27", "ner": [[13, 13, "conference"], [16, 21, "conference"], [23, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 23, 16, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Durante", "este", "tiempo", ",", "un", "total", "de", "43", "publicaciones", "fueron", "reconocidas", "por", "el", "CVPR", "y", "la", "Conferencia", "Internacional", "de", "Visi\u00f3n", "por", "Computador", "(", "ICCV", ")", "."], "sentence-detokenized": "Durante este tiempo, un total de 43 publicaciones fueron reconocidas por el CVPR y la Conferencia Internacional de Visi\u00f3n por Computador (ICCV).", "token2charspan": [[0, 7], [8, 12], [13, 19], [19, 20], [21, 23], [24, 29], [30, 32], [33, 35], [36, 49], [50, 56], [57, 68], [69, 72], [73, 75], [76, 80], [81, 82], [83, 85], [86, 97], [98, 111], [112, 114], [115, 121], [122, 125], [126, 136], [137, 138], [138, 142], [142, 143], [143, 144]]}
{"doc_key": "ai-test-28", "ner": [[1, 1, "product"], [15, 17, "field"], [24, 26, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 15, 17, "general-affiliation", "platform_for_education_about", false, false], [24, 26, 1, 1, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["El", "AIBO", "se", "ha", "utilizado", "mucho", "como", "plataforma", "econ\u00f3mica", "para", "la", "educaci\u00f3n", "e", "investigaci\u00f3n", "de", "la", "inteligencia", "artificial", ",", "porque", "integra", "un", "ordenador", ",", "visi\u00f3n", "por", "ordenador", "y", "articuladores", "en", "un", "paquete", "mucho", "m\u00e1s", "barato", "que", "los", "robots", "de", "investigaci\u00f3n", "convencionales", "."], "sentence-detokenized": "El AIBO se ha utilizado mucho como plataforma econ\u00f3mica para la educaci\u00f3n e investigaci\u00f3n de la inteligencia artificial, porque integra un ordenador, visi\u00f3n por ordenador y articuladores en un paquete mucho m\u00e1s barato que los robots de investigaci\u00f3n convencionales.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 13], [14, 23], [24, 29], [30, 34], [35, 45], [46, 55], [56, 60], [61, 63], [64, 73], [74, 75], [76, 89], [90, 92], [93, 95], [96, 108], [109, 119], [119, 120], [121, 127], [128, 135], [136, 138], [139, 148], [148, 149], [150, 156], [157, 160], [161, 170], [171, 172], [173, 186], [187, 189], [190, 192], [193, 200], [201, 206], [207, 210], [211, 217], [218, 221], [222, 225], [226, 232], [233, 235], [236, 249], [250, 264], [264, 265]]}
{"doc_key": "ai-test-29", "ner": [[7, 13, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ha", "sido", "presidenta", "del", "programa", "de", "la", "Conferencia", "Internacional", "de", "Visi\u00f3n", "por", "Computador", "2021", "."], "sentence-detokenized": "Ha sido presidenta del programa de la Conferencia Internacional de Visi\u00f3n por Computador 2021.", "token2charspan": [[0, 2], [3, 7], [8, 18], [19, 22], [23, 31], [32, 34], [35, 37], [38, 49], [50, 63], [64, 66], [67, 73], [74, 77], [78, 88], [89, 93], [93, 94]]}
{"doc_key": "ai-test-30", "ner": [[0, 0, "researcher"], [7, 7, "organisation"], [16, 16, "organisation"], [26, 27, "organisation"], [34, 38, "product"], [40, 40, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 7, 7, "role", "", false, false], [0, 0, 16, 16, "role", "", true, false], [16, 16, 26, 27, "role", "develops_with", false, false], [34, 38, 16, 16, "artifact", "", false, false], [40, 40, 34, 38, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Scheinman", ",", "tras", "recibir", "una", "beca", "de", "Unimation", "para", "desarrollar", "sus", "dise\u00f1os", ",", "los", "vendi\u00f3", "a", "Unimation", ",", "que", "los", "sigui\u00f3", "desarrollando", "con", "el", "apoyo", "de", "General", "Motors", "y", "m\u00e1s", "tarde", "los", "comercializ\u00f3", "como", "M\u00e1quina", "Universal", "Programable", "para", "Ensamblaje", "(", "PUMA", ")", "."], "sentence-detokenized": "Scheinman, tras recibir una beca de Unimation para desarrollar sus dise\u00f1os, los vendi\u00f3 a Unimation, que los sigui\u00f3 desarrollando con el apoyo de General Motors y m\u00e1s tarde los comercializ\u00f3 como M\u00e1quina Universal Programable para Ensamblaje (PUMA).", "token2charspan": [[0, 9], [9, 10], [11, 15], [16, 23], [24, 27], [28, 32], [33, 35], [36, 45], [46, 50], [51, 62], [63, 66], [67, 74], [74, 75], [76, 79], [80, 86], [87, 88], [89, 98], [98, 99], [100, 103], [104, 107], [108, 114], [115, 128], [129, 132], [133, 135], [136, 141], [142, 144], [145, 152], [153, 159], [160, 161], [162, 165], [166, 171], [172, 175], [176, 188], [189, 193], [194, 201], [202, 211], [212, 223], [224, 228], [229, 239], [240, 241], [241, 245], [245, 246], [246, 247]]}
{"doc_key": "ai-test-31", "ner": [[17, 17, "task"], [14, 19, "task"], [0, 0, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 17, 17, "general-affiliation", "works_with", false, false], [0, 0, 14, 19, "general-affiliation", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Gebel", "(", "2009", ")", "ofrece", "una", "visi\u00f3n", "general", "de", "los", "m\u00e9todos", "de", "calibraci\u00f3n", "para", "tareas", "de", "clasificaci\u00f3n", "binaria", "y", "multiclase"], "sentence-detokenized": "Gebel (2009) ofrece una visi\u00f3n general de los m\u00e9todos de calibraci\u00f3n para tareas de clasificaci\u00f3n binaria y multiclase", "token2charspan": [[0, 5], [6, 7], [7, 11], [11, 12], [13, 19], [20, 23], [24, 30], [31, 38], [39, 41], [42, 45], [46, 53], [54, 56], [57, 68], [69, 73], [74, 80], [81, 83], [84, 97], [98, 105], [106, 107], [108, 118]]}
{"doc_key": "ai-test-32", "ner": [[5, 8, "task"], [10, 10, "task"], [14, 16, "task"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 10, 5, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Participa", "en", "campos", "como", "el", "reconocimiento", "\u00f3ptico", "de", "caracteres", "(", "OCR", ")", ",", "la", "s\u00edntesis", "del", "habla", ",", "la", "tecnolog\u00eda", "de", "reconocimiento", "del", "habla", "y", "los", "instrumentos", "de", "teclado", "electr\u00f3nico", "."], "sentence-detokenized": "Participa en campos como el reconocimiento \u00f3ptico de caracteres (OCR), la s\u00edntesis del habla, la tecnolog\u00eda de reconocimiento del habla y los instrumentos de teclado electr\u00f3nico.", "token2charspan": [[0, 9], [10, 12], [13, 19], [20, 24], [25, 27], [28, 42], [43, 49], [50, 52], [53, 63], [64, 65], [65, 68], [68, 69], [69, 70], [71, 73], [74, 82], [83, 86], [87, 92], [92, 93], [94, 96], [97, 107], [108, 110], [111, 125], [126, 129], [130, 135], [136, 137], [138, 141], [142, 154], [155, 157], [158, 165], [166, 177], [177, 178]]}
{"doc_key": "ai-test-33", "ner": [[13, 16, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Para", "las", "t\u00e9cnicas", "m\u00e1s", "recientes", "y", "de", "vanguardia", ",", "se", "puede", "utilizar", "el", "conjunto", "de", "herramientas", "Kaldi", "."], "sentence-detokenized": "Para las t\u00e9cnicas m\u00e1s recientes y de vanguardia, se puede utilizar el conjunto de herramientas Kaldi.", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 21], [22, 31], [32, 33], [34, 36], [37, 47], [47, 48], [49, 51], [52, 57], [58, 66], [67, 69], [70, 78], [79, 81], [82, 94], [95, 100], [100, 101]]}
{"doc_key": "ai-test-34", "ner": [[0, 1, "researcher"], [5, 7, "organisation"], [11, 12, "organisation"], [16, 17, "organisation"], [21, 22, "researcher"], [26, 29, "organisation"], [33, 35, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 5, 7, "role", "", false, false], [0, 1, 11, 12, "role", "", false, false], [0, 1, 16, 17, "role", "", false, false], [0, 1, 26, 29, "role", "", false, false], [0, 1, 33, 35, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Johnson-Laird", "es", "miembro", "de", "la", "American", "Philosophical", "Society", ",", "de", "la", "Royal", "Society", ",", "de", "la", "British", "Academy", ",", "de", "la", "William", "James", "Fellow", "de", "la", "Association", "for", "Psychological", "Science", "y", "de", "la", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Johnson-Laird es miembro de la American Philosophical Society, de la Royal Society, de la British Academy, de la William James Fellow de la Association for Psychological Science y de la Cognitive Science Society.", "token2charspan": [[0, 13], [14, 16], [17, 24], [25, 27], [28, 30], [31, 39], [40, 53], [54, 61], [61, 62], [63, 65], [66, 68], [69, 74], [75, 82], [82, 83], [84, 86], [87, 89], [90, 97], [98, 105], [105, 106], [107, 109], [110, 112], [113, 120], [121, 126], [127, 133], [134, 136], [137, 139], [140, 151], [152, 155], [156, 169], [170, 177], [178, 179], [180, 182], [183, 185], [186, 195], [196, 203], [204, 211], [211, 212]]}
{"doc_key": "ai-test-35", "ner": [[2, 9, "conference"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [23, 24, "algorithm"], [29, 34, "task"], [36, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 14, 2, 9, "physical", "", false, false], [13, 14, 2, 9, "temporal", "", false, false], [16, 17, 2, 9, "physical", "", false, false], [16, 17, 2, 9, "temporal", "", false, false], [19, 20, 2, 9, "physical", "", false, false], [19, 20, 2, 9, "temporal", "", false, false], [23, 24, 19, 20, "role", "extends", false, false], [29, 34, 19, 20, "role", "extends", false, false], [36, 36, 29, 34, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["En", "la", "Conferencia", "Internacional", "del", "IEEE", "sobre", "Procesamiento", "de", "Im\u00e1genes", "de", "2010", ",", "Rui", "Hu", ",", "Mark", "Banard", "y", "John", "Collomosse", "ampliaron", "el", "descriptor", "HOG", "para", "utilizarlo", "en", "la", "recuperaci\u00f3n", "de", "im\u00e1genes", "basada", "en", "bocetos", "(", "SBIR", ")", "."], "sentence-detokenized": "En la Conferencia Internacional del IEEE sobre Procesamiento de Im\u00e1genes de 2010, Rui Hu, Mark Banard y John Collomosse ampliaron el descriptor HOG para utilizarlo en la recuperaci\u00f3n de im\u00e1genes basada en bocetos (SBIR).", "token2charspan": [[0, 2], [3, 5], [6, 17], [18, 31], [32, 35], [36, 40], [41, 46], [47, 60], [61, 63], [64, 72], [73, 75], [76, 80], [80, 81], [82, 85], [86, 88], [88, 89], [90, 94], [95, 101], [102, 103], [104, 108], [109, 119], [120, 129], [130, 132], [133, 143], [144, 147], [148, 152], [153, 163], [164, 166], [167, 169], [170, 182], [183, 185], [186, 194], [195, 201], [202, 204], [205, 212], [213, 214], [214, 218], [218, 219], [219, 220]]}
{"doc_key": "ai-test-36", "ner": [[0, 0, "metrics"], [6, 6, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["BLEU", "utiliza", "una", "forma", "modificada", "de", "precisi\u00f3n", "para", "comparar", "una", "traducci\u00f3n", "candidata", "con", "m\u00faltiples", "traducciones", "de", "referencia", "."], "sentence-detokenized": "BLEU utiliza una forma modificada de precisi\u00f3n para comparar una traducci\u00f3n candidata con m\u00faltiples traducciones de referencia.", "token2charspan": [[0, 4], [5, 12], [13, 16], [17, 22], [23, 33], [34, 36], [37, 46], [47, 51], [52, 60], [61, 64], [65, 75], [76, 85], [86, 89], [90, 99], [100, 112], [113, 115], [116, 126], [126, 127]]}
{"doc_key": "ai-test-37", "ner": [[40, 41, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Para", "el", "caso", "de", "un", "espacio", "base", "general", "math", "(", "Y", ",", "\\", "mathcal", "{", "B", "}", ",", "\\", "nu", ")", "/", "math", "(", "es", "decir", ",", "un", "espacio", "base", "que", "no", "es", "contable", ")", ",", "se", "suele", "considerar", "la", "entrop\u00eda", "relativa", "."], "sentence-detokenized": "Para el caso de un espacio base general math (Y,\\ mathcal {B},\\ nu) / math (es decir, un espacio base que no es contable), se suele considerar la entrop\u00eda relativa.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 15], [16, 18], [19, 26], [27, 31], [32, 39], [40, 44], [45, 46], [46, 47], [47, 48], [48, 49], [50, 57], [58, 59], [59, 60], [60, 61], [61, 62], [62, 63], [64, 66], [66, 67], [68, 69], [70, 74], [75, 76], [76, 78], [79, 84], [84, 85], [86, 88], [89, 96], [97, 101], [102, 105], [106, 108], [109, 111], [112, 120], [120, 121], [121, 122], [123, 125], [126, 131], [132, 142], [143, 145], [146, 154], [155, 163], [163, 164]]}
{"doc_key": "ai-test-38", "ner": [[19, 20, "country"], [11, 14, "organisation"], [16, 18, "organisation"], [28, 30, "country"], [23, 24, "organisation"], [26, 26, "organisation"], [33, 35, "organisation"], [48, 48, "country"], [38, 43, "organisation"], [45, 45, "organisation"], [57, 58, "misc"], [55, 56, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[11, 14, 19, 20, "physical", "", false, false], [16, 18, 11, 14, "named", "", false, false], [23, 24, 28, 30, "physical", "", false, false], [26, 26, 23, 24, "named", "", false, false], [38, 43, 48, 48, "physical", "", false, false], [45, 45, 38, 43, "named", "", false, false], [57, 58, 55, 56, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["En", "octubre", "de", "2011", ",", "las", "asociaciones", "ya", "existentes", "con", "el", "Servicio", "de", "Parques", "Nacionales", "(", "NPS", ")", "de", "Estados", "Unidos", ",", "el", "Historic", "Scotland", "(", "HS", ")", "del", "Reino", "Unido", ",", "el", "World", "Monuments", "Fund", "y", "el", "Instituto", "Nacional", "de", "Antropolog\u00eda", "e", "Historia", "(", "INAH", ")", "de", "M\u00e9xico", "se", "hab\u00edan", "ampliado", "considerablemente", ",", ",", "sitio", "web", "de", "CyArk"], "sentence-detokenized": "En octubre de 2011, las asociaciones ya existentes con el Servicio de Parques Nacionales (NPS) de Estados Unidos, el Historic Scotland (HS) del Reino Unido, el World Monuments Fund y el Instituto Nacional de Antropolog\u00eda e Historia (INAH) de M\u00e9xico se hab\u00edan ampliado considerablemente,, sitio web de CyArk", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 18], [18, 19], [20, 23], [24, 36], [37, 39], [40, 50], [51, 54], [55, 57], [58, 66], [67, 69], [70, 77], [78, 88], [89, 90], [90, 93], [93, 94], [95, 97], [98, 105], [106, 112], [112, 113], [114, 116], [117, 125], [126, 134], [135, 136], [136, 138], [138, 139], [140, 143], [144, 149], [150, 155], [155, 156], [157, 159], [160, 165], [166, 175], [176, 180], [181, 182], [183, 185], [186, 195], [196, 204], [205, 207], [208, 220], [221, 222], [223, 231], [232, 233], [233, 237], [237, 238], [239, 241], [242, 248], [249, 251], [252, 258], [259, 267], [268, 285], [285, 286], [286, 287], [288, 293], [294, 297], [298, 300], [301, 306]]}
{"doc_key": "ai-test-39", "ner": [[0, 3, "algorithm"], [11, 13, "field"], [16, 16, "product"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 16, 16, "part-of", "", false, false], [0, 3, 18, 18, "part-of", "", false, false], [16, 16, 11, 13, "general-affiliation", "", false, false], [18, 18, 11, 13, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Las", "SVM", "de", "n\u00facleo", "est\u00e1n", "disponibles", "en", "muchos", "conjuntos", "de", "herramientas", "de", "aprendizaje", "autom\u00e1tico", ",", "como", "LIBSVM", ",", "MATLAB", "y", "otros", "."], "sentence-detokenized": "Las SVM de n\u00facleo est\u00e1n disponibles en muchos conjuntos de herramientas de aprendizaje autom\u00e1tico, como LIBSVM, MATLAB y otros.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 17], [18, 23], [24, 35], [36, 38], [39, 45], [46, 55], [56, 58], [59, 71], [72, 74], [75, 86], [87, 97], [97, 98], [99, 103], [104, 110], [110, 111], [112, 118], [119, 120], [121, 126], [126, 127]]}
{"doc_key": "ai-test-40", "ner": [[0, 4, "misc"], [16, 17, "location"], [19, 19, "location"], [20, 22, "country"], [27, 29, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 16, 17, "physical", "", false, false], [0, 4, 27, 29, "temporal", "", false, false], [16, 17, 19, 19, "physical", "", false, false], [19, 19, 20, 22, "physical", "", false, false], [27, 29, 16, 17, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["El", "concurso", "del", "Premio", "Loebner", "2009", "se", "celebr\u00f3", "el", "6", "de", "septiembre", "de", "2009", "en", "el", "Brighton", "Centre", ",", "Brighton", ",", "Reino", "Unido", ",", "junto", "con", "la", "conferencia", "Interspeech", "2009", "."], "sentence-detokenized": "El concurso del Premio Loebner 2009 se celebr\u00f3 el 6 de septiembre de 2009 en el Brighton Centre, Brighton, Reino Unido, junto con la conferencia Interspeech 2009.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 22], [23, 30], [31, 35], [36, 38], [39, 46], [47, 49], [50, 51], [52, 54], [55, 65], [66, 68], [69, 73], [74, 76], [77, 79], [80, 88], [89, 95], [95, 96], [97, 105], [105, 106], [107, 112], [113, 118], [118, 119], [120, 125], [126, 129], [130, 132], [133, 144], [145, 156], [157, 161], [161, 162]]}
{"doc_key": "ai-test-41", "ner": [[0, 3, "product"], [9, 9, "product"], [18, 18, "product"], [15, 19, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 19, 0, 3, "part-of", "", false, false], [15, 19, 9, 9, "part-of", "", false, false], [15, 19, 18, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["El", "robot", "humanoide", "QRIO", "fue", "dise\u00f1ado", "como", "sucesor", "de", "AIBO", ",", "y", "ejecuta", "el", "mismo", "sistema", "operativo", "base", "R-CODE", "Aperios", "."], "sentence-detokenized": "El robot humanoide QRIO fue dise\u00f1ado como sucesor de AIBO, y ejecuta el mismo sistema operativo base R-CODE Aperios.", "token2charspan": [[0, 2], [3, 8], [9, 18], [19, 23], [24, 27], [28, 36], [37, 41], [42, 49], [50, 52], [53, 57], [57, 58], [59, 60], [61, 68], [69, 71], [72, 77], [78, 85], [86, 95], [96, 100], [101, 107], [108, 115], [115, 116]]}
{"doc_key": "ai-test-42", "ner": [[0, 5, "misc"], [11, 16, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 16, 0, 5, "cause-effect", "", true, false], [19, 20, 0, 5, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Las", "formas", "de", "onda", "del", "habla", "se", "generan", "a", "partir", "de", "los", "propios", "HMM", "basados", "en", "el", "criterio", "de", "m\u00e1xima", "verosimilitud", "."], "sentence-detokenized": "Las formas de onda del habla se generan a partir de los propios HMM basados en el criterio de m\u00e1xima verosimilitud.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 18], [19, 22], [23, 28], [29, 31], [32, 39], [40, 41], [42, 48], [49, 51], [52, 55], [56, 63], [64, 67], [68, 75], [76, 78], [79, 81], [82, 90], [91, 93], [94, 100], [101, 114], [114, 115]]}
{"doc_key": "ai-test-43", "ner": [[0, 1, "product"], [7, 12, "task"], [11, 11, "task"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 7, 12, "type-of", "", false, false], [0, 1, 11, 11, "type-of", "", false, false], [0, 1, 15, 15, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Google", "Translate", "es", "un", "servicio", "gratuito", "de", "traducci\u00f3n", "autom\u00e1tica", "estad\u00edstica", "y", "neural", "multiling\u00fce", "desarrollado", "por", "Google", ",", "para", "traducir", "textos", "y", "sitios", "web", "de", "un", "idioma", "a", "otro", "."], "sentence-detokenized": "Google Translate es un servicio gratuito de traducci\u00f3n autom\u00e1tica estad\u00edstica y neural multiling\u00fce desarrollado por Google, para traducir textos y sitios web de un idioma a otro.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 22], [23, 31], [32, 40], [41, 43], [44, 54], [55, 65], [66, 77], [78, 79], [80, 86], [87, 98], [99, 111], [112, 115], [116, 122], [122, 123], [124, 128], [129, 137], [138, 144], [145, 146], [147, 153], [154, 157], [158, 160], [161, 163], [164, 170], [171, 172], [173, 177], [177, 178]]}
{"doc_key": "ai-test-44", "ner": [[7, 9, "field"], [12, 14, "field"], [17, 19, "field"], [22, 25, "field"], [30, 33, "task"], [36, 39, "task"], [42, 46, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[30, 33, 7, 9, "part-of", "", false, true], [30, 33, 12, 14, "part-of", "", false, true], [30, 33, 17, 19, "part-of", "", false, true], [36, 39, 7, 9, "part-of", "", false, true], [36, 39, 12, 14, "part-of", "", false, true], [36, 39, 17, 19, "part-of", "", false, true], [42, 46, 7, 9, "part-of", "", false, true], [42, 46, 12, 14, "part-of", "", false, true], [42, 46, 17, 19, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Los", "esqueletos", "se", "utilizan", "ampliamente", "en", "la", "visi\u00f3n", "por", "ordenador", ",", "el", "an\u00e1lisis", "de", "im\u00e1genes", ",", "el", "reconocimiento", "de", "patrones", "y", "el", "procesamiento", "digital", "de", "im\u00e1genes", "para", "fines", "como", "el", "reconocimiento", "\u00f3ptico", "de", "caracteres", ",", "el", "reconocimiento", "de", "huellas", "dactilares", ",", "la", "inspecci\u00f3n", "visual", "o", "la", "compresi\u00f3n", "."], "sentence-detokenized": "Los esqueletos se utilizan ampliamente en la visi\u00f3n por ordenador, el an\u00e1lisis de im\u00e1genes, el reconocimiento de patrones y el procesamiento digital de im\u00e1genes para fines como el reconocimiento \u00f3ptico de caracteres, el reconocimiento de huellas dactilares, la inspecci\u00f3n visual o la compresi\u00f3n.", "token2charspan": [[0, 3], [4, 14], [15, 17], [18, 26], [27, 38], [39, 41], [42, 44], [45, 51], [52, 55], [56, 65], [65, 66], [67, 69], [70, 78], [79, 81], [82, 90], [90, 91], [92, 94], [95, 109], [110, 112], [113, 121], [122, 123], [124, 126], [127, 140], [141, 148], [149, 151], [152, 160], [161, 165], [166, 171], [172, 176], [177, 179], [180, 194], [195, 201], [202, 204], [205, 215], [215, 216], [217, 219], [220, 234], [235, 237], [238, 245], [246, 256], [256, 257], [258, 260], [261, 271], [272, 278], [279, 280], [281, 283], [284, 294], [294, 295]]}
{"doc_key": "ai-test-45", "ner": [[1, 9, "conference"], [15, 19, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 9, 15, 19, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["El", "reto", "de", "reconocimiento", "visual", "a", "gran", "escala", "de", "ImageNet", "es", "una", "referencia", "en", "la", "clasificaci\u00f3n", "y", "detecci\u00f3n", "de", "objetos", ",", "con", "millones", "de", "im\u00e1genes", "y", "cientos", "de", "clases", "de", "objetos", "."], "sentence-detokenized": "El reto de reconocimiento visual a gran escala de ImageNet es una referencia en la clasificaci\u00f3n y detecci\u00f3n de objetos, con millones de im\u00e1genes y cientos de clases de objetos.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 25], [26, 32], [33, 34], [35, 39], [40, 46], [47, 49], [50, 58], [59, 61], [62, 65], [66, 76], [77, 79], [80, 82], [83, 96], [97, 98], [99, 108], [109, 111], [112, 119], [119, 120], [121, 124], [125, 133], [134, 136], [137, 145], [146, 147], [148, 155], [156, 158], [159, 165], [166, 168], [169, 176], [176, 177]]}
{"doc_key": "ai-test-46", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 11, "researcher"], [16, 19, "misc"], [21, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 16, 19, "part-of", "", false, false], [0, 0, 21, 24, "part-of", "", false, false], [4, 5, 16, 19, "part-of", "", false, false], [4, 5, 21, 24, "part-of", "", false, false], [7, 11, 16, 19, "part-of", "", false, false], [7, 11, 21, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Bengio", ",", "junto", "con", "Geoffrey", "Hinton", "y", "Yann", "LeCun", ",", "son", "conocidos", "por", "algunos", "como", "los", "Padres", "de", "la", "IA", "y", "Padrinos", "del", "Aprendizaje", "Profundo", "."], "sentence-detokenized": "Bengio, junto con Geoffrey Hinton y Yann LeCun, son conocidos por algunos como los Padres de la IA y Padrinos del Aprendizaje Profundo.", "token2charspan": [[0, 6], [6, 7], [8, 13], [14, 17], [18, 26], [27, 33], [34, 35], [36, 40], [41, 46], [46, 47], [48, 51], [52, 61], [62, 65], [66, 73], [74, 78], [79, 82], [83, 89], [90, 92], [93, 95], [96, 98], [99, 100], [101, 109], [110, 113], [114, 125], [126, 134], [134, 135]]}
{"doc_key": "ai-test-47", "ner": [[3, 4, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Es", "miembro", "vitalicio", "del", "IEEE", "."], "sentence-detokenized": "Es miembro vitalicio del IEEE.", "token2charspan": [[0, 2], [3, 10], [11, 20], [21, 24], [25, 29], [29, 30]]}
{"doc_key": "ai-test-48", "ner": [[0, 3, "organisation"], [18, 23, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 18, 23, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["La", "NSA", "de", "Bethesda", "es", "responsable", "del", "apoyo", "operativo", "de", "la", "base", "para", "su", "principal", "inquilino", ",", "el", "Centro", "M\u00e9dico", "Militar", "Nacional", "Walter", "Reed", "."], "sentence-detokenized": "La NSA de Bethesda es responsable del apoyo operativo de la base para su principal inquilino, el Centro M\u00e9dico Militar Nacional Walter Reed.", "token2charspan": [[0, 2], [3, 6], [7, 9], [10, 18], [19, 21], [22, 33], [34, 37], [38, 43], [44, 53], [54, 56], [57, 59], [60, 64], [65, 69], [70, 72], [73, 82], [83, 92], [92, 93], [94, 96], [97, 103], [104, 110], [111, 118], [119, 127], [128, 134], [135, 139], [139, 140]]}
{"doc_key": "ai-test-49", "ner": [[8, 9, "field"], [12, 14, "field"], [17, 19, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Los", "tres", "principales", "paradigmas", "de", "aprendizaje", "son", "el", "aprendizaje", "supervisado", ",", "el", "aprendizaje", "no", "supervisado", "y", "el", "aprendizaje", "por", "refuerzo", "."], "sentence-detokenized": "Los tres principales paradigmas de aprendizaje son el aprendizaje supervisado, el aprendizaje no supervisado y el aprendizaje por refuerzo.", "token2charspan": [[0, 3], [4, 8], [9, 20], [21, 31], [32, 34], [35, 46], [47, 50], [51, 53], [54, 65], [66, 77], [77, 78], [79, 81], [82, 93], [94, 96], [97, 108], [109, 110], [111, 113], [114, 125], [126, 129], [130, 138], [138, 139]]}
{"doc_key": "ai-test-50", "ner": [[4, 4, "task"], [7, 10, "task"], [15, 23, "task"], [26, 29, "task"], [32, 35, "task"], [38, 40, "task"], [43, 44, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Algunos", "ejemplos", "son", "el", "control", ",", "la", "planificaci\u00f3n", "y", "la", "programaci\u00f3n", ",", "la", "capacidad", "de", "responder", "a", "preguntas", "de", "diagn\u00f3stico", "y", "de", "los", "consumidores", ",", "el", "reconocimiento", "de", "la", "escritura", ",", "la", "comprensi\u00f3n", "del", "lenguaje", "natural", ",", "el", "reconocimiento", "del", "habla", "y", "el", "reconocimiento", "facial", "."], "sentence-detokenized": "Algunos ejemplos son el control, la planificaci\u00f3n y la programaci\u00f3n, la capacidad de responder a preguntas de diagn\u00f3stico y de los consumidores, el reconocimiento de la escritura, la comprensi\u00f3n del lenguaje natural, el reconocimiento del habla y el reconocimiento facial.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 23], [24, 31], [31, 32], [33, 35], [36, 49], [50, 51], [52, 54], [55, 67], [67, 68], [69, 71], [72, 81], [82, 84], [85, 94], [95, 96], [97, 106], [107, 109], [110, 121], [122, 123], [124, 126], [127, 130], [131, 143], [143, 144], [145, 147], [148, 162], [163, 165], [166, 168], [169, 178], [178, 179], [180, 182], [183, 194], [195, 198], [199, 207], [208, 215], [215, 216], [217, 219], [220, 234], [235, 238], [239, 244], [245, 246], [247, 249], [250, 264], [265, 271], [271, 272]]}
{"doc_key": "ai-test-51", "ner": [[7, 14, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["En", "1991", "fue", "elegido", "miembro", "de", "la", "Asociaci\u00f3n", "para", "el", "Avance", "de", "la", "Inteligencia", "Artificial", "(", "1990", ",", "miembro", "fundador", ")", "."], "sentence-detokenized": "En 1991 fue elegido miembro de la Asociaci\u00f3n para el Avance de la Inteligencia Artificial (1990, miembro fundador).", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 19], [20, 27], [28, 30], [31, 33], [34, 44], [45, 49], [50, 52], [53, 59], [60, 62], [63, 65], [66, 78], [79, 89], [90, 91], [91, 95], [95, 96], [97, 104], [105, 113], [113, 114], [114, 115]]}
{"doc_key": "ai-test-52", "ner": [[11, 13, "misc"], [16, 19, "algorithm"], [31, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sin", "embargo", ",", "formulando", "el", "problema", "como", "la", "soluci\u00f3n", "de", "una", "matriz", "de", "Toeplitz", "y", "utilizando", "la", "recursividad", "de", "Levinson", ",", "podemos", "estimar", "con", "relativa", "rapidez", "un", "filtro", "con", "el", "menor", "error", "medio", "cuadr\u00e1tico", "posible", "."], "sentence-detokenized": "Sin embargo, formulando el problema como la soluci\u00f3n de una matriz de Toeplitz y utilizando la recursividad de Levinson, podemos estimar con relativa rapidez un filtro con el menor error medio cuadr\u00e1tico posible.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 23], [24, 26], [27, 35], [36, 40], [41, 43], [44, 52], [53, 55], [56, 59], [60, 66], [67, 69], [70, 78], [79, 80], [81, 91], [92, 94], [95, 107], [108, 110], [111, 119], [119, 120], [121, 128], [129, 136], [137, 140], [141, 149], [150, 157], [158, 160], [161, 167], [168, 171], [172, 174], [175, 180], [181, 186], [187, 192], [193, 203], [204, 211], [211, 212]]}
{"doc_key": "ai-test-53", "ner": [[7, 12, "conference"], [15, 21, "location"], [23, 23, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 12, 15, 21, "physical", "", false, false], [15, 21, 23, 23, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["En", "julio", "de", "2011", "se", "celebrar\u00e1", "la", "15\u00aa", "edici\u00f3n", "de", "Campus", "Party", "Espa\u00f1a", "en", "la", "Ciudad", "de", "las", "Artes", "y", "las", "Ciencias", "de", "Valencia", "."], "sentence-detokenized": "En julio de 2011 se celebrar\u00e1 la 15\u00aa edici\u00f3n de Campus Party Espa\u00f1a en la Ciudad de las Artes y las Ciencias de Valencia.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 16], [17, 19], [20, 29], [30, 32], [33, 36], [37, 44], [45, 47], [48, 54], [55, 60], [61, 67], [68, 70], [71, 73], [74, 80], [81, 83], [84, 87], [88, 93], [94, 95], [96, 99], [100, 108], [109, 111], [112, 120], [120, 121]]}
{"doc_key": "ai-test-54", "ner": [[13, 14, "product"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "menudo", ",", "esto", "s\u00f3lo", "es", "posible", "al", "final", "de", "juegos", "complicados", "como", "el", "ajedrez", "o", "el", "go", ",", "ya", "que", "no", "es", "computacionalmente", "factible", "mirar", "hacia", "adelante", "hasta", "la", "finalizaci\u00f3n", "del", "juego", ",", "excepto", "hacia", "el", "final", ",", "y", "en", "su", "lugar", ",", "las", "posiciones", "se", "dan", "valores", "finitos", "como", "estimaciones", "del", "grado", "de", "creencia", "de", "que", "conducir\u00e1n", "a", "una", "victoria", "para", "uno", "u", "otro", "jugador", "."], "sentence-detokenized": "A menudo, esto s\u00f3lo es posible al final de juegos complicados como el ajedrez o el go, ya que no es computacionalmente factible mirar hacia adelante hasta la finalizaci\u00f3n del juego, excepto hacia el final, y en su lugar, las posiciones se dan valores finitos como estimaciones del grado de creencia de que conducir\u00e1n a una victoria para uno u otro jugador.", "token2charspan": [[0, 1], [2, 8], [8, 9], [10, 14], [15, 19], [20, 22], [23, 30], [31, 33], [34, 39], [40, 42], [43, 49], [50, 61], [62, 66], [67, 69], [70, 77], [78, 79], [80, 82], [83, 85], [85, 86], [87, 89], [90, 93], [94, 96], [97, 99], [100, 118], [119, 127], [128, 133], [134, 139], [140, 148], [149, 154], [155, 157], [158, 170], [171, 174], [175, 180], [180, 181], [182, 189], [190, 195], [196, 198], [199, 204], [204, 205], [206, 207], [208, 210], [211, 213], [214, 219], [219, 220], [221, 224], [225, 235], [236, 238], [239, 242], [243, 250], [251, 258], [259, 263], [264, 276], [277, 280], [281, 286], [287, 289], [290, 298], [299, 301], [302, 305], [306, 316], [317, 318], [319, 322], [323, 331], [332, 336], [337, 340], [341, 342], [343, 347], [348, 355], [355, 356]]}
{"doc_key": "ai-test-55", "ner": [[4, 6, "algorithm"], [24, 26, "algorithm"], [30, 33, "algorithm"], [36, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 24, 26, "compare", "", false, false], [4, 6, 30, 33, "compare", "", false, false], [4, 6, 36, 38, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "diferencia", "entre", "el", "modelo", "logit", "multinomial", "y", "otros", "muchos", "m\u00e9todos", ",", "modelos", ",", "algoritmos", ",", "etc.", "con", "la", "misma", "configuraci\u00f3n", "b\u00e1sica", "(", "el", "algoritmo", "del", "perceptr\u00f3n", ",", "las", "m\u00e1quinas", "de", "vectores", "de", "apoyo", ",", "el", "an\u00e1lisis", "discriminante", "lineal", ",", "etc", "."], "sentence-detokenized": "La diferencia entre el modelo logit multinomial y otros muchos m\u00e9todos, modelos, algoritmos, etc. con la misma configuraci\u00f3n b\u00e1sica (el algoritmo del perceptr\u00f3n, las m\u00e1quinas de vectores de apoyo, el an\u00e1lisis discriminante lineal, etc.", "token2charspan": [[0, 2], [3, 13], [14, 19], [20, 22], [23, 29], [30, 35], [36, 47], [48, 49], [50, 55], [56, 62], [63, 70], [70, 71], [72, 79], [79, 80], [81, 91], [91, 92], [93, 97], [98, 101], [102, 104], [105, 110], [111, 124], [125, 131], [132, 133], [133, 135], [136, 145], [146, 149], [150, 160], [160, 161], [162, 165], [166, 174], [175, 177], [178, 186], [187, 189], [190, 195], [195, 196], [197, 199], [200, 208], [209, 222], [223, 229], [229, 230], [231, 234], [234, 235]]}
{"doc_key": "ai-test-56", "ner": [[0, 3, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Asociaci\u00f3n", "de", "Ling\u00fc\u00edstica", "Computacional", ",", "publicado", "por"], "sentence-detokenized": "Asociaci\u00f3n de Ling\u00fc\u00edstica Computacional, publicado por", "token2charspan": [[0, 10], [11, 13], [14, 25], [26, 39], [39, 40], [41, 50], [51, 54]]}
{"doc_key": "ai-test-57", "ner": [[2, 6, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["En", "el", "sistema", "inform\u00e1tico", "de", "reconocimiento", "facial", ",", "cada", "rostro", "est\u00e1", "representado", "por", "un", "gran", "n\u00famero", "de", "valores", "de", "p\u00edxeles", "."], "sentence-detokenized": "En el sistema inform\u00e1tico de reconocimiento facial, cada rostro est\u00e1 representado por un gran n\u00famero de valores de p\u00edxeles.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 25], [26, 28], [29, 43], [44, 50], [50, 51], [52, 56], [57, 63], [64, 68], [69, 81], [82, 85], [86, 88], [89, 93], [94, 100], [101, 103], [104, 111], [112, 114], [115, 122], [122, 123]]}
{"doc_key": "ai-test-58", "ner": [[6, 7, "person"], [15, 17, "organisation"], [24, 24, "country"], [30, 30, "person"], [44, 46, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 7, 15, 17, "role", "", false, false], [6, 7, 24, 24, "physical", "", false, false], [30, 30, 44, 46, "origin", "", false, false], [30, 30, 44, 46, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["En", "2002", ",", "su", "hijo", ",", "Daniel", "Pearl", ",", "un", "periodista", "que", "trabajaba", "para", "el", "Wall", "Street", "Journal", ",", "fue", "secuestrado", "y", "asesinado", "en", "Pakist\u00e1n", ",", "lo", "que", "llev\u00f3", "a", "Judea", "y", "a", "los", "dem\u00e1s", "miembros", "de", "la", "familia", "y", "amigos", "a", "crear", "la", "Fundaci\u00f3n", "Daniel", "Pearl", "."], "sentence-detokenized": "En 2002, su hijo, Daniel Pearl, un periodista que trabajaba para el Wall Street Journal, fue secuestrado y asesinado en Pakist\u00e1n, lo que llev\u00f3 a Judea y a los dem\u00e1s miembros de la familia y amigos a crear la Fundaci\u00f3n Daniel Pearl.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 16], [16, 17], [18, 24], [25, 30], [30, 31], [32, 34], [35, 45], [46, 49], [50, 59], [60, 64], [65, 67], [68, 72], [73, 79], [80, 87], [87, 88], [89, 92], [93, 104], [105, 106], [107, 116], [117, 119], [120, 128], [128, 129], [130, 132], [133, 136], [137, 142], [143, 144], [145, 150], [151, 152], [153, 154], [155, 158], [159, 164], [165, 173], [174, 176], [177, 179], [180, 187], [188, 189], [190, 196], [197, 198], [199, 204], [205, 207], [208, 217], [218, 224], [225, 230], [230, 231]]}
{"doc_key": "ai-test-59", "ner": [[5, 7, "organisation"], [20, 21, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 20, 21, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "finales", "de", "2006", ",", "Red", "Envelope", "Entertainment", "tambi\u00e9n", "se", "ampli\u00f3", "a", "la", "producci\u00f3n", "de", "contenidos", "originales", "con", "cineastas", "como", "John", "Waters", "."], "sentence-detokenized": "A finales de 2006, Red Envelope Entertainment tambi\u00e9n se ampli\u00f3 a la producci\u00f3n de contenidos originales con cineastas como John Waters.", "token2charspan": [[0, 1], [2, 9], [10, 12], [13, 17], [17, 18], [19, 22], [23, 31], [32, 45], [46, 53], [54, 56], [57, 63], [64, 65], [66, 68], [69, 79], [80, 82], [83, 93], [94, 104], [105, 108], [109, 118], [119, 123], [124, 128], [129, 135], [135, 136]]}
{"doc_key": "ai-test-60", "ner": [[6, 10, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["El", "edificio", "forma", "parte", "ahora", "del", "Centro", "M\u00e9dico", "Beth", "Israel", "Deaconess", "."], "sentence-detokenized": "El edificio forma parte ahora del Centro M\u00e9dico Beth Israel Deaconess.", "token2charspan": [[0, 2], [3, 11], [12, 17], [18, 23], [24, 29], [30, 33], [34, 40], [41, 47], [48, 52], [53, 59], [60, 69], [69, 70]]}
{"doc_key": "ai-test-61", "ner": [[19, 20, "field"], [22, 24, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Un", "tema", "com\u00fan", "de", "este", "trabajo", "es", "la", "adopci\u00f3n", "de", "una", "perspectiva", "te\u00f3rica", "de", "los", "signos", "en", "cuestiones", "de", "inteligencia", "artificial", "y", "representaci\u00f3n", "del", "conocimiento", "."], "sentence-detokenized": "Un tema com\u00fan de este trabajo es la adopci\u00f3n de una perspectiva te\u00f3rica de los signos en cuestiones de inteligencia artificial y representaci\u00f3n del conocimiento.", "token2charspan": [[0, 2], [3, 7], [8, 13], [14, 16], [17, 21], [22, 29], [30, 32], [33, 35], [36, 44], [45, 47], [48, 51], [52, 63], [64, 71], [72, 74], [75, 78], [79, 85], [86, 88], [89, 99], [100, 102], [103, 115], [116, 126], [127, 128], [129, 143], [144, 147], [148, 160], [160, 161]]}
{"doc_key": "ai-test-62", "ner": [[5, 7, "task"], [9, 9, "task"], [21, 22, "task"], [45, 47, "task"], [50, 52, "task"], [58, 60, "task"], [62, 62, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 7, 21, 22, "type-of", "", false, false], [5, 7, 58, 60, "compare", "", false, false], [5, 7, 58, 60, "opposite", "", false, false], [9, 9, 5, 7, "named", "", false, false], [45, 47, 58, 60, "part-of", "", false, false], [50, 52, 58, 60, "part-of", "", false, false], [58, 60, 21, 22, "type-of", "", false, false], [62, 62, 58, 60, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Por", "ejemplo", ",", "el", "t\u00e9rmino", "traducci\u00f3n", "autom\u00e1tica", "neural", "(", "NMT", ")", "hace", "hincapi\u00e9", "en", "el", "hecho", "de", "que", "los", "enfoques", "de", "traducci\u00f3n", "autom\u00e1tica", "basados", "en", "el", "aprendizaje", "profundo", "aprenden", "directamente", "las", "transformaciones", "de", "secuencia", "a", "secuencia", ",", "obviando", "la", "necesidad", "de", "pasos", "intermedios", "como", "la", "alineaci\u00f3n", "de", "palabras", "y", "el", "modelado", "del", "lenguaje", "que", "se", "utilizaba", "en", "la", "traducci\u00f3n", "autom\u00e1tica", "estad\u00edstica", "(", "SMT", ")", "."], "sentence-detokenized": "Por ejemplo, el t\u00e9rmino traducci\u00f3n autom\u00e1tica neural (NMT) hace hincapi\u00e9 en el hecho de que los enfoques de traducci\u00f3n autom\u00e1tica basados en el aprendizaje profundo aprenden directamente las transformaciones de secuencia a secuencia, obviando la necesidad de pasos intermedios como la alineaci\u00f3n de palabras y el modelado del lenguaje que se utilizaba en la traducci\u00f3n autom\u00e1tica estad\u00edstica (SMT).", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 23], [24, 34], [35, 45], [46, 52], [53, 54], [54, 57], [57, 58], [59, 63], [64, 72], [73, 75], [76, 78], [79, 84], [85, 87], [88, 91], [92, 95], [96, 104], [105, 107], [108, 118], [119, 129], [130, 137], [138, 140], [141, 143], [144, 155], [156, 164], [165, 173], [174, 186], [187, 190], [191, 207], [208, 210], [211, 220], [221, 222], [223, 232], [232, 233], [234, 242], [243, 245], [246, 255], [256, 258], [259, 264], [265, 276], [277, 281], [282, 284], [285, 295], [296, 298], [299, 307], [308, 309], [310, 312], [313, 321], [322, 325], [326, 334], [335, 338], [339, 341], [342, 351], [352, 354], [355, 357], [358, 368], [369, 379], [380, 391], [392, 393], [393, 396], [396, 397], [397, 398]]}
{"doc_key": "ai-test-63", "ner": [[10, 11, "field"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 11, 15, 15, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["La", "mayor", "parte", "de", "la", "investigaci\u00f3n", "en", "el", "campo", "de", "la", "WSD", "se", "realiza", "utilizando", "WordNet", "como", "inventario", "de", "sentidos", "de", "referencia", "para", "."], "sentence-detokenized": "La mayor parte de la investigaci\u00f3n en el campo de la WSD se realiza utilizando WordNet como inventario de sentidos de referencia para.", "token2charspan": [[0, 2], [3, 8], [9, 14], [15, 17], [18, 20], [21, 34], [35, 37], [38, 40], [41, 46], [47, 49], [50, 52], [53, 56], [57, 59], [60, 67], [68, 78], [79, 86], [87, 91], [92, 102], [103, 105], [106, 114], [115, 117], [118, 128], [129, 133], [133, 134]]}
{"doc_key": "ai-test-64", "ner": [[4, 5, "misc"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 14, 4, 5, "general-affiliation", "", false, true], [16, 17, 4, 5, "general-affiliation", "", false, true]], "relations_mapping_to_source": [0, 1], "sentence": ["Entre", "los", "antiguos", "estudiantes", "de", "doctorado", "e", "investigadores", "postdoctorales", "de", "su", "grupo", "destacan", "Richard", "Zemel", "y", "Zoubin", "Ghahramani", "."], "sentence-detokenized": "Entre los antiguos estudiantes de doctorado e investigadores postdoctorales de su grupo destacan Richard Zemel y Zoubin Ghahramani.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 30], [31, 33], [34, 43], [44, 45], [46, 60], [61, 75], [76, 78], [79, 81], [82, 87], [88, 96], [97, 104], [105, 110], [111, 112], [113, 119], [120, 130], [130, 131]]}
{"doc_key": "ai-test-65", "ner": [[8, 10, "metrics"], [17, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 10, 17, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cada", "resultado", "de", "predicci\u00f3n", "o", "instancia", "de", "una", "matriz", "de", "confusi\u00f3n", "representa", "un", "punto", "en", "el", "espacio", "ROC", "."], "sentence-detokenized": "Cada resultado de predicci\u00f3n o instancia de una matriz de confusi\u00f3n representa un punto en el espacio ROC.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 28], [29, 30], [31, 40], [41, 43], [44, 47], [48, 54], [55, 57], [58, 67], [68, 78], [79, 81], [82, 87], [88, 90], [91, 93], [94, 101], [102, 105], [105, 106]]}
{"doc_key": "ai-test-66", "ner": [[2, 2, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [14, 17, "product"], [21, 23, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 21, 23, "physical", "", false, false], [6, 7, 21, 23, "physical", "", false, false], [9, 10, 21, 23, "physical", "", false, false], [14, 17, 2, 2, "artifact", "", false, false], [14, 17, 6, 7, "artifact", "", false, false], [14, 17, 9, 10, "artifact", "", false, false], [14, 17, 21, 23, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["En", "1997", "Thrun", "y", "sus", "colegas", "Wolfram", "Burgard", "y", "Dieter", "Fox", "desarrollaron", "el", "primer", "gu\u00eda", "tur\u00edstico", "rob\u00f3tico", "del", "mundo", "en", "el", "Deutsches", "Museum", "Bonn", "(", "1997", ")", "."], "sentence-detokenized": "En 1997 Thrun y sus colegas Wolfram Burgard y Dieter Fox desarrollaron el primer gu\u00eda tur\u00edstico rob\u00f3tico del mundo en el Deutsches Museum Bonn (1997).", "token2charspan": [[0, 2], [3, 7], [8, 13], [14, 15], [16, 19], [20, 27], [28, 35], [36, 43], [44, 45], [46, 52], [53, 56], [57, 70], [71, 73], [74, 80], [81, 85], [86, 95], [96, 104], [105, 108], [109, 114], [115, 117], [118, 120], [121, 130], [131, 137], [138, 142], [143, 144], [144, 148], [148, 149], [149, 150]]}
{"doc_key": "ai-test-67", "ner": [[0, 0, "product"], [8, 9, "misc"], [23, 27, "field"], [32, 33, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 0, 0, "part-of", "", false, false], [23, 27, 0, 0, "usage", "", false, false], [32, 33, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["WordNet", "es", "una", "base", "de", "datos", "l\u00e9xica", "de", "relaciones", "sem\u00e1nticas", "entre", "palabras", "en", "m\u00e1s", "de", "200", "idiomas", ".", "Su", "uso", "principal", "es", "el", "procesamiento", "autom\u00e1tico", "del", "lenguaje", "natural", "y", "las", "aplicaciones", "de", "inteligencia", "artificial", "."], "sentence-detokenized": "WordNet es una base de datos l\u00e9xica de relaciones sem\u00e1nticas entre palabras en m\u00e1s de 200 idiomas. Su uso principal es el procesamiento autom\u00e1tico del lenguaje natural y las aplicaciones de inteligencia artificial.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 19], [20, 22], [23, 28], [29, 35], [36, 38], [39, 49], [50, 60], [61, 66], [67, 75], [76, 78], [79, 82], [83, 85], [86, 89], [90, 97], [97, 98], [99, 101], [102, 105], [106, 115], [116, 118], [119, 121], [122, 135], [136, 146], [147, 150], [151, 159], [160, 167], [168, 169], [170, 173], [174, 186], [187, 189], [190, 202], [203, 213], [213, 214]]}
{"doc_key": "ai-test-68", "ner": [[5, 8, "field"], [11, 15, "conference"], [18, 26, "conference"], [28, 29, "conference"], [32, 32, "conference"], [41, 43, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 15, 5, 8, "topic", "", false, false], [11, 15, 41, 43, "topic", "", false, false], [18, 26, 5, 8, "topic", "", false, false], [18, 26, 41, 43, "topic", "", false, false], [28, 29, 5, 8, "topic", "", false, false], [28, 29, 41, 43, "topic", "", false, false], [32, 32, 5, 8, "topic", "", false, false], [32, 32, 41, 43, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Los", "congresos", "del", "\u00e1mbito", "del", "procesamiento", "del", "lenguaje", "natural", ",", "como", "la", "Association", "for", "Computational", "Linguistics", ",", "la", "North", "American", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "la", "EMNLP", "y", "la", "HLT", ",", "est\u00e1n", "empezando", "a", "incluir", "art\u00edculos", "sobre", "el", "procesamiento", "del", "habla", "."], "sentence-detokenized": "Los congresos del \u00e1mbito del procesamiento del lenguaje natural, como la Association for Computational Linguistics, la North American Chapter of the Association for Computational Linguistics, la EMNLP y la HLT, est\u00e1n empezando a incluir art\u00edculos sobre el procesamiento del habla.", "token2charspan": [[0, 3], [4, 13], [14, 17], [18, 24], [25, 28], [29, 42], [43, 46], [47, 55], [56, 63], [63, 64], [65, 69], [70, 72], [73, 84], [85, 88], [89, 102], [103, 114], [114, 115], [116, 118], [119, 124], [125, 133], [134, 141], [142, 144], [145, 148], [149, 160], [161, 164], [165, 178], [179, 190], [190, 191], [192, 194], [195, 200], [201, 202], [203, 205], [206, 209], [209, 210], [211, 216], [217, 226], [227, 228], [229, 236], [237, 246], [247, 252], [253, 255], [256, 269], [270, 273], [274, 279], [279, 280]]}
{"doc_key": "ai-test-69", "ner": [[4, 4, "programlang"], [24, 27, "misc"], [43, 45, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Un", "conjunto", "de", "programas", "Java", "utiliza", "el", "l\u00e9xico", "para", "trabajar", "a", "trav\u00e9s", "de", "las", "variaciones", "de", "los", "textos", "biom\u00e9dicos", "relacionando", "las", "palabras", "por", "sus", "partes", "de", "la", "oraci\u00f3n", ",", "lo", "que", "puede", "ser", "\u00fatil", "en", "las", "b\u00fasquedas", "en", "la", "web", "o", "en", "una", "historia", "cl\u00ednica", "electr\u00f3nica", "."], "sentence-detokenized": "Un conjunto de programas Java utiliza el l\u00e9xico para trabajar a trav\u00e9s de las variaciones de los textos biom\u00e9dicos relacionando las palabras por sus partes de la oraci\u00f3n, lo que puede ser \u00fatil en las b\u00fasquedas en la web o en una historia cl\u00ednica electr\u00f3nica.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 24], [25, 29], [30, 37], [38, 40], [41, 47], [48, 52], [53, 61], [62, 63], [64, 70], [71, 73], [74, 77], [78, 89], [90, 92], [93, 96], [97, 103], [104, 114], [115, 127], [128, 131], [132, 140], [141, 144], [145, 148], [149, 155], [156, 158], [159, 161], [162, 169], [169, 170], [171, 173], [174, 177], [178, 183], [184, 187], [188, 192], [193, 195], [196, 199], [200, 209], [210, 212], [213, 215], [216, 219], [220, 221], [222, 224], [225, 228], [229, 237], [238, 245], [246, 257], [257, 258]]}
{"doc_key": "ai-test-70", "ner": [[7, 7, "algorithm"], [9, 9, "algorithm"], [11, 11, "algorithm"], [13, 13, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Hay", "muchos", "algoritmos", "m\u00e1s", "recientes", ",", "como", "LPBoost", ",", "TotalBoost", ",", "BrownBoost", ",", "xgboost", ",", "MadaBoost", ",", "y", "otros", "."], "sentence-detokenized": "Hay muchos algoritmos m\u00e1s recientes, como LPBoost, TotalBoost, BrownBoost, xgboost, MadaBoost, y otros.", "token2charspan": [[0, 3], [4, 10], [11, 21], [22, 25], [26, 35], [35, 36], [37, 41], [42, 49], [49, 50], [51, 61], [61, 62], [63, 73], [73, 74], [75, 82], [82, 83], [84, 93], [93, 94], [95, 96], [97, 102], [102, 103]]}
{"doc_key": "ai-test-71", "ner": [[7, 7, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Este", "es", "un", "ejemplo", "de", "implementaci\u00f3n", "en", "Python", ":"], "sentence-detokenized": "Este es un ejemplo de implementaci\u00f3n en Python:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 36], [37, 39], [40, 46], [46, 47]]}
{"doc_key": "ai-test-72", "ner": [[2, 2, "organisation"], [3, 3, "product"], [8, 11, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 2, 2, "artifact", "made_by_company", false, false], [8, 11, 3, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "videoconsola", "Mattel", "Intellivision", "ofrec\u00eda", "el", "m\u00f3dulo", "de", "s\u00edntesis", "de", "voz", "Intellivoice", "en", "1982", "."], "sentence-detokenized": "La videoconsola Mattel Intellivision ofrec\u00eda el m\u00f3dulo de s\u00edntesis de voz Intellivoice en 1982.", "token2charspan": [[0, 2], [3, 15], [16, 22], [23, 36], [37, 44], [45, 47], [48, 54], [55, 57], [58, 66], [67, 69], [70, 73], [74, 86], [87, 89], [90, 94], [94, 95]]}
{"doc_key": "ai-test-73", "ner": [[5, 6, "task"], [11, 19, "task"], [23, 24, "field"], [27, 29, "task"], [33, 39, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 19, 5, 6, "part-of", "", false, false], [23, 24, 5, 6, "part-of", "", false, false], [27, 29, 5, 6, "part-of", "", false, false], [33, 39, 27, 29, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Tambi\u00e9n", "ha", "trabajado", "en", "la", "traducci\u00f3n", "autom\u00e1tica", ",", "tanto", "en", "la", "traducci\u00f3n", "autom\u00e1tica", "de", "alta", "precisi\u00f3n", "basada", "en", "el", "conocimiento", "como", "en", "el", "aprendizaje", "autom\u00e1tico", "para", "la", "traducci\u00f3n", "autom\u00e1tica", "estad\u00edstica", "(", "como", "la", "traducci\u00f3n", "autom\u00e1tica", "basada", "en", "el", "ejemplo", "generalizado", ")", "."], "sentence-detokenized": "Tambi\u00e9n ha trabajado en la traducci\u00f3n autom\u00e1tica, tanto en la traducci\u00f3n autom\u00e1tica de alta precisi\u00f3n basada en el conocimiento como en el aprendizaje autom\u00e1tico para la traducci\u00f3n autom\u00e1tica estad\u00edstica (como la traducci\u00f3n autom\u00e1tica basada en el ejemplo generalizado).", "token2charspan": [[0, 7], [8, 10], [11, 20], [21, 23], [24, 26], [27, 37], [38, 48], [48, 49], [50, 55], [56, 58], [59, 61], [62, 72], [73, 83], [84, 86], [87, 91], [92, 101], [102, 108], [109, 111], [112, 114], [115, 127], [128, 132], [133, 135], [136, 138], [139, 150], [151, 161], [162, 166], [167, 169], [170, 180], [181, 191], [192, 203], [204, 205], [205, 209], [210, 212], [213, 223], [224, 234], [235, 241], [242, 244], [245, 247], [248, 255], [256, 268], [268, 269], [269, 270]]}
{"doc_key": "ai-test-74", "ner": [[0, 1, "misc"], [5, 5, "misc"], [23, 24, "algorithm"], [26, 27, "field"], [29, 31, "field"], [33, 33, "field"], [35, 37, "field"], [39, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 23, 24, "general-affiliation", "", false, false], [0, 1, 26, 27, "general-affiliation", "", false, false], [0, 1, 29, 31, "general-affiliation", "", false, false], [0, 1, 33, 33, "general-affiliation", "", false, false], [0, 1, 35, 37, "general-affiliation", "", false, false], [0, 1, 39, 39, "general-affiliation", "", false, false], [5, 5, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Wolfram", "Mathematica", "(", "usualmente", "llamado", "Mathematica", ")", "es", "un", "moderno", "sistema", "de", "computaci\u00f3n", "t\u00e9cnica", "que", "abarca", "la", "mayor\u00eda", "de", "las", "\u00e1reas", "t\u00e9cnicas", "-incluyendo", "redes", "neuronales", ",", "aprendizaje", "autom\u00e1tico", ",", "procesamiento", "de", "im\u00e1genes", ",", "geometr\u00eda", ",", "ciencia", "de", "datos", ",", "visualizaciones", "y", "otras", "."], "sentence-detokenized": "Wolfram Mathematica (usualmente llamado Mathematica) es un moderno sistema de computaci\u00f3n t\u00e9cnica que abarca la mayor\u00eda de las \u00e1reas t\u00e9cnicas -incluyendo redes neuronales, aprendizaje autom\u00e1tico, procesamiento de im\u00e1genes, geometr\u00eda, ciencia de datos, visualizaciones y otras.", "token2charspan": [[0, 7], [8, 19], [20, 21], [21, 31], [32, 39], [40, 51], [51, 52], [53, 55], [56, 58], [59, 66], [67, 74], [75, 77], [78, 89], [90, 97], [98, 101], [102, 108], [109, 111], [112, 119], [120, 122], [123, 126], [127, 132], [133, 141], [142, 153], [154, 159], [160, 170], [170, 171], [172, 183], [184, 194], [194, 195], [196, 209], [210, 212], [213, 221], [221, 222], [223, 232], [232, 233], [234, 241], [242, 244], [245, 250], [250, 251], [252, 267], [268, 269], [270, 275], [275, 276]]}
{"doc_key": "ai-test-75", "ner": [[2, 7, "product"], [11, 12, "researcher"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 18, 2, 7, "type-of", "", false, false], [18, 18, 11, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["El", "primer", "robot", "programable", "y", "de", "funcionamiento", "digital", "fue", "inventado", "por", "George", "Devol", "en", "1954", "y", "acab\u00f3", "llam\u00e1ndose", "Unimate", "."], "sentence-detokenized": "El primer robot programable y de funcionamiento digital fue inventado por George Devol en 1954 y acab\u00f3 llam\u00e1ndose Unimate.", "token2charspan": [[0, 2], [3, 9], [10, 15], [16, 27], [28, 29], [30, 32], [33, 47], [48, 55], [56, 59], [60, 69], [70, 73], [74, 80], [81, 86], [87, 89], [90, 94], [95, 96], [97, 102], [103, 113], [114, 121], [121, 122]]}
{"doc_key": "ai-test-76", "ner": [[3, 4, "algorithm"], [6, 7, "algorithm"], [22, 24, "task"], [27, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 6, 7, "compare", "", false, false], [6, 7, 22, 24, "general-affiliation", "", false, false], [6, 7, 27, 29, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Al", "igual", "que", "las", "DBN", ",", "las", "DBM", "pueden", "aprender", "representaciones", "internas", "complejas", "y", "abstractas", "de", "la", "entrada", "en", "tareas", "como", "el", "reconocimiento", "de", "objetos", "o", "el", "reconocimiento", "del", "habla", ",", "utilizando", "datos", "limitados", "y", "etiquetados", "para", "afinar", "las", "representaciones", "construidas", "con", "un", "gran", "conjunto", "de", "datos", "sensoriales", "de", "entrada", "no", "etiquetados", "."], "sentence-detokenized": "Al igual que las DBN, las DBM pueden aprender representaciones internas complejas y abstractas de la entrada en tareas como el reconocimiento de objetos o el reconocimiento del habla, utilizando datos limitados y etiquetados para afinar las representaciones construidas con un gran conjunto de datos sensoriales de entrada no etiquetados.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 16], [17, 20], [20, 21], [22, 25], [26, 29], [30, 36], [37, 45], [46, 62], [63, 71], [72, 81], [82, 83], [84, 94], [95, 97], [98, 100], [101, 108], [109, 111], [112, 118], [119, 123], [124, 126], [127, 141], [142, 144], [145, 152], [153, 154], [155, 157], [158, 172], [173, 176], [177, 182], [182, 183], [184, 194], [195, 200], [201, 210], [211, 212], [213, 224], [225, 229], [230, 236], [237, 240], [241, 257], [258, 269], [270, 273], [274, 276], [277, 281], [282, 290], [291, 293], [294, 299], [300, 311], [312, 314], [315, 322], [323, 325], [326, 337], [337, 338]]}
{"doc_key": "ai-test-77", "ner": [[10, 16, "task"], [18, 18, "conference"], [20, 20, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 18, 10, 16, "topic", "", false, false], [20, 20, 10, 16, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Las", "conferencias", "cient\u00edficas", "en", "las", "que", "suelen", "aparecer", "trabajos", "de", "reconocimiento", "de", "actividades", "basados", "en", "la", "visi\u00f3n", "son", "ICCV", "y", "CVPR", "."], "sentence-detokenized": "Las conferencias cient\u00edficas en las que suelen aparecer trabajos de reconocimiento de actividades basados en la visi\u00f3n son ICCV y CVPR.", "token2charspan": [[0, 3], [4, 16], [17, 28], [29, 31], [32, 35], [36, 39], [40, 46], [47, 55], [56, 64], [65, 67], [68, 82], [83, 85], [86, 97], [98, 105], [106, 108], [109, 111], [112, 118], [119, 122], [123, 127], [128, 129], [130, 134], [134, 135]]}
{"doc_key": "ai-test-78", "ner": [[1, 1, "field"], [5, 8, "algorithm"], [10, 10, "algorithm"], [20, 21, "metrics"], [23, 25, "metrics"], [27, 27, "metrics"], [41, 42, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 8, 1, 1, "part-of", "", false, false], [5, 8, 20, 21, "related-to", "finds", false, false], [5, 8, 23, 25, "related-to", "finds", false, false], [5, 8, 41, 42, "related-to", "", false, false], [10, 10, 5, 8, "named", "", false, false], [27, 27, 23, 25, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["En", "estad\u00edstica", ",", "un", "algoritmo", "de", "maximizaci\u00f3n", "de", "expectativas", "(", "EM", ")", "es", "un", "m\u00e9todo", "iterativo", "para", "encontrar", "estimaciones", "de", "m\u00e1xima", "verosimilitud", "o", "m\u00e1xima", "a", "posteriori", "(", "MAP", ")", "de", "los", "par\u00e1metros", "en", "modelos", "estad\u00edsticos", ",", "donde", "el", "modelo", "depende", "de", "variables", "latentes", "no", "observadas", "."], "sentence-detokenized": "En estad\u00edstica, un algoritmo de maximizaci\u00f3n de expectativas (EM) es un m\u00e9todo iterativo para encontrar estimaciones de m\u00e1xima verosimilitud o m\u00e1xima a posteriori (MAP) de los par\u00e1metros en modelos estad\u00edsticos, donde el modelo depende de variables latentes no observadas.", "token2charspan": [[0, 2], [3, 14], [14, 15], [16, 18], [19, 28], [29, 31], [32, 44], [45, 47], [48, 60], [61, 62], [62, 64], [64, 65], [66, 68], [69, 71], [72, 78], [79, 88], [89, 93], [94, 103], [104, 116], [117, 119], [120, 126], [127, 140], [141, 142], [143, 149], [150, 151], [152, 162], [163, 164], [164, 167], [167, 168], [169, 171], [172, 175], [176, 186], [187, 189], [190, 197], [198, 210], [210, 211], [212, 217], [218, 220], [221, 227], [228, 235], [236, 238], [239, 248], [249, 257], [258, 260], [261, 271], [271, 272]]}
{"doc_key": "ai-test-79", "ner": [[14, 14, "metrics"], [16, 16, "metrics"], [23, 26, "metrics"], [28, 28, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 16, 14, 14, "named", "", false, false], [28, 28, 23, 26, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Del", "mismo", "modo", ",", "los", "investigadores", "a", "veces", "informan", "de", "la", "tasa", "de", "falsos", "positivos", "(", "FPR", ")", ",", "as\u00ed", "como", "de", "la", "tasa", "de", "falsos", "negativos", "(", "FNR", ")", "."], "sentence-detokenized": "Del mismo modo, los investigadores a veces informan de la tasa de falsos positivos (FPR), as\u00ed como de la tasa de falsos negativos (FNR).", "token2charspan": [[0, 3], [4, 9], [10, 14], [14, 15], [16, 19], [20, 34], [35, 36], [37, 42], [43, 51], [52, 54], [55, 57], [58, 62], [63, 65], [66, 72], [73, 82], [83, 84], [84, 87], [87, 88], [88, 89], [90, 93], [94, 98], [99, 101], [102, 104], [105, 109], [110, 112], [113, 119], [120, 129], [130, 131], [131, 134], [134, 135], [135, 136]]}
{"doc_key": "ai-test-80", "ner": [[6, 7, "metrics"], [10, 11, "field"], [15, 17, "metrics"], [20, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 11, 6, 7, "usage", "", false, false], [20, 22, 15, 17, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["El", "concepto", "es", "similar", "a", "la", "relaci\u00f3n", "se\u00f1al/ruido", "utilizada", "en", "las", "ciencias", "y", "a", "la", "matriz", "de", "confusi\u00f3n", "utilizada", "en", "la", "inteligencia", "artificial", "."], "sentence-detokenized": "El concepto es similar a la relaci\u00f3n se\u00f1al/ruido utilizada en las ciencias y a la matriz de confusi\u00f3n utilizada en la inteligencia artificial.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 22], [23, 24], [25, 27], [28, 36], [37, 48], [49, 58], [59, 61], [62, 65], [66, 74], [75, 76], [77, 78], [79, 81], [82, 88], [89, 91], [92, 101], [102, 111], [112, 114], [115, 117], [118, 130], [131, 141], [141, 142]]}
{"doc_key": "ai-test-81", "ner": [[5, 6, "field"], [13, 14, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [33, 38, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 13, 14, "general-affiliation", "", false, false], [5, 6, 20, 21, "general-affiliation", "", false, false], [5, 6, 23, 24, "general-affiliation", "", false, false], [33, 38, 5, 6, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["El", "C\u00f3digo", "\u00c9tico", "sobre", "la", "Aumentaci\u00f3n", "Humana", ",", "que", "fue", "presentado", "originalmente", "por", "Steve", "Mann", "en", "2004", "y", "perfeccionado", "con", "Ray", "Kurzweil", "y", "Marvin", "Minsky", "en", "2013", ",", "fue", "finalmente", "ratificado", "en", "la", "conferencia", "de", "Realidad", "Virtual", "de", "Toronto", "el", "25", "de", "junio", "de", "2017", "."], "sentence-detokenized": "El C\u00f3digo \u00c9tico sobre la Aumentaci\u00f3n Humana, que fue presentado originalmente por Steve Mann en 2004 y perfeccionado con Ray Kurzweil y Marvin Minsky en 2013, fue finalmente ratificado en la conferencia de Realidad Virtual de Toronto el 25 de junio de 2017.", "token2charspan": [[0, 2], [3, 9], [10, 15], [16, 21], [22, 24], [25, 36], [37, 43], [43, 44], [45, 48], [49, 52], [53, 63], [64, 77], [78, 81], [82, 87], [88, 92], [93, 95], [96, 100], [101, 102], [103, 116], [117, 120], [121, 124], [125, 133], [134, 135], [136, 142], [143, 149], [150, 152], [153, 157], [157, 158], [159, 162], [163, 173], [174, 184], [185, 187], [188, 190], [191, 202], [203, 205], [206, 214], [215, 222], [223, 225], [226, 233], [234, 236], [237, 239], [240, 242], [243, 248], [249, 251], [252, 256], [256, 257]]}
{"doc_key": "ai-test-82", "ner": [[3, 6, "person"], [12, 15, "organisation"], [21, 22, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 6, 12, 15, "role", "directed_for", false, false], [3, 6, 21, 22, "role", "collaborator", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["En", "1913", ",", "Walter", "R", ".", "Booth", "dirigi\u00f3", "10", "pel\u00edculas", "para", "la", "Kinoplastikon", "del", "Reino", "Unido", ",", "presumiblemente", "en", "colaboraci\u00f3n", "con", "Cecil", "Hepworth", "."], "sentence-detokenized": "En 1913, Walter R. Booth dirigi\u00f3 10 pel\u00edculas para la Kinoplastikon del Reino Unido, presumiblemente en colaboraci\u00f3n con Cecil Hepworth.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 17], [17, 18], [19, 24], [25, 32], [33, 35], [36, 45], [46, 50], [51, 53], [54, 67], [68, 71], [72, 77], [78, 83], [83, 84], [85, 100], [101, 103], [104, 116], [117, 120], [121, 126], [127, 135], [135, 136]]}
{"doc_key": "ai-test-83", "ner": [[15, 15, "location"], [12, 13, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 13, 15, 15, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Presentaron", "su", "nuevo", "robot", "en", "1961", "en", "una", "feria", "comercial", "en", "el", "Cow", "Palace", "de", "Chicago", "."], "sentence-detokenized": "Presentaron su nuevo robot en 1961 en una feria comercial en el Cow Palace de Chicago.", "token2charspan": [[0, 11], [12, 14], [15, 20], [21, 26], [27, 29], [30, 34], [35, 37], [38, 41], [42, 47], [48, 57], [58, 60], [61, 63], [64, 67], [68, 74], [75, 77], [78, 85], [85, 86]]}
{"doc_key": "ai-test-84", "ner": [[5, 5, "product"], [10, 12, "task"], [15, 17, "field"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 10, 12, "usage", "", false, false], [5, 5, 15, 17, "usage", "", false, false], [5, 5, 21, 22, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Mientras", "que", "algunas", "aplicaciones", "de", "chatbot", "utilizan", "amplios", "procesos", "de", "clasificaci\u00f3n", "de", "palabras", ",", "procesadores", "de", "lenguaje", "natural", "y", "una", "sofisticada", "inteligencia", "artificial", ",", "otras", "se", "limitan", "a", "buscar", "palabras", "clave", "generales", "y", "a", "generar", "respuestas", "utilizando", "frases", "comunes", "obtenidas", "de", "una", "biblioteca", "o", "base", "de", "datos", "asociada", "."], "sentence-detokenized": "Mientras que algunas aplicaciones de chatbot utilizan amplios procesos de clasificaci\u00f3n de palabras, procesadores de lenguaje natural y una sofisticada inteligencia artificial, otras se limitan a buscar palabras clave generales y a generar respuestas utilizando frases comunes obtenidas de una biblioteca o base de datos asociada.", "token2charspan": [[0, 8], [9, 12], [13, 20], [21, 33], [34, 36], [37, 44], [45, 53], [54, 61], [62, 70], [71, 73], [74, 87], [88, 90], [91, 99], [99, 100], [101, 113], [114, 116], [117, 125], [126, 133], [134, 135], [136, 139], [140, 151], [152, 164], [165, 175], [175, 176], [177, 182], [183, 185], [186, 193], [194, 195], [196, 202], [203, 211], [212, 217], [218, 227], [228, 229], [230, 231], [232, 239], [240, 250], [251, 261], [262, 268], [269, 276], [277, 286], [287, 289], [290, 293], [294, 304], [305, 306], [307, 311], [312, 314], [315, 320], [321, 329], [329, 330]]}
{"doc_key": "ai-test-85", "ner": [[2, 2, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["El", "modelo", "WaveNet", "propuesto", "en", "2016", "consigue", "un", "gran", "rendimiento", "en", "la", "calidad", "del", "habla", "."], "sentence-detokenized": "El modelo WaveNet propuesto en 2016 consigue un gran rendimiento en la calidad del habla.", "token2charspan": [[0, 2], [3, 9], [10, 17], [18, 27], [28, 30], [31, 35], [36, 44], [45, 47], [48, 52], [53, 64], [65, 67], [68, 70], [71, 78], [79, 82], [83, 88], [88, 89]]}
{"doc_key": "ai-test-86", "ner": [[6, 6, "product"], [9, 11, "misc"], [14, 18, "misc"], [21, 22, "misc"], [25, 28, "misc"], [30, 32, "organisation"], [34, 34, "organisation"], [36, 41, "organisation"], [43, 43, "organisation"], [45, 48, "organisation"], [50, 51, "organisation"], [53, 55, "organisation"], [57, 59, "organisation"], [62, 62, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[6, 6, 9, 11, "general-affiliation", "", false, false], [6, 6, 14, 18, "general-affiliation", "", false, false], [6, 6, 21, 22, "general-affiliation", "", false, false], [6, 6, 25, 28, "general-affiliation", "", false, false], [30, 32, 6, 6, "usage", "", false, false], [34, 34, 6, 6, "usage", "", false, false], [36, 41, 6, 6, "usage", "", false, false], [43, 43, 6, 6, "usage", "", false, false], [45, 48, 6, 6, "usage", "", false, false], [50, 51, 6, 6, "usage", "", false, false], [53, 55, 6, 6, "usage", "", false, false], [57, 59, 6, 6, "usage", "", false, false], [62, 62, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Organizaciones", "que", "se", "sabe", "que", "utilizan", "ALE", "para", "la", "gesti\u00f3n", "de", "emergencias", ",", "la", "ayuda", "en", "caso", "de", "cat\u00e1strofe", ",", "la", "comunicaci\u00f3n", "ordinaria", "o", "la", "respuesta", "en", "situaciones", "extraordinarias", ":", "Cruz", "Roja", "Americana", ",", "FEMA", ",", "Equipos", "de", "Asistencia", "M\u00e9dica", "en", "Cat\u00e1strofes", ",", "OTAN", ",", "Oficina", "Federal", "de", "Investigaci\u00f3n", ",", "Naciones", "Unidas", ",", "AT", "&", "T", ",", "Patrulla", "A\u00e9rea", "Civil", ",", "(", "ARES", ")", "."], "sentence-detokenized": "Organizaciones que se sabe que utilizan ALE para la gesti\u00f3n de emergencias, la ayuda en caso de cat\u00e1strofe, la comunicaci\u00f3n ordinaria o la respuesta en situaciones extraordinarias: Cruz Roja Americana, FEMA, Equipos de Asistencia M\u00e9dica en Cat\u00e1strofes, OTAN, Oficina Federal de Investigaci\u00f3n, Naciones Unidas, AT & T, Patrulla A\u00e9rea Civil, (ARES).", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 26], [27, 30], [31, 39], [40, 43], [44, 48], [49, 51], [52, 59], [60, 62], [63, 74], [74, 75], [76, 78], [79, 84], [85, 87], [88, 92], [93, 95], [96, 106], [106, 107], [108, 110], [111, 123], [124, 133], [134, 135], [136, 138], [139, 148], [149, 151], [152, 163], [164, 179], [179, 180], [181, 185], [186, 190], [191, 200], [200, 201], [202, 206], [206, 207], [208, 215], [216, 218], [219, 229], [230, 236], [237, 239], [240, 251], [251, 252], [253, 257], [257, 258], [259, 266], [267, 274], [275, 277], [278, 291], [291, 292], [293, 301], [302, 308], [308, 309], [310, 312], [313, 314], [315, 316], [316, 317], [318, 326], [327, 332], [333, 338], [338, 339], [340, 341], [341, 345], [345, 346], [346, 347]]}
{"doc_key": "ai-test-87", "ner": [[7, 9, "algorithm"], [18, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["En", "este", "caso", ",", "se", "utiliza", "el", "delta", "de", "Kronecker", "para", "simplificar", "(", "v\u00e9ase", "la", "derivada", "de", "una", "funci\u00f3n", "sigmoidea", ",", "que", "se", "expresa", "a", "trav\u00e9s", "de", "la", "propia", "funci\u00f3n", ")", "."], "sentence-detokenized": "En este caso, se utiliza el delta de Kronecker para simplificar (v\u00e9ase la derivada de una funci\u00f3n sigmoidea, que se expresa a trav\u00e9s de la propia funci\u00f3n).", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 16], [17, 24], [25, 27], [28, 33], [34, 36], [37, 46], [47, 51], [52, 63], [64, 65], [65, 70], [71, 73], [74, 82], [83, 85], [86, 89], [90, 97], [98, 107], [107, 108], [109, 112], [113, 115], [116, 123], [124, 125], [126, 132], [133, 135], [136, 138], [139, 145], [146, 153], [153, 154], [154, 155]]}
{"doc_key": "ai-test-88", "ner": [[12, 13, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "teor\u00eda", "se", "basa", "en", "fundamentos", "filos\u00f3ficos", ",", "y", "fue", "fundada", "por", "Ray", "Solomonoff", "alrededor", "de", "1960", ".", "Samuel", "Rathmanner", "y", "Marcus", "Hutter", "."], "sentence-detokenized": "La teor\u00eda se basa en fundamentos filos\u00f3ficos, y fue fundada por Ray Solomonoff alrededor de 1960. Samuel Rathmanner y Marcus Hutter.", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 17], [18, 20], [21, 32], [33, 44], [44, 45], [46, 47], [48, 51], [52, 59], [60, 63], [64, 67], [68, 78], [79, 88], [89, 91], [92, 96], [96, 97], [98, 104], [105, 115], [116, 117], [118, 124], [125, 131], [131, 132]]}
{"doc_key": "ai-test-89", "ner": [[0, 0, "product"], [13, 14, "misc"], [17, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 13, 14, "type-of", "", false, false], [0, 0, 17, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["WordNet", ",", "una", "base", "de", "datos", "de", "libre", "acceso", "concebida", "originalmente", "como", "una", "red", "sem\u00e1ntica", "basada", "en", "principios", "psicoling\u00fc\u00edsticos", ",", "se", "ampli\u00f3", "mediante", "la", "adici\u00f3n", "de", "definiciones", "y", "ahora", "se", "considera", "tambi\u00e9n", "un", "diccionario", "."], "sentence-detokenized": "WordNet, una base de datos de libre acceso concebida originalmente como una red sem\u00e1ntica basada en principios psicoling\u00fc\u00edsticos, se ampli\u00f3 mediante la adici\u00f3n de definiciones y ahora se considera tambi\u00e9n un diccionario.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 17], [18, 20], [21, 26], [27, 29], [30, 35], [36, 42], [43, 52], [53, 66], [67, 71], [72, 75], [76, 79], [80, 89], [90, 96], [97, 99], [100, 110], [111, 128], [128, 129], [130, 132], [133, 139], [140, 148], [149, 151], [152, 159], [160, 162], [163, 175], [176, 177], [178, 183], [184, 186], [187, 196], [197, 204], [205, 207], [208, 219], [219, 220]]}
{"doc_key": "ai-test-90", "ner": [[9, 11, "field"], [22, 22, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[22, 22, 9, 11, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Los", "avances", "en", "el", "campo", "de", "la", "investigaci\u00f3n", "de", "la", "imagen", "computacional", "se", "presentan", "en", "varios", "lugares", ",", "como", "las", "publicaciones", "de", "SIGGRAPH", "y", "el", "."], "sentence-detokenized": "Los avances en el campo de la investigaci\u00f3n de la imagen computacional se presentan en varios lugares, como las publicaciones de SIGGRAPH y el.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 17], [18, 23], [24, 26], [27, 29], [30, 43], [44, 46], [47, 49], [50, 56], [57, 70], [71, 73], [74, 83], [84, 86], [87, 93], [94, 101], [101, 102], [103, 107], [108, 111], [112, 125], [126, 128], [129, 137], [138, 139], [140, 142], [142, 143]]}
{"doc_key": "ai-test-91", "ner": [[0, 1, "task"], [10, 11, "task"], [14, 15, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 0, 1, "part-of", "", false, false], [14, 15, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "clasificaci\u00f3n", "puede", "considerarse", "como", "dos", "problemas", "distintos", ":", "la", "clasificaci\u00f3n", "binaria", "y", "la", "clasificaci\u00f3n", "multiclase", "."], "sentence-detokenized": "La clasificaci\u00f3n puede considerarse como dos problemas distintos: la clasificaci\u00f3n binaria y la clasificaci\u00f3n multiclase.", "token2charspan": [[0, 2], [3, 16], [17, 22], [23, 35], [36, 40], [41, 44], [45, 54], [55, 64], [64, 65], [66, 68], [69, 82], [83, 90], [91, 92], [93, 95], [96, 109], [110, 120], [120, 121]]}
{"doc_key": "ai-test-92", "ner": [[15, 16, "algorithm"], [22, 24, "algorithm"], [26, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 24, 15, 16, "type-of", "", false, false], [26, 26, 22, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Los", "buscadores", "de", "genes", "avanzados", ",", "tanto", "para", "genomas", "procariotas", "como", "eucariotas", ",", "suelen", "utilizar", "modelos", "probabil\u00edsticos", "complejos", ",", "como", "los", "modelos", "de", "Markov", "ocultos", "(", "HMM", ")", ",", "para", "combinar", "la", "informaci\u00f3n", "procedente", "de", "una", "serie", "de", "mediciones", "de", "se\u00f1al", "y", "contenido", "diferentes", "."], "sentence-detokenized": "Los buscadores de genes avanzados, tanto para genomas procariotas como eucariotas, suelen utilizar modelos probabil\u00edsticos complejos, como los modelos de Markov ocultos (HMM), para combinar la informaci\u00f3n procedente de una serie de mediciones de se\u00f1al y contenido diferentes.", "token2charspan": [[0, 3], [4, 14], [15, 17], [18, 23], [24, 33], [33, 34], [35, 40], [41, 45], [46, 53], [54, 65], [66, 70], [71, 81], [81, 82], [83, 89], [90, 98], [99, 106], [107, 122], [123, 132], [132, 133], [134, 138], [139, 142], [143, 150], [151, 153], [154, 160], [161, 168], [169, 170], [170, 173], [173, 174], [174, 175], [176, 180], [181, 189], [190, 192], [193, 204], [205, 215], [216, 218], [219, 222], [223, 228], [229, 231], [232, 242], [243, 245], [246, 251], [252, 253], [254, 263], [264, 274], [274, 275]]}
{"doc_key": "ai-test-93", "ner": [[0, 1, "misc"], [4, 4, "misc"], [10, 11, "field"], [14, 15, "algorithm"], [18, 20, "algorithm"], [22, 22, "algorithm"], [32, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 10, 11, "part-of", "", false, false], [0, 1, 14, 15, "usage", "", false, false], [4, 4, 0, 1, "named", "", false, false], [18, 20, 0, 1, "origin", "", true, false], [22, 22, 18, 20, "named", "", false, false], [32, 33, 0, 1, "origin", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["La", "neuroevoluci\u00f3n", ",", "o", "neuro-evoluci\u00f3n", ",", "es", "una", "forma", "de", "inteligencia", "artificial", "que", "utiliza", "algoritmos", "evolutivos", "para", "generar", "redes", "neuronales", "artificiales", "(", "RNA", ")", ",", "par\u00e1metros", ",", "topolog\u00eda", "y", "reglas", ".", "y", "rob\u00f3tica", "evolutiva", "."], "sentence-detokenized": "La neuroevoluci\u00f3n, o neuro-evoluci\u00f3n, es una forma de inteligencia artificial que utiliza algoritmos evolutivos para generar redes neuronales artificiales (RNA), par\u00e1metros, topolog\u00eda y reglas. y rob\u00f3tica evolutiva.", "token2charspan": [[0, 2], [3, 17], [17, 18], [19, 20], [21, 36], [36, 37], [38, 40], [41, 44], [45, 50], [51, 53], [54, 66], [67, 77], [78, 81], [82, 89], [90, 100], [101, 111], [112, 116], [117, 124], [125, 130], [131, 141], [142, 154], [155, 156], [156, 159], [159, 160], [160, 161], [162, 172], [172, 173], [174, 183], [184, 185], [186, 192], [192, 193], [194, 195], [196, 204], [205, 214], [214, 215]]}
{"doc_key": "ai-test-94", "ner": [[2, 2, "organisation"], [9, 9, "metrics"], [10, 10, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 2, 2, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Desde", "que", "IBM", "propuso", "y", "realiz\u00f3", "el", "sistema", "de", "BLEU", "Papineni", "et", "al", "."], "sentence-detokenized": "Desde que IBM propuso y realiz\u00f3 el sistema de BLEU Papineni et al.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 21], [22, 23], [24, 31], [32, 34], [35, 42], [43, 45], [46, 50], [51, 59], [60, 62], [63, 65], [65, 66]]}
{"doc_key": "ai-test-95", "ner": [[12, 19, "conference"], [21, 21, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[21, 21, 12, 19, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["En", "2009", ",", "los", "expertos", "asistieron", "a", "una", "conferencia", "organizada", "por", "la", "Asociaci\u00f3n", "para", "el", "Avance", "de", "la", "Inteligencia", "Artificial", "(", "AAAI", ")", "para", "debatir", "si", "los", "ordenadores", "y", "los", "robots", "podr\u00edan", "adquirir", "alg\u00fan", "tipo", "de", "autonom\u00eda", ",", "y", "hasta", "qu\u00e9", "punto", "estas", "capacidades", "podr\u00edan", "suponer", "una", "amenaza", "o", "un", "peligro", "."], "sentence-detokenized": "En 2009, los expertos asistieron a una conferencia organizada por la Asociaci\u00f3n para el Avance de la Inteligencia Artificial (AAAI) para debatir si los ordenadores y los robots podr\u00edan adquirir alg\u00fan tipo de autonom\u00eda, y hasta qu\u00e9 punto estas capacidades podr\u00edan suponer una amenaza o un peligro.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 21], [22, 32], [33, 34], [35, 38], [39, 50], [51, 61], [62, 65], [66, 68], [69, 79], [80, 84], [85, 87], [88, 94], [95, 97], [98, 100], [101, 113], [114, 124], [125, 126], [126, 130], [130, 131], [132, 136], [137, 144], [145, 147], [148, 151], [152, 163], [164, 165], [166, 169], [170, 176], [177, 184], [185, 193], [194, 199], [200, 204], [205, 207], [208, 217], [217, 218], [219, 220], [221, 226], [227, 230], [231, 236], [237, 242], [243, 254], [255, 262], [263, 270], [271, 274], [275, 282], [283, 284], [285, 287], [288, 295], [295, 296]]}
{"doc_key": "ai-test-96", "ner": [[34, 35, "researcher"], [37, 38, "researcher"], [40, 43, "task"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[40, 43, 34, 35, "artifact", "", false, false], [40, 43, 37, 38, "artifact", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["Despu\u00e9s", "de", "la", "potenciaci\u00f3n", ",", "un", "clasificador", "construido", "a", "partir", "de", "200", "caracter\u00edsticas", "podr\u00eda", "producir", "una", "tasa", "de", "detecci\u00f3n", "del", "95%", "con", "una", "tasa", "positiva", "^", "{", "-5", "}", "/", "math", "FALSE", ".", "/", "P.", "Viola", ",", "M.", "Jones", ",", "Robust", "Real-time", "Object", "Detection", ",", "2001", "."], "sentence-detokenized": "Despu\u00e9s de la potenciaci\u00f3n, un clasificador construido a partir de 200 caracter\u00edsticas podr\u00eda producir una tasa de detecci\u00f3n del 95% con una tasa positiva ^ {-5} / math FALSE. / P. Viola, M. Jones, Robust Real-time Object Detection, 2001.", "token2charspan": [[0, 7], [8, 10], [11, 13], [14, 26], [26, 27], [28, 30], [31, 43], [44, 54], [55, 56], [57, 63], [64, 66], [67, 70], [71, 86], [87, 93], [94, 102], [103, 106], [107, 111], [112, 114], [115, 124], [125, 128], [129, 132], [133, 136], [137, 140], [141, 145], [146, 154], [155, 156], [157, 158], [158, 160], [160, 161], [162, 163], [164, 168], [169, 174], [174, 175], [176, 177], [178, 180], [181, 186], [186, 187], [188, 190], [191, 196], [196, 197], [198, 204], [205, 214], [215, 221], [222, 231], [231, 232], [233, 237], [237, 238]]}
{"doc_key": "ai-test-97", "ner": [[7, 7, "programlang"], [10, 10, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["El", "sitio", "web", "estaba", "originalmente", "basado", "en", "Perl", ",", "pero", "IMDb", "ya", "no", "revela", "qu\u00e9", "software", "utiliza", "por", "razones", "de", "seguridad", "."], "sentence-detokenized": "El sitio web estaba originalmente basado en Perl, pero IMDb ya no revela qu\u00e9 software utiliza por razones de seguridad.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 19], [20, 33], [34, 40], [41, 43], [44, 48], [48, 49], [50, 54], [55, 59], [60, 62], [63, 65], [66, 72], [73, 76], [77, 85], [86, 93], [94, 97], [98, 105], [106, 108], [109, 118], [118, 119]]}
{"doc_key": "ai-test-98", "ner": [[5, 6, "researcher"], [8, 9, "researcher"], [11, 12, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "empresa", "fue", "fundada", "por", "Demis", "Hassabis", ",", "Shane", "Legg", "y", "Mustafa", "Suleyman", "en", "2010", "."], "sentence-detokenized": "La empresa fue fundada por Demis Hassabis, Shane Legg y Mustafa Suleyman en 2010.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 22], [23, 26], [27, 32], [33, 41], [41, 42], [43, 48], [49, 53], [54, 55], [56, 63], [64, 72], [73, 75], [76, 80], [80, 81]]}
{"doc_key": "ai-test-99", "ner": [[1, 3, "misc"], [8, 10, "metrics"], [25, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 1, 3, "type-of", "", false, false], [25, 26, 1, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Dos", "funciones", "de", "p\u00e9rdida", "muy", "utilizadas", "son", "el", "error", "cuadr\u00e1tico", "medio", ",", "mathL", "(", "a", ")", "=", "a", "^", "2", "/", "math", ",", "y", "la", "p\u00e9rdida", "absoluta", ",", "mathL", "(", "a", ")", "=", "|", "a", "|", "/", "math", "."], "sentence-detokenized": "Dos funciones de p\u00e9rdida muy utilizadas son el error cuadr\u00e1tico medio, mathL (a) = a ^ 2 / math, y la p\u00e9rdida absoluta, mathL (a) = | a | / math.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 24], [25, 28], [29, 39], [40, 43], [44, 46], [47, 52], [53, 63], [64, 69], [69, 70], [71, 76], [77, 78], [78, 79], [79, 80], [81, 82], [83, 84], [85, 86], [87, 88], [89, 90], [91, 95], [95, 96], [97, 98], [99, 101], [102, 109], [110, 118], [118, 119], [120, 125], [126, 127], [127, 128], [128, 129], [130, 131], [132, 133], [134, 135], [136, 137], [138, 139], [140, 144], [144, 145]]}
{"doc_key": "ai-test-100", "ner": [[0, 5, "algorithm"], [15, 18, "algorithm"], [20, 20, "algorithm"], [24, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 5, 15, 18, "type-of", "example_of", false, false], [15, 18, 24, 26, "related-to", "", false, false], [20, 20, 15, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "m\u00e1quina", "de", "vectores", "de", "apoyo", "de", "margen", "suave", "descrita", "anteriormente", "es", "un", "ejemplo", "de", "minimizaci\u00f3n", "emp\u00edrica", "del", "riesgo", "(", "ERM", ")", "para", "la", "p\u00e9rdida", "de", "bisagra", "."], "sentence-detokenized": "La m\u00e1quina de vectores de apoyo de margen suave descrita anteriormente es un ejemplo de minimizaci\u00f3n emp\u00edrica del riesgo (ERM) para la p\u00e9rdida de bisagra.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 22], [23, 25], [26, 31], [32, 34], [35, 41], [42, 47], [48, 56], [57, 70], [71, 73], [74, 76], [77, 84], [85, 87], [88, 100], [101, 109], [110, 113], [114, 120], [121, 122], [122, 125], [125, 126], [127, 131], [132, 134], [135, 142], [143, 145], [146, 153], [153, 154]]}
{"doc_key": "ai-test-101", "ner": [[13, 14, "field"], [9, 9, "task"], [1, 3, "task"], [25, 25, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 3, 13, 14, "origin", "", false, false], [1, 3, 9, 9, "type-of", "", false, false], [25, 25, 1, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "traducci\u00f3n", "autom\u00e1tica", "neural", ",", "un", "enfoque", "de", "la", "TA", "basado", "en", "el", "aprendizaje", "profundo", ",", "ha", "progresado", "r\u00e1pidamente", "en", "los", "\u00faltimos", "a\u00f1os", ",", "y", "Google", "ha", "anunciado", "que", "sus", "servicios", "de", "traducci\u00f3n", "utilizan", "ahora", "esta", "tecnolog\u00eda", "en", "lugar", "de", "sus", "anteriores", "m\u00e9todos", "estad\u00edsticos", "."], "sentence-detokenized": "La traducci\u00f3n autom\u00e1tica neural, un enfoque de la TA basado en el aprendizaje profundo, ha progresado r\u00e1pidamente en los \u00faltimos a\u00f1os, y Google ha anunciado que sus servicios de traducci\u00f3n utilizan ahora esta tecnolog\u00eda en lugar de sus anteriores m\u00e9todos estad\u00edsticos.", "token2charspan": [[0, 2], [3, 13], [14, 24], [25, 31], [31, 32], [33, 35], [36, 43], [44, 46], [47, 49], [50, 52], [53, 59], [60, 62], [63, 65], [66, 77], [78, 86], [86, 87], [88, 90], [91, 101], [102, 113], [114, 116], [117, 120], [121, 128], [129, 133], [133, 134], [135, 136], [137, 143], [144, 146], [147, 156], [157, 160], [161, 164], [165, 174], [175, 177], [178, 188], [189, 197], [198, 203], [204, 208], [209, 219], [220, 222], [223, 228], [229, 231], [232, 235], [236, 246], [247, 254], [255, 267], [267, 268]]}
{"doc_key": "ai-test-102", "ner": [[16, 16, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Esto", "tiende", "a", "producir", "ganancias", "de", "rendimiento", "muy", "grandes", "cuando", "se", "trabaja", "con", "grandes", "corpus", "como", "WordNet", "."], "sentence-detokenized": "Esto tiende a producir ganancias de rendimiento muy grandes cuando se trabaja con grandes corpus como WordNet.", "token2charspan": [[0, 4], [5, 11], [12, 13], [14, 22], [23, 32], [33, 35], [36, 47], [48, 51], [52, 59], [60, 66], [67, 69], [70, 77], [78, 81], [82, 89], [90, 96], [97, 101], [102, 109], [109, 110]]}
{"doc_key": "ai-test-103", "ner": [[0, 3, "task"], [7, 7, "field"], [20, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 20, 23, "part-of", "", false, false], [20, 23, 7, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "detecci\u00f3n", "de", "rostros", "se", "utiliza", "en", "biometr\u00eda", ",", "a", "menudo", "como", "parte", "de", "(", "o", "junto", "con", ")", "un", "sistema", "de", "reconocimiento", "facial", "."], "sentence-detokenized": "La detecci\u00f3n de rostros se utiliza en biometr\u00eda, a menudo como parte de (o junto con) un sistema de reconocimiento facial.", "token2charspan": [[0, 2], [3, 12], [13, 15], [16, 23], [24, 26], [27, 34], [35, 37], [38, 47], [47, 48], [49, 50], [51, 57], [58, 62], [63, 68], [69, 71], [72, 73], [73, 74], [75, 80], [81, 84], [84, 85], [86, 88], [89, 96], [97, 99], [100, 114], [115, 121], [121, 122]]}
{"doc_key": "ai-test-104", "ner": [[2, 5, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["entrenado", "por", "estimaci\u00f3n", "de", "m\u00e1xima", "verosimilitud", "."], "sentence-detokenized": "entrenado por estimaci\u00f3n de m\u00e1xima verosimilitud.", "token2charspan": [[0, 9], [10, 13], [14, 24], [25, 27], [28, 34], [35, 48], [48, 49]]}
{"doc_key": "ai-test-105", "ner": [[3, 3, "country"], [5, 10, "organisation"], [14, 14, "location"], [16, 16, "country"], [18, 22, "organisation"], [24, 24, "country"], [30, 30, "organisation"], [35, 38, "organisation"], [40, 40, "country"], [51, 55, "organisation"], [57, 57, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[5, 10, 14, 14, "physical", "", false, false], [14, 14, 16, 16, "physical", "", false, false], [18, 22, 24, 24, "physical", "", false, false], [35, 38, 40, 40, "physical", "", false, false], [51, 55, 57, 57, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Ltd", ".", "en", "Tailandia", ";", "Komatsu", "(", "Shanghai", ")", "Ltd", ".", "en", "1996", "en", "Shanghai", ",", "China", ";", "Industrial", "Power", "Alliance", "Ltd", ".", "en", "Jap\u00f3n", ",", "una", "empresa", "conjunta", "con", "Cummins", ",", "en", "1998", ";", "L", "&", "T-Komatsu", "Limited", "en", "India", "en", "1998", "(", "acciones", "vendidas", "en", "2013", ")", ";", "y", "Komatsu", "Brasil", "International", "Ltda", ".", "en", "Brasil", "en", "1998", "."], "sentence-detokenized": "Ltd. en Tailandia; Komatsu (Shanghai) Ltd. en 1996 en Shanghai, China; Industrial Power Alliance Ltd. en Jap\u00f3n, una empresa conjunta con Cummins, en 1998; L & T-Komatsu Limited en India en 1998 (acciones vendidas en 2013); y Komatsu Brasil International Ltda. en Brasil en 1998.", "token2charspan": [[0, 3], [3, 4], [5, 7], [8, 17], [17, 18], [19, 26], [27, 28], [28, 36], [36, 37], [38, 41], [41, 42], [43, 45], [46, 50], [51, 53], [54, 62], [62, 63], [64, 69], [69, 70], [71, 81], [82, 87], [88, 96], [97, 100], [100, 101], [102, 104], [105, 110], [110, 111], [112, 115], [116, 123], [124, 132], [133, 136], [137, 144], [144, 145], [146, 148], [149, 153], [153, 154], [155, 156], [157, 158], [159, 168], [169, 176], [177, 179], [180, 185], [186, 188], [189, 193], [194, 195], [195, 203], [204, 212], [213, 215], [216, 220], [220, 221], [221, 222], [223, 224], [225, 232], [233, 239], [240, 253], [254, 258], [258, 259], [260, 262], [263, 269], [270, 272], [273, 277], [277, 278]]}
{"doc_key": "ai-test-106", "ner": [[0, 1, "organisation"], [6, 8, "misc"], [15, 16, "misc"], [17, 18, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[17, 18, 0, 1, "physical", "", false, false], [17, 18, 6, 8, "general-affiliation", "", false, false], [17, 18, 15, 16, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "dgp", "tambi\u00e9n", "acoge", "ocasionalmente", "a", "artistas", "en", "residencia", "(", "por", "ejemplo", ",", "el", "ganador", "del", "Oscar", "Chris", "Landreth", "."], "sentence-detokenized": "La dgp tambi\u00e9n acoge ocasionalmente a artistas en residencia (por ejemplo, el ganador del Oscar Chris Landreth.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 20], [21, 35], [36, 37], [38, 46], [47, 49], [50, 60], [61, 62], [62, 65], [66, 73], [73, 74], [75, 77], [78, 85], [86, 89], [90, 95], [96, 101], [102, 110], [110, 111]]}
{"doc_key": "ai-test-107", "ner": [[6, 9, "misc"], [12, 14, "misc"], [17, 21, "misc"], [25, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Actualmente", "incluye", "cuatro", "subcompeticiones", ":", "la", "competici\u00f3n", "de", "rob\u00f3tica", "RoboMaster", ",", "el", "desaf\u00edo", "t\u00e9cnico", "RoboMaster", ",", "el", "desaf\u00edo", "de", "IA", "ICRA", "RoboMaster", "y", "el", "nuevo", "torneo", "juvenil", "RoboMaster", "."], "sentence-detokenized": "Actualmente incluye cuatro subcompeticiones: la competici\u00f3n de rob\u00f3tica RoboMaster, el desaf\u00edo t\u00e9cnico RoboMaster, el desaf\u00edo de IA ICRA RoboMaster y el nuevo torneo juvenil RoboMaster.", "token2charspan": [[0, 11], [12, 19], [20, 26], [27, 43], [43, 44], [45, 47], [48, 59], [60, 62], [63, 71], [72, 82], [82, 83], [84, 86], [87, 94], [95, 102], [103, 113], [113, 114], [115, 117], [118, 125], [126, 128], [129, 131], [132, 136], [137, 147], [148, 149], [150, 152], [153, 158], [159, 165], [166, 173], [174, 184], [184, 185]]}
{"doc_key": "ai-test-108", "ner": [[11, 13, "field"], [19, 22, "algorithm"], [27, 28, "algorithm"], [33, 34, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 13, 27, 28, "usage", "", false, false], [11, 13, 33, 34, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "principios", "de", "la", "d\u00e9cada", "de", "2000", ",", "la", "estrategia", "de", "procesamiento", "del", "habla", "dominante", "empez\u00f3", "a", "alejarse", "del", "modelo", "de", "Markov", "oculto", "para", "acercarse", "a", "las", "redes", "neuronales", "m\u00e1s", "modernas", "y", "al", "aprendizaje", "profundo", "."], "sentence-detokenized": "A principios de la d\u00e9cada de 2000, la estrategia de procesamiento del habla dominante empez\u00f3 a alejarse del modelo de Markov oculto para acercarse a las redes neuronales m\u00e1s modernas y al aprendizaje profundo.", "token2charspan": [[0, 1], [2, 12], [13, 15], [16, 18], [19, 25], [26, 28], [29, 33], [33, 34], [35, 37], [38, 48], [49, 51], [52, 65], [66, 69], [70, 75], [76, 85], [86, 92], [93, 94], [95, 103], [104, 107], [108, 114], [115, 117], [118, 124], [125, 131], [132, 136], [137, 146], [147, 148], [149, 152], [153, 158], [159, 169], [170, 173], [174, 182], [183, 184], [185, 187], [188, 199], [200, 208], [208, 209]]}
{"doc_key": "ai-test-109", "ner": [[9, 11, "misc"], [17, 18, "metrics"], [22, 23, "metrics"], [31, 33, "metrics"], [36, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[17, 18, 22, 23, "related-to", "equal", false, false], [31, 33, 36, 38, "related-to", "equal", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Otra", "expresi\u00f3n", "equivalente", ",", "en", "el", "caso", "de", "una", "tasa", "objetivo", "binaria", ",", "es", "que", "la", "tasa", "positiva", "VERDADERA", "y", "la", "tasa", "positiva", "FALSA", "son", "iguales", "(", "y", "por", "tanto", "la", "tasa", "negativa", "FALSA", "y", "la", "tasa", "negativa", "VERDADERA", "son", "iguales", ")", "para", "cada", "valor", "de", "las", "caracter\u00edsticas", "sensibles", ":"], "sentence-detokenized": "Otra expresi\u00f3n equivalente, en el caso de una tasa objetivo binaria, es que la tasa positiva VERDADERA y la tasa positiva FALSA son iguales (y por tanto la tasa negativa FALSA y la tasa negativa VERDADERA son iguales) para cada valor de las caracter\u00edsticas sensibles:", "token2charspan": [[0, 4], [5, 14], [15, 26], [26, 27], [28, 30], [31, 33], [34, 38], [39, 41], [42, 45], [46, 50], [51, 59], [60, 67], [67, 68], [69, 71], [72, 75], [76, 78], [79, 83], [84, 92], [93, 102], [103, 104], [105, 107], [108, 112], [113, 121], [122, 127], [128, 131], [132, 139], [140, 141], [141, 142], [143, 146], [147, 152], [153, 155], [156, 160], [161, 169], [170, 175], [176, 177], [178, 180], [181, 185], [186, 194], [195, 204], [205, 208], [209, 216], [216, 217], [218, 222], [223, 227], [228, 233], [234, 236], [237, 240], [241, 256], [257, 266], [266, 267]]}
{"doc_key": "ai-test-110", "ner": [[3, 3, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "funci\u00f3n", "de", "MATLAB", ","], "sentence-detokenized": "La funci\u00f3n de MATLAB,", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 20], [20, 21]]}
{"doc_key": "ai-test-111", "ner": [[1, 2, "product"], [7, 8, "misc"], [19, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 1, 2, "part-of", "", false, false], [19, 20, 1, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Un", "robot", "articulado", "es", "un", "robot", "con", "articulaciones", "giratorias", "(", "por", "ejemplo", ",", "un", "robot", "con", "patas", "o", "un", "robot", "industrial", ")", "."], "sentence-detokenized": "Un robot articulado es un robot con articulaciones giratorias (por ejemplo, un robot con patas o un robot industrial).", "token2charspan": [[0, 2], [3, 8], [9, 19], [20, 22], [23, 25], [26, 31], [32, 35], [36, 50], [51, 61], [62, 63], [63, 66], [67, 74], [74, 75], [76, 78], [79, 84], [85, 88], [89, 94], [95, 96], [97, 99], [100, 105], [106, 116], [116, 117], [117, 118]]}
{"doc_key": "ai-test-112", "ner": [[0, 0, "product"], [5, 6, "product"], [8, 9, "product"], [14, 14, "misc"], [24, 27, "product"], [31, 33, "misc"], [38, 38, "location"], [40, 40, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 14, 14, "general-affiliation", "nationality", false, false], [0, 0, 31, 33, "usage", "", false, false], [0, 0, 38, 38, "physical", "", false, false], [5, 6, 0, 0, "named", "", false, false], [8, 9, 0, 0, "named", "", false, false], [38, 38, 40, 40, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pandora", "(", "tambi\u00e9n", "conocida", "como", "Pandora", "Media", "o", "Pandora", "Radio", ")", "es", "un", "servicio", "estadounidense", "de", "radio", "por", "Internet", "de", "transmisi\u00f3n", "de", "m\u00fasica", "y", "sistema", "de", "recomendaci\u00f3n", "automatizado", "impulsado", "por", "el", "Music", "Genome", "Project", "y", "con", "sede", "en", "Oakland", ",", "California", "."], "sentence-detokenized": "Pandora (tambi\u00e9n conocida como Pandora Media o Pandora Radio) es un servicio estadounidense de radio por Internet de transmisi\u00f3n de m\u00fasica y sistema de recomendaci\u00f3n automatizado impulsado por el Music Genome Project y con sede en Oakland, California.", "token2charspan": [[0, 7], [8, 9], [9, 16], [17, 25], [26, 30], [31, 38], [39, 44], [45, 46], [47, 54], [55, 60], [60, 61], [62, 64], [65, 67], [68, 76], [77, 91], [92, 94], [95, 100], [101, 104], [105, 113], [114, 116], [117, 128], [129, 131], [132, 138], [139, 140], [141, 148], [149, 151], [152, 165], [166, 178], [179, 188], [189, 192], [193, 195], [196, 201], [202, 208], [209, 216], [217, 218], [219, 222], [223, 227], [228, 230], [231, 238], [238, 239], [240, 250], [250, 251]]}
{"doc_key": "ai-test-113", "ner": [[8, 12, "organisation"], [18, 22, "organisation"], [29, 30, "conference"], [41, 42, "conference"], [44, 45, "conference"], [47, 48, "conference"], [51, 51, "conference"], [53, 54, "conference"], [57, 57, "conference"], [59, 60, "conference"], [63, 63, "conference"], [65, 66, "conference"], [68, 69, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [], "relations_mapping_to_source": [], "sentence": ["Es", "miembro", "de", "la", "junta", "directiva", "de", "la", "Sociedad", "Internacional", "de", "Aprendizaje", "Autom\u00e1tico", ",", "ha", "sido", "miembro", "del", "consejo", "ejecutivo", "de", "la", "AAAI", ",", "fue", "copresidenta", "del", "PC", "del", "ICML", "2011", "y", "ha", "sido", "miembro", "senior", "del", "PC", "de", "conferencias", "como", "la", "AAAI", ",", "el", "ICML", ",", "el", "IJCAI", ",", "el", "ISWC", ",", "la", "KDD", ",", "el", "SIGMOD", ",", "la", "UAI", ",", "el", "VLDB", ",", "el", "WSDM", "y", "la", "WWW."], "sentence-detokenized": "Es miembro de la junta directiva de la Sociedad Internacional de Aprendizaje Autom\u00e1tico, ha sido miembro del consejo ejecutivo de la AAAI, fue copresidenta del PC del ICML 2011 y ha sido miembro senior del PC de conferencias como la AAAI, el ICML, el IJCAI, el ISWC, la KDD, el SIGMOD, la UAI, el VLDB, el WSDM y la WWW.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 16], [17, 22], [23, 32], [33, 35], [36, 38], [39, 47], [48, 61], [62, 64], [65, 76], [77, 87], [87, 88], [89, 91], [92, 96], [97, 104], [105, 108], [109, 116], [117, 126], [127, 129], [130, 132], [133, 137], [137, 138], [139, 142], [143, 155], [156, 159], [160, 162], [163, 166], [167, 171], [172, 176], [177, 178], [179, 181], [182, 186], [187, 194], [195, 201], [202, 205], [206, 208], [209, 211], [212, 224], [225, 229], [230, 232], [233, 237], [237, 238], [239, 241], [242, 246], [246, 247], [248, 250], [251, 256], [256, 257], [258, 260], [261, 265], [265, 266], [267, 269], [270, 273], [273, 274], [275, 277], [278, 284], [284, 285], [286, 288], [289, 292], [292, 293], [294, 296], [297, 301], [301, 302], [303, 305], [306, 310], [311, 312], [313, 315], [316, 320]]}
{"doc_key": "ai-test-114", "ner": [[0, 2, "researcher"], [5, 10, "organisation"], [12, 12, "organisation"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 10, "role", "", false, false], [12, 12, 5, 10, "named", "", false, false], [17, 17, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["James", "S.", "Albus", ",", "del", "Instituto", "Nacional", "de", "Est\u00e1ndares", "y", "Tecnolog\u00eda", "(", "NIST", ")", ",", "desarroll\u00f3", "la", "Robocrane", ",", "en", "la", "que", "la", "plataforma", "cuelga", "de", "seis", "cables", "en", "lugar", "de", "apoyarse", "en", "seis", "gatos", "."], "sentence-detokenized": "James S. Albus, del Instituto Nacional de Est\u00e1ndares y Tecnolog\u00eda (NIST), desarroll\u00f3 la Robocrane, en la que la plataforma cuelga de seis cables en lugar de apoyarse en seis gatos.", "token2charspan": [[0, 5], [6, 8], [9, 14], [14, 15], [16, 19], [20, 29], [30, 38], [39, 41], [42, 52], [53, 54], [55, 65], [66, 67], [67, 71], [71, 72], [72, 73], [74, 84], [85, 87], [88, 97], [97, 98], [99, 101], [102, 104], [105, 108], [109, 111], [112, 122], [123, 129], [130, 132], [133, 137], [138, 144], [145, 147], [148, 153], [154, 156], [157, 165], [166, 168], [169, 173], [174, 179], [179, 180]]}
{"doc_key": "ai-test-115", "ner": [[3, 6, "algorithm"], [10, 13, "algorithm"], [16, 18, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 13, 3, 6, "type-of", "", false, false], [16, 18, 10, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Otra", "clase", "de", "algoritmos", "de", "b\u00fasqueda", "directa", "son", "los", "diversos", "algoritmos", "evolutivos", ",", "por", "ejemplo", ",", "los", "algoritmos", "gen\u00e9ticos", "."], "sentence-detokenized": "Otra clase de algoritmos de b\u00fasqueda directa son los diversos algoritmos evolutivos, por ejemplo, los algoritmos gen\u00e9ticos.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 24], [25, 27], [28, 36], [37, 44], [45, 48], [49, 52], [53, 61], [62, 72], [73, 83], [83, 84], [85, 88], [89, 96], [96, 97], [98, 101], [102, 112], [113, 122], [122, 123]]}
{"doc_key": "ai-test-116", "ner": [[0, 0, "organisation"], [3, 4, "misc"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 0, 0, "named", "", false, false], [6, 7, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["KUKA", "es", "un", "fabricante", "alem\u00e1n", "de", "robots", "industriales", "y", "soluciones", "para", "la", "automatizaci\u00f3n", "de", "f\u00e1bricas", "."], "sentence-detokenized": "KUKA es un fabricante alem\u00e1n de robots industriales y soluciones para la automatizaci\u00f3n de f\u00e1bricas.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 21], [22, 28], [29, 31], [32, 38], [39, 51], [52, 53], [54, 64], [65, 69], [70, 72], [73, 87], [88, 90], [91, 99], [99, 100]]}
{"doc_key": "ai-test-117", "ner": [[10, 10, "misc"], [21, 22, "person"], [12, 18, "misc"], [27, 28, "person"], [24, 24, "misc"], [34, 35, "person"], [30, 31, "misc"], [42, 43, "person"], [37, 39, "misc"], [51, 53, "person"], [45, 48, "misc"], [60, 61, "person"], [56, 67, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[21, 22, 10, 10, "usage", "", false, false], [12, 18, 21, 22, "artifact", "", false, false], [27, 28, 10, 10, "usage", "", false, false], [24, 24, 27, 28, "artifact", "", false, false], [34, 35, 10, 10, "usage", "", false, false], [30, 31, 34, 35, "artifact", "", false, false], [42, 43, 10, 10, "usage", "", false, false], [37, 39, 42, 43, "artifact", "", false, false], [51, 53, 10, 10, "usage", "", false, false], [45, 48, 51, 53, "artifact", "", false, false], [60, 61, 10, 10, "usage", "", false, false], [56, 67, 60, 61, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Otras", "pel\u00edculas", "entre", "2016", "y", "2020", "que", "captaron", "con", "c\u00e1maras", "IMAX", "fueron", "Batman", "v", "Superman", ":", "Dawn", "of", "Justice", ",", "de", "Zack", "Snyder", ",", "Sully", ",", "de", "Clint", "Eastwood", ",", "First", "Man", ",", "de", "Damien", "Chazelle", ",", "Wonder", "Woman", "1984", ",", "de", "Patty", "Jenkins", ",", "No", "Time", "to", "Die", ",", "de", "Cary", "Joji", "Fukunaga", ",", "y", "Top", "Gun", ",", "de", "Joseph", "Kosinski", ":", "Maverick", ",", "de", "Joseph", "Kosinski", "."], "sentence-detokenized": "Otras pel\u00edculas entre 2016 y 2020 que captaron con c\u00e1maras IMAX fueron Batman v Superman: Dawn of Justice, de Zack Snyder, Sully, de Clint Eastwood, First Man, de Damien Chazelle, Wonder Woman 1984, de Patty Jenkins, No Time to Die, de Cary Joji Fukunaga, y Top Gun, de Joseph Kosinski: Maverick, de Joseph Kosinski.", "token2charspan": [[0, 5], [6, 15], [16, 21], [22, 26], [27, 28], [29, 33], [34, 37], [38, 46], [47, 50], [51, 58], [59, 63], [64, 70], [71, 77], [78, 79], [80, 88], [88, 89], [90, 94], [95, 97], [98, 105], [105, 106], [107, 109], [110, 114], [115, 121], [121, 122], [123, 128], [128, 129], [130, 132], [133, 138], [139, 147], [147, 148], [149, 154], [155, 158], [158, 159], [160, 162], [163, 169], [170, 178], [178, 179], [180, 186], [187, 192], [193, 197], [197, 198], [199, 201], [202, 207], [208, 215], [215, 216], [217, 219], [220, 224], [225, 227], [228, 231], [231, 232], [233, 235], [236, 240], [241, 245], [246, 254], [254, 255], [256, 257], [258, 261], [262, 265], [265, 266], [267, 269], [270, 276], [277, 285], [285, 286], [287, 295], [295, 296], [297, 299], [300, 306], [307, 315], [315, 316]]}
{"doc_key": "ai-test-118", "ner": [[6, 7, "misc"], [12, 14, "organisation"], [16, 16, "organisation"], [30, 30, "misc"], [36, 37, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 7, 30, 30, "named", "", false, false], [12, 14, 6, 7, "usage", "", false, false], [12, 14, 36, 37, "physical", "", false, false], [16, 16, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["La", "prueba", "del", "tipo", "de", "letra", "MICR", "E13B", "se", "mostr\u00f3", "a", "la", "American", "Bankers", "Association", "(", "ABA", ")", "en", "julio", "de", "1956", ",", "que", "la", "adopt\u00f3", "en", "1958", "como", "norma", "MICR", "para", "los", "documentos", "negociables", "en", "Estados", "Unidos", "."], "sentence-detokenized": "La prueba del tipo de letra MICR E13B se mostr\u00f3 a la American Bankers Association (ABA) en julio de 1956, que la adopt\u00f3 en 1958 como norma MICR para los documentos negociables en Estados Unidos.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 18], [19, 21], [22, 27], [28, 32], [33, 37], [38, 40], [41, 47], [48, 49], [50, 52], [53, 61], [62, 69], [70, 81], [82, 83], [83, 86], [86, 87], [88, 90], [91, 96], [97, 99], [100, 104], [104, 105], [106, 109], [110, 112], [113, 119], [120, 122], [123, 127], [128, 132], [133, 138], [139, 143], [144, 148], [149, 152], [153, 163], [164, 175], [176, 178], [179, 186], [187, 193], [193, 194]]}
{"doc_key": "ai-test-119", "ner": [[0, 4, "misc"], [17, 20, "field"], [23, 24, "field"], [27, 27, "field"], [29, 31, "field"], [33, 33, "field"], [35, 35, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[17, 20, 0, 4, "usage", "", false, false], [23, 24, 17, 20, "part-of", "", false, false], [27, 27, 0, 4, "usage", "", false, false], [29, 31, 0, 4, "usage", "", false, false], [33, 33, 0, 4, "usage", "", false, false], [35, 35, 0, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Los", "algoritmos", "de", "b\u00fasqueda", "local", "se", "aplican", "ampliamente", "a", "numerosos", "problemas", "computacionales", "dif\u00edciles", ",", "incluyendo", "problemas", "de", "ciencias", "de", "la", "computaci\u00f3n", "(", "particularmente", "inteligencia", "artificial", ")", ",", "matem\u00e1ticas", ",", "investigaci\u00f3n", "de", "operaciones", ",", "ingenier\u00eda", "y", "bioinform\u00e1tica", "."], "sentence-detokenized": "Los algoritmos de b\u00fasqueda local se aplican ampliamente a numerosos problemas computacionales dif\u00edciles, incluyendo problemas de ciencias de la computaci\u00f3n (particularmente inteligencia artificial), matem\u00e1ticas, investigaci\u00f3n de operaciones, ingenier\u00eda y bioinform\u00e1tica.", "token2charspan": [[0, 3], [4, 14], [15, 17], [18, 26], [27, 32], [33, 35], [36, 43], [44, 55], [56, 57], [58, 67], [68, 77], [78, 93], [94, 103], [103, 104], [105, 115], [116, 125], [126, 128], [129, 137], [138, 140], [141, 143], [144, 155], [156, 157], [157, 172], [173, 185], [186, 196], [196, 197], [197, 198], [199, 210], [210, 211], [212, 225], [226, 228], [229, 240], [240, 241], [242, 252], [253, 254], [255, 269], [269, 270]]}
{"doc_key": "ai-test-120", "ner": [[0, 1, "researcher"], [11, 11, "location"], [13, 13, "country"], [18, 18, "country"], [26, 27, "algorithm"], [30, 30, "algorithm"], [33, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 11, 11, "physical", "", false, false], [0, 1, 18, 18, "general-affiliation", "nationality", false, false], [0, 1, 26, 27, "general-affiliation", "topic_of_study", false, false], [0, 1, 30, 30, "general-affiliation", "topic_of_study", false, false], [11, 11, 13, 13, "physical", "", false, false], [30, 30, 33, 35, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gerd", "Gigerenzer", "(", "nacido", "el", "3", "de", "septiembre", "de", "1947", "en", "Wallersdorf", ",", "Alemania", ")", "es", "un", "psic\u00f3logo", "alem\u00e1n", "que", "ha", "estudiado", "el", "uso", "de", "la", "racionalidad", "limitada", "y", "la", "heur\u00edstica", "en", "la", "toma", "de", "decisiones", "."], "sentence-detokenized": "Gerd Gigerenzer (nacido el 3 de septiembre de 1947 en Wallersdorf, Alemania) es un psic\u00f3logo alem\u00e1n que ha estudiado el uso de la racionalidad limitada y la heur\u00edstica en la toma de decisiones.", "token2charspan": [[0, 4], [5, 15], [16, 17], [17, 23], [24, 26], [27, 28], [29, 31], [32, 42], [43, 45], [46, 50], [51, 53], [54, 65], [65, 66], [67, 75], [75, 76], [77, 79], [80, 82], [83, 92], [93, 99], [100, 103], [104, 106], [107, 116], [117, 119], [120, 123], [124, 126], [127, 129], [130, 142], [143, 151], [152, 153], [154, 156], [157, 167], [168, 170], [171, 173], [174, 178], [179, 181], [182, 192], [192, 193]]}
{"doc_key": "ai-test-121", "ner": [[3, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["para", "minimizar", "el", "error", "cuadr\u00e1tico", "medio", "."], "sentence-detokenized": "para minimizar el error cuadr\u00e1tico medio.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 23], [24, 34], [35, 40], [40, 41]]}
{"doc_key": "ai-test-122", "ner": [[12, 13, "misc"], [16, 17, "organisation"], [32, 35, "field"], [53, 54, "misc"], [63, 65, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 13, 16, 17, "origin", "", false, false], [53, 54, 63, 65, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pero", "incluso", "una", "lengua", "oficial", "con", "una", "academia", "reguladora", ",", "como", "el", "franc\u00e9s", "est\u00e1ndar", "con", "la", "Acad\u00e9mie", "fran\u00e7aise", ",", "se", "clasifica", "como", "lengua", "natural", "(", "por", "ejemplo", ",", "en", "el", "\u00e1mbito", "del", "procesamiento", "del", "lenguaje", "natural", ")", ",", "ya", "que", "sus", "puntos", "prescriptivos", "no", "la", "hacen", "lo", "suficientemente", "construida", "como", "para", "clasificarla", "como", "lengua", "construida", "ni", "lo", "suficientemente", "controlada", "como", "para", "clasificarla", "como", "lengua", "natural", "controlada", "."], "sentence-detokenized": "Pero incluso una lengua oficial con una academia reguladora, como el franc\u00e9s est\u00e1ndar con la Acad\u00e9mie fran\u00e7aise, se clasifica como lengua natural (por ejemplo, en el \u00e1mbito del procesamiento del lenguaje natural), ya que sus puntos prescriptivos no la hacen lo suficientemente construida como para clasificarla como lengua construida ni lo suficientemente controlada como para clasificarla como lengua natural controlada.", "token2charspan": [[0, 4], [5, 12], [13, 16], [17, 23], [24, 31], [32, 35], [36, 39], [40, 48], [49, 59], [59, 60], [61, 65], [66, 68], [69, 76], [77, 85], [86, 89], [90, 92], [93, 101], [102, 111], [111, 112], [113, 115], [116, 125], [126, 130], [131, 137], [138, 145], [146, 147], [147, 150], [151, 158], [158, 159], [160, 162], [163, 165], [166, 172], [173, 176], [177, 190], [191, 194], [195, 203], [204, 211], [211, 212], [212, 213], [214, 216], [217, 220], [221, 224], [225, 231], [232, 245], [246, 248], [249, 251], [252, 257], [258, 260], [261, 276], [277, 287], [288, 292], [293, 297], [298, 310], [311, 315], [316, 322], [323, 333], [334, 336], [337, 339], [340, 355], [356, 366], [367, 371], [372, 376], [377, 389], [390, 394], [395, 401], [402, 409], [410, 420], [420, 421]]}
{"doc_key": "ai-test-123", "ner": [[9, 9, "metrics"], [11, 12, "metrics"], [14, 14, "metrics"], [34, 35, "metrics"], [37, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 14, 11, 12, "named", "", false, false], [37, 37, 34, 35, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Existen", "otras", "m\u00e9tricas", ",", "la", "m\u00e1s", "sencilla", "es", "la", "precisi\u00f3n", "o", "Fracci\u00f3n", "Correcta", "(", "FC", ")", ",", "que", "mide", "la", "fracci\u00f3n", "de", "todas", "las", "instancias", "que", "se", "clasifican", "correctamente", ";", "el", "complemento", "es", "la", "Fracci\u00f3n", "Incorrecta", "(", "FiC", ")", "."], "sentence-detokenized": "Existen otras m\u00e9tricas, la m\u00e1s sencilla es la precisi\u00f3n o Fracci\u00f3n Correcta (FC), que mide la fracci\u00f3n de todas las instancias que se clasifican correctamente; el complemento es la Fracci\u00f3n Incorrecta (FiC).", "token2charspan": [[0, 7], [8, 13], [14, 22], [22, 23], [24, 26], [27, 30], [31, 39], [40, 42], [43, 45], [46, 55], [56, 57], [58, 66], [67, 75], [76, 77], [77, 79], [79, 80], [80, 81], [82, 85], [86, 90], [91, 93], [94, 102], [103, 105], [106, 111], [112, 115], [116, 126], [127, 130], [131, 133], [134, 144], [145, 158], [158, 159], [160, 162], [163, 174], [175, 177], [178, 180], [181, 189], [190, 200], [201, 202], [202, 205], [205, 206], [206, 207]]}
{"doc_key": "ai-test-124", "ner": [[0, 0, "researcher"], [7, 10, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 7, 10, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cardie", "se", "convirti\u00f3", "en", "miembro", "de", "la", "Asociaci\u00f3n", "de", "Ling\u00fc\u00edstica", "Computacional", "en", "2016", "."], "sentence-detokenized": "Cardie se convirti\u00f3 en miembro de la Asociaci\u00f3n de Ling\u00fc\u00edstica Computacional en 2016.", "token2charspan": [[0, 6], [7, 9], [10, 19], [20, 22], [23, 30], [31, 33], [34, 36], [37, 47], [48, 50], [51, 62], [63, 76], [77, 79], [80, 84], [84, 85]]}
{"doc_key": "ai-test-125", "ner": [[14, 17, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["El", "aprendizaje", "de", "los", "par\u00e1metros", "math", "\\", "theta", "/", "math", "se", "suele", "hacer", "por", "aprendizaje", "de", "m\u00e1xima", "verosimilitud", "para", "mathp", "(", "Y", "_", "i", "|", "X", "_", "i", ";", "\\", "theta", ")", "/", "math", "."], "sentence-detokenized": "El aprendizaje de los par\u00e1metros math\\ theta / math se suele hacer por aprendizaje de m\u00e1xima verosimilitud para mathp (Y _ i | X _ i;\\ theta) / math.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 21], [22, 32], [33, 37], [37, 38], [39, 44], [45, 46], [47, 51], [52, 54], [55, 60], [61, 66], [67, 70], [71, 82], [83, 85], [86, 92], [93, 106], [107, 111], [112, 117], [118, 119], [119, 120], [121, 122], [123, 124], [125, 126], [127, 128], [129, 130], [131, 132], [132, 133], [133, 134], [135, 140], [140, 141], [142, 143], [144, 148], [148, 149]]}
{"doc_key": "ai-test-126", "ner": [[0, 2, "task"], [4, 8, "algorithm"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 0, 2, "usage", "", true, false], [11, 12, 4, 8, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An\u00e1lisis", "de", "cl\u00fasteres", "y", "factorizaci\u00f3n", "de", "matrices", "no", "negativas", "para", "la", "miner\u00eda", "descriptiva", "."], "sentence-detokenized": "An\u00e1lisis de cl\u00fasteres y factorizaci\u00f3n de matrices no negativas para la miner\u00eda descriptiva.", "token2charspan": [[0, 8], [9, 11], [12, 21], [22, 23], [24, 37], [38, 40], [41, 49], [50, 52], [53, 62], [63, 67], [68, 70], [71, 78], [79, 90], [90, 91]]}
{"doc_key": "ai-test-127", "ner": [[2, 5, "field"], [8, 11, "field"], [29, 33, "field"], [36, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[29, 33, 2, 5, "part-of", "", false, false], [29, 33, 8, 11, "part-of", "", false, false], [36, 39, 2, 5, "part-of", "", false, false], [36, 39, 8, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["En", "la", "ciencia", "de", "la", "computaci\u00f3n", "y", "la", "tecnolog\u00eda", "de", "la", "informaci\u00f3n", "que", "permite", ",", "ha", "sido", "un", "desaf\u00edo", "a", "largo", "plazo", "la", "capacidad", "en", "los", "ordenadores", "para", "hacer", "el", "procesamiento", "del", "lenguaje", "natural", "y", "el", "aprendizaje", "de", "la", "m\u00e1quina", "."], "sentence-detokenized": "En la ciencia de la computaci\u00f3n y la tecnolog\u00eda de la informaci\u00f3n que permite, ha sido un desaf\u00edo a largo plazo la capacidad en los ordenadores para hacer el procesamiento del lenguaje natural y el aprendizaje de la m\u00e1quina.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 19], [20, 31], [32, 33], [34, 36], [37, 47], [48, 50], [51, 53], [54, 65], [66, 69], [70, 77], [77, 78], [79, 81], [82, 86], [87, 89], [90, 97], [98, 99], [100, 105], [106, 111], [112, 114], [115, 124], [125, 127], [128, 131], [132, 143], [144, 148], [149, 154], [155, 157], [158, 171], [172, 175], [176, 184], [185, 192], [193, 194], [195, 197], [198, 209], [210, 212], [213, 215], [216, 223], [223, 224]]}
{"doc_key": "ai-test-128", "ner": [[5, 9, "algorithm"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 9, 15, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "El", "c\u00f3digo", "para", "la", "extracci\u00f3n", "de", "caracter\u00edsticas", "de", "Gabor", "a", "partir", "de", "im\u00e1genes", "en", "MATLAB", "puede", "encontrarse", "en"], "sentence-detokenized": "(El c\u00f3digo para la extracci\u00f3n de caracter\u00edsticas de Gabor a partir de im\u00e1genes en MATLAB puede encontrarse en", "token2charspan": [[0, 1], [1, 3], [4, 10], [11, 15], [16, 18], [19, 29], [30, 32], [33, 48], [49, 51], [52, 57], [58, 59], [60, 66], [67, 69], [70, 78], [79, 81], [82, 88], [89, 94], [95, 106], [107, 109]]}
{"doc_key": "ai-test-129", "ner": [[1, 1, "misc"], [19, 20, "algorithm"], [23, 23, "task"], [25, 25, "task"], [27, 29, "task"], [31, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 1, 19, 20, "general-affiliation", "", false, false], [1, 1, 23, 23, "related-to", "solves_problem_of_type", false, false], [1, 1, 25, 25, "related-to", "solves_problem_of_type", false, false], [1, 1, 27, 29, "related-to", "solves_problem_of_type", false, false], [1, 1, 31, 33, "related-to", "solves_problem_of_type", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["El", "NeuralExpert", "centra", "las", "especificaciones", "de", "dise\u00f1o", "en", "torno", "al", "tipo", "de", "problema", "que", "el", "usuario", "desea", "que", "la", "red", "neuronal", "resuelva", "(", "Clasificaci\u00f3n", ",", "Predicci\u00f3n", ",", "Aproximaci\u00f3n", "de", "funciones", "o", "An\u00e1lisis", "de", "conglomerados", ")", "."], "sentence-detokenized": "El NeuralExpert centra las especificaciones de dise\u00f1o en torno al tipo de problema que el usuario desea que la red neuronal resuelva (Clasificaci\u00f3n, Predicci\u00f3n, Aproximaci\u00f3n de funciones o An\u00e1lisis de conglomerados).", "token2charspan": [[0, 2], [3, 15], [16, 22], [23, 26], [27, 43], [44, 46], [47, 53], [54, 56], [57, 62], [63, 65], [66, 70], [71, 73], [74, 82], [83, 86], [87, 89], [90, 97], [98, 103], [104, 107], [108, 110], [111, 114], [115, 123], [124, 132], [133, 134], [134, 147], [147, 148], [149, 159], [159, 160], [161, 173], [174, 176], [177, 186], [187, 188], [189, 197], [198, 200], [201, 214], [214, 215], [215, 216]]}
{"doc_key": "ai-test-130", "ner": [[2, 6, "misc"], [30, 32, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Cuando", "el", "tama\u00f1o", "del", "paso", "de", "cuantificaci\u00f3n", "(", "\u0394", ")", "es", "peque\u00f1o", "en", "relaci\u00f3n", "con", "la", "variaci\u00f3n", "de", "la", "se\u00f1al", "que", "se", "cuantifica", ",", "es", "relativamente", "sencillo", "demostrar", "que", "el", "error", "cuadr\u00e1tico", "medio", "producido", "por", "dicha", "operaci\u00f3n", "de", "redondeo", "ser\u00e1", "aproximadamente", "math", "\\", "Delta", "^", "2", "/", "12", "/", "math.math"], "sentence-detokenized": "Cuando el tama\u00f1o del paso de cuantificaci\u00f3n (\u0394) es peque\u00f1o en relaci\u00f3n con la variaci\u00f3n de la se\u00f1al que se cuantifica, es relativamente sencillo demostrar que el error cuadr\u00e1tico medio producido por dicha operaci\u00f3n de redondeo ser\u00e1 aproximadamente math\\ Delta ^ 2 / 12 / math.math", "token2charspan": [[0, 6], [7, 9], [10, 16], [17, 20], [21, 25], [26, 28], [29, 43], [44, 45], [45, 46], [46, 47], [48, 50], [51, 58], [59, 61], [62, 70], [71, 74], [75, 77], [78, 87], [88, 90], [91, 93], [94, 99], [100, 103], [104, 106], [107, 117], [117, 118], [119, 121], [122, 135], [136, 144], [145, 154], [155, 158], [159, 161], [162, 167], [168, 178], [179, 184], [185, 194], [195, 198], [199, 204], [205, 214], [215, 217], [218, 226], [227, 231], [232, 247], [248, 252], [252, 253], [254, 259], [260, 261], [262, 263], [264, 265], [266, 268], [269, 270], [271, 280]]}
{"doc_key": "ai-test-131", "ner": [[20, 21, "product"], [28, 30, "researcher"], [32, 33, "researcher"], [35, 37, "researcher"], [39, 40, "researcher"], [42, 43, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "construcci\u00f3n", "de", "un", "l\u00e9xico", "rico", "con", "una", "ontolog\u00eda", "adecuada", "requiere", "un", "esfuerzo", "significativo", ",", "por", "ejemplo", ",", "el", "l\u00e9xico", "de", "Wordnet", "requiri\u00f3", "muchos", "a\u00f1os-persona", "de", "esfuerzo", ".", "G.", "A.", "Miller", ",", "R.", "Beckwith", ",", "C.", "D.", "Fellbaum", ",", "D.", "Gross", ",", "K.", "Miller", "."], "sentence-detokenized": "La construcci\u00f3n de un l\u00e9xico rico con una ontolog\u00eda adecuada requiere un esfuerzo significativo, por ejemplo, el l\u00e9xico de Wordnet requiri\u00f3 muchos a\u00f1os-persona de esfuerzo. G. A. Miller, R. Beckwith, C. D. Fellbaum, D. Gross, K. Miller.", "token2charspan": [[0, 2], [3, 15], [16, 18], [19, 21], [22, 28], [29, 33], [34, 37], [38, 41], [42, 51], [52, 60], [61, 69], [70, 72], [73, 81], [82, 95], [95, 96], [97, 100], [101, 108], [108, 109], [110, 112], [113, 119], [120, 122], [123, 130], [131, 139], [140, 146], [147, 159], [160, 162], [163, 171], [171, 172], [173, 175], [176, 178], [179, 185], [185, 186], [187, 189], [190, 198], [198, 199], [200, 202], [203, 205], [206, 214], [214, 215], [216, 218], [219, 224], [224, 225], [226, 228], [229, 235], [235, 236]]}
{"doc_key": "ai-test-132", "ner": [[3, 3, "organisation"], [18, 19, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 19, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["La", "cartera", "de", "Kawasaki", "tambi\u00e9n", "incluye", "techos", ",", "suelos", "y", "otras", "estructuras", "gigantes", "retr\u00e1ctiles", ";", "la", "superficie", "retr\u00e1ctil", "Sapporo", "Dome", "es", "un", "ejemplo", "."], "sentence-detokenized": "La cartera de Kawasaki tambi\u00e9n incluye techos, suelos y otras estructuras gigantes retr\u00e1ctiles; la superficie retr\u00e1ctil Sapporo Dome es un ejemplo.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 22], [23, 30], [31, 38], [39, 45], [45, 46], [47, 53], [54, 55], [56, 61], [62, 73], [74, 82], [83, 94], [94, 95], [96, 98], [99, 109], [110, 119], [120, 127], [128, 132], [133, 135], [136, 138], [139, 146], [146, 147]]}
{"doc_key": "ai-test-133", "ner": [[0, 2, "metrics"], [5, 8, "metrics"], [11, 13, "metrics"], [19, 22, "metrics"], [44, 44, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 19, 22, "related-to", "", false, false], [0, 2, 44, 44, "opposite", "alternative_to", false, false], [5, 8, 0, 2, "type-of", "", false, false], [11, 13, 0, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Los", "estad\u00edsticos", "kappa", ",", "como", "el", "kappa", "de", "Fleiss", "y", "el", "kappa", "de", "Cohen", ",", "son", "m\u00e9todos", "para", "calcular", "la", "fiabilidad", "entre", "evaluadores", "basados", "en", "diferentes", "supuestos", "sobre", "las", "distribuciones", "marginales", "o", "previas", ",", "y", "se", "utilizan", "cada", "vez", "m\u00e1s", "como", "alternativas", "a", "la", "precisi\u00f3n", "corregida", "por", "el", "azar", "en", "otros", "contextos", "."], "sentence-detokenized": "Los estad\u00edsticos kappa, como el kappa de Fleiss y el kappa de Cohen, son m\u00e9todos para calcular la fiabilidad entre evaluadores basados en diferentes supuestos sobre las distribuciones marginales o previas, y se utilizan cada vez m\u00e1s como alternativas a la precisi\u00f3n corregida por el azar en otros contextos.", "token2charspan": [[0, 3], [4, 16], [17, 22], [22, 23], [24, 28], [29, 31], [32, 37], [38, 40], [41, 47], [48, 49], [50, 52], [53, 58], [59, 61], [62, 67], [67, 68], [69, 72], [73, 80], [81, 85], [86, 94], [95, 97], [98, 108], [109, 114], [115, 126], [127, 134], [135, 137], [138, 148], [149, 158], [159, 164], [165, 168], [169, 183], [184, 194], [195, 196], [197, 204], [204, 205], [206, 207], [208, 210], [211, 219], [220, 224], [225, 228], [229, 232], [233, 237], [238, 250], [251, 252], [253, 255], [256, 265], [266, 275], [276, 279], [280, 282], [283, 287], [288, 290], [291, 296], [297, 306], [306, 307]]}
{"doc_key": "ai-test-134", "ner": [[3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [12, 13, "researcher"], [17, 17, "researcher"], [28, 30, "algorithm"], [32, 35, "algorithm"], [37, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 4, 17, 17, "role", "student_of", false, false], [6, 7, 17, 17, "role", "student_of", false, false], [9, 10, 17, 17, "role", "student_of", false, false], [12, 13, 17, 17, "role", "student_of", false, false], [32, 35, 3, 4, "origin", "", false, false], [32, 35, 6, 7, "origin", "", false, false], [32, 35, 9, 10, "origin", "", false, false], [32, 35, 12, 13, "origin", "", false, false], [32, 35, 17, 17, "origin", "", false, false], [32, 35, 28, 30, "type-of", "", false, false], [37, 37, 32, 35, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Con", "sus", "alumnos", "Sepp", "Hochreiter", ",", "Felix", "Gers", ",", "Fred", "Cummins", ",", "Alex", "Graves", "y", "otros", ",", "Schmidhuber", "public\u00f3", "versiones", "cada", "vez", "m\u00e1s", "sofisticadas", "de", "un", "tipo", "de", "red", "neuronal", "recurrente", "llamada", "memoria", "a", "corto", "plazo", "(", "LSTM", ")", "."], "sentence-detokenized": "Con sus alumnos Sepp Hochreiter, Felix Gers, Fred Cummins, Alex Graves y otros, Schmidhuber public\u00f3 versiones cada vez m\u00e1s sofisticadas de un tipo de red neuronal recurrente llamada memoria a corto plazo (LSTM).", "token2charspan": [[0, 3], [4, 7], [8, 15], [16, 20], [21, 31], [31, 32], [33, 38], [39, 43], [43, 44], [45, 49], [50, 57], [57, 58], [59, 63], [64, 70], [71, 72], [73, 78], [78, 79], [80, 91], [92, 99], [100, 109], [110, 114], [115, 118], [119, 122], [123, 135], [136, 138], [139, 141], [142, 146], [147, 149], [150, 153], [154, 162], [163, 173], [174, 181], [182, 189], [190, 191], [192, 197], [198, 203], [204, 205], [205, 209], [209, 210], [210, 211]]}
{"doc_key": "ai-test-135", "ner": [[6, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2004", "-", "Se", "lanza", "el", "primer", "Cobot", "KUKA", "LBR", "3", "."], "sentence-detokenized": "2004 - Se lanza el primer Cobot KUKA LBR 3.", "token2charspan": [[0, 4], [5, 6], [7, 9], [10, 15], [16, 18], [19, 25], [26, 31], [32, 36], [37, 40], [41, 42], [42, 43]]}
{"doc_key": "ai-test-136", "ner": [[10, 13, "algorithm"], [16, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Dos", "enfoques", "superficiales", "utilizados", "para", "entrenar", "y", "luego", "desambiguar", "son", "el", "clasificador", "Naive", "Bayes", "y", "los", "\u00e1rboles", "de", "decisi\u00f3n", "."], "sentence-detokenized": "Dos enfoques superficiales utilizados para entrenar y luego desambiguar son el clasificador Naive Bayes y los \u00e1rboles de decisi\u00f3n.", "token2charspan": [[0, 3], [4, 12], [13, 26], [27, 37], [38, 42], [43, 51], [52, 53], [54, 59], [60, 71], [72, 75], [76, 78], [79, 91], [92, 97], [98, 103], [104, 105], [106, 109], [110, 117], [118, 120], [121, 129], [129, 130]]}
{"doc_key": "ai-test-137", "ner": [[5, 5, "misc"], [13, 14, "person"], [16, 18, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 13, 14, "origin", "", false, false], [5, 5, 16, 18, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Las", "primeras", "formas", "pr\u00e1cticas", "de", "fotograf\u00eda", "fueron", "introducidas", "en", "enero", "de", "1839", "por", "Louis", "Daguerre", "y", "Henry", "Fox", "Talbot", "."], "sentence-detokenized": "Las primeras formas pr\u00e1cticas de fotograf\u00eda fueron introducidas en enero de 1839 por Louis Daguerre y Henry Fox Talbot.", "token2charspan": [[0, 3], [4, 12], [13, 19], [20, 29], [30, 32], [33, 43], [44, 50], [51, 63], [64, 66], [67, 72], [73, 75], [76, 80], [81, 84], [85, 90], [91, 99], [100, 101], [102, 107], [108, 111], [112, 118], [118, 119]]}
{"doc_key": "ai-test-138", "ner": [[4, 6, "task"], [11, 13, "task"], [24, 26, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 24, 26, "part-of", "task_part_of_field", false, false], [11, 13, 24, 26, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Por", "ejemplo", ",", "la", "s\u00edntesis", "del", "habla", ",", "combinada", "con", "el", "reconocimiento", "del", "habla", ",", "permite", "interactuar", "con", "los", "dispositivos", "m\u00f3viles", "mediante", "interfaces", "de", "procesamiento", "del", "lenguaje", "."], "sentence-detokenized": "Por ejemplo, la s\u00edntesis del habla, combinada con el reconocimiento del habla, permite interactuar con los dispositivos m\u00f3viles mediante interfaces de procesamiento del lenguaje.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 24], [25, 28], [29, 34], [34, 35], [36, 45], [46, 49], [50, 52], [53, 67], [68, 71], [72, 77], [77, 78], [79, 86], [87, 98], [99, 102], [103, 106], [107, 119], [120, 127], [128, 136], [137, 147], [148, 150], [151, 164], [165, 168], [169, 177], [177, 178]]}
{"doc_key": "ai-test-139", "ner": [[0, 1, "product"], [13, 13, "programlang"], [15, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 13, 13, "general-affiliation", "", false, false], [0, 1, 15, 16, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Los", "Phidgets", "pueden", "programarse", "con", "diversos", "programas", "y", "lenguajes", "de", "programaci\u00f3n", ",", "desde", "Java", "hasta", "Microsoft", "Excel", "."], "sentence-detokenized": "Los Phidgets pueden programarse con diversos programas y lenguajes de programaci\u00f3n, desde Java hasta Microsoft Excel.", "token2charspan": [[0, 3], [4, 12], [13, 19], [20, 31], [32, 35], [36, 44], [45, 54], [55, 56], [57, 66], [67, 69], [70, 82], [82, 83], [84, 89], [90, 94], [95, 100], [101, 110], [111, 116], [116, 117]]}
{"doc_key": "ai-test-140", "ner": [[2, 3, "field"], [9, 10, "researcher"], [13, 15, "misc"], [23, 25, "field"], [28, 29, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 9, 10, "origin", "", false, false], [9, 10, 23, 25, "general-affiliation", "topic_of_study", false, false], [9, 10, 28, 29, "general-affiliation", "topic_of_study", false, false], [13, 15, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["El", "t\u00e9rmino", "aprendizaje", "autom\u00e1tico", "fue", "acu\u00f1ado", "en", "1959", "por", "Arthur", "Samuel", ",", "un", "estadounidense", "de", "IBM", "y", "pionero", "en", "el", "campo", "de", "los", "juegos", "de", "ordenador", "y", "la", "inteligencia", "artificial", "."], "sentence-detokenized": "El t\u00e9rmino aprendizaje autom\u00e1tico fue acu\u00f1ado en 1959 por Arthur Samuel, un estadounidense de IBM y pionero en el campo de los juegos de ordenador y la inteligencia artificial.", "token2charspan": [[0, 2], [3, 10], [11, 22], [23, 33], [34, 37], [38, 45], [46, 48], [49, 53], [54, 57], [58, 64], [65, 71], [71, 72], [73, 75], [76, 90], [91, 93], [94, 97], [98, 99], [100, 107], [108, 110], [111, 113], [114, 119], [120, 122], [123, 126], [127, 133], [134, 136], [137, 146], [147, 148], [149, 151], [152, 164], [165, 175], [175, 176]]}
{"doc_key": "ai-test-141", "ner": [[1, 2, "misc"], [3, 4, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 1, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["El", "poeta", "israel\u00ed", "David", "Avidan", ",", "fascinado", "por", "las", "tecnolog\u00edas", "del", "futuro", "y", "su", "relaci\u00f3n", "con", "el", "arte", ",", "quiso", "explorar", "el", "uso", "de", "los", "ordenadores", "para", "escribir", "literatura", "."], "sentence-detokenized": "El poeta israel\u00ed David Avidan, fascinado por las tecnolog\u00edas del futuro y su relaci\u00f3n con el arte, quiso explorar el uso de los ordenadores para escribir literatura.", "token2charspan": [[0, 2], [3, 8], [9, 16], [17, 22], [23, 29], [29, 30], [31, 40], [41, 44], [45, 48], [49, 60], [61, 64], [65, 71], [72, 73], [74, 76], [77, 85], [86, 89], [90, 92], [93, 97], [97, 98], [99, 104], [105, 113], [114, 116], [117, 120], [121, 123], [124, 127], [128, 139], [140, 144], [145, 153], [154, 164], [164, 165]]}
{"doc_key": "ai-test-142", "ner": [[3, 4, "misc"], [8, 8, "organisation"], [14, 14, "location"], [30, 30, "location"], [31, 33, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 8, 3, 4, "part-of", "", false, false], [31, 33, 30, 30, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Como", "parte", "del", "proyecto", "GATEway", "en", "2017", ",", "Oxbotica", "prob\u00f3", "siete", "autobuses", "aut\u00f3nomos", "en", "Greenwich", ",", "navegando", "por", "un", "sendero", "de", "tres", "kil\u00f3metros", "junto", "al", "r\u00edo", ",", "cerca", "del", "estadio", "londinense", "The", "O2", "Arena", ",", "en", "una", "ruta", "tambi\u00e9n", "utilizada", "por", "peatones", "y", "ciclistas", "."], "sentence-detokenized": "Como parte del proyecto GATEway en 2017, Oxbotica prob\u00f3 siete autobuses aut\u00f3nomos en Greenwich, navegando por un sendero de tres kil\u00f3metros junto al r\u00edo, cerca del estadio londinense The O2 Arena, en una ruta tambi\u00e9n utilizada por peatones y ciclistas.", "token2charspan": [[0, 4], [5, 10], [11, 14], [15, 23], [24, 31], [32, 34], [35, 39], [39, 40], [41, 49], [50, 55], [56, 61], [62, 71], [72, 81], [82, 84], [85, 94], [94, 95], [96, 105], [106, 109], [110, 112], [113, 120], [121, 123], [124, 128], [129, 139], [140, 145], [146, 148], [149, 152], [152, 153], [154, 159], [160, 163], [164, 171], [172, 182], [183, 186], [187, 189], [190, 195], [195, 196], [197, 199], [200, 203], [204, 208], [209, 216], [217, 226], [227, 230], [231, 239], [240, 241], [242, 251], [251, 252]]}
{"doc_key": "ai-test-143", "ner": [[12, 14, "task"], [17, 18, "metrics"], [23, 24, "misc"], [31, 31, "metrics"], [34, 34, "metrics"], [38, 38, "metrics"], [40, 40, "metrics"], [42, 45, "metrics"], [48, 49, "metrics"], [52, 52, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[17, 18, 23, 24, "related-to", "is_a", false, false], [17, 18, 31, 31, "usage", "", false, false], [17, 18, 34, 34, "usage", "", false, false], [31, 31, 38, 38, "named", "same", false, false], [34, 34, 52, 52, "named", "same", false, false], [38, 38, 48, 49, "opposite", "", false, false], [38, 38, 52, 52, "opposite", "", false, false], [40, 40, 38, 38, "named", "", false, false], [42, 45, 38, 38, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Una", "combinaci\u00f3n", "no", "relacionada", "pero", "com\u00fanmente", "utilizada", "de", "estad\u00edsticas", "b\u00e1sicas", "de", "la", "recuperaci\u00f3n", "de", "informaci\u00f3n", "es", "la", "puntuaci\u00f3n", "F", ",", "que", "es", "una", "media", "arm\u00f3nica", "(", "posiblemente", "ponderada", ")", "de", "la", "recuperaci\u00f3n", "y", "la", "precisi\u00f3n", ",", "donde", "la", "recuperaci\u00f3n", "=", "sensibilidad", "=", "tasa", "de", "verdaderos", "positivos", ",", "pero", "la", "especificidad", "y", "la", "precisi\u00f3n", "son", "medidas", "totalmente", "diferentes", "."], "sentence-detokenized": "Una combinaci\u00f3n no relacionada pero com\u00fanmente utilizada de estad\u00edsticas b\u00e1sicas de la recuperaci\u00f3n de informaci\u00f3n es la puntuaci\u00f3n F, que es una media arm\u00f3nica (posiblemente ponderada) de la recuperaci\u00f3n y la precisi\u00f3n, donde la recuperaci\u00f3n = sensibilidad = tasa de verdaderos positivos, pero la especificidad y la precisi\u00f3n son medidas totalmente diferentes.", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 30], [31, 35], [36, 46], [47, 56], [57, 59], [60, 72], [73, 80], [81, 83], [84, 86], [87, 99], [100, 102], [103, 114], [115, 117], [118, 120], [121, 131], [132, 133], [133, 134], [135, 138], [139, 141], [142, 145], [146, 151], [152, 160], [161, 162], [162, 174], [175, 184], [184, 185], [186, 188], [189, 191], [192, 204], [205, 206], [207, 209], [210, 219], [219, 220], [221, 226], [227, 229], [230, 242], [243, 244], [245, 257], [258, 259], [260, 264], [265, 267], [268, 278], [279, 288], [288, 289], [290, 294], [295, 297], [298, 311], [312, 313], [314, 316], [317, 326], [327, 330], [331, 338], [339, 349], [350, 360], [360, 361]]}
{"doc_key": "ai-test-144", "ner": [[0, 2, "field"], [12, 12, "field"], [15, 15, "field"], [17, 18, "field"], [21, 21, "field"], [24, 25, "field"], [33, 35, "product"], [37, 38, "product"], [40, 41, "product"], [43, 44, "product"], [59, 61, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 2, 12, 12, "origin", "takes_inspiration_from", false, false], [0, 2, 15, 15, "origin", "takes_inspiration_from", false, false], [0, 2, 17, 18, "origin", "takes_inspiration_from", false, false], [0, 2, 21, 21, "origin", "takes_inspiration_from", false, false], [0, 2, 24, 25, "origin", "takes_inspiration_from", false, false], [33, 35, 0, 2, "origin", "", false, false], [37, 38, 0, 2, "origin", "", false, false], [40, 41, 0, 2, "origin", "", false, false], [43, 44, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["La", "ingenier\u00eda", "neurom\u00f3rfica", "es", "una", "materia", "interdisciplinar", "que", "se", "inspira", "en", "la", "biolog\u00eda", ",", "la", "f\u00edsica", ",", "las", "matem\u00e1ticas", ",", "la", "inform\u00e1tica", "y", "la", "ingenier\u00eda", "electr\u00f3nica", "para", "dise\u00f1ar", "sistemas", "neuronales", "artificiales", ",", "como", "sistemas", "de", "visi\u00f3n", ",", "sistemas", "cabeza-ojo", ",", "procesadores", "auditivos", "y", "robots", "aut\u00f3nomos", ",", "cuya", "arquitectura", "f\u00edsica", "y", "principios", "de", "dise\u00f1o", "se", "basan", "en", "los", "de", "los", "sistemas", "nerviosos", "biol\u00f3gicos", "."], "sentence-detokenized": "La ingenier\u00eda neurom\u00f3rfica es una materia interdisciplinar que se inspira en la biolog\u00eda, la f\u00edsica, las matem\u00e1ticas, la inform\u00e1tica y la ingenier\u00eda electr\u00f3nica para dise\u00f1ar sistemas neuronales artificiales, como sistemas de visi\u00f3n, sistemas cabeza-ojo, procesadores auditivos y robots aut\u00f3nomos, cuya arquitectura f\u00edsica y principios de dise\u00f1o se basan en los de los sistemas nerviosos biol\u00f3gicos.", "token2charspan": [[0, 2], [3, 13], [14, 26], [27, 29], [30, 33], [34, 41], [42, 58], [59, 62], [63, 65], [66, 73], [74, 76], [77, 79], [80, 88], [88, 89], [90, 92], [93, 99], [99, 100], [101, 104], [105, 116], [116, 117], [118, 120], [121, 132], [133, 134], [135, 137], [138, 148], [149, 160], [161, 165], [166, 173], [174, 182], [183, 193], [194, 206], [206, 207], [208, 212], [213, 221], [222, 224], [225, 231], [231, 232], [233, 241], [242, 252], [252, 253], [254, 266], [267, 276], [277, 278], [279, 285], [286, 295], [295, 296], [297, 301], [302, 314], [315, 321], [322, 323], [324, 334], [335, 337], [338, 344], [345, 347], [348, 353], [354, 356], [357, 360], [361, 363], [364, 367], [368, 376], [377, 386], [387, 397], [397, 398]]}
{"doc_key": "ai-test-145", "ner": [[4, 7, "metrics"], [11, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 11, 4, 7, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["En", "concreto", ",", "el", "criterio", "de", "estabilidad", "BIBO", "exige", "que", "el", "ROC", "del", "sistema", "incluya", "el", "c\u00edrculo", "unitario", "."], "sentence-detokenized": "En concreto, el criterio de estabilidad BIBO exige que el ROC del sistema incluya el c\u00edrculo unitario.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 15], [16, 24], [25, 27], [28, 39], [40, 44], [45, 50], [51, 54], [55, 57], [58, 61], [62, 65], [66, 73], [74, 81], [82, 84], [85, 92], [93, 101], [101, 102]]}
{"doc_key": "ai-test-146", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2", "El", "programa", "se", "reescribi\u00f3", "en", "Java", "a", "partir", "de", "1998", "."], "sentence-detokenized": "2 El programa se reescribi\u00f3 en Java a partir de 1998.", "token2charspan": [[0, 1], [2, 4], [5, 13], [14, 16], [17, 27], [28, 30], [31, 35], [36, 37], [38, 44], [45, 47], [48, 52], [52, 53]]}
{"doc_key": "ai-test-147", "ner": [[1, 1, "metrics"], [9, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 1, 9, 11, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["El", "MCC", "puede", "calcularse", "directamente", "a", "partir", "de", "la", "matriz", "de", "confusi\u00f3n", "mediante", "la", "f\u00f3rmula", ":"], "sentence-detokenized": "El MCC puede calcularse directamente a partir de la matriz de confusi\u00f3n mediante la f\u00f3rmula:", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 23], [24, 36], [37, 38], [39, 45], [46, 48], [49, 51], [52, 58], [59, 61], [62, 71], [72, 80], [81, 83], [84, 91], [91, 92]]}
{"doc_key": "ai-test-148", "ner": [[6, 9, "organisation"], [17, 25, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 9, 17, 25, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Fue", "desarrollado", "por", "un", "equipo", "del", "MIT-IBM", "Watson", "AI", "Lab", "y", "presentado", "por", "primera", "vez", "en", "la", "Conferencia", "Internacional", "de", "2018", "sobre", "el", "Aprendizaje", "de", "Representaciones", "."], "sentence-detokenized": "Fue desarrollado por un equipo del MIT-IBM Watson AI Lab y presentado por primera vez en la Conferencia Internacional de 2018 sobre el Aprendizaje de Representaciones.", "token2charspan": [[0, 3], [4, 16], [17, 20], [21, 23], [24, 30], [31, 34], [35, 42], [43, 49], [50, 52], [53, 56], [57, 58], [59, 69], [70, 73], [74, 81], [82, 85], [86, 88], [89, 91], [92, 103], [104, 117], [118, 120], [121, 125], [126, 131], [132, 134], [135, 146], [147, 149], [150, 166], [166, 167]]}
{"doc_key": "ai-test-149", "ner": [[2, 3, "metrics"], [17, 23, "metrics"], [21, 22, "metrics"], [53, 53, "metrics"], [55, 55, "metrics"], [62, 65, "metrics"], [69, 69, "metrics"], [72, 72, "metrics"], [20, 76, "metrics"], [82, 82, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[17, 23, 53, 53, "type-of", "", false, false], [17, 23, 62, 65, "related-to", "collapses_to_identity", false, false], [21, 22, 55, 55, "type-of", "", false, false], [21, 22, 62, 65, "related-to", "collapses_to_identity", false, false], [21, 22, 20, 76, "named", "same", false, false], [69, 69, 82, 82, "related-to", "collapses_to_identity", false, false], [72, 72, 82, 82, "related-to", "collapses_to_identity", false, false], [20, 76, 82, 82, "related-to", "collapses_to_identity", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Cuando", "las", "prevalencias", "VERDADERAS", "de", "las", "dos", "variables", "positivas", "son", "iguales", ",", "como", "se", "supone", "en", "el", "kappa", "y", "la", "puntuaci\u00f3n", "F", "de", "Fleiss", ",", "es", "decir", ",", "el", "n\u00famero", "de", "predicciones", "positivas", "coincide", "con", "el", "n\u00famero", "de", "clases", "positivas", "en", "el", "caso", "dicot\u00f3mico", "(", "dos", "clases", ")", ",", "las", "diferentes", "medidas", "de", "kappa", "y", "correlaci\u00f3n", "se", "colapsan", "hasta", "la", "identidad", "con", "la", "J", "de", "Youden", ",", "y", "el", "recuerdo", ",", "la", "precisi\u00f3n", "y", "la", "puntuaci\u00f3n", "F", "son", "igualmente", "id\u00e9nticos", "con", "la", "exactitud", "."], "sentence-detokenized": "Cuando las prevalencias VERDADERAS de las dos variables positivas son iguales, como se supone en el kappa y la puntuaci\u00f3n F de Fleiss, es decir, el n\u00famero de predicciones positivas coincide con el n\u00famero de clases positivas en el caso dicot\u00f3mico (dos clases), las diferentes medidas de kappa y correlaci\u00f3n se colapsan hasta la identidad con la J de Youden, y el recuerdo, la precisi\u00f3n y la puntuaci\u00f3n F son igualmente id\u00e9nticos con la exactitud.", "token2charspan": [[0, 6], [7, 10], [11, 23], [24, 34], [35, 37], [38, 41], [42, 45], [46, 55], [56, 65], [66, 69], [70, 77], [77, 78], [79, 83], [84, 86], [87, 93], [94, 96], [97, 99], [100, 105], [106, 107], [108, 110], [111, 121], [122, 123], [124, 126], [127, 133], [133, 134], [135, 137], [138, 143], [143, 144], [145, 147], [148, 154], [155, 157], [158, 170], [171, 180], [181, 189], [190, 193], [194, 196], [197, 203], [204, 206], [207, 213], [214, 223], [224, 226], [227, 229], [230, 234], [235, 245], [246, 247], [247, 250], [251, 257], [257, 258], [258, 259], [260, 263], [264, 274], [275, 282], [283, 285], [286, 291], [292, 293], [294, 305], [306, 308], [309, 317], [318, 323], [324, 326], [327, 336], [337, 340], [341, 343], [344, 345], [346, 348], [349, 355], [355, 356], [357, 358], [359, 361], [362, 370], [370, 371], [372, 374], [375, 384], [385, 386], [387, 389], [390, 400], [401, 402], [403, 406], [407, 417], [418, 427], [428, 431], [432, 434], [435, 444], [444, 445]]}
{"doc_key": "ai-test-150", "ner": [[1, 4, "misc"], [6, 6, "misc"], [9, 10, "conference"], [14, 19, "task"], [20, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 4, 9, 10, "part-of", "", false, false], [1, 4, 9, 10, "physical", "", false, false], [1, 4, 9, 10, "temporal", "", false, false], [6, 6, 1, 4, "named", "", false, false], [14, 19, 1, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["El", "taller", "Building", "Educational", "Applications", "(", "BEA", ")", "de", "la", "NAACL", "2013", "acogi\u00f3", "la", "tarea", "compartida", "inaugural", "de", "NLI", ".", "Tetreault", "et", "al", ",", "2013", "El", "concurso", "dio", "lugar", "a", "29", "entradas", "de", "equipos", "de", "todo", "el", "mundo", ",", "24", "de", "los", "cuales", "tambi\u00e9n", "publicaron", "un", "art\u00edculo", "que", "describ\u00eda", "sus", "sistemas", "y", "enfoques", "."], "sentence-detokenized": "El taller Building Educational Applications (BEA) de la NAACL 2013 acogi\u00f3 la tarea compartida inaugural de NLI. Tetreault et al, 2013 El concurso dio lugar a 29 entradas de equipos de todo el mundo, 24 de los cuales tambi\u00e9n publicaron un art\u00edculo que describ\u00eda sus sistemas y enfoques.", "token2charspan": [[0, 2], [3, 9], [10, 18], [19, 30], [31, 43], [44, 45], [45, 48], [48, 49], [50, 52], [53, 55], [56, 61], [62, 66], [67, 73], [74, 76], [77, 82], [83, 93], [94, 103], [104, 106], [107, 110], [110, 111], [112, 121], [122, 124], [125, 127], [127, 128], [129, 133], [134, 136], [137, 145], [146, 149], [150, 155], [156, 157], [158, 160], [161, 169], [170, 172], [173, 180], [181, 183], [184, 188], [189, 191], [192, 197], [197, 198], [199, 201], [202, 204], [205, 208], [209, 215], [216, 223], [224, 234], [235, 237], [238, 246], [247, 250], [251, 260], [261, 264], [265, 273], [274, 275], [276, 284], [284, 285]]}
{"doc_key": "ai-test-151", "ner": [[0, 3, "algorithm"], [6, 9, "algorithm"], [17, 18, "misc"], [21, 23, "misc"], [42, 45, "misc"], [49, 51, "algorithm"], [53, 53, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 6, 9, "type-of", "", false, false], [0, 3, 17, 18, "related-to", "finds", false, false], [21, 23, 17, 18, "type-of", "", false, false], [53, 53, 49, 51, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["El", "algoritmo", "de", "Viterbi", "es", "un", "algoritmo", "de", "programaci\u00f3n", "din\u00e1mica", "para", "encontrar", "la", "secuencia", "m\u00e1s", "probable", "de", "estados", "ocultos", ",", "llamada", "camino", "de", "Viterbi", ",", "que", "da", "lugar", "a", "una", "secuencia", "de", "eventos", "observados", ",", "especialmente", "en", "el", "contexto", "de", "las", "fuentes", "de", "informaci\u00f3n", "de", "Markov", "y", "los", "modelos", "de", "Markov", "ocultos", "(", "HMM", ")", "."], "sentence-detokenized": "El algoritmo de Viterbi es un algoritmo de programaci\u00f3n din\u00e1mica para encontrar la secuencia m\u00e1s probable de estados ocultos, llamada camino de Viterbi, que da lugar a una secuencia de eventos observados, especialmente en el contexto de las fuentes de informaci\u00f3n de Markov y los modelos de Markov ocultos (HMM).", "token2charspan": [[0, 2], [3, 12], [13, 15], [16, 23], [24, 26], [27, 29], [30, 39], [40, 42], [43, 55], [56, 64], [65, 69], [70, 79], [80, 82], [83, 92], [93, 96], [97, 105], [106, 108], [109, 116], [117, 124], [124, 125], [126, 133], [134, 140], [141, 143], [144, 151], [151, 152], [153, 156], [157, 159], [160, 165], [166, 167], [168, 171], [172, 181], [182, 184], [185, 192], [193, 203], [203, 204], [205, 218], [219, 221], [222, 224], [225, 233], [234, 236], [237, 240], [241, 248], [249, 251], [252, 263], [264, 266], [267, 273], [274, 275], [276, 279], [280, 287], [288, 290], [291, 297], [298, 305], [306, 307], [307, 310], [310, 311], [311, 312]]}
{"doc_key": "ai-test-152", "ner": [[1, 1, "field"], [3, 6, "algorithm"], [9, 11, "misc"], [15, 16, "algorithm"], [19, 20, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 6, 1, 1, "part-of", "", false, false], [3, 6, 9, 11, "general-affiliation", "", false, false], [3, 6, 15, 16, "related-to", "generalizes_from", false, false], [3, 6, 19, 20, "related-to", "generalizes_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["En", "estad\u00edstica", ",", "la", "regresi\u00f3n", "log\u00edstica", "multinomial", "es", "un", "m\u00e9todo", "de", "clasificaci\u00f3n", "que", "generaliza", "la", "regresi\u00f3n", "log\u00edstica", "a", "la", "clasificaci\u00f3n", "multiclase", ",", "es", "decir", ",", "con", "m\u00e1s", "de", "dos", "posibles", "resultados", "discretos", "."], "sentence-detokenized": "En estad\u00edstica, la regresi\u00f3n log\u00edstica multinomial es un m\u00e9todo de clasificaci\u00f3n que generaliza la regresi\u00f3n log\u00edstica a la clasificaci\u00f3n multiclase, es decir, con m\u00e1s de dos posibles resultados discretos.", "token2charspan": [[0, 2], [3, 14], [14, 15], [16, 18], [19, 28], [29, 38], [39, 50], [51, 53], [54, 56], [57, 63], [64, 66], [67, 80], [81, 84], [85, 95], [96, 98], [99, 108], [109, 118], [119, 120], [121, 123], [124, 137], [138, 148], [148, 149], [150, 152], [153, 158], [158, 159], [160, 163], [164, 167], [168, 170], [171, 174], [175, 183], [184, 194], [195, 204], [204, 205]]}
{"doc_key": "ai-test-153", "ner": [[0, 4, "algorithm"], [11, 13, "field"], [16, 19, "field"], [22, 22, "task"], [25, 30, "task"], [33, 35, "task"], [37, 38, "researcher"], [40, 41, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 4, 11, 13, "part-of", "", false, false], [0, 4, 16, 19, "part-of", "", false, false], [22, 22, 0, 4, "usage", "", true, false], [25, 30, 0, 4, "usage", "", true, false], [33, 35, 0, 4, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Los", "modelos", "ocultos", "de", "Markov", "son", "conocidos", "por", "sus", "aplicaciones", "al", "aprendizaje", "por", "refuerzo", "y", "al", "reconocimiento", "de", "patrones", "temporales", "como", "el", "habla", ",", "el", "reconocimiento", "de", "la", "escritura", "a", "mano", ",", "el", "reconocimiento", "de", "gestos", ",", "Thad", "Starner", ",", "Alex", "Pentland", "."], "sentence-detokenized": "Los modelos ocultos de Markov son conocidos por sus aplicaciones al aprendizaje por refuerzo y al reconocimiento de patrones temporales como el habla, el reconocimiento de la escritura a mano, el reconocimiento de gestos, Thad Starner, Alex Pentland.", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 22], [23, 29], [30, 33], [34, 43], [44, 47], [48, 51], [52, 64], [65, 67], [68, 79], [80, 83], [84, 92], [93, 94], [95, 97], [98, 112], [113, 115], [116, 124], [125, 135], [136, 140], [141, 143], [144, 149], [149, 150], [151, 153], [154, 168], [169, 171], [172, 174], [175, 184], [185, 186], [187, 191], [191, 192], [193, 195], [196, 210], [211, 213], [214, 220], [220, 221], [222, 226], [227, 234], [234, 235], [236, 240], [241, 249], [249, 250]]}
{"doc_key": "ai-test-154", "ner": [[6, 9, "misc"], [32, 35, "metrics"], [38, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 9, 38, 38, "named", "", false, false], [32, 35, 38, 38, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Esencialmente", ",", "esto", "significa", "que", "si", "el", "programa", "se", "ha", "visto", "m\u00e1s", "de", "k", "veces", "en", "el", "entrenamiento", ",", "la", "probabilidad", "condicional", "de", "una", "palabra", "dada", "su", "historia", "es", "proporcional", "a", "la", "estimaci\u00f3n", "de", "m\u00e1xima", "probabilidad", "de", "ese", "programa", "."], "sentence-detokenized": "Esencialmente, esto significa que si el programa se ha visto m\u00e1s de k veces en el entrenamiento, la probabilidad condicional de una palabra dada su historia es proporcional a la estimaci\u00f3n de m\u00e1xima probabilidad de ese programa.", "token2charspan": [[0, 13], [13, 14], [15, 19], [20, 29], [30, 33], [34, 36], [37, 39], [40, 48], [49, 51], [52, 54], [55, 60], [61, 64], [65, 67], [68, 69], [70, 75], [76, 78], [79, 81], [82, 95], [95, 96], [97, 99], [100, 112], [113, 124], [125, 127], [128, 131], [132, 139], [140, 144], [145, 147], [148, 156], [157, 159], [160, 172], [173, 174], [175, 177], [178, 188], [189, 191], [192, 198], [199, 211], [212, 214], [215, 218], [219, 227], [227, 228]]}
{"doc_key": "ai-test-155", "ner": [[4, 6, "task"], [9, 12, "task"], [15, 18, "task"], [24, 27, "task"], [35, 36, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[35, 36, 24, 27, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Est\u00e1", "interesado", "en", "la", "representaci\u00f3n", "del", "conocimiento", ",", "el", "razonamiento", "de", "sentido", "com\u00fan", "y", "la", "comprensi\u00f3n", "del", "lenguaje", "natural", ",", "y", "cree", "que", "la", "comprensi\u00f3n", "profunda", "del", "lenguaje", "s\u00f3lo", "puede", "lograrse", "actualmente", "mediante", "una", "importante", "ingenier\u00eda", "manual", "de", "formalismos", "ricos", "en", "sem\u00e1ntica", ",", "junto", "con", "preferencias", "estad\u00edsticas", "."], "sentence-detokenized": "Est\u00e1 interesado en la representaci\u00f3n del conocimiento, el razonamiento de sentido com\u00fan y la comprensi\u00f3n del lenguaje natural, y cree que la comprensi\u00f3n profunda del lenguaje s\u00f3lo puede lograrse actualmente mediante una importante ingenier\u00eda manual de formalismos ricos en sem\u00e1ntica, junto con preferencias estad\u00edsticas.", "token2charspan": [[0, 4], [5, 15], [16, 18], [19, 21], [22, 36], [37, 40], [41, 53], [53, 54], [55, 57], [58, 70], [71, 73], [74, 81], [82, 87], [88, 89], [90, 92], [93, 104], [105, 108], [109, 117], [118, 125], [125, 126], [127, 128], [129, 133], [134, 137], [138, 140], [141, 152], [153, 161], [162, 165], [166, 174], [175, 179], [180, 185], [186, 194], [195, 206], [207, 215], [216, 219], [220, 230], [231, 241], [242, 248], [249, 251], [252, 263], [264, 269], [270, 272], [273, 282], [282, 283], [284, 289], [290, 293], [294, 306], [307, 319], [319, 320]]}
{"doc_key": "ai-test-156", "ner": [[1, 1, "programlang"], [3, 3, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["En", "JavaScript", ",", "Python", "o"], "sentence-detokenized": "En JavaScript, Python o", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 21], [22, 23]]}
{"doc_key": "ai-test-157", "ner": [[1, 2, "misc"], [7, 9, "misc"], [12, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 7, 9, "part-of", "", false, false], [7, 9, 12, 13, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Los", "premios", "Newcomb", "se", "anuncian", "en", "la", "revista", "AI", "Magazine", "publicada", "por", "la", "AAAI", "."], "sentence-detokenized": "Los premios Newcomb se anuncian en la revista AI Magazine publicada por la AAAI.", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 22], [23, 31], [32, 34], [35, 37], [38, 45], [46, 48], [49, 57], [58, 67], [68, 71], [72, 74], [75, 79], [79, 80]]}
{"doc_key": "ai-test-158", "ner": [[1, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["El", "error", "cuadr\u00e1tico", "medio", "en", "un", "conjunto", "de", "prueba", "de", "100", "ejemplares", "es", "de", "0,084", ",", "menor", "que", "el", "error", "no", "normalizado", "."], "sentence-detokenized": "El error cuadr\u00e1tico medio en un conjunto de prueba de 100 ejemplares es de 0,084, menor que el error no normalizado.", "token2charspan": [[0, 2], [3, 8], [9, 19], [20, 25], [26, 28], [29, 31], [32, 40], [41, 43], [44, 50], [51, 53], [54, 57], [58, 68], [69, 71], [72, 74], [75, 80], [80, 81], [82, 87], [88, 91], [92, 94], [95, 100], [101, 103], [104, 115], [115, 116]]}
{"doc_key": "ai-test-159", "ner": [[1, 2, "metrics"], [11, 14, "field"], [20, 24, "task"], [26, 26, "task"], [30, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 14, 1, 2, "usage", "", false, false], [20, 24, 11, 14, "part-of", "task_part_of_field", false, false], [26, 26, 20, 24, "named", "", false, false], [30, 32, 11, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["La", "puntuaci\u00f3n", "F", "se", "ha", "utilizado", "ampliamente", "en", "la", "literatura", "de", "procesamiento", "del", "lenguaje", "natural", ",", "como", "la", "evaluaci\u00f3n", "del", "reconocimiento", "de", "entidades", "con", "nombre", "(", "NER", ")", "y", "la", "segmentaci\u00f3n", "de", "palabras", "."], "sentence-detokenized": "La puntuaci\u00f3n F se ha utilizado ampliamente en la literatura de procesamiento del lenguaje natural, como la evaluaci\u00f3n del reconocimiento de entidades con nombre (NER) y la segmentaci\u00f3n de palabras.", "token2charspan": [[0, 2], [3, 13], [14, 15], [16, 18], [19, 21], [22, 31], [32, 43], [44, 46], [47, 49], [50, 60], [61, 63], [64, 77], [78, 81], [82, 90], [91, 98], [98, 99], [100, 104], [105, 107], [108, 118], [119, 122], [123, 137], [138, 140], [141, 150], [151, 154], [155, 161], [162, 163], [163, 166], [166, 167], [168, 169], [170, 172], [173, 185], [186, 188], [189, 197], [197, 198]]}
{"doc_key": "ai-test-160", "ner": [[0, 1, "product"], [6, 8, "product"], [20, 22, "misc"], [25, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 20, 22, "related-to", "performs_task", false, false], [0, 1, 25, 27, "related-to", "performs_task", false, false], [6, 8, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Los", "chatbots", "se", "utilizan", "normalmente", "en", "sistemas", "de", "di\u00e1logo", "para", "diversos", "fines", ",", "como", "la", "atenci\u00f3n", "al", "cliente", ",", "el", "enrutamiento", "de", "solicitudes", "o", "la", "recopilaci\u00f3n", "de", "informaci\u00f3n", "."], "sentence-detokenized": "Los chatbots se utilizan normalmente en sistemas de di\u00e1logo para diversos fines, como la atenci\u00f3n al cliente, el enrutamiento de solicitudes o la recopilaci\u00f3n de informaci\u00f3n.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 24], [25, 36], [37, 39], [40, 48], [49, 51], [52, 59], [60, 64], [65, 73], [74, 79], [79, 80], [81, 85], [86, 88], [89, 97], [98, 100], [101, 108], [108, 109], [110, 112], [113, 125], [126, 128], [129, 140], [141, 142], [143, 145], [146, 158], [159, 161], [162, 173], [173, 174]]}
{"doc_key": "ai-test-161", "ner": [[7, 13, "conference"], [21, 29, "conference"], [37, 44, "conference"], [51, 52, "conference"], [55, 58, "conference"], [60, 61, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[21, 29, 7, 13, "named", "", false, false], [37, 44, 7, 13, "named", "", false, false], [51, 52, 37, 44, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Entre", "las", "revistas", "m\u00e1s", "importantes", "se", "encuentran", "IEEE", "Transactions", "on", "Speech", "and", "Audio", "Processing", "(", "que", "m\u00e1s", "tarde", "pas\u00f3", "a", "llamarse", "IEEE", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "y", ",", "desde", "septiembre", "de", "2014", ",", "IEEE/ACM", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", ",", "tras", "fusionarse", "con", "una", "publicaci\u00f3n", "de", "ACM", ")", ",", "Computer", "Speech", "and", "Language", "y", "Speech", "Communication", "."], "sentence-detokenized": "Entre las revistas m\u00e1s importantes se encuentran IEEE Transactions on Speech and Audio Processing (que m\u00e1s tarde pas\u00f3 a llamarse IEEE Transactions on Audio, Speech and Language Processing y, desde septiembre de 2014, IEEE/ACM Transactions on Audio, Speech and Language, tras fusionarse con una publicaci\u00f3n de ACM), Computer Speech and Language y Speech Communication.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 22], [23, 34], [35, 37], [38, 48], [49, 53], [54, 66], [67, 69], [70, 76], [77, 80], [81, 86], [87, 97], [98, 99], [99, 102], [103, 106], [107, 112], [113, 117], [118, 119], [120, 128], [129, 133], [134, 146], [147, 149], [150, 155], [155, 156], [157, 163], [164, 167], [168, 176], [177, 187], [188, 189], [189, 190], [191, 196], [197, 207], [208, 210], [211, 215], [215, 216], [217, 225], [226, 238], [239, 241], [242, 247], [247, 248], [249, 255], [256, 259], [260, 268], [268, 269], [270, 274], [275, 285], [286, 289], [290, 293], [294, 305], [306, 308], [309, 312], [312, 313], [313, 314], [315, 323], [324, 330], [331, 334], [335, 343], [344, 345], [346, 352], [353, 366], [366, 367]]}
{"doc_key": "ai-test-162", "ner": [[0, 1, "algorithm"], [8, 10, "task"], [13, 14, "field"], [17, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 10, 0, 1, "usage", "", false, false], [8, 10, 13, 14, "part-of", "task_part_of_field", false, false], [8, 10, 17, 19, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["El", "EM", "se", "utiliza", "con", "frecuencia", "para", "la", "agrupaci\u00f3n", "de", "datos", "en", "el", "aprendizaje", "autom\u00e1tico", "y", "la", "visi\u00f3n", "por", "ordenador", "."], "sentence-detokenized": "El EM se utiliza con frecuencia para la agrupaci\u00f3n de datos en el aprendizaje autom\u00e1tico y la visi\u00f3n por ordenador.", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 16], [17, 20], [21, 31], [32, 36], [37, 39], [40, 50], [51, 53], [54, 59], [60, 62], [63, 65], [66, 77], [78, 88], [89, 90], [91, 93], [94, 100], [101, 104], [105, 114], [114, 115]]}
{"doc_key": "ai-test-163", "ner": [[9, 11, "metrics"], [25, 30, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 25, 30, "related-to", "described_by", false, false]], "relations_mapping_to_source": [0], "sentence": ["Aunque", "no", "existe", "una", "forma", "perfecta", "de", "describir", "la", "matriz", "de", "confusi\u00f3n", "de", "positivos", "y", "negativos", "VERDADEROS", "y", "FALSOS", "con", "un", "solo", "n\u00famero", ",", "el", "coeficiente", "de", "correlaci\u00f3n", "de", "Matthews", "se", "considera", "generalmente", "como", "una", "de", "las", "mejores", "medidas", "de", "este", "tipo", "."], "sentence-detokenized": "Aunque no existe una forma perfecta de describir la matriz de confusi\u00f3n de positivos y negativos VERDADEROS y FALSOS con un solo n\u00famero, el coeficiente de correlaci\u00f3n de Matthews se considera generalmente como una de las mejores medidas de este tipo.", "token2charspan": [[0, 6], [7, 9], [10, 16], [17, 20], [21, 26], [27, 35], [36, 38], [39, 48], [49, 51], [52, 58], [59, 61], [62, 71], [72, 74], [75, 84], [85, 86], [87, 96], [97, 107], [108, 109], [110, 116], [117, 120], [121, 123], [124, 128], [129, 135], [135, 136], [137, 139], [140, 151], [152, 154], [155, 166], [167, 169], [170, 178], [179, 181], [182, 191], [192, 204], [205, 209], [210, 213], [214, 216], [217, 220], [221, 228], [229, 236], [237, 239], [240, 244], [245, 249], [249, 250]]}
{"doc_key": "ai-test-164", "ner": [[15, 17, "field"], [40, 40, "field"], [47, 48, "field"], [52, 53, "algorithm"], [56, 58, "task"], [60, 62, "algorithm"], [68, 73, "algorithm"], [76, 78, "algorithm"], [85, 90, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[47, 48, 40, 40, "part-of", "subfield", false, false], [52, 53, 47, 48, "part-of", "", false, true], [56, 58, 47, 48, "part-of", "", false, true], [60, 62, 47, 48, "part-of", "", false, true], [68, 73, 47, 48, "part-of", "", false, true], [76, 78, 47, 48, "part-of", "", false, true], [85, 90, 47, 48, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["A", "medida", "que", "los", "conjuntos", "de", "datos", "han", "crecido", "en", "tama\u00f1o", "y", "complejidad", ",", "el", "an\u00e1lisis", "de", "datos", "directo", "y", "pr\u00e1ctico", "se", "ha", "visto", "incrementado", "con", "el", "procesamiento", "de", "datos", "indirecto", "y", "automatizado", ",", "ayudado", "por", "otros", "descubrimientos", "de", "la", "inform\u00e1tica", ",", "especialmente", "en", "el", "campo", "del", "aprendizaje", "autom\u00e1tico", ",", "como", "las", "redes", "neuronales", ",", "el", "an\u00e1lisis", "de", "conglomerados", ",", "los", "algoritmos", "gen\u00e9ticos", "(", "a\u00f1os", "50", ")", ",", "el", "aprendizaje", "de", "\u00e1rboles", "de", "decisi\u00f3n", "y", "las", "reglas", "de", "decisi\u00f3n", "(", "a\u00f1os", "60", ")", ",", "y", "las", "m\u00e1quinas", "de", "vectores", "de", "apoyo", "(", "a\u00f1os", "90", ")", "."], "sentence-detokenized": "A medida que los conjuntos de datos han crecido en tama\u00f1o y complejidad, el an\u00e1lisis de datos directo y pr\u00e1ctico se ha visto incrementado con el procesamiento de datos indirecto y automatizado, ayudado por otros descubrimientos de la inform\u00e1tica, especialmente en el campo del aprendizaje autom\u00e1tico, como las redes neuronales, el an\u00e1lisis de conglomerados, los algoritmos gen\u00e9ticos (a\u00f1os 50), el aprendizaje de \u00e1rboles de decisi\u00f3n y las reglas de decisi\u00f3n (a\u00f1os 60), y las m\u00e1quinas de vectores de apoyo (a\u00f1os 90).", "token2charspan": [[0, 1], [2, 8], [9, 12], [13, 16], [17, 26], [27, 29], [30, 35], [36, 39], [40, 47], [48, 50], [51, 57], [58, 59], [60, 71], [71, 72], [73, 75], [76, 84], [85, 87], [88, 93], [94, 101], [102, 103], [104, 112], [113, 115], [116, 118], [119, 124], [125, 137], [138, 141], [142, 144], [145, 158], [159, 161], [162, 167], [168, 177], [178, 179], [180, 192], [192, 193], [194, 201], [202, 205], [206, 211], [212, 227], [228, 230], [231, 233], [234, 245], [245, 246], [247, 260], [261, 263], [264, 266], [267, 272], [273, 276], [277, 288], [289, 299], [299, 300], [301, 305], [306, 309], [310, 315], [316, 326], [326, 327], [328, 330], [331, 339], [340, 342], [343, 356], [356, 357], [358, 361], [362, 372], [373, 382], [383, 384], [384, 388], [389, 391], [391, 392], [392, 393], [394, 396], [397, 408], [409, 411], [412, 419], [420, 422], [423, 431], [432, 433], [434, 437], [438, 444], [445, 447], [448, 456], [457, 458], [458, 462], [463, 465], [465, 466], [466, 467], [468, 469], [470, 473], [474, 482], [483, 485], [486, 494], [495, 497], [498, 503], [504, 505], [505, 509], [510, 512], [512, 513], [513, 514]]}
{"doc_key": "ai-test-165", "ner": [[5, 5, "researcher"], [12, 16, "misc"], [25, 27, "researcher"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 16, 5, 5, "artifact", "", false, false], [12, 16, 25, 27, "artifact", "", false, false], [12, 16, 29, 30, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["En", "oto\u00f1o", "de", "2005", ",", "Thrun", "public\u00f3", "un", "libro", "de", "texto", "titulado", "Probabilistic", "Robotics", "(", "Rob\u00f3tica", "probabil\u00edstica", ")", "junto", "con", "sus", "colaboradores", "de", "muchos", "a\u00f1os", ",", "Dieter", "Fox", "y", "Wolfram", "Burgard", "."], "sentence-detokenized": "En oto\u00f1o de 2005, Thrun public\u00f3 un libro de texto titulado Probabilistic Robotics (Rob\u00f3tica probabil\u00edstica) junto con sus colaboradores de muchos a\u00f1os, Dieter Fox y Wolfram Burgard.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 16], [16, 17], [18, 23], [24, 31], [32, 34], [35, 40], [41, 43], [44, 49], [50, 58], [59, 72], [73, 81], [82, 83], [83, 91], [92, 106], [106, 107], [108, 113], [114, 117], [118, 121], [122, 135], [136, 138], [139, 145], [146, 150], [150, 151], [152, 158], [159, 162], [163, 164], [165, 172], [173, 180], [180, 181]]}
{"doc_key": "ai-test-166", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 7, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["John", "D.", "Lafferty", ",", "Andrew", "McCallum", "y", "Pereiramath", "como", "sigue", ":"], "sentence-detokenized": "John D. Lafferty, Andrew McCallum y Pereiramath como sigue:", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 24], [25, 33], [34, 35], [36, 47], [48, 52], [53, 58], [58, 59]]}
{"doc_key": "ai-test-167", "ner": [[0, 3, "task"], [5, 5, "task"], [17, 19, "field"], [22, 25, "field"], [27, 27, "field"]], "ner_mapping_to_source": [0, 1, 3, 4, 5], "relations": [[0, 3, 17, 19, "part-of", "task_part_of_field", false, false], [0, 3, 22, 25, "part-of", "task_part_of_field", false, false], [5, 5, 0, 3, "named", "", false, false], [27, 27, 22, 25, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 5], "sentence": ["La", "respuesta", "a", "preguntas", "(", "QA", ")", "es", "una", "disciplina", "inform\u00e1tica", "dentro", "de", "los", "campos", "de", "la", "recuperaci\u00f3n", "de", "informaci\u00f3n", "y", "el", "procesamiento", "del", "lenguaje", "natural", "(", "NLP", ")", ",", "que", "se", "ocupa", "de", "construir", "sistemas", "que", "respondan", "autom\u00e1ticamente", "a", "las", "preguntas", "planteadas", "por", "los", "humanos", "en", "un", "lenguaje", "natural", "."], "sentence-detokenized": "La respuesta a preguntas (QA) es una disciplina inform\u00e1tica dentro de los campos de la recuperaci\u00f3n de informaci\u00f3n y el procesamiento del lenguaje natural (NLP), que se ocupa de construir sistemas que respondan autom\u00e1ticamente a las preguntas planteadas por los humanos en un lenguaje natural.", "token2charspan": [[0, 2], [3, 12], [13, 14], [15, 24], [25, 26], [26, 28], [28, 29], [30, 32], [33, 36], [37, 47], [48, 59], [60, 66], [67, 69], [70, 73], [74, 80], [81, 83], [84, 86], [87, 99], [100, 102], [103, 114], [115, 116], [117, 119], [120, 133], [134, 137], [138, 146], [147, 154], [155, 156], [156, 159], [159, 160], [160, 161], [162, 165], [166, 168], [169, 174], [175, 177], [178, 187], [188, 196], [197, 200], [201, 210], [211, 226], [227, 228], [229, 232], [233, 242], [243, 253], [254, 257], [258, 261], [262, 269], [270, 272], [273, 275], [276, 284], [285, 292], [292, 293]]}
{"doc_key": "ai-test-168", "ner": [[13, 14, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sin", "embargo", ",", "en", "la", "versi\u00f3n", "de", "la", "m\u00e9trica", "utilizada", "por", "las", "evaluaciones", "del", "NIST", "antes", "de", "2009", ",", "se", "utilizaba", "la", "frase", "de", "referencia", "m\u00e1s", "corta", "."], "sentence-detokenized": "Sin embargo, en la versi\u00f3n de la m\u00e9trica utilizada por las evaluaciones del NIST antes de 2009, se utilizaba la frase de referencia m\u00e1s corta.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 18], [19, 26], [27, 29], [30, 32], [33, 40], [41, 50], [51, 54], [55, 58], [59, 71], [72, 75], [76, 80], [81, 86], [87, 89], [90, 94], [94, 95], [96, 98], [99, 108], [109, 111], [112, 117], [118, 120], [121, 131], [132, 135], [136, 141], [141, 142]]}
{"doc_key": "ai-test-169", "ner": [[7, 7, "person"], [21, 21, "organisation"], [18, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 18, 20, "related-to", "invests_in", false, false], [18, 20, 21, 21, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["El", "27", "de", "agosto", "de", "2018", ",", "Toyota", "anunci\u00f3", "una", "inversi\u00f3n", "de", "500", "millones", "de", "d\u00f3lares", "en", "los", "coches", "aut\u00f3nomos", "de", "Uber", "."], "sentence-detokenized": "El 27 de agosto de 2018, Toyota anunci\u00f3 una inversi\u00f3n de 500 millones de d\u00f3lares en los coches aut\u00f3nomos de Uber.", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 15], [16, 18], [19, 23], [23, 24], [25, 31], [32, 39], [40, 43], [44, 53], [54, 56], [57, 60], [61, 69], [70, 72], [73, 80], [81, 83], [84, 87], [88, 94], [95, 104], [105, 107], [108, 112], [112, 113]]}
{"doc_key": "ai-test-170", "ner": [[7, 10, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["El", "m\u00e1ximo", "de", "la", "muestra", "es", "el", "estimador", "de", "m\u00e1xima", "verosimilitud", "para", "el", "m\u00e1ximo", "de", "la", "poblaci\u00f3n", ",", "pero", ",", "como", "se", "ha", "comentado", "anteriormente", ",", "est\u00e1", "sesgado", "."], "sentence-detokenized": "El m\u00e1ximo de la muestra es el estimador de m\u00e1xima verosimilitud para el m\u00e1ximo de la poblaci\u00f3n, pero, como se ha comentado anteriormente, est\u00e1 sesgado.", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 15], [16, 23], [24, 26], [27, 29], [30, 39], [40, 42], [43, 49], [50, 63], [64, 68], [69, 71], [72, 78], [79, 81], [82, 84], [85, 94], [94, 95], [96, 100], [100, 101], [102, 106], [107, 109], [110, 112], [113, 122], [123, 136], [136, 137], [138, 142], [143, 150], [150, 151]]}
{"doc_key": "ai-test-171", "ner": [[0, 0, "task"], [4, 5, "misc"], [8, 8, "metrics"], [18, 22, "algorithm"], [25, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 4, 5, "related-to", "overcomes", false, false], [0, 0, 8, 8, "related-to", "increases", false, false], [4, 5, 18, 22, "opposite", "", false, false], [4, 5, 25, 28, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LSI", "ayuda", "a", "superar", "la", "sinonimia", "aumentando", "el", "recuerdo", ",", "una", "de", "las", "limitaciones", "m\u00e1s", "problem\u00e1ticas", "de", "las", "consultas", "de", "palabras", "clave", "booleanas", "y", "los", "modelos", "de", "espacio", "vectorial", "."], "sentence-detokenized": "LSI ayuda a superar la sinonimia aumentando el recuerdo, una de las limitaciones m\u00e1s problem\u00e1ticas de las consultas de palabras clave booleanas y los modelos de espacio vectorial.", "token2charspan": [[0, 3], [4, 9], [10, 11], [12, 19], [20, 22], [23, 32], [33, 43], [44, 46], [47, 55], [55, 56], [57, 60], [61, 63], [64, 67], [68, 80], [81, 84], [85, 98], [99, 101], [102, 105], [106, 115], [116, 118], [119, 127], [128, 133], [134, 143], [144, 145], [146, 149], [150, 157], [158, 160], [161, 168], [169, 178], [178, 179]]}
{"doc_key": "ai-test-172", "ner": [[3, 5, "task"], [24, 24, "programlang"], [26, 26, "programlang"], [28, 28, "programlang"], [30, 30, "programlang"], [32, 33, "programlang"], [35, 35, "programlang"], [37, 37, "programlang"], [39, 39, "programlang"], [41, 41, "programlang"], [43, 43, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[3, 5, 24, 24, "general-affiliation", "", false, false], [3, 5, 26, 26, "general-affiliation", "", false, false], [3, 5, 28, 28, "general-affiliation", "", false, false], [3, 5, 30, 30, "general-affiliation", "", false, false], [3, 5, 32, 33, "general-affiliation", "", false, false], [3, 5, 35, 35, "general-affiliation", "", false, false], [3, 5, 37, 37, "general-affiliation", "", false, false], [3, 5, 39, 39, "general-affiliation", "", false, false], [3, 5, 41, 41, "general-affiliation", "", false, false], [3, 5, 43, 43, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Las", "aplicaciones", "de", "adquisici\u00f3n", "de", "datos", "suelen", "estar", "controladas", "por", "programas", "de", "software", "desarrollados", "con", "diversos", "lenguajes", "de", "programaci\u00f3n", "de", "prop\u00f3sito", "general", ",", "como", "Assembly", ",", "BASIC", ",", "C", ",", "C+", ",", "C", "#", ",", "Fortran", ",", "Java", ",", "LabVIEW", ",", "Lisp", ",", "Pascal", ",", "etc", "."], "sentence-detokenized": "Las aplicaciones de adquisici\u00f3n de datos suelen estar controladas por programas de software desarrollados con diversos lenguajes de programaci\u00f3n de prop\u00f3sito general, como Assembly, BASIC, C, C+, C#, Fortran, Java, LabVIEW, Lisp, Pascal, etc.", "token2charspan": [[0, 3], [4, 16], [17, 19], [20, 31], [32, 34], [35, 40], [41, 47], [48, 53], [54, 65], [66, 69], [70, 79], [80, 82], [83, 91], [92, 105], [106, 109], [110, 118], [119, 128], [129, 131], [132, 144], [145, 147], [148, 157], [158, 165], [165, 166], [167, 171], [172, 180], [180, 181], [182, 187], [187, 188], [189, 190], [190, 191], [192, 194], [194, 195], [196, 197], [197, 198], [198, 199], [200, 207], [207, 208], [209, 213], [213, 214], [215, 222], [222, 223], [224, 228], [228, 229], [230, 236], [236, 237], [238, 241], [241, 242]]}
{"doc_key": "ai-test-173", "ner": [[3, 3, "organisation"], [7, 7, "product"], [10, 11, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 3, 3, "artifact", "", false, false], [7, 7, 10, 11, "physical", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["En", "2003", ",", "Honda", "lanz\u00f3", "su", "anuncio", "Cog", "en", "el", "Reino", "Unido", "y", "en", "Internet", "."], "sentence-detokenized": "En 2003, Honda lanz\u00f3 su anuncio Cog en el Reino Unido y en Internet.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 20], [21, 23], [24, 31], [32, 35], [36, 38], [39, 41], [42, 47], [48, 53], [54, 55], [56, 58], [59, 67], [67, 68]]}
{"doc_key": "ai-test-174", "ner": [[1, 4, "conference"], [7, 8, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 4, 7, 8, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["La", "Asociaci\u00f3n", "de", "Ling\u00fc\u00edstica", "Computacional", "define", "la", "ling\u00fc\u00edstica", "computacional", "como", ":"], "sentence-detokenized": "La Asociaci\u00f3n de Ling\u00fc\u00edstica Computacional define la ling\u00fc\u00edstica computacional como:", "token2charspan": [[0, 2], [3, 13], [14, 16], [17, 28], [29, 42], [43, 49], [50, 52], [53, 64], [65, 78], [79, 83], [83, 84]]}
{"doc_key": "ai-test-175", "ner": [[0, 5, "algorithm"], [11, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 5, 11, 15, "related-to", "calculates", false, false]], "relations_mapping_to_source": [0], "sentence": ["Los", "algoritmos", "de", "maximizaci\u00f3n", "de", "expectativas", "pueden", "emplearse", "para", "calcular", "las", "estimaciones", "aproximadas", "de", "m\u00e1xima", "verosimilitud", "de", "los", "par\u00e1metros", "desconocidos", "del", "espacio", "de", "estado", "dentro", "de", "los", "filtros", "y", "suavizadores", "de", "m\u00ednima", "varianza", "."], "sentence-detokenized": "Los algoritmos de maximizaci\u00f3n de expectativas pueden emplearse para calcular las estimaciones aproximadas de m\u00e1xima verosimilitud de los par\u00e1metros desconocidos del espacio de estado dentro de los filtros y suavizadores de m\u00ednima varianza.", "token2charspan": [[0, 3], [4, 14], [15, 17], [18, 30], [31, 33], [34, 46], [47, 53], [54, 63], [64, 68], [69, 77], [78, 81], [82, 94], [95, 106], [107, 109], [110, 116], [117, 130], [131, 133], [134, 137], [138, 148], [149, 161], [162, 165], [166, 173], [174, 176], [177, 183], [184, 190], [191, 193], [194, 197], [198, 205], [206, 207], [208, 220], [221, 223], [224, 230], [231, 239], [239, 240]]}
{"doc_key": "ai-test-176", "ner": [[9, 9, "misc"], [10, 11, "person"], [13, 14, "person"], [16, 17, "person"], [21, 22, "misc"], [19, 24, "person"], [28, 29, "person"], [34, 34, "person"], [36, 37, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[10, 11, 9, 9, "role", "actor_in", false, false], [13, 14, 9, 9, "role", "actor_in", false, false], [16, 17, 9, 9, "role", "actor_in", false, false], [19, 24, 21, 22, "role", "model_for", false, false], [34, 34, 36, 37, "social", "family", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Entre", "los", "corresponsales", "se", "encontraban", "las", "ex", "actrices", "de", "Baywatch", "Donna", "D'Errico", ",", "Carmen", "Electra", "y", "Traci", "Bingham", ",", "la", "ex", "Playboy", "Playmate", "Heidi", "Mark", ",", "el", "c\u00f3mico", "Arj", "Barker", "y", "los", "gemelos", "id\u00e9nticos", "Randy", "y", "Jason", "Sklar", "."], "sentence-detokenized": "Entre los corresponsales se encontraban las ex actrices de Baywatch Donna D'Errico, Carmen Electra y Traci Bingham, la ex Playboy Playmate Heidi Mark, el c\u00f3mico Arj Barker y los gemelos id\u00e9nticos Randy y Jason Sklar.", "token2charspan": [[0, 5], [6, 9], [10, 24], [25, 27], [28, 39], [40, 43], [44, 46], [47, 55], [56, 58], [59, 67], [68, 73], [74, 82], [82, 83], [84, 90], [91, 98], [99, 100], [101, 106], [107, 114], [114, 115], [116, 118], [119, 121], [122, 129], [130, 138], [139, 144], [145, 149], [149, 150], [151, 153], [154, 160], [161, 164], [165, 171], [172, 173], [174, 177], [178, 185], [186, 195], [196, 201], [202, 203], [204, 209], [210, 215], [215, 216]]}
{"doc_key": "ai-test-177", "ner": [[8, 10, "task"], [12, 12, "task"], [18, 20, "product"], [24, 26, "task"], [28, 31, "task"], [34, 35, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 12, 8, 10, "named", "", false, false], [18, 20, 8, 10, "general-affiliation", "", false, false], [28, 31, 24, 26, "named", "", false, false], [34, 35, 24, 26, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Se", "utiliza", "habitualmente", "para", "generar", "representaciones", "para", "el", "reconocimiento", "del", "habla", "(", "ASR", ")", ",", "por", "ejemplo", "el", "sistema", "CMU", "Sphinx", ",", "y", "la", "s\u00edntesis", "del", "habla", "(", "TTS", ")", ",", "por", "ejemplo", "el", "sistema", "Festival", "."], "sentence-detokenized": "Se utiliza habitualmente para generar representaciones para el reconocimiento del habla (ASR), por ejemplo el sistema CMU Sphinx, y la s\u00edntesis del habla (TTS), por ejemplo el sistema Festival.", "token2charspan": [[0, 2], [3, 10], [11, 24], [25, 29], [30, 37], [38, 54], [55, 59], [60, 62], [63, 77], [78, 81], [82, 87], [88, 89], [89, 92], [92, 93], [93, 94], [95, 98], [99, 106], [107, 109], [110, 117], [118, 121], [122, 128], [128, 129], [130, 131], [132, 134], [135, 143], [144, 147], [148, 153], [154, 155], [155, 158], [158, 159], [159, 160], [161, 164], [165, 172], [173, 175], [176, 183], [184, 192], [192, 193]]}
{"doc_key": "ai-test-178", "ner": [[0, 1, "metrics"], [3, 6, "metrics"], [8, 8, "metrics"], [14, 14, "metrics"], [32, 32, "metrics"], [34, 34, "metrics"], [45, 46, "metrics"], [48, 48, "metrics"], [50, 52, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 6, 0, 1, "named", "", false, false], [8, 8, 3, 6, "named", "", false, false], [14, 14, 0, 1, "named", "", false, false], [34, 34, 32, 32, "named", "", false, false], [48, 48, 45, 46, "named", "", false, false], [50, 52, 45, 46, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["La", "sensibilidad", "o", "Tasa", "de", "Verdaderos", "Positivos", "(", "TPR", ")", ",", "tambi\u00e9n", "conocida", "como", "recall", ",", "es", "la", "proporci\u00f3n", "de", "personas", "que", "dieron", "positivo", "en", "la", "prueba", "y", "son", "positivas", "(", "Verdaderos", "Positivos", ",", "TP", ")", "de", "todas", "las", "personas", "que", "realmente", "son", "positivas", "(", "Condici\u00f3n", "Positiva", ",", "CP", "=", "TP", "+", "FN", ")", "."], "sentence-detokenized": "La sensibilidad o Tasa de Verdaderos Positivos (TPR), tambi\u00e9n conocida como recall, es la proporci\u00f3n de personas que dieron positivo en la prueba y son positivas (Verdaderos Positivos, TP) de todas las personas que realmente son positivas (Condici\u00f3n Positiva, CP = TP + FN).", "token2charspan": [[0, 2], [3, 15], [16, 17], [18, 22], [23, 25], [26, 36], [37, 46], [47, 48], [48, 51], [51, 52], [52, 53], [54, 61], [62, 70], [71, 75], [76, 82], [82, 83], [84, 86], [87, 89], [90, 100], [101, 103], [104, 112], [113, 116], [117, 123], [124, 132], [133, 135], [136, 138], [139, 145], [146, 147], [148, 151], [152, 161], [162, 163], [163, 173], [174, 183], [183, 184], [185, 187], [187, 188], [189, 191], [192, 197], [198, 201], [202, 210], [211, 214], [215, 224], [225, 228], [229, 238], [239, 240], [240, 249], [250, 258], [258, 259], [260, 262], [263, 264], [265, 267], [268, 269], [270, 272], [272, 273], [273, 274]]}
{"doc_key": "ai-test-179", "ner": [[4, 6, "task"], [19, 19, "conference"], [21, 22, "conference"], [24, 24, "conference"], [26, 26, "conference"], [28, 28, "conference"], [31, 32, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[19, 19, 4, 6, "topic", "", false, false], [21, 22, 4, 6, "topic", "", false, false], [24, 24, 4, 6, "topic", "", false, false], [26, 26, 4, 6, "topic", "", false, false], [28, 28, 4, 6, "topic", "", false, false], [31, 32, 4, 6, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Entre", "las", "conferencias", "de", "reconocimiento", "del", "habla", "m\u00e1s", "populares", "que", "se", "celebran", "cada", "uno", "o", "dos", "a\u00f1os", "se", "encuentran", "SpeechTEK", "y", "SpeechTEK", "Europe", ",", "ICASSP", ",", "Interspeech", "/", "Eurospeech", "y", "la", "IEEE", "ASRU", "."], "sentence-detokenized": "Entre las conferencias de reconocimiento del habla m\u00e1s populares que se celebran cada uno o dos a\u00f1os se encuentran SpeechTEK y SpeechTEK Europe, ICASSP, Interspeech / Eurospeech y la IEEE ASRU.", "token2charspan": [[0, 5], [6, 9], [10, 22], [23, 25], [26, 40], [41, 44], [45, 50], [51, 54], [55, 64], [65, 68], [69, 71], [72, 80], [81, 85], [86, 89], [90, 91], [92, 95], [96, 100], [101, 103], [104, 114], [115, 124], [125, 126], [127, 136], [137, 143], [143, 144], [145, 151], [151, 152], [153, 164], [165, 166], [167, 177], [178, 179], [180, 182], [183, 187], [188, 192], [192, 193]]}
{"doc_key": "ai-test-180", "ner": [[0, 0, "researcher"], [3, 3, "researcher"], [17, 18, "product"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 22, 0, 0, "artifact", "", false, false], [22, 22, 3, 3, "artifact", "", false, false], [22, 22, 17, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Devol", "colabor\u00f3", "con", "Engelberger", ",", "que", "era", "presidente", "de", "la", "empresa", ",", "para", "dise\u00f1ar", "y", "producir", "un", "robot", "industrial", "bajo", "la", "marca", "Unimate", "."], "sentence-detokenized": "Devol colabor\u00f3 con Engelberger, que era presidente de la empresa, para dise\u00f1ar y producir un robot industrial bajo la marca Unimate.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 30], [30, 31], [32, 35], [36, 39], [40, 50], [51, 53], [54, 56], [57, 64], [64, 65], [66, 70], [71, 78], [79, 80], [81, 89], [90, 92], [93, 98], [99, 109], [110, 114], [115, 117], [118, 123], [124, 131], [131, 132]]}
{"doc_key": "ai-test-181", "ner": [[1, 4, "algorithm"], [6, 8, "algorithm"], [10, 13, "algorithm"], [25, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 4, 10, 13, "general-affiliation", "", false, false], [6, 8, 1, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Un", "modelo", "de", "Markov", "oculto", "(", "HMM", ")", "es", "un", "modelo", "estad\u00edstico", "de", "Markov", "en", "el", "que", "se", "supone", "que", "el", "sistema", "modelado", "es", "un", "proceso", "de", "Markov", "con", "estados", "no", "observados", "(", "ocultos", ")", "."], "sentence-detokenized": "Un modelo de Markov oculto (HMM) es un modelo estad\u00edstico de Markov en el que se supone que el sistema modelado es un proceso de Markov con estados no observados (ocultos).", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 19], [20, 26], [27, 28], [28, 31], [31, 32], [33, 35], [36, 38], [39, 45], [46, 57], [58, 60], [61, 67], [68, 70], [71, 73], [74, 77], [78, 80], [81, 87], [88, 91], [92, 94], [95, 102], [103, 111], [112, 114], [115, 117], [118, 125], [126, 128], [129, 135], [136, 139], [140, 147], [148, 150], [151, 161], [162, 163], [163, 170], [170, 171], [171, 172]]}
{"doc_key": "ai-test-182", "ner": [[18, 20, "metrics"], [27, 27, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Esta", "propiedad", ",", "indeseable", "en", "muchas", "aplicaciones", ",", "ha", "llevado", "a", "los", "investigadores", "a", "utilizar", "alternativas", "como", "el", "error", "medio", "absoluto", ",", "o", "las", "basadas", "en", "la", "mediana", "."], "sentence-detokenized": "Esta propiedad, indeseable en muchas aplicaciones, ha llevado a los investigadores a utilizar alternativas como el error medio absoluto, o las basadas en la mediana.", "token2charspan": [[0, 4], [5, 14], [14, 15], [16, 26], [27, 29], [30, 36], [37, 49], [49, 50], [51, 53], [54, 61], [62, 63], [64, 67], [68, 82], [83, 84], [85, 93], [94, 106], [107, 111], [112, 114], [115, 120], [121, 126], [127, 135], [135, 136], [137, 138], [139, 142], [143, 150], [151, 153], [154, 156], [157, 164], [164, 165]]}
{"doc_key": "ai-test-183", "ner": [[23, 25, "algorithm"], [33, 34, "field"], [37, 41, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 25, 33, 34, "part-of", "", false, false], [23, 25, 37, 41, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Una", "secuencia", "de", "este", "tipo", "(", "que", "depende", "del", "resultado", "de", "la", "investigaci\u00f3n", "de", "los", "atributos", "anteriores", "en", "cada", "etapa", ")", "se", "denomina", "\u00e1rbol", "de", "decisi\u00f3n", "y", "se", "aplica", "en", "el", "\u00e1mbito", "del", "aprendizaje", "autom\u00e1tico", "conocido", "como", "aprendizaje", "de", "\u00e1rboles", "de", "decisi\u00f3n", "."], "sentence-detokenized": "Una secuencia de este tipo (que depende del resultado de la investigaci\u00f3n de los atributos anteriores en cada etapa) se denomina \u00e1rbol de decisi\u00f3n y se aplica en el \u00e1mbito del aprendizaje autom\u00e1tico conocido como aprendizaje de \u00e1rboles de decisi\u00f3n.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 21], [22, 26], [27, 28], [28, 31], [32, 39], [40, 43], [44, 53], [54, 56], [57, 59], [60, 73], [74, 76], [77, 80], [81, 90], [91, 101], [102, 104], [105, 109], [110, 115], [115, 116], [117, 119], [120, 128], [129, 134], [135, 137], [138, 146], [147, 148], [149, 151], [152, 158], [159, 161], [162, 164], [165, 171], [172, 175], [176, 187], [188, 198], [199, 207], [208, 212], [213, 224], [225, 227], [228, 235], [236, 238], [239, 247], [247, 248]]}
{"doc_key": "ai-test-184", "ner": [[5, 6, "task"], [9, 9, "algorithm"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 9, 9, "compare", "", false, false], [23, 25, 9, 9, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Al", "igual", "que", "en", "el", "an\u00e1lisis", "factorial", ",", "el", "ACV", "tambi\u00e9n", "puede", "utilizarse", "para", "clasificar", "los", "casos", "seg\u00fan", "su", "pertenencia", "a", "una", "clase", "de", "m\u00e1xima", "probabilidad", "."], "sentence-detokenized": "Al igual que en el an\u00e1lisis factorial, el ACV tambi\u00e9n puede utilizarse para clasificar los casos seg\u00fan su pertenencia a una clase de m\u00e1xima probabilidad.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 15], [16, 18], [19, 27], [28, 37], [37, 38], [39, 41], [42, 45], [46, 53], [54, 59], [60, 70], [71, 75], [76, 86], [87, 90], [91, 96], [97, 102], [103, 105], [106, 117], [118, 119], [120, 123], [124, 129], [130, 132], [133, 139], [140, 152], [152, 153]]}
{"doc_key": "ai-test-185", "ner": [[0, 3, "algorithm"], [11, 13, "metrics"], [15, 15, "metrics"], [7, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 11, 13, "usage", "", false, false], [11, 13, 7, 10, "related-to", "", false, false], [15, 15, 11, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Las", "redes", "neuronales", "supervisadas", "que", "utilizan", "una", "funci\u00f3n", "de", "coste", "de", "error", "cuadr\u00e1tico", "medio", "(", "MSE", ")", "pueden", "utilizar", "m\u00e9todos", "estad\u00edsticos", "formales", "para", "determinar", "la", "confianza", "del", "modelo", "entrenado", "."], "sentence-detokenized": "Las redes neuronales supervisadas que utilizan una funci\u00f3n de coste de error cuadr\u00e1tico medio (MSE) pueden utilizar m\u00e9todos estad\u00edsticos formales para determinar la confianza del modelo entrenado.", "token2charspan": [[0, 3], [4, 9], [10, 20], [21, 33], [34, 37], [38, 46], [47, 50], [51, 58], [59, 61], [62, 67], [68, 70], [71, 76], [77, 87], [88, 93], [94, 95], [95, 98], [98, 99], [100, 106], [107, 115], [116, 123], [124, 136], [137, 145], [146, 150], [151, 161], [162, 164], [165, 174], [175, 178], [179, 185], [186, 195], [195, 196]]}
{"doc_key": "ai-test-186", "ner": [[16, 18, "algorithm"], [21, 25, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 18, 21, 25, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Esto", "se", "puede", "expresar", "directamente", "como", "un", "programa", "lineal", ",", "pero", "tambi\u00e9n", "es", "equivalente", "a", "la", "regularizaci\u00f3n", "de", "Tikhonov", "con", "la", "funci\u00f3n", "de", "p\u00e9rdida", "de", "bisagra", ",", "mathV", "(", "f", "(", "x", ")", ",", "y", ")", "=", "\\", "max", "(", "0", ",", "1", "-", "yf", "(", "x", ")", ")", "/", "math", ":"], "sentence-detokenized": "Esto se puede expresar directamente como un programa lineal, pero tambi\u00e9n es equivalente a la regularizaci\u00f3n de Tikhonov con la funci\u00f3n de p\u00e9rdida de bisagra, mathV (f (x), y) =\\ max (0, 1 - yf (x)) / math:", "token2charspan": [[0, 4], [5, 7], [8, 13], [14, 22], [23, 35], [36, 40], [41, 43], [44, 52], [53, 59], [59, 60], [61, 65], [66, 73], [74, 76], [77, 88], [89, 90], [91, 93], [94, 108], [109, 111], [112, 120], [121, 124], [125, 127], [128, 135], [136, 138], [139, 146], [147, 149], [150, 157], [157, 158], [159, 164], [165, 166], [166, 167], [168, 169], [169, 170], [170, 171], [171, 172], [173, 174], [174, 175], [176, 177], [177, 178], [179, 182], [183, 184], [184, 185], [185, 186], [187, 188], [189, 190], [191, 193], [194, 195], [195, 196], [196, 197], [197, 198], [199, 200], [201, 205], [205, 206]]}
{"doc_key": "ai-test-187", "ner": [[10, 10, "researcher"], [16, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "siguiente", "t\u00e9cnica", "se", "describe", "en", "el", "art\u00edculo", "original", "de", "Breiman", "y", "se", "implementa", "en", "el", "paquete", "R", "randomForest", "."], "sentence-detokenized": "La siguiente t\u00e9cnica se describe en el art\u00edculo original de Breiman y se implementa en el paquete R randomForest.", "token2charspan": [[0, 2], [3, 12], [13, 20], [21, 23], [24, 32], [33, 35], [36, 38], [39, 47], [48, 56], [57, 59], [60, 67], [68, 69], [70, 72], [73, 83], [84, 86], [87, 89], [90, 97], [98, 99], [100, 112], [112, 113]]}
{"doc_key": "ai-test-188", "ner": [[9, 10, "metrics"], [39, 40, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Las", "medidas", "tradicionales", "de", "calidad", "de", "imagen", ",", "como", "la", "PSNR", ",", "se", "realizan", "normalmente", "con", "im\u00e1genes", "de", "resoluci\u00f3n", "fija", "y", "no", "tienen", "en", "cuenta", "algunos", "aspectos", "del", "sistema", "visual", "humano", ",", "como", "el", "cambio", "de", "resoluci\u00f3n", "espacial", "en", "la", "retina", "."], "sentence-detokenized": "Las medidas tradicionales de calidad de imagen, como la PSNR, se realizan normalmente con im\u00e1genes de resoluci\u00f3n fija y no tienen en cuenta algunos aspectos del sistema visual humano, como el cambio de resoluci\u00f3n espacial en la retina.", "token2charspan": [[0, 3], [4, 11], [12, 25], [26, 28], [29, 36], [37, 39], [40, 46], [46, 47], [48, 52], [53, 55], [56, 60], [60, 61], [62, 64], [65, 73], [74, 85], [86, 89], [90, 98], [99, 101], [102, 112], [113, 117], [118, 119], [120, 122], [123, 129], [130, 132], [133, 139], [140, 147], [148, 156], [157, 160], [161, 168], [169, 175], [176, 182], [182, 183], [184, 188], [189, 191], [192, 198], [199, 201], [202, 212], [213, 221], [222, 224], [225, 227], [228, 234], [234, 235]]}
{"doc_key": "ai-test-189", "ner": [[0, 1, "person"], [3, 4, "person"], [6, 7, "person"], [14, 15, "person"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 16, 17, "role", "", false, false], [3, 4, 16, 17, "role", "", false, false], [6, 7, 16, 17, "role", "", false, false], [16, 17, 14, 15, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["John", "Ireland", ",", "Joanne", "Dru", "y", "Macdonald", "Carey", "protagonizaron", "la", "producci\u00f3n", "en", "color", "de", "Jack", "Broder", "Hannah", "Lee", ",", "estrenada", "el", "19", "de", "junio", "de", "1953", "."], "sentence-detokenized": "John Ireland, Joanne Dru y Macdonald Carey protagonizaron la producci\u00f3n en color de Jack Broder Hannah Lee, estrenada el 19 de junio de 1953.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 20], [21, 24], [25, 26], [27, 36], [37, 42], [43, 57], [58, 60], [61, 71], [72, 74], [75, 80], [81, 83], [84, 88], [89, 95], [96, 102], [103, 106], [106, 107], [108, 117], [118, 120], [121, 123], [124, 126], [127, 132], [133, 135], [136, 140], [140, 141]]}
{"doc_key": "ai-test-190", "ner": [[4, 6, "task"], [13, 15, "field"], [23, 23, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 13, 15, "usage", "", false, false], [23, 23, 13, 15, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Ese", "proceso", "se", "denomina", "registro", "de", "im\u00e1genes", ",", "y", "utiliza", "diferentes", "m\u00e9todos", "de", "visi\u00f3n", "por", "ordenador", ",", "en", "su", "mayor\u00eda", "relacionados", "con", "el", "seguimiento", "."], "sentence-detokenized": "Ese proceso se denomina registro de im\u00e1genes, y utiliza diferentes m\u00e9todos de visi\u00f3n por ordenador, en su mayor\u00eda relacionados con el seguimiento.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 23], [24, 32], [33, 35], [36, 44], [44, 45], [46, 47], [48, 55], [56, 66], [67, 74], [75, 77], [78, 84], [85, 88], [89, 98], [98, 99], [100, 102], [103, 105], [106, 113], [114, 126], [127, 130], [131, 133], [134, 145], [145, 146]]}
{"doc_key": "ai-test-191", "ner": [[16, 18, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Comencemos", "ahora", "a", "explicar", "las", "diferentes", "relaciones", "posibles", "entre", "el", "resultado", "previsto", "y", "el", "real", ":", "Matriz", "de", "confusi\u00f3n"], "sentence-detokenized": "Comencemos ahora a explicar las diferentes relaciones posibles entre el resultado previsto y el real: Matriz de confusi\u00f3n", "token2charspan": [[0, 10], [11, 16], [17, 18], [19, 27], [28, 31], [32, 42], [43, 53], [54, 62], [63, 68], [69, 71], [72, 81], [82, 90], [91, 92], [93, 95], [96, 100], [100, 101], [102, 108], [109, 111], [112, 121]]}
{"doc_key": "ai-test-192", "ner": [[8, 8, "product"], [1, 7, "misc"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 1, 7, "part-of", "", false, false], [8, 8, 1, 7, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "caja", "de", "herramientas", "de", "procesamiento", "del", "habla", "VOICEBOX", "para", "MATLAB", "implementa", "la", "conversi\u00f3n", "y", "su", "inversa", "como", ":"], "sentence-detokenized": "La caja de herramientas de procesamiento del habla VOICEBOX para MATLAB implementa la conversi\u00f3n y su inversa como:", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 23], [24, 26], [27, 40], [41, 44], [45, 50], [51, 59], [60, 64], [65, 71], [72, 82], [83, 85], [86, 96], [97, 98], [99, 101], [102, 109], [110, 114], [114, 115]]}
{"doc_key": "ai-test-193", "ner": [[0, 0, "programlang"], [10, 11, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 10, 11, "general-affiliation", "", false, false], [0, 0, 14, 15, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolog", "es", "un", "lenguaje", "de", "programaci\u00f3n", "l\u00f3gica", "asociado", "a", "la", "inteligencia", "artificial", "y", "la", "ling\u00fc\u00edstica", "computacional", "."], "sentence-detokenized": "Prolog es un lenguaje de programaci\u00f3n l\u00f3gica asociado a la inteligencia artificial y la ling\u00fc\u00edstica computacional.", "token2charspan": [[0, 6], [7, 9], [10, 12], [13, 21], [22, 24], [25, 37], [38, 44], [45, 53], [54, 55], [56, 58], [59, 71], [72, 82], [83, 84], [85, 87], [88, 99], [100, 113], [113, 114]]}
{"doc_key": "ai-test-194", "ner": [[0, 0, "researcher"], [10, 10, "field"], [13, 13, "field"], [21, 24, "organisation"], [27, 30, "organisation"], [33, 36, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 10, 10, "related-to", "works_with_topic", false, false], [0, 0, 13, 13, "related-to", "works_with_topic", false, false], [0, 0, 21, 24, "role", "", false, false], [0, 0, 27, 30, "role", "", false, false], [0, 0, 33, 36, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Milner", "ha", "recibido", "numerosos", "premios", "por", "sus", "contribuciones", "a", "la", "neurociencia", "y", "la", "psicolog\u00eda", ",", "entre", "ellos", "la", "pertenencia", "a", "la", "Royal", "Society", "de", "Londres", ",", "la", "Royal", "Society", "de", "Canad\u00e1", "y", "la", "Academia", "Nacional", "de", "Ciencias", "."], "sentence-detokenized": "Milner ha recibido numerosos premios por sus contribuciones a la neurociencia y la psicolog\u00eda, entre ellos la pertenencia a la Royal Society de Londres, la Royal Society de Canad\u00e1 y la Academia Nacional de Ciencias.", "token2charspan": [[0, 6], [7, 9], [10, 18], [19, 28], [29, 36], [37, 40], [41, 44], [45, 59], [60, 61], [62, 64], [65, 77], [78, 79], [80, 82], [83, 93], [93, 94], [95, 100], [101, 106], [107, 109], [110, 121], [122, 123], [124, 126], [127, 132], [133, 140], [141, 143], [144, 151], [151, 152], [153, 155], [156, 161], [162, 169], [170, 172], [173, 179], [180, 181], [182, 184], [185, 193], [194, 202], [203, 205], [206, 214], [214, 215]]}
{"doc_key": "ai-test-195", "ner": [[11, 16, "field"], [17, 19, "task"], [22, 24, "task"], [27, 29, "task"], [32, 34, "task"], [37, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[17, 19, 11, 16, "part-of", "task_part_of_field", false, false], [22, 24, 11, 16, "part-of", "task_part_of_field", false, false], [27, 29, 11, 16, "part-of", "task_part_of_field", false, false], [32, 34, 11, 16, "part-of", "task_part_of_field", false, false], [37, 37, 11, 16, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Combinando", "estos", "operadores", "se", "pueden", "obtener", "algoritmos", "para", "muchas", "tareas", "de", "procesamiento", "de", "im\u00e1genes", ",", "como", "la", "extracci\u00f3n", "de", "caracter\u00edsticas", ",", "la", "segmentaci\u00f3n", "de", "im\u00e1genes", ",", "el", "afinamiento", "de", "im\u00e1genes", ",", "el", "filtrado", "de", "im\u00e1genes", "y", "la", "clasificaci\u00f3n", "."], "sentence-detokenized": "Combinando estos operadores se pueden obtener algoritmos para muchas tareas de procesamiento de im\u00e1genes, como la extracci\u00f3n de caracter\u00edsticas, la segmentaci\u00f3n de im\u00e1genes, el afinamiento de im\u00e1genes, el filtrado de im\u00e1genes y la clasificaci\u00f3n.", "token2charspan": [[0, 10], [11, 16], [17, 27], [28, 30], [31, 37], [38, 45], [46, 56], [57, 61], [62, 68], [69, 75], [76, 78], [79, 92], [93, 95], [96, 104], [104, 105], [106, 110], [111, 113], [114, 124], [125, 127], [128, 143], [143, 144], [145, 147], [148, 160], [161, 163], [164, 172], [172, 173], [174, 176], [177, 188], [189, 191], [192, 200], [200, 201], [202, 204], [205, 213], [214, 216], [217, 225], [226, 227], [228, 230], [231, 244], [244, 245]]}
{"doc_key": "ai-test-196", "ner": [[6, 8, "university"], [17, 20, "organisation"], [22, 23, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 23, 17, 20, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Desde", "2017", ",", "es", "profesor", "del", "Coll\u00e8ge", "de", "France", "y", ",", "desde", "1989", ",", "director", "de", "la", "Unidad", "562", "del", "INSERM", ",", "Neuroimagen", "Cognitiva", "."], "sentence-detokenized": "Desde 2017, es profesor del Coll\u00e8ge de France y, desde 1989, director de la Unidad 562 del INSERM, Neuroimagen Cognitiva.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 14], [15, 23], [24, 27], [28, 35], [36, 38], [39, 45], [46, 47], [47, 48], [49, 54], [55, 59], [59, 60], [61, 69], [70, 72], [73, 75], [76, 82], [83, 86], [87, 90], [91, 97], [97, 98], [99, 110], [111, 120], [120, 121]]}
{"doc_key": "ai-test-197", "ner": [[13, 16, "algorithm"], [18, 22, "algorithm"], [28, 28, "algorithm"], [30, 38, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[28, 28, 30, 38, "temporal", "", false, true]], "relations_mapping_to_source": [0], "sentence": ["Hay", "muchos", "enfoques", "para", "el", "aprendizaje", "de", "estas", "incrustaciones", ",", "en", "particular", "utilizando", "marcos", "de", "agrupaci\u00f3n", "bayesiana", "o", "marcos", "basados", "en", "la", "energ\u00eda", ",", "y", "m\u00e1s", "recientemente", ",", "TransE", "(", "Conferencia", "sobre", "Sistemas", "de", "Procesamiento", "de", "Informaci\u00f3n", "Neural", "2013", ")", "."], "sentence-detokenized": "Hay muchos enfoques para el aprendizaje de estas incrustaciones, en particular utilizando marcos de agrupaci\u00f3n bayesiana o marcos basados en la energ\u00eda, y m\u00e1s recientemente, TransE (Conferencia sobre Sistemas de Procesamiento de Informaci\u00f3n Neural 2013).", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 24], [25, 27], [28, 39], [40, 42], [43, 48], [49, 63], [63, 64], [65, 67], [68, 78], [79, 89], [90, 96], [97, 99], [100, 110], [111, 120], [121, 122], [123, 129], [130, 137], [138, 140], [141, 143], [144, 151], [151, 152], [153, 154], [155, 158], [159, 172], [172, 173], [174, 180], [181, 182], [182, 193], [194, 199], [200, 208], [209, 211], [212, 225], [226, 228], [229, 240], [241, 247], [248, 252], [252, 253], [253, 254]]}
{"doc_key": "ai-test-198", "ner": [[5, 9, "metrics"], [11, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 13, 5, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Es", "una", "alternativa", "a", "la", "tasa", "de", "error", "de", "palabras", "(", "Word", "Error", "Rate", ")", "utilizada", "en", "varios", "pa\u00edses", "."], "sentence-detokenized": "Es una alternativa a la tasa de error de palabras (Word Error Rate) utilizada en varios pa\u00edses.", "token2charspan": [[0, 2], [3, 6], [7, 18], [19, 20], [21, 23], [24, 28], [29, 31], [32, 37], [38, 40], [41, 49], [50, 51], [51, 55], [56, 61], [62, 66], [66, 67], [68, 77], [78, 80], [81, 87], [88, 94], [94, 95]]}
{"doc_key": "ai-test-199", "ner": [[0, 2, "algorithm"], [10, 13, "task"], [16, 18, "task"], [21, 22, "task"], [25, 28, "task"], [30, 36, "task"], [39, 40, "task"], [56, 57, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 13, 0, 2, "usage", "", false, false], [16, 18, 0, 2, "usage", "", false, false], [21, 22, 0, 2, "usage", "", false, false], [25, 28, 0, 2, "usage", "", false, false], [30, 36, 0, 2, "usage", "", false, false], [39, 40, 0, 2, "usage", "", false, false], [56, 57, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Las", "RNA", "se", "han", "utilizado", "en", "diversas", "tareas", ",", "como", "la", "visi\u00f3n", "por", "ordenador", ",", "el", "reconocimiento", "del", "habla", ",", "la", "traducci\u00f3n", "autom\u00e1tica", ",", "el", "filtrado", "de", "redes", "sociales", ",", "los", "juegos", "de", "mesa", "y", "los", "videojuegos", ",", "el", "diagn\u00f3stico", "m\u00e9dico", "e", "incluso", "en", "actividades", "que", "tradicionalmente", "se", "han", "considerado", "reservadas", "a", "los", "humanos", ",", "como", "la", "pintura", "."], "sentence-detokenized": "Las RNA se han utilizado en diversas tareas, como la visi\u00f3n por ordenador, el reconocimiento del habla, la traducci\u00f3n autom\u00e1tica, el filtrado de redes sociales, los juegos de mesa y los videojuegos, el diagn\u00f3stico m\u00e9dico e incluso en actividades que tradicionalmente se han considerado reservadas a los humanos, como la pintura.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 14], [15, 24], [25, 27], [28, 36], [37, 43], [43, 44], [45, 49], [50, 52], [53, 59], [60, 63], [64, 73], [73, 74], [75, 77], [78, 92], [93, 96], [97, 102], [102, 103], [104, 106], [107, 117], [118, 128], [128, 129], [130, 132], [133, 141], [142, 144], [145, 150], [151, 159], [159, 160], [161, 164], [165, 171], [172, 174], [175, 179], [180, 181], [182, 185], [186, 197], [197, 198], [199, 201], [202, 213], [214, 220], [221, 222], [223, 230], [231, 233], [234, 245], [246, 249], [250, 266], [267, 269], [270, 273], [274, 285], [286, 296], [297, 298], [299, 302], [303, 310], [310, 311], [312, 316], [317, 319], [320, 327], [327, 328]]}
{"doc_key": "ai-test-200", "ner": [[0, 3, "product"], [5, 5, "product"], [21, 32, "field"], [34, 34, "field"], [38, 38, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 21, 32, "related-to", "", false, false], [0, 3, 38, 38, "general-affiliation", "", false, false], [5, 5, 0, 3, "named", "", false, false], [34, 34, 21, 32, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Modular", "Audio", "Recognition", "Framework", "(", "MARF", ")", "es", "una", "plataforma", "de", "investigaci\u00f3n", "de", "c\u00f3digo", "abierto", "y", "una", "colecci\u00f3n", "de", "algoritmos", "de", "procesamiento", "de", "voz", ",", "sonido", ",", "habla", ",", "texto", "y", "lenguaje", "natural", "(", "NLP", ")", "escritos", "en", "Java", "y", "organizados", "en", "un", "marco", "modular", "y", "extensible", "que", "intenta", "facilitar", "la", "adici\u00f3n", "de", "nuevos", "algoritmos", "."], "sentence-detokenized": "Modular Audio Recognition Framework (MARF) es una plataforma de investigaci\u00f3n de c\u00f3digo abierto y una colecci\u00f3n de algoritmos de procesamiento de voz, sonido, habla, texto y lenguaje natural (NLP) escritos en Java y organizados en un marco modular y extensible que intenta facilitar la adici\u00f3n de nuevos algoritmos.", "token2charspan": [[0, 7], [8, 13], [14, 25], [26, 35], [36, 37], [37, 41], [41, 42], [43, 45], [46, 49], [50, 60], [61, 63], [64, 77], [78, 80], [81, 87], [88, 95], [96, 97], [98, 101], [102, 111], [112, 114], [115, 125], [126, 128], [129, 142], [143, 145], [146, 149], [149, 150], [151, 157], [157, 158], [159, 164], [164, 165], [166, 171], [172, 173], [174, 182], [183, 190], [191, 192], [192, 195], [195, 196], [197, 205], [206, 208], [209, 213], [214, 215], [216, 227], [228, 230], [231, 233], [234, 239], [240, 247], [248, 249], [250, 260], [261, 264], [265, 272], [273, 282], [283, 285], [286, 293], [294, 296], [297, 303], [304, 314], [314, 315]]}
{"doc_key": "ai-test-201", "ner": [[15, 17, "organisation"], [23, 25, "country"], [27, 32, "organisation"], [35, 36, "organisation"], [41, 42, "task"], [62, 67, "organisation"], [68, 69, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[27, 32, 23, 25, "physical", "", false, false], [27, 32, 41, 42, "usage", "", false, false], [27, 32, 62, 67, "named", "", false, false], [35, 36, 23, 25, "physical", "", false, false], [35, 36, 41, 42, "usage", "", false, false], [62, 67, 68, 69, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["En", "2018", ",", "un", "informe", "de", "la", "organizaci\u00f3n", "de", "campa\u00f1as", "de", "derechos", "y", "libertades", "civiles", "Big", "Brother", "Watch", "revel\u00f3", "que", "dos", "fuerzas", "policiales", "del", "Reino", "Unido", ",", "la", "Polic\u00eda", "de", "Gales", "del", "Sur", "y", "la", "Polic\u00eda", "Metropolitana", ",", "estaban", "utilizando", "el", "reconocimiento", "facial", "en", "vivo", "en", "eventos", "p\u00fablicos", "y", "en", "espacios", "p\u00fablicos", ",", "en", "septiembre", "de", "2019", ",", "el", "uso", "de", "la", "Polic\u00eda", "de", "Gales", "del", "Sur", "del", "reconocimiento", "facial", "fue", "declarado", "legal", "."], "sentence-detokenized": "En 2018, un informe de la organizaci\u00f3n de campa\u00f1as de derechos y libertades civiles Big Brother Watch revel\u00f3 que dos fuerzas policiales del Reino Unido, la Polic\u00eda de Gales del Sur y la Polic\u00eda Metropolitana, estaban utilizando el reconocimiento facial en vivo en eventos p\u00fablicos y en espacios p\u00fablicos, en septiembre de 2019, el uso de la Polic\u00eda de Gales del Sur del reconocimiento facial fue declarado legal.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 19], [20, 22], [23, 25], [26, 38], [39, 41], [42, 50], [51, 53], [54, 62], [63, 64], [65, 75], [76, 83], [84, 87], [88, 95], [96, 101], [102, 108], [109, 112], [113, 116], [117, 124], [125, 135], [136, 139], [140, 145], [146, 151], [151, 152], [153, 155], [156, 163], [164, 166], [167, 172], [173, 176], [177, 180], [181, 182], [183, 185], [186, 193], [194, 207], [207, 208], [209, 216], [217, 227], [228, 230], [231, 245], [246, 252], [253, 255], [256, 260], [261, 263], [264, 271], [272, 280], [281, 282], [283, 285], [286, 294], [295, 303], [303, 304], [305, 307], [308, 318], [319, 321], [322, 326], [326, 327], [328, 330], [331, 334], [335, 337], [338, 340], [341, 348], [349, 351], [352, 357], [358, 361], [362, 365], [366, 369], [370, 384], [385, 391], [392, 395], [396, 405], [406, 411], [411, 412]]}
{"doc_key": "ai-test-202", "ner": [[0, 0, "product"], [5, 5, "programlang"], [16, 17, "field"], [20, 20, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 5, "general-affiliation", "", false, false], [0, 0, 16, 17, "related-to", "", false, false], [0, 0, 20, 20, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["ANIMAL", "ha", "sido", "portado", "a", "R", ",", "un", "lenguaje", "y", "entorno", "de", "libre", "acceso", "para", "la", "computaci\u00f3n", "estad\u00edstica", "y", "los", "gr\u00e1ficos", "."], "sentence-detokenized": "ANIMAL ha sido portado a R, un lenguaje y entorno de libre acceso para la computaci\u00f3n estad\u00edstica y los gr\u00e1ficos.", "token2charspan": [[0, 6], [7, 9], [10, 14], [15, 22], [23, 24], [25, 26], [26, 27], [28, 30], [31, 39], [40, 41], [42, 49], [50, 52], [53, 58], [59, 65], [66, 70], [71, 73], [74, 85], [86, 97], [98, 99], [100, 103], [104, 112], [112, 113]]}
{"doc_key": "ai-test-203", "ner": [[0, 6, "algorithm"], [8, 8, "algorithm"], [14, 17, "algorithm"], [19, 19, "algorithm"], [23, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 6, 14, 17, "opposite", "alternative to", false, false], [8, 8, 0, 6, "named", "", false, false], [19, 19, 14, 17, "named", "", false, false], [23, 26, 0, 6, "usage", "", false, false], [23, 26, 14, 17, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["El", "modelo", "Bernoulli", "oculto", "en", "el", "tiempo", "(", "TI-HBM", ")", "es", "una", "alternativa", "al", "modelo", "de", "Markov", "oculto", "(", "HMM", ")", "para", "el", "reconocimiento", "autom\u00e1tico", "del", "habla", "."], "sentence-detokenized": "El modelo Bernoulli oculto en el tiempo (TI-HBM) es una alternativa al modelo de Markov oculto (HMM) para el reconocimiento autom\u00e1tico del habla.", "token2charspan": [[0, 2], [3, 9], [10, 19], [20, 26], [27, 29], [30, 32], [33, 39], [40, 41], [41, 47], [47, 48], [49, 51], [52, 55], [56, 67], [68, 70], [71, 77], [78, 80], [81, 87], [88, 94], [95, 96], [96, 99], [99, 100], [101, 105], [106, 108], [109, 123], [124, 134], [135, 138], [139, 144], [144, 145]]}
{"doc_key": "ai-test-204", "ner": [[5, 5, "organisation"], [8, 8, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 8, 8, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["En", "julio", "de", "2016", ",", "Nvidia", "demostr\u00f3", "durante", "SIGGRAPH", "un", "nuevo", "m\u00e9todo", "de", "renderizado", "foveado", "que", "dec\u00eda", "ser", "invisible", "para", "los", "usuarios", "."], "sentence-detokenized": "En julio de 2016, Nvidia demostr\u00f3 durante SIGGRAPH un nuevo m\u00e9todo de renderizado foveado que dec\u00eda ser invisible para los usuarios.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 16], [16, 17], [18, 24], [25, 33], [34, 41], [42, 50], [51, 53], [54, 59], [60, 66], [67, 69], [70, 81], [82, 89], [90, 93], [94, 99], [100, 103], [104, 113], [114, 118], [119, 122], [123, 131], [131, 132]]}
{"doc_key": "ai-test-205", "ner": [[4, 10, "misc"], [13, 14, "researcher"], [23, 24, "researcher"], [26, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 10, 13, 14, "origin", "", false, false], [4, 10, 23, 24, "origin", "", false, false], [4, 10, 26, 26, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Ambos", "se", "basan", "en", "la", "teor\u00eda", "de", "los", "actos", "de", "habla", "desarrollada", "por", "John", "Searle", "en", "la", "d\u00e9cada", "de", "1960", "y", "mejorada", "por", "Terry", "Winograd", "y", "Flores", "en", "la", "d\u00e9cada", "de", "1970", "."], "sentence-detokenized": "Ambos se basan en la teor\u00eda de los actos de habla desarrollada por John Searle en la d\u00e9cada de 1960 y mejorada por Terry Winograd y Flores en la d\u00e9cada de 1970.", "token2charspan": [[0, 5], [6, 8], [9, 14], [15, 17], [18, 20], [21, 27], [28, 30], [31, 34], [35, 40], [41, 43], [44, 49], [50, 62], [63, 66], [67, 71], [72, 78], [79, 81], [82, 84], [85, 91], [92, 94], [95, 99], [100, 101], [102, 110], [111, 114], [115, 120], [121, 129], [130, 131], [132, 138], [139, 141], [142, 144], [145, 151], [152, 154], [155, 159], [159, 160]]}
{"doc_key": "ai-test-206", "ner": [[0, 4, "algorithm"], [29, 30, "researcher"], [27, 27, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 29, 30, "related-to", "", false, false], [27, 27, 29, 30, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Los", "modelos", "de", "redes", "neuronales", "sobre", "la", "formaci\u00f3n", "de", "conceptos", "y", "la", "estructura", "del", "conocimiento", "han", "abierto", "potentes", "modelos", "jer\u00e1rquicos", "de", "organizaci\u00f3n", "del", "conocimiento", ",", "como", "la", "Wordnet", "de", "George", "Miller", "."], "sentence-detokenized": "Los modelos de redes neuronales sobre la formaci\u00f3n de conceptos y la estructura del conocimiento han abierto potentes modelos jer\u00e1rquicos de organizaci\u00f3n del conocimiento, como la Wordnet de George Miller.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 20], [21, 31], [32, 37], [38, 40], [41, 50], [51, 53], [54, 63], [64, 65], [66, 68], [69, 79], [80, 83], [84, 96], [97, 100], [101, 108], [109, 117], [118, 125], [126, 137], [138, 140], [141, 153], [154, 157], [158, 170], [170, 171], [172, 176], [177, 179], [180, 187], [188, 190], [191, 197], [198, 204], [204, 205]]}
{"doc_key": "ai-test-207", "ner": [[0, 3, "algorithm"], [14, 16, "field"], [20, 23, "product"], [26, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 14, 16, "part-of", "", false, false], [0, 3, 26, 30, "part-of", "", false, false], [20, 23, 14, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "correspondencia", "de", "plantillas", "tiene", "varias", "aplicaciones", "y", "se", "utiliza", "en", "campos", "como", "el", "reconocimiento", "de", "caras", "(", "v\u00e9ase", "el", "sistema", "de", "reconocimiento", "facial", ")", "y", "el", "procesamiento", "de", "im\u00e1genes", "m\u00e9dicas", "."], "sentence-detokenized": "La correspondencia de plantillas tiene varias aplicaciones y se utiliza en campos como el reconocimiento de caras (v\u00e9ase el sistema de reconocimiento facial) y el procesamiento de im\u00e1genes m\u00e9dicas.", "token2charspan": [[0, 2], [3, 18], [19, 21], [22, 32], [33, 38], [39, 45], [46, 58], [59, 60], [61, 63], [64, 71], [72, 74], [75, 81], [82, 86], [87, 89], [90, 104], [105, 107], [108, 113], [114, 115], [115, 120], [121, 123], [124, 131], [132, 134], [135, 149], [150, 156], [156, 157], [158, 159], [160, 162], [163, 176], [177, 179], [180, 188], [189, 196], [196, 197]]}
{"doc_key": "ai-test-208", "ner": [[12, 13, "researcher"], [15, 16, "researcher"], [21, 31, "organisation"], [29, 29, "organisation"], [38, 40, "algorithm"], [43, 51, "conference"], [53, 53, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 13, 21, 31, "role", "", false, false], [12, 13, 43, 51, "physical", "", false, false], [12, 13, 43, 51, "temporal", "", false, false], [12, 13, 53, 53, "physical", "", false, false], [15, 16, 21, 31, "role", "", false, false], [15, 16, 43, 51, "temporal", "", false, false], [29, 29, 21, 31, "named", "", false, false], [43, 51, 38, 40, "topic", "", false, false], [53, 53, 43, 51, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Sin", "embargo", ",", "su", "uso", "no", "se", "generaliz\u00f3", "hasta", "2005", ",", "cuando", "Navneet", "Dalal", "y", "Bill", "Triggs", ",", "investigadores", "del", "Instituto", "Nacional", "de", "Investigaci\u00f3n", "en", "Inform\u00e1tica", "y", "Autom\u00e1tica", "(", "INRIA", ")", "franc\u00e9s", ",", "presentaron", "su", "trabajo", "complementario", "sobre", "los", "descriptores", "HOG", "en", "la", "Conferencia", "sobre", "Visi\u00f3n", "por", "Ordenador", "y", "Reconocimiento", "de", "Patrones", "(", "CVPR", ")", "."], "sentence-detokenized": "Sin embargo, su uso no se generaliz\u00f3 hasta 2005, cuando Navneet Dalal y Bill Triggs, investigadores del Instituto Nacional de Investigaci\u00f3n en Inform\u00e1tica y Autom\u00e1tica (INRIA) franc\u00e9s, presentaron su trabajo complementario sobre los descriptores HOG en la Conferencia sobre Visi\u00f3n por Ordenador y Reconocimiento de Patrones (CVPR).", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 19], [20, 22], [23, 25], [26, 36], [37, 42], [43, 47], [47, 48], [49, 55], [56, 63], [64, 69], [70, 71], [72, 76], [77, 83], [83, 84], [85, 99], [100, 103], [104, 113], [114, 122], [123, 125], [126, 139], [140, 142], [143, 154], [155, 156], [157, 167], [168, 169], [169, 174], [174, 175], [176, 183], [183, 184], [185, 196], [197, 199], [200, 207], [208, 222], [223, 228], [229, 232], [233, 245], [246, 249], [250, 252], [253, 255], [256, 267], [268, 273], [274, 280], [281, 284], [285, 294], [295, 296], [297, 311], [312, 314], [315, 323], [324, 325], [325, 329], [329, 330], [330, 331]]}
{"doc_key": "ai-test-209", "ner": [[7, 7, "university"], [18, 21, "organisation"], [23, 24, "organisation"], [34, 34, "field"], [38, 40, "researcher"], [42, 44, "researcher"], [46, 48, "researcher"], [51, 56, "organisation"], [59, 63, "organisation"], [67, 68, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[23, 24, 34, 34, "related-to", "", false, false], [38, 40, 23, 24, "physical", "", false, false], [38, 40, 23, 24, "role", "", false, false], [42, 44, 23, 24, "physical", "", false, false], [42, 44, 23, 24, "role", "", false, false], [46, 48, 23, 24, "physical", "", false, false], [46, 48, 23, 24, "role", "", false, false], [67, 68, 59, 63, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Antes", "de", "incorporarse", "a", "la", "facultad", "de", "Pennsylvania", "en", "2002", ",", "pas\u00f3", "una", "d\u00e9cada", "(", "1991-2001", ")", "en", "AT", "&", "T", "Labs", "y", "Bell", "Labs", ",", "entre", "otras", "cosas", "como", "jefe", "del", "departamento", "de", "IA", "con", "colegas", "como", "Michael", "L.", "Littman", ",", "David", "A.", "McAllester", "y", "Richard", "S.", "Sutton", ";", "del", "departamento", "de", "investigaci\u00f3n", "de", "sistemas", "seguros", ";", "y", "del", "departamento", "de", "aprendizaje", "autom\u00e1tico", "con", "miembros", "como", "Michael", "Collins", "y", "el", "l\u00edder", ")", "."], "sentence-detokenized": "Antes de incorporarse a la facultad de Pennsylvania en 2002, pas\u00f3 una d\u00e9cada (1991-2001) en AT & T Labs y Bell Labs, entre otras cosas como jefe del departamento de IA con colegas como Michael L. Littman, David A. McAllester y Richard S. Sutton; del departamento de investigaci\u00f3n de sistemas seguros; y del departamento de aprendizaje autom\u00e1tico con miembros como Michael Collins y el l\u00edder).", "token2charspan": [[0, 5], [6, 8], [9, 21], [22, 23], [24, 26], [27, 35], [36, 38], [39, 51], [52, 54], [55, 59], [59, 60], [61, 65], [66, 69], [70, 76], [77, 78], [78, 87], [87, 88], [89, 91], [92, 94], [95, 96], [97, 98], [99, 103], [104, 105], [106, 110], [111, 115], [115, 116], [117, 122], [123, 128], [129, 134], [135, 139], [140, 144], [145, 148], [149, 161], [162, 164], [165, 167], [168, 171], [172, 179], [180, 184], [185, 192], [193, 195], [196, 203], [203, 204], [205, 210], [211, 213], [214, 224], [225, 226], [227, 234], [235, 237], [238, 244], [244, 245], [246, 249], [250, 262], [263, 265], [266, 279], [280, 282], [283, 291], [292, 299], [299, 300], [301, 302], [303, 306], [307, 319], [320, 322], [323, 334], [335, 345], [346, 349], [350, 358], [359, 363], [364, 371], [372, 379], [380, 381], [382, 384], [385, 390], [390, 391], [391, 392]]}
{"doc_key": "ai-test-210", "ner": [[8, 9, "field"], [20, 22, "field"], [26, 28, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 20, 22, "compare", "", false, false], [26, 28, 20, 22, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cuando", "los", "datos", "no", "est\u00e1n", "etiquetados", ",", "el", "aprendizaje", "supervisado", "no", "es", "posible", ",", "y", "se", "requiere", "un", "enfoque", "de", "aprendizaje", "no", "supervisado", "que", "intente", "encontrar", "an\u00e1lisis", "de", "cl\u00fasteres", "naturales", "a", "los", "grupos", ",", "y", "luego", "asignar", "los", "nuevos", "datos", "a", "estos", "grupos", "formados", "."], "sentence-detokenized": "Cuando los datos no est\u00e1n etiquetados, el aprendizaje supervisado no es posible, y se requiere un enfoque de aprendizaje no supervisado que intente encontrar an\u00e1lisis de cl\u00fasteres naturales a los grupos, y luego asignar los nuevos datos a estos grupos formados.", "token2charspan": [[0, 6], [7, 10], [11, 16], [17, 19], [20, 25], [26, 37], [37, 38], [39, 41], [42, 53], [54, 65], [66, 68], [69, 71], [72, 79], [79, 80], [81, 82], [83, 85], [86, 94], [95, 97], [98, 105], [106, 108], [109, 120], [121, 123], [124, 135], [136, 139], [140, 147], [148, 157], [158, 166], [167, 169], [170, 179], [180, 189], [190, 191], [192, 195], [196, 202], [202, 203], [204, 205], [206, 211], [212, 219], [220, 223], [224, 230], [231, 236], [237, 238], [239, 244], [245, 251], [252, 260], [260, 261]]}
{"doc_key": "ai-test-211", "ner": [[4, 4, "field"], [16, 21, "organisation"], [29, 30, "field"], [33, 33, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 16, 21, "origin", "", false, false], [4, 4, 29, 30, "part-of", "", false, false], [4, 4, 33, 33, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Este", "campo", "de", "la", "inform\u00e1tica", "se", "desarroll\u00f3", "en", "los", "a\u00f1os", "50", "en", "instituciones", "acad\u00e9micas", "como", "el", "Laboratorio", "de", "Inteligencia", "Artificial", "del", "MIT", ",", "originalmente", "como", "una", "rama", "de", "la", "inteligencia", "artificial", "y", "la", "rob\u00f3tica", "."], "sentence-detokenized": "Este campo de la inform\u00e1tica se desarroll\u00f3 en los a\u00f1os 50 en instituciones acad\u00e9micas como el Laboratorio de Inteligencia Artificial del MIT, originalmente como una rama de la inteligencia artificial y la rob\u00f3tica.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 16], [17, 28], [29, 31], [32, 42], [43, 45], [46, 49], [50, 54], [55, 57], [58, 60], [61, 74], [75, 85], [86, 90], [91, 93], [94, 105], [106, 108], [109, 121], [122, 132], [133, 136], [137, 140], [140, 141], [142, 155], [156, 160], [161, 164], [165, 169], [170, 172], [173, 175], [176, 188], [189, 199], [200, 201], [202, 204], [205, 213], [213, 214]]}
{"doc_key": "ai-test-212", "ner": [[7, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Tambi\u00e9n", "podr\u00eda", "sustituirse", "por", "la", "ecuaci\u00f3n", "de", "p\u00e9rdidas", "log\u00edsticas", "que", "se", "indica", "a", "continuaci\u00f3n", ":"], "sentence-detokenized": "Tambi\u00e9n podr\u00eda sustituirse por la ecuaci\u00f3n de p\u00e9rdidas log\u00edsticas que se indica a continuaci\u00f3n:", "token2charspan": [[0, 7], [8, 14], [15, 26], [27, 30], [31, 33], [34, 42], [43, 45], [46, 54], [55, 65], [66, 69], [70, 72], [73, 79], [80, 81], [82, 94], [94, 95]]}
{"doc_key": "ai-test-213", "ner": [[1, 4, "organisation"], [7, 11, "organisation"], [15, 19, "university"], [21, 22, "university"], [24, 27, "university"], [29, 32, "university"], [35, 36, "country"], [43, 43, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[1, 4, 43, 43, "related-to", "research_leader_in_field", false, false], [7, 11, 1, 4, "named", "", false, false], [7, 11, 43, 43, "related-to", "research_leader_in_field", false, false], [15, 19, 43, 43, "related-to", "research_leader_in_field", false, false], [21, 22, 43, 43, "related-to", "research_leader_in_field", false, false], [24, 27, 43, 43, "related-to", "research_leader_in_field", false, false], [29, 32, 35, 36, "physical", "", false, false], [29, 32, 43, 43, "related-to", "research_leader_in_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["El", "AbilityLab", "de", "Shirley", "Ryan", "(", "antiguo", "Instituto", "de", "Rehabilitaci\u00f3n", "de", "Chicago", ")", ",", "la", "Universidad", "de", "California", "en", "Berkeley", ",", "el", "MIT", ",", "la", "Universidad", "de", "Stanford", "y", "la", "Universidad", "de", "Twente", "en", "los", "Pa\u00edses", "Bajos", "son", "los", "l\u00edderes", "en", "investigaci\u00f3n", "en", "biomecatr\u00f3nica", "."], "sentence-detokenized": "El AbilityLab de Shirley Ryan (antiguo Instituto de Rehabilitaci\u00f3n de Chicago), la Universidad de California en Berkeley, el MIT, la Universidad de Stanford y la Universidad de Twente en los Pa\u00edses Bajos son los l\u00edderes en investigaci\u00f3n en biomecatr\u00f3nica.", "token2charspan": [[0, 2], [3, 13], [14, 16], [17, 24], [25, 29], [30, 31], [31, 38], [39, 48], [49, 51], [52, 66], [67, 69], [70, 77], [77, 78], [78, 79], [80, 82], [83, 94], [95, 97], [98, 108], [109, 111], [112, 120], [120, 121], [122, 124], [125, 128], [128, 129], [130, 132], [133, 144], [145, 147], [148, 156], [157, 158], [159, 161], [162, 173], [174, 176], [177, 183], [184, 186], [187, 190], [191, 197], [198, 203], [204, 207], [208, 211], [212, 219], [220, 222], [223, 236], [237, 239], [240, 254], [254, 255]]}
{"doc_key": "ai-test-214", "ner": [[29, 34, "metrics"], [45, 48, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Dado", "un", "conjunto", "de", "valores", "predichos", "y", "un", "conjunto", "correspondiente", "de", "valores", "reales", "de", "X", "para", "varios", "periodos", "de", "tiempo", ",", "una", "t\u00e9cnica", "de", "evaluaci\u00f3n", "com\u00fan", "es", "utilizar", "el", "error", "medio", "de", "predicci\u00f3n", "al", "cuadrado", ";", "tambi\u00e9n", "hay", "otras", "medidas", "disponibles", "(", "v\u00e9ase", "previsi\u00f3n", "#", "precisi\u00f3n", "de", "la", "previsi\u00f3n", ")", "."], "sentence-detokenized": "Dado un conjunto de valores predichos y un conjunto correspondiente de valores reales de X para varios periodos de tiempo, una t\u00e9cnica de evaluaci\u00f3n com\u00fan es utilizar el error medio de predicci\u00f3n al cuadrado; tambi\u00e9n hay otras medidas disponibles (v\u00e9ase previsi\u00f3n # precisi\u00f3n de la previsi\u00f3n).", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 19], [20, 27], [28, 37], [38, 39], [40, 42], [43, 51], [52, 67], [68, 70], [71, 78], [79, 85], [86, 88], [89, 90], [91, 95], [96, 102], [103, 111], [112, 114], [115, 121], [121, 122], [123, 126], [127, 134], [135, 137], [138, 148], [149, 154], [155, 157], [158, 166], [167, 169], [170, 175], [176, 181], [182, 184], [185, 195], [196, 198], [199, 207], [207, 208], [209, 216], [217, 220], [221, 226], [227, 234], [235, 246], [247, 248], [248, 253], [254, 263], [264, 265], [266, 275], [276, 278], [279, 281], [282, 291], [291, 292], [292, 293]]}
{"doc_key": "ai-test-215", "ner": [[12, 12, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Otras", "medidas", ",", "como", "la", "proporci\u00f3n", "de", "predicciones", "correctas", "(", "tambi\u00e9n", "denominada", "precisi\u00f3n", ")", ",", "no", "son", "\u00fatiles", "cuando", "las", "dos", "clases", "son", "de", "tama\u00f1os", "muy", "diferentes", "."], "sentence-detokenized": "Otras medidas, como la proporci\u00f3n de predicciones correctas (tambi\u00e9n denominada precisi\u00f3n), no son \u00fatiles cuando las dos clases son de tama\u00f1os muy diferentes.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 22], [23, 33], [34, 36], [37, 49], [50, 59], [60, 61], [61, 68], [69, 79], [80, 89], [89, 90], [90, 91], [92, 94], [95, 98], [99, 105], [106, 112], [113, 116], [117, 120], [121, 127], [128, 131], [132, 134], [135, 142], [143, 146], [147, 157], [157, 158]]}
{"doc_key": "ai-test-216", "ner": [[5, 5, "product"], [13, 19, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 13, 19, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["La", "primera", "versi\u00f3n", "alfa", "de", "OpenCV", "se", "hizo", "p\u00fablica", "en", "la", "Conferencia", "sobre", "Visi\u00f3n", "por", "Computador", "y", "Reconocimiento", "de", "Patrones", "en", "2000", ",", "y", "se", "publicaron", "cinco", "betas", "entre", "2001", "y", "2005", "."], "sentence-detokenized": "La primera versi\u00f3n alfa de OpenCV se hizo p\u00fablica en la Conferencia sobre Visi\u00f3n por Computador y Reconocimiento de Patrones en 2000, y se publicaron cinco betas entre 2001 y 2005.", "token2charspan": [[0, 2], [3, 10], [11, 18], [19, 23], [24, 26], [27, 33], [34, 36], [37, 41], [42, 49], [50, 52], [53, 55], [56, 67], [68, 73], [74, 80], [81, 84], [85, 95], [96, 97], [98, 112], [113, 115], [116, 124], [125, 127], [128, 132], [132, 133], [134, 135], [136, 138], [139, 149], [150, 155], [156, 161], [162, 167], [168, 172], [173, 174], [175, 179], [179, 180]]}
{"doc_key": "ai-test-217", "ner": [[26, 26, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Se", "han", "presentado", "resultados", "que", "dan", "una", "correlaci\u00f3n", "de", "hasta", "0,964", "con", "el", "juicio", "humano", "a", "nivel", "de", "corpus", ",", "en", "comparaci\u00f3n", "con", "el", "logro", "de", "BLEU", "de", "0,817", "en", "el", "mismo", "conjunto", "de", "datos", "."], "sentence-detokenized": "Se han presentado resultados que dan una correlaci\u00f3n de hasta 0,964 con el juicio humano a nivel de corpus, en comparaci\u00f3n con el logro de BLEU de 0,817 en el mismo conjunto de datos.", "token2charspan": [[0, 2], [3, 6], [7, 17], [18, 28], [29, 32], [33, 36], [37, 40], [41, 52], [53, 55], [56, 61], [62, 67], [68, 71], [72, 74], [75, 81], [82, 88], [89, 90], [91, 96], [97, 99], [100, 106], [106, 107], [108, 110], [111, 122], [123, 126], [127, 129], [130, 135], [136, 138], [139, 143], [144, 146], [147, 152], [153, 155], [156, 158], [159, 164], [165, 173], [174, 176], [177, 182], [182, 183]]}
{"doc_key": "ai-test-218", "ner": [[4, 6, "metrics"], [19, 19, "metrics"], [21, 22, "metrics"], [24, 24, "metrics"], [35, 36, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 19, 19, "compare", "", false, false], [4, 6, 21, 22, "compare", "", false, false], [4, 6, 24, 24, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Una", "primera", "versi\u00f3n", "de", "VMAF", "ha", "demostrado", "que", "supera", "a", "otras", "m\u00e9tricas", "de", "calidad", "de", "imagen", "y", "v\u00eddeo", "como", "SSIM", ",", "PSNR", "-HVS", "y", "VQM-VFD", "en", "tres", "de", "cuatro", "conjuntos", "de", "datos", "en", "t\u00e9rminos", "de", "precisi\u00f3n", "de", "predicci\u00f3n", ",", "cuando", "se", "compara", "con", "calificaciones", "subjetivas", "."], "sentence-detokenized": "Una primera versi\u00f3n de VMAF ha demostrado que supera a otras m\u00e9tricas de calidad de imagen y v\u00eddeo como SSIM, PSNR -HVS y VQM-VFD en tres de cuatro conjuntos de datos en t\u00e9rminos de precisi\u00f3n de predicci\u00f3n, cuando se compara con calificaciones subjetivas.", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 22], [23, 27], [28, 30], [31, 41], [42, 45], [46, 52], [53, 54], [55, 60], [61, 69], [70, 72], [73, 80], [81, 83], [84, 90], [91, 92], [93, 98], [99, 103], [104, 108], [108, 109], [110, 114], [115, 119], [120, 121], [122, 129], [130, 132], [133, 137], [138, 140], [141, 147], [148, 157], [158, 160], [161, 166], [167, 169], [170, 178], [179, 181], [182, 191], [192, 194], [195, 205], [205, 206], [207, 213], [214, 216], [217, 224], [225, 228], [229, 243], [244, 254], [254, 255]]}
{"doc_key": "ai-test-219", "ner": [[19, 20, "task"], [26, 28, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[19, 20, 26, 28, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Por", "ejemplo", ",", "la", "ambig\u00fcedad", "de", "\"", "rat\u00f3n", "\"", "(", "animal", "o", "dispositivo", ")", "no", "es", "relevante", "en", "la", "traducci\u00f3n", "autom\u00e1tica", ",", "pero", "s\u00ed", "en", "la", "recuperaci\u00f3n", "de", "informaci\u00f3n", "."], "sentence-detokenized": "Por ejemplo, la ambig\u00fcedad de \"rat\u00f3n\" (animal o dispositivo) no es relevante en la traducci\u00f3n autom\u00e1tica, pero s\u00ed en la recuperaci\u00f3n de informaci\u00f3n.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 26], [27, 29], [30, 31], [31, 36], [36, 37], [38, 39], [39, 45], [46, 47], [48, 59], [59, 60], [61, 63], [64, 66], [67, 76], [77, 79], [80, 82], [83, 93], [94, 104], [104, 105], [106, 110], [111, 113], [114, 116], [117, 119], [120, 132], [133, 135], [136, 147], [147, 148]]}
{"doc_key": "ai-test-220", "ner": [[0, 2, "algorithm"], [8, 10, "field"], [13, 15, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 0, 2, "usage", "", false, false], [13, 15, 8, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["El", "hashing", "geom\u00e9trico", "se", "propuso", "originalmente", "en", "la", "visi\u00f3n", "por", "ordenador", "para", "el", "reconocimiento", "de", "objetos", "en", "2D", "y", "3D", ","], "sentence-detokenized": "El hashing geom\u00e9trico se propuso originalmente en la visi\u00f3n por ordenador para el reconocimiento de objetos en 2D y 3D,", "token2charspan": [[0, 2], [3, 10], [11, 21], [22, 24], [25, 32], [33, 46], [47, 49], [50, 52], [53, 59], [60, 63], [64, 73], [74, 78], [79, 81], [82, 96], [97, 99], [100, 107], [108, 110], [111, 113], [114, 115], [116, 118], [118, 119]]}
{"doc_key": "ai-test-221", "ner": [[8, 9, "field"], [13, 15, "field"], [17, 20, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 15, 8, 9, "part-of", "subfield", false, false], [17, 20, 8, 9, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Forma", "una", "de", "las", "tres", "categor\u00edas", "principales", "del", "aprendizaje", "autom\u00e1tico", ",", "junto", "con", "el", "aprendizaje", "supervisado", "y", "el", "aprendizaje", "por", "refuerzo", "."], "sentence-detokenized": "Forma una de las tres categor\u00edas principales del aprendizaje autom\u00e1tico, junto con el aprendizaje supervisado y el aprendizaje por refuerzo.", "token2charspan": [[0, 5], [6, 9], [10, 12], [13, 16], [17, 21], [22, 32], [33, 44], [45, 48], [49, 60], [61, 71], [71, 72], [73, 78], [79, 82], [83, 85], [86, 97], [98, 109], [110, 111], [112, 114], [115, 126], [127, 130], [131, 139], [139, 140]]}
{"doc_key": "ai-test-222", "ner": [[0, 3, "field"], [18, 19, "field"], [22, 24, "field"], [27, 29, "field"], [32, 35, "field"], [38, 42, "field"], [44, 46, "field"], [49, 51, "field"], [54, 54, "field"], [57, 58, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 3, 18, 19, "part-of", "subfield", false, false], [0, 3, 22, 24, "part-of", "subfield", false, false], [0, 3, 27, 29, "part-of", "subfield", false, false], [0, 3, 32, 35, "part-of", "subfield", false, false], [0, 3, 38, 42, "part-of", "subfield", false, false], [0, 3, 44, 46, "part-of", "subfield", false, false], [0, 3, 49, 51, "part-of", "subfield", false, false], [0, 3, 54, 54, "part-of", "subfield", false, false], [0, 3, 57, 58, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["El", "aprendizaje", "por", "refuerzo", ",", "debido", "a", "su", "generalidad", ",", "se", "estudia", "en", "muchas", "otras", "disciplinas", ",", "como", "los", "juegos", ",", "la", "teor\u00eda", "del", "control", ",", "la", "investigaci\u00f3n", "de", "operaciones", ",", "la", "teor\u00eda", "de", "la", "informaci\u00f3n", ",", "la", "optimizaci\u00f3n", "basada", "en", "la", "simulaci\u00f3n", ",", "los", "sistemas", "multiagente", ",", "la", "inteligencia", "de", "enjambre", ",", "la", "estad\u00edstica", "y", "los", "algoritmos", "gen\u00e9ticos", "."], "sentence-detokenized": "El aprendizaje por refuerzo, debido a su generalidad, se estudia en muchas otras disciplinas, como los juegos, la teor\u00eda del control, la investigaci\u00f3n de operaciones, la teor\u00eda de la informaci\u00f3n, la optimizaci\u00f3n basada en la simulaci\u00f3n, los sistemas multiagente, la inteligencia de enjambre, la estad\u00edstica y los algoritmos gen\u00e9ticos.", "token2charspan": [[0, 2], [3, 14], [15, 18], [19, 27], [27, 28], [29, 35], [36, 37], [38, 40], [41, 52], [52, 53], [54, 56], [57, 64], [65, 67], [68, 74], [75, 80], [81, 92], [92, 93], [94, 98], [99, 102], [103, 109], [109, 110], [111, 113], [114, 120], [121, 124], [125, 132], [132, 133], [134, 136], [137, 150], [151, 153], [154, 165], [165, 166], [167, 169], [170, 176], [177, 179], [180, 182], [183, 194], [194, 195], [196, 198], [199, 211], [212, 218], [219, 221], [222, 224], [225, 235], [235, 236], [237, 240], [241, 249], [250, 261], [261, 262], [263, 265], [266, 278], [279, 281], [282, 290], [290, 291], [292, 294], [295, 306], [307, 308], [309, 312], [313, 323], [324, 333], [333, 334]]}
{"doc_key": "ai-test-223", "ner": [[0, 3, "field"], [9, 10, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 9, 10, "related-to", "", false, false], [0, 3, 13, 14, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["El", "reconocimiento", "de", "patrones", "est\u00e1", "estrechamente", "relacionado", "con", "la", "inteligencia", "artificial", "y", "el", "aprendizaje", "autom\u00e1tico", ","], "sentence-detokenized": "El reconocimiento de patrones est\u00e1 estrechamente relacionado con la inteligencia artificial y el aprendizaje autom\u00e1tico,", "token2charspan": [[0, 2], [3, 17], [18, 20], [21, 29], [30, 34], [35, 48], [49, 60], [61, 64], [65, 67], [68, 80], [81, 91], [92, 93], [94, 96], [97, 108], [109, 119], [119, 120]]}
{"doc_key": "ai-test-224", "ner": [[12, 13, "algorithm"], [15, 16, "field"], [18, 20, "field"], [31, 33, "task"], [36, 36, "task"], [39, 41, "task"], [44, 45, "algorithm"], [48, 51, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[12, 13, 15, 16, "related-to", "", false, false], [12, 13, 18, 20, "related-to", "", false, false], [31, 33, 12, 13, "usage", "", true, false], [36, 36, 12, 13, "usage", "", true, false], [39, 41, 12, 13, "usage", "", true, false], [44, 45, 12, 13, "usage", "", true, false], [48, 51, 12, 13, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["El", "software", "se", "utiliza", "para", "dise\u00f1ar", ",", "entrenar", "y", "desplegar", "modelos", "de", "redes", "neuronales", "(", "aprendizaje", "supervisado", "y", "aprendizaje", "no", "supervisado", ")", "para", "realizar", "una", "amplia", "variedad", "de", "tareas", "como", "la", "miner\u00eda", "de", "datos", ",", "la", "clasificaci\u00f3n", ",", "la", "aproximaci\u00f3n", "de", "funciones", ",", "la", "regresi\u00f3n", "multivariante", "y", "la", "predicci\u00f3n", "de", "series", "temporales", "."], "sentence-detokenized": "El software se utiliza para dise\u00f1ar, entrenar y desplegar modelos de redes neuronales (aprendizaje supervisado y aprendizaje no supervisado) para realizar una amplia variedad de tareas como la miner\u00eda de datos, la clasificaci\u00f3n, la aproximaci\u00f3n de funciones, la regresi\u00f3n multivariante y la predicci\u00f3n de series temporales.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 22], [23, 27], [28, 35], [35, 36], [37, 45], [46, 47], [48, 57], [58, 65], [66, 68], [69, 74], [75, 85], [86, 87], [87, 98], [99, 110], [111, 112], [113, 124], [125, 127], [128, 139], [139, 140], [141, 145], [146, 154], [155, 158], [159, 165], [166, 174], [175, 177], [178, 184], [185, 189], [190, 192], [193, 200], [201, 203], [204, 209], [209, 210], [211, 213], [214, 227], [227, 228], [229, 231], [232, 244], [245, 247], [248, 257], [257, 258], [259, 261], [262, 271], [272, 285], [286, 287], [288, 290], [291, 301], [302, 304], [305, 311], [312, 322], [322, 323]]}
{"doc_key": "ai-test-225", "ner": [[8, 15, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["En", "2016", ",", "fue", "elegido", "miembro", "de", "la", "Asociaci\u00f3n", "para", "el", "Avance", "de", "la", "Inteligencia", "Artificial", "."], "sentence-detokenized": "En 2016, fue elegido miembro de la Asociaci\u00f3n para el Avance de la Inteligencia Artificial.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 20], [21, 28], [29, 31], [32, 34], [35, 45], [46, 50], [51, 53], [54, 60], [61, 63], [64, 66], [67, 79], [80, 90], [90, 91]]}
{"doc_key": "ai-test-226", "ner": [[4, 7, "organisation"], [14, 20, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Es", "miembro", "de", "la", "Academia", "Nacional", "de", "Ciencias", "(", "desde", "2005", ")", "y", "de", "la", "Academia", "Americana", "de", "Artes", "y", "Ciencias", "(", "desde", "2009", ")", ","], "sentence-detokenized": "Es miembro de la Academia Nacional de Ciencias (desde 2005) y de la Academia Americana de Artes y Ciencias (desde 2009),", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 16], [17, 25], [26, 34], [35, 37], [38, 46], [47, 48], [48, 53], [54, 58], [58, 59], [60, 61], [62, 64], [65, 67], [68, 76], [77, 86], [87, 89], [90, 95], [96, 97], [98, 106], [107, 108], [108, 113], [114, 118], [118, 119], [119, 120]]}
{"doc_key": "ai-test-227", "ner": [[2, 5, "misc"], [12, 13, "product"], [19, 19, "country"], [21, 21, "country"], [26, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 13, 2, 5, "temporal", "", false, false], [12, 13, 19, 19, "physical", "", false, false], [12, 13, 21, 21, "physical", "", false, false], [12, 13, 26, 30, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Durante", "la", "Guerra", "del", "Yom", "Kippur", "de", "1973", ",", "las", "bater\u00edas", "de", "misiles", "tierra-aire", "suministradas", "por", "los", "sovi\u00e9ticos", "en", "Egipto", "y", "Siria", "causaron", "graves", "da\u00f1os", "a", "los", "aviones", "de", "combate", "israel\u00edes", "."], "sentence-detokenized": "Durante la Guerra del Yom Kippur de 1973, las bater\u00edas de misiles tierra-aire suministradas por los sovi\u00e9ticos en Egipto y Siria causaron graves da\u00f1os a los aviones de combate israel\u00edes.", "token2charspan": [[0, 7], [8, 10], [11, 17], [18, 21], [22, 25], [26, 32], [33, 35], [36, 40], [40, 41], [42, 45], [46, 54], [55, 57], [58, 65], [66, 77], [78, 91], [92, 95], [96, 99], [100, 110], [111, 113], [114, 120], [121, 122], [123, 128], [129, 137], [138, 144], [145, 150], [151, 152], [153, 156], [157, 164], [165, 167], [168, 175], [176, 185], [185, 186]]}
{"doc_key": "ai-test-228", "ner": [[12, 13, "product"], [17, 20, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 20, 12, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Otro", "recurso", "(", "gratuito", "pero", "con", "derechos", "de", "autor", ")", "es", "el", "libro", "HTK", "(", "y", "el", "kit", "de", "herramientas", "HTK", "que", "lo", "acompa\u00f1a", ")", "."], "sentence-detokenized": "Otro recurso (gratuito pero con derechos de autor) es el libro HTK (y el kit de herramientas HTK que lo acompa\u00f1a).", "token2charspan": [[0, 4], [5, 12], [13, 14], [14, 22], [23, 27], [28, 31], [32, 40], [41, 43], [44, 49], [49, 50], [51, 53], [54, 56], [57, 62], [63, 66], [67, 68], [68, 69], [70, 72], [73, 76], [77, 79], [80, 92], [93, 96], [97, 100], [101, 103], [104, 112], [112, 113], [113, 114]]}
{"doc_key": "ai-test-229", "ner": [[9, 12, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["-", "se", "tomaron", "en", "el", "Simposio", "de", "Primavera", "de", "la", "AAAI", "de", "2004", ",", "en", "el", "que", "ling\u00fcistas", ",", "inform\u00e1ticos", "y", "otros", "investigadores", "interesados", "alinearon", "por", "primera", "vez", "sus", "intereses", "y", "propusieron", "tareas", "compartidas", "y", "conjuntos", "de", "datos", "de", "referencia", "para", "la", "investigaci\u00f3n", "computacional", "sistem\u00e1tica", "del", "afecto", ",", "el", "atractivo", ",", "la", "subjetividad", "y", "el", "sentimiento", "en", "el", "texto", "."], "sentence-detokenized": "- se tomaron en el Simposio de Primavera de la AAAI de 2004, en el que ling\u00fcistas, inform\u00e1ticos y otros investigadores interesados alinearon por primera vez sus intereses y propusieron tareas compartidas y conjuntos de datos de referencia para la investigaci\u00f3n computacional sistem\u00e1tica del afecto, el atractivo, la subjetividad y el sentimiento en el texto.", "token2charspan": [[0, 1], [2, 4], [5, 12], [13, 15], [16, 18], [19, 27], [28, 30], [31, 40], [41, 43], [44, 46], [47, 51], [52, 54], [55, 59], [59, 60], [61, 63], [64, 66], [67, 70], [71, 81], [81, 82], [83, 95], [96, 97], [98, 103], [104, 118], [119, 130], [131, 140], [141, 144], [145, 152], [153, 156], [157, 160], [161, 170], [171, 172], [173, 184], [185, 191], [192, 203], [204, 205], [206, 215], [216, 218], [219, 224], [225, 227], [228, 238], [239, 243], [244, 246], [247, 260], [261, 274], [275, 286], [287, 290], [291, 297], [297, 298], [299, 301], [302, 311], [311, 312], [313, 315], [316, 328], [329, 330], [331, 333], [334, 345], [346, 348], [349, 351], [352, 357], [357, 358]]}
{"doc_key": "ai-test-230", "ner": [[11, 12, "task"], [24, 27, "task"], [30, 33, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Una", "misma", "parrilla", "puede", "ser", "analizada", "tanto", "en", "su", "contenido", "(", "inspecci\u00f3n", "ocular", ")", "como", "en", "su", "estructura", "(", "las", "principales", "t\u00e9cnicas", "utilizadas", "son", "el", "an\u00e1lisis", "de", "conglomerados", ",", "el", "an\u00e1lisis", "de", "componentes", "principales", "y", "una", "serie", "de", "\u00edndices", "estructurales", "relacionados", "con", "la", "complejidad", "y", "el", "alcance", "de", "las", "calificaciones", ")", "."], "sentence-detokenized": "Una misma parrilla puede ser analizada tanto en su contenido (inspecci\u00f3n ocular) como en su estructura (las principales t\u00e9cnicas utilizadas son el an\u00e1lisis de conglomerados, el an\u00e1lisis de componentes principales y una serie de \u00edndices estructurales relacionados con la complejidad y el alcance de las calificaciones).", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 24], [25, 28], [29, 38], [39, 44], [45, 47], [48, 50], [51, 60], [61, 62], [62, 72], [73, 79], [79, 80], [81, 85], [86, 88], [89, 91], [92, 102], [103, 104], [104, 107], [108, 119], [120, 128], [129, 139], [140, 143], [144, 146], [147, 155], [156, 158], [159, 172], [172, 173], [174, 176], [177, 185], [186, 188], [189, 200], [201, 212], [213, 214], [215, 218], [219, 224], [225, 227], [228, 235], [236, 249], [250, 262], [263, 266], [267, 269], [270, 281], [282, 283], [284, 286], [287, 294], [295, 297], [298, 301], [302, 316], [316, 317], [317, 318]]}
{"doc_key": "ai-test-231", "ner": [[5, 5, "organisation"], [10, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["En", "2018", "se", "consideraba", "que", "Toyota", "estaba", "atrasada", "en", "el", "coche", "de", "autoconducci\u00f3n", "y", "que", "necesitaba", "innovar", "."], "sentence-detokenized": "En 2018 se consideraba que Toyota estaba atrasada en el coche de autoconducci\u00f3n y que necesitaba innovar.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 22], [23, 26], [27, 33], [34, 40], [41, 49], [50, 52], [53, 55], [56, 61], [62, 64], [65, 79], [80, 81], [82, 85], [86, 96], [97, 104], [104, 105]]}
{"doc_key": "ai-test-232", "ner": [[49, 52, "misc"], [55, 58, "misc"], [61, 64, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Estos", "objetivos", "incluyen", "objetos", "naturales", "como", "el", "suelo", ",", "el", "mar", ",", "las", "precipitaciones", "(", "como", "la", "lluvia", ",", "la", "nieve", "o", "el", "granizo", ")", ",", "las", "tormentas", "de", "arena", ",", "los", "animales", "(", "especialmente", "los", "p\u00e1jaros", ")", ",", "las", "turbulencias", "atmosf\u00e9ricas", "y", "otros", "efectos", "atmosf\u00e9ricos", ",", "como", "los", "reflejos", "de", "la", "ionosfera", ",", "las", "estelas", "de", "los", "meteoritos", "y", "la", "dispersi\u00f3n", "de", "tres", "cuerpos", "."], "sentence-detokenized": "Estos objetivos incluyen objetos naturales como el suelo, el mar, las precipitaciones (como la lluvia, la nieve o el granizo), las tormentas de arena, los animales (especialmente los p\u00e1jaros), las turbulencias atmosf\u00e9ricas y otros efectos atmosf\u00e9ricos, como los reflejos de la ionosfera, las estelas de los meteoritos y la dispersi\u00f3n de tres cuerpos.", "token2charspan": [[0, 5], [6, 15], [16, 24], [25, 32], [33, 42], [43, 47], [48, 50], [51, 56], [56, 57], [58, 60], [61, 64], [64, 65], [66, 69], [70, 85], [86, 87], [87, 91], [92, 94], [95, 101], [101, 102], [103, 105], [106, 111], [112, 113], [114, 116], [117, 124], [124, 125], [125, 126], [127, 130], [131, 140], [141, 143], [144, 149], [149, 150], [151, 154], [155, 163], [164, 165], [165, 178], [179, 182], [183, 190], [190, 191], [191, 192], [193, 196], [197, 209], [210, 222], [223, 224], [225, 230], [231, 238], [239, 251], [251, 252], [253, 257], [258, 261], [262, 270], [271, 273], [274, 276], [277, 286], [286, 287], [288, 291], [292, 299], [300, 302], [303, 306], [307, 317], [318, 319], [320, 322], [323, 333], [334, 336], [337, 341], [342, 349], [349, 350]]}
{"doc_key": "ai-test-233", "ner": [[21, 21, "product"], [44, 45, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["En", "la", "planificaci\u00f3n", "y", "el", "control", ",", "la", "diferencia", "esencial", "entre", "los", "humanoides", "y", "otros", "tipos", "de", "robots", "(", "como", "los", "industriales", ")", "es", "que", "el", "movimiento", "del", "robot", "debe", "ser", "similar", "al", "humano", ",", "utilizando", "la", "locomoci\u00f3n", "de", "las", "piernas", ",", "especialmente", "la", "marcha", "b\u00edpeda", "."], "sentence-detokenized": "En la planificaci\u00f3n y el control, la diferencia esencial entre los humanoides y otros tipos de robots (como los industriales) es que el movimiento del robot debe ser similar al humano, utilizando la locomoci\u00f3n de las piernas, especialmente la marcha b\u00edpeda.", "token2charspan": [[0, 2], [3, 5], [6, 19], [20, 21], [22, 24], [25, 32], [32, 33], [34, 36], [37, 47], [48, 56], [57, 62], [63, 66], [67, 77], [78, 79], [80, 85], [86, 91], [92, 94], [95, 101], [102, 103], [103, 107], [108, 111], [112, 124], [124, 125], [126, 128], [129, 132], [133, 135], [136, 146], [147, 150], [151, 156], [157, 161], [162, 165], [166, 173], [174, 176], [177, 183], [183, 184], [185, 195], [196, 198], [199, 209], [210, 212], [213, 216], [217, 224], [224, 225], [226, 239], [240, 242], [243, 249], [250, 256], [256, 257]]}
{"doc_key": "ai-test-234", "ner": [[1, 3, "algorithm"], [11, 12, "misc"], [15, 15, "metrics"], [20, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["El", "descenso", "del", "gradiente", "puede", "tardar", "muchas", "iteraciones", "en", "calcular", "un", "m\u00ednimo", "local", "con", "la", "precisi\u00f3n", "requerida", ",", "si", "la", "curvatura", "en", "diferentes", "direcciones", "es", "muy", "diferente", "para", "la", "funci\u00f3n", "dada", "."], "sentence-detokenized": "El descenso del gradiente puede tardar muchas iteraciones en calcular un m\u00ednimo local con la precisi\u00f3n requerida, si la curvatura en diferentes direcciones es muy diferente para la funci\u00f3n dada.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 25], [26, 31], [32, 38], [39, 45], [46, 57], [58, 60], [61, 69], [70, 72], [73, 79], [80, 85], [86, 89], [90, 92], [93, 102], [103, 112], [112, 113], [114, 116], [117, 119], [120, 129], [130, 132], [133, 143], [144, 155], [156, 158], [159, 162], [163, 172], [173, 177], [178, 180], [181, 188], [189, 193], [193, 194]]}
{"doc_key": "ai-test-235", "ner": [[1, 7, "misc"], [12, 13, "misc"], [18, 23, "conference"], [26, 26, "location"], [28, 28, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 7, 12, 13, "part-of", "", true, false], [18, 23, 26, 26, "physical", "", false, true], [26, 26, 28, 28, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "RoboCup", "2D", "Soccer", "Simulation", "League", "de", "1997", "fue", "la", "primera", "competici\u00f3n", "de", "RoboCup", "promovida", "conjuntamente", "con", "la", "International", "Joint", "Conference", "on", "Artificial", "Intelligence", "celebrada", "en", "Nagoya", ",", "Jap\u00f3n", ",", "del", "23", "al", "29", "de", "agosto", "de", "1997", "."], "sentence-detokenized": "La RoboCup 2D Soccer Simulation League de 1997 fue la primera competici\u00f3n de RoboCup promovida conjuntamente con la International Joint Conference on Artificial Intelligence celebrada en Nagoya, Jap\u00f3n, del 23 al 29 de agosto de 1997.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 20], [21, 31], [32, 38], [39, 41], [42, 46], [47, 50], [51, 53], [54, 61], [62, 73], [74, 76], [77, 84], [85, 94], [95, 108], [109, 112], [113, 115], [116, 129], [130, 135], [136, 146], [147, 149], [150, 160], [161, 173], [174, 183], [184, 186], [187, 193], [193, 194], [195, 200], [200, 201], [202, 205], [206, 208], [209, 211], [212, 214], [215, 217], [218, 224], [225, 227], [228, 232], [232, 233]]}
{"doc_key": "ai-test-236", "ner": [[7, 7, "programlang"], [12, 12, "programlang"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Otras", "opciones", "de", "programaci\u00f3n", "incluyen", "un", "entorno", "Python", "integrado", "y", "una", "consola", "R", ",", "adem\u00e1s", "de", "soporte", "para", "Rserve", "."], "sentence-detokenized": "Otras opciones de programaci\u00f3n incluyen un entorno Python integrado y una consola R, adem\u00e1s de soporte para Rserve.", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 30], [31, 39], [40, 42], [43, 50], [51, 57], [58, 67], [68, 69], [70, 73], [74, 81], [82, 83], [83, 84], [85, 91], [92, 94], [95, 102], [103, 107], [108, 114], [114, 115]]}
{"doc_key": "ai-test-237", "ner": [[1, 1, "location"], [7, 8, "field"], [12, 12, "field"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"], [33, 35, "field"], [41, 42, "field"], [46, 49, "field"], [55, 56, "field"], [59, 62, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[15, 16, 12, 12, "related-to", "contributes_to_field", true, false], [18, 19, 12, 12, "related-to", "contributes_to_field", true, false], [21, 22, 12, 12, "related-to", "contributes_to_field", true, false], [46, 49, 41, 42, "part-of", "", false, false], [55, 56, 46, 49, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Desde", "Bonn", "ha", "contribuido", "fundamentalmente", "a", "la", "inteligencia", "artificial", "y", "a", "la", "rob\u00f3tica", "(", "con", "Wolfram", "Burgard", ",", "Dieter", "Fox", ",", "Sebastian", "Thrun", "entre", "sus", "alumnos", ")", ",", "y", "al", "desarrollo", "de", "la", "ingenier\u00eda", "del", "software", ",", "en", "particular", "en", "la", "ingenier\u00eda", "civil", ",", "y", "de", "los", "sistemas", "de", "informaci\u00f3n", ",", "en", "particular", "en", "las", "geociencias", ".", "Gan\u00f3", "el", "premio", "AAAI", "Classic", "Paper", "de", "2016.2014", "."], "sentence-detokenized": "Desde Bonn ha contribuido fundamentalmente a la inteligencia artificial y a la rob\u00f3tica (con Wolfram Burgard, Dieter Fox, Sebastian Thrun entre sus alumnos), y al desarrollo de la ingenier\u00eda del software, en particular en la ingenier\u00eda civil, y de los sistemas de informaci\u00f3n, en particular en las geociencias. Gan\u00f3 el premio AAAI Classic Paper de 2016.2014.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 25], [26, 42], [43, 44], [45, 47], [48, 60], [61, 71], [72, 73], [74, 75], [76, 78], [79, 87], [88, 89], [89, 92], [93, 100], [101, 108], [108, 109], [110, 116], [117, 120], [120, 121], [122, 131], [132, 137], [138, 143], [144, 147], [148, 155], [155, 156], [156, 157], [158, 159], [160, 162], [163, 173], [174, 176], [177, 179], [180, 190], [191, 194], [195, 203], [203, 204], [205, 207], [208, 218], [219, 221], [222, 224], [225, 235], [236, 241], [241, 242], [243, 244], [245, 247], [248, 251], [252, 260], [261, 263], [264, 275], [275, 276], [277, 279], [280, 290], [291, 293], [294, 297], [298, 309], [309, 310], [311, 315], [316, 318], [319, 325], [326, 330], [331, 338], [339, 344], [345, 347], [348, 357], [357, 358]]}
{"doc_key": "ai-test-238", "ner": [[2, 9, "conference"], [17, 19, "location"], [21, 21, "location"], [23, 23, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 9, 17, 19, "physical", "", false, false], [17, 19, 21, 21, "physical", "", false, false], [21, 21, 23, 23, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "primera", "edici\u00f3n", "estadounidense", "de", "la", "Campus", "Party", "tendr\u00e1", "lugar", "del", "20", "al", "22", "de", "agosto", "en", "el", "TCF", "Center", "de", "Detroit", ",", "Michigan", "."], "sentence-detokenized": "La primera edici\u00f3n estadounidense de la Campus Party tendr\u00e1 lugar del 20 al 22 de agosto en el TCF Center de Detroit, Michigan.", "token2charspan": [[0, 2], [3, 10], [11, 18], [19, 33], [34, 36], [37, 39], [40, 46], [47, 52], [53, 59], [60, 65], [66, 69], [70, 72], [73, 75], [76, 78], [79, 81], [82, 88], [89, 91], [92, 94], [95, 98], [99, 105], [106, 108], [109, 116], [116, 117], [118, 126], [126, 127]]}
{"doc_key": "ai-test-239", "ner": [[2, 3, "researcher"], [6, 7, "researcher"], [9, 9, "researcher"], [12, 13, "misc"], [26, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 12, 13, "win-defeat", "", false, false], [6, 7, 12, 13, "win-defeat", "", false, false], [9, 9, 12, 13, "win-defeat", "", false, false], [12, 13, 26, 29, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Junto", "con", "Yann", "LeCun", ",", "y", "Yoshua", "Bengio", ",", "Hinton", "gan\u00f3", "el", "Premio", "Turing", "2018", "por", "los", "avances", "conceptuales", "y", "de", "ingenier\u00eda", "que", "han", "hecho", "de", "las", "redes", "neuronales", "profundas", "un", "componente", "cr\u00edtico", "de", "la", "computaci\u00f3n", "."], "sentence-detokenized": "Junto con Yann LeCun, y Yoshua Bengio, Hinton gan\u00f3 el Premio Turing 2018 por los avances conceptuales y de ingenier\u00eda que han hecho de las redes neuronales profundas un componente cr\u00edtico de la computaci\u00f3n.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 20], [20, 21], [22, 23], [24, 30], [31, 37], [37, 38], [39, 45], [46, 50], [51, 53], [54, 60], [61, 67], [68, 72], [73, 76], [77, 80], [81, 88], [89, 101], [102, 103], [104, 106], [107, 117], [118, 121], [122, 125], [126, 131], [132, 134], [135, 138], [139, 144], [145, 155], [156, 165], [166, 168], [169, 179], [180, 187], [188, 190], [191, 193], [194, 205], [205, 206]]}
{"doc_key": "ai-test-240", "ner": [[0, 2, "product"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 9, 9, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Euler", "Math", "Toolbox", "utiliza", "un", "lenguaje", "matricial", "similar", "a", "MATLAB", ",", "un", "sistema", "que", "se", "ven\u00eda", "desarrollando", "desde", "los", "a\u00f1os", "70", "."], "sentence-detokenized": "Euler Math Toolbox utiliza un lenguaje matricial similar a MATLAB, un sistema que se ven\u00eda desarrollando desde los a\u00f1os 70.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 26], [27, 29], [30, 38], [39, 48], [49, 56], [57, 58], [59, 65], [65, 66], [67, 69], [70, 77], [78, 81], [82, 84], [85, 90], [91, 104], [105, 110], [111, 114], [115, 119], [120, 122], [122, 123]]}
{"doc_key": "ai-test-241", "ner": [[12, 12, "programlang"], [14, 15, "programlang"], [17, 17, "programlang"], [19, 19, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Algunos", "lenguajes", "lo", "hacen", "posible", "de", "forma", "portable", "(", "por", "ejemplo", ",", "Scheme", ",", "Common", "Lisp", ",", "Perl", "o", "D", ")", "."], "sentence-detokenized": "Algunos lenguajes lo hacen posible de forma portable (por ejemplo, Scheme, Common Lisp, Perl o D).", "token2charspan": [[0, 7], [8, 17], [18, 20], [21, 26], [27, 34], [35, 37], [38, 43], [44, 52], [53, 54], [54, 57], [58, 65], [65, 66], [67, 73], [73, 74], [75, 81], [82, 86], [86, 87], [88, 92], [93, 94], [95, 96], [96, 97], [97, 98]]}
{"doc_key": "ai-test-242", "ner": [[7, 7, "misc"], [9, 10, "researcher"], [12, 13, "researcher"], [25, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 9, 10, "artifact", "", false, false], [7, 7, 12, 13, "artifact", "", false, false], [7, 7, 25, 26, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["En", "1969", ",", "un", "famoso", "libro", "titulado", "Perceptrons", "de", "Marvin", "Minsky", "y", "Seymour", "Papert", "demostr\u00f3", "que", "era", "imposible", "que", "estas", "clases", "de", "redes", "aprendieran", "una", "funci\u00f3n", "XOR", "."], "sentence-detokenized": "En 1969, un famoso libro titulado Perceptrons de Marvin Minsky y Seymour Papert demostr\u00f3 que era imposible que estas clases de redes aprendieran una funci\u00f3n XOR.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 18], [19, 24], [25, 33], [34, 45], [46, 48], [49, 55], [56, 62], [63, 64], [65, 72], [73, 79], [80, 88], [89, 92], [93, 96], [97, 106], [107, 110], [111, 116], [117, 123], [124, 126], [127, 132], [133, 144], [145, 148], [149, 156], [157, 160], [160, 161]]}
{"doc_key": "ai-test-243", "ner": [[4, 8, "misc"], [12, 12, "product"], [18, 24, "organisation"], [29, 35, "organisation"], [39, 42, "location"], [44, 44, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[18, 24, 12, 12, "usage", "", false, false], [18, 24, 39, 42, "physical", "", false, false], [29, 35, 18, 24, "named", "", false, false], [39, 42, 44, 44, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Un", "gran", "n\u00famero", "de", "documentos", "cient\u00edficos", "y", "t\u00e9cnicos", "rusos", "se", "tradujeron", "con", "SYSTRAN", "bajo", "los", "auspicios", "de", "la", "Divisi\u00f3n", "de", "Tecnolog\u00eda", "Extranjera", "de", "la", "USAF", "(", "m\u00e1s", "tarde", "el", "Centro", "Nacional", "de", "Inteligencia", "A\u00e9rea", "y", "Espacial", ")", "en", "la", "base", "a\u00e9rea", "de", "Wright-Patterson", ",", "Ohio", "."], "sentence-detokenized": "Un gran n\u00famero de documentos cient\u00edficos y t\u00e9cnicos rusos se tradujeron con SYSTRAN bajo los auspicios de la Divisi\u00f3n de Tecnolog\u00eda Extranjera de la USAF (m\u00e1s tarde el Centro Nacional de Inteligencia A\u00e9rea y Espacial) en la base a\u00e9rea de Wright-Patterson, Ohio.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 17], [18, 28], [29, 40], [41, 42], [43, 51], [52, 57], [58, 60], [61, 71], [72, 75], [76, 83], [84, 88], [89, 92], [93, 102], [103, 105], [106, 108], [109, 117], [118, 120], [121, 131], [132, 142], [143, 145], [146, 148], [149, 153], [154, 155], [155, 158], [159, 164], [165, 167], [168, 174], [175, 183], [184, 186], [187, 199], [200, 205], [206, 207], [208, 216], [216, 217], [218, 220], [221, 223], [224, 228], [229, 234], [235, 237], [238, 254], [254, 255], [256, 260], [260, 261]]}
{"doc_key": "ai-test-244", "ner": [[0, 2, "field"], [7, 9, "field"], [19, 20, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["El", "aprendizaje", "semisupervisado", "se", "sit\u00faa", "entre", "el", "aprendizaje", "no", "supervisado", "(", "sin", "datos", "de", "entrenamiento", "etiquetados", ")", "y", "el", "aprendizaje", "supervisado", "(", "con", "datos", "de", "entrenamiento", "completamente", "etiquetados", ")", "."], "sentence-detokenized": "El aprendizaje semisupervisado se sit\u00faa entre el aprendizaje no supervisado (sin datos de entrenamiento etiquetados) y el aprendizaje supervisado (con datos de entrenamiento completamente etiquetados).", "token2charspan": [[0, 2], [3, 14], [15, 30], [31, 33], [34, 39], [40, 45], [46, 48], [49, 60], [61, 63], [64, 75], [76, 77], [77, 80], [81, 86], [87, 89], [90, 103], [104, 115], [115, 116], [117, 118], [119, 121], [122, 133], [134, 145], [146, 147], [147, 150], [151, 156], [157, 159], [160, 173], [174, 187], [188, 199], [199, 200], [200, 201]]}
{"doc_key": "ai-test-245", "ner": [[0, 3, "algorithm"], [8, 10, "algorithm"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 8, 10, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["El", "modelo", "Ann", "-gram", "es", "un", "tipo", "de", "modelo", "ling\u00fc\u00edstico", "probabil\u00edstico", "para", "predecir", "el", "siguiente", "elemento", "de", "dicha", "secuencia", "en", "forma", "de", "un", "modelo", "de", "Markov", "de", "(", "n", "-", "1", ")", "orden.eficiente", "."], "sentence-detokenized": "El modelo Ann -gram es un tipo de modelo ling\u00fc\u00edstico probabil\u00edstico para predecir el siguiente elemento de dicha secuencia en forma de un modelo de Markov de (n - 1) orden.eficiente.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 19], [20, 22], [23, 25], [26, 30], [31, 33], [34, 40], [41, 52], [53, 67], [68, 72], [73, 81], [82, 84], [85, 94], [95, 103], [104, 106], [107, 112], [113, 122], [123, 125], [126, 131], [132, 134], [135, 137], [138, 144], [145, 147], [148, 154], [155, 157], [158, 159], [159, 160], [161, 162], [163, 164], [164, 165], [166, 181], [181, 182]]}
{"doc_key": "ai-test-246", "ner": [[1, 2, "organisation"], [5, 5, "product"], [9, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 5, 5, "usage", "", false, false], [9, 17, 1, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "Cl\u00ednica", "Cleveland", "ha", "utilizado", "Cyc", "para", "desarrollar", "una", "interfaz", "de", "consulta", "en", "lenguaje", "natural", "de", "informaci\u00f3n", "biom\u00e9dica", ",", "que", "abarca", "d\u00e9cadas", "de", "informaci\u00f3n", "sobre", "cirug\u00edas", "cardiotor\u00e1cicas", "."], "sentence-detokenized": "La Cl\u00ednica Cleveland ha utilizado Cyc para desarrollar una interfaz de consulta en lenguaje natural de informaci\u00f3n biom\u00e9dica, que abarca d\u00e9cadas de informaci\u00f3n sobre cirug\u00edas cardiotor\u00e1cicas.", "token2charspan": [[0, 2], [3, 10], [11, 20], [21, 23], [24, 33], [34, 37], [38, 42], [43, 54], [55, 58], [59, 67], [68, 70], [71, 79], [80, 82], [83, 91], [92, 99], [100, 102], [103, 114], [115, 124], [124, 125], [126, 129], [130, 136], [137, 144], [145, 147], [148, 159], [160, 165], [166, 174], [175, 190], [190, 191]]}
{"doc_key": "ai-test-247", "ner": [[6, 7, "country"], [9, 9, "country"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 9, 9, "opposite", "strained_relations", false, false]], "relations_mapping_to_source": [0], "sentence": ["El", "incidente", "tens\u00f3", "las", "relaciones", "entre", "Estados", "Unidos", "y", "Jap\u00f3n", ",", "y", "dio", "lugar", "a", "la", "detenci\u00f3n", "y", "el", "procesamiento", "de", "dos", "altos", "ejecutivos", ",", "as\u00ed", "como", "a", "la", "imposici\u00f3n", "de", "sanciones", "a", "la", "empresa", "por", "parte", "de", "ambos", "pa\u00edses", "."], "sentence-detokenized": "El incidente tens\u00f3 las relaciones entre Estados Unidos y Jap\u00f3n, y dio lugar a la detenci\u00f3n y el procesamiento de dos altos ejecutivos, as\u00ed como a la imposici\u00f3n de sanciones a la empresa por parte de ambos pa\u00edses.", "token2charspan": [[0, 2], [3, 12], [13, 18], [19, 22], [23, 33], [34, 39], [40, 47], [48, 54], [55, 56], [57, 62], [62, 63], [64, 65], [66, 69], [70, 75], [76, 77], [78, 80], [81, 90], [91, 92], [93, 95], [96, 109], [110, 112], [113, 116], [117, 122], [123, 133], [133, 134], [135, 138], [139, 143], [144, 145], [146, 148], [149, 159], [160, 162], [163, 172], [173, 174], [175, 177], [178, 185], [186, 189], [190, 195], [196, 198], [199, 204], [205, 211], [211, 212]]}
{"doc_key": "ai-test-248", "ner": [[7, 9, "algorithm"], [14, 15, "field"], [24, 24, "misc"], [37, 37, "misc"], [41, 43, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 9, 14, 15, "type-of", "", false, false], [24, 24, 14, 15, "part-of", "", true, false], [37, 37, 14, 15, "part-of", "", true, false], [41, 43, 14, 15, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Si", "el", "modelado", "se", "realiza", "mediante", "una", "red", "neuronal", "artificial", "u", "otro", "tipo", "de", "aprendizaje", "autom\u00e1tico", ",", "la", "optimizaci\u00f3n", "de", "los", "par\u00e1metros", "se", "denomina", "entrenamiento", ",", "mientras", "que", "la", "optimizaci\u00f3n", "de", "los", "hiperpar\u00e1metros", "del", "modelo", "se", "denomina", "sintonizaci\u00f3n", "y", "suele", "utilizar", "la", "validaci\u00f3n", "cruzada", "."], "sentence-detokenized": "Si el modelado se realiza mediante una red neuronal artificial u otro tipo de aprendizaje autom\u00e1tico, la optimizaci\u00f3n de los par\u00e1metros se denomina entrenamiento, mientras que la optimizaci\u00f3n de los hiperpar\u00e1metros del modelo se denomina sintonizaci\u00f3n y suele utilizar la validaci\u00f3n cruzada.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 25], [26, 34], [35, 38], [39, 42], [43, 51], [52, 62], [63, 64], [65, 69], [70, 74], [75, 77], [78, 89], [90, 100], [100, 101], [102, 104], [105, 117], [118, 120], [121, 124], [125, 135], [136, 138], [139, 147], [148, 161], [161, 162], [163, 171], [172, 175], [176, 178], [179, 191], [192, 194], [195, 198], [199, 214], [215, 218], [219, 225], [226, 228], [229, 237], [238, 251], [252, 253], [254, 259], [260, 268], [269, 271], [272, 282], [283, 290], [290, 291]]}
{"doc_key": "ai-test-249", "ner": [[8, 9, "country"], [11, 11, "country"], [13, 13, "country"], [20, 21, "organisation"], [25, 25, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[20, 21, 25, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Las", "versiones", "localizadas", "del", "sitio", "disponibles", "en", "el", "Reino", "Unido", ",", "India", "y", "Australia", "se", "interrumpieron", "tras", "la", "adquisici\u00f3n", "de", "Rotten", "Tomatoes", "por", "parte", "de", "Fandango", "."], "sentence-detokenized": "Las versiones localizadas del sitio disponibles en el Reino Unido, India y Australia se interrumpieron tras la adquisici\u00f3n de Rotten Tomatoes por parte de Fandango.", "token2charspan": [[0, 3], [4, 13], [14, 25], [26, 29], [30, 35], [36, 47], [48, 50], [51, 53], [54, 59], [60, 65], [65, 66], [67, 72], [73, 74], [75, 84], [85, 87], [88, 102], [103, 107], [108, 110], [111, 122], [123, 125], [126, 132], [133, 141], [142, 145], [146, 151], [152, 154], [155, 163], [163, 164]]}
{"doc_key": "ai-test-250", "ner": [[2, 2, "task"], [11, 11, "metrics"], [29, 31, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 11, 11, "related-to", "", false, false], [11, 11, 29, 31, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["El", "modelo", "NER", "es", "uno", "de", "los", "m\u00e9todos", "para", "determinar", "la", "precisi\u00f3n", "de", "los", "subt\u00edtulos", "en", "directo", "en", "las", "emisiones", "de", "televisi\u00f3n", "y", "eventos", "que", "se", "producen", "mediante", "el", "reconocimiento", "del", "habla", "."], "sentence-detokenized": "El modelo NER es uno de los m\u00e9todos para determinar la precisi\u00f3n de los subt\u00edtulos en directo en las emisiones de televisi\u00f3n y eventos que se producen mediante el reconocimiento del habla.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 16], [17, 20], [21, 23], [24, 27], [28, 35], [36, 40], [41, 51], [52, 54], [55, 64], [65, 67], [68, 71], [72, 82], [83, 85], [86, 93], [94, 96], [97, 100], [101, 110], [111, 113], [114, 124], [125, 126], [127, 134], [135, 138], [139, 141], [142, 150], [151, 159], [160, 162], [163, 177], [178, 181], [182, 187], [187, 188]]}
{"doc_key": "ai-test-251", "ner": [[0, 0, "researcher"], [4, 7, "university"], [10, 11, "university"], [13, 13, "location"], [16, 20, "university"], [22, 24, "university"], [26, 26, "location"], [30, 35, "university"], [37, 38, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 7, "physical", "", false, false], [0, 0, 4, 7, "role", "", false, false], [0, 0, 10, 11, "physical", "", false, false], [0, 0, 10, 11, "role", "", false, false], [0, 0, 16, 20, "physical", "", false, false], [0, 0, 16, 20, "role", "", false, false], [0, 0, 22, 24, "physical", "", false, false], [0, 0, 22, 24, "role", "", false, false], [0, 0, 30, 35, "physical", "", false, false], [0, 0, 30, 35, "role", "", false, false], [10, 11, 13, 13, "physical", "", false, false], [16, 20, 26, 26, "physical", "", false, false], [22, 24, 26, 26, "physical", "", false, false], [30, 35, 37, 38, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Atran", "ha", "ense\u00f1ado", "en", "la", "Universidad", "de", "Cambridge", ",", "la", "Universidad", "Hebrea", "de", "Jerusal\u00e9n", ",", "la", "\u00c9cole", "pratique", "des", "hautes", "\u00e9tudes", "y", "la", "\u00c9cole", "Polytechnique", "de", "Par\u00eds", ",", "y", "el", "John", "Jay", "College", "of", "Criminal", "Justice", "de", "Nueva", "York", "."], "sentence-detokenized": "Atran ha ense\u00f1ado en la Universidad de Cambridge, la Universidad Hebrea de Jerusal\u00e9n, la \u00c9cole pratique des hautes \u00e9tudes y la \u00c9cole Polytechnique de Par\u00eds, y el John Jay College of Criminal Justice de Nueva York.", "token2charspan": [[0, 5], [6, 8], [9, 17], [18, 20], [21, 23], [24, 35], [36, 38], [39, 48], [48, 49], [50, 52], [53, 64], [65, 71], [72, 74], [75, 84], [84, 85], [86, 88], [89, 94], [95, 103], [104, 107], [108, 114], [115, 121], [122, 123], [124, 126], [127, 132], [133, 146], [147, 149], [150, 155], [155, 156], [157, 158], [159, 161], [162, 166], [167, 170], [171, 178], [179, 181], [182, 190], [191, 198], [199, 201], [202, 207], [208, 212], [212, 213]]}
{"doc_key": "ai-test-252", "ner": [[0, 1, "product"], [9, 12, "task"], [16, 17, "researcher"], [19, 20, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 9, 12, "origin", "", false, false], [0, 1, 9, 12, "related-to", "", false, false], [9, 12, 19, 20, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["SHRDLU", "fue", "uno", "de", "los", "primeros", "programas", "inform\u00e1ticos", "de", "comprensi\u00f3n", "del", "lenguaje", "natural", ",", "desarrollado", "por", "Terry", "Winograd", "en", "el", "MIT", "en", "1968-1970"], "sentence-detokenized": "SHRDLU fue uno de los primeros programas inform\u00e1ticos de comprensi\u00f3n del lenguaje natural, desarrollado por Terry Winograd en el MIT en 1968-1970", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 17], [18, 21], [22, 30], [31, 40], [41, 53], [54, 56], [57, 68], [69, 72], [73, 81], [82, 89], [89, 90], [91, 103], [104, 107], [108, 113], [114, 122], [123, 125], [126, 128], [129, 132], [133, 135], [136, 145]]}
{"doc_key": "ai-test-253", "ner": [[1, 1, "misc"], [3, 6, "field"], [7, 11, "university"], [13, 13, "location"], [15, 15, "country"], [24, 27, "university"], [31, 31, "misc"], [33, 36, "field"], [40, 46, "university"], [47, 47, "misc"], [49, 49, "field"], [54, 54, "misc"], [62, 64, "university"], [68, 69, "field"], [73, 74, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "relations": [[1, 1, 3, 6, "topic", "", false, false], [1, 1, 7, 11, "origin", "", false, false], [7, 11, 13, 13, "physical", "", false, false], [7, 11, 24, 27, "role", "affiliated_with", false, false], [13, 13, 15, 15, "physical", "", false, false], [31, 31, 33, 36, "topic", "", false, false], [31, 31, 40, 46, "origin", "", false, false], [47, 47, 49, 49, "topic", "", false, false], [54, 54, 62, 64, "origin", "", false, false], [54, 54, 68, 69, "topic", "", false, false], [73, 74, 62, 64, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Se", "licenci\u00f3", "en", "ingenier\u00eda", "electr\u00f3nica", "en", "el", "B.M.S", ".", "College", "of", "Engineering", "de", "Bangalore", "(", "India", ")", "en", "1982", ",", "cuando", "estaba", "afiliado", "a", "la", "Universidad", "de", "Bangalore", ",", "obtuvo", "un", "m\u00e1ster", "en", "ingenier\u00eda", "el\u00e9ctrica", "e", "inform\u00e1tica", "en", "1984", "en", "la", "Universidad", "de", "Drexel", ",", "y", "un", "m\u00e1ster", "en", "inform\u00e1tica", "en", "1989", "y", "un", "doctorado", "en", "1990", ",", "respectivamente", ",", "en", "la", "Universidad", "de", "Wisconsin-Madison", ",", "donde", "estudi\u00f3", "Inteligencia", "Artificial", "y", "trabaj\u00f3", "con", "Leonard", "Uhr", "."], "sentence-detokenized": "Se licenci\u00f3 en ingenier\u00eda electr\u00f3nica en el B.M.S. College of Engineering de Bangalore (India) en 1982, cuando estaba afiliado a la Universidad de Bangalore, obtuvo un m\u00e1ster en ingenier\u00eda el\u00e9ctrica e inform\u00e1tica en 1984 en la Universidad de Drexel, y un m\u00e1ster en inform\u00e1tica en 1989 y un doctorado en 1990, respectivamente, en la Universidad de Wisconsin-Madison, donde estudi\u00f3 Inteligencia Artificial y trabaj\u00f3 con Leonard Uhr.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 25], [26, 37], [38, 40], [41, 43], [44, 49], [49, 50], [51, 58], [59, 61], [62, 73], [74, 76], [77, 86], [87, 88], [88, 93], [93, 94], [95, 97], [98, 102], [102, 103], [104, 110], [111, 117], [118, 126], [127, 128], [129, 131], [132, 143], [144, 146], [147, 156], [156, 157], [158, 164], [165, 167], [168, 174], [175, 177], [178, 188], [189, 198], [199, 200], [201, 212], [213, 215], [216, 220], [221, 223], [224, 226], [227, 238], [239, 241], [242, 248], [248, 249], [250, 251], [252, 254], [255, 261], [262, 264], [265, 276], [277, 279], [280, 284], [285, 286], [287, 289], [290, 299], [300, 302], [303, 307], [307, 308], [309, 324], [324, 325], [326, 328], [329, 331], [332, 343], [344, 346], [347, 364], [364, 365], [366, 371], [372, 379], [380, 392], [393, 403], [404, 405], [406, 413], [414, 417], [418, 425], [426, 429], [429, 430]]}
{"doc_key": "ai-test-254", "ner": [[7, 11, "metrics"], [13, 13, "metrics"], [24, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 13, 7, 11, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["La", "precisi\u00f3n", "se", "suele", "valorar", "con", "la", "tasa", "de", "error", "de", "palabra", "(", "WER", ")", ",", "mientras", "que", "la", "velocidad", "se", "mide", "con", "el", "factor", "de", "tiempo", "real", "."], "sentence-detokenized": "La precisi\u00f3n se suele valorar con la tasa de error de palabra (WER), mientras que la velocidad se mide con el factor de tiempo real.", "token2charspan": [[0, 2], [3, 12], [13, 15], [16, 21], [22, 29], [30, 33], [34, 36], [37, 41], [42, 44], [45, 50], [51, 53], [54, 61], [62, 63], [63, 66], [66, 67], [67, 68], [69, 77], [78, 81], [82, 84], [85, 94], [95, 97], [98, 102], [103, 106], [107, 109], [110, 116], [117, 119], [120, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-test-255", "ner": [[3, 4, "researcher"], [10, 13, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 10, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["En", "1971", ",", "Terry", "Winograd", "desarroll\u00f3", "un", "primer", "motor", "de", "procesamiento", "del", "lenguaje", "natural", "capaz", "de", "interpretar", "\u00f3rdenes", "escritas", "de", "forma", "natural", "en", "un", "entorno", "sencillo", "gobernado", "por", "reglas", "."], "sentence-detokenized": "En 1971, Terry Winograd desarroll\u00f3 un primer motor de procesamiento del lenguaje natural capaz de interpretar \u00f3rdenes escritas de forma natural en un entorno sencillo gobernado por reglas.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 34], [35, 37], [38, 44], [45, 50], [51, 53], [54, 67], [68, 71], [72, 80], [81, 88], [89, 94], [95, 97], [98, 109], [110, 117], [118, 126], [127, 129], [130, 135], [136, 143], [144, 146], [147, 149], [150, 157], [158, 166], [167, 176], [177, 180], [181, 187], [187, 188]]}
{"doc_key": "ai-test-256", "ner": [[1, 2, "field"], [4, 5, "researcher"], [7, 9, "researcher"], [11, 12, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 2, 4, 5, "related-to", "", false, false], [1, 2, 7, 9, "related-to", "", false, false], [1, 2, 11, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["En", "inteligencia", "artificial", "destacan", "Marvin", "Minsky", ",", "Herbert", "A.", "Simon", "y", "Allen", "Newell", "."], "sentence-detokenized": "En inteligencia artificial destacan Marvin Minsky, Herbert A. Simon y Allen Newell.", "token2charspan": [[0, 2], [3, 15], [16, 26], [27, 35], [36, 42], [43, 49], [49, 50], [51, 58], [59, 61], [62, 67], [68, 69], [70, 75], [76, 82], [82, 83]]}
{"doc_key": "ai-test-257", "ner": [[10, 11, "field"], [33, 34, "field"], [37, 38, "field"], [45, 48, "field"], [58, 59, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[33, 34, 10, 11, "origin", "", true, false], [33, 34, 10, 11, "part-of", "", false, false], [33, 34, 45, 48, "compare", "", false, false], [37, 38, 10, 11, "origin", "", true, false], [37, 38, 10, 11, "part-of", "", false, false], [37, 38, 45, 48, "compare", "", false, false], [45, 48, 10, 11, "origin", "", true, false], [45, 48, 10, 11, "part-of", "", false, false], [45, 48, 58, 59, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["En", "la", "segunda", "mitad", "del", "siglo", "XX", ",", "la", "propia", "ingenier\u00eda", "el\u00e9ctrica", "se", "separ\u00f3", "en", "varias", "disciplinas", ",", "especializadas", "en", "el", "dise\u00f1o", "y", "el", "an\u00e1lisis", "de", "sistemas", "que", "manipulan", "se\u00f1ales", "f\u00edsicas", ";", "la", "ingenier\u00eda", "electr\u00f3nica", "y", "la", "ingenier\u00eda", "inform\u00e1tica", ",", "por", "ejemplo", ";", "mientras", "que", "la", "ingenier\u00eda", "de", "dise\u00f1o", "se", "desarroll\u00f3", "para", "ocuparse", "del", "dise\u00f1o", "funcional", "de", "las", "interfaces", "usuario-m\u00e1quina", "."], "sentence-detokenized": "En la segunda mitad del siglo XX, la propia ingenier\u00eda el\u00e9ctrica se separ\u00f3 en varias disciplinas, especializadas en el dise\u00f1o y el an\u00e1lisis de sistemas que manipulan se\u00f1ales f\u00edsicas; la ingenier\u00eda electr\u00f3nica y la ingenier\u00eda inform\u00e1tica, por ejemplo; mientras que la ingenier\u00eda de dise\u00f1o se desarroll\u00f3 para ocuparse del dise\u00f1o funcional de las interfaces usuario-m\u00e1quina.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 19], [20, 23], [24, 29], [30, 32], [32, 33], [34, 36], [37, 43], [44, 54], [55, 64], [65, 67], [68, 74], [75, 77], [78, 84], [85, 96], [96, 97], [98, 112], [113, 115], [116, 118], [119, 125], [126, 127], [128, 130], [131, 139], [140, 142], [143, 151], [152, 155], [156, 165], [166, 173], [174, 181], [181, 182], [183, 185], [186, 196], [197, 208], [209, 210], [211, 213], [214, 224], [225, 236], [236, 237], [238, 241], [242, 249], [249, 250], [251, 259], [260, 263], [264, 266], [267, 277], [278, 280], [281, 287], [288, 290], [291, 301], [302, 306], [307, 315], [316, 319], [320, 326], [327, 336], [337, 339], [340, 343], [344, 354], [355, 370], [370, 371]]}
{"doc_key": "ai-test-258", "ner": [[7, 7, "metrics"], [9, 10, "metrics"], [12, 12, "metrics"], [49, 50, "metrics"], [57, 59, "metrics"], [63, 69, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 12, 9, 10, "named", "", false, false], [49, 50, 57, 59, "named", "", false, false], [57, 59, 63, 69, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Quiz\u00e1", "la", "estad\u00edstica", "m\u00e1s", "sencilla", "sea", "la", "precisi\u00f3n", "o", "Fracci\u00f3n", "Correcta", "(", "FC", ")", ",", "que", "mide", "la", "fracci\u00f3n", "de", "todas", "las", "instancias", "que", "se", "clasifican", "correctamente", ";", "es", "la", "relaci\u00f3n", "entre", "el", "n\u00famero", "de", "clasificaciones", "correctas", "y", "el", "n\u00famero", "total", "de", "clasificaciones", "correctas", "o", "incorrectas", ":", "(", "TP", "+", "TN", ")", "/", "Poblaci\u00f3n", "total", "=", "(", "TP", "+", "TN", ")", "/", "(", "TP", "+", "TN", "+", "FP", "+", "FN", ")", "."], "sentence-detokenized": "Quiz\u00e1 la estad\u00edstica m\u00e1s sencilla sea la precisi\u00f3n o Fracci\u00f3n Correcta (FC), que mide la fracci\u00f3n de todas las instancias que se clasifican correctamente; es la relaci\u00f3n entre el n\u00famero de clasificaciones correctas y el n\u00famero total de clasificaciones correctas o incorrectas: (TP + TN) / Poblaci\u00f3n total = (TP + TN) / (TP + TN + FP + FN).", "token2charspan": [[0, 5], [6, 8], [9, 20], [21, 24], [25, 33], [34, 37], [38, 40], [41, 50], [51, 52], [53, 61], [62, 70], [71, 72], [72, 74], [74, 75], [75, 76], [77, 80], [81, 85], [86, 88], [89, 97], [98, 100], [101, 106], [107, 110], [111, 121], [122, 125], [126, 128], [129, 139], [140, 153], [153, 154], [155, 157], [158, 160], [161, 169], [170, 175], [176, 178], [179, 185], [186, 188], [189, 204], [205, 214], [215, 216], [217, 219], [220, 226], [227, 232], [233, 235], [236, 251], [252, 261], [262, 263], [264, 275], [275, 276], [277, 278], [278, 280], [281, 282], [283, 285], [285, 286], [287, 288], [289, 298], [299, 304], [305, 306], [307, 308], [308, 310], [311, 312], [313, 315], [315, 316], [317, 318], [319, 320], [320, 322], [323, 324], [325, 327], [328, 329], [330, 332], [333, 334], [335, 337], [337, 338], [338, 339]]}
{"doc_key": "ai-test-259", "ner": [[18, 28, "conference"], [30, 30, "conference"], [33, 33, "location"], [38, 39, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[18, 28, 33, 33, "physical", "", false, false], [30, 30, 18, 28, "named", "", false, false], [38, 39, 18, 28, "role", "sponsors", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["En", "la", "comunidad", "acad\u00e9mica", ",", "los", "principales", "foros", "de", "investigaci\u00f3n", "comenzaron", "en", "1995", ",", "cuando", "se", "inici\u00f3", "la", "Primera", "Conferencia", "Internacional", "de", "Miner\u00eda", "de", "Datos", "y", "Descubrimiento", "de", "Conocimientos", "(", "KDD-95", ")", "en", "Montreal", "bajo", "el", "patrocinio", "de", "la", "AAAI", "."], "sentence-detokenized": "En la comunidad acad\u00e9mica, los principales foros de investigaci\u00f3n comenzaron en 1995, cuando se inici\u00f3 la Primera Conferencia Internacional de Miner\u00eda de Datos y Descubrimiento de Conocimientos (KDD-95) en Montreal bajo el patrocinio de la AAAI.", "token2charspan": [[0, 2], [3, 5], [6, 15], [16, 25], [25, 26], [27, 30], [31, 42], [43, 48], [49, 51], [52, 65], [66, 76], [77, 79], [80, 84], [84, 85], [86, 92], [93, 95], [96, 102], [103, 105], [106, 113], [114, 125], [126, 139], [140, 142], [143, 150], [151, 153], [154, 159], [160, 161], [162, 176], [177, 179], [180, 193], [194, 195], [195, 201], [201, 202], [203, 205], [206, 214], [215, 219], [220, 222], [223, 233], [234, 236], [237, 239], [240, 244], [244, 245]]}
{"doc_key": "ai-test-260", "ner": [[11, 13, "field"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["En", "este", "enfoque", ",", "se", "desarrollan", "modelos", "utilizando", "diferentes", "algoritmos", "de", "miner\u00eda", "de", "datos", "y", "aprendizaje", "autom\u00e1tico", "para", "predecir", "la", "valoraci\u00f3n", "de", "los", "usuarios", "de", "los", "art\u00edculos", "no", "calificados", "."], "sentence-detokenized": "En este enfoque, se desarrollan modelos utilizando diferentes algoritmos de miner\u00eda de datos y aprendizaje autom\u00e1tico para predecir la valoraci\u00f3n de los usuarios de los art\u00edculos no calificados.", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 19], [20, 31], [32, 39], [40, 50], [51, 61], [62, 72], [73, 75], [76, 83], [84, 86], [87, 92], [93, 94], [95, 106], [107, 117], [118, 122], [123, 131], [132, 134], [135, 145], [146, 148], [149, 152], [153, 161], [162, 164], [165, 168], [169, 178], [179, 181], [182, 193], [193, 194]]}
{"doc_key": "ai-test-261", "ner": [[12, 12, "algorithm"], [16, 17, "algorithm"], [19, 21, "algorithm"], [28, 30, "misc"], [33, 34, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 12, 16, 17, "related-to", "equivalent", false, false], [16, 17, 19, 21, "usage", "", false, false], [19, 21, 33, 34, "usage", "", false, false], [33, 34, 28, 30, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "la", "luz", "de", "la", "discusi\u00f3n", "anterior", ",", "vemos", "que", "la", "t\u00e9cnica", "SVM", "es", "equivalente", "al", "riesgo", "emp\u00edrico", "con", "regularizaci\u00f3n", "de", "Tikhonov", ",", "donde", "en", "este", "caso", "la", "funci\u00f3n", "de", "p\u00e9rdida", "es", "la", "p\u00e9rdida", "bisagra"], "sentence-detokenized": "A la luz de la discusi\u00f3n anterior, vemos que la t\u00e9cnica SVM es equivalente al riesgo emp\u00edrico con regularizaci\u00f3n de Tikhonov, donde en este caso la funci\u00f3n de p\u00e9rdida es la p\u00e9rdida bisagra", "token2charspan": [[0, 1], [2, 4], [5, 8], [9, 11], [12, 14], [15, 24], [25, 33], [33, 34], [35, 40], [41, 44], [45, 47], [48, 55], [56, 59], [60, 62], [63, 74], [75, 77], [78, 84], [85, 93], [94, 97], [98, 112], [113, 115], [116, 124], [124, 125], [126, 131], [132, 134], [135, 139], [140, 144], [145, 147], [148, 155], [156, 158], [159, 166], [167, 169], [170, 172], [173, 180], [181, 188]]}
{"doc_key": "ai-test-262", "ner": [[7, 8, "person"], [11, 12, "person"], [17, 19, "organisation"], [14, 21, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 21, 17, 19, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["La", "edici\u00f3n", "de", "2015", "fue", "presentada", "por", "Molly", "McGrath", ",", "con", "Chris", "Rose", "y", "el", "ex", "luchador", "de", "la", "UFC", "Kenny", "Florian", "como", "comentaristas", "."], "sentence-detokenized": "La edici\u00f3n de 2015 fue presentada por Molly McGrath, con Chris Rose y el ex luchador de la UFC Kenny Florian como comentaristas.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 18], [19, 22], [23, 33], [34, 37], [38, 43], [44, 51], [51, 52], [53, 56], [57, 62], [63, 67], [68, 69], [70, 72], [73, 75], [76, 84], [85, 87], [88, 90], [91, 94], [95, 100], [101, 108], [109, 113], [114, 127], [127, 128]]}
{"doc_key": "ai-test-263", "ner": [[3, 3, "product"], [7, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"], [16, 16, "researcher"], [20, 20, "researcher"], [34, 34, "researcher"], [29, 32, "task"], [35, 35, "product"], [44, 45, "researcher"], [40, 42, "task"], [50, 50, "researcher"], [53, 54, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[3, 3, 7, 9, "origin", "", false, false], [3, 3, 11, 12, "origin", "", false, false], [3, 3, 14, 15, "origin", "", false, false], [3, 3, 16, 16, "origin", "", false, false], [11, 12, 44, 45, "named", "same", false, false], [14, 15, 20, 20, "named", "same", false, false], [14, 15, 34, 34, "named", "same", false, false], [29, 32, 35, 35, "related-to", "", false, false], [35, 35, 34, 34, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Un", "subconjunto", "llamado", "Micro-Planner", "fue", "implementado", "por", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "y", "Terry", "Winograd", "Sussman", ",", ",", "y", "Winograd", "1971", "y", "fue", "utilizado", "en", "el", "programa", "de", "comprensi\u00f3n", "de", "lenguaje", "natural", "de", "Winograd", "SHRDLU", ",", "el", "trabajo", "de", "comprensi\u00f3n", "de", "historias", "de", "Eugene", "Charniak", ",", "el", "trabajo", "de", "Thorne", "McCarty", "sobre", "razonamiento", "legal", ",", "y", "algunos", "otros", "proyectos", "."], "sentence-detokenized": "Un subconjunto llamado Micro-Planner fue implementado por Gerald Jay Sussman, Eugene Charniak y Terry Winograd Sussman,, y Winograd 1971 y fue utilizado en el programa de comprensi\u00f3n de lenguaje natural de Winograd SHRDLU, el trabajo de comprensi\u00f3n de historias de Eugene Charniak, el trabajo de Thorne McCarty sobre razonamiento legal, y algunos otros proyectos.", "token2charspan": [[0, 2], [3, 14], [15, 22], [23, 36], [37, 40], [41, 53], [54, 57], [58, 64], [65, 68], [69, 76], [76, 77], [78, 84], [85, 93], [94, 95], [96, 101], [102, 110], [111, 118], [118, 119], [119, 120], [121, 122], [123, 131], [132, 136], [137, 138], [139, 142], [143, 152], [153, 155], [156, 158], [159, 167], [168, 170], [171, 182], [183, 185], [186, 194], [195, 202], [203, 205], [206, 214], [215, 221], [221, 222], [223, 225], [226, 233], [234, 236], [237, 248], [249, 251], [252, 261], [262, 264], [265, 271], [272, 280], [280, 281], [282, 284], [285, 292], [293, 295], [296, 302], [303, 310], [311, 316], [317, 329], [330, 335], [335, 336], [337, 338], [339, 346], [347, 352], [353, 362], [362, 363]]}
{"doc_key": "ai-test-264", "ner": [[0, 1, "product"], [8, 11, "product"], [15, 20, "task"], [23, 25, "task"], [28, 31, "task"], [34, 35, "task"], [38, 39, "task"], [43, 46, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[8, 11, 0, 1, "usage", "", true, false], [15, 20, 8, 11, "part-of", "", true, false], [23, 25, 8, 11, "part-of", "", true, false], [28, 31, 8, 11, "part-of", "", true, false], [34, 35, 8, 11, "part-of", "", true, false], [38, 39, 8, 11, "part-of", "", true, false], [43, 46, 8, 11, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["WordNet", "se", "ha", "utilizado", "para", "diversos", "fines", "en", "los", "sistemas", "de", "informaci\u00f3n", ",", "como", "la", "desambiguaci\u00f3n", "del", "sentido", "de", "las", "palabras", ",", "la", "recuperaci\u00f3n", "de", "informaci\u00f3n", ",", "la", "clasificaci\u00f3n", "autom\u00e1tica", "de", "textos", ",", "el", "resumen", "autom\u00e1tico", ",", "la", "traducci\u00f3n", "autom\u00e1tica", "e", "incluso", "la", "generaci\u00f3n", "autom\u00e1tica", "de", "crucigramas", "."], "sentence-detokenized": "WordNet se ha utilizado para diversos fines en los sistemas de informaci\u00f3n, como la desambiguaci\u00f3n del sentido de las palabras, la recuperaci\u00f3n de informaci\u00f3n, la clasificaci\u00f3n autom\u00e1tica de textos, el resumen autom\u00e1tico, la traducci\u00f3n autom\u00e1tica e incluso la generaci\u00f3n autom\u00e1tica de crucigramas.", "token2charspan": [[0, 7], [8, 10], [11, 13], [14, 23], [24, 28], [29, 37], [38, 43], [44, 46], [47, 50], [51, 59], [60, 62], [63, 74], [74, 75], [76, 80], [81, 83], [84, 98], [99, 102], [103, 110], [111, 113], [114, 117], [118, 126], [126, 127], [128, 130], [131, 143], [144, 146], [147, 158], [158, 159], [160, 162], [163, 176], [177, 187], [188, 190], [191, 197], [197, 198], [199, 201], [202, 209], [210, 220], [220, 221], [222, 224], [225, 235], [236, 246], [247, 248], [249, 256], [257, 259], [260, 270], [271, 281], [282, 284], [285, 296], [296, 297]]}
{"doc_key": "ai-test-265", "ner": [[0, 0, "researcher"], [5, 5, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 5, 5, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Keutzer", "fue", "nombrado", "miembro", "del", "IEEE", "en", "1996", "."], "sentence-detokenized": "Keutzer fue nombrado miembro del IEEE en 1996.", "token2charspan": [[0, 7], [8, 11], [12, 20], [21, 28], [29, 32], [33, 37], [38, 40], [41, 45], [45, 46]]}
{"doc_key": "ai-test-266", "ner": [[8, 11, "algorithm"], [57, 59, "misc"], [68, 69, "algorithm"], [72, 73, "algorithm"], [75, 77, "algorithm"], [81, 82, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[68, 69, 57, 59, "type-of", "", false, false], [72, 73, 57, 59, "type-of", "", false, false], [75, 77, 57, 59, "type-of", "", false, false], [81, 82, 57, 59, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Un", "tipo", "de", "composici\u00f3n", "ampliamente", "utilizado", "es", "la", "suma", "ponderada", "no", "lineal", ",", "donde", "math", "\\", "textstyle", "f", "(", "x", ")", "=", "K", "\\", "izquierda", "(", "\\", "suma", "_", "i", "w", "_", "i", "g", "_", "i", "(", "x", ")", "\\", "derecha", ")", "/", "math", ",", "donde", "math", "\\", "textstyle", "K", "/", "math", "(", "com\u00fanmente", "conocida", "como", "la", "funci\u00f3n", "de", "activaci\u00f3n", ")", "es", "alguna", "funci\u00f3n", "predefinida", ",", "como", "la", "tangente", "hiperb\u00f3lica", ",", "la", "funci\u00f3n", "sigmoide", ",", "la", "funci\u00f3n", "softmax", ",", "o", "la", "funci\u00f3n", "rectificadora", "."], "sentence-detokenized": "Un tipo de composici\u00f3n ampliamente utilizado es la suma ponderada no lineal, donde math\\ textstyle f (x) = K\\ izquierda (\\ suma _ i w _ i g _ i (x)\\ derecha) / math, donde math\\ textstyle K / math (com\u00fanmente conocida como la funci\u00f3n de activaci\u00f3n) es alguna funci\u00f3n predefinida, como la tangente hiperb\u00f3lica, la funci\u00f3n sigmoide, la funci\u00f3n softmax, o la funci\u00f3n rectificadora.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 22], [23, 34], [35, 44], [45, 47], [48, 50], [51, 55], [56, 65], [66, 68], [69, 75], [75, 76], [77, 82], [83, 87], [87, 88], [89, 98], [99, 100], [101, 102], [102, 103], [103, 104], [105, 106], [107, 108], [108, 109], [110, 119], [120, 121], [121, 122], [123, 127], [128, 129], [130, 131], [132, 133], [134, 135], [136, 137], [138, 139], [140, 141], [142, 143], [144, 145], [145, 146], [146, 147], [147, 148], [149, 156], [156, 157], [158, 159], [160, 164], [164, 165], [166, 171], [172, 176], [176, 177], [178, 187], [188, 189], [190, 191], [192, 196], [197, 198], [198, 208], [209, 217], [218, 222], [223, 225], [226, 233], [234, 236], [237, 247], [247, 248], [249, 251], [252, 258], [259, 266], [267, 278], [278, 279], [280, 284], [285, 287], [288, 296], [297, 308], [308, 309], [310, 312], [313, 320], [321, 329], [329, 330], [331, 333], [334, 341], [342, 349], [349, 350], [351, 352], [353, 355], [356, 363], [364, 377], [377, 378]]}
{"doc_key": "ai-test-267", "ner": [[3, 3, "misc"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["En", "la", "pel\u00edcula", "Westworld", ",", "los", "robots", "femeninos", "manten\u00edan", "relaciones", "sexuales", "con", "hombres", "humanos", "como", "parte", "del", "mundo", "vacacional", "imaginario", "por", "el", "que", "pagaban", "los", "clientes", "humanos", "."], "sentence-detokenized": "En la pel\u00edcula Westworld, los robots femeninos manten\u00edan relaciones sexuales con hombres humanos como parte del mundo vacacional imaginario por el que pagaban los clientes humanos.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 24], [24, 25], [26, 29], [30, 36], [37, 46], [47, 56], [57, 67], [68, 76], [77, 80], [81, 88], [89, 96], [97, 101], [102, 107], [108, 111], [112, 117], [118, 128], [129, 139], [140, 143], [144, 146], [147, 150], [151, 158], [159, 162], [163, 171], [172, 179], [179, 180]]}
{"doc_key": "ai-test-268", "ner": [[9, 11, "task"], [29, 34, "task"], [37, 39, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 11, 29, 34, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Por", "lo", "general", ",", "el", "proceso", "comienza", "con", "la", "extracci\u00f3n", "de", "terminolog\u00eda", "y", "conceptos", "o", "frases", "sustantivas", "a", "partir", "de", "un", "texto", "sin", "formato", ",", "utilizando", "procesadores", "ling\u00fc\u00edsticos", "como", "el", "etiquetado", "de", "partes", "del", "lenguaje", "y", "la", "fragmentaci\u00f3n", "de", "frases", "."], "sentence-detokenized": "Por lo general, el proceso comienza con la extracci\u00f3n de terminolog\u00eda y conceptos o frases sustantivas a partir de un texto sin formato, utilizando procesadores ling\u00fc\u00edsticos como el etiquetado de partes del lenguaje y la fragmentaci\u00f3n de frases.", "token2charspan": [[0, 3], [4, 6], [7, 14], [14, 15], [16, 18], [19, 26], [27, 35], [36, 39], [40, 42], [43, 53], [54, 56], [57, 69], [70, 71], [72, 81], [82, 83], [84, 90], [91, 102], [103, 104], [105, 111], [112, 114], [115, 117], [118, 123], [124, 127], [128, 135], [135, 136], [137, 147], [148, 160], [161, 173], [174, 178], [179, 181], [182, 192], [193, 195], [196, 202], [203, 206], [207, 215], [216, 217], [218, 220], [221, 234], [235, 237], [238, 244], [244, 245]]}
{"doc_key": "ai-test-269", "ner": [[14, 15, "field"], [19, 24, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[19, 24, 14, 15, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0], "sentence": ["Demostraron", "su", "rendimiento", "en", "una", "serie", "de", "problemas", "de", "inter\u00e9s", "para", "la", "comunidad", "del", "aprendizaje", "autom\u00e1tico", ",", "incluido", "el", "reconocimiento", "de", "la", "escritura", "a", "mano", "."], "sentence-detokenized": "Demostraron su rendimiento en una serie de problemas de inter\u00e9s para la comunidad del aprendizaje autom\u00e1tico, incluido el reconocimiento de la escritura a mano.", "token2charspan": [[0, 11], [12, 14], [15, 26], [27, 29], [30, 33], [34, 39], [40, 42], [43, 52], [53, 55], [56, 63], [64, 68], [69, 71], [72, 81], [82, 85], [86, 97], [98, 108], [108, 109], [110, 118], [119, 121], [122, 136], [137, 139], [140, 142], [143, 152], [153, 154], [155, 159], [159, 160]]}
{"doc_key": "ai-test-270", "ner": [[3, 3, "university"], [5, 5, "researcher"], [11, 12, "researcher"], [17, 17, "product"], [21, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 5, 3, 3, "physical", "", false, false], [5, 5, 3, 3, "role", "", false, false], [17, 17, 11, 12, "origin", "", false, false], [17, 17, 21, 22, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Mientras", "estudiaba", "en", "Stanford", ",", "Scheinman", "obtuvo", "una", "beca", "patrocinada", "por", "George", "Devol", ",", "el", "inventor", "del", "Unimate", ",", "el", "primer", "robot", "industrial", "."], "sentence-detokenized": "Mientras estudiaba en Stanford, Scheinman obtuvo una beca patrocinada por George Devol, el inventor del Unimate, el primer robot industrial.", "token2charspan": [[0, 8], [9, 18], [19, 21], [22, 30], [30, 31], [32, 41], [42, 48], [49, 52], [53, 57], [58, 69], [70, 73], [74, 80], [81, 86], [86, 87], [88, 90], [91, 99], [100, 103], [104, 111], [111, 112], [113, 115], [116, 122], [123, 128], [129, 139], [139, 140]]}
{"doc_key": "ai-test-271", "ner": [[6, 8, "task"], [11, 14, "metrics"], [16, 18, "metrics"], [26, 31, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 8, 11, 14, "usage", "", true, false], [16, 18, 11, 14, "named", "", false, false], [26, 31, 11, 14, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Aunque", "originalmente", "se", "utilizaba", "para", "evaluar", "las", "traducciones", "autom\u00e1ticas", ",", "el", "estudio", "de", "evaluaci\u00f3n", "biling\u00fce", "(", "BLEU", ")", "se", "ha", "utilizado", "con", "\u00e9xito", "para", "evaluar", "tambi\u00e9n", "los", "modelos", "de", "generaci\u00f3n", "de", "par\u00e1frasis", "."], "sentence-detokenized": "Aunque originalmente se utilizaba para evaluar las traducciones autom\u00e1ticas, el estudio de evaluaci\u00f3n biling\u00fce (BLEU) se ha utilizado con \u00e9xito para evaluar tambi\u00e9n los modelos de generaci\u00f3n de par\u00e1frasis.", "token2charspan": [[0, 6], [7, 20], [21, 23], [24, 33], [34, 38], [39, 46], [47, 50], [51, 63], [64, 75], [75, 76], [77, 79], [80, 87], [88, 90], [91, 101], [102, 110], [111, 112], [112, 116], [116, 117], [118, 120], [121, 123], [124, 133], [134, 137], [138, 143], [144, 148], [149, 156], [157, 164], [165, 168], [169, 176], [177, 179], [180, 190], [191, 193], [194, 204], [204, 205]]}
{"doc_key": "ai-test-272", "ner": [[2, 2, "organisation"], [10, 12, "organisation"], [15, 15, "organisation"], [19, 20, "product"], [22, 22, "country"], [24, 24, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 10, 12, "role", "licenses_to", false, false], [2, 2, 15, 15, "role", "licenses_to", false, false], [10, 12, 22, 22, "physical", "", false, false], [15, 15, 24, 24, "physical", "", false, false], [19, 20, 10, 12, "artifact", "produces", false, false], [19, 20, 15, 15, "artifact", "produces", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Posteriormente", ",", "Unimation", "concedi\u00f3", "la", "licencia", "de", "su", "tecnolog\u00eda", "a", "Kawasaki", "Heavy", "Industries", "y", "a", "GKN", ",", "que", "fabricaron", "los", "Unimates", "en", "Jap\u00f3n", "e", "Inglaterra", ",", "respectivamente", "."], "sentence-detokenized": "Posteriormente, Unimation concedi\u00f3 la licencia de su tecnolog\u00eda a Kawasaki Heavy Industries y a GKN, que fabricaron los Unimates en Jap\u00f3n e Inglaterra, respectivamente.", "token2charspan": [[0, 14], [14, 15], [16, 25], [26, 34], [35, 37], [38, 46], [47, 49], [50, 52], [53, 63], [64, 65], [66, 74], [75, 80], [81, 91], [92, 93], [94, 95], [96, 99], [99, 100], [101, 104], [105, 115], [116, 119], [120, 128], [129, 131], [132, 137], [138, 139], [140, 150], [150, 151], [152, 167], [167, 168]]}
{"doc_key": "ai-test-273", "ner": [[22, 24, "conference"], [41, 42, "field"], [62, 69, "field"], [71, 71, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[41, 42, 62, 69, "compare", "", false, false], [71, 71, 62, 69, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Gran", "parte", "de", "la", "confusi\u00f3n", "entre", "estas", "dos", "comunidades", "de", "investigaci\u00f3n", "(", "que", "a", "menudo", "tienen", "conferencias", "y", "revistas", "separadas", ",", "siendo", "el", "ECML", "PKDD", "una", "importante", "excepci\u00f3n", ")", "proviene", "de", "los", "supuestos", "b\u00e1sicos", "con", "los", "que", "trabajan", ":", "en", "el", "aprendizaje", "autom\u00e1tico", ",", "el", "rendimiento", "suele", "evaluarse", "con", "respecto", "a", "la", "capacidad", "de", "reproducir", "conocimientos", "conocidos", ",", "mientras", "que", "en", "el", "descubrimiento", "de", "conocimientos", "y", "la", "miner\u00eda", "de", "datos", "(", "KDD", ")", "la", "tarea", "clave", "es", "el", "descubrimiento", "de", "conocimientos", "previamente", "desconocidos", "."], "sentence-detokenized": "Gran parte de la confusi\u00f3n entre estas dos comunidades de investigaci\u00f3n (que a menudo tienen conferencias y revistas separadas, siendo el ECML PKDD una importante excepci\u00f3n) proviene de los supuestos b\u00e1sicos con los que trabajan: en el aprendizaje autom\u00e1tico, el rendimiento suele evaluarse con respecto a la capacidad de reproducir conocimientos conocidos, mientras que en el descubrimiento de conocimientos y la miner\u00eda de datos (KDD) la tarea clave es el descubrimiento de conocimientos previamente desconocidos.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 16], [17, 26], [27, 32], [33, 38], [39, 42], [43, 54], [55, 57], [58, 71], [72, 73], [73, 76], [77, 78], [79, 85], [86, 92], [93, 105], [106, 107], [108, 116], [117, 126], [126, 127], [128, 134], [135, 137], [138, 142], [143, 147], [148, 151], [152, 162], [163, 172], [172, 173], [174, 182], [183, 185], [186, 189], [190, 199], [200, 207], [208, 211], [212, 215], [216, 219], [220, 228], [228, 229], [230, 232], [233, 235], [236, 247], [248, 258], [258, 259], [260, 262], [263, 274], [275, 280], [281, 290], [291, 294], [295, 303], [304, 305], [306, 308], [309, 318], [319, 321], [322, 332], [333, 346], [347, 356], [356, 357], [358, 366], [367, 370], [371, 373], [374, 376], [377, 391], [392, 394], [395, 408], [409, 410], [411, 413], [414, 421], [422, 424], [425, 430], [431, 432], [432, 435], [435, 436], [437, 439], [440, 445], [446, 451], [452, 454], [455, 457], [458, 472], [473, 475], [476, 489], [490, 501], [502, 514], [514, 515]]}
{"doc_key": "ai-test-274", "ner": [[2, 4, "algorithm"], [13, 19, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 4, 13, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Los", "modelos", "de", "Markov", "ocultos", "son", "la", "base", "de", "la", "mayor\u00eda", "de", "los", "sistemas", "modernos", "de", "reconocimiento", "autom\u00e1tico", "del", "habla", "."], "sentence-detokenized": "Los modelos de Markov ocultos son la base de la mayor\u00eda de los sistemas modernos de reconocimiento autom\u00e1tico del habla.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 21], [22, 29], [30, 33], [34, 36], [37, 41], [42, 44], [45, 47], [48, 55], [56, 58], [59, 62], [63, 71], [72, 80], [81, 83], [84, 98], [99, 109], [110, 113], [114, 119], [119, 120]]}
{"doc_key": "ai-test-275", "ner": [[3, 3, "location"], [4, 5, "country"], [11, 15, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 4, 5, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["una", "empresa", "de", "Bangalore", "(", "India", ")", "especializada", "en", "software", "de", "reconocimiento", "de", "escritura", "a", "mano", "en", "l\u00ednea", "."], "sentence-detokenized": "una empresa de Bangalore (India) especializada en software de reconocimiento de escritura a mano en l\u00ednea.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 24], [25, 26], [26, 31], [31, 32], [33, 46], [47, 49], [50, 58], [59, 61], [62, 76], [77, 79], [80, 89], [90, 91], [92, 96], [97, 99], [100, 105], [105, 106]]}
{"doc_key": "ai-test-276", "ner": [[26, 27, "misc"], [55, 55, "metrics"], [57, 59, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[55, 55, 57, 59, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["\u00bf", "Convergen", "las", "traducciones", "repetidas", "en", "una", "\u00fanica", "expresi\u00f3n", "en", "ambas", "lenguas", "?", "Es", "decir", ",", "\u00bf", "el", "m\u00e9todo", "de", "traducci\u00f3n", "muestra", "estacionariedad", "o", "produce", "una", "forma", "can\u00f3nica", "?", "\u00bf", "Se", "convierte", "la", "traducci\u00f3n", "en", "estacionaria", "sin", "perder", "el", "significado", "original", "?", "Esta", "m\u00e9trica", "ha", "sido", "criticada", "por", "no", "estar", "bien", "correlacionada", "con", "las", "puntuaciones", "BLEU", "(", "BiLingual", "Evaluation", "Understudy", ")", "."], "sentence-detokenized": "\u00bfConvergen las traducciones repetidas en una \u00fanica expresi\u00f3n en ambas lenguas? Es decir, \u00bfel m\u00e9todo de traducci\u00f3n muestra estacionariedad o produce una forma can\u00f3nica? \u00bfSe convierte la traducci\u00f3n en estacionaria sin perder el significado original? Esta m\u00e9trica ha sido criticada por no estar bien correlacionada con las puntuaciones BLEU (BiLingual Evaluation Understudy).", "token2charspan": [[0, 1], [1, 10], [11, 14], [15, 27], [28, 37], [38, 40], [41, 44], [45, 50], [51, 60], [61, 63], [64, 69], [70, 77], [77, 78], [79, 81], [82, 87], [87, 88], [89, 90], [90, 92], [93, 99], [100, 102], [103, 113], [114, 121], [122, 137], [138, 139], [140, 147], [148, 151], [152, 157], [158, 166], [166, 167], [168, 169], [169, 171], [172, 181], [182, 184], [185, 195], [196, 198], [199, 211], [212, 215], [216, 222], [223, 225], [226, 237], [238, 246], [246, 247], [248, 252], [253, 260], [261, 263], [264, 268], [269, 278], [279, 282], [283, 285], [286, 291], [292, 296], [297, 311], [312, 315], [316, 319], [320, 332], [333, 337], [338, 339], [339, 348], [349, 359], [360, 370], [370, 371], [371, 372]]}
{"doc_key": "ai-test-277", "ner": [[4, 8, "organisation"], [11, 18, "organisation"], [20, 23, "university"], [30, 31, "university"], [28, 29, "field"], [34, 38, "organisation"], [42, 45, "organisation"], [53, 56, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 18, 20, 23, "part-of", "", false, false], [30, 31, 28, 29, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Es", "becario", "de", "la", "Asociaci\u00f3n", "Americana", "de", "Inteligencia", "Artificial", ",", "del", "Centro", "de", "Estudios", "Avanzados", "en", "Ciencias", "del", "Comportamiento", "de", "la", "Universidad", "de", "Stanford", ",", "del", "Centro", "de", "Ciencias", "Cognitivas", "del", "MIT", ",", "del", "Instituto", "Canadiense", "de", "Investigaci\u00f3n", "Avanzada", "y", "de", "la", "Asociaci\u00f3n", "Canadiense", "de", "Psicolog\u00eda", ",", "y", "fue", "elegido", "miembro", "de", "la", "Real", "Sociedad", "de", "Canad\u00e1", "en", "1998", "."], "sentence-detokenized": "Es becario de la Asociaci\u00f3n Americana de Inteligencia Artificial, del Centro de Estudios Avanzados en Ciencias del Comportamiento de la Universidad de Stanford, del Centro de Ciencias Cognitivas del MIT, del Instituto Canadiense de Investigaci\u00f3n Avanzada y de la Asociaci\u00f3n Canadiense de Psicolog\u00eda, y fue elegido miembro de la Real Sociedad de Canad\u00e1 en 1998.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 16], [17, 27], [28, 37], [38, 40], [41, 53], [54, 64], [64, 65], [66, 69], [70, 76], [77, 79], [80, 88], [89, 98], [99, 101], [102, 110], [111, 114], [115, 129], [130, 132], [133, 135], [136, 147], [148, 150], [151, 159], [159, 160], [161, 164], [165, 171], [172, 174], [175, 183], [184, 194], [195, 198], [199, 202], [202, 203], [204, 207], [208, 217], [218, 228], [229, 231], [232, 245], [246, 254], [255, 256], [257, 259], [260, 262], [263, 273], [274, 284], [285, 287], [288, 298], [298, 299], [300, 301], [302, 305], [306, 313], [314, 321], [322, 324], [325, 327], [328, 332], [333, 341], [342, 344], [345, 351], [352, 354], [355, 359], [359, 360]]}
{"doc_key": "ai-test-278", "ner": [[0, 0, "researcher"], [3, 4, "researcher"], [6, 6, "researcher"], [13, 16, "misc"], [18, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 13, 16, "part-of", "", false, false], [0, 0, 18, 21, "part-of", "", false, false], [3, 4, 13, 16, "part-of", "", false, false], [3, 4, 18, 21, "part-of", "", false, false], [6, 6, 13, 16, "part-of", "", false, false], [6, 6, 18, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Hinton", "-junto", "con", "Yoshua", "Bengio", "y", "Yann", "LeCun-", "son", "llamados", "por", "algunos", "los", "Padres", "de", "la", "IA", "y", "Padrinos", "del", "Aprendizaje", "Profundo", "."], "sentence-detokenized": "Hinton -junto con Yoshua Bengio y Yann LeCun- son llamados por algunos los Padres de la IA y Padrinos del Aprendizaje Profundo.", "token2charspan": [[0, 6], [7, 13], [14, 17], [18, 24], [25, 31], [32, 33], [34, 38], [39, 45], [46, 49], [50, 58], [59, 62], [63, 70], [71, 74], [75, 81], [82, 84], [85, 87], [88, 90], [91, 92], [93, 101], [102, 105], [106, 117], [118, 126], [126, 127]]}
{"doc_key": "ai-test-279", "ner": [[8, 8, "product"], [22, 22, "misc"], [25, 26, "misc"], [27, 27, "product"], [31, 32, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 8, 22, 22, "related-to", "", false, false], [8, 8, 25, 26, "related-to", "", false, false], [22, 22, 27, 27, "named", "same", false, false], [31, 32, 27, 27, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["El", "proyecto", "ligero", "de", "voz", "de", "c\u00f3digo", "abierto", "eSpeak", ",", "que", "tiene", "su", "propio", "enfoque", "de", "s\u00edntesis", ",", "ha", "experimentado", "con", "el", "mandar\u00edn", "y", "el", "canton\u00e9s", ".", "eSpeak", "fue", "utilizado", "por", "Google", "Translate", "desde", "mayo", "de", "2010", "a", "2010", "."], "sentence-detokenized": "El proyecto ligero de voz de c\u00f3digo abierto eSpeak, que tiene su propio enfoque de s\u00edntesis, ha experimentado con el mandar\u00edn y el canton\u00e9s. eSpeak fue utilizado por Google Translate desde mayo de 2010 a 2010.", "token2charspan": [[0, 2], [3, 11], [12, 18], [19, 21], [22, 25], [26, 28], [29, 35], [36, 43], [44, 50], [50, 51], [52, 55], [56, 61], [62, 64], [65, 71], [72, 79], [80, 82], [83, 91], [91, 92], [93, 95], [96, 109], [110, 113], [114, 116], [117, 125], [126, 127], [128, 130], [131, 139], [139, 140], [141, 147], [148, 151], [152, 161], [162, 165], [166, 172], [173, 182], [183, 188], [189, 193], [194, 196], [197, 201], [202, 203], [204, 208], [208, 209]]}
{"doc_key": "ai-test-280", "ner": [[5, 7, "product"], [11, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 11, 15, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Tambi\u00e9n", "lanzado", "en", "1982", ",", "Software", "Automatic", "Mouth", "fue", "el", "primer", "programa", "comercial", "de", "s\u00edntesis", "de", "voz", "totalmente", "automatizado", "."], "sentence-detokenized": "Tambi\u00e9n lanzado en 1982, Software Automatic Mouth fue el primer programa comercial de s\u00edntesis de voz totalmente automatizado.", "token2charspan": [[0, 7], [8, 15], [16, 18], [19, 23], [23, 24], [25, 33], [34, 43], [44, 49], [50, 53], [54, 56], [57, 63], [64, 72], [73, 82], [83, 85], [86, 94], [95, 97], [98, 101], [102, 112], [113, 125], [125, 126]]}
{"doc_key": "ai-test-281", "ner": [[8, 9, "metrics"], [11, 11, "metrics"], [14, 14, "metrics"], [16, 16, "metrics"], [19, 28, "metrics"], [32, 33, "metrics"], [35, 35, "metrics"], [38, 44, "metrics"], [49, 51, "metrics"], [53, 53, "metrics"], [56, 56, "metrics"], [58, 58, "metrics"], [61, 67, "metrics"], [73, 75, "metrics"], [77, 77, "metrics"], [80, 86, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[11, 11, 8, 9, "named", "", false, false], [14, 14, 8, 9, "named", "", false, false], [16, 16, 8, 9, "named", "", false, false], [19, 28, 8, 9, "named", "", false, false], [35, 35, 32, 33, "named", "", false, false], [38, 44, 32, 33, "named", "", false, false], [53, 53, 49, 51, "named", "", false, false], [56, 56, 49, 51, "named", "", false, false], [58, 58, 49, 51, "named", "", false, false], [61, 67, 49, 51, "named", "", false, false], [77, 77, 73, 75, "named", "", false, false], [80, 86, 73, 75, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Los", "ratios", "de", "las", "columnas", "son", "la", "Tasa", "Positiva", "Verdadera", "(", "TPR", ",", "alias", "Sensibilidad", "o", "recall", ")", "(", "TP", "/", "(", "TP", "+", "FN", ")", ")", ",", "con", "complemento", "la", "Tasa", "Negativa", "Falsa", "(", "FNR", ")", "(", "FN", "/", "(", "TP", "+", "FN", ")", ")", ";", "y", "la", "Tasa", "Negativa", "Verdadera", "(", "TNR", ",", "alias", "Especificidad", ",", "SPC", ")", "(", "TN", "/", "(", "TN", "+", "FP", ")", ")", ",", "con", "complemento", "la", "Tasa", "Positiva", "Falsa", "(", "FPR", ")", "(", "FP", "/", "(", "TN", "+", "FP", ")", ")", "."], "sentence-detokenized": "Los ratios de las columnas son la Tasa Positiva Verdadera (TPR, alias Sensibilidad o recall) (TP / (TP + FN)), con complemento la Tasa Negativa Falsa (FNR) (FN / (TP + FN)); y la Tasa Negativa Verdadera (TNR, alias Especificidad, SPC) (TN / (TN + FP)), con complemento la Tasa Positiva Falsa (FPR) (FP / (TN + FP)).", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 17], [18, 26], [27, 30], [31, 33], [34, 38], [39, 47], [48, 57], [58, 59], [59, 62], [62, 63], [64, 69], [70, 82], [83, 84], [85, 91], [91, 92], [93, 94], [94, 96], [97, 98], [99, 100], [100, 102], [103, 104], [105, 107], [107, 108], [108, 109], [109, 110], [111, 114], [115, 126], [127, 129], [130, 134], [135, 143], [144, 149], [150, 151], [151, 154], [154, 155], [156, 157], [157, 159], [160, 161], [162, 163], [163, 165], [166, 167], [168, 170], [170, 171], [171, 172], [172, 173], [174, 175], [176, 178], [179, 183], [184, 192], [193, 202], [203, 204], [204, 207], [207, 208], [209, 214], [215, 228], [228, 229], [230, 233], [233, 234], [235, 236], [236, 238], [239, 240], [241, 242], [242, 244], [245, 246], [247, 249], [249, 250], [250, 251], [251, 252], [253, 256], [257, 268], [269, 271], [272, 276], [277, 285], [286, 291], [292, 293], [293, 296], [296, 297], [298, 299], [299, 301], [302, 303], [304, 305], [305, 307], [308, 309], [310, 312], [312, 313], [313, 314], [314, 315]]}
{"doc_key": "ai-test-282", "ner": [[0, 0, "person"], [2, 2, "person"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 16, 16, "role", "working_with", false, false], [2, 2, 16, 16, "role", "working_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Edsinger", "y", "Weber", "tambi\u00e9n", "colaboraron", "en", "muchos", "otros", "robots", ",", "y", "su", "experiencia", "trabajando", "con", "el", "Kismet"], "sentence-detokenized": "Edsinger y Weber tambi\u00e9n colaboraron en muchos otros robots, y su experiencia trabajando con el Kismet", "token2charspan": [[0, 8], [9, 10], [11, 16], [17, 24], [25, 36], [37, 39], [40, 46], [47, 52], [53, 59], [59, 60], [61, 62], [63, 65], [66, 77], [78, 88], [89, 92], [93, 95], [96, 102]]}
{"doc_key": "ai-test-283", "ner": [[3, 3, "programlang"], [12, 12, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 12, 12, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["La", "funcionalidad", "de", "R", "es", "accesible", "desde", "varios", "lenguajes", "de", "scripting", "como", "Python", ",", "tambi\u00e9n", "est\u00e1n", "disponibles", "."], "sentence-detokenized": "La funcionalidad de R es accesible desde varios lenguajes de scripting como Python, tambi\u00e9n est\u00e1n disponibles.", "token2charspan": [[0, 2], [3, 16], [17, 19], [20, 21], [22, 24], [25, 34], [35, 40], [41, 47], [48, 57], [58, 60], [61, 70], [71, 75], [76, 82], [82, 83], [84, 91], [92, 97], [98, 109], [109, 110]]}
{"doc_key": "ai-test-284", "ner": [[0, 0, "programlang"], [13, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 14, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VAL", "fue", "uno", "de", "los", "primeros", "lenguajes", "rob\u00f3ticos", "y", "se", "utiliz\u00f3", "en", "los", "robots", "Unimate", "."], "sentence-detokenized": "VAL fue uno de los primeros lenguajes rob\u00f3ticos y se utiliz\u00f3 en los robots Unimate.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 18], [19, 27], [28, 37], [38, 47], [48, 49], [50, 52], [53, 60], [61, 63], [64, 67], [68, 74], [75, 82], [82, 83]]}
{"doc_key": "ai-test-285", "ner": [[14, 27, "conference"], [24, 24, "conference"], [30, 31, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 27, 30, 31, "physical", "", false, false], [24, 24, 14, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Presentaron", "su", "base", "de", "datos", "por", "primera", "vez", "en", "forma", "de", "p\u00f3ster", "en", "la", "Conferencia", "sobre", "Visi\u00f3n", "por", "Ordenador", "y", "Reconocimiento", "de", "Patrones", "(", "CVPR", ")", "de", "2009", ",", "celebrada", "en", "Florida", "."], "sentence-detokenized": "Presentaron su base de datos por primera vez en forma de p\u00f3ster en la Conferencia sobre Visi\u00f3n por Ordenador y Reconocimiento de Patrones (CVPR) de 2009, celebrada en Florida.", "token2charspan": [[0, 11], [12, 14], [15, 19], [20, 22], [23, 28], [29, 32], [33, 40], [41, 44], [45, 47], [48, 53], [54, 56], [57, 63], [64, 66], [67, 69], [70, 81], [82, 87], [88, 94], [95, 98], [99, 108], [109, 110], [111, 125], [126, 128], [129, 137], [138, 139], [139, 143], [143, 144], [145, 147], [148, 152], [152, 153], [154, 163], [164, 166], [167, 174], [174, 175]]}
{"doc_key": "ai-test-286", "ner": [[0, 3, "misc"], [13, 15, "task"], [17, 19, "field"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 15, 0, 3, "type-of", "", false, false], [17, 19, 0, 3, "type-of", "", false, false], [21, 23, 0, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Las", "tareas", "de", "categorizaci\u00f3n", "en", "las", "que", "no", "se", "suministran", "etiquetas", "se", "denominan", "clasificaci\u00f3n", "no", "supervisada", ",", "aprendizaje", "no", "supervisado", ",", "an\u00e1lisis", "de", "cl\u00fasteres", "."], "sentence-detokenized": "Las tareas de categorizaci\u00f3n en las que no se suministran etiquetas se denominan clasificaci\u00f3n no supervisada, aprendizaje no supervisado, an\u00e1lisis de cl\u00fasteres.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 28], [29, 31], [32, 35], [36, 39], [40, 42], [43, 45], [46, 57], [58, 67], [68, 70], [71, 80], [81, 94], [95, 97], [98, 109], [109, 110], [111, 122], [123, 125], [126, 137], [137, 138], [139, 147], [148, 150], [151, 160], [160, 161]]}
{"doc_key": "ai-test-287", "ner": [[2, 4, "task"], [15, 17, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Necesita", "el", "reconocimiento", "de", "objetos", ",", "reconocer", "y", "localizar", "a", "los", "seres", "humanos", "y", "seguir", "reconociendo", "las", "emociones", "."], "sentence-detokenized": "Necesita el reconocimiento de objetos, reconocer y localizar a los seres humanos y seguir reconociendo las emociones.", "token2charspan": [[0, 8], [9, 11], [12, 26], [27, 29], [30, 37], [37, 38], [39, 48], [49, 50], [51, 60], [61, 62], [63, 66], [67, 72], [73, 80], [81, 82], [83, 89], [90, 102], [103, 106], [107, 116], [116, 117]]}
{"doc_key": "ai-test-288", "ner": [[6, 6, "misc"], [8, 8, "misc"], [10, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["El", "proceso", "es", "complejo", "y", "contiene", "codificaci\u00f3n", "y", "recuerdo", "o", "recuperaci\u00f3n", "."], "sentence-detokenized": "El proceso es complejo y contiene codificaci\u00f3n y recuerdo o recuperaci\u00f3n.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 22], [23, 24], [25, 33], [34, 46], [47, 48], [49, 57], [58, 59], [60, 72], [72, 73]]}
{"doc_key": "ai-test-289", "ner": [[7, 8, "product"], [13, 14, "product"], [33, 34, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 13, 14, "named", "", false, false], [7, 8, 33, 34, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Tambi\u00e9n", "conocidos", "como", "robots", "paralelos", ",", "o", "plataformas", "Stewart", "generalizadas", "(", "en", "la", "plataforma", "Stewart", ",", "los", "actuadores", "est\u00e1n", "emparejados", "tanto", "en", "la", "base", "como", "en", "la", "plataforma", ")", ",", "estos", "sistemas", "son", "robots", "articulados", "que", "utilizan", "mecanismos", "similares", "para", "el", "movimiento", "del", "robot", "en", "su", "base", ",", "o", "de", "uno", "o", "m\u00e1s", "brazos", "manipuladores", "."], "sentence-detokenized": "Tambi\u00e9n conocidos como robots paralelos, o plataformas Stewart generalizadas (en la plataforma Stewart, los actuadores est\u00e1n emparejados tanto en la base como en la plataforma), estos sistemas son robots articulados que utilizan mecanismos similares para el movimiento del robot en su base, o de uno o m\u00e1s brazos manipuladores.", "token2charspan": [[0, 7], [8, 17], [18, 22], [23, 29], [30, 39], [39, 40], [41, 42], [43, 54], [55, 62], [63, 76], [77, 78], [78, 80], [81, 83], [84, 94], [95, 102], [102, 103], [104, 107], [108, 118], [119, 124], [125, 136], [137, 142], [143, 145], [146, 148], [149, 153], [154, 158], [159, 161], [162, 164], [165, 175], [175, 176], [176, 177], [178, 183], [184, 192], [193, 196], [197, 203], [204, 215], [216, 219], [220, 228], [229, 239], [240, 249], [250, 254], [255, 257], [258, 268], [269, 272], [273, 278], [279, 281], [282, 284], [285, 289], [289, 290], [291, 292], [293, 295], [296, 299], [300, 301], [302, 305], [306, 312], [313, 326], [326, 327]]}
{"doc_key": "ai-test-290", "ner": [[0, 2, "field"], [7, 10, "field"], [17, 19, "field"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 7, 10, "part-of", "subfield", false, false], [0, 2, 17, 19, "compare", "", false, false], [17, 19, 24, 25, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "visi\u00f3n", "artificial", ",", "como", "disciplina", "de", "la", "ingenier\u00eda", "de", "sistemas", ",", "puede", "considerarse", "distinta", "de", "la", "visi\u00f3n", "por", "ordenador", ",", "una", "forma", "de", "ciencia", "inform\u00e1tica", "."], "sentence-detokenized": "La visi\u00f3n artificial, como disciplina de la ingenier\u00eda de sistemas, puede considerarse distinta de la visi\u00f3n por ordenador, una forma de ciencia inform\u00e1tica.", "token2charspan": [[0, 2], [3, 9], [10, 20], [20, 21], [22, 26], [27, 37], [38, 40], [41, 43], [44, 54], [55, 57], [58, 66], [66, 67], [68, 73], [74, 86], [87, 95], [96, 98], [99, 101], [102, 108], [109, 112], [113, 122], [122, 123], [124, 127], [128, 133], [134, 136], [137, 144], [145, 156], [156, 157]]}
{"doc_key": "ai-test-291", "ner": [[6, 7, "algorithm"], [11, 13, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 11, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["La", "funci\u00f3n", "de", "activaci\u00f3n", "de", "las", "puertas", "LSTM", "suele", "ser", "la", "funci\u00f3n", "sigmoidea", "log\u00edstica", "."], "sentence-detokenized": "La funci\u00f3n de activaci\u00f3n de las puertas LSTM suele ser la funci\u00f3n sigmoidea log\u00edstica.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 24], [25, 27], [28, 31], [32, 39], [40, 44], [45, 50], [51, 54], [55, 57], [58, 65], [66, 75], [76, 85], [85, 86]]}
{"doc_key": "ai-test-292", "ner": [[5, 6, "metrics"], [22, 26, "metrics"], [28, 28, "metrics"], [35, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 22, 26, "named", "", false, false], [5, 6, 35, 38, "named", "", false, false], [28, 28, 22, 26, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["En", "otras", "palabras", ",", "la", "media", "muestral", "es", "el", "estimador", "eficiente", "(", "necesariamente", "\u00fanico", ")", "y", ",", "por", "tanto", ",", "tambi\u00e9n", "el", "estimador", "insesgado", "de", "m\u00ednima", "varianza", "(", "MVUE", ")", ",", "adem\u00e1s", "de", "ser", "el", "estimador", "de", "m\u00e1xima", "verosimilitud", "."], "sentence-detokenized": "En otras palabras, la media muestral es el estimador eficiente (necesariamente \u00fanico) y, por tanto, tambi\u00e9n el estimador insesgado de m\u00ednima varianza (MVUE), adem\u00e1s de ser el estimador de m\u00e1xima verosimilitud.", "token2charspan": [[0, 2], [3, 8], [9, 17], [17, 18], [19, 21], [22, 27], [28, 36], [37, 39], [40, 42], [43, 52], [53, 62], [63, 64], [64, 78], [79, 84], [84, 85], [86, 87], [87, 88], [89, 92], [93, 98], [98, 99], [100, 107], [108, 110], [111, 120], [121, 130], [131, 133], [134, 140], [141, 149], [150, 151], [151, 155], [155, 156], [156, 157], [158, 164], [165, 167], [168, 171], [172, 174], [175, 184], [185, 187], [188, 194], [195, 208], [208, 209]]}
{"doc_key": "ai-test-293", "ner": [[5, 6, "academicjournal"], [10, 10, "researcher"], [12, 13, "researcher"], [15, 16, "researcher"], [24, 26, "product"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 6, 24, 26, "topic", "", false, false], [5, 6, 28, 29, "topic", "", false, false], [10, 10, 5, 6, "role", "", false, false], [12, 13, 5, 6, "role", "", false, false], [15, 16, 5, 6, "role", "", false, false], [24, 26, 28, 29, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["El", "art\u00edculo", "de", "2001", "de", "Scientific", "American", ",", "escrito", "por", "Berners-Lee", ",", "James", "Hendler", "y", "Ora", "Lassila", ",", "describ\u00eda", "la", "evoluci\u00f3n", "prevista", "de", "la", "Web", "actual", "hacia", "una", "Web", "Sem\u00e1ntica", "."], "sentence-detokenized": "El art\u00edculo de 2001 de Scientific American, escrito por Berners-Lee, James Hendler y Ora Lassila, describ\u00eda la evoluci\u00f3n prevista de la Web actual hacia una Web Sem\u00e1ntica.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 19], [20, 22], [23, 33], [34, 42], [42, 43], [44, 51], [52, 55], [56, 67], [67, 68], [69, 74], [75, 82], [83, 84], [85, 88], [89, 96], [96, 97], [98, 107], [108, 110], [111, 120], [121, 129], [130, 132], [133, 135], [136, 139], [140, 146], [147, 152], [153, 156], [157, 160], [161, 170], [170, 171]]}
{"doc_key": "ai-test-294", "ner": [[0, 1, "misc"], [10, 11, "person"], [14, 14, "person"], [31, 31, "person"], [39, 39, "person"], [43, 44, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 11, 0, 1, "role", "actor_in_work", false, false], [14, 14, 10, 11, "named", "", false, false], [14, 14, 10, 11, "origin", "", false, false], [31, 31, 14, 14, "part-of", "", false, false], [43, 44, 14, 14, "role", "auditioned_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Blade", "Runner", "utiliz\u00f3", "a", "varios", "actores", "entonces", "menos", "conocidos", ":", "Sean", "Young", "interpreta", "a", "Rachael", ",", "una", "replicante", "experimental", "a", "la", "que", "se", "le", "implantan", "los", "recuerdos", "de", "la", "sobrina", "de", "Tyrell", ",", "haci\u00e9ndole", "creer", "que", "es", "humana", ";", "Sammon", ",", "pp.", "92-93", "Nina", "Axelrod", "hizo", "una", "audici\u00f3n", "para", "el", "papel", "."], "sentence-detokenized": "Blade Runner utiliz\u00f3 a varios actores entonces menos conocidos: Sean Young interpreta a Rachael, una replicante experimental a la que se le implantan los recuerdos de la sobrina de Tyrell, haci\u00e9ndole creer que es humana; Sammon, pp. 92-93 Nina Axelrod hizo una audici\u00f3n para el papel.", "token2charspan": [[0, 5], [6, 12], [13, 20], [21, 22], [23, 29], [30, 37], [38, 46], [47, 52], [53, 62], [62, 63], [64, 68], [69, 74], [75, 85], [86, 87], [88, 95], [95, 96], [97, 100], [101, 111], [112, 124], [125, 126], [127, 129], [130, 133], [134, 136], [137, 139], [140, 149], [150, 153], [154, 163], [164, 166], [167, 169], [170, 177], [178, 180], [181, 187], [187, 188], [189, 199], [200, 205], [206, 209], [210, 212], [213, 219], [219, 220], [221, 227], [227, 228], [229, 232], [233, 238], [239, 243], [244, 251], [252, 256], [257, 260], [261, 269], [270, 274], [275, 277], [278, 283], [283, 284]]}
{"doc_key": "ai-test-295", "ner": [[0, 1, "researcher"], [3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [13, 15, "university"], [22, 22, "product"], [24, 24, "product"], [46, 47, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 13, 15, "physical", "", false, false], [3, 4, 13, 15, "physical", "", false, false], [6, 7, 13, 15, "physical", "", false, false], [9, 10, 13, 15, "physical", "", false, false], [13, 15, 46, 47, "physical", "", true, false], [22, 22, 13, 15, "temporal", "", false, false], [24, 24, 13, 15, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Gerry", "Sussman", ",", "Eugene", "Charniak", ",", "Seymour", "Papert", "y", "Terry", "Winograd", "visitaron", "la", "Universidad", "de", "Edimburgo", "en", "1971", "difundiendo", "la", "noticia", "sobre", "Micro-Planner", "y", "SHRDLU", "y", "poniendo", "en", "duda", "el", "enfoque", "del", "procedimiento", "de", "prueba", "uniforme", "de", "resoluci\u00f3n", "que", "hab\u00eda", "sido", "el", "pilar", "de", "los", "logicistas", "de", "Edimburgo", "."], "sentence-detokenized": "Gerry Sussman, Eugene Charniak, Seymour Papert y Terry Winograd visitaron la Universidad de Edimburgo en 1971 difundiendo la noticia sobre Micro-Planner y SHRDLU y poniendo en duda el enfoque del procedimiento de prueba uniforme de resoluci\u00f3n que hab\u00eda sido el pilar de los logicistas de Edimburgo.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 21], [22, 30], [30, 31], [32, 39], [40, 46], [47, 48], [49, 54], [55, 63], [64, 73], [74, 76], [77, 88], [89, 91], [92, 101], [102, 104], [105, 109], [110, 121], [122, 124], [125, 132], [133, 138], [139, 152], [153, 154], [155, 161], [162, 163], [164, 172], [173, 175], [176, 180], [181, 183], [184, 191], [192, 195], [196, 209], [210, 212], [213, 219], [220, 228], [229, 231], [232, 242], [243, 246], [247, 252], [253, 257], [258, 260], [261, 266], [267, 269], [270, 273], [274, 284], [285, 287], [288, 297], [297, 298]]}
{"doc_key": "ai-test-296", "ner": [[11, 13, "field"], [14, 15, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["El", "trabajo", "de", "Walter", "inspir\u00f3", "a", "generaciones", "posteriores", "de", "investigadores", "en", "rob\u00f3tica", ",", "como", "Rodney", "Brooks", ",", "Hans", "Moravec", "y", "Mark", "Tilden", "."], "sentence-detokenized": "El trabajo de Walter inspir\u00f3 a generaciones posteriores de investigadores en rob\u00f3tica, como Rodney Brooks, Hans Moravec y Mark Tilden.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 20], [21, 28], [29, 30], [31, 43], [44, 55], [56, 58], [59, 73], [74, 76], [77, 85], [85, 86], [87, 91], [92, 98], [99, 105], [105, 106], [107, 111], [112, 119], [120, 121], [122, 126], [127, 133], [133, 134]]}
{"doc_key": "ai-test-297", "ner": [[3, 3, "algorithm"], [12, 13, "researcher"], [19, 28, "event"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 12, 13, "origin", "", false, false], [3, 3, 19, 28, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Posteriormente", ",", "una", "CNN", "similar", "basada", "en", "la", "GPU", ",", "obra", "de", "Alex", "Krizhevsky", "et", "al.", ",", "gan\u00f3", "el", "Desaf\u00edo", "de", "Reconocimiento", "Visual", "a", "Gran", "Escala", "de", "ImageNet", "2012", "."], "sentence-detokenized": "Posteriormente, una CNN similar basada en la GPU, obra de Alex Krizhevsky et al., gan\u00f3 el Desaf\u00edo de Reconocimiento Visual a Gran Escala de ImageNet 2012.", "token2charspan": [[0, 14], [14, 15], [16, 19], [20, 23], [24, 31], [32, 38], [39, 41], [42, 44], [45, 48], [48, 49], [50, 54], [55, 57], [58, 62], [63, 73], [74, 76], [77, 80], [80, 81], [82, 86], [87, 89], [90, 97], [98, 100], [101, 115], [116, 122], [123, 124], [125, 129], [130, 136], [137, 139], [140, 148], [149, 153], [153, 154]]}
{"doc_key": "ai-test-298", "ner": [[0, 3, "misc"], [12, 13, "metrics"], [16, 18, "metrics"], [23, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 13, 0, 3, "type-of", "", false, false], [16, 18, 0, 3, "type-of", "", false, false], [16, 18, 23, 27, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Las", "funciones", "de", "p\u00e9rdida", "com\u00fanmente", "utilizadas", "para", "la", "clasificaci\u00f3n", "probabil\u00edstica", "incluyen", "la", "p\u00e9rdida", "logar\u00edtmica", "y", "la", "puntuaci\u00f3n", "de", "Brier", "entre", "las", "distribuciones", "de", "probabilidad", "predichas", "y", "las", "verdaderas", "."], "sentence-detokenized": "Las funciones de p\u00e9rdida com\u00fanmente utilizadas para la clasificaci\u00f3n probabil\u00edstica incluyen la p\u00e9rdida logar\u00edtmica y la puntuaci\u00f3n de Brier entre las distribuciones de probabilidad predichas y las verdaderas.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 24], [25, 35], [36, 46], [47, 51], [52, 54], [55, 68], [69, 83], [84, 92], [93, 95], [96, 103], [104, 115], [116, 117], [118, 120], [121, 131], [132, 134], [135, 140], [141, 146], [147, 150], [151, 165], [166, 168], [169, 181], [182, 191], [192, 193], [194, 197], [198, 208], [208, 209]]}
{"doc_key": "ai-test-299", "ner": [[5, 5, "organisation"], [14, 14, "field"], [15, 16, "organisation"], [20, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 14, 14, "general-affiliation", "field_of_study", false, false], [5, 5, 20, 21, "part-of", "", false, false], [15, 16, 5, 5, "role", "admits_E2_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["En", "mayo", "de", "2016", ",", "NtechLab", "fue", "admitida", "en", "las", "pruebas", "oficiales", "de", "tecnolog\u00eda", "biom\u00e9trica", "del", "NIST", "entre", "las", "tres", "empresas", "rusas", "."], "sentence-detokenized": "En mayo de 2016, NtechLab fue admitida en las pruebas oficiales de tecnolog\u00eda biom\u00e9trica del NIST entre las tres empresas rusas.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 15], [15, 16], [17, 25], [26, 29], [30, 38], [39, 41], [42, 45], [46, 53], [54, 63], [64, 66], [67, 77], [78, 88], [89, 92], [93, 97], [98, 103], [104, 107], [108, 112], [113, 121], [122, 127], [127, 128]]}
{"doc_key": "ai-test-300", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sin", "embargo", ",", "los", "n\u00fameros", "de", "punto", "flotante", "s\u00f3lo", "tienen", "una", "cierta", "precisi\u00f3n", "matem\u00e1tica", "."], "sentence-detokenized": "Sin embargo, los n\u00fameros de punto flotante s\u00f3lo tienen una cierta precisi\u00f3n matem\u00e1tica.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 24], [25, 27], [28, 33], [34, 42], [43, 47], [48, 54], [55, 58], [59, 65], [66, 75], [76, 86], [86, 87]]}
{"doc_key": "ai-test-301", "ner": [[8, 8, "organisation"], [13, 19, "conference"], [21, 21, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 13, 19, "role", "contributes_to", false, false], [21, 21, 13, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Durante", "2015", ",", "muchos", "de", "los", "trabajos", "de", "SenseTime", "fueron", "aceptados", "en", "la", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "."], "sentence-detokenized": "Durante 2015, muchos de los trabajos de SenseTime fueron aceptados en la Conference on Computer Vision and Pattern Recognition (CVPR).", "token2charspan": [[0, 7], [8, 12], [12, 13], [14, 20], [21, 23], [24, 27], [28, 36], [37, 39], [40, 49], [50, 56], [57, 66], [67, 69], [70, 72], [73, 83], [84, 86], [87, 95], [96, 102], [103, 106], [107, 114], [115, 126], [127, 128], [128, 132], [132, 133], [133, 134]]}
{"doc_key": "ai-test-302", "ner": [[5, 9, "task"], [11, 11, "task"], [14, 15, "task"], [17, 20, "task"], [25, 26, "misc"], [31, 39, "conference"], [47, 49, "misc"], [51, 52, "conference"], [27, 71, "misc"], [23, 73, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10], "relations": [[11, 11, 5, 9, "named", "", false, false], [17, 20, 14, 15, "named", "", false, false], [25, 26, 31, 39, "temporal", "", false, false], [47, 49, 51, 52, "temporal", "", false, false], [27, 71, 23, 73, "temporal", "", false, false]], "relations_mapping_to_source": [1, 3, 4, 5, 6], "sentence": ["Co-desarroll\u00f3", "algoritmos", "\u00f3ptimos", "para", "la", "estructura", "a", "partir", "del", "movimiento", "(", "SFM", ",", "o", "Visual", "SLAM", ",", "localizaci\u00f3n", "y", "mapeo", "simult\u00e1neos", ",", "en", "Rob\u00f3tica", ";", "Premio", "al", "mejor", "art\u00edculo", "en", "la", "Conferencia", "de", "Visi\u00f3n", "por", "Computador", "y", "Reconocimiento", "de", "Patrones", "1998", ")", ",", "caracteriz\u00f3", "sus", "ambig\u00fcedades", "(", "Premio", "David", "Marr", "en", "ICCV", "1999", ")", ",", "tambi\u00e9n", "caracteriz\u00f3", "la", "identificabilidad", "y", "observabilidad", "de", "la", "fusi\u00f3n", "de", "sensores", "visuales-inerciales", "(", "Premio", "al", "mejor", "art\u00edculo", "en", "Rob\u00f3tica", "2015", ")", "."], "sentence-detokenized": "Co-desarroll\u00f3 algoritmos \u00f3ptimos para la estructura a partir del movimiento (SFM, o Visual SLAM, localizaci\u00f3n y mapeo simult\u00e1neos, en Rob\u00f3tica; Premio al mejor art\u00edculo en la Conferencia de Visi\u00f3n por Computador y Reconocimiento de Patrones 1998), caracteriz\u00f3 sus ambig\u00fcedades (Premio David Marr en ICCV 1999), tambi\u00e9n caracteriz\u00f3 la identificabilidad y observabilidad de la fusi\u00f3n de sensores visuales-inerciales (Premio al mejor art\u00edculo en Rob\u00f3tica 2015).", "token2charspan": [[0, 13], [14, 24], [25, 32], [33, 37], [38, 40], [41, 51], [52, 53], [54, 60], [61, 64], [65, 75], [76, 77], [77, 80], [80, 81], [82, 83], [84, 90], [91, 95], [95, 96], [97, 109], [110, 111], [112, 117], [118, 129], [129, 130], [131, 133], [134, 142], [142, 143], [144, 150], [151, 153], [154, 159], [160, 168], [169, 171], [172, 174], [175, 186], [187, 189], [190, 196], [197, 200], [201, 211], [212, 213], [214, 228], [229, 231], [232, 240], [241, 245], [245, 246], [246, 247], [248, 259], [260, 263], [264, 276], [277, 278], [278, 284], [285, 290], [291, 295], [296, 298], [299, 303], [304, 308], [308, 309], [309, 310], [311, 318], [319, 330], [331, 333], [334, 351], [352, 353], [354, 368], [369, 371], [372, 374], [375, 381], [382, 384], [385, 393], [394, 413], [414, 415], [415, 421], [422, 424], [425, 430], [431, 439], [440, 442], [443, 451], [452, 456], [456, 457], [457, 458]]}
{"doc_key": "ai-test-303", "ner": [[0, 2, "researcher"], [3, 3, "organisation"], [5, 5, "organisation"], [7, 14, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Stephen", "H.", "Muggleton", "FBCS", ",", "FIET", ",", "Asociaci\u00f3n", "para", "el", "Avance", "de", "la", "Inteligencia", "Artificial", ","], "sentence-detokenized": "Stephen H. Muggleton FBCS, FIET, Asociaci\u00f3n para el Avance de la Inteligencia Artificial,", "token2charspan": [[0, 7], [8, 10], [11, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 43], [44, 48], [49, 51], [52, 58], [59, 61], [62, 64], [65, 77], [78, 88], [88, 89]]}
{"doc_key": "ai-test-304", "ner": [[0, 3, "task"], [10, 12, "field"], [15, 16, "field"], [19, 21, "field"], [28, 28, "task"], [30, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 3, 10, 12, "part-of", "task_part_of_field", false, false], [0, 3, 15, 16, "part-of", "task_part_of_field", false, false], [0, 3, 19, 21, "part-of", "task_part_of_field", false, false], [0, 3, 28, 28, "part-of", "", false, false], [0, 3, 30, 32, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["La", "detecci\u00f3n", "de", "bordes", "es", "una", "herramienta", "fundamental", "en", "el", "procesamiento", "de", "im\u00e1genes", ",", "la", "visi\u00f3n", "artificial", "y", "la", "visi\u00f3n", "por", "ordenador", ",", "especialmente", "en", "las", "\u00e1reas", "de", "detecci\u00f3n", "y", "extracci\u00f3n", "de", "caracter\u00edsticas", "."], "sentence-detokenized": "La detecci\u00f3n de bordes es una herramienta fundamental en el procesamiento de im\u00e1genes, la visi\u00f3n artificial y la visi\u00f3n por ordenador, especialmente en las \u00e1reas de detecci\u00f3n y extracci\u00f3n de caracter\u00edsticas.", "token2charspan": [[0, 2], [3, 12], [13, 15], [16, 22], [23, 25], [26, 29], [30, 41], [42, 53], [54, 56], [57, 59], [60, 73], [74, 76], [77, 85], [85, 86], [87, 89], [90, 96], [97, 107], [108, 109], [110, 112], [113, 119], [120, 123], [124, 133], [133, 134], [135, 148], [149, 151], [152, 155], [156, 161], [162, 164], [165, 174], [175, 176], [177, 187], [188, 190], [191, 206], [206, 207]]}
{"doc_key": "ai-test-305", "ner": [[9, 10, "misc"], [26, 28, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Un", "ejemplo", "de", "esto", "ser\u00eda", "una", "variable", "como", "la", "temperatura", "exterior", "(", "mathtemp", "/", "math", ")", ",", "que", "en", "una", "aplicaci\u00f3n", "determinada", "podr\u00eda", "registrarse", "con", "varios", "decimales", "de", "precisi\u00f3n", "(", "dependiendo", "del", "aparato", "de", "detecci\u00f3n", ")", "."], "sentence-detokenized": "Un ejemplo de esto ser\u00eda una variable como la temperatura exterior (mathtemp / math), que en una aplicaci\u00f3n determinada podr\u00eda registrarse con varios decimales de precisi\u00f3n (dependiendo del aparato de detecci\u00f3n).", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 18], [19, 24], [25, 28], [29, 37], [38, 42], [43, 45], [46, 57], [58, 66], [67, 68], [68, 76], [77, 78], [79, 83], [83, 84], [84, 85], [86, 89], [90, 92], [93, 96], [97, 107], [108, 119], [120, 126], [127, 138], [139, 142], [143, 149], [150, 159], [160, 162], [163, 172], [173, 174], [174, 185], [186, 189], [190, 197], [198, 200], [201, 210], [210, 211], [211, 212]]}
{"doc_key": "ai-test-306", "ner": [[5, 6, "person"], [8, 9, "person"], [11, 12, "person"], [23, 24, "person"], [28, 29, "misc"], [34, 34, "misc"], [35, 39, "person"], [42, 43, "organisation"], [44, 45, "person"], [50, 50, "organisation"], [51, 56, "person"], [57, 57, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[35, 39, 28, 29, "part-of", "", false, false], [35, 39, 34, 34, "role", "", false, false], [44, 45, 42, 43, "role", "", false, false], [51, 56, 50, 50, "role", "youtuber", false, false], [57, 57, 51, 56, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Los", "jueces", "que", "regresan", "son", "Fon", "Davis", ",", "Jessica", "Chobot", "y", "Leland", "Melvin", ",", "as\u00ed", "como", "los", "jueces", "invitados", "famosos", ",", "el", "actor", "Clark", "Gregg", ",", "el", "presentador", "de", "MythBusters", "y", "antiguo", "constructor", "de", "Battlebots", ",", "Adam", "Savage", ",", "el", "jugador", "de", "la", "NFL", "Vernon", "Davis", "y", "la", "estrella", "de", "YouTube", "Michael", "Stevens", ",", "tambi\u00e9n", "conocido", "como", "Vsauce", "."], "sentence-detokenized": "Los jueces que regresan son Fon Davis, Jessica Chobot y Leland Melvin, as\u00ed como los jueces invitados famosos, el actor Clark Gregg, el presentador de MythBusters y antiguo constructor de Battlebots, Adam Savage, el jugador de la NFL Vernon Davis y la estrella de YouTube Michael Stevens, tambi\u00e9n conocido como Vsauce.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 27], [28, 31], [32, 37], [37, 38], [39, 46], [47, 53], [54, 55], [56, 62], [63, 69], [69, 70], [71, 74], [75, 79], [80, 83], [84, 90], [91, 100], [101, 108], [108, 109], [110, 112], [113, 118], [119, 124], [125, 130], [130, 131], [132, 134], [135, 146], [147, 149], [150, 161], [162, 163], [164, 171], [172, 183], [184, 186], [187, 197], [197, 198], [199, 203], [204, 210], [210, 211], [212, 214], [215, 222], [223, 225], [226, 228], [229, 232], [233, 239], [240, 245], [246, 247], [248, 250], [251, 259], [260, 262], [263, 270], [271, 278], [279, 286], [286, 287], [288, 295], [296, 304], [305, 309], [310, 316], [316, 317]]}
{"doc_key": "ai-test-307", "ner": [[10, 13, "algorithm"], [15, 18, "algorithm"], [20, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 13, 20, 20, "part-of", "", false, false], [15, 18, 20, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pero", "estos", "m\u00e9todos", "nunca", "se", "impusieron", "a", "la", "tecnolog\u00eda", "del", "modelo", "de", "mezcla", "gaussiana", "/", "modelo", "oculto", "de", "Markov", "(", "GMM-HMM", ")", "no", "uniforme", "y", "de", "elaboraci\u00f3n", "interna", ",", "basada", "en", "modelos", "generativos", "del", "habla", "entrenados", "de", "forma", "discriminatoria", "."], "sentence-detokenized": "Pero estos m\u00e9todos nunca se impusieron a la tecnolog\u00eda del modelo de mezcla gaussiana / modelo oculto de Markov (GMM-HMM) no uniforme y de elaboraci\u00f3n interna, basada en modelos generativos del habla entrenados de forma discriminatoria.", "token2charspan": [[0, 4], [5, 10], [11, 18], [19, 24], [25, 27], [28, 38], [39, 40], [41, 43], [44, 54], [55, 58], [59, 65], [66, 68], [69, 75], [76, 85], [86, 87], [88, 94], [95, 101], [102, 104], [105, 111], [112, 113], [113, 120], [120, 121], [122, 124], [125, 133], [134, 135], [136, 138], [139, 150], [151, 158], [158, 159], [160, 166], [167, 169], [170, 177], [178, 189], [190, 193], [194, 199], [200, 210], [211, 213], [214, 219], [220, 235], [235, 236]]}
{"doc_key": "ai-test-308", "ner": [[4, 4, "product"], [6, 7, "programlang"], [9, 9, "programlang"], [11, 11, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Paquetes", "de", "software", "como", "MATLAB", ",", "GNU", "Octave", ",", "Scilab", "y", "SciPy", "proporcionan", "formas", "convenientes", "de", "aplicar", "estos", "diferentes", "m\u00e9todos", "."], "sentence-detokenized": "Paquetes de software como MATLAB, GNU Octave, Scilab y SciPy proporcionan formas convenientes de aplicar estos diferentes m\u00e9todos.", "token2charspan": [[0, 8], [9, 11], [12, 20], [21, 25], [26, 32], [32, 33], [34, 37], [38, 44], [44, 45], [46, 52], [53, 54], [55, 60], [61, 73], [74, 80], [81, 93], [94, 96], [97, 104], [105, 110], [111, 121], [122, 129], [129, 130]]}
{"doc_key": "ai-test-309", "ner": [[0, 3, "algorithm"], [5, 5, "algorithm"], [11, 13, "task"], [21, 22, "researcher"], [25, 28, "university"], [31, 32, "researcher"], [35, 38, "organisation"], [40, 40, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 3, 11, 13, "related-to", "", false, false], [0, 3, 21, 22, "origin", "", false, false], [0, 3, 31, 32, "origin", "", false, false], [5, 5, 0, 3, "named", "", false, false], [21, 22, 25, 28, "physical", "", false, false], [21, 22, 25, 28, "role", "", false, false], [31, 32, 35, 38, "physical", "", false, false], [31, 32, 35, 38, "role", "", false, false], [40, 40, 35, 38, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["La", "codificaci\u00f3n", "predictiva", "lineal", "(", "LPC", ")", ",", "un", "algoritmo", "de", "procesamiento", "del", "habla", ",", "fue", "propuesta", "por", "primera", "vez", "por", "Fumitada", "Itakura", ",", "de", "la", "Universidad", "de", "Nagoya", ",", "y", "Shuzo", "Saito", ",", "de", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", ",", "en", "1966", "."], "sentence-detokenized": "La codificaci\u00f3n predictiva lineal (LPC), un algoritmo de procesamiento del habla, fue propuesta por primera vez por Fumitada Itakura, de la Universidad de Nagoya, y Shuzo Saito, de Nippon Telegraph and Telephone (NTT), en 1966.", "token2charspan": [[0, 2], [3, 15], [16, 26], [27, 33], [34, 35], [35, 38], [38, 39], [39, 40], [41, 43], [44, 53], [54, 56], [57, 70], [71, 74], [75, 80], [80, 81], [82, 85], [86, 95], [96, 99], [100, 107], [108, 111], [112, 115], [116, 124], [125, 132], [132, 133], [134, 136], [137, 139], [140, 151], [152, 154], [155, 161], [161, 162], [163, 164], [165, 170], [171, 176], [176, 177], [178, 180], [181, 187], [188, 197], [198, 201], [202, 211], [212, 213], [213, 216], [216, 217], [217, 218], [219, 221], [222, 226], [226, 227]]}
{"doc_key": "ai-test-310", "ner": [[17, 26, "conference"], [28, 28, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[28, 28, 17, 26, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["En", "2006", ",", "con", "motivo", "del", "25\u00ba", "aniversario", "del", "algoritmo", ",", "se", "organiz\u00f3", "un", "taller", "en", "la", "Conferencia", "Internacional", "de", "Visi\u00f3n", "por", "Computador", "y", "Reconocimiento", "de", "Patrones", "(", "CVPR", ")", "para", "resumir", "las", "contribuciones", "y", "variaciones", "m\u00e1s", "recientes", "al", "algoritmo", "original", ",", "en", "su", "mayor\u00eda", "destinadas", "a", "mejorar", "la", "velocidad", "del", "algoritmo", ",", "la", "robustez", "y", "la", "precisi\u00f3n", "de", "la", "soluci\u00f3n", "estimada", "y", "a", "disminuir", "la", "dependencia", "de", "las", "constantes", "definidas", "por", "el", "usuario", "."], "sentence-detokenized": "En 2006, con motivo del 25\u00ba aniversario del algoritmo, se organiz\u00f3 un taller en la Conferencia Internacional de Visi\u00f3n por Computador y Reconocimiento de Patrones (CVPR) para resumir las contribuciones y variaciones m\u00e1s recientes al algoritmo original, en su mayor\u00eda destinadas a mejorar la velocidad del algoritmo, la robustez y la precisi\u00f3n de la soluci\u00f3n estimada y a disminuir la dependencia de las constantes definidas por el usuario.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 19], [20, 23], [24, 27], [28, 39], [40, 43], [44, 53], [53, 54], [55, 57], [58, 66], [67, 69], [70, 76], [77, 79], [80, 82], [83, 94], [95, 108], [109, 111], [112, 118], [119, 122], [123, 133], [134, 135], [136, 150], [151, 153], [154, 162], [163, 164], [164, 168], [168, 169], [170, 174], [175, 182], [183, 186], [187, 201], [202, 203], [204, 215], [216, 219], [220, 229], [230, 232], [233, 242], [243, 251], [251, 252], [253, 255], [256, 258], [259, 266], [267, 277], [278, 279], [280, 287], [288, 290], [291, 300], [301, 304], [305, 314], [314, 315], [316, 318], [319, 327], [328, 329], [330, 332], [333, 342], [343, 345], [346, 348], [349, 357], [358, 366], [367, 368], [369, 370], [371, 380], [381, 383], [384, 395], [396, 398], [399, 402], [403, 413], [414, 423], [424, 427], [428, 430], [431, 438], [438, 439]]}
{"doc_key": "ai-test-311", "ner": [[5, 7, "university"], [10, 13, "organisation"], [15, 18, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Los", "miembros", "acudieron", "a", "la", "Universidad", "de", "Debrecen", ",", "la", "Academia", "H\u00fangara", "de", "Ciencias", ",", "la", "Universidad", "E\u00f6tv\u00f6s", "Lor\u00e1nd", ",", "etc", "."], "sentence-detokenized": "Los miembros acudieron a la Universidad de Debrecen, la Academia H\u00fangara de Ciencias, la Universidad E\u00f6tv\u00f6s Lor\u00e1nd, etc.", "token2charspan": [[0, 3], [4, 12], [13, 22], [23, 24], [25, 27], [28, 39], [40, 42], [43, 51], [51, 52], [53, 55], [56, 64], [65, 72], [73, 75], [76, 84], [84, 85], [86, 88], [89, 100], [101, 107], [108, 114], [114, 115], [116, 119], [119, 120]]}
{"doc_key": "ai-test-312", "ner": [[2, 3, "algorithm"], [18, 20, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 18, 20, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Para", "ampliar", "la", "SVM", "a", "los", "casos", "en", "que", "los", "datos", "no", "son", "linealmente", "separables", ",", "introducimos", "la", "funci\u00f3n", "de", "p\u00e9rdida", ","], "sentence-detokenized": "Para ampliar la SVM a los casos en que los datos no son linealmente separables, introducimos la funci\u00f3n de p\u00e9rdida,", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 19], [20, 21], [22, 25], [26, 31], [32, 34], [35, 38], [39, 42], [43, 48], [49, 51], [52, 55], [56, 67], [68, 78], [78, 79], [80, 92], [93, 95], [96, 103], [104, 106], [107, 114], [114, 115]]}
{"doc_key": "ai-test-313", "ner": [[0, 0, "programlang"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 12, 13, "origin", "", false, false], [0, 0, 15, 16, "origin", "", false, false], [0, 0, 18, 19, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Logo", "es", "un", "lenguaje", "de", "programaci\u00f3n", "educativo", ",", "dise\u00f1ado", "en", "1967", "por", "Wally", "Feurzeig", ",", "Seymour", "Papert", "y", "Cynthia", "Solomon", "."], "sentence-detokenized": "Logo es un lenguaje de programaci\u00f3n educativo, dise\u00f1ado en 1967 por Wally Feurzeig, Seymour Papert y Cynthia Solomon.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 19], [20, 22], [23, 35], [36, 45], [45, 46], [47, 55], [56, 58], [59, 63], [64, 67], [68, 73], [74, 82], [82, 83], [84, 91], [92, 98], [99, 100], [101, 108], [109, 116], [116, 117]]}
{"doc_key": "ai-test-314", "ner": [[0, 4, "organisation"], [11, 19, "organisation"], [24, 27, "location"], [31, 31, "location"], [33, 33, "location"], [46, 52, "product"], [59, 70, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 4, 11, 19, "role", "works_for", false, false], [11, 19, 24, 27, "physical", "", false, false], [24, 27, 31, 31, "physical", "", false, false], [31, 31, 33, 33, "physical", "", false, false], [46, 52, 0, 4, "origin", "", false, false], [59, 70, 46, 52, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["El", "Instituto", "de", "Investigaci\u00f3n", "Eyring", "desempe\u00f1\u00f3", "un", "papel", "decisivo", "en", "la", "Direcci\u00f3n", "de", "Misiles", "de", "las", "Fuerzas", "A\u00e9reas", "de", "EE.UU", ".", ",", "en", "la", "Base", "A\u00e9rea", "de", "Hill", ",", "cerca", "de", "Ogden", "(", "Utah", ")", ",", "para", "producir", ",", "en", "el", "m\u00e1ximo", "secreto", "militar", ",", "el", "programa", "inform\u00e1tico", "de", "tecnolog\u00eda", "de", "sistemas", "inteligentes", ",", "que", "fue", "fundamental", "para", "el", "programa", "de", "la", "Guerra", "de", "las", "Galaxias", ",", "posteriormente", "denominado", "por", "Reagan", "."], "sentence-detokenized": "El Instituto de Investigaci\u00f3n Eyring desempe\u00f1\u00f3 un papel decisivo en la Direcci\u00f3n de Misiles de las Fuerzas A\u00e9reas de EE.UU., en la Base A\u00e9rea de Hill, cerca de Ogden (Utah), para producir, en el m\u00e1ximo secreto militar, el programa inform\u00e1tico de tecnolog\u00eda de sistemas inteligentes, que fue fundamental para el programa de la Guerra de las Galaxias, posteriormente denominado por Reagan.", "token2charspan": [[0, 2], [3, 12], [13, 15], [16, 29], [30, 36], [37, 46], [47, 49], [50, 55], [56, 64], [65, 67], [68, 70], [71, 80], [81, 83], [84, 91], [92, 94], [95, 98], [99, 106], [107, 113], [114, 116], [117, 122], [122, 123], [123, 124], [125, 127], [128, 130], [131, 135], [136, 141], [142, 144], [145, 149], [149, 150], [151, 156], [157, 159], [160, 165], [166, 167], [167, 171], [171, 172], [172, 173], [174, 178], [179, 187], [187, 188], [189, 191], [192, 194], [195, 201], [202, 209], [210, 217], [217, 218], [219, 221], [222, 230], [231, 242], [243, 245], [246, 256], [257, 259], [260, 268], [269, 281], [281, 282], [283, 286], [287, 290], [291, 302], [303, 307], [308, 310], [311, 319], [320, 322], [323, 325], [326, 332], [333, 335], [336, 339], [340, 348], [348, 349], [350, 364], [365, 375], [376, 379], [380, 386], [386, 387]]}
{"doc_key": "ai-test-315", "ner": [[13, 13, "field"], [28, 30, "researcher"], [32, 33, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "lo", "largo", "de", "d\u00e9cadas", "ha", "investigado", "y", "desarrollado", "campos", "emergentes", "de", "la", "inform\u00e1tica", ",", "desde", "el", "compilador", ",", "los", "lenguajes", "de", "programaci\u00f3n", "y", "la", "arquitectura", "de", "sistemas", "John", "F.", "Sowa", "y", "John", "Zachman", "(", "1992", ")", "."], "sentence-detokenized": "A lo largo de d\u00e9cadas ha investigado y desarrollado campos emergentes de la inform\u00e1tica, desde el compilador, los lenguajes de programaci\u00f3n y la arquitectura de sistemas John F. Sowa y John Zachman (1992).", "token2charspan": [[0, 1], [2, 4], [5, 10], [11, 13], [14, 21], [22, 24], [25, 36], [37, 38], [39, 51], [52, 58], [59, 69], [70, 72], [73, 75], [76, 87], [87, 88], [89, 94], [95, 97], [98, 108], [108, 109], [110, 113], [114, 123], [124, 126], [127, 139], [140, 141], [142, 144], [145, 157], [158, 160], [161, 169], [170, 174], [175, 177], [178, 182], [183, 184], [185, 189], [190, 197], [198, 199], [199, 203], [203, 204], [204, 205]]}
{"doc_key": "ai-test-316", "ner": [[3, 3, "algorithm"], [8, 10, "algorithm"], [12, 14, "algorithm"], [20, 22, "field"], [26, 28, "field"], [33, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 10, 3, 3, "named", "", false, false], [12, 14, 3, 3, "named", "", false, false], [20, 22, 3, 3, "usage", "", false, false], [26, 28, 3, 3, "usage", "", false, false], [33, 37, 3, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["El", "operador", "de", "Sobel", ",", "a", "veces", "llamado", "operador", "de", "Sobel-Feldman", "o", "filtro", "de", "Sobel", ",", "se", "utiliza", "en", "el", "procesamiento", "de", "im\u00e1genes", "y", "en", "la", "visi\u00f3n", "por", "ordenador", ",", "especialmente", "en", "los", "algoritmos", "de", "detecci\u00f3n", "de", "bordes", ",", "donde", "crea", "una", "imagen", "que", "enfatiza", "los", "bordes", "."], "sentence-detokenized": "El operador de Sobel, a veces llamado operador de Sobel-Feldman o filtro de Sobel, se utiliza en el procesamiento de im\u00e1genes y en la visi\u00f3n por ordenador, especialmente en los algoritmos de detecci\u00f3n de bordes, donde crea una imagen que enfatiza los bordes.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 20], [20, 21], [22, 23], [24, 29], [30, 37], [38, 46], [47, 49], [50, 63], [64, 65], [66, 72], [73, 75], [76, 81], [81, 82], [83, 85], [86, 93], [94, 96], [97, 99], [100, 113], [114, 116], [117, 125], [126, 127], [128, 130], [131, 133], [134, 140], [141, 144], [145, 154], [154, 155], [156, 169], [170, 172], [173, 176], [177, 187], [188, 190], [191, 200], [201, 203], [204, 210], [210, 211], [212, 217], [218, 222], [223, 226], [227, 233], [234, 237], [238, 246], [247, 250], [251, 257], [257, 258]]}
{"doc_key": "ai-test-317", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [18, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "compare", "", false, false], [0, 1, 6, 7, "type-of", "", false, false], [0, 1, 18, 19, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["El", "LDA", "es", "un", "algoritmo", "de", "aprendizaje", "supervisado", "que", "utiliza", "las", "etiquetas", "de", "los", "datos", ",", "mientras", "que", "el", "PCA", "es", "un", "algoritmo", "de", "aprendizaje", "que", "ignora", "las", "etiquetas", "."], "sentence-detokenized": "El LDA es un algoritmo de aprendizaje supervisado que utiliza las etiquetas de los datos, mientras que el PCA es un algoritmo de aprendizaje que ignora las etiquetas.", "token2charspan": [[0, 2], [3, 6], [7, 9], [10, 12], [13, 22], [23, 25], [26, 37], [38, 49], [50, 53], [54, 61], [62, 65], [66, 75], [76, 78], [79, 82], [83, 88], [88, 89], [90, 98], [99, 102], [103, 105], [106, 109], [110, 112], [113, 115], [116, 125], [126, 128], [129, 140], [141, 144], [145, 151], [152, 155], [156, 165], [165, 166]]}
{"doc_key": "ai-test-318", "ner": [[6, 6, "algorithm"], [9, 13, "algorithm"], [16, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Otros", "algoritmos", "de", "clasificaci\u00f3n", "lineal", "son", "Winnow", ",", "la", "m\u00e1quina", "de", "vectores", "de", "apoyo", "y", "la", "regresi\u00f3n", "log\u00edstica", "."], "sentence-detokenized": "Otros algoritmos de clasificaci\u00f3n lineal son Winnow, la m\u00e1quina de vectores de apoyo y la regresi\u00f3n log\u00edstica.", "token2charspan": [[0, 5], [6, 16], [17, 19], [20, 33], [34, 40], [41, 44], [45, 51], [51, 52], [53, 55], [56, 63], [64, 66], [67, 75], [76, 78], [79, 84], [85, 86], [87, 89], [90, 99], [100, 109], [109, 110]]}
{"doc_key": "ai-test-319", "ner": [[0, 0, "product"], [8, 10, "programlang"], [18, 20, "product"], [22, 22, "programlang"], [24, 24, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 10, "general-affiliation", "", true, false], [0, 0, 18, 20, "general-affiliation", "", true, false], [0, 0, 22, 22, "general-affiliation", "", true, false], [0, 0, 24, 24, "general-affiliation", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["VTK", "se", "compone", "de", "una", "biblioteca", "de", "clases", "C", "+", "+", "y", "varias", "capas", "de", "interfaz", "interpretada", "incluyendo", "Tcl", "/", "Tk", ",", "Java", "y", "Python", "."], "sentence-detokenized": "VTK se compone de una biblioteca de clases C + + y varias capas de interfaz interpretada incluyendo Tcl / Tk, Java y Python.", "token2charspan": [[0, 3], [4, 6], [7, 14], [15, 17], [18, 21], [22, 32], [33, 35], [36, 42], [43, 44], [45, 46], [47, 48], [49, 50], [51, 57], [58, 63], [64, 66], [67, 75], [76, 88], [89, 99], [100, 103], [104, 105], [106, 108], [108, 109], [110, 114], [115, 116], [117, 123], [123, 124]]}
{"doc_key": "ai-test-320", "ner": [[13, 16, "task"], [25, 28, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Adem\u00e1s", ",", "el", "texto", "producido", "por", "el", "procesamiento", "del", "habla", "espont\u00e1nea", "mediante", "el", "reconocimiento", "autom\u00e1tico", "del", "habla", "y", "el", "texto", "impreso", "o", "manuscrito", "mediante", "el", "reconocimiento", "\u00f3ptico", "de", "caracteres", "contiene", "ruido", "de", "procesamiento", "."], "sentence-detokenized": "Adem\u00e1s, el texto producido por el procesamiento del habla espont\u00e1nea mediante el reconocimiento autom\u00e1tico del habla y el texto impreso o manuscrito mediante el reconocimiento \u00f3ptico de caracteres contiene ruido de procesamiento.", "token2charspan": [[0, 6], [6, 7], [8, 10], [11, 16], [17, 26], [27, 30], [31, 33], [34, 47], [48, 51], [52, 57], [58, 68], [69, 77], [78, 80], [81, 95], [96, 106], [107, 110], [111, 116], [117, 118], [119, 121], [122, 127], [128, 135], [136, 137], [138, 148], [149, 157], [158, 160], [161, 175], [176, 182], [183, 185], [186, 196], [197, 205], [206, 211], [212, 214], [215, 228], [228, 229]]}
{"doc_key": "ai-test-321", "ner": [[0, 0, "researcher"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 9, 9, "role", "directs_development_of", false, false]], "relations_mapping_to_source": [0], "sentence": ["Miller", "escribi\u00f3", "varios", "libros", "y", "dirigi\u00f3", "el", "desarrollo", "de", "WordNet", ",", "una", "base", "de", "datos", "de", "enlaces", "de", "palabras", "en", "l\u00ednea", "utilizable", "por", "programas", "inform\u00e1ticos", "."], "sentence-detokenized": "Miller escribi\u00f3 varios libros y dirigi\u00f3 el desarrollo de WordNet, una base de datos de enlaces de palabras en l\u00ednea utilizable por programas inform\u00e1ticos.", "token2charspan": [[0, 6], [7, 15], [16, 22], [23, 29], [30, 31], [32, 39], [40, 42], [43, 53], [54, 56], [57, 64], [64, 65], [66, 69], [70, 74], [75, 77], [78, 83], [84, 86], [87, 94], [95, 97], [98, 106], [107, 109], [110, 115], [116, 126], [127, 130], [131, 140], [141, 153], [153, 154]]}
{"doc_key": "ai-test-322", "ner": [[0, 1, "field"], [9, 11, "organisation"], [14, 15, "country"], [17, 18, "person"], [20, 22, "person"], [24, 25, "person"], [27, 28, "person"], [30, 31, "country"], [33, 36, "location"], [38, 39, "misc"], [40, 41, "person"], [44, 45, "person"], [47, 47, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[9, 11, 14, 15, "physical", "", false, false], [17, 18, 30, 31, "physical", "", false, false], [20, 22, 30, 31, "physical", "", false, false], [24, 25, 30, 31, "physical", "", false, false], [27, 28, 30, 31, "physical", "", false, false], [33, 36, 0, 1, "general-affiliation", "", false, false], [33, 36, 40, 41, "artifact", "", false, false], [38, 39, 40, 41, "named", "", false, false], [44, 45, 47, 47, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Los", "aut\u00f3matas", "contempor\u00e1neos", "est\u00e1n", "representados", "por", "las", "obras", "de", "Cabaret", "Mechanical", "Theatre", "en", "el", "Reino", "Unido", ",", "Dug", "North", "y", "Chomick", "+", "Meder", ",", "Arthur", "Ganson", ",", "Joe", "Jones", "en", "Estados", "Unidos", ",", "Le", "D\u00e9fenseur", "du", "Temps", "del", "artista", "franc\u00e9s", "Jacques", "Monestier", ",", "y", "Fran\u00e7ois", "Junod", "en", "Suiza", "."], "sentence-detokenized": "Los aut\u00f3matas contempor\u00e1neos est\u00e1n representados por las obras de Cabaret Mechanical Theatre en el Reino Unido, Dug North y Chomick + Meder, Arthur Ganson, Joe Jones en Estados Unidos, Le D\u00e9fenseur du Temps del artista franc\u00e9s Jacques Monestier, y Fran\u00e7ois Junod en Suiza.", "token2charspan": [[0, 3], [4, 13], [14, 28], [29, 34], [35, 48], [49, 52], [53, 56], [57, 62], [63, 65], [66, 73], [74, 84], [85, 92], [93, 95], [96, 98], [99, 104], [105, 110], [110, 111], [112, 115], [116, 121], [122, 123], [124, 131], [132, 133], [134, 139], [139, 140], [141, 147], [148, 154], [154, 155], [156, 159], [160, 165], [166, 168], [169, 176], [177, 183], [183, 184], [185, 187], [188, 197], [198, 200], [201, 206], [207, 210], [211, 218], [219, 226], [227, 234], [235, 244], [244, 245], [246, 247], [248, 256], [257, 262], [263, 265], [266, 271], [271, 272]]}
{"doc_key": "ai-test-323", "ner": [[0, 0, "product"], [23, 23, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 23, 23, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MATLAB", "incluye", "los", "bucles", "est\u00e1ndar", "codefor", "/", "code", "y", "codewhile", "/", "code", ",", "pero", "(", "al", "igual", "que", "en", "otras", "aplicaciones", "similares", "como", "R", ")", ",", "se", "fomenta", "el", "uso", "de", "la", "notaci\u00f3n", "vectorial", "y", "a", "menudo", "es", "m\u00e1s", "r\u00e1pido", "de", "ejecutar", "."], "sentence-detokenized": "MATLAB incluye los bucles est\u00e1ndar codefor / code y codewhile / code, pero (al igual que en otras aplicaciones similares como R), se fomenta el uso de la notaci\u00f3n vectorial y a menudo es m\u00e1s r\u00e1pido de ejecutar.", "token2charspan": [[0, 6], [7, 14], [15, 18], [19, 25], [26, 34], [35, 42], [43, 44], [45, 49], [50, 51], [52, 61], [62, 63], [64, 68], [68, 69], [70, 74], [75, 76], [76, 78], [79, 84], [85, 88], [89, 91], [92, 97], [98, 110], [111, 120], [121, 125], [126, 127], [127, 128], [128, 129], [130, 132], [133, 140], [141, 143], [144, 147], [148, 150], [151, 153], [154, 162], [163, 172], [173, 174], [175, 176], [177, 183], [184, 186], [187, 190], [191, 197], [198, 200], [201, 209], [209, 210]]}
{"doc_key": "ai-test-324", "ner": [[3, 3, "researcher"], [8, 12, "conference"], [17, 21, "field"], [24, 31, "misc"], [34, 46, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 24, 31, "win-defeat", "", false, false], [3, 3, 34, 46, "win-defeat", "", false, false], [24, 31, 8, 12, "temporal", "", false, false], [24, 31, 17, 21, "topic", "", false, false], [34, 46, 8, 12, "temporal", "", false, false], [34, 46, 17, 21, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["En", "2007", ",", "Pausch", "recibi\u00f3", "dos", "premios", "de", "la", "Association", "for", "Computing", "Machinery", "por", "sus", "logros", "en", "la", "ense\u00f1anza", "de", "la", "inform\u00e1tica", ":", "el", "premio", "Karl", "V", ".", "Karlstrom", "Outstanding", "Educator", "Award", "y", "el", "premio", "ACM", "SIGCSE", "por", "su", "destacada", "contribuci\u00f3n", "a", "la", "ense\u00f1anza", "de", "la", "inform\u00e1tica", "."], "sentence-detokenized": "En 2007, Pausch recibi\u00f3 dos premios de la Association for Computing Machinery por sus logros en la ense\u00f1anza de la inform\u00e1tica: el premio Karl V. Karlstrom Outstanding Educator Award y el premio ACM SIGCSE por su destacada contribuci\u00f3n a la ense\u00f1anza de la inform\u00e1tica.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 23], [24, 27], [28, 35], [36, 38], [39, 41], [42, 53], [54, 57], [58, 67], [68, 77], [78, 81], [82, 85], [86, 92], [93, 95], [96, 98], [99, 108], [109, 111], [112, 114], [115, 126], [126, 127], [128, 130], [131, 137], [138, 142], [143, 144], [144, 145], [146, 155], [156, 167], [168, 176], [177, 182], [183, 184], [185, 187], [188, 194], [195, 198], [199, 205], [206, 209], [210, 212], [213, 222], [223, 235], [236, 237], [238, 240], [241, 250], [251, 253], [254, 256], [257, 268], [268, 269]]}
{"doc_key": "ai-test-325", "ner": [[3, 3, "person"], [9, 9, "product"], [8, 8, "product"], [17, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 9, 9, "role", "sells", false, false], [9, 9, 8, 8, "general-affiliation", "", false, false], [9, 9, 17, 18, "physical", "shipped_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["En", "1960", ",", "Devol", "vendi\u00f3", "personalmente", "el", "primer", "robot", "Unimate", ",", "que", "fue", "enviado", "en", "1961", "a", "General", "Motors", "."], "sentence-detokenized": "En 1960, Devol vendi\u00f3 personalmente el primer robot Unimate, que fue enviado en 1961 a General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 21], [22, 35], [36, 38], [39, 45], [46, 51], [52, 59], [59, 60], [61, 64], [65, 68], [69, 76], [77, 79], [80, 84], [85, 86], [87, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-test-326", "ner": [[0, 2, "algorithm"], [8, 13, "field"], [14, 16, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 16, 0, 2, "usage", "", false, false], [14, 16, 8, 13, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Las", "redes", "sem\u00e1nticas", "se", "utilizan", "en", "aplicaciones", "de", "procesamiento", "del", "lenguaje", "natural", ",", "como", "el", "an\u00e1lisis", "sint\u00e1ctico", "."], "sentence-detokenized": "Las redes sem\u00e1nticas se utilizan en aplicaciones de procesamiento del lenguaje natural, como el an\u00e1lisis sint\u00e1ctico.", "token2charspan": [[0, 3], [4, 9], [10, 20], [21, 23], [24, 32], [33, 35], [36, 48], [49, 51], [52, 65], [66, 69], [70, 78], [79, 86], [86, 87], [88, 92], [93, 95], [96, 104], [105, 115], [115, 116]]}
{"doc_key": "ai-test-327", "ner": [[3, 5, "field"], [8, 10, "field"], [13, 15, "task"], [17, 18, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 29, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[8, 10, 3, 5, "usage", "", false, false], [13, 15, 3, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Algunas", "aplicaciones", "exitosas", "del", "aprendizaje", "profundo", "son", "la", "visi\u00f3n", "por", "ordenador", "y", "el", "reconocimiento", "del", "habla", ".", "Honglak", "Lee", ",", "Roger", "Grosse", ",", "Rajesh", "Ranganath", ",", "Andrew", "Y", ".", "Ng", "."], "sentence-detokenized": "Algunas aplicaciones exitosas del aprendizaje profundo son la visi\u00f3n por ordenador y el reconocimiento del habla. Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng.", "token2charspan": [[0, 7], [8, 20], [21, 29], [30, 33], [34, 45], [46, 54], [55, 58], [59, 61], [62, 68], [69, 72], [73, 82], [83, 84], [85, 87], [88, 102], [103, 106], [107, 112], [112, 113], [114, 121], [122, 125], [125, 126], [127, 132], [133, 139], [139, 140], [141, 147], [148, 157], [157, 158], [159, 165], [166, 167], [167, 168], [169, 171], [171, 172]]}
{"doc_key": "ai-test-328", "ner": [[3, 9, "product"], [15, 15, "misc"], [18, 18, "misc"], [24, 24, "product"], [29, 31, "task"], [33, 35, "task"], [37, 38, "task"], [40, 43, "field"], [45, 47, "task"], [49, 51, "field"], [53, 54, "task"], [56, 57, "task"], [59, 62, "task"], [64, 66, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[3, 9, 15, 15, "physical", "travels_to", false, false], [3, 9, 18, 18, "physical", "travels_to", false, false], [24, 24, 3, 9, "part-of", "", false, false], [24, 24, 3, 9, "role", "maintains", false, false], [24, 24, 29, 31, "related-to", "has_ability_to", false, false], [24, 24, 33, 35, "related-to", "has_ability_to", false, false], [24, 24, 37, 38, "related-to", "has_ability_to", false, false], [24, 24, 40, 43, "related-to", "has_ability_to", false, false], [24, 24, 45, 47, "related-to", "has_ability_to", false, false], [24, 24, 49, 51, "related-to", "has_ability_to", false, false], [24, 24, 53, 54, "related-to", "has_ability_to", false, false], [24, 24, 56, 57, "related-to", "has_ability_to", false, false], [24, 24, 59, 62, "related-to", "has_ability_to", false, false], [24, 24, 64, 66, "related-to", "has_ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Adem\u00e1s", "de", "mantener", "los", "sistemas", "de", "la", "nave", "Discovery", "One", "durante", "la", "misi\u00f3n", "interplanetaria", "a", "J\u00fapiter", "(", "o", "Saturno", "en", "la", "novela", ")", ",", "HAL", "es", "capaz", "de", "realizar", "s\u00edntesis", "de", "voz", ",", "reconocimiento", "del", "habla", ",", "reconocimiento", "facial", ",", "procesamiento", "del", "lenguaje", "natural", ",", "lectura", "de", "labios", ",", "apreciaci\u00f3n", "del", "arte", ",", "computaci\u00f3n", "afectiva", ",", "razonamiento", "automatizado", ",", "pilotaje", "de", "naves", "espaciales", "y", "jugar", "al", "ajedrez", "."], "sentence-detokenized": "Adem\u00e1s de mantener los sistemas de la nave Discovery One durante la misi\u00f3n interplanetaria a J\u00fapiter (o Saturno en la novela), HAL es capaz de realizar s\u00edntesis de voz, reconocimiento del habla, reconocimiento facial, procesamiento del lenguaje natural, lectura de labios, apreciaci\u00f3n del arte, computaci\u00f3n afectiva, razonamiento automatizado, pilotaje de naves espaciales y jugar al ajedrez.", "token2charspan": [[0, 6], [7, 9], [10, 18], [19, 22], [23, 31], [32, 34], [35, 37], [38, 42], [43, 52], [53, 56], [57, 64], [65, 67], [68, 74], [75, 90], [91, 92], [93, 100], [101, 102], [102, 103], [104, 111], [112, 114], [115, 117], [118, 124], [124, 125], [125, 126], [127, 130], [131, 133], [134, 139], [140, 142], [143, 151], [152, 160], [161, 163], [164, 167], [167, 168], [169, 183], [184, 187], [188, 193], [193, 194], [195, 209], [210, 216], [216, 217], [218, 231], [232, 235], [236, 244], [245, 252], [252, 253], [254, 261], [262, 264], [265, 271], [271, 272], [273, 284], [285, 288], [289, 293], [293, 294], [295, 306], [307, 315], [315, 316], [317, 329], [330, 342], [342, 343], [344, 352], [353, 355], [356, 361], [362, 372], [373, 374], [375, 380], [381, 383], [384, 391], [391, 392]]}
{"doc_key": "ai-test-329", "ner": [[0, 3, "researcher"], [6, 6, "country"], [8, 9, "country"], [13, 13, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 6, 6, "physical", "", false, false], [0, 3, 8, 9, "physical", "", false, false], [0, 3, 13, 13, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["El", "Dr", ".", "Julesz", "emigr\u00f3", "de", "Hungr\u00eda", "a", "Estados", "Unidos", "tras", "la", "invasi\u00f3n", "sovi\u00e9tica", "de", "1956", "."], "sentence-detokenized": "El Dr. Julesz emigr\u00f3 de Hungr\u00eda a Estados Unidos tras la invasi\u00f3n sovi\u00e9tica de 1956.", "token2charspan": [[0, 2], [3, 5], [5, 6], [7, 13], [14, 20], [21, 23], [24, 31], [32, 33], [34, 41], [42, 48], [49, 53], [54, 56], [57, 65], [66, 75], [76, 78], [79, 83], [83, 84]]}
{"doc_key": "ai-test-330", "ner": [[6, 7, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Las", "funciones", "de", "activaci\u00f3n", "de", "la", "funci\u00f3n", "sigmoide", "utilizan", "una", "segunda", "no", "linealidad", "para", "entradas", "grandes", ":", "math", "\\", "phi", "(", "v", "_", "i", ")", "=", "(", "1", "+", "\\", "exp", "(", "-v", "_", "i", ")", ")", "^", "{", "-1", "}", "/", "math", "."], "sentence-detokenized": "Las funciones de activaci\u00f3n de la funci\u00f3n sigmoide utilizan una segunda no linealidad para entradas grandes: math\\ phi (v _ i) = (1 +\\ exp (-v _ i)) ^ {-1} / math.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 27], [28, 30], [31, 33], [34, 41], [42, 50], [51, 59], [60, 63], [64, 71], [72, 74], [75, 85], [86, 90], [91, 99], [100, 107], [107, 108], [109, 113], [113, 114], [115, 118], [119, 120], [120, 121], [122, 123], [124, 125], [125, 126], [127, 128], [129, 130], [130, 131], [132, 133], [133, 134], [135, 138], [139, 140], [140, 142], [143, 144], [145, 146], [146, 147], [147, 148], [149, 150], [151, 152], [152, 154], [154, 155], [156, 157], [158, 162], [162, 163]]}
{"doc_key": "ai-test-331", "ner": [[12, 15, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Estas", "probabilidades", "se", "utilizan", "para", "determinar", "cu\u00e1l", "es", "el", "objetivo", "mediante", "una", "decisi\u00f3n", "de", "m\u00e1xima", "probabilidad", "."], "sentence-detokenized": "Estas probabilidades se utilizan para determinar cu\u00e1l es el objetivo mediante una decisi\u00f3n de m\u00e1xima probabilidad.", "token2charspan": [[0, 5], [6, 20], [21, 23], [24, 32], [33, 37], [38, 48], [49, 53], [54, 56], [57, 59], [60, 68], [69, 77], [78, 81], [82, 90], [91, 93], [94, 100], [101, 113], [113, 114]]}
{"doc_key": "ai-test-332", "ner": [[6, 8, "university"], [14, 15, "university"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["En", "1984", "se", "traslad\u00f3", "a", "la", "Universidad", "de", "Constanza", "y", "en", "1990", "a", "la", "de", "Salzburgo", "."], "sentence-detokenized": "En 1984 se traslad\u00f3 a la Universidad de Constanza y en 1990 a la de Salzburgo.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 19], [20, 21], [22, 24], [25, 36], [37, 39], [40, 49], [50, 51], [52, 54], [55, 59], [60, 61], [62, 64], [65, 67], [68, 77], [77, 78]]}
{"doc_key": "ai-test-333", "ner": [[8, 10, "metrics"], [13, 13, "metrics"], [16, 16, "metrics"], [18, 20, "metrics"], [23, 25, "metrics"], [27, 32, "metrics"], [35, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 13, 8, 10, "origin", "based_on", false, false], [16, 16, 8, 10, "origin", "based_on", false, false], [18, 20, 8, 10, "origin", "based_on", false, false], [23, 25, 8, 10, "origin", "based_on", false, false], [27, 32, 8, 10, "origin", "based_on", false, false], [35, 37, 8, 10, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Algunas", "funciones", "de", "aptitud", "populares", "basadas", "en", "la", "matriz", "de", "confusi\u00f3n", "son", "la", "sensibilidad/especificidad", ",", "la", "recuperaci\u00f3n/precisi\u00f3n", ",", "la", "medida", "F", ",", "la", "similitud", "de", "Jaccard", ",", "el", "coeficiente", "de", "correlaci\u00f3n", "de", "Matthews", "y", "la", "matriz", "de", "coste/ganancia", "que", "combina", "los", "costes", "y", "las", "ganancias", "asignadas", "a", "los", "4", "tipos", "diferentes", "de", "clasificaciones", "."], "sentence-detokenized": "Algunas funciones de aptitud populares basadas en la matriz de confusi\u00f3n son la sensibilidad/especificidad, la recuperaci\u00f3n/precisi\u00f3n, la medida F, la similitud de Jaccard, el coeficiente de correlaci\u00f3n de Matthews y la matriz de coste/ganancia que combina los costes y las ganancias asignadas a los 4 tipos diferentes de clasificaciones.", "token2charspan": [[0, 7], [8, 17], [18, 20], [21, 28], [29, 38], [39, 46], [47, 49], [50, 52], [53, 59], [60, 62], [63, 72], [73, 76], [77, 79], [80, 106], [106, 107], [108, 110], [111, 133], [133, 134], [135, 137], [138, 144], [145, 146], [146, 147], [148, 150], [151, 160], [161, 163], [164, 171], [171, 172], [173, 175], [176, 187], [188, 190], [191, 202], [203, 205], [206, 214], [215, 216], [217, 219], [220, 226], [227, 229], [230, 244], [245, 248], [249, 256], [257, 260], [261, 267], [268, 269], [270, 273], [274, 283], [284, 293], [294, 295], [296, 299], [300, 301], [302, 307], [308, 318], [319, 321], [322, 337], [337, 338]]}
{"doc_key": "ai-test-334", "ner": [[8, 8, "product"], [10, 10, "product"], [12, 12, "product"], [14, 14, "product"], [17, 18, "programlang"], [35, 39, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[35, 39, 8, 8, "part-of", "", false, false], [35, 39, 10, 10, "part-of", "", false, false], [35, 39, 12, 12, "part-of", "", false, false], [35, 39, 14, 14, "part-of", "", false, false], [35, 39, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Los", "entornos", "de", "programaci\u00f3n", "num\u00e9rica", "habituales", ",", "como", "MATLAB", ",", "SciLab", ",", "NumPy", ",", "Sklearn", "y", "el", "lenguaje", "R", ",", "proporcionan", "algunas", "de", "las", "t\u00e9cnicas", "de", "extracci\u00f3n", "de", "caracter\u00edsticas", "m\u00e1s", "sencillas", "(", "por", "ejemplo", ",", "el", "an\u00e1lisis", "de", "componentes", "principales", ")", "mediante", "comandos", "integrados", "."], "sentence-detokenized": "Los entornos de programaci\u00f3n num\u00e9rica habituales, como MATLAB, SciLab, NumPy, Sklearn y el lenguaje R, proporcionan algunas de las t\u00e9cnicas de extracci\u00f3n de caracter\u00edsticas m\u00e1s sencillas (por ejemplo, el an\u00e1lisis de componentes principales) mediante comandos integrados.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 28], [29, 37], [38, 48], [48, 49], [50, 54], [55, 61], [61, 62], [63, 69], [69, 70], [71, 76], [76, 77], [78, 85], [86, 87], [88, 90], [91, 99], [100, 101], [101, 102], [103, 115], [116, 123], [124, 126], [127, 130], [131, 139], [140, 142], [143, 153], [154, 156], [157, 172], [173, 176], [177, 186], [187, 188], [188, 191], [192, 199], [199, 200], [201, 203], [204, 212], [213, 215], [216, 227], [228, 239], [239, 240], [241, 249], [250, 258], [259, 269], [269, 270]]}
{"doc_key": "ai-test-335", "ner": [[0, 4, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Los", "robots", "industriales", "se", "han", "implementado", "para", "colaborar", "con", "los", "humanos", "en", "la", "realizaci\u00f3n", "de", "tareas", "de", "fabricaci\u00f3n", "industrial", "."], "sentence-detokenized": "Los robots industriales se han implementado para colaborar con los humanos en la realizaci\u00f3n de tareas de fabricaci\u00f3n industrial.", "token2charspan": [[0, 3], [4, 10], [11, 23], [24, 26], [27, 30], [31, 43], [44, 48], [49, 58], [59, 62], [63, 66], [67, 74], [75, 77], [78, 80], [81, 92], [93, 95], [96, 102], [103, 105], [106, 117], [118, 128], [128, 129]]}
{"doc_key": "ai-test-336", "ner": [[6, 7, "field"], [9, 11, "researcher"], [21, 22, "field"], [24, 24, "field"], [26, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 7, 21, 22, "related-to", "", false, false], [6, 7, 24, 24, "related-to", "", false, false], [6, 7, 26, 27, "related-to", "", false, false], [9, 11, 6, 7, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["En", "el", "primer", "art\u00edculo", "publicado", "sobre", "los", "GC", ",", "John", "F.", "Sowa", "los", "aplic\u00f3", "a", "una", "amplia", "gama", "de", "temas", "de", "inteligencia", "artificial", ",", "inform\u00e1tica", "y", "ciencias", "cognitivas", "."], "sentence-detokenized": "En el primer art\u00edculo publicado sobre los GC, John F. Sowa los aplic\u00f3 a una amplia gama de temas de inteligencia artificial, inform\u00e1tica y ciencias cognitivas.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 21], [22, 31], [32, 37], [38, 41], [42, 44], [44, 45], [46, 50], [51, 53], [54, 58], [59, 62], [63, 69], [70, 71], [72, 75], [76, 82], [83, 87], [88, 90], [91, 96], [97, 99], [100, 112], [113, 123], [123, 124], [125, 136], [137, 138], [139, 147], [148, 158], [158, 159]]}
{"doc_key": "ai-test-337", "ner": [[0, 1, "metrics"], [5, 5, "metrics"], [11, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 5, 5, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["El", "NIST", "tambi\u00e9n", "difiere", "del", "BLEU", "en", "su", "c\u00e1lculo", "de", "la", "penalizaci\u00f3n", "por", "brevedad", ",", "en", "la", "medida", "en", "que", "las", "peque\u00f1as", "variaciones", "en", "la", "longitud", "de", "la", "traducci\u00f3n", "no", "afectan", "tanto", "a", "la", "puntuaci\u00f3n", "global", "."], "sentence-detokenized": "El NIST tambi\u00e9n difiere del BLEU en su c\u00e1lculo de la penalizaci\u00f3n por brevedad, en la medida en que las peque\u00f1as variaciones en la longitud de la traducci\u00f3n no afectan tanto a la puntuaci\u00f3n global.", "token2charspan": [[0, 2], [3, 7], [8, 15], [16, 23], [24, 27], [28, 32], [33, 35], [36, 38], [39, 46], [47, 49], [50, 52], [53, 65], [66, 69], [70, 78], [78, 79], [80, 82], [83, 85], [86, 92], [93, 95], [96, 99], [100, 103], [104, 112], [113, 124], [125, 127], [128, 130], [131, 139], [140, 142], [143, 145], [146, 156], [157, 159], [160, 167], [168, 173], [174, 175], [176, 178], [179, 189], [190, 196], [196, 197]]}
{"doc_key": "ai-test-338", "ner": [[1, 6, "misc"], [17, 18, "conference"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 6, 17, 18, "temporal", "", false, false], [1, 6, 23, 24, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["El", "Premio", "IJCAI", "a", "la", "Excelencia", "Investigadora", "es", "un", "galard\u00f3n", "bianual", "que", "se", "concede", "en", "la", "conferencia", "del", "IJCAI", "a", "los", "investigadores", "en", "inteligencia", "artificial", "como", "reconocimiento", "a", "la", "excelencia", "de", "su", "carrera", "."], "sentence-detokenized": "El Premio IJCAI a la Excelencia Investigadora es un galard\u00f3n bianual que se concede en la conferencia del IJCAI a los investigadores en inteligencia artificial como reconocimiento a la excelencia de su carrera.", "token2charspan": [[0, 2], [3, 9], [10, 15], [16, 17], [18, 20], [21, 31], [32, 45], [46, 48], [49, 51], [52, 60], [61, 68], [69, 72], [73, 75], [76, 83], [84, 86], [87, 89], [90, 101], [102, 105], [106, 111], [112, 113], [114, 117], [118, 132], [133, 135], [136, 148], [149, 159], [160, 164], [165, 179], [180, 181], [182, 184], [185, 195], [196, 198], [199, 201], [202, 209], [209, 210]]}
{"doc_key": "ai-test-339", "ner": [[0, 0, "researcher"], [8, 9, "conference"], [20, 27, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 9, "role", "", false, false], [0, 0, 20, 27, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lenat", "fue", "uno", "de", "los", "primeros", "miembros", "de", "la", "AAAI", "y", "es", "el", "\u00fanico", "individuo", "que", "ha", "formado", "parte", "de", "los", "Consejos", "Cient\u00edficos", "Asesores", "de", "Microsoft", "y", "Apple", "."], "sentence-detokenized": "Lenat fue uno de los primeros miembros de la AAAI y es el \u00fanico individuo que ha formado parte de los Consejos Cient\u00edficos Asesores de Microsoft y Apple.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 16], [17, 20], [21, 29], [30, 38], [39, 41], [42, 44], [45, 49], [50, 51], [52, 54], [55, 57], [58, 63], [64, 73], [74, 77], [78, 80], [81, 88], [89, 94], [95, 97], [98, 101], [102, 110], [111, 122], [123, 131], [132, 134], [135, 144], [145, 146], [147, 152], [152, 153]]}
{"doc_key": "ai-test-340", "ner": [[0, 1, "algorithm"], [6, 9, "misc"], [13, 15, "metrics"], [21, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 6, 9, "related-to", "minimise", false, false], [13, 15, 6, 9, "type-of", "", false, false], [21, 21, 6, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Los", "autocodificadores", "se", "entrenan", "para", "minimizar", "los", "errores", "de", "reconstrucci\u00f3n", "(", "como", "el", "error", "cuadr\u00e1tico", "medio", ")", ",", "a", "menudo", "denominado", "p\u00e9rdida", ":"], "sentence-detokenized": "Los autocodificadores se entrenan para minimizar los errores de reconstrucci\u00f3n (como el error cuadr\u00e1tico medio), a menudo denominado p\u00e9rdida:", "token2charspan": [[0, 3], [4, 21], [22, 24], [25, 33], [34, 38], [39, 48], [49, 52], [53, 60], [61, 63], [64, 78], [79, 80], [80, 84], [85, 87], [88, 93], [94, 104], [105, 110], [110, 111], [111, 112], [113, 114], [115, 121], [122, 132], [133, 140], [140, 141]]}
{"doc_key": "ai-test-341", "ner": [[34, 37, "misc"], [41, 41, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[41, 41, 34, 37, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Una", "alternativa", "al", "uso", "de", "las", "definiciones", "es", "considerar", "la", "relaci\u00f3n", "general", "entre", "los", "sentidos", "de", "las", "palabras", "y", "calcular", "la", "similitud", "de", "cada", "par", "de", "sentidos", "de", "las", "palabras", "a", "partir", "de", "una", "base", "de", "conocimiento", "l\u00e9xico", "determinada", ",", "como", "WordNet", "."], "sentence-detokenized": "Una alternativa al uso de las definiciones es considerar la relaci\u00f3n general entre los sentidos de las palabras y calcular la similitud de cada par de sentidos de las palabras a partir de una base de conocimiento l\u00e9xico determinada, como WordNet.", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 22], [23, 25], [26, 29], [30, 42], [43, 45], [46, 56], [57, 59], [60, 68], [69, 76], [77, 82], [83, 86], [87, 95], [96, 98], [99, 102], [103, 111], [112, 113], [114, 122], [123, 125], [126, 135], [136, 138], [139, 143], [144, 147], [148, 150], [151, 159], [160, 162], [163, 166], [167, 175], [176, 177], [178, 184], [185, 187], [188, 191], [192, 196], [197, 199], [200, 212], [213, 219], [220, 231], [231, 232], [233, 237], [238, 245], [245, 246]]}
{"doc_key": "ai-test-342", "ner": [[0, 0, "algorithm"], [8, 10, "researcher"], [23, 24, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 10, "origin", "", false, false], [8, 10, 23, 24, "role", "work_based_on_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["TD-Lambda", "es", "un", "algoritmo", "de", "aprendizaje", "inventado", "por", "Richard", "S.", "Sutton", "basado", "en", "un", "trabajo", "anterior", "sobre", "el", "aprendizaje", "por", "diferencia", "temporal", "de", "Arthur", "Samuel", "."], "sentence-detokenized": "TD-Lambda es un algoritmo de aprendizaje inventado por Richard S. Sutton basado en un trabajo anterior sobre el aprendizaje por diferencia temporal de Arthur Samuel.", "token2charspan": [[0, 9], [10, 12], [13, 15], [16, 25], [26, 28], [29, 40], [41, 50], [51, 54], [55, 62], [63, 65], [66, 72], [73, 79], [80, 82], [83, 85], [86, 93], [94, 102], [103, 108], [109, 111], [112, 123], [124, 127], [128, 138], [139, 147], [148, 150], [151, 157], [158, 164], [164, 165]]}
{"doc_key": "ai-test-343", "ner": [[2, 4, "field"], [7, 7, "field"], [9, 11, "task"], [15, 18, "task"], [20, 20, "task"], [26, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 11, 2, 4, "part-of", "task_part_of_field", false, false], [9, 11, 7, 7, "part-of", "task_part_of_field", false, false], [15, 18, 9, 11, "named", "", false, false], [20, 20, 9, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["En", "la", "miner\u00eda", "de", "datos", "y", "la", "estad\u00edstica", ",", "el", "clustering", "jer\u00e1rquico", "(", "tambi\u00e9n", "llamado", "an\u00e1lisis", "de", "cluster", "jer\u00e1rquico", "o", "HCA", ")", "es", "un", "m\u00e9todo", "de", "an\u00e1lisis", "de", "cluster", "que", "busca", "construir", "una", "jerarqu\u00eda", "de", "clusters", "."], "sentence-detokenized": "En la miner\u00eda de datos y la estad\u00edstica, el clustering jer\u00e1rquico (tambi\u00e9n llamado an\u00e1lisis de cluster jer\u00e1rquico o HCA) es un m\u00e9todo de an\u00e1lisis de cluster que busca construir una jerarqu\u00eda de clusters.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 22], [23, 24], [25, 27], [28, 39], [39, 40], [41, 43], [44, 54], [55, 65], [66, 67], [67, 74], [75, 82], [83, 91], [92, 94], [95, 102], [103, 113], [114, 115], [116, 119], [119, 120], [121, 123], [124, 126], [127, 133], [134, 136], [137, 145], [146, 148], [149, 156], [157, 160], [161, 166], [167, 176], [177, 180], [181, 190], [191, 193], [194, 202], [202, 203]]}
{"doc_key": "ai-test-344", "ner": [[3, 3, "algorithm"], [11, 13, "field"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 11, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["El", "concepto", "de", "deconvoluci\u00f3n", "se", "utiliza", "ampliamente", "en", "las", "t\u00e9cnicas", "de", "procesamiento", "de", "se\u00f1ales", "y", "de", "im\u00e1genes", "."], "sentence-detokenized": "El concepto de deconvoluci\u00f3n se utiliza ampliamente en las t\u00e9cnicas de procesamiento de se\u00f1ales y de im\u00e1genes.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 28], [29, 31], [32, 39], [40, 51], [52, 54], [55, 58], [59, 67], [68, 70], [71, 84], [85, 87], [88, 95], [96, 97], [98, 100], [101, 109], [109, 110]]}
{"doc_key": "ai-test-345", "ner": [[0, 2, "algorithm"], [21, 23, "misc"], [27, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 21, 23, "related-to", "enhances", false, false], [0, 2, 21, 23, "related-to", "reduces", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Los", "mapas", "cognitivos", "sirven", "para", "construir", "y", "acumular", "conocimientos", "espaciales", ",", "permitiendo", "al", "ojo", "de", "la", "mente", "visualizar", "im\u00e1genes", "para", "reducir", "la", "carga", "cognitiva", "y", "mejorar", "el", "recuerdo", "y", "el", "aprendizaje", "de", "la", "informaci\u00f3n", "."], "sentence-detokenized": "Los mapas cognitivos sirven para construir y acumular conocimientos espaciales, permitiendo al ojo de la mente visualizar im\u00e1genes para reducir la carga cognitiva y mejorar el recuerdo y el aprendizaje de la informaci\u00f3n.", "token2charspan": [[0, 3], [4, 9], [10, 20], [21, 27], [28, 32], [33, 42], [43, 44], [45, 53], [54, 67], [68, 78], [78, 79], [80, 91], [92, 94], [95, 98], [99, 101], [102, 104], [105, 110], [111, 121], [122, 130], [131, 135], [136, 143], [144, 146], [147, 152], [153, 162], [163, 164], [165, 172], [173, 175], [176, 184], [185, 186], [187, 189], [190, 201], [202, 204], [205, 207], [208, 219], [219, 220]]}
{"doc_key": "ai-test-346", "ner": [[7, 7, "programlang"], [9, 9, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": [",", "normalmente", "proporcionando", "bindings", "a", "lenguajes", "como", "Python", ",", "C++", ",", "Java", ")", "."], "sentence-detokenized": ", normalmente proporcionando bindings a lenguajes como Python, C++, Java).", "token2charspan": [[0, 1], [2, 13], [14, 28], [29, 37], [38, 39], [40, 49], [50, 54], [55, 61], [61, 62], [63, 66], [66, 67], [68, 72], [72, 73], [73, 74]]}
{"doc_key": "ai-test-347", "ner": [[1, 5, "product"], [7, 7, "product"], [21, 23, "task"], [31, 34, "task"], [39, 41, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 5, 21, 23, "usage", "", false, false], [1, 5, 31, 34, "usage", "", false, false], [1, 5, 39, 41, "usage", "", false, false], [7, 7, 1, 5, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Una", "interfaz", "de", "usuario", "de", "voz", "(", "VUI", ")", "hace", "posible", "la", "interacci\u00f3n", "humana", "hablada", "con", "los", "ordenadores", ",", "utilizando", "el", "reconocimiento", "de", "voz", "para", "entender", "los", "comandos", "hablados", "y", "la", "respuesta", "a", "las", "preguntas", ",", "y", "normalmente", "el", "texto", "a", "voz", "para", "reproducir", "una", "respuesta", "."], "sentence-detokenized": "Una interfaz de usuario de voz (VUI) hace posible la interacci\u00f3n humana hablada con los ordenadores, utilizando el reconocimiento de voz para entender los comandos hablados y la respuesta a las preguntas, y normalmente el texto a voz para reproducir una respuesta.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 23], [24, 26], [27, 30], [31, 32], [32, 35], [35, 36], [37, 41], [42, 49], [50, 52], [53, 64], [65, 71], [72, 79], [80, 83], [84, 87], [88, 99], [99, 100], [101, 111], [112, 114], [115, 129], [130, 132], [133, 136], [137, 141], [142, 150], [151, 154], [155, 163], [164, 172], [173, 174], [175, 177], [178, 187], [188, 189], [190, 193], [194, 203], [203, 204], [205, 206], [207, 218], [219, 221], [222, 227], [228, 229], [230, 233], [234, 238], [239, 249], [250, 253], [254, 263], [263, 264]]}
{"doc_key": "ai-test-348", "ner": [[0, 0, "programlang"], [3, 5, "misc"], [9, 9, "programlang"], [14, 15, "researcher"], [17, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 5, "general-affiliation", "is_a", false, false], [0, 0, 9, 9, "general-affiliation", "made_with", false, false], [0, 0, 14, 15, "origin", "", false, false], [14, 15, 17, 18, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Jess", "es", "un", "motor", "de", "reglas", "para", "la", "plataforma", "Java", "que", "fue", "desarrollado", "por", "Ernest", "Friedman-Hill", "de", "Sandia", "National", "."], "sentence-detokenized": "Jess es un motor de reglas para la plataforma Java que fue desarrollado por Ernest Friedman-Hill de Sandia National.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 16], [17, 19], [20, 26], [27, 31], [32, 34], [35, 45], [46, 50], [51, 54], [55, 58], [59, 71], [72, 75], [76, 82], [83, 96], [97, 99], [100, 106], [107, 115], [115, 116]]}
{"doc_key": "ai-test-349", "ner": [[4, 6, "algorithm"], [23, 24, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 23, 24, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["En", "el", "caso", "de", "los", "perceptrones", "multicapa", ",", "en", "los", "que", "existe", "una", "capa", "oculta", ",", "deben", "utilizarse", "algoritmos", "m\u00e1s", "sofisticados", ",", "como", "la", "retropropagaci\u00f3n", "."], "sentence-detokenized": "En el caso de los perceptrones multicapa, en los que existe una capa oculta, deben utilizarse algoritmos m\u00e1s sofisticados, como la retropropagaci\u00f3n.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 13], [14, 17], [18, 30], [31, 40], [40, 41], [42, 44], [45, 48], [49, 52], [53, 59], [60, 63], [64, 68], [69, 75], [75, 76], [77, 82], [83, 93], [94, 104], [105, 108], [109, 121], [121, 122], [123, 127], [128, 130], [131, 147], [147, 148]]}
{"doc_key": "ai-test-350", "ner": [[7, 8, "product"], [0, 5, "product"], [12, 18, "algorithm"], [23, 24, "field"], [29, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 5, 7, 8, "part-of", "", false, false], [0, 5, 12, 18, "usage", "", false, true], [12, 18, 23, 24, "related-to", "performs", false, false], [29, 34, 23, 24, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["El", "sistema", "de", "traducci\u00f3n", "autom\u00e1tica", "neural", "de", "Google", "Translate", "utiliza", "una", "gran", "red", "neuronal", "artificial", "de", "extremo", "a", "extremo", "que", "intenta", "realizar", "un", "aprendizaje", "profundo", ",", "en", "particular", ",", "redes", "de", "memoria", "a", "corto", "plazo", "."], "sentence-detokenized": "El sistema de traducci\u00f3n autom\u00e1tica neural de Google Translate utiliza una gran red neuronal artificial de extremo a extremo que intenta realizar un aprendizaje profundo, en particular, redes de memoria a corto plazo.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 24], [25, 35], [36, 42], [43, 45], [46, 52], [53, 62], [63, 70], [71, 74], [75, 79], [80, 83], [84, 92], [93, 103], [104, 106], [107, 114], [115, 116], [117, 124], [125, 128], [129, 136], [137, 145], [146, 148], [149, 160], [161, 169], [169, 170], [171, 173], [174, 184], [184, 185], [186, 191], [192, 194], [195, 202], [203, 204], [205, 210], [211, 216], [216, 217]]}
{"doc_key": "ai-test-351", "ner": [[10, 10, "researcher"], [12, 12, "researcher"], [14, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["En", "los", "a\u00f1os", "80", "y", "principios", "de", "los", "90", ",", "Werbos", ",", "Williams", ",", "Robinson", ",", "J\u00fcrgen", "Schmidhuber", ",", "Sepp", "Hochreiter", ",", "Pearlmutter", "y", "otros", "desarrollaron", "varios", "m\u00e9todos", "para", "hacerlo", "."], "sentence-detokenized": "En los a\u00f1os 80 y principios de los 90, Werbos, Williams, Robinson, J\u00fcrgen Schmidhuber, Sepp Hochreiter, Pearlmutter y otros desarrollaron varios m\u00e9todos para hacerlo.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 16], [17, 27], [28, 30], [31, 34], [35, 37], [37, 38], [39, 45], [45, 46], [47, 55], [55, 56], [57, 65], [65, 66], [67, 73], [74, 85], [85, 86], [87, 91], [92, 102], [102, 103], [104, 115], [116, 117], [118, 123], [124, 137], [138, 144], [145, 152], [153, 157], [158, 165], [165, 166]]}
{"doc_key": "ai-test-352", "ner": [[1, 3, "organisation"], [9, 9, "organisation"], [15, 17, "task"], [22, 22, "product"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [[22, 22, 15, 17, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [3], "sentence": ["|", "Apple", "Apple", "Inc.", "originalmente", "licenci\u00f3", "el", "software", "de", "Nuance", "para", "dotar", "de", "capacidad", "de", "reconocimiento", "de", "voz", "a", "su", "asistente", "digital", "Siri", "."], "sentence-detokenized": "| Apple Apple Inc. originalmente licenci\u00f3 el software de Nuance para dotar de capacidad de reconocimiento de voz a su asistente digital Siri.", "token2charspan": [[0, 1], [2, 7], [8, 13], [14, 18], [19, 32], [33, 41], [42, 44], [45, 53], [54, 56], [57, 63], [64, 68], [69, 74], [75, 77], [78, 87], [88, 90], [91, 105], [106, 108], [109, 112], [113, 114], [115, 117], [118, 127], [128, 135], [136, 140], [140, 141]]}
{"doc_key": "ai-test-353", "ner": [[0, 0, "organisation"], [3, 5, "misc"], [8, 9, "person"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 3, 5, "role", "releases_movies_in_genre", false, false], [8, 9, 0, 0, "role", "directs_for", false, false], [13, 14, 0, 0, "role", "directs_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Columbia", "lanz\u00f3", "varios", "westerns", "en", "3D", "producidos", "por", "Sam", "Katzman", "y", "dirigidos", "por", "William", "Castle", "."], "sentence-detokenized": "Columbia lanz\u00f3 varios westerns en 3D producidos por Sam Katzman y dirigidos por William Castle.", "token2charspan": [[0, 8], [9, 14], [15, 21], [22, 30], [31, 33], [34, 36], [37, 47], [48, 51], [52, 55], [56, 63], [64, 65], [66, 75], [76, 79], [80, 87], [88, 94], [94, 95]]}
{"doc_key": "ai-test-354", "ner": [[9, 9, "field"], [12, 12, "field"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Incorpora", "conocimientos", "e", "investigaciones", "en", "los", "campos", "de", "la", "inform\u00e1tica", ",", "la", "ling\u00fc\u00edstica", "y", "la", "ingenier\u00eda", "inform\u00e1tica", "."], "sentence-detokenized": "Incorpora conocimientos e investigaciones en los campos de la inform\u00e1tica, la ling\u00fc\u00edstica y la ingenier\u00eda inform\u00e1tica.", "token2charspan": [[0, 9], [10, 23], [24, 25], [26, 41], [42, 44], [45, 48], [49, 55], [56, 58], [59, 61], [62, 73], [73, 74], [75, 77], [78, 89], [90, 91], [92, 94], [95, 105], [106, 117], [117, 118]]}
{"doc_key": "ai-test-355", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Aqu\u00ed", "hay", "un", "ejemplo", "de", "c\u00f3digo", "R", ":"], "sentence-detokenized": "Aqu\u00ed hay un ejemplo de c\u00f3digo R:", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 19], [20, 22], [23, 29], [30, 31], [31, 32]]}
{"doc_key": "ai-test-356", "ner": [[0, 2, "metrics"], [7, 10, "metrics"], [12, 12, "metrics"], [17, 20, "metrics"], [22, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 7, 10, "part-of", "plotted_into", false, false], [0, 2, 17, 20, "part-of", "plotted_into", false, false], [12, 12, 7, 10, "named", "", false, false], [22, 22, 17, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["La", "curva", "ROC", "se", "crea", "trazando", "la", "tasa", "de", "positivos", "VERDADEROS", "(", "TPR", ")", "frente", "a", "la", "tasa", "de", "positivos", "FALSOS", "(", "FPR", ")", "en", "varios", "ajustes", "de", "umbral", "."], "sentence-detokenized": "La curva ROC se crea trazando la tasa de positivos VERDADEROS (TPR) frente a la tasa de positivos FALSOS (FPR) en varios ajustes de umbral.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 15], [16, 20], [21, 29], [30, 32], [33, 37], [38, 40], [41, 50], [51, 61], [62, 63], [63, 66], [66, 67], [68, 74], [75, 76], [77, 79], [80, 84], [85, 87], [88, 97], [98, 104], [105, 106], [106, 109], [109, 110], [111, 113], [114, 120], [121, 128], [129, 131], [132, 138], [138, 139]]}
{"doc_key": "ai-test-357", "ner": [[8, 11, "field"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 15, 8, 11, "related-to", "researches_field", false, false], [17, 18, 8, 11, "related-to", "researches_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "investigaci\u00f3n", "se", "estanc\u00f3", "despu\u00e9s", "de", "las", "investigaciones", "sobre", "el", "aprendizaje", "autom\u00e1tico", "realizadas", "por", "Marvin", "Minsky", "y", "Seymour", "Papert", "(", "1969", ")", ","], "sentence-detokenized": "La investigaci\u00f3n se estanc\u00f3 despu\u00e9s de las investigaciones sobre el aprendizaje autom\u00e1tico realizadas por Marvin Minsky y Seymour Papert (1969),", "token2charspan": [[0, 2], [3, 16], [17, 19], [20, 27], [28, 35], [36, 38], [39, 42], [43, 58], [59, 64], [65, 67], [68, 79], [80, 90], [91, 101], [102, 105], [106, 112], [113, 119], [120, 121], [122, 129], [130, 136], [137, 138], [138, 142], [142, 143], [143, 144]]}
{"doc_key": "ai-test-358", "ner": [[10, 10, "task"], [13, 15, "programlang"], [17, 20, "product"], [22, 23, "programlang"], [25, 25, "product"], [28, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 10, 13, 15, "related-to", "used_to_build", false, false], [10, 10, 17, 20, "related-to", "used_to_build", false, false], [10, 10, 22, 23, "related-to", "used_to_build", false, false], [10, 10, 25, 25, "related-to", "used_to_build", false, false], [10, 10, 28, 28, "related-to", "used_to_build", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Otros", "entornos", "de", "programaci\u00f3n", "que", "se", "utilizan", "para", "construir", "aplicaciones", "DAQ", "incluyen", "la", "l\u00f3gica", "de", "escalera", ",", "Visual", "C", "+", "+", ",", "Visual", "Basic", ",", "LabVIEW", ",", "y", "MATLAB", "."], "sentence-detokenized": "Otros entornos de programaci\u00f3n que se utilizan para construir aplicaciones DAQ incluyen la l\u00f3gica de escalera, Visual C + +, Visual Basic, LabVIEW, y MATLAB.", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 30], [31, 34], [35, 37], [38, 46], [47, 51], [52, 61], [62, 74], [75, 78], [79, 87], [88, 90], [91, 97], [98, 100], [101, 109], [109, 110], [111, 117], [118, 119], [120, 121], [122, 123], [123, 124], [125, 131], [132, 137], [137, 138], [139, 146], [146, 147], [148, 149], [150, 156], [156, 157]]}
{"doc_key": "ai-test-359", "ner": [[13, 14, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "m\u00e9trica", "fue", "dise\u00f1ada", "para", "solucionar", "algunos", "de", "los", "problemas", "encontrados", "en", "la", "m\u00e9trica", "BLEU", "m\u00e1s", "popular", ",", "y", "tambi\u00e9n", "para", "producir", "una", "buena", "correlaci\u00f3n", "con", "el", "juicio", "humano", "a", "nivel", "de", "frase", "o", "segmento", "."], "sentence-detokenized": "La m\u00e9trica fue dise\u00f1ada para solucionar algunos de los problemas encontrados en la m\u00e9trica BLEU m\u00e1s popular, y tambi\u00e9n para producir una buena correlaci\u00f3n con el juicio humano a nivel de frase o segmento.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 23], [24, 28], [29, 39], [40, 47], [48, 50], [51, 54], [55, 64], [65, 76], [77, 79], [80, 82], [83, 90], [91, 95], [96, 99], [100, 107], [107, 108], [109, 110], [111, 118], [119, 123], [124, 132], [133, 136], [137, 142], [143, 154], [155, 158], [159, 161], [162, 168], [169, 175], [176, 177], [178, 183], [184, 186], [187, 192], [193, 194], [195, 203], [203, 204]]}
{"doc_key": "ai-test-360", "ner": [[3, 6, "algorithm"], [9, 11, "algorithm"], [13, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["T\u00e9cnicas", "como", "las", "redes", "de", "Markov", "din\u00e1micas", ",", "las", "redes", "neuronales", "convolucionales", "y", "la", "memoria", "a", "corto", "plazo", "suelen", "emplearse", "para", "explotar", "las", "correlaciones", "sem\u00e1nticas", "entre", "fotogramas", "de", "v\u00eddeo", "consecutivos", "."], "sentence-detokenized": "T\u00e9cnicas como las redes de Markov din\u00e1micas, las redes neuronales convolucionales y la memoria a corto plazo suelen emplearse para explotar las correlaciones sem\u00e1nticas entre fotogramas de v\u00eddeo consecutivos.", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 23], [24, 26], [27, 33], [34, 43], [43, 44], [45, 48], [49, 54], [55, 65], [66, 81], [82, 83], [84, 86], [87, 94], [95, 96], [97, 102], [103, 108], [109, 115], [116, 125], [126, 130], [131, 139], [140, 143], [144, 157], [158, 168], [169, 174], [175, 185], [186, 188], [189, 194], [195, 207], [207, 208]]}
{"doc_key": "ai-test-361", "ner": [[3, 4, "product"], [6, 6, "product"], [16, 20, "product"], [25, 25, "product"], [40, 41, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 16, 20, "artifact", "", false, false], [3, 4, 40, 41, "named", "", false, false], [6, 6, 3, 4, "named", "", false, false], [25, 25, 16, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Las", "placas", "de", "circuito", "impreso", "(", "PCB", ")", "producidas", "en", "serie", "se", "fabrican", "casi", "exclusivamente", "con", "robots", "de", "recogida", "y", "colocaci\u00f3n", ",", "normalmente", "con", "manipuladores", "SCARA", ",", "que", "extraen", "diminutos", "componentes", "electr\u00f3nicos", "de", "tiras", "o", "bandejas", "y", "los", "colocan", "en", "las", "PCB", "con", "gran", "precisi\u00f3n", "."], "sentence-detokenized": "Las placas de circuito impreso (PCB) producidas en serie se fabrican casi exclusivamente con robots de recogida y colocaci\u00f3n, normalmente con manipuladores SCARA, que extraen diminutos componentes electr\u00f3nicos de tiras o bandejas y los colocan en las PCB con gran precisi\u00f3n.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 22], [23, 30], [31, 32], [32, 35], [35, 36], [37, 47], [48, 50], [51, 56], [57, 59], [60, 68], [69, 73], [74, 88], [89, 92], [93, 99], [100, 102], [103, 111], [112, 113], [114, 124], [124, 125], [126, 137], [138, 141], [142, 155], [156, 161], [161, 162], [163, 166], [167, 174], [175, 184], [185, 196], [197, 209], [210, 212], [213, 218], [219, 220], [221, 229], [230, 231], [232, 235], [236, 243], [244, 246], [247, 250], [251, 254], [255, 258], [259, 263], [264, 273], [273, 274]]}
{"doc_key": "ai-test-362", "ner": [[4, 5, "field"], [16, 17, "algorithm"], [24, 25, "researcher"], [27, 28, "researcher"], [30, 33, "researcher"], [41, 42, "algorithm"], [45, 47, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[16, 17, 4, 5, "part-of", "", false, false], [16, 17, 24, 25, "origin", "", false, false], [16, 17, 27, 28, "origin", "", false, false], [16, 17, 30, 33, "origin", "", false, false], [16, 17, 41, 42, "type-of", "", false, false], [41, 42, 45, 47, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["En", "el", "contexto", "del", "aprendizaje", "autom\u00e1tico", ",", "donde", "se", "aplica", "m\u00e1s", "ampliamente", "en", "la", "actualidad", ",", "el", "LDA", "fue", "redescubierto", "de", "forma", "independiente", "por", "David", "Blei", ",", "Andrew", "Ng", "y", "Michael", "I", ".", "Jordan", "en", "2003", ",", "y", "presentado", "como", "un", "modelo", "gr\u00e1fico", "para", "el", "descubrimiento", "de", "temas", "."], "sentence-detokenized": "En el contexto del aprendizaje autom\u00e1tico, donde se aplica m\u00e1s ampliamente en la actualidad, el LDA fue redescubierto de forma independiente por David Blei, Andrew Ng y Michael I. Jordan en 2003, y presentado como un modelo gr\u00e1fico para el descubrimiento de temas.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 18], [19, 30], [31, 41], [41, 42], [43, 48], [49, 51], [52, 58], [59, 62], [63, 74], [75, 77], [78, 80], [81, 91], [91, 92], [93, 95], [96, 99], [100, 103], [104, 117], [118, 120], [121, 126], [127, 140], [141, 144], [145, 150], [151, 155], [155, 156], [157, 163], [164, 166], [167, 168], [169, 176], [177, 178], [178, 179], [180, 186], [187, 189], [190, 194], [194, 195], [196, 197], [198, 208], [209, 213], [214, 216], [217, 223], [224, 231], [232, 236], [237, 239], [240, 254], [255, 257], [258, 263], [263, 264]]}
{"doc_key": "ai-test-363", "ner": [[10, 10, "task"], [14, 14, "misc"], [19, 19, "metrics"], [22, 22, "metrics"], [25, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 10, 14, 14, "related-to", "task_across_domain", false, false]], "relations_mapping_to_source": [0], "sentence": ["El", "rendimiento", "medido", "en", "los", "datos", "de", "prueba", "de", "ocho", "WSI", "ingenuos", "en", "varias", "tauopat\u00edas", "dio", "como", "resultado", "un", "recuerdo", ",", "una", "precisi\u00f3n", "y", "una", "puntuaci\u00f3n", "F1", "de", "0,92", ",", "0,72", "y", "0,81", ",", "respectivamente", "."], "sentence-detokenized": "El rendimiento medido en los datos de prueba de ocho WSI ingenuos en varias tauopat\u00edas dio como resultado un recuerdo, una precisi\u00f3n y una puntuaci\u00f3n F1 de 0,92, 0,72 y 0,81, respectivamente.", "token2charspan": [[0, 2], [3, 14], [15, 21], [22, 24], [25, 28], [29, 34], [35, 37], [38, 44], [45, 47], [48, 52], [53, 56], [57, 65], [66, 68], [69, 75], [76, 86], [87, 90], [91, 95], [96, 105], [106, 108], [109, 117], [117, 118], [119, 122], [123, 132], [133, 134], [135, 138], [139, 149], [150, 152], [153, 155], [156, 160], [160, 161], [162, 166], [167, 168], [169, 173], [173, 174], [175, 190], [190, 191]]}
{"doc_key": "ai-test-364", "ner": [[7, 7, "field"], [13, 15, "field"], [20, 20, "field"], [25, 27, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 20, 20, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["Con", "la", "ayuda", "de", "tecnolog\u00edas", "avanzadas", "de", "RA", "(", "por", "ejemplo", ",", "a\u00f1adiendo", "visi\u00f3n", "por", "ordenador", ",", "incorporando", "c\u00e1maras", "de", "RA", "en", "el", "smartphone", "y", "reconocimiento", "de", "objetos", ")", "la", "informaci\u00f3n", "sobre", "el", "mundo", "real", "que", "rodea", "al", "usuario", "se", "convierte", "en", "interactiva", "y", "se", "manipula", "digitalmente", "."], "sentence-detokenized": "Con la ayuda de tecnolog\u00edas avanzadas de RA (por ejemplo, a\u00f1adiendo visi\u00f3n por ordenador, incorporando c\u00e1maras de RA en el smartphone y reconocimiento de objetos) la informaci\u00f3n sobre el mundo real que rodea al usuario se convierte en interactiva y se manipula digitalmente.", "token2charspan": [[0, 3], [4, 6], [7, 12], [13, 15], [16, 27], [28, 37], [38, 40], [41, 43], [44, 45], [45, 48], [49, 56], [56, 57], [58, 67], [68, 74], [75, 78], [79, 88], [88, 89], [90, 102], [103, 110], [111, 113], [114, 116], [117, 119], [120, 122], [123, 133], [134, 135], [136, 150], [151, 153], [154, 161], [161, 162], [163, 165], [166, 177], [178, 183], [184, 186], [187, 192], [193, 197], [198, 201], [202, 207], [208, 210], [211, 218], [219, 221], [222, 231], [232, 234], [235, 246], [247, 248], [249, 251], [252, 260], [261, 273], [273, 274]]}
{"doc_key": "ai-test-365", "ner": [[3, 3, "researcher"], [8, 8, "organisation"], [17, 18, "field"], [30, 31, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 8, 8, "role", "forms_company", false, false], [8, 8, 17, 18, "related-to", "works_with", false, false], [8, 8, 30, 31, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["En", "2014", ",", "Schmidhuber", "cre\u00f3", "una", "empresa", ",", "Nnaisense", ",", "para", "trabajar", "en", "aplicaciones", "comerciales", "de", "la", "inteligencia", "artificial", "en", "campos", "como", "las", "finanzas", ",", "la", "industria", "pesada", "y", "los", "coches", "autoconducidos", "."], "sentence-detokenized": "En 2014, Schmidhuber cre\u00f3 una empresa, Nnaisense, para trabajar en aplicaciones comerciales de la inteligencia artificial en campos como las finanzas, la industria pesada y los coches autoconducidos.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 25], [26, 29], [30, 37], [37, 38], [39, 48], [48, 49], [50, 54], [55, 63], [64, 66], [67, 79], [80, 91], [92, 94], [95, 97], [98, 110], [111, 121], [122, 124], [125, 131], [132, 136], [137, 140], [141, 149], [149, 150], [151, 153], [154, 163], [164, 170], [171, 172], [173, 176], [177, 183], [184, 198], [198, 199]]}
{"doc_key": "ai-test-366", "ner": [[26, 28, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Esto", "no", "s\u00f3lo", "altera", "el", "rendimiento", "de", "todas", "las", "pruebas", "posteriores", "en", "el", "modelo", "explicativo", "retenido", ",", "sino", "que", "puede", "introducir", "un", "sesgo", "y", "alterar", "el", "error", "cuadr\u00e1tico", "medio", "en", "la", "estimaci\u00f3n", "."], "sentence-detokenized": "Esto no s\u00f3lo altera el rendimiento de todas las pruebas posteriores en el modelo explicativo retenido, sino que puede introducir un sesgo y alterar el error cuadr\u00e1tico medio en la estimaci\u00f3n.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 19], [20, 22], [23, 34], [35, 37], [38, 43], [44, 47], [48, 55], [56, 67], [68, 70], [71, 73], [74, 80], [81, 92], [93, 101], [101, 102], [103, 107], [108, 111], [112, 117], [118, 128], [129, 131], [132, 137], [138, 139], [140, 147], [148, 150], [151, 156], [157, 167], [168, 173], [174, 176], [177, 179], [180, 190], [190, 191]]}
{"doc_key": "ai-test-367", "ner": [[0, 1, "misc"], [9, 10, "algorithm"], [15, 17, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 1, "usage", "", false, false], [9, 10, 15, 17, "topic", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Los", "bigramas", "se", "utilizan", "en", "la", "mayor\u00eda", "de", "los", "modelos", "ling\u00fc\u00edsticos", "de", "\u00e9xito", "para", "el", "reconocimiento", "del", "habla", "."], "sentence-detokenized": "Los bigramas se utilizan en la mayor\u00eda de los modelos ling\u00fc\u00edsticos de \u00e9xito para el reconocimiento del habla.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 24], [25, 27], [28, 30], [31, 38], [39, 41], [42, 45], [46, 53], [54, 66], [67, 69], [70, 75], [76, 80], [81, 83], [84, 98], [99, 102], [103, 108], [108, 109]]}
{"doc_key": "ai-test-368", "ner": [[3, 4, "field"], [10, 12, "misc"], [18, 20, "misc"], [25, 27, "organisation"], [30, 32, "misc"], [38, 41, "organisation"], [44, 46, "misc"], [52, 56, "organisation"], [60, 62, "misc"], [68, 70, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[10, 12, 3, 4, "topic", "", false, false], [18, 20, 25, 27, "origin", "", false, false], [30, 32, 38, 41, "origin", "", false, false], [44, 46, 52, 56, "origin", "", false, false], [60, 62, 68, 70, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Sus", "investigaciones", "en", "psicolog\u00eda", "cognitiva", "han", "sido", "premiadas", "con", "el", "Early", "Career", "Award", "(", "1984", ")", "y", "el", "Boyd", "McCandless", "Award", "1986", ")", "de", "la", "American", "Psychological", "Association", ",", "el", "Troland", "Research", "Award", "(", "1993", ")", "de", "la", "National", "Academy", "of", "Sciences", ",", "el", "Henry", "Dale", "Prize", "(", "2004", ")", "de", "la", "Royal", "Institution", "of", "Great", "Britain", ",", "y", "el", "George", "Miller", "Prize", "(", "2010", ")", "de", "la", "Cognitive", "Neuroscience", "Society", "."], "sentence-detokenized": "Sus investigaciones en psicolog\u00eda cognitiva han sido premiadas con el Early Career Award (1984) y el Boyd McCandless Award 1986) de la American Psychological Association, el Troland Research Award (1993) de la National Academy of Sciences, el Henry Dale Prize (2004) de la Royal Institution of Great Britain, y el George Miller Prize (2010) de la Cognitive Neuroscience Society.", "token2charspan": [[0, 3], [4, 19], [20, 22], [23, 33], [34, 43], [44, 47], [48, 52], [53, 62], [63, 66], [67, 69], [70, 75], [76, 82], [83, 88], [89, 90], [90, 94], [94, 95], [96, 97], [98, 100], [101, 105], [106, 116], [117, 122], [123, 127], [127, 128], [129, 131], [132, 134], [135, 143], [144, 157], [158, 169], [169, 170], [171, 173], [174, 181], [182, 190], [191, 196], [197, 198], [198, 202], [202, 203], [204, 206], [207, 209], [210, 218], [219, 226], [227, 229], [230, 238], [238, 239], [240, 242], [243, 248], [249, 253], [254, 259], [260, 261], [261, 265], [265, 266], [267, 269], [270, 272], [273, 278], [279, 290], [291, 293], [294, 299], [300, 307], [307, 308], [309, 310], [311, 313], [314, 320], [321, 327], [328, 333], [334, 335], [335, 339], [339, 340], [341, 343], [344, 346], [347, 356], [357, 369], [370, 377], [377, 378]]}
{"doc_key": "ai-test-369", "ner": [[1, 1, "misc"], [7, 7, "misc"], [10, 13, "product"], [17, 17, "researcher"], [19, 19, "researcher"], [26, 27, "researcher"], [29, 30, "researcher"], [33, 35, "task"], [37, 40, "researcher"], [42, 45, "researcher"], [46, 47, "task"], [49, 49, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[1, 1, 7, 7, "named", "", false, false], [1, 1, 49, 49, "named", "", false, false], [7, 7, 17, 17, "origin", "", false, false], [7, 7, 19, 19, "origin", "", false, false], [7, 7, 33, 35, "related-to", "used_for", false, false], [10, 13, 7, 7, "usage", "", false, false], [10, 13, 46, 47, "named", "", false, false], [26, 27, 7, 7, "usage", "", false, false], [26, 27, 37, 40, "named", "same", false, false], [29, 30, 7, 7, "usage", "", false, false], [29, 30, 42, 45, "named", "same", false, false], [46, 47, 49, 49, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Un", "eigenface", "(", "El", "enfoque", "de", "utilizar", "eigenfaces", "para", "el", "sistema", "de", "reconocimiento", "facial", "fue", "desarrollado", "por", "Sirovich", "y", "Kirby", "(", "1987", ")", "y", "utilizado", "por", "Matthew", "Turk", "y", "Alex", "Pentland", "en", "la", "clasificaci\u00f3n", "de", "rostros", ".", "Turk", ",", "Matthew", "A", "y", "Pentland", ",", "Alex", "P.", "Face", "recognition", "using", "eigenfaces", "."], "sentence-detokenized": "Un eigenface (El enfoque de utilizar eigenfaces para el sistema de reconocimiento facial fue desarrollado por Sirovich y Kirby (1987) y utilizado por Matthew Turk y Alex Pentland en la clasificaci\u00f3n de rostros. Turk, Matthew A y Pentland, Alex P. Face recognition using eigenfaces.", "token2charspan": [[0, 2], [3, 12], [13, 14], [14, 16], [17, 24], [25, 27], [28, 36], [37, 47], [48, 52], [53, 55], [56, 63], [64, 66], [67, 81], [82, 88], [89, 92], [93, 105], [106, 109], [110, 118], [119, 120], [121, 126], [127, 128], [128, 132], [132, 133], [134, 135], [136, 145], [146, 149], [150, 157], [158, 162], [163, 164], [165, 169], [170, 178], [179, 181], [182, 184], [185, 198], [199, 201], [202, 209], [209, 210], [211, 215], [215, 216], [217, 224], [225, 226], [227, 228], [229, 237], [237, 238], [239, 243], [244, 246], [247, 251], [252, 263], [264, 269], [270, 280], [280, 281]]}
{"doc_key": "ai-test-370", "ner": [[10, 10, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "continuaci\u00f3n", ",", "se", "puede", "utilizar", "un", "diccionario", "l\u00e9xico", "como", "WordNet", "para", "comprender", "el", "contexto", "."], "sentence-detokenized": "A continuaci\u00f3n, se puede utilizar un diccionario l\u00e9xico como WordNet para comprender el contexto.", "token2charspan": [[0, 1], [2, 14], [14, 15], [16, 18], [19, 24], [25, 33], [34, 36], [37, 48], [49, 55], [56, 60], [61, 68], [69, 73], [74, 84], [85, 87], [88, 96], [96, 97]]}
{"doc_key": "ai-test-371", "ner": [[0, 1, "misc"], [9, 10, "misc"], [19, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 9, 10, "part-of", "", false, false], [9, 10, 19, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "hiponimia", "es", "la", "relaci\u00f3n", "m\u00e1s", "frecuentemente", "codificada", "entre", "los", "synsets", "utilizados", "en", "las", "bases", "de", "datos", "l\u00e9xicas", "como", "WordNet", "."], "sentence-detokenized": "La hiponimia es la relaci\u00f3n m\u00e1s frecuentemente codificada entre los synsets utilizados en las bases de datos l\u00e9xicas como WordNet.", "token2charspan": [[0, 2], [3, 12], [13, 15], [16, 18], [19, 27], [28, 31], [32, 46], [47, 57], [58, 63], [64, 67], [68, 75], [76, 86], [87, 89], [90, 93], [94, 99], [100, 102], [103, 108], [109, 116], [117, 121], [122, 129], [129, 130]]}
{"doc_key": "ai-test-372", "ner": [[0, 0, "organisation"], [7, 9, "programlang"], [11, 11, "programlang"], [43, 43, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 7, 9, "general-affiliation", "", false, false], [0, 0, 11, 11, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["OPeNDAP", "ofrece", "bibliotecas", "de", "c\u00f3digo", "abierto", "en", "C", "+", "+", "y", "Java", ",", "pero", "muchos", "clientes", "conf\u00edan", "en", "las", "bibliotecas", "desarrolladas", "por", "la", "comunidad", "como", "las", "bibliotecas", "incluyen", "capacidades", "integradas", "para", "la", "recuperaci\u00f3n", "de", "datos", "(", "estilo", "de", "matriz", ")", "de", "los", "servidores", "DAP", "."], "sentence-detokenized": "OPeNDAP ofrece bibliotecas de c\u00f3digo abierto en C + + y Java, pero muchos clientes conf\u00edan en las bibliotecas desarrolladas por la comunidad como las bibliotecas incluyen capacidades integradas para la recuperaci\u00f3n de datos (estilo de matriz) de los servidores DAP.", "token2charspan": [[0, 7], [8, 14], [15, 26], [27, 29], [30, 36], [37, 44], [45, 47], [48, 49], [50, 51], [52, 53], [54, 55], [56, 60], [60, 61], [62, 66], [67, 73], [74, 82], [83, 90], [91, 93], [94, 97], [98, 109], [110, 123], [124, 127], [128, 130], [131, 140], [141, 145], [146, 149], [150, 161], [162, 170], [171, 182], [183, 193], [194, 198], [199, 201], [202, 214], [215, 217], [218, 223], [224, 225], [225, 231], [232, 234], [235, 241], [241, 242], [243, 245], [246, 249], [250, 260], [261, 264], [264, 265]]}
{"doc_key": "ai-test-373", "ner": [[4, 5, "misc"], [8, 8, "product"], [21, 21, "country"], [32, 33, "misc"], [47, 47, "organisation"], [45, 45, "product"], [53, 53, "organisation"], [50, 52, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 21, 21, "opposite", "", false, false], [8, 8, 21, 21, "artifact", "", false, false], [32, 33, 8, 8, "part-of", "", false, false], [45, 45, 47, 47, "artifact", "", false, false], [50, 52, 53, 53, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["En", "esa", "p\u00e1gina", ",", "Samurai", "Damashii", "exageraba", "el", "Senkousha", "como", "la", "cristalizaci\u00f3n", "de", "los", "cuatro", "mil", "a\u00f1os", "de", "conocimientos", "cient\u00edficos", "de", "China", ",", "comentaba", "su", "tosco", "dise\u00f1o", "(", "por", "ejemplo", ",", "el", "ca\u00f1\u00f3n", "chino", "en", "su", "entrepierna", ")", "y", "pon\u00eda", "su", "imagen", "entre", "las", "del", "ASIMO", "de", "Honda", "y", "el", "QRIO", "SDR-3X", "de", "Sony", "para", "yuxtaponerlas", "."], "sentence-detokenized": "En esa p\u00e1gina, Samurai Damashii exageraba el Senkousha como la cristalizaci\u00f3n de los cuatro mil a\u00f1os de conocimientos cient\u00edficos de China, comentaba su tosco dise\u00f1o (por ejemplo, el ca\u00f1\u00f3n chino en su entrepierna) y pon\u00eda su imagen entre las del ASIMO de Honda y el QRIO SDR-3X de Sony para yuxtaponerlas.", "token2charspan": [[0, 2], [3, 6], [7, 13], [13, 14], [15, 22], [23, 31], [32, 41], [42, 44], [45, 54], [55, 59], [60, 62], [63, 77], [78, 80], [81, 84], [85, 91], [92, 95], [96, 100], [101, 103], [104, 117], [118, 129], [130, 132], [133, 138], [138, 139], [140, 149], [150, 152], [153, 158], [159, 165], [166, 167], [167, 170], [171, 178], [178, 179], [180, 182], [183, 188], [189, 194], [195, 197], [198, 200], [201, 212], [212, 213], [214, 215], [216, 221], [222, 224], [225, 231], [232, 237], [238, 241], [242, 245], [246, 251], [252, 254], [255, 260], [261, 262], [263, 265], [266, 270], [271, 277], [278, 280], [281, 285], [286, 290], [291, 304], [304, 305]]}
{"doc_key": "ai-test-374", "ner": [[10, 11, "algorithm"], [21, 21, "product"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 21, 21, "part-of", "includes_functionality_of", false, false], [10, 11, 23, 23, "part-of", "includes_functionality_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Tambi\u00e9n", "hay", "muchas", "librer\u00edas", "de", "programaci\u00f3n", "que", "contienen", "funcionalidades", "de", "redes", "neuronales", "y", "que", "pueden", "utilizarse", "en", "implementaciones", "personalizadas", "(", "como", "TensorFlow", ",", "Theano", ",", "etc", "."], "sentence-detokenized": "Tambi\u00e9n hay muchas librer\u00edas de programaci\u00f3n que contienen funcionalidades de redes neuronales y que pueden utilizarse en implementaciones personalizadas (como TensorFlow, Theano, etc.", "token2charspan": [[0, 7], [8, 11], [12, 18], [19, 28], [29, 31], [32, 44], [45, 48], [49, 58], [59, 74], [75, 77], [78, 83], [84, 94], [95, 96], [97, 100], [101, 107], [108, 118], [119, 121], [122, 138], [139, 153], [154, 155], [155, 159], [160, 170], [170, 171], [172, 178], [178, 179], [180, 183], [183, 184]]}
{"doc_key": "ai-test-375", "ner": [[4, 7, "conference"], [9, 10, "organisation"], [13, 19, "conference"], [21, 22, "conference"], [24, 25, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Es", "miembro", "de", "la", "Association", "for", "Computing", "Machinery", ",", "el", "IEEE", ",", "la", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "el", "IAPR", "y", "el", "SPIE", "."], "sentence-detokenized": "Es miembro de la Association for Computing Machinery, el IEEE, la American Association for the Advancement of Science, el IAPR y el SPIE.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 16], [17, 28], [29, 32], [33, 42], [43, 52], [52, 53], [54, 56], [57, 61], [61, 62], [63, 65], [66, 74], [75, 86], [87, 90], [91, 94], [95, 106], [107, 109], [110, 117], [117, 118], [119, 121], [122, 126], [127, 128], [129, 131], [132, 136], [136, 137]]}
{"doc_key": "ai-test-376", "ner": [[4, 4, "organisation"], [9, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 9, 13, "related-to", "runs_trials_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["Una", "prueba", "realizada", "por", "RET", "en", "2011", "con", "c\u00e1maras", "del", "sistema", "de", "reconocimiento", "facial", "montadas", "en", "los", "tranv\u00edas", "permiti\u00f3", "que", "las", "personas", "a", "las", "que", "se", "les", "prohibi\u00f3", "la", "entrada", "en", "los", "tranv\u00edas", "de", "la", "ciudad", "no", "se", "colaran", "de", "todos", "modos", "."], "sentence-detokenized": "Una prueba realizada por RET en 2011 con c\u00e1maras del sistema de reconocimiento facial montadas en los tranv\u00edas permiti\u00f3 que las personas a las que se les prohibi\u00f3 la entrada en los tranv\u00edas de la ciudad no se colaran de todos modos.", "token2charspan": [[0, 3], [4, 10], [11, 20], [21, 24], [25, 28], [29, 31], [32, 36], [37, 40], [41, 48], [49, 52], [53, 60], [61, 63], [64, 78], [79, 85], [86, 94], [95, 97], [98, 101], [102, 110], [111, 119], [120, 123], [124, 127], [128, 136], [137, 138], [139, 142], [143, 146], [147, 149], [150, 153], [154, 162], [163, 165], [166, 173], [174, 176], [177, 180], [181, 189], [190, 192], [193, 195], [196, 202], [203, 205], [206, 208], [209, 216], [217, 219], [220, 225], [226, 231], [231, 232]]}
{"doc_key": "ai-test-377", "ner": [[8, 9, "person"], [10, 11, "organisation"], [24, 25, "person"], [27, 31, "person"], [34, 35, "person"], [37, 38, "person"], [40, 41, "person"], [43, 44, "person"], [46, 47, "person"], [49, 50, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[8, 9, 10, 11, "role", "works_for", false, false], [24, 25, 10, 11, "role", "works_for", false, false], [27, 31, 10, 11, "role", "works_for", false, false], [34, 35, 10, 11, "role", "works_for", false, false], [37, 38, 10, 11, "role", "works_for", false, false], [40, 41, 10, 11, "role", "works_for", false, false], [43, 44, 10, 11, "role", "works_for", false, false], [46, 47, 10, 11, "role", "works_for", false, false], [49, 50, 10, 11, "role", "works_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["La", "pel\u00edcula", ",", "adaptada", "del", "popular", "musical", "de", "Cole", "Porter", "en", "Broadway", ",", "estaba", "protagonizada", "por", "el", "equipo", "de", "cantantes", "de", "la", "MGM", ",", "Howard", "Keel", "y", "Kathryn", "Grayson", ",", "con", "el", "apoyo", "de", "Ann", "Miller", ",", "Keenan", "Wynn", ",", "Bobby", "Van", ",", "James", "Whitmore", ",", "Kurt", "Kasznar", "y", "Tommy", "Rall", "."], "sentence-detokenized": "La pel\u00edcula, adaptada del popular musical de Cole Porter en Broadway, estaba protagonizada por el equipo de cantantes de la MGM, Howard Keel y Kathryn Grayson, con el apoyo de Ann Miller, Keenan Wynn, Bobby Van, James Whitmore, Kurt Kasznar y Tommy Rall.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 21], [22, 25], [26, 33], [34, 41], [42, 44], [45, 49], [50, 56], [57, 59], [60, 68], [68, 69], [70, 76], [77, 90], [91, 94], [95, 97], [98, 104], [105, 107], [108, 117], [118, 120], [121, 123], [124, 127], [127, 128], [129, 135], [136, 140], [141, 142], [143, 150], [151, 158], [158, 159], [160, 163], [164, 166], [167, 172], [173, 175], [176, 179], [180, 186], [186, 187], [188, 194], [195, 199], [199, 200], [201, 206], [207, 210], [210, 211], [212, 217], [218, 226], [226, 227], [228, 232], [233, 240], [241, 242], [243, 248], [249, 253], [253, 254]]}
{"doc_key": "ai-test-378", "ner": [[21, 26, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Estas", "aplicaciones", "deben", "agilizar", "los", "flujos", "de", "llamadas", ",", "minimizar", "los", "avisos", ",", "eliminar", "las", "iteraciones", "innecesarias", "y", "permitir", "un", "elaborado", "sistema", "de", "di\u00e1logo", "de", "iniciativa", "mixta", ",", "que", "permita", "a", "los", "interlocutores", "introducir", "varios", "datos", "en", "un", "solo", "enunciado", "y", "en", "cualquier", "orden", "o", "combinaci\u00f3n", "."], "sentence-detokenized": "Estas aplicaciones deben agilizar los flujos de llamadas, minimizar los avisos, eliminar las iteraciones innecesarias y permitir un elaborado sistema de di\u00e1logo de iniciativa mixta, que permita a los interlocutores introducir varios datos en un solo enunciado y en cualquier orden o combinaci\u00f3n.", "token2charspan": [[0, 5], [6, 18], [19, 24], [25, 33], [34, 37], [38, 44], [45, 47], [48, 56], [56, 57], [58, 67], [68, 71], [72, 78], [78, 79], [80, 88], [89, 92], [93, 104], [105, 117], [118, 119], [120, 128], [129, 131], [132, 141], [142, 149], [150, 152], [153, 160], [161, 163], [164, 174], [175, 180], [180, 181], [182, 185], [186, 193], [194, 195], [196, 199], [200, 214], [215, 225], [226, 232], [233, 238], [239, 241], [242, 244], [245, 249], [250, 259], [260, 261], [262, 264], [265, 274], [275, 280], [281, 282], [283, 294], [294, 295]]}
{"doc_key": "ai-test-379", "ner": [[10, 12, "algorithm"], [15, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 18, 10, 12, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Para", "ello", ",", "se", "pueden", "adaptar", "los", "m\u00e9todos", "tradicionales", "de", "descenso", "de", "gradiente", "(", "o", "descenso", "de", "gradiente", "estoc\u00e1stico", ")", ",", "en", "los", "que", "en", "lugar", "de", "dar", "un", "paso", "en", "la", "direcci\u00f3n", "del", "gradiente", "de", "la", "funci\u00f3n", ",", "se", "da", "un", "paso", "en", "la", "direcci\u00f3n", "de", "un", "vector", "seleccionado", "del", "subgradiente", "de", "la", "funci\u00f3n", "."], "sentence-detokenized": "Para ello, se pueden adaptar los m\u00e9todos tradicionales de descenso de gradiente (o descenso de gradiente estoc\u00e1stico), en los que en lugar de dar un paso en la direcci\u00f3n del gradiente de la funci\u00f3n, se da un paso en la direcci\u00f3n de un vector seleccionado del subgradiente de la funci\u00f3n.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 13], [14, 20], [21, 28], [29, 32], [33, 40], [41, 54], [55, 57], [58, 66], [67, 69], [70, 79], [80, 81], [81, 82], [83, 91], [92, 94], [95, 104], [105, 116], [116, 117], [117, 118], [119, 121], [122, 125], [126, 129], [130, 132], [133, 138], [139, 141], [142, 145], [146, 148], [149, 153], [154, 156], [157, 159], [160, 169], [170, 173], [174, 183], [184, 186], [187, 189], [190, 197], [197, 198], [199, 201], [202, 204], [205, 207], [208, 212], [213, 215], [216, 218], [219, 228], [229, 231], [232, 234], [235, 241], [242, 254], [255, 258], [259, 271], [272, 274], [275, 277], [278, 285], [285, 286]]}
{"doc_key": "ai-test-380", "ner": [[10, 13, "metrics"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Si", "se", "supone", "que", "la", "distorsi\u00f3n", "se", "mide", "por", "el", "error", "medio", "al", "cuadrado", ",", "la", "distorsi\u00f3n", "D", ",", "viene", "dada", "por", ":"], "sentence-detokenized": "Si se supone que la distorsi\u00f3n se mide por el error medio al cuadrado, la distorsi\u00f3n D, viene dada por:", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 16], [17, 19], [20, 30], [31, 33], [34, 38], [39, 42], [43, 45], [46, 51], [52, 57], [58, 60], [61, 69], [69, 70], [71, 73], [74, 84], [85, 86], [86, 87], [88, 93], [94, 98], [99, 102], [102, 103]]}
{"doc_key": "ai-test-381", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [23, 25, "task"], [28, 30, "task"], [35, 36, "task"], [39, 40, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 6, 7, "part-of", "", false, false], [23, 25, 0, 1, "part-of", "", false, false], [28, 30, 0, 1, "part-of", "", false, false], [35, 36, 0, 1, "part-of", "", false, false], [39, 40, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Los", "MLP", "fueron", "una", "soluci\u00f3n", "de", "aprendizaje", "autom\u00e1tico", "muy", "popular", "en", "la", "d\u00e9cada", "de", "1980", ",", "encontrando", "aplicaciones", "en", "diversos", "campos", "como", "el", "reconocimiento", "del", "habla", ",", "el", "reconocimiento", "de", "im\u00e1genes", "y", "el", "software", "de", "traducci\u00f3n", "autom\u00e1tica", ",", "las", "redes", "neuronales", "."], "sentence-detokenized": "Los MLP fueron una soluci\u00f3n de aprendizaje autom\u00e1tico muy popular en la d\u00e9cada de 1980, encontrando aplicaciones en diversos campos como el reconocimiento del habla, el reconocimiento de im\u00e1genes y el software de traducci\u00f3n autom\u00e1tica, las redes neuronales.", "token2charspan": [[0, 3], [4, 7], [8, 14], [15, 18], [19, 27], [28, 30], [31, 42], [43, 53], [54, 57], [58, 65], [66, 68], [69, 71], [72, 78], [79, 81], [82, 86], [86, 87], [88, 99], [100, 112], [113, 115], [116, 124], [125, 131], [132, 136], [137, 139], [140, 154], [155, 158], [159, 164], [164, 165], [166, 168], [169, 183], [184, 186], [187, 195], [196, 197], [198, 200], [201, 209], [210, 212], [213, 223], [224, 234], [234, 235], [236, 239], [240, 245], [246, 256], [256, 257]]}
{"doc_key": "ai-test-382", "ner": [[0, 0, "researcher"], [2, 3, "misc"], [5, 7, "university"], [15, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 7, "physical", "", false, false], [0, 0, 5, 7, "role", "", false, false], [2, 3, 0, 0, "origin", "", false, false], [15, 18, 0, 0, "role", "supervised", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Allen", "se", "doctor\u00f3", "en", "la", "Universidad", "de", "Toronto", "en", "1979", ",", "bajo", "la", "supervisi\u00f3n", "de", "C", ".", "Raymond", "Perrault", ","], "sentence-detokenized": "Allen se doctor\u00f3 en la Universidad de Toronto en 1979, bajo la supervisi\u00f3n de C. Raymond Perrault,", "token2charspan": [[0, 5], [6, 8], [9, 16], [17, 19], [20, 22], [23, 34], [35, 37], [38, 45], [46, 48], [49, 53], [53, 54], [55, 59], [60, 62], [63, 74], [75, 77], [78, 79], [79, 80], [81, 88], [89, 97], [97, 98]]}
{"doc_key": "ai-test-383", "ner": [[0, 0, "product"], [5, 8, "field"], [10, 10, "product"], [12, 12, "product"], [14, 14, "product"], [22, 22, "product"], [25, 25, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 5, 8, "related-to", "supports", false, false], [10, 10, 5, 8, "type-of", "", true, false], [12, 12, 5, 8, "type-of", "", true, false], [14, 14, 5, 8, "type-of", "", true, false], [14, 14, 22, 22, "related-to", "converting_to", true, false], [25, 25, 5, 8, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["OpenCV", "admite", "algunos", "modelos", "de", "marcos", "de", "aprendizaje", "profundo", "como", "TensorFlow", ",", "Torch", ",", "PyTorch", "(", "despu\u00e9s", "de", "convertirlos", "en", "un", "modelo", "ONNX", ")", "y", "Caffe", "seg\u00fan", "una", "lista", "definida", "de", "capas", "admitidas", "."], "sentence-detokenized": "OpenCV admite algunos modelos de marcos de aprendizaje profundo como TensorFlow, Torch, PyTorch (despu\u00e9s de convertirlos en un modelo ONNX) y Caffe seg\u00fan una lista definida de capas admitidas.", "token2charspan": [[0, 6], [7, 13], [14, 21], [22, 29], [30, 32], [33, 39], [40, 42], [43, 54], [55, 63], [64, 68], [69, 79], [79, 80], [81, 86], [86, 87], [88, 95], [96, 97], [97, 104], [105, 107], [108, 120], [121, 123], [124, 126], [127, 133], [134, 138], [138, 139], [140, 141], [142, 147], [148, 153], [154, 157], [158, 163], [164, 172], [173, 175], [176, 181], [182, 191], [191, 192]]}
{"doc_key": "ai-test-384", "ner": [[2, 2, "researcher"], [8, 12, "organisation"], [14, 14, "organisation"], [21, 27, "organisation"], [30, 31, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 8, 12, "role", "", false, false], [2, 2, 21, 27, "role", "", false, false], [2, 2, 30, 31, "related-to", "lectures_in", false, false], [14, 14, 8, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Anteriormente", ",", "Christensen", "fue", "presidente", "fundador", "de", "la", "Red", "Europea", "de", "Investigaci\u00f3n", "Rob\u00f3tica", "(", "EURON", ")", "y", "conferenciante", "distinguido", "de", "la", "Sociedad", "de", "Rob\u00f3tica", "y", "Automatizaci\u00f3n", "del", "IEEE", "en", "materia", "de", "rob\u00f3tica", "."], "sentence-detokenized": "Anteriormente, Christensen fue presidente fundador de la Red Europea de Investigaci\u00f3n Rob\u00f3tica (EURON) y conferenciante distinguido de la Sociedad de Rob\u00f3tica y Automatizaci\u00f3n del IEEE en materia de rob\u00f3tica.", "token2charspan": [[0, 13], [13, 14], [15, 26], [27, 30], [31, 41], [42, 50], [51, 53], [54, 56], [57, 60], [61, 68], [69, 71], [72, 85], [86, 94], [95, 96], [96, 101], [101, 102], [103, 104], [105, 119], [120, 131], [132, 134], [135, 137], [138, 146], [147, 149], [150, 158], [159, 160], [161, 175], [176, 179], [180, 184], [185, 187], [188, 195], [196, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-test-385", "ner": [[4, 5, "field"], [7, 9, "university"], [10, 12, "location"], [14, 18, "country"], [25, 25, "misc"], [27, 27, "field"], [30, 34, "organisation"], [36, 36, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[7, 9, 10, 12, "physical", "", false, false], [10, 12, 14, 18, "physical", "", false, false], [25, 25, 27, 27, "topic", "", false, false], [30, 34, 36, 36, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Obtuvo", "su", "maestr\u00eda", "en", "matem\u00e1ticas", "en", "la", "Universidad", "Estatal", "de", "Samarcanda", ",", "Samarcanda", ",", "Rep\u00fablica", "Socialista", "Sovi\u00e9tica", "de", "Uzbekist\u00e1n", ",", "en", "1958", ",", "y", "su", "doctorado", "en", "estad\u00edstica", "en", "el", "Instituto", "de", "Ciencias", "del", "Control", ",", "Mosc\u00fa", ",", "en", "1964", "."], "sentence-detokenized": "Obtuvo su maestr\u00eda en matem\u00e1ticas en la Universidad Estatal de Samarcanda, Samarcanda, Rep\u00fablica Socialista Sovi\u00e9tica de Uzbekist\u00e1n, en 1958, y su doctorado en estad\u00edstica en el Instituto de Ciencias del Control, Mosc\u00fa, en 1964.", "token2charspan": [[0, 6], [7, 9], [10, 18], [19, 21], [22, 33], [34, 36], [37, 39], [40, 51], [52, 59], [60, 62], [63, 73], [73, 74], [75, 85], [85, 86], [87, 96], [97, 107], [108, 117], [118, 120], [121, 131], [131, 132], [133, 135], [136, 140], [140, 141], [142, 143], [144, 146], [147, 156], [157, 159], [160, 171], [172, 174], [175, 177], [178, 187], [188, 190], [191, 199], [200, 203], [204, 211], [211, 212], [213, 218], [218, 219], [220, 222], [223, 227], [227, 228]]}
{"doc_key": "ai-test-386", "ner": [[6, 6, "organisation"], [14, 15, "product"], [43, 44, "field"], [47, 50, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 43, 44, "usage", "", false, false], [6, 6, 47, 50, "usage", "", false, false], [14, 15, 6, 6, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Sin", "embargo", ",", "el", "trabajo", "de", "Cycorp", "consiste", "cada", "vez", "m\u00e1s", "en", "dotar", "al", "sistema", "Cyc", "de", "la", "capacidad", "de", "comunicarse", "con", "los", "usuarios", "finales", "en", "lenguaje", "natural", ",", "y", "de", "ayudar", "en", "el", "proceso", "de", "formaci\u00f3n", "de", "conocimientos", "en", "curso", "mediante", "el", "aprendizaje", "autom\u00e1tico", "y", "la", "comprensi\u00f3n", "del", "lenguaje", "natural", "."], "sentence-detokenized": "Sin embargo, el trabajo de Cycorp consiste cada vez m\u00e1s en dotar al sistema Cyc de la capacidad de comunicarse con los usuarios finales en lenguaje natural, y de ayudar en el proceso de formaci\u00f3n de conocimientos en curso mediante el aprendizaje autom\u00e1tico y la comprensi\u00f3n del lenguaje natural.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 23], [24, 26], [27, 33], [34, 42], [43, 47], [48, 51], [52, 55], [56, 58], [59, 64], [65, 67], [68, 75], [76, 79], [80, 82], [83, 85], [86, 95], [96, 98], [99, 110], [111, 114], [115, 118], [119, 127], [128, 135], [136, 138], [139, 147], [148, 155], [155, 156], [157, 158], [159, 161], [162, 168], [169, 171], [172, 174], [175, 182], [183, 185], [186, 195], [196, 198], [199, 212], [213, 215], [216, 221], [222, 230], [231, 233], [234, 245], [246, 256], [257, 258], [259, 261], [262, 273], [274, 277], [278, 286], [287, 294], [294, 295]]}
{"doc_key": "ai-test-387", "ner": [[68, 68, "metrics"], [71, 71, "metrics"], [74, 74, "metrics"], [76, 78, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Por", "ejemplo", ",", "si", "se", "busca", "el", "clasificador", "m\u00e1s", "adecuado", "para", "el", "problema", ",", "el", "conjunto", "de", "datos", "de", "entrenamiento", "se", "utiliza", "para", "entrenar", "a", "los", "algoritmos", "candidatos", ",", "el", "conjunto", "de", "datos", "de", "validaci\u00f3n", "se", "utiliza", "para", "comparar", "sus", "rendimientos", "y", "decidir", "con", "cu\u00e1l", "quedarse", "y", ",", "por", "\u00faltimo", ",", "el", "conjunto", "de", "datos", "de", "prueba", "se", "utiliza", "para", "obtener", "las", "caracter\u00edsticas", "de", "rendimiento", ",", "como", "la", "precisi\u00f3n", ",", "la", "sensibilidad", ",", "la", "especificidad", ",", "la", "medida", "F", ",", "etc", "."], "sentence-detokenized": "Por ejemplo, si se busca el clasificador m\u00e1s adecuado para el problema, el conjunto de datos de entrenamiento se utiliza para entrenar a los algoritmos candidatos, el conjunto de datos de validaci\u00f3n se utiliza para comparar sus rendimientos y decidir con cu\u00e1l quedarse y, por \u00faltimo, el conjunto de datos de prueba se utiliza para obtener las caracter\u00edsticas de rendimiento, como la precisi\u00f3n, la sensibilidad, la especificidad, la medida F, etc.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 18], [19, 24], [25, 27], [28, 40], [41, 44], [45, 53], [54, 58], [59, 61], [62, 70], [70, 71], [72, 74], [75, 83], [84, 86], [87, 92], [93, 95], [96, 109], [110, 112], [113, 120], [121, 125], [126, 134], [135, 136], [137, 140], [141, 151], [152, 162], [162, 163], [164, 166], [167, 175], [176, 178], [179, 184], [185, 187], [188, 198], [199, 201], [202, 209], [210, 214], [215, 223], [224, 227], [228, 240], [241, 242], [243, 250], [251, 254], [255, 259], [260, 268], [269, 270], [270, 271], [272, 275], [276, 282], [282, 283], [284, 286], [287, 295], [296, 298], [299, 304], [305, 307], [308, 314], [315, 317], [318, 325], [326, 330], [331, 338], [339, 342], [343, 358], [359, 361], [362, 373], [373, 374], [375, 379], [380, 382], [383, 392], [392, 393], [394, 396], [397, 409], [409, 410], [411, 413], [414, 427], [427, 428], [429, 431], [432, 438], [439, 440], [440, 441], [442, 445], [445, 446]]}
{"doc_key": "ai-test-388", "ner": [[1, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["El", "error", "cuadr\u00e1tico", "medio", "es", "de", "0,15", "."], "sentence-detokenized": "El error cuadr\u00e1tico medio es de 0,15.", "token2charspan": [[0, 2], [3, 8], [9, 19], [20, 25], [26, 28], [29, 31], [32, 36], [36, 37]]}
{"doc_key": "ai-test-389", "ner": [[7, 9, "misc"], [4, 4, "organisation"], [19, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 7, 9, "role", "", false, false], [19, 19, 7, 9, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["En", "1979", ",", "el", "IEEE", "organiz\u00f3", "un", "concurso", "de", "Micromouse", ",", "tal", "y", "como", "se", "muestra", "en", "la", "revista", "Spectrum", "."], "sentence-detokenized": "En 1979, el IEEE organiz\u00f3 un concurso de Micromouse, tal y como se muestra en la revista Spectrum.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 16], [17, 25], [26, 28], [29, 37], [38, 40], [41, 51], [51, 52], [53, 56], [57, 58], [59, 63], [64, 66], [67, 74], [75, 77], [78, 80], [81, 88], [89, 97], [97, 98]]}
{"doc_key": "ai-test-390", "ner": [[1, 3, "algorithm"], [10, 14, "field"], [15, 18, "task"], [21, 23, "task"], [26, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 3, 10, 14, "part-of", "", false, false], [15, 18, 10, 14, "part-of", "task_part_of_field", false, false], [21, 23, 10, 14, "part-of", "task_part_of_field", false, false], [26, 29, 10, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["El", "espacio", "de", "Gabor", "es", "muy", "\u00fatil", "en", "aplicaciones", "de", "procesamiento", "de", "im\u00e1genes", "como", "el", "reconocimiento", "\u00f3ptico", "de", "caracteres", ",", "el", "reconocimiento", "del", "iris", "y", "el", "reconocimiento", "de", "huellas", "dactilares", "."], "sentence-detokenized": "El espacio de Gabor es muy \u00fatil en aplicaciones de procesamiento de im\u00e1genes como el reconocimiento \u00f3ptico de caracteres, el reconocimiento del iris y el reconocimiento de huellas dactilares.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 19], [20, 22], [23, 26], [27, 31], [32, 34], [35, 47], [48, 50], [51, 64], [65, 67], [68, 76], [77, 81], [82, 84], [85, 99], [100, 106], [107, 109], [110, 120], [120, 121], [122, 124], [125, 139], [140, 143], [144, 148], [149, 150], [151, 153], [154, 168], [169, 171], [172, 179], [180, 190], [190, 191]]}
{"doc_key": "ai-test-391", "ner": [[7, 7, "programlang"], [9, 9, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["o", "mediante", "interfaces", "de", "alto", "nivel", "con", "Java", "y", "Tcl", "."], "sentence-detokenized": "o mediante interfaces de alto nivel con Java y Tcl.", "token2charspan": [[0, 1], [2, 10], [11, 21], [22, 24], [25, 29], [30, 35], [36, 39], [40, 44], [45, 46], [47, 50], [50, 51]]}
{"doc_key": "ai-test-392", "ner": [[14, 16, "algorithm"], [25, 25, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 16, 25, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["En", "investigaciones", "recientes", ",", "los", "m\u00e9todos", "basados", "en", "n\u00facleos", ",", "como", "las", "m\u00e1quinas", "de", "vectores", "de", "apoyo", ",", "han", "mostrado", "un", "rendimiento", "superior", "en", "la", "supervisi\u00f3n", "."], "sentence-detokenized": "En investigaciones recientes, los m\u00e9todos basados en n\u00facleos, como las m\u00e1quinas de vectores de apoyo, han mostrado un rendimiento superior en la supervisi\u00f3n.", "token2charspan": [[0, 2], [3, 18], [19, 28], [28, 29], [30, 33], [34, 41], [42, 49], [50, 52], [53, 60], [60, 61], [62, 66], [67, 70], [71, 79], [80, 82], [83, 91], [92, 94], [95, 100], [100, 101], [102, 105], [106, 114], [115, 117], [118, 129], [130, 138], [139, 141], [142, 144], [145, 156], [156, 157]]}
{"doc_key": "ai-test-393", "ner": [[18, 19, "misc"], [26, 26, "researcher"], [28, 28, "researcher"], [36, 36, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[26, 26, 36, 36, "usage", "", false, false], [28, 28, 36, 36, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Para", "ilustrar", "los", "principios", "b\u00e1sicos", "del", "embolsamiento", ",", "a", "continuaci\u00f3n", "se", "presenta", "un", "an\u00e1lisis", "sobre", "la", "relaci\u00f3n", "entre", "el", "ozono", "y", "la", "temperatura", "(", "datos", "de", "Rousseeuw", "y", "Leroy", "(", "1986", ")", ",", "an\u00e1lisis", "realizado", "en", "R", ")", "."], "sentence-detokenized": "Para ilustrar los principios b\u00e1sicos del embolsamiento, a continuaci\u00f3n se presenta un an\u00e1lisis sobre la relaci\u00f3n entre el ozono y la temperatura (datos de Rousseeuw y Leroy (1986), an\u00e1lisis realizado en R).", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 28], [29, 36], [37, 40], [41, 54], [54, 55], [56, 57], [58, 70], [71, 73], [74, 82], [83, 85], [86, 94], [95, 100], [101, 103], [104, 112], [113, 118], [119, 121], [122, 127], [128, 129], [130, 132], [133, 144], [145, 146], [146, 151], [152, 154], [155, 164], [165, 166], [167, 172], [173, 174], [174, 178], [178, 179], [179, 180], [181, 189], [190, 199], [200, 202], [203, 204], [204, 205], [205, 206]]}
{"doc_key": "ai-test-394", "ner": [[0, 1, "organisation"], [13, 16, "product"], [22, 23, "product"], [25, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 16, 0, 1, "artifact", "", false, false], [22, 23, 0, 1, "artifact", "", false, false], [25, 27, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Denso", "Wave", "es", "una", "filial", "que", "fabrica", "productos", "de", "identificaci\u00f3n", "autom\u00e1tica", "(", "lectores", "de", "c\u00f3digos", "de", "barras", "y", "productos", "relacionados", ")", ",", "robots", "industriales", "y", "controladores", "l\u00f3gicos", "programables", "."], "sentence-detokenized": "Denso Wave es una filial que fabrica productos de identificaci\u00f3n autom\u00e1tica (lectores de c\u00f3digos de barras y productos relacionados), robots industriales y controladores l\u00f3gicos programables.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 17], [18, 24], [25, 28], [29, 36], [37, 46], [47, 49], [50, 64], [65, 75], [76, 77], [77, 85], [86, 88], [89, 96], [97, 99], [100, 106], [107, 108], [109, 118], [119, 131], [131, 132], [132, 133], [134, 140], [141, 153], [154, 155], [156, 169], [170, 177], [178, 190], [190, 191]]}
{"doc_key": "ai-test-395", "ner": [[2, 6, "metrics"], [11, 13, "metrics"], [26, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 6, 26, 27, "compare", "", false, false], [11, 13, 2, 6, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Mientras", "que", "el", "estudio", "de", "evaluaci\u00f3n", "biling\u00fce", "se", "limita", "a", "calcular", "la", "precisi\u00f3n", "de", "los", "ngranos", "a\u00f1adiendo", "el", "mismo", "peso", "a", "cada", "uno", "de", "ellos", ",", "el", "NIST", "tambi\u00e9n", "calcula", "el", "grado", "de", "informaci\u00f3n", "de", "un", "ngrano", "concreto", "."], "sentence-detokenized": "Mientras que el estudio de evaluaci\u00f3n biling\u00fce se limita a calcular la precisi\u00f3n de los ngranos a\u00f1adiendo el mismo peso a cada uno de ellos, el NIST tambi\u00e9n calcula el grado de informaci\u00f3n de un ngrano concreto.", "token2charspan": [[0, 8], [9, 12], [13, 15], [16, 23], [24, 26], [27, 37], [38, 46], [47, 49], [50, 56], [57, 58], [59, 67], [68, 70], [71, 80], [81, 83], [84, 87], [88, 95], [96, 105], [106, 108], [109, 114], [115, 119], [120, 121], [122, 126], [127, 130], [131, 133], [134, 139], [139, 140], [141, 143], [144, 148], [149, 156], [157, 164], [165, 167], [168, 173], [174, 176], [177, 188], [189, 191], [192, 194], [195, 201], [202, 210], [210, 211]]}
{"doc_key": "ai-test-396", "ner": [[18, 18, "algorithm"], [21, 22, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["En", "particular", ",", "se", "utilizan", "durante", "el", "c\u00e1lculo", "de", "la", "probabilidad", "de", "un", "\u00e1rbol", "(", "en", "los", "enfoques", "bayesiano", "y", "de", "m\u00e1xima", "probabilidad", "para", "la", "estimaci\u00f3n", "de", "\u00e1rboles", ")", "y", "se", "utilizan", "para", "estimar", "la", "distancia", "evolutiva", "entre", "secuencias", "a", "partir", "de", "las", "diferencias", "observadas", "entre", "las", "secuencias", "."], "sentence-detokenized": "En particular, se utilizan durante el c\u00e1lculo de la probabilidad de un \u00e1rbol (en los enfoques bayesiano y de m\u00e1xima probabilidad para la estimaci\u00f3n de \u00e1rboles) y se utilizan para estimar la distancia evolutiva entre secuencias a partir de las diferencias observadas entre las secuencias.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 17], [18, 26], [27, 34], [35, 37], [38, 45], [46, 48], [49, 51], [52, 64], [65, 67], [68, 70], [71, 76], [77, 78], [78, 80], [81, 84], [85, 93], [94, 103], [104, 105], [106, 108], [109, 115], [116, 128], [129, 133], [134, 136], [137, 147], [148, 150], [151, 158], [158, 159], [160, 161], [162, 164], [165, 173], [174, 178], [179, 186], [187, 189], [190, 199], [200, 209], [210, 215], [216, 226], [227, 228], [229, 235], [236, 238], [239, 242], [243, 254], [255, 265], [266, 271], [272, 275], [276, 286], [286, 287]]}
{"doc_key": "ai-test-397", "ner": [[1, 3, "conference"], [27, 28, "misc"], [30, 30, "misc"], [62, 63, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[30, 30, 27, 28, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["La", "Audio", "Engineering", "Society", "recomienda", "una", "frecuencia", "de", "muestreo", "de", "48", "kHz", "para", "la", "mayor\u00eda", "de", "las", "aplicaciones", ",", "pero", "reconoce", "la", "de", "44,1", "kHz", "para", "los", "discos", "compactos", "(", "CD", ")", "y", "otros", "usos", "de", "consumo", ",", "la", "de", "32", "kHz", "para", "las", "aplicaciones", "relacionadas", "con", "la", "transmisi\u00f3n", "y", "la", "de", "96", "kHz", "para", "un", "mayor", "ancho", "de", "banda", "o", "un", "filtro", "antialiasing", "relajado", "."], "sentence-detokenized": "La Audio Engineering Society recomienda una frecuencia de muestreo de 48 kHz para la mayor\u00eda de las aplicaciones, pero reconoce la de 44,1 kHz para los discos compactos (CD) y otros usos de consumo, la de 32 kHz para las aplicaciones relacionadas con la transmisi\u00f3n y la de 96 kHz para un mayor ancho de banda o un filtro antialiasing relajado.", "token2charspan": [[0, 2], [3, 8], [9, 20], [21, 28], [29, 39], [40, 43], [44, 54], [55, 57], [58, 66], [67, 69], [70, 72], [73, 76], [77, 81], [82, 84], [85, 92], [93, 95], [96, 99], [100, 112], [112, 113], [114, 118], [119, 127], [128, 130], [131, 133], [134, 138], [139, 142], [143, 147], [148, 151], [152, 158], [159, 168], [169, 170], [170, 172], [172, 173], [174, 175], [176, 181], [182, 186], [187, 189], [190, 197], [197, 198], [199, 201], [202, 204], [205, 207], [208, 211], [212, 216], [217, 220], [221, 233], [234, 246], [247, 250], [251, 253], [254, 265], [266, 267], [268, 270], [271, 273], [274, 276], [277, 280], [281, 285], [286, 288], [289, 294], [295, 300], [301, 303], [304, 309], [310, 311], [312, 314], [315, 321], [322, 334], [335, 343], [343, 344]]}
{"doc_key": "ai-test-398", "ner": [[12, 12, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Se", "han", "realizado", "recursos", "para", "la", "afectividad", "de", "palabras", "y", "conceptos", "para", "WordNet", "{", "{", "cite", "journal"], "sentence-detokenized": "Se han realizado recursos para la afectividad de palabras y conceptos para WordNet {{cite journal", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 25], [26, 30], [31, 33], [34, 45], [46, 48], [49, 57], [58, 59], [60, 69], [70, 74], [75, 82], [83, 84], [84, 85], [85, 89], [90, 97]]}
{"doc_key": "ai-test-399", "ner": [[1, 2, "misc"], [22, 23, "person"], [28, 30, "person"], [35, 37, "person"], [43, 44, "organisation"], [62, 65, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[28, 30, 35, 37, "role", "acts_in", false, false], [43, 44, 35, 37, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["En", "anaglifo", "rojo-verde", ",", "se", "presentaron", "al", "p\u00fablico", "tres", "bobinas", "de", "pruebas", ",", "que", "inclu\u00edan", "escenas", "rurales", ",", "tomas", "de", "prueba", "de", "Marie", "Doro", ",", "un", "segmento", "de", "John", "B.", "Mason", "interpretando", "varios", "pasajes", "de", "Jim", "the", "Penman", "(", "una", "pel\u00edcula", "estrenada", "por", "Famous", "Players-Lasky", "ese", "a\u00f1o", ",", "pero", "no", "en", "3D", ")", ",", "bailarinas", "orientales", "y", "una", "bobina", "de", "im\u00e1genes", "de", "las", "cataratas", "del", "Ni\u00e1gara", "."], "sentence-detokenized": "En anaglifo rojo-verde, se presentaron al p\u00fablico tres bobinas de pruebas, que inclu\u00edan escenas rurales, tomas de prueba de Marie Doro, un segmento de John B. Mason interpretando varios pasajes de Jim the Penman (una pel\u00edcula estrenada por Famous Players-Lasky ese a\u00f1o, pero no en 3D), bailarinas orientales y una bobina de im\u00e1genes de las cataratas del Ni\u00e1gara.", "token2charspan": [[0, 2], [3, 11], [12, 22], [22, 23], [24, 26], [27, 38], [39, 41], [42, 49], [50, 54], [55, 62], [63, 65], [66, 73], [73, 74], [75, 78], [79, 87], [88, 95], [96, 103], [103, 104], [105, 110], [111, 113], [114, 120], [121, 123], [124, 129], [130, 134], [134, 135], [136, 138], [139, 147], [148, 150], [151, 155], [156, 158], [159, 164], [165, 178], [179, 185], [186, 193], [194, 196], [197, 200], [201, 204], [205, 211], [212, 213], [213, 216], [217, 225], [226, 235], [236, 239], [240, 246], [247, 260], [261, 264], [265, 268], [268, 269], [270, 274], [275, 277], [278, 280], [281, 283], [283, 284], [284, 285], [286, 296], [297, 307], [308, 309], [310, 313], [314, 320], [321, 323], [324, 332], [333, 335], [336, 339], [340, 349], [350, 353], [354, 361], [361, 362]]}
{"doc_key": "ai-test-400", "ner": [[8, 11, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Esta", "es", "una", "forma", "particular", "de", "implementar", "la", "estimaci\u00f3n", "de", "m\u00e1xima", "verosimilitud", "para", "este", "problema", "."], "sentence-detokenized": "Esta es una forma particular de implementar la estimaci\u00f3n de m\u00e1xima verosimilitud para este problema.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 17], [18, 28], [29, 31], [32, 43], [44, 46], [47, 57], [58, 60], [61, 67], [68, 81], [82, 86], [87, 91], [92, 100], [100, 101]]}
{"doc_key": "ai-test-401", "ner": [[0, 4, "product"], [18, 18, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Servidores", "web", "de", "f\u00e1cil", "rastreo", ",", "e", "integra", "las", "caracter\u00edsticas", "de", "los", "mapas", "de", "sitio", "y", "los", "canales", "RSS", "en", "un", "mecanismo", "descentralizado", "para", "que", "los", "bi\u00f3logos", "computacionales", "y", "los", "bioinform\u00e1ticos", "difundan", "y", "recuperen", "abiertamente", "metadatos", "sobre", "recursos", "biom\u00e9dicos", "."], "sentence-detokenized": "Servidores web de f\u00e1cil rastreo, e integra las caracter\u00edsticas de los mapas de sitio y los canales RSS en un mecanismo descentralizado para que los bi\u00f3logos computacionales y los bioinform\u00e1ticos difundan y recuperen abiertamente metadatos sobre recursos biom\u00e9dicos.", "token2charspan": [[0, 10], [11, 14], [15, 17], [18, 23], [24, 31], [31, 32], [33, 34], [35, 42], [43, 46], [47, 62], [63, 65], [66, 69], [70, 75], [76, 78], [79, 84], [85, 86], [87, 90], [91, 98], [99, 102], [103, 105], [106, 108], [109, 118], [119, 134], [135, 139], [140, 143], [144, 147], [148, 156], [157, 172], [173, 174], [175, 178], [179, 194], [195, 203], [204, 205], [206, 215], [216, 228], [229, 238], [239, 244], [245, 253], [254, 264], [264, 265]]}
{"doc_key": "ai-test-402", "ner": [[3, 12, "misc"], [15, 23, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Est\u00e1", "cubierta", "por", "la", "norma", "Z39.50", "del", "American", "National", "Standards", "Institute", "/", "NISO", ",", "y", "la", "norma", "23950", "de", "la", "Organizaci\u00f3n", "Internacional", "de", "Normalizaci\u00f3n", "."], "sentence-detokenized": "Est\u00e1 cubierta por la norma Z39.50 del American National Standards Institute / NISO, y la norma 23950 de la Organizaci\u00f3n Internacional de Normalizaci\u00f3n.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 20], [21, 26], [27, 33], [34, 37], [38, 46], [47, 55], [56, 65], [66, 75], [76, 77], [78, 82], [82, 83], [84, 85], [86, 88], [89, 94], [95, 100], [101, 103], [104, 106], [107, 119], [120, 133], [134, 136], [137, 150], [150, 151]]}
{"doc_key": "ai-test-403", "ner": [[14, 18, "misc"], [24, 25, "metrics"], [29, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["El", "codificador", "y", "el", "decodificador", "se", "entrenan", "para", "tomar", "una", "frase", "y", "reproducir", "la", "distribuci\u00f3n", "de", "un", "solo", "golpe", "de", "una", "par\u00e1frasis", "correspondiente", "minimizando", "la", "perplejidad", "mediante", "un", "simple", "descenso", "de", "gradiente", "estoc\u00e1stico", "."], "sentence-detokenized": "El codificador y el decodificador se entrenan para tomar una frase y reproducir la distribuci\u00f3n de un solo golpe de una par\u00e1frasis correspondiente minimizando la perplejidad mediante un simple descenso de gradiente estoc\u00e1stico.", "token2charspan": [[0, 2], [3, 14], [15, 16], [17, 19], [20, 33], [34, 36], [37, 45], [46, 50], [51, 56], [57, 60], [61, 66], [67, 68], [69, 79], [80, 82], [83, 95], [96, 98], [99, 101], [102, 106], [107, 112], [113, 115], [116, 119], [120, 130], [131, 146], [147, 158], [159, 161], [162, 173], [174, 182], [183, 185], [186, 192], [193, 201], [202, 204], [205, 214], [215, 226], [226, 227]]}
{"doc_key": "ai-test-404", "ner": [[7, 9, "field"], [12, 15, "task"], [18, 23, "task"], [39, 47, "task"], [50, 56, "task"], [59, 68, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 15, 7, 9, "part-of", "task_part_of_field", false, false], [18, 23, 7, 9, "part-of", "task_part_of_field", false, false], [39, 47, 7, 9, "part-of", "task_part_of_field", false, false], [50, 56, 7, 9, "part-of", "task_part_of_field", false, false], [59, 68, 7, 9, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Otras", "aplicaciones", "t\u00edpicas", "de", "las", "t\u00e9cnicas", "de", "reconocimiento", "de", "patrones", "son", "el", "reconocimiento", "autom\u00e1tico", "del", "habla", ",", "la", "clasificaci\u00f3n", "del", "texto", "en", "varias", "categor\u00edas", "(", "por", "ejemplo", ",", "mensajes", "de", "correo", "electr\u00f3nico", "spam", "/", "no", "spam", ")", ",", "el", "reconocimiento", "de", "la", "escritura", "a", "mano", "en", "sobres", "postales", ",", "el", "reconocimiento", "autom\u00e1tico", "de", "im\u00e1genes", "de", "rostros", "humanos", "o", "la", "extracci\u00f3n", "de", "im\u00e1genes", "de", "escritura", "a", "mano", "de", "formularios", "m\u00e9dicos", "."], "sentence-detokenized": "Otras aplicaciones t\u00edpicas de las t\u00e9cnicas de reconocimiento de patrones son el reconocimiento autom\u00e1tico del habla, la clasificaci\u00f3n del texto en varias categor\u00edas (por ejemplo, mensajes de correo electr\u00f3nico spam / no spam), el reconocimiento de la escritura a mano en sobres postales, el reconocimiento autom\u00e1tico de im\u00e1genes de rostros humanos o la extracci\u00f3n de im\u00e1genes de escritura a mano de formularios m\u00e9dicos.", "token2charspan": [[0, 5], [6, 18], [19, 26], [27, 29], [30, 33], [34, 42], [43, 45], [46, 60], [61, 63], [64, 72], [73, 76], [77, 79], [80, 94], [95, 105], [106, 109], [110, 115], [115, 116], [117, 119], [120, 133], [134, 137], [138, 143], [144, 146], [147, 153], [154, 164], [165, 166], [166, 169], [170, 177], [177, 178], [179, 187], [188, 190], [191, 197], [198, 209], [210, 214], [215, 216], [217, 219], [220, 224], [224, 225], [225, 226], [227, 229], [230, 244], [245, 247], [248, 250], [251, 260], [261, 262], [263, 267], [268, 270], [271, 277], [278, 286], [286, 287], [288, 290], [291, 305], [306, 316], [317, 319], [320, 328], [329, 331], [332, 339], [340, 347], [348, 349], [350, 352], [353, 363], [364, 366], [367, 375], [376, 378], [379, 388], [389, 390], [391, 395], [396, 398], [399, 410], [411, 418], [418, 419]]}
{"doc_key": "ai-test-405", "ner": [[0, 4, "algorithm"], [12, 15, "field"], [18, 20, "task"], [23, 24, "task"], [27, 30, "task"], [32, 38, "task"], [41, 42, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 15, 0, 4, "usage", "", false, false], [18, 20, 0, 4, "usage", "", false, false], [23, 24, 0, 4, "usage", "", false, false], [27, 30, 0, 4, "usage", "", false, false], [32, 38, 0, 4, "usage", "", false, false], [41, 42, 0, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Las", "redes", "neuronales", "artificiales", "se", "han", "utilizado", "en", "diversas", "tareas", ",", "como", "la", "visi\u00f3n", "por", "ordenador", ",", "el", "reconocimiento", "del", "habla", ",", "la", "traducci\u00f3n", "autom\u00e1tica", ",", "el", "filtrado", "de", "redes", "sociales", ",", "los", "juegos", "de", "mesa", "y", "los", "videojuegos", "y", "el", "diagn\u00f3stico", "m\u00e9dico", "."], "sentence-detokenized": "Las redes neuronales artificiales se han utilizado en diversas tareas, como la visi\u00f3n por ordenador, el reconocimiento del habla, la traducci\u00f3n autom\u00e1tica, el filtrado de redes sociales, los juegos de mesa y los videojuegos y el diagn\u00f3stico m\u00e9dico.", "token2charspan": [[0, 3], [4, 9], [10, 20], [21, 33], [34, 36], [37, 40], [41, 50], [51, 53], [54, 62], [63, 69], [69, 70], [71, 75], [76, 78], [79, 85], [86, 89], [90, 99], [99, 100], [101, 103], [104, 118], [119, 122], [123, 128], [128, 129], [130, 132], [133, 143], [144, 154], [154, 155], [156, 158], [159, 167], [168, 170], [171, 176], [177, 185], [185, 186], [187, 190], [191, 197], [198, 200], [201, 205], [206, 207], [208, 211], [212, 223], [224, 225], [226, 228], [229, 240], [241, 247], [247, 248]]}
{"doc_key": "ai-test-406", "ner": [[3, 4, "organisation"], [5, 5, "product"], [19, 19, "product"], [22, 22, "organisation"], [23, 24, "product"], [26, 26, "product"], [28, 30, "product"], [32, 32, "product"], [34, 34, "programlang"], [45, 46, "field"], [53, 55, "product"], [57, 57, "algorithm"], [59, 59, "algorithm"], [61, 61, "algorithm"], [64, 64, "product"], [69, 71, "task"], [83, 85, "algorithm"], [88, 88, "product"], [90, 90, "product"], [96, 98, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "relations": [[5, 5, 3, 4, "origin", "", false, false], [5, 5, 19, 19, "named", "same", false, false], [5, 5, 53, 55, "named", "same", false, false], [34, 34, 45, 46, "related-to", "used_for", false, false], [57, 57, 34, 34, "part-of", "", true, false], [57, 57, 53, 55, "origin", "", true, false], [59, 59, 34, 34, "part-of", "", true, false], [59, 59, 53, 55, "origin", "", true, false], [61, 61, 34, 34, "part-of", "", true, false], [61, 61, 53, 55, "origin", "", true, false], [64, 64, 69, 71, "related-to", "used_for", false, false], [83, 85, 64, 64, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Algunos", "ejemplos", "son", "Salford", "Systems", "CART", "(", "que", "tiene", "la", "licencia", "del", "c\u00f3digo", "propietario", "de", "los", "autores", "originales", "de", "CART", ")", ",", "IBM", "SPSS", "Modeler", ",", "RapidMiner", ",", "SAS", "Enterprise", "Miner", ",", "Matlab", ",", "R", "(", "un", "entorno", "de", "software", "de", "c\u00f3digo", "abierto", "para", "la", "computaci\u00f3n", "estad\u00edstica", ",", "que", "incluye", "varias", "implementaciones", "de", "CART", "como", "los", "paquetes", "rpart", ",", "party", "y", "randomForest", ")", ",", "Weka", "(", "una", "suite", "de", "miner\u00eda", "de", "datos", "gratuita", "y", "de", "c\u00f3digo", "abierto", ",", "que", "contiene", "muchos", "algoritmos", "de", "\u00e1rboles", "de", "decisi\u00f3n", ")", ",", "Orange", ",", "KNIME", ",", "el", "lenguaje", "de", "programaci\u00f3n", "Microsoft", "SQL", "Server", ")", "."], "sentence-detokenized": "Algunos ejemplos son Salford Systems CART (que tiene la licencia del c\u00f3digo propietario de los autores originales de CART), IBM SPSS Modeler, RapidMiner, SAS Enterprise Miner, Matlab, R (un entorno de software de c\u00f3digo abierto para la computaci\u00f3n estad\u00edstica, que incluye varias implementaciones de CART como los paquetes rpart, party y randomForest), Weka (una suite de miner\u00eda de datos gratuita y de c\u00f3digo abierto, que contiene muchos algoritmos de \u00e1rboles de decisi\u00f3n), Orange, KNIME, el lenguaje de programaci\u00f3n Microsoft SQL Server).", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 28], [29, 36], [37, 41], [42, 43], [43, 46], [47, 52], [53, 55], [56, 64], [65, 68], [69, 75], [76, 87], [88, 90], [91, 94], [95, 102], [103, 113], [114, 116], [117, 121], [121, 122], [122, 123], [124, 127], [128, 132], [133, 140], [140, 141], [142, 152], [152, 153], [154, 157], [158, 168], [169, 174], [174, 175], [176, 182], [182, 183], [184, 185], [186, 187], [187, 189], [190, 197], [198, 200], [201, 209], [210, 212], [213, 219], [220, 227], [228, 232], [233, 235], [236, 247], [248, 259], [259, 260], [261, 264], [265, 272], [273, 279], [280, 296], [297, 299], [300, 304], [305, 309], [310, 313], [314, 322], [323, 328], [328, 329], [330, 335], [336, 337], [338, 350], [350, 351], [351, 352], [353, 357], [358, 359], [359, 362], [363, 368], [369, 371], [372, 379], [380, 382], [383, 388], [389, 397], [398, 399], [400, 402], [403, 409], [410, 417], [417, 418], [419, 422], [423, 431], [432, 438], [439, 449], [450, 452], [453, 460], [461, 463], [464, 472], [472, 473], [473, 474], [475, 481], [481, 482], [483, 488], [488, 489], [490, 492], [493, 501], [502, 504], [505, 517], [518, 527], [528, 531], [532, 538], [538, 539], [539, 540]]}
{"doc_key": "ai-test-407", "ner": [[0, 3, "algorithm"], [5, 5, "algorithm"], [13, 14, "researcher"], [17, 20, "university"], [23, 24, "researcher"], [27, 30, "organisation"], [32, 32, "organisation"], [41, 43, "researcher"], [45, 47, "researcher"], [50, 54, "organisation"], [71, 75, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 3, 13, 14, "origin", "", false, false], [0, 3, 23, 24, "origin", "", false, false], [0, 3, 41, 43, "origin", "", false, false], [0, 3, 45, 47, "origin", "", false, false], [5, 5, 0, 3, "named", "", false, false], [13, 14, 17, 20, "physical", "", false, false], [13, 14, 17, 20, "role", "", false, false], [23, 24, 27, 30, "physical", "", false, false], [23, 24, 27, 30, "role", "", false, false], [32, 32, 27, 30, "named", "", false, false], [41, 43, 50, 54, "physical", "", false, false], [41, 43, 50, 54, "role", "", false, false], [45, 47, 50, 54, "physical", "", false, false], [45, 47, 50, 54, "role", "", false, false], [71, 75, 0, 3, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["La", "codificaci\u00f3n", "predictiva", "lineal", "(", "LPC", ")", "fue", "desarrollada", "por", "primera", "vez", "por", "Fumitada", "Itakura", ",", "de", "la", "Universidad", "de", "Nagoya", ",", "y", "Shuzo", "Saito", ",", "de", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", ",", "en", "1966", ",", "y", "posteriormente", "por", "Bishnu", "S.", "Atal", "y", "Manfred", "R.", "Schroeder", ",", "de", "los", "Laboratorios", "Bell", ",", "a", "principios", "y", "mediados", "de", "la", "d\u00e9cada", "de", "1970", ",", "convirti\u00e9ndose", "en", "la", "base", "de", "los", "primeros", "chips", "DSP", "sintetizadores", "de", "voz", "a", "finales", "de", "la", "misma", "."], "sentence-detokenized": "La codificaci\u00f3n predictiva lineal (LPC) fue desarrollada por primera vez por Fumitada Itakura, de la Universidad de Nagoya, y Shuzo Saito, de Nippon Telegraph and Telephone (NTT), en 1966, y posteriormente por Bishnu S. Atal y Manfred R. Schroeder, de los Laboratorios Bell, a principios y mediados de la d\u00e9cada de 1970, convirti\u00e9ndose en la base de los primeros chips DSP sintetizadores de voz a finales de la misma.", "token2charspan": [[0, 2], [3, 15], [16, 26], [27, 33], [34, 35], [35, 38], [38, 39], [40, 43], [44, 56], [57, 60], [61, 68], [69, 72], [73, 76], [77, 85], [86, 93], [93, 94], [95, 97], [98, 100], [101, 112], [113, 115], [116, 122], [122, 123], [124, 125], [126, 131], [132, 137], [137, 138], [139, 141], [142, 148], [149, 158], [159, 162], [163, 172], [173, 174], [174, 177], [177, 178], [178, 179], [180, 182], [183, 187], [187, 188], [189, 190], [191, 205], [206, 209], [210, 216], [217, 219], [220, 224], [225, 226], [227, 234], [235, 237], [238, 247], [247, 248], [249, 251], [252, 255], [256, 268], [269, 273], [273, 274], [275, 276], [277, 287], [288, 289], [290, 298], [299, 301], [302, 304], [305, 311], [312, 314], [315, 319], [319, 320], [321, 335], [336, 338], [339, 341], [342, 346], [347, 349], [350, 353], [354, 362], [363, 368], [369, 372], [373, 387], [388, 390], [391, 394], [395, 396], [397, 404], [405, 407], [408, 410], [411, 416], [416, 417]]}
{"doc_key": "ai-test-408", "ner": [[0, 2, "metrics"], [8, 8, "metrics"], [11, 11, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 0, 2, "part-of", "", false, false], [11, 11, 0, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "puntuaci\u00f3n", "F", "es", "una", "combinaci\u00f3n", "de", "la", "precisi\u00f3n", "y", "la", "recuperaci\u00f3n", ",", "que", "proporciona", "una", "\u00fanica", "puntuaci\u00f3n", "."], "sentence-detokenized": "La puntuaci\u00f3n F es una combinaci\u00f3n de la precisi\u00f3n y la recuperaci\u00f3n, que proporciona una \u00fanica puntuaci\u00f3n.", "token2charspan": [[0, 2], [3, 13], [14, 15], [16, 18], [19, 22], [23, 34], [35, 37], [38, 40], [41, 50], [51, 52], [53, 55], [56, 68], [68, 69], [70, 73], [74, 85], [86, 89], [90, 95], [96, 106], [106, 107]]}
{"doc_key": "ai-test-409", "ner": [[3, 5, "field"], [12, 18, "task"], [23, 27, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 18, 3, 5, "part-of", "task_part_of_field", false, false], [23, 27, 3, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Las", "tareas", "de", "an\u00e1lisis", "de", "im\u00e1genes", "pueden", "ser", "tan", "sencillas", "como", "la", "lectura", "de", "etiquetas", "con", "c\u00f3digos", "de", "barras", "o", "tan", "sofisticadas", "como", "un", "sistema", "de", "reconocimiento", "facial", "."], "sentence-detokenized": "Las tareas de an\u00e1lisis de im\u00e1genes pueden ser tan sencillas como la lectura de etiquetas con c\u00f3digos de barras o tan sofisticadas como un sistema de reconocimiento facial.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 22], [23, 25], [26, 34], [35, 41], [42, 45], [46, 49], [50, 59], [60, 64], [65, 67], [68, 75], [76, 78], [79, 88], [89, 92], [93, 100], [101, 103], [104, 110], [111, 112], [113, 116], [117, 129], [130, 134], [135, 137], [138, 145], [146, 148], [149, 163], [164, 170], [170, 171]]}
{"doc_key": "ai-test-410", "ner": [[4, 9, "algorithm"], [27, 29, "algorithm"], [37, 40, "algorithm"], [45, 45, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[37, 40, 27, 29, "type-of", "", false, false], [45, 45, 37, 40, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["El", "caso", "especial", "de", "las", "m\u00e1quinas", "lineales", "de", "vectores", "soporte", "puede", "ser", "resuelto", "m\u00e1s", "eficientemente", "por", "el", "mismo", "tipo", "de", "algoritmos", "para", "optimizar", "su", "primo", "cercano", ",", "la", "regresi\u00f3n", "log\u00edstica", ";", "esta", "clase", "de", "algoritmos", "incluye", "el", "descenso", "de", "gradiente", "estoc\u00e1stico", "(", "por", "ejemplo", ",", "PEGASOS", ")", "."], "sentence-detokenized": "El caso especial de las m\u00e1quinas lineales de vectores soporte puede ser resuelto m\u00e1s eficientemente por el mismo tipo de algoritmos para optimizar su primo cercano, la regresi\u00f3n log\u00edstica; esta clase de algoritmos incluye el descenso de gradiente estoc\u00e1stico (por ejemplo, PEGASOS).", "token2charspan": [[0, 2], [3, 7], [8, 16], [17, 19], [20, 23], [24, 32], [33, 41], [42, 44], [45, 53], [54, 61], [62, 67], [68, 71], [72, 80], [81, 84], [85, 99], [100, 103], [104, 106], [107, 112], [113, 117], [118, 120], [121, 131], [132, 136], [137, 146], [147, 149], [150, 155], [156, 163], [163, 164], [165, 167], [168, 177], [178, 187], [187, 188], [189, 193], [194, 199], [200, 202], [203, 213], [214, 221], [222, 224], [225, 233], [234, 236], [237, 246], [247, 258], [259, 260], [260, 263], [264, 271], [271, 272], [273, 280], [280, 281], [281, 282]]}
{"doc_key": "ai-test-411", "ner": [[5, 5, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Cuando", "se", "le", "pregunta", "a", "Siri", "en", "un", "dispositivo", "iOS", "\u00bf", "Tienes", "una", "mascota", "?", ",", "una", "de", "las", "respuestas", "es", "Sol\u00eda", "tener", "un", "AIBO", "."], "sentence-detokenized": "Cuando se le pregunta a Siri en un dispositivo iOS \u00bfTienes una mascota?, una de las respuestas es Sol\u00eda tener un AIBO.", "token2charspan": [[0, 6], [7, 9], [10, 12], [13, 21], [22, 23], [24, 28], [29, 31], [32, 34], [35, 46], [47, 50], [51, 52], [52, 58], [59, 62], [63, 70], [70, 71], [71, 72], [73, 76], [77, 79], [80, 83], [84, 94], [95, 97], [98, 103], [104, 109], [110, 112], [113, 117], [117, 118]]}
{"doc_key": "ai-test-412", "ner": [[2, 4, "task"], [7, 9, "metrics"], [12, 12, "metrics"], [15, 17, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 9, 2, 4, "part-of", "", false, false], [12, 12, 7, 9, "named", "", false, false], [15, 17, 2, 4, "part-of", "", false, false], [19, 19, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["En", "la", "recuperaci\u00f3n", "de", "informaci\u00f3n", ",", "el", "valor", "predictivo", "positivo", "se", "llama", "precisi\u00f3n", ",", "y", "la", "sensibilidad", "se", "llama", "recuerdo", "."], "sentence-detokenized": "En la recuperaci\u00f3n de informaci\u00f3n, el valor predictivo positivo se llama precisi\u00f3n, y la sensibilidad se llama recuerdo.", "token2charspan": [[0, 2], [3, 5], [6, 18], [19, 21], [22, 33], [33, 34], [35, 37], [38, 43], [44, 54], [55, 63], [64, 66], [67, 72], [73, 82], [82, 83], [84, 85], [86, 88], [89, 101], [102, 104], [105, 110], [111, 119], [119, 120]]}
{"doc_key": "ai-test-413", "ner": [[11, 13, "field"], [15, 15, "task"], [17, 17, "task"], [19, 21, "task"], [39, 41, "task"], [44, 45, "task"], [48, 53, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 15, 11, 13, "part-of", "task_part_of_field", false, false], [17, 17, 11, 13, "part-of", "task_part_of_field", false, false], [19, 21, 11, 13, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["En", "particular", ",", "su", "investigaci\u00f3n", "se", "centr\u00f3", "en", "\u00e1reas", "como", "la", "miner\u00eda", "de", "textos", "(", "extracci\u00f3n", ",", "categorizaci\u00f3n", ",", "detecci\u00f3n", "de", "novedades", ")", "y", "en", "nuevos", "marcos", "te\u00f3ricos", "como", "una", "teor\u00eda", "unificada", "basada", "en", "la", "utilidad", "que", "une", "la", "recuperaci\u00f3n", "de", "informaci\u00f3n", ",", "el", "resumen", "autom\u00e1tico", ",", "la", "respuesta", "a", "preguntas", "de", "texto", "libre", "y", "tareas", "relacionadas", "."], "sentence-detokenized": "En particular, su investigaci\u00f3n se centr\u00f3 en \u00e1reas como la miner\u00eda de textos (extracci\u00f3n, categorizaci\u00f3n, detecci\u00f3n de novedades) y en nuevos marcos te\u00f3ricos como una teor\u00eda unificada basada en la utilidad que une la recuperaci\u00f3n de informaci\u00f3n, el resumen autom\u00e1tico, la respuesta a preguntas de texto libre y tareas relacionadas.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 17], [18, 31], [32, 34], [35, 41], [42, 44], [45, 50], [51, 55], [56, 58], [59, 66], [67, 69], [70, 76], [77, 78], [78, 88], [88, 89], [90, 104], [104, 105], [106, 115], [116, 118], [119, 128], [128, 129], [130, 131], [132, 134], [135, 141], [142, 148], [149, 157], [158, 162], [163, 166], [167, 173], [174, 183], [184, 190], [191, 193], [194, 196], [197, 205], [206, 209], [210, 213], [214, 216], [217, 229], [230, 232], [233, 244], [244, 245], [246, 248], [249, 256], [257, 267], [267, 268], [269, 271], [272, 281], [282, 283], [284, 293], [294, 296], [297, 302], [303, 308], [309, 310], [311, 317], [318, 330], [330, 331]]}
{"doc_key": "ai-test-414", "ner": [[4, 5, "product"], [13, 21, "misc"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Los", "robots", "Delta", "tienen", "actuadores", "rotativos", "montados", "en", "la", "base", "que", "mueven", "un", "brazo", "ligero", ",", "r\u00edgido", "y", "en", "forma", "de", "paralelogramo", "."], "sentence-detokenized": "Los robots Delta tienen actuadores rotativos montados en la base que mueven un brazo ligero, r\u00edgido y en forma de paralelogramo.", "token2charspan": [[0, 3], [4, 10], [11, 16], [17, 23], [24, 34], [35, 44], [45, 53], [54, 56], [57, 59], [60, 64], [65, 68], [69, 75], [76, 78], [79, 84], [85, 91], [91, 92], [93, 99], [100, 101], [102, 104], [105, 110], [111, 113], [114, 127], [127, 128]]}
{"doc_key": "ai-test-415", "ner": [[7, 17, "metrics"], [11, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Los", "cuatro", "resultados", "pueden", "formularse", "en", "una", "tabla", "de", "contingencia", "o", "matriz", "de", "confusi\u00f3n", "de", "2", "\u00d7", "2", ",", "como", "sigue", ":"], "sentence-detokenized": "Los cuatro resultados pueden formularse en una tabla de contingencia o matriz de confusi\u00f3n de 2 \u00d7 2, como sigue:", "token2charspan": [[0, 3], [4, 10], [11, 21], [22, 28], [29, 39], [40, 42], [43, 46], [47, 52], [53, 55], [56, 68], [69, 70], [71, 77], [78, 80], [81, 90], [91, 93], [94, 95], [96, 97], [98, 99], [99, 100], [101, 105], [106, 111], [111, 112]]}
{"doc_key": "ai-test-416", "ner": [[4, 7, "field"], [33, 35, "task"], [41, 43, "task"], [48, 52, "task"], [54, 57, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[33, 35, 4, 7, "part-of", "task_part_of_field", false, false], [41, 43, 4, 7, "part-of", "task_part_of_field", false, false], [48, 52, 4, 7, "part-of", "task_part_of_field", false, false], [54, 57, 4, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["La", "tarea", "real", "de", "la", "miner\u00eda", "de", "datos", "es", "el", "an\u00e1lisis", "semiautom\u00e1tico", "o", "autom\u00e1tico", "de", "grandes", "cantidades", "de", "datos", "para", "extraer", "patrones", "desconocidos", "e", "interesantes", ",", "como", "grupos", "de", "registros", "de", "datos", "(", "an\u00e1lisis", "de", "cl\u00fasteres", ")", ",", "registros", "inusuales", "(", "detecci\u00f3n", "de", "anomal\u00edas", ")", "y", "dependencias", "(", "miner\u00eda", "de", "reglas", "de", "asociaci\u00f3n", ",", "miner\u00eda", "de", "patrones", "secuenciales", ")", "."], "sentence-detokenized": "La tarea real de la miner\u00eda de datos es el an\u00e1lisis semiautom\u00e1tico o autom\u00e1tico de grandes cantidades de datos para extraer patrones desconocidos e interesantes, como grupos de registros de datos (an\u00e1lisis de cl\u00fasteres), registros inusuales (detecci\u00f3n de anomal\u00edas) y dependencias (miner\u00eda de reglas de asociaci\u00f3n, miner\u00eda de patrones secuenciales).", "token2charspan": [[0, 2], [3, 8], [9, 13], [14, 16], [17, 19], [20, 27], [28, 30], [31, 36], [37, 39], [40, 42], [43, 51], [52, 66], [67, 68], [69, 79], [80, 82], [83, 90], [91, 101], [102, 104], [105, 110], [111, 115], [116, 123], [124, 132], [133, 145], [146, 147], [148, 160], [160, 161], [162, 166], [167, 173], [174, 176], [177, 186], [187, 189], [190, 195], [196, 197], [197, 205], [206, 208], [209, 218], [218, 219], [219, 220], [221, 230], [231, 240], [241, 242], [242, 251], [252, 254], [255, 264], [264, 265], [266, 267], [268, 280], [281, 282], [282, 289], [290, 292], [293, 299], [300, 302], [303, 313], [313, 314], [315, 322], [323, 325], [326, 334], [335, 347], [347, 348], [348, 349]]}
{"doc_key": "ai-test-417", "ner": [[2, 4, "product"], [7, 9, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 4, 7, 9, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Para", "un", "sistema", "de", "recomendaci\u00f3n", ",", "el", "an\u00e1lisis", "de", "sentimientos", "ha", "demostrado", "ser", "una", "t\u00e9cnica", "valiosa", "."], "sentence-detokenized": "Para un sistema de recomendaci\u00f3n, el an\u00e1lisis de sentimientos ha demostrado ser una t\u00e9cnica valiosa.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 32], [32, 33], [34, 36], [37, 45], [46, 48], [49, 61], [62, 64], [65, 75], [76, 79], [80, 83], [84, 91], [92, 99], [99, 100]]}
{"doc_key": "ai-test-418", "ner": [[4, 4, "misc"], [15, 15, "product"], [36, 38, "organisation"], [40, 41, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 15, 15, "usage", "", false, false], [36, 38, 40, 41, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Por", "casualidad", ",", "los", "alemanes", "hab\u00edan", "elegido", "muy", "mal", "la", "frecuencia", "de", "funcionamiento", "del", "sistema", "Wotan", ",", "que", "operaba", "en", "45", "MHz", ",", "que", "casualmente", "era", "la", "frecuencia", "de", "la", "potente", "pero", "inactiva", "emisora", "de", "televisi\u00f3n", "de", "la", "BBC", "en", "Alexandra", "Palace", "."], "sentence-detokenized": "Por casualidad, los alemanes hab\u00edan elegido muy mal la frecuencia de funcionamiento del sistema Wotan, que operaba en 45 MHz, que casualmente era la frecuencia de la potente pero inactiva emisora de televisi\u00f3n de la BBC en Alexandra Palace.", "token2charspan": [[0, 3], [4, 14], [14, 15], [16, 19], [20, 28], [29, 35], [36, 43], [44, 47], [48, 51], [52, 54], [55, 65], [66, 68], [69, 83], [84, 87], [88, 95], [96, 101], [101, 102], [103, 106], [107, 114], [115, 117], [118, 120], [121, 124], [124, 125], [126, 129], [130, 141], [142, 145], [146, 148], [149, 159], [160, 162], [163, 165], [166, 173], [174, 178], [179, 187], [188, 195], [196, 198], [199, 209], [210, 212], [213, 215], [216, 219], [220, 222], [223, 232], [233, 239], [239, 240]]}
{"doc_key": "ai-test-419", "ner": [[7, 17, "metrics"], [11, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Los", "cuatro", "resultados", "pueden", "formularse", "en", "una", "tabla", "de", "contingencia", "o", "matriz", "de", "confusi\u00f3n", "de", "2", "\u00d7", "2", ",", "como", "sigue", ":"], "sentence-detokenized": "Los cuatro resultados pueden formularse en una tabla de contingencia o matriz de confusi\u00f3n de 2 \u00d7 2, como sigue:", "token2charspan": [[0, 3], [4, 10], [11, 21], [22, 28], [29, 39], [40, 42], [43, 46], [47, 52], [53, 55], [56, 68], [69, 70], [71, 77], [78, 80], [81, 90], [91, 93], [94, 95], [96, 97], [98, 99], [99, 100], [101, 105], [106, 111], [111, 112]]}
{"doc_key": "ai-test-420", "ner": [[2, 6, "misc"], [14, 14, "misc"], [16, 16, "product"], [18, 18, "product"], [20, 22, "product"], [32, 32, "misc"], [49, 51, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[16, 16, 14, 14, "usage", "", false, false], [18, 18, 14, 14, "usage", "", false, false], [20, 22, 18, 18, "named", "", false, false], [32, 32, 14, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["En", "las", "aplicaciones", "de", "la", "Web", "Sem\u00e1ntica", ",", "y", "en", "aplicaciones", "relativamente", "populares", "de", "RDF", "como", "RSS", "y", "FOAF", "(", "Friend", "a", "Friend", ")", ",", "los", "recursos", "tienden", "a", "ser", "representados", "por", "URIs", "que", "denotan", "intencionadamente", ",", "y", "pueden", "ser", "utilizados", "para", "acceder", ",", "a", "datos", "reales", "en", "la", "World", "Wide", "Web", "."], "sentence-detokenized": "En las aplicaciones de la Web Sem\u00e1ntica, y en aplicaciones relativamente populares de RDF como RSS y FOAF (Friend a Friend), los recursos tienden a ser representados por URIs que denotan intencionadamente, y pueden ser utilizados para acceder, a datos reales en la World Wide Web.", "token2charspan": [[0, 2], [3, 6], [7, 19], [20, 22], [23, 25], [26, 29], [30, 39], [39, 40], [41, 42], [43, 45], [46, 58], [59, 72], [73, 82], [83, 85], [86, 89], [90, 94], [95, 98], [99, 100], [101, 105], [106, 107], [107, 113], [114, 115], [116, 122], [122, 123], [123, 124], [125, 128], [129, 137], [138, 145], [146, 147], [148, 151], [152, 165], [166, 169], [170, 174], [175, 178], [179, 186], [187, 204], [204, 205], [206, 207], [208, 214], [215, 218], [219, 229], [230, 234], [235, 242], [242, 243], [244, 245], [246, 251], [252, 258], [259, 261], [262, 264], [265, 270], [271, 275], [276, 279], [279, 280]]}
{"doc_key": "ai-test-421", "ner": [[1, 8, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "Asociaci\u00f3n", "para", "el", "Avance", "de", "la", "Inteligencia", "Artificial", "ha", "estudiado", "este", "tema", "en", "profundidad"], "sentence-detokenized": "La Asociaci\u00f3n para el Avance de la Inteligencia Artificial ha estudiado este tema en profundidad", "token2charspan": [[0, 2], [3, 13], [14, 18], [19, 21], [22, 28], [29, 31], [32, 34], [35, 47], [48, 58], [59, 61], [62, 71], [72, 76], [77, 81], [82, 84], [85, 96]]}
{"doc_key": "ai-test-422", "ner": [[6, 11, "product"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[22, 22, 6, 11, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Empezando", "como", "una", "curiosidad", ",", "el", "sistema", "de", "voz", "de", "Apple", "Macintosh", "ha", "evolucionado", "hasta", "convertirse", "en", "un", "programa", "totalmente", "compatible", ",", "PlainTalk", ",", "para", "personas", "con", "problemas", "de", "visi\u00f3n", "."], "sentence-detokenized": "Empezando como una curiosidad, el sistema de voz de Apple Macintosh ha evolucionado hasta convertirse en un programa totalmente compatible, PlainTalk, para personas con problemas de visi\u00f3n.", "token2charspan": [[0, 9], [10, 14], [15, 18], [19, 29], [29, 30], [31, 33], [34, 41], [42, 44], [45, 48], [49, 51], [52, 57], [58, 67], [68, 70], [71, 83], [84, 89], [90, 101], [102, 104], [105, 107], [108, 116], [117, 127], [128, 138], [138, 139], [140, 149], [149, 150], [151, 155], [156, 164], [165, 168], [169, 178], [179, 181], [182, 188], [188, 189]]}
{"doc_key": "ai-test-423", "ner": [[9, 10, "field"], [13, 15, "task"], [18, 20, "task"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 15, 9, 10, "part-of", "task_part_of_field", false, false], [18, 20, 9, 10, "part-of", "task_part_of_field", false, false], [23, 24, 9, 10, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Otras", "\u00e1reas", "de", "uso", "de", "las", "ontolog\u00edas", "dentro", "de", "la", "PNL", "son", "la", "recuperaci\u00f3n", "de", "informaci\u00f3n", ",", "la", "extracci\u00f3n", "de", "informaci\u00f3n", "y", "el", "resumen", "autom\u00e1tico", "."], "sentence-detokenized": "Otras \u00e1reas de uso de las ontolog\u00edas dentro de la PNL son la recuperaci\u00f3n de informaci\u00f3n, la extracci\u00f3n de informaci\u00f3n y el resumen autom\u00e1tico.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 18], [19, 21], [22, 25], [26, 36], [37, 43], [44, 46], [47, 49], [50, 53], [54, 57], [58, 60], [61, 73], [74, 76], [77, 88], [88, 89], [90, 92], [93, 103], [104, 106], [107, 118], [119, 120], [121, 123], [124, 131], [132, 142], [142, 143]]}
{"doc_key": "ai-test-424", "ner": [[7, 14, "organisation"], [17, 23, "organisation"], [26, 29, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["El", "Instituto", "ha", "colaborado", "estrechamente", "con", "el", "Campus", "Janelia", "Farm", "del", "Instituto", "M\u00e9dico", "Howard", "Hughes", ",", "el", "Instituto", "Allen", "para", "la", "Ciencia", "del", "Cerebro", "y", "los", "Institutos", "Nacionales", "de", "Salud", "para", "desarrollar", "mejores", "m\u00e9todos", "de", "reconstrucci\u00f3n", "de", "arquitecturas", "neuronales", "."], "sentence-detokenized": "El Instituto ha colaborado estrechamente con el Campus Janelia Farm del Instituto M\u00e9dico Howard Hughes, el Instituto Allen para la Ciencia del Cerebro y los Institutos Nacionales de Salud para desarrollar mejores m\u00e9todos de reconstrucci\u00f3n de arquitecturas neuronales.", "token2charspan": [[0, 2], [3, 12], [13, 15], [16, 26], [27, 40], [41, 44], [45, 47], [48, 54], [55, 62], [63, 67], [68, 71], [72, 81], [82, 88], [89, 95], [96, 102], [102, 103], [104, 106], [107, 116], [117, 122], [123, 127], [128, 130], [131, 138], [139, 142], [143, 150], [151, 152], [153, 156], [157, 167], [168, 178], [179, 181], [182, 187], [188, 192], [193, 204], [205, 212], [213, 220], [221, 223], [224, 238], [239, 241], [242, 255], [256, 266], [266, 267]]}
{"doc_key": "ai-test-425", "ner": [[2, 2, "organisation"], [5, 6, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 2, 2, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Recientemente", ",", "Google", "anunci\u00f3", "que", "Google", "Translate", "traduce", "aproximadamente", "suficiente", "texto", "para", "llenar", "un", "mill\u00f3n", "de", "libros", "en", "un", "d\u00eda", "(", "2012", ")", "."], "sentence-detokenized": "Recientemente, Google anunci\u00f3 que Google Translate traduce aproximadamente suficiente texto para llenar un mill\u00f3n de libros en un d\u00eda (2012).", "token2charspan": [[0, 13], [13, 14], [15, 21], [22, 29], [30, 33], [34, 40], [41, 50], [51, 58], [59, 74], [75, 85], [86, 91], [92, 96], [97, 103], [104, 106], [107, 113], [114, 116], [117, 123], [124, 126], [127, 129], [130, 133], [134, 135], [135, 139], [139, 140], [140, 141]]}
{"doc_key": "ai-test-426", "ner": [[15, 16, "country"], [18, 19, "country"], [21, 21, "country"], [23, 23, "country"], [25, 25, "country"], [27, 29, "country"], [40, 41, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Los", "eventos", "se", "celebran", "en", "todo", "el", "mundo", ",", "y", "son", "m\u00e1s", "populares", "en", "el", "Reino", "Unido", ",", "Estados", "Unidos", ",", "Jap\u00f3n", ",", "Singapur", ",", "India", ",", "Corea", "del", "Sur", "y", "se", "est\u00e1n", "haciendo", "populares", "en", "pa\u00edses", "del", "subcontinente", "como", "Sri", "Lanka", "."], "sentence-detokenized": "Los eventos se celebran en todo el mundo, y son m\u00e1s populares en el Reino Unido, Estados Unidos, Jap\u00f3n, Singapur, India, Corea del Sur y se est\u00e1n haciendo populares en pa\u00edses del subcontinente como Sri Lanka.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 23], [24, 26], [27, 31], [32, 34], [35, 40], [40, 41], [42, 43], [44, 47], [48, 51], [52, 61], [62, 64], [65, 67], [68, 73], [74, 79], [79, 80], [81, 88], [89, 95], [95, 96], [97, 102], [102, 103], [104, 112], [112, 113], [114, 119], [119, 120], [121, 126], [127, 130], [131, 134], [135, 136], [137, 139], [140, 145], [146, 154], [155, 164], [165, 167], [168, 174], [175, 178], [179, 192], [193, 197], [198, 201], [202, 207], [207, 208]]}
{"doc_key": "ai-test-427", "ner": [[6, 6, "programlang"], [12, 12, "programlang"], [14, 14, "programlang"], [16, 18, "programlang"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Estos", "paquetes", "se", "desarrollan", "principalmente", "en", "R", ",", "y", "a", "veces", "en", "Java", ",", "C", ",", "C", "+", "+", ",", "y", "Fortran", "."], "sentence-detokenized": "Estos paquetes se desarrollan principalmente en R, y a veces en Java, C, C + +, y Fortran.", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 29], [30, 44], [45, 47], [48, 49], [49, 50], [51, 52], [53, 54], [55, 60], [61, 63], [64, 68], [68, 69], [70, 71], [71, 72], [73, 74], [75, 76], [77, 78], [78, 79], [80, 81], [82, 89], [89, 90]]}
{"doc_key": "ai-test-428", "ner": [[5, 15, "conference"], [12, 12, "conference"], [17, 17, "researcher"], [19, 21, "researcher"], [23, 24, "researcher"], [27, 29, "algorithm"], [34, 39, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 12, 5, 15, "named", "", false, false], [17, 17, 5, 15, "physical", "", false, false], [17, 17, 5, 15, "role", "", false, false], [17, 17, 23, 24, "role", "teams_up_with", false, false], [17, 17, 27, 29, "usage", "", false, false], [19, 21, 5, 15, "physical", "", false, false], [19, 21, 5, 15, "role", "", false, false], [19, 21, 23, 24, "role", "teams_up_with", false, false], [19, 21, 27, 29, "usage", "", false, false], [23, 24, 5, 15, "physical", "", false, false], [23, 24, 5, 15, "role", "", false, false], [23, 24, 27, 29, "usage", "", false, false], [27, 29, 34, 39, "related-to", "used_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["En", "el", "marco", "de", "la", "Conferencia", "Europea", "de", "Visi\u00f3n", "por", "Ordenador", "(", "ECCV", ")", "de", "2006", ",", "Dalal", "y", "Triggs", "se", "asociaron", "con", "Cordelia", "Schmid", "para", "aplicar", "los", "detectores", "HOG", "al", "problema", "de", "la", "detecci\u00f3n", "humana", "en", "pel\u00edculas", "y", "v\u00eddeos", "."], "sentence-detokenized": "En el marco de la Conferencia Europea de Visi\u00f3n por Ordenador (ECCV) de 2006, Dalal y Triggs se asociaron con Cordelia Schmid para aplicar los detectores HOG al problema de la detecci\u00f3n humana en pel\u00edculas y v\u00eddeos.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 14], [15, 17], [18, 29], [30, 37], [38, 40], [41, 47], [48, 51], [52, 61], [62, 63], [63, 67], [67, 68], [69, 71], [72, 76], [76, 77], [78, 83], [84, 85], [86, 92], [93, 95], [96, 105], [106, 109], [110, 118], [119, 125], [126, 130], [131, 138], [139, 142], [143, 153], [154, 157], [158, 160], [161, 169], [170, 172], [173, 175], [176, 185], [186, 192], [193, 195], [196, 205], [206, 207], [208, 214], [214, 215]]}
{"doc_key": "ai-test-429", "ner": [[3, 3, "metrics"], [6, 6, "metrics"], [14, 15, "task"], [22, 22, "metrics"], [24, 24, "metrics"], [30, 30, "metrics"], [34, 36, "metrics"], [38, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 3, 14, 15, "related-to", "measured_with", false, false], [6, 6, 14, 15, "related-to", "measured_with", false, false], [22, 22, 14, 15, "related-to", "measured_with", false, false], [24, 24, 22, 22, "named", "", false, false], [30, 30, 22, 22, "named", "", false, false], [38, 38, 34, 36, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Adem\u00e1s", "de", "la", "sensibilidad", "y", "la", "especificidad", ",", "el", "rendimiento", "de", "una", "prueba", "de", "clasificaci\u00f3n", "binaria", "puede", "medirse", "con", "el", "valor", "predictivo", "positivo", "(", "VPP", ")", ",", "tambi\u00e9n", "conocido", "como", "precisi\u00f3n", ",", "y", "el", "valor", "predictivo", "negativo", "(", "VPN", ")", "."], "sentence-detokenized": "Adem\u00e1s de la sensibilidad y la especificidad, el rendimiento de una prueba de clasificaci\u00f3n binaria puede medirse con el valor predictivo positivo (VPP), tambi\u00e9n conocido como precisi\u00f3n, y el valor predictivo negativo (VPN).", "token2charspan": [[0, 6], [7, 9], [10, 12], [13, 25], [26, 27], [28, 30], [31, 44], [44, 45], [46, 48], [49, 60], [61, 63], [64, 67], [68, 74], [75, 77], [78, 91], [92, 99], [100, 105], [106, 113], [114, 117], [118, 120], [121, 126], [127, 137], [138, 146], [147, 148], [148, 151], [151, 152], [152, 153], [154, 161], [162, 170], [171, 175], [176, 185], [185, 186], [187, 188], [189, 191], [192, 197], [198, 208], [209, 217], [218, 219], [219, 222], [222, 223], [223, 224]]}
{"doc_key": "ai-test-430", "ner": [[15, 19, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Dichos", "modelos", "pueden", "dar", "cr\u00e9dito", "parcial", "a", "las", "coincidencias", "(", "por", "ejemplo", ",", "utilizando", "el", "criterio", "del", "\u00edndice", "de", "Jaccard", ")", "."], "sentence-detokenized": "Dichos modelos pueden dar cr\u00e9dito parcial a las coincidencias (por ejemplo, utilizando el criterio del \u00edndice de Jaccard).", "token2charspan": [[0, 6], [7, 14], [15, 21], [22, 25], [26, 33], [34, 41], [42, 43], [44, 47], [48, 61], [62, 63], [63, 66], [67, 74], [74, 75], [76, 86], [87, 89], [90, 98], [99, 102], [103, 109], [110, 112], [113, 120], [120, 121], [121, 122]]}
{"doc_key": "ai-test-431", "ner": [[25, 33, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Adem\u00e1s", ",", "en", "el", "caso", "de", "la", "estimaci\u00f3n", "basada", "en", "una", "sola", "muestra", ",", "demuestra", "cuestiones", "filos\u00f3ficas", "y", "posibles", "malentendidos", "en", "el", "uso", "de", "los", "estimadores", "de", "m\u00e1xima", "verosimilitud", "y", "las", "funciones", "de", "verosimilitud", "."], "sentence-detokenized": "Adem\u00e1s, en el caso de la estimaci\u00f3n basada en una sola muestra, demuestra cuestiones filos\u00f3ficas y posibles malentendidos en el uso de los estimadores de m\u00e1xima verosimilitud y las funciones de verosimilitud.", "token2charspan": [[0, 6], [6, 7], [8, 10], [11, 13], [14, 18], [19, 21], [22, 24], [25, 35], [36, 42], [43, 45], [46, 49], [50, 54], [55, 62], [62, 63], [64, 73], [74, 84], [85, 96], [97, 98], [99, 107], [108, 121], [122, 124], [125, 127], [128, 131], [132, 134], [135, 138], [139, 150], [151, 153], [154, 160], [161, 174], [175, 176], [177, 180], [181, 190], [191, 193], [194, 207], [207, 208]]}
