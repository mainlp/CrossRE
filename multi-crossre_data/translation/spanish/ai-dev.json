{"doc_key": "ai-dev-1", "ner": [[3, 3, "metrics"], [8, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 10, 3, 3, "part-of", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Aqu\u00ed", ",", "la", "precisi\u00f3n", "se", "mide", "por", "la", "tasa", "de", "error", ",", "que", "se", "define", "como", ":"], "sentence-detokenized": "Aqu\u00ed, la precisi\u00f3n se mide por la tasa de error, que se define como:", "token2charspan": [[0, 4], [4, 5], [6, 8], [9, 18], [19, 21], [22, 26], [27, 30], [31, 33], [34, 38], [39, 41], [42, 47], [47, 48], [49, 52], [53, 55], [56, 62], [63, 67], [67, 68]]}
{"doc_key": "ai-dev-2", "ner": [[4, 5, "algorithm"], [11, 13, "misc"], [20, 23, "algorithm"], [18, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 11, 13, "type-of", "", false, false], [4, 5, 20, 23, "related-to", "", false, false], [4, 5, 18, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Desde", "esta", "perspectiva", ",", "la", "SVM", "est\u00e1", "estrechamente", "relacionada", "con", "otros", "algoritmos", "de", "clasificaci\u00f3n", "fundamentales", ",", "como", "la", "regresi\u00f3n", "log\u00edstica", "por", "m\u00ednimos", "cuadrados", "regularizados", "."], "sentence-detokenized": "Desde esta perspectiva, la SVM est\u00e1 estrechamente relacionada con otros algoritmos de clasificaci\u00f3n fundamentales, como la regresi\u00f3n log\u00edstica por m\u00ednimos cuadrados regularizados.", "token2charspan": [[0, 5], [6, 10], [11, 22], [22, 23], [24, 26], [27, 30], [31, 35], [36, 49], [50, 61], [62, 65], [66, 71], [72, 82], [83, 85], [86, 99], [100, 113], [113, 114], [115, 119], [120, 122], [123, 132], [133, 142], [143, 146], [147, 154], [155, 164], [165, 178], [178, 179]]}
{"doc_key": "ai-dev-3", "ner": [[0, 1, "person"], [4, 5, "person"], [15, 16, "person"], [18, 18, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 0, 1, "named", "actor_plays_character", false, false], [4, 5, 0, 1, "origin", "actor_plays_character", false, false], [18, 18, 15, 16, "named", "actor_plays_character", false, false], [18, 18, 15, 16, "origin", "actor_plays_character", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Brion", "James", "interpreta", "a", "Leon", "Kowalski", ",", "un", "replicante", "de", "combate", "y", "trabajo", ",", "y", "Joanna", "Cassidy", "a", "Zhora", ",", "una", "replicante", "asesina", "."], "sentence-detokenized": "Brion James interpreta a Leon Kowalski, un replicante de combate y trabajo, y Joanna Cassidy a Zhora, una replicante asesina.", "token2charspan": [[0, 5], [6, 11], [12, 22], [23, 24], [25, 29], [30, 38], [38, 39], [40, 42], [43, 53], [54, 56], [57, 64], [65, 66], [67, 74], [74, 75], [76, 77], [78, 84], [85, 92], [93, 94], [95, 100], [100, 101], [102, 105], [106, 116], [117, 124], [124, 125]]}
{"doc_key": "ai-dev-4", "ner": [[17, 20, "product"], [22, 22, "product"], [24, 25, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 20, 24, 25, "physical", "", false, false], [22, 22, 17, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "primera", "imagen", "que", "se", "escane\u00f3", ",", "almacen\u00f3", "y", "recre\u00f3", "en", "p\u00edxeles", "digitales", "se", "visualiz\u00f3", "en", "el", "Ordenador", "Autom\u00e1tico", "del", "Este", "(", "SEAC", ")", "del", "NIST", "."], "sentence-detokenized": "La primera imagen que se escane\u00f3, almacen\u00f3 y recre\u00f3 en p\u00edxeles digitales se visualiz\u00f3 en el Ordenador Autom\u00e1tico del Este (SEAC) del NIST.", "token2charspan": [[0, 2], [3, 10], [11, 17], [18, 21], [22, 24], [25, 32], [32, 33], [34, 42], [43, 44], [45, 51], [52, 54], [55, 62], [63, 72], [73, 75], [76, 85], [86, 88], [89, 91], [92, 101], [102, 112], [113, 116], [117, 121], [122, 123], [123, 127], [127, 128], [129, 132], [133, 137], [137, 138]]}
{"doc_key": "ai-dev-5", "ner": [[0, 7, "task"], [22, 24, "task"], [27, 29, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 7, 22, 24, "part-of", "", false, false], [0, 7, 27, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Segmentar", "el", "texto", "en", "temas", "o", "giros", "discursivos", "puede", "ser", "\u00fatil", "en", "algunas", "tareas", "de", "procesamiento", "natural", ":", "puede", "mejorar", "significativamente", "la", "recuperaci\u00f3n", "de", "informaci\u00f3n", "o", "el", "reconocimiento", "del", "habla", "(", "indexando/reconociendo", "los", "documentos", "con", "mayor", "precisi\u00f3n", "o", "dando", "como", "resultado", "la", "parte", "espec\u00edfica", "de", "un", "documento", "correspondiente", "a", "la", "consulta", ")", "."], "sentence-detokenized": "Segmentar el texto en temas o giros discursivos puede ser \u00fatil en algunas tareas de procesamiento natural: puede mejorar significativamente la recuperaci\u00f3n de informaci\u00f3n o el reconocimiento del habla (indexando/reconociendo los documentos con mayor precisi\u00f3n o dando como resultado la parte espec\u00edfica de un documento correspondiente a la consulta).", "token2charspan": [[0, 9], [10, 12], [13, 18], [19, 21], [22, 27], [28, 29], [30, 35], [36, 47], [48, 53], [54, 57], [58, 62], [63, 65], [66, 73], [74, 80], [81, 83], [84, 97], [98, 105], [105, 106], [107, 112], [113, 120], [121, 139], [140, 142], [143, 155], [156, 158], [159, 170], [171, 172], [173, 175], [176, 190], [191, 194], [195, 200], [201, 202], [202, 224], [225, 228], [229, 239], [240, 243], [244, 249], [250, 259], [260, 261], [262, 267], [268, 272], [273, 282], [283, 285], [286, 291], [292, 302], [303, 305], [306, 308], [309, 318], [319, 334], [335, 336], [337, 339], [340, 348], [348, 349], [349, 350]]}
{"doc_key": "ai-dev-6", "ner": [[10, 12, "university"], [25, 26, "conference"], [28, 31, "university"], [41, 42, "researcher"], [44, 45, "researcher"], [47, 48, "researcher"], [50, 51, "researcher"], [53, 54, "researcher"], [56, 57, "researcher"], [59, 61, "researcher"], [63, 64, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[25, 26, 28, 31, "physical", "", false, false], [41, 42, 25, 26, "physical", "", false, false], [41, 42, 25, 26, "role", "", false, false], [41, 42, 25, 26, "temporal", "", false, false], [44, 45, 25, 26, "physical", "", false, false], [44, 45, 25, 26, "role", "", false, false], [44, 45, 25, 26, "temporal", "", false, false], [47, 48, 25, 26, "physical", "", false, false], [47, 48, 25, 26, "role", "", false, false], [47, 48, 25, 26, "temporal", "", false, false], [50, 51, 25, 26, "physical", "", false, false], [50, 51, 25, 26, "role", "", false, false], [50, 51, 25, 26, "temporal", "", false, false], [53, 54, 25, 26, "physical", "", false, false], [53, 54, 25, 26, "role", "", false, false], [53, 54, 25, 26, "temporal", "", false, false], [56, 57, 25, 26, "physical", "", false, false], [56, 57, 25, 26, "role", "", false, false], [56, 57, 25, 26, "temporal", "", false, false], [59, 61, 25, 26, "physical", "", false, false], [59, 61, 25, 26, "role", "", false, false], [59, 61, 25, 26, "temporal", "", false, false], [63, 64, 25, 26, "physical", "", false, false], [63, 64, 25, 26, "role", "", false, false], [63, 64, 25, 26, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "sentence": ["En", "1999", "organiz\u00f3", "un", "simposio", "de", "este", "tipo", "en", "la", "Universidad", "de", "Indiana", ",", "y", "en", "abril", "de", "2000", "organiz\u00f3", "un", "simposio", "m\u00e1s", "amplio", "titulado", "Robots", "espirituales", "en", "la", "Universidad", "de", "Stanford", ",", "en", "el", "que", "moder\u00f3", "un", "panel", "formado", "por", "Ray", "Kurzweil", ",", "Hans", "Moravec", ",", "Kevin", "Kelly", ",", "Ralph", "Merkle", ",", "Bill", "Joy", ",", "Frank", "Drake", ",", "John", "Henry", "Holland", "y", "John", "Koza", "."], "sentence-detokenized": "En 1999 organiz\u00f3 un simposio de este tipo en la Universidad de Indiana, y en abril de 2000 organiz\u00f3 un simposio m\u00e1s amplio titulado Robots espirituales en la Universidad de Stanford, en el que moder\u00f3 un panel formado por Ray Kurzweil, Hans Moravec, Kevin Kelly, Ralph Merkle, Bill Joy, Frank Drake, John Henry Holland y John Koza.", "token2charspan": [[0, 2], [3, 7], [8, 16], [17, 19], [20, 28], [29, 31], [32, 36], [37, 41], [42, 44], [45, 47], [48, 59], [60, 62], [63, 70], [70, 71], [72, 73], [74, 76], [77, 82], [83, 85], [86, 90], [91, 99], [100, 102], [103, 111], [112, 115], [116, 122], [123, 131], [132, 138], [139, 151], [152, 154], [155, 157], [158, 169], [170, 172], [173, 181], [181, 182], [183, 185], [186, 188], [189, 192], [193, 199], [200, 202], [203, 208], [209, 216], [217, 220], [221, 224], [225, 233], [233, 234], [235, 239], [240, 247], [247, 248], [249, 254], [255, 260], [260, 261], [262, 267], [268, 274], [274, 275], [276, 280], [281, 284], [284, 285], [286, 291], [292, 297], [297, 298], [299, 303], [304, 309], [310, 317], [318, 319], [320, 324], [325, 329], [329, 330]]}
{"doc_key": "ai-dev-7", "ner": [[3, 3, "metrics"], [4, 4, "metrics"], [7, 7, "metrics"], [8, 8, "metrics"], [17, 17, "metrics"], [40, 40, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 3, 17, 17, "named", "", false, false], [4, 4, 3, 3, "named", "", false, false], [7, 7, 40, 40, "named", "", false, false], [8, 8, 7, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Considera", "tanto", "la", "precisi\u00f3n", "p", "como", "la", "recuperaci\u00f3n", "r", "de", "la", "prueba", "para", "calcular", "la", "puntuaci\u00f3n", ":", "p", "es", "el", "n\u00famero", "de", "resultados", "positivos", "correctos", "dividido", "por", "el", "n\u00famero", "de", "todos", "los", "resultados", "positivos", "devueltos", "por", "el", "clasificador", ",", "y", "r", "es", "el", "n\u00famero", "de", "resultados", "positivos", "correctos", "dividido", "por", "el", "n\u00famero", "de", "todas", "las", "muestras", "relevantes", "(", "todas", "las", "muestras", "que", "deber\u00edan", "haber", "sido", "identificadas", "como", "positivas", ")", "."], "sentence-detokenized": "Considera tanto la precisi\u00f3n p como la recuperaci\u00f3n r de la prueba para calcular la puntuaci\u00f3n: p es el n\u00famero de resultados positivos correctos dividido por el n\u00famero de todos los resultados positivos devueltos por el clasificador, y r es el n\u00famero de resultados positivos correctos dividido por el n\u00famero de todas las muestras relevantes (todas las muestras que deber\u00edan haber sido identificadas como positivas).", "token2charspan": [[0, 9], [10, 15], [16, 18], [19, 28], [29, 30], [31, 35], [36, 38], [39, 51], [52, 53], [54, 56], [57, 59], [60, 66], [67, 71], [72, 80], [81, 83], [84, 94], [94, 95], [96, 97], [98, 100], [101, 103], [104, 110], [111, 113], [114, 124], [125, 134], [135, 144], [145, 153], [154, 157], [158, 160], [161, 167], [168, 170], [171, 176], [177, 180], [181, 191], [192, 201], [202, 211], [212, 215], [216, 218], [219, 231], [231, 232], [233, 234], [235, 236], [237, 239], [240, 242], [243, 249], [250, 252], [253, 263], [264, 273], [274, 283], [284, 292], [293, 296], [297, 299], [300, 306], [307, 309], [310, 315], [316, 319], [320, 328], [329, 339], [340, 341], [341, 346], [347, 350], [351, 359], [360, 363], [364, 372], [373, 378], [379, 383], [384, 397], [398, 402], [403, 412], [412, 413], [413, 414]]}
{"doc_key": "ai-dev-8", "ner": [[3, 6, "organisation"], [27, 27, "product"], [36, 37, "person"], [43, 43, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 6, 27, 27, "artifact", "", false, false], [27, 27, 36, 37, "win-defeat", "", false, false], [27, 27, 43, 43, "win-defeat", "", true, false], [36, 37, 43, 43, "win-defeat", "lose", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Desde", "la", "adquisici\u00f3n", "por", "parte", "de", "Google", ",", "la", "empresa", "se", "ha", "apuntado", "una", "serie", "de", "logros", "significativos", ",", "siendo", "quiz\u00e1", "el", "m\u00e1s", "notable", "la", "creaci\u00f3n", "de", "AlphaGo", ",", "un", "programa", "que", "derrot\u00f3", "al", "campe\u00f3n", "mundial", "Lee", "Sedol", "en", "el", "complejo", "juego", "del", "Go", "."], "sentence-detokenized": "Desde la adquisici\u00f3n por parte de Google, la empresa se ha apuntado una serie de logros significativos, siendo quiz\u00e1 el m\u00e1s notable la creaci\u00f3n de AlphaGo, un programa que derrot\u00f3 al campe\u00f3n mundial Lee Sedol en el complejo juego del Go.", "token2charspan": [[0, 5], [6, 8], [9, 20], [21, 24], [25, 30], [31, 33], [34, 40], [40, 41], [42, 44], [45, 52], [53, 55], [56, 58], [59, 67], [68, 71], [72, 77], [78, 80], [81, 87], [88, 102], [102, 103], [104, 110], [111, 116], [117, 119], [120, 123], [124, 131], [132, 134], [135, 143], [144, 146], [147, 154], [154, 155], [156, 158], [159, 167], [168, 171], [172, 179], [180, 182], [183, 190], [191, 198], [199, 202], [203, 208], [209, 211], [212, 214], [215, 223], [224, 229], [230, 233], [234, 236], [236, 237]]}
{"doc_key": "ai-dev-9", "ner": [[19, 19, "misc"], [34, 35, "field"], [38, 42, "product"], [61, 64, "misc"], [17, 73, "misc"], [76, 76, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[19, 19, 34, 35, "part-of", "", false, false], [19, 19, 17, 73, "named", "same", false, false], [38, 42, 61, 64, "related-to", "", false, false], [38, 42, 17, 73, "usage", "", false, false], [38, 42, 76, 76, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Representar", "las", "palabras", "teniendo", "en", "cuenta", "su", "contexto", "a", "trav\u00e9s", "de", "vectores", "densos", "de", "tama\u00f1o", "fijo", "(", "incrustaci\u00f3n", "de", "palabras", ")", "se", "ha", "convertido", "en", "uno", "de", "los", "bloques", "m\u00e1s", "fundamentales", "de", "varios", "sistemas", "de", "PNL", ".", "un", "sistema", "de", "desambiguaci\u00f3n", "no", "supervisado", "utiliza", "la", "similitud", "entre", "los", "sentidos", "de", "las", "palabras", "en", "una", "ventana", "de", "contexto", "fija", "para", "seleccionar", "el", "sentido", "de", "la", "palabra", "m\u00e1s", "adecuado", "utilizando", "un", "modelo", "de", "incrustaci\u00f3n", "de", "palabras", "preentrenado", "y", "WordNet", "."], "sentence-detokenized": "Representar las palabras teniendo en cuenta su contexto a trav\u00e9s de vectores densos de tama\u00f1o fijo (incrustaci\u00f3n de palabras) se ha convertido en uno de los bloques m\u00e1s fundamentales de varios sistemas de PNL. un sistema de desambiguaci\u00f3n no supervisado utiliza la similitud entre los sentidos de las palabras en una ventana de contexto fija para seleccionar el sentido de la palabra m\u00e1s adecuado utilizando un modelo de incrustaci\u00f3n de palabras preentrenado y WordNet.", "token2charspan": [[0, 11], [12, 15], [16, 24], [25, 33], [34, 36], [37, 43], [44, 46], [47, 55], [56, 57], [58, 64], [65, 67], [68, 76], [77, 83], [84, 86], [87, 93], [94, 98], [99, 100], [100, 112], [113, 115], [116, 124], [124, 125], [126, 128], [129, 131], [132, 142], [143, 145], [146, 149], [150, 152], [153, 156], [157, 164], [165, 168], [169, 182], [183, 185], [186, 192], [193, 201], [202, 204], [205, 208], [208, 209], [210, 212], [213, 220], [221, 223], [224, 238], [239, 241], [242, 253], [254, 261], [262, 264], [265, 274], [275, 280], [281, 284], [285, 293], [294, 296], [297, 300], [301, 309], [310, 312], [313, 316], [317, 324], [325, 327], [328, 336], [337, 341], [342, 346], [347, 358], [359, 361], [362, 369], [370, 372], [373, 375], [376, 383], [384, 387], [388, 396], [397, 407], [408, 410], [411, 417], [418, 420], [421, 433], [434, 436], [437, 445], [446, 458], [459, 460], [461, 468], [468, 469]]}
{"doc_key": "ai-dev-10", "ner": [[3, 4, "field"], [9, 10, "field"], [13, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 3, 4, "part-of", "", false, false], [13, 15, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Las", "t\u00e9cnicas", "de", "aprendizaje", "autom\u00e1tico", ",", "ya", "sean", "de", "aprendizaje", "supervisado", "o", "de", "aprendizaje", "no", "supervisado", ",", "se", "han", "utilizado", "para", "inducir", "dichas", "reglas", "autom\u00e1ticamente", "."], "sentence-detokenized": "Las t\u00e9cnicas de aprendizaje autom\u00e1tico, ya sean de aprendizaje supervisado o de aprendizaje no supervisado, se han utilizado para inducir dichas reglas autom\u00e1ticamente.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 38], [38, 39], [40, 42], [43, 47], [48, 50], [51, 62], [63, 74], [75, 76], [77, 79], [80, 91], [92, 94], [95, 106], [106, 107], [108, 110], [111, 114], [115, 124], [125, 129], [130, 137], [138, 144], [145, 151], [152, 167], [167, 168]]}
{"doc_key": "ai-dev-11", "ner": [[3, 3, "researcher"], [6, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["En", "1969", ",", "Scheinman", "invent\u00f3", "el", "brazo", "de", "Stanford", ","], "sentence-detokenized": "En 1969, Scheinman invent\u00f3 el brazo de Stanford,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 18], [19, 26], [27, 29], [30, 35], [36, 38], [39, 47], [47, 48]]}
{"doc_key": "ai-dev-12", "ner": [[3, 5, "metrics"], [13, 17, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Dado", "que", "la", "p\u00e9rdida", "del", "registro", "es", "diferenciable", ",", "se", "puede", "utilizar", "un", "m\u00e9todo", "basado", "en", "el", "gradiente", "para", "optimizar", "el", "modelo", "."], "sentence-detokenized": "Dado que la p\u00e9rdida del registro es diferenciable, se puede utilizar un m\u00e9todo basado en el gradiente para optimizar el modelo.", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 19], [20, 23], [24, 32], [33, 35], [36, 49], [49, 50], [51, 53], [54, 59], [60, 68], [69, 71], [72, 78], [79, 85], [86, 88], [89, 91], [92, 101], [102, 106], [107, 116], [117, 119], [120, 126], [126, 127]]}
{"doc_key": "ai-dev-13", "ner": [[2, 3, "field"], [6, 10, "algorithm"], [12, 12, "algorithm"], [15, 19, "algorithm"], [24, 25, "field"], [37, 37, "task"], [40, 42, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[6, 10, 24, 25, "part-of", "", false, false], [12, 12, 6, 10, "named", "", false, false], [15, 19, 6, 10, "named", "", false, false], [24, 25, 2, 3, "part-of", "subfield", false, false], [37, 37, 24, 25, "part-of", "", false, false], [40, 42, 24, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["En", "el", "aprendizaje", "autom\u00e1tico", ",", "las", "m\u00e1quinas", "de", "vectores", "de", "apoyo", "(", "SVM", ",", "tambi\u00e9n", "redes", "de", "vectores", "de", "apoyo", ")", "son", "modelos", "de", "aprendizaje", "supervisado", "con", "algoritmos", "de", "aprendizaje", "que", "analizan", "los", "datos", "utilizados", "para", "la", "clasificaci\u00f3n", "y", "el", "an\u00e1lisis", "de", "regresi\u00f3n", "."], "sentence-detokenized": "En el aprendizaje autom\u00e1tico, las m\u00e1quinas de vectores de apoyo (SVM, tambi\u00e9n redes de vectores de apoyo) son modelos de aprendizaje supervisado con algoritmos de aprendizaje que analizan los datos utilizados para la clasificaci\u00f3n y el an\u00e1lisis de regresi\u00f3n.", "token2charspan": [[0, 2], [3, 5], [6, 17], [18, 28], [28, 29], [30, 33], [34, 42], [43, 45], [46, 54], [55, 57], [58, 63], [64, 65], [65, 68], [68, 69], [70, 77], [78, 83], [84, 86], [87, 95], [96, 98], [99, 104], [104, 105], [106, 109], [110, 117], [118, 120], [121, 132], [133, 144], [145, 148], [149, 159], [160, 162], [163, 174], [175, 178], [179, 187], [188, 191], [192, 197], [198, 208], [209, 213], [214, 216], [217, 230], [231, 232], [233, 235], [236, 244], [245, 247], [248, 257], [257, 258]]}
{"doc_key": "ai-dev-14", "ner": [[11, 12, "task"], [14, 14, "task"], [29, 29, "metrics"], [31, 31, "metrics"], [33, 33, "researcher"], [35, 35, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 14, 11, 12, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "2002", ")", "como", "m\u00e9trica", "autom\u00e1tica", "para", "la", "evaluaci\u00f3n", "de", "la", "traducci\u00f3n", "autom\u00e1tica", "(", "TA", ")", ",", "se", "han", "propuesto", "muchos", "otros", "m\u00e9todos", "para", "revisarla", "o", "mejorarla", ",", "como", "TER", ",", "METEOR", ",", "Banerjee", "y", "Lavie", ",", "(", "2005", ")", ",", "etc", "."], "sentence-detokenized": "(2002) como m\u00e9trica autom\u00e1tica para la evaluaci\u00f3n de la traducci\u00f3n autom\u00e1tica (TA), se han propuesto muchos otros m\u00e9todos para revisarla o mejorarla, como TER, METEOR, Banerjee y Lavie, (2005), etc.", "token2charspan": [[0, 1], [1, 5], [5, 6], [7, 11], [12, 19], [20, 30], [31, 35], [36, 38], [39, 49], [50, 52], [53, 55], [56, 66], [67, 77], [78, 79], [79, 81], [81, 82], [82, 83], [84, 86], [87, 90], [91, 100], [101, 107], [108, 113], [114, 121], [122, 126], [127, 136], [137, 138], [139, 148], [148, 149], [150, 154], [155, 158], [158, 159], [160, 166], [166, 167], [168, 176], [177, 178], [179, 184], [184, 185], [186, 187], [187, 191], [191, 192], [192, 193], [194, 197], [197, 198]]}
{"doc_key": "ai-dev-15", "ner": [[2, 3, "misc"], [12, 13, "organisation"], [11, 11, "organisation"], [17, 18, "researcher"], [20, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 11, 11, "origin", "", false, false], [11, 11, 12, 13, "part-of", "", false, false], [17, 18, 11, 11, "role", "", false, false], [20, 21, 11, 11, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Incluye", "una", "ontolog\u00eda", "superior", ",", "creada", "por", "el", "grupo", "de", "trabajo", "P1600.1", "del", "IEEE", "(", "originalmente", "por", "Ian", "Niles", "y", "Adam", "Pease", ")", "."], "sentence-detokenized": "Incluye una ontolog\u00eda superior, creada por el grupo de trabajo P1600.1 del IEEE (originalmente por Ian Niles y Adam Pease).", "token2charspan": [[0, 7], [8, 11], [12, 21], [22, 30], [30, 31], [32, 38], [39, 42], [43, 45], [46, 51], [52, 54], [55, 62], [63, 70], [71, 74], [75, 79], [80, 81], [81, 94], [95, 98], [99, 102], [103, 108], [109, 110], [111, 115], [116, 121], [121, 122], [122, 123]]}
{"doc_key": "ai-dev-16", "ner": [[2, 4, "misc"], [34, 37, "algorithm"], [39, 43, "algorithm"], [47, 49, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[34, 37, 2, 4, "part-of", "", true, false], [39, 43, 2, 4, "part-of", "", true, false], [47, 49, 39, 43, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["En", "la", "crio", "tomograf\u00eda", "electr\u00f3nica", ",", "donde", "se", "adquiere", "un", "n\u00famero", "limitado", "de", "proyecciones", "debido", "a", "las", "limitaciones", "del", "hardware", "y", "para", "evitar", "el", "da\u00f1o", "del", "esp\u00e9cimen", "biol\u00f3gico", ",", "se", "puede", "utilizar", "junto", "con", "t\u00e9cnicas", "de", "detecci\u00f3n", "compresiva", "o", "funciones", "de", "regularizaci\u00f3n", "(", "por", "ejemplo", ",", "la", "p\u00e9rdida", "de", "Huber", ")", "para", "mejorar", "la", "reconstrucci\u00f3n", "para", "una", "mejor", "interpretaci\u00f3n", "."], "sentence-detokenized": "En la crio tomograf\u00eda electr\u00f3nica, donde se adquiere un n\u00famero limitado de proyecciones debido a las limitaciones del hardware y para evitar el da\u00f1o del esp\u00e9cimen biol\u00f3gico, se puede utilizar junto con t\u00e9cnicas de detecci\u00f3n compresiva o funciones de regularizaci\u00f3n (por ejemplo, la p\u00e9rdida de Huber) para mejorar la reconstrucci\u00f3n para una mejor interpretaci\u00f3n.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 21], [22, 33], [33, 34], [35, 40], [41, 43], [44, 52], [53, 55], [56, 62], [63, 71], [72, 74], [75, 87], [88, 94], [95, 96], [97, 100], [101, 113], [114, 117], [118, 126], [127, 128], [129, 133], [134, 140], [141, 143], [144, 148], [149, 152], [153, 162], [163, 172], [172, 173], [174, 176], [177, 182], [183, 191], [192, 197], [198, 201], [202, 210], [211, 213], [214, 223], [224, 234], [235, 236], [237, 246], [247, 249], [250, 264], [265, 266], [266, 269], [270, 277], [277, 278], [279, 281], [282, 289], [290, 292], [293, 298], [298, 299], [300, 304], [305, 312], [313, 315], [316, 330], [331, 335], [336, 339], [340, 345], [346, 360], [360, 361]]}
{"doc_key": "ai-dev-17", "ner": [[6, 6, "misc"], [8, 8, "programlang"], [13, 13, "algorithm"], [16, 17, "algorithm"], [22, 22, "algorithm"], [28, 31, "product"], [34, 34, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[6, 6, 8, 8, "part-of", "", false, false], [13, 13, 6, 6, "type-of", "", false, false], [16, 17, 6, 6, "type-of", "", false, false], [22, 22, 6, 6, "type-of", "", false, false], [28, 31, 8, 8, "general-affiliation", "", true, false], [28, 31, 8, 8, "part-of", "", true, false], [34, 34, 28, 31, "role", "publishes", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Una", "implementaci\u00f3n", "de", "varios", "procedimientos", "de", "blanqueo", "en", "R", ",", "incluyendo", "el", "blanqueo", "ZCA", "y", "el", "blanqueo", "PCA", "pero", "tambi\u00e9n", "el", "blanqueo", "CCA", ",", "est\u00e1", "disponible", "en", "el", "paquete", "R", "de", "blanqueo", "publicado", "en", "CRAN", "."], "sentence-detokenized": "Una implementaci\u00f3n de varios procedimientos de blanqueo en R, incluyendo el blanqueo ZCA y el blanqueo PCA pero tambi\u00e9n el blanqueo CCA, est\u00e1 disponible en el paquete R de blanqueo publicado en CRAN.", "token2charspan": [[0, 3], [4, 18], [19, 21], [22, 28], [29, 43], [44, 46], [47, 55], [56, 58], [59, 60], [60, 61], [62, 72], [73, 75], [76, 84], [85, 88], [89, 90], [91, 93], [94, 102], [103, 106], [107, 111], [112, 119], [120, 122], [123, 131], [132, 135], [135, 136], [137, 141], [142, 152], [153, 155], [156, 158], [159, 166], [167, 168], [169, 171], [172, 180], [181, 190], [191, 193], [194, 198], [198, 199]]}
{"doc_key": "ai-dev-18", "ner": [[33, 33, "product"], [35, 35, "product"], [37, 37, "product"], [39, 39, "product"], [41, 41, "product"], [43, 43, "product"], [46, 47, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[33, 33, 37, 37, "compare", "", false, false], [33, 33, 39, 39, "compare", "", false, false], [33, 33, 41, 41, "compare", "", false, false], [33, 33, 43, 43, "compare", "", false, false], [33, 33, 46, 47, "compare", "", false, false], [35, 35, 37, 37, "compare", "", false, false], [35, 35, 39, 39, "compare", "", false, false], [35, 35, 41, 41, "compare", "", false, false], [35, 35, 43, 43, "compare", "", false, false], [35, 35, 46, 47, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Hoy", "en", "d\u00eda", ",", "este", "campo", "se", "ha", "vuelto", "a\u00fan", "m\u00e1s", "abrumador", "y", "complejo", "con", "la", "incorporaci\u00f3n", "de", "lenguajes", "y", "software", "de", "an\u00e1lisis", "y", "dise\u00f1o", "de", "circuitos", ",", "sistemas", "y", "se\u00f1ales", ",", "desde", "MATLAB", "y", "Simulink", "hasta", "NumPy", ",", "VHDL", ",", "PSpice", ",", "Verilog", "e", "incluso", "lenguaje", "ensamblador", "."], "sentence-detokenized": "Hoy en d\u00eda, este campo se ha vuelto a\u00fan m\u00e1s abrumador y complejo con la incorporaci\u00f3n de lenguajes y software de an\u00e1lisis y dise\u00f1o de circuitos, sistemas y se\u00f1ales, desde MATLAB y Simulink hasta NumPy, VHDL, PSpice, Verilog e incluso lenguaje ensamblador.", "token2charspan": [[0, 3], [4, 6], [7, 10], [10, 11], [12, 16], [17, 22], [23, 25], [26, 28], [29, 35], [36, 39], [40, 43], [44, 53], [54, 55], [56, 64], [65, 68], [69, 71], [72, 85], [86, 88], [89, 98], [99, 100], [101, 109], [110, 112], [113, 121], [122, 123], [124, 130], [131, 133], [134, 143], [143, 144], [145, 153], [154, 155], [156, 163], [163, 164], [165, 170], [171, 177], [178, 179], [180, 188], [189, 194], [195, 200], [200, 201], [202, 206], [206, 207], [208, 214], [214, 215], [216, 223], [224, 225], [226, 233], [234, 242], [243, 254], [254, 255]]}
{"doc_key": "ai-dev-19", "ner": [[5, 6, "person"], [16, 17, "person"], [19, 20, "organisation"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[19, 20, 16, 17, "origin", "", false, false], [24, 24, 19, 20, "artifact", "builds", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "empresa", "fue", "fundada", "por", "Kiichiro", "Toyoda", "en", "1937", ",", "como", "una", "escisi\u00f3n", "de", "la", "compa\u00f1\u00eda", "Sakichi", "Toyoda", ",", "Toyota", "Industries", ",", "para", "crear", "autom\u00f3viles", "."], "sentence-detokenized": "La empresa fue fundada por Kiichiro Toyoda en 1937, como una escisi\u00f3n de la compa\u00f1\u00eda Sakichi Toyoda, Toyota Industries, para crear autom\u00f3viles.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 22], [23, 26], [27, 35], [36, 42], [43, 45], [46, 50], [50, 51], [52, 56], [57, 60], [61, 69], [70, 72], [73, 75], [76, 84], [85, 92], [93, 99], [99, 100], [101, 107], [108, 118], [118, 119], [120, 124], [125, 130], [131, 142], [142, 143]]}
{"doc_key": "ai-dev-20", "ner": [[0, 3, "field"], [60, 60, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[60, 60, 0, 3, "origin", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["El", "aprendizaje", "no", "supervisado", ",", "por", "su", "parte", ",", "parte", "de", "datos", "de", "entrenamiento", "que", "no", "han", "sido", "etiquetados", "a", "mano", ",", "e", "intenta", "encontrar", "patrones", "inherentes", "en", "los", "datos", "que", "puedan", "utilizarse", "para", "determinar", "el", "valor", "de", "salida", "correcto", "para", "las", "nuevas", "instancias", "de", "datos", "...", "Una", "combinaci\u00f3n", "de", "los", "dos", "que", "se", "ha", "explorado", "recientemente", "es", "el", "aprendizaje", "semisupervisado", ",", "que", "utiliza", "una", "combinaci\u00f3n", "de", "datos", "etiquetados", "y", "no", "etiquetados", "(", "normalmente", "un", "peque\u00f1o", "conjunto", "de", "datos", "etiquetados", "combinados", "con", "una", "gran", "cantidad", "de", "datos", "no", "etiquetados", ")", "."], "sentence-detokenized": "El aprendizaje no supervisado, por su parte, parte de datos de entrenamiento que no han sido etiquetados a mano, e intenta encontrar patrones inherentes en los datos que puedan utilizarse para determinar el valor de salida correcto para las nuevas instancias de datos... Una combinaci\u00f3n de los dos que se ha explorado recientemente es el aprendizaje semisupervisado, que utiliza una combinaci\u00f3n de datos etiquetados y no etiquetados (normalmente un peque\u00f1o conjunto de datos etiquetados combinados con una gran cantidad de datos no etiquetados).", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 29], [29, 30], [31, 34], [35, 37], [38, 43], [43, 44], [45, 50], [51, 53], [54, 59], [60, 62], [63, 76], [77, 80], [81, 83], [84, 87], [88, 92], [93, 104], [105, 106], [107, 111], [111, 112], [113, 114], [115, 122], [123, 132], [133, 141], [142, 152], [153, 155], [156, 159], [160, 165], [166, 169], [170, 176], [177, 187], [188, 192], [193, 203], [204, 206], [207, 212], [213, 215], [216, 222], [223, 231], [232, 236], [237, 240], [241, 247], [248, 258], [259, 261], [262, 267], [267, 270], [271, 274], [275, 286], [287, 289], [290, 293], [294, 297], [298, 301], [302, 304], [305, 307], [308, 317], [318, 331], [332, 334], [335, 337], [338, 349], [350, 365], [365, 366], [367, 370], [371, 378], [379, 382], [383, 394], [395, 397], [398, 403], [404, 415], [416, 417], [418, 420], [421, 432], [433, 434], [434, 445], [446, 448], [449, 456], [457, 465], [466, 468], [469, 474], [475, 486], [487, 497], [498, 501], [502, 505], [506, 510], [511, 519], [520, 522], [523, 528], [529, 531], [532, 543], [543, 544], [544, 545]]}
{"doc_key": "ai-dev-21", "ner": [[24, 24, "organisation"], [22, 22, "product"], [29, 30, "organisation"], [27, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 22, 24, 24, "artifact", "", false, false], [29, 30, 27, 27, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "pesar", "de", "estos", "robots", "humanoides", "para", "usos", "utilitarios", ",", "hay", "algunos", "robots", "humanoides", "cuyo", "objetivo", "es", "el", "entretenimiento", ",", "como", "el", "QRIO", "de", "Sony", "y", "el", "RoboSapien", "de", "Wow", "Wee", "."], "sentence-detokenized": "A pesar de estos robots humanoides para usos utilitarios, hay algunos robots humanoides cuyo objetivo es el entretenimiento, como el QRIO de Sony y el RoboSapien de Wow Wee.", "token2charspan": [[0, 1], [2, 7], [8, 10], [11, 16], [17, 23], [24, 34], [35, 39], [40, 44], [45, 56], [56, 57], [58, 61], [62, 69], [70, 76], [77, 87], [88, 92], [93, 101], [102, 104], [105, 107], [108, 123], [123, 124], [125, 129], [130, 132], [133, 137], [138, 140], [141, 145], [146, 147], [148, 150], [151, 161], [162, 164], [165, 168], [169, 172], [172, 173]]}
{"doc_key": "ai-dev-22", "ner": [[0, 0, "researcher"], [7, 14, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 7, 14, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Webber", "se", "convirti\u00f3", "en", "miembro", "de", "la", "Asociaci\u00f3n", "para", "el", "Avance", "de", "la", "Inteligencia", "Artificial", "en", "1991", ","], "sentence-detokenized": "Webber se convirti\u00f3 en miembro de la Asociaci\u00f3n para el Avance de la Inteligencia Artificial en 1991,", "token2charspan": [[0, 6], [7, 9], [10, 19], [20, 22], [23, 30], [31, 33], [34, 36], [37, 47], [48, 52], [53, 55], [56, 62], [63, 65], [66, 68], [69, 81], [82, 92], [93, 95], [96, 100], [100, 101]]}
{"doc_key": "ai-dev-23", "ner": [[6, 8, "field"], [10, 12, "field"], [25, 29, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[25, 29, 6, 8, "part-of", "task_part_of_field", false, false], [25, 29, 10, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["En", "esta", "empresa", "desarroll\u00f3", "tecnolog\u00eda", "de", "miner\u00eda", "de", "datos", "y", "bases", "de", "datos", ",", "m\u00e1s", "concretamente", "ontolog\u00edas", "de", "alto", "nivel", "para", "la", "inteligencia", "y", "la", "comprensi\u00f3n", "automatizada", "del", "lenguaje", "natural", "."], "sentence-detokenized": "En esta empresa desarroll\u00f3 tecnolog\u00eda de miner\u00eda de datos y bases de datos, m\u00e1s concretamente ontolog\u00edas de alto nivel para la inteligencia y la comprensi\u00f3n automatizada del lenguaje natural.", "token2charspan": [[0, 2], [3, 7], [8, 15], [16, 26], [27, 37], [38, 40], [41, 48], [49, 51], [52, 57], [58, 59], [60, 65], [66, 68], [69, 74], [74, 75], [76, 79], [80, 93], [94, 104], [105, 107], [108, 112], [113, 118], [119, 123], [124, 126], [127, 139], [140, 141], [142, 144], [145, 156], [157, 169], [170, 173], [174, 182], [183, 190], [190, 191]]}
{"doc_key": "ai-dev-24", "ner": [[26, 28, "misc"], [31, 34, "misc"], [37, 38, "misc"], [43, 43, "country"], [46, 49, "organisation"], [51, 51, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[26, 28, 43, 43, "physical", "", false, false], [31, 34, 43, 43, "physical", "", false, false], [37, 38, 43, 43, "physical", "", false, false], [46, 49, 51, 51, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sin", "embargo", ",", "en", "los", "\u00faltimos", "a\u00f1os", ",", "se", "puede", "observar", "la", "aparici\u00f3n", "de", "diferentes", "servicios", "electr\u00f3nicos", "e", "iniciativas", "relacionadas", "en", "los", "pa\u00edses", "en", "desarrollo", "como", "el", "Proyecto", "Nemmadi", ",", "el", "Proyecto", "MCA21", "Mission", "Mode", "o", "la", "India", "Digital", "a\u00fan", "m\u00e1s", ",", "en", "India", ";", "la", "Direcci\u00f3n", "de", "Gobierno", "Electr\u00f3nico", "en", "Pakist\u00e1n", ";", "etc", "."], "sentence-detokenized": "Sin embargo, en los \u00faltimos a\u00f1os, se puede observar la aparici\u00f3n de diferentes servicios electr\u00f3nicos e iniciativas relacionadas en los pa\u00edses en desarrollo como el Proyecto Nemmadi, el Proyecto MCA21 Mission Mode o la India Digital a\u00fan m\u00e1s, en India; la Direcci\u00f3n de Gobierno Electr\u00f3nico en Pakist\u00e1n; etc.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 19], [20, 27], [28, 32], [32, 33], [34, 36], [37, 42], [43, 51], [52, 54], [55, 64], [65, 67], [68, 78], [79, 88], [89, 101], [102, 103], [104, 115], [116, 128], [129, 131], [132, 135], [136, 142], [143, 145], [146, 156], [157, 161], [162, 164], [165, 173], [174, 181], [181, 182], [183, 185], [186, 194], [195, 200], [201, 208], [209, 213], [214, 215], [216, 218], [219, 224], [225, 232], [233, 236], [237, 240], [240, 241], [242, 244], [245, 250], [250, 251], [252, 254], [255, 264], [265, 267], [268, 276], [277, 288], [289, 291], [292, 300], [300, 301], [302, 305], [305, 306]]}
{"doc_key": "ai-dev-25", "ner": [[1, 1, "misc"], [3, 3, "field"], [5, 6, "field"], [10, 13, "university"], [14, 17, "university"], [23, 26, "university"], [30, 30, "misc"], [32, 33, "field"], [37, 40, "misc"], [43, 44, "university"], [47, 49, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[1, 1, 3, 3, "topic", "", false, false], [1, 1, 5, 6, "topic", "", false, false], [1, 1, 10, 13, "origin", "", false, false], [10, 13, 14, 17, "part-of", "", false, false], [23, 26, 10, 13, "part-of", "", false, false], [30, 30, 32, 33, "topic", "", false, false], [30, 30, 43, 44, "origin", "", false, false], [37, 40, 43, 44, "origin", "", false, false], [43, 44, 47, 49, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Se", "doctor\u00f3", "en", "Radiof\u00edsica", "y", "Electr\u00f3nica", "en", "el", "campus", "del", "Rajabazar", "Science", "College", "de", "la", "Universidad", "de", "Calcuta", "en", "1979", "como", "estudiante", "del", "Instituto", "Indio", "de", "Estad\u00edstica", ",", "y", "otro", "doctorado", "en", "Ingenier\u00eda", "El\u00e9ctrica", "junto", "con", "el", "Diploma", "del", "Imperial", "College", "en", "el", "Imperial", "College", "de", "la", "Universidad", "de", "Londres", "en", "1982", "."], "sentence-detokenized": "Se doctor\u00f3 en Radiof\u00edsica y Electr\u00f3nica en el campus del Rajabazar Science College de la Universidad de Calcuta en 1979 como estudiante del Instituto Indio de Estad\u00edstica, y otro doctorado en Ingenier\u00eda El\u00e9ctrica junto con el Diploma del Imperial College en el Imperial College de la Universidad de Londres en 1982.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 25], [26, 27], [28, 39], [40, 42], [43, 45], [46, 52], [53, 56], [57, 66], [67, 74], [75, 82], [83, 85], [86, 88], [89, 100], [101, 103], [104, 111], [112, 114], [115, 119], [120, 124], [125, 135], [136, 139], [140, 149], [150, 155], [156, 158], [159, 170], [170, 171], [172, 173], [174, 178], [179, 188], [189, 191], [192, 202], [203, 212], [213, 218], [219, 222], [223, 225], [226, 233], [234, 237], [238, 246], [247, 254], [255, 257], [258, 260], [261, 269], [270, 277], [278, 280], [281, 283], [284, 295], [296, 298], [299, 306], [307, 309], [310, 314], [314, 315]]}
{"doc_key": "ai-dev-26", "ner": [[0, 4, "location"], [19, 23, "misc"], [30, 31, "misc"], [33, 35, "person"], [37, 38, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 23, 0, 4, "temporal", "", false, false], [30, 31, 0, 4, "temporal", "", false, false], [33, 35, 30, 31, "role", "actor_in", false, false], [37, 38, 30, 31, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["En", "la", "Expo", "II", "se", "anunci\u00f3", "el", "estreno", "mundial", "de", "varias", "pel\u00edculas", "nunca", "vistas", "en", "3D", ",", "entre", "ellas", "El", "mago", "de", "los", "diamantes", "y", "el", "corto", "de", "Universal", ",", "Hawaiian", "Nights", "con", "Mamie", "Van", "Doren", "y", "Pinky", "Lee", "."], "sentence-detokenized": "En la Expo II se anunci\u00f3 el estreno mundial de varias pel\u00edculas nunca vistas en 3D, entre ellas El mago de los diamantes y el corto de Universal, Hawaiian Nights con Mamie Van Doren y Pinky Lee.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 13], [14, 16], [17, 24], [25, 27], [28, 35], [36, 43], [44, 46], [47, 53], [54, 63], [64, 69], [70, 76], [77, 79], [80, 82], [82, 83], [84, 89], [90, 95], [96, 98], [99, 103], [104, 106], [107, 110], [111, 120], [121, 122], [123, 125], [126, 131], [132, 134], [135, 144], [144, 145], [146, 154], [155, 161], [162, 165], [166, 171], [172, 175], [176, 181], [182, 183], [184, 189], [190, 193], [193, 194]]}
{"doc_key": "ai-dev-27", "ner": [[9, 10, "researcher"], [19, 22, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 10, 19, 22, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["El", "problema", "de", "la", "submatriz", "m\u00e1xima", "fue", "propuesto", "por", "Ulf", "Grenander", "en", "1977", "como", "un", "modelo", "simplificado", "para", "la", "estimaci\u00f3n", "de", "m\u00e1xima", "verosimilitud", "de", "patrones", "en", "im\u00e1genes", "digitalizadas", "."], "sentence-detokenized": "El problema de la submatriz m\u00e1xima fue propuesto por Ulf Grenander en 1977 como un modelo simplificado para la estimaci\u00f3n de m\u00e1xima verosimilitud de patrones en im\u00e1genes digitalizadas.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 17], [18, 27], [28, 34], [35, 38], [39, 48], [49, 52], [53, 56], [57, 66], [67, 69], [70, 74], [75, 79], [80, 82], [83, 89], [90, 102], [103, 107], [108, 110], [111, 121], [122, 124], [125, 131], [132, 145], [146, 148], [149, 157], [158, 160], [161, 169], [170, 183], [183, 184]]}
{"doc_key": "ai-dev-28", "ner": [[1, 2, "product"], [5, 6, "product"], [9, 11, "product"], [13, 15, "product"], [18, 20, "product"], [22, 25, "product"], [38, 38, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[38, 38, 1, 2, "part-of", "", false, false], [38, 38, 5, 6, "part-of", "", false, false], [38, 38, 9, 11, "part-of", "", false, false], [38, 38, 13, 15, "part-of", "", false, false], [38, 38, 18, 20, "part-of", "", false, false], [38, 38, 22, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["El", "iPhone", "4S", ",", "el", "iPad", "3", ",", "el", "iPad", "Mini", "1G", ",", "el", "iPad", "Air", ",", "el", "iPad", "Pro", "1G", "y", "el", "iPod", "Touch", "5G", "y", "posteriores", ",", "vienen", "con", "un", "asistente", "de", "voz", "m\u00e1s", "avanzado", "llamado", "Siri", "."], "sentence-detokenized": "El iPhone 4S, el iPad 3, el iPad Mini 1G, el iPad Air, el iPad Pro 1G y el iPod Touch 5G y posteriores, vienen con un asistente de voz m\u00e1s avanzado llamado Siri.", "token2charspan": [[0, 2], [3, 9], [10, 12], [12, 13], [14, 16], [17, 21], [22, 23], [23, 24], [25, 27], [28, 32], [33, 37], [38, 40], [40, 41], [42, 44], [45, 49], [50, 53], [53, 54], [55, 57], [58, 62], [63, 66], [67, 69], [70, 71], [72, 74], [75, 79], [80, 85], [86, 88], [89, 90], [91, 102], [102, 103], [104, 110], [111, 114], [115, 117], [118, 127], [128, 130], [131, 134], [135, 138], [139, 147], [148, 155], [156, 160], [160, 161]]}
{"doc_key": "ai-dev-29", "ner": [[5, 6, "metrics"], [13, 13, "metrics"], [15, 16, "metrics"], [52, 52, "metrics"], [58, 60, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 13, 52, 52, "named", "", false, false], [15, 16, 13, 13, "named", "", false, false], [52, 52, 58, 60, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Es", "f\u00e1cil", "comprobar", "que", "la", "p\u00e9rdida", "log\u00edstica", "y", "la", "p\u00e9rdida", "de", "entrop\u00eda", "cruzada", "binaria", "(", "p\u00e9rdida", "logar\u00edtmica", ")", "son", ",", "de", "hecho", ",", "la", "misma", "(", "hasta", "una", "constante", "multiplicativa", "math", "\\", "frac", "{", "1", "}", "{", "\\", "log", "(", "2", ")", "}", "/", "math", ")", ".", "{", "La", "p\u00e9rdida", "de", "entrop\u00eda", "cruzada", "est\u00e1", "estrechamente", "relacionada", "con", "la", "divergencia", "de", "Kullback-Leibler", "entre", "la", "distribuci\u00f3n", "emp\u00edrica", "y", "la", "distribuci\u00f3n", "predicha", "."], "sentence-detokenized": "Es f\u00e1cil comprobar que la p\u00e9rdida log\u00edstica y la p\u00e9rdida de entrop\u00eda cruzada binaria (p\u00e9rdida logar\u00edtmica) son, de hecho, la misma (hasta una constante multiplicativa math\\ frac {1} {\\ log (2)} / math). {La p\u00e9rdida de entrop\u00eda cruzada est\u00e1 estrechamente relacionada con la divergencia de Kullback-Leibler entre la distribuci\u00f3n emp\u00edrica y la distribuci\u00f3n predicha.", "token2charspan": [[0, 2], [3, 8], [9, 18], [19, 22], [23, 25], [26, 33], [34, 43], [44, 45], [46, 48], [49, 56], [57, 59], [60, 68], [69, 76], [77, 84], [85, 86], [86, 93], [94, 105], [105, 106], [107, 110], [110, 111], [112, 114], [115, 120], [120, 121], [122, 124], [125, 130], [131, 132], [132, 137], [138, 141], [142, 151], [152, 166], [167, 171], [171, 172], [173, 177], [178, 179], [179, 180], [180, 181], [182, 183], [183, 184], [185, 188], [189, 190], [190, 191], [191, 192], [192, 193], [194, 195], [196, 200], [200, 201], [201, 202], [203, 204], [204, 206], [207, 214], [215, 217], [218, 226], [227, 234], [235, 239], [240, 253], [254, 265], [266, 269], [270, 272], [273, 284], [285, 287], [288, 304], [305, 310], [311, 313], [314, 326], [327, 335], [336, 337], [338, 340], [341, 353], [354, 362], [362, 363]]}
{"doc_key": "ai-dev-30", "ner": [[1, 2, "algorithm"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 14, 1, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["El", "algoritmo", "EM", "se", "utiliza", "para", "encontrar", "los", "par\u00e1metros", "(", "locales", ")", "de", "m\u00e1xima", "verosimilitud", "de", "un", "modelo", "estad\u00edstico", "en", "los", "casos", "en", "que", "las", "ecuaciones", "no", "pueden", "resolverse", "directamente", "."], "sentence-detokenized": "El algoritmo EM se utiliza para encontrar los par\u00e1metros (locales) de m\u00e1xima verosimilitud de un modelo estad\u00edstico en los casos en que las ecuaciones no pueden resolverse directamente.", "token2charspan": [[0, 2], [3, 12], [13, 15], [16, 18], [19, 26], [27, 31], [32, 41], [42, 45], [46, 56], [57, 58], [58, 65], [65, 66], [67, 69], [70, 76], [77, 90], [91, 93], [94, 96], [97, 103], [104, 115], [116, 118], [119, 122], [123, 128], [129, 131], [132, 135], [136, 139], [140, 150], [151, 153], [154, 160], [161, 171], [172, 184], [184, 185]]}
{"doc_key": "ai-dev-31", "ner": [[12, 14, "task"], [17, 21, "task"], [27, 27, "task"], [30, 32, "task"], [39, 45, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Esta", "investigaci\u00f3n", "fue", "fundamental", "para", "el", "desarrollo", "de", "las", "t\u00e9cnicas", "modernas", "de", "s\u00edntesis", "del", "habla", ",", "las", "m\u00e1quinas", "de", "lectura", "para", "ciegos", ",", "el", "estudio", "de", "la", "percepci\u00f3n", "y", "el", "reconocimiento", "del", "habla", ",", "y", "el", "desarrollo", "de", "la", "teor\u00eda", "motora", "de", "la", "percepci\u00f3n", "del", "habla", "."], "sentence-detokenized": "Esta investigaci\u00f3n fue fundamental para el desarrollo de las t\u00e9cnicas modernas de s\u00edntesis del habla, las m\u00e1quinas de lectura para ciegos, el estudio de la percepci\u00f3n y el reconocimiento del habla, y el desarrollo de la teor\u00eda motora de la percepci\u00f3n del habla.", "token2charspan": [[0, 4], [5, 18], [19, 22], [23, 34], [35, 39], [40, 42], [43, 53], [54, 56], [57, 60], [61, 69], [70, 78], [79, 81], [82, 90], [91, 94], [95, 100], [100, 101], [102, 105], [106, 114], [115, 117], [118, 125], [126, 130], [131, 137], [137, 138], [139, 141], [142, 149], [150, 152], [153, 155], [156, 166], [167, 168], [169, 171], [172, 186], [187, 190], [191, 196], [196, 197], [198, 199], [200, 202], [203, 213], [214, 216], [217, 219], [220, 226], [227, 233], [234, 236], [237, 239], [240, 250], [251, 254], [255, 260], [260, 261]]}
{"doc_key": "ai-dev-32", "ner": [[8, 9, "product"], [1, 4, "misc"], [6, 6, "misc"], [12, 13, "misc"], [16, 16, "product"], [18, 18, "product"], [20, 20, "product"], [30, 30, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[1, 4, 8, 9, "origin", "", false, false], [1, 4, 12, 13, "type-of", "", false, false], [1, 4, 16, 16, "related-to", "program_for", false, false], [1, 4, 18, 18, "related-to", "program_for", false, false], [1, 4, 20, 20, "related-to", "program_for", false, false], [1, 4, 30, 30, "related-to", "program_for", false, false], [6, 6, 1, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["El", "entorno", "de", "desarrollo", "integrado", "(", "IDE", ")", "de", "Arduino", "es", "una", "aplicaci\u00f3n", "multiplataforma", "(", "para", "Windows", ",", "macOS", "y", "Linux", ")", "que", "est\u00e1", "escrita", "en", "el", "lenguaje", "de", "programaci\u00f3n", "Java", "."], "sentence-detokenized": "El entorno de desarrollo integrado (IDE) de Arduino es una aplicaci\u00f3n multiplataforma (para Windows, macOS y Linux) que est\u00e1 escrita en el lenguaje de programaci\u00f3n Java.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 24], [25, 34], [35, 36], [36, 39], [39, 40], [41, 43], [44, 51], [52, 54], [55, 58], [59, 69], [70, 85], [86, 87], [87, 91], [92, 99], [99, 100], [101, 106], [107, 108], [109, 114], [114, 115], [116, 119], [120, 124], [125, 132], [133, 135], [136, 138], [139, 147], [148, 150], [151, 163], [164, 168], [168, 169]]}
{"doc_key": "ai-dev-33", "ner": [[3, 4, "algorithm"], [13, 15, "field"], [17, 18, "researcher"], [20, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 13, 15, "opposite", "", false, false], [17, 18, 13, 15, "related-to", "works_with", false, false], [20, 21, 13, 15, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "investigaci\u00f3n", "sobre", "redes", "neuronales", "se", "estanc\u00f3", "tras", "la", "publicaci\u00f3n", "de", "las", "investigaciones", "sobre", "aprendizaje", "autom\u00e1tico", "de", "Marvin", "Minsky", "y", "Seymour", "Papert", "(", "1969", ")", "."], "sentence-detokenized": "La investigaci\u00f3n sobre redes neuronales se estanc\u00f3 tras la publicaci\u00f3n de las investigaciones sobre aprendizaje autom\u00e1tico de Marvin Minsky y Seymour Papert (1969).", "token2charspan": [[0, 2], [3, 16], [17, 22], [23, 28], [29, 39], [40, 42], [43, 50], [51, 55], [56, 58], [59, 70], [71, 73], [74, 77], [78, 93], [94, 99], [100, 111], [112, 122], [123, 125], [126, 132], [133, 139], [140, 141], [142, 149], [150, 156], [157, 158], [158, 162], [162, 163], [163, 164]]}
{"doc_key": "ai-dev-34", "ner": [[17, 18, "organisation"], [20, 20, "organisation"], [24, 24, "country"], [25, 28, "organisation"], [31, 31, "country"], [32, 33, "organisation"], [36, 36, "country"], [37, 37, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[25, 28, 24, 24, "general-affiliation", "", false, false], [32, 33, 31, 31, "general-affiliation", "", false, false], [37, 37, 36, 36, "general-affiliation", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["S\u00f3lo", "unas", "pocas", "empresas", "no", "japonesas", "consiguieron", "finalmente", "sobrevivir", "en", "este", "mercado", ",", "siendo", "las", "principales", ":", "Adept", "Technology", ",", "St\u00e4ubli", ",", "la", "empresa", "sueco-suiza", "ABB", "Asea", "Brown", "Boveri", ",", "la", "alemana", "KUKA", "Robotics", "y", "la", "italiana", "Comau", "."], "sentence-detokenized": "S\u00f3lo unas pocas empresas no japonesas consiguieron finalmente sobrevivir en este mercado, siendo las principales: Adept Technology, St\u00e4ubli, la empresa sueco-suiza ABB Asea Brown Boveri, la alemana KUKA Robotics y la italiana Comau.", "token2charspan": [[0, 4], [5, 9], [10, 15], [16, 24], [25, 27], [28, 37], [38, 50], [51, 61], [62, 72], [73, 75], [76, 80], [81, 88], [88, 89], [90, 96], [97, 100], [101, 112], [112, 113], [114, 119], [120, 130], [130, 131], [132, 139], [139, 140], [141, 143], [144, 151], [152, 163], [164, 167], [168, 172], [173, 178], [179, 185], [185, 186], [187, 189], [190, 197], [198, 202], [203, 211], [212, 213], [214, 216], [217, 225], [226, 231], [231, 232]]}
{"doc_key": "ai-dev-35", "ner": [[12, 13, "conference"], [18, 18, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 18, 12, 13, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Las", "actividades", "de", "investigaci\u00f3n", "incluyen", "una", "conferencia", "anual", "de", "investigaci\u00f3n", ",", "el", "Simposio", "RuleML", ",", "tambi\u00e9n", "conocido", "como", "RuleML", "para", "abreviar", "."], "sentence-detokenized": "Las actividades de investigaci\u00f3n incluyen una conferencia anual de investigaci\u00f3n, el Simposio RuleML, tambi\u00e9n conocido como RuleML para abreviar.", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 32], [33, 41], [42, 45], [46, 57], [58, 63], [64, 66], [67, 80], [80, 81], [82, 84], [85, 93], [94, 100], [100, 101], [102, 109], [110, 118], [119, 123], [124, 130], [131, 135], [136, 144], [144, 145]]}
{"doc_key": "ai-dev-36", "ner": [[10, 10, "field"], [12, 12, "field"], [14, 16, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Los", "conceptos", "se", "utilizan", "como", "herramientas", "o", "modelos", "formales", "en", "matem\u00e1ticas", ",", "inform\u00e1tica", ",", "bases", "de", "datos", "e", "inteligencia", "artificial", ",", "donde", "a", "veces", "se", "denominan", "clases", ",", "esquemas", "o", "categor\u00edas", "."], "sentence-detokenized": "Los conceptos se utilizan como herramientas o modelos formales en matem\u00e1ticas, inform\u00e1tica, bases de datos e inteligencia artificial, donde a veces se denominan clases, esquemas o categor\u00edas.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 25], [26, 30], [31, 43], [44, 45], [46, 53], [54, 62], [63, 65], [66, 77], [77, 78], [79, 90], [90, 91], [92, 97], [98, 100], [101, 106], [107, 108], [109, 121], [122, 132], [132, 133], [134, 139], [140, 141], [142, 147], [148, 150], [151, 160], [161, 167], [167, 168], [169, 177], [178, 179], [180, 190], [190, 191]]}
{"doc_key": "ai-dev-37", "ner": [[5, 8, "organisation"], [11, 14, "organisation"], [17, 17, "organisation"], [20, 23, "organisation"], [26, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ha", "recibido", "premios", "de", "la", "Asociaci\u00f3n", "Americana", "de", "Psicolog\u00eda", ",", "la", "Academia", "Nacional", "de", "Ciencias", ",", "la", "Royal", ",", "la", "Sociedad", "de", "Neurociencia", "Cognitiva", "y", "la", "Asociaci\u00f3n", "Humanista", "Americana", "."], "sentence-detokenized": "Ha recibido premios de la Asociaci\u00f3n Americana de Psicolog\u00eda, la Academia Nacional de Ciencias, la Royal, la Sociedad de Neurociencia Cognitiva y la Asociaci\u00f3n Humanista Americana.", "token2charspan": [[0, 2], [3, 11], [12, 19], [20, 22], [23, 25], [26, 36], [37, 46], [47, 49], [50, 60], [60, 61], [62, 64], [65, 73], [74, 82], [83, 85], [86, 94], [94, 95], [96, 98], [99, 104], [104, 105], [106, 108], [109, 117], [118, 120], [121, 133], [134, 143], [144, 145], [146, 148], [149, 159], [160, 169], [170, 179], [179, 180]]}
{"doc_key": "ai-dev-38", "ner": [[2, 3, "person"], [5, 6, "person"], [8, 9, "person"], [18, 19, "person"], [21, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[21, 28, 18, 19, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Protagonizada", "por", "Harrison", "Ford", ",", "Rutger", "Hauer", "y", "Sean", "Young", ",", "se", "basa", "libremente", "en", "la", "novela", "de", "Philip", "K.", "Dick", "\u00bf", "Sue\u00f1an", "los", "androides", "con", "ovejas", "el\u00e9ctricas", "?", "(", "1968", ")", "."], "sentence-detokenized": "Protagonizada por Harrison Ford, Rutger Hauer y Sean Young, se basa libremente en la novela de Philip K. Dick \u00bfSue\u00f1an los androides con ovejas el\u00e9ctricas? (1968).", "token2charspan": [[0, 13], [14, 17], [18, 26], [27, 31], [31, 32], [33, 39], [40, 45], [46, 47], [48, 52], [53, 58], [58, 59], [60, 62], [63, 67], [68, 78], [79, 81], [82, 84], [85, 91], [92, 94], [95, 101], [102, 104], [105, 109], [110, 111], [111, 117], [118, 121], [122, 131], [132, 135], [136, 142], [143, 153], [153, 154], [155, 156], [156, 160], [160, 161], [161, 162]]}
{"doc_key": "ai-dev-39", "ner": [[0, 3, "task"], [5, 10, "algorithm"], [18, 20, "field"], [23, 25, "task"], [27, 29, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 5, 10, "usage", "", false, false], [0, 3, 18, 20, "part-of", "task_part_of_field", false, false], [0, 3, 23, 25, "part-of", "task_part_of_field", false, false], [0, 3, 27, 29, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["La", "segmentaci\u00f3n", "de", "im\u00e1genes", "mediante", "algoritmos", "de", "agrupaci\u00f3n", "de", "k-means", "se", "ha", "utilizado", "durante", "mucho", "tiempo", "para", "el", "reconocimiento", "de", "patrones", ",", "la", "detecci\u00f3n", "de", "objetos", "y", "las", "im\u00e1genes", "m\u00e9dicas", "."], "sentence-detokenized": "La segmentaci\u00f3n de im\u00e1genes mediante algoritmos de agrupaci\u00f3n de k-means se ha utilizado durante mucho tiempo para el reconocimiento de patrones, la detecci\u00f3n de objetos y las im\u00e1genes m\u00e9dicas.", "token2charspan": [[0, 2], [3, 15], [16, 18], [19, 27], [28, 36], [37, 47], [48, 50], [51, 61], [62, 64], [65, 72], [73, 75], [76, 78], [79, 88], [89, 96], [97, 102], [103, 109], [110, 114], [115, 117], [118, 132], [133, 135], [136, 144], [144, 145], [146, 148], [149, 158], [159, 161], [162, 169], [170, 171], [172, 175], [176, 184], [185, 192], [192, 193]]}
{"doc_key": "ai-dev-40", "ner": [[13, 13, "algorithm"], [17, 18, "algorithm"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["El", "muestreo", "general", "de", "la", "normal", "truncada", "puede", "lograrse", "utilizando", "aproximaciones", "a", "la", "CDF", "normal", "y", "la", "funci\u00f3n", "probit", ",", "y", "R", "tiene", "una", "funci\u00f3n", "codertnorm", "(", ")", "/", "c\u00f3digo", "para", "generar", "muestras", "normales", "truncadas", "."], "sentence-detokenized": "El muestreo general de la normal truncada puede lograrse utilizando aproximaciones a la CDF normal y la funci\u00f3n probit, y R tiene una funci\u00f3n codertnorm () / c\u00f3digo para generar muestras normales truncadas.", "token2charspan": [[0, 2], [3, 11], [12, 19], [20, 22], [23, 25], [26, 32], [33, 41], [42, 47], [48, 56], [57, 67], [68, 82], [83, 84], [85, 87], [88, 91], [92, 98], [99, 100], [101, 103], [104, 111], [112, 118], [118, 119], [120, 121], [122, 123], [124, 129], [130, 133], [134, 141], [142, 152], [153, 154], [154, 155], [156, 157], [158, 164], [165, 169], [170, 177], [178, 186], [187, 195], [196, 205], [205, 206]]}
{"doc_key": "ai-dev-41", "ner": [[7, 9, "university"], [11, 11, "university"], [13, 14, "university"], [16, 17, "university"], [19, 19, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Tambi\u00e9n", "ha", "recibido", "doctorados", "honor\u00edficos", "de", "las", "universidades", "de", "Newcastle", ",", "Surrey", ",", "Tel", "Aviv", ",", "Simon", "Fraser", "y", "Troms\u00f8", "."], "sentence-detokenized": "Tambi\u00e9n ha recibido doctorados honor\u00edficos de las universidades de Newcastle, Surrey, Tel Aviv, Simon Fraser y Troms\u00f8.", "token2charspan": [[0, 7], [8, 10], [11, 19], [20, 30], [31, 42], [43, 45], [46, 49], [50, 63], [64, 66], [67, 76], [76, 77], [78, 84], [84, 85], [86, 89], [90, 94], [94, 95], [96, 101], [102, 108], [109, 110], [111, 117], [117, 118]]}
{"doc_key": "ai-dev-42", "ner": [[3, 3, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Una", "implementaci\u00f3n", "de", "Java", "que", "utiliza", "\u00edndices", "de", "matrices", "basados", "en", "cero", "junto", "con", "un", "m\u00e9todo", "conveniente", "para", "imprimir", "el", "orden", "de", "operaciones", "resuelto", ":"], "sentence-detokenized": "Una implementaci\u00f3n de Java que utiliza \u00edndices de matrices basados en cero junto con un m\u00e9todo conveniente para imprimir el orden de operaciones resuelto:", "token2charspan": [[0, 3], [4, 18], [19, 21], [22, 26], [27, 30], [31, 38], [39, 46], [47, 49], [50, 58], [59, 66], [67, 69], [70, 74], [75, 80], [81, 84], [85, 87], [88, 94], [95, 106], [107, 111], [112, 120], [121, 123], [124, 129], [130, 132], [133, 144], [145, 153], [153, 154]]}
{"doc_key": "ai-dev-43", "ner": [[9, 10, "metrics"], [13, 14, "metrics"], [26, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 14, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Este", "tipo", "de", "redes", "suelen", "entrenarse", "en", "r\u00e9gimen", "de", "entrop\u00eda", "cruzada", "(", "o", "entrop\u00eda", "cruzada", ")", ",", "dando", "lugar", "a", "una", "variante", "no", "lineal", "de", "la", "regresi\u00f3n", "log\u00edstica", "multinomial", "."], "sentence-detokenized": "Este tipo de redes suelen entrenarse en r\u00e9gimen de entrop\u00eda cruzada (o entrop\u00eda cruzada), dando lugar a una variante no lineal de la regresi\u00f3n log\u00edstica multinomial.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 18], [19, 25], [26, 36], [37, 39], [40, 47], [48, 50], [51, 59], [60, 67], [68, 69], [69, 70], [71, 79], [80, 87], [87, 88], [88, 89], [90, 95], [96, 101], [102, 103], [104, 107], [108, 116], [117, 119], [120, 126], [127, 129], [130, 132], [133, 142], [143, 152], [153, 164], [164, 165]]}
{"doc_key": "ai-dev-44", "ner": [[1, 1, "conference"], [5, 5, "misc"], [4, 14, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 1, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["La", "ACL", "tiene", "un", "cap\u00edtulo", "europeo", "(", "European", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ")"], "sentence-detokenized": "La ACL tiene un cap\u00edtulo europeo (European Chapter of the Association for Computational Linguistics)", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 24], [25, 32], [33, 34], [34, 42], [43, 50], [51, 53], [54, 57], [58, 69], [70, 73], [74, 87], [88, 99], [99, 100]]}
{"doc_key": "ai-dev-45", "ner": [[3, 4, "researcher"], [6, 8, "researcher"], [23, 23, "misc"], [25, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 23, 23, "role", "", false, false], [6, 8, 23, 23, "role", "", false, false], [23, 23, 25, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dos", "profesores", ",", "Hal", "Abelson", "y", "Gerald", "Jay", "Sussman", ",", "optaron", "por", "permanecer", "neutrales", ";", "su", "grupo", "fue", "denominado", "de", "diversas", "maneras", "como", "Suiza", "y", "Proyecto", "MAC", "durante", "los", "siguientes", "30", "a\u00f1os", "."], "sentence-detokenized": "Dos profesores, Hal Abelson y Gerald Jay Sussman, optaron por permanecer neutrales; su grupo fue denominado de diversas maneras como Suiza y Proyecto MAC durante los siguientes 30 a\u00f1os.", "token2charspan": [[0, 3], [4, 14], [14, 15], [16, 19], [20, 27], [28, 29], [30, 36], [37, 40], [41, 48], [48, 49], [50, 57], [58, 61], [62, 72], [73, 82], [82, 83], [84, 86], [87, 92], [93, 96], [97, 107], [108, 110], [111, 119], [120, 127], [128, 132], [133, 138], [139, 140], [141, 149], [150, 153], [154, 161], [162, 165], [166, 176], [177, 179], [180, 184], [184, 185]]}
{"doc_key": "ai-dev-46", "ner": [[2, 2, "misc"], [4, 4, "researcher"], [9, 11, "university"], [17, 18, "organisation"], [21, 24, "organisation"], [28, 29, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 4, 4, "temporal", "", false, false], [4, 4, 17, 18, "physical", "", false, false], [4, 4, 17, 18, "role", "", false, false], [4, 4, 21, 24, "role", "", false, false], [21, 24, 9, 11, "part-of", "", false, false], [28, 29, 21, 24, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Tras", "su", "doctorado", ",", "Ghahramani", "se", "traslad\u00f3", "a", "la", "Universidad", "de", "Toronto", "en", "1995", "como", "becario", "postdoctoral", "del", "ITRC", "en", "el", "Laboratorio", "de", "Inteligencia", "Artificial", ",", "trabajando", "con", "Geoffrey", "Hinton", "."], "sentence-detokenized": "Tras su doctorado, Ghahramani se traslad\u00f3 a la Universidad de Toronto en 1995 como becario postdoctoral del ITRC en el Laboratorio de Inteligencia Artificial, trabajando con Geoffrey Hinton.", "token2charspan": [[0, 4], [5, 7], [8, 17], [17, 18], [19, 29], [30, 32], [33, 41], [42, 43], [44, 46], [47, 58], [59, 61], [62, 69], [70, 72], [73, 77], [78, 82], [83, 90], [91, 103], [104, 107], [108, 112], [113, 115], [116, 118], [119, 130], [131, 133], [134, 146], [147, 157], [157, 158], [159, 169], [170, 173], [174, 182], [183, 189], [189, 190]]}
{"doc_key": "ai-dev-47", "ner": [[28, 29, "metrics"], [31, 31, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[31, 31, 28, 29, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Los", "trabajos", "posteriores", "se", "centraron", "en", "abordar", "estos", "problemas", ",", "pero", "no", "fue", "hasta", "la", "llegada", "del", "ordenador", "moderno", "y", "la", "popularizaci\u00f3n", "de", "las", "t\u00e9cnicas", "de", "parametrizaci\u00f3n", "de", "M\u00e1xima", "Verosimilitud", "(", "MLE", ")", "que", "la", "investigaci\u00f3n", "despeg\u00f3", "realmente", "."], "sentence-detokenized": "Los trabajos posteriores se centraron en abordar estos problemas, pero no fue hasta la llegada del ordenador moderno y la popularizaci\u00f3n de las t\u00e9cnicas de parametrizaci\u00f3n de M\u00e1xima Verosimilitud (MLE) que la investigaci\u00f3n despeg\u00f3 realmente.", "token2charspan": [[0, 3], [4, 12], [13, 24], [25, 27], [28, 37], [38, 40], [41, 48], [49, 54], [55, 64], [64, 65], [66, 70], [71, 73], [74, 77], [78, 83], [84, 86], [87, 94], [95, 98], [99, 108], [109, 116], [117, 118], [119, 121], [122, 136], [137, 139], [140, 143], [144, 152], [153, 155], [156, 171], [172, 174], [175, 181], [182, 195], [196, 197], [197, 200], [200, 201], [202, 205], [206, 208], [209, 222], [223, 230], [231, 240], [240, 241]]}
{"doc_key": "ai-dev-48", "ner": [[5, 6, "person"], [10, 11, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "serie", "fue", "producida", "por", "David", "Fincher", "y", "protagonizada", "por", "Kevin", "Spacey", "."], "sentence-detokenized": "La serie fue producida por David Fincher y protagonizada por Kevin Spacey.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 22], [23, 26], [27, 32], [33, 40], [41, 42], [43, 56], [57, 60], [61, 66], [67, 73], [73, 74]]}
{"doc_key": "ai-dev-49", "ner": [[23, 23, "metrics"], [32, 34, "algorithm"], [38, 41, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[32, 34, 38, 41, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Debido", "a", "los", "l\u00edmites", "de", "la", "potencia", "de", "c\u00e1lculo", ",", "los", "m\u00e9todos", "in", "silico", "actuales", "suelen", "tener", "que", "cambiar", "la", "velocidad", "por", "la", "precisi\u00f3n", ";", "por", "ejemplo", ",", "utilizar", "m\u00e9todos", "r\u00e1pidos", "de", "acoplamiento", "de", "prote\u00ednas", "en", "lugar", "de", "c\u00e1lculos", "de", "energ\u00eda", "libre", "que", "son", "costosos", "desde", "el", "punto", "de", "vista", "inform\u00e1tico", "."], "sentence-detokenized": "Debido a los l\u00edmites de la potencia de c\u00e1lculo, los m\u00e9todos in silico actuales suelen tener que cambiar la velocidad por la precisi\u00f3n; por ejemplo, utilizar m\u00e9todos r\u00e1pidos de acoplamiento de prote\u00ednas en lugar de c\u00e1lculos de energ\u00eda libre que son costosos desde el punto de vista inform\u00e1tico.", "token2charspan": [[0, 6], [7, 8], [9, 12], [13, 20], [21, 23], [24, 26], [27, 35], [36, 38], [39, 46], [46, 47], [48, 51], [52, 59], [60, 62], [63, 69], [70, 78], [79, 85], [86, 91], [92, 95], [96, 103], [104, 106], [107, 116], [117, 120], [121, 123], [124, 133], [133, 134], [135, 138], [139, 146], [146, 147], [148, 156], [157, 164], [165, 172], [173, 175], [176, 188], [189, 191], [192, 201], [202, 204], [205, 210], [211, 213], [214, 222], [223, 225], [226, 233], [234, 239], [240, 243], [244, 247], [248, 256], [257, 262], [263, 265], [266, 271], [272, 274], [275, 280], [281, 292], [292, 293]]}
{"doc_key": "ai-dev-50", "ner": [[7, 7, "country"], [9, 9, "country"], [11, 11, "country"], [13, 13, "country"], [15, 15, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ten\u00eda", "m\u00e1s", "de", "30", "locales", "en", "Estados", "Unidos", ",", "Canad\u00e1", ",", "M\u00e9xico", ",", "Brasil", "y", "Argentina", "."], "sentence-detokenized": "Ten\u00eda m\u00e1s de 30 locales en Estados Unidos, Canad\u00e1, M\u00e9xico, Brasil y Argentina.", "token2charspan": [[0, 5], [6, 9], [10, 12], [13, 15], [16, 23], [24, 26], [27, 34], [35, 41], [41, 42], [43, 49], [49, 50], [51, 57], [57, 58], [59, 65], [66, 67], [68, 77], [77, 78]]}
{"doc_key": "ai-dev-51", "ner": [[8, 10, "field"], [13, 16, "product"], [19, 20, "algorithm"], [24, 26, "task"], [33, 35, "task"], [40, 40, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 16, 8, 10, "part-of", "", false, false], [13, 16, 19, 20, "usage", "", false, false], [24, 26, 8, 10, "part-of", "task_part_of_field", false, false], [24, 26, 40, 40, "related-to", "performs", false, false], [33, 35, 8, 10, "part-of", "task_part_of_field", false, false], [33, 35, 40, 40, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Ejemplo", "de", "una", "l\u00ednea", "de", "c\u00e1lculo", "t\u00edpica", "de", "visi\u00f3n", "por", "ordenador", "para", "un", "sistema", "de", "reconocimiento", "facial", "que", "utiliza", "k", "-NN", ",", "incluyendo", "la", "extracci\u00f3n", "de", "caracter\u00edsticas", "y", "los", "pasos", "de", "preprocesamiento", "de", "reducci\u00f3n", "de", "dimensiones", "(", "normalmente", "implementados", "con", "OpenCV", ")", ":"], "sentence-detokenized": "Ejemplo de una l\u00ednea de c\u00e1lculo t\u00edpica de visi\u00f3n por ordenador para un sistema de reconocimiento facial que utiliza k -NN, incluyendo la extracci\u00f3n de caracter\u00edsticas y los pasos de preprocesamiento de reducci\u00f3n de dimensiones (normalmente implementados con OpenCV):", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 20], [21, 23], [24, 31], [32, 38], [39, 41], [42, 48], [49, 52], [53, 62], [63, 67], [68, 70], [71, 78], [79, 81], [82, 96], [97, 103], [104, 107], [108, 115], [116, 117], [118, 121], [121, 122], [123, 133], [134, 136], [137, 147], [148, 150], [151, 166], [167, 168], [169, 172], [173, 178], [179, 181], [182, 198], [199, 201], [202, 211], [212, 214], [215, 226], [227, 228], [228, 239], [240, 253], [254, 257], [258, 264], [264, 265], [265, 266]]}
{"doc_key": "ai-dev-52", "ner": [[10, 14, "algorithm"], [16, 16, "misc"], [18, 19, "misc"], [21, 21, "misc"], [25, 25, "programlang"], [27, 27, "product"], [31, 32, "algorithm"], [35, 36, "misc"], [38, 38, "misc"], [40, 40, "misc"], [42, 42, "misc"], [50, 50, "misc"], [53, 54, "misc"], [56, 58, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [], "relations_mapping_to_source": [], "sentence": ["Tiene", "un", "rico", "conjunto", "de", "caracter\u00edsticas", ",", "bibliotecas", "para", "la", "programaci\u00f3n", "de", "l\u00f3gica", "de", "restricciones", ",", "multihilo", ",", "pruebas", "unitarias", ",", "GUI", ",", "interfaz", "con", "Java", ",", "ODBC", "y", "otros", ",", "programaci\u00f3n", "alfabetizada", ",", "un", "servidor", "web", ",", "SGML", ",", "RDF", ",", "RDFS", ",", "herramientas", "para", "desarrolladores", "(", "incluyendo", "un", "IDE", "con", "un", "depurador", "GUI", "y", "un", "perfilador", "GUI", ")", ",", "y", "una", "extensa", "documentaci\u00f3n", "."], "sentence-detokenized": "Tiene un rico conjunto de caracter\u00edsticas, bibliotecas para la programaci\u00f3n de l\u00f3gica de restricciones, multihilo, pruebas unitarias, GUI, interfaz con Java, ODBC y otros, programaci\u00f3n alfabetizada, un servidor web, SGML, RDF, RDFS, herramientas para desarrolladores (incluyendo un IDE con un depurador GUI y un perfilador GUI), y una extensa documentaci\u00f3n.", "token2charspan": [[0, 5], [6, 8], [9, 13], [14, 22], [23, 25], [26, 41], [41, 42], [43, 54], [55, 59], [60, 62], [63, 75], [76, 78], [79, 85], [86, 88], [89, 102], [102, 103], [104, 113], [113, 114], [115, 122], [123, 132], [132, 133], [134, 137], [137, 138], [139, 147], [148, 151], [152, 156], [156, 157], [158, 162], [163, 164], [165, 170], [170, 171], [172, 184], [185, 197], [197, 198], [199, 201], [202, 210], [211, 214], [214, 215], [216, 220], [220, 221], [222, 225], [225, 226], [227, 231], [231, 232], [233, 245], [246, 250], [251, 266], [267, 268], [268, 278], [279, 281], [282, 285], [286, 289], [290, 292], [293, 302], [303, 306], [307, 308], [309, 311], [312, 322], [323, 326], [326, 327], [327, 328], [329, 330], [331, 334], [335, 342], [343, 356], [356, 357]]}
{"doc_key": "ai-dev-53", "ner": [[2, 4, "field"], [7, 9, "field"], [14, 18, "misc"], [21, 23, "misc"], [27, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 18, 2, 4, "part-of", "", true, false], [14, 18, 7, 9, "part-of", "", false, false], [14, 18, 27, 29, "type-of", "", false, false], [21, 23, 2, 4, "part-of", "", false, false], [21, 23, 7, 9, "part-of", "", false, false], [21, 23, 27, 29, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["En", "la", "visi\u00f3n", "por", "ordenador", "y", "el", "procesamiento", "de", "im\u00e1genes", ",", "la", "noci\u00f3n", "de", "representaci\u00f3n", "del", "espacio", "de", "escala", "y", "los", "operadores", "derivados", "gaussianos", "es", "como", "una", "representaci\u00f3n", "can\u00f3nica", "multiescala", "."], "sentence-detokenized": "En la visi\u00f3n por ordenador y el procesamiento de im\u00e1genes, la noci\u00f3n de representaci\u00f3n del espacio de escala y los operadores derivados gaussianos es como una representaci\u00f3n can\u00f3nica multiescala.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 16], [17, 26], [27, 28], [29, 31], [32, 45], [46, 48], [49, 57], [57, 58], [59, 61], [62, 68], [69, 71], [72, 86], [87, 90], [91, 98], [99, 101], [102, 108], [109, 110], [111, 114], [115, 125], [126, 135], [136, 146], [147, 149], [150, 154], [155, 158], [159, 173], [174, 182], [183, 194], [194, 195]]}
{"doc_key": "ai-dev-54", "ner": [[6, 7, "organisation"], [8, 32, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 8, 32, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Tambi\u00e9n", "es", "el", "Presidente", "de", "la", "Fundaci\u00f3n", "de", "Sistemas", "de", "Procesamiento", "de", "Informaci\u00f3n", "Neural", ",", "una", "organizaci\u00f3n", "sin", "\u00e1nimo", "de", "lucro", "que", "supervisa", "la", "Conferencia", "anual", "sobre", "Sistemas", "de", "Procesamiento", "de", "Informaci\u00f3n", "Neural", "."], "sentence-detokenized": "Tambi\u00e9n es el Presidente de la Fundaci\u00f3n de Sistemas de Procesamiento de Informaci\u00f3n Neural, una organizaci\u00f3n sin \u00e1nimo de lucro que supervisa la Conferencia anual sobre Sistemas de Procesamiento de Informaci\u00f3n Neural.", "token2charspan": [[0, 7], [8, 10], [11, 13], [14, 24], [25, 27], [28, 30], [31, 40], [41, 43], [44, 52], [53, 55], [56, 69], [70, 72], [73, 84], [85, 91], [91, 92], [93, 96], [97, 109], [110, 113], [114, 119], [120, 122], [123, 128], [129, 132], [133, 142], [143, 145], [146, 157], [158, 163], [164, 169], [170, 178], [179, 181], [182, 195], [196, 198], [199, 210], [211, 217], [217, 218]]}
{"doc_key": "ai-dev-55", "ner": [[4, 7, "task"], [11, 13, "metrics"], [14, 16, "misc"], [20, 21, "task"], [25, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 7, 11, 13, "usage", "", false, false], [11, 13, 14, 16, "type-of", "", false, false], [20, 21, 25, 26, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Para", "los", "problemas", "de", "an\u00e1lisis", "de", "regresi\u00f3n", "se", "puede", "utilizar", "el", "error", "cuadrado", "como", "funci\u00f3n", "de", "p\u00e9rdida", ",", "para", "la", "clasificaci\u00f3n", "se", "puede", "utilizar", "la", "entrop\u00eda", "cruzada", "."], "sentence-detokenized": "Para los problemas de an\u00e1lisis de regresi\u00f3n se puede utilizar el error cuadrado como funci\u00f3n de p\u00e9rdida, para la clasificaci\u00f3n se puede utilizar la entrop\u00eda cruzada.", "token2charspan": [[0, 4], [5, 8], [9, 18], [19, 21], [22, 30], [31, 33], [34, 43], [44, 46], [47, 52], [53, 61], [62, 64], [65, 70], [71, 79], [80, 84], [85, 92], [93, 95], [96, 103], [103, 104], [105, 109], [110, 112], [113, 126], [127, 129], [130, 135], [136, 144], [145, 147], [148, 156], [157, 164], [164, 165]]}
{"doc_key": "ai-dev-56", "ner": [[0, 1, "researcher"], [24, 29, "conference"], [31, 36, "conference"], [51, 52, "university"], [47, 50, "field"], [59, 63, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 24, 29, "role", "", false, false], [0, 1, 51, 52, "physical", "", false, false], [0, 1, 51, 52, "role", "", false, false], [0, 1, 59, 63, "role", "", false, false], [24, 29, 31, 36, "named", "same", false, false], [51, 52, 47, 50, "related-to", "subject_of_study_at", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Lafferty", "ocup\u00f3", "muchos", "puestos", "de", "prestigio", ",", "entre", "ellos", "1", ")", "copresidente", "del", "programa", "y", "copresidente", "general", "de", "las", "conferencias", "de", "la", "Fundaci\u00f3n", "de", "Sistemas", "de", "Procesamiento", "de", "Informaci\u00f3n", "Neural", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", ")", ";", "2", ")", "codirector", "del", "nuevo", "programa", "de", "doctorado", "en", "aprendizaje", "autom\u00e1tico", "de", "la", "CMU", ";", "3", ")", "editor", "asociado", "del", "Journal", "of", "Machine", "Learning", "Research"], "sentence-detokenized": "Lafferty ocup\u00f3 muchos puestos de prestigio, entre ellos 1) copresidente del programa y copresidente general de las conferencias de la Fundaci\u00f3n de Sistemas de Procesamiento de Informaci\u00f3n Neural (Conference on Neural Information Processing Systems); 2) codirector del nuevo programa de doctorado en aprendizaje autom\u00e1tico de la CMU; 3) editor asociado del Journal of Machine Learning Research", "token2charspan": [[0, 8], [9, 14], [15, 21], [22, 29], [30, 32], [33, 42], [42, 43], [44, 49], [50, 55], [56, 57], [57, 58], [59, 71], [72, 75], [76, 84], [85, 86], [87, 99], [100, 107], [108, 110], [111, 114], [115, 127], [128, 130], [131, 133], [134, 143], [144, 146], [147, 155], [156, 158], [159, 172], [173, 175], [176, 187], [188, 194], [195, 196], [196, 206], [207, 209], [210, 216], [217, 228], [229, 239], [240, 247], [247, 248], [248, 249], [250, 251], [251, 252], [253, 263], [264, 267], [268, 273], [274, 282], [283, 285], [286, 295], [296, 298], [299, 310], [311, 321], [322, 324], [325, 327], [328, 331], [331, 332], [333, 334], [334, 335], [336, 342], [343, 351], [352, 355], [356, 363], [364, 366], [367, 374], [375, 383], [384, 392]]}
{"doc_key": "ai-dev-57", "ner": [[0, 2, "misc"], [5, 5, "algorithm"], [7, 7, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 0, 2, "type-of", "", false, false], [7, 7, 0, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Los", "algoritmos", "convexos", ",", "como", "AdaBoost", "y", "LogitBoost", ",", "pueden", "ser", "derrotados", "por", "el", "ruido", "aleatorio", ",", "de", "manera", "que", "no", "pueden", "aprender", "combinaciones", "b\u00e1sicas", "y", "aprendibles", "de", "hip\u00f3tesis", "d\u00e9biles", "."], "sentence-detokenized": "Los algoritmos convexos, como AdaBoost y LogitBoost, pueden ser derrotados por el ruido aleatorio, de manera que no pueden aprender combinaciones b\u00e1sicas y aprendibles de hip\u00f3tesis d\u00e9biles.", "token2charspan": [[0, 3], [4, 14], [15, 23], [23, 24], [25, 29], [30, 38], [39, 40], [41, 51], [51, 52], [53, 59], [60, 63], [64, 74], [75, 78], [79, 81], [82, 87], [88, 97], [97, 98], [99, 101], [102, 108], [109, 112], [113, 115], [116, 122], [123, 131], [132, 145], [146, 153], [154, 155], [156, 167], [168, 170], [171, 180], [181, 188], [188, 189]]}
{"doc_key": "ai-dev-58", "ner": [[0, 0, "product"], [3, 9, "product"], [12, 15, "algorithm"], [23, 25, "algorithm"], [28, 32, "task"], [35, 39, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 3, 9, "type-of", "", false, false], [0, 0, 12, 15, "usage", "", false, false], [0, 0, 23, 25, "usage", "", false, false], [23, 25, 28, 32, "related-to", "used_for", true, false], [23, 25, 35, 39, "related-to", "used_for", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Apertium", "es", "un", "sistema", "de", "traducci\u00f3n", "autom\u00e1tica", "de", "transferencia", "superficial", "que", "utiliza", "transductores", "de", "estado", "finito", "para", "todas", "sus", "transformaciones", "l\u00e9xicas", "y", "modelos", "de", "Markov", "ocultos", "para", "el", "etiquetado", "de", "partes", "del", "habla", "o", "la", "desambiguaci\u00f3n", "de", "categor\u00edas", "de", "palabras", "."], "sentence-detokenized": "Apertium es un sistema de traducci\u00f3n autom\u00e1tica de transferencia superficial que utiliza transductores de estado finito para todas sus transformaciones l\u00e9xicas y modelos de Markov ocultos para el etiquetado de partes del habla o la desambiguaci\u00f3n de categor\u00edas de palabras.", "token2charspan": [[0, 8], [9, 11], [12, 14], [15, 22], [23, 25], [26, 36], [37, 47], [48, 50], [51, 64], [65, 76], [77, 80], [81, 88], [89, 102], [103, 105], [106, 112], [113, 119], [120, 124], [125, 130], [131, 134], [135, 151], [152, 159], [160, 161], [162, 169], [170, 172], [173, 179], [180, 187], [188, 192], [193, 195], [196, 206], [207, 209], [210, 216], [217, 220], [221, 226], [227, 228], [229, 231], [232, 246], [247, 249], [250, 260], [261, 263], [264, 272], [272, 273]]}
{"doc_key": "ai-dev-59", "ner": [[1, 2, "misc"], [15, 19, "metrics"], [35, 36, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 15, 19, "related-to", "", true, false], [15, 19, 35, 36, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["El", "gradiente", "natural", "de", "mathE", "f", "(", "x", ")", "/", "math", ",", "cumpliendo", "con", "la", "m\u00e9trica", "de", "informaci\u00f3n", "de", "Fisher", "(", "una", "medida", "de", "distancia", "informativa", "entre", "distribuciones", "de", "probabilidad", "y", "la", "curvatura", "de", "la", "entrop\u00eda", "relativa", ")", ",", "dice", "ahora"], "sentence-detokenized": "El gradiente natural de mathE f (x) / math, cumpliendo con la m\u00e9trica de informaci\u00f3n de Fisher (una medida de distancia informativa entre distribuciones de probabilidad y la curvatura de la entrop\u00eda relativa), dice ahora", "token2charspan": [[0, 2], [3, 12], [13, 20], [21, 23], [24, 29], [30, 31], [32, 33], [33, 34], [34, 35], [36, 37], [38, 42], [42, 43], [44, 54], [55, 58], [59, 61], [62, 69], [70, 72], [73, 84], [85, 87], [88, 94], [95, 96], [96, 99], [100, 106], [107, 109], [110, 119], [120, 131], [132, 137], [138, 152], [153, 155], [156, 168], [169, 170], [171, 173], [174, 183], [184, 186], [187, 189], [190, 198], [199, 207], [207, 208], [208, 209], [210, 214], [215, 220]]}
{"doc_key": "ai-dev-60", "ner": [[0, 4, "programlang"], [8, 9, "product"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 0, 4, "origin", "", false, false], [11, 11, 0, 4, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["El", "lenguaje", "de", "programaci\u00f3n", "S", "inspir\u00f3", "los", "sistemas", "S", "'-PLUS", "y", "R."], "sentence-detokenized": "El lenguaje de programaci\u00f3n S inspir\u00f3 los sistemas S '-PLUS y R.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 27], [28, 29], [30, 37], [38, 41], [42, 50], [51, 52], [53, 59], [60, 61], [62, 64]]}
{"doc_key": "ai-dev-61", "ner": [[5, 5, "product"], [10, 10, "product"], [13, 13, "product"], [17, 19, "researcher"], [21, 22, "researcher"], [24, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 5, 10, 10, "named", "same", false, false], [13, 13, 10, 10, "origin", "derived_from", false, false], [13, 13, 17, 19, "origin", "", false, false], [13, 13, 21, 22, "origin", "", false, false], [13, 13, 24, 25, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["La", "implementaci\u00f3n", "m\u00e1s", "influyente", "de", "Planner", "fue", "el", "subconjunto", "de", "Planner", ",", "llamado", "Micro-Planner", ",", "implementado", "por", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "y", "Terry", "Winograd", "."], "sentence-detokenized": "La implementaci\u00f3n m\u00e1s influyente de Planner fue el subconjunto de Planner, llamado Micro-Planner, implementado por Gerald Jay Sussman, Eugene Charniak y Terry Winograd.", "token2charspan": [[0, 2], [3, 17], [18, 21], [22, 32], [33, 35], [36, 43], [44, 47], [48, 50], [51, 62], [63, 65], [66, 73], [73, 74], [75, 82], [83, 96], [96, 97], [98, 110], [111, 114], [115, 121], [122, 125], [126, 133], [133, 134], [135, 141], [142, 150], [151, 152], [153, 158], [159, 167], [167, 168]]}
{"doc_key": "ai-dev-62", "ner": [[5, 5, "country"], [6, 8, "researcher"], [21, 21, "misc"], [19, 25, "university"], [32, 34, "misc"], [40, 41, "misc"], [46, 49, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "relations": [[6, 8, 5, 5, "general-affiliation", "from_country", false, false], [19, 25, 21, 21, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["En", "1779", ",", "el", "cient\u00edfico", "alem\u00e1n-dinamarqu\u00e9s", "Christian", "Gottlieb", "Kratzenstein", "gan\u00f3", "el", "primer", "premio", "en", "un", "concurso", "convocado", "por", "la", "Academia", "Imperial", "Rusa", "de", "Ciencias", "y", "Artes", "por", "los", "modelos", "que", "construy\u00f3", "del", "tracto", "vocal", "humano", "que", "pod\u00edan", "producir", "los", "cinco", "sonidos", "voc\u00e1licos", "largos", "(", "en", "notaci\u00f3n", "del", "Alfabeto", "Fon\u00e9tico", "Internacional", ":"], "sentence-detokenized": "En 1779, el cient\u00edfico alem\u00e1n-dinamarqu\u00e9s Christian Gottlieb Kratzenstein gan\u00f3 el primer premio en un concurso convocado por la Academia Imperial Rusa de Ciencias y Artes por los modelos que construy\u00f3 del tracto vocal humano que pod\u00edan producir los cinco sonidos voc\u00e1licos largos (en notaci\u00f3n del Alfabeto Fon\u00e9tico Internacional:", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 22], [23, 41], [42, 51], [52, 60], [61, 73], [74, 78], [79, 81], [82, 88], [89, 95], [96, 98], [99, 101], [102, 110], [111, 120], [121, 124], [125, 127], [128, 136], [137, 145], [146, 150], [151, 153], [154, 162], [163, 164], [165, 170], [171, 174], [175, 178], [179, 186], [187, 190], [191, 200], [201, 204], [205, 211], [212, 217], [218, 224], [225, 228], [229, 235], [236, 244], [245, 248], [249, 254], [255, 262], [263, 272], [273, 279], [280, 281], [281, 283], [284, 292], [293, 296], [297, 305], [306, 314], [315, 328], [328, 329]]}
{"doc_key": "ai-dev-63", "ner": [[5, 6, "product"], [10, 11, "misc"], [14, 20, "misc"], [40, 44, "misc"], [75, 77, "task"], [81, 82, "product"], [84, 84, "product"], [90, 92, "task"], [94, 95, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 6, 81, 82, "related-to", "supports_program", false, false], [5, 6, 84, 84, "related-to", "supports_program", false, false], [10, 11, 5, 6, "part-of", "", false, false], [14, 20, 5, 6, "part-of", "", false, false], [40, 44, 5, 6, "part-of", "", false, false], [75, 77, 5, 6, "part-of", "", false, false], [90, 92, 5, 6, "part-of", "", false, false], [94, 95, 5, 6, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Entre", "las", "nuevas", "caracter\u00edsticas", "de", "Office", "XP", "se", "encuentran", "las", "etiquetas", "inteligentes", ",", "una", "funci\u00f3n", "de", "b\u00fasqueda", "basada", "en", "la", "selecci\u00f3n", "que", "reconoce", "diferentes", "tipos", "de", "texto", "en", "un", "documento", "para", "que", "los", "usuarios", "puedan", "realizar", "acciones", "adicionales", ";", "una", "interfaz", "de", "panel", "de", "tareas", "que", "consolida", "los", "comandos", "m\u00e1s", "populares", "de", "la", "barra", "de", "men\u00fas", "en", "la", "parte", "derecha", "de", "la", "pantalla", "para", "facilitar", "el", "acceso", "r\u00e1pido", "a", "los", "mismos", ";", "nuevas", "capacidades", "de", "colaboraci\u00f3n", "en", "documentos", ",", "compatibilidad", "con", "MSN", "Groups", "y", "SharePoint", ";", "y", "capacidades", "integradas", "de", "reconocimiento", "de", "escritura", "y", "de", "voz", "."], "sentence-detokenized": "Entre las nuevas caracter\u00edsticas de Office XP se encuentran las etiquetas inteligentes, una funci\u00f3n de b\u00fasqueda basada en la selecci\u00f3n que reconoce diferentes tipos de texto en un documento para que los usuarios puedan realizar acciones adicionales; una interfaz de panel de tareas que consolida los comandos m\u00e1s populares de la barra de men\u00fas en la parte derecha de la pantalla para facilitar el acceso r\u00e1pido a los mismos; nuevas capacidades de colaboraci\u00f3n en documentos, compatibilidad con MSN Groups y SharePoint; y capacidades integradas de reconocimiento de escritura y de voz.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 32], [33, 35], [36, 42], [43, 45], [46, 48], [49, 59], [60, 63], [64, 73], [74, 86], [86, 87], [88, 91], [92, 99], [100, 102], [103, 111], [112, 118], [119, 121], [122, 124], [125, 134], [135, 138], [139, 147], [148, 158], [159, 164], [165, 167], [168, 173], [174, 176], [177, 179], [180, 189], [190, 194], [195, 198], [199, 202], [203, 211], [212, 218], [219, 227], [228, 236], [237, 248], [248, 249], [250, 253], [254, 262], [263, 265], [266, 271], [272, 274], [275, 281], [282, 285], [286, 295], [296, 299], [300, 308], [309, 312], [313, 322], [323, 325], [326, 328], [329, 334], [335, 337], [338, 343], [344, 346], [347, 349], [350, 355], [356, 363], [364, 366], [367, 369], [370, 378], [379, 383], [384, 393], [394, 396], [397, 403], [404, 410], [411, 412], [413, 416], [417, 423], [423, 424], [425, 431], [432, 443], [444, 446], [447, 459], [460, 462], [463, 473], [473, 474], [475, 489], [490, 493], [494, 497], [498, 504], [505, 506], [507, 517], [517, 518], [519, 520], [521, 532], [533, 543], [544, 546], [547, 561], [562, 564], [565, 574], [575, 576], [577, 579], [580, 583], [583, 584]]}
{"doc_key": "ai-dev-64", "ner": [[10, 11, "algorithm"], [13, 15, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 11, 13, 15, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["En", "muchas", "aplicaciones", "las", "unidades", "de", "estas", "redes", "aplican", "una", "funci\u00f3n", "sigmoidea", "como", "funci\u00f3n", "de", "activaci\u00f3n", "."], "sentence-detokenized": "En muchas aplicaciones las unidades de estas redes aplican una funci\u00f3n sigmoidea como funci\u00f3n de activaci\u00f3n.", "token2charspan": [[0, 2], [3, 9], [10, 22], [23, 26], [27, 35], [36, 38], [39, 44], [45, 50], [51, 58], [59, 62], [63, 70], [71, 80], [81, 85], [86, 93], [94, 96], [97, 107], [107, 108]]}
{"doc_key": "ai-dev-65", "ner": [[3, 3, "researcher"], [11, 18, "organisation"], [28, 35, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 11, 18, "role", "", false, false], [3, 3, 28, 35, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["En", "2001", ",", "Mehler", "fue", "elegido", "miembro", "honorario", "extranjero", "de", "la", "Academia", "Americana", "de", "las", "Artes", "y", "las", "Ciencias", ",", "y", "en", "2003", "fue", "elegido", "miembro", "de", "la", "Asociaci\u00f3n", "Americana", "para", "el", "Avance", "de", "la", "Ciencia", "."], "sentence-detokenized": "En 2001, Mehler fue elegido miembro honorario extranjero de la Academia Americana de las Artes y las Ciencias, y en 2003 fue elegido miembro de la Asociaci\u00f3n Americana para el Avance de la Ciencia.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 27], [28, 35], [36, 45], [46, 56], [57, 59], [60, 62], [63, 71], [72, 81], [82, 84], [85, 88], [89, 94], [95, 96], [97, 100], [101, 109], [109, 110], [111, 112], [113, 115], [116, 120], [121, 124], [125, 132], [133, 140], [141, 143], [144, 146], [147, 157], [158, 167], [168, 172], [173, 175], [176, 182], [183, 185], [186, 188], [189, 196], [196, 197]]}
{"doc_key": "ai-dev-66", "ner": [[6, 9, "task"], [14, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 9, 14, 16, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["La", "extensi\u00f3n", "de", "este", "concepto", "a", "las", "clasificaciones", "no", "binarias", "da", "lugar", "a", "la", "matriz", "de", "confusi\u00f3n", "."], "sentence-detokenized": "La extensi\u00f3n de este concepto a las clasificaciones no binarias da lugar a la matriz de confusi\u00f3n.", "token2charspan": [[0, 2], [3, 12], [13, 15], [16, 20], [21, 29], [30, 31], [32, 35], [36, 51], [52, 54], [55, 63], [64, 66], [67, 72], [73, 74], [75, 77], [78, 84], [85, 87], [88, 97], [97, 98]]}
{"doc_key": "ai-dev-67", "ner": [[18, 19, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Se", "puede", "obtener", "una", "estimaci\u00f3n", "actualizada", "de", "la", "varianza", "del", "ruido", "de", "medici\u00f3n", "a", "partir", "del", "c\u00e1lculo", "de", "m\u00e1xima", "verosimilitud"], "sentence-detokenized": "Se puede obtener una estimaci\u00f3n actualizada de la varianza del ruido de medici\u00f3n a partir del c\u00e1lculo de m\u00e1xima verosimilitud", "token2charspan": [[0, 2], [3, 8], [9, 16], [17, 20], [21, 31], [32, 43], [44, 46], [47, 49], [50, 58], [59, 62], [63, 68], [69, 71], [72, 80], [81, 82], [83, 89], [90, 93], [94, 101], [102, 104], [105, 111], [112, 125]]}
{"doc_key": "ai-dev-68", "ner": [[2, 3, "field"], [6, 6, "algorithm"], [11, 12, "field"], [14, 15, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 11, 12, "usage", "", true, false], [6, 6, 14, 15, "related-to", "", true, false], [11, 12, 2, 3, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["En", "el", "aprendizaje", "autom\u00e1tico", ",", "el", "perceptr\u00f3n", "es", "un", "algoritmo", "de", "aprendizaje", "supervisado", "de", "clasificaci\u00f3n", "binaria", "."], "sentence-detokenized": "En el aprendizaje autom\u00e1tico, el perceptr\u00f3n es un algoritmo de aprendizaje supervisado de clasificaci\u00f3n binaria.", "token2charspan": [[0, 2], [3, 5], [6, 17], [18, 28], [28, 29], [30, 32], [33, 43], [44, 46], [47, 49], [50, 59], [60, 62], [63, 74], [75, 86], [87, 89], [90, 103], [104, 111], [111, 112]]}
{"doc_key": "ai-dev-69", "ner": [[10, 11, "field"], [13, 13, "field"], [16, 24, "conference"], [28, 32, "conference"], [35, 43, "conference"], [46, 51, "conference"], [54, 59, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[16, 24, 10, 11, "topic", "", false, false], [16, 24, 13, 13, "topic", "", false, false], [28, 32, 10, 11, "topic", "", false, false], [28, 32, 13, 13, "topic", "", false, false], [35, 43, 10, 11, "topic", "", false, false], [35, 43, 13, 13, "topic", "", false, false], [46, 51, 10, 11, "topic", "", false, false], [46, 51, 13, 13, "topic", "", false, false], [54, 59, 10, 11, "topic", "", false, false], [54, 59, 13, 13, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Tambi\u00e9n", "ha", "sido", "presidenta", "de", "\u00e1rea", "de", "varias", "conferencias", "sobre", "aprendizaje", "autom\u00e1tico", "y", "visi\u00f3n", ",", "como", "la", "Conferencia", "sobre", "Sistemas", "de", "Procesamiento", "de", "Informaci\u00f3n", "Neural", ",", "la", "Conferencia", "Internacional", "sobre", "Representaciones", "de", "Aprendizaje", ",", "la", "Conferencia", "sobre", "Visi\u00f3n", "por", "Ordenador", "y", "Reconocimiento", "de", "Patrones", ",", "la", "Conferencia", "Internacional", "sobre", "Visi\u00f3n", "por", "Ordenador", "y", "la", "Conferencia", "Europea", "sobre", "Visi\u00f3n", "por", "Ordenador", "."], "sentence-detokenized": "Tambi\u00e9n ha sido presidenta de \u00e1rea de varias conferencias sobre aprendizaje autom\u00e1tico y visi\u00f3n, como la Conferencia sobre Sistemas de Procesamiento de Informaci\u00f3n Neural, la Conferencia Internacional sobre Representaciones de Aprendizaje, la Conferencia sobre Visi\u00f3n por Ordenador y Reconocimiento de Patrones, la Conferencia Internacional sobre Visi\u00f3n por Ordenador y la Conferencia Europea sobre Visi\u00f3n por Ordenador.", "token2charspan": [[0, 7], [8, 10], [11, 15], [16, 26], [27, 29], [30, 34], [35, 37], [38, 44], [45, 57], [58, 63], [64, 75], [76, 86], [87, 88], [89, 95], [95, 96], [97, 101], [102, 104], [105, 116], [117, 122], [123, 131], [132, 134], [135, 148], [149, 151], [152, 163], [164, 170], [170, 171], [172, 174], [175, 186], [187, 200], [201, 206], [207, 223], [224, 226], [227, 238], [238, 239], [240, 242], [243, 254], [255, 260], [261, 267], [268, 271], [272, 281], [282, 283], [284, 298], [299, 301], [302, 310], [310, 311], [312, 314], [315, 326], [327, 340], [341, 346], [347, 353], [354, 357], [358, 367], [368, 369], [370, 372], [373, 384], [385, 392], [393, 398], [399, 405], [406, 409], [410, 419], [419, 420]]}
{"doc_key": "ai-dev-70", "ner": [[1, 3, "algorithm"], [10, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 13, 1, 3, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["El", "algoritmo", "de", "condensaci\u00f3n", "tambi\u00e9n", "se", "ha", "utilizado", "para", "el", "sistema", "de", "reconocimiento", "facial", "en", "una", "secuencia", "de", "v\u00eddeo", "."], "sentence-detokenized": "El algoritmo de condensaci\u00f3n tambi\u00e9n se ha utilizado para el sistema de reconocimiento facial en una secuencia de v\u00eddeo.", "token2charspan": [[0, 2], [3, 12], [13, 15], [16, 28], [29, 36], [37, 39], [40, 42], [43, 52], [53, 57], [58, 60], [61, 68], [69, 71], [72, 86], [87, 93], [94, 96], [97, 100], [101, 110], [111, 113], [114, 119], [119, 120]]}
{"doc_key": "ai-dev-71", "ner": [[0, 4, "task"], [12, 16, "organisation"], [26, 26, "conference"], [29, 34, "academicjournal"], [38, 38, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[26, 26, 0, 4, "topic", "", false, false], [26, 26, 12, 16, "origin", "", false, false], [29, 34, 0, 4, "topic", "", false, false], [29, 34, 12, 16, "origin", "", true, false], [38, 38, 29, 34, "role", "edited_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["La", "difusi\u00f3n", "de", "la", "informaci\u00f3n", "tambi\u00e9n", "forma", "parte", "de", "las", "misiones", "de", "la", "ELRA", ",", "que", "se", "lleva", "a", "cabo", "mediante", "la", "organizaci\u00f3n", "de", "la", "conferencia", "LREC", "y", "la", "revista", "Language", "Resources", "and", "Evaluation", "Journal", ",", "editada", "por", "Springer", "."], "sentence-detokenized": "La difusi\u00f3n de la informaci\u00f3n tambi\u00e9n forma parte de las misiones de la ELRA, que se lleva a cabo mediante la organizaci\u00f3n de la conferencia LREC y la revista Language Resources and Evaluation Journal, editada por Springer.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 17], [18, 29], [30, 37], [38, 43], [44, 49], [50, 52], [53, 56], [57, 65], [66, 68], [69, 71], [72, 76], [76, 77], [78, 81], [82, 84], [85, 90], [91, 92], [93, 97], [98, 106], [107, 109], [110, 122], [123, 125], [126, 128], [129, 140], [141, 145], [146, 147], [148, 150], [151, 158], [159, 167], [168, 177], [178, 181], [182, 192], [193, 200], [200, 201], [202, 209], [210, 213], [214, 222], [222, 223]]}
{"doc_key": "ai-dev-72", "ner": [[2, 11, "field"], [16, 18, "field"], [22, 25, "field"], [28, 31, "field"], [69, 70, "field"], [77, 77, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 11, 69, 70, "named", "", false, false], [22, 25, 2, 11, "named", "", false, false], [77, 77, 16, 18, "part-of", "", true, false], [77, 77, 22, 25, "part-of", "", true, false], [77, 77, 69, 70, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["En", "la", "teor\u00eda", "de", "sistemas", "lineales", "invariantes", "en", "el", "tiempo", "(", "LTI", ")", ",", "en", "la", "teor\u00eda", "de", "control", "y", "en", "el", "procesamiento", "digital", "de", "se\u00f1ales", "o", "en", "el", "tratamiento", "de", "se\u00f1ales", ",", "la", "relaci\u00f3n", "entre", "la", "se\u00f1al", "de", "entrada", ",", "math", "\\", "displaystyle", "x", "(", "t", ")", "/", "math", ",", "y", "la", "se\u00f1al", "de", "salida", ",", "math", "\\", "displaystyle", "y", "(", "t", ")", "/", "math", ",", "de", "un", "sistema", "LTI", "se", "rige", "por", "una", "operaci\u00f3n", "de", "convoluci\u00f3n", ":"], "sentence-detokenized": "En la teor\u00eda de sistemas lineales invariantes en el tiempo (LTI), en la teor\u00eda de control y en el procesamiento digital de se\u00f1ales o en el tratamiento de se\u00f1ales, la relaci\u00f3n entre la se\u00f1al de entrada, math\\ displaystyle x (t) / math, y la se\u00f1al de salida, math\\ displaystyle y (t) / math, de un sistema LTI se rige por una operaci\u00f3n de convoluci\u00f3n:", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 15], [16, 24], [25, 33], [34, 45], [46, 48], [49, 51], [52, 58], [59, 60], [60, 63], [63, 64], [64, 65], [66, 68], [69, 71], [72, 78], [79, 81], [82, 89], [90, 91], [92, 94], [95, 97], [98, 111], [112, 119], [120, 122], [123, 130], [131, 132], [133, 135], [136, 138], [139, 150], [151, 153], [154, 161], [161, 162], [163, 165], [166, 174], [175, 180], [181, 183], [184, 189], [190, 192], [193, 200], [200, 201], [202, 206], [206, 207], [208, 220], [221, 222], [223, 224], [224, 225], [225, 226], [227, 228], [229, 233], [233, 234], [235, 236], [237, 239], [240, 245], [246, 248], [249, 255], [255, 256], [257, 261], [261, 262], [263, 275], [276, 277], [278, 279], [279, 280], [280, 281], [282, 283], [284, 288], [288, 289], [290, 292], [293, 295], [296, 303], [304, 307], [308, 310], [311, 315], [316, 319], [320, 323], [324, 333], [334, 336], [337, 348], [348, 349]]}
{"doc_key": "ai-dev-73", "ner": [[15, 19, "field"], [22, 24, "field"], [27, 29, "field"], [32, 35, "field"], [38, 42, "field"], [44, 46, "product"], [49, 51, "field"], [54, 54, "field"], [57, 58, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Debido", "a", "su", "generalidad", ",", "el", "campo", "se", "estudia", "en", "muchas", "otras", "disciplinas", ",", "como", "la", "teor\u00eda", "de", "los", "juegos", ",", "la", "teor\u00eda", "del", "control", ",", "la", "investigaci\u00f3n", "de", "operaciones", ",", "la", "teor\u00eda", "de", "la", "informaci\u00f3n", ",", "la", "optimizaci\u00f3n", "basada", "en", "la", "simulaci\u00f3n", ",", "los", "sistemas", "multiagentes", ",", "la", "inteligencia", "de", "enjambre", ",", "la", "estad\u00edstica", "y", "los", "algoritmos", "gen\u00e9ticos", "."], "sentence-detokenized": "Debido a su generalidad, el campo se estudia en muchas otras disciplinas, como la teor\u00eda de los juegos, la teor\u00eda del control, la investigaci\u00f3n de operaciones, la teor\u00eda de la informaci\u00f3n, la optimizaci\u00f3n basada en la simulaci\u00f3n, los sistemas multiagentes, la inteligencia de enjambre, la estad\u00edstica y los algoritmos gen\u00e9ticos.", "token2charspan": [[0, 6], [7, 8], [9, 11], [12, 23], [23, 24], [25, 27], [28, 33], [34, 36], [37, 44], [45, 47], [48, 54], [55, 60], [61, 72], [72, 73], [74, 78], [79, 81], [82, 88], [89, 91], [92, 95], [96, 102], [102, 103], [104, 106], [107, 113], [114, 117], [118, 125], [125, 126], [127, 129], [130, 143], [144, 146], [147, 158], [158, 159], [160, 162], [163, 169], [170, 172], [173, 175], [176, 187], [187, 188], [189, 191], [192, 204], [205, 211], [212, 214], [215, 217], [218, 228], [228, 229], [230, 233], [234, 242], [243, 255], [255, 256], [257, 259], [260, 272], [273, 275], [276, 284], [284, 285], [286, 288], [289, 300], [301, 302], [303, 306], [307, 317], [318, 327], [327, 328]]}
{"doc_key": "ai-dev-74", "ner": [[0, 4, "algorithm"], [18, 22, "field"], [25, 28, "algorithm"], [34, 35, "algorithm"], [42, 43, "algorithm"], [47, 48, "algorithm"], [46, 50, "researcher"], [52, 53, "researcher"], [55, 57, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[18, 22, 0, 4, "usage", "", true, false], [25, 28, 18, 22, "part-of", "", true, false], [34, 35, 18, 22, "part-of", "", true, false], [42, 43, 18, 22, "part-of", "", true, false], [47, 48, 18, 22, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["El", "descenso", "de", "gradiente", "estoc\u00e1stico", "es", "un", "algoritmo", "popular", "para", "entrenar", "una", "amplia", "gama", "de", "modelos", "en", "el", "aprendizaje", "de", "m\u00e1quinas", ",", "incluidas", "las", "m\u00e1quinas", "de", "vectores", "de", "apoyo", "(", "lineales", ")", ",", "la", "regresi\u00f3n", "log\u00edstica", "(", "v\u00e9ase", ",", "por", "ejemplo", ",", "Vowpal", "Wabbit", ")", "y", "los", "modelos", "gr\u00e1ficos.Jenny", "Rose", "Finkel", ",", "Alex", "Kleeman", ",", "Christopher", "D.", "Manning", "(", "2008", ")", "."], "sentence-detokenized": "El descenso de gradiente estoc\u00e1stico es un algoritmo popular para entrenar una amplia gama de modelos en el aprendizaje de m\u00e1quinas, incluidas las m\u00e1quinas de vectores de apoyo (lineales), la regresi\u00f3n log\u00edstica (v\u00e9ase, por ejemplo, Vowpal Wabbit) y los modelos gr\u00e1ficos.Jenny Rose Finkel, Alex Kleeman, Christopher D. Manning (2008).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 24], [25, 36], [37, 39], [40, 42], [43, 52], [53, 60], [61, 65], [66, 74], [75, 78], [79, 85], [86, 90], [91, 93], [94, 101], [102, 104], [105, 107], [108, 119], [120, 122], [123, 131], [131, 132], [133, 142], [143, 146], [147, 155], [156, 158], [159, 167], [168, 170], [171, 176], [177, 178], [178, 186], [186, 187], [187, 188], [189, 191], [192, 201], [202, 211], [212, 213], [213, 218], [218, 219], [220, 223], [224, 231], [231, 232], [233, 239], [240, 246], [246, 247], [248, 249], [250, 253], [254, 261], [262, 276], [277, 281], [282, 288], [288, 289], [290, 294], [295, 302], [302, 303], [304, 315], [316, 318], [319, 326], [327, 328], [328, 332], [332, 333], [333, 334]]}
{"doc_key": "ai-dev-75", "ner": [[8, 8, "organisation"], [11, 12, "product"], [21, 21, "country"], [24, 28, "university"], [30, 30, "location"], [33, 36, "university"], [38, 38, "location"], [40, 42, "university"], [44, 44, "location"], [46, 49, "university"], [51, 51, "location"], [53, 55, "university"], [57, 57, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 8, 24, 28, "role", "donates_to", false, false], [8, 8, 33, 36, "role", "donates_to", false, false], [8, 8, 40, 42, "role", "donates_to", false, false], [8, 8, 46, 49, "role", "donates_to", false, false], [8, 8, 53, 55, "role", "donates_to", false, false], [11, 12, 8, 8, "origin", "donates", true, false], [24, 28, 30, 30, "physical", "", false, false], [30, 30, 21, 21, "physical", "", false, false], [33, 36, 38, 38, "physical", "", false, false], [38, 38, 21, 21, "physical", "", false, false], [40, 42, 44, 44, "physical", "", false, false], [44, 44, 21, 21, "physical", "", false, false], [46, 49, 51, 51, "physical", "", false, false], [51, 51, 21, 21, "physical", "", false, false], [53, 55, 57, 57, "physical", "", false, false], [57, 57, 21, 21, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "sentence": ["En", "agosto", "de", "2011", ",", "se", "anunci\u00f3", "que", "Hitachi", "donar\u00eda", "un", "microscopio", "electr\u00f3nico", "a", "cada", "una", "de", "las", "cinco", "universidades", "de", "Indonesia", "(", "la", "Universidad", "de", "Sumatra", "del", "Norte", "en", "Medan", ",", "la", "Universidad", "Cristiana", "de", "Indonesia", "en", "Yakarta", ",", "la", "Universidad", "Padjadjaran", "en", "Bandung", ",", "la", "Universidad", "Jenderal", "Soedirman", "en", "Purwokerto", "y", "la", "Universidad", "Muhammadiyah", "en", "Malang", ")", "."], "sentence-detokenized": "En agosto de 2011, se anunci\u00f3 que Hitachi donar\u00eda un microscopio electr\u00f3nico a cada una de las cinco universidades de Indonesia (la Universidad de Sumatra del Norte en Medan, la Universidad Cristiana de Indonesia en Yakarta, la Universidad Padjadjaran en Bandung, la Universidad Jenderal Soedirman en Purwokerto y la Universidad Muhammadiyah en Malang).", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 17], [17, 18], [19, 21], [22, 29], [30, 33], [34, 41], [42, 49], [50, 52], [53, 64], [65, 76], [77, 78], [79, 83], [84, 87], [88, 90], [91, 94], [95, 100], [101, 114], [115, 117], [118, 127], [128, 129], [129, 131], [132, 143], [144, 146], [147, 154], [155, 158], [159, 164], [165, 167], [168, 173], [173, 174], [175, 177], [178, 189], [190, 199], [200, 202], [203, 212], [213, 215], [216, 223], [223, 224], [225, 227], [228, 239], [240, 251], [252, 254], [255, 262], [262, 263], [264, 266], [267, 278], [279, 287], [288, 297], [298, 300], [301, 311], [312, 313], [314, 316], [317, 328], [329, 341], [342, 344], [345, 351], [351, 352], [352, 353]]}
{"doc_key": "ai-dev-76", "ner": [[3, 3, "field"], [6, 7, "field"], [11, 12, "algorithm"], [15, 16, "algorithm"], [26, 28, "field"], [35, 36, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 3, 6, 7, "part-of", "", false, false], [3, 3, 26, 28, "related-to", "", true, false], [3, 3, 35, 36, "related-to", "", true, false], [11, 12, 3, 3, "type-of", "", false, false], [15, 16, 3, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Las", "t\u00e9cnicas", "de", "optimizaci\u00f3n", "de", "la", "investigaci\u00f3n", "operativa", ",", "como", "la", "programaci\u00f3n", "lineal", "o", "la", "programaci\u00f3n", "din\u00e1mica", ",", "suelen", "ser", "poco", "pr\u00e1cticas", "para", "los", "problemas", "de", "ingenier\u00eda", "de", "software", "a", "gran", "escala", "debido", "a", "su", "complejidad", "computacional", "."], "sentence-detokenized": "Las t\u00e9cnicas de optimizaci\u00f3n de la investigaci\u00f3n operativa, como la programaci\u00f3n lineal o la programaci\u00f3n din\u00e1mica, suelen ser poco pr\u00e1cticas para los problemas de ingenier\u00eda de software a gran escala debido a su complejidad computacional.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 28], [29, 31], [32, 34], [35, 48], [49, 58], [58, 59], [60, 64], [65, 67], [68, 80], [81, 87], [88, 89], [90, 92], [93, 105], [106, 114], [114, 115], [116, 122], [123, 126], [127, 131], [132, 141], [142, 146], [147, 150], [151, 160], [161, 163], [164, 174], [175, 177], [178, 186], [187, 188], [189, 193], [194, 200], [201, 207], [208, 209], [210, 212], [213, 224], [225, 238], [238, 239]]}
{"doc_key": "ai-dev-77", "ner": [[0, 1, "metrics"], [8, 8, "metrics"], [11, 13, "metrics"], [18, 19, "metrics"], [23, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 8, 8, "compare", "", false, false], [0, 1, 11, 13, "compare", "", false, false], [18, 19, 11, 13, "part-of", "", false, false], [23, 27, 11, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["La", "sensibilidad", "no", "es", "lo", "mismo", "que", "la", "precisi\u00f3n", "o", "el", "valor", "predictivo", "positivo", "(", "relaci\u00f3n", "entre", "los", "VERDADEROS", "positivos", "y", "la", "combinaci\u00f3n", "de", "VERDADEROS", "y", "FALSOS", "positivos", ")", ",", "que", "es", "tanto", "una", "declaraci\u00f3n", "sobre", "la", "proporci\u00f3n", "de", "positivos", "reales", "en", "la", "poblaci\u00f3n", "analizada", "como", "sobre", "la", "prueba", "."], "sentence-detokenized": "La sensibilidad no es lo mismo que la precisi\u00f3n o el valor predictivo positivo (relaci\u00f3n entre los VERDADEROS positivos y la combinaci\u00f3n de VERDADEROS y FALSOS positivos), que es tanto una declaraci\u00f3n sobre la proporci\u00f3n de positivos reales en la poblaci\u00f3n analizada como sobre la prueba.", "token2charspan": [[0, 2], [3, 15], [16, 18], [19, 21], [22, 24], [25, 30], [31, 34], [35, 37], [38, 47], [48, 49], [50, 52], [53, 58], [59, 69], [70, 78], [79, 80], [80, 88], [89, 94], [95, 98], [99, 109], [110, 119], [120, 121], [122, 124], [125, 136], [137, 139], [140, 150], [151, 152], [153, 159], [160, 169], [169, 170], [170, 171], [172, 175], [176, 178], [179, 184], [185, 188], [189, 200], [201, 206], [207, 209], [210, 220], [221, 223], [224, 233], [234, 240], [241, 243], [244, 246], [247, 256], [257, 266], [267, 271], [272, 277], [278, 280], [281, 287], [287, 288]]}
{"doc_key": "ai-dev-78", "ner": [[3, 4, "person"], [10, 10, "product"], [13, 13, "person"], [28, 28, "person"], [35, 36, "person"], [48, 49, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6], "relations": [[10, 10, 3, 4, "artifact", "", false, false], [35, 36, 48, 49, "role", "convinces", false, false], [48, 49, 10, 10, "role", "producer", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["El", "gui\u00f3n", "de", "Hampton", "Fancher", "--", "Inicialmente", "no", "se", "titul\u00f3", "Androide", "-", "Ver", "Sammon", ",", "pp.", "32", "y", "38", "para", "la", "explicaci\u00f3n", "--", "fue", "opcionado", "en", "1977", ".", "Sammon", ",", "pp", ".", "23-30", "El", "productor", "Michael", "Deeley", "se", "interes\u00f3", "por", "el", "borrador", "de", "Fancher", "y", "convenci\u00f3", "al", "director", "Ridley", "Scott", "para", "que", "lo", "filmara", "."], "sentence-detokenized": "El gui\u00f3n de Hampton Fancher -- Inicialmente no se titul\u00f3 Androide - Ver Sammon, pp. 32 y 38 para la explicaci\u00f3n -- fue opcionado en 1977. Sammon, pp. 23-30 El productor Michael Deeley se interes\u00f3 por el borrador de Fancher y convenci\u00f3 al director Ridley Scott para que lo filmara.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 19], [20, 27], [28, 30], [31, 43], [44, 46], [47, 49], [50, 56], [57, 65], [66, 67], [68, 71], [72, 78], [78, 79], [80, 83], [84, 86], [87, 88], [89, 91], [92, 96], [97, 99], [100, 111], [112, 114], [115, 118], [119, 128], [129, 131], [132, 136], [136, 137], [138, 144], [144, 145], [146, 148], [148, 149], [150, 155], [156, 158], [159, 168], [169, 176], [177, 183], [184, 186], [187, 195], [196, 199], [200, 202], [203, 211], [212, 214], [215, 222], [223, 224], [225, 234], [235, 237], [238, 246], [247, 253], [254, 259], [260, 264], [265, 268], [269, 271], [272, 279], [279, 280]]}
{"doc_key": "ai-dev-79", "ner": [[0, 3, "field"], [6, 8, "task"], [11, 12, "task"], [15, 21, "misc"], [24, 26, "field"], [29, 29, "task"], [32, 34, "task"], [39, 41, "field"], [45, 49, "task"], [52, 52, "task"], [55, 56, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[6, 8, 0, 3, "part-of", "", false, false], [11, 12, 0, 3, "part-of", "", false, false], [15, 21, 0, 3, "part-of", "", false, false], [24, 26, 0, 3, "part-of", "", false, false], [29, 29, 0, 3, "part-of", "", false, false], [32, 34, 0, 3, "part-of", "", false, false], [39, 41, 0, 3, "part-of", "", false, false], [45, 49, 0, 3, "part-of", "", false, false], [52, 52, 0, 3, "part-of", "", false, false], [55, 56, 0, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["El", "an\u00e1lisis", "de", "textos", "implica", "la", "recuperaci\u00f3n", "de", "informaci\u00f3n", ",", "el", "an\u00e1lisis", "l\u00e9xico", "para", "estudiar", "las", "distribuciones", "de", "frecuencia", "de", "las", "palabras", ",", "el", "reconocimiento", "de", "patrones", ",", "el", "etiquetado/anotado", ",", "la", "extracci\u00f3n", "de", "informaci\u00f3n", ",", "las", "t\u00e9cnicas", "de", "miner\u00eda", "de", "datos", ",", "incluido", "el", "an\u00e1lisis", "de", "enlaces", "y", "asociaciones", ",", "la", "visualizaci\u00f3n", "y", "el", "an\u00e1lisis", "predictivo", "."], "sentence-detokenized": "El an\u00e1lisis de textos implica la recuperaci\u00f3n de informaci\u00f3n, el an\u00e1lisis l\u00e9xico para estudiar las distribuciones de frecuencia de las palabras, el reconocimiento de patrones, el etiquetado/anotado, la extracci\u00f3n de informaci\u00f3n, las t\u00e9cnicas de miner\u00eda de datos, incluido el an\u00e1lisis de enlaces y asociaciones, la visualizaci\u00f3n y el an\u00e1lisis predictivo.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 21], [22, 29], [30, 32], [33, 45], [46, 48], [49, 60], [60, 61], [62, 64], [65, 73], [74, 80], [81, 85], [86, 94], [95, 98], [99, 113], [114, 116], [117, 127], [128, 130], [131, 134], [135, 143], [143, 144], [145, 147], [148, 162], [163, 165], [166, 174], [174, 175], [176, 178], [179, 197], [197, 198], [199, 201], [202, 212], [213, 215], [216, 227], [227, 228], [229, 232], [233, 241], [242, 244], [245, 252], [253, 255], [256, 261], [261, 262], [263, 271], [272, 274], [275, 283], [284, 286], [287, 294], [295, 296], [297, 309], [309, 310], [311, 313], [314, 327], [328, 329], [330, 332], [333, 341], [342, 352], [352, 353]]}
{"doc_key": "ai-dev-80", "ner": [[3, 3, "product"], [11, 12, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 3, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Varias", "m\u00e9tricas", "utilizan", "WordNet", ",", "una", "base", "de", "datos", "l\u00e9xica", "de", "palabras", "inglesas", "construida", "manualmente", "."], "sentence-detokenized": "Varias m\u00e9tricas utilizan WordNet, una base de datos l\u00e9xica de palabras inglesas construida manualmente.", "token2charspan": [[0, 6], [7, 15], [16, 24], [25, 32], [32, 33], [34, 37], [38, 42], [43, 45], [46, 51], [52, 58], [59, 61], [62, 70], [71, 79], [80, 90], [91, 102], [102, 103]]}
{"doc_key": "ai-dev-81", "ner": [[8, 9, "field"], [11, 13, "task"], [15, 20, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["El", "sistema", "utiliza", "una", "combinaci\u00f3n", "de", "t\u00e9cnicas", "de", "ling\u00fc\u00edstica", "computacional", ",", "recuperaci\u00f3n", "de", "informaci\u00f3n", "y", "representaci\u00f3n", "del", "conocimiento", "para", "encontrar", "respuestas", "."], "sentence-detokenized": "El sistema utiliza una combinaci\u00f3n de t\u00e9cnicas de ling\u00fc\u00edstica computacional, recuperaci\u00f3n de informaci\u00f3n y representaci\u00f3n del conocimiento para encontrar respuestas.", "token2charspan": [[0, 2], [3, 10], [11, 18], [19, 22], [23, 34], [35, 37], [38, 46], [47, 49], [50, 61], [62, 75], [75, 76], [77, 89], [90, 92], [93, 104], [105, 106], [107, 121], [122, 125], [126, 138], [139, 143], [144, 153], [154, 164], [164, 165]]}
{"doc_key": "ai-dev-82", "ner": [[6, 8, "metrics"], [14, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 14, 14, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Como", "m\u00e9trica", "de", "rendimiento", ",", "el", "coeficiente", "de", "incertidumbre", "tiene", "la", "ventaja", "sobre", "la", "precisi\u00f3n", "simple", "de", "que", "no", "se", "ve", "afectado", "por", "los", "tama\u00f1os", "relativos", "de", "las", "diferentes", "clases", "."], "sentence-detokenized": "Como m\u00e9trica de rendimiento, el coeficiente de incertidumbre tiene la ventaja sobre la precisi\u00f3n simple de que no se ve afectado por los tama\u00f1os relativos de las diferentes clases.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 27], [27, 28], [29, 31], [32, 43], [44, 46], [47, 60], [61, 66], [67, 69], [70, 77], [78, 83], [84, 86], [87, 96], [97, 103], [104, 106], [107, 110], [111, 113], [114, 116], [117, 119], [120, 128], [129, 132], [133, 136], [137, 144], [145, 154], [155, 157], [158, 161], [162, 172], [173, 179], [179, 180]]}
{"doc_key": "ai-dev-83", "ner": [[9, 10, "algorithm"], [13, 15, "algorithm"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Los", "investigadores", "han", "intentado", "varios", "m\u00e9todos", ",", "como", "el", "flujo", "\u00f3ptico", ",", "el", "filtrado", "de", "Kalman", ",", "los", "modelos", "de", "Markov", "ocultos", ",", "etc", "."], "sentence-detokenized": "Los investigadores han intentado varios m\u00e9todos, como el flujo \u00f3ptico, el filtrado de Kalman, los modelos de Markov ocultos, etc.", "token2charspan": [[0, 3], [4, 18], [19, 22], [23, 32], [33, 39], [40, 47], [47, 48], [49, 53], [54, 56], [57, 62], [63, 69], [69, 70], [71, 73], [74, 82], [83, 85], [86, 92], [92, 93], [94, 97], [98, 105], [106, 108], [109, 115], [116, 123], [123, 124], [125, 128], [128, 129]]}
{"doc_key": "ai-dev-84", "ner": [[12, 15, "conference"], [28, 30, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ha", "ocupado", "los", "cargos", "de", "presidenta", ",", "vicepresidenta", "y", "secretaria-tesorera", "de", "la", "Association", "for", "Computational", "Linguistics", "y", "ha", "sido", "miembro", "de", "la", "junta", "directiva", "y", "secretaria", "de", "la", "Computing", "Research", "Association", "."], "sentence-detokenized": "Ha ocupado los cargos de presidenta, vicepresidenta y secretaria-tesorera de la Association for Computational Linguistics y ha sido miembro de la junta directiva y secretaria de la Computing Research Association.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 21], [22, 24], [25, 35], [35, 36], [37, 51], [52, 53], [54, 73], [74, 76], [77, 79], [80, 91], [92, 95], [96, 109], [110, 121], [122, 123], [124, 126], [127, 131], [132, 139], [140, 142], [143, 145], [146, 151], [152, 161], [162, 163], [164, 174], [175, 177], [178, 180], [181, 190], [191, 199], [200, 211], [211, 212]]}
{"doc_key": "ai-dev-85", "ner": [[7, 7, "programlang"], [9, 9, "product"], [11, 11, "programlang"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 11, 11, "compare", "", false, false], [7, 7, 14, 15, "related-to", "supports", false, false], [9, 9, 11, 11, "compare", "", false, false], [9, 9, 14, 15, "related-to", "supports", false, false], [11, 11, 14, 15, "related-to", "supports", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Al", "igual", "que", "otros", "lenguajes", "similares", "como", "APL", "y", "MATLAB", ",", "R", "soporta", "la", "aritm\u00e9tica", "matricial", "."], "sentence-detokenized": "Al igual que otros lenguajes similares como APL y MATLAB, R soporta la aritm\u00e9tica matricial.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 18], [19, 28], [29, 38], [39, 43], [44, 47], [48, 49], [50, 56], [56, 57], [58, 59], [60, 67], [68, 70], [71, 81], [82, 91], [91, 92]]}
{"doc_key": "ai-dev-86", "ner": [[10, 13, "misc"], [16, 17, "organisation"], [21, 22, "researcher"], [26, 28, "university"], [33, 39, "misc"], [41, 41, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 13, 16, 17, "physical", "", false, false], [10, 13, 33, 39, "temporal", "", false, false], [21, 22, 10, 13, "role", "arranges", false, false], [21, 22, 26, 28, "role", "works_for", false, false], [41, 41, 10, 13, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["El", "7", "de", "junio", "de", "2014", ",", "en", "un", "concurso", "del", "test", "de", "Turing", "en", "la", "Royal", "Society", ",", "organizado", "por", "Kevin", "Warwick", ",", "de", "la", "Universidad", "de", "Reading", ",", "para", "conmemorar", "el", "60\u00ba", "aniversario", "de", "la", "muerte", "de", "Turing", ",", "Goostman", "gan\u00f3", "despu\u00e9s", "de", "que", "el", "33%", "de", "los", "jueces", "estuvieran", "convencidos", "de", "que", "el", "bot", "era", "humano", "."], "sentence-detokenized": "El 7 de junio de 2014, en un concurso del test de Turing en la Royal Society, organizado por Kevin Warwick, de la Universidad de Reading, para conmemorar el 60\u00ba aniversario de la muerte de Turing, Goostman gan\u00f3 despu\u00e9s de que el 33% de los jueces estuvieran convencidos de que el bot era humano.", "token2charspan": [[0, 2], [3, 4], [5, 7], [8, 13], [14, 16], [17, 21], [21, 22], [23, 25], [26, 28], [29, 37], [38, 41], [42, 46], [47, 49], [50, 56], [57, 59], [60, 62], [63, 68], [69, 76], [76, 77], [78, 88], [89, 92], [93, 98], [99, 106], [106, 107], [108, 110], [111, 113], [114, 125], [126, 128], [129, 136], [136, 137], [138, 142], [143, 153], [154, 156], [157, 160], [161, 172], [173, 175], [176, 178], [179, 185], [186, 188], [189, 195], [195, 196], [197, 205], [206, 210], [211, 218], [219, 221], [222, 225], [226, 228], [229, 232], [233, 235], [236, 239], [240, 246], [247, 257], [258, 269], [270, 272], [273, 276], [277, 279], [280, 283], [284, 287], [288, 294], [294, 295]]}
{"doc_key": "ai-dev-87", "ner": [[1, 2, "product"], [4, 4, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 1, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Un", "robot", "colaborativo", "o", "cobot", "es", "un", "robot", "que", "puede", "interactuar", "de", "forma", "segura", "y", "eficaz", "con", "trabajadores", "humanos", "mientras", "realiza", "tareas", "industriales", "sencillas", "."], "sentence-detokenized": "Un robot colaborativo o cobot es un robot que puede interactuar de forma segura y eficaz con trabajadores humanos mientras realiza tareas industriales sencillas.", "token2charspan": [[0, 2], [3, 8], [9, 21], [22, 23], [24, 29], [30, 32], [33, 35], [36, 41], [42, 45], [46, 51], [52, 63], [64, 66], [67, 72], [73, 79], [80, 81], [82, 88], [89, 92], [93, 105], [106, 113], [114, 122], [123, 130], [131, 137], [138, 150], [151, 160], [160, 161]]}
{"doc_key": "ai-dev-88", "ner": [[13, 15, "field"], [18, 21, "task"], [24, 26, "task"], [29, 31, "task"], [34, 36, "task"], [39, 41, "task"], [44, 48, "task"], [51, 53, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[18, 21, 13, 15, "part-of", "task_part_of_field", false, false], [24, 26, 13, 15, "part-of", "task_part_of_field", false, false], [29, 31, 13, 15, "part-of", "task_part_of_field", false, false], [34, 36, 13, 15, "part-of", "task_part_of_field", false, false], [39, 41, 13, 15, "part-of", "task_part_of_field", false, false], [44, 48, 13, 15, "part-of", "task_part_of_field", false, false], [51, 53, 13, 15, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Este", "marco", "general", "se", "ha", "aplicado", "a", "una", "gran", "variedad", "de", "problemas", "de", "visi\u00f3n", "por", "ordenador", ",", "como", "la", "detecci\u00f3n", "de", "rasgos", ",", "la", "clasificaci\u00f3n", "de", "rasgos", ",", "la", "segmentaci\u00f3n", "de", "im\u00e1genes", ",", "el", "emparejamiento", "de", "im\u00e1genes", ",", "la", "estimaci\u00f3n", "del", "movimiento", ",", "el", "c\u00e1lculo", "de", "claves", "de", "forma", "y", "el", "reconocimiento", "de", "objetos", "."], "sentence-detokenized": "Este marco general se ha aplicado a una gran variedad de problemas de visi\u00f3n por ordenador, como la detecci\u00f3n de rasgos, la clasificaci\u00f3n de rasgos, la segmentaci\u00f3n de im\u00e1genes, el emparejamiento de im\u00e1genes, la estimaci\u00f3n del movimiento, el c\u00e1lculo de claves de forma y el reconocimiento de objetos.", "token2charspan": [[0, 4], [5, 10], [11, 18], [19, 21], [22, 24], [25, 33], [34, 35], [36, 39], [40, 44], [45, 53], [54, 56], [57, 66], [67, 69], [70, 76], [77, 80], [81, 90], [90, 91], [92, 96], [97, 99], [100, 109], [110, 112], [113, 119], [119, 120], [121, 123], [124, 137], [138, 140], [141, 147], [147, 148], [149, 151], [152, 164], [165, 167], [168, 176], [176, 177], [178, 180], [181, 195], [196, 198], [199, 207], [207, 208], [209, 211], [212, 222], [223, 226], [227, 237], [237, 238], [239, 241], [242, 249], [250, 252], [253, 259], [260, 262], [263, 268], [269, 270], [271, 273], [274, 288], [289, 291], [292, 299], [299, 300]]}
{"doc_key": "ai-dev-89", "ner": [[6, 9, "task"], [11, 14, "algorithm"], [19, 20, "algorithm"], [31, 32, "algorithm"], [36, 37, "algorithm"], [41, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 9, 11, 14, "part-of", "", false, false], [6, 9, 19, 20, "usage", "", false, false], [11, 14, 31, 32, "named", "same", false, false], [31, 32, 36, 37, "related-to", "", false, false], [31, 32, 41, 42, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["En", "muchas", "aplicaciones", "pr\u00e1cticas", ",", "la", "estimaci\u00f3n", "de", "los", "par\u00e1metros", "de", "los", "modelos", "Bayes", "ingenuos", "utiliza", "el", "m\u00e9todo", "de", "m\u00e1xima", "verosimilitud", ";", "es", "decir", ",", "se", "puede", "trabajar", "con", "el", "modelo", "Bayes", "ingenuo", "sin", "aceptar", "la", "probabilidad", "bayesiana", "ni", "utilizar", "ning\u00fan", "m\u00e9todo", "bayesiano", "."], "sentence-detokenized": "En muchas aplicaciones pr\u00e1cticas, la estimaci\u00f3n de los par\u00e1metros de los modelos Bayes ingenuos utiliza el m\u00e9todo de m\u00e1xima verosimilitud; es decir, se puede trabajar con el modelo Bayes ingenuo sin aceptar la probabilidad bayesiana ni utilizar ning\u00fan m\u00e9todo bayesiano.", "token2charspan": [[0, 2], [3, 9], [10, 22], [23, 32], [32, 33], [34, 36], [37, 47], [48, 50], [51, 54], [55, 65], [66, 68], [69, 72], [73, 80], [81, 86], [87, 95], [96, 103], [104, 106], [107, 113], [114, 116], [117, 123], [124, 137], [137, 138], [139, 141], [142, 147], [147, 148], [149, 151], [152, 157], [158, 166], [167, 170], [171, 173], [174, 180], [181, 186], [187, 194], [195, 198], [199, 206], [207, 209], [210, 222], [223, 232], [233, 235], [236, 244], [245, 251], [252, 258], [259, 268], [268, 269]]}
{"doc_key": "ai-dev-90", "ner": [[2, 4, "researcher"], [6, 7, "misc"], [11, 14, "university"], [16, 18, "researcher"], [20, 21, "misc"], [28, 28, "university"], [30, 30, "university"], [32, 32, "misc"], [40, 42, "university"], [48, 51, "misc"], [53, 56, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[2, 4, 11, 14, "physical", "", false, false], [2, 4, 11, 14, "role", "", false, false], [2, 4, 16, 18, "social", "brothers", false, false], [6, 7, 2, 4, "named", "", false, false], [16, 18, 28, 28, "physical", "", false, false], [16, 18, 28, 28, "role", "", false, false], [16, 18, 30, 30, "physical", "", false, false], [16, 18, 30, 30, "role", "", false, false], [16, 18, 40, 42, "physical", "", false, false], [16, 18, 40, 42, "role", "", false, false], [20, 21, 16, 18, "named", "", false, false], [32, 32, 16, 18, "origin", "", false, false], [48, 51, 16, 18, "artifact", "", false, false], [48, 51, 53, 56, "part-of", "part", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Hermanos", "-", "Victor", "Gershevich", "Katz", ",", "matem\u00e1tico", "estadounidense", ",", "profesor", "del", "Instituto", "Tecnol\u00f3gico", "de", "Massachusetts", ";", "Mikhail", "Gershevich", "Katz", ",", "matem\u00e1tico", "israel\u00ed", ",", "licenciado", "por", "las", "universidades", "de", "Harvard", "y", "Columbia", "(", "doctorado", ",", "1984", ")", ",", "profesor", "de", "la", "Universidad", "de", "Bar-Ilan", ",", "autor", "de", "la", "monograf\u00eda", "Systolic", "Geometry", "and", "Topology", "(", "Mathematical", "Surveys", "and", "Monographs", ",", "vol", ".", "I", ")", "."], "sentence-detokenized": "Hermanos - Victor Gershevich Katz, matem\u00e1tico estadounidense, profesor del Instituto Tecnol\u00f3gico de Massachusetts; Mikhail Gershevich Katz, matem\u00e1tico israel\u00ed, licenciado por las universidades de Harvard y Columbia (doctorado, 1984), profesor de la Universidad de Bar-Ilan, autor de la monograf\u00eda Systolic Geometry and Topology (Mathematical Surveys and Monographs, vol. I).", "token2charspan": [[0, 8], [9, 10], [11, 17], [18, 28], [29, 33], [33, 34], [35, 45], [46, 60], [60, 61], [62, 70], [71, 74], [75, 84], [85, 96], [97, 99], [100, 113], [113, 114], [115, 122], [123, 133], [134, 138], [138, 139], [140, 150], [151, 158], [158, 159], [160, 170], [171, 174], [175, 178], [179, 192], [193, 195], [196, 203], [204, 205], [206, 214], [215, 216], [216, 225], [225, 226], [227, 231], [231, 232], [232, 233], [234, 242], [243, 245], [246, 248], [249, 260], [261, 263], [264, 272], [272, 273], [274, 279], [280, 282], [283, 285], [286, 296], [297, 305], [306, 314], [315, 318], [319, 327], [328, 329], [329, 341], [342, 349], [350, 353], [354, 364], [364, 365], [366, 369], [369, 370], [371, 372], [372, 373], [373, 374]]}
{"doc_key": "ai-dev-91", "ner": [[5, 6, "person"], [11, 12, "conference"], [17, 22, "organisation"], [24, 33, "location"], [37, 37, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 11, 12, "physical", "", false, false], [5, 6, 11, 12, "role", "", false, false], [5, 6, 17, 22, "role", "", false, false], [17, 22, 24, 33, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["En", "el", "a\u00f1o", "2000", ",", "Manuel", "Toharia", ",", "ponente", "en", "anteriores", "Campus", "Parties", ",", "y", "director", "del", "Museo", "de", "las", "Ciencias", "Pr\u00edncipe", "Felipe", "de", "la", "Ciudad", "de", "las", "Artes", "y", "las", "Ciencias", "de", "Valencia", ",", "sugiri\u00f3", "a", "Ragageles", "ampliar", "y", "hacer", "m\u00e1s", "internacional", "el", "evento", "traslad\u00e1ndolo", "al", "famoso", "museo", "."], "sentence-detokenized": "En el a\u00f1o 2000, Manuel Toharia, ponente en anteriores Campus Parties, y director del Museo de las Ciencias Pr\u00edncipe Felipe de la Ciudad de las Artes y las Ciencias de Valencia, sugiri\u00f3 a Ragageles ampliar y hacer m\u00e1s internacional el evento traslad\u00e1ndolo al famoso museo.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 14], [14, 15], [16, 22], [23, 30], [30, 31], [32, 39], [40, 42], [43, 53], [54, 60], [61, 68], [68, 69], [70, 71], [72, 80], [81, 84], [85, 90], [91, 93], [94, 97], [98, 106], [107, 115], [116, 122], [123, 125], [126, 128], [129, 135], [136, 138], [139, 142], [143, 148], [149, 150], [151, 154], [155, 163], [164, 166], [167, 175], [175, 176], [177, 184], [185, 186], [187, 196], [197, 204], [205, 206], [207, 212], [213, 216], [217, 230], [231, 233], [234, 240], [241, 254], [255, 257], [258, 264], [265, 270], [270, 271]]}
{"doc_key": "ai-dev-92", "ner": [[5, 8, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["En", "20", "minutos", ",", "un", "sistema", "de", "reconocimiento", "facial", "identifica", "los", "datos", "personales", ",", "como", "el", "apellido", ",", "el", "n\u00famero", "de", "DNI", "y", "la", "direcci\u00f3n", ",", "que", "se", "muestran", "en", "la", "calle", "en", "una", "pantalla", "publicitaria", "."], "sentence-detokenized": "En 20 minutos, un sistema de reconocimiento facial identifica los datos personales, como el apellido, el n\u00famero de DNI y la direcci\u00f3n, que se muestran en la calle en una pantalla publicitaria.", "token2charspan": [[0, 2], [3, 5], [6, 13], [13, 14], [15, 17], [18, 25], [26, 28], [29, 43], [44, 50], [51, 61], [62, 65], [66, 71], [72, 82], [82, 83], [84, 88], [89, 91], [92, 100], [100, 101], [102, 104], [105, 111], [112, 114], [115, 118], [119, 120], [121, 123], [124, 133], [133, 134], [135, 138], [139, 141], [142, 150], [151, 153], [154, 156], [157, 162], [163, 165], [166, 169], [170, 178], [179, 191], [191, 192]]}
{"doc_key": "ai-dev-93", "ner": [[14, 15, "field"], [17, 17, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "investigaci\u00f3n", "reciente", "se", "ha", "centrado", "cada", "vez", "m\u00e1s", "en", "los", "algoritmos", "de", "aprendizaje", "no", "supervisado", "y", "semisupervisado", "."], "sentence-detokenized": "La investigaci\u00f3n reciente se ha centrado cada vez m\u00e1s en los algoritmos de aprendizaje no supervisado y semisupervisado.", "token2charspan": [[0, 2], [3, 16], [17, 25], [26, 28], [29, 31], [32, 40], [41, 45], [46, 49], [50, 53], [54, 56], [57, 60], [61, 71], [72, 74], [75, 86], [87, 89], [90, 101], [102, 103], [104, 119], [119, 120]]}
{"doc_key": "ai-dev-94", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["C\u00e1lculo", "de", "este", "ejemplo", "mediante", "c\u00f3digo", "Python", ":"], "sentence-detokenized": "C\u00e1lculo de este ejemplo mediante c\u00f3digo Python:", "token2charspan": [[0, 7], [8, 10], [11, 15], [16, 23], [24, 32], [33, 39], [40, 46], [46, 47]]}
{"doc_key": "ai-dev-95", "ner": [[10, 12, "task"], [20, 21, "field"], [23, 26, "algorithm"], [28, 28, "algorithm"], [32, 34, "algorithm"], [37, 38, "researcher"], [40, 41, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[23, 26, 20, 21, "part-of", "", false, false], [23, 26, 32, 34, "type-of", "", false, false], [23, 26, 37, 38, "origin", "", false, false], [23, 26, 40, 41, "origin", "", false, false], [28, 28, 23, 26, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Sin", "embargo", ",", "hoy", "en", "d\u00eda", ",", "muchos", "aspectos", "del", "reconocimiento", "del", "habla", "han", "sido", "asumidos", "por", "un", "m\u00e9todo", "de", "aprendizaje", "profundo", "llamado", "memoria", "a", "corto", "plazo", "(", "LSTM", ")", ",", "una", "red", "neuronal", "recurrente", "publicada", "por", "Sepp", "Hochreiter", "y", "J\u00fcrgen", "Schmidhuber", "en", "1997", "."], "sentence-detokenized": "Sin embargo, hoy en d\u00eda, muchos aspectos del reconocimiento del habla han sido asumidos por un m\u00e9todo de aprendizaje profundo llamado memoria a corto plazo (LSTM), una red neuronal recurrente publicada por Sepp Hochreiter y J\u00fcrgen Schmidhuber en 1997.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 19], [20, 23], [23, 24], [25, 31], [32, 40], [41, 44], [45, 59], [60, 63], [64, 69], [70, 73], [74, 78], [79, 87], [88, 91], [92, 94], [95, 101], [102, 104], [105, 116], [117, 125], [126, 133], [134, 141], [142, 143], [144, 149], [150, 155], [156, 157], [157, 161], [161, 162], [162, 163], [164, 167], [168, 171], [172, 180], [181, 191], [192, 201], [202, 205], [206, 210], [211, 221], [222, 223], [224, 230], [231, 242], [243, 245], [246, 250], [250, 251]]}
{"doc_key": "ai-dev-96", "ner": [[11, 11, "algorithm"], [18, 18, "algorithm"], [23, 23, "algorithm"], [28, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 18, 18, "compare", "", false, false], [11, 11, 28, 28, "named", "same", false, false], [23, 23, 28, 28, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["En", "los", "resultados", "experimentales", "preliminares", "con", "conjuntos", "de", "datos", "ruidosos", ",", "BrownBoost", "super\u00f3", "el", "error", "de", "generalizaci\u00f3n", "de", "AdaBoost", ";", "sin", "embargo", ",", "LogitBoost", "funcion\u00f3", "tan", "bien", "como", "BrownBoost", "."], "sentence-detokenized": "En los resultados experimentales preliminares con conjuntos de datos ruidosos, BrownBoost super\u00f3 el error de generalizaci\u00f3n de AdaBoost; sin embargo, LogitBoost funcion\u00f3 tan bien como BrownBoost.", "token2charspan": [[0, 2], [3, 6], [7, 17], [18, 32], [33, 45], [46, 49], [50, 59], [60, 62], [63, 68], [69, 77], [77, 78], [79, 89], [90, 96], [97, 99], [100, 105], [106, 108], [109, 123], [124, 126], [127, 135], [135, 136], [137, 140], [141, 148], [148, 149], [150, 160], [161, 169], [170, 173], [174, 178], [179, 183], [184, 194], [194, 195]]}
{"doc_key": "ai-dev-97", "ner": [[0, 2, "algorithm"], [6, 8, "researcher"], [10, 11, "country"], [15, 17, "researcher"], [22, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 6, 8, "part-of", "", false, false], [6, 8, 10, 11, "physical", "", false, false], [22, 23, 15, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "programaci\u00f3n", "evolutiva", "fue", "introducida", "por", "Lawrence", "J.", "Fogel", "en", "Estados", "Unidos", ",", "mientras", "que", "John", "Henry", "Holland", "llam\u00f3", "a", "su", "m\u00e9todo", "algoritmo", "gen\u00e9tico", "."], "sentence-detokenized": "La programaci\u00f3n evolutiva fue introducida por Lawrence J. Fogel en Estados Unidos, mientras que John Henry Holland llam\u00f3 a su m\u00e9todo algoritmo gen\u00e9tico.", "token2charspan": [[0, 2], [3, 15], [16, 25], [26, 29], [30, 41], [42, 45], [46, 54], [55, 57], [58, 63], [64, 66], [67, 74], [75, 81], [81, 82], [83, 91], [92, 95], [96, 100], [101, 106], [107, 114], [115, 120], [121, 122], [123, 125], [126, 132], [133, 142], [143, 151], [151, 152]]}
{"doc_key": "ai-dev-98", "ner": [[3, 3, "researcher"], [5, 5, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"], [24, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 3, 15, 16, "role", "", false, false], [3, 3, 18, 19, "role", "", false, false], [3, 3, 21, 22, "role", "", false, false], [3, 3, 24, 25, "role", "", false, false], [5, 5, 15, 16, "role", "", false, false], [5, 5, 18, 19, "role", "", false, false], [5, 5, 21, 22, "role", "", false, false], [5, 5, 24, 25, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Los", "c\u00e1lculos", "de", "Doug", ",", "Alan", "y", "sus", "colegas", "(", "entre", "los", "que", "se", "encontraban", "Marvin", "Minsky", ",", "Allen", "Newell", ",", "Edward", "Feigenbaum", "y", "John", "McCarthy", ")", "indicaban", "que", "ese", "esfuerzo", "requerir\u00eda", "entre", "1000", "y", "3000", "a\u00f1os-persona", "de", "esfuerzo", ",", "mucho", "m\u00e1s", "all\u00e1", "del", "modelo", "de", "proyecto", "acad\u00e9mico", "est\u00e1ndar", "."], "sentence-detokenized": "Los c\u00e1lculos de Doug, Alan y sus colegas (entre los que se encontraban Marvin Minsky, Allen Newell, Edward Feigenbaum y John McCarthy) indicaban que ese esfuerzo requerir\u00eda entre 1000 y 3000 a\u00f1os-persona de esfuerzo, mucho m\u00e1s all\u00e1 del modelo de proyecto acad\u00e9mico est\u00e1ndar.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 20], [20, 21], [22, 26], [27, 28], [29, 32], [33, 40], [41, 42], [42, 47], [48, 51], [52, 55], [56, 58], [59, 70], [71, 77], [78, 84], [84, 85], [86, 91], [92, 98], [98, 99], [100, 106], [107, 117], [118, 119], [120, 124], [125, 133], [133, 134], [135, 144], [145, 148], [149, 152], [153, 161], [162, 172], [173, 178], [179, 183], [184, 185], [186, 190], [191, 203], [204, 206], [207, 215], [215, 216], [217, 222], [223, 226], [227, 231], [232, 235], [236, 242], [243, 245], [246, 254], [255, 264], [265, 273], [273, 274]]}
{"doc_key": "ai-dev-99", "ner": [[8, 11, "metrics"], [13, 13, "metrics"], [16, 19, "metrics"], [22, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 11, 13, 13, "part-of", "implemented_in", false, false], [16, 19, 22, 22, "part-of", "implemented_in", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Los", "criterios", "m\u00e1s", "comunes", "son", "el", "criterio", "de", "error", "cuadr\u00e1tico", "medio", "implementado", "en", "MSECriterion", "y", "el", "criterio", "de", "entrop\u00eda", "cruzada", "implementado", "en", "NLLCriterion", "."], "sentence-detokenized": "Los criterios m\u00e1s comunes son el criterio de error cuadr\u00e1tico medio implementado en MSECriterion y el criterio de entrop\u00eda cruzada implementado en NLLCriterion.", "token2charspan": [[0, 3], [4, 13], [14, 17], [18, 25], [26, 29], [30, 32], [33, 41], [42, 44], [45, 50], [51, 61], [62, 67], [68, 80], [81, 83], [84, 96], [97, 98], [99, 101], [102, 110], [111, 113], [114, 122], [123, 130], [131, 143], [144, 146], [147, 159], [159, 160]]}
{"doc_key": "ai-dev-100", "ner": [[0, 0, "researcher"], [11, 12, "organisation"], [18, 25, "misc"], [31, 36, "conference"], [42, 43, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 11, 12, "role", "", false, false], [0, 0, 31, 36, "role", "", false, false], [0, 0, 42, 43, "role", "", false, false], [18, 25, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Zurada", "ha", "servido", "a", "la", "profesi\u00f3n", "de", "la", "ingenier\u00eda", "como", "voluntario", "del", "IEEE", "durante", "mucho", "tiempo", ":", "como", "Vicepresidente", "de", "Actividades", "T\u00e9cnicas", "del", "IEEE", "en", "2014", ",", "como", "Presidente", "de", "la", "Sociedad", "de", "Inteligencia", "Computacional", "del", "IEEE", "en", "2004-05", "y", "como", "miembro", "del", "ADCOM", "en", "2009-14", ",", "2016-18", "y", "a\u00f1os", "anteriores", "."], "sentence-detokenized": "Zurada ha servido a la profesi\u00f3n de la ingenier\u00eda como voluntario del IEEE durante mucho tiempo: como Vicepresidente de Actividades T\u00e9cnicas del IEEE en 2014, como Presidente de la Sociedad de Inteligencia Computacional del IEEE en 2004-05 y como miembro del ADCOM en 2009-14, 2016-18 y a\u00f1os anteriores.", "token2charspan": [[0, 6], [7, 9], [10, 17], [18, 19], [20, 22], [23, 32], [33, 35], [36, 38], [39, 49], [50, 54], [55, 65], [66, 69], [70, 74], [75, 82], [83, 88], [89, 95], [95, 96], [97, 101], [102, 116], [117, 119], [120, 131], [132, 140], [141, 144], [145, 149], [150, 152], [153, 157], [157, 158], [159, 163], [164, 174], [175, 177], [178, 180], [181, 189], [190, 192], [193, 205], [206, 219], [220, 223], [224, 228], [229, 231], [232, 239], [240, 241], [242, 246], [247, 254], [255, 258], [259, 264], [265, 267], [268, 275], [275, 276], [277, 284], [285, 286], [287, 291], [292, 302], [302, 303]]}
{"doc_key": "ai-dev-101", "ner": [[4, 7, "field"], [13, 13, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 13, 4, 7, "part-of", "", false, false], [17, 18, 4, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["En", "general", ",", "la", "ling\u00fc\u00edstica", "computacional", "cuenta", "con", "la", "participaci\u00f3n", "de", "ling\u00fcistas", ",", "inform\u00e1ticos", ",", "expertos", "en", "inteligencia", "artificial", ",", "matem\u00e1ticos", ",", "l\u00f3gicos", ",", "fil\u00f3sofos", ",", "cient\u00edficos", "cognitivos", ",", "psic\u00f3logos", "cognitivos", ",", "psicoling\u00fcistas", ",", "antrop\u00f3logos", "y", "neurocient\u00edficos", ",", "entre", "otros", "."], "sentence-detokenized": "En general, la ling\u00fc\u00edstica computacional cuenta con la participaci\u00f3n de ling\u00fcistas, inform\u00e1ticos, expertos en inteligencia artificial, matem\u00e1ticos, l\u00f3gicos, fil\u00f3sofos, cient\u00edficos cognitivos, psic\u00f3logos cognitivos, psicoling\u00fcistas, antrop\u00f3logos y neurocient\u00edficos, entre otros.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 14], [15, 26], [27, 40], [41, 47], [48, 51], [52, 54], [55, 68], [69, 71], [72, 82], [82, 83], [84, 96], [96, 97], [98, 106], [107, 109], [110, 122], [123, 133], [133, 134], [135, 146], [146, 147], [148, 155], [155, 156], [157, 166], [166, 167], [168, 179], [180, 190], [190, 191], [192, 202], [203, 213], [213, 214], [215, 230], [230, 231], [232, 244], [245, 246], [247, 263], [263, 264], [265, 270], [271, 276], [276, 277]]}
{"doc_key": "ai-dev-102", "ner": [[3, 6, "algorithm"], [9, 11, "algorithm"], [13, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["T\u00e9cnicas", "como", "las", "redes", "de", "Markov", "din\u00e1micas", ",", "las", "redes", "neuronales", "convolucionales", "y", "la", "memoria", "a", "corto", "plazo", "suelen", "emplearse", "para", "explotar", "las", "correlaciones", "entre", "fotogramas", "."], "sentence-detokenized": "T\u00e9cnicas como las redes de Markov din\u00e1micas, las redes neuronales convolucionales y la memoria a corto plazo suelen emplearse para explotar las correlaciones entre fotogramas.", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 23], [24, 26], [27, 33], [34, 43], [43, 44], [45, 48], [49, 54], [55, 65], [66, 81], [82, 83], [84, 86], [87, 94], [95, 96], [97, 102], [103, 108], [109, 115], [116, 125], [126, 130], [131, 139], [140, 143], [144, 157], [158, 163], [164, 174], [174, 175]]}
{"doc_key": "ai-dev-103", "ner": [[0, 0, "product"], [4, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Unimate", "fue", "el", "primer", "robot", "industrial", ","], "sentence-detokenized": "Unimate fue el primer robot industrial,", "token2charspan": [[0, 7], [8, 11], [12, 14], [15, 21], [22, 27], [28, 38], [38, 39]]}
{"doc_key": "ai-dev-104", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [11, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 11, 13, "win-defeat", "", false, false], [5, 6, 11, 13, "win-defeat", "", false, false], [8, 8, 11, 13, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Junto", "con", "Geoffrey", "Hinton", "y", "Yann", "LeCun", ",", "Bengio", "gan\u00f3", "el", "Premio", "Turing", "2018", "."], "sentence-detokenized": "Junto con Geoffrey Hinton y Yann LeCun, Bengio gan\u00f3 el Premio Turing 2018.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 25], [26, 27], [28, 32], [33, 38], [38, 39], [40, 46], [47, 51], [52, 54], [55, 61], [62, 68], [69, 73], [73, 74]]}
{"doc_key": "ai-dev-105", "ner": [[5, 7, "country"], [19, 22, "misc"], [30, 31, "organisation"], [34, 37, "person"], [39, 40, "person"], [49, 51, "misc"], [57, 58, "country"], [64, 64, "country"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[19, 22, 5, 7, "physical", "filmed_in", false, false], [34, 37, 30, 31, "role", "host", false, false], [39, 40, 30, 31, "role", "reporter", false, false], [49, 51, 5, 7, "physical", "filmed_in", false, false], [49, 51, 57, 58, "physical", "distributed_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Se", "rodaron", "otras", "series", "en", "el", "Reino", "Unido", "para", "sectores", "espec\u00edficos", "del", "mercado", "mundial", ",", "como", "dos", "series", "de", "Robot", "Wars", "Extreme", "Warriors", "con", "competidores", "de", "Estados", "Unidos", "para", "la", "cadena", "TNN", "(", "con", "Mick", "Foley", "como", "presentador", "y", "Rebecca", "Grant", "como", "reportera", "de", "boxes", ")", ",", "dos", "de", "Dutch", "Robot", "Wars", "para", "su", "distribuci\u00f3n", "en", "los", "Pa\u00edses", "Bajos", "y", "una", "\u00fanica", "serie", "para", "Alemania", "."], "sentence-detokenized": "Se rodaron otras series en el Reino Unido para sectores espec\u00edficos del mercado mundial, como dos series de Robot Wars Extreme Warriors con competidores de Estados Unidos para la cadena TNN (con Mick Foley como presentador y Rebecca Grant como reportera de boxes), dos de Dutch Robot Wars para su distribuci\u00f3n en los Pa\u00edses Bajos y una \u00fanica serie para Alemania.", "token2charspan": [[0, 2], [3, 10], [11, 16], [17, 23], [24, 26], [27, 29], [30, 35], [36, 41], [42, 46], [47, 55], [56, 67], [68, 71], [72, 79], [80, 87], [87, 88], [89, 93], [94, 97], [98, 104], [105, 107], [108, 113], [114, 118], [119, 126], [127, 135], [136, 139], [140, 152], [153, 155], [156, 163], [164, 170], [171, 175], [176, 178], [179, 185], [186, 189], [190, 191], [191, 194], [195, 199], [200, 205], [206, 210], [211, 222], [223, 224], [225, 232], [233, 238], [239, 243], [244, 253], [254, 256], [257, 262], [262, 263], [263, 264], [265, 268], [269, 271], [272, 277], [278, 283], [284, 288], [289, 293], [294, 296], [297, 309], [310, 312], [313, 316], [317, 323], [324, 329], [330, 331], [332, 335], [336, 341], [342, 347], [348, 352], [353, 361], [361, 362]]}
{"doc_key": "ai-dev-106", "ner": [[9, 9, "researcher"], [14, 14, "product"], [29, 32, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 14, 14, "role", "", false, false], [29, 32, 14, 14, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Durante", "muchos", "a\u00f1os", ",", "a", "partir", "de", "1986", ",", "Miller", "dirigi\u00f3", "el", "desarrollo", "de", "WordNet", ",", "una", "gran", "referencia", "electr\u00f3nica", "legible", "por", "ordenador", "que", "puede", "utilizarse", "en", "aplicaciones", "como", "los", "motores", "de", "b\u00fasqueda", "."], "sentence-detokenized": "Durante muchos a\u00f1os, a partir de 1986, Miller dirigi\u00f3 el desarrollo de WordNet, una gran referencia electr\u00f3nica legible por ordenador que puede utilizarse en aplicaciones como los motores de b\u00fasqueda.", "token2charspan": [[0, 7], [8, 14], [15, 19], [19, 20], [21, 22], [23, 29], [30, 32], [33, 37], [37, 38], [39, 45], [46, 53], [54, 56], [57, 67], [68, 70], [71, 78], [78, 79], [80, 83], [84, 88], [89, 99], [100, 111], [112, 119], [120, 123], [124, 133], [134, 137], [138, 143], [144, 154], [155, 157], [158, 170], [171, 175], [176, 179], [180, 187], [188, 190], [191, 199], [199, 200]]}
{"doc_key": "ai-dev-107", "ner": [[4, 6, "algorithm"], [9, 13, "algorithm"], [21, 22, "researcher"], [25, 29, "organisation"], [33, 36, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 21, 22, "origin", "", false, false], [4, 6, 33, 36, "win-defeat", "", false, false], [9, 13, 21, 22, "origin", "", false, false], [9, 13, 33, 36, "win-defeat", "", false, false], [21, 22, 25, 29, "physical", "", false, false], [21, 22, 25, 29, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Desde", "2009", ",", "las", "redes", "neuronales", "recurrentes", "y", "las", "redes", "neuronales", "profundas", "de", "avance", "desarrolladas", "en", "el", "grupo", "de", "investigaci\u00f3n", "de", "J\u00fcrgen", "Schmidhuber", "en", "el", "laboratorio", "suizo", "de", "IA", "IDSIA", "han", "ganado", "varios", "concursos", "internacionales", "de", "escritura", "..."], "sentence-detokenized": "Desde 2009, las redes neuronales recurrentes y las redes neuronales profundas de avance desarrolladas en el grupo de investigaci\u00f3n de J\u00fcrgen Schmidhuber en el laboratorio suizo de IA IDSIA han ganado varios concursos internacionales de escritura...", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 15], [16, 21], [22, 32], [33, 44], [45, 46], [47, 50], [51, 56], [57, 67], [68, 77], [78, 80], [81, 87], [88, 101], [102, 104], [105, 107], [108, 113], [114, 116], [117, 130], [131, 133], [134, 140], [141, 152], [153, 155], [156, 158], [159, 170], [171, 176], [177, 179], [180, 182], [183, 188], [189, 192], [193, 199], [200, 206], [207, 216], [217, 232], [233, 235], [236, 245], [245, 248]]}
{"doc_key": "ai-dev-108", "ner": [[5, 7, "programlang"], [12, 12, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["El", "software", "se", "implementa", "en", "C", "+", "+", "y", "se", "envuelve", "para", "Python", "."], "sentence-detokenized": "El software se implementa en C + + y se envuelve para Python.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 25], [26, 28], [29, 30], [31, 32], [33, 34], [35, 36], [37, 39], [40, 48], [49, 53], [54, 60], [60, 61]]}
{"doc_key": "ai-dev-109", "ner": [[6, 7, "country"], [12, 13, "misc"], [19, 20, "misc"], [32, 33, "misc"], [35, 35, "misc"], [38, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[19, 20, 6, 7, "temporal", "", false, false], [19, 20, 12, 13, "artifact", "", false, false], [19, 20, 38, 38, "physical", "", false, false], [35, 35, 32, 33, "named", "", false, false], [35, 35, 38, 38, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["En", "1857", ",", "a", "petici\u00f3n", "del", "shogunato", "Tokugawa", ",", "un", "grupo", "de", "ingenieros", "holandeses", "comenz\u00f3", "a", "trabajar", "en", "el", "Nagasaki", "Yotetsusho", ",", "una", "moderna", "fundici\u00f3n", "y", "astillero", "de", "estilo", "occidental", "cerca", "del", "asentamiento", "holand\u00e9s", "de", "Dejima", ",", "en", "Nagasaki", "."], "sentence-detokenized": "En 1857, a petici\u00f3n del shogunato Tokugawa, un grupo de ingenieros holandeses comenz\u00f3 a trabajar en el Nagasaki Yotetsusho, una moderna fundici\u00f3n y astillero de estilo occidental cerca del asentamiento holand\u00e9s de Dejima, en Nagasaki.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 19], [20, 23], [24, 33], [34, 42], [42, 43], [44, 46], [47, 52], [53, 55], [56, 66], [67, 77], [78, 85], [86, 87], [88, 96], [97, 99], [100, 102], [103, 111], [112, 122], [122, 123], [124, 127], [128, 135], [136, 145], [146, 147], [148, 157], [158, 160], [161, 167], [168, 178], [179, 184], [185, 188], [189, 201], [202, 210], [211, 213], [214, 220], [220, 221], [222, 224], [225, 233], [233, 234]]}
{"doc_key": "ai-dev-110", "ner": [[7, 11, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Hacemos", "lo", "m\u00e1s", "preciso", "posible", "midiendo", "el", "error", "cuadr\u00e1tico", "medio", "entre", "mathy", "/", "math", "y", "math", "\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", "/", "math", ":", "queremos", "que", "math", "(", "y", "-", "\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", ")", "^", "2", "/", "math", "sea", "m\u00ednimo", ",", "tanto", "para", "mathx", "_", "1", ",", "\\", "puntos", ",", "x", "_n", "/", "math", "como", "para", "puntos", "fuera", "de", "nuestra", "muestra", "."], "sentence-detokenized": "Hacemos lo m\u00e1s preciso posible midiendo el error cuadr\u00e1tico medio entre mathy / math y math\\ hat {f} (x; D) / math: queremos que math (y -\\ hat {f} (x; D)) ^ 2 / math sea m\u00ednimo, tanto para mathx _ 1,\\ puntos, x _n / math como para puntos fuera de nuestra muestra.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 22], [23, 30], [31, 39], [40, 42], [43, 48], [49, 59], [60, 65], [66, 71], [72, 77], [78, 79], [80, 84], [85, 86], [87, 91], [91, 92], [93, 96], [97, 98], [98, 99], [99, 100], [101, 102], [102, 103], [103, 104], [105, 106], [106, 107], [108, 109], [110, 114], [114, 115], [116, 124], [125, 128], [129, 133], [134, 135], [135, 136], [137, 138], [138, 139], [140, 143], [144, 145], [145, 146], [146, 147], [148, 149], [149, 150], [150, 151], [152, 153], [153, 154], [154, 155], [156, 157], [158, 159], [160, 161], [162, 166], [167, 170], [171, 177], [177, 178], [179, 184], [185, 189], [190, 195], [196, 197], [198, 199], [199, 200], [200, 201], [202, 208], [208, 209], [210, 211], [212, 214], [215, 216], [217, 221], [222, 226], [227, 231], [232, 238], [239, 244], [245, 247], [248, 255], [256, 263], [263, 264]]}
{"doc_key": "ai-dev-111", "ner": [[7, 7, "researcher"], [15, 18, "organisation"], [27, 32, "product"], [41, 42, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 15, 18, "role", "", false, false], [27, 32, 15, 18, "temporal", "", false, false], [27, 32, 41, 42, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Posteriormente", ",", "extendi\u00f3", "una", "invitaci\u00f3n", "para", "que", "Wydner", "asistiera", "a", "la", "reuni\u00f3n", "anual", "de", "la", "Asociaci\u00f3n", "Americana", "de", "Traductores", "ese", "octubre", "siguiente", ",", "en", "la", "que", "el", "sistema", "de", "traducci\u00f3n", "autom\u00e1tica", "de", "Weidner", "fue", "aclamado", "como", "un", "esperado", "avance", "en", "la", "traducci\u00f3n", "autom\u00e1tica", "."], "sentence-detokenized": "Posteriormente, extendi\u00f3 una invitaci\u00f3n para que Wydner asistiera a la reuni\u00f3n anual de la Asociaci\u00f3n Americana de Traductores ese octubre siguiente, en la que el sistema de traducci\u00f3n autom\u00e1tica de Weidner fue aclamado como un esperado avance en la traducci\u00f3n autom\u00e1tica.", "token2charspan": [[0, 14], [14, 15], [16, 24], [25, 28], [29, 39], [40, 44], [45, 48], [49, 55], [56, 65], [66, 67], [68, 70], [71, 78], [79, 84], [85, 87], [88, 90], [91, 101], [102, 111], [112, 114], [115, 126], [127, 130], [131, 138], [139, 148], [148, 149], [150, 152], [153, 155], [156, 159], [160, 162], [163, 170], [171, 173], [174, 184], [185, 195], [196, 198], [199, 206], [207, 210], [211, 219], [220, 224], [225, 227], [228, 236], [237, 243], [244, 246], [247, 249], [250, 260], [261, 271], [271, 272]]}
{"doc_key": "ai-dev-112", "ner": [[2, 14, "conference"], [11, 11, "conference"], [18, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 2, 14, "named", "", false, false], [11, 11, 2, 14, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["En", "la", "Conferencia", "sobre", "Sistemas", "de", "Procesamiento", "de", "Informaci\u00f3n", "Neuronal", "(", "NeurIPS", ")", "de", "2018", ",", "investigadores", "de", "Google", "presentaron", "el", "trabajo", "."], "sentence-detokenized": "En la Conferencia sobre Sistemas de Procesamiento de Informaci\u00f3n Neuronal (NeurIPS) de 2018, investigadores de Google presentaron el trabajo.", "token2charspan": [[0, 2], [3, 5], [6, 17], [18, 23], [24, 32], [33, 35], [36, 49], [50, 52], [53, 64], [65, 73], [74, 75], [75, 82], [82, 83], [84, 86], [87, 91], [91, 92], [93, 107], [108, 110], [111, 117], [118, 129], [130, 132], [133, 140], [140, 141]]}
{"doc_key": "ai-dev-113", "ner": [[1, 2, "algorithm"], [6, 7, "algorithm"], [11, 14, "metrics"], [20, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 2, 6, 7, "usage", "", false, false], [6, 7, 11, 14, "related-to", "", true, false], [11, 14, 20, 23, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["El", "algoritmo", "Baum-Welch", "utiliza", "el", "conocido", "algoritmo", "EM", "para", "encontrar", "la", "estimaci\u00f3n", "de", "m\u00e1xima", "verosimilitud", "de", "los", "par\u00e1metros", "de", "un", "modelo", "de", "Markov", "oculto", "dado", "un", "conjunto", "de", "vectores", "de", "caracter\u00edsticas", "observadas", "."], "sentence-detokenized": "El algoritmo Baum-Welch utiliza el conocido algoritmo EM para encontrar la estimaci\u00f3n de m\u00e1xima verosimilitud de los par\u00e1metros de un modelo de Markov oculto dado un conjunto de vectores de caracter\u00edsticas observadas.", "token2charspan": [[0, 2], [3, 12], [13, 23], [24, 31], [32, 34], [35, 43], [44, 53], [54, 56], [57, 61], [62, 71], [72, 74], [75, 85], [86, 88], [89, 95], [96, 109], [110, 112], [113, 116], [117, 127], [128, 130], [131, 133], [134, 140], [141, 143], [144, 150], [151, 157], [158, 162], [163, 165], [166, 174], [175, 177], [178, 186], [187, 189], [190, 205], [206, 216], [216, 217]]}
{"doc_key": "ai-dev-114", "ner": [[8, 8, "product"], [10, 10, "product"], [32, 34, "misc"], [39, 49, "product"], [55, 55, "programlang"], [52, 62, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 8, 10, 10, "compare", "", false, false], [32, 34, 10, 10, "part-of", "", false, false], [39, 49, 10, 10, "part-of", "", false, false], [52, 62, 10, 10, "part-of", "", false, false], [52, 62, 55, 55, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": [")", "Adem\u00e1s", "de", "la", "informaci\u00f3n", "taxon\u00f3mica", "contenida", "en", "OpenCyc", ",", "ResearchCyc", "incluye", "muchos", "m\u00e1s", "conocimientos", "sem\u00e1nticos", "(", "es", "decir", ",", "hechos", "y", "reglas", "generales", "adicionales", ")", "relacionados", "con", "los", "conceptos", "de", "su", "base", "de", "conocimientos", ";", "tambi\u00e9n", "incluye", "un", "amplio", "l\u00e9xico", ",", "herramientas", "de", "an\u00e1lisis", "sint\u00e1ctico", "y", "generaci\u00f3n", "de", "ingl\u00e9s", ",", "e", "interfaces", "basadas", "en", "Java", "para", "la", "edici\u00f3n", "y", "consulta", "de", "conocimientos", "."], "sentence-detokenized": ") Adem\u00e1s de la informaci\u00f3n taxon\u00f3mica contenida en OpenCyc, ResearchCyc incluye muchos m\u00e1s conocimientos sem\u00e1nticos (es decir, hechos y reglas generales adicionales) relacionados con los conceptos de su base de conocimientos; tambi\u00e9n incluye un amplio l\u00e9xico, herramientas de an\u00e1lisis sint\u00e1ctico y generaci\u00f3n de ingl\u00e9s, e interfaces basadas en Java para la edici\u00f3n y consulta de conocimientos.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 14], [15, 26], [27, 37], [38, 47], [48, 50], [51, 58], [58, 59], [60, 71], [72, 79], [80, 86], [87, 90], [91, 104], [105, 115], [116, 117], [117, 119], [120, 125], [125, 126], [127, 133], [134, 135], [136, 142], [143, 152], [153, 164], [164, 165], [166, 178], [179, 182], [183, 186], [187, 196], [197, 199], [200, 202], [203, 207], [208, 210], [211, 224], [224, 225], [226, 233], [234, 241], [242, 244], [245, 251], [252, 258], [258, 259], [260, 272], [273, 275], [276, 284], [285, 295], [296, 297], [298, 308], [309, 311], [312, 318], [318, 319], [320, 321], [322, 332], [333, 340], [341, 343], [344, 348], [349, 353], [354, 356], [357, 364], [365, 366], [367, 375], [376, 378], [379, 392], [392, 393]]}
{"doc_key": "ai-dev-115", "ner": [[0, 3, "algorithm"], [8, 10, "task"], [14, 16, "field"], [19, 21, "field"], [24, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 8, 10, "type-of", "", false, false], [8, 10, 14, 16, "part-of", "task_part_of_field", false, false], [8, 10, 19, 21, "part-of", "task_part_of_field", false, false], [8, 10, 24, 27, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["La", "transformada", "de", "Hough", "es", "una", "t\u00e9cnica", "de", "extracci\u00f3n", "de", "caracter\u00edsticas", "utilizada", "en", "el", "an\u00e1lisis", "de", "im\u00e1genes", ",", "la", "visi\u00f3n", "por", "ordenador", "y", "el", "procesamiento", "digital", "de", "im\u00e1genes", "."], "sentence-detokenized": "La transformada de Hough es una t\u00e9cnica de extracci\u00f3n de caracter\u00edsticas utilizada en el an\u00e1lisis de im\u00e1genes, la visi\u00f3n por ordenador y el procesamiento digital de im\u00e1genes.", "token2charspan": [[0, 2], [3, 15], [16, 18], [19, 24], [25, 27], [28, 31], [32, 39], [40, 42], [43, 53], [54, 56], [57, 72], [73, 82], [83, 85], [86, 88], [89, 97], [98, 100], [101, 109], [109, 110], [111, 113], [114, 120], [121, 124], [125, 134], [135, 136], [137, 139], [140, 153], [154, 161], [162, 164], [165, 173], [173, 174]]}
{"doc_key": "ai-dev-116", "ner": [[5, 5, "product"], [7, 11, "product"], [16, 16, "organisation"], [20, 20, "product"], [22, 23, "researcher"], [30, 31, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 5, 7, 11, "named", "", false, false], [5, 5, 16, 16, "artifact", "", false, false], [5, 5, 20, 20, "origin", "developed_from", false, false], [20, 20, 22, 23, "artifact", "", false, false], [30, 31, 16, 16, "role", "supported", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["En", "1978", ",", "el", "robot", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", "fue", "desarrollado", "por", "Unimation", "a", "partir", "de", "Vicarm", "(", "Victor", "Scheinman", ")", "y", "con", "el", "apoyo", "de", "General", "Motors", "."], "sentence-detokenized": "En 1978, el robot PUMA (Programmable Universal Machine for Assembly) fue desarrollado por Unimation a partir de Vicarm (Victor Scheinman) y con el apoyo de General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 17], [18, 22], [23, 24], [24, 36], [37, 46], [47, 54], [55, 58], [59, 67], [67, 68], [69, 72], [73, 85], [86, 89], [90, 99], [100, 101], [102, 108], [109, 111], [112, 118], [119, 120], [120, 126], [127, 136], [136, 137], [138, 139], [140, 143], [144, 146], [147, 152], [153, 155], [156, 163], [164, 170], [170, 171]]}
{"doc_key": "ai-dev-117", "ner": [[0, 0, "algorithm"], [6, 7, "researcher"], [9, 10, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 6, 7, "origin", "", false, false], [0, 0, 9, 10, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["LSTM", "fue", "propuesto", "en", "1997", "por", "Sepp", "Hochreiter", "y", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "LSTM fue propuesto en 1997 por Sepp Hochreiter y J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 8], [9, 18], [19, 21], [22, 26], [27, 30], [31, 35], [36, 46], [47, 48], [49, 55], [56, 67], [67, 68]]}
{"doc_key": "ai-dev-118", "ner": [[7, 9, "metrics"], [11, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Los", "cuatro", "resultados", "pueden", "formularse", "en", "una", "tabla", "de", "contingencia", "o", "matriz", "de", "confusi\u00f3n", "de", "2", "\u00d7", "2", ",", "como", "sigue", ":"], "sentence-detokenized": "Los cuatro resultados pueden formularse en una tabla de contingencia o matriz de confusi\u00f3n de 2 \u00d7 2, como sigue:", "token2charspan": [[0, 3], [4, 10], [11, 21], [22, 28], [29, 39], [40, 42], [43, 46], [47, 52], [53, 55], [56, 68], [69, 70], [71, 77], [78, 80], [81, 90], [91, 93], [94, 95], [96, 97], [98, 99], [99, 100], [101, 105], [106, 111], [111, 112]]}
{"doc_key": "ai-dev-119", "ner": [[9, 10, "conference"], [14, 15, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Tambi\u00e9n", "contribuy\u00f3", "en", "gran", "medida", "a", "la", "creaci\u00f3n", "de", "la", "ELRA", "y", "de", "la", "conferencia", "LREC", "."], "sentence-detokenized": "Tambi\u00e9n contribuy\u00f3 en gran medida a la creaci\u00f3n de la ELRA y de la conferencia LREC.", "token2charspan": [[0, 7], [8, 18], [19, 21], [22, 26], [27, 33], [34, 35], [36, 38], [39, 47], [48, 50], [51, 53], [54, 58], [59, 60], [61, 63], [64, 66], [67, 78], [79, 83], [83, 84]]}
{"doc_key": "ai-dev-120", "ner": [[17, 19, "misc"], [27, 28, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[27, 28, 17, 19, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Una", "de", "las", "aplicaciones", "m\u00e1s", "populares", "de", "los", "robots", "en", "serie", "en", "la", "industria", "actual", "es", "el", "robot", "de", "ensamblaje", "\"", "pick", "and", "place", "\"", ",", "llamado", "robot", "SCARA", ",", "que", "tiene", "cuatro", "grados", "de", "libertad", "."], "sentence-detokenized": "Una de las aplicaciones m\u00e1s populares de los robots en serie en la industria actual es el robot de ensamblaje \"pick and place\", llamado robot SCARA, que tiene cuatro grados de libertad.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 23], [24, 27], [28, 37], [38, 40], [41, 44], [45, 51], [52, 54], [55, 60], [61, 63], [64, 66], [67, 76], [77, 83], [84, 86], [87, 89], [90, 95], [96, 98], [99, 109], [110, 111], [111, 115], [116, 119], [120, 125], [125, 126], [126, 127], [128, 135], [136, 141], [142, 147], [147, 148], [149, 152], [153, 158], [159, 165], [166, 172], [173, 175], [176, 184], [184, 185]]}
{"doc_key": "ai-dev-121", "ner": [[13, 19, "conference"], [21, 21, "conference"], [25, 28, "conference"], [37, 37, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 21, 13, 19, "named", "", false, false], [37, 37, 25, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Fue", "uno", "de", "los", "miembros", "fundadores", "y", "ex", "presidente", "(", "2006-2008", ")", "del", "Special", "Interest", "Group", "on", "Web", "as", "Corpus", "(", "SIGWAC", ")", "de", "la", "Association", "for", "Computational", "Linguistics", "y", "tambi\u00e9n", "uno", "de", "los", "organizadores", "fundadores", "de", "SENSEVAL", "."], "sentence-detokenized": "Fue uno de los miembros fundadores y ex presidente (2006-2008) del Special Interest Group on Web as Corpus (SIGWAC) de la Association for Computational Linguistics y tambi\u00e9n uno de los organizadores fundadores de SENSEVAL.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 14], [15, 23], [24, 34], [35, 36], [37, 39], [40, 50], [51, 52], [52, 61], [61, 62], [63, 66], [67, 74], [75, 83], [84, 89], [90, 92], [93, 96], [97, 99], [100, 106], [107, 108], [108, 114], [114, 115], [116, 118], [119, 121], [122, 133], [134, 137], [138, 151], [152, 163], [164, 165], [166, 173], [174, 177], [178, 180], [181, 184], [185, 198], [199, 209], [210, 212], [213, 221], [221, 222]]}
{"doc_key": "ai-dev-122", "ner": [[3, 3, "product"], [7, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 3, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Como", "plataforma", ",", "LinguaStream", "proporciona", "una", "amplia", "API", "Java", "."], "sentence-detokenized": "Como plataforma, LinguaStream proporciona una amplia API Java.", "token2charspan": [[0, 4], [5, 15], [15, 16], [17, 29], [30, 41], [42, 45], [46, 52], [53, 56], [57, 61], [61, 62]]}
{"doc_key": "ai-dev-123", "ner": [[12, 12, "programlang"], [15, 19, "misc"], [22, 26, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 12, 22, 26, "type-of", "", false, false], [15, 19, 22, 26, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["El", "kit", "del", "robot", "est\u00e1", "basado", "en", "Android", "y", "se", "programa", "mediante", "Java", ",", "la", "interfaz", "de", "programaci\u00f3n", "de", "bloques", "u", "otros", "sistemas", "de", "programaci\u00f3n", "de", "Android", "."], "sentence-detokenized": "El kit del robot est\u00e1 basado en Android y se programa mediante Java, la interfaz de programaci\u00f3n de bloques u otros sistemas de programaci\u00f3n de Android.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 16], [17, 21], [22, 28], [29, 31], [32, 39], [40, 41], [42, 44], [45, 53], [54, 62], [63, 67], [67, 68], [69, 71], [72, 80], [81, 83], [84, 96], [97, 99], [100, 107], [108, 109], [110, 115], [116, 124], [125, 127], [128, 140], [141, 143], [144, 151], [151, 152]]}
{"doc_key": "ai-dev-124", "ner": [[13, 15, "algorithm"], [17, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["El", "m\u00e9todo", "de", "definici\u00f3n", "de", "la", "lista", "enlazada", "especifica", "el", "uso", "de", "una", "b\u00fasqueda", "en", "profundidad", "o", "en", "amplitud", "."], "sentence-detokenized": "El m\u00e9todo de definici\u00f3n de la lista enlazada especifica el uso de una b\u00fasqueda en profundidad o en amplitud.", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 23], [24, 26], [27, 29], [30, 35], [36, 44], [45, 55], [56, 58], [59, 62], [63, 65], [66, 69], [70, 78], [79, 81], [82, 93], [94, 95], [96, 98], [99, 107], [107, 108]]}
{"doc_key": "ai-dev-125", "ner": [[21, 23, "task"], [26, 30, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Estas", "regiones", "podr\u00edan", "se\u00f1alar", "la", "presencia", "de", "objetos", "o", "partes", "de", "objetos", "en", "el", "dominio", "de", "la", "imagen", "con", "aplicaci\u00f3n", "al", "reconocimiento", "de", "objetos", "y/o", "al", "seguimiento", "de", "objetos", "por", "v\u00eddeo", "."], "sentence-detokenized": "Estas regiones podr\u00edan se\u00f1alar la presencia de objetos o partes de objetos en el dominio de la imagen con aplicaci\u00f3n al reconocimiento de objetos y/o al seguimiento de objetos por v\u00eddeo.", "token2charspan": [[0, 5], [6, 14], [15, 22], [23, 30], [31, 33], [34, 43], [44, 46], [47, 54], [55, 56], [57, 63], [64, 66], [67, 74], [75, 77], [78, 80], [81, 88], [89, 91], [92, 94], [95, 101], [102, 105], [106, 116], [117, 119], [120, 134], [135, 137], [138, 145], [146, 149], [150, 152], [153, 164], [165, 167], [168, 175], [176, 179], [180, 185], [185, 186]]}
{"doc_key": "ai-dev-126", "ner": [[3, 4, "algorithm"], [6, 6, "product"], [14, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 3, 4, "type-of", "", false, false], [6, 6, 14, 14, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Un", "ejemplo", "de", "red", "sem\u00e1ntica", "es", "WordNet", ",", "una", "base", "de", "datos", "l\u00e9xica", "del", "ingl\u00e9s", "."], "sentence-detokenized": "Un ejemplo de red sem\u00e1ntica es WordNet, una base de datos l\u00e9xica del ingl\u00e9s.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 17], [18, 27], [28, 30], [31, 38], [38, 39], [40, 43], [44, 48], [49, 51], [52, 57], [58, 64], [65, 68], [69, 75], [75, 76]]}
{"doc_key": "ai-dev-127", "ner": [[0, 3, "task"], [10, 10, "field"], [13, 14, "field"], [23, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 10, 10, "part-of", "", false, false], [0, 3, 13, 14, "named", "same", false, false], [0, 3, 13, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["El", "reconocimiento", "del", "habla", "es", "un", "subcampo", "interdisciplinar", "de", "la", "inform\u00e1tica", "y", "la", "ling\u00fc\u00edstica", "computacional", "que", "desarrolla", "metodolog\u00edas", "y", "tecnolog\u00edas", "que", "permiten", "el", "reconocimiento", "y", "la", "traducci\u00f3n", "del", "lenguaje", "hablado", "a", "texto", "por", "parte", "de", "los", "ordenadores", "."], "sentence-detokenized": "El reconocimiento del habla es un subcampo interdisciplinar de la inform\u00e1tica y la ling\u00fc\u00edstica computacional que desarrolla metodolog\u00edas y tecnolog\u00edas que permiten el reconocimiento y la traducci\u00f3n del lenguaje hablado a texto por parte de los ordenadores.", "token2charspan": [[0, 2], [3, 17], [18, 21], [22, 27], [28, 30], [31, 33], [34, 42], [43, 59], [60, 62], [63, 65], [66, 77], [78, 79], [80, 82], [83, 94], [95, 108], [109, 112], [113, 123], [124, 136], [137, 138], [139, 150], [151, 154], [155, 163], [164, 166], [167, 181], [182, 183], [184, 186], [187, 197], [198, 201], [202, 210], [211, 218], [219, 220], [221, 226], [227, 230], [231, 236], [237, 239], [240, 243], [244, 255], [255, 256]]}
{"doc_key": "ai-dev-128", "ner": [[0, 3, "field"], [15, 17, "misc"], [22, 25, "field"], [32, 32, "task"], [29, 35, "task"], [60, 61, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 3, 60, 61, "named", "same", false, false], [22, 25, 0, 3, "part-of", "subfield", false, false], [32, 32, 0, 3, "part-of", "", false, false], [32, 32, 22, 25, "part-of", "", false, false], [29, 35, 22, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["La", "inteligencia", "artificial", "es", "la", "que", "m\u00e1s", "atenci\u00f3n", "ha", "recibido", "en", "lo", "que", "respecta", "a", "la", "ontolog\u00eda", "aplicada", "en", "subcampos", "como", "el", "procesamiento", "del", "lenguaje", "natural", "dentro", "de", "la", "representaci\u00f3n", "de", "la", "m\u00e1quina", "y", "el", "conocimiento", ",", "pero", "los", "editores", "de", "ontolog\u00eda", "se", "utilizan", "a", "menudo", "en", "una", "serie", "de", "campos", "como", "la", "educaci\u00f3n", "sin", "la", "intenci\u00f3n", "de", "contribuir", "a", "la", "IA", "."], "sentence-detokenized": "La inteligencia artificial es la que m\u00e1s atenci\u00f3n ha recibido en lo que respecta a la ontolog\u00eda aplicada en subcampos como el procesamiento del lenguaje natural dentro de la representaci\u00f3n de la m\u00e1quina y el conocimiento, pero los editores de ontolog\u00eda se utilizan a menudo en una serie de campos como la educaci\u00f3n sin la intenci\u00f3n de contribuir a la IA.", "token2charspan": [[0, 2], [3, 15], [16, 26], [27, 29], [30, 32], [33, 36], [37, 40], [41, 49], [50, 52], [53, 61], [62, 64], [65, 67], [68, 71], [72, 80], [81, 82], [83, 85], [86, 95], [96, 104], [105, 107], [108, 117], [118, 122], [123, 125], [126, 139], [140, 143], [144, 152], [153, 160], [161, 167], [168, 170], [171, 173], [174, 188], [189, 191], [192, 194], [195, 202], [203, 204], [205, 207], [208, 220], [220, 221], [222, 226], [227, 230], [231, 239], [240, 242], [243, 252], [253, 255], [256, 264], [265, 266], [267, 273], [274, 276], [277, 280], [281, 286], [287, 289], [290, 296], [297, 301], [302, 304], [305, 314], [315, 318], [319, 321], [322, 331], [332, 334], [335, 345], [346, 347], [348, 350], [351, 353], [353, 354]]}
{"doc_key": "ai-dev-129", "ner": [[12, 15, "algorithm"], [18, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 15, 18, 19, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Esta", "regla", "de", "actualizaci\u00f3n", "es", ",", "de", "hecho", ",", "la", "actualizaci\u00f3n", "del", "descenso", "de", "gradiente", "estoc\u00e1stico", "para", "la", "regresi\u00f3n", "lineal", "."], "sentence-detokenized": "Esta regla de actualizaci\u00f3n es, de hecho, la actualizaci\u00f3n del descenso de gradiente estoc\u00e1stico para la regresi\u00f3n lineal.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 27], [28, 30], [30, 31], [32, 34], [35, 40], [40, 41], [42, 44], [45, 58], [59, 62], [63, 71], [72, 74], [75, 84], [85, 96], [97, 101], [102, 104], [105, 114], [115, 121], [121, 122]]}
{"doc_key": "ai-dev-130", "ner": [[5, 12, "organisation"], [16, 20, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Fue", "elegido", "miembro", "de", "la", "Academia", "Americana", "de", "las", "Artes", "y", "las", "Ciencias", "y", "de", "la", "Academia", "Nacional", "de", "las", "Ciencias", "y", "ha", "recibido", "una", "serie", "de", "premios", ":"], "sentence-detokenized": "Fue elegido miembro de la Academia Americana de las Artes y las Ciencias y de la Academia Nacional de las Ciencias y ha recibido una serie de premios:", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 22], [23, 25], [26, 34], [35, 44], [45, 47], [48, 51], [52, 57], [58, 59], [60, 63], [64, 72], [73, 74], [75, 77], [78, 80], [81, 89], [90, 98], [99, 101], [102, 105], [106, 114], [115, 116], [117, 119], [120, 128], [129, 132], [133, 138], [139, 141], [142, 149], [149, 150]]}
{"doc_key": "ai-dev-131", "ner": [[10, 10, "organisation"], [14, 15, "person"], [17, 19, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 14, 15, "related-to", "written_about_by", false, false], [10, 10, 17, 19, "related-to", "written_about_by", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "escuela", "de", "pensamiento", "m\u00e1s", "reciente", "sobre", "la", "estrategia", "de", "Honda", "fue", "planteada", "por", "Gary", "Hamel", "y", "C.", "K.", "Prahalad", "en", "1989", "."], "sentence-detokenized": "La escuela de pensamiento m\u00e1s reciente sobre la estrategia de Honda fue planteada por Gary Hamel y C. K. Prahalad en 1989.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 25], [26, 29], [30, 38], [39, 44], [45, 47], [48, 58], [59, 61], [62, 67], [68, 71], [72, 81], [82, 85], [86, 90], [91, 96], [97, 98], [99, 101], [102, 104], [105, 113], [114, 116], [117, 121], [121, 122]]}
{"doc_key": "ai-dev-132", "ner": [[2, 2, "metrics"], [7, 9, "metrics"], [22, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 7, 9, "related-to", "calculates", true, false], [2, 2, 22, 23, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Mientras", "que", "BLEU", "se", "limita", "a", "calcular", "la", "precisi\u00f3n", "de", "los", "ngranos", "a\u00f1adiendo", "el", "mismo", "peso", "a", "cada", "uno", "de", "ellos", ",", "el", "NIST", "tambi\u00e9n", "calcula", "el", "grado", "de", "informaci\u00f3n", "de", "un", "ngrano", "concreto", "."], "sentence-detokenized": "Mientras que BLEU se limita a calcular la precisi\u00f3n de los ngranos a\u00f1adiendo el mismo peso a cada uno de ellos, el NIST tambi\u00e9n calcula el grado de informaci\u00f3n de un ngrano concreto.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 20], [21, 27], [28, 29], [30, 38], [39, 41], [42, 51], [52, 54], [55, 58], [59, 66], [67, 76], [77, 79], [80, 85], [86, 90], [91, 92], [93, 97], [98, 101], [102, 104], [105, 110], [110, 111], [112, 114], [115, 119], [120, 127], [128, 135], [136, 138], [139, 144], [145, 147], [148, 159], [160, 162], [163, 165], [166, 172], [173, 181], [181, 182]]}
{"doc_key": "ai-dev-133", "ner": [[5, 8, "misc"], [11, 14, "conference"], [16, 16, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 8, 11, 14, "temporal", "", false, false], [16, 16, 11, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Ha", "sido", "galardonado", "con", "el", "Lifetime", "Achievement", "Award", "2019", "de", "la", "Association", "for", "Computational", "Linguistics", "(", "ACL", ")", "."], "sentence-detokenized": "Ha sido galardonado con el Lifetime Achievement Award 2019 de la Association for Computational Linguistics (ACL).", "token2charspan": [[0, 2], [3, 7], [8, 19], [20, 23], [24, 26], [27, 35], [36, 47], [48, 53], [54, 58], [59, 61], [62, 64], [65, 76], [77, 80], [81, 94], [95, 106], [107, 108], [108, 111], [111, 112], [112, 113]]}
{"doc_key": "ai-dev-134", "ner": [[0, 1, "researcher"], [4, 9, "organisation"], [11, 11, "organisation"], [16, 20, "conference"], [22, 22, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 4, 9, "role", "", false, false], [0, 1, 16, 20, "role", "", false, false], [11, 11, 4, 9, "named", "", false, false], [22, 22, 16, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sycara", "es", "miembro", "del", "Instituto", "de", "Ingenieros", "El\u00e9ctricos", "y", "Electr\u00f3nicos", "(", "IEEE", ")", "y", "de", "la", "Asociaci\u00f3n", "Americana", "de", "Inteligencia", "Artificial", "(", "AAAI", ")", "."], "sentence-detokenized": "Sycara es miembro del Instituto de Ingenieros El\u00e9ctricos y Electr\u00f3nicos (IEEE) y de la Asociaci\u00f3n Americana de Inteligencia Artificial (AAAI).", "token2charspan": [[0, 6], [7, 9], [10, 17], [18, 21], [22, 31], [32, 34], [35, 45], [46, 56], [57, 58], [59, 71], [72, 73], [73, 77], [77, 78], [79, 80], [81, 83], [84, 86], [87, 97], [98, 107], [108, 110], [111, 123], [124, 134], [135, 136], [136, 140], [140, 141], [141, 142]]}
{"doc_key": "ai-dev-135", "ner": [[3, 4, "product"], [12, 16, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 12, 16, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["El", "siguiente", "c\u00f3digo", "de", "MATLAB", "muestra", "una", "soluci\u00f3n", "concreta", "para", "resolver", "el", "sistema", "de", "ecuaciones", "no", "lineales", "presentado", "en", "la", "secci\u00f3n", "anterior", ":", "V\u00e9ase", "tambi\u00e9n"], "sentence-detokenized": "El siguiente c\u00f3digo de MATLAB muestra una soluci\u00f3n concreta para resolver el sistema de ecuaciones no lineales presentado en la secci\u00f3n anterior: V\u00e9ase tambi\u00e9n", "token2charspan": [[0, 2], [3, 12], [13, 19], [20, 22], [23, 29], [30, 37], [38, 41], [42, 50], [51, 59], [60, 64], [65, 73], [74, 76], [77, 84], [85, 87], [88, 98], [99, 101], [102, 110], [111, 121], [122, 124], [125, 127], [128, 135], [136, 144], [144, 145], [146, 151], [152, 159]]}
{"doc_key": "ai-dev-136", "ner": [[4, 9, "product"], [21, 21, "field"], [43, 45, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 9, 21, 21, "related-to", "trained_by", true, false], [4, 9, 43, 45, "related-to", "trained_by", true, false], [21, 21, 43, 45, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["En", "muchos", "casos", ",", "los", "sistemas", "de", "reconocimiento", "de", "patrones", "se", "entrenan", "a", "partir", "de", "datos", "de", "entrenamiento", "etiquetados", "(", "aprendizaje", "supervisado", ")", ",", "pero", "cuando", "no", "se", "dispone", "de", "datos", "etiquetados", "se", "pueden", "utilizar", "otros", "algoritmos", "para", "descubrir", "patrones", "previamente", "desconocidos", "(", "aprendizaje", "no", "supervisado", ")", "."], "sentence-detokenized": "En muchos casos, los sistemas de reconocimiento de patrones se entrenan a partir de datos de entrenamiento etiquetados (aprendizaje supervisado), pero cuando no se dispone de datos etiquetados se pueden utilizar otros algoritmos para descubrir patrones previamente desconocidos (aprendizaje no supervisado).", "token2charspan": [[0, 2], [3, 9], [10, 15], [15, 16], [17, 20], [21, 29], [30, 32], [33, 47], [48, 50], [51, 59], [60, 62], [63, 71], [72, 73], [74, 80], [81, 83], [84, 89], [90, 92], [93, 106], [107, 118], [119, 120], [120, 131], [132, 143], [143, 144], [144, 145], [146, 150], [151, 157], [158, 160], [161, 163], [164, 171], [172, 174], [175, 180], [181, 192], [193, 195], [196, 202], [203, 211], [212, 217], [218, 228], [229, 233], [234, 243], [244, 252], [253, 264], [265, 277], [278, 279], [279, 290], [291, 293], [294, 305], [305, 306], [306, 307]]}
{"doc_key": "ai-dev-137", "ner": [[6, 8, "researcher"], [10, 11, "country"], [28, 29, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 8, 10, 11, "physical", "", false, false], [6, 8, 28, 29, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Fue", "utilizado", "por", "primera", "vez", "por", "Lawrence", "J.", "Fogel", "en", "Estados", "Unidos", "en", "1960", "para", "utilizar", "la", "evoluci\u00f3n", "simulada", "como", "proceso", "de", "aprendizaje", "con", "el", "fin", "de", "generar", "inteligencia", "artificial", "."], "sentence-detokenized": "Fue utilizado por primera vez por Lawrence J. Fogel en Estados Unidos en 1960 para utilizar la evoluci\u00f3n simulada como proceso de aprendizaje con el fin de generar inteligencia artificial.", "token2charspan": [[0, 3], [4, 13], [14, 17], [18, 25], [26, 29], [30, 33], [34, 42], [43, 45], [46, 51], [52, 54], [55, 62], [63, 69], [70, 72], [73, 77], [78, 82], [83, 91], [92, 94], [95, 104], [105, 113], [114, 118], [119, 126], [127, 129], [130, 141], [142, 145], [146, 148], [149, 152], [153, 155], [156, 163], [164, 176], [177, 187], [187, 188]]}
{"doc_key": "ai-dev-138", "ner": [[0, 3, "field"], [11, 13, "field"], [17, 19, "field"], [22, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 11, 13, "part-of", "", false, false], [17, 19, 11, 13, "part-of", "", false, false], [22, 24, 11, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["El", "aprendizaje", "por", "refuerzo", "es", "uno", "de", "los", "tres", "paradigmas", "b\u00e1sicos", "del", "aprendizaje", "autom\u00e1tico", ",", "junto", "con", "el", "aprendizaje", "supervisado", "y", "el", "aprendizaje", "no", "supervisado", "."], "sentence-detokenized": "El aprendizaje por refuerzo es uno de los tres paradigmas b\u00e1sicos del aprendizaje autom\u00e1tico, junto con el aprendizaje supervisado y el aprendizaje no supervisado.", "token2charspan": [[0, 2], [3, 14], [15, 18], [19, 27], [28, 30], [31, 34], [35, 37], [38, 41], [42, 46], [47, 57], [58, 65], [66, 69], [70, 81], [82, 92], [92, 93], [94, 99], [100, 103], [104, 106], [107, 118], [119, 130], [131, 132], [133, 135], [136, 147], [148, 150], [151, 162], [162, 163]]}
{"doc_key": "ai-dev-139", "ner": [[5, 8, "field"], [17, 17, "programlang"], [40, 42, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 8, 40, 42, "usage", "applies", false, false], [17, 17, 40, 42, "usage", "applies", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["En", "estos", "casos", ",", "la", "computaci\u00f3n", "en", "la", "nube", "y", "el", "lenguaje", "de", "programaci\u00f3n", "de", "c\u00f3digo", "abierto", "R", "pueden", "ayudar", "a", "los", "bancos", "m\u00e1s", "peque\u00f1os", "a", "adoptar", "la", "anal\u00edtica", "de", "riesgos", "y", "apoyar", "la", "supervisi\u00f3n", "a", "nivel", "de", "sucursal", "aplicando", "la", "anal\u00edtica", "predictiva", "."], "sentence-detokenized": "En estos casos, la computaci\u00f3n en la nube y el lenguaje de programaci\u00f3n de c\u00f3digo abierto R pueden ayudar a los bancos m\u00e1s peque\u00f1os a adoptar la anal\u00edtica de riesgos y apoyar la supervisi\u00f3n a nivel de sucursal aplicando la anal\u00edtica predictiva.", "token2charspan": [[0, 2], [3, 8], [9, 14], [14, 15], [16, 18], [19, 30], [31, 33], [34, 36], [37, 41], [42, 43], [44, 46], [47, 55], [56, 58], [59, 71], [72, 74], [75, 81], [82, 89], [90, 91], [92, 98], [99, 105], [106, 107], [108, 111], [112, 118], [119, 122], [123, 131], [132, 133], [134, 141], [142, 144], [145, 154], [155, 157], [158, 165], [166, 167], [168, 174], [175, 177], [178, 189], [190, 191], [192, 197], [198, 200], [201, 209], [210, 219], [220, 222], [223, 232], [233, 243], [243, 244]]}
{"doc_key": "ai-dev-140", "ner": [[10, 11, "researcher"], [19, 20, "algorithm"], [22, 23, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 22, 23, "named", "same", false, false], [19, 20, 10, 11, "origin", "proves_function", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Una", "de", "las", "primeras", "versiones", "del", "teorema", "fue", "demostrada", "por", "George", "Cybenko", "en", "1989", "para", "funciones", "de", "activaci\u00f3n", "de", "tipo", "sigmoide", ".", "Cybenko", "G.", "(", "1989", ")", ",", "2", "(", "4", ")", ",", "303-314", "."], "sentence-detokenized": "Una de las primeras versiones del teorema fue demostrada por George Cybenko en 1989 para funciones de activaci\u00f3n de tipo sigmoide. Cybenko G. (1989), 2 (4), 303-314.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 19], [20, 29], [30, 33], [34, 41], [42, 45], [46, 56], [57, 60], [61, 67], [68, 75], [76, 78], [79, 83], [84, 88], [89, 98], [99, 101], [102, 112], [113, 115], [116, 120], [121, 129], [129, 130], [131, 138], [139, 141], [142, 143], [143, 147], [147, 148], [148, 149], [150, 151], [152, 153], [153, 154], [154, 155], [155, 156], [157, 164], [164, 165]]}
{"doc_key": "ai-dev-141", "ner": [[8, 9, "algorithm"], [12, 12, "metrics"], [15, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 12, 8, 9, "part-of", "", false, false], [15, 20, 12, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["En", "este", "proceso", ",", "que", "se", "conoce", "como", "validaci\u00f3n", "cruzada", ",", "el", "MSE", "suele", "denominarse", "error", "medio", "de", "predicci\u00f3n", "al", "cuadrado", ",", "y", "se", "calcula", "como"], "sentence-detokenized": "En este proceso, que se conoce como validaci\u00f3n cruzada, el MSE suele denominarse error medio de predicci\u00f3n al cuadrado, y se calcula como", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 20], [21, 23], [24, 30], [31, 35], [36, 46], [47, 54], [54, 55], [56, 58], [59, 62], [63, 68], [69, 80], [81, 86], [87, 92], [93, 95], [96, 106], [107, 109], [110, 118], [118, 119], [120, 121], [122, 124], [125, 132], [133, 137]]}
{"doc_key": "ai-dev-142", "ner": [[0, 1, "task"], [6, 9, "task"], [11, 14, "task"], [25, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 6, 9, "compare", "", false, false], [6, 9, 25, 27, "part-of", "", false, false], [11, 14, 6, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["El", "OMR", "se", "distingue", "generalmente", "del", "reconocimiento", "\u00f3ptico", "de", "caracteres", "(", "OCR", ")", "por", "el", "hecho", "de", "que", "no", "se", "requiere", "un", "complicado", "motor", "de", "reconocimiento", "de", "patrones", "."], "sentence-detokenized": "El OMR se distingue generalmente del reconocimiento \u00f3ptico de caracteres (OCR) por el hecho de que no se requiere un complicado motor de reconocimiento de patrones.", "token2charspan": [[0, 2], [3, 6], [7, 9], [10, 19], [20, 32], [33, 36], [37, 51], [52, 58], [59, 61], [62, 72], [73, 74], [74, 77], [77, 78], [79, 82], [83, 85], [86, 91], [92, 94], [95, 98], [99, 101], [102, 104], [105, 113], [114, 116], [117, 127], [128, 133], [134, 136], [137, 151], [152, 154], [155, 163], [163, 164]]}
{"doc_key": "ai-dev-143", "ner": [[10, 10, "location"], [12, 12, "location"], [14, 14, "location"], [18, 19, "location"], [22, 23, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 12, 14, 14, "physical", "", false, false], [18, 19, 12, 12, "physical", "", false, false], [22, 23, 12, 12, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["En", "2018", "y", "2019", ",", "el", "Campeonato", "se", "celebr\u00f3", "en", "Houston", "y", "Detroit", ",", "Michigan", ",", "en", "el", "TCF", "Center", "y", "el", "Ford", "Field", "."], "sentence-detokenized": "En 2018 y 2019, el Campeonato se celebr\u00f3 en Houston y Detroit, Michigan, en el TCF Center y el Ford Field.", "token2charspan": [[0, 2], [3, 7], [8, 9], [10, 14], [14, 15], [16, 18], [19, 29], [30, 32], [33, 40], [41, 43], [44, 51], [52, 53], [54, 61], [61, 62], [63, 71], [71, 72], [73, 75], [76, 78], [79, 82], [83, 89], [90, 91], [92, 94], [95, 99], [100, 105], [105, 106]]}
{"doc_key": "ai-dev-144", "ner": [[0, 1, "task"], [10, 11, "task"], [14, 15, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 0, 1, "part-of", "", false, false], [14, 15, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "clasificaci\u00f3n", "puede", "considerarse", "como", "dos", "problemas", "distintos", ":", "la", "clasificaci\u00f3n", "binaria", "y", "la", "clasificaci\u00f3n", "multiclase", "."], "sentence-detokenized": "La clasificaci\u00f3n puede considerarse como dos problemas distintos: la clasificaci\u00f3n binaria y la clasificaci\u00f3n multiclase.", "token2charspan": [[0, 2], [3, 16], [17, 22], [23, 35], [36, 40], [41, 44], [45, 54], [55, 64], [64, 65], [66, 68], [69, 82], [83, 90], [91, 92], [93, 95], [96, 109], [110, 120], [120, 121]]}
{"doc_key": "ai-dev-145", "ner": [[3, 4, "product"], [8, 9, "product"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 3, 4, "type-of", "", false, false], [12, 13, 3, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Dos", "ejemplos", "de", "robots", "paralelos", "populares", "son", "la", "plataforma", "Stewart", "y", "el", "robot", "Delta", "."], "sentence-detokenized": "Dos ejemplos de robots paralelos populares son la plataforma Stewart y el robot Delta.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 22], [23, 32], [33, 42], [43, 46], [47, 49], [50, 60], [61, 68], [69, 70], [71, 73], [74, 79], [80, 85], [85, 86]]}
{"doc_key": "ai-dev-146", "ner": [[5, 8, "algorithm"], [25, 25, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 8, 25, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "No", "obstante", ",", "la", "funci\u00f3n", "de", "activaci\u00f3n", "ReLU", ",", "que", "es", "indiferenciable", "en", "0", ",", "se", "ha", "hecho", "bastante", "popular", ",", "por", "ejemplo", "en", "AlexNet", ")"], "sentence-detokenized": "(No obstante, la funci\u00f3n de activaci\u00f3n ReLU, que es indiferenciable en 0, se ha hecho bastante popular, por ejemplo en AlexNet)", "token2charspan": [[0, 1], [1, 3], [4, 12], [12, 13], [14, 16], [17, 24], [25, 27], [28, 38], [39, 43], [43, 44], [45, 48], [49, 51], [52, 67], [68, 70], [71, 72], [72, 73], [74, 76], [77, 79], [80, 85], [86, 94], [95, 102], [102, 103], [104, 107], [108, 115], [116, 118], [119, 126], [126, 127]]}
{"doc_key": "ai-dev-147", "ner": [[0, 2, "metrics"], [12, 14, "task"], [21, 21, "task"], [24, 26, "task"], [29, 31, "task"], [36, 36, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 36, 36, "named", "", true, false], [12, 14, 0, 2, "usage", "", true, false], [21, 21, 12, 14, "part-of", "", false, false], [24, 26, 12, 14, "part-of", "", false, false], [29, 31, 12, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["La", "puntuaci\u00f3n", "F", "se", "utiliza", "a", "menudo", "en", "el", "campo", "de", "la", "recuperaci\u00f3n", "de", "informaci\u00f3n", "para", "medir", "el", "rendimiento", "de", "la", "b\u00fasqueda", ",", "la", "clasificaci\u00f3n", "de", "documentos", "y", "la", "clasificaci\u00f3n", "de", "consultas", ",", "por", "lo", "que", "F_beta", "tiene", "una", "amplia", "aplicaci\u00f3n", "."], "sentence-detokenized": "La puntuaci\u00f3n F se utiliza a menudo en el campo de la recuperaci\u00f3n de informaci\u00f3n para medir el rendimiento de la b\u00fasqueda, la clasificaci\u00f3n de documentos y la clasificaci\u00f3n de consultas, por lo que F_beta tiene una amplia aplicaci\u00f3n.", "token2charspan": [[0, 2], [3, 13], [14, 15], [16, 18], [19, 26], [27, 28], [29, 35], [36, 38], [39, 41], [42, 47], [48, 50], [51, 53], [54, 66], [67, 69], [70, 81], [82, 86], [87, 92], [93, 95], [96, 107], [108, 110], [111, 113], [114, 122], [122, 123], [124, 126], [127, 140], [141, 143], [144, 154], [155, 156], [157, 159], [160, 173], [174, 176], [177, 186], [186, 187], [188, 191], [192, 194], [195, 198], [199, 205], [206, 211], [212, 215], [216, 222], [223, 233], [233, 234]]}
{"doc_key": "ai-dev-148", "ner": [[22, 23, "algorithm"], [25, 25, "algorithm"], [29, 31, "algorithm"], [33, 33, "algorithm"], [37, 39, "algorithm"], [41, 41, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[25, 25, 22, 23, "named", "", false, false], [33, 33, 29, 31, "named", "", false, false], [41, 41, 37, 39, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Para", "ello", ",", "se", "modela", "la", "se\u00f1al", "recibida", "y", ",", "a", "continuaci\u00f3n", ",", "se", "utiliza", "un", "m\u00e9todo", "de", "estimaci\u00f3n", "estad\u00edstica", "como", "la", "m\u00e1xima", "verosimilitud", "(", "ML", ")", ",", "la", "votaci\u00f3n", "por", "mayor\u00eda", "(", "MV", ")", "o", "la", "m\u00e1xima", "a", "posteriori", "(", "MAP", ")", "para", "tomar", "una", "decisi\u00f3n", "sobre", "qu\u00e9", "objetivo", "de", "la", "biblioteca", "se", "ajusta", "mejor", "al", "modelo", "construido", "con", "la", "se\u00f1al", "recibida", "."], "sentence-detokenized": "Para ello, se modela la se\u00f1al recibida y, a continuaci\u00f3n, se utiliza un m\u00e9todo de estimaci\u00f3n estad\u00edstica como la m\u00e1xima verosimilitud (ML), la votaci\u00f3n por mayor\u00eda (MV) o la m\u00e1xima a posteriori (MAP) para tomar una decisi\u00f3n sobre qu\u00e9 objetivo de la biblioteca se ajusta mejor al modelo construido con la se\u00f1al recibida.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 13], [14, 20], [21, 23], [24, 29], [30, 38], [39, 40], [40, 41], [42, 43], [44, 56], [56, 57], [58, 60], [61, 68], [69, 71], [72, 78], [79, 81], [82, 92], [93, 104], [105, 109], [110, 112], [113, 119], [120, 133], [134, 135], [135, 137], [137, 138], [138, 139], [140, 142], [143, 151], [152, 155], [156, 163], [164, 165], [165, 167], [167, 168], [169, 170], [171, 173], [174, 180], [181, 182], [183, 193], [194, 195], [195, 198], [198, 199], [200, 204], [205, 210], [211, 214], [215, 223], [224, 229], [230, 233], [234, 242], [243, 245], [246, 248], [249, 259], [260, 262], [263, 269], [270, 275], [276, 278], [279, 285], [286, 296], [297, 300], [301, 303], [304, 309], [310, 318], [318, 319]]}
{"doc_key": "ai-dev-149", "ner": [[0, 0, "researcher"], [2, 2, "misc"], [4, 4, "field"], [7, 10, "university"], [16, 16, "misc"], [17, 17, "field"], [19, 22, "university"], [27, 27, "misc"], [29, 29, "field"], [32, 35, "university"], [42, 51, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 0, 7, 10, "physical", "", false, false], [0, 0, 7, 10, "role", "", false, false], [0, 0, 19, 22, "physical", "", false, false], [0, 0, 19, 22, "role", "", false, false], [0, 0, 32, 35, "physical", "", false, false], [0, 0, 32, 35, "role", "", false, false], [2, 2, 0, 0, "origin", "", false, false], [2, 2, 4, 4, "topic", "", false, false], [16, 16, 0, 0, "origin", "", false, false], [16, 16, 17, 17, "topic", "", false, false], [27, 27, 0, 0, "origin", "", false, false], [27, 27, 29, 29, "topic", "", false, false], [42, 51, 27, 27, "named", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Sowa", "se", "licenci\u00f3", "en", "matem\u00e1ticas", "en", "el", "Instituto", "Tecnol\u00f3gico", "de", "Massachusetts", "en", "1962", ",", "obtuvo", "un", "m\u00e1ster", "aplicado", "en", "la", "Universidad", "de", "Harvard", "en", "1966", "y", "se", "doctor\u00f3", "en", "inform\u00e1tica", "en", "la", "Universidad", "Libre", "de", "Bruselas", "en", "1999", "con", "una", "tesis", "titulada", "Knowledge", "Representation", ":", "Logical", ",", "Philosophical", ",", "and", "Computational", "Foundations", "."], "sentence-detokenized": "Sowa se licenci\u00f3 en matem\u00e1ticas en el Instituto Tecnol\u00f3gico de Massachusetts en 1962, obtuvo un m\u00e1ster aplicado en la Universidad de Harvard en 1966 y se doctor\u00f3 en inform\u00e1tica en la Universidad Libre de Bruselas en 1999 con una tesis titulada Knowledge Representation: Logical, Philosophical, and Computational Foundations.", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 19], [20, 31], [32, 34], [35, 37], [38, 47], [48, 59], [60, 62], [63, 76], [77, 79], [80, 84], [84, 85], [86, 92], [93, 95], [96, 102], [103, 111], [112, 114], [115, 117], [118, 129], [130, 132], [133, 140], [141, 143], [144, 148], [149, 150], [151, 153], [154, 161], [162, 164], [165, 176], [177, 179], [180, 182], [183, 194], [195, 200], [201, 203], [204, 212], [213, 215], [216, 220], [221, 224], [225, 228], [229, 234], [235, 243], [244, 253], [254, 268], [268, 269], [270, 277], [277, 278], [279, 292], [292, 293], [294, 297], [298, 311], [312, 323], [323, 324]]}
{"doc_key": "ai-dev-150", "ner": [[2, 5, "task"], [12, 12, "task"], [25, 25, "metrics"], [28, 29, "metrics"], [32, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 5, 12, 12, "general-affiliation", "", false, false], [25, 25, 2, 5, "part-of", "", true, false], [28, 29, 2, 5, "part-of", "", true, false], [32, 33, 2, 5, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Dado", "que", "el", "reconocimiento", "de", "par\u00e1frasis", "puede", "plantearse", "como", "un", "problema", "de", "clasificaci\u00f3n", ",", "la", "mayor\u00eda", "de", "las", "m\u00e9tricas", "de", "evaluaci\u00f3n", "est\u00e1ndar", ",", "como", "la", "precisi\u00f3n", ",", "la", "puntuaci\u00f3n", "f1", "o", "una", "curva", "ROC", ",", "funcionan", "relativamente", "bien", "."], "sentence-detokenized": "Dado que el reconocimiento de par\u00e1frasis puede plantearse como un problema de clasificaci\u00f3n, la mayor\u00eda de las m\u00e9tricas de evaluaci\u00f3n est\u00e1ndar, como la precisi\u00f3n, la puntuaci\u00f3n f1 o una curva ROC, funcionan relativamente bien.", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 26], [27, 29], [30, 40], [41, 46], [47, 57], [58, 62], [63, 65], [66, 74], [75, 77], [78, 91], [91, 92], [93, 95], [96, 103], [104, 106], [107, 110], [111, 119], [120, 122], [123, 133], [134, 142], [142, 143], [144, 148], [149, 151], [152, 161], [161, 162], [163, 165], [166, 176], [177, 179], [180, 181], [182, 185], [186, 191], [192, 195], [195, 196], [197, 206], [207, 220], [221, 225], [225, 226]]}
{"doc_key": "ai-dev-151", "ner": [[20, 21, "algorithm"], [34, 35, "algorithm"], [37, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[20, 21, 34, 35, "opposite", "not_suited_for", false, false], [20, 21, 37, 38, "opposite", "not_suited_for", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Esto", "hace", "que", "resulte", "pr\u00e1ctico", "para", "analizar", "grandes", "conjuntos", "de", "datos", "(", "cientos", "o", "miles", "de", "taxones", ")", "y", "para", "hacer", "bootstrapping", ",", "para", "lo", "cual", "otros", "medios", "de", "an\u00e1lisis", "(", "por", "ejemplo", ",", "m\u00e1xima", "parsimonia", ",", "m\u00e1xima", "verosimilitud", ")", "pueden", "ser", "prohibitivos", "desde", "el", "punto", "de", "vista", "computacional", "."], "sentence-detokenized": "Esto hace que resulte pr\u00e1ctico para analizar grandes conjuntos de datos (cientos o miles de taxones) y para hacer bootstrapping, para lo cual otros medios de an\u00e1lisis (por ejemplo, m\u00e1xima parsimonia, m\u00e1xima verosimilitud) pueden ser prohibitivos desde el punto de vista computacional.", "token2charspan": [[0, 4], [5, 9], [10, 13], [14, 21], [22, 30], [31, 35], [36, 44], [45, 52], [53, 62], [63, 65], [66, 71], [72, 73], [73, 80], [81, 82], [83, 88], [89, 91], [92, 99], [99, 100], [101, 102], [103, 107], [108, 113], [114, 127], [127, 128], [129, 133], [134, 136], [137, 141], [142, 147], [148, 154], [155, 157], [158, 166], [167, 168], [168, 171], [172, 179], [179, 180], [181, 187], [188, 198], [198, 199], [200, 206], [207, 220], [220, 221], [222, 228], [229, 232], [233, 245], [246, 251], [252, 254], [255, 260], [261, 263], [264, 269], [270, 283], [283, 284]]}
{"doc_key": "ai-dev-152", "ner": [[6, 6, "programlang"], [8, 8, "programlang"], [10, 15, "organisation"], [17, 17, "organisation"], [26, 26, "programlang"], [29, 43, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 6, 26, 26, "named", "same", false, false], [17, 17, 10, 15, "named", "", false, false], [29, 43, 6, 6, "role", "submits", true, false], [29, 43, 8, 8, "role", "submits", true, false], [29, 43, 10, 15, "role", "submits_to", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["La", "presentaci\u00f3n", "en", "2002", "del", "lenguaje", "DAML", "+", "OIL", "al", "Consorcio", "de", "la", "World", "Wide", "Web", "(", "W3C", ")", "el", "trabajo", "realizado", "por", "los", "contratistas", "de", "DAML", "y", "el", "Comit\u00e9", "Conjunto", "ad", "hoc", "sobre", "Lenguajes", "de", "Marcado", "de", "la", "Uni\u00f3n", "Europea", "y", "Estados", "Unidos", "."], "sentence-detokenized": "La presentaci\u00f3n en 2002 del lenguaje DAML + OIL al Consorcio de la World Wide Web (W3C) el trabajo realizado por los contratistas de DAML y el Comit\u00e9 Conjunto ad hoc sobre Lenguajes de Marcado de la Uni\u00f3n Europea y Estados Unidos.", "token2charspan": [[0, 2], [3, 15], [16, 18], [19, 23], [24, 27], [28, 36], [37, 41], [42, 43], [44, 47], [48, 50], [51, 60], [61, 63], [64, 66], [67, 72], [73, 77], [78, 81], [82, 83], [83, 86], [86, 87], [88, 90], [91, 98], [99, 108], [109, 112], [113, 116], [117, 129], [130, 132], [133, 137], [138, 139], [140, 142], [143, 149], [150, 158], [159, 161], [162, 165], [166, 171], [172, 181], [182, 184], [185, 192], [193, 195], [196, 198], [199, 204], [205, 212], [213, 214], [215, 222], [223, 229], [229, 230]]}
{"doc_key": "ai-dev-153", "ner": [[3, 5, "misc"], [9, 9, "misc"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 3, 5, "part-of", "", true, false], [12, 13, 3, 5, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Un", "ejemplo", "de", "normalizaci\u00f3n", "no", "lineal", "es", "cuando", "la", "normalizaci\u00f3n", "sigue", "una", "funci\u00f3n", "sigmoidea", ",", "en", "ese", "caso", ",", "la", "imagen", "normalizada", "se", "calcula", "seg\u00fan", "la", "f\u00f3rmula"], "sentence-detokenized": "Un ejemplo de normalizaci\u00f3n no lineal es cuando la normalizaci\u00f3n sigue una funci\u00f3n sigmoidea, en ese caso, la imagen normalizada se calcula seg\u00fan la f\u00f3rmula", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 27], [28, 30], [31, 37], [38, 40], [41, 47], [48, 50], [51, 64], [65, 70], [71, 74], [75, 82], [83, 92], [92, 93], [94, 96], [97, 100], [101, 105], [105, 106], [107, 109], [110, 116], [117, 128], [129, 131], [132, 139], [140, 145], [146, 148], [149, 156]]}
{"doc_key": "ai-dev-154", "ner": [[5, 5, "metrics"], [11, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 11, 11, "related-to", "used_together", false, false]], "relations_mapping_to_source": [0], "sentence": ["Se", "ha", "se\u00f1alado", "que", "la", "precisi\u00f3n", "suele", "ir", "unida", "a", "la", "memoria", "para", "superar", "este", "problema"], "sentence-detokenized": "Se ha se\u00f1alado que la precisi\u00f3n suele ir unida a la memoria para superar este problema", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 18], [19, 21], [22, 31], [32, 37], [38, 40], [41, 46], [47, 48], [49, 51], [52, 59], [60, 64], [65, 72], [73, 77], [78, 86]]}
{"doc_key": "ai-dev-155", "ner": [[6, 8, "metrics"], [11, 13, "metrics"], [20, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[20, 21, 11, 13, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Las", "m\u00e9tricas", "m\u00e1s", "utilizadas", "son", "el", "error", "medio", "cuadr\u00e1tico", "y", "el", "error", "medio", "cuadr\u00e1tico", ",", "este", "\u00faltimo", "utilizado", "en", "el", "Premio", "Netflix", "."], "sentence-detokenized": "Las m\u00e9tricas m\u00e1s utilizadas son el error medio cuadr\u00e1tico y el error medio cuadr\u00e1tico, este \u00faltimo utilizado en el Premio Netflix.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 27], [28, 31], [32, 34], [35, 40], [41, 46], [47, 57], [58, 59], [60, 62], [63, 68], [69, 74], [75, 85], [85, 86], [87, 91], [92, 98], [99, 108], [109, 111], [112, 114], [115, 121], [122, 129], [129, 130]]}
{"doc_key": "ai-dev-156", "ner": [[13, 18, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["En", "agosto", "de", "2016", ",", "se", "anunci\u00f3", "un", "programa", "de", "investigaci\u00f3n", "con", "el", "University", "College", "Hospital", "con", "el", "objetivo", "de", "desarrollar", "un", "algoritmo", "que", "pueda", "diferenciar", "autom\u00e1ticamente", "los", "tejidos", "sanos", "de", "los", "cancerosos", "en", "las", "zonas", "de", "la", "cabeza", "y", "el", "cuello", "."], "sentence-detokenized": "En agosto de 2016, se anunci\u00f3 un programa de investigaci\u00f3n con el University College Hospital con el objetivo de desarrollar un algoritmo que pueda diferenciar autom\u00e1ticamente los tejidos sanos de los cancerosos en las zonas de la cabeza y el cuello.", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 17], [17, 18], [19, 21], [22, 29], [30, 32], [33, 41], [42, 44], [45, 58], [59, 62], [63, 65], [66, 76], [77, 84], [85, 93], [94, 97], [98, 100], [101, 109], [110, 112], [113, 124], [125, 127], [128, 137], [138, 141], [142, 147], [148, 159], [160, 175], [176, 179], [180, 187], [188, 193], [194, 196], [197, 200], [201, 211], [212, 214], [215, 218], [219, 224], [225, 227], [228, 230], [231, 237], [238, 239], [240, 242], [243, 249], [249, 250]]}
{"doc_key": "ai-dev-157", "ner": [[9, 9, "researcher"], [20, 22, "organisation"], [25, 28, "organisation"], [31, 34, "organisation"], [37, 42, "organisation"], [45, 51, "organisation"], [54, 57, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 9, 20, 22, "role", "", false, false], [9, 9, 25, 28, "role", "", false, false], [9, 9, 31, 34, "role", "", false, false], [9, 9, 37, 42, "role", "", false, false], [9, 9, 45, 51, "role", "", false, false], [9, 9, 54, 57, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["La", "repercusi\u00f3n", "de", "las", "contribuciones", "te\u00f3ricas", "y", "emp\u00edricas", "de", "Posner", "ha", "sido", "reconocida", "a", "trav\u00e9s", "de", "su", "pertenencia", "a", "la", "American", "Psychological", "Association", ",", "la", "Association", "for", "Psychological", "Science", ",", "la", "Society", "of", "Experimental", "Psychologists", ",", "la", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "la", "American", "Association", "for", "the", "Advancement", "of", "Science", "y", "la", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "La repercusi\u00f3n de las contribuciones te\u00f3ricas y emp\u00edricas de Posner ha sido reconocida a trav\u00e9s de su pertenencia a la American Psychological Association, la Association for Psychological Science, la Society of Experimental Psychologists, la American Academy of Arts and Sciences, la American Association for the Advancement of Science y la National Academy of Sciences.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 21], [22, 36], [37, 45], [46, 47], [48, 57], [58, 60], [61, 67], [68, 70], [71, 75], [76, 86], [87, 88], [89, 95], [96, 98], [99, 101], [102, 113], [114, 115], [116, 118], [119, 127], [128, 141], [142, 153], [153, 154], [155, 157], [158, 169], [170, 173], [174, 187], [188, 195], [195, 196], [197, 199], [200, 207], [208, 210], [211, 223], [224, 237], [237, 238], [239, 241], [242, 250], [251, 258], [259, 261], [262, 266], [267, 270], [271, 279], [279, 280], [281, 283], [284, 292], [293, 304], [305, 308], [309, 312], [313, 324], [325, 327], [328, 335], [336, 337], [338, 340], [341, 349], [350, 357], [358, 360], [361, 369], [369, 370]]}
{"doc_key": "ai-dev-158", "ner": [[1, 1, "product"], [9, 10, "field"], [13, 15, "task"], [18, 21, "task"], [23, 23, "task"], [27, 30, "task"], [32, 32, "task"], [36, 37, "field"], [40, 41, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[1, 1, 9, 10, "usage", "", false, false], [13, 15, 9, 10, "part-of", "", false, false], [18, 21, 9, 10, "part-of", "", false, false], [23, 23, 18, 21, "named", "", false, false], [27, 30, 9, 10, "part-of", "", false, false], [32, 32, 27, 30, "named", "", false, false], [36, 37, 9, 10, "part-of", "", false, false], [40, 41, 9, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Estos", "chatbots", "inteligentes", "hacen", "uso", "de", "todo", "tipo", "de", "inteligencia", "artificial", "como", "la", "moderaci\u00f3n", "de", "im\u00e1genes", "y", "la", "comprensi\u00f3n", "del", "lenguaje", "natural", "(", "NLU", ")", ",", "la", "generaci\u00f3n", "del", "lenguaje", "natural", "(", "NLG", ")", ",", "el", "aprendizaje", "autom\u00e1tico", "y", "el", "aprendizaje", "profundo", "."], "sentence-detokenized": "Estos chatbots inteligentes hacen uso de todo tipo de inteligencia artificial como la moderaci\u00f3n de im\u00e1genes y la comprensi\u00f3n del lenguaje natural (NLU), la generaci\u00f3n del lenguaje natural (NLG), el aprendizaje autom\u00e1tico y el aprendizaje profundo.", "token2charspan": [[0, 5], [6, 14], [15, 27], [28, 33], [34, 37], [38, 40], [41, 45], [46, 50], [51, 53], [54, 66], [67, 77], [78, 82], [83, 85], [86, 96], [97, 99], [100, 108], [109, 110], [111, 113], [114, 125], [126, 129], [130, 138], [139, 146], [147, 148], [148, 151], [151, 152], [152, 153], [154, 156], [157, 167], [168, 171], [172, 180], [181, 188], [189, 190], [190, 193], [193, 194], [194, 195], [196, 198], [199, 210], [211, 221], [222, 223], [224, 226], [227, 238], [239, 247], [247, 248]]}
{"doc_key": "ai-dev-159", "ner": [[9, 9, "metrics"], [11, 11, "metrics"], [16, 16, "metrics"], [19, 26, "metrics"], [35, 35, "metrics"], [38, 38, "metrics"], [41, 47, "metrics"], [8, 54, "metrics"], [56, 56, "metrics"], [59, 65, "metrics"], [33, 76, "metrics"], [78, 78, "metrics"], [81, 87, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[11, 11, 9, 9, "named", "", false, false], [16, 16, 9, 9, "named", "", false, false], [19, 26, 9, 9, "named", "", false, false], [38, 38, 35, 35, "named", "", false, false], [41, 47, 35, 35, "named", "", false, false], [56, 56, 8, 54, "named", "", false, false], [59, 65, 8, 54, "named", "", false, false], [78, 78, 33, 76, "named", "", false, false], [81, 87, 33, 76, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Los", "ratios", "de", "las", "filas", "son", "el", "Valor", "Predictivo", "Positivo", "(", "PPV", ",", "tambi\u00e9n", "conocido", "como", "precisi\u00f3n", ")", "(", "TP", "/", "(", "TP", "+", "FP", ")", ")", ",", "con", "el", "complemento", "de", "la", "Tasa", "de", "Descubrimiento", "Falsa", "(", "FDR", ")", "(", "FP", "/", "(", "TP", "+", "FP", ")", ")", ";", "y", "el", "Valor", "Predictivo", "Negativo", "(", "NPV", ")", "(", "TN", "/", "(", "TN", "+", "FN", ")", ")", ",", "con", "el", "complemento", "de", "la", "Tasa", "de", "Omisi\u00f3n", "Falsa", "(", "FOR", ")", "(", "FN", "/", "(", "TN", "+", "FN", ")", ")", "."], "sentence-detokenized": "Los ratios de las filas son el Valor Predictivo Positivo (PPV, tambi\u00e9n conocido como precisi\u00f3n) (TP / (TP + FP)), con el complemento de la Tasa de Descubrimiento Falsa (FDR) (FP / (TP + FP)); y el Valor Predictivo Negativo (NPV) (TN / (TN + FN)), con el complemento de la Tasa de Omisi\u00f3n Falsa (FOR) (FN / (TN + FN)).", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 17], [18, 23], [24, 27], [28, 30], [31, 36], [37, 47], [48, 56], [57, 58], [58, 61], [61, 62], [63, 70], [71, 79], [80, 84], [85, 94], [94, 95], [96, 97], [97, 99], [100, 101], [102, 103], [103, 105], [106, 107], [108, 110], [110, 111], [111, 112], [112, 113], [114, 117], [118, 120], [121, 132], [133, 135], [136, 138], [139, 143], [144, 146], [147, 161], [162, 167], [168, 169], [169, 172], [172, 173], [174, 175], [175, 177], [178, 179], [180, 181], [181, 183], [184, 185], [186, 188], [188, 189], [189, 190], [190, 191], [192, 193], [194, 196], [197, 202], [203, 213], [214, 222], [223, 224], [224, 227], [227, 228], [229, 230], [230, 232], [233, 234], [235, 236], [236, 238], [239, 240], [241, 243], [243, 244], [244, 245], [245, 246], [247, 250], [251, 253], [254, 265], [266, 268], [269, 271], [272, 276], [277, 279], [280, 287], [288, 293], [294, 295], [295, 298], [298, 299], [300, 301], [301, 303], [304, 305], [306, 307], [307, 309], [310, 311], [312, 314], [314, 315], [315, 316], [316, 317]]}
{"doc_key": "ai-dev-160", "ner": [[10, 10, "misc"], [16, 18, "algorithm"], [20, 20, "algorithm"], [24, 27, "algorithm"], [29, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[20, 20, 16, 18, "named", "", false, false], [29, 29, 24, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "informaci\u00f3n", "es", "una", "mezcla", "de", "mapas", "de", "sitio", "y", "RSS", "y", "se", "crea", "utilizando", "el", "Modelo", "de", "Informaci\u00f3n", "(", "IM", ")", "y", "la", "Ontolog\u00eda", "de", "Recursos", "Biom\u00e9dicos", "(", "BRO", ")", "."], "sentence-detokenized": "La informaci\u00f3n es una mezcla de mapas de sitio y RSS y se crea utilizando el Modelo de Informaci\u00f3n (IM) y la Ontolog\u00eda de Recursos Biom\u00e9dicos (BRO).", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 21], [22, 28], [29, 31], [32, 37], [38, 40], [41, 46], [47, 48], [49, 52], [53, 54], [55, 57], [58, 62], [63, 73], [74, 76], [77, 83], [84, 86], [87, 98], [99, 100], [100, 102], [102, 103], [104, 105], [106, 108], [109, 118], [119, 121], [122, 130], [131, 141], [142, 143], [143, 146], [146, 147], [147, 148]]}
{"doc_key": "ai-dev-161", "ner": [[2, 4, "task"], [9, 11, "algorithm"], [13, 16, "algorithm"], [22, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 4, 13, 16, "origin", "based_on", false, false], [13, 16, 9, 11, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["El", "reciente", "reconocimiento", "de", "textos", "se", "basa", "en", "una", "red", "neuronal", "recurrente", "(", "memoria", "a", "corto", "plazo", ")", "y", "no", "requiere", "un", "modelo", "ling\u00fc\u00edstico", "."], "sentence-detokenized": "El reciente reconocimiento de textos se basa en una red neuronal recurrente (memoria a corto plazo) y no requiere un modelo ling\u00fc\u00edstico.", "token2charspan": [[0, 2], [3, 11], [12, 26], [27, 29], [30, 36], [37, 39], [40, 44], [45, 47], [48, 51], [52, 55], [56, 64], [65, 75], [76, 77], [77, 84], [85, 86], [87, 92], [93, 98], [98, 99], [100, 101], [102, 104], [105, 113], [114, 116], [117, 123], [124, 135], [135, 136]]}
{"doc_key": "ai-dev-162", "ner": [[0, 3, "misc"], [8, 10, "metrics"], [13, 15, "algorithm"], [19, 20, "metrics"], [24, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 10, 0, 3, "type-of", "", false, false], [13, 15, 8, 10, "related-to", "", true, false], [19, 20, 0, 3, "type-of", "", false, false], [24, 25, 19, 20, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Las", "funciones", "de", "p\u00e9rdida", "m\u00e1s", "populares", "son", "la", "p\u00e9rdida", "de", "bisagra", "(", "para", "las", "SVM", "lineales", ")", "y", "la", "p\u00e9rdida", "logar\u00edtmica", "(", "para", "la", "regresi\u00f3n", "log\u00edstica", ")", "."], "sentence-detokenized": "Las funciones de p\u00e9rdida m\u00e1s populares son la p\u00e9rdida de bisagra (para las SVM lineales) y la p\u00e9rdida logar\u00edtmica (para la regresi\u00f3n log\u00edstica).", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 24], [25, 28], [29, 38], [39, 42], [43, 45], [46, 53], [54, 56], [57, 64], [65, 66], [66, 70], [71, 74], [75, 78], [79, 87], [87, 88], [89, 90], [91, 93], [94, 101], [102, 113], [114, 115], [115, 119], [120, 122], [123, 132], [133, 142], [142, 143], [143, 144]]}
{"doc_key": "ai-dev-163", "ner": [[0, 1, "metrics"], [12, 14, "metrics"], [16, 16, "metrics"], [20, 22, "metrics"], [24, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 12, 14, "compare", "", false, false], [0, 1, 20, 22, "compare", "", false, false], [16, 16, 12, 14, "named", "", false, false], [24, 24, 20, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["El", "SSIM", "est\u00e1", "dise\u00f1ado", "para", "mejorar", "los", "m\u00e9todos", "tradicionales", ",", "como", "la", "relaci\u00f3n", "se\u00f1al-ruido", "m\u00e1xima", "(", "PSNR", ")", "y", "el", "error", "medio", "cuadr\u00e1tico", "(", "MSE", ")", "."], "sentence-detokenized": "El SSIM est\u00e1 dise\u00f1ado para mejorar los m\u00e9todos tradicionales, como la relaci\u00f3n se\u00f1al-ruido m\u00e1xima (PSNR) y el error medio cuadr\u00e1tico (MSE).", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 21], [22, 26], [27, 34], [35, 38], [39, 46], [47, 60], [60, 61], [62, 66], [67, 69], [70, 78], [79, 90], [91, 97], [98, 99], [99, 103], [103, 104], [105, 106], [107, 109], [110, 115], [116, 121], [122, 132], [133, 134], [134, 137], [137, 138], [138, 139]]}
{"doc_key": "ai-dev-164", "ner": [[12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Su", "trabajo", "inspir\u00f3", "a", "generaciones", "posteriores", "de", "investigadores", "en", "rob\u00f3tica", ",", "como", "Rodney", "Brooks", ",", "Hans", "Moravec", "y", "Mark", "Tilden", "."], "sentence-detokenized": "Su trabajo inspir\u00f3 a generaciones posteriores de investigadores en rob\u00f3tica, como Rodney Brooks, Hans Moravec y Mark Tilden.", "token2charspan": [[0, 2], [3, 10], [11, 18], [19, 20], [21, 33], [34, 45], [46, 48], [49, 63], [64, 66], [67, 75], [75, 76], [77, 81], [82, 88], [89, 95], [95, 96], [97, 101], [102, 109], [110, 111], [112, 116], [117, 123], [123, 124]]}
{"doc_key": "ai-dev-165", "ner": [[19, 20, "algorithm"], [23, 26, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[23, 26, 19, 20, "origin", "based_on", false, false]], "relations_mapping_to_source": [0], "sentence": ["Adem\u00e1s", ",", "el", "entrenamiento", "del", "pulso", "no", "es", "diferenciable", ",", "lo", "que", "elimina", "los", "m\u00e9todos", "de", "entrenamiento", "basados", "en", "la", "retropropagaci\u00f3n", ",", "como", "el", "descenso", "de", "gradiente", "."], "sentence-detokenized": "Adem\u00e1s, el entrenamiento del pulso no es diferenciable, lo que elimina los m\u00e9todos de entrenamiento basados en la retropropagaci\u00f3n, como el descenso de gradiente.", "token2charspan": [[0, 6], [6, 7], [8, 10], [11, 24], [25, 28], [29, 34], [35, 37], [38, 40], [41, 54], [54, 55], [56, 58], [59, 62], [63, 70], [71, 74], [75, 82], [83, 85], [86, 99], [100, 107], [108, 110], [111, 113], [114, 130], [130, 131], [132, 136], [137, 139], [140, 148], [149, 151], [152, 161], [161, 162]]}
{"doc_key": "ai-dev-166", "ner": [[7, 9, "metrics"], [16, 16, "metrics"], [21, 21, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 16, 16, "related-to", "describes", false, false], [16, 16, 21, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Estas", "relaciones", "pueden", "representarse", "f\u00e1cilmente", "con", "una", "matriz", "de", "confusi\u00f3n", ",", "una", "tabla", "que", "describe", "la", "precisi\u00f3n", "de", "un", "modelo", "de", "clasificaci\u00f3n", "."], "sentence-detokenized": "Estas relaciones pueden representarse f\u00e1cilmente con una matriz de confusi\u00f3n, una tabla que describe la precisi\u00f3n de un modelo de clasificaci\u00f3n.", "token2charspan": [[0, 5], [6, 16], [17, 23], [24, 37], [38, 48], [49, 52], [53, 56], [57, 63], [64, 66], [67, 76], [76, 77], [78, 81], [82, 87], [88, 91], [92, 100], [101, 103], [104, 113], [114, 116], [117, 119], [120, 126], [127, 129], [130, 143], [143, 144]]}
{"doc_key": "ai-dev-167", "ner": [[2, 14, "conference"], [11, 11, "conference"], [17, 17, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 2, 14, "named", "", false, false], [17, 17, 2, 14, "physical", "", false, false], [17, 17, 2, 14, "role", "", false, false], [17, 17, 2, 14, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["En", "la", "Conferencia", "sobre", "Sistemas", "de", "Procesamiento", "de", "Informaci\u00f3n", "Neuronal", "(", "NeurIPS", ")", "de", "2018", "investigadores", "de", "Google", "presentaron", "el", "trabajo"], "sentence-detokenized": "En la Conferencia sobre Sistemas de Procesamiento de Informaci\u00f3n Neuronal (NeurIPS) de 2018 investigadores de Google presentaron el trabajo", "token2charspan": [[0, 2], [3, 5], [6, 17], [18, 23], [24, 32], [33, 35], [36, 49], [50, 52], [53, 64], [65, 73], [74, 75], [75, 82], [82, 83], [84, 86], [87, 91], [92, 106], [107, 109], [110, 116], [117, 128], [129, 131], [132, 139]]}
{"doc_key": "ai-dev-168", "ner": [[4, 4, "university"], [13, 13, "product"], [18, 21, "misc"], [25, 26, "conference"], [31, 34, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 13, 18, 21, "win-defeat", "", false, false], [18, 21, 25, 26, "temporal", "", false, false], [31, 34, 25, 26, "part-of", "", false, false], [31, 34, 25, 26, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Durante", "su", "estancia", "en", "Duke", ",", "trabaj\u00f3", "en", "la", "soluci\u00f3n", "autom\u00e1tica", "de", "crucigramas", "PROVERB", ",", "que", "gan\u00f3", "el", "premio", "Outstanding", "Paper", "Award", "en", "1999", "de", "la", "AAAI", "y", "compiti\u00f3", "en", "el", "American", "Crossword", "Puzzle", "Tournament", "."], "sentence-detokenized": "Durante su estancia en Duke, trabaj\u00f3 en la soluci\u00f3n autom\u00e1tica de crucigramas PROVERB, que gan\u00f3 el premio Outstanding Paper Award en 1999 de la AAAI y compiti\u00f3 en el American Crossword Puzzle Tournament.", "token2charspan": [[0, 7], [8, 10], [11, 19], [20, 22], [23, 27], [27, 28], [29, 36], [37, 39], [40, 42], [43, 51], [52, 62], [63, 65], [66, 77], [78, 85], [85, 86], [87, 90], [91, 95], [96, 98], [99, 105], [106, 117], [118, 123], [124, 129], [130, 132], [133, 137], [138, 140], [141, 143], [144, 148], [149, 150], [151, 159], [160, 162], [163, 165], [166, 174], [175, 184], [185, 191], [192, 202], [202, 203]]}
{"doc_key": "ai-dev-169", "ner": [[3, 4, "location"], [6, 6, "location"], [17, 17, "country"], [19, 19, "country"], [21, 21, "country"], [23, 23, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 6, 6, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Con", "sede", "en", "Rochester", "Hills", ",", "Michigan", ",", "la", "empresa", "contaba", "con", "10", "sedes", "regionales", "en", "Estados", "Unidos", ",", "Canad\u00e1", ",", "M\u00e9xico", "y", "Brasil", "."], "sentence-detokenized": "Con sede en Rochester Hills, Michigan, la empresa contaba con 10 sedes regionales en Estados Unidos, Canad\u00e1, M\u00e9xico y Brasil.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 21], [22, 27], [27, 28], [29, 37], [37, 38], [39, 41], [42, 49], [50, 57], [58, 61], [62, 64], [65, 70], [71, 81], [82, 84], [85, 92], [93, 99], [99, 100], [101, 107], [107, 108], [109, 115], [116, 117], [118, 124], [124, 125]]}
{"doc_key": "ai-dev-170", "ner": [[13, 13, "product"], [16, 19, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Se", "une", "a", "una", "colecci\u00f3n", "de", "robots", "hist\u00f3ricamente", "importantes", "que", "incluye", "un", "primer", "Unimate", "y", "el", "Odex", "1", "de", "Odetics", "."], "sentence-detokenized": "Se une a una colecci\u00f3n de robots hist\u00f3ricamente importantes que incluye un primer Unimate y el Odex 1 de Odetics.", "token2charspan": [[0, 2], [3, 6], [7, 8], [9, 12], [13, 22], [23, 25], [26, 32], [33, 47], [48, 59], [60, 63], [64, 71], [72, 74], [75, 81], [82, 89], [90, 91], [92, 94], [95, 99], [100, 101], [102, 104], [105, 112], [112, 113]]}
{"doc_key": "ai-dev-171", "ner": [[11, 11, "researcher"], [13, 14, "organisation"], [16, 17, "researcher"], [27, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 13, 14, "physical", "", false, false], [11, 11, 13, 14, "role", "", false, false], [16, 17, 13, 14, "physical", "", false, false], [16, 17, 13, 14, "role", "", false, false], [16, 17, 27, 29, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["El", "editor", "invitado", "para", "ese", "n\u00famero", "ser\u00e1", "el", "antiguo", "colega", "de", "David", "en", "el", "NIST", ",", "Judah", "Levine", ",", "que", "es", "el", "\u00faltimo", "galardonado", "con", "el", "premio", "I.", "I.", "Rabi", "."], "sentence-detokenized": "El editor invitado para ese n\u00famero ser\u00e1 el antiguo colega de David en el NIST, Judah Levine, que es el \u00faltimo galardonado con el premio I. I. Rabi.", "token2charspan": [[0, 2], [3, 9], [10, 18], [19, 23], [24, 27], [28, 34], [35, 39], [40, 42], [43, 50], [51, 57], [58, 60], [61, 66], [67, 69], [70, 72], [73, 77], [77, 78], [79, 84], [85, 91], [91, 92], [93, 96], [97, 99], [100, 102], [103, 109], [110, 121], [122, 125], [126, 128], [129, 135], [136, 138], [139, 141], [142, 146], [146, 147]]}
{"doc_key": "ai-dev-172", "ner": [[13, 15, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["\u00c9stas", "pueden", "organizarse", "en", "una", "tabla", "de", "contingencia", "de", "2", "\u00d7", "2", "(", "matriz", "de", "confusi\u00f3n", ")", ",", "convencionalmente", "con", "el", "resultado", "de", "la", "prueba", "en", "el", "eje", "vertical", "y", "la", "condici\u00f3n", "real", "en", "el", "eje", "horizontal", "."], "sentence-detokenized": "\u00c9stas pueden organizarse en una tabla de contingencia de 2 \u00d7 2 (matriz de confusi\u00f3n), convencionalmente con el resultado de la prueba en el eje vertical y la condici\u00f3n real en el eje horizontal.", "token2charspan": [[0, 5], [6, 12], [13, 24], [25, 27], [28, 31], [32, 37], [38, 40], [41, 53], [54, 56], [57, 58], [59, 60], [61, 62], [63, 64], [64, 70], [71, 73], [74, 83], [83, 84], [84, 85], [86, 103], [104, 107], [108, 110], [111, 120], [121, 123], [124, 126], [127, 133], [134, 136], [137, 139], [140, 143], [144, 152], [153, 154], [155, 157], [158, 167], [168, 172], [173, 175], [176, 178], [179, 182], [183, 193], [193, 194]]}
{"doc_key": "ai-dev-173", "ner": [[1, 5, "product"], [9, 9, "product"], [12, 12, "product"], [15, 16, "product"], [21, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 5, 9, 9, "part-of", "", false, false], [1, 5, 12, 12, "part-of", "", false, false], [1, 5, 15, 16, "part-of", "", false, false], [1, 5, 21, 24, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["El", "sistema", "operativo", "iOS", "de", "Apple", "utilizado", "en", "el", "iPhone", ",", "el", "iPad", "y", "el", "iPod", "Touch", "utiliza", "la", "accesibilidad", "de", "s\u00edntesis", "de", "voz", "VoiceOver", "."], "sentence-detokenized": "El sistema operativo iOS de Apple utilizado en el iPhone, el iPad y el iPod Touch utiliza la accesibilidad de s\u00edntesis de voz VoiceOver.", "token2charspan": [[0, 2], [3, 10], [11, 20], [21, 24], [25, 27], [28, 33], [34, 43], [44, 46], [47, 49], [50, 56], [56, 57], [58, 60], [61, 65], [66, 67], [68, 70], [71, 75], [76, 81], [82, 89], [90, 92], [93, 106], [107, 109], [110, 118], [119, 121], [122, 125], [126, 135], [135, 136]]}
{"doc_key": "ai-dev-174", "ner": [[9, 9, "conference"], [14, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Por", "ejemplo", ",", "el", "mejor", "sistema", "que", "entra", "en", "MUC-7", "obtuvo", "un", "93,39%", "de", "la", "medida", "F", ",", "mientras", "que", "los", "anotadores", "humanos", "obtuvieron", "un", "97,6%", "y", "un", "96,95%", "."], "sentence-detokenized": "Por ejemplo, el mejor sistema que entra en MUC-7 obtuvo un 93,39% de la medida F, mientras que los anotadores humanos obtuvieron un 97,6% y un 96,95%.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 21], [22, 29], [30, 33], [34, 39], [40, 42], [43, 48], [49, 55], [56, 58], [59, 65], [66, 68], [69, 71], [72, 78], [79, 80], [80, 81], [82, 90], [91, 94], [95, 98], [99, 109], [110, 117], [118, 128], [129, 131], [132, 137], [138, 139], [140, 142], [143, 149], [149, 150]]}
{"doc_key": "ai-dev-175", "ner": [[14, 17, "algorithm"], [19, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[19, 19, 14, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Para", "ello", "se", "utilizan", "algoritmos", "de", "entrenamiento", "de", "redes", "neuronales", "est\u00e1ndar", ",", "como", "el", "descenso", "de", "gradiente", "estoc\u00e1stico", "con", "retropropagaci\u00f3n", "."], "sentence-detokenized": "Para ello se utilizan algoritmos de entrenamiento de redes neuronales est\u00e1ndar, como el descenso de gradiente estoc\u00e1stico con retropropagaci\u00f3n.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 21], [22, 32], [33, 35], [36, 49], [50, 52], [53, 58], [59, 69], [70, 78], [78, 79], [80, 84], [85, 87], [88, 96], [97, 99], [100, 109], [110, 121], [122, 125], [126, 142], [142, 143]]}
{"doc_key": "ai-dev-176", "ner": [[0, 1, "organisation"], [28, 29, "country"], [37, 37, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 28, 29, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Rotten", "Tomatoes", "es", "un", "sitio", "web", "que", "se", "encuentra", "entre", "los", "1000", "mejores", ",", "situ\u00e1ndose", "en", "el", "n\u00famero", "400", "a", "nivel", "mundial", "y", "entre", "los", "150", "mejores", "de", "Estados", "Unidos", ",", "seg\u00fan", "el", "clasificador", "de", "sitios", "web", "Alexa", "."], "sentence-detokenized": "Rotten Tomatoes es un sitio web que se encuentra entre los 1000 mejores, situ\u00e1ndose en el n\u00famero 400 a nivel mundial y entre los 150 mejores de Estados Unidos, seg\u00fan el clasificador de sitios web Alexa.", "token2charspan": [[0, 6], [7, 15], [16, 18], [19, 21], [22, 27], [28, 31], [32, 35], [36, 38], [39, 48], [49, 54], [55, 58], [59, 63], [64, 71], [71, 72], [73, 83], [84, 86], [87, 89], [90, 96], [97, 100], [101, 102], [103, 108], [109, 116], [117, 118], [119, 124], [125, 128], [129, 132], [133, 140], [141, 143], [144, 151], [152, 158], [158, 159], [160, 165], [166, 168], [169, 181], [182, 184], [185, 191], [192, 195], [196, 201], [201, 202]]}
{"doc_key": "ai-dev-177", "ner": [[16, 17, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["En", "general", ",", "todo", "aprendizaje", "muestra", "un", "cambio", "incremental", "en", "el", "tiempo", ",", "pero", "describe", "una", "funci\u00f3n", "sigmoidea", "que", "tiene", "diferentes", "apariencias", "seg\u00fan", "la", "escala", "temporal", "de", "observaci\u00f3n", "."], "sentence-detokenized": "En general, todo aprendizaje muestra un cambio incremental en el tiempo, pero describe una funci\u00f3n sigmoidea que tiene diferentes apariencias seg\u00fan la escala temporal de observaci\u00f3n.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 16], [17, 28], [29, 36], [37, 39], [40, 46], [47, 58], [59, 61], [62, 64], [65, 71], [71, 72], [73, 77], [78, 86], [87, 90], [91, 98], [99, 108], [109, 112], [113, 118], [119, 129], [130, 141], [142, 147], [148, 150], [151, 157], [158, 166], [167, 169], [170, 181], [181, 182]]}
{"doc_key": "ai-dev-178", "ner": [[1, 1, "metrics"], [6, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 1, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["El", "SSD", "tambi\u00e9n", "se", "conoce", "como", "error", "cuadr\u00e1tico", "medio", "."], "sentence-detokenized": "El SSD tambi\u00e9n se conoce como error cuadr\u00e1tico medio.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 24], [25, 29], [30, 35], [36, 46], [47, 52], [52, 53]]}
{"doc_key": "ai-dev-179", "ner": [[0, 5, "algorithm"], [8, 9, "algorithm"], [12, 14, "algorithm"], [28, 29, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 5, 28, 29, "related-to", "can_be_related_to", true, false], [8, 9, 28, 29, "related-to", "can_be_related_to", true, false], [12, 14, 28, 29, "related-to", "can_be_related_to", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["El", "aprendizaje", "de", "\u00e1rboles", "de", "decisi\u00f3n", ",", "las", "redes", "neuronales", "o", "un", "clasificador", "Bayes", "ingenuo", "podr\u00edan", "utilizarse", "en", "combinaci\u00f3n", "con", "medidas", "de", "calidad", "del", "modelo", ",", "como", "la", "precisi\u00f3n", "equilibrada"], "sentence-detokenized": "El aprendizaje de \u00e1rboles de decisi\u00f3n, las redes neuronales o un clasificador Bayes ingenuo podr\u00edan utilizarse en combinaci\u00f3n con medidas de calidad del modelo, como la precisi\u00f3n equilibrada", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 25], [26, 28], [29, 37], [37, 38], [39, 42], [43, 48], [49, 59], [60, 61], [62, 64], [65, 77], [78, 83], [84, 91], [92, 99], [100, 110], [111, 113], [114, 125], [126, 129], [130, 137], [138, 140], [141, 148], [149, 152], [153, 159], [159, 160], [161, 165], [166, 168], [169, 178], [179, 190]]}
{"doc_key": "ai-dev-180", "ner": [[13, 14, "conference"], [25, 31, "conference"], [19, 24, "misc"], [36, 39, "product"], [45, 48, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 24, 25, 31, "origin", "", false, false], [19, 24, 25, 31, "temporal", "", false, false], [36, 39, 19, 24, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Ha", "sido", "presidente", "(", "1979", ")", "y", "miembro", "inaugural", "(", "2011", ")", "de", "la", "ACL", ",", "ha", "recibido", "el", "Premio", "de", "Sistemas", "de", "Software", "de", "la", "Association", "for", "Computing", "Machinery", "de", "1992", "por", "su", "contribuci\u00f3n", "al", "sistema", "de", "programaci\u00f3n", "Interlisp", "y", "es", "miembro", "de", "la", "Association", "for", "Computing", "Machinery", "."], "sentence-detokenized": "Ha sido presidente (1979) y miembro inaugural (2011) de la ACL, ha recibido el Premio de Sistemas de Software de la Association for Computing Machinery de 1992 por su contribuci\u00f3n al sistema de programaci\u00f3n Interlisp y es miembro de la Association for Computing Machinery.", "token2charspan": [[0, 2], [3, 7], [8, 18], [19, 20], [20, 24], [24, 25], [26, 27], [28, 35], [36, 45], [46, 47], [47, 51], [51, 52], [53, 55], [56, 58], [59, 62], [62, 63], [64, 66], [67, 75], [76, 78], [79, 85], [86, 88], [89, 97], [98, 100], [101, 109], [110, 112], [113, 115], [116, 127], [128, 131], [132, 141], [142, 151], [152, 154], [155, 159], [160, 163], [164, 166], [167, 179], [180, 182], [183, 190], [191, 193], [194, 206], [207, 216], [217, 218], [219, 221], [222, 229], [230, 232], [233, 235], [236, 247], [248, 251], [252, 261], [262, 271], [271, 272]]}
{"doc_key": "ai-dev-181", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 9, "researcher"], [12, 13, "researcher"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 25, 26, "related-to", "", false, false], [5, 6, 25, 26, "related-to", "", false, false], [8, 9, 25, 26, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Junto", "con", "Geoffrey", "Hinton", "y", "Yann", "LeCun", ",", "Bengio", "es", "considerado", "por", "Cade", "Metz", "como", "una", "de", "las", "tres", "personas", "m\u00e1s", "responsables", "del", "avance", "del", "aprendizaje", "profundo", "durante", "las", "d\u00e9cadas", "de", "1990", "y", "2000", "."], "sentence-detokenized": "Junto con Geoffrey Hinton y Yann LeCun, Bengio es considerado por Cade Metz como una de las tres personas m\u00e1s responsables del avance del aprendizaje profundo durante las d\u00e9cadas de 1990 y 2000.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 25], [26, 27], [28, 32], [33, 38], [38, 39], [40, 46], [47, 49], [50, 61], [62, 65], [66, 70], [71, 75], [76, 80], [81, 84], [85, 87], [88, 91], [92, 96], [97, 105], [106, 109], [110, 122], [123, 126], [127, 133], [134, 137], [138, 149], [150, 158], [159, 166], [167, 170], [171, 178], [179, 181], [182, 186], [187, 188], [189, 193], [193, 194]]}
{"doc_key": "ai-dev-182", "ner": [[2, 5, "field"], [8, 8, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["En", "la", "teor\u00eda", "de", "la", "informaci\u00f3n", "y", "la", "inform\u00e1tica", ",", "un", "c\u00f3digo", "suele", "considerarse", "un", "algoritmo", "que", "representa", "de", "forma", "\u00fanica", "s\u00edmbolos", "de", "alg\u00fan", "alfabeto", "de", "origen", ",", "mediante", "cadenas", "codificadas", ",", "que", "pueden", "estar", "en", "alg\u00fan", "otro", "alfabeto", "de", "destino", "."], "sentence-detokenized": "En la teor\u00eda de la informaci\u00f3n y la inform\u00e1tica, un c\u00f3digo suele considerarse un algoritmo que representa de forma \u00fanica s\u00edmbolos de alg\u00fan alfabeto de origen, mediante cadenas codificadas, que pueden estar en alg\u00fan otro alfabeto de destino.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 15], [16, 18], [19, 30], [31, 32], [33, 35], [36, 47], [47, 48], [49, 51], [52, 58], [59, 64], [65, 77], [78, 80], [81, 90], [91, 94], [95, 105], [106, 108], [109, 114], [115, 120], [121, 129], [130, 132], [133, 138], [139, 147], [148, 150], [151, 157], [157, 158], [159, 167], [168, 175], [176, 187], [187, 188], [189, 192], [193, 199], [200, 205], [206, 208], [209, 214], [215, 219], [220, 228], [229, 231], [232, 239], [239, 240]]}
{"doc_key": "ai-dev-183", "ner": [[8, 9, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 14, 8, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Una", "funci\u00f3n", "no", "lineal", "bastante", "sencilla", ",", "la", "funci\u00f3n", "sigmoidea", ",", "como", "la", "funci\u00f3n", "log\u00edstica", ",", "tambi\u00e9n", "tiene", "una", "derivada", "f\u00e1cil", "de", "calcular", ",", "que", "puede", "ser", "importante", "a", "la", "hora", "de", "calcular", "las", "actualizaciones", "de", "peso", "en", "la", "red", "."], "sentence-detokenized": "Una funci\u00f3n no lineal bastante sencilla, la funci\u00f3n sigmoidea, como la funci\u00f3n log\u00edstica, tambi\u00e9n tiene una derivada f\u00e1cil de calcular, que puede ser importante a la hora de calcular las actualizaciones de peso en la red.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 21], [22, 30], [31, 39], [39, 40], [41, 43], [44, 51], [52, 61], [61, 62], [63, 67], [68, 70], [71, 78], [79, 88], [88, 89], [90, 97], [98, 103], [104, 107], [108, 116], [117, 122], [123, 125], [126, 134], [134, 135], [136, 139], [140, 145], [146, 149], [150, 160], [161, 162], [163, 165], [166, 170], [171, 173], [174, 182], [183, 186], [187, 202], [203, 205], [206, 210], [211, 213], [214, 216], [217, 220], [220, 221]]}
{"doc_key": "ai-dev-184", "ner": [[0, 0, "person"], [3, 3, "location"], [5, 5, "location"], [7, 7, "country"], [11, 11, "country"], [14, 15, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 3, 3, "physical", "", false, false], [3, 3, 5, 5, "physical", "", false, false], [5, 5, 7, 7, "physical", "", false, false], [5, 5, 11, 11, "physical", "", false, false], [5, 5, 14, 15, "physical", "", false, false], [11, 11, 7, 7, "origin", "", false, false], [14, 15, 11, 11, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["\u010capek", "naci\u00f3", "en", "Hronov", ",", "Bohemia", "(", "Austria-Hungr\u00eda", ",", "m\u00e1s", "tarde", "Checoslovaquia", ",", "ahora", "Rep\u00fablica", "Checa", ")", "en", "1887", "."], "sentence-detokenized": "\u010capek naci\u00f3 en Hronov, Bohemia (Austria-Hungr\u00eda, m\u00e1s tarde Checoslovaquia, ahora Rep\u00fablica Checa) en 1887.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 21], [21, 22], [23, 30], [31, 32], [32, 47], [47, 48], [49, 52], [53, 58], [59, 73], [73, 74], [75, 80], [81, 90], [91, 96], [96, 97], [98, 100], [101, 105], [105, 106]]}
{"doc_key": "ai-dev-185", "ner": [[6, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Algunos", "programas", "inform\u00e1ticos", "especializados", "pueden", "narrar", "el", "RSS", "."], "sentence-detokenized": "Algunos programas inform\u00e1ticos especializados pueden narrar el RSS.", "token2charspan": [[0, 7], [8, 17], [18, 30], [31, 45], [46, 52], [53, 59], [60, 62], [63, 66], [66, 67]]}
{"doc_key": "ai-dev-186", "ner": [[14, 15, "task"], [18, 20, "task"], [24, 25, "task"], [28, 28, "task"], [32, 34, "task"], [43, 46, "task"], [49, 51, "task"], [57, 57, "task"], [59, 59, "product"], [61, 62, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[14, 15, 18, 20, "related-to", "", true, false], [14, 15, 24, 25, "related-to", "", true, false], [14, 15, 28, 28, "related-to", "", true, false], [49, 51, 43, 46, "usage", "", true, false], [59, 59, 57, 57, "type-of", "", false, false], [61, 62, 57, 57, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Entre", "los", "aspectos", "de", "los", "editores", "de", "ontolog\u00edas", "se", "encuentran", ":", "las", "posibilidades", "de", "navegaci\u00f3n", "visual", "dentro", "del", "modelo", "de", "conocimiento", ",", "los", "motores", "de", "inferencia", "y", "la", "extracci\u00f3n", ";", "el", "apoyo", "a", "los", "m\u00f3dulos", ";", "la", "importaci\u00f3n", "y", "exportaci\u00f3n", "de", "lenguajes", "extranjeros", "de", "representaci\u00f3n", "del", "conocimiento", "para", "el", "cotejo", "de", "ontolog\u00edas", ";", "y", "el", "soporte", "de", "meta-ontolog\u00edas", "como", "OWL-S", ",", "Dublin", "Core", ",", "etc", "."], "sentence-detokenized": "Entre los aspectos de los editores de ontolog\u00edas se encuentran: las posibilidades de navegaci\u00f3n visual dentro del modelo de conocimiento, los motores de inferencia y la extracci\u00f3n; el apoyo a los m\u00f3dulos; la importaci\u00f3n y exportaci\u00f3n de lenguajes extranjeros de representaci\u00f3n del conocimiento para el cotejo de ontolog\u00edas; y el soporte de meta-ontolog\u00edas como OWL-S, Dublin Core, etc.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 21], [22, 25], [26, 34], [35, 37], [38, 48], [49, 51], [52, 62], [62, 63], [64, 67], [68, 81], [82, 84], [85, 95], [96, 102], [103, 109], [110, 113], [114, 120], [121, 123], [124, 136], [136, 137], [138, 141], [142, 149], [150, 152], [153, 163], [164, 165], [166, 168], [169, 179], [179, 180], [181, 183], [184, 189], [190, 191], [192, 195], [196, 203], [203, 204], [205, 207], [208, 219], [220, 221], [222, 233], [234, 236], [237, 246], [247, 258], [259, 261], [262, 276], [277, 280], [281, 293], [294, 298], [299, 301], [302, 308], [309, 311], [312, 322], [322, 323], [324, 325], [326, 328], [329, 336], [337, 339], [340, 355], [356, 360], [361, 366], [366, 367], [368, 374], [375, 379], [379, 380], [381, 384], [384, 385]]}
{"doc_key": "ai-dev-187", "ner": [[1, 1, "organisation"], [8, 13, "misc"], [17, 20, "task"], [23, 24, "field"], [29, 31, "misc"], [33, 36, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 13, 1, 1, "origin", "", false, false], [17, 20, 8, 13, "part-of", "", false, false], [23, 24, 8, 13, "part-of", "", false, false], [29, 31, 23, 24, "type-of", "", false, false], [33, 36, 23, 24, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["El", "FBI", "tambi\u00e9n", "ha", "puesto", "en", "marcha", "su", "programa", "de", "identificaci\u00f3n", "de", "nueva", "generaci\u00f3n", "para", "incluir", "el", "reconocimiento", "facial", ",", "adem\u00e1s", "de", "los", "datos", "biom\u00e9tricos", "m\u00e1s", "tradicionales", ",", "como", "las", "huellas", "dactilares", "y", "el", "esc\u00e1ner", "del", "iris", ",", "que", "pueden", "extraerse", "de", "las", "bases", "de", "datos", "penales", "y", "civiles", "."], "sentence-detokenized": "El FBI tambi\u00e9n ha puesto en marcha su programa de identificaci\u00f3n de nueva generaci\u00f3n para incluir el reconocimiento facial, adem\u00e1s de los datos biom\u00e9tricos m\u00e1s tradicionales, como las huellas dactilares y el esc\u00e1ner del iris, que pueden extraerse de las bases de datos penales y civiles.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 24], [25, 27], [28, 34], [35, 37], [38, 46], [47, 49], [50, 64], [65, 67], [68, 73], [74, 84], [85, 89], [90, 97], [98, 100], [101, 115], [116, 122], [122, 123], [124, 130], [131, 133], [134, 137], [138, 143], [144, 155], [156, 159], [160, 173], [173, 174], [175, 179], [180, 183], [184, 191], [192, 202], [203, 204], [205, 207], [208, 215], [216, 219], [220, 224], [224, 225], [226, 229], [230, 236], [237, 246], [247, 249], [250, 253], [254, 259], [260, 262], [263, 268], [269, 276], [277, 278], [279, 286], [286, 287]]}
{"doc_key": "ai-dev-188", "ner": [[8, 9, "person"], [16, 17, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Para", "la", "temporada", "2016", ",", "se", "a\u00f1adi\u00f3", "a", "Samantha", "Ponder", "como", "presentadora", ",", "en", "sustituci\u00f3n", "de", "Molly", "McGrath", "."], "sentence-detokenized": "Para la temporada 2016, se a\u00f1adi\u00f3 a Samantha Ponder como presentadora, en sustituci\u00f3n de Molly McGrath.", "token2charspan": [[0, 4], [5, 7], [8, 17], [18, 22], [22, 23], [24, 26], [27, 33], [34, 35], [36, 44], [45, 51], [52, 56], [57, 69], [69, 70], [71, 73], [74, 85], [86, 88], [89, 94], [95, 102], [102, 103]]}
{"doc_key": "ai-dev-189", "ner": [[4, 7, "algorithm"], [22, 24, "misc"], [26, 26, "misc"], [28, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Se", "trata", "de", "un", "algoritmo", "de", "b\u00fasqueda", "adversarial", "que", "se", "utiliza", "habitualmente", "para", "jugar", "a", "m\u00e1quina", "a", "juegos", "de", "dos", "jugadores", "(", "tres", "en", "raya", ",", "ajedrez", ",", "go", ",", "etc.", ")", "."], "sentence-detokenized": "Se trata de un algoritmo de b\u00fasqueda adversarial que se utiliza habitualmente para jugar a m\u00e1quina a juegos de dos jugadores (tres en raya, ajedrez, go, etc.).", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 14], [15, 24], [25, 27], [28, 36], [37, 48], [49, 52], [53, 55], [56, 63], [64, 77], [78, 82], [83, 88], [89, 90], [91, 98], [99, 100], [101, 107], [108, 110], [111, 114], [115, 124], [125, 126], [126, 130], [131, 133], [134, 138], [138, 139], [140, 147], [147, 148], [149, 151], [151, 152], [153, 157], [157, 158], [158, 159]]}
{"doc_key": "ai-dev-190", "ner": [[7, 9, "field"], [11, 12, "field"], [15, 16, "field"], [24, 26, "field"], [29, 30, "field"], [33, 35, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Se", "trata", "de", "los", "campos", "de", "la", "visi\u00f3n", "por", "ordenador", "o", "visi\u00f3n", "artificial", "y", "la", "imagen", "m\u00e9dica", ",", "y", "hace", "un", "uso", "intensivo", "del", "reconocimiento", "de", "patrones", ",", "la", "geometr\u00eda", "digital", "y", "el", "procesamiento", "de", "se\u00f1ales", "."], "sentence-detokenized": "Se trata de los campos de la visi\u00f3n por ordenador o visi\u00f3n artificial y la imagen m\u00e9dica, y hace un uso intensivo del reconocimiento de patrones, la geometr\u00eda digital y el procesamiento de se\u00f1ales.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 15], [16, 22], [23, 25], [26, 28], [29, 35], [36, 39], [40, 49], [50, 51], [52, 58], [59, 69], [70, 71], [72, 74], [75, 81], [82, 88], [88, 89], [90, 91], [92, 96], [97, 99], [100, 103], [104, 113], [114, 117], [118, 132], [133, 135], [136, 144], [144, 145], [146, 148], [149, 158], [159, 166], [167, 168], [169, 171], [172, 185], [186, 188], [189, 196], [196, 197]]}
{"doc_key": "ai-dev-191", "ner": [[2, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["En", "un", "sistema", "de", "reconocimiento", "facial", ",", "por", "ejemplo", ",", "la", "imagen", "de", "la", "cara", "de", "una", "persona", "ser\u00eda", "la", "entrada", ",", "y", "la", "etiqueta", "de", "salida", "ser\u00eda", "el", "nombre", "de", "esa", "persona", "."], "sentence-detokenized": "En un sistema de reconocimiento facial, por ejemplo, la imagen de la cara de una persona ser\u00eda la entrada, y la etiqueta de salida ser\u00eda el nombre de esa persona.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 31], [32, 38], [38, 39], [40, 43], [44, 51], [51, 52], [53, 55], [56, 62], [63, 65], [66, 68], [69, 73], [74, 76], [77, 80], [81, 88], [89, 94], [95, 97], [98, 105], [105, 106], [107, 108], [109, 111], [112, 120], [121, 123], [124, 130], [131, 136], [137, 139], [140, 146], [147, 149], [150, 153], [154, 161], [161, 162]]}
{"doc_key": "ai-dev-192", "ner": [[0, 1, "organisation"], [3, 4, "product"], [8, 9, "product"], [17, 18, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 3, 4, "artifact", "", false, false], [3, 4, 8, 9, "part-of", "", false, false], [8, 9, 3, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Apple", "Inc", "present\u00f3", "Face", "ID", "en", "el", "emblem\u00e1tico", "iPhone", "X", "como", "sucesor", "de", "la", "autenticaci\u00f3n", "biom\u00e9trica", "del", "Touch", "ID", ",", "un", "sistema", "basado", "en", "la", "huella", "dactilar", "."], "sentence-detokenized": "Apple Inc present\u00f3 Face ID en el emblem\u00e1tico iPhone X como sucesor de la autenticaci\u00f3n biom\u00e9trica del Touch ID, un sistema basado en la huella dactilar.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 23], [24, 26], [27, 29], [30, 32], [33, 44], [45, 51], [52, 53], [54, 58], [59, 66], [67, 69], [70, 72], [73, 86], [87, 97], [98, 101], [102, 107], [108, 110], [110, 111], [112, 114], [115, 122], [123, 129], [130, 132], [133, 135], [136, 142], [143, 151], [151, 152]]}
{"doc_key": "ai-dev-193", "ner": [[3, 4, "metrics"], [7, 7, "metrics"], [22, 24, "metrics"], [27, 29, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["O", "combinar", "la", "medida", "F", "con", "el", "R-cuadrado", "evaluado", "para", "la", "salida", "del", "modelo", "en", "bruto", "y", "el", "objetivo", ";", "o", "la", "matriz", "de", "coste/ganancia", "con", "el", "coeficiente", "de", "correlaci\u00f3n", ",", "etc", "."], "sentence-detokenized": "O combinar la medida F con el R-cuadrado evaluado para la salida del modelo en bruto y el objetivo; o la matriz de coste/ganancia con el coeficiente de correlaci\u00f3n, etc.", "token2charspan": [[0, 1], [2, 10], [11, 13], [14, 20], [21, 22], [23, 26], [27, 29], [30, 40], [41, 49], [50, 54], [55, 57], [58, 64], [65, 68], [69, 75], [76, 78], [79, 84], [85, 86], [87, 89], [90, 98], [98, 99], [100, 101], [102, 104], [105, 111], [112, 114], [115, 129], [130, 133], [134, 136], [137, 148], [149, 151], [152, 163], [163, 164], [165, 168], [168, 169]]}
{"doc_key": "ai-dev-194", "ner": [[1, 6, "conference"], [11, 13, "location"], [15, 15, "location"], [20, 23, "location"], [26, 26, "location"], [28, 28, "country"], [34, 38, "location"], [42, 48, "location"], [50, 52, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[1, 6, 11, 13, "physical", "", false, false], [1, 6, 20, 23, "physical", "", false, false], [1, 6, 34, 38, "physical", "", false, false], [1, 6, 42, 48, "physical", "", false, false], [11, 13, 15, 15, "physical", "", false, false], [20, 23, 26, 26, "physical", "", false, false], [26, 26, 28, 28, "physical", "", false, false], [34, 38, 50, 52, "physical", "", false, false], [42, 48, 50, 52, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["La", "edici\u00f3n", "espa\u00f1ola", "de", "Campus", "Party", "se", "ha", "celebrado", "en", "el", "Colegio", "Miguel", "Hern\u00e1ndez", ",", "Ceulaj", ",", "y", "en", "el", "Polideportivo", "Municipal", "de", "Benalm\u00e1dena", ",", "en", "M\u00e1laga", ",", "Espa\u00f1a", ";", "y", "tanto", "en", "la", "Feria", "del", "Condado", "de", "Valencia", "como", "en", "la", "Ciudad", "de", "las", "Artes", "y", "las", "Ciencias", "de", "Valencia", "en", "los", "\u00faltimos", "15", "a\u00f1os", "."], "sentence-detokenized": "La edici\u00f3n espa\u00f1ola de Campus Party se ha celebrado en el Colegio Miguel Hern\u00e1ndez, Ceulaj, y en el Polideportivo Municipal de Benalm\u00e1dena, en M\u00e1laga, Espa\u00f1a; y tanto en la Feria del Condado de Valencia como en la Ciudad de las Artes y las Ciencias de Valencia en los \u00faltimos 15 a\u00f1os.", "token2charspan": [[0, 2], [3, 10], [11, 19], [20, 22], [23, 29], [30, 35], [36, 38], [39, 41], [42, 51], [52, 54], [55, 57], [58, 65], [66, 72], [73, 82], [82, 83], [84, 90], [90, 91], [92, 93], [94, 96], [97, 99], [100, 113], [114, 123], [124, 126], [127, 138], [138, 139], [140, 142], [143, 149], [149, 150], [151, 157], [157, 158], [159, 160], [161, 166], [167, 169], [170, 172], [173, 178], [179, 182], [183, 190], [191, 193], [194, 202], [203, 207], [208, 210], [211, 213], [214, 220], [221, 223], [224, 227], [228, 233], [234, 235], [236, 239], [240, 248], [249, 251], [252, 260], [261, 263], [264, 267], [268, 275], [276, 278], [279, 283], [283, 284]]}
{"doc_key": "ai-dev-195", "ner": [[0, 0, "product"], [13, 13, "programlang"], [20, 20, "product"], [22, 22, "product"], [25, 25, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 13, 0, 0, "general-affiliation", "", false, false], [20, 20, 13, 13, "part-of", "", false, false], [22, 22, 13, 13, "part-of", "", false, false], [25, 25, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["gnuplot", "puede", "utilizarse", "desde", "varios", "lenguajes", "de", "programaci\u00f3n", "para", "graficar", "datos", ",", "incluyendo", "Perl", "(", "a", "trav\u00e9s", "de", "los", "paquetes", "PDL", "y", "CPAN", ")", ",", "Python", "(", "a", "trav\u00e9s", "de", ")", "."], "sentence-detokenized": "gnuplot puede utilizarse desde varios lenguajes de programaci\u00f3n para graficar datos, incluyendo Perl (a trav\u00e9s de los paquetes PDL y CPAN), Python (a trav\u00e9s de).", "token2charspan": [[0, 7], [8, 13], [14, 24], [25, 30], [31, 37], [38, 47], [48, 50], [51, 63], [64, 68], [69, 77], [78, 83], [83, 84], [85, 95], [96, 100], [101, 102], [102, 103], [104, 110], [111, 113], [114, 117], [118, 126], [127, 130], [131, 132], [133, 137], [137, 138], [138, 139], [140, 146], [147, 148], [148, 149], [150, 156], [157, 159], [159, 160], [160, 161]]}
{"doc_key": "ai-dev-196", "ner": [[3, 7, "product"], [21, 21, "conference"], [23, 23, "conference"], [36, 36, "conference"], [38, 38, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[21, 21, 3, 7, "topic", "", false, false], [23, 23, 3, 7, "topic", "", false, false], [36, 36, 3, 7, "topic", "", false, false], [38, 38, 3, 7, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["El", "campo", "de", "los", "sistemas", "de", "di\u00e1logo", "hablados", "es", "bastante", "amplio", "e", "incluye", "la", "investigaci\u00f3n", "(", "presente", "en", "conferencias", "cient\u00edficas", "como", "SIGdial", "e", "Interspeech", ")", "y", "un", "amplio", "sector", "industrial", "(", "con", "sus", "propias", "reuniones", "como", "SpeechTek", "y", "AVIOS", ")", "."], "sentence-detokenized": "El campo de los sistemas de di\u00e1logo hablados es bastante amplio e incluye la investigaci\u00f3n (presente en conferencias cient\u00edficas como SIGdial e Interspeech) y un amplio sector industrial (con sus propias reuniones como SpeechTek y AVIOS).", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 15], [16, 24], [25, 27], [28, 35], [36, 44], [45, 47], [48, 56], [57, 63], [64, 65], [66, 73], [74, 76], [77, 90], [91, 92], [92, 100], [101, 103], [104, 116], [117, 128], [129, 133], [134, 141], [142, 143], [144, 155], [155, 156], [157, 158], [159, 161], [162, 168], [169, 175], [176, 186], [187, 188], [188, 191], [192, 195], [196, 203], [204, 213], [214, 218], [219, 228], [229, 230], [231, 236], [236, 237], [237, 238]]}
{"doc_key": "ai-dev-197", "ner": [[4, 7, "field"], [11, 13, "task"], [16, 19, "task"], [22, 24, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 13, 4, 7, "part-of", "task_part_of_field", false, false], [16, 19, 4, 7, "part-of", "task_part_of_field", false, false], [22, 24, 4, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Los", "retos", "en", "el", "procesamiento", "del", "lenguaje", "natural", "suelen", "incluir", "el", "reconocimiento", "del", "habla", ",", "la", "comprensi\u00f3n", "del", "lenguaje", "natural", "y", "la", "generaci\u00f3n", "del", "mismo", "."], "sentence-detokenized": "Los retos en el procesamiento del lenguaje natural suelen incluir el reconocimiento del habla, la comprensi\u00f3n del lenguaje natural y la generaci\u00f3n del mismo.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 15], [16, 29], [30, 33], [34, 42], [43, 50], [51, 57], [58, 65], [66, 68], [69, 83], [84, 87], [88, 93], [93, 94], [95, 97], [98, 109], [110, 113], [114, 122], [123, 130], [131, 132], [133, 135], [136, 146], [147, 150], [151, 156], [156, 157]]}
{"doc_key": "ai-dev-198", "ner": [[4, 4, "product"], [6, 8, "product"], [42, 44, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 6, 8, "part-of", "", false, false], [4, 4, 42, 44, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Estos", "sistemas", ",", "como", "Siri", "del", "sistema", "operativo", "iOS", ",", "funcionan", "con", "una", "t\u00e9cnica", "de", "reconocimiento", "de", "patrones", "similar", "a", "la", "de", "los", "sistemas", "basados", "en", "texto", ",", "pero", "con", "los", "primeros", ",", "la", "entrada", "del", "usuario", "se", "realiza", "a", "trav\u00e9s", "del", "reconocimiento", "de", "voz", "."], "sentence-detokenized": "Estos sistemas, como Siri del sistema operativo iOS, funcionan con una t\u00e9cnica de reconocimiento de patrones similar a la de los sistemas basados en texto, pero con los primeros, la entrada del usuario se realiza a trav\u00e9s del reconocimiento de voz.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 20], [21, 25], [26, 29], [30, 37], [38, 47], [48, 51], [51, 52], [53, 62], [63, 66], [67, 70], [71, 78], [79, 81], [82, 96], [97, 99], [100, 108], [109, 116], [117, 118], [119, 121], [122, 124], [125, 128], [129, 137], [138, 145], [146, 148], [149, 154], [154, 155], [156, 160], [161, 164], [165, 168], [169, 177], [177, 178], [179, 181], [182, 189], [190, 193], [194, 201], [202, 204], [205, 212], [213, 214], [215, 221], [222, 225], [226, 240], [241, 243], [244, 247], [247, 248]]}
{"doc_key": "ai-dev-199", "ner": [[1, 5, "algorithm"], [17, 18, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 5, 17, 18, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Otras", "funciones", "de", "aptitud", "m\u00e1s", "ex\u00f3ticas", "que", "exploran", "la", "granularidad", "del", "modelo", "incluyen", "el", "\u00e1rea", "bajo", "la", "curva", "ROC", "y", "la", "medida", "de", "rango", "."], "sentence-detokenized": "Otras funciones de aptitud m\u00e1s ex\u00f3ticas que exploran la granularidad del modelo incluyen el \u00e1rea bajo la curva ROC y la medida de rango.", "token2charspan": [[0, 5], [6, 15], [16, 18], [19, 26], [27, 30], [31, 39], [40, 43], [44, 52], [53, 55], [56, 68], [69, 72], [73, 79], [80, 88], [89, 91], [92, 96], [97, 101], [102, 104], [105, 110], [111, 114], [115, 116], [117, 119], [120, 126], [127, 129], [130, 135], [135, 136]]}
{"doc_key": "ai-dev-200", "ner": [[2, 3, "product"], [7, 8, "researcher"], [13, 15, "product"], [19, 24, "organisation"], [26, 26, "organisation"], [34, 40, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 7, 8, "origin", "", false, false], [7, 8, 19, 24, "role", "", false, false], [13, 15, 7, 8, "origin", "", false, false], [26, 26, 19, 24, "named", "", false, false], [34, 40, 19, 24, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["El", "t\u00e9rmino", "web", "sem\u00e1ntica", "fue", "acu\u00f1ado", "por", "Tim", "Berners-Lee", ",", "inventor", "de", "la", "World", "Wide", "Web", "y", "director", "del", "Consorcio", "de", "la", "World", "Wide", "Web", "(", "W3C", ")", ",", "que", "supervisa", "el", "desarrollo", "de", "las", "normas", "propuestas", "para", "la", "web", "sem\u00e1ntica", "."], "sentence-detokenized": "El t\u00e9rmino web sem\u00e1ntica fue acu\u00f1ado por Tim Berners-Lee, inventor de la World Wide Web y director del Consorcio de la World Wide Web (W3C), que supervisa el desarrollo de las normas propuestas para la web sem\u00e1ntica.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 24], [25, 28], [29, 36], [37, 40], [41, 44], [45, 56], [56, 57], [58, 66], [67, 69], [70, 72], [73, 78], [79, 83], [84, 87], [88, 89], [90, 98], [99, 102], [103, 112], [113, 115], [116, 118], [119, 124], [125, 129], [130, 133], [134, 135], [135, 138], [138, 139], [139, 140], [141, 144], [145, 154], [155, 157], [158, 168], [169, 171], [172, 175], [176, 182], [183, 193], [194, 198], [199, 201], [202, 205], [206, 215], [215, 216]]}
{"doc_key": "ai-dev-201", "ner": [[0, 2, "task"], [10, 10, "task"], [18, 21, "product"], [24, 28, "product"], [30, 30, "product"], [34, 35, "product"], [43, 44, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 18, 21, "opposite", "", false, false], [0, 2, 24, 28, "opposite", "", false, false], [0, 2, 34, 35, "opposite", "", false, false], [0, 2, 43, 44, "part-of", "", false, false], [10, 10, 0, 2, "named", "", false, false], [30, 30, 24, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["La", "traducci\u00f3n", "autom\u00e1tica", ",", "a", "veces", "denominada", "por", "la", "abreviatura", "MT", "(", "que", "no", "debe", "confundirse", "con", "la", "traducci\u00f3n", "asistida", "por", "ordenador", ",", "la", "traducci\u00f3n", "humana", "asistida", "por", "m\u00e1quina", "(", "MAHT", ")", "o", "la", "traducci\u00f3n", "interactiva", ")", ",", "es", "un", "subcampo", "de", "la", "ling\u00fc\u00edstica", "computacional", "que", "investiga", "el", "uso", "de", "programas", "inform\u00e1ticos", "para", "traducir", "texto", "o", "voz", "de", "un", "idioma", "a", "otro", "."], "sentence-detokenized": "La traducci\u00f3n autom\u00e1tica, a veces denominada por la abreviatura MT (que no debe confundirse con la traducci\u00f3n asistida por ordenador, la traducci\u00f3n humana asistida por m\u00e1quina (MAHT) o la traducci\u00f3n interactiva), es un subcampo de la ling\u00fc\u00edstica computacional que investiga el uso de programas inform\u00e1ticos para traducir texto o voz de un idioma a otro.", "token2charspan": [[0, 2], [3, 13], [14, 24], [24, 25], [26, 27], [28, 33], [34, 44], [45, 48], [49, 51], [52, 63], [64, 66], [67, 68], [68, 71], [72, 74], [75, 79], [80, 91], [92, 95], [96, 98], [99, 109], [110, 118], [119, 122], [123, 132], [132, 133], [134, 136], [137, 147], [148, 154], [155, 163], [164, 167], [168, 175], [176, 177], [177, 181], [181, 182], [183, 184], [185, 187], [188, 198], [199, 210], [210, 211], [211, 212], [213, 215], [216, 218], [219, 227], [228, 230], [231, 233], [234, 245], [246, 259], [260, 263], [264, 273], [274, 276], [277, 280], [281, 283], [284, 293], [294, 306], [307, 311], [312, 320], [321, 326], [327, 328], [329, 332], [333, 335], [336, 338], [339, 345], [346, 347], [348, 352], [352, 353]]}
{"doc_key": "ai-dev-202", "ner": [[2, 6, "product"], [11, 13, "university"], [18, 19, "researcher"], [21, 22, "researcher"], [48, 51, "location"], [53, 53, "location"], [57, 61, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 6, 18, 19, "artifact", "", false, false], [2, 6, 21, 22, "artifact", "", false, false], [18, 19, 11, 13, "physical", "", false, false], [18, 19, 11, 13, "role", "", false, false], [21, 22, 11, 13, "physical", "", false, false], [21, 22, 11, 13, "role", "", false, false], [48, 51, 53, 53, "physical", "", false, false], [57, 61, 48, 51, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Los", "primeros", "sistemas", "de", "traducci\u00f3n", "autom\u00e1tica", "interling\u00fc\u00edstica", "tambi\u00e9n", "fueron", "construidos", "en", "Stanford", "en", "la", "d\u00e9cada", "de", "1970", "por", "Roger", "Schank", "y", "Yorick", "Wilks", ";", "el", "primero", "se", "convirti\u00f3", "en", "la", "base", "de", "un", "sistema", "comercial", "de", "transferencia", "de", "fondos", ",", "y", "el", "c\u00f3digo", "del", "segundo", "se", "conserva", "en", "el", "Museo", "de", "Inform\u00e1tica", "de", "Boston", "como", "el", "primer", "sistema", "de", "traducci\u00f3n", "autom\u00e1tica", "interling\u00fc\u00edstica", "."], "sentence-detokenized": "Los primeros sistemas de traducci\u00f3n autom\u00e1tica interling\u00fc\u00edstica tambi\u00e9n fueron construidos en Stanford en la d\u00e9cada de 1970 por Roger Schank y Yorick Wilks; el primero se convirti\u00f3 en la base de un sistema comercial de transferencia de fondos, y el c\u00f3digo del segundo se conserva en el Museo de Inform\u00e1tica de Boston como el primer sistema de traducci\u00f3n autom\u00e1tica interling\u00fc\u00edstica.", "token2charspan": [[0, 3], [4, 12], [13, 21], [22, 24], [25, 35], [36, 46], [47, 63], [64, 71], [72, 78], [79, 90], [91, 93], [94, 102], [103, 105], [106, 108], [109, 115], [116, 118], [119, 123], [124, 127], [128, 133], [134, 140], [141, 142], [143, 149], [150, 155], [155, 156], [157, 159], [160, 167], [168, 170], [171, 180], [181, 183], [184, 186], [187, 191], [192, 194], [195, 197], [198, 205], [206, 215], [216, 218], [219, 232], [233, 235], [236, 242], [242, 243], [244, 245], [246, 248], [249, 255], [256, 259], [260, 267], [268, 270], [271, 279], [280, 282], [283, 285], [286, 291], [292, 294], [295, 306], [307, 309], [310, 316], [317, 321], [322, 324], [325, 331], [332, 339], [340, 342], [343, 353], [354, 364], [365, 381], [381, 382]]}
{"doc_key": "ai-dev-203", "ner": [[0, 0, "researcher"], [7, 13, "conference"], [15, 16, "conference"], [23, 28, "conference"], [30, 31, "conference"], [36, 42, "organisation"], [51, 52, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 7, 13, "role", "", false, false], [0, 0, 23, 28, "role", "", false, false], [0, 0, 36, 42, "role", "", false, false], [0, 0, 51, 52, "role", "", false, false], [15, 16, 7, 13, "named", "", false, false], [30, 31, 23, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sycara", "fue", "presidente", "del", "programa", "de", "la", "Segunda", "Conferencia", "Internacional", "sobre", "la", "Web", "Sem\u00e1ntica", "(", "ISWC", "2003", ")", ";", "presidente", "general", "de", "la", "Segunda", "Conferencia", "Internacional", "sobre", "Agentes", "Aut\u00f3nomos", "(", "Agents", "98", ")", ";", "presidente", "del", "Comit\u00e9", "Directivo", "de", "la", "Conferencia", "sobre", "Agentes", "(", "1999-2001", ")", ";", "presidente", "de", "becas", "de", "la", "AAAI", "(", "1993-1999", ")", ";"], "sentence-detokenized": "Sycara fue presidente del programa de la Segunda Conferencia Internacional sobre la Web Sem\u00e1ntica (ISWC 2003); presidente general de la Segunda Conferencia Internacional sobre Agentes Aut\u00f3nomos (Agents 98); presidente del Comit\u00e9 Directivo de la Conferencia sobre Agentes (1999-2001); presidente de becas de la AAAI (1993-1999);", "token2charspan": [[0, 6], [7, 10], [11, 21], [22, 25], [26, 34], [35, 37], [38, 40], [41, 48], [49, 60], [61, 74], [75, 80], [81, 83], [84, 87], [88, 97], [98, 99], [99, 103], [104, 108], [108, 109], [109, 110], [111, 121], [122, 129], [130, 132], [133, 135], [136, 143], [144, 155], [156, 169], [170, 175], [176, 183], [184, 193], [194, 195], [195, 201], [202, 204], [204, 205], [205, 206], [207, 217], [218, 221], [222, 228], [229, 238], [239, 241], [242, 244], [245, 256], [257, 262], [263, 270], [271, 272], [272, 281], [281, 282], [282, 283], [284, 294], [295, 297], [298, 303], [304, 306], [307, 309], [310, 314], [315, 316], [316, 325], [325, 326], [326, 327]]}
{"doc_key": "ai-dev-204", "ner": [[12, 13, "conference"], [15, 18, "conference"], [8, 11, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 18, 12, 13, "named", "", false, false], [8, 11, 12, 13, "part-of", "", false, false], [8, 11, 12, 13, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["En", "2016", ",", "fue", "seleccionada", "como", "ganadora", "del", "premio", "Lifetime", "Achievement", "de", "la", "ACL", "(", "Asociaci\u00f3n", "de", "Ling\u00fc\u00edstica", "Computacional", ")", "."], "sentence-detokenized": "En 2016, fue seleccionada como ganadora del premio Lifetime Achievement de la ACL (Asociaci\u00f3n de Ling\u00fc\u00edstica Computacional).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 25], [26, 30], [31, 39], [40, 43], [44, 50], [51, 59], [60, 71], [72, 74], [75, 77], [78, 81], [82, 83], [83, 93], [94, 96], [97, 108], [109, 122], [122, 123], [123, 124]]}
{"doc_key": "ai-dev-205", "ner": [[0, 1, "researcher"], [3, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sepp", "Hochreiter", ",", "Y", ".", "Bengio", ",", "P.", "Frasconi", "y", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Sepp Hochreiter, Y. Bengio, P. Frasconi y J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 15], [15, 16], [17, 18], [18, 19], [20, 26], [26, 27], [28, 30], [31, 39], [40, 41], [42, 48], [49, 60], [60, 61]]}
{"doc_key": "ai-dev-206", "ner": [[3, 3, "product"], [6, 8, "misc"], [10, 10, "programlang"], [19, 21, "product"], [37, 37, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 10, 10, "usage", "", false, false], [10, 10, 6, 8, "type-of", "", false, false], [10, 10, 19, 21, "related-to", "", false, false], [37, 37, 3, 3, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Por", "ejemplo", ",", "A.L.I.C.E.", "utiliza", "un", "lenguaje", "de", "marcado", "llamado", "AIML", ",", "que", "es", "espec\u00edfico", "para", "su", "funci\u00f3n", "como", "sistema", "de", "di\u00e1logo", ",", "y", "que", "desde", "entonces", "ha", "sido", "adoptado", "por", "varios", "otros", "desarrolladores", "de", "los", "llamados", "Alicebots", "."], "sentence-detokenized": "Por ejemplo, A.L.I.C.E. utiliza un lenguaje de marcado llamado AIML, que es espec\u00edfico para su funci\u00f3n como sistema de di\u00e1logo, y que desde entonces ha sido adoptado por varios otros desarrolladores de los llamados Alicebots.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 23], [24, 31], [32, 34], [35, 43], [44, 46], [47, 54], [55, 62], [63, 67], [67, 68], [69, 72], [73, 75], [76, 86], [87, 91], [92, 94], [95, 102], [103, 107], [108, 115], [116, 118], [119, 126], [126, 127], [128, 129], [130, 133], [134, 139], [140, 148], [149, 151], [152, 156], [157, 165], [166, 169], [170, 176], [177, 182], [183, 198], [199, 201], [202, 205], [206, 214], [215, 224], [224, 225]]}
{"doc_key": "ai-dev-207", "ner": [[7, 14, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["En", "2000", "fue", "elegida", "miembro", "de", "la", "Asociaci\u00f3n", "para", "el", "Avance", "de", "la", "Inteligencia", "Artificial", "."], "sentence-detokenized": "En 2000 fue elegida miembro de la Asociaci\u00f3n para el Avance de la Inteligencia Artificial.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 19], [20, 27], [28, 30], [31, 33], [34, 44], [45, 49], [50, 52], [53, 59], [60, 62], [63, 65], [66, 78], [79, 89], [89, 90]]}
{"doc_key": "ai-dev-208", "ner": [[0, 4, "misc"], [6, 6, "misc"], [12, 18, "misc"], [28, 29, "algorithm"], [40, 41, "field"], [44, 46, "field"], [49, 51, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 4, 12, 18, "type-of", "", false, false], [0, 4, 40, 41, "related-to", "performs", true, false], [0, 4, 44, 46, "related-to", "performs", true, false], [0, 4, 49, 51, "related-to", "performs", true, false], [6, 6, 0, 4, "named", "", false, false], [28, 29, 12, 18, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Los", "sistemas", "clasificadores", "de", "aprendizaje", "(", "LCS", ")", "son", "una", "familia", "de", "algoritmos", "de", "aprendizaje", "autom\u00e1tico", "basados", "en", "reglas", "que", "combinan", "un", "componente", "de", "descubrimiento", ",", "normalmente", "un", "algoritmo", "gen\u00e9tico", ",", "con", "un", "componente", "de", "aprendizaje", ",", "que", "realiza", "un", "aprendizaje", "supervisado", ",", "un", "aprendizaje", "de", "refuerzo", "o", "un", "aprendizaje", "no", "supervisado", "."], "sentence-detokenized": "Los sistemas clasificadores de aprendizaje (LCS) son una familia de algoritmos de aprendizaje autom\u00e1tico basados en reglas que combinan un componente de descubrimiento, normalmente un algoritmo gen\u00e9tico, con un componente de aprendizaje, que realiza un aprendizaje supervisado, un aprendizaje de refuerzo o un aprendizaje no supervisado.", "token2charspan": [[0, 3], [4, 12], [13, 27], [28, 30], [31, 42], [43, 44], [44, 47], [47, 48], [49, 52], [53, 56], [57, 64], [65, 67], [68, 78], [79, 81], [82, 93], [94, 104], [105, 112], [113, 115], [116, 122], [123, 126], [127, 135], [136, 138], [139, 149], [150, 152], [153, 167], [167, 168], [169, 180], [181, 183], [184, 193], [194, 202], [202, 203], [204, 207], [208, 210], [211, 221], [222, 224], [225, 236], [236, 237], [238, 241], [242, 249], [250, 252], [253, 264], [265, 276], [276, 277], [278, 280], [281, 292], [293, 295], [296, 304], [305, 306], [307, 309], [310, 321], [322, 324], [325, 336], [336, 337]]}
{"doc_key": "ai-dev-209", "ner": [[15, 17, "algorithm"], [19, 19, "algorithm"], [28, 29, "algorithm"], [33, 33, "misc"], [44, 47, "algorithm"], [54, 59, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[15, 17, 28, 29, "origin", "", false, false], [15, 17, 33, 33, "usage", "", false, false], [19, 19, 15, 17, "named", "", false, false], [44, 47, 33, 33, "type-of", "", false, false], [44, 47, 54, 59, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Los", "par\u00e1metros", "desconocidos", "en", "cada", "vector", "\u03b2subk", "/", "sub", "se", "suelen", "estimar", "conjuntamente", "por", "estimaci\u00f3n", "m\u00e1xima", "a", "posteriori", "(", "MAP", ")", ",", "que", "es", "una", "extensi\u00f3n", "de", "la", "m\u00e1xima", "verosimilitud", "que", "utiliza", "la", "regularizaci\u00f3n", "de", "los", "pesos", "para", "evitar", "soluciones", "patol\u00f3gicas", "(", "normalmente", "una", "funci\u00f3n", "regularizadora", "al", "cuadrado", ",", "que", "equivale", "a", "colocar", "una", "distribuci\u00f3n", "previa", "gaussiana", "de", "media", "cero", "en", "los", "pesos", ",", "pero", "tambi\u00e9n", "son", "posibles", "otras", "distribuciones", ")", "."], "sentence-detokenized": "Los par\u00e1metros desconocidos en cada vector \u03b2subk / sub se suelen estimar conjuntamente por estimaci\u00f3n m\u00e1xima a posteriori (MAP), que es una extensi\u00f3n de la m\u00e1xima verosimilitud que utiliza la regularizaci\u00f3n de los pesos para evitar soluciones patol\u00f3gicas (normalmente una funci\u00f3n regularizadora al cuadrado, que equivale a colocar una distribuci\u00f3n previa gaussiana de media cero en los pesos, pero tambi\u00e9n son posibles otras distribuciones).", "token2charspan": [[0, 3], [4, 14], [15, 27], [28, 30], [31, 35], [36, 42], [43, 48], [49, 50], [51, 54], [55, 57], [58, 64], [65, 72], [73, 86], [87, 90], [91, 101], [102, 108], [109, 110], [111, 121], [122, 123], [123, 126], [126, 127], [127, 128], [129, 132], [133, 135], [136, 139], [140, 149], [150, 152], [153, 155], [156, 162], [163, 176], [177, 180], [181, 188], [189, 191], [192, 206], [207, 209], [210, 213], [214, 219], [220, 224], [225, 231], [232, 242], [243, 254], [255, 256], [256, 267], [268, 271], [272, 279], [280, 294], [295, 297], [298, 306], [306, 307], [308, 311], [312, 320], [321, 322], [323, 330], [331, 334], [335, 347], [348, 354], [355, 364], [365, 367], [368, 373], [374, 378], [379, 381], [382, 385], [386, 391], [391, 392], [393, 397], [398, 405], [406, 409], [410, 418], [419, 424], [425, 439], [439, 440], [440, 441]]}
{"doc_key": "ai-dev-210", "ner": [[14, 15, "researcher"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 12, 14, 15, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["La", "estructura", "jer\u00e1rquica", "de", "las", "palabras", "ha", "sido", "expl\u00edcitamente", "mapeada", "en", "la", "Wordnet", "de", "George", "Miller", "."], "sentence-detokenized": "La estructura jer\u00e1rquica de las palabras ha sido expl\u00edcitamente mapeada en la Wordnet de George Miller.", "token2charspan": [[0, 2], [3, 13], [14, 24], [25, 27], [28, 31], [32, 40], [41, 43], [44, 48], [49, 63], [64, 71], [72, 74], [75, 77], [78, 85], [86, 88], [89, 95], [96, 102], [102, 103]]}
{"doc_key": "ai-dev-211", "ner": [[7, 15, "conference"], [24, 28, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[24, 28, 7, 15, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Un", "ejemplo", "de", "sus", "capacidades", "es", "el", "reto", "de", "reconocimiento", "visual", "a", "gran", "escala", "de", "ImageNet", ";", "se", "trata", "de", "una", "referencia", "en", "la", "clasificaci\u00f3n", "y", "detecci\u00f3n", "de", "objetos", ",", "con", "millones", "de", "im\u00e1genes", "y", "cientos", "de", "clases", "de", "objetos", "."], "sentence-detokenized": "Un ejemplo de sus capacidades es el reto de reconocimiento visual a gran escala de ImageNet; se trata de una referencia en la clasificaci\u00f3n y detecci\u00f3n de objetos, con millones de im\u00e1genes y cientos de clases de objetos.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 17], [18, 29], [30, 32], [33, 35], [36, 40], [41, 43], [44, 58], [59, 65], [66, 67], [68, 72], [73, 79], [80, 82], [83, 91], [91, 92], [93, 95], [96, 101], [102, 104], [105, 108], [109, 119], [120, 122], [123, 125], [126, 139], [140, 141], [142, 151], [152, 154], [155, 162], [162, 163], [164, 167], [168, 176], [177, 179], [180, 188], [189, 190], [191, 198], [199, 201], [202, 208], [209, 211], [212, 219], [219, 220]]}
{"doc_key": "ai-dev-212", "ner": [[2, 5, "misc"], [30, 30, "misc"], [35, 37, "person"], [38, 38, "misc"], [46, 47, "person"], [49, 50, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[30, 30, 2, 5, "general-affiliation", "", false, false], [38, 38, 2, 5, "general-affiliation", "", false, false], [38, 38, 35, 37, "artifact", "", false, false], [49, 50, 2, 5, "general-affiliation", "", false, false], [49, 50, 46, 47, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["En", "la", "ciencia", "ficci\u00f3n", ",", "los", "robots", "con", "apariencia", "femenina", "se", "producen", "a", "menudo", "para", "ser", "utilizados", "como", "sirvientes", "dom\u00e9sticos", "y", "esclavos", "sexuales", ",", "como", "se", "ve", "en", "la", "pel\u00edcula", "Westworld", ",", "la", "novela", "de", "Paul", "J.", "McAuley", "Fairyland", "(", "1995", ")", "y", "el", "cuento", "de", "Lester", "del", "Rey", "Helen", "O'Loy", "(", "1938", ")", ",", "y", "a", "veces", "como", "guerreros", ",", "asesinos", "o", "trabajadores", "."], "sentence-detokenized": "En la ciencia ficci\u00f3n, los robots con apariencia femenina se producen a menudo para ser utilizados como sirvientes dom\u00e9sticos y esclavos sexuales, como se ve en la pel\u00edcula Westworld, la novela de Paul J. McAuley Fairyland (1995) y el cuento de Lester del Rey Helen O'Loy (1938), y a veces como guerreros, asesinos o trabajadores.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 21], [21, 22], [23, 26], [27, 33], [34, 37], [38, 48], [49, 57], [58, 60], [61, 69], [70, 71], [72, 78], [79, 83], [84, 87], [88, 98], [99, 103], [104, 114], [115, 125], [126, 127], [128, 136], [137, 145], [145, 146], [147, 151], [152, 154], [155, 157], [158, 160], [161, 163], [164, 172], [173, 182], [182, 183], [184, 186], [187, 193], [194, 196], [197, 201], [202, 204], [205, 212], [213, 222], [223, 224], [224, 228], [228, 229], [230, 231], [232, 234], [235, 241], [242, 244], [245, 251], [252, 255], [256, 259], [260, 265], [266, 271], [272, 273], [273, 277], [277, 278], [278, 279], [280, 281], [282, 283], [284, 289], [290, 294], [295, 304], [304, 305], [306, 314], [315, 316], [317, 329], [329, 330]]}
{"doc_key": "ai-dev-213", "ner": [[0, 2, "task"], [4, 6, "task"], [8, 9, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["respuesta", "a", "preguntas", ",", "reconocimiento", "de", "voz", "y", "traducci\u00f3n", "autom\u00e1tica", "."], "sentence-detokenized": "respuesta a preguntas, reconocimiento de voz y traducci\u00f3n autom\u00e1tica.", "token2charspan": [[0, 9], [10, 11], [12, 21], [21, 22], [23, 37], [38, 40], [41, 44], [45, 46], [47, 57], [58, 68], [68, 69]]}
{"doc_key": "ai-dev-214", "ner": [[5, 6, "researcher"], [10, 17, "organisation"], [20, 22, "location"], [25, 25, "location"], [27, 27, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 10, 17, "role", "", false, false], [10, 17, 20, 22, "physical", "", false, false], [20, 22, 25, 25, "physical", "", false, false], [25, 25, 27, 27, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["En", "su", "art\u00edculo", "seminal", ",", "Harry", "Blum", ",", "de", "los", "Laboratorios", "de", "Investigaci\u00f3n", "Cambridge", "de", "la", "Fuerza", "A\u00e9rea", "en", "la", "Base", "A\u00e9rea", "Hanscom", ",", "en", "Bedford", "(", "Massachusetts", ")", ",", "defini\u00f3", "un", "eje", "medial", "para", "calcular", "el", "esqueleto", "de", "una", "forma", ",", "utilizando", "un", "modelo", "intuitivo", "de", "propagaci\u00f3n", "del", "fuego", "en", "un", "campo", "de", "hierba", ",", "donde", "el", "campo", "tiene", "la", "forma", "de", "la", "forma", "dada", "."], "sentence-detokenized": "En su art\u00edculo seminal, Harry Blum, de los Laboratorios de Investigaci\u00f3n Cambridge de la Fuerza A\u00e9rea en la Base A\u00e9rea Hanscom, en Bedford (Massachusetts), defini\u00f3 un eje medial para calcular el esqueleto de una forma, utilizando un modelo intuitivo de propagaci\u00f3n del fuego en un campo de hierba, donde el campo tiene la forma de la forma dada.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 22], [22, 23], [24, 29], [30, 34], [34, 35], [36, 38], [39, 42], [43, 55], [56, 58], [59, 72], [73, 82], [83, 85], [86, 88], [89, 95], [96, 101], [102, 104], [105, 107], [108, 112], [113, 118], [119, 126], [126, 127], [128, 130], [131, 138], [139, 140], [140, 153], [153, 154], [154, 155], [156, 163], [164, 166], [167, 170], [171, 177], [178, 182], [183, 191], [192, 194], [195, 204], [205, 207], [208, 211], [212, 217], [217, 218], [219, 229], [230, 232], [233, 239], [240, 249], [250, 252], [253, 264], [265, 268], [269, 274], [275, 277], [278, 280], [281, 286], [287, 289], [290, 296], [296, 297], [298, 303], [304, 306], [307, 312], [313, 318], [319, 321], [322, 327], [328, 330], [331, 333], [334, 339], [340, 344], [344, 345]]}
{"doc_key": "ai-dev-215", "ner": [[22, 22, "algorithm"], [24, 24, "algorithm"], [27, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 22, 27, 27, "compare", "", false, false], [24, 24, 27, 27, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Sin", "embargo", ",", "a", "diferencia", "de", "los", "algoritmos", "de", "refuerzo", "que", "minimizan", "anal\u00edticamente", "una", "funci\u00f3n", "de", "p\u00e9rdida", "convexa", "(", "por", "ejemplo", ",", "AdaBoost", "y", "LogitBoost", ")", ",", "BrownBoost", "resuelve", "un", "sistema", "de", "dos", "ecuaciones", "y", "dos", "inc\u00f3gnitas", "utilizando", "m\u00e9todos", "num\u00e9ricos", "est\u00e1ndar", "."], "sentence-detokenized": "Sin embargo, a diferencia de los algoritmos de refuerzo que minimizan anal\u00edticamente una funci\u00f3n de p\u00e9rdida convexa (por ejemplo, AdaBoost y LogitBoost), BrownBoost resuelve un sistema de dos ecuaciones y dos inc\u00f3gnitas utilizando m\u00e9todos num\u00e9ricos est\u00e1ndar.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 14], [15, 25], [26, 28], [29, 32], [33, 43], [44, 46], [47, 55], [56, 59], [60, 69], [70, 84], [85, 88], [89, 96], [97, 99], [100, 107], [108, 115], [116, 117], [117, 120], [121, 128], [128, 129], [130, 138], [139, 140], [141, 151], [151, 152], [152, 153], [154, 164], [165, 173], [174, 176], [177, 184], [185, 187], [188, 191], [192, 202], [203, 204], [205, 208], [209, 219], [220, 230], [231, 238], [239, 248], [249, 257], [257, 258]]}
{"doc_key": "ai-dev-216", "ner": [[0, 0, "researcher"], [10, 16, "misc"], [22, 29, "conference"], [31, 31, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 10, 16, "win-defeat", "", false, false], [0, 0, 22, 29, "role", "", false, false], [31, 31, 22, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Getoor", "ha", "recibido", "varios", "premios", "al", "mejor", "art\u00edculo", ",", "un", "premio", "a", "la", "carrera", "de", "la", "NSF", "y", "es", "miembro", "de", "la", "Asociaci\u00f3n", "para", "el", "Avance", "de", "la", "Inteligencia", "Artificial", "(", "AAAI", ")", "."], "sentence-detokenized": "Getoor ha recibido varios premios al mejor art\u00edculo, un premio a la carrera de la NSF y es miembro de la Asociaci\u00f3n para el Avance de la Inteligencia Artificial (AAAI).", "token2charspan": [[0, 6], [7, 9], [10, 18], [19, 25], [26, 33], [34, 36], [37, 42], [43, 51], [51, 52], [53, 55], [56, 62], [63, 64], [65, 67], [68, 75], [76, 78], [79, 81], [82, 85], [86, 87], [88, 90], [91, 98], [99, 101], [102, 104], [105, 115], [116, 120], [121, 123], [124, 130], [131, 133], [134, 136], [137, 149], [150, 160], [161, 162], [162, 166], [166, 167], [167, 168]]}
{"doc_key": "ai-dev-217", "ner": [[0, 3, "misc"], [8, 14, "misc"], [19, 22, "misc"], [27, 35, "misc"], [40, 41, "misc"], [46, 50, "university"], [55, 66, "misc"], [71, 82, "misc"], [87, 91, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Miembro", "de", "la", "ACM", "(", "2015", ")", "br", "Miembro", "de", "la", "Asociaci\u00f3n", "de", "Ling\u00fc\u00edstica", "Computacional", "(", "2011", ")", "br", "Miembro", "de", "la", "AAAI", "(", "1994", ")", "br", "Miembro", "de", "la", "Asociaci\u00f3n", "Internacional", "de", "Comunicaci\u00f3n", "del", "Habla", "(", "2011", ")", "br", "Doctorado", "Honoris", "Causa", "(", "Hedersdoktor", ")", "KTH", "Royal", "Institute", "of", "Technology", "(", "2007", ")", "br", "Premio", "a", "la", "Ense\u00f1anza", "Distinguida", "de", "la", "Facultad", "de", "Ingenier\u00eda", "de", "Columbia", "(", "2009", ")", "br", "Premio", "IEEE", "James", "L.", "Flanagan", "al", "Procesamiento", "del", "Habla", "y", "el", "Audio", "(", "2011", ")", "br", "Medalla", "ISCA", "al", "Logro", "Cient\u00edfico", "(", "2011", ")"], "sentence-detokenized": "Miembro de la ACM (2015) br Miembro de la Asociaci\u00f3n de Ling\u00fc\u00edstica Computacional (2011) br Miembro de la AAAI (1994) br Miembro de la Asociaci\u00f3n Internacional de Comunicaci\u00f3n del Habla (2011) br Doctorado Honoris Causa (Hedersdoktor) KTH Royal Institute of Technology (2007) br Premio a la Ense\u00f1anza Distinguida de la Facultad de Ingenier\u00eda de Columbia (2009) br Premio IEEE James L. Flanagan al Procesamiento del Habla y el Audio (2011) br Medalla ISCA al Logro Cient\u00edfico (2011)", "token2charspan": [[0, 7], [8, 10], [11, 13], [14, 17], [18, 19], [19, 23], [23, 24], [25, 27], [28, 35], [36, 38], [39, 41], [42, 52], [53, 55], [56, 67], [68, 81], [82, 83], [83, 87], [87, 88], [89, 91], [92, 99], [100, 102], [103, 105], [106, 110], [111, 112], [112, 116], [116, 117], [118, 120], [121, 128], [129, 131], [132, 134], [135, 145], [146, 159], [160, 162], [163, 175], [176, 179], [180, 185], [186, 187], [187, 191], [191, 192], [193, 195], [196, 205], [206, 213], [214, 219], [220, 221], [221, 233], [233, 234], [235, 238], [239, 244], [245, 254], [255, 257], [258, 268], [269, 270], [270, 274], [274, 275], [276, 278], [279, 285], [286, 287], [288, 290], [291, 300], [301, 312], [313, 315], [316, 318], [319, 327], [328, 330], [331, 341], [342, 344], [345, 353], [354, 355], [355, 359], [359, 360], [361, 363], [364, 370], [371, 375], [376, 381], [382, 384], [385, 393], [394, 396], [397, 410], [411, 414], [415, 420], [421, 422], [423, 425], [426, 431], [432, 433], [433, 437], [437, 438], [439, 441], [442, 449], [450, 454], [455, 457], [458, 463], [464, 474], [475, 476], [476, 480], [480, 481]]}
{"doc_key": "ai-dev-218", "ner": [[7, 7, "university"], [18, 20, "task"], [46, 47, "metrics"], [33, 38, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[46, 47, 33, 38, "opposite", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Un", "resultado", "frustrante", "del", "mismo", "estudio", "de", "Stanford", "(", "y", "de", "otros", "intentos", "de", "mejorar", "la", "traducci\u00f3n", "de", "reconocimiento", "de", "nombres", ")", "es", "que", "muchas", "veces", ",", "la", "inclusi\u00f3n", "de", "m\u00e9todos", "para", "la", "traducci\u00f3n", "de", "entidades", "con", "nombre", "provoca", "una", "disminuci\u00f3n", "en", "las", "puntuaciones", "de", "la", "evaluaci\u00f3n", "biling\u00fce", "de", "la", "traducci\u00f3n", "."], "sentence-detokenized": "Un resultado frustrante del mismo estudio de Stanford (y de otros intentos de mejorar la traducci\u00f3n de reconocimiento de nombres) es que muchas veces, la inclusi\u00f3n de m\u00e9todos para la traducci\u00f3n de entidades con nombre provoca una disminuci\u00f3n en las puntuaciones de la evaluaci\u00f3n biling\u00fce de la traducci\u00f3n.", "token2charspan": [[0, 2], [3, 12], [13, 23], [24, 27], [28, 33], [34, 41], [42, 44], [45, 53], [54, 55], [55, 56], [57, 59], [60, 65], [66, 74], [75, 77], [78, 85], [86, 88], [89, 99], [100, 102], [103, 117], [118, 120], [121, 128], [128, 129], [130, 132], [133, 136], [137, 143], [144, 149], [149, 150], [151, 153], [154, 163], [164, 166], [167, 174], [175, 179], [180, 182], [183, 193], [194, 196], [197, 206], [207, 210], [211, 217], [218, 225], [226, 229], [230, 241], [242, 244], [245, 248], [249, 261], [262, 264], [265, 267], [268, 278], [279, 287], [288, 290], [291, 293], [294, 304], [304, 305]]}
{"doc_key": "ai-dev-219", "ner": [[0, 0, "organisation"], [14, 17, "organisation"], [21, 29, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 14, 17, "role", "works_with", false, false], [0, 0, 21, 29, "role", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Medtronic", "est\u00e1", "utilizando", "los", "datos", "recogidos", "de", "la", "PM", "y", "est\u00e1", "colaborando", "con", "investigadores", "del", "Hospital", "Johns", "Hopkins", "y", "de", "la", "Facultad", "de", "Medicina", "de", "la", "Universidad", "de", "Washington", "para", "ayudar", "a", "responder", "a", "preguntas", "concretas", "sobre", "las", "enfermedades", "card\u00edacas", ",", "como", "por", "ejemplo", "si", "los", "corazones", "d\u00e9biles", "provocan", "arritmias", "o", "viceversa", "."], "sentence-detokenized": "Medtronic est\u00e1 utilizando los datos recogidos de la PM y est\u00e1 colaborando con investigadores del Hospital Johns Hopkins y de la Facultad de Medicina de la Universidad de Washington para ayudar a responder a preguntas concretas sobre las enfermedades card\u00edacas, como por ejemplo si los corazones d\u00e9biles provocan arritmias o viceversa.", "token2charspan": [[0, 9], [10, 14], [15, 25], [26, 29], [30, 35], [36, 45], [46, 48], [49, 51], [52, 54], [55, 56], [57, 61], [62, 73], [74, 77], [78, 92], [93, 96], [97, 105], [106, 111], [112, 119], [120, 121], [122, 124], [125, 127], [128, 136], [137, 139], [140, 148], [149, 151], [152, 154], [155, 166], [167, 169], [170, 180], [181, 185], [186, 192], [193, 194], [195, 204], [205, 206], [207, 216], [217, 226], [227, 232], [233, 236], [237, 249], [250, 259], [259, 260], [261, 265], [266, 269], [270, 277], [278, 280], [281, 284], [285, 294], [295, 302], [303, 311], [312, 321], [322, 323], [324, 333], [333, 334]]}
{"doc_key": "ai-dev-220", "ner": [[7, 7, "organisation"], [9, 9, "misc"], [12, 13, "person"], [15, 16, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 7, 7, "artifact", "made_by_studio", false, false], [12, 13, 9, 9, "role", "", false, false], [15, 16, 9, 9, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "continuaci\u00f3n", "lleg\u00f3", "el", "primer", "largometraje", "de", "Paramount", ",", "Sangaree", ",", "con", "Fernando", "Lamas", "y", "Arlene", "Dahl", "."], "sentence-detokenized": "A continuaci\u00f3n lleg\u00f3 el primer largometraje de Paramount, Sangaree, con Fernando Lamas y Arlene Dahl.", "token2charspan": [[0, 1], [2, 14], [15, 20], [21, 23], [24, 30], [31, 43], [44, 46], [47, 56], [56, 57], [58, 66], [66, 67], [68, 71], [72, 80], [81, 86], [87, 88], [89, 95], [96, 100], [100, 101]]}
{"doc_key": "ai-dev-221", "ner": [[0, 0, "programlang"], [11, 13, "researcher"], [15, 16, "researcher"], [20, 22, "organisation"], [25, 28, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 11, 13, "origin", "", false, false], [0, 0, 15, 16, "origin", "", false, false], [11, 13, 20, 22, "physical", "", false, false], [11, 13, 20, 22, "role", "", false, false], [15, 16, 25, 28, "physical", "", false, false], [15, 16, 25, 28, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["KRL", "es", "un", "lenguaje", "de", "representaci\u00f3n", "del", "conocimiento", ",", "desarrollado", "por", "Daniel", "G.", "Bobrow", "y", "Terry", "Winograd", "cuando", "trabajaban", "en", "el", "Xerox", "PARC", "y", "en", "la", "Universidad", "de", "Stanford", ",", "respectivamente", "."], "sentence-detokenized": "KRL es un lenguaje de representaci\u00f3n del conocimiento, desarrollado por Daniel G. Bobrow y Terry Winograd cuando trabajaban en el Xerox PARC y en la Universidad de Stanford, respectivamente.", "token2charspan": [[0, 3], [4, 6], [7, 9], [10, 18], [19, 21], [22, 36], [37, 40], [41, 53], [53, 54], [55, 67], [68, 71], [72, 78], [79, 81], [82, 88], [89, 90], [91, 96], [97, 105], [106, 112], [113, 123], [124, 126], [127, 129], [130, 135], [136, 140], [141, 142], [143, 145], [146, 148], [149, 160], [161, 163], [164, 172], [172, 173], [174, 189], [189, 190]]}
{"doc_key": "ai-dev-222", "ner": [[2, 12, "conference"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 23, "researcher"], [25, 26, "researcher"], [34, 36, "task"], [38, 41, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 12, 34, 36, "topic", "", true, false], [16, 17, 2, 12, "physical", "", false, false], [16, 17, 2, 12, "role", "", false, false], [16, 17, 2, 12, "temporal", "", false, false], [19, 20, 2, 12, "physical", "", false, false], [19, 20, 2, 12, "role", "", false, false], [19, 20, 2, 12, "temporal", "", false, false], [22, 23, 2, 12, "physical", "", false, false], [22, 23, 2, 12, "role", "", false, false], [22, 23, 2, 12, "temporal", "", false, false], [25, 26, 2, 12, "physical", "", false, false], [25, 26, 2, 12, "role", "", false, false], [25, 26, 2, 12, "temporal", "", false, false], [34, 36, 38, 41, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["En", "la", "Conferencia", "del", "IEEE", "sobre", "Visi\u00f3n", "por", "Ordenador", "y", "Reconocimiento", "de", "Patrones", "de", "2006", ",", "Qiang", "Zhu", ",", "Shai", "Avidan", ",", "Mei-Chen", "Yeh", "y", "Kwang-Ting", "Cheng", "presentaron", "un", "algoritmo", "para", "acelerar", "significativamente", "la", "detecci\u00f3n", "de", "personas", "utilizando", "m\u00e9todos", "de", "descriptor", "HOG", "."], "sentence-detokenized": "En la Conferencia del IEEE sobre Visi\u00f3n por Ordenador y Reconocimiento de Patrones de 2006, Qiang Zhu, Shai Avidan, Mei-Chen Yeh y Kwang-Ting Cheng presentaron un algoritmo para acelerar significativamente la detecci\u00f3n de personas utilizando m\u00e9todos de descriptor HOG.", "token2charspan": [[0, 2], [3, 5], [6, 17], [18, 21], [22, 26], [27, 32], [33, 39], [40, 43], [44, 53], [54, 55], [56, 70], [71, 73], [74, 82], [83, 85], [86, 90], [90, 91], [92, 97], [98, 101], [101, 102], [103, 107], [108, 114], [114, 115], [116, 124], [125, 128], [129, 130], [131, 141], [142, 147], [148, 159], [160, 162], [163, 172], [173, 177], [178, 186], [187, 205], [206, 208], [209, 218], [219, 221], [222, 230], [231, 241], [242, 249], [250, 252], [253, 263], [264, 267], [267, 268]]}
{"doc_key": "ai-dev-223", "ner": [[0, 1, "researcher"], [5, 6, "conference"], [10, 12, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 5, 6, "role", "", false, false], [0, 1, 10, 12, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hayes", "es", "miembro", "fundador", "de", "la", "AAAI", "y", "de", "la", "Cognitive", "Science", "Society"], "sentence-detokenized": "Hayes es miembro fundador de la AAAI y de la Cognitive Science Society", "token2charspan": [[0, 5], [6, 8], [9, 16], [17, 25], [26, 28], [29, 31], [32, 36], [37, 38], [39, 41], [42, 44], [45, 54], [55, 62], [63, 70]]}
{"doc_key": "ai-dev-224", "ner": [[0, 2, "misc"], [7, 7, "field"], [10, 12, "field"], [15, 17, "field"], [20, 20, "field"], [23, 24, "field"], [27, 28, "field"], [31, 33, "field"], [36, 36, "field"], [40, 41, "field"], [44, 44, "field"], [47, 49, "field"], [60, 61, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[0, 2, 7, 7, "part-of", "", false, false], [0, 2, 7, 7, "usage", "", false, false], [0, 2, 10, 12, "part-of", "", false, false], [0, 2, 10, 12, "usage", "", false, false], [0, 2, 15, 17, "part-of", "", false, false], [0, 2, 15, 17, "usage", "", false, false], [0, 2, 20, 20, "part-of", "", false, false], [0, 2, 20, 20, "usage", "", false, false], [0, 2, 23, 24, "part-of", "", false, false], [0, 2, 23, 24, "usage", "", false, false], [0, 2, 27, 28, "part-of", "", false, false], [0, 2, 27, 28, "usage", "", false, false], [0, 2, 31, 33, "part-of", "", false, false], [0, 2, 31, 33, "usage", "", false, false], [0, 2, 36, 36, "part-of", "", false, false], [0, 2, 36, 36, "usage", "", false, false], [0, 2, 40, 41, "part-of", "", false, false], [0, 2, 40, 41, "usage", "", false, false], [0, 2, 44, 44, "part-of", "", false, false], [0, 2, 44, 44, "usage", "", false, false], [0, 2, 47, 49, "part-of", "", false, false], [0, 2, 47, 49, "usage", "", false, false], [0, 2, 60, 61, "part-of", "", false, false], [0, 2, 60, 61, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "sentence": ["Las", "series", "temporales", "se", "utilizan", "en", "la", "estad\u00edstica", ",", "el", "procesamiento", "de", "se\u00f1ales", ",", "el", "reconocimiento", "de", "patrones", ",", "la", "econometr\u00eda", ",", "las", "finanzas", "matem\u00e1ticas", ",", "la", "previsi\u00f3n", "meteorol\u00f3gica", ",", "la", "predicci\u00f3n", "de", "terremotos", ",", "la", "electroencefalograf\u00eda", ",", "la", "ingenier\u00eda", "de", "control", ",", "la", "astronom\u00eda", ",", "la", "ingenier\u00eda", "de", "comunicaciones", "y", ",", "en", "general", ",", "en", "cualquier", "\u00e1mbito", "de", "la", "ciencia", "aplicada", "y", "la", "ingenier\u00eda", "que", "implique", "mediciones", "temporales", "."], "sentence-detokenized": "Las series temporales se utilizan en la estad\u00edstica, el procesamiento de se\u00f1ales, el reconocimiento de patrones, la econometr\u00eda, las finanzas matem\u00e1ticas, la previsi\u00f3n meteorol\u00f3gica, la predicci\u00f3n de terremotos, la electroencefalograf\u00eda, la ingenier\u00eda de control, la astronom\u00eda, la ingenier\u00eda de comunicaciones y, en general, en cualquier \u00e1mbito de la ciencia aplicada y la ingenier\u00eda que implique mediciones temporales.", "token2charspan": [[0, 3], [4, 10], [11, 21], [22, 24], [25, 33], [34, 36], [37, 39], [40, 51], [51, 52], [53, 55], [56, 69], [70, 72], [73, 80], [80, 81], [82, 84], [85, 99], [100, 102], [103, 111], [111, 112], [113, 115], [116, 127], [127, 128], [129, 132], [133, 141], [142, 153], [153, 154], [155, 157], [158, 167], [168, 181], [181, 182], [183, 185], [186, 196], [197, 199], [200, 210], [210, 211], [212, 214], [215, 236], [236, 237], [238, 240], [241, 251], [252, 254], [255, 262], [262, 263], [264, 266], [267, 277], [277, 278], [279, 281], [282, 292], [293, 295], [296, 310], [311, 312], [312, 313], [314, 316], [317, 324], [324, 325], [326, 328], [329, 338], [339, 345], [346, 348], [349, 351], [352, 359], [360, 368], [369, 370], [371, 373], [374, 384], [385, 388], [389, 397], [398, 408], [409, 419], [419, 420]]}
{"doc_key": "ai-dev-225", "ner": [[13, 15, "metrics"], [38, 38, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["En", "principio", ",", "la", "recuperaci\u00f3n", "exacta", "puede", "resolverse", "en", "su", "rango", "factible", "utilizando", "la", "m\u00e1xima", "probabilidad", ",", "pero", "esto", "equivale", "a", "resolver", "un", "problema", "de", "corte", "restringido", "o", "regularizado", ",", "como", "la", "bisecci\u00f3n", "m\u00ednima", ",", "que", "suele", "ser", "NP-completo", "."], "sentence-detokenized": "En principio, la recuperaci\u00f3n exacta puede resolverse en su rango factible utilizando la m\u00e1xima probabilidad, pero esto equivale a resolver un problema de corte restringido o regularizado, como la bisecci\u00f3n m\u00ednima, que suele ser NP-completo.", "token2charspan": [[0, 2], [3, 12], [12, 13], [14, 16], [17, 29], [30, 36], [37, 42], [43, 53], [54, 56], [57, 59], [60, 65], [66, 74], [75, 85], [86, 88], [89, 95], [96, 108], [108, 109], [110, 114], [115, 119], [120, 128], [129, 130], [131, 139], [140, 142], [143, 151], [152, 154], [155, 160], [161, 172], [173, 174], [175, 187], [187, 188], [189, 193], [194, 196], [197, 206], [207, 213], [213, 214], [215, 218], [219, 224], [225, 228], [229, 240], [240, 241]]}
{"doc_key": "ai-dev-226", "ner": [[5, 7, "task"], [17, 17, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 17, 5, 7, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["en", "su", "trabajo", "para", "la", "detecci\u00f3n", "de", "peatones", ",", "que", "se", "describi\u00f3", "por", "primera", "vez", "en", "el", "BMVC", "en", "2009", "."], "sentence-detokenized": "en su trabajo para la detecci\u00f3n de peatones, que se describi\u00f3 por primera vez en el BMVC en 2009.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 18], [19, 21], [22, 31], [32, 34], [35, 43], [43, 44], [45, 48], [49, 51], [52, 61], [62, 65], [66, 73], [74, 77], [78, 80], [81, 83], [84, 88], [89, 91], [92, 96], [96, 97]]}
{"doc_key": "ai-dev-227", "ner": [[5, 10, "conference"], [12, 13, "researcher"], [15, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 13, 5, 10, "physical", "", false, false], [12, 13, 5, 10, "role", "", false, false], [12, 13, 15, 23, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["En", "2007", ",", "en", "la", "Conferencia", "Internacional", "de", "Visi\u00f3n", "por", "Computador", ",", "Terzopoulos", "recibi\u00f3", "el", "premio", "inaugural", "IEEE", "PAMI", "Computer", "Vision", "Distinguished", "Researcher", "Award", "por", "su", "investigaci\u00f3n", "pionera", "y", "sostenida", "sobre", "modelos", "deformables", "y", "sus", "aplicaciones", "."], "sentence-detokenized": "En 2007, en la Conferencia Internacional de Visi\u00f3n por Computador, Terzopoulos recibi\u00f3 el premio inaugural IEEE PAMI Computer Vision Distinguished Researcher Award por su investigaci\u00f3n pionera y sostenida sobre modelos deformables y sus aplicaciones.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 14], [15, 26], [27, 40], [41, 43], [44, 50], [51, 54], [55, 65], [65, 66], [67, 78], [79, 86], [87, 89], [90, 96], [97, 106], [107, 111], [112, 116], [117, 125], [126, 132], [133, 146], [147, 157], [158, 163], [164, 167], [168, 170], [171, 184], [185, 192], [193, 194], [195, 204], [205, 210], [211, 218], [219, 230], [231, 232], [233, 236], [237, 249], [249, 250]]}
{"doc_key": "ai-dev-228", "ner": [[0, 3, "task"], [5, 5, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 5, 5, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["El", "an\u00e1lisis", "de", "conglomerados", "o", "cl\u00fasteres", "consiste", "en", "asignar", "puntos", "de", "datos", "a", "conglomerados", "de", "tal", "manera", "que", "los", "elementos", "del", "mismo", "conglomerado", "sean", "lo", "m\u00e1s", "similares", "posible", ",", "mientras", "que", "los", "elementos", "que", "pertenecen", "a", "conglomerados", "diferentes", "sean", "lo", "m\u00e1s", "dis\u00edmiles", "."], "sentence-detokenized": "El an\u00e1lisis de conglomerados o cl\u00fasteres consiste en asignar puntos de datos a conglomerados de tal manera que los elementos del mismo conglomerado sean lo m\u00e1s similares posible, mientras que los elementos que pertenecen a conglomerados diferentes sean lo m\u00e1s dis\u00edmiles.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 28], [29, 30], [31, 40], [41, 49], [50, 52], [53, 60], [61, 67], [68, 70], [71, 76], [77, 78], [79, 92], [93, 95], [96, 99], [100, 106], [107, 110], [111, 114], [115, 124], [125, 128], [129, 134], [135, 147], [148, 152], [153, 155], [156, 159], [160, 169], [170, 177], [177, 178], [179, 187], [188, 191], [192, 195], [196, 205], [206, 209], [210, 220], [221, 222], [223, 236], [237, 247], [248, 252], [253, 255], [256, 259], [260, 269], [269, 270]]}
{"doc_key": "ai-dev-229", "ner": [[12, 12, "field"], [18, 20, "field"], [22, 24, "task"], [27, 29, "field"], [31, 34, "field"], [38, 40, "field"], [44, 46, "field"], [48, 50, "task"], [52, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[12, 12, 18, 20, "named", "", false, false], [12, 12, 27, 29, "named", "", false, false], [12, 12, 38, 40, "named", "", false, false], [22, 24, 18, 20, "part-of", "task_part_of_field", false, false], [31, 34, 27, 29, "part-of", "", false, false], [44, 46, 38, 40, "part-of", "", false, false], [48, 50, 44, 46, "part-of", "", false, false], [52, 54, 44, 46, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["(", "2005", ")", "podemos", "diferenciar", "tres", "perspectivas", "diferentes", "de", "la", "miner\u00eda", "de", "texto", ",", "a", "saber", ",", "la", "miner\u00eda", "de", "texto", "como", "extracci\u00f3n", "de", "informaci\u00f3n", ",", "la", "miner\u00eda", "de", "texto", "como", "miner\u00eda", "de", "datos", "de", "texto", "y", "la", "miner\u00eda", "de", "texto", "como", "proceso", "de", "miner\u00eda", "de", "datos", "(", "descubrimiento", "de", "conocimientos", "en", "bases", "de", "datos", ")", ".Hotho", ",", "A.", ",", "N\u00fcrnberger", ",", "A.", "y", "Paa\u00df", ",", "G.", "(", "2005", ")", "."], "sentence-detokenized": "(2005) podemos diferenciar tres perspectivas diferentes de la miner\u00eda de texto, a saber, la miner\u00eda de texto como extracci\u00f3n de informaci\u00f3n, la miner\u00eda de texto como miner\u00eda de datos de texto y la miner\u00eda de texto como proceso de miner\u00eda de datos (descubrimiento de conocimientos en bases de datos).Hotho, A., N\u00fcrnberger, A. y Paa\u00df, G. (2005).", "token2charspan": [[0, 1], [1, 5], [5, 6], [7, 14], [15, 26], [27, 31], [32, 44], [45, 55], [56, 58], [59, 61], [62, 69], [70, 72], [73, 78], [78, 79], [80, 81], [82, 87], [87, 88], [89, 91], [92, 99], [100, 102], [103, 108], [109, 113], [114, 124], [125, 127], [128, 139], [139, 140], [141, 143], [144, 151], [152, 154], [155, 160], [161, 165], [166, 173], [174, 176], [177, 182], [183, 185], [186, 191], [192, 193], [194, 196], [197, 204], [205, 207], [208, 213], [214, 218], [219, 226], [227, 229], [230, 237], [238, 240], [241, 246], [247, 248], [248, 262], [263, 265], [266, 279], [280, 282], [283, 288], [289, 291], [292, 297], [297, 298], [298, 304], [304, 305], [306, 308], [308, 309], [310, 320], [320, 321], [322, 324], [325, 326], [327, 331], [331, 332], [333, 335], [336, 337], [337, 341], [341, 342], [342, 343]]}
{"doc_key": "ai-dev-230", "ner": [[1, 2, "product"], [15, 22, "location"], [25, 25, "location"], [26, 27, "location"], [38, 41, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 15, 22, "related-to", "developed_for", false, false], [15, 22, 25, 25, "physical", "", false, false], [25, 25, 26, 27, "physical", "", false, false], [38, 41, 1, 2, "role", "buys", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["El", "Rancho", "Arm", "se", "desarroll\u00f3", "como", "brazo", "rob\u00f3tico", "para", "ayudar", "a", "los", "pacientes", "discapacitados", "del", "Centro", "Nacional", "de", "Rehabilitaci\u00f3n", "del", "Rancho", "Los", "Amigos", ",", "en", "Downey", "(", "California", ")", ";", "este", "brazo", "controlado", "por", "ordenador", "fue", "adquirido", "por", "la", "Universidad", "de", "Stanford", "en", "1963", "."], "sentence-detokenized": "El Rancho Arm se desarroll\u00f3 como brazo rob\u00f3tico para ayudar a los pacientes discapacitados del Centro Nacional de Rehabilitaci\u00f3n del Rancho Los Amigos, en Downey (California); este brazo controlado por ordenador fue adquirido por la Universidad de Stanford en 1963.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 16], [17, 27], [28, 32], [33, 38], [39, 47], [48, 52], [53, 59], [60, 61], [62, 65], [66, 75], [76, 90], [91, 94], [95, 101], [102, 110], [111, 113], [114, 128], [129, 132], [133, 139], [140, 143], [144, 150], [150, 151], [152, 154], [155, 161], [162, 163], [163, 173], [173, 174], [174, 175], [176, 180], [181, 186], [187, 197], [198, 201], [202, 211], [212, 215], [216, 225], [226, 229], [230, 232], [233, 244], [245, 247], [248, 256], [257, 259], [260, 264], [264, 265]]}
{"doc_key": "ai-dev-231", "ner": [[1, 2, "university"], [4, 4, "researcher"], [10, 14, "organisation"], [22, 25, "organisation"], [29, 30, "researcher"], [32, 34, "researcher"], [48, 49, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 4, 1, 2, "physical", "", false, false], [4, 4, 1, 2, "role", "", false, false], [4, 4, 10, 14, "role", "founder", false, false], [4, 4, 22, 25, "role", "founder", false, false], [22, 25, 48, 49, "physical", "", false, false], [29, 30, 22, 25, "role", "founder", false, false], [32, 34, 22, 25, "role", "founder", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["En", "la", "UCSD", ",", "Norman", "fue", "uno", "de", "los", "fundadores", "del", "Instituto", "de", "Ciencias", "Cognitivas", "y", "uno", "de", "los", "organizadores", "de", "la", "Sociedad", "de", "Ciencias", "Cognitivas", "(", "junto", "con", "Roger", "Schank", ",", "Allan", "M.", "Collins", "y", "otros", ")", ",", "que", "celebr\u00f3", "su", "primera", "reuni\u00f3n", "en", "el", "campus", "de", "la", "UCSD", "en", "1979", "."], "sentence-detokenized": "En la UCSD, Norman fue uno de los fundadores del Instituto de Ciencias Cognitivas y uno de los organizadores de la Sociedad de Ciencias Cognitivas (junto con Roger Schank, Allan M. Collins y otros), que celebr\u00f3 su primera reuni\u00f3n en el campus de la UCSD en 1979.", "token2charspan": [[0, 2], [3, 5], [6, 10], [10, 11], [12, 18], [19, 22], [23, 26], [27, 29], [30, 33], [34, 44], [45, 48], [49, 58], [59, 61], [62, 70], [71, 81], [82, 83], [84, 87], [88, 90], [91, 94], [95, 108], [109, 111], [112, 114], [115, 123], [124, 126], [127, 135], [136, 146], [147, 148], [148, 153], [154, 157], [158, 163], [164, 170], [170, 171], [172, 177], [178, 180], [181, 188], [189, 190], [191, 196], [196, 197], [197, 198], [199, 202], [203, 210], [211, 213], [214, 221], [222, 229], [230, 232], [233, 235], [236, 242], [243, 245], [246, 248], [249, 253], [254, 256], [257, 261], [261, 262]]}
{"doc_key": "ai-dev-232", "ner": [[8, 9, "product"], [12, 13, "product"], [15, 17, "product"], [19, 23, "product"], [26, 28, "product"], [30, 31, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[26, 28, 19, 23, "type-of", "", false, false], [30, 31, 19, 23, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Las", "configuraciones", "de", "robots", "m\u00e1s", "utilizadas", "son", "los", "robots", "articulados", ",", "los", "robots", "SCARA", ",", "los", "robots", "delta", "y", "los", "robots", "de", "coordenadas", "cartesianas", ",", "(", "robots", "de", "p\u00f3rtico", "o", "robots", "x-y-z", ")", "."], "sentence-detokenized": "Las configuraciones de robots m\u00e1s utilizadas son los robots articulados, los robots SCARA, los robots delta y los robots de coordenadas cartesianas, (robots de p\u00f3rtico o robots x-y-z).", "token2charspan": [[0, 3], [4, 19], [20, 22], [23, 29], [30, 33], [34, 44], [45, 48], [49, 52], [53, 59], [60, 71], [71, 72], [73, 76], [77, 83], [84, 89], [89, 90], [91, 94], [95, 101], [102, 107], [108, 109], [110, 113], [114, 120], [121, 123], [124, 135], [136, 147], [147, 148], [149, 150], [150, 156], [157, 159], [160, 167], [168, 169], [170, 176], [177, 182], [182, 183], [183, 184]]}
{"doc_key": "ai-dev-233", "ner": [[8, 8, "programlang"], [7, 9, "misc"], [14, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 8, 8, "part-of", "", false, false], [14, 14, 7, 9, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Tambi\u00e9n", "se", "puede", "utilizar", "directamente", "con", "el", "m\u00f3dulo", "Perl", "TM", "(", "que", "tambi\u00e9n", "soporta", "LTM", ")", "."], "sentence-detokenized": "Tambi\u00e9n se puede utilizar directamente con el m\u00f3dulo Perl TM (que tambi\u00e9n soporta LTM).", "token2charspan": [[0, 7], [8, 10], [11, 16], [17, 25], [26, 38], [39, 42], [43, 45], [46, 52], [53, 57], [58, 60], [61, 62], [62, 65], [66, 73], [74, 81], [82, 85], [85, 86], [86, 87]]}
{"doc_key": "ai-dev-234", "ner": [[6, 7, "organisation"], [15, 16, "organisation"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Lo", "gan\u00f3", "un", "equipo", "estadounidense", "de", "Newton", "Labs", ",", "y", "el", "concurso", "se", "emiti\u00f3", "en", "la", "CNN", "."], "sentence-detokenized": "Lo gan\u00f3 un equipo estadounidense de Newton Labs, y el concurso se emiti\u00f3 en la CNN.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 17], [18, 32], [33, 35], [36, 42], [43, 47], [47, 48], [49, 50], [51, 53], [54, 62], [63, 65], [66, 72], [73, 75], [76, 78], [79, 82], [82, 83]]}
{"doc_key": "ai-dev-235", "ner": [[0, 3, "misc"], [9, 10, "person"], [14, 15, "person"], [17, 18, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 0, 3, "role", "directs", false, false], [14, 15, 0, 3, "role", "acts_in", false, false], [17, 18, 0, 3, "role", "acts_in", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Butler's", "in", "Love", ",", "un", "cortometraje", "dirigido", "por", "David", "Arquette", "y", "protagonizado", "por", "Elizabeth", "Berkley", "y", "Thomas", "Jane", "se", "estren\u00f3", "el", "23", "de", "junio", "de", "2008", "."], "sentence-detokenized": "The Butler's in Love, un cortometraje dirigido por David Arquette y protagonizado por Elizabeth Berkley y Thomas Jane se estren\u00f3 el 23 de junio de 2008.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 20], [20, 21], [22, 24], [25, 37], [38, 46], [47, 50], [51, 56], [57, 65], [66, 67], [68, 81], [82, 85], [86, 95], [96, 103], [104, 105], [106, 112], [113, 117], [118, 120], [121, 128], [129, 131], [132, 134], [135, 137], [138, 143], [144, 146], [147, 151], [151, 152]]}
{"doc_key": "ai-dev-236", "ner": [[3, 3, "product"], [10, 10, "field"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 18, 19, "general-affiliation", "", false, false], [10, 10, 3, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Por", "ejemplo", ",", "WordNet", "es", "un", "recurso", "que", "incluye", "una", "taxonom\u00eda", ",", "cuyos", "elementos", "son", "significados", "de", "palabras", "en", "ingl\u00e9s", "."], "sentence-detokenized": "Por ejemplo, WordNet es un recurso que incluye una taxonom\u00eda, cuyos elementos son significados de palabras en ingl\u00e9s.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 20], [21, 23], [24, 26], [27, 34], [35, 38], [39, 46], [47, 50], [51, 60], [60, 61], [62, 67], [68, 77], [78, 81], [82, 94], [95, 97], [98, 106], [107, 109], [110, 116], [116, 117]]}
{"doc_key": "ai-dev-237", "ner": [[0, 4, "product"], [8, 8, "product"], [10, 10, "product"], [18, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 0, 4, "type-of", "", false, false], [8, 8, 18, 18, "related-to", "ability_to", false, false], [10, 10, 0, 4, "type-of", "", false, false], [10, 10, 18, 18, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Los", "sistemas", "de", "robots", "humanoides", "existentes", ",", "como", "ASIMO", "y", "QRIO", ",", "utilizan", "muchos", "motores", "para", "lograr", "la", "locomoci\u00f3n", "."], "sentence-detokenized": "Los sistemas de robots humanoides existentes, como ASIMO y QRIO, utilizan muchos motores para lograr la locomoci\u00f3n.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 22], [23, 33], [34, 44], [44, 45], [46, 50], [51, 56], [57, 58], [59, 63], [63, 64], [65, 73], [74, 80], [81, 88], [89, 93], [94, 100], [101, 103], [104, 114], [114, 115]]}
{"doc_key": "ai-dev-238", "ner": [[0, 0, "metrics"], [7, 9, "metrics"], [12, 12, "metrics"], [14, 20, "misc"], [22, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 9, 0, 0, "part-of", "", false, false], [12, 12, 0, 0, "part-of", "", false, false], [14, 20, 0, 0, "part-of", "", false, false], [22, 22, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LEPOR", "est\u00e1", "dise\u00f1ado", "con", "los", "factores", "de", "penalizaci\u00f3n", "de", "longitud", "mejorada", ",", "precisi\u00f3n", ",", "penalizaci\u00f3n", "de", "orden", "de", "palabras", "de", "n-gramas", "y", "recall", "."], "sentence-detokenized": "LEPOR est\u00e1 dise\u00f1ado con los factores de penalizaci\u00f3n de longitud mejorada, precisi\u00f3n, penalizaci\u00f3n de orden de palabras de n-gramas y recall.", "token2charspan": [[0, 5], [6, 10], [11, 19], [20, 23], [24, 27], [28, 36], [37, 39], [40, 52], [53, 55], [56, 64], [65, 73], [73, 74], [75, 84], [84, 85], [86, 98], [99, 101], [102, 107], [108, 110], [111, 119], [120, 122], [123, 131], [132, 133], [134, 140], [140, 141]]}
{"doc_key": "ai-dev-239", "ner": [[4, 10, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Se", "basa", "en", "la", "m\u00e9trica", "de", "la", "evaluaci\u00f3n", "biling\u00fce", "del", "estudiante", ",", "pero", "con", "algunas", "alteraciones", "."], "sentence-detokenized": "Se basa en la m\u00e9trica de la evaluaci\u00f3n biling\u00fce del estudiante, pero con algunas alteraciones.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 13], [14, 21], [22, 24], [25, 27], [28, 38], [39, 47], [48, 51], [52, 62], [62, 63], [64, 68], [69, 72], [73, 80], [81, 93], [93, 94]]}
{"doc_key": "ai-dev-240", "ner": [[7, 7, "product"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Este", "es", "un", "ejemplo", "de", "implementaci\u00f3n", "en", "MATLAB", "/", "Octave", ":"], "sentence-detokenized": "Este es un ejemplo de implementaci\u00f3n en MATLAB / Octave:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 36], [37, 39], [40, 46], [47, 48], [49, 55], [55, 56]]}
{"doc_key": "ai-dev-241", "ner": [[15, 15, "programlang"], [17, 17, "programlang"], [19, 19, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Est\u00e1", "dise\u00f1ado", "para", "ser", "utilizado", "a", "trav\u00e9s", "de", "una", "serie", "de", "lenguajes", "inform\u00e1ticos", ",", "incluyendo", "Python", ",", "Ruby", "y", "Scheme", "."], "sentence-detokenized": "Est\u00e1 dise\u00f1ado para ser utilizado a trav\u00e9s de una serie de lenguajes inform\u00e1ticos, incluyendo Python, Ruby y Scheme.", "token2charspan": [[0, 4], [5, 13], [14, 18], [19, 22], [23, 32], [33, 34], [35, 41], [42, 44], [45, 48], [49, 54], [55, 57], [58, 67], [68, 80], [80, 81], [82, 92], [93, 99], [99, 100], [101, 105], [106, 107], [108, 114], [114, 115]]}
{"doc_key": "ai-dev-242", "ner": [[0, 0, "researcher"], [5, 6, "organisation"], [11, 12, "conference"], [18, 18, "academicjournal"], [23, 25, "organisation"], [30, 34, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 5, 6, "role", "", false, false], [0, 0, 11, 12, "role", "", false, false], [0, 0, 18, 18, "role", "", false, false], [0, 0, 23, 25, "role", "", false, false], [0, 0, 30, 34, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hayes", "ha", "sido", "secretario", "de", "la", "AISB", ",", "presidente", "y", "administrador", "del", "IJCAI", ",", "editor", "asociado", "de", "Artificial", "Intelligence", ",", "gobernador", "de", "la", "Cognitive", "Science", "Society", "y", "presidente", "de", "la", "American", "Association", "for", "Artificial", "Intelligence", "."], "sentence-detokenized": "Hayes ha sido secretario de la AISB, presidente y administrador del IJCAI, editor asociado de Artificial Intelligence, gobernador de la Cognitive Science Society y presidente de la American Association for Artificial Intelligence.", "token2charspan": [[0, 5], [6, 8], [9, 13], [14, 24], [25, 27], [28, 30], [31, 35], [35, 36], [37, 47], [48, 49], [50, 63], [64, 67], [68, 73], [73, 74], [75, 81], [82, 90], [91, 93], [94, 104], [105, 117], [117, 118], [119, 129], [130, 132], [133, 135], [136, 145], [146, 153], [154, 161], [162, 163], [164, 174], [175, 177], [178, 180], [181, 189], [190, 201], [202, 205], [206, 216], [217, 229], [229, 230]]}
{"doc_key": "ai-dev-243", "ner": [[4, 14, "misc"], [16, 18, "misc"], [23, 24, "person"], [29, 33, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 24, 4, 14, "role", "directed_by", false, false], [23, 24, 16, 18, "role", "directed_by", false, false], [23, 24, 29, 33, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dos", "de", "ellas", ",", "Now", "is", "the", "Time", "(", "to", "Put", "On", "Your", "Glasses", ")", "y", "Around", "is", "Around", ",", "fueron", "dirigidas", "por", "Norman", "McLaren", "en", "1951", "para", "el", "National", "Film", "Board", "of", "Canada", "."], "sentence-detokenized": "Dos de ellas, Now is the Time (to Put On Your Glasses) y Around is Around, fueron dirigidas por Norman McLaren en 1951 para el National Film Board of Canada.", "token2charspan": [[0, 3], [4, 6], [7, 12], [12, 13], [14, 17], [18, 20], [21, 24], [25, 29], [30, 31], [31, 33], [34, 37], [38, 40], [41, 45], [46, 53], [53, 54], [55, 56], [57, 63], [64, 66], [67, 73], [73, 74], [75, 81], [82, 91], [92, 95], [96, 102], [103, 110], [111, 113], [114, 118], [119, 123], [124, 126], [127, 135], [136, 140], [141, 146], [147, 149], [150, 156], [156, 157]]}
{"doc_key": "ai-dev-244", "ner": [[1, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Un", "sistema", "de", "recomendaci\u00f3n", "tiene", "como", "objetivo", "predecir", "la", "preferencia", "por", "un", "art\u00edculo", "de", "un", "usuario", "objetivo", "."], "sentence-detokenized": "Un sistema de recomendaci\u00f3n tiene como objetivo predecir la preferencia por un art\u00edculo de un usuario objetivo.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 27], [28, 33], [34, 38], [39, 47], [48, 56], [57, 59], [60, 71], [72, 75], [76, 78], [79, 87], [88, 90], [91, 93], [94, 101], [102, 110], [110, 111]]}
{"doc_key": "ai-dev-245", "ner": [[0, 1, "algorithm"], [7, 7, "field"], [10, 10, "field"], [13, 15, "field"], [18, 21, "field"], [24, 26, "field"], [28, 29, "field"], [32, 32, "field"], [34, 36, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 1, 7, 7, "part-of", "", true, false], [0, 1, 10, 10, "part-of", "", true, false], [0, 1, 13, 15, "part-of", "", true, false], [0, 1, 18, 21, "part-of", "", true, false], [0, 1, 24, 26, "part-of", "", true, false], [0, 1, 28, 29, "part-of", "", true, false], [0, 1, 32, 32, "part-of", "", true, false], [0, 1, 34, 36, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["La", "convoluci\u00f3n", "tiene", "aplicaciones", "que", "incluyen", "la", "probabilidad", ",", "la", "estad\u00edstica", ",", "la", "visi\u00f3n", "por", "ordenador", ",", "el", "procesamiento", "del", "lenguaje", "natural", ",", "el", "procesamiento", "de", "im\u00e1genes", "y", "de", "se\u00f1ales", ",", "la", "ingenier\u00eda", "y", "las", "ecuaciones", "diferenciales", "."], "sentence-detokenized": "La convoluci\u00f3n tiene aplicaciones que incluyen la probabilidad, la estad\u00edstica, la visi\u00f3n por ordenador, el procesamiento del lenguaje natural, el procesamiento de im\u00e1genes y de se\u00f1ales, la ingenier\u00eda y las ecuaciones diferenciales.", "token2charspan": [[0, 2], [3, 14], [15, 20], [21, 33], [34, 37], [38, 46], [47, 49], [50, 62], [62, 63], [64, 66], [67, 78], [78, 79], [80, 82], [83, 89], [90, 93], [94, 103], [103, 104], [105, 107], [108, 121], [122, 125], [126, 134], [135, 142], [142, 143], [144, 146], [147, 160], [161, 163], [164, 172], [173, 174], [175, 177], [178, 185], [185, 186], [187, 189], [190, 200], [201, 202], [203, 206], [207, 217], [218, 231], [231, 232]]}
{"doc_key": "ai-dev-246", "ner": [[2, 3, "field"], [6, 10, "task"], [13, 15, "task"], [19, 19, "task"], [21, 21, "task"], [18, 20, "task"], [24, 26, "task"], [29, 31, "task"], [34, 36, "task"], [39, 40, "task"], [42, 44, "task"], [47, 47, "field"], [50, 50, "field"], [53, 56, "field"], [59, 59, "field"], [62, 62, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[2, 3, 6, 10, "part-of", "", true, false], [2, 3, 13, 15, "part-of", "", true, false], [2, 3, 19, 19, "part-of", "", true, false], [2, 3, 21, 21, "part-of", "", true, false], [2, 3, 18, 20, "part-of", "", true, false], [2, 3, 24, 26, "part-of", "", true, false], [2, 3, 29, 31, "part-of", "", true, false], [2, 3, 34, 36, "part-of", "", true, false], [2, 3, 39, 40, "part-of", "", true, false], [2, 3, 42, 44, "part-of", "", true, false], [2, 3, 47, 47, "part-of", "", true, false], [2, 3, 50, 50, "part-of", "", true, false], [2, 3, 53, 56, "part-of", "", true, false], [2, 3, 59, 59, "part-of", "", true, false], [2, 3, 62, 62, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Las", "aplicaciones", "del", "DSP", "incluyen", "el", "procesamiento", "de", "se\u00f1ales", "de", "audio", ",", "la", "compresi\u00f3n", "de", "audio", ",", "el", "procesamiento", "digital", "de", "im\u00e1genes", ",", "la", "compresi\u00f3n", "de", "v\u00eddeo", ",", "el", "procesamiento", "del", "habla", ",", "el", "reconocimiento", "del", "habla", ",", "las", "comunicaciones", "digitales", ",", "los", "sintetizadores", "digitales", ",", "el", "radar", ",", "el", "sonar", ",", "el", "procesamiento", "de", "se\u00f1ales", "financieras", ",", "la", "sismolog\u00eda", "y", "la", "biomedicina", "."], "sentence-detokenized": "Las aplicaciones del DSP incluyen el procesamiento de se\u00f1ales de audio, la compresi\u00f3n de audio, el procesamiento digital de im\u00e1genes, la compresi\u00f3n de v\u00eddeo, el procesamiento del habla, el reconocimiento del habla, las comunicaciones digitales, los sintetizadores digitales, el radar, el sonar, el procesamiento de se\u00f1ales financieras, la sismolog\u00eda y la biomedicina.", "token2charspan": [[0, 3], [4, 16], [17, 20], [21, 24], [25, 33], [34, 36], [37, 50], [51, 53], [54, 61], [62, 64], [65, 70], [70, 71], [72, 74], [75, 85], [86, 88], [89, 94], [94, 95], [96, 98], [99, 112], [113, 120], [121, 123], [124, 132], [132, 133], [134, 136], [137, 147], [148, 150], [151, 156], [156, 157], [158, 160], [161, 174], [175, 178], [179, 184], [184, 185], [186, 188], [189, 203], [204, 207], [208, 213], [213, 214], [215, 218], [219, 233], [234, 243], [243, 244], [245, 248], [249, 263], [264, 273], [273, 274], [275, 277], [278, 283], [283, 284], [285, 287], [288, 293], [293, 294], [295, 297], [298, 311], [312, 314], [315, 322], [323, 334], [334, 335], [336, 338], [339, 349], [350, 351], [352, 354], [355, 366], [366, 367]]}
{"doc_key": "ai-dev-247", "ner": [[15, 16, "misc"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["(", "20", "de", "febrero", "de", "1912", "-", "11", "de", "agosto", "de", "2011", ")", "fue", "un", "inventor", "estadounidense", ",", "m\u00e1s", "conocido", "por", "la", "creaci\u00f3n", "de", "Unimate", ",", "el", "primer", "robot", "industrial", "."], "sentence-detokenized": "(20 de febrero de 1912 - 11 de agosto de 2011) fue un inventor estadounidense, m\u00e1s conocido por la creaci\u00f3n de Unimate, el primer robot industrial.", "token2charspan": [[0, 1], [1, 3], [4, 6], [7, 14], [15, 17], [18, 22], [23, 24], [25, 27], [28, 30], [31, 37], [38, 40], [41, 45], [45, 46], [47, 50], [51, 53], [54, 62], [63, 77], [77, 78], [79, 82], [83, 91], [92, 95], [96, 98], [99, 107], [108, 110], [111, 118], [118, 119], [120, 122], [123, 129], [130, 135], [136, 146], [146, 147]]}
{"doc_key": "ai-dev-248", "ner": [[1, 3, "researcher"], [5, 7, "researcher"], [9, 9, "researcher"], [23, 25, "algorithm"], [30, 32, "algorithm"], [38, 40, "task"], [43, 43, "algorithm"], [48, 49, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[1, 3, 23, 25, "related-to", "writes_about", true, false], [5, 7, 23, 25, "related-to", "writes_about", true, false], [9, 9, 23, 25, "related-to", "writes_about", true, false], [23, 25, 30, 32, "related-to", "", true, false], [38, 40, 43, 43, "related-to", "", true, false], [48, 49, 43, 43, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Con", "David", "E.", "Rumelhart", "y", "Ronald", "J.", "Williams", ",", "Hinton", "fue", "coautor", "de", "un", "art\u00edculo", "muy", "citado", "publicado", "en", "1986", "que", "populariz\u00f3", "el", "algoritmo", "de", "retropropagaci\u00f3n", "para", "el", "entrenamiento", "de", "redes", "neuronales", "multicapa", ",", "El", "espectacular", "hito", "de", "reconocimiento", "de", "im\u00e1genes", "de", "la", "AlexNet", "dise\u00f1ada", "por", "su", "alumno", "Alex", "Krizhevsky", "{", "{", "cite", "web"], "sentence-detokenized": "Con David E. Rumelhart y Ronald J. Williams, Hinton fue coautor de un art\u00edculo muy citado publicado en 1986 que populariz\u00f3 el algoritmo de retropropagaci\u00f3n para el entrenamiento de redes neuronales multicapa, El espectacular hito de reconocimiento de im\u00e1genes de la AlexNet dise\u00f1ada por su alumno Alex Krizhevsky {{cite web", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 22], [23, 24], [25, 31], [32, 34], [35, 43], [43, 44], [45, 51], [52, 55], [56, 63], [64, 66], [67, 69], [70, 78], [79, 82], [83, 89], [90, 99], [100, 102], [103, 107], [108, 111], [112, 122], [123, 125], [126, 135], [136, 138], [139, 155], [156, 160], [161, 163], [164, 177], [178, 180], [181, 186], [187, 197], [198, 207], [207, 208], [209, 211], [212, 224], [225, 229], [230, 232], [233, 247], [248, 250], [251, 259], [260, 262], [263, 265], [266, 273], [274, 282], [283, 286], [287, 289], [290, 296], [297, 301], [302, 312], [313, 314], [314, 315], [315, 319], [320, 323]]}
{"doc_key": "ai-dev-249", "ner": [[16, 18, "metrics"], [21, 23, "metrics"], [25, 28, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Cuando", "el", "valor", "que", "se", "predice", "est\u00e1", "distribuido", "de", "forma", "continua", ",", "se", "puede", "utilizar", "el", "error", "cuadr\u00e1tico", "medio", ",", "el", "error", "cuadr\u00e1tico", "medio", "o", "la", "desviaci\u00f3n", "absoluta", "media", "para", "resumir", "los", "errores", "."], "sentence-detokenized": "Cuando el valor que se predice est\u00e1 distribuido de forma continua, se puede utilizar el error cuadr\u00e1tico medio, el error cuadr\u00e1tico medio o la desviaci\u00f3n absoluta media para resumir los errores.", "token2charspan": [[0, 6], [7, 9], [10, 15], [16, 19], [20, 22], [23, 30], [31, 35], [36, 47], [48, 50], [51, 56], [57, 65], [65, 66], [67, 69], [70, 75], [76, 84], [85, 87], [88, 93], [94, 104], [105, 110], [110, 111], [112, 114], [115, 120], [121, 131], [132, 137], [138, 139], [140, 142], [143, 153], [154, 162], [163, 168], [169, 173], [174, 181], [182, 185], [186, 193], [193, 194]]}
{"doc_key": "ai-dev-250", "ner": [[0, 2, "algorithm"], [20, 22, "field"]], "ner_mapping_to_source": [0, 2], "relations": [[0, 2, 20, 22, "part-of", "", true, false]], "relations_mapping_to_source": [1], "sentence": ["El", "clustering", "conceptual", "se", "desarroll\u00f3", "principalmente", "durante", "la", "d\u00e9cada", "de", "1980", ",", "como", "un", "paradigma", "de", "aprendizaje", "autom\u00e1tico", "para", "el", "aprendizaje", "no", "supervisado", "."], "sentence-detokenized": "El clustering conceptual se desarroll\u00f3 principalmente durante la d\u00e9cada de 1980, como un paradigma de aprendizaje autom\u00e1tico para el aprendizaje no supervisado.", "token2charspan": [[0, 2], [3, 13], [14, 24], [25, 27], [28, 38], [39, 53], [54, 61], [62, 64], [65, 71], [72, 74], [75, 79], [79, 80], [81, 85], [86, 88], [89, 98], [99, 101], [102, 113], [114, 124], [125, 129], [130, 132], [133, 144], [145, 147], [148, 159], [159, 160]]}
{"doc_key": "ai-dev-251", "ner": [[11, 12, "product"], [35, 37, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Si", "las", "entidades", "con", "nombre", "no", "pueden", "ser", "reconocidas", "por", "el", "traductor", "autom\u00e1tico", ",", "es", "posible", "que", "se", "traduzcan", "err\u00f3neamente", "como", "sustantivos", "comunes", ",", "lo", "que", "muy", "probablemente", "no", "afectar\u00eda", "a", "la", "calificaci\u00f3n", "de", "la", "evaluaci\u00f3n", "biling\u00fce", "de", "la", "traducci\u00f3n", ",", "pero", "s\u00ed", "cambiar\u00eda", "la", "legibilidad", "humana", "del", "texto", "."], "sentence-detokenized": "Si las entidades con nombre no pueden ser reconocidas por el traductor autom\u00e1tico, es posible que se traduzcan err\u00f3neamente como sustantivos comunes, lo que muy probablemente no afectar\u00eda a la calificaci\u00f3n de la evaluaci\u00f3n biling\u00fce de la traducci\u00f3n, pero s\u00ed cambiar\u00eda la legibilidad humana del texto.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 20], [21, 27], [28, 30], [31, 37], [38, 41], [42, 53], [54, 57], [58, 60], [61, 70], [71, 81], [81, 82], [83, 85], [86, 93], [94, 97], [98, 100], [101, 110], [111, 123], [124, 128], [129, 140], [141, 148], [148, 149], [150, 152], [153, 156], [157, 160], [161, 174], [175, 177], [178, 187], [188, 189], [190, 192], [193, 205], [206, 208], [209, 211], [212, 222], [223, 231], [232, 234], [235, 237], [238, 248], [248, 249], [250, 254], [255, 257], [258, 267], [268, 270], [271, 282], [283, 289], [290, 293], [294, 299], [299, 300]]}
{"doc_key": "ai-dev-252", "ner": [[0, 1, "researcher"], [10, 11, "misc"], [12, 18, "conference"], [20, 20, "location"], [22, 22, "country"], [35, 36, "researcher"], [45, 45, "researcher"], [47, 50, "university"], [53, 54, "researcher"], [56, 57, "researcher"], [59, 60, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 11, "related-to", "writes_about", false, false], [0, 1, 12, 18, "temporal", "", true, false], [12, 18, 20, 20, "physical", "", false, false], [20, 20, 22, 22, "physical", "", false, false], [45, 45, 47, 50, "physical", "", false, false], [45, 45, 47, 50, "role", "", false, false], [53, 54, 47, 50, "physical", "", false, false], [53, 54, 47, 50, "role", "", false, false], [56, 57, 47, 50, "physical", "", false, false], [56, 57, 47, 50, "role", "", false, false], [59, 60, 47, 50, "physical", "", false, false], [59, 60, 47, 50, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Roger", "Schank", ",", "1969", ",", "A", "conceptual", "dependency", "parser", "for", "natural", "language", "Proceedings", "of", "the", "1969", "on", "Computational", "linguistics", ",", "S\u00e5ng-S\u00e4by", ",", "Suecia", ",", "p\u00e1ginas", "1-3", "Este", "modelo", ",", "parcialmente", "influenciado", "por", "el", "trabajo", "de", "Sydney", "Lamb", ",", "fue", "ampliamente", "utilizado", "por", "los", "estudiantes", "de", "Schank", "en", "la", "Universidad", "de", "Yale", ",", "como", "Robert", "Wilensky", ",", "Wendy", "Lehnert", "y", "Janet", "Kolodner", "."], "sentence-detokenized": "Roger Schank, 1969, A conceptual dependency parser for natural language Proceedings of the 1969 on Computational linguistics, S\u00e5ng-S\u00e4by, Suecia, p\u00e1ginas 1-3 Este modelo, parcialmente influenciado por el trabajo de Sydney Lamb, fue ampliamente utilizado por los estudiantes de Schank en la Universidad de Yale, como Robert Wilensky, Wendy Lehnert y Janet Kolodner.", "token2charspan": [[0, 5], [6, 12], [12, 13], [14, 18], [18, 19], [20, 21], [22, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 71], [72, 83], [84, 86], [87, 90], [91, 95], [96, 98], [99, 112], [113, 124], [124, 125], [126, 135], [135, 136], [137, 143], [143, 144], [145, 152], [153, 156], [157, 161], [162, 168], [168, 169], [170, 182], [183, 195], [196, 199], [200, 202], [203, 210], [211, 213], [214, 220], [221, 225], [225, 226], [227, 230], [231, 242], [243, 252], [253, 256], [257, 260], [261, 272], [273, 275], [276, 282], [283, 285], [286, 288], [289, 300], [301, 303], [304, 308], [308, 309], [310, 314], [315, 321], [322, 330], [330, 331], [332, 337], [338, 345], [346, 347], [348, 353], [354, 362], [362, 363]]}
{"doc_key": "ai-dev-253", "ner": [[0, 4, "algorithm"], [7, 7, "algorithm"], [15, 15, "algorithm"], [17, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 0, 4, "named", "", false, false], [15, 15, 0, 4, "named", "", false, false], [17, 19, 0, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["El", "m\u00e9todo", "de", "m\u00e1xima", "verosimilitud", "mejorado", "(", "IMLM", ")", "es", "una", "combinaci\u00f3n", "de", "dos", "estimadores", "MLM", "(", "de", "m\u00e1xima", "verosimilitud", ")", "."], "sentence-detokenized": "El m\u00e9todo de m\u00e1xima verosimilitud mejorado (IMLM) es una combinaci\u00f3n de dos estimadores MLM (de m\u00e1xima verosimilitud).", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 19], [20, 33], [34, 42], [43, 44], [44, 48], [48, 49], [50, 52], [53, 56], [57, 68], [69, 71], [72, 75], [76, 87], [88, 91], [92, 93], [93, 95], [96, 102], [103, 116], [116, 117], [117, 118]]}
{"doc_key": "ai-dev-254", "ner": [[24, 26, "metrics"], [29, 31, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[29, 31, 24, 26, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Estos", "m\u00e9todos", "tambi\u00e9n", "pueden", "analizar", "el", "resultado", "de", "un", "programa", "y", "su", "utilidad", "y", ",", "por", "tanto", ",", "pueden", "implicar", "el", "an\u00e1lisis", "de", "su", "matriz", "de", "confusi\u00f3n", "(", "o", "tabla", "de", "confusi\u00f3n", ")", "."], "sentence-detokenized": "Estos m\u00e9todos tambi\u00e9n pueden analizar el resultado de un programa y su utilidad y, por tanto, pueden implicar el an\u00e1lisis de su matriz de confusi\u00f3n (o tabla de confusi\u00f3n).", "token2charspan": [[0, 5], [6, 13], [14, 21], [22, 28], [29, 37], [38, 40], [41, 50], [51, 53], [54, 56], [57, 65], [66, 67], [68, 70], [71, 79], [80, 81], [81, 82], [83, 86], [87, 92], [92, 93], [94, 100], [101, 109], [110, 112], [113, 121], [122, 124], [125, 127], [128, 134], [135, 137], [138, 147], [148, 149], [149, 150], [151, 156], [157, 159], [160, 169], [169, 170], [170, 171]]}
{"doc_key": "ai-dev-255", "ner": [[0, 0, "product"], [7, 8, "researcher"], [10, 11, "researcher"], [13, 15, "researcher"], [21, 28, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 7, 8, "origin", "", false, false], [0, 0, 10, 11, "origin", "", false, false], [0, 0, 13, 15, "origin", "", false, false], [0, 0, 21, 28, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SURF", "fue", "publicado", "por", "primera", "vez", "por", "Herbert", "Bay", ",", "Tinne", "Tuytelaars", "y", "Luc", "Van", "Gool", ",", "y", "presentado", "en", "la", "Conferencia", "Europea", "de", "Visi\u00f3n", "por", "Ordenador", "de", "2006", "."], "sentence-detokenized": "SURF fue publicado por primera vez por Herbert Bay, Tinne Tuytelaars y Luc Van Gool, y presentado en la Conferencia Europea de Visi\u00f3n por Ordenador de 2006.", "token2charspan": [[0, 4], [5, 8], [9, 18], [19, 22], [23, 30], [31, 34], [35, 38], [39, 46], [47, 50], [50, 51], [52, 57], [58, 68], [69, 70], [71, 74], [75, 78], [79, 83], [83, 84], [85, 86], [87, 97], [98, 100], [101, 103], [104, 115], [116, 123], [124, 126], [127, 133], [134, 137], [138, 147], [148, 150], [151, 155], [155, 156]]}
{"doc_key": "ai-dev-256", "ner": [[0, 1, "task"], [9, 11, "field"], [14, 15, "field"], [18, 20, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 9, 11, "part-of", "", false, false], [0, 1, 14, 15, "part-of", "", false, false], [0, 1, 18, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["El", "OCR", "es", "un", "campo", "de", "investigaci\u00f3n", "en", "el", "reconocimiento", "de", "patrones", ",", "la", "inteligencia", "artificial", "y", "la", "visi\u00f3n", "por", "ordenador", "."], "sentence-detokenized": "El OCR es un campo de investigaci\u00f3n en el reconocimiento de patrones, la inteligencia artificial y la visi\u00f3n por ordenador.", "token2charspan": [[0, 2], [3, 6], [7, 9], [10, 12], [13, 18], [19, 21], [22, 35], [36, 38], [39, 41], [42, 56], [57, 59], [60, 68], [68, 69], [70, 72], [73, 85], [86, 96], [97, 98], [99, 101], [102, 108], [109, 112], [113, 122], [122, 123]]}
{"doc_key": "ai-dev-257", "ner": [[6, 9, "metrics"], [12, 16, "algorithm"], [18, 18, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 18, 12, 16, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Siguiendo", "con", "el", "ejemplo", "utilizando", "el", "estimador", "de", "m\u00e1xima", "verosimilitud", ",", "la", "funci\u00f3n", "de", "densidad", "de", "probabilidad", "(", "pdf", ")", "del", "ruido", "para", "una", "muestra", "mathwn", "/", "math", "es"], "sentence-detokenized": "Siguiendo con el ejemplo utilizando el estimador de m\u00e1xima verosimilitud, la funci\u00f3n de densidad de probabilidad (pdf) del ruido para una muestra mathwn / math es", "token2charspan": [[0, 9], [10, 13], [14, 16], [17, 24], [25, 35], [36, 38], [39, 48], [49, 51], [52, 58], [59, 72], [72, 73], [74, 76], [77, 84], [85, 87], [88, 96], [97, 99], [100, 112], [113, 114], [114, 117], [117, 118], [119, 122], [123, 128], [129, 133], [134, 137], [138, 145], [146, 152], [153, 154], [155, 159], [160, 162]]}
{"doc_key": "ai-dev-258", "ner": [[4, 7, "field"], [11, 13, "task"], [16, 18, "task"], [21, 23, "task"], [26, 28, "task"], [31, 36, "task"], [39, 39, "task"], [42, 42, "task"], [45, 47, "task"], [50, 51, "task"], [54, 58, "task"], [61, 63, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[11, 13, 4, 7, "part-of", "", false, false], [16, 18, 4, 7, "part-of", "", false, false], [21, 23, 4, 7, "part-of", "", false, false], [26, 28, 4, 7, "part-of", "", false, false], [31, 36, 4, 7, "part-of", "", false, false], [39, 39, 4, 7, "part-of", "", false, false], [42, 42, 4, 7, "part-of", "", false, false], [45, 47, 4, 7, "part-of", "", false, false], [50, 51, 4, 7, "part-of", "", false, false], [54, 58, 4, 7, "part-of", "", false, false], [61, 63, 4, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Entre", "los", "subdominios", "de", "la", "visi\u00f3n", "por", "ordenador", "se", "encuentran", "la", "reconstrucci\u00f3n", "de", "escenas", ",", "la", "detecci\u00f3n", "de", "eventos", ",", "el", "seguimiento", "de", "v\u00eddeos", ",", "el", "reconocimiento", "de", "objetos", ",", "la", "estimaci\u00f3n", "de", "la", "postura", "en", "3D", ",", "el", "aprendizaje", ",", "la", "indexaci\u00f3n", ",", "la", "estimaci\u00f3n", "del", "movimiento", ",", "la", "servoformaci\u00f3n", "visual", ",", "el", "modelado", "de", "escenas", "en", "3D", "y", "la", "restauraci\u00f3n", "de", "im\u00e1genes", "."], "sentence-detokenized": "Entre los subdominios de la visi\u00f3n por ordenador se encuentran la reconstrucci\u00f3n de escenas, la detecci\u00f3n de eventos, el seguimiento de v\u00eddeos, el reconocimiento de objetos, la estimaci\u00f3n de la postura en 3D, el aprendizaje, la indexaci\u00f3n, la estimaci\u00f3n del movimiento, la servoformaci\u00f3n visual, el modelado de escenas en 3D y la restauraci\u00f3n de im\u00e1genes.", "token2charspan": [[0, 5], [6, 9], [10, 21], [22, 24], [25, 27], [28, 34], [35, 38], [39, 48], [49, 51], [52, 62], [63, 65], [66, 80], [81, 83], [84, 91], [91, 92], [93, 95], [96, 105], [106, 108], [109, 116], [116, 117], [118, 120], [121, 132], [133, 135], [136, 142], [142, 143], [144, 146], [147, 161], [162, 164], [165, 172], [172, 173], [174, 176], [177, 187], [188, 190], [191, 193], [194, 201], [202, 204], [205, 207], [207, 208], [209, 211], [212, 223], [223, 224], [225, 227], [228, 238], [238, 239], [240, 242], [243, 253], [254, 257], [258, 268], [268, 269], [270, 272], [273, 287], [288, 294], [294, 295], [296, 298], [299, 307], [308, 310], [311, 318], [319, 321], [322, 324], [325, 326], [327, 329], [330, 342], [343, 345], [346, 354], [354, 355]]}
{"doc_key": "ai-dev-259", "ner": [[5, 10, "conference"], [12, 14, "researcher"], [17, 18, "misc"], [23, 26, "conference"], [28, 28, "researcher"], [30, 30, "researcher"], [33, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 10, 23, 26, "named", "", false, false], [12, 14, 17, 18, "win-defeat", "", false, false], [12, 14, 33, 35, "related-to", "writes_about", true, false], [17, 18, 5, 10, "temporal", "", false, false], [28, 28, 17, 18, "win-defeat", "", false, true], [28, 28, 33, 35, "related-to", "writes_about", true, false], [30, 30, 17, 18, "win-defeat", "", false, true], [30, 30, 33, 35, "related-to", "writes_about", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["En", "2013", ",", "en", "la", "Conferencia", "Internacional", "de", "Visi\u00f3n", "por", "Computador", ",", "Terzopoulos", "fue", "galardonado", "con", "el", "Premio", "Helmholtz", "por", "su", "trabajo", "de", "1987", "en", "el", "ICCV", "con", "Kass", "y", "Witkin", "sobre", "modelos", "de", "contorno", "activo", "."], "sentence-detokenized": "En 2013, en la Conferencia Internacional de Visi\u00f3n por Computador, Terzopoulos fue galardonado con el Premio Helmholtz por su trabajo de 1987 en el ICCV con Kass y Witkin sobre modelos de contorno activo.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 14], [15, 26], [27, 40], [41, 43], [44, 50], [51, 54], [55, 65], [65, 66], [67, 78], [79, 82], [83, 94], [95, 98], [99, 101], [102, 108], [109, 118], [119, 122], [123, 125], [126, 133], [134, 136], [137, 141], [142, 144], [145, 147], [148, 152], [153, 156], [157, 161], [162, 163], [164, 170], [171, 176], [177, 184], [185, 187], [188, 196], [197, 203], [203, 204]]}
{"doc_key": "ai-dev-260", "ner": [[20, 21, "task"], [27, 27, "algorithm"], [30, 34, "algorithm"], [35, 35, "algorithm"], [38, 40, "algorithm"], [44, 45, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 21, 27, 27, "usage", "", true, false], [20, 21, 30, 34, "usage", "", true, false], [20, 21, 35, 35, "usage", "", true, false], [20, 21, 38, 40, "usage", "", true, false], [20, 21, 44, 45, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Si", "la", "funci\u00f3n", "de", "regularizaci\u00f3n", "Existen", "muchos", "algoritmos", "para", "resolver", "este", "tipo", "de", "problemas", ";", "los", "m\u00e1s", "populares", "para", "la", "clasificaci\u00f3n", "lineal", "son", "el", "descenso", "de", "gradiente", "estoc\u00e1stico", ")", "el", "descenso", "de", "gradiente", ",", "el", "L-BFGS", ",", "el", "descenso", "de", "coordenadas", "y", "los", "m\u00e9todos", "de", "Newton", "."], "sentence-detokenized": "Si la funci\u00f3n de regularizaci\u00f3n Existen muchos algoritmos para resolver este tipo de problemas; los m\u00e1s populares para la clasificaci\u00f3n lineal son el descenso de gradiente estoc\u00e1stico) el descenso de gradiente, el L-BFGS, el descenso de coordenadas y los m\u00e9todos de Newton.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 31], [32, 39], [40, 46], [47, 57], [58, 62], [63, 71], [72, 76], [77, 81], [82, 84], [85, 94], [94, 95], [96, 99], [100, 103], [104, 113], [114, 118], [119, 121], [122, 135], [136, 142], [143, 146], [147, 149], [150, 158], [159, 161], [162, 171], [172, 183], [183, 184], [185, 187], [188, 196], [197, 199], [200, 209], [209, 210], [211, 213], [214, 220], [220, 221], [222, 224], [225, 233], [234, 236], [237, 248], [249, 250], [251, 254], [255, 262], [263, 265], [266, 272], [272, 273]]}
{"doc_key": "ai-dev-261", "ner": [[3, 6, "algorithm"], [8, 8, "algorithm"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 6, 13, 14, "origin", "", false, false], [8, 8, 3, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Las", "redes", "de", "memoria", "a", "corto", "plazo", "(", "LSTM", ")", "fueron", "inventadas", "por", "Sepp", "Hochreiter", "y", "J\u00fcrgen", "Schmidhuber", "en", "1997", "y", "establecieron", "r\u00e9cords", "de", "precisi\u00f3n", "en", "m\u00faltiples", "dominios", "de", "aplicaci\u00f3n", "."], "sentence-detokenized": "Las redes de memoria a corto plazo (LSTM) fueron inventadas por Sepp Hochreiter y J\u00fcrgen Schmidhuber en 1997 y establecieron r\u00e9cords de precisi\u00f3n en m\u00faltiples dominios de aplicaci\u00f3n.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 20], [21, 22], [23, 28], [29, 34], [35, 36], [36, 40], [40, 41], [42, 48], [49, 59], [60, 63], [64, 68], [69, 79], [80, 81], [82, 88], [89, 100], [101, 103], [104, 108], [109, 110], [111, 124], [125, 132], [133, 135], [136, 145], [146, 148], [149, 158], [159, 167], [168, 170], [171, 181], [181, 182]]}
{"doc_key": "ai-dev-262", "ner": [[0, 0, "product"], [5, 8, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 5, 8, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["TN", "se", "desarroll\u00f3", "en", "el", "Hospital", "General", "de", "Massachusetts", "y", "se", "prob\u00f3", "en", "m\u00faltiples", "escenarios", ",", "incluyendo", "la", "extracci\u00f3n", "del", "estado", "de", "tabaquismo", ",", "los", "antecedentes", "familiares", "de", "enfermedad", "arterial", "coronaria", ",", "la", "identificaci\u00f3n", "de", "pacientes", "con", "trastornos", "del", "sue\u00f1o", ","], "sentence-detokenized": "TN se desarroll\u00f3 en el Hospital General de Massachusetts y se prob\u00f3 en m\u00faltiples escenarios, incluyendo la extracci\u00f3n del estado de tabaquismo, los antecedentes familiares de enfermedad arterial coronaria, la identificaci\u00f3n de pacientes con trastornos del sue\u00f1o,", "token2charspan": [[0, 2], [3, 5], [6, 16], [17, 19], [20, 22], [23, 31], [32, 39], [40, 42], [43, 56], [57, 58], [59, 61], [62, 67], [68, 70], [71, 80], [81, 91], [91, 92], [93, 103], [104, 106], [107, 117], [118, 121], [122, 128], [129, 131], [132, 142], [142, 143], [144, 147], [148, 160], [161, 171], [172, 174], [175, 185], [186, 194], [195, 204], [204, 205], [206, 208], [209, 223], [224, 226], [227, 236], [237, 240], [241, 251], [252, 255], [256, 261], [261, 262]]}
{"doc_key": "ai-dev-263", "ner": [[3, 3, "researcher"], [9, 9, "product"], [17, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 9, 9, "role", "sells", false, false], [9, 9, 17, 18, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["En", "1960", ",", "Devol", "vendi\u00f3", "personalmente", "el", "primer", "robot", "Unimate", ",", "que", "fue", "enviado", "en", "1961", "a", "General", "Motors", "."], "sentence-detokenized": "En 1960, Devol vendi\u00f3 personalmente el primer robot Unimate, que fue enviado en 1961 a General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 21], [22, 35], [36, 38], [39, 45], [46, 51], [52, 59], [59, 60], [61, 64], [65, 68], [69, 76], [77, 79], [80, 84], [85, 86], [87, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-dev-264", "ner": [[1, 3, "conference"], [16, 17, "location"], [19, 19, "location"], [21, 21, "country"], [35, 37, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 3, 16, 17, "physical", "", false, false], [16, 17, 19, 19, "physical", "", false, false], [19, 19, 21, 21, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "Campus", "Party", "Europa", "se", "celebr\u00f3", "del", "14", "al", "18", "de", "abril", "de", "2010", "en", "la", "Caja", "M\u00e1gica", "de", "Madrid", ",", "Espa\u00f1a", ",", "con", "800", "participantes", "de", "cada", "uno", "de", "los", "27", "estados", "miembros", "de", "la", "Uni\u00f3n", "Europea", "."], "sentence-detokenized": "La Campus Party Europa se celebr\u00f3 del 14 al 18 de abril de 2010 en la Caja M\u00e1gica de Madrid, Espa\u00f1a, con 800 participantes de cada uno de los 27 estados miembros de la Uni\u00f3n Europea.", "token2charspan": [[0, 2], [3, 9], [10, 15], [16, 22], [23, 25], [26, 33], [34, 37], [38, 40], [41, 43], [44, 46], [47, 49], [50, 55], [56, 58], [59, 63], [64, 66], [67, 69], [70, 74], [75, 81], [82, 84], [85, 91], [91, 92], [93, 99], [99, 100], [101, 104], [105, 108], [109, 122], [123, 125], [126, 130], [131, 134], [135, 137], [138, 141], [142, 144], [145, 152], [153, 161], [162, 164], [165, 167], [168, 173], [174, 181], [181, 182]]}
{"doc_key": "ai-dev-265", "ner": [[10, 10, "organisation"], [13, 15, "organisation"], [18, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 24, 10, 10, "origin", "", false, false], [18, 24, 13, 15, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["En", "julio", "de", "2016", ",", "se", "anunci\u00f3", "una", "colaboraci\u00f3n", "entre", "DeepMind", "y", "el", "Moorfields", "Eye", "Hospital", "para", "desarrollar", "aplicaciones", "de", "IA", "para", "la", "atenci\u00f3n", "sanitaria", "."], "sentence-detokenized": "En julio de 2016, se anunci\u00f3 una colaboraci\u00f3n entre DeepMind y el Moorfields Eye Hospital para desarrollar aplicaciones de IA para la atenci\u00f3n sanitaria.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 16], [16, 17], [18, 20], [21, 28], [29, 32], [33, 45], [46, 51], [52, 60], [61, 62], [63, 65], [66, 76], [77, 80], [81, 89], [90, 94], [95, 106], [107, 119], [120, 122], [123, 125], [126, 130], [131, 133], [134, 142], [143, 152], [152, 153]]}
{"doc_key": "ai-dev-266", "ner": [[3, 3, "misc"], [11, 13, "university"], [15, 15, "university"], [17, 18, "university"], [20, 21, "university"], [23, 23, "university"], [25, 25, "university"], [27, 30, "university"], [32, 33, "university"], [35, 36, "university"], [38, 38, "university"], [41, 43, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[3, 3, 11, 13, "physical", "", false, false], [3, 3, 15, 15, "physical", "", false, false], [3, 3, 17, 18, "physical", "", false, false], [3, 3, 20, 21, "physical", "", false, false], [3, 3, 23, 23, "physical", "", false, false], [3, 3, 25, 25, "physical", "", false, false], [3, 3, 27, 30, "physical", "", false, false], [3, 3, 32, 33, "physical", "", false, false], [3, 3, 35, 36, "physical", "", false, false], [3, 3, 38, 38, "physical", "", false, false], [3, 3, 41, 43, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Acabaron", "concediendo", "once", "PR2", "a", "diferentes", "instituciones", ",", "entre", "ellas", "la", "Universidad", "de", "Friburgo", ",", "Bosch", ",", "Georgia", "Tech", ",", "KU", "Leuven", ",", "MIT", ",", "Stanford", ",", "Universidad", "T\u00e9cnica", "de", "M\u00fanich", ",", "UC", "Berkeley", ",", "U", "Penn", ",", "USC", "y", "la", "Universidad", "de", "Tokio", "."], "sentence-detokenized": "Acabaron concediendo once PR2 a diferentes instituciones, entre ellas la Universidad de Friburgo, Bosch, Georgia Tech, KU Leuven, MIT, Stanford, Universidad T\u00e9cnica de M\u00fanich, UC Berkeley, U Penn, USC y la Universidad de Tokio.", "token2charspan": [[0, 8], [9, 20], [21, 25], [26, 29], [30, 31], [32, 42], [43, 56], [56, 57], [58, 63], [64, 69], [70, 72], [73, 84], [85, 87], [88, 96], [96, 97], [98, 103], [103, 104], [105, 112], [113, 117], [117, 118], [119, 121], [122, 128], [128, 129], [130, 133], [133, 134], [135, 143], [143, 144], [145, 156], [157, 164], [165, 167], [168, 174], [174, 175], [176, 178], [179, 187], [187, 188], [189, 190], [191, 195], [195, 196], [197, 200], [201, 202], [203, 205], [206, 217], [218, 220], [221, 226], [226, 227]]}
{"doc_key": "ai-dev-267", "ner": [[3, 3, "metrics"], [5, 5, "metrics"], [7, 7, "metrics"], [9, 9, "metrics"], [18, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 18, 20, "part-of", "", false, false], [5, 5, 18, 20, "part-of", "", false, false], [7, 7, 18, 20, "part-of", "", false, false], [9, 9, 18, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Los", "recuentos", "de", "TP", ",", "TN", ",", "FP", "y", "FN", "se", "suelen", "guardar", "en", "una", "tabla", "conocida", "como", "matriz", "de", "confusi\u00f3n", "."], "sentence-detokenized": "Los recuentos de TP, TN, FP y FN se suelen guardar en una tabla conocida como matriz de confusi\u00f3n.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 19], [19, 20], [21, 23], [23, 24], [25, 27], [28, 29], [30, 32], [33, 35], [36, 42], [43, 50], [51, 53], [54, 57], [58, 63], [64, 72], [73, 77], [78, 84], [85, 87], [88, 97], [97, 98]]}
{"doc_key": "ai-dev-268", "ner": [[9, 11, "metrics"], [14, 15, "metrics"], [18, 19, "metrics"], [22, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Como", "conjunto", "de", "caracter\u00edsticas", ",", "se", "suelen", "utilizar", "la", "ganancia", "de", "informaci\u00f3n", ",", "la", "entrop\u00eda", "cruzada", ",", "la", "informaci\u00f3n", "mutua", "y", "la", "proporci\u00f3n", "de", "probabilidades", "."], "sentence-detokenized": "Como conjunto de caracter\u00edsticas, se suelen utilizar la ganancia de informaci\u00f3n, la entrop\u00eda cruzada, la informaci\u00f3n mutua y la proporci\u00f3n de probabilidades.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 32], [32, 33], [34, 36], [37, 43], [44, 52], [53, 55], [56, 64], [65, 67], [68, 79], [79, 80], [81, 83], [84, 92], [93, 100], [100, 101], [102, 104], [105, 116], [117, 122], [123, 124], [125, 127], [128, 138], [139, 141], [142, 156], [156, 157]]}
{"doc_key": "ai-dev-269", "ner": [[10, 13, "task"], [16, 18, "task"], [20, 21, "task"], [23, 24, "task"], [27, 27, "task"], [29, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[29, 29, 27, 27, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Se", "ha", "aplicado", "con", "\u00e9xito", "a", "diversos", "problemas", ",", "como", "el", "control", "de", "robots", ",", "la", "programaci\u00f3n", "de", "ascensores", ",", "las", "telecomunicaciones", ",", "las", "damas", "y", "el", "Go", "(", "AlphaGo", ")", "."], "sentence-detokenized": "Se ha aplicado con \u00e9xito a diversos problemas, como el control de robots, la programaci\u00f3n de ascensores, las telecomunicaciones, las damas y el Go (AlphaGo).", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 18], [19, 24], [25, 26], [27, 35], [36, 45], [45, 46], [47, 51], [52, 54], [55, 62], [63, 65], [66, 72], [72, 73], [74, 76], [77, 89], [90, 92], [93, 103], [103, 104], [105, 108], [109, 127], [127, 128], [129, 132], [133, 138], [139, 140], [141, 143], [144, 146], [147, 148], [148, 155], [155, 156], [156, 157]]}
{"doc_key": "ai-dev-270", "ner": [[13, 13, "misc"], [20, 24, "university"], [26, 26, "location"], [28, 28, "location"], [32, 36, "location"], [43, 48, "location"], [50, 50, "location"], [51, 51, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[13, 13, 20, 24, "physical", "", false, false], [20, 24, 26, 26, "physical", "", false, false], [26, 26, 28, 28, "physical", "", false, false], [32, 36, 43, 48, "physical", "", false, false], [43, 48, 50, 50, "physical", "", false, false], [50, 50, 51, 51, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["En", "2018", ",", "el", "a\u00f1o", "inaugural", "de", "la", "misi\u00f3n", "8", ",", "la", "sede", "americana", "se", "celebr\u00f3", "en", "el", "campus", "del", "Instituto", "de", "Tecnolog\u00eda", "de", "Georgia", "en", "Atlanta", ",", "Georgia", ",", "y", "la", "sede", "de", "Asia", "/", "Pac\u00edfico", "se", "llev\u00f3", "a", "cabo", "en", "el", "Gimnasio", "de", "la", "Universidad", "de", "Beihang", "en", "Beijing", "China", "."], "sentence-detokenized": "En 2018, el a\u00f1o inaugural de la misi\u00f3n 8, la sede americana se celebr\u00f3 en el campus del Instituto de Tecnolog\u00eda de Georgia en Atlanta, Georgia, y la sede de Asia / Pac\u00edfico se llev\u00f3 a cabo en el Gimnasio de la Universidad de Beihang en Beijing China.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 25], [26, 28], [29, 31], [32, 38], [39, 40], [40, 41], [42, 44], [45, 49], [50, 59], [60, 62], [63, 70], [71, 73], [74, 76], [77, 83], [84, 87], [88, 97], [98, 100], [101, 111], [112, 114], [115, 122], [123, 125], [126, 133], [133, 134], [135, 142], [142, 143], [144, 145], [146, 148], [149, 153], [154, 156], [157, 161], [162, 163], [164, 172], [173, 175], [176, 181], [182, 183], [184, 188], [189, 191], [192, 194], [195, 203], [204, 206], [207, 209], [210, 221], [222, 224], [225, 232], [233, 235], [236, 243], [244, 249], [249, 250]]}
{"doc_key": "ai-dev-271", "ner": [[0, 2, "field"], [8, 10, "field"], [16, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 8, 10, "origin", "", false, false], [0, 2, 8, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["El", "aprendizaje", "autom\u00e1tico", "est\u00e1", "muy", "relacionado", "con", "el", "reconocimiento", "de", "patrones", "y", "tiene", "su", "origen", "en", "la", "inteligencia", "artificial", "."], "sentence-detokenized": "El aprendizaje autom\u00e1tico est\u00e1 muy relacionado con el reconocimiento de patrones y tiene su origen en la inteligencia artificial.", "token2charspan": [[0, 2], [3, 14], [15, 25], [26, 30], [31, 34], [35, 46], [47, 50], [51, 53], [54, 68], [69, 71], [72, 80], [81, 82], [83, 88], [89, 91], [92, 98], [99, 101], [102, 104], [105, 117], [118, 128], [128, 129]]}
{"doc_key": "ai-dev-272", "ner": [[4, 4, "programlang"], [18, 19, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Viene", "con", "3", "juegos", "Java", "que", "se", "controlan", "con", "el", "mando", "a", "distancia", "y", "se", "muestran", "en", "su", "pantalla", "LCD", "."], "sentence-detokenized": "Viene con 3 juegos Java que se controlan con el mando a distancia y se muestran en su pantalla LCD.", "token2charspan": [[0, 5], [6, 9], [10, 11], [12, 18], [19, 23], [24, 27], [28, 30], [31, 40], [41, 44], [45, 47], [48, 53], [54, 55], [56, 65], [66, 67], [68, 70], [71, 79], [80, 82], [83, 85], [86, 94], [95, 98], [98, 99]]}
{"doc_key": "ai-dev-273", "ner": [[3, 16, "task"], [27, 30, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[27, 30, 3, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Una", "t\u00e9cnica", "de", "estimaci\u00f3n", "de", "la", "postura", "del", "cuerpo", "articulado", ",", "basada", "en", "la", "visi\u00f3n", "por", "ordenador", ",", "de", "gran", "\u00e9xito", "comercial", "pero", "especializada", ",", "es", "la", "captura", "\u00f3ptica", "de", "movimiento", "."], "sentence-detokenized": "Una t\u00e9cnica de estimaci\u00f3n de la postura del cuerpo articulado, basada en la visi\u00f3n por ordenador, de gran \u00e9xito comercial pero especializada, es la captura \u00f3ptica de movimiento.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 25], [26, 28], [29, 31], [32, 39], [40, 43], [44, 50], [51, 61], [61, 62], [63, 69], [70, 72], [73, 75], [76, 82], [83, 86], [87, 96], [96, 97], [98, 100], [101, 105], [106, 111], [112, 121], [122, 126], [127, 140], [140, 141], [142, 144], [145, 147], [148, 155], [156, 162], [163, 165], [166, 176], [176, 177]]}
{"doc_key": "ai-dev-274", "ner": [[1, 1, "organisation"], [8, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 1, 8, 10, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["El", "SMR", "es", "muy", "similar", "al", "m\u00e1s", "popular", "\u00edndice", "de", "Jaccard", "."], "sentence-detokenized": "El SMR es muy similar al m\u00e1s popular \u00edndice de Jaccard.", "token2charspan": [[0, 2], [3, 6], [7, 9], [10, 13], [14, 21], [22, 24], [25, 28], [29, 36], [37, 43], [44, 46], [47, 54], [54, 55]]}
{"doc_key": "ai-dev-275", "ner": [[1, 1, "product"], [3, 7, "product"], [10, 14, "product"], [23, 24, "researcher"], [31, 31, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 10, 14, "named", "", false, false], [1, 1, 23, 24, "artifact", "", false, false], [1, 1, 31, 31, "artifact", "", false, false], [3, 7, 1, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["El", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ",", "o", "brazo", "de", "manipulaci\u00f3n", "universal", "programable", ")", "es", "un", "brazo", "rob\u00f3tico", "industrial", "desarrollado", "por", "Victor", "Scheinman", "en", "la", "empresa", "pionera", "de", "rob\u00f3tica", "Unimation", "."], "sentence-detokenized": "El PUMA (Programmable Universal Machine for Assembly, o brazo de manipulaci\u00f3n universal programable) es un brazo rob\u00f3tico industrial desarrollado por Victor Scheinman en la empresa pionera de rob\u00f3tica Unimation.", "token2charspan": [[0, 2], [3, 7], [8, 9], [9, 21], [22, 31], [32, 39], [40, 43], [44, 52], [52, 53], [54, 55], [56, 61], [62, 64], [65, 77], [78, 87], [88, 99], [99, 100], [101, 103], [104, 106], [107, 112], [113, 121], [122, 132], [133, 145], [146, 149], [150, 156], [157, 166], [167, 169], [170, 172], [173, 180], [181, 188], [189, 191], [192, 200], [201, 210], [210, 211]]}
{"doc_key": "ai-dev-276", "ner": [[3, 3, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Est\u00e1", "escrito", "en", "Python", "."], "sentence-detokenized": "Est\u00e1 escrito en Python.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 22], [22, 23]]}
{"doc_key": "ai-dev-277", "ner": [[0, 3, "misc"], [5, 5, "misc"], [16, 16, "field"], [19, 22, "field"], [25, 26, "field"], [31, 34, "field"], [36, 37, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6, 7], "relations": [[0, 3, 5, 5, "related-to", "metric_for", true, false], [0, 3, 16, 16, "part-of", "", false, false], [0, 3, 19, 22, "part-of", "", false, false], [0, 3, 25, 26, "part-of", "", false, false], [0, 3, 31, 34, "part-of", "", false, false], [0, 3, 36, 37, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5, 6], "sentence": ["El", "ancho", "de", "banda", "en", "hercios", "es", "un", "concepto", "central", "en", "muchos", "campos", ",", "como", "la", "electr\u00f3nica", ",", "la", "teor\u00eda", "de", "la", "informaci\u00f3n", ",", "las", "comunicaciones", "digitales", ",", "las", "radiocomunicaciones", ",", "el", "procesamiento", "de", "se\u00f1ales", "y", "la", "espectroscopia", ",", "y", "es", "uno", "de", "los", "determinantes", "de", "la", "capacidad", "de", "un", "determinado", "canal", "de", "comunicaci\u00f3n", "."], "sentence-detokenized": "El ancho de banda en hercios es un concepto central en muchos campos, como la electr\u00f3nica, la teor\u00eda de la informaci\u00f3n, las comunicaciones digitales, las radiocomunicaciones, el procesamiento de se\u00f1ales y la espectroscopia, y es uno de los determinantes de la capacidad de un determinado canal de comunicaci\u00f3n.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 17], [18, 20], [21, 28], [29, 31], [32, 34], [35, 43], [44, 51], [52, 54], [55, 61], [62, 68], [68, 69], [70, 74], [75, 77], [78, 89], [89, 90], [91, 93], [94, 100], [101, 103], [104, 106], [107, 118], [118, 119], [120, 123], [124, 138], [139, 148], [148, 149], [150, 153], [154, 173], [173, 174], [175, 177], [178, 191], [192, 194], [195, 202], [203, 204], [205, 207], [208, 222], [222, 223], [224, 225], [226, 228], [229, 232], [233, 235], [236, 239], [240, 253], [254, 256], [257, 259], [260, 269], [270, 272], [273, 275], [276, 287], [288, 293], [294, 296], [297, 309], [309, 310]]}
{"doc_key": "ai-dev-278", "ner": [[9, 9, "algorithm"], [11, 11, "algorithm"], [17, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 17, 21, "part-of", "", false, false], [11, 11, 17, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Si", "se", "utiliza", "una", "p\u00e9rdida", "convexa", "(", "como", "en", "AdaBoost", ",", "LogitBoost", "y", "todos", "los", "miembros", "de", "la", "familia", "de", "algoritmos", "AnyBoost", ")", ",", "un", "ejemplo", "con", "mayor", "margen", "recibir\u00e1", "menos", "(", "o", "igual", ")", "peso", "que", "un", "ejemplo", "con", "menor", "margen", "."], "sentence-detokenized": "Si se utiliza una p\u00e9rdida convexa (como en AdaBoost, LogitBoost y todos los miembros de la familia de algoritmos AnyBoost), un ejemplo con mayor margen recibir\u00e1 menos (o igual) peso que un ejemplo con menor margen.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 17], [18, 25], [26, 33], [34, 35], [35, 39], [40, 42], [43, 51], [51, 52], [53, 63], [64, 65], [66, 71], [72, 75], [76, 84], [85, 87], [88, 90], [91, 98], [99, 101], [102, 112], [113, 121], [121, 122], [122, 123], [124, 126], [127, 134], [135, 138], [139, 144], [145, 151], [152, 160], [161, 166], [167, 168], [168, 169], [170, 175], [175, 176], [177, 181], [182, 185], [186, 188], [189, 196], [197, 200], [201, 206], [207, 213], [213, 214]]}
{"doc_key": "ai-dev-279", "ner": [[4, 9, "researcher"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Tesis", "de", "diploma", "de", "Sepp", "Hochreiter", "de", "1991", "Sepp", "Hochreiter", "."], "sentence-detokenized": "Tesis de diploma de Sepp Hochreiter de 1991 Sepp Hochreiter.", "token2charspan": [[0, 5], [6, 8], [9, 16], [17, 19], [20, 24], [25, 35], [36, 38], [39, 43], [44, 48], [49, 59], [59, 60]]}
{"doc_key": "ai-dev-280", "ner": [[6, 7, "algorithm"], [9, 9, "algorithm"], [15, 17, "algorithm"], [19, 19, "algorithm"], [23, 25, "algorithm"], [27, 27, "algorithm"], [33, 35, "algorithm"], [39, 41, "algorithm"], [44, 45, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[9, 9, 6, 7, "named", "", false, false], [19, 19, 15, 17, "named", "", false, false], [23, 25, 33, 35, "related-to", "", true, false], [27, 27, 23, 25, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Los", "modelos", "discriminativos", "t\u00edpicos", "incluyen", "la", "regresi\u00f3n", "log\u00edstica", "(", "LR", ")", ",", "las", "m\u00e1quinas", "de", "vectores", "de", "apoyo", "(", "SVM", ")", ",", "los", "campos", "aleatorios", "condicionales", "(", "CRF", ")", "(", "especificados", "sobre", "un", "gr\u00e1fico", "no", "dirigido", ")", ",", "los", "\u00e1rboles", "de", "decisi\u00f3n", ",", "las", "redes", "neuronales", "y", "muchos", "otros", "."], "sentence-detokenized": "Los modelos discriminativos t\u00edpicos incluyen la regresi\u00f3n log\u00edstica (LR), las m\u00e1quinas de vectores de apoyo (SVM), los campos aleatorios condicionales (CRF) (especificados sobre un gr\u00e1fico no dirigido), los \u00e1rboles de decisi\u00f3n, las redes neuronales y muchos otros.", "token2charspan": [[0, 3], [4, 11], [12, 27], [28, 35], [36, 44], [45, 47], [48, 57], [58, 67], [68, 69], [69, 71], [71, 72], [72, 73], [74, 77], [78, 86], [87, 89], [90, 98], [99, 101], [102, 107], [108, 109], [109, 112], [112, 113], [113, 114], [115, 118], [119, 125], [126, 136], [137, 150], [151, 152], [152, 155], [155, 156], [157, 158], [158, 171], [172, 177], [178, 180], [181, 188], [189, 191], [192, 200], [200, 201], [201, 202], [203, 206], [207, 214], [215, 217], [218, 226], [226, 227], [228, 231], [232, 237], [238, 248], [249, 250], [251, 257], [258, 263], [263, 264]]}
{"doc_key": "ai-dev-281", "ner": [[10, 12, "metrics"], [34, 36, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Entonces", "tambi\u00e9n", "es", "posible", "utilizar", "estas", "probabilidades", "y", "evaluar", "el", "error", "cuadr\u00e1tico", "medio", "(", "o", "alguna", "otra", "medida", "similar", ")", "entre", "las", "probabilidades", "y", "los", "valores", "reales", ",", "y", "luego", "combinar", "esto", "con", "la", "matriz", "de", "confusi\u00f3n", "para", "crear", "funciones", "de", "aptitud", "muy", "eficientes", "para", "la", "regresi\u00f3n", "log\u00edstica", "."], "sentence-detokenized": "Entonces tambi\u00e9n es posible utilizar estas probabilidades y evaluar el error cuadr\u00e1tico medio (o alguna otra medida similar) entre las probabilidades y los valores reales, y luego combinar esto con la matriz de confusi\u00f3n para crear funciones de aptitud muy eficientes para la regresi\u00f3n log\u00edstica.", "token2charspan": [[0, 8], [9, 16], [17, 19], [20, 27], [28, 36], [37, 42], [43, 57], [58, 59], [60, 67], [68, 70], [71, 76], [77, 87], [88, 93], [94, 95], [95, 96], [97, 103], [104, 108], [109, 115], [116, 123], [123, 124], [125, 130], [131, 134], [135, 149], [150, 151], [152, 155], [156, 163], [164, 170], [170, 171], [172, 173], [174, 179], [180, 188], [189, 193], [194, 197], [198, 200], [201, 207], [208, 210], [211, 220], [221, 225], [226, 231], [232, 241], [242, 244], [245, 252], [253, 256], [257, 267], [268, 272], [273, 275], [276, 285], [286, 295], [295, 296]]}
{"doc_key": "ai-dev-282", "ner": [[0, 1, "product"], [8, 11, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 8, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VoiceOver", "apareci\u00f3", "por", "primera", "vez", "en", "2005", "en", "Mac", "OS", "X", "Tiger", "(", "10.4", ")", "."], "sentence-detokenized": "VoiceOver apareci\u00f3 por primera vez en 2005 en Mac OS X Tiger (10.4).", "token2charspan": [[0, 9], [10, 18], [19, 22], [23, 30], [31, 34], [35, 37], [38, 42], [43, 45], [46, 49], [50, 52], [53, 54], [55, 60], [61, 62], [62, 66], [66, 67], [67, 68]]}
{"doc_key": "ai-dev-283", "ner": [[15, 16, "algorithm"], [19, 21, "misc"], [26, 28, "metrics"], [31, 35, "algorithm"], [67, 70, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 16, 19, 21, "related-to", "applied_to", false, false], [26, 28, 19, 21, "type-of", "", false, false], [26, 28, 31, 35, "related-to", "used_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["En", "la", "pr\u00e1ctica", ",", "los", "algoritmos", "de", "aprendizaje", "autom\u00e1tico", "hacen", "frente", "a", "esto", "empleando", "una", "aproximaci\u00f3n", "convexa", "a", "la", "funci\u00f3n", "de", "p\u00e9rdida", "0-1", "(", "como", "la", "p\u00e9rdida", "de", "bisagra", "para", "la", "m\u00e1quina", "de", "vectores", "de", "apoyo", ")", ",", "que", "es", "m\u00e1s", "f\u00e1cil", "de", "optimizar", ",", "o", "imponiendo", "supuestos", "sobre", "la", "distribuci\u00f3n", "mathP", "(", "x", ",", "y", ")", "/", "math", "(", "y", "por", "lo", "tanto", "dejan", "de", "ser", "algoritmos", "de", "aprendizaje", "agn\u00f3sticos", "a", "los", "que", "se", "aplica", "el", "resultado", "anterior", ")", "."], "sentence-detokenized": "En la pr\u00e1ctica, los algoritmos de aprendizaje autom\u00e1tico hacen frente a esto empleando una aproximaci\u00f3n convexa a la funci\u00f3n de p\u00e9rdida 0-1 (como la p\u00e9rdida de bisagra para la m\u00e1quina de vectores de apoyo), que es m\u00e1s f\u00e1cil de optimizar, o imponiendo supuestos sobre la distribuci\u00f3n mathP (x, y) / math (y por lo tanto dejan de ser algoritmos de aprendizaje agn\u00f3sticos a los que se aplica el resultado anterior).", "token2charspan": [[0, 2], [3, 5], [6, 14], [14, 15], [16, 19], [20, 30], [31, 33], [34, 45], [46, 56], [57, 62], [63, 69], [70, 71], [72, 76], [77, 86], [87, 90], [91, 103], [104, 111], [112, 113], [114, 116], [117, 124], [125, 127], [128, 135], [136, 139], [140, 141], [141, 145], [146, 148], [149, 156], [157, 159], [160, 167], [168, 172], [173, 175], [176, 183], [184, 186], [187, 195], [196, 198], [199, 204], [204, 205], [205, 206], [207, 210], [211, 213], [214, 217], [218, 223], [224, 226], [227, 236], [236, 237], [238, 239], [240, 250], [251, 260], [261, 266], [267, 269], [270, 282], [283, 288], [289, 290], [290, 291], [291, 292], [293, 294], [294, 295], [296, 297], [298, 302], [303, 304], [304, 305], [306, 309], [310, 312], [313, 318], [319, 324], [325, 327], [328, 331], [332, 342], [343, 345], [346, 357], [358, 368], [369, 370], [371, 374], [375, 378], [379, 381], [382, 388], [389, 391], [392, 401], [402, 410], [410, 411], [411, 412]]}
{"doc_key": "ai-dev-284", "ner": [[0, 0, "misc"], [11, 14, "field"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 14, "usage", "", false, false], [0, 0, 23, 23, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Westworld", "(", "1973", ")", "fue", "el", "primer", "largometraje", "que", "utiliz\u00f3", "el", "procesamiento", "digital", "de", "im\u00e1genes", "para", "simular", "el", "punto", "de", "vista", "de", "un", "androide", "."], "sentence-detokenized": "Westworld (1973) fue el primer largometraje que utiliz\u00f3 el procesamiento digital de im\u00e1genes para simular el punto de vista de un androide.", "token2charspan": [[0, 9], [10, 11], [11, 15], [15, 16], [17, 20], [21, 23], [24, 30], [31, 43], [44, 47], [48, 55], [56, 58], [59, 72], [73, 80], [81, 83], [84, 92], [93, 97], [98, 105], [106, 108], [109, 114], [115, 117], [118, 123], [124, 126], [127, 129], [130, 138], [138, 139]]}
{"doc_key": "ai-dev-285", "ner": [[9, 11, "task"], [14, 16, "task"], [19, 19, "task"], [21, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["En", "la", "actualidad", "tambi\u00e9n", "se", "utiliza", "habitualmente", "en", "el", "reconocimiento", "del", "habla", ",", "la", "s\u00edntesis", "del", "habla", ",", "la", "diarizaci\u00f3n", ",", "Xavier", "Anguera", "et", "al", "."], "sentence-detokenized": "En la actualidad tambi\u00e9n se utiliza habitualmente en el reconocimiento del habla, la s\u00edntesis del habla, la diarizaci\u00f3n, Xavier Anguera et al.", "token2charspan": [[0, 2], [3, 5], [6, 16], [17, 24], [25, 27], [28, 35], [36, 49], [50, 52], [53, 55], [56, 70], [71, 74], [75, 80], [80, 81], [82, 84], [85, 93], [94, 97], [98, 103], [103, 104], [105, 107], [108, 119], [119, 120], [121, 127], [128, 135], [136, 138], [139, 141], [141, 142]]}
{"doc_key": "ai-dev-286", "ner": [[9, 13, "algorithm"], [16, 17, "algorithm"], [20, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 17, 9, 13, "type-of", "", false, false], [20, 22, 9, 13, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Aqu\u00ed", ",", "math", "\\", "sigma", "/", "math", "es", "una", "funci\u00f3n", "de", "activaci\u00f3n", "por", "elementos", "como", "una", "funci\u00f3n", "sigmoide", "o", "una", "unidad", "lineal", "rectificada", "."], "sentence-detokenized": "Aqu\u00ed, math\\ sigma / math es una funci\u00f3n de activaci\u00f3n por elementos como una funci\u00f3n sigmoide o una unidad lineal rectificada.", "token2charspan": [[0, 4], [4, 5], [6, 10], [10, 11], [12, 17], [18, 19], [20, 24], [25, 27], [28, 31], [32, 39], [40, 42], [43, 53], [54, 57], [58, 67], [68, 72], [73, 76], [77, 84], [85, 93], [94, 95], [96, 99], [100, 106], [107, 113], [114, 125], [125, 126]]}
{"doc_key": "ai-dev-287", "ner": [[17, 20, "algorithm"], [31, 31, "misc"], [33, 33, "misc"], [29, 35, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Los", "enfoques", "tradicionales", "basados", "en", "la", "fon\u00e9tica", "(", "es", "decir", ",", "todos", "los", "modelos", "basados", "en", "el", "modelo", "de", "Markov", "oculto", ")", "requer\u00edan", "componentes", "y", "entrenamiento", "separados", "para", "el", "modelo", "de", "pronunciaci\u00f3n", ",", "ac\u00fastico", "y", "ling\u00fc\u00edstico", "."], "sentence-detokenized": "Los enfoques tradicionales basados en la fon\u00e9tica (es decir, todos los modelos basados en el modelo de Markov oculto) requer\u00edan componentes y entrenamiento separados para el modelo de pronunciaci\u00f3n, ac\u00fastico y ling\u00fc\u00edstico.", "token2charspan": [[0, 3], [4, 12], [13, 26], [27, 34], [35, 37], [38, 40], [41, 49], [50, 51], [51, 53], [54, 59], [59, 60], [61, 66], [67, 70], [71, 78], [79, 86], [87, 89], [90, 92], [93, 99], [100, 102], [103, 109], [110, 116], [116, 117], [118, 127], [128, 139], [140, 141], [142, 155], [156, 165], [166, 170], [171, 173], [174, 180], [181, 183], [184, 197], [197, 198], [199, 207], [208, 209], [210, 221], [221, 222]]}
{"doc_key": "ai-dev-288", "ner": [[1, 5, "algorithm"], [10, 12, "field"], [15, 17, "field"], [20, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 5, 20, 22, "related-to", "used_for", false, false], [10, 12, 1, 5, "usage", "", false, false], [15, 17, 1, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["El", "operador", "de", "cruz", "de", "Roberts", "se", "utiliza", "en", "el", "procesamiento", "de", "im\u00e1genes", "y", "la", "visi\u00f3n", "por", "ordenador", "para", "la", "detecci\u00f3n", "de", "bordes", "."], "sentence-detokenized": "El operador de cruz de Roberts se utiliza en el procesamiento de im\u00e1genes y la visi\u00f3n por ordenador para la detecci\u00f3n de bordes.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 19], [20, 22], [23, 30], [31, 33], [34, 41], [42, 44], [45, 47], [48, 61], [62, 64], [65, 73], [74, 75], [76, 78], [79, 85], [86, 89], [90, 99], [100, 104], [105, 107], [108, 117], [118, 120], [121, 127], [127, 128]]}
{"doc_key": "ai-dev-289", "ner": [[3, 3, "metrics"], [5, 5, "metrics"], [28, 28, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 28, 28, "opposite", "", false, false], [5, 5, 28, 28, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Los", "valores", "de", "sensibilidad", "y", "especificidad", "son", "agn\u00f3sticos", "respecto", "al", "porcentaje", "de", "casos", "positivos", "en", "la", "poblaci\u00f3n", "de", "inter\u00e9s", "(", "a", "diferencia", "de", ",", "por", "ejemplo", ",", "la", "precisi\u00f3n", ")", "."], "sentence-detokenized": "Los valores de sensibilidad y especificidad son agn\u00f3sticos respecto al porcentaje de casos positivos en la poblaci\u00f3n de inter\u00e9s (a diferencia de, por ejemplo, la precisi\u00f3n).", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 27], [28, 29], [30, 43], [44, 47], [48, 58], [59, 67], [68, 70], [71, 81], [82, 84], [85, 90], [91, 100], [101, 103], [104, 106], [107, 116], [117, 119], [120, 127], [128, 129], [129, 130], [131, 141], [142, 144], [144, 145], [146, 149], [150, 157], [157, 158], [159, 161], [162, 171], [171, 172], [172, 173]]}
{"doc_key": "ai-dev-290", "ner": [[2, 4, "algorithm"], [12, 12, "misc"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 12, 2, 4, "topic", "", false, false], [12, 12, 14, 15, "artifact", "", false, false], [12, 12, 17, 18, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Pero", "los", "modelos", "de", "perceptr\u00f3n", "se", "hicieron", "muy", "impopulares", "con", "el", "libro", "Perceptrones", "de", "Marvin", "Minsky", "y", "Seymour", "Papert", ",", "publicado", "en", "1969", "."], "sentence-detokenized": "Pero los modelos de perceptr\u00f3n se hicieron muy impopulares con el libro Perceptrones de Marvin Minsky y Seymour Papert, publicado en 1969.", "token2charspan": [[0, 4], [5, 8], [9, 16], [17, 19], [20, 30], [31, 33], [34, 42], [43, 46], [47, 58], [59, 62], [63, 65], [66, 71], [72, 84], [85, 87], [88, 94], [95, 101], [102, 103], [104, 111], [112, 118], [118, 119], [120, 129], [130, 132], [133, 137], [137, 138]]}
{"doc_key": "ai-dev-291", "ner": [[1, 5, "conference"], [10, 11, "organisation"], [28, 31, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 5, 28, 31, "topic", "", false, false], [10, 11, 1, 5, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Las", "Conferencias", "de", "Comprensi\u00f3n", "de", "Documentos", ",", "organizadas", "anualmente", "por", "el", "NIST", ",", "han", "desarrollado", "sofisticados", "criterios", "de", "evaluaci\u00f3n", "para", "las", "t\u00e9cnicas", "que", "aceptan", "el", "reto", "de", "la", "s\u00edntesis", "de", "m\u00faltiples", "documentos", "."], "sentence-detokenized": "Las Conferencias de Comprensi\u00f3n de Documentos, organizadas anualmente por el NIST, han desarrollado sofisticados criterios de evaluaci\u00f3n para las t\u00e9cnicas que aceptan el reto de la s\u00edntesis de m\u00faltiples documentos.", "token2charspan": [[0, 3], [4, 16], [17, 19], [20, 31], [32, 34], [35, 45], [45, 46], [47, 58], [59, 69], [70, 73], [74, 76], [77, 81], [81, 82], [83, 86], [87, 99], [100, 112], [113, 122], [123, 125], [126, 136], [137, 141], [142, 145], [146, 154], [155, 158], [159, 166], [167, 169], [170, 174], [175, 177], [178, 180], [181, 189], [190, 192], [193, 202], [203, 213], [213, 214]]}
{"doc_key": "ai-dev-292", "ner": [[2, 2, "product"], [33, 35, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 33, 35, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Un", "manipulador", "paralelo", "est\u00e1", "dise\u00f1ado", "de", "manera", "que", "cada", "cadena", "suele", "ser", "corta", ",", "sencilla", "y", ",", "por", "lo", "tanto", ",", "puede", "ser", "r\u00edgida", "contra", "movimientos", "no", "deseados", ",", "en", "comparaci\u00f3n", "con", "un", "manipulador", "en", "serie", "."], "sentence-detokenized": "Un manipulador paralelo est\u00e1 dise\u00f1ado de manera que cada cadena suele ser corta, sencilla y, por lo tanto, puede ser r\u00edgida contra movimientos no deseados, en comparaci\u00f3n con un manipulador en serie.", "token2charspan": [[0, 2], [3, 14], [15, 23], [24, 28], [29, 37], [38, 40], [41, 47], [48, 51], [52, 56], [57, 63], [64, 69], [70, 73], [74, 79], [79, 80], [81, 89], [90, 91], [91, 92], [93, 96], [97, 99], [100, 105], [105, 106], [107, 112], [113, 116], [117, 123], [124, 130], [131, 142], [143, 145], [146, 154], [154, 155], [156, 158], [159, 170], [171, 174], [175, 177], [178, 189], [190, 192], [193, 198], [198, 199]]}
{"doc_key": "ai-dev-293", "ner": [[27, 27, "misc"], [30, 33, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["El", "manipulador", "es", "lo", "que", "hace", "que", "el", "robot", "se", "mueva", ",", "y", "el", "dise\u00f1o", "de", "estos", "sistemas", "puede", "clasificarse", "en", "varios", "tipos", "comunes", ",", "como", "el", "SCARA", "y", "el", "robot", "de", "coordenadas", "cartesianas", ",", "que", "utilizan", "diferentes", "sistemas", "de", "coordenadas", "para", "dirigir", "los", "brazos", "de", "la", "m\u00e1quina", "."], "sentence-detokenized": "El manipulador es lo que hace que el robot se mueva, y el dise\u00f1o de estos sistemas puede clasificarse en varios tipos comunes, como el SCARA y el robot de coordenadas cartesianas, que utilizan diferentes sistemas de coordenadas para dirigir los brazos de la m\u00e1quina.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 20], [21, 24], [25, 29], [30, 33], [34, 36], [37, 42], [43, 45], [46, 51], [51, 52], [53, 54], [55, 57], [58, 64], [65, 67], [68, 73], [74, 82], [83, 88], [89, 101], [102, 104], [105, 111], [112, 117], [118, 125], [125, 126], [127, 131], [132, 134], [135, 140], [141, 142], [143, 145], [146, 151], [152, 154], [155, 166], [167, 178], [178, 179], [180, 183], [184, 192], [193, 203], [204, 212], [213, 215], [216, 227], [228, 232], [233, 240], [241, 244], [245, 251], [252, 254], [255, 257], [258, 265], [265, 266]]}
{"doc_key": "ai-dev-294", "ner": [[1, 2, "country"], [7, 10, "organisation"], [13, 18, "organisation"], [21, 24, "organisation"], [27, 29, "organisation"], [32, 39, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 10, 1, 2, "physical", "", false, false], [13, 18, 1, 2, "physical", "", false, false], [21, 24, 1, 2, "physical", "", false, false], [27, 29, 1, 2, "physical", "", false, false], [32, 39, 1, 2, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["En", "Estados", "Unidos", "es", "miembro", "de", "la", "Academia", "Nacional", "de", "Ciencias", ",", "la", "Academia", "Americana", "de", "Artes", "y", "Ciencias", ",", "la", "Sociedad", "Ling\u00fc\u00edstica", "de", "Am\u00e9rica", ",", "la", "Asociaci\u00f3n", "Filos\u00f3fica", "Americana", "y", "la", "Asociaci\u00f3n", "Americana", "para", "el", "Avance", "de", "la", "Ciencia", "."], "sentence-detokenized": "En Estados Unidos es miembro de la Academia Nacional de Ciencias, la Academia Americana de Artes y Ciencias, la Sociedad Ling\u00fc\u00edstica de Am\u00e9rica, la Asociaci\u00f3n Filos\u00f3fica Americana y la Asociaci\u00f3n Americana para el Avance de la Ciencia.", "token2charspan": [[0, 2], [3, 10], [11, 17], [18, 20], [21, 28], [29, 31], [32, 34], [35, 43], [44, 52], [53, 55], [56, 64], [64, 65], [66, 68], [69, 77], [78, 87], [88, 90], [91, 96], [97, 98], [99, 107], [107, 108], [109, 111], [112, 120], [121, 132], [133, 135], [136, 143], [143, 144], [145, 147], [148, 158], [159, 169], [170, 179], [180, 181], [182, 184], [185, 195], [196, 205], [206, 210], [211, 213], [214, 220], [221, 223], [224, 226], [227, 234], [234, 235]]}
{"doc_key": "ai-dev-295", "ner": [[8, 12, "algorithm"], [14, 14, "algorithm"], [27, 27, "algorithm"], [32, 33, "algorithm"], [38, 43, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 12, 27, 27, "named", "", false, false], [14, 14, 8, 12, "named", "", false, false], [27, 27, 32, 33, "compare", "", false, false], [27, 27, 38, 43, "related-to", "performs", false, false], [32, 33, 38, 43, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Alcanzaron", "gran", "protagonismo", "con", "la", "popularidad", "de", "la", "m\u00e1quina", "de", "vectores", "de", "soporte", "(", "SVM", ")", "en", "la", "d\u00e9cada", "de", "1990", ",", "cuando", "se", "descubri\u00f3", "que", "la", "SVM", "era", "competitiva", "con", "las", "redes", "neuronales", "en", "tareas", "como", "el", "reconocimiento", "de", "la", "escritura", "a", "mano", "."], "sentence-detokenized": "Alcanzaron gran protagonismo con la popularidad de la m\u00e1quina de vectores de soporte (SVM) en la d\u00e9cada de 1990, cuando se descubri\u00f3 que la SVM era competitiva con las redes neuronales en tareas como el reconocimiento de la escritura a mano.", "token2charspan": [[0, 10], [11, 15], [16, 28], [29, 32], [33, 35], [36, 47], [48, 50], [51, 53], [54, 61], [62, 64], [65, 73], [74, 76], [77, 84], [85, 86], [86, 89], [89, 90], [91, 93], [94, 96], [97, 103], [104, 106], [107, 111], [111, 112], [113, 119], [120, 122], [123, 132], [133, 136], [137, 139], [140, 143], [144, 147], [148, 159], [160, 163], [164, 167], [168, 173], [174, 184], [185, 187], [188, 194], [195, 199], [200, 202], [203, 217], [218, 220], [221, 223], [224, 233], [234, 235], [236, 240], [240, 241]]}
{"doc_key": "ai-dev-296", "ner": [[1, 3, "misc"], [9, 9, "misc"], [15, 16, "algorithm"], [22, 24, "misc"], [32, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 3, 9, 9, "usage", "", false, false], [1, 3, 22, 24, "usage", "", false, false], [9, 9, 15, 16, "origin", "result_of_algorithm", false, false], [22, 24, 32, 34, "origin", "result_of_algorithm", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Una", "transformada", "de", "blanqueo", "emp\u00edrica", "se", "obtiene", "estimando", "la", "covarianza", "(", "por", "ejemplo", ",", "por", "m\u00e1xima", "verosimilitud", ")", "y", "construyendo", "posteriormente", "una", "matriz", "de", "blanqueo", "estimada", "correspondiente", "(", "por", "ejemplo", ",", "por", "descomposici\u00f3n", "de", "Cholesky", ")", "."], "sentence-detokenized": "Una transformada de blanqueo emp\u00edrica se obtiene estimando la covarianza (por ejemplo, por m\u00e1xima verosimilitud) y construyendo posteriormente una matriz de blanqueo estimada correspondiente (por ejemplo, por descomposici\u00f3n de Cholesky).", "token2charspan": [[0, 3], [4, 16], [17, 19], [20, 28], [29, 37], [38, 40], [41, 48], [49, 58], [59, 61], [62, 72], [73, 74], [74, 77], [78, 85], [85, 86], [87, 90], [91, 97], [98, 111], [111, 112], [113, 114], [115, 127], [128, 142], [143, 146], [147, 153], [154, 156], [157, 165], [166, 174], [175, 190], [191, 192], [192, 195], [196, 203], [203, 204], [205, 208], [209, 223], [224, 226], [227, 235], [235, 236], [236, 237]]}
{"doc_key": "ai-dev-297", "ner": [[0, 0, "organisation"], [9, 10, "product"], [17, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 0, "artifact", "", false, false], [17, 19, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["IAI", "es", "el", "mayor", "fabricante", "mundial", "de", "robots", "de", "coordenadas", "cartesianas", "y", "es", "un", "l\u00edder", "consolidado", "en", "robots", "SCARA", "de", "bajo", "coste", "y", "alto", "rendimiento", "."], "sentence-detokenized": "IAI es el mayor fabricante mundial de robots de coordenadas cartesianas y es un l\u00edder consolidado en robots SCARA de bajo coste y alto rendimiento.", "token2charspan": [[0, 3], [4, 6], [7, 9], [10, 15], [16, 26], [27, 34], [35, 37], [38, 44], [45, 47], [48, 59], [60, 71], [72, 73], [74, 76], [77, 79], [80, 85], [86, 97], [98, 100], [101, 107], [108, 113], [114, 116], [117, 121], [122, 127], [128, 129], [130, 134], [135, 146], [146, 147]]}
{"doc_key": "ai-dev-298", "ner": [[12, 14, "field"], [17, 19, "field"], [22, 23, "field"], [26, 28, "field"], [31, 32, "field"], [35, 37, "field"], [40, 40, "field"], [43, 43, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [], "relations_mapping_to_source": [], "sentence": ["El", "an\u00e1lisis", "formal", "de", "conceptos", "encuentra", "aplicaci\u00f3n", "pr\u00e1ctica", "en", "campos", "como", "la", "miner\u00eda", "de", "datos", ",", "la", "miner\u00eda", "de", "textos", ",", "el", "aprendizaje", "autom\u00e1tico", ",", "la", "gesti\u00f3n", "del", "conocimiento", ",", "la", "web", "sem\u00e1ntica", ",", "el", "desarrollo", "de", "software", ",", "la", "qu\u00edmica", "y", "la", "biolog\u00eda", "."], "sentence-detokenized": "El an\u00e1lisis formal de conceptos encuentra aplicaci\u00f3n pr\u00e1ctica en campos como la miner\u00eda de datos, la miner\u00eda de textos, el aprendizaje autom\u00e1tico, la gesti\u00f3n del conocimiento, la web sem\u00e1ntica, el desarrollo de software, la qu\u00edmica y la biolog\u00eda.", "token2charspan": [[0, 2], [3, 11], [12, 18], [19, 21], [22, 31], [32, 41], [42, 52], [53, 61], [62, 64], [65, 71], [72, 76], [77, 79], [80, 87], [88, 90], [91, 96], [96, 97], [98, 100], [101, 108], [109, 111], [112, 118], [118, 119], [120, 122], [123, 134], [135, 145], [145, 146], [147, 149], [150, 157], [158, 161], [162, 174], [174, 175], [176, 178], [179, 182], [183, 192], [192, 193], [194, 196], [197, 207], [208, 210], [211, 219], [219, 220], [221, 223], [224, 231], [232, 233], [234, 236], [237, 245], [245, 246]]}
{"doc_key": "ai-dev-299", "ner": [[1, 1, "field"], [3, 7, "field"], [11, 13, "field"], [20, 21, "field"], [34, 35, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 7, 20, 21, "part-of", "", false, false], [3, 7, 34, 35, "topic", "", false, false], [11, 13, 3, 7, "named", "", false, false], [20, 21, 1, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["En", "inform\u00e1tica", ",", "la", "teor\u00eda", "del", "aprendizaje", "computacional", "(", "o", "simplemente", "teor\u00eda", "del", "aprendizaje", ")", "es", "un", "subcampo", "de", "la", "inteligencia", "artificial", "dedicado", "a", "estudiar", "el", "dise\u00f1o", "y", "el", "an\u00e1lisis", "de", "los", "algoritmos", "de", "aprendizaje", "autom\u00e1tico", "."], "sentence-detokenized": "En inform\u00e1tica, la teor\u00eda del aprendizaje computacional (o simplemente teor\u00eda del aprendizaje) es un subcampo de la inteligencia artificial dedicado a estudiar el dise\u00f1o y el an\u00e1lisis de los algoritmos de aprendizaje autom\u00e1tico.", "token2charspan": [[0, 2], [3, 14], [14, 15], [16, 18], [19, 25], [26, 29], [30, 41], [42, 55], [56, 57], [57, 58], [59, 70], [71, 77], [78, 81], [82, 93], [93, 94], [95, 97], [98, 100], [101, 109], [110, 112], [113, 115], [116, 128], [129, 139], [140, 148], [149, 150], [151, 159], [160, 162], [163, 169], [170, 171], [172, 174], [175, 183], [184, 186], [187, 190], [191, 201], [202, 204], [205, 216], [217, 227], [227, 228]]}
{"doc_key": "ai-dev-300", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [13, 14, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 0, 2, "named", "", false, false], [13, 14, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["El", "filtrado", "colaborativo", "(", "FC", ")", "es", "una", "t\u00e9cnica", "utilizada", "por", "los", "sistemas", "de", "recomendaci\u00f3n", "."], "sentence-detokenized": "El filtrado colaborativo (FC) es una t\u00e9cnica utilizada por los sistemas de recomendaci\u00f3n.", "token2charspan": [[0, 2], [3, 11], [12, 24], [25, 26], [26, 28], [28, 29], [30, 32], [33, 36], [37, 44], [45, 54], [55, 58], [59, 62], [63, 71], [72, 74], [75, 88], [88, 89]]}
{"doc_key": "ai-dev-301", "ner": [[0, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "tasa", "de", "falsos", "positivos", "es", "la", "proporci\u00f3n", "de", "todos", "los", "negativos", "que", "siguen", "dando", "resultados", "positivos", "en", "la", "prueba", ",", "es", "decir", ",", "la", "probabilidad", "condicional", "de", "un", "resultado", "positivo", "en", "la", "prueba", "dado", "un", "evento", "que", "no", "estaba", "presente", "."], "sentence-detokenized": "La tasa de falsos positivos es la proporci\u00f3n de todos los negativos que siguen dando resultados positivos en la prueba, es decir, la probabilidad condicional de un resultado positivo en la prueba dado un evento que no estaba presente.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 17], [18, 27], [28, 30], [31, 33], [34, 44], [45, 47], [48, 53], [54, 57], [58, 67], [68, 71], [72, 78], [79, 84], [85, 95], [96, 105], [106, 108], [109, 111], [112, 118], [118, 119], [120, 122], [123, 128], [128, 129], [130, 132], [133, 145], [146, 157], [158, 160], [161, 163], [164, 173], [174, 182], [183, 185], [186, 188], [189, 195], [196, 200], [201, 203], [204, 210], [211, 214], [215, 217], [218, 224], [225, 233], [233, 234]]}
{"doc_key": "ai-dev-302", "ner": [[1, 13, "misc"], [34, 34, "metrics"], [40, 40, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 13, 34, 34, "topic", "", false, false], [1, 13, 40, 40, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["En", "VLDB", "'8:", "Proceedings", "of", "the", "34th", "International", "Conference", "on", "Very", "Large", "Data", "Bases", ",", "p\u00e1ginas", "422--433", ".", "mostraron", "que", "los", "valores", "dados", "para", "mathC", "/", "math", "y", "mathK", "/", "math", "generalmente", "implican", "una", "precisi\u00f3n", "relativamente", "baja", "de", "las", "puntuaciones", "SimRank", "calculadas", "iterativamente", "."], "sentence-detokenized": "En VLDB '8: Proceedings of the 34th International Conference on Very Large Data Bases, p\u00e1ginas 422--433. mostraron que los valores dados para mathC / math y mathK / math generalmente implican una precisi\u00f3n relativamente baja de las puntuaciones SimRank calculadas iterativamente.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 23], [24, 26], [27, 30], [31, 35], [36, 49], [50, 60], [61, 63], [64, 68], [69, 74], [75, 79], [80, 85], [85, 86], [87, 94], [95, 103], [103, 104], [105, 114], [115, 118], [119, 122], [123, 130], [131, 136], [137, 141], [142, 147], [148, 149], [150, 154], [155, 156], [157, 162], [163, 164], [165, 169], [170, 182], [183, 191], [192, 195], [196, 205], [206, 219], [220, 224], [225, 227], [228, 231], [232, 244], [245, 252], [253, 263], [264, 278], [278, 279]]}
{"doc_key": "ai-dev-303", "ner": [[7, 10, "misc"], [11, 11, "misc"], [17, 18, "person"], [20, 22, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 7, 10, "general-affiliation", "", false, false], [11, 11, 17, 18, "artifact", "", false, false], [11, 11, 20, 22, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["En", "junio", "de", "2015", "se", "estren\u00f3", "el", "drama", "de", "ciencia", "ficci\u00f3n", "Sense8", ",", "escrito", "y", "producido", "por", "los", "Wachowski", "y", "J.", "Michael", "Straczynski", "."], "sentence-detokenized": "En junio de 2015 se estren\u00f3 el drama de ciencia ficci\u00f3n Sense8, escrito y producido por los Wachowski y J. Michael Straczynski.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 16], [17, 19], [20, 27], [28, 30], [31, 36], [37, 39], [40, 47], [48, 55], [56, 62], [62, 63], [64, 71], [72, 73], [74, 83], [84, 87], [88, 91], [92, 101], [102, 103], [104, 106], [107, 114], [115, 126], [126, 127]]}
{"doc_key": "ai-dev-304", "ner": [[1, 1, "misc"], [7, 10, "product"], [30, 32, "misc"], [42, 42, "country"], [44, 44, "country"], [46, 46, "country"], [48, 48, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 1, 7, 10, "topic", "", false, false], [42, 42, 30, 32, "type-of", "", false, false], [44, 44, 30, 32, "type-of", "", false, false], [46, 46, 30, 32, "type-of", "", false, false], [48, 48, 30, 32, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Aunque", "Eurotra", "nunca", "lleg\u00f3", "a", "ofrecer", "un", "sistema", "de", "traducci\u00f3n", "autom\u00e1tica", "que", "funcionara", ",", "el", "proyecto", "tuvo", "una", "gran", "repercusi\u00f3n", "a", "largo", "plazo", "en", "las", "incipientes", "industrias", "ling\u00fc\u00edsticas", "de", "los", "Estados", "miembros", "europeos", ",", "en", "particular", "en", "los", "pa\u00edses", "del", "sur", ":", "Grecia", ",", "Italia", ",", "Espa\u00f1a", "y", "Portugal", "."], "sentence-detokenized": "Aunque Eurotra nunca lleg\u00f3 a ofrecer un sistema de traducci\u00f3n autom\u00e1tica que funcionara, el proyecto tuvo una gran repercusi\u00f3n a largo plazo en las incipientes industrias ling\u00fc\u00edsticas de los Estados miembros europeos, en particular en los pa\u00edses del sur: Grecia, Italia, Espa\u00f1a y Portugal.", "token2charspan": [[0, 6], [7, 14], [15, 20], [21, 26], [27, 28], [29, 36], [37, 39], [40, 47], [48, 50], [51, 61], [62, 72], [73, 76], [77, 87], [87, 88], [89, 91], [92, 100], [101, 105], [106, 109], [110, 114], [115, 126], [127, 128], [129, 134], [135, 140], [141, 143], [144, 147], [148, 159], [160, 170], [171, 183], [184, 186], [187, 190], [191, 198], [199, 207], [208, 216], [216, 217], [218, 220], [221, 231], [232, 234], [235, 238], [239, 245], [246, 249], [250, 253], [253, 254], [255, 261], [261, 262], [263, 269], [269, 270], [271, 277], [278, 279], [280, 288], [288, 289]]}
{"doc_key": "ai-dev-305", "ner": [[0, 1, "algorithm"], [9, 10, "task"], [19, 21, "task"], [23, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 0, 1, "usage", "", true, false], [19, 21, 9, 10, "named", "", false, false], [23, 23, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["El", "autocodificador", "se", "ha", "aplicado", "con", "\u00e9xito", "a", "la", "traducci\u00f3n", "autom\u00e1tica", "de", "lenguas", "humanas", ",", "lo", "que", "suele", "denominarse", "traducci\u00f3n", "autom\u00e1tica", "neural", "(", "NMT", ")", "."], "sentence-detokenized": "El autocodificador se ha aplicado con \u00e9xito a la traducci\u00f3n autom\u00e1tica de lenguas humanas, lo que suele denominarse traducci\u00f3n autom\u00e1tica neural (NMT).", "token2charspan": [[0, 2], [3, 18], [19, 21], [22, 24], [25, 33], [34, 37], [38, 43], [44, 45], [46, 48], [49, 59], [60, 70], [71, 73], [74, 81], [82, 89], [89, 90], [91, 93], [94, 97], [98, 103], [104, 115], [116, 126], [127, 137], [138, 144], [145, 146], [146, 149], [149, 150], [150, 151]]}
{"doc_key": "ai-dev-306", "ner": [[12, 16, "metrics"], [19, 21, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Algunos", "ejemplos", "populares", "de", "funciones", "de", "aptitud", "basadas", "en", "las", "probabilidades", "son", "la", "estimaci\u00f3n", "de", "m\u00e1xima", "verosimilitud", "y", "la", "p\u00e9rdida", "de", "bisagra", "."], "sentence-detokenized": "Algunos ejemplos populares de funciones de aptitud basadas en las probabilidades son la estimaci\u00f3n de m\u00e1xima verosimilitud y la p\u00e9rdida de bisagra.", "token2charspan": [[0, 7], [8, 16], [17, 26], [27, 29], [30, 39], [40, 42], [43, 50], [51, 58], [59, 61], [62, 65], [66, 80], [81, 84], [85, 87], [88, 98], [99, 101], [102, 108], [109, 122], [123, 124], [125, 127], [128, 135], [136, 138], [139, 146], [146, 147]]}
{"doc_key": "ai-dev-307", "ner": [[0, 3, "field"], [16, 19, "task"], [22, 24, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 19, 0, 3, "part-of", "", false, false], [22, 24, 0, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "miner\u00eda", "de", "datos", "es", "un", "campo", "de", "estudio", "relacionado", ",", "que", "se", "centra", "en", "el", "an\u00e1lisis", "exploratorio", "de", "datos", "mediante", "el", "aprendizaje", "no", "supervisado", "."], "sentence-detokenized": "La miner\u00eda de datos es un campo de estudio relacionado, que se centra en el an\u00e1lisis exploratorio de datos mediante el aprendizaje no supervisado.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 19], [20, 22], [23, 25], [26, 31], [32, 34], [35, 42], [43, 54], [54, 55], [56, 59], [60, 62], [63, 69], [70, 72], [73, 75], [76, 84], [85, 97], [98, 100], [101, 106], [107, 115], [116, 118], [119, 130], [131, 133], [134, 145], [145, 146]]}
{"doc_key": "ai-dev-308", "ner": [[0, 2, "algorithm"], [14, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 14, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["El", "filtrado", "colaborativo", "engloba", "t\u00e9cnicas", "para", "emparejar", "a", "personas", "con", "intereses", "similares", "y", "hacer", "un", "sistema", "de", "recomendaci\u00f3n", "sobre", "esta", "base", "."], "sentence-detokenized": "El filtrado colaborativo engloba t\u00e9cnicas para emparejar a personas con intereses similares y hacer un sistema de recomendaci\u00f3n sobre esta base.", "token2charspan": [[0, 2], [3, 11], [12, 24], [25, 32], [33, 41], [42, 46], [47, 56], [57, 58], [59, 67], [68, 71], [72, 81], [82, 91], [92, 93], [94, 99], [100, 102], [103, 110], [111, 113], [114, 127], [128, 133], [134, 138], [139, 143], [143, 144]]}
{"doc_key": "ai-dev-309", "ner": [[1, 8, "algorithm"], [14, 14, "programlang"], [16, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 19, 1, 8, "type-of", "", false, false], [16, 19, 14, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Varios", "algoritmos", "de", "similitud", "de", "palabras", "basados", "en", "WordNet", "est\u00e1n", "implementados", "en", "un", "paquete", "Perl", "llamado", "WordNet", ":", ":", "Similarity", "."], "sentence-detokenized": "Varios algoritmos de similitud de palabras basados en WordNet est\u00e1n implementados en un paquete Perl llamado WordNet:: Similarity.", "token2charspan": [[0, 6], [7, 17], [18, 20], [21, 30], [31, 33], [34, 42], [43, 50], [51, 53], [54, 61], [62, 67], [68, 81], [82, 84], [85, 87], [88, 95], [96, 100], [101, 108], [109, 116], [116, 117], [117, 118], [119, 129], [129, 130]]}
{"doc_key": "ai-dev-310", "ner": [[9, 9, "conference"], [11, 11, "conference"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 11, 9, 9, "named", "", false, false], [15, 16, 9, 9, "temporal", "", false, false], [18, 19, 9, 9, "temporal", "", false, false], [21, 22, 9, 9, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Tambi\u00e9n", "se", "discutir\u00e1", "otro", "trabajo", ",", "presentado", "en", "el", "CVPR", "(", "CVPR", ")", "2000", "por", "Erik", "Miller", ",", "Nicholas", "Matsakis", "y", "Paul", "Viola", "."], "sentence-detokenized": "Tambi\u00e9n se discutir\u00e1 otro trabajo, presentado en el CVPR (CVPR) 2000 por Erik Miller, Nicholas Matsakis y Paul Viola.", "token2charspan": [[0, 7], [8, 10], [11, 20], [21, 25], [26, 33], [33, 34], [35, 45], [46, 48], [49, 51], [52, 56], [57, 58], [58, 62], [62, 63], [64, 68], [69, 72], [73, 77], [78, 84], [84, 85], [86, 94], [95, 103], [104, 105], [106, 110], [111, 116], [116, 117]]}
{"doc_key": "ai-dev-311", "ner": [[0, 1, "algorithm"], [9, 11, "misc"], [17, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 17, 19, "compare", "", false, false], [17, 19, 9, 11, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["El", "QC", "no", "se", "ha", "evaluado", "frente", "a", "los", "algoritmos", "de", "agrupaci\u00f3n", "modernos", "tradicionales", ",", "aparte", "del", "\u00edndice", "de", "Jaccard", "."], "sentence-detokenized": "El QC no se ha evaluado frente a los algoritmos de agrupaci\u00f3n modernos tradicionales, aparte del \u00edndice de Jaccard.", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 11], [12, 14], [15, 23], [24, 30], [31, 32], [33, 36], [37, 47], [48, 50], [51, 61], [62, 70], [71, 84], [84, 85], [86, 92], [93, 96], [97, 103], [104, 106], [107, 114], [114, 115]]}
{"doc_key": "ai-dev-312", "ner": [[2, 6, "misc"], [11, 14, "misc"], [16, 18, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 14, 2, 6, "physical", "", false, false], [11, 14, 16, 18, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Durante", "el", "Campeonato", "Mundial", "de", "Rob\u00f3tica", "VEX", ",", "se", "celebra", "un", "Desfile", "de", "las", "Naciones", "en", "el", "Freedom", "Hall", "que", "incluye", "a", "cientos", "de", "estudiantes", "de", "m\u00e1s", "de", "30", "pa\u00edses", "."], "sentence-detokenized": "Durante el Campeonato Mundial de Rob\u00f3tica VEX, se celebra un Desfile de las Naciones en el Freedom Hall que incluye a cientos de estudiantes de m\u00e1s de 30 pa\u00edses.", "token2charspan": [[0, 7], [8, 10], [11, 21], [22, 29], [30, 32], [33, 41], [42, 45], [45, 46], [47, 49], [50, 57], [58, 60], [61, 68], [69, 71], [72, 75], [76, 84], [85, 87], [88, 90], [91, 98], [99, 103], [104, 107], [108, 115], [116, 117], [118, 125], [126, 128], [129, 140], [141, 143], [144, 147], [148, 150], [151, 153], [154, 160], [160, 161]]}
{"doc_key": "ai-dev-313", "ner": [[5, 12, "metrics"], [14, 14, "metrics"], [18, 22, "metrics"], [24, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 14, 5, 12, "named", "", false, false], [24, 24, 18, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Otras", "medidas", "de", "precisi\u00f3n", "son", "la", "tasa", "de", "error", "de", "una", "sola", "palabra", "(", "SWER", ")", "y", "la", "tasa", "de", "\u00e9xito", "de", "comandos", "(", "CSR", ")", "."], "sentence-detokenized": "Otras medidas de precisi\u00f3n son la tasa de error de una sola palabra (SWER) y la tasa de \u00e9xito de comandos (CSR).", "token2charspan": [[0, 5], [6, 13], [14, 16], [17, 26], [27, 30], [31, 33], [34, 38], [39, 41], [42, 47], [48, 50], [51, 54], [55, 59], [60, 67], [68, 69], [69, 73], [73, 74], [75, 76], [77, 79], [80, 84], [85, 87], [88, 93], [94, 96], [97, 105], [106, 107], [107, 110], [110, 111], [111, 112]]}
{"doc_key": "ai-dev-314", "ner": [[6, 7, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Presentaron", "su", "m\u00e9todo", "y", "resultados", "en", "SIGGRAPH", "2000", "."], "sentence-detokenized": "Presentaron su m\u00e9todo y resultados en SIGGRAPH 2000.", "token2charspan": [[0, 11], [12, 14], [15, 21], [22, 23], [24, 34], [35, 37], [38, 46], [47, 51], [51, 52]]}
{"doc_key": "ai-dev-315", "ner": [[0, 2, "conference"], [9, 9, "misc"], [11, 15, "misc"], [19, 22, "conference"], [26, 29, "researcher"], [38, 39, "researcher"], [43, 45, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 9, 9, "origin", "", false, false], [9, 9, 19, 22, "physical", "", false, false], [9, 9, 19, 22, "temporal", "", false, false], [9, 9, 26, 29, "origin", "", false, false], [9, 9, 38, 39, "origin", "", false, false], [11, 15, 9, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["La", "Conferencia", "KDD", "surgi\u00f3", "a", "partir", "de", "los", "talleres", "KDD", "(", "Knowledge", "Discovery", "and", "Data", "Mining", ")", "de", "las", "conferencias", "de", "la", "AAAI", ",", "iniciados", "por", "Gregory", "I", ".", "Piatetsky-Shapiro", "en", "1989", ",", "1991", "y", "1993", ",", "y", "Usama", "Fayyad", "en", "1994", ".", "Maquinaria", "|", "ACM", "."], "sentence-detokenized": "La Conferencia KDD surgi\u00f3 a partir de los talleres KDD (Knowledge Discovery and Data Mining) de las conferencias de la AAAI, iniciados por Gregory I. Piatetsky-Shapiro en 1989, 1991 y 1993, y Usama Fayyad en 1994. Maquinaria | ACM.", "token2charspan": [[0, 2], [3, 14], [15, 18], [19, 25], [26, 27], [28, 34], [35, 37], [38, 41], [42, 50], [51, 54], [55, 56], [56, 65], [66, 75], [76, 79], [80, 84], [85, 91], [91, 92], [93, 95], [96, 99], [100, 112], [113, 115], [116, 118], [119, 123], [123, 124], [125, 134], [135, 138], [139, 146], [147, 148], [148, 149], [150, 167], [168, 170], [171, 175], [175, 176], [177, 181], [182, 183], [184, 188], [188, 189], [190, 191], [192, 197], [198, 204], [205, 207], [208, 212], [212, 213], [214, 224], [225, 226], [227, 230], [230, 231]]}
{"doc_key": "ai-dev-316", "ner": [[6, 9, "conference"], [11, 11, "conference"], [15, 20, "organisation"], [22, 22, "organisation"], [26, 30, "conference"], [32, 32, "conference"], [36, 42, "conference"], [44, 44, "conference"], [48, 53, "conference"], [55, 55, "conference"], [59, 64, "conference"], [66, 66, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[11, 11, 6, 9, "named", "", false, false], [22, 22, 15, 20, "named", "", false, false], [32, 32, 26, 30, "named", "", false, false], [44, 44, 36, 42, "named", "", false, false], [55, 55, 48, 53, "named", "", false, false], [66, 66, 59, 64, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Ha", "sido", "elegido", "miembro", "de", "la", "Association", "for", "Computing", "Machinery", "(", "ACM", ")", ",", "el", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", ",", "la", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", ",", "la", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", ",", "la", "American", "Association", "for", "Advancement", "of", "Science", "(", "AAAS", ")", "y", "la", "Society", "for", "Optics", "and", "Photonics", "Technology", "(", "SPIE", ")", "."], "sentence-detokenized": "Ha sido elegido miembro de la Association for Computing Machinery (ACM), el Institute of Electrical and Electronics Engineers (IEEE), la International Association for Pattern Recognition (IAPR), la Association for the Advancement of Artificial Intelligence (AAAI), la American Association for Advancement of Science (AAAS) y la Society for Optics and Photonics Technology (SPIE).", "token2charspan": [[0, 2], [3, 7], [8, 15], [16, 23], [24, 26], [27, 29], [30, 41], [42, 45], [46, 55], [56, 65], [66, 67], [67, 70], [70, 71], [71, 72], [73, 75], [76, 85], [86, 88], [89, 99], [100, 103], [104, 115], [116, 125], [126, 127], [127, 131], [131, 132], [132, 133], [134, 136], [137, 150], [151, 162], [163, 166], [167, 174], [175, 186], [187, 188], [188, 192], [192, 193], [193, 194], [195, 197], [198, 209], [210, 213], [214, 217], [218, 229], [230, 232], [233, 243], [244, 256], [257, 258], [258, 262], [262, 263], [263, 264], [265, 267], [268, 276], [277, 288], [289, 292], [293, 304], [305, 307], [308, 315], [316, 317], [317, 321], [321, 322], [323, 324], [325, 327], [328, 335], [336, 339], [340, 346], [347, 350], [351, 360], [361, 371], [372, 373], [373, 377], [377, 378], [378, 379]]}
{"doc_key": "ai-dev-317", "ner": [[0, 2, "field"], [7, 7, "field"], [23, 25, "field"], [6, 48, "field"], [70, 77, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 23, 25, "named", "", false, false], [7, 7, 6, 48, "named", "", false, false], [6, 48, 70, 77, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["El", "aprendizaje", "autom\u00e1tico", "y", "la", "miner\u00eda", "de", "datos", "suelen", "emplear", "los", "mismos", "m\u00e9todos", "y", "se", "solapan", "de", "forma", "significativa", ",", "pero", "mientras", "que", "el", "aprendizaje", "autom\u00e1tico", "se", "centra", "en", "la", "predicci\u00f3n", ",", "basada", "en", "propiedades", "conocidas", "aprendidas", "a", "partir", "de", "los", "datos", "de", "entrenamiento", ",", "la", "miner\u00eda", "de", "datos", "se", "centra", "en", "el", "descubrimiento", "de", "propiedades", "(", "previamente", ")", "desconocidas", "en", "los", "datos", "(", "es", "el", "paso", "de", "an\u00e1lisis", "del", "descubrimiento", "de", "conocimiento", "en", "las", "bases", "de", "datos", ")", "."], "sentence-detokenized": "El aprendizaje autom\u00e1tico y la miner\u00eda de datos suelen emplear los mismos m\u00e9todos y se solapan de forma significativa, pero mientras que el aprendizaje autom\u00e1tico se centra en la predicci\u00f3n, basada en propiedades conocidas aprendidas a partir de los datos de entrenamiento, la miner\u00eda de datos se centra en el descubrimiento de propiedades (previamente) desconocidas en los datos (es el paso de an\u00e1lisis del descubrimiento de conocimiento en las bases de datos).", "token2charspan": [[0, 2], [3, 14], [15, 25], [26, 27], [28, 30], [31, 38], [39, 41], [42, 47], [48, 54], [55, 62], [63, 66], [67, 73], [74, 81], [82, 83], [84, 86], [87, 94], [95, 97], [98, 103], [104, 117], [117, 118], [119, 123], [124, 132], [133, 136], [137, 139], [140, 151], [152, 162], [163, 165], [166, 172], [173, 175], [176, 178], [179, 189], [189, 190], [191, 197], [198, 200], [201, 212], [213, 222], [223, 233], [234, 235], [236, 242], [243, 245], [246, 249], [250, 255], [256, 258], [259, 272], [272, 273], [274, 276], [277, 284], [285, 287], [288, 293], [294, 296], [297, 303], [304, 306], [307, 309], [310, 324], [325, 327], [328, 339], [340, 341], [341, 352], [352, 353], [354, 366], [367, 369], [370, 373], [374, 379], [380, 381], [381, 383], [384, 386], [387, 391], [392, 394], [395, 403], [404, 407], [408, 422], [423, 425], [426, 438], [439, 441], [442, 445], [446, 451], [452, 454], [455, 460], [460, 461], [461, 462]]}
{"doc_key": "ai-dev-318", "ner": [[0, 0, "product"], [4, 4, "programlang"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 4, "general-affiliation", "", false, false], [0, 0, 4, 4, "related-to", "runs_on", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Indy", "est\u00e1", "escrito", "en", "Java", "y", ",", "por", "tanto", ",", "funciona", "en", "la", "mayor\u00eda", "de", "los", "sistemas", "operativos", "modernos", "."], "sentence-detokenized": "Indy est\u00e1 escrito en Java y, por tanto, funciona en la mayor\u00eda de los sistemas operativos modernos.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 20], [21, 25], [26, 27], [27, 28], [29, 32], [33, 38], [38, 39], [40, 48], [49, 51], [52, 54], [55, 62], [63, 65], [66, 69], [70, 78], [79, 89], [90, 98], [98, 99]]}
{"doc_key": "ai-dev-319", "ner": [[0, 1, "algorithm"], [7, 10, "algorithm"], [12, 12, "algorithm"], [19, 23, "algorithm"], [25, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 7, 10, "type-of", "", true, false], [12, 12, 7, 10, "named", "", false, false], [19, 23, 7, 10, "type-of", "", true, false], [25, 25, 19, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["El", "NMF", "es", "una", "instancia", "de", "la", "programaci\u00f3n", "cuadr\u00e1tica", "no", "negativa", "(", "NQP", ")", ",", "al", "igual", "que", "la", "m\u00e1quina", "de", "vectores", "de", "apoyo", "(", "SVM", ")", "."], "sentence-detokenized": "El NMF es una instancia de la programaci\u00f3n cuadr\u00e1tica no negativa (NQP), al igual que la m\u00e1quina de vectores de apoyo (SVM).", "token2charspan": [[0, 2], [3, 6], [7, 9], [10, 13], [14, 23], [24, 26], [27, 29], [30, 42], [43, 53], [54, 56], [57, 65], [66, 67], [67, 70], [70, 71], [71, 72], [73, 75], [76, 81], [82, 85], [86, 88], [89, 96], [97, 99], [100, 108], [109, 111], [112, 117], [118, 119], [119, 122], [122, 123], [123, 124]]}
{"doc_key": "ai-dev-320", "ner": [[9, 10, "misc"], [15, 18, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 10, 15, 18, "usage", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["El", "m\u00e9todo", "se", "basa", "en", "la", "estimaci\u00f3n", "de", "las", "probabilidades", "condicionales", "mediante", "el", "m\u00e9todo", "de", "m\u00e1xima", "verosimilitud", "no", "param\u00e9trica", "que", "conduce"], "sentence-detokenized": "El m\u00e9todo se basa en la estimaci\u00f3n de las probabilidades condicionales mediante el m\u00e9todo de m\u00e1xima verosimilitud no param\u00e9trica que conduce", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 17], [18, 20], [21, 23], [24, 34], [35, 37], [38, 41], [42, 56], [57, 70], [71, 79], [80, 82], [83, 89], [90, 92], [93, 99], [100, 113], [114, 116], [117, 128], [129, 132], [133, 140]]}
{"doc_key": "ai-dev-321", "ner": [[8, 9, "algorithm"], [12, 15, "algorithm"], [18, 20, "metrics"], [22, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Los", "conceptos", "b\u00e1sicos", "de", "la", "estimaci\u00f3n", "espectral", "son", "la", "autocorrelaci\u00f3n", ",", "la", "transformada", "de", "Fourier", "multidimensional", ",", "el", "error", "cuadr\u00e1tico", "medio", "y", "la", "entrop\u00eda", "."], "sentence-detokenized": "Los conceptos b\u00e1sicos de la estimaci\u00f3n espectral son la autocorrelaci\u00f3n, la transformada de Fourier multidimensional, el error cuadr\u00e1tico medio y la entrop\u00eda.", "token2charspan": [[0, 3], [4, 13], [14, 21], [22, 24], [25, 27], [28, 38], [39, 48], [49, 52], [53, 55], [56, 71], [71, 72], [73, 75], [76, 88], [89, 91], [92, 99], [100, 116], [116, 117], [118, 120], [121, 126], [127, 137], [138, 143], [144, 145], [146, 148], [149, 157], [157, 158]]}
{"doc_key": "ai-dev-322", "ner": [[5, 7, "algorithm"], [13, 13, "field"], [16, 16, "algorithm"], [19, 23, "algorithm"], [26, 27, "task"], [30, 30, "field"], [33, 33, "field"], [36, 38, "task"], [41, 44, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 7, 13, 13, "part-of", "", false, false], [5, 7, 16, 16, "part-of", "", false, false], [5, 7, 19, 23, "part-of", "", false, false], [5, 7, 26, 27, "part-of", "", false, false], [5, 7, 30, 30, "part-of", "", false, false], [5, 7, 33, 33, "part-of", "", false, false], [5, 7, 36, 38, "part-of", "", false, false], [5, 7, 41, 44, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Las", "\u00e1reas", "de", "aplicaci\u00f3n", "de", "los", "m\u00e9todos", "kernel", "son", "diversas", "e", "incluyen", "la", "geoestad\u00edstica", ",", "el", "kriging", ",", "la", "ponderaci\u00f3n", "inversa", "de", "la", "distancia", ",", "la", "reconstrucci\u00f3n", "3D", ",", "la", "bioinform\u00e1tica", ",", "la", "quimioinform\u00e1tica", ",", "la", "extracci\u00f3n", "de", "informaci\u00f3n", "y", "el", "reconocimiento", "de", "la", "escritura", "."], "sentence-detokenized": "Las \u00e1reas de aplicaci\u00f3n de los m\u00e9todos kernel son diversas e incluyen la geoestad\u00edstica, el kriging, la ponderaci\u00f3n inversa de la distancia, la reconstrucci\u00f3n 3D, la bioinform\u00e1tica, la quimioinform\u00e1tica, la extracci\u00f3n de informaci\u00f3n y el reconocimiento de la escritura.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 23], [24, 26], [27, 30], [31, 38], [39, 45], [46, 49], [50, 58], [59, 60], [61, 69], [70, 72], [73, 87], [87, 88], [89, 91], [92, 99], [99, 100], [101, 103], [104, 115], [116, 123], [124, 126], [127, 129], [130, 139], [139, 140], [141, 143], [144, 158], [159, 161], [161, 162], [163, 165], [166, 180], [180, 181], [182, 184], [185, 202], [202, 203], [204, 206], [207, 217], [218, 220], [221, 232], [233, 234], [235, 237], [238, 252], [253, 255], [256, 258], [259, 268], [268, 269]]}
{"doc_key": "ai-dev-323", "ner": [[22, 22, "organisation"], [13, 17, "product"], [19, 21, "product"], [34, 34, "organisation"], [26, 29, "product"], [31, 31, "product"], [37, 38, "product"], [41, 43, "product"], [45, 49, "product"], [51, 54, "product"], [56, 58, "product"], [62, 63, "product"], [66, 70, "product"], [74, 76, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[13, 17, 22, 22, "artifact", "", false, false], [13, 17, 37, 38, "compare", "", false, false], [13, 17, 41, 43, "compare", "", false, false], [13, 17, 45, 49, "compare", "", false, false], [13, 17, 51, 54, "compare", "", false, false], [13, 17, 56, 58, "compare", "", false, false], [13, 17, 62, 63, "compare", "", false, false], [13, 17, 66, 70, "compare", "", false, false], [13, 17, 74, 76, "compare", "", false, false], [19, 21, 13, 17, "named", "", false, false], [26, 29, 34, 34, "artifact", "", false, false], [26, 29, 37, 38, "compare", "", false, false], [26, 29, 41, 43, "compare", "", false, false], [26, 29, 45, 49, "compare", "", false, false], [26, 29, 51, 54, "compare", "", false, false], [26, 29, 56, 58, "compare", "", false, false], [26, 29, 62, 63, "compare", "", false, false], [26, 29, 66, 70, "compare", "", false, false], [26, 29, 74, 76, "compare", "", false, false], [31, 31, 26, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "sentence": ["Los", "robots", "pueden", "ser", "aut\u00f3nomos", "o", "semiaut\u00f3nomos", "y", "van", "desde", "humanoides", "como", "el", "Advanced", "Step", "in", "Innovative", "Mobility", "(", "ASIMO", ")", "de", "Honda", "y", "el", "TOSY", "Ping", "Pong", "Playing", "Robot", "(", "TOPIO", ")", "de", "TOSY", ",", "hasta", "robots", "industriales", ",", "robots", "de", "operaciones", "m\u00e9dicas", ",", "robots", "de", "asistencia", "a", "pacientes", ",", "robots", "de", "terapia", "canina", ",", "robots", "de", "enjambre", "programados", "colectivamente", ",", "drones", "UAV", "como", "el", "MQ-1", "Predator", "de", "General", "Atomics", ",", "e", "incluso", "nano", "robots", "microsc\u00f3picos", "."], "sentence-detokenized": "Los robots pueden ser aut\u00f3nomos o semiaut\u00f3nomos y van desde humanoides como el Advanced Step in Innovative Mobility (ASIMO) de Honda y el TOSY Ping Pong Playing Robot (TOPIO) de TOSY, hasta robots industriales, robots de operaciones m\u00e9dicas, robots de asistencia a pacientes, robots de terapia canina, robots de enjambre programados colectivamente, drones UAV como el MQ-1 Predator de General Atomics, e incluso nano robots microsc\u00f3picos.", "token2charspan": [[0, 3], [4, 10], [11, 17], [18, 21], [22, 31], [32, 33], [34, 47], [48, 49], [50, 53], [54, 59], [60, 70], [71, 75], [76, 78], [79, 87], [88, 92], [93, 95], [96, 106], [107, 115], [116, 117], [117, 122], [122, 123], [124, 126], [127, 132], [133, 134], [135, 137], [138, 142], [143, 147], [148, 152], [153, 160], [161, 166], [167, 168], [168, 173], [173, 174], [175, 177], [178, 182], [182, 183], [184, 189], [190, 196], [197, 209], [209, 210], [211, 217], [218, 220], [221, 232], [233, 240], [240, 241], [242, 248], [249, 251], [252, 262], [263, 264], [265, 274], [274, 275], [276, 282], [283, 285], [286, 293], [294, 300], [300, 301], [302, 308], [309, 311], [312, 320], [321, 332], [333, 347], [347, 348], [349, 355], [356, 359], [360, 364], [365, 367], [368, 372], [373, 381], [382, 384], [385, 392], [393, 400], [400, 401], [402, 403], [404, 411], [412, 416], [417, 423], [424, 437], [437, 438]]}
{"doc_key": "ai-dev-324", "ner": [[0, 0, "product"], [2, 3, "product"], [9, 16, "university"], [18, 19, "researcher"], [21, 22, "researcher"], [24, 25, "researcher"], [27, 28, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 18, 19, "artifact", "", false, false], [0, 0, 21, 22, "artifact", "", false, false], [0, 0, 24, 25, "artifact", "", false, false], [0, 0, 27, 28, "artifact", "", false, false], [2, 3, 18, 19, "artifact", "", false, false], [2, 3, 21, 22, "artifact", "", false, false], [2, 3, 24, 25, "artifact", "", false, false], [2, 3, 27, 28, "artifact", "", false, false], [18, 19, 9, 16, "physical", "", false, false], [21, 22, 9, 16, "physical", "", false, false], [24, 25, 9, 16, "physical", "", false, false], [27, 28, 9, 16, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Freddy", "y", "Freddy", "II", "eran", "robots", "construidos", "en", "la", "Escuela", "de", "Inform\u00e1tica", "de", "la", "Universidad", "de", "Edimburgo", "por", "Pat", "Ambler", ",", "Robin", "Popplestone", ",", "Austin", "Tate", "y", "Donald", "Mitchie", ",", "y", "eran", "capaces", "de", "ensamblar", "bloques", "de", "madera", "en", "un", "periodo", "de", "varias", "horas", "."], "sentence-detokenized": "Freddy y Freddy II eran robots construidos en la Escuela de Inform\u00e1tica de la Universidad de Edimburgo por Pat Ambler, Robin Popplestone, Austin Tate y Donald Mitchie, y eran capaces de ensamblar bloques de madera en un periodo de varias horas.", "token2charspan": [[0, 6], [7, 8], [9, 15], [16, 18], [19, 23], [24, 30], [31, 42], [43, 45], [46, 48], [49, 56], [57, 59], [60, 71], [72, 74], [75, 77], [78, 89], [90, 92], [93, 102], [103, 106], [107, 110], [111, 117], [117, 118], [119, 124], [125, 136], [136, 137], [138, 144], [145, 149], [150, 151], [152, 158], [159, 166], [166, 167], [168, 169], [170, 174], [175, 182], [183, 185], [186, 195], [196, 203], [204, 206], [207, 213], [214, 216], [217, 219], [220, 227], [228, 230], [231, 237], [238, 243], [243, 244]]}
{"doc_key": "ai-dev-325", "ner": [[4, 4, "location"], [6, 6, "country"], [14, 15, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 6, 6, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Pas\u00f3", "su", "infancia", "en", "Par\u00eds", ",", "Francia", ",", "donde", "sus", "padres", "hab\u00edan", "emigrado", "de", "Lituania", "a", "principios", "de", "los", "a\u00f1os", "veinte", "."], "sentence-detokenized": "Pas\u00f3 su infancia en Par\u00eds, Francia, donde sus padres hab\u00edan emigrado de Lituania a principios de los a\u00f1os veinte.", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 19], [20, 25], [25, 26], [27, 34], [34, 35], [36, 41], [42, 45], [46, 52], [53, 59], [60, 68], [69, 71], [72, 80], [81, 82], [83, 93], [94, 96], [97, 100], [101, 105], [106, 112], [112, 113]]}
{"doc_key": "ai-dev-326", "ner": [[2, 5, "researcher"], [8, 12, "misc"], [15, 17, "organisation"], [19, 22, "university"], [28, 31, "university"], [39, 41, "university"], [45, 49, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 5, 8, 12, "role", "", false, false], [2, 5, 19, 22, "physical", "", false, false], [2, 5, 28, 31, "role", "", false, false], [2, 5, 39, 41, "role", "", false, false], [2, 5, 45, 49, "role", "", false, false], [8, 12, 15, 17, "part-of", "", false, false], [15, 17, 19, 22, "part-of", "", false, false], [39, 41, 28, 31, "part-of", "", false, false], [45, 49, 28, 31, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Anteriormente", ",", "el", "Dr", ".", "Paulos", "ocup\u00f3", "la", "C\u00e1tedra", "Cooper-Siegel", "de", "Profesor", "Asociado", "en", "la", "Escuela", "de", "Inform\u00e1tica", "de", "la", "Universidad", "Carnegie", "Mellon", ",", "donde", "fue", "profesor", "del", "Instituto", "de", "Interacci\u00f3n", "Persona-Ordenador", ",", "con", "nombramientos", "de", "cortes\u00eda", "en", "el", "Instituto", "de", "Rob\u00f3tica", "y", "en", "el", "Centro", "de", "Tecnolog\u00eda", "del", "Entretenimiento", "."], "sentence-detokenized": "Anteriormente, el Dr. Paulos ocup\u00f3 la C\u00e1tedra Cooper-Siegel de Profesor Asociado en la Escuela de Inform\u00e1tica de la Universidad Carnegie Mellon, donde fue profesor del Instituto de Interacci\u00f3n Persona-Ordenador, con nombramientos de cortes\u00eda en el Instituto de Rob\u00f3tica y en el Centro de Tecnolog\u00eda del Entretenimiento.", "token2charspan": [[0, 13], [13, 14], [15, 17], [18, 20], [20, 21], [22, 28], [29, 34], [35, 37], [38, 45], [46, 59], [60, 62], [63, 71], [72, 80], [81, 83], [84, 86], [87, 94], [95, 97], [98, 109], [110, 112], [113, 115], [116, 127], [128, 136], [137, 143], [143, 144], [145, 150], [151, 154], [155, 163], [164, 167], [168, 177], [178, 180], [181, 192], [193, 210], [210, 211], [212, 215], [216, 229], [230, 232], [233, 241], [242, 244], [245, 247], [248, 257], [258, 260], [261, 269], [270, 271], [272, 274], [275, 277], [278, 284], [285, 287], [288, 298], [299, 302], [303, 318], [318, 319]]}
{"doc_key": "ai-dev-327", "ner": [[3, 4, "researcher"], [7, 10, "university"], [14, 15, "product"], [18, 22, "product"], [29, 31, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 7, 10, "physical", "", false, false], [3, 4, 7, 10, "role", "", false, false], [14, 15, 3, 4, "artifact", "", false, false], [14, 15, 18, 22, "type-of", "", false, false], [14, 15, 29, 31, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["En", "1969", ",", "Victor", "Scheinman", ",", "de", "la", "Universidad", "de", "Stanford", ",", "invent\u00f3", "el", "brazo", "Stanford", ",", "un", "robot", "articulado", "de", "6", "ejes", "totalmente", "el\u00e9ctrico", "dise\u00f1ado", "para", "permitir", "una", "soluci\u00f3n", "de", "brazo", "."], "sentence-detokenized": "En 1969, Victor Scheinman, de la Universidad de Stanford, invent\u00f3 el brazo Stanford, un robot articulado de 6 ejes totalmente el\u00e9ctrico dise\u00f1ado para permitir una soluci\u00f3n de brazo.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 25], [25, 26], [27, 29], [30, 32], [33, 44], [45, 47], [48, 56], [56, 57], [58, 65], [66, 68], [69, 74], [75, 83], [83, 84], [85, 87], [88, 93], [94, 104], [105, 107], [108, 109], [110, 114], [115, 125], [126, 135], [136, 144], [145, 149], [150, 158], [159, 162], [163, 171], [172, 174], [175, 180], [180, 181]]}
{"doc_key": "ai-dev-328", "ner": [[5, 5, "product"], [17, 18, "field"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 17, 18, "related-to", "", false, false], [5, 5, 21, 22, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "creaci\u00f3n", "e", "implementaci\u00f3n", "de", "chatbots", "es", "todav\u00eda", "un", "\u00e1rea", "en", "desarrollo", ",", "fuertemente", "relacionada", "con", "la", "inteligencia", "artificial", "y", "el", "aprendizaje", "autom\u00e1tico", ",", "por", "lo", "que", "las", "soluciones", "proporcionadas", ",", "aunque", "poseen", "ventajas", "obvias", ",", "tienen", "algunas", "limitaciones", "importantes", "en", "t\u00e9rminos", "de", "funcionalidades", "y", "casos", "de", "uso", "."], "sentence-detokenized": "La creaci\u00f3n e implementaci\u00f3n de chatbots es todav\u00eda un \u00e1rea en desarrollo, fuertemente relacionada con la inteligencia artificial y el aprendizaje autom\u00e1tico, por lo que las soluciones proporcionadas, aunque poseen ventajas obvias, tienen algunas limitaciones importantes en t\u00e9rminos de funcionalidades y casos de uso.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 28], [29, 31], [32, 40], [41, 43], [44, 51], [52, 54], [55, 59], [60, 62], [63, 73], [73, 74], [75, 86], [87, 98], [99, 102], [103, 105], [106, 118], [119, 129], [130, 131], [132, 134], [135, 146], [147, 157], [157, 158], [159, 162], [163, 165], [166, 169], [170, 173], [174, 184], [185, 199], [199, 200], [201, 207], [208, 214], [215, 223], [224, 230], [230, 231], [232, 238], [239, 246], [247, 259], [260, 271], [272, 274], [275, 283], [284, 286], [287, 302], [303, 304], [305, 310], [311, 313], [314, 317], [317, 318]]}
{"doc_key": "ai-dev-329", "ner": [[16, 19, "university"], [11, 14, "product"], [29, 31, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 14, 16, 19, "part-of", "", true, false], [29, 31, 11, 14, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["En", "cuanto", "a", "los", "recursos", "disponibles", "de", "forma", "gratuita", ",", "el", "conjunto", "de", "herramientas", "Sphinx", "de", "la", "Universidad", "Carnegie", "Mellon", "es", "un", "punto", "de", "partida", "para", "aprender", "sobre", "el", "reconocimiento", "del", "habla", "y", "empezar", "a", "experimentar", "."], "sentence-detokenized": "En cuanto a los recursos disponibles de forma gratuita, el conjunto de herramientas Sphinx de la Universidad Carnegie Mellon es un punto de partida para aprender sobre el reconocimiento del habla y empezar a experimentar.", "token2charspan": [[0, 2], [3, 9], [10, 11], [12, 15], [16, 24], [25, 36], [37, 39], [40, 45], [46, 54], [54, 55], [56, 58], [59, 67], [68, 70], [71, 83], [84, 90], [91, 93], [94, 96], [97, 108], [109, 117], [118, 124], [125, 127], [128, 130], [131, 136], [137, 139], [140, 147], [148, 152], [153, 161], [162, 167], [168, 170], [171, 185], [186, 189], [190, 195], [196, 197], [198, 205], [206, 207], [208, 220], [220, 221]]}
{"doc_key": "ai-dev-330", "ner": [[0, 5, "misc"], [17, 22, "misc"], [24, 24, "misc"], [28, 29, "university"], [31, 31, "location"], [33, 33, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 5, 17, 22, "temporal", "", false, false], [24, 24, 17, 22, "named", "", false, false], [24, 24, 31, 31, "physical", "", false, false], [28, 29, 24, 24, "role", "", false, false], [31, 31, 33, 33, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["La", "competici\u00f3n", "formal", "de", "la", "RoboCup", "fue", "precedida", "por", "el", "(", "a", "menudo", "no", "reconocido", ")", "primer", "Torneo", "Internacional", "de", "F\u00fatbol", "de", "Microrobots", "(", "MIROSOT", ")", "celebrado", "por", "el", "KAIST", "en", "Taejon", ",", "Corea", ",", "en", "noviembre", "de", "1996", "."], "sentence-detokenized": "La competici\u00f3n formal de la RoboCup fue precedida por el (a menudo no reconocido) primer Torneo Internacional de F\u00fatbol de Microrobots (MIROSOT) celebrado por el KAIST en Taejon, Corea, en noviembre de 1996.", "token2charspan": [[0, 2], [3, 14], [15, 21], [22, 24], [25, 27], [28, 35], [36, 39], [40, 49], [50, 53], [54, 56], [57, 58], [58, 59], [60, 66], [67, 69], [70, 80], [80, 81], [82, 88], [89, 95], [96, 109], [110, 112], [113, 119], [120, 122], [123, 134], [135, 136], [136, 143], [143, 144], [145, 154], [155, 158], [159, 161], [162, 167], [168, 170], [171, 177], [177, 178], [179, 184], [184, 185], [186, 188], [189, 198], [199, 201], [202, 206], [206, 207]]}
{"doc_key": "ai-dev-331", "ner": [[5, 5, "metrics"], [26, 28, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Adem\u00e1s", "de", "la", "p\u00e9rdida", "de", "bisagra", "est\u00e1ndar", "math", "(", "1-yf", "(", "x", ")", ")", "_", "+", "/", "math", "para", "los", "datos", "etiquetados", ",", "se", "introduce", "una", "funci\u00f3n", "de", "p\u00e9rdida", "math", "(", "-1", "|", "f", "(", "x", ")", "|", ")", "_", "+", "/", "math", "se", "introduce", "sobre", "los", "datos", "no", "etiquetados", "dejando", "que", "mathy", "=", "\\", "nombre", "del", "operador", "{", "signo", "}", "{", "f", "(", "x", ")", "}", "/", "math", "."], "sentence-detokenized": "Adem\u00e1s de la p\u00e9rdida de bisagra est\u00e1ndar math (1-yf (x)) _ + / math para los datos etiquetados, se introduce una funci\u00f3n de p\u00e9rdida math (-1 | f (x) |) _ + / math se introduce sobre los datos no etiquetados dejando que mathy =\\ nombre del operador {signo} {f (x)} / math.", "token2charspan": [[0, 6], [7, 9], [10, 12], [13, 20], [21, 23], [24, 31], [32, 40], [41, 45], [46, 47], [47, 51], [52, 53], [53, 54], [54, 55], [55, 56], [57, 58], [59, 60], [61, 62], [63, 67], [68, 72], [73, 76], [77, 82], [83, 94], [94, 95], [96, 98], [99, 108], [109, 112], [113, 120], [121, 123], [124, 131], [132, 136], [137, 138], [138, 140], [141, 142], [143, 144], [145, 146], [146, 147], [147, 148], [149, 150], [150, 151], [152, 153], [154, 155], [156, 157], [158, 162], [163, 165], [166, 175], [176, 181], [182, 185], [186, 191], [192, 194], [195, 206], [207, 214], [215, 218], [219, 224], [225, 226], [226, 227], [228, 234], [235, 238], [239, 247], [248, 249], [249, 254], [254, 255], [256, 257], [257, 258], [259, 260], [260, 261], [261, 262], [262, 263], [264, 265], [266, 270], [270, 271]]}
{"doc_key": "ai-dev-332", "ner": [[3, 4, "misc"], [10, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 10, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["En", "particular", ",", "el", "RLS", "est\u00e1", "dise\u00f1ado", "para", "minimizar", "el", "error", "cuadr\u00e1tico", "medio", "entre", "los", "valores", "predichos", "y", "las", "etiquetas", "VERDADERAS", ",", "sujeto", "a", "la", "regularizaci\u00f3n", "."], "sentence-detokenized": "En particular, el RLS est\u00e1 dise\u00f1ado para minimizar el error cuadr\u00e1tico medio entre los valores predichos y las etiquetas VERDADERAS, sujeto a la regularizaci\u00f3n.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 17], [18, 21], [22, 26], [27, 35], [36, 40], [41, 50], [51, 53], [54, 59], [60, 70], [71, 76], [77, 82], [83, 86], [87, 94], [95, 104], [105, 106], [107, 110], [111, 120], [121, 131], [131, 132], [133, 139], [140, 141], [142, 144], [145, 159], [159, 160]]}
{"doc_key": "ai-dev-333", "ner": [[5, 8, "algorithm"], [11, 13, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 8, 11, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Esencialmente", ",", "esto", "combina", "la", "estimaci\u00f3n", "de", "m\u00e1xima", "verosimilitud", "con", "un", "procedimiento", "de", "regularizaci\u00f3n", "que", "favorece", "los", "modelos", "m\u00e1s", "simples", "sobre", "los", "m\u00e1s", "complejos", "."], "sentence-detokenized": "Esencialmente, esto combina la estimaci\u00f3n de m\u00e1xima verosimilitud con un procedimiento de regularizaci\u00f3n que favorece los modelos m\u00e1s simples sobre los m\u00e1s complejos.", "token2charspan": [[0, 13], [13, 14], [15, 19], [20, 27], [28, 30], [31, 41], [42, 44], [45, 51], [52, 65], [66, 69], [70, 72], [73, 86], [87, 89], [90, 104], [105, 108], [109, 117], [118, 121], [122, 129], [130, 133], [134, 141], [142, 147], [148, 151], [152, 155], [156, 165], [165, 166]]}
{"doc_key": "ai-dev-334", "ner": [[1, 4, "metrics"], [9, 9, "metrics"], [11, 11, "metrics"], [13, 15, "misc"], [18, 20, "misc"], [34, 37, "algorithm"], [40, 43, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 9, 1, 4, "named", "", false, false], [11, 11, 1, 4, "named", "", false, false], [13, 15, 18, 20, "related-to", "", false, false], [13, 15, 34, 37, "related-to", "ratio", false, false], [34, 37, 40, 43, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["La", "tasa", "de", "verdaderos", "positivos", "tambi\u00e9n", "se", "conoce", "como", "sensibilidad", ",", "recuerdo", "o", "probabilidad", "de", "detecci\u00f3n", "matem\u00e1tica", "al", "umbral", "de", "discriminaci\u00f3n", ")", "de", "la", "probabilidad", "de", "detecci\u00f3n", "en", "el", "eje", "y", "frente", "a", "la", "funci\u00f3n", "de", "distribuci\u00f3n", "acumulativa", "de", "la", "probabilidad", "de", "falsa", "alarma", "en", "el", "eje", "x."], "sentence-detokenized": "La tasa de verdaderos positivos tambi\u00e9n se conoce como sensibilidad, recuerdo o probabilidad de detecci\u00f3n matem\u00e1tica al umbral de discriminaci\u00f3n) de la probabilidad de detecci\u00f3n en el eje y frente a la funci\u00f3n de distribuci\u00f3n acumulativa de la probabilidad de falsa alarma en el eje x.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 21], [22, 31], [32, 39], [40, 42], [43, 49], [50, 54], [55, 67], [67, 68], [69, 77], [78, 79], [80, 92], [93, 95], [96, 105], [106, 116], [117, 119], [120, 126], [127, 129], [130, 144], [144, 145], [146, 148], [149, 151], [152, 164], [165, 167], [168, 177], [178, 180], [181, 183], [184, 187], [188, 189], [190, 196], [197, 198], [199, 201], [202, 209], [210, 212], [213, 225], [226, 237], [238, 240], [241, 243], [244, 256], [257, 259], [260, 265], [266, 272], [273, 275], [276, 278], [279, 282], [283, 285]]}
{"doc_key": "ai-dev-335", "ner": [[1, 1, "misc"], [3, 3, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 1, 1, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["En", "ingl\u00e9s", ",", "WordNet", "es", "un", "ejemplo", "de", "red", "sem\u00e1ntica", "."], "sentence-detokenized": "En ingl\u00e9s, WordNet es un ejemplo de red sem\u00e1ntica.", "token2charspan": [[0, 2], [3, 9], [9, 10], [11, 18], [19, 21], [22, 24], [25, 32], [33, 35], [36, 39], [40, 49], [49, 50]]}
{"doc_key": "ai-dev-336", "ner": [[4, 8, "product"], [11, 13, "product"], [29, 31, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[29, 31, 4, 8, "usage", "", false, false], [29, 31, 11, 13, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["El", "uso", "prolongado", "de", "programas", "de", "reconocimiento", "de", "voz", "junto", "con", "procesadores", "de", "texto", "ha", "demostrado", "ser", "beneficioso", "para", "el", "fortalecimiento", "de", "la", "memoria", "a", "corto", "plazo", "en", "pacientes", "con", "MAV", "cerebral", "que", "han", "sido", "tratados", "con", "resecci\u00f3n", "."], "sentence-detokenized": "El uso prolongado de programas de reconocimiento de voz junto con procesadores de texto ha demostrado ser beneficioso para el fortalecimiento de la memoria a corto plazo en pacientes con MAV cerebral que han sido tratados con resecci\u00f3n.", "token2charspan": [[0, 2], [3, 6], [7, 17], [18, 20], [21, 30], [31, 33], [34, 48], [49, 51], [52, 55], [56, 61], [62, 65], [66, 78], [79, 81], [82, 87], [88, 90], [91, 101], [102, 105], [106, 117], [118, 122], [123, 125], [126, 141], [142, 144], [145, 147], [148, 155], [156, 157], [158, 163], [164, 169], [170, 172], [173, 182], [183, 186], [187, 190], [191, 199], [200, 203], [204, 207], [208, 212], [213, 221], [222, 225], [226, 235], [235, 236]]}
{"doc_key": "ai-dev-337", "ner": [[6, 7, "researcher"], [9, 10, "researcher"], [12, 13, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sus", "jefes", "de", "redacci\u00f3n", "fundadores", "fueron", "Ron", "Sun", ",", "Vasant", "Honavar", "y", "Gregg", "Oden", "(", "de", "1999", "a", "2014", ")", "."], "sentence-detokenized": "Sus jefes de redacci\u00f3n fundadores fueron Ron Sun, Vasant Honavar y Gregg Oden (de 1999 a 2014).", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 22], [23, 33], [34, 40], [41, 44], [45, 48], [48, 49], [50, 56], [57, 64], [65, 66], [67, 72], [73, 77], [78, 79], [79, 81], [82, 86], [87, 88], [89, 93], [93, 94], [94, 95]]}
{"doc_key": "ai-dev-338", "ner": [[10, 12, "product"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 12, 18, 19, "opposite", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Su", "distinci\u00f3n", "\"", "paralela", "\"", ",", "a", "diferencia", "de", "un", "manipulador", "en", "serie", ",", "consiste", "en", "que", "el", "efector", "final", "(", "o", "\"", "mano", "\"", ")", "de", "este", "enlace", "(", "o", "\"", "brazo", "\"", ")", "est\u00e1", "directamente", "conectado", "a", "su", "base", "por", "una", "serie", "de", "enlaces", "(", "normalmente", "tres", "o", "seis", ")", "separados", "e", "independientes", "que", "trabajan", "simult\u00e1neamente", "."], "sentence-detokenized": "Su distinci\u00f3n \"paralela\", a diferencia de un manipulador en serie, consiste en que el efector final (o \"mano\") de este enlace (o \"brazo\") est\u00e1 directamente conectado a su base por una serie de enlaces (normalmente tres o seis) separados e independientes que trabajan simult\u00e1neamente.", "token2charspan": [[0, 2], [3, 13], [14, 15], [15, 23], [23, 24], [24, 25], [26, 27], [28, 38], [39, 41], [42, 44], [45, 56], [57, 59], [60, 65], [65, 66], [67, 75], [76, 78], [79, 82], [83, 85], [86, 93], [94, 99], [100, 101], [101, 102], [103, 104], [104, 108], [108, 109], [109, 110], [111, 113], [114, 118], [119, 125], [126, 127], [127, 128], [129, 130], [130, 135], [135, 136], [136, 137], [138, 142], [143, 155], [156, 165], [166, 167], [168, 170], [171, 175], [176, 179], [180, 183], [184, 189], [190, 192], [193, 200], [201, 202], [202, 213], [214, 218], [219, 220], [221, 225], [225, 226], [227, 236], [237, 238], [239, 253], [254, 257], [258, 266], [267, 282], [282, 283]]}
{"doc_key": "ai-dev-339", "ner": [[7, 8, "researcher"], [21, 22, "researcher"], [23, 24, "researcher"], [26, 27, "researcher"], [29, 30, "researcher"], [32, 33, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Su", "director", "de", "tesis", "fue", "el", "profesor", "Cordell", "Green", ",", "y", "su", "comit\u00e9", "de", "tesis", "/", "oral", "incluy\u00f3", "a", "los", "profesores", "Edward", "Feigenbaum", "Joshua", "Lederberg", ",", "Paul", "Cohen", ",", "Allen", "Newell", ",", "Herbert", "Simon", ",", "."], "sentence-detokenized": "Su director de tesis fue el profesor Cordell Green, y su comit\u00e9 de tesis / oral incluy\u00f3 a los profesores Edward Feigenbaum Joshua Lederberg, Paul Cohen, Allen Newell, Herbert Simon,.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 20], [21, 24], [25, 27], [28, 36], [37, 44], [45, 50], [50, 51], [52, 53], [54, 56], [57, 63], [64, 66], [67, 72], [73, 74], [75, 79], [80, 87], [88, 89], [90, 93], [94, 104], [105, 111], [112, 122], [123, 129], [130, 139], [139, 140], [141, 145], [146, 151], [151, 152], [153, 158], [159, 165], [165, 166], [167, 174], [175, 180], [180, 181], [181, 182]]}
{"doc_key": "ai-dev-340", "ner": [[5, 6, "metrics"], [9, 11, "metrics"], [14, 16, "metrics"], [19, 21, "metrics"], [24, 26, "metrics"], [29, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Dichas", "funciones", "incluyen", "el", "error", "cuadr\u00e1tico", "medio", ",", "el", "error", "cuadr\u00e1tico", "medio", ",", "el", "error", "absoluto", "medio", ",", "el", "error", "cuadr\u00e1tico", "relativo", ",", "el", "error", "cuadr\u00e1tico", "relativo", ",", "el", "error", "absoluto", "relativo", "y", "otros", "."], "sentence-detokenized": "Dichas funciones incluyen el error cuadr\u00e1tico medio, el error cuadr\u00e1tico medio, el error absoluto medio, el error cuadr\u00e1tico relativo, el error cuadr\u00e1tico relativo, el error absoluto relativo y otros.", "token2charspan": [[0, 6], [7, 16], [17, 25], [26, 28], [29, 34], [35, 45], [46, 51], [51, 52], [53, 55], [56, 61], [62, 72], [73, 78], [78, 79], [80, 82], [83, 88], [89, 97], [98, 103], [103, 104], [105, 107], [108, 113], [114, 124], [125, 133], [133, 134], [135, 137], [138, 143], [144, 154], [155, 163], [163, 164], [165, 167], [168, 173], [174, 182], [183, 191], [192, 193], [194, 199], [199, 200]]}
{"doc_key": "ai-dev-341", "ner": [[3, 3, "programlang"], [5, 5, "programlang"], [7, 7, "product"], [9, 9, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Hay", "enlaces", "en", "Python", ",", "Java", "y", "MATLAB", "/", "OCTAVE", "."], "sentence-detokenized": "Hay enlaces en Python, Java y MATLAB / OCTAVE.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 21], [21, 22], [23, 27], [28, 29], [30, 36], [37, 38], [39, 45], [45, 46]]}
{"doc_key": "ai-dev-342", "ner": [[6, 6, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Se", "puede", "encontrar", "una", "implementaci\u00f3n", "en", "MATLAB", "en", "el", "."], "sentence-detokenized": "Se puede encontrar una implementaci\u00f3n en MATLAB en el.", "token2charspan": [[0, 2], [3, 8], [9, 18], [19, 22], [23, 37], [38, 40], [41, 47], [48, 50], [51, 53], [53, 54]]}
{"doc_key": "ai-dev-343", "ner": [[0, 1, "researcher"], [10, 11, "field"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"], [24, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 11, 0, 1, "origin", "", false, false], [10, 11, 15, 16, "origin", "", false, false], [10, 11, 18, 19, "origin", "", false, false], [10, 11, 21, 22, "origin", "", false, false], [10, 11, 24, 26, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["John", "McCarthy", "es", "uno", "de", "los", "padres", "fundadores", "de", "la", "inteligencia", "artificial", ",", "junto", "con", "Alan", "Turing", ",", "Marvin", "Minsky", ",", "Allen", "Newell", "y", "Herbert", "A.", "Simon", "."], "sentence-detokenized": "John McCarthy es uno de los padres fundadores de la inteligencia artificial, junto con Alan Turing, Marvin Minsky, Allen Newell y Herbert A. Simon.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 20], [21, 23], [24, 27], [28, 34], [35, 45], [46, 48], [49, 51], [52, 64], [65, 75], [75, 76], [77, 82], [83, 86], [87, 91], [92, 98], [98, 99], [100, 106], [107, 113], [113, 114], [115, 120], [121, 127], [128, 129], [130, 137], [138, 140], [141, 146], [146, 147]]}
{"doc_key": "ai-dev-344", "ner": [[10, 12, "product"], [20, 21, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Un", "manipulador", "paralelo", "es", "un", "sistema", "mec\u00e1nico", "que", "utiliza", "varios", "manipuladores", "en", "serie", "para", "soportar", "una", "\u00fanica", "plataforma", ",", "o", "efector", "final", "."], "sentence-detokenized": "Un manipulador paralelo es un sistema mec\u00e1nico que utiliza varios manipuladores en serie para soportar una \u00fanica plataforma, o efector final.", "token2charspan": [[0, 2], [3, 14], [15, 23], [24, 26], [27, 29], [30, 37], [38, 46], [47, 50], [51, 58], [59, 65], [66, 79], [80, 82], [83, 88], [89, 93], [94, 102], [103, 106], [107, 112], [113, 123], [123, 124], [125, 126], [127, 134], [135, 140], [140, 141]]}
{"doc_key": "ai-dev-345", "ner": [[0, 0, "product"], [5, 7, "task"], [9, 9, "product"], [11, 15, "product"], [27, 27, "misc"], [30, 30, "misc"], [33, 35, "misc"], [38, 42, "task"], [45, 50, "product"], [53, 55, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[9, 9, 0, 0, "part-of", "", false, false], [9, 9, 5, 7, "type-of", "", false, false], [11, 15, 9, 9, "named", "", false, false], [27, 27, 9, 9, "part-of", "", false, false], [30, 30, 9, 9, "part-of", "", false, false], [33, 35, 9, 9, "part-of", "", false, false], [38, 42, 9, 9, "part-of", "", false, false], [45, 50, 9, 9, "part-of", "", false, false], [53, 55, 9, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["GATE", "incluye", "un", "sistema", "de", "extracci\u00f3n", "de", "informaci\u00f3n", "denominado", "ANNIE", "(", "A", "Nearly-New", "Information", "Extraction", "System", ")", ",", "que", "es", "un", "conjunto", "de", "m\u00f3dulos", "compuesto", "por", "un", "tokenizador", ",", "un", "nomencl\u00e1tor", ",", "un", "divisor", "de", "frases", ",", "un", "etiquetador", "de", "parte", "del", "discurso", ",", "un", "transductor", "de", "reconocimiento", "de", "entidades", "nombradas", "y", "un", "etiquetador", "de", "coreferencia", "."], "sentence-detokenized": "GATE incluye un sistema de extracci\u00f3n de informaci\u00f3n denominado ANNIE (A Nearly-New Information Extraction System), que es un conjunto de m\u00f3dulos compuesto por un tokenizador, un nomencl\u00e1tor, un divisor de frases, un etiquetador de parte del discurso, un transductor de reconocimiento de entidades nombradas y un etiquetador de coreferencia.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 23], [24, 26], [27, 37], [38, 40], [41, 52], [53, 63], [64, 69], [70, 71], [71, 72], [73, 83], [84, 95], [96, 106], [107, 113], [113, 114], [114, 115], [116, 119], [120, 122], [123, 125], [126, 134], [135, 137], [138, 145], [146, 155], [156, 159], [160, 162], [163, 174], [174, 175], [176, 178], [179, 190], [190, 191], [192, 194], [195, 202], [203, 205], [206, 212], [212, 213], [214, 216], [217, 228], [229, 231], [232, 237], [238, 241], [242, 250], [250, 251], [252, 254], [255, 266], [267, 269], [270, 284], [285, 287], [288, 297], [298, 307], [308, 309], [310, 312], [313, 324], [325, 327], [328, 340], [340, 341]]}
{"doc_key": "ai-dev-346", "ner": [[4, 7, "university"], [16, 19, "country"], [23, 27, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Se", "gradu\u00f3", "en", "la", "Universidad", "Estatal", "de", "Mosc\u00fa", "y", "en", "noviembre", "de", "1978", "se", "march\u00f3", "a", "Estados", "Unidos", "gracias", "a", "la", "intervenci\u00f3n", "personal", "del", "senador", "Edward", "M.", "Kennedy", "."], "sentence-detokenized": "Se gradu\u00f3 en la Universidad Estatal de Mosc\u00fa y en noviembre de 1978 se march\u00f3 a Estados Unidos gracias a la intervenci\u00f3n personal del senador Edward M. Kennedy.", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 15], [16, 27], [28, 35], [36, 38], [39, 44], [45, 46], [47, 49], [50, 59], [60, 62], [63, 67], [68, 70], [71, 77], [78, 79], [80, 87], [88, 94], [95, 102], [103, 104], [105, 107], [108, 120], [121, 129], [130, 133], [134, 141], [142, 148], [149, 151], [152, 159], [159, 160]]}
{"doc_key": "ai-dev-347", "ner": [[4, 7, "organisation"], [10, 15, "misc"], [21, 21, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 7, 10, 15, "win-defeat", "", false, false], [10, 15, 21, 21, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["En", "2017", ",", "el", "equipo", "de", "DeepMind", "AlphaGo", "recibi\u00f3", "la", "medalla", "inaugural", "del", "IJCAI", "Marvin", "Minsky", "por", "sus", "logros", "sobresalientes", "en", "IA", "."], "sentence-detokenized": "En 2017, el equipo de DeepMind AlphaGo recibi\u00f3 la medalla inaugural del IJCAI Marvin Minsky por sus logros sobresalientes en IA.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 18], [19, 21], [22, 30], [31, 38], [39, 46], [47, 49], [50, 57], [58, 67], [68, 71], [72, 77], [78, 84], [85, 91], [92, 95], [96, 99], [100, 106], [107, 121], [122, 124], [125, 127], [127, 128]]}
{"doc_key": "ai-dev-348", "ner": [[5, 7, "misc"], [8, 9, "misc"], [14, 15, "misc"], [28, 33, "misc"], [34, 34, "misc"], [40, 40, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 7, 8, 9, "related-to", "is_recorded_by", false, false], [8, 9, 14, 15, "cause-effect", "", false, false], [8, 9, 14, 15, "physical", "", false, false], [8, 9, 28, 33, "physical", "", false, false], [8, 9, 40, 40, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Otras", "formas", "de", "registrar", "la", "propagaci\u00f3n", "an\u00f3mala", "son", "los", "troposcatters", "que", "provocan", "irregularidades", "en", "la", "troposfera", ",", "la", "dispersi\u00f3n", "debida", "a", "los", "meteoros", ",", "la", "refracci\u00f3n", "en", "las", "regiones", "y", "capas", "ionizadas", "de", "la", "ionosfera", "y", "la", "reflexi\u00f3n", "desde", "la", "ionosfera", "."], "sentence-detokenized": "Otras formas de registrar la propagaci\u00f3n an\u00f3mala son los troposcatters que provocan irregularidades en la troposfera, la dispersi\u00f3n debida a los meteoros, la refracci\u00f3n en las regiones y capas ionizadas de la ionosfera y la reflexi\u00f3n desde la ionosfera.", "token2charspan": [[0, 5], [6, 12], [13, 15], [16, 25], [26, 28], [29, 40], [41, 48], [49, 52], [53, 56], [57, 70], [71, 74], [75, 83], [84, 99], [100, 102], [103, 105], [106, 116], [116, 117], [118, 120], [121, 131], [132, 138], [139, 140], [141, 144], [145, 153], [153, 154], [155, 157], [158, 168], [169, 171], [172, 175], [176, 184], [185, 186], [187, 192], [193, 202], [203, 205], [206, 208], [209, 218], [219, 220], [221, 223], [224, 233], [234, 239], [240, 242], [243, 252], [252, 253]]}
{"doc_key": "ai-dev-349", "ner": [[0, 4, "field"], [6, 6, "field"], [13, 13, "field"], [16, 16, "field"], [19, 22, "field"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 4, 13, 13, "part-of", "", false, false], [0, 4, 16, 16, "part-of", "", false, false], [0, 4, 19, 22, "part-of", "", false, false], [0, 4, 25, 26, "part-of", "", false, false], [6, 6, 0, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["El", "procesamiento", "del", "lenguaje", "natural", "(", "PLN", ")", "es", "un", "subcampo", "de", "la", "ling\u00fc\u00edstica", ",", "la", "inform\u00e1tica", ",", "la", "ingenier\u00eda", "de", "la", "informaci\u00f3n", "y", "la", "inteligencia", "artificial", "que", "se", "ocupa", "de", "las", "interacciones", "entre", "los", "ordenadores", "y", "las", "lenguas", "humanas", "(", "naturales", ")", ",", "en", "particular", "de", "c\u00f3mo", "programar", "los", "ordenadores", "para", "procesar", "y", "analizar", "grandes", "cantidades", "de", "datos", "del", "lenguaje", "natural", "."], "sentence-detokenized": "El procesamiento del lenguaje natural (PLN) es un subcampo de la ling\u00fc\u00edstica, la inform\u00e1tica, la ingenier\u00eda de la informaci\u00f3n y la inteligencia artificial que se ocupa de las interacciones entre los ordenadores y las lenguas humanas (naturales), en particular de c\u00f3mo programar los ordenadores para procesar y analizar grandes cantidades de datos del lenguaje natural.", "token2charspan": [[0, 2], [3, 16], [17, 20], [21, 29], [30, 37], [38, 39], [39, 42], [42, 43], [44, 46], [47, 49], [50, 58], [59, 61], [62, 64], [65, 76], [76, 77], [78, 80], [81, 92], [92, 93], [94, 96], [97, 107], [108, 110], [111, 113], [114, 125], [126, 127], [128, 130], [131, 143], [144, 154], [155, 158], [159, 161], [162, 167], [168, 170], [171, 174], [175, 188], [189, 194], [195, 198], [199, 210], [211, 212], [213, 216], [217, 224], [225, 232], [233, 234], [234, 243], [243, 244], [244, 245], [246, 248], [249, 259], [260, 262], [263, 267], [268, 277], [278, 281], [282, 293], [294, 298], [299, 307], [308, 309], [310, 318], [319, 326], [327, 337], [338, 340], [341, 346], [347, 350], [351, 359], [360, 367], [367, 368]]}
{"doc_key": "ai-dev-350", "ner": [[8, 9, "organisation"], [11, 12, "organisation"], [14, 14, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Otros", "grupos", "clim\u00e1ticos", "activos", "liderados", "por", "j\u00f3venes", "son", "Extinction", "Rebellion", ",", "Sunrise", "Movement", ",", "SustainUS", ",", "entre", "otros", "que", "trabajan", "tanto", "a", "nivel", "transnacional", "como", "local", "."], "sentence-detokenized": "Otros grupos clim\u00e1ticos activos liderados por j\u00f3venes son Extinction Rebellion, Sunrise Movement, SustainUS, entre otros que trabajan tanto a nivel transnacional como local.", "token2charspan": [[0, 5], [6, 12], [13, 23], [24, 31], [32, 41], [42, 45], [46, 53], [54, 57], [58, 68], [69, 78], [78, 79], [80, 87], [88, 96], [96, 97], [98, 107], [107, 108], [109, 114], [115, 120], [121, 124], [125, 133], [134, 139], [140, 141], [142, 147], [148, 161], [162, 166], [167, 172], [172, 173]]}
