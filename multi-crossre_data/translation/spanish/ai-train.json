{"doc_key": "ai-train-1", "ner": [[4, 10, "product"], [16, 19, "field"], [22, 24, "task"], [27, 29, "task"], [33, 37, "task"], [41, 42, "field"], [43, 45, "researcher"], [47, 48, "researcher"], [50, 51, "researcher"], [53, 54, "researcher"], [56, 58, "researcher"], [60, 62, "researcher"], [64, 65, "researcher"], [67, 68, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 10, 16, 19, "part-of", "", false, false], [4, 10, 16, 19, "usage", "", false, false], [4, 10, 22, 24, "part-of", "", false, false], [4, 10, 22, 24, "usage", "", false, false], [4, 10, 27, 29, "part-of", "", false, false], [4, 10, 27, 29, "usage", "", false, false], [4, 10, 41, 42, "part-of", "", false, false], [4, 10, 41, 42, "usage", "", false, false], [33, 37, 27, 29, "part-of", "", false, false], [33, 37, 27, 29, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Los", "enfoques", "populares", "del", "sistema", "de", "recomendaci\u00f3n", "basado", "en", "la", "opini\u00f3n", "utilizan", "varias", "t\u00e9cnicas", ",", "como", "la", "miner\u00eda", "de", "textos", ",", "la", "recuperaci\u00f3n", "de", "informaci\u00f3n", ",", "el", "an\u00e1lisis", "de", "sentimientos", "(", "v\u00e9ase", "tambi\u00e9n", "el", "an\u00e1lisis", "de", "sentimientos", "multimodal", ")", "y", "el", "aprendizaje", "profundo", "X.Y", ".", "Feng", ",", "H.", "Zhang", ",", "Y.J.", "Ren", ",", "P.H.", "Shang", ",", "Y", ".", "Zhu", ",", "Y.C", ".", "Liang", ",", "R.C.", "Guan", ",", "D.", "Xu", ",", "(", "2019", ")", ",", ",", "21", "(", "5", ")", ":", "e12957", "."], "sentence-detokenized": "Los enfoques populares del sistema de recomendaci\u00f3n basado en la opini\u00f3n utilizan varias t\u00e9cnicas, como la miner\u00eda de textos, la recuperaci\u00f3n de informaci\u00f3n, el an\u00e1lisis de sentimientos (v\u00e9ase tambi\u00e9n el an\u00e1lisis de sentimientos multimodal) y el aprendizaje profundo X.Y. Feng, H. Zhang, Y.J. Ren, P.H. Shang, Y. Zhu, Y.C. Liang, R.C. Guan, D. Xu, (2019),, 21 (5): e12957.", "token2charspan": [[0, 3], [4, 12], [13, 22], [23, 26], [27, 34], [35, 37], [38, 51], [52, 58], [59, 61], [62, 64], [65, 72], [73, 81], [82, 88], [89, 97], [97, 98], [99, 103], [104, 106], [107, 114], [115, 117], [118, 124], [124, 125], [126, 128], [129, 141], [142, 144], [145, 156], [156, 157], [158, 160], [161, 169], [170, 172], [173, 185], [186, 187], [187, 192], [193, 200], [201, 203], [204, 212], [213, 215], [216, 228], [229, 239], [239, 240], [241, 242], [243, 245], [246, 257], [258, 266], [267, 270], [270, 271], [272, 276], [276, 277], [278, 280], [281, 286], [286, 287], [288, 292], [293, 296], [296, 297], [298, 302], [303, 308], [308, 309], [310, 311], [311, 312], [313, 316], [316, 317], [318, 321], [321, 322], [323, 328], [328, 329], [330, 334], [335, 339], [339, 340], [341, 343], [344, 346], [346, 347], [348, 349], [349, 353], [353, 354], [354, 355], [355, 356], [357, 359], [360, 361], [361, 362], [362, 363], [363, 364], [365, 371], [371, 372]]}
{"doc_key": "ai-train-2", "ner": [[10, 11, "university"], [17, 18, "researcher"], [20, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 18, 10, 11, "physical", "", false, false], [17, 18, 10, 11, "role", "", false, false], [20, 21, 10, 11, "physical", "", false, false], [20, 21, 10, 11, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Los", "defensores", "de", "las", "representaciones", "procedimentales", "se", "centraron", "principalmente", "en", "el", "MIT", ",", "bajo", "el", "liderazgo", "de", "Marvin", "Minsky", "y", "Seymour", "Papert", "."], "sentence-detokenized": "Los defensores de las representaciones procedimentales se centraron principalmente en el MIT, bajo el liderazgo de Marvin Minsky y Seymour Papert.", "token2charspan": [[0, 3], [4, 14], [15, 17], [18, 21], [22, 38], [39, 54], [55, 57], [58, 67], [68, 82], [83, 85], [86, 88], [89, 92], [92, 93], [94, 98], [99, 101], [102, 111], [112, 114], [115, 121], [122, 128], [129, 130], [131, 138], [139, 145], [145, 146]]}
{"doc_key": "ai-train-3", "ner": [[12, 12, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "interfaz", "est\u00e1ndar", "y", "la", "interfaz", "de", "la", "calculadora", "est\u00e1n", "escritas", "en", "Java", "."], "sentence-detokenized": "La interfaz est\u00e1ndar y la interfaz de la calculadora est\u00e1n escritas en Java.", "token2charspan": [[0, 2], [3, 11], [12, 20], [21, 22], [23, 25], [26, 34], [35, 37], [38, 40], [41, 52], [53, 58], [59, 67], [68, 70], [71, 75], [75, 76]]}
{"doc_key": "ai-train-4", "ner": [[0, 0, "product"], [28, 28, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 28, 28, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["Octave", "ayuda", "a", "resolver", "num\u00e9ricamente", "problemas", "lineales", "y", "no", "lineales", ",", "y", "a", "realizar", "otros", "experimentos", "num\u00e9ricos", "utilizando", "un", "programa", "que", "es", "compatible", "en", "su", "mayor", "parte", "con", "MATLAB", "."], "sentence-detokenized": "Octave ayuda a resolver num\u00e9ricamente problemas lineales y no lineales, y a realizar otros experimentos num\u00e9ricos utilizando un programa que es compatible en su mayor parte con MATLAB.", "token2charspan": [[0, 6], [7, 12], [13, 14], [15, 23], [24, 37], [38, 47], [48, 56], [57, 58], [59, 61], [62, 70], [70, 71], [72, 73], [74, 75], [76, 84], [85, 90], [91, 103], [104, 113], [114, 124], [125, 127], [128, 136], [137, 140], [141, 143], [144, 154], [155, 157], [158, 160], [161, 166], [167, 172], [173, 176], [177, 183], [183, 184]]}
{"doc_key": "ai-train-5", "ner": [[3, 5, "algorithm"], [10, 12, "misc"], [14, 15, "researcher"], [20, 23, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 5, 14, 15, "origin", "", false, false], [10, 12, 14, 15, "origin", "", false, false], [14, 15, 20, 23, "physical", "", false, false], [14, 15, 20, 23, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Las", "variantes", "del", "algoritmo", "de", "retropropagaci\u00f3n", ",", "as\u00ed", "como", "los", "m\u00e9todos", "no", "supervisados", "de", "Geoff", "Hinton", "y", "sus", "colegas", "de", "la", "Universidad", "de", "Toronto", ",", "pueden", "utilizarse", "para", "entrenar", "arquitecturas", "neuronales", "profundas", "y", "altamente", "no", "lineales", ",", "{", "{", "cite", "journal"], "sentence-detokenized": "Las variantes del algoritmo de retropropagaci\u00f3n, as\u00ed como los m\u00e9todos no supervisados de Geoff Hinton y sus colegas de la Universidad de Toronto, pueden utilizarse para entrenar arquitecturas neuronales profundas y altamente no lineales, {{cite journal", "token2charspan": [[0, 3], [4, 13], [14, 17], [18, 27], [28, 30], [31, 47], [47, 48], [49, 52], [53, 57], [58, 61], [62, 69], [70, 72], [73, 85], [86, 88], [89, 94], [95, 101], [102, 103], [104, 107], [108, 115], [116, 118], [119, 121], [122, 133], [134, 136], [137, 144], [144, 145], [146, 152], [153, 163], [164, 168], [169, 177], [178, 191], [192, 202], [203, 212], [213, 214], [215, 224], [225, 227], [228, 236], [236, 237], [238, 239], [239, 240], [240, 244], [245, 252]]}
{"doc_key": "ai-train-6", "ner": [[9, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["o", ",", "de", "forma", "equivalente", ",", "utilizando", "la", "notaci\u00f3n", "DCG", ":"], "sentence-detokenized": "o, de forma equivalente, utilizando la notaci\u00f3n DCG:", "token2charspan": [[0, 1], [1, 2], [3, 5], [6, 11], [12, 23], [23, 24], [25, 35], [36, 38], [39, 47], [48, 51], [51, 52]]}
{"doc_key": "ai-train-7", "ner": [[0, 2, "algorithm"], [7, 9, "algorithm"], [13, 16, "algorithm"], [19, 23, "algorithm"], [26, 27, "algorithm"], [29, 31, "algorithm"], [48, 49, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 7, 9, "type-of", "", false, false], [0, 2, 13, 16, "usage", "part-of?", true, false], [13, 16, 19, 23, "compare", "", false, false], [26, 27, 19, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Los", "mapas", "autoorganizativos", "se", "diferencian", "de", "otras", "redes", "neuronales", "artificiales", "porque", "aplican", "un", "aprendizaje", "competitivo", ",", "en", "contraposici\u00f3n", "al", "aprendizaje", "con", "correcci\u00f3n", "de", "errores", "(", "como", "la", "retropropagaci\u00f3n", "con", "descenso", "de", "gradiente", ")", ",", "y", "en", "el", "sentido", "de", "que", "utilizan", "una", "funci\u00f3n", "de", "vecindad", "para", "preservar", "las", "propiedades", "topol\u00f3gicas", "del", "espacio", "de", "entrada", "."], "sentence-detokenized": "Los mapas autoorganizativos se diferencian de otras redes neuronales artificiales porque aplican un aprendizaje competitivo, en contraposici\u00f3n al aprendizaje con correcci\u00f3n de errores (como la retropropagaci\u00f3n con descenso de gradiente), y en el sentido de que utilizan una funci\u00f3n de vecindad para preservar las propiedades topol\u00f3gicas del espacio de entrada.", "token2charspan": [[0, 3], [4, 9], [10, 27], [28, 30], [31, 42], [43, 45], [46, 51], [52, 57], [58, 68], [69, 81], [82, 88], [89, 96], [97, 99], [100, 111], [112, 123], [123, 124], [125, 127], [128, 142], [143, 145], [146, 157], [158, 161], [162, 172], [173, 175], [176, 183], [184, 185], [185, 189], [190, 192], [193, 209], [210, 213], [214, 222], [223, 225], [226, 235], [235, 236], [236, 237], [238, 239], [240, 242], [243, 245], [246, 253], [254, 256], [257, 260], [261, 269], [270, 273], [274, 281], [282, 284], [285, 293], [294, 298], [299, 308], [309, 312], [313, 324], [325, 336], [337, 340], [341, 348], [349, 351], [352, 359], [359, 360]]}
{"doc_key": "ai-train-8", "ner": [[13, 17, "organisation"], [30, 32, "misc"], [41, 45, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Desde", "principios", "de", "la", "d\u00e9cada", "de", "1990", ",", "varias", "autoridades", ",", "incluida", "la", "Sociedad", "de", "Ingenier\u00eda", "de", "Audio", ",", "recomiendan", "que", "las", "mediciones", "del", "rango", "din\u00e1mico", "se", "realicen", "con", "una", "se\u00f1al", "de", "audio", "presente", ",", "que", "luego", "se", "filtra", "en", "la", "medici\u00f3n", "del", "piso", "de", "ruido", "utilizada", "para", "determinar", "el", "rango", "din\u00e1mico", ".", "De", "esta", "forma", "se", "evitan", "las", "mediciones", "dudosas", "basadas", "en", "el", "uso", "de", "medios", "vac\u00edos", "o", "circuitos", "de", "silenciamiento", "."], "sentence-detokenized": "Desde principios de la d\u00e9cada de 1990, varias autoridades, incluida la Sociedad de Ingenier\u00eda de Audio, recomiendan que las mediciones del rango din\u00e1mico se realicen con una se\u00f1al de audio presente, que luego se filtra en la medici\u00f3n del piso de ruido utilizada para determinar el rango din\u00e1mico. De esta forma se evitan las mediciones dudosas basadas en el uso de medios vac\u00edos o circuitos de silenciamiento.", "token2charspan": [[0, 5], [6, 16], [17, 19], [20, 22], [23, 29], [30, 32], [33, 37], [37, 38], [39, 45], [46, 57], [57, 58], [59, 67], [68, 70], [71, 79], [80, 82], [83, 93], [94, 96], [97, 102], [102, 103], [104, 115], [116, 119], [120, 123], [124, 134], [135, 138], [139, 144], [145, 153], [154, 156], [157, 165], [166, 169], [170, 173], [174, 179], [180, 182], [183, 188], [189, 197], [197, 198], [199, 202], [203, 208], [209, 211], [212, 218], [219, 221], [222, 224], [225, 233], [234, 237], [238, 242], [243, 245], [246, 251], [252, 261], [262, 266], [267, 277], [278, 280], [281, 286], [287, 295], [295, 296], [297, 299], [300, 304], [305, 310], [311, 313], [314, 320], [321, 324], [325, 335], [336, 343], [344, 351], [352, 354], [355, 357], [358, 361], [362, 364], [365, 371], [372, 378], [379, 380], [381, 390], [391, 393], [394, 408], [408, 409]]}
{"doc_key": "ai-train-9", "ner": [[7, 8, "misc"], [20, 22, "task"], [24, 28, "task"], [30, 32, "task"], [34, 36, "task"], [39, 42, "task"], [38, 47, "task"], [49, 52, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[7, 8, 20, 22, "part-of", "concept_used_in", true, false], [7, 8, 24, 28, "part-of", "concept_used_in", false, false], [7, 8, 30, 32, "part-of", "concept_used_in", false, false], [7, 8, 34, 36, "part-of", "concept_used_in", false, false], [7, 8, 39, 42, "part-of", "concept_used_in", false, false], [7, 8, 38, 47, "part-of", "concept_used_in", false, false], [7, 8, 49, 52, "part-of", "concept_used_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["La", "t\u00e9cnica", "utilizada", "en", "la", "creaci\u00f3n", "de", "rostros", "propios", "y", "su", "uso", "para", "el", "reconocimiento", "tambi\u00e9n", "se", "utiliza", "fuera", "del", "reconocimiento", "de", "rostros", ":", "reconocimiento", "de", "escritura", "a", "mano", ",", "lectura", "de", "labios", ",", "reconocimiento", "de", "voz", ",", "interpretaci\u00f3n", "del", "lenguaje", "de", "signos", "/", "gestos", "de", "la", "mano", "y", "an\u00e1lisis", "de", "im\u00e1genes", "m\u00e9dicas", "."], "sentence-detokenized": "La t\u00e9cnica utilizada en la creaci\u00f3n de rostros propios y su uso para el reconocimiento tambi\u00e9n se utiliza fuera del reconocimiento de rostros: reconocimiento de escritura a mano, lectura de labios, reconocimiento de voz, interpretaci\u00f3n del lenguaje de signos / gestos de la mano y an\u00e1lisis de im\u00e1genes m\u00e9dicas.", "token2charspan": [[0, 2], [3, 10], [11, 20], [21, 23], [24, 26], [27, 35], [36, 38], [39, 46], [47, 54], [55, 56], [57, 59], [60, 63], [64, 68], [69, 71], [72, 86], [87, 94], [95, 97], [98, 105], [106, 111], [112, 115], [116, 130], [131, 133], [134, 141], [141, 142], [143, 157], [158, 160], [161, 170], [171, 172], [173, 177], [177, 178], [179, 186], [187, 189], [190, 196], [196, 197], [198, 212], [213, 215], [216, 219], [219, 220], [221, 235], [236, 239], [240, 248], [249, 251], [252, 258], [259, 260], [261, 267], [268, 270], [271, 273], [274, 278], [279, 280], [281, 289], [290, 292], [293, 301], [302, 309], [309, 310]]}
{"doc_key": "ai-train-10", "ner": [[0, 4, "organisation"], [11, 18, "organisation"], [19, 20, "organisation"], [24, 28, "organisation"], [32, 38, "organisation"], [41, 45, "organisation"], [49, 56, "organisation"], [58, 58, "organisation"], [62, 65, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[11, 18, 0, 4, "part-of", "", false, false], [19, 20, 11, 18, "named", "", false, false], [24, 28, 0, 4, "part-of", "", false, false], [32, 38, 0, 4, "part-of", "", false, false], [41, 45, 0, 4, "part-of", "", false, false], [49, 56, 0, 4, "part-of", "", false, false], [58, 58, 49, 56, "named", "", false, false], [62, 65, 0, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["La", "Fundaci\u00f3n", "Nacional", "de", "la", "Ciencia", "fue", "un", "paraguas", "para", "la", "Administraci\u00f3n", "Nacional", "de", "la", "Aeron\u00e1utica", "y", "del", "Espacio", "(", "NASA", ")", ",", "el", "Departamento", "de", "Energ\u00eda", "de", "EE.UU", ".", ",", "el", "Departamento", "de", "Comercio", "de", "EE.UU", ".", "NIST", ",", "el", "Departamento", "de", "Defensa", "de", "EE.UU", ".", ",", "la", "Agencia", "de", "Proyectos", "de", "Investigaci\u00f3n", "Avanzada", "de", "Defensa", "(", "DARPA", ")", "y", "la", "Oficina", "de", "Investigaci\u00f3n", "Naval", "coordinaron", "estudios", "para", "informar", "a", "los", "planificadores", "estrat\u00e9gicos", "en", "sus", "deliberaciones", "."], "sentence-detokenized": "La Fundaci\u00f3n Nacional de la Ciencia fue un paraguas para la Administraci\u00f3n Nacional de la Aeron\u00e1utica y del Espacio (NASA), el Departamento de Energ\u00eda de EE.UU., el Departamento de Comercio de EE.UU. NIST, el Departamento de Defensa de EE.UU., la Agencia de Proyectos de Investigaci\u00f3n Avanzada de Defensa (DARPA) y la Oficina de Investigaci\u00f3n Naval coordinaron estudios para informar a los planificadores estrat\u00e9gicos en sus deliberaciones.", "token2charspan": [[0, 2], [3, 12], [13, 21], [22, 24], [25, 27], [28, 35], [36, 39], [40, 42], [43, 51], [52, 56], [57, 59], [60, 74], [75, 83], [84, 86], [87, 89], [90, 101], [102, 103], [104, 107], [108, 115], [116, 117], [117, 121], [121, 122], [122, 123], [124, 126], [127, 139], [140, 142], [143, 150], [151, 153], [154, 159], [159, 160], [160, 161], [162, 164], [165, 177], [178, 180], [181, 189], [190, 192], [193, 198], [198, 199], [200, 204], [204, 205], [206, 208], [209, 221], [222, 224], [225, 232], [233, 235], [236, 241], [241, 242], [242, 243], [244, 246], [247, 254], [255, 257], [258, 267], [268, 270], [271, 284], [285, 293], [294, 296], [297, 304], [305, 306], [306, 311], [311, 312], [313, 314], [315, 317], [318, 325], [326, 328], [329, 342], [343, 348], [349, 360], [361, 369], [370, 374], [375, 383], [384, 385], [386, 389], [390, 404], [405, 417], [418, 420], [421, 424], [425, 439], [439, 440]]}
{"doc_key": "ai-train-11", "ner": [[8, 9, "metrics"], [12, 13, "algorithm"], [17, 19, "researcher"], [24, 24, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 12, 13, "part-of", "", false, false], [17, 19, 24, 24, "related-to", "added_appendix_to_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Un", "m\u00e9todo", "r\u00e1pido", "para", "calcular", "las", "estimaciones", "de", "m\u00e1xima", "verosimilitud", "para", "el", "modelo", "probit", "fue", "propuesto", "por", "Ronald", "Fisher", "como", "ap\u00e9ndice", "al", "trabajo", "de", "Bliss", "en", "1935", "."], "sentence-detokenized": "Un m\u00e9todo r\u00e1pido para calcular las estimaciones de m\u00e1xima verosimilitud para el modelo probit fue propuesto por Ronald Fisher como ap\u00e9ndice al trabajo de Bliss en 1935.", "token2charspan": [[0, 2], [3, 9], [10, 16], [17, 21], [22, 30], [31, 34], [35, 47], [48, 50], [51, 57], [58, 71], [72, 76], [77, 79], [80, 86], [87, 93], [94, 97], [98, 107], [108, 111], [112, 118], [119, 125], [126, 130], [131, 139], [140, 142], [143, 150], [151, 153], [154, 159], [160, 162], [163, 167], [167, 168]]}
{"doc_key": "ai-train-12", "ner": [[10, 11, "product"], [14, 15, "product"], [20, 20, "organisation"], [18, 18, "product"], [25, 28, "organisation"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[18, 18, 14, 15, "usage", "uses_software", false, false], [18, 18, 20, 20, "artifact", "", false, false], [18, 18, 23, 23, "named", "", false, false], [23, 23, 25, 28, "artifact", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Varios", "de", "estos", "programas", "est\u00e1n", "disponibles", "en", "l\u00ednea", ",", "como", "Google", "Translate", "y", "el", "sistema", "SYSTRAN", "que", "impulsa", "BabelFish", "de", "AltaVista", "(", "ahora", "Babelfish", "de", "Yahoo", "a", "partir", "del", "9", "de", "mayo", "de", "2008", ")", "."], "sentence-detokenized": "Varios de estos programas est\u00e1n disponibles en l\u00ednea, como Google Translate y el sistema SYSTRAN que impulsa BabelFish de AltaVista (ahora Babelfish de Yahoo a partir del 9 de mayo de 2008).", "token2charspan": [[0, 6], [7, 9], [10, 15], [16, 25], [26, 31], [32, 43], [44, 46], [47, 52], [52, 53], [54, 58], [59, 65], [66, 75], [76, 77], [78, 80], [81, 88], [89, 96], [97, 100], [101, 108], [109, 118], [119, 121], [122, 131], [132, 133], [133, 138], [139, 148], [149, 151], [152, 157], [158, 159], [160, 166], [167, 170], [171, 172], [173, 175], [176, 180], [181, 183], [184, 188], [188, 189], [189, 190]]}
{"doc_key": "ai-train-13", "ner": [[3, 3, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [21, 23, "field"], [26, 27, "misc"], [32, 34, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 3, 21, 23, "related-to", "", true, false], [3, 3, 26, 27, "related-to", "", true, false], [3, 3, 32, 34, "related-to", "", true, false], [7, 8, 21, 23, "related-to", "", true, false], [7, 8, 26, 27, "related-to", "", true, false], [7, 8, 32, 34, "related-to", "", true, false], [10, 11, 21, 23, "related-to", "", true, false], [10, 11, 26, 27, "related-to", "", true, false], [10, 11, 32, 34, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["En", "2002", ",", "Hutter", ",", "junto", "con", "J\u00fcrgen", "Schmidhuber", "y", "Shane", "Legg", ",", "desarroll\u00f3", "y", "public\u00f3", "una", "teor\u00eda", "matem\u00e1tica", "de", "la", "inteligencia", "general", "artificial", "basada", "en", "agentes", "inteligentes", "idealizados", "y", "en", "el", "aprendizaje", "por", "refuerzo", "motivado", "por", "la", "recompensa", "."], "sentence-detokenized": "En 2002, Hutter, junto con J\u00fcrgen Schmidhuber y Shane Legg, desarroll\u00f3 y public\u00f3 una teor\u00eda matem\u00e1tica de la inteligencia general artificial basada en agentes inteligentes idealizados y en el aprendizaje por refuerzo motivado por la recompensa.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [15, 16], [17, 22], [23, 26], [27, 33], [34, 45], [46, 47], [48, 53], [54, 58], [58, 59], [60, 70], [71, 72], [73, 80], [81, 84], [85, 91], [92, 102], [103, 105], [106, 108], [109, 121], [122, 129], [130, 140], [141, 147], [148, 150], [151, 158], [159, 171], [172, 183], [184, 185], [186, 188], [189, 191], [192, 203], [204, 207], [208, 216], [217, 225], [226, 229], [230, 232], [233, 243], [243, 244]]}
{"doc_key": "ai-train-14", "ner": [[9, 9, "metrics"], [11, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 9, 11, 15, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["La", "forma", "m\u00e1s", "habitual", "es", "utilizar", "la", "medida", "denominada", "ROUGE", "(", "Recall-Oriented", "Understudy", "for", "Gisting", "Evaluation", ")", "."], "sentence-detokenized": "La forma m\u00e1s habitual es utilizar la medida denominada ROUGE (Recall-Oriented Understudy for Gisting Evaluation).", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 21], [22, 24], [25, 33], [34, 36], [37, 43], [44, 54], [55, 60], [61, 62], [62, 77], [78, 88], [89, 92], [93, 100], [101, 111], [111, 112], [112, 113]]}
{"doc_key": "ai-train-15", "ner": [[0, 0, "product"], [14, 15, "programlang"], [17, 17, "programlang"], [19, 20, "researcher"], [22, 23, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 14, 15, "related-to", "", false, false], [0, 0, 17, 17, "related-to", "", false, false], [19, 20, 22, 23, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["RapidMiner", "proporciona", "esquemas", "de", "aprendizaje", ",", "modelos", "y", "algoritmos", "y", "puede", "ampliarse", "mediante", "scripts", "en", "R", "y", "Python", ".", "David", "Norris", ",", "Bloor", "Research", ",", "13", "de", "noviembre", "de", "2013", "."], "sentence-detokenized": "RapidMiner proporciona esquemas de aprendizaje, modelos y algoritmos y puede ampliarse mediante scripts en R y Python. David Norris, Bloor Research, 13 de noviembre de 2013.", "token2charspan": [[0, 10], [11, 22], [23, 31], [32, 34], [35, 46], [46, 47], [48, 55], [56, 57], [58, 68], [69, 70], [71, 76], [77, 86], [87, 95], [96, 103], [104, 106], [107, 108], [109, 110], [111, 117], [117, 118], [119, 124], [125, 131], [131, 132], [133, 138], [139, 147], [147, 148], [149, 151], [152, 154], [155, 164], [165, 167], [168, 172], [172, 173]]}
{"doc_key": "ai-train-16", "ner": [[0, 0, "product"], [12, 14, "field"], [17, 20, "task"], [24, 27, "misc"], [45, 45, "programlang"], [47, 48, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 12, 14, "related-to", "", false, false], [0, 0, 17, 20, "related-to", "", false, false], [0, 0, 47, 48, "related-to", "", true, false], [24, 27, 0, 0, "part-of", "", false, false], [47, 48, 45, 45, "general-affiliation", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["tity", "contiene", "una", "colecci\u00f3n", "de", "herramientas", "de", "visualizaci\u00f3n", "y", "algoritmos", "para", "el", "an\u00e1lisis", "de", "datos", "y", "la", "elaboraci\u00f3n", "de", "modelos", "predictivos", ",", "junto", "con", "interfaces", "gr\u00e1ficas", "de", "usuario", "que", "facilitan", "el", "acceso", "a", "estas", "funciones", ".", "pero", "la", "versi\u00f3n", "m\u00e1s", "reciente", ",", "totalmente", "basada", "en", "Java", "(", "Weka", "3", ")", ",", "cuyo", "desarrollo", "se", "inici\u00f3", "en", "1997", ",", "se", "utiliza", "actualmente", "en", "muchos", "\u00e1mbitos", "de", "aplicaci\u00f3n", "diferentes", ",", "en", "particular", "para", "fines", "educativos", "y", "de", "investigaci\u00f3n", "."], "sentence-detokenized": "tity contiene una colecci\u00f3n de herramientas de visualizaci\u00f3n y algoritmos para el an\u00e1lisis de datos y la elaboraci\u00f3n de modelos predictivos, junto con interfaces gr\u00e1ficas de usuario que facilitan el acceso a estas funciones. pero la versi\u00f3n m\u00e1s reciente, totalmente basada en Java (Weka 3), cuyo desarrollo se inici\u00f3 en 1997, se utiliza actualmente en muchos \u00e1mbitos de aplicaci\u00f3n diferentes, en particular para fines educativos y de investigaci\u00f3n.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 27], [28, 30], [31, 43], [44, 46], [47, 60], [61, 62], [63, 73], [74, 78], [79, 81], [82, 90], [91, 93], [94, 99], [100, 101], [102, 104], [105, 116], [117, 119], [120, 127], [128, 139], [139, 140], [141, 146], [147, 150], [151, 161], [162, 170], [171, 173], [174, 181], [182, 185], [186, 195], [196, 198], [199, 205], [206, 207], [208, 213], [214, 223], [223, 224], [225, 229], [230, 232], [233, 240], [241, 244], [245, 253], [253, 254], [255, 265], [266, 272], [273, 275], [276, 280], [281, 282], [282, 286], [287, 288], [288, 289], [289, 290], [291, 295], [296, 306], [307, 309], [310, 316], [317, 319], [320, 324], [324, 325], [326, 328], [329, 336], [337, 348], [349, 351], [352, 358], [359, 366], [367, 369], [370, 380], [381, 391], [391, 392], [393, 395], [396, 406], [407, 411], [412, 417], [418, 428], [429, 430], [431, 433], [434, 447], [447, 448]]}
{"doc_key": "ai-train-17", "ner": [[0, 0, "product"], [16, 23, "misc"], [26, 29, "misc"], [32, 40, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 23, 0, 0, "topic", "", false, false], [16, 23, 26, 29, "win-defeat", "", false, false], [26, 29, 32, 40, "temporal", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Eurisko", "hizo", "muchos", "descubrimientos", "interesantes", "y", "disfrut\u00f3", "de", "una", "importante", "aclamaci\u00f3n", ",", "ya", "que", "su", "art\u00edculo", "Heuretics", ":", "Theoretical", "and", "Study", "of", "Heuristic", "Rules", "gan\u00f3", "el", "premio", "al", "mejor", "art\u00edculo", "en", "la", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "de", "1982", "."], "sentence-detokenized": "Eurisko hizo muchos descubrimientos interesantes y disfrut\u00f3 de una importante aclamaci\u00f3n, ya que su art\u00edculo Heuretics: Theoretical and Study of Heuristic Rules gan\u00f3 el premio al mejor art\u00edculo en la Association for the Advancement of Artificial Intelligence de 1982.", "token2charspan": [[0, 7], [8, 12], [13, 19], [20, 35], [36, 48], [49, 50], [51, 59], [60, 62], [63, 66], [67, 77], [78, 88], [88, 89], [90, 92], [93, 96], [97, 99], [100, 108], [109, 118], [118, 119], [120, 131], [132, 135], [136, 141], [142, 144], [145, 154], [155, 160], [161, 165], [166, 168], [169, 175], [176, 178], [179, 184], [185, 193], [194, 196], [197, 199], [200, 211], [212, 215], [216, 219], [220, 231], [232, 234], [235, 245], [246, 258], [259, 261], [262, 266], [266, 267]]}
{"doc_key": "ai-train-18", "ner": [[11, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Para", "tener", "en", "cuenta", "las", "entidades", "m\u00faltiples", ",", "se", "calcula", "una", "p\u00e9rdida", "de", "bisagra", "distinta", "para", "cada", "c\u00e1psula", "."], "sentence-detokenized": "Para tener en cuenta las entidades m\u00faltiples, se calcula una p\u00e9rdida de bisagra distinta para cada c\u00e1psula.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 20], [21, 24], [25, 34], [35, 44], [44, 45], [46, 48], [49, 56], [57, 60], [61, 68], [69, 71], [72, 79], [80, 88], [89, 93], [94, 98], [99, 106], [106, 107]]}
{"doc_key": "ai-train-19", "ner": [[7, 9, "product"], [11, 12, "product"], [14, 15, "product"], [17, 18, "product"], [20, 22, "product"], [29, 32, "product"], [39, 45, "product"], [48, 49, "product"], [51, 52, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[7, 9, 29, 32, "type-of", "", false, false], [11, 12, 29, 32, "type-of", "", false, false], [14, 15, 29, 32, "type-of", "", false, false], [17, 18, 29, 32, "type-of", "", false, false], [20, 22, 29, 32, "type-of", "", false, false], [48, 49, 39, 45, "type-of", "", false, false], [51, 52, 39, 45, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Con", "la", "aparici\u00f3n", "de", "asistentes", "conversacionales", "como", "Siri", "de", "Apple", ",", "Amazon", "Alexa", ",", "Google", "Assistant", ",", "Microsoft", "Cortana", "y", "Bixby", "de", "Samsung", ",", "ahora", "se", "puede", "acceder", "a", "los", "portales", "de", "voz", "a", "trav\u00e9s", "de", "dispositivos", "m\u00f3viles", "y", "altavoces", "inteligentes", "de", "voz", "de", "Far", "Field", ",", "como", "Amazon", "Echo", "y", "Google", "Home", "."], "sentence-detokenized": "Con la aparici\u00f3n de asistentes conversacionales como Siri de Apple, Amazon Alexa, Google Assistant, Microsoft Cortana y Bixby de Samsung, ahora se puede acceder a los portales de voz a trav\u00e9s de dispositivos m\u00f3viles y altavoces inteligentes de voz de Far Field, como Amazon Echo y Google Home.", "token2charspan": [[0, 3], [4, 6], [7, 16], [17, 19], [20, 30], [31, 47], [48, 52], [53, 57], [58, 60], [61, 66], [66, 67], [68, 74], [75, 80], [80, 81], [82, 88], [89, 98], [98, 99], [100, 109], [110, 117], [118, 119], [120, 125], [126, 128], [129, 136], [136, 137], [138, 143], [144, 146], [147, 152], [153, 160], [161, 162], [163, 166], [167, 175], [176, 178], [179, 182], [183, 184], [185, 191], [192, 194], [195, 207], [208, 215], [216, 217], [218, 227], [228, 240], [241, 243], [244, 247], [248, 250], [251, 254], [255, 260], [260, 261], [262, 266], [267, 273], [274, 278], [279, 280], [281, 287], [288, 292], [292, 293]]}
{"doc_key": "ai-train-20", "ner": [[2, 3, "field"], [6, 8, "algorithm"], [11, 15, "algorithm"], [18, 20, "algorithm"], [23, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 8, 2, 3, "type-of", "", false, false], [11, 15, 2, 3, "type-of", "", false, false], [18, 20, 2, 3, "type-of", "", false, false], [23, 23, 2, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Ejemplos", "de", "aprendizaje", "supervisado", "son", "el", "clasificador", "Naive", "Bayes", ",", "la", "m\u00e1quina", "de", "vectores", "de", "apoyo", ",", "las", "mezclas", "de", "Gaussianas", "y", "la", "red", "."], "sentence-detokenized": "Ejemplos de aprendizaje supervisado son el clasificador Naive Bayes, la m\u00e1quina de vectores de apoyo, las mezclas de Gaussianas y la red.", "token2charspan": [[0, 8], [9, 11], [12, 23], [24, 35], [36, 39], [40, 42], [43, 55], [56, 61], [62, 67], [67, 68], [69, 71], [72, 79], [80, 82], [83, 91], [92, 94], [95, 100], [100, 101], [102, 105], [106, 113], [114, 116], [117, 127], [128, 129], [130, 132], [133, 136], [136, 137]]}
{"doc_key": "ai-train-21", "ner": [[4, 5, "algorithm"], [29, 33, "algorithm"], [36, 36, "task"], [41, 43, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 29, 33, "part-of", "", true, false], [41, 43, 36, 36, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Se", "puede", "utilizar", "el", "algoritmo", "OSD", "para", "derivar", "matem\u00e1ticamente", "O", "(", "\\", "sqrt", "{", "T", "}", ")", "/", "matem\u00e1ticamente", "l\u00edmites", "de", "arrepentimiento", "para", "la", "versi\u00f3n", "en", "l\u00ednea", "de", "la", "m\u00e1quina", "de", "vectores", "de", "apoyo", "para", "la", "clasificaci\u00f3n", ",", "que", "utilizan", "la", "p\u00e9rdida", "de", "bisagra", "matem\u00e1tica", "v", "_t", "(", "w", ")", "=", "\\", "max", "{", "0", ",", "1", "-", "y", "_t", "(", "w", "\\", "cdot", "x", "_t", ")", "\\", "}", ".", "/", "math"], "sentence-detokenized": "Se puede utilizar el algoritmo OSD para derivar matem\u00e1ticamente O (\\ sqrt {T}) / matem\u00e1ticamente l\u00edmites de arrepentimiento para la versi\u00f3n en l\u00ednea de la m\u00e1quina de vectores de apoyo para la clasificaci\u00f3n, que utilizan la p\u00e9rdida de bisagra matem\u00e1tica v _t (w) =\\ max {0, 1 - y _t (w\\ cdot x _t)\\}. / math", "token2charspan": [[0, 2], [3, 8], [9, 17], [18, 20], [21, 30], [31, 34], [35, 39], [40, 47], [48, 63], [64, 65], [66, 67], [67, 68], [69, 73], [74, 75], [75, 76], [76, 77], [77, 78], [79, 80], [81, 96], [97, 104], [105, 107], [108, 123], [124, 128], [129, 131], [132, 139], [140, 142], [143, 148], [149, 151], [152, 154], [155, 162], [163, 165], [166, 174], [175, 177], [178, 183], [184, 188], [189, 191], [192, 205], [205, 206], [207, 210], [211, 219], [220, 222], [223, 230], [231, 233], [234, 241], [242, 252], [253, 254], [255, 257], [258, 259], [259, 260], [260, 261], [262, 263], [263, 264], [265, 268], [269, 270], [270, 271], [271, 272], [273, 274], [275, 276], [277, 278], [279, 281], [282, 283], [283, 284], [284, 285], [286, 290], [291, 292], [293, 295], [295, 296], [296, 297], [297, 298], [298, 299], [300, 301], [302, 306]]}
{"doc_key": "ai-train-22", "ner": [[4, 6, "task"], [9, 13, "task"], [12, 12, "task"], [16, 18, "task"], [21, 23, "task"], [26, 28, "task"], [31, 33, "task"], [36, 40, "task"], [43, 45, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Las", "aplicaciones", "incluyen", "el", "reconocimiento", "de", "objetos", ",", "la", "cartograf\u00eda", "y", "la", "navegaci\u00f3n", "rob\u00f3tica", ",", "el", "cosido", "de", "im\u00e1genes", ",", "el", "modelado", "en", "3D", ",", "el", "reconocimiento", "de", "gestos", ",", "el", "seguimiento", "de", "v\u00eddeos", ",", "la", "identificaci\u00f3n", "individual", "de", "la", "fauna", "y", "el", "movimiento", "de", "partidos", "."], "sentence-detokenized": "Las aplicaciones incluyen el reconocimiento de objetos, la cartograf\u00eda y la navegaci\u00f3n rob\u00f3tica, el cosido de im\u00e1genes, el modelado en 3D, el reconocimiento de gestos, el seguimiento de v\u00eddeos, la identificaci\u00f3n individual de la fauna y el movimiento de partidos.", "token2charspan": [[0, 3], [4, 16], [17, 25], [26, 28], [29, 43], [44, 46], [47, 54], [54, 55], [56, 58], [59, 70], [71, 72], [73, 75], [76, 86], [87, 95], [95, 96], [97, 99], [100, 106], [107, 109], [110, 118], [118, 119], [120, 122], [123, 131], [132, 134], [135, 137], [137, 138], [139, 141], [142, 156], [157, 159], [160, 166], [166, 167], [168, 170], [171, 182], [183, 185], [186, 192], [192, 193], [194, 196], [197, 211], [212, 222], [223, 225], [226, 228], [229, 234], [235, 236], [237, 239], [240, 250], [251, 253], [254, 262], [262, 263]]}
{"doc_key": "ai-train-23", "ner": [[5, 9, "task"], [15, 18, "university"], [20, 23, "university"], [25, 28, "university"], [30, 33, "university"], [36, 41, "university"], [44, 48, "university"], [49, 52, "university"], [54, 57, "university"], [60, 65, "university"], [67, 67, "university"], [71, 75, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[5, 9, 15, 18, "related-to", "", true, false], [5, 9, 20, 23, "related-to", "", true, false], [5, 9, 25, 28, "related-to", "", true, false], [5, 9, 30, 33, "related-to", "", true, false], [5, 9, 36, 41, "related-to", "", true, false], [5, 9, 44, 48, "related-to", "", true, false], [5, 9, 49, 52, "related-to", "", true, false], [5, 9, 54, 57, "related-to", "", true, false], [5, 9, 60, 65, "related-to", "", true, false], [5, 9, 67, 67, "related-to", "", true, false], [5, 9, 71, 75, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Varios", "grupos", "y", "empresas", "investigan", "la", "estimaci\u00f3n", "de", "la", "pose", ",", "entre", "ellos", "los", "de", "la", "Universidad", "de", "Brown", ",", "la", "Universidad", "Carnegie", "Mellon", ",", "el", "MPI", "de", "Saarbruecken", ",", "la", "Universidad", "de", "Stanford", ",", "la", "Universidad", "de", "California", "en", "San", "Diego", ",", "la", "Universidad", "de", "Toronto", ",", "la", "\u00c9cole", "Centrale", "de", "Par\u00eds", ",", "la", "ETH", "de", "Z\u00farich", ",", "la", "Universidad", "Nacional", "de", "Ciencias", "y", "Tecnolog\u00eda", "(", "NUST", ")", "y", "la", "Universidad", "de", "California", "en", "Irvine", "."], "sentence-detokenized": "Varios grupos y empresas investigan la estimaci\u00f3n de la pose, entre ellos los de la Universidad de Brown, la Universidad Carnegie Mellon, el MPI de Saarbruecken, la Universidad de Stanford, la Universidad de California en San Diego, la Universidad de Toronto, la \u00c9cole Centrale de Par\u00eds, la ETH de Z\u00farich, la Universidad Nacional de Ciencias y Tecnolog\u00eda (NUST) y la Universidad de California en Irvine.", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 24], [25, 35], [36, 38], [39, 49], [50, 52], [53, 55], [56, 60], [60, 61], [62, 67], [68, 73], [74, 77], [78, 80], [81, 83], [84, 95], [96, 98], [99, 104], [104, 105], [106, 108], [109, 120], [121, 129], [130, 136], [136, 137], [138, 140], [141, 144], [145, 147], [148, 160], [160, 161], [162, 164], [165, 176], [177, 179], [180, 188], [188, 189], [190, 192], [193, 204], [205, 207], [208, 218], [219, 221], [222, 225], [226, 231], [231, 232], [233, 235], [236, 247], [248, 250], [251, 258], [258, 259], [260, 262], [263, 268], [269, 277], [278, 280], [281, 286], [286, 287], [288, 290], [291, 294], [295, 297], [298, 304], [304, 305], [306, 308], [309, 320], [321, 329], [330, 332], [333, 341], [342, 343], [344, 354], [355, 356], [356, 360], [360, 361], [362, 363], [364, 366], [367, 378], [379, 381], [382, 392], [393, 395], [396, 402], [402, 403]]}
{"doc_key": "ai-train-24", "ner": [[0, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "funci\u00f3n", "sigmoide", "de", "p\u00e9rdida", "de", "entrop\u00eda", "cruzada", "se", "utiliza", "para", "predecir", "K", "valores", "de", "probabilidad", "independientes", "en", "matem\u00e1ticas", "0,1", "/", "matem\u00e1ticas", "."], "sentence-detokenized": "La funci\u00f3n sigmoide de p\u00e9rdida de entrop\u00eda cruzada se utiliza para predecir K valores de probabilidad independientes en matem\u00e1ticas 0,1 / matem\u00e1ticas.", "token2charspan": [[0, 2], [3, 10], [11, 19], [20, 22], [23, 30], [31, 33], [34, 42], [43, 50], [51, 53], [54, 61], [62, 66], [67, 75], [76, 77], [78, 85], [86, 88], [89, 101], [102, 116], [117, 119], [120, 131], [132, 135], [136, 137], [138, 149], [149, 150]]}
{"doc_key": "ai-train-25", "ner": [[4, 6, "misc"], [8, 8, "field"], [10, 10, "field"], [13, 15, "university"], [17, 18, "country"], [23, 24, "misc"], [27, 30, "university"], [32, 32, "country"], [40, 40, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[4, 6, 8, 8, "topic", "", false, false], [4, 6, 10, 10, "topic", "", false, false], [4, 6, 13, 15, "physical", "", true, false], [13, 15, 17, 18, "physical", "", false, false], [23, 24, 27, 30, "physical", "", true, false], [27, 30, 32, 32, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Fue", "titular", "de", "la", "C\u00e1tedra", "Johann", "Bernoulli", "de", "Matem\u00e1ticas", "e", "Inform\u00e1tica", "en", "la", "Universidad", "de", "Groningen", "(", "Pa\u00edses", "Bajos", ")", "y", "de", "la", "C\u00e1tedra", "Toshiba", "en", "el", "Instituto", "Tecnol\u00f3gico", "de", "Tokio", "(", "Jap\u00f3n", ")", "antes", "de", "convertirse", "en", "profesor", "en", "Cambridge", "."], "sentence-detokenized": "Fue titular de la C\u00e1tedra Johann Bernoulli de Matem\u00e1ticas e Inform\u00e1tica en la Universidad de Groningen (Pa\u00edses Bajos) y de la C\u00e1tedra Toshiba en el Instituto Tecnol\u00f3gico de Tokio (Jap\u00f3n) antes de convertirse en profesor en Cambridge.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 17], [18, 25], [26, 32], [33, 42], [43, 45], [46, 57], [58, 59], [60, 71], [72, 74], [75, 77], [78, 89], [90, 92], [93, 102], [103, 104], [104, 110], [111, 116], [116, 117], [118, 119], [120, 122], [123, 125], [126, 133], [134, 141], [142, 144], [145, 147], [148, 157], [158, 169], [170, 172], [173, 178], [179, 180], [180, 185], [185, 186], [187, 192], [193, 195], [196, 207], [208, 210], [211, 219], [220, 222], [223, 232], [232, 233]]}
{"doc_key": "ai-train-26", "ner": [[6, 8, "algorithm"], [13, 16, "algorithm"], [18, 18, "algorithm"], [23, 24, "researcher"], [26, 27, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 8, 13, 16, "usage", "", true, false], [13, 16, 23, 24, "origin", "", false, false], [13, 16, 26, 27, "origin", "", false, false], [18, 18, 13, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Otra", "t\u00e9cnica", "especialmente", "utilizada", "para", "las", "redes", "neuronales", "recurrentes", "es", "la", "red", "de", "memoria", "a", "corto", "plazo", "(", "LSTM", ")", "de", "1997", "de", "Sepp", "Hochreiter", "y", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Otra t\u00e9cnica especialmente utilizada para las redes neuronales recurrentes es la red de memoria a corto plazo (LSTM) de 1997 de Sepp Hochreiter y J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 12], [13, 26], [27, 36], [37, 41], [42, 45], [46, 51], [52, 62], [63, 74], [75, 77], [78, 80], [81, 84], [85, 87], [88, 95], [96, 97], [98, 103], [104, 109], [110, 111], [111, 115], [115, 116], [117, 119], [120, 124], [125, 127], [128, 132], [133, 143], [144, 145], [146, 152], [153, 164], [164, 165]]}
{"doc_key": "ai-train-27", "ner": [[6, 8, "programlang"], [10, 10, "product"], [16, 16, "product"], [57, 57, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 10, 6, 8, "general-affiliation", "", false, false], [10, 10, 16, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["La", "inclusi\u00f3n", "de", "un", "int\u00e9rprete", "de", "C", "+", "+", "(", "CINT", "hasta", "la", "versi\u00f3n", "5.34", ",", "Cling", "a", "partir", "de", "la", "versi\u00f3n", "6", ")", "hace", "que", "este", "paquete", "sea", "muy", "vers\u00e1til", ",", "ya", "que", "se", "puede", "utilizar", "en", "los", "modos", "interactivo", ",", "de", "secuencias", "de", "comandos", "y", "compilado", "de", "una", "manera", "similar", "a", "los", "productos", "comerciales", "como", "MATLAB", "."], "sentence-detokenized": "La inclusi\u00f3n de un int\u00e9rprete de C + + (CINT hasta la versi\u00f3n 5.34, Cling a partir de la versi\u00f3n 6) hace que este paquete sea muy vers\u00e1til, ya que se puede utilizar en los modos interactivo, de secuencias de comandos y compilado de una manera similar a los productos comerciales como MATLAB.", "token2charspan": [[0, 2], [3, 12], [13, 15], [16, 18], [19, 29], [30, 32], [33, 34], [35, 36], [37, 38], [39, 40], [40, 44], [45, 50], [51, 53], [54, 61], [62, 66], [66, 67], [68, 73], [74, 75], [76, 82], [83, 85], [86, 88], [89, 96], [97, 98], [98, 99], [100, 104], [105, 108], [109, 113], [114, 121], [122, 125], [126, 129], [130, 138], [138, 139], [140, 142], [143, 146], [147, 149], [150, 155], [156, 164], [165, 167], [168, 171], [172, 177], [178, 189], [189, 190], [191, 193], [194, 204], [205, 207], [208, 216], [217, 218], [219, 228], [229, 231], [232, 235], [236, 242], [243, 250], [251, 252], [253, 256], [257, 266], [267, 278], [279, 283], [284, 290], [290, 291]]}
{"doc_key": "ai-train-28", "ner": [[0, 5, "product"], [29, 33, "field"], [36, 38, "task"], [41, 45, "task"], [48, 50, "task"], [53, 55, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 5, 29, 33, "related-to", "", false, false], [36, 38, 29, 33, "part-of", "", false, false], [41, 45, 29, 33, "part-of", "", false, false], [48, 50, 29, 33, "part-of", "", false, false], [53, 55, 29, 33, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Las", "interfaces", "de", "usuario", "de", "voz", "que", "interpretan", "y", "gestionan", "el", "estado", "de", "la", "conversaci\u00f3n", "son", "un", "reto", "de", "dise\u00f1o", "debido", "a", "la", "dificultad", "inherente", "de", "integrar", "tareas", "complejas", "de", "procesamiento", "del", "lenguaje", "natural", "como", "la", "resoluci\u00f3n", "de", "coreferencias", ",", "el", "reconocimiento", "de", "entidades", "con", "nombre", ",", "la", "recuperaci\u00f3n", "de", "informaci\u00f3n", "y", "la", "gesti\u00f3n", "del", "di\u00e1logo", "."], "sentence-detokenized": "Las interfaces de usuario de voz que interpretan y gestionan el estado de la conversaci\u00f3n son un reto de dise\u00f1o debido a la dificultad inherente de integrar tareas complejas de procesamiento del lenguaje natural como la resoluci\u00f3n de coreferencias, el reconocimiento de entidades con nombre, la recuperaci\u00f3n de informaci\u00f3n y la gesti\u00f3n del di\u00e1logo.", "token2charspan": [[0, 3], [4, 14], [15, 17], [18, 25], [26, 28], [29, 32], [33, 36], [37, 48], [49, 50], [51, 60], [61, 63], [64, 70], [71, 73], [74, 76], [77, 89], [90, 93], [94, 96], [97, 101], [102, 104], [105, 111], [112, 118], [119, 120], [121, 123], [124, 134], [135, 144], [145, 147], [148, 156], [157, 163], [164, 173], [174, 176], [177, 190], [191, 194], [195, 203], [204, 211], [212, 216], [217, 219], [220, 230], [231, 233], [234, 247], [247, 248], [249, 251], [252, 266], [267, 269], [270, 279], [280, 283], [284, 290], [290, 291], [292, 294], [295, 307], [308, 310], [311, 322], [323, 324], [325, 327], [328, 335], [336, 339], [340, 347], [347, 348]]}
{"doc_key": "ai-train-29", "ner": [[6, 8, "algorithm"], [11, 15, "algorithm"], [23, 24, "researcher"], [27, 31, "organisation"], [38, 40, "field"], [42, 43, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 8, 23, 24, "origin", "", false, false], [6, 8, 38, 40, "part-of", "", false, false], [6, 8, 42, 43, "part-of", "", false, false], [11, 15, 23, 24, "origin", "", false, false], [11, 15, 38, 40, "part-of", "", false, false], [11, 15, 42, 43, "part-of", "", false, false], [23, 24, 27, 31, "physical", "", false, false], [23, 24, 27, 31, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Entre", "2009", "y", "2012", ",", "las", "redes", "neuronales", "recurrentes", "y", "las", "redes", "neuronales", "profundas", "de", "avance", "desarrolladas", "en", "el", "grupo", "de", "investigaci\u00f3n", "de", "J\u00fcrgen", "Schmidhuber", "en", "el", "laboratorio", "suizo", "de", "IA", "IDSIA", "han", "ganado", "ocho", "concursos", "internacionales", "de", "reconocimiento", "de", "patrones", "y", "aprendizaje", "autom\u00e1tico", "."], "sentence-detokenized": "Entre 2009 y 2012, las redes neuronales recurrentes y las redes neuronales profundas de avance desarrolladas en el grupo de investigaci\u00f3n de J\u00fcrgen Schmidhuber en el laboratorio suizo de IA IDSIA han ganado ocho concursos internacionales de reconocimiento de patrones y aprendizaje autom\u00e1tico.", "token2charspan": [[0, 5], [6, 10], [11, 12], [13, 17], [17, 18], [19, 22], [23, 28], [29, 39], [40, 51], [52, 53], [54, 57], [58, 63], [64, 74], [75, 84], [85, 87], [88, 94], [95, 108], [109, 111], [112, 114], [115, 120], [121, 123], [124, 137], [138, 140], [141, 147], [148, 159], [160, 162], [163, 165], [166, 177], [178, 183], [184, 186], [187, 189], [190, 195], [196, 199], [200, 206], [207, 211], [212, 221], [222, 237], [238, 240], [241, 255], [256, 258], [259, 267], [268, 269], [270, 281], [282, 292], [292, 293]]}
{"doc_key": "ai-train-30", "ner": [[0, 6, "product"], [10, 11, "product"], [13, 14, "product"], [18, 20, "task"], [23, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 6, 10, 11, "usage", "", false, false], [0, 6, 13, 14, "usage", "", false, false], [0, 6, 18, 20, "usage", "", true, false], [0, 6, 23, 23, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Los", "sistemas", "de", "escritorio", "modernos", "de", "Windows", "pueden", "utilizar", "componentes", "SAPI", "4", "y", "SAPI", "5", "para", "soportar", "la", "s\u00edntesis", "de", "voz", "y", "el", "habla", "."], "sentence-detokenized": "Los sistemas de escritorio modernos de Windows pueden utilizar componentes SAPI 4 y SAPI 5 para soportar la s\u00edntesis de voz y el habla.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 26], [27, 35], [36, 38], [39, 46], [47, 53], [54, 62], [63, 74], [75, 79], [80, 81], [82, 83], [84, 88], [89, 90], [91, 95], [96, 104], [105, 107], [108, 116], [117, 119], [120, 123], [124, 125], [126, 128], [129, 134], [134, 135]]}
{"doc_key": "ai-train-31", "ner": [[6, 11, "misc"], [13, 13, "field"], [16, 18, "university"], [25, 28, "field"], [30, 34, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 11, 13, 13, "topic", "topic_of_award", false, false], [6, 11, 16, 18, "origin", "", true, false], [25, 28, 30, 34, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Recibi\u00f3", "dos", "t\u00edtulos", "honor\u00edficos", ",", "uno", "S.", "V.", "della", "laurea", "ad", "honorem", "en", "Psicolog\u00eda", "por", "la", "Universidad", "de", "Padua", "en", "1995", "y", "un", "doctorado", "en", "Dise\u00f1o", "e", "Ingenier\u00eda", "Industrial", "por", "la", "Universidad", "Tecnol\u00f3gica", "de", "Delft", "."], "sentence-detokenized": "Recibi\u00f3 dos t\u00edtulos honor\u00edficos, uno S. V. della laurea ad honorem en Psicolog\u00eda por la Universidad de Padua en 1995 y un doctorado en Dise\u00f1o e Ingenier\u00eda Industrial por la Universidad Tecnol\u00f3gica de Delft.", "token2charspan": [[0, 7], [8, 11], [12, 19], [20, 31], [31, 32], [33, 36], [37, 39], [40, 42], [43, 48], [49, 55], [56, 58], [59, 66], [67, 69], [70, 80], [81, 84], [85, 87], [88, 99], [100, 102], [103, 108], [109, 111], [112, 116], [117, 118], [119, 121], [122, 131], [132, 134], [135, 141], [142, 143], [144, 154], [155, 165], [166, 169], [170, 172], [173, 184], [185, 196], [197, 199], [200, 205], [205, 206]]}
{"doc_key": "ai-train-32", "ner": [[4, 5, "researcher"], [9, 10, "organisation"], [12, 12, "location"], [14, 14, "researcher"], [25, 26, "misc"], [42, 44, "misc"], [64, 65, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 5, 9, 10, "physical", "", false, false], [4, 5, 9, 10, "role", "", false, false], [9, 10, 12, 12, "physical", "", false, false], [14, 14, 25, 26, "related-to", "works_with", true, false], [14, 14, 42, 44, "related-to", "works_with", true, false], [14, 14, 64, 65, "related-to", "works_with", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Con", "su", "antiguo", "colaborador", "Laurent", "Cohen", ",", "neur\u00f3logo", "del", "Hospital", "Piti\u00e9-Salp\u00eatri\u00e8re", "de", "Par\u00eds", ",", "Dehaene", "tambi\u00e9n", "identific\u00f3", "a", "pacientes", "con", "lesiones", "en", "diferentes", "regiones", "del", "l\u00f3bulo", "parietal", "con", "alteraci\u00f3n", "de", "la", "multiplicaci\u00f3n", ",", "pero", "con", "sustracci\u00f3n", "preservada", "(", "asociada", "a", "lesiones", "del", "l\u00f3bulo", "parietal", "inferior", ")", "y", "a", "otros", "con", "alteraci\u00f3n", "de", "la", "sustracci\u00f3n", ",", "pero", "con", "multiplicaci\u00f3n", "preservada", "(", "asociada", "a", "lesiones", "del", "surco", "intraparietal", ")", "."], "sentence-detokenized": "Con su antiguo colaborador Laurent Cohen, neur\u00f3logo del Hospital Piti\u00e9-Salp\u00eatri\u00e8re de Par\u00eds, Dehaene tambi\u00e9n identific\u00f3 a pacientes con lesiones en diferentes regiones del l\u00f3bulo parietal con alteraci\u00f3n de la multiplicaci\u00f3n, pero con sustracci\u00f3n preservada (asociada a lesiones del l\u00f3bulo parietal inferior) y a otros con alteraci\u00f3n de la sustracci\u00f3n, pero con multiplicaci\u00f3n preservada (asociada a lesiones del surco intraparietal).", "token2charspan": [[0, 3], [4, 6], [7, 14], [15, 26], [27, 34], [35, 40], [40, 41], [42, 51], [52, 55], [56, 64], [65, 82], [83, 85], [86, 91], [91, 92], [93, 100], [101, 108], [109, 119], [120, 121], [122, 131], [132, 135], [136, 144], [145, 147], [148, 158], [159, 167], [168, 171], [172, 178], [179, 187], [188, 191], [192, 202], [203, 205], [206, 208], [209, 223], [223, 224], [225, 229], [230, 233], [234, 245], [246, 256], [257, 258], [258, 266], [267, 268], [269, 277], [278, 281], [282, 288], [289, 297], [298, 306], [306, 307], [308, 309], [310, 311], [312, 317], [318, 321], [322, 332], [333, 335], [336, 338], [339, 350], [350, 351], [352, 356], [357, 360], [361, 375], [376, 386], [387, 388], [388, 396], [397, 398], [399, 407], [408, 411], [412, 417], [418, 431], [431, 432], [432, 433]]}
{"doc_key": "ai-train-33", "ner": [[7, 9, "product"], [13, 14, "misc"], [16, 17, "misc"], [25, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 14, 7, 9, "topic", "", false, false], [16, 17, 7, 9, "topic", "", false, false], [25, 25, 7, 9, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["M\u00e1s", "recientemente", ",", "las", "representaciones", "ficticias", "de", "robots", "artificialmente", "inteligentes", "en", "pel\u00edculas", "como", "Inteligencia", "Artificial", "y", "Ex", "Machina", "y", "la", "adaptaci\u00f3n", "televisiva", "de", "2016", "de", "Westworld", "han", "despertado", "la", "simpat\u00eda", "del", "p\u00fablico", "por", "los", "propios", "robots", "."], "sentence-detokenized": "M\u00e1s recientemente, las representaciones ficticias de robots artificialmente inteligentes en pel\u00edculas como Inteligencia Artificial y Ex Machina y la adaptaci\u00f3n televisiva de 2016 de Westworld han despertado la simpat\u00eda del p\u00fablico por los propios robots.", "token2charspan": [[0, 3], [4, 17], [17, 18], [19, 22], [23, 39], [40, 49], [50, 52], [53, 59], [60, 75], [76, 88], [89, 91], [92, 101], [102, 106], [107, 119], [120, 130], [131, 132], [133, 135], [136, 143], [144, 145], [146, 148], [149, 159], [160, 170], [171, 173], [174, 178], [179, 181], [182, 191], [192, 195], [196, 206], [207, 209], [210, 218], [219, 222], [223, 230], [231, 234], [235, 238], [239, 246], [247, 253], [253, 254]]}
{"doc_key": "ai-train-34", "ner": [[8, 10, "field"], [13, 16, "algorithm"], [19, 21, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 16, 8, 10, "part-of", "", false, false], [19, 21, 8, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Dos", "de", "los", "principales", "m\u00e9todos", "utilizados", "en", "el", "aprendizaje", "no", "supervisado", "son", "el", "an\u00e1lisis", "de", "componentes", "principales", "y", "el", "an\u00e1lisis", "de", "conglomerados", "."], "sentence-detokenized": "Dos de los principales m\u00e9todos utilizados en el aprendizaje no supervisado son el an\u00e1lisis de componentes principales y el an\u00e1lisis de conglomerados.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 22], [23, 30], [31, 41], [42, 44], [45, 47], [48, 59], [60, 62], [63, 74], [75, 78], [79, 81], [82, 90], [91, 93], [94, 105], [106, 117], [118, 119], [120, 122], [123, 131], [132, 134], [135, 148], [148, 149]]}
{"doc_key": "ai-train-35", "ner": [[0, 2, "organisation"], [27, 28, "misc"], [33, 34, "misc"], [36, 38, "person"], [44, 45, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[27, 28, 0, 2, "artifact", "", false, false], [33, 34, 0, 2, "artifact", "", false, false], [33, 34, 36, 38, "role", "director_of", false, false], [33, 34, 44, 45, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Walt", "Disney", "Company", "tambi\u00e9n", "comenz\u00f3", "a", "utilizar", "de", "forma", "m\u00e1s", "destacada", "las", "pel\u00edculas", "en", "3D", "en", "lugares", "especiales", "para", "impresionar", "al", "p\u00fablico", ",", "siendo", "ejemplos", "notables", "los", "Viajes", "M\u00e1gicos", "(", "1982", ")", "y", "Capit\u00e1n", "EO", "(", "Francis", "Ford", "Coppola", ",", "1986", ",", "protagonizada", "por", "Michael", "Jackson", ")", "."], "sentence-detokenized": "Walt Disney Company tambi\u00e9n comenz\u00f3 a utilizar de forma m\u00e1s destacada las pel\u00edculas en 3D en lugares especiales para impresionar al p\u00fablico, siendo ejemplos notables los Viajes M\u00e1gicos (1982) y Capit\u00e1n EO (Francis Ford Coppola, 1986, protagonizada por Michael Jackson).", "token2charspan": [[0, 4], [5, 11], [12, 19], [20, 27], [28, 35], [36, 37], [38, 46], [47, 49], [50, 55], [56, 59], [60, 69], [70, 73], [74, 83], [84, 86], [87, 89], [90, 92], [93, 100], [101, 111], [112, 116], [117, 128], [129, 131], [132, 139], [139, 140], [141, 147], [148, 156], [157, 165], [166, 169], [170, 176], [177, 184], [185, 186], [186, 190], [190, 191], [192, 193], [194, 201], [202, 204], [205, 206], [206, 213], [214, 218], [219, 226], [226, 227], [228, 232], [232, 233], [234, 247], [248, 251], [252, 259], [260, 267], [267, 268], [268, 269]]}
{"doc_key": "ai-train-36", "ner": [[15, 18, "field"], [22, 27, "task"], [30, 31, "task"], [33, 33, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 27, 15, 18, "part-of", "", false, false], [30, 31, 15, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Desde", "2002", ",", "el", "entrenamiento", "con", "perceptrones", "se", "ha", "hecho", "popular", "en", "el", "campo", "del", "procesamiento", "del", "lenguaje", "natural", "para", "tareas", "como", "el", "etiquetado", "de", "partes", "del", "habla", "y", "el", "an\u00e1lisis", "sint\u00e1ctico", "(", "Collins", ",", "2002", ")", "."], "sentence-detokenized": "Desde 2002, el entrenamiento con perceptrones se ha hecho popular en el campo del procesamiento del lenguaje natural para tareas como el etiquetado de partes del habla y el an\u00e1lisis sint\u00e1ctico (Collins, 2002).", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 14], [15, 28], [29, 32], [33, 45], [46, 48], [49, 51], [52, 57], [58, 65], [66, 68], [69, 71], [72, 77], [78, 81], [82, 95], [96, 99], [100, 108], [109, 116], [117, 121], [122, 128], [129, 133], [134, 136], [137, 147], [148, 150], [151, 157], [158, 161], [162, 167], [168, 169], [170, 172], [173, 181], [182, 192], [193, 194], [194, 201], [201, 202], [203, 207], [207, 208], [208, 209]]}
{"doc_key": "ai-train-37", "ner": [[2, 3, "product"], [10, 14, "organisation"], [16, 17, "organisation"], [19, 19, "country"], [23, 28, "product"], [32, 33, "researcher"], [43, 43, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 14, 2, 3, "role", "introduces_to_market", true, false], [16, 17, 2, 3, "role", "introduces_to_market", true, false], [16, 17, 19, 19, "physical", "", false, false], [23, 28, 43, 43, "related-to", "sold_to", true, false], [32, 33, 23, 28, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["El", "primer", "robot", "paletizador", "fue", "introducido", "en", "1963", "por", "la", "empresa", "Fuji", "Yusoki", "Kogyo", ".", "por", "KUKA", "robotics", "en", "Alemania", ",", "y", "la", "m\u00e1quina", "universal", "programable", "para", "el", "montaje", "fue", "inventada", "por", "Victor", "Scheinman", "en", "1976", ",", "y", "el", "dise\u00f1o", "fue", "vendido", "a", "Unimation", "."], "sentence-detokenized": "El primer robot paletizador fue introducido en 1963 por la empresa Fuji Yusoki Kogyo. por KUKA robotics en Alemania, y la m\u00e1quina universal programable para el montaje fue inventada por Victor Scheinman en 1976, y el dise\u00f1o fue vendido a Unimation.", "token2charspan": [[0, 2], [3, 9], [10, 15], [16, 27], [28, 31], [32, 43], [44, 46], [47, 51], [52, 55], [56, 58], [59, 66], [67, 71], [72, 78], [79, 84], [84, 85], [86, 89], [90, 94], [95, 103], [104, 106], [107, 115], [115, 116], [117, 118], [119, 121], [122, 129], [130, 139], [140, 151], [152, 156], [157, 159], [160, 167], [168, 171], [172, 181], [182, 185], [186, 192], [193, 202], [203, 205], [206, 210], [210, 211], [212, 213], [214, 216], [217, 223], [224, 227], [228, 235], [236, 237], [238, 247], [247, 248]]}
{"doc_key": "ai-train-38", "ner": [[12, 13, "conference"], [15, 15, "researcher"], [25, 26, "field"], [41, 42, "researcher"], [51, 54, "researcher"], [66, 66, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[15, 15, 12, 13, "role", "president_of", false, false], [15, 15, 41, 42, "role", "colleagues", false, false], [25, 26, 66, 66, "named", "same", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "mediados", "de", "la", "d\u00e9cada", "de", "1990", ",", "mientras", "era", "presidente", "de", "la", "AAAI", ",", "Hayes", "inici\u00f3", "una", "serie", "de", "ataques", "a", "los", "cr\u00edticos", "de", "la", "IA", ",", "casi", "siempre", "redactados", "en", "tono", "ir\u00f3nico", ",", "y", "(", "junto", "con", "su", "colega", "Kenneth", "Ford", ")", "invent\u00f3", "un", "premio", "con", "el", "nombre", "de", "Simon", "Newcomb", "que", "se", "otorgar\u00eda", "al", "argumento", "m\u00e1s", "rid\u00edculo", "que", "refutara", "la", "posibilidad", "de", "la", "IA", "."], "sentence-detokenized": "A mediados de la d\u00e9cada de 1990, mientras era presidente de la AAAI, Hayes inici\u00f3 una serie de ataques a los cr\u00edticos de la IA, casi siempre redactados en tono ir\u00f3nico, y (junto con su colega Kenneth Ford) invent\u00f3 un premio con el nombre de Simon Newcomb que se otorgar\u00eda al argumento m\u00e1s rid\u00edculo que refutara la posibilidad de la IA.", "token2charspan": [[0, 1], [2, 10], [11, 13], [14, 16], [17, 23], [24, 26], [27, 31], [31, 32], [33, 41], [42, 45], [46, 56], [57, 59], [60, 62], [63, 67], [67, 68], [69, 74], [75, 81], [82, 85], [86, 91], [92, 94], [95, 102], [103, 104], [105, 108], [109, 117], [118, 120], [121, 123], [124, 126], [126, 127], [128, 132], [133, 140], [141, 151], [152, 154], [155, 159], [160, 167], [167, 168], [169, 170], [171, 172], [172, 177], [178, 181], [182, 184], [185, 191], [192, 199], [200, 204], [204, 205], [206, 213], [214, 216], [217, 223], [224, 227], [228, 230], [231, 237], [238, 240], [241, 246], [247, 254], [255, 258], [259, 261], [262, 271], [272, 274], [275, 284], [285, 288], [289, 297], [298, 301], [302, 310], [311, 313], [314, 325], [326, 328], [329, 331], [332, 334], [334, 335]]}
{"doc_key": "ai-train-39", "ner": [[17, 23, "algorithm"], [50, 52, "algorithm"], [64, 68, "algorithm"], [71, 74, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[17, 23, 50, 52, "named", "same", false, false], [64, 68, 17, 23, "type-of", "", false, false], [71, 74, 17, 23, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Un", "valor", "\u00f3ptimo", "para", "math", "\\", "alpha", "/", "math", "se", "puede", "encontrar", "mediante", "el", "uso", "de", "un", "algoritmo", "de", "b\u00fasqueda", "de", "l\u00ednea", ",", "es", "decir", ",", "la", "magnitud", "de", "math", "\\", "alpha", "/", "math", "se", "determina", "mediante", "la", "b\u00fasqueda", "del", "valor", "que", "minimiza", "S", ",", "por", "lo", "general", "utilizando", "una", "b\u00fasqueda", "de", "l\u00ednea", "en", "el", "intervalo", "math0", "\\", "alpha", "1", "/", "math", "o", "una", "b\u00fasqueda", "de", "l\u00ednea", "de", "retroceso", "como", "la", "b\u00fasqueda", "de", "l\u00ednea", "Armijo", "."], "sentence-detokenized": "Un valor \u00f3ptimo para math\\ alpha / math se puede encontrar mediante el uso de un algoritmo de b\u00fasqueda de l\u00ednea, es decir, la magnitud de math\\ alpha / math se determina mediante la b\u00fasqueda del valor que minimiza S, por lo general utilizando una b\u00fasqueda de l\u00ednea en el intervalo math0\\ alpha 1 / math o una b\u00fasqueda de l\u00ednea de retroceso como la b\u00fasqueda de l\u00ednea Armijo.", "token2charspan": [[0, 2], [3, 8], [9, 15], [16, 20], [21, 25], [25, 26], [27, 32], [33, 34], [35, 39], [40, 42], [43, 48], [49, 58], [59, 67], [68, 70], [71, 74], [75, 77], [78, 80], [81, 90], [91, 93], [94, 102], [103, 105], [106, 111], [111, 112], [113, 115], [116, 121], [121, 122], [123, 125], [126, 134], [135, 137], [138, 142], [142, 143], [144, 149], [150, 151], [152, 156], [157, 159], [160, 169], [170, 178], [179, 181], [182, 190], [191, 194], [195, 200], [201, 204], [205, 213], [214, 215], [215, 216], [217, 220], [221, 223], [224, 231], [232, 242], [243, 246], [247, 255], [256, 258], [259, 264], [265, 267], [268, 270], [271, 280], [281, 286], [286, 287], [288, 293], [294, 295], [296, 297], [298, 302], [303, 304], [305, 308], [309, 317], [318, 320], [321, 326], [327, 329], [330, 339], [340, 344], [345, 347], [348, 356], [357, 359], [360, 365], [366, 372], [372, 373]]}
{"doc_key": "ai-train-40", "ner": [[4, 5, "algorithm"], [7, 7, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Discute", "las", "t\u00e9cnicas", "de", "b\u00fasqueda", "Breadth-first", "y", "Depth-first", ",", "pero", "finalmente", "concluye", "que", "los", "resultados", "representan", "sistemas", "expertos", "que", "encarnan", "mucho", "conocimiento", "t\u00e9cnico", ",", "pero", "no", "arrojan", "mucha", "luz", "sobre", "los", "procesos", "mentales", "que", "los", "humanos", "utilizan", "para", "resolver", "esos", "rompecabezas", "."], "sentence-detokenized": "Discute las t\u00e9cnicas de b\u00fasqueda Breadth-first y Depth-first, pero finalmente concluye que los resultados representan sistemas expertos que encarnan mucho conocimiento t\u00e9cnico, pero no arrojan mucha luz sobre los procesos mentales que los humanos utilizan para resolver esos rompecabezas.", "token2charspan": [[0, 7], [8, 11], [12, 20], [21, 23], [24, 32], [33, 46], [47, 48], [49, 60], [60, 61], [62, 66], [67, 77], [78, 86], [87, 90], [91, 94], [95, 105], [106, 117], [118, 126], [127, 135], [136, 139], [140, 148], [149, 154], [155, 167], [168, 175], [175, 176], [177, 181], [182, 184], [185, 192], [193, 198], [199, 202], [203, 208], [209, 212], [213, 221], [222, 230], [231, 234], [235, 238], [239, 246], [247, 255], [256, 260], [261, 269], [270, 274], [275, 287], [287, 288]]}
{"doc_key": "ai-train-41", "ner": [[0, 1, "task"], [4, 6, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["El", "reconocimiento", "y", "la", "s\u00edntesis", "del", "habla", "se", "ocupan", "de", "c\u00f3mo", "se", "puede", "entender", "o", "crear", "el", "lenguaje", "hablado", "mediante", "ordenadores", "."], "sentence-detokenized": "El reconocimiento y la s\u00edntesis del habla se ocupan de c\u00f3mo se puede entender o crear el lenguaje hablado mediante ordenadores.", "token2charspan": [[0, 2], [3, 17], [18, 19], [20, 22], [23, 31], [32, 35], [36, 41], [42, 44], [45, 51], [52, 54], [55, 59], [60, 62], [63, 68], [69, 77], [78, 79], [80, 85], [86, 88], [89, 97], [98, 105], [106, 114], [115, 126], [126, 127]]}
{"doc_key": "ai-train-42", "ner": [[17, 18, "algorithm"], [38, 40, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Esta", "math", "\\", "theta", "^", "{", "*", "}", "/", "math", "se", "estima", "normalmente", "usando", "un", "procedimiento", "de", "M\u00e1xima", "Verosimilitud", "(", "math", "\\", "theta", "^", "{", "*", "}", "=", "\\", "theta", "^", "{", "ML", "}", "/", "math", ")", "o", "M\u00e1ximo", "A", "Posteriori", "(", "math", "\\", "theta", "^", "{", "*", "}", "=", "\\", "theta", "^", "{", "MAP", "}", "/", "math", ")", "."], "sentence-detokenized": "Esta math\\ theta ^ {*} / math se estima normalmente usando un procedimiento de M\u00e1xima Verosimilitud (math\\ theta ^ {*} =\\ theta ^ {ML} / math) o M\u00e1ximo A Posteriori (math\\ theta ^ {*} =\\ theta ^ {MAP} / math).", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 16], [17, 18], [19, 20], [20, 21], [21, 22], [23, 24], [25, 29], [30, 32], [33, 39], [40, 51], [52, 58], [59, 61], [62, 75], [76, 78], [79, 85], [86, 99], [100, 101], [101, 105], [105, 106], [107, 112], [113, 114], [115, 116], [116, 117], [117, 118], [119, 120], [120, 121], [122, 127], [128, 129], [130, 131], [131, 133], [133, 134], [135, 136], [137, 141], [141, 142], [143, 144], [145, 151], [152, 153], [154, 164], [165, 166], [166, 170], [170, 171], [172, 177], [178, 179], [180, 181], [181, 182], [182, 183], [184, 185], [185, 186], [187, 192], [193, 194], [195, 196], [196, 199], [199, 200], [201, 202], [203, 207], [207, 208], [208, 209]]}
{"doc_key": "ai-train-43", "ner": [[6, 10, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Algunos", "idiomas", "menos", "hablados", "utilizan", "el", "sintetizador", "de", "c\u00f3digo", "abierto", "eSpeak", "para", "su", "habla", ",", "produciendo", "una", "voz", "rob\u00f3tica", "y", "torpe", "que", "puede", "ser", "dif\u00edcil", "de", "entender", "."], "sentence-detokenized": "Algunos idiomas menos hablados utilizan el sintetizador de c\u00f3digo abierto eSpeak para su habla, produciendo una voz rob\u00f3tica y torpe que puede ser dif\u00edcil de entender.", "token2charspan": [[0, 7], [8, 15], [16, 21], [22, 30], [31, 39], [40, 42], [43, 55], [56, 58], [59, 65], [66, 73], [74, 80], [81, 85], [86, 88], [89, 94], [94, 95], [96, 107], [108, 111], [112, 115], [116, 124], [125, 126], [127, 132], [133, 136], [137, 142], [143, 146], [147, 154], [155, 157], [158, 166], [166, 167]]}
{"doc_key": "ai-train-44", "ner": [[23, 23, "programlang"], [43, 44, "programlang"], [46, 46, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 23, 43, 44, "compare", "", false, false], [23, 23, 46, 46, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Aunque", "lo", "utilizan", "principalmente", "los", "estad\u00edsticos", "y", "otros", "profesionales", "que", "necesitan", "un", "entorno", "para", "el", "c\u00e1lculo", "estad\u00edstico", "y", "el", "desarrollo", "de", "software", ",", "R", "tambi\u00e9n", "puede", "funcionar", "como", "una", "caja", "de", "herramientas", "de", "c\u00e1lculo", "matricial", "general", ",", "con", "un", "rendimiento", "comparable", "al", "de", "GNU", "Octave", "o", "MATLAB", "."], "sentence-detokenized": "Aunque lo utilizan principalmente los estad\u00edsticos y otros profesionales que necesitan un entorno para el c\u00e1lculo estad\u00edstico y el desarrollo de software, R tambi\u00e9n puede funcionar como una caja de herramientas de c\u00e1lculo matricial general, con un rendimiento comparable al de GNU Octave o MATLAB.", "token2charspan": [[0, 6], [7, 9], [10, 18], [19, 33], [34, 37], [38, 50], [51, 52], [53, 58], [59, 72], [73, 76], [77, 86], [87, 89], [90, 97], [98, 102], [103, 105], [106, 113], [114, 125], [126, 127], [128, 130], [131, 141], [142, 144], [145, 153], [153, 154], [155, 156], [157, 164], [165, 170], [171, 180], [181, 185], [186, 189], [190, 194], [195, 197], [198, 210], [211, 213], [214, 221], [222, 231], [232, 239], [239, 240], [241, 244], [245, 247], [248, 259], [260, 270], [271, 273], [274, 276], [277, 280], [281, 287], [288, 289], [290, 296], [296, 297]]}
{"doc_key": "ai-train-45", "ner": [[0, 1, "algorithm"], [6, 8, "field"], [11, 13, "misc"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 6, 8, "part-of", "", false, false], [0, 1, 14, 15, "origin", "", false, false], [11, 13, 14, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "heterodinaci\u00f3n", "es", "una", "t\u00e9cnica", "de", "procesamiento", "de", "se\u00f1ales", "inventada", "por", "el", "inventor-ingeniero", "canadiense", "Reginald", "Fessenden", "que", "crea", "nuevas", "frecuencias", "al", "combinar", "la", "mezcla", "de", "dos", "frecuencias", "."], "sentence-detokenized": "La heterodinaci\u00f3n es una t\u00e9cnica de procesamiento de se\u00f1ales inventada por el inventor-ingeniero canadiense Reginald Fessenden que crea nuevas frecuencias al combinar la mezcla de dos frecuencias.", "token2charspan": [[0, 2], [3, 17], [18, 20], [21, 24], [25, 32], [33, 35], [36, 49], [50, 52], [53, 60], [61, 70], [71, 74], [75, 77], [78, 96], [97, 107], [108, 116], [117, 126], [127, 130], [131, 135], [136, 142], [143, 154], [155, 157], [158, 166], [167, 169], [170, 176], [177, 179], [180, 183], [184, 195], [195, 196]]}
{"doc_key": "ai-train-46", "ner": [[17, 18, "person"], [14, 16, "misc"], [22, 24, "organisation"], [32, 32, "organisation"], [27, 29, "misc"], [35, 36, "person"], [44, 44, "organisation"], [39, 41, "misc"], [47, 48, "person"], [50, 51, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[17, 18, 14, 16, "role", "actor_in", false, false], [14, 16, 22, 24, "artifact", "", false, false], [27, 29, 32, 32, "artifact", "", false, false], [35, 36, 27, 29, "role", "actor_in", false, false], [39, 41, 44, 44, "artifact", "", false, false], [47, 48, 39, 41, "role", "actor_in", false, false], [50, 51, 39, 41, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Otros", "largometrajes", "que", "ayudaron", "a", "poner", "el", "3D", "en", "el", "mapa", "ese", "mes", "fueron", "Hondo", ",", "de", "John", "Wayne", "(", "distribuido", "por", "Warner", "Bros", ".", ")", ",", "Miss", "Sadie", "Thompson", ",", "de", "Columbia", ",", "con", "Rita", "Hayworth", ",", "y", "Money", "From", "Home", ",", "de", "Paramount", ",", "con", "Dean", "Martin", "y", "Jerry", "Lewis", "."], "sentence-detokenized": "Otros largometrajes que ayudaron a poner el 3D en el mapa ese mes fueron Hondo, de John Wayne (distribuido por Warner Bros. ), Miss Sadie Thompson, de Columbia, con Rita Hayworth, y Money From Home, de Paramount, con Dean Martin y Jerry Lewis.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 32], [33, 34], [35, 40], [41, 43], [44, 46], [47, 49], [50, 52], [53, 57], [58, 61], [62, 65], [66, 72], [73, 78], [78, 79], [80, 82], [83, 87], [88, 93], [94, 95], [95, 106], [107, 110], [111, 117], [118, 122], [122, 123], [124, 125], [125, 126], [127, 131], [132, 137], [138, 146], [146, 147], [148, 150], [151, 159], [159, 160], [161, 164], [165, 169], [170, 178], [178, 179], [180, 181], [182, 187], [188, 192], [193, 197], [197, 198], [199, 201], [202, 211], [211, 212], [213, 216], [217, 221], [222, 228], [229, 230], [231, 236], [237, 242], [242, 243]]}
{"doc_key": "ai-train-47", "ner": [[0, 0, "product"], [7, 9, "field"], [5, 6, "task"], [17, 17, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 6, "general-affiliation", "", false, false], [0, 0, 17, 17, "artifact", "", false, false], [5, 6, 7, 9, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["DeepFace", "es", "un", "sistema", "de", "reconocimiento", "facial", "de", "aprendizaje", "profundo", "creado", "por", "un", "grupo", "de", "investigaci\u00f3n", "de", "Facebook", "."], "sentence-detokenized": "DeepFace es un sistema de reconocimiento facial de aprendizaje profundo creado por un grupo de investigaci\u00f3n de Facebook.", "token2charspan": [[0, 8], [9, 11], [12, 14], [15, 22], [23, 25], [26, 40], [41, 47], [48, 50], [51, 62], [63, 71], [72, 78], [79, 82], [83, 85], [86, 91], [92, 94], [95, 108], [109, 111], [112, 120], [120, 121]]}
{"doc_key": "ai-train-48", "ner": [[0, 3, "field"], [12, 12, "conference"], [19, 21, "field"], [4, 34, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 19, 21, "part-of", "subfield", false, false], [12, 12, 0, 3, "topic", "", false, false], [4, 34, 0, 3, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["El", "procesamiento", "de", "la", "geometr\u00eda", "es", "un", "tema", "de", "investigaci\u00f3n", "habitual", "en", "SIGGRAPH", ",", "la", "principal", "conferencia", "acad\u00e9mica", "sobre", "gr\u00e1ficos", "por", "ordenador", ",", "y", "el", "tema", "principal", "del", "Simposio", "anual", "sobre", "Procesamiento", "de", "la", "Geometr\u00eda", "."], "sentence-detokenized": "El procesamiento de la geometr\u00eda es un tema de investigaci\u00f3n habitual en SIGGRAPH, la principal conferencia acad\u00e9mica sobre gr\u00e1ficos por ordenador, y el tema principal del Simposio anual sobre Procesamiento de la Geometr\u00eda.", "token2charspan": [[0, 2], [3, 16], [17, 19], [20, 22], [23, 32], [33, 35], [36, 38], [39, 43], [44, 46], [47, 60], [61, 69], [70, 72], [73, 81], [81, 82], [83, 85], [86, 95], [96, 107], [108, 117], [118, 123], [124, 132], [133, 136], [137, 146], [146, 147], [148, 149], [150, 152], [153, 157], [158, 167], [168, 171], [172, 180], [181, 186], [187, 192], [193, 206], [207, 209], [210, 212], [213, 222], [222, 223]]}
{"doc_key": "ai-train-49", "ner": [[0, 3, "task"], [6, 8, "task"], [18, 21, "algorithm"], [23, 23, "algorithm"], [26, 28, "algorithm"], [30, 30, "algorithm"], [33, 36, "algorithm"], [38, 40, "algorithm"], [42, 44, "misc"], [51, 52, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[18, 21, 42, 44, "general-affiliation", "", false, false], [23, 23, 18, 21, "named", "", false, false], [26, 28, 42, 44, "general-affiliation", "", false, false], [30, 30, 26, 28, "named", "", false, false], [33, 36, 42, 44, "general-affiliation", "", false, false], [38, 40, 33, 36, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["La", "extracci\u00f3n", "de", "caracter\u00edsticas", "y", "la", "reducci\u00f3n", "de", "dimensiones", "pueden", "combinarse", "en", "un", "solo", "paso", "utilizando", "t\u00e9cnicas", "de", "an\u00e1lisis", "de", "componentes", "principales", "(", "PCA", ")", ",", "an\u00e1lisis", "discriminante", "lineal", "(", "LDA", ")", "o", "an\u00e1lisis", "de", "correlaci\u00f3n", "can\u00f3nica", "(", "CCA", ")", "como", "paso", "previo", "al", "procesamiento", ",", "seguido", "de", "la", "agrupaci\u00f3n", "por", "k", "-NN", "en", "vectores", "de", "caracter\u00edsticas", "en", "el", "espacio", "de", "dimensi\u00f3n", "reducida", "."], "sentence-detokenized": "La extracci\u00f3n de caracter\u00edsticas y la reducci\u00f3n de dimensiones pueden combinarse en un solo paso utilizando t\u00e9cnicas de an\u00e1lisis de componentes principales (PCA), an\u00e1lisis discriminante lineal (LDA) o an\u00e1lisis de correlaci\u00f3n can\u00f3nica (CCA) como paso previo al procesamiento, seguido de la agrupaci\u00f3n por k -NN en vectores de caracter\u00edsticas en el espacio de dimensi\u00f3n reducida.", "token2charspan": [[0, 2], [3, 13], [14, 16], [17, 32], [33, 34], [35, 37], [38, 47], [48, 50], [51, 62], [63, 69], [70, 80], [81, 83], [84, 86], [87, 91], [92, 96], [97, 107], [108, 116], [117, 119], [120, 128], [129, 131], [132, 143], [144, 155], [156, 157], [157, 160], [160, 161], [161, 162], [163, 171], [172, 185], [186, 192], [193, 194], [194, 197], [197, 198], [199, 200], [201, 209], [210, 212], [213, 224], [225, 233], [234, 235], [235, 238], [238, 239], [240, 244], [245, 249], [250, 256], [257, 259], [260, 273], [273, 274], [275, 282], [283, 285], [286, 288], [289, 299], [300, 303], [304, 305], [306, 309], [310, 312], [313, 321], [322, 324], [325, 340], [341, 343], [344, 346], [347, 354], [355, 357], [358, 367], [368, 376], [376, 377]]}
{"doc_key": "ai-train-50", "ner": [[0, 3, "algorithm"], [11, 12, "field"], [15, 17, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 11, 12, "related-to", "good_at", true, false], [0, 3, 15, 17, "related-to", "good_at", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Las", "redes", "neuronales", "artificiales", "son", "modelos", "computacionales", "que", "destacan", "en", "el", "aprendizaje", "autom\u00e1tico", "y", "el", "reconocimiento", "de", "patrones", "."], "sentence-detokenized": "Las redes neuronales artificiales son modelos computacionales que destacan en el aprendizaje autom\u00e1tico y el reconocimiento de patrones.", "token2charspan": [[0, 3], [4, 9], [10, 20], [21, 33], [34, 37], [38, 45], [46, 61], [62, 65], [66, 74], [75, 77], [78, 80], [81, 92], [93, 103], [104, 105], [106, 108], [109, 123], [124, 126], [127, 135], [135, 136]]}
{"doc_key": "ai-train-51", "ner": [[0, 2, "researcher"], [4, 6, "researcher"], [8, 12, "misc"], [14, 18, "conference"], [20, 20, "conference"], [33, 34, "algorithm"], [38, 39, "researcher"], [41, 42, "researcher"], [35, 50, "misc"], [52, 61, "conference"], [63, 63, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[8, 12, 0, 2, "artifact", "", false, false], [8, 12, 4, 6, "artifact", "", false, false], [8, 12, 14, 18, "temporal", "", false, false], [20, 20, 14, 18, "named", "", false, false], [35, 50, 33, 34, "topic", "", false, false], [35, 50, 38, 39, "artifact", "", false, false], [35, 50, 41, 42, "artifact", "", false, false], [35, 50, 52, 61, "temporal", "", false, false], [63, 63, 52, 61, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["C", ".", "Papageorgiou", "y", "T", ".", "Poggio", ",", "A", "Trainable", "Pedestrian", "Detection", "system", ",", "International", "Journal", "of", "Computer", "Vision", "(", "IJCV", ")", ",", "p\u00e1ginas", "1:", "15-33", ",", "2000", "otros", "utilizan", "caracter\u00edsticas", "locales", "como", "el", "histograma", "de", "gradientes", "orientados", "N.", "Dalal", ",", "B.", "Triggs", ",", "Histograms", "of", "oriented", "gradients", "for", "human", "detection", ",", "IEEE", "Computer", "Society", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", ",", "p\u00e1ginas", "1:", "886-893", ",", "2005", "descriptores", "."], "sentence-detokenized": "C. Papageorgiou y T. Poggio, A Trainable Pedestrian Detection system, International Journal of Computer Vision (IJCV), p\u00e1ginas 1: 15-33, 2000 otros utilizan caracter\u00edsticas locales como el histograma de gradientes orientados N. Dalal, B. Triggs, Histograms of oriented gradients for human detection, IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), p\u00e1ginas 1: 886-893, 2005 descriptores.", "token2charspan": [[0, 1], [1, 2], [3, 15], [16, 17], [18, 19], [19, 20], [21, 27], [27, 28], [29, 30], [31, 40], [41, 51], [52, 61], [62, 68], [68, 69], [70, 83], [84, 91], [92, 94], [95, 103], [104, 110], [111, 112], [112, 116], [116, 117], [117, 118], [119, 126], [127, 129], [130, 135], [135, 136], [137, 141], [142, 147], [148, 156], [157, 172], [173, 180], [181, 185], [186, 188], [189, 199], [200, 202], [203, 213], [214, 224], [225, 227], [228, 233], [233, 234], [235, 237], [238, 244], [244, 245], [246, 256], [257, 259], [260, 268], [269, 278], [279, 282], [283, 288], [289, 298], [298, 299], [300, 304], [305, 313], [314, 321], [322, 332], [333, 335], [336, 344], [345, 351], [352, 355], [356, 363], [364, 375], [376, 377], [377, 381], [381, 382], [382, 383], [384, 391], [392, 394], [395, 402], [402, 403], [404, 408], [409, 421], [421, 422]]}
{"doc_key": "ai-train-52", "ner": [[1, 1, "algorithm"], [6, 9, "algorithm"], [15, 17, "task"], [20, 21, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 6, 9, "type-of", "", false, false], [15, 17, 1, 1, "usage", "", true, false], [15, 17, 20, 21, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Un", "autocodificador", "es", "un", "tipo", "de", "red", "neuronal", "artificial", "que", "se", "utiliza", "para", "aprender", "el", "aprendizaje", "de", "caracter\u00edsticas", "de", "forma", "no", "supervisada", "."], "sentence-detokenized": "Un autocodificador es un tipo de red neuronal artificial que se utiliza para aprender el aprendizaje de caracter\u00edsticas de forma no supervisada.", "token2charspan": [[0, 2], [3, 18], [19, 21], [22, 24], [25, 29], [30, 32], [33, 36], [37, 45], [46, 56], [57, 60], [61, 63], [64, 71], [72, 76], [77, 85], [86, 88], [89, 100], [101, 103], [104, 119], [120, 122], [123, 128], [129, 131], [132, 143], [143, 144]]}
{"doc_key": "ai-train-53", "ner": [[0, 0, "researcher"], [4, 4, "organisation"], [13, 15, "field"], [17, 20, "field"], [25, 30, "organisation"], [32, 32, "organisation"], [39, 41, "field"], [44, 46, "field"], [51, 52, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 4, "role", "fellow_of", false, false], [0, 0, 13, 15, "related-to", "contributes_to", false, false], [0, 0, 17, 20, "related-to", "contributes_to", false, false], [0, 0, 25, 30, "role", "fellow_of", false, false], [0, 0, 39, 41, "related-to", "contributes_to", false, false], [0, 0, 44, 46, "related-to", "contributes_to", false, false], [32, 32, 25, 30, "named", "", false, false], [51, 52, 25, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Haralick", "es", "miembro", "del", "IEEE", "por", "sus", "contribuciones", "en", "el", "campo", "de", "la", "visi\u00f3n", "por", "ordenador", "y", "el", "procesamiento", "de", "im\u00e1genes", "y", "miembro", "de", "la", "Asociaci\u00f3n", "Internacional", "de", "Reconocimiento", "de", "Patrones", "(", "IAPR", ")", "por", "sus", "contribuciones", "en", "el", "reconocimiento", "de", "patrones", ",", "el", "procesamiento", "de", "im\u00e1genes", "y", "el", "servicio", "a", "la", "IAPR", "."], "sentence-detokenized": "Haralick es miembro del IEEE por sus contribuciones en el campo de la visi\u00f3n por ordenador y el procesamiento de im\u00e1genes y miembro de la Asociaci\u00f3n Internacional de Reconocimiento de Patrones (IAPR) por sus contribuciones en el reconocimiento de patrones, el procesamiento de im\u00e1genes y el servicio a la IAPR.", "token2charspan": [[0, 8], [9, 11], [12, 19], [20, 23], [24, 28], [29, 32], [33, 36], [37, 51], [52, 54], [55, 57], [58, 63], [64, 66], [67, 69], [70, 76], [77, 80], [81, 90], [91, 92], [93, 95], [96, 109], [110, 112], [113, 121], [122, 123], [124, 131], [132, 134], [135, 137], [138, 148], [149, 162], [163, 165], [166, 180], [181, 183], [184, 192], [193, 194], [194, 198], [198, 199], [200, 203], [204, 207], [208, 222], [223, 225], [226, 228], [229, 243], [244, 246], [247, 255], [255, 256], [257, 259], [260, 273], [274, 276], [277, 285], [286, 287], [288, 290], [291, 299], [300, 301], [302, 304], [305, 309], [309, 310]]}
{"doc_key": "ai-train-54", "ner": [[4, 8, "task"], [15, 18, "algorithm"], [20, 20, "algorithm"], [24, 25, "researcher"], [27, 28, "organisation"], [30, 31, "researcher"], [34, 36, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 8, 15, 18, "usage", "", false, false], [15, 18, 24, 25, "origin", "", true, false], [15, 18, 30, 31, "origin", "", true, false], [20, 20, 15, 18, "named", "", false, false], [24, 25, 27, 28, "physical", "", false, false], [24, 25, 27, 28, "role", "", false, false], [30, 31, 34, 36, "physical", "", false, false], [30, 31, 34, 36, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["El", "primer", "intento", "de", "ASR", "de", "extremo", "a", "extremo", "fue", "con", "los", "sistemas", "basados", "en", "la", "clasificaci\u00f3n", "temporal", "conexionista", "(", "CTC", ")", "introducidos", "por", "Alex", "Graves", "de", "Google", "DeepMind", "y", "Navdeep", "Jaitly", "de", "la", "Universidad", "de", "Toronto", "en", "2014", "."], "sentence-detokenized": "El primer intento de ASR de extremo a extremo fue con los sistemas basados en la clasificaci\u00f3n temporal conexionista (CTC) introducidos por Alex Graves de Google DeepMind y Navdeep Jaitly de la Universidad de Toronto en 2014.", "token2charspan": [[0, 2], [3, 9], [10, 17], [18, 20], [21, 24], [25, 27], [28, 35], [36, 37], [38, 45], [46, 49], [50, 53], [54, 57], [58, 66], [67, 74], [75, 77], [78, 80], [81, 94], [95, 103], [104, 116], [117, 118], [118, 121], [121, 122], [123, 135], [136, 139], [140, 144], [145, 151], [152, 154], [155, 161], [162, 170], [171, 172], [173, 180], [181, 187], [188, 190], [191, 193], [194, 205], [206, 208], [209, 216], [217, 219], [220, 224], [224, 225]]}
{"doc_key": "ai-train-55", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [11, 12, "algorithm"], [14, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 0, 2, "named", "", false, false], [11, 12, 0, 2, "type-of", "", false, false], [14, 14, 11, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["La", "programaci\u00f3n", "lineal-fraccionada", "(", "PLF", ")", "es", "una", "generalizaci\u00f3n", "de", "la", "programaci\u00f3n", "lineal", "(", "PL", ")", "."], "sentence-detokenized": "La programaci\u00f3n lineal-fraccionada (PLF) es una generalizaci\u00f3n de la programaci\u00f3n lineal (PL).", "token2charspan": [[0, 2], [3, 15], [16, 34], [35, 36], [36, 39], [39, 40], [41, 43], [44, 47], [48, 62], [63, 65], [66, 68], [69, 81], [82, 88], [89, 90], [90, 92], [92, 93], [93, 94]]}
{"doc_key": "ai-train-56", "ner": [[0, 0, "researcher"], [8, 9, "misc"], [12, 19, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 9, "win-defeat", "", false, false], [8, 9, 12, 19, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lafferty", "recibi\u00f3", "numerosos", "premios", ",", "entre", "ellos", "dos", "premios", "Test-of-Time", "en", "la", "International", "Conference", "on", "Machine", "Learning", "2011", "y", "2012", ","], "sentence-detokenized": "Lafferty recibi\u00f3 numerosos premios, entre ellos dos premios Test-of-Time en la International Conference on Machine Learning 2011 y 2012,", "token2charspan": [[0, 8], [9, 16], [17, 26], [27, 34], [34, 35], [36, 41], [42, 47], [48, 51], [52, 59], [60, 72], [73, 75], [76, 78], [79, 92], [93, 103], [104, 106], [107, 114], [115, 123], [124, 128], [129, 130], [131, 135], [135, 136]]}
{"doc_key": "ai-train-57", "ner": [[11, 11, "product"], [13, 13, "programlang"], [27, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Con", "la", "llegada", "de", "los", "frameworks", "basados", "en", "componentes", ",", "como", ".NET", "y", "Java", ",", "los", "entornos", "de", "desarrollo", "basados", "en", "componentes", "son", "capaces", "de", "desplegar", "la", "red", "neuronal", "desarrollada", "en", "estos", "frameworks", "como", "componentes", "heredables", "."], "sentence-detokenized": "Con la llegada de los frameworks basados en componentes, como .NET y Java, los entornos de desarrollo basados en componentes son capaces de desplegar la red neuronal desarrollada en estos frameworks como componentes heredables.", "token2charspan": [[0, 3], [4, 6], [7, 14], [15, 17], [18, 21], [22, 32], [33, 40], [41, 43], [44, 55], [55, 56], [57, 61], [62, 66], [67, 68], [69, 73], [73, 74], [75, 78], [79, 87], [88, 90], [91, 101], [102, 109], [110, 112], [113, 124], [125, 128], [129, 136], [137, 139], [140, 149], [150, 152], [153, 156], [157, 165], [166, 178], [179, 181], [182, 187], [188, 198], [199, 203], [204, 215], [216, 226], [226, 227]]}
{"doc_key": "ai-train-58", "ner": [[4, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Como", "en", "el", "caso", "de", "BLEU", ",", "la", "unidad", "b\u00e1sica", "de", "evaluaci\u00f3n", "es", "la", "frase", ",", "el", "algoritmo", "crea", "primero", "un", "alineamiento", "(", "ver", "ilustraciones", ")", "entre", "dos", "frases", ",", "la", "cadena", "de", "traducci\u00f3n", "candidata", "y", "la", "cadena", "de", "traducci\u00f3n", "de", "referencia", "."], "sentence-detokenized": "Como en el caso de BLEU, la unidad b\u00e1sica de evaluaci\u00f3n es la frase, el algoritmo crea primero un alineamiento (ver ilustraciones) entre dos frases, la cadena de traducci\u00f3n candidata y la cadena de traducci\u00f3n de referencia.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 15], [16, 18], [19, 23], [23, 24], [25, 27], [28, 34], [35, 41], [42, 44], [45, 55], [56, 58], [59, 61], [62, 67], [67, 68], [69, 71], [72, 81], [82, 86], [87, 94], [95, 97], [98, 110], [111, 112], [112, 115], [116, 129], [129, 130], [131, 136], [137, 140], [141, 147], [147, 148], [149, 151], [152, 158], [159, 161], [162, 172], [173, 182], [183, 184], [185, 187], [188, 194], [195, 197], [198, 208], [209, 211], [212, 222], [222, 223]]}
{"doc_key": "ai-train-59", "ner": [[7, 14, "conference"], [30, 30, "task"], [28, 33, "task"], [37, 38, "metrics"], [40, 44, "metrics"], [55, 60, "conference"], [62, 62, "conference"], [65, 65, "location"], [67, 67, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[7, 14, 30, 30, "related-to", "subject_at", false, false], [7, 14, 28, 33, "related-to", "subject_at", false, false], [37, 38, 7, 14, "temporal", "", false, false], [40, 44, 37, 38, "named", "", true, false], [62, 62, 55, 60, "named", "", false, false], [65, 65, 67, 67, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Una", "de", "las", "m\u00e9tricas", "utilizadas", "en", "las", "conferencias", "anuales", "de", "comprensi\u00f3n", "de", "documentos", "del", "NIST", ",", "en", "las", "que", "los", "grupos", "de", "investigaci\u00f3n", "presentan", "sus", "sistemas", "tanto", "para", "tareas", "de", "resumen", "como", "de", "traducci\u00f3n", ",", "es", "la", "m\u00e9trica", "ROUGE", "(", "Recall-Oriented", "Understudy", "for", "Gisting", "Evaluation", ",", "en", "ingl\u00e9s", ")", ",", "en", "los", "avances", "de", "los", "sistemas", "de", "procesamiento", "de", "informaci\u00f3n", "neuronal", "(", "NIPS", ")", ",", "Montreal", ",", "Canad\u00e1", ",", "diciembre", "-", "2014", "."], "sentence-detokenized": "Una de las m\u00e9tricas utilizadas en las conferencias anuales de comprensi\u00f3n de documentos del NIST, en las que los grupos de investigaci\u00f3n presentan sus sistemas tanto para tareas de resumen como de traducci\u00f3n, es la m\u00e9trica ROUGE (Recall-Oriented Understudy for Gisting Evaluation, en ingl\u00e9s), en los avances de los sistemas de procesamiento de informaci\u00f3n neuronal (NIPS), Montreal, Canad\u00e1, diciembre - 2014.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 19], [20, 30], [31, 33], [34, 37], [38, 50], [51, 58], [59, 61], [62, 73], [74, 76], [77, 87], [88, 91], [92, 96], [96, 97], [98, 100], [101, 104], [105, 108], [109, 112], [113, 119], [120, 122], [123, 136], [137, 146], [147, 150], [151, 159], [160, 165], [166, 170], [171, 177], [178, 180], [181, 188], [189, 193], [194, 196], [197, 207], [207, 208], [209, 211], [212, 214], [215, 222], [223, 228], [229, 230], [230, 245], [246, 256], [257, 260], [261, 268], [269, 279], [279, 280], [281, 283], [284, 290], [290, 291], [291, 292], [293, 295], [296, 299], [300, 307], [308, 310], [311, 314], [315, 323], [324, 326], [327, 340], [341, 343], [344, 355], [356, 364], [365, 366], [366, 370], [370, 371], [371, 372], [373, 381], [381, 382], [383, 389], [389, 390], [391, 400], [401, 402], [403, 407], [407, 408]]}
{"doc_key": "ai-train-60", "ner": [[7, 7, "programlang"], [9, 9, "product"], [11, 12, "programlang"], [16, 16, "product"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 7, 11, 12, "type-of", "", false, false], [7, 7, 22, 22, "named", "", false, false], [9, 9, 11, 12, "part-of", "", false, false], [9, 9, 16, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["La", "misma", "implementaci\u00f3n", ",", "para", "ejecutar", "en", "Java", "con", "JShell", "(", "Java", "9", "m\u00ednimo", ")", ":", "codejshell", "scriptfile", "/", "codesyntaxhighlight", "lang", "=", "java"], "sentence-detokenized": "La misma implementaci\u00f3n, para ejecutar en Java con JShell (Java 9 m\u00ednimo): codejshell scriptfile / codesyntaxhighlight lang = java", "token2charspan": [[0, 2], [3, 8], [9, 23], [23, 24], [25, 29], [30, 38], [39, 41], [42, 46], [47, 50], [51, 57], [58, 59], [59, 63], [64, 65], [66, 72], [72, 73], [73, 74], [75, 85], [86, 96], [97, 98], [99, 118], [119, 123], [124, 125], [126, 130]]}
{"doc_key": "ai-train-61", "ner": [[0, 4, "metrics"], [8, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 4, 8, 9, "origin", "based_on", false, false]], "relations_mapping_to_source": [0], "sentence": ["La", "m\u00e9trica", "del", "NIST", "se", "basa", "en", "la", "m\u00e9trica", "BLEU", ",", "pero", "con", "algunas", "alteraciones", "."], "sentence-detokenized": "La m\u00e9trica del NIST se basa en la m\u00e9trica BLEU, pero con algunas alteraciones.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 19], [20, 22], [23, 27], [28, 30], [31, 33], [34, 41], [42, 46], [46, 47], [48, 52], [53, 56], [57, 64], [65, 77], [77, 78]]}
{"doc_key": "ai-train-62", "ner": [[9, 9, "country"], [11, 14, "university"], [16, 19, "university"], [26, 27, "product"], [31, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 14, 9, 9, "physical", "", false, false], [16, 19, 9, 9, "physical", "", false, false], [26, 27, 11, 14, "origin", "", false, false], [26, 27, 16, 19, "origin", "", false, false], [26, 27, 31, 32, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["A", "finales", "de", "los", "a\u00f1os", "80", ",", "dos", "universidades", "holandesas", ",", "la", "Universidad", "de", "Groningen", "y", "la", "Universidad", "de", "Twente", ",", "iniciaron", "conjuntamente", "un", "proyecto", "llamado", "Knowledge", "Graphs", ",", "que", "son", "redes", "sem\u00e1nticas", "pero", "con", "la", "restricci\u00f3n", "a\u00f1adida", "de", "que", "las", "aristas", "est\u00e1n", "restringidas", "a", "ser", "de", "un", "conjunto", "limitado", "de", "relaciones", "posibles", ",", "para", "facilitar", "las", "\u00e1lgebras", "en", "el", "grafo", "."], "sentence-detokenized": "A finales de los a\u00f1os 80, dos universidades holandesas, la Universidad de Groningen y la Universidad de Twente, iniciaron conjuntamente un proyecto llamado Knowledge Graphs, que son redes sem\u00e1nticas pero con la restricci\u00f3n a\u00f1adida de que las aristas est\u00e1n restringidas a ser de un conjunto limitado de relaciones posibles, para facilitar las \u00e1lgebras en el grafo.", "token2charspan": [[0, 1], [2, 9], [10, 12], [13, 16], [17, 21], [22, 24], [24, 25], [26, 29], [30, 43], [44, 54], [54, 55], [56, 58], [59, 70], [71, 73], [74, 83], [84, 85], [86, 88], [89, 100], [101, 103], [104, 110], [110, 111], [112, 121], [122, 135], [136, 138], [139, 147], [148, 155], [156, 165], [166, 172], [172, 173], [174, 177], [178, 181], [182, 187], [188, 198], [199, 203], [204, 207], [208, 210], [211, 222], [223, 230], [231, 233], [234, 237], [238, 241], [242, 249], [250, 255], [256, 268], [269, 270], [271, 274], [275, 277], [278, 280], [281, 289], [290, 298], [299, 301], [302, 312], [313, 321], [321, 322], [323, 327], [328, 337], [338, 341], [342, 350], [351, 353], [354, 356], [357, 362], [362, 363]]}
{"doc_key": "ai-train-63", "ner": [[0, 2, "product"], [16, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 16, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Los", "correctores", "gramaticales", "suelen", "implementarse", "como", "una", "funci\u00f3n", "de", "un", "programa", "m\u00e1s", "amplio", ",", "como", "un", "procesador", "de", "textos", ",", "pero", "tambi\u00e9n", "est\u00e1n", "disponibles", "como", "una", "aplicaci\u00f3n", "independiente", "que", "puede", "activarse", "desde", "los", "programas", "que", "trabajan", "con", "texto", "editable", "."], "sentence-detokenized": "Los correctores gramaticales suelen implementarse como una funci\u00f3n de un programa m\u00e1s amplio, como un procesador de textos, pero tambi\u00e9n est\u00e1n disponibles como una aplicaci\u00f3n independiente que puede activarse desde los programas que trabajan con texto editable.", "token2charspan": [[0, 3], [4, 15], [16, 28], [29, 35], [36, 49], [50, 54], [55, 58], [59, 66], [67, 69], [70, 72], [73, 81], [82, 85], [86, 92], [92, 93], [94, 98], [99, 101], [102, 112], [113, 115], [116, 122], [122, 123], [124, 128], [129, 136], [137, 142], [143, 154], [155, 159], [160, 163], [164, 174], [175, 188], [189, 192], [193, 198], [199, 208], [209, 214], [215, 218], [219, 228], [229, 232], [233, 241], [242, 245], [246, 251], [252, 260], [260, 261]]}
{"doc_key": "ai-train-64", "ner": [[4, 11, "organisation"], [14, 21, "conference"], [23, 27, "organisation"], [33, 34, "conference"], [36, 38, "conference"], [40, 42, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Es", "miembro", "de", "la", "Asociaci\u00f3n", "Americana", "para", "el", "Avance", "de", "la", "Ciencia", ",", "la", "Asociaci\u00f3n", "para", "el", "Avance", "de", "la", "Inteligencia", "Artificial", "y", "la", "Sociedad", "de", "Ciencias", "Cognitivas", ",", "y", "editor", "de", "J.", "Automated", "Reasoning", ",", "J.", "Learning", "Sciences", "y", "J.", "Applied", "Ontology", "."], "sentence-detokenized": "Es miembro de la Asociaci\u00f3n Americana para el Avance de la Ciencia, la Asociaci\u00f3n para el Avance de la Inteligencia Artificial y la Sociedad de Ciencias Cognitivas, y editor de J. Automated Reasoning, J. Learning Sciences y J. Applied Ontology.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 16], [17, 27], [28, 37], [38, 42], [43, 45], [46, 52], [53, 55], [56, 58], [59, 66], [66, 67], [68, 70], [71, 81], [82, 86], [87, 89], [90, 96], [97, 99], [100, 102], [103, 115], [116, 126], [127, 128], [129, 131], [132, 140], [141, 143], [144, 152], [153, 163], [163, 164], [165, 166], [167, 173], [174, 176], [177, 179], [180, 189], [190, 199], [199, 200], [201, 203], [204, 212], [213, 221], [222, 223], [224, 226], [227, 234], [235, 243], [243, 244]]}
{"doc_key": "ai-train-65", "ner": [[0, 3, "algorithm"], [5, 5, "algorithm"], [11, 13, "task"], [21, 22, "researcher"], [24, 27, "university"], [29, 30, "researcher"], [32, 35, "organisation"], [37, 37, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 3, 11, 13, "type-of", "", false, false], [0, 3, 21, 22, "origin", "", false, false], [0, 3, 29, 30, "origin", "", false, false], [5, 5, 0, 3, "named", "", false, false], [21, 22, 24, 27, "physical", "", false, false], [21, 22, 24, 27, "role", "", false, false], [29, 30, 32, 35, "role", "", false, false], [37, 37, 32, 35, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["La", "codificaci\u00f3n", "predictiva", "lineal", "(", "LPC", ")", ",", "una", "forma", "de", "codificaci\u00f3n", "del", "habla", ",", "comenz\u00f3", "a", "desarrollarse", "con", "el", "trabajo", "Fumitada", "Itakura", "de", "la", "Universidad", "de", "Nagoya", "y", "Shuzo", "Saito", "de", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "en", "1966", "."], "sentence-detokenized": "La codificaci\u00f3n predictiva lineal (LPC), una forma de codificaci\u00f3n del habla, comenz\u00f3 a desarrollarse con el trabajo Fumitada Itakura de la Universidad de Nagoya y Shuzo Saito de Nippon Telegraph and Telephone (NTT) en 1966.", "token2charspan": [[0, 2], [3, 15], [16, 26], [27, 33], [34, 35], [35, 38], [38, 39], [39, 40], [41, 44], [45, 50], [51, 53], [54, 66], [67, 70], [71, 76], [76, 77], [78, 85], [86, 87], [88, 101], [102, 105], [106, 108], [109, 116], [117, 125], [126, 133], [134, 136], [137, 139], [140, 151], [152, 154], [155, 161], [162, 163], [164, 169], [170, 175], [176, 178], [179, 185], [186, 195], [196, 199], [200, 209], [210, 211], [211, 214], [214, 215], [216, 218], [219, 223], [223, 224]]}
{"doc_key": "ai-train-66", "ner": [[63, 65, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Si", "la", "se\u00f1al", "es", "adem\u00e1s", "erg\u00f3dica", ",", "todas", "las", "trayectorias", "de", "muestreo", "exhiben", "la", "misma", "media", "temporal", "y", ",", "por", "tanto", ",", "mathR", "_", "x", "^", "{", "n", "/", "T", "_", "0", "}", "(", "\\", "tau", ")", "=", "\\", "widehat", "{", "R", "}", "_", "x", "^", "{", "n", "/", "T", "_", "0", "}", "(", "\\", "tau", ")", "/", "math", "en", "el", "sentido", "del", "error", "cuadr\u00e1tico", "medio", "."], "sentence-detokenized": "Si la se\u00f1al es adem\u00e1s erg\u00f3dica, todas las trayectorias de muestreo exhiben la misma media temporal y, por tanto, mathR _ x ^ {n / T _ 0} (\\ tau) =\\ widehat {R} _ x ^ {n / T _ 0} (\\ tau) / math en el sentido del error cuadr\u00e1tico medio.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 14], [15, 21], [22, 30], [30, 31], [32, 37], [38, 41], [42, 54], [55, 57], [58, 66], [67, 74], [75, 77], [78, 83], [84, 89], [90, 98], [99, 100], [100, 101], [102, 105], [106, 111], [111, 112], [113, 118], [119, 120], [121, 122], [123, 124], [125, 126], [126, 127], [128, 129], [130, 131], [132, 133], [134, 135], [135, 136], [137, 138], [138, 139], [140, 143], [143, 144], [145, 146], [146, 147], [148, 155], [156, 157], [157, 158], [158, 159], [160, 161], [162, 163], [164, 165], [166, 167], [167, 168], [169, 170], [171, 172], [173, 174], [175, 176], [176, 177], [178, 179], [179, 180], [181, 184], [184, 185], [186, 187], [188, 192], [193, 195], [196, 198], [199, 206], [207, 210], [211, 216], [217, 227], [228, 233], [233, 234]]}
{"doc_key": "ai-train-67", "ner": [[0, 3, "task"], [6, 8, "task"], [18, 21, "algorithm"], [23, 23, "algorithm"], [26, 28, "algorithm"], [30, 30, "algorithm"], [33, 36, "algorithm"], [38, 38, "algorithm"], [41, 45, "algorithm"], [47, 49, "algorithm"], [50, 53, "misc"], [60, 60, "algorithm"], [62, 64, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[18, 21, 50, 53, "related-to", "", false, false], [23, 23, 18, 21, "named", "", false, false], [26, 28, 50, 53, "related-to", "", false, false], [30, 30, 26, 28, "named", "", false, false], [33, 36, 50, 53, "related-to", "", false, false], [38, 38, 33, 36, "named", "", false, false], [41, 45, 50, 53, "related-to", "", false, false], [47, 49, 41, 45, "named", "", false, false], [60, 60, 62, 64, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["La", "extracci\u00f3n", "de", "caracter\u00edsticas", "y", "la", "reducci\u00f3n", "de", "dimensiones", "pueden", "combinarse", "en", "un", "solo", "paso", "utilizando", "t\u00e9cnicas", "de", "an\u00e1lisis", "de", "componentes", "principales", "(", "PCA", ")", ",", "an\u00e1lisis", "discriminante", "lineal", "(", "LDA", ")", ",", "an\u00e1lisis", "de", "correlaci\u00f3n", "can\u00f3nica", "(", "CCA", ")", "o", "factorizaci\u00f3n", "de", "matrices", "no", "negativas", "(", "NMF", ")", "como", "paso", "previo", "al", "procesamiento", ",", "seguido", "de", "la", "agrupaci\u00f3n", "por", "K-NN", "en", "vectores", "de", "caracter\u00edsticas", "en", "el", "espacio", "de", "dimensi\u00f3n", "reducida", "."], "sentence-detokenized": "La extracci\u00f3n de caracter\u00edsticas y la reducci\u00f3n de dimensiones pueden combinarse en un solo paso utilizando t\u00e9cnicas de an\u00e1lisis de componentes principales (PCA), an\u00e1lisis discriminante lineal (LDA), an\u00e1lisis de correlaci\u00f3n can\u00f3nica (CCA) o factorizaci\u00f3n de matrices no negativas (NMF) como paso previo al procesamiento, seguido de la agrupaci\u00f3n por K-NN en vectores de caracter\u00edsticas en el espacio de dimensi\u00f3n reducida.", "token2charspan": [[0, 2], [3, 13], [14, 16], [17, 32], [33, 34], [35, 37], [38, 47], [48, 50], [51, 62], [63, 69], [70, 80], [81, 83], [84, 86], [87, 91], [92, 96], [97, 107], [108, 116], [117, 119], [120, 128], [129, 131], [132, 143], [144, 155], [156, 157], [157, 160], [160, 161], [161, 162], [163, 171], [172, 185], [186, 192], [193, 194], [194, 197], [197, 198], [198, 199], [200, 208], [209, 211], [212, 223], [224, 232], [233, 234], [234, 237], [237, 238], [239, 240], [241, 254], [255, 257], [258, 266], [267, 269], [270, 279], [280, 281], [281, 284], [284, 285], [286, 290], [291, 295], [296, 302], [303, 305], [306, 319], [319, 320], [321, 328], [329, 331], [332, 334], [335, 345], [346, 349], [350, 354], [355, 357], [358, 366], [367, 369], [370, 385], [386, 388], [389, 391], [392, 399], [400, 402], [403, 412], [413, 421], [421, 422]]}
{"doc_key": "ai-train-68", "ner": [[4, 4, "programlang"], [6, 6, "programlang"], [8, 8, "programlang"], [10, 10, "programlang"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 15, 4, 4, "related-to", "program_type_compatible_with", false, false], [15, 15, 6, 6, "related-to", "program_type_compatible_with", false, false], [15, 15, 8, 8, "related-to", "program_type_compatible_with", false, false], [15, 15, 10, 10, "related-to", "program_type_compatible_with", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Las", "bibliotecas", "escritas", "en", "Perl", ",", "Java", ",", "ActiveX", "o", ".NET", "pueden", "llamarse", "directamente", "desde", "MATLAB", ","], "sentence-detokenized": "Las bibliotecas escritas en Perl, Java, ActiveX o .NET pueden llamarse directamente desde MATLAB,", "token2charspan": [[0, 3], [4, 15], [16, 24], [25, 27], [28, 32], [32, 33], [34, 38], [38, 39], [40, 47], [48, 49], [50, 54], [55, 61], [62, 70], [71, 83], [84, 89], [90, 96], [96, 97]]}
{"doc_key": "ai-train-69", "ner": [[3, 9, "task"], [12, 16, "task"], [37, 39, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 9, 12, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["La", "tarea", "de", "reconocer", "entidades", "con", "nombre", "en", "el", "texto", "es", "el", "Reconocimiento", "de", "Entidades", "con", "Nombre", ",", "mientras", "que", "la", "tarea", "de", "determinar", "la", "identidad", "de", "las", "entidades", "con", "nombre", "mencionadas", "en", "el", "texto", "se", "llama", "Enlace", "de", "Entidades", "."], "sentence-detokenized": "La tarea de reconocer entidades con nombre en el texto es el Reconocimiento de Entidades con Nombre, mientras que la tarea de determinar la identidad de las entidades con nombre mencionadas en el texto se llama Enlace de Entidades.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 21], [22, 31], [32, 35], [36, 42], [43, 45], [46, 48], [49, 54], [55, 57], [58, 60], [61, 75], [76, 78], [79, 88], [89, 92], [93, 99], [99, 100], [101, 109], [110, 113], [114, 116], [117, 122], [123, 125], [126, 136], [137, 139], [140, 149], [150, 152], [153, 156], [157, 166], [167, 170], [171, 177], [178, 189], [190, 192], [193, 195], [196, 201], [202, 204], [205, 210], [211, 217], [218, 220], [221, 230], [230, 231]]}
{"doc_key": "ai-train-70", "ner": [[1, 2, "algorithm"], [29, 29, "programlang"], [31, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 31, 31, "part-of", "", true, false], [31, 31, 29, 29, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Las", "funciones", "sigmoides", "y", "las", "derivadas", "utilizadas", "en", "el", "paquete", "se", "incluyeron", "originalmente", "en", "el", "paquete", ",", "a", "partir", "de", "la", "versi\u00f3n", "0.8.0", ",", "se", "publicaron", "en", "un", "paquete", "R", "separado", "sigmoid", ",", "con", "la", "intenci\u00f3n", "de", "permitir", "un", "uso", "m\u00e1s", "general", "."], "sentence-detokenized": "Las funciones sigmoides y las derivadas utilizadas en el paquete se incluyeron originalmente en el paquete, a partir de la versi\u00f3n 0.8.0, se publicaron en un paquete R separado sigmoid, con la intenci\u00f3n de permitir un uso m\u00e1s general.", "token2charspan": [[0, 3], [4, 13], [14, 23], [24, 25], [26, 29], [30, 39], [40, 50], [51, 53], [54, 56], [57, 64], [65, 67], [68, 78], [79, 92], [93, 95], [96, 98], [99, 106], [106, 107], [108, 109], [110, 116], [117, 119], [120, 122], [123, 130], [131, 136], [136, 137], [138, 140], [141, 151], [152, 154], [155, 157], [158, 165], [166, 167], [168, 176], [177, 184], [184, 185], [186, 189], [190, 192], [193, 202], [203, 205], [206, 214], [215, 217], [218, 221], [222, 225], [226, 233], [233, 234]]}
{"doc_key": "ai-train-71", "ner": [[0, 1, "programlang"], [7, 11, "organisation"], [13, 13, "organisation"], [21, 21, "location"], [23, 23, "location"], [26, 27, "researcher"], [29, 30, "researcher"], [32, 33, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 26, 27, "artifact", "", true, false], [0, 1, 29, 30, "artifact", "", true, false], [0, 1, 32, 33, "artifact", "", true, false], [13, 13, 7, 11, "named", "", false, false], [13, 13, 21, 21, "physical", "", false, false], [21, 21, 23, 23, "physical", "", false, false], [26, 27, 7, 11, "role", "", false, false], [29, 30, 7, 11, "role", "", false, false], [32, 33, 7, 11, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["El", "logotipo", "fue", "creado", "en", "1967", "en", "Bolt", ",", "Beranek", "y", "Newman", "(", "BBN", ")", ",", "una", "empresa", "de", "investigaci\u00f3n", "de", "Cambridge", ",", "Massachusetts", ",", "por", "Wally", "Feurzeig", ",", "Cynthia", "Solomon", "y", "Seymour", "Papert", "."], "sentence-detokenized": "El logotipo fue creado en 1967 en Bolt, Beranek y Newman (BBN), una empresa de investigaci\u00f3n de Cambridge, Massachusetts, por Wally Feurzeig, Cynthia Solomon y Seymour Papert.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 22], [23, 25], [26, 30], [31, 33], [34, 38], [38, 39], [40, 47], [48, 49], [50, 56], [57, 58], [58, 61], [61, 62], [62, 63], [64, 67], [68, 75], [76, 78], [79, 92], [93, 95], [96, 105], [105, 106], [107, 120], [120, 121], [122, 125], [126, 131], [132, 140], [140, 141], [142, 149], [150, 157], [158, 159], [160, 167], [168, 174], [174, 175]]}
{"doc_key": "ai-train-72", "ner": [[0, 1, "misc"], [10, 12, "field"], [22, 23, "field"], [27, 29, "algorithm"], [32, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 10, 12, "part-of", "", false, false], [0, 1, 22, 23, "compare", "", false, false], [27, 29, 22, 23, "part-of", "", false, false], [32, 33, 22, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["La", "neuroevoluci\u00f3n", "se", "utiliza", "habitualmente", "como", "parte", "del", "paradigma", "del", "aprendizaje", "por", "refuerzo", ",", "y", "puede", "contrastarse", "con", "las", "t\u00e9cnicas", "convencionales", "de", "aprendizaje", "profundo", "que", "utilizan", "el", "descenso", "de", "gradiente", "en", "una", "red", "neuronal", "con", "una", "topolog\u00eda", "fija", "."], "sentence-detokenized": "La neuroevoluci\u00f3n se utiliza habitualmente como parte del paradigma del aprendizaje por refuerzo, y puede contrastarse con las t\u00e9cnicas convencionales de aprendizaje profundo que utilizan el descenso de gradiente en una red neuronal con una topolog\u00eda fija.", "token2charspan": [[0, 2], [3, 17], [18, 20], [21, 28], [29, 42], [43, 47], [48, 53], [54, 57], [58, 67], [68, 71], [72, 83], [84, 87], [88, 96], [96, 97], [98, 99], [100, 105], [106, 118], [119, 122], [123, 126], [127, 135], [136, 150], [151, 153], [154, 165], [166, 174], [175, 178], [179, 187], [188, 190], [191, 199], [200, 202], [203, 212], [213, 215], [216, 219], [220, 223], [224, 232], [233, 236], [237, 240], [241, 250], [251, 255], [255, 256]]}
{"doc_key": "ai-train-73", "ner": [[2, 4, "algorithm"], [53, 55, "metrics"], [57, 57, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[57, 57, 53, 55, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Si", "utilizamos", "los", "m\u00ednimos", "cuadrados", "para", "ajustar", "una", "funci\u00f3n", "en", "forma", "de", "hiperplano", "\u0177", "=", "a", "+", "\u03b2", "supT", "/", "sup", "x", "a", "los", "datos", "(", "x", "sub", "i", "/", "sub", ",", "y", "sub", "i", "/", "sub", ")", "sub", "1", "\u2264", "i", "\u2264n", "/", "sub", ",", "podr\u00edamos", "entonces", "evaluar", "el", "ajuste", "utilizando", "el", "error", "cuadr\u00e1tico", "medio", "(", "MSE", ")", "."], "sentence-detokenized": "Si utilizamos los m\u00ednimos cuadrados para ajustar una funci\u00f3n en forma de hiperplano \u0177 = a + \u03b2 supT / sup x a los datos (x sub i / sub, y sub i / sub) sub 1 \u2264 i \u2264n / sub, podr\u00edamos entonces evaluar el ajuste utilizando el error cuadr\u00e1tico medio (MSE).", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 25], [26, 35], [36, 40], [41, 48], [49, 52], [53, 60], [61, 63], [64, 69], [70, 72], [73, 83], [84, 85], [86, 87], [88, 89], [90, 91], [92, 93], [94, 98], [99, 100], [101, 104], [105, 106], [107, 108], [109, 112], [113, 118], [119, 120], [120, 121], [122, 125], [126, 127], [128, 129], [130, 133], [133, 134], [135, 136], [137, 140], [141, 142], [143, 144], [145, 148], [148, 149], [150, 153], [154, 155], [156, 157], [158, 159], [160, 162], [163, 164], [165, 168], [168, 169], [170, 179], [180, 188], [189, 196], [197, 199], [200, 206], [207, 217], [218, 220], [221, 226], [227, 237], [238, 243], [244, 245], [245, 248], [248, 249], [249, 250]]}
{"doc_key": "ai-train-74", "ner": [[6, 6, "country"], [8, 8, "country"], [10, 10, "country"], [12, 12, "country"], [14, 14, "country"], [16, 16, "country"], [18, 18, "country"], [20, 20, "country"], [22, 22, "country"], [24, 24, "country"], [26, 26, "country"], [28, 28, "country"], [30, 30, "country"], [32, 32, "country"], [34, 34, "country"], [36, 36, "country"], [38, 38, "country"], [40, 40, "country"], [42, 42, "country"], [44, 44, "country"], [47, 48, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "empresa", "tiene", "sedes", "internacionales", "en", "Australia", ",", "Brasil", ",", "Canad\u00e1", ",", "China", ",", "Alemania", ",", "India", ",", "Italia", ",", "Jap\u00f3n", ",", "Corea", ",", "Lituania", ",", "Polonia", ",", "Malasia", ",", "Filipinas", ",", "Rusia", ",", "Singapur", ",", "Sud\u00e1frica", ",", "Espa\u00f1a", ",", "Taiw\u00e1n", ",", "Tailandia", ",", "Turqu\u00eda", "y", "el", "Reino", "Unido", "."], "sentence-detokenized": "La empresa tiene sedes internacionales en Australia, Brasil, Canad\u00e1, China, Alemania, India, Italia, Jap\u00f3n, Corea, Lituania, Polonia, Malasia, Filipinas, Rusia, Singapur, Sud\u00e1frica, Espa\u00f1a, Taiw\u00e1n, Tailandia, Turqu\u00eda y el Reino Unido.", "token2charspan": [[0, 2], [3, 10], [11, 16], [17, 22], [23, 38], [39, 41], [42, 51], [51, 52], [53, 59], [59, 60], [61, 67], [67, 68], [69, 74], [74, 75], [76, 84], [84, 85], [86, 91], [91, 92], [93, 99], [99, 100], [101, 106], [106, 107], [108, 113], [113, 114], [115, 123], [123, 124], [125, 132], [132, 133], [134, 141], [141, 142], [143, 152], [152, 153], [154, 159], [159, 160], [161, 169], [169, 170], [171, 180], [180, 181], [182, 188], [188, 189], [190, 196], [196, 197], [198, 207], [207, 208], [209, 216], [217, 218], [219, 221], [222, 227], [228, 233], [233, 234]]}
{"doc_key": "ai-train-75", "ner": [[1, 1, "misc"], [3, 6, "field"], [11, 11, "organisation"], [14, 18, "university"], [26, 28, "organisation"], [30, 33, "university"], [43, 44, "university"], [46, 46, "university"], [48, 48, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[1, 1, 3, 6, "topic", "", false, false], [1, 1, 11, 11, "origin", "", false, false], [1, 1, 14, 18, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Es", "doctor", "en", "ingenier\u00eda", "el\u00e9ctrica", "e", "inform\u00e1tica", "(", "2000", ")", "por", "Inria", "y", "la", "Universidad", "de", "Niza", "Sophia", "Antipolis", ",", "y", "ha", "ocupado", "puestos", "permanentes", "en", "Siemens", "Corporate", "Technology", ",", "\u00c9cole", "des", "ponts", "ParisTech", ",", "as\u00ed", "como", "puestos", "de", "visita", "en", "las", "universidades", "de", "Rutgers", ",", "Yale", "y", "Houston", "."], "sentence-detokenized": "Es doctor en ingenier\u00eda el\u00e9ctrica e inform\u00e1tica (2000) por Inria y la Universidad de Niza Sophia Antipolis, y ha ocupado puestos permanentes en Siemens Corporate Technology, \u00c9cole des ponts ParisTech, as\u00ed como puestos de visita en las universidades de Rutgers, Yale y Houston.", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 23], [24, 33], [34, 35], [36, 47], [48, 49], [49, 53], [53, 54], [55, 58], [59, 64], [65, 66], [67, 69], [70, 81], [82, 84], [85, 89], [90, 96], [97, 106], [106, 107], [108, 109], [110, 112], [113, 120], [121, 128], [129, 140], [141, 143], [144, 151], [152, 161], [162, 172], [172, 173], [174, 179], [180, 183], [184, 189], [190, 199], [199, 200], [201, 204], [205, 209], [210, 217], [218, 220], [221, 227], [228, 230], [231, 234], [235, 248], [249, 251], [252, 259], [259, 260], [261, 265], [266, 267], [268, 275], [275, 276]]}
{"doc_key": "ai-train-76", "ner": [[10, 11, "researcher"], [13, 13, "researcher"], [17, 18, "product"], [20, 21, "country"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 13, 10, 11, "role", "licensing_patent_to", false, false], [13, 13, 20, 21, "physical", "", false, false], [24, 24, 13, 13, "artifact", "", false, false], [24, 24, 17, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Con", "la", "licencia", "de", "la", "patente", "original", "concedida", "al", "inventor", "George", "Devol", ",", "Engelberger", "desarroll\u00f3", "el", "primer", "robot", "industrial", "de", "Estados", "Unidos", ",", "el", "Unimate", ",", "en", "la", "d\u00e9cada", "de", "1950", "."], "sentence-detokenized": "Con la licencia de la patente original concedida al inventor George Devol, Engelberger desarroll\u00f3 el primer robot industrial de Estados Unidos, el Unimate, en la d\u00e9cada de 1950.", "token2charspan": [[0, 3], [4, 6], [7, 15], [16, 18], [19, 21], [22, 29], [30, 38], [39, 48], [49, 51], [52, 60], [61, 67], [68, 73], [73, 74], [75, 86], [87, 97], [98, 100], [101, 107], [108, 113], [114, 124], [125, 127], [128, 135], [136, 142], [142, 143], [144, 146], [147, 154], [154, 155], [156, 158], [159, 161], [162, 168], [169, 171], [172, 176], [176, 177]]}
{"doc_key": "ai-train-77", "ner": [[4, 6, "task"], [12, 14, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["La", "entrada", "se", "llama", "reconocimiento", "del", "habla", "y", "la", "salida", "se", "llama", "s\u00edntesis", "del", "habla", "."], "sentence-detokenized": "La entrada se llama reconocimiento del habla y la salida se llama s\u00edntesis del habla.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 19], [20, 34], [35, 38], [39, 44], [45, 46], [47, 49], [50, 56], [57, 59], [60, 65], [66, 74], [75, 78], [79, 84], [84, 85]]}
{"doc_key": "ai-train-78", "ner": [[5, 5, "programlang"], [8, 8, "programlang"], [12, 12, "programlang"], [19, 19, "programlang"], [29, 29, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 5, 12, 12, "named", "", false, false], [8, 8, 5, 5, "origin", "descendant_of", false, false], [8, 8, 19, 19, "general-affiliation", "", false, false], [8, 8, 29, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Entre", "los", "descendientes", "del", "lenguaje", "CLIPS", "se", "encuentran", "Jess", "(", "parte", "de", "CLIPS", "basada", "en", "reglas", "y", "reescrita", "en", "Java", ",", "que", "posteriormente", "creci\u00f3", "en", "otra", "direcci\u00f3n", ")", ",", "JESS", "se", "inspir\u00f3", "originalmente", "en"], "sentence-detokenized": "Entre los descendientes del lenguaje CLIPS se encuentran Jess (parte de CLIPS basada en reglas y reescrita en Java, que posteriormente creci\u00f3 en otra direcci\u00f3n), JESS se inspir\u00f3 originalmente en", "token2charspan": [[0, 5], [6, 9], [10, 23], [24, 27], [28, 36], [37, 42], [43, 45], [46, 56], [57, 61], [62, 63], [63, 68], [69, 71], [72, 77], [78, 84], [85, 87], [88, 94], [95, 96], [97, 106], [107, 109], [110, 114], [114, 115], [116, 119], [120, 134], [135, 141], [142, 144], [145, 149], [150, 159], [159, 160], [160, 161], [162, 166], [167, 169], [170, 177], [178, 191], [192, 194]]}
{"doc_key": "ai-train-79", "ner": [[3, 3, "product"], [10, 13, "product"], [16, 17, "organisation"], [21, 22, "product"], [39, 41, "product"], [43, 45, "product"], [66, 68, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 13, 3, 3, "type-of", "", false, false], [16, 17, 10, 13, "usage", "", false, false], [21, 22, 16, 17, "artifact", "", false, false], [39, 41, 16, 17, "origin", "", true, false], [39, 41, 66, 68, "related-to", "", true, false], [43, 45, 16, 17, "origin", "", true, false], [43, 45, 66, 68, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Tambi\u00e9n", "cre\u00f3", "aplicaciones", "AGV", "inteligentes", "y", "flexibles", ",", "dise\u00f1ando", "el", "sistema", "de", "control", "Motivity", "utilizado", "por", "RMT", "Robotics", "para", "desarrollar", "su", "ADAM", "iAGV", "(", "veh\u00edculo", "autoguiado", ")", ",", "utilizado", "para", "operaciones", "complejas", "de", "recogida", "y", "colocaci\u00f3n", ",", "junto", "con", "sistemas", "de", "p\u00f3rtico", "y", "brazos", "rob\u00f3ticos", "industriales", ",", "utilizados", "en", "f\u00e1bricas", "de", "suministros", "de", "autom\u00f3viles", "de", "primer", "nivel", "para", "trasladar", "productos", "de", "un", "proceso", "a", "otro", "en", "disposiciones", "no", "lineales", "."], "sentence-detokenized": "Tambi\u00e9n cre\u00f3 aplicaciones AGV inteligentes y flexibles, dise\u00f1ando el sistema de control Motivity utilizado por RMT Robotics para desarrollar su ADAM iAGV (veh\u00edculo autoguiado), utilizado para operaciones complejas de recogida y colocaci\u00f3n, junto con sistemas de p\u00f3rtico y brazos rob\u00f3ticos industriales, utilizados en f\u00e1bricas de suministros de autom\u00f3viles de primer nivel para trasladar productos de un proceso a otro en disposiciones no lineales.", "token2charspan": [[0, 7], [8, 12], [13, 25], [26, 29], [30, 42], [43, 44], [45, 54], [54, 55], [56, 65], [66, 68], [69, 76], [77, 79], [80, 87], [88, 96], [97, 106], [107, 110], [111, 114], [115, 123], [124, 128], [129, 140], [141, 143], [144, 148], [149, 153], [154, 155], [155, 163], [164, 174], [174, 175], [175, 176], [177, 186], [187, 191], [192, 203], [204, 213], [214, 216], [217, 225], [226, 227], [228, 238], [238, 239], [240, 245], [246, 249], [250, 258], [259, 261], [262, 269], [270, 271], [272, 278], [279, 288], [289, 301], [301, 302], [303, 313], [314, 316], [317, 325], [326, 328], [329, 340], [341, 343], [344, 355], [356, 358], [359, 365], [366, 371], [372, 376], [377, 386], [387, 396], [397, 399], [400, 402], [403, 410], [411, 412], [413, 417], [418, 420], [421, 434], [435, 437], [438, 446], [446, 447]]}
{"doc_key": "ai-train-80", "ner": [[6, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Los", "par\u00e1metros", "\u03b2", "suelen", "estimarse", "por", "m\u00e1xima", "verosimilitud", "."], "sentence-detokenized": "Los par\u00e1metros \u03b2 suelen estimarse por m\u00e1xima verosimilitud.", "token2charspan": [[0, 3], [4, 14], [15, 16], [17, 23], [24, 33], [34, 37], [38, 44], [45, 58], [58, 59]]}
{"doc_key": "ai-train-81", "ner": [[3, 8, "task"], [9, 9, "metrics"], [12, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 3, 8, "part-of", "", false, false], [12, 12, 3, 8, "part-of", "", false, false], [14, 15, 3, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Las", "m\u00e9tricas", "de", "recuperaci\u00f3n", "de", "informaci\u00f3n", ",", "como", "la", "precisi\u00f3n", "y", "el", "recuerdo", "o", "la", "DCG", ",", "son", "\u00fatiles", "para", "evaluar", "la", "calidad", "de", "un", "m\u00e9todo", "de", "recomendaci\u00f3n", "."], "sentence-detokenized": "Las m\u00e9tricas de recuperaci\u00f3n de informaci\u00f3n, como la precisi\u00f3n y el recuerdo o la DCG, son \u00fatiles para evaluar la calidad de un m\u00e9todo de recomendaci\u00f3n.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 28], [29, 31], [32, 43], [43, 44], [45, 49], [50, 52], [53, 62], [63, 64], [65, 67], [68, 76], [77, 78], [79, 81], [82, 85], [85, 86], [87, 90], [91, 97], [98, 102], [103, 110], [111, 113], [114, 121], [122, 124], [125, 127], [128, 134], [135, 137], [138, 151], [151, 152]]}
{"doc_key": "ai-train-82", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["Una", "f\u00e1brica", "t\u00edpica", "contiene", "cientos", "de", "robots", "industriales", "que", "trabajan", "en", "l\u00edneas", "de", "producci\u00f3n", "totalmente", "automatizadas", ",", "con", "un", "robot", "por", "cada", "diez", "trabajadores", "humanos", "."], "sentence-detokenized": "Una f\u00e1brica t\u00edpica contiene cientos de robots industriales que trabajan en l\u00edneas de producci\u00f3n totalmente automatizadas, con un robot por cada diez trabajadores humanos.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 27], [28, 35], [36, 38], [39, 45], [46, 58], [59, 62], [63, 71], [72, 74], [75, 81], [82, 84], [85, 95], [96, 106], [107, 120], [120, 121], [122, 125], [126, 128], [129, 134], [135, 138], [139, 143], [144, 148], [149, 161], [162, 169], [169, 170]]}
{"doc_key": "ai-train-83", "ner": [[5, 7, "product"], [16, 19, "field"], [24, 26, "task"], [28, 30, "task"], [32, 34, "task"], [36, 38, "task"], [40, 42, "task"], [44, 46, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[16, 19, 5, 7, "usage", "", false, true], [24, 26, 16, 19, "part-of", "", false, false], [28, 30, 16, 19, "part-of", "", false, false], [32, 34, 16, 19, "part-of", "", false, false], [36, 38, 16, 19, "part-of", "", false, false], [40, 42, 16, 19, "part-of", "", false, false], [44, 46, 16, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["En", "la", "\u00faltima", "d\u00e9cada", ",", "las", "PCNN", "se", "han", "utilizado", "en", "una", "gran", "variedad", "de", "aplicaciones", "de", "procesamiento", "de", "im\u00e1genes", ",", "entre", "ellas", ":", "segmentaci\u00f3n", "de", "im\u00e1genes", ",", "generaci\u00f3n", "de", "caracter\u00edsticas", ",", "extracci\u00f3n", "de", "rostros", ",", "detecci\u00f3n", "de", "movimiento", ",", "crecimiento", "de", "regiones", "y", "reducci\u00f3n", "de", "ruido", "."], "sentence-detokenized": "En la \u00faltima d\u00e9cada, las PCNN se han utilizado en una gran variedad de aplicaciones de procesamiento de im\u00e1genes, entre ellas: segmentaci\u00f3n de im\u00e1genes, generaci\u00f3n de caracter\u00edsticas, extracci\u00f3n de rostros, detecci\u00f3n de movimiento, crecimiento de regiones y reducci\u00f3n de ruido.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 19], [19, 20], [21, 24], [25, 29], [30, 32], [33, 36], [37, 46], [47, 49], [50, 53], [54, 58], [59, 67], [68, 70], [71, 83], [84, 86], [87, 100], [101, 103], [104, 112], [112, 113], [114, 119], [120, 125], [125, 126], [127, 139], [140, 142], [143, 151], [151, 152], [153, 163], [164, 166], [167, 182], [182, 183], [184, 194], [195, 197], [198, 205], [205, 206], [207, 216], [217, 219], [220, 230], [230, 231], [232, 243], [244, 246], [247, 255], [256, 257], [258, 267], [268, 270], [271, 276], [276, 277]]}
{"doc_key": "ai-train-84", "ner": [[0, 0, "researcher"], [18, 20, "field"], [25, 28, "misc"], [31, 38, "conference"], [40, 40, "conference"], [45, 48, "misc"], [51, 57, "conference"], [58, 59, "conference"], [61, 65, "conference"], [67, 67, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 0, 18, 20, "related-to", "contributes_to", false, false], [0, 0, 25, 28, "win-defeat", "", false, false], [0, 0, 45, 48, "win-defeat", "", false, false], [25, 28, 31, 38, "temporal", "", false, false], [40, 40, 31, 38, "named", "", false, false], [45, 48, 51, 57, "temporal", "", false, false], [45, 48, 61, 65, "temporal", "", false, false], [58, 59, 51, 57, "named", "", false, false], [67, 67, 61, 65, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Xu", "ha", "publicado", "m\u00e1s", "de", "50", "art\u00edculos", "en", "conferencias", "internacionales", "y", "en", "revistas", "en", "el", "campo", "de", "la", "visi\u00f3n", "por", "ordenador", "y", "ha", "ganado", "el", "premio", "al", "mejor", "art\u00edculo", "en", "la", "conferencia", "internacional", "sobre", "Renderizaci\u00f3n", "y", "Animaci\u00f3n", "No", "Fotorrealista", "(", "NPAR", ")", "2012", "y", "el", "premio", "al", "mejor", "revisor", "en", "las", "conferencias", "internacionales", "Asian", "Conference", "on", "Computer", "Vision", "ACCV", "2012", "e", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "2015", "."], "sentence-detokenized": "Xu ha publicado m\u00e1s de 50 art\u00edculos en conferencias internacionales y en revistas en el campo de la visi\u00f3n por ordenador y ha ganado el premio al mejor art\u00edculo en la conferencia internacional sobre Renderizaci\u00f3n y Animaci\u00f3n No Fotorrealista (NPAR) 2012 y el premio al mejor revisor en las conferencias internacionales Asian Conference on Computer Vision ACCV 2012 e International Conference on Computer Vision (ICCV) 2015.", "token2charspan": [[0, 2], [3, 5], [6, 15], [16, 19], [20, 22], [23, 25], [26, 35], [36, 38], [39, 51], [52, 67], [68, 69], [70, 72], [73, 81], [82, 84], [85, 87], [88, 93], [94, 96], [97, 99], [100, 106], [107, 110], [111, 120], [121, 122], [123, 125], [126, 132], [133, 135], [136, 142], [143, 145], [146, 151], [152, 160], [161, 163], [164, 166], [167, 178], [179, 192], [193, 198], [199, 212], [213, 214], [215, 224], [225, 227], [228, 241], [242, 243], [243, 247], [247, 248], [249, 253], [254, 255], [256, 258], [259, 265], [266, 268], [269, 274], [275, 282], [283, 285], [286, 289], [290, 302], [303, 318], [319, 324], [325, 335], [336, 338], [339, 347], [348, 354], [355, 359], [360, 364], [365, 366], [367, 380], [381, 391], [392, 394], [395, 403], [404, 410], [411, 412], [412, 416], [416, 417], [418, 422], [422, 423]]}
{"doc_key": "ai-train-85", "ner": [[0, 0, "programlang"], [2, 2, "field"], [4, 5, "field"], [8, 9, "misc"], [17, 18, "researcher"], [13, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 2, 2, "part-of", "", false, false], [0, 0, 4, 5, "part-of", "", false, false], [0, 0, 8, 9, "type-of", "", false, false], [13, 15, 0, 0, "usage", "", false, false], [13, 15, 17, 18, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["CycL", "en", "inform\u00e1tica", "e", "inteligencia", "artificial", "es", "un", "lenguaje", "ontol\u00f3gico", "utilizado", "por", "el", "proyecto", "Cyc", "artificial", "de", "Doug", "Lenat", "."], "sentence-detokenized": "CycL en inform\u00e1tica e inteligencia artificial es un lenguaje ontol\u00f3gico utilizado por el proyecto Cyc artificial de Doug Lenat.", "token2charspan": [[0, 4], [5, 7], [8, 19], [20, 21], [22, 34], [35, 45], [46, 48], [49, 51], [52, 60], [61, 71], [72, 81], [82, 85], [86, 88], [89, 97], [98, 101], [102, 112], [113, 115], [116, 120], [121, 126], [126, 127]]}
{"doc_key": "ai-train-86", "ner": [[3, 5, "task"], [8, 10, "metrics"], [19, 19, "metrics"], [21, 27, "metrics"], [36, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 10, 3, 5, "part-of", "", false, false], [19, 19, 8, 10, "named", "", false, false], [21, 27, 8, 10, "named", "", false, false], [36, 37, 8, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Tambi\u00e9n", "en", "el", "an\u00e1lisis", "de", "regresi\u00f3n", ",", "el", "error", "cuadr\u00e1tico", "medio", ",", "a", "menudo", "denominado", "error", "cuadr\u00e1tico", "medio", "de", "predicci\u00f3n", "o", "error", "cuadr\u00e1tico", "medio", "fuera", "de", "la", "muestra", ",", "puede", "referirse", "al", "valor", "medio", "de", "las", "desviaciones", "cuadr\u00e1ticas", "de", "las", "predicciones", "de", "los", "valores", "VERDADEROS", ",", "sobre", "un", "espacio", "de", "prueba", "fuera", "de", "la", "muestra", ",", "generado", "por", "un", "modelo", "estimado", "sobre", "un", "espacio", "de", "muestra", "particular", "."], "sentence-detokenized": "Tambi\u00e9n en el an\u00e1lisis de regresi\u00f3n, el error cuadr\u00e1tico medio, a menudo denominado error cuadr\u00e1tico medio de predicci\u00f3n o error cuadr\u00e1tico medio fuera de la muestra, puede referirse al valor medio de las desviaciones cuadr\u00e1ticas de las predicciones de los valores VERDADEROS, sobre un espacio de prueba fuera de la muestra, generado por un modelo estimado sobre un espacio de muestra particular.", "token2charspan": [[0, 7], [8, 10], [11, 13], [14, 22], [23, 25], [26, 35], [35, 36], [37, 39], [40, 45], [46, 56], [57, 62], [62, 63], [64, 65], [66, 72], [73, 83], [84, 89], [90, 100], [101, 106], [107, 109], [110, 120], [121, 122], [123, 128], [129, 139], [140, 145], [146, 151], [152, 154], [155, 157], [158, 165], [165, 166], [167, 172], [173, 182], [183, 185], [186, 191], [192, 197], [198, 200], [201, 204], [205, 217], [218, 229], [230, 232], [233, 236], [237, 249], [250, 252], [253, 256], [257, 264], [265, 275], [275, 276], [277, 282], [283, 285], [286, 293], [294, 296], [297, 303], [304, 309], [310, 312], [313, 315], [316, 323], [323, 324], [325, 333], [334, 337], [338, 340], [341, 347], [348, 356], [357, 362], [363, 365], [366, 373], [374, 376], [377, 384], [385, 395], [395, 396]]}
{"doc_key": "ai-train-87", "ner": [[10, 10, "algorithm"], [12, 12, "algorithm"], [7, 22, "algorithm"], [34, 36, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 10, 12, 12, "compare", "", false, false], [10, 10, 7, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["En", "cuanto", "a", "los", "resultados", ",", "los", "descriptores", "de", "bloque", "C-HOG", "y", "R-HOG", "se", "comportan", "de", "forma", "comparable", ",", "manteniendo", "los", "descriptores", "C-HOG", "una", "ligera", "ventaja", "en", "la", "tasa", "de", "fallos", "de", "detecci\u00f3n", "con", "tasas", "positivas", "falsas", "fijas", "en", "ambos", "conjuntos", "de", "datos", "."], "sentence-detokenized": "En cuanto a los resultados, los descriptores de bloque C-HOG y R-HOG se comportan de forma comparable, manteniendo los descriptores C-HOG una ligera ventaja en la tasa de fallos de detecci\u00f3n con tasas positivas falsas fijas en ambos conjuntos de datos.", "token2charspan": [[0, 2], [3, 9], [10, 11], [12, 15], [16, 26], [26, 27], [28, 31], [32, 44], [45, 47], [48, 54], [55, 60], [61, 62], [63, 68], [69, 71], [72, 81], [82, 84], [85, 90], [91, 101], [101, 102], [103, 114], [115, 118], [119, 131], [132, 137], [138, 141], [142, 148], [149, 156], [157, 159], [160, 162], [163, 167], [168, 170], [171, 177], [178, 180], [181, 190], [191, 194], [195, 200], [201, 210], [211, 217], [218, 223], [224, 226], [227, 232], [233, 242], [243, 245], [246, 251], [251, 252]]}
{"doc_key": "ai-train-88", "ner": [[10, 13, "algorithm"], [18, 18, "misc"], [21, 23, "algorithm"], [25, 27, "algorithm"], [30, 31, "algorithm"], [34, 37, "algorithm"], [40, 43, "algorithm"], [46, 47, "misc"], [50, 53, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[10, 13, 18, 18, "usage", "", false, false], [21, 23, 46, 47, "usage", "", false, false], [25, 27, 46, 47, "usage", "", false, false], [30, 31, 46, 47, "usage", "", false, false], [34, 37, 46, 47, "usage", "", false, false], [40, 43, 46, 47, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Entre", "los", "algoritmos", "de", "reconocimiento", "m\u00e1s", "conocidos", "se", "encuentran", "el", "an\u00e1lisis", "de", "componentes", "principales", "mediante", "el", "uso", "de", "eigenfaces", ",", "el", "an\u00e1lisis", "discriminante", "lineal", ",", "el", "emparejamiento", "el\u00e1stico", "mediante", "el", "algoritmo", "Fisherface", ",", "el", "modelo", "de", "Markov", "oculto", ",", "el", "aprendizaje", "del", "subespacio", "multilineal", "mediante", "la", "representaci\u00f3n", "tensorial", "y", "el", "emparejamiento", "de", "enlaces", "din\u00e1micos", "motivado", "por", "las", "neuronas", "."], "sentence-detokenized": "Entre los algoritmos de reconocimiento m\u00e1s conocidos se encuentran el an\u00e1lisis de componentes principales mediante el uso de eigenfaces, el an\u00e1lisis discriminante lineal, el emparejamiento el\u00e1stico mediante el algoritmo Fisherface, el modelo de Markov oculto, el aprendizaje del subespacio multilineal mediante la representaci\u00f3n tensorial y el emparejamiento de enlaces din\u00e1micos motivado por las neuronas.", "token2charspan": [[0, 5], [6, 9], [10, 20], [21, 23], [24, 38], [39, 42], [43, 52], [53, 55], [56, 66], [67, 69], [70, 78], [79, 81], [82, 93], [94, 105], [106, 114], [115, 117], [118, 121], [122, 124], [125, 135], [135, 136], [137, 139], [140, 148], [149, 162], [163, 169], [169, 170], [171, 173], [174, 188], [189, 197], [198, 206], [207, 209], [210, 219], [220, 230], [230, 231], [232, 234], [235, 241], [242, 244], [245, 251], [252, 258], [258, 259], [260, 262], [263, 274], [275, 278], [279, 289], [290, 301], [302, 310], [311, 313], [314, 328], [329, 338], [339, 340], [341, 343], [344, 358], [359, 361], [362, 369], [370, 379], [380, 388], [389, 392], [393, 396], [397, 405], [405, 406]]}
{"doc_key": "ai-train-89", "ner": [[3, 10, "misc"], [22, 24, "location"], [40, 42, "location"], [55, 55, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 24, 3, 10, "temporal", "", false, false], [40, 42, 3, 10, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "partir", "del", "Festival", "Internacional", "de", "Cine", "de", "Toronto", "de", "2019", ",", "ahora", "se", "podr\u00e1", "restringir", "la", "proyecci\u00f3n", "de", "pel\u00edculas", "en", "el", "Scotiabank", "Theatre", "Toronto", "-una", "de", "las", "sedes", "principales", "del", "festival-", "y", "proyectarlas", "en", "otros", "lugares", "(", "como", "el", "TIFF", "Bell", "Lightbox", "y", "otros", "cines", "locales", ")", "si", "son", "distribuidas", "por", "un", "servicio", "como", "Netflix", "."], "sentence-detokenized": "A partir del Festival Internacional de Cine de Toronto de 2019, ahora se podr\u00e1 restringir la proyecci\u00f3n de pel\u00edculas en el Scotiabank Theatre Toronto -una de las sedes principales del festival- y proyectarlas en otros lugares (como el TIFF Bell Lightbox y otros cines locales) si son distribuidas por un servicio como Netflix.", "token2charspan": [[0, 1], [2, 8], [9, 12], [13, 21], [22, 35], [36, 38], [39, 43], [44, 46], [47, 54], [55, 57], [58, 62], [62, 63], [64, 69], [70, 72], [73, 78], [79, 89], [90, 92], [93, 103], [104, 106], [107, 116], [117, 119], [120, 122], [123, 133], [134, 141], [142, 149], [150, 154], [155, 157], [158, 161], [162, 167], [168, 179], [180, 183], [184, 193], [194, 195], [196, 208], [209, 211], [212, 217], [218, 225], [226, 227], [227, 231], [232, 234], [235, 239], [240, 244], [245, 253], [254, 255], [256, 261], [262, 267], [268, 275], [275, 276], [277, 279], [280, 283], [284, 296], [297, 300], [301, 303], [304, 312], [313, 317], [318, 325], [325, 326]]}
{"doc_key": "ai-train-90", "ner": [[0, 0, "organisation"], [5, 6, "researcher"], [2, 3, "organisation"], [15, 15, "researcher"], [25, 29, "product"], [48, 48, "researcher"], [43, 46, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 2, 3, "related-to", "purchases", false, false], [5, 6, 15, 15, "named", "same", false, false], [5, 6, 48, 48, "named", "same", false, false], [2, 3, 5, 6, "origin", "founded_by", false, false], [25, 29, 0, 0, "artifact", "", false, false], [43, 46, 48, 48, "artifact", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Unimation", "compr\u00f3", "Vicarm", "Inc.", "de", "Victor", "Scheinman", "en", "1977", "y", ",", "con", "la", "ayuda", "de", "\u00e9ste", ",", "la", "empresa", "cre\u00f3", "y", "empez\u00f3", "a", "producir", "la", "M\u00e1quina", "Universal", "Programable", "para", "Ensamblaje", ",", "un", "nuevo", "modelo", "de", "brazo", "rob\u00f3tico", ",", "y", "a", "utilizar", "el", "vanguardista", "lenguaje", "de", "programaci\u00f3n", "VAL", "de", "Scheinman", "."], "sentence-detokenized": "Unimation compr\u00f3 Vicarm Inc. de Victor Scheinman en 1977 y, con la ayuda de \u00e9ste, la empresa cre\u00f3 y empez\u00f3 a producir la M\u00e1quina Universal Programable para Ensamblaje, un nuevo modelo de brazo rob\u00f3tico, y a utilizar el vanguardista lenguaje de programaci\u00f3n VAL de Scheinman.", "token2charspan": [[0, 9], [10, 16], [17, 23], [24, 28], [29, 31], [32, 38], [39, 48], [49, 51], [52, 56], [57, 58], [58, 59], [60, 63], [64, 66], [67, 72], [73, 75], [76, 80], [80, 81], [82, 84], [85, 92], [93, 97], [98, 99], [100, 106], [107, 108], [109, 117], [118, 120], [121, 128], [129, 138], [139, 150], [151, 155], [156, 166], [166, 167], [168, 170], [171, 176], [177, 183], [184, 186], [187, 192], [193, 201], [201, 202], [203, 204], [205, 206], [207, 215], [216, 218], [219, 231], [232, 240], [241, 243], [244, 256], [257, 260], [261, 263], [264, 273], [273, 274]]}
{"doc_key": "ai-train-91", "ner": [[0, 0, "product"], [4, 5, "programlang"], [9, 10, "algorithm"], [13, 18, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 5, "general-affiliation", "", false, false], [0, 0, 9, 10, "origin", "implementation_of", false, false], [0, 0, 13, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["J48", "es", "una", "implementaci\u00f3n", "Java", "de", "c\u00f3digo", "abierto", "del", "algoritmo", "C4.5", "en", "la", "herramienta", "de", "miner\u00eda", "de", "datos", "Weka", "."], "sentence-detokenized": "J48 es una implementaci\u00f3n Java de c\u00f3digo abierto del algoritmo C4.5 en la herramienta de miner\u00eda de datos Weka.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 25], [26, 30], [31, 33], [34, 40], [41, 48], [49, 52], [53, 62], [63, 67], [68, 70], [71, 73], [74, 85], [86, 88], [89, 96], [97, 99], [100, 105], [106, 110], [110, 111]]}
{"doc_key": "ai-train-92", "ner": [[2, 4, "metrics"], [15, 16, "product"], [22, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 4, 15, 16, "win-defeat", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["El", "art\u00edculo", "sobre", "el", "SSIM", "de", "2004", "ha", "sido", "citado", "m\u00e1s", "de", "20.000", "veces", "seg\u00fan", "Google", "Scholar", ",", "y", "tambi\u00e9n", "recibi\u00f3", "el", "premio", "IEEE", "Signal", "Processing", "Society", "Sustained", "Impact", "Award", "de", "2016", ",", "que", "indica", "que", "un", "art\u00edculo", "tiene", "un", "impacto", "inusualmente", "alto", "durante", "al", "menos", "10", "a\u00f1os", "despu\u00e9s", "de", "su", "publicaci\u00f3n", "."], "sentence-detokenized": "El art\u00edculo sobre el SSIM de 2004 ha sido citado m\u00e1s de 20.000 veces seg\u00fan Google Scholar, y tambi\u00e9n recibi\u00f3 el premio IEEE Signal Processing Society Sustained Impact Award de 2016, que indica que un art\u00edculo tiene un impacto inusualmente alto durante al menos 10 a\u00f1os despu\u00e9s de su publicaci\u00f3n.", "token2charspan": [[0, 2], [3, 11], [12, 17], [18, 20], [21, 25], [26, 28], [29, 33], [34, 36], [37, 41], [42, 48], [49, 52], [53, 55], [56, 62], [63, 68], [69, 74], [75, 81], [82, 89], [89, 90], [91, 92], [93, 100], [101, 108], [109, 111], [112, 118], [119, 123], [124, 130], [131, 141], [142, 149], [150, 159], [160, 166], [167, 172], [173, 175], [176, 180], [180, 181], [182, 185], [186, 192], [193, 196], [197, 199], [200, 208], [209, 214], [215, 217], [218, 225], [226, 238], [239, 243], [244, 251], [252, 254], [255, 260], [261, 263], [264, 268], [269, 276], [277, 279], [280, 282], [283, 294], [294, 295]]}
{"doc_key": "ai-train-93", "ner": [[1, 3, "task"], [31, 32, "product"], [41, 43, "product"], [45, 45, "organisation"], [46, 46, "product"], [51, 51, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 3, 45, 45, "artifact", "", false, false], [31, 32, 1, 3, "related-to", "performs", false, false], [31, 32, 41, 43, "part-of", "", false, false], [45, 45, 51, 51, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["La", "s\u00edntesis", "de", "voz", "est\u00e1", "a", "punto", "de", "ser", "completamente", "indistinguible", "de", "la", "voz", "de", "un", "humano", "real", "con", "la", "presentaci\u00f3n", "en", "2016", "del", "software", "de", "edici\u00f3n", "y", "generaci\u00f3n", "de", "voz", "Adobe", "Voco", ",", "un", "prototipo", "programado", "para", "formar", "parte", "de", "Adobe", "Creative", "Suite", "y", "DeepMind", "WaveNet", ",", "un", "prototipo", "de", "Google", "."], "sentence-detokenized": "La s\u00edntesis de voz est\u00e1 a punto de ser completamente indistinguible de la voz de un humano real con la presentaci\u00f3n en 2016 del software de edici\u00f3n y generaci\u00f3n de voz Adobe Voco, un prototipo programado para formar parte de Adobe Creative Suite y DeepMind WaveNet, un prototipo de Google.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 18], [19, 23], [24, 25], [26, 31], [32, 34], [35, 38], [39, 52], [53, 67], [68, 70], [71, 73], [74, 77], [78, 80], [81, 83], [84, 90], [91, 95], [96, 99], [100, 102], [103, 115], [116, 118], [119, 123], [124, 127], [128, 136], [137, 139], [140, 147], [148, 149], [150, 160], [161, 163], [164, 167], [168, 173], [174, 178], [178, 179], [180, 182], [183, 192], [193, 203], [204, 208], [209, 215], [216, 221], [222, 224], [225, 230], [231, 239], [240, 245], [246, 247], [248, 256], [257, 264], [264, 265], [266, 268], [269, 278], [279, 281], [282, 288], [288, 289]]}
{"doc_key": "ai-train-94", "ner": [[0, 1, "researcher"], [5, 9, "organisation"], [14, 21, "organisation"], [26, 27, "conference"], [30, 36, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 9, "role", "", false, false], [0, 1, 14, 21, "role", "", false, false], [0, 1, 26, 27, "role", "", false, false], [0, 1, 30, 36, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Poggio", "es", "miembro", "honorario", "del", "Programa", "de", "Investigaci\u00f3n", "en", "Neurociencia", ",", "miembro", "de", "la", "Academia", "Americana", "de", "las", "Artes", "y", "las", "Ciencias", "y", "miembro", "fundador", "de", "la", "AAAI", "y", "del", "Instituto", "McGovern", "para", "la", "Investigaci\u00f3n", "del", "Cerebro", "."], "sentence-detokenized": "Poggio es miembro honorario del Programa de Investigaci\u00f3n en Neurociencia, miembro de la Academia Americana de las Artes y las Ciencias y miembro fundador de la AAAI y del Instituto McGovern para la Investigaci\u00f3n del Cerebro.", "token2charspan": [[0, 6], [7, 9], [10, 17], [18, 27], [28, 31], [32, 40], [41, 43], [44, 57], [58, 60], [61, 73], [73, 74], [75, 82], [83, 85], [86, 88], [89, 97], [98, 107], [108, 110], [111, 114], [115, 120], [121, 122], [123, 126], [127, 135], [136, 137], [138, 145], [146, 154], [155, 157], [158, 160], [161, 165], [166, 167], [168, 171], [172, 181], [182, 190], [191, 195], [196, 198], [199, 212], [213, 216], [217, 224], [224, 225]]}
{"doc_key": "ai-train-95", "ner": [[13, 13, "task"], [16, 18, "task"], [26, 28, "task"], [34, 34, "misc"], [33, 35, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 13, 26, 28, "cause-effect", "", false, false], [16, 18, 26, 28, "cause-effect", "", false, false], [33, 35, 26, 28, "topic", "", false, false], [33, 35, 34, 34, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["En", "la", "d\u00e9cada", "de", "los", "90", ",", "animados", "por", "los", "\u00e9xitos", "en", "el", "reconocimiento", "y", "la", "s\u00edntesis", "del", "habla", ",", "se", "empez\u00f3", "a", "investigar", "en", "la", "traducci\u00f3n", "del", "habla", "con", "el", "desarrollo", "del", "proyecto", "alem\u00e1n", "Verbmobil", "."], "sentence-detokenized": "En la d\u00e9cada de los 90, animados por los \u00e9xitos en el reconocimiento y la s\u00edntesis del habla, se empez\u00f3 a investigar en la traducci\u00f3n del habla con el desarrollo del proyecto alem\u00e1n Verbmobil.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 15], [16, 19], [20, 22], [22, 23], [24, 32], [33, 36], [37, 40], [41, 47], [48, 50], [51, 53], [54, 68], [69, 70], [71, 73], [74, 82], [83, 86], [87, 92], [92, 93], [94, 96], [97, 103], [104, 105], [106, 116], [117, 119], [120, 122], [123, 133], [134, 137], [138, 143], [144, 147], [148, 150], [151, 161], [162, 165], [166, 174], [175, 181], [182, 191], [191, 192]]}
{"doc_key": "ai-train-96", "ner": [[3, 4, "researcher"], [8, 9, "researcher"], [11, 12, "researcher"], [15, 17, "algorithm"], [21, 23, "algorithm"], [28, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 8, 9, "role", "", false, false], [15, 17, 3, 4, "origin", "", false, false], [15, 17, 8, 9, "origin", "", false, false], [15, 17, 11, 12, "origin", "", false, false], [15, 17, 28, 28, "part-of", "", false, false], [21, 23, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["En", "1999", ",", "Felix", "Gers", "y", "su", "asesor", "J\u00fcrgen", "Schmidhuber", "y", "Fred", "Cummins", "introdujeron", "la", "puerta", "del", "olvido", "(", "tambi\u00e9n", "llamada", "puerta", "de", "mantenimiento", ")", "en", "la", "arquitectura", "LSTM", ","], "sentence-detokenized": "En 1999, Felix Gers y su asesor J\u00fcrgen Schmidhuber y Fred Cummins introdujeron la puerta del olvido (tambi\u00e9n llamada puerta de mantenimiento) en la arquitectura LSTM,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 19], [20, 21], [22, 24], [25, 31], [32, 38], [39, 50], [51, 52], [53, 57], [58, 65], [66, 78], [79, 81], [82, 88], [89, 92], [93, 99], [100, 101], [101, 108], [109, 116], [117, 123], [124, 126], [127, 140], [140, 141], [142, 144], [145, 147], [148, 160], [161, 165], [165, 166]]}
{"doc_key": "ai-train-97", "ner": [[2, 5, "field"], [8, 11, "field"], [14, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 16, 2, 5, "part-of", "", false, false], [14, 16, 8, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["En", "el", "procesamiento", "de", "se\u00f1ales", "digitales", "y", "la", "teor\u00eda", "de", "la", "informaci\u00f3n", ",", "la", "funci\u00f3n", "sinc", "normalizada", "se", "define", "com\u00fanmente", "por"], "sentence-detokenized": "En el procesamiento de se\u00f1ales digitales y la teor\u00eda de la informaci\u00f3n, la funci\u00f3n sinc normalizada se define com\u00fanmente por", "token2charspan": [[0, 2], [3, 5], [6, 19], [20, 22], [23, 30], [31, 40], [41, 42], [43, 45], [46, 52], [53, 55], [56, 58], [59, 70], [70, 71], [72, 74], [75, 82], [83, 87], [88, 99], [100, 102], [103, 109], [110, 120], [121, 124]]}
{"doc_key": "ai-train-98", "ner": [[2, 3, "field"], [7, 8, "researcher"], [14, 17, "conference"], [20, 24, "organisation"], [26, 26, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 7, 8, "origin", "coined_term", false, false], [7, 8, 14, 17, "role", "", false, false], [7, 8, 20, 24, "role", "", false, false], [26, 26, 20, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["El", "t\u00e9rmino", "ling\u00fc\u00edstica", "computacional", "fue", "acu\u00f1ado", "por", "David", "Hays", ",", "miembro", "fundador", "de", "la", "Asociaci\u00f3n", "de", "Ling\u00fc\u00edstica", "Computacional", "y", "del", "Comit\u00e9", "Internacional", "de", "Ling\u00fc\u00edstica", "Computacional", "(", "ICCL", ")", "."], "sentence-detokenized": "El t\u00e9rmino ling\u00fc\u00edstica computacional fue acu\u00f1ado por David Hays, miembro fundador de la Asociaci\u00f3n de Ling\u00fc\u00edstica Computacional y del Comit\u00e9 Internacional de Ling\u00fc\u00edstica Computacional (ICCL).", "token2charspan": [[0, 2], [3, 10], [11, 22], [23, 36], [37, 40], [41, 48], [49, 52], [53, 58], [59, 63], [63, 64], [65, 72], [73, 81], [82, 84], [85, 87], [88, 98], [99, 101], [102, 113], [114, 127], [128, 129], [130, 133], [134, 140], [141, 154], [155, 157], [158, 169], [170, 183], [184, 185], [185, 189], [189, 190], [190, 191]]}
{"doc_key": "ai-train-99", "ner": [[12, 17, "misc"], [11, 11, "misc"], [37, 39, "metrics"], [41, 41, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[41, 41, 37, 39, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["59", ",", "pp", ".", "2547-2553", ",", "oct", ".", "2011", "En", "el", "DPD", "unidimensional", "basado", "en", "polinomios", "con", "memoria", "(", "o", "sin", "memoria", ")", ",", "para", "resolver", "los", "coeficientes", "de", "los", "polinomios", "del", "predistorador", "digital", "y", "minimizar", "el", "error", "cuadr\u00e1tico", "medio", "(", "MSE", ")", ",", "la", "salida", "distorsionada", "del", "sistema", "no", "lineal", "debe", "sobremuestrearse", "a", "una", "velocidad", "que", "permita", "capturar", "los", "productos", "no", "lineales", "del", "orden", "del", "predistorador", "digital", "."], "sentence-detokenized": "59, pp. 2547-2553, oct. 2011 En el DPD unidimensional basado en polinomios con memoria (o sin memoria), para resolver los coeficientes de los polinomios del predistorador digital y minimizar el error cuadr\u00e1tico medio (MSE), la salida distorsionada del sistema no lineal debe sobremuestrearse a una velocidad que permita capturar los productos no lineales del orden del predistorador digital.", "token2charspan": [[0, 2], [2, 3], [4, 6], [6, 7], [8, 17], [17, 18], [19, 22], [22, 23], [24, 28], [29, 31], [32, 34], [35, 38], [39, 53], [54, 60], [61, 63], [64, 74], [75, 78], [79, 86], [87, 88], [88, 89], [90, 93], [94, 101], [101, 102], [102, 103], [104, 108], [109, 117], [118, 121], [122, 134], [135, 137], [138, 141], [142, 152], [153, 156], [157, 170], [171, 178], [179, 180], [181, 190], [191, 193], [194, 199], [200, 210], [211, 216], [217, 218], [218, 221], [221, 222], [222, 223], [224, 226], [227, 233], [234, 247], [248, 251], [252, 259], [260, 262], [263, 269], [270, 274], [275, 291], [292, 293], [294, 297], [298, 307], [308, 311], [312, 319], [320, 328], [329, 332], [333, 342], [343, 345], [346, 354], [355, 358], [359, 364], [365, 368], [369, 382], [383, 390], [390, 391]]}
{"doc_key": "ai-train-100", "ner": [[0, 1, "researcher"], [13, 13, "location"], [15, 17, "location"], [19, 20, "country"], [24, 24, "location"], [26, 26, "country"], [40, 50, "organisation"], [54, 57, "organisation"], [60, 60, "location"], [65, 67, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 1, 13, 13, "physical", "", false, false], [0, 1, 54, 57, "physical", "", false, false], [0, 1, 65, 67, "role", "", false, false], [13, 13, 15, 17, "physical", "", false, false], [15, 17, 19, 20, "physical", "", false, false], [40, 50, 54, 57, "part-of", "", false, false], [54, 57, 60, 60, "physical", "", false, false], [65, 67, 40, 50, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Boris", "Katz", ",", "(", "nacido", "el", "5", "de", "octubre", "de", "1947", ",", "en", "Chi\u0219in\u0103u", ",", "R.S.S.", "de", "Moldavia", ",", "Uni\u00f3n", "Sovi\u00e9tica", ",", "(", "actualmente", "Chi\u0219in\u0103u", ",", "Moldavia", ")", ")", "es", "un", "investigador", "cient\u00edfico", "estadounidense", "principal", "(", "inform\u00e1tico", ")", "en", "el", "Laboratorio", "de", "Ciencias", "de", "la", "Computaci\u00f3n", "e", "Inteligencia", "Artificial", "del", "MIT", ",", "en", "el", "Instituto", "Tecnol\u00f3gico", "de", "Massachusetts", ",", "en", "Cambridge", ",", "y", "jefe", "del", "Grupo", "InfoLab", "del", "Laboratorio", "."], "sentence-detokenized": "Boris Katz, (nacido el 5 de octubre de 1947, en Chi\u0219in\u0103u, R.S.S. de Moldavia, Uni\u00f3n Sovi\u00e9tica, (actualmente Chi\u0219in\u0103u, Moldavia)) es un investigador cient\u00edfico estadounidense principal (inform\u00e1tico) en el Laboratorio de Ciencias de la Computaci\u00f3n e Inteligencia Artificial del MIT, en el Instituto Tecnol\u00f3gico de Massachusetts, en Cambridge, y jefe del Grupo InfoLab del Laboratorio.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 13], [13, 19], [20, 22], [23, 24], [25, 27], [28, 35], [36, 38], [39, 43], [43, 44], [45, 47], [48, 56], [56, 57], [58, 64], [65, 67], [68, 76], [76, 77], [78, 83], [84, 93], [93, 94], [95, 96], [96, 107], [108, 116], [116, 117], [118, 126], [126, 127], [127, 128], [129, 131], [132, 134], [135, 147], [148, 158], [159, 173], [174, 183], [184, 185], [185, 196], [196, 197], [198, 200], [201, 203], [204, 215], [216, 218], [219, 227], [228, 230], [231, 233], [234, 245], [246, 247], [248, 260], [261, 271], [272, 275], [276, 279], [279, 280], [281, 283], [284, 286], [287, 296], [297, 308], [309, 311], [312, 325], [325, 326], [327, 329], [330, 339], [339, 340], [341, 342], [343, 347], [348, 351], [352, 357], [358, 365], [366, 369], [370, 381], [381, 382]]}
