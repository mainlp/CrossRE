{"doc_key": "ai-test-1", "ner": [[6, 6, "algorithm"], [8, 8, "algorithm"], [11, 11, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Zu", "den", "typischen", "generativen", "Modellans\u00e4tzen", "geh\u00f6ren", "Naive-Bayes-Klassifikatoren", ",", "Gau\u00dfsche", "Mischmodelle", ",", "Variations-Auto-Encoder", "und", "andere", "."], "sentence-detokenized": "Zu den typischen generativen Modellans\u00e4tzen geh\u00f6ren Naive-Bayes-Klassifikatoren, Gau\u00dfsche Mischmodelle, Variations-Auto-Encoder und andere.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 28], [29, 43], [44, 51], [52, 79], [79, 80], [81, 89], [90, 102], [102, 103], [104, 127], [128, 131], [132, 138], [138, 139]]}
{"doc_key": "ai-test-2", "ner": [[2, 2, "organisation"], [9, 9, "conference"], [12, 17, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 9, 9, "role", "", false, false], [12, 17, 9, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Schlie\u00dflich", "organisiert", "ELRA", "alle", "zwei", "Jahre", "eine", "gro\u00dfe", "Konferenz", "LREC", ",", "die", "International", "Language", "Resources", "and", "Evaluation", "Conference", "."], "sentence-detokenized": "Schlie\u00dflich organisiert ELRA alle zwei Jahre eine gro\u00dfe Konferenz LREC, die International Language Resources and Evaluation Conference.", "token2charspan": [[0, 11], [12, 23], [24, 28], [29, 33], [34, 38], [39, 44], [45, 49], [50, 55], [56, 65], [66, 70], [70, 71], [72, 75], [76, 89], [90, 98], [99, 108], [109, 112], [113, 123], [124, 134], [134, 135]]}
{"doc_key": "ai-test-3", "ner": [[9, 9, "algorithm"], [13, 13, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Die", "Aufgabe", "besteht", "in", "der", "Regel", "darin", ",", "eine", "Maximum-Likelihood-Sch\u00e4tzung", "der", "Parameter", "des", "HMM", "aus", "den", "Ausgangssequenzen", "abzuleiten", "."], "sentence-detokenized": "Die Aufgabe besteht in der Regel darin, eine Maximum-Likelihood-Sch\u00e4tzung der Parameter des HMM aus den Ausgangssequenzen abzuleiten.", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 22], [23, 26], [27, 32], [33, 38], [38, 39], [40, 44], [45, 73], [74, 77], [78, 87], [88, 91], [92, 95], [96, 99], [100, 103], [104, 121], [122, 132], [132, 133]]}
{"doc_key": "ai-test-4", "ner": [[3, 3, "algorithm"], [6, 8, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Im", "Gegensatz", "zu", "neuronalen", "Netzen", "und", "Support", "Vector", "Machine", "werden", "beim", "AdaBoost-Trainingsprozess", "nur", "die", "Merkmale", "ausgew\u00e4hlt", ",", "von", "denen", "bekannt", "ist", ",", "dass", "sie", "die", "Vorhersagekraft", "des", "Modells", "verbessern", ",", "wodurch", "die", "Dimensionalit\u00e4t", "verringert", "und", "die", "Ausf\u00fchrungszeit", "potenziell", "verk\u00fcrzt", "wird", ",", "da", "irrelevante", "Merkmale", "nicht", "berechnet", "werden", "m\u00fcssen", "."], "sentence-detokenized": "Im Gegensatz zu neuronalen Netzen und Support Vector Machine werden beim AdaBoost-Trainingsprozess nur die Merkmale ausgew\u00e4hlt, von denen bekannt ist, dass sie die Vorhersagekraft des Modells verbessern, wodurch die Dimensionalit\u00e4t verringert und die Ausf\u00fchrungszeit potenziell verk\u00fcrzt wird, da irrelevante Merkmale nicht berechnet werden m\u00fcssen.", "token2charspan": [[0, 2], [3, 12], [13, 15], [16, 26], [27, 33], [34, 37], [38, 45], [46, 52], [53, 60], [61, 67], [68, 72], [73, 98], [99, 102], [103, 106], [107, 115], [116, 126], [126, 127], [128, 131], [132, 137], [138, 145], [146, 149], [149, 150], [151, 155], [156, 159], [160, 163], [164, 179], [180, 183], [184, 191], [192, 202], [202, 203], [204, 211], [212, 215], [216, 231], [232, 242], [243, 246], [247, 250], [251, 266], [267, 277], [278, 286], [287, 291], [291, 292], [293, 295], [296, 307], [308, 316], [317, 322], [323, 332], [333, 339], [340, 346], [346, 347]]}
{"doc_key": "ai-test-5", "ner": [[0, 0, "misc"], [9, 10, "misc"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 9, 10, "part-of", "", false, false], [9, 10, 12, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Troponymie", "ist", "eine", "der", "m\u00f6glichen", "Beziehungen", "zwischen", "Verben", "im", "semantischen", "Netz", "der", "WordNet-Datenbank", "."], "sentence-detokenized": "Troponymie ist eine der m\u00f6glichen Beziehungen zwischen Verben im semantischen Netz der WordNet-Datenbank.", "token2charspan": [[0, 10], [11, 14], [15, 19], [20, 23], [24, 33], [34, 45], [46, 54], [55, 61], [62, 64], [65, 77], [78, 82], [83, 86], [87, 104], [104, 105]]}
{"doc_key": "ai-test-6", "ner": [[8, 8, "task"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 8, 11, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Eine", "Rahmensprache", "ist", "eine", "Technologie", ",", "die", "zur", "Wissensdarstellung", "in", "der", "k\u00fcnstlichen", "Intelligenz", "verwendet", "wird", "."], "sentence-detokenized": "Eine Rahmensprache ist eine Technologie, die zur Wissensdarstellung in der k\u00fcnstlichen Intelligenz verwendet wird.", "token2charspan": [[0, 4], [5, 18], [19, 22], [23, 27], [28, 39], [39, 40], [41, 44], [45, 48], [49, 67], [68, 70], [71, 74], [75, 86], [87, 98], [99, 108], [109, 113], [113, 114]]}
{"doc_key": "ai-test-7", "ner": [[0, 0, "metrics"], [4, 6, "metrics"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 6, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "unterscheidet", "sich", "von", "Bilingual", "Evaluation", "Understudy", "auch", "in", "der", "Berechnung", "des", "Brevity", "Penalty", ",", "da", "kleine", "Abweichungen", "in", "der", "\u00dcbersetzungsl\u00e4nge", "sich", "nicht", "so", "stark", "auf", "die", "Gesamtbewertung", "auswirken", "."], "sentence-detokenized": "NIST unterscheidet sich von Bilingual Evaluation Understudy auch in der Berechnung des Brevity Penalty, da kleine Abweichungen in der \u00dcbersetzungsl\u00e4nge sich nicht so stark auf die Gesamtbewertung auswirken.", "token2charspan": [[0, 4], [5, 18], [19, 23], [24, 27], [28, 37], [38, 48], [49, 59], [60, 64], [65, 67], [68, 71], [72, 82], [83, 86], [87, 94], [95, 102], [102, 103], [104, 106], [107, 113], [114, 126], [127, 129], [130, 133], [134, 151], [152, 156], [157, 162], [163, 165], [166, 171], [172, 175], [176, 179], [180, 195], [196, 205], [205, 206]]}
{"doc_key": "ai-test-8", "ner": [[15, 16, "algorithm"], [19, 19, "algorithm"], [27, 27, "field"], [37, 37, "algorithm"], [40, 41, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 16, 27, 27, "usage", "", false, false], [19, 19, 27, 27, "usage", "", false, false], [37, 37, 27, 27, "type-of", "", false, false], [40, 41, 27, 27, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Das", "Modell", "wird", "zun\u00e4chst", "an", "einen", "Trainingsdatensatz", "angepasst", ".", "Das", "Modell", "(", "z.", "B.", "ein", "neuronales", "Netz", "oder", "ein", "Naive-Bayes-Klassifikator", ")", "wird", "anhand", "des", "Trainingsdatensatzes", "mit", "einer", "\u00fcberwachten", "Lernmethode", "trainiert", ",", "z.", "B.", "mit", "Optimierungsmethoden", "wie", "dem", "Gradientenabstieg", "oder", "dem", "stochastischen", "Gradientenabstieg", "."], "sentence-detokenized": "Das Modell wird zun\u00e4chst an einen Trainingsdatensatz angepasst. Das Modell (z. B. ein neuronales Netz oder ein Naive-Bayes-Klassifikator) wird anhand des Trainingsdatensatzes mit einer \u00fcberwachten Lernmethode trainiert, z. B. mit Optimierungsmethoden wie dem Gradientenabstieg oder dem stochastischen Gradientenabstieg.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 24], [25, 27], [28, 33], [34, 52], [53, 62], [62, 63], [64, 67], [68, 74], [75, 76], [76, 78], [79, 81], [82, 85], [86, 96], [97, 101], [102, 106], [107, 110], [111, 136], [136, 137], [138, 142], [143, 149], [150, 153], [154, 174], [175, 178], [179, 184], [185, 196], [197, 208], [209, 218], [218, 219], [220, 222], [223, 225], [226, 229], [230, 250], [251, 254], [255, 258], [259, 276], [277, 281], [282, 285], [286, 300], [301, 318], [318, 319]]}
{"doc_key": "ai-test-9", "ner": [[0, 0, "product"], [6, 8, "task"], [11, 11, "task"], [14, 16, "task"], [19, 19, "task"], [26, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 8, 0, 0, "usage", "", true, false], [11, 11, 0, 0, "usage", "", true, false], [14, 16, 0, 0, "usage", "", true, false], [19, 19, 0, 0, "usage", "", true, false], [26, 28, 0, 0, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["FrameNet", "wurde", "in", "Anwendungen", "wie", "der", "Beantwortung", "von", "Fragen", ",", "der", "Paraphrasierung", ",", "der", "Erkennung", "von", "Textverkn\u00fcpfungen", "und", "der", "Informationsextraktion", "entweder", "direkt", "oder", "mit", "Hilfe", "von", "Semantic", "Role", "Labeling", "Tools", "eingesetzt", "."], "sentence-detokenized": "FrameNet wurde in Anwendungen wie der Beantwortung von Fragen, der Paraphrasierung, der Erkennung von Textverkn\u00fcpfungen und der Informationsextraktion entweder direkt oder mit Hilfe von Semantic Role Labeling Tools eingesetzt.", "token2charspan": [[0, 8], [9, 14], [15, 17], [18, 29], [30, 33], [34, 37], [38, 50], [51, 54], [55, 61], [61, 62], [63, 66], [67, 82], [82, 83], [84, 87], [88, 97], [98, 101], [102, 119], [120, 123], [124, 127], [128, 150], [151, 159], [160, 166], [167, 171], [172, 175], [176, 181], [182, 185], [186, 194], [195, 199], [200, 208], [209, 214], [215, 225], [225, 226]]}
{"doc_key": "ai-test-10", "ner": [[8, 8, "misc"], [12, 12, "product"], [15, 15, "misc"], [19, 19, "product"], [22, 23, "field"], [27, 27, "product"], [30, 31, "misc"], [35, 35, "product"], [37, 37, "product"], [39, 39, "product"], [42, 43, "misc"], [47, 48, "product"], [50, 51, "product"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[12, 12, 8, 8, "general-affiliation", "", false, false], [19, 19, 15, 15, "general-affiliation", "", false, false], [27, 27, 22, 23, "general-affiliation", "", false, false], [35, 35, 30, 31, "type-of", "", false, false], [37, 37, 30, 31, "type-of", "", false, false], [39, 39, 30, 31, "type-of", "", false, false], [47, 48, 42, 43, "general-affiliation", "", false, false], [50, 51, 42, 43, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Dazu", "geh\u00f6ren", "Programme", "wie", "Datenanalyse-", "und", "Extraktionstools", ",", "Tabellenkalkulationen", "(", "z.", "B.", "Excel", ")", ",", "Datenbanken", "(", "z.", "B.", "Access", ")", ",", "statistische", "Analysen", "(", "z.", "B.", "SAS", ")", ",", "allgemeine", "Audit-Software", "(", "z.", "B.", "ACL", ",", "Arbutus", ",", "EAS", ")", ",", "Business", "Intelligence", "(", "z.", "B.", "Crystal", "Reports", "und", "Business", "Objects", ")", "usw."], "sentence-detokenized": "Dazu geh\u00f6ren Programme wie Datenanalyse- und Extraktionstools, Tabellenkalkulationen (z. B. Excel), Datenbanken (z. B. Access), statistische Analysen (z. B. SAS), allgemeine Audit-Software (z. B. ACL, Arbutus, EAS), Business Intelligence (z. B. Crystal Reports und Business Objects) usw.", "token2charspan": [[0, 4], [5, 12], [13, 22], [23, 26], [27, 40], [41, 44], [45, 61], [61, 62], [63, 84], [85, 86], [86, 88], [89, 91], [92, 97], [97, 98], [98, 99], [100, 111], [112, 113], [113, 115], [116, 118], [119, 125], [125, 126], [126, 127], [128, 140], [141, 149], [150, 151], [151, 153], [154, 156], [157, 160], [160, 161], [161, 162], [163, 173], [174, 188], [189, 190], [190, 192], [193, 195], [196, 199], [199, 200], [201, 208], [208, 209], [210, 213], [213, 214], [214, 215], [216, 224], [225, 237], [238, 239], [239, 241], [242, 244], [245, 252], [253, 260], [261, 264], [265, 273], [274, 281], [281, 282], [283, 287]]}
{"doc_key": "ai-test-11", "ner": [[0, 1, "organisation"], [5, 6, "researcher"], [11, 11, "organisation"], [16, 16, "product"], [25, 25, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 6, "origin", "", false, false], [5, 6, 11, 11, "role", "", false, false], [16, 16, 25, 25, "type-of", "", false, false], [25, 25, 5, 6, "origin", "introduced_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Rethink", "Robotics", "-", "gegr\u00fcndet", "von", "Rodney", "Brooks", ",", "der", "zuvor", "bei", "iRobot", "t\u00e4tig", "war", "-", "stellte", "Baxter", "im", "September", "2012", "vor", ".", "Baxter", "ist", "ein", "Industrieroboter", ",", "der", "f\u00fcr", "die", "sichere", "Interaktion", "mit", "benachbarten", "menschlichen", "Arbeitern", "konzipiert", "ist", "und", "f\u00fcr", "die", "Ausf\u00fchrung", "einfacher", "Aufgaben", "programmiert", "werden", "kann", "."], "sentence-detokenized": "Rethink Robotics - gegr\u00fcndet von Rodney Brooks, der zuvor bei iRobot t\u00e4tig war - stellte Baxter im September 2012 vor. Baxter ist ein Industrieroboter, der f\u00fcr die sichere Interaktion mit benachbarten menschlichen Arbeitern konzipiert ist und f\u00fcr die Ausf\u00fchrung einfacher Aufgaben programmiert werden kann.", "token2charspan": [[0, 7], [8, 16], [17, 18], [19, 28], [29, 32], [33, 39], [40, 46], [46, 47], [48, 51], [52, 57], [58, 61], [62, 68], [69, 74], [75, 78], [79, 80], [81, 88], [89, 95], [96, 98], [99, 108], [109, 113], [114, 117], [117, 118], [119, 125], [126, 129], [130, 133], [134, 150], [150, 151], [152, 155], [156, 159], [160, 163], [164, 171], [172, 183], [184, 187], [188, 200], [201, 213], [214, 223], [224, 234], [235, 238], [239, 242], [243, 246], [247, 250], [251, 261], [262, 271], [272, 280], [281, 293], [294, 300], [301, 305], [305, 306]]}
{"doc_key": "ai-test-12", "ner": [[3, 3, "task"], [5, 5, "task"], [7, 7, "task"], [9, 11, "task"], [13, 13, "task"], [15, 15, "task"], [17, 19, "task"], [28, 29, "task"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typische", "Textmining-Aufgaben", "sind", "Textkategorisierung", ",", "Textclustering", ",", "Konzept-/Entit\u00e4tsextraktion", ",", "Erstellung", "granularer", "Taxonomien", ",", "Stimmungsanalyse", ",", "Dokumentenzusammenfassung", "und", "Modellierung", "von", "Entit\u00e4tsbeziehungen", "(", "d.", "h", ".", "Lernen", "von", "Beziehungen", "zwischen", "benannten", "Entit\u00e4ten", ")", "."], "sentence-detokenized": "Typische Textmining-Aufgaben sind Textkategorisierung, Textclustering, Konzept-/Entit\u00e4tsextraktion, Erstellung granularer Taxonomien, Stimmungsanalyse, Dokumentenzusammenfassung und Modellierung von Entit\u00e4tsbeziehungen (d. h. Lernen von Beziehungen zwischen benannten Entit\u00e4ten).", "token2charspan": [[0, 8], [9, 28], [29, 33], [34, 53], [53, 54], [55, 69], [69, 70], [71, 98], [98, 99], [100, 110], [111, 121], [122, 132], [132, 133], [134, 150], [150, 151], [152, 177], [178, 181], [182, 194], [195, 198], [199, 218], [219, 220], [220, 222], [223, 224], [224, 225], [226, 232], [233, 236], [237, 248], [249, 257], [258, 267], [268, 277], [277, 278], [278, 279]]}
{"doc_key": "ai-test-13", "ner": [[8, 8, "metrics"], [11, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Dennoch", "verringert", "das", "Stemming", "bei", "solchen", "Systemen", "die", "Pr\u00e4zision", "bzw.", "die", "TRUE", "negative", "Rate", "."], "sentence-detokenized": "Dennoch verringert das Stemming bei solchen Systemen die Pr\u00e4zision bzw. die TRUE negative Rate.", "token2charspan": [[0, 7], [8, 18], [19, 22], [23, 31], [32, 35], [36, 43], [44, 52], [53, 56], [57, 66], [67, 71], [72, 75], [76, 80], [81, 89], [90, 94], [94, 95]]}
{"doc_key": "ai-test-14", "ner": [[3, 3, "task"], [8, 8, "misc"], [11, 11, "misc"], [21, 21, "product"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 8, 3, 3, "temporal", "", false, false], [11, 11, 8, 8, "named", "", false, false], [21, 21, 8, 8, "usage", "", false, false], [23, 23, 8, 8, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Ein", "Sonderfall", "des", "Keyword-Spotting", "ist", "die", "Erkennung", "von", "Wake-Words", "(", "auch", "Hot-Words", "genannt", ")", ",", "die", "von", "pers\u00f6nlichen", "digitalen", "Assistenten", "wie", "Alexa", "oder", "Siri", "verwendet", "werden", ",", "um", "aufzuwachen", ",", "wenn", "ihr", "Name", "gesprochen", "wird", "."], "sentence-detokenized": "Ein Sonderfall des Keyword-Spotting ist die Erkennung von Wake-Words (auch Hot-Words genannt), die von pers\u00f6nlichen digitalen Assistenten wie Alexa oder Siri verwendet werden, um aufzuwachen, wenn ihr Name gesprochen wird.", "token2charspan": [[0, 3], [4, 14], [15, 18], [19, 35], [36, 39], [40, 43], [44, 53], [54, 57], [58, 68], [69, 70], [70, 74], [75, 84], [85, 92], [92, 93], [93, 94], [95, 98], [99, 102], [103, 115], [116, 125], [126, 137], [138, 141], [142, 147], [148, 152], [153, 157], [158, 167], [168, 174], [174, 175], [176, 178], [179, 190], [190, 191], [192, 196], [197, 200], [201, 205], [206, 216], [217, 221], [221, 222]]}
{"doc_key": "ai-test-15", "ner": [[0, 0, "programlang"], [6, 6, "programlang"], [8, 8, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 0, 0, "part-of", "", false, false], [8, 8, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prova", "ist", "eine", "Open-Source-Programmiersprache", ",", "die", "Prolog", "mit", "Java", "kombiniert", "."], "sentence-detokenized": "Prova ist eine Open-Source-Programmiersprache, die Prolog mit Java kombiniert.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 45], [45, 46], [47, 50], [51, 57], [58, 61], [62, 66], [67, 77], [77, 78]]}
{"doc_key": "ai-test-16", "ner": [[2, 3, "organisation"], [8, 8, "organisation"], [24, 24, "product"], [33, 34, "country"], [23, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[2, 3, 8, 8, "part-of", "", false, false], [2, 3, 8, 8, "role", "sells", false, false], [2, 3, 33, 34, "role", "sells_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["1987", "wurde", "Tocibai", "Machine", ",", "eine", "Tochtergesellschaft", "von", "Toshiba", ",", "beschuldigt", ",", "unter", "Verletzung", "des", "CoCom-Abkommens", ",", "eines", "internationalen", "Embargos", "gegen", "bestimmte", "L\u00e4nder", ",", "CNC-Fr\u00e4steile", "zur", "Herstellung", "sehr", "leiser", "U-Boot-Propeller", "illegal", "an", "die", "Sowjetunion", "zu", "verkaufen", "."], "sentence-detokenized": "1987 wurde Tocibai Machine, eine Tochtergesellschaft von Toshiba, beschuldigt, unter Verletzung des CoCom-Abkommens, eines internationalen Embargos gegen bestimmte L\u00e4nder, CNC-Fr\u00e4steile zur Herstellung sehr leiser U-Boot-Propeller illegal an die Sowjetunion zu verkaufen.", "token2charspan": [[0, 4], [5, 10], [11, 18], [19, 26], [26, 27], [28, 32], [33, 52], [53, 56], [57, 64], [64, 65], [66, 77], [77, 78], [79, 84], [85, 95], [96, 99], [100, 115], [115, 116], [117, 122], [123, 138], [139, 147], [148, 153], [154, 163], [164, 170], [170, 171], [172, 185], [186, 189], [190, 201], [202, 206], [207, 213], [214, 230], [231, 238], [239, 241], [242, 245], [246, 257], [258, 260], [261, 270], [270, 271]]}
{"doc_key": "ai-test-17", "ner": [[0, 0, "researcher"], [5, 5, "product"], [15, 18, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 0, 0, "artifact", "", false, false], [5, 5, 15, 18, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Engelbergers", "ber\u00fchmteste", "Co-Erfindung", ",", "der", "Unimate-Industrieroboterarm", ",", "wurde", "2003", "als", "einer", "der", "ersten", "in", "die", "Robot", "Hall", "of", "Fame", "aufgenommen", "."], "sentence-detokenized": "Engelbergers ber\u00fchmteste Co-Erfindung, der Unimate-Industrieroboterarm, wurde 2003 als einer der ersten in die Robot Hall of Fame aufgenommen.", "token2charspan": [[0, 12], [13, 24], [25, 37], [37, 38], [39, 42], [43, 70], [70, 71], [72, 77], [78, 82], [83, 86], [87, 92], [93, 96], [97, 103], [104, 106], [107, 110], [111, 116], [117, 121], [122, 124], [125, 129], [130, 141], [141, 142]]}
{"doc_key": "ai-test-18", "ner": [[2, 2, "misc"], [5, 5, "misc"], [9, 9, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 5, 5, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Urspr\u00fcnglich", "\u00fcber", "statische", "HTML-Webseiten", "mit", "CGI", "gesteuert", ",", "f\u00fchrte", "Dalton", "eine", "Augmented-Reality-Schnittstelle", "auf", "Java-Basis", "ein", ",", "die", "nur", "begrenzt", "erfolgreich", "war", "."], "sentence-detokenized": "Urspr\u00fcnglich \u00fcber statische HTML-Webseiten mit CGI gesteuert, f\u00fchrte Dalton eine Augmented-Reality-Schnittstelle auf Java-Basis ein, die nur begrenzt erfolgreich war.", "token2charspan": [[0, 12], [13, 17], [18, 27], [28, 42], [43, 46], [47, 50], [51, 60], [60, 61], [62, 68], [69, 75], [76, 80], [81, 112], [113, 116], [117, 127], [128, 131], [131, 132], [133, 136], [137, 140], [141, 149], [150, 161], [162, 165], [165, 166]]}
{"doc_key": "ai-test-19", "ner": [[5, 5, "task"], [11, 11, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 11, 11, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Die", "erste", "Ver\u00f6ffentlichung", "\u00fcber", "die", "LMF-Spezifikation", ",", "wie", "sie", "von", "der", "ISO", "ratifiziert", "wurde", "(", "dieses", "Papier", "wurde", "(", "2015", ")", "das", "9.", "meistzitierte", "Papier", "innerhalb", "der", "LREC-Konferenzen", "von", "LREC-Papieren", ")", ":"], "sentence-detokenized": "Die erste Ver\u00f6ffentlichung \u00fcber die LMF-Spezifikation, wie sie von der ISO ratifiziert wurde (dieses Papier wurde (2015) das 9. meistzitierte Papier innerhalb der LREC-Konferenzen von LREC-Papieren):", "token2charspan": [[0, 3], [4, 9], [10, 26], [27, 31], [32, 35], [36, 53], [53, 54], [55, 58], [59, 62], [63, 66], [67, 70], [71, 74], [75, 86], [87, 92], [93, 94], [94, 100], [101, 107], [108, 113], [114, 115], [115, 119], [119, 120], [121, 124], [125, 127], [128, 141], [142, 148], [149, 158], [159, 162], [163, 179], [180, 183], [184, 197], [197, 198], [198, 199]]}
{"doc_key": "ai-test-20", "ner": [[1, 1, "metrics"], [11, 11, "metrics"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 1, 1, "usage", "", false, false], [11, 11, 13, 14, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Eine", "Konfusionsmatrix", "oder", "Matching-Matrix", "wird", "h\u00e4ufig", "als", "Instrument", "zur", "\u00dcberpr\u00fcfung", "der", "Genauigkeit", "der", "k", "-NN-Klassifikation", "verwendet", "."], "sentence-detokenized": "Eine Konfusionsmatrix oder Matching-Matrix wird h\u00e4ufig als Instrument zur \u00dcberpr\u00fcfung der Genauigkeit der k -NN-Klassifikation verwendet.", "token2charspan": [[0, 4], [5, 21], [22, 26], [27, 42], [43, 47], [48, 54], [55, 58], [59, 69], [70, 73], [74, 85], [86, 89], [90, 101], [102, 105], [106, 107], [108, 126], [127, 136], [136, 137]]}
{"doc_key": "ai-test-21", "ner": [[3, 4, "algorithm"], [14, 14, "field"], [16, 17, "field"], [19, 20, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 14, 14, "part-of", "", false, false], [3, 4, 16, 17, "part-of", "", false, false], [3, 4, 19, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Das", "Lernen", "von", "Entscheidungsb\u00e4umen", "geh\u00f6rt", "zu", "den", "pr\u00e4diktiven", "Modellierungsans\u00e4tzen", ",", "die", "in", "den", "Bereichen", "Statistik", ",", "Data", "Mining", "und", "maschinelles", "Lernen", "verwendet", "werden", "."], "sentence-detokenized": "Das Lernen von Entscheidungsb\u00e4umen geh\u00f6rt zu den pr\u00e4diktiven Modellierungsans\u00e4tzen, die in den Bereichen Statistik, Data Mining und maschinelles Lernen verwendet werden.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 34], [35, 41], [42, 44], [45, 48], [49, 60], [61, 82], [82, 83], [84, 87], [88, 90], [91, 94], [95, 104], [105, 114], [114, 115], [116, 120], [121, 127], [128, 131], [132, 144], [145, 151], [152, 161], [162, 168], [168, 169]]}
{"doc_key": "ai-test-22", "ner": [[4, 5, "misc"], [12, 14, "algorithm"], [16, 16, "algorithm"]], "ner_mapping_to_source": [0, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Zur", "Laufzeit", "wird", "die", "Zielpersodie", "eines", "Satzes", "mit", "Hilfe", "von", "Signalverarbeitungstechniken", "wie", "linearer", "pr\u00e4diktiver", "Kodierung", "und", "PSOLA", "\u00fcber", "diese", "minimalen", "Einheiten", "gelegt", "."], "sentence-detokenized": "Zur Laufzeit wird die Zielpersodie eines Satzes mit Hilfe von Signalverarbeitungstechniken wie linearer pr\u00e4diktiver Kodierung und PSOLA \u00fcber diese minimalen Einheiten gelegt.", "token2charspan": [[0, 3], [4, 12], [13, 17], [18, 21], [22, 34], [35, 40], [41, 47], [48, 51], [52, 57], [58, 61], [62, 90], [91, 94], [95, 103], [104, 115], [116, 125], [126, 129], [130, 135], [136, 140], [141, 146], [147, 156], [157, 166], [167, 173], [173, 174]]}
{"doc_key": "ai-test-23", "ner": [[4, 5, "field"], [7, 8, "field"], [21, 22, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[21, 22, 4, 5, "usage", "", true, false], [21, 22, 7, 8, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Bei", "diesem", "Ansatz", "wurden", "k\u00fcnstliche", "Intelligenz", "und", "maschinelles", "Lernen", "eingesetzt", ",", "um", "den", "Forschern", "einen", "sichtbaren", "Vergleich", "zwischen", "herk\u00f6mmlichen", "und", "thermischen", "Gesichtsbildern", "zu", "erm\u00f6glichen", "."], "sentence-detokenized": "Bei diesem Ansatz wurden k\u00fcnstliche Intelligenz und maschinelles Lernen eingesetzt, um den Forschern einen sichtbaren Vergleich zwischen herk\u00f6mmlichen und thermischen Gesichtsbildern zu erm\u00f6glichen.", "token2charspan": [[0, 3], [4, 10], [11, 17], [18, 24], [25, 35], [36, 47], [48, 51], [52, 64], [65, 71], [72, 82], [82, 83], [84, 86], [87, 90], [91, 100], [101, 106], [107, 117], [118, 127], [128, 136], [137, 150], [151, 154], [155, 166], [167, 182], [183, 185], [186, 197], [197, 198]]}
{"doc_key": "ai-test-24", "ner": [[2, 2, "field"], [5, 6, "algorithm"], [12, 13, "task"], [18, 19, "misc"], [27, 28, "field"], [31, 32, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 6, 2, 2, "part-of", "", false, false], [5, 6, 12, 13, "topic", "", false, false], [12, 13, 18, 19, "origin", "", false, false], [27, 28, 2, 2, "part-of", "", false, false], [27, 28, 5, 6, "topic", "", false, false], [31, 32, 2, 2, "part-of", "", false, false], [31, 32, 5, 6, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "der", "Informatik", "ist", "die", "evolution\u00e4re", "Berechnung", "eine", "Familie", "von", "Algorithmen", "zur", "globalen", "Optimierung", ",", "die", "von", "der", "biologischen", "Evolution", "inspiriert", "ist", ",", "und", "das", "Teilgebiet", "der", "k\u00fcnstlichen", "Intelligenz", "und", "des", "Soft", "Computing", ",", "das", "diese", "Algorithmen", "untersucht", "."], "sentence-detokenized": "In der Informatik ist die evolution\u00e4re Berechnung eine Familie von Algorithmen zur globalen Optimierung, die von der biologischen Evolution inspiriert ist, und das Teilgebiet der k\u00fcnstlichen Intelligenz und des Soft Computing, das diese Algorithmen untersucht.", "token2charspan": [[0, 2], [3, 6], [7, 17], [18, 21], [22, 25], [26, 38], [39, 49], [50, 54], [55, 62], [63, 66], [67, 78], [79, 82], [83, 91], [92, 103], [103, 104], [105, 108], [109, 112], [113, 116], [117, 129], [130, 139], [140, 150], [151, 154], [154, 155], [156, 159], [160, 163], [164, 174], [175, 178], [179, 190], [191, 202], [203, 206], [207, 210], [211, 215], [216, 225], [225, 226], [227, 230], [231, 236], [237, 248], [249, 259], [259, 260]]}
{"doc_key": "ai-test-25", "ner": [[7, 7, "metrics"], [12, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["So", "kann", "man", "beispielsweise", "ein", "auf", "der", "Konfusionsmatrix", "basierendes", "Ma\u00df", "mit", "dem", "mittleren", "quadratischen", "Fehler", "zwischen", "den", "Rohdaten", "des", "Modells", "und", "den", "tats\u00e4chlichen", "Werten", "kombinieren", "."], "sentence-detokenized": "So kann man beispielsweise ein auf der Konfusionsmatrix basierendes Ma\u00df mit dem mittleren quadratischen Fehler zwischen den Rohdaten des Modells und den tats\u00e4chlichen Werten kombinieren.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 26], [27, 30], [31, 34], [35, 38], [39, 55], [56, 67], [68, 71], [72, 75], [76, 79], [80, 89], [90, 103], [104, 110], [111, 119], [120, 123], [124, 132], [133, 136], [137, 144], [145, 148], [149, 152], [153, 166], [167, 173], [174, 185], [185, 186]]}
{"doc_key": "ai-test-26", "ner": [[10, 10, "product"], [6, 6, "researcher"], [14, 14, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 6, 6, "origin", "", false, false], [10, 10, 14, 14, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Die", "meisten", "sind", "Ergebnisse", "des", "von", "Mikolov", "et", "al.", "entwickelten", "word2vec-Modells", "oder", "Varianten", "von", "word2vec", "."], "sentence-detokenized": "Die meisten sind Ergebnisse des von Mikolov et al. entwickelten word2vec-Modells oder Varianten von word2vec.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 27], [28, 31], [32, 35], [36, 43], [44, 46], [47, 50], [51, 63], [64, 80], [81, 85], [86, 95], [96, 99], [100, 108], [108, 109]]}
{"doc_key": "ai-test-27", "ner": [[9, 9, "conference"], [12, 16, "conference"], [18, 18, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 18, 12, 16, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "dieser", "Zeit", "wurden", "insgesamt", "43", "Publikationen", "von", "der", "CVPR", "und", "der", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "anerkannt", "."], "sentence-detokenized": "In dieser Zeit wurden insgesamt 43 Publikationen von der CVPR und der International Conference on Computer Vision (ICCV) anerkannt.", "token2charspan": [[0, 2], [3, 9], [10, 14], [15, 21], [22, 31], [32, 34], [35, 48], [49, 52], [53, 56], [57, 61], [62, 65], [66, 69], [70, 83], [84, 94], [95, 97], [98, 106], [107, 113], [114, 115], [115, 119], [119, 120], [121, 130], [130, 131]]}
{"doc_key": "ai-test-28", "ner": [[1, 1, "product"], [14, 17, "field"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 14, 17, "general-affiliation", "platform_for_education_about", false, false], [24, 25, 1, 1, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Der", "AIBO", "hat", "sich", "als", "kosteng\u00fcnstige", "Plattform", "f\u00fcr", "die", "Ausbildung", "und", "Forschung", "im", "Bereich", "der", "k\u00fcnstlichen", "Intelligenz", "bew\u00e4hrt", ",", "da", "er", "einen", "Computer", ",", "Computer", "Vision", "und", "Artikulatoren", "in", "einem", "Paket", "integriert", ",", "das", "wesentlich", "billiger", "ist", "als", "herk\u00f6mmliche", "Forschungsroboter", "."], "sentence-detokenized": "Der AIBO hat sich als kosteng\u00fcnstige Plattform f\u00fcr die Ausbildung und Forschung im Bereich der k\u00fcnstlichen Intelligenz bew\u00e4hrt, da er einen Computer, Computer Vision und Artikulatoren in einem Paket integriert, das wesentlich billiger ist als herk\u00f6mmliche Forschungsroboter.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 17], [18, 21], [22, 36], [37, 46], [47, 50], [51, 54], [55, 65], [66, 69], [70, 79], [80, 82], [83, 90], [91, 94], [95, 106], [107, 118], [119, 126], [126, 127], [128, 130], [131, 133], [134, 139], [140, 148], [148, 149], [150, 158], [159, 165], [166, 169], [170, 183], [184, 186], [187, 192], [193, 198], [199, 209], [209, 210], [211, 214], [215, 225], [226, 234], [235, 238], [239, 242], [243, 255], [256, 273], [273, 274]]}
{"doc_key": "ai-test-29", "ner": [[5, 10, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sie", "war", "die", "Programmvorsitzende", "der", "International", "Conference", "on", "Computer", "Vision", "2021", "."], "sentence-detokenized": "Sie war die Programmvorsitzende der International Conference on Computer Vision 2021.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 31], [32, 35], [36, 49], [50, 60], [61, 63], [64, 72], [73, 79], [80, 84], [84, 85]]}
{"doc_key": "ai-test-30", "ner": [[1, 1, "researcher"], [5, 5, "organisation"], [19, 19, "organisation"], [26, 27, "organisation"], [32, 36, "product"], [38, 38, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 1, 5, 5, "role", "", false, false], [1, 1, 19, 19, "role", "", true, false], [19, 19, 26, 27, "role", "develops_with", false, false], [32, 36, 19, 19, "artifact", "", false, false], [38, 38, 32, 36, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Nachdem", "Scheinman", "ein", "Stipendium", "von", "Unimation", "f\u00fcr", "die", "Entwicklung", "seiner", "Entw\u00fcrfe", "erhalten", "hatte", ",", "verkaufte", "er", "diese", "Entw\u00fcrfe", "an", "Unimation", ",", "das", "sie", "mit", "Unterst\u00fctzung", "von", "General", "Motors", "weiterentwickelte", "und", "sp\u00e4ter", "als", "Programmable", "Universal", "Machine", "for", "Assembly", "(", "PUMA", ")", "auf", "den", "Markt", "brachte", "."], "sentence-detokenized": "Nachdem Scheinman ein Stipendium von Unimation f\u00fcr die Entwicklung seiner Entw\u00fcrfe erhalten hatte, verkaufte er diese Entw\u00fcrfe an Unimation, das sie mit Unterst\u00fctzung von General Motors weiterentwickelte und sp\u00e4ter als Programmable Universal Machine for Assembly (PUMA) auf den Markt brachte.", "token2charspan": [[0, 7], [8, 17], [18, 21], [22, 32], [33, 36], [37, 46], [47, 50], [51, 54], [55, 66], [67, 73], [74, 82], [83, 91], [92, 97], [97, 98], [99, 108], [109, 111], [112, 117], [118, 126], [127, 129], [130, 139], [139, 140], [141, 144], [145, 148], [149, 152], [153, 166], [167, 170], [171, 178], [179, 185], [186, 203], [204, 207], [208, 214], [215, 218], [219, 231], [232, 241], [242, 249], [250, 253], [254, 262], [263, 264], [264, 268], [268, 269], [270, 273], [274, 277], [278, 283], [284, 291], [291, 292]]}
{"doc_key": "ai-test-31", "ner": [[5, 5, "task"], [7, 8, "task"], [10, 10, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 5, 5, "general-affiliation", "works_with", false, false], [10, 10, 7, 8, "general-affiliation", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Einen", "\u00dcberblick", "\u00fcber", "Kalibrierungsmethoden", "f\u00fcr", "bin\u00e4re", "und", "mehrklassige", "Klassifizierungsaufgaben", "gibt", "Gebel", "(", "2009", ")"], "sentence-detokenized": "Einen \u00dcberblick \u00fcber Kalibrierungsmethoden f\u00fcr bin\u00e4re und mehrklassige Klassifizierungsaufgaben gibt Gebel (2009)", "token2charspan": [[0, 5], [6, 15], [16, 20], [21, 42], [43, 46], [47, 53], [54, 57], [58, 70], [71, 95], [96, 100], [101, 106], [107, 108], [108, 112], [112, 113]]}
{"doc_key": "ai-test-32", "ner": [[6, 7, "task"], [9, 9, "task"], [12, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Er", "befasst", "sich", "mit", "Bereichen", "wie", "optische", "Zeichenerkennung", "(", "OCR", ")", ",", "Sprachsynthese", ",", "Spracherkennungstechnologie", "und", "elektronische", "Tastaturinstrumente", "."], "sentence-detokenized": "Er befasst sich mit Bereichen wie optische Zeichenerkennung (OCR), Sprachsynthese, Spracherkennungstechnologie und elektronische Tastaturinstrumente.", "token2charspan": [[0, 2], [3, 10], [11, 15], [16, 19], [20, 29], [30, 33], [34, 42], [43, 59], [60, 61], [61, 64], [64, 65], [65, 66], [67, 81], [81, 82], [83, 110], [111, 114], [115, 128], [129, 148], [148, 149]]}
{"doc_key": "ai-test-33", "ner": [[7, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["F\u00fcr", "neuere", "und", "modernere", "Techniken", "kann", "das", "Kaldi-Toolkit", "verwendet", "werden", "."], "sentence-detokenized": "F\u00fcr neuere und modernere Techniken kann das Kaldi-Toolkit verwendet werden.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 24], [25, 34], [35, 39], [40, 43], [44, 57], [58, 67], [68, 74], [74, 75]]}
{"doc_key": "ai-test-34", "ner": [[0, 0, "researcher"], [5, 7, "organisation"], [12, 13, "organisation"], [18, 19, "organisation"], [22, 23, "researcher"], [26, 29, "organisation"], [34, 36, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 5, 7, "role", "", false, false], [0, 0, 12, 13, "role", "", false, false], [0, 0, 18, 19, "role", "", false, false], [0, 0, 26, 29, "role", "", false, false], [0, 0, 34, 36, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Johnson-Laird", "ist", "ein", "Fellow", "der", "American", "Philosophical", "Society", ",", "ein", "Fellow", "der", "Royal", "Society", ",", "ein", "Fellow", "der", "British", "Academy", ",", "ein", "William", "James", "Fellow", "der", "Association", "for", "Psychological", "Science", "und", "ein", "Fellow", "der", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Johnson-Laird ist ein Fellow der American Philosophical Society, ein Fellow der Royal Society, ein Fellow der British Academy, ein William James Fellow der Association for Psychological Science und ein Fellow der Cognitive Science Society.", "token2charspan": [[0, 13], [14, 17], [18, 21], [22, 28], [29, 32], [33, 41], [42, 55], [56, 63], [63, 64], [65, 68], [69, 75], [76, 79], [80, 85], [86, 93], [93, 94], [95, 98], [99, 105], [106, 109], [110, 117], [118, 125], [125, 126], [127, 130], [131, 138], [139, 144], [145, 151], [152, 155], [156, 167], [168, 171], [172, 185], [186, 193], [194, 197], [198, 201], [202, 208], [209, 212], [213, 222], [223, 230], [231, 238], [238, 239]]}
{"doc_key": "ai-test-35", "ner": [[2, 7, "conference"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 21, "algorithm"], [27, 28, "task"], [30, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 13, 2, 7, "physical", "", false, false], [12, 13, 2, 7, "temporal", "", false, false], [15, 16, 2, 7, "physical", "", false, false], [15, 16, 2, 7, "temporal", "", false, false], [18, 19, 2, 7, "physical", "", false, false], [18, 19, 2, 7, "temporal", "", false, false], [21, 21, 18, 19, "role", "extends", false, false], [27, 28, 18, 19, "role", "extends", false, false], [30, 30, 27, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Auf", "der", "IEEE", "International", "Conference", "on", "Image", "Processing", "im", "Jahr", "2010", "erweiterten", "Rui", "Hu", ",", "Mark", "Banard", "und", "John", "Collomosse", "den", "HOG-Deskriptor", "f\u00fcr", "den", "Einsatz", "in", "der", "skizzenbasierten", "Bildsuche", "(", "SBIR", ")", "."], "sentence-detokenized": "Auf der IEEE International Conference on Image Processing im Jahr 2010 erweiterten Rui Hu, Mark Banard und John Collomosse den HOG-Deskriptor f\u00fcr den Einsatz in der skizzenbasierten Bildsuche (SBIR).", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 26], [27, 37], [38, 40], [41, 46], [47, 57], [58, 60], [61, 65], [66, 70], [71, 82], [83, 86], [87, 89], [89, 90], [91, 95], [96, 102], [103, 106], [107, 111], [112, 122], [123, 126], [127, 141], [142, 145], [146, 149], [150, 157], [158, 160], [161, 164], [165, 181], [182, 191], [192, 193], [193, 197], [197, 198], [198, 199]]}
{"doc_key": "ai-test-36", "ner": [[0, 0, "metrics"], [6, 6, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["BLEU", "verwendet", "eine", "modifizierte", "Form", "der", "Pr\u00e4zision", ",", "um", "eine", "Kandidaten\u00fcbersetzung", "mit", "mehreren", "Referenz\u00fcbersetzungen", "zu", "vergleichen", "."], "sentence-detokenized": "BLEU verwendet eine modifizierte Form der Pr\u00e4zision, um eine Kandidaten\u00fcbersetzung mit mehreren Referenz\u00fcbersetzungen zu vergleichen.", "token2charspan": [[0, 4], [5, 14], [15, 19], [20, 32], [33, 37], [38, 41], [42, 51], [51, 52], [53, 55], [56, 60], [61, 82], [83, 86], [87, 95], [96, 117], [118, 120], [121, 132], [132, 133]]}
{"doc_key": "ai-test-37", "ner": [[32, 33, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["F\u00fcr", "den", "Fall", "eines", "allgemeinen", "Basisraums", "math", "(", "Y,\\", "mathcal", "{", "B}", ",\\", "nu", ")", "/", "math", "(", "d.h.", "eines", "Basisraums", ",", "der", "nicht", "abz\u00e4hlbar", "ist", ")", ",", "betrachtet", "man", "\u00fcblicherweise", "die", "relative", "Entropie", "."], "sentence-detokenized": "F\u00fcr den Fall eines allgemeinen Basisraums math (Y,\\ mathcal {B},\\ nu) / math (d.h. eines Basisraums, der nicht abz\u00e4hlbar ist), betrachtet man \u00fcblicherweise die relative Entropie.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 18], [19, 30], [31, 41], [42, 46], [47, 48], [48, 51], [52, 59], [60, 61], [61, 63], [63, 65], [66, 68], [68, 69], [70, 71], [72, 76], [77, 78], [78, 82], [83, 88], [89, 99], [99, 100], [101, 104], [105, 110], [111, 120], [121, 124], [124, 125], [125, 126], [127, 137], [138, 141], [142, 155], [156, 159], [160, 168], [169, 177], [177, 178]]}
{"doc_key": "ai-test-38", "ner": [[16, 18, "country"], [10, 12, "organisation"], [14, 14, "organisation"], [27, 28, "country"], [21, 22, "organisation"], [24, 24, "organisation"], [31, 33, "organisation"], [36, 36, "country"], [37, 42, "organisation"], [44, 44, "organisation"], [51, 51, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11], "relations": [[10, 12, 16, 18, "physical", "", false, false], [14, 14, 10, 12, "named", "", false, false], [21, 22, 27, 28, "physical", "", false, false], [24, 24, 21, 22, "named", "", false, false], [37, 42, 36, 36, "physical", "", false, false], [44, 44, 37, 42, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Im", "Oktober", "2011", "wurden", "die", "bereits", "bestehenden", "Partnerschaften", "mit", "dem", "National", "Park", "Service", "(", "NPS", ")", "der", "Vereinigten", "Staaten", ",", "dem", "Historic", "Scotland", "(", "HS", ")", "des", "Vereinigten", "K\u00f6nigreichs", ",", "dem", "World", "Monuments", "Fund", "und", "dem", "mexikanischen", "Instituto", "Nacional", "de", "Antropolog\u00eda", "y", "Historia", "(", "INAH", ")", "erheblich", "erweitert", ",", "so", "die", "CyArk-Website"], "sentence-detokenized": "Im Oktober 2011 wurden die bereits bestehenden Partnerschaften mit dem National Park Service (NPS) der Vereinigten Staaten, dem Historic Scotland (HS) des Vereinigten K\u00f6nigreichs, dem World Monuments Fund und dem mexikanischen Instituto Nacional de Antropolog\u00eda y Historia (INAH) erheblich erweitert, so die CyArk-Website", "token2charspan": [[0, 2], [3, 10], [11, 15], [16, 22], [23, 26], [27, 34], [35, 46], [47, 62], [63, 66], [67, 70], [71, 79], [80, 84], [85, 92], [93, 94], [94, 97], [97, 98], [99, 102], [103, 114], [115, 122], [122, 123], [124, 127], [128, 136], [137, 145], [146, 147], [147, 149], [149, 150], [151, 154], [155, 166], [167, 178], [178, 179], [180, 183], [184, 189], [190, 199], [200, 204], [205, 208], [209, 212], [213, 226], [227, 236], [237, 245], [246, 248], [249, 261], [262, 263], [264, 272], [273, 274], [274, 278], [278, 279], [280, 289], [290, 299], [299, 300], [301, 303], [304, 307], [308, 321]]}
{"doc_key": "ai-test-39", "ner": [[0, 0, "algorithm"], [8, 8, "product"], [10, 10, "product"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[0, 0, 8, 8, "part-of", "", false, false], [0, 0, 10, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Kernel-SVMs", "sind", "in", "vielen", "Machine-Learning-Toolkits", "verf\u00fcgbar", ",", "darunter", "LIBSVM", ",", "MATLAB", "und", "andere", "."], "sentence-detokenized": "Kernel-SVMs sind in vielen Machine-Learning-Toolkits verf\u00fcgbar, darunter LIBSVM, MATLAB und andere.", "token2charspan": [[0, 11], [12, 16], [17, 19], [20, 26], [27, 52], [53, 62], [62, 63], [64, 72], [73, 79], [79, 80], [81, 87], [88, 91], [92, 98], [98, 99]]}
{"doc_key": "ai-test-40", "ner": [[1, 4, "misc"], [12, 13, "location"], [15, 15, "location"], [16, 16, "country"], [22, 24, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 4, 12, 13, "physical", "", false, false], [1, 4, 22, 24, "temporal", "", false, false], [12, 13, 15, 15, "physical", "", false, false], [15, 15, 16, 16, "physical", "", false, false], [22, 24, 12, 13, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Der", "Wettbewerb", "um", "den", "Loebner-Preis", "2009", "fand", "am", "6.", "September", "2009", "im", "Brighton", "Centre", ",", "Brighton", "UK", ",", "in", "Verbindung", "mit", "der", "Konferenz", "Interspeech", "2009", "statt", "."], "sentence-detokenized": "Der Wettbewerb um den Loebner-Preis 2009 fand am 6. September 2009 im Brighton Centre, Brighton UK, in Verbindung mit der Konferenz Interspeech 2009 statt.", "token2charspan": [[0, 3], [4, 14], [15, 17], [18, 21], [22, 35], [36, 40], [41, 45], [46, 48], [49, 51], [52, 61], [62, 66], [67, 69], [70, 78], [79, 85], [85, 86], [87, 95], [96, 98], [98, 99], [100, 102], [103, 113], [114, 117], [118, 121], [122, 131], [132, 143], [144, 148], [149, 154], [154, 155]]}
{"doc_key": "ai-test-41", "ner": [[2, 2, "product"], [7, 7, "product"], [13, 13, "product"], [14, 14, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 14, 2, 2, "part-of", "", false, false], [14, 14, 7, 7, "part-of", "", false, false], [14, 14, 13, 13, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Der", "humanoide", "QRIO-Roboter", "wurde", "als", "Nachfolger", "von", "AIBO", "entwickelt", "und", "l\u00e4uft", "mit", "demselben", "R-CODE", "Aperios-Betriebssystem", "."], "sentence-detokenized": "Der humanoide QRIO-Roboter wurde als Nachfolger von AIBO entwickelt und l\u00e4uft mit demselben R-CODE Aperios-Betriebssystem.", "token2charspan": [[0, 3], [4, 13], [14, 26], [27, 32], [33, 36], [37, 47], [48, 51], [52, 56], [57, 67], [68, 71], [72, 77], [78, 81], [82, 91], [92, 98], [99, 121], [121, 122]]}
{"doc_key": "ai-test-42", "ner": [[1, 1, "misc"], [5, 5, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 1, 1, "cause-effect", "", true, false], [13, 14, 1, 1, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Die", "Sprachwellenformen", "werden", "aus", "den", "HMMs", "selbst", "auf", "der", "Grundlage", "des", "Kriteriums", "der", "maximalen", "Wahrscheinlichkeit", "erzeugt", "."], "sentence-detokenized": "Die Sprachwellenformen werden aus den HMMs selbst auf der Grundlage des Kriteriums der maximalen Wahrscheinlichkeit erzeugt.", "token2charspan": [[0, 3], [4, 22], [23, 29], [30, 33], [34, 37], [38, 42], [43, 49], [50, 53], [54, 57], [58, 67], [68, 71], [72, 82], [83, 86], [87, 96], [97, 115], [116, 123], [123, 124]]}
{"doc_key": "ai-test-43", "ner": [[0, 1, "product"], [5, 13, "task"], [11, 11, "task"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 5, 13, "type-of", "", false, false], [0, 1, 11, 11, "type-of", "", false, false], [0, 1, 17, 17, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Google", "Translate", "ist", "ein", "kostenloser", ",", "mehrsprachiger", "Dienst", "f\u00fcr", "statistische", "und", "neuronale", "maschinelle", "\u00dcbersetzung", ",", "der", "von", "Google", "entwickelt", "wurde", ",", "um", "Texte", "und", "Websites", "von", "einer", "Sprache", "in", "eine", "andere", "zu", "\u00fcbersetzen", "."], "sentence-detokenized": "Google Translate ist ein kostenloser, mehrsprachiger Dienst f\u00fcr statistische und neuronale maschinelle \u00dcbersetzung, der von Google entwickelt wurde, um Texte und Websites von einer Sprache in eine andere zu \u00fcbersetzen.", "token2charspan": [[0, 6], [7, 16], [17, 20], [21, 24], [25, 36], [36, 37], [38, 52], [53, 59], [60, 63], [64, 76], [77, 80], [81, 90], [91, 102], [103, 114], [114, 115], [116, 119], [120, 123], [124, 130], [131, 141], [142, 147], [147, 148], [149, 151], [152, 157], [158, 161], [162, 170], [171, 174], [175, 180], [181, 188], [189, 191], [192, 196], [197, 203], [204, 206], [207, 217], [217, 218]]}
{"doc_key": "ai-test-44", "ner": [[4, 5, "field"], [8, 8, "field"], [11, 11, "field"], [14, 15, "field"], [23, 24, "task"], [27, 29, "task"], [32, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[23, 24, 4, 5, "part-of", "", false, true], [23, 24, 8, 8, "part-of", "", false, true], [23, 24, 11, 11, "part-of", "", false, true], [27, 29, 4, 5, "part-of", "", false, true], [27, 29, 8, 8, "part-of", "", false, true], [27, 29, 11, 11, "part-of", "", false, true], [32, 36, 4, 5, "part-of", "", false, true], [32, 36, 8, 8, "part-of", "", false, true], [32, 36, 11, 11, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Skelette", "sind", "in", "der", "Computer", "Vision", ",", "der", "Bildanalyse", ",", "der", "Mustererkennung", "und", "der", "digitalen", "Bildverarbeitung", "weit", "verbreitet", ",", "z.", "B.", "f\u00fcr", "die", "optische", "Zeichenerkennung", ",", "die", "Erkennung", "von", "Fingerabdr\u00fccken", ",", "die", "visuelle", "Inspektion", "oder", "die", "Kompression", "."], "sentence-detokenized": "Skelette sind in der Computer Vision, der Bildanalyse, der Mustererkennung und der digitalen Bildverarbeitung weit verbreitet, z. B. f\u00fcr die optische Zeichenerkennung, die Erkennung von Fingerabdr\u00fccken, die visuelle Inspektion oder die Kompression.", "token2charspan": [[0, 8], [9, 13], [14, 16], [17, 20], [21, 29], [30, 36], [36, 37], [38, 41], [42, 53], [53, 54], [55, 58], [59, 74], [75, 78], [79, 82], [83, 92], [93, 109], [110, 114], [115, 125], [125, 126], [127, 129], [130, 132], [133, 136], [137, 140], [141, 149], [150, 166], [166, 167], [168, 171], [172, 181], [182, 185], [186, 201], [201, 202], [203, 206], [207, 215], [216, 226], [227, 231], [232, 235], [236, 247], [247, 248]]}
{"doc_key": "ai-test-45", "ner": [[1, 6, "conference"], [12, 16, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 6, 12, 16, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Die", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "ist", "ein", "Benchmark", "f\u00fcr", "die", "Klassifizierung", "und", "Erkennung", "von", "Objekten", ",", "mit", "Millionen", "von", "Bildern", "und", "Hunderten", "von", "Objektklassen", "."], "sentence-detokenized": "Die ImageNet Large Scale Visual Recognition Challenge ist ein Benchmark f\u00fcr die Klassifizierung und Erkennung von Objekten, mit Millionen von Bildern und Hunderten von Objektklassen.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 24], [25, 31], [32, 43], [44, 53], [54, 57], [58, 61], [62, 71], [72, 75], [76, 79], [80, 95], [96, 99], [100, 109], [110, 113], [114, 122], [122, 123], [124, 127], [128, 137], [138, 141], [142, 149], [150, 153], [154, 163], [164, 167], [168, 181], [181, 182]]}
{"doc_key": "ai-test-46", "ner": [[0, 1, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [12, 14, "misc"], [17, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 12, 14, "part-of", "", false, false], [0, 1, 17, 21, "part-of", "", false, false], [4, 5, 12, 14, "part-of", "", false, false], [4, 5, 17, 21, "part-of", "", false, false], [7, 8, 12, 14, "part-of", "", false, false], [7, 8, 17, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Bengio", "wird", "zusammen", "mit", "Geoffrey", "Hinton", "und", "Yann", "LeCun", "von", "einigen", "als", "Pate", "der", "KI", "und", "als", "Pate", "des", "Deep", "Learning", "bezeichnet", "."], "sentence-detokenized": "Bengio wird zusammen mit Geoffrey Hinton und Yann LeCun von einigen als Pate der KI und als Pate des Deep Learning bezeichnet.", "token2charspan": [[0, 6], [7, 11], [12, 20], [21, 24], [25, 33], [34, 40], [41, 44], [45, 49], [50, 55], [56, 59], [60, 67], [68, 71], [72, 76], [77, 80], [81, 83], [84, 87], [88, 91], [92, 96], [97, 100], [101, 105], [106, 114], [115, 125], [125, 126]]}
{"doc_key": "ai-test-47", "ner": [[6, 6, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Er", "ist", "ein", "Life", "Fellow", "des", "IEEE", "."], "sentence-detokenized": "Er ist ein Life Fellow des IEEE.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 15], [16, 22], [23, 26], [27, 31], [31, 32]]}
{"doc_key": "ai-test-48", "ner": [[0, 2, "organisation"], [12, 17, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 12, 17, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Die", "NSA", "Bethesda", "ist", "f\u00fcr", "die", "operative", "Unterst\u00fctzung", "ihres", "Hauptmieters", ",", "des", "Walter", "Reed", "National", "Military", "Medical", "Center", ",", "zust\u00e4ndig", "."], "sentence-detokenized": "Die NSA Bethesda ist f\u00fcr die operative Unterst\u00fctzung ihres Hauptmieters, des Walter Reed National Military Medical Center, zust\u00e4ndig.", "token2charspan": [[0, 3], [4, 7], [8, 16], [17, 20], [21, 24], [25, 28], [29, 38], [39, 52], [53, 58], [59, 71], [71, 72], [73, 76], [77, 83], [84, 88], [89, 97], [98, 106], [107, 114], [115, 121], [121, 122], [123, 132], [132, 133]]}
{"doc_key": "ai-test-49", "ner": [[6, 7, "field"], [10, 11, "field"], [14, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Die", "drei", "wichtigsten", "Lernparadigmen", "sind", "das", "\u00fcberwachte", "Lernen", ",", "das", "un\u00fcberwachte", "Lernen", "und", "das", "Verst\u00e4rkungslernen", "."], "sentence-detokenized": "Die drei wichtigsten Lernparadigmen sind das \u00fcberwachte Lernen, das un\u00fcberwachte Lernen und das Verst\u00e4rkungslernen.", "token2charspan": [[0, 3], [4, 8], [9, 20], [21, 35], [36, 40], [41, 44], [45, 55], [56, 62], [62, 63], [64, 67], [68, 80], [81, 87], [88, 91], [92, 95], [96, 114], [114, 115]]}
{"doc_key": "ai-test-50", "ner": [[3, 3, "task"], [5, 7, "task"], [10, 14, "task"], [16, 16, "task"], [18, 19, "task"], [21, 21, "task"], [23, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Beispiele", "hierf\u00fcr", "sind", "Steuerung", ",", "Planung", "und", "Terminierung", ",", "die", "Beantwortung", "von", "Diagnose-", "und", "Verbraucherfragen", ",", "Handschrifterkennung", ",", "nat\u00fcrliches", "Sprachverst\u00e4ndnis", ",", "Spracherkennung", "und", "Gesichtserkennung", "."], "sentence-detokenized": "Beispiele hierf\u00fcr sind Steuerung, Planung und Terminierung, die Beantwortung von Diagnose- und Verbraucherfragen, Handschrifterkennung, nat\u00fcrliches Sprachverst\u00e4ndnis, Spracherkennung und Gesichtserkennung.", "token2charspan": [[0, 9], [10, 17], [18, 22], [23, 32], [32, 33], [34, 41], [42, 45], [46, 58], [58, 59], [60, 63], [64, 76], [77, 80], [81, 90], [91, 94], [95, 112], [112, 113], [114, 134], [134, 135], [136, 147], [148, 165], [165, 166], [167, 182], [183, 186], [187, 204], [204, 205]]}
{"doc_key": "ai-test-51", "ner": [[8, 14, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Im", "Jahr", "1991", "wurde", "er", "zum", "Fellow", "der", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "gew\u00e4hlt", "(", "1990", ",", "Gr\u00fcndungsfellow", ")", "."], "sentence-detokenized": "Im Jahr 1991 wurde er zum Fellow der Association for the Advancement of Artificial Intelligence gew\u00e4hlt (1990, Gr\u00fcndungsfellow).", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 18], [19, 21], [22, 25], [26, 32], [33, 36], [37, 48], [49, 52], [53, 56], [57, 68], [69, 71], [72, 82], [83, 95], [96, 103], [104, 105], [105, 109], [109, 110], [111, 126], [126, 127], [127, 128]]}
{"doc_key": "ai-test-52", "ner": [[8, 8, "misc"], [13, 13, "algorithm"], [24, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Durch", "die", "Formulierung", "des", "Problems", "als", "L\u00f6sung", "einer", "Toeplitz-Matrix", "und", "die", "Verwendung", "der", "Levinson-Rekursion", "k\u00f6nnen", "wir", "jedoch", "relativ", "schnell", "einen", "Filter", "mit", "dem", "kleinstm\u00f6glichen", "mittleren", "quadratischen", "Fehler", "sch\u00e4tzen", "."], "sentence-detokenized": "Durch die Formulierung des Problems als L\u00f6sung einer Toeplitz-Matrix und die Verwendung der Levinson-Rekursion k\u00f6nnen wir jedoch relativ schnell einen Filter mit dem kleinstm\u00f6glichen mittleren quadratischen Fehler sch\u00e4tzen.", "token2charspan": [[0, 5], [6, 9], [10, 22], [23, 26], [27, 35], [36, 39], [40, 46], [47, 52], [53, 68], [69, 72], [73, 76], [77, 87], [88, 91], [92, 110], [111, 117], [118, 121], [122, 128], [129, 136], [137, 144], [145, 150], [151, 157], [158, 161], [162, 165], [166, 182], [183, 192], [193, 206], [207, 213], [214, 222], [222, 223]]}
{"doc_key": "ai-test-53", "ner": [[5, 10, "conference"], [13, 17, "location"], [19, 20, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 10, 13, 17, "physical", "", false, false], [13, 17, 19, 20, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Im", "Juli", "2011", "wird", "die", "15.", "Ausgabe", "der", "Campus", "Party", "Spanien", "in", "der", "Stadt", "der", "K\u00fcnste", "und", "Wissenschaften", "in", "Valencia", "stattfinden", "."], "sentence-detokenized": "Im Juli 2011 wird die 15. Ausgabe der Campus Party Spanien in der Stadt der K\u00fcnste und Wissenschaften in Valencia stattfinden.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 17], [18, 21], [22, 25], [26, 33], [34, 37], [38, 44], [45, 50], [51, 58], [59, 61], [62, 65], [66, 71], [72, 75], [76, 82], [83, 86], [87, 101], [102, 104], [105, 113], [114, 125], [125, 126]]}
{"doc_key": "ai-test-54", "ner": [[11, 11, "product"], [13, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Dies", "ist", "in", "der", "Regel", "nur", "am", "Ende", "komplizierter", "Spiele", "wie", "Schach", "oder", "Go", "m\u00f6glich", ",", "da", "es", "rechnerisch", "nicht", "m\u00f6glich", "ist", ",", "bis", "zum", "Ende", "des", "Spiels", "in", "die", "Zukunft", "zu", "blicken", ",", "es", "sei", "denn", "gegen", "Ende", ",", "und", "stattdessen", "werden", "die", "Positionen", "mit", "endlichen", "Werten", "versehen", ",", "die", "den", "Grad", "der", "\u00dcberzeugung", "angeben", ",", "dass", "sie", "zu", "einem", "Sieg", "f\u00fcr", "den", "einen", "oder", "anderen", "Spieler", "f\u00fchren", "werden", "."], "sentence-detokenized": "Dies ist in der Regel nur am Ende komplizierter Spiele wie Schach oder Go m\u00f6glich, da es rechnerisch nicht m\u00f6glich ist, bis zum Ende des Spiels in die Zukunft zu blicken, es sei denn gegen Ende, und stattdessen werden die Positionen mit endlichen Werten versehen, die den Grad der \u00dcberzeugung angeben, dass sie zu einem Sieg f\u00fcr den einen oder anderen Spieler f\u00fchren werden.", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 15], [16, 21], [22, 25], [26, 28], [29, 33], [34, 47], [48, 54], [55, 58], [59, 65], [66, 70], [71, 73], [74, 81], [81, 82], [83, 85], [86, 88], [89, 100], [101, 106], [107, 114], [115, 118], [118, 119], [120, 123], [124, 127], [128, 132], [133, 136], [137, 143], [144, 146], [147, 150], [151, 158], [159, 161], [162, 169], [169, 170], [171, 173], [174, 177], [178, 182], [183, 188], [189, 193], [193, 194], [195, 198], [199, 210], [211, 217], [218, 221], [222, 232], [233, 236], [237, 246], [247, 253], [254, 262], [262, 263], [264, 267], [268, 271], [272, 276], [277, 280], [281, 292], [293, 300], [300, 301], [302, 306], [307, 310], [311, 313], [314, 319], [320, 324], [325, 328], [329, 332], [333, 338], [339, 343], [344, 351], [352, 359], [360, 366], [367, 373], [373, 374]]}
{"doc_key": "ai-test-55", "ner": [[4, 43, "algorithm"], [19, 19, "algorithm"], [23, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[4, 43, 19, 19, "compare", "", false, false], [4, 43, 23, 24, "compare", "", false, false]], "relations_mapping_to_source": [0, 2], "sentence": ["Der", "Unterschied", "zwischen", "dem", "multinomialen", "Logit-Modell", "und", "zahlreichen", "anderen", "Methoden", ",", "Modellen", ",", "Algorithmen", "usw.", "mit", "demselben", "Grundaufbau", "(", "Perceptron-Algorithmus", ",", "Support-Vector-Machines", ",", "lineare", "Diskriminanzanalyse", "usw.", ")", "besteht", "darin", ",", "dass", "das", "Multinomial-Logit-Modell", "in", "der", "Lage", "ist", ",", "eine", "Vielzahl", "von", "Informationen", "zu", "liefern", "."], "sentence-detokenized": "Der Unterschied zwischen dem multinomialen Logit-Modell und zahlreichen anderen Methoden, Modellen, Algorithmen usw. mit demselben Grundaufbau (Perceptron-Algorithmus, Support-Vector-Machines, lineare Diskriminanzanalyse usw.) besteht darin, dass das Multinomial-Logit-Modell in der Lage ist, eine Vielzahl von Informationen zu liefern.", "token2charspan": [[0, 3], [4, 15], [16, 24], [25, 28], [29, 42], [43, 55], [56, 59], [60, 71], [72, 79], [80, 88], [88, 89], [90, 98], [98, 99], [100, 111], [112, 116], [117, 120], [121, 130], [131, 142], [143, 144], [144, 166], [166, 167], [168, 191], [191, 192], [193, 200], [201, 220], [221, 225], [225, 226], [227, 234], [235, 240], [240, 241], [242, 246], [247, 250], [251, 275], [276, 278], [279, 282], [283, 287], [288, 291], [291, 292], [293, 297], [298, 306], [307, 310], [311, 324], [325, 327], [328, 335], [335, 336]]}
{"doc_key": "ai-test-56", "ner": [[0, 3, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Association", "for", "Computational", "Linguistics", ",", "ver\u00f6ffentlicht", "von"], "sentence-detokenized": "Association for Computational Linguistics, ver\u00f6ffentlicht von", "token2charspan": [[0, 11], [12, 15], [16, 29], [30, 41], [41, 42], [43, 57], [58, 61]]}
{"doc_key": "ai-test-57", "ner": [[2, 2, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "computergest\u00fctzten", "Gesichtserkennungssystemen", "wird", "jedes", "Gesicht", "durch", "eine", "gro\u00dfe", "Anzahl", "von", "Pixelwerten", "dargestellt", "."], "sentence-detokenized": "In computergest\u00fctzten Gesichtserkennungssystemen wird jedes Gesicht durch eine gro\u00dfe Anzahl von Pixelwerten dargestellt.", "token2charspan": [[0, 2], [3, 21], [22, 48], [49, 53], [54, 59], [60, 67], [68, 73], [74, 78], [79, 84], [85, 91], [92, 95], [96, 107], [108, 119], [119, 120]]}
{"doc_key": "ai-test-58", "ner": [[6, 7, "person"], [12, 14, "organisation"], [17, 17, "country"], [24, 24, "person"], [35, 37, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 7, 12, 14, "role", "", false, false], [6, 7, 17, 17, "physical", "", false, false], [24, 24, 35, 37, "origin", "", false, false], [24, 24, 35, 37, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Im", "Jahr", "2002", "wurde", "sein", "Sohn", "Daniel", "Pearl", ",", "ein", "Journalist", "des", "Wall", "Street", "Journal", ",", "in", "Pakistan", "entf\u00fchrt", "und", "ermordet", ".", "Dies", "veranlasste", "Judea", "und", "die", "anderen", "Mitglieder", "der", "Familie", "und", "Freunde", ",", "die", "Daniel", "Pearl", "Foundation", "zu", "gr\u00fcnden", "."], "sentence-detokenized": "Im Jahr 2002 wurde sein Sohn Daniel Pearl, ein Journalist des Wall Street Journal, in Pakistan entf\u00fchrt und ermordet. Dies veranlasste Judea und die anderen Mitglieder der Familie und Freunde, die Daniel Pearl Foundation zu gr\u00fcnden.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 18], [19, 23], [24, 28], [29, 35], [36, 41], [41, 42], [43, 46], [47, 57], [58, 61], [62, 66], [67, 73], [74, 81], [81, 82], [83, 85], [86, 94], [95, 103], [104, 107], [108, 116], [116, 117], [118, 122], [123, 134], [135, 140], [141, 144], [145, 148], [149, 156], [157, 167], [168, 171], [172, 179], [180, 183], [184, 191], [191, 192], [193, 196], [197, 203], [204, 209], [210, 220], [221, 223], [224, 231], [231, 232]]}
{"doc_key": "ai-test-59", "ner": [[3, 5, "organisation"], [15, 16, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 5, 15, 16, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Ende", "2006", "expandierte", "Red", "Envelope", "Entertainment", "auch", "in", "die", "Produktion", "von", "Originalinhalten", "mit", "Filmemachern", "wie", "John", "Waters", "."], "sentence-detokenized": "Ende 2006 expandierte Red Envelope Entertainment auch in die Produktion von Originalinhalten mit Filmemachern wie John Waters.", "token2charspan": [[0, 4], [5, 9], [10, 21], [22, 25], [26, 34], [35, 48], [49, 53], [54, 56], [57, 60], [61, 71], [72, 75], [76, 92], [93, 96], [97, 109], [110, 113], [114, 118], [119, 125], [125, 126]]}
{"doc_key": "ai-test-60", "ner": [[6, 10, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Das", "Geb\u00e4ude", "ist", "heute", "Teil", "des", "Beth", "Israel", "Deaconess", "Medical", "Center", "."], "sentence-detokenized": "Das Geb\u00e4ude ist heute Teil des Beth Israel Deaconess Medical Center.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 21], [22, 26], [27, 30], [31, 35], [36, 42], [43, 52], [53, 60], [61, 67], [67, 68]]}
{"doc_key": "ai-test-61", "ner": [[14, 15, "field"], [18, 18, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ein", "gemeinsames", "Thema", "dieser", "Arbeit", "ist", "die", "Annahme", "einer", "zeichentheoretischen", "Perspektive", "auf", "Fragen", "der", "k\u00fcnstlichen", "Intelligenz", "und", "der", "Wissensdarstellung", "."], "sentence-detokenized": "Ein gemeinsames Thema dieser Arbeit ist die Annahme einer zeichentheoretischen Perspektive auf Fragen der k\u00fcnstlichen Intelligenz und der Wissensdarstellung.", "token2charspan": [[0, 3], [4, 15], [16, 21], [22, 28], [29, 35], [36, 39], [40, 43], [44, 51], [52, 57], [58, 78], [79, 90], [91, 94], [95, 101], [102, 105], [106, 117], [118, 129], [130, 133], [134, 137], [138, 156], [156, 157]]}
{"doc_key": "ai-test-62", "ner": [[2, 4, "task"], [6, 8, "task"], [20, 21, "task"], [32, 32, "task"], [34, 34, "task"], [39, 41, "task"], [43, 43, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 4, 20, 21, "type-of", "", false, false], [2, 4, 39, 41, "compare", "", false, false], [2, 4, 39, 41, "opposite", "", false, false], [6, 8, 2, 4, "named", "", false, false], [32, 32, 39, 41, "part-of", "", false, false], [34, 34, 39, 41, "part-of", "", false, false], [39, 41, 20, 21, "type-of", "", false, false], [43, 43, 39, 41, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Der", "Begriff", "neuronale", "maschinelle", "\u00dcbersetzung", "(", "NMT", ")", "beispielsweise", "unterstreicht", "die", "Tatsache", ",", "dass", "auf", "tiefem", "Lernen", "basierende", "Ans\u00e4tze", "zur", "maschinellen", "\u00dcbersetzung", "direkt", "Sequenz-zu-Sequenz-Transformationen", "erlernen", ",", "wodurch", "die", "Notwendigkeit", "von", "Zwischenschritten", "wie", "Wortalignment", "und", "Sprachmodellierung", ",", "die", "bei", "der", "statistischen", "maschinellen", "\u00dcbersetzung", "(", "SMT", ")", "verwendet", "wurden", ",", "entf\u00e4llt", "."], "sentence-detokenized": "Der Begriff neuronale maschinelle \u00dcbersetzung (NMT) beispielsweise unterstreicht die Tatsache, dass auf tiefem Lernen basierende Ans\u00e4tze zur maschinellen \u00dcbersetzung direkt Sequenz-zu-Sequenz-Transformationen erlernen, wodurch die Notwendigkeit von Zwischenschritten wie Wortalignment und Sprachmodellierung, die bei der statistischen maschinellen \u00dcbersetzung (SMT) verwendet wurden, entf\u00e4llt.", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 33], [34, 45], [46, 47], [47, 50], [50, 51], [52, 66], [67, 80], [81, 84], [85, 93], [93, 94], [95, 99], [100, 103], [104, 110], [111, 117], [118, 128], [129, 136], [137, 140], [141, 153], [154, 165], [166, 172], [173, 208], [209, 217], [217, 218], [219, 226], [227, 230], [231, 244], [245, 248], [249, 266], [267, 270], [271, 284], [285, 288], [289, 307], [307, 308], [309, 312], [313, 316], [317, 320], [321, 334], [335, 347], [348, 359], [360, 361], [361, 364], [364, 365], [366, 375], [376, 382], [382, 383], [384, 392], [392, 393]]}
{"doc_key": "ai-test-63", "ner": [[7, 7, "field"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 7, 12, 12, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Die", "meisten", "Forschungsarbeiten", "auf", "dem", "Gebiet", "der", "WSD", "werden", "unter", "Verwendung", "von", "WordNet", "als", "Referenz-Sinninventar", "durchgef\u00fchrt", "."], "sentence-detokenized": "Die meisten Forschungsarbeiten auf dem Gebiet der WSD werden unter Verwendung von WordNet als Referenz-Sinninventar durchgef\u00fchrt.", "token2charspan": [[0, 3], [4, 11], [12, 30], [31, 34], [35, 38], [39, 45], [46, 49], [50, 53], [54, 60], [61, 66], [67, 77], [78, 81], [82, 89], [90, 93], [94, 115], [116, 128], [128, 129]]}
{"doc_key": "ai-test-64", "ner": [[4, 4, "misc"], [10, 11, "researcher"], [13, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 4, 4, "general-affiliation", "", false, true], [13, 14, 4, 4, "general-affiliation", "", false, true]], "relations_mapping_to_source": [0, 1], "sentence": ["Zu", "den", "namhaften", "ehemaligen", "Doktoranden", "und", "Postdocs", "seiner", "Gruppe", "geh\u00f6ren", "Richard", "Zemel", "und", "Zoubin", "Ghahramani", "."], "sentence-detokenized": "Zu den namhaften ehemaligen Doktoranden und Postdocs seiner Gruppe geh\u00f6ren Richard Zemel und Zoubin Ghahramani.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 27], [28, 39], [40, 43], [44, 52], [53, 59], [60, 66], [67, 74], [75, 82], [83, 88], [89, 92], [93, 99], [100, 110], [110, 111]]}
{"doc_key": "ai-test-65", "ner": [[6, 6, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Jedes", "Vorhersageergebnis", "oder", "jede", "Instanz", "einer", "Konfusionsmatrix", "stellt", "einen", "Punkt", "im", "ROC-Raum", "dar", "."], "sentence-detokenized": "Jedes Vorhersageergebnis oder jede Instanz einer Konfusionsmatrix stellt einen Punkt im ROC-Raum dar.", "token2charspan": [[0, 5], [6, 24], [25, 29], [30, 34], [35, 42], [43, 48], [49, 65], [66, 72], [73, 78], [79, 84], [85, 87], [88, 96], [97, 100], [100, 101]]}
{"doc_key": "ai-test-66", "ner": [[2, 2, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [21, 22, "product"], [12, 14, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 12, 14, "physical", "", false, false], [6, 7, 12, 14, "physical", "", false, false], [9, 10, 12, 14, "physical", "", false, false], [21, 22, 2, 2, "artifact", "", false, false], [21, 22, 6, 7, "artifact", "", false, false], [21, 22, 9, 10, "artifact", "", false, false], [21, 22, 12, 14, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["1997", "entwickelten", "Thrun", "und", "seine", "Kollegen", "Wolfram", "Burgard", "und", "Dieter", "Fox", "im", "Deutschen", "Museum", "Bonn", "(", "1997", ")", "den", "weltweit", "ersten", "robotergest\u00fctzten", "Besucherf\u00fchrer", "."], "sentence-detokenized": "1997 entwickelten Thrun und seine Kollegen Wolfram Burgard und Dieter Fox im Deutschen Museum Bonn (1997) den weltweit ersten robotergest\u00fctzten Besucherf\u00fchrer.", "token2charspan": [[0, 4], [5, 17], [18, 23], [24, 27], [28, 33], [34, 42], [43, 50], [51, 58], [59, 62], [63, 69], [70, 73], [74, 76], [77, 86], [87, 93], [94, 98], [99, 100], [100, 104], [104, 105], [106, 109], [110, 118], [119, 125], [126, 143], [144, 158], [158, 159]]}
{"doc_key": "ai-test-67", "ner": [[0, 0, "product"], [6, 6, "misc"], [22, 24, "field"], [29, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 0, 0, "part-of", "", false, false], [22, 24, 0, 0, "usage", "", false, false], [29, 30, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["WordNet", "ist", "eine", "lexikalische", "Datenbank", "mit", "semantischen", "Beziehungen", "zwischen", "W\u00f6rtern", "in", "mehr", "als", "200", "Sprachen", ".", "Sie", "wird", "haupts\u00e4chlich", "f\u00fcr", "die", "automatische", "Verarbeitung", "nat\u00fcrlicher", "Sprache", "und", "f\u00fcr", "Anwendungen", "der", "k\u00fcnstlichen", "Intelligenz", "verwendet", "."], "sentence-detokenized": "WordNet ist eine lexikalische Datenbank mit semantischen Beziehungen zwischen W\u00f6rtern in mehr als 200 Sprachen. Sie wird haupts\u00e4chlich f\u00fcr die automatische Verarbeitung nat\u00fcrlicher Sprache und f\u00fcr Anwendungen der k\u00fcnstlichen Intelligenz verwendet.", "token2charspan": [[0, 7], [8, 11], [12, 16], [17, 29], [30, 39], [40, 43], [44, 56], [57, 68], [69, 77], [78, 85], [86, 88], [89, 93], [94, 97], [98, 101], [102, 110], [110, 111], [112, 115], [116, 120], [121, 134], [135, 138], [139, 142], [143, 155], [156, 168], [169, 180], [181, 188], [189, 192], [193, 196], [197, 208], [209, 212], [213, 224], [225, 236], [237, 246], [246, 247]]}
{"doc_key": "ai-test-68", "ner": [[4, 6, "field"], [12, 15, "conference"], [17, 25, "conference"], [27, 27, "conference"], [29, 29, "conference"], [35, 35, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 15, 4, 6, "topic", "", false, false], [12, 15, 35, 35, "topic", "", false, false], [17, 25, 4, 6, "topic", "", false, false], [17, 25, 35, 35, "topic", "", false, false], [27, 27, 4, 6, "topic", "", false, false], [27, 27, 35, 35, "topic", "", false, false], [29, 29, 4, 6, "topic", "", false, false], [29, 29, 35, 35, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Konferenzen", "im", "Bereich", "der", "Verarbeitung", "nat\u00fcrlicher", "Sprache", ",", "wie", "z.", "B.", "die", "Association", "for", "Computational", "Linguistics", ",", "North", "American", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "EMNLP", "und", "HLT", ",", "beginnen", ",", "Beitr\u00e4ge", "zur", "Sprachverarbeitung", "aufzunehmen", "."], "sentence-detokenized": "Konferenzen im Bereich der Verarbeitung nat\u00fcrlicher Sprache, wie z.B. die Association for Computational Linguistics, North American Chapter of the Association for Computational Linguistics, EMNLP und HLT, beginnen, Beitr\u00e4ge zur Sprachverarbeitung aufzunehmen.", "token2charspan": [[0, 11], [12, 14], [15, 22], [23, 26], [27, 39], [40, 51], [52, 59], [59, 60], [61, 64], [65, 67], [67, 69], [70, 73], [74, 85], [86, 89], [90, 103], [104, 115], [115, 116], [117, 122], [123, 131], [132, 139], [140, 142], [143, 146], [147, 158], [159, 162], [163, 176], [177, 188], [188, 189], [190, 195], [196, 199], [200, 203], [203, 204], [205, 213], [213, 214], [215, 223], [224, 227], [228, 246], [247, 258], [258, 259]]}
{"doc_key": "ai-test-69", "ner": [[21, 22, "misc"], [34, 35, "misc"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Eine", "Reihe", "von", "Java-Programmen", "nutzt", "das", "Lexikon", ",", "um", "die", "Variationen", "in", "biomedizinischen", "Texten", "durch", "die", "Zuordnung", "von", "W\u00f6rtern", "zu", "ihren", "Wortarten", "zu", "verarbeiten", ",", "was", "bei", "der", "Suche", "im", "Internet", "oder", "in", "einer", "elektronischen", "Patientenakte", "hilfreich", "sein", "kann", "."], "sentence-detokenized": "Eine Reihe von Java-Programmen nutzt das Lexikon, um die Variationen in biomedizinischen Texten durch die Zuordnung von W\u00f6rtern zu ihren Wortarten zu verarbeiten, was bei der Suche im Internet oder in einer elektronischen Patientenakte hilfreich sein kann.", "token2charspan": [[0, 4], [5, 10], [11, 14], [15, 30], [31, 36], [37, 40], [41, 48], [48, 49], [50, 52], [53, 56], [57, 68], [69, 71], [72, 88], [89, 95], [96, 101], [102, 105], [106, 115], [116, 119], [120, 127], [128, 130], [131, 136], [137, 146], [147, 149], [150, 161], [161, 162], [163, 166], [167, 170], [171, 174], [175, 180], [181, 183], [184, 192], [193, 197], [198, 200], [201, 206], [207, 221], [222, 235], [236, 245], [246, 250], [251, 255], [255, 256]]}
{"doc_key": "ai-test-70", "ner": [[6, 6, "algorithm"], [8, 8, "algorithm"], [10, 10, "algorithm"], [12, 12, "algorithm"], [14, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Es", "gibt", "viele", "neuere", "Algorithmen", "wie", "LPBoost", ",", "TotalBoost", ",", "BrownBoost", ",", "xgboost", ",", "MadaBoost", ",", "und", "andere", "."], "sentence-detokenized": "Es gibt viele neuere Algorithmen wie LPBoost, TotalBoost, BrownBoost, xgboost, MadaBoost, und andere.", "token2charspan": [[0, 2], [3, 7], [8, 13], [14, 20], [21, 32], [33, 36], [37, 44], [44, 45], [46, 56], [56, 57], [58, 68], [68, 69], [70, 77], [77, 78], [79, 88], [88, 89], [90, 93], [94, 100], [100, 101]]}
{"doc_key": "ai-test-71", "ner": [[5, 5, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Dies", "ist", "eine", "Beispielimplementierung", "in", "Python", ":"], "sentence-detokenized": "Dies ist eine Beispielimplementierung in Python:", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 37], [38, 40], [41, 47], [47, 48]]}
{"doc_key": "ai-test-72", "ner": [[4, 4, "organisation"], [2, 3, "product"], [8, 9, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 3, 4, 4, "artifact", "made_by_company", false, false], [8, 9, 2, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Die", "Spielkonsole", "Intellivision", "von", "Mattel", "bot", "1982", "das", "Sprachsynthesemodul", "Intellivoice", "an", "."], "sentence-detokenized": "Die Spielkonsole Intellivision von Mattel bot 1982 das Sprachsynthesemodul Intellivoice an.", "token2charspan": [[0, 3], [4, 16], [17, 30], [31, 34], [35, 41], [42, 45], [46, 50], [51, 54], [55, 74], [75, 87], [88, 90], [90, 91]]}
{"doc_key": "ai-test-73", "ner": [[4, 5, "task"], [9, 11, "task"], [15, 16, "field"], [18, 20, "task"], [24, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 11, 4, 5, "part-of", "", false, false], [15, 16, 4, 5, "part-of", "", false, false], [18, 20, 4, 5, "part-of", "", false, false], [24, 26, 18, 20, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Er", "arbeitete", "auch", "an", "maschineller", "\u00dcbersetzung", ",", "sowohl", "an", "hochpr\u00e4ziser", "wissensbasierter", "M\u00dc", "als", "auch", "an", "maschinellem", "Lernen", "f\u00fcr", "statistische", "maschinelle", "\u00dcbersetzung", "(", "z.", "B.", "generalisierte", "beispielbasierte", "M\u00dc", ")", "."], "sentence-detokenized": "Er arbeitete auch an maschineller \u00dcbersetzung, sowohl an hochpr\u00e4ziser wissensbasierter M\u00dc als auch an maschinellem Lernen f\u00fcr statistische maschinelle \u00dcbersetzung (z. B. generalisierte beispielbasierte M\u00dc).", "token2charspan": [[0, 2], [3, 12], [13, 17], [18, 20], [21, 33], [34, 45], [45, 46], [47, 53], [54, 56], [57, 69], [70, 86], [87, 89], [90, 93], [94, 98], [99, 101], [102, 114], [115, 121], [122, 125], [126, 138], [139, 150], [151, 162], [163, 164], [164, 166], [167, 169], [170, 184], [185, 201], [202, 204], [204, 205], [205, 206]]}
{"doc_key": "ai-test-74", "ner": [[0, 1, "misc"], [4, 4, "misc"], [21, 22, "algorithm"], [24, 25, "field"], [27, 27, "field"], [29, 29, "field"], [31, 31, "field"], [33, 33, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 21, 22, "general-affiliation", "", false, false], [0, 1, 24, 25, "general-affiliation", "", false, false], [0, 1, 27, 27, "general-affiliation", "", false, false], [0, 1, 29, 29, "general-affiliation", "", false, false], [0, 1, 31, 31, "general-affiliation", "", false, false], [0, 1, 33, 33, "general-affiliation", "", false, false], [4, 4, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Wolfram", "Mathematica", "(", "gew\u00f6hnlich", "Mathematica", "genannt", ")", "ist", "ein", "modernes", "technisches", "Rechensystem", ",", "das", "die", "meisten", "technischen", "Bereiche", "abdeckt", "-", "einschlie\u00dflich", "neuronaler", "Netze", ",", "maschinelles", "Lernen", ",", "Bildverarbeitung", ",", "Geometrie", ",", "Datenwissenschaft", ",", "Visualisierungen", "und", "andere", "."], "sentence-detokenized": "Wolfram Mathematica (gew\u00f6hnlich Mathematica genannt) ist ein modernes technisches Rechensystem, das die meisten technischen Bereiche abdeckt - einschlie\u00dflich neuronaler Netze, maschinelles Lernen, Bildverarbeitung, Geometrie, Datenwissenschaft, Visualisierungen und andere.", "token2charspan": [[0, 7], [8, 19], [20, 21], [21, 31], [32, 43], [44, 51], [51, 52], [53, 56], [57, 60], [61, 69], [70, 81], [82, 94], [94, 95], [96, 99], [100, 103], [104, 111], [112, 123], [124, 132], [133, 140], [141, 142], [143, 157], [158, 168], [169, 174], [174, 175], [176, 188], [189, 195], [195, 196], [197, 213], [213, 214], [215, 224], [224, 225], [226, 243], [243, 244], [245, 261], [262, 265], [266, 272], [272, 273]]}
{"doc_key": "ai-test-75", "ner": [[2, 6, "product"], [10, 11, "researcher"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 15, 2, 6, "type-of", "", false, false], [15, 15, 10, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Der", "erste", "digital", "betriebene", "und", "programmierbare", "Roboter", "wurde", "1954", "von", "George", "Devol", "erfunden", "und", "schlie\u00dflich", "Unimate", "genannt", "."], "sentence-detokenized": "Der erste digital betriebene und programmierbare Roboter wurde 1954 von George Devol erfunden und schlie\u00dflich Unimate genannt.", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 28], [29, 32], [33, 48], [49, 56], [57, 62], [63, 67], [68, 71], [72, 78], [79, 84], [85, 93], [94, 97], [98, 109], [110, 117], [118, 125], [125, 126]]}
{"doc_key": "ai-test-76", "ner": [[1, 1, "algorithm"], [3, 3, "algorithm"], [17, 17, "task"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[1, 1, 3, 3, "compare", "", false, false], [3, 3, 17, 17, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 2], "sentence": ["Wie", "DBNs", "k\u00f6nnen", "DBMs", "komplexe", "und", "abstrakte", "interne", "Repr\u00e4sentationen", "des", "Inputs", "in", "Aufgaben", "wie", "der", "Objekt-", "oder", "Spracherkennung", "erlernen", ",", "indem", "sie", "begrenzte", ",", "beschriftete", "Daten", "zur", "Feinabstimmung", "der", "Repr\u00e4sentationen", "verwenden", ",", "die", "mit", "einem", "gro\u00dfen", "Satz", "unbeschrifteter", "sensorischer", "Inputdaten", "erstellt", "wurden", "."], "sentence-detokenized": "Wie DBNs k\u00f6nnen DBMs komplexe und abstrakte interne Repr\u00e4sentationen des Inputs in Aufgaben wie der Objekt- oder Spracherkennung erlernen, indem sie begrenzte, beschriftete Daten zur Feinabstimmung der Repr\u00e4sentationen verwenden, die mit einem gro\u00dfen Satz unbeschrifteter sensorischer Inputdaten erstellt wurden.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 20], [21, 29], [30, 33], [34, 43], [44, 51], [52, 68], [69, 72], [73, 79], [80, 82], [83, 91], [92, 95], [96, 99], [100, 107], [108, 112], [113, 128], [129, 137], [137, 138], [139, 144], [145, 148], [149, 158], [158, 159], [160, 172], [173, 178], [179, 182], [183, 197], [198, 201], [202, 218], [219, 228], [228, 229], [230, 233], [234, 237], [238, 243], [244, 250], [251, 255], [256, 271], [272, 284], [285, 295], [296, 304], [305, 311], [311, 312]]}
{"doc_key": "ai-test-77", "ner": [[8, 9, "task"], [13, 13, "conference"], [15, 15, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 13, 8, 9, "topic", "", false, false], [15, 15, 8, 9, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Wissenschaftliche", "Konferenzen", ",", "auf", "denen", "h\u00e4ufig", "Arbeiten", "zur", "bildgest\u00fctzten", "Aktivit\u00e4tserkennung", "erscheinen", ",", "sind", "ICCV", "und", "CVPR", "."], "sentence-detokenized": "Wissenschaftliche Konferenzen, auf denen h\u00e4ufig Arbeiten zur bildgest\u00fctzten Aktivit\u00e4tserkennung erscheinen, sind ICCV und CVPR.", "token2charspan": [[0, 17], [18, 29], [29, 30], [31, 34], [35, 40], [41, 47], [48, 56], [57, 60], [61, 75], [76, 95], [96, 106], [106, 107], [108, 112], [113, 117], [118, 121], [122, 126], [126, 127]]}
{"doc_key": "ai-test-78", "ner": [[2, 2, "field"], [7, 7, "algorithm"], [9, 9, "algorithm"], [32, 32, "misc"]], "ner_mapping_to_source": [0, 1, 2, 6], "relations": [[7, 7, 2, 2, "part-of", "", false, false], [7, 7, 32, 32, "related-to", "", false, false], [9, 9, 7, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 3, 4], "sentence": ["In", "der", "Statistik", "ist", "ein", "Algorithmus", "zur", "Erwartungsmaximierung", "(", "EM", ")", "eine", "iterative", "Methode", "zur", "Ermittlung", "von", "Maximum-Likelihood-", "oder", "Maximum-A-Posteriori-Sch\u00e4tzungen", "von", "Parametern", "in", "statistischen", "Modellen", ",", "bei", "denen", "das", "Modell", "von", "unbeobachteten", "latenten", "Variablen", "abh\u00e4ngt", "."], "sentence-detokenized": "In der Statistik ist ein Algorithmus zur Erwartungsmaximierung (EM) eine iterative Methode zur Ermittlung von Maximum-Likelihood- oder Maximum-A-Posteriori-Sch\u00e4tzungen von Parametern in statistischen Modellen, bei denen das Modell von unbeobachteten latenten Variablen abh\u00e4ngt.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 20], [21, 24], [25, 36], [37, 40], [41, 62], [63, 64], [64, 66], [66, 67], [68, 72], [73, 82], [83, 90], [91, 94], [95, 105], [106, 109], [110, 129], [130, 134], [135, 167], [168, 171], [172, 182], [183, 185], [186, 199], [200, 208], [208, 209], [210, 213], [214, 219], [220, 223], [224, 230], [231, 234], [235, 249], [250, 258], [259, 268], [269, 276], [276, 277]]}
{"doc_key": "ai-test-79", "ner": [[8, 8, "metrics"], [10, 10, "metrics"], [14, 14, "metrics"], [16, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 10, 8, 8, "named", "", false, false], [16, 16, 14, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "\u00e4hnlicher", "Weise", "geben", "die", "Pr\u00fcfer", "manchmal", "die", "FALSCH-Positiv-Rate", "(", "FPR", ")", "und", "die", "FALSCH-Negativ-Rate", "(", "FNR", ")", "an", "."], "sentence-detokenized": "In \u00e4hnlicher Weise geben die Pr\u00fcfer manchmal die FALSCH-Positiv-Rate (FPR) und die FALSCH-Negativ-Rate (FNR) an.", "token2charspan": [[0, 2], [3, 12], [13, 18], [19, 24], [25, 28], [29, 35], [36, 44], [45, 48], [49, 68], [69, 70], [70, 73], [73, 74], [75, 78], [79, 82], [83, 102], [103, 104], [104, 107], [107, 108], [109, 111], [111, 112]]}
{"doc_key": "ai-test-80", "ner": [[4, 4, "metrics"], [9, 9, "field"], [15, 15, "metrics"], [20, 21, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 4, 4, "usage", "", false, false], [20, 21, 15, 15, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Das", "Konzept", "\u00e4hnelt", "dem", "Signal-Rausch-Verh\u00e4ltnis", ",", "das", "in", "den", "Wissenschaften", "verwendet", "wird", ",", "und", "der", "Konfusionsmatrix", ",", "die", "in", "der", "k\u00fcnstlichen", "Intelligenz", "verwendet", "wird", "."], "sentence-detokenized": "Das Konzept \u00e4hnelt dem Signal-Rausch-Verh\u00e4ltnis, das in den Wissenschaften verwendet wird, und der Konfusionsmatrix, die in der k\u00fcnstlichen Intelligenz verwendet wird.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 22], [23, 47], [47, 48], [49, 52], [53, 55], [56, 59], [60, 74], [75, 84], [85, 89], [89, 90], [91, 94], [95, 98], [99, 115], [115, 116], [117, 120], [121, 123], [124, 127], [128, 139], [140, 151], [152, 161], [162, 166], [166, 167]]}
{"doc_key": "ai-test-81", "ner": [[3, 4, "field"], [10, 11, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [28, 31, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 10, 11, "general-affiliation", "", false, false], [3, 4, 16, 17, "general-affiliation", "", false, false], [3, 4, 19, 20, "general-affiliation", "", false, false], [28, 31, 3, 4, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Der", "Ethikkodex", "f\u00fcr", "Human", "Augmentation", ",", "der", "urspr\u00fcnglich", "2004", "von", "Steve", "Mann", "eingef\u00fchrt", "und", "2013", "mit", "Ray", "Kurzweil", "und", "Marvin", "Minsky", "verfeinert", "wurde", ",", "wurde", "schlie\u00dflich", "auf", "der", "Konferenz", "Virtual", "Reality", "Toronto", "am", "25.", "Juni", "2017", "ratifiziert", "."], "sentence-detokenized": "Der Ethikkodex f\u00fcr Human Augmentation, der urspr\u00fcnglich 2004 von Steve Mann eingef\u00fchrt und 2013 mit Ray Kurzweil und Marvin Minsky verfeinert wurde, wurde schlie\u00dflich auf der Konferenz Virtual Reality Toronto am 25. Juni 2017 ratifiziert.", "token2charspan": [[0, 3], [4, 14], [15, 18], [19, 24], [25, 37], [37, 38], [39, 42], [43, 55], [56, 60], [61, 64], [65, 70], [71, 75], [76, 86], [87, 90], [91, 95], [96, 99], [100, 103], [104, 112], [113, 116], [117, 123], [124, 130], [131, 141], [142, 147], [147, 148], [149, 154], [155, 166], [167, 170], [171, 174], [175, 184], [185, 192], [193, 200], [201, 208], [209, 211], [212, 215], [216, 220], [221, 225], [226, 237], [237, 238]]}
{"doc_key": "ai-test-82", "ner": [[4, 7, "person"], [13, 13, "organisation"], [20, 21, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 7, 13, 13, "role", "directed_for", false, false], [4, 7, 20, 21, "role", "collaborator", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Im", "Jahr", "1913", "f\u00fchrte", "Walter", "R.", "Booth", "bei", "10", "Filmen", "f\u00fcr", "das", "britische", "Kinoplastikon", "Regie", ",", "vermutlich", "in", "Zusammenarbeit", "mit", "Cecil", "Hepworth", "."], "sentence-detokenized": "Im Jahr 1913 f\u00fchrte Walter R. Booth bei 10 Filmen f\u00fcr das britische Kinoplastikon Regie, vermutlich in Zusammenarbeit mit Cecil Hepworth.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 19], [20, 26], [27, 29], [30, 35], [36, 39], [40, 42], [43, 49], [50, 53], [54, 57], [58, 67], [68, 81], [82, 87], [87, 88], [89, 99], [100, 102], [103, 117], [118, 121], [122, 127], [128, 136], [136, 137]]}
{"doc_key": "ai-test-83", "ner": [[13, 13, "location"], [10, 11, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 11, 13, 13, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Sie", "stellten", "ihren", "neuen", "Roboter", "1961", "auf", "einer", "Fachmesse", "im", "Cow", "Palace", "in", "Chicago", "vor", "."], "sentence-detokenized": "Sie stellten ihren neuen Roboter 1961 auf einer Fachmesse im Cow Palace in Chicago vor.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 24], [25, 32], [33, 37], [38, 41], [42, 47], [48, 57], [58, 60], [61, 64], [65, 71], [72, 74], [75, 82], [83, 86], [86, 87]]}
{"doc_key": "ai-test-84", "ner": [[7, 10, "field"], [13, 14, "field"]], "ner_mapping_to_source": [2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["W\u00e4hrend", "einige", "Chatbot-Anwendungen", "umfangreiche", "Wortklassifizierungsprozesse", ",", "Prozessoren", "zur", "Verarbeitung", "nat\u00fcrlicher", "Sprache", "und", "ausgefeilte", "k\u00fcnstliche", "Intelligenz", "verwenden", ",", "suchen", "andere", "einfach", "nach", "allgemeinen", "Schl\u00fcsselw\u00f6rtern", "und", "generieren", "Antworten", "anhand", "allgemeiner", "Phrasen", ",", "die", "aus", "einer", "zugeh\u00f6rigen", "Bibliothek", "oder", "Datenbank", "stammen", "."], "sentence-detokenized": "W\u00e4hrend einige Chatbot-Anwendungen umfangreiche Wortklassifizierungsprozesse, Prozessoren zur Verarbeitung nat\u00fcrlicher Sprache und ausgefeilte k\u00fcnstliche Intelligenz verwenden, suchen andere einfach nach allgemeinen Schl\u00fcsselw\u00f6rtern und generieren Antworten anhand allgemeiner Phrasen, die aus einer zugeh\u00f6rigen Bibliothek oder Datenbank stammen.", "token2charspan": [[0, 7], [8, 14], [15, 34], [35, 47], [48, 76], [76, 77], [78, 89], [90, 93], [94, 106], [107, 118], [119, 126], [127, 130], [131, 142], [143, 153], [154, 165], [166, 175], [175, 176], [177, 183], [184, 190], [191, 198], [199, 203], [204, 215], [216, 232], [233, 236], [237, 247], [248, 257], [258, 264], [265, 276], [277, 284], [284, 285], [286, 289], [290, 293], [294, 299], [300, 311], [312, 322], [323, 327], [328, 337], [338, 345], [345, 346]]}
{"doc_key": "ai-test-85", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["Das", "im", "Jahr", "2016", "vorgeschlagene", "WaveNet-Modell", "erzielt", "eine", "hervorragende", "Leistung", "bei", "der", "Sprachqualit\u00e4t", "."], "sentence-detokenized": "Das im Jahr 2016 vorgeschlagene WaveNet-Modell erzielt eine hervorragende Leistung bei der Sprachqualit\u00e4t.", "token2charspan": [[0, 3], [4, 6], [7, 11], [12, 16], [17, 31], [32, 46], [47, 54], [55, 59], [60, 73], [74, 82], [83, 86], [87, 90], [91, 105], [105, 106]]}
{"doc_key": "ai-test-86", "ner": [[9, 9, "product"], [12, 12, "misc"], [15, 15, "misc"], [18, 19, "misc"], [22, 25, "misc"], [28, 30, "organisation"], [32, 32, "organisation"], [34, 36, "organisation"], [39, 39, "organisation"], [41, 44, "organisation"], [46, 47, "organisation"], [49, 51, "organisation"], [53, 55, "organisation"], [58, 58, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[9, 9, 12, 12, "general-affiliation", "", false, false], [9, 9, 15, 15, "general-affiliation", "", false, false], [9, 9, 18, 19, "general-affiliation", "", false, false], [9, 9, 22, 25, "general-affiliation", "", false, false], [28, 30, 9, 9, "usage", "", false, false], [32, 32, 9, 9, "usage", "", false, false], [34, 36, 9, 9, "usage", "", false, false], [39, 39, 9, 9, "usage", "", false, false], [41, 44, 9, 9, "usage", "", false, false], [46, 47, 9, 9, "usage", "", false, false], [49, 51, 9, 9, "usage", "", false, false], [53, 55, 9, 9, "usage", "", false, false], [58, 58, 9, 9, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Organisationen", ",", "von", "denen", "bekannt", "ist", ",", "dass", "sie", "ALE", "f\u00fcr", "das", "Notfallmanagement", ",", "die", "Katastrophenhilfe", ",", "die", "normale", "Kommunikation", "oder", "die", "Reaktion", "auf", "au\u00dfergew\u00f6hnliche", "Situationen", "nutzen", ":", "Amerikanisches", "Rotes", "Kreuz", ",", "FEMA", ",", "Disaster", "Medical", "Assistance", "Teams", ",", "NATO", ",", "Federal", "Bureau", "of", "Investigation", ",", "Vereinte", "Nationen", ",", "AT", "&", "T", ",", "Civil", "Air", "Patrol", ",", "(", "ARES", ")", "."], "sentence-detokenized": "Organisationen, von denen bekannt ist, dass sie ALE f\u00fcr das Notfallmanagement, die Katastrophenhilfe, die normale Kommunikation oder die Reaktion auf au\u00dfergew\u00f6hnliche Situationen nutzen: Amerikanisches Rotes Kreuz, FEMA, Disaster Medical Assistance Teams, NATO, Federal Bureau of Investigation, Vereinte Nationen, AT & T, Civil Air Patrol, (ARES).", "token2charspan": [[0, 14], [14, 15], [16, 19], [20, 25], [26, 33], [34, 37], [37, 38], [39, 43], [44, 47], [48, 51], [52, 55], [56, 59], [60, 77], [77, 78], [79, 82], [83, 100], [100, 101], [102, 105], [106, 113], [114, 127], [128, 132], [133, 136], [137, 145], [146, 149], [150, 166], [167, 178], [179, 185], [185, 186], [187, 201], [202, 207], [208, 213], [213, 214], [215, 219], [219, 220], [221, 229], [230, 237], [238, 248], [249, 254], [254, 255], [256, 260], [260, 261], [262, 269], [270, 276], [277, 279], [280, 293], [293, 294], [295, 303], [304, 312], [312, 313], [314, 316], [317, 318], [319, 320], [320, 321], [322, 327], [328, 331], [332, 338], [338, 339], [340, 341], [341, 345], [345, 346], [346, 347]]}
{"doc_key": "ai-test-87", "ner": [[6, 6, "algorithm"], [13, 13, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Hier", "wird", "der", "Einfachheit", "halber", "das", "Kronecker-Delta", "verwendet", "(", "vgl.", "die", "Ableitung", "einer", "Sigmoidfunktion", ",", "die", "durch", "die", "Funktion", "selbst", "ausgedr\u00fcckt", "wird", ")", "."], "sentence-detokenized": "Hier wird der Einfachheit halber das Kronecker-Delta verwendet (vgl. die Ableitung einer Sigmoidfunktion, die durch die Funktion selbst ausgedr\u00fcckt wird).", "token2charspan": [[0, 4], [5, 9], [10, 13], [14, 25], [26, 32], [33, 36], [37, 52], [53, 62], [63, 64], [64, 68], [69, 72], [73, 82], [83, 88], [89, 104], [104, 105], [106, 109], [110, 115], [116, 119], [120, 128], [129, 135], [136, 147], [148, 152], [152, 153], [153, 154]]}
{"doc_key": "ai-test-88", "ner": [[11, 12, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Die", "Theorie", "basiert", "auf", "philosophischen", "Grundlagen", "und", "wurde", "um", "1960", "von", "Ray", "Solomonoff", "begr\u00fcndet", ".", "Samuel", "Rathmanner", "und", "Marcus", "Hutter", "."], "sentence-detokenized": "Die Theorie basiert auf philosophischen Grundlagen und wurde um 1960 von Ray Solomonoff begr\u00fcndet. Samuel Rathmanner und Marcus Hutter.", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 23], [24, 39], [40, 50], [51, 54], [55, 60], [61, 63], [64, 68], [69, 72], [73, 76], [77, 87], [88, 97], [97, 98], [99, 105], [106, 116], [117, 120], [121, 127], [128, 134], [134, 135]]}
{"doc_key": "ai-test-89", "ner": [[0, 0, "product"], [10, 11, "misc"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 10, 11, "type-of", "", false, false], [0, 0, 15, 16, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["WordNet", ",", "eine", "frei", "verf\u00fcgbare", "Datenbank", ",", "die", "urspr\u00fcnglich", "als", "semantisches", "Netz", "auf", "der", "Grundlage", "psycholinguistischer", "Prinzipien", "konzipiert", "war", ",", "wurde", "durch", "Hinzuf\u00fcgen", "von", "Definitionen", "erweitert", "und", "wird", "nun", "auch", "als", "W\u00f6rterbuch", "betrachtet", "."], "sentence-detokenized": "WordNet, eine frei verf\u00fcgbare Datenbank, die urspr\u00fcnglich als semantisches Netz auf der Grundlage psycholinguistischer Prinzipien konzipiert war, wurde durch Hinzuf\u00fcgen von Definitionen erweitert und wird nun auch als W\u00f6rterbuch betrachtet.", "token2charspan": [[0, 7], [7, 8], [9, 13], [14, 18], [19, 29], [30, 39], [39, 40], [41, 44], [45, 57], [58, 61], [62, 74], [75, 79], [80, 83], [84, 87], [88, 97], [98, 118], [119, 129], [130, 140], [141, 144], [144, 145], [146, 151], [152, 157], [158, 168], [169, 172], [173, 185], [186, 195], [196, 199], [200, 204], [205, 208], [209, 213], [214, 217], [218, 228], [229, 239], [239, 240]]}
{"doc_key": "ai-test-90", "ner": [[9, 10, "field"], [21, 21, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[21, 21, 9, 10, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Fortschritte", "auf", "dem", "Gebiet", "der", "Forschung", "im", "Bereich", "der", "computergest\u00fctzten", "Bildgebung", "werden", "an", "verschiedenen", "Orten", "vorgestellt", ",", "darunter", "in", "Ver\u00f6ffentlichungen", "der", "SIGGRAPH", "und", "der", "."], "sentence-detokenized": "Fortschritte auf dem Gebiet der Forschung im Bereich der computergest\u00fctzten Bildgebung werden an verschiedenen Orten vorgestellt, darunter in Ver\u00f6ffentlichungen der SIGGRAPH und der.", "token2charspan": [[0, 12], [13, 16], [17, 20], [21, 27], [28, 31], [32, 41], [42, 44], [45, 52], [53, 56], [57, 75], [76, 86], [87, 93], [94, 96], [97, 110], [111, 116], [117, 128], [128, 129], [130, 138], [139, 141], [142, 160], [161, 164], [165, 173], [174, 177], [178, 181], [181, 182]]}
{"doc_key": "ai-test-91", "ner": [[0, 1, "task"], [11, 12, "task"], [15, 15, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 0, 1, "part-of", "", false, false], [15, 15, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Die", "Klassifizierung", "kann", "als", "zwei", "getrennte", "Probleme", "betrachtet", "werden", "-", "die", "bin\u00e4re", "Klassifizierung", "und", "die", "Multiklassen-Klassifizierung", "."], "sentence-detokenized": "Die Klassifizierung kann als zwei getrennte Probleme betrachtet werden - die bin\u00e4re Klassifizierung und die Multiklassen-Klassifizierung.", "token2charspan": [[0, 3], [4, 19], [20, 24], [25, 28], [29, 33], [34, 43], [44, 52], [53, 63], [64, 70], [71, 72], [73, 76], [77, 83], [84, 99], [100, 103], [104, 107], [108, 136], [136, 137]]}
{"doc_key": "ai-test-92", "ner": [[12, 12, "algorithm"], [20, 20, "algorithm"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Fortgeschrittene", "Genfinder", "f\u00fcr", "prokaryotische", "und", "eukaryotische", "Genome", "verwenden", "in", "der", "Regel", "komplexe", "probabilistische", "Modelle", ",", "wie", "z.", "B.", "Hidden-Markov-Modelle", "(", "HMMs", ")", ",", "um", "Informationen", "aus", "einer", "Vielzahl", "verschiedener", "Signal-", "und", "Inhaltsmessungen", "zu", "kombinieren", "."], "sentence-detokenized": "Fortgeschrittene Genfinder f\u00fcr prokaryotische und eukaryotische Genome verwenden in der Regel komplexe probabilistische Modelle, wie z. B. Hidden-Markov-Modelle (HMMs), um Informationen aus einer Vielzahl verschiedener Signal- und Inhaltsmessungen zu kombinieren.", "token2charspan": [[0, 16], [17, 26], [27, 30], [31, 45], [46, 49], [50, 63], [64, 70], [71, 80], [81, 83], [84, 87], [88, 93], [94, 102], [103, 119], [120, 127], [127, 128], [129, 132], [133, 135], [136, 138], [139, 160], [161, 162], [162, 166], [166, 167], [167, 168], [169, 171], [172, 185], [186, 189], [190, 195], [196, 204], [205, 218], [219, 226], [227, 230], [231, 247], [248, 250], [251, 262], [262, 263]]}
{"doc_key": "ai-test-93", "ner": [[0, 0, "misc"], [5, 6, "field"], [10, 11, "algorithm"], [15, 16, "algorithm"], [19, 19, "algorithm"], [31, 32, "algorithm"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6], "relations": [[19, 19, 15, 16, "named", "", false, false]], "relations_mapping_to_source": [4], "sentence": ["Neuroevolution", "ist", "eine", "Form", "der", "k\u00fcnstlichen", "Intelligenz", ",", "bei", "der", "evolution\u00e4re", "Algorithmen", "zur", "Generierung", "von", "k\u00fcnstlichen", "neuronalen", "Netzen", "(", "ANN", ")", ",", "Parametern", ",", "Topologie", "und", "Regeln", "eingesetzt", "werden", ".", "und", "evolution\u00e4re", "Robotik", "."], "sentence-detokenized": "Neuroevolution ist eine Form der k\u00fcnstlichen Intelligenz, bei der evolution\u00e4re Algorithmen zur Generierung von k\u00fcnstlichen neuronalen Netzen (ANN), Parametern, Topologie und Regeln eingesetzt werden. und evolution\u00e4re Robotik.", "token2charspan": [[0, 14], [15, 18], [19, 23], [24, 28], [29, 32], [33, 44], [45, 56], [56, 57], [58, 61], [62, 65], [66, 78], [79, 90], [91, 94], [95, 106], [107, 110], [111, 122], [123, 133], [134, 140], [141, 142], [142, 145], [145, 146], [146, 147], [148, 158], [158, 159], [160, 169], [170, 173], [174, 180], [181, 191], [192, 198], [198, 199], [200, 203], [204, 216], [217, 224], [224, 225]]}
{"doc_key": "ai-test-94", "ner": [[1, 1, "organisation"], [3, 3, "metrics"], [10, 10, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 1, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Seit", "IBM", "das", "BLEU-System", "vorgeschlagen", "und", "realisiert", "hat", ",", "haben", "Papineni", "et", "al", "."], "sentence-detokenized": "Seit IBM das BLEU-System vorgeschlagen und realisiert hat, haben Papineni et al.", "token2charspan": [[0, 4], [5, 8], [9, 12], [13, 24], [25, 38], [39, 42], [43, 53], [54, 57], [57, 58], [59, 64], [65, 73], [74, 76], [77, 79], [79, 80]]}
{"doc_key": "ai-test-95", "ner": [[9, 15, "conference"], [17, 17, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 17, 9, 15, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Im", "Jahr", "2009", "diskutierten", "Experten", "auf", "einer", "Konferenz", "der", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", ",", "ob", "Computer", "und", "Roboter", "in", "der", "Lage", "sein", "k\u00f6nnten", ",", "Autonomie", "zu", "erlangen", ",", "und", "inwieweit", "diese", "F\u00e4higkeiten", "eine", "Bedrohung", "oder", "Gefahr", "darstellen", "k\u00f6nnten", "."], "sentence-detokenized": "Im Jahr 2009 diskutierten Experten auf einer Konferenz der Association for the Advancement of Artificial Intelligence (AAAI), ob Computer und Roboter in der Lage sein k\u00f6nnten, Autonomie zu erlangen, und inwieweit diese F\u00e4higkeiten eine Bedrohung oder Gefahr darstellen k\u00f6nnten.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 25], [26, 34], [35, 38], [39, 44], [45, 54], [55, 58], [59, 70], [71, 74], [75, 78], [79, 90], [91, 93], [94, 104], [105, 117], [118, 119], [119, 123], [123, 124], [124, 125], [126, 128], [129, 137], [138, 141], [142, 149], [150, 152], [153, 156], [157, 161], [162, 166], [167, 174], [174, 175], [176, 185], [186, 188], [189, 197], [197, 198], [199, 202], [203, 212], [213, 218], [219, 230], [231, 235], [236, 245], [246, 250], [251, 257], [258, 268], [269, 276], [276, 277]]}
{"doc_key": "ai-test-96", "ner": [[23, 25, "metrics"], [26, 27, "researcher"], [29, 30, "researcher"], [32, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[32, 35, 23, 25, "topic", "", false, false], [32, 35, 26, 27, "artifact", "", false, false], [32, 35, 29, 30, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Nach", "dem", "Boosting", "k\u00f6nnte", "ein", "aus", "200", "Merkmalen", "konstruierter", "Klassifikator", "eine", "Erkennungsrate", "von", "95", "%", "bei", "einer", "^", "{", "-5", "}", "/", "math", "FALSE", "positive", "rate", ".P.", "Viola", ",", "M.", "Jones", ",", "Robust", "Real-time", "Object", "Detection", ",", "2001", "."], "sentence-detokenized": "Nach dem Boosting k\u00f6nnte ein aus 200 Merkmalen konstruierter Klassifikator eine Erkennungsrate von 95 % bei einer ^ {-5} / math FALSE positive rate .P. Viola, M. Jones, Robust Real-time Object Detection, 2001.", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 24], [25, 28], [29, 32], [33, 36], [37, 46], [47, 60], [61, 74], [75, 79], [80, 94], [95, 98], [99, 101], [102, 103], [104, 107], [108, 113], [114, 115], [116, 117], [117, 119], [119, 120], [121, 122], [123, 127], [128, 133], [134, 142], [143, 147], [148, 151], [152, 157], [157, 158], [159, 161], [162, 167], [167, 168], [169, 175], [176, 185], [186, 192], [193, 202], [202, 203], [204, 208], [208, 209]]}
{"doc_key": "ai-test-97", "ner": [[5, 5, "programlang"], [8, 8, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Die", "Website", "basierte", "urspr\u00fcnglich", "auf", "Perl", ",", "aber", "IMDb", "gibt", "aus", "Sicherheitsgr\u00fcnden", "nicht", "mehr", "bekannt", ",", "welche", "Software", "verwendet", "wird", "."], "sentence-detokenized": "Die Website basierte urspr\u00fcnglich auf Perl, aber IMDb gibt aus Sicherheitsgr\u00fcnden nicht mehr bekannt, welche Software verwendet wird.", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 33], [34, 37], [38, 42], [42, 43], [44, 48], [49, 53], [54, 58], [59, 62], [63, 81], [82, 87], [88, 92], [93, 100], [100, 101], [102, 108], [109, 117], [118, 127], [128, 132], [132, 133]]}
{"doc_key": "ai-test-98", "ner": [[5, 6, "researcher"], [8, 9, "researcher"], [11, 12, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Das", "Start-up", "wurde", "2010", "von", "Demis", "Hassabis", ",", "Shane", "Legg", "und", "Mustafa", "Suleyman", "gegr\u00fcndet", "."], "sentence-detokenized": "Das Start-up wurde 2010 von Demis Hassabis, Shane Legg und Mustafa Suleyman gegr\u00fcndet.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 23], [24, 27], [28, 33], [34, 42], [42, 43], [44, 49], [50, 54], [55, 58], [59, 66], [67, 75], [76, 85], [85, 86]]}
{"doc_key": "ai-test-99", "ner": [[4, 4, "misc"], [7, 9, "metrics"], [24, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 4, 4, "type-of", "", false, false], [24, 25, 4, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Zwei", "sehr", "h\u00e4ufig", "verwendete", "Verlustfunktionen", "sind", "der", "mittlere", "quadratische", "Fehler", ",", "mathL", "(", "a", ")", "=", "a", "^", "2", "/", "math", ",", "und", "der", "absolute", "Verlust", ",", "mathL", "(", "a", ")", "=", "|", "a", "|", "/", "math", "."], "sentence-detokenized": "Zwei sehr h\u00e4ufig verwendete Verlustfunktionen sind der mittlere quadratische Fehler, mathL (a) = a ^ 2 / math, und der absolute Verlust, mathL (a) = | a | / math.", "token2charspan": [[0, 4], [5, 9], [10, 16], [17, 27], [28, 45], [46, 50], [51, 54], [55, 63], [64, 76], [77, 83], [83, 84], [85, 90], [91, 92], [92, 93], [93, 94], [95, 96], [97, 98], [99, 100], [101, 102], [103, 104], [105, 109], [109, 110], [111, 114], [115, 118], [119, 127], [128, 135], [135, 136], [137, 142], [143, 144], [144, 145], [145, 146], [147, 148], [149, 150], [151, 152], [153, 154], [155, 156], [157, 161], [161, 162]]}
{"doc_key": "ai-test-100", "ner": [[3, 3, "algorithm"], [9, 10, "algorithm"], [12, 12, "algorithm"], [16, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 9, 10, "type-of", "example_of", false, false], [9, 10, 16, 16, "related-to", "", false, false], [12, 12, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Die", "oben", "beschriebene", "Soft-Margin-Support-Vektor-Maschine", "ist", "ein", "Beispiel", "f\u00fcr", "eine", "empirische", "Risikominimierung", "(", "ERM", ")", "f\u00fcr", "den", "Scharnierverlust", "."], "sentence-detokenized": "Die oben beschriebene Soft-Margin-Support-Vektor-Maschine ist ein Beispiel f\u00fcr eine empirische Risikominimierung (ERM) f\u00fcr den Scharnierverlust.", "token2charspan": [[0, 3], [4, 8], [9, 21], [22, 57], [58, 61], [62, 65], [66, 74], [75, 78], [79, 83], [84, 94], [95, 112], [113, 114], [114, 117], [117, 118], [119, 122], [123, 126], [127, 143], [143, 144]]}
{"doc_key": "ai-test-101", "ner": [[7, 8, "field"], [13, 13, "task"], [0, 3, "task"], [25, 25, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 7, 8, "origin", "", false, false], [0, 3, 13, 13, "type-of", "", false, false], [25, 25, 0, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Die", "neuronale", "maschinelle", "\u00dcbersetzung", ",", "ein", "auf", "Deep", "Learning", "basierender", "Ansatz", "f\u00fcr", "die", "MT", ",", "hat", "in", "den", "letzten", "Jahren", "rasante", "Fortschritte", "gemacht", ",", "und", "Google", "hat", "angek\u00fcndigt", ",", "dass", "seine", "\u00dcbersetzungsdienste", "nun", "diese", "Technologie", "anstelle", "der", "bisherigen", "statistischen", "Methoden", "verwenden", "."], "sentence-detokenized": "Die neuronale maschinelle \u00dcbersetzung, ein auf Deep Learning basierender Ansatz f\u00fcr die MT, hat in den letzten Jahren rasante Fortschritte gemacht, und Google hat angek\u00fcndigt, dass seine \u00dcbersetzungsdienste nun diese Technologie anstelle der bisherigen statistischen Methoden verwenden.", "token2charspan": [[0, 3], [4, 13], [14, 25], [26, 37], [37, 38], [39, 42], [43, 46], [47, 51], [52, 60], [61, 72], [73, 79], [80, 83], [84, 87], [88, 90], [90, 91], [92, 95], [96, 98], [99, 102], [103, 110], [111, 117], [118, 125], [126, 138], [139, 146], [146, 147], [148, 151], [152, 158], [159, 162], [163, 174], [174, 175], [176, 180], [181, 186], [187, 206], [207, 210], [211, 216], [217, 228], [229, 237], [238, 241], [242, 252], [253, 266], [267, 275], [276, 285], [285, 286]]}
{"doc_key": "ai-test-102", "ner": [[9, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Dies", "f\u00fchrt", "bei", "der", "Arbeit", "mit", "gro\u00dfen", "Korpora", "wie", "WordNet", "in", "der", "Regel", "zu", "sehr", "gro\u00dfen", "Leistungssteigerungen", "."], "sentence-detokenized": "Dies f\u00fchrt bei der Arbeit mit gro\u00dfen Korpora wie WordNet in der Regel zu sehr gro\u00dfen Leistungssteigerungen.", "token2charspan": [[0, 4], [5, 10], [11, 14], [15, 18], [19, 25], [26, 29], [30, 36], [37, 44], [45, 48], [49, 56], [57, 59], [60, 63], [64, 69], [70, 72], [73, 77], [78, 84], [85, 106], [106, 107]]}
{"doc_key": "ai-test-103", "ner": [[0, 1, "task"], [5, 5, "field"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 12, 12, "part-of", "", false, false], [12, 12, 5, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Die", "Gesichtserkennung", "wird", "in", "der", "Biometrie", "eingesetzt", ",", "oft", "als", "Teil", "eines", "Gesichtserkennungssystems", "(", "oder", "zusammen", "mit", "diesem", ")", "."], "sentence-detokenized": "Die Gesichtserkennung wird in der Biometrie eingesetzt, oft als Teil eines Gesichtserkennungssystems (oder zusammen mit diesem).", "token2charspan": [[0, 3], [4, 21], [22, 26], [27, 29], [30, 33], [34, 43], [44, 54], [54, 55], [56, 59], [60, 63], [64, 68], [69, 74], [75, 100], [101, 102], [102, 106], [107, 115], [116, 119], [120, 126], [126, 127], [127, 128]]}
{"doc_key": "ai-test-104", "ner": [[2, 2, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["trainiert", "durch", "Maximum-Likelihood-Sch\u00e4tzung", "."], "sentence-detokenized": "trainiert durch Maximum-Likelihood-Sch\u00e4tzung.", "token2charspan": [[0, 9], [10, 15], [16, 44], [44, 45]]}
{"doc_key": "ai-test-105", "ner": [[2, 2, "country"], [4, 9, "organisation"], [12, 12, "location"], [14, 14, "country"], [16, 19, "organisation"], [21, 21, "country"], [27, 27, "organisation"], [31, 34, "organisation"], [36, 36, "country"], [45, 48, "organisation"], [50, 51, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[4, 9, 12, 12, "physical", "", false, false], [12, 12, 14, 14, "physical", "", false, false], [16, 19, 21, 21, "physical", "", false, false], [31, 34, 36, 36, "physical", "", false, false], [45, 48, 50, 51, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Ltd.", "in", "Thailand", ";", "Komatsu", "(", "Shanghai", ")", "Ltd", ".", "1996", "in", "Shanghai", ",", "China", ";", "Industrial", "Power", "Alliance", "Ltd.", "in", "Japan", ",", "ein", "Joint", "Venture", "mit", "Cummins", ",", "1998", ";", "L", "&", "T-Komatsu", "Limited", "in", "Indien", "1998", "(", "Anteile", "2013", "verkauft", ")", ";", "und", "Komatsu", "Brasil", "International", "Ltda.", "in", "Brasilien", "1998", "."], "sentence-detokenized": "Ltd. in Thailand; Komatsu (Shanghai) Ltd. 1996 in Shanghai, China; Industrial Power Alliance Ltd. in Japan, ein Joint Venture mit Cummins, 1998; L & T-Komatsu Limited in Indien 1998 (Anteile 2013 verkauft); und Komatsu Brasil International Ltda. in Brasilien 1998.", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 25], [26, 27], [27, 35], [35, 36], [37, 40], [40, 41], [42, 46], [47, 49], [50, 58], [58, 59], [60, 65], [65, 66], [67, 77], [78, 83], [84, 92], [93, 97], [98, 100], [101, 106], [106, 107], [108, 111], [112, 117], [118, 125], [126, 129], [130, 137], [137, 138], [139, 143], [143, 144], [145, 146], [147, 148], [149, 158], [159, 166], [167, 169], [170, 176], [177, 181], [182, 183], [183, 190], [191, 195], [196, 204], [204, 205], [205, 206], [207, 210], [211, 218], [219, 225], [226, 239], [240, 245], [246, 248], [249, 258], [259, 263], [263, 264]]}
{"doc_key": "ai-test-106", "ner": [[0, 0, "organisation"], [4, 6, "misc"], [11, 12, "person"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[11, 12, 0, 0, "physical", "", false, false], [11, 12, 4, 6, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["dgp", "beherbergt", "auch", "gelegentlich", "K\u00fcnstler", "in", "Residenzen", "(", "z.", "B.", "Oscar-Preistr\u00e4ger", "Chris", "Landreth", ")", "."], "sentence-detokenized": "dgp beherbergt auch gelegentlich K\u00fcnstler in Residenzen (z. B. Oscar-Preistr\u00e4ger Chris Landreth).", "token2charspan": [[0, 3], [4, 14], [15, 19], [20, 32], [33, 41], [42, 44], [45, 55], [56, 57], [57, 59], [60, 62], [63, 80], [81, 86], [87, 95], [95, 96], [96, 97]]}
{"doc_key": "ai-test-107", "ner": [[7, 9, "misc"], [12, 14, "misc"], [17, 20, "misc"], [24, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Es", "umfasst", "derzeit", "vier", "Unterwettbewerbe", "-", "den", "RoboMaster", "Robotics", "Competition", ",", "den", "RoboMaster", "Technical", "Challenge", ",", "den", "ICRA", "RoboMaster", "AI", "Challenge", "und", "das", "neue", "RoboMaster", "Youth", "Tournament", "."], "sentence-detokenized": "Es umfasst derzeit vier Unterwettbewerbe - den RoboMaster Robotics Competition, den RoboMaster Technical Challenge, den ICRA RoboMaster AI Challenge und das neue RoboMaster Youth Tournament.", "token2charspan": [[0, 2], [3, 10], [11, 18], [19, 23], [24, 40], [41, 42], [43, 46], [47, 57], [58, 66], [67, 78], [78, 79], [80, 83], [84, 94], [95, 104], [105, 114], [114, 115], [116, 119], [120, 124], [125, 135], [136, 138], [139, 148], [149, 152], [153, 156], [157, 161], [162, 172], [173, 178], [179, 189], [189, 190]]}
{"doc_key": "ai-test-108", "ner": [[11, 11, "algorithm"], [15, 16, "algorithm"], [18, 21, "field"]], "ner_mapping_to_source": [1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "den", "fr\u00fchen", "2000er", "Jahren", "begann", "sich", "die", "vorherrschende", "Sprachverarbeitungsstrategie", "vom", "Hidden-Markov-Modell", "hin", "zu", "moderneren", "neuronalen", "Netzen", "und", "Deep", "Learning", "zu", "verlagern", "."], "sentence-detokenized": "In den fr\u00fchen 2000er Jahren begann sich die vorherrschende Sprachverarbeitungsstrategie vom Hidden-Markov-Modell hin zu moderneren neuronalen Netzen und Deep Learning zu verlagern.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 20], [21, 27], [28, 34], [35, 39], [40, 43], [44, 58], [59, 87], [88, 91], [92, 112], [113, 116], [117, 119], [120, 130], [131, 141], [142, 148], [149, 152], [153, 157], [158, 166], [167, 169], [170, 179], [179, 180]]}
{"doc_key": "ai-test-109", "ner": [[7, 8, "misc"], [13, 13, "metrics"], [16, 16, "metrics"], [23, 23, "metrics"], [26, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 13, 16, 16, "related-to", "equal", false, false], [23, 23, 26, 26, "related-to", "equal", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Eine", "andere", "\u00e4quivalente", "Auspr\u00e4gung", "im", "Falle", "einer", "bin\u00e4ren", "Zielquote", "ist", ",", "dass", "die", "Richtig-Positiv-Quote", "und", "die", "Falsch-Positiv-Quote", "gleich", "sind", "(", "und", "daher", "die", "Falsch-Negativ-Quote", "und", "die", "Richtig-Negativ-Quote", "gleich", "sind", ")", "f\u00fcr", "jeden", "Wert", "der", "sensitiven", "Merkmale", ":"], "sentence-detokenized": "Eine andere \u00e4quivalente Auspr\u00e4gung im Falle einer bin\u00e4ren Zielquote ist, dass die Richtig-Positiv-Quote und die Falsch-Positiv-Quote gleich sind (und daher die Falsch-Negativ-Quote und die Richtig-Negativ-Quote gleich sind) f\u00fcr jeden Wert der sensitiven Merkmale:", "token2charspan": [[0, 4], [5, 11], [12, 23], [24, 34], [35, 37], [38, 43], [44, 49], [50, 57], [58, 67], [68, 71], [71, 72], [73, 77], [78, 81], [82, 103], [104, 107], [108, 111], [112, 132], [133, 139], [140, 144], [145, 146], [146, 149], [150, 155], [156, 159], [160, 180], [181, 184], [185, 188], [189, 210], [211, 217], [218, 222], [222, 223], [224, 227], [228, 233], [234, 238], [239, 242], [243, 253], [254, 262], [262, 263]]}
{"doc_key": "ai-test-110", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["Die", "MATLAB-Funktion", ","], "sentence-detokenized": "Die MATLAB-Funktion,", "token2charspan": [[0, 3], [4, 19], [19, 20]]}
{"doc_key": "ai-test-111", "ner": [[1, 1, "product"], [16, 16, "product"]], "ner_mapping_to_source": [0, 2], "relations": [[16, 16, 1, 1, "type-of", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Ein", "Knickarmroboter", "ist", "ein", "Roboter", "mit", "Drehgelenken", "(", "z.", "B.", "ein", "Roboter", "mit", "Beinen", "oder", "ein", "Industrieroboter", ")", "."], "sentence-detokenized": "Ein Knickarmroboter ist ein Roboter mit Drehgelenken (z. B. ein Roboter mit Beinen oder ein Industrieroboter).", "token2charspan": [[0, 3], [4, 19], [20, 23], [24, 27], [28, 35], [36, 39], [40, 52], [53, 54], [54, 56], [57, 59], [60, 63], [64, 71], [72, 75], [76, 82], [83, 87], [88, 91], [92, 108], [108, 109], [109, 110]]}
{"doc_key": "ai-test-112", "ner": [[0, 0, "product"], [5, 6, "product"], [8, 9, "product"], [13, 13, "misc"], [18, 19, "product"], [23, 25, "misc"], [32, 32, "location"], [34, 34, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 13, 13, "general-affiliation", "nationality", false, false], [0, 0, 23, 25, "usage", "", false, false], [0, 0, 32, 32, "physical", "", false, false], [5, 6, 0, 0, "named", "", false, false], [8, 9, 0, 0, "named", "", false, false], [32, 32, 34, 34, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pandora", "(", "auch", "bekannt", "als", "Pandora", "Media", "oder", "Pandora", "Radio", ")", "ist", "ein", "amerikanischer", "Internet-Radiodienst", "f\u00fcr", "Musikstreaming", "und", "automatisierte", "Empfehlungssysteme", ",", "der", "vom", "Music", "Genome", "Project", "betrieben", "wird", "und", "seinen", "Hauptsitz", "in", "Oakland", ",", "Kalifornien", "hat", "."], "sentence-detokenized": "Pandora (auch bekannt als Pandora Media oder Pandora Radio) ist ein amerikanischer Internet-Radiodienst f\u00fcr Musikstreaming und automatisierte Empfehlungssysteme, der vom Music Genome Project betrieben wird und seinen Hauptsitz in Oakland, Kalifornien hat.", "token2charspan": [[0, 7], [8, 9], [9, 13], [14, 21], [22, 25], [26, 33], [34, 39], [40, 44], [45, 52], [53, 58], [58, 59], [60, 63], [64, 67], [68, 82], [83, 103], [104, 107], [108, 122], [123, 126], [127, 141], [142, 160], [160, 161], [162, 165], [166, 169], [170, 175], [176, 182], [183, 190], [191, 200], [201, 205], [206, 209], [210, 216], [217, 226], [227, 229], [230, 237], [237, 238], [239, 250], [251, 254], [254, 255]]}
{"doc_key": "ai-test-113", "ner": [[4, 7, "organisation"], [12, 14, "organisation"], [19, 20, "conference"], [29, 29, "conference"], [31, 31, "conference"], [33, 33, "conference"], [35, 35, "conference"], [37, 37, "conference"], [39, 39, "conference"], [41, 41, "conference"], [43, 43, "conference"], [45, 45, "conference"], [47, 47, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sie", "ist", "Vorstandsmitglied", "der", "International", "Machine", "Learning", "Society", ",", "war", "Mitglied", "des", "Exekutivrats", "der", "AAAI", ",", "war", "Co-Vorsitzende", "der", "ICML", "2011", "und", "hat", "als", "leitendes", "PC-Mitglied", "f\u00fcr", "Konferenzen", "wie", "AAAI", ",", "ICML", ",", "IJCAI", ",", "ISWC", ",", "KDD", ",", "SIGMOD", ",", "UAI", ",", "VLDB", ",", "WSDM", "und", "WWW", "gearbeitet", "."], "sentence-detokenized": "Sie ist Vorstandsmitglied der International Machine Learning Society, war Mitglied des Exekutivrats der AAAI, war Co-Vorsitzende der ICML 2011 und hat als leitendes PC-Mitglied f\u00fcr Konferenzen wie AAAI, ICML, IJCAI, ISWC, KDD, SIGMOD, UAI, VLDB, WSDM und WWW gearbeitet.", "token2charspan": [[0, 3], [4, 7], [8, 25], [26, 29], [30, 43], [44, 51], [52, 60], [61, 68], [68, 69], [70, 73], [74, 82], [83, 86], [87, 99], [100, 103], [104, 108], [108, 109], [110, 113], [114, 128], [129, 132], [133, 137], [138, 142], [143, 146], [147, 150], [151, 154], [155, 164], [165, 176], [177, 180], [181, 192], [193, 196], [197, 201], [201, 202], [203, 207], [207, 208], [209, 214], [214, 215], [216, 220], [220, 221], [222, 225], [225, 226], [227, 233], [233, 234], [235, 238], [238, 239], [240, 244], [244, 245], [246, 250], [251, 254], [255, 258], [259, 269], [269, 270]]}
{"doc_key": "ai-test-114", "ner": [[0, 2, "researcher"], [4, 9, "organisation"], [11, 11, "organisation"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 4, 9, "role", "", false, false], [11, 11, 4, 9, "named", "", false, false], [15, 15, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["James", "S.", "Albus", "vom", "National", "Institute", "of", "Standards", "and", "Technology", "(", "NIST", ")", "entwickelte", "den", "Robocrane", ",", "bei", "dem", "die", "Plattform", "an", "sechs", "Kabeln", "h\u00e4ngt", ",", "anstatt", "von", "sechs", "Buchsen", "getragen", "zu", "werden", "."], "sentence-detokenized": "James S. Albus vom National Institute of Standards and Technology (NIST) entwickelte den Robocrane, bei dem die Plattform an sechs Kabeln h\u00e4ngt, anstatt von sechs Buchsen getragen zu werden.", "token2charspan": [[0, 5], [6, 8], [9, 14], [15, 18], [19, 27], [28, 37], [38, 40], [41, 50], [51, 54], [55, 65], [66, 67], [67, 71], [71, 72], [73, 84], [85, 88], [89, 98], [98, 99], [100, 103], [104, 107], [108, 111], [112, 121], [122, 124], [125, 130], [131, 137], [138, 143], [143, 144], [145, 152], [153, 156], [157, 162], [163, 170], [171, 179], [180, 182], [183, 189], [189, 190]]}
{"doc_key": "ai-test-115", "ner": [[3, 4, "algorithm"], [8, 9, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 3, 4, "type-of", "", false, false], [14, 15, 8, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Eine", "weitere", "Klasse", "direkter", "Suchalgorithmen", "sind", "die", "verschiedenen", "evolution\u00e4ren", "Algorithmen", ",", "z.", "B.", "die", "genetischen", "Algorithmen", "."], "sentence-detokenized": "Eine weitere Klasse direkter Suchalgorithmen sind die verschiedenen evolution\u00e4ren Algorithmen, z. B. die genetischen Algorithmen.", "token2charspan": [[0, 4], [5, 12], [13, 19], [20, 28], [29, 44], [45, 49], [50, 53], [54, 67], [68, 81], [82, 93], [93, 94], [95, 97], [98, 100], [101, 104], [105, 116], [117, 128], [128, 129]]}
{"doc_key": "ai-test-116", "ner": [[0, 0, "organisation"], [3, 4, "misc"], [6, 6, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 0, 0, "named", "", false, false], [6, 6, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["KUKA", "ist", "ein", "deutscher", "Hersteller", "von", "Industrierobotern", "und", "L\u00f6sungen", "f\u00fcr", "die", "Fabrikautomation", "."], "sentence-detokenized": "KUKA ist ein deutscher Hersteller von Industrierobotern und L\u00f6sungen f\u00fcr die Fabrikautomation.", "token2charspan": [[0, 4], [5, 8], [9, 12], [13, 22], [23, 33], [34, 37], [38, 55], [56, 59], [60, 68], [69, 72], [73, 76], [77, 93], [93, 94]]}
{"doc_key": "ai-test-117", "ner": [[22, 23, "person"], [14, 20, "misc"], [27, 28, "person"], [25, 25, "misc"], [33, 34, "person"], [30, 31, "misc"], [40, 41, "person"], [36, 38, "misc"], [48, 50, "person"], [43, 46, "misc"], [55, 56, "person"], [52, 58, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[14, 20, 22, 23, "artifact", "", false, false], [25, 25, 27, 28, "artifact", "", false, false], [30, 31, 33, 34, "artifact", "", false, false], [36, 38, 40, 41, "artifact", "", false, false], [43, 46, 48, 50, "artifact", "", false, false], [52, 58, 55, 56, "artifact", "", false, false]], "relations_mapping_to_source": [1, 3, 5, 7, 9, 11], "sentence": ["Weitere", "Filme", ",", "die", "zwischen", "2016", "und", "2020", "mit", "IMAX-Kameras", "aufgenommen", "wurden", ",", "sind", "Batman", "v", "Superman", ":", "Dawn", "of", "Justice", "von", "Zack", "Snyder", ",", "Sully", "von", "Clint", "Eastwood", ",", "First", "Man", "von", "Damien", "Chazelle", ",", "Wonder", "Woman", "1984", "von", "Patty", "Jenkins", ",", "No", "Time", "to", "Die", "von", "Cary", "Joji", "Fukunaga", "und", "Top", "Gun", "von", "Joseph", "Kosinski", ":", "Maverick", "."], "sentence-detokenized": "Weitere Filme, die zwischen 2016 und 2020 mit IMAX-Kameras aufgenommen wurden, sind Batman v Superman: Dawn of Justice von Zack Snyder, Sully von Clint Eastwood, First Man von Damien Chazelle, Wonder Woman 1984 von Patty Jenkins, No Time to Die von Cary Joji Fukunaga und Top Gun von Joseph Kosinski: Maverick.", "token2charspan": [[0, 7], [8, 13], [13, 14], [15, 18], [19, 27], [28, 32], [33, 36], [37, 41], [42, 45], [46, 58], [59, 70], [71, 77], [77, 78], [79, 83], [84, 90], [91, 92], [93, 101], [101, 102], [103, 107], [108, 110], [111, 118], [119, 122], [123, 127], [128, 134], [134, 135], [136, 141], [142, 145], [146, 151], [152, 160], [160, 161], [162, 167], [168, 171], [172, 175], [176, 182], [183, 191], [191, 192], [193, 199], [200, 205], [206, 210], [211, 214], [215, 220], [221, 228], [228, 229], [230, 232], [233, 237], [238, 240], [241, 244], [245, 248], [249, 253], [254, 258], [259, 267], [268, 271], [272, 275], [276, 279], [280, 283], [284, 290], [291, 299], [299, 300], [301, 309], [309, 310]]}
{"doc_key": "ai-test-118", "ner": [[3, 4, "misc"], [7, 9, "organisation"], [11, 11, "organisation"], [28, 29, "country"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[7, 9, 3, 4, "usage", "", false, false], [7, 9, 28, 29, "physical", "", false, false], [11, 11, 7, 9, "named", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Die", "Testversion", "der", "MICR-Schriftart", "E13B", "wurde", "der", "American", "Bankers", "Association", "(", "ABA", ")", "im", "Juli", "1956", "vorgelegt", ",", "die", "sie", "1958", "als", "MICR-Standard", "f\u00fcr", "begebbare", "Dokumente", "in", "den", "Vereinigten", "Staaten", "annahm", "."], "sentence-detokenized": "Die Testversion der MICR-Schriftart E13B wurde der American Bankers Association (ABA) im Juli 1956 vorgelegt, die sie 1958 als MICR-Standard f\u00fcr begebbare Dokumente in den Vereinigten Staaten annahm.", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 35], [36, 40], [41, 46], [47, 50], [51, 59], [60, 67], [68, 79], [80, 81], [81, 84], [84, 85], [86, 88], [89, 93], [94, 98], [99, 108], [108, 109], [110, 113], [114, 117], [118, 122], [123, 126], [127, 140], [141, 144], [145, 154], [155, 164], [165, 167], [168, 171], [172, 183], [184, 191], [192, 198], [198, 199]]}
{"doc_key": "ai-test-119", "ner": [[0, 1, "misc"], [17, 17, "field"], [20, 21, "field"], [24, 24, "field"], [26, 27, "field"], [29, 29, "field"], [31, 31, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[17, 17, 0, 1, "usage", "", false, false], [20, 21, 17, 17, "part-of", "", false, false], [24, 24, 0, 1, "usage", "", false, false], [26, 27, 0, 1, "usage", "", false, false], [29, 29, 0, 1, "usage", "", false, false], [31, 31, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Lokale", "Suchalgorithmen", "werden", "in", "gro\u00dfem", "Umfang", "auf", "zahlreiche", "schwierige", "Rechenprobleme", "angewandt", ",", "darunter", "Probleme", "aus", "den", "Bereichen", "Informatik", "(", "insbesondere", "k\u00fcnstliche", "Intelligenz", ")", ",", "Mathematik", ",", "Operations", "Research", ",", "Ingenieurwesen", "und", "Bioinformatik", "."], "sentence-detokenized": "Lokale Suchalgorithmen werden in gro\u00dfem Umfang auf zahlreiche schwierige Rechenprobleme angewandt, darunter Probleme aus den Bereichen Informatik (insbesondere k\u00fcnstliche Intelligenz), Mathematik, Operations Research, Ingenieurwesen und Bioinformatik.", "token2charspan": [[0, 6], [7, 22], [23, 29], [30, 32], [33, 39], [40, 46], [47, 50], [51, 61], [62, 72], [73, 87], [88, 97], [97, 98], [99, 107], [108, 116], [117, 120], [121, 124], [125, 134], [135, 145], [146, 147], [147, 159], [160, 170], [171, 182], [182, 183], [183, 184], [185, 195], [195, 196], [197, 207], [208, 216], [216, 217], [218, 232], [233, 236], [237, 250], [250, 251]]}
{"doc_key": "ai-test-120", "ner": [[0, 1, "researcher"], [9, 9, "location"], [11, 11, "country"], [15, 15, "country"], [22, 23, "algorithm"], [25, 25, "algorithm"], [28, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 9, 9, "physical", "", false, false], [0, 1, 15, 15, "general-affiliation", "nationality", false, false], [0, 1, 22, 23, "general-affiliation", "topic_of_study", false, false], [0, 1, 25, 25, "general-affiliation", "topic_of_study", false, false], [9, 9, 11, 11, "physical", "", false, false], [25, 25, 28, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gerd", "Gigerenzer", "(", "geboren", "am", "3.", "September", "1947", "in", "Wallersdorf", ",", "Deutschland", ")", "ist", "ein", "deutscher", "Psychologe", ",", "der", "die", "Verwendung", "von", "begrenzter", "Rationalit\u00e4t", "und", "Heuristiken", "bei", "der", "Entscheidungsfindung", "untersucht", "hat", "."], "sentence-detokenized": "Gerd Gigerenzer (geboren am 3. September 1947 in Wallersdorf, Deutschland) ist ein deutscher Psychologe, der die Verwendung von begrenzter Rationalit\u00e4t und Heuristiken bei der Entscheidungsfindung untersucht hat.", "token2charspan": [[0, 4], [5, 15], [16, 17], [17, 24], [25, 27], [28, 30], [31, 40], [41, 45], [46, 48], [49, 60], [60, 61], [62, 73], [73, 74], [75, 78], [79, 82], [83, 92], [93, 103], [103, 104], [105, 108], [109, 112], [113, 123], [124, 127], [128, 138], [139, 151], [152, 155], [156, 167], [168, 171], [172, 175], [176, 196], [197, 207], [208, 211], [211, 212]]}
{"doc_key": "ai-test-121", "ner": [[2, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["um", "den", "mittleren", "quadratischen", "Fehler", "zu", "minimieren", "."], "sentence-detokenized": "um den mittleren quadratischen Fehler zu minimieren.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 30], [31, 37], [38, 40], [41, 51], [51, 52]]}
{"doc_key": "ai-test-122", "ner": [[12, 12, "misc"], [15, 16, "organisation"], [29, 30, "field"], [46, 47, "misc"], [58, 60, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 12, 15, 16, "origin", "", false, false], [46, 47, 58, 60, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Aber", "auch", "eine", "offizielle", "Sprache", "mit", "einer", "regulierenden", "Akademie", ",", "wie", "das", "Standardfranz\u00f6sisch", "mit", "der", "Acad\u00e9mie", "fran\u00e7aise", ",", "wird", "als", "nat\u00fcrliche", "Sprache", "eingestuft", "(", "z.", "B.", "im", "Bereich", "der", "nat\u00fcrlichen", "Sprachverarbeitung", ")", ",", "da", "sie", "aufgrund", "ihrer", "pr\u00e4skriptiven", "Punkte", "weder", "konstruiert", "genug", "ist", ",", "um", "als", "konstruierte", "Sprache", "eingestuft", "zu", "werden", ",", "noch", "kontrolliert", "genug", ",", "um", "als", "kontrollierte", "nat\u00fcrliche", "Sprache", "eingestuft", "zu", "werden", "."], "sentence-detokenized": "Aber auch eine offizielle Sprache mit einer regulierenden Akademie, wie das Standardfranz\u00f6sisch mit der Acad\u00e9mie fran\u00e7aise, wird als nat\u00fcrliche Sprache eingestuft (z. B. im Bereich der nat\u00fcrlichen Sprachverarbeitung), da sie aufgrund ihrer pr\u00e4skriptiven Punkte weder konstruiert genug ist, um als konstruierte Sprache eingestuft zu werden, noch kontrolliert genug, um als kontrollierte nat\u00fcrliche Sprache eingestuft zu werden.", "token2charspan": [[0, 4], [5, 9], [10, 14], [15, 25], [26, 33], [34, 37], [38, 43], [44, 57], [58, 66], [66, 67], [68, 71], [72, 75], [76, 95], [96, 99], [100, 103], [104, 112], [113, 122], [122, 123], [124, 128], [129, 132], [133, 143], [144, 151], [152, 162], [163, 164], [164, 166], [167, 169], [170, 172], [173, 180], [181, 184], [185, 196], [197, 215], [215, 216], [216, 217], [218, 220], [221, 224], [225, 233], [234, 239], [240, 253], [254, 260], [261, 266], [267, 278], [279, 284], [285, 288], [288, 289], [290, 292], [293, 296], [297, 309], [310, 317], [318, 328], [329, 331], [332, 338], [338, 339], [340, 344], [345, 357], [358, 363], [363, 364], [365, 367], [368, 371], [372, 385], [386, 396], [397, 404], [405, 415], [416, 418], [419, 425], [425, 426]]}
{"doc_key": "ai-test-123", "ner": [[11, 11, "metrics"], [13, 14, "metrics"], [16, 16, "metrics"], [35, 36, "metrics"], [38, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[16, 16, 13, 14, "named", "", false, false], [38, 38, 35, 36, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Es", "gibt", "eine", "Reihe", "weiterer", "Metriken", ",", "die", "einfachste", "ist", "die", "Genauigkeit", "oder", "Fraction", "Correct", "(", "FC", ")", ",", "die", "den", "Anteil", "aller", "Instanzen", "misst", ",", "die", "korrekt", "kategorisiert", "wurden", ";", "das", "Komplement", "ist", "die", "Fraction", "Incorrect", "(", "FiC", ")", "."], "sentence-detokenized": "Es gibt eine Reihe weiterer Metriken, die einfachste ist die Genauigkeit oder Fraction Correct (FC), die den Anteil aller Instanzen misst, die korrekt kategorisiert wurden; das Komplement ist die Fraction Incorrect (FiC).", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 18], [19, 27], [28, 36], [36, 37], [38, 41], [42, 52], [53, 56], [57, 60], [61, 72], [73, 77], [78, 86], [87, 94], [95, 96], [96, 98], [98, 99], [99, 100], [101, 104], [105, 108], [109, 115], [116, 121], [122, 131], [132, 137], [137, 138], [139, 142], [143, 150], [151, 164], [165, 171], [171, 172], [173, 176], [177, 187], [188, 191], [192, 195], [196, 204], [205, 214], [215, 216], [216, 219], [219, 220], [220, 221]]}
{"doc_key": "ai-test-124", "ner": [[0, 0, "researcher"], [6, 10, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 10, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cardie", "wurde", "2016", "zum", "Fellow", "der", "Association", "for", "Computational", "Linguistics", "ernannt", "."], "sentence-detokenized": "Cardie wurde 2016 zum Fellow der Association for Computational Linguistics ernannt.", "token2charspan": [[0, 6], [7, 12], [13, 17], [18, 21], [22, 28], [29, 32], [33, 44], [45, 48], [49, 62], [63, 74], [75, 82], [82, 83]]}
{"doc_key": "ai-test-125", "ner": [[13, 13, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Das", "Lernen", "der", "Parameter", "math\\", "theta", "/", "math", "erfolgt", "in", "der", "Regel", "durch", "Maximum-Likelihood-Lernen", "f\u00fcr", "mathp", "(", "Y", "_", "i", "|", "X", "_", "i;\\", "theta", ")", "/", "math", "."], "sentence-detokenized": "Das Lernen der Parameter math\\ theta / math erfolgt in der Regel durch Maximum-Likelihood-Lernen f\u00fcr mathp (Y _ i | X _ i;\\ theta) / math.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 24], [25, 30], [31, 36], [37, 38], [39, 43], [44, 51], [52, 54], [55, 58], [59, 64], [65, 70], [71, 96], [97, 100], [101, 106], [107, 108], [108, 109], [110, 111], [112, 113], [114, 115], [116, 117], [118, 119], [120, 123], [124, 129], [129, 130], [131, 132], [133, 137], [137, 138]]}
{"doc_key": "ai-test-126", "ner": [[0, 0, "task"], [2, 3, "algorithm"], [5, 6, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 0, 0, "usage", "", true, false], [5, 6, 2, 3, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Clusteranalyse", "und", "nicht-negative", "Matrixfaktorisierung", "f\u00fcr", "deskriptives", "Mining", "."], "sentence-detokenized": "Clusteranalyse und nicht-negative Matrixfaktorisierung f\u00fcr deskriptives Mining.", "token2charspan": [[0, 14], [15, 18], [19, 33], [34, 54], [55, 58], [59, 71], [72, 78], [78, 79]]}
{"doc_key": "ai-test-127", "ner": [[2, 2, "field"], [5, 5, "field"], [17, 20, "field"], [22, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[17, 20, 2, 2, "part-of", "", false, false], [17, 20, 5, 5, "part-of", "", false, false], [22, 25, 2, 2, "part-of", "", false, false], [22, 25, 5, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "der", "Informatik", "und", "der", "Informationstechnologie", ",", "die", "sie", "erm\u00f6glicht", ",", "ist", "die", "F\u00e4higkeit", "von", "Computern", ",", "nat\u00fcrliche", "Sprache", "zu", "verarbeiten", "und", "maschinelles", "Lernen", "zu", "betreiben", ",", "eine", "langfristige", "Herausforderung", "."], "sentence-detokenized": "In der Informatik und der Informationstechnologie, die sie erm\u00f6glicht, ist die F\u00e4higkeit von Computern, nat\u00fcrliche Sprache zu verarbeiten und maschinelles Lernen zu betreiben, eine langfristige Herausforderung.", "token2charspan": [[0, 2], [3, 6], [7, 17], [18, 21], [22, 25], [26, 49], [49, 50], [51, 54], [55, 58], [59, 69], [69, 70], [71, 74], [75, 78], [79, 88], [89, 92], [93, 102], [102, 103], [104, 114], [115, 122], [123, 125], [126, 137], [138, 141], [142, 154], [155, 161], [162, 164], [165, 174], [174, 175], [176, 180], [181, 193], [194, 209], [209, 210]]}
{"doc_key": "ai-test-128", "ner": [[5, 7, "algorithm"], [11, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 11, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "Der", "Code", "f\u00fcr", "die", "Extraktion", "von", "Gabor-Merkmalen", "aus", "Bildern", "in", "MATLAB", "findet", "sich", "unter"], "sentence-detokenized": "(Der Code f\u00fcr die Extraktion von Gabor-Merkmalen aus Bildern in MATLAB findet sich unter", "token2charspan": [[0, 1], [1, 4], [5, 9], [10, 13], [14, 17], [18, 28], [29, 32], [33, 48], [49, 52], [53, 60], [61, 63], [64, 70], [71, 77], [78, 82], [83, 88]]}
{"doc_key": "ai-test-129", "ner": [[1, 1, "misc"], [16, 17, "algorithm"], [21, 21, "task"], [23, 23, "task"], [25, 25, "task"], [27, 27, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 1, 16, 17, "general-affiliation", "", false, false], [1, 1, 21, 21, "related-to", "solves_problem_of_type", false, false], [1, 1, 23, 23, "related-to", "solves_problem_of_type", false, false], [1, 1, 25, 25, "related-to", "solves_problem_of_type", false, false], [1, 1, 27, 27, "related-to", "solves_problem_of_type", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Der", "NeuralExpert", "konzentriert", "die", "Entwurfsspezifikationen", "auf", "die", "Art", "des", "Problems", ",", "das", "der", "Benutzer", "mit", "dem", "neuronalen", "Netzwerk", "l\u00f6sen", "m\u00f6chte", "(", "Klassifizierung", ",", "Vorhersage", ",", "Funktionsann\u00e4herung", "oder", "Clusteranalyse", ")", "."], "sentence-detokenized": "Der NeuralExpert konzentriert die Entwurfsspezifikationen auf die Art des Problems, das der Benutzer mit dem neuronalen Netzwerk l\u00f6sen m\u00f6chte (Klassifizierung, Vorhersage, Funktionsann\u00e4herung oder Clusteranalyse).", "token2charspan": [[0, 3], [4, 16], [17, 29], [30, 33], [34, 57], [58, 61], [62, 65], [66, 69], [70, 73], [74, 82], [82, 83], [84, 87], [88, 91], [92, 100], [101, 104], [105, 108], [109, 119], [120, 128], [129, 134], [135, 141], [142, 143], [143, 158], [158, 159], [160, 170], [170, 171], [172, 191], [192, 196], [197, 211], [211, 212], [212, 213]]}
{"doc_key": "ai-test-130", "ner": [[2, 2, "misc"], [25, 27, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Wenn", "die", "Quantisierungsschrittweite", "(", "\u0394", ")", "im", "Verh\u00e4ltnis", "zur", "Variation", "des", "zu", "quantisierenden", "Signals", "klein", "ist", ",", "l\u00e4sst", "sich", "relativ", "einfach", "zeigen", ",", "dass", "der", "mittlere", "quadratische", "Fehler", ",", "der", "durch", "eine", "solche", "Rundungsoperation", "entsteht", ",", "ungef\u00e4hr", "math\\", "Delta", "^", "2", "/", "12", "/", "math.math", "betr\u00e4gt"], "sentence-detokenized": "Wenn die Quantisierungsschrittweite (\u0394) im Verh\u00e4ltnis zur Variation des zu quantisierenden Signals klein ist, l\u00e4sst sich relativ einfach zeigen, dass der mittlere quadratische Fehler, der durch eine solche Rundungsoperation entsteht, ungef\u00e4hr math\\ Delta ^ 2 / 12 / math.math betr\u00e4gt", "token2charspan": [[0, 4], [5, 8], [9, 35], [36, 37], [37, 38], [38, 39], [40, 42], [43, 53], [54, 57], [58, 67], [68, 71], [72, 74], [75, 90], [91, 98], [99, 104], [105, 108], [108, 109], [110, 115], [116, 120], [121, 128], [129, 136], [137, 143], [143, 144], [145, 149], [150, 153], [154, 162], [163, 175], [176, 182], [182, 183], [184, 187], [188, 193], [194, 198], [199, 205], [206, 223], [224, 232], [232, 233], [234, 242], [243, 248], [249, 254], [255, 256], [257, 258], [259, 260], [261, 263], [264, 265], [266, 275], [276, 283]]}
{"doc_key": "ai-test-131", "ner": [[24, 26, "researcher"], [28, 29, "researcher"], [31, 33, "researcher"], [35, 36, "researcher"], [38, 39, "researcher"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Der", "Aufbau", "eines", "umfangreichen", "Lexikons", "mit", "einer", "geeigneten", "Ontologie", "erfordert", "einen", "erheblichen", "Aufwand", ",", "z.", "B.", "erforderte", "das", "Wordnet-Lexikon", "viele", "Personenjahre", "an", "Arbeit", ".", "G.", "A.", "Miller", ",", "R.", "Beckwith", ",", "C.", "D.", "Fellbaum", ",", "D.", "Gross", ",", "K.", "Miller", "."], "sentence-detokenized": "Der Aufbau eines umfangreichen Lexikons mit einer geeigneten Ontologie erfordert einen erheblichen Aufwand, z. B. erforderte das Wordnet-Lexikon viele Personenjahre an Arbeit. G. A. Miller, R. Beckwith, C. D. Fellbaum, D. Gross, K. Miller.", "token2charspan": [[0, 3], [4, 10], [11, 16], [17, 30], [31, 39], [40, 43], [44, 49], [50, 60], [61, 70], [71, 80], [81, 86], [87, 98], [99, 106], [106, 107], [108, 110], [111, 113], [114, 124], [125, 128], [129, 144], [145, 150], [151, 164], [165, 167], [168, 174], [174, 175], [176, 178], [179, 181], [182, 188], [188, 189], [190, 192], [193, 201], [201, 202], [203, 205], [206, 208], [209, 217], [217, 218], [219, 221], [222, 227], [227, 228], [229, 231], [232, 238], [238, 239]]}
{"doc_key": "ai-test-132", "ner": [[3, 3, "organisation"], [22, 23, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[22, 23, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Das", "Portfolio", "von", "Kawasaki", "umfasst", "auch", "einziehbare", "D\u00e4cher", ",", "B\u00f6den", "und", "andere", "riesige", "Strukturen", ",", "wie", "z.", "B.", "die", "einziehbare", "Oberfl\u00e4che", "des", "Sapporo", "Dome", "\"", "."], "sentence-detokenized": "Das Portfolio von Kawasaki umfasst auch einziehbare D\u00e4cher, B\u00f6den und andere riesige Strukturen, wie z. B. die einziehbare Oberfl\u00e4che des Sapporo Dome\".", "token2charspan": [[0, 3], [4, 13], [14, 17], [18, 26], [27, 34], [35, 39], [40, 51], [52, 58], [58, 59], [60, 65], [66, 69], [70, 76], [77, 84], [85, 95], [95, 96], [97, 100], [101, 103], [104, 106], [107, 110], [111, 122], [123, 133], [134, 137], [138, 145], [146, 150], [150, 151], [151, 152]]}
{"doc_key": "ai-test-133", "ner": [[0, 0, "metrics"], [2, 3, "metrics"], [5, 6, "metrics"], [12, 12, "metrics"], [30, 30, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 12, 12, "related-to", "", false, false], [0, 0, 30, 30, "opposite", "alternative_to", false, false], [2, 3, 0, 0, "type-of", "", false, false], [5, 6, 0, 0, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kappa-Statistiken", "wie", "Fleiss'", "Kappa", "und", "Cohen's", "Kappa", "sind", "Methoden", "zur", "Berechnung", "der", "Inter-Rater-Reliabilit\u00e4t", ",", "die", "auf", "unterschiedlichen", "Annahmen", "\u00fcber", "die", "Rand-", "oder", "Vorverteilungen", "beruhen", "und", "zunehmend", "als", "zufallsbereinigte", "Alternativen", "zur", "Genauigkeit", "in", "anderen", "Zusammenh\u00e4ngen", "verwendet", "werden", "."], "sentence-detokenized": "Kappa-Statistiken wie Fleiss' Kappa und Cohen's Kappa sind Methoden zur Berechnung der Inter-Rater-Reliabilit\u00e4t, die auf unterschiedlichen Annahmen \u00fcber die Rand- oder Vorverteilungen beruhen und zunehmend als zufallsbereinigte Alternativen zur Genauigkeit in anderen Zusammenh\u00e4ngen verwendet werden.", "token2charspan": [[0, 17], [18, 21], [22, 29], [30, 35], [36, 39], [40, 47], [48, 53], [54, 58], [59, 67], [68, 71], [72, 82], [83, 86], [87, 111], [111, 112], [113, 116], [117, 120], [121, 138], [139, 147], [148, 152], [153, 156], [157, 162], [163, 167], [168, 183], [184, 191], [192, 195], [196, 205], [206, 209], [210, 227], [228, 240], [241, 244], [245, 256], [257, 259], [260, 267], [268, 282], [283, 292], [293, 299], [299, 300]]}
{"doc_key": "ai-test-134", "ner": [[4, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [18, 18, "researcher"], [23, 25, "algorithm"], [32, 34, "algorithm"], [30, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 18, 18, "role", "student_of", false, false], [7, 8, 18, 18, "role", "student_of", false, false], [10, 11, 18, 18, "role", "student_of", false, false], [13, 14, 18, 18, "role", "student_of", false, false], [32, 34, 4, 5, "origin", "", false, false], [32, 34, 7, 8, "origin", "", false, false], [32, 34, 10, 11, "origin", "", false, false], [32, 34, 13, 14, "origin", "", false, false], [32, 34, 18, 18, "origin", "", false, false], [32, 34, 23, 25, "type-of", "", false, false], [30, 30, 32, 34, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Zusammen", "mit", "seinen", "Studenten", "Sepp", "Hochreiter", ",", "Felix", "Gers", ",", "Fred", "Cummins", ",", "Alex", "Graves", "und", "anderen", "ver\u00f6ffentlichte", "Schmidhuber", "immer", "ausgefeiltere", "Versionen", "eines", "rekurrenten", "neuronalen", "Netzes", ",", "des", "so", "genannten", "LSTM", "(", "Long", "Short", "Memory", ")", "."], "sentence-detokenized": "Zusammen mit seinen Studenten Sepp Hochreiter, Felix Gers, Fred Cummins, Alex Graves und anderen ver\u00f6ffentlichte Schmidhuber immer ausgefeiltere Versionen eines rekurrenten neuronalen Netzes, des so genannten LSTM (Long Short Memory).", "token2charspan": [[0, 8], [9, 12], [13, 19], [20, 29], [30, 34], [35, 45], [45, 46], [47, 52], [53, 57], [57, 58], [59, 63], [64, 71], [71, 72], [73, 77], [78, 84], [85, 88], [89, 96], [97, 112], [113, 124], [125, 130], [131, 144], [145, 154], [155, 160], [161, 172], [173, 183], [184, 190], [190, 191], [192, 195], [196, 198], [199, 208], [209, 213], [214, 215], [215, 219], [220, 225], [226, 232], [232, 233], [233, 234]]}
{"doc_key": "ai-test-135", "ner": [[4, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2004", "-", "Der", "erste", "Cobot", "KUKA", "LBR", "3", "kommt", "auf", "den", "Markt", "."], "sentence-detokenized": "2004 - Der erste Cobot KUKA LBR 3 kommt auf den Markt.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 16], [17, 22], [23, 27], [28, 31], [32, 33], [34, 39], [40, 43], [44, 47], [48, 53], [53, 54]]}
{"doc_key": "ai-test-136", "ner": [[14, 15, "algorithm"], [17, 17, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Zwei", "oberfl\u00e4chliche", "Ans\u00e4tze", ",", "die", "zum", "Trainieren", "und", "anschlie\u00dfenden", "Disambiguieren", "verwendet", "werden", ",", "sind", "Naive", "Bayes-Klassifikatoren", "und", "Entscheidungsb\u00e4ume", "."], "sentence-detokenized": "Zwei oberfl\u00e4chliche Ans\u00e4tze, die zum Trainieren und anschlie\u00dfenden Disambiguieren verwendet werden, sind Naive Bayes-Klassifikatoren und Entscheidungsb\u00e4ume.", "token2charspan": [[0, 4], [5, 19], [20, 27], [27, 28], [29, 32], [33, 36], [37, 47], [48, 51], [52, 66], [67, 81], [82, 91], [92, 98], [98, 99], [100, 104], [105, 110], [111, 132], [133, 136], [137, 155], [155, 156]]}
{"doc_key": "ai-test-137", "ner": [[5, 5, "misc"], [11, 12, "person"], [14, 16, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 11, 12, "origin", "", false, false], [5, 5, 14, 16, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Die", "ersten", "praktischen", "Formen", "der", "Fotografie", "wurden", "im", "Januar", "1839", "von", "Louis", "Daguerre", "und", "Henry", "Fox", "Talbot", "eingef\u00fchrt", "."], "sentence-detokenized": "Die ersten praktischen Formen der Fotografie wurden im Januar 1839 von Louis Daguerre und Henry Fox Talbot eingef\u00fchrt.", "token2charspan": [[0, 3], [4, 10], [11, 22], [23, 29], [30, 33], [34, 44], [45, 51], [52, 54], [55, 61], [62, 66], [67, 70], [71, 76], [77, 85], [86, 89], [90, 95], [96, 99], [100, 106], [107, 117], [117, 118]]}
{"doc_key": "ai-test-138", "ner": [[4, 5, "task"], [9, 9, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["So", "erm\u00f6glicht", "beispielsweise", "die", "Sprachsynthese", "in", "Verbindung", "mit", "der", "Spracherkennung", "die", "Interaktion", "mit", "mobilen", "Ger\u00e4ten", "\u00fcber", "Sprachverarbeitungsschnittstellen", "."], "sentence-detokenized": "So erm\u00f6glicht beispielsweise die Sprachsynthese in Verbindung mit der Spracherkennung die Interaktion mit mobilen Ger\u00e4ten \u00fcber Sprachverarbeitungsschnittstellen.", "token2charspan": [[0, 2], [3, 13], [14, 28], [29, 32], [33, 47], [48, 50], [51, 61], [62, 65], [66, 69], [70, 85], [86, 89], [90, 101], [102, 105], [106, 113], [114, 121], [122, 126], [127, 160], [160, 161]]}
{"doc_key": "ai-test-139", "ner": [[0, 0, "product"], [14, 14, "programlang"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 14, 14, "general-affiliation", "", false, false], [0, 0, 16, 17, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Phidgets", "k\u00f6nnen", "mit", "einer", "Vielzahl", "von", "Software", "und", "Programmiersprachen", "programmiert", "werden", ",", "die", "von", "Java", "bis", "Microsoft", "Excel", "reichen", "."], "sentence-detokenized": "Phidgets k\u00f6nnen mit einer Vielzahl von Software und Programmiersprachen programmiert werden, die von Java bis Microsoft Excel reichen.", "token2charspan": [[0, 8], [9, 15], [16, 19], [20, 25], [26, 34], [35, 38], [39, 47], [48, 51], [52, 71], [72, 84], [85, 91], [91, 92], [93, 96], [97, 100], [101, 105], [106, 109], [110, 119], [120, 125], [126, 133], [133, 134]]}
{"doc_key": "ai-test-140", "ner": [[2, 3, "field"], [7, 8, "researcher"], [12, 13, "misc"], [20, 20, "field"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 7, 8, "origin", "", false, false], [7, 8, 20, 20, "general-affiliation", "topic_of_study", false, false], [7, 8, 23, 24, "general-affiliation", "topic_of_study", false, false], [12, 13, 7, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Der", "Begriff", "maschinelles", "Lernen", "wurde", "1959", "von", "Arthur", "Samuel", "gepr\u00e4gt", ",", "einem", "amerikanischen", "IBM-Mitarbeiter", "und", "Pionier", "auf", "dem", "Gebiet", "der", "Computerspiele", "und", "der", "k\u00fcnstlichen", "Intelligenz", "."], "sentence-detokenized": "Der Begriff maschinelles Lernen wurde 1959 von Arthur Samuel gepr\u00e4gt, einem amerikanischen IBM-Mitarbeiter und Pionier auf dem Gebiet der Computerspiele und der k\u00fcnstlichen Intelligenz.", "token2charspan": [[0, 3], [4, 11], [12, 24], [25, 31], [32, 37], [38, 42], [43, 46], [47, 53], [54, 60], [61, 68], [68, 69], [70, 75], [76, 90], [91, 106], [107, 110], [111, 118], [119, 122], [123, 126], [127, 133], [134, 137], [138, 152], [153, 156], [157, 160], [161, 172], [173, 184], [184, 185]]}
{"doc_key": "ai-test-141", "ner": [[1, 2, "misc"], [3, 4, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 1, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Der", "israelische", "Dichter", "David", "Avidan", ",", "der", "von", "Zukunftstechnologien", "und", "ihrem", "Verh\u00e4ltnis", "zur", "Kunst", "fasziniert", "war", ",", "wollte", "die", "Verwendung", "von", "Computern", "zum", "Schreiben", "von", "Literatur", "erforschen", "."], "sentence-detokenized": "Der israelische Dichter David Avidan, der von Zukunftstechnologien und ihrem Verh\u00e4ltnis zur Kunst fasziniert war, wollte die Verwendung von Computern zum Schreiben von Literatur erforschen.", "token2charspan": [[0, 3], [4, 15], [16, 23], [24, 29], [30, 36], [36, 37], [38, 41], [42, 45], [46, 66], [67, 70], [71, 76], [77, 87], [88, 91], [92, 97], [98, 108], [109, 112], [112, 113], [114, 120], [121, 124], [125, 135], [136, 139], [140, 149], [150, 153], [154, 163], [164, 167], [168, 177], [178, 188], [188, 189]]}
{"doc_key": "ai-test-142", "ner": [[0, 3, "misc"], [5, 5, "organisation"], [11, 11, "location"], [23, 23, "location"], [24, 24, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 5, 0, 3, "part-of", "", false, false], [24, 24, 23, 23, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Im", "Rahmen", "des", "GATEway-Projekts", "testete", "Oxbotica", "2017", "sieben", "autonome", "Shuttlebusse", "in", "Greenwich", ",", "die", "einen", "zwei", "Meilen", "langen", "Uferweg", "in", "der", "N\u00e4he", "der", "Londoner", "O2-Arena", "befuhren", ",", "der", "auch", "von", "Fu\u00dfg\u00e4ngern", "und", "Radfahrern", "genutzt", "wird", "."], "sentence-detokenized": "Im Rahmen des GATEway-Projekts testete Oxbotica 2017 sieben autonome Shuttlebusse in Greenwich, die einen zwei Meilen langen Uferweg in der N\u00e4he der Londoner O2-Arena befuhren, der auch von Fu\u00dfg\u00e4ngern und Radfahrern genutzt wird.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 30], [31, 38], [39, 47], [48, 52], [53, 59], [60, 68], [69, 81], [82, 84], [85, 94], [94, 95], [96, 99], [100, 105], [106, 110], [111, 117], [118, 124], [125, 132], [133, 135], [136, 139], [140, 144], [145, 148], [149, 157], [158, 166], [167, 175], [175, 176], [177, 180], [181, 185], [186, 189], [190, 200], [201, 204], [205, 215], [216, 223], [224, 228], [228, 229]]}
{"doc_key": "ai-test-143", "ner": [[12, 13, "task"], [16, 16, "metrics"], [23, 24, "misc"], [26, 26, "metrics"], [28, 28, "metrics"], [31, 31, "metrics"], [33, 33, "metrics"], [35, 38, "metrics"], [40, 40, "metrics"], [42, 42, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[16, 16, 23, 24, "related-to", "is_a", false, false], [16, 16, 26, 26, "usage", "", false, false], [16, 16, 28, 28, "usage", "", false, false], [26, 26, 31, 31, "named", "same", false, false], [28, 28, 42, 42, "named", "same", false, false], [31, 31, 40, 40, "opposite", "", false, false], [31, 31, 42, 42, "opposite", "", false, false], [33, 33, 31, 31, "named", "", false, false], [35, 38, 31, 31, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Eine", "nicht", "verwandte", ",", "aber", "h\u00e4ufig", "verwendete", "Kombination", "grundlegender", "Statistiken", "aus", "dem", "Information", "Retrieval", "ist", "der", "F-Score", ",", "ein", "(", "m\u00f6glicherweise", "gewichtetes", ")", "harmonisches", "Mittel", "aus", "Recall", "und", "Precision", ",", "wobei", "Recall", "=", "Sensitivit\u00e4t", "=", "TRUE", "positive", "Rate", "ist", ",", "Spezifit\u00e4t", "und", "Precision", "aber", "v\u00f6llig", "unterschiedliche", "Ma\u00dfe", "sind", "."], "sentence-detokenized": "Eine nicht verwandte, aber h\u00e4ufig verwendete Kombination grundlegender Statistiken aus dem Information Retrieval ist der F-Score, ein (m\u00f6glicherweise gewichtetes) harmonisches Mittel aus Recall und Precision, wobei Recall = Sensitivit\u00e4t = TRUE positive Rate ist, Spezifit\u00e4t und Precision aber v\u00f6llig unterschiedliche Ma\u00dfe sind.", "token2charspan": [[0, 4], [5, 10], [11, 20], [20, 21], [22, 26], [27, 33], [34, 44], [45, 56], [57, 70], [71, 82], [83, 86], [87, 90], [91, 102], [103, 112], [113, 116], [117, 120], [121, 128], [128, 129], [130, 133], [134, 135], [135, 149], [150, 161], [161, 162], [163, 175], [176, 182], [183, 186], [187, 193], [194, 197], [198, 207], [207, 208], [209, 214], [215, 221], [222, 223], [224, 236], [237, 238], [239, 243], [244, 252], [253, 257], [258, 261], [261, 262], [263, 273], [274, 277], [278, 287], [288, 292], [293, 299], [300, 316], [317, 321], [322, 326], [326, 327]]}
{"doc_key": "ai-test-144", "ner": [[0, 1, "field"], [10, 10, "field"], [12, 12, "field"], [14, 14, "field"], [16, 16, "field"], [18, 18, "field"], [27, 27, "product"], [29, 29, "product"], [31, 31, "product"], [33, 34, "product"], [45, 47, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 10, "origin", "takes_inspiration_from", false, false], [0, 1, 12, 12, "origin", "takes_inspiration_from", false, false], [0, 1, 14, 14, "origin", "takes_inspiration_from", false, false], [0, 1, 16, 16, "origin", "takes_inspiration_from", false, false], [0, 1, 18, 18, "origin", "takes_inspiration_from", false, false], [27, 27, 0, 1, "origin", "", false, false], [29, 29, 0, 1, "origin", "", false, false], [31, 31, 0, 1, "origin", "", false, false], [33, 34, 0, 1, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Neuromorphes", "Engineering", "ist", "ein", "interdisziplin\u00e4res", "Fachgebiet", ",", "das", "sich", "von", "Biologie", ",", "Physik", ",", "Mathematik", ",", "Informatik", "und", "Elektrotechnik", "inspirieren", "l\u00e4sst", ",", "um", "k\u00fcnstliche", "neuronale", "Systeme", "wie", "Sehsysteme", ",", "Kopf-Augen-Systeme", ",", "H\u00f6rprozessoren", "und", "autonome", "Roboter", "zu", "entwickeln", ",", "deren", "physikalische", "Architektur", "und", "Konstruktionsprinzipien", "auf", "denen", "biologischer", "Nervensysteme", "basieren", "."], "sentence-detokenized": "Neuromorphes Engineering ist ein interdisziplin\u00e4res Fachgebiet, das sich von Biologie, Physik, Mathematik, Informatik und Elektrotechnik inspirieren l\u00e4sst, um k\u00fcnstliche neuronale Systeme wie Sehsysteme, Kopf-Augen-Systeme, H\u00f6rprozessoren und autonome Roboter zu entwickeln, deren physikalische Architektur und Konstruktionsprinzipien auf denen biologischer Nervensysteme basieren.", "token2charspan": [[0, 12], [13, 24], [25, 28], [29, 32], [33, 51], [52, 62], [62, 63], [64, 67], [68, 72], [73, 76], [77, 85], [85, 86], [87, 93], [93, 94], [95, 105], [105, 106], [107, 117], [118, 121], [122, 136], [137, 148], [149, 154], [154, 155], [156, 158], [159, 169], [170, 179], [180, 187], [188, 191], [192, 202], [202, 203], [204, 222], [222, 223], [224, 238], [239, 242], [243, 251], [252, 259], [260, 262], [263, 273], [273, 274], [275, 280], [281, 294], [295, 306], [307, 310], [311, 334], [335, 338], [339, 344], [345, 357], [358, 371], [372, 380], [380, 381]]}
{"doc_key": "ai-test-145", "ner": [[3, 3, "metrics"], [7, 7, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 7, 3, 3, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Konkret", "verlangt", "das", "BIBO-Stabilit\u00e4tskriterium", ",", "dass", "die", "ROC", "des", "Systems", "den", "Einheitskreis", "umfasst", "."], "sentence-detokenized": "Konkret verlangt das BIBO-Stabilit\u00e4tskriterium, dass die ROC des Systems den Einheitskreis umfasst.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 46], [46, 47], [48, 52], [53, 56], [57, 60], [61, 64], [65, 72], [73, 76], [77, 90], [91, 98], [98, 99]]}
{"doc_key": "ai-test-146", "ner": [[7, 7, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2", "Das", "Programm", "wurde", "ab", "1998", "in", "Java", "neu", "geschrieben", "."], "sentence-detokenized": "2 Das Programm wurde ab 1998 in Java neu geschrieben.", "token2charspan": [[0, 1], [2, 5], [6, 14], [15, 20], [21, 23], [24, 28], [29, 31], [32, 36], [37, 40], [41, 52], [52, 53]]}
{"doc_key": "ai-test-147", "ner": [[1, 1, "metrics"], [6, 6, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 1, 6, 6, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Der", "MCC", "kann", "direkt", "aus", "der", "Konfusionsmatrix", "mit", "Hilfe", "der", "folgenden", "Formel", "berechnet", "werden", ":"], "sentence-detokenized": "Der MCC kann direkt aus der Konfusionsmatrix mit Hilfe der folgenden Formel berechnet werden:", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 19], [20, 23], [24, 27], [28, 44], [45, 48], [49, 54], [55, 58], [59, 68], [69, 75], [76, 85], [86, 92], [92, 93]]}
{"doc_key": "ai-test-148", "ner": [[6, 9, "organisation"], [15, 20, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 9, 15, 20, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Es", "wurde", "von", "einem", "Team", "des", "MIT-IBM", "Watson", "AI", "Lab", "entwickelt", "und", "erstmals", "auf", "der", "International", "Conference", "on", "Learning", "Representations", "2018", "vorgestellt", "."], "sentence-detokenized": "Es wurde von einem Team des MIT-IBM Watson AI Lab entwickelt und erstmals auf der International Conference on Learning Representations 2018 vorgestellt.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 18], [19, 23], [24, 27], [28, 35], [36, 42], [43, 45], [46, 49], [50, 60], [61, 64], [65, 73], [74, 77], [78, 81], [82, 95], [96, 106], [107, 109], [110, 118], [119, 134], [135, 139], [140, 151], [151, 152]]}
{"doc_key": "ai-test-149", "ner": [[2, 2, "metrics"], [13, 14, "metrics"], [16, 16, "metrics"], [49, 50, "metrics"], [53, 53, "metrics"], [55, 55, "metrics"], [57, 57, "metrics"], [62, 62, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 5, 6, 7, 8, 9], "relations": [[13, 14, 49, 50, "related-to", "collapses_to_identity", false, false], [16, 16, 49, 50, "related-to", "collapses_to_identity", false, false], [16, 16, 57, 57, "named", "same", false, false], [53, 53, 62, 62, "related-to", "collapses_to_identity", false, false], [55, 55, 62, 62, "related-to", "collapses_to_identity", false, false], [57, 57, 62, 62, "related-to", "collapses_to_identity", false, false]], "relations_mapping_to_source": [1, 3, 4, 5, 6, 7], "sentence": ["Wenn", "die", "TRUE-Pr\u00e4valenzen", "f\u00fcr", "die", "beiden", "positiven", "Variablen", "gleich", "sind", ",", "wie", "in", "Fleiss", "kappa", "und", "F-score", "angenommen", ",", "d.h.", "die", "Anzahl", "der", "positiven", "Vorhersagen", "entspricht", "der", "Anzahl", "der", "positiven", "Klassen", "im", "dichotomen", "(", "Zweiklassen-", ")", "Fall", ",", "dann", "kollabieren", "die", "verschiedenen", "Kappa-", "und", "Korrelationsma\u00dfe", "und", "sind", "identisch", "mit", "Youden's", "J", ",", "und", "recall", ",", "precision", "und", "F-score", "sind", "ebenfalls", "identisch", "mit", "accuracy", "."], "sentence-detokenized": "Wenn die TRUE-Pr\u00e4valenzen f\u00fcr die beiden positiven Variablen gleich sind, wie in Fleiss kappa und F-score angenommen, d.h. die Anzahl der positiven Vorhersagen entspricht der Anzahl der positiven Klassen im dichotomen (Zweiklassen-) Fall, dann kollabieren die verschiedenen Kappa- und Korrelationsma\u00dfe und sind identisch mit Youden's J, und recall, precision und F-score sind ebenfalls identisch mit accuracy.", "token2charspan": [[0, 4], [5, 8], [9, 25], [26, 29], [30, 33], [34, 40], [41, 50], [51, 60], [61, 67], [68, 72], [72, 73], [74, 77], [78, 80], [81, 87], [88, 93], [94, 97], [98, 105], [106, 116], [116, 117], [118, 122], [123, 126], [127, 133], [134, 137], [138, 147], [148, 159], [160, 170], [171, 174], [175, 181], [182, 185], [186, 195], [196, 203], [204, 206], [207, 217], [218, 219], [219, 231], [231, 232], [233, 237], [237, 238], [239, 243], [244, 255], [256, 259], [260, 273], [274, 280], [281, 284], [285, 301], [302, 305], [306, 310], [311, 320], [321, 324], [325, 333], [334, 335], [335, 336], [337, 340], [341, 347], [347, 348], [349, 358], [359, 362], [363, 370], [371, 375], [376, 385], [386, 395], [396, 399], [400, 408], [408, 409]]}
{"doc_key": "ai-test-150", "ner": [[1, 4, "misc"], [6, 6, "misc"], [10, 10, "conference"], [16, 18, "task"], [19, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 4, 10, 10, "part-of", "", false, false], [1, 4, 10, 10, "physical", "", false, false], [1, 4, 10, 10, "temporal", "", false, false], [6, 6, 1, 4, "named", "", false, false], [16, 18, 1, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Der", "Workshop", "Building", "Educational", "Applications", "(", "BEA", ")", "auf", "der", "NAACL", "2013", "war", "Gastgeber", "der", "ersten", "gemeinsamen", "NLI-Aufgabe", ".", "Tetreault", "et", "al.", ",", "2013", "Der", "Wettbewerb", "f\u00fchrte", "zu", "29", "Beitr\u00e4gen", "von", "Teams", "aus", "der", "ganzen", "Welt", ",", "von", "denen", "24", "auch", "ein", "Papier", "zur", "Beschreibung", "ihrer", "Systeme", "und", "Ans\u00e4tze", "ver\u00f6ffentlichten", "."], "sentence-detokenized": "Der Workshop Building Educational Applications (BEA) auf der NAACL 2013 war Gastgeber der ersten gemeinsamen NLI-Aufgabe. Tetreault et al., 2013 Der Wettbewerb f\u00fchrte zu 29 Beitr\u00e4gen von Teams aus der ganzen Welt, von denen 24 auch ein Papier zur Beschreibung ihrer Systeme und Ans\u00e4tze ver\u00f6ffentlichten.", "token2charspan": [[0, 3], [4, 12], [13, 21], [22, 33], [34, 46], [47, 48], [48, 51], [51, 52], [53, 56], [57, 60], [61, 66], [67, 71], [72, 75], [76, 85], [86, 89], [90, 96], [97, 108], [109, 120], [120, 121], [122, 131], [132, 134], [135, 138], [138, 139], [140, 144], [145, 148], [149, 159], [160, 166], [167, 169], [170, 172], [173, 182], [183, 186], [187, 192], [193, 196], [197, 200], [201, 207], [208, 212], [212, 213], [214, 217], [218, 223], [224, 226], [227, 231], [232, 235], [236, 242], [243, 246], [247, 259], [260, 265], [266, 273], [274, 277], [278, 285], [286, 302], [302, 303]]}
{"doc_key": "ai-test-151", "ner": [[1, 1, "algorithm"], [4, 5, "algorithm"], [12, 13, "misc"], [18, 18, "misc"], [35, 35, "algorithm"], [38, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6], "relations": [[1, 1, 4, 5, "type-of", "", false, false], [1, 1, 12, 13, "related-to", "finds", false, false], [18, 18, 12, 13, "type-of", "", false, false], [38, 38, 35, 35, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Der", "Viterbi-Algorithmus", "ist", "ein", "dynamischer", "Programmieralgorithmus", "zur", "Ermittlung", "der", "wahrscheinlichsten", "Folge", "von", "verborgenen", "Zust\u00e4nden", ",", "dem", "so", "genannten", "Viterbi-Pfad", ",", "der", "zu", "einer", "Folge", "von", "beobachteten", "Ereignissen", "f\u00fchrt", ",", "insbesondere", "im", "Zusammenhang", "mit", "Markov-Informationsquellen", "und", "verborgenen", "Markov-Modellen", "(", "HMM", ")", "."], "sentence-detokenized": "Der Viterbi-Algorithmus ist ein dynamischer Programmieralgorithmus zur Ermittlung der wahrscheinlichsten Folge von verborgenen Zust\u00e4nden, dem so genannten Viterbi-Pfad, der zu einer Folge von beobachteten Ereignissen f\u00fchrt, insbesondere im Zusammenhang mit Markov-Informationsquellen und verborgenen Markov-Modellen (HMM).", "token2charspan": [[0, 3], [4, 23], [24, 27], [28, 31], [32, 43], [44, 66], [67, 70], [71, 81], [82, 85], [86, 104], [105, 110], [111, 114], [115, 126], [127, 136], [136, 137], [138, 141], [142, 144], [145, 154], [155, 167], [167, 168], [169, 172], [173, 175], [176, 181], [182, 187], [188, 191], [192, 204], [205, 216], [217, 222], [222, 223], [224, 236], [237, 239], [240, 252], [253, 256], [257, 283], [284, 287], [288, 299], [300, 315], [316, 317], [317, 320], [320, 321], [321, 322]]}
{"doc_key": "ai-test-152", "ner": [[2, 2, "field"], [5, 8, "algorithm"], [9, 9, "misc"], [13, 14, "algorithm"], [17, 20, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 8, 2, 2, "part-of", "", false, false], [5, 8, 9, 9, "general-affiliation", "", false, false], [5, 8, 13, 14, "related-to", "generalizes_from", false, false], [5, 8, 17, 20, "related-to", "generalizes_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "der", "Statistik", "ist", "die", "multinomiale", "logistische", "Regression", "eine", "Klassifizierungsmethode", ",", "die", "die", "logistische", "Regression", "auf", "die", "Klassifizierung", "in", "mehreren", "Klassen", "verallgemeinert", ",", "d.", "h.", "mit", "mehr", "als", "zwei", "m\u00f6glichen", "diskreten", "Ergebnissen", "."], "sentence-detokenized": "In der Statistik ist die multinomiale logistische Regression eine Klassifizierungsmethode, die die logistische Regression auf die Klassifizierung in mehreren Klassen verallgemeinert, d. h. mit mehr als zwei m\u00f6glichen diskreten Ergebnissen.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 20], [21, 24], [25, 37], [38, 49], [50, 60], [61, 65], [66, 89], [89, 90], [91, 94], [95, 98], [99, 110], [111, 121], [122, 125], [126, 129], [130, 145], [146, 148], [149, 157], [158, 165], [166, 181], [181, 182], [183, 185], [186, 188], [189, 192], [193, 197], [198, 201], [202, 206], [207, 216], [217, 226], [227, 238], [238, 239]]}
{"doc_key": "ai-test-153", "ner": [[0, 1, "algorithm"], [9, 9, "field"], [12, 13, "field"], [18, 18, "task"], [20, 20, "task"], [22, 22, "task"], [24, 25, "researcher"], [27, 28, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 9, 9, "part-of", "", false, false], [0, 1, 12, 13, "part-of", "", false, false], [18, 18, 0, 1, "usage", "", true, false], [20, 20, 0, 1, "usage", "", true, false], [22, 22, 0, 1, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hidden-Markov-Modelle", "sind", "bekannt", "f\u00fcr", "ihre", "Anwendungen", "im", "Bereich", "des", "Verst\u00e4rkungslernens", "und", "der", "zeitlichen", "Mustererkennung", ",", "wie", "z.", "B.", "Sprache", ",", "Handschrifterkennung", ",", "Gestenerkennung", ",", "Thad", "Starner", ",", "Alex", "Pentland", "."], "sentence-detokenized": "Hidden-Markov-Modelle sind bekannt f\u00fcr ihre Anwendungen im Bereich des Verst\u00e4rkungslernens und der zeitlichen Mustererkennung, wie z. B. Sprache, Handschrifterkennung, Gestenerkennung, Thad Starner, Alex Pentland.", "token2charspan": [[0, 21], [22, 26], [27, 34], [35, 38], [39, 43], [44, 55], [56, 58], [59, 66], [67, 70], [71, 90], [91, 94], [95, 98], [99, 109], [110, 125], [125, 126], [127, 130], [131, 133], [134, 136], [137, 144], [144, 145], [146, 166], [166, 167], [168, 183], [183, 184], [185, 189], [190, 197], [197, 198], [199, 203], [204, 212], [212, 213]]}
{"doc_key": "ai-test-154", "ner": [[16, 16, "metrics"], [18, 19, "misc"]], "ner_mapping_to_source": [1, 2], "relations": [[16, 16, 18, 19, "related-to", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Im", "Wesentlichen", "bedeutet", "dies", ",", "dass", "die", "bedingte", "Wahrscheinlichkeit", "eines", "Wortes", "angesichts", "seiner", "Geschichte", "proportional", "zur", "Maximum-Likelihood-Sch\u00e4tzung", "diesesn", "-Gramms", "ist", ",", "wenn", "es", "im", "Training", "mehr", "als", "k", "Mal", "gesehen", "wurde", "."], "sentence-detokenized": "Im Wesentlichen bedeutet dies, dass die bedingte Wahrscheinlichkeit eines Wortes angesichts seiner Geschichte proportional zur Maximum-Likelihood-Sch\u00e4tzung diesesn -Gramms ist, wenn es im Training mehr als k Mal gesehen wurde.", "token2charspan": [[0, 2], [3, 15], [16, 24], [25, 29], [29, 30], [31, 35], [36, 39], [40, 48], [49, 67], [68, 73], [74, 80], [81, 91], [92, 98], [99, 109], [110, 122], [123, 126], [127, 155], [156, 163], [164, 171], [172, 175], [175, 176], [177, 181], [182, 184], [185, 187], [188, 196], [197, 201], [202, 205], [206, 207], [208, 211], [212, 219], [220, 225], [225, 226]]}
{"doc_key": "ai-test-155", "ner": [[4, 4, "task"], [7, 8, "task"], [11, 13, "task"], [22, 23, "task"], [28, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[28, 29, 22, 23, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Sein", "Interesse", "gilt", "der", "Wissensrepr\u00e4sentation", ",", "dem", "logischen", "Denken", "und", "dem", "Verstehen", "nat\u00fcrlicher", "Sprache", ".", "Er", "ist", "der", "Meinung", ",", "dass", "ein", "tiefes", "Sprachverst\u00e4ndnis", "derzeit", "nur", "durch", "die", "manuelle", "Entwicklung", "von", "semantisch", "reichhaltigen", "Formalismen", "in", "Verbindung", "mit", "statistischen", "Pr\u00e4ferenzen", "erreicht", "werden", "kann", "."], "sentence-detokenized": "Sein Interesse gilt der Wissensrepr\u00e4sentation, dem logischen Denken und dem Verstehen nat\u00fcrlicher Sprache. Er ist der Meinung, dass ein tiefes Sprachverst\u00e4ndnis derzeit nur durch die manuelle Entwicklung von semantisch reichhaltigen Formalismen in Verbindung mit statistischen Pr\u00e4ferenzen erreicht werden kann.", "token2charspan": [[0, 4], [5, 14], [15, 19], [20, 23], [24, 45], [45, 46], [47, 50], [51, 60], [61, 67], [68, 71], [72, 75], [76, 85], [86, 97], [98, 105], [105, 106], [107, 109], [110, 113], [114, 117], [118, 125], [125, 126], [127, 131], [132, 135], [136, 142], [143, 160], [161, 168], [169, 172], [173, 178], [179, 182], [183, 191], [192, 203], [204, 207], [208, 218], [219, 232], [233, 244], [245, 247], [248, 258], [259, 262], [263, 276], [277, 288], [289, 297], [298, 304], [305, 309], [309, 310]]}
{"doc_key": "ai-test-156", "ner": [[1, 1, "programlang"], [3, 3, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "JavaScript", ",", "Python", "oder"], "sentence-detokenized": "In JavaScript, Python oder", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 21], [22, 26]]}
{"doc_key": "ai-test-157", "ner": [[1, 2, "misc"], [10, 11, "misc"], [8, 8, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 10, 11, "part-of", "", false, false], [10, 11, 8, 8, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Die", "Newcomb", "Awards", "werden", "in", "dem", "von", "der", "AAAI", "herausgegebenen", "AI", "Magazine", "ver\u00f6ffentlicht", "."], "sentence-detokenized": "Die Newcomb Awards werden in dem von der AAAI herausgegebenen AI Magazine ver\u00f6ffentlicht.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 25], [26, 28], [29, 32], [33, 36], [37, 40], [41, 45], [46, 61], [62, 64], [65, 73], [74, 88], [88, 89]]}
{"doc_key": "ai-test-158", "ner": [[1, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Der", "mittlere", "quadratische", "Fehler", "bei", "einer", "Testmenge", "von", "100", "Beispielen", "ist", "0,084", "und", "damit", "kleiner", "als", "der", "nicht", "normalisierte", "Fehler", "."], "sentence-detokenized": "Der mittlere quadratische Fehler bei einer Testmenge von 100 Beispielen ist 0,084 und damit kleiner als der nicht normalisierte Fehler.", "token2charspan": [[0, 3], [4, 12], [13, 25], [26, 32], [33, 36], [37, 42], [43, 52], [53, 56], [57, 60], [61, 71], [72, 75], [76, 81], [82, 85], [86, 91], [92, 99], [100, 103], [104, 107], [108, 113], [114, 127], [128, 134], [134, 135]]}
{"doc_key": "ai-test-159", "ner": [[1, 2, "metrics"], [6, 9, "field"], [19, 21, "task"], [23, 23, "task"], [27, 27, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 9, 1, 2, "usage", "", false, false], [19, 21, 6, 9, "part-of", "task_part_of_field", false, false], [23, 23, 19, 21, "named", "", false, false], [27, 27, 6, 9, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Der", "F-Score", "ist", "in", "der", "Literatur", "zur", "Verarbeitung", "nat\u00fcrlicher", "Sprache", "weit", "verbreitet", ",", "z.", "B.", "bei", "der", "Bewertung", "der", "Erkennung", "benannter", "Entit\u00e4ten", "(", "NER", ")", "und", "der", "Wortsegmentierung", "."], "sentence-detokenized": "Der F-Score ist in der Literatur zur Verarbeitung nat\u00fcrlicher Sprache weit verbreitet, z. B. bei der Bewertung der Erkennung benannter Entit\u00e4ten (NER) und der Wortsegmentierung.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 18], [19, 22], [23, 32], [33, 36], [37, 49], [50, 61], [62, 69], [70, 74], [75, 85], [85, 86], [87, 89], [90, 92], [93, 96], [97, 100], [101, 110], [111, 114], [115, 124], [125, 134], [135, 144], [145, 146], [146, 149], [149, 150], [151, 154], [155, 158], [159, 176], [176, 177]]}
{"doc_key": "ai-test-160", "ner": [[0, 0, "product"], [4, 4, "product"], [17, 19, "misc"], [22, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 17, 19, "related-to", "performs_task", false, false], [0, 0, 22, 22, "related-to", "performs_task", false, false], [4, 4, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Chatbots", "werden", "typischerweise", "in", "Dialogsystemen", "f\u00fcr", "verschiedene", "Zwecke", "eingesetzt", ",", "z.", "B.", "f\u00fcr", "den", "Kundendienst", ",", "die", "Weiterleitung", "von", "Anfragen", "oder", "die", "Informationsbeschaffung", "."], "sentence-detokenized": "Chatbots werden typischerweise in Dialogsystemen f\u00fcr verschiedene Zwecke eingesetzt, z. B. f\u00fcr den Kundendienst, die Weiterleitung von Anfragen oder die Informationsbeschaffung.", "token2charspan": [[0, 8], [9, 15], [16, 30], [31, 33], [34, 48], [49, 52], [53, 65], [66, 72], [73, 83], [83, 84], [85, 87], [88, 90], [91, 94], [95, 98], [99, 111], [111, 112], [113, 116], [117, 130], [131, 134], [135, 143], [144, 148], [149, 152], [153, 176], [176, 177]]}
{"doc_key": "ai-test-161", "ner": [[4, 10, "conference"], [15, 23, "conference"], [30, 40, "conference"], [50, 53, "conference"], [55, 56, "conference"]], "ner_mapping_to_source": [0, 1, 2, 4, 5], "relations": [[15, 23, 4, 10, "named", "", false, false], [30, 40, 4, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Wichtige", "Zeitschriften", "sind", "die", "IEEE", "Transactions", "on", "Speech", "and", "Audio", "Processing", "(", "sp\u00e4ter", "umbenannt", "in", "IEEE", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "und", "seit", "September", "2014", "umbenannt", "in", "IEEE", "/", "ACM", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "-", "nach", "der", "Zusammenlegung", "mit", "einer", "ACM-Publikation", ")", ",", "Computer", "Speech", "and", "Language", "und", "Speech", "Communication", "."], "sentence-detokenized": "Wichtige Zeitschriften sind die IEEE Transactions on Speech and Audio Processing (sp\u00e4ter umbenannt in IEEE Transactions on Audio, Speech and Language Processing und seit September 2014 umbenannt in IEEE / ACM Transactions on Audio, Speech and Language Processing - nach der Zusammenlegung mit einer ACM-Publikation), Computer Speech and Language und Speech Communication.", "token2charspan": [[0, 8], [9, 22], [23, 27], [28, 31], [32, 36], [37, 49], [50, 52], [53, 59], [60, 63], [64, 69], [70, 80], [81, 82], [82, 88], [89, 98], [99, 101], [102, 106], [107, 119], [120, 122], [123, 128], [128, 129], [130, 136], [137, 140], [141, 149], [150, 160], [161, 164], [165, 169], [170, 179], [180, 184], [185, 194], [195, 197], [198, 202], [203, 204], [205, 208], [209, 221], [222, 224], [225, 230], [230, 231], [232, 238], [239, 242], [243, 251], [252, 262], [263, 264], [265, 269], [270, 273], [274, 288], [289, 292], [293, 298], [299, 314], [314, 315], [315, 316], [317, 325], [326, 332], [333, 336], [337, 345], [346, 349], [350, 356], [357, 370], [370, 371]]}
{"doc_key": "ai-test-162", "ner": [[0, 0, "algorithm"], [5, 7, "task"], [9, 10, "field"], [13, 13, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 7, 0, 0, "usage", "", false, false], [5, 7, 9, 10, "part-of", "task_part_of_field", false, false], [5, 7, 13, 13, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["EM", "wird", "h\u00e4ufig", "f\u00fcr", "das", "Clustering", "von", "Daten", "beim", "maschinellen", "Lernen", "und", "beim", "Computersehen", "verwendet", "."], "sentence-detokenized": "EM wird h\u00e4ufig f\u00fcr das Clustering von Daten beim maschinellen Lernen und beim Computersehen verwendet.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 18], [19, 22], [23, 33], [34, 37], [38, 43], [44, 48], [49, 61], [62, 68], [69, 72], [73, 77], [78, 91], [92, 101], [101, 102]]}
{"doc_key": "ai-test-163", "ner": [[9, 9, "metrics"], [25, 25, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 9, 25, 25, "related-to", "described_by", false, false]], "relations_mapping_to_source": [0], "sentence": ["Es", "gibt", "zwar", "keine", "perfekte", "Methode", ",", "um", "die", "Konfusionsmatrix", "aus", "WAHR-", "und", "FALSCH-Positiven", "und", "-Negativen", "mit", "einer", "einzigen", "Zahl", "zu", "beschreiben", ",", "aber", "der", "Matthews-Korrelationskoeffizient", "gilt", "allgemein", "als", "eines", "der", "besten", "Ma\u00dfe", "dieser", "Art", "."], "sentence-detokenized": "Es gibt zwar keine perfekte Methode, um die Konfusionsmatrix aus WAHR- und FALSCH-Positiven und -Negativen mit einer einzigen Zahl zu beschreiben, aber der Matthews-Korrelationskoeffizient gilt allgemein als eines der besten Ma\u00dfe dieser Art.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 18], [19, 27], [28, 35], [35, 36], [37, 39], [40, 43], [44, 60], [61, 64], [65, 70], [71, 74], [75, 91], [92, 95], [96, 106], [107, 110], [111, 116], [117, 125], [126, 130], [131, 133], [134, 145], [145, 146], [147, 151], [152, 155], [156, 188], [189, 193], [194, 203], [204, 207], [208, 213], [214, 217], [218, 224], [225, 229], [230, 236], [237, 240], [240, 241]]}
{"doc_key": "ai-test-164", "ner": [[12, 12, "field"], [27, 27, "field"], [33, 34, "field"], [37, 38, "algorithm"], [40, 40, "task"], [42, 43, "algorithm"], [49, 49, "algorithm"], [51, 51, "algorithm"], [57, 59, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[33, 34, 27, 27, "part-of", "subfield", false, false], [37, 38, 33, 34, "part-of", "", false, true], [40, 40, 33, 34, "part-of", "", false, true], [42, 43, 33, 34, "part-of", "", false, true], [49, 49, 33, 34, "part-of", "", false, true], [51, 51, 33, 34, "part-of", "", false, true], [57, 59, 33, 34, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Mit", "der", "zunehmenden", "Gr\u00f6\u00dfe", "und", "Komplexit\u00e4t", "der", "Datens\u00e4tze", "wurde", "die", "direkte", "praktische", "Datenanalyse", "durch", "eine", "indirekte", ",", "automatisierte", "Datenverarbeitung", "erg\u00e4nzt", ",", "die", "durch", "andere", "Entdeckungen", "in", "der", "Informatik", ",", "insbesondere", "im", "Bereich", "des", "maschinellen", "Lernens", ",", "wie", "neuronale", "Netze", ",", "Clusteranalyse", ",", "genetische", "Algorithmen", "(", "1950er", "Jahre", ")", ",", "Entscheidungsbaumlernen", "und", "Entscheidungsregeln", "(", "1960er", "Jahre", ")", "und", "Support", "Vector", "Machines", "(", "1990er", "Jahre", ")", "unterst\u00fctzt", "wurde", "."], "sentence-detokenized": "Mit der zunehmenden Gr\u00f6\u00dfe und Komplexit\u00e4t der Datens\u00e4tze wurde die direkte praktische Datenanalyse durch eine indirekte, automatisierte Datenverarbeitung erg\u00e4nzt, die durch andere Entdeckungen in der Informatik, insbesondere im Bereich des maschinellen Lernens, wie neuronale Netze, Clusteranalyse, genetische Algorithmen (1950er Jahre), Entscheidungsbaumlernen und Entscheidungsregeln (1960er Jahre) und Support Vector Machines (1990er Jahre) unterst\u00fctzt wurde.", "token2charspan": [[0, 3], [4, 7], [8, 19], [20, 25], [26, 29], [30, 41], [42, 45], [46, 56], [57, 62], [63, 66], [67, 74], [75, 85], [86, 98], [99, 104], [105, 109], [110, 119], [119, 120], [121, 135], [136, 153], [154, 161], [161, 162], [163, 166], [167, 172], [173, 179], [180, 192], [193, 195], [196, 199], [200, 210], [210, 211], [212, 224], [225, 227], [228, 235], [236, 239], [240, 252], [253, 260], [260, 261], [262, 265], [266, 275], [276, 281], [281, 282], [283, 297], [297, 298], [299, 309], [310, 321], [322, 323], [323, 329], [330, 335], [335, 336], [336, 337], [338, 361], [362, 365], [366, 385], [386, 387], [387, 393], [394, 399], [399, 400], [401, 404], [405, 412], [413, 419], [420, 428], [429, 430], [430, 436], [437, 442], [442, 443], [444, 455], [456, 461], [461, 462]]}
{"doc_key": "ai-test-165", "ner": [[4, 4, "researcher"], [20, 21, "misc"], [10, 11, "researcher"], [13, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[20, 21, 4, 4, "artifact", "", false, false], [20, 21, 10, 11, "artifact", "", false, false], [20, 21, 13, 14, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Im", "Herbst", "2005", "ver\u00f6ffentlichte", "Thrun", "zusammen", "mit", "seinen", "langj\u00e4hrigen", "Mitarbeitern", "Dieter", "Fox", "und", "Wolfram", "Burgard", "ein", "Lehrbuch", "mit", "dem", "Titel", "Probabilistic", "Robotics", "."], "sentence-detokenized": "Im Herbst 2005 ver\u00f6ffentlichte Thrun zusammen mit seinen langj\u00e4hrigen Mitarbeitern Dieter Fox und Wolfram Burgard ein Lehrbuch mit dem Titel Probabilistic Robotics.", "token2charspan": [[0, 2], [3, 9], [10, 14], [15, 30], [31, 36], [37, 45], [46, 49], [50, 56], [57, 69], [70, 82], [83, 89], [90, 93], [94, 97], [98, 105], [106, 113], [114, 117], [118, 126], [127, 130], [131, 134], [135, 140], [141, 154], [155, 163], [163, 164]]}
{"doc_key": "ai-test-166", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 7, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["John", "D.", "Lafferty", ",", "Andrew", "McCallum", "und", "Pereiramath", "wie", "folgt", ":"], "sentence-detokenized": "John D. Lafferty, Andrew McCallum und Pereiramath wie folgt:", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 24], [25, 33], [34, 37], [38, 49], [50, 53], [54, 59], [59, 60]]}
{"doc_key": "ai-test-167", "ner": [[0, 6, "task"], [8, 8, "task"], [13, 14, "field"], [18, 19, "field"], [21, 23, "field"], [25, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 6, 18, 19, "part-of", "task_part_of_field", false, false], [0, 6, 21, 23, "part-of", "task_part_of_field", false, false], [8, 8, 0, 6, "named", "", false, false], [18, 19, 13, 14, "part-of", "subfield", false, false], [21, 23, 13, 14, "part-of", "subfield", false, false], [25, 25, 21, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Die", "Beantwortung", "von", "Fragen", "(", "Question", "Answering", ",", "QA", ")", "ist", "ein", "Teilgebiet", "der", "Informatik", "in", "den", "Bereichen", "Information", "Retrieval", "und", "Natural", "Language", "Processing", "(", "NLP", ")", ",", "das", "sich", "mit", "der", "Entwicklung", "von", "Systemen", "befasst", ",", "die", "automatisch", "von", "Menschen", "in", "nat\u00fcrlicher", "Sprache", "gestellte", "Fragen", "beantworten", "."], "sentence-detokenized": "Die Beantwortung von Fragen (Question Answering, QA) ist ein Teilgebiet der Informatik in den Bereichen Information Retrieval und Natural Language Processing (NLP), das sich mit der Entwicklung von Systemen befasst, die automatisch von Menschen in nat\u00fcrlicher Sprache gestellte Fragen beantworten.", "token2charspan": [[0, 3], [4, 16], [17, 20], [21, 27], [28, 29], [29, 37], [38, 47], [47, 48], [49, 51], [51, 52], [53, 56], [57, 60], [61, 71], [72, 75], [76, 86], [87, 89], [90, 93], [94, 103], [104, 115], [116, 125], [126, 129], [130, 137], [138, 146], [147, 157], [158, 159], [159, 162], [162, 163], [163, 164], [165, 168], [169, 173], [174, 177], [178, 181], [182, 193], [194, 197], [198, 206], [207, 214], [214, 215], [216, 219], [220, 231], [232, 235], [236, 244], [245, 247], [248, 259], [260, 267], [268, 277], [278, 284], [285, 296], [296, 297]]}
{"doc_key": "ai-test-168", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "der", "Version", "der", "Metrik", ",", "die", "bei", "den", "NIST-Evaluierungen", "vor", "2009", "verwendet", "wurde", ",", "wurde", "jedoch", "stattdessen", "der", "k\u00fcrzeste", "Referenzsatz", "verwendet", "."], "sentence-detokenized": "In der Version der Metrik, die bei den NIST-Evaluierungen vor 2009 verwendet wurde, wurde jedoch stattdessen der k\u00fcrzeste Referenzsatz verwendet.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 18], [19, 25], [25, 26], [27, 30], [31, 34], [35, 38], [39, 57], [58, 61], [62, 66], [67, 76], [77, 82], [82, 83], [84, 89], [90, 96], [97, 108], [109, 112], [113, 121], [122, 134], [135, 144], [144, 145]]}
{"doc_key": "ai-test-169", "ner": [[5, 5, "person"], [16, 16, "organisation"], [13, 13, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 13, 13, "related-to", "invests_in", false, false], [13, 13, 16, 16, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Am", "27.", "August", "2018", "k\u00fcndigte", "Toyota", "eine", "Investition", "von", "500", "Millionen", "Dollar", "in", "autonome", "Autos", "von", "Uber", "an", "."], "sentence-detokenized": "Am 27. August 2018 k\u00fcndigte Toyota eine Investition von 500 Millionen Dollar in autonome Autos von Uber an.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 18], [19, 27], [28, 34], [35, 39], [40, 51], [52, 55], [56, 59], [60, 69], [70, 76], [77, 79], [80, 88], [89, 94], [95, 98], [99, 103], [104, 106], [106, 107]]}
{"doc_key": "ai-test-170", "ner": [[4, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Das", "Stichprobenmaximum", "ist", "der", "Maximum-Likelihood-Sch\u00e4tzer", "f\u00fcr", "das", "Populationsmaximum", ",", "ist", "aber", ",", "wie", "bereits", "erw\u00e4hnt", ",", "verzerrt", "."], "sentence-detokenized": "Das Stichprobenmaximum ist der Maximum-Likelihood-Sch\u00e4tzer f\u00fcr das Populationsmaximum, ist aber, wie bereits erw\u00e4hnt, verzerrt.", "token2charspan": [[0, 3], [4, 22], [23, 26], [27, 30], [31, 58], [59, 62], [63, 66], [67, 85], [85, 86], [87, 90], [91, 95], [95, 96], [97, 100], [101, 108], [109, 116], [116, 117], [118, 126], [126, 127]]}
{"doc_key": "ai-test-171", "ner": [[0, 0, "task"], [6, 6, "misc"], [11, 11, "metrics"], [19, 20, "algorithm"], [22, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 6, "related-to", "overcomes", false, false], [0, 0, 11, 11, "related-to", "increases", false, false], [6, 6, 19, 20, "opposite", "", false, false], [6, 6, 22, 22, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LSI", "hilft", "bei", "der", "\u00dcberwindung", "von", "Synonymie", ",", "indem", "es", "die", "Wiederauffindbarkeit", "erh\u00f6ht", ",", "eine", "der", "problematischsten", "Einschr\u00e4nkungen", "bei", "booleschen", "Schl\u00fcsselwortabfragen", "und", "Vektorraummodellen", "."], "sentence-detokenized": "LSI hilft bei der \u00dcberwindung von Synonymie, indem es die Wiederauffindbarkeit erh\u00f6ht, eine der problematischsten Einschr\u00e4nkungen bei booleschen Schl\u00fcsselwortabfragen und Vektorraummodellen.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 17], [18, 29], [30, 33], [34, 43], [43, 44], [45, 50], [51, 53], [54, 57], [58, 78], [79, 85], [85, 86], [87, 91], [92, 95], [96, 113], [114, 129], [130, 133], [134, 144], [145, 166], [167, 170], [171, 189], [189, 190]]}
{"doc_key": "ai-test-172", "ner": [[15, 15, "programlang"], [17, 17, "programlang"], [19, 19, "programlang"], [21, 21, "programlang"], [23, 23, "programlang"], [25, 25, "programlang"], [27, 27, "programlang"], [29, 29, "programlang"], [31, 31, "programlang"], [33, 33, "programlang"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [], "relations_mapping_to_source": [], "sentence": ["Datenerfassungsanwendungen", "werden", "in", "der", "Regel", "durch", "Softwareprogramme", "gesteuert", ",", "die", "in", "verschiedenen", "allgemeinen", "Programmiersprachen", "wie", "Assembler", ",", "BASIC", ",", "C", ",", "C+", ",", "C#", ",", "Fortran", ",", "Java", ",", "LabVIEW", ",", "Lisp", ",", "Pascal", "usw.", "entwickelt", "wurden", "."], "sentence-detokenized": "Datenerfassungsanwendungen werden in der Regel durch Softwareprogramme gesteuert, die in verschiedenen allgemeinen Programmiersprachen wie Assembler, BASIC, C, C+, C#, Fortran, Java, LabVIEW, Lisp, Pascal usw. entwickelt wurden.", "token2charspan": [[0, 26], [27, 33], [34, 36], [37, 40], [41, 46], [47, 52], [53, 70], [71, 80], [80, 81], [82, 85], [86, 88], [89, 102], [103, 114], [115, 134], [135, 138], [139, 148], [148, 149], [150, 155], [155, 156], [157, 158], [158, 159], [160, 162], [162, 163], [164, 166], [166, 167], [168, 175], [175, 176], [177, 181], [181, 182], [183, 190], [190, 191], [192, 196], [196, 197], [198, 204], [205, 209], [210, 220], [221, 227], [227, 228]]}
{"doc_key": "ai-test-173", "ner": [[4, 4, "organisation"], [8, 9, "country"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Im", "Jahr", "2003", "ver\u00f6ffentlichte", "Honda", "seine", "Cog-Werbung", "im", "Vereinigten", "K\u00f6nigreich", "und", "im", "Internet", "."], "sentence-detokenized": "Im Jahr 2003 ver\u00f6ffentlichte Honda seine Cog-Werbung im Vereinigten K\u00f6nigreich und im Internet.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 28], [29, 34], [35, 40], [41, 52], [53, 55], [56, 67], [68, 78], [79, 82], [83, 85], [86, 94], [94, 95]]}
{"doc_key": "ai-test-174", "ner": [[1, 4, "conference"], [6, 6, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 4, 6, 6, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Die", "Association", "for", "Computational", "Linguistics", "definiert", "Computerlinguistik", "als", ":"], "sentence-detokenized": "Die Association for Computational Linguistics definiert Computerlinguistik als:", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 33], [34, 45], [46, 55], [56, 74], [75, 78], [78, 79]]}
{"doc_key": "ai-test-175", "ner": [[0, 0, "algorithm"], [7, 7, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 7, 7, "related-to", "calculates", false, false]], "relations_mapping_to_source": [0], "sentence": ["Erwartungsmaximierungsalgorithmen", "k\u00f6nnen", "eingesetzt", "werden", ",", "um", "ann\u00e4hernde", "Maximum-Likelihood-Sch\u00e4tzungen", "von", "unbekannten", "Zustandsraumparametern", "innerhalb", "von", "Minimum-Varianz-Filtern", "und", "Gl\u00e4ttern", "zu", "berechnen", "."], "sentence-detokenized": "Erwartungsmaximierungsalgorithmen k\u00f6nnen eingesetzt werden, um ann\u00e4hernde Maximum-Likelihood-Sch\u00e4tzungen von unbekannten Zustandsraumparametern innerhalb von Minimum-Varianz-Filtern und Gl\u00e4ttern zu berechnen.", "token2charspan": [[0, 33], [34, 40], [41, 51], [52, 58], [58, 59], [60, 62], [63, 73], [74, 104], [105, 108], [109, 120], [121, 143], [144, 153], [154, 157], [158, 181], [182, 185], [186, 194], [195, 197], [198, 207], [207, 208]]}
{"doc_key": "ai-test-176", "ner": [[7, 8, "person"], [10, 11, "person"], [13, 14, "person"], [18, 18, "misc"], [19, 20, "person"], [24, 25, "person"], [30, 30, "person"], [32, 33, "person"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8], "relations": [[19, 20, 18, 18, "role", "model_for", false, false], [30, 30, 32, 33, "social", "family", false, false]], "relations_mapping_to_source": [3, 4], "sentence": ["Zu", "den", "Korrespondenten", "geh\u00f6rten", "die", "ehemaligen", "Baywatch-Darstellerinnen", "Donna", "D'Errico", ",", "Carmen", "Electra", "und", "Traci", "Bingham", ",", "das", "ehemalige", "Playboy-Playmate", "Heidi", "Mark", ",", "der", "Komiker", "Arj", "Barker", "und", "die", "eineiigen", "Zwillinge", "Randy", "und", "Jason", "Sklar", "."], "sentence-detokenized": "Zu den Korrespondenten geh\u00f6rten die ehemaligen Baywatch-Darstellerinnen Donna D'Errico, Carmen Electra und Traci Bingham, das ehemalige Playboy-Playmate Heidi Mark, der Komiker Arj Barker und die eineiigen Zwillinge Randy und Jason Sklar.", "token2charspan": [[0, 2], [3, 6], [7, 22], [23, 31], [32, 35], [36, 46], [47, 71], [72, 77], [78, 86], [86, 87], [88, 94], [95, 102], [103, 106], [107, 112], [113, 120], [120, 121], [122, 125], [126, 135], [136, 152], [153, 158], [159, 163], [163, 164], [165, 168], [169, 176], [177, 180], [181, 187], [188, 191], [192, 195], [196, 205], [206, 215], [216, 221], [222, 225], [226, 231], [232, 237], [237, 238]]}
{"doc_key": "ai-test-177", "ner": [[9, 9, "task"], [11, 11, "task"], [17, 18, "product"], [22, 22, "task"], [24, 24, "task"], [30, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 9, 9, "named", "", false, false], [17, 18, 9, 9, "general-affiliation", "", false, false], [24, 24, 22, 22, "named", "", false, false], [30, 30, 22, 22, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sie", "wird", "\u00fcblicherweise", "zur", "Erzeugung", "von", "Repr\u00e4sentationen", "f\u00fcr", "die", "Spracherkennung", "(", "ASR", ")", ",", "z.", "B.", "das", "CMU", "Sphinx-System", ",", "und", "die", "Sprachsynthese", "(", "TTS", ")", ",", "z.", "B.", "das", "Festival-System", ",", "verwendet", "."], "sentence-detokenized": "Sie wird \u00fcblicherweise zur Erzeugung von Repr\u00e4sentationen f\u00fcr die Spracherkennung (ASR), z.B. das CMU Sphinx-System, und die Sprachsynthese (TTS), z.B. das Festival-System, verwendet.", "token2charspan": [[0, 3], [4, 8], [9, 22], [23, 26], [27, 36], [37, 40], [41, 57], [58, 61], [62, 65], [66, 81], [82, 83], [83, 86], [86, 87], [87, 88], [89, 91], [91, 93], [94, 97], [98, 101], [102, 115], [115, 116], [117, 120], [121, 124], [125, 139], [140, 141], [141, 144], [144, 145], [145, 146], [147, 149], [149, 151], [152, 155], [156, 171], [171, 172], [173, 182], [182, 183]]}
{"doc_key": "ai-test-178", "ner": [[0, 1, "metrics"], [3, 3, "metrics"], [5, 5, "metrics"], [9, 9, "metrics"], [24, 24, "metrics"], [26, 26, "metrics"], [35, 35, "metrics"], [37, 37, "metrics"], [39, 41, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 3, 0, 1, "named", "", false, false], [5, 5, 3, 3, "named", "", false, false], [9, 9, 0, 1, "named", "", false, false], [26, 26, 24, 24, "named", "", false, false], [37, 37, 35, 35, "named", "", false, false], [39, 41, 35, 35, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Die", "Sensitivit\u00e4t", "oder", "WAHR-Positiv-Rate", "(", "TPR", ")", ",", "auch", "Recall", "genannt", ",", "ist", "der", "Anteil", "der", "positiv", "getesteten", "Personen", ",", "die", "positiv", "sind", "(", "WAHR-Positiv", ",", "TP", ")", ",", "an", "allen", "tats\u00e4chlich", "positiven", "Personen", "(", "Bedingungspositiv", ",", "CP", "=", "TP", "+", "FN", ")", "."], "sentence-detokenized": "Die Sensitivit\u00e4t oder WAHR-Positiv-Rate (TPR), auch Recall genannt, ist der Anteil der positiv getesteten Personen, die positiv sind (WAHR-Positiv, TP), an allen tats\u00e4chlich positiven Personen (Bedingungspositiv, CP = TP + FN).", "token2charspan": [[0, 3], [4, 16], [17, 21], [22, 39], [40, 41], [41, 44], [44, 45], [45, 46], [47, 51], [52, 58], [59, 66], [66, 67], [68, 71], [72, 75], [76, 82], [83, 86], [87, 94], [95, 105], [106, 114], [114, 115], [116, 119], [120, 127], [128, 132], [133, 134], [134, 146], [146, 147], [148, 150], [150, 151], [151, 152], [153, 155], [156, 161], [162, 173], [174, 183], [184, 192], [193, 194], [194, 211], [211, 212], [213, 215], [216, 217], [218, 220], [221, 222], [223, 225], [225, 226], [226, 227]]}
{"doc_key": "ai-test-179", "ner": [[14, 14, "conference"], [16, 17, "conference"], [19, 19, "conference"], [21, 21, "conference"], [23, 23, "conference"], [26, 27, "conference"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Zu", "den", "beliebten", "Spracherkennungskonferenzen", ",", "die", "alle", "ein", "bis", "zwei", "Jahre", "stattfinden", ",", "geh\u00f6ren", "SpeechTEK", "und", "SpeechTEK", "Europe", ",", "ICASSP", ",", "Interspeech", "/", "Eurospeech", "und", "die", "IEEE", "ASRU", "."], "sentence-detokenized": "Zu den beliebten Spracherkennungskonferenzen, die alle ein bis zwei Jahre stattfinden, geh\u00f6ren SpeechTEK und SpeechTEK Europe, ICASSP, Interspeech / Eurospeech und die IEEE ASRU.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 44], [44, 45], [46, 49], [50, 54], [55, 58], [59, 62], [63, 67], [68, 73], [74, 85], [85, 86], [87, 94], [95, 104], [105, 108], [109, 118], [119, 125], [125, 126], [127, 133], [133, 134], [135, 146], [147, 148], [149, 159], [160, 163], [164, 167], [168, 172], [173, 177], [177, 178]]}
{"doc_key": "ai-test-180", "ner": [[0, 0, "researcher"], [3, 3, "researcher"], [16, 16, "product"], [20, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[20, 21, 0, 0, "artifact", "", false, false], [20, 21, 3, 3, "artifact", "", false, false], [20, 21, 16, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Devol", "arbeitete", "mit", "Engelberger", ",", "der", "als", "Pr\u00e4sident", "des", "Unternehmens", "fungierte", ",", "zusammen", ",", "um", "einen", "Industrieroboter", "unter", "dem", "Markennamen", "Unimate", "zu", "entwickeln", "und", "zu", "produzieren", "."], "sentence-detokenized": "Devol arbeitete mit Engelberger, der als Pr\u00e4sident des Unternehmens fungierte, zusammen, um einen Industrieroboter unter dem Markennamen Unimate zu entwickeln und zu produzieren.", "token2charspan": [[0, 5], [6, 15], [16, 19], [20, 31], [31, 32], [33, 36], [37, 40], [41, 50], [51, 54], [55, 67], [68, 77], [77, 78], [79, 87], [87, 88], [89, 91], [92, 97], [98, 114], [115, 120], [121, 124], [125, 136], [137, 144], [145, 147], [148, 158], [159, 162], [163, 165], [166, 177], [177, 178]]}
{"doc_key": "ai-test-181", "ner": [[1, 1, "algorithm"], [3, 3, "algorithm"], [7, 8, "algorithm"], [16, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 7, 8, "general-affiliation", "", false, false], [3, 3, 1, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Ein", "Hidden-Markov-Modell", "(", "HMM", ")", "ist", "ein", "statistisches", "Markov-Modell", ",", "bei", "dem", "das", "modellierte", "System", "als", "Markov-Prozess", "mit", "unbeobachteten", "(", "verborgenen", ")", "Zust\u00e4nden", "angenommen", "wird", "."], "sentence-detokenized": "Ein Hidden-Markov-Modell (HMM) ist ein statistisches Markov-Modell, bei dem das modellierte System als Markov-Prozess mit unbeobachteten (verborgenen) Zust\u00e4nden angenommen wird.", "token2charspan": [[0, 3], [4, 24], [25, 26], [26, 29], [29, 30], [31, 34], [35, 38], [39, 52], [53, 66], [66, 67], [68, 71], [72, 75], [76, 79], [80, 91], [92, 98], [99, 102], [103, 117], [118, 121], [122, 136], [137, 138], [138, 149], [149, 150], [151, 160], [161, 171], [172, 176], [176, 177]]}
{"doc_key": "ai-test-182", "ner": [[14, 16, "metrics"], [19, 20, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Diese", "in", "vielen", "Anwendungen", "unerw\u00fcnschte", "Eigenschaft", "hat", "Forscher", "dazu", "veranlasst", ",", "Alternativen", "wie", "den", "mittleren", "absoluten", "Fehler", "oder", "den", "Median", "zu", "verwenden", "."], "sentence-detokenized": "Diese in vielen Anwendungen unerw\u00fcnschte Eigenschaft hat Forscher dazu veranlasst, Alternativen wie den mittleren absoluten Fehler oder den Median zu verwenden.", "token2charspan": [[0, 5], [6, 8], [9, 15], [16, 27], [28, 40], [41, 52], [53, 56], [57, 65], [66, 70], [71, 81], [81, 82], [83, 95], [96, 99], [100, 103], [104, 113], [114, 123], [124, 130], [131, 135], [136, 139], [140, 146], [147, 149], [150, 159], [159, 160]]}
{"doc_key": "ai-test-183", "ner": [[19, 19, "algorithm"], [25, 26, "field"], [31, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 19, 25, 26, "part-of", "", false, false], [19, 19, 31, 31, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Eine", "solche", "Abfolge", "(", "die", "in", "jeder", "Phase", "vom", "Ergebnis", "der", "Untersuchung", "der", "vorangegangenen", "Attribute", "abh\u00e4ngt", ")", "wird", "als", "Entscheidungsbaum", "bezeichnet", "und", "im", "Bereich", "des", "maschinellen", "Lernens", ",", "dem", "so", "genannten", "Entscheidungsbaumlernen", ",", "angewendet", "."], "sentence-detokenized": "Eine solche Abfolge (die in jeder Phase vom Ergebnis der Untersuchung der vorangegangenen Attribute abh\u00e4ngt) wird als Entscheidungsbaum bezeichnet und im Bereich des maschinellen Lernens, dem so genannten Entscheidungsbaumlernen, angewendet.", "token2charspan": [[0, 4], [5, 11], [12, 19], [20, 21], [21, 24], [25, 27], [28, 33], [34, 39], [40, 43], [44, 52], [53, 56], [57, 69], [70, 73], [74, 89], [90, 99], [100, 107], [107, 108], [109, 113], [114, 117], [118, 135], [136, 146], [147, 150], [151, 153], [154, 161], [162, 165], [166, 178], [179, 186], [186, 187], [188, 191], [192, 194], [195, 204], [205, 228], [228, 229], [230, 240], [240, 241]]}
{"doc_key": "ai-test-184", "ner": [[3, 3, "task"], [6, 6, "algorithm"], [20, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 6, 6, "compare", "", false, false], [20, 21, 6, 6, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Wie", "bei", "der", "Faktorenanalyse", "kann", "die", "\u00d6kobilanz", "auch", "zur", "Klassifizierung", "von", "F\u00e4llen", "nach", "ihrer", "Zugeh\u00f6rigkeit", "zu", "einer", "bestimmten", "Klasse", "mit", "maximaler", "Wahrscheinlichkeit", "verwendet", "werden", "."], "sentence-detokenized": "Wie bei der Faktorenanalyse kann die \u00d6kobilanz auch zur Klassifizierung von F\u00e4llen nach ihrer Zugeh\u00f6rigkeit zu einer bestimmten Klasse mit maximaler Wahrscheinlichkeit verwendet werden.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 27], [28, 32], [33, 36], [37, 46], [47, 51], [52, 55], [56, 71], [72, 75], [76, 82], [83, 87], [88, 93], [94, 107], [108, 110], [111, 116], [117, 127], [128, 134], [135, 138], [139, 148], [149, 167], [168, 177], [178, 184], [184, 185]]}
{"doc_key": "ai-test-185", "ner": [[0, 3, "algorithm"], [9, 12, "metrics"], [14, 14, "metrics"], [7, 8, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 9, 12, "usage", "", false, false], [9, 12, 7, 8, "related-to", "", false, false], [14, 14, 9, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Bei", "\u00fcberwachten", "neuronalen", "Netzen", ",", "die", "eine", "Kostenfunktion", "f\u00fcr", "den", "mittleren", "quadratischen", "Fehler", "(", "MSE", ")", "verwenden", ",", "k\u00f6nnen", "formale", "statistische", "Methoden", "eingesetzt", "werden", ",", "um", "die", "Zuverl\u00e4ssigkeit", "des", "trainierten", "Modells", "zu", "bestimmen", "."], "sentence-detokenized": "Bei \u00fcberwachten neuronalen Netzen, die eine Kostenfunktion f\u00fcr den mittleren quadratischen Fehler (MSE) verwenden, k\u00f6nnen formale statistische Methoden eingesetzt werden, um die Zuverl\u00e4ssigkeit des trainierten Modells zu bestimmen.", "token2charspan": [[0, 3], [4, 15], [16, 26], [27, 33], [33, 34], [35, 38], [39, 43], [44, 58], [59, 62], [63, 66], [67, 76], [77, 90], [91, 97], [98, 99], [99, 102], [102, 103], [104, 113], [113, 114], [115, 121], [122, 129], [130, 142], [143, 151], [152, 162], [163, 169], [169, 170], [171, 173], [174, 177], [178, 193], [194, 197], [198, 209], [210, 217], [218, 220], [221, 230], [230, 231]]}
{"doc_key": "ai-test-186", "ner": [[14, 14, "algorithm"], [17, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 14, 17, 17, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Dies", "kann", "direkt", "als", "lineares", "Programm", "ausgedr\u00fcckt", "werden", ",", "ist", "aber", "auch", "\u00e4quivalent", "zur", "Tikhonov-Regularisierung", "mit", "der", "Scharnierverlustfunktion", ",", "mathV", "(", "f", "(x", ")", ",", "y", ")", "=\\", "max", "(", "0", ",", "1", "-", "yf", "(x", ")", ")", "/", "math", ":"], "sentence-detokenized": "Dies kann direkt als lineares Programm ausgedr\u00fcckt werden, ist aber auch \u00e4quivalent zur Tikhonov-Regularisierung mit der Scharnierverlustfunktion, mathV (f (x), y) =\\ max (0, 1 - yf (x)) / math:", "token2charspan": [[0, 4], [5, 9], [10, 16], [17, 20], [21, 29], [30, 38], [39, 50], [51, 57], [57, 58], [59, 62], [63, 67], [68, 72], [73, 83], [84, 87], [88, 112], [113, 116], [117, 120], [121, 145], [145, 146], [147, 152], [153, 154], [154, 155], [156, 158], [158, 159], [159, 160], [161, 162], [162, 163], [164, 166], [167, 170], [171, 172], [172, 173], [173, 174], [175, 176], [177, 178], [179, 181], [182, 184], [184, 185], [185, 186], [187, 188], [189, 193], [193, 194]]}
{"doc_key": "ai-test-187", "ner": [[8, 8, "researcher"], [13, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Die", "folgende", "Technik", "wurde", "in", "der", "Originalarbeit", "von", "Breiman", "beschrieben", "und", "ist", "im", "R-Paket", "randomForest", "implementiert", "."], "sentence-detokenized": "Die folgende Technik wurde in der Originalarbeit von Breiman beschrieben und ist im R-Paket randomForest implementiert.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 26], [27, 29], [30, 33], [34, 48], [49, 52], [53, 60], [61, 72], [73, 76], [77, 80], [81, 83], [84, 91], [92, 104], [105, 118], [118, 119]]}
{"doc_key": "ai-test-188", "ner": [[3, 3, "metrics"], [33, 33, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Herk\u00f6mmliche", "Bildqualit\u00e4tsmessungen", "wie", "PSNR", "werden", "in", "der", "Regel", "f\u00fcr", "Bilder", "mit", "fester", "Aufl\u00f6sung", "durchgef\u00fchrt", "und", "ber\u00fccksichtigen", "einige", "Aspekte", "des", "menschlichen", "Sehsystems", "nicht", ",", "wie", "z.", "B.", "die", "Ver\u00e4nderung", "der", "r\u00e4umlichen", "Aufl\u00f6sung", "auf", "der", "Netzhaut", "."], "sentence-detokenized": "Herk\u00f6mmliche Bildqualit\u00e4tsmessungen wie PSNR werden in der Regel f\u00fcr Bilder mit fester Aufl\u00f6sung durchgef\u00fchrt und ber\u00fccksichtigen einige Aspekte des menschlichen Sehsystems nicht, wie z. B. die Ver\u00e4nderung der r\u00e4umlichen Aufl\u00f6sung auf der Netzhaut.", "token2charspan": [[0, 12], [13, 35], [36, 39], [40, 44], [45, 51], [52, 54], [55, 58], [59, 64], [65, 68], [69, 75], [76, 79], [80, 86], [87, 96], [97, 109], [110, 113], [114, 129], [130, 136], [137, 144], [145, 148], [149, 161], [162, 172], [173, 178], [178, 179], [180, 183], [184, 186], [187, 189], [190, 193], [194, 205], [206, 209], [210, 220], [221, 230], [231, 234], [235, 238], [239, 247], [247, 248]]}
{"doc_key": "ai-test-189", "ner": [[0, 1, "person"], [3, 4, "person"], [6, 7, "person"], [13, 13, "person"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 15, 16, "role", "", false, false], [3, 4, 15, 16, "role", "", false, false], [6, 7, 15, 16, "role", "", false, false], [15, 16, 13, 13, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["John", "Ireland", ",", "Joanne", "Dru", "und", "Macdonald", "Carey", "spielten", "die", "Hauptrollen", "in", "der", "Jack", "Broder-Farbproduktion", "Hannah", "Lee", ",", "die", "am", "19.", "Juni", "1953", "uraufgef\u00fchrt", "wurde", "."], "sentence-detokenized": "John Ireland, Joanne Dru und Macdonald Carey spielten die Hauptrollen in der Jack Broder-Farbproduktion Hannah Lee, die am 19. Juni 1953 uraufgef\u00fchrt wurde.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 20], [21, 24], [25, 28], [29, 38], [39, 44], [45, 53], [54, 57], [58, 69], [70, 72], [73, 76], [77, 81], [82, 103], [104, 110], [111, 114], [114, 115], [116, 119], [120, 122], [123, 126], [127, 131], [132, 136], [137, 149], [150, 155], [155, 156]]}
{"doc_key": "ai-test-190", "ner": [[4, 4, "task"], [11, 12, "field"], [18, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 11, 12, "usage", "", false, false], [18, 18, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Dieser", "Prozess", "wird", "als", "Bildregistrierung", "bezeichnet", "und", "nutzt", "verschiedene", "Methoden", "der", "Computer", "Vision", ",", "die", "meist", "mit", "der", "Verfolgung", "zusammenh\u00e4ngen", "."], "sentence-detokenized": "Dieser Prozess wird als Bildregistrierung bezeichnet und nutzt verschiedene Methoden der Computer Vision, die meist mit der Verfolgung zusammenh\u00e4ngen.", "token2charspan": [[0, 6], [7, 14], [15, 19], [20, 23], [24, 41], [42, 52], [53, 56], [57, 62], [63, 75], [76, 84], [85, 88], [89, 97], [98, 104], [104, 105], [106, 109], [110, 115], [116, 119], [120, 123], [124, 134], [135, 149], [149, 150]]}
{"doc_key": "ai-test-191", "ner": [[19, 19, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Lassen", "Sie", "uns", "nun", "damit", "beginnen", ",", "die", "verschiedenen", "m\u00f6glichen", "Beziehungen", "zwischen", "vorhergesagtem", "und", "tats\u00e4chlichem", "Ergebnis", "zu", "erkl\u00e4ren", ":", "Konfusionsmatrix"], "sentence-detokenized": "Lassen Sie uns nun damit beginnen, die verschiedenen m\u00f6glichen Beziehungen zwischen vorhergesagtem und tats\u00e4chlichem Ergebnis zu erkl\u00e4ren: Konfusionsmatrix", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 18], [19, 24], [25, 33], [33, 34], [35, 38], [39, 52], [53, 62], [63, 74], [75, 83], [84, 98], [99, 102], [103, 116], [117, 125], [126, 128], [129, 137], [137, 138], [139, 155]]}
{"doc_key": "ai-test-192", "ner": [[1, 1, "product"], [2, 2, "misc"], [4, 4, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 2, 2, "part-of", "", false, false], [1, 1, 2, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Die", "VOICEBOX", "Sprachverarbeitungs-Toolbox", "f\u00fcr", "MATLAB", "implementiert", "die", "Konvertierung", "und", "ihre", "Umkehrung", "als", ":"], "sentence-detokenized": "Die VOICEBOX Sprachverarbeitungs-Toolbox f\u00fcr MATLAB implementiert die Konvertierung und ihre Umkehrung als:", "token2charspan": [[0, 3], [4, 12], [13, 40], [41, 44], [45, 51], [52, 65], [66, 69], [70, 83], [84, 87], [88, 92], [93, 102], [103, 106], [106, 107]]}
{"doc_key": "ai-test-193", "ner": [[0, 0, "programlang"], [8, 9, "field"], [11, 11, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 9, "general-affiliation", "", false, false], [0, 0, 11, 11, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolog", "ist", "eine", "logische", "Programmiersprache", ",", "die", "mit", "k\u00fcnstlicher", "Intelligenz", "und", "Computerlinguistik", "verbunden", "ist", "."], "sentence-detokenized": "Prolog ist eine logische Programmiersprache, die mit k\u00fcnstlicher Intelligenz und Computerlinguistik verbunden ist.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 24], [25, 43], [43, 44], [45, 48], [49, 52], [53, 64], [65, 76], [77, 80], [81, 99], [100, 109], [110, 113], [113, 114]]}
{"doc_key": "ai-test-194", "ner": [[0, 0, "researcher"], [8, 8, "field"], [10, 10, "field"], [17, 20, "organisation"], [23, 26, "organisation"], [29, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 8, 8, "related-to", "works_with_topic", false, false], [0, 0, 10, 10, "related-to", "works_with_topic", false, false], [0, 0, 17, 20, "role", "", false, false], [0, 0, 23, 26, "role", "", false, false], [0, 0, 29, 32, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Milner", "hat", "zahlreiche", "Auszeichnungen", "f\u00fcr", "ihre", "Beitr\u00e4ge", "zur", "Neurowissenschaft", "und", "Psychologie", "erhalten", ",", "darunter", "Mitgliedschaften", "in", "der", "Royal", "Society", "of", "London", ",", "der", "Royal", "Society", "of", "Canada", "und", "der", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Milner hat zahlreiche Auszeichnungen f\u00fcr ihre Beitr\u00e4ge zur Neurowissenschaft und Psychologie erhalten, darunter Mitgliedschaften in der Royal Society of London, der Royal Society of Canada und der National Academy of Sciences.", "token2charspan": [[0, 6], [7, 10], [11, 21], [22, 36], [37, 40], [41, 45], [46, 54], [55, 58], [59, 76], [77, 80], [81, 92], [93, 101], [101, 102], [103, 111], [112, 128], [129, 131], [132, 135], [136, 141], [142, 149], [150, 152], [153, 159], [159, 160], [161, 164], [165, 170], [171, 178], [179, 181], [182, 188], [189, 192], [193, 196], [197, 205], [206, 213], [214, 216], [217, 225], [225, 226]]}
{"doc_key": "ai-test-195", "ner": [[15, 15, "task"], [17, 17, "task"], [19, 19, "task"], [21, 21, "task"], [23, 23, "task"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Durch", "die", "Kombination", "dieser", "Operatoren", "erh\u00e4lt", "man", "Algorithmen", "f\u00fcr", "viele", "Bildverarbeitungsaufgaben", ",", "wie", "z.", "B.", "Merkmalsextraktion", ",", "Bildsegmentierung", ",", "Bildsch\u00e4rfung", ",", "Bildfilterung", "und", "Klassifizierung", "."], "sentence-detokenized": "Durch die Kombination dieser Operatoren erh\u00e4lt man Algorithmen f\u00fcr viele Bildverarbeitungsaufgaben, wie z. B. Merkmalsextraktion, Bildsegmentierung, Bildsch\u00e4rfung, Bildfilterung und Klassifizierung.", "token2charspan": [[0, 5], [6, 9], [10, 21], [22, 28], [29, 39], [40, 46], [47, 50], [51, 62], [63, 66], [67, 72], [73, 98], [98, 99], [100, 103], [104, 106], [107, 109], [110, 128], [128, 129], [130, 147], [147, 148], [149, 162], [162, 163], [164, 177], [178, 181], [182, 197], [197, 198]]}
{"doc_key": "ai-test-196", "ner": [[6, 8, "university"], [14, 16, "organisation"], [18, 19, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 19, 14, 16, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Seit", "2017", "ist", "er", "Professor", "am", "Coll\u00e8ge", "de", "France", "und", "seit", "1989", "Direktor", "der", "INSERM", "Unit", "562", ",", "Cognitive", "Neuroimaging", "."], "sentence-detokenized": "Seit 2017 ist er Professor am Coll\u00e8ge de France und seit 1989 Direktor der INSERM Unit 562, Cognitive Neuroimaging.", "token2charspan": [[0, 4], [5, 9], [10, 13], [14, 16], [17, 26], [27, 29], [30, 37], [38, 40], [41, 47], [48, 51], [52, 56], [57, 61], [62, 70], [71, 74], [75, 81], [82, 86], [87, 90], [90, 91], [92, 101], [102, 114], [114, 115]]}
{"doc_key": "ai-test-197", "ner": [[13, 14, "algorithm"], [16, 17, "algorithm"], [21, 21, "algorithm"], [23, 29, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 21, 23, 29, "temporal", "", false, true]], "relations_mapping_to_source": [0], "sentence": ["Es", "gibt", "viele", "Ans\u00e4tze", ",", "um", "diese", "Einbettungen", "zu", "lernen", ",", "insbesondere", "mit", "Bayes'schen", "Clustering-Frameworks", "oder", "energiebasierten", "Frameworks", "und", "neuerdings", "mit", "TransE", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", "2013", ")", "."], "sentence-detokenized": "Es gibt viele Ans\u00e4tze, um diese Einbettungen zu lernen, insbesondere mit Bayes'schen Clustering-Frameworks oder energiebasierten Frameworks und neuerdings mit TransE (Conference on Neural Information Processing Systems 2013).", "token2charspan": [[0, 2], [3, 7], [8, 13], [14, 21], [21, 22], [23, 25], [26, 31], [32, 44], [45, 47], [48, 54], [54, 55], [56, 68], [69, 72], [73, 84], [85, 106], [107, 111], [112, 128], [129, 139], [140, 143], [144, 154], [155, 158], [159, 165], [166, 167], [167, 177], [178, 180], [181, 187], [188, 199], [200, 210], [211, 218], [219, 223], [223, 224], [224, 225]]}
{"doc_key": "ai-test-198", "ner": [[5, 7, "metrics"], [8, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 5, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Sie", "ist", "eine", "Alternative", "zur", "Wortfehlerrate", "(", "Word", "Error", "Rate", ")", ",", "die", "in", "mehreren", "L\u00e4ndern", "verwendet", "wird", "."], "sentence-detokenized": "Sie ist eine Alternative zur Wortfehlerrate (Word Error Rate), die in mehreren L\u00e4ndern verwendet wird.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 24], [25, 28], [29, 43], [44, 45], [45, 49], [50, 55], [56, 60], [60, 61], [61, 62], [63, 66], [67, 69], [70, 78], [79, 86], [87, 96], [97, 101], [101, 102]]}
{"doc_key": "ai-test-199", "ner": [[0, 0, "algorithm"], [10, 11, "task"], [13, 13, "task"], [15, 16, "task"], [18, 20, "task"], [22, 24, "task"], [26, 27, "task"], [44, 44, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 11, 0, 0, "usage", "", false, false], [13, 13, 0, 0, "usage", "", false, false], [15, 16, 0, 0, "usage", "", false, false], [18, 20, 0, 0, "usage", "", false, false], [22, 24, 0, 0, "usage", "", false, false], [26, 27, 0, 0, "usage", "", false, false], [44, 44, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["ANNs", "wurden", "f\u00fcr", "eine", "Vielzahl", "von", "Aufgaben", "eingesetzt", ",", "darunter", "Computer", "Vision", ",", "Spracherkennung", ",", "maschinelle", "\u00dcbersetzung", ",", "Filterung", "sozialer", "Netzwerke", ",", "Brett-", "und", "Videospiele", ",", "medizinische", "Diagnose", "und", "sogar", "f\u00fcr", "T\u00e4tigkeiten", ",", "die", "traditionell", "als", "dem", "Menschen", "vorbehalten", "galten", ",", "wie", "z.", "B.", "Malen", "."], "sentence-detokenized": "ANNs wurden f\u00fcr eine Vielzahl von Aufgaben eingesetzt, darunter Computer Vision, Spracherkennung, maschinelle \u00dcbersetzung, Filterung sozialer Netzwerke, Brett- und Videospiele, medizinische Diagnose und sogar f\u00fcr T\u00e4tigkeiten, die traditionell als dem Menschen vorbehalten galten, wie z. B. Malen.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 29], [30, 33], [34, 42], [43, 53], [53, 54], [55, 63], [64, 72], [73, 79], [79, 80], [81, 96], [96, 97], [98, 109], [110, 121], [121, 122], [123, 132], [133, 141], [142, 151], [151, 152], [153, 159], [160, 163], [164, 175], [175, 176], [177, 189], [190, 198], [199, 202], [203, 208], [209, 212], [213, 224], [224, 225], [226, 229], [230, 242], [243, 246], [247, 250], [251, 259], [260, 271], [272, 278], [278, 279], [280, 283], [284, 286], [287, 289], [290, 295], [295, 296]]}
{"doc_key": "ai-test-200", "ner": [[0, 3, "product"], [5, 5, "product"], [16, 27, "field"], [29, 29, "field"], [34, 34, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 16, 27, "related-to", "", false, false], [0, 3, 34, 34, "general-affiliation", "", false, false], [5, 5, 0, 3, "named", "", false, false], [29, 29, 16, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Modular", "Audio", "Recognition", "Framework", "(", "MARF", ")", "ist", "eine", "Open-Source-Forschungsplattform", "und", "eine", "Sammlung", "von", "Algorithmen", "zur", "Verarbeitung", "von", "Stimme", ",", "Ton", ",", "Sprache", ",", "Text", "und", "nat\u00fcrlicher", "Sprache", "(", "NLP", ")", ",", "die", "in", "Java", "geschrieben", "und", "in", "einem", "modularen", "und", "erweiterbaren", "Rahmen", "angeordnet", "sind", ",", "der", "das", "Hinzuf\u00fcgen", "neuer", "Algorithmen", "erleichtern", "soll", "."], "sentence-detokenized": "Modular Audio Recognition Framework (MARF) ist eine Open-Source-Forschungsplattform und eine Sammlung von Algorithmen zur Verarbeitung von Stimme, Ton, Sprache, Text und nat\u00fcrlicher Sprache (NLP), die in Java geschrieben und in einem modularen und erweiterbaren Rahmen angeordnet sind, der das Hinzuf\u00fcgen neuer Algorithmen erleichtern soll.", "token2charspan": [[0, 7], [8, 13], [14, 25], [26, 35], [36, 37], [37, 41], [41, 42], [43, 46], [47, 51], [52, 83], [84, 87], [88, 92], [93, 101], [102, 105], [106, 117], [118, 121], [122, 134], [135, 138], [139, 145], [145, 146], [147, 150], [150, 151], [152, 159], [159, 160], [161, 165], [166, 169], [170, 181], [182, 189], [190, 191], [191, 194], [194, 195], [195, 196], [197, 200], [201, 203], [204, 208], [209, 220], [221, 224], [225, 227], [228, 233], [234, 243], [244, 247], [248, 261], [262, 268], [269, 279], [280, 284], [284, 285], [286, 289], [290, 293], [294, 304], [305, 310], [311, 322], [323, 334], [335, 339], [339, 340]]}
{"doc_key": "ai-test-201", "ner": [[8, 10, "organisation"], [15, 15, "country"], [19, 22, "organisation"], [25, 26, "organisation"], [35, 35, "task"], [47, 51, "organisation"], [45, 46, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[19, 22, 15, 15, "physical", "", false, false], [19, 22, 35, 35, "usage", "", false, false], [19, 22, 47, 51, "named", "", false, false], [25, 26, 15, 15, "physical", "", false, false], [25, 26, 35, 35, "usage", "", false, false], [47, 51, 45, 46, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Im", "Jahr", "2018", "deckte", "ein", "Bericht", "der", "B\u00fcrgerrechtsorganisation", "Big", "Brother", "Watch", "auf", ",", "dass", "zwei", "britische", "Polizeikr\u00e4fte", ",", "die", "Polizei", "von", "South", "Wales", "und", "die", "Metropolitan", "Police", ",", "bei", "\u00f6ffentlichen", "Veranstaltungen", "und", "im", "\u00f6ffentlichen", "Raum", "Live-Gesichtserkennung", "einsetzten", ";", "im", "September", "2019", "wurde", "der", "Einsatz", "der", "Gesichtserkennung", "durch", "die", "Polizei", "von", "South", "Wales", "f\u00fcr", "rechtm\u00e4\u00dfig", "erkl\u00e4rt", "."], "sentence-detokenized": "Im Jahr 2018 deckte ein Bericht der B\u00fcrgerrechtsorganisation Big Brother Watch auf, dass zwei britische Polizeikr\u00e4fte, die Polizei von South Wales und die Metropolitan Police, bei \u00f6ffentlichen Veranstaltungen und im \u00f6ffentlichen Raum Live-Gesichtserkennung einsetzten; im September 2019 wurde der Einsatz der Gesichtserkennung durch die Polizei von South Wales f\u00fcr rechtm\u00e4\u00dfig erkl\u00e4rt.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 19], [20, 23], [24, 31], [32, 35], [36, 60], [61, 64], [65, 72], [73, 78], [79, 82], [82, 83], [84, 88], [89, 93], [94, 103], [104, 117], [117, 118], [119, 122], [123, 130], [131, 134], [135, 140], [141, 146], [147, 150], [151, 154], [155, 167], [168, 174], [174, 175], [176, 179], [180, 192], [193, 208], [209, 212], [213, 215], [216, 228], [229, 233], [234, 256], [257, 267], [267, 268], [269, 271], [272, 281], [282, 286], [287, 292], [293, 296], [297, 304], [305, 308], [309, 326], [327, 332], [333, 336], [337, 344], [345, 348], [349, 354], [355, 360], [361, 364], [365, 375], [376, 383], [383, 384]]}
{"doc_key": "ai-test-202", "ner": [[0, 1, "product"], [3, 3, "programlang"], [13, 14, "field"], [16, 16, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 3, 3, "general-affiliation", "", false, false], [0, 1, 13, 14, "related-to", "", false, false], [0, 1, 16, 16, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["ANIMAL", "wurde", "auf", "R", "portiert", ",", "eine", "frei", "verf\u00fcgbare", "Sprache", "und", "Umgebung", "f\u00fcr", "statistische", "Berechnungen", "und", "Grafiken", "."], "sentence-detokenized": "ANIMAL wurde auf R portiert, eine frei verf\u00fcgbare Sprache und Umgebung f\u00fcr statistische Berechnungen und Grafiken.", "token2charspan": [[0, 6], [7, 12], [13, 16], [17, 18], [19, 27], [27, 28], [29, 33], [34, 38], [39, 49], [50, 57], [58, 61], [62, 70], [71, 74], [75, 87], [88, 100], [101, 104], [105, 113], [113, 114]]}
{"doc_key": "ai-test-203", "ner": [[0, 3, "algorithm"], [5, 5, "algorithm"], [11, 12, "algorithm"], [14, 14, "algorithm"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 11, 12, "opposite", "alternative to", false, false], [5, 5, 0, 3, "named", "", false, false], [14, 14, 11, 12, "named", "", false, false], [18, 19, 0, 3, "usage", "", false, false], [18, 19, 11, 12, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Das", "zeitinhomogene", "versteckte", "Bernoulli-Modell", "(", "TI-HBM", ")", "ist", "eine", "Alternative", "zum", "versteckten", "Markov-Modell", "(", "HMM", ")", "f\u00fcr", "die", "automatische", "Spracherkennung", "."], "sentence-detokenized": "Das zeitinhomogene versteckte Bernoulli-Modell (TI-HBM) ist eine Alternative zum versteckten Markov-Modell (HMM) f\u00fcr die automatische Spracherkennung.", "token2charspan": [[0, 3], [4, 18], [19, 29], [30, 46], [47, 48], [48, 54], [54, 55], [56, 59], [60, 64], [65, 76], [77, 80], [81, 92], [93, 106], [107, 108], [108, 111], [111, 112], [113, 116], [117, 120], [121, 133], [134, 149], [149, 150]]}
{"doc_key": "ai-test-204", "ner": [[4, 4, "organisation"], [7, 7, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 7, 7, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Im", "Juli", "2016", "demonstrierte", "Nvidia", "auf", "der", "SIGGRAPH", "eine", "neue", "Methode", "des", "foveated", "rendering", ",", "die", "angeblich", "f\u00fcr", "den", "Nutzer", "unsichtbar", "ist", "."], "sentence-detokenized": "Im Juli 2016 demonstrierte Nvidia auf der SIGGRAPH eine neue Methode des foveated rendering, die angeblich f\u00fcr den Nutzer unsichtbar ist.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 26], [27, 33], [34, 37], [38, 41], [42, 50], [51, 55], [56, 60], [61, 68], [69, 72], [73, 81], [82, 91], [91, 92], [93, 96], [97, 106], [107, 110], [111, 114], [115, 121], [122, 132], [133, 136], [136, 137]]}
{"doc_key": "ai-test-205", "ner": [[4, 4, "misc"], [8, 9, "researcher"], [17, 18, "researcher"], [20, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 8, 9, "origin", "", false, false], [4, 4, 17, 18, "origin", "", false, false], [4, 4, 20, 20, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Beide", "basieren", "auf", "der", "Sprechakttheorie", ",", "die", "von", "John", "Searle", "in", "den", "1960er", "Jahren", "entwickelt", "und", "von", "Terry", "Winograd", "und", "Flores", "in", "den", "1970er", "Jahren", "weiterentwickelt", "wurde", "."], "sentence-detokenized": "Beide basieren auf der Sprechakttheorie, die von John Searle in den 1960er Jahren entwickelt und von Terry Winograd und Flores in den 1970er Jahren weiterentwickelt wurde.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 22], [23, 39], [39, 40], [41, 44], [45, 48], [49, 53], [54, 60], [61, 63], [64, 67], [68, 74], [75, 81], [82, 92], [93, 96], [97, 100], [101, 106], [107, 115], [116, 119], [120, 126], [127, 129], [130, 133], [134, 140], [141, 147], [148, 164], [165, 170], [170, 171]]}
{"doc_key": "ai-test-206", "ner": [[0, 1, "algorithm"], [14, 15, "researcher"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 14, 15, "related-to", "", false, false], [16, 16, 14, 15, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Neuronale", "Netzmodelle", "der", "Begriffsbildung", "und", "der", "Wissensstruktur", "haben", "leistungsf\u00e4hige", "hierarchische", "Modelle", "der", "Wissensorganisation", "wie", "George", "Millers", "Wordnet", "er\u00f6ffnet", "."], "sentence-detokenized": "Neuronale Netzmodelle der Begriffsbildung und der Wissensstruktur haben leistungsf\u00e4hige hierarchische Modelle der Wissensorganisation wie George Millers Wordnet er\u00f6ffnet.", "token2charspan": [[0, 9], [10, 21], [22, 25], [26, 41], [42, 45], [46, 49], [50, 65], [66, 71], [72, 87], [88, 101], [102, 109], [110, 113], [114, 133], [134, 137], [138, 144], [145, 152], [153, 160], [161, 169], [169, 170]]}
{"doc_key": "ai-test-207", "ner": [[0, 1, "algorithm"], [11, 11, "field"], [14, 14, "product"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 11, 11, "part-of", "", false, false], [0, 1, 18, 19, "part-of", "", false, false], [14, 14, 11, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Der", "Vorlagenabgleich", "hat", "verschiedene", "Anwendungen", "und", "wird", "in", "Bereichen", "wie", "der", "Gesichtserkennung", "(", "siehe", "Gesichtserkennungssystem", ")", "und", "der", "medizinischen", "Bildverarbeitung", "eingesetzt", "."], "sentence-detokenized": "Der Vorlagenabgleich hat verschiedene Anwendungen und wird in Bereichen wie der Gesichtserkennung (siehe Gesichtserkennungssystem) und der medizinischen Bildverarbeitung eingesetzt.", "token2charspan": [[0, 3], [4, 20], [21, 24], [25, 37], [38, 49], [50, 53], [54, 58], [59, 61], [62, 71], [72, 75], [76, 79], [80, 97], [98, 99], [99, 104], [105, 129], [129, 130], [131, 134], [135, 138], [139, 152], [153, 169], [170, 180], [180, 181]]}
{"doc_key": "ai-test-208", "ner": [[10, 11, "researcher"], [13, 14, "researcher"], [18, 26, "organisation"], [28, 28, "organisation"], [35, 35, "algorithm"], [38, 44, "conference"], [46, 46, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 11, 18, 26, "role", "", false, false], [10, 11, 38, 44, "physical", "", false, false], [10, 11, 38, 44, "temporal", "", false, false], [10, 11, 46, 46, "physical", "", false, false], [13, 14, 18, 26, "role", "", false, false], [13, 14, 38, 44, "temporal", "", false, false], [28, 28, 18, 26, "named", "", false, false], [38, 44, 35, 35, "topic", "", false, false], [46, 46, 38, 44, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Die", "Verwendung", "wurde", "jedoch", "erst", "2005", "weit", "verbreitet", ",", "als", "Navneet", "Dalal", "und", "Bill", "Triggs", ",", "Forscher", "des", "franz\u00f6sischen", "Nationalen", "Instituts", "f\u00fcr", "Forschung", "in", "Informatik", "und", "Automatisierung", "(", "INRIA", ")", ",", "ihre", "erg\u00e4nzenden", "Arbeiten", "zu", "HOG-Deskriptoren", "auf", "der", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "vorstellten", "."], "sentence-detokenized": "Die Verwendung wurde jedoch erst 2005 weit verbreitet, als Navneet Dalal und Bill Triggs, Forscher des franz\u00f6sischen Nationalen Instituts f\u00fcr Forschung in Informatik und Automatisierung (INRIA), ihre erg\u00e4nzenden Arbeiten zu HOG-Deskriptoren auf der Conference on Computer Vision and Pattern Recognition (CVPR) vorstellten.", "token2charspan": [[0, 3], [4, 14], [15, 20], [21, 27], [28, 32], [33, 37], [38, 42], [43, 53], [53, 54], [55, 58], [59, 66], [67, 72], [73, 76], [77, 81], [82, 88], [88, 89], [90, 98], [99, 102], [103, 116], [117, 127], [128, 137], [138, 141], [142, 151], [152, 154], [155, 165], [166, 169], [170, 185], [186, 187], [187, 192], [192, 193], [193, 194], [195, 199], [200, 211], [212, 220], [221, 223], [224, 240], [241, 244], [245, 248], [249, 259], [260, 262], [263, 271], [272, 278], [279, 282], [283, 290], [291, 302], [303, 304], [304, 308], [308, 309], [310, 321], [321, 322]]}
{"doc_key": "ai-test-209", "ner": [[16, 19, "organisation"], [22, 23, "organisation"], [34, 36, "researcher"], [38, 40, "researcher"], [42, 44, "researcher"], [47, 50, "organisation"], [53, 56, "organisation"], [60, 61, "researcher"]], "ner_mapping_to_source": [1, 2, 4, 5, 6, 7, 8, 9], "relations": [[34, 36, 22, 23, "physical", "", false, false], [34, 36, 22, 23, "role", "", false, false], [38, 40, 22, 23, "physical", "", false, false], [38, 40, 22, 23, "role", "", false, false], [42, 44, 22, 23, "physical", "", false, false], [42, 44, 22, 23, "role", "", false, false], [60, 61, 53, 56, "role", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "sentence": ["Bevor", "er", "2002", "der", "Penn-Fakult\u00e4t", "beitrat", ",", "verbrachte", "er", "ein", "Jahrzehnt", "(", "1991-2001", ")", "in", "den", "AT", "&", "T", "Labs", "und", "den", "Bell", "Labs", ",", "u.", "a.", "als", "Leiter", "der", "KI-Abteilung", "mit", "Kollegen", "wie", "Michael", "L.", "Littman", ",", "David", "A.", "McAllester", "und", "Richard", "S.", "Sutton", ",", "der", "Forschungsabteilung", "f\u00fcr", "sichere", "Systeme", "und", "der", "Abteilung", "f\u00fcr", "maschinelles", "Lernen", "mit", "Mitgliedern", "wie", "Michael", "Collins", "und", "dem", "Leiter", ")", "."], "sentence-detokenized": "Bevor er 2002 der Penn-Fakult\u00e4t beitrat, verbrachte er ein Jahrzehnt (1991-2001) in den AT & T Labs und den Bell Labs, u. a. als Leiter der KI-Abteilung mit Kollegen wie Michael L. Littman, David A. McAllester und Richard S. Sutton, der Forschungsabteilung f\u00fcr sichere Systeme und der Abteilung f\u00fcr maschinelles Lernen mit Mitgliedern wie Michael Collins und dem Leiter).", "token2charspan": [[0, 5], [6, 8], [9, 13], [14, 17], [18, 31], [32, 39], [39, 40], [41, 51], [52, 54], [55, 58], [59, 68], [69, 70], [70, 79], [79, 80], [81, 83], [84, 87], [88, 90], [91, 92], [93, 94], [95, 99], [100, 103], [104, 107], [108, 112], [113, 117], [117, 118], [119, 121], [122, 124], [125, 128], [129, 135], [136, 139], [140, 152], [153, 156], [157, 165], [166, 169], [170, 177], [178, 180], [181, 188], [188, 189], [190, 195], [196, 198], [199, 209], [210, 213], [214, 221], [222, 224], [225, 231], [231, 232], [233, 236], [237, 256], [257, 260], [261, 268], [269, 276], [277, 280], [281, 284], [285, 294], [295, 298], [299, 311], [312, 318], [319, 322], [323, 334], [335, 338], [339, 346], [347, 354], [355, 358], [359, 362], [363, 369], [369, 370], [370, 371]]}
{"doc_key": "ai-test-210", "ner": [[7, 8, "field"], [14, 14, "field"], [23, 23, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 14, 14, "compare", "", false, false], [23, 23, 14, 14, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Wenn", "Daten", "nicht", "etikettiert", "sind", ",", "ist", "\u00fcberwachtes", "Lernen", "nicht", "m\u00f6glich", ",", "und", "ein", "un\u00fcberwachter", "Lernansatz", "ist", "erforderlich", ",", "der", "versucht", ",", "nat\u00fcrliche", "Clusteranalysen", "zu", "Gruppen", "zu", "finden", "und", "dann", "neue", "Daten", "diesen", "gebildeten", "Gruppen", "zuzuordnen", "."], "sentence-detokenized": "Wenn Daten nicht etikettiert sind, ist \u00fcberwachtes Lernen nicht m\u00f6glich, und ein un\u00fcberwachter Lernansatz ist erforderlich, der versucht, nat\u00fcrliche Clusteranalysen zu Gruppen zu finden und dann neue Daten diesen gebildeten Gruppen zuzuordnen.", "token2charspan": [[0, 4], [5, 10], [11, 16], [17, 28], [29, 33], [33, 34], [35, 38], [39, 50], [51, 57], [58, 63], [64, 71], [71, 72], [73, 76], [77, 80], [81, 94], [95, 105], [106, 109], [110, 122], [122, 123], [124, 127], [128, 136], [136, 137], [138, 148], [149, 164], [165, 167], [168, 175], [176, 178], [179, 185], [186, 189], [190, 194], [195, 199], [200, 205], [206, 212], [213, 223], [224, 231], [232, 242], [242, 243]]}
{"doc_key": "ai-test-211", "ner": [[3, 3, "field"], [15, 17, "organisation"], [24, 25, "field"], [28, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 15, 17, "origin", "", false, false], [3, 3, 24, 25, "part-of", "", false, false], [3, 3, 28, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dieser", "Bereich", "der", "Informatik", "entwickelte", "sich", "in", "den", "1950er", "Jahren", "an", "akademischen", "Einrichtungen", "wie", "dem", "MIT", "A.I.", "Lab", ",", "urspr\u00fcnglich", "als", "ein", "Zweig", "der", "k\u00fcnstlichen", "Intelligenz", "und", "der", "Robotik", "."], "sentence-detokenized": "Dieser Bereich der Informatik entwickelte sich in den 1950er Jahren an akademischen Einrichtungen wie dem MIT A.I. Lab, urspr\u00fcnglich als ein Zweig der k\u00fcnstlichen Intelligenz und der Robotik.", "token2charspan": [[0, 6], [7, 14], [15, 18], [19, 29], [30, 41], [42, 46], [47, 49], [50, 53], [54, 60], [61, 67], [68, 70], [71, 83], [84, 97], [98, 101], [102, 105], [106, 109], [110, 114], [115, 118], [118, 119], [120, 132], [133, 136], [137, 140], [141, 146], [147, 150], [151, 162], [163, 174], [175, 178], [179, 182], [183, 190], [190, 191]]}
{"doc_key": "ai-test-212", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sie", "k\u00f6nnte", "auch", "durch", "die", "nachstehende", "Log-Verlust-Gleichung", "ersetzt", "werden", ":"], "sentence-detokenized": "Sie k\u00f6nnte auch durch die nachstehende Log-Verlust-Gleichung ersetzt werden:", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 21], [22, 25], [26, 38], [39, 60], [61, 68], [69, 75], [75, 76]]}
{"doc_key": "ai-test-213", "ner": [[1, 3, "organisation"], [7, 10, "organisation"], [14, 18, "university"], [21, 21, "university"], [24, 25, "university"], [28, 29, "university"], [32, 32, "country"], [40, 40, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[1, 3, 40, 40, "related-to", "research_leader_in_field", false, false], [7, 10, 1, 3, "named", "", false, false], [7, 10, 40, 40, "related-to", "research_leader_in_field", false, false], [14, 18, 40, 40, "related-to", "research_leader_in_field", false, false], [21, 21, 40, 40, "related-to", "research_leader_in_field", false, false], [24, 25, 40, 40, "related-to", "research_leader_in_field", false, false], [28, 29, 32, 32, "physical", "", false, false], [28, 29, 40, 40, "related-to", "research_leader_in_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Das", "Shirley", "Ryan", "AbilityLab", "(", "ehemals", "das", "Rehabilitation", "Institute", "of", "Chicago", ")", ",", "die", "University", "of", "California", "in", "Berkeley", ",", "das", "MIT", ",", "die", "Stanford", "University", "und", "die", "Universit\u00e4t", "Twente", "in", "den", "Niederlanden", "sind", "die", "f\u00fchrenden", "Forschungseinrichtungen", "im", "Bereich", "der", "Biomechatronik", "."], "sentence-detokenized": "Das Shirley Ryan AbilityLab (ehemals das Rehabilitation Institute of Chicago), die University of California in Berkeley, das MIT, die Stanford University und die Universit\u00e4t Twente in den Niederlanden sind die f\u00fchrenden Forschungseinrichtungen im Bereich der Biomechatronik.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 27], [28, 29], [29, 36], [37, 40], [41, 55], [56, 65], [66, 68], [69, 76], [76, 77], [77, 78], [79, 82], [83, 93], [94, 96], [97, 107], [108, 110], [111, 119], [119, 120], [121, 124], [125, 128], [128, 129], [130, 133], [134, 142], [143, 153], [154, 157], [158, 161], [162, 173], [174, 180], [181, 183], [184, 187], [188, 200], [201, 205], [206, 209], [210, 219], [220, 243], [244, 246], [247, 254], [255, 258], [259, 273], [273, 274]]}
{"doc_key": "ai-test-214", "ner": [[26, 28, "metrics"], [39, 39, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Bei", "einer", "Reihe", "von", "vorhergesagten", "Werten", "und", "einer", "entsprechenden", "Reihe", "von", "tats\u00e4chlichen", "Werten", "f\u00fcr", "X", "f\u00fcr", "verschiedene", "Zeitr\u00e4ume", "besteht", "eine", "g\u00e4ngige", "Bewertungstechnik", "in", "der", "Verwendung", "des", "mittleren", "quadratischen", "Vorhersagefehlers", ";", "andere", "Ma\u00dfe", "sind", "ebenfalls", "verf\u00fcgbar", "(", "siehe", "Prognose", "#", "Vorhersagegenauigkeit", ")", "."], "sentence-detokenized": "Bei einer Reihe von vorhergesagten Werten und einer entsprechenden Reihe von tats\u00e4chlichen Werten f\u00fcr X f\u00fcr verschiedene Zeitr\u00e4ume besteht eine g\u00e4ngige Bewertungstechnik in der Verwendung des mittleren quadratischen Vorhersagefehlers; andere Ma\u00dfe sind ebenfalls verf\u00fcgbar (siehe Prognose # Vorhersagegenauigkeit).", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 19], [20, 34], [35, 41], [42, 45], [46, 51], [52, 66], [67, 72], [73, 76], [77, 90], [91, 97], [98, 101], [102, 103], [104, 107], [108, 120], [121, 130], [131, 138], [139, 143], [144, 151], [152, 169], [170, 172], [173, 176], [177, 187], [188, 191], [192, 201], [202, 215], [216, 233], [233, 234], [235, 241], [242, 246], [247, 251], [252, 261], [262, 271], [272, 273], [273, 278], [279, 287], [288, 289], [290, 311], [311, 312], [312, 313]]}
{"doc_key": "ai-test-215", "ner": [[12, 12, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Andere", "Ma\u00dfe", ",", "wie", "der", "Anteil", "der", "richtigen", "Vorhersagen", "(", "auch", "als", "Genauigkeit", "bezeichnet", ")", ",", "sind", "nicht", "sinnvoll", ",", "wenn", "die", "beiden", "Klassen", "sehr", "unterschiedlich", "gro\u00df", "sind", "."], "sentence-detokenized": "Andere Ma\u00dfe, wie der Anteil der richtigen Vorhersagen (auch als Genauigkeit bezeichnet), sind nicht sinnvoll, wenn die beiden Klassen sehr unterschiedlich gro\u00df sind.", "token2charspan": [[0, 6], [7, 11], [11, 12], [13, 16], [17, 20], [21, 27], [28, 31], [32, 41], [42, 53], [54, 55], [55, 59], [60, 63], [64, 75], [76, 86], [86, 87], [87, 88], [89, 93], [94, 99], [100, 108], [108, 109], [110, 114], [115, 118], [119, 125], [126, 133], [134, 138], [139, 154], [155, 159], [160, 164], [164, 165]]}
{"doc_key": "ai-test-216", "ner": [[4, 4, "product"], [10, 14, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 10, 14, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Die", "erste", "Alphaversion", "von", "OpenCV", "wurde", "auf", "der", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "im", "Jahr", "2000", "der", "\u00d6ffentlichkeit", "zug\u00e4nglich", "gemacht", ",", "und", "zwischen", "2001", "und", "2005", "wurden", "f\u00fcnf", "Betaversionen", "ver\u00f6ffentlicht", "."], "sentence-detokenized": "Die erste Alphaversion von OpenCV wurde auf der Conference on Computer Vision and Pattern Recognition im Jahr 2000 der \u00d6ffentlichkeit zug\u00e4nglich gemacht, und zwischen 2001 und 2005 wurden f\u00fcnf Betaversionen ver\u00f6ffentlicht.", "token2charspan": [[0, 3], [4, 9], [10, 22], [23, 26], [27, 33], [34, 39], [40, 43], [44, 47], [48, 58], [59, 61], [62, 70], [71, 77], [78, 81], [82, 89], [90, 101], [102, 104], [105, 109], [110, 114], [115, 118], [119, 133], [134, 144], [145, 152], [152, 153], [154, 157], [158, 166], [167, 171], [172, 175], [176, 180], [181, 187], [188, 192], [193, 206], [207, 221], [221, 222]]}
{"doc_key": "ai-test-217", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["Es", "wurden", "Ergebnisse", "pr\u00e4sentiert", ",", "die", "eine", "Korrelation", "von", "bis", "zu", "0,964", "mit", "der", "menschlichen", "Beurteilung", "auf", "Korpusebene", "ergeben", ",", "verglichen", "mit", "dem", "BLEU-Ergebnis", "von", "0,817", "f\u00fcr", "denselben", "Datensatz", "."], "sentence-detokenized": "Es wurden Ergebnisse pr\u00e4sentiert, die eine Korrelation von bis zu 0,964 mit der menschlichen Beurteilung auf Korpusebene ergeben, verglichen mit dem BLEU-Ergebnis von 0,817 f\u00fcr denselben Datensatz.", "token2charspan": [[0, 2], [3, 9], [10, 20], [21, 32], [32, 33], [34, 37], [38, 42], [43, 54], [55, 58], [59, 62], [63, 65], [66, 71], [72, 75], [76, 79], [80, 92], [93, 104], [105, 108], [109, 120], [121, 128], [128, 129], [130, 140], [141, 144], [145, 148], [149, 162], [163, 166], [167, 172], [173, 176], [177, 186], [187, 196], [196, 197]]}
{"doc_key": "ai-test-218", "ner": [[4, 4, "metrics"], [15, 15, "metrics"], [17, 19, "metrics"], [21, 21, "metrics"], [31, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 15, 15, "compare", "", false, false], [4, 4, 17, 19, "compare", "", false, false], [4, 4, 21, 21, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Eine", "fr\u00fche", "Version", "von", "VMAF", "hat", "gezeigt", ",", "dass", "sie", "andere", "Bild-", "und", "Videoqualit\u00e4tsmetriken", "wie", "SSIM", ",", "PSNR", "-", "HVS", "und", "VQM-VFD", "bei", "drei", "von", "vier", "Datens\u00e4tzen", "in", "Bezug", "auf", "die", "Vorhersagegenauigkeit", "\u00fcbertrifft", ",", "wenn", "sie", "mit", "subjektiven", "Bewertungen", "verglichen", "wird", "."], "sentence-detokenized": "Eine fr\u00fche Version von VMAF hat gezeigt, dass sie andere Bild- und Videoqualit\u00e4tsmetriken wie SSIM, PSNR -HVS und VQM-VFD bei drei von vier Datens\u00e4tzen in Bezug auf die Vorhersagegenauigkeit \u00fcbertrifft, wenn sie mit subjektiven Bewertungen verglichen wird.", "token2charspan": [[0, 4], [5, 10], [11, 18], [19, 22], [23, 27], [28, 31], [32, 39], [39, 40], [41, 45], [46, 49], [50, 56], [57, 62], [63, 66], [67, 89], [90, 93], [94, 98], [98, 99], [100, 104], [105, 106], [106, 109], [110, 113], [114, 121], [122, 125], [126, 130], [131, 134], [135, 139], [140, 151], [152, 154], [155, 160], [161, 164], [165, 168], [169, 190], [191, 201], [201, 202], [203, 207], [208, 211], [212, 215], [216, 227], [228, 239], [240, 250], [251, 255], [255, 256]]}
{"doc_key": "ai-test-219", "ner": [[16, 17, "task"], [25, 25, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 17, 25, 25, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["So", "ist", "beispielsweise", "die", "Mehrdeutigkeit", "von", "\"", "Maus", "\"", "(", "Tier", "oder", "Ger\u00e4t", ")", "f\u00fcr", "die", "maschinelle", "\u00dcbersetzung", "nicht", "relevant", ",", "wohl", "aber", "f\u00fcr", "die", "Informationsbeschaffung", "."], "sentence-detokenized": "So ist beispielsweise die Mehrdeutigkeit von \"Maus\" (Tier oder Ger\u00e4t) f\u00fcr die maschinelle \u00dcbersetzung nicht relevant, wohl aber f\u00fcr die Informationsbeschaffung.", "token2charspan": [[0, 2], [3, 6], [7, 21], [22, 25], [26, 40], [41, 44], [45, 46], [46, 50], [50, 51], [52, 53], [53, 57], [58, 62], [63, 68], [68, 69], [70, 73], [74, 77], [78, 89], [90, 101], [102, 107], [108, 116], [116, 117], [118, 122], [123, 127], [128, 131], [132, 135], [136, 159], [159, 160]]}
{"doc_key": "ai-test-220", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [10, 10, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 0, 1, "usage", "", false, false], [10, 10, 6, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Geometrisches", "Hashing", "wurde", "urspr\u00fcnglich", "in", "der", "Computer", "Vision", "f\u00fcr", "die", "Objekterkennung", "in", "2D", "und", "3D", "vorgeschlagen", ","], "sentence-detokenized": "Geometrisches Hashing wurde urspr\u00fcnglich in der Computer Vision f\u00fcr die Objekterkennung in 2D und 3D vorgeschlagen,", "token2charspan": [[0, 13], [14, 21], [22, 27], [28, 40], [41, 43], [44, 47], [48, 56], [57, 63], [64, 67], [68, 71], [72, 87], [88, 90], [91, 93], [94, 97], [98, 100], [101, 114], [114, 115]]}
{"doc_key": "ai-test-221", "ner": [[7, 8, "field"], [13, 14, "field"], [17, 17, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 14, 7, 8, "part-of", "subfield", false, false], [17, 17, 7, 8, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Es", "bildet", "eine", "der", "drei", "Hauptkategorien", "des", "maschinellen", "Lernens", ",", "zusammen", "mit", "dem", "\u00fcberwachten", "Lernen", "und", "dem", "Verst\u00e4rkungslernen", "."], "sentence-detokenized": "Es bildet eine der drei Hauptkategorien des maschinellen Lernens, zusammen mit dem \u00fcberwachten Lernen und dem Verst\u00e4rkungslernen.", "token2charspan": [[0, 2], [3, 9], [10, 14], [15, 18], [19, 23], [24, 39], [40, 43], [44, 56], [57, 64], [64, 65], [66, 74], [75, 78], [79, 82], [83, 94], [95, 101], [102, 105], [106, 109], [110, 128], [128, 129]]}
{"doc_key": "ai-test-222", "ner": [[0, 0, "field"], [17, 17, "field"], [20, 21, "field"], [25, 25, "field"], [29, 30, "field"], [33, 33, "field"], [37, 37, "field"], [41, 41, "field"], [44, 45, "algorithm"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 0, 17, 17, "part-of", "subfield", false, false], [0, 0, 20, 21, "part-of", "subfield", false, false], [0, 0, 25, 25, "part-of", "subfield", false, false], [0, 0, 29, 30, "part-of", "subfield", false, false], [0, 0, 33, 33, "part-of", "subfield", false, false], [0, 0, 37, 37, "part-of", "subfield", false, false], [0, 0, 41, 41, "part-of", "subfield", false, false], [0, 0, 44, 45, "part-of", "subfield", false, false]], "relations_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Verst\u00e4rkungslernen", "wird", "aufgrund", "seiner", "Allgemeinheit", "in", "vielen", "anderen", "Disziplinen", "untersucht", ",", "z.", "B.", "in", "der", "Spiel-", "und", "Kontrolltheorie", ",", "im", "Operations", "Research", ",", "in", "der", "Informationstheorie", ",", "in", "der", "simulationsbasierten", "Optimierung", ",", "in", "Multiagentensystemen", ",", "in", "der", "Schwarmintelligenz", ",", "in", "der", "Statistik", "und", "in", "genetischen", "Algorithmen", "."], "sentence-detokenized": "Verst\u00e4rkungslernen wird aufgrund seiner Allgemeinheit in vielen anderen Disziplinen untersucht, z. B. in der Spiel- und Kontrolltheorie, im Operations Research, in der Informationstheorie, in der simulationsbasierten Optimierung, in Multiagentensystemen, in der Schwarmintelligenz, in der Statistik und in genetischen Algorithmen.", "token2charspan": [[0, 18], [19, 23], [24, 32], [33, 39], [40, 53], [54, 56], [57, 63], [64, 71], [72, 83], [84, 94], [94, 95], [96, 98], [99, 101], [102, 104], [105, 108], [109, 115], [116, 119], [120, 135], [135, 136], [137, 139], [140, 150], [151, 159], [159, 160], [161, 163], [164, 167], [168, 187], [187, 188], [189, 191], [192, 195], [196, 216], [217, 228], [228, 229], [230, 232], [233, 253], [253, 254], [255, 257], [258, 261], [262, 280], [280, 281], [282, 284], [285, 288], [289, 298], [299, 302], [303, 305], [306, 317], [318, 329], [329, 330]]}
{"doc_key": "ai-test-223", "ner": [[0, 1, "field"], [6, 7, "field"], [10, 11, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "related-to", "", false, false], [0, 1, 10, 11, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Die", "Mustererkennung", "ist", "eng", "mit", "der", "k\u00fcnstlichen", "Intelligenz", "und", "dem", "maschinellen", "Lernen", "verbunden", ","], "sentence-detokenized": "Die Mustererkennung ist eng mit der k\u00fcnstlichen Intelligenz und dem maschinellen Lernen verbunden,", "token2charspan": [[0, 3], [4, 19], [20, 23], [24, 27], [28, 31], [32, 35], [36, 47], [48, 59], [60, 63], [64, 67], [68, 80], [81, 87], [88, 97], [97, 98]]}
{"doc_key": "ai-test-224", "ner": [[12, 13, "algorithm"], [15, 15, "field"], [17, 18, "field"], [27, 28, "task"], [30, 30, "task"], [32, 32, "task"], [34, 35, "algorithm"], [37, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[12, 13, 15, 15, "related-to", "", false, false], [12, 13, 17, 18, "related-to", "", false, false], [27, 28, 12, 13, "usage", "", true, false], [30, 30, 12, 13, "usage", "", true, false], [32, 32, 12, 13, "usage", "", true, false], [34, 35, 12, 13, "usage", "", true, false], [37, 37, 12, 13, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Die", "Software", "dient", "zum", "Entwerfen", ",", "Trainieren", "und", "Bereitstellen", "von", "Modellen", "f\u00fcr", "neuronale", "Netze", "(", "\u00fcberwachtes", "und", "un\u00fcberwachtes", "Lernen", ")", "zur", "Durchf\u00fchrung", "einer", "Vielzahl", "von", "Aufgaben", "wie", "Data", "Mining", ",", "Klassifizierung", ",", "Funktionsann\u00e4herung", ",", "multivariate", "Regression", "und", "Zeitreihenvorhersage", "."], "sentence-detokenized": "Die Software dient zum Entwerfen, Trainieren und Bereitstellen von Modellen f\u00fcr neuronale Netze (\u00fcberwachtes und un\u00fcberwachtes Lernen) zur Durchf\u00fchrung einer Vielzahl von Aufgaben wie Data Mining, Klassifizierung, Funktionsann\u00e4herung, multivariate Regression und Zeitreihenvorhersage.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 22], [23, 32], [32, 33], [34, 44], [45, 48], [49, 62], [63, 66], [67, 75], [76, 79], [80, 89], [90, 95], [96, 97], [97, 108], [109, 112], [113, 126], [127, 133], [133, 134], [135, 138], [139, 151], [152, 157], [158, 166], [167, 170], [171, 179], [180, 183], [184, 188], [189, 195], [195, 196], [197, 212], [212, 213], [214, 233], [233, 234], [235, 247], [248, 258], [259, 262], [263, 283], [283, 284]]}
{"doc_key": "ai-test-225", "ner": [[8, 14, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Im", "Jahr", "2016", "wurde", "er", "zum", "Fellow", "der", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "gew\u00e4hlt", "."], "sentence-detokenized": "Im Jahr 2016 wurde er zum Fellow der Association for the Advancement of Artificial Intelligence gew\u00e4hlt.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 18], [19, 21], [22, 25], [26, 32], [33, 36], [37, 48], [49, 52], [53, 56], [57, 68], [69, 71], [72, 82], [83, 95], [96, 103], [103, 104]]}
{"doc_key": "ai-test-226", "ner": [[4, 7, "organisation"], [14, 19, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sie", "ist", "Mitglied", "der", "National", "Academy", "of", "Sciences", "(", "seit", "2005", ")", "und", "der", "American", "Academy", "of", "Arts", "and", "Sciences", "(", "seit", "2009", ")", ","], "sentence-detokenized": "Sie ist Mitglied der National Academy of Sciences (seit 2005) und der American Academy of Arts and Sciences (seit 2009),", "token2charspan": [[0, 3], [4, 7], [8, 16], [17, 20], [21, 29], [30, 37], [38, 40], [41, 49], [50, 51], [51, 55], [56, 60], [60, 61], [62, 65], [66, 69], [70, 78], [79, 86], [87, 89], [90, 94], [95, 98], [99, 107], [108, 109], [109, 113], [114, 118], [118, 119], [119, 120]]}
{"doc_key": "ai-test-227", "ner": [[2, 2, "misc"], [12, 12, "country"], [14, 14, "country"], [18, 20, "misc"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["W\u00e4hrend", "des", "Jom-Kippur-Krieges", "1973", "richteten", "die", "von", "der", "Sowjetunion", "gelieferten", "Boden-Luft-Raketenbatterien", "in", "\u00c4gypten", "und", "Syrien", "schwere", "Sch\u00e4den", "an", "israelischen", "Kampfflugzeugen", "an", "."], "sentence-detokenized": "W\u00e4hrend des Jom-Kippur-Krieges 1973 richteten die von der Sowjetunion gelieferten Boden-Luft-Raketenbatterien in \u00c4gypten und Syrien schwere Sch\u00e4den an israelischen Kampfflugzeugen an.", "token2charspan": [[0, 7], [8, 11], [12, 30], [31, 35], [36, 45], [46, 49], [50, 53], [54, 57], [58, 69], [70, 81], [82, 109], [110, 112], [113, 120], [121, 124], [125, 131], [132, 139], [140, 147], [148, 150], [151, 163], [164, 179], [180, 182], [182, 183]]}
{"doc_key": "ai-test-228", "ner": [[12, 12, "product"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 17, 12, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Eine", "weitere", "(", "kostenlose", ",", "aber", "urheberrechtlich", "gesch\u00fctzte", ")", "Ressource", "ist", "das", "HTK-Buch", "(", "und", "das", "dazugeh\u00f6rige", "HTK-Toolkit", ")", "."], "sentence-detokenized": "Eine weitere (kostenlose, aber urheberrechtlich gesch\u00fctzte) Ressource ist das HTK-Buch (und das dazugeh\u00f6rige HTK-Toolkit).", "token2charspan": [[0, 4], [5, 12], [13, 14], [14, 24], [24, 25], [26, 30], [31, 47], [48, 58], [58, 59], [60, 69], [70, 73], [74, 77], [78, 86], [87, 88], [88, 91], [92, 95], [96, 108], [109, 120], [120, 121], [121, 122]]}
{"doc_key": "ai-test-229", "ner": [[4, 5, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["-", "wurden", "auf", "dem", "AAAI-Fr\u00fchjahrssymposium", "2004", "aufgenommen", ",", "auf", "dem", "Linguisten", ",", "Informatiker", "und", "andere", "interessierte", "Forscher", "erstmals", "ihre", "Interessen", "abstimmten", "und", "gemeinsame", "Aufgaben", "und", "Benchmark-Datens\u00e4tze", "f\u00fcr", "die", "systematische", "computergest\u00fctzte", "Erforschung", "von", "Affekt", ",", "Appell", ",", "Subjektivit\u00e4t", "und", "Stimmung", "in", "Texten", "vorschlugen", "."], "sentence-detokenized": "- wurden auf dem AAAI-Fr\u00fchjahrssymposium 2004 aufgenommen, auf dem Linguisten, Informatiker und andere interessierte Forscher erstmals ihre Interessen abstimmten und gemeinsame Aufgaben und Benchmark-Datens\u00e4tze f\u00fcr die systematische computergest\u00fctzte Erforschung von Affekt, Appell, Subjektivit\u00e4t und Stimmung in Texten vorschlugen.", "token2charspan": [[0, 1], [2, 8], [9, 12], [13, 16], [17, 40], [41, 45], [46, 57], [57, 58], [59, 62], [63, 66], [67, 77], [77, 78], [79, 91], [92, 95], [96, 102], [103, 116], [117, 125], [126, 134], [135, 139], [140, 150], [151, 161], [162, 165], [166, 176], [177, 185], [186, 189], [190, 210], [211, 214], [215, 218], [219, 232], [233, 250], [251, 262], [263, 266], [267, 273], [273, 274], [275, 281], [281, 282], [283, 296], [297, 300], [301, 309], [310, 312], [313, 319], [320, 331], [331, 332]]}
{"doc_key": "ai-test-230", "ner": [[7, 7, "task"], [15, 15, "task"], [17, 17, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ein", "einziges", "Raster", "kann", "sowohl", "inhaltlich", "(", "Augenschein", ")", "als", "auch", "strukturell", "analysiert", "werden", "(", "Clusteranalyse", ",", "Hauptkomponentenanalyse", "und", "eine", "Reihe", "von", "Strukturindizes", ",", "die", "sich", "auf", "die", "Komplexit\u00e4t", "und", "den", "Umfang", "der", "Bewertungen", "beziehen", ",", "sind", "die", "wichtigsten", "verwendeten", "Techniken", ")", "."], "sentence-detokenized": "Ein einziges Raster kann sowohl inhaltlich (Augenschein) als auch strukturell analysiert werden (Clusteranalyse, Hauptkomponentenanalyse und eine Reihe von Strukturindizes, die sich auf die Komplexit\u00e4t und den Umfang der Bewertungen beziehen, sind die wichtigsten verwendeten Techniken).", "token2charspan": [[0, 3], [4, 12], [13, 19], [20, 24], [25, 31], [32, 42], [43, 44], [44, 55], [55, 56], [57, 60], [61, 65], [66, 77], [78, 88], [89, 95], [96, 97], [97, 111], [111, 112], [113, 136], [137, 140], [141, 145], [146, 151], [152, 155], [156, 171], [171, 172], [173, 176], [177, 181], [182, 185], [186, 189], [190, 201], [202, 205], [206, 209], [210, 216], [217, 220], [221, 232], [233, 241], [241, 242], [243, 247], [248, 251], [252, 263], [264, 275], [276, 285], [285, 286], [286, 287]]}
{"doc_key": "ai-test-231", "ner": [[4, 5, "organisation"], [8, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Im", "Jahr", "2018", "galt", "Toyota", "als", "r\u00fcckst\u00e4ndig", "bei", "selbstfahrenden", "Autos", "und", "als", "innovationsbed\u00fcrftig", "."], "sentence-detokenized": "Im Jahr 2018 galt Toyota als r\u00fcckst\u00e4ndig bei selbstfahrenden Autos und als innovationsbed\u00fcrftig.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 17], [18, 24], [25, 28], [29, 40], [41, 44], [45, 60], [61, 66], [67, 70], [71, 74], [75, 95], [95, 96]]}
{"doc_key": "ai-test-232", "ner": [[38, 38, "misc"], [40, 40, "misc"], [42, 42, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Zu", "diesen", "Zielen", "geh\u00f6ren", "nat\u00fcrliche", "Objekte", "wie", "der", "Boden", ",", "das", "Meer", ",", "Niederschl\u00e4ge", "(", "wie", "Regen", ",", "Schnee", "oder", "Hagel", ")", ",", "Sandst\u00fcrme", ",", "Tiere", "(", "insbesondere", "V\u00f6gel", ")", ",", "atmosph\u00e4rische", "Turbulenzen", "und", "andere", "atmosph\u00e4rische", "Effekte", "wie", "Ionosph\u00e4renreflexionen", ",", "Meteorspuren", "und", "Dreik\u00f6rperstreuungen", "."], "sentence-detokenized": "Zu diesen Zielen geh\u00f6ren nat\u00fcrliche Objekte wie der Boden, das Meer, Niederschl\u00e4ge (wie Regen, Schnee oder Hagel), Sandst\u00fcrme, Tiere (insbesondere V\u00f6gel), atmosph\u00e4rische Turbulenzen und andere atmosph\u00e4rische Effekte wie Ionosph\u00e4renreflexionen, Meteorspuren und Dreik\u00f6rperstreuungen.", "token2charspan": [[0, 2], [3, 9], [10, 16], [17, 24], [25, 35], [36, 43], [44, 47], [48, 51], [52, 57], [57, 58], [59, 62], [63, 67], [67, 68], [69, 82], [83, 84], [84, 87], [88, 93], [93, 94], [95, 101], [102, 106], [107, 112], [112, 113], [113, 114], [115, 125], [125, 126], [127, 132], [133, 134], [134, 146], [147, 152], [152, 153], [153, 154], [155, 169], [170, 181], [182, 185], [186, 192], [193, 207], [208, 215], [216, 219], [220, 242], [242, 243], [244, 256], [257, 260], [261, 281], [281, 282]]}
{"doc_key": "ai-test-233", "ner": [[19, 19, "product"], [44, 45, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Bei", "der", "Planung", "und", "Steuerung", "besteht", "der", "wesentliche", "Unterschied", "zwischen", "Humanoiden", "und", "anderen", "Arten", "von", "Robotern", "(", "z.", "B.", "Industrierobotern", ")", "darin", ",", "dass", "die", "Bewegung", "des", "Roboters", "menschen\u00e4hnlich", "sein", "muss", ",", "d.", "h.", "er", "muss", "sich", "auf", "den", "Beinen", "fortbewegen", ",", "insbesondere", "auf", "zwei", "Beinen", "."], "sentence-detokenized": "Bei der Planung und Steuerung besteht der wesentliche Unterschied zwischen Humanoiden und anderen Arten von Robotern (z. B. Industrierobotern) darin, dass die Bewegung des Roboters menschen\u00e4hnlich sein muss, d. h. er muss sich auf den Beinen fortbewegen, insbesondere auf zwei Beinen.", "token2charspan": [[0, 3], [4, 7], [8, 15], [16, 19], [20, 29], [30, 37], [38, 41], [42, 53], [54, 65], [66, 74], [75, 85], [86, 89], [90, 97], [98, 103], [104, 107], [108, 116], [117, 118], [118, 120], [121, 123], [124, 141], [141, 142], [143, 148], [148, 149], [150, 154], [155, 158], [159, 167], [168, 171], [172, 180], [181, 196], [197, 201], [202, 206], [206, 207], [208, 210], [211, 213], [214, 216], [217, 221], [222, 226], [227, 230], [231, 234], [235, 241], [242, 253], [253, 254], [255, 267], [268, 271], [272, 276], [277, 283], [283, 284]]}
{"doc_key": "ai-test-234", "ner": [[1, 1, "algorithm"], [9, 10, "misc"], [14, 14, "metrics"], [20, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Der", "Gradientenabstieg", "kann", "viele", "Iterationen", "ben\u00f6tigen", ",", "um", "ein", "lokales", "Minimum", "mit", "der", "erforderlichen", "Genauigkeit", "zu", "berechnen", ",", "wenn", "die", "Kr\u00fcmmung", "in", "verschiedenen", "Richtungen", "f\u00fcr", "die", "gegebene", "Funktion", "sehr", "unterschiedlich", "ist", "."], "sentence-detokenized": "Der Gradientenabstieg kann viele Iterationen ben\u00f6tigen, um ein lokales Minimum mit der erforderlichen Genauigkeit zu berechnen, wenn die Kr\u00fcmmung in verschiedenen Richtungen f\u00fcr die gegebene Funktion sehr unterschiedlich ist.", "token2charspan": [[0, 3], [4, 21], [22, 26], [27, 32], [33, 44], [45, 54], [54, 55], [56, 58], [59, 62], [63, 70], [71, 78], [79, 82], [83, 86], [87, 101], [102, 113], [114, 116], [117, 126], [126, 127], [128, 132], [133, 136], [137, 145], [146, 148], [149, 162], [163, 173], [174, 177], [178, 181], [182, 190], [191, 199], [200, 204], [205, 220], [221, 224], [224, 225]]}
{"doc_key": "ai-test-235", "ner": [[1, 6, "misc"], [17, 22, "conference"], [30, 30, "location"], [32, 34, "country"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[17, 22, 30, 30, "physical", "", false, true], [30, 30, 32, 34, "physical", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["Die", "RoboCup", "2D", "Soccer", "Simulation", "League", "1997", "war", "der", "erste", "RoboCup-Wettbewerb", ",", "der", "in", "Verbindung", "mit", "der", "International", "Joint", "Conference", "on", "Artificial", "Intelligence", "vom", "23.", "bis", "29.", "August", "1997", "in", "Nagoya", ",", "Japan", ",", "stattfand", "."], "sentence-detokenized": "Die RoboCup 2D Soccer Simulation League 1997 war der erste RoboCup-Wettbewerb, der in Verbindung mit der International Joint Conference on Artificial Intelligence vom 23. bis 29. August 1997 in Nagoya, Japan, stattfand.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 21], [22, 32], [33, 39], [40, 44], [45, 48], [49, 52], [53, 58], [59, 77], [77, 78], [79, 82], [83, 85], [86, 96], [97, 100], [101, 104], [105, 118], [119, 124], [125, 135], [136, 138], [139, 149], [150, 162], [163, 166], [167, 170], [171, 174], [175, 178], [179, 185], [186, 190], [191, 193], [194, 200], [200, 201], [202, 207], [207, 208], [209, 218], [218, 219]]}
{"doc_key": "ai-test-236", "ner": [[12, 12, "product"]], "ner_mapping_to_source": [2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Weitere", "Programmieroptionen", "sind", "eine", "eingebettete", "Python-Umgebung", "und", "eine", "R-Konsole", "sowie", "Unterst\u00fctzung", "f\u00fcr", "Rserve", "."], "sentence-detokenized": "Weitere Programmieroptionen sind eine eingebettete Python-Umgebung und eine R-Konsole sowie Unterst\u00fctzung f\u00fcr Rserve.", "token2charspan": [[0, 7], [8, 27], [28, 32], [33, 37], [38, 50], [51, 66], [67, 70], [71, 75], [76, 85], [86, 91], [92, 105], [106, 109], [110, 116], [116, 117]]}
{"doc_key": "ai-test-237", "ner": [[1, 1, "location"], [8, 9, "field"], [11, 11, "field"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 23, "researcher"], [29, 29, "field"], [33, 33, "field"], [37, 37, "field"], [42, 43, "field"], [49, 53, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[16, 17, 11, 11, "related-to", "contributes_to_field", true, false], [19, 20, 11, 11, "related-to", "contributes_to_field", true, false], [22, 23, 11, 11, "related-to", "contributes_to_field", true, false], [37, 37, 33, 33, "part-of", "", false, false], [42, 43, 37, 37, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Von", "Bonn", "aus", "leistete", "er", "grundlegende", "Beitr\u00e4ge", "zur", "K\u00fcnstlichen", "Intelligenz", "und", "Robotik", "(", "u.", "a.", "mit", "Wolfram", "Burgard", ",", "Dieter", "Fox", ",", "Sebastian", "Thrun", ")", "sowie", "zur", "Entwicklung", "des", "Software-Engineerings", ",", "insbesondere", "im", "Bauwesen", ",", "und", "der", "Informationssysteme", ",", "insbesondere", "in", "den", "Geowissenschaften", ".", "2016", "wurde", "er", "mit", "dem", "AAAI", "Classic", "Paper", "Award", "ausgezeichnet.", "2014."], "sentence-detokenized": "Von Bonn aus leistete er grundlegende Beitr\u00e4ge zur K\u00fcnstlichen Intelligenz und Robotik (u.a. mit Wolfram Burgard, Dieter Fox, Sebastian Thrun) sowie zur Entwicklung des Software-Engineerings, insbesondere im Bauwesen, und der Informationssysteme, insbesondere in den Geowissenschaften. 2016 wurde er mit dem AAAI Classic Paper Award ausgezeichnet.2014.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 21], [22, 24], [25, 37], [38, 46], [47, 50], [51, 62], [63, 74], [75, 78], [79, 86], [87, 88], [88, 90], [90, 92], [93, 96], [97, 104], [105, 112], [112, 113], [114, 120], [121, 124], [124, 125], [126, 135], [136, 141], [141, 142], [143, 148], [149, 152], [153, 164], [165, 168], [169, 190], [190, 191], [192, 204], [205, 207], [208, 216], [216, 217], [218, 221], [222, 225], [226, 245], [245, 246], [247, 259], [260, 262], [263, 266], [267, 284], [284, 285], [286, 290], [291, 296], [297, 299], [300, 303], [304, 307], [308, 312], [313, 320], [321, 326], [327, 332], [333, 347], [347, 352]]}
{"doc_key": "ai-test-238", "ner": [[2, 6, "conference"], [13, 14, "location"], [16, 16, "location"], [18, 20, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 6, 13, 14, "physical", "", false, false], [13, 14, 16, 16, "physical", "", false, false], [16, 16, 18, 20, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Die", "erste", "USA-Ausgabe", "der", "Campus", "Party", "findet", "vom", "20.", "bis", "22.", "August", "im", "TCF", "Center", "in", "Detroit", ",", "Michigan", ",", "statt", "."], "sentence-detokenized": "Die erste USA-Ausgabe der Campus Party findet vom 20. bis 22. August im TCF Center in Detroit, Michigan, statt.", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 25], [26, 32], [33, 38], [39, 45], [46, 49], [50, 53], [54, 57], [58, 61], [62, 68], [69, 71], [72, 75], [76, 82], [83, 85], [86, 93], [93, 94], [95, 103], [103, 104], [105, 110], [110, 111]]}
{"doc_key": "ai-test-239", "ner": [[2, 4, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [10, 11, "misc"], [20, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 10, 11, "win-defeat", "", false, false], [5, 6, 10, 11, "win-defeat", "", false, false], [8, 8, 10, 11, "win-defeat", "", false, false], [10, 11, 20, 24, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Zusammen", "mit", "Yann", "LeCun", "und", "Yoshua", "Bengio", "erhielt", "Hinton", "den", "Turing", "Award", "2018", "f\u00fcr", "konzeptionelle", "und", "technische", "Durchbr\u00fcche", ",", "die", "tiefe", "neuronale", "Netze", "zu", "einer", "entscheidenden", "Komponente", "der", "Datenverarbeitung", "gemacht", "haben", "."], "sentence-detokenized": "Zusammen mit Yann LeCun und Yoshua Bengio erhielt Hinton den Turing Award 2018 f\u00fcr konzeptionelle und technische Durchbr\u00fcche, die tiefe neuronale Netze zu einer entscheidenden Komponente der Datenverarbeitung gemacht haben.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 23], [24, 27], [28, 34], [35, 41], [42, 49], [50, 56], [57, 60], [61, 67], [68, 73], [74, 78], [79, 82], [83, 97], [98, 101], [102, 112], [113, 124], [124, 125], [126, 129], [130, 135], [136, 145], [146, 151], [152, 154], [155, 160], [161, 175], [176, 186], [187, 190], [191, 208], [209, 216], [217, 222], [222, 223]]}
{"doc_key": "ai-test-240", "ner": [[0, 3, "product"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 9, 9, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Die", "Euler", "Math", "Toolbox", "verwendet", "eine", "Matrixsprache", "\u00e4hnlich", "wie", "MATLAB", ",", "ein", "System", ",", "das", "seit", "den", "1970er", "Jahren", "entwickelt", "wurde", "."], "sentence-detokenized": "Die Euler Math Toolbox verwendet eine Matrixsprache \u00e4hnlich wie MATLAB, ein System, das seit den 1970er Jahren entwickelt wurde.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 22], [23, 32], [33, 37], [38, 51], [52, 59], [60, 63], [64, 70], [70, 71], [72, 75], [76, 82], [82, 83], [84, 87], [88, 92], [93, 96], [97, 103], [104, 110], [111, 121], [122, 127], [127, 128]]}
{"doc_key": "ai-test-241", "ner": [[9, 9, "programlang"], [11, 12, "programlang"], [14, 14, "programlang"], [16, 16, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Einige", "Sprachen", "machen", "dies", "portabel", "m\u00f6glich", "(", "z.", "B.", "Scheme", ",", "Common", "Lisp", ",", "Perl", "oder", "D", ")", "."], "sentence-detokenized": "Einige Sprachen machen dies portabel m\u00f6glich (z.B. Scheme, Common Lisp, Perl oder D).", "token2charspan": [[0, 6], [7, 15], [16, 22], [23, 27], [28, 36], [37, 44], [45, 46], [46, 48], [48, 50], [51, 57], [57, 58], [59, 65], [66, 70], [70, 71], [72, 76], [77, 81], [82, 83], [83, 84], [84, 85]]}
{"doc_key": "ai-test-242", "ner": [[9, 9, "misc"], [11, 12, "researcher"], [14, 15, "researcher"], [27, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 11, 12, "artifact", "", false, false], [9, 9, 14, 15, "artifact", "", false, false], [9, 9, 27, 27, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["1969", "wurde", "in", "einem", "ber\u00fchmten", "Buch", "mit", "dem", "Titel", "Perceptrons", "von", "Marvin", "Minsky", "und", "Seymour", "Papert", "gezeigt", ",", "dass", "es", "f\u00fcr", "diese", "Netzklassen", "unm\u00f6glich", "ist", ",", "eine", "XOR-Funktion", "zu", "lernen", "."], "sentence-detokenized": "1969 wurde in einem ber\u00fchmten Buch mit dem Titel Perceptrons von Marvin Minsky und Seymour Papert gezeigt, dass es f\u00fcr diese Netzklassen unm\u00f6glich ist, eine XOR-Funktion zu lernen.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 19], [20, 29], [30, 34], [35, 38], [39, 42], [43, 48], [49, 60], [61, 64], [65, 71], [72, 78], [79, 82], [83, 90], [91, 97], [98, 105], [105, 106], [107, 111], [112, 114], [115, 118], [119, 124], [125, 136], [137, 146], [147, 150], [150, 151], [152, 156], [157, 169], [170, 172], [173, 179], [179, 180]]}
{"doc_key": "ai-test-243", "ner": [[30, 34, "misc"], [36, 36, "product"], [4, 7, "organisation"], [10, 15, "organisation"], [19, 22, "location"], [24, 24, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 7, 36, 36, "usage", "", false, false], [4, 7, 19, 22, "physical", "", false, false], [10, 15, 4, 7, "named", "", false, false], [19, 22, 24, 24, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Unter", "der", "Schirmherrschaft", "der", "USAF", "Foreign", "Technology", "Division", "(", "sp\u00e4ter", "National", "Air", "and", "Space", "Intelligence", "Center", ")", "auf", "der", "Wright-Patterson", "Air", "Force", "Base", ",", "Ohio", ",", "wurde", "eine", "gro\u00dfe", "Anzahl", "russischer", "wissenschaftlicher", "und", "technischer", "Dokumente", "mit", "SYSTRAN", "\u00fcbersetzt", "."], "sentence-detokenized": "Unter der Schirmherrschaft der USAF Foreign Technology Division (sp\u00e4ter National Air and Space Intelligence Center) auf der Wright-Patterson Air Force Base, Ohio, wurde eine gro\u00dfe Anzahl russischer wissenschaftlicher und technischer Dokumente mit SYSTRAN \u00fcbersetzt.", "token2charspan": [[0, 5], [6, 9], [10, 26], [27, 30], [31, 35], [36, 43], [44, 54], [55, 63], [64, 65], [65, 71], [72, 80], [81, 84], [85, 88], [89, 94], [95, 107], [108, 114], [114, 115], [116, 119], [120, 123], [124, 140], [141, 144], [145, 150], [151, 155], [155, 156], [157, 161], [161, 162], [163, 168], [169, 173], [174, 179], [180, 186], [187, 197], [198, 216], [217, 220], [221, 232], [233, 242], [243, 246], [247, 254], [255, 264], [264, 265]]}
{"doc_key": "ai-test-244", "ner": [[0, 1, "field"], [4, 5, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Semi-\u00fcberwachtes", "Lernen", "liegt", "zwischen", "un\u00fcberwachtem", "Lernen", "(", "ohne", "markierte", "Trainingsdaten", ")", "und", "\u00fcberwachtem", "Lernen", "(", "mit", "vollst\u00e4ndig", "markierten", "Trainingsdaten", ")", "."], "sentence-detokenized": "Semi-\u00fcberwachtes Lernen liegt zwischen un\u00fcberwachtem Lernen (ohne markierte Trainingsdaten) und \u00fcberwachtem Lernen (mit vollst\u00e4ndig markierten Trainingsdaten).", "token2charspan": [[0, 16], [17, 23], [24, 29], [30, 38], [39, 52], [53, 59], [60, 61], [61, 65], [66, 75], [76, 90], [90, 91], [92, 95], [96, 107], [108, 114], [115, 116], [116, 119], [120, 131], [132, 142], [143, 157], [157, 158], [158, 159]]}
{"doc_key": "ai-test-245", "ner": [[0, 1, "algorithm"], [5, 6, "algorithm"], [19, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 5, 6, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Das", "Ann-Gramm-Modell", "ist", "eine", "Art", "probabilistisches", "Sprachmodell", "zur", "Vorhersage", "des", "n\u00e4chsten", "Elements", "in", "einer", "solchen", "Sequenz", "in", "Form", "eines", "Markov-Modells", "(", "n", "-", "1", ")", "-", "effizienter", "Ordnung", "."], "sentence-detokenized": "Das Ann-Gramm-Modell ist eine Art probabilistisches Sprachmodell zur Vorhersage des n\u00e4chsten Elements in einer solchen Sequenz in Form eines Markov-Modells (n - 1) - effizienter Ordnung.", "token2charspan": [[0, 3], [4, 20], [21, 24], [25, 29], [30, 33], [34, 51], [52, 64], [65, 68], [69, 79], [80, 83], [84, 92], [93, 101], [102, 104], [105, 110], [111, 118], [119, 126], [127, 129], [130, 134], [135, 140], [141, 155], [156, 157], [157, 158], [159, 160], [161, 162], [162, 163], [164, 165], [166, 177], [178, 185], [185, 186]]}
{"doc_key": "ai-test-246", "ner": [[1, 3, "organisation"], [4, 4, "product"], [9, 14, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 3, 4, 4, "usage", "", false, false], [9, 14, 1, 3, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Die", "Cleveland", "Clinic", "hat", "Cyc", "verwendet", ",", "um", "eine", "nat\u00fcrlichsprachliche", "Abfrageoberfl\u00e4che", "f\u00fcr", "biomedizinische", "Informationen", "zu", "entwickeln", ",", "die", "jahrzehntelange", "Informationen", "\u00fcber", "kardiothorakale", "Operationen", "umfasst", "."], "sentence-detokenized": "Die Cleveland Clinic hat Cyc verwendet, um eine nat\u00fcrlichsprachliche Abfrageoberfl\u00e4che f\u00fcr biomedizinische Informationen zu entwickeln, die jahrzehntelange Informationen \u00fcber kardiothorakale Operationen umfasst.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 24], [25, 28], [29, 38], [38, 39], [40, 42], [43, 47], [48, 68], [69, 86], [87, 90], [91, 106], [107, 120], [121, 123], [124, 134], [134, 135], [136, 139], [140, 155], [156, 169], [170, 174], [175, 190], [191, 202], [203, 210], [210, 211]]}
{"doc_key": "ai-test-247", "ner": [[7, 8, "country"], [10, 10, "country"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 10, 10, "opposite", "strained_relations", false, false]], "relations_mapping_to_source": [0], "sentence": ["Der", "Vorfall", "belastete", "die", "Beziehungen", "zwischen", "den", "Vereinigten", "Staaten", "und", "Japan", "und", "f\u00fchrte", "zur", "Verhaftung", "und", "strafrechtlichen", "Verfolgung", "zweier", "leitender", "Angestellter", "sowie", "zur", "Verh\u00e4ngung", "von", "Sanktionen", "gegen", "das", "Unternehmen", "durch", "beide", "L\u00e4nder", "."], "sentence-detokenized": "Der Vorfall belastete die Beziehungen zwischen den Vereinigten Staaten und Japan und f\u00fchrte zur Verhaftung und strafrechtlichen Verfolgung zweier leitender Angestellter sowie zur Verh\u00e4ngung von Sanktionen gegen das Unternehmen durch beide L\u00e4nder.", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 25], [26, 37], [38, 46], [47, 50], [51, 62], [63, 70], [71, 74], [75, 80], [81, 84], [85, 91], [92, 95], [96, 106], [107, 110], [111, 127], [128, 138], [139, 145], [146, 155], [156, 168], [169, 174], [175, 178], [179, 189], [190, 193], [194, 204], [205, 210], [211, 214], [215, 226], [227, 232], [233, 238], [239, 245], [245, 246]]}
{"doc_key": "ai-test-248", "ner": [[5, 7, "algorithm"], [11, 13, "field"], [21, 21, "misc"], [32, 32, "misc"], [38, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 7, 11, 13, "type-of", "", false, false], [21, 21, 11, 13, "part-of", "", true, false], [32, 32, 11, 13, "part-of", "", true, false], [38, 38, 11, 13, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Wenn", "die", "Modellierung", "durch", "ein", "k\u00fcnstliches", "neuronales", "Netz", "oder", "ein", "anderes", "maschinelles", "Lernen", "erfolgt", ",", "wird", "die", "Optimierung", "der", "Parameter", "als", "Training", "bezeichnet", ",", "w\u00e4hrend", "die", "Optimierung", "der", "Hyperparameter", "des", "Modells", "als", "Tuning", "bezeichnet", "wird", "und", "h\u00e4ufig", "eine", "Kreuzvalidierung", "verwendet", "wird", "."], "sentence-detokenized": "Wenn die Modellierung durch ein k\u00fcnstliches neuronales Netz oder ein anderes maschinelles Lernen erfolgt, wird die Optimierung der Parameter als Training bezeichnet, w\u00e4hrend die Optimierung der Hyperparameter des Modells als Tuning bezeichnet wird und h\u00e4ufig eine Kreuzvalidierung verwendet wird.", "token2charspan": [[0, 4], [5, 8], [9, 21], [22, 27], [28, 31], [32, 43], [44, 54], [55, 59], [60, 64], [65, 68], [69, 76], [77, 89], [90, 96], [97, 104], [104, 105], [106, 110], [111, 114], [115, 126], [127, 130], [131, 140], [141, 144], [145, 153], [154, 164], [164, 165], [166, 173], [174, 177], [178, 189], [190, 193], [194, 208], [209, 212], [213, 220], [221, 224], [225, 231], [232, 242], [243, 247], [248, 251], [252, 258], [259, 263], [264, 280], [281, 290], [291, 295], [295, 296]]}
{"doc_key": "ai-test-249", "ner": [[7, 8, "country"], [10, 10, "country"], [12, 12, "country"], [21, 22, "organisation"], [24, 24, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[21, 22, 24, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Lokalisierte", "Versionen", "der", "Website", ",", "die", "im", "Vereinigten", "K\u00f6nigreich", ",", "Indien", "und", "Australien", "verf\u00fcgbar", "waren", ",", "wurden", "nach", "der", "\u00dcbernahme", "von", "Rotten", "Tomatoes", "durch", "Fandango", "eingestellt", "."], "sentence-detokenized": "Lokalisierte Versionen der Website, die im Vereinigten K\u00f6nigreich, Indien und Australien verf\u00fcgbar waren, wurden nach der \u00dcbernahme von Rotten Tomatoes durch Fandango eingestellt.", "token2charspan": [[0, 12], [13, 22], [23, 26], [27, 34], [34, 35], [36, 39], [40, 42], [43, 54], [55, 65], [65, 66], [67, 73], [74, 77], [78, 88], [89, 98], [99, 104], [104, 105], [106, 112], [113, 117], [118, 121], [122, 131], [132, 135], [136, 142], [143, 151], [152, 157], [158, 166], [167, 178], [178, 179]]}
{"doc_key": "ai-test-250", "ner": [[10, 10, "metrics"], [22, 22, "task"]], "ner_mapping_to_source": [1, 2], "relations": [[10, 10, 22, 22, "related-to", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Das", "NER-Modell", "ist", "eine", "von", "mehreren", "Methoden", "zur", "Bestimmung", "der", "Genauigkeit", "von", "Live-Untertiteln", "bei", "Fernsehsendungen", "und", "Veranstaltungen", ",", "die", "mit", "Hilfe", "von", "Spracherkennung", "produziert", "werden", "."], "sentence-detokenized": "Das NER-Modell ist eine von mehreren Methoden zur Bestimmung der Genauigkeit von Live-Untertiteln bei Fernsehsendungen und Veranstaltungen, die mit Hilfe von Spracherkennung produziert werden.", "token2charspan": [[0, 3], [4, 14], [15, 18], [19, 23], [24, 27], [28, 36], [37, 45], [46, 49], [50, 60], [61, 64], [65, 76], [77, 80], [81, 97], [98, 101], [102, 118], [119, 122], [123, 138], [138, 139], [140, 143], [144, 147], [148, 153], [154, 157], [158, 173], [174, 184], [185, 191], [191, 192]]}
{"doc_key": "ai-test-251", "ner": [[0, 0, "researcher"], [4, 5, "university"], [8, 9, "university"], [11, 11, "location"], [14, 18, "university"], [21, 22, "university"], [24, 24, "location"], [27, 32, "university"], [34, 36, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 5, "physical", "", false, false], [0, 0, 4, 5, "role", "", false, false], [0, 0, 8, 9, "physical", "", false, false], [0, 0, 8, 9, "role", "", false, false], [0, 0, 14, 18, "physical", "", false, false], [0, 0, 14, 18, "role", "", false, false], [0, 0, 21, 22, "physical", "", false, false], [0, 0, 21, 22, "role", "", false, false], [0, 0, 27, 32, "physical", "", false, false], [0, 0, 27, 32, "role", "", false, false], [8, 9, 11, 11, "physical", "", false, false], [14, 18, 24, 24, "physical", "", false, false], [21, 22, 24, 24, "physical", "", false, false], [27, 32, 34, 36, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Atran", "hat", "an", "der", "Universit\u00e4t", "Cambridge", ",", "der", "Hebr\u00e4ischen", "Universit\u00e4t", "in", "Jerusalem", ",", "der", "\u00c9cole", "pratique", "des", "hautes", "\u00e9tudes", "und", "der", "\u00c9cole", "Polytechnique", "in", "Paris", "sowie", "am", "John", "Jay", "College", "of", "Criminal", "Justice", "in", "New", "York", "City", "unterrichtet", "."], "sentence-detokenized": "Atran hat an der Universit\u00e4t Cambridge, der Hebr\u00e4ischen Universit\u00e4t in Jerusalem, der \u00c9cole pratique des hautes \u00e9tudes und der \u00c9cole Polytechnique in Paris sowie am John Jay College of Criminal Justice in New York City unterrichtet.", "token2charspan": [[0, 5], [6, 9], [10, 12], [13, 16], [17, 28], [29, 38], [38, 39], [40, 43], [44, 55], [56, 67], [68, 70], [71, 80], [80, 81], [82, 85], [86, 91], [92, 100], [101, 104], [105, 111], [112, 118], [119, 122], [123, 126], [127, 132], [133, 146], [147, 149], [150, 155], [156, 161], [162, 164], [165, 169], [170, 173], [174, 181], [182, 184], [185, 193], [194, 201], [202, 204], [205, 208], [209, 213], [214, 218], [219, 231], [231, 232]]}
{"doc_key": "ai-test-252", "ner": [[0, 0, "product"], [5, 8, "task"], [12, 13, "researcher"], [15, 15, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 8, "origin", "", false, false], [0, 0, 5, 8, "related-to", "", false, false], [5, 8, 15, 15, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["SHRDLU", "war", "ein", "fr\u00fches", "Computerprogramm", "zum", "Verstehen", "nat\u00fcrlicher", "Sprache", ",", "das", "von", "Terry", "Winograd", "am", "MIT", "in", "den", "Jahren", "1968-1970", "entwickelt", "wurde", "."], "sentence-detokenized": "SHRDLU war ein fr\u00fches Computerprogramm zum Verstehen nat\u00fcrlicher Sprache, das von Terry Winograd am MIT in den Jahren 1968-1970 entwickelt wurde.", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 21], [22, 38], [39, 42], [43, 52], [53, 64], [65, 72], [72, 73], [74, 77], [78, 81], [82, 87], [88, 96], [97, 99], [100, 103], [104, 106], [107, 110], [111, 117], [118, 127], [128, 138], [139, 144], [144, 145]]}
{"doc_key": "ai-test-253", "ner": [[4, 4, "misc"], [6, 6, "field"], [8, 11, "university"], [13, 13, "location"], [15, 15, "country"], [20, 21, "university"], [27, 27, "misc"], [29, 31, "field"], [34, 35, "university"], [39, 39, "misc"], [41, 41, "field"], [45, 45, "misc"], [48, 50, "university"], [54, 55, "field"], [59, 60, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "relations": [[4, 4, 6, 6, "topic", "", false, false], [4, 4, 8, 11, "origin", "", false, false], [8, 11, 13, 13, "physical", "", false, false], [8, 11, 20, 21, "role", "affiliated_with", false, false], [13, 13, 15, 15, "physical", "", false, false], [27, 27, 29, 31, "topic", "", false, false], [27, 27, 34, 35, "origin", "", false, false], [39, 39, 41, 41, "topic", "", false, false], [45, 45, 48, 50, "origin", "", false, false], [45, 45, 54, 55, "topic", "", false, false], [59, 60, 48, 50, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Er", "erwarb", "1982", "einen", "B.E.", "in", "Elektrotechnik", "am", "B.M.S.", "College", "of", "Engineering", "in", "Bangalore", ",", "Indien", ",", "das", "damals", "der", "Universit\u00e4t", "Bangalore", "angegliedert", "war", ",", "1984", "einen", "M.S.", "in", "Elektrotechnik", "und", "Computertechnik", "an", "der", "Drexel", "University", "und", "1989", "einen", "M.S.", "in", "Computerwissenschaften", "sowie", "1990", "einen", "Ph.D.", "an", "der", "University", "of", "Wisconsin-Madison", ",", "wo", "er", "k\u00fcnstliche", "Intelligenz", "studierte", "und", "mit", "Leonard", "Uhr", "zusammenarbeitete", "."], "sentence-detokenized": "Er erwarb 1982 einen B.E. in Elektrotechnik am B.M.S. College of Engineering in Bangalore, Indien, das damals der Universit\u00e4t Bangalore angegliedert war, 1984 einen M.S. in Elektrotechnik und Computertechnik an der Drexel University und 1989 einen M.S. in Computerwissenschaften sowie 1990 einen Ph.D. an der University of Wisconsin-Madison, wo er k\u00fcnstliche Intelligenz studierte und mit Leonard Uhr zusammenarbeitete.", "token2charspan": [[0, 2], [3, 9], [10, 14], [15, 20], [21, 25], [26, 28], [29, 43], [44, 46], [47, 53], [54, 61], [62, 64], [65, 76], [77, 79], [80, 89], [89, 90], [91, 97], [97, 98], [99, 102], [103, 109], [110, 113], [114, 125], [126, 135], [136, 148], [149, 152], [152, 153], [154, 158], [159, 164], [165, 169], [170, 172], [173, 187], [188, 191], [192, 207], [208, 210], [211, 214], [215, 221], [222, 232], [233, 236], [237, 241], [242, 247], [248, 252], [253, 255], [256, 278], [279, 284], [285, 289], [290, 295], [296, 301], [302, 304], [305, 308], [309, 319], [320, 322], [323, 340], [340, 341], [342, 344], [345, 347], [348, 358], [359, 370], [371, 380], [381, 384], [385, 388], [389, 396], [397, 400], [401, 418], [418, 419]]}
{"doc_key": "ai-test-254", "ner": [[8, 8, "metrics"], [10, 10, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 8, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Die", "Genauigkeit", "wird", "in", "der", "Regel", "mit", "der", "Wortfehlerrate", "(", "WER", ")", "bewertet", ",", "w\u00e4hrend", "die", "Geschwindigkeit", "mit", "dem", "Echtzeitfaktor", "gemessen", "wird", "."], "sentence-detokenized": "Die Genauigkeit wird in der Regel mit der Wortfehlerrate (WER) bewertet, w\u00e4hrend die Geschwindigkeit mit dem Echtzeitfaktor gemessen wird.", "token2charspan": [[0, 3], [4, 15], [16, 20], [21, 23], [24, 27], [28, 33], [34, 37], [38, 41], [42, 56], [57, 58], [58, 61], [61, 62], [63, 71], [71, 72], [73, 80], [81, 84], [85, 100], [101, 104], [105, 108], [109, 123], [124, 132], [133, 137], [137, 138]]}
{"doc_key": "ai-test-255", "ner": [[2, 3, "researcher"], [7, 13, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 7, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["1971", "entwickelte", "Terry", "Winograd", "eine", "fr\u00fche", "Maschine", "zur", "Verarbeitung", "nat\u00fcrlicher", "Sprache", ",", "die", "in", "der", "Lage", "war", ",", "nat\u00fcrlich", "geschriebene", "Befehle", "in", "einer", "einfachen", ",", "regelgesteuerten", "Umgebung", "zu", "interpretieren", "."], "sentence-detokenized": "1971 entwickelte Terry Winograd eine fr\u00fche Maschine zur Verarbeitung nat\u00fcrlicher Sprache, die in der Lage war, nat\u00fcrlich geschriebene Befehle in einer einfachen, regelgesteuerten Umgebung zu interpretieren.", "token2charspan": [[0, 4], [5, 16], [17, 22], [23, 31], [32, 36], [37, 42], [43, 51], [52, 55], [56, 68], [69, 80], [81, 88], [88, 89], [90, 93], [94, 96], [97, 100], [101, 105], [106, 109], [109, 110], [111, 120], [121, 133], [134, 141], [142, 144], [145, 150], [151, 160], [160, 161], [162, 178], [179, 187], [188, 190], [191, 205], [205, 206]]}
{"doc_key": "ai-test-256", "ner": [[3, 4, "field"], [6, 7, "researcher"], [9, 11, "researcher"], [13, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 6, 7, "related-to", "", false, false], [3, 4, 9, 11, "related-to", "", false, false], [3, 4, 13, 15, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Im", "Bereich", "der", "k\u00fcnstlichen", "Intelligenz", "sind", "Marvin", "Minsky", ",", "Herbert", "A.", "Simon", "und", "Allen", "Newell", "zu", "nennen", "."], "sentence-detokenized": "Im Bereich der k\u00fcnstlichen Intelligenz sind Marvin Minsky, Herbert A. Simon und Allen Newell zu nennen.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 26], [27, 38], [39, 43], [44, 50], [51, 57], [57, 58], [59, 66], [67, 69], [70, 75], [76, 79], [80, 85], [86, 92], [93, 95], [96, 102], [102, 103]]}
{"doc_key": "ai-test-257", "ner": [[39, 39, "field"], [42, 42, "field"], [47, 47, "field"], [57, 57, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [[39, 39, 47, 47, "compare", "", false, false], [42, 42, 47, 47, "compare", "", false, false], [47, 47, 57, 57, "topic", "", false, false]], "relations_mapping_to_source": [2, 5, 8], "sentence": ["In", "der", "zweiten", "H\u00e4lfte", "des", "20.", "Jahrhunderts", "teilte", "sich", "die", "Elektrotechnik", "selbst", "in", "mehrere", "Disziplinen", "auf", ",", "die", "sich", "auf", "den", "Entwurf", "und", "die", "Analyse", "von", "Systemen", ",", "die", "physikalische", "Signale", "verarbeiten", ",", "spezialisierten", ",", "wie", "z.", "B.", "die", "Elektrotechnik", "und", "die", "Computertechnik", ",", "w\u00e4hrend", "sich", "das", "Design-Engineering", "entwickelte", ",", "das", "sich", "mit", "der", "funktionalen", "Gestaltung", "von", "Benutzer-Maschine-Schnittstellen", "befasste", "."], "sentence-detokenized": "In der zweiten H\u00e4lfte des 20. Jahrhunderts teilte sich die Elektrotechnik selbst in mehrere Disziplinen auf, die sich auf den Entwurf und die Analyse von Systemen, die physikalische Signale verarbeiten, spezialisierten, wie z. B. die Elektrotechnik und die Computertechnik, w\u00e4hrend sich das Design-Engineering entwickelte, das sich mit der funktionalen Gestaltung von Benutzer-Maschine-Schnittstellen befasste.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 21], [22, 25], [26, 29], [30, 42], [43, 49], [50, 54], [55, 58], [59, 73], [74, 80], [81, 83], [84, 91], [92, 103], [104, 107], [107, 108], [109, 112], [113, 117], [118, 121], [122, 125], [126, 133], [134, 137], [138, 141], [142, 149], [150, 153], [154, 162], [162, 163], [164, 167], [168, 181], [182, 189], [190, 201], [201, 202], [203, 218], [218, 219], [220, 223], [224, 226], [227, 229], [230, 233], [234, 248], [249, 252], [253, 256], [257, 272], [272, 273], [274, 281], [282, 286], [287, 290], [291, 309], [310, 321], [321, 322], [323, 326], [327, 331], [332, 335], [336, 339], [340, 352], [353, 363], [364, 367], [368, 400], [401, 409], [409, 410]]}
{"doc_key": "ai-test-258", "ner": [[6, 6, "metrics"], [8, 9, "metrics"], [11, 11, "metrics"], [44, 46, "metrics"], [52, 54, "metrics"], [58, 64, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 8, 9, "named", "", false, false], [44, 46, 52, 54, "named", "", false, false], [52, 54, 58, 64, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Die", "vielleicht", "einfachste", "Statistik", "ist", "die", "Genauigkeit", "oder", "Fraction", "Correct", "(", "FC", ")", ",", "die", "den", "Anteil", "aller", "Instanzen", "misst", ",", "die", "korrekt", "kategorisiert", "werden", ";", "sie", "ist", "das", "Verh\u00e4ltnis", "der", "Anzahl", "der", "korrekten", "Klassifizierungen", "zur", "Gesamtzahl", "der", "korrekten", "oder", "falschen", "Klassifizierungen", ":", "(", "TP", "+", "TN", ")", "/", "Gesamtpopulation", "=", "(", "TP", "+", "TN", ")", "/", "(", "TP", "+", "TN", "+", "FP", "+", "FN", ")", "."], "sentence-detokenized": "Die vielleicht einfachste Statistik ist die Genauigkeit oder Fraction Correct (FC), die den Anteil aller Instanzen misst, die korrekt kategorisiert werden; sie ist das Verh\u00e4ltnis der Anzahl der korrekten Klassifizierungen zur Gesamtzahl der korrekten oder falschen Klassifizierungen: (TP + TN) / Gesamtpopulation = (TP + TN) / (TP + TN + FP + FN).", "token2charspan": [[0, 3], [4, 14], [15, 25], [26, 35], [36, 39], [40, 43], [44, 55], [56, 60], [61, 69], [70, 77], [78, 79], [79, 81], [81, 82], [82, 83], [84, 87], [88, 91], [92, 98], [99, 104], [105, 114], [115, 120], [120, 121], [122, 125], [126, 133], [134, 147], [148, 154], [154, 155], [156, 159], [160, 163], [164, 167], [168, 178], [179, 182], [183, 189], [190, 193], [194, 203], [204, 221], [222, 225], [226, 236], [237, 240], [241, 250], [251, 255], [256, 264], [265, 282], [282, 283], [284, 285], [285, 287], [288, 289], [290, 292], [292, 293], [294, 295], [296, 312], [313, 314], [315, 316], [316, 318], [319, 320], [321, 323], [323, 324], [325, 326], [327, 328], [328, 330], [331, 332], [333, 335], [336, 337], [338, 340], [341, 342], [343, 345], [345, 346], [346, 347]]}
{"doc_key": "ai-test-259", "ner": [[15, 22, "conference"], [24, 24, "conference"], [27, 27, "location"], [32, 34, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 22, 27, 27, "physical", "", false, false], [24, 24, 15, 22, "named", "", false, false], [32, 34, 15, 22, "role", "sponsors", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "der", "akademischen", "Gemeinschaft", "begannen", "die", "wichtigsten", "Foren", "f\u00fcr", "die", "Forschung", "1995", ",", "als", "die", "erste", "internationale", "Konferenz", "Data", "Mining", "and", "Knowledge", "Discovery", "(", "KDD-95", ")", "in", "Montreal", "unter", "der", "Schirmherrschaft", "der", "AAAI", "ins", "Leben", "gerufen", "wurde", "."], "sentence-detokenized": "In der akademischen Gemeinschaft begannen die wichtigsten Foren f\u00fcr die Forschung 1995, als die erste internationale Konferenz Data Mining and Knowledge Discovery (KDD-95) in Montreal unter der Schirmherrschaft der AAAI ins Leben gerufen wurde.", "token2charspan": [[0, 2], [3, 6], [7, 19], [20, 32], [33, 41], [42, 45], [46, 57], [58, 63], [64, 67], [68, 71], [72, 81], [82, 86], [86, 87], [88, 91], [92, 95], [96, 101], [102, 116], [117, 126], [127, 131], [132, 138], [139, 142], [143, 152], [153, 162], [163, 164], [164, 170], [170, 171], [172, 174], [175, 183], [184, 189], [190, 193], [194, 210], [211, 214], [215, 219], [220, 223], [224, 229], [230, 237], [238, 243], [243, 244]]}
{"doc_key": "ai-test-260", "ner": [[9, 9, "field"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Bei", "diesem", "Ansatz", "werden", "mit", "Hilfe", "verschiedener", "Data-Mining-", "und", "maschineller", "Lernalgorithmen", "Modelle", "entwickelt", ",", "um", "die", "Bewertung", "von", "nicht", "bewerteten", "Artikeln", "durch", "die", "Nutzer", "vorherzusagen", "."], "sentence-detokenized": "Bei diesem Ansatz werden mit Hilfe verschiedener Data-Mining- und maschineller Lernalgorithmen Modelle entwickelt, um die Bewertung von nicht bewerteten Artikeln durch die Nutzer vorherzusagen.", "token2charspan": [[0, 3], [4, 10], [11, 17], [18, 24], [25, 28], [29, 34], [35, 48], [49, 61], [62, 65], [66, 78], [79, 94], [95, 102], [103, 113], [113, 114], [115, 117], [118, 121], [122, 131], [132, 135], [136, 141], [142, 152], [153, 161], [162, 167], [168, 171], [172, 178], [179, 192], [192, 193]]}
{"doc_key": "ai-test-261", "ner": [[12, 13, "algorithm"], [15, 16, "algorithm"], [23, 24, "misc"], [25, 25, "metrics"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [[12, 13, 15, 16, "usage", "", false, false], [15, 16, 25, 25, "usage", "", false, false], [25, 25, 23, 24, "type-of", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["In", "Anbetracht", "der", "obigen", "Diskussion", "sehen", "wir", ",", "dass", "die", "SVM-Technik", "dem", "empirischen", "Risiko", "mit", "Tichonov-Regularisierung", "entspricht", ",", "wobei", "in", "diesem", "Fall", "die", "Verlustfunktion", "der", "Scharnierverlust", "ist"], "sentence-detokenized": "In Anbetracht der obigen Diskussion sehen wir, dass die SVM-Technik dem empirischen Risiko mit Tichonov-Regularisierung entspricht, wobei in diesem Fall die Verlustfunktion der Scharnierverlust ist", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 24], [25, 35], [36, 41], [42, 45], [45, 46], [47, 51], [52, 55], [56, 67], [68, 71], [72, 83], [84, 90], [91, 94], [95, 119], [120, 130], [130, 131], [132, 137], [138, 140], [141, 147], [148, 152], [153, 156], [157, 172], [173, 176], [177, 193], [194, 197]]}
{"doc_key": "ai-test-262", "ner": [[5, 6, "person"], [9, 10, "person"], [15, 16, "person"]], "ner_mapping_to_source": [0, 1, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Die", "Ausgabe", "2015", "wurde", "von", "Molly", "McGrath", "moderiert", ",", "Chris", "Rose", "und", "der", "ehemalige", "UFC-K\u00e4mpfer", "Kenny", "Florian", "waren", "die", "Kommentatoren", "."], "sentence-detokenized": "Die Ausgabe 2015 wurde von Molly McGrath moderiert, Chris Rose und der ehemalige UFC-K\u00e4mpfer Kenny Florian waren die Kommentatoren.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 22], [23, 26], [27, 32], [33, 40], [41, 50], [50, 51], [52, 57], [58, 62], [63, 66], [67, 70], [71, 80], [81, 92], [93, 98], [99, 106], [107, 112], [113, 116], [117, 130], [130, 131]]}
{"doc_key": "ai-test-263", "ner": [[3, 3, "product"], [6, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [15, 15, "researcher"], [17, 17, "researcher"], [25, 28, "task"], [29, 29, "product"], [31, 31, "researcher"], [35, 37, "task"], [39, 40, "researcher"], [43, 44, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12], "relations": [[3, 3, 6, 8, "origin", "", false, false], [3, 3, 10, 11, "origin", "", false, false], [3, 3, 13, 14, "origin", "", false, false], [3, 3, 15, 15, "origin", "", false, false], [10, 11, 31, 31, "named", "same", false, false], [13, 14, 17, 17, "named", "same", false, false], [25, 28, 29, 29, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 7], "sentence": ["Eine", "Teilmenge", "namens", "Micro-Planner", "wurde", "von", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "und", "Terry", "Winograd", "Sussman", "und", "Winograd", "1971", "implementiert", "und", "wurde", "in", "Winograds", "Programm", "zum", "Verstehen", "nat\u00fcrlicher", "Sprache", "SHRDLU", ",", "Eugene", "Charniaks", "Arbeit", "zum", "Verstehen", "von", "Geschichten", ",", "Thorne", "McCartys", "Arbeit", "zum", "juristischen", "Denken", "und", "einigen", "anderen", "Projekten", "verwendet", "."], "sentence-detokenized": "Eine Teilmenge namens Micro-Planner wurde von Gerald Jay Sussman, Eugene Charniak und Terry Winograd Sussman und Winograd 1971 implementiert und wurde in Winograds Programm zum Verstehen nat\u00fcrlicher Sprache SHRDLU, Eugene Charniaks Arbeit zum Verstehen von Geschichten, Thorne McCartys Arbeit zum juristischen Denken und einigen anderen Projekten verwendet.", "token2charspan": [[0, 4], [5, 14], [15, 21], [22, 35], [36, 41], [42, 45], [46, 52], [53, 56], [57, 64], [64, 65], [66, 72], [73, 81], [82, 85], [86, 91], [92, 100], [101, 108], [109, 112], [113, 121], [122, 126], [127, 140], [141, 144], [145, 150], [151, 153], [154, 163], [164, 172], [173, 176], [177, 186], [187, 198], [199, 206], [207, 213], [213, 214], [215, 221], [222, 231], [232, 238], [239, 242], [243, 252], [253, 256], [257, 268], [268, 269], [270, 276], [277, 285], [286, 292], [293, 296], [297, 309], [310, 316], [317, 320], [321, 328], [329, 336], [337, 346], [347, 356], [356, 357]]}
{"doc_key": "ai-test-264", "ner": [[0, 0, "product"], [8, 8, "product"], [13, 15, "task"], [18, 18, "task"], [21, 22, "task"], [25, 26, "task"], [29, 30, "task"], [34, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[8, 8, 0, 0, "usage", "", true, false], [13, 15, 8, 8, "part-of", "", true, false], [18, 18, 8, 8, "part-of", "", true, false], [21, 22, 8, 8, "part-of", "", true, false], [25, 26, 8, 8, "part-of", "", true, false], [29, 30, 8, 8, "part-of", "", true, false], [34, 37, 8, 8, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["WordNet", "wurde", "f\u00fcr", "eine", "Reihe", "von", "Zwecken", "in", "Informationssystemen", "verwendet", ",", "einschlie\u00dflich", "der", "Disambiguierung", "von", "Wortsinn", ",", "der", "Informationsbeschaffung", ",", "der", "automatischen", "Textklassifizierung", ",", "der", "automatischen", "Zusammenfassung", ",", "der", "maschinellen", "\u00dcbersetzung", "und", "sogar", "der", "automatischen", "Erstellung", "von", "Kreuzwortr\u00e4tseln", "."], "sentence-detokenized": "WordNet wurde f\u00fcr eine Reihe von Zwecken in Informationssystemen verwendet, einschlie\u00dflich der Disambiguierung von Wortsinn, der Informationsbeschaffung, der automatischen Textklassifizierung, der automatischen Zusammenfassung, der maschinellen \u00dcbersetzung und sogar der automatischen Erstellung von Kreuzwortr\u00e4tseln.", "token2charspan": [[0, 7], [8, 13], [14, 17], [18, 22], [23, 28], [29, 32], [33, 40], [41, 43], [44, 64], [65, 74], [74, 75], [76, 90], [91, 94], [95, 110], [111, 114], [115, 123], [123, 124], [125, 128], [129, 152], [152, 153], [154, 157], [158, 171], [172, 191], [191, 192], [193, 196], [197, 210], [211, 226], [226, 227], [228, 231], [232, 244], [245, 256], [257, 260], [261, 266], [267, 270], [271, 284], [285, 295], [296, 299], [300, 316], [316, 317]]}
{"doc_key": "ai-test-265", "ner": [[0, 0, "researcher"], [6, 6, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 6, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Keutzer", "wurde", "1996", "zum", "Fellow", "des", "IEEE", "ernannt", "."], "sentence-detokenized": "Keutzer wurde 1996 zum Fellow des IEEE ernannt.", "token2charspan": [[0, 7], [8, 13], [14, 18], [19, 22], [23, 29], [30, 33], [34, 38], [39, 46], [46, 47]]}
{"doc_key": "ai-test-266", "ner": [[8, 10, "algorithm"], [48, 48, "misc"], [60, 61, "algorithm"], [64, 64, "algorithm"], [67, 67, "algorithm"], [70, 70, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[60, 61, 48, 48, "type-of", "", false, false], [64, 64, 48, 48, "type-of", "", false, false], [67, 67, 48, 48, "type-of", "", false, false], [70, 70, 48, 48, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Eine", "weit", "verbreitete", "Art", "der", "Zusammensetzung", "ist", "die", "nichtlineare", "gewichtete", "Summe", ",", "wobei", "math\\", "textstyle", "f", "(x", ")", "=", "K\\", "links", "(", "\\", "sum", "_", "i", "w", "_", "i", "g", "_", "i", "(", "x)\\", "rechts", ")", "/", "math", ",", "wobei", "math\\", "textstyle", "K", "/", "math", "(", "allgemein", "als", "Aktivierungsfunktion", "bezeichnet", ")", "eine", "vordefinierte", "Funktion", "ist", ",", "wie", "z.", "B.", "der", "hyperbolische", "Tangens", ",", "die", "Sigmoidfunktion", ",", "die", "Softmaxfunktion", "oder", "die", "Gleichrichterfunktion", "."], "sentence-detokenized": "Eine weit verbreitete Art der Zusammensetzung ist die nichtlineare gewichtete Summe, wobei math\\ textstyle f (x) = K\\ links (\\ sum _ i w _ i g _ i (x)\\ rechts) / math, wobei math\\ textstyle K / math (allgemein als Aktivierungsfunktion bezeichnet) eine vordefinierte Funktion ist, wie z. B. der hyperbolische Tangens, die Sigmoidfunktion, die Softmaxfunktion oder die Gleichrichterfunktion.", "token2charspan": [[0, 4], [5, 9], [10, 21], [22, 25], [26, 29], [30, 45], [46, 49], [50, 53], [54, 66], [67, 77], [78, 83], [83, 84], [85, 90], [91, 96], [97, 106], [107, 108], [109, 111], [111, 112], [113, 114], [115, 117], [118, 123], [124, 125], [125, 126], [127, 130], [131, 132], [133, 134], [135, 136], [137, 138], [139, 140], [141, 142], [143, 144], [145, 146], [147, 148], [148, 151], [152, 158], [158, 159], [160, 161], [162, 166], [166, 167], [168, 173], [174, 179], [180, 189], [190, 191], [192, 193], [194, 198], [199, 200], [200, 209], [210, 213], [214, 234], [235, 245], [245, 246], [247, 251], [252, 265], [266, 274], [275, 278], [278, 279], [280, 283], [284, 286], [287, 289], [290, 293], [294, 307], [308, 315], [315, 316], [317, 320], [321, 336], [336, 337], [338, 341], [342, 357], [358, 362], [363, 366], [367, 388], [388, 389]]}
{"doc_key": "ai-test-267", "ner": [[3, 4, "misc"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "dem", "Film", "Westworld", "haben", "weibliche", "Roboter", "tats\u00e4chlich", "Geschlechtsverkehr", "mit", "menschlichen", "M\u00e4nnern", "als", "Teil", "der", "fiktiven", "Urlaubswelt", ",", "f\u00fcr", "die", "menschliche", "Kunden", "bezahlen", "."], "sentence-detokenized": "In dem Film Westworld haben weibliche Roboter tats\u00e4chlich Geschlechtsverkehr mit menschlichen M\u00e4nnern als Teil der fiktiven Urlaubswelt, f\u00fcr die menschliche Kunden bezahlen.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 21], [22, 27], [28, 37], [38, 45], [46, 57], [58, 76], [77, 80], [81, 93], [94, 101], [102, 105], [106, 110], [111, 114], [115, 123], [124, 135], [135, 136], [137, 140], [141, 144], [145, 156], [157, 163], [164, 172], [172, 173]]}
{"doc_key": "ai-test-268", "ner": [[8, 10, "task"], [23, 23, "task"], [25, 26, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 23, 23, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "der", "Regel", "beginnt", "der", "Prozess", "mit", "der", "Extraktion", "von", "Terminologie", "und", "Konzepten", "oder", "Substantivphrasen", "aus", "reinem", "Text", "unter", "Verwendung", "linguistischer", "Prozessoren", "wie", "Part-of-Speech-Tagging", "und", "Phrase", "Chunking", "."], "sentence-detokenized": "In der Regel beginnt der Prozess mit der Extraktion von Terminologie und Konzepten oder Substantivphrasen aus reinem Text unter Verwendung linguistischer Prozessoren wie Part-of-Speech-Tagging und Phrase Chunking.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 20], [21, 24], [25, 32], [33, 36], [37, 40], [41, 51], [52, 55], [56, 68], [69, 72], [73, 82], [83, 87], [88, 105], [106, 109], [110, 116], [117, 121], [122, 127], [128, 138], [139, 153], [154, 165], [166, 169], [170, 192], [193, 196], [197, 203], [204, 212], [212, 213]]}
{"doc_key": "ai-test-269", "ner": [[15, 17, "field"], [23, 23, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[23, 23, 15, 17, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0], "sentence": ["Sie", "demonstrierten", "seine", "Leistungsf\u00e4higkeit", "bei", "einer", "Reihe", "von", "Problemen", ",", "die", "f\u00fcr", "die", "Gemeinschaft", "des", "maschinellen", "Lernens", "von", "Interesse", "sind", ",", "einschlie\u00dflich", "der", "Handschrifterkennung", "."], "sentence-detokenized": "Sie demonstrierten seine Leistungsf\u00e4higkeit bei einer Reihe von Problemen, die f\u00fcr die Gemeinschaft des maschinellen Lernens von Interesse sind, einschlie\u00dflich der Handschrifterkennung.", "token2charspan": [[0, 3], [4, 18], [19, 24], [25, 43], [44, 47], [48, 53], [54, 59], [60, 63], [64, 73], [73, 74], [75, 78], [79, 82], [83, 86], [87, 99], [100, 103], [104, 116], [117, 124], [125, 128], [129, 138], [139, 143], [143, 144], [145, 159], [160, 163], [164, 184], [184, 185]]}
{"doc_key": "ai-test-270", "ner": [[4, 4, "university"], [6, 6, "researcher"], [12, 13, "researcher"], [18, 18, "product"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 4, 4, "physical", "", false, false], [6, 6, 4, 4, "role", "", false, false], [18, 18, 12, 13, "origin", "", false, false], [18, 18, 22, 22, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["W\u00e4hrend", "seines", "Studiums", "in", "Stanford", "erhielt", "Scheinman", "ein", "Stipendium", ",", "das", "von", "George", "Devol", ",", "dem", "Erfinder", "des", "Unimate", ",", "des", "ersten", "Industrieroboters", ",", "gesponsert", "wurde", "."], "sentence-detokenized": "W\u00e4hrend seines Studiums in Stanford erhielt Scheinman ein Stipendium, das von George Devol, dem Erfinder des Unimate, des ersten Industrieroboters, gesponsert wurde.", "token2charspan": [[0, 7], [8, 14], [15, 23], [24, 26], [27, 35], [36, 43], [44, 53], [54, 57], [58, 68], [68, 69], [70, 73], [74, 77], [78, 84], [85, 90], [90, 91], [92, 95], [96, 104], [105, 108], [109, 116], [116, 117], [118, 121], [122, 128], [129, 146], [146, 147], [148, 158], [159, 164], [164, 165]]}
{"doc_key": "ai-test-271", "ner": [[4, 5, "task"], [10, 11, "metrics"], [13, 15, "metrics"], [20, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 10, 11, "usage", "", true, false], [13, 15, 10, 11, "named", "", false, false], [20, 22, 10, 11, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Urspr\u00fcnglich", "zur", "Bewertung", "von", "maschinellen", "\u00dcbersetzungen", "verwendet", ",", "wurde", "die", "zweisprachige", "Evaluierungsstudie", "(", "BLEU", ")", "auch", "erfolgreich", "zur", "Bewertung", "von", "Modellen", "zur", "Paraphrasengenerierung", "eingesetzt", "."], "sentence-detokenized": "Urspr\u00fcnglich zur Bewertung von maschinellen \u00dcbersetzungen verwendet, wurde die zweisprachige Evaluierungsstudie (BLEU) auch erfolgreich zur Bewertung von Modellen zur Paraphrasengenerierung eingesetzt.", "token2charspan": [[0, 12], [13, 16], [17, 26], [27, 30], [31, 43], [44, 57], [58, 67], [67, 68], [69, 74], [75, 78], [79, 92], [93, 111], [112, 113], [113, 117], [117, 118], [119, 123], [124, 135], [136, 139], [140, 149], [150, 153], [154, 162], [163, 166], [167, 189], [190, 200], [200, 201]]}
{"doc_key": "ai-test-272", "ner": [[2, 2, "organisation"], [6, 8, "organisation"], [10, 10, "organisation"], [13, 13, "product"], [15, 15, "country"], [17, 17, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 6, 8, "role", "licenses_to", false, false], [2, 2, 10, 10, "role", "licenses_to", false, false], [6, 8, 15, 15, "physical", "", false, false], [10, 10, 17, 17, "physical", "", false, false], [13, 13, 6, 8, "artifact", "produces", false, false], [13, 13, 10, 10, "artifact", "produces", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sp\u00e4ter", "lizenzierte", "Unimation", "seine", "Technologie", "an", "Kawasaki", "Heavy", "Industries", "und", "GKN", ",", "die", "Unimates", "in", "Japan", "bzw.", "England", "herstellten", "."], "sentence-detokenized": "Sp\u00e4ter lizenzierte Unimation seine Technologie an Kawasaki Heavy Industries und GKN, die Unimates in Japan bzw. England herstellten.", "token2charspan": [[0, 6], [7, 18], [19, 28], [29, 34], [35, 46], [47, 49], [50, 58], [59, 64], [65, 75], [76, 79], [80, 83], [83, 84], [85, 88], [89, 97], [98, 100], [101, 106], [107, 111], [112, 119], [120, 131], [131, 132]]}
{"doc_key": "ai-test-273", "ner": [[18, 19, "conference"], [37, 40, "field"], [60, 64, "field"], [66, 66, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[37, 40, 60, 64, "compare", "", false, false], [66, 66, 60, 64, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Ein", "Gro\u00dfteil", "der", "Verwirrung", "zwischen", "diesen", "beiden", "Forschungsgemeinschaften", "(", "die", "oft", "getrennte", "Konferenzen", "und", "Zeitschriften", "haben", ",", "wobei", "ECML", "PKDD", "eine", "gro\u00dfe", "Ausnahme", "darstellt", ")", "r\u00fchrt", "von", "den", "Grundannahmen", "her", ",", "mit", "denen", "sie", "arbeiten", ":", "Beim", "maschinellen", "Lernen", "wird", "die", "Leistung", "in", "der", "Regel", "im", "Hinblick", "auf", "die", "F\u00e4higkeit", "bewertet", ",", "bekanntes", "Wissen", "zu", "reproduzieren", ",", "w\u00e4hrend", "bei", "der", "Wissensentdeckung", "und", "dem", "Data", "Mining", "(", "KDD", ")", "die", "Hauptaufgabe", "in", "der", "Entdeckung", "von", "bisher", "unbekanntem", "Wissen", "besteht", "."], "sentence-detokenized": "Ein Gro\u00dfteil der Verwirrung zwischen diesen beiden Forschungsgemeinschaften (die oft getrennte Konferenzen und Zeitschriften haben, wobei ECML PKDD eine gro\u00dfe Ausnahme darstellt) r\u00fchrt von den Grundannahmen her, mit denen sie arbeiten: Beim maschinellen Lernen wird die Leistung in der Regel im Hinblick auf die F\u00e4higkeit bewertet, bekanntes Wissen zu reproduzieren, w\u00e4hrend bei der Wissensentdeckung und dem Data Mining (KDD) die Hauptaufgabe in der Entdeckung von bisher unbekanntem Wissen besteht.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 27], [28, 36], [37, 43], [44, 50], [51, 75], [76, 77], [77, 80], [81, 84], [85, 94], [95, 106], [107, 110], [111, 124], [125, 130], [130, 131], [132, 137], [138, 142], [143, 147], [148, 152], [153, 158], [159, 167], [168, 177], [177, 178], [179, 184], [185, 188], [189, 192], [193, 206], [207, 210], [210, 211], [212, 215], [216, 221], [222, 225], [226, 234], [234, 235], [236, 240], [241, 253], [254, 260], [261, 265], [266, 269], [270, 278], [279, 281], [282, 285], [286, 291], [292, 294], [295, 303], [304, 307], [308, 311], [312, 321], [322, 330], [330, 331], [332, 341], [342, 348], [349, 351], [352, 365], [365, 366], [367, 374], [375, 378], [379, 382], [383, 400], [401, 404], [405, 408], [409, 413], [414, 420], [421, 422], [422, 425], [425, 426], [427, 430], [431, 443], [444, 446], [447, 450], [451, 461], [462, 465], [466, 472], [473, 484], [485, 491], [492, 499], [499, 500]]}
{"doc_key": "ai-test-274", "ner": [[8, 9, "product"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Hidden-Markov-Modelle", "sind", "die", "Grundlage", "f\u00fcr", "die", "meisten", "modernen", "automatischen", "Spracherkennungssysteme", "."], "sentence-detokenized": "Hidden-Markov-Modelle sind die Grundlage f\u00fcr die meisten modernen automatischen Spracherkennungssysteme.", "token2charspan": [[0, 21], [22, 26], [27, 30], [31, 40], [41, 44], [45, 48], [49, 56], [57, 65], [66, 79], [80, 103], [103, 104]]}
{"doc_key": "ai-test-275", "ner": [[3, 3, "location"], [5, 5, "country"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 5, 5, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["ein", "Unternehmen", "in", "Bangalore", ",", "Indien", ",", "das", "sich", "auf", "Online-Software", "zur", "Handschrifterkennung", "spezialisiert", "hat", "."], "sentence-detokenized": "ein Unternehmen in Bangalore, Indien, das sich auf Online-Software zur Handschrifterkennung spezialisiert hat.", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 28], [28, 29], [30, 36], [36, 37], [38, 41], [42, 46], [47, 50], [51, 66], [67, 70], [71, 91], [92, 105], [106, 109], [109, 110]]}
{"doc_key": "ai-test-276", "ner": [[20, 21, "misc"], [48, 50, "metrics"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Konvergieren", "wiederholte", "\u00dcbersetzungen", "auf", "einen", "einzigen", "Ausdruck", "in", "beiden", "Sprachen", "?", "D.h.", "zeigt", "die", "\u00dcbersetzungsmethode", "Stationarit\u00e4t", "oder", "erzeugt", "sie", "eine", "kanonische", "Form", "?", "Wird", "die", "\u00dcbersetzung", "station\u00e4r", ",", "ohne", "die", "urspr\u00fcngliche", "Bedeutung", "zu", "verlieren", "?", "Diese", "Metrik", "wurde", "kritisiert", ",", "weil", "sie", "nicht", "gut", "mit", "den", "BLEU-Werten", "(", "BiLingual", "Evaluation", "Understudy", ")", "korreliert", "."], "sentence-detokenized": "Konvergieren wiederholte \u00dcbersetzungen auf einen einzigen Ausdruck in beiden Sprachen? D.h. zeigt die \u00dcbersetzungsmethode Stationarit\u00e4t oder erzeugt sie eine kanonische Form? Wird die \u00dcbersetzung station\u00e4r, ohne die urspr\u00fcngliche Bedeutung zu verlieren? Diese Metrik wurde kritisiert, weil sie nicht gut mit den BLEU-Werten (BiLingual Evaluation Understudy) korreliert.", "token2charspan": [[0, 12], [13, 24], [25, 38], [39, 42], [43, 48], [49, 57], [58, 66], [67, 69], [70, 76], [77, 85], [85, 86], [87, 91], [92, 97], [98, 101], [102, 121], [122, 135], [136, 140], [141, 148], [149, 152], [153, 157], [158, 168], [169, 173], [173, 174], [175, 179], [180, 183], [184, 195], [196, 205], [205, 206], [207, 211], [212, 215], [216, 229], [230, 239], [240, 242], [243, 252], [252, 253], [254, 259], [260, 266], [267, 272], [273, 283], [283, 284], [285, 289], [290, 293], [294, 299], [300, 303], [304, 307], [308, 311], [312, 323], [324, 325], [325, 334], [335, 345], [346, 356], [356, 357], [358, 368], [368, 369]]}
{"doc_key": "ai-test-277", "ner": [[4, 8, "organisation"], [11, 18, "organisation"], [20, 21, "university"], [24, 24, "university"], [27, 28, "field"], [31, 35, "organisation"], [38, 40, "organisation"], [47, 50, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 18, 20, 21, "part-of", "", false, false], [24, 24, 27, 28, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Er", "ist", "Stipendiat", "der", "American", "Association", "for", "Artificial", "Intelligence", ",", "des", "Center", "for", "Advanced", "Study", "in", "the", "Behavioral", "Sciences", "der", "Stanford", "University", ",", "des", "MIT", "Center", "for", "Cognitive", "Science", ",", "des", "Canadian", "Institute", "for", "Advanced", "Research", ",", "der", "Canadian", "Psychological", "Association", "und", "wurde", "1998", "zum", "Fellow", "der", "Royal", "Society", "of", "Canada", "gew\u00e4hlt", "."], "sentence-detokenized": "Er ist Stipendiat der American Association for Artificial Intelligence, des Center for Advanced Study in the Behavioral Sciences der Stanford University, des MIT Center for Cognitive Science, des Canadian Institute for Advanced Research, der Canadian Psychological Association und wurde 1998 zum Fellow der Royal Society of Canada gew\u00e4hlt.", "token2charspan": [[0, 2], [3, 6], [7, 17], [18, 21], [22, 30], [31, 42], [43, 46], [47, 57], [58, 70], [70, 71], [72, 75], [76, 82], [83, 86], [87, 95], [96, 101], [102, 104], [105, 108], [109, 119], [120, 128], [129, 132], [133, 141], [142, 152], [152, 153], [154, 157], [158, 161], [162, 168], [169, 172], [173, 182], [183, 190], [190, 191], [192, 195], [196, 204], [205, 214], [215, 218], [219, 227], [228, 236], [236, 237], [238, 241], [242, 250], [251, 264], [265, 276], [277, 280], [281, 286], [287, 291], [292, 295], [296, 302], [303, 306], [307, 312], [313, 320], [321, 323], [324, 330], [331, 338], [338, 339]]}
{"doc_key": "ai-test-278", "ner": [[0, 1, "researcher"], [5, 6, "researcher"], [8, 9, "researcher"], [15, 17, "misc"], [20, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 15, 17, "part-of", "", false, false], [0, 1, 20, 23, "part-of", "", false, false], [5, 6, 15, 17, "part-of", "", false, false], [5, 6, 20, 23, "part-of", "", false, false], [8, 9, 15, 17, "part-of", "", false, false], [8, 9, 20, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Hinton", "wird", "-", "zusammen", "mit", "Yoshua", "Bengio", "und", "Yann", "LeCun", "-", "von", "einigen", "als", "der", "Pate", "der", "KI", "und", "der", "Pate", "des", "Deep", "Learning", "bezeichnet", "."], "sentence-detokenized": "Hinton wird - zusammen mit Yoshua Bengio und Yann LeCun - von einigen als der Pate der KI und der Pate des Deep Learning bezeichnet.", "token2charspan": [[0, 6], [7, 11], [12, 13], [14, 22], [23, 26], [27, 33], [34, 40], [41, 44], [45, 49], [50, 55], [56, 57], [58, 61], [62, 69], [70, 73], [74, 77], [78, 82], [83, 86], [87, 89], [90, 93], [94, 97], [98, 102], [103, 106], [107, 111], [112, 120], [121, 131], [131, 132]]}
{"doc_key": "ai-test-279", "ner": [[3, 3, "product"], [15, 15, "misc"], [17, 19, "misc"], [20, 20, "product"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 15, 15, "related-to", "", false, false], [3, 3, 17, 19, "related-to", "", false, false], [15, 15, 20, 20, "named", "same", false, false], [28, 29, 20, 20, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Das", "leichtgewichtige", "Open-Source-Sprachprojekt", "eSpeak", ",", "das", "einen", "eigenen", "Ansatz", "zur", "Synthese", "verfolgt", ",", "hat", "mit", "Mandarin", "und", "Kantonesisch", "experimentiert", ".", "eSpeak", "wurde", "von", "Mai", "2010", "bis", "2010", "von", "Google", "Translate", "verwendet", "."], "sentence-detokenized": "Das leichtgewichtige Open-Source-Sprachprojekt eSpeak, das einen eigenen Ansatz zur Synthese verfolgt, hat mit Mandarin und Kantonesisch experimentiert. eSpeak wurde von Mai 2010 bis 2010 von Google Translate verwendet.", "token2charspan": [[0, 3], [4, 20], [21, 46], [47, 53], [53, 54], [55, 58], [59, 64], [65, 72], [73, 79], [80, 83], [84, 92], [93, 101], [101, 102], [103, 106], [107, 110], [111, 119], [120, 123], [124, 136], [137, 151], [151, 152], [153, 159], [160, 165], [166, 169], [170, 173], [174, 178], [179, 182], [183, 187], [188, 191], [192, 198], [199, 208], [209, 218], [218, 219]]}
{"doc_key": "ai-test-280", "ner": [[0, 2, "product"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 12, 12, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Software", "Automatic", "Mouth", "wurde", "ebenfalls", "1982", "ver\u00f6ffentlicht", "und", "war", "das", "erste", "kommerzielle", "Sprachsyntheseprogramm", ",", "das", "ausschlie\u00dflich", "aus", "Software", "bestand", "."], "sentence-detokenized": "Software Automatic Mouth wurde ebenfalls 1982 ver\u00f6ffentlicht und war das erste kommerzielle Sprachsyntheseprogramm, das ausschlie\u00dflich aus Software bestand.", "token2charspan": [[0, 8], [9, 18], [19, 24], [25, 30], [31, 40], [41, 45], [46, 60], [61, 64], [65, 68], [69, 72], [73, 78], [79, 91], [92, 114], [114, 115], [116, 119], [120, 134], [135, 138], [139, 147], [148, 155], [155, 156]]}
{"doc_key": "ai-test-281", "ner": [[3, 3, "metrics"], [5, 5, "metrics"], [8, 8, "metrics"], [10, 11, "metrics"], [14, 20, "metrics"], [27, 27, "metrics"], [29, 29, "metrics"], [32, 38, "metrics"], [42, 42, "metrics"], [44, 44, "metrics"], [47, 47, "metrics"], [49, 49, "metrics"], [52, 58, "metrics"], [64, 64, "metrics"], [66, 66, "metrics"], [69, 75, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[5, 5, 3, 3, "named", "", false, false], [8, 8, 3, 3, "named", "", false, false], [10, 11, 3, 3, "named", "", false, false], [14, 20, 3, 3, "named", "", false, false], [29, 29, 27, 27, "named", "", false, false], [32, 38, 27, 27, "named", "", false, false], [44, 44, 42, 42, "named", "", false, false], [47, 47, 42, 42, "named", "", false, false], [49, 49, 42, 42, "named", "", false, false], [52, 58, 42, 42, "named", "", false, false], [66, 66, 64, 64, "named", "", false, false], [69, 75, 64, 64, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Die", "Spaltenkennzahlen", "sind", "WAHR-Positiv-Rate", "(", "TPR", ",", "auch", "Sensitivit\u00e4t", "oder", "Recall", "genannt", ")", "(", "TP", "/", "(", "TP", "+", "FN", ")", ")", ",", "mit", "dem", "Komplement", "der", "FALSCH-Negativ-Rate", "(", "FNR", ")", "(", "FN", "/", "(", "TP", "+", "FN", ")", ")", ";", "und", "WAHR-Negativ-Rate", "(", "TNR", ",", "auch", "Spezifit\u00e4t", ",", "SPC", ")", "(", "TN", "/", "(", "TN", "+", "FP", ")", ")", ",", "mit", "dem", "Komplement", "FALSCH-Positiv-Rate", "(", "FPR", ")", "(", "FP", "/", "(", "TN", "+", "FP", ")", ")", "."], "sentence-detokenized": "Die Spaltenkennzahlen sind WAHR-Positiv-Rate (TPR, auch Sensitivit\u00e4t oder Recall genannt) (TP / (TP + FN)), mit dem Komplement der FALSCH-Negativ-Rate (FNR) (FN / (TP + FN)); und WAHR-Negativ-Rate (TNR, auch Spezifit\u00e4t, SPC) (TN / (TN + FP)), mit dem Komplement FALSCH-Positiv-Rate (FPR) (FP / (TN + FP)).", "token2charspan": [[0, 3], [4, 21], [22, 26], [27, 44], [45, 46], [46, 49], [49, 50], [51, 55], [56, 68], [69, 73], [74, 80], [81, 88], [88, 89], [90, 91], [91, 93], [94, 95], [96, 97], [97, 99], [100, 101], [102, 104], [104, 105], [105, 106], [106, 107], [108, 111], [112, 115], [116, 126], [127, 130], [131, 150], [151, 152], [152, 155], [155, 156], [157, 158], [158, 160], [161, 162], [163, 164], [164, 166], [167, 168], [169, 171], [171, 172], [172, 173], [173, 174], [175, 178], [179, 196], [197, 198], [198, 201], [201, 202], [203, 207], [208, 218], [218, 219], [220, 223], [223, 224], [225, 226], [226, 228], [229, 230], [231, 232], [232, 234], [235, 236], [237, 239], [239, 240], [240, 241], [241, 242], [243, 246], [247, 250], [251, 261], [262, 281], [282, 283], [283, 286], [286, 287], [288, 289], [289, 291], [292, 293], [294, 295], [295, 297], [298, 299], [300, 302], [302, 303], [303, 304], [304, 305]]}
{"doc_key": "ai-test-282", "ner": [[0, 0, "person"], [2, 2, "person"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 16, 16, "role", "working_with", false, false], [2, 2, 16, 16, "role", "working_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Edsinger", "und", "Weber", "haben", "auch", "an", "vielen", "anderen", "Robotern", "zusammengearbeitet", ",", "und", "ihre", "Erfahrungen", "mit", "dem", "Kismet"], "sentence-detokenized": "Edsinger und Weber haben auch an vielen anderen Robotern zusammengearbeitet, und ihre Erfahrungen mit dem Kismet", "token2charspan": [[0, 8], [9, 12], [13, 18], [19, 24], [25, 29], [30, 32], [33, 39], [40, 47], [48, 56], [57, 75], [75, 76], [77, 80], [81, 85], [86, 97], [98, 101], [102, 105], [106, 112]]}
{"doc_key": "ai-test-283", "ner": [[8, 8, "programlang"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Die", "R-Funktionen", "sind", "auch", "\u00fcber", "verschiedene", "Skriptsprachen", "wie", "Python", "zug\u00e4nglich", "."], "sentence-detokenized": "Die R-Funktionen sind auch \u00fcber verschiedene Skriptsprachen wie Python zug\u00e4nglich.", "token2charspan": [[0, 3], [4, 16], [17, 21], [22, 26], [27, 31], [32, 44], [45, 59], [60, 63], [64, 70], [71, 81], [81, 82]]}
{"doc_key": "ai-test-284", "ner": [[0, 0, "programlang"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 9, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VAL", "war", "eine", "der", "ersten", "Robotersprachen", "und", "wurde", "in", "Unimate-Robotern", "verwendet", "."], "sentence-detokenized": "VAL war eine der ersten Robotersprachen und wurde in Unimate-Robotern verwendet.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 16], [17, 23], [24, 39], [40, 43], [44, 49], [50, 52], [53, 69], [70, 79], [79, 80]]}
{"doc_key": "ai-test-285", "ner": [[11, 21, "conference"], [19, 19, "conference"], [23, 23, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 21, 23, 23, "physical", "", false, false], [19, 19, 11, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Sie", "pr\u00e4sentierten", "ihre", "Datenbank", "zum", "ersten", "Mal", "als", "Poster", "auf", "der", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "2009", "in", "Florida", "."], "sentence-detokenized": "Sie pr\u00e4sentierten ihre Datenbank zum ersten Mal als Poster auf der Conference on Computer Vision and Pattern Recognition (CVPR) 2009 in Florida.", "token2charspan": [[0, 3], [4, 17], [18, 22], [23, 32], [33, 36], [37, 43], [44, 47], [48, 51], [52, 58], [59, 62], [63, 66], [67, 77], [78, 80], [81, 89], [90, 96], [97, 100], [101, 108], [109, 120], [121, 122], [122, 126], [126, 127], [128, 132], [133, 135], [136, 143], [143, 144]]}
{"doc_key": "ai-test-286", "ner": [[0, 0, "misc"], [11, 12, "task"], [14, 15, "field"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 12, 0, 0, "type-of", "", false, false], [14, 15, 0, 0, "type-of", "", false, false], [17, 18, 0, 0, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Kategorisierungsaufgaben", ",", "bei", "denen", "keine", "Kennzeichnungen", "geliefert", "werden", ",", "werden", "als", "un\u00fcberwachte", "Klassifizierung", ",", "un\u00fcberwachtes", "Lernen", "und", "Clusteranalyse", "bezeichnet", "."], "sentence-detokenized": "Kategorisierungsaufgaben, bei denen keine Kennzeichnungen geliefert werden, werden als un\u00fcberwachte Klassifizierung, un\u00fcberwachtes Lernen und Clusteranalyse bezeichnet.", "token2charspan": [[0, 24], [24, 25], [26, 29], [30, 35], [36, 41], [42, 57], [58, 67], [68, 74], [74, 75], [76, 82], [83, 86], [87, 99], [100, 115], [115, 116], [117, 130], [131, 137], [138, 141], [142, 156], [157, 167], [167, 168]]}
{"doc_key": "ai-test-287", "ner": [[3, 3, "task"], [13, 13, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Es", "geht", "um", "Objekterkennung", ",", "das", "Erkennen", "und", "Lokalisieren", "von", "Menschen", "und", "weitere", "Emotionserkennung", "."], "sentence-detokenized": "Es geht um Objekterkennung, das Erkennen und Lokalisieren von Menschen und weitere Emotionserkennung.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 26], [26, 27], [28, 31], [32, 40], [41, 44], [45, 57], [58, 61], [62, 70], [71, 74], [75, 82], [83, 100], [100, 101]]}
{"doc_key": "ai-test-288", "ner": [[7, 7, "misc"], [10, 10, "misc"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Der", "Prozess", "ist", "komplex", "und", "umfasst", "die", "Codierung", "und", "den", "Abruf", "."], "sentence-detokenized": "Der Prozess ist komplex und umfasst die Codierung und den Abruf.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 27], [28, 35], [36, 39], [40, 49], [50, 53], [54, 57], [58, 63], [63, 64]]}
{"doc_key": "ai-test-289", "ner": [[9, 9, "product"], [15, 15, "product"], [32, 32, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 15, 15, "named", "", false, false], [9, 9, 32, 32, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Diese", "Systeme", ",", "die", "auch", "als", "Parallelroboter", "oder", "verallgemeinerte", "Stewart-Plattformen", "bekannt", "sind", "(", "bei", "der", "Stewart-Plattform", "sind", "die", "Aktoren", "sowohl", "auf", "der", "Basis", "als", "auch", "auf", "der", "Plattform", "gepaart", ")", ",", "sind", "Gelenkroboter", ",", "die", "\u00e4hnliche", "Mechanismen", "f\u00fcr", "die", "Bewegung", "entweder", "des", "Roboters", "auf", "seiner", "Basis", "oder", "eines", "oder", "mehrerer", "Manipulatorarme", "verwenden", "."], "sentence-detokenized": "Diese Systeme, die auch als Parallelroboter oder verallgemeinerte Stewart-Plattformen bekannt sind (bei der Stewart-Plattform sind die Aktoren sowohl auf der Basis als auch auf der Plattform gepaart), sind Gelenkroboter, die \u00e4hnliche Mechanismen f\u00fcr die Bewegung entweder des Roboters auf seiner Basis oder eines oder mehrerer Manipulatorarme verwenden.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 18], [19, 23], [24, 27], [28, 43], [44, 48], [49, 65], [66, 85], [86, 93], [94, 98], [99, 100], [100, 103], [104, 107], [108, 125], [126, 130], [131, 134], [135, 142], [143, 149], [150, 153], [154, 157], [158, 163], [164, 167], [168, 172], [173, 176], [177, 180], [181, 190], [191, 198], [198, 199], [199, 200], [201, 205], [206, 219], [219, 220], [221, 224], [225, 233], [234, 245], [246, 249], [250, 253], [254, 262], [263, 271], [272, 275], [276, 284], [285, 288], [289, 295], [296, 301], [302, 306], [307, 312], [313, 317], [318, 326], [327, 342], [343, 352], [352, 353]]}
{"doc_key": "ai-test-290", "ner": [[0, 2, "field"], [4, 4, "field"], [9, 10, "field"], [15, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 4, 4, "part-of", "subfield", false, false], [0, 2, 9, 10, "compare", "", false, false], [9, 10, 15, 17, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Das", "maschinelle", "Sehen", "als", "systemtechnische", "Disziplin", "ist", "von", "der", "Computer", "Vision", ",", "einer", "Form", "der", "Informatik", ",", "zu", "unterscheiden", "."], "sentence-detokenized": "Das maschinelle Sehen als systemtechnische Disziplin ist von der Computer Vision, einer Form der Informatik, zu unterscheiden.", "token2charspan": [[0, 3], [4, 15], [16, 21], [22, 25], [26, 42], [43, 52], [53, 56], [57, 60], [61, 64], [65, 73], [74, 80], [80, 81], [82, 87], [88, 92], [93, 96], [97, 107], [107, 108], [109, 111], [112, 125], [125, 126]]}
{"doc_key": "ai-test-291", "ner": [[3, 3, "algorithm"], [7, 8, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 7, 8, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Die", "Aktivierungsfunktion", "der", "LSTM-Gates", "ist", "h\u00e4ufig", "die", "logistische", "Sigmoidfunktion", "."], "sentence-detokenized": "Die Aktivierungsfunktion der LSTM-Gates ist h\u00e4ufig die logistische Sigmoidfunktion.", "token2charspan": [[0, 3], [4, 24], [25, 28], [29, 39], [40, 43], [44, 50], [51, 54], [55, 66], [67, 82], [82, 83]]}
{"doc_key": "ai-test-292", "ner": [[5, 5, "metrics"], [18, 22, "metrics"], [24, 24, "metrics"], [32, 32, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 18, 22, "named", "", false, false], [5, 5, 32, 32, "named", "", false, false], [24, 24, 18, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Mit", "anderen", "Worten", ",", "der", "Stichprobenmittelwert", "ist", "der", "(", "notwendigerweise", "einzige", ")", "effiziente", "Sch\u00e4tzer", "und", "somit", "auch", "der", "unvoreingenommene", "Sch\u00e4tzer", "mit", "minimaler", "Varianz", "(", "MVUE", ")", ",", "der", "zudem", "auch", "noch", "der", "Maximum-Likelihood-Sch\u00e4tzer", "ist", "."], "sentence-detokenized": "Mit anderen Worten, der Stichprobenmittelwert ist der (notwendigerweise einzige) effiziente Sch\u00e4tzer und somit auch der unvoreingenommene Sch\u00e4tzer mit minimaler Varianz (MVUE), der zudem auch noch der Maximum-Likelihood-Sch\u00e4tzer ist.", "token2charspan": [[0, 3], [4, 11], [12, 18], [18, 19], [20, 23], [24, 45], [46, 49], [50, 53], [54, 55], [55, 71], [72, 79], [79, 80], [81, 91], [92, 100], [101, 104], [105, 110], [111, 115], [116, 119], [120, 137], [138, 146], [147, 150], [151, 160], [161, 168], [169, 170], [170, 174], [174, 175], [175, 176], [177, 180], [181, 186], [187, 191], [192, 196], [197, 200], [201, 228], [229, 232], [232, 233]]}
{"doc_key": "ai-test-293", "ner": [[1, 1, "academicjournal"], [4, 4, "researcher"], [6, 7, "researcher"], [9, 11, "researcher"], [22, 22, "product"], [25, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 1, 22, 22, "topic", "", false, false], [1, 1, 25, 26, "topic", "", false, false], [4, 4, 1, 1, "role", "", false, false], [6, 7, 1, 1, "role", "", false, false], [9, 11, 1, 1, "role", "", false, false], [22, 22, 25, 26, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Der", "Scientific", "American-Artikel", "von", "Berners-Lee", ",", "James", "Hendler", "und", "Ora", "Lassila", "aus", "dem", "Jahr", "2001", "beschrieb", "die", "zu", "erwartende", "Weiterentwicklung", "des", "bestehenden", "Webs", "zu", "einem", "Semantic", "Web", "."], "sentence-detokenized": "Der Scientific American-Artikel von Berners-Lee, James Hendler und Ora Lassila aus dem Jahr 2001 beschrieb die zu erwartende Weiterentwicklung des bestehenden Webs zu einem Semantic Web.", "token2charspan": [[0, 3], [4, 14], [15, 31], [32, 35], [36, 47], [47, 48], [49, 54], [55, 62], [63, 66], [67, 70], [71, 78], [79, 82], [83, 86], [87, 91], [92, 96], [97, 106], [107, 110], [111, 113], [114, 124], [125, 142], [143, 146], [147, 158], [159, 163], [164, 166], [167, 172], [173, 181], [182, 185], [185, 186]]}
{"doc_key": "ai-test-294", "ner": [[0, 3, "misc"], [13, 14, "person"], [16, 16, "person"], [41, 41, "person"], [45, 46, "person"]], "ner_mapping_to_source": [0, 1, 2, 4, 5], "relations": [[13, 14, 0, 3, "role", "actor_in_work", false, false], [16, 16, 13, 14, "named", "", false, false], [16, 16, 13, 14, "origin", "", false, false], [45, 46, 16, 16, "role", "auditioned_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 4], "sentence": ["In", "Blade", "Runner", "wurde", "eine", "Reihe", "von", "damals", "weniger", "bekannten", "Schauspielern", "eingesetzt", ":", "Sean", "Young", "spielt", "Rachael", ",", "einen", "experimentellen", "Replikanten", ",", "dem", "die", "Erinnerungen", "von", "Tyrells", "Nichte", "eingepflanzt", "wurden", ",", "so", "dass", "sie", "glaubt", ",", "sie", "sei", "ein", "Mensch", ";", "Sammon", ",", "S.", "92-93", "Nina", "Axelrod", "sprach", "f\u00fcr", "die", "Rolle", "vor", "."], "sentence-detokenized": "In Blade Runner wurde eine Reihe von damals weniger bekannten Schauspielern eingesetzt: Sean Young spielt Rachael, einen experimentellen Replikanten, dem die Erinnerungen von Tyrells Nichte eingepflanzt wurden, so dass sie glaubt, sie sei ein Mensch; Sammon, S. 92-93 Nina Axelrod sprach f\u00fcr die Rolle vor.", "token2charspan": [[0, 2], [3, 8], [9, 15], [16, 21], [22, 26], [27, 32], [33, 36], [37, 43], [44, 51], [52, 61], [62, 75], [76, 86], [86, 87], [88, 92], [93, 98], [99, 105], [106, 113], [113, 114], [115, 120], [121, 136], [137, 148], [148, 149], [150, 153], [154, 157], [158, 170], [171, 174], [175, 182], [183, 189], [190, 202], [203, 209], [209, 210], [211, 213], [214, 218], [219, 222], [223, 229], [229, 230], [231, 234], [235, 238], [239, 242], [243, 249], [249, 250], [251, 257], [257, 258], [259, 261], [262, 267], [268, 272], [273, 280], [281, 287], [288, 291], [292, 295], [296, 301], [302, 305], [305, 306]]}
{"doc_key": "ai-test-295", "ner": [[0, 1, "researcher"], [3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [14, 16, "university"], [22, 22, "product"], [24, 24, "product"], [39, 39, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 14, 16, "physical", "", false, false], [3, 4, 14, 16, "physical", "", false, false], [6, 7, 14, 16, "physical", "", false, false], [9, 10, 14, 16, "physical", "", false, false], [14, 16, 39, 39, "physical", "", true, false], [22, 22, 14, 16, "temporal", "", false, false], [24, 24, 14, 16, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Gerry", "Sussman", ",", "Eugene", "Charniak", ",", "Seymour", "Papert", "und", "Terry", "Winograd", "besuchten", "1971", "die", "Universit\u00e4t", "von", "Edinburgh", "und", "verbreiteten", "die", "Neuigkeiten", "\u00fcber", "Micro-Planner", "und", "SHRDLU", "und", "stellten", "den", "Ansatz", "der", "einheitlichen", "Beweisverfahren", "in", "Frage", ",", "der", "die", "Hauptst\u00fctze", "der", "Edinburgher", "Logiker", "gewesen", "war", "."], "sentence-detokenized": "Gerry Sussman, Eugene Charniak, Seymour Papert und Terry Winograd besuchten 1971 die Universit\u00e4t von Edinburgh und verbreiteten die Neuigkeiten \u00fcber Micro-Planner und SHRDLU und stellten den Ansatz der einheitlichen Beweisverfahren in Frage, der die Hauptst\u00fctze der Edinburgher Logiker gewesen war.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 21], [22, 30], [30, 31], [32, 39], [40, 46], [47, 50], [51, 56], [57, 65], [66, 75], [76, 80], [81, 84], [85, 96], [97, 100], [101, 110], [111, 114], [115, 127], [128, 131], [132, 143], [144, 148], [149, 162], [163, 166], [167, 173], [174, 177], [178, 186], [187, 190], [191, 197], [198, 201], [202, 215], [216, 231], [232, 234], [235, 240], [240, 241], [242, 245], [246, 249], [250, 261], [262, 265], [266, 277], [278, 285], [286, 293], [294, 297], [297, 298]]}
{"doc_key": "ai-test-296", "ner": [[0, 0, "researcher"], [8, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[0, 0, 8, 9, "role", "inspires", false, false], [0, 0, 11, 12, "role", "inspires", false, false], [0, 0, 14, 15, "role", "inspires", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Walters", "Arbeit", "inspirierte", "nachfolgende", "Generationen", "von", "Robotikforschern", "wie", "Rodney", "Brooks", ",", "Hans", "Moravec", "und", "Mark", "Tilden", "."], "sentence-detokenized": "Walters Arbeit inspirierte nachfolgende Generationen von Robotikforschern wie Rodney Brooks, Hans Moravec und Mark Tilden.", "token2charspan": [[0, 7], [8, 14], [15, 26], [27, 39], [40, 52], [53, 56], [57, 73], [74, 77], [78, 84], [85, 91], [91, 92], [93, 97], [98, 105], [106, 109], [110, 114], [115, 121], [121, 122]]}
{"doc_key": "ai-test-297", "ner": [[5, 5, "algorithm"], [7, 8, "researcher"], [12, 18, "event"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 7, 8, "origin", "", false, false], [5, 5, 12, 18, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Anschlie\u00dfend", "gewann", "ein", "\u00e4hnliches", "GPU-basiertes", "CNN", "von", "Alex", "Krizhevsky", "et", "al.", "die", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "2012", "."], "sentence-detokenized": "Anschlie\u00dfend gewann ein \u00e4hnliches GPU-basiertes CNN von Alex Krizhevsky et al. die ImageNet Large Scale Visual Recognition Challenge 2012.", "token2charspan": [[0, 12], [13, 19], [20, 23], [24, 33], [34, 47], [48, 51], [52, 55], [56, 60], [61, 71], [72, 74], [75, 78], [79, 82], [83, 91], [92, 97], [98, 103], [104, 110], [111, 122], [123, 132], [133, 137], [137, 138]]}
{"doc_key": "ai-test-298", "ner": [[4, 4, "misc"], [11, 12, "metrics"], [15, 15, "metrics"], [21, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 12, 4, 4, "type-of", "", false, false], [15, 15, 4, 4, "type-of", "", false, false], [15, 15, 21, 21, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Zu", "den", "h\u00e4ufig", "verwendeten", "Verlustfunktionen", "f\u00fcr", "die", "probabilistische", "Klassifizierung", "geh\u00f6ren", "der", "logarithmische", "Verlust", "und", "der", "Brier-Score", "zwischen", "den", "vorhergesagten", "und", "den", "wahren", "Wahrscheinlichkeitsverteilungen", "."], "sentence-detokenized": "Zu den h\u00e4ufig verwendeten Verlustfunktionen f\u00fcr die probabilistische Klassifizierung geh\u00f6ren der logarithmische Verlust und der Brier-Score zwischen den vorhergesagten und den wahren Wahrscheinlichkeitsverteilungen.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 25], [26, 43], [44, 47], [48, 51], [52, 68], [69, 84], [85, 92], [93, 96], [97, 111], [112, 119], [120, 123], [124, 127], [128, 139], [140, 148], [149, 152], [153, 167], [168, 171], [172, 175], [176, 182], [183, 214], [214, 215]]}
{"doc_key": "ai-test-299", "ner": [[4, 4, "organisation"], [18, 18, "organisation"], [9, 10, "misc"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[4, 4, 9, 10, "part-of", "", false, false], [18, 18, 4, 4, "role", "admits_E2_to", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["Im", "Mai", "2016", "wurde", "NtechLab", "als", "eines", "der", "drei", "russischen", "Unternehmen", "zur", "offiziellen", "Pr\u00fcfung", "der", "Biometrietechnologie", "durch", "das", "NIST", "zugelassen", "."], "sentence-detokenized": "Im Mai 2016 wurde NtechLab als eines der drei russischen Unternehmen zur offiziellen Pr\u00fcfung der Biometrietechnologie durch das NIST zugelassen.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 17], [18, 26], [27, 30], [31, 36], [37, 40], [41, 45], [46, 56], [57, 68], [69, 72], [73, 84], [85, 92], [93, 96], [97, 117], [118, 123], [124, 127], [128, 132], [133, 143], [143, 144]]}
{"doc_key": "ai-test-300", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["Gleitkommazahlen", "haben", "jedoch", "nur", "eine", "gewisse", "mathematische", "Genauigkeit", "."], "sentence-detokenized": "Gleitkommazahlen haben jedoch nur eine gewisse mathematische Genauigkeit.", "token2charspan": [[0, 16], [17, 22], [23, 29], [30, 33], [34, 38], [39, 46], [47, 60], [61, 72], [72, 73]]}
{"doc_key": "ai-test-301", "ner": [[7, 7, "organisation"], [10, 16, "conference"], [18, 18, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 10, 16, "role", "contributes_to", false, false], [18, 18, 10, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Im", "Jahr", "2015", "wurden", "viele", "Beitr\u00e4ge", "von", "SenseTime", "auf", "der", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "angenommen", "."], "sentence-detokenized": "Im Jahr 2015 wurden viele Beitr\u00e4ge von SenseTime auf der Conference on Computer Vision and Pattern Recognition (CVPR) angenommen.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 19], [20, 25], [26, 34], [35, 38], [39, 48], [49, 52], [53, 56], [57, 67], [68, 70], [71, 79], [80, 86], [87, 90], [91, 98], [99, 110], [111, 112], [112, 116], [116, 117], [118, 128], [128, 129]]}
{"doc_key": "ai-test-302", "ner": [[5, 7, "task"], [9, 9, "task"], [12, 13, "task"], [15, 18, "task"], [21, 21, "field"], [23, 25, "misc"], [28, 34, "conference"], [43, 45, "misc"], [47, 48, "conference"], [65, 67, "misc"], [69, 69, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[5, 7, 21, 21, "part-of", "task_part_of_field", false, false], [9, 9, 5, 7, "named", "", false, false], [12, 13, 21, 21, "part-of", "task_part_of_field", false, false], [15, 18, 12, 13, "named", "", false, false], [23, 25, 28, 34, "temporal", "", false, false], [43, 45, 47, 48, "temporal", "", false, false], [65, 67, 69, 69, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Er", "hat", "optimale", "Algorithmen", "f\u00fcr", "Structure", "From", "Motion", "(", "SFM", ",", "oder", "Visual", "SLAM", ",", "gleichzeitige", "Lokalisierung", "und", "Kartierung", ",", "in", "Robotics", ";", "Best", "Paper", "Award", "bei", "der", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "1998", ")", "mitentwickelt", ",", "deren", "Mehrdeutigkeiten", "charakterisiert", "(", "David", "Marr", "Prize", "bei", "ICCV", "1999", ")", "und", "auch", "die", "Identifizierbarkeit", "und", "Beobachtbarkeit", "der", "Fusion", "von", "visuellen", "und", "inertialen", "Sensoren", "charakterisiert", "(", "Best", "Paper", "Award", "bei", "Robotics", "2015", ")", "."], "sentence-detokenized": "Er hat optimale Algorithmen f\u00fcr Structure From Motion (SFM, oder Visual SLAM, gleichzeitige Lokalisierung und Kartierung, in Robotics; Best Paper Award bei der Conference on Computer Vision and Pattern Recognition 1998) mitentwickelt, deren Mehrdeutigkeiten charakterisiert (David Marr Prize bei ICCV 1999) und auch die Identifizierbarkeit und Beobachtbarkeit der Fusion von visuellen und inertialen Sensoren charakterisiert (Best Paper Award bei Robotics 2015).", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 27], [28, 31], [32, 41], [42, 46], [47, 53], [54, 55], [55, 58], [58, 59], [60, 64], [65, 71], [72, 76], [76, 77], [78, 91], [92, 105], [106, 109], [110, 120], [120, 121], [122, 124], [125, 133], [133, 134], [135, 139], [140, 145], [146, 151], [152, 155], [156, 159], [160, 170], [171, 173], [174, 182], [183, 189], [190, 193], [194, 201], [202, 213], [214, 218], [218, 219], [220, 233], [233, 234], [235, 240], [241, 257], [258, 273], [274, 275], [275, 280], [281, 285], [286, 291], [292, 295], [296, 300], [301, 305], [305, 306], [307, 310], [311, 315], [316, 319], [320, 339], [340, 343], [344, 359], [360, 363], [364, 370], [371, 374], [375, 384], [385, 388], [389, 399], [400, 408], [409, 424], [425, 426], [426, 430], [431, 436], [437, 442], [443, 446], [447, 455], [456, 460], [460, 461], [461, 462]]}
{"doc_key": "ai-test-303", "ner": [[0, 2, "researcher"], [3, 3, "organisation"], [5, 5, "organisation"], [7, 12, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Stephen", "H.", "Muggleton", "FBCS", ",", "FIET", ",", "Gesellschaft", "zur", "F\u00f6rderung", "der", "k\u00fcnstlichen", "Intelligenz", ","], "sentence-detokenized": "Stephen H. Muggleton FBCS, FIET, Gesellschaft zur F\u00f6rderung der k\u00fcnstlichen Intelligenz,", "token2charspan": [[0, 7], [8, 10], [11, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 45], [46, 49], [50, 59], [60, 63], [64, 75], [76, 87], [87, 88]]}
{"doc_key": "ai-test-304", "ner": [[0, 1, "task"], [7, 7, "field"], [10, 11, "field"], [14, 15, "field"], [21, 21, "task"], [23, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 7, 7, "part-of", "task_part_of_field", false, false], [0, 1, 10, 11, "part-of", "task_part_of_field", false, false], [0, 1, 14, 15, "part-of", "task_part_of_field", false, false], [0, 1, 21, 21, "part-of", "", false, false], [0, 1, 23, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Die", "Kantendetektion", "ist", "ein", "grundlegendes", "Instrument", "der", "Bildverarbeitung", ",", "des", "maschinellen", "Sehens", "und", "der", "Computer", "Vision", ",", "insbesondere", "in", "den", "Bereichen", "Merkmalserkennung", "und", "Merkmalsextraktion", "."], "sentence-detokenized": "Die Kantendetektion ist ein grundlegendes Instrument der Bildverarbeitung, des maschinellen Sehens und der Computer Vision, insbesondere in den Bereichen Merkmalserkennung und Merkmalsextraktion.", "token2charspan": [[0, 3], [4, 19], [20, 23], [24, 27], [28, 41], [42, 52], [53, 56], [57, 73], [73, 74], [75, 78], [79, 91], [92, 98], [99, 102], [103, 106], [107, 115], [116, 122], [122, 123], [124, 136], [137, 139], [140, 143], [144, 153], [154, 171], [172, 175], [176, 194], [194, 195]]}
{"doc_key": "ai-test-305", "ner": [[8, 8, "misc"], [22, 23, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ein", "Beispiel", "hierf\u00fcr", "w\u00e4re", "eine", "Variable", "wie", "die", "Au\u00dfentemperatur", "(", "mathtemp", "/", "math", ")", ",", "die", "in", "einer", "bestimmten", "Anwendung", "auf", "mehrere", "Dezimalstellen", "genau", "aufgezeichnet", "werden", "kann", "(", "je", "nach", "Messger\u00e4t", ")", "."], "sentence-detokenized": "Ein Beispiel hierf\u00fcr w\u00e4re eine Variable wie die Au\u00dfentemperatur (mathtemp / math), die in einer bestimmten Anwendung auf mehrere Dezimalstellen genau aufgezeichnet werden kann (je nach Messger\u00e4t).", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 25], [26, 30], [31, 39], [40, 43], [44, 47], [48, 63], [64, 65], [65, 73], [74, 75], [76, 80], [80, 81], [81, 82], [83, 86], [87, 89], [90, 95], [96, 106], [107, 116], [117, 120], [121, 128], [129, 143], [144, 149], [150, 163], [164, 170], [171, 175], [176, 177], [177, 179], [180, 184], [185, 194], [194, 195], [195, 196]]}
{"doc_key": "ai-test-306", "ner": [[4, 5, "person"], [7, 8, "person"], [10, 12, "person"], [17, 18, "person"], [24, 25, "person"], [28, 29, "person"], [32, 33, "person"], [35, 35, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 6, 8, 10, 11], "relations": [[35, 35, 32, 33, "named", "", false, false]], "relations_mapping_to_source": [4], "sentence": ["Die", "wiederkehrenden", "Juroren", "sind", "Fon", "Davis", ",", "Jessica", "Chobot", "und", "Leland", "Melvin", "sowie", "prominente", "Gastjuroren", "wie", "Schauspieler", "Clark", "Gregg", ",", "MythBusters-Moderator", "und", "ehemaliger", "Battlebots-Erbauer", "Adam", "Savage", ",", "NFL-Tightman", "Vernon", "Davis", "und", "YouTube-Star", "Michael", "Stevens", "alias", "Vsauce", "."], "sentence-detokenized": "Die wiederkehrenden Juroren sind Fon Davis, Jessica Chobot und Leland Melvin sowie prominente Gastjuroren wie Schauspieler Clark Gregg, MythBusters-Moderator und ehemaliger Battlebots-Erbauer Adam Savage, NFL-Tightman Vernon Davis und YouTube-Star Michael Stevens alias Vsauce.", "token2charspan": [[0, 3], [4, 19], [20, 27], [28, 32], [33, 36], [37, 42], [42, 43], [44, 51], [52, 58], [59, 62], [63, 69], [70, 76], [77, 82], [83, 93], [94, 105], [106, 109], [110, 122], [123, 128], [129, 134], [134, 135], [136, 157], [158, 161], [162, 172], [173, 191], [192, 196], [197, 203], [203, 204], [205, 217], [218, 224], [225, 230], [231, 234], [235, 247], [248, 255], [256, 263], [264, 269], [270, 276], [276, 277]]}
{"doc_key": "ai-test-307", "ner": [[17, 19, "algorithm"], [21, 23, "algorithm"], [25, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 19, 25, 31, "part-of", "", false, false], [21, 23, 25, 31, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Diese", "Methoden", "konnten", "sich", "jedoch", "nie", "gegen", "die", "auf", "generativen", ",", "diskriminativ", "trainierten", "Sprachmodellen", "basierende", "Technologie", "des", "Gaussian", "Mixture", "Model", "/", "Hidden", "Markov", "Model", "(", "GMM-HMM", ")", "durchsetzen", ",", "die", "auf", "einer", "uneinheitlichen", "internen", "Verarbeitung", "beruht", "."], "sentence-detokenized": "Diese Methoden konnten sich jedoch nie gegen die auf generativen, diskriminativ trainierten Sprachmodellen basierende Technologie des Gaussian Mixture Model / Hidden Markov Model (GMM-HMM) durchsetzen, die auf einer uneinheitlichen internen Verarbeitung beruht.", "token2charspan": [[0, 5], [6, 14], [15, 22], [23, 27], [28, 34], [35, 38], [39, 44], [45, 48], [49, 52], [53, 64], [64, 65], [66, 79], [80, 91], [92, 106], [107, 117], [118, 129], [130, 133], [134, 142], [143, 150], [151, 156], [157, 158], [159, 165], [166, 172], [173, 178], [179, 180], [180, 187], [187, 188], [189, 200], [200, 201], [202, 205], [206, 209], [210, 215], [216, 231], [232, 240], [241, 253], [254, 260], [260, 261]]}
{"doc_key": "ai-test-308", "ner": [[2, 2, "product"], [4, 5, "programlang"], [7, 7, "programlang"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Softwarepakete", "wie", "MATLAB", ",", "GNU", "Octave", ",", "Scilab", "und", "SciPy", "bieten", "bequeme", "M\u00f6glichkeiten", "zur", "Anwendung", "dieser", "verschiedenen", "Methoden", "."], "sentence-detokenized": "Softwarepakete wie MATLAB, GNU Octave, Scilab und SciPy bieten bequeme M\u00f6glichkeiten zur Anwendung dieser verschiedenen Methoden.", "token2charspan": [[0, 14], [15, 18], [19, 25], [25, 26], [27, 30], [31, 37], [37, 38], [39, 45], [46, 49], [50, 55], [56, 62], [63, 70], [71, 84], [85, 88], [89, 98], [99, 105], [106, 119], [120, 128], [128, 129]]}
{"doc_key": "ai-test-309", "ner": [[0, 3, "algorithm"], [5, 5, "algorithm"], [10, 11, "task"], [17, 18, "researcher"], [21, 22, "university"], [24, 25, "researcher"], [27, 30, "organisation"], [32, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 3, 10, 11, "related-to", "", false, false], [0, 3, 17, 18, "origin", "", false, false], [0, 3, 24, 25, "origin", "", false, false], [5, 5, 0, 3, "named", "", false, false], [17, 18, 21, 22, "physical", "", false, false], [17, 18, 21, 22, "role", "", false, false], [24, 25, 27, 30, "physical", "", false, false], [24, 25, 27, 30, "role", "", false, false], [32, 32, 27, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Die", "lineare", "pr\u00e4diktive", "Kodierung", "(", "LPC", ")", ",", "ein", "Algorithmus", "zur", "Sprachverarbeitung", ",", "wurde", "erstmals", "1966", "von", "Fumitada", "Itakura", "von", "der", "Universit\u00e4t", "Nagoya", "und", "Shuzo", "Saito", "von", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "vorgeschlagen", "."], "sentence-detokenized": "Die lineare pr\u00e4diktive Kodierung (LPC), ein Algorithmus zur Sprachverarbeitung, wurde erstmals 1966 von Fumitada Itakura von der Universit\u00e4t Nagoya und Shuzo Saito von Nippon Telegraph and Telephone (NTT) vorgeschlagen.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 32], [33, 34], [34, 37], [37, 38], [38, 39], [40, 43], [44, 55], [56, 59], [60, 78], [78, 79], [80, 85], [86, 94], [95, 99], [100, 103], [104, 112], [113, 120], [121, 124], [125, 128], [129, 140], [141, 147], [148, 151], [152, 157], [158, 163], [164, 167], [168, 174], [175, 184], [185, 188], [189, 198], [199, 200], [200, 203], [203, 204], [205, 218], [218, 219]]}
{"doc_key": "ai-test-310", "ner": [[10, 17, "conference"], [19, 19, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[19, 19, 10, 17, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Anl\u00e4sslich", "des", "25-j\u00e4hrigen", "Jubil\u00e4ums", "des", "Algorithmus", "wurde", "2006", "auf", "der", "International", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "ein", "Workshop", "organisiert", ",", "um", "die", "j\u00fcngsten", "Beitr\u00e4ge", "und", "Variationen", "des", "urspr\u00fcnglichen", "Algorithmus", "zusammenzufassen", ",", "die", "haupts\u00e4chlich", "darauf", "abzielten", ",", "die", "Geschwindigkeit", "des", "Algorithmus", ",", "die", "Robustheit", "und", "Genauigkeit", "der", "gesch\u00e4tzten", "L\u00f6sung", "zu", "verbessern", "und", "die", "Abh\u00e4ngigkeit", "von", "benutzerdefinierten", "Konstanten", "zu", "verringern", "."], "sentence-detokenized": "Anl\u00e4sslich des 25-j\u00e4hrigen Jubil\u00e4ums des Algorithmus wurde 2006 auf der International Conference on Computer Vision and Pattern Recognition (CVPR) ein Workshop organisiert, um die j\u00fcngsten Beitr\u00e4ge und Variationen des urspr\u00fcnglichen Algorithmus zusammenzufassen, die haupts\u00e4chlich darauf abzielten, die Geschwindigkeit des Algorithmus, die Robustheit und Genauigkeit der gesch\u00e4tzten L\u00f6sung zu verbessern und die Abh\u00e4ngigkeit von benutzerdefinierten Konstanten zu verringern.", "token2charspan": [[0, 10], [11, 14], [15, 26], [27, 36], [37, 40], [41, 52], [53, 58], [59, 63], [64, 67], [68, 71], [72, 85], [86, 96], [97, 99], [100, 108], [109, 115], [116, 119], [120, 127], [128, 139], [140, 141], [141, 145], [145, 146], [147, 150], [151, 159], [160, 171], [171, 172], [173, 175], [176, 179], [180, 188], [189, 197], [198, 201], [202, 213], [214, 217], [218, 232], [233, 244], [245, 261], [261, 262], [263, 266], [267, 280], [281, 287], [288, 297], [297, 298], [299, 302], [303, 318], [319, 322], [323, 334], [334, 335], [336, 339], [340, 350], [351, 354], [355, 366], [367, 370], [371, 382], [383, 389], [390, 392], [393, 403], [404, 407], [408, 411], [412, 424], [425, 428], [429, 448], [449, 459], [460, 462], [463, 473], [473, 474]]}
{"doc_key": "ai-test-311", "ner": [[4, 6, "university"], [9, 12, "organisation"], [15, 18, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Die", "Mitglieder", "besuchten", "die", "Universit\u00e4t", "von", "Debrecen", ",", "die", "Ungarische", "Akademie", "der", "Wissenschaften", ",", "die", "E\u00f6tv\u00f6s", "Lor", "\u00e1nd", "Universit\u00e4t", "usw."], "sentence-detokenized": "Die Mitglieder besuchten die Universit\u00e4t von Debrecen, die Ungarische Akademie der Wissenschaften, die E\u00f6tv\u00f6s Lor\u00e1nd Universit\u00e4t usw.", "token2charspan": [[0, 3], [4, 14], [15, 24], [25, 28], [29, 40], [41, 44], [45, 53], [53, 54], [55, 58], [59, 69], [70, 78], [79, 82], [83, 97], [97, 98], [99, 102], [103, 109], [110, 113], [113, 116], [117, 128], [129, 133]]}
{"doc_key": "ai-test-312", "ner": [[1, 1, "algorithm"], [19, 19, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 1, 19, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Um", "SVM", "auf", "F\u00e4lle", "zu", "erweitern", ",", "in", "denen", "die", "Daten", "nicht", "linear", "trennbar", "sind", ",", "f\u00fchren", "wir", "die", "Verlustfunktion", "ein", ","], "sentence-detokenized": "Um SVM auf F\u00e4lle zu erweitern, in denen die Daten nicht linear trennbar sind, f\u00fchren wir die Verlustfunktion ein,", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 16], [17, 19], [20, 29], [29, 30], [31, 33], [34, 39], [40, 43], [44, 49], [50, 55], [56, 62], [63, 71], [72, 76], [76, 77], [78, 84], [85, 88], [89, 92], [93, 108], [109, 112], [112, 113]]}
{"doc_key": "ai-test-313", "ner": [[0, 0, "programlang"], [9, 10, "researcher"], [12, 13, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 9, 10, "origin", "", false, false], [0, 0, 12, 13, "origin", "", false, false], [0, 0, 15, 16, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Logo", "ist", "eine", "p\u00e4dagogische", "Programmiersprache", ",", "die", "1967", "von", "Wally", "Feurzeig", ",", "Seymour", "Papert", "und", "Cynthia", "Solomon", "entwickelt", "wurde", "."], "sentence-detokenized": "Logo ist eine p\u00e4dagogische Programmiersprache, die 1967 von Wally Feurzeig, Seymour Papert und Cynthia Solomon entwickelt wurde.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 26], [27, 45], [45, 46], [47, 50], [51, 55], [56, 59], [60, 65], [66, 74], [74, 75], [76, 83], [84, 90], [91, 94], [95, 102], [103, 110], [111, 121], [122, 127], [127, 128]]}
{"doc_key": "ai-test-314", "ner": [[0, 3, "organisation"], [7, 11, "organisation"], [14, 17, "location"], [22, 22, "location"], [24, 24, "location"], [36, 39, "product"], [49, 53, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 7, 11, "role", "works_for", false, false], [7, 11, 14, 17, "physical", "", false, false], [14, 17, 22, 22, "physical", "", false, false], [22, 22, 24, 24, "physical", "", false, false], [36, 39, 0, 3, "origin", "", false, false], [49, 53, 36, 39, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Das", "Eyring", "Research", "Institute", "war", "f\u00fcr", "das", "U.S.", "Air", "Force", "Missile", "Directorate", "auf", "der", "Hill", "Air", "Force", "Base", "in", "der", "N\u00e4he", "von", "Ogden", ",", "Utah", ",", "ma\u00dfgeblich", "an", "der", "unter", "strengster", "milit\u00e4rischer", "Geheimhaltung", "erfolgten", "Entwicklung", "der", "Intelligent", "Systems", "Technology", "Software", "beteiligt", ",", "die", "die", "Grundlage", "f\u00fcr", "das", "sp\u00e4ter", "nach", "Reagan", "benannte", "Star", "Wars-Programm", "bildete", "."], "sentence-detokenized": "Das Eyring Research Institute war f\u00fcr das U.S. Air Force Missile Directorate auf der Hill Air Force Base in der N\u00e4he von Ogden, Utah, ma\u00dfgeblich an der unter strengster milit\u00e4rischer Geheimhaltung erfolgten Entwicklung der Intelligent Systems Technology Software beteiligt, die die Grundlage f\u00fcr das sp\u00e4ter nach Reagan benannte Star Wars-Programm bildete.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 29], [30, 33], [34, 37], [38, 41], [42, 46], [47, 50], [51, 56], [57, 64], [65, 76], [77, 80], [81, 84], [85, 89], [90, 93], [94, 99], [100, 104], [105, 107], [108, 111], [112, 116], [117, 120], [121, 126], [126, 127], [128, 132], [132, 133], [134, 144], [145, 147], [148, 151], [152, 157], [158, 168], [169, 182], [183, 196], [197, 206], [207, 218], [219, 222], [223, 234], [235, 242], [243, 253], [254, 262], [263, 272], [272, 273], [274, 277], [278, 281], [282, 291], [292, 295], [296, 299], [300, 306], [307, 311], [312, 318], [319, 327], [328, 332], [333, 346], [347, 354], [354, 355]]}
{"doc_key": "ai-test-315", "ner": [[9, 9, "field"], [23, 25, "researcher"], [27, 28, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Im", "Laufe", "der", "Jahrzehnte", "hat", "er", "aufkommende", "Bereiche", "der", "Informatik", "erforscht", "und", "entwickelt", ",", "von", "Compilern", "\u00fcber", "Programmiersprachen", "bis", "hin", "zu", "Systemarchitekturen", "(", "John", "F.", "Sowa", "und", "John", "Zachman", ",", "1992", ")", "."], "sentence-detokenized": "Im Laufe der Jahrzehnte hat er aufkommende Bereiche der Informatik erforscht und entwickelt, von Compilern \u00fcber Programmiersprachen bis hin zu Systemarchitekturen (John F. Sowa und John Zachman, 1992).", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 23], [24, 27], [28, 30], [31, 42], [43, 51], [52, 55], [56, 66], [67, 76], [77, 80], [81, 91], [91, 92], [93, 96], [97, 106], [107, 111], [112, 131], [132, 135], [136, 139], [140, 142], [143, 162], [163, 164], [164, 168], [169, 171], [172, 176], [177, 180], [181, 185], [186, 193], [193, 194], [195, 199], [199, 200], [200, 201]]}
{"doc_key": "ai-test-316", "ner": [[1, 1, "algorithm"], [5, 5, "algorithm"], [7, 7, "algorithm"], [13, 13, "field"], [16, 17, "field"], [22, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 5, 1, 1, "named", "", false, false], [7, 7, 1, 1, "named", "", false, false], [13, 13, 1, 1, "usage", "", false, false], [16, 17, 1, 1, "usage", "", false, false], [22, 24, 1, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Der", "Sobel-Operator", ",", "manchmal", "auch", "Sobel-Feldman-Operator", "oder", "Sobel-Filter", "genannt", ",", "wird", "in", "der", "Bildverarbeitung", "und", "der", "Computer", "Vision", "verwendet", ",", "insbesondere", "bei", "Algorithmen", "zur", "Kantenerkennung", ",", "wo", "er", "ein", "Bild", "erzeugt", ",", "das", "die", "Kanten", "hervorhebt", "."], "sentence-detokenized": "Der Sobel-Operator, manchmal auch Sobel-Feldman-Operator oder Sobel-Filter genannt, wird in der Bildverarbeitung und der Computer Vision verwendet, insbesondere bei Algorithmen zur Kantenerkennung, wo er ein Bild erzeugt, das die Kanten hervorhebt.", "token2charspan": [[0, 3], [4, 18], [18, 19], [20, 28], [29, 33], [34, 56], [57, 61], [62, 74], [75, 82], [82, 83], [84, 88], [89, 91], [92, 95], [96, 112], [113, 116], [117, 120], [121, 129], [130, 136], [137, 146], [146, 147], [148, 160], [161, 164], [165, 176], [177, 180], [181, 196], [196, 197], [198, 200], [201, 203], [204, 207], [208, 212], [213, 220], [220, 221], [222, 225], [226, 229], [230, 236], [237, 247], [247, 248]]}
{"doc_key": "ai-test-317", "ner": [[0, 0, "algorithm"], [3, 3, "field"], [14, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 3, 3, "compare", "", false, false], [0, 0, 3, 3, "type-of", "", false, false], [0, 0, 14, 14, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["LDA", "ist", "ein", "\u00fcberwachter", "Lernalgorithmus", ",", "der", "die", "Kennzeichnungen", "der", "Daten", "verwendet", ",", "w\u00e4hrend", "PCA", "ein", "Lernalgorithmus", "ist", ",", "der", "die", "Kennzeichnungen", "ignoriert", "."], "sentence-detokenized": "LDA ist ein \u00fcberwachter Lernalgorithmus, der die Kennzeichnungen der Daten verwendet, w\u00e4hrend PCA ein Lernalgorithmus ist, der die Kennzeichnungen ignoriert.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 23], [24, 39], [39, 40], [41, 44], [45, 48], [49, 64], [65, 68], [69, 74], [75, 84], [84, 85], [86, 93], [94, 97], [98, 101], [102, 117], [118, 121], [121, 122], [123, 126], [127, 130], [131, 146], [147, 156], [156, 157]]}
{"doc_key": "ai-test-318", "ner": [[4, 4, "algorithm"], [6, 8, "algorithm"], [10, 11, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Andere", "lineare", "Klassifizierungsalgorithmen", "sind", "Winnow", ",", "Support", "Vector", "Machine", "und", "logistische", "Regression", "."], "sentence-detokenized": "Andere lineare Klassifizierungsalgorithmen sind Winnow, Support Vector Machine und logistische Regression.", "token2charspan": [[0, 6], [7, 14], [15, 42], [43, 47], [48, 54], [54, 55], [56, 63], [64, 70], [71, 78], [79, 82], [83, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-test-319", "ner": [[0, 0, "product"], [11, 11, "product"], [13, 13, "programlang"], [15, 15, "programlang"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[0, 0, 11, 11, "general-affiliation", "", true, false], [0, 0, 13, 13, "general-affiliation", "", true, false], [0, 0, 15, 15, "general-affiliation", "", true, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["VTK", "besteht", "aus", "einer", "C++-Klassenbibliothek", "und", "mehreren", "interpretierten", "Schnittstellenschichten", ",", "darunter", "Tcl/Tk", ",", "Java", "und", "Python", "."], "sentence-detokenized": "VTK besteht aus einer C++-Klassenbibliothek und mehreren interpretierten Schnittstellenschichten, darunter Tcl/Tk, Java und Python.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 21], [22, 43], [44, 47], [48, 56], [57, 72], [73, 96], [96, 97], [98, 106], [107, 113], [113, 114], [115, 119], [120, 123], [124, 130], [130, 131]]}
{"doc_key": "ai-test-320", "ner": [[10, 11, "task"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Auch", "Text", ",", "der", "durch", "die", "Verarbeitung", "spontaner", "Sprache", "mittels", "automatischer", "Spracherkennung", "und", "gedruckter", "oder", "handgeschriebener", "Texte", "mittels", "optischer", "Zeichenerkennung", "erzeugt", "wird", ",", "enth\u00e4lt", "Verarbeitungsrauschen", "."], "sentence-detokenized": "Auch Text, der durch die Verarbeitung spontaner Sprache mittels automatischer Spracherkennung und gedruckter oder handgeschriebener Texte mittels optischer Zeichenerkennung erzeugt wird, enth\u00e4lt Verarbeitungsrauschen.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 14], [15, 20], [21, 24], [25, 37], [38, 47], [48, 55], [56, 63], [64, 77], [78, 93], [94, 97], [98, 108], [109, 113], [114, 131], [132, 137], [138, 145], [146, 155], [156, 172], [173, 180], [181, 185], [185, 186], [187, 194], [195, 216], [216, 217]]}
{"doc_key": "ai-test-321", "ner": [[0, 0, "researcher"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 9, 9, "role", "directs_development_of", false, false]], "relations_mapping_to_source": [0], "sentence": ["Miller", "schrieb", "mehrere", "B\u00fccher", "und", "leitete", "die", "Entwicklung", "von", "WordNet", ",", "einer", "Online-Datenbank", "f\u00fcr", "Wortverkn\u00fcpfungen", ",", "die", "von", "Computerprogrammen", "genutzt", "werden", "kann", "."], "sentence-detokenized": "Miller schrieb mehrere B\u00fccher und leitete die Entwicklung von WordNet, einer Online-Datenbank f\u00fcr Wortverkn\u00fcpfungen, die von Computerprogrammen genutzt werden kann.", "token2charspan": [[0, 6], [7, 14], [15, 22], [23, 29], [30, 33], [34, 41], [42, 45], [46, 57], [58, 61], [62, 69], [69, 70], [71, 76], [77, 93], [94, 97], [98, 115], [115, 116], [117, 120], [121, 124], [125, 143], [144, 151], [152, 158], [159, 163], [163, 164]]}
{"doc_key": "ai-test-322", "ner": [[1, 1, "field"], [8, 10, "organisation"], [12, 13, "country"], [15, 16, "person"], [18, 20, "person"], [22, 23, "person"], [25, 26, "person"], [29, 30, "country"], [32, 35, "location"], [37, 38, "misc"], [39, 40, "person"], [42, 43, "person"], [46, 46, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 10, 12, 13, "physical", "", false, false], [15, 16, 29, 30, "physical", "", false, false], [18, 20, 29, 30, "physical", "", false, false], [22, 23, 29, 30, "physical", "", false, false], [25, 26, 29, 30, "physical", "", false, false], [32, 35, 1, 1, "general-affiliation", "", false, false], [32, 35, 39, 40, "artifact", "", false, false], [37, 38, 39, 40, "named", "", false, false], [42, 43, 46, 46, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Zeitgen\u00f6ssische", "Automaten", "sind", "vertreten", "durch", "die", "Werke", "von", "Cabaret", "Mechanical", "Theatre", "im", "Vereinigten", "K\u00f6nigreich", ",", "Dug", "North", "und", "Chomick", "+", "Meder", ",", "Arthur", "Ganson", ",", "Joe", "Jones", "in", "den", "Vereinigten", "Staaten", ",", "Le", "D\u00e9fenseur", "du", "Temps", "des", "franz\u00f6sischen", "K\u00fcnstlers", "Jacques", "Monestier", "und", "Fran\u00e7ois", "Junod", "in", "der", "Schweiz", "."], "sentence-detokenized": "Zeitgen\u00f6ssische Automaten sind vertreten durch die Werke von Cabaret Mechanical Theatre im Vereinigten K\u00f6nigreich, Dug North und Chomick + Meder, Arthur Ganson, Joe Jones in den Vereinigten Staaten, Le D\u00e9fenseur du Temps des franz\u00f6sischen K\u00fcnstlers Jacques Monestier und Fran\u00e7ois Junod in der Schweiz.", "token2charspan": [[0, 15], [16, 25], [26, 30], [31, 40], [41, 46], [47, 50], [51, 56], [57, 60], [61, 68], [69, 79], [80, 87], [88, 90], [91, 102], [103, 113], [113, 114], [115, 118], [119, 124], [125, 128], [129, 136], [137, 138], [139, 144], [144, 145], [146, 152], [153, 159], [159, 160], [161, 164], [165, 170], [171, 173], [174, 177], [178, 189], [190, 197], [197, 198], [199, 201], [202, 211], [212, 214], [215, 220], [221, 224], [225, 238], [239, 248], [249, 256], [257, 266], [267, 270], [271, 279], [280, 285], [286, 288], [289, 292], [293, 300], [300, 301]]}
{"doc_key": "ai-test-323", "ner": [[0, 0, "product"], [17, 17, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 17, 17, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MATLAB", "enth\u00e4lt", "standardm\u00e4\u00dfige", "Codefor/Code-", "und", "Codewhile/Code-Schleifen", ",", "aber", "(", "wie", "in", "anderen", "\u00e4hnlichen", "Anwendungen", ",", "z.", "B.", "R", ")", "wird", "die", "Verwendung", "der", "vektorisierten", "Notation", "empfohlen", ",", "die", "oft", "schneller", "ausgef\u00fchrt", "werden", "kann", "."], "sentence-detokenized": "MATLAB enth\u00e4lt standardm\u00e4\u00dfige Codefor/Code- und Codewhile/Code-Schleifen, aber (wie in anderen \u00e4hnlichen Anwendungen, z. B. R) wird die Verwendung der vektorisierten Notation empfohlen, die oft schneller ausgef\u00fchrt werden kann.", "token2charspan": [[0, 6], [7, 14], [15, 29], [30, 43], [44, 47], [48, 72], [72, 73], [74, 78], [79, 80], [80, 83], [84, 86], [87, 94], [95, 104], [105, 116], [116, 117], [118, 120], [121, 123], [124, 125], [125, 126], [127, 131], [132, 135], [136, 146], [147, 150], [151, 165], [166, 174], [175, 184], [184, 185], [186, 189], [190, 193], [194, 203], [204, 214], [215, 221], [222, 226], [226, 227]]}
{"doc_key": "ai-test-324", "ner": [[0, 0, "researcher"], [6, 9, "conference"], [15, 15, "field"], [18, 23, "misc"], [26, 35, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 18, 23, "win-defeat", "", false, false], [0, 0, 26, 35, "win-defeat", "", false, false], [18, 23, 6, 9, "temporal", "", false, false], [18, 23, 15, 15, "topic", "", false, false], [26, 35, 6, 9, "temporal", "", false, false], [26, 35, 15, 15, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pausch", "erhielt", "2007", "zwei", "Auszeichnungen", "der", "Association", "for", "Computing", "Machinery", "f\u00fcr", "seine", "Leistungen", "in", "der", "Informatikausbildung", ":", "den", "Karl", "V.", "Karlstrom", "Outstanding", "Educator", "Award", "und", "den", "ACM", "SIGCSE", "Award", "for", "Outstanding", "Contributions", "to", "Computer", "Science", "Education", "."], "sentence-detokenized": "Pausch erhielt 2007 zwei Auszeichnungen der Association for Computing Machinery f\u00fcr seine Leistungen in der Informatikausbildung: den Karl V. Karlstrom Outstanding Educator Award und den ACM SIGCSE Award for Outstanding Contributions to Computer Science Education.", "token2charspan": [[0, 6], [7, 14], [15, 19], [20, 24], [25, 39], [40, 43], [44, 55], [56, 59], [60, 69], [70, 79], [80, 83], [84, 89], [90, 100], [101, 103], [104, 107], [108, 128], [128, 129], [130, 133], [134, 138], [139, 141], [142, 151], [152, 163], [164, 172], [173, 178], [179, 182], [183, 186], [187, 190], [191, 197], [198, 203], [204, 207], [208, 219], [220, 233], [234, 236], [237, 245], [246, 253], [254, 263], [263, 264]]}
{"doc_key": "ai-test-325", "ner": [[4, 4, "person"], [8, 8, "product"], [13, 14, "organisation"]], "ner_mapping_to_source": [0, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Im", "Jahr", "1960", "verkaufte", "Devol", "pers\u00f6nlich", "den", "ersten", "Unimate-Roboter", ",", "der", "1961", "an", "General", "Motors", "ausgeliefert", "wurde", "."], "sentence-detokenized": "Im Jahr 1960 verkaufte Devol pers\u00f6nlich den ersten Unimate-Roboter, der 1961 an General Motors ausgeliefert wurde.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 22], [23, 28], [29, 39], [40, 43], [44, 50], [51, 66], [66, 67], [68, 71], [72, 76], [77, 79], [80, 87], [88, 94], [95, 107], [108, 113], [113, 114]]}
{"doc_key": "ai-test-326", "ner": [[0, 1, "algorithm"], [5, 8, "field"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 0, 1, "usage", "", false, false], [11, 12, 5, 8, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Semantische", "Netze", "werden", "in", "Anwendungen", "zur", "Verarbeitung", "nat\u00fcrlicher", "Sprache", "wie", "dem", "semantischen", "Parsing", "eingesetzt", "."], "sentence-detokenized": "Semantische Netze werden in Anwendungen zur Verarbeitung nat\u00fcrlicher Sprache wie dem semantischen Parsing eingesetzt.", "token2charspan": [[0, 11], [12, 17], [18, 24], [25, 27], [28, 39], [40, 43], [44, 56], [57, 68], [69, 76], [77, 80], [81, 84], [85, 97], [98, 105], [106, 116], [116, 117]]}
{"doc_key": "ai-test-327", "ner": [[4, 5, "field"], [7, 8, "field"], [10, 10, "task"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 23, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[7, 8, 4, 5, "usage", "", false, false], [10, 10, 4, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Einige", "erfolgreiche", "Anwendungen", "von", "Deep", "Learning", "sind", "Computer", "Vision", "und", "Spracherkennung", ".", "Honglak", "Lee", ",", "Roger", "Grosse", ",", "Rajesh", "Ranganath", ",", "Andrew", "Y.", "Ng", "."], "sentence-detokenized": "Einige erfolgreiche Anwendungen von Deep Learning sind Computer Vision und Spracherkennung. Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng.", "token2charspan": [[0, 6], [7, 19], [20, 31], [32, 35], [36, 40], [41, 49], [50, 54], [55, 63], [64, 70], [71, 74], [75, 90], [90, 91], [92, 99], [100, 103], [103, 104], [105, 110], [111, 117], [117, 118], [119, 125], [126, 135], [135, 136], [137, 143], [144, 146], [147, 149], [149, 150]]}
{"doc_key": "ai-test-328", "ner": [[4, 8, "product"], [14, 14, "misc"], [17, 17, "misc"], [22, 22, "product"], [27, 27, "task"], [29, 29, "task"], [31, 31, "task"], [33, 35, "field"], [37, 37, "task"], [39, 39, "field"], [41, 42, "task"], [44, 45, "task"], [47, 49, "task"], [51, 51, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 8, 14, 14, "physical", "travels_to", false, false], [4, 8, 17, 17, "physical", "travels_to", false, false], [22, 22, 4, 8, "part-of", "", false, false], [22, 22, 4, 8, "role", "maintains", false, false], [22, 22, 27, 27, "related-to", "has_ability_to", false, false], [22, 22, 29, 29, "related-to", "has_ability_to", false, false], [22, 22, 31, 31, "related-to", "has_ability_to", false, false], [22, 22, 33, 35, "related-to", "has_ability_to", false, false], [22, 22, 37, 37, "related-to", "has_ability_to", false, false], [22, 22, 39, 39, "related-to", "has_ability_to", false, false], [22, 22, 41, 42, "related-to", "has_ability_to", false, false], [22, 22, 44, 45, "related-to", "has_ability_to", false, false], [22, 22, 47, 49, "related-to", "has_ability_to", false, false], [22, 22, 51, 51, "related-to", "has_ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Neben", "der", "Wartung", "der", "Systeme", "des", "Raumschiffs", "Discovery", "One", "w\u00e4hrend", "der", "interplanetaren", "Mission", "zum", "Jupiter", "(", "oder", "Saturn", "im", "Roman", ")", "ist", "HAL", "in", "der", "Lage", ",", "Sprachsynthese", ",", "Spracherkennung", ",", "Gesichtserkennung", ",", "Verarbeitung", "nat\u00fcrlicher", "Sprache", ",", "Lippenlesen", ",", "Kunstverst\u00e4ndnis", ",", "Affective", "Computing", ",", "automatisiertes", "Denken", ",", "Steuerung", "von", "Raumschiffen", "und", "Schachspielen", "."], "sentence-detokenized": "Neben der Wartung der Systeme des Raumschiffs Discovery One w\u00e4hrend der interplanetaren Mission zum Jupiter (oder Saturn im Roman) ist HAL in der Lage, Sprachsynthese, Spracherkennung, Gesichtserkennung, Verarbeitung nat\u00fcrlicher Sprache, Lippenlesen, Kunstverst\u00e4ndnis, Affective Computing, automatisiertes Denken, Steuerung von Raumschiffen und Schachspielen.", "token2charspan": [[0, 5], [6, 9], [10, 17], [18, 21], [22, 29], [30, 33], [34, 45], [46, 55], [56, 59], [60, 67], [68, 71], [72, 87], [88, 95], [96, 99], [100, 107], [108, 109], [109, 113], [114, 120], [121, 123], [124, 129], [129, 130], [131, 134], [135, 138], [139, 141], [142, 145], [146, 150], [150, 151], [152, 166], [166, 167], [168, 183], [183, 184], [185, 202], [202, 203], [204, 216], [217, 228], [229, 236], [236, 237], [238, 249], [249, 250], [251, 267], [267, 268], [269, 278], [279, 288], [288, 289], [290, 305], [306, 312], [312, 313], [314, 323], [324, 327], [328, 340], [341, 344], [345, 358], [358, 359]]}
{"doc_key": "ai-test-329", "ner": [[0, 1, "researcher"], [9, 9, "country"], [12, 13, "country"], [5, 5, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 9, 9, "physical", "", false, false], [0, 1, 12, 13, "physical", "", false, false], [0, 1, 5, 5, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dr.", "Julesz", "emigrierte", "nach", "der", "sowjetischen", "Invasion", "1956", "aus", "Ungarn", "in", "die", "Vereinigten", "Staaten", "."], "sentence-detokenized": "Dr. Julesz emigrierte nach der sowjetischen Invasion 1956 aus Ungarn in die Vereinigten Staaten.", "token2charspan": [[0, 3], [4, 10], [11, 21], [22, 26], [27, 30], [31, 43], [44, 52], [53, 57], [58, 61], [62, 68], [69, 71], [72, 75], [76, 87], [88, 95], [95, 96]]}
{"doc_key": "ai-test-330", "ner": [[2, 2, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Aktivierungsfunktionen", "mit", "Sigmoidfunktion", "verwenden", "eine", "zweite", "Nichtlinearit\u00e4t", "f\u00fcr", "gro\u00dfe", "Eingaben", ":", "math\\", "phi", "(", "v", "_", "i", ")", "=", "(", "1", "+\\", "exp", "(", "-v", "_", "i", ")", ")", "^", "{", "-1", "}", "/", "math", "."], "sentence-detokenized": "Aktivierungsfunktionen mit Sigmoidfunktion verwenden eine zweite Nichtlinearit\u00e4t f\u00fcr gro\u00dfe Eingaben: math\\ phi (v _ i) = (1 +\\ exp (-v _ i)) ^ {-1} / math.", "token2charspan": [[0, 22], [23, 26], [27, 42], [43, 52], [53, 57], [58, 64], [65, 80], [81, 84], [85, 90], [91, 99], [99, 100], [101, 106], [107, 110], [111, 112], [112, 113], [114, 115], [116, 117], [117, 118], [119, 120], [121, 122], [122, 123], [124, 126], [127, 130], [131, 132], [132, 134], [135, 136], [137, 138], [138, 139], [139, 140], [141, 142], [143, 144], [144, 146], [146, 147], [148, 149], [150, 154], [154, 155]]}
{"doc_key": "ai-test-331", "ner": [[11, 12, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Diese", "Wahrscheinlichkeiten", "werden", "verwendet", ",", "um", "das", "Ziel", "mit", "Hilfe", "einer", "Maximalwahrscheinlichkeitsentscheidung", "zu", "bestimmen", "."], "sentence-detokenized": "Diese Wahrscheinlichkeiten werden verwendet, um das Ziel mit Hilfe einer Maximalwahrscheinlichkeitsentscheidung zu bestimmen.", "token2charspan": [[0, 5], [6, 26], [27, 33], [34, 43], [43, 44], [45, 47], [48, 51], [52, 56], [57, 60], [61, 66], [67, 72], [73, 111], [112, 114], [115, 124], [124, 125]]}
{"doc_key": "ai-test-332", "ner": [[7, 8, "university"], [13, 14, "university"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Im", "Jahr", "1984", "wechselte", "er", "an", "die", "Universit\u00e4t", "Konstanz", "und", "1990", "an", "die", "Universit\u00e4t", "Salzburg", "."], "sentence-detokenized": "Im Jahr 1984 wechselte er an die Universit\u00e4t Konstanz und 1990 an die Universit\u00e4t Salzburg.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 22], [23, 25], [26, 28], [29, 32], [33, 44], [45, 53], [54, 57], [58, 62], [63, 65], [66, 69], [70, 81], [82, 90], [90, 91]]}
{"doc_key": "ai-test-333", "ner": [[8, 8, "metrics"], [10, 10, "metrics"], [12, 12, "metrics"], [14, 14, "metrics"], [16, 16, "metrics"], [18, 18, "metrics"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 10, 8, 8, "origin", "based_on", false, false], [12, 12, 8, 8, "origin", "based_on", false, false], [14, 14, 8, 8, "origin", "based_on", false, false], [16, 16, 8, 8, "origin", "based_on", false, false], [18, 18, 8, 8, "origin", "based_on", false, false], [20, 20, 8, 8, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Zu", "den", "g\u00e4ngigen", "Fitnessfunktionen", "auf", "der", "Grundlage", "der", "Konfusionsmatrix", "geh\u00f6ren", "Sensitivit\u00e4t/Spezifit\u00e4t", ",", "Recall/Pr\u00e4zision", ",", "F-Ma\u00df", ",", "Jaccard-\u00c4hnlichkeit", ",", "Matthews-Korrelationskoeffizient", "und", "Kosten/Gewinn-Matrix", ",", "die", "die", "Kosten", "und", "Gewinne", "der", "vier", "verschiedenen", "Klassifizierungstypen", "kombiniert", "."], "sentence-detokenized": "Zu den g\u00e4ngigen Fitnessfunktionen auf der Grundlage der Konfusionsmatrix geh\u00f6ren Sensitivit\u00e4t/Spezifit\u00e4t, Recall/Pr\u00e4zision, F-Ma\u00df, Jaccard-\u00c4hnlichkeit, Matthews-Korrelationskoeffizient und Kosten/Gewinn-Matrix, die die Kosten und Gewinne der vier verschiedenen Klassifizierungstypen kombiniert.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 33], [34, 37], [38, 41], [42, 51], [52, 55], [56, 72], [73, 80], [81, 104], [104, 105], [106, 122], [122, 123], [124, 129], [129, 130], [131, 150], [150, 151], [152, 184], [185, 188], [189, 209], [209, 210], [211, 214], [215, 218], [219, 225], [226, 229], [230, 237], [238, 241], [242, 246], [247, 260], [261, 282], [283, 293], [293, 294]]}
{"doc_key": "ai-test-334", "ner": [[4, 4, "product"], [6, 6, "product"], [8, 8, "product"], [10, 10, "product"], [13, 14, "programlang"], [26, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[26, 26, 4, 4, "part-of", "", false, false], [26, 26, 6, 6, "part-of", "", false, false], [26, 26, 8, 8, "part-of", "", false, false], [26, 26, 10, 10, "part-of", "", false, false], [26, 26, 13, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["G\u00e4ngige", "numerische", "Programmierumgebungen", "wie", "MATLAB", ",", "SciLab", ",", "NumPy", ",", "Sklearn", "und", "die", "Sprache", "R", "bieten", "einige", "der", "einfacheren", "Techniken", "zur", "Merkmalsextraktion", "(", "z.", "B.", "die", "Hauptkomponentenanalyse", ")", "\u00fcber", "integrierte", "Befehle", "."], "sentence-detokenized": "G\u00e4ngige numerische Programmierumgebungen wie MATLAB, SciLab, NumPy, Sklearn und die Sprache R bieten einige der einfacheren Techniken zur Merkmalsextraktion (z. B. die Hauptkomponentenanalyse) \u00fcber integrierte Befehle.", "token2charspan": [[0, 7], [8, 18], [19, 40], [41, 44], [45, 51], [51, 52], [53, 59], [59, 60], [61, 66], [66, 67], [68, 75], [76, 79], [80, 83], [84, 91], [92, 93], [94, 100], [101, 107], [108, 111], [112, 123], [124, 133], [134, 137], [138, 156], [157, 158], [158, 160], [161, 163], [164, 167], [168, 191], [191, 192], [193, 197], [198, 209], [210, 217], [217, 218]]}
{"doc_key": "ai-test-335", "ner": [[0, 0, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Industrieroboter", "werden", "eingesetzt", ",", "um", "mit", "Menschen", "zusammenzuarbeiten", "und", "Aufgaben", "in", "der", "industriellen", "Fertigung", "auszuf\u00fchren", "."], "sentence-detokenized": "Industrieroboter werden eingesetzt, um mit Menschen zusammenzuarbeiten und Aufgaben in der industriellen Fertigung auszuf\u00fchren.", "token2charspan": [[0, 16], [17, 23], [24, 34], [34, 35], [36, 38], [39, 42], [43, 51], [52, 70], [71, 74], [75, 83], [84, 86], [87, 90], [91, 104], [105, 114], [115, 126], [126, 127]]}
{"doc_key": "ai-test-336", "ner": [[6, 6, "field"], [8, 10, "researcher"], [19, 20, "field"], [23, 23, "field"], [26, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 19, 20, "related-to", "", false, false], [6, 6, 23, 23, "related-to", "", false, false], [6, 6, 26, 26, "related-to", "", false, false], [8, 10, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "der", "ersten", "ver\u00f6ffentlichten", "Arbeit", "\u00fcber", "CGs", "wendete", "John", "F.", "Sowa", "diese", "auf", "eine", "breite", "Palette", "von", "Themen", "der", "k\u00fcnstlichen", "Intelligenz", ",", "der", "Informatik", "und", "der", "Kognitionswissenschaft", "an", "."], "sentence-detokenized": "In der ersten ver\u00f6ffentlichten Arbeit \u00fcber CGs wendete John F. Sowa diese auf eine breite Palette von Themen der k\u00fcnstlichen Intelligenz, der Informatik und der Kognitionswissenschaft an.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 30], [31, 37], [38, 42], [43, 46], [47, 54], [55, 59], [60, 62], [63, 67], [68, 73], [74, 77], [78, 82], [83, 89], [90, 97], [98, 101], [102, 108], [109, 112], [113, 124], [125, 136], [136, 137], [138, 141], [142, 152], [153, 156], [157, 160], [161, 183], [184, 186], [186, 187]]}
{"doc_key": "ai-test-337", "ner": [[0, 0, "metrics"], [4, 4, "metrics"], [10, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 4, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "unterscheidet", "sich", "von", "BLEU", "auch", "in", "der", "Berechnung", "der", "Strafe", "f\u00fcr", "die", "K\u00fcrze", ",", "da", "sich", "kleine", "Abweichungen", "in", "der", "\u00dcbersetzungsl\u00e4nge", "nicht", "so", "stark", "auf", "die", "Gesamtbewertung", "auswirken", "."], "sentence-detokenized": "NIST unterscheidet sich von BLEU auch in der Berechnung der Strafe f\u00fcr die K\u00fcrze, da sich kleine Abweichungen in der \u00dcbersetzungsl\u00e4nge nicht so stark auf die Gesamtbewertung auswirken.", "token2charspan": [[0, 4], [5, 18], [19, 23], [24, 27], [28, 32], [33, 37], [38, 40], [41, 44], [45, 55], [56, 59], [60, 66], [67, 70], [71, 74], [75, 80], [80, 81], [82, 84], [85, 89], [90, 96], [97, 109], [110, 112], [113, 116], [117, 134], [135, 140], [141, 143], [144, 149], [150, 153], [154, 157], [158, 173], [174, 183], [183, 184]]}
{"doc_key": "ai-test-338", "ner": [[1, 6, "misc"], [18, 19, "field"]], "ner_mapping_to_source": [0, 2], "relations": [[1, 6, 18, 19, "topic", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Der", "IJCAI", "Award", "for", "Research", "Excellence", "wird", "alle", "zwei", "Jahre", "auf", "der", "IJCAI-Konferenz", "an", "Forscher", "im", "Bereich", "der", "k\u00fcnstlichen", "Intelligenz", "als", "Anerkennung", "f\u00fcr", "herausragende", "Leistungen", "in", "ihrer", "Karriere", "verliehen", "."], "sentence-detokenized": "Der IJCAI Award for Research Excellence wird alle zwei Jahre auf der IJCAI-Konferenz an Forscher im Bereich der k\u00fcnstlichen Intelligenz als Anerkennung f\u00fcr herausragende Leistungen in ihrer Karriere verliehen.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 19], [20, 28], [29, 39], [40, 44], [45, 49], [50, 54], [55, 60], [61, 64], [65, 68], [69, 84], [85, 87], [88, 96], [97, 99], [100, 107], [108, 111], [112, 123], [124, 135], [136, 139], [140, 151], [152, 155], [156, 169], [170, 180], [181, 183], [184, 189], [190, 198], [199, 208], [208, 209]]}
{"doc_key": "ai-test-339", "ner": [[0, 0, "researcher"], [7, 7, "conference"], [17, 24, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 7, 7, "role", "", false, false], [0, 0, 17, 24, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lenat", "war", "einer", "der", "ersten", "Fellows", "der", "AAAI", "und", "ist", "die", "einzige", "Person", ",", "die", "in", "den", "wissenschaftlichen", "Beir\u00e4ten", "von", "Microsoft", "und", "Apple", "vertreten", "ist", "."], "sentence-detokenized": "Lenat war einer der ersten Fellows der AAAI und ist die einzige Person, die in den wissenschaftlichen Beir\u00e4ten von Microsoft und Apple vertreten ist.", "token2charspan": [[0, 5], [6, 9], [10, 15], [16, 19], [20, 26], [27, 34], [35, 38], [39, 43], [44, 47], [48, 51], [52, 55], [56, 63], [64, 70], [70, 71], [72, 75], [76, 78], [79, 82], [83, 101], [102, 110], [111, 114], [115, 124], [125, 128], [129, 134], [135, 144], [145, 148], [148, 149]]}
{"doc_key": "ai-test-340", "ner": [[0, 0, "algorithm"], [6, 6, "misc"], [10, 12, "metrics"], [18, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 6, "related-to", "minimise", false, false], [10, 12, 6, 6, "type-of", "", false, false], [18, 20, 6, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Autoencoder", "werden", "so", "trainiert", ",", "dass", "Rekonstruktionsfehler", "(", "z.", "B.", "mittlerer", "quadratischer", "Fehler", ")", ",", "die", "oft", "als", "Verlust", "bezeichnet", "werden", ",", "minimiert", "werden", ":"], "sentence-detokenized": "Autoencoder werden so trainiert, dass Rekonstruktionsfehler (z. B. mittlerer quadratischer Fehler), die oft als Verlust bezeichnet werden, minimiert werden:", "token2charspan": [[0, 11], [12, 18], [19, 21], [22, 31], [31, 32], [33, 37], [38, 59], [60, 61], [61, 63], [64, 66], [67, 76], [77, 90], [91, 97], [97, 98], [98, 99], [100, 103], [104, 107], [108, 111], [112, 119], [120, 130], [131, 137], [137, 138], [139, 148], [149, 155], [155, 156]]}
{"doc_key": "ai-test-341", "ner": [[24, 25, "misc"], [27, 27, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[27, 27, 24, 25, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Eine", "Alternative", "zur", "Verwendung", "der", "Definitionen", "besteht", "darin", ",", "die", "allgemeine", "Wort-Sinn-Verwandtschaft", "zu", "ber\u00fccksichtigen", "und", "die", "\u00c4hnlichkeit", "jedes", "Wort-Sinn-Paares", "auf", "der", "Grundlage", "einer", "bestimmten", "lexikalischen", "Wissensbasis", "wie", "WordNet", "zu", "berechnen", "."], "sentence-detokenized": "Eine Alternative zur Verwendung der Definitionen besteht darin, die allgemeine Wort-Sinn-Verwandtschaft zu ber\u00fccksichtigen und die \u00c4hnlichkeit jedes Wort-Sinn-Paares auf der Grundlage einer bestimmten lexikalischen Wissensbasis wie WordNet zu berechnen.", "token2charspan": [[0, 4], [5, 16], [17, 20], [21, 31], [32, 35], [36, 48], [49, 56], [57, 62], [62, 63], [64, 67], [68, 78], [79, 103], [104, 106], [107, 122], [123, 126], [127, 130], [131, 142], [143, 148], [149, 165], [166, 169], [170, 173], [174, 183], [184, 189], [190, 200], [201, 214], [215, 227], [228, 231], [232, 239], [240, 242], [243, 252], [252, 253]]}
{"doc_key": "ai-test-342", "ner": [[0, 0, "algorithm"], [4, 6, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 6, "origin", "", false, false], [4, 6, 15, 16, "role", "work_based_on_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["TD-Lambda", "ist", "ein", "von", "Richard", "S.", "Sutton", "erfundener", "Lernalgorithmus", ",", "der", "auf", "fr\u00fcheren", "Arbeiten", "von", "Arthur", "Samuel", "zum", "Lernen", "mit", "zeitlichen", "Differenzen", "basiert", "."], "sentence-detokenized": "TD-Lambda ist ein von Richard S. Sutton erfundener Lernalgorithmus, der auf fr\u00fcheren Arbeiten von Arthur Samuel zum Lernen mit zeitlichen Differenzen basiert.", "token2charspan": [[0, 9], [10, 13], [14, 17], [18, 21], [22, 29], [30, 32], [33, 39], [40, 50], [51, 66], [66, 67], [68, 71], [72, 75], [76, 84], [85, 93], [94, 97], [98, 104], [105, 111], [112, 115], [116, 122], [123, 126], [127, 137], [138, 149], [150, 157], [157, 158]]}
{"doc_key": "ai-test-343", "ner": [[3, 4, "field"], [6, 6, "field"], [9, 10, "task"], [13, 14, "task"], [16, 16, "task"], [22, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 10, 3, 4, "part-of", "task_part_of_field", false, false], [9, 10, 6, 6, "part-of", "task_part_of_field", false, false], [13, 14, 9, 10, "named", "", false, false], [16, 16, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "den", "Bereichen", "Data", "Mining", "und", "Statistik", "ist", "das", "hierarchische", "Clustering", "(", "auch", "hierarchische", "Clusteranalyse", "oder", "HCA", "genannt", ")", "eine", "Methode", "der", "Clusteranalyse", ",", "die", "darauf", "abzielt", ",", "eine", "Hierarchie", "von", "Clustern", "aufzubauen", "."], "sentence-detokenized": "In den Bereichen Data Mining und Statistik ist das hierarchische Clustering (auch hierarchische Clusteranalyse oder HCA genannt) eine Methode der Clusteranalyse, die darauf abzielt, eine Hierarchie von Clustern aufzubauen.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 21], [22, 28], [29, 32], [33, 42], [43, 46], [47, 50], [51, 64], [65, 75], [76, 77], [77, 81], [82, 95], [96, 110], [111, 115], [116, 119], [120, 127], [127, 128], [129, 133], [134, 141], [142, 145], [146, 160], [160, 161], [162, 165], [166, 172], [173, 180], [180, 181], [182, 186], [187, 197], [198, 201], [202, 210], [211, 221], [221, 222]]}
{"doc_key": "ai-test-344", "ner": [[3, 3, "algorithm"], [11, 11, "field"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Das", "Konzept", "der", "Entfaltung", "ist", "in", "den", "Techniken", "der", "Signal-", "und", "Bildverarbeitung", "weit", "verbreitet", "."], "sentence-detokenized": "Das Konzept der Entfaltung ist in den Techniken der Signal- und Bildverarbeitung weit verbreitet.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 26], [27, 30], [31, 33], [34, 37], [38, 47], [48, 51], [52, 59], [60, 63], [64, 80], [81, 85], [86, 96], [96, 97]]}
{"doc_key": "ai-test-345", "ner": [[0, 1, "algorithm"], [24, 26, "misc"], [30, 30, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 24, 26, "related-to", "enhances", false, false], [0, 1, 24, 26, "related-to", "reduces", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Kognitive", "Karten", "dienen", "dem", "Aufbau", "und", "der", "Anh\u00e4ufung", "von", "r\u00e4umlichem", "Wissen", "und", "erm\u00f6glichen", "es", "dem", "geistigen", "Auge", ",", "Bilder", "zu", "visualisieren", ",", "um", "die", "kognitive", "Belastung", "zu", "verringern", "und", "das", "Abrufen", "und", "Lernen", "von", "Informationen", "zu", "verbessern", "."], "sentence-detokenized": "Kognitive Karten dienen dem Aufbau und der Anh\u00e4ufung von r\u00e4umlichem Wissen und erm\u00f6glichen es dem geistigen Auge, Bilder zu visualisieren, um die kognitive Belastung zu verringern und das Abrufen und Lernen von Informationen zu verbessern.", "token2charspan": [[0, 9], [10, 16], [17, 23], [24, 27], [28, 34], [35, 38], [39, 42], [43, 52], [53, 56], [57, 67], [68, 74], [75, 78], [79, 90], [91, 93], [94, 97], [98, 107], [108, 112], [112, 113], [114, 120], [121, 123], [124, 137], [137, 138], [139, 141], [142, 145], [146, 155], [156, 165], [166, 168], [169, 179], [180, 183], [184, 187], [188, 195], [196, 199], [200, 206], [207, 210], [211, 224], [225, 227], [228, 238], [238, 239]]}
{"doc_key": "ai-test-346", "ner": [[9, 9, "programlang"], [11, 13, "programlang"], [15, 15, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": [",", "die", "in", "der", "Regel", "Bindungen", "zu", "Sprachen", "wie", "Python", ",", "C", "+", "+", ",", "Java", ")", "."], "sentence-detokenized": ", die in der Regel Bindungen zu Sprachen wie Python, C + +, Java).", "token2charspan": [[0, 1], [2, 5], [6, 8], [9, 12], [13, 18], [19, 28], [29, 31], [32, 40], [41, 44], [45, 51], [51, 52], [53, 54], [55, 56], [57, 58], [58, 59], [60, 64], [64, 65], [65, 66]]}
{"doc_key": "ai-test-347", "ner": [[1, 1, "product"], [3, 3, "product"], [15, 15, "task"], [24, 26, "task"], [30, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 15, 15, "usage", "", false, false], [1, 1, 24, 26, "usage", "", false, false], [1, 1, 30, 33, "usage", "", false, false], [3, 3, 1, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Eine", "Sprachbenutzerschnittstelle", "(", "VUI", ")", "erm\u00f6glicht", "die", "gesprochene", "menschliche", "Interaktion", "mit", "Computern", ",", "indem", "sie", "Spracherkennung", "einsetzt", ",", "um", "gesprochene", "Befehle", "zu", "verstehen", "und", "Fragen", "zu", "beantworten", ",", "und", "normalerweise", "Text", "in", "Sprache", "umsetzt", ",", "um", "eine", "Antwort", "wiederzugeben", "."], "sentence-detokenized": "Eine Sprachbenutzerschnittstelle (VUI) erm\u00f6glicht die gesprochene menschliche Interaktion mit Computern, indem sie Spracherkennung einsetzt, um gesprochene Befehle zu verstehen und Fragen zu beantworten, und normalerweise Text in Sprache umsetzt, um eine Antwort wiederzugeben.", "token2charspan": [[0, 4], [5, 32], [33, 34], [34, 37], [37, 38], [39, 49], [50, 53], [54, 65], [66, 77], [78, 89], [90, 93], [94, 103], [103, 104], [105, 110], [111, 114], [115, 130], [131, 139], [139, 140], [141, 143], [144, 155], [156, 163], [164, 166], [167, 176], [177, 180], [181, 187], [188, 190], [191, 202], [202, 203], [204, 207], [208, 221], [222, 226], [227, 229], [230, 237], [238, 245], [245, 246], [247, 249], [250, 254], [255, 262], [263, 276], [276, 277]]}
{"doc_key": "ai-test-348", "ner": [[0, 0, "programlang"], [3, 3, "misc"], [10, 11, "researcher"], [13, 14, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4], "relations": [[0, 0, 3, 3, "general-affiliation", "is_a", false, false], [0, 0, 10, 11, "origin", "", false, false], [10, 11, 13, 14, "role", "", false, false]], "relations_mapping_to_source": [0, 2, 3], "sentence": ["Jess", "ist", "eine", "Regelmaschine", "f\u00fcr", "die", "Java-Plattform", ",", "die", "von", "Ernest", "Friedman-Hill", "von", "Sandia", "National", "entwickelt", "wurde", "."], "sentence-detokenized": "Jess ist eine Regelmaschine f\u00fcr die Java-Plattform, die von Ernest Friedman-Hill von Sandia National entwickelt wurde.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 27], [28, 31], [32, 35], [36, 50], [50, 51], [52, 55], [56, 59], [60, 66], [67, 80], [81, 84], [85, 91], [92, 100], [101, 111], [112, 117], [117, 118]]}
{"doc_key": "ai-test-349", "ner": [[1, 2, "algorithm"], [16, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 16, 16, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Bei", "mehrschichtigen", "Perceptrons", ",", "bei", "denen", "eine", "versteckte", "Schicht", "vorhanden", "ist", ",", "m\u00fcssen", "anspruchsvollere", "Algorithmen", "wie", "Backpropagation", "verwendet", "werden", "."], "sentence-detokenized": "Bei mehrschichtigen Perceptrons, bei denen eine versteckte Schicht vorhanden ist, m\u00fcssen anspruchsvollere Algorithmen wie Backpropagation verwendet werden.", "token2charspan": [[0, 3], [4, 19], [20, 31], [31, 32], [33, 36], [37, 42], [43, 47], [48, 58], [59, 66], [67, 76], [77, 80], [80, 81], [82, 88], [89, 105], [106, 117], [118, 121], [122, 137], [138, 147], [148, 154], [154, 155]]}
{"doc_key": "ai-test-350", "ner": [[5, 6, "product"], [0, 3, "product"], [10, 12, "algorithm"], [17, 19, "field"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 5, 6, "part-of", "", false, false], [0, 3, 10, 12, "usage", "", false, true], [10, 12, 17, 19, "related-to", "performs", false, false], [23, 25, 17, 19, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Das", "neuronale", "maschinelle", "\u00dcbersetzungssystem", "von", "Google", "Translate", "verwendet", "ein", "gro\u00dfes", "k\u00fcnstliches", "neuronales", "End-to-End-Netzwerk", ",", "das", "versucht", ",", "Deep", "Learning", "zu", "betreiben", ",", "insbesondere", "Netzwerke", "mit", "Langzeitged\u00e4chtnis", "."], "sentence-detokenized": "Das neuronale maschinelle \u00dcbersetzungssystem von Google Translate verwendet ein gro\u00dfes k\u00fcnstliches neuronales End-to-End-Netzwerk, das versucht, Deep Learning zu betreiben, insbesondere Netzwerke mit Langzeitged\u00e4chtnis.", "token2charspan": [[0, 3], [4, 13], [14, 25], [26, 44], [45, 48], [49, 55], [56, 65], [66, 75], [76, 79], [80, 86], [87, 98], [99, 109], [110, 129], [129, 130], [131, 134], [135, 143], [143, 144], [145, 149], [150, 158], [159, 161], [162, 171], [171, 172], [173, 185], [186, 195], [196, 199], [200, 218], [218, 219]]}
{"doc_key": "ai-test-351", "ner": [[12, 12, "researcher"], [14, 14, "researcher"], [16, 16, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"], [24, 24, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Verschiedene", "Methoden", "dazu", "wurden", "in", "den", "1980er", "und", "fr\u00fchen", "1990er", "Jahren", "von", "Werbos", ",", "Williams", ",", "Robinson", ",", "J\u00fcrgen", "Schmidhuber", ",", "Sepp", "Hochreiter", ",", "Pearlmutter", "und", "anderen", "entwickelt", "."], "sentence-detokenized": "Verschiedene Methoden dazu wurden in den 1980er und fr\u00fchen 1990er Jahren von Werbos, Williams, Robinson, J\u00fcrgen Schmidhuber, Sepp Hochreiter, Pearlmutter und anderen entwickelt.", "token2charspan": [[0, 12], [13, 21], [22, 26], [27, 33], [34, 36], [37, 40], [41, 47], [48, 51], [52, 58], [59, 65], [66, 72], [73, 76], [77, 83], [83, 84], [85, 93], [93, 94], [95, 103], [103, 104], [105, 111], [112, 123], [123, 124], [125, 129], [130, 140], [140, 141], [142, 153], [154, 157], [158, 165], [166, 176], [176, 177]]}
{"doc_key": "ai-test-352", "ner": [[0, 1, "organisation"], [2, 3, "organisation"], [8, 8, "organisation"], [14, 14, "product"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[0, 1, 8, 8, "role", "licenses_from", false, false], [2, 3, 0, 1, "named", "", false, false], [14, 14, 0, 1, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["|", "Apple", "Apple", "Inc.", "lizenzierte", "urspr\u00fcnglich", "Software", "von", "Nuance", ",", "um", "seinen", "digitalen", "Assistenten", "Siri", "mit", "Spracherkennungsfunktionen", "auszustatten", "."], "sentence-detokenized": "| Apple Apple Inc. lizenzierte urspr\u00fcnglich Software von Nuance, um seinen digitalen Assistenten Siri mit Spracherkennungsfunktionen auszustatten.", "token2charspan": [[0, 1], [2, 7], [8, 13], [14, 18], [19, 30], [31, 43], [44, 52], [53, 56], [57, 63], [63, 64], [65, 67], [68, 74], [75, 84], [85, 96], [97, 101], [102, 105], [106, 132], [133, 145], [145, 146]]}
{"doc_key": "ai-test-353", "ner": [[0, 0, "organisation"], [3, 3, "misc"], [7, 8, "person"], [12, 13, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 3, 3, "role", "releases_movies_in_genre", false, false], [7, 8, 0, 0, "role", "directs_for", false, false], [12, 13, 0, 0, "role", "directs_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Columbia", "ver\u00f6ffentlichte", "mehrere", "3D-Western", ",", "die", "von", "Sam", "Katzman", "produziert", "und", "von", "William", "Castle", "inszeniert", "wurden", "."], "sentence-detokenized": "Columbia ver\u00f6ffentlichte mehrere 3D-Western, die von Sam Katzman produziert und von William Castle inszeniert wurden.", "token2charspan": [[0, 8], [9, 24], [25, 32], [33, 43], [43, 44], [45, 48], [49, 52], [53, 56], [57, 64], [65, 75], [76, 79], [80, 83], [84, 91], [92, 98], [99, 109], [110, 116], [116, 117]]}
{"doc_key": "ai-test-354", "ner": [[8, 8, "field"], [10, 10, "field"], [12, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sie", "umfasst", "Wissen", "und", "Forschung", "in", "den", "Bereichen", "Informatik", ",", "Linguistik", "und", "Computertechnik", "."], "sentence-detokenized": "Sie umfasst Wissen und Forschung in den Bereichen Informatik, Linguistik und Computertechnik.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 22], [23, 32], [33, 35], [36, 39], [40, 49], [50, 60], [60, 61], [62, 72], [73, 76], [77, 92], [92, 93]]}
{"doc_key": "ai-test-355", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["Hier", "ist", "ein", "Beispiel", "f\u00fcr", "R-Code", ":"], "sentence-detokenized": "Hier ist ein Beispiel f\u00fcr R-Code:", "token2charspan": [[0, 4], [5, 8], [9, 12], [13, 21], [22, 25], [26, 32], [32, 33]]}
{"doc_key": "ai-test-356", "ner": [[1, 1, "metrics"], [7, 7, "metrics"], [9, 9, "metrics"], [13, 13, "metrics"], [15, 15, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 7, 7, "part-of", "plotted_into", false, false], [1, 1, 13, 13, "part-of", "plotted_into", false, false], [9, 9, 7, 7, "named", "", false, false], [15, 15, 13, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Die", "ROC-Kurve", "wird", "erstellt", ",", "indem", "die", "TRUE-positive-Rate", "(", "TPR", ")", "gegen", "die", "FALSCH-positive-Rate", "(", "FPR", ")", "bei", "verschiedenen", "Schwellenwerten", "aufgetragen", "wird", "."], "sentence-detokenized": "Die ROC-Kurve wird erstellt, indem die TRUE-positive-Rate (TPR) gegen die FALSCH-positive-Rate (FPR) bei verschiedenen Schwellenwerten aufgetragen wird.", "token2charspan": [[0, 3], [4, 13], [14, 18], [19, 27], [27, 28], [29, 34], [35, 38], [39, 57], [58, 59], [59, 62], [62, 63], [64, 69], [70, 73], [74, 94], [95, 96], [96, 99], [99, 100], [101, 104], [105, 118], [119, 134], [135, 146], [147, 151], [151, 152]]}
{"doc_key": "ai-test-357", "ner": [[4, 5, "field"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 4, 5, "related-to", "researches_field", false, false], [10, 11, 4, 5, "related-to", "researches_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Nach", "der", "Erforschung", "des", "maschinellen", "Lernens", "durch", "Marvin", "Minsky", "und", "Seymour", "Papert", "(", "1969", ")", "stagnierte", "die", "Forschung", ","], "sentence-detokenized": "Nach der Erforschung des maschinellen Lernens durch Marvin Minsky und Seymour Papert (1969) stagnierte die Forschung,", "token2charspan": [[0, 4], [5, 8], [9, 20], [21, 24], [25, 37], [38, 45], [46, 51], [52, 58], [59, 65], [66, 69], [70, 77], [78, 84], [85, 86], [86, 90], [90, 91], [92, 102], [103, 106], [107, 116], [116, 117]]}
{"doc_key": "ai-test-358", "ner": [[13, 13, "programlang"], [15, 16, "product"], [18, 19, "programlang"], [21, 21, "product"], [23, 23, "product"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Andere", "Programmierumgebungen", ",", "die", "f\u00fcr", "die", "Erstellung", "von", "DAQ-Anwendungen", "verwendet", "werden", ",", "sind", "Kontaktplan", ",", "Visual", "C++", ",", "Visual", "Basic", ",", "LabVIEW", "und", "MATLAB", "."], "sentence-detokenized": "Andere Programmierumgebungen, die f\u00fcr die Erstellung von DAQ-Anwendungen verwendet werden, sind Kontaktplan, Visual C++, Visual Basic, LabVIEW und MATLAB.", "token2charspan": [[0, 6], [7, 28], [28, 29], [30, 33], [34, 37], [38, 41], [42, 52], [53, 56], [57, 72], [73, 82], [83, 89], [89, 90], [91, 95], [96, 107], [107, 108], [109, 115], [116, 119], [119, 120], [121, 127], [128, 133], [133, 134], [135, 142], [143, 146], [147, 153], [153, 154]]}
{"doc_key": "ai-test-359", "ner": [[11, 11, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Die", "Metrik", "wurde", "entwickelt", ",", "um", "einige", "der", "Probleme", "der", "bekannteren", "BLEU-Metrik", "zu", "beheben", "und", "eine", "gute", "Korrelation", "mit", "der", "menschlichen", "Beurteilung", "auf", "Satz-", "oder", "Segmentebene", "herzustellen", "."], "sentence-detokenized": "Die Metrik wurde entwickelt, um einige der Probleme der bekannteren BLEU-Metrik zu beheben und eine gute Korrelation mit der menschlichen Beurteilung auf Satz- oder Segmentebene herzustellen.", "token2charspan": [[0, 3], [4, 10], [11, 16], [17, 27], [27, 28], [29, 31], [32, 38], [39, 42], [43, 51], [52, 55], [56, 67], [68, 79], [80, 82], [83, 90], [91, 94], [95, 99], [100, 104], [105, 116], [117, 120], [121, 124], [125, 137], [138, 149], [150, 153], [154, 159], [160, 164], [165, 177], [178, 190], [190, 191]]}
{"doc_key": "ai-test-360", "ner": [[2, 3, "algorithm"], [5, 6, "algorithm"], [9, 9, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniken", "wie", "dynamische", "Markov-Netzwerke", ",", "neuronale", "Faltungsnetzwerke", "und", "das", "Langzeitged\u00e4chtnis", "werden", "h\u00e4ufig", "eingesetzt", ",", "um", "die", "semantischen", "Korrelationen", "zwischen", "aufeinanderfolgenden", "Videobildern", "zu", "nutzen", "."], "sentence-detokenized": "Techniken wie dynamische Markov-Netzwerke, neuronale Faltungsnetzwerke und das Langzeitged\u00e4chtnis werden h\u00e4ufig eingesetzt, um die semantischen Korrelationen zwischen aufeinanderfolgenden Videobildern zu nutzen.", "token2charspan": [[0, 9], [10, 13], [14, 24], [25, 41], [41, 42], [43, 52], [53, 70], [71, 74], [75, 78], [79, 97], [98, 104], [105, 111], [112, 122], [122, 123], [124, 126], [127, 130], [131, 143], [144, 157], [158, 166], [167, 187], [188, 200], [201, 203], [204, 210], [210, 211]]}
{"doc_key": "ai-test-361", "ner": [[4, 4, "product"], [6, 6, "product"], [11, 11, "product"], [34, 34, "product"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[4, 4, 11, 11, "artifact", "", false, false], [4, 4, 34, 34, "named", "", false, false], [6, 6, 4, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "der", "Massenproduktion", "werden", "Leiterplatten", "(", "PCBs", ")", "fast", "ausschlie\u00dflich", "von", "Pick-and-Place-Robotern", ",", "typischerweise", "mit", "SCARA-Manipulatoren", ",", "hergestellt", ",", "die", "winzige", "elektronische", "Bauteile", "von", "Streifen", "oder", "Trays", "abnehmen", "und", "mit", "gro\u00dfer", "Genauigkeit", "auf", "die", "PCBs", "setzen", "."], "sentence-detokenized": "In der Massenproduktion werden Leiterplatten (PCBs) fast ausschlie\u00dflich von Pick-and-Place-Robotern, typischerweise mit SCARA-Manipulatoren, hergestellt, die winzige elektronische Bauteile von Streifen oder Trays abnehmen und mit gro\u00dfer Genauigkeit auf die PCBs setzen.", "token2charspan": [[0, 2], [3, 6], [7, 23], [24, 30], [31, 44], [45, 46], [46, 50], [50, 51], [52, 56], [57, 71], [72, 75], [76, 99], [99, 100], [101, 115], [116, 119], [120, 139], [139, 140], [141, 152], [152, 153], [154, 157], [158, 165], [166, 179], [180, 188], [189, 192], [193, 201], [202, 206], [207, 212], [213, 221], [222, 225], [226, 229], [230, 236], [237, 248], [249, 252], [253, 256], [257, 261], [262, 268], [268, 269]]}
{"doc_key": "ai-test-362", "ner": [[3, 4, "field"], [15, 15, "algorithm"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 28, "researcher"], [34, 35, "algorithm"], [38, 38, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 15, 3, 4, "part-of", "", false, false], [15, 15, 20, 21, "origin", "", false, false], [15, 15, 23, 24, "origin", "", false, false], [15, 15, 26, 28, "origin", "", false, false], [15, 15, 34, 35, "type-of", "", false, false], [34, 35, 38, 38, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Im", "Kontext", "des", "maschinellen", "Lernens", ",", "wo", "es", "heute", "am", "h\u00e4ufigsten", "angewendet", "wird", ",", "wurde", "LDA", "im", "Jahr", "2003", "von", "David", "Blei", ",", "Andrew", "Ng", "und", "Michael", "I.", "Jordan", "unabh\u00e4ngig", "voneinander", "wiederentdeckt", "und", "als", "grafisches", "Modell", "f\u00fcr", "die", "Themenfindung", "vorgestellt", "."], "sentence-detokenized": "Im Kontext des maschinellen Lernens, wo es heute am h\u00e4ufigsten angewendet wird, wurde LDA im Jahr 2003 von David Blei, Andrew Ng und Michael I. Jordan unabh\u00e4ngig voneinander wiederentdeckt und als grafisches Modell f\u00fcr die Themenfindung vorgestellt.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 27], [28, 35], [35, 36], [37, 39], [40, 42], [43, 48], [49, 51], [52, 62], [63, 73], [74, 78], [78, 79], [80, 85], [86, 89], [90, 92], [93, 97], [98, 102], [103, 106], [107, 112], [113, 117], [117, 118], [119, 125], [126, 128], [129, 132], [133, 140], [141, 143], [144, 150], [151, 161], [162, 173], [174, 188], [189, 192], [193, 196], [197, 207], [208, 214], [215, 218], [219, 222], [223, 236], [237, 248], [248, 249]]}
{"doc_key": "ai-test-363", "ner": [[8, 8, "task"], [11, 11, "misc"], [15, 15, "metrics"], [18, 18, "metrics"], [21, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 8, 11, 11, "related-to", "task_across_domain", false, false]], "relations_mapping_to_source": [0], "sentence": ["Die", "gemessene", "Leistung", "auf", "Testdaten", "von", "acht", "naiven", "WSI", "\u00fcber", "verschiedene", "Tauopathien", "hinweg", "ergab", "einen", "Recall", ",", "eine", "Pr\u00e4zision", "und", "einen", "F1-Wert", "von", "0,92", ",", "0,72", "bzw.", "0,81."], "sentence-detokenized": "Die gemessene Leistung auf Testdaten von acht naiven WSI \u00fcber verschiedene Tauopathien hinweg ergab einen Recall, eine Pr\u00e4zision und einen F1-Wert von 0,92, 0,72 bzw. 0,81.", "token2charspan": [[0, 3], [4, 13], [14, 22], [23, 26], [27, 36], [37, 40], [41, 45], [46, 52], [53, 56], [57, 61], [62, 74], [75, 86], [87, 93], [94, 99], [100, 105], [106, 112], [112, 113], [114, 118], [119, 128], [129, 132], [133, 138], [139, 146], [147, 150], [151, 155], [155, 156], [157, 161], [162, 166], [167, 172]]}
{"doc_key": "ai-test-364", "ner": [[10, 11, "field"], [19, 19, "task"]], "ner_mapping_to_source": [1, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Mit", "Hilfe", "fortschrittlicher", "AR-Technologien", "(", "z.", "B.", "durch", "Hinzuf\u00fcgen", "von", "Computer", "Vision", ",", "Einbau", "von", "AR-Kameras", "in", "Smartphones", "und", "Objekterkennung", ")", "werden", "die", "Informationen", "\u00fcber", "die", "reale", "Umgebung", "des", "Nutzers", "interaktiv", "und", "digital", "manipuliert", "."], "sentence-detokenized": "Mit Hilfe fortschrittlicher AR-Technologien (z. B. durch Hinzuf\u00fcgen von Computer Vision, Einbau von AR-Kameras in Smartphones und Objekterkennung) werden die Informationen \u00fcber die reale Umgebung des Nutzers interaktiv und digital manipuliert.", "token2charspan": [[0, 3], [4, 9], [10, 27], [28, 43], [44, 45], [45, 47], [48, 50], [51, 56], [57, 67], [68, 71], [72, 80], [81, 87], [87, 88], [89, 95], [96, 99], [100, 110], [111, 113], [114, 125], [126, 129], [130, 145], [145, 146], [147, 153], [154, 157], [158, 171], [172, 176], [177, 180], [181, 186], [187, 195], [196, 199], [200, 207], [208, 218], [219, 222], [223, 230], [231, 242], [242, 243]]}
{"doc_key": "ai-test-365", "ner": [[2, 3, "researcher"], [5, 5, "organisation"], [12, 13, "field"], [21, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 5, 5, "role", "forms_company", false, false], [5, 5, 12, 13, "related-to", "works_with", false, false], [5, 5, 21, 21, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["2014", "gr\u00fcndete", "Schmidhuber", "das", "Unternehmen", "Nnaisense", ",", "um", "an", "kommerziellen", "Anwendungen", "von", "k\u00fcnstlicher", "Intelligenz", "in", "Bereichen", "wie", "Finanzen", ",", "Schwerindustrie", "und", "selbstfahrenden", "Autos", "zu", "arbeiten", "."], "sentence-detokenized": "2014 gr\u00fcndete Schmidhuber das Unternehmen Nnaisense, um an kommerziellen Anwendungen von k\u00fcnstlicher Intelligenz in Bereichen wie Finanzen, Schwerindustrie und selbstfahrenden Autos zu arbeiten.", "token2charspan": [[0, 4], [5, 13], [14, 25], [26, 29], [30, 41], [42, 51], [51, 52], [53, 55], [56, 58], [59, 72], [73, 84], [85, 88], [89, 100], [101, 112], [113, 115], [116, 125], [126, 129], [130, 138], [138, 139], [140, 155], [156, 159], [160, 175], [176, 181], [182, 184], [185, 193], [193, 194]]}
{"doc_key": "ai-test-366", "ner": [[23, 25, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Dies", "ver\u00e4ndert", "nicht", "nur", "die", "Leistung", "aller", "nachfolgenden", "Tests", "f\u00fcr", "das", "beibehaltene", "erkl\u00e4rende", "Modell", ",", "sondern", "kann", "auch", "zu", "Verzerrungen", "f\u00fchren", "und", "den", "mittleren", "quadratischen", "Fehler", "bei", "der", "Sch\u00e4tzung", "ver\u00e4ndern", "."], "sentence-detokenized": "Dies ver\u00e4ndert nicht nur die Leistung aller nachfolgenden Tests f\u00fcr das beibehaltene erkl\u00e4rende Modell, sondern kann auch zu Verzerrungen f\u00fchren und den mittleren quadratischen Fehler bei der Sch\u00e4tzung ver\u00e4ndern.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 24], [25, 28], [29, 37], [38, 43], [44, 57], [58, 63], [64, 67], [68, 71], [72, 84], [85, 95], [96, 102], [102, 103], [104, 111], [112, 116], [117, 121], [122, 124], [125, 137], [138, 144], [145, 148], [149, 152], [153, 162], [163, 176], [177, 183], [184, 187], [188, 191], [192, 201], [202, 211], [211, 212]]}
{"doc_key": "ai-test-367", "ner": [[0, 0, "misc"], [9, 9, "task"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Bigramme", "werden", "in", "den", "meisten", "erfolgreichen", "Sprachmodellen", "f\u00fcr", "die", "Spracherkennung", "verwendet", "."], "sentence-detokenized": "Bigramme werden in den meisten erfolgreichen Sprachmodellen f\u00fcr die Spracherkennung verwendet.", "token2charspan": [[0, 8], [9, 15], [16, 18], [19, 22], [23, 30], [31, 44], [45, 59], [60, 63], [64, 67], [68, 83], [84, 93], [93, 94]]}
{"doc_key": "ai-test-368", "ner": [[6, 7, "field"], [12, 14, "misc"], [20, 22, "misc"], [27, 29, "organisation"], [32, 34, "misc"], [39, 42, "organisation"], [45, 47, "misc"], [52, 56, "organisation"], [59, 61, "misc"], [66, 68, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[12, 14, 6, 7, "topic", "", false, false], [20, 22, 27, 29, "origin", "", false, false], [32, 34, 39, 42, "origin", "", false, false], [45, 47, 52, 56, "origin", "", false, false], [59, 61, 66, 68, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["F\u00fcr", "seine", "Forschungen", "im", "Bereich", "der", "kognitiven", "Psychologie", "wurde", "er", "mit", "dem", "Early", "Career", "Award", "(", "1984", ")", "und", "dem", "Boyd", "McCandless", "Award", "(", "1986", ")", "der", "American", "Psychological", "Association", ",", "dem", "Troland", "Research", "Award", "(", "1993", ")", "der", "National", "Academy", "of", "Sciences", ",", "dem", "Henry", "Dale", "Prize", "(", "2004", ")", "der", "Royal", "Institution", "of", "Great", "Britain", "und", "dem", "George", "Miller", "Prize", "(", "2010", ")", "der", "Cognitive", "Neuroscience", "Society", "ausgezeichnet", "."], "sentence-detokenized": "F\u00fcr seine Forschungen im Bereich der kognitiven Psychologie wurde er mit dem Early Career Award (1984) und dem Boyd McCandless Award (1986) der American Psychological Association, dem Troland Research Award (1993) der National Academy of Sciences, dem Henry Dale Prize (2004) der Royal Institution of Great Britain und dem George Miller Prize (2010) der Cognitive Neuroscience Society ausgezeichnet.", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 24], [25, 32], [33, 36], [37, 47], [48, 59], [60, 65], [66, 68], [69, 72], [73, 76], [77, 82], [83, 89], [90, 95], [96, 97], [97, 101], [101, 102], [103, 106], [107, 110], [111, 115], [116, 126], [127, 132], [133, 134], [134, 138], [138, 139], [140, 143], [144, 152], [153, 166], [167, 178], [178, 179], [180, 183], [184, 191], [192, 200], [201, 206], [207, 208], [208, 212], [212, 213], [214, 217], [218, 226], [227, 234], [235, 237], [238, 246], [246, 247], [248, 251], [252, 257], [258, 262], [263, 268], [269, 270], [270, 274], [274, 275], [276, 279], [280, 285], [286, 297], [298, 300], [301, 306], [307, 314], [315, 318], [319, 322], [323, 329], [330, 336], [337, 342], [343, 344], [344, 348], [348, 349], [350, 353], [354, 363], [364, 376], [377, 384], [385, 398], [398, 399]]}
{"doc_key": "ai-test-369", "ner": [[1, 1, "misc"], [6, 6, "misc"], [9, 9, "product"], [15, 15, "researcher"], [17, 17, "researcher"], [24, 25, "researcher"], [27, 28, "researcher"], [31, 33, "task"], [36, 39, "researcher"], [41, 44, "researcher"], [45, 46, "task"], [48, 48, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[1, 1, 6, 6, "named", "", false, false], [1, 1, 48, 48, "named", "", false, false], [6, 6, 15, 15, "origin", "", false, false], [6, 6, 17, 17, "origin", "", false, false], [6, 6, 31, 33, "related-to", "used_for", false, false], [9, 9, 6, 6, "usage", "", false, false], [9, 9, 45, 46, "named", "", false, false], [24, 25, 6, 6, "usage", "", false, false], [24, 25, 36, 39, "named", "same", false, false], [27, 28, 6, 6, "usage", "", false, false], [27, 28, 41, 44, "named", "same", false, false], [45, 46, 48, 48, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Ein", "Eigengesicht", "(", "Der", "Ansatz", ",", "Eigengesichter", "f\u00fcr", "ein", "Gesichtserkennungssystem", "zu", "verwenden", ",", "wurde", "von", "Sirovich", "und", "Kirby", "(", "1987", ")", "entwickelt", "und", "von", "Matthew", "Turk", "und", "Alex", "Pentland", "bei", "der", "Klassifizierung", "von", "Gesichtern", "verwendet", ".", "Turk", ",", "Matthew", "A.", "und", "Pentland", ",", "Alex", "P.", "Face", "recognition", "using", "eigenfaces", "."], "sentence-detokenized": "Ein Eigengesicht (Der Ansatz, Eigengesichter f\u00fcr ein Gesichtserkennungssystem zu verwenden, wurde von Sirovich und Kirby (1987) entwickelt und von Matthew Turk und Alex Pentland bei der Klassifizierung von Gesichtern verwendet. Turk, Matthew A. und Pentland, Alex P. Face recognition using eigenfaces.", "token2charspan": [[0, 3], [4, 16], [17, 18], [18, 21], [22, 28], [28, 29], [30, 44], [45, 48], [49, 52], [53, 77], [78, 80], [81, 90], [90, 91], [92, 97], [98, 101], [102, 110], [111, 114], [115, 120], [121, 122], [122, 126], [126, 127], [128, 138], [139, 142], [143, 146], [147, 154], [155, 159], [160, 163], [164, 168], [169, 177], [178, 181], [182, 185], [186, 201], [202, 205], [206, 216], [217, 226], [226, 227], [228, 232], [232, 233], [234, 241], [242, 244], [245, 248], [249, 257], [257, 258], [259, 263], [264, 266], [267, 271], [272, 283], [284, 289], [290, 300], [300, 301]]}
{"doc_key": "ai-test-370", "ner": [[4, 4, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ein", "lexikalisches", "W\u00f6rterbuch", "wie", "WordNet", "kann", "dann", "zum", "Verst\u00e4ndnis", "des", "Kontexts", "herangezogen", "werden", "."], "sentence-detokenized": "Ein lexikalisches W\u00f6rterbuch wie WordNet kann dann zum Verst\u00e4ndnis des Kontexts herangezogen werden.", "token2charspan": [[0, 3], [4, 17], [18, 28], [29, 32], [33, 40], [41, 45], [46, 50], [51, 54], [55, 66], [67, 70], [71, 79], [80, 92], [93, 99], [99, 100]]}
{"doc_key": "ai-test-371", "ner": [[0, 0, "misc"], [8, 8, "misc"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 8, "part-of", "", false, false], [8, 8, 15, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hyponymie", "ist", "die", "am", "h\u00e4ufigsten", "kodierte", "Beziehung", "zwischen", "Synsets", ",", "die", "in", "lexikalischen", "Datenbanken", "wie", "WordNet", "verwendet", "werden", "."], "sentence-detokenized": "Hyponymie ist die am h\u00e4ufigsten kodierte Beziehung zwischen Synsets, die in lexikalischen Datenbanken wie WordNet verwendet werden.", "token2charspan": [[0, 9], [10, 13], [14, 17], [18, 20], [21, 31], [32, 40], [41, 50], [51, 59], [60, 67], [67, 68], [69, 72], [73, 75], [76, 89], [90, 101], [102, 105], [106, 113], [114, 123], [124, 130], [130, 131]]}
{"doc_key": "ai-test-372", "ner": [[0, 0, "organisation"], [4, 6, "programlang"], [8, 8, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 6, "general-affiliation", "", false, false], [0, 0, 8, 8, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["OPeNDAP", "bietet", "Open-Source-Bibliotheken", "in", "C", "+", "+", "und", "Java", ",", "aber", "viele", "Kunden", "verlassen", "sich", "auf", "von", "der", "Gemeinschaft", "entwickelte", "Bibliotheken", ",", "wie", "z.", "B.", "Bibliotheken", ",", "die", "eingebettete", "Funktionen", "zum", "Abrufen", "von", "Daten", "(", "im", "Array-Stil", ")", "von", "DAP-Servern", "enthalten", "."], "sentence-detokenized": "OPeNDAP bietet Open-Source-Bibliotheken in C + + und Java, aber viele Kunden verlassen sich auf von der Gemeinschaft entwickelte Bibliotheken, wie z. B. Bibliotheken, die eingebettete Funktionen zum Abrufen von Daten (im Array-Stil) von DAP-Servern enthalten.", "token2charspan": [[0, 7], [8, 14], [15, 39], [40, 42], [43, 44], [45, 46], [47, 48], [49, 52], [53, 57], [57, 58], [59, 63], [64, 69], [70, 76], [77, 86], [87, 91], [92, 95], [96, 99], [100, 103], [104, 116], [117, 128], [129, 141], [141, 142], [143, 146], [147, 149], [150, 152], [153, 165], [165, 166], [167, 170], [171, 183], [184, 194], [195, 198], [199, 206], [207, 210], [211, 216], [217, 218], [218, 220], [221, 231], [231, 232], [233, 236], [237, 248], [249, 258], [258, 259]]}
{"doc_key": "ai-test-373", "ner": [[4, 5, "misc"], [7, 7, "product"], [26, 27, "misc"], [39, 39, "product"], [41, 41, "organisation"], [42, 43, "product"]], "ner_mapping_to_source": [0, 1, 3, 5, 6, 7], "relations": [[26, 27, 7, 7, "part-of", "", false, false], [42, 43, 41, 41, "artifact", "", false, false]], "relations_mapping_to_source": [2, 4], "sentence": ["Auf", "dieser", "Seite", "stellte", "Samurai", "Damashii", "den", "Senkousha", "\u00fcberspitzt", "als", "Kristallisation", "von", "Chinas", "viertausendj\u00e4hrigem", "wissenschaftlichen", "Wissen", "dar", ",", "kommentierte", "das", "krude", "Design", "(", "z.", "B.", "die", "chinesische", "Kanone", "im", "Schritt", ")", "und", "stellte", "sein", "Bild", "neben", "Bilder", "von", "Hondas", "ASIMO", "und", "Sonys", "QRIO", "SDR-3X", ",", "um", "es", "nebeneinander", "zu", "stellen", "."], "sentence-detokenized": "Auf dieser Seite stellte Samurai Damashii den Senkousha \u00fcberspitzt als Kristallisation von Chinas viertausendj\u00e4hrigem wissenschaftlichen Wissen dar, kommentierte das krude Design (z. B. die chinesische Kanone im Schritt) und stellte sein Bild neben Bilder von Hondas ASIMO und Sonys QRIO SDR-3X, um es nebeneinander zu stellen.", "token2charspan": [[0, 3], [4, 10], [11, 16], [17, 24], [25, 32], [33, 41], [42, 45], [46, 55], [56, 66], [67, 70], [71, 86], [87, 90], [91, 97], [98, 117], [118, 136], [137, 143], [144, 147], [147, 148], [149, 161], [162, 165], [166, 171], [172, 178], [179, 180], [180, 182], [183, 185], [186, 189], [190, 201], [202, 208], [209, 211], [212, 219], [219, 220], [221, 224], [225, 232], [233, 237], [238, 242], [243, 248], [249, 255], [256, 259], [260, 266], [267, 272], [273, 276], [277, 282], [283, 287], [288, 294], [294, 295], [296, 298], [299, 301], [302, 315], [316, 318], [319, 326], [326, 327]]}
{"doc_key": "ai-test-374", "ner": [[9, 10, "algorithm"], [23, 23, "product"], [25, 25, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 23, 23, "part-of", "includes_functionality_of", false, false], [9, 10, 25, 25, "part-of", "includes_functionality_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Es", "gibt", "auch", "viele", "Programmierbibliotheken", ",", "die", "Funktionen", "f\u00fcr", "neuronale", "Netze", "enthalten", "und", "die", "in", "benutzerdefinierten", "Implementierungen", "verwendet", "werden", "k\u00f6nnen", "(", "z.", "B.", "TensorFlow", ",", "Theano", ",", "usw.", ")", "."], "sentence-detokenized": "Es gibt auch viele Programmierbibliotheken, die Funktionen f\u00fcr neuronale Netze enthalten und die in benutzerdefinierten Implementierungen verwendet werden k\u00f6nnen (z. B. TensorFlow, Theano, usw.).", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 18], [19, 42], [42, 43], [44, 47], [48, 58], [59, 62], [63, 72], [73, 78], [79, 88], [89, 92], [93, 96], [97, 99], [100, 119], [120, 137], [138, 147], [148, 154], [155, 161], [162, 163], [163, 165], [166, 168], [169, 179], [179, 180], [181, 187], [187, 188], [189, 193], [193, 194], [194, 195]]}
{"doc_key": "ai-test-375", "ner": [[4, 7, "conference"], [9, 9, "organisation"], [11, 17, "conference"], [19, 19, "conference"], [21, 21, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Er", "ist", "Fellow", "der", "Association", "for", "Computing", "Machinery", ",", "IEEE", ",", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "IAPR", "und", "SPIE", "."], "sentence-detokenized": "Er ist Fellow der Association for Computing Machinery, IEEE, American Association for the Advancement of Science, IAPR und SPIE.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 17], [18, 29], [30, 33], [34, 43], [44, 53], [53, 54], [55, 59], [59, 60], [61, 69], [70, 81], [82, 85], [86, 89], [90, 101], [102, 104], [105, 112], [112, 113], [114, 118], [119, 122], [123, 127], [127, 128]]}
{"doc_key": "ai-test-376", "ner": [[3, 3, "organisation"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 10, 10, "related-to", "runs_trials_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["Ein", "Versuch", "von", "RET", "im", "Jahr", "2011", "mit", "Kameras", "zur", "Gesichtserkennung", ",", "die", "an", "Stra\u00dfenbahnen", "angebracht", "waren", ",", "stellte", "sicher", ",", "dass", "sich", "die", "Personen", ",", "denen", "der", "Zutritt", "zu", "den", "Stra\u00dfenbahnen", "verwehrt", "wurde", ",", "nicht", "trotzdem", "hineinschlichen", "."], "sentence-detokenized": "Ein Versuch von RET im Jahr 2011 mit Kameras zur Gesichtserkennung, die an Stra\u00dfenbahnen angebracht waren, stellte sicher, dass sich die Personen, denen der Zutritt zu den Stra\u00dfenbahnen verwehrt wurde, nicht trotzdem hineinschlichen.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 19], [20, 22], [23, 27], [28, 32], [33, 36], [37, 44], [45, 48], [49, 66], [66, 67], [68, 71], [72, 74], [75, 88], [89, 99], [100, 105], [105, 106], [107, 114], [115, 121], [121, 122], [123, 127], [128, 132], [133, 136], [137, 145], [145, 146], [147, 152], [153, 156], [157, 164], [165, 167], [168, 171], [172, 185], [186, 194], [195, 200], [200, 201], [202, 207], [208, 216], [217, 232], [232, 233]]}
{"doc_key": "ai-test-377", "ner": [[9, 12, "person"], [17, 18, "person"], [20, 22, "person"], [27, 28, "person"], [30, 31, "person"], [33, 34, "person"], [36, 37, "person"], [39, 40, "person"], [42, 43, "person"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "dem", "Film", ",", "der", "auf", "dem", "beliebten", "Broadway-Musical", "von", "Cole", "Porter", "basiert", ",", "spielte", "das", "MGM-Gesangsduo", "Howard", "Keel", "und", "Kathryn", "Grayson", "die", "Hauptrollen", ",", "unterst\u00fctzt", "von", "Ann", "Miller", ",", "Keenan", "Wynn", ",", "Bobby", "Van", ",", "James", "Whitmore", ",", "Kurt", "Kasznar", "und", "Tommy", "Rall", "."], "sentence-detokenized": "In dem Film, der auf dem beliebten Broadway-Musical von Cole Porter basiert, spielte das MGM-Gesangsduo Howard Keel und Kathryn Grayson die Hauptrollen, unterst\u00fctzt von Ann Miller, Keenan Wynn, Bobby Van, James Whitmore, Kurt Kasznar und Tommy Rall.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [13, 16], [17, 20], [21, 24], [25, 34], [35, 51], [52, 55], [56, 60], [61, 67], [68, 75], [75, 76], [77, 84], [85, 88], [89, 103], [104, 110], [111, 115], [116, 119], [120, 127], [128, 135], [136, 139], [140, 151], [151, 152], [153, 164], [165, 168], [169, 172], [173, 179], [179, 180], [181, 187], [188, 192], [192, 193], [194, 199], [200, 203], [203, 204], [205, 210], [211, 219], [219, 220], [221, 225], [226, 233], [234, 237], [238, 243], [244, 248], [248, 249]]}
{"doc_key": "ai-test-378", "ner": [[15, 16, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Solche", "Anwendungen", "sollten", "den", "Anruffluss", "straffen", ",", "Aufforderungen", "minimieren", ",", "unn\u00f6tige", "Iterationen", "eliminieren", "und", "ausgekl\u00fcgelte", "gemischte", "Initiativdialoge", "erm\u00f6glichen", ",", "bei", "denen", "der", "Anrufer", "mehrere", "Informationen", "in", "einer", "einzigen", "\u00c4u\u00dferung", "und", "in", "beliebiger", "Reihenfolge", "oder", "Kombination", "eingeben", "kann", "."], "sentence-detokenized": "Solche Anwendungen sollten den Anruffluss straffen, Aufforderungen minimieren, unn\u00f6tige Iterationen eliminieren und ausgekl\u00fcgelte gemischte Initiativdialoge erm\u00f6glichen, bei denen der Anrufer mehrere Informationen in einer einzigen \u00c4u\u00dferung und in beliebiger Reihenfolge oder Kombination eingeben kann.", "token2charspan": [[0, 6], [7, 18], [19, 26], [27, 30], [31, 41], [42, 50], [50, 51], [52, 66], [67, 77], [77, 78], [79, 87], [88, 99], [100, 111], [112, 115], [116, 129], [130, 139], [140, 156], [157, 168], [168, 169], [170, 173], [174, 179], [180, 183], [184, 191], [192, 199], [200, 213], [214, 216], [217, 222], [223, 231], [232, 240], [241, 244], [245, 247], [248, 258], [259, 270], [271, 275], [276, 287], [288, 296], [297, 301], [301, 302]]}
{"doc_key": "ai-test-379", "ner": [[5, 5, "algorithm"], [9, 10, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 10, 5, 5, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["So", "k\u00f6nnen", "herk\u00f6mmliche", "Methoden", "des", "Gradientenabstiegs", "(", "oder", "des", "stochastischen", "Gradientenabstiegs", ")", "angepasst", "werden", ",", "bei", "denen", "statt", "eines", "Schritts", "in", "Richtung", "des", "Funktionsgradienten", "ein", "Schritt", "in", "Richtung", "eines", "aus", "dem", "Teilgradienten", "der", "Funktion", "ausgew\u00e4hlten", "Vektors", "gemacht", "wird", "."], "sentence-detokenized": "So k\u00f6nnen herk\u00f6mmliche Methoden des Gradientenabstiegs (oder des stochastischen Gradientenabstiegs) angepasst werden, bei denen statt eines Schritts in Richtung des Funktionsgradienten ein Schritt in Richtung eines aus dem Teilgradienten der Funktion ausgew\u00e4hlten Vektors gemacht wird.", "token2charspan": [[0, 2], [3, 9], [10, 22], [23, 31], [32, 35], [36, 54], [55, 56], [56, 60], [61, 64], [65, 79], [80, 98], [98, 99], [100, 109], [110, 116], [116, 117], [118, 121], [122, 127], [128, 133], [134, 139], [140, 148], [149, 151], [152, 160], [161, 164], [165, 184], [185, 188], [189, 196], [197, 199], [200, 208], [209, 214], [215, 218], [219, 222], [223, 237], [238, 241], [242, 250], [251, 263], [264, 271], [272, 279], [280, 284], [284, 285]]}
{"doc_key": "ai-test-380", "ner": [[10, 12, "metrics"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Wenn", "man", "davon", "ausgeht", ",", "dass", "die", "Verzerrung", "durch", "den", "mittleren", "quadratischen", "Fehler", "gemessen", "wird", ",", "ist", "die", "Verzerrung", "D", "gegeben", "durch", ":"], "sentence-detokenized": "Wenn man davon ausgeht, dass die Verzerrung durch den mittleren quadratischen Fehler gemessen wird, ist die Verzerrung D gegeben durch:", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 22], [22, 23], [24, 28], [29, 32], [33, 43], [44, 49], [50, 53], [54, 63], [64, 77], [78, 84], [85, 93], [94, 98], [98, 99], [100, 103], [104, 107], [108, 118], [119, 120], [121, 128], [129, 134], [134, 135]]}
{"doc_key": "ai-test-381", "ner": [[0, 0, "algorithm"], [11, 12, "field"], [19, 19, "task"], [21, 21, "task"], [23, 23, "task"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 11, 12, "part-of", "", false, false], [19, 19, 0, 0, "part-of", "", false, false], [21, 21, 0, 0, "part-of", "", false, false], [23, 23, 0, 0, "part-of", "", false, false], [28, 29, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["MLPs", "waren", "in", "den", "1980er", "Jahren", "eine", "beliebte", "L\u00f6sung", "f\u00fcr", "das", "maschinelle", "Lernen", ",", "die", "in", "verschiedenen", "Bereichen", "wie", "Spracherkennung", ",", "Bilderkennung", "und", "maschineller", "\u00dcbersetzungssoftware", "Anwendung", "fand", ",", "Neuronale", "Netze", "."], "sentence-detokenized": "MLPs waren in den 1980er Jahren eine beliebte L\u00f6sung f\u00fcr das maschinelle Lernen, die in verschiedenen Bereichen wie Spracherkennung, Bilderkennung und maschineller \u00dcbersetzungssoftware Anwendung fand, Neuronale Netze.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 17], [18, 24], [25, 31], [32, 36], [37, 45], [46, 52], [53, 56], [57, 60], [61, 72], [73, 79], [79, 80], [81, 84], [85, 87], [88, 101], [102, 111], [112, 115], [116, 131], [131, 132], [133, 146], [147, 150], [151, 163], [164, 184], [185, 194], [195, 199], [199, 200], [201, 210], [211, 216], [216, 217]]}
{"doc_key": "ai-test-382", "ner": [[0, 0, "researcher"], [1, 1, "misc"], [5, 7, "university"], [12, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 7, "physical", "", false, false], [0, 0, 5, 7, "role", "", false, false], [1, 1, 0, 0, "origin", "", false, false], [12, 14, 0, 0, "role", "supervised", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Allen", "promovierte", "1979", "an", "der", "Universit\u00e4t", "von", "Toronto", "unter", "der", "Leitung", "von", "C.", "Raymond", "Perrault", ","], "sentence-detokenized": "Allen promovierte 1979 an der Universit\u00e4t von Toronto unter der Leitung von C. Raymond Perrault,", "token2charspan": [[0, 5], [6, 17], [18, 22], [23, 25], [26, 29], [30, 41], [42, 45], [46, 53], [54, 59], [60, 63], [64, 71], [72, 75], [76, 78], [79, 86], [87, 95], [95, 96]]}
{"doc_key": "ai-test-383", "ner": [[0, 0, "product"], [5, 5, "field"], [7, 7, "product"], [9, 9, "product"], [11, 11, "product"], [20, 20, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6], "relations": [[0, 0, 5, 5, "related-to", "supports", false, false], [7, 7, 5, 5, "type-of", "", true, false], [9, 9, 5, 5, "type-of", "", true, false], [11, 11, 5, 5, "type-of", "", true, false], [20, 20, 5, 5, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5], "sentence": ["OpenCV", "unterst\u00fctzt", "einige", "Modelle", "aus", "Deep-Learning-Frameworks", "wie", "TensorFlow", ",", "Torch", ",", "PyTorch", "(", "nach", "Konvertierung", "in", "ein", "ONNX-Modell", ")", "und", "Caffe", "gem\u00e4\u00df", "einer", "definierten", "Liste", "unterst\u00fctzter", "Schichten", "."], "sentence-detokenized": "OpenCV unterst\u00fctzt einige Modelle aus Deep-Learning-Frameworks wie TensorFlow, Torch, PyTorch (nach Konvertierung in ein ONNX-Modell) und Caffe gem\u00e4\u00df einer definierten Liste unterst\u00fctzter Schichten.", "token2charspan": [[0, 6], [7, 18], [19, 25], [26, 33], [34, 37], [38, 62], [63, 66], [67, 77], [77, 78], [79, 84], [84, 85], [86, 93], [94, 95], [95, 99], [100, 113], [114, 116], [117, 120], [121, 132], [132, 133], [134, 137], [138, 143], [144, 149], [150, 155], [156, 167], [168, 173], [174, 187], [188, 197], [197, 198]]}
{"doc_key": "ai-test-384", "ner": [[2, 2, "researcher"], [5, 8, "organisation"], [10, 10, "organisation"], [17, 21, "organisation"], [24, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 5, 8, "role", "", false, false], [2, 2, 17, 21, "role", "", false, false], [2, 2, 24, 24, "related-to", "lectures_in", false, false], [10, 10, 5, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Zuvor", "war", "Christensen", "Gr\u00fcndungsvorsitzender", "des", "European", "Robotics", "Research", "Network", "(", "EURON", ")", "und", "ein", "Distinguished", "Lecturer", "der", "IEEE", "Robotics", "and", "Automation", "Society", "im", "Bereich", "Robotik", "."], "sentence-detokenized": "Zuvor war Christensen Gr\u00fcndungsvorsitzender des European Robotics Research Network (EURON) und ein Distinguished Lecturer der IEEE Robotics and Automation Society im Bereich Robotik.", "token2charspan": [[0, 5], [6, 9], [10, 21], [22, 43], [44, 47], [48, 56], [57, 65], [66, 74], [75, 82], [83, 84], [84, 89], [89, 90], [91, 94], [95, 98], [99, 112], [113, 121], [122, 125], [126, 130], [131, 139], [140, 143], [144, 154], [155, 162], [163, 165], [166, 173], [174, 181], [181, 182]]}
{"doc_key": "ai-test-385", "ner": [[6, 6, "field"], [9, 11, "university"], [13, 13, "location"], [15, 17, "country"], [20, 20, "misc"], [23, 23, "field"], [25, 27, "organisation"], [29, 29, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[9, 11, 13, 13, "physical", "", false, false], [13, 13, 15, 17, "physical", "", false, false], [20, 20, 23, 23, "topic", "", false, false], [25, 27, 29, 29, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Er", "erwarb", "1958", "einen", "Master-Abschluss", "in", "Mathematik", "an", "der", "Staatlichen", "Universit\u00e4t", "Samarkand", ",", "Samarkand", ",", "Usbekische", "Sozialistische", "Sowjetrepublik", ",", "und", "promovierte", "1964", "in", "Statistik", "am", "Institut", "f\u00fcr", "Kontrollwissenschaften", "in", "Moskau", "."], "sentence-detokenized": "Er erwarb 1958 einen Master-Abschluss in Mathematik an der Staatlichen Universit\u00e4t Samarkand, Samarkand, Usbekische Sozialistische Sowjetrepublik, und promovierte 1964 in Statistik am Institut f\u00fcr Kontrollwissenschaften in Moskau.", "token2charspan": [[0, 2], [3, 9], [10, 14], [15, 20], [21, 37], [38, 40], [41, 51], [52, 54], [55, 58], [59, 70], [71, 82], [83, 92], [92, 93], [94, 103], [103, 104], [105, 115], [116, 130], [131, 145], [145, 146], [147, 150], [151, 162], [163, 167], [168, 170], [171, 180], [181, 183], [184, 192], [193, 196], [197, 219], [220, 222], [223, 229], [229, 230]]}
{"doc_key": "ai-test-386", "ner": [[3, 3, "organisation"], [10, 11, "product"], [30, 31, "field"], [33, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 30, 31, "usage", "", false, false], [3, 3, 33, 35, "usage", "", false, false], [10, 11, 3, 3, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Die", "Arbeit", "bei", "Cycorp", "besteht", "jedoch", "zunehmend", "darin", ",", "das", "Cyc-System", "in", "die", "Lage", "zu", "versetzen", ",", "mit", "den", "Endnutzern", "in", "nat\u00fcrlicher", "Sprache", "zu", "kommunizieren", "und", "den", "laufenden", "Wissensbildungsprozess", "durch", "maschinelles", "Lernen", "und", "nat\u00fcrliches", "Sprachverst\u00e4ndnis", "zu", "unterst\u00fctzen", "."], "sentence-detokenized": "Die Arbeit bei Cycorp besteht jedoch zunehmend darin, das Cyc-System in die Lage zu versetzen, mit den Endnutzern in nat\u00fcrlicher Sprache zu kommunizieren und den laufenden Wissensbildungsprozess durch maschinelles Lernen und nat\u00fcrliches Sprachverst\u00e4ndnis zu unterst\u00fctzen.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 21], [22, 29], [30, 36], [37, 46], [47, 52], [52, 53], [54, 57], [58, 68], [69, 71], [72, 75], [76, 80], [81, 83], [84, 93], [93, 94], [95, 98], [99, 102], [103, 113], [114, 116], [117, 128], [129, 136], [137, 139], [140, 153], [154, 157], [158, 161], [162, 171], [172, 194], [195, 200], [201, 213], [214, 220], [221, 224], [225, 236], [237, 254], [255, 257], [258, 270], [270, 271]]}
{"doc_key": "ai-test-387", "ner": [[55, 55, "metrics"], [57, 57, "metrics"], [59, 59, "metrics"], [61, 62, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Wenn", "zum", "Beispiel", "der", "am", "besten", "geeignete", "Klassifikator", "f\u00fcr", "ein", "Problem", "gesucht", "wird", ",", "wird", "der", "Trainingsdatensatz", "verwendet", ",", "um", "die", "Kandidatenalgorithmen", "zu", "trainieren", ",", "der", "Validierungsdatensatz", "wird", "verwendet", ",", "um", "ihre", "Leistungen", "zu", "vergleichen", "und", "zu", "entscheiden", ",", "welcher", "zu", "w\u00e4hlen", "ist", ",", "und", "schlie\u00dflich", "wird", "der", "Testdatensatz", "verwendet", ",", "um", "die", "Leistungsmerkmale", "wie", "Genauigkeit", ",", "Empfindlichkeit", ",", "Spezifit\u00e4t", ",", "F-Ma\u00df", "usw.", "zu", "erhalten", "."], "sentence-detokenized": "Wenn zum Beispiel der am besten geeignete Klassifikator f\u00fcr ein Problem gesucht wird, wird der Trainingsdatensatz verwendet, um die Kandidatenalgorithmen zu trainieren, der Validierungsdatensatz wird verwendet, um ihre Leistungen zu vergleichen und zu entscheiden, welcher zu w\u00e4hlen ist, und schlie\u00dflich wird der Testdatensatz verwendet, um die Leistungsmerkmale wie Genauigkeit, Empfindlichkeit, Spezifit\u00e4t, F-Ma\u00df usw. zu erhalten.", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 21], [22, 24], [25, 31], [32, 41], [42, 55], [56, 59], [60, 63], [64, 71], [72, 79], [80, 84], [84, 85], [86, 90], [91, 94], [95, 113], [114, 123], [123, 124], [125, 127], [128, 131], [132, 153], [154, 156], [157, 167], [167, 168], [169, 172], [173, 194], [195, 199], [200, 209], [209, 210], [211, 213], [214, 218], [219, 229], [230, 232], [233, 244], [245, 248], [249, 251], [252, 263], [263, 264], [265, 272], [273, 275], [276, 282], [283, 286], [286, 287], [288, 291], [292, 303], [304, 308], [309, 312], [313, 326], [327, 336], [336, 337], [338, 340], [341, 344], [345, 362], [363, 366], [367, 378], [378, 379], [380, 395], [395, 396], [397, 407], [407, 408], [409, 414], [415, 419], [420, 422], [423, 431], [431, 432]]}
{"doc_key": "ai-test-388", "ner": [[1, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Der", "mittlere", "quadratische", "Fehler", "betr\u00e4gt", "0,15."], "sentence-detokenized": "Der mittlere quadratische Fehler betr\u00e4gt 0,15.", "token2charspan": [[0, 3], [4, 12], [13, 25], [26, 32], [33, 40], [41, 46]]}
{"doc_key": "ai-test-389", "ner": [[5, 5, "misc"], [3, 3, "organisation"], [12, 12, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 5, 5, "role", "", false, false], [12, 12, 5, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["1979", "wurde", "vom", "IEEE", "ein", "Micromouse-Wettbewerb", "veranstaltet", ",", "der", "in", "der", "Zeitschrift", "Spectrum", "ver\u00f6ffentlicht", "wurde", "."], "sentence-detokenized": "1979 wurde vom IEEE ein Micromouse-Wettbewerb veranstaltet, der in der Zeitschrift Spectrum ver\u00f6ffentlicht wurde.", "token2charspan": [[0, 4], [5, 10], [11, 14], [15, 19], [20, 23], [24, 45], [46, 58], [58, 59], [60, 63], [64, 66], [67, 70], [71, 82], [83, 91], [92, 106], [107, 112], [112, 113]]}
{"doc_key": "ai-test-390", "ner": [[1, 1, "algorithm"], [7, 8, "task"], [11, 11, "task"], [14, 16, "task"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Der", "Gabor-Raum", "ist", "bei", "Bildverarbeitungsanwendungen", "wie", "der", "optischen", "Zeichenerkennung", ",", "der", "Iriserkennung", "und", "der", "Erkennung", "von", "Fingerabdr\u00fccken", "sehr", "n\u00fctzlich", "."], "sentence-detokenized": "Der Gabor-Raum ist bei Bildverarbeitungsanwendungen wie der optischen Zeichenerkennung, der Iriserkennung und der Erkennung von Fingerabdr\u00fccken sehr n\u00fctzlich.", "token2charspan": [[0, 3], [4, 14], [15, 18], [19, 22], [23, 51], [52, 55], [56, 59], [60, 69], [70, 86], [86, 87], [88, 91], [92, 105], [106, 109], [110, 113], [114, 123], [124, 127], [128, 143], [144, 148], [149, 157], [157, 158]]}
{"doc_key": "ai-test-391", "ner": [[4, 4, "programlang"], [6, 6, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["oder", "\u00fcber", "High-Level-Schnittstellen", "zu", "Java", "und", "Tcl", "."], "sentence-detokenized": "oder \u00fcber High-Level-Schnittstellen zu Java und Tcl.", "token2charspan": [[0, 4], [5, 9], [10, 35], [36, 38], [39, 43], [44, 47], [48, 51], [51, 52]]}
{"doc_key": "ai-test-392", "ner": [[14, 14, "field"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "der", "neueren", "Forschung", "haben", "kernelbasierte", "Methoden", "wie", "Support-Vektor-Maschinen", "eine", "\u00fcberlegene", "Leistung", "bei", "der", "\u00dcberwachung", "gezeigt", "."], "sentence-detokenized": "In der neueren Forschung haben kernelbasierte Methoden wie Support-Vektor-Maschinen eine \u00fcberlegene Leistung bei der \u00dcberwachung gezeigt.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 24], [25, 30], [31, 45], [46, 54], [55, 58], [59, 83], [84, 88], [89, 99], [100, 108], [109, 112], [113, 116], [117, 128], [129, 136], [136, 137]]}
{"doc_key": "ai-test-393", "ner": [[14, 14, "misc"], [21, 21, "researcher"], [23, 23, "researcher"], [30, 30, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 21, 30, 30, "usage", "", false, false], [23, 23, 30, 30, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Zur", "Veranschaulichung", "der", "Grundprinzipien", "des", "Bagging", "wird", "im", "Folgenden", "eine", "Analyse", "der", "Beziehung", "zwischen", "Ozon", "und", "Temperatur", "dargestellt", "(", "Daten", "von", "Rousseeuw", "und", "Leroy", "(", "1986", ")", ",", "Analyse", "in", "R", ")", "."], "sentence-detokenized": "Zur Veranschaulichung der Grundprinzipien des Bagging wird im Folgenden eine Analyse der Beziehung zwischen Ozon und Temperatur dargestellt (Daten von Rousseeuw und Leroy (1986), Analyse in R).", "token2charspan": [[0, 3], [4, 21], [22, 25], [26, 41], [42, 45], [46, 53], [54, 58], [59, 61], [62, 71], [72, 76], [77, 84], [85, 88], [89, 98], [99, 107], [108, 112], [113, 116], [117, 127], [128, 139], [140, 141], [141, 146], [147, 150], [151, 160], [161, 164], [165, 170], [171, 172], [172, 176], [176, 177], [177, 178], [179, 186], [187, 189], [190, 191], [191, 192], [192, 193]]}
{"doc_key": "ai-test-394", "ner": [[0, 1, "organisation"], [18, 18, "product"], [20, 21, "product"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[18, 18, 0, 1, "artifact", "", false, false], [20, 21, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["Denso", "Wave", "ist", "eine", "Tochtergesellschaft", ",", "die", "Produkte", "zur", "automatischen", "Identifizierung", "(", "Strichcodeleser", "und", "verwandte", "Produkte", ")", ",", "Industrieroboter", "und", "speicherprogrammierbare", "Steuerungen", "herstellt", "."], "sentence-detokenized": "Denso Wave ist eine Tochtergesellschaft, die Produkte zur automatischen Identifizierung (Strichcodeleser und verwandte Produkte), Industrieroboter und speicherprogrammierbare Steuerungen herstellt.", "token2charspan": [[0, 5], [6, 10], [11, 14], [15, 19], [20, 39], [39, 40], [41, 44], [45, 53], [54, 57], [58, 71], [72, 87], [88, 89], [89, 104], [105, 108], [109, 118], [119, 127], [127, 128], [128, 129], [130, 146], [147, 150], [151, 174], [175, 186], [187, 196], [196, 197]]}
{"doc_key": "ai-test-395", "ner": [[2, 3, "metrics"], [6, 6, "metrics"], [17, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 3, 17, 17, "compare", "", false, false], [6, 6, 2, 3, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["W\u00e4hrend", "die", "zweisprachige", "Evaluierungsstudie", "lediglich", "die", "Pr\u00e4zision", "der", "n-Gramme", "berechnet", "und", "diese", "gleich", "gewichtet", ",", "berechnet", "das", "NIST", "auch", ",", "wie", "informativ", "ein", "bestimmtes", "n-Gramm", "ist", "."], "sentence-detokenized": "W\u00e4hrend die zweisprachige Evaluierungsstudie lediglich die Pr\u00e4zision der n-Gramme berechnet und diese gleich gewichtet, berechnet das NIST auch, wie informativ ein bestimmtes n-Gramm ist.", "token2charspan": [[0, 7], [8, 11], [12, 25], [26, 44], [45, 54], [55, 58], [59, 68], [69, 72], [73, 81], [82, 91], [92, 95], [96, 101], [102, 108], [109, 118], [118, 119], [120, 129], [130, 133], [134, 138], [139, 143], [143, 144], [145, 148], [149, 159], [160, 163], [164, 174], [175, 182], [183, 186], [186, 187]]}
{"doc_key": "ai-test-396", "ner": [[12, 12, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sie", "werden", "insbesondere", "bei", "der", "Berechnung", "der", "Wahrscheinlichkeit", "eines", "Baums", "(", "in", "Bayes'schen", "und", "Maximum-Likelihood-Ans\u00e4tzen", "zur", "Baumsch\u00e4tzung", ")", "und", "zur", "Sch\u00e4tzung", "des", "evolution\u00e4ren", "Abstands", "zwischen", "Sequenzen", "anhand", "der", "beobachteten", "Unterschiede", "zwischen", "den", "Sequenzen", "verwendet", "."], "sentence-detokenized": "Sie werden insbesondere bei der Berechnung der Wahrscheinlichkeit eines Baums (in Bayes'schen und Maximum-Likelihood-Ans\u00e4tzen zur Baumsch\u00e4tzung) und zur Sch\u00e4tzung des evolution\u00e4ren Abstands zwischen Sequenzen anhand der beobachteten Unterschiede zwischen den Sequenzen verwendet.", "token2charspan": [[0, 3], [4, 10], [11, 23], [24, 27], [28, 31], [32, 42], [43, 46], [47, 65], [66, 71], [72, 77], [78, 79], [79, 81], [82, 93], [94, 97], [98, 125], [126, 129], [130, 143], [143, 144], [145, 148], [149, 152], [153, 162], [163, 166], [167, 180], [181, 189], [190, 198], [199, 208], [209, 215], [216, 219], [220, 232], [233, 245], [246, 254], [255, 258], [259, 268], [269, 278], [278, 279]]}
{"doc_key": "ai-test-397", "ner": [[1, 3, "conference"], [20, 21, "misc"], [23, 23, "misc"], [42, 42, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 20, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Die", "Audio", "Engineering", "Society", "empfiehlt", "f\u00fcr", "die", "meisten", "Anwendungen", "eine", "Abtastrate", "von", "48", "kHz", ",", "erkennt", "jedoch", "44,1", "kHz", "f\u00fcr", "Compact", "Discs", "(", "CD", ")", "und", "andere", "Verbraucheranwendungen", ",", "32", "kHz", "f\u00fcr", "\u00fcbertragungstechnische", "Anwendungen", "und", "96", "kHz", "f\u00fcr", "h\u00f6here", "Bandbreiten", "oder", "entspannte", "Anti-Aliasing-Filter", "an", "."], "sentence-detokenized": "Die Audio Engineering Society empfiehlt f\u00fcr die meisten Anwendungen eine Abtastrate von 48 kHz, erkennt jedoch 44,1 kHz f\u00fcr Compact Discs (CD) und andere Verbraucheranwendungen, 32 kHz f\u00fcr \u00fcbertragungstechnische Anwendungen und 96 kHz f\u00fcr h\u00f6here Bandbreiten oder entspannte Anti-Aliasing-Filter an.", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 29], [30, 39], [40, 43], [44, 47], [48, 55], [56, 67], [68, 72], [73, 83], [84, 87], [88, 90], [91, 94], [94, 95], [96, 103], [104, 110], [111, 115], [116, 119], [120, 123], [124, 131], [132, 137], [138, 139], [139, 141], [141, 142], [143, 146], [147, 153], [154, 176], [176, 177], [178, 180], [181, 184], [185, 188], [189, 211], [212, 223], [224, 227], [228, 230], [231, 234], [235, 238], [239, 245], [246, 257], [258, 262], [263, 273], [274, 294], [295, 297], [297, 298]]}
{"doc_key": "ai-test-398", "ner": [[10, 10, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ressourcen", "f\u00fcr", "die", "Affektivit\u00e4t", "von", "W\u00f6rtern", "und", "Begriffen", "wurden", "f\u00fcr", "WordNet", "{", "{", "cite", "journal"], "sentence-detokenized": "Ressourcen f\u00fcr die Affektivit\u00e4t von W\u00f6rtern und Begriffen wurden f\u00fcr WordNet {{cite journal", "token2charspan": [[0, 10], [11, 14], [15, 18], [19, 31], [32, 35], [36, 43], [44, 47], [48, 57], [58, 64], [65, 68], [69, 76], [77, 78], [78, 79], [79, 83], [84, 91]]}
{"doc_key": "ai-test-399", "ner": [[1, 2, "misc"], [16, 17, "person"], [22, 24, "person"], [30, 32, "person"], [43, 44, "organisation"], [62, 62, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[22, 24, 30, 32, "role", "acts_in", false, false], [43, 44, 30, 32, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "rot-gr\u00fcner", "Anaglyphe", "wurden", "dem", "Publikum", "drei", "Testrollen", "pr\u00e4sentiert", ",", "darunter", "l\u00e4ndliche", "Szenen", ",", "Testaufnahmen", "von", "Marie", "Doro", ",", "ein", "Ausschnitt", "von", "John", "B.", "Mason", ",", "der", "einige", "Passagen", "aus", "Jim", "the", "Penman", "spielt", "(", "ein", "Film", ",", "der", "im", "selben", "Jahr", "von", "Famous", "Players-Lasky", "ver\u00f6ffentlicht", "wurde", ",", "aber", "nicht", "in", "3D", ")", ",", "orientalische", "T\u00e4nzerinnen", "und", "eine", "Rolle", "mit", "Aufnahmen", "der", "Niagaraf\u00e4lle", "."], "sentence-detokenized": "In rot-gr\u00fcner Anaglyphe wurden dem Publikum drei Testrollen pr\u00e4sentiert, darunter l\u00e4ndliche Szenen, Testaufnahmen von Marie Doro, ein Ausschnitt von John B. Mason, der einige Passagen aus Jim the Penman spielt (ein Film, der im selben Jahr von Famous Players-Lasky ver\u00f6ffentlicht wurde, aber nicht in 3D), orientalische T\u00e4nzerinnen und eine Rolle mit Aufnahmen der Niagaraf\u00e4lle.", "token2charspan": [[0, 2], [3, 13], [14, 23], [24, 30], [31, 34], [35, 43], [44, 48], [49, 59], [60, 71], [71, 72], [73, 81], [82, 91], [92, 98], [98, 99], [100, 113], [114, 117], [118, 123], [124, 128], [128, 129], [130, 133], [134, 144], [145, 148], [149, 153], [154, 156], [157, 162], [162, 163], [164, 167], [168, 174], [175, 183], [184, 187], [188, 191], [192, 195], [196, 202], [203, 209], [210, 211], [211, 214], [215, 219], [219, 220], [221, 224], [225, 227], [228, 234], [235, 239], [240, 243], [244, 250], [251, 264], [265, 279], [280, 285], [285, 286], [287, 291], [292, 297], [298, 300], [301, 303], [303, 304], [304, 305], [306, 319], [320, 331], [332, 335], [336, 340], [341, 346], [347, 350], [351, 360], [361, 364], [365, 377], [377, 378]]}
{"doc_key": "ai-test-400", "ner": [[8, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Dies", "ist", "eine", "besondere", "Art", "der", "Implementierung", "der", "Maximum-Likelihood-Sch\u00e4tzung", "f\u00fcr", "dieses", "Problem", "."], "sentence-detokenized": "Dies ist eine besondere Art der Implementierung der Maximum-Likelihood-Sch\u00e4tzung f\u00fcr dieses Problem.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 23], [24, 27], [28, 31], [32, 47], [48, 51], [52, 80], [81, 84], [85, 91], [92, 99], [99, 100]]}
{"doc_key": "ai-test-401", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Crawler-freundliche", "Webserver", ",", "und", "es", "integriert", "die", "Funktionen", "von", "Sitemaps", "und", "RSS-Feeds", "in", "einen", "dezentralisierten", "Mechanismus", "f\u00fcr", "Computerbiologen", "und", "Bioinformatiker", ",", "um", "Metadaten", "\u00fcber", "biomedizinische", "Ressourcen", "offen", "zu", "verbreiten", "und", "abzurufen", "."], "sentence-detokenized": "Crawler-freundliche Webserver, und es integriert die Funktionen von Sitemaps und RSS-Feeds in einen dezentralisierten Mechanismus f\u00fcr Computerbiologen und Bioinformatiker, um Metadaten \u00fcber biomedizinische Ressourcen offen zu verbreiten und abzurufen.", "token2charspan": [[0, 19], [20, 29], [29, 30], [31, 34], [35, 37], [38, 48], [49, 52], [53, 63], [64, 67], [68, 76], [77, 80], [81, 90], [91, 93], [94, 99], [100, 117], [118, 129], [130, 133], [134, 150], [151, 154], [155, 170], [170, 171], [172, 174], [175, 184], [185, 189], [190, 205], [206, 216], [217, 222], [223, 225], [226, 236], [237, 240], [241, 250], [250, 251]]}
{"doc_key": "ai-test-402", "ner": [[4, 12, "misc"], [15, 21, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sie", "wird", "von", "der", "Norm", "Z39.50", "des", "American", "National", "Standards", "Institute", "/", "NISO", "und", "der", "Norm", "23950", "der", "Internationalen", "Organisation", "f\u00fcr", "Normung", "abgedeckt", "."], "sentence-detokenized": "Sie wird von der Norm Z39.50 des American National Standards Institute / NISO und der Norm 23950 der Internationalen Organisation f\u00fcr Normung abgedeckt.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 16], [17, 21], [22, 28], [29, 32], [33, 41], [42, 50], [51, 60], [61, 70], [71, 72], [73, 77], [78, 81], [82, 85], [86, 90], [91, 96], [97, 100], [101, 116], [117, 129], [130, 133], [134, 141], [142, 151], [151, 152]]}
{"doc_key": "ai-test-403", "ner": [[15, 15, "misc"], [24, 24, "metrics"], [28, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Der", "Kodierer", "und", "der", "Dekodierer", "werden", "darauf", "trainiert", ",", "eine", "Phrase", "zu", "nehmen", "und", "die", "One-Hot-Verteilung", "einer", "entsprechenden", "Paraphrase", "zu", "reproduzieren", ",", "indem", "die", "Perplexit\u00e4t", "mittels", "eines", "einfachen", "stochastischen", "Gradientenabstiegs", "minimiert", "wird", "."], "sentence-detokenized": "Der Kodierer und der Dekodierer werden darauf trainiert, eine Phrase zu nehmen und die One-Hot-Verteilung einer entsprechenden Paraphrase zu reproduzieren, indem die Perplexit\u00e4t mittels eines einfachen stochastischen Gradientenabstiegs minimiert wird.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 20], [21, 31], [32, 38], [39, 45], [46, 55], [55, 56], [57, 61], [62, 68], [69, 71], [72, 78], [79, 82], [83, 86], [87, 105], [106, 111], [112, 126], [127, 137], [138, 140], [141, 154], [154, 155], [156, 161], [162, 165], [166, 177], [178, 185], [186, 191], [192, 201], [202, 216], [217, 235], [236, 245], [246, 250], [250, 251]]}
{"doc_key": "ai-test-404", "ner": [[7, 8, "task"], [11, 16, "task"], [24, 26, "task"], [29, 34, "task"], [37, 42, "task"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Andere", "typische", "Anwendungen", "von", "Mustererkennungstechniken", "sind", "die", "automatische", "Spracherkennung", ",", "die", "Klassifizierung", "von", "Text", "in", "verschiedene", "Kategorien", "(", "z.", "B.", "Spam/Nicht-Spam-E-Mails", ")", ",", "die", "Handschrifterkennung", "auf", "Postumschl\u00e4gen", ",", "die", "automatische", "Erkennung", "von", "Bildern", "menschlicher", "Gesichter", "oder", "die", "Extraktion", "von", "Handschriftbildern", "aus", "medizinischen", "Formularen", "."], "sentence-detokenized": "Andere typische Anwendungen von Mustererkennungstechniken sind die automatische Spracherkennung, die Klassifizierung von Text in verschiedene Kategorien (z. B. Spam/Nicht-Spam-E-Mails), die Handschrifterkennung auf Postumschl\u00e4gen, die automatische Erkennung von Bildern menschlicher Gesichter oder die Extraktion von Handschriftbildern aus medizinischen Formularen.", "token2charspan": [[0, 6], [7, 15], [16, 27], [28, 31], [32, 57], [58, 62], [63, 66], [67, 79], [80, 95], [95, 96], [97, 100], [101, 116], [117, 120], [121, 125], [126, 128], [129, 141], [142, 152], [153, 154], [154, 156], [157, 159], [160, 183], [183, 184], [184, 185], [186, 189], [190, 210], [211, 214], [215, 229], [229, 230], [231, 234], [235, 247], [248, 257], [258, 261], [262, 269], [270, 282], [283, 292], [293, 297], [298, 301], [302, 312], [313, 316], [317, 335], [336, 339], [340, 353], [354, 364], [364, 365]]}
{"doc_key": "ai-test-405", "ner": [[0, 2, "algorithm"], [12, 13, "field"], [15, 15, "task"], [17, 18, "task"], [20, 22, "task"], [24, 26, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 13, 0, 2, "usage", "", false, false], [15, 15, 0, 2, "usage", "", false, false], [17, 18, 0, 2, "usage", "", false, false], [20, 22, 0, 2, "usage", "", false, false], [24, 26, 0, 2, "usage", "", false, false], [28, 29, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["K\u00fcnstliche", "neuronale", "Netze", "wurden", "f\u00fcr", "eine", "Vielzahl", "von", "Aufgaben", "eingesetzt", ",", "darunter", "Computer", "Vision", ",", "Spracherkennung", ",", "maschinelle", "\u00dcbersetzung", ",", "Filterung", "sozialer", "Netzwerke", ",", "Brett-", "und", "Videospiele", "und", "medizinische", "Diagnose", "."], "sentence-detokenized": "K\u00fcnstliche neuronale Netze wurden f\u00fcr eine Vielzahl von Aufgaben eingesetzt, darunter Computer Vision, Spracherkennung, maschinelle \u00dcbersetzung, Filterung sozialer Netzwerke, Brett- und Videospiele und medizinische Diagnose.", "token2charspan": [[0, 10], [11, 20], [21, 26], [27, 33], [34, 37], [38, 42], [43, 51], [52, 55], [56, 64], [65, 75], [75, 76], [77, 85], [86, 94], [95, 101], [101, 102], [103, 118], [118, 119], [120, 131], [132, 143], [143, 144], [145, 154], [155, 163], [164, 173], [173, 174], [175, 181], [182, 185], [186, 197], [198, 201], [202, 214], [215, 223], [223, 224]]}
{"doc_key": "ai-test-406", "ner": [[2, 3, "organisation"], [4, 4, "product"], [17, 17, "organisation"], [18, 19, "product"], [21, 21, "product"], [23, 25, "product"], [27, 27, "product"], [29, 29, "programlang"], [34, 35, "field"], [43, 43, "algorithm"], [45, 45, "algorithm"], [47, 47, "algorithm"], [51, 51, "product"], [64, 64, "product"], [66, 66, "product"], [68, 70, "product"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 17, 18, 19], "relations": [[4, 4, 2, 3, "origin", "", false, false], [29, 29, 34, 35, "related-to", "used_for", false, false], [43, 43, 29, 29, "part-of", "", true, false], [45, 45, 29, 29, "part-of", "", true, false], [47, 47, 29, 29, "part-of", "", true, false]], "relations_mapping_to_source": [0, 3, 4, 6, 8], "sentence": ["Beispiele", "sind", "Salford", "Systems", "CART", "(", "das", "den", "propriet\u00e4ren", "Code", "der", "urspr\u00fcnglichen", "CART-Autoren", "lizenziert", "hat", ")", ",", "IBM", "SPSS", "Modeler", ",", "RapidMiner", ",", "SAS", "Enterprise", "Miner", ",", "Matlab", ",", "R", "(", "eine", "Open-Source-Softwareumgebung", "f\u00fcr", "statistische", "Berechnungen", ",", "die", "mehrere", "CART-Implementierungen", "wie", "die", "Pakete", "rpart", ",", "party", "und", "randomForest", "enth\u00e4lt", ")", ",", "Weka", "(", "eine", "kostenlose", "und", "Open-Source-Data-Mining-Suite", ",", "die", "viele", "Entscheidungsbaum-Algorithmen", "enth\u00e4lt", ")", ",", "Orange", ",", "KNIME", ",", "Microsoft", "SQL", "Server", "Programmiersprache", ")", "."], "sentence-detokenized": "Beispiele sind Salford Systems CART (das den propriet\u00e4ren Code der urspr\u00fcnglichen CART-Autoren lizenziert hat), IBM SPSS Modeler, RapidMiner, SAS Enterprise Miner, Matlab, R (eine Open-Source-Softwareumgebung f\u00fcr statistische Berechnungen, die mehrere CART-Implementierungen wie die Pakete rpart, party und randomForest enth\u00e4lt), Weka (eine kostenlose und Open-Source-Data-Mining-Suite, die viele Entscheidungsbaum-Algorithmen enth\u00e4lt), Orange, KNIME, Microsoft SQL Server Programmiersprache).", "token2charspan": [[0, 9], [10, 14], [15, 22], [23, 30], [31, 35], [36, 37], [37, 40], [41, 44], [45, 57], [58, 62], [63, 66], [67, 81], [82, 94], [95, 105], [106, 109], [109, 110], [110, 111], [112, 115], [116, 120], [121, 128], [128, 129], [130, 140], [140, 141], [142, 145], [146, 156], [157, 162], [162, 163], [164, 170], [170, 171], [172, 173], [174, 175], [175, 179], [180, 208], [209, 212], [213, 225], [226, 238], [238, 239], [240, 243], [244, 251], [252, 274], [275, 278], [279, 282], [283, 289], [290, 295], [295, 296], [297, 302], [303, 306], [307, 319], [320, 327], [327, 328], [328, 329], [330, 334], [335, 336], [336, 340], [341, 351], [352, 355], [356, 385], [385, 386], [387, 390], [391, 396], [397, 426], [427, 434], [434, 435], [435, 436], [437, 443], [443, 444], [445, 450], [450, 451], [452, 461], [462, 465], [466, 472], [473, 491], [491, 492], [492, 493]]}
{"doc_key": "ai-test-407", "ner": [[0, 3, "algorithm"], [5, 5, "algorithm"], [11, 12, "researcher"], [15, 16, "university"], [18, 19, "researcher"], [21, 24, "organisation"], [26, 26, "organisation"], [32, 34, "researcher"], [36, 38, "researcher"], [41, 42, "organisation"], [61, 61, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 3, 11, 12, "origin", "", false, false], [0, 3, 18, 19, "origin", "", false, false], [0, 3, 32, 34, "origin", "", false, false], [0, 3, 36, 38, "origin", "", false, false], [5, 5, 0, 3, "named", "", false, false], [11, 12, 15, 16, "physical", "", false, false], [11, 12, 15, 16, "role", "", false, false], [18, 19, 21, 24, "physical", "", false, false], [18, 19, 21, 24, "role", "", false, false], [26, 26, 21, 24, "named", "", false, false], [32, 34, 41, 42, "physical", "", false, false], [32, 34, 41, 42, "role", "", false, false], [36, 38, 41, 42, "physical", "", false, false], [36, 38, 41, 42, "role", "", false, false], [61, 61, 0, 3, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Die", "lineare", "pr\u00e4diktive", "Kodierung", "(", "LPC", ")", "wurde", "erstmals", "1966", "von", "Fumitada", "Itakura", "von", "der", "Universit\u00e4t", "Nagoya", "und", "Shuzo", "Saito", "von", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "entwickelt", "und", "dann", "von", "Bishnu", "S.", "Atal", "und", "Manfred", "R.", "Schroeder", "in", "den", "Bell", "Labs", "Anfang", "bis", "Mitte", "der", "1970er", "Jahre", "weiterentwickelt", "und", "diente", "Ende", "der", "1970er", "Jahre", "als", "Grundlage", "f\u00fcr", "die", "ersten", "Sprachsynthesizer-DSP-Chips", "."], "sentence-detokenized": "Die lineare pr\u00e4diktive Kodierung (LPC) wurde erstmals 1966 von Fumitada Itakura von der Universit\u00e4t Nagoya und Shuzo Saito von Nippon Telegraph and Telephone (NTT) entwickelt und dann von Bishnu S. Atal und Manfred R. Schroeder in den Bell Labs Anfang bis Mitte der 1970er Jahre weiterentwickelt und diente Ende der 1970er Jahre als Grundlage f\u00fcr die ersten Sprachsynthesizer-DSP-Chips.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 32], [33, 34], [34, 37], [37, 38], [39, 44], [45, 53], [54, 58], [59, 62], [63, 71], [72, 79], [80, 83], [84, 87], [88, 99], [100, 106], [107, 110], [111, 116], [117, 122], [123, 126], [127, 133], [134, 143], [144, 147], [148, 157], [158, 159], [159, 162], [162, 163], [164, 174], [175, 178], [179, 183], [184, 187], [188, 194], [195, 197], [198, 202], [203, 206], [207, 214], [215, 217], [218, 227], [228, 230], [231, 234], [235, 239], [240, 244], [245, 251], [252, 255], [256, 261], [262, 265], [266, 272], [273, 278], [279, 295], [296, 299], [300, 306], [307, 311], [312, 315], [316, 322], [323, 328], [329, 332], [333, 342], [343, 346], [347, 350], [351, 357], [358, 385], [385, 386]]}
{"doc_key": "ai-test-408", "ner": [[1, 1, "metrics"], [6, 6, "metrics"], [8, 8, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 1, 1, "part-of", "", false, false], [8, 8, 1, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Ein", "F-Score", "ist", "eine", "Kombination", "aus", "Precision", "und", "Recall", ",", "die", "eine", "einzige", "Punktzahl", "ergibt", "."], "sentence-detokenized": "Ein F-Score ist eine Kombination aus Precision und Recall, die eine einzige Punktzahl ergibt.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 20], [21, 32], [33, 36], [37, 46], [47, 50], [51, 57], [57, 58], [59, 62], [63, 67], [68, 75], [76, 85], [86, 92], [92, 93]]}
{"doc_key": "ai-test-409", "ner": [[7, 10, "task"], [14, 14, "product"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Bildanalyseaufgaben", "k\u00f6nnen", "so", "einfach", "sein", "wie", "das", "Lesen", "von", "Strichcodes", "oder", "so", "anspruchsvoll", "wie", "Gesichtserkennungssysteme", "."], "sentence-detokenized": "Bildanalyseaufgaben k\u00f6nnen so einfach sein wie das Lesen von Strichcodes oder so anspruchsvoll wie Gesichtserkennungssysteme.", "token2charspan": [[0, 19], [20, 26], [27, 29], [30, 37], [38, 42], [43, 46], [47, 50], [51, 56], [57, 60], [61, 72], [73, 77], [78, 80], [81, 94], [95, 98], [99, 124], [124, 125]]}
{"doc_key": "ai-test-410", "ner": [[4, 4, "algorithm"], [24, 28, "algorithm"], [37, 38, "algorithm"], [42, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[37, 38, 24, 28, "type-of", "", false, false], [42, 42, 37, 38, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Der", "Spezialfall", "der", "linearen", "Support-Vektor-Maschinen", "kann", "durch", "dieselbe", "Art", "von", "Algorithmen", "effizienter", "gel\u00f6st", "werden", ",", "die", "auch", "zur", "Optimierung", "des", "nahen", "Verwandten", ",", "der", "logistischen", "Regression", ",", "eingesetzt", "werden", ";", "zu", "dieser", "Klasse", "von", "Algorithmen", "geh\u00f6rt", "der", "stochastische", "Gradientenabstieg", "(", "z.", "B.", "PEGASOS", ")", "."], "sentence-detokenized": "Der Spezialfall der linearen Support-Vektor-Maschinen kann durch dieselbe Art von Algorithmen effizienter gel\u00f6st werden, die auch zur Optimierung des nahen Verwandten, der logistischen Regression, eingesetzt werden; zu dieser Klasse von Algorithmen geh\u00f6rt der stochastische Gradientenabstieg (z. B. PEGASOS).", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 28], [29, 53], [54, 58], [59, 64], [65, 73], [74, 77], [78, 81], [82, 93], [94, 105], [106, 112], [113, 119], [119, 120], [121, 124], [125, 129], [130, 133], [134, 145], [146, 149], [150, 155], [156, 166], [166, 167], [168, 171], [172, 184], [185, 195], [195, 196], [197, 207], [208, 214], [214, 215], [216, 218], [219, 225], [226, 232], [233, 236], [237, 248], [249, 255], [256, 259], [260, 273], [274, 291], [292, 293], [293, 295], [296, 298], [299, 306], [306, 307], [307, 308]]}
{"doc_key": "ai-test-411", "ner": [[1, 1, "product"], [26, 26, "product"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Wenn", "Siri", "auf", "einem", "iOS-Ger\u00e4t", "gefragt", "wird", ":", "\"", "Haben", "Sie", "ein", "Haustier", "?", "\"", ",", "lautet", "eine", "der", "Antworten", ":", "\"", "Ich", "hatte", "fr\u00fcher", "einen", "AIBO", "\"", "."], "sentence-detokenized": "Wenn Siri auf einem iOS-Ger\u00e4t gefragt wird: \"Haben Sie ein Haustier?\", lautet eine der Antworten: \"Ich hatte fr\u00fcher einen AIBO\".", "token2charspan": [[0, 4], [5, 9], [10, 13], [14, 19], [20, 29], [30, 37], [38, 42], [42, 43], [44, 45], [45, 50], [51, 54], [55, 58], [59, 67], [67, 68], [68, 69], [69, 70], [71, 77], [78, 82], [83, 86], [87, 96], [96, 97], [98, 99], [99, 102], [103, 108], [109, 115], [116, 121], [122, 126], [126, 127], [127, 128]]}
{"doc_key": "ai-test-412", "ner": [[1, 3, "task"], [5, 6, "metrics"], [8, 8, "metrics"], [11, 11, "metrics"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 1, 3, "part-of", "", false, false], [8, 8, 5, 6, "named", "", false, false], [11, 11, 1, 3, "part-of", "", false, false], [13, 14, 11, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Beim", "Information", "Retrieval", "wird", "der", "positive", "Vorhersagewert", "als", "Pr\u00e4zision", "und", "die", "Empfindlichkeit", "als", "Recall", "bezeichnet", "."], "sentence-detokenized": "Beim Information Retrieval wird der positive Vorhersagewert als Pr\u00e4zision und die Empfindlichkeit als Recall bezeichnet.", "token2charspan": [[0, 4], [5, 16], [17, 26], [27, 31], [32, 35], [36, 44], [45, 59], [60, 63], [64, 73], [74, 77], [78, 81], [82, 97], [98, 101], [102, 108], [109, 119], [119, 120]]}
{"doc_key": "ai-test-413", "ner": [[8, 9, "field"], [11, 11, "task"], [13, 13, "task"], [15, 17, "task"], [31, 32, "task"], [34, 35, "task"], [37, 39, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 11, 8, 9, "part-of", "task_part_of_field", false, false], [13, 13, 8, 9, "part-of", "task_part_of_field", false, false], [15, 17, 8, 9, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Seine", "Forschung", "konzentrierte", "sich", "insbesondere", "auf", "Bereiche", "wie", "Text", "Mining", "(", "Extraktion", ",", "Kategorisierung", ",", "Erkennung", "von", "Neuheiten", ")", "und", "auf", "neue", "theoretische", "Rahmenwerke", "wie", "eine", "einheitliche", "nutzungsbasierte", "Theorie", ",", "die", "Information", "Retrieval", ",", "automatische", "Zusammenfassung", ",", "Beantwortung", "von", "Freitextfragen", "und", "verwandte", "Aufgaben", "verbindet", "."], "sentence-detokenized": "Seine Forschung konzentrierte sich insbesondere auf Bereiche wie Text Mining (Extraktion, Kategorisierung, Erkennung von Neuheiten) und auf neue theoretische Rahmenwerke wie eine einheitliche nutzungsbasierte Theorie, die Information Retrieval, automatische Zusammenfassung, Beantwortung von Freitextfragen und verwandte Aufgaben verbindet.", "token2charspan": [[0, 5], [6, 15], [16, 29], [30, 34], [35, 47], [48, 51], [52, 60], [61, 64], [65, 69], [70, 76], [77, 78], [78, 88], [88, 89], [90, 105], [105, 106], [107, 116], [117, 120], [121, 130], [130, 131], [132, 135], [136, 139], [140, 144], [145, 157], [158, 169], [170, 173], [174, 178], [179, 191], [192, 208], [209, 216], [216, 217], [218, 221], [222, 233], [234, 243], [243, 244], [245, 257], [258, 273], [273, 274], [275, 287], [288, 291], [292, 306], [307, 310], [311, 320], [321, 329], [330, 339], [339, 340]]}
{"doc_key": "ai-test-414", "ner": [[0, 0, "product"], [6, 6, "product"], [13, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 0, 0, "part-of", "", false, false], [13, 13, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Delta-Roboter", "haben", "an", "der", "Basis", "montierte", "Drehantriebe", ",", "die", "einen", "leichten", ",", "steifen", "Parallelogrammarm", "bewegen", "."], "sentence-detokenized": "Delta-Roboter haben an der Basis montierte Drehantriebe, die einen leichten, steifen Parallelogrammarm bewegen.", "token2charspan": [[0, 13], [14, 19], [20, 22], [23, 26], [27, 32], [33, 42], [43, 55], [55, 56], [57, 60], [61, 66], [67, 75], [75, 76], [77, 84], [85, 102], [103, 110], [110, 111]]}
{"doc_key": "ai-test-415", "ner": [[6, 9, "metrics"], [11, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Die", "vier", "Ergebnisse", "k\u00f6nnen", "in", "einer", "2", "\u00d7", "2", "Kontingenztabelle", "oder", "Konfusionsmatrix", "wie", "folgt", "formuliert", "werden", ":"], "sentence-detokenized": "Die vier Ergebnisse k\u00f6nnen in einer 2 \u00d7 2 Kontingenztabelle oder Konfusionsmatrix wie folgt formuliert werden:", "token2charspan": [[0, 3], [4, 8], [9, 19], [20, 26], [27, 29], [30, 35], [36, 37], [38, 39], [40, 41], [42, 59], [60, 64], [65, 81], [82, 85], [86, 91], [92, 102], [103, 109], [109, 110]]}
{"doc_key": "ai-test-416", "ner": [[4, 5, "field"], [25, 25, "task"], [31, 31, "task"], [36, 36, "task"], [38, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[25, 25, 4, 5, "part-of", "task_part_of_field", false, false], [31, 31, 4, 5, "part-of", "task_part_of_field", false, false], [36, 36, 4, 5, "part-of", "task_part_of_field", false, false], [38, 40, 4, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Die", "eigentliche", "Aufgabe", "des", "Data", "Mining", "ist", "die", "halbautomatische", "oder", "automatische", "Analyse", "gro\u00dfer", "Datenmengen", ",", "um", "unbekannte", ",", "interessante", "Muster", "wie", "Gruppen", "von", "Datens\u00e4tzen", "(", "Clusteranalyse", ")", ",", "ungew\u00f6hnliche", "Datens\u00e4tze", "(", "Anomalieerkennung", ")", "und", "Abh\u00e4ngigkeiten", "(", "Assoziationsregel-Mining", ",", "Sequential", "Pattern", "Mining", ")", "zu", "extrahieren", "."], "sentence-detokenized": "Die eigentliche Aufgabe des Data Mining ist die halbautomatische oder automatische Analyse gro\u00dfer Datenmengen, um unbekannte, interessante Muster wie Gruppen von Datens\u00e4tzen (Clusteranalyse), ungew\u00f6hnliche Datens\u00e4tze (Anomalieerkennung) und Abh\u00e4ngigkeiten (Assoziationsregel-Mining, Sequential Pattern Mining) zu extrahieren.", "token2charspan": [[0, 3], [4, 15], [16, 23], [24, 27], [28, 32], [33, 39], [40, 43], [44, 47], [48, 64], [65, 69], [70, 82], [83, 90], [91, 97], [98, 109], [109, 110], [111, 113], [114, 124], [124, 125], [126, 138], [139, 145], [146, 149], [150, 157], [158, 161], [162, 173], [174, 175], [175, 189], [189, 190], [190, 191], [192, 205], [206, 216], [217, 218], [218, 235], [235, 236], [237, 240], [241, 255], [256, 257], [257, 281], [281, 282], [283, 293], [294, 301], [302, 308], [308, 309], [310, 312], [313, 324], [324, 325]]}
{"doc_key": "ai-test-417", "ner": [[2, 4, "product"], [6, 7, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 4, 6, 7, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["F\u00fcr", "ein", "Empfehlungssystem", "hat", "sich", "die", "Stimmungsanalyse", "als", "wertvolle", "Technik", "erwiesen", "."], "sentence-detokenized": "F\u00fcr ein Empfehlungssystem hat sich die Stimmungsanalyse als wertvolle Technik erwiesen.", "token2charspan": [[0, 3], [4, 7], [8, 25], [26, 29], [30, 34], [35, 38], [39, 55], [56, 59], [60, 69], [70, 77], [78, 86], [86, 87]]}
{"doc_key": "ai-test-418", "ner": [[3, 4, "misc"], [29, 31, "location"]], "ner_mapping_to_source": [0, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Zuf\u00e4lligerweise", "hatten", "die", "Deutschen", "die", "Betriebsfrequenz", "des", "Wotan-Systems", "sehr", "schlecht", "gew\u00e4hlt", ";", "es", "arbeitete", "auf", "45", "MHz", ",", "was", "zuf\u00e4llig", "die", "Frequenz", "des", "leistungsstarken", ",", "aber", "schlafenden", "BBC-Fernsehsenders", "im", "Alexandra", "Palace", "war", "."], "sentence-detokenized": "Zuf\u00e4lligerweise hatten die Deutschen die Betriebsfrequenz des Wotan-Systems sehr schlecht gew\u00e4hlt; es arbeitete auf 45 MHz, was zuf\u00e4llig die Frequenz des leistungsstarken, aber schlafenden BBC-Fernsehsenders im Alexandra Palace war.", "token2charspan": [[0, 15], [16, 22], [23, 26], [27, 36], [37, 40], [41, 57], [58, 61], [62, 75], [76, 80], [81, 89], [90, 97], [97, 98], [99, 101], [102, 111], [112, 115], [116, 118], [119, 122], [122, 123], [124, 127], [128, 136], [137, 140], [141, 149], [150, 153], [154, 170], [170, 171], [172, 176], [177, 188], [189, 207], [208, 210], [211, 220], [221, 227], [228, 231], [231, 232]]}
{"doc_key": "ai-test-419", "ner": [[6, 9, "metrics"], [11, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Die", "vier", "Ergebnisse", "k\u00f6nnen", "in", "einer", "2", "\u00d7", "2", "Kontingenztabelle", "oder", "Konfusionsmatrix", "wie", "folgt", "formuliert", "werden", ":"], "sentence-detokenized": "Die vier Ergebnisse k\u00f6nnen in einer 2 \u00d7 2 Kontingenztabelle oder Konfusionsmatrix wie folgt formuliert werden:", "token2charspan": [[0, 3], [4, 8], [9, 19], [20, 26], [27, 29], [30, 35], [36, 37], [38, 39], [40, 41], [42, 59], [60, 64], [65, 81], [82, 85], [86, 91], [92, 102], [103, 109], [109, 110]]}
{"doc_key": "ai-test-420", "ner": [[1, 4, "misc"], [11, 11, "misc"], [13, 13, "product"], [15, 15, "product"], [17, 19, "product"], [27, 27, "misc"], [35, 37, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 13, 11, 11, "usage", "", false, false], [15, 15, 11, 11, "usage", "", false, false], [17, 19, 15, 15, "named", "", false, false], [27, 27, 11, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "Anwendungen", "des", "Semantic", "Web", "und", "in", "relativ", "popul\u00e4ren", "Anwendungen", "von", "RDF", "wie", "RSS", "und", "FOAF", "(", "Friend", "a", "Friend", ")", "werden", "Ressourcen", "in", "der", "Regel", "durch", "URIs", "dargestellt", ",", "die", "absichtlich", "tats\u00e4chliche", "Daten", "im", "World", "Wide", "Web", "bezeichnen", "und", "f\u00fcr", "den", "Zugriff", "darauf", "verwendet", "werden", "k\u00f6nnen", "."], "sentence-detokenized": "In Anwendungen des Semantic Web und in relativ popul\u00e4ren Anwendungen von RDF wie RSS und FOAF (Friend a Friend) werden Ressourcen in der Regel durch URIs dargestellt, die absichtlich tats\u00e4chliche Daten im World Wide Web bezeichnen und f\u00fcr den Zugriff darauf verwendet werden k\u00f6nnen.", "token2charspan": [[0, 2], [3, 14], [15, 18], [19, 27], [28, 31], [32, 35], [36, 38], [39, 46], [47, 56], [57, 68], [69, 72], [73, 76], [77, 80], [81, 84], [85, 88], [89, 93], [94, 95], [95, 101], [102, 103], [104, 110], [110, 111], [112, 118], [119, 129], [130, 132], [133, 136], [137, 142], [143, 148], [149, 153], [154, 165], [165, 166], [167, 170], [171, 182], [183, 195], [196, 201], [202, 204], [205, 210], [211, 215], [216, 219], [220, 230], [231, 234], [235, 238], [239, 242], [243, 250], [251, 257], [258, 267], [268, 274], [275, 281], [281, 282]]}
{"doc_key": "ai-test-421", "ner": [[1, 7, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Die", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "hat", "dieses", "Thema", "eingehend", "untersucht"], "sentence-detokenized": "Die Association for the Advancement of Artificial Intelligence hat dieses Thema eingehend untersucht", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 23], [24, 35], [36, 38], [39, 49], [50, 62], [63, 66], [67, 73], [74, 79], [80, 89], [90, 100]]}
{"doc_key": "ai-test-422", "ner": [[7, 10, "product"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 16, 7, 10, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Aus", "einer", "Kuriosit\u00e4t", "heraus", "hat", "sich", "das", "Sprachsystem", "des", "Apple", "Macintosh", "zu", "einem", "vollst\u00e4ndig", "unterst\u00fctzten", "Programm", "PlainTalk", "f\u00fcr", "Menschen", "mit", "Sehbehinderung", "entwickelt", "."], "sentence-detokenized": "Aus einer Kuriosit\u00e4t heraus hat sich das Sprachsystem des Apple Macintosh zu einem vollst\u00e4ndig unterst\u00fctzten Programm PlainTalk f\u00fcr Menschen mit Sehbehinderung entwickelt.", "token2charspan": [[0, 3], [4, 9], [10, 20], [21, 27], [28, 31], [32, 36], [37, 40], [41, 53], [54, 57], [58, 63], [64, 73], [74, 76], [77, 82], [83, 94], [95, 108], [109, 117], [118, 127], [128, 131], [132, 140], [141, 144], [145, 159], [160, 170], [170, 171]]}
{"doc_key": "ai-test-423", "ner": [[7, 7, "field"], [9, 10, "task"], [12, 12, "task"], [14, 15, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 7, 7, "part-of", "task_part_of_field", false, false], [12, 12, 7, 7, "part-of", "task_part_of_field", false, false], [14, 15, 7, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Weitere", "Anwendungsbereiche", "f\u00fcr", "Ontologien", "im", "Rahmen", "von", "NLP", "sind", "Information", "Retrieval", ",", "Informationsextraktion", "und", "automatische", "Zusammenfassungen", "."], "sentence-detokenized": "Weitere Anwendungsbereiche f\u00fcr Ontologien im Rahmen von NLP sind Information Retrieval, Informationsextraktion und automatische Zusammenfassungen.", "token2charspan": [[0, 7], [8, 26], [27, 30], [31, 41], [42, 44], [45, 51], [52, 55], [56, 59], [60, 64], [65, 76], [77, 86], [86, 87], [88, 110], [111, 114], [115, 127], [128, 145], [145, 146]]}
{"doc_key": "ai-test-424", "ner": [[6, 13, "organisation"], [16, 20, "organisation"], [23, 26, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Das", "Institut", "hat", "eng", "mit", "dem", "Janelia", "Farm", "Campus", "des", "Howard", "Hughes", "Medical", "Institute", ",", "dem", "Allen", "Institute", "for", "Brain", "Science", "und", "den", "National", "Institutes", "of", "Health", "zusammengearbeitet", ",", "um", "bessere", "Methoden", "zur", "Rekonstruktion", "neuronaler", "Architekturen", "zu", "entwickeln", "."], "sentence-detokenized": "Das Institut hat eng mit dem Janelia Farm Campus des Howard Hughes Medical Institute, dem Allen Institute for Brain Science und den National Institutes of Health zusammengearbeitet, um bessere Methoden zur Rekonstruktion neuronaler Architekturen zu entwickeln.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 20], [21, 24], [25, 28], [29, 36], [37, 41], [42, 48], [49, 52], [53, 59], [60, 66], [67, 74], [75, 84], [84, 85], [86, 89], [90, 95], [96, 105], [106, 109], [110, 115], [116, 123], [124, 127], [128, 131], [132, 140], [141, 151], [152, 154], [155, 161], [162, 180], [180, 181], [182, 184], [185, 192], [193, 201], [202, 205], [206, 220], [221, 231], [232, 245], [246, 248], [249, 259], [259, 260]]}
{"doc_key": "ai-test-425", "ner": [[2, 2, "organisation"], [6, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 9, 2, 2, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["K\u00fcrzlich", "gab", "Google", "bekannt", ",", "dass", "Google", "Translate", "an", "einem", "Tag", "so", "viel", "Text", "\u00fcbersetzt", ",", "dass", "man", "damit", "1", "Million", "B\u00fccher", "f\u00fcllen", "k\u00f6nnte", "(", "2012", ")", "."], "sentence-detokenized": "K\u00fcrzlich gab Google bekannt, dass Google Translate an einem Tag so viel Text \u00fcbersetzt, dass man damit 1 Million B\u00fccher f\u00fcllen k\u00f6nnte (2012).", "token2charspan": [[0, 8], [9, 12], [13, 19], [20, 27], [27, 28], [29, 33], [34, 40], [41, 50], [51, 53], [54, 59], [60, 63], [64, 66], [67, 71], [72, 76], [77, 86], [86, 87], [88, 92], [93, 96], [97, 102], [103, 104], [105, 112], [113, 119], [120, 126], [127, 133], [134, 135], [135, 139], [139, 140], [140, 141]]}
{"doc_key": "ai-test-426", "ner": [[10, 11, "country"], [14, 16, "country"], [18, 18, "country"], [20, 20, "country"], [22, 22, "country"], [24, 24, "country"], [34, 35, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Die", "Veranstaltungen", "finden", "weltweit", "statt", "und", "sind", "vor", "allem", "im", "Vereinigten", "K\u00f6nigreich", ",", "in", "den", "Vereinigten", "Staaten", ",", "Japan", ",", "Singapur", ",", "Indien", "und", "S\u00fcdkorea", "beliebt", "und", "werden", "auch", "in", "L\u00e4ndern", "des", "Subkontinents", "wie", "Sri", "Lanka", "immer", "beliebter", "."], "sentence-detokenized": "Die Veranstaltungen finden weltweit statt und sind vor allem im Vereinigten K\u00f6nigreich, in den Vereinigten Staaten, Japan, Singapur, Indien und S\u00fcdkorea beliebt und werden auch in L\u00e4ndern des Subkontinents wie Sri Lanka immer beliebter.", "token2charspan": [[0, 3], [4, 19], [20, 26], [27, 35], [36, 41], [42, 45], [46, 50], [51, 54], [55, 60], [61, 63], [64, 75], [76, 86], [86, 87], [88, 90], [91, 94], [95, 106], [107, 114], [114, 115], [116, 121], [121, 122], [123, 131], [131, 132], [133, 139], [140, 143], [144, 152], [153, 160], [161, 164], [165, 171], [172, 176], [177, 179], [180, 187], [188, 191], [192, 205], [206, 209], [210, 213], [214, 219], [220, 225], [226, 235], [235, 236]]}
{"doc_key": "ai-test-427", "ner": [[5, 5, "programlang"], [11, 11, "programlang"], [13, 13, "programlang"], [15, 15, "programlang"], [17, 17, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Diese", "Pakete", "werden", "haupts\u00e4chlich", "in", "R", "entwickelt", ",", "manchmal", "auch", "in", "Java", ",", "C", ",", "C++", "und", "Fortran", "."], "sentence-detokenized": "Diese Pakete werden haupts\u00e4chlich in R entwickelt, manchmal auch in Java, C, C++ und Fortran.", "token2charspan": [[0, 5], [6, 12], [13, 19], [20, 33], [34, 36], [37, 38], [39, 49], [49, 50], [51, 59], [60, 64], [65, 67], [68, 72], [72, 73], [74, 75], [75, 76], [77, 80], [81, 84], [85, 92], [92, 93]]}
{"doc_key": "ai-test-428", "ner": [[3, 12, "conference"], [9, 9, "conference"], [13, 13, "researcher"], [15, 15, "researcher"], [18, 19, "researcher"], [24, 24, "algorithm"], [29, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 9, 3, 12, "named", "", false, false], [13, 13, 3, 12, "physical", "", false, false], [13, 13, 3, 12, "role", "", false, false], [13, 13, 18, 19, "role", "teams_up_with", false, false], [13, 13, 24, 24, "usage", "", false, false], [15, 15, 3, 12, "physical", "", false, false], [15, 15, 3, 12, "role", "", false, false], [15, 15, 18, 19, "role", "teams_up_with", false, false], [15, 15, 24, 24, "usage", "", false, false], [18, 19, 3, 12, "physical", "", false, false], [18, 19, 3, 12, "role", "", false, false], [18, 19, 24, 24, "usage", "", false, false], [24, 24, 29, 33, "related-to", "used_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Im", "Rahmen", "der", "European", "Conference", "on", "Computer", "Vision", "(", "ECCV", ")", "2006", "arbeiteten", "Dalal", "und", "Triggs", "zusammen", "mit", "Cordelia", "Schmid", "an", "der", "Anwendung", "von", "HOG-Detektoren", "auf", "das", "Problem", "der", "Menschenerkennung", "in", "Filmen", "und", "Videos", "."], "sentence-detokenized": "Im Rahmen der European Conference on Computer Vision (ECCV) 2006 arbeiteten Dalal und Triggs zusammen mit Cordelia Schmid an der Anwendung von HOG-Detektoren auf das Problem der Menschenerkennung in Filmen und Videos.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 22], [23, 33], [34, 36], [37, 45], [46, 52], [53, 54], [54, 58], [58, 59], [60, 64], [65, 75], [76, 81], [82, 85], [86, 92], [93, 101], [102, 105], [106, 114], [115, 121], [122, 124], [125, 128], [129, 138], [139, 142], [143, 157], [158, 161], [162, 165], [166, 173], [174, 177], [178, 195], [196, 198], [199, 205], [206, 209], [210, 216], [216, 217]]}
{"doc_key": "ai-test-429", "ner": [[2, 2, "metrics"], [4, 4, "metrics"], [9, 9, "task"], [13, 14, "metrics"], [16, 16, "metrics"], [22, 22, "metrics"], [26, 27, "metrics"], [29, 29, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[2, 2, 9, 9, "related-to", "measured_with", false, false], [4, 4, 9, 9, "related-to", "measured_with", false, false], [13, 14, 9, 9, "related-to", "measured_with", false, false], [16, 16, 13, 14, "named", "", false, false], [22, 22, 13, 14, "named", "", false, false], [29, 29, 26, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Zus\u00e4tzlich", "zur", "Sensitivit\u00e4t", "und", "Spezifit\u00e4t", "kann", "die", "Leistung", "eines", "bin\u00e4ren", "Klassifikationstests", "mit", "dem", "positiven", "Vorhersagewert", "(", "PPV", ")", ",", "auch", "bekannt", "als", "Pr\u00e4zision", ",", "und", "dem", "negativen", "Vorhersagewert", "(", "NPV", ")", "gemessen", "werden", "."], "sentence-detokenized": "Zus\u00e4tzlich zur Sensitivit\u00e4t und Spezifit\u00e4t kann die Leistung eines bin\u00e4ren Klassifikationstests mit dem positiven Vorhersagewert (PPV), auch bekannt als Pr\u00e4zision, und dem negativen Vorhersagewert (NPV) gemessen werden.", "token2charspan": [[0, 10], [11, 14], [15, 27], [28, 31], [32, 42], [43, 47], [48, 51], [52, 60], [61, 66], [67, 74], [75, 95], [96, 99], [100, 103], [104, 113], [114, 128], [129, 130], [130, 133], [133, 134], [134, 135], [136, 140], [141, 148], [149, 152], [153, 162], [162, 163], [164, 167], [168, 171], [172, 181], [182, 196], [197, 198], [198, 201], [201, 202], [203, 211], [212, 218], [218, 219]]}
{"doc_key": "ai-test-430", "ner": [[15, 15, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Bei", "solchen", "Modellen", "k\u00f6nnen", "sich", "\u00fcberschneidende", "\u00dcbereinstimmungen", "teilweise", "angerechnet", "werden", "(", "z.", "B.", "anhand", "des", "Jaccard-Index-Kriteriums", ")", "."], "sentence-detokenized": "Bei solchen Modellen k\u00f6nnen sich \u00fcberschneidende \u00dcbereinstimmungen teilweise angerechnet werden (z. B. anhand des Jaccard-Index-Kriteriums).", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 27], [28, 32], [33, 48], [49, 66], [67, 76], [77, 88], [89, 95], [96, 97], [97, 99], [100, 102], [103, 109], [110, 113], [114, 138], [138, 139], [139, 140]]}
{"doc_key": "ai-test-431", "ner": [[22, 24, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Dar\u00fcber", "hinaus", "werden", "im", "Falle", "der", "Sch\u00e4tzung", "auf", "der", "Grundlage", "einer", "einzigen", "Stichprobe", "philosophische", "Fragen", "und", "m\u00f6gliche", "Missverst\u00e4ndnisse", "bei", "der", "Verwendung", "von", "Maximum-Likelihood-Sch\u00e4tzern", "und", "Likelihood-Funktionen", "aufgezeigt", "."], "sentence-detokenized": "Dar\u00fcber hinaus werden im Falle der Sch\u00e4tzung auf der Grundlage einer einzigen Stichprobe philosophische Fragen und m\u00f6gliche Missverst\u00e4ndnisse bei der Verwendung von Maximum-Likelihood-Sch\u00e4tzern und Likelihood-Funktionen aufgezeigt.", "token2charspan": [[0, 7], [8, 14], [15, 21], [22, 24], [25, 30], [31, 34], [35, 44], [45, 48], [49, 52], [53, 62], [63, 68], [69, 77], [78, 88], [89, 103], [104, 110], [111, 114], [115, 123], [124, 141], [142, 145], [146, 149], [150, 160], [161, 164], [165, 193], [194, 197], [198, 219], [220, 230], [230, 231]]}
