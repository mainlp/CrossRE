{"doc_key": "ai-dev-1", "ner": [[3, 3, "metrics"], [6, 6, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 6, 3, 3, "part-of", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Hier", "wird", "die", "Genauigkeit", "anhand", "der", "Fehlerquote", "gemessen", ",", "die", "wie", "folgt", "definiert", "ist", ":"], "sentence-detokenized": "Hier wird die Genauigkeit anhand der Fehlerquote gemessen, die wie folgt definiert ist:", "token2charspan": [[0, 4], [5, 9], [10, 13], [14, 25], [26, 32], [33, 36], [37, 48], [49, 57], [57, 58], [59, 62], [63, 66], [67, 72], [73, 82], [83, 86], [86, 87]]}
{"doc_key": "ai-dev-2", "ner": [[4, 4, "algorithm"], [9, 9, "misc"], [12, 17, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 9, 9, "type-of", "", false, false], [4, 4, 12, 17, "related-to", "", false, false], [4, 4, 13, 14, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "dieser", "Hinsicht", "ist", "SVM", "eng", "mit", "anderen", "grundlegenden", "Klassifizierungsalgorithmen", "wie", "der", "regularisierten", "logistischen", "Regression", "mit", "kleinsten", "Quadraten", "verwandt", "."], "sentence-detokenized": "In dieser Hinsicht ist SVM eng mit anderen grundlegenden Klassifizierungsalgorithmen wie der regularisierten logistischen Regression mit kleinsten Quadraten verwandt.", "token2charspan": [[0, 2], [3, 9], [10, 18], [19, 22], [23, 26], [27, 30], [31, 34], [35, 42], [43, 56], [57, 84], [85, 88], [89, 92], [93, 108], [109, 121], [122, 132], [133, 136], [137, 146], [147, 156], [157, 165], [165, 166]]}
{"doc_key": "ai-dev-3", "ner": [[0, 1, "person"], [3, 4, "person"], [12, 13, "person"], [15, 15, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 0, 1, "named", "actor_plays_character", false, false], [3, 4, 0, 1, "origin", "actor_plays_character", false, false], [15, 15, 12, 13, "named", "actor_plays_character", false, false], [15, 15, 12, 13, "origin", "actor_plays_character", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Brion", "James", "spielt", "Leon", "Kowalski", ",", "einen", "Kampf-", "und", "Arbeitsreplikanten", ",", "und", "Joanna", "Cassidy", "spielt", "Zhora", ",", "einen", "Attent\u00e4ter-Replikanten", "."], "sentence-detokenized": "Brion James spielt Leon Kowalski, einen Kampf- und Arbeitsreplikanten, und Joanna Cassidy spielt Zhora, einen Attent\u00e4ter-Replikanten.", "token2charspan": [[0, 5], [6, 11], [12, 18], [19, 23], [24, 32], [32, 33], [34, 39], [40, 46], [47, 50], [51, 69], [69, 70], [71, 74], [75, 81], [82, 89], [90, 96], [97, 102], [102, 103], [104, 109], [110, 132], [132, 133]]}
{"doc_key": "ai-dev-4", "ner": [[18, 21, "product"], [23, 23, "product"], [26, 26, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 21, 26, 26, "physical", "", false, false], [23, 23, 18, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Das", "erste", "Bild", ",", "das", "gescannt", ",", "gespeichert", "und", "in", "digitalen", "Pixeln", "wiederhergestellt", "wurde", ",", "wurde", "auf", "dem", "Standards", "Eastern", "Automatic", "Computer", "(", "SEAC", ")", "am", "NIST", "angezeigt", "."], "sentence-detokenized": "Das erste Bild, das gescannt, gespeichert und in digitalen Pixeln wiederhergestellt wurde, wurde auf dem Standards Eastern Automatic Computer (SEAC) am NIST angezeigt.", "token2charspan": [[0, 3], [4, 9], [10, 14], [14, 15], [16, 19], [20, 28], [28, 29], [30, 41], [42, 45], [46, 48], [49, 58], [59, 65], [66, 83], [84, 89], [89, 90], [91, 96], [97, 100], [101, 104], [105, 114], [115, 122], [123, 132], [133, 141], [142, 143], [143, 147], [147, 148], [149, 151], [152, 156], [157, 166], [166, 167]]}
{"doc_key": "ai-dev-5", "ner": [[0, 7, "task"], [21, 21, "task"], [24, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 7, 21, 21, "part-of", "", false, false], [0, 7, 24, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Die", "Segmentierung", "des", "Textes", "in", "Themen", "oder", "Diskurs-Turns", "kann", "bei", "einigen", "Aufgaben", "der", "nat\u00fcrlichen", "Verarbeitung", "n\u00fctzlich", "sein", ":", "Sie", "kann", "die", "Informationssuche", "oder", "die", "Spracherkennung", "erheblich", "verbessern", "(", "indem", "Dokumente", "genauer", "indiziert/erkannt", "werden", "oder", "indem", "der", "spezifische", "Teil", "eines", "Dokuments", ",", "der", "der", "Anfrage", "entspricht", ",", "als", "Ergebnis", "geliefert", "wird", ")", "."], "sentence-detokenized": "Die Segmentierung des Textes in Themen oder Diskurs-Turns kann bei einigen Aufgaben der nat\u00fcrlichen Verarbeitung n\u00fctzlich sein: Sie kann die Informationssuche oder die Spracherkennung erheblich verbessern (indem Dokumente genauer indiziert/erkannt werden oder indem der spezifische Teil eines Dokuments, der der Anfrage entspricht, als Ergebnis geliefert wird).", "token2charspan": [[0, 3], [4, 17], [18, 21], [22, 28], [29, 31], [32, 38], [39, 43], [44, 57], [58, 62], [63, 66], [67, 74], [75, 83], [84, 87], [88, 99], [100, 112], [113, 121], [122, 126], [126, 127], [128, 131], [132, 136], [137, 140], [141, 158], [159, 163], [164, 167], [168, 183], [184, 193], [194, 204], [205, 206], [206, 211], [212, 221], [222, 229], [230, 247], [248, 254], [255, 259], [260, 265], [266, 269], [270, 281], [282, 286], [287, 292], [293, 302], [302, 303], [304, 307], [308, 311], [312, 319], [320, 330], [330, 331], [332, 335], [336, 344], [345, 354], [355, 359], [359, 360], [360, 361]]}
{"doc_key": "ai-dev-6", "ner": [[2, 3, "university"], [27, 28, "conference"], [19, 20, "university"], [39, 40, "researcher"], [42, 43, "researcher"], [45, 46, "researcher"], [48, 49, "researcher"], [51, 52, "researcher"], [54, 55, "researcher"], [57, 59, "researcher"], [61, 63, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[27, 28, 19, 20, "physical", "", false, false], [39, 40, 27, 28, "physical", "", false, false], [39, 40, 27, 28, "role", "", false, false], [39, 40, 27, 28, "temporal", "", false, false], [42, 43, 27, 28, "physical", "", false, false], [42, 43, 27, 28, "role", "", false, false], [42, 43, 27, 28, "temporal", "", false, false], [45, 46, 27, 28, "physical", "", false, false], [45, 46, 27, 28, "role", "", false, false], [45, 46, 27, 28, "temporal", "", false, false], [48, 49, 27, 28, "physical", "", false, false], [48, 49, 27, 28, "role", "", false, false], [48, 49, 27, 28, "temporal", "", false, false], [51, 52, 27, 28, "physical", "", false, false], [51, 52, 27, 28, "role", "", false, false], [51, 52, 27, 28, "temporal", "", false, false], [54, 55, 27, 28, "physical", "", false, false], [54, 55, 27, 28, "role", "", false, false], [54, 55, 27, 28, "temporal", "", false, false], [57, 59, 27, 28, "physical", "", false, false], [57, 59, 27, 28, "role", "", false, false], [57, 59, 27, 28, "temporal", "", false, false], [61, 63, 27, 28, "physical", "", false, false], [61, 63, 27, 28, "role", "", false, false], [61, 63, 27, 28, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "sentence": ["An", "der", "Indiana", "University", "organisierte", "er", "1999", "ein", "solches", "Symposium", ",", "und", "im", "April", "2000", "veranstaltete", "er", "an", "der", "Stanford", "University", "ein", "gr\u00f6\u00dferes", "Symposium", "mit", "dem", "Titel", "Spiritual", "Robots", ",", "bei", "dem", "er", "eine", "Diskussionsrunde", "moderierte", ",", "an", "der", "Ray", "Kurzweil", ",", "Hans", "Moravec", ",", "Kevin", "Kelly", ",", "Ralph", "Merkle", ",", "Bill", "Joy", ",", "Frank", "Drake", ",", "John", "Henry", "Holland", "und", "John", "Koza", "teilnahmen", "."], "sentence-detokenized": "An der Indiana University organisierte er 1999 ein solches Symposium, und im April 2000 veranstaltete er an der Stanford University ein gr\u00f6\u00dferes Symposium mit dem Titel Spiritual Robots, bei dem er eine Diskussionsrunde moderierte, an der Ray Kurzweil, Hans Moravec, Kevin Kelly, Ralph Merkle, Bill Joy, Frank Drake, John Henry Holland und John Koza teilnahmen.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 25], [26, 38], [39, 41], [42, 46], [47, 50], [51, 58], [59, 68], [68, 69], [70, 73], [74, 76], [77, 82], [83, 87], [88, 101], [102, 104], [105, 107], [108, 111], [112, 120], [121, 131], [132, 135], [136, 144], [145, 154], [155, 158], [159, 162], [163, 168], [169, 178], [179, 185], [185, 186], [187, 190], [191, 194], [195, 197], [198, 202], [203, 219], [220, 230], [230, 231], [232, 234], [235, 238], [239, 242], [243, 251], [251, 252], [253, 257], [258, 265], [265, 266], [267, 272], [273, 278], [278, 279], [280, 285], [286, 292], [292, 293], [294, 298], [299, 302], [302, 303], [304, 309], [310, 315], [315, 316], [317, 321], [322, 327], [328, 335], [336, 339], [340, 344], [345, 349], [350, 360], [360, 361]]}
{"doc_key": "ai-dev-7", "ner": [[8, 8, "metrics"], [9, 9, "metrics"], [13, 13, "metrics"], [14, 14, "metrics"], [19, 19, "metrics"], [41, 41, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 8, 19, 19, "named", "", false, false], [9, 9, 8, 8, "named", "", false, false], [13, 13, 41, 41, "named", "", false, false], [14, 14, 13, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Bei", "der", "Berechnung", "der", "Punktzahl", "werden", "sowohl", "die", "Genauigkeit", "p", "als", "auch", "der", "R\u00fcckruf", "r", "des", "Tests", "ber\u00fccksichtigt", ":", "p", "ist", "die", "Anzahl", "der", "richtigen", "positiven", "Ergebnisse", "geteilt", "durch", "die", "Anzahl", "aller", "positiven", "Ergebnisse", ",", "die", "der", "Klassifikator", "liefert", ",", "und", "r", "ist", "die", "Anzahl", "der", "richtigen", "positiven", "Ergebnisse", "geteilt", "durch", "die", "Anzahl", "aller", "relevanten", "Proben", "(", "alle", "Proben", ",", "die", "als", "positiv", "h\u00e4tten", "identifiziert", "werden", "m\u00fcssen", ")", "."], "sentence-detokenized": "Bei der Berechnung der Punktzahl werden sowohl die Genauigkeit p als auch der R\u00fcckruf r des Tests ber\u00fccksichtigt: p ist die Anzahl der richtigen positiven Ergebnisse geteilt durch die Anzahl aller positiven Ergebnisse, die der Klassifikator liefert, und r ist die Anzahl der richtigen positiven Ergebnisse geteilt durch die Anzahl aller relevanten Proben (alle Proben, die als positiv h\u00e4tten identifiziert werden m\u00fcssen).", "token2charspan": [[0, 3], [4, 7], [8, 18], [19, 22], [23, 32], [33, 39], [40, 46], [47, 50], [51, 62], [63, 64], [65, 68], [69, 73], [74, 77], [78, 85], [86, 87], [88, 91], [92, 97], [98, 112], [112, 113], [114, 115], [116, 119], [120, 123], [124, 130], [131, 134], [135, 144], [145, 154], [155, 165], [166, 173], [174, 179], [180, 183], [184, 190], [191, 196], [197, 206], [207, 217], [217, 218], [219, 222], [223, 226], [227, 240], [241, 248], [248, 249], [250, 253], [254, 255], [256, 259], [260, 263], [264, 270], [271, 274], [275, 284], [285, 294], [295, 305], [306, 313], [314, 319], [320, 323], [324, 330], [331, 336], [337, 347], [348, 354], [355, 356], [356, 360], [361, 367], [367, 368], [369, 372], [373, 376], [377, 384], [385, 391], [392, 405], [406, 412], [413, 419], [419, 420], [420, 421]]}
{"doc_key": "ai-dev-8", "ner": [[3, 4, "organisation"], [21, 21, "product"], [29, 30, "person"], [35, 35, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 21, 21, "artifact", "", false, false], [21, 21, 29, 30, "win-defeat", "", false, false], [21, 21, 35, 35, "win-defeat", "", true, false], [29, 30, 35, 35, "win-defeat", "lose", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Seit", "der", "\u00dcbernahme", "durch", "Google", "hat", "das", "Unternehmen", "eine", "Reihe", "bedeutender", "Erfolge", "erzielt", ".", "Der", "vielleicht", "bemerkenswerteste", "ist", "die", "Entwicklung", "von", "AlphaGo", ",", "einem", "Programm", ",", "das", "den", "Weltmeister", "Lee", "Sedol", "in", "dem", "komplexen", "Spiel", "Go", "besiegt", "hat", "."], "sentence-detokenized": "Seit der \u00dcbernahme durch Google hat das Unternehmen eine Reihe bedeutender Erfolge erzielt. Der vielleicht bemerkenswerteste ist die Entwicklung von AlphaGo, einem Programm, das den Weltmeister Lee Sedol in dem komplexen Spiel Go besiegt hat.", "token2charspan": [[0, 4], [5, 8], [9, 18], [19, 24], [25, 31], [32, 35], [36, 39], [40, 51], [52, 56], [57, 62], [63, 74], [75, 82], [83, 90], [90, 91], [92, 95], [96, 106], [107, 124], [125, 128], [129, 132], [133, 144], [145, 148], [149, 156], [156, 157], [158, 163], [164, 172], [172, 173], [174, 177], [178, 181], [182, 193], [194, 197], [198, 203], [204, 206], [207, 210], [211, 220], [221, 226], [227, 229], [230, 237], [238, 241], [241, 242]]}
{"doc_key": "ai-dev-9", "ner": [[14, 14, "misc"], [28, 29, "product"], [45, 45, "misc"], [53, 53, "product"]], "ner_mapping_to_source": [0, 2, 3, 5], "relations": [[28, 29, 45, 45, "related-to", "", false, false], [28, 29, 53, 53, "usage", "", false, false]], "relations_mapping_to_source": [2, 4], "sentence": ["Die", "Darstellung", "von", "W\u00f6rtern", "unter", "Ber\u00fccksichtigung", "ihres", "Kontexts", "durch", "dichte", "Vektoren", "fester", "Gr\u00f6\u00dfe", "(", "Worteinbettungen", ")", "ist", "zu", "einem", "der", "grundlegendsten", "Bausteine", "in", "verschiedenen", "NLP-Systemen", "geworden", ".", "Ein", "un\u00fcberwachtes", "Disambiguierungssystem", "verwendet", "die", "\u00c4hnlichkeit", "zwischen", "Wortsinnen", "in", "einem", "festen", "Kontextfenster", ",", "um", "die", "am", "besten", "geeignete", "Wortbedeutung", "unter", "Verwendung", "eines", "vorab", "trainierten", "Worteinbettungsmodells", "und", "WordNet", "auszuw\u00e4hlen", "."], "sentence-detokenized": "Die Darstellung von W\u00f6rtern unter Ber\u00fccksichtigung ihres Kontexts durch dichte Vektoren fester Gr\u00f6\u00dfe (Worteinbettungen) ist zu einem der grundlegendsten Bausteine in verschiedenen NLP-Systemen geworden. Ein un\u00fcberwachtes Disambiguierungssystem verwendet die \u00c4hnlichkeit zwischen Wortsinnen in einem festen Kontextfenster, um die am besten geeignete Wortbedeutung unter Verwendung eines vorab trainierten Worteinbettungsmodells und WordNet auszuw\u00e4hlen.", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 27], [28, 33], [34, 50], [51, 56], [57, 65], [66, 71], [72, 78], [79, 87], [88, 94], [95, 100], [101, 102], [102, 118], [118, 119], [120, 123], [124, 126], [127, 132], [133, 136], [137, 152], [153, 162], [163, 165], [166, 179], [180, 192], [193, 201], [201, 202], [203, 206], [207, 220], [221, 243], [244, 253], [254, 257], [258, 269], [270, 278], [279, 289], [290, 292], [293, 298], [299, 305], [306, 320], [320, 321], [322, 324], [325, 328], [329, 331], [332, 338], [339, 348], [349, 362], [363, 368], [369, 379], [380, 385], [386, 391], [392, 403], [404, 426], [427, 430], [431, 438], [439, 450], [450, 451]]}
{"doc_key": "ai-dev-10", "ner": [[0, 0, "field"], [4, 5, "field"], [7, 8, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 0, 0, "part-of", "", false, false], [7, 8, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Maschinelle", "Lerntechniken", ",", "entweder", "\u00fcberwachtes", "Lernen", "oder", "un\u00fcberwachtes", "Lernen", ",", "wurden", "eingesetzt", ",", "um", "solche", "Regeln", "automatisch", "zu", "erstellen", "."], "sentence-detokenized": "Maschinelle Lerntechniken, entweder \u00fcberwachtes Lernen oder un\u00fcberwachtes Lernen, wurden eingesetzt, um solche Regeln automatisch zu erstellen.", "token2charspan": [[0, 11], [12, 25], [25, 26], [27, 35], [36, 47], [48, 54], [55, 59], [60, 73], [74, 80], [80, 81], [82, 88], [89, 99], [99, 100], [101, 103], [104, 110], [111, 117], [118, 129], [130, 132], [133, 142], [142, 143]]}
{"doc_key": "ai-dev-11", "ner": [[4, 4, "researcher"], [6, 6, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 6, 4, 4, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Im", "Jahr", "1969", "erfand", "Scheinman", "den", "Stanford-Arm", ","], "sentence-detokenized": "Im Jahr 1969 erfand Scheinman den Stanford-Arm,", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 19], [20, 29], [30, 33], [34, 46], [46, 47]]}
{"doc_key": "ai-dev-12", "ner": [[2, 2, "metrics"], [8, 9, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Da", "der", "Log-Verlust", "differenzierbar", "ist", ",", "kann", "eine", "gradientenbasierte", "Methode", "zur", "Optimierung", "des", "Modells", "verwendet", "werden", "."], "sentence-detokenized": "Da der Log-Verlust differenzierbar ist, kann eine gradientenbasierte Methode zur Optimierung des Modells verwendet werden.", "token2charspan": [[0, 2], [3, 6], [7, 18], [19, 34], [35, 38], [38, 39], [40, 44], [45, 49], [50, 68], [69, 76], [77, 80], [81, 92], [93, 96], [97, 104], [105, 114], [115, 121], [121, 122]]}
{"doc_key": "ai-dev-13", "ner": [[1, 2, "field"], [4, 4, "algorithm"], [6, 6, "algorithm"], [9, 9, "algorithm"], [11, 11, "field"], [21, 21, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6], "relations": [[4, 4, 11, 11, "part-of", "", false, false], [6, 6, 4, 4, "named", "", false, false], [9, 9, 4, 4, "named", "", false, false], [11, 11, 1, 2, "part-of", "subfield", false, false], [21, 21, 11, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5], "sentence": ["Beim", "maschinellen", "Lernen", "sind", "Support-Vektor-Maschinen", "(", "SVMs", ",", "auch", "Support-Vektor-Netzwerke", ")", "\u00fcberwachte", "Lernmodelle", "mit", "Lernalgorithmen", ",", "die", "Daten", "f\u00fcr", "Klassifizierungs-", "und", "Regressionsanalysen", "analysieren", "."], "sentence-detokenized": "Beim maschinellen Lernen sind Support-Vektor-Maschinen (SVMs, auch Support-Vektor-Netzwerke) \u00fcberwachte Lernmodelle mit Lernalgorithmen, die Daten f\u00fcr Klassifizierungs- und Regressionsanalysen analysieren.", "token2charspan": [[0, 4], [5, 17], [18, 24], [25, 29], [30, 54], [55, 56], [56, 60], [60, 61], [62, 66], [67, 91], [91, 92], [93, 103], [104, 115], [116, 119], [120, 135], [135, 136], [137, 140], [141, 146], [147, 150], [151, 168], [169, 172], [173, 192], [193, 204], [204, 205]]}
{"doc_key": "ai-dev-14", "ner": [[10, 11, "task"], [13, 13, "task"], [31, 31, "metrics"], [33, 33, "metrics"], [35, 35, "researcher"], [37, 37, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 13, 10, 11, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "2002", ")", "als", "automatische", "Metrik", "f\u00fcr", "die", "Bewertung", "der", "maschinellen", "\u00dcbersetzung", "(", "MT", ")", ",", "wurden", "viele", "andere", "Methoden", "vorgeschlagen", ",", "um", "sie", "zu", "\u00fcberarbeiten", "oder", "zu", "verbessern", ",", "wie", "TER", ",", "METEOR", ",", "Banerjee", "und", "Lavie", ",", "(", "2005", ")", "usw."], "sentence-detokenized": "(2002) als automatische Metrik f\u00fcr die Bewertung der maschinellen \u00dcbersetzung (MT), wurden viele andere Methoden vorgeschlagen, um sie zu \u00fcberarbeiten oder zu verbessern, wie TER, METEOR, Banerjee und Lavie, (2005) usw.", "token2charspan": [[0, 1], [1, 5], [5, 6], [7, 10], [11, 23], [24, 30], [31, 34], [35, 38], [39, 48], [49, 52], [53, 65], [66, 77], [78, 79], [79, 81], [81, 82], [82, 83], [84, 90], [91, 96], [97, 103], [104, 112], [113, 126], [126, 127], [128, 130], [131, 134], [135, 137], [138, 150], [151, 155], [156, 158], [159, 169], [169, 170], [171, 174], [175, 178], [178, 179], [180, 186], [186, 187], [188, 196], [197, 200], [201, 206], [206, 207], [208, 209], [209, 213], [213, 214], [215, 219]]}
{"doc_key": "ai-dev-15", "ner": [[3, 4, "misc"], [10, 10, "organisation"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[3, 4, 10, 10, "origin", "", false, false], [14, 15, 10, 10, "role", "", false, false], [17, 18, 10, 10, "role", "", false, false]], "relations_mapping_to_source": [0, 2, 3], "sentence": ["Sie", "enth\u00e4lt", "eine", "obere", "Ontologie", ",", "die", "von", "der", "IEEE-Arbeitsgruppe", "P1600.1", "(", "urspr\u00fcnglich", "von", "Ian", "Niles", "und", "Adam", "Pease", ")", "erstellt", "wurde", "."], "sentence-detokenized": "Sie enth\u00e4lt eine obere Ontologie, die von der IEEE-Arbeitsgruppe P1600.1 (urspr\u00fcnglich von Ian Niles und Adam Pease) erstellt wurde.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 22], [23, 32], [32, 33], [34, 37], [38, 41], [42, 45], [46, 64], [65, 72], [73, 74], [74, 86], [87, 90], [91, 94], [95, 100], [101, 104], [105, 109], [110, 115], [115, 116], [117, 125], [126, 131], [131, 132]]}
{"doc_key": "ai-dev-16", "ner": [[2, 2, "misc"], [31, 34, "algorithm"], [36, 36, "algorithm"], [40, 40, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[31, 34, 2, 2, "part-of", "", true, false], [36, 36, 2, 2, "part-of", "", true, false], [40, 40, 36, 36, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "der", "Kryo-Elektronentomographie", ",", "wo", "aufgrund", "der", "Hardwarebeschr\u00e4nkungen", "nur", "eine", "begrenzte", "Anzahl", "von", "Projektionen", "erfasst", "werden", "kann", ",", "um", "eine", "Besch\u00e4digung", "der", "biologischen", "Probe", "zu", "vermeiden", ",", "kann", "sie", "zusammen", "mit", "Techniken", "der", "kompressiven", "Abtastung", "oder", "Regularisierungsfunktionen", "(", "z.", "B.", "Huber-Verlust", ")", "zur", "Verbesserung", "der", "Rekonstruktion", "f\u00fcr", "eine", "bessere", "Interpretation", "verwendet", "werden", "."], "sentence-detokenized": "In der Kryo-Elektronentomographie, wo aufgrund der Hardwarebeschr\u00e4nkungen nur eine begrenzte Anzahl von Projektionen erfasst werden kann, um eine Besch\u00e4digung der biologischen Probe zu vermeiden, kann sie zusammen mit Techniken der kompressiven Abtastung oder Regularisierungsfunktionen (z. B. Huber-Verlust) zur Verbesserung der Rekonstruktion f\u00fcr eine bessere Interpretation verwendet werden.", "token2charspan": [[0, 2], [3, 6], [7, 33], [33, 34], [35, 37], [38, 46], [47, 50], [51, 73], [74, 77], [78, 82], [83, 92], [93, 99], [100, 103], [104, 116], [117, 124], [125, 131], [132, 136], [136, 137], [138, 140], [141, 145], [146, 158], [159, 162], [163, 175], [176, 181], [182, 184], [185, 194], [194, 195], [196, 200], [201, 204], [205, 213], [214, 217], [218, 227], [228, 231], [232, 244], [245, 254], [255, 259], [260, 286], [287, 288], [288, 290], [291, 293], [294, 307], [307, 308], [309, 312], [313, 325], [326, 329], [330, 344], [345, 348], [349, 353], [354, 361], [362, 376], [377, 386], [387, 393], [393, 394]]}
{"doc_key": "ai-dev-17", "ner": [[5, 5, "programlang"], [8, 8, "algorithm"], [10, 10, "algorithm"], [14, 14, "algorithm"], [18, 19, "product"], [24, 24, "product"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6], "relations": [[18, 19, 5, 5, "general-affiliation", "", true, false], [18, 19, 5, 5, "part-of", "", true, false], [24, 24, 18, 19, "role", "publishes", false, false]], "relations_mapping_to_source": [4, 5, 6], "sentence": ["Eine", "Implementierung", "mehrerer", "Whitening-Verfahren", "in", "R", ",", "einschlie\u00dflich", "ZCA-Whitening", "und", "PCA-Whitening", ",", "aber", "auch", "CCA-Whitening", ",", "ist", "im", "R-Paket", "whitening", "verf\u00fcgbar", ",", "das", "auf", "CRAN", "ver\u00f6ffentlicht", "ist", "."], "sentence-detokenized": "Eine Implementierung mehrerer Whitening-Verfahren in R, einschlie\u00dflich ZCA-Whitening und PCA-Whitening, aber auch CCA-Whitening, ist im R-Paket whitening verf\u00fcgbar, das auf CRAN ver\u00f6ffentlicht ist.", "token2charspan": [[0, 4], [5, 20], [21, 29], [30, 49], [50, 52], [53, 54], [54, 55], [56, 70], [71, 84], [85, 88], [89, 102], [102, 103], [104, 108], [109, 113], [114, 127], [127, 128], [129, 132], [133, 135], [136, 143], [144, 153], [154, 163], [163, 164], [165, 168], [169, 172], [173, 177], [178, 192], [193, 196], [196, 197]]}
{"doc_key": "ai-dev-18", "ner": [[31, 31, "product"], [33, 33, "product"], [37, 37, "product"], [39, 39, "product"], [41, 41, "product"], [43, 43, "product"], [46, 46, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[31, 31, 37, 37, "compare", "", false, false], [31, 31, 39, 39, "compare", "", false, false], [31, 31, 41, 41, "compare", "", false, false], [31, 31, 43, 43, "compare", "", false, false], [31, 31, 46, 46, "compare", "", false, false], [33, 33, 37, 37, "compare", "", false, false], [33, 33, 39, 39, "compare", "", false, false], [33, 33, 41, 41, "compare", "", false, false], [33, 33, 43, 43, "compare", "", false, false], [33, 33, 46, 46, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Heute", "ist", "das", "Feld", "noch", "abschreckender", "und", "komplexer", "geworden", ",", "da", "neue", "Sprachen", "und", "Software", "f\u00fcr", "die", "Analyse", "und", "den", "Entwurf", "von", "Schaltungen", ",", "Systemen", "und", "Signalen", "hinzugekommen", "sind", ",", "von", "MATLAB", "und", "Simulink", "bis", "hin", "zu", "NumPy", ",", "VHDL", ",", "PSpice", ",", "Verilog", "und", "sogar", "Assembler", "."], "sentence-detokenized": "Heute ist das Feld noch abschreckender und komplexer geworden, da neue Sprachen und Software f\u00fcr die Analyse und den Entwurf von Schaltungen, Systemen und Signalen hinzugekommen sind, von MATLAB und Simulink bis hin zu NumPy, VHDL, PSpice, Verilog und sogar Assembler.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 18], [19, 23], [24, 38], [39, 42], [43, 52], [53, 61], [61, 62], [63, 65], [66, 70], [71, 79], [80, 83], [84, 92], [93, 96], [97, 100], [101, 108], [109, 112], [113, 116], [117, 124], [125, 128], [129, 140], [140, 141], [142, 150], [151, 154], [155, 163], [164, 177], [178, 182], [182, 183], [184, 187], [188, 194], [195, 198], [199, 207], [208, 211], [212, 215], [216, 218], [219, 224], [224, 225], [226, 230], [230, 231], [232, 238], [238, 239], [240, 247], [248, 251], [252, 257], [258, 267], [267, 268]]}
{"doc_key": "ai-dev-19", "ner": [[5, 6, "person"], [14, 15, "person"], [11, 13, "organisation"], [19, 19, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 13, 14, 15, "origin", "", false, false], [19, 19, 11, 13, "artifact", "builds", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Das", "Unternehmen", "wurde", "1937", "von", "Kiichiro", "Toyoda", "als", "Ableger", "des", "Unternehmens", "Toyota", "Industries", "von", "Sakichi", "Toyoda", "gegr\u00fcndet", ",", "um", "Automobile", "herzustellen", "."], "sentence-detokenized": "Das Unternehmen wurde 1937 von Kiichiro Toyoda als Ableger des Unternehmens Toyota Industries von Sakichi Toyoda gegr\u00fcndet, um Automobile herzustellen.", "token2charspan": [[0, 3], [4, 15], [16, 21], [22, 26], [27, 30], [31, 39], [40, 46], [47, 50], [51, 58], [59, 62], [63, 75], [76, 82], [83, 93], [94, 97], [98, 105], [106, 112], [113, 122], [122, 123], [124, 126], [127, 137], [138, 150], [150, 151]]}
{"doc_key": "ai-dev-20", "ner": [[0, 3, "field"], [51, 52, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[51, 52, 0, 3, "origin", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Beim", "un\u00fcberwachten", "Lernen", "hingegen", "wird", "von", "Trainingsdaten", "ausgegangen", ",", "die", "nicht", "von", "Hand", "beschriftet", "wurden", ",", "und", "es", "wird", "versucht", ",", "inh\u00e4rente", "Muster", "in", "den", "Daten", "zu", "finden", ",", "die", "dann", "zur", "Bestimmung", "des", "korrekten", "Ausgabewerts", "f\u00fcr", "neue", "Dateninstanzen", "verwendet", "werden", "k\u00f6nnen", ".", "Eine", "k\u00fcrzlich", "erforschte", "Kombination", "aus", "beiden", "ist", "das", "halb\u00fcberwachte", "Lernen", ",", "bei", "dem", "eine", "Kombination", "aus", "gekennzeichneten", "und", "nicht", "gekennzeichneten", "Daten", "verwendet", "wird", "(", "in", "der", "Regel", "ein", "kleiner", "Satz", "gekennzeichneter", "Daten", "in", "Kombination", "mit", "einer", "gro\u00dfen", "Menge", "nicht", "gekennzeichneter", "Daten", ")", "."], "sentence-detokenized": "Beim un\u00fcberwachten Lernen hingegen wird von Trainingsdaten ausgegangen, die nicht von Hand beschriftet wurden, und es wird versucht, inh\u00e4rente Muster in den Daten zu finden, die dann zur Bestimmung des korrekten Ausgabewerts f\u00fcr neue Dateninstanzen verwendet werden k\u00f6nnen. Eine k\u00fcrzlich erforschte Kombination aus beiden ist das halb\u00fcberwachte Lernen, bei dem eine Kombination aus gekennzeichneten und nicht gekennzeichneten Daten verwendet wird (in der Regel ein kleiner Satz gekennzeichneter Daten in Kombination mit einer gro\u00dfen Menge nicht gekennzeichneter Daten).", "token2charspan": [[0, 4], [5, 18], [19, 25], [26, 34], [35, 39], [40, 43], [44, 58], [59, 70], [70, 71], [72, 75], [76, 81], [82, 85], [86, 90], [91, 102], [103, 109], [109, 110], [111, 114], [115, 117], [118, 122], [123, 131], [131, 132], [133, 142], [143, 149], [150, 152], [153, 156], [157, 162], [163, 165], [166, 172], [172, 173], [174, 177], [178, 182], [183, 186], [187, 197], [198, 201], [202, 211], [212, 224], [225, 228], [229, 233], [234, 248], [249, 258], [259, 265], [266, 272], [272, 273], [274, 278], [279, 287], [288, 298], [299, 310], [311, 314], [315, 321], [322, 325], [326, 329], [330, 344], [345, 351], [351, 352], [353, 356], [357, 360], [361, 365], [366, 377], [378, 381], [382, 398], [399, 402], [403, 408], [409, 425], [426, 431], [432, 441], [442, 446], [447, 448], [448, 450], [451, 454], [455, 460], [461, 464], [465, 472], [473, 477], [478, 494], [495, 500], [501, 503], [504, 515], [516, 519], [520, 525], [526, 532], [533, 538], [539, 544], [545, 561], [562, 567], [567, 568], [568, 569]]}
{"doc_key": "ai-dev-21", "ner": [[24, 24, "organisation"], [22, 22, "product"], [29, 30, "organisation"], [27, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 22, 24, 24, "artifact", "", false, false], [29, 30, 27, 27, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Abgesehen", "von", "diesen", "humanoiden", "Robotern", "f\u00fcr", "utilitaristische", "Zwecke", "gibt", "es", "auch", "einige", "humanoide", "Roboter", ",", "die", "der", "Unterhaltung", "dienen", ",", "wie", "der", "QRIO", "von", "Sony", "und", "der", "RoboSapien", "von", "Wow", "Wee", "."], "sentence-detokenized": "Abgesehen von diesen humanoiden Robotern f\u00fcr utilitaristische Zwecke gibt es auch einige humanoide Roboter, die der Unterhaltung dienen, wie der QRIO von Sony und der RoboSapien von Wow Wee.", "token2charspan": [[0, 9], [10, 13], [14, 20], [21, 31], [32, 40], [41, 44], [45, 61], [62, 68], [69, 73], [74, 76], [77, 81], [82, 88], [89, 98], [99, 106], [106, 107], [108, 111], [112, 115], [116, 128], [129, 135], [135, 136], [137, 140], [141, 144], [145, 149], [150, 153], [154, 158], [159, 162], [163, 166], [167, 177], [178, 181], [182, 185], [186, 189], [189, 190]]}
{"doc_key": "ai-dev-22", "ner": [[0, 0, "researcher"], [6, 13, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 13, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Webber", "wurde", "1991", "zum", "Fellow", "der", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "ernannt", ","], "sentence-detokenized": "Webber wurde 1991 zum Fellow der Association for the Advancement of Artificial Intelligence ernannt,", "token2charspan": [[0, 6], [7, 12], [13, 17], [18, 21], [22, 28], [29, 32], [33, 44], [45, 48], [49, 52], [53, 64], [65, 67], [68, 78], [79, 91], [92, 99], [99, 100]]}
{"doc_key": "ai-dev-23", "ner": [[14, 16, "task"]], "ner_mapping_to_source": [2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Mit", "diesem", "Unternehmen", "entwickelte", "er", "Data-Mining-", "und", "Datenbanktechnologie", ",", "insbesondere", "High-Level-Ontologien", "f\u00fcr", "Intelligenz", "und", "automatisiertes", "nat\u00fcrliches", "Sprachverst\u00e4ndnis", "."], "sentence-detokenized": "Mit diesem Unternehmen entwickelte er Data-Mining- und Datenbanktechnologie, insbesondere High-Level-Ontologien f\u00fcr Intelligenz und automatisiertes nat\u00fcrliches Sprachverst\u00e4ndnis.", "token2charspan": [[0, 3], [4, 10], [11, 22], [23, 34], [35, 37], [38, 50], [51, 54], [55, 75], [75, 76], [77, 89], [90, 111], [112, 115], [116, 127], [128, 131], [132, 147], [148, 159], [160, 177], [177, 178]]}
{"doc_key": "ai-dev-24", "ner": [[20, 21, "misc"], [24, 28, "misc"], [30, 31, "misc"], [33, 33, "country"], [36, 38, "organisation"], [40, 40, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 21, 33, 33, "physical", "", false, false], [24, 28, 33, 33, "physical", "", false, false], [30, 31, 33, 33, "physical", "", false, false], [36, 38, 40, 40, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "den", "letzten", "Jahren", "sind", "jedoch", "verschiedene", "elektronische", "Dienste", "und", "damit", "verbundene", "Initiativen", "in", "Entwicklungsl\u00e4ndern", "entstanden", ",", "z.", "B.", "das", "Projekt", "Nemmadi", ",", "das", "MCA", "21", "Mission", "Mode", "Project", "oder", "Digital", "India", "in", "Indien", ",", "das", "Electronic", "Government", "Directorate", "in", "Pakistan", "usw."], "sentence-detokenized": "In den letzten Jahren sind jedoch verschiedene elektronische Dienste und damit verbundene Initiativen in Entwicklungsl\u00e4ndern entstanden, z. B. das Projekt Nemmadi, das MCA21 Mission Mode Project oder Digital India in Indien, das Electronic Government Directorate in Pakistan usw.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 21], [22, 26], [27, 33], [34, 46], [47, 60], [61, 68], [69, 72], [73, 78], [79, 89], [90, 101], [102, 104], [105, 124], [125, 135], [135, 136], [137, 139], [140, 142], [143, 146], [147, 154], [155, 162], [162, 163], [164, 167], [168, 171], [171, 173], [174, 181], [182, 186], [187, 194], [195, 199], [200, 207], [208, 213], [214, 216], [217, 223], [223, 224], [225, 228], [229, 239], [240, 250], [251, 262], [263, 265], [266, 274], [275, 279]]}
{"doc_key": "ai-dev-25", "ner": [[1, 1, "misc"], [17, 17, "field"], [19, 19, "field"], [10, 12, "university"], [14, 15, "university"], [6, 9, "university"], [21, 21, "misc"], [30, 30, "field"], [24, 36, "misc"], [25, 25, "university"], [27, 28, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[1, 1, 17, 17, "topic", "", false, false], [1, 1, 19, 19, "topic", "", false, false], [1, 1, 10, 12, "origin", "", false, false], [10, 12, 14, 15, "part-of", "", false, false], [6, 9, 10, 12, "part-of", "", false, false], [21, 21, 30, 30, "topic", "", false, false], [21, 21, 25, 25, "origin", "", false, false], [24, 36, 25, 25, "origin", "", false, false], [25, 25, 27, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Er", "promovierte", "1979", "als", "Student", "des", "Indian", "Statistical", "Institute", "am", "Rajabazar", "Science", "College", "der", "Universit\u00e4t", "Kalkutta", "in", "Radiophysik", "und", "Elektronik", "und", "promovierte", "1982", "am", "Imperial", "College", "der", "Universit\u00e4t", "London", "in", "Elektrotechnik", "mit", "dem", "Diplom", "des", "Imperial", "College", "."], "sentence-detokenized": "Er promovierte 1979 als Student des Indian Statistical Institute am Rajabazar Science College der Universit\u00e4t Kalkutta in Radiophysik und Elektronik und promovierte 1982 am Imperial College der Universit\u00e4t London in Elektrotechnik mit dem Diplom des Imperial College.", "token2charspan": [[0, 2], [3, 14], [15, 19], [20, 23], [24, 31], [32, 35], [36, 42], [43, 54], [55, 64], [65, 67], [68, 77], [78, 85], [86, 93], [94, 97], [98, 109], [110, 118], [119, 121], [122, 133], [134, 137], [138, 148], [149, 152], [153, 164], [165, 169], [170, 172], [173, 181], [182, 189], [190, 193], [194, 205], [206, 212], [213, 215], [216, 230], [231, 234], [235, 238], [239, 245], [246, 249], [250, 258], [259, 266], [266, 267]]}
{"doc_key": "ai-dev-26", "ner": [[0, 2, "location"], [24, 26, "misc"], [30, 31, "misc"], [33, 35, "person"], [37, 38, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[24, 26, 0, 2, "temporal", "", false, false], [30, 31, 0, 2, "temporal", "", false, false], [33, 35, 30, 31, "role", "actor_in", false, false], [37, 38, 30, 31, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Die", "Expo", "II", "wurde", "als", "Schauplatz", "f\u00fcr", "die", "Weltpremiere", "mehrerer", "Filme", "angek\u00fcndigt", ",", "die", "noch", "nie", "zuvor", "in", "3D", "zu", "sehen", "waren", ",", "darunter", "The", "Diamond", "Wizard", "und", "der", "Universal-Kurzfilm", "Hawaiian", "Nights", "mit", "Mamie", "Van", "Doren", "und", "Pinky", "Lee", "."], "sentence-detokenized": "Die Expo II wurde als Schauplatz f\u00fcr die Weltpremiere mehrerer Filme angek\u00fcndigt, die noch nie zuvor in 3D zu sehen waren, darunter The Diamond Wizard und der Universal-Kurzfilm Hawaiian Nights mit Mamie Van Doren und Pinky Lee.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 17], [18, 21], [22, 32], [33, 36], [37, 40], [41, 53], [54, 62], [63, 68], [69, 80], [80, 81], [82, 85], [86, 90], [91, 94], [95, 100], [101, 103], [104, 106], [107, 109], [110, 115], [116, 121], [121, 122], [123, 131], [132, 135], [136, 143], [144, 150], [151, 154], [155, 158], [159, 177], [178, 186], [187, 193], [194, 197], [198, 203], [204, 207], [208, 213], [214, 217], [218, 223], [224, 227], [227, 228]]}
{"doc_key": "ai-dev-27", "ner": [[5, 6, "researcher"], [12, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 12, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Das", "Maximum-Subarray-Problem", "wurde", "1977", "von", "Ulf", "Grenander", "als", "vereinfachtes", "Modell", "f\u00fcr", "die", "Maximum-Likelihood-Sch\u00e4tzung", "von", "Mustern", "in", "digitalisierten", "Bildern", "vorgeschlagen", "."], "sentence-detokenized": "Das Maximum-Subarray-Problem wurde 1977 von Ulf Grenander als vereinfachtes Modell f\u00fcr die Maximum-Likelihood-Sch\u00e4tzung von Mustern in digitalisierten Bildern vorgeschlagen.", "token2charspan": [[0, 3], [4, 28], [29, 34], [35, 39], [40, 43], [44, 47], [48, 57], [58, 61], [62, 75], [76, 82], [83, 86], [87, 90], [91, 119], [120, 123], [124, 131], [132, 134], [135, 150], [151, 158], [159, 172], [172, 173]]}
{"doc_key": "ai-dev-28", "ner": [[1, 2, "product"], [5, 6, "product"], [9, 11, "product"], [14, 15, "product"], [18, 20, "product"], [23, 25, "product"], [36, 36, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[36, 36, 1, 2, "part-of", "", false, false], [36, 36, 5, 6, "part-of", "", false, false], [36, 36, 9, 11, "part-of", "", false, false], [36, 36, 14, 15, "part-of", "", false, false], [36, 36, 18, 20, "part-of", "", false, false], [36, 36, 23, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Das", "iPhone", "4S", ",", "das", "iPad", "3", ",", "das", "iPad", "Mini", "1G", ",", "das", "iPad", "Air", ",", "das", "iPad", "Pro", "1G", ",", "der", "iPod", "Touch", "5G", "und", "sp\u00e4tere", "Modelle", "verf\u00fcgen", "alle", "\u00fcber", "einen", "erweiterten", "Sprachassistenten", "namens", "Siri", "."], "sentence-detokenized": "Das iPhone 4S, das iPad 3, das iPad Mini 1G, das iPad Air, das iPad Pro 1G, der iPod Touch 5G und sp\u00e4tere Modelle verf\u00fcgen alle \u00fcber einen erweiterten Sprachassistenten namens Siri.", "token2charspan": [[0, 3], [4, 10], [11, 13], [13, 14], [15, 18], [19, 23], [24, 25], [25, 26], [27, 30], [31, 35], [36, 40], [41, 43], [43, 44], [45, 48], [49, 53], [54, 57], [57, 58], [59, 62], [63, 67], [68, 71], [72, 74], [74, 75], [76, 79], [80, 84], [85, 90], [91, 93], [94, 97], [98, 105], [106, 113], [114, 122], [123, 127], [128, 132], [133, 138], [139, 150], [151, 168], [169, 175], [176, 180], [180, 181]]}
{"doc_key": "ai-dev-29", "ner": [[8, 9, "metrics"], [12, 13, "metrics"], [15, 15, "metrics"], [34, 34, "metrics"], [39, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 13, 34, 34, "named", "", false, false], [15, 15, 12, 13, "named", "", false, false], [34, 34, 39, 39, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Es", "ist", "leicht", "zu", "\u00fcberpr\u00fcfen", ",", "dass", "der", "logistische", "Verlust", "und", "der", "bin\u00e4re", "Kreuzentropieverlust", "(", "Log-Verlust", ")", "in", "der", "Tat", "gleich", "sind", "(", "bis", "zu", "einer", "multiplikativen", "Konstante", "math\\", "frac", "{", "1}", "{", "Der", "Kreuzentropieverlust", "ist", "eng", "mit", "der", "Kullback-Leibler-Divergenz", "zwischen", "der", "empirischen", "Verteilung", "und", "der", "vorhergesagten", "Verteilung", "verbunden", "."], "sentence-detokenized": "Es ist leicht zu \u00fcberpr\u00fcfen, dass der logistische Verlust und der bin\u00e4re Kreuzentropieverlust (Log-Verlust) in der Tat gleich sind (bis zu einer multiplikativen Konstante math\\ frac {1} {Der Kreuzentropieverlust ist eng mit der Kullback-Leibler-Divergenz zwischen der empirischen Verteilung und der vorhergesagten Verteilung verbunden.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 16], [17, 27], [27, 28], [29, 33], [34, 37], [38, 49], [50, 57], [58, 61], [62, 65], [66, 72], [73, 93], [94, 95], [95, 106], [106, 107], [108, 110], [111, 114], [115, 118], [119, 125], [126, 130], [131, 132], [132, 135], [136, 138], [139, 144], [145, 160], [161, 170], [171, 176], [177, 181], [182, 183], [183, 185], [186, 187], [187, 190], [191, 211], [212, 215], [216, 219], [220, 223], [224, 227], [228, 254], [255, 263], [264, 267], [268, 279], [280, 290], [291, 294], [295, 298], [299, 313], [314, 324], [325, 334], [334, 335]]}
{"doc_key": "ai-dev-30", "ner": [[1, 1, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Der", "EM-Algorithmus", "wird", "verwendet", ",", "um", "(", "lokale", ")", "Maximum-Likelihood-Parameter", "eines", "statistischen", "Modells", "in", "F\u00e4llen", "zu", "finden", ",", "in", "denen", "die", "Gleichungen", "nicht", "direkt", "gel\u00f6st", "werden", "k\u00f6nnen", "."], "sentence-detokenized": "Der EM-Algorithmus wird verwendet, um (lokale) Maximum-Likelihood-Parameter eines statistischen Modells in F\u00e4llen zu finden, in denen die Gleichungen nicht direkt gel\u00f6st werden k\u00f6nnen.", "token2charspan": [[0, 3], [4, 18], [19, 23], [24, 33], [33, 34], [35, 37], [38, 39], [39, 45], [45, 46], [47, 75], [76, 81], [82, 95], [96, 103], [104, 106], [107, 113], [114, 116], [117, 123], [123, 124], [125, 127], [128, 133], [134, 137], [138, 149], [150, 155], [156, 162], [163, 169], [170, 176], [177, 183], [183, 184]]}
{"doc_key": "ai-dev-31", "ner": [[10, 10, "task"], [13, 15, "task"], [21, 21, "task"], [23, 26, "task"], [29, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Diese", "Forschung", "war", "grundlegend", "f\u00fcr", "die", "Entwicklung", "moderner", "Techniken", "der", "Sprachsynthese", ",", "von", "Leseger\u00e4ten", "f\u00fcr", "Blinde", ",", "f\u00fcr", "die", "Untersuchung", "der", "Sprachwahrnehmung", "und", "Spracherkennung", "sowie", "f\u00fcr", "die", "Entwicklung", "der", "motorischen", "Theorie", "der", "Sprachwahrnehmung", "."], "sentence-detokenized": "Diese Forschung war grundlegend f\u00fcr die Entwicklung moderner Techniken der Sprachsynthese, von Leseger\u00e4ten f\u00fcr Blinde, f\u00fcr die Untersuchung der Sprachwahrnehmung und Spracherkennung sowie f\u00fcr die Entwicklung der motorischen Theorie der Sprachwahrnehmung.", "token2charspan": [[0, 5], [6, 15], [16, 19], [20, 31], [32, 35], [36, 39], [40, 51], [52, 60], [61, 70], [71, 74], [75, 89], [89, 90], [91, 94], [95, 106], [107, 110], [111, 117], [117, 118], [119, 122], [123, 126], [127, 139], [140, 143], [144, 161], [162, 165], [166, 181], [182, 187], [188, 191], [192, 195], [196, 207], [208, 211], [212, 223], [224, 231], [232, 235], [236, 253], [253, 254]]}
{"doc_key": "ai-dev-32", "ner": [[7, 7, "product"], [1, 2, "misc"], [4, 6, "misc"], [10, 11, "misc"], [14, 14, "product"], [16, 16, "product"], [18, 18, "product"], [25, 25, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[1, 2, 7, 7, "origin", "", false, false], [1, 2, 10, 11, "type-of", "", false, false], [1, 2, 14, 14, "related-to", "program_for", false, false], [1, 2, 16, 16, "related-to", "program_for", false, false], [1, 2, 18, 18, "related-to", "program_for", false, false], [1, 2, 25, 25, "related-to", "program_for", false, false], [4, 6, 1, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Die", "integrierte", "Entwicklungsumgebung", "(", "IDE", ")", "von", "Arduino", "ist", "eine", "plattform\u00fcbergreifende", "Anwendung", "(", "f\u00fcr", "Windows", ",", "macOS", "und", "Linux", ")", ",", "die", "in", "der", "Programmiersprache", "Java", "geschrieben", "ist", "."], "sentence-detokenized": "Die integrierte Entwicklungsumgebung (IDE) von Arduino ist eine plattform\u00fcbergreifende Anwendung (f\u00fcr Windows, macOS und Linux), die in der Programmiersprache Java geschrieben ist.", "token2charspan": [[0, 3], [4, 15], [16, 36], [37, 38], [38, 41], [41, 42], [43, 46], [47, 54], [55, 58], [59, 63], [64, 86], [87, 96], [97, 98], [98, 101], [102, 109], [109, 110], [111, 116], [117, 120], [121, 126], [126, 127], [127, 128], [129, 132], [133, 135], [136, 139], [140, 158], [159, 163], [164, 175], [176, 179], [179, 180]]}
{"doc_key": "ai-dev-33", "ner": [[5, 6, "algorithm"], [14, 15, "field"], [17, 18, "researcher"], [20, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 14, 15, "opposite", "", false, false], [17, 18, 14, 15, "related-to", "works_with", false, false], [20, 21, 14, 15, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Die", "Forschung", "im", "Bereich", "der", "neuronalen", "Netze", "stagnierte", "nach", "der", "Ver\u00f6ffentlichung", "der", "Forschungen", "zum", "maschinellen", "Lernen", "von", "Marvin", "Minsky", "und", "Seymour", "Papert", "(", "1969", ")", "."], "sentence-detokenized": "Die Forschung im Bereich der neuronalen Netze stagnierte nach der Ver\u00f6ffentlichung der Forschungen zum maschinellen Lernen von Marvin Minsky und Seymour Papert (1969).", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 24], [25, 28], [29, 39], [40, 45], [46, 56], [57, 61], [62, 65], [66, 82], [83, 86], [87, 98], [99, 102], [103, 115], [116, 122], [123, 126], [127, 133], [134, 140], [141, 144], [145, 152], [153, 159], [160, 161], [161, 165], [165, 166], [166, 167]]}
{"doc_key": "ai-dev-34", "ner": [[18, 19, "organisation"], [21, 21, "organisation"], [24, 24, "country"], [26, 29, "organisation"], [32, 32, "country"], [34, 35, "organisation"], [38, 38, "country"], [40, 40, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[26, 29, 24, 24, "general-affiliation", "", false, false], [34, 35, 32, 32, "general-affiliation", "", false, false], [40, 40, 38, 38, "general-affiliation", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Nur", "einige", "wenige", "nicht-japanische", "Unternehmen", "konnten", "schlie\u00dflich", "auf", "diesem", "Markt", "\u00fcberleben", ",", "die", "wichtigsten", "von", "ihnen", "sind", ":", "Adept", "Technology", ",", "St\u00e4ubli", ",", "das", "schwedisch-schweizerische", "Unternehmen", "ABB", "Asea", "Brown", "Boveri", ",", "das", "deutsche", "Unternehmen", "KUKA", "Robotics", "und", "das", "italienische", "Unternehmen", "Comau", "."], "sentence-detokenized": "Nur einige wenige nicht-japanische Unternehmen konnten schlie\u00dflich auf diesem Markt \u00fcberleben, die wichtigsten von ihnen sind: Adept Technology, St\u00e4ubli, das schwedisch-schweizerische Unternehmen ABB Asea Brown Boveri, das deutsche Unternehmen KUKA Robotics und das italienische Unternehmen Comau.", "token2charspan": [[0, 3], [4, 10], [11, 17], [18, 34], [35, 46], [47, 54], [55, 66], [67, 70], [71, 77], [78, 83], [84, 93], [93, 94], [95, 98], [99, 110], [111, 114], [115, 120], [121, 125], [125, 126], [127, 132], [133, 143], [143, 144], [145, 152], [152, 153], [154, 157], [158, 183], [184, 195], [196, 199], [200, 204], [205, 210], [211, 217], [217, 218], [219, 222], [223, 231], [232, 243], [244, 248], [249, 257], [258, 261], [262, 265], [266, 278], [279, 290], [291, 296], [296, 297]]}
{"doc_key": "ai-dev-35", "ner": [[9, 9, "conference"], [13, 13, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 13, 9, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Zu", "den", "Forschungsaktivit\u00e4ten", "geh\u00f6rt", "eine", "j\u00e4hrliche", "Forschungskonferenz", ",", "das", "RuleML-Symposium", ",", "auch", "kurz", "RuleML", "genannt", "."], "sentence-detokenized": "Zu den Forschungsaktivit\u00e4ten geh\u00f6rt eine j\u00e4hrliche Forschungskonferenz, das RuleML-Symposium, auch kurz RuleML genannt.", "token2charspan": [[0, 2], [3, 6], [7, 28], [29, 35], [36, 40], [41, 50], [51, 70], [70, 71], [72, 75], [76, 92], [92, 93], [94, 98], [99, 103], [104, 110], [111, 118], [118, 119]]}
{"doc_key": "ai-dev-36", "ner": [[9, 9, "field"], [11, 11, "field"], [14, 14, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Konzepte", "werden", "als", "formale", "Werkzeuge", "oder", "Modelle", "in", "der", "Mathematik", ",", "Informatik", ",", "in", "Datenbanken", "und", "in", "der", "k\u00fcnstlichen", "Intelligenz", "verwendet", ",", "wo", "sie", "manchmal", "als", "Klassen", ",", "Schemata", "oder", "Kategorien", "bezeichnet", "werden", "."], "sentence-detokenized": "Konzepte werden als formale Werkzeuge oder Modelle in der Mathematik, Informatik, in Datenbanken und in der k\u00fcnstlichen Intelligenz verwendet, wo sie manchmal als Klassen, Schemata oder Kategorien bezeichnet werden.", "token2charspan": [[0, 8], [9, 15], [16, 19], [20, 27], [28, 37], [38, 42], [43, 50], [51, 53], [54, 57], [58, 68], [68, 69], [70, 80], [80, 81], [82, 84], [85, 96], [97, 100], [101, 103], [104, 107], [108, 119], [120, 131], [132, 141], [141, 142], [143, 145], [146, 149], [150, 158], [159, 162], [163, 170], [170, 171], [172, 180], [181, 185], [186, 196], [197, 207], [208, 214], [214, 215]]}
{"doc_key": "ai-dev-37", "ner": [[0, 6, "organisation"], [9, 12, "organisation"], [15, 15, "organisation"], [18, 20, "organisation"], [23, 25, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Er", "wurde", "von", "der", "American", "Psychological", "Association", ",", "der", "National", "Academy", "of", "Sciences", ",", "der", "Royal", ",", "der", "Cognitive", "Neuroscience", "Society", "und", "der", "American", "Humanist", "Association", "ausgezeichnet", "."], "sentence-detokenized": "Er wurde von der American Psychological Association, der National Academy of Sciences, der Royal, der Cognitive Neuroscience Society und der American Humanist Association ausgezeichnet.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 16], [17, 25], [26, 39], [40, 51], [51, 52], [53, 56], [57, 65], [66, 73], [74, 76], [77, 85], [85, 86], [87, 90], [91, 96], [96, 97], [98, 101], [102, 111], [112, 124], [125, 132], [133, 136], [137, 140], [141, 149], [150, 158], [159, 170], [171, 184], [184, 185]]}
{"doc_key": "ai-dev-38", "ner": [[3, 4, "person"], [6, 7, "person"], [9, 10, "person"], [17, 18, "person"], [21, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[21, 27, 17, 18, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Der", "Film", "mit", "Harrison", "Ford", ",", "Rutger", "Hauer", "und", "Sean", "Young", "in", "den", "Hauptrollen", "basiert", "lose", "auf", "Philip", "K.", "Dicks", "Roman", "Do", "Androids", "Dream", "of", "Electric", "Sheep", "?", "(", "1968", ")", "."], "sentence-detokenized": "Der Film mit Harrison Ford, Rutger Hauer und Sean Young in den Hauptrollen basiert lose auf Philip K. Dicks Roman Do Androids Dream of Electric Sheep? (1968).", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 21], [22, 26], [26, 27], [28, 34], [35, 40], [41, 44], [45, 49], [50, 55], [56, 58], [59, 62], [63, 74], [75, 82], [83, 87], [88, 91], [92, 98], [99, 101], [102, 107], [108, 113], [114, 116], [117, 125], [126, 131], [132, 134], [135, 143], [144, 149], [149, 150], [151, 152], [152, 156], [156, 157], [157, 158]]}
{"doc_key": "ai-dev-39", "ner": [[0, 1, "task"], [5, 6, "algorithm"], [11, 11, "field"], [14, 14, "task"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 6, "usage", "", false, false], [0, 1, 11, 11, "part-of", "task_part_of_field", false, false], [0, 1, 14, 14, "part-of", "task_part_of_field", false, false], [0, 1, 17, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Die", "Bildsegmentierung", "mit", "Hilfe", "von", "k-means-Clustering-Algorithmen", "wird", "seit", "langem", "f\u00fcr", "die", "Mustererkennung", ",", "die", "Objekterkennung", "und", "die", "medizinische", "Bildgebung", "verwendet", "."], "sentence-detokenized": "Die Bildsegmentierung mit Hilfe von k-means-Clustering-Algorithmen wird seit langem f\u00fcr die Mustererkennung, die Objekterkennung und die medizinische Bildgebung verwendet.", "token2charspan": [[0, 3], [4, 21], [22, 25], [26, 31], [32, 35], [36, 66], [67, 71], [72, 76], [77, 83], [84, 87], [88, 91], [92, 107], [107, 108], [109, 112], [113, 128], [129, 132], [133, 136], [137, 149], [150, 160], [161, 170], [170, 171]]}
{"doc_key": "ai-dev-40", "ner": [[14, 14, "algorithm"], [17, 17, "algorithm"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Allgemeine", "Stichproben", "aus", "der", "abgeschnittenen", "Normalen", "k\u00f6nnen", "mit", "Hilfe", "von", "Ann\u00e4herungen", "an", "die", "normale", "CDF", "und", "die", "Probit-Funktion", "erzielt", "werden", ",", "und", "R", "verf\u00fcgt", "\u00fcber", "eine", "Funktion", "codertnorm", "(", ")", "/", "code", "zur", "Erzeugung", "von", "Stichproben", "aus", "der", "abgeschnittenen", "Normalen", "."], "sentence-detokenized": "Allgemeine Stichproben aus der abgeschnittenen Normalen k\u00f6nnen mit Hilfe von Ann\u00e4herungen an die normale CDF und die Probit-Funktion erzielt werden, und R verf\u00fcgt \u00fcber eine Funktion codertnorm () / code zur Erzeugung von Stichproben aus der abgeschnittenen Normalen.", "token2charspan": [[0, 10], [11, 22], [23, 26], [27, 30], [31, 46], [47, 55], [56, 62], [63, 66], [67, 72], [73, 76], [77, 89], [90, 92], [93, 96], [97, 104], [105, 108], [109, 112], [113, 116], [117, 132], [133, 140], [141, 147], [147, 148], [149, 152], [153, 154], [155, 162], [163, 167], [168, 172], [173, 181], [182, 192], [193, 194], [194, 195], [196, 197], [198, 202], [203, 206], [207, 216], [217, 220], [221, 232], [233, 236], [237, 240], [241, 256], [257, 265], [265, 266]]}
{"doc_key": "ai-dev-41", "ner": [[6, 7, "university"], [9, 9, "university"], [11, 12, "university"], [14, 16, "university"], [19, 20, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Au\u00dferdem", "erhielt", "er", "die", "Ehrendoktorw\u00fcrde", "der", "Universit\u00e4ten", "Newcastle", ",", "Surrey", ",", "Tel", "Aviv", ",", "Simon", "Fraser", "University", "und", "der", "Universit\u00e4t", "Troms\u00f8", "."], "sentence-detokenized": "Au\u00dferdem erhielt er die Ehrendoktorw\u00fcrde der Universit\u00e4ten Newcastle, Surrey, Tel Aviv, Simon Fraser University und der Universit\u00e4t Troms\u00f8.", "token2charspan": [[0, 8], [9, 16], [17, 19], [20, 23], [24, 40], [41, 44], [45, 58], [59, 68], [68, 69], [70, 76], [76, 77], [78, 81], [82, 86], [86, 87], [88, 93], [94, 100], [101, 111], [112, 115], [116, 119], [120, 131], [132, 138], [138, 139]]}
{"doc_key": "ai-dev-42", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["Eine", "Java-Implementierung", ",", "die", "auf", "Null", "basierende", "Array-Indizes", "zusammen", "mit", "einer", "praktischen", "Methode", "zum", "Drucken", "der", "gel\u00f6sten", "Reihenfolge", "der", "Operationen", "verwendet", ":"], "sentence-detokenized": "Eine Java-Implementierung, die auf Null basierende Array-Indizes zusammen mit einer praktischen Methode zum Drucken der gel\u00f6sten Reihenfolge der Operationen verwendet:", "token2charspan": [[0, 4], [5, 25], [25, 26], [27, 30], [31, 34], [35, 39], [40, 50], [51, 64], [65, 73], [74, 77], [78, 83], [84, 95], [96, 103], [104, 107], [108, 115], [116, 119], [120, 128], [129, 140], [141, 144], [145, 156], [157, 166], [166, 167]]}
{"doc_key": "ai-dev-43", "ner": [[8, 8, "metrics"], [11, 11, "metrics"], [21, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 8, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Solche", "Netze", "werden", "in", "der", "Regel", "nach", "einem", "Cross-Entropie-", "(", "oder", "Cross-Entropie-", ")", "Verfahren", "trainiert", ",", "das", "eine", "nichtlineare", "Variante", "der", "multinomialen", "logistischen", "Regression", "darstellt", "."], "sentence-detokenized": "Solche Netze werden in der Regel nach einem Cross-Entropie- (oder Cross-Entropie-) Verfahren trainiert, das eine nichtlineare Variante der multinomialen logistischen Regression darstellt.", "token2charspan": [[0, 6], [7, 12], [13, 19], [20, 22], [23, 26], [27, 32], [33, 37], [38, 43], [44, 59], [60, 61], [61, 65], [66, 81], [81, 82], [83, 92], [93, 102], [102, 103], [104, 107], [108, 112], [113, 125], [126, 134], [135, 138], [139, 152], [153, 165], [166, 176], [177, 186], [186, 187]]}
{"doc_key": "ai-dev-44", "ner": [[1, 1, "conference"], [4, 4, "misc"], [5, 14, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 1, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Die", "ACL", "hat", "eine", "europ\u00e4ische", "Abteilung", "(", "European", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ")"], "sentence-detokenized": "Die ACL hat eine europ\u00e4ische Abteilung (European Chapter of the Association for Computational Linguistics)", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 16], [17, 28], [29, 38], [39, 40], [40, 48], [49, 56], [57, 59], [60, 63], [64, 75], [76, 79], [80, 93], [94, 105], [105, 106]]}
{"doc_key": "ai-dev-45", "ner": [[3, 4, "researcher"], [6, 8, "researcher"], [29, 29, "misc"], [31, 33, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 29, 29, "role", "", false, false], [6, 8, 29, 29, "role", "", false, false], [29, 29, 31, 33, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Zwei", "Professoren", ",", "Hal", "Abelson", "und", "Gerald", "Jay", "Sussman", ",", "zogen", "es", "vor", ",", "neutral", "zu", "bleiben", "-", "ihre", "Gruppe", "wurde", "in", "den", "folgenden", "30", "Jahren", "unter", "den", "Namen", "Schweiz", "und", "Projekt", "MAC", "gef\u00fchrt", "."], "sentence-detokenized": "Zwei Professoren, Hal Abelson und Gerald Jay Sussman, zogen es vor, neutral zu bleiben - ihre Gruppe wurde in den folgenden 30 Jahren unter den Namen Schweiz und Projekt MAC gef\u00fchrt.", "token2charspan": [[0, 4], [5, 16], [16, 17], [18, 21], [22, 29], [30, 33], [34, 40], [41, 44], [45, 52], [52, 53], [54, 59], [60, 62], [63, 66], [66, 67], [68, 75], [76, 78], [79, 86], [87, 88], [89, 93], [94, 100], [101, 106], [107, 109], [110, 113], [114, 123], [124, 126], [127, 133], [134, 139], [140, 143], [144, 149], [150, 157], [158, 161], [162, 169], [170, 173], [174, 181], [181, 182]]}
{"doc_key": "ai-dev-46", "ner": [[2, 2, "misc"], [4, 4, "researcher"], [8, 10, "university"], [15, 15, "organisation"], [19, 21, "organisation"], [23, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 4, 4, "temporal", "", false, false], [4, 4, 15, 15, "physical", "", false, false], [4, 4, 15, 15, "role", "", false, false], [4, 4, 19, 21, "role", "", false, false], [19, 21, 8, 10, "part-of", "", false, false], [23, 25, 19, 21, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Nach", "seiner", "Promotion", "wechselte", "Ghahramani", "1995", "an", "die", "Universit\u00e4t", "von", "Toronto", ",", "wo", "er", "als", "ITRC", "Postdoctoral", "Fellow", "im", "Artificial", "Intelligence", "Lab", "mit", "Geoffrey", "Hinton", "zusammenarbeitete", "."], "sentence-detokenized": "Nach seiner Promotion wechselte Ghahramani 1995 an die Universit\u00e4t von Toronto, wo er als ITRC Postdoctoral Fellow im Artificial Intelligence Lab mit Geoffrey Hinton zusammenarbeitete.", "token2charspan": [[0, 4], [5, 11], [12, 21], [22, 31], [32, 42], [43, 47], [48, 50], [51, 54], [55, 66], [67, 70], [71, 78], [78, 79], [80, 82], [83, 85], [86, 89], [90, 94], [95, 107], [108, 114], [115, 117], [118, 128], [129, 141], [142, 145], [146, 149], [150, 158], [159, 165], [166, 183], [183, 184]]}
{"doc_key": "ai-dev-47", "ner": [[24, 27, "metrics"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sp\u00e4tere", "Arbeiten", "konzentrierten", "sich", "auf", "die", "L\u00f6sung", "dieser", "Probleme", ",", "aber", "erst", "mit", "dem", "Aufkommen", "des", "modernen", "Computers", "und", "der", "Popularisierung", "der", "Maximum-Likelihood-Parametrisierungstechniken", "(", "MLE", ")", "nahm", "die", "Forschung", "richtig", "Fahrt", "auf", "."], "sentence-detokenized": "Sp\u00e4tere Arbeiten konzentrierten sich auf die L\u00f6sung dieser Probleme, aber erst mit dem Aufkommen des modernen Computers und der Popularisierung der Maximum-Likelihood-Parametrisierungstechniken (MLE) nahm die Forschung richtig Fahrt auf.", "token2charspan": [[0, 7], [8, 16], [17, 31], [32, 36], [37, 40], [41, 44], [45, 51], [52, 58], [59, 67], [67, 68], [69, 73], [74, 78], [79, 82], [83, 86], [87, 96], [97, 100], [101, 109], [110, 119], [120, 123], [124, 127], [128, 143], [144, 147], [148, 193], [194, 195], [195, 198], [198, 199], [200, 204], [205, 208], [209, 218], [219, 226], [227, 232], [233, 236], [236, 237]]}
{"doc_key": "ai-dev-48", "ner": [[4, 5, "person"], [11, 12, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Die", "Serie", "wurde", "von", "David", "Fincher", "produziert", ",", "die", "Hauptrolle", "spielte", "Kevin", "Spacey", "."], "sentence-detokenized": "Die Serie wurde von David Fincher produziert, die Hauptrolle spielte Kevin Spacey.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 19], [20, 25], [26, 33], [34, 44], [44, 45], [46, 49], [50, 60], [61, 68], [69, 74], [75, 81], [81, 82]]}
{"doc_key": "ai-dev-49", "ner": [[13, 13, "metrics"], [27, 29, "algorithm"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Aufgrund", "der", "begrenzten", "Rechenleistung", "m\u00fcssen", "die", "derzeitigen", "In-silico-Methoden", "in", "der", "Regel", "Geschwindigkeit", "gegen", "Genauigkeit", "eintauschen", ",", "z.", "B.", "durch", "den", "Einsatz", "schneller", "Protein-Docking-Methoden", "anstelle", "von", "rechenintensiven", "Berechnungen", "der", "freien", "Energie", "."], "sentence-detokenized": "Aufgrund der begrenzten Rechenleistung m\u00fcssen die derzeitigen In-silico-Methoden in der Regel Geschwindigkeit gegen Genauigkeit eintauschen, z. B. durch den Einsatz schneller Protein-Docking-Methoden anstelle von rechenintensiven Berechnungen der freien Energie.", "token2charspan": [[0, 8], [9, 12], [13, 23], [24, 38], [39, 45], [46, 49], [50, 61], [62, 80], [81, 83], [84, 87], [88, 93], [94, 109], [110, 115], [116, 127], [128, 139], [139, 140], [141, 143], [144, 146], [147, 152], [153, 156], [157, 164], [165, 174], [175, 199], [200, 208], [209, 212], [213, 229], [230, 242], [243, 246], [247, 253], [254, 261], [261, 262]]}
{"doc_key": "ai-dev-50", "ner": [[7, 7, "country"], [9, 9, "country"], [11, 11, "country"], [13, 13, "country"], [15, 15, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Es", "hatte", "\u00fcber", "30", "Standorte", "in", "den", "USA", ",", "Kanada", ",", "Mexiko", ",", "Brasilien", "und", "Argentinien", "."], "sentence-detokenized": "Es hatte \u00fcber 30 Standorte in den USA, Kanada, Mexiko, Brasilien und Argentinien.", "token2charspan": [[0, 2], [3, 8], [9, 13], [14, 16], [17, 26], [27, 29], [30, 33], [34, 37], [37, 38], [39, 45], [45, 46], [47, 53], [53, 54], [55, 64], [65, 68], [69, 80], [80, 81]]}
{"doc_key": "ai-dev-51", "ner": [[8, 8, "product"], [10, 12, "algorithm"], [19, 19, "task"], [21, 21, "task"], [25, 25, "product"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[8, 8, 10, 12, "usage", "", false, false], [19, 19, 25, 25, "related-to", "performs", false, false], [21, 21, 25, 25, "related-to", "performs", false, false]], "relations_mapping_to_source": [1, 3, 5], "sentence": ["Ein", "Beispiel", "f\u00fcr", "eine", "typische", "Bildverarbeitungspipeline", "f\u00fcr", "ein", "Gesichtserkennungssystem", "mit", "k", "-", "NN", ",", "einschlie\u00dflich", "der", "Vorverarbeitungsschritte", "f\u00fcr", "die", "Merkmalsextraktion", "und", "Dimensionsreduktion", "(", "normalerweise", "mit", "OpenCV", "implementiert", ")", ":"], "sentence-detokenized": "Ein Beispiel f\u00fcr eine typische Bildverarbeitungspipeline f\u00fcr ein Gesichtserkennungssystem mit k -NN, einschlie\u00dflich der Vorverarbeitungsschritte f\u00fcr die Merkmalsextraktion und Dimensionsreduktion (normalerweise mit OpenCV implementiert):", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 21], [22, 30], [31, 56], [57, 60], [61, 64], [65, 89], [90, 93], [94, 95], [96, 97], [97, 99], [99, 100], [101, 115], [116, 119], [120, 144], [145, 148], [149, 152], [153, 171], [172, 175], [176, 195], [196, 197], [197, 210], [211, 214], [215, 221], [222, 235], [235, 236], [236, 237]]}
{"doc_key": "ai-dev-52", "ner": [[10, 10, "algorithm"], [12, 12, "misc"], [14, 14, "misc"], [16, 16, "misc"], [20, 20, "programlang"], [22, 22, "product"], [26, 27, "algorithm"], [30, 30, "misc"], [32, 32, "misc"], [34, 34, "misc"], [36, 36, "misc"], [42, 42, "misc"], [45, 45, "misc"], [47, 47, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [], "relations_mapping_to_source": [], "sentence": ["Es", "verf\u00fcgt", "\u00fcber", "eine", "Vielzahl", "von", "Funktionen", ",", "Bibliotheken", "f\u00fcr", "Constraint-Logik-Programmierung", ",", "Multithreading", ",", "Unit-Tests", ",", "GUI", ",", "Schnittstellen", "zu", "Java", ",", "ODBC", "und", "anderen", ",", "literate", "Programmierung", ",", "einen", "Web-Server", ",", "SGML", ",", "RDF", ",", "RDFS", ",", "Entwickler-Tools", "(", "einschlie\u00dflich", "einer", "IDE", "mit", "einem", "GUI-Debugger", "und", "GUI-Profiler", ")", "und", "eine", "umfangreiche", "Dokumentation", "."], "sentence-detokenized": "Es verf\u00fcgt \u00fcber eine Vielzahl von Funktionen, Bibliotheken f\u00fcr Constraint-Logik-Programmierung, Multithreading, Unit-Tests, GUI, Schnittstellen zu Java, ODBC und anderen, literate Programmierung, einen Web-Server, SGML, RDF, RDFS, Entwickler-Tools (einschlie\u00dflich einer IDE mit einem GUI-Debugger und GUI-Profiler) und eine umfangreiche Dokumentation.", "token2charspan": [[0, 2], [3, 10], [11, 15], [16, 20], [21, 29], [30, 33], [34, 44], [44, 45], [46, 58], [59, 62], [63, 94], [94, 95], [96, 110], [110, 111], [112, 122], [122, 123], [124, 127], [127, 128], [129, 143], [144, 146], [147, 151], [151, 152], [153, 157], [158, 161], [162, 169], [169, 170], [171, 179], [180, 194], [194, 195], [196, 201], [202, 212], [212, 213], [214, 218], [218, 219], [220, 223], [223, 224], [225, 229], [229, 230], [231, 247], [248, 249], [249, 263], [264, 269], [270, 273], [274, 277], [278, 283], [284, 296], [297, 300], [301, 313], [313, 314], [315, 318], [319, 323], [324, 336], [337, 350], [350, 351]]}
{"doc_key": "ai-dev-53", "ner": [[2, 3, "field"], [6, 6, "field"], [11, 11, "misc"], [14, 16, "misc"], [17, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 11, 2, 3, "part-of", "", true, false], [11, 11, 6, 6, "part-of", "", false, false], [11, 11, 17, 18, "type-of", "", false, false], [14, 16, 2, 3, "part-of", "", false, false], [14, 16, 6, 6, "part-of", "", false, false], [14, 16, 17, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "der", "Computer", "Vision", "und", "der", "Bildverarbeitung", "ist", "der", "Begriff", "der", "Skalenraumdarstellung", "und", "der", "Gau\u00dfschen", "Ableitungsoperatoren", "eine", "kanonische", "Multiskalendarstellung", "."], "sentence-detokenized": "In der Computer Vision und der Bildverarbeitung ist der Begriff der Skalenraumdarstellung und der Gau\u00dfschen Ableitungsoperatoren eine kanonische Multiskalendarstellung.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 22], [23, 26], [27, 30], [31, 47], [48, 51], [52, 55], [56, 63], [64, 67], [68, 89], [90, 93], [94, 97], [98, 107], [108, 128], [129, 133], [134, 144], [145, 167], [167, 168]]}
{"doc_key": "ai-dev-54", "ner": [[5, 9, "organisation"], [18, 24, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 9, 18, 24, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Er", "ist", "au\u00dferdem", "Pr\u00e4sident", "der", "Neural", "Information", "Processing", "Systems", "Foundation", ",", "einer", "gemeinn\u00fctzigen", "Organisation", ",", "die", "die", "j\u00e4hrliche", "Conference", "on", "Neural", "Information", "Processing", "Systems", "Conference", "leitet", "."], "sentence-detokenized": "Er ist au\u00dferdem Pr\u00e4sident der Neural Information Processing Systems Foundation, einer gemeinn\u00fctzigen Organisation, die die j\u00e4hrliche Conference on Neural Information Processing Systems Conference leitet.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 25], [26, 29], [30, 36], [37, 48], [49, 59], [60, 67], [68, 78], [78, 79], [80, 85], [86, 100], [101, 113], [113, 114], [115, 118], [119, 122], [123, 132], [133, 143], [144, 146], [147, 153], [154, 165], [166, 176], [177, 184], [185, 195], [196, 202], [202, 203]]}
{"doc_key": "ai-dev-55", "ner": [[3, 3, "task"], [6, 7, "metrics"], [9, 9, "misc"], [15, 15, "task"], [17, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 6, 7, "usage", "", false, false], [6, 7, 9, 9, "type-of", "", false, false], [15, 15, 17, 17, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Bei", "Problemen", "der", "Regressionsanalyse", "kann", "der", "quadrierte", "Fehler", "als", "Verlustfunktion", "verwendet", "werden", ",", "bei", "der", "Klassifizierung", "die", "Kreuzentropie", "."], "sentence-detokenized": "Bei Problemen der Regressionsanalyse kann der quadrierte Fehler als Verlustfunktion verwendet werden, bei der Klassifizierung die Kreuzentropie.", "token2charspan": [[0, 3], [4, 13], [14, 17], [18, 36], [37, 41], [42, 45], [46, 56], [57, 63], [64, 67], [68, 83], [84, 93], [94, 100], [100, 101], [102, 105], [106, 109], [110, 125], [126, 129], [130, 143], [143, 144]]}
{"doc_key": "ai-dev-56", "ner": [[0, 1, "researcher"], [19, 22, "conference"], [24, 29, "conference"], [44, 44, "university"], [40, 43, "field"], [50, 54, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 19, 22, "role", "", false, false], [0, 1, 44, 44, "physical", "", false, false], [0, 1, 44, 44, "role", "", false, false], [0, 1, 50, 54, "role", "", false, false], [19, 22, 24, 29, "named", "same", false, false], [44, 44, 40, 43, "related-to", "subject_of_study_at", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Lafferty", "bekleidete", "viele", "prestigetr\u00e4chtige", "Positionen", ",", "darunter", ":", "1", ")", "Co-Vorsitzender", "des", "Programms", "und", "allgemeiner", "Co-Vorsitzender", "der", "Konferenzen", "der", "Neural", "Information", "Processing", "Systems", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", ")", "Foundation", ";", "2", ")", "Co-Direktor", "des", "neuen", "Ph.D.-Programms", "f\u00fcr", "Maschinelles", "Lernen", "an", "der", "CMU", ";", "3", ")", "Mitherausgeber", "des", "Journal", "of", "Machine", "Learning", "Research"], "sentence-detokenized": "Lafferty bekleidete viele prestigetr\u00e4chtige Positionen, darunter: 1) Co-Vorsitzender des Programms und allgemeiner Co-Vorsitzender der Konferenzen der Neural Information Processing Systems (Conference on Neural Information Processing Systems) Foundation; 2) Co-Direktor des neuen Ph.D.-Programms f\u00fcr Maschinelles Lernen an der CMU; 3) Mitherausgeber des Journal of Machine Learning Research", "token2charspan": [[0, 8], [9, 19], [20, 25], [26, 43], [44, 54], [54, 55], [56, 64], [64, 65], [66, 67], [67, 68], [69, 84], [85, 88], [89, 98], [99, 102], [103, 114], [115, 130], [131, 134], [135, 146], [147, 150], [151, 157], [158, 169], [170, 180], [181, 188], [189, 190], [190, 200], [201, 203], [204, 210], [211, 222], [223, 233], [234, 241], [241, 242], [243, 253], [253, 254], [255, 256], [256, 257], [258, 269], [270, 273], [274, 279], [280, 295], [296, 299], [300, 312], [313, 319], [320, 322], [323, 326], [327, 330], [330, 331], [332, 333], [333, 334], [335, 349], [350, 353], [354, 361], [362, 364], [365, 372], [373, 381], [382, 390]]}
{"doc_key": "ai-dev-57", "ner": [[0, 1, "misc"], [6, 6, "algorithm"], [8, 8, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 0, 1, "type-of", "", false, false], [8, 8, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Konvexe", "Algorithmen", ",", "wie", "z.", "B.", "AdaBoost", "und", "LogitBoost", ",", "k\u00f6nnen", "durch", "zuf\u00e4lliges", "Rauschen", "besiegt", "werden", ",", "so", "dass", "sie", "keine", "grundlegenden", "und", "erlernbaren", "Kombinationen", "schwacher", "Hypothesen", "lernen", "k\u00f6nnen", "."], "sentence-detokenized": "Konvexe Algorithmen, wie z.B. AdaBoost und LogitBoost, k\u00f6nnen durch zuf\u00e4lliges Rauschen besiegt werden, so dass sie keine grundlegenden und erlernbaren Kombinationen schwacher Hypothesen lernen k\u00f6nnen.", "token2charspan": [[0, 7], [8, 19], [19, 20], [21, 24], [25, 27], [27, 29], [30, 38], [39, 42], [43, 53], [53, 54], [55, 61], [62, 67], [68, 78], [79, 87], [88, 95], [96, 102], [102, 103], [104, 106], [107, 111], [112, 115], [116, 121], [122, 135], [136, 139], [140, 151], [152, 165], [166, 175], [176, 186], [187, 193], [194, 200], [200, 201]]}
{"doc_key": "ai-dev-58", "ner": [[0, 0, "product"], [3, 7, "product"], [14, 14, "algorithm"], [18, 18, "task"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 4, 5], "relations": [[0, 0, 3, 7, "type-of", "", false, false], [0, 0, 14, 14, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Apertium", "ist", "ein", "maschinelles", "\u00dcbersetzungssystem", "mit", "seichtem", "Transfer", ",", "das", "f\u00fcr", "alle", "lexikalischen", "Transformationen", "Finite-State-Transducer", "und", "f\u00fcr", "das", "Part-of-Speech-Tagging", "oder", "die", "Disambiguierung", "von", "Wortkategorien", "Hidden-Markov-Modelle", "verwendet", "."], "sentence-detokenized": "Apertium ist ein maschinelles \u00dcbersetzungssystem mit seichtem Transfer, das f\u00fcr alle lexikalischen Transformationen Finite-State-Transducer und f\u00fcr das Part-of-Speech-Tagging oder die Disambiguierung von Wortkategorien Hidden-Markov-Modelle verwendet.", "token2charspan": [[0, 8], [9, 12], [13, 16], [17, 29], [30, 48], [49, 52], [53, 61], [62, 70], [70, 71], [72, 75], [76, 79], [80, 84], [85, 98], [99, 115], [116, 139], [140, 143], [144, 147], [148, 151], [152, 174], [175, 179], [180, 183], [184, 199], [200, 203], [204, 218], [219, 240], [241, 250], [250, 251]]}
{"doc_key": "ai-dev-59", "ner": [[1, 2, "misc"], [13, 13, "metrics"], [27, 28, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 13, 13, "related-to", "", true, false], [13, 13, 27, 28, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Der", "nat\u00fcrliche", "Gradient", "von", "mathE", "f", "(x", ")", "/", "math", ",", "der", "der", "Fisher-Informationsmetrik", "entspricht", "(", "ein", "Ma\u00df", "f\u00fcr", "den", "Informationsabstand", "zwischen", "Wahrscheinlichkeitsverteilungen", "und", "die", "Kr\u00fcmmung", "der", "relativen", "Entropie", ")", ",", "lautet", "nun"], "sentence-detokenized": "Der nat\u00fcrliche Gradient von mathE f (x) / math, der der Fisher-Informationsmetrik entspricht (ein Ma\u00df f\u00fcr den Informationsabstand zwischen Wahrscheinlichkeitsverteilungen und die Kr\u00fcmmung der relativen Entropie), lautet nun", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 27], [28, 33], [34, 35], [36, 38], [38, 39], [40, 41], [42, 46], [46, 47], [48, 51], [52, 55], [56, 81], [82, 92], [93, 94], [94, 97], [98, 101], [102, 105], [106, 109], [110, 129], [130, 138], [139, 170], [171, 174], [175, 178], [179, 187], [188, 191], [192, 201], [202, 210], [210, 211], [211, 212], [213, 219], [220, 223]]}
{"doc_key": "ai-dev-60", "ner": [[1, 2, "programlang"], [6, 6, "product"], [8, 8, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 1, 2, "origin", "", false, false], [8, 8, 1, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Die", "Programmiersprache", "S", "inspirierte", "die", "Systeme", "S'-PLUS", "und", "R."], "sentence-detokenized": "Die Programmiersprache S inspirierte die Systeme S'-PLUS und R.", "token2charspan": [[0, 3], [4, 22], [23, 24], [25, 36], [37, 40], [41, 48], [49, 56], [57, 60], [61, 63]]}
{"doc_key": "ai-dev-61", "ner": [[4, 4, "product"], [9, 9, "product"], [11, 11, "product"], [16, 18, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 4, 9, 9, "named", "same", false, false], [11, 11, 9, 9, "origin", "derived_from", false, false], [11, 11, 16, 18, "origin", "", false, false], [11, 11, 20, 21, "origin", "", false, false], [11, 11, 23, 24, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Die", "einflussreichste", "Implementierung", "von", "Planner", "war", "die", "Teilmenge", "von", "Planner", ",", "Micro-Planner", "genannt", ",", "die", "von", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "und", "Terry", "Winograd", "implementiert", "wurde", "."], "sentence-detokenized": "Die einflussreichste Implementierung von Planner war die Teilmenge von Planner, Micro-Planner genannt, die von Gerald Jay Sussman, Eugene Charniak und Terry Winograd implementiert wurde.", "token2charspan": [[0, 3], [4, 20], [21, 36], [37, 40], [41, 48], [49, 52], [53, 56], [57, 66], [67, 70], [71, 78], [78, 79], [80, 93], [94, 101], [101, 102], [103, 106], [107, 110], [111, 117], [118, 121], [122, 129], [129, 130], [131, 137], [138, 146], [147, 150], [151, 156], [157, 165], [166, 179], [180, 185], [185, 186]]}
{"doc_key": "ai-dev-62", "ner": [[5, 5, "country"], [7, 9, "researcher"], [17, 17, "misc"], [18, 23, "university"], [31, 31, "misc"], [37, 37, "misc"], [43, 45, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "relations": [[7, 9, 5, 5, "general-affiliation", "from_country", false, false], [18, 23, 17, 17, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["Im", "Jahr", "1779", "gewann", "der", "deutsch-d\u00e4nische", "Wissenschaftler", "Christian", "Gottlieb", "Kratzenstein", "den", "ersten", "Preis", "in", "einem", "von", "der", "Russischen", "Kaiserlichen", "Akademie", "der", "Wissenschaften", "und", "K\u00fcnste", "ausgeschriebenen", "Wettbewerb", "f\u00fcr", "seine", "Modelle", "des", "menschlichen", "Vokaltrakts", ",", "die", "die", "f\u00fcnf", "langen", "Vokallaute", "(", "in", "der", "Notation", "des", "Internationalen", "Phonetischen", "Alphabets", ")", "erzeugen", "konnten", ":"], "sentence-detokenized": "Im Jahr 1779 gewann der deutsch-d\u00e4nische Wissenschaftler Christian Gottlieb Kratzenstein den ersten Preis in einem von der Russischen Kaiserlichen Akademie der Wissenschaften und K\u00fcnste ausgeschriebenen Wettbewerb f\u00fcr seine Modelle des menschlichen Vokaltrakts, die die f\u00fcnf langen Vokallaute (in der Notation des Internationalen Phonetischen Alphabets) erzeugen konnten:", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 19], [20, 23], [24, 40], [41, 56], [57, 66], [67, 75], [76, 88], [89, 92], [93, 99], [100, 105], [106, 108], [109, 114], [115, 118], [119, 122], [123, 133], [134, 146], [147, 155], [156, 159], [160, 174], [175, 178], [179, 185], [186, 202], [203, 213], [214, 217], [218, 223], [224, 231], [232, 235], [236, 248], [249, 260], [260, 261], [262, 265], [266, 269], [270, 274], [275, 281], [282, 292], [293, 294], [294, 296], [297, 300], [301, 309], [310, 313], [314, 329], [330, 342], [343, 352], [352, 353], [354, 362], [363, 370], [370, 371]]}
{"doc_key": "ai-dev-63", "ner": [[5, 6, "product"], [8, 9, "misc"], [12, 15, "misc"], [36, 36, "misc"], [61, 63, "task"], [67, 68, "product"], [70, 70, "product"], [73, 73, "task"], [75, 75, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 6, 67, 68, "related-to", "supports_program", false, false], [5, 6, 70, 70, "related-to", "supports_program", false, false], [8, 9, 5, 6, "part-of", "", false, false], [12, 15, 5, 6, "part-of", "", false, false], [36, 36, 5, 6, "part-of", "", false, false], [61, 63, 5, 6, "part-of", "", false, false], [73, 73, 5, 6, "part-of", "", false, false], [75, 75, 5, 6, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Zu", "den", "neuen", "Funktionen", "in", "Office", "XP", "geh\u00f6ren", "Smart", "Tags", ",", "eine", "auf", "Auswahl", "basierende", "Suchfunktion", ",", "die", "verschiedene", "Arten", "von", "Text", "in", "einem", "Dokument", "erkennt", ",", "so", "dass", "Benutzer", "zus\u00e4tzliche", "Aktionen", "durchf\u00fchren", "k\u00f6nnen", ";", "eine", "Aufgabenbereich-Oberfl\u00e4che", ",", "die", "g\u00e4ngige", "Men\u00fcleistenbefehle", "auf", "der", "rechten", "Seite", "des", "Bildschirms", "zusammenfasst", ",", "um", "den", "schnellen", "Zugriff", "darauf", "zu", "erleichtern", ";", "neue", "Funktionen", "f\u00fcr", "die", "Zusammenarbeit", "mit", "Dokumenten", ",", "Unterst\u00fctzung", "f\u00fcr", "MSN", "Groups", "und", "SharePoint", "sowie", "integrierte", "Handschrifterkennung", "und", "Spracherkennung", "."], "sentence-detokenized": "Zu den neuen Funktionen in Office XP geh\u00f6ren Smart Tags, eine auf Auswahl basierende Suchfunktion, die verschiedene Arten von Text in einem Dokument erkennt, so dass Benutzer zus\u00e4tzliche Aktionen durchf\u00fchren k\u00f6nnen; eine Aufgabenbereich-Oberfl\u00e4che, die g\u00e4ngige Men\u00fcleistenbefehle auf der rechten Seite des Bildschirms zusammenfasst, um den schnellen Zugriff darauf zu erleichtern; neue Funktionen f\u00fcr die Zusammenarbeit mit Dokumenten, Unterst\u00fctzung f\u00fcr MSN Groups und SharePoint sowie integrierte Handschrifterkennung und Spracherkennung.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 23], [24, 26], [27, 33], [34, 36], [37, 44], [45, 50], [51, 55], [55, 56], [57, 61], [62, 65], [66, 73], [74, 84], [85, 97], [97, 98], [99, 102], [103, 115], [116, 121], [122, 125], [126, 130], [131, 133], [134, 139], [140, 148], [149, 156], [156, 157], [158, 160], [161, 165], [166, 174], [175, 186], [187, 195], [196, 207], [208, 214], [214, 215], [216, 220], [221, 247], [247, 248], [249, 252], [253, 260], [261, 279], [280, 283], [284, 287], [288, 295], [296, 301], [302, 305], [306, 317], [318, 331], [331, 332], [333, 335], [336, 339], [340, 349], [350, 357], [358, 364], [365, 367], [368, 379], [379, 380], [381, 385], [386, 396], [397, 400], [401, 404], [405, 419], [420, 423], [424, 434], [434, 435], [436, 449], [450, 453], [454, 457], [458, 464], [465, 468], [469, 479], [480, 485], [486, 497], [498, 518], [519, 522], [523, 538], [538, 539]]}
{"doc_key": "ai-dev-64", "ner": [[9, 9, "algorithm"], [11, 11, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 9, 11, 11, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "vielen", "Anwendungen", "verwenden", "die", "Einheiten", "dieser", "Netze", "eine", "Sigmoidfunktion", "als", "Aktivierungsfunktion", "."], "sentence-detokenized": "In vielen Anwendungen verwenden die Einheiten dieser Netze eine Sigmoidfunktion als Aktivierungsfunktion.", "token2charspan": [[0, 2], [3, 9], [10, 21], [22, 31], [32, 35], [36, 45], [46, 52], [53, 58], [59, 63], [64, 79], [80, 83], [84, 104], [104, 105]]}
{"doc_key": "ai-dev-65", "ner": [[4, 4, "researcher"], [9, 14, "organisation"], [24, 30, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 9, 14, "role", "", false, false], [4, 4, 24, 30, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Im", "Jahr", "2001", "wurde", "Mehler", "zum", "ausl\u00e4ndischen", "Ehrenmitglied", "der", "American", "Academy", "of", "Arts", "and", "Sciences", "gew\u00e4hlt", ",", "und", "2003", "wurde", "er", "zum", "Fellow", "der", "American", "Association", "for", "the", "Advancement", "of", "Science", "ernannt", "."], "sentence-detokenized": "Im Jahr 2001 wurde Mehler zum ausl\u00e4ndischen Ehrenmitglied der American Academy of Arts and Sciences gew\u00e4hlt, und 2003 wurde er zum Fellow der American Association for the Advancement of Science ernannt.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 18], [19, 25], [26, 29], [30, 43], [44, 57], [58, 61], [62, 70], [71, 78], [79, 81], [82, 86], [87, 90], [91, 99], [100, 107], [107, 108], [109, 112], [113, 117], [118, 123], [124, 126], [127, 130], [131, 137], [138, 141], [142, 150], [151, 162], [163, 166], [167, 170], [171, 182], [183, 185], [186, 193], [194, 201], [201, 202]]}
{"doc_key": "ai-dev-66", "ner": [[5, 6, "task"], [9, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 9, 9, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Die", "Ausweitung", "dieses", "Konzepts", "auf", "nicht-bin\u00e4re", "Klassifikationen", "ergibt", "die", "Konfusionsmatrix", "."], "sentence-detokenized": "Die Ausweitung dieses Konzepts auf nicht-bin\u00e4re Klassifikationen ergibt die Konfusionsmatrix.", "token2charspan": [[0, 3], [4, 14], [15, 21], [22, 30], [31, 34], [35, 47], [48, 64], [65, 71], [72, 75], [76, 92], [92, 93]]}
{"doc_key": "ai-dev-67", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["Eine", "aktualisierte", "Sch\u00e4tzung", "der", "Varianz", "des", "Messrauschens", "kann", "aus", "der", "Maximum-Likelihood-Berechnung", "gewonnen", "werden"], "sentence-detokenized": "Eine aktualisierte Sch\u00e4tzung der Varianz des Messrauschens kann aus der Maximum-Likelihood-Berechnung gewonnen werden", "token2charspan": [[0, 4], [5, 18], [19, 28], [29, 32], [33, 40], [41, 44], [45, 58], [59, 63], [64, 67], [68, 71], [72, 101], [102, 110], [111, 117]]}
{"doc_key": "ai-dev-68", "ner": [[1, 2, "field"], [5, 5, "algorithm"], [9, 10, "field"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 9, 10, "usage", "", true, false], [5, 5, 12, 13, "related-to", "", true, false], [9, 10, 1, 2, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Beim", "maschinellen", "Lernen", "ist", "das", "Perzeptron", "ein", "Algorithmus", "f\u00fcr", "\u00fcberwachtes", "Lernen", "der", "bin\u00e4ren", "Klassifizierung", "."], "sentence-detokenized": "Beim maschinellen Lernen ist das Perzeptron ein Algorithmus f\u00fcr \u00fcberwachtes Lernen der bin\u00e4ren Klassifizierung.", "token2charspan": [[0, 4], [5, 17], [18, 24], [25, 28], [29, 32], [33, 43], [44, 47], [48, 59], [60, 63], [64, 75], [76, 82], [83, 86], [87, 94], [95, 110], [110, 111]]}
{"doc_key": "ai-dev-69", "ner": [[7, 9, "field"], [12, 12, "field"], [15, 20, "conference"], [22, 26, "conference"], [28, 34, "conference"], [36, 40, "conference"], [42, 46, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 20, 7, 9, "topic", "", false, false], [15, 20, 12, 12, "topic", "", false, false], [22, 26, 7, 9, "topic", "", false, false], [22, 26, 12, 12, "topic", "", false, false], [28, 34, 7, 9, "topic", "", false, false], [28, 34, 12, 12, "topic", "", false, false], [36, 40, 7, 9, "topic", "", false, false], [36, 40, 12, 12, "topic", "", false, false], [42, 46, 7, 9, "topic", "", false, false], [42, 46, 12, 12, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Sie", "war", "au\u00dferdem", "Area", "Chair", "mehrerer", "Konferenzen", "zum", "maschinellen", "Lernen", "und", "zur", "Bildverarbeitung", ",", "darunter", "Conference", "on", "Neural", "Information", "Processing", "Systems", ",", "International", "Conference", "on", "Learning", "Representations", ",", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "International", "Conference", "on", "Computer", "Vision", "und", "European", "Conference", "on", "Computer", "Vision", "."], "sentence-detokenized": "Sie war au\u00dferdem Area Chair mehrerer Konferenzen zum maschinellen Lernen und zur Bildverarbeitung, darunter Conference on Neural Information Processing Systems, International Conference on Learning Representations, Conference on Computer Vision and Pattern Recognition, International Conference on Computer Vision und European Conference on Computer Vision.", "token2charspan": [[0, 3], [4, 7], [8, 16], [17, 21], [22, 27], [28, 36], [37, 48], [49, 52], [53, 65], [66, 72], [73, 76], [77, 80], [81, 97], [97, 98], [99, 107], [108, 118], [119, 121], [122, 128], [129, 140], [141, 151], [152, 159], [159, 160], [161, 174], [175, 185], [186, 188], [189, 197], [198, 213], [213, 214], [215, 225], [226, 228], [229, 237], [238, 244], [245, 248], [249, 256], [257, 268], [268, 269], [270, 283], [284, 294], [295, 297], [298, 306], [307, 313], [314, 317], [318, 326], [327, 337], [338, 340], [341, 349], [350, 356], [356, 357]]}
{"doc_key": "ai-dev-70", "ner": [[1, 1, "algorithm"], [6, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 1, 1, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Der", "Kondensationsalgorithmus", "wurde", "auch", "f\u00fcr", "ein", "System", "zur", "Gesichtserkennung", "in", "einer", "Videosequenz", "verwendet", "."], "sentence-detokenized": "Der Kondensationsalgorithmus wurde auch f\u00fcr ein System zur Gesichtserkennung in einer Videosequenz verwendet.", "token2charspan": [[0, 3], [4, 28], [29, 34], [35, 39], [40, 43], [44, 47], [48, 54], [55, 58], [59, 76], [77, 79], [80, 85], [86, 98], [99, 108], [108, 109]]}
{"doc_key": "ai-dev-71", "ner": [[0, 3, "task"], [10, 10, "organisation"], [20, 20, "conference"], [28, 33, "academicjournal"], [26, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[20, 20, 0, 3, "topic", "", false, false], [20, 20, 10, 10, "origin", "", false, false], [28, 33, 0, 3, "topic", "", false, false], [28, 33, 10, 10, "origin", "", true, false], [26, 26, 28, 33, "role", "edited_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Die", "Verbreitung", "von", "Informationen", "geh\u00f6rt", "ebenfalls", "zu", "den", "Aufgaben", "von", "ELRA", ",", "die", "so", "wohl", "durch", "die", "Organisation", "der", "Konferenz", "LREC", "als", "auch", "durch", "die", "von", "Springer", "herausgegebene", "Zeitschrift", "Language", "Resources", "and", "Evaluation", "erfolgt", "."], "sentence-detokenized": "Die Verbreitung von Informationen geh\u00f6rt ebenfalls zu den Aufgaben von ELRA, die sowohl durch die Organisation der Konferenz LREC als auch durch die von Springer herausgegebene Zeitschrift Language Resources and Evaluation erfolgt.", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 33], [34, 40], [41, 50], [51, 53], [54, 57], [58, 66], [67, 70], [71, 75], [75, 76], [77, 80], [81, 83], [83, 87], [88, 93], [94, 97], [98, 110], [111, 114], [115, 124], [125, 129], [130, 133], [134, 138], [139, 144], [145, 148], [149, 152], [153, 161], [162, 176], [177, 188], [189, 197], [198, 207], [208, 211], [212, 222], [223, 230], [230, 231]]}
{"doc_key": "ai-dev-72", "ner": [[2, 7, "field"], [12, 12, "field"], [16, 16, "field"], [17, 18, "field"], [46, 46, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 7, 46, 46, "named", "", false, false], [16, 16, 2, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "der", "Theorie", "linearer", "zeitinvarianter", "Systeme", "(", "LTI", ")", ",", "in", "der", "Steuerungstheorie", "und", "in", "der", "digitalen", "Signalverarbeitung", "wird", "die", "Beziehung", "zwischen", "dem", "Eingangssignal", ",", "math\\", "displaystyle", "x", "(t", ")", "/", "math", ",", "und", "dem", "Ausgangssignal", ",", "math\\", "displaystyle", "y", "(t", ")", "/", "math", ",", "eines", "LTI-Systems", "durch", "eine", "Faltungsoperation", "bestimmt", ":"], "sentence-detokenized": "In der Theorie linearer zeitinvarianter Systeme (LTI), in der Steuerungstheorie und in der digitalen Signalverarbeitung wird die Beziehung zwischen dem Eingangssignal, math\\ displaystyle x (t) / math, und dem Ausgangssignal, math\\ displaystyle y (t) / math, eines LTI-Systems durch eine Faltungsoperation bestimmt:", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 23], [24, 39], [40, 47], [48, 49], [49, 52], [52, 53], [53, 54], [55, 57], [58, 61], [62, 79], [80, 83], [84, 86], [87, 90], [91, 100], [101, 119], [120, 124], [125, 128], [129, 138], [139, 147], [148, 151], [152, 166], [166, 167], [168, 173], [174, 186], [187, 188], [189, 191], [191, 192], [193, 194], [195, 199], [199, 200], [201, 204], [205, 208], [209, 223], [223, 224], [225, 230], [231, 243], [244, 245], [246, 248], [248, 249], [250, 251], [252, 256], [256, 257], [258, 263], [264, 275], [276, 281], [282, 286], [287, 304], [305, 313], [313, 314]]}
{"doc_key": "ai-dev-73", "ner": [[16, 16, "field"], [19, 19, "field"], [22, 23, "field"], [26, 26, "field"], [29, 30, "field"], [33, 33, "product"], [36, 36, "field"], [39, 39, "field"], [42, 43, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Aufgrund", "seiner", "Allgemeing\u00fcltigkeit", "wird", "das", "Gebiet", "in", "vielen", "anderen", "Disziplinen", "untersucht", ",", "z.", "B.", "in", "der", "Spieltheorie", ",", "der", "Kontrolltheorie", ",", "dem", "Operations", "Research", ",", "der", "Informationstheorie", ",", "der", "simulationsbasierten", "Optimierung", ",", "den", "Multiagentensystemen", ",", "der", "Schwarmintelligenz", ",", "der", "Statistik", "und", "den", "genetischen", "Algorithmen", "."], "sentence-detokenized": "Aufgrund seiner Allgemeing\u00fcltigkeit wird das Gebiet in vielen anderen Disziplinen untersucht, z. B. in der Spieltheorie, der Kontrolltheorie, dem Operations Research, der Informationstheorie, der simulationsbasierten Optimierung, den Multiagentensystemen, der Schwarmintelligenz, der Statistik und den genetischen Algorithmen.", "token2charspan": [[0, 8], [9, 15], [16, 35], [36, 40], [41, 44], [45, 51], [52, 54], [55, 61], [62, 69], [70, 81], [82, 92], [92, 93], [94, 96], [97, 99], [100, 102], [103, 106], [107, 119], [119, 120], [121, 124], [125, 140], [140, 141], [142, 145], [146, 156], [157, 165], [165, 166], [167, 170], [171, 190], [190, 191], [192, 195], [196, 216], [217, 228], [228, 229], [230, 233], [234, 254], [254, 255], [256, 259], [260, 278], [278, 279], [280, 283], [284, 293], [294, 297], [298, 301], [302, 313], [314, 325], [325, 326]]}
{"doc_key": "ai-dev-74", "ner": [[0, 2, "algorithm"], [18, 19, "field"], [27, 28, "algorithm"], [33, 34, "algorithm"], [37, 37, "algorithm"], [38, 40, "researcher"], [42, 43, "researcher"], [45, 47, "researcher"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[18, 19, 0, 2, "usage", "", true, false], [27, 28, 18, 19, "part-of", "", true, false], [33, 34, 18, 19, "part-of", "", true, false], [37, 37, 18, 19, "part-of", "", true, false]], "relations_mapping_to_source": [0, 2, 3, 4], "sentence": ["Der", "stochastische", "Gradientenabstieg", "ist", "ein", "beliebter", "Algorithmus", "f\u00fcr", "das", "Training", "einer", "breiten", "Palette", "von", "Modellen", "im", "Bereich", "des", "maschinellen", "Lernens", ",", "einschlie\u00dflich", "(", "linearer", ")", "Support-Vektor-Maschinen", ",", "logistischer", "Regression", "(", "siehe", "z.", "B.", "Vowpal", "Wabbit", ")", "und", "grafischer", "Modelle.Jenny", "Rose", "Finkel", ",", "Alex", "Kleeman", ",", "Christopher", "D.", "Manning", "(", "2008", ")", "."], "sentence-detokenized": "Der stochastische Gradientenabstieg ist ein beliebter Algorithmus f\u00fcr das Training einer breiten Palette von Modellen im Bereich des maschinellen Lernens, einschlie\u00dflich (linearer) Support-Vektor-Maschinen, logistischer Regression (siehe z. B. Vowpal Wabbit) und grafischer Modelle.Jenny Rose Finkel, Alex Kleeman, Christopher D. Manning (2008).", "token2charspan": [[0, 3], [4, 17], [18, 35], [36, 39], [40, 43], [44, 53], [54, 65], [66, 69], [70, 73], [74, 82], [83, 88], [89, 96], [97, 104], [105, 108], [109, 117], [118, 120], [121, 128], [129, 132], [133, 145], [146, 153], [153, 154], [155, 169], [170, 171], [171, 179], [179, 180], [181, 205], [205, 206], [207, 219], [220, 230], [231, 232], [232, 237], [238, 240], [241, 243], [244, 250], [251, 257], [257, 258], [259, 262], [263, 273], [274, 287], [288, 292], [293, 299], [299, 300], [301, 305], [306, 313], [313, 314], [315, 326], [327, 329], [330, 337], [338, 339], [339, 343], [343, 344], [344, 345]]}
{"doc_key": "ai-dev-75", "ner": [[8, 8, "organisation"], [46, 46, "product"], [12, 12, "country"], [15, 17, "university"], [19, 19, "location"], [22, 24, "university"], [26, 26, "location"], [29, 29, "university"], [31, 31, "location"], [34, 35, "university"], [37, 37, "location"], [40, 40, "university"], [42, 42, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 8, 15, 17, "role", "donates_to", false, false], [8, 8, 22, 24, "role", "donates_to", false, false], [8, 8, 29, 29, "role", "donates_to", false, false], [8, 8, 34, 35, "role", "donates_to", false, false], [8, 8, 40, 40, "role", "donates_to", false, false], [46, 46, 8, 8, "origin", "donates", true, false], [15, 17, 19, 19, "physical", "", false, false], [19, 19, 12, 12, "physical", "", false, false], [22, 24, 26, 26, "physical", "", false, false], [26, 26, 12, 12, "physical", "", false, false], [29, 29, 31, 31, "physical", "", false, false], [31, 31, 12, 12, "physical", "", false, false], [34, 35, 37, 37, "physical", "", false, false], [37, 37, 12, 12, "physical", "", false, false], [40, 40, 42, 42, "physical", "", false, false], [42, 42, 12, 12, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "sentence": ["Im", "August", "2011", "wurde", "bekannt", "gegeben", ",", "dass", "Hitachi", "f\u00fcnf", "Universit\u00e4ten", "in", "Indonesien", "(", "der", "Universit\u00e4t", "von", "Nordsumatra", "in", "Medan", ",", "der", "Indonesischen", "Christlichen", "Universit\u00e4t", "in", "Jakarta", ",", "der", "Padjadjaran-Universit\u00e4t", "in", "Bandung", ",", "der", "Jenderal", "Soedirman-Universit\u00e4t", "in", "Purwokerto", "und", "der", "Muhammadiyah-Universit\u00e4t", "in", "Malang", ")", "jeweils", "ein", "Elektronenmikroskop", "schenken", "wird", "."], "sentence-detokenized": "Im August 2011 wurde bekannt gegeben, dass Hitachi f\u00fcnf Universit\u00e4ten in Indonesien (der Universit\u00e4t von Nordsumatra in Medan, der Indonesischen Christlichen Universit\u00e4t in Jakarta, der Padjadjaran-Universit\u00e4t in Bandung, der Jenderal Soedirman-Universit\u00e4t in Purwokerto und der Muhammadiyah-Universit\u00e4t in Malang) jeweils ein Elektronenmikroskop schenken wird.", "token2charspan": [[0, 2], [3, 9], [10, 14], [15, 20], [21, 28], [29, 36], [36, 37], [38, 42], [43, 50], [51, 55], [56, 69], [70, 72], [73, 83], [84, 85], [85, 88], [89, 100], [101, 104], [105, 116], [117, 119], [120, 125], [125, 126], [127, 130], [131, 144], [145, 157], [158, 169], [170, 172], [173, 180], [180, 181], [182, 185], [186, 209], [210, 212], [213, 220], [220, 221], [222, 225], [226, 234], [235, 256], [257, 259], [260, 270], [271, 274], [275, 278], [279, 303], [304, 306], [307, 313], [313, 314], [315, 322], [323, 326], [327, 346], [347, 355], [356, 360], [360, 361]]}
{"doc_key": "ai-dev-76", "ner": [[2, 3, "field"], [5, 6, "algorithm"], [8, 9, "algorithm"], [13, 13, "metrics"]], "ner_mapping_to_source": [1, 2, 3, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Optimierungstechniken", "des", "Operations", "Research", "wie", "lineare", "Programmierung", "oder", "dynamische", "Programmierung", "sind", "aufgrund", "ihrer", "Rechenkomplexit\u00e4t", "f\u00fcr", "gro\u00dfe", "Software-Engineering-Probleme", "oft", "unpraktisch", "."], "sentence-detokenized": "Optimierungstechniken des Operations Research wie lineare Programmierung oder dynamische Programmierung sind aufgrund ihrer Rechenkomplexit\u00e4t f\u00fcr gro\u00dfe Software-Engineering-Probleme oft unpraktisch.", "token2charspan": [[0, 21], [22, 25], [26, 36], [37, 45], [46, 49], [50, 57], [58, 72], [73, 77], [78, 88], [89, 103], [104, 108], [109, 117], [118, 123], [124, 141], [142, 145], [146, 151], [152, 181], [182, 185], [186, 197], [197, 198]]}
{"doc_key": "ai-dev-77", "ner": [[0, 1, "metrics"], [7, 7, "metrics"], [10, 12, "metrics"], [16, 16, "metrics"], [20, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 7, 7, "compare", "", false, false], [0, 1, 10, 12, "compare", "", false, false], [16, 16, 10, 12, "part-of", "", false, false], [20, 22, 10, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Die", "Empfindlichkeit", "ist", "nicht", "dasselbe", "wie", "die", "Pr\u00e4zision", "oder", "der", "positive", "pr\u00e4diktive", "Wert", "(", "Verh\u00e4ltnis", "der", "RICHTIG-Positiven", "zu", "den", "kombinierten", "RICHTIG-", "und", "FALSCH-Positiven", ")", ",", "der", "ebenso", "viel", "\u00fcber", "den", "Anteil", "der", "tats\u00e4chlich", "positiven", "Ergebnisse", "in", "der", "getesteten", "Population", "aussagt", "wie", "\u00fcber", "den", "Test", "."], "sentence-detokenized": "Die Empfindlichkeit ist nicht dasselbe wie die Pr\u00e4zision oder der positive pr\u00e4diktive Wert (Verh\u00e4ltnis der RICHTIG-Positiven zu den kombinierten RICHTIG- und FALSCH-Positiven), der ebenso viel \u00fcber den Anteil der tats\u00e4chlich positiven Ergebnisse in der getesteten Population aussagt wie \u00fcber den Test.", "token2charspan": [[0, 3], [4, 19], [20, 23], [24, 29], [30, 38], [39, 42], [43, 46], [47, 56], [57, 61], [62, 65], [66, 74], [75, 85], [86, 90], [91, 92], [92, 102], [103, 106], [107, 124], [125, 127], [128, 131], [132, 144], [145, 153], [154, 157], [158, 174], [174, 175], [175, 176], [177, 180], [181, 187], [188, 192], [193, 197], [198, 201], [202, 208], [209, 212], [213, 224], [225, 234], [235, 245], [246, 248], [249, 252], [253, 263], [264, 274], [275, 282], [283, 286], [287, 291], [292, 295], [296, 300], [300, 301]]}
{"doc_key": "ai-dev-78", "ner": [[3, 4, "person"], [10, 10, "product"], [15, 15, "person"], [27, 27, "person"], [33, 34, "person"], [44, 45, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6], "relations": [[10, 10, 3, 4, "artifact", "", false, false], [33, 34, 44, 45, "role", "convinces", false, false], [44, 45, 10, 10, "role", "producer", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Das", "Drehbuch", "von", "Hampton", "Fancher", "!", "-", "-", "urspr\u00fcnglich", "nicht", "Android", "betitelt", "-", "Erkl\u00e4rung", "siehe", "Sammon", ",", "S.", "32", "und", "38", "-", "-", "wurde", "1977", "optioniert", ".", "Sammon", ",", "S.", "23-30", "Der", "Produzent", "Michael", "Deeley", "interessierte", "sich", "f\u00fcr", "Fanchers", "Entwurf", "und", "\u00fcberzeugte", "den", "Regisseur", "Ridley", "Scott", ",", "ihn", "zu", "verfilmen", "."], "sentence-detokenized": "Das Drehbuch von Hampton Fancher! -- urspr\u00fcnglich nicht Android betitelt - Erkl\u00e4rung siehe Sammon, S. 32 und 38 -- wurde 1977 optioniert. Sammon, S. 23-30 Der Produzent Michael Deeley interessierte sich f\u00fcr Fanchers Entwurf und \u00fcberzeugte den Regisseur Ridley Scott, ihn zu verfilmen.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 24], [25, 32], [32, 33], [34, 35], [35, 36], [37, 49], [50, 55], [56, 63], [64, 72], [73, 74], [75, 84], [85, 90], [91, 97], [97, 98], [99, 101], [102, 104], [105, 108], [109, 111], [112, 113], [113, 114], [115, 120], [121, 125], [126, 136], [136, 137], [138, 144], [144, 145], [146, 148], [149, 154], [155, 158], [159, 168], [169, 176], [177, 183], [184, 197], [198, 202], [203, 206], [207, 215], [216, 223], [224, 227], [228, 238], [239, 242], [243, 252], [253, 259], [260, 265], [265, 266], [267, 270], [271, 273], [274, 283], [283, 284]]}
{"doc_key": "ai-dev-79", "ner": [[0, 1, "field"], [4, 4, "task"], [7, 8, "task"], [12, 12, "misc"], [15, 15, "field"], [18, 18, "task"], [21, 21, "task"], [25, 27, "task"], [30, 30, "task"], [33, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10], "relations": [[4, 4, 0, 1, "part-of", "", false, false], [7, 8, 0, 1, "part-of", "", false, false], [12, 12, 0, 1, "part-of", "", false, false], [15, 15, 0, 1, "part-of", "", false, false], [18, 18, 0, 1, "part-of", "", false, false], [21, 21, 0, 1, "part-of", "", false, false], [25, 27, 0, 1, "part-of", "", false, false], [30, 30, 0, 1, "part-of", "", false, false], [33, 34, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 7, 8, 9], "sentence": ["Die", "Textanalyse", "umfasst", "die", "Informationsbeschaffung", ",", "die", "lexikalische", "Analyse", "zur", "Untersuchung", "von", "Worth\u00e4ufigkeitsverteilungen", ",", "die", "Mustererkennung", ",", "die", "Markierung/Anmerkung", ",", "die", "Informationsextraktion", ",", "Data-Mining-Techniken", "einschlie\u00dflich", "Link-", "und", "Assoziationsanalyse", ",", "die", "Visualisierung", "und", "die", "pr\u00e4diktive", "Analytik", "."], "sentence-detokenized": "Die Textanalyse umfasst die Informationsbeschaffung, die lexikalische Analyse zur Untersuchung von Worth\u00e4ufigkeitsverteilungen, die Mustererkennung, die Markierung/Anmerkung, die Informationsextraktion, Data-Mining-Techniken einschlie\u00dflich Link- und Assoziationsanalyse, die Visualisierung und die pr\u00e4diktive Analytik.", "token2charspan": [[0, 3], [4, 15], [16, 23], [24, 27], [28, 51], [51, 52], [53, 56], [57, 69], [70, 77], [78, 81], [82, 94], [95, 98], [99, 126], [126, 127], [128, 131], [132, 147], [147, 148], [149, 152], [153, 173], [173, 174], [175, 178], [179, 201], [201, 202], [203, 224], [225, 239], [240, 245], [246, 249], [250, 269], [269, 270], [271, 274], [275, 289], [290, 293], [294, 297], [298, 308], [309, 317], [317, 318]]}
{"doc_key": "ai-dev-80", "ner": [[3, 3, "product"], [11, 12, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 3, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Mehrere", "Metriken", "verwenden", "WordNet", ",", "eine", "manuell", "erstellte", "lexikalische", "Datenbank", "mit", "englischen", "W\u00f6rtern", "."], "sentence-detokenized": "Mehrere Metriken verwenden WordNet, eine manuell erstellte lexikalische Datenbank mit englischen W\u00f6rtern.", "token2charspan": [[0, 7], [8, 16], [17, 26], [27, 34], [34, 35], [36, 40], [41, 48], [49, 58], [59, 71], [72, 81], [82, 85], [86, 96], [97, 104], [104, 105]]}
{"doc_key": "ai-dev-81", "ner": [[9, 9, "field"], [12, 13, "task"], [16, 21, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Das", "System", "nutzt", "eine", "Kombination", "von", "Techniken", "aus", "der", "Computerlinguistik", ",", "dem", "Information", "Retrieval", "und", "der", "Wissensdarstellung", ",", "um", "Antworten", "zu", "finden", "."], "sentence-detokenized": "Das System nutzt eine Kombination von Techniken aus der Computerlinguistik, dem Information Retrieval und der Wissensdarstellung, um Antworten zu finden.", "token2charspan": [[0, 3], [4, 10], [11, 16], [17, 21], [22, 33], [34, 37], [38, 47], [48, 51], [52, 55], [56, 74], [74, 75], [76, 79], [80, 91], [92, 101], [102, 105], [106, 109], [110, 128], [128, 129], [130, 132], [133, 142], [143, 145], [146, 152], [152, 153]]}
{"doc_key": "ai-dev-82", "ner": [[4, 4, "metrics"], [8, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 8, 9, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Als", "Leistungsma\u00dfstab", "hat", "der", "Unsicherheitskoeffizient", "gegen\u00fcber", "der", "einfachen", "Genauigkeit", "den", "Vorteil", ",", "dass", "er", "nicht", "von", "der", "relativen", "Gr\u00f6\u00dfe", "der", "verschiedenen", "Klassen", "beeinflusst", "wird", "."], "sentence-detokenized": "Als Leistungsma\u00dfstab hat der Unsicherheitskoeffizient gegen\u00fcber der einfachen Genauigkeit den Vorteil, dass er nicht von der relativen Gr\u00f6\u00dfe der verschiedenen Klassen beeinflusst wird.", "token2charspan": [[0, 3], [4, 20], [21, 24], [25, 28], [29, 53], [54, 63], [64, 67], [68, 77], [78, 89], [90, 93], [94, 101], [101, 102], [103, 107], [108, 110], [111, 116], [117, 120], [121, 124], [125, 134], [135, 140], [141, 144], [145, 158], [159, 166], [167, 178], [179, 183], [183, 184]]}
{"doc_key": "ai-dev-83", "ner": [[8, 9, "algorithm"], [11, 11, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Die", "Forscher", "haben", "eine", "Reihe", "von", "Methoden", "wie", "optischer", "Fluss", ",", "Kalman-Filterung", ",", "Hidden-Markov-Modelle", "usw.", "ausprobiert", "."], "sentence-detokenized": "Die Forscher haben eine Reihe von Methoden wie optischer Fluss, Kalman-Filterung, Hidden-Markov-Modelle usw. ausprobiert.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 23], [24, 29], [30, 33], [34, 42], [43, 46], [47, 56], [57, 62], [62, 63], [64, 80], [80, 81], [82, 103], [104, 108], [109, 120], [120, 121]]}
{"doc_key": "ai-dev-84", "ner": [[8, 11, "conference"], [20, 22, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sie", "war", "Pr\u00e4sidentin", ",", "Vizepr\u00e4sidentin", "und", "Schatzmeisterin", "der", "Association", "for", "Computational", "Linguistics", "und", "war", "Vorstandsmitglied", "und", "Sekret\u00e4rin", "des", "Vorstands", "der", "Computing", "Research", "Association", "."], "sentence-detokenized": "Sie war Pr\u00e4sidentin, Vizepr\u00e4sidentin und Schatzmeisterin der Association for Computational Linguistics und war Vorstandsmitglied und Sekret\u00e4rin des Vorstands der Computing Research Association.", "token2charspan": [[0, 3], [4, 7], [8, 19], [19, 20], [21, 36], [37, 40], [41, 56], [57, 60], [61, 72], [73, 76], [77, 90], [91, 102], [103, 106], [107, 110], [111, 128], [129, 132], [133, 143], [144, 147], [148, 157], [158, 161], [162, 171], [172, 180], [181, 192], [192, 193]]}
{"doc_key": "ai-dev-85", "ner": [[7, 7, "programlang"], [9, 9, "product"], [12, 12, "programlang"], [14, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 12, 12, "compare", "", false, false], [7, 7, 14, 14, "related-to", "supports", false, false], [9, 9, 12, 12, "compare", "", false, false], [9, 9, 14, 14, "related-to", "supports", false, false], [12, 12, 14, 14, "related-to", "supports", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Wie", "andere", "\u00e4hnliche", "Sprachen", ",", "z.", "B.", "APL", "und", "MATLAB", ",", "unterst\u00fctzt", "R", "die", "Matrixarithmetik", "."], "sentence-detokenized": "Wie andere \u00e4hnliche Sprachen, z. B. APL und MATLAB, unterst\u00fctzt R die Matrixarithmetik.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 28], [28, 29], [30, 32], [33, 35], [36, 39], [40, 43], [44, 50], [50, 51], [52, 63], [64, 65], [66, 69], [70, 86], [86, 87]]}
{"doc_key": "ai-dev-86", "ner": [[25, 26, "organisation"], [8, 9, "researcher"], [12, 14, "university"], [17, 20, "misc"], [5, 7, "researcher"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[8, 9, 12, 14, "role", "works_for", false, false]], "relations_mapping_to_source": [3], "sentence": ["Am", "7.", "Juni", "2014", "gewann", "Goostman", "einen", "von", "Kevin", "Warwick", "von", "der", "University", "of", "Reading", "anl\u00e4sslich", "des", "60.", "Todestages", "von", "Turing", "organisierten", "Turing-Test-Wettbewerb", "bei", "der", "Royal", "Society", ",", "nachdem", "33", "%", "der", "Juroren", "\u00fcberzeugt", "waren", ",", "dass", "der", "Bot", "ein", "Mensch", "war", "."], "sentence-detokenized": "Am 7. Juni 2014 gewann Goostman einen von Kevin Warwick von der University of Reading anl\u00e4sslich des 60. Todestages von Turing organisierten Turing-Test-Wettbewerb bei der Royal Society, nachdem 33 % der Juroren \u00fcberzeugt waren, dass der Bot ein Mensch war.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 15], [16, 22], [23, 31], [32, 37], [38, 41], [42, 47], [48, 55], [56, 59], [60, 63], [64, 74], [75, 77], [78, 85], [86, 96], [97, 100], [101, 104], [105, 115], [116, 119], [120, 126], [127, 140], [141, 163], [164, 167], [168, 171], [172, 177], [178, 185], [185, 186], [187, 194], [195, 197], [198, 199], [200, 203], [204, 211], [212, 221], [222, 227], [227, 228], [229, 233], [234, 237], [238, 241], [242, 245], [246, 252], [253, 256], [256, 257]]}
{"doc_key": "ai-dev-87", "ner": [[1, 2, "product"], [4, 4, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 1, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Ein", "kollaborativer", "Roboter", "oder", "Cobot", "ist", "ein", "Roboter", ",", "der", "bei", "der", "Ausf\u00fchrung", "einfacher", "industrieller", "Aufgaben", "sicher", "und", "effektiv", "mit", "menschlichen", "Arbeitern", "zusammenarbeiten", "kann", "."], "sentence-detokenized": "Ein kollaborativer Roboter oder Cobot ist ein Roboter, der bei der Ausf\u00fchrung einfacher industrieller Aufgaben sicher und effektiv mit menschlichen Arbeitern zusammenarbeiten kann.", "token2charspan": [[0, 3], [4, 18], [19, 26], [27, 31], [32, 37], [38, 41], [42, 45], [46, 53], [53, 54], [55, 58], [59, 62], [63, 66], [67, 77], [78, 87], [88, 101], [102, 110], [111, 117], [118, 121], [122, 130], [131, 134], [135, 147], [148, 157], [158, 174], [175, 179], [179, 180]]}
{"doc_key": "ai-dev-88", "ner": [[11, 11, "field"], [16, 18, "task"], [21, 23, "task"], [26, 28, "task"], [31, 33, "task"], [36, 38, "task"], [41, 43, "task"], [46, 46, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[16, 18, 11, 11, "part-of", "task_part_of_field", false, false], [21, 23, 11, 11, "part-of", "task_part_of_field", false, false], [26, 28, 11, 11, "part-of", "task_part_of_field", false, false], [31, 33, 11, 11, "part-of", "task_part_of_field", false, false], [36, 38, 11, 11, "part-of", "task_part_of_field", false, false], [41, 43, 11, 11, "part-of", "task_part_of_field", false, false], [46, 46, 11, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Dieser", "Gesamtrahmen", "wurde", "auf", "eine", "Vielzahl", "von", "Problemen", "im", "Bereich", "des", "Computersehens", "angewandt", ",", "darunter", "die", "Erkennung", "von", "Merkmalen", ",", "die", "Klassifizierung", "von", "Merkmalen", ",", "die", "Segmentierung", "von", "Bildern", ",", "der", "Abgleich", "von", "Bildern", ",", "die", "Sch\u00e4tzung", "von", "Bewegungen", ",", "die", "Berechnung", "von", "Formmerkmalen", "und", "die", "Objekterkennung", "."], "sentence-detokenized": "Dieser Gesamtrahmen wurde auf eine Vielzahl von Problemen im Bereich des Computersehens angewandt, darunter die Erkennung von Merkmalen, die Klassifizierung von Merkmalen, die Segmentierung von Bildern, der Abgleich von Bildern, die Sch\u00e4tzung von Bewegungen, die Berechnung von Formmerkmalen und die Objekterkennung.", "token2charspan": [[0, 6], [7, 19], [20, 25], [26, 29], [30, 34], [35, 43], [44, 47], [48, 57], [58, 60], [61, 68], [69, 72], [73, 87], [88, 97], [97, 98], [99, 107], [108, 111], [112, 121], [122, 125], [126, 135], [135, 136], [137, 140], [141, 156], [157, 160], [161, 170], [170, 171], [172, 175], [176, 189], [190, 193], [194, 201], [201, 202], [203, 206], [207, 215], [216, 219], [220, 227], [227, 228], [229, 232], [233, 242], [243, 246], [247, 257], [257, 258], [259, 262], [263, 273], [274, 277], [278, 291], [292, 295], [296, 299], [300, 315], [315, 316]]}
{"doc_key": "ai-dev-89", "ner": [[7, 7, "task"], [9, 10, "algorithm"], [14, 15, "algorithm"], [24, 24, "algorithm"], [30, 32, "algorithm"], [36, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 7, 9, 10, "part-of", "", false, false], [7, 7, 14, 15, "usage", "", false, false], [9, 10, 24, 24, "named", "same", false, false], [24, 24, 30, 32, "related-to", "", false, false], [24, 24, 36, 37, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "vielen", "praktischen", "Anwendungen", "wird", "bei", "der", "Parametersch\u00e4tzung", "f\u00fcr", "naive", "Bayes-Modelle", "die", "Methode", "der", "maximalen", "Wahrscheinlichkeit", "verwendet", ",", "d.", "h.", "man", "kann", "mit", "dem", "naiven", "Bayes-Modell", "arbeiten", ",", "ohne", "die", "Bayes'sche", "Wahrscheinlichkeit", "zu", "akzeptieren", "oder", "irgendwelche", "Bayes'schen", "Methoden", "anzuwenden", "."], "sentence-detokenized": "In vielen praktischen Anwendungen wird bei der Parametersch\u00e4tzung f\u00fcr naive Bayes-Modelle die Methode der maximalen Wahrscheinlichkeit verwendet, d. h. man kann mit dem naiven Bayes-Modell arbeiten, ohne die Bayes'sche Wahrscheinlichkeit zu akzeptieren oder irgendwelche Bayes'schen Methoden anzuwenden.", "token2charspan": [[0, 2], [3, 9], [10, 21], [22, 33], [34, 38], [39, 42], [43, 46], [47, 65], [66, 69], [70, 75], [76, 89], [90, 93], [94, 101], [102, 105], [106, 115], [116, 134], [135, 144], [144, 145], [146, 148], [149, 151], [152, 155], [156, 160], [161, 164], [165, 168], [169, 175], [176, 188], [189, 197], [197, 198], [199, 203], [204, 207], [208, 218], [219, 237], [238, 240], [241, 252], [253, 257], [258, 270], [271, 282], [283, 291], [292, 302], [302, 303]]}
{"doc_key": "ai-dev-90", "ner": [[2, 4, "researcher"], [6, 7, "misc"], [11, 14, "university"], [16, 18, "researcher"], [20, 21, "misc"], [26, 26, "university"], [28, 28, "university"], [30, 30, "misc"], [38, 39, "university"], [44, 47, "misc"], [49, 52, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[2, 4, 11, 14, "physical", "", false, false], [2, 4, 11, 14, "role", "", false, false], [2, 4, 16, 18, "social", "brothers", false, false], [6, 7, 2, 4, "named", "", false, false], [16, 18, 26, 26, "physical", "", false, false], [16, 18, 26, 26, "role", "", false, false], [16, 18, 28, 28, "physical", "", false, false], [16, 18, 28, 28, "role", "", false, false], [16, 18, 38, 39, "physical", "", false, false], [16, 18, 38, 39, "role", "", false, false], [20, 21, 16, 18, "named", "", false, false], [30, 30, 16, 18, "origin", "", false, false], [44, 47, 16, 18, "artifact", "", false, false], [44, 47, 49, 52, "part-of", "part", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Br\u00fcder", "-", "Victor", "Gershevich", "Katz", ",", "amerikanischer", "Mathematiker", ",", "Professor", "am", "Massachusetts", "Institute", "of", "Technology", ";", "Mikhail", "Gershevich", "Katz", ",", "israelischer", "Mathematiker", ",", "Absolvent", "der", "Universit\u00e4ten", "Harvard", "und", "Columbia", "(", "Ph.D.", ",", "1984", ")", ",", "Professor", "an", "der", "Bar-Ilan", "Universit\u00e4t", ",", "Autor", "der", "Monographie", "Systolic", "Geometry", "and", "Topology", "(", "Mathematical", "Surveys", "and", "Monographs", ",", "vol", "."], "sentence-detokenized": "Br\u00fcder - Victor Gershevich Katz, amerikanischer Mathematiker, Professor am Massachusetts Institute of Technology; Mikhail Gershevich Katz, israelischer Mathematiker, Absolvent der Universit\u00e4ten Harvard und Columbia (Ph.D., 1984), Professor an der Bar-Ilan Universit\u00e4t, Autor der Monographie Systolic Geometry and Topology (Mathematical Surveys and Monographs, vol.", "token2charspan": [[0, 6], [7, 8], [9, 15], [16, 26], [27, 31], [31, 32], [33, 47], [48, 60], [60, 61], [62, 71], [72, 74], [75, 88], [89, 98], [99, 101], [102, 112], [112, 113], [114, 121], [122, 132], [133, 137], [137, 138], [139, 151], [152, 164], [164, 165], [166, 175], [176, 179], [180, 193], [194, 201], [202, 205], [206, 214], [215, 216], [216, 221], [221, 222], [223, 227], [227, 228], [228, 229], [230, 239], [240, 242], [243, 246], [247, 255], [256, 267], [267, 268], [269, 274], [275, 278], [279, 290], [291, 299], [300, 308], [309, 312], [313, 321], [322, 323], [323, 335], [336, 343], [344, 347], [348, 358], [358, 359], [360, 363], [363, 364]]}
{"doc_key": "ai-dev-91", "ner": [[4, 5, "person"], [11, 11, "conference"], [14, 19, "organisation"], [22, 28, "location"], [32, 32, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 11, 11, "physical", "", false, false], [4, 5, 11, 11, "role", "", false, false], [4, 5, 14, 19, "role", "", false, false], [14, 19, 22, 28, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Im", "Jahr", "2000", "schlug", "Manuel", "Toharia", ",", "ein", "Redner", "bei", "fr\u00fcheren", "Campus-Partys", "und", "Direktor", "des", "Museums", "der", "Wissenschaften", "Pr\u00edncipe", "Felipe", "in", "der", "Stadt", "der", "K\u00fcnste", "und", "Wissenschaften", "von", "Valencia", ",", "vor", ",", "Ragageles", "zu", "erweitern", "und", "die", "Veranstaltung", "internationaler", "zu", "gestalten", ",", "indem", "sie", "in", "das", "ber\u00fchmte", "Museum", "verlegt", "wird", "."], "sentence-detokenized": "Im Jahr 2000 schlug Manuel Toharia, ein Redner bei fr\u00fcheren Campus-Partys und Direktor des Museums der Wissenschaften Pr\u00edncipe Felipe in der Stadt der K\u00fcnste und Wissenschaften von Valencia, vor, Ragageles zu erweitern und die Veranstaltung internationaler zu gestalten, indem sie in das ber\u00fchmte Museum verlegt wird.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 19], [20, 26], [27, 34], [34, 35], [36, 39], [40, 46], [47, 50], [51, 59], [60, 73], [74, 77], [78, 86], [87, 90], [91, 98], [99, 102], [103, 117], [118, 126], [127, 133], [134, 136], [137, 140], [141, 146], [147, 150], [151, 157], [158, 161], [162, 176], [177, 180], [181, 189], [189, 190], [191, 194], [194, 195], [196, 205], [206, 208], [209, 218], [219, 222], [223, 226], [227, 240], [241, 256], [257, 259], [260, 269], [269, 270], [271, 276], [277, 280], [281, 283], [284, 287], [288, 296], [297, 303], [304, 311], [312, 316], [316, 317]]}
{"doc_key": "ai-dev-92", "ner": [[6, 6, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Innerhalb", "von", "20", "Minuten", "identifiziert", "ein", "Gesichtserkennungssystem", "pers\u00f6nliche", "Informationen", "wie", "Familienname", ",", "Ausweisnummer", "und", "Adresse", ",", "die", "auf", "der", "Stra\u00dfe", "auf", "einem", "Werbebildschirm", "angezeigt", "werden", "."], "sentence-detokenized": "Innerhalb von 20 Minuten identifiziert ein Gesichtserkennungssystem pers\u00f6nliche Informationen wie Familienname, Ausweisnummer und Adresse, die auf der Stra\u00dfe auf einem Werbebildschirm angezeigt werden.", "token2charspan": [[0, 9], [10, 13], [14, 16], [17, 24], [25, 38], [39, 42], [43, 67], [68, 79], [80, 93], [94, 97], [98, 110], [110, 111], [112, 125], [126, 129], [130, 137], [137, 138], [139, 142], [143, 146], [147, 150], [151, 157], [158, 161], [162, 167], [168, 183], [184, 193], [194, 200], [200, 201]]}
{"doc_key": "ai-dev-93", "ner": [[7, 8, "field"], [10, 10, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Die", "j\u00fcngste", "Forschung", "konzentriert", "sich", "zunehmend", "auf", "un\u00fcberwachtes", "Lernen", "und", "halb\u00fcberwachte", "Lernalgorithmen", "."], "sentence-detokenized": "Die j\u00fcngste Forschung konzentriert sich zunehmend auf un\u00fcberwachtes Lernen und halb\u00fcberwachte Lernalgorithmen.", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 34], [35, 39], [40, 49], [50, 53], [54, 67], [68, 74], [75, 78], [79, 93], [94, 109], [109, 110]]}
{"doc_key": "ai-dev-94", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["Berechnung", "dieses", "Beispiels", "mit", "Python-Code", ":"], "sentence-detokenized": "Berechnung dieses Beispiels mit Python-Code:", "token2charspan": [[0, 10], [11, 17], [18, 27], [28, 31], [32, 43], [43, 44]]}
{"doc_key": "ai-dev-95", "ner": [[6, 6, "task"], [11, 13, "algorithm"], [15, 17, "algorithm"], [20, 22, "algorithm"], [27, 28, "researcher"], [30, 31, "researcher"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6], "relations": [[11, 13, 20, 22, "type-of", "", false, false], [11, 13, 27, 28, "origin", "", false, false], [11, 13, 30, 31, "origin", "", false, false], [15, 17, 11, 13, "named", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4], "sentence": ["Heute", "werden", "jedoch", "viele", "Aspekte", "der", "Spracherkennung", "von", "einer", "Deep-Learning-Methode", "namens", "Long", "Short", "Memory", "(", "LSTM", ")", "\u00fcbernommen", ",", "einem", "rekurrenten", "neuronalen", "Netzwerk", ",", "das", "1997", "von", "Sepp", "Hochreiter", "und", "J\u00fcrgen", "Schmidhuber", "ver\u00f6ffentlicht", "wurde", "."], "sentence-detokenized": "Heute werden jedoch viele Aspekte der Spracherkennung von einer Deep-Learning-Methode namens Long Short Memory (LSTM) \u00fcbernommen, einem rekurrenten neuronalen Netzwerk, das 1997 von Sepp Hochreiter und J\u00fcrgen Schmidhuber ver\u00f6ffentlicht wurde.", "token2charspan": [[0, 5], [6, 12], [13, 19], [20, 25], [26, 33], [34, 37], [38, 53], [54, 57], [58, 63], [64, 85], [86, 92], [93, 97], [98, 103], [104, 110], [111, 112], [112, 116], [116, 117], [118, 128], [128, 129], [130, 135], [136, 147], [148, 158], [159, 167], [167, 168], [169, 172], [173, 177], [178, 181], [182, 186], [187, 197], [198, 201], [202, 208], [209, 220], [221, 235], [236, 241], [241, 242]]}
{"doc_key": "ai-dev-96", "ner": [[8, 8, "algorithm"], [12, 12, "algorithm"], [14, 14, "algorithm"], [21, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 12, 12, "compare", "", false, false], [8, 8, 21, 21, "named", "same", false, false], [14, 14, 21, 21, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "ersten", "experimentellen", "Ergebnissen", "mit", "verrauschten", "Datens\u00e4tzen", "\u00fcbertraf", "BrownBoost", "den", "Generalisierungsfehler", "von", "AdaBoost", ";", "LogitBoost", "schnitt", "jedoch", "genauso", "gut", "ab", "wie", "BrownBoost", "."], "sentence-detokenized": "In ersten experimentellen Ergebnissen mit verrauschten Datens\u00e4tzen \u00fcbertraf BrownBoost den Generalisierungsfehler von AdaBoost; LogitBoost schnitt jedoch genauso gut ab wie BrownBoost.", "token2charspan": [[0, 2], [3, 9], [10, 25], [26, 37], [38, 41], [42, 54], [55, 66], [67, 75], [76, 86], [87, 90], [91, 113], [114, 117], [118, 126], [126, 127], [128, 138], [139, 146], [147, 153], [154, 161], [162, 165], [166, 168], [169, 172], [173, 183], [183, 184]]}
{"doc_key": "ai-dev-97", "ner": [[0, 2, "algorithm"], [5, 7, "researcher"], [10, 10, "country"], [14, 16, "researcher"], [20, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 5, 7, "part-of", "", false, false], [5, 7, 10, 10, "physical", "", false, false], [20, 21, 14, 16, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Die", "evolution\u00e4re", "Programmierung", "wurde", "von", "Lawrence", "J.", "Fogel", "in", "den", "USA", "eingef\u00fchrt", ",", "w\u00e4hrend", "John", "Henry", "Holland", "seine", "Methode", "als", "genetischen", "Algorithmus", "bezeichnete", "."], "sentence-detokenized": "Die evolution\u00e4re Programmierung wurde von Lawrence J. Fogel in den USA eingef\u00fchrt, w\u00e4hrend John Henry Holland seine Methode als genetischen Algorithmus bezeichnete.", "token2charspan": [[0, 3], [4, 16], [17, 31], [32, 37], [38, 41], [42, 50], [51, 53], [54, 59], [60, 62], [63, 66], [67, 70], [71, 81], [81, 82], [83, 90], [91, 95], [96, 101], [102, 109], [110, 115], [116, 123], [124, 127], [128, 139], [140, 151], [152, 163], [163, 164]]}
{"doc_key": "ai-dev-98", "ner": [[3, 3, "researcher"], [5, 5, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 3, 11, 12, "role", "", false, false], [3, 3, 14, 15, "role", "", false, false], [3, 3, 17, 18, "role", "", false, false], [3, 3, 20, 21, "role", "", false, false], [5, 5, 11, 12, "role", "", false, false], [5, 5, 14, 15, "role", "", false, false], [5, 5, 17, 18, "role", "", false, false], [5, 5, 20, 21, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Die", "R\u00fcckrechnungen", "von", "Doug", ",", "Alan", "und", "ihren", "Kollegen", "(", "darunter", "Marvin", "Minsky", ",", "Allen", "Newell", ",", "Edward", "Feigenbaum", "und", "John", "McCarthy", ")", "ergaben", ",", "dass", "dieser", "Aufwand", "zwischen", "1000", "und", "3000", "Personenjahre", "erfordern", "w\u00fcrde", ",", "was", "weit", "\u00fcber", "das", "Standardmodell", "f\u00fcr", "akademische", "Projekte", "hinausgeht", "."], "sentence-detokenized": "Die R\u00fcckrechnungen von Doug, Alan und ihren Kollegen (darunter Marvin Minsky, Allen Newell, Edward Feigenbaum und John McCarthy) ergaben, dass dieser Aufwand zwischen 1000 und 3000 Personenjahre erfordern w\u00fcrde, was weit \u00fcber das Standardmodell f\u00fcr akademische Projekte hinausgeht.", "token2charspan": [[0, 3], [4, 18], [19, 22], [23, 27], [27, 28], [29, 33], [34, 37], [38, 43], [44, 52], [53, 54], [54, 62], [63, 69], [70, 76], [76, 77], [78, 83], [84, 90], [90, 91], [92, 98], [99, 109], [110, 113], [114, 118], [119, 127], [127, 128], [129, 136], [136, 137], [138, 142], [143, 149], [150, 157], [158, 166], [167, 171], [172, 175], [176, 180], [181, 194], [195, 204], [205, 210], [210, 211], [212, 215], [216, 220], [221, 225], [226, 229], [230, 244], [245, 248], [249, 260], [261, 269], [270, 280], [280, 281]]}
{"doc_key": "ai-dev-99", "ner": [[5, 12, "metrics"], [17, 17, "metrics"], [23, 25, "metrics"], [29, 29, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 12, 17, 17, "part-of", "implemented_in", false, false], [23, 25, 29, 29, "part-of", "implemented_in", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["\u00dcbliche", "Kriterien", "sind", "das", "Kriterium", "des", "mittleren", "quadratischen", "Fehlers", "(", "Mean", "Squared", "Error", ")", ",", "das", "in", "MSECriterion", "implementiert", "ist", ",", "und", "das", "Kriterium", "der", "Kreuzentropie", ",", "das", "in", "NLLCriterion", "implementiert", "ist", "."], "sentence-detokenized": "\u00dcbliche Kriterien sind das Kriterium des mittleren quadratischen Fehlers (Mean Squared Error), das in MSECriterion implementiert ist, und das Kriterium der Kreuzentropie, das in NLLCriterion implementiert ist.", "token2charspan": [[0, 7], [8, 17], [18, 22], [23, 26], [27, 36], [37, 40], [41, 50], [51, 64], [65, 72], [73, 74], [74, 78], [79, 86], [87, 92], [92, 93], [93, 94], [95, 98], [99, 101], [102, 114], [115, 128], [129, 132], [132, 133], [134, 137], [138, 141], [142, 151], [152, 155], [156, 169], [169, 170], [171, 174], [175, 177], [178, 190], [191, 204], [205, 208], [208, 209]]}
{"doc_key": "ai-dev-100", "ner": [[0, 0, "researcher"], [10, 10, "organisation"], [13, 17, "misc"], [26, 29, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 10, 10, "role", "", false, false], [0, 0, 26, 29, "role", "", false, false], [13, 17, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 3], "sentence": ["Zurada", "hat", "dem", "Berufsstand", "der", "Ingenieure", "als", "langj\u00e4hriger", "Freiwilliger", "des", "IEEE", "gedient", ":", "2014", "als", "IEEE", "Vice-President-Technical", "Activities", "(", "TAB", "Chair", ")", ",", "als", "Pr\u00e4sident", "der", "IEEE", "Computational", "Intelligence", "Society", "in", "2004-05", "und", "als", "ADCOM-Mitglied", "in", "2009-14", ",", "2016-18", "und", "fr\u00fcheren", "Jahren", "."], "sentence-detokenized": "Zurada hat dem Berufsstand der Ingenieure als langj\u00e4hriger Freiwilliger des IEEE gedient: 2014 als IEEE Vice-President-Technical Activities (TAB Chair), als Pr\u00e4sident der IEEE Computational Intelligence Society in 2004-05 und als ADCOM-Mitglied in 2009-14, 2016-18 und fr\u00fcheren Jahren.", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 26], [27, 30], [31, 41], [42, 45], [46, 58], [59, 71], [72, 75], [76, 80], [81, 88], [88, 89], [90, 94], [95, 98], [99, 103], [104, 128], [129, 139], [140, 141], [141, 144], [145, 150], [150, 151], [151, 152], [153, 156], [157, 166], [167, 170], [171, 175], [176, 189], [190, 202], [203, 210], [211, 213], [214, 221], [222, 225], [226, 229], [230, 244], [245, 247], [248, 255], [255, 256], [257, 264], [265, 268], [269, 277], [278, 284], [284, 285]]}
{"doc_key": "ai-dev-101", "ner": [[5, 5, "field"], [12, 12, "field"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 12, 5, 5, "part-of", "", false, false], [16, 17, 5, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Im", "Allgemeinen", "st\u00fctzt", "sich", "die", "Computerlinguistik", "auf", "die", "Beteiligung", "von", "Linguisten", ",", "Informatikern", ",", "Experten", "f\u00fcr", "k\u00fcnstliche", "Intelligenz", ",", "Mathematikern", ",", "Logikern", ",", "Philosophen", ",", "Kognitionswissenschaftlern", ",", "Kognitionspsychologen", ",", "Psycholinguisten", ",", "Anthropologen", "und", "Neurowissenschaftlern", ",", "um", "nur", "einige", "zu", "nennen", "."], "sentence-detokenized": "Im Allgemeinen st\u00fctzt sich die Computerlinguistik auf die Beteiligung von Linguisten, Informatikern, Experten f\u00fcr k\u00fcnstliche Intelligenz, Mathematikern, Logikern, Philosophen, Kognitionswissenschaftlern, Kognitionspsychologen, Psycholinguisten, Anthropologen und Neurowissenschaftlern, um nur einige zu nennen.", "token2charspan": [[0, 2], [3, 14], [15, 21], [22, 26], [27, 30], [31, 49], [50, 53], [54, 57], [58, 69], [70, 73], [74, 84], [84, 85], [86, 99], [99, 100], [101, 109], [110, 113], [114, 124], [125, 136], [136, 137], [138, 151], [151, 152], [153, 161], [161, 162], [163, 174], [174, 175], [176, 202], [202, 203], [204, 225], [225, 226], [227, 243], [243, 244], [245, 258], [259, 262], [263, 284], [284, 285], [286, 288], [289, 292], [293, 299], [300, 302], [303, 309], [309, 310]]}
{"doc_key": "ai-dev-102", "ner": [[2, 3, "algorithm"], [5, 6, "algorithm"], [9, 9, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniken", "wie", "dynamische", "Markov-Netze", ",", "neuronale", "Faltungsnetze", "und", "das", "Langzeitged\u00e4chtnis", "werden", "h\u00e4ufig", "eingesetzt", ",", "um", "die", "Korrelationen", "zwischen", "den", "einzelnen", "Bildern", "auszunutzen", "."], "sentence-detokenized": "Techniken wie dynamische Markov-Netze, neuronale Faltungsnetze und das Langzeitged\u00e4chtnis werden h\u00e4ufig eingesetzt, um die Korrelationen zwischen den einzelnen Bildern auszunutzen.", "token2charspan": [[0, 9], [10, 13], [14, 24], [25, 37], [37, 38], [39, 48], [49, 62], [63, 66], [67, 70], [71, 89], [90, 96], [97, 103], [104, 114], [114, 115], [116, 118], [119, 122], [123, 136], [137, 145], [146, 149], [150, 159], [160, 167], [168, 179], [179, 180]]}
{"doc_key": "ai-dev-103", "ner": [[0, 0, "product"], [4, 4, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Unimate", "war", "der", "erste", "Industrieroboter", ","], "sentence-detokenized": "Unimate war der erste Industrieroboter,", "token2charspan": [[0, 7], [8, 11], [12, 15], [16, 21], [22, 38], [38, 39]]}
{"doc_key": "ai-dev-104", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [10, 12, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 10, 12, "win-defeat", "", false, false], [5, 6, 10, 12, "win-defeat", "", false, false], [8, 8, 10, 12, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Zusammen", "mit", "Geoffrey", "Hinton", "und", "Yann", "LeCun", "gewann", "Bengio", "den", "Turing", "Award", "2018", "."], "sentence-detokenized": "Zusammen mit Geoffrey Hinton und Yann LeCun gewann Bengio den Turing Award 2018.", "token2charspan": [[0, 8], [9, 12], [13, 21], [22, 28], [29, 32], [33, 37], [38, 43], [44, 50], [51, 57], [58, 61], [62, 68], [69, 74], [75, 79], [79, 80]]}
{"doc_key": "ai-dev-105", "ner": [[4, 4, "country"], [17, 20, "misc"], [23, 26, "country"], [29, 29, "organisation"], [33, 34, "person"], [36, 37, "person"], [45, 47, "misc"], [53, 53, "country"], [59, 59, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[17, 20, 4, 4, "physical", "filmed_in", false, false], [33, 34, 29, 29, "role", "host", false, false], [36, 37, 29, 29, "role", "reporter", false, false], [45, 47, 4, 4, "physical", "filmed_in", false, false], [45, 47, 53, 53, "physical", "distributed_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Weitere", "Serien", "wurden", "am", "britischen", "Schauplatz", "f\u00fcr", "bestimmte", "Sektoren", "des", "Weltmarkts", "gedreht", ",", "darunter", "zwei", "Serien", "von", "Robot", "Wars", "Extreme", "Warriors", "mit", "Wettbewerbern", "aus", "den", "Vereinigten", "Staaten", "f\u00fcr", "das", "TNN-Netz", "(", "moderiert", "von", "Mick", "Foley", "mit", "Rebecca", "Grant", "als", "Boxenreporterin", ")", ",", "zwei", "Serien", "von", "Dutch", "Robot", "Wars", "f\u00fcr", "den", "Vertrieb", "in", "den", "Niederlanden", "und", "eine", "einzelne", "Serie", "f\u00fcr", "Deutschland", "."], "sentence-detokenized": "Weitere Serien wurden am britischen Schauplatz f\u00fcr bestimmte Sektoren des Weltmarkts gedreht, darunter zwei Serien von Robot Wars Extreme Warriors mit Wettbewerbern aus den Vereinigten Staaten f\u00fcr das TNN-Netz (moderiert von Mick Foley mit Rebecca Grant als Boxenreporterin), zwei Serien von Dutch Robot Wars f\u00fcr den Vertrieb in den Niederlanden und eine einzelne Serie f\u00fcr Deutschland.", "token2charspan": [[0, 7], [8, 14], [15, 21], [22, 24], [25, 35], [36, 46], [47, 50], [51, 60], [61, 69], [70, 73], [74, 84], [85, 92], [92, 93], [94, 102], [103, 107], [108, 114], [115, 118], [119, 124], [125, 129], [130, 137], [138, 146], [147, 150], [151, 164], [165, 168], [169, 172], [173, 184], [185, 192], [193, 196], [197, 200], [201, 209], [210, 211], [211, 220], [221, 224], [225, 229], [230, 235], [236, 239], [240, 247], [248, 253], [254, 257], [258, 273], [273, 274], [274, 275], [276, 280], [281, 287], [288, 291], [292, 297], [298, 303], [304, 308], [309, 312], [313, 316], [317, 325], [326, 328], [329, 332], [333, 345], [346, 349], [350, 354], [355, 363], [364, 369], [370, 373], [374, 385], [385, 386]]}
{"doc_key": "ai-dev-106", "ner": [[3, 3, "researcher"], [10, 10, "product"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 10, 10, "role", "", false, false], [22, 22, 10, 10, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Ab", "1986", "leitete", "Miller", "viele", "Jahre", "lang", "die", "Entwicklung", "von", "WordNet", ",", "einer", "gro\u00dfen", "computerlesbaren", "elektronischen", "Referenz", ",", "die", "in", "Anwendungen", "wie", "Suchmaschinen", "verwendet", "werden", "kann", "."], "sentence-detokenized": "Ab 1986 leitete Miller viele Jahre lang die Entwicklung von WordNet, einer gro\u00dfen computerlesbaren elektronischen Referenz, die in Anwendungen wie Suchmaschinen verwendet werden kann.", "token2charspan": [[0, 2], [3, 7], [8, 15], [16, 22], [23, 28], [29, 34], [35, 39], [40, 43], [44, 55], [56, 59], [60, 67], [67, 68], [69, 74], [75, 81], [82, 98], [99, 113], [114, 122], [122, 123], [124, 127], [128, 130], [131, 142], [143, 146], [147, 160], [161, 170], [171, 177], [178, 182], [182, 183]]}
{"doc_key": "ai-dev-107", "ner": [[4, 5, "algorithm"], [9, 12, "algorithm"], [19, 20, "researcher"], [22, 24, "organisation"], [29, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 19, 20, "origin", "", false, false], [4, 5, 29, 30, "win-defeat", "", false, false], [9, 12, 19, 20, "origin", "", false, false], [9, 12, 29, 30, "win-defeat", "", false, false], [19, 20, 22, 24, "physical", "", false, false], [19, 20, 22, 24, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Seit", "2009", "haben", "die", "rekurrenten", "neuronalen", "Netze", "und", "die", "tiefen", "vorw\u00e4rtsgerichteten", "neuronalen", "Netze", ",", "die", "in", "der", "Forschungsgruppe", "von", "J\u00fcrgen", "Schmidhuber", "am", "Schweizer", "KI-Labor", "IDSIA", "entwickelt", "wurden", ",", "mehrere", "internationale", "Handschriftenwettbewerbe", "gewonnen", "."], "sentence-detokenized": "Seit 2009 haben die rekurrenten neuronalen Netze und die tiefen vorw\u00e4rtsgerichteten neuronalen Netze, die in der Forschungsgruppe von J\u00fcrgen Schmidhuber am Schweizer KI-Labor IDSIA entwickelt wurden, mehrere internationale Handschriftenwettbewerbe gewonnen.", "token2charspan": [[0, 4], [5, 9], [10, 15], [16, 19], [20, 31], [32, 42], [43, 48], [49, 52], [53, 56], [57, 63], [64, 83], [84, 94], [95, 100], [100, 101], [102, 105], [106, 108], [109, 112], [113, 129], [130, 133], [134, 140], [141, 152], [153, 155], [156, 165], [166, 174], [175, 180], [181, 191], [192, 198], [198, 199], [200, 207], [208, 222], [223, 247], [248, 256], [256, 257]]}
{"doc_key": "ai-dev-108", "ner": [[4, 6, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Die", "Software", "ist", "in", "C", "+", "+", "implementiert", "und", "ist", "f\u00fcr", "Python", "verpackt", "."], "sentence-detokenized": "Die Software ist in C + + implementiert und ist f\u00fcr Python verpackt.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 19], [20, 21], [22, 23], [24, 25], [26, 39], [40, 43], [44, 47], [48, 51], [52, 58], [59, 67], [67, 68]]}
{"doc_key": "ai-dev-109", "ner": [[9, 9, "country"], [4, 5, "misc"], [14, 15, "misc"], [29, 29, "misc"], [31, 31, "misc"], [33, 33, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 15, 9, 9, "temporal", "", false, false], [14, 15, 4, 5, "artifact", "", false, false], [14, 15, 33, 33, "physical", "", false, false], [31, 31, 29, 29, "named", "", false, false], [31, 31, 33, 33, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["1857", "begann", "eine", "Gruppe", "niederl\u00e4ndischer", "Ingenieure", "auf", "Ersuchen", "des", "Tokugawa-Shogunats", "mit", "dem", "Bau", "der", "Nagasaki", "Yotetsusho", ",", "einer", "modernen", "Gie\u00dferei", "und", "Werft", "im", "westlichen", "Stil", "in", "der", "N\u00e4he", "der", "niederl\u00e4ndischen", "Siedlung", "Dejima", "in", "Nagasaki", "."], "sentence-detokenized": "1857 begann eine Gruppe niederl\u00e4ndischer Ingenieure auf Ersuchen des Tokugawa-Shogunats mit dem Bau der Nagasaki Yotetsusho, einer modernen Gie\u00dferei und Werft im westlichen Stil in der N\u00e4he der niederl\u00e4ndischen Siedlung Dejima in Nagasaki.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 23], [24, 40], [41, 51], [52, 55], [56, 64], [65, 68], [69, 87], [88, 91], [92, 95], [96, 99], [100, 103], [104, 112], [113, 123], [123, 124], [125, 130], [131, 139], [140, 148], [149, 152], [153, 158], [159, 161], [162, 172], [173, 177], [178, 180], [181, 184], [185, 189], [190, 193], [194, 210], [211, 219], [220, 226], [227, 229], [230, 238], [238, 239]]}
{"doc_key": "ai-dev-110", "ner": [[11, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Wir", "machen", "das", "so", "genau", "wie", "m\u00f6glich", ",", "indem", "wir", "den", "mittleren", "quadratischen", "Fehler", "zwischen", "math", "/", "math", "und", "math\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", "/", "math", "messen", ":", "wir", "wollen", ",", "dass", "math", "(", "y", "-\\", "hat", "{f", "}", "(", "x", ";", "D)", ")", "^", "2", "/", "math", "minimal", "sein", ",", "sowohl", "f\u00fcr", "mathx", "_", "1,\\", "Punkte", ",", "x", "_n", "/", "math", "als", "auch", "f\u00fcr", "Punkte", "au\u00dferhalb", "unserer", "Stichprobe", "."], "sentence-detokenized": "Wir machen das so genau wie m\u00f6glich, indem wir den mittleren quadratischen Fehler zwischen math / math und math\\ hat {f} (x; D) / math messen: wir wollen, dass math (y -\\ hat {f} (x; D)) ^ 2 / math minimal sein, sowohl f\u00fcr mathx _ 1,\\ Punkte, x _n / math als auch f\u00fcr Punkte au\u00dferhalb unserer Stichprobe.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 17], [18, 23], [24, 27], [28, 35], [35, 36], [37, 42], [43, 46], [47, 50], [51, 60], [61, 74], [75, 81], [82, 90], [91, 95], [96, 97], [98, 102], [103, 106], [107, 112], [113, 116], [117, 118], [118, 119], [119, 120], [121, 122], [122, 123], [123, 124], [125, 126], [126, 127], [128, 129], [130, 134], [135, 141], [141, 142], [143, 146], [147, 153], [153, 154], [155, 159], [160, 164], [165, 166], [166, 167], [168, 170], [171, 174], [175, 177], [177, 178], [179, 180], [180, 181], [181, 182], [183, 185], [185, 186], [187, 188], [189, 190], [191, 192], [193, 197], [198, 205], [206, 210], [210, 211], [212, 218], [219, 222], [223, 228], [229, 230], [231, 234], [235, 241], [241, 242], [243, 244], [245, 247], [248, 249], [250, 254], [255, 258], [259, 263], [264, 267], [268, 274], [275, 284], [285, 292], [293, 303], [303, 304]]}
{"doc_key": "ai-dev-111", "ner": [[3, 4, "researcher"], [7, 9, "organisation"], [18, 21, "product"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 7, 9, "role", "", false, false], [18, 21, 7, 9, "temporal", "", false, false], [18, 21, 27, 28, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Daraufhin", "lud", "er", "Wydner", "zur", "Jahrestagung", "der", "American", "Translators", "Association", "im", "darauf", "folgenden", "Oktober", "ein", ",", "wo", "das", "Weidner", "Machine", "Translation", "System", "als", "erhoffter", "Durchbruch", "in", "der", "maschinellen", "\u00dcbersetzung", "gefeiert", "wurde", "."], "sentence-detokenized": "Daraufhin lud er Wydner zur Jahrestagung der American Translators Association im darauf folgenden Oktober ein, wo das Weidner Machine Translation System als erhoffter Durchbruch in der maschinellen \u00dcbersetzung gefeiert wurde.", "token2charspan": [[0, 9], [10, 13], [14, 16], [17, 23], [24, 27], [28, 40], [41, 44], [45, 53], [54, 65], [66, 77], [78, 80], [81, 87], [88, 97], [98, 105], [106, 109], [109, 110], [111, 113], [114, 117], [118, 125], [126, 133], [134, 145], [146, 152], [153, 156], [157, 166], [167, 177], [178, 180], [181, 184], [185, 197], [198, 209], [210, 218], [219, 224], [224, 225]]}
{"doc_key": "ai-dev-112", "ner": [[2, 8, "conference"], [10, 10, "conference"], [15, 15, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 2, 8, "named", "", false, false], [10, 10, 2, 8, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Auf", "der", "2018", "Conference", "on", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", "stellten", "Forscher", "von", "Google", "die", "Arbeit", "vor", "."], "sentence-detokenized": "Auf der 2018 Conference on Neural Information Processing Systems (NeurIPS) stellten Forscher von Google die Arbeit vor.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 23], [24, 26], [27, 33], [34, 45], [46, 56], [57, 64], [65, 66], [66, 73], [73, 74], [75, 83], [84, 92], [93, 96], [97, 103], [104, 107], [108, 114], [115, 118], [118, 119]]}
{"doc_key": "ai-dev-113", "ner": [[1, 1, "algorithm"], [5, 5, "algorithm"], [9, 9, "metrics"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 5, 5, "usage", "", false, false], [5, 5, 9, 9, "related-to", "", true, false], [9, 9, 13, 14, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Der", "Baum-Welch-Algorithmus", "verwendet", "den", "bekannten", "EM-Algorithmus", ",", "um", "die", "Maximum-Likelihood-Sch\u00e4tzung", "der", "Parameter", "eines", "verborgenen", "Markov-Modells", "bei", "einer", "Reihe", "von", "beobachteten", "Merkmalsvektoren", "zu", "finden", "."], "sentence-detokenized": "Der Baum-Welch-Algorithmus verwendet den bekannten EM-Algorithmus, um die Maximum-Likelihood-Sch\u00e4tzung der Parameter eines verborgenen Markov-Modells bei einer Reihe von beobachteten Merkmalsvektoren zu finden.", "token2charspan": [[0, 3], [4, 26], [27, 36], [37, 40], [41, 50], [51, 65], [65, 66], [67, 69], [70, 73], [74, 102], [103, 106], [107, 116], [117, 122], [123, 134], [135, 149], [150, 153], [154, 159], [160, 165], [166, 169], [170, 182], [183, 199], [200, 202], [203, 209], [209, 210]]}
{"doc_key": "ai-dev-114", "ner": [[5, 5, "product"], [10, 10, "product"], [28, 28, "misc"], [34, 40, "product"], [43, 50, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[5, 5, 10, 10, "compare", "", false, false], [28, 28, 10, 10, "part-of", "", false, false], [34, 40, 10, 10, "part-of", "", false, false], [43, 50, 10, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": [")", "Zus\u00e4tzlich", "zu", "den", "in", "OpenCyc", "enthaltenen", "taxonomischen", "Informationen", "enth\u00e4lt", "ResearchCyc", "wesentlich", "mehr", "semantisches", "Wissen", "(", "d.", "h.", "zus\u00e4tzliche", "Fakten", "und", "Faustregeln", ")", "zu", "den", "Konzepten", "in", "seiner", "Wissensbasis", ";", "es", "umfasst", "auch", "ein", "umfangreiches", "Lexikon", ",", "englische", "Parsing-", "und", "Generierungswerkzeuge", "sowie", "Java-basierte", "Schnittstellen", "f\u00fcr", "die", "Bearbeitung", "und", "Abfrage", "von", "Wissen", "."], "sentence-detokenized": ") Zus\u00e4tzlich zu den in OpenCyc enthaltenen taxonomischen Informationen enth\u00e4lt ResearchCyc wesentlich mehr semantisches Wissen (d. h. zus\u00e4tzliche Fakten und Faustregeln) zu den Konzepten in seiner Wissensbasis; es umfasst auch ein umfangreiches Lexikon, englische Parsing- und Generierungswerkzeuge sowie Java-basierte Schnittstellen f\u00fcr die Bearbeitung und Abfrage von Wissen.", "token2charspan": [[0, 1], [2, 12], [13, 15], [16, 19], [20, 22], [23, 30], [31, 42], [43, 56], [57, 70], [71, 78], [79, 90], [91, 101], [102, 106], [107, 119], [120, 126], [127, 128], [128, 130], [131, 133], [134, 145], [146, 152], [153, 156], [157, 168], [168, 169], [170, 172], [173, 176], [177, 186], [187, 189], [190, 196], [197, 209], [209, 210], [211, 213], [214, 221], [222, 226], [227, 230], [231, 244], [245, 252], [252, 253], [254, 263], [264, 272], [273, 276], [277, 298], [299, 304], [305, 318], [319, 333], [334, 337], [338, 341], [342, 353], [354, 357], [358, 365], [366, 369], [370, 376], [376, 377]]}
{"doc_key": "ai-dev-115", "ner": [[1, 1, "algorithm"], [5, 8, "task"], [13, 13, "field"], [16, 17, "field"], [20, 21, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 5, 8, "type-of", "", false, false], [5, 8, 13, 13, "part-of", "task_part_of_field", false, false], [5, 8, 16, 17, "part-of", "task_part_of_field", false, false], [5, 8, 20, 21, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Die", "Hough-Transformation", "ist", "ein", "Verfahren", "zur", "Extraktion", "von", "Merkmalen", ",", "das", "in", "der", "Bildanalyse", ",", "der", "Computer", "Vision", "und", "der", "digitalen", "Bildverarbeitung", "eingesetzt", "wird", "."], "sentence-detokenized": "Die Hough-Transformation ist ein Verfahren zur Extraktion von Merkmalen, das in der Bildanalyse, der Computer Vision und der digitalen Bildverarbeitung eingesetzt wird.", "token2charspan": [[0, 3], [4, 24], [25, 28], [29, 32], [33, 42], [43, 46], [47, 57], [58, 61], [62, 71], [71, 72], [73, 76], [77, 79], [80, 83], [84, 95], [95, 96], [97, 100], [101, 109], [110, 116], [117, 120], [121, 124], [125, 134], [135, 151], [152, 162], [163, 167], [167, 168]]}
{"doc_key": "ai-dev-116", "ner": [[5, 9, "product"], [12, 12, "organisation"], [17, 17, "product"], [19, 20, "researcher"], [26, 27, "organisation"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[17, 17, 19, 20, "artifact", "", false, false], [26, 27, 12, 12, "role", "supported", false, false]], "relations_mapping_to_source": [3, 4], "sentence": ["1978", "wurde", "der", "PUMA-Roboter", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", "von", "Unimation", "auf", "der", "Grundlage", "von", "Vicarm", "(", "Victor", "Scheinman", ")", "und", "mit", "Unterst\u00fctzung", "von", "General", "Motors", "entwickelt", "."], "sentence-detokenized": "1978 wurde der PUMA-Roboter (Programmable Universal Machine for Assembly) von Unimation auf der Grundlage von Vicarm (Victor Scheinman) und mit Unterst\u00fctzung von General Motors entwickelt.", "token2charspan": [[0, 4], [5, 10], [11, 14], [15, 27], [28, 29], [29, 41], [42, 51], [52, 59], [60, 63], [64, 72], [72, 73], [74, 77], [78, 87], [88, 91], [92, 95], [96, 105], [106, 109], [110, 116], [117, 118], [118, 124], [125, 134], [134, 135], [136, 139], [140, 143], [144, 157], [158, 161], [162, 169], [170, 176], [177, 187], [187, 188]]}
{"doc_key": "ai-dev-117", "ner": [[0, 0, "algorithm"], [4, 5, "researcher"], [7, 8, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 5, "origin", "", false, false], [0, 0, 7, 8, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["LSTM", "wurde", "1997", "von", "Sepp", "Hochreiter", "und", "J\u00fcrgen", "Schmidhuber", "vorgeschlagen", "."], "sentence-detokenized": "LSTM wurde 1997 von Sepp Hochreiter und J\u00fcrgen Schmidhuber vorgeschlagen.", "token2charspan": [[0, 4], [5, 10], [11, 15], [16, 19], [20, 24], [25, 35], [36, 39], [40, 46], [47, 58], [59, 72], [72, 73]]}
{"doc_key": "ai-dev-118", "ner": [[9, 9, "metrics"], [11, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Die", "vier", "Ergebnisse", "k\u00f6nnen", "in", "einer", "2", "\u00d7", "2", "Kontingenztabelle", "oder", "Konfusionsmatrix", "wie", "folgt", "formuliert", "werden", ":"], "sentence-detokenized": "Die vier Ergebnisse k\u00f6nnen in einer 2 \u00d7 2 Kontingenztabelle oder Konfusionsmatrix wie folgt formuliert werden:", "token2charspan": [[0, 3], [4, 8], [9, 19], [20, 26], [27, 29], [30, 35], [36, 37], [38, 39], [40, 41], [42, 59], [60, 64], [65, 81], [82, 85], [86, 91], [92, 102], [103, 109], [109, 110]]}
{"doc_key": "ai-dev-119", "ner": [[9, 9, "conference"], [12, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Er", "leistete", "auch", "einen", "wichtigen", "Beitrag", "zur", "Gr\u00fcndung", "von", "ELRA", "und", "der", "LREC-Konferenz", "."], "sentence-detokenized": "Er leistete auch einen wichtigen Beitrag zur Gr\u00fcndung von ELRA und der LREC-Konferenz.", "token2charspan": [[0, 2], [3, 11], [12, 16], [17, 22], [23, 32], [33, 40], [41, 44], [45, 53], [54, 57], [58, 62], [63, 66], [67, 70], [71, 85], [85, 86]]}
{"doc_key": "ai-dev-120", "ner": [[11, 11, "misc"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 16, 11, 11, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Eine", "beliebte", "Anwendung", "f\u00fcr", "Serienroboter", "in", "der", "heutigen", "Industrie", "ist", "der", "Pick-and-Place-Montageroboter", ",", "ein", "so", "genannter", "SCARA-Roboter", ",", "der", "\u00fcber", "vier", "Freiheitsgrade", "verf\u00fcgt", "."], "sentence-detokenized": "Eine beliebte Anwendung f\u00fcr Serienroboter in der heutigen Industrie ist der Pick-and-Place-Montageroboter, ein so genannter SCARA-Roboter, der \u00fcber vier Freiheitsgrade verf\u00fcgt.", "token2charspan": [[0, 4], [5, 13], [14, 23], [24, 27], [28, 41], [42, 44], [45, 48], [49, 57], [58, 67], [68, 71], [72, 75], [76, 105], [105, 106], [107, 110], [111, 113], [114, 123], [124, 137], [137, 138], [139, 142], [143, 147], [148, 152], [153, 167], [168, 175], [175, 176]]}
{"doc_key": "ai-dev-121", "ner": [[12, 18, "conference"], [20, 20, "conference"], [23, 26, "conference"], [33, 33, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[20, 20, 12, 18, "named", "", false, false], [33, 33, 23, 26, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Er", "war", "eines", "der", "Gr\u00fcndungsmitglieder", "und", "ehemaliger", "Vorsitzender", "(", "2006-2008", ")", "der", "Special", "Interest", "Group", "on", "Web", "as", "Corpus", "(", "SIGWAC", ")", "der", "Association", "for", "Computational", "Linguistics", "und", "auch", "einer", "der", "Gr\u00fcndungsorganisatoren", "von", "SENSEVAL", "."], "sentence-detokenized": "Er war eines der Gr\u00fcndungsmitglieder und ehemaliger Vorsitzender (2006-2008) der Special Interest Group on Web as Corpus (SIGWAC) der Association for Computational Linguistics und auch einer der Gr\u00fcndungsorganisatoren von SENSEVAL.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 16], [17, 36], [37, 40], [41, 51], [52, 64], [65, 66], [66, 75], [75, 76], [77, 80], [81, 88], [89, 97], [98, 103], [104, 106], [107, 110], [111, 113], [114, 120], [121, 122], [122, 128], [128, 129], [130, 133], [134, 145], [146, 149], [150, 163], [164, 175], [176, 179], [180, 184], [185, 190], [191, 194], [195, 217], [218, 221], [222, 230], [230, 231]]}
{"doc_key": "ai-dev-122", "ner": [[3, 3, "product"], [6, 6, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 6, 3, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Als", "Plattform", "bietet", "LinguaStream", "eine", "umfangreiche", "Java-API", "."], "sentence-detokenized": "Als Plattform bietet LinguaStream eine umfangreiche Java-API.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 33], [34, 38], [39, 51], [52, 60], [60, 61]]}
{"doc_key": "ai-dev-123", "ner": [[8, 8, "programlang"], [11, 11, "misc"], [14, 14, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 14, 14, "type-of", "", false, false], [11, 11, 14, 14, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Der", "Roboterbausatz", "basiert", "auf", "Android", "und", "wird", "mit", "Java", ",", "der", "Blocks-Programmierschnittstelle", "oder", "anderen", "Android-Programmiersystemen", "programmiert", "."], "sentence-detokenized": "Der Roboterbausatz basiert auf Android und wird mit Java, der Blocks-Programmierschnittstelle oder anderen Android-Programmiersystemen programmiert.", "token2charspan": [[0, 3], [4, 18], [19, 26], [27, 30], [31, 38], [39, 42], [43, 47], [48, 51], [52, 56], [56, 57], [58, 61], [62, 93], [94, 98], [99, 106], [107, 134], [135, 147], [147, 148]]}
{"doc_key": "ai-dev-124", "ner": [[11, 11, "algorithm"], [14, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Die", "Methode", "zur", "Definition", "der", "verkn\u00fcpften", "Liste", "legt", "die", "Verwendung", "einer", "Tiefensuche", "oder", "einer", "Breitensuche", "fest", "."], "sentence-detokenized": "Die Methode zur Definition der verkn\u00fcpften Liste legt die Verwendung einer Tiefensuche oder einer Breitensuche fest.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 26], [27, 30], [31, 42], [43, 48], [49, 53], [54, 57], [58, 68], [69, 74], [75, 86], [87, 91], [92, 97], [98, 110], [111, 115], [115, 116]]}
{"doc_key": "ai-dev-125", "ner": [[18, 18, "task"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Diese", "Regionen", "k\u00f6nnten", "das", "Vorhandensein", "von", "Objekten", "oder", "Teilen", "von", "Objekten", "im", "Bildbereich", "signalisieren", ",", "was", "bei", "der", "Objekterkennung", "und/oder", "der", "Videoverfolgung", "von", "Objekten", "Anwendung", "findet", "."], "sentence-detokenized": "Diese Regionen k\u00f6nnten das Vorhandensein von Objekten oder Teilen von Objekten im Bildbereich signalisieren, was bei der Objekterkennung und/oder der Videoverfolgung von Objekten Anwendung findet.", "token2charspan": [[0, 5], [6, 14], [15, 22], [23, 26], [27, 40], [41, 44], [45, 53], [54, 58], [59, 65], [66, 69], [70, 78], [79, 81], [82, 93], [94, 107], [107, 108], [109, 112], [113, 116], [117, 120], [121, 136], [137, 145], [146, 149], [150, 165], [166, 169], [170, 178], [179, 188], [189, 195], [195, 196]]}
{"doc_key": "ai-dev-126", "ner": [[4, 5, "algorithm"], [7, 7, "product"], [13, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 4, 5, "type-of", "", false, false], [7, 7, 13, 13, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Ein", "Beispiel", "f\u00fcr", "ein", "semantisches", "Netz", "ist", "WordNet", ",", "eine", "lexikalische", "Datenbank", "des", "Englischen", "."], "sentence-detokenized": "Ein Beispiel f\u00fcr ein semantisches Netz ist WordNet, eine lexikalische Datenbank des Englischen.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 20], [21, 33], [34, 38], [39, 42], [43, 50], [50, 51], [52, 56], [57, 69], [70, 79], [80, 83], [84, 94], [94, 95]]}
{"doc_key": "ai-dev-127", "ner": [[0, 0, "task"], [6, 6, "field"], [8, 8, "field"], [18, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 6, "part-of", "", false, false], [0, 0, 8, 8, "named", "same", false, false], [0, 0, 8, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Spracherkennung", "ist", "ein", "interdisziplin\u00e4res", "Teilgebiet", "der", "Informatik", "und", "Computerlinguistik", ",", "das", "Methoden", "und", "Technologien", "entwickelt", ",", "die", "die", "Erkennung", "und", "\u00dcbersetzung", "gesprochener", "Sprache", "in", "Text", "durch", "Computer", "erm\u00f6glichen", "."], "sentence-detokenized": "Spracherkennung ist ein interdisziplin\u00e4res Teilgebiet der Informatik und Computerlinguistik, das Methoden und Technologien entwickelt, die die Erkennung und \u00dcbersetzung gesprochener Sprache in Text durch Computer erm\u00f6glichen.", "token2charspan": [[0, 15], [16, 19], [20, 23], [24, 42], [43, 53], [54, 57], [58, 68], [69, 72], [73, 91], [91, 92], [93, 96], [97, 105], [106, 109], [110, 122], [123, 133], [133, 134], [135, 138], [139, 142], [143, 152], [153, 156], [157, 168], [169, 181], [182, 189], [190, 192], [193, 197], [198, 203], [204, 212], [213, 224], [224, 225]]}
{"doc_key": "ai-dev-128", "ner": [[0, 1, "field"], [9, 10, "misc"], [16, 18, "field"], [15, 15, "task"], [21, 21, "task"], [45, 46, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 45, 46, "named", "same", false, false], [16, 18, 0, 1, "part-of", "subfield", false, false], [15, 15, 0, 1, "part-of", "", false, false], [15, 15, 16, 18, "part-of", "", false, false], [21, 21, 16, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["K\u00fcnstliche", "Intelligenz", "hat", "die", "meiste", "Aufmerksamkeit", "in", "Bezug", "auf", "angewandte", "Ontologie", "in", "Teilbereichen", "wie", "der", "maschinellen", "Verarbeitung", "nat\u00fcrlicher", "Sprache", "und", "der", "Wissensrepr\u00e4sentation", "erhalten", ",", "aber", "Ontologie-Editoren", "werden", "oft", "in", "einer", "Reihe", "von", "Bereichen", "wie", "der", "Bildung", "eingesetzt", ",", "ohne", "die", "Absicht", ",", "einen", "Beitrag", "zur", "KI", "zu", "leisten", "."], "sentence-detokenized": "K\u00fcnstliche Intelligenz hat die meiste Aufmerksamkeit in Bezug auf angewandte Ontologie in Teilbereichen wie der maschinellen Verarbeitung nat\u00fcrlicher Sprache und der Wissensrepr\u00e4sentation erhalten, aber Ontologie-Editoren werden oft in einer Reihe von Bereichen wie der Bildung eingesetzt, ohne die Absicht, einen Beitrag zur KI zu leisten.", "token2charspan": [[0, 10], [11, 22], [23, 26], [27, 30], [31, 37], [38, 52], [53, 55], [56, 61], [62, 65], [66, 76], [77, 86], [87, 89], [90, 103], [104, 107], [108, 111], [112, 124], [125, 137], [138, 149], [150, 157], [158, 161], [162, 165], [166, 187], [188, 196], [196, 197], [198, 202], [203, 221], [222, 228], [229, 232], [233, 235], [236, 241], [242, 247], [248, 251], [252, 261], [262, 265], [266, 269], [270, 277], [278, 288], [288, 289], [290, 294], [295, 298], [299, 306], [306, 307], [308, 313], [314, 321], [322, 325], [326, 328], [329, 331], [332, 339], [339, 340]]}
{"doc_key": "ai-dev-129", "ner": [[5, 5, "algorithm"], [8, 9, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 8, 9, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Diese", "Aktualisierungsregel", "ist", "eigentlich", "die", "stochastische", "Gradientenabstiegsaktualisierung", "f\u00fcr", "lineare", "Regression", "."], "sentence-detokenized": "Diese Aktualisierungsregel ist eigentlich die stochastische Gradientenabstiegsaktualisierung f\u00fcr lineare Regression.", "token2charspan": [[0, 5], [6, 26], [27, 30], [31, 41], [42, 45], [46, 59], [60, 92], [93, 96], [97, 104], [105, 115], [115, 116]]}
{"doc_key": "ai-dev-130", "ner": [[4, 9, "organisation"], [12, 15, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Er", "wurde", "in", "die", "American", "Academy", "of", "Arts", "and", "Sciences", "und", "die", "National", "Academy", "of", "Sciences", "gew\u00e4hlt", "und", "hat", "eine", "Reihe", "von", "Auszeichnungen", "erhalten", ":"], "sentence-detokenized": "Er wurde in die American Academy of Arts and Sciences und die National Academy of Sciences gew\u00e4hlt und hat eine Reihe von Auszeichnungen erhalten:", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 15], [16, 24], [25, 32], [33, 35], [36, 40], [41, 44], [45, 53], [54, 57], [58, 61], [62, 70], [71, 78], [79, 81], [82, 90], [91, 98], [99, 102], [103, 106], [107, 111], [112, 117], [118, 121], [122, 136], [137, 145], [145, 146]]}
{"doc_key": "ai-dev-131", "ner": [[6, 6, "organisation"], [10, 11, "person"], [13, 16, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 10, 11, "related-to", "written_about_by", false, false], [6, 6, 13, 16, "related-to", "written_about_by", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Die", "j\u00fcngste", "Denkschule", "zur", "Strategie", "von", "Honda", "wurde", "1989", "von", "Gary", "Hamel", "und", "C.", "K.", "Prahalad", "vorgelegt", "."], "sentence-detokenized": "Die j\u00fcngste Denkschule zur Strategie von Honda wurde 1989 von Gary Hamel und C. K. Prahalad vorgelegt.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 26], [27, 36], [37, 40], [41, 46], [47, 52], [53, 57], [58, 61], [62, 66], [67, 72], [73, 76], [77, 79], [80, 82], [83, 91], [92, 101], [101, 102]]}
{"doc_key": "ai-dev-132", "ner": [[1, 1, "metrics"], [4, 4, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 4, 4, "related-to", "calculates", true, false], [1, 1, 19, 19, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["W\u00e4hrend", "BLEU", "einfach", "die", "Pr\u00e4zision", "der", "n-Gramme", "berechnet", ",", "indem", "es", "jedem", "n-Gramm", "das", "gleiche", "Gewicht", "beimisst", ",", "berechnet", "NIST", "auch", ",", "wie", "informativ", "ein", "bestimmtes", "n-Gramm", "ist", "."], "sentence-detokenized": "W\u00e4hrend BLEU einfach die Pr\u00e4zision der n-Gramme berechnet, indem es jedem n-Gramm das gleiche Gewicht beimisst, berechnet NIST auch, wie informativ ein bestimmtes n-Gramm ist.", "token2charspan": [[0, 7], [8, 12], [13, 20], [21, 24], [25, 34], [35, 38], [39, 47], [48, 57], [57, 58], [59, 64], [65, 67], [68, 73], [74, 81], [82, 85], [86, 93], [94, 101], [102, 110], [110, 111], [112, 121], [122, 126], [127, 131], [131, 132], [133, 136], [137, 147], [148, 151], [152, 162], [163, 170], [171, 174], [174, 175]]}
{"doc_key": "ai-dev-133", "ner": [[13, 16, "misc"], [4, 7, "conference"], [9, 9, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 16, 4, 7, "temporal", "", false, false], [9, 9, 4, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Er", "wurde", "von", "der", "Association", "for", "Computational", "Linguistics", "(", "ACL", ")", "mit", "dem", "Lifetime", "Achievement", "Award", "2019", "ausgezeichnet", "."], "sentence-detokenized": "Er wurde von der Association for Computational Linguistics (ACL) mit dem Lifetime Achievement Award 2019 ausgezeichnet.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 16], [17, 28], [29, 32], [33, 46], [47, 58], [59, 60], [60, 63], [63, 64], [65, 68], [69, 72], [73, 81], [82, 93], [94, 99], [100, 104], [105, 118], [118, 119]]}
{"doc_key": "ai-dev-134", "ner": [[0, 0, "researcher"], [5, 10, "organisation"], [12, 12, "organisation"], [18, 22, "conference"], [24, 24, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 10, "role", "", false, false], [0, 0, 18, 22, "role", "", false, false], [12, 12, 5, 10, "named", "", false, false], [24, 24, 18, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sycara", "ist", "ein", "Fellow", "des", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", "und", "ein", "Fellow", "der", "American", "Association", "for", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Sycara ist ein Fellow des Institute of Electrical and Electronics Engineers (IEEE) und ein Fellow der American Association for Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 21], [22, 25], [26, 35], [36, 38], [39, 49], [50, 53], [54, 65], [66, 75], [76, 77], [77, 81], [81, 82], [83, 86], [87, 90], [91, 97], [98, 101], [102, 110], [111, 122], [123, 126], [127, 137], [138, 150], [151, 152], [152, 156], [156, 157], [157, 158]]}
{"doc_key": "ai-dev-135", "ner": [[13, 13, "misc"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Der", "folgende", "MATLAB-Code", "demonstriert", "eine", "konkrete", "L\u00f6sung", "f\u00fcr", "das", "im", "vorherigen", "Abschnitt", "vorgestellte", "nichtlineare", "Gleichungssystem", ":", "Siehe", "auch"], "sentence-detokenized": "Der folgende MATLAB-Code demonstriert eine konkrete L\u00f6sung f\u00fcr das im vorherigen Abschnitt vorgestellte nichtlineare Gleichungssystem: Siehe auch", "token2charspan": [[0, 3], [4, 12], [13, 24], [25, 37], [38, 42], [43, 51], [52, 58], [59, 62], [63, 66], [67, 69], [70, 80], [81, 90], [91, 103], [104, 116], [117, 133], [133, 134], [135, 140], [141, 145]]}
{"doc_key": "ai-dev-136", "ner": [[0, 0, "product"], [11, 12, "field"], [36, 37, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 12, "related-to", "trained_by", true, false], [0, 0, 36, 37, "related-to", "trained_by", true, false], [11, 12, 36, 37, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Mustererkennungssysteme", "werden", "in", "vielen", "F\u00e4llen", "anhand", "von", "markierten", "Trainingsdaten", "trainiert", "(", "\u00fcberwachtes", "Lernen", ")", ",", "aber", "wenn", "keine", "markierten", "Daten", "verf\u00fcgbar", "sind", ",", "k\u00f6nnen", "andere", "Algorithmen", "verwendet", "werden", ",", "um", "zuvor", "unbekannte", "Muster", "zu", "entdecken", "(", "un\u00fcberwachtes", "Lernen", ")", "."], "sentence-detokenized": "Mustererkennungssysteme werden in vielen F\u00e4llen anhand von markierten Trainingsdaten trainiert (\u00fcberwachtes Lernen), aber wenn keine markierten Daten verf\u00fcgbar sind, k\u00f6nnen andere Algorithmen verwendet werden, um zuvor unbekannte Muster zu entdecken (un\u00fcberwachtes Lernen).", "token2charspan": [[0, 23], [24, 30], [31, 33], [34, 40], [41, 47], [48, 54], [55, 58], [59, 69], [70, 84], [85, 94], [95, 96], [96, 107], [108, 114], [114, 115], [115, 116], [117, 121], [122, 126], [127, 132], [133, 143], [144, 149], [150, 159], [160, 164], [164, 165], [166, 172], [173, 179], [180, 191], [192, 201], [202, 208], [208, 209], [210, 212], [213, 218], [219, 229], [230, 236], [237, 239], [240, 249], [250, 251], [251, 264], [265, 271], [271, 272], [272, 273]]}
{"doc_key": "ai-dev-137", "ner": [[5, 7, "researcher"], [10, 10, "country"], [21, 23, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 7, 10, 10, "physical", "", false, false], [5, 7, 21, 23, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Sie", "wurde", "erstmals", "1960", "von", "Lawrence", "J.", "Fogel", "in", "den", "USA", "eingesetzt", ",", "um", "die", "simulierte", "Evolution", "als", "Lernprozess", "zur", "Erzeugung", "k\u00fcnstlicher", "Intelligenz", "zu", "nutzen", "."], "sentence-detokenized": "Sie wurde erstmals 1960 von Lawrence J. Fogel in den USA eingesetzt, um die simulierte Evolution als Lernprozess zur Erzeugung k\u00fcnstlicher Intelligenz zu nutzen.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 23], [24, 27], [28, 36], [37, 39], [40, 45], [46, 48], [49, 52], [53, 56], [57, 67], [67, 68], [69, 71], [72, 75], [76, 86], [87, 96], [97, 100], [101, 112], [113, 116], [117, 126], [127, 138], [139, 150], [151, 153], [154, 160], [160, 161]]}
{"doc_key": "ai-dev-138", "ner": [[0, 1, "field"], [9, 10, "field"], [14, 15, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 9, 10, "part-of", "", false, false], [14, 15, 9, 10, "part-of", "", false, false], [18, 19, 9, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Das", "Verst\u00e4rkungslernen", "ist", "eines", "der", "drei", "grundlegenden", "Paradigmen", "des", "maschinellen", "Lernens", ",", "neben", "dem", "\u00fcberwachten", "Lernen", "und", "dem", "un\u00fcberwachten", "Lernen", "."], "sentence-detokenized": "Das Verst\u00e4rkungslernen ist eines der drei grundlegenden Paradigmen des maschinellen Lernens, neben dem \u00fcberwachten Lernen und dem un\u00fcberwachten Lernen.", "token2charspan": [[0, 3], [4, 22], [23, 26], [27, 32], [33, 36], [37, 41], [42, 55], [56, 66], [67, 70], [71, 83], [84, 91], [91, 92], [93, 98], [99, 102], [103, 114], [115, 121], [122, 125], [126, 129], [130, 143], [144, 150], [150, 151]]}
{"doc_key": "ai-dev-139", "ner": [[4, 5, "field"], [9, 9, "programlang"], [24, 26, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 24, 26, "usage", "applies", false, false], [9, 9, 24, 26, "usage", "applies", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "solchen", "F\u00e4llen", "k\u00f6nnen", "Cloud", "Computing", "und", "die", "Open-Source-Programmiersprache", "R", "kleineren", "Banken", "helfen", ",", "Risikoanalysen", "einzuf\u00fchren", "und", "die", "\u00dcberwachung", "auf", "Filialebene", "durch", "die", "Anwendung", "pr\u00e4diktiver", "Analysen", "zu", "unterst\u00fctzen", "."], "sentence-detokenized": "In solchen F\u00e4llen k\u00f6nnen Cloud Computing und die Open-Source-Programmiersprache R kleineren Banken helfen, Risikoanalysen einzuf\u00fchren und die \u00dcberwachung auf Filialebene durch die Anwendung pr\u00e4diktiver Analysen zu unterst\u00fctzen.", "token2charspan": [[0, 2], [3, 10], [11, 17], [18, 24], [25, 30], [31, 40], [41, 44], [45, 48], [49, 79], [80, 81], [82, 91], [92, 98], [99, 105], [105, 106], [107, 121], [122, 133], [134, 137], [138, 141], [142, 153], [154, 157], [158, 169], [170, 175], [176, 179], [180, 189], [190, 201], [202, 210], [211, 213], [214, 226], [226, 227]]}
{"doc_key": "ai-dev-140", "ner": [[9, 10, "researcher"], [13, 14, "algorithm"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 17, 18, "named", "same", false, false], [13, 14, 9, 10, "origin", "proves_function", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Eine", "der", "ersten", "Versionen", "des", "Theorems", "wurde", "1989", "von", "George", "Cybenko", "f\u00fcr", "Aktivierungsfunktionen", "mit", "Sigmoidfunktion", "bewiesen", ".", "Cybenko", "G.", "(", "1989", ")", ",", "2", "(", "4", ")", ",", "303-314."], "sentence-detokenized": "Eine der ersten Versionen des Theorems wurde 1989 von George Cybenko f\u00fcr Aktivierungsfunktionen mit Sigmoidfunktion bewiesen. Cybenko G. (1989), 2 (4), 303-314.", "token2charspan": [[0, 4], [5, 8], [9, 15], [16, 25], [26, 29], [30, 38], [39, 44], [45, 49], [50, 53], [54, 60], [61, 68], [69, 72], [73, 95], [96, 99], [100, 115], [116, 124], [124, 125], [126, 133], [134, 136], [137, 138], [138, 142], [142, 143], [143, 144], [145, 146], [147, 148], [148, 149], [149, 150], [150, 151], [152, 160]]}
{"doc_key": "ai-dev-141", "ner": [[6, 6, "algorithm"], [12, 12, "metrics"], [15, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 12, 6, 6, "part-of", "", false, false], [15, 17, 12, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "diesem", "Prozess", ",", "der", "als", "Kreuzvalidierung", "bekannt", "ist", ",", "wird", "der", "MSE", "oft", "als", "mittlerer", "quadratischer", "Vorhersagefehler", "bezeichnet", "und", "wie", "folgt", "berechnet"], "sentence-detokenized": "In diesem Prozess, der als Kreuzvalidierung bekannt ist, wird der MSE oft als mittlerer quadratischer Vorhersagefehler bezeichnet und wie folgt berechnet", "token2charspan": [[0, 2], [3, 9], [10, 17], [17, 18], [19, 22], [23, 26], [27, 43], [44, 51], [52, 55], [55, 56], [57, 61], [62, 65], [66, 69], [70, 73], [74, 77], [78, 87], [88, 101], [102, 118], [119, 129], [130, 133], [134, 137], [138, 143], [144, 153]]}
{"doc_key": "ai-dev-142", "ner": [[0, 0, "task"], [7, 8, "task"], [10, 10, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 7, 8, "compare", "", false, false], [10, 10, 7, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 2], "sentence": ["OMR", "unterscheidet", "sich", "im", "Allgemeinen", "von", "der", "optischen", "Zeichenerkennung", "(", "OCR", ")", "dadurch", ",", "dass", "kein", "kompliziertes", "Mustererkennungssystem", "erforderlich", "ist", "."], "sentence-detokenized": "OMR unterscheidet sich im Allgemeinen von der optischen Zeichenerkennung (OCR) dadurch, dass kein kompliziertes Mustererkennungssystem erforderlich ist.", "token2charspan": [[0, 3], [4, 17], [18, 22], [23, 25], [26, 37], [38, 41], [42, 45], [46, 55], [56, 72], [73, 74], [74, 77], [77, 78], [79, 86], [86, 87], [88, 92], [93, 97], [98, 111], [112, 134], [135, 147], [148, 151], [151, 152]]}
{"doc_key": "ai-dev-143", "ner": [[10, 10, "location"], [12, 12, "location"], [14, 14, "location"], [17, 18, "location"], [20, 21, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 12, 14, 14, "physical", "", false, false], [17, 18, 12, 12, "physical", "", false, false], [20, 21, 12, 12, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "den", "Jahren", "2018", "und", "2019", "wurde", "die", "Meisterschaft", "in", "Houston", "und", "Detroit", ",", "Michigan", ",", "im", "TCF", "Center", "und", "Ford", "Field", "ausgetragen", "."], "sentence-detokenized": "In den Jahren 2018 und 2019 wurde die Meisterschaft in Houston und Detroit, Michigan, im TCF Center und Ford Field ausgetragen.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 18], [19, 22], [23, 27], [28, 33], [34, 37], [38, 51], [52, 54], [55, 62], [63, 66], [67, 74], [74, 75], [76, 84], [84, 85], [86, 88], [89, 92], [93, 99], [100, 103], [104, 108], [109, 114], [115, 126], [126, 127]]}
{"doc_key": "ai-dev-144", "ner": [[0, 1, "task"], [11, 12, "task"], [15, 15, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 0, 1, "part-of", "", false, false], [15, 15, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Die", "Klassifizierung", "kann", "als", "zwei", "getrennte", "Probleme", "betrachtet", "werden", "-", "die", "bin\u00e4re", "Klassifizierung", "und", "die", "Multiklassen-Klassifizierung", "."], "sentence-detokenized": "Die Klassifizierung kann als zwei getrennte Probleme betrachtet werden - die bin\u00e4re Klassifizierung und die Multiklassen-Klassifizierung.", "token2charspan": [[0, 3], [4, 19], [20, 24], [25, 28], [29, 33], [34, 43], [44, 52], [53, 63], [64, 70], [71, 72], [73, 76], [77, 83], [84, 99], [100, 103], [104, 107], [108, 136], [136, 137]]}
{"doc_key": "ai-dev-145", "ner": [[4, 4, "product"], [7, 7, "product"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 4, 4, "type-of", "", false, false], [10, 10, 4, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Zwei", "Beispiele", "f\u00fcr", "beliebte", "Parallelroboter", "sind", "die", "Stewart-Plattform", "und", "der", "Delta-Roboter", "."], "sentence-detokenized": "Zwei Beispiele f\u00fcr beliebte Parallelroboter sind die Stewart-Plattform und der Delta-Roboter.", "token2charspan": [[0, 4], [5, 14], [15, 18], [19, 27], [28, 43], [44, 48], [49, 52], [53, 70], [71, 74], [75, 78], [79, 92], [92, 93]]}
{"doc_key": "ai-dev-146", "ner": [[4, 4, "algorithm"], [20, 20, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 20, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "Dennoch", "ist", "die", "ReLU-Aktivierungsfunktion", ",", "die", "bei", "0", "nicht", "differenzierbar", "ist", ",", "recht", "popul\u00e4r", "geworden", ",", "z.", "B.", "in", "AlexNet", ")"], "sentence-detokenized": "(Dennoch ist die ReLU-Aktivierungsfunktion, die bei 0 nicht differenzierbar ist, recht popul\u00e4r geworden, z. B. in AlexNet)", "token2charspan": [[0, 1], [1, 8], [9, 12], [13, 16], [17, 42], [42, 43], [44, 47], [48, 51], [52, 53], [54, 59], [60, 75], [76, 79], [79, 80], [81, 86], [87, 94], [95, 103], [103, 104], [105, 107], [108, 110], [111, 113], [114, 121], [121, 122]]}
{"doc_key": "ai-dev-147", "ner": [[1, 1, "metrics"], [7, 8, "task"], [14, 14, "task"], [21, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 3, 5], "relations": [[1, 1, 21, 22, "named", "", true, false], [7, 8, 1, 1, "usage", "", true, false], [14, 14, 7, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 3], "sentence": ["Der", "F-Score", "wird", "h\u00e4ufig", "im", "Bereich", "des", "Information", "Retrieval", "zur", "Messung", "der", "Such-", ",", "Dokumentenklassifizierungs-", "und", "Abfrageklassifizierungsleistung", "verwendet", ",", "so", "dass", "F_beta", "eine", "breite", "Anwendung", "erf\u00e4hrt", "."], "sentence-detokenized": "Der F-Score wird h\u00e4ufig im Bereich des Information Retrieval zur Messung der Such-, Dokumentenklassifizierungs- und Abfrageklassifizierungsleistung verwendet, so dass F_beta eine breite Anwendung erf\u00e4hrt.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 23], [24, 26], [27, 34], [35, 38], [39, 50], [51, 60], [61, 64], [65, 72], [73, 76], [77, 82], [82, 83], [84, 111], [112, 115], [116, 147], [148, 157], [157, 158], [159, 161], [162, 166], [167, 173], [174, 178], [179, 185], [186, 195], [196, 203], [203, 204]]}
{"doc_key": "ai-dev-148", "ner": [[12, 13, "algorithm"], [15, 15, "algorithm"], [18, 19, "algorithm"], [21, 21, "algorithm"], [24, 26, "algorithm"], [28, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[15, 15, 12, 13, "named", "", false, false], [21, 21, 18, 19, "named", "", false, false], [28, 28, 24, 26, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dazu", "wird", "das", "empfangene", "Signal", "modelliert", "und", "dann", "ein", "statistisches", "Sch\u00e4tzverfahren", "wie", "Maximum", "Likelihood", "(", "ML", ")", ",", "Majority", "Voting", "(", "MV", ")", "oder", "Maximum", "a", "Posteriori", "(", "MAP", ")", "verwendet", ",", "um", "zu", "entscheiden", ",", "welches", "Ziel", "in", "der", "Bibliothek", "am", "besten", "zu", "dem", "anhand", "des", "empfangenen", "Signals", "erstellten", "Modell", "passt", "."], "sentence-detokenized": "Dazu wird das empfangene Signal modelliert und dann ein statistisches Sch\u00e4tzverfahren wie Maximum Likelihood (ML), Majority Voting (MV) oder Maximum a Posteriori (MAP) verwendet, um zu entscheiden, welches Ziel in der Bibliothek am besten zu dem anhand des empfangenen Signals erstellten Modell passt.", "token2charspan": [[0, 4], [5, 9], [10, 13], [14, 24], [25, 31], [32, 42], [43, 46], [47, 51], [52, 55], [56, 69], [70, 85], [86, 89], [90, 97], [98, 108], [109, 110], [110, 112], [112, 113], [113, 114], [115, 123], [124, 130], [131, 132], [132, 134], [134, 135], [136, 140], [141, 148], [149, 150], [151, 161], [162, 163], [163, 166], [166, 167], [168, 177], [177, 178], [179, 181], [182, 184], [185, 196], [196, 197], [198, 205], [206, 210], [211, 213], [214, 217], [218, 228], [229, 231], [232, 238], [239, 241], [242, 245], [246, 252], [253, 256], [257, 268], [269, 276], [277, 287], [288, 294], [295, 300], [300, 301]]}
{"doc_key": "ai-dev-149", "ner": [[0, 0, "researcher"], [4, 4, "misc"], [6, 6, "field"], [8, 11, "university"], [15, 15, "misc"], [17, 18, "field"], [21, 22, "university"], [26, 26, "misc"], [28, 28, "field"], [31, 33, "university"], [39, 47, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 0, 8, 11, "physical", "", false, false], [0, 0, 8, 11, "role", "", false, false], [0, 0, 21, 22, "physical", "", false, false], [0, 0, 21, 22, "role", "", false, false], [0, 0, 31, 33, "physical", "", false, false], [0, 0, 31, 33, "role", "", false, false], [4, 4, 0, 0, "origin", "", false, false], [4, 4, 6, 6, "topic", "", false, false], [15, 15, 0, 0, "origin", "", false, false], [15, 15, 17, 18, "topic", "", false, false], [26, 26, 0, 0, "origin", "", false, false], [26, 26, 28, 28, "topic", "", false, false], [39, 47, 26, 26, "named", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Sowa", "erwarb", "1962", "einen", "BS", "in", "Mathematik", "am", "Massachusetts", "Institute", "of", "Technology", ",", "1966", "einen", "MA", "in", "Angewandter", "Informatik", "an", "der", "Harvard", "University", "und", "1999", "einen", "PhD", "in", "Informatik", "an", "der", "Vrije", "Universiteit", "Brussel", "mit", "einer", "Dissertation", "zum", "Thema", "Wissensrepr\u00e4sentation", ":", "Logical", ",", "Philosophical", ",", "and", "Computational", "Foundations", "."], "sentence-detokenized": "Sowa erwarb 1962 einen BS in Mathematik am Massachusetts Institute of Technology, 1966 einen MA in Angewandter Informatik an der Harvard University und 1999 einen PhD in Informatik an der Vrije Universiteit Brussel mit einer Dissertation zum Thema Wissensrepr\u00e4sentation: Logical, Philosophical, and Computational Foundations.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 22], [23, 25], [26, 28], [29, 39], [40, 42], [43, 56], [57, 66], [67, 69], [70, 80], [80, 81], [82, 86], [87, 92], [93, 95], [96, 98], [99, 110], [111, 121], [122, 124], [125, 128], [129, 136], [137, 147], [148, 151], [152, 156], [157, 162], [163, 166], [167, 169], [170, 180], [181, 183], [184, 187], [188, 193], [194, 206], [207, 214], [215, 218], [219, 224], [225, 237], [238, 241], [242, 247], [248, 269], [269, 270], [271, 278], [278, 279], [280, 293], [293, 294], [295, 298], [299, 312], [313, 324], [324, 325]]}
{"doc_key": "ai-dev-150", "ner": [[3, 5, "task"], [16, 16, "metrics"], [18, 18, "metrics"], [21, 21, "metrics"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[16, 16, 3, 5, "part-of", "", true, false], [18, 18, 3, 5, "part-of", "", true, false], [21, 21, 3, 5, "part-of", "", true, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Da", "sich", "die", "Erkennung", "von", "Umschreibungen", "als", "Klassifizierungsproblem", "darstellen", "l\u00e4sst", ",", "sind", "die", "meisten", "Standardbewertungsmetriken", "wie", "Genauigkeit", ",", "f1-Score", "oder", "eine", "ROC-Kurve", "relativ", "gut", "geeignet", "."], "sentence-detokenized": "Da sich die Erkennung von Umschreibungen als Klassifizierungsproblem darstellen l\u00e4sst, sind die meisten Standardbewertungsmetriken wie Genauigkeit, f1-Score oder eine ROC-Kurve relativ gut geeignet.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 21], [22, 25], [26, 40], [41, 44], [45, 68], [69, 79], [80, 85], [85, 86], [87, 91], [92, 95], [96, 103], [104, 130], [131, 134], [135, 146], [146, 147], [148, 156], [157, 161], [162, 166], [167, 176], [177, 184], [185, 188], [189, 197], [197, 198]]}
{"doc_key": "ai-dev-151", "ner": [[18, 18, "algorithm"], [27, 28, "algorithm"], [30, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 18, 27, 28, "opposite", "not_suited_for", false, false], [18, 18, 30, 31, "opposite", "not_suited_for", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Dies", "macht", "es", "praktisch", "f\u00fcr", "die", "Analyse", "gro\u00dfer", "Datens\u00e4tze", "(", "Hunderte", "oder", "Tausende", "von", "Taxa", ")", "und", "f\u00fcr", "Bootstrapping", ",", "f\u00fcr", "die", "andere", "Analysemethoden", "(", "z.", "B.", "Maximum", "Parsimony", ",", "Maximum", "Likelihood", ")", "zu", "rechenintensiv", "sein", "k\u00f6nnen", "."], "sentence-detokenized": "Dies macht es praktisch f\u00fcr die Analyse gro\u00dfer Datens\u00e4tze (Hunderte oder Tausende von Taxa) und f\u00fcr Bootstrapping, f\u00fcr die andere Analysemethoden (z. B. Maximum Parsimony, Maximum Likelihood) zu rechenintensiv sein k\u00f6nnen.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 23], [24, 27], [28, 31], [32, 39], [40, 46], [47, 57], [58, 59], [59, 67], [68, 72], [73, 81], [82, 85], [86, 90], [90, 91], [92, 95], [96, 99], [100, 113], [113, 114], [115, 118], [119, 122], [123, 129], [130, 145], [146, 147], [147, 149], [150, 152], [153, 160], [161, 170], [170, 171], [172, 179], [180, 190], [190, 191], [192, 194], [195, 209], [210, 214], [215, 221], [221, 222]]}
{"doc_key": "ai-dev-152", "ner": [[4, 4, "programlang"], [6, 6, "programlang"], [8, 11, "organisation"], [13, 15, "organisation"], [27, 37, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[13, 15, 8, 11, "named", "", false, false], [27, 37, 4, 4, "role", "submits", true, false], [27, 37, 6, 6, "role", "submits", true, false], [27, 37, 8, 11, "role", "submits_to", true, false]], "relations_mapping_to_source": [1, 2, 3, 4], "sentence": ["Die", "Einreichung", "der", "Sprache", "DAML", "+", "OIL", "beim", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", "im", "Jahr", "2002", "ist", "das", "Ergebnis", "der", "Arbeit", "der", "DAML-Vertragspartner", "und", "des", "gemeinsamen", "Ad-hoc-Ausschusses", "der", "Europ\u00e4ischen", "Union", "und", "der", "Vereinigten", "Staaten", "f\u00fcr", "Auszeichnungssprachen", "."], "sentence-detokenized": "Die Einreichung der Sprache DAML + OIL beim World Wide Web Consortium (W3C) im Jahr 2002 ist das Ergebnis der Arbeit der DAML-Vertragspartner und des gemeinsamen Ad-hoc-Ausschusses der Europ\u00e4ischen Union und der Vereinigten Staaten f\u00fcr Auszeichnungssprachen.", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 27], [28, 32], [33, 34], [35, 38], [39, 43], [44, 49], [50, 54], [55, 58], [59, 69], [70, 71], [71, 74], [74, 75], [76, 78], [79, 83], [84, 88], [89, 92], [93, 96], [97, 105], [106, 109], [110, 116], [117, 120], [121, 141], [142, 145], [146, 149], [150, 161], [162, 180], [181, 184], [185, 197], [198, 203], [204, 207], [208, 211], [212, 223], [224, 231], [232, 235], [236, 257], [257, 258]]}
{"doc_key": "ai-dev-153", "ner": [[4, 6, "misc"], [11, 11, "misc"], [13, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 4, 6, "part-of", "", true, false], [13, 13, 4, 6, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Ein", "Beispiel", "f\u00fcr", "eine", "nicht", "lineare", "Normalisierung", "ist", ",", "wenn", "die", "Normalisierung", "einer", "Sigmoidfunktion", "folgt", ".", "In", "diesem", "Fall", "wird", "das", "normalisierte", "Bild", "nach", "der", "folgenden", "Formel", "berechnet"], "sentence-detokenized": "Ein Beispiel f\u00fcr eine nicht lineare Normalisierung ist, wenn die Normalisierung einer Sigmoidfunktion folgt. In diesem Fall wird das normalisierte Bild nach der folgenden Formel berechnet", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 21], [22, 27], [28, 35], [36, 50], [51, 54], [54, 55], [56, 60], [61, 64], [65, 79], [80, 85], [86, 101], [102, 107], [107, 108], [109, 111], [112, 118], [119, 123], [124, 128], [129, 132], [133, 146], [147, 151], [152, 156], [157, 160], [161, 170], [171, 177], [178, 187]]}
{"doc_key": "ai-dev-154", "ner": [[7, 7, "metrics"], [13, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 7, 13, 13, "related-to", "used_together", false, false]], "relations_mapping_to_source": [0], "sentence": ["Es", "wurde", "darauf", "hingewiesen", ",", "dass", "die", "Genauigkeit", "in", "der", "Regel", "mit", "der", "Wiederauffindbarkeit", "gepaart", "wird", ",", "um", "dieses", "Problem", "zu", "l\u00f6sen", "."], "sentence-detokenized": "Es wurde darauf hingewiesen, dass die Genauigkeit in der Regel mit der Wiederauffindbarkeit gepaart wird, um dieses Problem zu l\u00f6sen.", "token2charspan": [[0, 2], [3, 8], [9, 15], [16, 27], [27, 28], [29, 33], [34, 37], [38, 49], [50, 52], [53, 56], [57, 62], [63, 66], [67, 70], [71, 91], [92, 99], [100, 104], [104, 105], [106, 108], [109, 115], [116, 123], [124, 126], [127, 132], [132, 133]]}
{"doc_key": "ai-dev-155", "ner": [[5, 7, "metrics"], [10, 12, "metrics"], [18, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 18, 10, 12, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Die", "gebr\u00e4uchlichsten", "Metriken", "sind", "der", "mittlere", "quadratische", "Fehler", "und", "der", "mittlere", "quadratische", "Wurzelfehler", ",", "wobei", "der", "letztere", "beim", "Netflix-Preis", "verwendet", "wurde", "."], "sentence-detokenized": "Die gebr\u00e4uchlichsten Metriken sind der mittlere quadratische Fehler und der mittlere quadratische Wurzelfehler, wobei der letztere beim Netflix-Preis verwendet wurde.", "token2charspan": [[0, 3], [4, 20], [21, 29], [30, 34], [35, 38], [39, 47], [48, 60], [61, 67], [68, 71], [72, 75], [76, 84], [85, 97], [98, 110], [110, 111], [112, 117], [118, 121], [122, 130], [131, 135], [136, 149], [150, 159], [160, 165], [165, 166]]}
{"doc_key": "ai-dev-156", "ner": [[8, 10, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Im", "August", "2016", "wurde", "ein", "Forschungsprogramm", "mit", "dem", "University", "College", "Hospital", "angek\u00fcndigt", ",", "dessen", "Ziel", "die", "Entwicklung", "eines", "Algorithmus", "ist", ",", "der", "automatisch", "zwischen", "gesundem", "und", "krebsartigem", "Gewebe", "im", "Kopf-", "und", "Halsbereich", "unterscheiden", "kann", "."], "sentence-detokenized": "Im August 2016 wurde ein Forschungsprogramm mit dem University College Hospital angek\u00fcndigt, dessen Ziel die Entwicklung eines Algorithmus ist, der automatisch zwischen gesundem und krebsartigem Gewebe im Kopf- und Halsbereich unterscheiden kann.", "token2charspan": [[0, 2], [3, 9], [10, 14], [15, 20], [21, 24], [25, 43], [44, 47], [48, 51], [52, 62], [63, 70], [71, 79], [80, 91], [91, 92], [93, 99], [100, 104], [105, 108], [109, 120], [121, 126], [127, 138], [139, 142], [142, 143], [144, 147], [148, 159], [160, 168], [169, 177], [178, 181], [182, 194], [195, 201], [202, 204], [205, 210], [211, 214], [215, 226], [227, 240], [241, 245], [245, 246]]}
{"doc_key": "ai-dev-157", "ner": [[14, 16, "organisation"], [19, 22, "organisation"], [25, 28, "organisation"], [31, 36, "organisation"], [39, 45, "organisation"], [48, 51, "organisation"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Der", "Einfluss", "von", "Posners", "theoretischen", "und", "empirischen", "Beitr\u00e4gen", "wurde", "durch", "die", "Mitgliedschaft", "in", "der", "American", "Psychological", "Association", ",", "der", "Association", "for", "Psychological", "Science", ",", "der", "Society", "of", "Experimental", "Psychologists", ",", "der", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "der", "American", "Association", "for", "the", "Advancement", "of", "Science", "und", "der", "National", "Academy", "of", "Sciences", "anerkannt", "."], "sentence-detokenized": "Der Einfluss von Posners theoretischen und empirischen Beitr\u00e4gen wurde durch die Mitgliedschaft in der American Psychological Association, der Association for Psychological Science, der Society of Experimental Psychologists, der American Academy of Arts and Sciences, der American Association for the Advancement of Science und der National Academy of Sciences anerkannt.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 24], [25, 38], [39, 42], [43, 54], [55, 64], [65, 70], [71, 76], [77, 80], [81, 95], [96, 98], [99, 102], [103, 111], [112, 125], [126, 137], [137, 138], [139, 142], [143, 154], [155, 158], [159, 172], [173, 180], [180, 181], [182, 185], [186, 193], [194, 196], [197, 209], [210, 223], [223, 224], [225, 228], [229, 237], [238, 245], [246, 248], [249, 253], [254, 257], [258, 266], [266, 267], [268, 271], [272, 280], [281, 292], [293, 296], [297, 300], [301, 312], [313, 315], [316, 323], [324, 327], [328, 331], [332, 340], [341, 348], [349, 351], [352, 360], [361, 370], [370, 371]]}
{"doc_key": "ai-dev-158", "ner": [[2, 2, "product"], [7, 8, "field"], [10, 10, "task"], [12, 13, "task"], [15, 15, "task"], [18, 19, "task"], [21, 21, "task"], [24, 25, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 2, 7, 8, "usage", "", false, false], [10, 10, 7, 8, "part-of", "", false, false], [12, 13, 7, 8, "part-of", "", false, false], [15, 15, 12, 13, "named", "", false, false], [18, 19, 7, 8, "part-of", "", false, false], [21, 21, 18, 19, "named", "", false, false], [24, 25, 7, 8, "part-of", "", false, false], [27, 28, 7, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Diese", "intelligenten", "Chatbots", "nutzen", "alle", "Arten", "von", "k\u00fcnstlicher", "Intelligenz", "wie", "Bildmoderation", "und", "nat\u00fcrliches", "Sprachverst\u00e4ndnis", "(", "NLU", ")", ",", "nat\u00fcrliche", "Sprachgenerierung", "(", "NLG", ")", ",", "maschinelles", "Lernen", "und", "Deep", "Learning", "."], "sentence-detokenized": "Diese intelligenten Chatbots nutzen alle Arten von k\u00fcnstlicher Intelligenz wie Bildmoderation und nat\u00fcrliches Sprachverst\u00e4ndnis (NLU), nat\u00fcrliche Sprachgenerierung (NLG), maschinelles Lernen und Deep Learning.", "token2charspan": [[0, 5], [6, 19], [20, 28], [29, 35], [36, 40], [41, 46], [47, 50], [51, 62], [63, 74], [75, 78], [79, 93], [94, 97], [98, 109], [110, 127], [128, 129], [129, 132], [132, 133], [133, 134], [135, 145], [146, 163], [164, 165], [165, 168], [168, 169], [169, 170], [171, 183], [184, 190], [191, 194], [195, 199], [200, 208], [208, 209]]}
{"doc_key": "ai-dev-159", "ner": [[4, 6, "metrics"], [8, 8, "metrics"], [11, 11, "metrics"], [15, 21, "metrics"], [27, 27, "metrics"], [29, 29, "metrics"], [32, 38, "metrics"], [43, 45, "metrics"], [47, 47, "metrics"], [50, 56, "metrics"], [62, 62, "metrics"], [64, 64, "metrics"], [67, 73, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 8, 4, 6, "named", "", false, false], [11, 11, 4, 6, "named", "", false, false], [15, 21, 4, 6, "named", "", false, false], [29, 29, 27, 27, "named", "", false, false], [32, 38, 27, 27, "named", "", false, false], [47, 47, 43, 45, "named", "", false, false], [50, 56, 43, 45, "named", "", false, false], [64, 64, 62, 62, "named", "", false, false], [67, 73, 62, 62, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Die", "Zeilenverh\u00e4ltnisse", "sind", "der", "positive", "pr\u00e4diktive", "Wert", "(", "PPV", ",", "auch", "Pr\u00e4zision", "genannt", ")", "(", "TP", "/", "(", "TP", "+", "FP", ")", ")", ",", "erg\u00e4nzt", "durch", "die", "FALSCH-Entdeckungsrate", "(", "FDR", ")", "(", "FP", "/", "(", "TP", "+", "FP", ")", ")", ";", "und", "der", "negative", "pr\u00e4diktive", "Wert", "(", "NPV", ")", "(", "TN", "/", "(", "TN", "+", "FN", ")", ")", ",", "erg\u00e4nzt", "durch", "die", "FALSCH-Auslassungsrate", "(", "FOR", ")", "(", "FN", "/", "(", "TN", "+", "FN", ")", ")", "."], "sentence-detokenized": "Die Zeilenverh\u00e4ltnisse sind der positive pr\u00e4diktive Wert (PPV, auch Pr\u00e4zision genannt) (TP / (TP + FP)), erg\u00e4nzt durch die FALSCH-Entdeckungsrate (FDR) (FP / (TP + FP)); und der negative pr\u00e4diktive Wert (NPV) (TN / (TN + FN)), erg\u00e4nzt durch die FALSCH-Auslassungsrate (FOR) (FN / (TN + FN)).", "token2charspan": [[0, 3], [4, 22], [23, 27], [28, 31], [32, 40], [41, 51], [52, 56], [57, 58], [58, 61], [61, 62], [63, 67], [68, 77], [78, 85], [85, 86], [87, 88], [88, 90], [91, 92], [93, 94], [94, 96], [97, 98], [99, 101], [101, 102], [102, 103], [103, 104], [105, 112], [113, 118], [119, 122], [123, 145], [146, 147], [147, 150], [150, 151], [152, 153], [153, 155], [156, 157], [158, 159], [159, 161], [162, 163], [164, 166], [166, 167], [167, 168], [168, 169], [170, 173], [174, 177], [178, 186], [187, 197], [198, 202], [203, 204], [204, 207], [207, 208], [209, 210], [210, 212], [213, 214], [215, 216], [216, 218], [219, 220], [221, 223], [223, 224], [224, 225], [225, 226], [227, 234], [235, 240], [241, 244], [245, 267], [268, 269], [269, 272], [272, 273], [274, 275], [275, 277], [278, 279], [280, 281], [281, 283], [284, 285], [286, 288], [288, 289], [289, 290], [290, 291]]}
{"doc_key": "ai-dev-160", "ner": [[8, 8, "misc"], [14, 14, "algorithm"], [16, 16, "algorithm"], [20, 22, "algorithm"], [24, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[16, 16, 14, 14, "named", "", false, false], [24, 24, 20, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Die", "Informationen", "sind", "eine", "Mischung", "aus", "Sitemaps", "und", "RSS", "und", "werden", "unter", "Verwendung", "des", "Informationsmodells", "(", "IM", ")", "und", "der", "Biomedical", "Resource", "Ontology", "(", "BRO", ")", "erstellt", "."], "sentence-detokenized": "Die Informationen sind eine Mischung aus Sitemaps und RSS und werden unter Verwendung des Informationsmodells (IM) und der Biomedical Resource Ontology (BRO) erstellt.", "token2charspan": [[0, 3], [4, 17], [18, 22], [23, 27], [28, 36], [37, 40], [41, 49], [50, 53], [54, 57], [58, 61], [62, 68], [69, 74], [75, 85], [86, 89], [90, 109], [110, 111], [111, 113], [113, 114], [115, 118], [119, 122], [123, 133], [134, 142], [143, 151], [152, 153], [153, 156], [156, 157], [158, 166], [166, 167]]}
{"doc_key": "ai-dev-161", "ner": [[2, 2, "task"], [6, 8, "algorithm"], [10, 10, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 2, 10, 10, "origin", "based_on", false, false], [10, 10, 6, 8, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Die", "neueste", "Texterkennung", "basiert", "auf", "einem", "rekurrenten", "neuronalen", "Netz", "(", "Langzeitged\u00e4chtnis", ")", "und", "erfordert", "kein", "Sprachmodell", "."], "sentence-detokenized": "Die neueste Texterkennung basiert auf einem rekurrenten neuronalen Netz (Langzeitged\u00e4chtnis) und erfordert kein Sprachmodell.", "token2charspan": [[0, 3], [4, 11], [12, 25], [26, 33], [34, 37], [38, 43], [44, 55], [56, 66], [67, 71], [72, 73], [73, 91], [91, 92], [93, 96], [97, 106], [107, 111], [112, 124], [124, 125]]}
{"doc_key": "ai-dev-162", "ner": [[1, 1, "misc"], [4, 4, "metrics"], [7, 8, "algorithm"], [12, 12, "metrics"], [15, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 1, 1, "type-of", "", false, false], [7, 8, 4, 4, "related-to", "", true, false], [12, 12, 1, 1, "type-of", "", false, false], [15, 16, 12, 12, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Beliebte", "Verlustfunktionen", "sind", "der", "Scharnierverlust", "(", "f\u00fcr", "lineare", "SVMs", ")", "und", "der", "log-Verlust", "(", "f\u00fcr", "logistische", "Regression", ")", "."], "sentence-detokenized": "Beliebte Verlustfunktionen sind der Scharnierverlust (f\u00fcr lineare SVMs) und der log-Verlust (f\u00fcr logistische Regression).", "token2charspan": [[0, 8], [9, 26], [27, 31], [32, 35], [36, 52], [53, 54], [54, 57], [58, 65], [66, 70], [70, 71], [72, 75], [76, 79], [80, 91], [92, 93], [93, 96], [97, 108], [109, 119], [119, 120], [120, 121]]}
{"doc_key": "ai-dev-163", "ner": [[0, 1, "metrics"], [9, 11, "metrics"], [13, 13, "metrics"], [17, 19, "metrics"], [21, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 9, 11, "compare", "", false, false], [0, 1, 17, 19, "compare", "", false, false], [13, 13, 9, 11, "named", "", false, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SSIM", "wurde", "entwickelt", ",", "um", "herk\u00f6mmliche", "Methoden", "wie", "den", "Spitzenwert", "des", "Signal-Rausch-Verh\u00e4ltnisses", "(", "PSNR", ")", "und", "den", "mittleren", "quadratischen", "Fehler", "(", "MSE", ")", "zu", "verbessern", "."], "sentence-detokenized": "SSIM wurde entwickelt, um herk\u00f6mmliche Methoden wie den Spitzenwert des Signal-Rausch-Verh\u00e4ltnisses (PSNR) und den mittleren quadratischen Fehler (MSE) zu verbessern.", "token2charspan": [[0, 4], [5, 10], [11, 21], [21, 22], [23, 25], [26, 38], [39, 47], [48, 51], [52, 55], [56, 67], [68, 71], [72, 99], [100, 101], [101, 105], [105, 106], [107, 110], [111, 114], [115, 124], [125, 138], [139, 145], [146, 147], [147, 150], [150, 151], [152, 154], [155, 165], [165, 166]]}
{"doc_key": "ai-dev-164", "ner": [[8, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Seine", "Arbeit", "inspirierte", "nachfolgende", "Generationen", "von", "Robotikforschern", "wie", "Rodney", "Brooks", ",", "Hans", "Moravec", "und", "Mark", "Tilden", "."], "sentence-detokenized": "Seine Arbeit inspirierte nachfolgende Generationen von Robotikforschern wie Rodney Brooks, Hans Moravec und Mark Tilden.", "token2charspan": [[0, 5], [6, 12], [13, 24], [25, 37], [38, 50], [51, 54], [55, 71], [72, 75], [76, 82], [83, 89], [89, 90], [91, 95], [96, 103], [104, 107], [108, 112], [113, 119], [119, 120]]}
{"doc_key": "ai-dev-165", "ner": [[10, 10, "algorithm"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Weiteres", "Impulstraining", "ist", "nicht", "differenzierbar", ",", "was", "Backpropagation-basierte", "Trainingsmethoden", "wie", "Gradientenabstieg", "ausschlie\u00dft", "."], "sentence-detokenized": "Weiteres Impulstraining ist nicht differenzierbar, was Backpropagation-basierte Trainingsmethoden wie Gradientenabstieg ausschlie\u00dft.", "token2charspan": [[0, 8], [9, 23], [24, 27], [28, 33], [34, 49], [49, 50], [51, 54], [55, 79], [80, 97], [98, 101], [102, 119], [120, 131], [131, 132]]}
{"doc_key": "ai-dev-166", "ner": [[7, 7, "metrics"], [15, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 7, 15, 15, "related-to", "describes", false, false]], "relations_mapping_to_source": [0], "sentence": ["Diese", "Beziehungen", "lassen", "sich", "leicht", "mit", "einer", "Konfusionsmatrix", "darstellen", ",", "einer", "Tabelle", ",", "die", "die", "Genauigkeit", "eines", "Klassifizierungsmodells", "beschreibt", "."], "sentence-detokenized": "Diese Beziehungen lassen sich leicht mit einer Konfusionsmatrix darstellen, einer Tabelle, die die Genauigkeit eines Klassifizierungsmodells beschreibt.", "token2charspan": [[0, 5], [6, 17], [18, 24], [25, 29], [30, 36], [37, 40], [41, 46], [47, 63], [64, 74], [74, 75], [76, 81], [82, 89], [89, 90], [91, 94], [95, 98], [99, 110], [111, 116], [117, 140], [141, 151], [151, 152]]}
{"doc_key": "ai-dev-167", "ner": [[2, 9, "conference"], [7, 7, "conference"], [13, 13, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 2, 9, "named", "", false, false], [13, 13, 2, 9, "physical", "", false, false], [13, 13, 2, 9, "role", "", false, false], [13, 13, 2, 9, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Auf", "der", "Konferenz", "f\u00fcr", "neuronale", "Informationsverarbeitungssysteme", "(", "NeurIPS", ")", "2018", "stellten", "Forscher", "von", "Google", "die", "Arbeit"], "sentence-detokenized": "Auf der Konferenz f\u00fcr neuronale Informationsverarbeitungssysteme (NeurIPS) 2018 stellten Forscher von Google die Arbeit", "token2charspan": [[0, 3], [4, 7], [8, 17], [18, 21], [22, 31], [32, 64], [65, 66], [66, 73], [73, 74], [75, 79], [80, 88], [89, 97], [98, 101], [102, 108], [109, 112], [113, 119]]}
{"doc_key": "ai-dev-168", "ner": [[5, 6, "university"], [13, 13, "product"], [22, 26, "misc"], [19, 19, "conference"], [29, 32, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 13, 22, 26, "win-defeat", "", false, false], [22, 26, 19, 19, "temporal", "", false, false], [29, 32, 19, 19, "part-of", "", false, false], [29, 32, 19, 19, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["W\u00e4hrend", "seiner", "Zeit", "an", "der", "Duke", "University", "arbeitete", "er", "an", "dem", "automatischen", "Kreuzwortr\u00e4tsel-L\u00f6ser", "PROVERB", ",", "der", "1999", "von", "der", "AAAI", "mit", "einem", "Outstanding", "Paper", "Award", "ausgezeichnet", "wurde", "und", "am", "American", "Crossword", "Puzzle", "Tournament", "teilnahm", "."], "sentence-detokenized": "W\u00e4hrend seiner Zeit an der Duke University arbeitete er an dem automatischen Kreuzwortr\u00e4tsel-L\u00f6ser PROVERB, der 1999 von der AAAI mit einem Outstanding Paper Award ausgezeichnet wurde und am American Crossword Puzzle Tournament teilnahm.", "token2charspan": [[0, 7], [8, 14], [15, 19], [20, 22], [23, 26], [27, 31], [32, 42], [43, 52], [53, 55], [56, 58], [59, 62], [63, 76], [77, 98], [99, 106], [106, 107], [108, 111], [112, 116], [117, 120], [121, 124], [125, 129], [130, 133], [134, 139], [140, 151], [152, 157], [158, 163], [164, 177], [178, 183], [184, 187], [188, 190], [191, 199], [200, 209], [210, 216], [217, 227], [228, 236], [236, 237]]}
{"doc_key": "ai-dev-169", "ner": [[6, 7, "location"], [9, 9, "location"], [19, 19, "country"], [21, 21, "country"], [23, 23, "country"], [25, 25, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 7, 9, 9, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Das", "Unternehmen", "hatte", "seinen", "Hauptsitz", "in", "Rochester", "Hills", ",", "Michigan", ",", "und", "verf\u00fcgte", "\u00fcber", "10", "regionale", "Standorte", "in", "den", "USA", ",", "Kanada", ",", "Mexiko", "und", "Brasilien", "."], "sentence-detokenized": "Das Unternehmen hatte seinen Hauptsitz in Rochester Hills, Michigan, und verf\u00fcgte \u00fcber 10 regionale Standorte in den USA, Kanada, Mexiko und Brasilien.", "token2charspan": [[0, 3], [4, 15], [16, 21], [22, 28], [29, 38], [39, 41], [42, 51], [52, 57], [57, 58], [59, 67], [67, 68], [69, 72], [73, 81], [82, 86], [87, 89], [90, 99], [100, 109], [110, 112], [113, 116], [117, 120], [120, 121], [122, 128], [128, 129], [130, 136], [137, 140], [141, 150], [150, 151]]}
{"doc_key": "ai-dev-170", "ner": [[16, 16, "product"], [19, 22, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Er", "reiht", "sich", "ein", "in", "eine", "Sammlung", "historisch", "bedeutender", "Roboter", ",", "zu", "denen", "auch", "ein", "fr\u00fcher", "Unimate", "und", "der", "Odetics", "Odex", "1", "geh\u00f6ren", "."], "sentence-detokenized": "Er reiht sich ein in eine Sammlung historisch bedeutender Roboter, zu denen auch ein fr\u00fcher Unimate und der Odetics Odex 1 geh\u00f6ren.", "token2charspan": [[0, 2], [3, 8], [9, 13], [14, 17], [18, 20], [21, 25], [26, 34], [35, 45], [46, 57], [58, 65], [65, 66], [67, 69], [70, 75], [76, 80], [81, 84], [85, 91], [92, 99], [100, 103], [104, 107], [108, 115], [116, 120], [121, 122], [123, 130], [130, 131]]}
{"doc_key": "ai-dev-171", "ner": [[4, 4, "researcher"], [8, 8, "organisation"], [10, 11, "researcher"], [19, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 8, 8, "physical", "", false, false], [4, 4, 8, 8, "role", "", false, false], [10, 11, 8, 8, "physical", "", false, false], [10, 11, 8, 8, "role", "", false, false], [10, 11, 19, 22, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Gastredakteur", "dieser", "Ausgabe", "wird", "Davids", "ehemaliger", "Kollege", "am", "NIST", ",", "Judah", "Levine", ",", "sein", ",", "der", "k\u00fcrzlich", "mit", "dem", "I.", "I.", "Rabi-Preises", "ist", "."], "sentence-detokenized": "Gastredakteur dieser Ausgabe wird Davids ehemaliger Kollege am NIST, Judah Levine, sein, der k\u00fcrzlich mit dem I. I. Rabi-Preises ist.", "token2charspan": [[0, 13], [14, 20], [21, 28], [29, 33], [34, 40], [41, 51], [52, 59], [60, 62], [63, 67], [67, 68], [69, 74], [75, 81], [81, 82], [83, 87], [87, 88], [89, 92], [93, 101], [102, 105], [106, 109], [110, 112], [113, 115], [116, 128], [129, 132], [132, 133]]}
{"doc_key": "ai-dev-172", "ner": [[8, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Diese", "k\u00f6nnen", "in", "einer", "2", "\u00d7", "2-Kontingenztabelle", "(", "Konfusionsmatrix", ")", "angeordnet", "werden", ",", "wobei", "\u00fcblicherweise", "das", "Testergebnis", "auf", "der", "vertikalen", "Achse", "und", "der", "tats\u00e4chliche", "Zustand", "auf", "der", "horizontalen", "Achse", "liegt", "."], "sentence-detokenized": "Diese k\u00f6nnen in einer 2 \u00d7 2-Kontingenztabelle (Konfusionsmatrix) angeordnet werden, wobei \u00fcblicherweise das Testergebnis auf der vertikalen Achse und der tats\u00e4chliche Zustand auf der horizontalen Achse liegt.", "token2charspan": [[0, 5], [6, 12], [13, 15], [16, 21], [22, 23], [24, 25], [26, 45], [46, 47], [47, 63], [63, 64], [65, 75], [76, 82], [82, 83], [84, 89], [90, 103], [104, 107], [108, 120], [121, 124], [125, 128], [129, 139], [140, 145], [146, 149], [150, 153], [154, 166], [167, 174], [175, 178], [179, 182], [183, 195], [196, 201], [202, 207], [207, 208]]}
{"doc_key": "ai-dev-173", "ner": [[1, 2, "product"], [7, 7, "product"], [10, 10, "product"], [13, 16, "product"], [20, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 7, 7, "part-of", "", false, false], [1, 2, 10, 10, "part-of", "", false, false], [1, 2, 13, 16, "part-of", "", false, false], [1, 2, 20, 21, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Das", "Apple-Betriebssystem", "iOS", ",", "das", "auf", "dem", "iPhone", ",", "dem", "iPad", "und", "dem", "iPod", "Touch", "verwendet", "wird", ",", "nutzt", "die", "Sprachsynthese", "VoiceOver", "f\u00fcr", "die", "Barrierefreiheit", "."], "sentence-detokenized": "Das Apple-Betriebssystem iOS, das auf dem iPhone, dem iPad und dem iPod Touch verwendet wird, nutzt die Sprachsynthese VoiceOver f\u00fcr die Barrierefreiheit.", "token2charspan": [[0, 3], [4, 24], [25, 28], [28, 29], [30, 33], [34, 37], [38, 41], [42, 48], [48, 49], [50, 53], [54, 58], [59, 62], [63, 66], [67, 71], [72, 77], [78, 87], [88, 92], [92, 93], [94, 99], [100, 103], [104, 118], [119, 128], [129, 132], [133, 136], [137, 153], [153, 154]]}
{"doc_key": "ai-dev-174", "ner": [[6, 6, "conference"], [15, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Das", "beste", "System", ",", "das", "in", "MUC-7", "eingegeben", "wurde", ",", "erreichte", "beispielsweise", "93,39", "%", "des", "F-Ma\u00dfes", ",", "w\u00e4hrend", "die", "menschlichen", "Annotatoren", "97,6", "%", "und", "96,95", "%", "erreichten", "."], "sentence-detokenized": "Das beste System, das in MUC-7 eingegeben wurde, erreichte beispielsweise 93,39 % des F-Ma\u00dfes, w\u00e4hrend die menschlichen Annotatoren 97,6 % und 96,95 % erreichten.", "token2charspan": [[0, 3], [4, 9], [10, 16], [16, 17], [18, 21], [22, 24], [25, 30], [31, 41], [42, 47], [47, 48], [49, 58], [59, 73], [74, 79], [80, 81], [82, 85], [86, 93], [93, 94], [95, 102], [103, 106], [107, 119], [120, 131], [132, 136], [137, 138], [139, 142], [143, 148], [149, 150], [151, 161], [161, 162]]}
{"doc_key": "ai-dev-175", "ner": [[12, 13, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 15, 12, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Dies", "geschieht", "mit", "Hilfe", "von", "Standard-Algorithmen", "zum", "Training", "neuronaler", "Netze", "wie", "dem", "stochastischen", "Gradientenabstieg", "mit", "Backpropagation", "."], "sentence-detokenized": "Dies geschieht mit Hilfe von Standard-Algorithmen zum Training neuronaler Netze wie dem stochastischen Gradientenabstieg mit Backpropagation.", "token2charspan": [[0, 4], [5, 14], [15, 18], [19, 24], [25, 28], [29, 49], [50, 53], [54, 62], [63, 73], [74, 79], [80, 83], [84, 87], [88, 102], [103, 120], [121, 124], [125, 140], [140, 141]]}
{"doc_key": "ai-dev-176", "ner": [[0, 1, "organisation"], [19, 19, "country"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 19, 19, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Rotten", "Tomatoes", "ist", "eine", "Top-1000-Website", ",", "die", "laut", "dem", "Website-Rankingdienst", "Alexa", "weltweit", "auf", "Platz", "400", "und", "nur", "in", "den", "USA", "auf", "Platz", "150", "liegt", "."], "sentence-detokenized": "Rotten Tomatoes ist eine Top-1000-Website, die laut dem Website-Rankingdienst Alexa weltweit auf Platz 400 und nur in den USA auf Platz 150 liegt.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 24], [25, 41], [41, 42], [43, 46], [47, 51], [52, 55], [56, 77], [78, 83], [84, 92], [93, 96], [97, 102], [103, 106], [107, 110], [111, 114], [115, 117], [118, 121], [122, 125], [126, 129], [130, 135], [136, 139], [140, 145], [145, 146]]}
{"doc_key": "ai-dev-177", "ner": [[16, 16, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Im", "Allgemeinen", "zeigt", "jegliches", "Lernen", "eine", "inkrementelle", "Ver\u00e4nderung", "im", "Laufe", "der", "Zeit", ",", "beschreibt", "aber", "eine", "Sigmoid-Funktion", ",", "die", "je", "nach", "Zeitskala", "der", "Beobachtung", "unterschiedliche", "Erscheinungsformen", "hat", "."], "sentence-detokenized": "Im Allgemeinen zeigt jegliches Lernen eine inkrementelle Ver\u00e4nderung im Laufe der Zeit, beschreibt aber eine Sigmoid-Funktion, die je nach Zeitskala der Beobachtung unterschiedliche Erscheinungsformen hat.", "token2charspan": [[0, 2], [3, 14], [15, 20], [21, 30], [31, 37], [38, 42], [43, 56], [57, 68], [69, 71], [72, 77], [78, 81], [82, 86], [86, 87], [88, 98], [99, 103], [104, 108], [109, 125], [125, 126], [127, 130], [131, 133], [134, 138], [139, 148], [149, 152], [153, 164], [165, 181], [182, 200], [201, 204], [204, 205]]}
{"doc_key": "ai-dev-178", "ner": [[1, 2, "metrics"], [5, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 5, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Der", "SSD", "wird", "auch", "als", "mittlerer", "quadratischer", "Fehler", "bezeichnet", "."], "sentence-detokenized": "Der SSD wird auch als mittlerer quadratischer Fehler bezeichnet.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 17], [18, 21], [22, 31], [32, 45], [46, 52], [53, 63], [63, 64]]}
{"doc_key": "ai-dev-179", "ner": [[0, 0, "algorithm"], [2, 3, "algorithm"], [6, 6, "algorithm"], [20, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 20, 21, "related-to", "can_be_related_to", true, false], [2, 3, 20, 21, "related-to", "can_be_related_to", true, false], [6, 6, 20, 21, "related-to", "can_be_related_to", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Entscheidungsbaum-Lernen", ",", "neuronale", "Netze", "oder", "ein", "Naive-Bayes-Klassifikator", "k\u00f6nnten", "in", "Kombination", "mit", "Ma\u00dfst\u00e4ben", "f\u00fcr", "die", "Modellqualit\u00e4t", ",", "wie", "z.", "B.", "der", "ausgewogenen", "Genauigkeit", ",", "verwendet", "werden", "."], "sentence-detokenized": "Entscheidungsbaum-Lernen, neuronale Netze oder ein Naive-Bayes-Klassifikator k\u00f6nnten in Kombination mit Ma\u00dfst\u00e4ben f\u00fcr die Modellqualit\u00e4t, wie z. B. der ausgewogenen Genauigkeit, verwendet werden.", "token2charspan": [[0, 24], [24, 25], [26, 35], [36, 41], [42, 46], [47, 50], [51, 76], [77, 84], [85, 87], [88, 99], [100, 103], [104, 113], [114, 117], [118, 121], [122, 136], [136, 137], [138, 141], [142, 144], [145, 147], [148, 151], [152, 164], [165, 176], [176, 177], [178, 187], [188, 194], [194, 195]]}
{"doc_key": "ai-dev-180", "ner": [[13, 13, "conference"], [17, 21, "conference"], [22, 24, "misc"], [29, 29, "product"], [33, 36, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[22, 24, 17, 21, "origin", "", false, false], [22, 24, 17, 21, "temporal", "", false, false], [29, 29, 22, 24, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Er", "ist", "ehemaliger", "Pr\u00e4sident", "(", "1979", ")", "und", "Gr\u00fcndungsmitglied", "(", "2011", ")", "der", "ACL", ",", "Mitpreistr\u00e4ger", "des", "1992", "Association", "for", "Computing", "Machinery", "Software", "Systems", "Award", "f\u00fcr", "seinen", "Beitrag", "zum", "Interlisp-Programmiersystem", "und", "Fellow", "der", "Association", "for", "Computing", "Machinery", "."], "sentence-detokenized": "Er ist ehemaliger Pr\u00e4sident (1979) und Gr\u00fcndungsmitglied (2011) der ACL, Mitpreistr\u00e4ger des 1992 Association for Computing Machinery Software Systems Award f\u00fcr seinen Beitrag zum Interlisp-Programmiersystem und Fellow der Association for Computing Machinery.", "token2charspan": [[0, 2], [3, 6], [7, 17], [18, 27], [28, 29], [29, 33], [33, 34], [35, 38], [39, 56], [57, 58], [58, 62], [62, 63], [64, 67], [68, 71], [71, 72], [73, 87], [88, 91], [92, 96], [97, 108], [109, 112], [113, 122], [123, 132], [133, 141], [142, 149], [150, 155], [156, 159], [160, 166], [167, 174], [175, 178], [179, 206], [207, 210], [211, 217], [218, 221], [222, 233], [234, 237], [238, 247], [248, 257], [257, 258]]}
{"doc_key": "ai-dev-181", "ner": [[2, 3, "researcher"], [5, 7, "researcher"], [8, 8, "researcher"], [10, 13, "researcher"], [26, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 26, 27, "related-to", "", false, false], [5, 7, 26, 27, "related-to", "", false, false], [8, 8, 26, 27, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Zusammen", "mit", "Geoffrey", "Hinton", "und", "Yann", "LeCun", "wird", "Bengio", "von", "Cade", "Metz", "als", "eine", "der", "drei", "Personen", "betrachtet", ",", "die", "am", "meisten", "f\u00fcr", "die", "Entwicklung", "des", "Deep", "Learning", "in", "den", "1990er", "und", "2000er", "Jahren", "verantwortlich", "waren", "."], "sentence-detokenized": "Zusammen mit Geoffrey Hinton und Yann LeCun wird Bengio von Cade Metz als eine der drei Personen betrachtet, die am meisten f\u00fcr die Entwicklung des Deep Learning in den 1990er und 2000er Jahren verantwortlich waren.", "token2charspan": [[0, 8], [9, 12], [13, 21], [22, 28], [29, 32], [33, 37], [38, 43], [44, 48], [49, 55], [56, 59], [60, 64], [65, 69], [70, 73], [74, 78], [79, 82], [83, 87], [88, 96], [97, 107], [107, 108], [109, 112], [113, 115], [116, 123], [124, 127], [128, 131], [132, 143], [144, 147], [148, 152], [153, 161], [162, 164], [165, 168], [169, 175], [176, 179], [180, 186], [187, 193], [194, 208], [209, 214], [214, 215]]}
{"doc_key": "ai-dev-182", "ner": [[2, 2, "field"], [5, 6, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "der", "Informationstheorie", "und", "der", "Informatik", "wird", "ein", "Code", "in", "der", "Regel", "als", "ein", "Algorithmus", "betrachtet", ",", "der", "Symbole", "aus", "einem", "Quellalphabet", "durch", "kodierte", "Zeichenketten", ",", "die", "in", "einem", "anderen", "Zielalphabet", "vorliegen", "k\u00f6nnen", ",", "eindeutig", "darstellt", "."], "sentence-detokenized": "In der Informationstheorie und der Informatik wird ein Code in der Regel als ein Algorithmus betrachtet, der Symbole aus einem Quellalphabet durch kodierte Zeichenketten, die in einem anderen Zielalphabet vorliegen k\u00f6nnen, eindeutig darstellt.", "token2charspan": [[0, 2], [3, 6], [7, 26], [27, 30], [31, 34], [35, 45], [46, 50], [51, 54], [55, 59], [60, 62], [63, 66], [67, 72], [73, 76], [77, 80], [81, 92], [93, 103], [103, 104], [105, 108], [109, 116], [117, 120], [121, 126], [127, 140], [141, 146], [147, 155], [156, 169], [169, 170], [171, 174], [175, 177], [178, 183], [184, 191], [192, 204], [205, 214], [215, 221], [221, 222], [223, 232], [233, 242], [242, 243]]}
{"doc_key": "ai-dev-183", "ner": [[7, 7, "algorithm"], [10, 11, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 11, 7, 7, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Als", "relativ", "einfache", "nichtlineare", "Funktion", "hat", "die", "Sigmoidfunktion", "wie", "die", "logistische", "Funktion", "auch", "eine", "leicht", "zu", "berechnende", "Ableitung", ",", "die", "bei", "der", "Berechnung", "der", "Gewichtsaktualisierungen", "im", "Netz", "wichtig", "sein", "kann", "."], "sentence-detokenized": "Als relativ einfache nichtlineare Funktion hat die Sigmoidfunktion wie die logistische Funktion auch eine leicht zu berechnende Ableitung, die bei der Berechnung der Gewichtsaktualisierungen im Netz wichtig sein kann.", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 33], [34, 42], [43, 46], [47, 50], [51, 66], [67, 70], [71, 74], [75, 86], [87, 95], [96, 100], [101, 105], [106, 112], [113, 115], [116, 127], [128, 137], [137, 138], [139, 142], [143, 146], [147, 150], [151, 161], [162, 165], [166, 190], [191, 193], [194, 198], [199, 206], [207, 211], [212, 216], [216, 217]]}
{"doc_key": "ai-dev-184", "ner": [[0, 1, "person"], [4, 4, "location"], [6, 6, "location"], [8, 8, "country"], [11, 11, "country"], [14, 15, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 4, 4, "physical", "", false, false], [4, 4, 6, 6, "physical", "", false, false], [6, 6, 8, 8, "physical", "", false, false], [6, 6, 11, 11, "physical", "", false, false], [6, 6, 14, 15, "physical", "", false, false], [11, 11, 8, 8, "origin", "", false, false], [14, 15, 11, 11, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["\u010capek", "wurde", "1887", "in", "Hronov", "in", "B\u00f6hmen", "(", "\u00d6sterreich-Ungarn", ",", "sp\u00e4ter", "Tschechoslowakei", ",", "heute", "Tschechische", "Republik", ")", "geboren", "."], "sentence-detokenized": "\u010capek wurde 1887 in Hronov in B\u00f6hmen (\u00d6sterreich-Ungarn, sp\u00e4ter Tschechoslowakei, heute Tschechische Republik) geboren.", "token2charspan": [[0, 5], [6, 11], [12, 16], [17, 19], [20, 26], [27, 29], [30, 36], [37, 38], [38, 55], [55, 56], [57, 63], [64, 80], [80, 81], [82, 87], [88, 100], [101, 109], [109, 110], [111, 118], [118, 119]]}
{"doc_key": "ai-dev-185", "ner": [[4, 4, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Einige", "spezielle", "Software", "kann", "RSS", "wiedergeben", "."], "sentence-detokenized": "Einige spezielle Software kann RSS wiedergeben.", "token2charspan": [[0, 6], [7, 16], [17, 25], [26, 30], [31, 34], [35, 46], [46, 47]]}
{"doc_key": "ai-dev-186", "ner": [[7, 7, "task"], [11, 11, "task"], [15, 15, "task"], [17, 19, "task"], [29, 29, "task"], [35, 35, "task"], [37, 37, "product"], [39, 40, "product"]], "ner_mapping_to_source": [0, 1, 3, 4, 6, 7, 8, 9], "relations": [[7, 7, 11, 11, "related-to", "", true, false], [7, 7, 15, 15, "related-to", "", true, false], [37, 37, 35, 35, "type-of", "", false, false], [39, 40, 35, 35, "type-of", "", false, false]], "relations_mapping_to_source": [0, 2, 4, 5], "sentence": ["Zu", "den", "Aspekten", "von", "Ontologie-Editoren", "geh\u00f6ren", ":", "visuelle", "Navigationsm\u00f6glichkeiten", "innerhalb", "des", "Wissensmodells", ",", "Inferenzmaschinen", "und", "Extraktion", ";", "Unterst\u00fctzung", "von", "Modulen", ";", "Import", "und", "Export", "von", "fremden", "Wissensrepr\u00e4sentationssprachen", "f\u00fcr", "den", "Ontologieabgleich", ";", "und", "die", "Unterst\u00fctzung", "von", "Metaontologien", "wie", "OWL-S", ",", "Dublin", "Core", "usw."], "sentence-detokenized": "Zu den Aspekten von Ontologie-Editoren geh\u00f6ren: visuelle Navigationsm\u00f6glichkeiten innerhalb des Wissensmodells, Inferenzmaschinen und Extraktion; Unterst\u00fctzung von Modulen; Import und Export von fremden Wissensrepr\u00e4sentationssprachen f\u00fcr den Ontologieabgleich; und die Unterst\u00fctzung von Metaontologien wie OWL-S, Dublin Core usw.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 19], [20, 38], [39, 46], [46, 47], [48, 56], [57, 81], [82, 91], [92, 95], [96, 110], [110, 111], [112, 129], [130, 133], [134, 144], [144, 145], [146, 159], [160, 163], [164, 171], [171, 172], [173, 179], [180, 183], [184, 190], [191, 194], [195, 202], [203, 233], [234, 237], [238, 241], [242, 259], [259, 260], [261, 264], [265, 268], [269, 282], [283, 286], [287, 301], [302, 305], [306, 311], [311, 312], [313, 319], [320, 324], [325, 329]]}
{"doc_key": "ai-dev-187", "ner": [[1, 1, "organisation"], [5, 10, "misc"], [27, 27, "task"], [19, 20, "field"], [22, 22, "misc"], [24, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 10, 1, 1, "origin", "", false, false], [27, 27, 5, 10, "part-of", "", false, false], [19, 20, 5, 10, "part-of", "", false, false], [22, 22, 19, 20, "type-of", "", false, false], [24, 26, 19, 20, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Das", "FBI", "hat", "au\u00dferdem", "ein", "Programm", "zur", "Identifizierung", "der", "n\u00e4chsten", "Generation", "ins", "Leben", "gerufen", ",", "das", "neben", "den", "herk\u00f6mmlichen", "biometrischen", "Merkmalen", "wie", "Fingerabdr\u00fccken", "und", "Iris-Scans", "auch", "die", "Gesichtserkennung", "einschlie\u00dft", "und", "auf", "straf-", "und", "zivilrechtliche", "Datenbanken", "zur\u00fcckgreifen", "kann", "."], "sentence-detokenized": "Das FBI hat au\u00dferdem ein Programm zur Identifizierung der n\u00e4chsten Generation ins Leben gerufen, das neben den herk\u00f6mmlichen biometrischen Merkmalen wie Fingerabdr\u00fccken und Iris-Scans auch die Gesichtserkennung einschlie\u00dft und auf straf- und zivilrechtliche Datenbanken zur\u00fcckgreifen kann.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 20], [21, 24], [25, 33], [34, 37], [38, 53], [54, 57], [58, 66], [67, 77], [78, 81], [82, 87], [88, 95], [95, 96], [97, 100], [101, 106], [107, 110], [111, 124], [125, 138], [139, 148], [149, 152], [153, 168], [169, 172], [173, 183], [184, 188], [189, 192], [193, 210], [211, 222], [223, 226], [227, 230], [231, 237], [238, 241], [242, 257], [258, 269], [270, 283], [284, 288], [288, 289]]}
{"doc_key": "ai-dev-188", "ner": [[5, 6, "person"], [12, 13, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["F\u00fcr", "die", "Saison", "2016", "wurde", "Samantha", "Ponder", "als", "Moderatorin", "hinzugef\u00fcgt", ",", "die", "Molly", "McGrath", "abl\u00f6ste", "."], "sentence-detokenized": "F\u00fcr die Saison 2016 wurde Samantha Ponder als Moderatorin hinzugef\u00fcgt, die Molly McGrath abl\u00f6ste.", "token2charspan": [[0, 3], [4, 7], [8, 14], [15, 19], [20, 25], [26, 34], [35, 41], [42, 45], [46, 57], [58, 69], [69, 70], [71, 74], [75, 80], [81, 88], [89, 96], [96, 97]]}
{"doc_key": "ai-dev-189", "ner": [[5, 6, "algorithm"], [17, 17, "misc"], [19, 19, "misc"], [21, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Es", "handelt", "sich", "um", "einen", "kontradiktorischen", "Suchalgorithmus", ",", "der", "\u00fcblicherweise", "f\u00fcr", "das", "maschinelle", "Spielen", "von", "Zwei-Personen-Spielen", "(", "Tic-Tac-Toe", ",", "Schach", ",", "Go", "usw.", ")", "verwendet", "wird", "."], "sentence-detokenized": "Es handelt sich um einen kontradiktorischen Suchalgorithmus, der \u00fcblicherweise f\u00fcr das maschinelle Spielen von Zwei-Personen-Spielen (Tic-Tac-Toe, Schach, Go usw.) verwendet wird.", "token2charspan": [[0, 2], [3, 10], [11, 15], [16, 18], [19, 24], [25, 43], [44, 59], [59, 60], [61, 64], [65, 78], [79, 82], [83, 86], [87, 98], [99, 106], [107, 110], [111, 132], [133, 134], [134, 145], [145, 146], [147, 153], [153, 154], [155, 157], [158, 162], [162, 163], [164, 173], [174, 178], [178, 179]]}
{"doc_key": "ai-dev-190", "ner": [[4, 5, "field"], [7, 8, "field"], [10, 11, "field"], [19, 19, "field"], [22, 23, "field"], [26, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sie", "umfasst", "die", "Bereiche", "Computer", "Vision", "oder", "maschinelles", "Sehen", "und", "medizinische", "Bildgebung", "und", "bedient", "sich", "in", "hohem", "Ma\u00dfe", "der", "Mustererkennung", ",", "der", "digitalen", "Geometrie", "und", "der", "Signalverarbeitung", "."], "sentence-detokenized": "Sie umfasst die Bereiche Computer Vision oder maschinelles Sehen und medizinische Bildgebung und bedient sich in hohem Ma\u00dfe der Mustererkennung, der digitalen Geometrie und der Signalverarbeitung.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 24], [25, 33], [34, 40], [41, 45], [46, 58], [59, 64], [65, 68], [69, 81], [82, 92], [93, 96], [97, 104], [105, 109], [110, 112], [113, 118], [119, 123], [124, 127], [128, 143], [143, 144], [145, 148], [149, 158], [159, 168], [169, 172], [173, 176], [177, 195], [195, 196]]}
{"doc_key": "ai-dev-191", "ner": [[2, 2, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Bei", "einem", "Gesichtserkennungssystem", "w\u00e4re", "beispielsweise", "ein", "Bild", "des", "Gesichts", "einer", "Person", "die", "Eingabe", ",", "und", "die", "Ausgabebezeichnung", "w\u00e4re", "der", "Name", "dieser", "Person", "."], "sentence-detokenized": "Bei einem Gesichtserkennungssystem w\u00e4re beispielsweise ein Bild des Gesichts einer Person die Eingabe, und die Ausgabebezeichnung w\u00e4re der Name dieser Person.", "token2charspan": [[0, 3], [4, 9], [10, 34], [35, 39], [40, 54], [55, 58], [59, 63], [64, 67], [68, 76], [77, 82], [83, 89], [90, 93], [94, 101], [101, 102], [103, 106], [107, 110], [111, 129], [130, 134], [135, 138], [139, 143], [144, 150], [151, 157], [157, 158]]}
{"doc_key": "ai-dev-192", "ner": [[0, 1, "organisation"], [3, 4, "product"], [8, 9, "product"], [14, 15, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 3, 4, "artifact", "", false, false], [3, 4, 8, 9, "part-of", "", false, false], [8, 9, 3, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Apple", "Inc.", "hat", "Face", "ID", "auf", "dem", "Flaggschiff", "iPhone", "X", "als", "biometrischen", "Authentifizierungsnachfolger", "von", "Touch", "ID", ",", "einem", "auf", "Fingerabdr\u00fccken", "basierenden", "System", ",", "eingef\u00fchrt", "."], "sentence-detokenized": "Apple Inc. hat Face ID auf dem Flaggschiff iPhone X als biometrischen Authentifizierungsnachfolger von Touch ID, einem auf Fingerabdr\u00fccken basierenden System, eingef\u00fchrt.", "token2charspan": [[0, 5], [6, 10], [11, 14], [15, 19], [20, 22], [23, 26], [27, 30], [31, 42], [43, 49], [50, 51], [52, 55], [56, 69], [70, 98], [99, 102], [103, 108], [109, 111], [111, 112], [113, 118], [119, 122], [123, 138], [139, 150], [151, 157], [157, 158], [159, 169], [169, 170]]}
{"doc_key": "ai-dev-193", "ner": [[4, 4, "metrics"], [7, 7, "metrics"], [21, 21, "metrics"], [24, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Oder", "kombinieren", "Sie", "das", "F-Ma\u00df", "mit", "dem", "R-Quadrat", ",", "das", "f\u00fcr", "den", "Rohmodell-Output", "und", "das", "Ziel", "ausgewertet", "wurde", ",", "oder", "die", "Kosten/Gewinn-Matrix", "mit", "dem", "Korrelationskoeffizienten", "usw."], "sentence-detokenized": "Oder kombinieren Sie das F-Ma\u00df mit dem R-Quadrat, das f\u00fcr den Rohmodell-Output und das Ziel ausgewertet wurde, oder die Kosten/Gewinn-Matrix mit dem Korrelationskoeffizienten usw.", "token2charspan": [[0, 4], [5, 16], [17, 20], [21, 24], [25, 30], [31, 34], [35, 38], [39, 48], [48, 49], [50, 53], [54, 57], [58, 61], [62, 78], [79, 82], [83, 86], [87, 91], [92, 103], [104, 109], [109, 110], [111, 115], [116, 119], [120, 140], [141, 144], [145, 148], [149, 174], [175, 179]]}
{"doc_key": "ai-dev-194", "ner": [[1, 6, "conference"], [13, 16, "location"], [18, 18, "location"], [23, 28, "location"], [30, 30, "location"], [32, 32, "country"], [37, 39, "location"], [43, 47, "location"], [49, 50, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[1, 6, 13, 16, "physical", "", false, false], [1, 6, 23, 28, "physical", "", false, false], [1, 6, 37, 39, "physical", "", false, false], [1, 6, 43, 47, "physical", "", false, false], [13, 16, 18, 18, "physical", "", false, false], [23, 28, 30, 30, "physical", "", false, false], [30, 30, 32, 32, "physical", "", false, false], [37, 39, 49, 50, "physical", "", false, false], [43, 47, 49, 50, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Die", "spanische", "Ausgabe", "der", "Campus", "Party", "fand", "in", "den", "letzten", "15", "Jahren", "im", "Colegio", "Miguel", "Hern", "\u00e1ndez", ",", "Ceulaj", ",", "und", "in", "der", "st\u00e4dtischen", "Sportarena", "von", "Benalm", "\u00e1", "dena", "in", "M\u00e1laga", ",", "Spanien", ",", "sowie", "auf", "der", "Landesmesse", "von", "Valencia", "und", "in", "der", "Stadt", "der", "K\u00fcnste", "und", "Wissenschaften", "in", "Valencia", "statt", "."], "sentence-detokenized": "Die spanische Ausgabe der Campus Party fand in den letzten 15 Jahren im Colegio Miguel Hern\u00e1ndez, Ceulaj, und in der st\u00e4dtischen Sportarena von Benalm\u00e1dena in M\u00e1laga, Spanien, sowie auf der Landesmesse von Valencia und in der Stadt der K\u00fcnste und Wissenschaften in Valencia statt.", "token2charspan": [[0, 3], [4, 13], [14, 21], [22, 25], [26, 32], [33, 38], [39, 43], [44, 46], [47, 50], [51, 58], [59, 61], [62, 68], [69, 71], [72, 79], [80, 86], [87, 91], [91, 96], [96, 97], [98, 104], [104, 105], [106, 109], [110, 112], [113, 116], [117, 128], [129, 139], [140, 143], [144, 150], [150, 151], [151, 155], [156, 158], [159, 165], [165, 166], [167, 174], [174, 175], [176, 181], [182, 185], [186, 189], [190, 201], [202, 205], [206, 214], [215, 218], [219, 221], [222, 225], [226, 231], [232, 235], [236, 242], [243, 246], [247, 261], [262, 264], [265, 273], [274, 279], [279, 280]]}
{"doc_key": "ai-dev-195", "ner": [[0, 0, "product"], [15, 15, "programlang"], [18, 18, "product"], [23, 23, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[15, 15, 0, 0, "general-affiliation", "", false, false], [18, 18, 15, 15, "part-of", "", false, false], [23, 23, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 3], "sentence": ["gnuplot", "kann", "von", "verschiedenen", "Programmiersprachen", "aus", "verwendet", "werden", ",", "um", "Daten", "grafisch", "darzustellen", ",", "einschlie\u00dflich", "Perl", "(", "\u00fcber", "PDL", "und", "CPAN-Pakete", ")", ",", "Python", "(", "\u00fcber", ")", "."], "sentence-detokenized": "gnuplot kann von verschiedenen Programmiersprachen aus verwendet werden, um Daten grafisch darzustellen, einschlie\u00dflich Perl (\u00fcber PDL und CPAN-Pakete), Python (\u00fcber).", "token2charspan": [[0, 7], [8, 12], [13, 16], [17, 30], [31, 50], [51, 54], [55, 64], [65, 71], [71, 72], [73, 75], [76, 81], [82, 90], [91, 103], [103, 104], [105, 119], [120, 124], [125, 126], [126, 130], [131, 134], [135, 138], [139, 150], [150, 151], [151, 152], [153, 159], [160, 161], [161, 165], [165, 166], [166, 167]]}
{"doc_key": "ai-dev-196", "ner": [[3, 4, "product"], [19, 19, "conference"], [21, 21, "conference"], [34, 34, "conference"], [36, 36, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 19, 3, 4, "topic", "", false, false], [21, 21, 3, 4, "topic", "", false, false], [34, 34, 3, 4, "topic", "", false, false], [36, 36, 3, 4, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Der", "Bereich", "der", "gesprochenen", "Dialogsysteme", "ist", "recht", "gro\u00df", "und", "umfasst", "so", "wohl", "die", "Forschung", "(", "auf", "wissenschaftlichen", "Konferenzen", "wie", "SIGdial", "und", "Interspeech", ")", "als", "auch", "einen", "gro\u00dfen", "industriellen", "Sektor", "(", "mit", "eigenen", "Konferenzen", "wie", "SpeechTek", "und", "AVIOS", ")", "."], "sentence-detokenized": "Der Bereich der gesprochenen Dialogsysteme ist recht gro\u00df und umfasst sowohl die Forschung (auf wissenschaftlichen Konferenzen wie SIGdial und Interspeech) als auch einen gro\u00dfen industriellen Sektor (mit eigenen Konferenzen wie SpeechTek und AVIOS).", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 28], [29, 42], [43, 46], [47, 52], [53, 57], [58, 61], [62, 69], [70, 72], [72, 76], [77, 80], [81, 90], [91, 92], [92, 95], [96, 114], [115, 126], [127, 130], [131, 138], [139, 142], [143, 154], [154, 155], [156, 159], [160, 164], [165, 170], [171, 177], [178, 191], [192, 198], [199, 200], [200, 203], [204, 211], [212, 223], [224, 227], [228, 237], [238, 241], [242, 247], [247, 248], [248, 249]]}
{"doc_key": "ai-dev-197", "ner": [[4, 6, "field"], [10, 10, "task"], [13, 15, "task"], [18, 20, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 10, 4, 6, "part-of", "task_part_of_field", false, false], [13, 15, 4, 6, "part-of", "task_part_of_field", false, false], [18, 20, 4, 6, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Die", "Herausforderungen", "bei", "der", "Verarbeitung", "nat\u00fcrlicher", "Sprache", "betreffen", "h\u00e4ufig", "die", "Spracherkennung", ",", "das", "Verstehen", "nat\u00fcrlicher", "Sprache", "und", "die", "Erzeugung", "nat\u00fcrlicher", "Sprache", "."], "sentence-detokenized": "Die Herausforderungen bei der Verarbeitung nat\u00fcrlicher Sprache betreffen h\u00e4ufig die Spracherkennung, das Verstehen nat\u00fcrlicher Sprache und die Erzeugung nat\u00fcrlicher Sprache.", "token2charspan": [[0, 3], [4, 21], [22, 25], [26, 29], [30, 42], [43, 54], [55, 62], [63, 72], [73, 79], [80, 83], [84, 99], [99, 100], [101, 104], [105, 114], [115, 126], [127, 134], [135, 138], [139, 142], [143, 152], [153, 164], [165, 172], [172, 173]]}
{"doc_key": "ai-dev-198", "ner": [[6, 6, "product"], [8, 8, "product"], [27, 27, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 8, 8, "part-of", "", false, false], [6, 6, 27, 27, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Diese", "Systeme", ",", "wie", "z.", "B.", "Siri", "des", "iOS-Betriebssystems", ",", "arbeiten", "mit", "einer", "\u00e4hnlichen", "Mustererkennungstechnik", "wie", "die", "textbasierten", "Systeme", ",", "aber", "bei", "ersteren", "erfolgt", "die", "Benutzereingabe", "durch", "Spracherkennung", "."], "sentence-detokenized": "Diese Systeme, wie z. B. Siri des iOS-Betriebssystems, arbeiten mit einer \u00e4hnlichen Mustererkennungstechnik wie die textbasierten Systeme, aber bei ersteren erfolgt die Benutzereingabe durch Spracherkennung.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 18], [19, 21], [22, 24], [25, 29], [30, 33], [34, 53], [53, 54], [55, 63], [64, 67], [68, 73], [74, 83], [84, 107], [108, 111], [112, 115], [116, 129], [130, 137], [137, 138], [139, 143], [144, 147], [148, 156], [157, 164], [165, 168], [169, 184], [185, 190], [191, 206], [206, 207]]}
{"doc_key": "ai-dev-199", "ner": [[2, 3, "algorithm"], [15, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 15, 15, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Zu", "den", "exotischeren", "Fitnessfunktionen", ",", "die", "die", "Modellgranularit\u00e4t", "untersuchen", ",", "geh\u00f6ren", "die", "Fl\u00e4che", "unter", "der", "ROC-Kurve", "und", "das", "Rangma\u00df", "."], "sentence-detokenized": "Zu den exotischeren Fitnessfunktionen, die die Modellgranularit\u00e4t untersuchen, geh\u00f6ren die Fl\u00e4che unter der ROC-Kurve und das Rangma\u00df.", "token2charspan": [[0, 2], [3, 6], [7, 19], [20, 37], [37, 38], [39, 42], [43, 46], [47, 65], [66, 77], [77, 78], [79, 86], [87, 90], [91, 97], [98, 103], [104, 107], [108, 117], [118, 121], [122, 125], [126, 133], [133, 134]]}
{"doc_key": "ai-dev-200", "ner": [[2, 3, "product"], [6, 7, "researcher"], [13, 15, "product"], [19, 22, "organisation"], [24, 24, "organisation"], [32, 33, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 6, 7, "origin", "", false, false], [6, 7, 19, 22, "role", "", false, false], [13, 15, 6, 7, "origin", "", false, false], [24, 24, 19, 22, "named", "", false, false], [32, 33, 19, 22, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Der", "Begriff", "Semantic", "Web", "wurde", "von", "Tim", "Berners-Lee", "gepr\u00e4gt", ",", "dem", "Erfinder", "des", "World", "Wide", "Web", "und", "Direktor", "des", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", ",", "das", "die", "Entwicklung", "der", "vorgeschlagenen", "Semantic", "Web-Standards", "\u00fcberwacht", "."], "sentence-detokenized": "Der Begriff Semantic Web wurde von Tim Berners-Lee gepr\u00e4gt, dem Erfinder des World Wide Web und Direktor des World Wide Web Consortium (W3C), das die Entwicklung der vorgeschlagenen Semantic Web-Standards \u00fcberwacht.", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 24], [25, 30], [31, 34], [35, 38], [39, 50], [51, 58], [58, 59], [60, 63], [64, 72], [73, 76], [77, 82], [83, 87], [88, 91], [92, 95], [96, 104], [105, 108], [109, 114], [115, 119], [120, 123], [124, 134], [135, 136], [136, 139], [139, 140], [140, 141], [142, 145], [146, 149], [150, 161], [162, 165], [166, 181], [182, 190], [191, 204], [205, 214], [214, 215]]}
{"doc_key": "ai-dev-201", "ner": [[0, 1, "task"], [8, 9, "task"], [15, 16, "product"], [18, 20, "product"], [22, 22, "product"], [25, 26, "product"], [33, 33, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 15, 16, "opposite", "", false, false], [0, 1, 18, 20, "opposite", "", false, false], [0, 1, 25, 26, "opposite", "", false, false], [0, 1, 33, 33, "part-of", "", false, false], [8, 9, 0, 1, "named", "", false, false], [22, 22, 18, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Maschinelle", "\u00dcbersetzung", ",", "manchmal", "auch", "mit", "der", "Abk\u00fcrzung", "MT", "bezeichnet", "(", "nicht", "zu", "verwechseln", "mit", "computergest\u00fctzter", "\u00dcbersetzung", ",", "maschinengest\u00fctzter", "menschlicher", "\u00dcbersetzung", "(", "MAHT", ")", "oder", "interaktiver", "\u00dcbersetzung", ")", ",", "ist", "ein", "Teilgebiet", "der", "Computerlinguistik", ",", "das", "den", "Einsatz", "von", "Software", "zur", "\u00dcbersetzung", "von", "Text", "oder", "Sprache", "von", "einer", "Sprache", "in", "eine", "andere", "untersucht", "."], "sentence-detokenized": "Maschinelle \u00dcbersetzung, manchmal auch mit der Abk\u00fcrzung MT bezeichnet (nicht zu verwechseln mit computergest\u00fctzter \u00dcbersetzung, maschinengest\u00fctzter menschlicher \u00dcbersetzung (MAHT) oder interaktiver \u00dcbersetzung), ist ein Teilgebiet der Computerlinguistik, das den Einsatz von Software zur \u00dcbersetzung von Text oder Sprache von einer Sprache in eine andere untersucht.", "token2charspan": [[0, 11], [12, 23], [23, 24], [25, 33], [34, 38], [39, 42], [43, 46], [47, 56], [57, 59], [60, 70], [71, 72], [72, 77], [78, 80], [81, 92], [93, 96], [97, 115], [116, 127], [127, 128], [129, 148], [149, 161], [162, 173], [174, 175], [175, 179], [179, 180], [181, 185], [186, 198], [199, 210], [210, 211], [211, 212], [213, 216], [217, 220], [221, 231], [232, 235], [236, 254], [254, 255], [256, 259], [260, 263], [264, 271], [272, 275], [276, 284], [285, 288], [289, 300], [301, 304], [305, 309], [310, 314], [315, 322], [323, 326], [327, 332], [333, 340], [341, 343], [344, 348], [349, 355], [356, 366], [366, 367]]}
{"doc_key": "ai-dev-202", "ner": [[1, 3, "product"], [10, 10, "university"], [12, 13, "researcher"], [15, 16, "researcher"], [37, 37, "location"], [39, 39, "location"], [43, 45, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 3, 12, 13, "artifact", "", false, false], [1, 3, 15, 16, "artifact", "", false, false], [12, 13, 10, 10, "physical", "", false, false], [12, 13, 10, 10, "role", "", false, false], [15, 16, 10, 10, "physical", "", false, false], [15, 16, 10, 10, "role", "", false, false], [37, 37, 39, 39, "physical", "", false, false], [43, 45, 37, 37, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Fr\u00fche", "interlinguale", "maschinelle", "\u00dcbersetzungssysteme", "wurden", "in", "den", "1970er", "Jahren", "in", "Stanford", "von", "Roger", "Schank", "und", "Yorick", "Wilks", "entwickelt", ".", "Ersteres", "wurde", "zur", "Grundlage", "eines", "kommerziellen", "Systems", "f\u00fcr", "den", "Geldtransfer", ",", "und", "der", "Code", "des", "letzteren", "wird", "im", "Computermuseum", "in", "Boston", "als", "das", "erste", "interlinguale", "maschinelle", "\u00dcbersetzungssystem", "aufbewahrt", "."], "sentence-detokenized": "Fr\u00fche interlinguale maschinelle \u00dcbersetzungssysteme wurden in den 1970er Jahren in Stanford von Roger Schank und Yorick Wilks entwickelt. Ersteres wurde zur Grundlage eines kommerziellen Systems f\u00fcr den Geldtransfer, und der Code des letzteren wird im Computermuseum in Boston als das erste interlinguale maschinelle \u00dcbersetzungssystem aufbewahrt.", "token2charspan": [[0, 5], [6, 19], [20, 31], [32, 51], [52, 58], [59, 61], [62, 65], [66, 72], [73, 79], [80, 82], [83, 91], [92, 95], [96, 101], [102, 108], [109, 112], [113, 119], [120, 125], [126, 136], [136, 137], [138, 146], [147, 152], [153, 156], [157, 166], [167, 172], [173, 186], [187, 194], [195, 198], [199, 202], [203, 215], [215, 216], [217, 220], [221, 224], [225, 229], [230, 233], [234, 243], [244, 248], [249, 251], [252, 266], [267, 269], [270, 276], [277, 280], [281, 284], [285, 290], [291, 304], [305, 316], [317, 335], [336, 346], [346, 347]]}
{"doc_key": "ai-dev-203", "ner": [[0, 0, "researcher"], [5, 8, "conference"], [10, 11, "conference"], [17, 22, "conference"], [24, 25, "conference"], [30, 32, "organisation"], [39, 39, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 5, 8, "role", "", false, false], [0, 0, 17, 22, "role", "", false, false], [0, 0, 30, 32, "role", "", false, false], [0, 0, 39, 39, "role", "", false, false], [10, 11, 5, 8, "named", "", false, false], [24, 25, 17, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sycara", "war", "der", "Programmvorsitzende", "der", "Zweiten", "Internationalen", "Semantischen", "Webkonferenz", "(", "ISWC", "2003", ")", ";", "allgemeiner", "Vorsitzender", "der", "Zweiten", "Internationalen", "Konferenz", "\u00fcber", "autonome", "Agenten", "(", "Agents", "98", ")", ";", "Vorsitzender", "des", "Lenkungsausschusses", "der", "Agenten-Konferenz", "(", "1999-2001", ")", ";", "Stipendienvorsitzender", "der", "AAAI", "(", "1993-1999", ")", ";"], "sentence-detokenized": "Sycara war der Programmvorsitzende der Zweiten Internationalen Semantischen Webkonferenz (ISWC 2003); allgemeiner Vorsitzender der Zweiten Internationalen Konferenz \u00fcber autonome Agenten (Agents 98); Vorsitzender des Lenkungsausschusses der Agenten-Konferenz (1999-2001); Stipendienvorsitzender der AAAI (1993-1999);", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 34], [35, 38], [39, 46], [47, 62], [63, 75], [76, 88], [89, 90], [90, 94], [95, 99], [99, 100], [100, 101], [102, 113], [114, 126], [127, 130], [131, 138], [139, 154], [155, 164], [165, 169], [170, 178], [179, 186], [187, 188], [188, 194], [195, 197], [197, 198], [198, 199], [200, 212], [213, 216], [217, 236], [237, 240], [241, 258], [259, 260], [260, 269], [269, 270], [270, 271], [272, 294], [295, 298], [299, 303], [304, 305], [305, 314], [314, 315], [315, 316]]}
{"doc_key": "ai-dev-204", "ner": [[7, 7, "conference"], [9, 12, "conference"], [14, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 12, 7, 7, "named", "", false, false], [14, 17, 7, 7, "part-of", "", false, false], [14, 17, 7, 7, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Im", "Jahr", "2016", "wurde", "sie", "mit", "dem", "ACL", "(", "Association", "for", "Computational", "Linguistics", ")", "Lifetime", "Achievement", "Award", "ausgezeichnet", "."], "sentence-detokenized": "Im Jahr 2016 wurde sie mit dem ACL (Association for Computational Linguistics) Lifetime Achievement Award ausgezeichnet.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 18], [19, 22], [23, 26], [27, 30], [31, 34], [35, 36], [36, 47], [48, 51], [52, 65], [66, 77], [77, 78], [79, 87], [88, 99], [100, 105], [106, 119], [119, 120]]}
{"doc_key": "ai-dev-205", "ner": [[0, 1, "researcher"], [3, 4, "researcher"], [6, 7, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sepp", "Hochreiter", ",", "Y.", "Bengio", ",", "P.", "Frasconi", ",", "und", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Sepp Hochreiter, Y. Bengio, P. Frasconi, und J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 15], [15, 16], [17, 19], [20, 26], [26, 27], [28, 30], [31, 39], [39, 40], [41, 44], [45, 51], [52, 63], [63, 64]]}
{"doc_key": "ai-dev-206", "ner": [[0, 0, "product"], [5, 5, "misc"], [7, 9, "programlang"], [15, 18, "product"], [27, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 7, 9, "usage", "", false, false], [7, 9, 5, 5, "type-of", "", false, false], [7, 9, 15, 18, "related-to", "", false, false], [27, 27, 0, 0, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A.L.I.C.E.", "zum", "Beispiel", "verwendet", "eine", "Auszeichnungssprache", "namens", "AIML", ",", "die", "speziell", "f\u00fcr", "seine", "Funktion", "als", "Dialogsystem", "entwickelt", "wurde", "und", "inzwischen", "von", "verschiedenen", "anderen", "Entwicklern", "von", "so", "genannten", "Alicebots", "\u00fcbernommen", "wurde", "."], "sentence-detokenized": "A.L.I.C.E. zum Beispiel verwendet eine Auszeichnungssprache namens AIML, die speziell f\u00fcr seine Funktion als Dialogsystem entwickelt wurde und inzwischen von verschiedenen anderen Entwicklern von so genannten Alicebots \u00fcbernommen wurde.", "token2charspan": [[0, 10], [11, 14], [15, 23], [24, 33], [34, 38], [39, 59], [60, 66], [67, 71], [71, 72], [73, 76], [77, 85], [86, 89], [90, 95], [96, 104], [105, 108], [109, 121], [122, 132], [133, 138], [139, 142], [143, 153], [154, 157], [158, 171], [172, 179], [180, 191], [192, 195], [196, 198], [199, 208], [209, 218], [219, 229], [230, 235], [235, 236]]}
{"doc_key": "ai-dev-207", "ner": [[8, 14, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Im", "Jahr", "2000", "wurde", "sie", "zum", "Fellow", "der", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "gew\u00e4hlt", "."], "sentence-detokenized": "Im Jahr 2000 wurde sie zum Fellow der Association for the Advancement of Artificial Intelligence gew\u00e4hlt.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 18], [19, 22], [23, 26], [27, 33], [34, 37], [38, 49], [50, 53], [54, 57], [58, 69], [70, 72], [73, 83], [84, 96], [97, 104], [104, 105]]}
{"doc_key": "ai-dev-208", "ner": [[0, 1, "misc"], [3, 3, "misc"], [9, 11, "misc"], [19, 20, "algorithm"], [29, 30, "field"], [32, 32, "field"], [34, 35, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 9, 11, "type-of", "", false, false], [0, 1, 29, 30, "related-to", "performs", true, false], [0, 1, 32, 32, "related-to", "performs", true, false], [0, 1, 34, 35, "related-to", "performs", true, false], [3, 3, 0, 1, "named", "", false, false], [19, 20, 9, 11, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Lernende", "Klassifizierungssysteme", "(", "LCS", ")", "sind", "eine", "Familie", "von", "regelbasierten", "maschinellen", "Lernalgorithmen", ",", "die", "eine", "Entdeckungskomponente", ",", "typischerweise", "einen", "genetischen", "Algorithmus", ",", "mit", "einer", "Lernkomponente", "kombinieren", ",", "die", "entweder", "\u00fcberwachtes", "Lernen", ",", "Verst\u00e4rkungslernen", "oder", "unbeaufsichtigtes", "Lernen", "durchf\u00fchrt", "."], "sentence-detokenized": "Lernende Klassifizierungssysteme (LCS) sind eine Familie von regelbasierten maschinellen Lernalgorithmen, die eine Entdeckungskomponente, typischerweise einen genetischen Algorithmus, mit einer Lernkomponente kombinieren, die entweder \u00fcberwachtes Lernen, Verst\u00e4rkungslernen oder unbeaufsichtigtes Lernen durchf\u00fchrt.", "token2charspan": [[0, 8], [9, 32], [33, 34], [34, 37], [37, 38], [39, 43], [44, 48], [49, 56], [57, 60], [61, 75], [76, 88], [89, 104], [104, 105], [106, 109], [110, 114], [115, 136], [136, 137], [138, 152], [153, 158], [159, 170], [171, 182], [182, 183], [184, 187], [188, 193], [194, 208], [209, 220], [220, 221], [222, 225], [226, 234], [235, 246], [247, 253], [253, 254], [255, 273], [274, 278], [279, 296], [297, 303], [304, 314], [314, 315]]}
{"doc_key": "ai-dev-209", "ner": [[19, 19, "algorithm"], [27, 27, "algorithm"], [31, 31, "misc"], [46, 47, "algorithm"], [51, 57, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[46, 47, 31, 31, "type-of", "", false, false], [46, 47, 51, 57, "compare", "", false, false]], "relations_mapping_to_source": [3, 4], "sentence": ["Die", "unbekannten", "Parameter", "in", "den", "einzelnen", "Vektoren", "\u03b2subk", "/", "sub", "werden", "in", "der", "Regel", "gemeinsam", "durch", "eine", "Maximum-a-posteriori-Sch\u00e4tzung", "(", "MAP", ")", "gesch\u00e4tzt", ",", "die", "eine", "Erweiterung", "der", "Maximum-Likelihood-Sch\u00e4tzung", "ist", "und", "eine", "Regularisierung", "der", "Gewichte", "verwendet", ",", "um", "pathologische", "L\u00f6sungen", "zu", "verhindern", "(", "in", "der", "Regel", "eine", "quadratische", "Regularisierungsfunktion", ",", "die", "einer", "Gau\u00df'schen", "Priorit\u00e4tsverteilung", "mit", "dem", "Mittelwert", "Null", "auf", "die", "Gewichte", "entspricht", ",", "aber", "auch", "andere", "Verteilungen", "sind", "m\u00f6glich", ")", "."], "sentence-detokenized": "Die unbekannten Parameter in den einzelnen Vektoren \u03b2subk / sub werden in der Regel gemeinsam durch eine Maximum-a-posteriori-Sch\u00e4tzung (MAP) gesch\u00e4tzt, die eine Erweiterung der Maximum-Likelihood-Sch\u00e4tzung ist und eine Regularisierung der Gewichte verwendet, um pathologische L\u00f6sungen zu verhindern (in der Regel eine quadratische Regularisierungsfunktion, die einer Gau\u00df'schen Priorit\u00e4tsverteilung mit dem Mittelwert Null auf die Gewichte entspricht, aber auch andere Verteilungen sind m\u00f6glich).", "token2charspan": [[0, 3], [4, 15], [16, 25], [26, 28], [29, 32], [33, 42], [43, 51], [52, 57], [58, 59], [60, 63], [64, 70], [71, 73], [74, 77], [78, 83], [84, 93], [94, 99], [100, 104], [105, 135], [136, 137], [137, 140], [140, 141], [142, 151], [151, 152], [153, 156], [157, 161], [162, 173], [174, 177], [178, 206], [207, 210], [211, 214], [215, 219], [220, 235], [236, 239], [240, 248], [249, 258], [258, 259], [260, 262], [263, 276], [277, 285], [286, 288], [289, 299], [300, 301], [301, 303], [304, 307], [308, 313], [314, 318], [319, 331], [332, 356], [356, 357], [358, 361], [362, 367], [368, 378], [379, 399], [400, 403], [404, 407], [408, 418], [419, 423], [424, 427], [428, 431], [432, 440], [441, 451], [451, 452], [453, 457], [458, 462], [463, 469], [470, 482], [483, 487], [488, 495], [495, 496], [496, 497]]}
{"doc_key": "ai-dev-210", "ner": [[7, 8, "researcher"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 9, 7, 8, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Die", "hierarchische", "Struktur", "von", "W\u00f6rtern", "ist", "in", "George", "Millers", "Wordnet", "explizit", "abgebildet", "worden", "."], "sentence-detokenized": "Die hierarchische Struktur von W\u00f6rtern ist in George Millers Wordnet explizit abgebildet worden.", "token2charspan": [[0, 3], [4, 17], [18, 26], [27, 30], [31, 38], [39, 42], [43, 45], [46, 52], [53, 60], [61, 68], [69, 77], [78, 88], [89, 95], [95, 96]]}
{"doc_key": "ai-dev-211", "ner": [[7, 12, "conference"], [18, 23, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 23, 7, 12, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Ein", "Beispiel", "f\u00fcr", "ihre", "F\u00e4higkeiten", "ist", "die", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", ",", "ein", "Benchmark", "f\u00fcr", "die", "Klassifizierung", "und", "Erkennung", "von", "Objekten", "mit", "Millionen", "von", "Bildern", "und", "Hunderten", "von", "Objektklassen", "."], "sentence-detokenized": "Ein Beispiel f\u00fcr ihre F\u00e4higkeiten ist die ImageNet Large Scale Visual Recognition Challenge, ein Benchmark f\u00fcr die Klassifizierung und Erkennung von Objekten mit Millionen von Bildern und Hunderten von Objektklassen.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 21], [22, 33], [34, 37], [38, 41], [42, 50], [51, 56], [57, 62], [63, 69], [70, 81], [82, 91], [91, 92], [93, 96], [97, 106], [107, 110], [111, 114], [115, 130], [131, 134], [135, 144], [145, 148], [149, 157], [158, 161], [162, 171], [172, 175], [176, 183], [184, 187], [188, 197], [198, 201], [202, 215], [215, 216]]}
{"doc_key": "ai-dev-212", "ner": [[2, 2, "misc"], [17, 17, "misc"], [20, 21, "person"], [24, 24, "misc"], [30, 32, "person"], [34, 35, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[17, 17, 2, 2, "general-affiliation", "", false, false], [24, 24, 2, 2, "general-affiliation", "", false, false], [24, 24, 20, 21, "artifact", "", false, false], [34, 35, 2, 2, "general-affiliation", "", false, false], [34, 35, 30, 32, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "der", "Science-Fiction", "werden", "weiblich", "aussehende", "Roboter", "oft", "als", "Hausangestellte", "und", "Sexsklaven", "produziert", ",", "wie", "im", "Film", "Westworld", ",", "in", "Paul", "J.", "McAuleys", "Roman", "Fairyland", "(", "1995", ")", "und", "in", "Lester", "del", "Reys", "Kurzgeschichte", "Helen", "O'Loy", "(", "1938", ")", ",", "und", "manchmal", "auch", "als", "Krieger", ",", "Killer", "oder", "Arbeiter", "."], "sentence-detokenized": "In der Science-Fiction werden weiblich aussehende Roboter oft als Hausangestellte und Sexsklaven produziert, wie im Film Westworld, in Paul J. McAuleys Roman Fairyland (1995) und in Lester del Reys Kurzgeschichte Helen O'Loy (1938), und manchmal auch als Krieger, Killer oder Arbeiter.", "token2charspan": [[0, 2], [3, 6], [7, 22], [23, 29], [30, 38], [39, 49], [50, 57], [58, 61], [62, 65], [66, 81], [82, 85], [86, 96], [97, 107], [107, 108], [109, 112], [113, 115], [116, 120], [121, 130], [130, 131], [132, 134], [135, 139], [140, 142], [143, 151], [152, 157], [158, 167], [168, 169], [169, 173], [173, 174], [175, 178], [179, 181], [182, 188], [189, 192], [193, 197], [198, 212], [213, 218], [219, 224], [225, 226], [226, 230], [230, 231], [231, 232], [233, 236], [237, 245], [246, 250], [251, 254], [255, 262], [262, 263], [264, 270], [271, 275], [276, 284], [284, 285]]}
{"doc_key": "ai-dev-213", "ner": [[0, 2, "task"], [4, 4, "task"], [6, 7, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Beantwortung", "von", "Fragen", ",", "Spracherkennung", "und", "maschinelle", "\u00dcbersetzung", "."], "sentence-detokenized": "Beantwortung von Fragen, Spracherkennung und maschinelle \u00dcbersetzung.", "token2charspan": [[0, 12], [13, 16], [17, 23], [23, 24], [25, 40], [41, 44], [45, 56], [57, 68], [68, 69]]}
{"doc_key": "ai-dev-214", "ner": [[5, 6, "researcher"], [9, 13, "organisation"], [16, 19, "location"], [21, 21, "location"], [23, 23, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 9, 13, "role", "", false, false], [9, 13, 16, 19, "physical", "", false, false], [16, 19, 21, 21, "physical", "", false, false], [21, 21, 23, 23, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "seiner", "bahnbrechenden", "Arbeit", "definierte", "Harry", "Blum", "von", "den", "Air", "Force", "Cambridge", "Research", "Laboratories", "auf", "der", "Hanscom", "Air", "Force", "Base", "in", "Bedford", ",", "Massachusetts", ",", "eine", "Mittelachse", "zur", "Berechnung", "des", "Skeletts", "einer", "Form", ",", "wobei", "er", "ein", "intuitives", "Modell", "der", "Brandausbreitung", "auf", "einem", "Grasfeld", "verwendete", ",", "das", "die", "Form", "der", "gegebenen", "Form", "hat", "."], "sentence-detokenized": "In seiner bahnbrechenden Arbeit definierte Harry Blum von den Air Force Cambridge Research Laboratories auf der Hanscom Air Force Base in Bedford, Massachusetts, eine Mittelachse zur Berechnung des Skeletts einer Form, wobei er ein intuitives Modell der Brandausbreitung auf einem Grasfeld verwendete, das die Form der gegebenen Form hat.", "token2charspan": [[0, 2], [3, 9], [10, 24], [25, 31], [32, 42], [43, 48], [49, 53], [54, 57], [58, 61], [62, 65], [66, 71], [72, 81], [82, 90], [91, 103], [104, 107], [108, 111], [112, 119], [120, 123], [124, 129], [130, 134], [135, 137], [138, 145], [145, 146], [147, 160], [160, 161], [162, 166], [167, 178], [179, 182], [183, 193], [194, 197], [198, 206], [207, 212], [213, 217], [217, 218], [219, 224], [225, 227], [228, 231], [232, 242], [243, 249], [250, 253], [254, 270], [271, 274], [275, 280], [281, 289], [290, 300], [300, 301], [302, 305], [306, 309], [310, 314], [315, 318], [319, 328], [329, 333], [334, 337], [337, 338]]}
{"doc_key": "ai-dev-215", "ner": [[14, 14, "algorithm"], [16, 16, "algorithm"], [20, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 20, 20, "compare", "", false, false], [16, 16, 20, 20, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Im", "Gegensatz", "zu", "Boosting-Algorithmen", ",", "die", "analytisch", "eine", "konvexe", "Verlustfunktion", "minimieren", "(", "z.", "B.", "AdaBoost", "und", "LogitBoost", ")", ",", "l\u00f6st", "BrownBoost", "ein", "System", "aus", "zwei", "Gleichungen", "und", "zwei", "Unbekannten", "mit", "Hilfe", "von", "numerischen", "Standardmethoden", "."], "sentence-detokenized": "Im Gegensatz zu Boosting-Algorithmen, die analytisch eine konvexe Verlustfunktion minimieren (z.B. AdaBoost und LogitBoost), l\u00f6st BrownBoost ein System aus zwei Gleichungen und zwei Unbekannten mit Hilfe von numerischen Standardmethoden.", "token2charspan": [[0, 2], [3, 12], [13, 15], [16, 36], [36, 37], [38, 41], [42, 52], [53, 57], [58, 65], [66, 81], [82, 92], [93, 94], [94, 96], [96, 98], [99, 107], [108, 111], [112, 122], [122, 123], [123, 124], [125, 129], [130, 140], [141, 144], [145, 151], [152, 155], [156, 160], [161, 172], [173, 176], [177, 181], [182, 193], [194, 197], [198, 203], [204, 207], [208, 219], [220, 236], [236, 237]]}
{"doc_key": "ai-dev-216", "ner": [[0, 0, "researcher"], [14, 16, "misc"], [22, 28, "conference"], [30, 30, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 14, 16, "win-defeat", "", false, false], [0, 0, 22, 28, "role", "", false, false], [30, 30, 22, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Getoor", "wurde", "mehrfach", "mit", "dem", "Preis", "f\u00fcr", "die", "beste", "Arbeit", "ausgezeichnet", ",", "erhielt", "einen", "NSF", "Career", "Award", "und", "ist", "ein", "Fellow", "der", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Getoor wurde mehrfach mit dem Preis f\u00fcr die beste Arbeit ausgezeichnet, erhielt einen NSF Career Award und ist ein Fellow der Association for the Advancement of Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 12], [13, 21], [22, 25], [26, 29], [30, 35], [36, 39], [40, 43], [44, 49], [50, 56], [57, 70], [70, 71], [72, 79], [80, 85], [86, 89], [90, 96], [97, 102], [103, 106], [107, 110], [111, 114], [115, 121], [122, 125], [126, 137], [138, 141], [142, 145], [146, 157], [158, 160], [161, 171], [172, 184], [185, 186], [186, 190], [190, 191], [191, 192]]}
{"doc_key": "ai-dev-217", "ner": [[0, 1, "misc"], [6, 10, "misc"], [15, 16, "misc"], [21, 25, "misc"], [30, 31, "misc"], [32, 36, "university"], [41, 49, "misc"], [54, 62, "misc"], [67, 71, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["ACM", "Fellow", "(", "2015", ")", "br", "Association", "for", "Computational", "Linguistics", "Fellow", "(", "2011", ")", "br", "AAAI", "Fellow", "(", "1994", ")", "br", "International", "Speech", "Communication", "Association", "Fellow", "(", "2011", ")", "br", "Ehrendoktor", "der", "KTH", "Royal", "Institute", "of", "Technology", "(", "2007", ")", "br", "Columbia", "Engineering", "School", "Alumni", "Association", "Distinguished", "Faculty", "Teaching", "Award", "(", "2009", ")", "br", "IEEE", "James", "L.", "Flanagan", "Speech", "and", "Audio", "Processing", "Award", "(", "2011", ")", "br", "ISCA", "Medal", "for", "Scientific", "Achievement", "(", "2011", ")"], "sentence-detokenized": "ACM Fellow (2015) br Association for Computational Linguistics Fellow (2011) br AAAI Fellow (1994) br International Speech Communication Association Fellow (2011) br Ehrendoktor der KTH Royal Institute of Technology (2007) br Columbia Engineering School Alumni Association Distinguished Faculty Teaching Award (2009) br IEEE James L. Flanagan Speech and Audio Processing Award (2011) br ISCA Medal for Scientific Achievement (2011)", "token2charspan": [[0, 3], [4, 10], [11, 12], [12, 16], [16, 17], [18, 20], [21, 32], [33, 36], [37, 50], [51, 62], [63, 69], [70, 71], [71, 75], [75, 76], [77, 79], [80, 84], [85, 91], [92, 93], [93, 97], [97, 98], [99, 101], [102, 115], [116, 122], [123, 136], [137, 148], [149, 155], [156, 157], [157, 161], [161, 162], [163, 165], [166, 177], [178, 181], [182, 185], [186, 191], [192, 201], [202, 204], [205, 215], [216, 217], [217, 221], [221, 222], [223, 225], [226, 234], [235, 246], [247, 253], [254, 260], [261, 272], [273, 286], [287, 294], [295, 303], [304, 309], [310, 311], [311, 315], [315, 316], [317, 319], [320, 324], [325, 330], [331, 333], [334, 342], [343, 349], [350, 353], [354, 359], [360, 370], [371, 376], [377, 378], [378, 382], [382, 383], [384, 386], [387, 391], [392, 397], [398, 401], [402, 412], [413, 424], [425, 426], [426, 430], [430, 431]]}
{"doc_key": "ai-dev-218", "ner": [[4, 4, "university"], [11, 14, "task"], [38, 41, "metrics"], [27, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[38, 41, 27, 29, "opposite", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Ein", "frustrierendes", "Ergebnis", "dieser", "Stanford-Studie", "(", "und", "anderer", "Versuche", ",", "die", "\u00dcbersetzung", "von", "Benennungen", "zu", "verbessern", ")", "ist", ",", "dass", "die", "Einbeziehung", "von", "Methoden", "zur", "\u00dcbersetzung", "von", "benannten", "Entit\u00e4ten", "in", "vielen", "F\u00e4llen", "zu", "einer", "Verschlechterung", "der", "Ergebnisse", "der", "zweisprachigen", "Evaluierung", "f\u00fcr", "die", "\u00dcbersetzung", "f\u00fchrt", "."], "sentence-detokenized": "Ein frustrierendes Ergebnis dieser Stanford-Studie (und anderer Versuche, die \u00dcbersetzung von Benennungen zu verbessern) ist, dass die Einbeziehung von Methoden zur \u00dcbersetzung von benannten Entit\u00e4ten in vielen F\u00e4llen zu einer Verschlechterung der Ergebnisse der zweisprachigen Evaluierung f\u00fcr die \u00dcbersetzung f\u00fchrt.", "token2charspan": [[0, 3], [4, 18], [19, 27], [28, 34], [35, 50], [51, 52], [52, 55], [56, 63], [64, 72], [72, 73], [74, 77], [78, 89], [90, 93], [94, 105], [106, 108], [109, 119], [119, 120], [121, 124], [124, 125], [126, 130], [131, 134], [135, 147], [148, 151], [152, 160], [161, 164], [165, 176], [177, 180], [181, 190], [191, 200], [201, 203], [204, 210], [211, 217], [218, 220], [221, 226], [227, 243], [244, 247], [248, 258], [259, 262], [263, 277], [278, 289], [290, 293], [294, 297], [298, 309], [310, 315], [315, 316]]}
{"doc_key": "ai-dev-219", "ner": [[0, 0, "organisation"], [10, 12, "organisation"], [15, 20, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 10, 12, "role", "works_with", false, false], [0, 0, 15, 20, "role", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Medtronic", "nutzt", "die", "gesammelten", "PM-Daten", "und", "arbeitet", "mit", "Forschern", "des", "Johns", "Hopkins", "Hospitals", "und", "der", "Washington", "University", "School", "of", "Medicine", "zusammen", ",", "um", "spezifische", "Fragen", "zu", "Herzkrankheiten", "zu", "beantworten", ",", "z.", "B.", "ob", "schwache", "Herzen", "Herzrhythmusst\u00f6rungen", "verursachen", "oder", "umgekehrt", "."], "sentence-detokenized": "Medtronic nutzt die gesammelten PM-Daten und arbeitet mit Forschern des Johns Hopkins Hospitals und der Washington University School of Medicine zusammen, um spezifische Fragen zu Herzkrankheiten zu beantworten, z. B. ob schwache Herzen Herzrhythmusst\u00f6rungen verursachen oder umgekehrt.", "token2charspan": [[0, 9], [10, 15], [16, 19], [20, 31], [32, 40], [41, 44], [45, 53], [54, 57], [58, 67], [68, 71], [72, 77], [78, 85], [86, 95], [96, 99], [100, 103], [104, 114], [115, 125], [126, 132], [133, 135], [136, 144], [145, 153], [153, 154], [155, 157], [158, 169], [170, 176], [177, 179], [180, 195], [196, 198], [199, 210], [210, 211], [212, 214], [215, 217], [218, 220], [221, 229], [230, 236], [237, 258], [259, 270], [271, 275], [276, 285], [285, 286]]}
{"doc_key": "ai-dev-220", "ner": [[6, 6, "organisation"], [8, 8, "misc"], [10, 11, "person"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 6, 6, "artifact", "made_by_studio", false, false], [10, 11, 8, 8, "role", "", false, false], [13, 14, 8, 8, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Es", "folgte", "der", "erste", "Spielfilm", "von", "Paramount", ",", "Sangaree", "mit", "Fernando", "Lamas", "und", "Arlene", "Dahl", "."], "sentence-detokenized": "Es folgte der erste Spielfilm von Paramount, Sangaree mit Fernando Lamas und Arlene Dahl.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 19], [20, 29], [30, 33], [34, 43], [43, 44], [45, 53], [54, 57], [58, 66], [67, 72], [73, 76], [77, 83], [84, 88], [88, 89]]}
{"doc_key": "ai-dev-221", "ner": [[0, 0, "programlang"], [7, 9, "researcher"], [11, 12, "researcher"], [17, 18, "organisation"], [21, 23, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 7, 9, "origin", "", false, false], [0, 0, 11, 12, "origin", "", false, false], [7, 9, 17, 18, "physical", "", false, false], [7, 9, 17, 18, "role", "", false, false], [11, 12, 21, 23, "physical", "", false, false], [11, 12, 21, 23, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["KRL", "ist", "eine", "Wissensrepr\u00e4sentationssprache", ",", "die", "von", "Daniel", "G.", "Bobrow", "und", "Terry", "Winograd", "w\u00e4hrend", "ihrer", "Zeit", "bei", "Xerox", "PARC", "bzw.", "an", "der", "Stanford", "University", "entwickelt", "wurde", "."], "sentence-detokenized": "KRL ist eine Wissensrepr\u00e4sentationssprache, die von Daniel G. Bobrow und Terry Winograd w\u00e4hrend ihrer Zeit bei Xerox PARC bzw. an der Stanford University entwickelt wurde.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 42], [42, 43], [44, 47], [48, 51], [52, 58], [59, 61], [62, 68], [69, 72], [73, 78], [79, 87], [88, 95], [96, 101], [102, 106], [107, 110], [111, 116], [117, 121], [122, 126], [127, 129], [130, 133], [134, 142], [143, 153], [154, 164], [165, 170], [170, 171]]}
{"doc_key": "ai-dev-222", "ner": [[2, 10, "conference"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"], [29, 31, "task"], [34, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 10, 29, 31, "topic", "", true, false], [12, 13, 2, 10, "physical", "", false, false], [12, 13, 2, 10, "role", "", false, false], [12, 13, 2, 10, "temporal", "", false, false], [15, 16, 2, 10, "physical", "", false, false], [15, 16, 2, 10, "role", "", false, false], [15, 16, 2, 10, "temporal", "", false, false], [18, 19, 2, 10, "physical", "", false, false], [18, 19, 2, 10, "role", "", false, false], [18, 19, 2, 10, "temporal", "", false, false], [21, 22, 2, 10, "physical", "", false, false], [21, 22, 2, 10, "role", "", false, false], [21, 22, 2, 10, "temporal", "", false, false], [29, 31, 34, 34, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Auf", "der", "IEEE", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "2006", "stellten", "Qiang", "Zhu", ",", "Shai", "Avidan", ",", "Mei-Chen", "Yeh", "und", "Kwang-Ting", "Cheng", "einen", "Algorithmus", "vor", ",", "der", "die", "Erkennung", "von", "Menschen", "mithilfe", "von", "HOG-Deskriptoren", "erheblich", "beschleunigt", "."], "sentence-detokenized": "Auf der IEEE Conference on Computer Vision and Pattern Recognition 2006 stellten Qiang Zhu, Shai Avidan, Mei-Chen Yeh und Kwang-Ting Cheng einen Algorithmus vor, der die Erkennung von Menschen mithilfe von HOG-Deskriptoren erheblich beschleunigt.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 23], [24, 26], [27, 35], [36, 42], [43, 46], [47, 54], [55, 66], [67, 71], [72, 80], [81, 86], [87, 90], [90, 91], [92, 96], [97, 103], [103, 104], [105, 113], [114, 117], [118, 121], [122, 132], [133, 138], [139, 144], [145, 156], [157, 160], [160, 161], [162, 165], [166, 169], [170, 179], [180, 183], [184, 192], [193, 201], [202, 205], [206, 222], [223, 232], [233, 245], [245, 246]]}
{"doc_key": "ai-dev-223", "ner": [[0, 0, "researcher"], [6, 6, "conference"], [9, 11, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 6, 6, "role", "", false, false], [0, 0, 9, 11, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hayes", "ist", "ein", "Charter", "Fellow", "der", "AAAI", "und", "der", "Cognitive", "Science", "Society"], "sentence-detokenized": "Hayes ist ein Charter Fellow der AAAI und der Cognitive Science Society", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 21], [22, 28], [29, 32], [33, 37], [38, 41], [42, 45], [46, 55], [56, 63], [64, 71]]}
{"doc_key": "ai-dev-224", "ner": [[0, 0, "misc"], [4, 4, "field"], [7, 7, "field"], [10, 10, "field"], [13, 13, "field"], [16, 16, "field"], [19, 19, "field"], [22, 22, "field"], [25, 25, "field"], [28, 28, "field"], [31, 31, "field"], [34, 34, "field"], [41, 42, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[0, 0, 4, 4, "part-of", "", false, false], [0, 0, 4, 4, "usage", "", false, false], [0, 0, 7, 7, "part-of", "", false, false], [0, 0, 7, 7, "usage", "", false, false], [0, 0, 10, 10, "part-of", "", false, false], [0, 0, 10, 10, "usage", "", false, false], [0, 0, 13, 13, "part-of", "", false, false], [0, 0, 13, 13, "usage", "", false, false], [0, 0, 16, 16, "part-of", "", false, false], [0, 0, 16, 16, "usage", "", false, false], [0, 0, 19, 19, "part-of", "", false, false], [0, 0, 19, 19, "usage", "", false, false], [0, 0, 22, 22, "part-of", "", false, false], [0, 0, 22, 22, "usage", "", false, false], [0, 0, 25, 25, "part-of", "", false, false], [0, 0, 25, 25, "usage", "", false, false], [0, 0, 28, 28, "part-of", "", false, false], [0, 0, 28, 28, "usage", "", false, false], [0, 0, 31, 31, "part-of", "", false, false], [0, 0, 31, 31, "usage", "", false, false], [0, 0, 34, 34, "part-of", "", false, false], [0, 0, 34, 34, "usage", "", false, false], [0, 0, 41, 42, "part-of", "", false, false], [0, 0, 41, 42, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "sentence": ["Zeitreihen", "werden", "in", "der", "Statistik", ",", "der", "Signalverarbeitung", ",", "der", "Mustererkennung", ",", "der", "\u00d6konometrie", ",", "der", "Finanzmathematik", ",", "der", "Wettervorhersage", ",", "der", "Erdbebenvorhersage", ",", "der", "Elektroenzephalographie", ",", "der", "Regelungstechnik", ",", "der", "Astronomie", ",", "der", "Nachrichtentechnik", "und", "weitgehend", "in", "allen", "Bereichen", "der", "angewandten", "Wissenschaft", "und", "Technik", "verwendet", ",", "die", "zeitliche", "Messungen", "beinhalten", "."], "sentence-detokenized": "Zeitreihen werden in der Statistik, der Signalverarbeitung, der Mustererkennung, der \u00d6konometrie, der Finanzmathematik, der Wettervorhersage, der Erdbebenvorhersage, der Elektroenzephalographie, der Regelungstechnik, der Astronomie, der Nachrichtentechnik und weitgehend in allen Bereichen der angewandten Wissenschaft und Technik verwendet, die zeitliche Messungen beinhalten.", "token2charspan": [[0, 10], [11, 17], [18, 20], [21, 24], [25, 34], [34, 35], [36, 39], [40, 58], [58, 59], [60, 63], [64, 79], [79, 80], [81, 84], [85, 96], [96, 97], [98, 101], [102, 118], [118, 119], [120, 123], [124, 140], [140, 141], [142, 145], [146, 164], [164, 165], [166, 169], [170, 193], [193, 194], [195, 198], [199, 215], [215, 216], [217, 220], [221, 231], [231, 232], [233, 236], [237, 255], [256, 259], [260, 270], [271, 273], [274, 279], [280, 289], [290, 293], [294, 305], [306, 318], [319, 322], [323, 330], [331, 340], [340, 341], [342, 345], [346, 355], [356, 365], [366, 376], [376, 377]]}
{"doc_key": "ai-dev-225", "ner": [[11, 12, "metrics"], [37, 37, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Im", "Prinzip", "kann", "die", "exakte", "Wiederherstellung", "in", "ihrem", "machbaren", "Bereich", "mit", "maximaler", "Wahrscheinlichkeit", "gel\u00f6st", "werden", ",", "aber", "dies", "l\u00e4uft", "auf", "die", "L\u00f6sung", "eines", "eingeschr\u00e4nkten", "oder", "regulierten", "Schnittproblems", "wie", "der", "minimalen", "Halbierung", "hinaus", ",", "das", "in", "der", "Regel", "NP-komplett", "ist", "."], "sentence-detokenized": "Im Prinzip kann die exakte Wiederherstellung in ihrem machbaren Bereich mit maximaler Wahrscheinlichkeit gel\u00f6st werden, aber dies l\u00e4uft auf die L\u00f6sung eines eingeschr\u00e4nkten oder regulierten Schnittproblems wie der minimalen Halbierung hinaus, das in der Regel NP-komplett ist.", "token2charspan": [[0, 2], [3, 10], [11, 15], [16, 19], [20, 26], [27, 44], [45, 47], [48, 53], [54, 63], [64, 71], [72, 75], [76, 85], [86, 104], [105, 111], [112, 118], [118, 119], [120, 124], [125, 129], [130, 135], [136, 139], [140, 143], [144, 150], [151, 156], [157, 172], [173, 177], [178, 189], [190, 205], [206, 209], [210, 213], [214, 223], [224, 234], [235, 241], [241, 242], [243, 246], [247, 249], [250, 253], [254, 259], [260, 271], [272, 275], [275, 276]]}
{"doc_key": "ai-dev-226", "ner": [[4, 4, "task"], [10, 11, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 11, 4, 4, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["in", "ihrer", "Arbeit", "zur", "Fu\u00dfg\u00e4ngererkennung", ",", "die", "erstmals", "auf", "dem", "BMVC", "2009", "beschrieben", "wurde", "."], "sentence-detokenized": "in ihrer Arbeit zur Fu\u00dfg\u00e4ngererkennung, die erstmals auf dem BMVC 2009 beschrieben wurde.", "token2charspan": [[0, 2], [3, 8], [9, 15], [16, 19], [20, 38], [38, 39], [40, 43], [44, 52], [53, 56], [57, 60], [61, 65], [66, 70], [71, 82], [83, 88], [88, 89]]}
{"doc_key": "ai-dev-227", "ner": [[7, 11, "conference"], [4, 4, "researcher"], [14, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 7, 11, "physical", "", false, false], [4, 4, 7, 11, "role", "", false, false], [4, 4, 14, 21, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Im", "Jahr", "2007", "wurde", "Terzopoulos", "auf", "der", "International", "Conference", "on", "Computer", "Vision", "mit", "dem", "ersten", "IEEE", "PAMI", "Computer", "Vision", "Distinguished", "Researcher", "Award", "f\u00fcr", "seine", "bahnbrechenden", "und", "nachhaltigen", "Forschungen", "zu", "deformierbaren", "Modellen", "und", "deren", "Anwendungen", "ausgezeichnet", "."], "sentence-detokenized": "Im Jahr 2007 wurde Terzopoulos auf der International Conference on Computer Vision mit dem ersten IEEE PAMI Computer Vision Distinguished Researcher Award f\u00fcr seine bahnbrechenden und nachhaltigen Forschungen zu deformierbaren Modellen und deren Anwendungen ausgezeichnet.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 18], [19, 30], [31, 34], [35, 38], [39, 52], [53, 63], [64, 66], [67, 75], [76, 82], [83, 86], [87, 90], [91, 97], [98, 102], [103, 107], [108, 116], [117, 123], [124, 137], [138, 148], [149, 154], [155, 158], [159, 164], [165, 179], [180, 183], [184, 196], [197, 208], [209, 211], [212, 226], [227, 235], [236, 239], [240, 245], [246, 257], [258, 271], [271, 272]]}
{"doc_key": "ai-dev-228", "ner": [[0, 2, "task"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Bei", "der", "Clusteranalyse", "werden", "die", "Datenpunkte", "den", "Clustern", "so", "zugeordnet", ",", "dass", "die", "Elemente", "desselben", "Clusters", "so", "\u00e4hnlich", "wie", "m\u00f6glich", "sind", ",", "w\u00e4hrend", "die", "Elemente", ",", "die", "zu", "verschiedenen", "Clustern", "geh\u00f6ren", ",", "so", "unterschiedlich", "wie", "m\u00f6glich", "sind", "."], "sentence-detokenized": "Bei der Clusteranalyse werden die Datenpunkte den Clustern so zugeordnet, dass die Elemente desselben Clusters so \u00e4hnlich wie m\u00f6glich sind, w\u00e4hrend die Elemente, die zu verschiedenen Clustern geh\u00f6ren, so unterschiedlich wie m\u00f6glich sind.", "token2charspan": [[0, 3], [4, 7], [8, 22], [23, 29], [30, 33], [34, 45], [46, 49], [50, 58], [59, 61], [62, 72], [72, 73], [74, 78], [79, 82], [83, 91], [92, 101], [102, 110], [111, 113], [114, 121], [122, 125], [126, 133], [134, 138], [138, 139], [140, 147], [148, 151], [152, 160], [160, 161], [162, 165], [166, 168], [169, 182], [183, 191], [192, 199], [199, 200], [201, 203], [204, 219], [220, 223], [224, 231], [232, 236], [236, 237]]}
{"doc_key": "ai-dev-229", "ner": [[9, 10, "field"], [14, 15, "field"], [17, 17, "task"], [19, 20, "field"], [23, 24, "field"], [26, 27, "field"], [29, 30, "field"], [32, 33, "task"], [35, 35, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[9, 10, 14, 15, "named", "", false, false], [9, 10, 19, 20, "named", "", false, false], [9, 10, 26, 27, "named", "", false, false], [17, 17, 14, 15, "part-of", "task_part_of_field", false, false], [23, 24, 19, 20, "part-of", "", false, false], [29, 30, 26, 27, "part-of", "", false, false], [32, 33, 29, 30, "part-of", "", false, false], [35, 35, 29, 30, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["(", "2005", ")", "k\u00f6nnen", "wir", "drei", "verschiedene", "Perspektiven", "von", "Text", "Mining", "unterscheiden", ",", "n\u00e4mlich", "Text", "Mining", "als", "Informationsextraktion", ",", "Text", "Mining", "als", "Text", "Data", "Mining", "und", "Text", "Mining", "als", "Data", "Mining", "(", "Knowledge", "Discovery", "in", "Databases", ")", "Prozess.Hotho", ",", "A.", ",", "N\u00fcrnberger", ",", "A.", "und", "Paa\u00df", ",", "G.", "(", "2005", ")", "."], "sentence-detokenized": "(2005) k\u00f6nnen wir drei verschiedene Perspektiven von Text Mining unterscheiden, n\u00e4mlich Text Mining als Informationsextraktion, Text Mining als Text Data Mining und Text Mining als Data Mining (Knowledge Discovery in Databases) Prozess.Hotho, A., N\u00fcrnberger, A. und Paa\u00df, G. (2005).", "token2charspan": [[0, 1], [1, 5], [5, 6], [7, 13], [14, 17], [18, 22], [23, 35], [36, 48], [49, 52], [53, 57], [58, 64], [65, 78], [78, 79], [80, 87], [88, 92], [93, 99], [100, 103], [104, 126], [126, 127], [128, 132], [133, 139], [140, 143], [144, 148], [149, 153], [154, 160], [161, 164], [165, 169], [170, 176], [177, 180], [181, 185], [186, 192], [193, 194], [194, 203], [204, 213], [214, 216], [217, 226], [226, 227], [228, 241], [241, 242], [243, 245], [245, 246], [247, 257], [257, 258], [259, 261], [262, 265], [266, 270], [270, 271], [272, 274], [275, 276], [276, 280], [280, 281], [281, 282]]}
{"doc_key": "ai-dev-230", "ner": [[1, 2, "product"], [12, 17, "location"], [19, 19, "location"], [21, 21, "location"], [33, 34, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 12, 17, "related-to", "developed_for", false, false], [12, 17, 19, 19, "physical", "", false, false], [19, 19, 21, 21, "physical", "", false, false], [33, 34, 1, 2, "role", "buys", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Der", "Rancho", "Arm", "wurde", "als", "Roboterarm", "entwickelt", ",", "um", "behinderten", "Patienten", "im", "Rancho", "Los", "Amigos", "National", "Rehabilitation", "Center", "in", "Downey", ",", "Kalifornien", ",", "zu", "helfen", ";", "dieser", "computergesteuerte", "Arm", "wurde", "1963", "von", "der", "Stanford", "University", "gekauft", "."], "sentence-detokenized": "Der Rancho Arm wurde als Roboterarm entwickelt, um behinderten Patienten im Rancho Los Amigos National Rehabilitation Center in Downey, Kalifornien, zu helfen; dieser computergesteuerte Arm wurde 1963 von der Stanford University gekauft.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 20], [21, 24], [25, 35], [36, 46], [46, 47], [48, 50], [51, 62], [63, 72], [73, 75], [76, 82], [83, 86], [87, 93], [94, 102], [103, 117], [118, 124], [125, 127], [128, 134], [134, 135], [136, 147], [147, 148], [149, 151], [152, 158], [158, 159], [160, 166], [167, 185], [186, 189], [190, 195], [196, 200], [201, 204], [205, 208], [209, 217], [218, 228], [229, 236], [236, 237]]}
{"doc_key": "ai-dev-231", "ner": [[2, 2, "university"], [4, 4, "researcher"], [7, 10, "organisation"], [16, 18, "organisation"], [22, 23, "researcher"], [25, 27, "researcher"], [41, 41, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 4, 2, 2, "physical", "", false, false], [4, 4, 2, 2, "role", "", false, false], [4, 4, 7, 10, "role", "founder", false, false], [4, 4, 16, 18, "role", "founder", false, false], [16, 18, 41, 41, "physical", "", false, false], [22, 23, 16, 18, "role", "founder", false, false], [25, 27, 16, 18, "role", "founder", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["An", "der", "UCSD", "war", "Norman", "Mitbegr\u00fcnder", "des", "Institute", "for", "Cognitive", "Science", "und", "einer", "der", "Organisatoren", "der", "Cognitive", "Science", "Society", "(", "zusammen", "mit", "Roger", "Schank", ",", "Allan", "M.", "Collins", "und", "anderen", ")", ",", "die", "1979", "ihr", "erstes", "Treffen", "auf", "dem", "Campus", "der", "UCSD", "abhielt", "."], "sentence-detokenized": "An der UCSD war Norman Mitbegr\u00fcnder des Institute for Cognitive Science und einer der Organisatoren der Cognitive Science Society (zusammen mit Roger Schank, Allan M. Collins und anderen), die 1979 ihr erstes Treffen auf dem Campus der UCSD abhielt.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 15], [16, 22], [23, 35], [36, 39], [40, 49], [50, 53], [54, 63], [64, 71], [72, 75], [76, 81], [82, 85], [86, 99], [100, 103], [104, 113], [114, 121], [122, 129], [130, 131], [131, 139], [140, 143], [144, 149], [150, 156], [156, 157], [158, 163], [164, 166], [167, 174], [175, 178], [179, 186], [186, 187], [187, 188], [189, 192], [193, 197], [198, 201], [202, 208], [209, 216], [217, 220], [221, 224], [225, 231], [232, 235], [236, 240], [241, 248], [248, 249]]}
{"doc_key": "ai-dev-232", "ner": [[6, 6, "product"], [8, 8, "product"], [10, 10, "product"], [12, 13, "product"], [15, 15, "product"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[15, 15, 12, 13, "type-of", "", false, false], [17, 17, 12, 13, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Die", "am", "h\u00e4ufigsten", "verwendeten", "Roboterkonfigurationen", "sind", "Knickarmroboter", ",", "SCARA-Roboter", ",", "Delta-Roboter", "und", "kartesische", "Koordinatenroboter", "(", "Portalroboter", "oder", "x-y-z-Roboter", ")", "."], "sentence-detokenized": "Die am h\u00e4ufigsten verwendeten Roboterkonfigurationen sind Knickarmroboter, SCARA-Roboter, Delta-Roboter und kartesische Koordinatenroboter (Portalroboter oder x-y-z-Roboter).", "token2charspan": [[0, 3], [4, 6], [7, 17], [18, 29], [30, 52], [53, 57], [58, 73], [73, 74], [75, 88], [88, 89], [90, 103], [104, 107], [108, 119], [120, 138], [139, 140], [140, 153], [154, 158], [159, 172], [172, 173], [173, 174]]}
{"doc_key": "ai-dev-233", "ner": [[7, 8, "misc"], [12, 12, "misc"]], "ner_mapping_to_source": [1, 2], "relations": [[12, 12, 7, 8, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [1], "sentence": ["Alternativ", "kann", "es", "auch", "direkt", "mit", "dem", "Perl-Modul", "TM", "(", "das", "auch", "LTM", "unterst\u00fctzt", ")", "verwendet", "werden", "."], "sentence-detokenized": "Alternativ kann es auch direkt mit dem Perl-Modul TM (das auch LTM unterst\u00fctzt) verwendet werden.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 23], [24, 30], [31, 34], [35, 38], [39, 49], [50, 52], [53, 54], [54, 57], [58, 62], [63, 66], [67, 78], [78, 79], [80, 89], [90, 96], [96, 97]]}
{"doc_key": "ai-dev-234", "ner": [[3, 3, "country"], [6, 7, "organisation"], [14, 14, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 3, 3, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Gewonnen", "hat", "ein", "amerikanisches", "Team", "von", "Newton", "Labs", ",", "und", "der", "Wettbewerb", "wurde", "auf", "CNN", "\u00fcbertragen", "."], "sentence-detokenized": "Gewonnen hat ein amerikanisches Team von Newton Labs, und der Wettbewerb wurde auf CNN \u00fcbertragen.", "token2charspan": [[0, 8], [9, 12], [13, 16], [17, 31], [32, 36], [37, 40], [41, 47], [48, 52], [52, 53], [54, 57], [58, 61], [62, 72], [73, 78], [79, 82], [83, 86], [87, 97], [97, 98]]}
{"doc_key": "ai-dev-235", "ner": [[0, 3, "misc"], [11, 12, "person"], [15, 16, "person"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 12, 0, 3, "role", "directs", false, false], [15, 16, 0, 3, "role", "acts_in", false, false], [18, 19, 0, 3, "role", "acts_in", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Butler's", "in", "Love", ",", "ein", "Kurzfilm", "unter", "der", "Regie", "von", "David", "Arquette", "und", "mit", "Elizabeth", "Berkley", "und", "Thomas", "Jane", "in", "den", "Hauptrollen", ",", "wurde", "am", "23.", "Juni", "2008", "ver\u00f6ffentlicht", "."], "sentence-detokenized": "The Butler's in Love, ein Kurzfilm unter der Regie von David Arquette und mit Elizabeth Berkley und Thomas Jane in den Hauptrollen, wurde am 23. Juni 2008 ver\u00f6ffentlicht.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 20], [20, 21], [22, 25], [26, 34], [35, 40], [41, 44], [45, 50], [51, 54], [55, 60], [61, 69], [70, 73], [74, 77], [78, 87], [88, 95], [96, 99], [100, 106], [107, 111], [112, 114], [115, 118], [119, 130], [130, 131], [132, 137], [138, 140], [141, 144], [145, 149], [150, 154], [155, 169], [169, 170]]}
{"doc_key": "ai-dev-236", "ner": [[0, 0, "product"], [8, 8, "field"], [14, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 14, 14, "general-affiliation", "", false, false], [8, 8, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["WordNet", "zum", "Beispiel", "ist", "eine", "Ressource", "mit", "einer", "Taxonomie", ",", "deren", "Elemente", "die", "Bedeutungen", "englischer", "W\u00f6rter", "sind", "."], "sentence-detokenized": "WordNet zum Beispiel ist eine Ressource mit einer Taxonomie, deren Elemente die Bedeutungen englischer W\u00f6rter sind.", "token2charspan": [[0, 7], [8, 11], [12, 20], [21, 24], [25, 29], [30, 39], [40, 43], [44, 49], [50, 59], [59, 60], [61, 66], [67, 75], [76, 79], [80, 91], [92, 102], [103, 109], [110, 114], [114, 115]]}
{"doc_key": "ai-dev-237", "ner": [[1, 2, "product"], [4, 4, "product"], [6, 6, "product"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 1, 2, "type-of", "", false, false], [4, 4, 12, 13, "related-to", "ability_to", false, false], [6, 6, 1, 2, "type-of", "", false, false], [6, 6, 12, 13, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Bestehende", "humanoide", "Robotersysteme", "wie", "ASIMO", "und", "QRIO", "verwenden", "viele", "Motoren", ",", "um", "sich", "fortzubewegen", "."], "sentence-detokenized": "Bestehende humanoide Robotersysteme wie ASIMO und QRIO verwenden viele Motoren, um sich fortzubewegen.", "token2charspan": [[0, 10], [11, 20], [21, 35], [36, 39], [40, 45], [46, 49], [50, 54], [55, 64], [65, 70], [71, 78], [78, 79], [80, 82], [83, 87], [88, 101], [101, 102]]}
{"doc_key": "ai-dev-238", "ner": [[0, 0, "metrics"], [6, 6, "metrics"], [8, 8, "metrics"], [10, 10, "misc"], [12, 12, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 0, 0, "part-of", "", false, false], [8, 8, 0, 0, "part-of", "", false, false], [10, 10, 0, 0, "part-of", "", false, false], [12, 12, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LEPOR", "wurde", "mit", "den", "Faktoren", "erweiterte", "L\u00e4ngenstrafe", ",", "Pr\u00e4zision", ",", "n-Gramm-Wortordnungsstrafe", "und", "Recall", "entwickelt", "."], "sentence-detokenized": "LEPOR wurde mit den Faktoren erweiterte L\u00e4ngenstrafe, Pr\u00e4zision, n-Gramm-Wortordnungsstrafe und Recall entwickelt.", "token2charspan": [[0, 5], [6, 11], [12, 15], [16, 19], [20, 28], [29, 39], [40, 52], [52, 53], [54, 63], [63, 64], [65, 91], [92, 95], [96, 102], [103, 113], [113, 114]]}
{"doc_key": "ai-dev-239", "ner": [[4, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sie", "basiert", "auf", "der", "Metrik", "f\u00fcr", "die", "Bewertung", "zweisprachiger", "Studierender", ",", "allerdings", "mit", "einigen", "\u00c4nderungen", "."], "sentence-detokenized": "Sie basiert auf der Metrik f\u00fcr die Bewertung zweisprachiger Studierender, allerdings mit einigen \u00c4nderungen.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 19], [20, 26], [27, 30], [31, 34], [35, 44], [45, 59], [60, 72], [72, 73], [74, 84], [85, 88], [89, 96], [97, 107], [107, 108]]}
{"doc_key": "ai-dev-240", "ner": [[5, 5, "product"], [7, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Dies", "ist", "eine", "Beispielimplementierung", "in", "MATLAB", "/", "Octave", ":"], "sentence-detokenized": "Dies ist eine Beispielimplementierung in MATLAB / Octave:", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 37], [38, 40], [41, 47], [48, 49], [50, 56], [56, 57]]}
{"doc_key": "ai-dev-241", "ner": [[17, 17, "programlang"], [19, 19, "programlang"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Es", "ist", "so", "konzipiert", ",", "dass", "es", "mit", "einer", "Reihe", "von", "Computersprachen", "verwendet", "werden", "kann", ",", "darunter", "Python", ",", "Ruby", "und", "Scheme", "."], "sentence-detokenized": "Es ist so konzipiert, dass es mit einer Reihe von Computersprachen verwendet werden kann, darunter Python, Ruby und Scheme.", "token2charspan": [[0, 2], [3, 6], [7, 9], [10, 20], [20, 21], [22, 26], [27, 29], [30, 33], [34, 39], [40, 45], [46, 49], [50, 66], [67, 76], [77, 83], [84, 88], [88, 89], [90, 98], [99, 105], [105, 106], [107, 111], [112, 115], [116, 122], [122, 123]]}
{"doc_key": "ai-dev-242", "ner": [[0, 0, "researcher"], [4, 4, "organisation"], [10, 10, "conference"], [14, 15, "academicjournal"], [19, 21, "organisation"], [25, 29, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 4, 4, "role", "", false, false], [0, 0, 10, 10, "role", "", false, false], [0, 0, 14, 15, "role", "", false, false], [0, 0, 19, 21, "role", "", false, false], [0, 0, 25, 29, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hayes", "war", "Sekret\u00e4r", "des", "AISB", ",", "Vorsitzender", "und", "Treuh\u00e4nder", "des", "IJCAI", ",", "Mitherausgeber", "von", "Artificial", "Intelligence", ",", "Gouverneur", "der", "Cognitive", "Science", "Society", "und", "Pr\u00e4sident", "der", "American", "Association", "for", "Artificial", "Intelligence", "."], "sentence-detokenized": "Hayes war Sekret\u00e4r des AISB, Vorsitzender und Treuh\u00e4nder des IJCAI, Mitherausgeber von Artificial Intelligence, Gouverneur der Cognitive Science Society und Pr\u00e4sident der American Association for Artificial Intelligence.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 22], [23, 27], [27, 28], [29, 41], [42, 45], [46, 56], [57, 60], [61, 66], [66, 67], [68, 82], [83, 86], [87, 97], [98, 110], [110, 111], [112, 122], [123, 126], [127, 136], [137, 144], [145, 152], [153, 156], [157, 166], [167, 170], [171, 179], [180, 191], [192, 195], [196, 206], [207, 219], [219, 220]]}
{"doc_key": "ai-dev-243", "ner": [[3, 13, "misc"], [15, 17, "misc"], [22, 23, "person"], [26, 31, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 23, 3, 13, "role", "directed_by", false, false], [22, 23, 15, 17, "role", "directed_by", false, false], [22, 23, 26, 31, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Zwei", "davon", ",", "Now", "is", "the", "Time", "(", "to", "Put", "On", "Your", "Glasses", ")", "und", "Around", "is", "Around", ",", "wurden", "1951", "von", "Norman", "McLaren", "f\u00fcr", "das", "National", "Film", "Board", "of", "Canada", "gedreht", "."], "sentence-detokenized": "Zwei davon, Now is the Time (to Put On Your Glasses) und Around is Around, wurden 1951 von Norman McLaren f\u00fcr das National Film Board of Canada gedreht.", "token2charspan": [[0, 4], [5, 10], [10, 11], [12, 15], [16, 18], [19, 22], [23, 27], [28, 29], [29, 31], [32, 35], [36, 38], [39, 43], [44, 51], [51, 52], [53, 56], [57, 63], [64, 66], [67, 73], [73, 74], [75, 81], [82, 86], [87, 90], [91, 97], [98, 105], [106, 109], [110, 113], [114, 122], [123, 127], [128, 133], [134, 136], [137, 143], [144, 151], [151, 152]]}
{"doc_key": "ai-dev-244", "ner": [[1, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ein", "Empfehlungssystem", "zielt", "darauf", "ab", ",", "die", "Vorliebe", "eines", "Zielbenutzers", "f\u00fcr", "einen", "Artikel", "vorherzusagen", "."], "sentence-detokenized": "Ein Empfehlungssystem zielt darauf ab, die Vorliebe eines Zielbenutzers f\u00fcr einen Artikel vorherzusagen.", "token2charspan": [[0, 3], [4, 21], [22, 27], [28, 34], [35, 37], [37, 38], [39, 42], [43, 51], [52, 57], [58, 71], [72, 75], [76, 81], [82, 89], [90, 103], [103, 104]]}
{"doc_key": "ai-dev-245", "ner": [[0, 3, "algorithm"], [8, 8, "field"], [10, 10, "field"], [12, 13, "field"], [15, 17, "field"], [21, 21, "field"], [23, 23, "field"], [25, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6, 7, 8], "relations": [[0, 3, 8, 8, "part-of", "", true, false], [0, 3, 10, 10, "part-of", "", true, false], [0, 3, 12, 13, "part-of", "", true, false], [0, 3, 15, 17, "part-of", "", true, false], [0, 3, 21, 21, "part-of", "", true, false], [0, 3, 23, 23, "part-of", "", true, false], [0, 3, 25, 25, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5, 6, 7], "sentence": ["Die", "Faltung", "wird", "unter", "anderem", "in", "den", "Bereichen", "Wahrscheinlichkeitsrechnung", ",", "Statistik", ",", "Computer", "Vision", ",", "Verarbeitung", "nat\u00fcrlicher", "Sprache", ",", "Bild-", "und", "Signalverarbeitung", ",", "Technik", "und", "Differentialgleichungen", "eingesetzt", "."], "sentence-detokenized": "Die Faltung wird unter anderem in den Bereichen Wahrscheinlichkeitsrechnung, Statistik, Computer Vision, Verarbeitung nat\u00fcrlicher Sprache, Bild- und Signalverarbeitung, Technik und Differentialgleichungen eingesetzt.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 22], [23, 30], [31, 33], [34, 37], [38, 47], [48, 75], [75, 76], [77, 86], [86, 87], [88, 96], [97, 103], [103, 104], [105, 117], [118, 129], [130, 137], [137, 138], [139, 144], [145, 148], [149, 167], [167, 168], [169, 176], [177, 180], [181, 204], [205, 215], [215, 216]]}
{"doc_key": "ai-dev-246", "ner": [[4, 4, "field"], [6, 6, "task"], [8, 8, "task"], [10, 10, "task"], [11, 11, "task"], [13, 13, "task"], [15, 15, "task"], [17, 17, "task"], [19, 19, "task"], [22, 23, "task"], [25, 25, "field"], [27, 27, "field"], [29, 29, "field"], [31, 31, "field"], [33, 33, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[4, 4, 6, 6, "part-of", "", true, false], [4, 4, 8, 8, "part-of", "", true, false], [4, 4, 10, 10, "part-of", "", true, false], [4, 4, 11, 11, "part-of", "", true, false], [4, 4, 13, 13, "part-of", "", true, false], [4, 4, 15, 15, "part-of", "", true, false], [4, 4, 17, 17, "part-of", "", true, false], [4, 4, 19, 19, "part-of", "", true, false], [4, 4, 22, 23, "part-of", "", true, false], [4, 4, 25, 25, "part-of", "", true, false], [4, 4, 27, 27, "part-of", "", true, false], [4, 4, 29, 29, "part-of", "", true, false], [4, 4, 31, 31, "part-of", "", true, false], [4, 4, 33, 33, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Zu", "den", "Anwendungen", "von", "DSP", "geh\u00f6ren", "Audiosignalverarbeitung", ",", "Audiokompression", ",", "digitale", "Bildverarbeitung", ",", "Videokompression", ",", "Sprachverarbeitung", ",", "Spracherkennung", ",", "digitale", "Kommunikation", ",", "digitale", "Synthesizer", ",", "Radar", ",", "Sonar", ",", "Finanzsignalverarbeitung", ",", "Seismologie", "und", "Biomedizin", "."], "sentence-detokenized": "Zu den Anwendungen von DSP geh\u00f6ren Audiosignalverarbeitung, Audiokompression, digitale Bildverarbeitung, Videokompression, Sprachverarbeitung, Spracherkennung, digitale Kommunikation, digitale Synthesizer, Radar, Sonar, Finanzsignalverarbeitung, Seismologie und Biomedizin.", "token2charspan": [[0, 2], [3, 6], [7, 18], [19, 22], [23, 26], [27, 34], [35, 58], [58, 59], [60, 76], [76, 77], [78, 86], [87, 103], [103, 104], [105, 121], [121, 122], [123, 141], [141, 142], [143, 158], [158, 159], [160, 168], [169, 182], [182, 183], [184, 192], [193, 204], [204, 205], [206, 211], [211, 212], [213, 218], [218, 219], [220, 244], [244, 245], [246, 257], [258, 261], [262, 272], [272, 273]]}
{"doc_key": "ai-dev-247", "ner": [[11, 12, "misc"], [21, 21, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["(", "20.", "Februar", "1912", "-", "11.", "August", "2011", ")", "war", "ein", "amerikanischer", "Erfinder", ",", "der", "vor", "allem", "f\u00fcr", "die", "Entwicklung", "von", "Unimate", ",", "dem", "ersten", "Industrieroboter", ",", "bekannt", "ist", "."], "sentence-detokenized": "(20. Februar 1912 - 11. August 2011) war ein amerikanischer Erfinder, der vor allem f\u00fcr die Entwicklung von Unimate, dem ersten Industrieroboter, bekannt ist.", "token2charspan": [[0, 1], [1, 4], [5, 12], [13, 17], [18, 19], [20, 23], [24, 30], [31, 35], [35, 36], [37, 40], [41, 44], [45, 59], [60, 68], [68, 69], [70, 73], [74, 77], [78, 83], [84, 87], [88, 91], [92, 103], [104, 107], [108, 115], [115, 116], [117, 120], [121, 127], [128, 144], [144, 145], [146, 153], [154, 157], [157, 158]]}
{"doc_key": "ai-dev-248", "ner": [[2, 4, "researcher"], [6, 8, "researcher"], [10, 10, "researcher"], [23, 23, "algorithm"], [27, 29, "algorithm"], [38, 38, "task"], [47, 47, "algorithm"], [44, 45, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[2, 4, 23, 23, "related-to", "writes_about", true, false], [6, 8, 23, 23, "related-to", "writes_about", true, false], [10, 10, 23, 23, "related-to", "writes_about", true, false], [23, 23, 27, 29, "related-to", "", true, false], [38, 38, 47, 47, "related-to", "", true, false], [44, 45, 47, 47, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Zusammen", "mit", "David", "E.", "Rumelhart", "und", "Ronald", "J.", "Williams", "war", "Hinton", "Mitautor", "einer", "viel", "zitierten", "Ver\u00f6ffentlichung", "aus", "dem", "Jahr", "1986", ",", "die", "den", "Backpropagation-Algorithmus", "f\u00fcr", "das", "Training", "mehrschichtiger", "neuronaler", "Netze", "popul\u00e4r", "machte", ".", "Der", "dramatische", "Meilenstein", "in", "der", "Bilderkennung", ",", "das", "von", "seinem", "Studenten", "Alex", "Krizhevsky", "entwickelte", "AlexNet", "{", "{", "cite", "web"], "sentence-detokenized": "Zusammen mit David E. Rumelhart und Ronald J. Williams war Hinton Mitautor einer viel zitierten Ver\u00f6ffentlichung aus dem Jahr 1986, die den Backpropagation-Algorithmus f\u00fcr das Training mehrschichtiger neuronaler Netze popul\u00e4r machte. Der dramatische Meilenstein in der Bilderkennung, das von seinem Studenten Alex Krizhevsky entwickelte AlexNet {{cite web", "token2charspan": [[0, 8], [9, 12], [13, 18], [19, 21], [22, 31], [32, 35], [36, 42], [43, 45], [46, 54], [55, 58], [59, 65], [66, 74], [75, 80], [81, 85], [86, 95], [96, 112], [113, 116], [117, 120], [121, 125], [126, 130], [130, 131], [132, 135], [136, 139], [140, 167], [168, 171], [172, 175], [176, 184], [185, 200], [201, 211], [212, 217], [218, 225], [226, 232], [232, 233], [234, 237], [238, 249], [250, 261], [262, 264], [265, 268], [269, 282], [282, 283], [284, 287], [288, 291], [292, 298], [299, 308], [309, 313], [314, 324], [325, 336], [337, 344], [345, 346], [346, 347], [347, 351], [352, 355]]}
{"doc_key": "ai-dev-249", "ner": [[10, 12, "metrics"], [15, 19, "metrics"], [22, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Wenn", "der", "vorhergesagte", "Wert", "kontinuierlich", "verteilt", "ist", ",", "k\u00f6nnen", "der", "mittlere", "quadratische", "Fehler", ",", "die", "Wurzel", "des", "mittleren", "quadratischen", "Fehlers", "oder", "der", "Median", "der", "absoluten", "Abweichung", "verwendet", "werden", ",", "um", "die", "Fehler", "zusammenzufassen", "."], "sentence-detokenized": "Wenn der vorhergesagte Wert kontinuierlich verteilt ist, k\u00f6nnen der mittlere quadratische Fehler, die Wurzel des mittleren quadratischen Fehlers oder der Median der absoluten Abweichung verwendet werden, um die Fehler zusammenzufassen.", "token2charspan": [[0, 4], [5, 8], [9, 22], [23, 27], [28, 42], [43, 51], [52, 55], [55, 56], [57, 63], [64, 67], [68, 76], [77, 89], [90, 96], [96, 97], [98, 101], [102, 108], [109, 112], [113, 122], [123, 136], [137, 144], [145, 149], [150, 153], [154, 160], [161, 164], [165, 174], [175, 185], [186, 195], [196, 202], [202, 203], [204, 206], [207, 210], [211, 217], [218, 234], [234, 235]]}
{"doc_key": "ai-dev-250", "ner": [[0, 1, "algorithm"], [12, 13, "field"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 12, 13, "part-of", "", true, false], [0, 1, 15, 16, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Konzeptuelles", "Clustering", "entwickelte", "sich", "haupts\u00e4chlich", "in", "den", "1980er", "Jahren", "als", "Paradigma", "des", "maschinellen", "Lernens", "f\u00fcr", "un\u00fcberwachtes", "Lernen", "."], "sentence-detokenized": "Konzeptuelles Clustering entwickelte sich haupts\u00e4chlich in den 1980er Jahren als Paradigma des maschinellen Lernens f\u00fcr un\u00fcberwachtes Lernen.", "token2charspan": [[0, 13], [14, 24], [25, 36], [37, 41], [42, 55], [56, 58], [59, 62], [63, 69], [70, 76], [77, 80], [81, 90], [91, 94], [95, 107], [108, 115], [116, 119], [120, 133], [134, 140], [140, 141]]}
{"doc_key": "ai-dev-251", "ner": [[4, 5, "product"], [29, 33, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Wenn", "benannte", "Entit\u00e4ten", "vom", "maschinellen", "\u00dcbersetzer", "nicht", "erkannt", "werden", "k\u00f6nnen", ",", "werden", "sie", "m\u00f6glicherweise", "f\u00e4lschlicherweise", "als", "gew\u00f6hnliche", "Substantive", "\u00fcbersetzt", ",", "was", "sich", "h\u00f6chstwahrscheinlich", "nicht", "auf", "die", "Bewertung", "der", "\u00dcbersetzung", "durch", "die", "zweisprachige", "Bewertungsgruppe", "auswirkt", ",", "aber", "die", "Lesbarkeit", "des", "Textes", "beeintr\u00e4chtigt", "."], "sentence-detokenized": "Wenn benannte Entit\u00e4ten vom maschinellen \u00dcbersetzer nicht erkannt werden k\u00f6nnen, werden sie m\u00f6glicherweise f\u00e4lschlicherweise als gew\u00f6hnliche Substantive \u00fcbersetzt, was sich h\u00f6chstwahrscheinlich nicht auf die Bewertung der \u00dcbersetzung durch die zweisprachige Bewertungsgruppe auswirkt, aber die Lesbarkeit des Textes beeintr\u00e4chtigt.", "token2charspan": [[0, 4], [5, 13], [14, 23], [24, 27], [28, 40], [41, 51], [52, 57], [58, 65], [66, 72], [73, 79], [79, 80], [81, 87], [88, 91], [92, 106], [107, 124], [125, 128], [129, 140], [141, 152], [153, 162], [162, 163], [164, 167], [168, 172], [173, 193], [194, 199], [200, 203], [204, 207], [208, 217], [218, 221], [222, 233], [234, 239], [240, 243], [244, 257], [258, 274], [275, 283], [283, 284], [285, 289], [290, 293], [294, 304], [305, 308], [309, 315], [316, 330], [330, 331]]}
{"doc_key": "ai-dev-252", "ner": [[0, 1, "researcher"], [10, 11, "misc"], [12, 18, "conference"], [20, 20, "location"], [22, 22, "country"], [35, 36, "researcher"], [46, 47, "university"], [50, 51, "researcher"], [53, 54, "researcher"], [56, 57, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10], "relations": [[0, 1, 10, 11, "related-to", "writes_about", false, false], [0, 1, 12, 18, "temporal", "", true, false], [12, 18, 20, 20, "physical", "", false, false], [20, 20, 22, 22, "physical", "", false, false], [50, 51, 46, 47, "physical", "", false, false], [50, 51, 46, 47, "role", "", false, false], [53, 54, 46, 47, "physical", "", false, false], [53, 54, 46, 47, "role", "", false, false], [56, 57, 46, 47, "physical", "", false, false], [56, 57, 46, 47, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 6, 7, 8, 9, 10, 11], "sentence": ["Roger", "Schank", ",", "1969", ",", "A", "conceptual", "dependency", "parser", "for", "natural", "language", "Proceedings", "of", "the", "1969", "on", "Computational", "linguistics", ",", "S\u00e5ng-S\u00e4by", ",", "Sweden", ",", "Seiten", "1-3", "Dieses", "Modell", ",", "das", "teilweise", "von", "der", "Arbeit", "von", "Sydney", "Lamb", "beeinflusst", "wurde", ",", "wurde", "von", "Schanks", "Studenten", "an", "der", "Yale", "University", ",", "wie", "Robert", "Wilensky", ",", "Wendy", "Lehnert", "und", "Janet", "Kolodner", ",", "ausgiebig", "genutzt", "."], "sentence-detokenized": "Roger Schank, 1969, A conceptual dependency parser for natural language Proceedings of the 1969 on Computational linguistics, S\u00e5ng-S\u00e4by, Sweden, Seiten 1-3 Dieses Modell, das teilweise von der Arbeit von Sydney Lamb beeinflusst wurde, wurde von Schanks Studenten an der Yale University, wie Robert Wilensky, Wendy Lehnert und Janet Kolodner, ausgiebig genutzt.", "token2charspan": [[0, 5], [6, 12], [12, 13], [14, 18], [18, 19], [20, 21], [22, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 71], [72, 83], [84, 86], [87, 90], [91, 95], [96, 98], [99, 112], [113, 124], [124, 125], [126, 135], [135, 136], [137, 143], [143, 144], [145, 151], [152, 155], [156, 162], [163, 169], [169, 170], [171, 174], [175, 184], [185, 188], [189, 192], [193, 199], [200, 203], [204, 210], [211, 215], [216, 227], [228, 233], [233, 234], [235, 240], [241, 244], [245, 252], [253, 262], [263, 265], [266, 269], [270, 274], [275, 285], [285, 286], [287, 290], [291, 297], [298, 306], [306, 307], [308, 313], [314, 321], [322, 325], [326, 331], [332, 340], [340, 341], [342, 351], [352, 359], [359, 360]]}
{"doc_key": "ai-dev-253", "ner": [[2, 2, "algorithm"], [4, 4, "algorithm"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[4, 4, 2, 2, "named", "", false, false], [13, 14, 2, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 2], "sentence": ["Die", "verbesserte", "Maximum-Likelihood-Methode", "(", "IMLM", ")", "ist", "eine", "Kombination", "aus", "zwei", "MLM-Sch\u00e4tzern", "(", "Maximum", "Likelihood", ")", "."], "sentence-detokenized": "Die verbesserte Maximum-Likelihood-Methode (IMLM) ist eine Kombination aus zwei MLM-Sch\u00e4tzern (Maximum Likelihood).", "token2charspan": [[0, 3], [4, 15], [16, 42], [43, 44], [44, 48], [48, 49], [50, 53], [54, 58], [59, 70], [71, 74], [75, 79], [80, 93], [94, 95], [95, 102], [103, 113], [113, 114], [114, 115]]}
{"doc_key": "ai-dev-254", "ner": [[18, 18, "metrics"], [21, 21, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[21, 21, 18, 18, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Diese", "Methoden", "k\u00f6nnen", "auch", "die", "Ausgabe", "eines", "Programms", "und", "seine", "N\u00fctzlichkeit", "analysieren", "und", "k\u00f6nnen", "daher", "die", "Analyse", "seiner", "Konfusionsmatrix", "(", "oder", "Konfusionstabelle", ")", "beinhalten", "."], "sentence-detokenized": "Diese Methoden k\u00f6nnen auch die Ausgabe eines Programms und seine N\u00fctzlichkeit analysieren und k\u00f6nnen daher die Analyse seiner Konfusionsmatrix (oder Konfusionstabelle) beinhalten.", "token2charspan": [[0, 5], [6, 14], [15, 21], [22, 26], [27, 30], [31, 38], [39, 44], [45, 54], [55, 58], [59, 64], [65, 77], [78, 89], [90, 93], [94, 100], [101, 106], [107, 110], [111, 118], [119, 125], [126, 142], [143, 144], [144, 148], [149, 166], [166, 167], [168, 178], [178, 179]]}
{"doc_key": "ai-dev-255", "ner": [[0, 0, "product"], [4, 5, "researcher"], [7, 8, "researcher"], [10, 12, "researcher"], [17, 22, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 4, 5, "origin", "", false, false], [0, 0, 7, 8, "origin", "", false, false], [0, 0, 10, 12, "origin", "", false, false], [0, 0, 17, 22, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SURF", "wurde", "erstmals", "von", "Herbert", "Bay", ",", "Tinne", "Tuytelaars", "und", "Luc", "Van", "Gool", "ver\u00f6ffentlicht", "und", "auf", "der", "European", "Conference", "on", "Computer", "Vision", "2006", "vorgestellt", "."], "sentence-detokenized": "SURF wurde erstmals von Herbert Bay, Tinne Tuytelaars und Luc Van Gool ver\u00f6ffentlicht und auf der European Conference on Computer Vision 2006 vorgestellt.", "token2charspan": [[0, 4], [5, 10], [11, 19], [20, 23], [24, 31], [32, 35], [35, 36], [37, 42], [43, 53], [54, 57], [58, 61], [62, 65], [66, 70], [71, 85], [86, 89], [90, 93], [94, 97], [98, 106], [107, 117], [118, 120], [121, 129], [130, 136], [137, 141], [142, 153], [153, 154]]}
{"doc_key": "ai-dev-256", "ner": [[0, 0, "task"], [7, 7, "field"], [10, 11, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 7, 7, "part-of", "", false, false], [0, 0, 10, 11, "part-of", "", false, false], [0, 0, 14, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OCR", "ist", "ein", "Forschungsgebiet", "im", "Bereich", "der", "Mustererkennung", ",", "der", "k\u00fcnstlichen", "Intelligenz", "und", "der", "Computer", "Vision", "."], "sentence-detokenized": "OCR ist ein Forschungsgebiet im Bereich der Mustererkennung, der k\u00fcnstlichen Intelligenz und der Computer Vision.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 28], [29, 31], [32, 39], [40, 43], [44, 59], [59, 60], [61, 64], [65, 76], [77, 88], [89, 92], [93, 96], [97, 105], [106, 112], [112, 113]]}
{"doc_key": "ai-dev-257", "ner": [[6, 6, "metrics"], [11, 11, "algorithm"], [13, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 13, 11, 11, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Wenn", "man", "das", "Beispiel", "mit", "dem", "Maximum-Likelihood-Sch\u00e4tzer", "fortsetzt", ",", "ist", "die", "Wahrscheinlichkeitsdichtefunktion", "(", "pdf", ")", "des", "Rauschens", "f\u00fcr", "eine", "Stichprobe", "mathwn", "/", "math"], "sentence-detokenized": "Wenn man das Beispiel mit dem Maximum-Likelihood-Sch\u00e4tzer fortsetzt, ist die Wahrscheinlichkeitsdichtefunktion (pdf) des Rauschens f\u00fcr eine Stichprobe mathwn / math", "token2charspan": [[0, 4], [5, 8], [9, 12], [13, 21], [22, 25], [26, 29], [30, 57], [58, 67], [67, 68], [69, 72], [73, 76], [77, 110], [111, 112], [112, 115], [115, 116], [117, 120], [121, 130], [131, 134], [135, 139], [140, 150], [151, 157], [158, 159], [160, 164]]}
{"doc_key": "ai-dev-258", "ner": [[4, 5, "field"], [8, 10, "task"], [13, 15, "task"], [18, 18, "task"], [21, 21, "task"], [24, 24, "task"], [27, 27, "task"], [30, 30, "task"], [33, 33, "task"], [36, 37, "task"], [40, 40, "task"], [43, 43, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[8, 10, 4, 5, "part-of", "", false, false], [13, 15, 4, 5, "part-of", "", false, false], [18, 18, 4, 5, "part-of", "", false, false], [21, 21, 4, 5, "part-of", "", false, false], [24, 24, 4, 5, "part-of", "", false, false], [27, 27, 4, 5, "part-of", "", false, false], [30, 30, 4, 5, "part-of", "", false, false], [33, 33, 4, 5, "part-of", "", false, false], [36, 37, 4, 5, "part-of", "", false, false], [40, 40, 4, 5, "part-of", "", false, false], [43, 43, 4, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Zu", "den", "Teilbereichen", "der", "Computer", "Vision", "geh\u00f6ren", "die", "Rekonstruktion", "von", "Szenen", ",", "die", "Erkennung", "von", "Ereignissen", ",", "die", "Videoverfolgung", ",", "die", "Objekterkennung", ",", "die", "3D-Positionsabsch\u00e4tzung", ",", "das", "Lernen", ",", "die", "Indexierung", ",", "die", "Bewegungsabsch\u00e4tzung", ",", "die", "visuelle", "Servosteuerung", ",", "die", "3D-Szenenmodellierung", "und", "die", "Bildwiederherstellung", "."], "sentence-detokenized": "Zu den Teilbereichen der Computer Vision geh\u00f6ren die Rekonstruktion von Szenen, die Erkennung von Ereignissen, die Videoverfolgung, die Objekterkennung, die 3D-Positionsabsch\u00e4tzung, das Lernen, die Indexierung, die Bewegungsabsch\u00e4tzung, die visuelle Servosteuerung, die 3D-Szenenmodellierung und die Bildwiederherstellung.", "token2charspan": [[0, 2], [3, 6], [7, 20], [21, 24], [25, 33], [34, 40], [41, 48], [49, 52], [53, 67], [68, 71], [72, 78], [78, 79], [80, 83], [84, 93], [94, 97], [98, 109], [109, 110], [111, 114], [115, 130], [130, 131], [132, 135], [136, 151], [151, 152], [153, 156], [157, 180], [180, 181], [182, 185], [186, 192], [192, 193], [194, 197], [198, 209], [209, 210], [211, 214], [215, 235], [235, 236], [237, 240], [241, 249], [250, 264], [264, 265], [266, 269], [270, 291], [292, 295], [296, 299], [300, 321], [321, 322]]}
{"doc_key": "ai-dev-259", "ner": [[7, 11, "conference"], [4, 4, "researcher"], [14, 14, "misc"], [17, 19, "conference"], [21, 21, "researcher"], [23, 23, "researcher"], [25, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[7, 11, 17, 19, "named", "", false, false], [4, 4, 14, 14, "win-defeat", "", false, false], [4, 4, 25, 25, "related-to", "writes_about", true, false], [14, 14, 7, 11, "temporal", "", false, false], [21, 21, 14, 14, "win-defeat", "", false, true], [21, 21, 25, 25, "related-to", "writes_about", true, false], [23, 23, 14, 14, "win-defeat", "", false, true], [23, 23, 25, 25, "related-to", "writes_about", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Im", "Jahr", "2013", "wurde", "Terzopoulos", "auf", "der", "International", "Conference", "on", "Computer", "Vision", "mit", "dem", "Helmholtz-Preis", "f\u00fcr", "seinen", "ICCV-Beitrag", "von", "1987", "mit", "Kass", "und", "Witkin", "\u00fcber", "aktive", "Konturmodelle", "ausgezeichnet", "."], "sentence-detokenized": "Im Jahr 2013 wurde Terzopoulos auf der International Conference on Computer Vision mit dem Helmholtz-Preis f\u00fcr seinen ICCV-Beitrag von 1987 mit Kass und Witkin \u00fcber aktive Konturmodelle ausgezeichnet.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 18], [19, 30], [31, 34], [35, 38], [39, 52], [53, 63], [64, 66], [67, 75], [76, 82], [83, 86], [87, 90], [91, 106], [107, 110], [111, 117], [118, 130], [131, 134], [135, 139], [140, 143], [144, 148], [149, 152], [153, 159], [160, 164], [165, 171], [172, 185], [186, 199], [199, 200]]}
{"doc_key": "ai-dev-260", "ner": [[16, 17, "task"], [20, 21, "algorithm"], [24, 24, "algorithm"], [26, 26, "algorithm"], [29, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[16, 17, 20, 21, "usage", "", true, false], [16, 17, 24, 24, "usage", "", true, false], [16, 17, 26, 26, "usage", "", true, false], [16, 17, 29, 29, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Wenn", "die", "Regularisierungsfunktion", "Viele", "Algorithmen", "existieren", "f\u00fcr", "die", "L\u00f6sung", "solcher", "Probleme", ";", "beliebte", "Algorithmen", "f\u00fcr", "die", "lineare", "Klassifizierung", "sind", "der", "stochastische", "Gradientenabstieg", ",", "der", "Gradientenabstieg", ",", "L-BFGS", ",", "der", "Koordinatenabstieg", "und", "Newton-Methoden", "."], "sentence-detokenized": "Wenn die Regularisierungsfunktion Viele Algorithmen existieren f\u00fcr die L\u00f6sung solcher Probleme; beliebte Algorithmen f\u00fcr die lineare Klassifizierung sind der stochastische Gradientenabstieg, der Gradientenabstieg, L-BFGS, der Koordinatenabstieg und Newton-Methoden.", "token2charspan": [[0, 4], [5, 8], [9, 33], [34, 39], [40, 51], [52, 62], [63, 66], [67, 70], [71, 77], [78, 85], [86, 94], [94, 95], [96, 104], [105, 116], [117, 120], [121, 124], [125, 132], [133, 148], [149, 153], [154, 157], [158, 171], [172, 189], [189, 190], [191, 194], [195, 212], [212, 213], [214, 220], [220, 221], [222, 225], [226, 244], [245, 248], [249, 264], [264, 265]]}
{"doc_key": "ai-dev-261", "ner": [[2, 3, "algorithm"], [5, 5, "algorithm"], [10, 11, "researcher"], [13, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 10, 11, "origin", "", false, false], [5, 5, 2, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Netzwerke", "mit", "langem", "Kurzzeitged\u00e4chtnis", "(", "LSTM", ")", "wurden", "1997", "von", "Sepp", "Hochreiter", "und", "J\u00fcrgen", "Schmidhuber", "erfunden", "und", "stellten", "in", "mehreren", "Anwendungsbereichen", "Genauigkeitsrekorde", "auf", "."], "sentence-detokenized": "Netzwerke mit langem Kurzzeitged\u00e4chtnis (LSTM) wurden 1997 von Sepp Hochreiter und J\u00fcrgen Schmidhuber erfunden und stellten in mehreren Anwendungsbereichen Genauigkeitsrekorde auf.", "token2charspan": [[0, 9], [10, 13], [14, 20], [21, 39], [40, 41], [41, 45], [45, 46], [47, 53], [54, 58], [59, 62], [63, 67], [68, 78], [79, 82], [83, 89], [90, 101], [102, 110], [111, 114], [115, 123], [124, 126], [127, 135], [136, 155], [156, 175], [176, 179], [179, 180]]}
{"doc_key": "ai-dev-262", "ner": [[0, 0, "product"], [3, 5, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 3, 5, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["TN", "wurde", "am", "Massachusetts", "General", "Hospital", "entwickelt", "und", "in", "mehreren", "Szenarien", "getestet", ",", "u.", "a.", "zur", "Ermittlung", "des", "Raucherstatus", ",", "der", "Familienanamnese", "f\u00fcr", "koronare", "Herzkrankheiten", "und", "zur", "Identifizierung", "von", "Patienten", "mit", "Schlafst\u00f6rungen", ","], "sentence-detokenized": "TN wurde am Massachusetts General Hospital entwickelt und in mehreren Szenarien getestet, u. a. zur Ermittlung des Raucherstatus, der Familienanamnese f\u00fcr koronare Herzkrankheiten und zur Identifizierung von Patienten mit Schlafst\u00f6rungen,", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 25], [26, 33], [34, 42], [43, 53], [54, 57], [58, 60], [61, 69], [70, 79], [80, 88], [88, 89], [90, 92], [93, 95], [96, 99], [100, 110], [111, 114], [115, 128], [128, 129], [130, 133], [134, 150], [151, 154], [155, 163], [164, 179], [180, 183], [184, 187], [188, 203], [204, 207], [208, 217], [218, 221], [222, 237], [237, 238]]}
{"doc_key": "ai-dev-263", "ner": [[4, 4, "researcher"], [13, 14, "organisation"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Im", "Jahr", "1960", "verkaufte", "Devol", "pers\u00f6nlich", "den", "ersten", "Unimate-Roboter", ",", "der", "1961", "an", "General", "Motors", "ausgeliefert", "wurde", "."], "sentence-detokenized": "Im Jahr 1960 verkaufte Devol pers\u00f6nlich den ersten Unimate-Roboter, der 1961 an General Motors ausgeliefert wurde.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 22], [23, 28], [29, 39], [40, 43], [44, 50], [51, 66], [66, 67], [68, 71], [72, 76], [77, 79], [80, 87], [88, 94], [95, 107], [108, 113], [113, 114]]}
{"doc_key": "ai-dev-264", "ner": [[1, 4, "conference"], [13, 14, "location"], [16, 16, "location"], [18, 18, "country"], [27, 30, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 4, 13, 14, "physical", "", false, false], [13, 14, 16, 16, "physical", "", false, false], [16, 16, 18, 18, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Die", "Campus", "Party", "Europe", "fand", "vom", "14.", "bis", "18.", "April", "2010", "in", "der", "Caja", "M\u00e1gica", "in", "Madrid", ",", "Spanien", ",", "mit", "800", "Teilnehmern", "aus", "allen", "27", "Mitgliedstaaten", "der", "Europ\u00e4ischen", "Union", "statt", "."], "sentence-detokenized": "Die Campus Party Europe fand vom 14. bis 18. April 2010 in der Caja M\u00e1gica in Madrid, Spanien, mit 800 Teilnehmern aus allen 27 Mitgliedstaaten der Europ\u00e4ischen Union statt.", "token2charspan": [[0, 3], [4, 10], [11, 16], [17, 23], [24, 28], [29, 32], [33, 36], [37, 40], [41, 44], [45, 50], [51, 55], [56, 58], [59, 62], [63, 67], [68, 74], [75, 77], [78, 84], [84, 85], [86, 93], [93, 94], [95, 98], [99, 102], [103, 114], [115, 118], [119, 124], [125, 127], [128, 143], [144, 147], [148, 160], [161, 166], [167, 172], [172, 173]]}
{"doc_key": "ai-dev-265", "ner": [[7, 7, "organisation"], [10, 12, "organisation"], [16, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 19, 7, 7, "origin", "", false, false], [16, 19, 10, 12, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Im", "Juli", "2016", "wurde", "eine", "Zusammenarbeit", "zwischen", "DeepMind", "und", "dem", "Moorfields", "Eye", "Hospital", "angek\u00fcndigt", ",", "um", "KI-Anwendungen", "f\u00fcr", "das", "Gesundheitswesen", "zu", "entwickeln", "."], "sentence-detokenized": "Im Juli 2016 wurde eine Zusammenarbeit zwischen DeepMind und dem Moorfields Eye Hospital angek\u00fcndigt, um KI-Anwendungen f\u00fcr das Gesundheitswesen zu entwickeln.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 18], [19, 23], [24, 38], [39, 47], [48, 56], [57, 60], [61, 64], [65, 75], [76, 79], [80, 88], [89, 100], [100, 101], [102, 104], [105, 119], [120, 123], [124, 127], [128, 144], [145, 147], [148, 158], [158, 159]]}
{"doc_key": "ai-dev-266", "ner": [[4, 4, "misc"], [12, 13, "university"], [15, 15, "university"], [17, 18, "university"], [20, 21, "university"], [23, 23, "university"], [25, 25, "university"], [27, 29, "university"], [31, 32, "university"], [34, 35, "university"], [37, 37, "university"], [40, 41, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[4, 4, 12, 13, "physical", "", false, false], [4, 4, 15, 15, "physical", "", false, false], [4, 4, 17, 18, "physical", "", false, false], [4, 4, 20, 21, "physical", "", false, false], [4, 4, 23, 23, "physical", "", false, false], [4, 4, 25, 25, "physical", "", false, false], [4, 4, 27, 29, "physical", "", false, false], [4, 4, 31, 32, "physical", "", false, false], [4, 4, 34, 35, "physical", "", false, false], [4, 4, 37, 37, "physical", "", false, false], [4, 4, 40, 41, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Am", "Ende", "wurden", "elf", "PR2", "an", "verschiedene", "Einrichtungen", "vergeben", ",", "darunter", "die", "Universit\u00e4t", "Freiburg", ",", "Bosch", ",", "Georgia", "Tech", ",", "KU", "Leuven", ",", "MIT", ",", "Stanford", ",", "Technische", "Universit\u00e4t", "M\u00fcnchen", ",", "UC", "Berkeley", ",", "U", "Penn", ",", "USC", "und", "die", "Universit\u00e4t", "Tokio", "."], "sentence-detokenized": "Am Ende wurden elf PR2 an verschiedene Einrichtungen vergeben, darunter die Universit\u00e4t Freiburg, Bosch, Georgia Tech, KU Leuven, MIT, Stanford, Technische Universit\u00e4t M\u00fcnchen, UC Berkeley, U Penn, USC und die Universit\u00e4t Tokio.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 18], [19, 22], [23, 25], [26, 38], [39, 52], [53, 61], [61, 62], [63, 71], [72, 75], [76, 87], [88, 96], [96, 97], [98, 103], [103, 104], [105, 112], [113, 117], [117, 118], [119, 121], [122, 128], [128, 129], [130, 133], [133, 134], [135, 143], [143, 144], [145, 155], [156, 167], [168, 175], [175, 176], [177, 179], [180, 188], [188, 189], [190, 191], [192, 196], [196, 197], [198, 201], [202, 205], [206, 209], [210, 221], [222, 227], [227, 228]]}
{"doc_key": "ai-dev-267", "ner": [[3, 3, "metrics"], [5, 5, "metrics"], [7, 7, "metrics"], [9, 9, "metrics"], [21, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 21, 21, "part-of", "", false, false], [5, 5, 21, 21, "part-of", "", false, false], [7, 7, 21, 21, "part-of", "", false, false], [9, 9, 21, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Die", "Anzahl", "der", "TP", ",", "TN", ",", "FP", "und", "FN", "wird", "in", "der", "Regel", "in", "einer", "Tabelle", ",", "der", "so", "genannten", "Konfusionsmatrix", ",", "festgehalten", "."], "sentence-detokenized": "Die Anzahl der TP, TN, FP und FN wird in der Regel in einer Tabelle, der sogenannten Konfusionsmatrix, festgehalten.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 17], [17, 18], [19, 21], [21, 22], [23, 25], [26, 29], [30, 32], [33, 37], [38, 40], [41, 44], [45, 50], [51, 53], [54, 59], [60, 67], [67, 68], [69, 72], [73, 75], [75, 84], [85, 101], [101, 102], [103, 115], [115, 116]]}
{"doc_key": "ai-dev-268", "ner": [[6, 6, "metrics"], [8, 8, "metrics"], [10, 11, "metrics"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Als", "Merkmale", "werden", "in", "der", "Regel", "Informationsgewinn", ",", "Kreuzentropie", ",", "gegenseitige", "Information", "und", "Odds", "Ratio", "verwendet", "."], "sentence-detokenized": "Als Merkmale werden in der Regel Informationsgewinn, Kreuzentropie, gegenseitige Information und Odds Ratio verwendet.", "token2charspan": [[0, 3], [4, 12], [13, 19], [20, 22], [23, 26], [27, 32], [33, 51], [51, 52], [53, 66], [66, 67], [68, 80], [81, 92], [93, 96], [97, 101], [102, 107], [108, 117], [117, 118]]}
{"doc_key": "ai-dev-269", "ner": [[10, 10, "task"], [12, 12, "task"], [14, 14, "task"], [16, 16, "task"], [18, 18, "task"], [20, 20, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 20, 18, 18, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Es", "wurde", "bereits", "erfolgreich", "auf", "verschiedene", "Probleme", "angewandt", ",", "darunter", "Robotersteuerung", ",", "Aufzugsplanung", ",", "Telekommunikation", ",", "Dame", "und", "Go", "(", "AlphaGo", ")", "."], "sentence-detokenized": "Es wurde bereits erfolgreich auf verschiedene Probleme angewandt, darunter Robotersteuerung, Aufzugsplanung, Telekommunikation, Dame und Go (AlphaGo).", "token2charspan": [[0, 2], [3, 8], [9, 16], [17, 28], [29, 32], [33, 45], [46, 54], [55, 64], [64, 65], [66, 74], [75, 91], [91, 92], [93, 107], [107, 108], [109, 126], [126, 127], [128, 132], [133, 136], [137, 139], [140, 141], [141, 148], [148, 149], [149, 150]]}
{"doc_key": "ai-dev-270", "ner": [[13, 14, "misc"], [19, 22, "university"], [24, 24, "location"], [26, 28, "location"], [31, 32, "location"], [36, 39, "location"], [41, 41, "location"], [42, 45, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[13, 14, 19, 22, "physical", "", false, false], [19, 22, 24, 24, "physical", "", false, false], [24, 24, 26, 28, "physical", "", false, false], [31, 32, 36, 39, "physical", "", false, false], [36, 39, 41, 41, "physical", "", false, false], [41, 41, 42, 45, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Im", "Jahr", "2018", ",", "dem", "ersten", "Jahr", "der", "Mission", "8", ",", "fand", "der", "amerikanische", "Austragungsort", "auf", "dem", "Campus", "des", "Georgia", "Institute", "of", "Technology", "in", "Atlanta", ",", "Georgia", ",", "statt", "und", "der", "asiatisch-pazifische", "Austragungsort", "wurde", "in", "der", "Sporthalle", "der", "Beihang", "University", "in", "Peking", ",", "China", ",", "abgehalten", "."], "sentence-detokenized": "Im Jahr 2018, dem ersten Jahr der Mission 8, fand der amerikanische Austragungsort auf dem Campus des Georgia Institute of Technology in Atlanta, Georgia, statt und der asiatisch-pazifische Austragungsort wurde in der Sporthalle der Beihang University in Peking, China, abgehalten.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 24], [25, 29], [30, 33], [34, 41], [42, 43], [43, 44], [45, 49], [50, 53], [54, 67], [68, 82], [83, 86], [87, 90], [91, 97], [98, 101], [102, 109], [110, 119], [120, 122], [123, 133], [134, 136], [137, 144], [144, 145], [146, 153], [153, 154], [155, 160], [161, 164], [165, 168], [169, 189], [190, 204], [205, 210], [211, 213], [214, 217], [218, 228], [229, 232], [233, 240], [241, 251], [252, 254], [255, 261], [261, 262], [263, 268], [268, 269], [270, 280], [280, 281]]}
{"doc_key": "ai-dev-271", "ner": [[0, 1, "field"], [6, 6, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 6, "origin", "", false, false], [0, 1, 6, 6, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Maschinelles", "Lernen", "ist", "eng", "mit", "der", "Mustererkennung", "verbunden", "und", "hat", "seinen", "Ursprung", "in", "der", "k\u00fcnstlichen", "Intelligenz", "."], "sentence-detokenized": "Maschinelles Lernen ist eng mit der Mustererkennung verbunden und hat seinen Ursprung in der k\u00fcnstlichen Intelligenz.", "token2charspan": [[0, 12], [13, 19], [20, 23], [24, 27], [28, 31], [32, 35], [36, 51], [52, 61], [62, 65], [66, 69], [70, 76], [77, 85], [86, 88], [89, 92], [93, 104], [105, 116], [116, 117]]}
{"doc_key": "ai-dev-272", "ner": [[13, 13, "product"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Es", "enth\u00e4lt", "3", "Java-Spiele", ",", "die", "mit", "der", "Fernbedienung", "gesteuert", "und", "auf", "dem", "LCD-Bildschirm", "angezeigt", "werden", "."], "sentence-detokenized": "Es enth\u00e4lt 3 Java-Spiele, die mit der Fernbedienung gesteuert und auf dem LCD-Bildschirm angezeigt werden.", "token2charspan": [[0, 2], [3, 10], [11, 12], [13, 24], [24, 25], [26, 29], [30, 33], [34, 37], [38, 51], [52, 61], [62, 65], [66, 69], [70, 73], [74, 88], [89, 98], [99, 105], [105, 106]]}
{"doc_key": "ai-dev-273", "ner": [[6, 17, "task"], [20, 21, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 21, 6, 17, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Ein", "kommerziell", "erfolgreiches", ",", "aber", "spezialisiertes", ",", "auf", "Computer", "Vision", "basierendes", "Verfahren", "zur", "Sch\u00e4tzung", "der", "K\u00f6rperhaltung", "von", "Gelenkfiguren", "ist", "die", "optische", "Bewegungserfassung", "."], "sentence-detokenized": "Ein kommerziell erfolgreiches, aber spezialisiertes, auf Computer Vision basierendes Verfahren zur Sch\u00e4tzung der K\u00f6rperhaltung von Gelenkfiguren ist die optische Bewegungserfassung.", "token2charspan": [[0, 3], [4, 15], [16, 29], [29, 30], [31, 35], [36, 51], [51, 52], [53, 56], [57, 65], [66, 72], [73, 84], [85, 94], [95, 98], [99, 108], [109, 112], [113, 126], [127, 130], [131, 144], [145, 148], [149, 152], [153, 161], [162, 180], [180, 181]]}
{"doc_key": "ai-dev-274", "ner": [[1, 1, "organisation"], [5, 5, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 1, 5, 5, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Der", "SMC", "ist", "dem", "bekannteren", "Jaccard-Index", "sehr", "\u00e4hnlich", "."], "sentence-detokenized": "Der SMC ist dem bekannteren Jaccard-Index sehr \u00e4hnlich.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 15], [16, 27], [28, 41], [42, 46], [47, 54], [54, 55]]}
{"doc_key": "ai-dev-275", "ner": [[1, 1, "product"], [3, 7, "product"], [9, 12, "product"], [20, 21, "researcher"], [26, 26, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 9, 12, "named", "", false, false], [1, 1, 20, 21, "artifact", "", false, false], [1, 1, 26, 26, "artifact", "", false, false], [3, 7, 1, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Der", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", "oder", "Programmable", "Universal", "Manipulation", "Arm", ")", "ist", "ein", "Industrieroboterarm", ",", "der", "von", "Victor", "Scheinman", "bei", "der", "bahnbrechenden", "Roboterfirma", "Unimation", "entwickelt", "wurde", "."], "sentence-detokenized": "Der PUMA (Programmable Universal Machine for Assembly oder Programmable Universal Manipulation Arm) ist ein Industrieroboterarm, der von Victor Scheinman bei der bahnbrechenden Roboterfirma Unimation entwickelt wurde.", "token2charspan": [[0, 3], [4, 8], [9, 10], [10, 22], [23, 32], [33, 40], [41, 44], [45, 53], [54, 58], [59, 71], [72, 81], [82, 94], [95, 98], [98, 99], [100, 103], [104, 107], [108, 127], [127, 128], [129, 132], [133, 136], [137, 143], [144, 153], [154, 157], [158, 161], [162, 176], [177, 189], [190, 199], [200, 210], [211, 216], [216, 217]]}
{"doc_key": "ai-dev-276", "ner": [[3, 3, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Es", "ist", "in", "Python", "geschrieben", "."], "sentence-detokenized": "Es ist in Python geschrieben.", "token2charspan": [[0, 2], [3, 6], [7, 9], [10, 16], [17, 28], [28, 29]]}
{"doc_key": "ai-dev-277", "ner": [[0, 1, "misc"], [3, 3, "misc"], [13, 13, "field"], [15, 15, "field"], [17, 17, "field"], [22, 22, "field"], [24, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6, 7], "relations": [[0, 1, 3, 3, "related-to", "metric_for", true, false], [0, 1, 13, 13, "part-of", "", false, false], [0, 1, 15, 15, "part-of", "", false, false], [0, 1, 17, 17, "part-of", "", false, false], [0, 1, 22, 22, "part-of", "", false, false], [0, 1, 24, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5, 6], "sentence": ["Die", "Bandbreite", "in", "Hertz", "ist", "ein", "zentrales", "Konzept", "in", "vielen", "Bereichen", ",", "darunter", "Elektronik", ",", "Informationstheorie", ",", "digitale", "Kommunikation", ",", "Funkkommunikation", ",", "Signalverarbeitung", "und", "Spektroskopie", ",", "und", "ist", "eine", "der", "Determinanten", "f\u00fcr", "die", "Kapazit\u00e4t", "eines", "bestimmten", "Kommunikationskanals", "."], "sentence-detokenized": "Die Bandbreite in Hertz ist ein zentrales Konzept in vielen Bereichen, darunter Elektronik, Informationstheorie, digitale Kommunikation, Funkkommunikation, Signalverarbeitung und Spektroskopie, und ist eine der Determinanten f\u00fcr die Kapazit\u00e4t eines bestimmten Kommunikationskanals.", "token2charspan": [[0, 3], [4, 14], [15, 17], [18, 23], [24, 27], [28, 31], [32, 41], [42, 49], [50, 52], [53, 59], [60, 69], [69, 70], [71, 79], [80, 90], [90, 91], [92, 111], [111, 112], [113, 121], [122, 135], [135, 136], [137, 154], [154, 155], [156, 174], [175, 178], [179, 192], [192, 193], [194, 197], [198, 201], [202, 206], [207, 210], [211, 224], [225, 228], [229, 232], [233, 242], [243, 248], [249, 259], [260, 280], [280, 281]]}
{"doc_key": "ai-dev-278", "ner": [[9, 9, "algorithm"], [11, 11, "algorithm"], [16, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 16, 18, "part-of", "", false, false], [11, 11, 16, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Wenn", "ein", "konvexer", "Verlust", "verwendet", "wird", "(", "wie", "bei", "AdaBoost", ",", "LogitBoost", "und", "allen", "Mitgliedern", "der", "AnyBoost-Familie", "von", "Algorithmen", ")", ",", "dann", "wird", "ein", "Beispiel", "mit", "einer", "h\u00f6heren", "Marge", "weniger", "(", "oder", "gleich", ")", "gewichtet", "als", "ein", "Beispiel", "mit", "einer", "niedrigeren", "Marge", "."], "sentence-detokenized": "Wenn ein konvexer Verlust verwendet wird (wie bei AdaBoost, LogitBoost und allen Mitgliedern der AnyBoost-Familie von Algorithmen), dann wird ein Beispiel mit einer h\u00f6heren Marge weniger (oder gleich) gewichtet als ein Beispiel mit einer niedrigeren Marge.", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 25], [26, 35], [36, 40], [41, 42], [42, 45], [46, 49], [50, 58], [58, 59], [60, 70], [71, 74], [75, 80], [81, 92], [93, 96], [97, 113], [114, 117], [118, 129], [129, 130], [130, 131], [132, 136], [137, 141], [142, 145], [146, 154], [155, 158], [159, 164], [165, 172], [173, 178], [179, 186], [187, 188], [188, 192], [193, 199], [199, 200], [201, 210], [211, 214], [215, 218], [219, 227], [228, 231], [232, 237], [238, 249], [250, 255], [255, 256]]}
{"doc_key": "ai-dev-279", "ner": [[0, 0, "researcher"], [5, 6, "researcher"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 5, 6, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Sepp", "Hochreiters", "Diplomarbeit", "von", "1991", "Sepp", "Hochreiter", "."], "sentence-detokenized": "Sepp Hochreiters Diplomarbeit von 1991 Sepp Hochreiter.", "token2charspan": [[0, 4], [5, 16], [17, 29], [30, 33], [34, 38], [39, 43], [44, 54], [54, 55]]}
{"doc_key": "ai-dev-280", "ner": [[4, 5, "algorithm"], [7, 7, "algorithm"], [10, 11, "algorithm"], [14, 14, "algorithm"], [17, 19, "algorithm"], [21, 21, "algorithm"], [27, 28, "algorithm"], [31, 31, "algorithm"], [33, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[7, 7, 4, 5, "named", "", false, false], [14, 14, 10, 11, "named", "", false, false], [17, 19, 27, 28, "related-to", "", true, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Typische", "diskriminative", "Modelle", "sind", "logistische", "Regression", "(", "LR", ")", ",", "Support", "Vector", "Machines", "(", "SVM", ")", ",", "Conditional", "Random", "Fields", "(", "CRF", ")", "(", "spezifiziert", "\u00fcber", "einen", "ungerichteten", "Graphen", ")", ",", "Entscheidungsb\u00e4ume", ",", "neuronale", "Netze", "und", "viele", "andere", "."], "sentence-detokenized": "Typische diskriminative Modelle sind logistische Regression (LR), Support Vector Machines (SVM), Conditional Random Fields (CRF) (spezifiziert \u00fcber einen ungerichteten Graphen), Entscheidungsb\u00e4ume, neuronale Netze und viele andere.", "token2charspan": [[0, 8], [9, 23], [24, 31], [32, 36], [37, 48], [49, 59], [60, 61], [61, 63], [63, 64], [64, 65], [66, 73], [74, 80], [81, 89], [90, 91], [91, 94], [94, 95], [95, 96], [97, 108], [109, 115], [116, 122], [123, 124], [124, 127], [127, 128], [129, 130], [130, 142], [143, 147], [148, 153], [154, 167], [168, 175], [175, 176], [176, 177], [178, 196], [196, 197], [198, 207], [208, 213], [214, 217], [218, 223], [224, 230], [230, 231]]}
{"doc_key": "ai-dev-281", "ner": [[12, 14, "metrics"], [36, 36, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Dann", "ist", "es", "auch", "m\u00f6glich", ",", "diese", "Wahrscheinlichkeiten", "zu", "verwenden", "und", "den", "mittleren", "quadratischen", "Fehler", "(", "oder", "ein", "anderes", "\u00e4hnliches", "Ma\u00df", ")", "zwischen", "den", "Wahrscheinlichkeiten", "und", "den", "tats\u00e4chlichen", "Werten", "zu", "bewerten", "und", "dies", "dann", "mit", "der", "Konfusionsmatrix", "zu", "kombinieren", ",", "um", "sehr", "effiziente", "Fitnessfunktionen", "f\u00fcr", "die", "logistische", "Regression", "zu", "erstellen", "."], "sentence-detokenized": "Dann ist es auch m\u00f6glich, diese Wahrscheinlichkeiten zu verwenden und den mittleren quadratischen Fehler (oder ein anderes \u00e4hnliches Ma\u00df) zwischen den Wahrscheinlichkeiten und den tats\u00e4chlichen Werten zu bewerten und dies dann mit der Konfusionsmatrix zu kombinieren, um sehr effiziente Fitnessfunktionen f\u00fcr die logistische Regression zu erstellen.", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 16], [17, 24], [24, 25], [26, 31], [32, 52], [53, 55], [56, 65], [66, 69], [70, 73], [74, 83], [84, 97], [98, 104], [105, 106], [106, 110], [111, 114], [115, 122], [123, 132], [133, 136], [136, 137], [138, 146], [147, 150], [151, 171], [172, 175], [176, 179], [180, 193], [194, 200], [201, 203], [204, 212], [213, 216], [217, 221], [222, 226], [227, 230], [231, 234], [235, 251], [252, 254], [255, 266], [266, 267], [268, 270], [271, 275], [276, 286], [287, 304], [305, 308], [309, 312], [313, 324], [325, 335], [336, 338], [339, 348], [348, 349]]}
{"doc_key": "ai-dev-282", "ner": [[0, 0, "product"], [7, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 7, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VoiceOver", "wurde", "2005", "zum", "ersten", "Mal", "in", "Mac", "OS", "X", "Tiger", "(", "10.4", ")", "eingesetzt", "."], "sentence-detokenized": "VoiceOver wurde 2005 zum ersten Mal in Mac OS X Tiger (10.4) eingesetzt.", "token2charspan": [[0, 9], [10, 15], [16, 20], [21, 24], [25, 31], [32, 35], [36, 38], [39, 42], [43, 45], [46, 47], [48, 53], [54, 55], [55, 59], [59, 60], [61, 71], [71, 72]]}
{"doc_key": "ai-dev-283", "ner": [[15, 16, "algorithm"], [19, 19, "misc"], [24, 24, "metrics"], [26, 26, "algorithm"], [56, 58, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 16, 19, 19, "related-to", "applied_to", false, false], [24, 24, 19, 19, "type-of", "", false, false], [24, 24, 26, 26, "related-to", "used_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "der", "Praxis", "werden", "Algorithmen", "des", "maschinellen", "Lernens", "damit", "fertig", ",", "indem", "sie", "entweder", "eine", "konvexe", "Ann\u00e4herung", "an", "die", "0-1-Verlustfunktion", "verwenden", "(", "z.", "B.", "Scharnierverlust", "f\u00fcr", "Support-Vektor-Maschinen", ")", ",", "die", "leichter", "zu", "optimieren", "ist", ",", "oder", "indem", "sie", "Annahmen", "\u00fcber", "die", "Verteilung", "mathP", "(", "x", ",", "y", ")", "/", "math", "auferlegen", "(", "und", "damit", "aufh\u00f6ren", ",", "agnostische", "Lernalgorithmen", "zu", "sein", ",", "f\u00fcr", "die", "das", "obige", "Ergebnis", "gilt", ")", "."], "sentence-detokenized": "In der Praxis werden Algorithmen des maschinellen Lernens damit fertig, indem sie entweder eine konvexe Ann\u00e4herung an die 0-1-Verlustfunktion verwenden (z. B. Scharnierverlust f\u00fcr Support-Vektor-Maschinen), die leichter zu optimieren ist, oder indem sie Annahmen \u00fcber die Verteilung mathP (x, y) / math auferlegen (und damit aufh\u00f6ren, agnostische Lernalgorithmen zu sein, f\u00fcr die das obige Ergebnis gilt).", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 20], [21, 32], [33, 36], [37, 49], [50, 57], [58, 63], [64, 70], [70, 71], [72, 77], [78, 81], [82, 90], [91, 95], [96, 103], [104, 114], [115, 117], [118, 121], [122, 141], [142, 151], [152, 153], [153, 155], [156, 158], [159, 175], [176, 179], [180, 204], [204, 205], [205, 206], [207, 210], [211, 219], [220, 222], [223, 233], [234, 237], [237, 238], [239, 243], [244, 249], [250, 253], [254, 262], [263, 267], [268, 271], [272, 282], [283, 288], [289, 290], [290, 291], [291, 292], [293, 294], [294, 295], [296, 297], [298, 302], [303, 313], [314, 315], [315, 318], [319, 324], [325, 333], [333, 334], [335, 346], [347, 362], [363, 365], [366, 370], [370, 371], [372, 375], [376, 379], [380, 383], [384, 389], [390, 398], [399, 403], [403, 404], [404, 405]]}
{"doc_key": "ai-dev-284", "ner": [[0, 0, "misc"], [11, 12, "field"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 12, "usage", "", false, false], [0, 0, 22, 22, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Westworld", "(", "1973", ")", "war", "der", "erste", "Spielfilm", ",", "der", "die", "digitale", "Bildverarbeitung", "f\u00fcr", "die", "Fotografie", "nutzte", ",", "um", "die", "Sichtweise", "eines", "Androiden", "zu", "simulieren", "."], "sentence-detokenized": "Westworld (1973) war der erste Spielfilm, der die digitale Bildverarbeitung f\u00fcr die Fotografie nutzte, um die Sichtweise eines Androiden zu simulieren.", "token2charspan": [[0, 9], [10, 11], [11, 15], [15, 16], [17, 20], [21, 24], [25, 30], [31, 40], [40, 41], [42, 45], [46, 49], [50, 58], [59, 75], [76, 79], [80, 83], [84, 94], [95, 101], [101, 102], [103, 105], [106, 109], [110, 120], [121, 126], [127, 136], [137, 139], [140, 150], [150, 151]]}
{"doc_key": "ai-dev-285", "ner": [[7, 7, "task"], [9, 9, "task"], [11, 11, "task"], [13, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sie", "wird", "jetzt", "auch", "h\u00e4ufig", "in", "der", "Spracherkennung", ",", "Sprachsynthese", ",", "Diarisierung", ",", "Xavier", "Anguera", "et", "al", "."], "sentence-detokenized": "Sie wird jetzt auch h\u00e4ufig in der Spracherkennung, Sprachsynthese, Diarisierung, Xavier Anguera et al.", "token2charspan": [[0, 3], [4, 8], [9, 14], [15, 19], [20, 26], [27, 29], [30, 33], [34, 49], [49, 50], [51, 65], [65, 66], [67, 79], [79, 80], [81, 87], [88, 95], [96, 98], [99, 101], [101, 102]]}
{"doc_key": "ai-dev-286", "ner": [[7, 8, "algorithm"], [11, 11, "algorithm"], [14, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 7, 8, "type-of", "", false, false], [14, 16, 7, 8, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hier", "ist", "math\\", "sigma", "/", "math", "eine", "elementweise", "Aktivierungsfunktion", "wie", "eine", "Sigmoidfunktion", "oder", "eine", "gleichgerichtete", "lineare", "Einheit", "."], "sentence-detokenized": "Hier ist math\\ sigma / math eine elementweise Aktivierungsfunktion wie eine Sigmoidfunktion oder eine gleichgerichtete lineare Einheit.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 20], [21, 22], [23, 27], [28, 32], [33, 45], [46, 66], [67, 70], [71, 75], [76, 91], [92, 96], [97, 101], [102, 118], [119, 126], [127, 134], [134, 135]]}
{"doc_key": "ai-dev-287", "ner": [[6, 6, "algorithm"], [21, 21, "misc"]], "ner_mapping_to_source": [0, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditionelle", "phonetisch", "basierte", "(", "d.h.", "auf", "Hidden-Markov-Modellen", "basierende", ")", "Ans\u00e4tze", "erforderten", "separate", "Komponenten", "und", "Training", "f\u00fcr", "das", "Aussprache-", ",", "Akustik-", "und", "Sprachmodell", "."], "sentence-detokenized": "Traditionelle phonetisch basierte (d.h. auf Hidden-Markov-Modellen basierende) Ans\u00e4tze erforderten separate Komponenten und Training f\u00fcr das Aussprache-, Akustik- und Sprachmodell.", "token2charspan": [[0, 13], [14, 24], [25, 33], [34, 35], [35, 39], [40, 43], [44, 66], [67, 77], [77, 78], [79, 86], [87, 98], [99, 107], [108, 119], [120, 123], [124, 132], [133, 136], [137, 140], [141, 152], [152, 153], [154, 162], [163, 166], [167, 179], [179, 180]]}
{"doc_key": "ai-dev-288", "ner": [[1, 1, "algorithm"], [5, 5, "field"], [8, 9, "field"], [11, 11, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 11, 11, "related-to", "used_for", false, false], [5, 5, 1, 1, "usage", "", false, false], [8, 9, 1, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Der", "Roberts-Kreuz-Operator", "wird", "in", "der", "Bildverarbeitung", "und", "der", "Computer", "Vision", "zur", "Kantenerkennung", "verwendet", "."], "sentence-detokenized": "Der Roberts-Kreuz-Operator wird in der Bildverarbeitung und der Computer Vision zur Kantenerkennung verwendet.", "token2charspan": [[0, 3], [4, 26], [27, 31], [32, 34], [35, 38], [39, 55], [56, 59], [60, 63], [64, 72], [73, 79], [80, 83], [84, 99], [100, 109], [109, 110]]}
{"doc_key": "ai-dev-289", "ner": [[3, 3, "metrics"], [5, 5, "metrics"], [23, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 23, 23, "opposite", "", false, false], [5, 5, 23, 23, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Die", "Werte", "f\u00fcr", "Sensitivit\u00e4t", "und", "Spezifit\u00e4t", "sind", "unabh\u00e4ngig", "vom", "Prozentsatz", "der", "positiven", "F\u00e4lle", "in", "der", "interessierenden", "Population", "(", "im", "Gegensatz", "z.", "B.", "zur", "Pr\u00e4zision", ")", "."], "sentence-detokenized": "Die Werte f\u00fcr Sensitivit\u00e4t und Spezifit\u00e4t sind unabh\u00e4ngig vom Prozentsatz der positiven F\u00e4lle in der interessierenden Population (im Gegensatz z. B. zur Pr\u00e4zision).", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 26], [27, 30], [31, 41], [42, 46], [47, 57], [58, 61], [62, 73], [74, 77], [78, 87], [88, 93], [94, 96], [97, 100], [101, 117], [118, 128], [129, 130], [130, 132], [133, 142], [143, 145], [146, 148], [149, 152], [153, 162], [162, 163], [163, 164]]}
{"doc_key": "ai-dev-290", "ner": [[0, 1, "algorithm"], [8, 8, "misc"], [10, 11, "researcher"], [13, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 0, 1, "topic", "", false, false], [8, 8, 10, 11, "artifact", "", false, false], [8, 8, 13, 14, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Perceptron-Modelle", "wurden", "jedoch", "durch", "das", "1969", "erschienene", "Buch", "Perceptrons", "von", "Marvin", "Minsky", "und", "Seymour", "Papert", "sehr", "unbeliebt", "gemacht", "."], "sentence-detokenized": "Perceptron-Modelle wurden jedoch durch das 1969 erschienene Buch Perceptrons von Marvin Minsky und Seymour Papert sehr unbeliebt gemacht.", "token2charspan": [[0, 18], [19, 25], [26, 32], [33, 38], [39, 42], [43, 47], [48, 59], [60, 64], [65, 76], [77, 80], [81, 87], [88, 94], [95, 98], [99, 106], [107, 113], [114, 118], [119, 128], [129, 136], [136, 137]]}
{"doc_key": "ai-dev-291", "ner": [[1, 3, "conference"], [8, 8, "organisation"], [23, 25, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 3, 23, 25, "topic", "", false, false], [8, 8, 1, 3, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Die", "Document", "Understanding", "Conferences", ",", "die", "j\u00e4hrlich", "vom", "NIST", "durchgef\u00fchrt", "werden", ",", "haben", "ausgefeilte", "Bewertungskriterien", "f\u00fcr", "Techniken", "entwickelt", ",", "die", "die", "Herausforderung", "der", "Zusammenfassung", "mehrerer", "Dokumente", "annehmen", "."], "sentence-detokenized": "Die Document Understanding Conferences, die j\u00e4hrlich vom NIST durchgef\u00fchrt werden, haben ausgefeilte Bewertungskriterien f\u00fcr Techniken entwickelt, die die Herausforderung der Zusammenfassung mehrerer Dokumente annehmen.", "token2charspan": [[0, 3], [4, 12], [13, 26], [27, 38], [38, 39], [40, 43], [44, 52], [53, 56], [57, 61], [62, 74], [75, 81], [81, 82], [83, 88], [89, 100], [101, 120], [121, 124], [125, 134], [135, 145], [145, 146], [147, 150], [151, 154], [155, 170], [171, 174], [175, 190], [191, 199], [200, 209], [210, 218], [218, 219]]}
{"doc_key": "ai-dev-292", "ner": [[1, 1, "product"], [13, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 1, 13, 14, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Ein", "Parallelmanipulator", "ist", "so", "konstruiert", ",", "dass", "jede", "Kette", "im", "Vergleich", "zu", "einem", "seriellen", "Manipulator", "in", "der", "Regel", "kurz", "und", "einfach", "ist", "und", "daher", "starr", "gegen", "unerw\u00fcnschte", "Bewegungen", "sein", "kann", "."], "sentence-detokenized": "Ein Parallelmanipulator ist so konstruiert, dass jede Kette im Vergleich zu einem seriellen Manipulator in der Regel kurz und einfach ist und daher starr gegen unerw\u00fcnschte Bewegungen sein kann.", "token2charspan": [[0, 3], [4, 23], [24, 27], [28, 30], [31, 42], [42, 43], [44, 48], [49, 53], [54, 59], [60, 62], [63, 72], [73, 75], [76, 81], [82, 91], [92, 103], [104, 106], [107, 110], [111, 116], [117, 121], [122, 125], [126, 133], [134, 137], [138, 141], [142, 147], [148, 153], [154, 159], [160, 172], [173, 183], [184, 188], [189, 193], [193, 194]]}
{"doc_key": "ai-dev-293", "ner": [[25, 25, "misc"], [27, 28, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Der", "Manipulator", "sorgt", "daf\u00fcr", ",", "dass", "sich", "der", "Roboter", "bewegt", ",", "und", "die", "Konstruktion", "dieser", "Systeme", "kann", "in", "mehrere", "g\u00e4ngige", "Typen", "unterteilt", "werden", ",", "wie", "SCARA", "und", "kartesische", "Koordinatenroboter", ",", "die", "verschiedene", "Koordinatensysteme", "zur", "Steuerung", "der", "Arme", "der", "Maschine", "verwenden", "."], "sentence-detokenized": "Der Manipulator sorgt daf\u00fcr, dass sich der Roboter bewegt, und die Konstruktion dieser Systeme kann in mehrere g\u00e4ngige Typen unterteilt werden, wie SCARA und kartesische Koordinatenroboter, die verschiedene Koordinatensysteme zur Steuerung der Arme der Maschine verwenden.", "token2charspan": [[0, 3], [4, 15], [16, 21], [22, 27], [27, 28], [29, 33], [34, 38], [39, 42], [43, 50], [51, 57], [57, 58], [59, 62], [63, 66], [67, 79], [80, 86], [87, 94], [95, 99], [100, 102], [103, 110], [111, 118], [119, 124], [125, 135], [136, 142], [142, 143], [144, 147], [148, 153], [154, 157], [158, 169], [170, 188], [188, 189], [190, 193], [194, 206], [207, 225], [226, 229], [230, 239], [240, 243], [244, 248], [249, 252], [253, 261], [262, 271], [271, 272]]}
{"doc_key": "ai-dev-294", "ner": [[2, 3, "country"], [8, 11, "organisation"], [14, 19, "organisation"], [22, 25, "organisation"], [28, 30, "organisation"], [33, 39, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 11, 2, 3, "physical", "", false, false], [14, 19, 2, 3, "physical", "", false, false], [22, 25, 2, 3, "physical", "", false, false], [28, 30, 2, 3, "physical", "", false, false], [33, 39, 2, 3, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "den", "Vereinigten", "Staaten", "ist", "er", "Mitglied", "der", "National", "Academy", "of", "Sciences", ",", "der", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "der", "Linguistic", "Society", "of", "America", ",", "der", "American", "Philosophical", "Association", "und", "der", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In den Vereinigten Staaten ist er Mitglied der National Academy of Sciences, der American Academy of Arts and Sciences, der Linguistic Society of America, der American Philosophical Association und der American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 6], [7, 18], [19, 26], [27, 30], [31, 33], [34, 42], [43, 46], [47, 55], [56, 63], [64, 66], [67, 75], [75, 76], [77, 80], [81, 89], [90, 97], [98, 100], [101, 105], [106, 109], [110, 118], [118, 119], [120, 123], [124, 134], [135, 142], [143, 145], [146, 153], [153, 154], [155, 158], [159, 167], [168, 181], [182, 193], [194, 197], [198, 201], [202, 210], [211, 222], [223, 226], [227, 230], [231, 242], [243, 245], [246, 253], [253, 254]]}
{"doc_key": "ai-dev-295", "ner": [[8, 10, "algorithm"], [12, 12, "algorithm"], [25, 25, "algorithm"], [32, 33, "algorithm"], [30, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 10, 25, 25, "named", "", false, false], [12, 12, 8, 10, "named", "", false, false], [25, 25, 32, 33, "compare", "", false, false], [25, 25, 30, 30, "related-to", "performs", false, false], [32, 33, 30, 30, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Gro\u00dfe", "Bekanntheit", "erlangten", "sie", "mit", "der", "Popularit\u00e4t", "der", "Support", "Vector", "Machine", "(", "SVM", ")", "in", "den", "1990er", "Jahren", ",", "als", "festgestellt", "wurde", ",", "dass", "die", "SVM", "bei", "Aufgaben", "wie", "der", "Handschrifterkennung", "mit", "neuronalen", "Netzen", "konkurrieren", "kann", "."], "sentence-detokenized": "Gro\u00dfe Bekanntheit erlangten sie mit der Popularit\u00e4t der Support Vector Machine (SVM) in den 1990er Jahren, als festgestellt wurde, dass die SVM bei Aufgaben wie der Handschrifterkennung mit neuronalen Netzen konkurrieren kann.", "token2charspan": [[0, 5], [6, 17], [18, 27], [28, 31], [32, 35], [36, 39], [40, 51], [52, 55], [56, 63], [64, 70], [71, 78], [79, 80], [80, 83], [83, 84], [85, 87], [88, 91], [92, 98], [99, 105], [105, 106], [107, 110], [111, 123], [124, 129], [129, 130], [131, 135], [136, 139], [140, 143], [144, 147], [148, 156], [157, 160], [161, 164], [165, 185], [186, 189], [190, 200], [201, 207], [208, 220], [221, 225], [225, 226]]}
{"doc_key": "ai-dev-296", "ner": [[2, 2, "misc"], [7, 7, "misc"], [12, 13, "algorithm"], [21, 21, "misc"], [26, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 7, 7, "usage", "", false, false], [2, 2, 21, 21, "usage", "", false, false], [7, 7, 12, 13, "origin", "result_of_algorithm", false, false], [21, 21, 26, 26, "origin", "result_of_algorithm", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Eine", "empirische", "Whitening-Transformation", "wird", "durch", "Sch\u00e4tzung", "der", "Kovarianz", "(", "z.", "B.", "durch", "Maximum", "Likelihood", ")", "und", "anschlie\u00dfende", "Konstruktion", "einer", "entsprechenden", "gesch\u00e4tzten", "Whitening-Matrix", "(", "z.", "B.", "durch", "Cholesky-Zerlegung", ")", "gewonnen", "."], "sentence-detokenized": "Eine empirische Whitening-Transformation wird durch Sch\u00e4tzung der Kovarianz (z. B. durch Maximum Likelihood) und anschlie\u00dfende Konstruktion einer entsprechenden gesch\u00e4tzten Whitening-Matrix (z. B. durch Cholesky-Zerlegung) gewonnen.", "token2charspan": [[0, 4], [5, 15], [16, 40], [41, 45], [46, 51], [52, 61], [62, 65], [66, 75], [76, 77], [77, 79], [80, 82], [83, 88], [89, 96], [97, 107], [107, 108], [109, 112], [113, 126], [127, 139], [140, 145], [146, 160], [161, 172], [173, 189], [190, 191], [191, 193], [194, 196], [197, 202], [203, 221], [221, 222], [223, 231], [231, 232]]}
{"doc_key": "ai-dev-297", "ner": [[0, 0, "organisation"], [7, 8, "product"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 0, 0, "artifact", "", false, false], [15, 15, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["IAI", "ist", "der", "weltweit", "gr\u00f6\u00dfte", "Hersteller", "von", "kartesischen", "Koordinatenrobotern", "und", "f\u00fchrend", "bei", "kosteng\u00fcnstigen", ",", "leistungsstarken", "SCARA-Robotern", "."], "sentence-detokenized": "IAI ist der weltweit gr\u00f6\u00dfte Hersteller von kartesischen Koordinatenrobotern und f\u00fchrend bei kosteng\u00fcnstigen, leistungsstarken SCARA-Robotern.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 20], [21, 27], [28, 38], [39, 42], [43, 55], [56, 75], [76, 79], [80, 87], [88, 91], [92, 107], [107, 108], [109, 125], [126, 140], [140, 141]]}
{"doc_key": "ai-dev-298", "ner": [[9, 10, "field"], [12, 13, "field"], [15, 16, "field"], [18, 18, "field"], [20, 21, "field"], [23, 23, "field"], [25, 25, "field"], [27, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [], "relations_mapping_to_source": [], "sentence": ["Die", "formale", "Konzeptanalyse", "findet", "praktische", "Anwendung", "in", "Bereichen", "wie", "Data", "Mining", ",", "Text", "Mining", ",", "maschinelles", "Lernen", ",", "Wissensmanagement", ",", "semantisches", "Web", ",", "Softwareentwicklung", ",", "Chemie", "und", "Biologie", "."], "sentence-detokenized": "Die formale Konzeptanalyse findet praktische Anwendung in Bereichen wie Data Mining, Text Mining, maschinelles Lernen, Wissensmanagement, semantisches Web, Softwareentwicklung, Chemie und Biologie.", "token2charspan": [[0, 3], [4, 11], [12, 26], [27, 33], [34, 44], [45, 54], [55, 57], [58, 67], [68, 71], [72, 76], [77, 83], [83, 84], [85, 89], [90, 96], [96, 97], [98, 110], [111, 117], [117, 118], [119, 136], [136, 137], [138, 150], [151, 154], [154, 155], [156, 175], [175, 176], [177, 183], [184, 187], [188, 196], [196, 197]]}
{"doc_key": "ai-dev-299", "ner": [[2, 2, "field"], [5, 6, "field"], [11, 11, "field"], [16, 17, "field"], [30, 31, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 16, 17, "part-of", "", false, false], [5, 6, 30, 31, "topic", "", false, false], [11, 11, 5, 6, "named", "", false, false], [16, 17, 2, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "der", "Informatik", "ist", "die", "computergest\u00fctzte", "Lerntheorie", "(", "oder", "einfach", "nur", "Lerntheorie", ")", "ein", "Teilgebiet", "der", "k\u00fcnstlichen", "Intelligenz", ",", "das", "sich", "mit", "dem", "Entwurf", "und", "der", "Analyse", "von", "Algorithmen", "f\u00fcr", "maschinelles", "Lernen", "befasst", "."], "sentence-detokenized": "In der Informatik ist die computergest\u00fctzte Lerntheorie (oder einfach nur Lerntheorie) ein Teilgebiet der k\u00fcnstlichen Intelligenz, das sich mit dem Entwurf und der Analyse von Algorithmen f\u00fcr maschinelles Lernen befasst.", "token2charspan": [[0, 2], [3, 6], [7, 17], [18, 21], [22, 25], [26, 43], [44, 55], [56, 57], [57, 61], [62, 69], [70, 73], [74, 85], [85, 86], [87, 90], [91, 101], [102, 105], [106, 117], [118, 129], [129, 130], [131, 134], [135, 139], [140, 143], [144, 147], [148, 155], [156, 159], [160, 163], [164, 171], [172, 175], [176, 187], [188, 191], [192, 204], [205, 211], [212, 219], [219, 220]]}
{"doc_key": "ai-dev-300", "ner": [[0, 1, "algorithm"], [3, 3, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Collaborative", "Filtering", "(", "CF", ")", "ist", "eine", "Technik", ",", "die", "in", "Empfehlungssystemen", "eingesetzt", "wird", "."], "sentence-detokenized": "Collaborative Filtering (CF) ist eine Technik, die in Empfehlungssystemen eingesetzt wird.", "token2charspan": [[0, 13], [14, 23], [24, 25], [25, 27], [27, 28], [29, 32], [33, 37], [38, 45], [45, 46], [47, 50], [51, 53], [54, 73], [74, 84], [85, 89], [89, 90]]}
{"doc_key": "ai-dev-301", "ner": [[1, 1, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Die", "FALSCH-positiv-Rate", "ist", "der", "Anteil", "aller", "Negativtests", ",", "die", "noch", "zu", "positiven", "Testergebnissen", "f\u00fchren", ",", "d.", "h.", "die", "bedingte", "Wahrscheinlichkeit", "eines", "positiven", "Testergebnisses", "bei", "einem", "nicht", "vorhandenen", "Ereignis", "."], "sentence-detokenized": "Die FALSCH-positiv-Rate ist der Anteil aller Negativtests, die noch zu positiven Testergebnissen f\u00fchren, d. h. die bedingte Wahrscheinlichkeit eines positiven Testergebnisses bei einem nicht vorhandenen Ereignis.", "token2charspan": [[0, 3], [4, 23], [24, 27], [28, 31], [32, 38], [39, 44], [45, 57], [57, 58], [59, 62], [63, 67], [68, 70], [71, 80], [81, 96], [97, 103], [103, 104], [105, 107], [108, 110], [111, 114], [115, 123], [124, 142], [143, 148], [149, 158], [159, 174], [175, 178], [179, 184], [185, 190], [191, 202], [203, 211], [211, 212]]}
{"doc_key": "ai-dev-302", "ner": [[1, 14, "misc"], [37, 37, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 14, 37, 37, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "VLDB", "'8", ":", "Proceedings", "of", "the", "34th", "International", "Conference", "on", "Very", "Large", "Data", "Bases", ",", "pages", "422--433.", "zeigte", ",", "dass", "die", "angegebenen", "Werte", "f\u00fcr", "mathC", "/", "math", "und", "mathK", "/", "math", "im", "Allgemeinen", "eine", "relativ", "geringe", "Genauigkeit", "der", "iterativ", "berechneten", "SimRank-Scores", "bedeuten", "."], "sentence-detokenized": "In VLDB '8: Proceedings of the 34th International Conference on Very Large Data Bases, pages 422--433. zeigte, dass die angegebenen Werte f\u00fcr mathC / math und mathK / math im Allgemeinen eine relativ geringe Genauigkeit der iterativ berechneten SimRank-Scores bedeuten.", "token2charspan": [[0, 2], [3, 7], [8, 10], [10, 11], [12, 23], [24, 26], [27, 30], [31, 35], [36, 49], [50, 60], [61, 63], [64, 68], [69, 74], [75, 79], [80, 85], [85, 86], [87, 92], [93, 102], [103, 109], [109, 110], [111, 115], [116, 119], [120, 131], [132, 137], [138, 141], [142, 147], [148, 149], [150, 154], [155, 158], [159, 164], [165, 166], [167, 171], [172, 174], [175, 186], [187, 191], [192, 199], [200, 207], [208, 219], [220, 223], [224, 232], [233, 244], [245, 259], [260, 268], [268, 269]]}
{"doc_key": "ai-dev-303", "ner": [[5, 5, "misc"], [6, 6, "misc"], [11, 12, "person"], [14, 16, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 5, 5, "general-affiliation", "", false, false], [6, 6, 11, 12, "artifact", "", false, false], [6, 6, 14, 16, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Im", "Juni", "2015", "wurde", "das", "Science-Fiction-Drama", "Sense8", "uraufgef\u00fchrt", ",", "das", "von", "den", "Wachowskis", "und", "J.", "Michael", "Straczynski", "geschrieben", "und", "produziert", "wurde", "."], "sentence-detokenized": "Im Juni 2015 wurde das Science-Fiction-Drama Sense8 uraufgef\u00fchrt, das von den Wachowskis und J. Michael Straczynski geschrieben und produziert wurde.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 18], [19, 22], [23, 44], [45, 51], [52, 64], [64, 65], [66, 69], [70, 73], [74, 77], [78, 88], [89, 92], [93, 95], [96, 103], [104, 115], [116, 127], [128, 131], [132, 142], [143, 148], [148, 149]]}
{"doc_key": "ai-dev-304", "ner": [[1, 1, "misc"], [5, 5, "product"], [21, 22, "misc"], [29, 29, "country"], [31, 31, "country"], [33, 33, "country"], [35, 35, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 1, 5, 5, "topic", "", false, false], [29, 29, 21, 22, "type-of", "", false, false], [31, 31, 21, 22, "type-of", "", false, false], [33, 33, 21, 22, "type-of", "", false, false], [35, 35, 21, 22, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Obwohl", "Eurotra", "nie", "ein", "funktionierendes", "M\u00dc-System", "lieferte", ",", "hatte", "das", "Projekt", "langfristig", "einen", "weitreichenden", "Einfluss", "auf", "die", "entstehenden", "Sprachindustrien", "in", "den", "europ\u00e4ischen", "Mitgliedsstaaten", ",", "insbesondere", "in", "den", "s\u00fcdlichen", "L\u00e4ndern", "Griechenland", ",", "Italien", ",", "Spanien", "und", "Portugal", "."], "sentence-detokenized": "Obwohl Eurotra nie ein funktionierendes M\u00dc-System lieferte, hatte das Projekt langfristig einen weitreichenden Einfluss auf die entstehenden Sprachindustrien in den europ\u00e4ischen Mitgliedsstaaten, insbesondere in den s\u00fcdlichen L\u00e4ndern Griechenland, Italien, Spanien und Portugal.", "token2charspan": [[0, 6], [7, 14], [15, 18], [19, 22], [23, 39], [40, 49], [50, 58], [58, 59], [60, 65], [66, 69], [70, 77], [78, 89], [90, 95], [96, 110], [111, 119], [120, 123], [124, 127], [128, 140], [141, 157], [158, 160], [161, 164], [165, 177], [178, 194], [194, 195], [196, 208], [209, 211], [212, 215], [216, 225], [226, 233], [234, 246], [246, 247], [248, 255], [255, 256], [257, 264], [265, 268], [269, 277], [277, 278]]}
{"doc_key": "ai-dev-305", "ner": [[0, 2, "algorithm"], [6, 7, "task"], [15, 17, "task"], [19, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 7, 0, 2, "usage", "", true, false], [15, 17, 6, 7, "named", "", false, false], [19, 22, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Der", "Autoencoder", "wurde", "erfolgreich", "bei", "der", "maschinellen", "\u00dcbersetzung", "menschlicher", "Sprachen", "eingesetzt", ",", "die", "gew\u00f6hnlich", "als", "neuronale", "maschinelle", "\u00dcbersetzung", "(", "NMT", ")", "bezeichnet", "wird", "."], "sentence-detokenized": "Der Autoencoder wurde erfolgreich bei der maschinellen \u00dcbersetzung menschlicher Sprachen eingesetzt, die gew\u00f6hnlich als neuronale maschinelle \u00dcbersetzung (NMT) bezeichnet wird.", "token2charspan": [[0, 3], [4, 15], [16, 21], [22, 33], [34, 37], [38, 41], [42, 54], [55, 66], [67, 79], [80, 88], [89, 99], [99, 100], [101, 104], [105, 115], [116, 119], [120, 129], [130, 141], [142, 153], [154, 155], [155, 158], [158, 159], [160, 170], [171, 175], [175, 176]]}
{"doc_key": "ai-dev-306", "ner": [[12, 12, "metrics"], [15, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Beliebte", "Beispiele", "f\u00fcr", "Fitnessfunktionen", ",", "die", "auf", "Wahrscheinlichkeiten", "basieren", ",", "sind", "die", "Maximum-Likelihood-Sch\u00e4tzung", "und", "der", "Scharnierverlust", "."], "sentence-detokenized": "Beliebte Beispiele f\u00fcr Fitnessfunktionen, die auf Wahrscheinlichkeiten basieren, sind die Maximum-Likelihood-Sch\u00e4tzung und der Scharnierverlust.", "token2charspan": [[0, 8], [9, 18], [19, 22], [23, 40], [40, 41], [42, 45], [46, 49], [50, 70], [71, 79], [79, 80], [81, 85], [86, 89], [90, 118], [119, 122], [123, 126], [127, 143], [143, 144]]}
{"doc_key": "ai-dev-307", "ner": [[0, 1, "field"], [11, 12, "task"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 0, 1, "part-of", "", false, false], [14, 15, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Data", "Mining", "ist", "ein", "verwandtes", "Studiengebiet", ",", "das", "sich", "auf", "die", "explorative", "Datenanalyse", "durch", "un\u00fcberwachtes", "Lernen", "konzentriert", "."], "sentence-detokenized": "Data Mining ist ein verwandtes Studiengebiet, das sich auf die explorative Datenanalyse durch un\u00fcberwachtes Lernen konzentriert.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 19], [20, 30], [31, 44], [44, 45], [46, 49], [50, 54], [55, 58], [59, 62], [63, 74], [75, 87], [88, 93], [94, 107], [108, 114], [115, 127], [127, 128]]}
{"doc_key": "ai-dev-308", "ner": [[0, 2, "algorithm"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 16, 16, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Die", "kollaborative", "Filterung", "umfasst", "Techniken", "zum", "Abgleich", "von", "Personen", "mit", "\u00e4hnlichen", "Interessen", "und", "zur", "Erstellung", "von", "Empfehlungssystemen", "auf", "dieser", "Grundlage", "."], "sentence-detokenized": "Die kollaborative Filterung umfasst Techniken zum Abgleich von Personen mit \u00e4hnlichen Interessen und zur Erstellung von Empfehlungssystemen auf dieser Grundlage.", "token2charspan": [[0, 3], [4, 17], [18, 27], [28, 35], [36, 45], [46, 49], [50, 58], [59, 62], [63, 71], [72, 75], [76, 85], [86, 96], [97, 100], [101, 104], [105, 115], [116, 119], [120, 139], [140, 143], [144, 150], [151, 160], [160, 161]]}
{"doc_key": "ai-dev-309", "ner": [[3, 4, "algorithm"], [10, 13, "product"]], "ner_mapping_to_source": [0, 2], "relations": [[10, 13, 3, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Eine", "Reihe", "von", "WordNet-basierten", "Wort\u00e4hnlichkeitsalgorithmen", "sind", "in", "einem", "Perl-Paket", "namens", "WordNet", ":", ":", "Similarity", "implementiert", "."], "sentence-detokenized": "Eine Reihe von WordNet-basierten Wort\u00e4hnlichkeitsalgorithmen sind in einem Perl-Paket namens WordNet:: Similarity implementiert.", "token2charspan": [[0, 4], [5, 10], [11, 14], [15, 32], [33, 60], [61, 65], [66, 68], [69, 74], [75, 85], [86, 92], [93, 100], [100, 101], [101, 102], [103, 113], [114, 127], [127, 128]]}
{"doc_key": "ai-dev-310", "ner": [[7, 7, "conference"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[10, 11, 7, 7, "temporal", "", false, false], [13, 14, 7, 7, "temporal", "", false, false], [16, 17, 7, 7, "temporal", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Ein", "weiteres", "Papier", ",", "das", "auf", "der", "CVPR", "2000", "von", "Erik", "Miller", ",", "Nicholas", "Matsakis", "und", "Paul", "Viola", "vorgestellt", "wurde", ",", "wird", "ebenfalls", "besprochen", "."], "sentence-detokenized": "Ein weiteres Papier, das auf der CVPR 2000 von Erik Miller, Nicholas Matsakis und Paul Viola vorgestellt wurde, wird ebenfalls besprochen.", "token2charspan": [[0, 3], [4, 12], [13, 19], [19, 20], [21, 24], [25, 28], [29, 32], [33, 37], [38, 42], [43, 46], [47, 51], [52, 58], [58, 59], [60, 68], [69, 77], [78, 81], [82, 86], [87, 92], [93, 104], [105, 110], [110, 111], [112, 116], [117, 126], [127, 137], [137, 138]]}
{"doc_key": "ai-dev-311", "ner": [[0, 0, "algorithm"], [8, 8, "misc"], [13, 13, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 13, 13, "compare", "", false, false], [13, 13, 8, 8, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["QC", "wurde", "nicht", "im", "Vergleich", "zu", "traditionellen", "modernen", "Clustering-Algorithmen", "bewertet", ",", "abgesehen", "vom", "Jaccard-Index", "."], "sentence-detokenized": "QC wurde nicht im Vergleich zu traditionellen modernen Clustering-Algorithmen bewertet, abgesehen vom Jaccard-Index.", "token2charspan": [[0, 2], [3, 8], [9, 14], [15, 17], [18, 27], [28, 30], [31, 45], [46, 54], [55, 77], [78, 86], [86, 87], [88, 97], [98, 101], [102, 115], [115, 116]]}
{"doc_key": "ai-dev-312", "ner": [[2, 6, "misc"], [12, 15, "misc"], [9, 10, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 15, 2, 6, "physical", "", false, false], [12, 15, 9, 10, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["W\u00e4hrend", "der", "VEX", "Robotics", "World", "Championship", "findet", "in", "der", "Freedom", "Hall", "eine", "Parade", "der", "Nationen", "statt", ",", "an", "der", "Hunderte", "von", "Sch\u00fclern", "aus", "mehr", "als", "30", "L\u00e4ndern", "teilnehmen", "."], "sentence-detokenized": "W\u00e4hrend der VEX Robotics World Championship findet in der Freedom Hall eine Parade der Nationen statt, an der Hunderte von Sch\u00fclern aus mehr als 30 L\u00e4ndern teilnehmen.", "token2charspan": [[0, 7], [8, 11], [12, 15], [16, 24], [25, 30], [31, 43], [44, 50], [51, 53], [54, 57], [58, 65], [66, 70], [71, 75], [76, 82], [83, 86], [87, 95], [96, 101], [101, 102], [103, 105], [106, 109], [110, 118], [119, 122], [123, 131], [132, 135], [136, 140], [141, 144], [145, 147], [148, 155], [156, 166], [166, 167]]}
{"doc_key": "ai-dev-313", "ner": [[7, 7, "metrics"], [9, 9, "metrics"], [13, 13, "metrics"], [15, 15, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 7, 7, "named", "", false, false], [15, 15, 13, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Weitere", "Ma\u00dfst\u00e4be", "f\u00fcr", "die", "Genauigkeit", "sind", "die", "Einzelwortfehlerrate", "(", "SWER", ")", "und", "die", "Befehlserfolgsrate", "(", "CSR", ")", "."], "sentence-detokenized": "Weitere Ma\u00dfst\u00e4be f\u00fcr die Genauigkeit sind die Einzelwortfehlerrate (SWER) und die Befehlserfolgsrate (CSR).", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 24], [25, 36], [37, 41], [42, 45], [46, 66], [67, 68], [68, 72], [72, 73], [74, 77], [78, 81], [82, 100], [101, 102], [102, 105], [105, 106], [106, 107]]}
{"doc_key": "ai-dev-314", "ner": [[8, 9, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sie", "stellten", "ihre", "Methode", "und", "Ergebnisse", "auf", "der", "SIGGRAPH", "2000", "vor", "."], "sentence-detokenized": "Sie stellten ihre Methode und Ergebnisse auf der SIGGRAPH 2000 vor.", "token2charspan": [[0, 3], [4, 12], [13, 17], [18, 25], [26, 29], [30, 40], [41, 44], [45, 48], [49, 57], [58, 62], [63, 66], [66, 67]]}
{"doc_key": "ai-dev-315", "ner": [[1, 1, "conference"], [8, 12, "misc"], [16, 16, "conference"], [25, 27, "researcher"], [31, 34, "researcher"], [38, 40, "conference"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Die", "KDD-Konferenz", "entwickelte", "sich", "aus", "den", "KDD-Workshops", "(", "Knowledge", "Discovery", "and", "Data", "Mining", ")", "auf", "den", "AAAI-Konferenzen", ",", "die", "1989", ",", "1991", "und", "1993", "von", "Gregory", "I.", "Piatetsky-Shapiro", "und", "1994", "von", "Usama", "Fayyad", "ins", "Leben", "gerufen", "wurden", ".", "Machinery", "|", "ACM", "."], "sentence-detokenized": "Die KDD-Konferenz entwickelte sich aus den KDD-Workshops (Knowledge Discovery and Data Mining) auf den AAAI-Konferenzen, die 1989, 1991 und 1993 von Gregory I. Piatetsky-Shapiro und 1994 von Usama Fayyad ins Leben gerufen wurden. Machinery | ACM.", "token2charspan": [[0, 3], [4, 17], [18, 29], [30, 34], [35, 38], [39, 42], [43, 56], [57, 58], [58, 67], [68, 77], [78, 81], [82, 86], [87, 93], [93, 94], [95, 98], [99, 102], [103, 119], [119, 120], [121, 124], [125, 129], [129, 130], [131, 135], [136, 139], [140, 144], [145, 148], [149, 156], [157, 159], [160, 177], [178, 181], [182, 186], [187, 190], [191, 196], [197, 203], [204, 207], [208, 213], [214, 221], [222, 228], [228, 229], [230, 239], [240, 241], [242, 245], [245, 246]]}
{"doc_key": "ai-dev-316", "ner": [[5, 8, "conference"], [10, 10, "conference"], [14, 19, "organisation"], [21, 21, "organisation"], [25, 29, "conference"], [31, 31, "conference"], [35, 41, "conference"], [43, 43, "conference"], [47, 52, "conference"], [54, 54, "conference"], [58, 63, "conference"], [65, 65, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[10, 10, 5, 8, "named", "", false, false], [21, 21, 14, 19, "named", "", false, false], [31, 31, 25, 29, "named", "", false, false], [43, 43, 35, 41, "named", "", false, false], [54, 54, 47, 52, "named", "", false, false], [65, 65, 58, 63, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Er", "wurde", "zum", "Fellow", "der", "Association", "for", "Computing", "Machinery", "(", "ACM", ")", ",", "des", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", ",", "der", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", ",", "der", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", ",", "der", "American", "Association", "for", "Advancement", "of", "Science", "(", "AAAS", ")", "und", "der", "Society", "for", "Optics", "and", "Photonics", "Technology", "(", "SPIE", ")", "gew\u00e4hlt", "."], "sentence-detokenized": "Er wurde zum Fellow der Association for Computing Machinery (ACM), des Institute of Electrical and Electronics Engineers (IEEE), der International Association for Pattern Recognition (IAPR), der Association for the Advancement of Artificial Intelligence (AAAI), der American Association for Advancement of Science (AAAS) und der Society for Optics and Photonics Technology (SPIE) gew\u00e4hlt.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 19], [20, 23], [24, 35], [36, 39], [40, 49], [50, 59], [60, 61], [61, 64], [64, 65], [65, 66], [67, 70], [71, 80], [81, 83], [84, 94], [95, 98], [99, 110], [111, 120], [121, 122], [122, 126], [126, 127], [127, 128], [129, 132], [133, 146], [147, 158], [159, 162], [163, 170], [171, 182], [183, 184], [184, 188], [188, 189], [189, 190], [191, 194], [195, 206], [207, 210], [211, 214], [215, 226], [227, 229], [230, 240], [241, 253], [254, 255], [255, 259], [259, 260], [260, 261], [262, 265], [266, 274], [275, 286], [287, 290], [291, 302], [303, 305], [306, 313], [314, 315], [315, 319], [319, 320], [321, 324], [325, 328], [329, 336], [337, 340], [341, 347], [348, 351], [352, 361], [362, 372], [373, 374], [374, 378], [378, 379], [380, 387], [387, 388]]}
{"doc_key": "ai-dev-317", "ner": [[0, 1, "field"], [3, 4, "field"], [17, 18, "field"], [41, 42, "field"], [61, 63, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 17, 18, "named", "", false, false], [3, 4, 41, 42, "named", "", false, false], [41, 42, 61, 63, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Maschinelles", "Lernen", "und", "Data", "Mining", "verwenden", "h\u00e4ufig", "dieselben", "Methoden", "und", "\u00fcberschneiden", "sich", "erheblich", ".", "W\u00e4hrend", "sich", "das", "maschinelle", "Lernen", "jedoch", "auf", "Vorhersagen", "konzentriert", ",", "die", "auf", "bekannten", "Eigenschaften", "beruhen", ",", "die", "aus", "den", "Trainingsdaten", "gelernt", "wurden", ",", "liegt", "der", "Schwerpunkt", "beim", "Data", "Mining", "auf", "der", "Entdeckung", "von", "(", "zuvor", ")", "unbekannten", "Eigenschaften", "in", "den", "Daten", "(", "dies", "ist", "der", "Analyseschritt", "der", "Wissensentdeckung", "in", "Datenbanken", ")", "."], "sentence-detokenized": "Maschinelles Lernen und Data Mining verwenden h\u00e4ufig dieselben Methoden und \u00fcberschneiden sich erheblich. W\u00e4hrend sich das maschinelle Lernen jedoch auf Vorhersagen konzentriert, die auf bekannten Eigenschaften beruhen, die aus den Trainingsdaten gelernt wurden, liegt der Schwerpunkt beim Data Mining auf der Entdeckung von (zuvor) unbekannten Eigenschaften in den Daten (dies ist der Analyseschritt der Wissensentdeckung in Datenbanken).", "token2charspan": [[0, 12], [13, 19], [20, 23], [24, 28], [29, 35], [36, 45], [46, 52], [53, 62], [63, 71], [72, 75], [76, 89], [90, 94], [95, 104], [104, 105], [106, 113], [114, 118], [119, 122], [123, 134], [135, 141], [142, 148], [149, 152], [153, 164], [165, 177], [177, 178], [179, 182], [183, 186], [187, 196], [197, 210], [211, 218], [218, 219], [220, 223], [224, 227], [228, 231], [232, 246], [247, 254], [255, 261], [261, 262], [263, 268], [269, 272], [273, 284], [285, 289], [290, 294], [295, 301], [302, 305], [306, 309], [310, 320], [321, 324], [325, 326], [326, 331], [331, 332], [333, 344], [345, 358], [359, 361], [362, 365], [366, 371], [372, 373], [373, 377], [378, 381], [382, 385], [386, 400], [401, 404], [405, 422], [423, 425], [426, 437], [437, 438], [438, 439]]}
{"doc_key": "ai-dev-318", "ner": [[0, 0, "product"], [3, 3, "programlang"], [12, 12, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 3, 3, "general-affiliation", "", false, false], [0, 0, 3, 3, "related-to", "runs_on", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Indy", "ist", "in", "Java", "geschrieben", "und", "l\u00e4uft", "daher", "auf", "den", "meisten", "modernen", "Betriebssystemen", "."], "sentence-detokenized": "Indy ist in Java geschrieben und l\u00e4uft daher auf den meisten modernen Betriebssystemen.", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 16], [17, 28], [29, 32], [33, 38], [39, 44], [45, 48], [49, 52], [53, 60], [61, 69], [70, 86], [86, 87]]}
{"doc_key": "ai-dev-319", "ner": [[0, 1, "algorithm"], [6, 8, "algorithm"], [10, 10, "algorithm"], [16, 16, "algorithm"], [18, 18, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 6, 8, "type-of", "", true, false], [10, 10, 6, 8, "named", "", false, false], [16, 16, 6, 8, "type-of", "", true, false], [18, 18, 16, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Die", "NMF", "ist", "eine", "Instanz", "der", "nichtnegativen", "quadratischen", "Programmierung", "(", "NQP", ")", ",", "genau", "wie", "die", "Support-Vektor-Maschine", "(", "SVM", ")", "."], "sentence-detokenized": "Die NMF ist eine Instanz der nichtnegativen quadratischen Programmierung (NQP), genau wie die Support-Vektor-Maschine (SVM).", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 16], [17, 24], [25, 28], [29, 43], [44, 57], [58, 72], [73, 74], [74, 77], [77, 78], [78, 79], [80, 85], [86, 89], [90, 93], [94, 117], [118, 119], [119, 122], [122, 123], [123, 124]]}
{"doc_key": "ai-dev-320", "ner": [[7, 8, "misc"], [12, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 12, 12, "usage", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Die", "Methode", "basiert", "auf", "der", "Sch\u00e4tzung", "der", "bedingten", "Wahrscheinlichkeiten", "unter", "Verwendung", "der", "nichtparametrischen", "Maximum-Likelihood-Methode", ",", "die", "zu", "folgenden", "Ergebnissen", "f\u00fchrt"], "sentence-detokenized": "Die Methode basiert auf der Sch\u00e4tzung der bedingten Wahrscheinlichkeiten unter Verwendung der nichtparametrischen Maximum-Likelihood-Methode, die zu folgenden Ergebnissen f\u00fchrt", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 23], [24, 27], [28, 37], [38, 41], [42, 51], [52, 72], [73, 78], [79, 89], [90, 93], [94, 113], [114, 140], [140, 141], [142, 145], [146, 148], [149, 158], [159, 170], [171, 176]]}
{"doc_key": "ai-dev-321", "ner": [[7, 7, "algorithm"], [9, 9, "algorithm"], [11, 13, "metrics"], [15, 15, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Zu", "den", "grundlegenden", "Konzepten", "der", "Spektralsch\u00e4tzung", "geh\u00f6ren", "Autokorrelation", ",", "Multi-D-Fourier-Transformation", ",", "mittlerer", "quadratischer", "Fehler", "und", "Entropie", "."], "sentence-detokenized": "Zu den grundlegenden Konzepten der Spektralsch\u00e4tzung geh\u00f6ren Autokorrelation, Multi-D-Fourier-Transformation, mittlerer quadratischer Fehler und Entropie.", "token2charspan": [[0, 2], [3, 6], [7, 20], [21, 30], [31, 34], [35, 52], [53, 60], [61, 76], [76, 77], [78, 108], [108, 109], [110, 119], [120, 133], [134, 140], [141, 144], [145, 153], [153, 154]]}
{"doc_key": "ai-dev-322", "ner": [[3, 3, "algorithm"], [8, 8, "field"], [10, 10, "algorithm"], [12, 13, "algorithm"], [15, 15, "task"], [17, 17, "field"], [19, 19, "field"], [21, 21, "task"], [23, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 3, 8, 8, "part-of", "", false, false], [3, 3, 10, 10, "part-of", "", false, false], [3, 3, 12, 13, "part-of", "", false, false], [3, 3, 15, 15, "part-of", "", false, false], [3, 3, 17, 17, "part-of", "", false, false], [3, 3, 19, 19, "part-of", "", false, false], [3, 3, 21, 21, "part-of", "", false, false], [3, 3, 23, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Die", "Anwendungsbereiche", "von", "Kernel-Methoden", "sind", "vielf\u00e4ltig", "und", "umfassen", "Geostatistik", ",", "Kriging", ",", "inverse", "Distanzgewichtung", ",", "3D-Rekonstruktion", ",", "Bioinformatik", ",", "Chemoinformatik", ",", "Informationsextraktion", "und", "Handschrifterkennung", "."], "sentence-detokenized": "Die Anwendungsbereiche von Kernel-Methoden sind vielf\u00e4ltig und umfassen Geostatistik, Kriging, inverse Distanzgewichtung, 3D-Rekonstruktion, Bioinformatik, Chemoinformatik, Informationsextraktion und Handschrifterkennung.", "token2charspan": [[0, 3], [4, 22], [23, 26], [27, 42], [43, 47], [48, 58], [59, 62], [63, 71], [72, 84], [84, 85], [86, 93], [93, 94], [95, 102], [103, 120], [120, 121], [122, 139], [139, 140], [141, 154], [154, 155], [156, 171], [171, 172], [173, 195], [196, 199], [200, 220], [220, 221]]}
{"doc_key": "ai-dev-323", "ner": [[12, 16, "product"], [18, 18, "product"], [22, 26, "product"], [28, 28, "product"], [33, 33, "product"], [35, 36, "product"], [38, 38, "product"], [40, 40, "product"], [44, 44, "product"], [46, 46, "product"], [48, 51, "product"], [54, 56, "product"]], "ner_mapping_to_source": [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[12, 16, 33, 33, "compare", "", false, false], [12, 16, 35, 36, "compare", "", false, false], [12, 16, 38, 38, "compare", "", false, false], [12, 16, 40, 40, "compare", "", false, false], [12, 16, 44, 44, "compare", "", false, false], [12, 16, 46, 46, "compare", "", false, false], [12, 16, 48, 51, "compare", "", false, false], [12, 16, 54, 56, "compare", "", false, false], [18, 18, 12, 16, "named", "", false, false], [22, 26, 33, 33, "compare", "", false, false], [22, 26, 35, 36, "compare", "", false, false], [22, 26, 38, 38, "compare", "", false, false], [22, 26, 40, 40, "compare", "", false, false], [22, 26, 44, 44, "compare", "", false, false], [22, 26, 46, 46, "compare", "", false, false], [22, 26, 48, 51, "compare", "", false, false], [22, 26, 54, 56, "compare", "", false, false], [28, 28, 22, 26, "named", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19], "sentence": ["Roboter", "k\u00f6nnen", "autonom", "oder", "teilautonom", "sein", "und", "reichen", "von", "Humanoiden", "wie", "Hondas", "Advanced", "Step", "in", "Innovative", "Mobility", "(", "ASIMO", ")", "und", "TOSYs", "TOSY", "Ping", "Pong", "Playing", "Robot", "(", "TOPIO", ")", "bis", "hin", "zu", "Industrierobotern", ",", "medizinischen", "Operationsrobotern", ",", "Patientenhilfsrobotern", ",", "Hundetherapierobotern", ",", "kollektiv", "programmierten", "Schwarmrobotern", ",", "UAV-Drohnen", "wie", "General", "Atomics", "MQ-1", "Predator", "und", "sogar", "mikroskopisch", "kleinen", "Nanorobotern", "."], "sentence-detokenized": "Roboter k\u00f6nnen autonom oder teilautonom sein und reichen von Humanoiden wie Hondas Advanced Step in Innovative Mobility (ASIMO) und TOSYs TOSY Ping Pong Playing Robot (TOPIO) bis hin zu Industrierobotern, medizinischen Operationsrobotern, Patientenhilfsrobotern, Hundetherapierobotern, kollektiv programmierten Schwarmrobotern, UAV-Drohnen wie General Atomics MQ-1 Predator und sogar mikroskopisch kleinen Nanorobotern.", "token2charspan": [[0, 7], [8, 14], [15, 22], [23, 27], [28, 39], [40, 44], [45, 48], [49, 56], [57, 60], [61, 71], [72, 75], [76, 82], [83, 91], [92, 96], [97, 99], [100, 110], [111, 119], [120, 121], [121, 126], [126, 127], [128, 131], [132, 137], [138, 142], [143, 147], [148, 152], [153, 160], [161, 166], [167, 168], [168, 173], [173, 174], [175, 178], [179, 182], [183, 185], [186, 203], [203, 204], [205, 218], [219, 237], [237, 238], [239, 261], [261, 262], [263, 284], [284, 285], [286, 295], [296, 310], [311, 326], [326, 327], [328, 339], [340, 343], [344, 351], [352, 359], [360, 364], [365, 373], [374, 377], [378, 383], [384, 397], [398, 405], [406, 418], [418, 419]]}
{"doc_key": "ai-dev-324", "ner": [[0, 0, "product"], [2, 3, "product"], [10, 15, "university"], [17, 18, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 27, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 17, 18, "artifact", "", false, false], [0, 0, 20, 21, "artifact", "", false, false], [0, 0, 23, 24, "artifact", "", false, false], [0, 0, 26, 27, "artifact", "", false, false], [2, 3, 17, 18, "artifact", "", false, false], [2, 3, 20, 21, "artifact", "", false, false], [2, 3, 23, 24, "artifact", "", false, false], [2, 3, 26, 27, "artifact", "", false, false], [17, 18, 10, 15, "physical", "", false, false], [20, 21, 10, 15, "physical", "", false, false], [23, 24, 10, 15, "physical", "", false, false], [26, 27, 10, 15, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Freddy", "und", "Freddy", "II", "waren", "Roboter", ",", "die", "an", "der", "University", "of", "Edinburgh", "School", "of", "Informatics", "von", "Pat", "Ambler", ",", "Robin", "Popplestone", ",", "Austin", "Tate", "und", "Donald", "Mitchie", "gebaut", "wurden", "und", "in", "der", "Lage", "waren", ",", "Holzbl\u00f6cke", "in", "mehreren", "Stunden", "zusammenzusetzen", "."], "sentence-detokenized": "Freddy und Freddy II waren Roboter, die an der University of Edinburgh School of Informatics von Pat Ambler, Robin Popplestone, Austin Tate und Donald Mitchie gebaut wurden und in der Lage waren, Holzbl\u00f6cke in mehreren Stunden zusammenzusetzen.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 20], [21, 26], [27, 34], [34, 35], [36, 39], [40, 42], [43, 46], [47, 57], [58, 60], [61, 70], [71, 77], [78, 80], [81, 92], [93, 96], [97, 100], [101, 107], [107, 108], [109, 114], [115, 126], [126, 127], [128, 134], [135, 139], [140, 143], [144, 150], [151, 158], [159, 165], [166, 172], [173, 176], [177, 179], [180, 183], [184, 188], [189, 194], [194, 195], [196, 206], [207, 209], [210, 218], [219, 226], [227, 243], [243, 244]]}
{"doc_key": "ai-dev-325", "ner": [[5, 5, "location"], [7, 7, "country"], [18, 18, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 7, 7, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Seine", "Kindheit", "verbrachte", "er", "in", "Paris", ",", "Frankreich", ",", "wohin", "seine", "Eltern", "in", "den", "fr\u00fchen", "1920er", "Jahren", "aus", "Litauen", "emigriert", "waren", "."], "sentence-detokenized": "Seine Kindheit verbrachte er in Paris, Frankreich, wohin seine Eltern in den fr\u00fchen 1920er Jahren aus Litauen emigriert waren.", "token2charspan": [[0, 5], [6, 14], [15, 25], [26, 28], [29, 31], [32, 37], [37, 38], [39, 49], [49, 50], [51, 56], [57, 62], [63, 69], [70, 72], [73, 76], [77, 83], [84, 90], [91, 97], [98, 101], [102, 109], [110, 119], [120, 125], [125, 126]]}
{"doc_key": "ai-dev-326", "ner": [[2, 3, "researcher"], [5, 8, "misc"], [11, 14, "organisation"], [16, 18, "university"], [24, 26, "university"], [31, 32, "university"], [35, 37, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 3, 5, 8, "role", "", false, false], [2, 3, 16, 18, "physical", "", false, false], [2, 3, 24, 26, "role", "", false, false], [2, 3, 31, 32, "role", "", false, false], [2, 3, 35, 37, "role", "", false, false], [5, 8, 11, 14, "part-of", "", false, false], [11, 14, 16, 18, "part-of", "", false, false], [31, 32, 24, 26, "part-of", "", false, false], [35, 37, 24, 26, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Zuvor", "hatte", "Dr.", "Paulos", "den", "Cooper-Siegel", "Associate", "Professor", "Chair", "an", "der", "School", "of", "Computer", "Science", "der", "Carnegie", "Mellon", "University", "inne", ",", "wo", "er", "am", "Human-Computer", "Interaction", "Institute", "lehrte", "und", "Gastprofessuren", "am", "Robotics", "Institute", "und", "am", "Entertainment", "Technology", "Center", "innehatte", "."], "sentence-detokenized": "Zuvor hatte Dr. Paulos den Cooper-Siegel Associate Professor Chair an der School of Computer Science der Carnegie Mellon University inne, wo er am Human-Computer Interaction Institute lehrte und Gastprofessuren am Robotics Institute und am Entertainment Technology Center innehatte.", "token2charspan": [[0, 5], [6, 11], [12, 15], [16, 22], [23, 26], [27, 40], [41, 50], [51, 60], [61, 66], [67, 69], [70, 73], [74, 80], [81, 83], [84, 92], [93, 100], [101, 104], [105, 113], [114, 120], [121, 131], [132, 136], [136, 137], [138, 140], [141, 143], [144, 146], [147, 161], [162, 173], [174, 183], [184, 190], [191, 194], [195, 210], [211, 213], [214, 222], [223, 232], [233, 236], [237, 239], [240, 253], [254, 264], [265, 271], [272, 281], [281, 282]]}
{"doc_key": "ai-dev-327", "ner": [[2, 3, "researcher"], [6, 7, "university"], [9, 9, "product"], [13, 13, "product"], [17, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 6, 7, "physical", "", false, false], [2, 3, 6, 7, "role", "", false, false], [9, 9, 2, 3, "artifact", "", false, false], [9, 9, 13, 13, "type-of", "", false, false], [9, 9, 17, 17, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["1969", "erfand", "Victor", "Scheinman", "an", "der", "Stanford", "University", "den", "Stanford-Arm", ",", "einen", "vollelektrischen", "6-Achsen-Gelenkroboter", ",", "der", "eine", "Arml\u00f6sung", "erm\u00f6glichen", "sollte", "."], "sentence-detokenized": "1969 erfand Victor Scheinman an der Stanford University den Stanford-Arm, einen vollelektrischen 6-Achsen-Gelenkroboter, der eine Arml\u00f6sung erm\u00f6glichen sollte.", "token2charspan": [[0, 4], [5, 11], [12, 18], [19, 28], [29, 31], [32, 35], [36, 44], [45, 55], [56, 59], [60, 72], [72, 73], [74, 79], [80, 96], [97, 119], [119, 120], [121, 124], [125, 129], [130, 139], [140, 151], [152, 158], [158, 159]]}
{"doc_key": "ai-dev-328", "ner": [[5, 5, "product"], [15, 16, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 15, 16, "related-to", "", false, false], [5, 5, 18, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Die", "Erstellung", "und", "Implementierung", "von", "Chatbots", "ist", "immer", "noch", "ein", "Entwicklungsbereich", ",", "der", "stark", "mit", "k\u00fcnstlicher", "Intelligenz", "und", "maschinellem", "Lernen", "zusammenh\u00e4ngt", ",", "so", "dass", "die", "bereitgestellten", "L\u00f6sungen", "zwar", "offensichtliche", "Vorteile", "aufweisen", ",", "aber", "auch", "einige", "wichtige", "Einschr\u00e4nkungen", "in", "Bezug", "auf", "Funktionen", "und", "Anwendungsf\u00e4lle", "."], "sentence-detokenized": "Die Erstellung und Implementierung von Chatbots ist immer noch ein Entwicklungsbereich, der stark mit k\u00fcnstlicher Intelligenz und maschinellem Lernen zusammenh\u00e4ngt, so dass die bereitgestellten L\u00f6sungen zwar offensichtliche Vorteile aufweisen, aber auch einige wichtige Einschr\u00e4nkungen in Bezug auf Funktionen und Anwendungsf\u00e4lle.", "token2charspan": [[0, 3], [4, 14], [15, 18], [19, 34], [35, 38], [39, 47], [48, 51], [52, 57], [58, 62], [63, 66], [67, 86], [86, 87], [88, 91], [92, 97], [98, 101], [102, 113], [114, 125], [126, 129], [130, 142], [143, 149], [150, 163], [163, 164], [165, 167], [168, 172], [173, 176], [177, 193], [194, 202], [203, 207], [208, 223], [224, 232], [233, 242], [242, 243], [244, 248], [249, 253], [254, 260], [261, 269], [270, 285], [286, 288], [289, 294], [295, 298], [299, 309], [310, 313], [314, 329], [329, 330]]}
{"doc_key": "ai-dev-329", "ner": [[11, 13, "university"], [9, 9, "product"], [21, 21, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 11, 13, "part-of", "", true, false], [21, 21, 9, 9, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Was", "frei", "verf\u00fcgbare", "Ressourcen", "betrifft", ",", "so", "ist", "das", "Sphinx-Toolkit", "der", "Carnegie", "Mellon", "University", "eine", "gute", "Anlaufstelle", ",", "um", "mehr", "\u00fcber", "Spracherkennung", "zu", "erfahren", "und", "mit", "dem", "Experimentieren", "zu", "beginnen", "."], "sentence-detokenized": "Was frei verf\u00fcgbare Ressourcen betrifft, so ist das Sphinx-Toolkit der Carnegie Mellon University eine gute Anlaufstelle, um mehr \u00fcber Spracherkennung zu erfahren und mit dem Experimentieren zu beginnen.", "token2charspan": [[0, 3], [4, 8], [9, 19], [20, 30], [31, 39], [39, 40], [41, 43], [44, 47], [48, 51], [52, 66], [67, 70], [71, 79], [80, 86], [87, 97], [98, 102], [103, 107], [108, 120], [120, 121], [122, 124], [125, 129], [130, 134], [135, 150], [151, 153], [154, 162], [163, 166], [167, 170], [171, 174], [175, 190], [191, 193], [194, 202], [202, 203]]}
{"doc_key": "ai-dev-330", "ner": [[2, 2, "misc"], [11, 17, "misc"], [19, 19, "misc"], [28, 28, "university"], [30, 30, "location"], [32, 32, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 11, 17, "temporal", "", false, false], [19, 19, 11, 17, "named", "", false, false], [19, 19, 30, 30, "physical", "", false, false], [28, 28, 19, 19, "role", "", false, false], [30, 30, 32, 32, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Dem", "offiziellen", "RoboCup-Wettbewerb", "ging", "das", "(", "oft", "nicht", "anerkannte", ")", "erste", "internationale", "Fu\u00dfballturnier", "um", "die", "Weltmeisterschaft", "der", "Mikroroboter", "(", "MIROSOT", ")", "voraus", ",", "das", "im", "November", "1996", "vom", "KAIST", "in", "Taejon", ",", "Korea", ",", "veranstaltet", "wurde", "."], "sentence-detokenized": "Dem offiziellen RoboCup-Wettbewerb ging das (oft nicht anerkannte) erste internationale Fu\u00dfballturnier um die Weltmeisterschaft der Mikroroboter (MIROSOT) voraus, das im November 1996 vom KAIST in Taejon, Korea, veranstaltet wurde.", "token2charspan": [[0, 3], [4, 15], [16, 34], [35, 39], [40, 43], [44, 45], [45, 48], [49, 54], [55, 65], [65, 66], [67, 72], [73, 87], [88, 102], [103, 105], [106, 109], [110, 127], [128, 131], [132, 144], [145, 146], [146, 153], [153, 154], [155, 161], [161, 162], [163, 166], [167, 169], [170, 178], [179, 183], [184, 187], [188, 193], [194, 196], [197, 203], [203, 204], [205, 210], [210, 211], [212, 224], [225, 230], [230, 231]]}
{"doc_key": "ai-dev-331", "ner": [[2, 2, "metrics"], [20, 20, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Zus\u00e4tzlich", "zur", "Standard-Scharnierverlustfunktion", "math", "(", "1-yf", "(", "x", ")", ")", "_", "+", "/", "math", "f\u00fcr", "beschriftete", "Daten", ",", "wird", "eine", "Verlustfunktion", "math", "(", "-1", "|", "f", "(x", ")", "|)", "(", "-1", "|", "f", "(x", ")", "|)", "_", "+", "/", "math", "f\u00fcr", "die", "nicht", "beschrifteten", "Daten", "eingef\u00fchrt", ",", "indem", "mathy", "=\\", "operatorname", "{", "sign", "}", "{", "f", "(x", ")", "}", "/", "math", "."], "sentence-detokenized": "Zus\u00e4tzlich zur Standard-Scharnierverlustfunktion math (1-yf (x)) _ + / math f\u00fcr beschriftete Daten, wird eine Verlustfunktion math (-1 | f (x) |) (-1 | f (x) |) _ + / math f\u00fcr die nicht beschrifteten Daten eingef\u00fchrt, indem mathy =\\ operatorname {sign} {f (x)} / math.", "token2charspan": [[0, 10], [11, 14], [15, 48], [49, 53], [54, 55], [55, 59], [60, 61], [61, 62], [62, 63], [63, 64], [65, 66], [67, 68], [69, 70], [71, 75], [76, 79], [80, 92], [93, 98], [98, 99], [100, 104], [105, 109], [110, 125], [126, 130], [131, 132], [132, 134], [135, 136], [137, 138], [139, 141], [141, 142], [143, 145], [146, 147], [147, 149], [150, 151], [152, 153], [154, 156], [156, 157], [158, 160], [161, 162], [163, 164], [165, 166], [167, 171], [172, 175], [176, 179], [180, 185], [186, 199], [200, 205], [206, 216], [216, 217], [218, 223], [224, 229], [230, 232], [233, 245], [246, 247], [247, 251], [251, 252], [253, 254], [254, 255], [256, 258], [258, 259], [259, 260], [261, 262], [263, 267], [267, 268]]}
{"doc_key": "ai-dev-332", "ner": [[0, 1, "misc"], [7, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 7, 9, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["RLS", "ist", "insbesondere", "darauf", "ausgelegt", ",", "den", "mittleren", "quadratischen", "Fehler", "zwischen", "den", "vorhergesagten", "Werten", "und", "den", "WAHREN", "Etiketten", "zu", "minimieren", ",", "wobei", "eine", "Regularisierung", "erfolgt", "."], "sentence-detokenized": "RLS ist insbesondere darauf ausgelegt, den mittleren quadratischen Fehler zwischen den vorhergesagten Werten und den WAHREN Etiketten zu minimieren, wobei eine Regularisierung erfolgt.", "token2charspan": [[0, 3], [4, 7], [8, 20], [21, 27], [28, 37], [37, 38], [39, 42], [43, 52], [53, 66], [67, 73], [74, 82], [83, 86], [87, 101], [102, 108], [109, 112], [113, 116], [117, 123], [124, 133], [134, 136], [137, 147], [147, 148], [149, 154], [155, 159], [160, 175], [176, 183], [183, 184]]}
{"doc_key": "ai-dev-333", "ner": [[5, 5, "algorithm"], [8, 8, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 8, 8, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Im", "Wesentlichen", "wird", "dabei", "eine", "Maximum-Likelihood-Sch\u00e4tzung", "mit", "einem", "Regularisierungsverfahren", "kombiniert", ",", "das", "einfachere", "Modelle", "gegen\u00fcber", "komplexeren", "Modellen", "bevorzugt", "."], "sentence-detokenized": "Im Wesentlichen wird dabei eine Maximum-Likelihood-Sch\u00e4tzung mit einem Regularisierungsverfahren kombiniert, das einfachere Modelle gegen\u00fcber komplexeren Modellen bevorzugt.", "token2charspan": [[0, 2], [3, 15], [16, 20], [21, 26], [27, 31], [32, 60], [61, 64], [65, 70], [71, 96], [97, 107], [107, 108], [109, 112], [113, 123], [124, 131], [132, 141], [142, 153], [154, 162], [163, 172], [172, 173]]}
{"doc_key": "ai-dev-334", "ner": [[1, 1, "metrics"], [6, 6, "metrics"], [8, 8, "metrics"], [10, 10, "misc"], [13, 13, "misc"], [23, 24, "algorithm"], [26, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[6, 6, 1, 1, "named", "", false, false], [8, 8, 1, 1, "named", "", false, false], [10, 10, 13, 13, "related-to", "", false, false], [10, 10, 23, 24, "related-to", "ratio", false, false], [23, 24, 26, 26, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Die", "Wahr-Positiv-Rate", "(", "auch", "bekannt", "als", "Sensitivit\u00e4t", ",", "Recall", "oder", "Erkennungswahrscheinlichkeit", "bis", "zur", "Unterscheidungsschwelle", ")", "der", "Erkennungswahrscheinlichkeit", "auf", "der", "y-Achse", "im", "Vergleich", "zur", "kumulativen", "Verteilungsfunktion", "der", "Falschalarmwahrscheinlichkeit", "auf", "der", "x-Achse", "."], "sentence-detokenized": "Die Wahr-Positiv-Rate (auch bekannt als Sensitivit\u00e4t, Recall oder Erkennungswahrscheinlichkeit bis zur Unterscheidungsschwelle) der Erkennungswahrscheinlichkeit auf der y-Achse im Vergleich zur kumulativen Verteilungsfunktion der Falschalarmwahrscheinlichkeit auf der x-Achse.", "token2charspan": [[0, 3], [4, 21], [22, 23], [23, 27], [28, 35], [36, 39], [40, 52], [52, 53], [54, 60], [61, 65], [66, 94], [95, 98], [99, 102], [103, 126], [126, 127], [128, 131], [132, 160], [161, 164], [165, 168], [169, 176], [177, 179], [180, 189], [190, 193], [194, 205], [206, 225], [226, 229], [230, 259], [260, 263], [264, 267], [268, 275], [275, 276]]}
{"doc_key": "ai-dev-335", "ner": [[1, 1, "misc"], [4, 4, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 1, 1, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Im", "Englischen", "ist", "das", "WordNet", "ein", "Beispiel", "f\u00fcr", "ein", "semantisches", "Netz", "."], "sentence-detokenized": "Im Englischen ist das WordNet ein Beispiel f\u00fcr ein semantisches Netz.", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 21], [22, 29], [30, 33], [34, 42], [43, 46], [47, 50], [51, 63], [64, 68], [68, 69]]}
{"doc_key": "ai-dev-336", "ner": [[4, 4, "product"], [8, 8, "product"], [21, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[21, 23, 4, 4, "usage", "", false, false], [21, 23, 8, 8, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Die", "l\u00e4ngere", "Verwendung", "von", "Spracherkennungssoftware", "in", "Verbindung", "mit", "Textverarbeitungsprogrammen", "hat", "sich", "als", "vorteilhaft", "f\u00fcr", "die", "St\u00e4rkung", "des", "Kurzzeitged\u00e4chtnisses", "bei", "Patienten", "mit", "AVM", "im", "Gehirn", "erwiesen", ",", "die", "mit", "einer", "Resektion", "behandelt", "wurden", "."], "sentence-detokenized": "Die l\u00e4ngere Verwendung von Spracherkennungssoftware in Verbindung mit Textverarbeitungsprogrammen hat sich als vorteilhaft f\u00fcr die St\u00e4rkung des Kurzzeitged\u00e4chtnisses bei Patienten mit AVM im Gehirn erwiesen, die mit einer Resektion behandelt wurden.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 26], [27, 51], [52, 54], [55, 65], [66, 69], [70, 97], [98, 101], [102, 106], [107, 110], [111, 122], [123, 126], [127, 130], [131, 139], [140, 143], [144, 165], [166, 169], [170, 179], [180, 183], [184, 187], [188, 190], [191, 197], [198, 206], [206, 207], [208, 211], [212, 215], [216, 221], [222, 231], [232, 241], [242, 248], [248, 249]]}
{"doc_key": "ai-dev-337", "ner": [[3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ihre", "Gr\u00fcndungs-Chefredakteure", "waren", "Ron", "Sun", ",", "Vasant", "Honavar", "und", "Gregg", "Oden", "(", "von", "1999", "bis", "2014", ")", "."], "sentence-detokenized": "Ihre Gr\u00fcndungs-Chefredakteure waren Ron Sun, Vasant Honavar und Gregg Oden (von 1999 bis 2014).", "token2charspan": [[0, 4], [5, 29], [30, 35], [36, 39], [40, 43], [43, 44], [45, 51], [52, 59], [60, 63], [64, 69], [70, 74], [75, 76], [76, 79], [80, 84], [85, 88], [89, 93], [93, 94], [94, 95]]}
{"doc_key": "ai-dev-338", "ner": [[7, 8, "product"], [14, 14, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 14, 14, "opposite", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Ihr", "\"", "paralleler", "\"", "Unterschied", "zu", "einem", "seriellen", "Manipulator", "besteht", "darin", ",", "dass", "der", "Endeffektor", "(", "oder", "die", "\"", "Hand", "\"", ")", "dieses", "Gest\u00e4nges", "(", "oder", "\"", "Arms", "\"", ")", "direkt", "mit", "seiner", "Basis", "durch", "eine", "Reihe", "von", "(", "in", "der", "Regel", "drei", "oder", "sechs", ")", "separaten", "und", "unabh\u00e4ngigen", "Gest\u00e4ngen", "verbunden", "ist", ",", "die", "gleichzeitig", "arbeiten", "."], "sentence-detokenized": "Ihr \"paralleler\" Unterschied zu einem seriellen Manipulator besteht darin, dass der Endeffektor (oder die \"Hand\") dieses Gest\u00e4nges (oder \"Arms\") direkt mit seiner Basis durch eine Reihe von (in der Regel drei oder sechs) separaten und unabh\u00e4ngigen Gest\u00e4ngen verbunden ist, die gleichzeitig arbeiten.", "token2charspan": [[0, 3], [4, 5], [5, 15], [15, 16], [17, 28], [29, 31], [32, 37], [38, 47], [48, 59], [60, 67], [68, 73], [73, 74], [75, 79], [80, 83], [84, 95], [96, 97], [97, 101], [102, 105], [106, 107], [107, 111], [111, 112], [112, 113], [114, 120], [121, 130], [131, 132], [132, 136], [137, 138], [138, 142], [142, 143], [143, 144], [145, 151], [152, 155], [156, 162], [163, 168], [169, 174], [175, 179], [180, 185], [186, 189], [190, 191], [191, 193], [194, 197], [198, 203], [204, 208], [209, 213], [214, 219], [219, 220], [221, 230], [231, 234], [235, 247], [248, 257], [258, 267], [268, 271], [271, 272], [273, 276], [277, 289], [290, 298], [298, 299]]}
{"doc_key": "ai-dev-339", "ner": [[5, 6, "researcher"], [21, 22, "researcher"], [23, 25, "researcher"], [27, 28, "researcher"], [30, 31, "researcher"], [33, 34, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Seine", "Dissertation", "wurde", "von", "Professor", "Cordell", "Green", "betreut", ",", "und", "zu", "seinem", "Ausschuss", "f\u00fcr", "Dissertation", "und", "m\u00fcndliche", "Pr\u00fcfung", "geh\u00f6rten", "die", "Professoren", "Edward", "Feigenbaum", ",", "Joshua", "Lederberg", ",", "Paul", "Cohen", ",", "Allen", "Newell", ",", "Herbert", "Simon", ",", "."], "sentence-detokenized": "Seine Dissertation wurde von Professor Cordell Green betreut, und zu seinem Ausschuss f\u00fcr Dissertation und m\u00fcndliche Pr\u00fcfung geh\u00f6rten die Professoren Edward Feigenbaum, Joshua Lederberg, Paul Cohen, Allen Newell, Herbert Simon,.", "token2charspan": [[0, 5], [6, 18], [19, 24], [25, 28], [29, 38], [39, 46], [47, 52], [53, 60], [60, 61], [62, 65], [66, 68], [69, 75], [76, 85], [86, 89], [90, 102], [103, 106], [107, 116], [117, 124], [125, 133], [134, 137], [138, 149], [150, 156], [157, 167], [167, 168], [169, 175], [176, 185], [185, 186], [187, 191], [192, 197], [197, 198], [199, 204], [205, 211], [211, 212], [213, 220], [221, 226], [226, 227], [227, 228]]}
{"doc_key": "ai-dev-340", "ner": [[5, 7, "metrics"], [10, 14, "metrics"], [17, 19, "metrics"], [22, 24, "metrics"], [27, 31, "metrics"], [34, 36, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Zu", "diesen", "Funktionen", "geh\u00f6ren", "der", "mittlere", "quadratische", "Fehler", ",", "die", "Wurzel", "des", "mittleren", "quadratischen", "Fehlers", ",", "der", "mittlere", "absolute", "Fehler", ",", "der", "relative", "quadratische", "Fehler", ",", "die", "Wurzel", "des", "relativen", "quadratischen", "Fehlers", ",", "der", "relative", "absolute", "Fehler", "und", "andere", "."], "sentence-detokenized": "Zu diesen Funktionen geh\u00f6ren der mittlere quadratische Fehler, die Wurzel des mittleren quadratischen Fehlers, der mittlere absolute Fehler, der relative quadratische Fehler, die Wurzel des relativen quadratischen Fehlers, der relative absolute Fehler und andere.", "token2charspan": [[0, 2], [3, 9], [10, 20], [21, 28], [29, 32], [33, 41], [42, 54], [55, 61], [61, 62], [63, 66], [67, 73], [74, 77], [78, 87], [88, 101], [102, 109], [109, 110], [111, 114], [115, 123], [124, 132], [133, 139], [139, 140], [141, 144], [145, 153], [154, 166], [167, 173], [173, 174], [175, 178], [179, 185], [186, 189], [190, 199], [200, 213], [214, 221], [221, 222], [223, 226], [227, 235], [236, 244], [245, 251], [252, 255], [256, 262], [262, 263]]}
{"doc_key": "ai-dev-341", "ner": [[4, 4, "programlang"], [6, 6, "programlang"], [8, 8, "product"], [10, 10, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Es", "gibt", "Bindungen", "in", "Python", ",", "Java", "und", "MATLAB", "/", "OCTAVE", "."], "sentence-detokenized": "Es gibt Bindungen in Python, Java und MATLAB / OCTAVE.", "token2charspan": [[0, 2], [3, 7], [8, 17], [18, 20], [21, 27], [27, 28], [29, 33], [34, 37], [38, 44], [45, 46], [47, 53], [53, 54]]}
{"doc_key": "ai-dev-342", "ner": [[3, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Eine", "Implementierung", "in", "MATLAB", "findet", "sich", "auf", "der", "Website", "."], "sentence-detokenized": "Eine Implementierung in MATLAB findet sich auf der Website.", "token2charspan": [[0, 4], [5, 20], [21, 23], [24, 30], [31, 37], [38, 42], [43, 46], [47, 50], [51, 58], [58, 59]]}
{"doc_key": "ai-dev-343", "ner": [[0, 1, "researcher"], [7, 8, "field"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 23, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 8, 0, 1, "origin", "", false, false], [7, 8, 12, 13, "origin", "", false, false], [7, 8, 15, 16, "origin", "", false, false], [7, 8, 18, 19, "origin", "", false, false], [7, 8, 21, 23, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["John", "McCarthy", "ist", "einer", "der", "Gr\u00fcnderv\u00e4ter", "der", "k\u00fcnstlichen", "Intelligenz", ",", "zusammen", "mit", "Alan", "Turing", ",", "Marvin", "Minsky", ",", "Allen", "Newell", "und", "Herbert", "A.", "Simon", "."], "sentence-detokenized": "John McCarthy ist einer der Gr\u00fcnderv\u00e4ter der k\u00fcnstlichen Intelligenz, zusammen mit Alan Turing, Marvin Minsky, Allen Newell und Herbert A. Simon.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 23], [24, 27], [28, 40], [41, 44], [45, 56], [57, 68], [68, 69], [70, 78], [79, 82], [83, 87], [88, 94], [94, 95], [96, 102], [103, 109], [109, 110], [111, 116], [117, 123], [124, 127], [128, 135], [136, 138], [139, 144], [144, 145]]}
{"doc_key": "ai-dev-344", "ner": [[9, 10, "product"], [18, 18, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ein", "Parallelmanipulator", "ist", "ein", "mechanisches", "System", ",", "das", "mehrere", "serielle", "Manipulatoren", "zur", "Unterst\u00fctzung", "einer", "einzigen", "Plattform", "oder", "eines", "Endeffektors", "verwendet", "."], "sentence-detokenized": "Ein Parallelmanipulator ist ein mechanisches System, das mehrere serielle Manipulatoren zur Unterst\u00fctzung einer einzigen Plattform oder eines Endeffektors verwendet.", "token2charspan": [[0, 3], [4, 23], [24, 27], [28, 31], [32, 44], [45, 51], [51, 52], [53, 56], [57, 64], [65, 73], [74, 87], [88, 91], [92, 105], [106, 111], [112, 120], [121, 130], [131, 135], [136, 141], [142, 154], [155, 164], [164, 165]]}
{"doc_key": "ai-dev-345", "ner": [[0, 0, "product"], [5, 5, "product"], [7, 11, "product"], [24, 24, "misc"], [27, 27, "misc"], [30, 30, "misc"], [33, 33, "task"], [36, 36, "product"], [39, 40, "product"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[5, 5, 0, 0, "part-of", "", false, false], [7, 11, 5, 5, "named", "", false, false], [24, 24, 5, 5, "part-of", "", false, false], [27, 27, 5, 5, "part-of", "", false, false], [30, 30, 5, 5, "part-of", "", false, false], [33, 33, 5, 5, "part-of", "", false, false], [36, 36, 5, 5, "part-of", "", false, false], [39, 40, 5, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 2, 3, 4, 5, 6, 7, 8], "sentence": ["GATE", "enth\u00e4lt", "ein", "Informationsextraktionssystem", "namens", "ANNIE", "(", "A", "Nearly-New", "Information", "Extraction", "System", ")", ",", "das", "aus", "einer", "Reihe", "von", "Modulen", "besteht", ",", "darunter", "ein", "Tokenizer", ",", "ein", "Gazetteer", ",", "ein", "Satzteiler", ",", "ein", "Part-of-Speech-Tagging", ",", "ein", "Named-Entity-Recognition-Transducer", "und", "ein", "Coreference", "Tagger", "."], "sentence-detokenized": "GATE enth\u00e4lt ein Informationsextraktionssystem namens ANNIE (A Nearly-New Information Extraction System), das aus einer Reihe von Modulen besteht, darunter ein Tokenizer, ein Gazetteer, ein Satzteiler, ein Part-of-Speech-Tagging, ein Named-Entity-Recognition-Transducer und ein Coreference Tagger.", "token2charspan": [[0, 4], [5, 12], [13, 16], [17, 46], [47, 53], [54, 59], [60, 61], [61, 62], [63, 73], [74, 85], [86, 96], [97, 103], [103, 104], [104, 105], [106, 109], [110, 113], [114, 119], [120, 125], [126, 129], [130, 137], [138, 145], [145, 146], [147, 155], [156, 159], [160, 169], [169, 170], [171, 174], [175, 184], [184, 185], [186, 189], [190, 200], [200, 201], [202, 205], [206, 228], [228, 229], [230, 233], [234, 269], [270, 273], [274, 277], [278, 289], [290, 296], [296, 297]]}
{"doc_key": "ai-dev-346", "ner": [[6, 8, "university"], [26, 27, "country"], [20, 23, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Er", "schloss", "sein", "Studium", "an", "der", "Staatlichen", "Universit\u00e4t", "Moskau", "ab", "und", "ging", "im", "November", "1978", "dank", "der", "pers\u00f6nlichen", "Intervention", "von", "Senator", "Edward", "M.", "Kennedy", "in", "die", "Vereinigten", "Staaten", "."], "sentence-detokenized": "Er schloss sein Studium an der Staatlichen Universit\u00e4t Moskau ab und ging im November 1978 dank der pers\u00f6nlichen Intervention von Senator Edward M. Kennedy in die Vereinigten Staaten.", "token2charspan": [[0, 2], [3, 10], [11, 15], [16, 23], [24, 26], [27, 30], [31, 42], [43, 54], [55, 61], [62, 64], [65, 68], [69, 73], [74, 76], [77, 85], [86, 90], [91, 95], [96, 99], [100, 112], [113, 125], [126, 129], [130, 137], [138, 144], [145, 147], [148, 155], [156, 158], [159, 162], [163, 174], [175, 182], [182, 183]]}
{"doc_key": "ai-dev-347", "ner": [[5, 5, "organisation"], [7, 8, "misc"], [15, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 7, 8, "win-defeat", "", false, false], [7, 8, 15, 15, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Im", "Jahr", "2017", "erhielt", "das", "DeepMind-AlphaGo-Team", "die", "erste", "IJCAI-Marvin-Minsky-Medaille", "f\u00fcr", "herausragende", "Leistungen", "im", "Bereich", "der", "KI", "."], "sentence-detokenized": "Im Jahr 2017 erhielt das DeepMind-AlphaGo-Team die erste IJCAI-Marvin-Minsky-Medaille f\u00fcr herausragende Leistungen im Bereich der KI.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 20], [21, 24], [25, 46], [47, 50], [51, 56], [57, 85], [86, 89], [90, 103], [104, 114], [115, 117], [118, 125], [126, 129], [130, 132], [132, 133]]}
{"doc_key": "ai-dev-348", "ner": [[3, 5, "misc"], [9, 9, "misc"], [15, 15, "misc"], [25, 26, "misc"], [30, 30, "misc"], [35, 35, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 5, 9, 9, "related-to", "is_recorded_by", false, false], [9, 9, 15, 15, "cause-effect", "", false, false], [9, 9, 15, 15, "physical", "", false, false], [9, 9, 25, 26, "physical", "", false, false], [9, 9, 35, 35, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Andere", "M\u00f6glichkeiten", ",", "anomale", "Ausbreitung", "zu", "erfassen", ",", "sind", "Troposkatern", ",", "die", "Unregelm\u00e4\u00dfigkeiten", "in", "der", "Troposph\u00e4re", "verursachen", ",", "Streuung", "durch", "Meteore", ",", "Brechung", "in", "den", "ionisierten", "Regionen", "und", "Schichten", "der", "Ionosph\u00e4re", "und", "Reflexion", "an", "der", "Ionosph\u00e4re", "."], "sentence-detokenized": "Andere M\u00f6glichkeiten, anomale Ausbreitung zu erfassen, sind Troposkatern, die Unregelm\u00e4\u00dfigkeiten in der Troposph\u00e4re verursachen, Streuung durch Meteore, Brechung in den ionisierten Regionen und Schichten der Ionosph\u00e4re und Reflexion an der Ionosph\u00e4re.", "token2charspan": [[0, 6], [7, 20], [20, 21], [22, 29], [30, 41], [42, 44], [45, 53], [53, 54], [55, 59], [60, 72], [72, 73], [74, 77], [78, 96], [97, 99], [100, 103], [104, 115], [116, 127], [127, 128], [129, 137], [138, 143], [144, 151], [151, 152], [153, 161], [162, 164], [165, 168], [169, 180], [181, 189], [190, 193], [194, 203], [204, 207], [208, 218], [219, 222], [223, 232], [233, 235], [236, 239], [240, 250], [250, 251]]}
{"doc_key": "ai-dev-349", "ner": [[0, 7, "field"], [9, 9, "field"], [15, 15, "field"], [18, 18, "field"], [21, 21, "field"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 7, 15, 15, "part-of", "", false, false], [0, 7, 18, 18, "part-of", "", false, false], [0, 7, 21, 21, "part-of", "", false, false], [0, 7, 24, 25, "part-of", "", false, false], [9, 9, 0, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Die", "Verarbeitung", "nat\u00fcrlicher", "Sprache", "(", "Natural", "Language", "Processing", ",", "NLP", ")", "ist", "ein", "Teilgebiet", "der", "Linguistik", ",", "der", "Informatik", ",", "der", "Informationstechnik", "und", "der", "k\u00fcnstlichen", "Intelligenz", ",", "das", "sich", "mit", "der", "Interaktion", "zwischen", "Computern", "und", "menschlichen", "(", "nat\u00fcrlichen", ")", "Sprachen", "befasst", ",", "insbesondere", "mit", "der", "Frage", ",", "wie", "man", "Computer", "so", "programmiert", ",", "dass", "sie", "gro\u00dfe", "Mengen", "an", "nat\u00fcrlichsprachlichen", "Daten", "verarbeiten", "und", "analysieren", "k\u00f6nnen", "."], "sentence-detokenized": "Die Verarbeitung nat\u00fcrlicher Sprache (Natural Language Processing, NLP) ist ein Teilgebiet der Linguistik, der Informatik, der Informationstechnik und der k\u00fcnstlichen Intelligenz, das sich mit der Interaktion zwischen Computern und menschlichen (nat\u00fcrlichen) Sprachen befasst, insbesondere mit der Frage, wie man Computer so programmiert, dass sie gro\u00dfe Mengen an nat\u00fcrlichsprachlichen Daten verarbeiten und analysieren k\u00f6nnen.", "token2charspan": [[0, 3], [4, 16], [17, 28], [29, 36], [37, 38], [38, 45], [46, 54], [55, 65], [65, 66], [67, 70], [70, 71], [72, 75], [76, 79], [80, 90], [91, 94], [95, 105], [105, 106], [107, 110], [111, 121], [121, 122], [123, 126], [127, 146], [147, 150], [151, 154], [155, 166], [167, 178], [178, 179], [180, 183], [184, 188], [189, 192], [193, 196], [197, 208], [209, 217], [218, 227], [228, 231], [232, 244], [245, 246], [246, 257], [257, 258], [259, 267], [268, 275], [275, 276], [277, 289], [290, 293], [294, 297], [298, 303], [303, 304], [305, 308], [309, 312], [313, 321], [322, 324], [325, 337], [337, 338], [339, 343], [344, 347], [348, 353], [354, 360], [361, 363], [364, 385], [386, 391], [392, 403], [404, 407], [408, 419], [420, 426], [426, 427]]}
{"doc_key": "ai-dev-350", "ner": [[5, 6, "organisation"], [9, 9, "organisation"], [11, 12, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Andere", "aktive", "jugendliche", "Klimagruppen", "sind", "Extinction", "Rebellion", ",", "die", "Sunrise-Bewegung", ",", "SustainUS", "und", "andere", ",", "die", "so", "wohl", "auf", "transnationaler", "als", "auch", "auf", "lokaler", "Ebene", "arbeiten", "."], "sentence-detokenized": "Andere aktive jugendliche Klimagruppen sind Extinction Rebellion, die Sunrise-Bewegung, SustainUS und andere, die sowohl auf transnationaler als auch auf lokaler Ebene arbeiten.", "token2charspan": [[0, 6], [7, 13], [14, 25], [26, 38], [39, 43], [44, 54], [55, 64], [64, 65], [66, 69], [70, 86], [86, 87], [88, 97], [98, 101], [102, 108], [108, 109], [110, 113], [114, 116], [116, 120], [121, 124], [125, 140], [141, 144], [145, 149], [150, 153], [154, 161], [162, 167], [168, 176], [176, 177]]}
