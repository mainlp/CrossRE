{"doc_key": "ai-train-1", "ner": [[3, 4, "product"], [10, 10, "field"], [12, 12, "task"], [14, 14, "task"], [18, 19, "task"], [22, 23, "field"], [24, 25, "researcher"], [27, 28, "researcher"], [30, 31, "researcher"], [33, 34, "researcher"], [36, 38, "researcher"], [40, 41, "researcher"], [43, 44, "researcher"], [46, 47, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[3, 4, 10, 10, "part-of", "", false, false], [3, 4, 10, 10, "usage", "", false, false], [3, 4, 12, 12, "part-of", "", false, false], [3, 4, 12, 12, "usage", "", false, false], [3, 4, 14, 14, "part-of", "", false, false], [3, 4, 14, 14, "usage", "", false, false], [3, 4, 22, 23, "part-of", "", false, false], [3, 4, 22, 23, "usage", "", false, false], [18, 19, 14, 14, "part-of", "", false, false], [18, 19, 14, 14, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Popul\u00e6re", "tilgange", "til", "meningsbaserede", "anbefalingssystemer", "anvender", "forskellige", "teknikker", ",", "herunder", "tekstminedrift", ",", "informationss\u00f8gning", ",", "f\u00f8lelsesanalyse", "(", "se", "ogs\u00e5", "Multimodal", "f\u00f8lelsesanalyse", ")", "og", "dyb", "indl\u00e6ring", "X.Y.", "Feng", ",", "H.", "Zhang", ",", "Y.J.", "Ren", ",", "P.H.", "Shang", ",", "Y", ".", "Zhu", ",", "Y.C.", "Liang", ",", "R.C.", "Guan", ",", "D.", "Xu", ",", "(", "2019", ")", ",", ",", "21", "(", "5", ")", ":", "e12957", "."], "sentence-detokenized": "Popul\u00e6re tilgange til meningsbaserede anbefalingssystemer anvender forskellige teknikker, herunder tekstminedrift, informationss\u00f8gning, f\u00f8lelsesanalyse (se ogs\u00e5 Multimodal f\u00f8lelsesanalyse) og dyb indl\u00e6ring X.Y. Feng, H. Zhang, Y.J. Ren, P.H. Shang, Y. Zhu, Y.C. Liang, R.C. Guan, D. Xu, (2019),, 21 (5): e12957.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 37], [38, 57], [58, 66], [67, 78], [79, 88], [88, 89], [90, 98], [99, 113], [113, 114], [115, 134], [134, 135], [136, 151], [152, 153], [153, 155], [156, 160], [161, 171], [172, 187], [187, 188], [189, 191], [192, 195], [196, 205], [206, 210], [211, 215], [215, 216], [217, 219], [220, 225], [225, 226], [227, 231], [232, 235], [235, 236], [237, 241], [242, 247], [247, 248], [249, 250], [250, 251], [252, 255], [255, 256], [257, 261], [262, 267], [267, 268], [269, 273], [274, 278], [278, 279], [280, 282], [283, 285], [285, 286], [287, 288], [288, 292], [292, 293], [293, 294], [294, 295], [296, 298], [299, 300], [300, 301], [301, 302], [302, 303], [304, 310], [310, 311]]}
{"doc_key": "ai-train-2", "ner": [[8, 8, "university"], [12, 13, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 13, 8, 8, "physical", "", false, false], [12, 13, 8, 8, "role", "", false, false], [15, 16, 8, 8, "physical", "", false, false], [15, 16, 8, 8, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Fortalerne", "for", "procedurale", "repr\u00e6sentationer", "var", "hovedsageligt", "centreret", "p\u00e5", "MIT", "under", "ledelse", "af", "Marvin", "Minsky", "og", "Seymour", "Papert", "."], "sentence-detokenized": "Fortalerne for procedurale repr\u00e6sentationer var hovedsageligt centreret p\u00e5 MIT under ledelse af Marvin Minsky og Seymour Papert.", "token2charspan": [[0, 10], [11, 14], [15, 26], [27, 43], [44, 47], [48, 61], [62, 71], [72, 74], [75, 78], [79, 84], [85, 92], [93, 95], [96, 102], [103, 109], [110, 112], [113, 120], [121, 127], [127, 128]]}
{"doc_key": "ai-train-3", "ner": [[7, 7, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Standardgr\u00e6nsefladen", "og", "regnemaskinens", "gr\u00e6nseflade", "er", "skrevet", "i", "Java", "."], "sentence-detokenized": "Standardgr\u00e6nsefladen og regnemaskinens gr\u00e6nseflade er skrevet i Java.", "token2charspan": [[0, 20], [21, 23], [24, 38], [39, 50], [51, 53], [54, 61], [62, 63], [64, 68], [68, 69]]}
{"doc_key": "ai-train-4", "ner": [[0, 0, "product"], [30, 30, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 30, 30, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["Octave", "hj\u00e6lper", "med", "at", "l\u00f8se", "line\u00e6re", "og", "ikke-line\u00e6re", "problemer", "numerisk", "og", "med", "at", "udf\u00f8re", "andre", "numeriske", "eksperimenter", "ved", "hj\u00e6lp", "af", "et", "program", ",", "der", "for", "det", "meste", "er", "kompatibelt", "med", "MATLAB", "."], "sentence-detokenized": "Octave hj\u00e6lper med at l\u00f8se line\u00e6re og ikke-line\u00e6re problemer numerisk og med at udf\u00f8re andre numeriske eksperimenter ved hj\u00e6lp af et program, der for det meste er kompatibelt med MATLAB.", "token2charspan": [[0, 6], [7, 14], [15, 18], [19, 21], [22, 26], [27, 34], [35, 37], [38, 50], [51, 60], [61, 69], [70, 72], [73, 76], [77, 79], [80, 86], [87, 92], [93, 102], [103, 116], [117, 120], [121, 126], [127, 129], [130, 132], [133, 140], [140, 141], [142, 145], [146, 149], [150, 153], [154, 159], [160, 162], [163, 174], [175, 178], [179, 185], [185, 186]]}
{"doc_key": "ai-train-5", "ner": [[2, 2, "algorithm"], [4, 5, "misc"], [7, 8, "researcher"], [12, 14, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 2, 7, 8, "origin", "", false, false], [4, 5, 7, 8, "origin", "", false, false], [7, 8, 12, 14, "physical", "", false, false], [7, 8, 12, 14, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Varianter", "af", "back-propagation-algoritmen", "samt", "uoverv\u00e5gede", "metoder", "af", "Geoff", "Hinton", "og", "kolleger", "ved", "University", "of", "Toronto", "kan", "bruges", "til", "at", "tr\u00e6ne", "dybe", ",", "meget", "ikke-line\u00e6re", "neurale", "arkitekturer", ",", "{", "{", "cite", "journal"], "sentence-detokenized": "Varianter af back-propagation-algoritmen samt uoverv\u00e5gede metoder af Geoff Hinton og kolleger ved University of Toronto kan bruges til at tr\u00e6ne dybe, meget ikke-line\u00e6re neurale arkitekturer, {{cite journal", "token2charspan": [[0, 9], [10, 12], [13, 40], [41, 45], [46, 57], [58, 65], [66, 68], [69, 74], [75, 81], [82, 84], [85, 93], [94, 97], [98, 108], [109, 111], [112, 119], [120, 123], [124, 130], [131, 134], [135, 137], [138, 143], [144, 148], [148, 149], [150, 155], [156, 168], [169, 176], [177, 189], [189, 190], [191, 192], [192, 193], [193, 197], [198, 205]]}
{"doc_key": "ai-train-6", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["eller", "tilsvarende", "ved", "hj\u00e6lp", "af", "DCG-notation", ":"], "sentence-detokenized": "eller tilsvarende ved hj\u00e6lp af DCG-notation:", "token2charspan": [[0, 5], [6, 17], [18, 21], [22, 27], [28, 30], [31, 43], [43, 44]]}
{"doc_key": "ai-train-7", "ner": [[0, 1, "algorithm"], [6, 8, "algorithm"], [12, 14, "algorithm"], [17, 17, "algorithm"], [21, 21, "algorithm"], [23, 23, "algorithm"], [35, 36, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 6, 8, "type-of", "", false, false], [0, 1, 12, 14, "usage", "part-of?", true, false], [12, 14, 17, 17, "compare", "", false, false], [21, 21, 17, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Selvorganiserende", "kort", "adskiller", "sig", "fra", "andre", "kunstige", "neurale", "netv\u00e6rk", "ved", "at", "anvende", "konkurrerende", "l\u00e6ring", "i", "mods\u00e6tning", "til", "fejlkorrektionsl\u00e6ring", "som", "f.eks", ".", "backpropagation", "med", "gradientafstigning", ")", "og", "ved", "at", "anvende", "en", "nabofunktion", "til", "at", "bevare", "de", "topologiske", "egenskaber", "af", "inputrummet", "."], "sentence-detokenized": "Selvorganiserende kort adskiller sig fra andre kunstige neurale netv\u00e6rk ved at anvende konkurrerende l\u00e6ring i mods\u00e6tning til fejlkorrektionsl\u00e6ring som f.eks. backpropagation med gradientafstigning) og ved at anvende en nabofunktion til at bevare de topologiske egenskaber af inputrummet.", "token2charspan": [[0, 17], [18, 22], [23, 32], [33, 36], [37, 40], [41, 46], [47, 55], [56, 63], [64, 71], [72, 75], [76, 78], [79, 86], [87, 100], [101, 107], [108, 109], [110, 120], [121, 124], [125, 146], [147, 150], [151, 156], [156, 157], [158, 173], [174, 177], [178, 196], [196, 197], [198, 200], [201, 204], [205, 207], [208, 215], [216, 218], [219, 231], [232, 235], [236, 238], [239, 245], [246, 248], [249, 260], [261, 271], [272, 274], [275, 286], [286, 287]]}
{"doc_key": "ai-train-8", "ner": [[13, 15, "organisation"], [24, 24, "misc"], [34, 36, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Siden", "begyndelsen", "af", "1990'erne", "er", "det", "blevet", "anbefalet", "af", "flere", "myndigheder", ",", "herunder", "Audio", "Engineering", "Society", ",", "at", "m\u00e5linger", "af", "dynamikomr\u00e5det", "foretages", "med", "et", "lydsignal", "til", "stede", ",", "som", "derefter", "filtreres", "fra", "i", "den", "m\u00e5ling", "af", "st\u00f8jgulvet", ",", "der", "anvendes", "til", "at", "bestemme", "dynamikomr\u00e5det", ".", "Derved", "undg\u00e5s", "tvivlsomme", "m\u00e5linger", "baseret", "p\u00e5", "brugen", "af", "tomme", "medier", "eller", "muting-kredsl\u00f8b", "."], "sentence-detokenized": "Siden begyndelsen af 1990'erne er det blevet anbefalet af flere myndigheder, herunder Audio Engineering Society, at m\u00e5linger af dynamikomr\u00e5det foretages med et lydsignal til stede, som derefter filtreres fra i den m\u00e5ling af st\u00f8jgulvet, der anvendes til at bestemme dynamikomr\u00e5det. Derved undg\u00e5s tvivlsomme m\u00e5linger baseret p\u00e5 brugen af tomme medier eller muting-kredsl\u00f8b.", "token2charspan": [[0, 5], [6, 17], [18, 20], [21, 30], [31, 33], [34, 37], [38, 44], [45, 54], [55, 57], [58, 63], [64, 75], [75, 76], [77, 85], [86, 91], [92, 103], [104, 111], [111, 112], [113, 115], [116, 124], [125, 127], [128, 142], [143, 152], [153, 156], [157, 159], [160, 169], [170, 173], [174, 179], [179, 180], [181, 184], [185, 193], [194, 203], [204, 207], [208, 209], [210, 213], [214, 220], [221, 223], [224, 234], [234, 235], [236, 239], [240, 248], [249, 252], [253, 255], [256, 264], [265, 279], [279, 280], [281, 287], [288, 294], [295, 305], [306, 314], [315, 322], [323, 325], [326, 332], [333, 335], [336, 341], [342, 348], [349, 354], [355, 370], [370, 371]]}
{"doc_key": "ai-train-9", "ner": [[8, 8, "misc"], [19, 19, "task"], [21, 21, "task"], [23, 23, "task"], [25, 25, "task"], [27, 29, "task"], [31, 34, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6, 7], "relations": [[8, 8, 19, 19, "part-of", "concept_used_in", true, false], [8, 8, 21, 21, "part-of", "concept_used_in", false, false], [8, 8, 23, 23, "part-of", "concept_used_in", false, false], [8, 8, 25, 25, "part-of", "concept_used_in", false, false], [8, 8, 27, 29, "part-of", "concept_used_in", false, false], [8, 8, 31, 34, "part-of", "concept_used_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5, 6], "sentence": ["Den", "teknik", ",", "der", "anvendes", "til", "at", "skabe", "egenansigter", "og", "bruge", "dem", "til", "genkendelse", ",", "anvendes", "ogs\u00e5", "uden", "for", "ansigtsgenkendelse", ":", "h\u00e5ndskriftgenkendelse", ",", "l\u00e6bel\u00e6sning", ",", "stemmegenkendelse", ",", "tolkning", "af", "tegnsprog/h\u00e5ndbev\u00e6gelser", "og", "analyse", "af", "medicinske", "billeddannelser", "."], "sentence-detokenized": "Den teknik, der anvendes til at skabe egenansigter og bruge dem til genkendelse, anvendes ogs\u00e5 uden for ansigtsgenkendelse: h\u00e5ndskriftgenkendelse, l\u00e6bel\u00e6sning, stemmegenkendelse, tolkning af tegnsprog/h\u00e5ndbev\u00e6gelser og analyse af medicinske billeddannelser.", "token2charspan": [[0, 3], [4, 10], [10, 11], [12, 15], [16, 24], [25, 28], [29, 31], [32, 37], [38, 50], [51, 53], [54, 59], [60, 63], [64, 67], [68, 79], [79, 80], [81, 89], [90, 94], [95, 99], [100, 103], [104, 122], [122, 123], [124, 145], [145, 146], [147, 158], [158, 159], [160, 177], [177, 178], [179, 187], [188, 190], [191, 215], [216, 218], [219, 226], [227, 229], [230, 240], [241, 256], [256, 257]]}
{"doc_key": "ai-train-10", "ner": [[0, 2, "organisation"], [7, 11, "organisation"], [13, 13, "organisation"], [17, 18, "organisation"], [21, 23, "organisation"], [26, 27, "organisation"], [29, 33, "organisation"], [35, 35, "organisation"], [38, 41, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[7, 11, 0, 2, "part-of", "", false, false], [13, 13, 7, 11, "named", "", false, false], [17, 18, 0, 2, "part-of", "", false, false], [21, 23, 0, 2, "part-of", "", false, false], [26, 27, 0, 2, "part-of", "", false, false], [29, 33, 0, 2, "part-of", "", false, false], [35, 35, 29, 33, "named", "", false, false], [38, 41, 0, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["National", "Science", "Foundation", "var", "en", "paraply", "for", "National", "Aeronautics", "and", "Space", "Administration", "(", "NASA", ")", ",", "det", "amerikanske", "energiministerium", ",", "det", "amerikanske", "handelsministerium", "NIST", ",", "det", "amerikanske", "forsvarsministerium", ",", "Defense", "Advanced", "Research", "Projects", "Agency", "(", "DARPA", ")", "og", "Office", "of", "Naval", "Research", "koordinerede", "unders\u00f8gelser", "for", "at", "informere", "strategiske", "planl\u00e6ggere", "i", "deres", "overvejelser", "."], "sentence-detokenized": "National Science Foundation var en paraply for National Aeronautics and Space Administration (NASA), det amerikanske energiministerium, det amerikanske handelsministerium NIST, det amerikanske forsvarsministerium, Defense Advanced Research Projects Agency (DARPA) og Office of Naval Research koordinerede unders\u00f8gelser for at informere strategiske planl\u00e6ggere i deres overvejelser.", "token2charspan": [[0, 8], [9, 16], [17, 27], [28, 31], [32, 34], [35, 42], [43, 46], [47, 55], [56, 67], [68, 71], [72, 77], [78, 92], [93, 94], [94, 98], [98, 99], [99, 100], [101, 104], [105, 116], [117, 134], [134, 135], [136, 139], [140, 151], [152, 170], [171, 175], [175, 176], [177, 180], [181, 192], [193, 212], [212, 213], [214, 221], [222, 230], [231, 239], [240, 248], [249, 255], [256, 257], [257, 262], [262, 263], [264, 266], [267, 273], [274, 276], [277, 282], [283, 291], [292, 304], [305, 318], [319, 322], [323, 325], [326, 335], [336, 347], [348, 359], [360, 361], [362, 367], [368, 380], [380, 381]]}
{"doc_key": "ai-train-11", "ner": [[6, 6, "metrics"], [9, 9, "algorithm"], [13, 14, "researcher"], [19, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 9, 9, "part-of", "", false, false], [13, 14, 19, 19, "related-to", "added_appendix_to_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["En", "hurtig", "metode", "til", "beregning", "af", "maximum", "likelihood-estimater", "for", "probit-modellen", "blev", "foresl\u00e5et", "af", "Ronald", "Fisher", "som", "et", "till\u00e6g", "til", "Bliss'", "arbejde", "i", "1935", "."], "sentence-detokenized": "En hurtig metode til beregning af maximum likelihood-estimater for probit-modellen blev foresl\u00e5et af Ronald Fisher som et till\u00e6g til Bliss' arbejde i 1935.", "token2charspan": [[0, 2], [3, 9], [10, 16], [17, 20], [21, 30], [31, 33], [34, 41], [42, 62], [63, 66], [67, 82], [83, 87], [88, 97], [98, 100], [101, 107], [108, 114], [115, 118], [119, 121], [122, 128], [129, 132], [133, 139], [140, 147], [148, 149], [150, 154], [154, 155]]}
{"doc_key": "ai-train-12", "ner": [[10, 11, "product"], [13, 13, "product"], [17, 17, "organisation"], [18, 18, "product"], [22, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[18, 18, 13, 13, "usage", "uses_software", false, false], [18, 18, 17, 17, "artifact", "", false, false], [18, 18, 22, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Flere", "af", "disse", "programmer", "er", "tilg\u00e6ngelige", "online", ",", "f.eks", ".", "Google", "Translate", "og", "SYSTRAN-systemet", ",", "som", "driver", "AltaVistas", "BabelFish", "(", "nu", "Yahoos", "Babelfish", "fra", "den", "9.", "maj", "2008", ")", "."], "sentence-detokenized": "Flere af disse programmer er tilg\u00e6ngelige online, f.eks. Google Translate og SYSTRAN-systemet, som driver AltaVistas BabelFish (nu Yahoos Babelfish fra den 9. maj 2008).", "token2charspan": [[0, 5], [6, 8], [9, 14], [15, 25], [26, 28], [29, 41], [42, 48], [48, 49], [50, 55], [55, 56], [57, 63], [64, 73], [74, 76], [77, 93], [93, 94], [95, 98], [99, 105], [106, 116], [117, 126], [127, 128], [128, 130], [131, 137], [138, 147], [148, 151], [152, 155], [156, 158], [159, 162], [163, 167], [167, 168], [168, 169]]}
{"doc_key": "ai-train-13", "ner": [[5, 5, "researcher"], [8, 9, "researcher"], [11, 12, "researcher"], [17, 19, "field"], [23, 24, "misc"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 5, 17, 19, "related-to", "", true, false], [5, 5, 23, 24, "related-to", "", true, false], [5, 5, 27, 28, "related-to", "", true, false], [8, 9, 17, 19, "related-to", "", true, false], [8, 9, 23, 24, "related-to", "", true, false], [8, 9, 27, 28, "related-to", "", true, false], [11, 12, 17, 19, "related-to", "", true, false], [11, 12, 23, 24, "related-to", "", true, false], [11, 12, 27, 28, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["I", "2002", "udviklede", "og", "offentliggjorde", "Hutter", "sammen", "med", "J\u00fcrgen", "Schmidhuber", "og", "Shane", "Legg", "en", "matematisk", "teori", "om", "kunstig", "generel", "intelligens", "baseret", "p\u00e5", "idealiserede", "intelligente", "agenter", "og", "bel\u00f8nningsmotiveret", "forst\u00e6rket", "l\u00e6ring", "."], "sentence-detokenized": "I 2002 udviklede og offentliggjorde Hutter sammen med J\u00fcrgen Schmidhuber og Shane Legg en matematisk teori om kunstig generel intelligens baseret p\u00e5 idealiserede intelligente agenter og bel\u00f8nningsmotiveret forst\u00e6rket l\u00e6ring.", "token2charspan": [[0, 1], [2, 6], [7, 16], [17, 19], [20, 35], [36, 42], [43, 49], [50, 53], [54, 60], [61, 72], [73, 75], [76, 81], [82, 86], [87, 89], [90, 100], [101, 106], [107, 109], [110, 117], [118, 125], [126, 137], [138, 145], [146, 148], [149, 161], [162, 174], [175, 182], [183, 185], [186, 205], [206, 216], [217, 223], [223, 224]]}
{"doc_key": "ai-train-14", "ner": [[11, 15, "metrics"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Den", "mest", "almindelige", "m\u00e5de", "er", "ved", "hj\u00e6lp", "af", "den", "s\u00e5kaldte", "ROUGE-m\u00e5ling", "(Recall-Oriented", "Understudy", "for", "Gisting", "Evaluation", ")", "."], "sentence-detokenized": "Den mest almindelige m\u00e5de er ved hj\u00e6lp af den s\u00e5kaldte ROUGE-m\u00e5ling (Recall-Oriented Understudy for Gisting Evaluation).", "token2charspan": [[0, 3], [4, 8], [9, 20], [21, 25], [26, 28], [29, 32], [33, 38], [39, 41], [42, 45], [46, 54], [55, 67], [68, 84], [85, 95], [96, 99], [100, 107], [108, 118], [118, 119], [119, 120]]}
{"doc_key": "ai-train-15", "ner": [[0, 0, "product"], [13, 13, "programlang"], [17, 18, "researcher"], [20, 21, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4], "relations": [[0, 0, 13, 13, "related-to", "", false, false], [17, 18, 20, 21, "role", "", false, false]], "relations_mapping_to_source": [0, 2], "sentence": ["RapidMiner", "indeholder", "l\u00e6ringsordninger", ",", "modeller", "og", "algoritmer", "og", "kan", "udvides", "ved", "hj\u00e6lp", "af", "R-", "og", "Python-scripts", ".", "David", "Norris", ",", "Bloor", "Research", ",", "13.", "november", "2013", "."], "sentence-detokenized": "RapidMiner indeholder l\u00e6ringsordninger, modeller og algoritmer og kan udvides ved hj\u00e6lp af R- og Python-scripts. David Norris, Bloor Research, 13. november 2013.", "token2charspan": [[0, 10], [11, 21], [22, 38], [38, 39], [40, 48], [49, 51], [52, 62], [63, 65], [66, 69], [70, 77], [78, 81], [82, 87], [88, 90], [91, 93], [94, 96], [97, 111], [111, 112], [113, 118], [119, 125], [125, 126], [127, 132], [133, 141], [141, 142], [143, 146], [147, 155], [156, 160], [160, 161]]}
{"doc_key": "ai-train-16", "ner": [[0, 0, "product"], [9, 9, "field"], [11, 12, "task"], [14, 15, "misc"], [30, 31, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[0, 0, 9, 9, "related-to", "", false, false], [0, 0, 11, 12, "related-to", "", false, false], [0, 0, 30, 31, "related-to", "", true, false], [14, 15, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["tity", "indeholder", "en", "samling", "af", "visualiseringsv\u00e6rkt\u00f8jer", "og", "algoritmer", "til", "dataanalyse", "og", "pr\u00e6diktiv", "modellering", "samt", "grafiske", "brugergr\u00e6nseflader", "for", "nem", "adgang", "til", "disse", "funktioner", ".", "men", "den", "nyere", "fuldt", "Java-baserede", "version", "(", "Weka", "3", ")", ",", "hvis", "udvikling", "startede", "i", "1997", ",", "anvendes", "nu", "inden", "for", "mange", "forskellige", "anvendelsesomr\u00e5der", ",", "is\u00e6r", "til", "uddannelsesform\u00e5l", "og", "forskning", "."], "sentence-detokenized": "tity indeholder en samling af visualiseringsv\u00e6rkt\u00f8jer og algoritmer til dataanalyse og pr\u00e6diktiv modellering samt grafiske brugergr\u00e6nseflader for nem adgang til disse funktioner. men den nyere fuldt Java-baserede version (Weka 3), hvis udvikling startede i 1997, anvendes nu inden for mange forskellige anvendelsesomr\u00e5der, is\u00e6r til uddannelsesform\u00e5l og forskning.", "token2charspan": [[0, 4], [5, 15], [16, 18], [19, 26], [27, 29], [30, 53], [54, 56], [57, 67], [68, 71], [72, 83], [84, 86], [87, 96], [97, 108], [109, 113], [114, 122], [123, 141], [142, 145], [146, 149], [150, 156], [157, 160], [161, 166], [167, 177], [177, 178], [179, 182], [183, 186], [187, 192], [193, 198], [199, 212], [213, 220], [221, 222], [222, 226], [227, 228], [228, 229], [229, 230], [231, 235], [236, 245], [246, 254], [255, 256], [257, 261], [261, 262], [263, 271], [272, 274], [275, 280], [281, 284], [285, 290], [291, 302], [303, 321], [321, 322], [323, 327], [328, 331], [332, 349], [350, 352], [353, 362], [362, 363]]}
{"doc_key": "ai-train-17", "ner": [[0, 0, "product"], [12, 19, "misc"], [21, 24, "misc"], [26, 34, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 19, 0, 0, "topic", "", false, false], [12, 19, 21, 24, "win-defeat", "", false, false], [21, 24, 26, 34, "temporal", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Eurisko", "gjorde", "mange", "interessante", "opdagelser", "og", "fik", "stor", "anerkendelse", "med", "sin", "artikel", "Heuretics", ":", "Theoretical", "and", "Study", "of", "Heuristic", "Rules", "vandt", "prisen", "for", "bedste", "artikel", "p\u00e5", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "i", "1982", "."], "sentence-detokenized": "Eurisko gjorde mange interessante opdagelser og fik stor anerkendelse med sin artikel Heuretics: Theoretical and Study of Heuristic Rules vandt prisen for bedste artikel p\u00e5 Association for the Advancement of Artificial Intelligence i 1982.", "token2charspan": [[0, 7], [8, 14], [15, 20], [21, 33], [34, 44], [45, 47], [48, 51], [52, 56], [57, 69], [70, 73], [74, 77], [78, 85], [86, 95], [95, 96], [97, 108], [109, 112], [113, 118], [119, 121], [122, 131], [132, 137], [138, 143], [144, 150], [151, 154], [155, 161], [162, 169], [170, 172], [173, 184], [185, 188], [189, 192], [193, 204], [205, 207], [208, 218], [219, 231], [232, 233], [234, 238], [238, 239]]}
{"doc_key": "ai-train-18", "ner": [[10, 10, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "at", "tage", "h\u00f8jde", "for", "flere", "enheder", "beregnes", "et", "separat", "h\u00e6ngselstab", "for", "hver", "kapsel", "."], "sentence-detokenized": "For at tage h\u00f8jde for flere enheder beregnes et separat h\u00e6ngselstab for hver kapsel.", "token2charspan": [[0, 3], [4, 6], [7, 11], [12, 17], [18, 21], [22, 27], [28, 35], [36, 44], [45, 47], [48, 55], [56, 67], [68, 71], [72, 76], [77, 83], [83, 84]]}
{"doc_key": "ai-train-19", "ner": [[6, 7, "product"], [9, 10, "product"], [12, 13, "product"], [15, 16, "product"], [18, 19, "product"], [21, 21, "product"], [28, 29, "product"], [31, 32, "product"], [34, 35, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[6, 7, 21, 21, "type-of", "", false, false], [9, 10, 21, 21, "type-of", "", false, false], [12, 13, 21, 21, "type-of", "", false, false], [15, 16, 21, 21, "type-of", "", false, false], [18, 19, 21, 21, "type-of", "", false, false], [31, 32, 28, 29, "type-of", "", false, false], [34, 35, 28, 29, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Med", "fremkomsten", "af", "talende", "assistenter", "som", "Apples", "Siri", ",", "Amazons", "Alexa", ",", "Google", "Assistant", ",", "Microsoft", "Cortana", "og", "Samsungs", "Bixby", "kan", "stemmeportaler", "nu", "tilg\u00e5s", "via", "mobile", "enheder", "og", "intelligente", "h\u00f8jttalere", "som", "Amazon", "Echo", "og", "Google", "Home", "."], "sentence-detokenized": "Med fremkomsten af talende assistenter som Apples Siri, Amazons Alexa, Google Assistant, Microsoft Cortana og Samsungs Bixby kan stemmeportaler nu tilg\u00e5s via mobile enheder og intelligente h\u00f8jttalere som Amazon Echo og Google Home.", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 26], [27, 38], [39, 42], [43, 49], [50, 54], [54, 55], [56, 63], [64, 69], [69, 70], [71, 77], [78, 87], [87, 88], [89, 98], [99, 106], [107, 109], [110, 118], [119, 124], [125, 128], [129, 143], [144, 146], [147, 153], [154, 157], [158, 164], [165, 172], [173, 175], [176, 188], [189, 199], [200, 203], [204, 210], [211, 215], [216, 218], [219, 225], [226, 230], [230, 231]]}
{"doc_key": "ai-train-20", "ner": [[2, 3, "field"], [5, 6, "algorithm"], [8, 8, "algorithm"], [10, 10, "algorithm"], [12, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 2, 3, "type-of", "", false, false], [8, 8, 2, 3, "type-of", "", false, false], [10, 10, 2, 3, "type-of", "", false, false], [12, 12, 2, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Eksempler", "p\u00e5", "overv\u00e5get", "indl\u00e6ring", "er", "Naive", "Bayes-klassificator", ",", "supportvektormaskine", ",", "Gaussian-blandinger", "og", "netv\u00e6rk", "."], "sentence-detokenized": "Eksempler p\u00e5 overv\u00e5get indl\u00e6ring er Naive Bayes-klassificator, supportvektormaskine, Gaussian-blandinger og netv\u00e6rk.", "token2charspan": [[0, 9], [10, 12], [13, 22], [23, 32], [33, 35], [36, 41], [42, 61], [61, 62], [63, 83], [83, 84], [85, 104], [105, 107], [108, 115], [115, 116]]}
{"doc_key": "ai-train-21", "ner": [[3, 3, "algorithm"], [22, 24, "algorithm"], [26, 26, "task"], [30, 30, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 22, 24, "part-of", "", true, false], [30, 30, 26, 26, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Man", "kan", "bruge", "OSD-algoritmen", "til", "at", "udlede", "math", "O", "(", "\\", "sqrt", "{", "T", "}", ")", "/", "math", "fortrydelsesgr\u00e6nser", "for", "online-versionen", "af", "Support", "vector", "machine", "til", "klassifikation", ",", "som", "bruger", "h\u00e6ngselstabet", "math", "v", "_t", "(", "w", ")", "=", "\\", "max", "\\", "{", "0", ",", "1", "-", "y", "_t", "(", "w", "\\", "cdot", "x", "_t)", "\\", "}", "/", "math"], "sentence-detokenized": "Man kan bruge OSD-algoritmen til at udlede math O (\\ sqrt {T}) / math fortrydelsesgr\u00e6nser for online-versionen af Support vector machine til klassifikation, som bruger h\u00e6ngselstabet math v _t (w) =\\ max\\ {0, 1 - y _t (w\\ cdot x _t)\\} / math", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 28], [29, 32], [33, 35], [36, 42], [43, 47], [48, 49], [50, 51], [51, 52], [53, 57], [58, 59], [59, 60], [60, 61], [61, 62], [63, 64], [65, 69], [70, 89], [90, 93], [94, 110], [111, 113], [114, 121], [122, 128], [129, 136], [137, 140], [141, 155], [155, 156], [157, 160], [161, 167], [168, 181], [182, 186], [187, 188], [189, 191], [192, 193], [193, 194], [194, 195], [196, 197], [197, 198], [199, 202], [202, 203], [204, 205], [205, 206], [206, 207], [208, 209], [210, 211], [212, 213], [214, 216], [217, 218], [218, 219], [219, 220], [221, 225], [226, 227], [228, 231], [231, 232], [232, 233], [234, 235], [236, 240]]}
{"doc_key": "ai-train-22", "ner": [[2, 2, "task"], [4, 4, "task"], [6, 6, "task"], [8, 8, "task"], [10, 10, "task"], [12, 12, "task"], [14, 14, "task"], [16, 19, "task"], [21, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Anvendelserne", "omfatter", "objektgenkendelse", ",", "robotkortl\u00e6gning", "og", "-navigation", ",", "billedstitching", ",", "3D-modellering", ",", "gestusgenkendelse", ",", "videosporing", ",", "individuel", "identifikation", "af", "dyreliv", "og", "match", "moving", "."], "sentence-detokenized": "Anvendelserne omfatter objektgenkendelse, robotkortl\u00e6gning og -navigation, billedstitching, 3D-modellering, gestusgenkendelse, videosporing, individuel identifikation af dyreliv og match moving.", "token2charspan": [[0, 13], [14, 22], [23, 40], [40, 41], [42, 58], [59, 61], [62, 73], [73, 74], [75, 90], [90, 91], [92, 106], [106, 107], [108, 125], [125, 126], [127, 139], [139, 140], [141, 151], [152, 166], [167, 169], [170, 177], [178, 180], [181, 186], [187, 193], [193, 194]]}
{"doc_key": "ai-train-23", "ner": [[7, 7, "task"], [12, 13, "university"], [15, 17, "university"], [19, 20, "university"], [22, 23, "university"], [25, 30, "university"], [32, 34, "university"], [36, 38, "university"], [40, 41, "university"], [43, 48, "university"], [50, 50, "university"], [53, 57, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[7, 7, 12, 13, "related-to", "", true, false], [7, 7, 15, 17, "related-to", "", true, false], [7, 7, 19, 20, "related-to", "", true, false], [7, 7, 22, 23, "related-to", "", true, false], [7, 7, 25, 30, "related-to", "", true, false], [7, 7, 32, 34, "related-to", "", true, false], [7, 7, 36, 38, "related-to", "", true, false], [7, 7, 40, 41, "related-to", "", true, false], [7, 7, 43, 48, "related-to", "", true, false], [7, 7, 50, 50, "related-to", "", true, false], [7, 7, 53, 57, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["En", "r\u00e6kke", "grupper", "og", "virksomheder", "forsker", "i", "posesk\u00f8n", ",", "herunder", "grupper", "p\u00e5", "Brown", "University", ",", "Carnegie", "Mellon", "University", ",", "MPI", "Saarbr\u00fccken", ",", "Stanford", "University", ",", "University", "of", "California", ",", "San", "Diego", ",", "University", "of", "Toronto", ",", "\u00c9cole", "Centrale", "Paris", ",", "ETH", "Z\u00fcrich", ",", "National", "University", "of", "Sciences", "and", "Technology", "(", "NUST", ")", "og", "University", "of", "California", ",", "Irvine", "."], "sentence-detokenized": "En r\u00e6kke grupper og virksomheder forsker i posesk\u00f8n, herunder grupper p\u00e5 Brown University, Carnegie Mellon University, MPI Saarbr\u00fccken, Stanford University, University of California, San Diego, University of Toronto, \u00c9cole Centrale Paris, ETH Z\u00fcrich, National University of Sciences and Technology (NUST) og University of California, Irvine.", "token2charspan": [[0, 2], [3, 8], [9, 16], [17, 19], [20, 32], [33, 40], [41, 42], [43, 51], [51, 52], [53, 61], [62, 69], [70, 72], [73, 78], [79, 89], [89, 90], [91, 99], [100, 106], [107, 117], [117, 118], [119, 122], [123, 134], [134, 135], [136, 144], [145, 155], [155, 156], [157, 167], [168, 170], [171, 181], [181, 182], [183, 186], [187, 192], [192, 193], [194, 204], [205, 207], [208, 215], [215, 216], [217, 222], [223, 231], [232, 237], [237, 238], [239, 242], [243, 249], [249, 250], [251, 259], [260, 270], [271, 273], [274, 282], [283, 286], [287, 297], [298, 299], [299, 303], [303, 304], [305, 307], [308, 318], [319, 321], [322, 332], [332, 333], [334, 340], [340, 341]]}
{"doc_key": "ai-train-24", "ner": [[0, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sigmoid-funktionen", "Cross", "entropy", "loss", "bruges", "til", "at", "forudsige", "K", "uafh\u00e6ngige", "sandsynlighedsv\u00e6rdier", "i", "math", "0,1", "/", "math", "."], "sentence-detokenized": "Sigmoid-funktionen Cross entropy loss bruges til at forudsige K uafh\u00e6ngige sandsynlighedsv\u00e6rdier i math 0,1 / math.", "token2charspan": [[0, 18], [19, 24], [25, 32], [33, 37], [38, 44], [45, 48], [49, 51], [52, 61], [62, 63], [64, 74], [75, 96], [97, 98], [99, 103], [104, 107], [108, 109], [110, 114], [114, 115]]}
{"doc_key": "ai-train-25", "ner": [[2, 3, "misc"], [5, 5, "field"], [7, 7, "field"], [9, 11, "university"], [13, 13, "country"], [15, 15, "misc"], [17, 20, "university"], [22, 22, "country"], [29, 29, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 3, 5, 5, "topic", "", false, false], [2, 3, 7, 7, "topic", "", false, false], [2, 3, 9, 11, "physical", "", true, false], [9, 11, 13, 13, "physical", "", false, false], [15, 15, 17, 20, "physical", "", true, false], [17, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Han", "havde", "Johann", "Bernoulli-l\u00e6restolen", "i", "matematik", "og", "informatik", "p\u00e5", "universitetet", "i", "Groningen", "i", "Nederlandene", "og", "Toshiba-l\u00e6restolen", "p\u00e5", "Tokyo", "Institute", "of", "Technology", "i", "Japan", ",", "f\u00f8r", "han", "blev", "professor", "p\u00e5", "Cambridge", "."], "sentence-detokenized": "Han havde Johann Bernoulli-l\u00e6restolen i matematik og informatik p\u00e5 universitetet i Groningen i Nederlandene og Toshiba-l\u00e6restolen p\u00e5 Tokyo Institute of Technology i Japan, f\u00f8r han blev professor p\u00e5 Cambridge.", "token2charspan": [[0, 3], [4, 9], [10, 16], [17, 37], [38, 39], [40, 49], [50, 52], [53, 63], [64, 66], [67, 80], [81, 82], [83, 92], [93, 94], [95, 107], [108, 110], [111, 129], [130, 132], [133, 138], [139, 148], [149, 151], [152, 162], [163, 164], [165, 170], [170, 171], [172, 175], [176, 179], [180, 184], [185, 194], [195, 197], [198, 207], [207, 208]]}
{"doc_key": "ai-train-26", "ner": [[8, 9, "algorithm"], [15, 18, "algorithm"], [23, 24, "researcher"], [26, 27, "researcher"]], "ner_mapping_to_source": [0, 1, 3, 4], "relations": [[8, 9, 15, 18, "usage", "", true, false], [15, 18, 23, 24, "origin", "", false, false], [15, 18, 26, 27, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["En", "anden", "teknik", ",", "der", "is\u00e6r", "anvendes", "til", "tilbagevendende", "neurale", "netv\u00e6rk", ",", "er", "LSTM-netv\u00e6rket", "(", "Long", "Short", "Term", "Memory", ")", "fra", "1997", "af", "Sepp", "Hochreiter", "og", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "En anden teknik, der is\u00e6r anvendes til tilbagevendende neurale netv\u00e6rk, er LSTM-netv\u00e6rket (Long Short Term Memory) fra 1997 af Sepp Hochreiter og J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 2], [3, 8], [9, 15], [15, 16], [17, 20], [21, 25], [26, 34], [35, 38], [39, 54], [55, 62], [63, 70], [70, 71], [72, 74], [75, 89], [90, 91], [91, 95], [96, 101], [102, 106], [107, 113], [113, 114], [115, 118], [119, 123], [124, 126], [127, 131], [132, 142], [143, 145], [146, 152], [153, 164], [164, 165]]}
{"doc_key": "ai-train-27", "ner": [[5, 5, "product"], [10, 10, "product"], [39, 39, "product"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[5, 5, 10, 10, "named", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Medtagelsen", "af", "en", "C++-fortolker", "(", "CINT", "indtil", "version", "5.34", ",", "Cling", "fra", "version", "6", ")", "g\u00f8r", "denne", "pakke", "meget", "alsidig", ",", "da", "den", "kan", "bruges", "i", "interaktive", ",", "scriptede", "og", "kompilerede", "tilstande", "p\u00e5", "samme", "m\u00e5de", "som", "kommercielle", "produkter", "som", "MATLAB", "."], "sentence-detokenized": "Medtagelsen af en C++-fortolker (CINT indtil version 5.34, Cling fra version 6) g\u00f8r denne pakke meget alsidig, da den kan bruges i interaktive, scriptede og kompilerede tilstande p\u00e5 samme m\u00e5de som kommercielle produkter som MATLAB.", "token2charspan": [[0, 11], [12, 14], [15, 17], [18, 31], [32, 33], [33, 37], [38, 44], [45, 52], [53, 57], [57, 58], [59, 64], [65, 68], [69, 76], [77, 78], [78, 79], [80, 83], [84, 89], [90, 95], [96, 101], [102, 109], [109, 110], [111, 113], [114, 117], [118, 121], [122, 128], [129, 130], [131, 142], [142, 143], [144, 153], [154, 156], [157, 168], [169, 178], [179, 181], [182, 187], [188, 192], [193, 196], [197, 209], [210, 219], [220, 223], [224, 230], [230, 231]]}
{"doc_key": "ai-train-28", "ner": [[6, 6, "product"], [24, 24, "field"], [29, 31, "task"], [33, 36, "task"], [38, 38, "task"], [40, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 6, 24, 24, "related-to", "", false, false], [29, 31, 24, 24, "part-of", "", false, false], [33, 36, 24, 24, "part-of", "", false, false], [38, 38, 24, 24, "part-of", "", false, false], [40, 40, 24, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Det", "er", "en", "udfordring", "at", "designe", "stemmebrugergr\u00e6nseflader", ",", "der", "fortolker", "og", "h\u00e5ndterer", "samtalestatus", ",", "p\u00e5", "grund", "af", "den", "iboende", "vanskelighed", "ved", "at", "integrere", "komplekse", "naturlige", "sprogbehandlingsopgaver", "som", "f.eks", ".", "opl\u00f8sning", "af", "kerneferencer", ",", "genkendelse", "af", "navngivne", "enheder", ",", "informationss\u00f8gning", "og", "dialogstyring", "."], "sentence-detokenized": "Det er en udfordring at designe stemmebrugergr\u00e6nseflader, der fortolker og h\u00e5ndterer samtalestatus, p\u00e5 grund af den iboende vanskelighed ved at integrere komplekse naturlige sprogbehandlingsopgaver som f.eks. opl\u00f8sning af kerneferencer, genkendelse af navngivne enheder, informationss\u00f8gning og dialogstyring.", "token2charspan": [[0, 3], [4, 6], [7, 9], [10, 20], [21, 23], [24, 31], [32, 56], [56, 57], [58, 61], [62, 71], [72, 74], [75, 84], [85, 98], [98, 99], [100, 102], [103, 108], [109, 111], [112, 115], [116, 123], [124, 136], [137, 140], [141, 143], [144, 153], [154, 163], [164, 173], [174, 197], [198, 201], [202, 207], [207, 208], [209, 218], [219, 221], [222, 235], [235, 236], [237, 248], [249, 251], [252, 261], [262, 269], [269, 270], [271, 290], [291, 293], [294, 307], [307, 308]]}
{"doc_key": "ai-train-29", "ner": [[6, 7, "algorithm"], [10, 12, "algorithm"], [19, 20, "researcher"], [24, 27, "organisation"], [35, 35, "field"], [37, 37, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 7, 19, 20, "origin", "", false, false], [6, 7, 35, 35, "part-of", "", false, false], [6, 7, 37, 37, "part-of", "", false, false], [10, 12, 19, 20, "origin", "", false, false], [10, 12, 35, 35, "part-of", "", false, false], [10, 12, 37, 37, "part-of", "", false, false], [19, 20, 24, 27, "physical", "", false, false], [19, 20, 24, 27, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Mellem", "2009", "og", "2012", "har", "de", "recurrent", "neural", "networks", "og", "deep", "feedforward", "neural", "networks", ",", "der", "er", "udviklet", "i", "J\u00fcrgen", "Schmidhuber's", "forskningsgruppe", "p\u00e5", "det", "schweiziske", "AI", "Lab", "IDSIA", ",", "vundet", "otte", "internationale", "konkurrencer", "inden", "for", "m\u00f8nstergenkendelse", "og", "maskinl\u00e6ring", "."], "sentence-detokenized": "Mellem 2009 og 2012 har de recurrent neural networks og deep feedforward neural networks, der er udviklet i J\u00fcrgen Schmidhuber's forskningsgruppe p\u00e5 det schweiziske AI Lab IDSIA, vundet otte internationale konkurrencer inden for m\u00f8nstergenkendelse og maskinl\u00e6ring.", "token2charspan": [[0, 6], [7, 11], [12, 14], [15, 19], [20, 23], [24, 26], [27, 36], [37, 43], [44, 52], [53, 55], [56, 60], [61, 72], [73, 79], [80, 88], [88, 89], [90, 93], [94, 96], [97, 105], [106, 107], [108, 114], [115, 128], [129, 145], [146, 148], [149, 152], [153, 164], [165, 167], [168, 171], [172, 177], [177, 178], [179, 185], [186, 190], [191, 205], [206, 218], [219, 224], [225, 228], [229, 247], [248, 250], [251, 263], [263, 264]]}
{"doc_key": "ai-train-30", "ner": [[1, 1, "product"], [4, 5, "product"], [7, 7, "product"], [12, 12, "task"], [14, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 4, 5, "usage", "", false, false], [1, 1, 7, 7, "usage", "", false, false], [1, 1, 12, 12, "usage", "", true, false], [1, 1, 14, 14, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Moderne", "Windows-skrivebordssystemer", "kan", "bruge", "SAPI", "4-", "og", "SAPI", "5-komponenter", "til", "at", "underst\u00f8tte", "talesyntese", "og", "tale", "."], "sentence-detokenized": "Moderne Windows-skrivebordssystemer kan bruge SAPI 4- og SAPI 5-komponenter til at underst\u00f8tte talesyntese og tale.", "token2charspan": [[0, 7], [8, 35], [36, 39], [40, 45], [46, 50], [51, 53], [54, 56], [57, 61], [62, 75], [76, 79], [80, 82], [83, 94], [95, 106], [107, 109], [110, 114], [114, 115]]}
{"doc_key": "ai-train-31", "ner": [[6, 11, "misc"], [13, 13, "field"], [15, 17, "university"], [24, 27, "field"], [29, 32, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 11, 13, 13, "topic", "topic_of_award", false, false], [6, 11, 15, 17, "origin", "", true, false], [24, 27, 29, 32, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Han", "modtog", "to", "\u00e6resgrader", ",", "en", "S.", "V.", "della", "laurea", "ad", "honorem", "i", "psykologi", "fra", "universitetet", "i", "Padova", "i", "1995", "og", "en", "doktorgrad", "i", "industrielt", "design", "og", "ingeni\u00f8rvidenskab", "fra", "Delft", "University", "of", "Technology", "."], "sentence-detokenized": "Han modtog to \u00e6resgrader, en S. V. della laurea ad honorem i psykologi fra universitetet i Padova i 1995 og en doktorgrad i industrielt design og ingeni\u00f8rvidenskab fra Delft University of Technology.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 24], [24, 25], [26, 28], [29, 31], [32, 34], [35, 40], [41, 47], [48, 50], [51, 58], [59, 60], [61, 70], [71, 74], [75, 88], [89, 90], [91, 97], [98, 99], [100, 104], [105, 107], [108, 110], [111, 121], [122, 123], [124, 135], [136, 142], [143, 145], [146, 163], [164, 167], [168, 173], [174, 184], [185, 187], [188, 198], [198, 199]]}
{"doc_key": "ai-train-32", "ner": [[5, 6, "researcher"], [11, 12, "organisation"], [14, 14, "location"], [17, 17, "researcher"], [26, 26, "misc"], [40, 41, "misc"], [58, 59, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 6, 11, 12, "physical", "", false, false], [5, 6, 11, 12, "role", "", false, false], [11, 12, 14, 14, "physical", "", false, false], [17, 17, 26, 26, "related-to", "works_with", true, false], [17, 17, 40, 41, "related-to", "works_with", true, false], [17, 17, 58, 59, "related-to", "works_with", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sammen", "med", "sin", "mange\u00e5rige", "samarbejdspartner", "Laurent", "Cohen", ",", "en", "neurolog", "ved", "Piti\u00e9-Salp\u00eatri\u00e8re", "hospitalet", "i", "Paris", ",", "identificerede", "Dehaene", "ogs\u00e5", "patienter", "med", "l\u00e6sioner", "i", "forskellige", "regioner", "af", "parietallappen", "med", "nedsat", "multiplikation", ",", "men", "bevaret", "subtraktion", "(", "forbundet", "med", "l\u00e6sioner", "i", "den", "nedre", "parietallap", ")", "og", "andre", "med", "nedsat", "subtraktion", ",", "men", "bevaret", "multiplikation", "(", "forbundet", "med", "l\u00e6sioner", "i", "den", "intraparietale", "sulcus", ")", "."], "sentence-detokenized": "Sammen med sin mange\u00e5rige samarbejdspartner Laurent Cohen, en neurolog ved Piti\u00e9-Salp\u00eatri\u00e8re hospitalet i Paris, identificerede Dehaene ogs\u00e5 patienter med l\u00e6sioner i forskellige regioner af parietallappen med nedsat multiplikation, men bevaret subtraktion (forbundet med l\u00e6sioner i den nedre parietallap) og andre med nedsat subtraktion, men bevaret multiplikation (forbundet med l\u00e6sioner i den intraparietale sulcus).", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 25], [26, 43], [44, 51], [52, 57], [57, 58], [59, 61], [62, 70], [71, 74], [75, 92], [93, 103], [104, 105], [106, 111], [111, 112], [113, 127], [128, 135], [136, 140], [141, 150], [151, 154], [155, 163], [164, 165], [166, 177], [178, 186], [187, 189], [190, 204], [205, 208], [209, 215], [216, 230], [230, 231], [232, 235], [236, 243], [244, 255], [256, 257], [257, 266], [267, 270], [271, 279], [280, 281], [282, 285], [286, 291], [292, 303], [303, 304], [305, 307], [308, 313], [314, 317], [318, 324], [325, 336], [336, 337], [338, 341], [342, 349], [350, 364], [365, 366], [366, 375], [376, 379], [380, 388], [389, 390], [391, 394], [395, 409], [410, 416], [416, 417], [417, 418]]}
{"doc_key": "ai-train-33", "ner": [[7, 9, "product"], [13, 15, "misc"], [17, 18, "misc"], [21, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 15, 7, 9, "topic", "", false, false], [17, 18, 7, 9, "topic", "", false, false], [21, 22, 7, 9, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["P\u00e5", "det", "seneste", "har", "fiktive", "fremstillinger", "af", "kunstigt", "intelligente", "robotter", "i", "film", "som", "A.I.", "Artificial", "Intelligence", "og", "Ex", "Machina", "og", "tv-filmen", "Westworld", "fra", "2016", "vakt", "publikums", "sympati", "for", "robotterne", "selv", "."], "sentence-detokenized": "P\u00e5 det seneste har fiktive fremstillinger af kunstigt intelligente robotter i film som A.I. Artificial Intelligence og Ex Machina og tv-filmen Westworld fra 2016 vakt publikums sympati for robotterne selv.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 18], [19, 26], [27, 41], [42, 44], [45, 53], [54, 66], [67, 75], [76, 77], [78, 82], [83, 86], [87, 91], [92, 102], [103, 115], [116, 118], [119, 121], [122, 129], [130, 132], [133, 142], [143, 152], [153, 156], [157, 161], [162, 166], [167, 176], [177, 184], [185, 188], [189, 199], [200, 204], [204, 205]]}
{"doc_key": "ai-train-34", "ner": [[9, 10, "field"], [13, 13, "algorithm"], [15, 15, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 13, 9, 10, "part-of", "", false, false], [15, 15, 9, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["To", "af", "de", "vigtigste", "metoder", ",", "der", "anvendes", "i", "uoverv\u00e5get", "indl\u00e6ring", ",", "er", "hovedkomponentanalyse", "og", "klyngeanalyse", "."], "sentence-detokenized": "To af de vigtigste metoder, der anvendes i uoverv\u00e5get indl\u00e6ring, er hovedkomponentanalyse og klyngeanalyse.", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 18], [19, 26], [26, 27], [28, 31], [32, 40], [41, 42], [43, 53], [54, 63], [63, 64], [65, 67], [68, 89], [90, 92], [93, 106], [106, 107]]}
{"doc_key": "ai-train-35", "ner": [[0, 2, "organisation"], [18, 19, "misc"], [24, 25, "misc"], [27, 29, "person"], [34, 35, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[18, 19, 0, 2, "artifact", "", false, false], [24, 25, 0, 2, "artifact", "", false, false], [24, 25, 27, 29, "role", "director_of", false, false], [24, 25, 34, 35, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Walt", "Disney", "Company", "begyndte", "ogs\u00e5", "at", "bruge", "3D-film", "mere", "markant", "p\u00e5", "s\u00e6rlige", "steder", "for", "at", "imponere", "publikum", "med", "Magic", "Journeys", "(", "1982", ")", "og", "Captain", "EO", "(", "Francis", "Ford", "Coppola", ",", "1986", ",", "med", "Michael", "Jackson", "i", "hovedrollen", ")", "som", "bem\u00e6rkelsesv\u00e6rdige", "eksempler", "."], "sentence-detokenized": "Walt Disney Company begyndte ogs\u00e5 at bruge 3D-film mere markant p\u00e5 s\u00e6rlige steder for at imponere publikum med Magic Journeys (1982) og Captain EO (Francis Ford Coppola, 1986, med Michael Jackson i hovedrollen) som bem\u00e6rkelsesv\u00e6rdige eksempler.", "token2charspan": [[0, 4], [5, 11], [12, 19], [20, 28], [29, 33], [34, 36], [37, 42], [43, 50], [51, 55], [56, 63], [64, 66], [67, 74], [75, 81], [82, 85], [86, 88], [89, 97], [98, 106], [107, 110], [111, 116], [117, 125], [126, 127], [127, 131], [131, 132], [133, 135], [136, 143], [144, 146], [147, 148], [148, 155], [156, 160], [161, 168], [168, 169], [170, 174], [174, 175], [176, 179], [180, 187], [188, 195], [196, 197], [198, 209], [209, 210], [211, 214], [215, 233], [234, 243], [243, 244]]}
{"doc_key": "ai-train-36", "ner": [[8, 9, "field"], [15, 16, "task"], [18, 19, "task"], [21, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 16, 8, 9, "part-of", "", false, false], [18, 19, 8, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Siden", "2002", "er", "perceptrontr\u00e6ning", "blevet", "popul\u00e6r", "inden", "for", "naturlig", "sprogbehandling", "til", "opgaver", "som", "f.eks", ".", "part-of-speech", "tagging", "og", "syntaktisk", "parsing", "(", "Collins", ",", "2002", ")", "."], "sentence-detokenized": "Siden 2002 er perceptrontr\u00e6ning blevet popul\u00e6r inden for naturlig sprogbehandling til opgaver som f.eks. part-of-speech tagging og syntaktisk parsing (Collins, 2002).", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 31], [32, 38], [39, 46], [47, 52], [53, 56], [57, 65], [66, 81], [82, 85], [86, 93], [94, 97], [98, 103], [103, 104], [105, 119], [120, 127], [128, 130], [131, 141], [142, 149], [150, 151], [151, 158], [158, 159], [160, 164], [164, 165], [165, 166]]}
{"doc_key": "ai-train-37", "ner": [[2, 2, "product"], [8, 12, "organisation"], [14, 15, "organisation"], [17, 17, "country"], [21, 24, "product"], [28, 29, "researcher"], [38, 38, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[8, 12, 2, 2, "role", "introduces_to_market", true, false], [14, 15, 2, 2, "role", "introduces_to_market", true, false], [14, 15, 17, 17, "physical", "", false, false], [21, 24, 38, 38, "related-to", "sold_to", true, false], [28, 29, 21, 24, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Den", "f\u00f8rste", "palleteringsrobot", "blev", "introduceret", "i", "1963", "af", "Fuji", "Yusoki", "Kogyo", "Company", ".", "af", "KUKA", "robotics", "i", "Tyskland", ",", "og", "den", "programmerbare", "universalmaskine", "til", "samling", "blev", "opfundet", "af", "Victor", "Scheinman", "i", "1976", ",", "og", "designet", "blev", "solgt", "til", "Unimation", "."], "sentence-detokenized": "Den f\u00f8rste palleteringsrobot blev introduceret i 1963 af Fuji Yusoki Kogyo Company. af KUKA robotics i Tyskland, og den programmerbare universalmaskine til samling blev opfundet af Victor Scheinman i 1976, og designet blev solgt til Unimation.", "token2charspan": [[0, 3], [4, 10], [11, 28], [29, 33], [34, 46], [47, 48], [49, 53], [54, 56], [57, 61], [62, 68], [69, 74], [75, 82], [82, 83], [84, 86], [87, 91], [92, 100], [101, 102], [103, 111], [111, 112], [113, 115], [116, 119], [120, 134], [135, 151], [152, 155], [156, 163], [164, 168], [169, 177], [178, 180], [181, 187], [188, 197], [198, 199], [200, 204], [204, 205], [206, 208], [209, 217], [218, 222], [223, 228], [229, 232], [233, 242], [242, 243]]}
{"doc_key": "ai-train-38", "ner": [[10, 10, "conference"], [13, 13, "researcher"], [20, 20, "field"], [36, 37, "researcher"], [45, 46, "researcher"], [61, 61, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 13, 10, 10, "role", "president_of", false, false], [13, 13, 36, 37, "role", "colleagues", false, false], [20, 20, 61, 61, "named", "same", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["I", "midten", "af", "1990'erne", ",", "mens", "han", "var", "formand", "for", "AAAI", ",", "indledte", "Hayes", "en", "r\u00e6kke", "angreb", "p\u00e5", "kritikere", "af", "AI", ",", "som", "for", "det", "meste", "var", "ironisk", "formuleret", ",", "og", "(", "sammen", "med", "sin", "kollega", "Kenneth", "Ford", ")", "opfandt", "han", "en", "pris", "opkaldt", "efter", "Simon", "Newcomb", ",", "som", "skulle", "uddeles", "til", "det", "mest", "latterlige", "argument", ",", "der", "modbeviser", "muligheden", "for", "AI", "."], "sentence-detokenized": "I midten af 1990'erne, mens han var formand for AAAI, indledte Hayes en r\u00e6kke angreb p\u00e5 kritikere af AI, som for det meste var ironisk formuleret, og (sammen med sin kollega Kenneth Ford) opfandt han en pris opkaldt efter Simon Newcomb, som skulle uddeles til det mest latterlige argument, der modbeviser muligheden for AI.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 21], [21, 22], [23, 27], [28, 31], [32, 35], [36, 43], [44, 47], [48, 52], [52, 53], [54, 62], [63, 68], [69, 71], [72, 77], [78, 84], [85, 87], [88, 97], [98, 100], [101, 103], [103, 104], [105, 108], [109, 112], [113, 116], [117, 122], [123, 126], [127, 134], [135, 145], [145, 146], [147, 149], [150, 151], [151, 157], [158, 161], [162, 165], [166, 173], [174, 181], [182, 186], [186, 187], [188, 195], [196, 199], [200, 202], [203, 207], [208, 215], [216, 221], [222, 227], [228, 235], [235, 236], [237, 240], [241, 247], [248, 255], [256, 259], [260, 263], [264, 268], [269, 279], [280, 288], [288, 289], [290, 293], [294, 304], [305, 315], [316, 319], [320, 322], [322, 323]]}
{"doc_key": "ai-train-39", "ner": [[15, 15, "algorithm"], [42, 42, "algorithm"], [53, 54, "algorithm"], [58, 58, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 15, 42, 42, "named", "same", false, false], [53, 54, 15, 15, "type-of", "", false, false], [58, 58, 15, 15, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["En", "optimal", "v\u00e6rdi", "for", "math", "\\", "alpha", "/", "math", "kan", "findes", "ved", "hj\u00e6lp", "af", "en", "linjes\u00f8gningsalgoritme", ",", "dvs.", "at", "st\u00f8rrelsen", "af", "math", "\\", "alpha", "/", "math", "bestemmes", "ved", "at", "finde", "den", "v\u00e6rdi", ",", "der", "minimerer", "S", ",", "normalt", "ved", "hj\u00e6lp", "af", "en", "linjes\u00f8gning", "i", "intervallet", "math0", "\\", "alpha", "1", "/", "math", "eller", "en", "backtracking", "linjes\u00f8gning", "som", "f.eks", ".", "armijo-linjes\u00f8gning", "."], "sentence-detokenized": "En optimal v\u00e6rdi for math\\ alpha / math kan findes ved hj\u00e6lp af en linjes\u00f8gningsalgoritme, dvs. at st\u00f8rrelsen af math\\ alpha / math bestemmes ved at finde den v\u00e6rdi, der minimerer S, normalt ved hj\u00e6lp af en linjes\u00f8gning i intervallet math0\\ alpha 1 / math eller en backtracking linjes\u00f8gning som f.eks. armijo-linjes\u00f8gning.", "token2charspan": [[0, 2], [3, 10], [11, 16], [17, 20], [21, 25], [25, 26], [27, 32], [33, 34], [35, 39], [40, 43], [44, 50], [51, 54], [55, 60], [61, 63], [64, 66], [67, 89], [89, 90], [91, 95], [96, 98], [99, 109], [110, 112], [113, 117], [117, 118], [119, 124], [125, 126], [127, 131], [132, 141], [142, 145], [146, 148], [149, 154], [155, 158], [159, 164], [164, 165], [166, 169], [170, 179], [180, 181], [181, 182], [183, 190], [191, 194], [195, 200], [201, 203], [204, 206], [207, 219], [220, 221], [222, 233], [234, 239], [239, 240], [241, 246], [247, 248], [249, 250], [251, 255], [256, 261], [262, 264], [265, 277], [278, 290], [291, 294], [295, 300], [300, 301], [302, 321], [321, 322]]}
{"doc_key": "ai-train-40", "ner": [[2, 3, "algorithm"], [5, 5, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Han", "diskuterer", "Breadth-first", "search-", "og", "Depth-first", "search-teknikker", ",", "men", "konkluderer", "til", "sidst", ",", "at", "resultaterne", "repr\u00e6senterer", "ekspertsystemer", ",", "der", "indeholder", "en", "masse", "teknisk", "viden", ",", "men", "som", "ikke", "belyser", "de", "mentale", "processer", ",", "som", "mennesker", "bruger", "til", "at", "l\u00f8se", "s\u00e5danne", "g\u00e5der", "."], "sentence-detokenized": "Han diskuterer Breadth-first search- og Depth-first search-teknikker, men konkluderer til sidst, at resultaterne repr\u00e6senterer ekspertsystemer, der indeholder en masse teknisk viden, men som ikke belyser de mentale processer, som mennesker bruger til at l\u00f8se s\u00e5danne g\u00e5der.", "token2charspan": [[0, 3], [4, 14], [15, 28], [29, 36], [37, 39], [40, 51], [52, 68], [68, 69], [70, 73], [74, 85], [86, 89], [90, 95], [95, 96], [97, 99], [100, 112], [113, 126], [127, 142], [142, 143], [144, 147], [148, 158], [159, 161], [162, 167], [168, 175], [176, 181], [181, 182], [183, 186], [187, 190], [191, 195], [196, 203], [204, 206], [207, 214], [215, 224], [224, 225], [226, 229], [230, 239], [240, 246], [247, 250], [251, 253], [254, 258], [259, 266], [267, 272], [272, 273]]}
{"doc_key": "ai-train-41", "ner": [[0, 0, "task"], [2, 2, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Taleregenkendelse", "og", "talesyntese", "handler", "om", ",", "hvordan", "talesprog", "kan", "forst\u00e5s", "eller", "skabes", "ved", "hj\u00e6lp", "af", "computere", "."], "sentence-detokenized": "Taleregenkendelse og talesyntese handler om, hvordan talesprog kan forst\u00e5s eller skabes ved hj\u00e6lp af computere.", "token2charspan": [[0, 17], [18, 20], [21, 32], [33, 40], [41, 43], [43, 44], [45, 52], [53, 62], [63, 66], [67, 74], [75, 80], [81, 87], [88, 91], [92, 97], [98, 100], [101, 110], [110, 111]]}
{"doc_key": "ai-train-42", "ner": [[16, 17, "algorithm"], [37, 39, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Denne", "matematik", "\\", "theta", "^", "{", "*", "}", "/", "math", "estimeres", "normalt", "ved", "hj\u00e6lp", "af", "en", "Maximum", "Likelihood", "(", "math", "\\", "theta", "^", "{", "*", "}", "=", "\\", "theta", "^", "{", "ML", "}", "/", "math", ")", "eller", "Maximum", "A", "Posteriori", "(", "math", "\\", "theta", "^", "{", "*", "}", "=", "\\", "theta", "^", "{", "MAP", "}", "/", "math", ")", "procedure", "."], "sentence-detokenized": "Denne matematik\\ theta ^ {*} / math estimeres normalt ved hj\u00e6lp af en Maximum Likelihood (math\\ theta ^ {*} =\\ theta ^ {ML} / math) eller Maximum A Posteriori (math\\ theta ^ {*} =\\ theta ^ {MAP} / math) procedure.", "token2charspan": [[0, 5], [6, 15], [15, 16], [17, 22], [23, 24], [25, 26], [26, 27], [27, 28], [29, 30], [31, 35], [36, 45], [46, 53], [54, 57], [58, 63], [64, 66], [67, 69], [70, 77], [78, 88], [89, 90], [90, 94], [94, 95], [96, 101], [102, 103], [104, 105], [105, 106], [106, 107], [108, 109], [109, 110], [111, 116], [117, 118], [119, 120], [120, 122], [122, 123], [124, 125], [126, 130], [130, 131], [132, 137], [138, 145], [146, 147], [148, 158], [159, 160], [160, 164], [164, 165], [166, 171], [172, 173], [174, 175], [175, 176], [176, 177], [178, 179], [179, 180], [181, 186], [187, 188], [189, 190], [190, 193], [193, 194], [195, 196], [197, 201], [201, 202], [203, 212], [212, 213]]}
{"doc_key": "ai-train-43", "ner": [[6, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Nogle", "mindre", "udbredte", "sprog", "bruger", "open", "source-synthesizeren", "eSpeak", "til", "deres", "tale", ",", "hvilket", "giver", "en", "robotagtig", ",", "akavet", "stemme", ",", "som", "kan", "v\u00e6re", "sv\u00e6r", "at", "forst\u00e5", "."], "sentence-detokenized": "Nogle mindre udbredte sprog bruger open source-synthesizeren eSpeak til deres tale, hvilket giver en robotagtig, akavet stemme, som kan v\u00e6re sv\u00e6r at forst\u00e5.", "token2charspan": [[0, 5], [6, 12], [13, 21], [22, 27], [28, 34], [35, 39], [40, 60], [61, 67], [68, 71], [72, 77], [78, 82], [82, 83], [84, 91], [92, 97], [98, 100], [101, 111], [111, 112], [113, 119], [120, 126], [126, 127], [128, 131], [132, 135], [136, 140], [141, 145], [146, 148], [149, 155], [155, 156]]}
{"doc_key": "ai-train-44", "ner": [[2, 2, "programlang"], [41, 42, "programlang"], [44, 44, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 41, 42, "compare", "", false, false], [2, 2, 44, 44, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Selv", "om", "R", "hovedsagelig", "anvendes", "af", "statistikere", "og", "andre", "praktikere", ",", "der", "har", "brug", "for", "et", "milj\u00f8", "til", "statistiske", "beregninger", "og", "softwareudvikling", ",", "kan", "det", "ogs\u00e5", "fungere", "som", "en", "generel", "v\u00e6rkt\u00f8jskasse", "til", "matrixberegning", "-", "med", "benchmarks", ",", "der", "kan", "sammenlignes", "med", "GNU", "Octave", "eller", "MATLAB", "."], "sentence-detokenized": "Selv om R hovedsagelig anvendes af statistikere og andre praktikere, der har brug for et milj\u00f8 til statistiske beregninger og softwareudvikling, kan det ogs\u00e5 fungere som en generel v\u00e6rkt\u00f8jskasse til matrixberegning - med benchmarks, der kan sammenlignes med GNU Octave eller MATLAB.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 22], [23, 31], [32, 34], [35, 47], [48, 50], [51, 56], [57, 67], [67, 68], [69, 72], [73, 76], [77, 81], [82, 85], [86, 88], [89, 94], [95, 98], [99, 110], [111, 122], [123, 125], [126, 143], [143, 144], [145, 148], [149, 152], [153, 157], [158, 165], [166, 169], [170, 172], [173, 180], [181, 194], [195, 198], [199, 214], [215, 216], [217, 220], [221, 231], [231, 232], [233, 236], [237, 240], [241, 253], [254, 257], [258, 261], [262, 268], [269, 274], [275, 281], [281, 282]]}
{"doc_key": "ai-train-45", "ner": [[0, 1, "algorithm"], [7, 10, "misc"], [11, 12, "researcher"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[0, 1, 11, 12, "origin", "", false, false], [7, 10, 11, 12, "named", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["Heterodyning", "er", "en", "signalbehandlingsteknik", "opfundet", "af", "den", "canadiske", "opfinder", "og", "ingeni\u00f8r", "Reginald", "Fessenden", ",", "der", "skaber", "nye", "frekvenser", "ved", "at", "kombinere", "to", "frekvenser", "."], "sentence-detokenized": "Heterodyning er en signalbehandlingsteknik opfundet af den canadiske opfinder og ingeni\u00f8r Reginald Fessenden, der skaber nye frekvenser ved at kombinere to frekvenser.", "token2charspan": [[0, 12], [13, 15], [16, 18], [19, 42], [43, 51], [52, 54], [55, 58], [59, 68], [69, 77], [78, 80], [81, 89], [90, 98], [99, 108], [108, 109], [110, 113], [114, 120], [121, 124], [125, 135], [136, 139], [140, 142], [143, 152], [153, 155], [156, 166], [166, 167]]}
{"doc_key": "ai-train-46", "ner": [[19, 19, "person"], [21, 21, "misc"], [25, 27, "organisation"], [30, 30, "organisation"], [31, 33, "misc"], [35, 36, "person"], [38, 38, "organisation"], [39, 41, "misc"], [43, 44, "person"], [46, 47, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[19, 19, 21, 21, "role", "actor_in", false, false], [21, 21, 25, 27, "artifact", "", false, false], [31, 33, 30, 30, "artifact", "", false, false], [35, 36, 31, 33, "role", "actor_in", false, false], [39, 41, 38, 38, "artifact", "", false, false], [43, 44, 39, 41, "role", "actor_in", false, false], [46, 47, 39, 41, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Flere", "andre", "film", ",", "der", "var", "med", "til", "at", "s\u00e6tte", "3D", "p\u00e5", "landkortet", "igen", "i", "den", "m\u00e5ned", ",", "var", "John", "Wayne-filmen", "Hondo", "(", "distribueret", "af", "Warner", "Bros", ".", ")", ",", "Columbia's", "Miss", "Sadie", "Thompson", "med", "Rita", "Hayworth", "og", "Paramount's", "Money", "From", "Home", "med", "Dean", "Martin", "og", "Jerry", "Lewis", "."], "sentence-detokenized": "Flere andre film, der var med til at s\u00e6tte 3D p\u00e5 landkortet igen i den m\u00e5ned, var John Wayne-filmen Hondo (distribueret af Warner Bros. ), Columbia's Miss Sadie Thompson med Rita Hayworth og Paramount's Money From Home med Dean Martin og Jerry Lewis.", "token2charspan": [[0, 5], [6, 11], [12, 16], [16, 17], [18, 21], [22, 25], [26, 29], [30, 33], [34, 36], [37, 42], [43, 45], [46, 48], [49, 59], [60, 64], [65, 66], [67, 70], [71, 76], [76, 77], [78, 81], [82, 86], [87, 99], [100, 105], [106, 107], [107, 119], [120, 122], [123, 129], [130, 134], [134, 135], [136, 137], [137, 138], [139, 149], [150, 154], [155, 160], [161, 169], [170, 173], [174, 178], [179, 187], [188, 190], [191, 202], [203, 208], [209, 213], [214, 218], [219, 222], [223, 227], [228, 234], [235, 237], [238, 243], [244, 249], [249, 250]]}
{"doc_key": "ai-train-47", "ner": [[0, 1, "product"], [3, 3, "field"], [6, 9, "task"], [15, 15, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 6, 9, "general-affiliation", "", false, false], [0, 1, 15, 15, "artifact", "", false, false], [6, 9, 3, 3, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["DeepFace", "er", "et", "dybt", "l\u00e6ringssystem", "til", "ansigtsgenkendelse", ",", "der", "er", "udviklet", "af", "en", "forskningsgruppe", "p\u00e5", "Facebook", "."], "sentence-detokenized": "DeepFace er et dybt l\u00e6ringssystem til ansigtsgenkendelse, der er udviklet af en forskningsgruppe p\u00e5 Facebook.", "token2charspan": [[0, 8], [9, 11], [12, 14], [15, 19], [20, 33], [34, 37], [38, 56], [56, 57], [58, 61], [62, 64], [65, 73], [74, 76], [77, 79], [80, 96], [97, 99], [100, 108], [108, 109]]}
{"doc_key": "ai-train-48", "ner": [[0, 1, "field"], [6, 6, "conference"], [13, 13, "field"], [20, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 13, 13, "part-of", "subfield", false, false], [6, 6, 0, 1, "topic", "", false, false], [20, 23, 0, 1, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Geometribehandling", "er", "et", "almindeligt", "forskningsemne", "p\u00e5", "SIGGRAPH", ",", "den", "f\u00f8rende", "akademiske", "konference", "om", "computergrafik", ",", "og", "hovedemnet", "for", "det", "\u00e5rlige", "Symposium", "on", "Geometry", "Processing", "."], "sentence-detokenized": "Geometribehandling er et almindeligt forskningsemne p\u00e5 SIGGRAPH, den f\u00f8rende akademiske konference om computergrafik, og hovedemnet for det \u00e5rlige Symposium on Geometry Processing.", "token2charspan": [[0, 18], [19, 21], [22, 24], [25, 36], [37, 51], [52, 54], [55, 63], [63, 64], [65, 68], [69, 76], [77, 87], [88, 98], [99, 101], [102, 116], [116, 117], [118, 120], [121, 131], [132, 135], [136, 139], [140, 146], [147, 156], [157, 159], [160, 168], [169, 179], [179, 180]]}
{"doc_key": "ai-train-49", "ner": [[0, 2, "task"], [4, 4, "task"], [15, 17, "algorithm"], [13, 13, "algorithm"], [22, 24, "algorithm"], [20, 20, "algorithm"], [29, 31, "algorithm"], [27, 27, "algorithm"], [39, 40, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 9], "relations": [[13, 13, 15, 17, "named", "", false, false], [20, 20, 22, 24, "named", "", false, false], [27, 27, 29, 31, "named", "", false, false]], "relations_mapping_to_source": [1, 3, 5], "sentence": ["Udtr\u00e6kning", "af", "kendetegn", "og", "dimensionsreduktion", "kan", "kombineres", "i", "\u00e9t", "trin", "ved", "hj\u00e6lp", "af", "PCA", "(", "Principal", "Component", "Analysis", ")", ",", "LDA", "(", "linear", "discriminant", "analysis", ")", "eller", "CCA", "(", "canonical", "correlation", "analysis", ")", "som", "et", "forbehandlingstrin", ",", "efterfulgt", "af", "k", "-NN-gruppering", "p\u00e5", "kendetegnets", "vektorer", "i", "et", "rum", "med", "reduceret", "dimension", "."], "sentence-detokenized": "Udtr\u00e6kning af kendetegn og dimensionsreduktion kan kombineres i \u00e9t trin ved hj\u00e6lp af PCA (Principal Component Analysis), LDA (linear discriminant analysis) eller CCA (canonical correlation analysis) som et forbehandlingstrin, efterfulgt af k -NN-gruppering p\u00e5 kendetegnets vektorer i et rum med reduceret dimension.", "token2charspan": [[0, 10], [11, 13], [14, 23], [24, 26], [27, 46], [47, 50], [51, 61], [62, 63], [64, 66], [67, 71], [72, 75], [76, 81], [82, 84], [85, 88], [89, 90], [90, 99], [100, 109], [110, 118], [118, 119], [119, 120], [121, 124], [125, 126], [126, 132], [133, 145], [146, 154], [154, 155], [156, 161], [162, 165], [166, 167], [167, 176], [177, 188], [189, 197], [197, 198], [199, 202], [203, 205], [206, 224], [224, 225], [226, 236], [237, 239], [240, 241], [242, 256], [257, 259], [260, 272], [273, 281], [282, 283], [284, 286], [287, 290], [291, 294], [295, 304], [305, 314], [314, 315]]}
{"doc_key": "ai-train-50", "ner": [[0, 3, "algorithm"], [10, 10, "field"], [12, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 10, 10, "related-to", "good_at", true, false], [0, 3, 12, 12, "related-to", "good_at", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Kunstige", "neurale", "netv\u00e6rk", "er", "beregningsmodeller", ",", "der", "er", "fremragende", "til", "maskinl\u00e6ring", "og", "m\u00f8nstergenkendelse", "."], "sentence-detokenized": "Kunstige neurale netv\u00e6rk er beregningsmodeller, der er fremragende til maskinl\u00e6ring og m\u00f8nstergenkendelse.", "token2charspan": [[0, 8], [9, 16], [17, 24], [25, 27], [28, 46], [46, 47], [48, 51], [52, 54], [55, 66], [67, 70], [71, 83], [84, 86], [87, 105], [105, 106]]}
{"doc_key": "ai-train-51", "ner": [[1, 2, "researcher"], [4, 5, "researcher"], [7, 11, "misc"], [13, 17, "conference"], [19, 19, "conference"], [33, 36, "algorithm"], [37, 38, "researcher"], [40, 41, "researcher"], [43, 49, "misc"], [51, 60, "conference"], [62, 62, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[7, 11, 1, 2, "artifact", "", false, false], [7, 11, 4, 5, "artifact", "", false, false], [7, 11, 13, 17, "temporal", "", false, false], [19, 19, 13, 17, "named", "", false, false], [43, 49, 33, 36, "topic", "", false, false], [43, 49, 37, 38, "artifact", "", false, false], [43, 49, 40, 41, "artifact", "", false, false], [43, 49, 51, 60, "temporal", "", false, false], [62, 62, 51, 60, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": [",", "C.", "Papageorgiou", "og", "T.", "Poggio", ",", "A", "Trainable", "Pedestrian", "Detection", "system", ",", "International", "Journal", "of", "Computer", "Vision", "(", "IJCV", ")", ",", "side", "1", ":", "15-33", ",", "2000", "andre", "bruger", "lokale", "tr\u00e6k", "som", "histogrammer", "af", "orienterede", "gradienter", "N.", "Dalal", ",", "B.", "Triggs", ",", "Histograms", "of", "oriented", "gradients", "for", "human", "detection", ",", "IEEE", "Computer", "Society", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", ",", "side", "1", ":", "886-893", ",", "2005", "descriptors", "."], "sentence-detokenized": ", C. Papageorgiou og T. Poggio, A Trainable Pedestrian Detection system, International Journal of Computer Vision (IJCV), side 1: 15-33, 2000 andre bruger lokale tr\u00e6k som histogrammer af orienterede gradienter N. Dalal, B. Triggs, Histograms of oriented gradients for human detection, IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), side 1: 886-893, 2005 descriptors.", "token2charspan": [[0, 1], [2, 4], [5, 17], [18, 20], [21, 23], [24, 30], [30, 31], [32, 33], [34, 43], [44, 54], [55, 64], [65, 71], [71, 72], [73, 86], [87, 94], [95, 97], [98, 106], [107, 113], [114, 115], [115, 119], [119, 120], [120, 121], [122, 126], [127, 128], [128, 129], [130, 135], [135, 136], [137, 141], [142, 147], [148, 154], [155, 161], [162, 166], [167, 170], [171, 183], [184, 186], [187, 198], [199, 209], [210, 212], [213, 218], [218, 219], [220, 222], [223, 229], [229, 230], [231, 241], [242, 244], [245, 253], [254, 263], [264, 267], [268, 273], [274, 283], [283, 284], [285, 289], [290, 298], [299, 306], [307, 317], [318, 320], [321, 329], [330, 336], [337, 340], [341, 348], [349, 360], [361, 362], [362, 366], [366, 367], [367, 368], [369, 373], [374, 375], [375, 376], [377, 384], [384, 385], [386, 390], [391, 402], [402, 403]]}
{"doc_key": "ai-train-52", "ner": [[1, 2, "algorithm"], [5, 9, "algorithm"], [14, 15, "task"], [18, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 2, 5, 9, "type-of", "", false, false], [14, 15, 1, 2, "usage", "", true, false], [14, 15, 18, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["En", "autoenkoder", "er", "en", "type", "kunstigt", "neuralt", "netv\u00e6rk", ",", "der", "bruges", "til", "at", "l\u00e6re", "funktionel", "l\u00e6ring", "p\u00e5", "en", "uoverv\u00e5get", "l\u00e6ringsm\u00e5de", "."], "sentence-detokenized": "En autoenkoder er en type kunstigt neuralt netv\u00e6rk, der bruges til at l\u00e6re funktionel l\u00e6ring p\u00e5 en uoverv\u00e5get l\u00e6ringsm\u00e5de.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 20], [21, 25], [26, 34], [35, 42], [43, 50], [50, 51], [52, 55], [56, 62], [63, 66], [67, 69], [70, 74], [75, 85], [86, 92], [93, 95], [96, 98], [99, 109], [110, 121], [121, 122]]}
{"doc_key": "ai-train-53", "ner": [[0, 1, "researcher"], [4, 4, "organisation"], [10, 11, "field"], [13, 13, "field"], [17, 21, "organisation"], [23, 23, "organisation"], [30, 30, "field"], [32, 32, "field"], [38, 38, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 1, 4, 4, "role", "fellow_of", false, false], [0, 1, 10, 11, "related-to", "contributes_to", false, false], [0, 1, 13, 13, "related-to", "contributes_to", false, false], [0, 1, 17, 21, "role", "fellow_of", false, false], [0, 1, 30, 30, "related-to", "contributes_to", false, false], [0, 1, 32, 32, "related-to", "contributes_to", false, false], [23, 23, 17, 21, "named", "", false, false], [38, 38, 17, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Haralick", "er", "Fellow", "of", "IEEE", "for", "sine", "bidrag", "inden", "for", "computer", "vision", "og", "billedbehandling", "og", "Fellow", "of", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", "for", "sine", "bidrag", "inden", "for", "m\u00f8nstergenkendelse", ",", "billedbehandling", "og", "for", "sin", "indsats", "for", "IAPR", "."], "sentence-detokenized": "Haralick er Fellow of IEEE for sine bidrag inden for computer vision og billedbehandling og Fellow of International Association for Pattern Recognition (IAPR) for sine bidrag inden for m\u00f8nstergenkendelse, billedbehandling og for sin indsats for IAPR.", "token2charspan": [[0, 8], [9, 11], [12, 18], [19, 21], [22, 26], [27, 30], [31, 35], [36, 42], [43, 48], [49, 52], [53, 61], [62, 68], [69, 71], [72, 88], [89, 91], [92, 98], [99, 101], [102, 115], [116, 127], [128, 131], [132, 139], [140, 151], [152, 153], [153, 157], [157, 158], [159, 162], [163, 167], [168, 174], [175, 180], [181, 184], [185, 203], [203, 204], [205, 221], [222, 224], [225, 228], [229, 232], [233, 240], [241, 244], [245, 249], [249, 250]]}
{"doc_key": "ai-train-54", "ner": [[4, 5, "task"], [9, 11, "algorithm"], [13, 13, "algorithm"], [20, 21, "researcher"], [23, 24, "organisation"], [26, 27, "researcher"], [29, 31, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 5, 9, 11, "usage", "", false, false], [9, 11, 20, 21, "origin", "", true, false], [9, 11, 26, 27, "origin", "", true, false], [13, 13, 9, 11, "named", "", false, false], [20, 21, 23, 24, "physical", "", false, false], [20, 21, 23, 24, "role", "", false, false], [26, 27, 29, 31, "physical", "", false, false], [26, 27, 29, 31, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Det", "f\u00f8rste", "fors\u00f8g", "p\u00e5", "end-to-end", "ASR", "blev", "gjort", "med", "Connectionist", "Temporal", "Classification", "(", "CTC)-baserede", "systemer", ",", "der", "blev", "introduceret", "af", "Alex", "Graves", "fra", "Google", "DeepMind", "og", "Navdeep", "Jaitly", "fra", "University", "of", "Toronto", "i", "2014", "."], "sentence-detokenized": "Det f\u00f8rste fors\u00f8g p\u00e5 end-to-end ASR blev gjort med Connectionist Temporal Classification (CTC)-baserede systemer, der blev introduceret af Alex Graves fra Google DeepMind og Navdeep Jaitly fra University of Toronto i 2014.", "token2charspan": [[0, 3], [4, 10], [11, 17], [18, 20], [21, 31], [32, 35], [36, 40], [41, 46], [47, 50], [51, 64], [65, 73], [74, 88], [89, 90], [90, 103], [104, 112], [112, 113], [114, 117], [118, 122], [123, 135], [136, 138], [139, 143], [144, 150], [151, 154], [155, 161], [162, 170], [171, 173], [174, 181], [182, 188], [189, 192], [193, 203], [204, 206], [207, 214], [215, 216], [217, 221], [221, 222]]}
{"doc_key": "ai-train-55", "ner": [[0, 1, "algorithm"], [3, 6, "algorithm"], [9, 10, "algorithm"], [12, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 6, 0, 1, "named", "", false, false], [9, 10, 0, 1, "type-of", "", false, false], [12, 12, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Line\u00e6r-fraktionel", "programmering", "(", "LFP", ")", "er", "en", "generalisering", "af", "line\u00e6r", "programmering", "(", "LP", ")", "."], "sentence-detokenized": "Line\u00e6r-fraktionel programmering (LFP) er en generalisering af line\u00e6r programmering (LP).", "token2charspan": [[0, 17], [18, 31], [32, 33], [33, 36], [36, 37], [38, 40], [41, 43], [44, 58], [59, 61], [62, 68], [69, 82], [83, 84], [84, 86], [86, 87], [87, 88]]}
{"doc_key": "ai-train-56", "ner": [[0, 1, "researcher"], [8, 8, "misc"], [10, 17, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 8, 8, "win-defeat", "", false, false], [8, 8, 10, 17, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lafferty", "har", "modtaget", "adskillige", "priser", ",", "herunder", "to", "Test-of-Time-priser", "ved", "International", "Conference", "on", "Machine", "Learning", "2011", "og", "2012", ","], "sentence-detokenized": "Lafferty har modtaget adskillige priser, herunder to Test-of-Time-priser ved International Conference on Machine Learning 2011 og 2012,", "token2charspan": [[0, 8], [9, 12], [13, 21], [22, 32], [33, 39], [39, 40], [41, 49], [50, 52], [53, 72], [73, 76], [77, 90], [91, 101], [102, 104], [105, 112], [113, 121], [122, 126], [127, 129], [130, 134], [134, 135]]}
{"doc_key": "ai-train-57", "ner": [[6, 6, "product"], [8, 8, "programlang"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Med", "fremkomsten", "af", "komponentbaserede", "rammer", "som", ".NET", "og", "Java", "er", "komponentbaserede", "udviklingsmilj\u00f8er", "i", "stand", "til", "at", "implementere", "det", "udviklede", "neurale", "netv\u00e6rk", "i", "disse", "rammer", "som", "arvelige", "komponenter", "."], "sentence-detokenized": "Med fremkomsten af komponentbaserede rammer som .NET og Java er komponentbaserede udviklingsmilj\u00f8er i stand til at implementere det udviklede neurale netv\u00e6rk i disse rammer som arvelige komponenter.", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 36], [37, 43], [44, 47], [48, 52], [53, 55], [56, 60], [61, 63], [64, 81], [82, 99], [100, 101], [102, 107], [108, 111], [112, 114], [115, 127], [128, 131], [132, 141], [142, 149], [150, 157], [158, 159], [160, 165], [166, 172], [173, 176], [177, 185], [186, 197], [197, 198]]}
{"doc_key": "ai-train-58", "ner": [[2, 2, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ligesom", "med", "BLEU", "er", "den", "grundl\u00e6ggende", "evalueringsenhed", "s\u00e6tningen", ",", "og", "algoritmen", "skaber", "f\u00f8rst", "en", "tilpasning", "(", "se", "illustrationer", ")", "mellem", "to", "s\u00e6tninger", ",", "kandidatovers\u00e6ttelsesstrengen", "og", "referenceovers\u00e6ttelsesstrengen", "."], "sentence-detokenized": "Ligesom med BLEU er den grundl\u00e6ggende evalueringsenhed s\u00e6tningen, og algoritmen skaber f\u00f8rst en tilpasning (se illustrationer) mellem to s\u00e6tninger, kandidatovers\u00e6ttelsesstrengen og referenceovers\u00e6ttelsesstrengen.", "token2charspan": [[0, 7], [8, 11], [12, 16], [17, 19], [20, 23], [24, 37], [38, 54], [55, 64], [64, 65], [66, 68], [69, 79], [80, 86], [87, 92], [93, 95], [96, 106], [107, 108], [108, 110], [111, 125], [125, 126], [127, 133], [134, 136], [137, 146], [146, 147], [148, 177], [178, 180], [181, 211], [211, 212]]}
{"doc_key": "ai-train-59", "ner": [[8, 12, "conference"], [21, 21, "task"], [23, 23, "task"], [26, 26, "metrics"], [27, 31, "metrics"], [36, 39, "conference"], [41, 41, "conference"], [44, 44, "location"], [46, 46, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[8, 12, 21, 21, "related-to", "subject_at", false, false], [8, 12, 23, 23, "related-to", "subject_at", false, false], [26, 26, 8, 12, "temporal", "", false, false], [27, 31, 26, 26, "named", "", true, false], [41, 41, 36, 39, "named", "", false, false], [44, 44, 46, 46, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["En", "af", "de", "m\u00e5linger", ",", "der", "anvendes", "p\u00e5", "NIST's", "\u00e5rlige", "konferencer", "om", "dokumentforst\u00e5else", ",", "hvor", "forskningsgrupper", "indsender", "deres", "systemer", "til", "b\u00e5de", "opsummerings-", "og", "overs\u00e6ttelsesopgaver", ",", "er", "ROUGE-metrikken", "(Recall-Oriented", "Understudy", "for", "Gisting", "Evaluation", ",", "In", "Advances", "of", "Neural", "Information", "Processing", "Systems", "(", "NIPS", ")", ",", "Montreal", ",", "Canada", ",", "december", "2014", ")", "."], "sentence-detokenized": "En af de m\u00e5linger, der anvendes p\u00e5 NIST's \u00e5rlige konferencer om dokumentforst\u00e5else, hvor forskningsgrupper indsender deres systemer til b\u00e5de opsummerings- og overs\u00e6ttelsesopgaver, er ROUGE-metrikken (Recall-Oriented Understudy for Gisting Evaluation, In Advances of Neural Information Processing Systems (NIPS), Montreal, Canada, december 2014).", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 17], [17, 18], [19, 22], [23, 31], [32, 34], [35, 41], [42, 48], [49, 60], [61, 63], [64, 82], [82, 83], [84, 88], [89, 106], [107, 116], [117, 122], [123, 131], [132, 135], [136, 140], [141, 154], [155, 157], [158, 178], [178, 179], [180, 182], [183, 198], [199, 215], [216, 226], [227, 230], [231, 238], [239, 249], [249, 250], [251, 253], [254, 262], [263, 265], [266, 272], [273, 284], [285, 295], [296, 303], [304, 305], [305, 309], [309, 310], [310, 311], [312, 320], [320, 321], [322, 328], [328, 329], [330, 338], [339, 343], [343, 344], [344, 345]]}
{"doc_key": "ai-train-60", "ner": [[7, 7, "programlang"], [9, 9, "product"], [11, 12, "programlang"], [16, 16, "product"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 7, 11, 12, "type-of", "", false, false], [7, 7, 22, 22, "named", "", false, false], [9, 9, 11, 12, "part-of", "", false, false], [9, 9, 16, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Samme", "implementering", ",", "til", "at", "k\u00f8re", "i", "Java", "med", "JShell", "(", "Java", "9", "minimum", ")", ":", "codejshell", "scriptfile", "/", "codesyntaxhighlight", "lang", "=", "java"], "sentence-detokenized": "Samme implementering, til at k\u00f8re i Java med JShell (Java 9 minimum): codejshell scriptfile / codesyntaxhighlight lang = java", "token2charspan": [[0, 5], [6, 20], [20, 21], [22, 25], [26, 28], [29, 33], [34, 35], [36, 40], [41, 44], [45, 51], [52, 53], [53, 57], [58, 59], [60, 67], [67, 68], [68, 69], [70, 80], [81, 91], [92, 93], [94, 113], [114, 118], [119, 120], [121, 125]]}
{"doc_key": "ai-train-61", "ner": [[0, 0, "metrics"], [4, 4, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 4, "origin", "based_on", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST-metrikken", "er", "baseret", "p\u00e5", "BLEU-metrikken", ",", "men", "med", "nogle", "\u00e6ndringer", "."], "sentence-detokenized": "NIST-metrikken er baseret p\u00e5 BLEU-metrikken, men med nogle \u00e6ndringer.", "token2charspan": [[0, 14], [15, 17], [18, 25], [26, 28], [29, 43], [43, 44], [45, 48], [49, 52], [53, 58], [59, 68], [68, 69]]}
{"doc_key": "ai-train-62", "ner": [[6, 6, "country"], [9, 11, "university"], [13, 15, "university"], [22, 23, "product"], [27, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 11, 6, 6, "physical", "", false, false], [13, 15, 6, 6, "physical", "", false, false], [22, 23, 9, 11, "origin", "", false, false], [22, 23, 13, 15, "origin", "", false, false], [22, 23, 27, 28, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["I", "slutningen", "af", "1980'erne", "indledte", "to", "nederlandske", "universiteter", ",", "University", "of", "Groningen", "og", "University", "of", "Twente", ",", "i", "f\u00e6llesskab", "et", "projekt", "kaldet", "Knowledge", "Graphs", ",", "som", "er", "semantiske", "netv\u00e6rk", ",", "men", "med", "den", "tilf\u00f8jede", "begr\u00e6nsning", ",", "at", "kanterne", "kun", "m\u00e5", "v\u00e6re", "fra", "et", "begr\u00e6nset", "s\u00e6t", "af", "mulige", "relationer", ",", "for", "at", "g\u00f8re", "det", "lettere", "at", "lave", "algebraer", "p\u00e5", "grafen", "."], "sentence-detokenized": "I slutningen af 1980'erne indledte to nederlandske universiteter, University of Groningen og University of Twente, i f\u00e6llesskab et projekt kaldet Knowledge Graphs, som er semantiske netv\u00e6rk, men med den tilf\u00f8jede begr\u00e6nsning, at kanterne kun m\u00e5 v\u00e6re fra et begr\u00e6nset s\u00e6t af mulige relationer, for at g\u00f8re det lettere at lave algebraer p\u00e5 grafen.", "token2charspan": [[0, 1], [2, 12], [13, 15], [16, 25], [26, 34], [35, 37], [38, 50], [51, 64], [64, 65], [66, 76], [77, 79], [80, 89], [90, 92], [93, 103], [104, 106], [107, 113], [113, 114], [115, 116], [117, 127], [128, 130], [131, 138], [139, 145], [146, 155], [156, 162], [162, 163], [164, 167], [168, 170], [171, 181], [182, 189], [189, 190], [191, 194], [195, 198], [199, 202], [203, 212], [213, 224], [224, 225], [226, 228], [229, 237], [238, 241], [242, 244], [245, 249], [250, 253], [254, 256], [257, 266], [267, 270], [271, 273], [274, 280], [281, 291], [291, 292], [293, 296], [297, 299], [300, 304], [305, 308], [309, 316], [317, 319], [320, 324], [325, 334], [335, 337], [338, 344], [344, 345]]}
{"doc_key": "ai-train-63", "ner": [[0, 2, "product"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 15, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Grammatikkontroller", "er", "oftest", "implementeret", "som", "en", "funktion", "i", "et", "st\u00f8rre", "program", ",", "f.eks", ".", "et", "tekstbehandlingsprogram", ",", "men", "findes", "ogs\u00e5", "som", "et", "selvst\u00e6ndigt", "program", ",", "der", "kan", "aktiveres", "fra", "programmer", ",", "der", "arbejder", "med", "redigerbar", "tekst", "."], "sentence-detokenized": "Grammatikkontroller er oftest implementeret som en funktion i et st\u00f8rre program, f.eks. et tekstbehandlingsprogram, men findes ogs\u00e5 som et selvst\u00e6ndigt program, der kan aktiveres fra programmer, der arbejder med redigerbar tekst.", "token2charspan": [[0, 19], [20, 22], [23, 29], [30, 43], [44, 47], [48, 50], [51, 59], [60, 61], [62, 64], [65, 71], [72, 79], [79, 80], [81, 86], [86, 87], [88, 90], [91, 114], [114, 115], [116, 119], [120, 126], [127, 131], [132, 135], [136, 138], [139, 151], [152, 159], [159, 160], [161, 164], [165, 168], [169, 178], [179, 182], [183, 193], [193, 194], [195, 198], [199, 207], [208, 211], [212, 222], [223, 228], [228, 229]]}
{"doc_key": "ai-train-64", "ner": [[4, 10, "organisation"], [12, 17, "conference"], [19, 25, "organisation"], [28, 30, "conference"], [32, 34, "conference"], [36, 38, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Han", "er", "medlem", "af", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "Association", "for", "the", "Advancement", "Artificial", "Intelligence", "og", "Cognitive", "Science", "Society", ",", "og", "han", "er", "redakt\u00f8r", "af", "J.", "Automated", "Reasoning", ",", "J.", "Learning", "Sciences", "og", "J.", "Applied", "Ontology", "."], "sentence-detokenized": "Han er medlem af American Association for the Advancement of Science, Association for the Advancement Artificial Intelligence og Cognitive Science Society, og han er redakt\u00f8r af J. Automated Reasoning, J. Learning Sciences og J. Applied Ontology.", "token2charspan": [[0, 3], [4, 6], [7, 13], [14, 16], [17, 25], [26, 37], [38, 41], [42, 45], [46, 57], [58, 60], [61, 68], [68, 69], [70, 81], [82, 85], [86, 89], [90, 101], [102, 112], [113, 125], [126, 128], [129, 138], [139, 146], [147, 154], [154, 155], [156, 158], [159, 162], [163, 165], [166, 174], [175, 177], [178, 180], [181, 190], [191, 200], [200, 201], [202, 204], [205, 213], [214, 222], [223, 225], [226, 228], [229, 236], [237, 245], [245, 246]]}
{"doc_key": "ai-train-65", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [10, 10, "task"], [17, 18, "researcher"], [20, 21, "university"], [23, 24, "researcher"], [26, 29, "organisation"], [31, 31, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 10, 10, "type-of", "", false, false], [0, 2, 17, 18, "origin", "", false, false], [0, 2, 23, 24, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [17, 18, 20, 21, "physical", "", false, false], [17, 18, 20, 21, "role", "", false, false], [23, 24, 26, 29, "role", "", false, false], [31, 31, 26, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Linear", "predictive", "coding", "(", "LPC", ")", ",", "en", "form", "for", "talekodning", ",", "begyndte", "at", "blive", "udviklet", "med", "Fumitada", "Itakura", "fra", "Nagoya", "University", "og", "Shuzo", "Saito", "fra", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "i", "1966", "."], "sentence-detokenized": "Linear predictive coding (LPC), en form for talekodning, begyndte at blive udviklet med Fumitada Itakura fra Nagoya University og Shuzo Saito fra Nippon Telegraph and Telephone (NTT) i 1966.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [30, 31], [32, 34], [35, 39], [40, 43], [44, 55], [55, 56], [57, 65], [66, 68], [69, 74], [75, 83], [84, 87], [88, 96], [97, 104], [105, 108], [109, 115], [116, 126], [127, 129], [130, 135], [136, 141], [142, 145], [146, 152], [153, 162], [163, 166], [167, 176], [177, 178], [178, 181], [181, 182], [183, 184], [185, 189], [189, 190]]}
{"doc_key": "ai-train-66", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["Hvis", "signalet", "desuden", "er", "ergodisk", ",", "har", "alle", "pr\u00f8vebaner", "samme", "tidsgennemsnit", ",", "og", "dermed", "mathR", "_", "x", "^", "{", "n", "/", "T", "_", "0", "}", "(", "\\", "tau", ")", "=", "\\", "widehat", "{", "R", "}", "_", "x", "^", "{", "n", "/", "T", "_", "0", "}", "(", "\\", "tau", ")", "/", "math", "i", "middelkvadratfejlsammenh\u00e6ng", "."], "sentence-detokenized": "Hvis signalet desuden er ergodisk, har alle pr\u00f8vebaner samme tidsgennemsnit, og dermed mathR _ x ^ {n / T _ 0} (\\ tau) =\\ widehat {R} _ x ^ {n / T _ 0} (\\ tau) / math i middelkvadratfejlsammenh\u00e6ng.", "token2charspan": [[0, 4], [5, 13], [14, 21], [22, 24], [25, 33], [33, 34], [35, 38], [39, 43], [44, 54], [55, 60], [61, 75], [75, 76], [77, 79], [80, 86], [87, 92], [93, 94], [95, 96], [97, 98], [99, 100], [100, 101], [102, 103], [104, 105], [106, 107], [108, 109], [109, 110], [111, 112], [112, 113], [114, 117], [117, 118], [119, 120], [120, 121], [122, 129], [130, 131], [131, 132], [132, 133], [134, 135], [136, 137], [138, 139], [140, 141], [141, 142], [143, 144], [145, 146], [147, 148], [149, 150], [150, 151], [152, 153], [153, 154], [155, 158], [158, 159], [160, 161], [162, 166], [167, 168], [169, 196], [196, 197]]}
{"doc_key": "ai-train-67", "ner": [[0, 2, "task"], [4, 4, "task"], [15, 17, "algorithm"], [13, 13, "algorithm"], [22, 24, "algorithm"], [20, 20, "algorithm"], [29, 31, "algorithm"], [27, 27, "algorithm"], [36, 38, "algorithm"], [42, 42, "misc"], [45, 45, "algorithm"], [47, 48, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12], "relations": [[15, 17, 42, 42, "related-to", "", false, false], [13, 13, 15, 17, "named", "", false, false], [22, 24, 42, 42, "related-to", "", false, false], [20, 20, 22, 24, "named", "", false, false], [29, 31, 42, 42, "related-to", "", false, false], [27, 27, 29, 31, "named", "", false, false], [36, 38, 42, 42, "related-to", "", false, false], [45, 45, 47, 48, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 8], "sentence": ["Udtr\u00e6kning", "af", "kendetegn", "og", "dimensionsreduktion", "kan", "kombineres", "i", "\u00e9t", "trin", "ved", "hj\u00e6lp", "af", "PCA", "(", "principal", "component", "analysis", ")", ",", "LDA", "(", "linear", "discriminant", "analysis", ")", ",", "CCA", "(", "canonical", "correlation", "analysis", ")", "eller", "NMF-teknikker", "(", "non-negative", "matrix", "factorization", ")", "som", "et", "forbehandlingstrin", "efterfulgt", "af", "K-NN-gruppering", "p\u00e5", "kendetegnets", "vektorer", "i", "et", "rum", "med", "reduceret", "dimension", "."], "sentence-detokenized": "Udtr\u00e6kning af kendetegn og dimensionsreduktion kan kombineres i \u00e9t trin ved hj\u00e6lp af PCA (principal component analysis), LDA (linear discriminant analysis), CCA (canonical correlation analysis) eller NMF-teknikker (non-negative matrix factorization) som et forbehandlingstrin efterfulgt af K-NN-gruppering p\u00e5 kendetegnets vektorer i et rum med reduceret dimension.", "token2charspan": [[0, 10], [11, 13], [14, 23], [24, 26], [27, 46], [47, 50], [51, 61], [62, 63], [64, 66], [67, 71], [72, 75], [76, 81], [82, 84], [85, 88], [89, 90], [90, 99], [100, 109], [110, 118], [118, 119], [119, 120], [121, 124], [125, 126], [126, 132], [133, 145], [146, 154], [154, 155], [155, 156], [157, 160], [161, 162], [162, 171], [172, 183], [184, 192], [192, 193], [194, 199], [200, 213], [214, 215], [215, 227], [228, 234], [235, 248], [248, 249], [250, 253], [254, 256], [257, 275], [276, 286], [287, 289], [290, 305], [306, 308], [309, 321], [322, 330], [331, 332], [333, 335], [336, 339], [340, 343], [344, 353], [354, 363], [363, 364]]}
{"doc_key": "ai-train-68", "ner": [[6, 6, "programlang"], [8, 8, "programlang"], [10, 10, "programlang"], [12, 12, "programlang"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[18, 18, 6, 6, "related-to", "program_type_compatible_with", false, false], [18, 18, 8, 8, "related-to", "program_type_compatible_with", false, false], [18, 18, 10, 10, "related-to", "program_type_compatible_with", false, false], [18, 18, 12, 12, "related-to", "program_type_compatible_with", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Biblioteker", ",", "der", "er", "skrevet", "i", "Perl", ",", "Java", ",", "ActiveX", "eller", ".NET", ",", "kan", "kaldes", "direkte", "fra", "MATLAB", ","], "sentence-detokenized": "Biblioteker, der er skrevet i Perl, Java, ActiveX eller .NET, kan kaldes direkte fra MATLAB,", "token2charspan": [[0, 11], [11, 12], [13, 16], [17, 19], [20, 27], [28, 29], [30, 34], [34, 35], [36, 40], [40, 41], [42, 49], [50, 55], [56, 60], [60, 61], [62, 65], [66, 72], [73, 80], [81, 84], [85, 91], [91, 92]]}
{"doc_key": "ai-train-69", "ner": [[3, 7, "task"], [9, 16, "task"], [37, 42, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 7, 9, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Opgaven", "med", "at", "genkende", "navngivne", "enheder", "i", "tekst", "er", "Named", "Entity", "Recognition", "(", "genkendelse", "af", "navngivne", "enheder", ")", ",", "mens", "opgaven", "med", "at", "bestemme", "identiteten", "af", "de", "navngivne", "enheder", ",", "der", "er", "n\u00e6vnt", "i", "teksten", ",", "kaldes", "Entity", "Linking", "(", "sammenk\u00e6dning", "af", "enheder", ")", "."], "sentence-detokenized": "Opgaven med at genkende navngivne enheder i tekst er Named Entity Recognition (genkendelse af navngivne enheder), mens opgaven med at bestemme identiteten af de navngivne enheder, der er n\u00e6vnt i teksten, kaldes Entity Linking (sammenk\u00e6dning af enheder).", "token2charspan": [[0, 7], [8, 11], [12, 14], [15, 23], [24, 33], [34, 41], [42, 43], [44, 49], [50, 52], [53, 58], [59, 65], [66, 77], [78, 79], [79, 90], [91, 93], [94, 103], [104, 111], [111, 112], [112, 113], [114, 118], [119, 126], [127, 130], [131, 133], [134, 142], [143, 154], [155, 157], [158, 160], [161, 170], [171, 178], [178, 179], [180, 183], [184, 186], [187, 192], [193, 194], [195, 202], [202, 203], [204, 210], [211, 217], [218, 225], [226, 227], [227, 240], [241, 243], [244, 251], [251, 252], [252, 253]]}
{"doc_key": "ai-train-70", "ner": [[29, 30, "algorithm"]], "ner_mapping_to_source": [2], "relations": [], "relations_mapping_to_source": [], "sentence": ["De", "sigmoidfunktioner", "og", "derivater", ",", "der", "anvendes", "i", "pakken", ",", "var", "oprindeligt", "inkluderet", "i", "pakken", ",", "men", "fra", "version", "0.8.0", "og", "fremefter", "blev", "de", "udgivet", "i", "en", "separat", "R-pakke", "sigmoid", "med", "henblik", "p\u00e5", "at", "muligg\u00f8re", "en", "mere", "generel", "anvendelse", "."], "sentence-detokenized": "De sigmoidfunktioner og derivater, der anvendes i pakken, var oprindeligt inkluderet i pakken, men fra version 0.8.0 og fremefter blev de udgivet i en separat R-pakke sigmoid med henblik p\u00e5 at muligg\u00f8re en mere generel anvendelse.", "token2charspan": [[0, 2], [3, 20], [21, 23], [24, 33], [33, 34], [35, 38], [39, 47], [48, 49], [50, 56], [56, 57], [58, 61], [62, 73], [74, 84], [85, 86], [87, 93], [93, 94], [95, 98], [99, 102], [103, 110], [111, 116], [117, 119], [120, 129], [130, 134], [135, 137], [138, 145], [146, 147], [148, 150], [151, 158], [159, 166], [167, 174], [175, 178], [179, 186], [187, 189], [190, 192], [193, 202], [203, 205], [206, 210], [211, 218], [219, 229], [229, 230]]}
{"doc_key": "ai-train-71", "ner": [[0, 1, "programlang"], [15, 19, "organisation"], [21, 21, "organisation"], [27, 27, "location"], [29, 29, "location"], [6, 7, "researcher"], [9, 10, "researcher"], [12, 13, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 6, 7, "artifact", "", true, false], [0, 1, 9, 10, "artifact", "", true, false], [0, 1, 12, 13, "artifact", "", true, false], [21, 21, 15, 19, "named", "", false, false], [21, 21, 27, 27, "physical", "", false, false], [27, 27, 29, 29, "physical", "", false, false], [6, 7, 15, 19, "role", "", false, false], [9, 10, 15, 19, "role", "", false, false], [12, 13, 15, 19, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Logo", "blev", "skabt", "i", "1967", "af", "Wally", "Feurzeig", ",", "Cynthia", "Solomon", "og", "Seymour", "Papert", "hos", "Bolt", ",", "Beranek", "and", "Newman", "(", "BBN", ")", ",", "et", "forskningsfirma", "i", "Cambridge", ",", "Massachusetts", "."], "sentence-detokenized": "Logo blev skabt i 1967 af Wally Feurzeig, Cynthia Solomon og Seymour Papert hos Bolt, Beranek and Newman (BBN), et forskningsfirma i Cambridge, Massachusetts.", "token2charspan": [[0, 4], [5, 9], [10, 15], [16, 17], [18, 22], [23, 25], [26, 31], [32, 40], [40, 41], [42, 49], [50, 57], [58, 60], [61, 68], [69, 75], [76, 79], [80, 84], [84, 85], [86, 93], [94, 97], [98, 104], [105, 106], [106, 109], [109, 110], [110, 111], [112, 114], [115, 130], [131, 132], [133, 142], [142, 143], [144, 157], [157, 158]]}
{"doc_key": "ai-train-72", "ner": [[0, 0, "misc"], [9, 10, "field"], [18, 18, "field"], [23, 23, "algorithm"], [26, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 9, 10, "part-of", "", false, false], [0, 0, 18, 18, "compare", "", false, false], [23, 23, 18, 18, "part-of", "", false, false], [26, 27, 18, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Neuroevolution", "anvendes", "almindeligvis", "som", "en", "del", "af", "paradigmet", "for", "forst\u00e6rkende", "l\u00e6ring", ",", "og", "den", "kan", "sammenlignes", "med", "konventionelle", "dybe", "l\u00e6ringsteknikker", ",", "der", "anvender", "gradientafstigning", "p\u00e5", "et", "neuralt", "netv\u00e6rk", "med", "en", "fast", "topologi", "."], "sentence-detokenized": "Neuroevolution anvendes almindeligvis som en del af paradigmet for forst\u00e6rkende l\u00e6ring, og den kan sammenlignes med konventionelle dybe l\u00e6ringsteknikker, der anvender gradientafstigning p\u00e5 et neuralt netv\u00e6rk med en fast topologi.", "token2charspan": [[0, 14], [15, 23], [24, 37], [38, 41], [42, 44], [45, 48], [49, 51], [52, 62], [63, 66], [67, 79], [80, 86], [86, 87], [88, 90], [91, 94], [95, 98], [99, 111], [112, 115], [116, 130], [131, 135], [136, 152], [152, 153], [154, 157], [158, 166], [167, 185], [186, 188], [189, 191], [192, 199], [200, 207], [208, 211], [212, 214], [215, 219], [220, 228], [228, 229]]}
{"doc_key": "ai-train-73", "ner": [[3, 5, "algorithm"], [57, 59, "metrics"], [61, 61, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[61, 61, 57, 59, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Hvis", "vi", "bruger", "mindste", "kvadraters", "metode", "til", "at", "tilpasse", "en", "funktion", "i", "form", "af", "en", "hyperplan", "\u0177", "=", "a", "+", "\u03b2", "supT", "/", "sup", "x", "til", "dataene", "(", "x", "sub", "i", "/", "sub", ",", "y", "sub", "i", "/", "sub", ")", "sub", "1", "\u2264", "i", "\u2264n", "/", "sub", ",", "kan", "vi", "derefter", "vurdere", "tilpasningen", "ved", "hj\u00e6lp", "af", "den", "gennemsnitlige", "kvadrerede", "fejl", "(", "MSE", ")", "."], "sentence-detokenized": "Hvis vi bruger mindste kvadraters metode til at tilpasse en funktion i form af en hyperplan \u0177 = a + \u03b2 supT / sup x til dataene (x sub i / sub, y sub i / sub) sub 1 \u2264 i \u2264n / sub, kan vi derefter vurdere tilpasningen ved hj\u00e6lp af den gennemsnitlige kvadrerede fejl (MSE).", "token2charspan": [[0, 4], [5, 7], [8, 14], [15, 22], [23, 33], [34, 40], [41, 44], [45, 47], [48, 56], [57, 59], [60, 68], [69, 70], [71, 75], [76, 78], [79, 81], [82, 91], [92, 93], [94, 95], [96, 97], [98, 99], [100, 101], [102, 106], [107, 108], [109, 112], [113, 114], [115, 118], [119, 126], [127, 128], [128, 129], [130, 133], [134, 135], [136, 137], [138, 141], [141, 142], [143, 144], [145, 148], [149, 150], [151, 152], [153, 156], [156, 157], [158, 161], [162, 163], [164, 165], [166, 167], [168, 170], [171, 172], [173, 176], [176, 177], [178, 181], [182, 184], [185, 193], [194, 201], [202, 214], [215, 218], [219, 224], [225, 227], [228, 231], [232, 246], [247, 257], [258, 262], [263, 264], [264, 267], [267, 268], [268, 269]]}
{"doc_key": "ai-train-74", "ner": [[5, 5, "country"], [7, 7, "country"], [9, 9, "country"], [11, 11, "country"], [13, 49, "country"], [15, 17, "country"], [19, 19, "country"], [21, 21, "country"], [23, 23, "country"], [25, 25, "country"], [27, 27, "country"], [29, 29, "country"], [31, 31, "country"], [33, 33, "country"], [35, 37, "country"], [39, 39, "country"], [41, 41, "country"], [43, 43, "country"], [45, 45, "country"], [47, 47, "country"], [51, 51, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "relations": [], "relations_mapping_to_source": [], "sentence": ["Virksomheden", "har", "internationale", "afdelinger", "i", "Australien", ",", "Brasilien", ",", "Canada", ",", "Kina", ",", "Tyskland", ",", "Indien", ",", "Indien", ",", "Italien", ",", "Japan", ",", "Korea", ",", "Litauen", ",", "Polen", ",", "Malaysia", ",", "Filippinerne", ",", "Rusland", ",", "Singapore", ",", "Singapore", ",", "Sydafrika", ",", "Spanien", ",", "Taiwan", ",", "Thailand", ",", "Tyrkiet", ",", "Tyskland", "og", "Storbritannien", "."], "sentence-detokenized": "Virksomheden har internationale afdelinger i Australien, Brasilien, Canada, Kina, Tyskland, Indien, Indien, Italien, Japan, Korea, Litauen, Polen, Malaysia, Filippinerne, Rusland, Singapore, Singapore, Sydafrika, Spanien, Taiwan, Thailand, Tyrkiet, Tyskland og Storbritannien.", "token2charspan": [[0, 12], [13, 16], [17, 31], [32, 42], [43, 44], [45, 55], [55, 56], [57, 66], [66, 67], [68, 74], [74, 75], [76, 80], [80, 81], [82, 90], [90, 91], [92, 98], [98, 99], [100, 106], [106, 107], [108, 115], [115, 116], [117, 122], [122, 123], [124, 129], [129, 130], [131, 138], [138, 139], [140, 145], [145, 146], [147, 155], [155, 156], [157, 169], [169, 170], [171, 178], [178, 179], [180, 189], [189, 190], [191, 200], [200, 201], [202, 211], [211, 212], [213, 220], [220, 221], [222, 228], [228, 229], [230, 238], [238, 239], [240, 247], [247, 248], [249, 257], [258, 260], [261, 275], [275, 276]]}
{"doc_key": "ai-train-75", "ner": [[3, 3, "misc"], [6, 8, "field"], [13, 13, "organisation"], [15, 20, "university"], [26, 28, "organisation"], [30, 33, "university"], [37, 38, "university"], [40, 41, "university"], [43, 45, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 3, 6, 8, "topic", "", false, false], [3, 3, 13, 13, "origin", "", false, false], [3, 3, 15, 20, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Han", "er", "uddannet", "cand.scient", ".", "i", "elektroteknik", "og", "datateknik", "(", "2000", ")", "fra", "Inria", "og", "universitetet", "i", "Nice", "Sophia", "Antipolis", "og", "har", "haft", "faste", "stillinger", "hos", "Siemens", "Corporate", "Technology", ",", "\u00c9cole", "des", "ponts", "ParisTech", "samt", "g\u00e6stestillinger", "p\u00e5", "Rutgers", "University", ",", "Yale", "University", "og", "University", "of", "Houston", "."], "sentence-detokenized": "Han er uddannet cand.scient. i elektroteknik og datateknik (2000) fra Inria og universitetet i Nice Sophia Antipolis og har haft faste stillinger hos Siemens Corporate Technology, \u00c9cole des ponts ParisTech samt g\u00e6stestillinger p\u00e5 Rutgers University, Yale University og University of Houston.", "token2charspan": [[0, 3], [4, 6], [7, 15], [16, 27], [27, 28], [29, 30], [31, 44], [45, 47], [48, 58], [59, 60], [60, 64], [64, 65], [66, 69], [70, 75], [76, 78], [79, 92], [93, 94], [95, 99], [100, 106], [107, 116], [117, 119], [120, 123], [124, 128], [129, 134], [135, 145], [146, 149], [150, 157], [158, 167], [168, 178], [178, 179], [180, 185], [186, 189], [190, 195], [196, 205], [206, 210], [211, 226], [227, 229], [230, 237], [238, 248], [248, 249], [250, 254], [255, 265], [266, 268], [269, 279], [280, 282], [283, 290], [290, 291]]}
{"doc_key": "ai-train-76", "ner": [[10, 11, "researcher"], [0, 0, "researcher"], [17, 18, "product"], [20, 20, "country"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 10, 11, "role", "licensing_patent_to", false, false], [0, 0, 20, 20, "physical", "", false, false], [22, 22, 0, 0, "artifact", "", false, false], [22, 22, 17, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Engelberger", "licenserede", "det", "oprindelige", "patent", ",", "der", "var", "tildelt", "opfinderen", "George", "Devol", ",", "og", "udviklede", "den", "f\u00f8rste", "industrielle", "robot", "i", "USA", ",", "Unimate", ",", "i", "1950'erne", "."], "sentence-detokenized": "Engelberger licenserede det oprindelige patent, der var tildelt opfinderen George Devol, og udviklede den f\u00f8rste industrielle robot i USA, Unimate, i 1950'erne.", "token2charspan": [[0, 11], [12, 23], [24, 27], [28, 39], [40, 46], [46, 47], [48, 51], [52, 55], [56, 63], [64, 74], [75, 81], [82, 87], [87, 88], [89, 91], [92, 101], [102, 105], [106, 112], [113, 125], [126, 131], [132, 133], [134, 137], [137, 138], [139, 146], [146, 147], [148, 149], [150, 159], [159, 160]]}
{"doc_key": "ai-train-77", "ner": [[2, 2, "task"], [7, 7, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Indgangen", "kaldes", "talegenkendelse", ",", "og", "udgangen", "kaldes", "talesyntese", "."], "sentence-detokenized": "Indgangen kaldes talegenkendelse, og udgangen kaldes talesyntese.", "token2charspan": [[0, 9], [10, 16], [17, 32], [32, 33], [34, 36], [37, 45], [46, 52], [53, 64], [64, 65]]}
{"doc_key": "ai-train-78", "ner": [[2, 2, "programlang"], [5, 5, "programlang"], [10, 10, "programlang"], [13, 13, "programlang"], [25, 25, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 10, 10, "named", "", false, false], [5, 5, 2, 2, "origin", "descendant_of", false, false], [5, 5, 13, 13, "general-affiliation", "", false, false], [5, 5, 25, 25, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Efterkommere", "af", "CLIPS", "sproget", "omfatter", "Jess", "(", "regelbaseret", "del", "af", "CLIPS", "omskrevet", "i", "Java", ",", "det", "voksede", "senere", "op", "i", "en", "anden", "retning", ")", ",", "JESS", "var", "oprindeligt", "inspireret"], "sentence-detokenized": "Efterkommere af CLIPS sproget omfatter Jess (regelbaseret del af CLIPS omskrevet i Java, det voksede senere op i en anden retning), JESS var oprindeligt inspireret", "token2charspan": [[0, 12], [13, 15], [16, 21], [22, 29], [30, 38], [39, 43], [44, 45], [45, 57], [58, 61], [62, 64], [65, 70], [71, 80], [81, 82], [83, 87], [87, 88], [89, 92], [93, 100], [101, 107], [108, 110], [111, 112], [113, 115], [116, 121], [122, 129], [129, 130], [130, 131], [132, 136], [137, 140], [141, 152], [153, 163]]}
{"doc_key": "ai-train-79", "ner": [[9, 9, "product"], [14, 15, "organisation"], [19, 20, "product"], [36, 36, "product"], [38, 41, "product"], [56, 57, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6], "relations": [[14, 15, 9, 9, "usage", "", false, false], [19, 20, 14, 15, "artifact", "", false, false], [36, 36, 14, 15, "origin", "", true, false], [36, 36, 56, 57, "related-to", "", true, false], [38, 41, 14, 15, "origin", "", true, false], [38, 41, 56, 57, "related-to", "", true, false]], "relations_mapping_to_source": [1, 2, 3, 4, 5, 6], "sentence": ["Virksomheden", "har", "ogs\u00e5", "skabt", "fleksible", "intelligente", "AGV-applikationer", "og", "designet", "Motivity-kontrolsystemet", ",", "der", "anvendes", "af", "RMT", "Robotics", "til", "at", "udvikle", "ADAM", "iAGV", "(", "Self-Guided", "Vehicle", ")", ",", "der", "anvendes", "til", "komplekse", "pick", "and", "place-operationer", "i", "forbindelse", "med", "portalsystemer", "og", "industrielle", "robotarme", ",", "der", "anvendes", "i", "de", "f\u00f8rende", "bilfabrikker", "til", "at", "flytte", "produkter", "fra", "proces", "til", "proces", "i", "ikke-line\u00e6re", "layouts", "."], "sentence-detokenized": "Virksomheden har ogs\u00e5 skabt fleksible intelligente AGV-applikationer og designet Motivity-kontrolsystemet, der anvendes af RMT Robotics til at udvikle ADAM iAGV (Self-Guided Vehicle), der anvendes til komplekse pick and place-operationer i forbindelse med portalsystemer og industrielle robotarme, der anvendes i de f\u00f8rende bilfabrikker til at flytte produkter fra proces til proces i ikke-line\u00e6re layouts.", "token2charspan": [[0, 12], [13, 16], [17, 21], [22, 27], [28, 37], [38, 50], [51, 68], [69, 71], [72, 80], [81, 105], [105, 106], [107, 110], [111, 119], [120, 122], [123, 126], [127, 135], [136, 139], [140, 142], [143, 150], [151, 155], [156, 160], [161, 162], [162, 173], [174, 181], [181, 182], [182, 183], [184, 187], [188, 196], [197, 200], [201, 210], [211, 215], [216, 219], [220, 237], [238, 239], [240, 251], [252, 255], [256, 270], [271, 273], [274, 286], [287, 296], [296, 297], [298, 301], [302, 310], [311, 312], [313, 315], [316, 323], [324, 336], [337, 340], [341, 343], [344, 350], [351, 360], [361, 364], [365, 371], [372, 375], [376, 382], [383, 384], [385, 397], [398, 405], [405, 406]]}
{"doc_key": "ai-train-80", "ner": [[7, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Parametrene", "\u03b2", "estimeres", "typisk", "ved", "hj\u00e6lp", "af", "maksimal", "sandsynlighed", "."], "sentence-detokenized": "Parametrene \u03b2 estimeres typisk ved hj\u00e6lp af maksimal sandsynlighed.", "token2charspan": [[0, 11], [12, 13], [14, 23], [24, 30], [31, 34], [35, 40], [41, 43], [44, 52], [53, 66], [66, 67]]}
{"doc_key": "ai-train-81", "ner": [[2, 2, "metrics"], [4, 4, "metrics"], [6, 7, "metrics"]], "ner_mapping_to_source": [1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Informationss\u00f8gningsmetrikker", "som", "pr\u00e6cision", "og", "tilbagekaldelse", "eller", "DCG", "er", "nyttige", "til", "at", "vurdere", "kvaliteten", "af", "en", "anbefalingsmetode", "."], "sentence-detokenized": "Informationss\u00f8gningsmetrikker som pr\u00e6cision og tilbagekaldelse eller DCG er nyttige til at vurdere kvaliteten af en anbefalingsmetode.", "token2charspan": [[0, 29], [30, 33], [34, 43], [44, 46], [47, 62], [63, 68], [69, 72], [73, 75], [76, 83], [84, 87], [88, 90], [91, 98], [99, 109], [110, 112], [113, 115], [116, 133], [133, 134]]}
{"doc_key": "ai-train-82", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["En", "typisk", "fabrik", "indeholder", "hundredvis", "af", "industrirobotter", ",", "der", "arbejder", "p\u00e5", "fuldautomatiske", "produktionslinjer", ",", "med", "en", "robot", "for", "hver", "ti", "menneskelige", "arbejdere", "."], "sentence-detokenized": "En typisk fabrik indeholder hundredvis af industrirobotter, der arbejder p\u00e5 fuldautomatiske produktionslinjer, med en robot for hver ti menneskelige arbejdere.", "token2charspan": [[0, 2], [3, 9], [10, 16], [17, 27], [28, 38], [39, 41], [42, 58], [58, 59], [60, 63], [64, 72], [73, 75], [76, 91], [92, 109], [109, 110], [111, 114], [115, 117], [118, 123], [124, 127], [128, 132], [133, 135], [136, 148], [149, 158], [158, 159]]}
{"doc_key": "ai-train-83", "ner": [[7, 7, "product"], [18, 18, "task"], [20, 22, "task"], [24, 24, "task"], [26, 26, "task"], [28, 28, "task"], [30, 30, "task"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6, 7], "relations": [], "relations_mapping_to_source": [], "sentence": ["I", "l\u00f8bet", "af", "det", "seneste", "\u00e5rti", "er", "PCNN'er", "blevet", "anvendt", "i", "en", "r\u00e6kke", "forskellige", "billedbehandlingsapplikationer", ",", "herunder", ":", "billedsegmentering", ",", "generering", "af", "funktioner", ",", "ansigtsudtr\u00e6kning", ",", "bev\u00e6gelsesdetektion", ",", "omr\u00e5dev\u00e6kst", "og", "st\u00f8jreduktion", "."], "sentence-detokenized": "I l\u00f8bet af det seneste \u00e5rti er PCNN'er blevet anvendt i en r\u00e6kke forskellige billedbehandlingsapplikationer, herunder: billedsegmentering, generering af funktioner, ansigtsudtr\u00e6kning, bev\u00e6gelsesdetektion, omr\u00e5dev\u00e6kst og st\u00f8jreduktion.", "token2charspan": [[0, 1], [2, 7], [8, 10], [11, 14], [15, 22], [23, 27], [28, 30], [31, 38], [39, 45], [46, 53], [54, 55], [56, 58], [59, 64], [65, 76], [77, 107], [107, 108], [109, 117], [117, 118], [119, 137], [137, 138], [139, 149], [150, 152], [153, 163], [163, 164], [165, 182], [182, 183], [184, 203], [203, 204], [205, 216], [217, 219], [220, 233], [233, 234]]}
{"doc_key": "ai-train-84", "ner": [[0, 0, "researcher"], [15, 16, "field"], [20, 23, "misc"], [26, 32, "conference"], [34, 34, "conference"], [38, 41, "misc"], [44, 50, "conference"], [51, 52, "conference"], [54, 58, "conference"], [60, 60, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 0, 15, 16, "related-to", "contributes_to", false, false], [0, 0, 20, 23, "win-defeat", "", false, false], [0, 0, 38, 41, "win-defeat", "", false, false], [20, 23, 26, 32, "temporal", "", false, false], [34, 34, 26, 32, "named", "", false, false], [38, 41, 44, 50, "temporal", "", false, false], [38, 41, 54, 58, "temporal", "", false, false], [51, 52, 44, 50, "named", "", false, false], [60, 60, 54, 58, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Xu", "har", "offentliggjort", "mere", "end", "50", "artikler", "p\u00e5", "internationale", "konferencer", "og", "i", "tidsskrifter", "inden", "for", "computer", "vision", "og", "har", "vundet", "prisen", "for", "bedste", "artikel", "p\u00e5", "den", "internationale", "konference", "om", "ikke-fotorealistisk", "rendering", "og", "animation", "(", "NPAR", ")", "2012", "og", "prisen", "for", "bedste", "anmelder", "p\u00e5", "de", "internationale", "konferencer", "Asian", "Conference", "on", "Computer", "Vision", "ACCV", "2012", "og", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "2015", "."], "sentence-detokenized": "Xu har offentliggjort mere end 50 artikler p\u00e5 internationale konferencer og i tidsskrifter inden for computer vision og har vundet prisen for bedste artikel p\u00e5 den internationale konference om ikke-fotorealistisk rendering og animation (NPAR) 2012 og prisen for bedste anmelder p\u00e5 de internationale konferencer Asian Conference on Computer Vision ACCV 2012 og International Conference on Computer Vision (ICCV) 2015.", "token2charspan": [[0, 2], [3, 6], [7, 21], [22, 26], [27, 30], [31, 33], [34, 42], [43, 45], [46, 60], [61, 72], [73, 75], [76, 77], [78, 90], [91, 96], [97, 100], [101, 109], [110, 116], [117, 119], [120, 123], [124, 130], [131, 137], [138, 141], [142, 148], [149, 156], [157, 159], [160, 163], [164, 178], [179, 189], [190, 192], [193, 212], [213, 222], [223, 225], [226, 235], [236, 237], [237, 241], [241, 242], [243, 247], [248, 250], [251, 257], [258, 261], [262, 268], [269, 277], [278, 280], [281, 283], [284, 298], [299, 310], [311, 316], [317, 327], [328, 330], [331, 339], [340, 346], [347, 351], [352, 356], [357, 359], [360, 373], [374, 384], [385, 387], [388, 396], [397, 403], [404, 405], [405, 409], [409, 410], [411, 415], [415, 416]]}
{"doc_key": "ai-train-85", "ner": [[0, 0, "programlang"], [3, 3, "field"], [5, 6, "field"], [9, 9, "misc"], [14, 14, "researcher"], [16, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 3, 3, "part-of", "", false, false], [0, 0, 5, 6, "part-of", "", false, false], [0, 0, 9, 9, "type-of", "", false, false], [16, 19, 0, 0, "usage", "", false, false], [16, 19, 14, 14, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["CycL", "inden", "for", "datalogi", "og", "kunstig", "intelligens", "er", "et", "ontologisprog", ",", "der", "anvendes", "af", "Doug", "Lenats", "Cyc-projekt", "om", "kunstig", "intelligens", "."], "sentence-detokenized": "CycL inden for datalogi og kunstig intelligens er et ontologisprog, der anvendes af Doug Lenats Cyc-projekt om kunstig intelligens.", "token2charspan": [[0, 4], [5, 10], [11, 14], [15, 23], [24, 26], [27, 34], [35, 46], [47, 49], [50, 52], [53, 66], [66, 67], [68, 71], [72, 80], [81, 83], [84, 88], [89, 95], [96, 107], [108, 110], [111, 118], [119, 130], [130, 131]]}
{"doc_key": "ai-train-86", "ner": [[2, 2, "task"], [4, 4, "metrics"], [8, 8, "metrics"], [10, 13, "metrics"], [20, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 2, 2, "part-of", "", false, false], [8, 8, 4, 4, "named", "", false, false], [10, 13, 4, 4, "named", "", false, false], [20, 21, 4, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Ogs\u00e5", "i", "regressionsanalyse", "kan", "middelkvadratfejl", ",", "ofte", "ben\u00e6vnt", "middelkvadratpr\u00e6diktionsfejl", "eller", "middelkvadratfejl", "uden", "for", "stikpr\u00f8ven", ",", "henvise", "til", "middelv\u00e6rdien", "af", "de", "kvadrerede", "afvigelser", "af", "forudsigelserne", "fra", "de", "sande", "v\u00e6rdier", "over", "et", "testomr\u00e5de", "uden", "for", "stikpr\u00f8ven", ",", "som", "er", "genereret", "af", "en", "model", ",", "der", "er", "estimeret", "over", "et", "bestemt", "pr\u00f8veomr\u00e5de", "."], "sentence-detokenized": "Ogs\u00e5 i regressionsanalyse kan middelkvadratfejl, ofte ben\u00e6vnt middelkvadratpr\u00e6diktionsfejl eller middelkvadratfejl uden for stikpr\u00f8ven, henvise til middelv\u00e6rdien af de kvadrerede afvigelser af forudsigelserne fra de sande v\u00e6rdier over et testomr\u00e5de uden for stikpr\u00f8ven, som er genereret af en model, der er estimeret over et bestemt pr\u00f8veomr\u00e5de.", "token2charspan": [[0, 4], [5, 6], [7, 25], [26, 29], [30, 47], [47, 48], [49, 53], [54, 61], [62, 90], [91, 96], [97, 114], [115, 119], [120, 123], [124, 134], [134, 135], [136, 143], [144, 147], [148, 161], [162, 164], [165, 167], [168, 178], [179, 189], [190, 192], [193, 208], [209, 212], [213, 215], [216, 221], [222, 229], [230, 234], [235, 237], [238, 248], [249, 253], [254, 257], [258, 268], [268, 269], [270, 273], [274, 276], [277, 286], [287, 289], [290, 292], [293, 298], [298, 299], [300, 303], [304, 306], [307, 316], [317, 321], [322, 324], [325, 332], [333, 344], [344, 345]]}
{"doc_key": "ai-train-87", "ner": [[4, 4, "algorithm"], [12, 14, "algorithm"]], "ner_mapping_to_source": [0, 2], "relations": [[4, 4, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Resultaterne", "viser", ",", "at", "C-HOG-", "og", "R-HOG-blokdeskriptorerne", "klarer", "sig", "sammenligneligt", ",", "idet", "C-HOG-deskriptorerne", "har", "en", "lille", "fordel", "med", "hensyn", "til", "fejlfindingsraten", "ved", "fastlagte", "FALSK-positivrater", "p\u00e5", "tv\u00e6rs", "af", "begge", "datas\u00e6t", "."], "sentence-detokenized": "Resultaterne viser, at C-HOG- og R-HOG-blokdeskriptorerne klarer sig sammenligneligt, idet C-HOG-deskriptorerne har en lille fordel med hensyn til fejlfindingsraten ved fastlagte FALSK-positivrater p\u00e5 tv\u00e6rs af begge datas\u00e6t.", "token2charspan": [[0, 12], [13, 18], [18, 19], [20, 22], [23, 29], [30, 32], [33, 57], [58, 64], [65, 68], [69, 84], [84, 85], [86, 90], [91, 111], [112, 115], [116, 118], [119, 124], [125, 131], [132, 135], [136, 142], [143, 146], [147, 164], [165, 168], [169, 178], [179, 197], [198, 200], [201, 206], [207, 209], [210, 215], [216, 223], [223, 224]]}
{"doc_key": "ai-train-88", "ner": [[3, 3, "algorithm"], [7, 7, "misc"], [9, 10, "algorithm"], [12, 13, "algorithm"], [17, 17, "algorithm"], [20, 21, "algorithm"], [23, 25, "algorithm"], [29, 29, "misc"], [33, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 3, 7, 7, "usage", "", false, false], [9, 10, 29, 29, "usage", "", false, false], [12, 13, 29, 29, "usage", "", false, false], [17, 17, 29, 29, "usage", "", false, false], [20, 21, 29, 29, "usage", "", false, false], [23, 25, 29, 29, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Popul\u00e6re", "genkendelsesalgoritmer", "omfatter", "hovedkomponentanalyse", "ved", "hj\u00e6lp", "af", "egenansigter", ",", "line\u00e6r", "diskriminantanalyse", ",", "elastisk", "matching", "ved", "hj\u00e6lp", "af", "Fisherface-algoritmen", ",", "den", "skjulte", "Markov-model", ",", "multilinear", "subspace", "learning", "ved", "hj\u00e6lp", "af", "tensorrepr\u00e6sentation", "og", "neuronal", "motiveret", "dynamisk", "link", "matching", "."], "sentence-detokenized": "Popul\u00e6re genkendelsesalgoritmer omfatter hovedkomponentanalyse ved hj\u00e6lp af egenansigter, line\u00e6r diskriminantanalyse, elastisk matching ved hj\u00e6lp af Fisherface-algoritmen, den skjulte Markov-model, multilinear subspace learning ved hj\u00e6lp af tensorrepr\u00e6sentation og neuronal motiveret dynamisk link matching.", "token2charspan": [[0, 8], [9, 31], [32, 40], [41, 62], [63, 66], [67, 72], [73, 75], [76, 88], [88, 89], [90, 96], [97, 116], [116, 117], [118, 126], [127, 135], [136, 139], [140, 145], [146, 148], [149, 170], [170, 171], [172, 175], [176, 183], [184, 196], [196, 197], [198, 209], [210, 218], [219, 227], [228, 231], [232, 237], [238, 240], [241, 261], [262, 264], [265, 273], [274, 283], [284, 292], [293, 297], [298, 306], [306, 307]]}
{"doc_key": "ai-train-89", "ner": [[3, 7, "misc"], [17, 19, "location"], [37, 39, "location"], [53, 53, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[17, 19, 3, 7, "temporal", "", false, false], [37, 39, 3, 7, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Fra", "og", "med", "Toronto", "International", "Film", "Festival", "2019", "kan", "det", "nu", "v\u00e6re", "forbudt", "at", "vise", "film", "i", "Scotiabank", "Theatre", "Toronto", "-", "et", "af", "festivalens", "vigtigste", "spillesteder", "-", "og", "at", "vise", "dem", "andre", "steder", "(", "f.eks", ".", "i", "TIFF", "Bell", "Lightbox", "og", "andre", "lokale", "biografer", ")", ",", "hvis", "de", "distribueres", "af", "en", "tjeneste", "som", "Netflix", "."], "sentence-detokenized": "Fra og med Toronto International Film Festival 2019 kan det nu v\u00e6re forbudt at vise film i Scotiabank Theatre Toronto - et af festivalens vigtigste spillesteder - og at vise dem andre steder (f.eks. i TIFF Bell Lightbox og andre lokale biografer), hvis de distribueres af en tjeneste som Netflix.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 18], [19, 32], [33, 37], [38, 46], [47, 51], [52, 55], [56, 59], [60, 62], [63, 67], [68, 75], [76, 78], [79, 83], [84, 88], [89, 90], [91, 101], [102, 109], [110, 117], [118, 119], [120, 122], [123, 125], [126, 137], [138, 147], [148, 160], [161, 162], [163, 165], [166, 168], [169, 173], [174, 177], [178, 183], [184, 190], [191, 192], [192, 197], [197, 198], [199, 200], [201, 205], [206, 210], [211, 219], [220, 222], [223, 228], [229, 235], [236, 245], [245, 246], [246, 247], [248, 252], [253, 255], [256, 268], [269, 271], [272, 274], [275, 283], [284, 287], [288, 295], [295, 296]]}
{"doc_key": "ai-train-90", "ner": [[0, 0, "organisation"], [2, 3, "researcher"], [4, 5, "organisation"], [11, 11, "researcher"], [20, 25, "product"], [33, 33, "researcher"], [35, 35, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 4, 5, "related-to", "purchases", false, false], [2, 3, 11, 11, "named", "same", false, false], [2, 3, 33, 33, "named", "same", false, false], [4, 5, 2, 3, "origin", "founded_by", false, false], [20, 25, 0, 0, "artifact", "", false, false], [35, 35, 33, 33, "artifact", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Unimation", "k\u00f8bte", "Victor", "Scheinmans", "Vicarm", "Inc.", "i", "1977", ",", "og", "med", "Scheinmans", "hj\u00e6lp", "skabte", "og", "begyndte", "virksomheden", "at", "producere", "den", "programmerbare", "universalmaskine", "til", "montage", ",", "en", "ny", "model", "af", "robotarm", ",", "og", "brugte", "Scheinmans", "avancerede", "VAL-programmeringssprog", "."], "sentence-detokenized": "Unimation k\u00f8bte Victor Scheinmans Vicarm Inc. i 1977, og med Scheinmans hj\u00e6lp skabte og begyndte virksomheden at producere den programmerbare universalmaskine til montage, en ny model af robotarm, og brugte Scheinmans avancerede VAL-programmeringssprog.", "token2charspan": [[0, 9], [10, 15], [16, 22], [23, 33], [34, 40], [41, 45], [46, 47], [48, 52], [52, 53], [54, 56], [57, 60], [61, 71], [72, 77], [78, 84], [85, 87], [88, 96], [97, 109], [110, 112], [113, 122], [123, 126], [127, 141], [142, 158], [159, 162], [163, 170], [170, 171], [172, 174], [175, 177], [178, 183], [184, 186], [187, 195], [195, 196], [197, 199], [200, 206], [207, 217], [218, 228], [229, 252], [252, 253]]}
{"doc_key": "ai-train-91", "ner": [[0, 1, "product"], [7, 7, "algorithm"], [9, 11, "product"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[0, 1, 7, 7, "origin", "implementation_of", false, false], [0, 1, 9, 11, "part-of", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["J48", "er", "en", "open", "source", "Java-implementering", "af", "C4.5-algoritmen", "i", "Weka-v\u00e6rkt\u00f8jet", "til", "datamining", "."], "sentence-detokenized": "J48 er en open source Java-implementering af C4.5-algoritmen i Weka-v\u00e6rkt\u00f8jet til datamining.", "token2charspan": [[0, 3], [4, 6], [7, 9], [10, 14], [15, 21], [22, 41], [42, 44], [45, 60], [61, 62], [63, 77], [78, 81], [82, 92], [92, 93]]}
{"doc_key": "ai-train-92", "ner": [[10, 13, "product"], [18, 24, "misc"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["SSIM-papiret", "fra", "2004", "er", "blevet", "citeret", "over", "20.000", "gange", "if\u00f8lge", "Google", "Scholar", ",", "og", "det", "har", "ogs\u00e5", "modtaget", "IEEE", "Signal", "Processing", "Society", "Sustained", "Impact", "Award", "for", "2016", ",", "som", "er", "et", "tegn", "p\u00e5", ",", "at", "et", "papir", "har", "haft", "us\u00e6dvanlig", "stor", "gennemslagskraft", "i", "mindst", "10", "\u00e5r", "efter", "offentligg\u00f8relsen", "."], "sentence-detokenized": "SSIM-papiret fra 2004 er blevet citeret over 20.000 gange if\u00f8lge Google Scholar, og det har ogs\u00e5 modtaget IEEE Signal Processing Society Sustained Impact Award for 2016, som er et tegn p\u00e5, at et papir har haft us\u00e6dvanlig stor gennemslagskraft i mindst 10 \u00e5r efter offentligg\u00f8relsen.", "token2charspan": [[0, 12], [13, 16], [17, 21], [22, 24], [25, 31], [32, 39], [40, 44], [45, 51], [52, 57], [58, 64], [65, 71], [72, 79], [79, 80], [81, 83], [84, 87], [88, 91], [92, 96], [97, 105], [106, 110], [111, 117], [118, 128], [129, 136], [137, 146], [147, 153], [154, 159], [160, 163], [164, 168], [168, 169], [170, 173], [174, 176], [177, 179], [180, 184], [185, 187], [187, 188], [189, 191], [192, 194], [195, 200], [201, 204], [205, 209], [210, 220], [221, 225], [226, 242], [243, 244], [245, 251], [252, 254], [255, 257], [258, 263], [264, 281], [281, 282]]}
{"doc_key": "ai-train-93", "ner": [[0, 0, "task"], [23, 24, "product"], [38, 40, "product"], [43, 43, "organisation"], [44, 44, "product"], [49, 49, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 43, 43, "artifact", "", false, false], [23, 24, 0, 0, "related-to", "performs", false, false], [23, 24, 38, 40, "part-of", "", false, false], [43, 43, 49, 49, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Talesyntesen", "er", "t\u00e6t", "p\u00e5", "at", "v\u00e6re", "helt", "umulig", "at", "skelne", "fra", "en", "rigtig", "menneskelig", "stemme", "med", "introduktionen", "i", "2016", "af", "stemmebearbejdnings-", "og", "genereringsprogrammet", "Adobe", "Voco", ",", "en", "prototype", ",", "der", "er", "planlagt", "til", "at", "blive", "en", "del", "af", "Adobe", "Creative", "Suite", ",", "og", "DeepMind", "WaveNet", ",", "en", "prototype", "fra", "Google", "."], "sentence-detokenized": "Talesyntesen er t\u00e6t p\u00e5 at v\u00e6re helt umulig at skelne fra en rigtig menneskelig stemme med introduktionen i 2016 af stemmebearbejdnings- og genereringsprogrammet Adobe Voco, en prototype, der er planlagt til at blive en del af Adobe Creative Suite, og DeepMind WaveNet, en prototype fra Google.", "token2charspan": [[0, 12], [13, 15], [16, 19], [20, 22], [23, 25], [26, 30], [31, 35], [36, 42], [43, 45], [46, 52], [53, 56], [57, 59], [60, 66], [67, 78], [79, 85], [86, 89], [90, 104], [105, 106], [107, 111], [112, 114], [115, 135], [136, 138], [139, 160], [161, 166], [167, 171], [171, 172], [173, 175], [176, 185], [185, 186], [187, 190], [191, 193], [194, 202], [203, 206], [207, 209], [210, 215], [216, 218], [219, 222], [223, 225], [226, 231], [232, 240], [241, 246], [246, 247], [248, 250], [251, 259], [260, 267], [267, 268], [269, 271], [272, 281], [282, 285], [286, 292], [292, 293]]}
{"doc_key": "ai-train-94", "ner": [[0, 1, "researcher"], [4, 6, "organisation"], [10, 15, "organisation"], [21, 21, "conference"], [27, 31, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 4, 6, "role", "", false, false], [0, 1, 10, 15, "role", "", false, false], [0, 1, 21, 21, "role", "", false, false], [0, 1, 27, 31, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Poggio", "er", "\u00e6resmedlem", "af", "Neuroscience", "Research", "Program", ",", "medlem", "af", "American", "Academy", "of", "Arts", "and", "Sciences", "og", "en", "af", "grundl\u00e6ggerne", "af", "AAAI", "og", "et", "af", "grundl\u00e6ggerne", "af", "McGovern", "Institute", "for", "Brain", "Research", "."], "sentence-detokenized": "Poggio er \u00e6resmedlem af Neuroscience Research Program, medlem af American Academy of Arts and Sciences og en af grundl\u00e6ggerne af AAAI og et af grundl\u00e6ggerne af McGovern Institute for Brain Research.", "token2charspan": [[0, 6], [7, 9], [10, 20], [21, 23], [24, 36], [37, 45], [46, 53], [53, 54], [55, 61], [62, 64], [65, 73], [74, 81], [82, 84], [85, 89], [90, 93], [94, 102], [103, 105], [106, 108], [109, 111], [112, 125], [126, 128], [129, 133], [134, 136], [137, 139], [140, 142], [143, 156], [157, 159], [160, 168], [169, 178], [179, 182], [183, 188], [189, 197], [197, 198]]}
{"doc_key": "ai-train-95", "ner": [[12, 12, "task"], [14, 16, "task"], [19, 19, "task"], [24, 24, "misc"], [25, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 12, 19, 19, "cause-effect", "", false, false], [14, 16, 19, 19, "cause-effect", "", false, false], [25, 25, 19, 19, "topic", "", false, false], [25, 25, 24, 24, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["I", "l\u00f8bet", "af", "1990'erne", "begyndte", "man", ",", "tilskyndet", "af", "succeser", "inden", "for", "talegenkendelse", "og", "talesyntese", ",", "at", "forske", "i", "taleovers\u00e6ttelse", "med", "udviklingen", "af", "det", "tyske", "Verbmobilprojekt", "."], "sentence-detokenized": "I l\u00f8bet af 1990'erne begyndte man, tilskyndet af succeser inden for talegenkendelse og talesyntese, at forske i taleovers\u00e6ttelse med udviklingen af det tyske Verbmobilprojekt.", "token2charspan": [[0, 1], [2, 7], [8, 10], [11, 20], [21, 29], [30, 33], [33, 34], [35, 45], [46, 48], [49, 57], [58, 63], [64, 67], [68, 83], [84, 86], [87, 98], [98, 99], [100, 102], [103, 109], [110, 111], [112, 128], [129, 132], [133, 144], [145, 147], [148, 151], [152, 157], [158, 174], [174, 175]]}
{"doc_key": "ai-train-96", "ner": [[3, 4, "researcher"], [8, 9, "researcher"], [11, 12, "researcher"], [13, 14, "algorithm"], [18, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 8, 9, "role", "", false, false], [13, 14, 3, 4, "origin", "", false, false], [13, 14, 8, 9, "origin", "", false, false], [13, 14, 11, 12, "origin", "", false, false], [18, 19, 13, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5], "sentence": ["I", "1999", "indf\u00f8rte", "Felix", "Gers", "og", "hans", "r\u00e5dgiver", "J\u00fcrgen", "Schmidhuber", "og", "Fred", "Cummins", "forget", "gate", "(", "ogs\u00e5", "kaldet", "keep", "gate", ")", "i", "LSTM-arkitekturen", ","], "sentence-detokenized": "I 1999 indf\u00f8rte Felix Gers og hans r\u00e5dgiver J\u00fcrgen Schmidhuber og Fred Cummins forget gate (ogs\u00e5 kaldet keep gate) i LSTM-arkitekturen,", "token2charspan": [[0, 1], [2, 6], [7, 15], [16, 21], [22, 26], [27, 29], [30, 34], [35, 43], [44, 50], [51, 62], [63, 65], [66, 70], [71, 78], [79, 85], [86, 90], [91, 92], [92, 96], [97, 103], [104, 108], [109, 113], [113, 114], [115, 116], [117, 134], [134, 135]]}
{"doc_key": "ai-train-97", "ner": [[2, 3, "field"], [5, 5, "field"], [8, 9, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 2, 3, "part-of", "", false, false], [8, 9, 5, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Inden", "for", "digital", "signalbehandling", "og", "informationsteori", "defineres", "den", "normaliserede", "sinc-funktion", "almindeligvis", "ved"], "sentence-detokenized": "Inden for digital signalbehandling og informationsteori defineres den normaliserede sinc-funktion almindeligvis ved", "token2charspan": [[0, 5], [6, 9], [10, 17], [18, 34], [35, 37], [38, 55], [56, 65], [66, 69], [70, 83], [84, 97], [98, 111], [112, 115]]}
{"doc_key": "ai-train-98", "ner": [[2, 2, "field"], [7, 8, "researcher"], [17, 20, "conference"], [22, 26, "organisation"], [28, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 7, 8, "origin", "coined_term", false, false], [7, 8, 17, 20, "role", "", false, false], [7, 8, 22, 26, "role", "", false, false], [28, 28, 22, 26, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Selve", "udtrykket", "computerlingvistik", "blev", "f\u00f8rst", "opfundet", "af", "David", "Hays", ",", "et", "af", "de", "stiftende", "medlemmer", "af", "b\u00e5de", "Association", "for", "Computational", "Linguistics", "og", "International", "Committee", "on", "Computational", "Linguistics", "(", "ICCL", ")", "."], "sentence-detokenized": "Selve udtrykket computerlingvistik blev f\u00f8rst opfundet af David Hays, et af de stiftende medlemmer af b\u00e5de Association for Computational Linguistics og International Committee on Computational Linguistics (ICCL).", "token2charspan": [[0, 5], [6, 15], [16, 34], [35, 39], [40, 45], [46, 54], [55, 57], [58, 63], [64, 68], [68, 69], [70, 72], [73, 75], [76, 78], [79, 88], [89, 98], [99, 101], [102, 106], [107, 118], [119, 122], [123, 136], [137, 148], [149, 151], [152, 165], [166, 175], [176, 178], [179, 192], [193, 204], [205, 206], [206, 210], [210, 211], [211, 212]]}
{"doc_key": "ai-train-99", "ner": [[9, 12, "misc"], [17, 17, "misc"], [48, 50, "metrics"], [52, 56, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[52, 56, 48, 50, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["59", ",", "pp.", "2547-2553", ",", "Oct", ".", "2011", "I", "en", "dimensionel", "polynomialbaseret", "hukommelse", "(", "eller", "hukommelsesl\u00f8s", ")", "DPD", "skal", "det", "forvr\u00e6ngede", "output", "af", "det", "ikke-line\u00e6re", "system", "over-samples", "med", "en", "hastighed", ",", "der", "g\u00f8r", "det", "muligt", "at", "indfange", "de", "ikke-line\u00e6re", "produkter", "af", "den", "digitale", "pre-distorters", "koefficienter", "og", "minimere", "den", "gennemsnitlige", "kvadrerede", "fejl", "(", "MSE", ")", ",", "for", "at", "l\u00f8se", "for", "de", "digitale", "pre-distorters", "koefficienter", "."], "sentence-detokenized": "59, pp. 2547-2553, Oct. 2011 I en dimensionel polynomialbaseret hukommelse (eller hukommelsesl\u00f8s) DPD skal det forvr\u00e6ngede output af det ikke-line\u00e6re system over-samples med en hastighed, der g\u00f8r det muligt at indfange de ikke-line\u00e6re produkter af den digitale pre-distorters koefficienter og minimere den gennemsnitlige kvadrerede fejl (MSE), for at l\u00f8se for de digitale pre-distorters koefficienter.", "token2charspan": [[0, 2], [2, 3], [4, 7], [8, 17], [17, 18], [19, 22], [22, 23], [24, 28], [29, 30], [31, 33], [34, 45], [46, 63], [64, 74], [75, 76], [76, 81], [82, 96], [96, 97], [98, 101], [102, 106], [107, 110], [111, 122], [123, 129], [130, 132], [133, 136], [137, 149], [150, 156], [157, 169], [170, 173], [174, 176], [177, 186], [186, 187], [188, 191], [192, 195], [196, 199], [200, 206], [207, 209], [210, 218], [219, 221], [222, 234], [235, 244], [245, 247], [248, 251], [252, 260], [261, 275], [276, 289], [290, 292], [293, 301], [302, 305], [306, 320], [321, 331], [332, 336], [337, 338], [338, 341], [341, 342], [342, 343], [344, 347], [348, 350], [351, 355], [356, 359], [360, 362], [363, 371], [372, 386], [387, 400], [400, 401]]}
{"doc_key": "ai-train-100", "ner": [[0, 1, "researcher"], [10, 10, "location"], [12, 13, "location"], [15, 15, "country"], [18, 18, "location"], [20, 20, "country"], [31, 37, "organisation"], [39, 42, "organisation"], [44, 44, "location"], [49, 50, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 1, 10, 10, "physical", "", false, false], [0, 1, 39, 42, "physical", "", false, false], [0, 1, 49, 50, "role", "", false, false], [10, 10, 12, 13, "physical", "", false, false], [12, 13, 15, 15, "physical", "", false, false], [31, 37, 39, 42, "part-of", "", false, false], [39, 42, 44, 44, "physical", "", false, false], [49, 50, 31, 37, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Boris", "Katz", ",", "(", "f\u00f8dt", "den", "5.", "oktober", "1947", "i", "Chi\u0219in\u0103u", ",", "Moldavisk", "SSR", ",", "Sovjetunionen", "(", "nu", "Chi\u0219in\u0103u", ",", "Moldova", ")", ")", "er", "en", "amerikansk", "forsker", "(", "datalog", ")", "ved", "MIT", "Computer", "Science", "and", "Artificial", "Intelligence", "Laboratory", "ved", "Massachusetts", "Institute", "of", "Technology", "i", "Cambridge", "og", "leder", "af", "laboratoriets", "InfoLab", "Group", "."], "sentence-detokenized": "Boris Katz, (f\u00f8dt den 5. oktober 1947 i Chi\u0219in\u0103u, Moldavisk SSR, Sovjetunionen (nu Chi\u0219in\u0103u, Moldova)) er en amerikansk forsker (datalog) ved MIT Computer Science and Artificial Intelligence Laboratory ved Massachusetts Institute of Technology i Cambridge og leder af laboratoriets InfoLab Group.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 13], [13, 17], [18, 21], [22, 24], [25, 32], [33, 37], [38, 39], [40, 48], [48, 49], [50, 59], [60, 63], [63, 64], [65, 78], [79, 80], [80, 82], [83, 91], [91, 92], [93, 100], [100, 101], [101, 102], [103, 105], [106, 108], [109, 119], [120, 127], [128, 129], [129, 136], [136, 137], [138, 141], [142, 145], [146, 154], [155, 162], [163, 166], [167, 177], [178, 190], [191, 201], [202, 205], [206, 219], [220, 229], [230, 232], [233, 243], [244, 245], [246, 255], [256, 258], [259, 264], [265, 267], [268, 281], [282, 289], [290, 295], [295, 296]]}
