{"doc_key": "ai-train-1", "ner": [[2, 6, "product"], [14, 14, "field"], [16, 17, "task"], [19, 20, "task"], [24, 26, "task"], [29, 30, "field"], [31, 35, "researcher"], [37, 37, "researcher"], [43, 45, "researcher"], [47, 49, "researcher"], [39, 53, "researcher"], [57, 59, "researcher"], [61, 65, "researcher"], [67, 69, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[2, 6, 14, 14, "part-of", "", false, false], [2, 6, 14, 14, "usage", "", false, false], [2, 6, 16, 17, "part-of", "", false, false], [2, 6, 16, 17, "usage", "", false, false], [2, 6, 19, 20, "part-of", "", false, false], [2, 6, 19, 20, "usage", "", false, false], [2, 6, 29, 30, "part-of", "", false, false], [2, 6, 29, 30, "usage", "", false, false], [24, 26, 19, 20, "part-of", "", false, false], [24, 26, 19, 20, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Popularne", "podej\u015bcia", "systemu", "rekomendacji", "opartego", "na", "opinii", "wykorzystuj\u0105", "r\u00f3\u017cne", "techniki", ",", "w", "tym", "eksploracj\u0119", "tekstu", ",", "wyszukiwanie", "informacji", ",", "analiz\u0119", "sentymentu", "(", "patrz", "tak\u017ce", "Multimodalna", "analiza", "sentymentu", ")", "i", "g\u0142\u0119bokie", "uczenie", "X", ".", "Y", ".", "Feng", ",", "H", ".", "Zhang", ",", "Y", ".", "J", ".", "Ren", ",", "P.H", ".", "Shang", ",", "Y", ".", "Zhu", ",", "Y", ".", "C", ".", "Liang", ",", "R", ".", "C", ".", "Guan", ",", "D", ".", "Xu", ",", "(", "2019", ")", ",", "21", "(", "5", ")", ":", "e12957", "."], "sentence-detokenized": "Popularne podej\u015bcia systemu rekomendacji opartego na opinii wykorzystuj\u0105 r\u00f3\u017cne techniki, w tym eksploracj\u0119 tekstu, wyszukiwanie informacji, analiz\u0119 sentymentu (patrz tak\u017ce Multimodalna analiza sentymentu) i g\u0142\u0119bokie uczenie X.Y. Feng, H. Zhang, Y.J. Ren, P.H. Shang, Y. Zhu, Y.C. Liang, R.C. Guan, D. Xu, (2019), 21 (5): e12957.", "token2charspan": [[0, 9], [10, 19], [20, 27], [28, 40], [41, 49], [50, 52], [53, 59], [60, 72], [73, 78], [79, 87], [87, 88], [89, 90], [91, 94], [95, 106], [107, 113], [113, 114], [115, 127], [128, 138], [138, 139], [140, 147], [148, 158], [159, 160], [160, 165], [166, 171], [172, 184], [185, 192], [193, 203], [203, 204], [205, 206], [207, 215], [216, 223], [224, 225], [225, 226], [226, 227], [227, 228], [229, 233], [233, 234], [235, 236], [236, 237], [238, 243], [243, 244], [245, 246], [246, 247], [247, 248], [248, 249], [250, 253], [253, 254], [255, 258], [258, 259], [260, 265], [265, 266], [267, 268], [268, 269], [270, 273], [273, 274], [275, 276], [276, 277], [277, 278], [278, 279], [280, 285], [285, 286], [287, 288], [288, 289], [289, 290], [290, 291], [292, 296], [296, 297], [298, 299], [299, 300], [301, 303], [303, 304], [305, 306], [306, 310], [310, 311], [311, 312], [313, 315], [316, 317], [317, 318], [318, 319], [319, 320], [321, 327], [327, 328]]}
{"doc_key": "ai-train-2", "ner": [[7, 7, "university"], [11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 7, 7, "physical", "", false, false], [11, 12, 7, 7, "role", "", false, false], [14, 15, 7, 7, "physical", "", false, false], [14, 15, 7, 7, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Zwolennicy", "reprezentacji", "proceduralnych", "skupiali", "si\u0119", "g\u0142\u00f3wnie", "w", "MIT", ",", "pod", "przewodnictwem", "Marvina", "Minsky'ego", "i", "Seymoura", "Paperta", "."], "sentence-detokenized": "Zwolennicy reprezentacji proceduralnych skupiali si\u0119 g\u0142\u00f3wnie w MIT, pod przewodnictwem Marvina Minsky'ego i Seymoura Paperta.", "token2charspan": [[0, 10], [11, 24], [25, 39], [40, 48], [49, 52], [53, 60], [61, 62], [63, 66], [66, 67], [68, 71], [72, 86], [87, 94], [95, 105], [106, 107], [108, 116], [117, 124], [124, 125]]}
{"doc_key": "ai-train-3", "ner": [[9, 9, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Interfejs", "standardowy", "i", "interfejs", "kalkulatora", "s\u0105", "napisane", "w", "j\u0119zyku", "Java", "."], "sentence-detokenized": "Interfejs standardowy i interfejs kalkulatora s\u0105 napisane w j\u0119zyku Java.", "token2charspan": [[0, 9], [10, 21], [22, 23], [24, 33], [34, 45], [46, 48], [49, 57], [58, 59], [60, 66], [67, 71], [71, 72]]}
{"doc_key": "ai-train-4", "ner": [[0, 0, "product"], [25, 25, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 25, 25, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["Octave", "pomaga", "w", "numerycznym", "rozwi\u0105zywaniu", "liniowych", "i", "nieliniowych", "problem\u00f3w", "oraz", "w", "przeprowadzaniu", "innych", "eksperyment\u00f3w", "numerycznych", "przy", "u\u017cyciu", "programu", ",", "kt\u00f3ry", "jest", "w", "wi\u0119kszo\u015bci", "kompatybilny", "z", "MATLABem", "."], "sentence-detokenized": "Octave pomaga w numerycznym rozwi\u0105zywaniu liniowych i nieliniowych problem\u00f3w oraz w przeprowadzaniu innych eksperyment\u00f3w numerycznych przy u\u017cyciu programu, kt\u00f3ry jest w wi\u0119kszo\u015bci kompatybilny z MATLABem.", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 27], [28, 41], [42, 51], [52, 53], [54, 66], [67, 76], [77, 81], [82, 83], [84, 99], [100, 106], [107, 120], [121, 133], [134, 138], [139, 145], [146, 154], [154, 155], [156, 161], [162, 166], [167, 168], [169, 179], [180, 192], [193, 194], [195, 203], [203, 204]]}
{"doc_key": "ai-train-5", "ner": [[1, 3, "algorithm"], [7, 9, "misc"], [10, 11, "researcher"], [15, 17, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 3, 10, 11, "origin", "", false, false], [7, 9, 10, 11, "origin", "", false, false], [10, 11, 15, 17, "physical", "", false, false], [10, 11, 15, 17, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Warianty", "algorytmu", "wstecznej", "propagacji", ",", "jak", "r\u00f3wnie\u017c", "metody", "bez", "nadzoru", "Geoffa", "Hintona", "i", "koleg\u00f3w", "z", "Uniwersytetu", "w", "Toronto", "mog\u0105", "by\u0107", "wykorzystane", "do", "trenowania", "g\u0142\u0119bokich", ",", "wysoce", "nieliniowych", "architektur", "neuronowych", ",", "{", "{", "cite", "journal"], "sentence-detokenized": "Warianty algorytmu wstecznej propagacji, jak r\u00f3wnie\u017c metody bez nadzoru Geoffa Hintona i koleg\u00f3w z Uniwersytetu w Toronto mog\u0105 by\u0107 wykorzystane do trenowania g\u0142\u0119bokich, wysoce nieliniowych architektur neuronowych, {{cite journal", "token2charspan": [[0, 8], [9, 18], [19, 28], [29, 39], [39, 40], [41, 44], [45, 52], [53, 59], [60, 63], [64, 71], [72, 78], [79, 86], [87, 88], [89, 96], [97, 98], [99, 111], [112, 113], [114, 121], [122, 126], [127, 130], [131, 143], [144, 146], [147, 157], [158, 167], [167, 168], [169, 175], [176, 188], [189, 200], [201, 212], [212, 213], [214, 215], [215, 216], [216, 220], [221, 228]]}
{"doc_key": "ai-train-6", "ner": [[4, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["lub", "r\u00f3wnowa\u017cnie", "u\u017cywaj\u0105c", "notacji", "DCG", ":"], "sentence-detokenized": "lub r\u00f3wnowa\u017cnie u\u017cywaj\u0105c notacji DCG:", "token2charspan": [[0, 3], [4, 15], [16, 24], [25, 32], [33, 36], [36, 37]]}
{"doc_key": "ai-train-7", "ner": [[0, 2, "algorithm"], [7, 10, "algorithm"], [14, 17, "algorithm"], [22, 23, "algorithm"], [28, 28, "algorithm"], [30, 31, "algorithm"], [42, 43, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 7, 10, "type-of", "", false, false], [0, 2, 14, 17, "usage", "part-of?", true, false], [14, 17, 22, 23, "compare", "", false, false], [28, 28, 22, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Mapy", "samoorganizuj\u0105ce", "si\u0119", "r\u00f3\u017cni\u0105", "si\u0119", "od", "innych", "sztucznych", "sieci", "neuronowych", "tym", ",", "\u017ce", "stosuj\u0105", "uczenie", "konkurencyjne", "(", "w", "przeciwie\u0144stwie", "do", "uczenia", "z", "korekcj\u0105", "b\u0142\u0119d\u00f3w", ",", "jak", "np", ".", "backpropagacja", "z", "zej\u015bciem", "gradientowym", ")", "oraz", "tym", ",", "\u017ce", "wykorzystuj\u0105", "funkcj\u0119", "s\u0105siedztwa", "do", "zachowania", "topologicznych", "w\u0142a\u015bciwo\u015bci", "przestrzeni", "wej\u015bciowej", "."], "sentence-detokenized": "Mapy samoorganizuj\u0105ce si\u0119 r\u00f3\u017cni\u0105 si\u0119 od innych sztucznych sieci neuronowych tym, \u017ce stosuj\u0105 uczenie konkurencyjne (w przeciwie\u0144stwie do uczenia z korekcj\u0105 b\u0142\u0119d\u00f3w, jak np. backpropagacja z zej\u015bciem gradientowym) oraz tym, \u017ce wykorzystuj\u0105 funkcj\u0119 s\u0105siedztwa do zachowania topologicznych w\u0142a\u015bciwo\u015bci przestrzeni wej\u015bciowej.", "token2charspan": [[0, 4], [5, 21], [22, 25], [26, 32], [33, 36], [37, 39], [40, 46], [47, 57], [58, 63], [64, 75], [76, 79], [79, 80], [81, 83], [84, 91], [92, 99], [100, 113], [114, 115], [115, 116], [117, 132], [133, 135], [136, 143], [144, 145], [146, 154], [155, 161], [161, 162], [163, 166], [167, 169], [169, 170], [171, 185], [186, 187], [188, 196], [197, 209], [209, 210], [211, 215], [216, 219], [219, 220], [221, 223], [224, 236], [237, 244], [245, 255], [256, 258], [259, 269], [270, 284], [285, 296], [297, 308], [309, 319], [319, 320]]}
{"doc_key": "ai-train-8", "ner": [[13, 15, "organisation"], [25, 26, "misc"], [33, 35, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Od", "wczesnych", "lat", "90-tych", ",", "zalecane", "jest", "przez", "kilka", "autorytet\u00f3w", ",", "w", "tym", "Audio", "Engineering", "Society", ",", "aby", "pomiary", "zakresu", "dynamiki", "by\u0142y", "wykonywane", "przy", "obecnym", "sygnale", "audio", ",", "kt\u00f3ry", "jest", "nast\u0119pnie", "odfiltrowywany", "w", "pomiarze", "pod\u0142ogi", "szum\u00f3w", "u\u017cywanym", "do", "okre\u015blenia", "zakresu", "dynamiki", ".", "Pozwala", "to", "na", "unikni\u0119cie", "w\u0105tpliwych", "pomiar\u00f3w", "opartych", "na", "wykorzystaniu", "pustych", "no\u015bnik\u00f3w", "lub", "uk\u0142ad\u00f3w", "wyciszaj\u0105cych", "."], "sentence-detokenized": "Od wczesnych lat 90-tych, zalecane jest przez kilka autorytet\u00f3w, w tym Audio Engineering Society, aby pomiary zakresu dynamiki by\u0142y wykonywane przy obecnym sygnale audio, kt\u00f3ry jest nast\u0119pnie odfiltrowywany w pomiarze pod\u0142ogi szum\u00f3w u\u017cywanym do okre\u015blenia zakresu dynamiki. Pozwala to na unikni\u0119cie w\u0105tpliwych pomiar\u00f3w opartych na wykorzystaniu pustych no\u015bnik\u00f3w lub uk\u0142ad\u00f3w wyciszaj\u0105cych.", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 24], [24, 25], [26, 34], [35, 39], [40, 45], [46, 51], [52, 63], [63, 64], [65, 66], [67, 70], [71, 76], [77, 88], [89, 96], [96, 97], [98, 101], [102, 109], [110, 117], [118, 126], [127, 131], [132, 142], [143, 147], [148, 155], [156, 163], [164, 169], [169, 170], [171, 176], [177, 181], [182, 191], [192, 206], [207, 208], [209, 217], [218, 225], [226, 232], [233, 241], [242, 244], [245, 255], [256, 263], [264, 272], [272, 273], [274, 281], [282, 284], [285, 287], [288, 298], [299, 309], [310, 318], [319, 327], [328, 330], [331, 344], [345, 352], [353, 361], [362, 365], [366, 373], [374, 387], [387, 388]]}
{"doc_key": "ai-train-9", "ner": [[5, 5, "misc"], [4, 16, "task"], [19, 20, "task"], [22, 27, "task"], [28, 28, "task"], [31, 32, "task"], [30, 35, "task"], [37, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[5, 5, 4, 16, "part-of", "concept_used_in", true, false], [5, 5, 19, 20, "part-of", "concept_used_in", false, false], [5, 5, 22, 27, "part-of", "concept_used_in", false, false], [5, 5, 28, 28, "part-of", "concept_used_in", false, false], [5, 5, 31, 32, "part-of", "concept_used_in", false, false], [5, 5, 30, 35, "part-of", "concept_used_in", false, false], [5, 5, 37, 39, "part-of", "concept_used_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Technika", "stosowana", "przy", "tworzeniu", "twarzy", "w\u0142asnych", "i", "wykorzystywaniu", "ich", "do", "rozpoznawania", "znajduje", "zastosowanie", "r\u00f3wnie\u017c", "poza", "rozpoznawaniem", "twarzy", ":", "rozpoznawanie", "pisma", "r\u0119cznego", ",", "czytanie", "z", "ruchu", "warg", ",", "rozpoznawanie", "g\u0142osu", ",", "interpretacja", "j\u0119zyka", "migowego", "/", "gest\u00f3w", "r\u0105k", "oraz", "analiza", "obraz\u00f3w", "medycznych", "."], "sentence-detokenized": "Technika stosowana przy tworzeniu twarzy w\u0142asnych i wykorzystywaniu ich do rozpoznawania znajduje zastosowanie r\u00f3wnie\u017c poza rozpoznawaniem twarzy: rozpoznawanie pisma r\u0119cznego, czytanie z ruchu warg, rozpoznawanie g\u0142osu, interpretacja j\u0119zyka migowego / gest\u00f3w r\u0105k oraz analiza obraz\u00f3w medycznych.", "token2charspan": [[0, 8], [9, 18], [19, 23], [24, 33], [34, 40], [41, 49], [50, 51], [52, 67], [68, 71], [72, 74], [75, 88], [89, 97], [98, 110], [111, 118], [119, 123], [124, 138], [139, 145], [145, 146], [147, 160], [161, 166], [167, 175], [175, 176], [177, 185], [186, 187], [188, 193], [194, 198], [198, 199], [200, 213], [214, 219], [219, 220], [221, 234], [235, 241], [242, 250], [251, 252], [253, 259], [260, 263], [264, 268], [269, 276], [277, 284], [285, 295], [295, 296]]}
{"doc_key": "ai-train-10", "ner": [[0, 2, "organisation"], [6, 10, "organisation"], [12, 12, "organisation"], [15, 17, "organisation"], [20, 22, "organisation"], [25, 26, "organisation"], [29, 32, "organisation"], [34, 34, "organisation"], [37, 40, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[6, 10, 0, 2, "part-of", "", false, false], [12, 12, 6, 10, "named", "", false, false], [15, 17, 0, 2, "part-of", "", false, false], [20, 22, 0, 2, "part-of", "", false, false], [25, 26, 0, 2, "part-of", "", false, false], [29, 32, 0, 2, "part-of", "", false, false], [34, 34, 29, 32, "named", "", false, false], [37, 40, 0, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["National", "Science", "Foundation", "by\u0142a", "parasolem", "dla", "National", "Aeronautics", "and", "Space", "Administration", "(", "NASA", ")", ",", "Departament", "Energii", "USA", ",", "Departament", "Handlu", "USA", "NIST", ",", "Departament", "Obrony", "USA", ",", "Defense", "Advanced", "Research", "Projects", "Agency", "(", "DARPA", ")", "i", "Office", "of", "Naval", "Research", "koordynowa\u0142y", "badania", ",", "aby", "poinformowa\u0107", "planist\u00f3w", "strategicznych", "w", "ich", "rozwa\u017caniach", "."], "sentence-detokenized": "National Science Foundation by\u0142a parasolem dla National Aeronautics and Space Administration (NASA), Departament Energii USA, Departament Handlu USA NIST, Departament Obrony USA, Defense Advanced Research Projects Agency (DARPA) i Office of Naval Research koordynowa\u0142y badania, aby poinformowa\u0107 planist\u00f3w strategicznych w ich rozwa\u017caniach.", "token2charspan": [[0, 8], [9, 16], [17, 27], [28, 32], [33, 42], [43, 46], [47, 55], [56, 67], [68, 71], [72, 77], [78, 92], [93, 94], [94, 98], [98, 99], [99, 100], [101, 112], [113, 120], [121, 124], [124, 125], [126, 137], [138, 144], [145, 148], [149, 153], [153, 154], [155, 166], [167, 173], [174, 177], [177, 178], [179, 186], [187, 195], [196, 204], [205, 213], [214, 220], [221, 222], [222, 227], [227, 228], [229, 230], [231, 237], [238, 240], [241, 246], [247, 255], [256, 268], [269, 276], [276, 277], [278, 281], [282, 294], [295, 304], [305, 319], [320, 321], [322, 325], [326, 338], [338, 339]]}
{"doc_key": "ai-train-11", "ner": [[4, 5, "metrics"], [7, 8, "algorithm"], [12, 13, "researcher"], [18, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 7, 8, "part-of", "", false, false], [12, 13, 18, 18, "related-to", "added_appendix_to_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Szybka", "metoda", "obliczania", "oszacowa\u0144", "maksymalnego", "prawdopodobie\u0144stwa", "dla", "modelu", "probitowego", "zosta\u0142a", "zaproponowana", "przez", "Ronalda", "Fishera", "jako", "dodatek", "do", "pracy", "Blissa", "w", "1935", "roku", "."], "sentence-detokenized": "Szybka metoda obliczania oszacowa\u0144 maksymalnego prawdopodobie\u0144stwa dla modelu probitowego zosta\u0142a zaproponowana przez Ronalda Fishera jako dodatek do pracy Blissa w 1935 roku.", "token2charspan": [[0, 6], [7, 13], [14, 24], [25, 34], [35, 47], [48, 66], [67, 70], [71, 77], [78, 89], [90, 97], [98, 111], [112, 117], [118, 125], [126, 133], [134, 138], [139, 146], [147, 149], [150, 155], [156, 162], [163, 164], [165, 169], [170, 174], [174, 175]]}
{"doc_key": "ai-train-12", "ner": [[11, 12, "product"], [14, 15, "product"], [21, 21, "organisation"], [19, 19, "product"], [31, 31, "organisation"], [29, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[19, 19, 14, 15, "usage", "uses_software", false, false], [19, 19, 21, 21, "artifact", "", false, false], [19, 19, 29, 29, "named", "", false, false], [29, 29, 31, 31, "artifact", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kilka", "z", "tych", "program\u00f3w", "jest", "dost\u0119pnych", "w", "Internecie", ",", "np", ".", "Google", "Translate", "i", "system", "SYSTRAN", ",", "kt\u00f3ry", "zasila", "BabelFish", "firmy", "AltaVista", "(", "od", "9", "maja", "2008", "r", ".", "Babelfish", "firmy", "Yahoo", ")", "."], "sentence-detokenized": "Kilka z tych program\u00f3w jest dost\u0119pnych w Internecie, np. Google Translate i system SYSTRAN, kt\u00f3ry zasila BabelFish firmy AltaVista (od 9 maja 2008 r. Babelfish firmy Yahoo).", "token2charspan": [[0, 5], [6, 7], [8, 12], [13, 22], [23, 27], [28, 38], [39, 40], [41, 51], [51, 52], [53, 55], [55, 56], [57, 63], [64, 73], [74, 75], [76, 82], [83, 90], [90, 91], [92, 97], [98, 104], [105, 114], [115, 120], [121, 130], [131, 132], [132, 134], [135, 136], [137, 141], [142, 146], [147, 148], [148, 149], [150, 159], [160, 165], [166, 171], [171, 172], [172, 173]]}
{"doc_key": "ai-train-13", "ner": [[3, 3, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [18, 20, "field"], [25, 26, "misc"], [28, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 3, 18, 20, "related-to", "", true, false], [3, 3, 25, 26, "related-to", "", true, false], [3, 3, 28, 30, "related-to", "", true, false], [7, 8, 18, 20, "related-to", "", true, false], [7, 8, 25, 26, "related-to", "", true, false], [7, 8, 28, 30, "related-to", "", true, false], [10, 11, 18, 20, "related-to", "", true, false], [10, 11, 25, 26, "related-to", "", true, false], [10, 11, 28, 30, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["W", "2002", "roku", "Hutter", ",", "wraz", "z", "J\u00fcrgenem", "Schmidhuberem", "i", "Shane'em", "Leggiem", ",", "opracowa\u0142", "i", "opublikowa\u0142", "matematyczn\u0105", "teori\u0119", "sztucznej", "inteligencji", "og\u00f3lnej", ",", "opartej", "na", "wyidealizowanych", "inteligentnych", "agentach", "i", "uczeniu", "si\u0119", "wzmocnie\u0144", "motywowanych", "nagrod\u0105", "."], "sentence-detokenized": "W 2002 roku Hutter, wraz z J\u00fcrgenem Schmidhuberem i Shane'em Leggiem, opracowa\u0142 i opublikowa\u0142 matematyczn\u0105 teori\u0119 sztucznej inteligencji og\u00f3lnej, opartej na wyidealizowanych inteligentnych agentach i uczeniu si\u0119 wzmocnie\u0144 motywowanych nagrod\u0105.", "token2charspan": [[0, 1], [2, 6], [7, 11], [12, 18], [18, 19], [20, 24], [25, 26], [27, 35], [36, 49], [50, 51], [52, 60], [61, 68], [68, 69], [70, 79], [80, 81], [82, 93], [94, 106], [107, 113], [114, 123], [124, 136], [137, 144], [144, 145], [146, 153], [154, 156], [157, 173], [174, 188], [189, 197], [198, 199], [200, 207], [208, 211], [212, 221], [222, 234], [235, 242], [242, 243]]}
{"doc_key": "ai-train-14", "ner": [[7, 7, "metrics"], [9, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 7, 9, 15, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Najpopularniejszym", "sposobem", "jest", "zastosowanie", "tzw", ".", "miary", "ROUGE", "(", "Recall", "-", "Oriented", "Understudy", "for", "Gisting", "Evaluation", ")", "."], "sentence-detokenized": "Najpopularniejszym sposobem jest zastosowanie tzw. miary ROUGE (Recall-Oriented Understudy for Gisting Evaluation).", "token2charspan": [[0, 18], [19, 27], [28, 32], [33, 45], [46, 49], [49, 50], [51, 56], [57, 62], [63, 64], [64, 70], [70, 71], [71, 79], [80, 90], [91, 94], [95, 102], [103, 113], [113, 114], [114, 115]]}
{"doc_key": "ai-train-15", "ner": [[0, 0, "product"], [15, 15, "programlang"], [17, 17, "programlang"], [19, 20, "researcher"], [22, 23, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 15, 15, "related-to", "", false, false], [0, 0, 17, 17, "related-to", "", false, false], [19, 20, 22, 23, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["RapidMiner", "dostarcza", "schemat\u00f3w", "uczenia", ",", "modeli", "i", "algorytm\u00f3w", "i", "mo\u017ce", "by\u0107", "rozszerzany", "za", "pomoc\u0105", "skrypt\u00f3w", "R", "i", "Pythona", ".", "David", "Norris", ",", "Bloor", "Research", ",", "13", "listopada", "2013", "r", "."], "sentence-detokenized": "RapidMiner dostarcza schemat\u00f3w uczenia, modeli i algorytm\u00f3w i mo\u017ce by\u0107 rozszerzany za pomoc\u0105 skrypt\u00f3w R i Pythona. David Norris, Bloor Research, 13 listopada 2013 r.", "token2charspan": [[0, 10], [11, 20], [21, 30], [31, 38], [38, 39], [40, 46], [47, 48], [49, 59], [60, 61], [62, 66], [67, 70], [71, 82], [83, 85], [86, 92], [93, 101], [102, 103], [104, 105], [106, 113], [113, 114], [115, 120], [121, 127], [127, 128], [129, 134], [135, 143], [143, 144], [145, 147], [148, 157], [158, 162], [163, 164], [164, 165]]}
{"doc_key": "ai-train-16", "ner": [[3, 3, "product"], [26, 26, "task"], [0, 1, "product"]], "ner_mapping_to_source": [0, 2, 5], "relations": [[3, 3, 26, 26, "related-to", "", false, false], [3, 3, 0, 1, "related-to", "", true, false]], "relations_mapping_to_source": [1, 2], "sentence": ["Weka", "3", ",", "kt\u00f3rej", "rozw\u00f3j", "rozpocz\u0105\u0142", "si\u0119", "w", "1997", "roku", ",", "jest", "obecnie", "wykorzystywana", "w", "wielu", "r\u00f3\u017cnych", "obszarach", "zastosowa\u0144", ",", "w", "szczeg\u00f3lno\u015bci", "w", "celach", "edukacyjnych", "i", "badawczych", "."], "sentence-detokenized": "Weka 3, kt\u00f3rej rozw\u00f3j rozpocz\u0105\u0142 si\u0119 w 1997 roku, jest obecnie wykorzystywana w wielu r\u00f3\u017cnych obszarach zastosowa\u0144, w szczeg\u00f3lno\u015bci w celach edukacyjnych i badawczych.", "token2charspan": [[0, 4], [5, 6], [6, 7], [8, 14], [15, 21], [22, 31], [32, 35], [36, 37], [38, 42], [43, 47], [47, 48], [49, 53], [54, 61], [62, 76], [77, 78], [79, 84], [85, 92], [93, 102], [103, 113], [113, 114], [115, 116], [117, 130], [131, 132], [133, 139], [140, 152], [153, 154], [155, 165], [165, 166]]}
{"doc_key": "ai-train-17", "ner": [[0, 0, "product"], [14, 21, "misc"], [23, 26, "misc"], [28, 37, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 21, 0, 0, "topic", "", false, false], [14, 21, 23, 26, "win-defeat", "", false, false], [23, 26, 28, 37, "temporal", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Eurisko", "dokona\u0142", "wielu", "ciekawych", "odkry\u0107", "i", "cieszy\u0142", "si\u0119", "sporym", "uznaniem", ",", "a", "jego", "praca", "Heuretics", ":", "Theoretical", "and", "Study", "of", "Heuristic", "Rules", "zdoby\u0142", "nagrod\u0119", "za", "najlepszy", "referat", "na", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "w", "1982", "roku", "."], "sentence-detokenized": "Eurisko dokona\u0142 wielu ciekawych odkry\u0107 i cieszy\u0142 si\u0119 sporym uznaniem, a jego praca Heuretics: Theoretical and Study of Heuristic Rules zdoby\u0142 nagrod\u0119 za najlepszy referat na Association for the Advancement of Artificial Intelligence w 1982 roku.", "token2charspan": [[0, 7], [8, 15], [16, 21], [22, 31], [32, 38], [39, 40], [41, 48], [49, 52], [53, 59], [60, 68], [68, 69], [70, 71], [72, 76], [77, 82], [83, 92], [92, 93], [94, 105], [106, 109], [110, 115], [116, 118], [119, 128], [129, 134], [135, 141], [142, 149], [150, 152], [153, 162], [163, 170], [171, 173], [174, 185], [186, 189], [190, 193], [194, 205], [206, 208], [209, 219], [220, 232], [233, 234], [235, 239], [240, 244], [244, 245]]}
{"doc_key": "ai-train-18", "ner": [[13, 14, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Aby", "umo\u017cliwi\u0107", "korzystanie", "z", "wielu", "podmiot\u00f3w", ",", "dla", "ka\u017cdej", "kapsu\u0142y", "oblicza", "si\u0119", "oddzielny", "ubytek", "zawiasu", "."], "sentence-detokenized": "Aby umo\u017cliwi\u0107 korzystanie z wielu podmiot\u00f3w, dla ka\u017cdej kapsu\u0142y oblicza si\u0119 oddzielny ubytek zawiasu.", "token2charspan": [[0, 3], [4, 13], [14, 25], [26, 27], [28, 33], [34, 43], [43, 44], [45, 48], [49, 55], [56, 63], [64, 71], [72, 75], [76, 85], [86, 92], [93, 100], [100, 101]]}
{"doc_key": "ai-train-19", "ner": [[9, 10, "product"], [12, 13, "product"], [15, 16, "product"], [18, 19, "product"], [21, 22, "product"], [24, 25, "product"], [35, 39, "product"], [43, 44, "product"], [46, 47, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[9, 10, 24, 25, "type-of", "", false, false], [12, 13, 24, 25, "type-of", "", false, false], [15, 16, 24, 25, "type-of", "", false, false], [18, 19, 24, 25, "type-of", "", false, false], [21, 22, 24, 25, "type-of", "", false, false], [43, 44, 35, 39, "type-of", "", false, false], [46, 47, 35, 39, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Wraz", "z", "pojawieniem", "si\u0119", "asystent\u00f3w", "konwersacyjnych", ",", "takich", "jak", "Apple's", "Siri", ",", "Amazon", "Alexa", ",", "Google", "Assistant", ",", "Microsoft", "Cortana", "i", "Samsung's", "Bixby", ",", "portale", "g\u0142osowe", "mog\u0105", "by\u0107", "teraz", "dost\u0119pne", "za", "po\u015brednictwem", "urz\u0105dze\u0144", "mobilnych", "i", "inteligentnych", "g\u0142o\u015bnik\u00f3w", "g\u0142osowych", "Far", "Field", ",", "takich", "jak", "Amazon", "Echo", "i", "Google", "Home", "."], "sentence-detokenized": "Wraz z pojawieniem si\u0119 asystent\u00f3w konwersacyjnych, takich jak Apple's Siri, Amazon Alexa, Google Assistant, Microsoft Cortana i Samsung's Bixby, portale g\u0142osowe mog\u0105 by\u0107 teraz dost\u0119pne za po\u015brednictwem urz\u0105dze\u0144 mobilnych i inteligentnych g\u0142o\u015bnik\u00f3w g\u0142osowych Far Field, takich jak Amazon Echo i Google Home.", "token2charspan": [[0, 4], [5, 6], [7, 18], [19, 22], [23, 33], [34, 49], [49, 50], [51, 57], [58, 61], [62, 69], [70, 74], [74, 75], [76, 82], [83, 88], [88, 89], [90, 96], [97, 106], [106, 107], [108, 117], [118, 125], [126, 127], [128, 137], [138, 143], [143, 144], [145, 152], [153, 160], [161, 165], [166, 169], [170, 175], [176, 184], [185, 187], [188, 201], [202, 210], [211, 220], [221, 222], [223, 237], [238, 247], [248, 257], [258, 261], [262, 267], [267, 268], [269, 275], [276, 279], [280, 286], [287, 291], [292, 293], [294, 300], [301, 305], [305, 306]]}
{"doc_key": "ai-train-20", "ner": [[1, 2, "field"], [4, 6, "algorithm"], [8, 10, "algorithm"], [12, 13, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 1, 2, "type-of", "", false, false], [8, 10, 1, 2, "type-of", "", false, false], [12, 13, 1, 2, "type-of", "", false, false], [15, 15, 1, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Przyk\u0142adami", "uczenia", "nadzorowanego", "s\u0105", "klasyfikator", "Naive", "Bayes", ",", "maszyna", "wektor\u00f3w", "wsparcia", ",", "mieszaniny", "Gauss\u00f3w", "oraz", "sie\u0107", "."], "sentence-detokenized": "Przyk\u0142adami uczenia nadzorowanego s\u0105 klasyfikator Naive Bayes, maszyna wektor\u00f3w wsparcia, mieszaniny Gauss\u00f3w oraz sie\u0107.", "token2charspan": [[0, 11], [12, 19], [20, 33], [34, 36], [37, 49], [50, 55], [56, 61], [61, 62], [63, 70], [71, 79], [80, 88], [88, 89], [90, 100], [101, 108], [109, 113], [114, 118], [118, 119]]}
{"doc_key": "ai-train-21", "ner": [[2, 3, "algorithm"], [23, 25, "algorithm"], [27, 27, "task"], [31, 32, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 23, 25, "part-of", "", true, false], [31, 32, 27, 27, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Mo\u017cna", "u\u017cy\u0107", "algorytmu", "OSD", "do", "wyprowadzenia", "math", "O", "(", "\\u00", "}", "sqrt", "{", "T", "}", ")", "/", "math", "regret", "bounds", "dla", "wersji", "online", "Support", "vector", "machine", "for", "classification", ",", "kt\u00f3re", "u\u017cywaj\u0105", "straty", "zawiasowej", "math", "v", "_t", "(", "w", ")", "=", "max", "{", "0", ",", "1", "-", "y", "_t", "(", "w", "cdot", "x", "_t)", "\\u00", "}", ".", "/", "mat", "."], "sentence-detokenized": "Mo\u017cna u\u017cy\u0107 algorytmu OSD do wyprowadzenia math O (\\u00} sqrt {T}) / math regret bounds dla wersji online Support vector machine for classification, kt\u00f3re u\u017cywaj\u0105 straty zawiasowej math v _t (w) = max {0, 1 - y _t (w cdot x _t)\\u00}. / mat.", "token2charspan": [[0, 5], [6, 10], [11, 20], [21, 24], [25, 27], [28, 41], [42, 46], [47, 48], [49, 50], [50, 54], [54, 55], [56, 60], [61, 62], [62, 63], [63, 64], [64, 65], [66, 67], [68, 72], [73, 79], [80, 86], [87, 90], [91, 97], [98, 104], [105, 112], [113, 119], [120, 127], [128, 131], [132, 146], [146, 147], [148, 153], [154, 161], [162, 168], [169, 179], [180, 184], [185, 186], [187, 189], [190, 191], [191, 192], [192, 193], [194, 195], [196, 199], [200, 201], [201, 202], [202, 203], [204, 205], [206, 207], [208, 209], [210, 212], [213, 214], [214, 215], [216, 220], [221, 222], [223, 226], [226, 230], [230, 231], [231, 232], [233, 234], [235, 238], [238, 239]]}
{"doc_key": "ai-train-22", "ner": [[2, 3, "task"], [5, 8, "task"], [7, 7, "task"], [10, 10, "task"], [13, 14, "task"], [16, 17, "task"], [19, 20, "task"], [22, 25, "task"], [28, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Zastosowania", "obejmuj\u0105", "rozpoznawanie", "obiekt\u00f3w", ",", "mapowanie", "i", "nawigacj\u0119", "robot\u00f3w", ",", "zszywanie", "obraz\u00f3w", ",", "modelowanie", "3D", ",", "rozpoznawanie", "gest\u00f3w", ",", "\u015bledzenie", "wideo", ",", "indywidualn\u0105", "identyfikacj\u0119", "dzikich", "zwierz\u0105t", "i", "przenoszenie", "mecz\u00f3w", "."], "sentence-detokenized": "Zastosowania obejmuj\u0105 rozpoznawanie obiekt\u00f3w, mapowanie i nawigacj\u0119 robot\u00f3w, zszywanie obraz\u00f3w, modelowanie 3D, rozpoznawanie gest\u00f3w, \u015bledzenie wideo, indywidualn\u0105 identyfikacj\u0119 dzikich zwierz\u0105t i przenoszenie mecz\u00f3w.", "token2charspan": [[0, 12], [13, 21], [22, 35], [36, 44], [44, 45], [46, 55], [56, 57], [58, 67], [68, 75], [75, 76], [77, 86], [87, 94], [94, 95], [96, 107], [108, 110], [110, 111], [112, 125], [126, 132], [132, 133], [134, 143], [144, 149], [149, 150], [151, 163], [164, 177], [178, 185], [186, 194], [195, 196], [197, 209], [210, 216], [216, 217]]}
{"doc_key": "ai-train-23", "ner": [[7, 8, "task"], [14, 15, "university"], [17, 19, "university"], [21, 22, "university"], [24, 25, "university"], [29, 32, "university"], [36, 36, "university"], [38, 40, "university"], [42, 43, "university"], [45, 50, "university"], [52, 52, "university"], [59, 59, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[7, 8, 14, 15, "related-to", "", true, false], [7, 8, 17, 19, "related-to", "", true, false], [7, 8, 21, 22, "related-to", "", true, false], [7, 8, 24, 25, "related-to", "", true, false], [7, 8, 29, 32, "related-to", "", true, false], [7, 8, 36, 36, "related-to", "", true, false], [7, 8, 38, 40, "related-to", "", true, false], [7, 8, 42, 43, "related-to", "", true, false], [7, 8, 45, 50, "related-to", "", true, false], [7, 8, 52, 52, "related-to", "", true, false], [7, 8, 59, 59, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Wiele", "grup", "i", "firm", "prowadzi", "badania", "nad", "estymacj\u0105", "pozy", ",", "w", "tym", "grupy", "z", "Brown", "University", ",", "Carnegie", "Mellon", "University", ",", "MPI", "Saarbruecken", ",", "Stanford", "University", ",", "University", "of", "California", ",", "San", "Diego", ",", "University", "of", "Toronto", ",", "\u00c9cole", "Centrale", "Paris", ",", "ETH", "Zurich", ",", "National", "University", "of", "Sciences", "and", "Technology", "(", "NUST", ")", "oraz", "University", "of", "California", ",", "Irvine", "."], "sentence-detokenized": "Wiele grup i firm prowadzi badania nad estymacj\u0105 pozy, w tym grupy z Brown University, Carnegie Mellon University, MPI Saarbruecken, Stanford University, University of California, San Diego, University of Toronto, \u00c9cole Centrale Paris, ETH Zurich, National University of Sciences and Technology (NUST) oraz University of California, Irvine.", "token2charspan": [[0, 5], [6, 10], [11, 12], [13, 17], [18, 26], [27, 34], [35, 38], [39, 48], [49, 53], [53, 54], [55, 56], [57, 60], [61, 66], [67, 68], [69, 74], [75, 85], [85, 86], [87, 95], [96, 102], [103, 113], [113, 114], [115, 118], [119, 131], [131, 132], [133, 141], [142, 152], [152, 153], [154, 164], [165, 167], [168, 178], [178, 179], [180, 183], [184, 189], [189, 190], [191, 201], [202, 204], [205, 212], [212, 213], [214, 219], [220, 228], [229, 234], [234, 235], [236, 239], [240, 246], [246, 247], [248, 256], [257, 267], [268, 270], [271, 279], [280, 283], [284, 294], [295, 296], [296, 300], [300, 301], [302, 306], [307, 317], [318, 320], [321, 331], [331, 332], [333, 339], [339, 340]]}
{"doc_key": "ai-train-24", "ner": [[0, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Funkcja", "sigmoidalna", "Cross", "entropy", "loss", "s\u0142u\u017cy", "do", "przewidywania", "K", "niezale\u017cnych", "warto\u015bci", "prawdopodobie\u0144stwa", "w", "matematyce", "0,1", "/", "mat", "."], "sentence-detokenized": "Funkcja sigmoidalna Cross entropy loss s\u0142u\u017cy do przewidywania K niezale\u017cnych warto\u015bci prawdopodobie\u0144stwa w matematyce 0,1 / mat.", "token2charspan": [[0, 7], [8, 19], [20, 25], [26, 33], [34, 38], [39, 44], [45, 47], [48, 61], [62, 63], [64, 76], [77, 85], [86, 104], [105, 106], [107, 117], [118, 121], [122, 123], [124, 127], [127, 128]]}
{"doc_key": "ai-train-25", "ner": [[8, 10, "misc"], [12, 14, "field"], [16, 18, "university"], [20, 20, "country"], [22, 24, "misc"], [26, 30, "university"], [31, 31, "country"], [4, 4, "university"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6, 7, 8], "relations": [[8, 10, 12, 14, "topic", "", false, false], [8, 10, 16, 18, "physical", "", true, false], [16, 18, 20, 20, "physical", "", false, false], [22, 24, 26, 30, "physical", "", true, false], [26, 30, 31, 31, "physical", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4, 5], "sentence": ["Zanim", "zosta\u0142", "profesorem", "w", "Cambridge", ",", "pe\u0142ni\u0142", "funkcj\u0119", "Johann", "Bernoulli", "Chair", "of", "Mathematics", "and", "Informatics", "na", "Uniwersytecie", "w", "Groningen", "w", "Holandii", "oraz", "Toshiba", "Endowed", "Chair", "w", "Tokyo", "Institute", "of", "Technology", "w", "Japonii", "."], "sentence-detokenized": "Zanim zosta\u0142 profesorem w Cambridge, pe\u0142ni\u0142 funkcj\u0119 Johann Bernoulli Chair of Mathematics and Informatics na Uniwersytecie w Groningen w Holandii oraz Toshiba Endowed Chair w Tokyo Institute of Technology w Japonii.", "token2charspan": [[0, 5], [6, 12], [13, 23], [24, 25], [26, 35], [35, 36], [37, 43], [44, 51], [52, 58], [59, 68], [69, 74], [75, 77], [78, 89], [90, 93], [94, 105], [106, 108], [109, 122], [123, 124], [125, 134], [135, 136], [137, 145], [146, 150], [151, 158], [159, 166], [167, 172], [173, 174], [175, 180], [181, 190], [191, 193], [194, 204], [205, 206], [207, 214], [214, 215]]}
{"doc_key": "ai-train-26", "ner": [[5, 7, "algorithm"], [12, 14, "algorithm"], [10, 10, "algorithm"], [20, 21, "researcher"], [23, 24, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 7, 12, 14, "usage", "", true, false], [12, 14, 20, 21, "origin", "", false, false], [12, 14, 23, 24, "origin", "", false, false], [10, 10, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Inn\u0105", "technik\u0105", "szczeg\u00f3lnie", "wykorzystywan\u0105", "w", "rekurencyjnych", "sieciach", "neuronowych", "jest", "sie\u0107", "LSTM", "(", "long", "short-term", "memory", ")", "z", "1997", "roku", "autorstwa", "Seppa", "Hochreitera", "&", "J\u00fcrgena", "Schmidhubera", "."], "sentence-detokenized": "Inn\u0105 technik\u0105 szczeg\u00f3lnie wykorzystywan\u0105 w rekurencyjnych sieciach neuronowych jest sie\u0107 LSTM (long short-term memory) z 1997 roku autorstwa Seppa Hochreitera & J\u00fcrgena Schmidhubera.", "token2charspan": [[0, 4], [5, 13], [14, 25], [26, 40], [41, 42], [43, 57], [58, 66], [67, 78], [79, 83], [84, 88], [89, 93], [94, 95], [95, 99], [100, 110], [111, 117], [117, 118], [119, 120], [121, 125], [126, 130], [131, 140], [141, 146], [147, 158], [159, 160], [161, 168], [169, 181], [181, 182]]}
{"doc_key": "ai-train-27", "ner": [[2, 4, "programlang"], [6, 6, "product"], [11, 11, "product"], [42, 42, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 2, 4, "general-affiliation", "", false, false], [6, 6, 11, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["W\u0142\u0105czenie", "interpretera", "C", "+", "+", "(", "CINT", "do", "wersji", "5.34", ",", "Cling", "od", "wersji", "6", ")", "czyni", "ten", "pakiet", "bardzo", "wszechstronnym", ",", "poniewa\u017c", "mo\u017ce", "by\u0107", "u\u017cywany", "w", "trybie", "interaktywnym", ",", "skryptowym", "i", "kompilowanym", "w", "spos\u00f3b", "podobny", "do", "produkt\u00f3w", "komercyjnych", ",", "takich", "jak", "MATLAB", "."], "sentence-detokenized": "W\u0142\u0105czenie interpretera C ++ (CINT do wersji 5.34, Cling od wersji 6) czyni ten pakiet bardzo wszechstronnym, poniewa\u017c mo\u017ce by\u0107 u\u017cywany w trybie interaktywnym, skryptowym i kompilowanym w spos\u00f3b podobny do produkt\u00f3w komercyjnych, takich jak MATLAB.", "token2charspan": [[0, 9], [10, 22], [23, 24], [25, 26], [26, 27], [28, 29], [29, 33], [34, 36], [37, 43], [44, 48], [48, 49], [50, 55], [56, 58], [59, 65], [66, 67], [67, 68], [69, 74], [75, 78], [79, 85], [86, 92], [93, 107], [107, 108], [109, 117], [118, 122], [123, 126], [127, 134], [135, 136], [137, 143], [144, 157], [157, 158], [159, 169], [170, 171], [172, 184], [185, 186], [187, 193], [194, 201], [202, 204], [205, 214], [215, 227], [227, 228], [229, 235], [236, 239], [240, 246], [246, 247]]}
{"doc_key": "ai-train-28", "ner": [[0, 2, "product"], [23, 25, "field"], [29, 30, "task"], [32, 33, "task"], [35, 36, "task"], [38, 39, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 23, 25, "related-to", "", false, false], [29, 30, 23, 25, "part-of", "", false, false], [32, 33, 23, 25, "part-of", "", false, false], [35, 36, 23, 25, "part-of", "", false, false], [38, 39, 23, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["G\u0142osowe", "interfejsy", "u\u017cytkownika", ",", "kt\u00f3re", "interpretuj\u0105", "i", "zarz\u0105dzaj\u0105", "stanem", "konwersacji", ",", "s\u0105", "trudne", "do", "zaprojektowania", "ze", "wzgl\u0119du", "na", "nieod\u0142\u0105czn\u0105", "trudno\u015b\u0107", "integracji", "z\u0142o\u017conych", "zada\u0144", "przetwarzania", "j\u0119zyka", "naturalnego", ",", "takich", "jak", "rozwi\u0105zywanie", "rdzeni", ",", "rozpoznawanie", "nazwisk", ",", "wyszukiwanie", "informacji", "i", "zarz\u0105dzanie", "dialogiem", "."], "sentence-detokenized": "G\u0142osowe interfejsy u\u017cytkownika, kt\u00f3re interpretuj\u0105 i zarz\u0105dzaj\u0105 stanem konwersacji, s\u0105 trudne do zaprojektowania ze wzgl\u0119du na nieod\u0142\u0105czn\u0105 trudno\u015b\u0107 integracji z\u0142o\u017conych zada\u0144 przetwarzania j\u0119zyka naturalnego, takich jak rozwi\u0105zywanie rdzeni, rozpoznawanie nazwisk, wyszukiwanie informacji i zarz\u0105dzanie dialogiem.", "token2charspan": [[0, 7], [8, 18], [19, 30], [30, 31], [32, 37], [38, 50], [51, 52], [53, 63], [64, 70], [71, 82], [82, 83], [84, 86], [87, 93], [94, 96], [97, 112], [113, 115], [116, 123], [124, 126], [127, 138], [139, 147], [148, 158], [159, 168], [169, 174], [175, 188], [189, 195], [196, 207], [207, 208], [209, 215], [216, 219], [220, 233], [234, 240], [240, 241], [242, 255], [256, 263], [263, 264], [265, 277], [278, 288], [289, 290], [291, 302], [303, 312], [312, 313]]}
{"doc_key": "ai-train-29", "ner": [[5, 7, "algorithm"], [9, 13, "algorithm"], [18, 19, "researcher"], [21, 24, "organisation"], [31, 32, "field"], [34, 35, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 7, 18, 19, "origin", "", false, false], [5, 7, 31, 32, "part-of", "", false, false], [5, 7, 34, 35, "part-of", "", false, false], [9, 13, 18, 19, "origin", "", false, false], [9, 13, 31, 32, "part-of", "", false, false], [9, 13, 34, 35, "part-of", "", false, false], [18, 19, 21, 24, "physical", "", false, false], [18, 19, 21, 24, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["W", "latach", "2009", "-", "2012", "rekurencyjne", "sieci", "neuronowe", "i", "g\u0142\u0119bokie", "sieci", "neuronowe", "typu", "feedforward", "opracowane", "w", "grupie", "badawczej", "J\u00fcrgena", "Schmidhubera", "w", "Swiss", "AI", "Lab", "IDSIA", "wygra\u0142y", "osiem", "mi\u0119dzynarodowych", "konkurs\u00f3w", "z", "zakresu", "rozpoznawania", "wzorc\u00f3w", "i", "uczenia", "maszynowego", "."], "sentence-detokenized": "W latach 2009-2012 rekurencyjne sieci neuronowe i g\u0142\u0119bokie sieci neuronowe typu feedforward opracowane w grupie badawczej J\u00fcrgena Schmidhubera w Swiss AI Lab IDSIA wygra\u0142y osiem mi\u0119dzynarodowych konkurs\u00f3w z zakresu rozpoznawania wzorc\u00f3w i uczenia maszynowego.", "token2charspan": [[0, 1], [2, 8], [9, 13], [13, 14], [14, 18], [19, 31], [32, 37], [38, 47], [48, 49], [50, 58], [59, 64], [65, 74], [75, 79], [80, 91], [92, 102], [103, 104], [105, 111], [112, 121], [122, 129], [130, 142], [143, 144], [145, 150], [151, 153], [154, 157], [158, 163], [164, 171], [172, 177], [178, 194], [195, 204], [205, 206], [207, 214], [215, 228], [229, 236], [237, 238], [239, 246], [247, 258], [258, 259]]}
{"doc_key": "ai-train-30", "ner": [[1, 3, "product"], [7, 8, "product"], [10, 11, "product"], [14, 15, "task"], [17, 17, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 3, 7, 8, "usage", "", false, false], [1, 3, 10, 11, "usage", "", false, false], [1, 3, 14, 15, "usage", "", true, false], [1, 3, 17, 17, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Nowoczesne", "systemy", "desktopowe", "Windows", "mog\u0105", "wykorzystywa\u0107", "komponenty", "SAPI", "4", "i", "SAPI", "5", "do", "obs\u0142ugi", "syntezy", "mowy", "i", "mowy", "."], "sentence-detokenized": "Nowoczesne systemy desktopowe Windows mog\u0105 wykorzystywa\u0107 komponenty SAPI 4 i SAPI 5 do obs\u0142ugi syntezy mowy i mowy.", "token2charspan": [[0, 10], [11, 18], [19, 29], [30, 37], [38, 42], [43, 56], [57, 67], [68, 72], [73, 74], [75, 76], [77, 81], [82, 83], [84, 86], [87, 94], [95, 102], [103, 107], [108, 109], [110, 114], [114, 115]]}
{"doc_key": "ai-train-31", "ner": [[6, 13, "misc"], [16, 16, "field"], [18, 21, "university"], [29, 32, "field"], [34, 37, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 13, 16, 16, "topic", "topic_of_award", false, false], [6, 13, 18, 21, "origin", "", true, false], [29, 32, 34, 37, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Otrzyma\u0142", "dwa", "tytu\u0142y", "honorowe", ",", "jeden", "S", ".", "V", ".", "della", "laurea", "ad", "honorem", "w", "dziedzinie", "psychologii", "z", "Uniwersytetu", "w", "Padwie", "w", "1995", "roku", "i", "jeden", "doktorat", "w", "dziedzinie", "projektowania", "i", "in\u017cynierii", "przemys\u0142owej", "z", "Uniwersytetu", "Technicznego", "w", "Delft", "."], "sentence-detokenized": "Otrzyma\u0142 dwa tytu\u0142y honorowe, jeden S. V. della laurea ad honorem w dziedzinie psychologii z Uniwersytetu w Padwie w 1995 roku i jeden doktorat w dziedzinie projektowania i in\u017cynierii przemys\u0142owej z Uniwersytetu Technicznego w Delft.", "token2charspan": [[0, 8], [9, 12], [13, 19], [20, 28], [28, 29], [30, 35], [36, 37], [37, 38], [39, 40], [40, 41], [42, 47], [48, 54], [55, 57], [58, 65], [66, 67], [68, 78], [79, 90], [91, 92], [93, 105], [106, 107], [108, 114], [115, 116], [117, 121], [122, 126], [127, 128], [129, 134], [135, 143], [144, 145], [146, 156], [157, 170], [171, 172], [173, 183], [184, 196], [197, 198], [199, 211], [212, 224], [225, 226], [227, 232], [232, 233]]}
{"doc_key": "ai-train-32", "ner": [[4, 5, "researcher"], [9, 12, "organisation"], [14, 14, "location"], [16, 16, "researcher"], [26, 26, "misc"], [39, 41, "misc"], [58, 58, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 5, 9, 12, "physical", "", false, false], [4, 5, 9, 12, "role", "", false, false], [9, 12, 14, 14, "physical", "", false, false], [16, 16, 26, 26, "related-to", "works_with", true, false], [16, 16, 39, 41, "related-to", "works_with", true, false], [16, 16, 58, 58, "related-to", "works_with", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Wraz", "z", "d\u0142ugoletnim", "wsp\u00f3\u0142pracownikiem", "Laurentem", "Cohenem", ",", "neurologiem", "ze", "szpitala", "Piti\u00e9", "-", "Salp\u00eatri\u00e8re", "w", "Pary\u017cu", ",", "Dehaene", "zidentyfikowa\u0142", "r\u00f3wnie\u017c", "pacjent\u00f3w", "ze", "zmianami", "w", "r\u00f3\u017cnych", "regionach", "p\u0142ata", "ciemieniowego", "z", "upo\u015bledzon\u0105", "multiplikacj\u0105", ",", "ale", "zachowan\u0105", "subtrakcj\u0105", "(", "zwi\u0105zan\u0105", "ze", "zmianami", "w", "dolnym", "p\u0142acie", "ciemieniowym", ")", "oraz", "innych", "z", "upo\u015bledzon\u0105", "subtrakcj\u0105", ",", "ale", "zachowan\u0105", "multiplikacj\u0105", "(", "zwi\u0105zan\u0105", "ze", "zmianami", "w", "bru\u017adzie", "\u015br\u00f3dciemieniowej", ")", "."], "sentence-detokenized": "Wraz z d\u0142ugoletnim wsp\u00f3\u0142pracownikiem Laurentem Cohenem, neurologiem ze szpitala Piti\u00e9-Salp\u00eatri\u00e8re w Pary\u017cu, Dehaene zidentyfikowa\u0142 r\u00f3wnie\u017c pacjent\u00f3w ze zmianami w r\u00f3\u017cnych regionach p\u0142ata ciemieniowego z upo\u015bledzon\u0105 multiplikacj\u0105, ale zachowan\u0105 subtrakcj\u0105 (zwi\u0105zan\u0105 ze zmianami w dolnym p\u0142acie ciemieniowym) oraz innych z upo\u015bledzon\u0105 subtrakcj\u0105, ale zachowan\u0105 multiplikacj\u0105 (zwi\u0105zan\u0105 ze zmianami w bru\u017adzie \u015br\u00f3dciemieniowej).", "token2charspan": [[0, 4], [5, 6], [7, 18], [19, 36], [37, 46], [47, 54], [54, 55], [56, 67], [68, 70], [71, 79], [80, 85], [85, 86], [86, 97], [98, 99], [100, 106], [106, 107], [108, 115], [116, 130], [131, 138], [139, 148], [149, 151], [152, 160], [161, 162], [163, 170], [171, 180], [181, 186], [187, 200], [201, 202], [203, 214], [215, 228], [228, 229], [230, 233], [234, 243], [244, 254], [255, 256], [256, 264], [265, 267], [268, 276], [277, 278], [279, 285], [286, 292], [293, 305], [305, 306], [307, 311], [312, 318], [319, 320], [321, 332], [333, 343], [343, 344], [345, 348], [349, 358], [359, 372], [373, 374], [374, 382], [383, 385], [386, 394], [395, 396], [397, 405], [406, 422], [422, 423], [423, 424]]}
{"doc_key": "ai-train-33", "ner": [[3, 5, "product"], [10, 13, "misc"], [15, 16, "misc"], [20, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 13, 3, 5, "topic", "", false, false], [15, 16, 3, 5, "topic", "", false, false], [20, 21, 3, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Ostatnio", "fikcyjne", "reprezentacje", "sztucznie", "inteligentnych", "robot\u00f3w", "w", "filmach", "takich", "jak", "A.I", ".", "Sztuczna", "inteligencja", "i", "Ex", "Machina", "oraz", "telewizyjna", "adaptacja", "Westworld", "z", "2016", "roku", "zaanga\u017cowa\u0142y", "sympati\u0119", "widz\u00f3w", "do", "samych", "robot\u00f3w", "."], "sentence-detokenized": "Ostatnio fikcyjne reprezentacje sztucznie inteligentnych robot\u00f3w w filmach takich jak A.I. Sztuczna inteligencja i Ex Machina oraz telewizyjna adaptacja Westworld z 2016 roku zaanga\u017cowa\u0142y sympati\u0119 widz\u00f3w do samych robot\u00f3w.", "token2charspan": [[0, 8], [9, 17], [18, 31], [32, 41], [42, 56], [57, 64], [65, 66], [67, 74], [75, 81], [82, 85], [86, 89], [89, 90], [91, 99], [100, 112], [113, 114], [115, 117], [118, 125], [126, 130], [131, 142], [143, 152], [153, 162], [163, 164], [165, 169], [170, 174], [175, 187], [188, 196], [197, 203], [204, 206], [207, 213], [214, 221], [221, 222]]}
{"doc_key": "ai-train-34", "ner": [[5, 7, "field"], [9, 11, "algorithm"], [13, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 11, 5, 7, "part-of", "", false, false], [13, 13, 5, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Dwie", "g\u0142\u00f3wne", "metody", "stosowane", "w", "uczeniu", "bez", "nadzoru", "to", "analiza", "sk\u0142adowych", "g\u0142\u00f3wnych", "i", "analiza", "skupie\u0144", "."], "sentence-detokenized": "Dwie g\u0142\u00f3wne metody stosowane w uczeniu bez nadzoru to analiza sk\u0142adowych g\u0142\u00f3wnych i analiza skupie\u0144.", "token2charspan": [[0, 4], [5, 11], [12, 18], [19, 28], [29, 30], [31, 38], [39, 42], [43, 50], [51, 53], [54, 61], [62, 72], [73, 81], [82, 83], [84, 91], [92, 99], [99, 100]]}
{"doc_key": "ai-train-35", "ner": [[0, 3, "organisation"], [19, 20, "misc"], [25, 26, "misc"], [28, 30, "person"], [36, 37, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 20, 0, 3, "artifact", "", false, false], [25, 26, 0, 3, "artifact", "", false, false], [25, 26, 28, 30, "role", "director_of", false, false], [25, 26, 36, 37, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Walt", "Disney", "Company", "r\u00f3wnie\u017c", "rozpocz\u0105\u0142", "bardziej", "widoczne", "wykorzystanie", "film\u00f3w", "3D", "w", "specjalnych", "miejscach", ",", "aby", "zaimponowa\u0107", "publiczno\u015bci", "z", "Magiczne", "podr\u00f3\u017ce", "(", "1982", ")", "i", "Kapitan", "EO", "(", "Francis", "Ford", "Coppola", ",", "1986", ",", "z", "udzia\u0142em", "Michaela", "Jacksona", ")", "s\u0105", "godne", "uwagi", "przyk\u0142ady", "."], "sentence-detokenized": "The Walt Disney Company r\u00f3wnie\u017c rozpocz\u0105\u0142 bardziej widoczne wykorzystanie film\u00f3w 3D w specjalnych miejscach, aby zaimponowa\u0107 publiczno\u015bci z Magiczne podr\u00f3\u017ce (1982) i Kapitan EO (Francis Ford Coppola, 1986, z udzia\u0142em Michaela Jacksona) s\u0105 godne uwagi przyk\u0142ady.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 23], [24, 31], [32, 41], [42, 50], [51, 59], [60, 73], [74, 80], [81, 83], [84, 85], [86, 97], [98, 107], [107, 108], [109, 112], [113, 124], [125, 137], [138, 139], [140, 148], [149, 156], [157, 158], [158, 162], [162, 163], [164, 165], [166, 173], [174, 176], [177, 178], [178, 185], [186, 190], [191, 198], [198, 199], [200, 204], [204, 205], [206, 207], [208, 216], [217, 225], [226, 234], [234, 235], [236, 238], [239, 244], [245, 250], [251, 260], [260, 261]]}
{"doc_key": "ai-train-36", "ner": [[10, 12, "field"], [17, 18, "task"], [20, 21, "task"], [23, 23, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[17, 18, 10, 12, "part-of", "", false, false], [20, 21, 10, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Od", "2002", "roku", "trening", "perceptronowy", "sta\u0142", "si\u0119", "popularny", "w", "dziedzinie", "przetwarzania", "j\u0119zyka", "naturalnego", "dla", "takich", "zada\u0144", "jak", "part-of-speech", "tagging", "i", "syntactic", "parsing", "(", "Collins", ",", "2002", ")", "."], "sentence-detokenized": "Od 2002 roku trening perceptronowy sta\u0142 si\u0119 popularny w dziedzinie przetwarzania j\u0119zyka naturalnego dla takich zada\u0144 jak part-of-speech tagging i syntactic parsing (Collins, 2002).", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 20], [21, 34], [35, 39], [40, 43], [44, 53], [54, 55], [56, 66], [67, 80], [81, 87], [88, 99], [100, 103], [104, 110], [111, 116], [117, 120], [121, 135], [136, 143], [144, 145], [146, 155], [156, 163], [164, 165], [165, 172], [172, 173], [174, 178], [178, 179], [179, 180]]}
{"doc_key": "ai-train-37", "ner": [[1, 2, "product"], [9, 41, "organisation"], [17, 17, "organisation"], [15, 15, "country"], [21, 26, "product"], [29, 30, "researcher"], [40, 40, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 41, 1, 2, "role", "introduces_to_market", true, false], [17, 17, 1, 2, "role", "introduces_to_market", true, false], [17, 17, 15, 15, "physical", "", false, false], [21, 26, 40, 40, "related-to", "sold_to", true, false], [29, 30, 21, 26, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Pierwszy", "robot", "paletyzuj\u0105cy", "zosta\u0142", "wprowadzony", "w", "1963", "roku", "przez", "Fuji", "Yusoki", "Kogyo", "Company", ".", "przez", "niemieck\u0105", "firm\u0119", "KUKA", "robotics", ",", "a", "programowalna", "uniwersalna", "maszyna", "do", "monta\u017cu", "zosta\u0142a", "wynaleziona", "przez", "Victora", "Scheinmana", "w", "1976", "roku", ",", "a", "projekt", "zosta\u0142", "sprzedany", "firmie", "Unimation", "."], "sentence-detokenized": "Pierwszy robot paletyzuj\u0105cy zosta\u0142 wprowadzony w 1963 roku przez Fuji Yusoki Kogyo Company. przez niemieck\u0105 firm\u0119 KUKA robotics, a programowalna uniwersalna maszyna do monta\u017cu zosta\u0142a wynaleziona przez Victora Scheinmana w 1976 roku, a projekt zosta\u0142 sprzedany firmie Unimation.", "token2charspan": [[0, 8], [9, 14], [15, 27], [28, 34], [35, 46], [47, 48], [49, 53], [54, 58], [59, 64], [65, 69], [70, 76], [77, 82], [83, 90], [90, 91], [92, 97], [98, 107], [108, 113], [114, 118], [119, 127], [127, 128], [129, 130], [131, 144], [145, 156], [157, 164], [165, 167], [168, 175], [176, 183], [184, 195], [196, 201], [202, 209], [210, 220], [221, 222], [223, 227], [228, 232], [232, 233], [234, 235], [236, 243], [244, 250], [251, 260], [261, 267], [268, 277], [277, 278]]}
{"doc_key": "ai-train-38", "ner": [[10, 10, "conference"], [5, 5, "researcher"], [17, 19, "field"], [32, 33, "researcher"], [38, 39, "researcher"], [52, 52, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 5, 10, 10, "role", "president_of", false, false], [5, 5, 32, 33, "role", "colleagues", false, false], [17, 19, 52, 52, "named", "same", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["W", "po\u0142owie", "lat", "90", ".", "Hayes", ",", "pe\u0142ni\u0105c", "funkcj\u0119", "prezesa", "AAAI", ",", "rozpocz\u0105\u0142", "seri\u0119", "atak\u00f3w", "na", "krytyk\u00f3w", "AI", ",", "w", "wi\u0119kszo\u015bci", "sformu\u0142owanych", "w", "ironicznym", "\u015bwietle", ",", "i", "(", "wraz", "ze", "swoim", "koleg\u0105", "Kennethem", "Fordem", ")", "wymy\u015bli\u0142", "nagrod\u0119", "imienia", "Simona", "Newcomba", ",", "kt\u00f3ra", "mia\u0142a", "by\u0107", "przyznawana", "za", "najbardziej", "absurdalny", "argument", "obalaj\u0105cy", "mo\u017cliwo\u015b\u0107", "istnienia", "AI", "."], "sentence-detokenized": "W po\u0142owie lat 90. Hayes, pe\u0142ni\u0105c funkcj\u0119 prezesa AAAI, rozpocz\u0105\u0142 seri\u0119 atak\u00f3w na krytyk\u00f3w AI, w wi\u0119kszo\u015bci sformu\u0142owanych w ironicznym \u015bwietle, i (wraz ze swoim koleg\u0105 Kennethem Fordem) wymy\u015bli\u0142 nagrod\u0119 imienia Simona Newcomba, kt\u00f3ra mia\u0142a by\u0107 przyznawana za najbardziej absurdalny argument obalaj\u0105cy mo\u017cliwo\u015b\u0107 istnienia AI.", "token2charspan": [[0, 1], [2, 9], [10, 13], [14, 16], [16, 17], [18, 23], [23, 24], [25, 32], [33, 40], [41, 48], [49, 53], [53, 54], [55, 64], [65, 70], [71, 77], [78, 80], [81, 89], [90, 92], [92, 93], [94, 95], [96, 106], [107, 121], [122, 123], [124, 134], [135, 142], [142, 143], [144, 145], [146, 147], [147, 151], [152, 154], [155, 160], [161, 167], [168, 177], [178, 184], [184, 185], [186, 194], [195, 202], [203, 210], [211, 217], [218, 226], [226, 227], [228, 233], [234, 239], [240, 243], [244, 255], [256, 258], [259, 270], [271, 281], [282, 290], [291, 300], [301, 310], [311, 320], [321, 323], [323, 324]]}
{"doc_key": "ai-train-39", "ner": [[8, 10, "algorithm"], [31, 32, "algorithm"], [42, 42, "algorithm"], [48, 50, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 10, 31, 32, "named", "same", false, false], [42, 42, 8, 10, "type-of", "", false, false], [48, 50, 8, 10, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Optymaln\u0105", "warto\u015b\u0107", "dla", "matematyki", "mo\u017cna", "znale\u017a\u0107", "za", "pomoc\u0105", "algorytmu", "wyszukiwania", "liniowego", ",", "to", "znaczy", ",", "\u017ce", "wielko\u015b\u0107", "matematyki", "jest", "okre\u015blana", "przez", "znalezienie", "warto\u015bci", ",", "kt\u00f3ra", "minimalizuje", "S", ",", "zwykle", "za", "pomoc\u0105", "wyszukiwania", "liniowego", "w", "przedziale", "matematycznym0", "alfa", "1", "/", "matematycznym", "lub", "wyszukiwania", "liniowego", "z", "cofaniem", ",", "takiego", "jak", "Armijo", "-line", "search", "."], "sentence-detokenized": "Optymaln\u0105 warto\u015b\u0107 dla matematyki mo\u017cna znale\u017a\u0107 za pomoc\u0105 algorytmu wyszukiwania liniowego, to znaczy, \u017ce wielko\u015b\u0107 matematyki jest okre\u015blana przez znalezienie warto\u015bci, kt\u00f3ra minimalizuje S, zwykle za pomoc\u0105 wyszukiwania liniowego w przedziale matematycznym0 alfa 1 / matematycznym lub wyszukiwania liniowego z cofaniem, takiego jak Armijo-line search.", "token2charspan": [[0, 9], [10, 17], [18, 21], [22, 32], [33, 38], [39, 46], [47, 49], [50, 56], [57, 66], [67, 79], [80, 89], [89, 90], [91, 93], [94, 100], [100, 101], [102, 104], [105, 113], [114, 124], [125, 129], [130, 139], [140, 145], [146, 157], [158, 166], [166, 167], [168, 173], [174, 186], [187, 188], [188, 189], [190, 196], [197, 199], [200, 206], [207, 219], [220, 229], [230, 231], [232, 242], [243, 257], [258, 262], [263, 264], [265, 266], [267, 280], [281, 284], [285, 297], [298, 307], [308, 309], [310, 318], [318, 319], [320, 327], [328, 331], [332, 338], [338, 343], [344, 350], [350, 351]]}
{"doc_key": "ai-train-40", "ner": [[2, 4, "algorithm"], [6, 7, "algorithm"], [18, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Omawia", "techniki", "Breadth-", "first", "search", "i", "Depth-first", "search", ",", "ale", "ostatecznie", "dochodzi", "do", "wniosku", ",", "\u017ce", "wyniki", "reprezentuj\u0105", "systemy", "eksperckie", ",", "kt\u00f3re", "wcielaj\u0105", "wiele", "wiedzy", "technicznej", ",", "ale", "nie", "rzucaj\u0105", "wiele", "\u015bwiat\u0142a", "na", "procesy", "umys\u0142owe", ",", "kt\u00f3rych", "ludzie", "u\u017cywaj\u0105", "do", "rozwi\u0105zywania", "takich", "zagadek", "."], "sentence-detokenized": "Omawia techniki Breadth-first search i Depth-first search, ale ostatecznie dochodzi do wniosku, \u017ce wyniki reprezentuj\u0105 systemy eksperckie, kt\u00f3re wcielaj\u0105 wiele wiedzy technicznej, ale nie rzucaj\u0105 wiele \u015bwiat\u0142a na procesy umys\u0142owe, kt\u00f3rych ludzie u\u017cywaj\u0105 do rozwi\u0105zywania takich zagadek.", "token2charspan": [[0, 6], [7, 15], [16, 24], [24, 29], [30, 36], [37, 38], [39, 50], [51, 57], [57, 58], [59, 62], [63, 74], [75, 83], [84, 86], [87, 94], [94, 95], [96, 98], [99, 105], [106, 118], [119, 126], [127, 137], [137, 138], [139, 144], [145, 153], [154, 159], [160, 166], [167, 178], [178, 179], [180, 183], [184, 187], [188, 195], [196, 201], [202, 209], [210, 212], [213, 220], [221, 229], [229, 230], [231, 238], [239, 245], [246, 253], [254, 256], [257, 270], [271, 277], [278, 285], [285, 286]]}
{"doc_key": "ai-train-41", "ner": [[0, 1, "task"], [3, 4, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Rozpoznawanie", "mowy", "i", "synteza", "mowy", "zajmuj\u0105", "si\u0119", "tym", ",", "jak", "j\u0119zyk", "m\u00f3wiony", "mo\u017ce", "by\u0107", "rozumiany", "lub", "tworzony", "przy", "u\u017cyciu", "komputer\u00f3w", "."], "sentence-detokenized": "Rozpoznawanie mowy i synteza mowy zajmuj\u0105 si\u0119 tym, jak j\u0119zyk m\u00f3wiony mo\u017ce by\u0107 rozumiany lub tworzony przy u\u017cyciu komputer\u00f3w.", "token2charspan": [[0, 13], [14, 18], [19, 20], [21, 28], [29, 33], [34, 41], [42, 45], [46, 49], [49, 50], [51, 54], [55, 60], [61, 68], [69, 73], [74, 77], [78, 87], [88, 91], [92, 100], [101, 105], [106, 112], [113, 123], [123, 124]]}
{"doc_key": "ai-train-42", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ta", "matematyka", "^", "{", "*", "}"], "sentence-detokenized": "Ta matematyka ^ {*} ", "token2charspan": [[0, 2], [3, 13], [14, 15], [16, 17], [17, 18], [18, 19]]}
{"doc_key": "ai-train-43", "ner": [[5, 8, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Niekt\u00f3re", "mniej", "popularne", "j\u0119zyki", "u\u017cywaj\u0105", "syntezatora", "mowy", "eSpeak", "o", "otwartym", "kodzie", "\u017ar\u00f3d\u0142owym", ";", "produkuj\u0105c", "robotyczny", ",", "niezr\u0119czny", "g\u0142os", ",", "kt\u00f3ry", "mo\u017ce", "by\u0107", "trudny", "do", "zrozumienia", "."], "sentence-detokenized": "Niekt\u00f3re mniej popularne j\u0119zyki u\u017cywaj\u0105 syntezatora mowy eSpeak o otwartym kodzie \u017ar\u00f3d\u0142owym; produkuj\u0105c robotyczny, niezr\u0119czny g\u0142os, kt\u00f3ry mo\u017ce by\u0107 trudny do zrozumienia.", "token2charspan": [[0, 8], [9, 14], [15, 24], [25, 31], [32, 39], [40, 51], [52, 56], [57, 63], [64, 65], [66, 74], [75, 81], [82, 91], [91, 92], [93, 103], [104, 114], [114, 115], [116, 126], [127, 131], [131, 132], [133, 138], [139, 143], [144, 147], [148, 154], [155, 157], [158, 169], [169, 170]]}
{"doc_key": "ai-train-44", "ner": [[17, 17, "programlang"], [34, 35, "programlang"], [37, 37, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 17, 34, 35, "compare", "", false, false], [17, 17, 37, 37, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cho\u0107", "u\u017cywany", "g\u0142\u00f3wnie", "przez", "statystyk\u00f3w", "i", "innych", "praktyk\u00f3w", "wymagaj\u0105cych", "\u015brodowiska", "do", "oblicze\u0144", "statystycznych", "i", "tworzenia", "oprogramowania", ",", "R", "mo\u017ce", "r\u00f3wnie\u017c", "dzia\u0142a\u0107", "jako", "og\u00f3lny", "zestaw", "narz\u0119dzi", "do", "oblicze\u0144", "macierzowych", "-", "z", "benchmarkami", "wydajno\u015bci", "por\u00f3wnywalnymi", "z", "GNU", "Octave", "lub", "MATLAB", "."], "sentence-detokenized": "Cho\u0107 u\u017cywany g\u0142\u00f3wnie przez statystyk\u00f3w i innych praktyk\u00f3w wymagaj\u0105cych \u015brodowiska do oblicze\u0144 statystycznych i tworzenia oprogramowania, R mo\u017ce r\u00f3wnie\u017c dzia\u0142a\u0107 jako og\u00f3lny zestaw narz\u0119dzi do oblicze\u0144 macierzowych - z benchmarkami wydajno\u015bci por\u00f3wnywalnymi z GNU Octave lub MATLAB.", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 26], [27, 38], [39, 40], [41, 47], [48, 57], [58, 70], [71, 81], [82, 84], [85, 93], [94, 108], [109, 110], [111, 120], [121, 135], [135, 136], [137, 138], [139, 143], [144, 151], [152, 159], [160, 164], [165, 171], [172, 178], [179, 187], [188, 190], [191, 199], [200, 212], [213, 214], [215, 216], [217, 229], [230, 240], [241, 255], [256, 257], [258, 261], [262, 268], [269, 272], [273, 279], [279, 280]]}
{"doc_key": "ai-train-45", "ner": [[0, 0, "algorithm"], [3, 4, "field"], [7, 10, "misc"], [11, 12, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 3, 4, "part-of", "", false, false], [0, 0, 11, 12, "origin", "", false, false], [7, 10, 11, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Heterodynowanie", "to", "technika", "przetwarzania", "sygna\u0142u", "wynaleziona", "przez", "kanadyjskiego", "wynalazc\u0119", "-", "in\u017cyniera", "Reginalda", "Fessendena", ",", "kt\u00f3ra", "tworzy", "nowe", "cz\u0119stotliwo\u015bci", "poprzez", "\u0142\u0105czenie", "mieszania", "dw\u00f3ch", "cz\u0119stotliwo\u015bci", "."], "sentence-detokenized": "Heterodynowanie to technika przetwarzania sygna\u0142u wynaleziona przez kanadyjskiego wynalazc\u0119-in\u017cyniera Reginalda Fessendena, kt\u00f3ra tworzy nowe cz\u0119stotliwo\u015bci poprzez \u0142\u0105czenie mieszania dw\u00f3ch cz\u0119stotliwo\u015bci.", "token2charspan": [[0, 15], [16, 18], [19, 27], [28, 41], [42, 49], [50, 61], [62, 67], [68, 81], [82, 91], [91, 92], [92, 101], [102, 111], [112, 122], [122, 123], [124, 129], [130, 136], [137, 141], [142, 156], [157, 164], [165, 173], [174, 183], [184, 189], [190, 204], [204, 205]]}
{"doc_key": "ai-train-46", "ner": [[17, 18, "person"], [16, 16, "misc"], [22, 24, "organisation"], [30, 30, "organisation"], [27, 29, "misc"], [32, 33, "person"], [38, 38, "organisation"], [35, 37, "misc"], [40, 41, "person"], [44, 44, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[17, 18, 16, 16, "role", "actor_in", false, false], [16, 16, 22, 24, "artifact", "", false, false], [27, 29, 30, 30, "artifact", "", false, false], [32, 33, 27, 29, "role", "actor_in", false, false], [35, 37, 38, 38, "artifact", "", false, false], [40, 41, 35, 37, "role", "actor_in", false, false], [44, 44, 35, 37, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Kilka", "innych", "film\u00f3w", ",", "kt\u00f3re", "pomog\u0142y", "umie\u015bci\u0107", "3D", "z", "powrotem", "na", "mapie", "w", "tym", "miesi\u0105cu", "to", "Hondo", "Johna", "Wayne'a", "(", "dystrybuowany", "przez", "Warner", "Bros", ".", ")", ",", "Miss", "Sadie", "Thompsona", "Columbii", "z", "Rit\u0105", "Hayworth", "oraz", "Money", "From", "Home", "Paramountu", "z", "Deanem", "Martinem", "i", "Jerrym", "Lewisem", "."], "sentence-detokenized": "Kilka innych film\u00f3w, kt\u00f3re pomog\u0142y umie\u015bci\u0107 3D z powrotem na mapie w tym miesi\u0105cu to Hondo Johna Wayne'a (dystrybuowany przez Warner Bros. ), Miss Sadie Thompsona Columbii z Rit\u0105 Hayworth oraz Money From Home Paramountu z Deanem Martinem i Jerrym Lewisem.", "token2charspan": [[0, 5], [6, 12], [13, 19], [19, 20], [21, 26], [27, 34], [35, 43], [44, 46], [47, 48], [49, 57], [58, 60], [61, 66], [67, 68], [69, 72], [73, 81], [82, 84], [85, 90], [91, 96], [97, 104], [105, 106], [106, 119], [120, 125], [126, 132], [133, 137], [137, 138], [139, 140], [140, 141], [142, 146], [147, 152], [153, 162], [163, 171], [172, 173], [174, 178], [179, 187], [188, 192], [193, 198], [199, 203], [204, 208], [209, 219], [220, 221], [222, 228], [229, 237], [238, 239], [240, 246], [247, 254], [254, 255]]}
{"doc_key": "ai-train-47", "ner": [[0, 0, "product"], [7, 8, "field"], [3, 6, "task"], [16, 16, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 3, 6, "general-affiliation", "", false, false], [0, 0, 16, 16, "artifact", "", false, false], [3, 6, 7, 8, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["DeepFace", "to", "system", "rozpoznawania", "twarzy", "oparty", "na", "g\u0142\u0119bokim", "uczeniu", ",", "stworzony", "przez", "grup\u0119", "badawcz\u0105", "dzia\u0142aj\u0105c\u0105", "przy", "Facebooku", "."], "sentence-detokenized": "DeepFace to system rozpoznawania twarzy oparty na g\u0142\u0119bokim uczeniu, stworzony przez grup\u0119 badawcz\u0105 dzia\u0142aj\u0105c\u0105 przy Facebooku.", "token2charspan": [[0, 8], [9, 11], [12, 18], [19, 32], [33, 39], [40, 46], [47, 49], [50, 58], [59, 66], [66, 67], [68, 77], [78, 83], [84, 89], [90, 98], [99, 109], [110, 114], [115, 124], [124, 125]]}
{"doc_key": "ai-train-48", "ner": [[0, 1, "field"], [7, 7, "conference"], [13, 14, "field"], [21, 25, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 13, 14, "part-of", "subfield", false, false], [7, 7, 0, 1, "topic", "", false, false], [21, 25, 0, 1, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Przetwarzanie", "geometrii", "jest", "cz\u0119stym", "tematem", "bada\u0144", "na", "SIGGRAPH", ",", "g\u0142\u00f3wnej", "konferencji", "akademickiej", "po\u015bwi\u0119conej", "grafice", "komputerowej", ",", "a", "tak\u017ce", "g\u0142\u00f3wnym", "tematem", "corocznego", "Sympozjum", "na", "temat", "Przetwarzania", "Geometrii", "."], "sentence-detokenized": "Przetwarzanie geometrii jest cz\u0119stym tematem bada\u0144 na SIGGRAPH, g\u0142\u00f3wnej konferencji akademickiej po\u015bwi\u0119conej grafice komputerowej, a tak\u017ce g\u0142\u00f3wnym tematem corocznego Sympozjum na temat Przetwarzania Geometrii.", "token2charspan": [[0, 13], [14, 23], [24, 28], [29, 36], [37, 44], [45, 50], [51, 53], [54, 62], [62, 63], [64, 71], [72, 83], [84, 96], [97, 108], [109, 116], [117, 129], [129, 130], [131, 132], [133, 138], [139, 146], [147, 154], [155, 165], [166, 175], [176, 178], [179, 184], [185, 198], [199, 208], [208, 209]]}
{"doc_key": "ai-train-49", "ner": [[0, 1, "task"], [3, 4, "task"], [12, 14, "algorithm"], [16, 16, "algorithm"], [19, 21, "algorithm"], [23, 23, "algorithm"], [26, 28, "algorithm"], [30, 30, "algorithm"], [34, 35, "misc"], [41, 43, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[12, 14, 34, 35, "general-affiliation", "", false, false], [16, 16, 12, 14, "named", "", false, false], [19, 21, 34, 35, "general-affiliation", "", false, false], [23, 23, 19, 21, "named", "", false, false], [26, 28, 34, 35, "general-affiliation", "", false, false], [30, 30, 26, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Ekstrakcj\u0119", "cech", "i", "redukcj\u0119", "wymiar\u00f3w", "mo\u017cna", "po\u0142\u0105czy\u0107", "w", "jednym", "kroku", ",", "stosuj\u0105c", "analiz\u0119", "sk\u0142adowych", "g\u0142\u00f3wnych", "(", "PCA", ")", ",", "liniow\u0105", "analiz\u0119", "dyskryminacyjn\u0105", "(", "LDA", ")", "lub", "analiz\u0119", "korelacji", "kanonicznej", "(", "CCA", ")", "jako", "etap", "przetwarzania", "wst\u0119pnego", ",", "a", "nast\u0119pnie", "klastrowanie", "przez", "k", "-", "NN", "na", "wektorach", "cech", "w", "przestrzeni", "o", "zredukowanym", "wymiarze", "."], "sentence-detokenized": "Ekstrakcj\u0119 cech i redukcj\u0119 wymiar\u00f3w mo\u017cna po\u0142\u0105czy\u0107 w jednym kroku, stosuj\u0105c analiz\u0119 sk\u0142adowych g\u0142\u00f3wnych (PCA), liniow\u0105 analiz\u0119 dyskryminacyjn\u0105 (LDA) lub analiz\u0119 korelacji kanonicznej (CCA) jako etap przetwarzania wst\u0119pnego, a nast\u0119pnie klastrowanie przez k -NN na wektorach cech w przestrzeni o zredukowanym wymiarze.", "token2charspan": [[0, 10], [11, 15], [16, 17], [18, 26], [27, 35], [36, 41], [42, 50], [51, 52], [53, 59], [60, 65], [65, 66], [67, 75], [76, 83], [84, 94], [95, 103], [104, 105], [105, 108], [108, 109], [109, 110], [111, 118], [119, 126], [127, 142], [143, 144], [144, 147], [147, 148], [149, 152], [153, 160], [161, 170], [171, 182], [183, 184], [184, 187], [187, 188], [189, 193], [194, 198], [199, 212], [213, 222], [222, 223], [224, 225], [226, 235], [236, 248], [249, 254], [255, 256], [257, 258], [258, 260], [261, 263], [264, 273], [274, 278], [279, 280], [281, 292], [293, 294], [295, 307], [308, 316], [316, 317]]}
{"doc_key": "ai-train-50", "ner": [[0, 2, "algorithm"], [12, 13, "field"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 12, 13, "related-to", "good_at", true, false], [0, 2, 15, 16, "related-to", "good_at", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Sztuczne", "sieci", "neuronowe", "to", "modele", "obliczeniowe", ",", "kt\u00f3re", "doskonale", "sprawdzaj\u0105", "si\u0119", "w", "uczeniu", "maszynowym", "i", "rozpoznawaniu", "wzorc\u00f3w", "."], "sentence-detokenized": "Sztuczne sieci neuronowe to modele obliczeniowe, kt\u00f3re doskonale sprawdzaj\u0105 si\u0119 w uczeniu maszynowym i rozpoznawaniu wzorc\u00f3w.", "token2charspan": [[0, 8], [9, 14], [15, 24], [25, 27], [28, 34], [35, 47], [47, 48], [49, 54], [55, 64], [65, 75], [76, 79], [80, 81], [82, 89], [90, 100], [101, 102], [103, 116], [117, 124], [124, 125]]}
{"doc_key": "ai-train-51", "ner": [[1, 3, "researcher"], [5, 7, "researcher"], [9, 13, "misc"], [15, 19, "conference"], [21, 21, "conference"], [39, 53, "algorithm"], [42, 44, "researcher"], [46, 48, "researcher"], [50, 56, "misc"], [58, 67, "conference"], [69, 69, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[9, 13, 1, 3, "artifact", "", false, false], [9, 13, 5, 7, "artifact", "", false, false], [9, 13, 15, 19, "temporal", "", false, false], [21, 21, 15, 19, "named", "", false, false], [50, 56, 39, 53, "topic", "", false, false], [50, 56, 42, 44, "artifact", "", false, false], [50, 56, 46, 48, "artifact", "", false, false], [50, 56, 58, 67, "temporal", "", false, false], [69, 69, 58, 67, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": [",", "C", ".", "Papageorgiou", "and", "T", ".", "Poggio", ",", "A", "Trainable", "Pedestrian", "Detection", "system", ",", "International", "Journal", "of", "Computer", "Vision", "(", "IJCV", ")", ",", "pages", "1", ":", "15", "-", "33", ",", "2000", "inni", "wykorzystuj\u0105", "cechy", "lokalne", ",", "takie", "jak", "histogram", "zorientowanych", "gradient\u00f3w", "N", ".", "Dalal", ",", "B", ".", "Triggs", ",", "Histograms", "of", "oriented", "gradients", "for", "human", "detection", ",", "IEEE", "Computer", "Society", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", ",", "pages", "1", ":", "886", "-", "893", ",", "2005", "descriptors", "."], "sentence-detokenized": ", C. Papageorgiou and T. Poggio, A Trainable Pedestrian Detection system, International Journal of Computer Vision (IJCV), pages 1: 15-33, 2000 inni wykorzystuj\u0105 cechy lokalne, takie jak histogram zorientowanych gradient\u00f3w N. Dalal, B. Triggs, Histograms of oriented gradients for human detection, IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), pages 1: 886-893, 2005 descriptors.", "token2charspan": [[0, 1], [2, 3], [3, 4], [5, 17], [18, 21], [22, 23], [23, 24], [25, 31], [31, 32], [33, 34], [35, 44], [45, 55], [56, 65], [66, 72], [72, 73], [74, 87], [88, 95], [96, 98], [99, 107], [108, 114], [115, 116], [116, 120], [120, 121], [121, 122], [123, 128], [129, 130], [130, 131], [132, 134], [134, 135], [135, 137], [137, 138], [139, 143], [144, 148], [149, 161], [162, 167], [168, 175], [175, 176], [177, 182], [183, 186], [187, 196], [197, 211], [212, 222], [223, 224], [224, 225], [226, 231], [231, 232], [233, 234], [234, 235], [236, 242], [242, 243], [244, 254], [255, 257], [258, 266], [267, 276], [277, 280], [281, 286], [287, 296], [296, 297], [298, 302], [303, 311], [312, 319], [320, 330], [331, 333], [334, 342], [343, 349], [350, 353], [354, 361], [362, 373], [374, 375], [375, 379], [379, 380], [380, 381], [382, 387], [388, 389], [389, 390], [391, 394], [394, 395], [395, 398], [398, 399], [400, 404], [405, 416], [416, 417]]}
{"doc_key": "ai-train-52", "ner": [[0, 0, "algorithm"], [3, 5, "algorithm"], [10, 10, "task"], [13, 13, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 3, 5, "type-of", "", false, false], [10, 10, 0, 0, "usage", "", true, false], [10, 10, 13, 13, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Autoenkoder", "jest", "rodzajem", "sztucznej", "sieci", "neuronowej", "u\u017cywanej", "do", "uczenia", "si\u0119", "Cechy", "w", "spos\u00f3b", "nienadzorowany", "."], "sentence-detokenized": "Autoenkoder jest rodzajem sztucznej sieci neuronowej u\u017cywanej do uczenia si\u0119 Cechy w spos\u00f3b nienadzorowany.", "token2charspan": [[0, 11], [12, 16], [17, 25], [26, 35], [36, 41], [42, 52], [53, 61], [62, 64], [65, 72], [73, 76], [77, 82], [83, 84], [85, 91], [92, 106], [106, 107]]}
{"doc_key": "ai-train-53", "ner": [[0, 0, "researcher"], [4, 4, "organisation"], [9, 10, "field"], [12, 13, "field"], [18, 22, "organisation"], [24, 24, "organisation"], [30, 30, "field"], [32, 33, "field"], [38, 38, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 4, "role", "fellow_of", false, false], [0, 0, 9, 10, "related-to", "contributes_to", false, false], [0, 0, 12, 13, "related-to", "contributes_to", false, false], [0, 0, 18, 22, "role", "fellow_of", false, false], [0, 0, 30, 30, "related-to", "contributes_to", false, false], [0, 0, 32, 33, "related-to", "contributes_to", false, false], [24, 24, 18, 22, "named", "", false, false], [38, 38, 18, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Haralick", "jest", "Fellow", "of", "IEEE", "za", "wk\u0142ad", "w", "dziedzinie", "widzenia", "komputerowego", "i", "przetwarzania", "obraz\u00f3w", "oraz", "Fellow", "of", "the", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", "za", "wk\u0142ad", "w", "rozpoznawanie", "wzor\u00f3w", ",", "przetwarzanie", "obraz\u00f3w", "i", "za", "s\u0142u\u017cb\u0119", "dla", "IAPR", "."], "sentence-detokenized": "Haralick jest Fellow of IEEE za wk\u0142ad w dziedzinie widzenia komputerowego i przetwarzania obraz\u00f3w oraz Fellow of the International Association for Pattern Recognition (IAPR) za wk\u0142ad w rozpoznawanie wzor\u00f3w, przetwarzanie obraz\u00f3w i za s\u0142u\u017cb\u0119 dla IAPR.", "token2charspan": [[0, 8], [9, 13], [14, 20], [21, 23], [24, 28], [29, 31], [32, 37], [38, 39], [40, 50], [51, 59], [60, 73], [74, 75], [76, 89], [90, 97], [98, 102], [103, 109], [110, 112], [113, 116], [117, 130], [131, 142], [143, 146], [147, 154], [155, 166], [167, 168], [168, 172], [172, 173], [174, 176], [177, 182], [183, 184], [185, 198], [199, 205], [205, 206], [207, 220], [221, 228], [229, 230], [231, 233], [234, 240], [241, 244], [245, 249], [249, 250]]}
{"doc_key": "ai-train-54", "ner": [[2, 3, "task"], [6, 8, "algorithm"], [10, 10, "algorithm"], [16, 17, "researcher"], [19, 20, "organisation"], [22, 23, "researcher"], [25, 27, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 3, 6, 8, "usage", "", false, false], [6, 8, 16, 17, "origin", "", true, false], [6, 8, 22, 23, "origin", "", true, false], [10, 10, 6, 8, "named", "", false, false], [16, 17, 19, 20, "physical", "", false, false], [16, 17, 19, 20, "role", "", false, false], [22, 23, 25, 27, "physical", "", false, false], [22, 23, 25, 27, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Pierwsz\u0105", "pr\u00f3b\u0105", "end-to-end", "ASR", "by\u0142y", "systemy", "Connectionist", "Temporal", "Classification", "(", "CTC", ")", "-", "based", "wprowadzone", "przez", "Alexa", "Gravesa", "z", "Google", "DeepMind", "i", "Navdeepa", "Jaitly", "z", "University", "of", "Toronto", "w", "2014", "roku", "."], "sentence-detokenized": "Pierwsz\u0105 pr\u00f3b\u0105 end-to-end ASR by\u0142y systemy Connectionist Temporal Classification (CTC) -based wprowadzone przez Alexa Gravesa z Google DeepMind i Navdeepa Jaitly z University of Toronto w 2014 roku.", "token2charspan": [[0, 8], [9, 14], [15, 25], [26, 29], [30, 34], [35, 42], [43, 56], [57, 65], [66, 80], [81, 82], [82, 85], [85, 86], [87, 88], [88, 93], [94, 105], [106, 111], [112, 117], [118, 125], [126, 127], [128, 134], [135, 143], [144, 145], [146, 154], [155, 161], [162, 163], [164, 174], [175, 177], [178, 185], [186, 187], [188, 192], [193, 197], [197, 198]]}
{"doc_key": "ai-train-55", "ner": [[0, 3, "algorithm"], [5, 5, "algorithm"], [9, 10, "algorithm"], [12, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 0, 3, "named", "", false, false], [9, 10, 0, 3, "type-of", "", false, false], [12, 12, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Programowanie", "liniowo", "-", "frakcyjne", "(", "LFP", ")", "jest", "uog\u00f3lnieniem", "programowania", "liniowego", "(", "LP", ")", "."], "sentence-detokenized": "Programowanie liniowo-frakcyjne (LFP) jest uog\u00f3lnieniem programowania liniowego (LP).", "token2charspan": [[0, 13], [14, 21], [21, 22], [22, 31], [32, 33], [33, 36], [36, 37], [38, 42], [43, 55], [56, 69], [70, 79], [80, 81], [81, 83], [83, 84], [84, 85]]}
{"doc_key": "ai-train-56", "ner": [[0, 0, "researcher"], [8, 9, "misc"], [11, 18, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 9, "win-defeat", "", false, false], [8, 9, 11, 18, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lafferty", "otrzyma\u0142", "liczne", "nagrody", ",", "w", "tym", "dwie", "nagrody", "Test-of-Time", "na", "International", "Conference", "on", "Machine", "Learning", "2011", "&", "2012", ","], "sentence-detokenized": "Lafferty otrzyma\u0142 liczne nagrody, w tym dwie nagrody Test-of-Time na International Conference on Machine Learning 2011 & 2012,", "token2charspan": [[0, 8], [9, 17], [18, 24], [25, 32], [32, 33], [34, 35], [36, 39], [40, 44], [45, 52], [53, 65], [66, 68], [69, 82], [83, 93], [94, 96], [97, 104], [105, 113], [114, 118], [119, 120], [121, 125], [125, 126]]}
{"doc_key": "ai-train-57", "ner": [[11, 11, "product"], [13, 13, "programlang"], [25, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Wraz", "z", "pojawieniem", "si\u0119", "framework\u00f3w", "opartych", "na", "komponentach", ",", "takich", "jak", ".NET", "i", "Java", ",", "\u015brodowiska", "programistyczne", "oparte", "na", "komponentach", "s\u0105", "w", "stanie", "wdro\u017cy\u0107", "opracowan\u0105", "sie\u0107", "neuronow\u0105", "do", "tych", "framework\u00f3w", "jako", "dziedziczone", "komponenty", "."], "sentence-detokenized": "Wraz z pojawieniem si\u0119 framework\u00f3w opartych na komponentach, takich jak .NET i Java, \u015brodowiska programistyczne oparte na komponentach s\u0105 w stanie wdro\u017cy\u0107 opracowan\u0105 sie\u0107 neuronow\u0105 do tych framework\u00f3w jako dziedziczone komponenty.", "token2charspan": [[0, 4], [5, 6], [7, 18], [19, 22], [23, 34], [35, 43], [44, 46], [47, 59], [59, 60], [61, 67], [68, 71], [72, 76], [77, 78], [79, 83], [83, 84], [85, 95], [96, 111], [112, 118], [119, 121], [122, 134], [135, 137], [138, 139], [140, 146], [147, 154], [155, 165], [166, 170], [171, 180], [181, 183], [184, 188], [189, 200], [201, 205], [206, 218], [219, 229], [229, 230]]}
{"doc_key": "ai-train-58", "ner": [[4, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Podobnie", "jak", "w", "przypadku", "BLEU", ",", "podstawow\u0105", "jednostk\u0105", "oceny", "jest", "zdanie", ",", "algorytm", "najpierw", "tworzy", "wyr\u00f3wnanie", "(", "patrz", "ilustracje", ")", "pomi\u0119dzy", "dwoma", "zdaniami", ",", "ci\u0105giem", "t\u0142umacze\u0144", "kandyduj\u0105cych", "i", "ci\u0105giem", "t\u0142umacze\u0144", "referencyjnych", "."], "sentence-detokenized": "Podobnie jak w przypadku BLEU, podstawow\u0105 jednostk\u0105 oceny jest zdanie, algorytm najpierw tworzy wyr\u00f3wnanie (patrz ilustracje) pomi\u0119dzy dwoma zdaniami, ci\u0105giem t\u0142umacze\u0144 kandyduj\u0105cych i ci\u0105giem t\u0142umacze\u0144 referencyjnych.", "token2charspan": [[0, 8], [9, 12], [13, 14], [15, 24], [25, 29], [29, 30], [31, 41], [42, 51], [52, 57], [58, 62], [63, 69], [69, 70], [71, 79], [80, 88], [89, 95], [96, 106], [107, 108], [108, 113], [114, 124], [124, 125], [126, 134], [135, 140], [141, 149], [149, 150], [151, 158], [159, 168], [169, 182], [183, 184], [185, 192], [193, 202], [203, 217], [217, 218]]}
{"doc_key": "ai-train-59", "ner": [[5, 10, "conference"], [22, 22, "task"], [21, 26, "task"], [29, 30, "metrics"], [32, 38, "metrics"], [43, 46, "conference"], [48, 48, "conference"], [51, 51, "location"], [53, 53, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 10, 22, 22, "related-to", "subject_at", false, false], [5, 10, 21, 26, "related-to", "subject_at", false, false], [29, 30, 5, 10, "temporal", "", false, false], [32, 38, 29, 30, "named", "", true, false], [48, 48, 43, 46, "named", "", false, false], [51, 51, 53, 53, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Jedn\u0105", "z", "metryk", "wykorzystywanych", "podczas", "corocznych", "konferencji", "NIST", "Document", "Understanding", "Conferences", ",", "w", "kt\u00f3rych", "grupy", "badawcze", "zg\u0142aszaj\u0105", "swoje", "systemy", "zar\u00f3wno", "do", "zada\u0144", "streszczania", ",", "jak", "i", "t\u0142umaczenia", ",", "jest", "metryka", "ROUGE", "(", "Recall", "-", "Oriented", "Understudy", "for", "Gisting", "Evaluation", ",", "In", "Advances", "of", "Neural", "Information", "Processing", "Systems", "(", "NIPS", ")", ",", "Montreal", ",", "Canada", ",", "December", "-", "2014", "."], "sentence-detokenized": "Jedn\u0105 z metryk wykorzystywanych podczas corocznych konferencji NIST Document Understanding Conferences, w kt\u00f3rych grupy badawcze zg\u0142aszaj\u0105 swoje systemy zar\u00f3wno do zada\u0144 streszczania, jak i t\u0142umaczenia, jest metryka ROUGE (Recall-Oriented Understudy for Gisting Evaluation, In Advances of Neural Information Processing Systems (NIPS), Montreal, Canada, December - 2014.", "token2charspan": [[0, 5], [6, 7], [8, 14], [15, 31], [32, 39], [40, 50], [51, 62], [63, 67], [68, 76], [77, 90], [91, 102], [102, 103], [104, 105], [106, 113], [114, 119], [120, 128], [129, 138], [139, 144], [145, 152], [153, 160], [161, 163], [164, 169], [170, 182], [182, 183], [184, 187], [188, 189], [190, 201], [201, 202], [203, 207], [208, 215], [216, 221], [222, 223], [223, 229], [229, 230], [230, 238], [239, 249], [250, 253], [254, 261], [262, 272], [272, 273], [274, 276], [277, 285], [286, 288], [289, 295], [296, 307], [308, 318], [319, 326], [327, 328], [328, 332], [332, 333], [333, 334], [335, 343], [343, 344], [345, 351], [351, 352], [353, 361], [362, 363], [364, 368], [368, 369]]}
{"doc_key": "ai-train-60", "ner": [[7, 7, "programlang"], [9, 9, "product"], [13, 13, "programlang"], [16, 16, "product"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 7, 13, 13, "type-of", "", false, false], [7, 7, 22, 22, "named", "", false, false], [9, 9, 13, 13, "part-of", "", false, false], [9, 9, 16, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Ta", "sama", "implementacja", ",", "do", "uruchomienia", "w", "Javie", "z", "JShell", "(", "minimum", "Java", "9", ")", ":", "codejshell", "scriptfile", "/", "codesyntaxhighlight", "lang", "=", "java"], "sentence-detokenized": "Ta sama implementacja, do uruchomienia w Javie z JShell (minimum Java 9): codejshell scriptfile / codesyntaxhighlight lang = java", "token2charspan": [[0, 2], [3, 7], [8, 21], [21, 22], [23, 25], [26, 38], [39, 40], [41, 46], [47, 48], [49, 55], [56, 57], [57, 64], [65, 69], [70, 71], [71, 72], [72, 73], [74, 84], [85, 95], [96, 97], [98, 117], [118, 122], [123, 124], [125, 129]]}
{"doc_key": "ai-train-61", "ner": [[0, 1, "metrics"], [6, 6, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 6, 6, "origin", "based_on", false, false]], "relations_mapping_to_source": [0], "sentence": ["Metryka", "NIST", "jest", "oparta", "na", "metryce", "BLEU", ",", "ale", "z", "pewnymi", "zmianami", "."], "sentence-detokenized": "Metryka NIST jest oparta na metryce BLEU, ale z pewnymi zmianami.", "token2charspan": [[0, 7], [8, 12], [13, 17], [18, 24], [25, 27], [28, 35], [36, 40], [40, 41], [42, 45], [46, 47], [48, 55], [56, 64], [64, 65]]}
{"doc_key": "ai-train-62", "ner": [[6, 6, "country"], [9, 11, "university"], [13, 15, "university"], [22, 23, "product"], [27, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 11, 6, 6, "physical", "", false, false], [13, 15, 6, 6, "physical", "", false, false], [22, 23, 9, 11, "origin", "", false, false], [22, 23, 13, 15, "origin", "", false, false], [22, 23, 27, 28, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Pod", "koniec", "lat", "80", ".", "dwa", "holenderskie", "uniwersytety", ",", "University", "of", "Groningen", "i", "University", "of", "Twente", ",", "wsp\u00f3lnie", "rozpocz\u0119\u0142y", "projekt", "o", "nazwie", "Knowledge", "Graphs", ",", "kt\u00f3ry", "jest", "sieci\u0105", "semantyczn\u0105", ",", "ale", "z", "dodatkowym", "ograniczeniem", ",", "\u017ce", "kraw\u0119dzie", "s\u0105", "ograniczone", "do", "bycia", "z", "ograniczonego", "zbioru", "mo\u017cliwych", "relacji", ",", "aby", "u\u0142atwi\u0107", "algebry", "na", "grafie", "."], "sentence-detokenized": "Pod koniec lat 80. dwa holenderskie uniwersytety, University of Groningen i University of Twente, wsp\u00f3lnie rozpocz\u0119\u0142y projekt o nazwie Knowledge Graphs, kt\u00f3ry jest sieci\u0105 semantyczn\u0105, ale z dodatkowym ograniczeniem, \u017ce kraw\u0119dzie s\u0105 ograniczone do bycia z ograniczonego zbioru mo\u017cliwych relacji, aby u\u0142atwi\u0107 algebry na grafie.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 17], [17, 18], [19, 22], [23, 35], [36, 48], [48, 49], [50, 60], [61, 63], [64, 73], [74, 75], [76, 86], [87, 89], [90, 96], [96, 97], [98, 106], [107, 117], [118, 125], [126, 127], [128, 134], [135, 144], [145, 151], [151, 152], [153, 158], [159, 163], [164, 170], [171, 182], [182, 183], [184, 187], [188, 189], [190, 200], [201, 214], [214, 215], [216, 218], [219, 228], [229, 231], [232, 243], [244, 246], [247, 252], [253, 254], [255, 268], [269, 275], [276, 285], [286, 293], [293, 294], [295, 298], [299, 306], [307, 314], [315, 317], [318, 324], [324, 325]]}
{"doc_key": "ai-train-63", "ner": [[0, 2, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Programy", "sprawdzaj\u0105ce", "gramatyk\u0119", "s\u0105", "najcz\u0119\u015bciej", "implementowane", "jako", "funkcja", "wi\u0119kszego", "programu", ",", "takiego", "jak", "edytor", "tekstu", ",", "ale", "s\u0105", "r\u00f3wnie\u017c", "dost\u0119pne", "jako", "samodzielne", "aplikacje", ",", "kt\u00f3re", "mog\u0105", "by\u0107", "aktywowane", "z", "poziomu", "program\u00f3w", "pracuj\u0105cych", "z", "edytowalnym", "tekstem", "."], "sentence-detokenized": "Programy sprawdzaj\u0105ce gramatyk\u0119 s\u0105 najcz\u0119\u015bciej implementowane jako funkcja wi\u0119kszego programu, takiego jak edytor tekstu, ale s\u0105 r\u00f3wnie\u017c dost\u0119pne jako samodzielne aplikacje, kt\u00f3re mog\u0105 by\u0107 aktywowane z poziomu program\u00f3w pracuj\u0105cych z edytowalnym tekstem.", "token2charspan": [[0, 8], [9, 21], [22, 31], [32, 34], [35, 46], [47, 61], [62, 66], [67, 74], [75, 84], [85, 93], [93, 94], [95, 102], [103, 106], [107, 113], [114, 120], [120, 121], [122, 125], [126, 128], [129, 136], [137, 145], [146, 150], [151, 162], [163, 172], [172, 173], [174, 179], [180, 184], [185, 188], [189, 199], [200, 201], [202, 209], [210, 219], [220, 231], [232, 233], [234, 245], [246, 253], [253, 254]]}
{"doc_key": "ai-train-64", "ner": [[2, 7, "organisation"], [9, 15, "conference"], [16, 20, "organisation"], [24, 27, "conference"], [29, 32, "conference"], [36, 37, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Jest", "cz\u0142onkiem", "American", "Association", "for", "Advancement", "of", "Science", ",", "Association", "for", "the", "Advancement", "Artificial", "Intelligence", "oraz", "Cognitive", "Science", "Society", ",", "a", "tak\u017ce", "redaktorem", "czasopism", "J", ".", "Automated", "Reasoning", ",", "J", ".", "Learning", "Sciences", "oraz", "J", ".", "Applied", "Ontology", "."], "sentence-detokenized": "Jest cz\u0142onkiem American Association for Advancement of Science, Association for the Advancement Artificial Intelligence oraz Cognitive Science Society, a tak\u017ce redaktorem czasopism J. Automated Reasoning, J. Learning Sciences oraz J. Applied Ontology.", "token2charspan": [[0, 4], [5, 14], [15, 23], [24, 35], [36, 39], [40, 51], [52, 54], [55, 62], [62, 63], [64, 75], [76, 79], [80, 83], [84, 95], [96, 106], [107, 119], [120, 124], [125, 134], [135, 142], [143, 150], [150, 151], [152, 153], [154, 159], [160, 170], [171, 180], [181, 182], [182, 183], [184, 193], [194, 203], [203, 204], [205, 206], [206, 207], [208, 216], [217, 225], [226, 230], [231, 232], [232, 233], [234, 241], [242, 250], [250, 251]]}
{"doc_key": "ai-train-65", "ner": [[0, 8, "algorithm"], [4, 4, "algorithm"], [9, 9, "task"], [16, 17, "researcher"], [19, 20, "university"], [22, 23, "researcher"], [25, 28, "organisation"], [30, 30, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 8, 9, 9, "type-of", "", false, false], [0, 8, 16, 17, "origin", "", false, false], [0, 8, 22, 23, "origin", "", false, false], [4, 4, 0, 8, "named", "", false, false], [16, 17, 19, 20, "physical", "", false, false], [16, 17, 19, 20, "role", "", false, false], [22, 23, 25, 28, "role", "", false, false], [30, 30, 25, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Linear", "predictive", "coding", "(", "LPC", ")", ",", "forma", "kodowania", "mowy", ",", "zacz\u0119\u0142a", "si\u0119", "rozwija\u0107", "dzi\u0119ki", "pracy", "Fumitady", "Itakury", "z", "Uniwersytetu", "Nagoya", "i", "Shuzo", "Saito", "z", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "w", "1966", "roku", "."], "sentence-detokenized": "Linear predictive coding (LPC), forma kodowania mowy, zacz\u0119\u0142a si\u0119 rozwija\u0107 dzi\u0119ki pracy Fumitady Itakury z Uniwersytetu Nagoya i Shuzo Saito z Nippon Telegraph and Telephone (NTT) w 1966 roku.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [30, 31], [32, 37], [38, 47], [48, 52], [52, 53], [54, 61], [62, 65], [66, 74], [75, 81], [82, 87], [88, 96], [97, 104], [105, 106], [107, 119], [120, 126], [127, 128], [129, 134], [135, 140], [141, 142], [143, 149], [150, 159], [160, 163], [164, 173], [174, 175], [175, 178], [178, 179], [180, 181], [182, 186], [187, 191], [191, 192]]}
{"doc_key": "ai-train-66", "ner": [[58, 59, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Je\u015bli", "sygna\u0142", "jest", "dalej", "ergodyczny", ",", "to", "wszystkie", "\u015bcie\u017cki", "pr\u00f3bek", "wykazuj\u0105", "t\u0119", "sam\u0105", "\u015bredni\u0105", "czasow\u0105", ",", "a", "zatem", "mathR", "_", "x", "^", "{", "n", "/", "T", "_", "0", "}", "(", "\\u00", "\u21a9", "tau", ")", "=", "widehat", "{", "R", "}", "_", "x", "^", "{", "n", "/", "T", "_", "0", "}", "(", "\\u00", "\u21a9", "tau", ")", "/", "math", "w", "sensie", "b\u0142\u0119du", "\u015bredniokwadratowego", "."], "sentence-detokenized": "Je\u015bli sygna\u0142 jest dalej ergodyczny, to wszystkie \u015bcie\u017cki pr\u00f3bek wykazuj\u0105 t\u0119 sam\u0105 \u015bredni\u0105 czasow\u0105, a zatem mathR _ x ^ {n / T _ 0} (\\u00\u21a9 tau) = widehat {R} _ x ^ {n / T _ 0} (\\u00\u21a9 tau) / math w sensie b\u0142\u0119du \u015bredniokwadratowego.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 23], [24, 34], [34, 35], [36, 38], [39, 48], [49, 56], [57, 63], [64, 72], [73, 75], [76, 80], [81, 88], [89, 96], [96, 97], [98, 99], [100, 105], [106, 111], [112, 113], [114, 115], [116, 117], [118, 119], [119, 120], [121, 122], [123, 124], [125, 126], [127, 128], [128, 129], [130, 131], [131, 135], [135, 136], [137, 140], [140, 141], [142, 143], [144, 151], [152, 153], [153, 154], [154, 155], [156, 157], [158, 159], [160, 161], [162, 163], [163, 164], [165, 166], [167, 168], [169, 170], [171, 172], [172, 173], [174, 175], [175, 179], [179, 180], [181, 184], [184, 185], [186, 187], [188, 192], [193, 194], [195, 201], [202, 207], [208, 227], [227, 228]]}
{"doc_key": "ai-train-67", "ner": [[0, 1, "task"], [3, 4, "task"], [12, 14, "algorithm"], [16, 16, "algorithm"], [19, 21, "algorithm"], [23, 23, "algorithm"], [26, 28, "algorithm"], [30, 30, "algorithm"], [34, 36, "algorithm"], [38, 38, "algorithm"], [41, 43, "misc"], [51, 52, "algorithm"], [54, 56, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[12, 14, 41, 43, "related-to", "", false, false], [16, 16, 12, 14, "named", "", false, false], [19, 21, 41, 43, "related-to", "", false, false], [23, 23, 19, 21, "named", "", false, false], [26, 28, 41, 43, "related-to", "", false, false], [30, 30, 26, 28, "named", "", false, false], [34, 36, 41, 43, "related-to", "", false, false], [38, 38, 34, 36, "named", "", false, false], [51, 52, 54, 56, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Ekstrakcj\u0119", "cech", "i", "redukcj\u0119", "wymiar\u00f3w", "mo\u017cna", "po\u0142\u0105czy\u0107", "w", "jednym", "kroku", ",", "stosuj\u0105c", "analiz\u0119", "sk\u0142adowych", "g\u0142\u00f3wnych", "(", "PCA", ")", ",", "liniow\u0105", "analiz\u0119", "dyskryminacyjn\u0105", "(", "LDA", ")", ",", "analiz\u0119", "korelacji", "kanonicznej", "(", "CCA", ")", "lub", "techniki", "faktoryzacji", "macierzy", "nieujemnej", "(", "NMF", ")", "jako", "etap", "przetwarzania", "wst\u0119pnego", ",", "po", "kt\u00f3rym", "nast\u0119puje", "grupowanie", "za", "pomoc\u0105", "K", "-NN", "na", "wektorach", "cech", "w", "przestrzeni", "o", "zredukowanym", "wymiarze", "."], "sentence-detokenized": "Ekstrakcj\u0119 cech i redukcj\u0119 wymiar\u00f3w mo\u017cna po\u0142\u0105czy\u0107 w jednym kroku, stosuj\u0105c analiz\u0119 sk\u0142adowych g\u0142\u00f3wnych (PCA), liniow\u0105 analiz\u0119 dyskryminacyjn\u0105 (LDA), analiz\u0119 korelacji kanonicznej (CCA) lub techniki faktoryzacji macierzy nieujemnej (NMF) jako etap przetwarzania wst\u0119pnego, po kt\u00f3rym nast\u0119puje grupowanie za pomoc\u0105 K-NN na wektorach cech w przestrzeni o zredukowanym wymiarze.", "token2charspan": [[0, 10], [11, 15], [16, 17], [18, 26], [27, 35], [36, 41], [42, 50], [51, 52], [53, 59], [60, 65], [65, 66], [67, 75], [76, 83], [84, 94], [95, 103], [104, 105], [105, 108], [108, 109], [109, 110], [111, 118], [119, 126], [127, 142], [143, 144], [144, 147], [147, 148], [148, 149], [150, 157], [158, 167], [168, 179], [180, 181], [181, 184], [184, 185], [186, 189], [190, 198], [199, 211], [212, 220], [221, 231], [232, 233], [233, 236], [236, 237], [238, 242], [243, 247], [248, 261], [262, 271], [271, 272], [273, 275], [276, 282], [283, 292], [293, 303], [304, 306], [307, 313], [314, 315], [315, 318], [319, 321], [322, 331], [332, 336], [337, 338], [339, 350], [351, 352], [353, 365], [366, 374], [374, 375]]}
{"doc_key": "ai-train-68", "ner": [[3, 3, "programlang"], [5, 5, "programlang"], [7, 7, "programlang"], [9, 10, "programlang"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[16, 16, 3, 3, "related-to", "program_type_compatible_with", false, false], [16, 16, 5, 5, "related-to", "program_type_compatible_with", false, false], [16, 16, 7, 7, "related-to", "program_type_compatible_with", false, false], [16, 16, 9, 10, "related-to", "program_type_compatible_with", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Biblioteki", "napisane", "w", "Perlu", ",", "Javie", ",", "ActiveX", "lub", ".", "NET", "mog\u0105", "by\u0107", "bezpo\u015brednio", "wywo\u0142ywane", "z", "MATLABa", ","], "sentence-detokenized": "Biblioteki napisane w Perlu, Javie, ActiveX lub .NET mog\u0105 by\u0107 bezpo\u015brednio wywo\u0142ywane z MATLABa,", "token2charspan": [[0, 10], [11, 19], [20, 21], [22, 27], [27, 28], [29, 34], [34, 35], [36, 43], [44, 47], [48, 49], [49, 52], [53, 57], [58, 61], [62, 74], [75, 85], [86, 87], [88, 95], [95, 96]]}
{"doc_key": "ai-train-69", "ner": [[2, 5, "task"], [7, 9, "task"], [21, 22, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 5, 7, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Zadanie", "rozpoznawania", "nazwanych", "jednostek", "w", "tek\u015bcie", "to", "Named", "Entity", "Recognition", ",", "natomiast", "zadanie", "okre\u015blania", "to\u017csamo\u015bci", "nazwanych", "jednostek", "wymienionych", "w", "tek\u015bcie", "to", "Entity", "Linking", "."], "sentence-detokenized": "Zadanie rozpoznawania nazwanych jednostek w tek\u015bcie to Named Entity Recognition, natomiast zadanie okre\u015blania to\u017csamo\u015bci nazwanych jednostek wymienionych w tek\u015bcie to Entity Linking.", "token2charspan": [[0, 7], [8, 21], [22, 31], [32, 41], [42, 43], [44, 51], [52, 54], [55, 60], [61, 67], [68, 79], [79, 80], [81, 90], [91, 98], [99, 109], [110, 120], [121, 130], [131, 140], [141, 153], [154, 155], [156, 163], [164, 166], [167, 173], [174, 181], [181, 182]]}
{"doc_key": "ai-train-70", "ner": [[0, 1, "algorithm"], [22, 22, "programlang"], [23, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 23, 23, "part-of", "", true, false], [23, 23, 22, 22, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Funkcje", "sigmoidalne", "i", "pochodne", "u\u017cywane", "w", "pakiecie", "by\u0142y", "pierwotnie", "zawarte", "w", "pakiecie", ",", "od", "wersji", "0.8.0", "zosta\u0142y", "one", "wydane", "w", "oddzielnym", "pakiecie", "R", "sigmoid", ",", "z", "zamiarem", "umo\u017cliwienia", "bardziej", "og\u00f3lnego", "u\u017cycia", "."], "sentence-detokenized": "Funkcje sigmoidalne i pochodne u\u017cywane w pakiecie by\u0142y pierwotnie zawarte w pakiecie, od wersji 0.8.0 zosta\u0142y one wydane w oddzielnym pakiecie R sigmoid, z zamiarem umo\u017cliwienia bardziej og\u00f3lnego u\u017cycia.", "token2charspan": [[0, 7], [8, 19], [20, 21], [22, 30], [31, 38], [39, 40], [41, 49], [50, 54], [55, 65], [66, 73], [74, 75], [76, 84], [84, 85], [86, 88], [89, 95], [96, 101], [102, 109], [110, 113], [114, 120], [121, 122], [123, 133], [134, 142], [143, 144], [145, 152], [152, 153], [154, 155], [156, 164], [165, 177], [178, 186], [187, 195], [196, 202], [202, 203]]}
{"doc_key": "ai-train-71", "ner": [[0, 0, "programlang"], [7, 11, "organisation"], [13, 13, "organisation"], [19, 20, "location"], [21, 21, "location"], [24, 25, "researcher"], [27, 28, "researcher"], [30, 31, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 24, 25, "artifact", "", true, false], [0, 0, 27, 28, "artifact", "", true, false], [0, 0, 30, 31, "artifact", "", true, false], [13, 13, 7, 11, "named", "", false, false], [13, 13, 19, 20, "physical", "", false, false], [19, 20, 21, 21, "physical", "", false, false], [24, 25, 7, 11, "role", "", false, false], [27, 28, 7, 11, "role", "", false, false], [30, 31, 7, 11, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Logo", "zosta\u0142o", "stworzone", "w", "1967", "roku", "w", "Bolt", ",", "Beranek", "and", "Newman", "(", "BBN", ")", ",", "firmie", "badawczej", "z", "Cambridge", "w", "Massachusetts", ",", "przez", "Wally'ego", "Feurzeiga", ",", "Cynthi\u0119", "Solomon", "i", "Seymoura", "Paperta", "."], "sentence-detokenized": "Logo zosta\u0142o stworzone w 1967 roku w Bolt, Beranek and Newman (BBN), firmie badawczej z Cambridge w Massachusetts, przez Wally'ego Feurzeiga, Cynthi\u0119 Solomon i Seymoura Paperta.", "token2charspan": [[0, 4], [5, 12], [13, 22], [23, 24], [25, 29], [30, 34], [35, 36], [37, 41], [41, 42], [43, 50], [51, 54], [55, 61], [62, 63], [63, 66], [66, 67], [67, 68], [69, 75], [76, 85], [86, 87], [88, 97], [98, 99], [100, 113], [113, 114], [115, 120], [121, 130], [131, 140], [140, 141], [142, 149], [150, 157], [158, 159], [160, 168], [169, 176], [176, 177]]}
{"doc_key": "ai-train-72", "ner": [[0, 0, "misc"], [7, 8, "field"], [16, 16, "field"], [20, 21, "algorithm"], [23, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 7, 8, "part-of", "", false, false], [0, 0, 16, 16, "compare", "", false, false], [20, 21, 16, 16, "part-of", "", false, false], [23, 24, 16, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Neuroewolucja", "jest", "powszechnie", "stosowana", "jako", "cz\u0119\u015b\u0107", "paradygmatu", "uczenia", "wzmacniaj\u0105cego", "i", "mo\u017cna", "j\u0105", "przeciwstawi\u0107", "konwencjonalnym", "technikom", "uczenia", "g\u0142\u0119bokiego", ",", "kt\u00f3re", "wykorzystuj\u0105", "zej\u015bcie", "gradientowe", "na", "sieci", "neuronowej", "o", "ustalonej", "topologii", "."], "sentence-detokenized": "Neuroewolucja jest powszechnie stosowana jako cz\u0119\u015b\u0107 paradygmatu uczenia wzmacniaj\u0105cego i mo\u017cna j\u0105 przeciwstawi\u0107 konwencjonalnym technikom uczenia g\u0142\u0119bokiego, kt\u00f3re wykorzystuj\u0105 zej\u015bcie gradientowe na sieci neuronowej o ustalonej topologii.", "token2charspan": [[0, 13], [14, 18], [19, 30], [31, 40], [41, 45], [46, 51], [52, 63], [64, 71], [72, 86], [87, 88], [89, 94], [95, 97], [98, 111], [112, 127], [128, 137], [138, 145], [146, 156], [156, 157], [158, 163], [164, 176], [177, 184], [185, 196], [197, 199], [200, 205], [206, 216], [217, 218], [219, 228], [229, 238], [238, 239]]}
{"doc_key": "ai-train-73", "ner": [[2, 3, "algorithm"], [50, 52, "metrics"], [54, 54, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[54, 54, 50, 52, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Je\u015bli", "u\u017cyjemy", "least", "squares", ",", "aby", "dopasowa\u0107", "funkcj\u0119", "w", "postaci", "hiperp\u0142aszczyzny", "\u0177", "=", "a", "+", "\u03b2", "supT", "/", "sup", "x", "do", "danych", "(", "x", "sub", "i", "/", "sub", ",", "y", "sub", "i", "/", "sub", ")", "sub", "1", "\u2264", "i", "\u2264", "n", "/", "sub", ",", "mogliby\u015bmy", "nast\u0119pnie", "oceni\u0107", "dopasowanie", "za", "pomoc\u0105", "\u015bredniego", "b\u0142\u0119du", "kwadratowego", "(", "MSE", ")", "."], "sentence-detokenized": "Je\u015bli u\u017cyjemy least squares, aby dopasowa\u0107 funkcj\u0119 w postaci hiperp\u0142aszczyzny \u0177 = a + \u03b2 supT / sup x do danych (x sub i / sub, y sub i / sub) sub 1 \u2264 i \u2264n / sub, mogliby\u015bmy nast\u0119pnie oceni\u0107 dopasowanie za pomoc\u0105 \u015bredniego b\u0142\u0119du kwadratowego (MSE).", "token2charspan": [[0, 5], [6, 13], [14, 19], [20, 27], [27, 28], [29, 32], [33, 42], [43, 50], [51, 52], [53, 60], [61, 77], [78, 79], [80, 81], [82, 83], [84, 85], [86, 87], [88, 92], [93, 94], [95, 98], [99, 100], [101, 103], [104, 110], [111, 112], [112, 113], [114, 117], [118, 119], [120, 121], [122, 125], [125, 126], [127, 128], [129, 132], [133, 134], [135, 136], [137, 140], [140, 141], [142, 145], [146, 147], [148, 149], [150, 151], [152, 153], [153, 154], [155, 156], [157, 160], [160, 161], [162, 172], [173, 182], [183, 189], [190, 201], [202, 204], [205, 211], [212, 221], [222, 227], [228, 240], [241, 242], [242, 245], [245, 246], [246, 247]]}
{"doc_key": "ai-train-74", "ner": [[5, 5, "country"], [7, 7, "country"], [9, 9, "country"], [11, 11, "country"], [13, 13, "country"], [15, 15, "country"], [17, 17, "country"], [19, 19, "country"], [21, 21, "country"], [23, 23, "country"], [25, 25, "country"], [27, 27, "country"], [29, 29, "country"], [31, 31, "country"], [33, 33, "country"], [35, 35, "country"], [37, 37, "country"], [39, 39, "country"], [41, 41, "country"], [43, 43, "country"], [46, 46, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "relations": [], "relations_mapping_to_source": [], "sentence": ["Firma", "posiada", "mi\u0119dzynarodowe", "oddzia\u0142y", "w", "Australii", ",", "Brazylii", ",", "Kanadzie", ",", "Chinach", ",", "Niemczech", ",", "Indiach", ",", "W\u0142oszech", ",", "Japonii", ",", "Korei", ",", "Litwie", ",", "Polsce", ",", "Malezji", ",", "Filipinach", ",", "Rosji", ",", "Singapurze", ",", "RPA", ",", "Hiszpanii", ",", "Tajwanie", ",", "Tajlandii", ",", "Turcji", "i", "Wielkiej", "Brytanii", "."], "sentence-detokenized": "Firma posiada mi\u0119dzynarodowe oddzia\u0142y w Australii, Brazylii, Kanadzie, Chinach, Niemczech, Indiach, W\u0142oszech, Japonii, Korei, Litwie, Polsce, Malezji, Filipinach, Rosji, Singapurze, RPA, Hiszpanii, Tajwanie, Tajlandii, Turcji i Wielkiej Brytanii.", "token2charspan": [[0, 5], [6, 13], [14, 28], [29, 37], [38, 39], [40, 49], [49, 50], [51, 59], [59, 60], [61, 69], [69, 70], [71, 78], [78, 79], [80, 89], [89, 90], [91, 98], [98, 99], [100, 108], [108, 109], [110, 117], [117, 118], [119, 124], [124, 125], [126, 132], [132, 133], [134, 140], [140, 141], [142, 149], [149, 150], [151, 161], [161, 162], [163, 168], [168, 169], [170, 180], [180, 181], [182, 185], [185, 186], [187, 196], [196, 197], [198, 206], [206, 207], [208, 217], [217, 218], [219, 225], [226, 227], [228, 236], [237, 245], [245, 246]]}
{"doc_key": "ai-train-75", "ner": [[3, 6, "field"], [12, 12, "organisation"], [15, 19, "university"], [25, 27, "organisation"], [29, 34, "university"], [39, 40, "university"], [42, 43, "university"], [45, 47, "university"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Posiada", "tytu\u0142", "doktora", "in\u017cynierii", "elektrycznej", "i", "komputerowej", "(", "2000", ")", "uzyskany", "w", "Inrii", "i", "na", "Uniwersytecie", "w", "Nicei", "Sophia", "Antipolis", ",", "zajmowa\u0142", "sta\u0142e", "stanowiska", "w", "Siemens", "Corporate", "Technology", ",", "\u00c9cole", "des", "ponts", "ParisTech", ",", "a", "tak\u017ce", "stanowiska", "go\u015bcinne", "w", "Rutgers", "University", ",", "Yale", "University", "i", "University", "of", "Houston", "."], "sentence-detokenized": "Posiada tytu\u0142 doktora in\u017cynierii elektrycznej i komputerowej (2000) uzyskany w Inrii i na Uniwersytecie w Nicei Sophia Antipolis, zajmowa\u0142 sta\u0142e stanowiska w Siemens Corporate Technology, \u00c9cole des ponts ParisTech, a tak\u017ce stanowiska go\u015bcinne w Rutgers University, Yale University i University of Houston.", "token2charspan": [[0, 7], [8, 13], [14, 21], [22, 32], [33, 45], [46, 47], [48, 60], [61, 62], [62, 66], [66, 67], [68, 76], [77, 78], [79, 84], [85, 86], [87, 89], [90, 103], [104, 105], [106, 111], [112, 118], [119, 128], [128, 129], [130, 138], [139, 144], [145, 155], [156, 157], [158, 165], [166, 175], [176, 186], [186, 187], [188, 193], [194, 197], [198, 203], [204, 213], [213, 214], [215, 216], [217, 222], [223, 233], [234, 242], [243, 244], [245, 252], [253, 263], [263, 264], [265, 269], [270, 280], [281, 282], [283, 293], [294, 296], [297, 304], [304, 305]]}
{"doc_key": "ai-train-76", "ner": [[7, 8, "researcher"], [10, 10, "researcher"], [17, 18, "product"], [20, 21, "country"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 10, 7, 8, "role", "licensing_patent_to", false, false], [10, 10, 20, 21, "physical", "", false, false], [23, 23, 10, 10, "artifact", "", false, false], [23, 23, 17, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Udzielaj\u0105c", "licencji", "na", "oryginalny", "patent", "przyznany", "wynalazcy", "George'owi", "Devolowi", ",", "Engelberger", "opracowa\u0142", "w", "latach", "50", ".", "pierwszego", "robota", "przemys\u0142owego", "w", "Stanach", "Zjednoczonych", "-", "Unimate", "."], "sentence-detokenized": "Udzielaj\u0105c licencji na oryginalny patent przyznany wynalazcy George'owi Devolowi, Engelberger opracowa\u0142 w latach 50. pierwszego robota przemys\u0142owego w Stanach Zjednoczonych - Unimate.", "token2charspan": [[0, 10], [11, 19], [20, 22], [23, 33], [34, 40], [41, 50], [51, 60], [61, 71], [72, 80], [80, 81], [82, 93], [94, 103], [104, 105], [106, 112], [113, 115], [115, 116], [117, 127], [128, 134], [135, 148], [149, 150], [151, 158], [159, 172], [173, 174], [175, 182], [182, 183]]}
{"doc_key": "ai-train-77", "ner": [[3, 4, "task"], [8, 9, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Wej\u015bcie", "nazywane", "jest", "rozpoznawaniem", "mowy", ",", "a", "wyj\u015bcie", "syntez\u0105", "mowy", "."], "sentence-detokenized": "Wej\u015bcie nazywane jest rozpoznawaniem mowy, a wyj\u015bcie syntez\u0105 mowy.", "token2charspan": [[0, 7], [8, 16], [17, 21], [22, 36], [37, 41], [41, 42], [43, 44], [45, 52], [53, 60], [61, 65], [65, 66]]}
{"doc_key": "ai-train-78", "ner": [[2, 2, "programlang"], [6, 6, "programlang"], [12, 12, "programlang"], [15, 15, "programlang"], [24, 24, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 12, 12, "named", "", false, false], [6, 6, 2, 2, "origin", "descendant_of", false, false], [6, 6, 15, 15, "general-affiliation", "", false, false], [6, 6, 24, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Potomkami", "j\u0119zyka", "CLIPS", "s\u0105", "m.in", ".", "Jess", "(", "oparta", "na", "regu\u0142ach", "cz\u0119\u015b\u0107", "CLIPS", "przepisana", "w", "Javie", ",", "p\u00f3\u017aniej", "wyros\u0142a", "w", "innym", "kierunku", ")", ",", "JESS", "by\u0142", "pierwotnie", "inspirowany"], "sentence-detokenized": "Potomkami j\u0119zyka CLIPS s\u0105 m.in. Jess (oparta na regu\u0142ach cz\u0119\u015b\u0107 CLIPS przepisana w Javie, p\u00f3\u017aniej wyros\u0142a w innym kierunku), JESS by\u0142 pierwotnie inspirowany", "token2charspan": [[0, 9], [10, 16], [17, 22], [23, 25], [26, 30], [30, 31], [32, 36], [37, 38], [38, 44], [45, 47], [48, 56], [57, 62], [63, 68], [69, 79], [80, 81], [82, 87], [87, 88], [89, 96], [97, 104], [105, 106], [107, 112], [113, 121], [121, 122], [122, 123], [124, 128], [129, 132], [133, 143], [144, 155]]}
{"doc_key": "ai-train-79", "ner": [[6, 6, "product"], [9, 11, "product"], [14, 16, "organisation"], [18, 19, "product"], [38, 38, "product"], [41, 43, "product"], [58, 59, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 11, 6, 6, "type-of", "", false, false], [14, 16, 9, 11, "usage", "", false, false], [18, 19, 14, 16, "artifact", "", false, false], [38, 38, 14, 16, "origin", "", true, false], [38, 38, 58, 59, "related-to", "", true, false], [41, 43, 14, 16, "origin", "", true, false], [41, 43, 58, 59, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Firma", "stworzy\u0142a", "r\u00f3wnie\u017c", "elastyczne", "inteligentne", "aplikacje", "AGV", ",", "projektuj\u0105c", "system", "sterowania", "Motivity", "wykorzystywany", "przez", "RMT", "Robotics", "do", "opracowania", "ADAM", "iAGV", "(", "Self", "-", "Guided", "Vehicle", ")", ",", "wykorzystywanego", "do", "z\u0142o\u017conych", "operacji", "podnoszenia", "i", "uk\u0142adania", ",", "w", "po\u0142\u0105czeniu", "z", "systemami", "bramowymi", "i", "ramionami", "robot\u00f3w", "przemys\u0142owych", ",", "stosowanymi", "w", "pierwszorz\u0119dnych", "fabrykach", "samochodowych", "do", "przenoszenia", "produkt\u00f3w", "z", "procesu", "do", "procesu", "w", "uk\u0142adach", "nieliniowych", "."], "sentence-detokenized": "Firma stworzy\u0142a r\u00f3wnie\u017c elastyczne inteligentne aplikacje AGV, projektuj\u0105c system sterowania Motivity wykorzystywany przez RMT Robotics do opracowania ADAM iAGV (Self-Guided Vehicle), wykorzystywanego do z\u0142o\u017conych operacji podnoszenia i uk\u0142adania, w po\u0142\u0105czeniu z systemami bramowymi i ramionami robot\u00f3w przemys\u0142owych, stosowanymi w pierwszorz\u0119dnych fabrykach samochodowych do przenoszenia produkt\u00f3w z procesu do procesu w uk\u0142adach nieliniowych.", "token2charspan": [[0, 5], [6, 15], [16, 23], [24, 34], [35, 47], [48, 57], [58, 61], [61, 62], [63, 74], [75, 81], [82, 92], [93, 101], [102, 116], [117, 122], [123, 126], [127, 135], [136, 138], [139, 150], [151, 155], [156, 160], [161, 162], [162, 166], [166, 167], [167, 173], [174, 181], [181, 182], [182, 183], [184, 200], [201, 203], [204, 213], [214, 222], [223, 234], [235, 236], [237, 246], [246, 247], [248, 249], [250, 260], [261, 262], [263, 272], [273, 282], [283, 284], [285, 294], [295, 302], [303, 316], [316, 317], [318, 329], [330, 331], [332, 348], [349, 358], [359, 372], [373, 375], [376, 388], [389, 398], [399, 400], [401, 408], [409, 411], [412, 419], [420, 421], [422, 430], [431, 443], [443, 444]]}
{"doc_key": "ai-train-80", "ner": [[6, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Parametry", "\u03b2", "s\u0105", "zwykle", "szacowane", "metod\u0105", "najwi\u0119kszego", "prawdopodobie\u0144stwa", "."], "sentence-detokenized": "Parametry \u03b2 s\u0105 zwykle szacowane metod\u0105 najwi\u0119kszego prawdopodobie\u0144stwa.", "token2charspan": [[0, 9], [10, 11], [12, 14], [15, 21], [22, 31], [32, 38], [39, 51], [52, 70], [70, 71]]}
{"doc_key": "ai-train-81", "ner": [[1, 2, "task"], [5, 5, "metrics"], [7, 7, "metrics"], [9, 9, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 1, 2, "part-of", "", false, false], [7, 7, 1, 2, "part-of", "", false, false], [9, 9, 1, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Metryki", "wyszukiwania", "informacji", "takie", "jak", "precyzja", "i", "recall", "czy", "DCG", "s\u0105", "przydatne", "do", "oceny", "jako\u015bci", "metody", "rekomendacji", "."], "sentence-detokenized": "Metryki wyszukiwania informacji takie jak precyzja i recall czy DCG s\u0105 przydatne do oceny jako\u015bci metody rekomendacji.", "token2charspan": [[0, 7], [8, 20], [21, 31], [32, 37], [38, 41], [42, 50], [51, 52], [53, 59], [60, 63], [64, 67], [68, 70], [71, 80], [81, 83], [84, 89], [90, 97], [98, 104], [105, 117], [117, 118]]}
{"doc_key": "ai-train-82", "ner": [[4, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typowa", "fabryka", "zawiera", "setki", "robot\u00f3w", "przemys\u0142owych", "pracuj\u0105cych", "na", "w", "pe\u0142ni", "zautomatyzowanych", "liniach", "produkcyjnych", ",", "gdzie", "jeden", "robot", "przypada", "na", "ka\u017cdych", "dziesi\u0119ciu", "pracownik\u00f3w", "ludzkich", "."], "sentence-detokenized": "Typowa fabryka zawiera setki robot\u00f3w przemys\u0142owych pracuj\u0105cych na w pe\u0142ni zautomatyzowanych liniach produkcyjnych, gdzie jeden robot przypada na ka\u017cdych dziesi\u0119ciu pracownik\u00f3w ludzkich.", "token2charspan": [[0, 6], [7, 14], [15, 22], [23, 28], [29, 36], [37, 50], [51, 62], [63, 65], [66, 67], [68, 73], [74, 91], [92, 99], [100, 113], [113, 114], [115, 120], [121, 126], [127, 132], [133, 141], [142, 144], [145, 152], [153, 163], [164, 175], [176, 184], [184, 185]]}
{"doc_key": "ai-train-83", "ner": [[5, 5, "product"], [13, 14, "field"], [19, 20, "task"], [22, 23, "task"], [25, 26, "task"], [28, 29, "task"], [31, 32, "task"], [34, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[13, 14, 5, 5, "usage", "", false, true], [19, 20, 13, 14, "part-of", "", false, false], [22, 23, 13, 14, "part-of", "", false, false], [25, 26, 13, 14, "part-of", "", false, false], [28, 29, 13, 14, "part-of", "", false, false], [31, 32, 13, 14, "part-of", "", false, false], [34, 35, 13, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["W", "ci\u0105gu", "ostatniej", "dekady", "sieci", "PCNN", "by\u0142y", "wykorzystywane", "w", "wielu", "zastosowaniach", "zwi\u0105zanych", "z", "przetwarzaniem", "obraz\u00f3w", ",", "w", "tym", ":", "segmentacji", "obraz\u00f3w", ",", "generowaniu", "cech", ",", "ekstrakcji", "twarzy", ",", "detekcji", "ruchu", ",", "powi\u0119kszaniu", "region\u00f3w", "i", "redukcji", "szum\u00f3w", "."], "sentence-detokenized": "W ci\u0105gu ostatniej dekady sieci PCNN by\u0142y wykorzystywane w wielu zastosowaniach zwi\u0105zanych z przetwarzaniem obraz\u00f3w, w tym: segmentacji obraz\u00f3w, generowaniu cech, ekstrakcji twarzy, detekcji ruchu, powi\u0119kszaniu region\u00f3w i redukcji szum\u00f3w.", "token2charspan": [[0, 1], [2, 7], [8, 17], [18, 24], [25, 30], [31, 35], [36, 40], [41, 55], [56, 57], [58, 63], [64, 78], [79, 89], [90, 91], [92, 106], [107, 114], [114, 115], [116, 117], [118, 121], [121, 122], [123, 134], [135, 142], [142, 143], [144, 155], [156, 160], [160, 161], [162, 172], [173, 179], [179, 180], [181, 189], [190, 195], [195, 196], [197, 209], [210, 218], [219, 220], [221, 229], [230, 236], [236, 237]]}
{"doc_key": "ai-train-84", "ner": [[0, 0, "researcher"], [13, 14, "field"], [17, 20, "misc"], [15, 28, "conference"], [30, 30, "conference"], [34, 37, "misc"], [39, 45, "conference"], [46, 47, "conference"], [49, 53, "conference"], [55, 55, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 0, 13, 14, "related-to", "contributes_to", false, false], [0, 0, 17, 20, "win-defeat", "", false, false], [0, 0, 34, 37, "win-defeat", "", false, false], [17, 20, 15, 28, "temporal", "", false, false], [30, 30, 15, 28, "named", "", false, false], [34, 37, 39, 45, "temporal", "", false, false], [34, 37, 49, 53, "temporal", "", false, false], [46, 47, 39, 45, "named", "", false, false], [55, 55, 49, 53, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Xu", "opublikowa\u0142", "ponad", "50", "prac", "na", "mi\u0119dzynarodowych", "konferencjach", "i", "w", "czasopismach", "z", "dziedziny", "widzenia", "komputerowego", "i", "zdoby\u0142", "nagrod\u0119", "Best", "Paper", "Award", "na", "mi\u0119dzynarodowej", "konferencji", "Non", "-Photorealistic", "Rendering", "and", "Animation", "(", "NPAR", ")", "2012", "oraz", "nagrod\u0119", "Best", "Reviewer", "Award", "na", "mi\u0119dzynarodowych", "konferencjach", "Asian", "Conference", "on", "Computer", "Vision", "ACCV", "2012", "i", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "2015", "."], "sentence-detokenized": "Xu opublikowa\u0142 ponad 50 prac na mi\u0119dzynarodowych konferencjach i w czasopismach z dziedziny widzenia komputerowego i zdoby\u0142 nagrod\u0119 Best Paper Award na mi\u0119dzynarodowej konferencji Non-Photorealistic Rendering and Animation (NPAR) 2012 oraz nagrod\u0119 Best Reviewer Award na mi\u0119dzynarodowych konferencjach Asian Conference on Computer Vision ACCV 2012 i International Conference on Computer Vision (ICCV) 2015.", "token2charspan": [[0, 2], [3, 14], [15, 20], [21, 23], [24, 28], [29, 31], [32, 48], [49, 62], [63, 64], [65, 66], [67, 79], [80, 81], [82, 91], [92, 100], [101, 114], [115, 116], [117, 123], [124, 131], [132, 136], [137, 142], [143, 148], [149, 151], [152, 167], [168, 179], [180, 183], [183, 198], [199, 208], [209, 212], [213, 222], [223, 224], [224, 228], [228, 229], [230, 234], [235, 239], [240, 247], [248, 252], [253, 261], [262, 267], [268, 270], [271, 287], [288, 301], [302, 307], [308, 318], [319, 321], [322, 330], [331, 337], [338, 342], [343, 347], [348, 349], [350, 363], [364, 374], [375, 377], [378, 386], [387, 393], [394, 395], [395, 399], [399, 400], [401, 405], [405, 406]]}
{"doc_key": "ai-train-85", "ner": [[0, 0, "programlang"], [2, 2, "field"], [4, 5, "field"], [7, 8, "misc"], [11, 12, "researcher"], [14, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 2, 2, "part-of", "", false, false], [0, 0, 4, 5, "part-of", "", false, false], [0, 0, 7, 8, "type-of", "", false, false], [14, 16, 0, 0, "usage", "", false, false], [14, 16, 11, 12, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["CycL", "w", "informatyce", "i", "sztucznej", "inteligencji", "to", "j\u0119zyk", "ontologii", "u\u017cywany", "przez", "Douga", "Lenata", "w", "projekcie", "Cyc", "artificial", "."], "sentence-detokenized": "CycL w informatyce i sztucznej inteligencji to j\u0119zyk ontologii u\u017cywany przez Douga Lenata w projekcie Cyc artificial.", "token2charspan": [[0, 4], [5, 6], [7, 18], [19, 20], [21, 30], [31, 43], [44, 46], [47, 52], [53, 62], [63, 70], [71, 76], [77, 82], [83, 89], [90, 91], [92, 101], [102, 105], [106, 116], [116, 117]]}
{"doc_key": "ai-train-86", "ner": [[2, 3, "task"], [5, 6, "metrics"], [13, 13, "metrics"], [15, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 2, 3, "part-of", "", false, false], [13, 13, 5, 6, "named", "", false, false], [15, 17, 5, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["R\u00f3wnie\u017c", "w", "analizie", "regresji", ",", "b\u0142\u0105d", "\u015bredniokwadratowy", ",", "cz\u0119sto", "okre\u015blany", "jako", "\u015bredniokwadratowy", "b\u0142\u0105d", "predykcji", "lub", "pozapr\u00f3bkowy", "b\u0142\u0105d", "\u015bredniokwadratowy", ",", "mo\u017ce", "odnosi\u0107", "si\u0119", "do", "\u015bredniej", "warto\u015bci", "kwadratowych", "odchyle\u0144", "predykcji", "od", "warto\u015bci", "TRUE", ",", "nad", "pozapr\u00f3bkow\u0105", "przestrzeni\u0105", "testow\u0105", ",", "wygenerowanych", "przez", "model", "oszacowany", "nad", "okre\u015blon\u0105", "przestrzeni\u0105", "pr\u00f3bkow\u0105", "."], "sentence-detokenized": "R\u00f3wnie\u017c w analizie regresji, b\u0142\u0105d \u015bredniokwadratowy, cz\u0119sto okre\u015blany jako \u015bredniokwadratowy b\u0142\u0105d predykcji lub pozapr\u00f3bkowy b\u0142\u0105d \u015bredniokwadratowy, mo\u017ce odnosi\u0107 si\u0119 do \u015bredniej warto\u015bci kwadratowych odchyle\u0144 predykcji od warto\u015bci TRUE, nad pozapr\u00f3bkow\u0105 przestrzeni\u0105 testow\u0105, wygenerowanych przez model oszacowany nad okre\u015blon\u0105 przestrzeni\u0105 pr\u00f3bkow\u0105.", "token2charspan": [[0, 7], [8, 9], [10, 18], [19, 27], [27, 28], [29, 33], [34, 51], [51, 52], [53, 59], [60, 69], [70, 74], [75, 92], [93, 97], [98, 107], [108, 111], [112, 124], [125, 129], [130, 147], [147, 148], [149, 153], [154, 161], [162, 165], [166, 168], [169, 177], [178, 186], [187, 199], [200, 208], [209, 218], [219, 221], [222, 230], [231, 235], [235, 236], [237, 240], [241, 253], [254, 266], [267, 274], [274, 275], [276, 290], [291, 296], [297, 302], [303, 313], [314, 317], [318, 327], [328, 340], [341, 349], [349, 350]]}
{"doc_key": "ai-train-87", "ner": [[7, 7, "algorithm"], [9, 10, "algorithm"], [16, 17, "algorithm"], [28, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 9, 10, "compare", "", false, false], [7, 7, 16, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Je\u015bli", "chodzi", "o", "wyniki", ",", "deskryptory", "blokowe", "C-HOG", "i", "R-HOG", "maj\u0105", "por\u00f3wnywalne", "wyniki", ",", "przy", "czym", "deskryptory", "C-HOG", "utrzymuj\u0105", "niewielk\u0105", "przewag\u0119", "w", "zakresie", "wska\u017anika", "braku", "wykrycia", "przy", "sta\u0142ych", "wska\u017anikach", "FALSE", "positive", "w", "obu", "zestawach", "danych", "."], "sentence-detokenized": "Je\u015bli chodzi o wyniki, deskryptory blokowe C-HOG i R-HOG maj\u0105 por\u00f3wnywalne wyniki, przy czym deskryptory C-HOG utrzymuj\u0105 niewielk\u0105 przewag\u0119 w zakresie wska\u017anika braku wykrycia przy sta\u0142ych wska\u017anikach FALSE positive w obu zestawach danych.", "token2charspan": [[0, 5], [6, 12], [13, 14], [15, 21], [21, 22], [23, 34], [35, 42], [43, 48], [49, 50], [51, 56], [57, 61], [62, 74], [75, 81], [81, 82], [83, 87], [88, 92], [93, 104], [105, 110], [111, 120], [121, 130], [131, 139], [140, 141], [142, 150], [151, 160], [161, 166], [167, 175], [176, 180], [181, 188], [189, 200], [201, 206], [207, 215], [216, 217], [218, 221], [222, 231], [232, 238], [238, 239]]}
{"doc_key": "ai-train-88", "ner": [[4, 7, "algorithm"], [9, 10, "misc"], [12, 14, "algorithm"], [16, 19, "algorithm"], [20, 21, "algorithm"], [23, 25, "algorithm"], [27, 29, "algorithm"], [32, 33, "misc"], [37, 39, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[4, 7, 9, 10, "usage", "", false, false], [12, 14, 32, 33, "usage", "", false, false], [16, 19, 32, 33, "usage", "", false, false], [20, 21, 32, 33, "usage", "", false, false], [23, 25, 32, 33, "usage", "", false, false], [27, 29, 32, 33, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Popularne", "algorytmy", "rozpoznawania", "obejmuj\u0105", "analiz\u0119", "sk\u0142adowych", "g\u0142\u00f3wnych", "z", "wykorzystaniem", "powierzchni", "w\u0142asnych", ",", "liniow\u0105", "analiz\u0119", "dyskryminacyjn\u0105", ",", "dopasowanie", "spr\u0119\u017cyste", "z", "wykorzystaniem", "algorytmu", "Fisherface", ",", "ukryty", "model", "Markowa", ",", "uczenie", "wieloliniowe", "podprzestrzeni", "z", "wykorzystaniem", "reprezentacji", "tensorowej", "oraz", "motywowane", "neuronalnie", "dynamiczne", "dopasowanie", "\u0142\u0105cza", "."], "sentence-detokenized": "Popularne algorytmy rozpoznawania obejmuj\u0105 analiz\u0119 sk\u0142adowych g\u0142\u00f3wnych z wykorzystaniem powierzchni w\u0142asnych, liniow\u0105 analiz\u0119 dyskryminacyjn\u0105, dopasowanie spr\u0119\u017cyste z wykorzystaniem algorytmu Fisherface, ukryty model Markowa, uczenie wieloliniowe podprzestrzeni z wykorzystaniem reprezentacji tensorowej oraz motywowane neuronalnie dynamiczne dopasowanie \u0142\u0105cza.", "token2charspan": [[0, 9], [10, 19], [20, 33], [34, 42], [43, 50], [51, 61], [62, 70], [71, 72], [73, 87], [88, 99], [100, 108], [108, 109], [110, 117], [118, 125], [126, 141], [141, 142], [143, 154], [155, 164], [165, 166], [167, 181], [182, 191], [192, 202], [202, 203], [204, 210], [211, 216], [217, 224], [224, 225], [226, 233], [234, 246], [247, 261], [262, 263], [264, 278], [279, 292], [293, 303], [304, 308], [309, 319], [320, 331], [332, 342], [343, 354], [355, 360], [360, 361]]}
{"doc_key": "ai-train-89", "ner": [[2, 6, "misc"], [16, 18, "location"], [34, 36, "location"], [50, 50, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 18, 2, 6, "temporal", "", false, false], [34, 36, 2, 6, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pocz\u0105wszy", "od", "2019", "Toronto", "International", "Film", "Festival", ",", "filmy", "mog\u0105", "by\u0107", "teraz", "ograniczone", "z", "wy\u015bwietlania", "w", "Scotiabank", "Theatre", "Toronto", "-", "jednym", "z", "g\u0142\u00f3wnych", "miejsc", "festiwalu", "-", "i", "wy\u015bwietlane", "w", "innych", "miejscach", "(", "takich", "jak", "TIFF", "Bell", "Lightbox", "i", "inne", "lokalne", "kina", ")", ",", "je\u015bli", "s\u0105", "dystrybuowane", "przez", "us\u0142ug\u0119", "tak\u0105", "jak", "Netflix", "."], "sentence-detokenized": "Pocz\u0105wszy od 2019 Toronto International Film Festival, filmy mog\u0105 by\u0107 teraz ograniczone z wy\u015bwietlania w Scotiabank Theatre Toronto - jednym z g\u0142\u00f3wnych miejsc festiwalu - i wy\u015bwietlane w innych miejscach (takich jak TIFF Bell Lightbox i inne lokalne kina), je\u015bli s\u0105 dystrybuowane przez us\u0142ug\u0119 tak\u0105 jak Netflix.", "token2charspan": [[0, 9], [10, 12], [13, 17], [18, 25], [26, 39], [40, 44], [45, 53], [53, 54], [55, 60], [61, 65], [66, 69], [70, 75], [76, 87], [88, 89], [90, 102], [103, 104], [105, 115], [116, 123], [124, 131], [132, 133], [134, 140], [141, 142], [143, 151], [152, 158], [159, 168], [169, 170], [171, 172], [173, 184], [185, 186], [187, 193], [194, 203], [204, 205], [205, 211], [212, 215], [216, 220], [221, 225], [226, 234], [235, 236], [237, 241], [242, 249], [250, 254], [254, 255], [255, 256], [257, 262], [263, 265], [266, 279], [280, 285], [286, 292], [293, 297], [298, 301], [302, 309], [309, 310]]}
{"doc_key": "ai-train-90", "ner": [[3, 3, "organisation"], [8, 9, "researcher"], [5, 7, "organisation"], [18, 22, "product"], [13, 13, "researcher"], [31, 33, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6], "relations": [[3, 3, 5, 7, "related-to", "purchases", false, false], [8, 9, 13, 13, "named", "same", false, false], [5, 7, 8, 9, "origin", "founded_by", false, false], [18, 22, 3, 3, "artifact", "", false, false], [31, 33, 13, 13, "artifact", "", true, false]], "relations_mapping_to_source": [0, 2, 3, 4, 5], "sentence": ["W", "1977", "roku", "Unimation", "zakupi\u0142o", "Vicarm", "Inc", ".", "Victora", "Scheinmana", "i", "z", "pomoc\u0105", "Scheinmana", "stworzy\u0142o", "i", "rozpocz\u0119\u0142o", "produkcj\u0119", "Programowalnej", "Uniwersalnej", "Maszyny", "do", "Monta\u017cu", ",", "nowego", "modelu", "ramienia", "robotycznego", ",", "wykorzystuj\u0105cego", "najnowocze\u015bniejszy", "j\u0119zyk", "programowania", "VAL", "."], "sentence-detokenized": "W 1977 roku Unimation zakupi\u0142o Vicarm Inc. Victora Scheinmana i z pomoc\u0105 Scheinmana stworzy\u0142o i rozpocz\u0119\u0142o produkcj\u0119 Programowalnej Uniwersalnej Maszyny do Monta\u017cu, nowego modelu ramienia robotycznego, wykorzystuj\u0105cego najnowocze\u015bniejszy j\u0119zyk programowania VAL.", "token2charspan": [[0, 1], [2, 6], [7, 11], [12, 21], [22, 30], [31, 37], [38, 41], [41, 42], [43, 50], [51, 61], [62, 63], [64, 65], [66, 72], [73, 83], [84, 93], [94, 95], [96, 106], [107, 116], [117, 131], [132, 144], [145, 152], [153, 155], [156, 163], [163, 164], [165, 171], [172, 178], [179, 187], [188, 200], [200, 201], [202, 218], [219, 237], [238, 243], [244, 257], [258, 261], [261, 262]]}
{"doc_key": "ai-train-91", "ner": [[0, 0, "product"], [4, 4, "programlang"], [5, 6, "algorithm"], [8, 12, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 4, "general-affiliation", "", false, false], [0, 0, 5, 6, "origin", "implementation_of", false, false], [0, 0, 8, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["J48", "jest", "otwart\u0105", "implementacj\u0105", "Java", "algorytmu", "C4.5", "w", "narz\u0119dziu", "do", "eksploracji", "danych", "Weka", "."], "sentence-detokenized": "J48 jest otwart\u0105 implementacj\u0105 Java algorytmu C4.5 w narz\u0119dziu do eksploracji danych Weka.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 30], [31, 35], [36, 45], [46, 50], [51, 52], [53, 62], [63, 65], [66, 77], [78, 84], [85, 89], [89, 90]]}
{"doc_key": "ai-train-92", "ner": [[1, 2, "metrics"], [12, 13, "product"], [17, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 12, 13, "win-defeat", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Papier", "SSIM", "z", "2004", "roku", "by\u0142", "cytowany", "ponad", "20", "000", "razy", "wed\u0142ug", "Google", "Scholar", ",", "Otrzyma\u0142", "r\u00f3wnie\u017c", "nagrod\u0119", "IEEE", "Signal", "Processing", "Society", "Sustained", "Impact", "Award", "za", "2016", "rok", ",", "wskazuj\u0105c\u0105", "na", "papier", "maj\u0105cy", "niezwykle", "wysoki", "wp\u0142yw", "przez", "co", "najmniej", "10", "lat", "po", "jego", "publikacji", "."], "sentence-detokenized": "Papier SSIM z 2004 roku by\u0142 cytowany ponad 20 000 razy wed\u0142ug Google Scholar, Otrzyma\u0142 r\u00f3wnie\u017c nagrod\u0119 IEEE Signal Processing Society Sustained Impact Award za 2016 rok, wskazuj\u0105c\u0105 na papier maj\u0105cy niezwykle wysoki wp\u0142yw przez co najmniej 10 lat po jego publikacji.", "token2charspan": [[0, 6], [7, 11], [12, 13], [14, 18], [19, 23], [24, 27], [28, 36], [37, 42], [43, 45], [46, 49], [50, 54], [55, 61], [62, 68], [69, 76], [76, 77], [78, 86], [87, 94], [95, 102], [103, 107], [108, 114], [115, 125], [126, 133], [134, 143], [144, 150], [151, 156], [157, 159], [160, 164], [165, 168], [168, 169], [170, 180], [181, 183], [184, 190], [191, 197], [198, 207], [208, 214], [215, 220], [221, 226], [227, 229], [230, 238], [239, 241], [242, 245], [246, 248], [249, 253], [254, 264], [264, 265]]}
{"doc_key": "ai-train-93", "ner": [[0, 1, "task"], [21, 22, "product"], [31, 32, "product"], [34, 34, "organisation"], [35, 35, "product"], [39, 39, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 34, 34, "artifact", "", false, false], [21, 22, 0, 1, "related-to", "performs", false, false], [21, 22, 31, 32, "part-of", "", false, false], [34, 34, 39, 39, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Synteza", "mowy", "graniczy", "z", "ca\u0142kowit\u0105", "nieodr\u00f3\u017cnialno\u015bci\u0105", "od", "g\u0142osu", "prawdziwego", "cz\u0142owieka", "dzi\u0119ki", "wprowadzeniu", "w", "2016", "roku", "oprogramowania", "do", "edycji", "i", "generowania", "g\u0142osu", "Adobe", "Voco", ",", "prototypu", ",", "kt\u00f3ry", "ma", "by\u0107", "cz\u0119\u015bci\u0105", "Adobe", "Creative", "Suite", "oraz", "DeepMind", "WaveNet", ",", "prototypu", "od", "Google", "."], "sentence-detokenized": "Synteza mowy graniczy z ca\u0142kowit\u0105 nieodr\u00f3\u017cnialno\u015bci\u0105 od g\u0142osu prawdziwego cz\u0142owieka dzi\u0119ki wprowadzeniu w 2016 roku oprogramowania do edycji i generowania g\u0142osu Adobe Voco, prototypu, kt\u00f3ry ma by\u0107 cz\u0119\u015bci\u0105 Adobe Creative Suite oraz DeepMind WaveNet, prototypu od Google.", "token2charspan": [[0, 7], [8, 12], [13, 21], [22, 23], [24, 33], [34, 52], [53, 55], [56, 61], [62, 73], [74, 83], [84, 90], [91, 103], [104, 105], [106, 110], [111, 115], [116, 130], [131, 133], [134, 140], [141, 142], [143, 154], [155, 160], [161, 166], [167, 171], [171, 172], [173, 182], [182, 183], [184, 189], [190, 192], [193, 196], [197, 204], [205, 210], [211, 219], [220, 225], [226, 230], [231, 239], [240, 247], [247, 248], [249, 258], [259, 261], [262, 268], [268, 269]]}
{"doc_key": "ai-train-94", "ner": [[0, 0, "researcher"], [4, 6, "organisation"], [9, 16, "organisation"], [19, 19, "conference"], [23, 27, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 4, 6, "role", "", false, false], [0, 0, 9, 16, "role", "", false, false], [0, 0, 19, 19, "role", "", false, false], [0, 0, 23, 27, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Poggio", "jest", "honorowym", "cz\u0142onkiem", "Neuroscience", "Research", "Program", ",", "cz\u0142onkiem", "Ameryka\u0144skiej", "Akademii", "Sztuk", "i", "Nauk", ",", "a", "tak\u017ce", "stypendyst\u0105", "za\u0142o\u017cycielem", "AAAI", "i", "cz\u0142onkiem", "za\u0142o\u017cycielem", "McGovern", "Institute", "for", "Brain", "Research", "."], "sentence-detokenized": "Poggio jest honorowym cz\u0142onkiem Neuroscience Research Program, cz\u0142onkiem Ameryka\u0144skiej Akademii Sztuk i Nauk, a tak\u017ce stypendyst\u0105 za\u0142o\u017cycielem AAAI i cz\u0142onkiem za\u0142o\u017cycielem McGovern Institute for Brain Research.", "token2charspan": [[0, 6], [7, 11], [12, 21], [22, 31], [32, 44], [45, 53], [54, 61], [61, 62], [63, 72], [73, 86], [87, 95], [96, 101], [102, 103], [104, 108], [108, 109], [110, 111], [112, 117], [118, 129], [130, 142], [143, 147], [148, 149], [150, 159], [160, 172], [173, 181], [182, 191], [192, 195], [196, 201], [202, 210], [210, 211]]}
{"doc_key": "ai-train-95", "ner": [[7, 8, "task"], [10, 11, "task"], [16, 17, "task"], [20, 20, "misc"], [21, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 8, 16, 17, "cause-effect", "", false, false], [10, 11, 16, 17, "cause-effect", "", false, false], [21, 22, 16, 17, "topic", "", false, false], [21, 22, 20, 20, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["W", "latach", "90-tych", ",", "zach\u0119cone", "sukcesami", "w", "rozpoznawaniu", "mowy", "i", "syntezie", "mowy", ",", "rozpocz\u0119to", "badania", "nad", "t\u0142umaczeniem", "mowy", ",", "rozwijaj\u0105c", "niemiecki", "projekt", "Verbmobil", "."], "sentence-detokenized": "W latach 90-tych, zach\u0119cone sukcesami w rozpoznawaniu mowy i syntezie mowy, rozpocz\u0119to badania nad t\u0142umaczeniem mowy, rozwijaj\u0105c niemiecki projekt Verbmobil.", "token2charspan": [[0, 1], [2, 8], [9, 16], [16, 17], [18, 27], [28, 37], [38, 39], [40, 53], [54, 58], [59, 60], [61, 69], [70, 74], [74, 75], [76, 86], [87, 94], [95, 98], [99, 111], [112, 116], [116, 117], [118, 128], [129, 138], [139, 146], [147, 156], [156, 157]]}
{"doc_key": "ai-train-96", "ner": [[3, 4, "researcher"], [9, 10, "researcher"], [12, 13, "researcher"], [18, 23, "algorithm"], [24, 24, "algorithm"], [17, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 9, 10, "role", "", false, false], [18, 23, 3, 4, "origin", "", false, false], [18, 23, 9, 10, "origin", "", false, false], [18, 23, 12, 13, "origin", "", false, false], [18, 23, 17, 17, "part-of", "", false, false], [24, 24, 18, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["W", "1999", "roku", "Felix", "Gers", "wraz", "ze", "swoim", "doradc\u0105", "J\u00fcrgenem", "Schmidhuberem", "i", "Fredem", "Cumminsem", "wprowadzili", "do", "architektury", "LSTM", "bramk\u0119", "zapomnienia", "(", "zwan\u0105", "te\u017c", "bramk\u0105", "trzymania", ")", ","], "sentence-detokenized": "W 1999 roku Felix Gers wraz ze swoim doradc\u0105 J\u00fcrgenem Schmidhuberem i Fredem Cumminsem wprowadzili do architektury LSTM bramk\u0119 zapomnienia (zwan\u0105 te\u017c bramk\u0105 trzymania),", "token2charspan": [[0, 1], [2, 6], [7, 11], [12, 17], [18, 22], [23, 27], [28, 30], [31, 36], [37, 44], [45, 53], [54, 67], [68, 69], [70, 76], [77, 86], [87, 98], [99, 101], [102, 114], [115, 119], [120, 126], [127, 138], [139, 140], [140, 145], [146, 149], [150, 156], [157, 166], [166, 167], [167, 168]]}
{"doc_key": "ai-train-97", "ner": [[1, 3, "field"], [5, 6, "field"], [7, 9, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 1, 3, "part-of", "", false, false], [7, 9, 5, 6, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["W", "cyfrowym", "przetwarzaniu", "sygna\u0142\u00f3w", "i", "teorii", "informacji", "znormalizowana", "funkcja", "sinc", "jest", "powszechnie", "definiowana", "przez"], "sentence-detokenized": "W cyfrowym przetwarzaniu sygna\u0142\u00f3w i teorii informacji znormalizowana funkcja sinc jest powszechnie definiowana przez", "token2charspan": [[0, 1], [2, 10], [11, 24], [25, 33], [34, 35], [36, 42], [43, 53], [54, 68], [69, 76], [77, 81], [82, 86], [87, 98], [99, 110], [111, 116]]}
{"doc_key": "ai-train-98", "ner": [[2, 3, "field"], [10, 11, "researcher"], [16, 19, "conference"], [23, 27, "organisation"], [29, 29, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 10, 11, "origin", "coined_term", false, false], [10, 11, 16, 19, "role", "", false, false], [10, 11, 23, 27, "role", "", false, false], [29, 29, 23, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sam", "termin", "lingwistyka", "obliczeniowa", "zosta\u0142", "po", "raz", "pierwszy", "ukuty", "przez", "Davida", "Haysa", ",", "cz\u0142onka", "za\u0142o\u017cyciela", "zar\u00f3wno", "Association", "for", "Computational", "Linguistics", ",", "jak", "i", "International", "Committee", "on", "Computational", "Linguistics", "(", "ICCL", ")", "."], "sentence-detokenized": "Sam termin lingwistyka obliczeniowa zosta\u0142 po raz pierwszy ukuty przez Davida Haysa, cz\u0142onka za\u0142o\u017cyciela zar\u00f3wno Association for Computational Linguistics, jak i International Committee on Computational Linguistics (ICCL).", "token2charspan": [[0, 3], [4, 10], [11, 22], [23, 35], [36, 42], [43, 45], [46, 49], [50, 58], [59, 64], [65, 70], [71, 77], [78, 83], [83, 84], [85, 92], [93, 104], [105, 112], [113, 124], [125, 128], [129, 142], [143, 154], [154, 155], [156, 159], [160, 161], [162, 175], [176, 185], [186, 188], [189, 202], [203, 214], [215, 216], [216, 220], [220, 221], [221, 222]]}
{"doc_key": "ai-train-99", "ner": [[12, 18, "misc"], [13, 13, "misc"], [35, 36, "metrics"], [38, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[38, 38, 35, 36, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["59", ",", "pp", ".", "2547", "-", "2553", ",", "Oct", ".", "2011", "W", "jednowymiarowej", "DPD", "opartej", "na", "wielomianach", "z", "pami\u0119ci\u0105", "(", "lub", "bez", "pami\u0119ci", ")", ",", "w", "celu", "rozwi\u0105zania", "dla", "wsp\u00f3\u0142czynnik\u00f3w", "wielomian\u00f3w", "cyfrowego", "predyktora", "i", "minimalizacji", "b\u0142\u0119du", "\u015bredniokwadratowego", "(", "MSE", ")", ",", "zniekszta\u0142cone", "wyj\u015bcie", "uk\u0142adu", "nieliniowego", "musi", "by\u0107", "nadpr\u00f3bkowane", "z", "szybko\u015bci\u0105", "umo\u017cliwiaj\u0105c\u0105", "uchwycenie", "iloczyn\u00f3w", "nieliniowych", "rz\u0119du", "cyfrowego", "predyktora", "."], "sentence-detokenized": "59, pp. 2547-2553, Oct. 2011 W jednowymiarowej DPD opartej na wielomianach z pami\u0119ci\u0105 (lub bez pami\u0119ci), w celu rozwi\u0105zania dla wsp\u00f3\u0142czynnik\u00f3w wielomian\u00f3w cyfrowego predyktora i minimalizacji b\u0142\u0119du \u015bredniokwadratowego (MSE), zniekszta\u0142cone wyj\u015bcie uk\u0142adu nieliniowego musi by\u0107 nadpr\u00f3bkowane z szybko\u015bci\u0105 umo\u017cliwiaj\u0105c\u0105 uchwycenie iloczyn\u00f3w nieliniowych rz\u0119du cyfrowego predyktora.", "token2charspan": [[0, 2], [2, 3], [4, 6], [6, 7], [8, 12], [12, 13], [13, 17], [17, 18], [19, 22], [22, 23], [24, 28], [29, 30], [31, 46], [47, 50], [51, 58], [59, 61], [62, 74], [75, 76], [77, 85], [86, 87], [87, 90], [91, 94], [95, 102], [102, 103], [103, 104], [105, 106], [107, 111], [112, 123], [124, 127], [128, 142], [143, 154], [155, 164], [165, 175], [176, 177], [178, 191], [192, 197], [198, 217], [218, 219], [219, 222], [222, 223], [223, 224], [225, 239], [240, 247], [248, 254], [255, 267], [268, 272], [273, 276], [277, 290], [291, 292], [293, 303], [304, 317], [318, 328], [329, 338], [339, 351], [352, 357], [358, 367], [368, 378], [378, 379]]}
{"doc_key": "ai-train-100", "ner": [[0, 1, "researcher"], [10, 10, "location"], [13, 13, "location"], [15, 16, "country"], [20, 20, "location"], [22, 22, "country"], [34, 40, "organisation"], [42, 45, "organisation"], [47, 47, "location"], [51, 52, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 1, 10, 10, "physical", "", false, false], [0, 1, 42, 45, "physical", "", false, false], [0, 1, 51, 52, "role", "", false, false], [10, 10, 13, 13, "physical", "", false, false], [13, 13, 15, 16, "physical", "", false, false], [34, 40, 42, 45, "part-of", "", false, false], [42, 45, 47, 47, "physical", "", false, false], [51, 52, 34, 40, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Boris", "Katz", ",", "(", "ur", ".", "5", "pa\u017adziernika", "1947", ",", "Kiszyni\u00f3w", ",", "Mo\u0142dawska", "SRR", ",", "Zwi\u0105zek", "Radziecki", ",", "(", "obecnie", "Kiszyni\u00f3w", ",", "Mo\u0142dawia", ")", ")", "jest", "g\u0142\u00f3wnym", "ameryka\u0144skim", "naukowcem", "badawczym", "(", "informatykiem", ")", "w", "MIT", "Computer", "Science", "and", "Artificial", "Intelligence", "Laboratory", "w", "Massachusetts", "Institute", "of", "Technology", "w", "Cambridge", "i", "szefem", "Laboratory's", "InfoLab", "Group", "."], "sentence-detokenized": "Boris Katz, (ur. 5 pa\u017adziernika 1947, Kiszyni\u00f3w, Mo\u0142dawska SRR, Zwi\u0105zek Radziecki, (obecnie Kiszyni\u00f3w, Mo\u0142dawia)) jest g\u0142\u00f3wnym ameryka\u0144skim naukowcem badawczym (informatykiem) w MIT Computer Science and Artificial Intelligence Laboratory w Massachusetts Institute of Technology w Cambridge i szefem Laboratory's InfoLab Group.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 13], [13, 15], [15, 16], [17, 18], [19, 31], [32, 36], [36, 37], [38, 47], [47, 48], [49, 58], [59, 62], [62, 63], [64, 71], [72, 81], [81, 82], [83, 84], [84, 91], [92, 101], [101, 102], [103, 111], [111, 112], [112, 113], [114, 118], [119, 126], [127, 139], [140, 149], [150, 159], [160, 161], [161, 174], [174, 175], [176, 177], [178, 181], [182, 190], [191, 198], [199, 202], [203, 213], [214, 226], [227, 237], [238, 239], [240, 253], [254, 263], [264, 266], [267, 277], [278, 279], [280, 289], [290, 291], [292, 298], [299, 311], [312, 319], [320, 325], [325, 326]]}
