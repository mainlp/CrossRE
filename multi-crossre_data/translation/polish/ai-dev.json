{"doc_key": "ai-dev-1", "ner": [[1, 1, "metrics"], [4, 5, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 1, 1, "part-of", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Tutaj", "dok\u0142adno\u015b\u0107", "jest", "mierzona", "stop\u0105", "b\u0142\u0119du", ",", "kt\u00f3ra", "jest", "zdefiniowana", "jako", ":"], "sentence-detokenized": "Tutaj dok\u0142adno\u015b\u0107 jest mierzona stop\u0105 b\u0142\u0119du, kt\u00f3ra jest zdefiniowana jako:", "token2charspan": [[0, 5], [6, 16], [17, 21], [22, 30], [31, 36], [37, 42], [42, 43], [44, 49], [50, 54], [55, 67], [68, 72], [72, 73]]}
{"doc_key": "ai-dev-2", "ner": [[3, 3, "algorithm"], [10, 11, "misc"], [18, 20, "algorithm"], [15, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 10, 11, "type-of", "", false, false], [3, 3, 18, 20, "related-to", "", false, false], [3, 3, 15, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Z", "tej", "perspektywy", "SVM", "jest", "\u015bci\u015ble", "zwi\u0105zana", "z", "innymi", "podstawowymi", "algorytmami", "klasyfikacyjnymi", ",", "takimi", "jak", "regresja", "logistyczna", "z", "regularyzacj\u0105", "najmniejszych", "kwadrat\u00f3w", "."], "sentence-detokenized": "Z tej perspektywy SVM jest \u015bci\u015ble zwi\u0105zana z innymi podstawowymi algorytmami klasyfikacyjnymi, takimi jak regresja logistyczna z regularyzacj\u0105 najmniejszych kwadrat\u00f3w.", "token2charspan": [[0, 1], [2, 5], [6, 17], [18, 21], [22, 26], [27, 33], [34, 42], [43, 44], [45, 51], [52, 64], [65, 76], [77, 93], [93, 94], [95, 101], [102, 105], [106, 114], [115, 126], [127, 128], [129, 142], [143, 156], [157, 166], [166, 167]]}
{"doc_key": "ai-dev-3", "ner": [[0, 1, "person"], [3, 4, "person"], [12, 13, "person"], [15, 15, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 0, 1, "named", "actor_plays_character", false, false], [3, 4, 0, 1, "origin", "actor_plays_character", false, false], [15, 15, 12, 13, "named", "actor_plays_character", false, false], [15, 15, 12, 13, "origin", "actor_plays_character", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Brion", "James", "portretuje", "Leona", "Kowalskiego", ",", "replikanta", "bojowego", "i", "robotniczego", ",", "a", "Joanna", "Cassidy", "-", "Zhor\u0119", ",", "replikantk\u0119", "-", "zab\u00f3jczyni\u0119", "."], "sentence-detokenized": "Brion James portretuje Leona Kowalskiego, replikanta bojowego i robotniczego, a Joanna Cassidy - Zhor\u0119, replikantk\u0119-zab\u00f3jczyni\u0119.", "token2charspan": [[0, 5], [6, 11], [12, 22], [23, 28], [29, 40], [40, 41], [42, 52], [53, 61], [62, 63], [64, 76], [76, 77], [78, 79], [80, 86], [87, 94], [95, 96], [97, 102], [102, 103], [104, 115], [115, 116], [116, 127], [127, 128]]}
{"doc_key": "ai-dev-4", "ner": [[17, 20, "product"], [22, 22, "product"], [25, 25, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 20, 25, 25, "physical", "", false, false], [22, 22, 17, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pierwszy", "obraz", ",", "kt\u00f3ry", "zosta\u0142", "zeskanowany", ",", "zapisany", "i", "odtworzony", "w", "cyfrowych", "pikselach", ",", "zosta\u0142", "wy\u015bwietlony", "na", "Standards", "Eastern", "Automatic", "Computer", "(", "SEAC", ")", "w", "NIST", "."], "sentence-detokenized": "Pierwszy obraz, kt\u00f3ry zosta\u0142 zeskanowany, zapisany i odtworzony w cyfrowych pikselach, zosta\u0142 wy\u015bwietlony na Standards Eastern Automatic Computer (SEAC) w NIST.", "token2charspan": [[0, 8], [9, 14], [14, 15], [16, 21], [22, 28], [29, 40], [40, 41], [42, 50], [51, 52], [53, 63], [64, 65], [66, 75], [76, 85], [85, 86], [87, 93], [94, 105], [106, 108], [109, 118], [119, 126], [127, 136], [137, 145], [146, 147], [147, 151], [151, 152], [153, 154], [155, 159], [159, 160]]}
{"doc_key": "ai-dev-5", "ner": [[0, 6, "task"], [19, 20, "task"], [22, 23, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 6, 19, 20, "part-of", "", false, false], [0, 6, 22, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Segmentacja", "tekstu", "na", "tematy", "lub", "zwroty", "dyskursywne", "mo\u017ce", "by\u0107", "przydatna", "w", "niekt\u00f3rych", "zadaniach", "przetwarzania", "naturalnego", ":", "mo\u017ce", "znacznie", "poprawi\u0107", "wyszukiwanie", "informacji", "lub", "rozpoznawanie", "mowy", "(", "poprzez", "dok\u0142adniejsze", "indeksowanie", "/", "rozpoznawanie", "dokument\u00f3w", "lub", "poprzez", "podanie", "w", "wyniku", "konkretnego", "fragmentu", "dokumentu", "odpowiadaj\u0105cego", "zapytaniu", ")", "."], "sentence-detokenized": "Segmentacja tekstu na tematy lub zwroty dyskursywne mo\u017ce by\u0107 przydatna w niekt\u00f3rych zadaniach przetwarzania naturalnego: mo\u017ce znacznie poprawi\u0107 wyszukiwanie informacji lub rozpoznawanie mowy (poprzez dok\u0142adniejsze indeksowanie/rozpoznawanie dokument\u00f3w lub poprzez podanie w wyniku konkretnego fragmentu dokumentu odpowiadaj\u0105cego zapytaniu).", "token2charspan": [[0, 11], [12, 18], [19, 21], [22, 28], [29, 32], [33, 39], [40, 51], [52, 56], [57, 60], [61, 70], [71, 72], [73, 83], [84, 93], [94, 107], [108, 119], [119, 120], [121, 125], [126, 134], [135, 143], [144, 156], [157, 167], [168, 171], [172, 185], [186, 190], [191, 192], [192, 199], [200, 213], [214, 226], [226, 227], [227, 240], [241, 251], [252, 255], [256, 263], [264, 271], [272, 273], [274, 280], [281, 292], [293, 302], [303, 312], [313, 328], [329, 338], [338, 339], [339, 340]]}
{"doc_key": "ai-dev-6", "ner": [[1, 2, "university"], [22, 23, "conference"], [16, 17, "university"], [31, 32, "researcher"], [34, 35, "researcher"], [37, 38, "researcher"], [40, 41, "researcher"], [43, 44, "researcher"], [46, 47, "researcher"], [49, 50, "researcher"], [51, 54, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[22, 23, 16, 17, "physical", "", false, false], [31, 32, 22, 23, "physical", "", false, false], [31, 32, 22, 23, "role", "", false, false], [31, 32, 22, 23, "temporal", "", false, false], [34, 35, 22, 23, "physical", "", false, false], [34, 35, 22, 23, "role", "", false, false], [34, 35, 22, 23, "temporal", "", false, false], [37, 38, 22, 23, "physical", "", false, false], [37, 38, 22, 23, "role", "", false, false], [37, 38, 22, 23, "temporal", "", false, false], [40, 41, 22, 23, "physical", "", false, false], [40, 41, 22, 23, "role", "", false, false], [40, 41, 22, 23, "temporal", "", false, false], [43, 44, 22, 23, "physical", "", false, false], [43, 44, 22, 23, "role", "", false, false], [43, 44, 22, 23, "temporal", "", false, false], [46, 47, 22, 23, "physical", "", false, false], [46, 47, 22, 23, "role", "", false, false], [46, 47, 22, 23, "temporal", "", false, false], [49, 50, 22, 23, "physical", "", false, false], [49, 50, 22, 23, "role", "", false, false], [49, 50, 22, 23, "temporal", "", false, false], [51, 54, 22, 23, "physical", "", false, false], [51, 54, 22, 23, "role", "", false, false], [51, 54, 22, 23, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "sentence": ["Na", "Indiana", "University", "w", "1999", "roku", "zorganizowa\u0142", "takie", "sympozjum", ",", "a", "w", "kwietniu", "2000", "roku", "na", "Stanford", "University", "zorganizowa\u0142", "wi\u0119ksze", "sympozjum", "zatytu\u0142owane", "Spiritual", "Robots", ",", "w", "kt\u00f3rym", "moderowa\u0142", "panel", "z\u0142o\u017cony", "z", "Raya", "Kurzweila", ",", "Hansa", "Moraveca", ",", "Kevina", "Kelly'ego", ",", "Ralpha", "Merkle", ",", "Billa", "Joya", ",", "Franka", "Drake'a", ",", "Johna", "Henry'ego", "Hollanda", "i", "Johna", "Kozy", "."], "sentence-detokenized": "Na Indiana University w 1999 roku zorganizowa\u0142 takie sympozjum, a w kwietniu 2000 roku na Stanford University zorganizowa\u0142 wi\u0119ksze sympozjum zatytu\u0142owane Spiritual Robots, w kt\u00f3rym moderowa\u0142 panel z\u0142o\u017cony z Raya Kurzweila, Hansa Moraveca, Kevina Kelly'ego, Ralpha Merkle, Billa Joya, Franka Drake'a, Johna Henry'ego Hollanda i Johna Kozy.", "token2charspan": [[0, 2], [3, 10], [11, 21], [22, 23], [24, 28], [29, 33], [34, 46], [47, 52], [53, 62], [62, 63], [64, 65], [66, 67], [68, 76], [77, 81], [82, 86], [87, 89], [90, 98], [99, 109], [110, 122], [123, 130], [131, 140], [141, 153], [154, 163], [164, 170], [170, 171], [172, 173], [174, 180], [181, 190], [191, 196], [197, 204], [205, 206], [207, 211], [212, 221], [221, 222], [223, 228], [229, 237], [237, 238], [239, 245], [246, 255], [255, 256], [257, 263], [264, 270], [270, 271], [272, 277], [278, 282], [282, 283], [284, 290], [291, 298], [298, 299], [300, 305], [306, 315], [316, 324], [325, 326], [327, 332], [333, 337], [337, 338]]}
{"doc_key": "ai-dev-7", "ner": [[3, 3, "metrics"], [4, 4, "metrics"], [8, 8, "metrics"], [9, 9, "metrics"], [16, 16, "metrics"], [33, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 3, 16, 16, "named", "", false, false], [4, 4, 3, 3, "named", "", false, false], [8, 8, 33, 33, "named", "", false, false], [9, 9, 8, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Uwzgl\u0119dnia", "on", "zar\u00f3wno", "precyzj\u0119", "p", ",", "jak", "i", "wycofanie", "r", "testu", "w", "celu", "obliczenia", "wyniku", ":", "p", "to", "liczba", "poprawnych", "wynik\u00f3w", "pozytywnych", "podzielona", "przez", "liczb\u0119", "wszystkich", "pozytywnych", "wynik\u00f3w", "zwr\u00f3conych", "przez", "klasyfikator", ",", "a", "r", "to", "liczba", "poprawnych", "wynik\u00f3w", "pozytywnych", "podzielona", "przez", "liczb\u0119", "wszystkich", "istotnych", "pr\u00f3bek", "(", "wszystkie", "pr\u00f3bki", ",", "kt\u00f3re", "powinny", "by\u0107", "zidentyfikowane", "jako", "pozytywne", ")", "."], "sentence-detokenized": "Uwzgl\u0119dnia on zar\u00f3wno precyzj\u0119 p, jak i wycofanie r testu w celu obliczenia wyniku: p to liczba poprawnych wynik\u00f3w pozytywnych podzielona przez liczb\u0119 wszystkich pozytywnych wynik\u00f3w zwr\u00f3conych przez klasyfikator, a r to liczba poprawnych wynik\u00f3w pozytywnych podzielona przez liczb\u0119 wszystkich istotnych pr\u00f3bek (wszystkie pr\u00f3bki, kt\u00f3re powinny by\u0107 zidentyfikowane jako pozytywne).", "token2charspan": [[0, 10], [11, 13], [14, 21], [22, 30], [31, 32], [32, 33], [34, 37], [38, 39], [40, 49], [50, 51], [52, 57], [58, 59], [60, 64], [65, 75], [76, 82], [82, 83], [84, 85], [86, 88], [89, 95], [96, 106], [107, 114], [115, 126], [127, 137], [138, 143], [144, 150], [151, 161], [162, 173], [174, 181], [182, 192], [193, 198], [199, 211], [211, 212], [213, 214], [215, 216], [217, 219], [220, 226], [227, 237], [238, 245], [246, 257], [258, 268], [269, 274], [275, 281], [282, 292], [293, 302], [303, 309], [310, 311], [311, 320], [321, 327], [327, 328], [329, 334], [335, 342], [343, 346], [347, 362], [363, 367], [368, 377], [377, 378], [378, 379]]}
{"doc_key": "ai-dev-8", "ner": [[4, 4, "organisation"], [18, 18, "product"], [26, 27, "person"], [31, 31, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 18, 18, "artifact", "", false, false], [18, 18, 26, 27, "win-defeat", "", false, false], [18, 18, 31, 31, "win-defeat", "", true, false], [26, 27, 31, 31, "win-defeat", "lose", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Od", "czasu", "przej\u0119cia", "przez", "Google", "firma", "zanotowa\u0142a", "wiele", "znacz\u0105cych", "osi\u0105gni\u0119\u0107", ",", "z", "kt\u00f3rych", "najbardziej", "godnym", "uwagi", "jest", "stworzenie", "AlphaGo", ",", "programu", ",", "kt\u00f3ry", "pokona\u0142", "mistrza", "\u015bwiata", "Lee", "Sedola", "w", "skomplikowanej", "grze", "Go", "."], "sentence-detokenized": "Od czasu przej\u0119cia przez Google firma zanotowa\u0142a wiele znacz\u0105cych osi\u0105gni\u0119\u0107, z kt\u00f3rych najbardziej godnym uwagi jest stworzenie AlphaGo, programu, kt\u00f3ry pokona\u0142 mistrza \u015bwiata Lee Sedola w skomplikowanej grze Go.", "token2charspan": [[0, 2], [3, 8], [9, 18], [19, 24], [25, 31], [32, 37], [38, 48], [49, 54], [55, 65], [66, 75], [75, 76], [77, 78], [79, 86], [87, 98], [99, 105], [106, 111], [112, 116], [117, 127], [128, 135], [135, 136], [137, 145], [145, 146], [147, 152], [153, 160], [161, 168], [169, 175], [176, 179], [180, 186], [187, 188], [189, 203], [204, 208], [209, 211], [211, 212]]}
{"doc_key": "ai-dev-9", "ner": [[12, 13, "misc"], [25, 25, "field"], [27, 29, "product"], [45, 45, "misc"], [51, 52, "misc"], [54, 54, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 13, 25, 25, "part-of", "", false, false], [12, 13, 51, 52, "named", "same", false, false], [27, 29, 45, 45, "related-to", "", false, false], [27, 29, 51, 52, "usage", "", false, false], [27, 29, 54, 54, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Reprezentacja", "s\u0142\u00f3w", "z", "uwzgl\u0119dnieniem", "ich", "kontekstu", "poprzez", "wektory", "o", "sta\u0142ym", "rozmiarze", "(", "word", "embeddings", ")", "sta\u0142a", "si\u0119", "jednym", "z", "najbardziej", "podstawowych", "blok\u00f3w", "w", "wielu", "systemach", "NLP", ".", "Beznadzorowy", "system", "dezambiguacji", "wykorzystuje", "podobie\u0144stwo", "pomi\u0119dzy", "sensami", "s\u0142\u00f3w", "w", "ustalonym", "oknie", "kontekstowym", ",", "aby", "wybra\u0107", "najbardziej", "odpowiedni", "sens", "s\u0142owa", "przy", "u\u017cyciu", "wst\u0119pnie", "wytrenowanego", "modelu", "osadzania", "s\u0142\u00f3w", "i", "WordNet", "."], "sentence-detokenized": "Reprezentacja s\u0142\u00f3w z uwzgl\u0119dnieniem ich kontekstu poprzez wektory o sta\u0142ym rozmiarze (word embeddings) sta\u0142a si\u0119 jednym z najbardziej podstawowych blok\u00f3w w wielu systemach NLP. Beznadzorowy system dezambiguacji wykorzystuje podobie\u0144stwo pomi\u0119dzy sensami s\u0142\u00f3w w ustalonym oknie kontekstowym, aby wybra\u0107 najbardziej odpowiedni sens s\u0142owa przy u\u017cyciu wst\u0119pnie wytrenowanego modelu osadzania s\u0142\u00f3w i WordNet.", "token2charspan": [[0, 13], [14, 18], [19, 20], [21, 35], [36, 39], [40, 49], [50, 57], [58, 65], [66, 67], [68, 74], [75, 84], [85, 86], [86, 90], [91, 101], [101, 102], [103, 108], [109, 112], [113, 119], [120, 121], [122, 133], [134, 146], [147, 153], [154, 155], [156, 161], [162, 171], [172, 175], [175, 176], [177, 189], [190, 196], [197, 210], [211, 223], [224, 236], [237, 245], [246, 253], [254, 258], [259, 260], [261, 270], [271, 276], [277, 289], [289, 290], [291, 294], [295, 301], [302, 313], [314, 324], [325, 329], [330, 335], [336, 340], [341, 347], [348, 356], [357, 370], [371, 377], [378, 387], [388, 392], [393, 394], [395, 402], [402, 403]]}
{"doc_key": "ai-dev-10", "ner": [[2, 2, "field"], [6, 6, "field"], [10, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 2, 2, "part-of", "", false, false], [10, 14, 2, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Techniki", "uczenia", "maszynowego", ",", "zar\u00f3wno", "uczenia", "nadzorowanego", ",", "jak", "i", "uczenia", "bez", "nadzoru", ",", "zosta\u0142y", "wykorzystane", "do", "automatycznego", "indukowania", "takich", "regu\u0142", "."], "sentence-detokenized": "Techniki uczenia maszynowego, zar\u00f3wno uczenia nadzorowanego, jak i uczenia bez nadzoru, zosta\u0142y wykorzystane do automatycznego indukowania takich regu\u0142.", "token2charspan": [[0, 8], [9, 16], [17, 28], [28, 29], [30, 37], [38, 45], [46, 59], [59, 60], [61, 64], [65, 66], [67, 74], [75, 78], [79, 86], [86, 87], [88, 95], [96, 108], [109, 111], [112, 126], [127, 138], [139, 145], [146, 151], [151, 152]]}
{"doc_key": "ai-dev-11", "ner": [[3, 3, "researcher"], [5, 6, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["W", "1969", "roku", "Scheinman", "wynalaz\u0142", "rami\u0119", "Stanforda", ","], "sentence-detokenized": "W 1969 roku Scheinman wynalaz\u0142 rami\u0119 Stanforda,", "token2charspan": [[0, 1], [2, 6], [7, 11], [12, 21], [22, 30], [31, 36], [37, 46], [46, 47]]}
{"doc_key": "ai-dev-12", "ner": [[1, 2, "metrics"], [11, 14, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Poniewa\u017c", "strata", "Log", "jest", "r\u00f3\u017cniczkowalna", ",", "do", "optymalizacji", "modelu", "mo\u017cna", "zastosowa\u0107", "metod\u0119", "opart\u0105", "na", "gradiencie", "."], "sentence-detokenized": "Poniewa\u017c strata Log jest r\u00f3\u017cniczkowalna, do optymalizacji modelu mo\u017cna zastosowa\u0107 metod\u0119 opart\u0105 na gradiencie.", "token2charspan": [[0, 8], [9, 15], [16, 19], [20, 24], [25, 39], [39, 40], [41, 43], [44, 57], [58, 64], [65, 70], [71, 81], [82, 88], [89, 95], [96, 98], [99, 109], [109, 110]]}
{"doc_key": "ai-dev-13", "ner": [[1, 2, "field"], [3, 5, "algorithm"], [7, 7, "algorithm"], [10, 12, "algorithm"], [15, 15, "field"], [27, 27, "task"], [29, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 5, 15, 15, "part-of", "", false, false], [7, 7, 3, 5, "named", "", false, false], [10, 12, 3, 5, "named", "", false, false], [15, 15, 1, 2, "part-of", "subfield", false, false], [27, 27, 15, 15, "part-of", "", false, false], [29, 30, 15, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["W", "uczeniu", "maszynowym", "maszyny", "wektor\u00f3w", "podporowych", "(", "SVM", ",", "r\u00f3wnie\u017c", "sieci", "wektor\u00f3w", "podporowych", ")", "s\u0105", "nadzorowanymi", "modelami", "uczenia", "z", "algorytmami", "uczenia", ",", "kt\u00f3re", "analizuj\u0105", "dane", "u\u017cywane", "do", "klasyfikacji", "i", "analizy", "regresji", "."], "sentence-detokenized": "W uczeniu maszynowym maszyny wektor\u00f3w podporowych (SVM, r\u00f3wnie\u017c sieci wektor\u00f3w podporowych) s\u0105 nadzorowanymi modelami uczenia z algorytmami uczenia, kt\u00f3re analizuj\u0105 dane u\u017cywane do klasyfikacji i analizy regresji.", "token2charspan": [[0, 1], [2, 9], [10, 20], [21, 28], [29, 37], [38, 49], [50, 51], [51, 54], [54, 55], [56, 63], [64, 69], [70, 78], [79, 90], [90, 91], [92, 94], [95, 108], [109, 117], [118, 125], [126, 127], [128, 139], [140, 147], [147, 148], [149, 154], [155, 164], [165, 169], [170, 177], [178, 180], [181, 193], [194, 195], [196, 203], [204, 212], [212, 213]]}
{"doc_key": "ai-dev-14", "ner": [[8, 9, "task"], [11, 11, "task"], [28, 28, "metrics"], [30, 30, "metrics"], [32, 32, "researcher"], [34, 34, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 8, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": [",", "(", "2002", ")", "jako", "automatyczna", "metryka", "oceny", "t\u0142umaczenia", "maszynowego", "(", "MT", ")", ",", "wiele", "innych", "metod", "zosta\u0142o", "zaproponowanych", "w", "celu", "jej", "weryfikacji", "lub", "poprawy", ",", "takich", "jak", "TER", ",", "METEOR", ",", "Banerjee", "i", "Lavie", ",", "(", "2005", ")", "itp", "."], "sentence-detokenized": ", (2002) jako automatyczna metryka oceny t\u0142umaczenia maszynowego (MT), wiele innych metod zosta\u0142o zaproponowanych w celu jej weryfikacji lub poprawy, takich jak TER, METEOR, Banerjee i Lavie, (2005) itp.", "token2charspan": [[0, 1], [2, 3], [3, 7], [7, 8], [9, 13], [14, 26], [27, 34], [35, 40], [41, 52], [53, 64], [65, 66], [66, 68], [68, 69], [69, 70], [71, 76], [77, 83], [84, 89], [90, 97], [98, 113], [114, 115], [116, 120], [121, 124], [125, 136], [137, 140], [141, 148], [148, 149], [150, 156], [157, 160], [161, 164], [164, 165], [166, 172], [172, 173], [174, 182], [183, 184], [185, 190], [190, 191], [192, 193], [193, 197], [197, 198], [199, 202], [202, 203]]}
{"doc_key": "ai-dev-15", "ner": [[1, 3, "misc"], [9, 9, "organisation"], [10, 10, "organisation"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 3, 10, 10, "origin", "", false, false], [10, 10, 9, 9, "part-of", "", false, false], [14, 15, 10, 10, "role", "", false, false], [17, 18, 10, 10, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Zawiera", "on", "g\u00f3rn\u0105", "ontologi\u0119", ",", "stworzon\u0105", "przez", "grup\u0119", "robocz\u0105", "IEEE", "P1600.1", "(", "pierwotnie", "przez", "Iana", "Nilesa", "i", "Adama", "Pease'a", ")", "."], "sentence-detokenized": "Zawiera on g\u00f3rn\u0105 ontologi\u0119, stworzon\u0105 przez grup\u0119 robocz\u0105 IEEE P1600.1 (pierwotnie przez Iana Nilesa i Adama Pease'a).", "token2charspan": [[0, 7], [8, 10], [11, 16], [17, 26], [26, 27], [28, 37], [38, 43], [44, 49], [50, 57], [58, 62], [63, 70], [71, 72], [72, 82], [83, 88], [89, 93], [94, 100], [101, 102], [103, 108], [109, 116], [116, 117], [117, 118]]}
{"doc_key": "ai-dev-16", "ner": [[1, 3, "misc"], [32, 34, "algorithm"], [36, 37, "algorithm"], [41, 42, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[32, 34, 1, 3, "part-of", "", true, false], [36, 37, 1, 3, "part-of", "", true, false], [41, 42, 36, 37, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["W", "tomografii", "elektronowej", "Cryo", ",", "gdzie", "ze", "wzgl\u0119du", "na", "ograniczenia", "sprz\u0119towe", "pozyskiwana", "jest", "ograniczona", "liczba", "projekcji", ",", "a", "tak\u017ce", "w", "celu", "unikni\u0119cia", "uszkodze\u0144", "pr\u00f3bek", "biologicznych", ",", "mo\u017ce", "by\u0107", "ona", "stosowana", "wraz", "z", "technikami", "wyczucia", "kompresyjnego", "lub", "funkcjami", "regularyzacji", "(", "np", ".", "strat\u0105", "Hubera", ")", "w", "celu", "poprawy", "rekonstrukcji", "dla", "lepszej", "interpretacji", "."], "sentence-detokenized": "W tomografii elektronowej Cryo, gdzie ze wzgl\u0119du na ograniczenia sprz\u0119towe pozyskiwana jest ograniczona liczba projekcji, a tak\u017ce w celu unikni\u0119cia uszkodze\u0144 pr\u00f3bek biologicznych, mo\u017ce by\u0107 ona stosowana wraz z technikami wyczucia kompresyjnego lub funkcjami regularyzacji (np. strat\u0105 Hubera) w celu poprawy rekonstrukcji dla lepszej interpretacji.", "token2charspan": [[0, 1], [2, 12], [13, 25], [26, 30], [30, 31], [32, 37], [38, 40], [41, 48], [49, 51], [52, 64], [65, 74], [75, 86], [87, 91], [92, 103], [104, 110], [111, 120], [120, 121], [122, 123], [124, 129], [130, 131], [132, 136], [137, 147], [148, 157], [158, 164], [165, 178], [178, 179], [180, 184], [185, 188], [189, 192], [193, 202], [203, 207], [208, 209], [210, 220], [221, 229], [230, 243], [244, 247], [248, 257], [258, 271], [272, 273], [273, 275], [275, 276], [277, 283], [284, 290], [290, 291], [292, 293], [294, 298], [299, 306], [307, 320], [321, 324], [325, 332], [333, 346], [346, 347]]}
{"doc_key": "ai-dev-17", "ner": [[3, 3, "misc"], [5, 5, "programlang"], [9, 9, "algorithm"], [11, 12, "algorithm"], [16, 16, "algorithm"], [17, 24, "product"], [27, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 3, 5, 5, "part-of", "", false, false], [9, 9, 3, 3, "type-of", "", false, false], [11, 12, 3, 3, "type-of", "", false, false], [16, 16, 3, 3, "type-of", "", false, false], [17, 24, 5, 5, "general-affiliation", "", true, false], [17, 24, 5, 5, "part-of", "", true, false], [27, 27, 17, 24, "role", "publishes", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Implementacja", "kilku", "procedur", "wybielania", "w", "R", ",", "w", "tym", "ZCA-whitening", "i", "PCA", "whitening", ",", "ale", "tak\u017ce", "CCA", "whitening", ",", "jest", "dost\u0119pna", "w", "pakiecie", "Whitening", "R", "opublikowanym", "na", "CRAN", "."], "sentence-detokenized": "Implementacja kilku procedur wybielania w R, w tym ZCA-whitening i PCA whitening, ale tak\u017ce CCA whitening, jest dost\u0119pna w pakiecie Whitening R opublikowanym na CRAN.", "token2charspan": [[0, 13], [14, 19], [20, 28], [29, 39], [40, 41], [42, 43], [43, 44], [45, 46], [47, 50], [51, 64], [65, 66], [67, 70], [71, 80], [80, 81], [82, 85], [86, 91], [92, 95], [96, 105], [105, 106], [107, 111], [112, 120], [121, 122], [123, 131], [132, 141], [142, 143], [144, 157], [158, 160], [161, 165], [165, 166]]}
{"doc_key": "ai-dev-18", "ner": [[26, 26, "product"], [28, 28, "product"], [30, 30, "product"], [32, 32, "product"], [34, 34, "product"], [36, 36, "product"], [40, 41, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[26, 26, 30, 30, "compare", "", false, false], [26, 26, 32, 32, "compare", "", false, false], [26, 26, 34, 34, "compare", "", false, false], [26, 26, 36, 36, "compare", "", false, false], [26, 26, 40, 41, "compare", "", false, false], [28, 28, 30, 30, "compare", "", false, false], [28, 28, 32, 32, "compare", "", false, false], [28, 28, 34, 34, "compare", "", false, false], [28, 28, 36, 36, "compare", "", false, false], [28, 28, 40, 41, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Obecnie", "dziedzina", "ta", "sta\u0142a", "si\u0119", "jeszcze", "bardziej", "zniech\u0119caj\u0105ca", "i", "z\u0142o\u017cona", "dzi\u0119ki", "dodaniu", "j\u0119zyk\u00f3w", "i", "oprogramowania", "do", "analizy", "i", "projektowania", "obwod\u00f3w", ",", "system\u00f3w", "i", "sygna\u0142\u00f3w", ",", "od", "MATLAB", "i", "Simulink", "do", "NumPy", ",", "VHDL", ",", "PSpice", ",", "Verilog", ",", "a", "nawet", "j\u0119zyka", "Assembly", "."], "sentence-detokenized": "Obecnie dziedzina ta sta\u0142a si\u0119 jeszcze bardziej zniech\u0119caj\u0105ca i z\u0142o\u017cona dzi\u0119ki dodaniu j\u0119zyk\u00f3w i oprogramowania do analizy i projektowania obwod\u00f3w, system\u00f3w i sygna\u0142\u00f3w, od MATLAB i Simulink do NumPy, VHDL, PSpice, Verilog, a nawet j\u0119zyka Assembly.", "token2charspan": [[0, 7], [8, 17], [18, 20], [21, 26], [27, 30], [31, 38], [39, 47], [48, 61], [62, 63], [64, 71], [72, 78], [79, 86], [87, 94], [95, 96], [97, 111], [112, 114], [115, 122], [123, 124], [125, 138], [139, 146], [146, 147], [148, 156], [157, 158], [159, 167], [167, 168], [169, 171], [172, 178], [179, 180], [181, 189], [190, 192], [193, 198], [198, 199], [200, 204], [204, 205], [206, 212], [212, 213], [214, 221], [221, 222], [223, 224], [225, 230], [231, 237], [238, 246], [246, 247]]}
{"doc_key": "ai-dev-19", "ner": [[4, 5, "person"], [13, 14, "person"], [16, 18, "organisation"], [21, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 18, 13, 14, "origin", "", false, false], [21, 21, 16, 18, "artifact", "builds", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Firma", "zosta\u0142a", "za\u0142o\u017cona", "przez", "Kiichiro", "Toyod\u0119", "w", "1937", "roku", ",", "jako", "spinoff", "od", "Sakichi", "Toyody", "firmy", "Toyota", "Industries", "w", "celu", "stworzenia", "samochod\u00f3w", "."], "sentence-detokenized": "Firma zosta\u0142a za\u0142o\u017cona przez Kiichiro Toyod\u0119 w 1937 roku, jako spinoff od Sakichi Toyody firmy Toyota Industries w celu stworzenia samochod\u00f3w.", "token2charspan": [[0, 5], [6, 13], [14, 22], [23, 28], [29, 37], [38, 44], [45, 46], [47, 51], [52, 56], [56, 57], [58, 62], [63, 70], [71, 73], [74, 81], [82, 88], [89, 94], [95, 101], [102, 112], [113, 114], [115, 119], [120, 130], [131, 141], [141, 142]]}
{"doc_key": "ai-dev-20", "ner": [[0, 2, "field"], [51, 53, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[51, 53, 0, 2, "origin", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Uczenie", "bez", "nadzoru", ",", "z", "drugiej", "strony", ",", "zak\u0142ada", "dane", "szkoleniowe", ",", "kt\u00f3re", "nie", "zosta\u0142y", "r\u0119cznie", "oznakowane", "i", "pr\u00f3buje", "znale\u017a\u0107", "nieod\u0142\u0105czne", "wzorce", "w", "danych", ",", "kt\u00f3re", "mog\u0105", "by\u0107", "wykorzystane", "do", "okre\u015blenia", "prawid\u0142owej", "warto\u015bci", "wyj\u015bciowej", "dla", "nowych", "instancji", "danych", ".", "Kombinacj\u0105", "tych", "dw\u00f3ch", "metod", ",", "kt\u00f3ra", "zosta\u0142a", "ostatnio", "zbadana", ",", "jest", "uczenie", "p\u00f3\u0142nadzorowane", ",", "kt\u00f3re", "wykorzystuje", "kombinacj\u0119", "danych", "oznaczonych", "i", "nieoznaczonych", "(", "zazwyczaj", "ma\u0142y", "zestaw", "oznaczonych", "danych", "po\u0142\u0105czony", "z", "du\u017c\u0105", "ilo\u015bci\u0105", "danych", "nieoznaczonych", ")", "."], "sentence-detokenized": "Uczenie bez nadzoru, z drugiej strony, zak\u0142ada dane szkoleniowe, kt\u00f3re nie zosta\u0142y r\u0119cznie oznakowane i pr\u00f3buje znale\u017a\u0107 nieod\u0142\u0105czne wzorce w danych, kt\u00f3re mog\u0105 by\u0107 wykorzystane do okre\u015blenia prawid\u0142owej warto\u015bci wyj\u015bciowej dla nowych instancji danych. Kombinacj\u0105 tych dw\u00f3ch metod, kt\u00f3ra zosta\u0142a ostatnio zbadana, jest uczenie p\u00f3\u0142nadzorowane, kt\u00f3re wykorzystuje kombinacj\u0119 danych oznaczonych i nieoznaczonych (zazwyczaj ma\u0142y zestaw oznaczonych danych po\u0142\u0105czony z du\u017c\u0105 ilo\u015bci\u0105 danych nieoznaczonych).", "token2charspan": [[0, 7], [8, 11], [12, 19], [19, 20], [21, 22], [23, 30], [31, 37], [37, 38], [39, 46], [47, 51], [52, 63], [63, 64], [65, 70], [71, 74], [75, 82], [83, 90], [91, 101], [102, 103], [104, 111], [112, 119], [120, 131], [132, 138], [139, 140], [141, 147], [147, 148], [149, 154], [155, 159], [160, 163], [164, 176], [177, 179], [180, 190], [191, 202], [203, 211], [212, 222], [223, 226], [227, 233], [234, 243], [244, 250], [250, 251], [252, 262], [263, 267], [268, 273], [274, 279], [279, 280], [281, 286], [287, 294], [295, 303], [304, 311], [311, 312], [313, 317], [318, 325], [326, 340], [340, 341], [342, 347], [348, 360], [361, 371], [372, 378], [379, 390], [391, 392], [393, 407], [408, 409], [409, 418], [419, 423], [424, 430], [431, 442], [443, 449], [450, 459], [460, 461], [462, 466], [467, 474], [475, 481], [482, 496], [496, 497], [497, 498]]}
{"doc_key": "ai-dev-21", "ner": [[22, 22, "organisation"], [20, 21, "product"], [26, 27, "organisation"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[20, 21, 22, 22, "artifact", "", false, false], [26, 27, 24, 24, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pomimo", "tych", "robot\u00f3w", "humanoidalnych", "do", "zastosowa\u0144", "utylitarnych", ",", "istniej\u0105", "pewne", "roboty", "humanoidalne", ",", "kt\u00f3rych", "celem", "jest", "rozrywka", ",", "takie", "jak", "QRIO", "firmy", "Sony", "i", "RoboSapien", "firmy", "Wow", "Wee", "."], "sentence-detokenized": "Pomimo tych robot\u00f3w humanoidalnych do zastosowa\u0144 utylitarnych, istniej\u0105 pewne roboty humanoidalne, kt\u00f3rych celem jest rozrywka, takie jak QRIO firmy Sony i RoboSapien firmy Wow Wee.", "token2charspan": [[0, 6], [7, 11], [12, 19], [20, 34], [35, 37], [38, 48], [49, 61], [61, 62], [63, 71], [72, 77], [78, 84], [85, 97], [97, 98], [99, 106], [107, 112], [113, 117], [118, 126], [126, 127], [128, 133], [134, 137], [138, 142], [143, 148], [149, 153], [154, 155], [156, 166], [167, 172], [173, 176], [177, 180], [180, 181]]}
{"doc_key": "ai-dev-22", "ner": [[0, 0, "researcher"], [8, 14, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 8, 14, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Webber", "zosta\u0142", "w", "1991", "roku", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ","], "sentence-detokenized": "Webber zosta\u0142 w 1991 roku Fellow of the Association for the Advancement of Artificial Intelligence,", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 20], [21, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [98, 99]]}
{"doc_key": "ai-dev-23", "ner": [[6, 6, "field"], [8, 9, "field"], [18, 21, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 21, 6, 6, "part-of", "task_part_of_field", false, false], [18, 21, 8, 9, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["W", "tej", "firmie", "rozwija\u0142", "technologi\u0119", "eksploracji", "danych", "i", "baz", "danych", ",", "a", "dok\u0142adniej", "wysokopoziomowe", "ontologie", "dla", "inteligencji", "i", "automatycznego", "rozumienia", "j\u0119zyka", "naturalnego", "."], "sentence-detokenized": "W tej firmie rozwija\u0142 technologi\u0119 eksploracji danych i baz danych, a dok\u0142adniej wysokopoziomowe ontologie dla inteligencji i automatycznego rozumienia j\u0119zyka naturalnego.", "token2charspan": [[0, 1], [2, 5], [6, 12], [13, 21], [22, 33], [34, 45], [46, 52], [53, 54], [55, 58], [59, 65], [65, 66], [67, 68], [69, 79], [80, 95], [96, 105], [106, 109], [110, 122], [123, 124], [125, 139], [140, 150], [151, 157], [158, 169], [169, 170]]}
{"doc_key": "ai-dev-24", "ner": [[23, 24, "misc"], [26, 29, "misc"], [33, 35, "misc"], [36, 36, "country"], [38, 40, "organisation"], [42, 42, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[23, 24, 36, 36, "physical", "", false, false], [26, 29, 36, 36, "physical", "", false, false], [33, 35, 36, 36, "physical", "", false, false], [38, 40, 42, 42, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["W", "ostatnich", "latach", "mo\u017cna", "jednak", "zaobserwowa\u0107", "pojawianie", "si\u0119", "r\u00f3\u017cnych", "e-", "us\u0142ug", "i", "zwi\u0105zanych", "z", "nimi", "inicjatyw", "w", "krajach", "rozwijaj\u0105cych", "si\u0119", ",", "takich", "jak", "Project", "Nemmadi", ",", "MCA21", "Mission", "Mode", "Project", "czy", "jeszcze", "bardziej", "Digital", "India", "w", "Indiach", ";", "Electronic", "Government", "Directorate", "w", "Pakistanie", ";", "itp", "."], "sentence-detokenized": "W ostatnich latach mo\u017cna jednak zaobserwowa\u0107 pojawianie si\u0119 r\u00f3\u017cnych e-us\u0142ug i zwi\u0105zanych z nimi inicjatyw w krajach rozwijaj\u0105cych si\u0119, takich jak Project Nemmadi, MCA21 Mission Mode Project czy jeszcze bardziej Digital India w Indiach; Electronic Government Directorate w Pakistanie; itp.", "token2charspan": [[0, 1], [2, 11], [12, 18], [19, 24], [25, 31], [32, 44], [45, 55], [56, 59], [60, 67], [68, 70], [70, 75], [76, 77], [78, 88], [89, 90], [91, 95], [96, 105], [106, 107], [108, 115], [116, 129], [130, 133], [133, 134], [135, 141], [142, 145], [146, 153], [154, 161], [161, 162], [163, 168], [169, 176], [177, 181], [182, 189], [190, 193], [194, 201], [202, 210], [211, 218], [219, 224], [225, 226], [227, 234], [234, 235], [236, 246], [247, 257], [258, 269], [270, 271], [272, 282], [282, 283], [284, 287], [287, 288]]}
{"doc_key": "ai-dev-25", "ner": [[0, 0, "misc"], [2, 3, "field"], [5, 5, "field"], [9, 11, "university"], [12, 14, "university"], [20, 22, "university"], [26, 26, "misc"], [28, 28, "field"], [31, 33, "misc"], [35, 36, "university"], [38, 40, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 0, 2, 3, "topic", "", false, false], [0, 0, 5, 5, "topic", "", false, false], [0, 0, 9, 11, "origin", "", false, false], [9, 11, 12, 14, "part-of", "", false, false], [20, 22, 9, 11, "part-of", "", false, false], [26, 26, 28, 28, "topic", "", false, false], [26, 26, 35, 36, "origin", "", false, false], [31, 33, 35, 36, "origin", "", false, false], [35, 36, 38, 40, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Doktorat", "z", "fizyki", "radiowej", "i", "elektroniki", "uzyska\u0142", "w", "kampusie", "Rajabazar", "Science", "College", "Uniwersytetu", "w", "Kalkucie", "w", "1979", "roku", "jako", "student", "Indyjskiego", "Instytutu", "Statystycznego", ",", "a", "kolejny", "doktorat", "z", "elektrotechniki", "wraz", "z", "dyplomem", "Imperial", "College", "z", "Imperial", "College", ",", "University", "of", "London", ",", "w", "1982", "roku", "."], "sentence-detokenized": "Doktorat z fizyki radiowej i elektroniki uzyska\u0142 w kampusie Rajabazar Science College Uniwersytetu w Kalkucie w 1979 roku jako student Indyjskiego Instytutu Statystycznego, a kolejny doktorat z elektrotechniki wraz z dyplomem Imperial College z Imperial College, University of London, w 1982 roku.", "token2charspan": [[0, 8], [9, 10], [11, 17], [18, 26], [27, 28], [29, 40], [41, 48], [49, 50], [51, 59], [60, 69], [70, 77], [78, 85], [86, 98], [99, 100], [101, 109], [110, 111], [112, 116], [117, 121], [122, 126], [127, 134], [135, 146], [147, 156], [157, 171], [171, 172], [173, 174], [175, 182], [183, 191], [192, 193], [194, 209], [210, 214], [215, 216], [217, 225], [226, 234], [235, 242], [243, 244], [245, 253], [254, 261], [261, 262], [263, 273], [274, 276], [277, 283], [283, 284], [285, 286], [287, 291], [292, 296], [296, 297]]}
{"doc_key": "ai-dev-26", "ner": [[0, 1, "location"], [22, 23, "misc"], [30, 31, "misc"], [33, 35, "person"], [37, 38, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[22, 23, 0, 1, "temporal", "", false, false], [30, 31, 0, 1, "temporal", "", false, false], [33, 35, 30, 31, "role", "actor_in", false, false], [37, 38, 30, 31, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Expo", "II", "zosta\u0142o", "og\u0142oszone", "jako", "miejsce", "\u015bwiatowej", "premiery", "kilku", "film\u00f3w", ",", "kt\u00f3rych", "nigdy", "wcze\u015bniej", "nie", "widziano", "w", "3D", ",", "w", "tym", "\"", "Diamentowego", "czarodzieja", "\"", "i", "kr\u00f3tkometra\u017cowego", "filmu", "Universalu", "\"", "Hawajskie", "noce", "z", "Mamie", "Van", "Doren", "i", "Pinky", "Lee", "\"", "."], "sentence-detokenized": "Expo II zosta\u0142o og\u0142oszone jako miejsce \u015bwiatowej premiery kilku film\u00f3w, kt\u00f3rych nigdy wcze\u015bniej nie widziano w 3D, w tym \"Diamentowego czarodzieja\" i kr\u00f3tkometra\u017cowego filmu Universalu \"Hawajskie noce z Mamie Van Doren i Pinky Lee\".", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 25], [26, 30], [31, 38], [39, 48], [49, 57], [58, 63], [64, 70], [70, 71], [72, 79], [80, 85], [86, 95], [96, 99], [100, 108], [109, 110], [111, 113], [113, 114], [115, 116], [117, 120], [121, 122], [122, 134], [135, 146], [146, 147], [148, 149], [150, 167], [168, 173], [174, 184], [185, 186], [186, 195], [196, 200], [201, 202], [203, 208], [209, 212], [213, 218], [219, 220], [221, 226], [227, 230], [230, 231], [231, 232]]}
{"doc_key": "ai-dev-27", "ner": [[6, 8, "researcher"], [14, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 14, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Problem", "maksymalnego", "poduk\u0142adu", "zosta\u0142", "zaproponowany", "przez", "Ulfa", "Grenandera", "w", "1977", "roku", "jako", "uproszczony", "model", "estymacji", "z", "maksymalnym", "prawdopodobie\u0144stwem", "wzorc\u00f3w", "w", "obrazach", "cyfrowych", "."], "sentence-detokenized": "Problem maksymalnego poduk\u0142adu zosta\u0142 zaproponowany przez Ulfa Grenandera w 1977 roku jako uproszczony model estymacji z maksymalnym prawdopodobie\u0144stwem wzorc\u00f3w w obrazach cyfrowych.", "token2charspan": [[0, 7], [8, 20], [21, 30], [31, 37], [38, 51], [52, 57], [58, 62], [63, 73], [74, 75], [76, 80], [81, 85], [86, 90], [91, 102], [103, 108], [109, 118], [119, 120], [121, 132], [133, 152], [153, 160], [161, 162], [163, 171], [172, 181], [181, 182]]}
{"doc_key": "ai-dev-28", "ner": [[0, 1, "product"], [3, 4, "product"], [7, 8, "product"], [11, 11, "product"], [14, 15, "product"], [17, 19, "product"], [33, 33, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[33, 33, 0, 1, "part-of", "", false, false], [33, 33, 3, 4, "part-of", "", false, false], [33, 33, 7, 8, "part-of", "", false, false], [33, 33, 11, 11, "part-of", "", false, false], [33, 33, 14, 15, "part-of", "", false, false], [33, 33, 17, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["iPhone", "4S", ",", "iPad", "3", ",", "iPad", "Mini", "1G", ",", "iPad", "Air", ",", "iPad", "Pro", "1G", ",", "iPod", "Touch", "5G", "i", "nowsze", ",", "wszystkie", "wyposa\u017cone", "s\u0105", "w", "bardziej", "zaawansowanego", "asystenta", "g\u0142osowego", "o", "nazwie", "Siri", "."], "sentence-detokenized": "iPhone 4S, iPad 3, iPad Mini 1G, iPad Air, iPad Pro 1G, iPod Touch 5G i nowsze, wszystkie wyposa\u017cone s\u0105 w bardziej zaawansowanego asystenta g\u0142osowego o nazwie Siri.", "token2charspan": [[0, 6], [7, 9], [9, 10], [11, 15], [16, 17], [17, 18], [19, 23], [24, 28], [29, 31], [31, 32], [33, 37], [38, 41], [41, 42], [43, 47], [48, 51], [52, 54], [54, 55], [56, 60], [61, 66], [67, 69], [70, 71], [72, 78], [78, 79], [80, 89], [90, 100], [101, 103], [104, 105], [106, 114], [115, 129], [130, 139], [140, 149], [150, 151], [152, 158], [159, 163], [163, 164]]}
{"doc_key": "ai-dev-29", "ner": [[5, 5, "metrics"], [7, 10, "metrics"], [13, 13, "metrics"], [42, 43, "metrics"], [48, 51, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 10, 42, 43, "named", "", false, false], [13, 13, 7, 10, "named", "", false, false], [42, 43, 48, 51, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["\u0141atwo", "sprawdzi\u0107", ",", "\u017ce", "strata", "logistyczna", "i", "binarna", "strata", "entropii", "krzy\u017cowej", "(", "strata", "log", ")", "s\u0105", "w", "rzeczywisto\u015bci", "takie", "same", "(", "a\u017c", "do", "sta\u0142ej", "mno\u017cnikowej", "math", "\\", "frac", "{", "1", "}", "{", "log", "(", "2", ")", "}", "/", "math", ")", ".", "Strata", "entropii", "krzy\u017cowej", "jest", "\u015bci\u015ble", "zwi\u0105zana", "z", "dywergencj\u0105", "Kullbacka", "-", "Leiblera", "mi\u0119dzy", "rozk\u0142adem", "empirycznym", "a", "przewidywanym", "rozk\u0142adem", "."], "sentence-detokenized": "\u0141atwo sprawdzi\u0107, \u017ce strata logistyczna i binarna strata entropii krzy\u017cowej (strata log) s\u0105 w rzeczywisto\u015bci takie same (a\u017c do sta\u0142ej mno\u017cnikowej math\\ frac {1} {log (2)} / math) .Strata entropii krzy\u017cowej jest \u015bci\u015ble zwi\u0105zana z dywergencj\u0105 Kullbacka-Leiblera mi\u0119dzy rozk\u0142adem empirycznym a przewidywanym rozk\u0142adem.", "token2charspan": [[0, 5], [6, 15], [15, 16], [17, 19], [20, 26], [27, 38], [39, 40], [41, 48], [49, 55], [56, 64], [65, 74], [75, 76], [76, 82], [83, 86], [86, 87], [88, 90], [91, 92], [93, 107], [108, 113], [114, 118], [119, 120], [120, 122], [123, 125], [126, 132], [133, 144], [145, 149], [149, 150], [151, 155], [156, 157], [157, 158], [158, 159], [160, 161], [161, 164], [165, 166], [166, 167], [167, 168], [168, 169], [170, 171], [172, 176], [176, 177], [178, 179], [179, 185], [186, 194], [195, 204], [205, 209], [210, 216], [217, 225], [226, 227], [228, 239], [240, 249], [249, 250], [250, 258], [259, 265], [266, 275], [276, 287], [288, 289], [290, 303], [304, 313], [313, 314]]}
{"doc_key": "ai-dev-30", "ner": [[0, 1, "algorithm"], [8, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Algorytm", "EM", "s\u0142u\u017cy", "do", "znalezienia", "(", "lokalnego", ")", "maksimum", "prawdopodobie\u0144stwa", "parametr\u00f3w", "modelu", "statystycznego", "w", "przypadkach", ",", "gdy", "nie", "mo\u017cna", "bezpo\u015brednio", "rozwi\u0105za\u0107", "r\u00f3wna\u0144", "."], "sentence-detokenized": "Algorytm EM s\u0142u\u017cy do znalezienia (lokalnego) maksimum prawdopodobie\u0144stwa parametr\u00f3w modelu statystycznego w przypadkach, gdy nie mo\u017cna bezpo\u015brednio rozwi\u0105za\u0107 r\u00f3wna\u0144.", "token2charspan": [[0, 8], [9, 11], [12, 17], [18, 20], [21, 32], [33, 34], [34, 43], [43, 44], [45, 53], [54, 72], [73, 83], [84, 90], [91, 105], [106, 107], [108, 119], [119, 120], [121, 124], [125, 128], [129, 134], [135, 147], [148, 157], [158, 164], [164, 165]]}
{"doc_key": "ai-dev-31", "ner": [[9, 10, "task"], [12, 16, "task"], [20, 20, "task"], [22, 23, "task"], [26, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Badania", "te", "mia\u0142y", "fundamentalne", "znaczenie", "dla", "rozwoju", "nowoczesnych", "technik", "syntezy", "mowy", ",", "maszyn", "do", "czytania", "dla", "niewidomych", ",", "bada\u0144", "nad", "percepcj\u0105", "i", "rozpoznawaniem", "mowy", "oraz", "rozwoju", "motorycznej", "teorii", "percepcji", "mowy", "."], "sentence-detokenized": "Badania te mia\u0142y fundamentalne znaczenie dla rozwoju nowoczesnych technik syntezy mowy, maszyn do czytania dla niewidomych, bada\u0144 nad percepcj\u0105 i rozpoznawaniem mowy oraz rozwoju motorycznej teorii percepcji mowy.", "token2charspan": [[0, 7], [8, 10], [11, 16], [17, 30], [31, 40], [41, 44], [45, 52], [53, 65], [66, 73], [74, 81], [82, 86], [86, 87], [88, 94], [95, 97], [98, 106], [107, 110], [111, 122], [122, 123], [124, 129], [130, 133], [134, 143], [144, 145], [146, 160], [161, 165], [166, 170], [171, 178], [179, 190], [191, 197], [198, 207], [208, 212], [212, 213]]}
{"doc_key": "ai-dev-32", "ner": [[6, 6, "product"], [0, 2, "misc"], [4, 4, "misc"], [8, 9, "misc"], [13, 13, "product"], [15, 15, "product"], [17, 17, "product"], [26, 26, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 6, 6, "origin", "", false, false], [0, 2, 8, 9, "type-of", "", false, false], [0, 2, 13, 13, "related-to", "program_for", false, false], [0, 2, 15, 15, "related-to", "program_for", false, false], [0, 2, 17, 17, "related-to", "program_for", false, false], [0, 2, 26, 26, "related-to", "program_for", false, false], [4, 4, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Zintegrowane", "\u015brodowisko", "programistyczne", "(", "IDE", ")", "Arduino", "to", "wieloplatformowa", "aplikacja", "(", "dla", "system\u00f3w", "Windows", ",", "macOS", "i", "Linux", ")", ",", "kt\u00f3ra", "zosta\u0142a", "napisana", "w", "j\u0119zyku", "programowania", "Java", "."], "sentence-detokenized": "Zintegrowane \u015brodowisko programistyczne (IDE) Arduino to wieloplatformowa aplikacja (dla system\u00f3w Windows, macOS i Linux), kt\u00f3ra zosta\u0142a napisana w j\u0119zyku programowania Java.", "token2charspan": [[0, 12], [13, 23], [24, 39], [40, 41], [41, 44], [44, 45], [46, 53], [54, 56], [57, 73], [74, 83], [84, 85], [85, 88], [89, 97], [98, 105], [105, 106], [107, 112], [113, 114], [115, 120], [120, 121], [121, 122], [123, 128], [129, 136], [137, 145], [146, 147], [148, 154], [155, 168], [169, 173], [173, 174]]}
{"doc_key": "ai-dev-33", "ner": [[2, 4, "algorithm"], [10, 11, "field"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 4, 10, 11, "opposite", "", false, false], [13, 14, 10, 11, "related-to", "works_with", false, false], [16, 17, 10, 11, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Badania", "nad", "sieciami", "neuronowymi", "uleg\u0142y", "stagnacji", "po", "opublikowaniu", "bada\u0144", "nad", "uczeniem", "maszynowym", "przez", "Marvina", "Minsky'ego", "i", "Seymoura", "Paperta", "(", "1969", ")", "."], "sentence-detokenized": "Badania nad sieciami neuronowymi uleg\u0142y stagnacji po opublikowaniu bada\u0144 nad uczeniem maszynowym przez Marvina Minsky'ego i Seymoura Paperta (1969).", "token2charspan": [[0, 7], [8, 11], [12, 20], [21, 32], [33, 39], [40, 49], [50, 52], [53, 66], [67, 72], [73, 76], [77, 85], [86, 96], [97, 102], [103, 110], [111, 121], [122, 123], [124, 132], [133, 140], [141, 142], [142, 146], [146, 147], [147, 148]]}
{"doc_key": "ai-dev-34", "ner": [[18, 19, "organisation"], [21, 21, "organisation"], [23, 25, "country"], [27, 30, "organisation"], [32, 32, "country"], [34, 35, "organisation"], [37, 37, "country"], [39, 39, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[27, 30, 23, 25, "general-affiliation", "", false, false], [34, 35, 32, 32, "general-affiliation", "", false, false], [39, 39, 37, 37, "general-affiliation", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Tylko", "kilku", "firmom", "nie", "japo\u0144skim", "uda\u0142o", "si\u0119", "ostatecznie", "przetrwa\u0107", "na", "tym", "rynku", ",", "g\u0142\u00f3wne", "z", "nich", "to", ":", "Adept", "Technology", ",", "St\u00e4ubli", ",", "szwedzko", "-", "szwajcarska", "firma", "ABB", "Asea", "Brown", "Boveri", ",", "niemiecka", "firma", "KUKA", "Robotics", "oraz", "w\u0142oska", "firma", "Comau", "."], "sentence-detokenized": "Tylko kilku firmom nie japo\u0144skim uda\u0142o si\u0119 ostatecznie przetrwa\u0107 na tym rynku, g\u0142\u00f3wne z nich to: Adept Technology, St\u00e4ubli, szwedzko-szwajcarska firma ABB Asea Brown Boveri, niemiecka firma KUKA Robotics oraz w\u0142oska firma Comau.", "token2charspan": [[0, 5], [6, 11], [12, 18], [19, 22], [23, 32], [33, 38], [39, 42], [43, 54], [55, 64], [65, 67], [68, 71], [72, 77], [77, 78], [79, 85], [86, 87], [88, 92], [93, 95], [95, 96], [97, 102], [103, 113], [113, 114], [115, 122], [122, 123], [124, 132], [132, 133], [133, 144], [145, 150], [151, 154], [155, 159], [160, 165], [166, 172], [172, 173], [174, 183], [184, 189], [190, 194], [195, 203], [204, 208], [209, 215], [216, 221], [222, 227], [227, 228]]}
{"doc_key": "ai-dev-35", "ner": [[9, 10, "conference"], [16, 16, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 16, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["W", "ramach", "dzia\u0142alno\u015bci", "badawczej", "organizowana", "jest", "coroczna", "konferencja", "naukowa", "RuleML", "Symposium", ",", "zwana", "te\u017c", "w", "skr\u00f3cie", "RuleML", "."], "sentence-detokenized": "W ramach dzia\u0142alno\u015bci badawczej organizowana jest coroczna konferencja naukowa RuleML Symposium, zwana te\u017c w skr\u00f3cie RuleML.", "token2charspan": [[0, 1], [2, 8], [9, 21], [22, 31], [32, 44], [45, 49], [50, 58], [59, 70], [71, 78], [79, 85], [86, 95], [95, 96], [97, 102], [103, 106], [107, 108], [109, 116], [117, 123], [123, 124]]}
{"doc_key": "ai-dev-36", "ner": [[9, 9, "field"], [11, 11, "field"], [13, 14, "field"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Koncepcje", "s\u0105", "u\u017cywane", "jako", "formalne", "narz\u0119dzia", "lub", "modele", "w", "matematyce", ",", "informatyce", ",", "bazach", "danych", "i", "sztucznej", "inteligencji", ",", "gdzie", "s\u0105", "czasami", "nazywane", "klasami", ",", "schematami", "lub", "kategoriami", "."], "sentence-detokenized": "Koncepcje s\u0105 u\u017cywane jako formalne narz\u0119dzia lub modele w matematyce, informatyce, bazach danych i sztucznej inteligencji, gdzie s\u0105 czasami nazywane klasami, schematami lub kategoriami.", "token2charspan": [[0, 9], [10, 12], [13, 20], [21, 25], [26, 34], [35, 44], [45, 48], [49, 55], [56, 57], [58, 68], [68, 69], [70, 81], [81, 82], [83, 89], [90, 96], [97, 98], [99, 108], [109, 121], [121, 122], [123, 128], [129, 131], [132, 139], [140, 148], [149, 156], [156, 157], [158, 168], [169, 172], [173, 184], [184, 185]]}
{"doc_key": "ai-dev-37", "ner": [[3, 5, "organisation"], [7, 9, "organisation"], [11, 11, "organisation"], [13, 15, "organisation"], [17, 19, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Jest", "laureatem", "nagr\u00f3d", "Ameryka\u0144skiego", "Stowarzyszenia", "Psychologicznego", ",", "Narodowej", "Akademii", "Nauk", ",", "Royal", ",", "Cognitive", "Neuroscience", "Society", "i", "American", "Humanist", "Association", "."], "sentence-detokenized": "Jest laureatem nagr\u00f3d Ameryka\u0144skiego Stowarzyszenia Psychologicznego, Narodowej Akademii Nauk, Royal, Cognitive Neuroscience Society i American Humanist Association.", "token2charspan": [[0, 4], [5, 14], [15, 21], [22, 36], [37, 51], [52, 68], [68, 69], [70, 79], [80, 88], [89, 93], [93, 94], [95, 100], [100, 101], [102, 111], [112, 124], [125, 132], [133, 134], [135, 143], [144, 152], [153, 164], [164, 165]]}
{"doc_key": "ai-dev-38", "ner": [[3, 4, "person"], [6, 7, "person"], [9, 10, "person"], [17, 20, "person"], [21, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[21, 27, 17, 20, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["W", "rolach", "g\u0142\u00f3wnych", "Harrison", "Ford", ",", "Rutger", "Hauer", "i", "Sean", "Young", ",", "jest", "lu\u017ano", "oparty", "na", "powie\u015bci", "Philipa", "K", ".", "Dicka", "Czy", "androidy", "\u015bni\u0105", "o", "elektrycznych", "owcach", "?", "(", "1968", ")", "."], "sentence-detokenized": "W rolach g\u0142\u00f3wnych Harrison Ford, Rutger Hauer i Sean Young, jest lu\u017ano oparty na powie\u015bci Philipa K. Dicka Czy androidy \u015bni\u0105 o elektrycznych owcach? (1968).", "token2charspan": [[0, 1], [2, 8], [9, 17], [18, 26], [27, 31], [31, 32], [33, 39], [40, 45], [46, 47], [48, 52], [53, 58], [58, 59], [60, 64], [65, 70], [71, 77], [78, 80], [81, 89], [90, 97], [98, 99], [99, 100], [101, 106], [107, 110], [111, 119], [120, 124], [125, 126], [127, 140], [141, 147], [147, 148], [149, 150], [150, 154], [154, 155], [155, 156]]}
{"doc_key": "ai-dev-39", "ner": [[0, 0, "task"], [4, 6, "algorithm"], [12, 13, "field"], [15, 16, "task"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 4, 6, "usage", "", false, false], [0, 0, 12, 13, "part-of", "task_part_of_field", false, false], [0, 0, 15, 16, "part-of", "task_part_of_field", false, false], [0, 0, 18, 19, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Segmentacja", "obraz\u00f3w", "z", "wykorzystaniem", "algorytm\u00f3w", "klastra", "k-\u015brednich", "jest", "od", "dawna", "stosowana", "w", "rozpoznawaniu", "wzorc\u00f3w", ",", "detekcji", "obiekt\u00f3w", "i", "obrazowaniu", "medycznym", "."], "sentence-detokenized": "Segmentacja obraz\u00f3w z wykorzystaniem algorytm\u00f3w klastra k-\u015brednich jest od dawna stosowana w rozpoznawaniu wzorc\u00f3w, detekcji obiekt\u00f3w i obrazowaniu medycznym.", "token2charspan": [[0, 11], [12, 19], [20, 21], [22, 36], [37, 47], [48, 55], [56, 66], [67, 71], [72, 74], [75, 80], [81, 90], [91, 92], [93, 106], [107, 114], [114, 115], [116, 124], [125, 133], [134, 135], [136, 147], [148, 157], [157, 158]]}
{"doc_key": "ai-dev-40", "ner": [[12, 12, "algorithm"], [14, 15, "algorithm"], [18, 18, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Og\u00f3lne", "pr\u00f3bkowanie", "z", "obci\u0119tej", "normalnej", "mo\u017cna", "osi\u0105gn\u0105\u0107", "za", "pomoc\u0105", "przybli\u017ce\u0144", "do", "normalnego", "CDF", "i", "funkcji", "probitowej", ",", "a", "R", "ma", "funkcj\u0119", "codertnorm", "(", ")", "/", "kod", "do", "generowania", "pr\u00f3bek", "obci\u0119tej", "normalnej", "."], "sentence-detokenized": "Og\u00f3lne pr\u00f3bkowanie z obci\u0119tej normalnej mo\u017cna osi\u0105gn\u0105\u0107 za pomoc\u0105 przybli\u017ce\u0144 do normalnego CDF i funkcji probitowej, a R ma funkcj\u0119 codertnorm () / kod do generowania pr\u00f3bek obci\u0119tej normalnej.", "token2charspan": [[0, 6], [7, 18], [19, 20], [21, 29], [30, 39], [40, 45], [46, 54], [55, 57], [58, 64], [65, 75], [76, 78], [79, 89], [90, 93], [94, 95], [96, 103], [104, 114], [114, 115], [116, 117], [118, 119], [120, 122], [123, 130], [131, 141], [142, 143], [143, 144], [145, 146], [147, 150], [151, 153], [154, 165], [166, 172], [173, 181], [182, 191], [191, 192]]}
{"doc_key": "ai-dev-41", "ner": [[5, 7, "university"], [9, 9, "university"], [11, 13, "university"], [16, 18, "university"], [22, 22, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Otrzyma\u0142", "r\u00f3wnie\u017c", "doktoraty", "honoris", "causa", "uniwersytet\u00f3w", "w", "Newcastle", ",", "Surrey", ",", "Tel", "Aviv", "University", ",", ",", "Simon", "Fraser", "University", "i", "University", "of", "Troms\u00f8", "."], "sentence-detokenized": "Otrzyma\u0142 r\u00f3wnie\u017c doktoraty honoris causa uniwersytet\u00f3w w Newcastle, Surrey, Tel Aviv University,, Simon Fraser University i University of Troms\u00f8.", "token2charspan": [[0, 8], [9, 16], [17, 26], [27, 34], [35, 40], [41, 54], [55, 56], [57, 66], [66, 67], [68, 74], [74, 75], [76, 79], [80, 84], [85, 95], [95, 96], [96, 97], [98, 103], [104, 110], [111, 121], [122, 123], [124, 134], [135, 137], [138, 144], [144, 145]]}
{"doc_key": "ai-dev-42", "ner": [[1, 1, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Implementacja", "Java", "wykorzystuj\u0105ca", "indeksy", "tablicowe", "oparte", "na", "zerach", "wraz", "z", "wygodn\u0105", "metod\u0105", "drukowania", "rozwi\u0105zanej", "kolejno\u015bci", "operacji", ":"], "sentence-detokenized": "Implementacja Java wykorzystuj\u0105ca indeksy tablicowe oparte na zerach wraz z wygodn\u0105 metod\u0105 drukowania rozwi\u0105zanej kolejno\u015bci operacji:", "token2charspan": [[0, 13], [14, 18], [19, 33], [34, 41], [42, 51], [52, 58], [59, 61], [62, 68], [69, 73], [74, 75], [76, 83], [84, 90], [91, 101], [102, 113], [114, 124], [125, 133], [133, 134]]}
{"doc_key": "ai-dev-43", "ner": [[7, 8, "metrics"], [11, 13, "metrics"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 13, 7, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Sieci", "takie", "s\u0105", "powszechnie", "trenowane", "w", "re\u017cimie", "entropii", "krzy\u017cowej", "(", "lub", "cross", "-", "entropii", ")", ",", "daj\u0105c", "nieliniowy", "wariant", "wielomianowej", "regresji", "logistycznej", "."], "sentence-detokenized": "Sieci takie s\u0105 powszechnie trenowane w re\u017cimie entropii krzy\u017cowej (lub cross-entropii), daj\u0105c nieliniowy wariant wielomianowej regresji logistycznej.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 26], [27, 36], [37, 38], [39, 46], [47, 55], [56, 65], [66, 67], [67, 70], [71, 76], [76, 77], [77, 85], [85, 86], [86, 87], [88, 93], [94, 104], [105, 112], [113, 126], [127, 135], [136, 148], [148, 149]]}
{"doc_key": "ai-dev-44", "ner": [[0, 0, "conference"], [2, 2, "misc"], [5, 11, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["ACL", "posiada", "europejski", "(", "European", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ")"], "sentence-detokenized": "ACL posiada europejski (European Chapter of the Association for Computational Linguistics)", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 24], [24, 32], [33, 40], [41, 43], [44, 47], [48, 59], [60, 63], [64, 77], [78, 89], [89, 90]]}
{"doc_key": "ai-dev-45", "ner": [[3, 4, "researcher"], [6, 8, "researcher"], [24, 24, "misc"], [26, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 24, 24, "role", "", false, false], [6, 8, 24, 24, "role", "", false, false], [24, 24, 26, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dwaj", "profesorowie", ",", "Hal", "Abelson", "i", "Gerald", "Jay", "Sussman", ",", "postanowili", "zachowa\u0107", "neutralno\u015b\u0107", "-", "ich", "grupa", "przez", "nast\u0119pne", "30", "lat", "by\u0142a", "okre\u015blana", "r\u00f3\u017cnie", "jako", "Szwajcaria", "i", "Projekt", "MAC", "."], "sentence-detokenized": "Dwaj profesorowie, Hal Abelson i Gerald Jay Sussman, postanowili zachowa\u0107 neutralno\u015b\u0107 - ich grupa przez nast\u0119pne 30 lat by\u0142a okre\u015blana r\u00f3\u017cnie jako Szwajcaria i Projekt MAC.", "token2charspan": [[0, 4], [5, 17], [17, 18], [19, 22], [23, 30], [31, 32], [33, 39], [40, 43], [44, 51], [51, 52], [53, 64], [65, 73], [74, 85], [86, 87], [88, 91], [92, 97], [98, 103], [104, 112], [113, 115], [116, 119], [120, 124], [125, 134], [135, 141], [142, 146], [147, 157], [158, 159], [160, 167], [168, 171], [171, 172]]}
{"doc_key": "ai-dev-46", "ner": [[2, 2, "misc"], [3, 3, "researcher"], [7, 10, "university"], [14, 14, "organisation"], [18, 20, "organisation"], [24, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 3, 3, "temporal", "", false, false], [3, 3, 14, 14, "physical", "", false, false], [3, 3, 14, 14, "role", "", false, false], [3, 3, 18, 20, "role", "", false, false], [18, 20, 7, 10, "part-of", "", false, false], [24, 25, 18, 20, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Po", "uzyskaniu", "doktoratu", "Ghahramani", "przeni\u00f3s\u0142", "si\u0119", "na", "Uniwersytet", "w", "Toronto", "w", "1995", "roku", "jako", "ITRC", "Postdoctoral", "Fellow", "w", "Artificial", "Intelligence", "Lab", ",", "pracuj\u0105c", "z", "Geoffreyem", "Hintonem", "."], "sentence-detokenized": "Po uzyskaniu doktoratu Ghahramani przeni\u00f3s\u0142 si\u0119 na Uniwersytet w Toronto w 1995 roku jako ITRC Postdoctoral Fellow w Artificial Intelligence Lab, pracuj\u0105c z Geoffreyem Hintonem.", "token2charspan": [[0, 2], [3, 12], [13, 22], [23, 33], [34, 43], [44, 47], [48, 50], [51, 62], [63, 64], [65, 72], [73, 74], [75, 79], [80, 84], [85, 89], [90, 94], [95, 107], [108, 114], [115, 116], [117, 127], [128, 140], [141, 144], [144, 145], [146, 154], [155, 156], [157, 167], [168, 176], [176, 177]]}
{"doc_key": "ai-dev-47", "ner": [[19, 20, "metrics"], [22, 22, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[22, 22, 19, 20, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Kolejne", "prace", "koncentrowa\u0142y", "si\u0119", "na", "rozwi\u0105zaniu", "tych", "problem\u00f3w", ",", "ale", "dopiero", "pojawienie", "si\u0119", "nowoczesnego", "komputera", "i", "popularyzacja", "technik", "parametryzacji", "Maximum", "Likelihood", "(", "MLE", ")", "spowodowa\u0142y", "prawdziwy", "rozkwit", "bada\u0144", "."], "sentence-detokenized": "Kolejne prace koncentrowa\u0142y si\u0119 na rozwi\u0105zaniu tych problem\u00f3w, ale dopiero pojawienie si\u0119 nowoczesnego komputera i popularyzacja technik parametryzacji Maximum Likelihood (MLE) spowodowa\u0142y prawdziwy rozkwit bada\u0144.", "token2charspan": [[0, 7], [8, 13], [14, 27], [28, 31], [32, 34], [35, 46], [47, 51], [52, 61], [61, 62], [63, 66], [67, 74], [75, 85], [86, 89], [90, 102], [103, 112], [113, 114], [115, 128], [129, 136], [137, 151], [152, 159], [160, 170], [171, 172], [172, 175], [175, 176], [177, 188], [189, 198], [199, 206], [207, 212], [212, 213]]}
{"doc_key": "ai-dev-48", "ner": [[2, 3, "person"], [10, 11, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Serial", "wyprodukowa\u0142", "David", "Fincher", ",", "a", "w", "roli", "g\u0142\u00f3wnej", "wyst\u0105pi\u0142", "Kevin", "Spacey", "."], "sentence-detokenized": "Serial wyprodukowa\u0142 David Fincher, a w roli g\u0142\u00f3wnej wyst\u0105pi\u0142 Kevin Spacey.", "token2charspan": [[0, 6], [7, 19], [20, 25], [26, 33], [33, 34], [35, 36], [37, 38], [39, 43], [44, 51], [52, 60], [61, 66], [67, 73], [73, 74]]}
{"doc_key": "ai-dev-49", "ner": [[15, 15, "metrics"], [22, 23, "algorithm"], [27, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 23, 27, 29, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Z", "powodu", "ograniczonej", "mocy", "obliczeniowej", ",", "obecne", "metody", "in", "silico", "musz\u0105", "zwykle", "przehandlowa\u0107", "szybko\u015b\u0107", "za", "dok\u0142adno\u015b\u0107", ";", "np", ".", "stosowa\u0107", "szybkie", "metody", "dokowania", "bia\u0142ek", "zamiast", "kosztownych", "obliczeniowo", "oblicze\u0144", "energii", "swobodnej", "."], "sentence-detokenized": "Z powodu ograniczonej mocy obliczeniowej, obecne metody in silico musz\u0105 zwykle przehandlowa\u0107 szybko\u015b\u0107 za dok\u0142adno\u015b\u0107; np. stosowa\u0107 szybkie metody dokowania bia\u0142ek zamiast kosztownych obliczeniowo oblicze\u0144 energii swobodnej.", "token2charspan": [[0, 1], [2, 8], [9, 21], [22, 26], [27, 40], [40, 41], [42, 48], [49, 55], [56, 58], [59, 65], [66, 71], [72, 78], [79, 92], [93, 101], [102, 104], [105, 115], [115, 116], [117, 119], [119, 120], [121, 129], [130, 137], [138, 144], [145, 154], [155, 161], [162, 169], [170, 181], [182, 194], [195, 203], [204, 211], [212, 221], [221, 222]]}
{"doc_key": "ai-dev-50", "ner": [[5, 5, "country"], [7, 7, "country"], [0, 9, "country"], [11, 11, "country"], [13, 13, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Mia\u0142a", "ponad", "30", "lokalizacji", "w", "USA", ",", "Kanadzie", ",", "Meksyku", ",", "Brazylii", "i", "Argentynie", "."], "sentence-detokenized": "Mia\u0142a ponad 30 lokalizacji w USA , Kanadzie, Meksyku, Brazylii i Argentynie.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 26], [27, 28], [29, 32], [33, 34], [35, 43], [43, 44], [45, 52], [52, 53], [54, 62], [63, 64], [65, 75], [75, 76]]}
{"doc_key": "ai-dev-51", "ner": [[5, 7, "product"], [10, 12, "algorithm"], [16, 17, "task"], [20, 21, "task"], [27, 27, "product"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[5, 7, 10, 12, "usage", "", false, false], [16, 17, 27, 27, "related-to", "performs", false, false], [20, 21, 27, 27, "related-to", "performs", false, false]], "relations_mapping_to_source": [1, 3, 5], "sentence": ["Przyk\u0142ad", "typowego", "potoku", "obliczeniowego", "dla", "systemu", "rozpoznawania", "twarzy", "z", "wykorzystaniem", "k", "-", "NN", ",", "obejmuj\u0105cego", "etapy", "ekstrakcji", "cech", "i", "wst\u0119pnej", "redukcji", "wymiar\u00f3w", "(", "zwykle", "implementowane", "za", "pomoc\u0105", "OpenCV", ")", ":"], "sentence-detokenized": "Przyk\u0142ad typowego potoku obliczeniowego dla systemu rozpoznawania twarzy z wykorzystaniem k -NN, obejmuj\u0105cego etapy ekstrakcji cech i wst\u0119pnej redukcji wymiar\u00f3w (zwykle implementowane za pomoc\u0105 OpenCV):", "token2charspan": [[0, 8], [9, 17], [18, 24], [25, 39], [40, 43], [44, 51], [52, 65], [66, 72], [73, 74], [75, 89], [90, 91], [92, 93], [93, 95], [95, 96], [97, 109], [110, 115], [116, 126], [127, 131], [132, 133], [134, 142], [143, 151], [152, 160], [161, 162], [162, 168], [169, 183], [184, 186], [187, 193], [194, 200], [200, 201], [201, 202]]}
{"doc_key": "ai-dev-52", "ner": [[7, 10, "algorithm"], [12, 12, "misc"], [14, 15, "misc"], [17, 17, "misc"], [21, 21, "programlang"], [23, 23, "product"], [27, 28, "algorithm"], [30, 31, "misc"], [33, 33, "misc"], [35, 35, "misc"], [37, 37, "misc"], [44, 44, "misc"], [46, 46, "misc"], [48, 49, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [], "relations_mapping_to_source": [], "sentence": ["Posiada", "bogaty", "zestaw", "funkcji", ",", "biblioteki", "do", "programowania", "w", "logice", "ogranicze\u0144", ",", "wielow\u0105tkowo\u015b\u0107", ",", "testy", "jednostkowe", ",", "GUI", ",", "interfejsy", "do", "Javy", ",", "ODBC", "i", "innych", ",", "programowanie", "literackie", ",", "serwer", "WWW", ",", "SGML", ",", "RDF", ",", "RDFS", ",", "narz\u0119dzia", "deweloperskie", "(", "w", "tym", "IDE", "z", "debuggerem", "i", "profilerem", "GUI", ")", "oraz", "obszern\u0105", "dokumentacj\u0119", "."], "sentence-detokenized": "Posiada bogaty zestaw funkcji, biblioteki do programowania w logice ogranicze\u0144, wielow\u0105tkowo\u015b\u0107, testy jednostkowe, GUI, interfejsy do Javy, ODBC i innych, programowanie literackie, serwer WWW, SGML, RDF, RDFS, narz\u0119dzia deweloperskie (w tym IDE z debuggerem i profilerem GUI) oraz obszern\u0105 dokumentacj\u0119.", "token2charspan": [[0, 7], [8, 14], [15, 21], [22, 29], [29, 30], [31, 41], [42, 44], [45, 58], [59, 60], [61, 67], [68, 78], [78, 79], [80, 94], [94, 95], [96, 101], [102, 113], [113, 114], [115, 118], [118, 119], [120, 130], [131, 133], [134, 138], [138, 139], [140, 144], [145, 146], [147, 153], [153, 154], [155, 168], [169, 179], [179, 180], [181, 187], [188, 191], [191, 192], [193, 197], [197, 198], [199, 202], [202, 203], [204, 208], [208, 209], [210, 219], [220, 233], [234, 235], [235, 236], [237, 240], [241, 244], [245, 246], [247, 257], [258, 259], [260, 270], [271, 274], [274, 275], [276, 280], [281, 289], [290, 302], [302, 303]]}
{"doc_key": "ai-dev-53", "ner": [[1, 2, "field"], [4, 4, "field"], [7, 9, "misc"], [11, 13, "misc"], [16, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 9, 1, 2, "part-of", "", true, false], [7, 9, 4, 4, "part-of", "", false, false], [7, 9, 16, 18, "type-of", "", false, false], [11, 13, 1, 2, "part-of", "", false, false], [11, 13, 4, 4, "part-of", "", false, false], [11, 13, 16, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["W", "wizji", "komputerowej", "i", "przetwarzaniu", "obraz\u00f3w", "poj\u0119cie", "reprezentacji", "przestrzeni", "skalowej", "i", "operator\u00f3w", "pochodnych", "gaussowskich", "jest", "jako", "kanoniczna", "reprezentacja", "wieloskalowa", "."], "sentence-detokenized": "W wizji komputerowej i przetwarzaniu obraz\u00f3w poj\u0119cie reprezentacji przestrzeni skalowej i operator\u00f3w pochodnych gaussowskich jest jako kanoniczna reprezentacja wieloskalowa.", "token2charspan": [[0, 1], [2, 7], [8, 20], [21, 22], [23, 36], [37, 44], [45, 52], [53, 66], [67, 78], [79, 87], [88, 89], [90, 100], [101, 111], [112, 124], [125, 129], [130, 134], [135, 145], [146, 159], [160, 172], [172, 173]]}
{"doc_key": "ai-dev-54", "ner": [[3, 7, "organisation"], [16, 22, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 7, 16, 22, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Jest", "r\u00f3wnie\u017c", "prezesem", "Neural", "Information", "Processing", "Systems", "Foundation", ",", "organizacji", "non-", "profit", ",", "kt\u00f3ra", "nadzoruje", "coroczn\u0105", "konferencj\u0119", "Conference", "on", "Neural", "Information", "Processing", "Systems", "."], "sentence-detokenized": "Jest r\u00f3wnie\u017c prezesem Neural Information Processing Systems Foundation, organizacji non-profit, kt\u00f3ra nadzoruje coroczn\u0105 konferencj\u0119 Conference on Neural Information Processing Systems.", "token2charspan": [[0, 4], [5, 12], [13, 21], [22, 28], [29, 40], [41, 51], [52, 59], [60, 70], [70, 71], [72, 83], [84, 88], [88, 94], [94, 95], [96, 101], [102, 111], [112, 120], [121, 132], [133, 143], [144, 146], [147, 153], [154, 165], [166, 176], [177, 184], [184, 185]]}
{"doc_key": "ai-dev-55", "ner": [[2, 3, "task"], [10, 11, "metrics"], [5, 6, "misc"], [14, 14, "task"], [15, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 10, 11, "usage", "", false, false], [10, 11, 5, 6, "type-of", "", false, false], [14, 14, 15, 16, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dla", "problem\u00f3w", "analizy", "regresji", "jako", "funkcja", "straty", "mo\u017ce", "by\u0107", "u\u017cyty", "b\u0142\u0105d", "kwadratowy", ",", "dla", "klasyfikacji", "entropia", "krzy\u017cowa", "."], "sentence-detokenized": "Dla problem\u00f3w analizy regresji jako funkcja straty mo\u017ce by\u0107 u\u017cyty b\u0142\u0105d kwadratowy, dla klasyfikacji entropia krzy\u017cowa.", "token2charspan": [[0, 3], [4, 13], [14, 21], [22, 30], [31, 35], [36, 43], [44, 50], [51, 55], [56, 59], [60, 65], [66, 70], [71, 81], [81, 82], [83, 86], [87, 99], [100, 108], [109, 117], [117, 118]]}
{"doc_key": "ai-dev-56", "ner": [[0, 1, "researcher"], [18, 20, "conference"], [22, 27, "conference"], [36, 38, "university"], [39, 40, "field"], [46, 50, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 18, 20, "role", "", false, false], [0, 1, 36, 38, "physical", "", false, false], [0, 1, 36, 38, "role", "", false, false], [0, 1, 46, 50, "role", "", false, false], [18, 20, 22, 27, "named", "same", false, false], [36, 38, 39, 40, "related-to", "subject_of_study_at", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Lafferty", "pe\u0142ni\u0142", "wiele", "presti\u017cowych", "funkcji", ",", "w", "tym", ":", "1", ")", "wsp\u00f3\u0142przewodnicz\u0105cego", "programowego", "i", "og\u00f3lnego", "konferencji", "Fundacji", "Neural", "Information", "Processing", "Systems", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", ")", ";", "2", ")", "wsp\u00f3\u0142dyrektora", "nowego", "programu", "doktoranckiego", "CMU", "w", "zakresie", "uczenia", "maszynowego", ";", "3", ")", "redaktora", "stowarzyszonego", "Journal", "of", "Machine", "Learning", "Research"], "sentence-detokenized": "Lafferty pe\u0142ni\u0142 wiele presti\u017cowych funkcji, w tym: 1) wsp\u00f3\u0142przewodnicz\u0105cego programowego i og\u00f3lnego konferencji Fundacji Neural Information Processing Systems (Conference on Neural Information Processing Systems); 2) wsp\u00f3\u0142dyrektora nowego programu doktoranckiego CMU w zakresie uczenia maszynowego; 3) redaktora stowarzyszonego Journal of Machine Learning Research", "token2charspan": [[0, 8], [9, 15], [16, 21], [22, 34], [35, 42], [42, 43], [44, 45], [46, 49], [49, 50], [51, 52], [52, 53], [54, 75], [76, 88], [89, 90], [91, 99], [100, 111], [112, 120], [121, 127], [128, 139], [140, 150], [151, 158], [159, 160], [160, 170], [171, 173], [174, 180], [181, 192], [193, 203], [204, 211], [211, 212], [212, 213], [214, 215], [215, 216], [217, 231], [232, 238], [239, 247], [248, 262], [263, 266], [267, 268], [269, 277], [278, 285], [286, 297], [297, 298], [299, 300], [300, 301], [302, 311], [312, 327], [328, 335], [336, 338], [339, 346], [347, 355], [356, 364]]}
{"doc_key": "ai-dev-57", "ner": [[0, 1, "misc"], [5, 5, "algorithm"], [7, 7, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 0, 1, "type-of", "", false, false], [7, 7, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Algorytmy", "wypuk\u0142e", ",", "takie", "jak", "AdaBoost", "i", "LogitBoost", ",", "mog\u0105", "zosta\u0107", "pokonane", "przez", "losowy", "szum", ",", "przez", "co", "nie", "s\u0105", "w", "stanie", "nauczy\u0107", "si\u0119", "podstawowych", "i", "mo\u017cliwych", "do", "nauczenia", "si\u0119", "kombinacji", "s\u0142abych", "hipotez", "."], "sentence-detokenized": "Algorytmy wypuk\u0142e, takie jak AdaBoost i LogitBoost, mog\u0105 zosta\u0107 pokonane przez losowy szum, przez co nie s\u0105 w stanie nauczy\u0107 si\u0119 podstawowych i mo\u017cliwych do nauczenia si\u0119 kombinacji s\u0142abych hipotez.", "token2charspan": [[0, 9], [10, 17], [17, 18], [19, 24], [25, 28], [29, 37], [38, 39], [40, 50], [50, 51], [52, 56], [57, 63], [64, 72], [73, 78], [79, 85], [86, 90], [90, 91], [92, 97], [98, 100], [101, 104], [105, 107], [108, 109], [110, 116], [117, 124], [125, 128], [129, 141], [142, 143], [144, 153], [154, 156], [157, 166], [167, 170], [171, 181], [182, 189], [190, 197], [197, 198]]}
{"doc_key": "ai-dev-58", "ner": [[0, 0, "product"], [2, 5, "product"], [9, 11, "algorithm"], [17, 19, "algorithm"], [21, 23, "task"], [25, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 2, 5, "type-of", "", false, false], [0, 0, 9, 11, "usage", "", false, false], [0, 0, 17, 19, "usage", "", false, false], [17, 19, 21, 23, "related-to", "used_for", true, false], [17, 19, 25, 26, "related-to", "used_for", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Apertium", "jest", "systemem", "p\u0142ytkiego", "t\u0142umaczenia", "maszynowego", ",", "kt\u00f3ry", "wykorzystuje", "transduktory", "sko\u0144czonych", "stan\u00f3w", "do", "wszystkich", "transformacji", "leksykalnych", "oraz", "ukryte", "modele", "Markowa", "do", "oznaczania", "cz\u0119\u015bci", "mowy", "i", "rozr\u00f3\u017cniania", "kategorii", "s\u0142\u00f3w", "."], "sentence-detokenized": "Apertium jest systemem p\u0142ytkiego t\u0142umaczenia maszynowego, kt\u00f3ry wykorzystuje transduktory sko\u0144czonych stan\u00f3w do wszystkich transformacji leksykalnych oraz ukryte modele Markowa do oznaczania cz\u0119\u015bci mowy i rozr\u00f3\u017cniania kategorii s\u0142\u00f3w.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 32], [33, 44], [45, 56], [56, 57], [58, 63], [64, 76], [77, 89], [90, 101], [102, 108], [109, 111], [112, 122], [123, 136], [137, 149], [150, 154], [155, 161], [162, 168], [169, 176], [177, 179], [180, 190], [191, 197], [198, 202], [203, 204], [205, 217], [218, 227], [228, 232], [232, 233]]}
{"doc_key": "ai-dev-59", "ner": [[0, 1, "misc"], [12, 14, "metrics"], [24, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 12, 14, "related-to", "", true, false], [12, 14, 24, 25, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Naturalny", "gradient", "mathE", "f", "(", "x", ")", "/", "math", ",", "zgodny", "z", "metryk\u0105", "informacyjn\u0105", "Fishera", "(", "informacyjna", "miara", "odleg\u0142o\u015bci", "mi\u0119dzy", "rozk\u0142adami", "prawdopodobie\u0144stwa", "i", "krzywizna", "entropii", "wzgl\u0119dnej", ")", ",", "ma", "teraz", "posta\u0107"], "sentence-detokenized": "Naturalny gradient mathE f (x) / math, zgodny z metryk\u0105 informacyjn\u0105 Fishera (informacyjna miara odleg\u0142o\u015bci mi\u0119dzy rozk\u0142adami prawdopodobie\u0144stwa i krzywizna entropii wzgl\u0119dnej), ma teraz posta\u0107", "token2charspan": [[0, 9], [10, 18], [19, 24], [25, 26], [27, 28], [28, 29], [29, 30], [31, 32], [33, 37], [37, 38], [39, 45], [46, 47], [48, 55], [56, 68], [69, 76], [77, 78], [78, 90], [91, 96], [97, 107], [108, 114], [115, 125], [126, 144], [145, 146], [147, 156], [157, 165], [166, 175], [175, 176], [176, 177], [178, 180], [181, 186], [187, 193]]}
{"doc_key": "ai-dev-60", "ner": [[0, 3, "programlang"], [7, 11, "product"], [13, 13, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 11, 0, 3, "origin", "", false, false], [13, 13, 0, 3, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["J\u0119zyk", "programowania", "S", "stanowi\u0142", "inspiracj\u0119", "dla", "system\u00f3w", "'", "S", "'", "-", "PLUS", "i", "R", "."], "sentence-detokenized": "J\u0119zyk programowania S stanowi\u0142 inspiracj\u0119 dla system\u00f3w' S '-PLUS i R.", "token2charspan": [[0, 5], [6, 19], [20, 21], [22, 30], [31, 41], [42, 45], [46, 54], [54, 55], [56, 57], [58, 59], [59, 60], [60, 64], [65, 66], [67, 68], [68, 69]]}
{"doc_key": "ai-dev-61", "ner": [[3, 3, "product"], [6, 6, "product"], [9, 9, "product"], [13, 15, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 3, 6, 6, "named", "same", false, false], [9, 9, 6, 6, "origin", "derived_from", false, false], [9, 9, 13, 15, "origin", "", false, false], [9, 9, 17, 18, "origin", "", false, false], [9, 9, 20, 21, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Najbardziej", "wp\u0142ywow\u0105", "implementacj\u0105", "Planera", "by\u0142", "podzbi\u00f3r", "Planera", ",", "zwany", "Micro-Planner", ",", "wdro\u017cony", "przez", "Geralda", "Jay", "Sussmana", ",", "Eugene'a", "Charniaka", "i", "Terry'ego", "Winograda", "."], "sentence-detokenized": "Najbardziej wp\u0142ywow\u0105 implementacj\u0105 Planera by\u0142 podzbi\u00f3r Planera, zwany Micro-Planner, wdro\u017cony przez Geralda Jay Sussmana, Eugene'a Charniaka i Terry'ego Winograda.", "token2charspan": [[0, 11], [12, 20], [21, 34], [35, 42], [43, 46], [47, 55], [56, 63], [63, 64], [65, 70], [71, 84], [84, 85], [86, 94], [95, 100], [101, 108], [109, 112], [113, 121], [121, 122], [123, 131], [132, 141], [142, 143], [144, 153], [154, 163], [163, 164]]}
{"doc_key": "ai-dev-62", "ner": [[4, 6, "country"], [8, 10, "researcher"], [18, 18, "misc"], [19, 23, "university"], [30, 31, "misc"], [38, 38, "misc"], [42, 44, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "relations": [[8, 10, 4, 6, "general-affiliation", "from_country", false, false], [19, 23, 18, 18, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["W", "1779", "r", ".", "niemiecko", "-", "du\u0144ski", "uczony", "Christian", "Gottlieb", "Kratzenstein", "zdoby\u0142", "pierwsz\u0105", "nagrod\u0119", "w", "konkursie", "og\u0142oszonym", "przez", "Rosyjsk\u0105", "Cesarsk\u0105", "Akademi\u0119", "Nauk", "i", "Sztuk", "za", "zbudowane", "przez", "siebie", "modele", "ludzkiego", "traktu", "g\u0142osowego", ",", "kt\u00f3re", "potrafi\u0142y", "wydoby\u0107", "pi\u0119\u0107", "d\u0142ugich", "samog\u0142osek", "(", "w", "zapisie", "Mi\u0119dzynarodowego", "Alfabetu", "Fonetycznego", ":"], "sentence-detokenized": "W 1779 r. niemiecko-du\u0144ski uczony Christian Gottlieb Kratzenstein zdoby\u0142 pierwsz\u0105 nagrod\u0119 w konkursie og\u0142oszonym przez Rosyjsk\u0105 Cesarsk\u0105 Akademi\u0119 Nauk i Sztuk za zbudowane przez siebie modele ludzkiego traktu g\u0142osowego, kt\u00f3re potrafi\u0142y wydoby\u0107 pi\u0119\u0107 d\u0142ugich samog\u0142osek (w zapisie Mi\u0119dzynarodowego Alfabetu Fonetycznego:", "token2charspan": [[0, 1], [2, 6], [7, 8], [8, 9], [10, 19], [19, 20], [20, 26], [27, 33], [34, 43], [44, 52], [53, 65], [66, 72], [73, 81], [82, 89], [90, 91], [92, 101], [102, 112], [113, 118], [119, 127], [128, 136], [137, 145], [146, 150], [151, 152], [153, 158], [159, 161], [162, 171], [172, 177], [178, 184], [185, 191], [192, 201], [202, 208], [209, 218], [218, 219], [220, 225], [226, 235], [236, 243], [244, 248], [249, 256], [257, 267], [268, 269], [269, 270], [271, 278], [279, 295], [296, 304], [305, 317], [317, 318]]}
{"doc_key": "ai-dev-63", "ner": [[3, 4, "product"], [6, 7, "misc"], [9, 13, "misc"], [31, 33, "misc"], [55, 57, "task"], [60, 61, "product"], [63, 63, "product"], [69, 70, "task"], [72, 72, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 4, 60, 61, "related-to", "supports_program", false, false], [3, 4, 63, 63, "related-to", "supports_program", false, false], [6, 7, 3, 4, "part-of", "", false, false], [9, 13, 3, 4, "part-of", "", false, false], [31, 33, 3, 4, "part-of", "", false, false], [55, 57, 3, 4, "part-of", "", false, false], [69, 70, 3, 4, "part-of", "", false, false], [72, 72, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Nowe", "funkcje", "w", "Office", "XP", "obejmuj\u0105", "inteligentne", "znaczniki", ",", "funkcj\u0119", "wyszukiwania", "opart\u0105", "na", "selekcji", ",", "kt\u00f3ra", "rozpoznaje", "r\u00f3\u017cne", "typy", "tekstu", "w", "dokumencie", ",", "dzi\u0119ki", "czemu", "u\u017cytkownicy", "mog\u0105", "wykonywa\u0107", "dodatkowe", "dzia\u0142ania", ";", "interfejs", "panelu", "zada\u0144", ",", "kt\u00f3ry", "konsoliduje", "popularne", "polecenia", "paska", "menu", "po", "prawej", "stronie", "ekranu", ",", "aby", "u\u0142atwi\u0107", "do", "nich", "szybki", "dost\u0119p", ";", "nowe", "mo\u017cliwo\u015bci", "wsp\u00f3\u0142pracy", "z", "dokumentami", ",", "obs\u0142ug\u0119", "MSN", "Groups", "i", "SharePoint", ";", "oraz", "zintegrowane", "funkcje", "rozpoznawania", "pisma", "r\u0119cznego", "i", "mowy", "."], "sentence-detokenized": "Nowe funkcje w Office XP obejmuj\u0105 inteligentne znaczniki, funkcj\u0119 wyszukiwania opart\u0105 na selekcji, kt\u00f3ra rozpoznaje r\u00f3\u017cne typy tekstu w dokumencie, dzi\u0119ki czemu u\u017cytkownicy mog\u0105 wykonywa\u0107 dodatkowe dzia\u0142ania; interfejs panelu zada\u0144, kt\u00f3ry konsoliduje popularne polecenia paska menu po prawej stronie ekranu, aby u\u0142atwi\u0107 do nich szybki dost\u0119p; nowe mo\u017cliwo\u015bci wsp\u00f3\u0142pracy z dokumentami, obs\u0142ug\u0119 MSN Groups i SharePoint; oraz zintegrowane funkcje rozpoznawania pisma r\u0119cznego i mowy.", "token2charspan": [[0, 4], [5, 12], [13, 14], [15, 21], [22, 24], [25, 33], [34, 46], [47, 56], [56, 57], [58, 65], [66, 78], [79, 85], [86, 88], [89, 97], [97, 98], [99, 104], [105, 115], [116, 121], [122, 126], [127, 133], [134, 135], [136, 146], [146, 147], [148, 154], [155, 160], [161, 172], [173, 177], [178, 187], [188, 197], [198, 207], [207, 208], [209, 218], [219, 225], [226, 231], [231, 232], [233, 238], [239, 250], [251, 260], [261, 270], [271, 276], [277, 281], [282, 284], [285, 291], [292, 299], [300, 306], [306, 307], [308, 311], [312, 319], [320, 322], [323, 327], [328, 334], [335, 341], [341, 342], [343, 347], [348, 358], [359, 369], [370, 371], [372, 383], [383, 384], [385, 392], [393, 396], [397, 403], [404, 405], [406, 416], [416, 417], [418, 422], [423, 435], [436, 443], [444, 457], [458, 463], [464, 472], [473, 474], [475, 479], [479, 480]]}
{"doc_key": "ai-dev-64", "ner": [[10, 10, "algorithm"], [9, 9, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 10, 9, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["W", "wielu", "zastosowaniach", "jednostki", "tych", "sieci", "stosuj\u0105", "jako", "funkcj\u0119", "aktywacji", "funkcj\u0119", "sigmoidaln\u0105", "."], "sentence-detokenized": "W wielu zastosowaniach jednostki tych sieci stosuj\u0105 jako funkcj\u0119 aktywacji funkcj\u0119 sigmoidaln\u0105.", "token2charspan": [[0, 1], [2, 7], [8, 22], [23, 32], [33, 37], [38, 43], [44, 51], [52, 56], [57, 64], [65, 74], [75, 82], [83, 94], [94, 95]]}
{"doc_key": "ai-dev-65", "ner": [[3, 3, "researcher"], [9, 13, "organisation"], [24, 30, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 9, 13, "role", "", false, false], [3, 3, 24, 30, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["W", "2001", "roku", "Mehler", "zosta\u0142", "wybrany", "zagranicznym", "cz\u0142onkiem", "honorowym", "Ameryka\u0144skiej", "Akademii", "Sztuk", "i", "Nauk", ",", "a", "w", "2003", "roku", "zosta\u0142", "wybrany", "Fellow", "of", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "W 2001 roku Mehler zosta\u0142 wybrany zagranicznym cz\u0142onkiem honorowym Ameryka\u0144skiej Akademii Sztuk i Nauk, a w 2003 roku zosta\u0142 wybrany Fellow of the American Association for the Advancement of Science.", "token2charspan": [[0, 1], [2, 6], [7, 11], [12, 18], [19, 25], [26, 33], [34, 46], [47, 56], [57, 66], [67, 80], [81, 89], [90, 95], [96, 97], [98, 102], [102, 103], [104, 105], [106, 107], [108, 112], [113, 117], [118, 124], [125, 132], [133, 139], [140, 142], [143, 146], [147, 155], [156, 167], [168, 171], [172, 175], [176, 187], [188, 190], [191, 198], [198, 199]]}
{"doc_key": "ai-dev-66", "ner": [[4, 5, "task"], [7, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 7, 8, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Rozszerzenie", "tej", "koncepcji", "na", "klasyfikacje", "niebinarne", "daje", "macierz", "konfuzji", "."], "sentence-detokenized": "Rozszerzenie tej koncepcji na klasyfikacje niebinarne daje macierz konfuzji.", "token2charspan": [[0, 12], [13, 16], [17, 26], [27, 29], [30, 42], [43, 53], [54, 58], [59, 66], [67, 75], [75, 76]]}
{"doc_key": "ai-dev-67", "ner": [[10, 11, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Zaktualizowan\u0105", "estymacj\u0119", "wariancji", "szumu", "pomiarowego", "mo\u017cna", "uzyska\u0107", "z", "obliczenia", "z", "maksymalnym", "prawdopodobie\u0144stwem"], "sentence-detokenized": "Zaktualizowan\u0105 estymacj\u0119 wariancji szumu pomiarowego mo\u017cna uzyska\u0107 z obliczenia z maksymalnym prawdopodobie\u0144stwem", "token2charspan": [[0, 14], [15, 24], [25, 34], [35, 40], [41, 52], [53, 58], [59, 66], [67, 68], [69, 79], [80, 81], [82, 93], [94, 113]]}
{"doc_key": "ai-dev-68", "ner": [[1, 1, "field"], [3, 3, "algorithm"], [6, 7, "field"], [8, 9, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 6, 7, "usage", "", true, false], [3, 3, 8, 9, "related-to", "", true, false], [6, 7, 1, 1, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["W", "uczeniu", "maszynowym", "perceptron", "jest", "algorytmem", "nadzorowanego", "uczenia", "klasyfikacji", "binarnej", "."], "sentence-detokenized": "W uczeniu maszynowym perceptron jest algorytmem nadzorowanego uczenia klasyfikacji binarnej.", "token2charspan": [[0, 1], [2, 9], [10, 20], [21, 31], [32, 36], [37, 47], [48, 61], [62, 69], [70, 82], [83, 91], [91, 92]]}
{"doc_key": "ai-dev-69", "ner": [[9, 10, "field"], [12, 12, "field"], [17, 21, "conference"], [26, 27, "conference"], [31, 35, "conference"], [37, 41, "conference"], [43, 47, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[17, 21, 9, 10, "topic", "", false, false], [17, 21, 12, 12, "topic", "", false, false], [26, 27, 9, 10, "topic", "", false, false], [26, 27, 12, 12, "topic", "", false, false], [31, 35, 9, 10, "topic", "", false, false], [31, 35, 12, 12, "topic", "", false, false], [37, 41, 9, 10, "topic", "", false, false], [37, 41, 12, 12, "topic", "", false, false], [43, 47, 9, 10, "topic", "", false, false], [43, 47, 12, 12, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Pe\u0142ni\u0142a", "r\u00f3wnie\u017c", "funkcj\u0119", "Area", "Chair", "na", "wielu", "konferencjach", "dotycz\u0105cych", "uczenia", "maszynowego", "i", "widzenia", ",", "w", "tym", "Conference", "on", "Neural", "Information", "Processing", "Systems", ",", "International", "Conference", "on", "Learning", "Representations", ",", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "International", "Conference", "on", "Computer", "Vision", "oraz", "European", "Conference", "on", "Computer", "Vision", "."], "sentence-detokenized": "Pe\u0142ni\u0142a r\u00f3wnie\u017c funkcj\u0119 Area Chair na wielu konferencjach dotycz\u0105cych uczenia maszynowego i widzenia, w tym Conference on Neural Information Processing Systems, International Conference on Learning Representations, Conference on Computer Vision and Pattern Recognition, International Conference on Computer Vision oraz European Conference on Computer Vision.", "token2charspan": [[0, 7], [8, 15], [16, 23], [24, 28], [29, 34], [35, 37], [38, 43], [44, 57], [58, 69], [70, 77], [78, 89], [90, 91], [92, 100], [100, 101], [102, 103], [104, 107], [108, 118], [119, 121], [122, 128], [129, 140], [141, 151], [152, 159], [159, 160], [161, 174], [175, 185], [186, 188], [189, 197], [198, 213], [213, 214], [215, 225], [226, 228], [229, 237], [238, 244], [245, 248], [249, 256], [257, 268], [268, 269], [270, 283], [284, 294], [295, 297], [298, 306], [307, 313], [314, 318], [319, 327], [328, 338], [339, 341], [342, 350], [351, 357], [357, 358]]}
{"doc_key": "ai-dev-70", "ner": [[0, 1, "algorithm"], [6, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Algorytm", "kondensacyjny", "zosta\u0142", "r\u00f3wnie\u017c", "wykorzystany", "do", "systemu", "rozpoznawania", "twarzy", "w", "sekwencji", "wideo", "."], "sentence-detokenized": "Algorytm kondensacyjny zosta\u0142 r\u00f3wnie\u017c wykorzystany do systemu rozpoznawania twarzy w sekwencji wideo.", "token2charspan": [[0, 8], [9, 22], [23, 29], [30, 37], [38, 50], [51, 53], [54, 61], [62, 75], [76, 82], [83, 84], [85, 94], [95, 100], [100, 101]]}
{"doc_key": "ai-dev-71", "ner": [[0, 1, "task"], [6, 6, "organisation"], [15, 15, "conference"], [22, 26, "academicjournal"], [21, 21, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 15, 0, 1, "topic", "", false, false], [15, 15, 6, 6, "origin", "", false, false], [22, 26, 0, 1, "topic", "", false, false], [22, 26, 6, 6, "origin", "", true, false], [21, 21, 22, 26, "role", "edited_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Rozpowszechnianie", "informacji", "jest", "r\u00f3wnie\u017c", "cz\u0119\u015bci\u0105", "misji", "ELRA", ",", "kt\u00f3ra", "jest", "realizowana", "zar\u00f3wno", "poprzez", "organizacj\u0119", "konferencji", "LREC", ",", "jak", "i", "wydawany", "przez", "Springera", "Language", "Resources", "and", "Evaluation", "Journal", "."], "sentence-detokenized": "Rozpowszechnianie informacji jest r\u00f3wnie\u017c cz\u0119\u015bci\u0105 misji ELRA, kt\u00f3ra jest realizowana zar\u00f3wno poprzez organizacj\u0119 konferencji LREC, jak i wydawany przez Springera Language Resources and Evaluation Journal.", "token2charspan": [[0, 17], [18, 28], [29, 33], [34, 41], [42, 49], [50, 55], [56, 60], [60, 61], [62, 67], [68, 72], [73, 84], [85, 92], [93, 100], [101, 112], [113, 124], [125, 129], [129, 130], [131, 134], [135, 136], [137, 145], [146, 151], [152, 161], [162, 170], [171, 180], [181, 184], [185, 195], [196, 203], [203, 204]]}
{"doc_key": "ai-dev-72", "ner": [[1, 8, "field"], [11, 12, "field"], [17, 19, "field"], [21, 22, "field"], [49, 50, "field"], [55, 55, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 8, 49, 50, "named", "", false, false], [17, 19, 1, 8, "named", "", false, false], [55, 55, 11, 12, "part-of", "", true, false], [55, 55, 17, 19, "part-of", "", true, false], [55, 55, 49, 50, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["W", "teorii", "liniowych", "uk\u0142ad\u00f3w", "niezmiennych", "w", "czasie", "(", "LTI", ")", ",", "teorii", "sterowania", ",", "a", "tak\u017ce", "w", "cyfrowym", "przetwarzaniu", "sygna\u0142\u00f3w", "lub", "obr\u00f3bce", "sygna\u0142\u00f3w", ",", "zale\u017cno\u015b\u0107", "mi\u0119dzy", "sygna\u0142em", "wej\u015bciowym", ",", "matematycznym", "x", "(", "t", ")", "/", "matematycznym", ",", "a", "sygna\u0142em", "wyj\u015bciowym", ",", "matematycznym", "y", "(", "t", ")", "/", "matematycznym", ",", "uk\u0142adu", "LTI", "jest", "regulowana", "przez", "operacj\u0119", "konwolucji", ":"], "sentence-detokenized": "W teorii liniowych uk\u0142ad\u00f3w niezmiennych w czasie (LTI), teorii sterowania, a tak\u017ce w cyfrowym przetwarzaniu sygna\u0142\u00f3w lub obr\u00f3bce sygna\u0142\u00f3w, zale\u017cno\u015b\u0107 mi\u0119dzy sygna\u0142em wej\u015bciowym, matematycznym x (t) / matematycznym, a sygna\u0142em wyj\u015bciowym, matematycznym y (t) / matematycznym, uk\u0142adu LTI jest regulowana przez operacj\u0119 konwolucji:", "token2charspan": [[0, 1], [2, 8], [9, 18], [19, 26], [27, 39], [40, 41], [42, 48], [49, 50], [50, 53], [53, 54], [54, 55], [56, 62], [63, 73], [73, 74], [75, 76], [77, 82], [83, 84], [85, 93], [94, 107], [108, 116], [117, 120], [121, 128], [129, 137], [137, 138], [139, 148], [149, 155], [156, 164], [165, 175], [175, 176], [177, 190], [191, 192], [193, 194], [194, 195], [195, 196], [197, 198], [199, 212], [212, 213], [214, 215], [216, 224], [225, 235], [235, 236], [237, 250], [251, 252], [253, 254], [254, 255], [255, 256], [257, 258], [259, 272], [272, 273], [274, 280], [281, 284], [285, 289], [290, 300], [301, 306], [307, 315], [316, 326], [326, 327]]}
{"doc_key": "ai-dev-73", "ner": [[16, 17, "field"], [20, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 31, "field"], [33, 34, "product"], [36, 37, "field"], [39, 39, "field"], [41, 41, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ze", "wzgl\u0119du", "na", "swoj\u0105", "og\u00f3lno\u015b\u0107", "dziedzina", "ta", "jest", "badana", "w", "wielu", "innych", "dyscyplinach", ",", "takich", "jak", "teoria", "gier", ",", "teoria", "sterowania", ",", "badania", "operacyjne", ",", "teoria", "informacji", ",", "optymalizacja", "oparta", "na", "symulacji", ",", "systemy", "wieloagentowe", ",", "inteligencja", "rojowa", ",", "statystyka", "i", "algorytmy", "genetyczne", "."], "sentence-detokenized": "Ze wzgl\u0119du na swoj\u0105 og\u00f3lno\u015b\u0107 dziedzina ta jest badana w wielu innych dyscyplinach, takich jak teoria gier, teoria sterowania, badania operacyjne, teoria informacji, optymalizacja oparta na symulacji, systemy wieloagentowe, inteligencja rojowa, statystyka i algorytmy genetyczne.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 19], [20, 28], [29, 38], [39, 41], [42, 46], [47, 53], [54, 55], [56, 61], [62, 68], [69, 81], [81, 82], [83, 89], [90, 93], [94, 100], [101, 105], [105, 106], [107, 113], [114, 124], [124, 125], [126, 133], [134, 144], [144, 145], [146, 152], [153, 163], [163, 164], [165, 178], [179, 185], [186, 188], [189, 198], [198, 199], [200, 207], [208, 221], [221, 222], [223, 235], [236, 242], [242, 243], [244, 254], [255, 256], [257, 266], [267, 277], [277, 278]]}
{"doc_key": "ai-dev-74", "ner": [[0, 2, "algorithm"], [12, 13, "field"], [21, 22, "algorithm"], [24, 25, "algorithm"], [30, 31, "algorithm"], [34, 35, "algorithm"], [34, 37, "researcher"], [39, 40, "researcher"], [42, 45, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[12, 13, 0, 2, "usage", "", true, false], [21, 22, 12, 13, "part-of", "", true, false], [24, 25, 12, 13, "part-of", "", true, false], [30, 31, 12, 13, "part-of", "", true, false], [34, 35, 12, 13, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Stochastyczne", "zej\u015bcie", "gradientowe", "jest", "popularnym", "algorytmem", "do", "szkolenia", "szerokiego", "zakresu", "modeli", "w", "uczeniu", "maszynowym", ",", "w", "tym", "(", "liniowych", ")", "maszyn", "wektor\u00f3w", "wsparcia", ",", "regresji", "logistycznej", "(", "patrz", "np", ".", "Vowpal", "Wabbit", ")", "i", "modeli", "graficznych.Jenny", "Rose", "Finkel", ",", "Alex", "Kleeman", ",", "Christopher", "D", ".", "Manning", "(", "2008", ")", "."], "sentence-detokenized": "Stochastyczne zej\u015bcie gradientowe jest popularnym algorytmem do szkolenia szerokiego zakresu modeli w uczeniu maszynowym, w tym (liniowych) maszyn wektor\u00f3w wsparcia, regresji logistycznej (patrz np. Vowpal Wabbit) i modeli graficznych.Jenny Rose Finkel, Alex Kleeman, Christopher D. Manning (2008).", "token2charspan": [[0, 13], [14, 21], [22, 33], [34, 38], [39, 49], [50, 60], [61, 63], [64, 73], [74, 84], [85, 92], [93, 99], [100, 101], [102, 109], [110, 120], [120, 121], [122, 123], [124, 127], [128, 129], [129, 138], [138, 139], [140, 146], [147, 155], [156, 164], [164, 165], [166, 174], [175, 187], [188, 189], [189, 194], [195, 197], [197, 198], [199, 205], [206, 212], [212, 213], [214, 215], [216, 222], [223, 240], [241, 245], [246, 252], [252, 253], [254, 258], [259, 266], [266, 267], [268, 279], [280, 281], [281, 282], [283, 290], [291, 292], [292, 296], [296, 297], [297, 298]]}
{"doc_key": "ai-dev-75", "ner": [[7, 7, "organisation"], [9, 10, "product"], [16, 16, "country"], [18, 20, "university"], [22, 22, "location"], [24, 26, "university"], [28, 28, "location"], [31, 31, "university"], [33, 35, "location"], [36, 38, "university"], [39, 39, "location"], [42, 42, "university"], [44, 44, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[7, 7, 18, 20, "role", "donates_to", false, false], [7, 7, 24, 26, "role", "donates_to", false, false], [7, 7, 31, 31, "role", "donates_to", false, false], [7, 7, 36, 38, "role", "donates_to", false, false], [7, 7, 42, 42, "role", "donates_to", false, false], [9, 10, 7, 7, "origin", "donates", true, false], [18, 20, 22, 22, "physical", "", false, false], [22, 22, 16, 16, "physical", "", false, false], [24, 26, 28, 28, "physical", "", false, false], [28, 28, 16, 16, "physical", "", false, false], [31, 31, 33, 35, "physical", "", false, false], [33, 35, 16, 16, "physical", "", false, false], [36, 38, 39, 39, "physical", "", false, false], [39, 39, 16, 16, "physical", "", false, false], [42, 42, 44, 44, "physical", "", false, false], [44, 44, 16, 16, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "sentence": ["W", "sierpniu", "2011", "roku", "og\u0142oszono", ",", "\u017ce", "Hitachi", "przeka\u017ce", "mikroskop", "elektronowy", "ka\u017cdemu", "z", "pi\u0119ciu", "uniwersytet\u00f3w", "w", "Indonezji", "(", "Uniwersytetowi", "P\u00f3\u0142nocnej", "Sumatry", "w", "Medan", ",", "Indonezyjskiemu", "Uniwersytetowi", "Chrze\u015bcija\u0144skiemu", "w", "D\u017cakarcie", ",", "Uniwersytetowi", "Padjadjaran", "w", "Bandung", ",", "Uniwersytetowi", "Jenderal", "Soedirman", "w", "Purwokerto", "i", "Uniwersytetowi", "Muhammadiyah", "w", "Malang", ")", "."], "sentence-detokenized": "W sierpniu 2011 roku og\u0142oszono, \u017ce Hitachi przeka\u017ce mikroskop elektronowy ka\u017cdemu z pi\u0119ciu uniwersytet\u00f3w w Indonezji (Uniwersytetowi P\u00f3\u0142nocnej Sumatry w Medan, Indonezyjskiemu Uniwersytetowi Chrze\u015bcija\u0144skiemu w D\u017cakarcie, Uniwersytetowi Padjadjaran w Bandung, Uniwersytetowi Jenderal Soedirman w Purwokerto i Uniwersytetowi Muhammadiyah w Malang).", "token2charspan": [[0, 1], [2, 10], [11, 15], [16, 20], [21, 30], [30, 31], [32, 34], [35, 42], [43, 51], [52, 61], [62, 73], [74, 81], [82, 83], [84, 90], [91, 104], [105, 106], [107, 116], [117, 118], [118, 132], [133, 142], [143, 150], [151, 152], [153, 158], [158, 159], [160, 175], [176, 190], [191, 208], [209, 210], [211, 220], [220, 221], [222, 236], [237, 248], [249, 250], [251, 258], [258, 259], [260, 274], [275, 283], [284, 293], [294, 295], [296, 306], [307, 308], [309, 323], [324, 336], [337, 338], [339, 345], [345, 346], [346, 347]]}
{"doc_key": "ai-dev-76", "ner": [[1, 1, "field"], [2, 3, "field"], [7, 8, "algorithm"], [10, 11, "algorithm"], [18, 19, "field"], [27, 28, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 1, 2, 3, "part-of", "", false, false], [1, 1, 18, 19, "related-to", "", true, false], [1, 1, 27, 28, "related-to", "", true, false], [7, 8, 1, 1, "type-of", "", false, false], [10, 11, 1, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Techniki", "optymalizacyjne", "bada\u0144", "operacyjnych", ",", "takie", "jak", "programowanie", "liniowe", "czy", "programowanie", "dynamiczne", ",", "s\u0105", "cz\u0119sto", "niepraktyczne", "dla", "problem\u00f3w", "in\u017cynierii", "oprogramowania", "o", "du\u017cej", "skali", "ze", "wzgl\u0119du", "na", "ich", "z\u0142o\u017cono\u015b\u0107", "obliczeniow\u0105", "."], "sentence-detokenized": "Techniki optymalizacyjne bada\u0144 operacyjnych, takie jak programowanie liniowe czy programowanie dynamiczne, s\u0105 cz\u0119sto niepraktyczne dla problem\u00f3w in\u017cynierii oprogramowania o du\u017cej skali ze wzgl\u0119du na ich z\u0142o\u017cono\u015b\u0107 obliczeniow\u0105.", "token2charspan": [[0, 8], [9, 24], [25, 30], [31, 43], [43, 44], [45, 50], [51, 54], [55, 68], [69, 76], [77, 80], [81, 94], [95, 105], [105, 106], [107, 109], [110, 116], [117, 130], [131, 134], [135, 144], [145, 155], [156, 170], [171, 172], [173, 178], [179, 184], [185, 187], [188, 195], [196, 198], [199, 202], [203, 212], [213, 225], [225, 226]]}
{"doc_key": "ai-dev-77", "ner": [[0, 0, "metrics"], [7, 7, "metrics"], [9, 35, "metrics"], [16, 16, "metrics"], [21, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 7, 7, "compare", "", false, false], [0, 0, 9, 35, "compare", "", false, false], [16, 16, 9, 35, "part-of", "", false, false], [21, 23, 9, 35, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Czu\u0142o\u015b\u0107", "nie", "jest", "tym", "samym", ",", "co", "precyzja", "lub", "pozytywna", "warto\u015b\u0107", "predykcyjna", "(", "stosunek", "warto\u015bci", "dodatnich", "TRUE", "do", "po\u0142\u0105czonych", "warto\u015bci", "dodatnich", "TRUE", "i", "FALSE", ")", ",", "kt\u00f3ra", "jest", "tak", "samo", "stwierdzeniem", "dotycz\u0105cym", "proporcji", "rzeczywistych", "warto\u015bci", "dodatnich", "w", "badanej", "populacji", ",", "jak", "i", "testu", "."], "sentence-detokenized": "Czu\u0142o\u015b\u0107 nie jest tym samym, co precyzja lub pozytywna warto\u015b\u0107 predykcyjna (stosunek warto\u015bci dodatnich TRUE do po\u0142\u0105czonych warto\u015bci dodatnich TRUE i FALSE), kt\u00f3ra jest tak samo stwierdzeniem dotycz\u0105cym proporcji rzeczywistych warto\u015bci dodatnich w badanej populacji, jak i testu.", "token2charspan": [[0, 7], [8, 11], [12, 16], [17, 20], [21, 26], [26, 27], [28, 30], [31, 39], [40, 43], [44, 53], [54, 61], [62, 73], [74, 75], [75, 83], [84, 92], [93, 102], [103, 107], [108, 110], [111, 122], [123, 131], [132, 141], [142, 146], [147, 148], [149, 154], [154, 155], [155, 156], [157, 162], [163, 167], [168, 171], [172, 176], [177, 190], [191, 201], [202, 211], [212, 225], [226, 234], [235, 244], [245, 246], [247, 254], [255, 264], [264, 265], [266, 269], [270, 271], [272, 277], [277, 278]]}
{"doc_key": "ai-dev-78", "ner": [[2, 3, "person"], [9, 9, "product"], [12, 12, "person"], [29, 29, "person"], [36, 37, "person"], [41, 41, "person"], [45, 46, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 3, 41, 41, "named", "same", false, false], [9, 9, 2, 3, "artifact", "", false, false], [36, 37, 45, 46, "role", "convinces", false, false], [45, 46, 9, 9, "role", "producer", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Scenariusz", "autorstwa", "Hamptona", "Fanchera", "!", "--", "Pocz\u0105tkowo", "nie", "zatytu\u0142owany", "Android", "-", "patrz", "Sammon", ",", "str", ".", "32", "i", "38", "w", "celu", "wyja\u015bnienia", "-", "zosta\u0142", "wybrany", "w", "1977", "roku", ".", "Sammon", ",", "s", ".", "23", "-30", "Producent", "Michael", "Deeley", "zainteresowa\u0142", "si\u0119", "szkicem", "Fanchera", "i", "przekona\u0142", "re\u017cysera", "Ridleya", "Scotta", "do", "jego", "sfilmowania", "."], "sentence-detokenized": "Scenariusz autorstwa Hamptona Fanchera! -- Pocz\u0105tkowo nie zatytu\u0142owany Android - patrz Sammon, str. 32 i 38 w celu wyja\u015bnienia - zosta\u0142 wybrany w 1977 roku. Sammon, s. 23-30 Producent Michael Deeley zainteresowa\u0142 si\u0119 szkicem Fanchera i przekona\u0142 re\u017cysera Ridleya Scotta do jego sfilmowania.", "token2charspan": [[0, 10], [11, 20], [21, 29], [30, 38], [38, 39], [40, 42], [43, 53], [54, 57], [58, 70], [71, 78], [79, 80], [81, 86], [87, 93], [93, 94], [95, 98], [98, 99], [100, 102], [103, 104], [105, 107], [108, 109], [110, 114], [115, 126], [127, 128], [129, 135], [136, 143], [144, 145], [146, 150], [151, 155], [155, 156], [157, 163], [163, 164], [165, 166], [166, 167], [168, 170], [170, 173], [174, 183], [184, 191], [192, 198], [199, 212], [213, 216], [217, 224], [225, 233], [234, 235], [236, 245], [246, 254], [255, 262], [263, 269], [270, 272], [273, 277], [278, 289], [289, 290]]}
{"doc_key": "ai-dev-79", "ner": [[0, 1, "field"], [3, 4, "task"], [6, 8, "task"], [11, 13, "misc"], [15, 16, "field"], [18, 20, "task"], [22, 23, "task"], [27, 27, "field"], [31, 34, "task"], [36, 36, "task"], [38, 39, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[3, 4, 0, 1, "part-of", "", false, false], [6, 8, 0, 1, "part-of", "", false, false], [11, 13, 0, 1, "part-of", "", false, false], [15, 16, 0, 1, "part-of", "", false, false], [18, 20, 0, 1, "part-of", "", false, false], [22, 23, 0, 1, "part-of", "", false, false], [27, 27, 0, 1, "part-of", "", false, false], [31, 34, 0, 1, "part-of", "", false, false], [36, 36, 0, 1, "part-of", "", false, false], [38, 39, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Analiza", "tekstu", "obejmuje", "wyszukiwanie", "informacji", ",", "analiz\u0119", "leksykaln\u0105", "w", "celu", "zbadania", "rozk\u0142adu", "cz\u0119stotliwo\u015bci", "s\u0142\u00f3w", ",", "rozpoznawanie", "wzorc\u00f3w", ",", "tagowanie", "/", "adnotacj\u0119", ",", "ekstrakcj\u0119", "informacji", ",", "techniki", "eksploracji", "danych", ",", "w", "tym", "analiz\u0119", "powi\u0105za\u0144", "i", "asocjacji", ",", "wizualizacj\u0119", "i", "analityk\u0119", "predykcyjn\u0105", "."], "sentence-detokenized": "Analiza tekstu obejmuje wyszukiwanie informacji, analiz\u0119 leksykaln\u0105 w celu zbadania rozk\u0142adu cz\u0119stotliwo\u015bci s\u0142\u00f3w, rozpoznawanie wzorc\u00f3w, tagowanie / adnotacj\u0119, ekstrakcj\u0119 informacji, techniki eksploracji danych, w tym analiz\u0119 powi\u0105za\u0144 i asocjacji, wizualizacj\u0119 i analityk\u0119 predykcyjn\u0105.", "token2charspan": [[0, 7], [8, 14], [15, 23], [24, 36], [37, 47], [47, 48], [49, 56], [57, 67], [68, 69], [70, 74], [75, 83], [84, 92], [93, 107], [108, 112], [112, 113], [114, 127], [128, 135], [135, 136], [137, 146], [147, 148], [149, 158], [158, 159], [160, 170], [171, 181], [181, 182], [183, 191], [192, 203], [204, 210], [210, 211], [212, 213], [214, 217], [218, 225], [226, 234], [235, 236], [237, 246], [246, 247], [248, 260], [261, 262], [263, 272], [273, 284], [284, 285]]}
{"doc_key": "ai-dev-80", "ner": [[3, 3, "product"], [10, 11, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 11, 3, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Kilka", "metryk", "wykorzystuje", "WordNet", ",", "r\u0119cznie", "skonstruowan\u0105", "leksykaln\u0105", "baz\u0119", "danych", "angielskich", "s\u0142\u00f3w", "."], "sentence-detokenized": "Kilka metryk wykorzystuje WordNet, r\u0119cznie skonstruowan\u0105 leksykaln\u0105 baz\u0119 danych angielskich s\u0142\u00f3w.", "token2charspan": [[0, 5], [6, 12], [13, 25], [26, 33], [33, 34], [35, 42], [43, 56], [57, 67], [68, 72], [73, 79], [80, 91], [92, 96], [96, 97]]}
{"doc_key": "ai-dev-81", "ner": [[6, 7, "field"], [10, 10, "task"], [12, 16, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["System", "wykorzystuje", "po\u0142\u0105czenie", "technik", "z", "zakresu", "lingwistyki", "obliczeniowej", ",", "wyszukiwania", "informacji", "i", "reprezentacji", "wiedzy", "do", "wyszukiwania", "odpowiedzi", "."], "sentence-detokenized": "System wykorzystuje po\u0142\u0105czenie technik z zakresu lingwistyki obliczeniowej, wyszukiwania informacji i reprezentacji wiedzy do wyszukiwania odpowiedzi.", "token2charspan": [[0, 6], [7, 19], [20, 30], [31, 38], [39, 40], [41, 48], [49, 60], [61, 74], [74, 75], [76, 88], [89, 99], [100, 101], [102, 115], [116, 122], [123, 125], [126, 138], [139, 149], [149, 150]]}
{"doc_key": "ai-dev-82", "ner": [[4, 5, "metrics"], [11, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 11, 11, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Jako", "metryka", "wydajno\u015bci", ",", "wsp\u00f3\u0142czynnik", "niepewno\u015bci", "ma", "t\u0119", "przewag\u0119", "nad", "prost\u0105", "dok\u0142adno\u015bci\u0105", ",", "\u017ce", "nie", "ma", "na", "niego", "wp\u0142ywu", "wzgl\u0119dna", "wielko\u015b\u0107", "poszczeg\u00f3lnych", "klas", "."], "sentence-detokenized": "Jako metryka wydajno\u015bci, wsp\u00f3\u0142czynnik niepewno\u015bci ma t\u0119 przewag\u0119 nad prost\u0105 dok\u0142adno\u015bci\u0105, \u017ce nie ma na niego wp\u0142ywu wzgl\u0119dna wielko\u015b\u0107 poszczeg\u00f3lnych klas.", "token2charspan": [[0, 4], [5, 12], [13, 23], [23, 24], [25, 37], [38, 49], [50, 52], [53, 55], [56, 64], [65, 68], [69, 75], [76, 88], [88, 89], [90, 92], [93, 96], [97, 99], [100, 102], [103, 108], [109, 115], [116, 124], [125, 133], [134, 148], [149, 153], [153, 154]]}
{"doc_key": "ai-dev-83", "ner": [[7, 8, "algorithm"], [10, 11, "algorithm"], [13, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Naukowcy", "pr\u00f3bowali", "wielu", "metod", ",", "takich", "jak", "przep\u0142yw", "optyczny", ",", "filtrowanie", "Kalmana", ",", "ukryte", "modele", "Markowa", "itp", "."], "sentence-detokenized": "Naukowcy pr\u00f3bowali wielu metod, takich jak przep\u0142yw optyczny, filtrowanie Kalmana, ukryte modele Markowa itp.", "token2charspan": [[0, 8], [9, 18], [19, 24], [25, 30], [30, 31], [32, 38], [39, 42], [43, 51], [52, 60], [60, 61], [62, 73], [74, 81], [81, 82], [83, 89], [90, 96], [97, 104], [105, 108], [108, 109]]}
{"doc_key": "ai-dev-84", "ner": [[9, 12, "conference"], [20, 22, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Pe\u0142ni\u0142a", "funkcje", "prezesa", ",", "wiceprezesa", "i", "sekretarza", "-", "skarbnika", "Association", "for", "Computational", "Linguistics", "oraz", "by\u0142a", "cz\u0142onkiem", "zarz\u0105du", "i", "sekretarzem", "zarz\u0105du", "Computing", "Research", "Association", "."], "sentence-detokenized": "Pe\u0142ni\u0142a funkcje prezesa, wiceprezesa i sekretarza-skarbnika Association for Computational Linguistics oraz by\u0142a cz\u0142onkiem zarz\u0105du i sekretarzem zarz\u0105du Computing Research Association.", "token2charspan": [[0, 7], [8, 15], [16, 23], [23, 24], [25, 36], [37, 38], [39, 49], [49, 50], [50, 59], [60, 71], [72, 75], [76, 89], [90, 101], [102, 106], [107, 111], [112, 121], [122, 129], [130, 131], [132, 143], [144, 151], [152, 161], [162, 170], [171, 182], [182, 183]]}
{"doc_key": "ai-dev-85", "ner": [[8, 8, "programlang"], [10, 10, "product"], [12, 12, "programlang"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 12, 12, "compare", "", false, false], [8, 8, 14, 15, "related-to", "supports", false, false], [10, 10, 12, 12, "compare", "", false, false], [10, 10, 14, 15, "related-to", "supports", false, false], [12, 12, 14, 15, "related-to", "supports", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Podobnie", "jak", "inne", "podobne", "j\u0119zyki", ",", "takie", "jak", "APL", "i", "MATLAB", ",", "R", "obs\u0142uguje", "arytmetyk\u0119", "macierzy", "."], "sentence-detokenized": "Podobnie jak inne podobne j\u0119zyki, takie jak APL i MATLAB, R obs\u0142uguje arytmetyk\u0119 macierzy.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 25], [26, 32], [32, 33], [34, 39], [40, 43], [44, 47], [48, 49], [50, 56], [56, 57], [58, 59], [60, 69], [70, 80], [81, 89], [89, 90]]}
{"doc_key": "ai-dev-86", "ner": [[7, 9, "misc"], [10, 11, "organisation"], [15, 16, "researcher"], [18, 21, "university"], [23, 27, "misc"], [29, 29, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 9, 10, 11, "physical", "", false, false], [7, 9, 23, 27, "temporal", "", false, false], [15, 16, 7, 9, "role", "arranges", false, false], [15, 16, 18, 21, "role", "works_for", false, false], [29, 29, 7, 9, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["7", "czerwca", "2014", "roku", "w", "konkursie", "na", "test", "Turinga", "w", "Royal", "Society", ",", "zorganizowanym", "przez", "Kevina", "Warwicka", "z", "University", "of", "Reading", "z", "okazji", "60", ".", "rocznicy", "\u015bmierci", "Turinga", ",", "Goostman", "wygra\u0142", "po", "tym", ",", "jak", "33", "%", "s\u0119dzi\u00f3w", "by\u0142o", "przekonanych", ",", "\u017ce", "bot", "jest", "cz\u0142owiekiem", "."], "sentence-detokenized": "7 czerwca 2014 roku w konkursie na test Turinga w Royal Society, zorganizowanym przez Kevina Warwicka z University of Reading z okazji 60. rocznicy \u015bmierci Turinga, Goostman wygra\u0142 po tym, jak 33% s\u0119dzi\u00f3w by\u0142o przekonanych, \u017ce bot jest cz\u0142owiekiem.", "token2charspan": [[0, 1], [2, 9], [10, 14], [15, 19], [20, 21], [22, 31], [32, 34], [35, 39], [40, 47], [48, 49], [50, 55], [56, 63], [63, 64], [65, 79], [80, 85], [86, 92], [93, 101], [102, 103], [104, 114], [115, 117], [118, 125], [126, 127], [128, 134], [135, 137], [137, 138], [139, 147], [148, 155], [156, 163], [163, 164], [165, 173], [174, 180], [181, 183], [184, 187], [187, 188], [189, 192], [193, 195], [195, 196], [197, 204], [205, 209], [210, 222], [222, 223], [224, 226], [227, 230], [231, 235], [236, 247], [247, 248]]}
{"doc_key": "ai-dev-87", "ner": [[0, 1, "product"], [3, 3, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Robot", "wsp\u00f3\u0142pracuj\u0105cy", "lub", "cobot", "to", "robot", ",", "kt\u00f3ry", "mo\u017ce", "bezpiecznie", "i", "skutecznie", "wsp\u00f3\u0142dzia\u0142a\u0107", "z", "pracownikami", "ludzkimi", "podczas", "wykonywania", "prostych", "zada\u0144", "przemys\u0142owych", "."], "sentence-detokenized": "Robot wsp\u00f3\u0142pracuj\u0105cy lub cobot to robot, kt\u00f3ry mo\u017ce bezpiecznie i skutecznie wsp\u00f3\u0142dzia\u0142a\u0107 z pracownikami ludzkimi podczas wykonywania prostych zada\u0144 przemys\u0142owych.", "token2charspan": [[0, 5], [6, 20], [21, 24], [25, 30], [31, 33], [34, 39], [39, 40], [41, 46], [47, 51], [52, 63], [64, 65], [66, 76], [77, 89], [90, 91], [92, 104], [105, 113], [114, 121], [122, 133], [134, 142], [143, 148], [149, 162], [162, 163]]}
{"doc_key": "ai-dev-88", "ner": [[10, 11, "field"], [15, 16, "task"], [18, 19, "task"], [21, 22, "task"], [24, 25, "task"], [27, 28, "task"], [30, 32, "task"], [34, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[15, 16, 10, 11, "part-of", "task_part_of_field", false, false], [18, 19, 10, 11, "part-of", "task_part_of_field", false, false], [21, 22, 10, 11, "part-of", "task_part_of_field", false, false], [24, 25, 10, 11, "part-of", "task_part_of_field", false, false], [27, 28, 10, 11, "part-of", "task_part_of_field", false, false], [30, 32, 10, 11, "part-of", "task_part_of_field", false, false], [34, 35, 10, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Te", "og\u00f3lne", "ramy", "zosta\u0142y", "zastosowane", "do", "wielu", "r\u00f3\u017cnych", "problem\u00f3w", "w", "wizji", "komputerowej", ",", "w", "tym", "wykrywania", "cech", ",", "klasyfikacji", "cech", ",", "segmentacji", "obrazu", ",", "dopasowania", "obrazu", ",", "estymacji", "ruchu", ",", "obliczania", "wskaz\u00f3wek", "kszta\u0142tu", "i", "rozpoznawania", "obiekt\u00f3w", "."], "sentence-detokenized": "Te og\u00f3lne ramy zosta\u0142y zastosowane do wielu r\u00f3\u017cnych problem\u00f3w w wizji komputerowej, w tym wykrywania cech, klasyfikacji cech, segmentacji obrazu, dopasowania obrazu, estymacji ruchu, obliczania wskaz\u00f3wek kszta\u0142tu i rozpoznawania obiekt\u00f3w.", "token2charspan": [[0, 2], [3, 9], [10, 14], [15, 22], [23, 34], [35, 37], [38, 43], [44, 51], [52, 61], [62, 63], [64, 69], [70, 82], [82, 83], [84, 85], [86, 89], [90, 100], [101, 105], [105, 106], [107, 119], [120, 124], [124, 125], [126, 137], [138, 144], [144, 145], [146, 157], [158, 164], [164, 165], [166, 175], [176, 181], [181, 182], [183, 193], [194, 203], [204, 212], [213, 214], [215, 228], [229, 237], [237, 238]]}
{"doc_key": "ai-dev-89", "ner": [[4, 5, "task"], [7, 9, "algorithm"], [12, 13, "algorithm"], [21, 23, "algorithm"], [26, 27, "algorithm"], [31, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 7, 9, "part-of", "", false, false], [4, 5, 12, 13, "usage", "", false, false], [7, 9, 21, 23, "named", "same", false, false], [21, 23, 26, 27, "related-to", "", false, false], [21, 23, 31, 32, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["W", "wielu", "praktycznych", "zastosowaniach", "estymacja", "parametr\u00f3w", "dla", "naiwnych", "modeli", "Bayesa", "wykorzystuje", "metod\u0119", "maksymalnego", "prawdopodobie\u0144stwa", ";", "innymi", "s\u0142owy", ",", "mo\u017cna", "pracowa\u0107", "z", "naiwnym", "modelem", "Bayesa", "bez", "przyjmowania", "prawdopodobie\u0144stwa", "Bayesa", "lub", "stosowania", "jakichkolwiek", "metod", "Bayesa", "."], "sentence-detokenized": "W wielu praktycznych zastosowaniach estymacja parametr\u00f3w dla naiwnych modeli Bayesa wykorzystuje metod\u0119 maksymalnego prawdopodobie\u0144stwa; innymi s\u0142owy, mo\u017cna pracowa\u0107 z naiwnym modelem Bayesa bez przyjmowania prawdopodobie\u0144stwa Bayesa lub stosowania jakichkolwiek metod Bayesa.", "token2charspan": [[0, 1], [2, 7], [8, 20], [21, 35], [36, 45], [46, 56], [57, 60], [61, 69], [70, 76], [77, 83], [84, 96], [97, 103], [104, 116], [117, 135], [135, 136], [137, 143], [144, 149], [149, 150], [151, 156], [157, 165], [166, 167], [168, 175], [176, 183], [184, 190], [191, 194], [195, 207], [208, 226], [227, 233], [234, 237], [238, 248], [249, 262], [263, 268], [269, 275], [275, 276]]}
{"doc_key": "ai-dev-90", "ner": [[2, 4, "researcher"], [6, 7, "misc"], [10, 13, "university"], [15, 17, "researcher"], [19, 20, "misc"], [24, 24, "university"], [26, 26, "university"], [28, 31, "misc"], [37, 39, "university"], [43, 46, "misc"], [48, 51, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[2, 4, 10, 13, "physical", "", false, false], [2, 4, 10, 13, "role", "", false, false], [2, 4, 15, 17, "social", "brothers", false, false], [6, 7, 2, 4, "named", "", false, false], [15, 17, 24, 24, "physical", "", false, false], [15, 17, 24, 24, "role", "", false, false], [15, 17, 26, 26, "physical", "", false, false], [15, 17, 26, 26, "role", "", false, false], [15, 17, 37, 39, "physical", "", false, false], [15, 17, 37, 39, "role", "", false, false], [19, 20, 15, 17, "named", "", false, false], [28, 31, 15, 17, "origin", "", false, false], [43, 46, 15, 17, "artifact", "", false, false], [43, 46, 48, 51, "part-of", "part", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Bracia", "-", "Victor", "Gershevich", "Katz", ",", "matematyk", "ameryka\u0144ski", ",", "profesor", "Massachusetts", "Institute", "of", "Technology", ";", "Mikhail", "Gershevich", "Katz", ",", "matematyk", "izraelski", ",", "absolwent", "uniwersytet\u00f3w", "Harvarda", "i", "Columbii", "(", "Ph", ".", "D", ".", ",", "1984", ")", ",", "profesor", "Uniwersytetu", "Bar-", "Ilan", ",", "autor", "monografii", "Systolic", "Geometry", "and", "Topology", "(", "Mathematical", "Surveys", "and", "Monographs", ",", "vol", "."], "sentence-detokenized": "Bracia - Victor Gershevich Katz, matematyk ameryka\u0144ski, profesor Massachusetts Institute of Technology; Mikhail Gershevich Katz, matematyk izraelski, absolwent uniwersytet\u00f3w Harvarda i Columbii (Ph.D. , 1984), profesor Uniwersytetu Bar-Ilan, autor monografii Systolic Geometry and Topology (Mathematical Surveys and Monographs, vol.", "token2charspan": [[0, 6], [7, 8], [9, 15], [16, 26], [27, 31], [31, 32], [33, 42], [43, 54], [54, 55], [56, 64], [65, 78], [79, 88], [89, 91], [92, 102], [102, 103], [104, 111], [112, 122], [123, 127], [127, 128], [129, 138], [139, 148], [148, 149], [150, 159], [160, 173], [174, 182], [183, 184], [185, 193], [194, 195], [195, 197], [197, 198], [198, 199], [199, 200], [201, 202], [203, 207], [207, 208], [208, 209], [210, 218], [219, 231], [232, 236], [236, 240], [240, 241], [242, 247], [248, 258], [259, 267], [268, 276], [277, 280], [281, 289], [290, 291], [291, 303], [304, 311], [312, 315], [316, 326], [326, 327], [328, 331], [331, 332]]}
{"doc_key": "ai-dev-91", "ner": [[3, 4, "person"], [8, 9, "conference"], [12, 15, "organisation"], [17, 17, "location"], [21, 21, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 8, 9, "physical", "", false, false], [3, 4, 8, 9, "role", "", false, false], [3, 4, 12, 15, "role", "", false, false], [12, 15, 17, 17, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["W", "2000", "roku", "Manuel", "Toharia", ",", "prelegent", "poprzednich", "Campus", "Parties", "i", "dyrektor", "Muzeum", "Nauki", "Pr\u00edncipe", "Felipe", "w", "Walencji", "zasugerowa\u0142", ",", "aby", "Ragageles", "rozszerzy\u0142", "i", "uczyni\u0142", "imprez\u0119", "bardziej", "mi\u0119dzynarodow\u0105", ",", "przenosz\u0105c", "j\u0105", "do", "s\u0142ynnego", "muzeum", "."], "sentence-detokenized": "W 2000 roku Manuel Toharia, prelegent poprzednich Campus Parties i dyrektor Muzeum Nauki Pr\u00edncipe Felipe w Walencji zasugerowa\u0142, aby Ragageles rozszerzy\u0142 i uczyni\u0142 imprez\u0119 bardziej mi\u0119dzynarodow\u0105, przenosz\u0105c j\u0105 do s\u0142ynnego muzeum.", "token2charspan": [[0, 1], [2, 6], [7, 11], [12, 18], [19, 26], [26, 27], [28, 37], [38, 49], [50, 56], [57, 64], [65, 66], [67, 75], [76, 82], [83, 88], [89, 97], [98, 104], [105, 106], [107, 115], [116, 127], [127, 128], [129, 132], [133, 142], [143, 153], [154, 155], [156, 163], [164, 171], [172, 180], [181, 195], [195, 196], [197, 207], [208, 210], [211, 213], [214, 222], [223, 229], [229, 230]]}
{"doc_key": "ai-dev-92", "ner": [[4, 6, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["W", "ci\u0105gu", "20", "minut", "system", "rozpoznawania", "twarzy", "identyfikuje", "dane", "osobowe", ",", "w", "tym", "nazwisko", ",", "numer", "dowodu", "osobistego", "i", "adres", ",", "kt\u00f3re", "s\u0105", "wy\u015bwietlane", "na", "ulicy", "na", "ekranie", "reklamowym", "."], "sentence-detokenized": "W ci\u0105gu 20 minut system rozpoznawania twarzy identyfikuje dane osobowe, w tym nazwisko, numer dowodu osobistego i adres, kt\u00f3re s\u0105 wy\u015bwietlane na ulicy na ekranie reklamowym.", "token2charspan": [[0, 1], [2, 7], [8, 10], [11, 16], [17, 23], [24, 37], [38, 44], [45, 57], [58, 62], [63, 70], [70, 71], [72, 73], [74, 77], [78, 86], [86, 87], [88, 93], [94, 100], [101, 111], [112, 113], [114, 119], [119, 120], [121, 126], [127, 129], [130, 141], [142, 144], [145, 150], [151, 153], [154, 161], [162, 172], [172, 173]]}
{"doc_key": "ai-dev-93", "ner": [[8, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ostatnie", "badania", "coraz", "cz\u0119\u015bciej", "skupiaj\u0105", "si\u0119", "na", "algorytmach", "uczenia", "bez", "nadzoru", "i", "uczenia", "p\u00f3\u0142nadzorowanego", "."], "sentence-detokenized": "Ostatnie badania coraz cz\u0119\u015bciej skupiaj\u0105 si\u0119 na algorytmach uczenia bez nadzoru i uczenia p\u00f3\u0142nadzorowanego.", "token2charspan": [[0, 8], [9, 16], [17, 22], [23, 31], [32, 40], [41, 44], [45, 47], [48, 59], [60, 67], [68, 71], [72, 79], [80, 81], [82, 89], [90, 106], [106, 107]]}
{"doc_key": "ai-dev-94", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Obliczenie", "tego", "przyk\u0142adu", "za", "pomoc\u0105", "kodu", "Pythona", ":"], "sentence-detokenized": "Obliczenie tego przyk\u0142adu za pomoc\u0105 kodu Pythona:", "token2charspan": [[0, 10], [11, 15], [16, 25], [26, 28], [29, 35], [36, 40], [41, 48], [48, 49]]}
{"doc_key": "ai-dev-95", "ner": [[4, 6, "task"], [10, 12, "field"], [14, 18, "algorithm"], [20, 20, "algorithm"], [23, 25, "algorithm"], [28, 29, "researcher"], [31, 32, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[14, 18, 10, 12, "part-of", "", false, false], [14, 18, 23, 25, "type-of", "", false, false], [14, 18, 28, 29, "origin", "", false, false], [14, 18, 31, 32, "origin", "", false, false], [20, 20, 14, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Obecnie", "jednak", "wiele", "aspekt\u00f3w", "rozpoznawania", "mowy", "zosta\u0142o", "przej\u0119tych", "przez", "metod\u0119", "g\u0142\u0119bokiego", "uczenia", "o", "nazwie", "Long", "short", "-", "term", "memory", "(", "LSTM", ")", ",", "rekurencyjn\u0105", "sie\u0107", "neuronow\u0105", "opublikowan\u0105", "przez", "Seppa", "Hochreitera", "&", "J\u00fcrgena", "Schmidhubera", "w", "1997", "roku", "."], "sentence-detokenized": "Obecnie jednak wiele aspekt\u00f3w rozpoznawania mowy zosta\u0142o przej\u0119tych przez metod\u0119 g\u0142\u0119bokiego uczenia o nazwie Long short-term memory (LSTM), rekurencyjn\u0105 sie\u0107 neuronow\u0105 opublikowan\u0105 przez Seppa Hochreitera & J\u00fcrgena Schmidhubera w 1997 roku.", "token2charspan": [[0, 7], [8, 14], [15, 20], [21, 29], [30, 43], [44, 48], [49, 56], [57, 67], [68, 73], [74, 80], [81, 91], [92, 99], [100, 101], [102, 108], [109, 113], [114, 119], [119, 120], [120, 124], [125, 131], [132, 133], [133, 137], [137, 138], [138, 139], [140, 152], [153, 157], [158, 167], [168, 180], [181, 186], [187, 192], [193, 204], [205, 206], [207, 214], [215, 227], [228, 229], [230, 234], [235, 239], [239, 240]]}
{"doc_key": "ai-dev-96", "ner": [[9, 9, "algorithm"], [13, 13, "algorithm"], [16, 17, "algorithm"], [21, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 13, 13, "compare", "", false, false], [9, 9, 21, 21, "named", "same", false, false], [16, 17, 21, 21, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["We", "wst\u0119pnych", "wynikach", "eksperymentalnych", "z", "zaszumionymi", "zestawami", "danych", ",", "BrownBoost", "przewy\u017cszy\u0142", "b\u0142\u0119dem", "generalizacji", "AdaBoost", ";", "jednak", "LogitBoost", "wypad\u0142", "r\u00f3wnie", "dobrze", "jak", "BrownBoost", "."], "sentence-detokenized": "We wst\u0119pnych wynikach eksperymentalnych z zaszumionymi zestawami danych, BrownBoost przewy\u017cszy\u0142 b\u0142\u0119dem generalizacji AdaBoost; jednak LogitBoost wypad\u0142 r\u00f3wnie dobrze jak BrownBoost.", "token2charspan": [[0, 2], [3, 12], [13, 21], [22, 39], [40, 41], [42, 54], [55, 64], [65, 71], [71, 72], [73, 83], [84, 95], [96, 102], [103, 116], [117, 125], [125, 126], [127, 133], [134, 144], [145, 151], [152, 158], [159, 165], [166, 169], [170, 180], [180, 181]]}
{"doc_key": "ai-dev-97", "ner": [[0, 1, "algorithm"], [5, 8, "researcher"], [4, 4, "country"], [11, 13, "researcher"], [17, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 8, "part-of", "", false, false], [5, 8, 4, 4, "physical", "", false, false], [17, 17, 11, 13, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Programowanie", "ewolucyjne", "wprowadzi\u0142", "w", "USA", "Lawrence", "J", ".", "Fogel", ",", "natomiast", "John", "Henry", "Holland", "nazwa\u0142", "swoj\u0105", "metod\u0119", "algorytmem", "genetycznym", "."], "sentence-detokenized": "Programowanie ewolucyjne wprowadzi\u0142 w USA Lawrence J. Fogel, natomiast John Henry Holland nazwa\u0142 swoj\u0105 metod\u0119 algorytmem genetycznym.", "token2charspan": [[0, 13], [14, 24], [25, 35], [36, 37], [38, 41], [42, 50], [51, 52], [52, 53], [54, 59], [59, 60], [61, 70], [71, 75], [76, 81], [82, 89], [90, 96], [97, 102], [103, 109], [110, 120], [121, 132], [132, 133]]}
{"doc_key": "ai-dev-98", "ner": [[1, 1, "researcher"], [3, 3, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 1, 10, 11, "role", "", false, false], [1, 1, 13, 14, "role", "", false, false], [1, 1, 16, 17, "role", "", false, false], [1, 1, 19, 20, "role", "", false, false], [3, 3, 10, 11, "role", "", false, false], [3, 3, 13, 14, "role", "", false, false], [3, 3, 16, 17, "role", "", false, false], [3, 3, 19, 20, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Obliczenia", "Douga", ",", "Alana", "i", "ich", "koleg\u00f3w", "(", "w", "tym", "Marvina", "Minsky'ego", ",", "Allena", "Newella", ",", "Edwarda", "Feigenbauma", "i", "Johna", "McCarthy'ego", ")", "wskazywa\u0142y", ",", "\u017ce", "wysi\u0142ek", "ten", "wymaga\u0142by", "od", "1000", "do", "3000", "osobo", "-lat", "pracy", ",", "co", "znacznie", "przekracza", "standardowy", "model", "projektu", "akademickiego", "."], "sentence-detokenized": "Obliczenia Douga, Alana i ich koleg\u00f3w (w tym Marvina Minsky'ego, Allena Newella, Edwarda Feigenbauma i Johna McCarthy'ego) wskazywa\u0142y, \u017ce wysi\u0142ek ten wymaga\u0142by od 1000 do 3000 osobo-lat pracy, co znacznie przekracza standardowy model projektu akademickiego.", "token2charspan": [[0, 10], [11, 16], [16, 17], [18, 23], [24, 25], [26, 29], [30, 37], [38, 39], [39, 40], [41, 44], [45, 52], [53, 63], [63, 64], [65, 71], [72, 79], [79, 80], [81, 88], [89, 100], [101, 102], [103, 108], [109, 121], [121, 122], [123, 133], [133, 134], [135, 137], [138, 145], [146, 149], [150, 159], [160, 162], [163, 167], [168, 170], [171, 175], [176, 181], [181, 185], [186, 191], [191, 192], [193, 195], [196, 204], [205, 215], [216, 227], [228, 233], [234, 242], [243, 256], [256, 257]]}
{"doc_key": "ai-dev-99", "ner": [[4, 6, "metrics"], [9, 9, "metrics"], [11, 13, "metrics"], [16, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 9, 9, "part-of", "implemented_in", false, false], [11, 13, 16, 16, "part-of", "implemented_in", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Wsp\u00f3lnymi", "kryteriami", "s\u0105", "kryterium", "Mean", "Squared", "Error", "zaimplementowane", "w", "MSECriterion", "oraz", "kryterium", "entropii", "krzy\u017cowej", "zaimplementowane", "w", "NLLCriterion", "."], "sentence-detokenized": "Wsp\u00f3lnymi kryteriami s\u0105 kryterium Mean Squared Error zaimplementowane w MSECriterion oraz kryterium entropii krzy\u017cowej zaimplementowane w NLLCriterion.", "token2charspan": [[0, 9], [10, 20], [21, 23], [24, 33], [34, 38], [39, 46], [47, 52], [53, 69], [70, 71], [72, 84], [85, 89], [90, 99], [100, 108], [109, 118], [119, 135], [136, 137], [138, 150], [150, 151]]}
{"doc_key": "ai-dev-100", "ner": [[0, 0, "researcher"], [7, 7, "organisation"], [10, 16, "misc"], [24, 27, "conference"], [35, 36, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 7, 7, "role", "", false, false], [0, 0, 24, 27, "role", "", false, false], [0, 0, 35, 36, "role", "", false, false], [10, 16, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Zurada", "s\u0142u\u017cy\u0142", "profesji", "in\u017cynierskiej", "jako", "wieloletni", "wolontariusz", "IEEE", ":", "jako", "2014", "IEEE", "Vice-", "President", "-", "Technical", "Activities", "(", "TAB", "Chair", ")", ",", "jako", "prezydent", "IEEE", "Computational", "Intelligence", "Society", "w", "latach", "2004", "-", "05", "oraz", "cz\u0142onek", "ADCOM", "w", "latach", "2009", "-", "14", ",", "2016", "-", "18", "i", "wcze\u015bniejszych", "."], "sentence-detokenized": "Zurada s\u0142u\u017cy\u0142 profesji in\u017cynierskiej jako wieloletni wolontariusz IEEE: jako 2014 IEEE Vice-President-Technical Activities (TAB Chair), jako prezydent IEEE Computational Intelligence Society w latach 2004-05 oraz cz\u0142onek ADCOM w latach 2009-14, 2016-18 i wcze\u015bniejszych.", "token2charspan": [[0, 6], [7, 13], [14, 22], [23, 36], [37, 41], [42, 52], [53, 65], [66, 70], [70, 71], [72, 76], [77, 81], [82, 86], [87, 92], [92, 101], [101, 102], [102, 111], [112, 122], [123, 124], [124, 127], [128, 133], [133, 134], [134, 135], [136, 140], [141, 150], [151, 155], [156, 169], [170, 182], [183, 190], [191, 192], [193, 199], [200, 204], [204, 205], [205, 207], [208, 212], [213, 220], [221, 226], [227, 228], [229, 235], [236, 240], [240, 241], [241, 243], [243, 244], [245, 249], [249, 250], [250, 252], [253, 254], [255, 269], [269, 270]]}
{"doc_key": "ai-dev-101", "ner": [[5, 5, "field"], [13, 13, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 13, 5, 5, "part-of", "", false, false], [17, 18, 5, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Og\u00f3lnie", "rzecz", "bior\u0105c", ",", "lingwistyka", "obliczeniowa", "czerpie", "z", "zaanga\u017cowania", "m.in", ".", "lingwist\u00f3w", ",", "informatyk\u00f3w", ",", "specjalist\u00f3w", "od", "sztucznej", "inteligencji", ",", "matematyk\u00f3w", ",", "logik\u00f3w", ",", "filozof\u00f3w", ",", "kognitywist\u00f3w", ",", "psycholog\u00f3w", "poznawczych", ",", "psycholingwist\u00f3w", ",", "antropolog\u00f3w", "i", "neuronaukowc\u00f3w", "."], "sentence-detokenized": "Og\u00f3lnie rzecz bior\u0105c, lingwistyka obliczeniowa czerpie z zaanga\u017cowania m.in. lingwist\u00f3w, informatyk\u00f3w, specjalist\u00f3w od sztucznej inteligencji, matematyk\u00f3w, logik\u00f3w, filozof\u00f3w, kognitywist\u00f3w, psycholog\u00f3w poznawczych, psycholingwist\u00f3w, antropolog\u00f3w i neuronaukowc\u00f3w.", "token2charspan": [[0, 7], [8, 13], [14, 20], [20, 21], [22, 33], [34, 46], [47, 54], [55, 56], [57, 70], [71, 75], [75, 76], [77, 87], [87, 88], [89, 101], [101, 102], [103, 115], [116, 118], [119, 128], [129, 141], [141, 142], [143, 154], [154, 155], [156, 163], [163, 164], [165, 174], [174, 175], [176, 189], [189, 190], [191, 202], [203, 214], [214, 215], [216, 232], [232, 233], [234, 246], [247, 248], [249, 263], [263, 264]]}
{"doc_key": "ai-dev-102", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniki", "takie", "jak", "dynamiczne", "sieci", "Markowa", ",", "konwolucyjne", "sieci", "neuronowe", "i", "d\u0142uga", "pami\u0119\u0107", "kr\u00f3tkotrwa\u0142a", "s\u0105", "cz\u0119sto", "stosowane", "w", "celu", "wykorzystania", "korelacji", "mi\u0119dzy", "klatkami", "."], "sentence-detokenized": "Techniki takie jak dynamiczne sieci Markowa, konwolucyjne sieci neuronowe i d\u0142uga pami\u0119\u0107 kr\u00f3tkotrwa\u0142a s\u0105 cz\u0119sto stosowane w celu wykorzystania korelacji mi\u0119dzy klatkami.", "token2charspan": [[0, 8], [9, 14], [15, 18], [19, 29], [30, 35], [36, 43], [43, 44], [45, 57], [58, 63], [64, 73], [74, 75], [76, 81], [82, 88], [89, 101], [102, 104], [105, 111], [112, 121], [122, 123], [124, 128], [129, 142], [143, 152], [153, 159], [160, 168], [168, 169]]}
{"doc_key": "ai-dev-103", "ner": [[0, 0, "product"], [3, 4, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 3, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Unimate", "by\u0142", "pierwszym", "robotem", "przemys\u0142owym", ","], "sentence-detokenized": "Unimate by\u0142 pierwszym robotem przemys\u0142owym,", "token2charspan": [[0, 7], [8, 11], [12, 21], [22, 29], [30, 42], [42, 43]]}
{"doc_key": "ai-dev-104", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [10, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 10, 13, "win-defeat", "", false, false], [5, 6, 10, 13, "win-defeat", "", false, false], [8, 8, 10, 13, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Wraz", "z", "Geoffreyem", "Hintonem", "i", "Yannem", "LeCunem", ",", "Bengio", "zdoby\u0142", "nagrod\u0119", "Turing", "Award", "2018", "."], "sentence-detokenized": "Wraz z Geoffreyem Hintonem i Yannem LeCunem, Bengio zdoby\u0142 nagrod\u0119 Turing Award 2018.", "token2charspan": [[0, 4], [5, 6], [7, 17], [18, 26], [27, 28], [29, 35], [36, 43], [43, 44], [45, 51], [52, 58], [59, 66], [67, 73], [74, 79], [80, 84], [84, 85]]}
{"doc_key": "ai-dev-105", "ner": [[5, 6, "country"], [17, 20, "misc"], [25, 26, "country"], [28, 29, "organisation"], [33, 34, "person"], [37, 38, "person"], [48, 50, "misc"], [54, 54, "country"], [59, 59, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[17, 20, 5, 6, "physical", "filmed_in", false, false], [33, 34, 28, 29, "role", "host", false, false], [37, 38, 28, 29, "role", "reporter", false, false], [48, 50, 5, 6, "physical", "filmed_in", false, false], [48, 50, 54, 54, "physical", "distributed_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Dodatkowe", "serie", "zosta\u0142y", "nakr\u0119cone", "w", "Wielkiej", "Brytanii", "dla", "poszczeg\u00f3lnych", "sektor\u00f3w", "rynku", "globalnego", ",", "w", "tym", "dwie", "serie", "Robot", "Wars", "Extreme", "Warriors", "z", "udzia\u0142em", "zawodnik\u00f3w", "ze", "Stan\u00f3w", "Zjednoczonych", "dla", "sieci", "TNN", "(", "gospodarzem", "by\u0142", "Mick", "Foley", ",", "a", "Rebecca", "Grant", "pe\u0142ni\u0142a", "rol\u0119", "reportera", "z", "kana\u0142u", ")", ",", "dwie", "serie", "Dutch", "Robot", "Wars", "dla", "dystrybucji", "w", "Holandii", "oraz", "jedna", "seria", "dla", "Niemiec", "."], "sentence-detokenized": "Dodatkowe serie zosta\u0142y nakr\u0119cone w Wielkiej Brytanii dla poszczeg\u00f3lnych sektor\u00f3w rynku globalnego, w tym dwie serie Robot Wars Extreme Warriors z udzia\u0142em zawodnik\u00f3w ze Stan\u00f3w Zjednoczonych dla sieci TNN (gospodarzem by\u0142 Mick Foley, a Rebecca Grant pe\u0142ni\u0142a rol\u0119 reportera z kana\u0142u), dwie serie Dutch Robot Wars dla dystrybucji w Holandii oraz jedna seria dla Niemiec.", "token2charspan": [[0, 9], [10, 15], [16, 23], [24, 33], [34, 35], [36, 44], [45, 53], [54, 57], [58, 72], [73, 81], [82, 87], [88, 98], [98, 99], [100, 101], [102, 105], [106, 110], [111, 116], [117, 122], [123, 127], [128, 135], [136, 144], [145, 146], [147, 155], [156, 166], [167, 169], [170, 176], [177, 190], [191, 194], [195, 200], [201, 204], [205, 206], [206, 217], [218, 221], [222, 226], [227, 232], [232, 233], [234, 235], [236, 243], [244, 249], [250, 257], [258, 262], [263, 272], [273, 274], [275, 281], [281, 282], [282, 283], [284, 288], [289, 294], [295, 300], [301, 306], [307, 311], [312, 315], [316, 327], [328, 329], [330, 338], [339, 343], [344, 349], [350, 355], [356, 359], [360, 367], [367, 368]]}
{"doc_key": "ai-dev-106", "ner": [[9, 9, "researcher"], [12, 12, "product"], [27, 27, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 12, 12, "role", "", false, false], [27, 27, 12, 12, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Przez", "wiele", "lat", ",", "pocz\u0105wszy", "od", "1986", "roku", ",", "Miller", "kierowa\u0142", "rozwojem", "WordNetu", ",", "du\u017cego", ",", "odczytywanego", "przez", "komputer", "elektronicznego", "odno\u015bnika", ",", "wykorzystywanego", "w", "takich", "aplikacjach", "jak", "wyszukiwarki", "."], "sentence-detokenized": "Przez wiele lat, pocz\u0105wszy od 1986 roku, Miller kierowa\u0142 rozwojem WordNetu, du\u017cego, odczytywanego przez komputer elektronicznego odno\u015bnika, wykorzystywanego w takich aplikacjach jak wyszukiwarki.", "token2charspan": [[0, 5], [6, 11], [12, 15], [15, 16], [17, 26], [27, 29], [30, 34], [35, 39], [39, 40], [41, 47], [48, 56], [57, 65], [66, 74], [74, 75], [76, 82], [82, 83], [84, 97], [98, 103], [104, 112], [113, 128], [129, 138], [138, 139], [140, 156], [157, 158], [159, 165], [166, 177], [178, 181], [182, 194], [194, 195]]}
{"doc_key": "ai-dev-107", "ner": [[3, 5, "algorithm"], [7, 11, "algorithm"], [16, 17, "researcher"], [19, 23, "organisation"], [26, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 5, 16, 17, "origin", "", false, false], [3, 5, 26, 29, "win-defeat", "", false, false], [7, 11, 16, 17, "origin", "", false, false], [7, 11, 26, 29, "win-defeat", "", false, false], [16, 17, 19, 23, "physical", "", false, false], [16, 17, 19, 23, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Od", "2009", "roku", "rekurencyjne", "sieci", "neuronowe", "i", "g\u0142\u0119bokie", "sieci", "neuronowe", "typu", "feedforward", "opracowane", "w", "grupie", "badawczej", "J\u00fcrgena", "Schmidhubera", "w", "szwajcarskim", "laboratorium", "AI", "Lab", "IDSIA", "wygra\u0142y", "kilka", "mi\u0119dzynarodowych", "konkurs\u00f3w", "pisma", "r\u0119cznego", ".", ".", ".", "."], "sentence-detokenized": "Od 2009 roku rekurencyjne sieci neuronowe i g\u0142\u0119bokie sieci neuronowe typu feedforward opracowane w grupie badawczej J\u00fcrgena Schmidhubera w szwajcarskim laboratorium AI Lab IDSIA wygra\u0142y kilka mi\u0119dzynarodowych konkurs\u00f3w pisma r\u0119cznego....", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 25], [26, 31], [32, 41], [42, 43], [44, 52], [53, 58], [59, 68], [69, 73], [74, 85], [86, 96], [97, 98], [99, 105], [106, 115], [116, 123], [124, 136], [137, 138], [139, 151], [152, 164], [165, 167], [168, 171], [172, 177], [178, 185], [186, 191], [192, 208], [209, 218], [219, 224], [225, 233], [233, 234], [234, 235], [235, 236], [236, 237]]}
{"doc_key": "ai-dev-108", "ner": [[4, 6, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Oprogramowanie", "jest", "zaimplementowane", "w", "C", "+", "+", "i", "jest", "opakowane", "dla", "Pythona", "."], "sentence-detokenized": "Oprogramowanie jest zaimplementowane w C ++ i jest opakowane dla Pythona.", "token2charspan": [[0, 14], [15, 19], [20, 36], [37, 38], [39, 40], [41, 42], [42, 43], [44, 45], [46, 50], [51, 60], [61, 64], [65, 72], [72, 73]]}
{"doc_key": "ai-dev-109", "ner": [[6, 7, "country"], [10, 11, "misc"], [15, 16, "misc"], [29, 30, "misc"], [31, 31, "misc"], [34, 34, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[15, 16, 6, 7, "temporal", "", false, false], [15, 16, 10, 11, "artifact", "", false, false], [15, 16, 34, 34, "physical", "", false, false], [31, 31, 29, 30, "named", "", false, false], [31, 31, 34, 34, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["W", "1857", "roku", ",", "na", "pro\u015bb\u0119", "szogunatu", "Tokugawy", ",", "grupa", "holenderskich", "in\u017cynier\u00f3w", "rozpocz\u0119\u0142a", "prace", "nad", "Nagasaki", "Yotetsusho", ",", "nowoczesn\u0105", ",", "zbudowan\u0105", "w", "zachodnim", "stylu", "odlewni\u0105", "i", "stoczni\u0105", "w", "pobli\u017cu", "holenderskiej", "osady", "Dejima", ",", "w", "Nagasaki", "."], "sentence-detokenized": "W 1857 roku, na pro\u015bb\u0119 szogunatu Tokugawy, grupa holenderskich in\u017cynier\u00f3w rozpocz\u0119\u0142a prace nad Nagasaki Yotetsusho, nowoczesn\u0105, zbudowan\u0105 w zachodnim stylu odlewni\u0105 i stoczni\u0105 w pobli\u017cu holenderskiej osady Dejima, w Nagasaki.", "token2charspan": [[0, 1], [2, 6], [7, 11], [11, 12], [13, 15], [16, 22], [23, 32], [33, 41], [41, 42], [43, 48], [49, 62], [63, 73], [74, 84], [85, 90], [91, 94], [95, 103], [104, 114], [114, 115], [116, 126], [126, 127], [128, 137], [138, 139], [140, 149], [150, 155], [156, 164], [165, 166], [167, 175], [176, 177], [178, 185], [186, 199], [200, 205], [206, 212], [212, 213], [214, 215], [216, 224], [224, 225]]}
{"doc_key": "ai-dev-110", "ner": [[6, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Czynimy", "jak", "najlepiej", "precyzyjnym", ",", "mierz\u0105c", "\u015bredni", "b\u0142\u0105d", "kwadratowy", "mi\u0119dzy", "math\u0105", "/", "math\u0105", "a", "math\u0105", "{", "f", "}", "(", "x", ";", "D", ")", "/", "math\u0105", ":", "chcemy", ",", "aby", "math", "(", "y", "-the", "hat", "{", "f", "}", "(", "x", ";", "D", ")", ")", "^", "2", "/", "math", ",", "aby", "by\u0142", "minimalny", ",", "zar\u00f3wno", "dla", "mathx", "_", "1", ",", "^", "kropki", ",", "x", "_n", "/", "math", ",", "jak", "i", "dla", "punkt\u00f3w", "spoza", "naszej", "pr\u00f3bki", "."], "sentence-detokenized": "Czynimy jak najlepiej precyzyjnym, mierz\u0105c \u015bredni b\u0142\u0105d kwadratowy mi\u0119dzy math\u0105 / math\u0105 a math\u0105 {f} (x; D) / math\u0105: chcemy, aby math (y -the hat {f} (x; D)) ^ 2 / math, aby by\u0142 minimalny, zar\u00f3wno dla mathx _ 1, ^ kropki, x _n / math, jak i dla punkt\u00f3w spoza naszej pr\u00f3bki.", "token2charspan": [[0, 7], [8, 11], [12, 21], [22, 33], [33, 34], [35, 42], [43, 49], [50, 54], [55, 65], [66, 72], [73, 78], [79, 80], [81, 86], [87, 88], [89, 94], [95, 96], [96, 97], [97, 98], [99, 100], [100, 101], [101, 102], [103, 104], [104, 105], [106, 107], [108, 113], [113, 114], [115, 121], [121, 122], [123, 126], [127, 131], [132, 133], [133, 134], [135, 139], [140, 143], [144, 145], [145, 146], [146, 147], [148, 149], [149, 150], [150, 151], [152, 153], [153, 154], [154, 155], [156, 157], [158, 159], [160, 161], [162, 166], [166, 167], [168, 171], [172, 175], [176, 185], [185, 186], [187, 194], [195, 198], [199, 204], [205, 206], [207, 208], [208, 209], [210, 211], [212, 218], [218, 219], [220, 221], [222, 224], [225, 226], [227, 231], [231, 232], [233, 236], [237, 238], [239, 242], [243, 250], [251, 256], [257, 263], [264, 270], [270, 271]]}
{"doc_key": "ai-dev-111", "ner": [[2, 3, "researcher"], [6, 8, "organisation"], [19, 23, "product"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 6, 8, "role", "", false, false], [19, 23, 6, 8, "temporal", "", false, false], [19, 23, 28, 29, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Nast\u0119pnie", "zaprosi\u0142", "Wydnera", "na", "doroczne", "spotkanie", "Ameryka\u0144skiego", "Stowarzyszenia", "T\u0142umaczy", ",", "kt\u00f3re", "odby\u0142o", "si\u0119", "w", "pa\u017adzierniku", "nast\u0119pnego", "roku", ",", "gdzie", "system", "Weidner", "Machine", "Translation", "System", "zosta\u0142", "okrzykni\u0119ty", "prze\u0142omem", "w", "t\u0142umaczeniu", "maszynowym", "."], "sentence-detokenized": "Nast\u0119pnie zaprosi\u0142 Wydnera na doroczne spotkanie Ameryka\u0144skiego Stowarzyszenia T\u0142umaczy, kt\u00f3re odby\u0142o si\u0119 w pa\u017adzierniku nast\u0119pnego roku, gdzie system Weidner Machine Translation System zosta\u0142 okrzykni\u0119ty prze\u0142omem w t\u0142umaczeniu maszynowym.", "token2charspan": [[0, 9], [10, 18], [19, 26], [27, 29], [30, 38], [39, 48], [49, 63], [64, 78], [79, 87], [87, 88], [89, 94], [95, 101], [102, 105], [106, 107], [108, 120], [121, 131], [132, 136], [136, 137], [138, 143], [144, 150], [151, 158], [159, 166], [167, 178], [179, 185], [186, 192], [193, 204], [205, 214], [215, 216], [217, 228], [229, 239], [239, 240]]}
{"doc_key": "ai-dev-112", "ner": [[1, 7, "conference"], [9, 9, "conference"], [13, 13, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 1, 7, "named", "", false, false], [9, 9, 1, 7, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Podczas", "2018", "Conference", "on", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", "badacze", "z", "Google", "zaprezentowali", "prac\u0119", "."], "sentence-detokenized": "Podczas 2018 Conference on Neural Information Processing Systems (NeurIPS) badacze z Google zaprezentowali prac\u0119.", "token2charspan": [[0, 7], [8, 12], [13, 23], [24, 26], [27, 33], [34, 45], [46, 56], [57, 64], [65, 66], [66, 73], [73, 74], [75, 82], [83, 84], [85, 91], [92, 106], [107, 112], [112, 113]]}
{"doc_key": "ai-dev-113", "ner": [[0, 3, "algorithm"], [8, 8, "algorithm"], [11, 13, "metrics"], [15, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 8, 8, "usage", "", false, false], [8, 8, 11, 13, "related-to", "", true, false], [11, 13, 15, 17, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Algorytm", "Bauma", "-", "Welcha", "wykorzystuje", "dobrze", "znany", "algorytm", "EM", "do", "znalezienia", "maksymalnego", "prawdopodobie\u0144stwa", "oszacowania", "parametr\u00f3w", "ukrytego", "modelu", "Markowa", ",", "bior\u0105c", "pod", "uwag\u0119", "zbi\u00f3r", "obserwowanych", "wektor\u00f3w", "cech", "."], "sentence-detokenized": "Algorytm Bauma-Welcha wykorzystuje dobrze znany algorytm EM do znalezienia maksymalnego prawdopodobie\u0144stwa oszacowania parametr\u00f3w ukrytego modelu Markowa, bior\u0105c pod uwag\u0119 zbi\u00f3r obserwowanych wektor\u00f3w cech.", "token2charspan": [[0, 8], [9, 14], [14, 15], [15, 21], [22, 34], [35, 41], [42, 47], [48, 56], [57, 59], [60, 62], [63, 74], [75, 87], [88, 106], [107, 118], [119, 129], [130, 138], [139, 145], [146, 153], [153, 154], [155, 161], [162, 165], [166, 171], [172, 177], [178, 191], [192, 200], [201, 205], [205, 206]]}
{"doc_key": "ai-dev-114", "ner": [[5, 5, "product"], [7, 7, "product"], [25, 26, "misc"], [30, 37, "product"], [41, 41, "programlang"], [42, 47, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 5, 7, 7, "compare", "", false, false], [25, 26, 7, 7, "part-of", "", false, false], [30, 37, 7, 7, "part-of", "", false, false], [42, 47, 7, 7, "part-of", "", false, false], [42, 47, 41, 41, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Opr\u00f3cz", "informacji", "taksonomicznych", "zawartych", "w", "OpenCyc", ",", "ResearchCyc", "zawiera", "znacznie", "wi\u0119cej", "wiedzy", "semantycznej", "(", "tj", ".", "dodatkowe", "fakty", "i", "zasady", ")", "dotycz\u0105cej", "poj\u0119\u0107", "w", "swojej", "bazie", "wiedzy", ";", "zawiera", "r\u00f3wnie\u017c", "du\u017cy", "leksykon", ",", "angielskie", "narz\u0119dzia", "parsowania", "i", "generowania", "oraz", "oparte", "na", "Javie", "interfejsy", "do", "edycji", "wiedzy", "i", "zapyta\u0144", "."], "sentence-detokenized": "Opr\u00f3cz informacji taksonomicznych zawartych w OpenCyc, ResearchCyc zawiera znacznie wi\u0119cej wiedzy semantycznej (tj. dodatkowe fakty i zasady) dotycz\u0105cej poj\u0119\u0107 w swojej bazie wiedzy; zawiera r\u00f3wnie\u017c du\u017cy leksykon, angielskie narz\u0119dzia parsowania i generowania oraz oparte na Javie interfejsy do edycji wiedzy i zapyta\u0144.", "token2charspan": [[0, 6], [7, 17], [18, 33], [34, 43], [44, 45], [46, 53], [53, 54], [55, 66], [67, 74], [75, 83], [84, 90], [91, 97], [98, 110], [111, 112], [112, 114], [114, 115], [116, 125], [126, 131], [132, 133], [134, 140], [140, 141], [142, 152], [153, 158], [159, 160], [161, 167], [168, 173], [174, 180], [180, 181], [182, 189], [190, 197], [198, 202], [203, 211], [211, 212], [213, 223], [224, 233], [234, 244], [245, 246], [247, 258], [259, 263], [264, 270], [271, 273], [274, 279], [280, 290], [291, 293], [294, 300], [301, 307], [308, 309], [310, 317], [317, 318]]}
{"doc_key": "ai-dev-115", "ner": [[0, 1, "algorithm"], [4, 5, "task"], [8, 8, "field"], [11, 12, "field"], [14, 16, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 4, 5, "type-of", "", false, false], [4, 5, 8, 8, "part-of", "task_part_of_field", false, false], [4, 5, 11, 12, "part-of", "task_part_of_field", false, false], [4, 5, 14, 16, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Transformata", "Hougha", "jest", "technik\u0105", "ekstrakcji", "cech", "stosowan\u0105", "w", "analizie", "obraz\u00f3w", ",", "wizji", "komputerowej", "i", "cyfrowym", "przetwarzaniu", "obraz\u00f3w", "."], "sentence-detokenized": "Transformata Hougha jest technik\u0105 ekstrakcji cech stosowan\u0105 w analizie obraz\u00f3w, wizji komputerowej i cyfrowym przetwarzaniu obraz\u00f3w.", "token2charspan": [[0, 12], [13, 19], [20, 24], [25, 33], [34, 44], [45, 49], [50, 59], [60, 61], [62, 70], [71, 78], [78, 79], [80, 85], [86, 98], [99, 100], [101, 109], [110, 123], [124, 131], [131, 132]]}
{"doc_key": "ai-dev-116", "ner": [[4, 4, "product"], [6, 10, "product"], [16, 16, "organisation"], [18, 18, "product"], [20, 21, "researcher"], [26, 27, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 4, 6, 10, "named", "", false, false], [4, 4, 16, 16, "artifact", "", false, false], [4, 4, 18, 18, "origin", "developed_from", false, false], [18, 18, 20, 21, "artifact", "", false, false], [26, 27, 16, 16, "role", "supported", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["W", "1978", "roku", "robot", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", "zosta\u0142", "opracowany", "przez", "firm\u0119", "Unimation", "z", "Vicarm", "(", "Victor", "Scheinman", ")", "i", "przy", "wsparciu", "General", "Motors", "."], "sentence-detokenized": "W 1978 roku robot PUMA (Programmable Universal Machine for Assembly) zosta\u0142 opracowany przez firm\u0119 Unimation z Vicarm (Victor Scheinman) i przy wsparciu General Motors.", "token2charspan": [[0, 1], [2, 6], [7, 11], [12, 17], [18, 22], [23, 24], [24, 36], [37, 46], [47, 54], [55, 58], [59, 67], [67, 68], [69, 75], [76, 86], [87, 92], [93, 98], [99, 108], [109, 110], [111, 117], [118, 119], [119, 125], [126, 135], [135, 136], [137, 138], [139, 143], [144, 152], [153, 160], [161, 167], [167, 168]]}
{"doc_key": "ai-dev-117", "ner": [[0, 0, "algorithm"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 7, 8, "origin", "", false, false], [0, 0, 10, 11, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["LSTM", "zosta\u0142a", "zaproponowana", "w", "1997", "roku", "przez", "Seppa", "Hochreitera", "i", "J\u00fcrgena", "Schmidhubera", "."], "sentence-detokenized": "LSTM zosta\u0142a zaproponowana w 1997 roku przez Seppa Hochreitera i J\u00fcrgena Schmidhubera.", "token2charspan": [[0, 4], [5, 12], [13, 26], [27, 28], [29, 33], [34, 38], [39, 44], [45, 50], [51, 62], [63, 64], [65, 72], [73, 85], [85, 86]]}
{"doc_key": "ai-dev-118", "ner": [[6, 7, "metrics"], [12, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Cztery", "wyniki", "mo\u017cna", "sformu\u0142owa\u0107", "w", "postaci", "tabeli", "kontyngencji", "2", "\u00d7", "2", "lub", "macierzy", "konfuzji", ",", "w", "nast\u0119puj\u0105cy", "spos\u00f3b", ":"], "sentence-detokenized": "Cztery wyniki mo\u017cna sformu\u0142owa\u0107 w postaci tabeli kontyngencji 2 \u00d7 2 lub macierzy konfuzji, w nast\u0119puj\u0105cy spos\u00f3b:", "token2charspan": [[0, 6], [7, 13], [14, 19], [20, 31], [32, 33], [34, 41], [42, 48], [49, 61], [62, 63], [64, 65], [66, 67], [68, 71], [72, 80], [81, 89], [89, 90], [91, 92], [93, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-dev-119", "ner": [[5, 5, "conference"], [7, 8, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Wiele", "wni\u00f3s\u0142", "r\u00f3wnie\u017c", "poprzez", "utworzenie", "ELRA", "i", "konferencji", "LREC", "."], "sentence-detokenized": "Wiele wni\u00f3s\u0142 r\u00f3wnie\u017c poprzez utworzenie ELRA i konferencji LREC.", "token2charspan": [[0, 5], [6, 12], [13, 20], [21, 28], [29, 39], [40, 44], [45, 46], [47, 58], [59, 63], [63, 64]]}
{"doc_key": "ai-dev-120", "ner": [[9, 10, "misc"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 18, 9, 10, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Popularnym", "zastosowaniem", "robot\u00f3w", "seryjnych", "w", "dzisiejszym", "przemy\u015ble", "jest", "robot", "monta\u017cowy", "typu", "pick-", "and", "-", "place", ",", "zwany", "robotem", "SCARA", ",", "kt\u00f3ry", "posiada", "cztery", "stopnie", "swobody", "."], "sentence-detokenized": "Popularnym zastosowaniem robot\u00f3w seryjnych w dzisiejszym przemy\u015ble jest robot monta\u017cowy typu pick-and-place, zwany robotem SCARA, kt\u00f3ry posiada cztery stopnie swobody.", "token2charspan": [[0, 10], [11, 24], [25, 32], [33, 42], [43, 44], [45, 56], [57, 66], [67, 71], [72, 77], [78, 87], [88, 92], [93, 98], [98, 101], [101, 102], [102, 107], [107, 108], [109, 114], [115, 122], [123, 128], [128, 129], [130, 135], [136, 143], [144, 150], [151, 158], [159, 166], [166, 167]]}
{"doc_key": "ai-dev-121", "ner": [[13, 19, "conference"], [21, 21, "conference"], [24, 27, "conference"], [35, 35, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 21, 13, 19, "named", "", false, false], [35, 35, 24, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Jest", "jednym", "z", "cz\u0142onk\u00f3w", "za\u0142o\u017cycieli", "i", "by\u0142ym", "przewodnicz\u0105cym", "(", "2006", "-", "2008", ")", "Special", "Interest", "Group", "on", "Web", "as", "Corpus", "(", "SIGWAC", ")", "w", "Association", "for", "Computational", "Linguistics", ",", "a", "tak\u017ce", "jednym", "z", "za\u0142o\u017cycieli", "organizator\u00f3w", "SENSEVAL", "."], "sentence-detokenized": "Jest jednym z cz\u0142onk\u00f3w za\u0142o\u017cycieli i by\u0142ym przewodnicz\u0105cym (2006-2008) Special Interest Group on Web as Corpus (SIGWAC) w Association for Computational Linguistics, a tak\u017ce jednym z za\u0142o\u017cycieli organizator\u00f3w SENSEVAL.", "token2charspan": [[0, 4], [5, 11], [12, 13], [14, 22], [23, 34], [35, 36], [37, 42], [43, 58], [59, 60], [60, 64], [64, 65], [65, 69], [69, 70], [71, 78], [79, 87], [88, 93], [94, 96], [97, 100], [101, 103], [104, 110], [111, 112], [112, 118], [118, 119], [120, 121], [122, 133], [134, 137], [138, 151], [152, 163], [163, 164], [165, 166], [167, 172], [173, 179], [180, 181], [182, 193], [194, 207], [208, 216], [216, 217]]}
{"doc_key": "ai-dev-122", "ner": [[3, 3, "product"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 3, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Jako", "platforma", ",", "LinguaStream", "udost\u0119pnia", "rozbudowane", "Java", "API", "."], "sentence-detokenized": "Jako platforma, LinguaStream udost\u0119pnia rozbudowane Java API.", "token2charspan": [[0, 4], [5, 14], [14, 15], [16, 28], [29, 39], [40, 51], [52, 56], [57, 60], [60, 61]]}
{"doc_key": "ai-dev-123", "ner": [[15, 15, "programlang"], [17, 19, "misc"], [22, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 15, 22, 24, "type-of", "", false, false], [17, 19, 22, 24, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Zestaw", "robota", "jest", "oparty", "na", "systemie", "Android", ",", "a", "jego", "programowanie", "odbywa", "si\u0119", "przy", "u\u017cyciu", "Javy", ",", "interfejsu", "programowania", "Blocks", "lub", "innych", "system\u00f3w", "programowania", "Androida", "."], "sentence-detokenized": "Zestaw robota jest oparty na systemie Android, a jego programowanie odbywa si\u0119 przy u\u017cyciu Javy, interfejsu programowania Blocks lub innych system\u00f3w programowania Androida.", "token2charspan": [[0, 6], [7, 13], [14, 18], [19, 25], [26, 28], [29, 37], [38, 45], [45, 46], [47, 48], [49, 53], [54, 67], [68, 74], [75, 78], [79, 83], [84, 90], [91, 95], [95, 96], [97, 107], [108, 121], [122, 128], [129, 132], [133, 139], [140, 148], [149, 162], [163, 171], [171, 172]]}
{"doc_key": "ai-dev-124", "ner": [[6, 11, "algorithm"], [14, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Metoda", "definiowania", "listy", "po\u0142\u0105czonej", "okre\u015bla", "zastosowanie", "wyszukiwania", "wg\u0142\u0119bnego", "(", "depth-", "first", "search", ")", "lub", "wyszukiwania", "wg\u0142\u0119bnego", "(", "breadth-", "first", "search", ")", "."], "sentence-detokenized": "Metoda definiowania listy po\u0142\u0105czonej okre\u015bla zastosowanie wyszukiwania wg\u0142\u0119bnego (depth-first search) lub wyszukiwania wg\u0142\u0119bnego (breadth-first search).", "token2charspan": [[0, 6], [7, 19], [20, 25], [26, 36], [37, 44], [45, 57], [58, 70], [71, 80], [81, 82], [82, 88], [88, 93], [94, 100], [100, 101], [102, 105], [106, 118], [119, 128], [129, 130], [130, 138], [138, 143], [144, 150], [150, 151], [151, 152]]}
{"doc_key": "ai-dev-125", "ner": [[15, 16, "task"], [20, 22, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Regiony", "te", "mog\u0105", "sygnalizowa\u0107", "obecno\u015b\u0107", "obiekt\u00f3w", "lub", "cz\u0119\u015bci", "obiekt\u00f3w", "w", "domenie", "obrazu", "z", "zastosowaniem", "do", "rozpoznawania", "obiekt\u00f3w", "i", "/", "lub", "\u015bledzenia", "wideo", "obiekt\u00f3w", "."], "sentence-detokenized": "Regiony te mog\u0105 sygnalizowa\u0107 obecno\u015b\u0107 obiekt\u00f3w lub cz\u0119\u015bci obiekt\u00f3w w domenie obrazu z zastosowaniem do rozpoznawania obiekt\u00f3w i / lub \u015bledzenia wideo obiekt\u00f3w.", "token2charspan": [[0, 7], [8, 10], [11, 15], [16, 28], [29, 37], [38, 46], [47, 50], [51, 57], [58, 66], [67, 68], [69, 76], [77, 83], [84, 85], [86, 99], [100, 102], [103, 116], [117, 125], [126, 127], [128, 129], [130, 133], [134, 143], [144, 149], [150, 158], [158, 159]]}
{"doc_key": "ai-dev-126", "ner": [[1, 2, "algorithm"], [4, 4, "product"], [10, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 1, 2, "type-of", "", false, false], [4, 4, 10, 10, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Przyk\u0142adem", "sieci", "semantycznej", "jest", "WordNet", ",", "leksykalna", "baza", "danych", "j\u0119zyka", "angielskiego", "."], "sentence-detokenized": "Przyk\u0142adem sieci semantycznej jest WordNet, leksykalna baza danych j\u0119zyka angielskiego.", "token2charspan": [[0, 10], [11, 16], [17, 29], [30, 34], [35, 42], [42, 43], [44, 54], [55, 59], [60, 66], [67, 73], [74, 86], [86, 87]]}
{"doc_key": "ai-dev-127", "ner": [[0, 1, "task"], [5, 5, "field"], [7, 8, "field"], [16, 20, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 5, 5, "part-of", "", false, false], [0, 1, 7, 8, "named", "same", false, false], [0, 1, 7, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Rozpoznawanie", "mowy", "to", "interdyscyplinarna", "dziedzina", "informatyki", "i", "lingwistyki", "obliczeniowej", ",", "kt\u00f3ra", "rozwija", "metodologie", "i", "technologie", "umo\u017cliwiaj\u0105ce", "rozpoznawanie", "i", "t\u0142umaczenie", "j\u0119zyka", "m\u00f3wionego", "na", "tekst", "przez", "komputery", "."], "sentence-detokenized": "Rozpoznawanie mowy to interdyscyplinarna dziedzina informatyki i lingwistyki obliczeniowej, kt\u00f3ra rozwija metodologie i technologie umo\u017cliwiaj\u0105ce rozpoznawanie i t\u0142umaczenie j\u0119zyka m\u00f3wionego na tekst przez komputery.", "token2charspan": [[0, 13], [14, 18], [19, 21], [22, 40], [41, 50], [51, 62], [63, 64], [65, 76], [77, 90], [90, 91], [92, 97], [98, 105], [106, 117], [118, 119], [120, 131], [132, 145], [146, 159], [160, 161], [162, 173], [174, 180], [181, 190], [191, 193], [194, 199], [200, 205], [206, 215], [215, 216]]}
{"doc_key": "ai-dev-128", "ner": [[0, 1, "field"], [8, 10, "misc"], [14, 17, "field"], [19, 19, "task"], [21, 22, "task"], [43, 43, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 43, 43, "named", "same", false, false], [14, 17, 0, 1, "part-of", "subfield", false, false], [19, 19, 0, 1, "part-of", "", false, false], [19, 19, 14, 17, "part-of", "", false, false], [21, 22, 14, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Sztuczna", "inteligencja", "zachowa\u0142a", "najwi\u0119cej", "uwagi", "w", "odniesieniu", "do", "ontologii", "stosowanej", "w", "takich", "subdyscyplinach", "jak", "przetwarzanie", "j\u0119zyka", "naturalnego", "w", "ramach", "maszyn", "i", "reprezentacji", "wiedzy", ",", "ale", "edytory", "ontologii", "s\u0105", "cz\u0119sto", "u\u017cywane", "w", "wielu", "dziedzinach", ",", "takich", "jak", "edukacja", ",", "bez", "zamiaru", "przyczyniania", "si\u0119", "do", "AI", "."], "sentence-detokenized": "Sztuczna inteligencja zachowa\u0142a najwi\u0119cej uwagi w odniesieniu do ontologii stosowanej w takich subdyscyplinach jak przetwarzanie j\u0119zyka naturalnego w ramach maszyn i reprezentacji wiedzy, ale edytory ontologii s\u0105 cz\u0119sto u\u017cywane w wielu dziedzinach, takich jak edukacja, bez zamiaru przyczyniania si\u0119 do AI.", "token2charspan": [[0, 8], [9, 21], [22, 31], [32, 41], [42, 47], [48, 49], [50, 61], [62, 64], [65, 74], [75, 85], [86, 87], [88, 94], [95, 110], [111, 114], [115, 128], [129, 135], [136, 147], [148, 149], [150, 156], [157, 163], [164, 165], [166, 179], [180, 186], [186, 187], [188, 191], [192, 199], [200, 209], [210, 212], [213, 219], [220, 227], [228, 229], [230, 235], [236, 247], [247, 248], [249, 255], [256, 259], [260, 268], [268, 269], [270, 273], [274, 281], [282, 295], [296, 299], [300, 302], [303, 305], [305, 306]]}
{"doc_key": "ai-dev-129", "ner": [[7, 9, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 9, 11, 12, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Ta", "zasada", "aktualizacji", "jest", "w", "rzeczywisto\u015bci", "aktualizacj\u0105", "stochastycznego", "zej\u015bcia", "gradientowego", "dla", "regresji", "liniowej", "."], "sentence-detokenized": "Ta zasada aktualizacji jest w rzeczywisto\u015bci aktualizacj\u0105 stochastycznego zej\u015bcia gradientowego dla regresji liniowej.", "token2charspan": [[0, 2], [3, 9], [10, 22], [23, 27], [28, 29], [30, 44], [45, 57], [58, 73], [74, 81], [82, 95], [96, 99], [100, 108], [109, 117], [117, 118]]}
{"doc_key": "ai-dev-130", "ner": [[3, 8, "organisation"], [10, 14, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Zosta\u0142", "wybrany", "do", "American", "Academy", "of", "Arts", "and", "Sciences", "oraz", "National", "Academy", "of", "Sciences", "i", "otrzyma\u0142", "szereg", "nagr\u00f3d", ":"], "sentence-detokenized": "Zosta\u0142 wybrany do American Academy of Arts and Sciences oraz National Academy of Sciences i otrzyma\u0142 szereg nagr\u00f3d:", "token2charspan": [[0, 6], [7, 14], [15, 17], [18, 26], [27, 34], [35, 37], [38, 42], [43, 46], [47, 55], [56, 60], [61, 69], [70, 77], [78, 80], [81, 89], [90, 91], [92, 100], [101, 107], [108, 114], [114, 115]]}
{"doc_key": "ai-dev-131", "ner": [[9, 10, "person"], [12, 16, "person"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Najnowsza", "szko\u0142a", "my\u015blenia", "o", "strategii", "Hondy", "zosta\u0142a", "wysuni\u0119ta", "przez", "Gary'ego", "Hamela", "i", "C", ".", "K", ".", "Prahalada", "w", "1989", "roku", "."], "sentence-detokenized": "Najnowsza szko\u0142a my\u015blenia o strategii Hondy zosta\u0142a wysuni\u0119ta przez Gary'ego Hamela i C. K. Prahalada w 1989 roku.", "token2charspan": [[0, 9], [10, 16], [17, 25], [26, 27], [28, 37], [38, 43], [44, 51], [52, 61], [62, 67], [68, 76], [77, 83], [84, 85], [86, 87], [87, 88], [89, 90], [90, 91], [92, 101], [102, 103], [104, 108], [109, 113], [113, 114]]}
{"doc_key": "ai-dev-132", "ner": [[2, 2, "metrics"], [6, 6, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 6, 6, "related-to", "calculates", true, false], [2, 2, 19, 19, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Podczas", "gdy", "BLEU", "po", "prostu", "oblicza", "precyzj\u0119", "n", "-", "gram\u00f3w", ",", "dodaj\u0105c", "do", "ka\u017cdego", "z", "nich", "r\u00f3wn\u0105", "wag\u0119", ",", "NIST", "oblicza", "r\u00f3wnie\u017c", ",", "jak", "informatywny", "jest", "dany", "n-gram", "."], "sentence-detokenized": "Podczas gdy BLEU po prostu oblicza precyzj\u0119 n-gram\u00f3w, dodaj\u0105c do ka\u017cdego z nich r\u00f3wn\u0105 wag\u0119, NIST oblicza r\u00f3wnie\u017c, jak informatywny jest dany n-gram.", "token2charspan": [[0, 7], [8, 11], [12, 16], [17, 19], [20, 26], [27, 34], [35, 43], [44, 45], [45, 46], [46, 52], [52, 53], [54, 61], [62, 64], [65, 72], [73, 74], [75, 79], [80, 85], [86, 90], [90, 91], [92, 96], [97, 104], [105, 112], [112, 113], [114, 117], [118, 130], [131, 135], [136, 140], [141, 147], [147, 148]]}
{"doc_key": "ai-dev-133", "ner": [[2, 7, "misc"], [9, 12, "conference"], [14, 14, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 7, 9, 12, "temporal", "", false, false], [14, 14, 9, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Zosta\u0142", "uhonorowany", "nagrod\u0105", "2019", "Lifetime", "Achievement", "Award", "przyznawan\u0105", "przez", "Association", "for", "Computational", "Linguistics", "(", "ACL", ")", "."], "sentence-detokenized": "Zosta\u0142 uhonorowany nagrod\u0105 2019 Lifetime Achievement Award przyznawan\u0105 przez Association for Computational Linguistics (ACL).", "token2charspan": [[0, 6], [7, 18], [19, 26], [27, 31], [32, 40], [41, 52], [53, 58], [59, 70], [71, 76], [77, 88], [89, 92], [93, 106], [107, 118], [119, 120], [120, 123], [123, 124], [124, 125]]}
{"doc_key": "ai-dev-134", "ner": [[0, 0, "researcher"], [3, 8, "organisation"], [10, 10, "organisation"], [14, 18, "conference"], [20, 20, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 8, "role", "", false, false], [0, 0, 14, 18, "role", "", false, false], [10, 10, 3, 8, "named", "", false, false], [20, 20, 14, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sycara", "jest", "cz\u0142onkiem", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", "oraz", "cz\u0142onkiem", "American", "Association", "for", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Sycara jest cz\u0142onkiem Institute of Electrical and Electronics Engineers (IEEE) oraz cz\u0142onkiem American Association for Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 11], [12, 21], [22, 31], [32, 34], [35, 45], [46, 49], [50, 61], [62, 71], [72, 73], [73, 77], [77, 78], [79, 83], [84, 93], [94, 102], [103, 114], [115, 118], [119, 129], [130, 142], [143, 144], [144, 148], [148, 149], [149, 150]]}
{"doc_key": "ai-dev-135", "ner": [[2, 2, "product"], [8, 9, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 8, 9, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Poni\u017cszy", "kod", "MATLAB", "demonstruje", "konkretne", "rozwi\u0105zanie", "do", "rozwi\u0105zania", "nieliniowego", "uk\u0142adu", "r\u00f3wna\u0144", "przedstawionego", "w", "poprzednim", "rozdziale", ":", "Zob", ".", "tak\u017ce", "."], "sentence-detokenized": "Poni\u017cszy kod MATLAB demonstruje konkretne rozwi\u0105zanie do rozwi\u0105zania nieliniowego uk\u0142adu r\u00f3wna\u0144 przedstawionego w poprzednim rozdziale: Zob. tak\u017ce.", "token2charspan": [[0, 8], [9, 12], [13, 19], [20, 31], [32, 41], [42, 53], [54, 56], [57, 68], [69, 81], [82, 88], [89, 95], [96, 111], [112, 113], [114, 124], [125, 134], [134, 135], [136, 139], [139, 140], [141, 146], [146, 147]]}
{"doc_key": "ai-dev-136", "ner": [[0, 2, "product"], [14, 15, "field"], [37, 38, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 14, 15, "related-to", "trained_by", true, false], [0, 2, 37, 38, "related-to", "trained_by", true, false], [14, 15, 37, 38, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Systemy", "rozpoznawania", "wzorc\u00f3w", "s\u0105", "w", "wielu", "przypadkach", "trenowane", "na", "podstawie", "oznaczonych", "danych", "szkoleniowych", "(", "uczenie", "nadzorowane", ")", ",", "ale", "gdy", "nie", "s\u0105", "dost\u0119pne", "oznaczone", "dane", ",", "mo\u017cna", "u\u017cy\u0107", "innych", "algorytm\u00f3w", "do", "odkrycia", "wcze\u015bniej", "nieznanych", "wzorc\u00f3w", "(", "uczenie", "bez", "nadzoru", ")", "."], "sentence-detokenized": "Systemy rozpoznawania wzorc\u00f3w s\u0105 w wielu przypadkach trenowane na podstawie oznaczonych danych szkoleniowych (uczenie nadzorowane), ale gdy nie s\u0105 dost\u0119pne oznaczone dane, mo\u017cna u\u017cy\u0107 innych algorytm\u00f3w do odkrycia wcze\u015bniej nieznanych wzorc\u00f3w (uczenie bez nadzoru).", "token2charspan": [[0, 7], [8, 21], [22, 29], [30, 32], [33, 34], [35, 40], [41, 52], [53, 62], [63, 65], [66, 75], [76, 87], [88, 94], [95, 108], [109, 110], [110, 117], [118, 129], [129, 130], [130, 131], [132, 135], [136, 139], [140, 143], [144, 146], [147, 155], [156, 165], [166, 170], [170, 171], [172, 177], [178, 182], [183, 189], [190, 200], [201, 203], [204, 212], [213, 222], [223, 233], [234, 241], [242, 243], [243, 250], [251, 254], [255, 262], [262, 263], [263, 264]]}
{"doc_key": "ai-dev-137", "ner": [[6, 9, "researcher"], [11, 12, "country"], [28, 29, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 9, 11, 12, "physical", "", false, false], [6, 9, 28, 29, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Po", "raz", "pierwszy", "zosta\u0142a", "zastosowana", "przez", "Lawrence'a", "J", ".", "Fogla", "w", "USA", "w", "1960", "roku", "w", "celu", "wykorzystania", "symulowanej", "ewolucji", "jako", "procesu", "uczenia", "si\u0119", "maj\u0105cego", "na", "celu", "wygenerowanie", "sztucznej", "inteligencji", "."], "sentence-detokenized": "Po raz pierwszy zosta\u0142a zastosowana przez Lawrence'a J. Fogla w USA w 1960 roku w celu wykorzystania symulowanej ewolucji jako procesu uczenia si\u0119 maj\u0105cego na celu wygenerowanie sztucznej inteligencji.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 23], [24, 35], [36, 41], [42, 52], [53, 54], [54, 55], [56, 61], [62, 63], [64, 67], [68, 69], [70, 74], [75, 79], [80, 81], [82, 86], [87, 100], [101, 112], [113, 121], [122, 126], [127, 134], [135, 142], [143, 146], [147, 155], [156, 158], [159, 163], [164, 177], [178, 187], [188, 200], [200, 201]]}
{"doc_key": "ai-dev-138", "ner": [[0, 1, "field"], [9, 9, "field"], [13, 17, "field"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 9, 9, "part-of", "", false, false], [13, 17, 9, 9, "part-of", "", false, false], [15, 16, 9, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Uczenie", "wzmacniaj\u0105ce", "jest", "jednym", "z", "trzech", "podstawowych", "paradygmat\u00f3w", "uczenia", "maszynowego", ",", "obok", "uczenia", "nadzorowanego", "i", "uczenia", "bez", "nadzoru", "."], "sentence-detokenized": "Uczenie wzmacniaj\u0105ce jest jednym z trzech podstawowych paradygmat\u00f3w uczenia maszynowego, obok uczenia nadzorowanego i uczenia bez nadzoru.", "token2charspan": [[0, 7], [8, 20], [21, 25], [26, 32], [33, 34], [35, 41], [42, 54], [55, 67], [68, 75], [76, 87], [87, 88], [89, 93], [94, 101], [102, 115], [116, 117], [118, 125], [126, 129], [130, 137], [137, 138]]}
{"doc_key": "ai-dev-139", "ner": [[3, 4, "field"], [10, 10, "programlang"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 27, 28, "usage", "applies", false, false], [10, 10, 27, 28, "usage", "applies", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["W", "takich", "przypadkach", "chmura", "obliczeniowa", "i", "j\u0119zyk", "programowania", "open", "source", "R", "mog\u0105", "pom\u00f3c", "mniejszym", "bankom", "w", "zaadoptowaniu", "analityki", "ryzyka", "i", "wsparciu", "monitorowania", "na", "poziomie", "oddzia\u0142u", "poprzez", "zastosowanie", "analityki", "predykcyjnej", "."], "sentence-detokenized": "W takich przypadkach chmura obliczeniowa i j\u0119zyk programowania open source R mog\u0105 pom\u00f3c mniejszym bankom w zaadoptowaniu analityki ryzyka i wsparciu monitorowania na poziomie oddzia\u0142u poprzez zastosowanie analityki predykcyjnej.", "token2charspan": [[0, 1], [2, 8], [9, 20], [21, 27], [28, 40], [41, 42], [43, 48], [49, 62], [63, 67], [68, 74], [75, 76], [77, 81], [82, 87], [88, 97], [98, 104], [105, 106], [107, 120], [121, 130], [131, 137], [138, 139], [140, 148], [149, 162], [163, 165], [166, 174], [175, 183], [184, 191], [192, 204], [205, 214], [215, 227], [227, 228]]}
{"doc_key": "ai-dev-140", "ner": [[8, 9, "researcher"], [17, 17, "algorithm"], [20, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 20, 21, "named", "same", false, false], [17, 17, 8, 9, "origin", "proves_function", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Jedna", "z", "pierwszych", "wersji", "twierdzenia", "zosta\u0142a", "udowodniona", "przez", "Georga", "Cybenko", "w", "1989", "roku", "dla", "funkcji", "aktywacji", "typu", "sigmoidalnego", ".", "Cybenko", "G", ".", "(", "1989", ")", ",", "2", "(", "4", ")", ",", "303-314", "."], "sentence-detokenized": "Jedna z pierwszych wersji twierdzenia zosta\u0142a udowodniona przez Georga Cybenko w 1989 roku dla funkcji aktywacji typu sigmoidalnego. Cybenko G. (1989), 2 (4), 303-314.", "token2charspan": [[0, 5], [6, 7], [8, 18], [19, 25], [26, 37], [38, 45], [46, 57], [58, 63], [64, 70], [71, 78], [79, 80], [81, 85], [86, 90], [91, 94], [95, 102], [103, 112], [113, 117], [118, 131], [131, 132], [133, 140], [141, 142], [142, 143], [144, 145], [145, 149], [149, 150], [150, 151], [152, 153], [154, 155], [155, 156], [156, 157], [157, 158], [159, 166], [166, 167]]}
{"doc_key": "ai-dev-141", "ner": [[8, 9, "algorithm"], [11, 11, "metrics"], [15, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 8, 9, "part-of", "", false, false], [15, 18, 11, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["W", "tym", "procesie", ",", "kt\u00f3ry", "jest", "znany", "jako", "walidacja", "krzy\u017cowa", ",", "MSE", "jest", "cz\u0119sto", "nazywany", "\u015brednim", "kwadratowym", "b\u0142\u0119dem", "predykcji", "i", "jest", "obliczany", "jako"], "sentence-detokenized": "W tym procesie, kt\u00f3ry jest znany jako walidacja krzy\u017cowa, MSE jest cz\u0119sto nazywany \u015brednim kwadratowym b\u0142\u0119dem predykcji i jest obliczany jako", "token2charspan": [[0, 1], [2, 5], [6, 14], [14, 15], [16, 21], [22, 26], [27, 32], [33, 37], [38, 47], [48, 56], [56, 57], [58, 61], [62, 66], [67, 73], [74, 82], [83, 90], [91, 102], [103, 109], [110, 119], [120, 121], [122, 126], [127, 136], [137, 141]]}
{"doc_key": "ai-dev-142", "ner": [[0, 0, "task"], [4, 6, "task"], [8, 8, "task"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 6, "compare", "", false, false], [4, 6, 18, 19, "part-of", "", false, false], [8, 8, 4, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OMR", "odr\u00f3\u017cnia", "si\u0119", "od", "optycznego", "rozpoznawania", "znak\u00f3w", "(", "OCR", ")", "tym", ",", "\u017ce", "nie", "jest", "wymagany", "skomplikowany", "silnik", "rozpoznawania", "wzor\u00f3w", "."], "sentence-detokenized": "OMR odr\u00f3\u017cnia si\u0119 od optycznego rozpoznawania znak\u00f3w (OCR) tym, \u017ce nie jest wymagany skomplikowany silnik rozpoznawania wzor\u00f3w.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 19], [20, 30], [31, 44], [45, 51], [52, 53], [53, 56], [56, 57], [58, 61], [61, 62], [63, 65], [66, 69], [70, 74], [75, 83], [84, 97], [98, 104], [105, 118], [119, 125], [125, 126]]}
{"doc_key": "ai-dev-143", "ner": [[9, 9, "location"], [11, 11, "location"], [13, 13, "location"], [15, 16, "location"], [18, 19, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 11, 13, 13, "physical", "", false, false], [15, 16, 11, 11, "physical", "", false, false], [18, 19, 11, 11, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["W", "2018", "i", "2019", "roku", "mistrzostwa", "odbywa\u0142y", "si\u0119", "w", "Houston", "i", "Detroit", ",", "Michigan", "w", "TCF", "Center", "i", "Ford", "Field", "."], "sentence-detokenized": "W 2018 i 2019 roku mistrzostwa odbywa\u0142y si\u0119 w Houston i Detroit, Michigan w TCF Center i Ford Field.", "token2charspan": [[0, 1], [2, 6], [7, 8], [9, 13], [14, 18], [19, 30], [31, 39], [40, 43], [44, 45], [46, 53], [54, 55], [56, 63], [63, 64], [65, 73], [74, 75], [76, 79], [80, 86], [87, 88], [89, 93], [94, 99], [99, 100]]}
{"doc_key": "ai-dev-144", "ner": [[1, 1, "task"], [11, 11, "task"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 1, 1, "part-of", "", false, false], [13, 14, 1, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["O", "klasyfikacji", "mo\u017cna", "my\u015ble\u0107", "jako", "o", "dw\u00f3ch", "odr\u0119bnych", "problemach", "-", "klasyfikacji", "binarnej", "i", "klasyfikacji", "wieloklasowej", "."], "sentence-detokenized": "O klasyfikacji mo\u017cna my\u015ble\u0107 jako o dw\u00f3ch odr\u0119bnych problemach - klasyfikacji binarnej i klasyfikacji wieloklasowej.", "token2charspan": [[0, 1], [2, 14], [15, 20], [21, 27], [28, 32], [33, 34], [35, 40], [41, 50], [51, 61], [62, 63], [64, 76], [77, 85], [86, 87], [88, 100], [101, 114], [114, 115]]}
{"doc_key": "ai-dev-145", "ner": [[3, 4, "product"], [6, 7, "product"], [9, 10, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 3, 4, "type-of", "", false, false], [9, 10, 3, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Dwa", "przyk\u0142ady", "popularnych", "robot\u00f3w", "r\u00f3wnoleg\u0142ych", "to", "platforma", "Stewarta", "i", "robot", "Delta", "."], "sentence-detokenized": "Dwa przyk\u0142ady popularnych robot\u00f3w r\u00f3wnoleg\u0142ych to platforma Stewarta i robot Delta.", "token2charspan": [[0, 3], [4, 13], [14, 25], [26, 33], [34, 46], [47, 49], [50, 59], [60, 68], [69, 70], [71, 76], [77, 82], [82, 83]]}
{"doc_key": "ai-dev-146", "ner": [[3, 5, "algorithm"], [21, 21, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 5, 21, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "Niemniej", "jednak", "funkcja", "aktywacji", "ReLU", ",", "kt\u00f3ra", "jest", "niezr\u00f3\u017cnicowana", "na", "0", ",", "sta\u0142a", "si\u0119", "do\u015b\u0107", "popularna", ",", "np", ".", "w", "AlexNet", ")"], "sentence-detokenized": "(Niemniej jednak funkcja aktywacji ReLU, kt\u00f3ra jest niezr\u00f3\u017cnicowana na 0, sta\u0142a si\u0119 do\u015b\u0107 popularna, np. w AlexNet)", "token2charspan": [[0, 1], [1, 9], [10, 16], [17, 24], [25, 34], [35, 39], [39, 40], [41, 46], [47, 51], [52, 67], [68, 70], [71, 72], [72, 73], [74, 79], [80, 83], [84, 88], [89, 98], [98, 99], [100, 102], [102, 103], [104, 105], [106, 113], [113, 114]]}
{"doc_key": "ai-dev-147", "ner": [[0, 0, "metrics"], [7, 7, "task"], [11, 11, "task"], [13, 14, "task"], [16, 17, "task"], [21, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 21, 21, "named", "", true, false], [7, 7, 0, 0, "usage", "", true, false], [11, 11, 7, 7, "part-of", "", false, false], [13, 14, 7, 7, "part-of", "", false, false], [16, 17, 7, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["F-score", "jest", "cz\u0119sto", "u\u017cywany", "w", "dziedzinie", "wyszukiwania", "informacji", "do", "pomiaru", "wydajno\u015bci", "wyszukiwania", ",", "klasyfikacji", "dokument\u00f3w", "i", "klasyfikacji", "zapyta\u0144", ".", "i", "tak", "F_beta", "jest", "postrzegany", "w", "szerokim", "zastosowaniu", "."], "sentence-detokenized": "F-score jest cz\u0119sto u\u017cywany w dziedzinie wyszukiwania informacji do pomiaru wydajno\u015bci wyszukiwania, klasyfikacji dokument\u00f3w i klasyfikacji zapyta\u0144. i tak F_beta jest postrzegany w szerokim zastosowaniu.", "token2charspan": [[0, 7], [8, 12], [13, 19], [20, 27], [28, 29], [30, 40], [41, 53], [54, 64], [65, 67], [68, 75], [76, 86], [87, 99], [99, 100], [101, 113], [114, 124], [125, 126], [127, 139], [140, 147], [147, 148], [149, 150], [151, 154], [155, 161], [162, 166], [167, 178], [179, 180], [181, 189], [190, 202], [202, 203]]}
{"doc_key": "ai-dev-148", "ner": [[17, 18, "algorithm"], [20, 20, "algorithm"], [23, 24, "algorithm"], [26, 26, "algorithm"], [29, 31, "algorithm"], [33, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 20, 17, 18, "named", "", false, false], [26, 26, 23, 24, "named", "", false, false], [33, 33, 29, 31, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Odbywa", "si\u0119", "to", "poprzez", "modelowanie", "odebranego", "sygna\u0142u", ",", "a", "nast\u0119pnie", "zastosowanie", "metody", "estymacji", "statystycznej", ",", "takiej", "jak", "maksymalne", "prawdopodobie\u0144stwo", "(", "ML", ")", ",", "g\u0142osowanie", "wi\u0119kszo\u015bciowe", "(", "MV", ")", "lub", "maksymalne", "a", "posteriori", "(", "MAP", ")", ",", "aby", "podj\u0105\u0107", "decyzj\u0119", "o", "tym", ",", "kt\u00f3ry", "cel", "w", "bibliotece", "najlepiej", "pasuje", "do", "modelu", "zbudowanego", "przy", "u\u017cyciu", "odebranego", "sygna\u0142u", "."], "sentence-detokenized": "Odbywa si\u0119 to poprzez modelowanie odebranego sygna\u0142u, a nast\u0119pnie zastosowanie metody estymacji statystycznej, takiej jak maksymalne prawdopodobie\u0144stwo (ML), g\u0142osowanie wi\u0119kszo\u015bciowe (MV) lub maksymalne a posteriori (MAP), aby podj\u0105\u0107 decyzj\u0119 o tym, kt\u00f3ry cel w bibliotece najlepiej pasuje do modelu zbudowanego przy u\u017cyciu odebranego sygna\u0142u.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 21], [22, 33], [34, 44], [45, 52], [52, 53], [54, 55], [56, 65], [66, 78], [79, 85], [86, 95], [96, 109], [109, 110], [111, 117], [118, 121], [122, 132], [133, 151], [152, 153], [153, 155], [155, 156], [156, 157], [158, 168], [169, 182], [183, 184], [184, 186], [186, 187], [188, 191], [192, 202], [203, 204], [205, 215], [216, 217], [217, 220], [220, 221], [221, 222], [223, 226], [227, 233], [234, 241], [242, 243], [244, 247], [247, 248], [249, 254], [255, 258], [259, 260], [261, 271], [272, 281], [282, 288], [289, 291], [292, 298], [299, 310], [311, 315], [316, 322], [323, 333], [334, 341], [341, 342]]}
{"doc_key": "ai-dev-149", "ner": [[0, 0, "researcher"], [3, 3, "misc"], [5, 6, "field"], [7, 10, "university"], [15, 17, "misc"], [19, 19, "field"], [21, 22, "university"], [28, 28, "misc"], [18, 30, "field"], [31, 34, "university"], [41, 50, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 0, 7, 10, "physical", "", false, false], [0, 0, 7, 10, "role", "", false, false], [0, 0, 21, 22, "physical", "", false, false], [0, 0, 21, 22, "role", "", false, false], [0, 0, 31, 34, "physical", "", false, false], [0, 0, 31, 34, "role", "", false, false], [3, 3, 0, 0, "origin", "", false, false], [3, 3, 5, 6, "topic", "", false, false], [15, 17, 0, 0, "origin", "", false, false], [15, 17, 19, 19, "topic", "", false, false], [28, 28, 0, 0, "origin", "", false, false], [28, 28, 18, 30, "topic", "", false, false], [41, 50, 28, 28, "named", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Sowa", "uzyska\u0142", "tytu\u0142", "BS", "w", "matematyce", "w", "Massachusetts", "Institute", "of", "Technology", "w", "1962", "roku", ",", "MA", "w", "dziedzinie", "nauk", "stosowanych", "na", "Uniwersytecie", "Harvarda", "w", "1966", "roku", "oraz", "tytu\u0142", "doktora", "informatyki", "na", "Vrije", "Universiteit", "Brussel", "w", "1999", "roku", "na", "podstawie", "rozprawy", "zatytu\u0142owanej", "Knowledge", "Representation", ":", "Logical", ",", "Philosophical", ",", "and", "Computational", "Foundations", "."], "sentence-detokenized": "Sowa uzyska\u0142 tytu\u0142 BS w matematyce w Massachusetts Institute of Technology w 1962 roku, MA w dziedzinie nauk stosowanych na Uniwersytecie Harvarda w 1966 roku oraz tytu\u0142 doktora informatyki na Vrije Universiteit Brussel w 1999 roku na podstawie rozprawy zatytu\u0142owanej Knowledge Representation: Logical, Philosophical, and Computational Foundations.", "token2charspan": [[0, 4], [5, 12], [13, 18], [19, 21], [22, 23], [24, 34], [35, 36], [37, 50], [51, 60], [61, 63], [64, 74], [75, 76], [77, 81], [82, 86], [86, 87], [88, 90], [91, 92], [93, 103], [104, 108], [109, 120], [121, 123], [124, 137], [138, 146], [147, 148], [149, 153], [154, 158], [159, 163], [164, 169], [170, 177], [178, 189], [190, 192], [193, 198], [199, 211], [212, 219], [220, 221], [222, 226], [227, 231], [232, 234], [235, 244], [245, 253], [254, 267], [268, 277], [278, 292], [292, 293], [294, 301], [301, 302], [303, 316], [316, 317], [318, 321], [322, 335], [336, 347], [347, 348]]}
{"doc_key": "ai-dev-150", "ner": [[1, 2, "task"], [8, 8, "task"], [17, 17, "metrics"], [19, 20, "metrics"], [22, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 8, 8, "general-affiliation", "", false, false], [17, 17, 1, 2, "part-of", "", true, false], [19, 20, 1, 2, "part-of", "", true, false], [22, 23, 1, 2, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Poniewa\u017c", "rozpoznawanie", "parafraz", "mo\u017ce", "by\u0107", "postawione", "jako", "problem", "klasyfikacyjny", ",", "wi\u0119kszo\u015b\u0107", "standardowych", "metryk", "oceny", ",", "takich", "jak", "dok\u0142adno\u015b\u0107", ",", "wynik", "f1", "lub", "krzywa", "ROC", ",", "radzi", "sobie", "stosunkowo", "dobrze", "."], "sentence-detokenized": "Poniewa\u017c rozpoznawanie parafraz mo\u017ce by\u0107 postawione jako problem klasyfikacyjny, wi\u0119kszo\u015b\u0107 standardowych metryk oceny, takich jak dok\u0142adno\u015b\u0107, wynik f1 lub krzywa ROC, radzi sobie stosunkowo dobrze.", "token2charspan": [[0, 8], [9, 22], [23, 31], [32, 36], [37, 40], [41, 51], [52, 56], [57, 64], [65, 79], [79, 80], [81, 90], [91, 104], [105, 111], [112, 117], [117, 118], [119, 125], [126, 129], [130, 140], [140, 141], [142, 147], [148, 150], [151, 154], [155, 161], [162, 165], [165, 166], [167, 172], [173, 178], [179, 189], [190, 196], [196, 197]]}
{"doc_key": "ai-dev-151", "ner": [[17, 17, "algorithm"], [27, 28, "algorithm"], [31, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 17, 27, 28, "opposite", "not_suited_for", false, false], [17, 17, 31, 31, "opposite", "not_suited_for", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["To", "czyni", "go", "praktycznym", "do", "analizy", "du\u017cych", "zbior\u00f3w", "danych", "(", "setki", "lub", "tysi\u0105ce", "takson\u00f3w", ")", "oraz", "do", "bootstrappingu", ",", "dla", "kt\u00f3rego", "inne", "sposoby", "analizy", "(", "np", ".", "maksymalna", "parsymonia", ",", "maksymalne", "prawdopodobie\u0144stwo", ")", "mog\u0105", "by\u0107", "obliczeniowo", "zaporowe", "."], "sentence-detokenized": "To czyni go praktycznym do analizy du\u017cych zbior\u00f3w danych (setki lub tysi\u0105ce takson\u00f3w) oraz do bootstrappingu, dla kt\u00f3rego inne sposoby analizy (np. maksymalna parsymonia, maksymalne prawdopodobie\u0144stwo) mog\u0105 by\u0107 obliczeniowo zaporowe.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 23], [24, 26], [27, 34], [35, 41], [42, 49], [50, 56], [57, 58], [58, 63], [64, 67], [68, 75], [76, 84], [84, 85], [86, 90], [91, 93], [94, 108], [108, 109], [110, 113], [114, 121], [122, 126], [127, 134], [135, 142], [143, 144], [144, 146], [146, 147], [148, 158], [159, 169], [169, 170], [171, 181], [182, 200], [200, 201], [202, 206], [207, 210], [211, 223], [224, 232], [232, 233]]}
{"doc_key": "ai-dev-152", "ner": [[6, 6, "programlang"], [8, 8, "programlang"], [10, 13, "organisation"], [15, 15, "organisation"], [23, 34, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[15, 15, 10, 13, "named", "", false, false], [23, 34, 6, 6, "role", "submits", true, false], [23, 34, 8, 8, "role", "submits", true, false], [23, 34, 10, 13, "role", "submits_to", true, false]], "relations_mapping_to_source": [1, 2, 3, 4], "sentence": ["Z\u0142o\u017cenie", "w", "2002", "r", ".", "j\u0119zyka", "DAML", "+", "OIL", "do", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", "praca", "wykonana", "przez", "wykonawc\u00f3w", "DAML", "i", "ad", "hoc", "Joint", "Committee", "on", "Markup", "Languages", "Unii", "Europejskiej", "/", "Stan\u00f3w", "Zjednoczonych", "."], "sentence-detokenized": "Z\u0142o\u017cenie w 2002 r. j\u0119zyka DAML + OIL do World Wide Web Consortium (W3C) praca wykonana przez wykonawc\u00f3w DAML i ad hoc Joint Committee on Markup Languages Unii Europejskiej / Stan\u00f3w Zjednoczonych.", "token2charspan": [[0, 8], [9, 10], [11, 15], [16, 17], [17, 18], [19, 25], [26, 30], [31, 32], [33, 36], [37, 39], [40, 45], [46, 50], [51, 54], [55, 65], [66, 67], [67, 70], [70, 71], [72, 77], [78, 86], [87, 92], [93, 103], [104, 108], [109, 110], [111, 113], [114, 117], [118, 123], [124, 133], [134, 136], [137, 143], [144, 153], [154, 158], [159, 171], [172, 173], [174, 180], [181, 194], [194, 195]]}
{"doc_key": "ai-dev-153", "ner": [[1, 2, "misc"], [7, 8, "misc"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 1, 2, "part-of", "", true, false], [11, 12, 1, 2, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Przyk\u0142adem", "normalizacji", "nieliniowej", "jest", "sytuacja", ",", "gdy", "normalizacja", "przebiega", "zgodnie", "z", "funkcj\u0105", "sigmoidaln\u0105", ",", "w", "takim", "przypadku", "znormalizowany", "obraz", "jest", "obliczany", "wed\u0142ug", "wzoru"], "sentence-detokenized": "Przyk\u0142adem normalizacji nieliniowej jest sytuacja, gdy normalizacja przebiega zgodnie z funkcj\u0105 sigmoidaln\u0105, w takim przypadku znormalizowany obraz jest obliczany wed\u0142ug wzoru", "token2charspan": [[0, 10], [11, 23], [24, 35], [36, 40], [41, 49], [49, 50], [51, 54], [55, 67], [68, 77], [78, 85], [86, 87], [88, 95], [96, 107], [107, 108], [109, 110], [111, 116], [117, 126], [127, 141], [142, 147], [148, 152], [153, 162], [163, 169], [170, 175]]}
{"doc_key": "ai-dev-154", "ner": [[4, 4, "metrics"], [9, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 9, 9, "related-to", "used_together", false, false]], "relations_mapping_to_source": [0], "sentence": ["Zwr\u00f3cono", "uwag\u0119", ",", "\u017ce", "precyzja", "jest", "zwykle", "po\u0142\u0105czona", "z", "przywo\u0142aniem", ",", "aby", "przezwyci\u0119\u017cy\u0107", "ten", "problem", "."], "sentence-detokenized": "Zwr\u00f3cono uwag\u0119, \u017ce precyzja jest zwykle po\u0142\u0105czona z przywo\u0142aniem, aby przezwyci\u0119\u017cy\u0107 ten problem.", "token2charspan": [[0, 8], [9, 14], [14, 15], [16, 18], [19, 27], [28, 32], [33, 39], [40, 49], [50, 51], [52, 64], [64, 65], [66, 69], [70, 83], [84, 87], [88, 95], [95, 96]]}
{"doc_key": "ai-dev-155", "ner": [[4, 5, "metrics"], [7, 10, "metrics"], [17, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 18, 7, 10, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Powszechnie", "stosowanymi", "metrykami", "s\u0105", "b\u0142\u0105d", "\u015bredniokwadratowy", "i", "b\u0142\u0105d", "\u015bredniokwadratowy", ",", "przy", "czym", "ten", "ostatni", "zosta\u0142", "wykorzystany", "w", "nagrodzie", "Netflixa", "."], "sentence-detokenized": "Powszechnie stosowanymi metrykami s\u0105 b\u0142\u0105d \u015bredniokwadratowy i b\u0142\u0105d \u015bredniokwadratowy, przy czym ten ostatni zosta\u0142 wykorzystany w nagrodzie Netflixa.", "token2charspan": [[0, 11], [12, 23], [24, 33], [34, 36], [37, 41], [42, 59], [60, 61], [62, 66], [67, 84], [84, 85], [86, 90], [91, 95], [96, 99], [100, 107], [108, 114], [115, 127], [128, 129], [130, 139], [140, 148], [148, 149]]}
{"doc_key": "ai-dev-156", "ner": [[8, 10, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["W", "sierpniu", "2016", "roku", "og\u0142oszono", "program", "badawczy", "z", "University", "College", "Hospital", ",", "kt\u00f3rego", "celem", "jest", "opracowanie", "algorytmu", ",", "kt\u00f3ry", "mo\u017ce", "automatycznie", "rozr\u00f3\u017cnia\u0107", "zdrowe", "i", "nowotworowe", "tkanki", "w", "obszarach", "g\u0142owy", "i", "szyi", "."], "sentence-detokenized": "W sierpniu 2016 roku og\u0142oszono program badawczy z University College Hospital, kt\u00f3rego celem jest opracowanie algorytmu, kt\u00f3ry mo\u017ce automatycznie rozr\u00f3\u017cnia\u0107 zdrowe i nowotworowe tkanki w obszarach g\u0142owy i szyi.", "token2charspan": [[0, 1], [2, 10], [11, 15], [16, 20], [21, 30], [31, 38], [39, 47], [48, 49], [50, 60], [61, 68], [69, 77], [77, 78], [79, 86], [87, 92], [93, 97], [98, 109], [110, 119], [119, 120], [121, 126], [127, 131], [132, 145], [146, 156], [157, 163], [164, 165], [166, 177], [178, 184], [185, 186], [187, 196], [197, 202], [203, 204], [205, 209], [209, 210]]}
{"doc_key": "ai-dev-157", "ner": [[5, 5, "researcher"], [11, 13, "organisation"], [15, 18, "organisation"], [20, 23, "organisation"], [26, 30, "organisation"], [32, 38, "organisation"], [40, 43, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 5, 11, 13, "role", "", false, false], [5, 5, 15, 18, "role", "", false, false], [5, 5, 20, 23, "role", "", false, false], [5, 5, 26, 30, "role", "", false, false], [5, 5, 32, 38, "role", "", false, false], [5, 5, 40, 43, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Wp\u0142yw", "teoretycznego", "i", "empirycznego", "wk\u0142adu", "Posnera", "zosta\u0142", "doceniony", "poprzez", "cz\u0142onkostwo", "w", "American", "Psychological", "Association", ",", "Association", "for", "Psychological", "Science", ",", "Society", "of", "Experimental", "Psychologists", ",", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "American", "Association", "for", "the", "Advancement", "of", "Science", "oraz", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Wp\u0142yw teoretycznego i empirycznego wk\u0142adu Posnera zosta\u0142 doceniony poprzez cz\u0142onkostwo w American Psychological Association, Association for Psychological Science, Society of Experimental Psychologists, American Academy of Arts and Sciences, American Association for the Advancement of Science oraz National Academy of Sciences.", "token2charspan": [[0, 5], [6, 19], [20, 21], [22, 34], [35, 41], [42, 49], [50, 56], [57, 66], [67, 74], [75, 86], [87, 88], [89, 97], [98, 111], [112, 123], [123, 124], [125, 136], [137, 140], [141, 154], [155, 162], [162, 163], [164, 171], [172, 174], [175, 187], [188, 201], [201, 202], [203, 211], [212, 219], [220, 222], [223, 227], [228, 231], [232, 240], [240, 241], [242, 250], [251, 262], [263, 266], [267, 270], [271, 282], [283, 285], [286, 293], [294, 298], [299, 307], [308, 315], [316, 318], [319, 327], [327, 328]]}
{"doc_key": "ai-dev-158", "ner": [[2, 2, "product"], [6, 7, "field"], [11, 12, "task"], [14, 16, "task"], [18, 18, "task"], [21, 23, "task"], [25, 25, "task"], [28, 29, "field"], [31, 32, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 2, 6, 7, "usage", "", false, false], [11, 12, 6, 7, "part-of", "", false, false], [14, 16, 6, 7, "part-of", "", false, false], [18, 18, 14, 16, "named", "", false, false], [21, 23, 6, 7, "part-of", "", false, false], [25, 25, 21, 23, "named", "", false, false], [28, 29, 6, 7, "part-of", "", false, false], [31, 32, 6, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Te", "inteligentne", "Chatboty", "wykorzystuj\u0105", "wszystkie", "rodzaje", "sztucznej", "inteligencji", ",", "takie", "jak", "moderacja", "obrazu", "i", "rozumienie", "j\u0119zyka", "naturalnego", "(", "NLU", ")", ",", "generowanie", "j\u0119zyka", "naturalnego", "(", "NLG", ")", ",", "uczenie", "maszynowe", "i", "g\u0142\u0119bokie", "uczenie", "."], "sentence-detokenized": "Te inteligentne Chatboty wykorzystuj\u0105 wszystkie rodzaje sztucznej inteligencji, takie jak moderacja obrazu i rozumienie j\u0119zyka naturalnego (NLU), generowanie j\u0119zyka naturalnego (NLG), uczenie maszynowe i g\u0142\u0119bokie uczenie.", "token2charspan": [[0, 2], [3, 15], [16, 24], [25, 37], [38, 47], [48, 55], [56, 65], [66, 78], [78, 79], [80, 85], [86, 89], [90, 99], [100, 106], [107, 108], [109, 119], [120, 126], [127, 138], [139, 140], [140, 143], [143, 144], [144, 145], [146, 157], [158, 164], [165, 176], [177, 178], [178, 181], [181, 182], [182, 183], [184, 191], [192, 201], [202, 203], [204, 212], [213, 220], [220, 221]]}
{"doc_key": "ai-dev-159", "ner": [[3, 5, "metrics"], [7, 7, "metrics"], [10, 10, "metrics"], [13, 20, "metrics"], [24, 26, "metrics"], [28, 28, "metrics"], [31, 38, "metrics"], [41, 43, "metrics"], [45, 45, "metrics"], [48, 55, "metrics"], [59, 61, "metrics"], [63, 63, "metrics"], [67, 72, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[7, 7, 3, 5, "named", "", false, false], [10, 10, 3, 5, "named", "", false, false], [13, 20, 3, 5, "named", "", false, false], [28, 28, 24, 26, "named", "", false, false], [31, 38, 24, 26, "named", "", false, false], [45, 45, 41, 43, "named", "", false, false], [48, 55, 41, 43, "named", "", false, false], [63, 63, 59, 61, "named", "", false, false], [67, 72, 59, 61, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Wsp\u00f3\u0142czynniki", "rz\u0119dowe", "to", "Pozytywna", "Warto\u015b\u0107", "Predykcyjna", "(", "PPV", ",", "vel", "precyzja", ")", "(", "TP", "/", "(", "TP", "+", "FP", ")", ")", ",", "z", "uzupe\u0142nieniem", "FALSE", "Discovery", "Rate", "(", "FDR", ")", "(", "FP", "/", "(", "TP", "+", "FP", ")", ")", ";", "oraz", "Negatywna", "Warto\u015b\u0107", "Predykcyjna", "(", "NPV", ")", "(", "TN", "/", "(", "TN", "+", "FN", ")", ")", ",", "z", "uzupe\u0142nieniem", "FALSE", "Omission", "Rate", "(", "FOR", ")", "(", "FN", "/", "(", "TN", "+", "FN", ")", ")", "."], "sentence-detokenized": "Wsp\u00f3\u0142czynniki rz\u0119dowe to Pozytywna Warto\u015b\u0107 Predykcyjna (PPV, vel precyzja) (TP / (TP + FP)), z uzupe\u0142nieniem FALSE Discovery Rate (FDR) (FP / (TP + FP)); oraz Negatywna Warto\u015b\u0107 Predykcyjna (NPV) (TN / (TN + FN)), z uzupe\u0142nieniem FALSE Omission Rate (FOR) (FN / (TN + FN)).", "token2charspan": [[0, 13], [14, 21], [22, 24], [25, 34], [35, 42], [43, 54], [55, 56], [56, 59], [59, 60], [61, 64], [65, 73], [73, 74], [75, 76], [76, 78], [79, 80], [81, 82], [82, 84], [85, 86], [87, 89], [89, 90], [90, 91], [91, 92], [93, 94], [95, 108], [109, 114], [115, 124], [125, 129], [130, 131], [131, 134], [134, 135], [136, 137], [137, 139], [140, 141], [142, 143], [143, 145], [146, 147], [148, 150], [150, 151], [151, 152], [152, 153], [154, 158], [159, 168], [169, 176], [177, 188], [189, 190], [190, 193], [193, 194], [195, 196], [196, 198], [199, 200], [201, 202], [202, 204], [205, 206], [207, 209], [209, 210], [210, 211], [211, 212], [213, 214], [215, 228], [229, 234], [235, 243], [244, 248], [249, 250], [250, 253], [253, 254], [255, 256], [256, 258], [259, 260], [261, 262], [262, 264], [265, 266], [267, 269], [269, 270], [270, 271], [271, 272]]}
{"doc_key": "ai-dev-160", "ner": [[5, 5, "misc"], [11, 12, "algorithm"], [14, 14, "algorithm"], [17, 19, "algorithm"], [21, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 14, 11, 12, "named", "", false, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Informacje", "s\u0105", "mieszank\u0105", "sitemaps", "i", "RSS", "i", "s\u0105", "tworzone", "przy", "u\u017cyciu", "Information", "Model", "(", "IM", ")", "i", "Biomedical", "Resource", "Ontology", "(", "BRO", ")", "."], "sentence-detokenized": "Informacje s\u0105 mieszank\u0105 sitemaps i RSS i s\u0105 tworzone przy u\u017cyciu Information Model (IM) i Biomedical Resource Ontology (BRO).", "token2charspan": [[0, 10], [11, 13], [14, 23], [24, 32], [33, 34], [35, 38], [39, 40], [41, 43], [44, 52], [53, 57], [58, 64], [65, 76], [77, 82], [83, 84], [84, 86], [86, 87], [88, 89], [90, 100], [101, 109], [110, 118], [119, 120], [120, 123], [123, 124], [124, 125]]}
{"doc_key": "ai-dev-161", "ner": [[1, 2, "task"], [6, 8, "algorithm"], [10, 14, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 2, 10, 14, "origin", "based_on", false, false], [10, 14, 6, 8, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Najnowsze", "rozpoznawanie", "tekstu", "oparte", "jest", "na", "sieci", "neuronowej", "Recurrent", "(", "Long", "short", "-", "term", "memory", ")", "i", "nie", "wymaga", "modelu", "j\u0119zykowego", "."], "sentence-detokenized": "Najnowsze rozpoznawanie tekstu oparte jest na sieci neuronowej Recurrent (Long short-term memory) i nie wymaga modelu j\u0119zykowego.", "token2charspan": [[0, 9], [10, 23], [24, 30], [31, 37], [38, 42], [43, 45], [46, 51], [52, 62], [63, 72], [73, 74], [74, 78], [79, 84], [84, 85], [85, 89], [90, 96], [96, 97], [98, 99], [100, 103], [104, 110], [111, 117], [118, 128], [128, 129]]}
{"doc_key": "ai-dev-162", "ner": [[1, 4, "misc"], [5, 5, "metrics"], [8, 9, "algorithm"], [12, 13, "metrics"], [16, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 5, 1, 4, "type-of", "", false, false], [8, 9, 5, 5, "related-to", "", true, false], [12, 13, 1, 4, "type-of", "", false, false], [16, 17, 12, 13, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Popularne", "funkcje", "straty", "to", "strata", "zawiasowa", "(", "dla", "liniowych", "SVM", ")", "i", "strata", "logiczna", "(", "dla", "regresji", "logistycznej", ")", "."], "sentence-detokenized": "Popularne funkcje straty to strata zawiasowa (dla liniowych SVM) i strata logiczna (dla regresji logistycznej).", "token2charspan": [[0, 9], [10, 17], [18, 24], [25, 27], [28, 34], [35, 44], [45, 46], [46, 49], [50, 59], [60, 63], [63, 64], [65, 66], [67, 73], [74, 82], [83, 84], [84, 87], [88, 96], [97, 109], [109, 110], [110, 111]]}
{"doc_key": "ai-dev-163", "ner": [[0, 1, "metrics"], [10, 13, "metrics"], [15, 15, "metrics"], [18, 19, "metrics"], [21, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 10, 13, "compare", "", false, false], [0, 1, 18, 19, "compare", "", false, false], [15, 15, 10, 13, "named", "", false, false], [21, 21, 18, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SSIM", "ma", "na", "celu", "popraw\u0119", "tradycyjnych", "metod", ",", "takich", "jak", "stosunek", "sygna\u0142u", "do", "szumu", "(", "PSNR", ")", "i", "b\u0142\u0105d", "\u015bredniokwadratowy", "(", "MSE", ")", "."], "sentence-detokenized": "SSIM ma na celu popraw\u0119 tradycyjnych metod, takich jak stosunek sygna\u0142u do szumu (PSNR) i b\u0142\u0105d \u015bredniokwadratowy (MSE).", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 15], [16, 23], [24, 36], [37, 42], [42, 43], [44, 50], [51, 54], [55, 63], [64, 71], [72, 74], [75, 80], [81, 82], [82, 86], [86, 87], [88, 89], [90, 94], [95, 112], [113, 114], [114, 117], [117, 118], [118, 119]]}
{"doc_key": "ai-dev-164", "ner": [[10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Jego", "praca", "zainspirowa\u0142a", "kolejne", "pokolenia", "badaczy", "robotyki", ",", "takich", "jak", "Rodney", "Brooks", ",", "Hans", "Moravec", "czy", "Mark", "Tilden", "."], "sentence-detokenized": "Jego praca zainspirowa\u0142a kolejne pokolenia badaczy robotyki, takich jak Rodney Brooks, Hans Moravec czy Mark Tilden.", "token2charspan": [[0, 4], [5, 10], [11, 24], [25, 32], [33, 42], [43, 50], [51, 59], [59, 60], [61, 67], [68, 71], [72, 78], [79, 85], [85, 86], [87, 91], [92, 99], [100, 103], [104, 108], [109, 115], [115, 116]]}
{"doc_key": "ai-dev-165", "ner": [[14, 14, "algorithm"], [19, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[19, 19, 14, 14, "origin", "based_on", false, false]], "relations_mapping_to_source": [0], "sentence": ["Dalsze", "szkolenie", "impulsowe", "nie", "jest", "zr\u00f3\u017cnicowane", ",", "co", "eliminuje", "metody", "szkolenia", "oparte", "na", "propagacji", "wstecznej", ",", "takie", "jak", "zej\u015bcie", "gradientowe", "."], "sentence-detokenized": "Dalsze szkolenie impulsowe nie jest zr\u00f3\u017cnicowane, co eliminuje metody szkolenia oparte na propagacji wstecznej, takie jak zej\u015bcie gradientowe.", "token2charspan": [[0, 6], [7, 16], [17, 26], [27, 30], [31, 35], [36, 48], [48, 49], [50, 52], [53, 62], [63, 69], [70, 79], [80, 86], [87, 89], [90, 100], [101, 110], [110, 111], [112, 117], [118, 121], [122, 129], [130, 141], [141, 142]]}
{"doc_key": "ai-dev-166", "ner": [[7, 8, "metrics"], [15, 15, "metrics"], [17, 17, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 15, 15, "related-to", "describes", false, false], [15, 15, 17, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Relacje", "te", "mo\u017cna", "\u0142atwo", "przedstawi\u0107", "za", "pomoc\u0105", "macierzy", "konfuzji", ",", "czyli", "tabeli", ",", "kt\u00f3ra", "opisuje", "dok\u0142adno\u015b\u0107", "modelu", "klasyfikacyjnego", "."], "sentence-detokenized": "Relacje te mo\u017cna \u0142atwo przedstawi\u0107 za pomoc\u0105 macierzy konfuzji, czyli tabeli, kt\u00f3ra opisuje dok\u0142adno\u015b\u0107 modelu klasyfikacyjnego.", "token2charspan": [[0, 7], [8, 10], [11, 16], [17, 22], [23, 34], [35, 37], [38, 44], [45, 53], [54, 62], [62, 63], [64, 69], [70, 76], [76, 77], [78, 83], [84, 91], [92, 102], [103, 109], [110, 126], [126, 127]]}
{"doc_key": "ai-dev-167", "ner": [[1, 7, "conference"], [9, 9, "conference"], [13, 13, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 1, 7, "named", "", false, false], [13, 13, 1, 7, "physical", "", false, false], [13, 13, 1, 7, "role", "", false, false], [13, 13, 1, 7, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Podczas", "2018", "Conference", "on", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", "naukowcy", "z", "Google", "zaprezentowali", "prac\u0119"], "sentence-detokenized": "Podczas 2018 Conference on Neural Information Processing Systems (NeurIPS) naukowcy z Google zaprezentowali prac\u0119", "token2charspan": [[0, 7], [8, 12], [13, 23], [24, 26], [27, 33], [34, 45], [46, 56], [57, 64], [65, 66], [66, 73], [73, 74], [75, 83], [84, 85], [86, 92], [93, 107], [108, 113]]}
{"doc_key": "ai-dev-168", "ner": [[4, 4, "university"], [10, 10, "product"], [17, 20, "misc"], [22, 22, "conference"], [27, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 10, 17, 20, "win-defeat", "", false, false], [17, 20, 22, 22, "temporal", "", false, false], [27, 30, 22, 22, "part-of", "", false, false], [27, 30, 22, 22, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["W", "czasie", "pracy", "w", "Duke", "pracowa\u0142", "nad", "automatycznym", "rozwi\u0105zaniem", "krzy\u017c\u00f3wki", "PROVERB", ",", "kt\u00f3re", "w", "1999", "roku", "otrzyma\u0142o", "nagrod\u0119", "Outstanding", "Paper", "Award", "od", "AAAI", "i", "bra\u0142o", "udzia\u0142", "w", "American", "Crossword", "Puzzle", "Tournament", "."], "sentence-detokenized": "W czasie pracy w Duke pracowa\u0142 nad automatycznym rozwi\u0105zaniem krzy\u017c\u00f3wki PROVERB, kt\u00f3re w 1999 roku otrzyma\u0142o nagrod\u0119 Outstanding Paper Award od AAAI i bra\u0142o udzia\u0142 w American Crossword Puzzle Tournament.", "token2charspan": [[0, 1], [2, 8], [9, 14], [15, 16], [17, 21], [22, 30], [31, 34], [35, 48], [49, 61], [62, 71], [72, 79], [79, 80], [81, 86], [87, 88], [89, 93], [94, 98], [99, 108], [109, 116], [117, 128], [129, 134], [135, 140], [141, 143], [144, 148], [149, 150], [151, 156], [157, 163], [164, 165], [166, 174], [175, 184], [185, 191], [192, 202], [202, 203]]}
{"doc_key": "ai-dev-169", "ner": [[5, 6, "location"], [8, 8, "location"], [16, 16, "country"], [18, 18, "country"], [20, 20, "country"], [22, 22, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 6, 8, 8, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Siedziba", "g\u0142\u00f3wna", "znajduje", "si\u0119", "w", "Rochester", "Hills", ",", "Michigan", ",", "firma", "mia\u0142a", "10", "regionalnych", "lokalizacji", "w", "USA", ",", "Kanadzie", ",", "Meksyku", "i", "Brazylii", "."], "sentence-detokenized": "Siedziba g\u0142\u00f3wna znajduje si\u0119 w Rochester Hills, Michigan, firma mia\u0142a 10 regionalnych lokalizacji w USA, Kanadzie, Meksyku i Brazylii.", "token2charspan": [[0, 8], [9, 15], [16, 24], [25, 28], [29, 30], [31, 40], [41, 46], [46, 47], [48, 56], [56, 57], [58, 63], [64, 69], [70, 72], [73, 85], [86, 97], [98, 99], [100, 103], [103, 104], [105, 113], [113, 114], [115, 122], [123, 124], [125, 133], [133, 134]]}
{"doc_key": "ai-dev-170", "ner": [[12, 12, "product"], [14, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Do\u0142\u0105cza", "on", "do", "kolekcji", "historycznie", "wa\u017cnych", "robot\u00f3w", ",", "do", "kt\u00f3rych", "nale\u017c\u0105", "wczesny", "Unimate", "i", "Odetics", "Odex", "1", "."], "sentence-detokenized": "Do\u0142\u0105cza on do kolekcji historycznie wa\u017cnych robot\u00f3w, do kt\u00f3rych nale\u017c\u0105 wczesny Unimate i Odetics Odex 1.", "token2charspan": [[0, 7], [8, 10], [11, 13], [14, 22], [23, 35], [36, 43], [44, 51], [51, 52], [53, 55], [56, 63], [64, 70], [71, 78], [79, 86], [87, 88], [89, 96], [97, 101], [102, 103], [103, 104]]}
{"doc_key": "ai-dev-171", "ner": [[7, 8, "researcher"], [9, 9, "organisation"], [11, 12, "researcher"], [18, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 9, 9, "physical", "", false, false], [7, 8, 9, 9, "role", "", false, false], [11, 12, 9, 9, "physical", "", false, false], [11, 12, 9, 9, "role", "", false, false], [11, 12, 18, 23, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Go\u015bcinnym", "redaktorem", "tego", "numeru", "b\u0119dzie", "by\u0142y", "kolega", "Davida", "z", "NIST", ",", "Judah", "Levine", ",", "kt\u00f3ry", "jest", "najnowszym", "laureatem", "I", ".", "I", ".", "Rabi", "Award", "."], "sentence-detokenized": "Go\u015bcinnym redaktorem tego numeru b\u0119dzie by\u0142y kolega Davida z NIST, Judah Levine, kt\u00f3ry jest najnowszym laureatem I. I. Rabi Award.", "token2charspan": [[0, 9], [10, 20], [21, 25], [26, 32], [33, 39], [40, 44], [45, 51], [52, 58], [59, 60], [61, 65], [65, 66], [67, 72], [73, 79], [79, 80], [81, 86], [87, 91], [92, 102], [103, 112], [113, 114], [114, 115], [116, 117], [117, 118], [119, 123], [124, 129], [129, 130]]}
{"doc_key": "ai-dev-172", "ner": [[10, 11, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Mo\u017cna", "je", "u\u0142o\u017cy\u0107", "w", "tabel\u0119", "kontyngencji", "2", "\u00d7", "2", "(", "macierz", "konfuzji", ")", ",", "umownie", "z", "wynikiem", "testu", "na", "osi", "pionowej", "i", "stanem", "rzeczywistym", "na", "osi", "poziomej", "."], "sentence-detokenized": "Mo\u017cna je u\u0142o\u017cy\u0107 w tabel\u0119 kontyngencji 2 \u00d7 2 (macierz konfuzji), umownie z wynikiem testu na osi pionowej i stanem rzeczywistym na osi poziomej.", "token2charspan": [[0, 5], [6, 8], [9, 15], [16, 17], [18, 24], [25, 37], [38, 39], [40, 41], [42, 43], [44, 45], [45, 52], [53, 61], [61, 62], [62, 63], [64, 71], [72, 73], [74, 82], [83, 88], [89, 91], [92, 95], [96, 104], [105, 106], [107, 113], [114, 126], [127, 129], [130, 133], [134, 142], [142, 143]]}
{"doc_key": "ai-dev-173", "ner": [[0, 3, "product"], [7, 7, "product"], [9, 9, "product"], [11, 12, "product"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 7, 7, "part-of", "", false, false], [0, 3, 9, 9, "part-of", "", false, false], [0, 3, 11, 12, "part-of", "", false, false], [0, 3, 15, 17, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["System", "operacyjny", "Apple", "iOS", "u\u017cywany", "w", "urz\u0105dzeniach", "iPhone", ",", "iPad", "i", "iPod", "Touch", "wykorzystuje", "funkcj\u0119", "syntezy", "mowy", "VoiceOver", "."], "sentence-detokenized": "System operacyjny Apple iOS u\u017cywany w urz\u0105dzeniach iPhone, iPad i iPod Touch wykorzystuje funkcj\u0119 syntezy mowy VoiceOver.", "token2charspan": [[0, 6], [7, 17], [18, 23], [24, 27], [28, 35], [36, 37], [38, 50], [51, 57], [57, 58], [59, 63], [64, 65], [66, 70], [71, 76], [77, 89], [90, 97], [98, 105], [106, 110], [111, 120], [120, 121]]}
{"doc_key": "ai-dev-174", "ner": [[7, 9, "conference"], [13, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Na", "przyk\u0142ad", ",", "najlepszy", "system", "wchodz\u0105cy", "do", "MUC", "-", "7", "uzyska\u0142", "93,39", "%", "F-measure", ",", "podczas", "gdy", "ludzcy", "anotatorzy", "uzyskali", "97,6", "%", "i", "96,95", "%", "."], "sentence-detokenized": "Na przyk\u0142ad, najlepszy system wchodz\u0105cy do MUC-7 uzyska\u0142 93,39% F-measure, podczas gdy ludzcy anotatorzy uzyskali 97,6% i 96,95%.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 22], [23, 29], [30, 39], [40, 42], [43, 46], [46, 47], [47, 48], [49, 56], [57, 62], [62, 63], [64, 73], [73, 74], [75, 82], [83, 86], [87, 93], [94, 104], [105, 113], [114, 118], [118, 119], [120, 121], [122, 127], [127, 128], [128, 129]]}
{"doc_key": "ai-dev-175", "ner": [[13, 15, "algorithm"], [17, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 18, 13, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Odbywa", "si\u0119", "to", "przy", "u\u017cyciu", "standardowych", "algorytm\u00f3w", "szkolenia", "sieci", "neuronowych", ",", "takich", "jak", "stochastyczne", "zej\u015bcie", "gradientowe", "z", "wsteczn\u0105", "propagacj\u0105", "."], "sentence-detokenized": "Odbywa si\u0119 to przy u\u017cyciu standardowych algorytm\u00f3w szkolenia sieci neuronowych, takich jak stochastyczne zej\u015bcie gradientowe z wsteczn\u0105 propagacj\u0105.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 18], [19, 25], [26, 39], [40, 50], [51, 60], [61, 66], [67, 78], [78, 79], [80, 86], [87, 90], [91, 104], [105, 112], [113, 124], [125, 126], [127, 135], [136, 146], [146, 147]]}
{"doc_key": "ai-dev-176", "ner": [[0, 1, "organisation"], [21, 22, "country"], [28, 28, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 21, 22, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Rotten", "Tomatoes", "to", "witryna", "z", "listy", "Top", "1000", ",", "plasuj\u0105ca", "si\u0119", "w", "okolicach", "#", "400", "globalnie", "i", "Top", "150", "tylko", "dla", "Stan\u00f3w", "Zjednoczonych", ",", "wed\u0142ug", "rankingera", "stron", "internetowych", "Alexa", "."], "sentence-detokenized": "Rotten Tomatoes to witryna z listy Top 1000, plasuj\u0105ca si\u0119 w okolicach # 400 globalnie i Top 150 tylko dla Stan\u00f3w Zjednoczonych, wed\u0142ug rankingera stron internetowych Alexa.", "token2charspan": [[0, 6], [7, 15], [16, 18], [19, 26], [27, 28], [29, 34], [35, 38], [39, 43], [43, 44], [45, 54], [55, 58], [59, 60], [61, 70], [71, 72], [73, 76], [77, 86], [87, 88], [89, 92], [93, 96], [97, 102], [103, 106], [107, 113], [114, 127], [127, 128], [129, 135], [136, 146], [147, 152], [153, 166], [167, 172], [172, 173]]}
{"doc_key": "ai-dev-177", "ner": [[15, 16, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Og\u00f3lnie", "rzecz", "bior\u0105c", ",", "ca\u0142e", "uczenie", "si\u0119", "wykazuje", "zmiany", "przyrostowe", "w", "czasie", ",", "ale", "opisuje", "funkcj\u0119", "sigmoidaln\u0105", ",", "kt\u00f3ra", "ma", "r\u00f3\u017cne", "wygl\u0105dy", "w", "zale\u017cno\u015bci", "od", "skali", "czasowej", "obserwacji", "."], "sentence-detokenized": "Og\u00f3lnie rzecz bior\u0105c, ca\u0142e uczenie si\u0119 wykazuje zmiany przyrostowe w czasie, ale opisuje funkcj\u0119 sigmoidaln\u0105, kt\u00f3ra ma r\u00f3\u017cne wygl\u0105dy w zale\u017cno\u015bci od skali czasowej obserwacji.", "token2charspan": [[0, 7], [8, 13], [14, 20], [20, 21], [22, 26], [27, 34], [35, 38], [39, 47], [48, 54], [55, 66], [67, 68], [69, 75], [75, 76], [77, 80], [81, 88], [89, 96], [97, 108], [108, 109], [110, 115], [116, 118], [119, 124], [125, 132], [133, 134], [135, 145], [146, 148], [149, 154], [155, 163], [164, 174], [174, 175]]}
{"doc_key": "ai-dev-178", "ner": [[0, 0, "metrics"], [5, 7, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 5, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["SSD", "jest", "r\u00f3wnie\u017c", "znany", "jako", "\u015bredni", "b\u0142\u0105d", "kwadratowy", "."], "sentence-detokenized": "SSD jest r\u00f3wnie\u017c znany jako \u015bredni b\u0142\u0105d kwadratowy.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 27], [28, 34], [35, 39], [40, 50], [50, 51]]}
{"doc_key": "ai-dev-179", "ner": [[0, 2, "algorithm"], [4, 5, "algorithm"], [7, 9, "algorithm"], [22, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 22, 23, "related-to", "can_be_related_to", true, false], [4, 5, 22, 23, "related-to", "can_be_related_to", true, false], [7, 9, 22, 23, "related-to", "can_be_related_to", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Uczenie", "drzew", "decyzyjnych", ",", "sieci", "neuronowe", "lub", "naiwny", "klasyfikator", "Bayesa", "mog\u0105", "by\u0107", "stosowane", "w", "po\u0142\u0105czeniu", "z", "miarami", "jako\u015bci", "modelu", ",", "takimi", "jak", "zr\u00f3wnowa\u017cona", "dok\u0142adno\u015b\u0107"], "sentence-detokenized": "Uczenie drzew decyzyjnych, sieci neuronowe lub naiwny klasyfikator Bayesa mog\u0105 by\u0107 stosowane w po\u0142\u0105czeniu z miarami jako\u015bci modelu, takimi jak zr\u00f3wnowa\u017cona dok\u0142adno\u015b\u0107", "token2charspan": [[0, 7], [8, 13], [14, 25], [25, 26], [27, 32], [33, 42], [43, 46], [47, 53], [54, 66], [67, 73], [74, 78], [79, 82], [83, 92], [93, 94], [95, 105], [106, 107], [108, 115], [116, 123], [124, 130], [130, 131], [132, 138], [139, 142], [143, 155], [156, 166]]}
{"doc_key": "ai-dev-180", "ner": [[12, 12, "conference"], [17, 26, "conference"], [21, 24, "misc"], [30, 32, "product"], [38, 41, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[21, 24, 17, 26, "origin", "", false, false], [21, 24, 17, 26, "temporal", "", false, false], [30, 32, 21, 24, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Jest", "by\u0142ym", "prezydentem", "(", "1979", ")", "i", "inauguracyjnym", "Fellow", "(", "2011", ")", "ACL", ",", "wsp\u00f3\u0142odpowiedzialnym", "za", "nagrod\u0119", "Association", "for", "Computing", "Machinery", "Software", "Systems", "Award", "w", "1992", "roku", "za", "wk\u0142ad", "w", "system", "programowania", "Interlisp", ",", "oraz", "Fellow", "of", "the", "Association", "for", "Computing", "Machinery", "."], "sentence-detokenized": "Jest by\u0142ym prezydentem (1979) i inauguracyjnym Fellow (2011) ACL, wsp\u00f3\u0142odpowiedzialnym za nagrod\u0119 Association for Computing Machinery Software Systems Award w 1992 roku za wk\u0142ad w system programowania Interlisp, oraz Fellow of the Association for Computing Machinery.", "token2charspan": [[0, 4], [5, 10], [11, 22], [23, 24], [24, 28], [28, 29], [30, 31], [32, 46], [47, 53], [54, 55], [55, 59], [59, 60], [61, 64], [64, 65], [66, 86], [87, 89], [90, 97], [98, 109], [110, 113], [114, 123], [124, 133], [134, 142], [143, 150], [151, 156], [157, 158], [159, 163], [164, 168], [169, 171], [172, 177], [178, 179], [180, 186], [187, 200], [201, 210], [210, 211], [212, 216], [217, 223], [224, 226], [227, 230], [231, 242], [243, 246], [247, 256], [257, 266], [266, 267]]}
{"doc_key": "ai-dev-181", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [12, 13, "researcher"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 25, 26, "related-to", "", false, false], [5, 6, 25, 26, "related-to", "", false, false], [8, 8, 25, 26, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Wraz", "z", "Geoffreyem", "Hintonem", "i", "Yannem", "LeCunem", ",", "Bengio", "jest", "uwa\u017cany", "przez", "Cade'a", "Metza", "za", "jedn\u0105", "z", "trzech", "os\u00f3b", "najbardziej", "odpowiedzialnych", "za", "post\u0119p", "w", "dziedzinie", "uczenia", "g\u0142\u0119bokiego", "w", "latach", "90", ".", "i", "2000", "."], "sentence-detokenized": "Wraz z Geoffreyem Hintonem i Yannem LeCunem, Bengio jest uwa\u017cany przez Cade'a Metza za jedn\u0105 z trzech os\u00f3b najbardziej odpowiedzialnych za post\u0119p w dziedzinie uczenia g\u0142\u0119bokiego w latach 90. i 2000.", "token2charspan": [[0, 4], [5, 6], [7, 17], [18, 26], [27, 28], [29, 35], [36, 43], [43, 44], [45, 51], [52, 56], [57, 64], [65, 70], [71, 77], [78, 83], [84, 86], [87, 92], [93, 94], [95, 101], [102, 106], [107, 118], [119, 135], [136, 138], [139, 145], [146, 147], [148, 158], [159, 166], [167, 177], [178, 179], [180, 186], [187, 189], [189, 190], [191, 192], [193, 197], [197, 198]]}
{"doc_key": "ai-dev-182", "ner": [[1, 2, "field"], [4, 5, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["W", "teorii", "informacji", "i", "informatyce", "za", "kod", "uwa\u017ca", "si\u0119", "zwykle", "algorytm", ",", "kt\u00f3ry", "jednoznacznie", "reprezentuje", "symbole", "z", "jakiego\u015b", "alfabetu", "\u017ar\u00f3d\u0142owego", ",", "przez", "zakodowane", "ci\u0105gi", "znak\u00f3w", ",", "kt\u00f3re", "mog\u0105", "by\u0107", "w", "jakim\u015b", "innym", "alfabecie", "docelowym", "."], "sentence-detokenized": "W teorii informacji i informatyce za kod uwa\u017ca si\u0119 zwykle algorytm, kt\u00f3ry jednoznacznie reprezentuje symbole z jakiego\u015b alfabetu \u017ar\u00f3d\u0142owego, przez zakodowane ci\u0105gi znak\u00f3w, kt\u00f3re mog\u0105 by\u0107 w jakim\u015b innym alfabecie docelowym.", "token2charspan": [[0, 1], [2, 8], [9, 19], [20, 21], [22, 33], [34, 36], [37, 40], [41, 46], [47, 50], [51, 57], [58, 66], [66, 67], [68, 73], [74, 87], [88, 100], [101, 108], [109, 110], [111, 119], [120, 128], [129, 139], [139, 140], [141, 146], [147, 157], [158, 163], [164, 170], [170, 171], [172, 177], [178, 182], [183, 186], [187, 188], [189, 195], [196, 201], [202, 211], [212, 221], [221, 222]]}
{"doc_key": "ai-dev-183", "ner": [[5, 6, "algorithm"], [10, 11, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 11, 5, 6, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Do\u015b\u0107", "prosta", "funkcja", "nieliniowa", ",", "funkcja", "sigmoidalna", ",", "taka", "jak", "funkcja", "logistyczna", ",", "ma", "r\u00f3wnie\u017c", "\u0142atwo", "obliczaln\u0105", "pochodn\u0105", ",", "co", "mo\u017ce", "by\u0107", "istotne", "przy", "obliczaniu", "aktualizacji", "wag", "w", "sieci", "."], "sentence-detokenized": "Do\u015b\u0107 prosta funkcja nieliniowa, funkcja sigmoidalna, taka jak funkcja logistyczna, ma r\u00f3wnie\u017c \u0142atwo obliczaln\u0105 pochodn\u0105, co mo\u017ce by\u0107 istotne przy obliczaniu aktualizacji wag w sieci.", "token2charspan": [[0, 4], [5, 11], [12, 19], [20, 30], [30, 31], [32, 39], [40, 51], [51, 52], [53, 57], [58, 61], [62, 69], [70, 81], [81, 82], [83, 85], [86, 93], [94, 99], [100, 110], [111, 119], [119, 120], [121, 123], [124, 128], [129, 132], [133, 140], [141, 145], [146, 156], [157, 169], [170, 173], [174, 175], [176, 181], [181, 182]]}
{"doc_key": "ai-dev-184", "ner": [[0, 0, "person"], [4, 5, "location"], [6, 6, "location"], [8, 10, "country"], [13, 13, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[0, 0, 4, 5, "physical", "", false, false], [4, 5, 6, 6, "physical", "", false, false], [6, 6, 8, 10, "physical", "", false, false], [6, 6, 13, 13, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 4], "sentence": ["\u010capek", "urodzi\u0142", "si\u0119", "w", "Hronovie", "w", "Czechach", "(", "Austro", "-", "W\u0119gry", ",", "p\u00f3\u017aniej", "Czechos\u0142owacja", ",", "obecnie", "Czechy", ")", "w", "1887", "roku", "."], "sentence-detokenized": "\u010capek urodzi\u0142 si\u0119 w Hronovie w Czechach (Austro-W\u0119gry, p\u00f3\u017aniej Czechos\u0142owacja, obecnie Czechy) w 1887 roku.", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 19], [20, 28], [29, 30], [31, 39], [40, 41], [41, 47], [47, 48], [48, 53], [53, 54], [55, 62], [63, 77], [77, 78], [79, 86], [87, 93], [93, 94], [95, 96], [97, 101], [102, 106], [106, 107]]}
{"doc_key": "ai-dev-185", "ner": [[6, 6, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Niekt\u00f3re", "wyspecjalizowane", "programy", "mog\u0105", "prowadzi\u0107", "narracj\u0119", "RSS", "."], "sentence-detokenized": "Niekt\u00f3re wyspecjalizowane programy mog\u0105 prowadzi\u0107 narracj\u0119 RSS.", "token2charspan": [[0, 8], [9, 25], [26, 34], [35, 39], [40, 49], [50, 58], [59, 62], [62, 63]]}
{"doc_key": "ai-dev-186", "ner": [[6, 7, "task"], [10, 11, "task"], [13, 14, "task"], [16, 16, "task"], [18, 20, "task"], [27, 28, "task"], [30, 31, "task"], [34, 35, "task"], [38, 38, "product"], [40, 41, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[6, 7, 10, 11, "related-to", "", true, false], [6, 7, 13, 14, "related-to", "", true, false], [6, 7, 16, 16, "related-to", "", true, false], [30, 31, 27, 28, "usage", "", true, false], [38, 38, 34, 35, "type-of", "", false, false], [40, 41, 34, 35, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Aspekty", "edytor\u00f3w", "ontologii", "obejmuj\u0105", ":", "mo\u017cliwo\u015bci", "wizualnej", "nawigacji", "w", "obr\u0119bie", "modelu", "wiedzy", ",", "silnik\u00f3w", "wnioskowania", "i", "ekstrakcji", ";", "wsparcie", "dla", "modu\u0142\u00f3w", ";", "import", "i", "eksport", "obcych", "j\u0119zyk\u00f3w", "reprezentacji", "wiedzy", "dla", "dopasowania", "ontologii", ";", "wsparcie", "meta-", "ontologii", "takich", "jak", "OWL-S", ",", "Dublin", "Core", ",", "itp", "."], "sentence-detokenized": "Aspekty edytor\u00f3w ontologii obejmuj\u0105: mo\u017cliwo\u015bci wizualnej nawigacji w obr\u0119bie modelu wiedzy, silnik\u00f3w wnioskowania i ekstrakcji; wsparcie dla modu\u0142\u00f3w; import i eksport obcych j\u0119zyk\u00f3w reprezentacji wiedzy dla dopasowania ontologii; wsparcie meta-ontologii takich jak OWL-S, Dublin Core, itp.", "token2charspan": [[0, 7], [8, 16], [17, 26], [27, 35], [35, 36], [37, 47], [48, 57], [58, 67], [68, 69], [70, 77], [78, 84], [85, 91], [91, 92], [93, 101], [102, 114], [115, 116], [117, 127], [127, 128], [129, 137], [138, 141], [142, 149], [149, 150], [151, 157], [158, 159], [160, 167], [168, 174], [175, 182], [183, 196], [197, 203], [204, 207], [208, 219], [220, 229], [229, 230], [231, 239], [240, 245], [245, 254], [255, 261], [262, 265], [266, 271], [271, 272], [273, 279], [280, 284], [284, 285], [286, 289], [289, 290]]}
{"doc_key": "ai-dev-187", "ner": [[0, 0, "organisation"], [3, 6, "misc"], [10, 14, "task"], [17, 18, "field"], [22, 23, "misc"], [25, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 6, 0, 0, "origin", "", false, false], [10, 14, 3, 6, "part-of", "", false, false], [17, 18, 3, 6, "part-of", "", false, false], [22, 23, 17, 18, "type-of", "", false, false], [25, 26, 17, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["FBI", "wprowadzi\u0142o", "r\u00f3wnie\u017c", "program", "Next", "Generation", "Identification", ",", "kt\u00f3ry", "obejmuje", "rozpoznawanie", "twarzy", ",", "a", "tak\u017ce", "bardziej", "tradycyjne", "dane", "biometryczne", ",", "takie", "jak", "odciski", "palc\u00f3w", "i", "skany", "t\u0119cz\u00f3wki", ",", "kt\u00f3re", "mog\u0105", "pochodzi\u0107", "zar\u00f3wno", "z", "kryminalnych", ",", "jak", "i", "cywilnych", "baz", "danych", "."], "sentence-detokenized": "FBI wprowadzi\u0142o r\u00f3wnie\u017c program Next Generation Identification, kt\u00f3ry obejmuje rozpoznawanie twarzy, a tak\u017ce bardziej tradycyjne dane biometryczne, takie jak odciski palc\u00f3w i skany t\u0119cz\u00f3wki, kt\u00f3re mog\u0105 pochodzi\u0107 zar\u00f3wno z kryminalnych, jak i cywilnych baz danych.", "token2charspan": [[0, 3], [4, 15], [16, 23], [24, 31], [32, 36], [37, 47], [48, 62], [62, 63], [64, 69], [70, 78], [79, 92], [93, 99], [99, 100], [101, 102], [103, 108], [109, 117], [118, 128], [129, 133], [134, 146], [146, 147], [148, 153], [154, 157], [158, 165], [166, 172], [173, 174], [175, 180], [181, 189], [189, 190], [191, 196], [197, 201], [202, 211], [212, 219], [220, 221], [222, 234], [234, 235], [236, 239], [240, 241], [242, 251], [252, 255], [256, 262], [262, 263]]}
{"doc_key": "ai-dev-188", "ner": [[4, 5, "person"], [10, 11, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["W", "sezonie", "2016", "dodano", "Samanth\u0119", "Ponder", "jako", "gospodarza", ",", "zast\u0119puj\u0105c", "Molly", "McGrath", "."], "sentence-detokenized": "W sezonie 2016 dodano Samanth\u0119 Ponder jako gospodarza, zast\u0119puj\u0105c Molly McGrath.", "token2charspan": [[0, 1], [2, 9], [10, 14], [15, 21], [22, 30], [31, 37], [38, 42], [43, 53], [53, 54], [55, 65], [66, 71], [72, 79], [79, 80]]}
{"doc_key": "ai-dev-189", "ner": [[2, 4, "algorithm"], [14, 15, "misc"], [17, 17, "misc"], [19, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Jest", "to", "algorytm", "wyszukiwania", "adwersarza", "stosowany", "powszechnie", "do", "maszynowego", "grania", "w", "gry", "dwuosobowe", "(", "Tic-tac-", "toe", ",", "Szachy", ",", "Go", "itp", "."], "sentence-detokenized": "Jest to algorytm wyszukiwania adwersarza stosowany powszechnie do maszynowego grania w gry dwuosobowe (Tic-tac-toe, Szachy, Go itp.", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 29], [30, 40], [41, 50], [51, 62], [63, 65], [66, 77], [78, 84], [85, 86], [87, 90], [91, 101], [102, 103], [103, 111], [111, 114], [114, 115], [116, 122], [122, 123], [124, 126], [127, 130], [130, 131]]}
{"doc_key": "ai-dev-190", "ner": [[3, 4, "field"], [6, 6, "field"], [8, 11, "field"], [15, 16, "field"], [18, 19, "field"], [21, 21, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Obejmuje", "ona", "dziedziny", "wizji", "komputerowej", "lub", "maszynowej", "oraz", "obrazowania", "medycznego", "i", "w", "znacznym", "stopniu", "wykorzystuje", "rozpoznawanie", "wzor\u00f3w", ",", "geometri\u0119", "cyfrow\u0105", "i", "przetwarzanie", "sygna\u0142\u00f3w", "."], "sentence-detokenized": "Obejmuje ona dziedziny wizji komputerowej lub maszynowej oraz obrazowania medycznego i w znacznym stopniu wykorzystuje rozpoznawanie wzor\u00f3w, geometri\u0119 cyfrow\u0105 i przetwarzanie sygna\u0142\u00f3w.", "token2charspan": [[0, 8], [9, 12], [13, 22], [23, 28], [29, 41], [42, 45], [46, 56], [57, 61], [62, 73], [74, 84], [85, 86], [87, 88], [89, 97], [98, 105], [106, 118], [119, 132], [133, 139], [139, 140], [141, 150], [151, 158], [159, 160], [161, 174], [175, 183], [183, 184]]}
{"doc_key": "ai-dev-191", "ner": [[1, 6, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["W", "systemie", "rozpoznawania", "twarzy", ",", "na", "przyk\u0142ad", ",", "zdj\u0119cie", "twarzy", "osoby", "b\u0119dzie", "wej\u015bciem", ",", "a", "etykiet\u0105", "wyj\u015bciow\u0105", "b\u0119dzie", "imi\u0119", "tej", "osoby", "."], "sentence-detokenized": "W systemie rozpoznawania twarzy, na przyk\u0142ad, zdj\u0119cie twarzy osoby b\u0119dzie wej\u015bciem, a etykiet\u0105 wyj\u015bciow\u0105 b\u0119dzie imi\u0119 tej osoby.", "token2charspan": [[0, 1], [2, 10], [11, 24], [25, 31], [31, 32], [33, 35], [36, 44], [44, 45], [46, 53], [54, 60], [61, 66], [67, 73], [74, 82], [82, 83], [84, 85], [86, 94], [95, 104], [105, 111], [112, 116], [117, 120], [121, 126], [126, 127]]}
{"doc_key": "ai-dev-192", "ner": [[0, 1, "organisation"], [3, 5, "product"], [7, 8, "product"], [14, 15, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 3, 5, "artifact", "", false, false], [3, 5, 7, 8, "part-of", "", false, false], [7, 8, 3, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Apple", "Inc", "wprowadzi\u0142", "Face", "ID", "we", "flagowym", "iPhone", "X", "jako", "nast\u0119pc\u0119", "uwierzytelniania", "biometrycznego", "dla", "Touch", "ID", ",", "systemu", "opartego", "na", "odciskach", "palc\u00f3w", "."], "sentence-detokenized": "Apple Inc wprowadzi\u0142 Face ID we flagowym iPhone X jako nast\u0119pc\u0119 uwierzytelniania biometrycznego dla Touch ID, systemu opartego na odciskach palc\u00f3w.", "token2charspan": [[0, 5], [6, 9], [10, 20], [21, 25], [26, 28], [29, 31], [32, 40], [41, 47], [48, 49], [50, 54], [55, 63], [64, 80], [81, 95], [96, 99], [100, 105], [106, 108], [108, 109], [110, 117], [118, 126], [127, 129], [130, 139], [140, 146], [146, 147]]}
{"doc_key": "ai-dev-193", "ner": [[2, 3, "metrics"], [5, 5, "metrics"], [15, 18, "metrics"], [20, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Lub", "po\u0142\u0105czy\u0107", "\u015brodek", "F", "z", "R-kwadratem", "ocenionym", "dla", "surowego", "wyj\u015bcia", "modelu", "i", "celu", ";", "lub", "macierz", "koszt\u00f3w", "/", "zysk\u00f3w", "z", "wsp\u00f3\u0142czynnikiem", "korelacji", ",", "i", "tak", "dalej", "."], "sentence-detokenized": "Lub po\u0142\u0105czy\u0107 \u015brodek F z R-kwadratem ocenionym dla surowego wyj\u015bcia modelu i celu; lub macierz koszt\u00f3w / zysk\u00f3w z wsp\u00f3\u0142czynnikiem korelacji, i tak dalej.", "token2charspan": [[0, 3], [4, 12], [13, 19], [20, 21], [22, 23], [24, 35], [36, 45], [46, 49], [50, 58], [59, 66], [67, 73], [74, 75], [76, 80], [80, 81], [82, 85], [86, 93], [94, 101], [102, 103], [104, 110], [111, 112], [113, 128], [129, 138], [138, 139], [140, 141], [142, 145], [146, 151], [151, 152]]}
{"doc_key": "ai-dev-194", "ner": [[0, 3, "conference"], [7, 9, "location"], [11, 11, "location"], [13, 17, "location"], [19, 20, "location"], [21, 21, "country"], [26, 28, "location"], [33, 37, "location"], [39, 40, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 3, 7, 9, "physical", "", false, false], [0, 3, 13, 17, "physical", "", false, false], [0, 3, 26, 28, "physical", "", false, false], [0, 3, 33, 37, "physical", "", false, false], [7, 9, 11, 11, "physical", "", false, false], [13, 17, 19, 20, "physical", "", false, false], [19, 20, 21, 21, "physical", "", false, false], [26, 28, 39, 40, "physical", "", false, false], [33, 37, 39, 40, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Hiszpa\u0144ska", "edycja", "Campus", "Party", "odby\u0142a", "si\u0119", "w", "Colegio", "Miguel", "Hern\u00e1ndez", ",", "Ceulaj", "i", "Municipal", "Sport", "Arena", "of", "Benalm\u00e1dena", "w", "M\u00e1laga", "w", "Hiszpanii", ";", "oraz", "zar\u00f3wno", "na", "Targach", "Hrabstwa", "Walencji", ",", "jak", "i", "w", "City", "of", "Arts", "and", "Sciences", "w", "Walencji", "w", "ci\u0105gu", "ostatnich", "15", "lat", "."], "sentence-detokenized": "Hiszpa\u0144ska edycja Campus Party odby\u0142a si\u0119 w Colegio Miguel Hern\u00e1ndez, Ceulaj i Municipal Sport Arena of Benalm\u00e1dena w M\u00e1laga w Hiszpanii; oraz zar\u00f3wno na Targach Hrabstwa Walencji, jak i w City of Arts and Sciences w Walencji w ci\u0105gu ostatnich 15 lat.", "token2charspan": [[0, 10], [11, 17], [18, 24], [25, 30], [31, 37], [38, 41], [42, 43], [44, 51], [52, 58], [59, 68], [68, 69], [70, 76], [77, 78], [79, 88], [89, 94], [95, 100], [101, 103], [104, 115], [116, 117], [118, 124], [125, 126], [127, 136], [136, 137], [138, 142], [143, 150], [151, 153], [154, 161], [162, 170], [171, 179], [179, 180], [181, 184], [185, 186], [187, 188], [189, 193], [194, 196], [197, 201], [202, 205], [206, 214], [215, 216], [217, 225], [226, 227], [228, 233], [234, 243], [244, 246], [247, 250], [250, 251]]}
{"doc_key": "ai-dev-195", "ner": [[0, 0, "product"], [15, 15, "programlang"], [19, 19, "product"], [21, 21, "product"], [24, 24, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 15, 0, 0, "general-affiliation", "", false, false], [19, 19, 15, 15, "part-of", "", false, false], [21, 21, 15, 15, "part-of", "", false, false], [24, 24, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["gnuplot", "mo\u017ce", "by\u0107", "u\u017cywany", "z", "r\u00f3\u017cnych", "j\u0119zyk\u00f3w", "programowania", "do", "tworzenia", "wykres\u00f3w", "danych", ",", "w", "tym", "Perl", "(", "poprzez", "pakiety", "PDL", "i", "CPAN", ")", ",", "Python", "(", "poprzez", ")", "."], "sentence-detokenized": "gnuplot mo\u017ce by\u0107 u\u017cywany z r\u00f3\u017cnych j\u0119zyk\u00f3w programowania do tworzenia wykres\u00f3w danych, w tym Perl (poprzez pakiety PDL i CPAN), Python (poprzez).", "token2charspan": [[0, 7], [8, 12], [13, 16], [17, 24], [25, 26], [27, 34], [35, 42], [43, 56], [57, 59], [60, 69], [70, 78], [79, 85], [85, 86], [87, 88], [89, 92], [93, 97], [98, 99], [99, 106], [107, 114], [115, 118], [119, 120], [121, 125], [125, 126], [126, 127], [128, 134], [135, 136], [136, 143], [143, 144], [144, 145]]}
{"doc_key": "ai-dev-196", "ner": [[1, 3, "product"], [17, 17, "conference"], [19, 19, "conference"], [31, 31, "conference"], [33, 33, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[17, 17, 1, 3, "topic", "", false, false], [19, 19, 1, 3, "topic", "", false, false], [31, 31, 1, 3, "topic", "", false, false], [33, 33, 1, 3, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Dziedzina", "m\u00f3wionych", "system\u00f3w", "dialogowych", "jest", "do\u015b\u0107", "du\u017ca", "i", "obejmuje", "badania", "(", "prezentowane", "na", "konferencjach", "naukowych", "takich", "jak", "SIGdial", "i", "Interspeech", ")", "oraz", "du\u017cy", "sektor", "przemys\u0142owy", "(", "z", "w\u0142asnymi", "spotkaniami", "takimi", "jak", "SpeechTek", "i", "AVIOS", ")", "."], "sentence-detokenized": "Dziedzina m\u00f3wionych system\u00f3w dialogowych jest do\u015b\u0107 du\u017ca i obejmuje badania (prezentowane na konferencjach naukowych takich jak SIGdial i Interspeech) oraz du\u017cy sektor przemys\u0142owy (z w\u0142asnymi spotkaniami takimi jak SpeechTek i AVIOS).", "token2charspan": [[0, 9], [10, 19], [20, 28], [29, 40], [41, 45], [46, 50], [51, 55], [56, 57], [58, 66], [67, 74], [75, 76], [76, 88], [89, 91], [92, 105], [106, 115], [116, 122], [123, 126], [127, 134], [135, 136], [137, 148], [148, 149], [150, 154], [155, 159], [160, 166], [167, 178], [179, 180], [180, 181], [182, 190], [191, 202], [203, 209], [210, 213], [214, 223], [224, 225], [226, 231], [231, 232], [232, 233]]}
{"doc_key": "ai-dev-197", "ner": [[3, 5, "field"], [8, 9, "task"], [11, 13, "task"], [15, 17, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 3, 5, "part-of", "task_part_of_field", false, false], [11, 13, 3, 5, "part-of", "task_part_of_field", false, false], [15, 17, 3, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Wyzwania", "zwi\u0105zane", "z", "przetwarzaniem", "j\u0119zyka", "naturalnego", "cz\u0119sto", "dotycz\u0105", "rozpoznawania", "mowy", ",", "rozumienia", "j\u0119zyka", "naturalnego", "i", "generowania", "j\u0119zyka", "naturalnego", "."], "sentence-detokenized": "Wyzwania zwi\u0105zane z przetwarzaniem j\u0119zyka naturalnego cz\u0119sto dotycz\u0105 rozpoznawania mowy, rozumienia j\u0119zyka naturalnego i generowania j\u0119zyka naturalnego.", "token2charspan": [[0, 8], [9, 17], [18, 19], [20, 34], [35, 41], [42, 53], [54, 60], [61, 68], [69, 82], [83, 87], [87, 88], [89, 99], [100, 106], [107, 118], [119, 120], [121, 132], [133, 139], [140, 151], [151, 152]]}
{"doc_key": "ai-dev-198", "ner": [[5, 5, "product"], [7, 9, "product"], [33, 34, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 7, 9, "part-of", "", false, false], [5, 5, 33, 34, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Systemy", "te", ",", "takie", "jak", "Siri", "z", "systemu", "operacyjnego", "iOS", ",", "dzia\u0142aj\u0105", "na", "podobnej", "technice", "rozpoznawania", "wzorc\u00f3w", "jak", "systemy", "tekstowe", ",", "jednak", "w", "przypadku", "tych", "pierwszych", "wprowadzanie", "danych", "przez", "u\u017cytkownika", "odbywa", "si\u0119", "poprzez", "rozpoznawanie", "mowy", "."], "sentence-detokenized": "Systemy te, takie jak Siri z systemu operacyjnego iOS, dzia\u0142aj\u0105 na podobnej technice rozpoznawania wzorc\u00f3w jak systemy tekstowe, jednak w przypadku tych pierwszych wprowadzanie danych przez u\u017cytkownika odbywa si\u0119 poprzez rozpoznawanie mowy.", "token2charspan": [[0, 7], [8, 10], [10, 11], [12, 17], [18, 21], [22, 26], [27, 28], [29, 36], [37, 49], [50, 53], [53, 54], [55, 63], [64, 66], [67, 75], [76, 84], [85, 98], [99, 106], [107, 110], [111, 118], [119, 127], [127, 128], [129, 135], [136, 137], [138, 147], [148, 152], [153, 163], [164, 176], [177, 183], [184, 189], [190, 201], [202, 208], [209, 212], [213, 220], [221, 234], [235, 239], [239, 240]]}
{"doc_key": "ai-dev-199", "ner": [[1, 3, "algorithm"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 3, 13, 14, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Bardziej", "egzotyczne", "funkcje", "fitness", ",", "kt\u00f3re", "badaj\u0105", "ziarnisto\u015b\u0107", "modelu", ",", "obejmuj\u0105", "obszar", "pod", "krzyw\u0105", "ROC", "i", "miar\u0119", "rangi", "."], "sentence-detokenized": "Bardziej egzotyczne funkcje fitness, kt\u00f3re badaj\u0105 ziarnisto\u015b\u0107 modelu, obejmuj\u0105 obszar pod krzyw\u0105 ROC i miar\u0119 rangi.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 35], [35, 36], [37, 42], [43, 49], [50, 61], [62, 68], [68, 69], [70, 78], [79, 85], [86, 89], [90, 96], [97, 100], [101, 102], [103, 108], [109, 114], [114, 115]]}
{"doc_key": "ai-dev-200", "ner": [[1, 2, "product"], [6, 7, "researcher"], [10, 12, "product"], [15, 18, "organisation"], [20, 20, "organisation"], [27, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 2, 6, 7, "origin", "", false, false], [6, 7, 15, 18, "role", "", false, false], [10, 12, 6, 7, "origin", "", false, false], [20, 20, 15, 18, "named", "", false, false], [27, 29, 15, 18, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Termin", "Semantic", "Web", "zosta\u0142", "ukuty", "przez", "Tima", "Berners-Lee", ",", "wynalazc\u0119", "World", "Wide", "Web", "i", "dyrektora", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", ",", "kt\u00f3re", "nadzoruje", "rozw\u00f3j", "proponowanych", "standard\u00f3w", "Semantic", "Web", "."], "sentence-detokenized": "Termin Semantic Web zosta\u0142 ukuty przez Tima Berners-Lee, wynalazc\u0119 World Wide Web i dyrektora World Wide Web Consortium (W3C), kt\u00f3re nadzoruje rozw\u00f3j proponowanych standard\u00f3w Semantic Web.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 26], [27, 32], [33, 38], [39, 43], [44, 55], [55, 56], [57, 66], [67, 72], [73, 77], [78, 81], [82, 83], [84, 93], [94, 99], [100, 104], [105, 108], [109, 119], [120, 121], [121, 124], [124, 125], [125, 126], [127, 132], [133, 142], [143, 149], [150, 163], [164, 174], [175, 183], [184, 187], [187, 188]]}
{"doc_key": "ai-dev-201", "ner": [[0, 1, "task"], [6, 6, "task"], [13, 13, "product"], [16, 17, "product"], [19, 19, "product"], [23, 23, "product"], [28, 29, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 13, 13, "opposite", "", false, false], [0, 1, 16, 17, "opposite", "", false, false], [0, 1, 23, 23, "opposite", "", false, false], [0, 1, 28, 29, "part-of", "", false, false], [6, 6, 0, 1, "named", "", false, false], [19, 19, 16, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["T\u0142umaczenie", "maszynowe", ",", "czasami", "okre\u015blane", "skr\u00f3tem", "MT", "(", "nie", "myli\u0107", "z", "t\u0142umaczeniem", "wspomaganym", "komputerowo", ",", "t\u0142umaczeniem", "wspomaganym", "maszynowo", "(", "MAHT", ")", "lub", "t\u0142umaczeniem", "interaktywnym", ")", ",", "jest", "poddziedzin\u0105", "lingwistyki", "obliczeniowej", ",", "kt\u00f3ra", "bada", "wykorzystanie", "oprogramowania", "do", "t\u0142umaczenia", "tekstu", "lub", "mowy", "z", "jednego", "j\u0119zyka", "na", "drugi", "."], "sentence-detokenized": "T\u0142umaczenie maszynowe, czasami okre\u015blane skr\u00f3tem MT (nie myli\u0107 z t\u0142umaczeniem wspomaganym komputerowo, t\u0142umaczeniem wspomaganym maszynowo (MAHT) lub t\u0142umaczeniem interaktywnym), jest poddziedzin\u0105 lingwistyki obliczeniowej, kt\u00f3ra bada wykorzystanie oprogramowania do t\u0142umaczenia tekstu lub mowy z jednego j\u0119zyka na drugi.", "token2charspan": [[0, 11], [12, 21], [21, 22], [23, 30], [31, 40], [41, 48], [49, 51], [52, 53], [53, 56], [57, 62], [63, 64], [65, 77], [78, 89], [90, 101], [101, 102], [103, 115], [116, 127], [128, 137], [138, 139], [139, 143], [143, 144], [145, 148], [149, 161], [162, 175], [175, 176], [176, 177], [178, 182], [183, 195], [196, 207], [208, 221], [221, 222], [223, 228], [229, 233], [234, 247], [248, 262], [263, 265], [266, 277], [278, 284], [285, 288], [289, 293], [294, 295], [296, 303], [304, 310], [311, 313], [314, 319], [319, 320]]}
{"doc_key": "ai-dev-202", "ner": [[1, 3, "product"], [8, 9, "university"], [14, 15, "researcher"], [17, 18, "researcher"], [37, 39, "location"], [41, 41, "location"], [44, 47, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 3, 14, 15, "artifact", "", false, false], [1, 3, 17, 18, "artifact", "", false, false], [14, 15, 8, 9, "physical", "", false, false], [14, 15, 8, 9, "role", "", false, false], [17, 18, 8, 9, "physical", "", false, false], [17, 18, 8, 9, "role", "", false, false], [37, 39, 41, 41, "physical", "", false, false], [44, 47, 37, 39, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Wczesne", "mi\u0119dzyj\u0119zykowe", "systemy", "MT", "zosta\u0142y", "r\u00f3wnie\u017c", "zbudowane", "w", "Stanford", "w", "latach", "70", ".", "przez", "Rogera", "Schanka", "i", "Yoricka", "Wilksa", ";", "pierwszy", "z", "nich", "sta\u0142", "si\u0119", "podstaw\u0105", "komercyjnego", "systemu", "transferu", "\u015brodk\u00f3w", ",", "a", "kod", "drugiego", "zachowa\u0142", "si\u0119", "w", "The", "Computer", "Museum", "w", "Bostonie", "jako", "pierwszy", "mi\u0119dzyj\u0119zykowy", "system", "t\u0142umaczenia", "maszynowego", "."], "sentence-detokenized": "Wczesne mi\u0119dzyj\u0119zykowe systemy MT zosta\u0142y r\u00f3wnie\u017c zbudowane w Stanford w latach 70. przez Rogera Schanka i Yoricka Wilksa; pierwszy z nich sta\u0142 si\u0119 podstaw\u0105 komercyjnego systemu transferu \u015brodk\u00f3w, a kod drugiego zachowa\u0142 si\u0119 w The Computer Museum w Bostonie jako pierwszy mi\u0119dzyj\u0119zykowy system t\u0142umaczenia maszynowego.", "token2charspan": [[0, 7], [8, 22], [23, 30], [31, 33], [34, 41], [42, 49], [50, 59], [60, 61], [62, 70], [71, 72], [73, 79], [80, 82], [82, 83], [84, 89], [90, 96], [97, 104], [105, 106], [107, 114], [115, 121], [121, 122], [123, 131], [132, 133], [134, 138], [139, 143], [144, 147], [148, 156], [157, 169], [170, 177], [178, 187], [188, 195], [195, 196], [197, 198], [199, 202], [203, 211], [212, 220], [221, 224], [225, 226], [227, 230], [231, 239], [240, 246], [247, 248], [249, 257], [258, 262], [263, 271], [272, 286], [287, 293], [294, 305], [306, 317], [317, 318]]}
{"doc_key": "ai-dev-203", "ner": [[0, 1, "researcher"], [5, 9, "conference"], [11, 12, "conference"], [17, 21, "conference"], [24, 24, "conference"], [28, 31, "organisation"], [40, 40, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 5, 9, "role", "", false, false], [0, 1, 17, 21, "role", "", false, false], [0, 1, 28, 31, "role", "", false, false], [0, 1, 40, 40, "role", "", false, false], [11, 12, 5, 9, "named", "", false, false], [24, 24, 17, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sycara", "pe\u0142ni\u0142", "funkcj\u0119", "przewodnicz\u0105cego", "programu", "Drugiej", "Mi\u0119dzynarodowej", "Konferencji", "Semantycznej", "Sieci", "(", "ISWC", "2003", ")", ";", "og\u00f3lnego", "przewodnicz\u0105cego", "Drugiej", "Mi\u0119dzynarodowej", "Konferencji", "Agent\u00f3w", "Autonomicznych", "(", "Agents", "98", ")", ";", "przewodnicz\u0105cego", "Komitetu", "Steruj\u0105cego", "Konferencji", "Agent\u00f3w", "(", "1999", "-", "2001", ")", ";", "przewodnicz\u0105cego", "stypendium", "AAAI", "(", "1993", "-", "1999", ")", ";"], "sentence-detokenized": "Sycara pe\u0142ni\u0142 funkcj\u0119 przewodnicz\u0105cego programu Drugiej Mi\u0119dzynarodowej Konferencji Semantycznej Sieci (ISWC 2003); og\u00f3lnego przewodnicz\u0105cego Drugiej Mi\u0119dzynarodowej Konferencji Agent\u00f3w Autonomicznych (Agents 98); przewodnicz\u0105cego Komitetu Steruj\u0105cego Konferencji Agent\u00f3w (1999-2001); przewodnicz\u0105cego stypendium AAAI (1993-1999);", "token2charspan": [[0, 6], [7, 13], [14, 21], [22, 38], [39, 47], [48, 55], [56, 71], [72, 83], [84, 96], [97, 102], [103, 104], [104, 108], [109, 113], [113, 114], [114, 115], [116, 124], [125, 141], [142, 149], [150, 165], [166, 177], [178, 185], [186, 200], [201, 202], [202, 208], [209, 211], [211, 212], [212, 213], [214, 230], [231, 239], [240, 251], [252, 263], [264, 271], [272, 273], [273, 277], [277, 278], [278, 282], [282, 283], [283, 284], [285, 301], [302, 312], [313, 317], [318, 319], [319, 323], [323, 324], [324, 328], [328, 329], [329, 330]]}
{"doc_key": "ai-dev-204", "ner": [[7, 7, "conference"], [9, 12, "conference"], [14, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 12, 7, 7, "named", "", false, false], [14, 16, 7, 7, "part-of", "", false, false], [14, 16, 7, 7, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["W", "2016", "roku", "zosta\u0142a", "wybrana", "jako", "laureatka", "ACL", "(", "Association", "for", "Computational", "Linguistics", ")", "Lifetime", "Achievement", "Award", "."], "sentence-detokenized": "W 2016 roku zosta\u0142a wybrana jako laureatka ACL (Association for Computational Linguistics) Lifetime Achievement Award.", "token2charspan": [[0, 1], [2, 6], [7, 11], [12, 19], [20, 27], [28, 32], [33, 42], [43, 46], [47, 48], [48, 59], [60, 63], [64, 77], [78, 89], [89, 90], [91, 99], [100, 111], [112, 117], [117, 118]]}
{"doc_key": "ai-dev-205", "ner": [[0, 1, "researcher"], [3, 5, "researcher"], [7, 9, "researcher"], [11, 12, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sepp", "Hochreiter", ",", "Y", ".", "Bengio", ",", "P", ".", "Frasconi", "i", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Sepp Hochreiter, Y. Bengio, P. Frasconi i J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 15], [15, 16], [17, 18], [18, 19], [20, 26], [26, 27], [28, 29], [29, 30], [31, 39], [40, 41], [42, 48], [49, 60], [60, 61]]}
{"doc_key": "ai-dev-206", "ner": [[3, 6, "product"], [8, 9, "misc"], [11, 11, "programlang"], [20, 22, "product"], [36, 36, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 6, 11, 11, "usage", "", false, false], [11, 11, 8, 9, "type-of", "", false, false], [11, 11, 20, 22, "related-to", "", false, false], [36, 36, 3, 6, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Na", "przyk\u0142ad", ",", "A.L.I.C", ".", "E", ".", "u\u017cywa", "j\u0119zyka", "znacznik\u00f3w", "zwanego", "AIML", ",", "kt\u00f3ry", "jest", "specyficzny", "dla", "jego", "funkcji", "jako", "systemu", "dialogowego", "i", "od", "tego", "czasu", "zosta\u0142", "przyj\u0119ty", "przez", "r\u00f3\u017cnych", "innych", "tw\u00f3rc\u00f3w", ",", "tak", "zwanych", ",", "Alicebots", "."], "sentence-detokenized": "Na przyk\u0142ad, A.L.I.C.E. u\u017cywa j\u0119zyka znacznik\u00f3w zwanego AIML, kt\u00f3ry jest specyficzny dla jego funkcji jako systemu dialogowego i od tego czasu zosta\u0142 przyj\u0119ty przez r\u00f3\u017cnych innych tw\u00f3rc\u00f3w, tak zwanych, Alicebots.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 20], [20, 21], [21, 22], [22, 23], [24, 29], [30, 36], [37, 47], [48, 55], [56, 60], [60, 61], [62, 67], [68, 72], [73, 84], [85, 88], [89, 93], [94, 101], [102, 106], [107, 114], [115, 126], [127, 128], [129, 131], [132, 136], [137, 142], [143, 149], [150, 158], [159, 164], [165, 172], [173, 179], [180, 187], [187, 188], [189, 192], [193, 200], [200, 201], [202, 211], [211, 212]]}
{"doc_key": "ai-dev-207", "ner": [[9, 15, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["W", "2000", "roku", "zosta\u0142a", "wybrana", "jako", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "W 2000 roku zosta\u0142a wybrana jako Fellow of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 1], [2, 6], [7, 11], [12, 19], [20, 27], [28, 32], [33, 39], [40, 42], [43, 46], [47, 58], [59, 62], [63, 66], [67, 78], [79, 81], [82, 92], [93, 105], [105, 106]]}
{"doc_key": "ai-dev-208", "ner": [[0, 3, "misc"], [5, 5, "misc"], [9, 13, "misc"], [22, 23, "algorithm"], [32, 32, "field"], [35, 35, "field"], [38, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 9, 13, "type-of", "", false, false], [0, 3, 32, 32, "related-to", "performs", true, false], [0, 3, 35, 35, "related-to", "performs", true, false], [0, 3, 38, 39, "related-to", "performs", true, false], [5, 5, 0, 3, "named", "", false, false], [22, 23, 9, 13, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Systemy", "klasyfikator\u00f3w", "ucz\u0105cych", "si\u0119", "(", "LCS", ")", "s\u0105", "rodzin\u0105", "algorytm\u00f3w", "uczenia", "maszynowego", "opartych", "na", "regu\u0142ach", ",", "kt\u00f3re", "\u0142\u0105cz\u0105", "komponent", "odkrywania", ",", "zwykle", "algorytm", "genetyczny", ",", "z", "komponentem", "uczenia", "si\u0119", ",", "wykonuj\u0105cym", "uczenie", "nadzorowane", ",", "uczenie", "wzmacniaj\u0105ce", "lub", "uczenie", "bez", "nadzoru", "."], "sentence-detokenized": "Systemy klasyfikator\u00f3w ucz\u0105cych si\u0119 (LCS) s\u0105 rodzin\u0105 algorytm\u00f3w uczenia maszynowego opartych na regu\u0142ach, kt\u00f3re \u0142\u0105cz\u0105 komponent odkrywania, zwykle algorytm genetyczny, z komponentem uczenia si\u0119, wykonuj\u0105cym uczenie nadzorowane, uczenie wzmacniaj\u0105ce lub uczenie bez nadzoru.", "token2charspan": [[0, 7], [8, 22], [23, 31], [32, 35], [36, 37], [37, 40], [40, 41], [42, 44], [45, 52], [53, 63], [64, 71], [72, 83], [84, 92], [93, 95], [96, 104], [104, 105], [106, 111], [112, 117], [118, 127], [128, 138], [138, 139], [140, 146], [147, 155], [156, 166], [166, 167], [168, 169], [170, 181], [182, 189], [190, 193], [193, 194], [195, 206], [207, 214], [215, 226], [226, 227], [228, 235], [236, 248], [249, 252], [253, 260], [261, 264], [265, 272], [272, 273]]}
{"doc_key": "ai-dev-209", "ner": [[15, 25, "algorithm"], [19, 19, "algorithm"], [26, 27, "algorithm"], [29, 29, "misc"], [38, 40, "algorithm"], [46, 50, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[15, 25, 26, 27, "origin", "", false, false], [15, 25, 29, 29, "usage", "", false, false], [19, 19, 15, 25, "named", "", false, false], [38, 40, 29, 29, "type-of", "", false, false], [38, 40, 46, 50, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Nieznane", "parametry", "w", "ka\u017cdym", "wektorze", "\u03b2subk", "/", "sub", "s\u0105", "zwykle", "wsp\u00f3lnie", "szacowane", "za", "pomoc\u0105", "estymacji", "maksymalnej", "a", "posteriori", "(", "MAP", ")", ",", "kt\u00f3ra", "jest", "rozszerzeniem", "maksymalnego", "prawdopodobie\u0144stwa", "z", "wykorzystaniem", "regularyzacji", "wag", ",", "aby", "zapobiec", "patologicznym", "rozwi\u0105zaniom", "(", "zwykle", "kwadratowa", "funkcja", "regularyzuj\u0105ca", ",", "kt\u00f3ra", "jest", "r\u00f3wnowa\u017cna", "umieszczeniu", "zerowej", "\u015bredniej", "Gaussa", "rozk\u0142adu", "priorytetowego", "na", "wagach", ",", "ale", "inne", "rozk\u0142ady", "s\u0105", "r\u00f3wnie\u017c", "mo\u017cliwe", ")", "."], "sentence-detokenized": "Nieznane parametry w ka\u017cdym wektorze \u03b2subk / sub s\u0105 zwykle wsp\u00f3lnie szacowane za pomoc\u0105 estymacji maksymalnej a posteriori (MAP), kt\u00f3ra jest rozszerzeniem maksymalnego prawdopodobie\u0144stwa z wykorzystaniem regularyzacji wag, aby zapobiec patologicznym rozwi\u0105zaniom (zwykle kwadratowa funkcja regularyzuj\u0105ca, kt\u00f3ra jest r\u00f3wnowa\u017cna umieszczeniu zerowej \u015bredniej Gaussa rozk\u0142adu priorytetowego na wagach, ale inne rozk\u0142ady s\u0105 r\u00f3wnie\u017c mo\u017cliwe).", "token2charspan": [[0, 8], [9, 18], [19, 20], [21, 27], [28, 36], [37, 42], [43, 44], [45, 48], [49, 51], [52, 58], [59, 67], [68, 77], [78, 80], [81, 87], [88, 97], [98, 109], [110, 111], [112, 122], [123, 124], [124, 127], [127, 128], [128, 129], [130, 135], [136, 140], [141, 154], [155, 167], [168, 186], [187, 188], [189, 203], [204, 217], [218, 221], [221, 222], [223, 226], [227, 235], [236, 249], [250, 262], [263, 264], [264, 270], [271, 281], [282, 289], [290, 304], [304, 305], [306, 311], [312, 316], [317, 327], [328, 340], [341, 348], [349, 357], [358, 364], [365, 373], [374, 388], [389, 391], [392, 398], [398, 399], [400, 403], [404, 408], [409, 417], [418, 420], [421, 428], [429, 436], [436, 437], [437, 438]]}
{"doc_key": "ai-dev-210", "ner": [[8, 9, "researcher"], [7, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 7, 8, 9, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Hierarchiczna", "struktura", "s\u0142\u00f3w", "zosta\u0142a", "jednoznacznie", "odwzorowana", "w", "Wordnecie", "George'a", "Millera", "."], "sentence-detokenized": "Hierarchiczna struktura s\u0142\u00f3w zosta\u0142a jednoznacznie odwzorowana w Wordnecie George'a Millera.", "token2charspan": [[0, 13], [14, 23], [24, 28], [29, 36], [37, 50], [51, 62], [63, 64], [65, 74], [75, 83], [84, 91], [91, 92]]}
{"doc_key": "ai-dev-211", "ner": [[4, 9, "conference"], [15, 23, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 23, 4, 9, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Ilustracj\u0105", "ich", "mo\u017cliwo\u015bci", "jest", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", ";", "jest", "to", "benchmark", "w", "klasyfikacji", "i", "detekcji", "obiekt\u00f3w", ",", "z", "milionami", "obraz\u00f3w", "i", "setkami", "klas", "obiekt\u00f3w", "."], "sentence-detokenized": "Ilustracj\u0105 ich mo\u017cliwo\u015bci jest ImageNet Large Scale Visual Recognition Challenge; jest to benchmark w klasyfikacji i detekcji obiekt\u00f3w, z milionami obraz\u00f3w i setkami klas obiekt\u00f3w.", "token2charspan": [[0, 10], [11, 14], [15, 25], [26, 30], [31, 39], [40, 45], [46, 51], [52, 58], [59, 70], [71, 80], [80, 81], [82, 86], [87, 89], [90, 99], [100, 101], [102, 114], [115, 116], [117, 125], [126, 134], [134, 135], [136, 137], [138, 147], [148, 155], [156, 157], [158, 165], [166, 170], [171, 179], [179, 180]]}
{"doc_key": "ai-dev-212", "ner": [[1, 2, "misc"], [24, 24, "misc"], [27, 30, "person"], [31, 31, "misc"], [37, 39, "person"], [40, 41, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[24, 24, 1, 2, "general-affiliation", "", false, false], [31, 31, 1, 2, "general-affiliation", "", false, false], [31, 31, 27, 30, "artifact", "", false, false], [40, 41, 1, 2, "general-affiliation", "", false, false], [40, 41, 37, 39, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["W", "science", "fiction", "roboty", "o", "wygl\u0105dzie", "kobiet", "s\u0105", "cz\u0119sto", "produkowane", "do", "u\u017cytku", "jako", "s\u0142u\u017cba", "domowa", "i", "seksualne", "niewolnice", ",", "jak", "to", "wida\u0107", "w", "filmie", "Westworld", ",", "powie\u015bci", "Paula", "J", ".", "McAuleya", "Fairyland", "(", "1995", ")", "i", "opowiadaniu", "Lestera", "del", "Reya", "Helen", "O'Loy", "(", "1938", ")", ",", "a", "czasem", "jako", "wojowniczki", ",", "zab\u00f3jczynie", "lub", "robotnice", "."], "sentence-detokenized": "W science fiction roboty o wygl\u0105dzie kobiet s\u0105 cz\u0119sto produkowane do u\u017cytku jako s\u0142u\u017cba domowa i seksualne niewolnice, jak to wida\u0107 w filmie Westworld, powie\u015bci Paula J. McAuleya Fairyland (1995) i opowiadaniu Lestera del Reya Helen O'Loy (1938), a czasem jako wojowniczki, zab\u00f3jczynie lub robotnice.", "token2charspan": [[0, 1], [2, 9], [10, 17], [18, 24], [25, 26], [27, 36], [37, 43], [44, 46], [47, 53], [54, 65], [66, 68], [69, 75], [76, 80], [81, 87], [88, 94], [95, 96], [97, 106], [107, 117], [117, 118], [119, 122], [123, 125], [126, 131], [132, 133], [134, 140], [141, 150], [150, 151], [152, 160], [161, 166], [167, 168], [168, 169], [170, 178], [179, 188], [189, 190], [190, 194], [194, 195], [196, 197], [198, 209], [210, 217], [218, 221], [222, 226], [227, 232], [233, 238], [239, 240], [240, 244], [244, 245], [245, 246], [247, 248], [249, 255], [256, 260], [261, 272], [272, 273], [274, 285], [286, 289], [290, 299], [299, 300]]}
{"doc_key": "ai-dev-213", "ner": [[0, 2, "task"], [4, 5, "task"], [7, 8, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["odpowiadanie", "na", "pytania", ",", "rozpoznawanie", "mowy", "i", "t\u0142umaczenie", "maszynowe", "."], "sentence-detokenized": "odpowiadanie na pytania, rozpoznawanie mowy i t\u0142umaczenie maszynowe.", "token2charspan": [[0, 12], [13, 15], [16, 23], [23, 24], [25, 38], [39, 43], [44, 45], [46, 57], [58, 67], [67, 68]]}
{"doc_key": "ai-dev-214", "ner": [[4, 5, "researcher"], [7, 11, "organisation"], [13, 16, "location"], [19, 19, "location"], [21, 21, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 7, 11, "role", "", false, false], [7, 11, 13, 16, "physical", "", false, false], [13, 16, 19, 19, "physical", "", false, false], [19, 19, 21, 21, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["W", "swojej", "prze\u0142omowej", "pracy", "Harry", "Blum", "z", "Air", "Force", "Cambridge", "Research", "Laboratories", "w", "Hanscom", "Air", "Force", "Base", ",", "w", "Bedford", ",", "Massachusetts", ",", "zdefiniowa\u0142", "o\u015b", "\u015brodkow\u0105", "do", "obliczania", "szkieletu", "kszta\u0142tu", ",", "wykorzystuj\u0105c", "intuicyjny", "model", "rozprzestrzeniania", "si\u0119", "ognia", "na", "polu", "trawy", ",", "gdzie", "pole", "ma", "posta\u0107", "danego", "kszta\u0142tu", "."], "sentence-detokenized": "W swojej prze\u0142omowej pracy Harry Blum z Air Force Cambridge Research Laboratories w Hanscom Air Force Base, w Bedford, Massachusetts, zdefiniowa\u0142 o\u015b \u015brodkow\u0105 do obliczania szkieletu kszta\u0142tu, wykorzystuj\u0105c intuicyjny model rozprzestrzeniania si\u0119 ognia na polu trawy, gdzie pole ma posta\u0107 danego kszta\u0142tu.", "token2charspan": [[0, 1], [2, 8], [9, 20], [21, 26], [27, 32], [33, 37], [38, 39], [40, 43], [44, 49], [50, 59], [60, 68], [69, 81], [82, 83], [84, 91], [92, 95], [96, 101], [102, 106], [106, 107], [108, 109], [110, 117], [117, 118], [119, 132], [132, 133], [134, 145], [146, 148], [149, 157], [158, 160], [161, 171], [172, 181], [182, 190], [190, 191], [192, 205], [206, 216], [217, 222], [223, 241], [242, 245], [246, 251], [252, 254], [255, 259], [260, 265], [265, 266], [267, 272], [273, 277], [278, 280], [281, 287], [288, 294], [295, 303], [303, 304]]}
{"doc_key": "ai-dev-215", "ner": [[16, 16, "algorithm"], [18, 18, "algorithm"], [21, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 16, 21, 21, "compare", "", false, false], [18, 18, 21, 21, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Jednak", "w", "przeciwie\u0144stwie", "do", "algorytm\u00f3w", "boostingu", ",", "kt\u00f3re", "analitycznie", "minimalizuj\u0105", "wypuk\u0142\u0105", "funkcj\u0119", "straty", "(", "np", ".", "AdaBoost", "i", "LogitBoost", ")", ",", "BrownBoost", "rozwi\u0105zuje", "uk\u0142ad", "dw\u00f3ch", "r\u00f3wna\u0144", "i", "dw\u00f3ch", "niewiadomych", "przy", "u\u017cyciu", "standardowych", "metod", "numerycznych", "."], "sentence-detokenized": "Jednak w przeciwie\u0144stwie do algorytm\u00f3w boostingu, kt\u00f3re analitycznie minimalizuj\u0105 wypuk\u0142\u0105 funkcj\u0119 straty (np. AdaBoost i LogitBoost), BrownBoost rozwi\u0105zuje uk\u0142ad dw\u00f3ch r\u00f3wna\u0144 i dw\u00f3ch niewiadomych przy u\u017cyciu standardowych metod numerycznych.", "token2charspan": [[0, 6], [7, 8], [9, 24], [25, 27], [28, 38], [39, 48], [48, 49], [50, 55], [56, 68], [69, 81], [82, 89], [90, 97], [98, 104], [105, 106], [106, 108], [108, 109], [110, 118], [119, 120], [121, 131], [131, 132], [132, 133], [134, 144], [145, 155], [156, 161], [162, 167], [168, 174], [175, 176], [177, 182], [183, 195], [196, 200], [201, 207], [208, 221], [222, 227], [228, 240], [240, 241]]}
{"doc_key": "ai-dev-216", "ner": [[0, 0, "researcher"], [10, 12, "misc"], [16, 21, "conference"], [23, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 10, 12, "win-defeat", "", false, false], [0, 0, 16, 21, "role", "", false, false], [23, 23, 16, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Getoor", "ma", "na", "koncie", "wiele", "nagr\u00f3d", "za", "najlepsze", "prace", ",", "NSF", "Career", "Award", "i", "jest", "cz\u0142onkiem", "Association", "for", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "Fellow", "."], "sentence-detokenized": "Getoor ma na koncie wiele nagr\u00f3d za najlepsze prace, NSF Career Award i jest cz\u0142onkiem Association for Advancement of Artificial Intelligence (AAAI) Fellow.", "token2charspan": [[0, 6], [7, 9], [10, 12], [13, 19], [20, 25], [26, 32], [33, 35], [36, 45], [46, 51], [51, 52], [53, 56], [57, 63], [64, 69], [70, 71], [72, 76], [77, 86], [87, 98], [99, 102], [103, 114], [115, 117], [118, 128], [129, 141], [142, 143], [143, 147], [147, 148], [149, 155], [155, 156]]}
{"doc_key": "ai-dev-217", "ner": [[0, 1, "misc"], [6, 10, "misc"], [15, 16, "misc"], [21, 25, "misc"], [30, 31, "misc"], [35, 39, "university"], [44, 52, "misc"], [57, 66, "misc"], [71, 75, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["ACM", "Fellow", "(", "2015", ")", "br", "Association", "for", "Computational", "Linguistics", "Fellow", "(", "2011", ")", "br", "AAAI", "Fellow", "(", "1994", ")", "br", "International", "Speech", "Communication", "Association", "Fellow", "(", "2011", ")", "br", "Honorary", "Doctorate", "(", "Hedersdoktor", ")", "KTH", "Royal", "Institute", "of", "Technology", "(", "2007", ")", "br", "Columbia", "Engineering", "School", "Alumni", "Association", "Distinguished", "Faculty", "Teaching", "award", "(", "2009", ")", "br", "IEEE", "James", "L", ".", "Flanagan", "Speech", "and", "Audio", "Processing", "Award", "(", "2011", ")", "br", "ISCA", "Medal", "for", "Scientific", "Achievement", "(", "2011", ")"], "sentence-detokenized": "ACM Fellow (2015) br Association for Computational Linguistics Fellow (2011) br AAAI Fellow (1994) br International Speech Communication Association Fellow (2011) br Honorary Doctorate (Hedersdoktor) KTH Royal Institute of Technology (2007) br Columbia Engineering School Alumni Association Distinguished Faculty Teaching award (2009) br IEEE James L. Flanagan Speech and Audio Processing Award (2011) br ISCA Medal for Scientific Achievement (2011)", "token2charspan": [[0, 3], [4, 10], [11, 12], [12, 16], [16, 17], [18, 20], [21, 32], [33, 36], [37, 50], [51, 62], [63, 69], [70, 71], [71, 75], [75, 76], [77, 79], [80, 84], [85, 91], [92, 93], [93, 97], [97, 98], [99, 101], [102, 115], [116, 122], [123, 136], [137, 148], [149, 155], [156, 157], [157, 161], [161, 162], [163, 165], [166, 174], [175, 184], [185, 186], [186, 198], [198, 199], [200, 203], [204, 209], [210, 219], [220, 222], [223, 233], [234, 235], [235, 239], [239, 240], [241, 243], [244, 252], [253, 264], [265, 271], [272, 278], [279, 290], [291, 304], [305, 312], [313, 321], [322, 327], [328, 329], [329, 333], [333, 334], [335, 337], [338, 342], [343, 348], [349, 350], [350, 351], [352, 360], [361, 367], [368, 371], [372, 377], [378, 388], [389, 394], [395, 396], [396, 400], [400, 401], [402, 404], [405, 409], [410, 415], [416, 419], [420, 430], [431, 442], [443, 444], [444, 448], [448, 449]]}
{"doc_key": "ai-dev-218", "ner": [[7, 7, "university"], [13, 15, "task"], [25, 29, "metrics"], [35, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[25, 29, 35, 37, "opposite", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Frustruj\u0105cym", "wynikiem", "tego", "samego", "badania", "przeprowadzonego", "przez", "Stanford", "(", "i", "innych", "pr\u00f3b", "poprawy", "t\u0142umaczenia", "rozpoznawania", "nazw", ")", "jest", "to", ",", "\u017ce", "wiele", "razy", "spadek", "wynik\u00f3w", "oceny", "dwuj\u0119zycznej", "pod", "wzgl\u0119dem", "t\u0142umaczenia", "b\u0119dzie", "wynika\u0142", "z", "w\u0142\u0105czenia", "metod", "t\u0142umaczenia", "nazwanych", "encji", "."], "sentence-detokenized": "Frustruj\u0105cym wynikiem tego samego badania przeprowadzonego przez Stanford (i innych pr\u00f3b poprawy t\u0142umaczenia rozpoznawania nazw) jest to, \u017ce wiele razy spadek wynik\u00f3w oceny dwuj\u0119zycznej pod wzgl\u0119dem t\u0142umaczenia b\u0119dzie wynika\u0142 z w\u0142\u0105czenia metod t\u0142umaczenia nazwanych encji.", "token2charspan": [[0, 12], [13, 21], [22, 26], [27, 33], [34, 41], [42, 58], [59, 64], [65, 73], [74, 75], [75, 76], [77, 83], [84, 88], [89, 96], [97, 108], [109, 122], [123, 127], [127, 128], [129, 133], [134, 136], [136, 137], [138, 140], [141, 146], [147, 151], [152, 158], [159, 166], [167, 172], [173, 185], [186, 189], [190, 198], [199, 210], [211, 217], [218, 225], [226, 227], [228, 237], [238, 243], [244, 255], [256, 265], [266, 271], [271, 272]]}
{"doc_key": "ai-dev-219", "ner": [[0, 0, "organisation"], [10, 12, "organisation"], [14, 18, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 10, 12, "role", "works_with", false, false], [0, 0, 14, 18, "role", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Medtronic", "wykorzystuje", "zebrane", "dane", "PM", "i", "wsp\u00f3\u0142pracuje", "z", "naukowcami", "z", "Johns", "Hopkins", "Hospital", "i", "Washington", "University", "School", "of", "Medicine", ",", "aby", "pom\u00f3c", "odpowiedzie\u0107", "na", "konkretne", "pytania", "dotycz\u0105ce", "chor\u00f3b", "serca", ",", "takie", "jak", "to", ",", "czy", "s\u0142abe", "serca", "powoduj\u0105", "arytmi\u0119", ",", "czy", "odwrotnie", "."], "sentence-detokenized": "Medtronic wykorzystuje zebrane dane PM i wsp\u00f3\u0142pracuje z naukowcami z Johns Hopkins Hospital i Washington University School of Medicine, aby pom\u00f3c odpowiedzie\u0107 na konkretne pytania dotycz\u0105ce chor\u00f3b serca, takie jak to, czy s\u0142abe serca powoduj\u0105 arytmi\u0119, czy odwrotnie.", "token2charspan": [[0, 9], [10, 22], [23, 30], [31, 35], [36, 38], [39, 40], [41, 53], [54, 55], [56, 66], [67, 68], [69, 74], [75, 82], [83, 91], [92, 93], [94, 104], [105, 115], [116, 122], [123, 125], [126, 134], [134, 135], [136, 139], [140, 145], [146, 158], [159, 161], [162, 171], [172, 179], [180, 189], [190, 196], [197, 202], [202, 203], [204, 209], [210, 213], [214, 216], [216, 217], [218, 221], [222, 227], [228, 233], [234, 242], [243, 250], [250, 251], [252, 255], [256, 265], [265, 266]]}
{"doc_key": "ai-dev-220", "ner": [[5, 5, "organisation"], [7, 7, "misc"], [9, 10, "person"], [12, 13, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 5, 5, "artifact", "made_by_studio", false, false], [9, 10, 7, 7, "role", "", false, false], [12, 13, 7, 7, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Po", "nim", "powsta\u0142", "pierwszy", "film", "Paramountu", ",", "Sangaree", "z", "Fernando", "Lamasem", "i", "Arlene", "Dahl", "."], "sentence-detokenized": "Po nim powsta\u0142 pierwszy film Paramountu, Sangaree z Fernando Lamasem i Arlene Dahl.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 23], [24, 28], [29, 39], [39, 40], [41, 49], [50, 51], [52, 60], [61, 68], [69, 70], [71, 77], [78, 82], [82, 83]]}
{"doc_key": "ai-dev-221", "ner": [[0, 0, "programlang"], [8, 11, "researcher"], [13, 14, "researcher"], [19, 20, "organisation"], [23, 24, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 11, "origin", "", false, false], [0, 0, 13, 14, "origin", "", false, false], [8, 11, 19, 20, "physical", "", false, false], [8, 11, 19, 20, "role", "", false, false], [13, 14, 23, 24, "physical", "", false, false], [13, 14, 23, 24, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["KRL", "jest", "j\u0119zykiem", "reprezentacji", "wiedzy", ",", "opracowanym", "przez", "Daniela", "G", ".", "Bobrowa", "i", "Terry'ego", "Winograda", "podczas", "pracy", "odpowiednio", "w", "Xerox", "PARC", "i", "na", "Uniwersytecie", "Stanforda", "."], "sentence-detokenized": "KRL jest j\u0119zykiem reprezentacji wiedzy, opracowanym przez Daniela G. Bobrowa i Terry'ego Winograda podczas pracy odpowiednio w Xerox PARC i na Uniwersytecie Stanforda.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 31], [32, 38], [38, 39], [40, 51], [52, 57], [58, 65], [66, 67], [67, 68], [69, 76], [77, 78], [79, 88], [89, 98], [99, 106], [107, 112], [113, 124], [125, 126], [127, 132], [133, 137], [138, 139], [140, 142], [143, 156], [157, 166], [166, 167]]}
{"doc_key": "ai-dev-222", "ner": [[1, 10, "conference"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 23, "researcher"], [30, 32, "task"], [34, 36, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 10, 30, 32, "topic", "", true, false], [13, 14, 1, 10, "physical", "", false, false], [13, 14, 1, 10, "role", "", false, false], [13, 14, 1, 10, "temporal", "", false, false], [16, 17, 1, 10, "physical", "", false, false], [16, 17, 1, 10, "role", "", false, false], [16, 17, 1, 10, "temporal", "", false, false], [19, 20, 1, 10, "physical", "", false, false], [19, 20, 1, 10, "role", "", false, false], [19, 20, 1, 10, "temporal", "", false, false], [22, 23, 1, 10, "physical", "", false, false], [22, 23, 1, 10, "role", "", false, false], [22, 23, 1, 10, "temporal", "", false, false], [30, 32, 34, 36, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Na", "konferencji", "IEEE", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "w", "2006", "roku", "Qiang", "Zhu", ",", "Shai", "Avidan", ",", "Mei-Chen", "Yeh", "i", "Kwang-Ting", "Cheng", "przedstawili", "algorytm", "pozwalaj\u0105cy", "na", "znaczne", "przyspieszenie", "detekcji", "cz\u0142owieka", "przy", "u\u017cyciu", "metod", "deskryptor\u00f3w", "HOG", "."], "sentence-detokenized": "Na konferencji IEEE Conference on Computer Vision and Pattern Recognition w 2006 roku Qiang Zhu, Shai Avidan, Mei-Chen Yeh i Kwang-Ting Cheng przedstawili algorytm pozwalaj\u0105cy na znaczne przyspieszenie detekcji cz\u0142owieka przy u\u017cyciu metod deskryptor\u00f3w HOG.", "token2charspan": [[0, 2], [3, 14], [15, 19], [20, 30], [31, 33], [34, 42], [43, 49], [50, 53], [54, 61], [62, 73], [74, 75], [76, 80], [81, 85], [86, 91], [92, 95], [95, 96], [97, 101], [102, 108], [108, 109], [110, 118], [119, 122], [123, 124], [125, 135], [136, 141], [142, 154], [155, 163], [164, 175], [176, 178], [179, 186], [187, 201], [202, 210], [211, 220], [221, 225], [226, 232], [233, 238], [239, 251], [252, 255], [255, 256]]}
{"doc_key": "ai-dev-223", "ner": [[0, 0, "researcher"], [3, 3, "conference"], [5, 7, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 3, 3, "role", "", false, false], [0, 0, 5, 7, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hayes", "jest", "cz\u0142onkiem", "AAAI", "i", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Hayes jest cz\u0142onkiem AAAI i Cognitive Science Society.", "token2charspan": [[0, 5], [6, 10], [11, 20], [21, 25], [26, 27], [28, 37], [38, 45], [46, 53], [53, 54]]}
{"doc_key": "ai-dev-224", "ner": [[0, 1, "misc"], [5, 5, "field"], [7, 8, "field"], [10, 11, "field"], [13, 13, "field"], [15, 16, "field"], [18, 19, "field"], [21, 23, "field"], [25, 25, "field"], [28, 28, "field"], [30, 30, "field"], [33, 33, "field"], [41, 42, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[0, 1, 5, 5, "part-of", "", false, false], [0, 1, 5, 5, "usage", "", false, false], [0, 1, 7, 8, "part-of", "", false, false], [0, 1, 7, 8, "usage", "", false, false], [0, 1, 10, 11, "part-of", "", false, false], [0, 1, 10, 11, "usage", "", false, false], [0, 1, 13, 13, "part-of", "", false, false], [0, 1, 13, 13, "usage", "", false, false], [0, 1, 15, 16, "part-of", "", false, false], [0, 1, 15, 16, "usage", "", false, false], [0, 1, 18, 19, "part-of", "", false, false], [0, 1, 18, 19, "usage", "", false, false], [0, 1, 21, 23, "part-of", "", false, false], [0, 1, 21, 23, "usage", "", false, false], [0, 1, 25, 25, "part-of", "", false, false], [0, 1, 25, 25, "usage", "", false, false], [0, 1, 28, 28, "part-of", "", false, false], [0, 1, 28, 28, "usage", "", false, false], [0, 1, 30, 30, "part-of", "", false, false], [0, 1, 30, 30, "usage", "", false, false], [0, 1, 33, 33, "part-of", "", false, false], [0, 1, 33, 33, "usage", "", false, false], [0, 1, 41, 42, "part-of", "", false, false], [0, 1, 41, 42, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "sentence": ["Szeregi", "czasowe", "s\u0105", "wykorzystywane", "w", "statystyce", ",", "przetwarzaniu", "sygna\u0142\u00f3w", ",", "rozpoznawaniu", "wzorc\u00f3w", ",", "ekonometrii", ",", "finansach", "matematycznych", ",", "prognozowaniu", "pogody", ",", "przewidywaniu", "trz\u0119sie\u0144", "ziemi", ",", "elektroencefalografii", ",", "in\u017cynierii", "sterowania", ",", "astronomii", ",", "in\u017cynierii", "komunikacyjnej", "i", "w", "du\u017cej", "mierze", "w", "ka\u017cdej", "dziedzinie", "nauki", "stosowanej", "i", "in\u017cynierii", ",", "kt\u00f3ra", "obejmuje", "pomiary", "czasowe", "."], "sentence-detokenized": "Szeregi czasowe s\u0105 wykorzystywane w statystyce, przetwarzaniu sygna\u0142\u00f3w, rozpoznawaniu wzorc\u00f3w, ekonometrii, finansach matematycznych, prognozowaniu pogody, przewidywaniu trz\u0119sie\u0144 ziemi, elektroencefalografii, in\u017cynierii sterowania, astronomii, in\u017cynierii komunikacyjnej i w du\u017cej mierze w ka\u017cdej dziedzinie nauki stosowanej i in\u017cynierii, kt\u00f3ra obejmuje pomiary czasowe.", "token2charspan": [[0, 7], [8, 15], [16, 18], [19, 33], [34, 35], [36, 46], [46, 47], [48, 61], [62, 70], [70, 71], [72, 85], [86, 93], [93, 94], [95, 106], [106, 107], [108, 117], [118, 132], [132, 133], [134, 147], [148, 154], [154, 155], [156, 169], [170, 178], [179, 184], [184, 185], [186, 207], [207, 208], [209, 219], [220, 230], [230, 231], [232, 242], [242, 243], [244, 254], [255, 269], [270, 271], [272, 273], [274, 279], [280, 286], [287, 288], [289, 295], [296, 306], [307, 312], [313, 323], [324, 325], [326, 336], [336, 337], [338, 343], [344, 352], [353, 360], [361, 368], [368, 369]]}
{"doc_key": "ai-dev-225", "ner": [[13, 14, "metrics"], [36, 37, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Zasadniczo", ",", "dok\u0142adne", "odzyskanie", "mo\u017ce", "by\u0107", "rozwi\u0105zany", "w", "swoim", "zakresie", "wykonalnym", "przy", "u\u017cyciu", "maksymalnego", "prawdopodobie\u0144stwa", ",", "ale", "to", "sprowadza", "si\u0119", "do", "rozwi\u0105zywania", "ograniczone", "lub", "regularne", "problem", "ci\u0119cia", ",", "takie", "jak", "minimum", "bisection", ",", "\u017ce", "jest", "zwykle", "NP-", "complete", "."], "sentence-detokenized": "Zasadniczo, dok\u0142adne odzyskanie mo\u017ce by\u0107 rozwi\u0105zany w swoim zakresie wykonalnym przy u\u017cyciu maksymalnego prawdopodobie\u0144stwa, ale to sprowadza si\u0119 do rozwi\u0105zywania ograniczone lub regularne problem ci\u0119cia, takie jak minimum bisection, \u017ce jest zwykle NP-complete.", "token2charspan": [[0, 10], [10, 11], [12, 20], [21, 31], [32, 36], [37, 40], [41, 51], [52, 53], [54, 59], [60, 68], [69, 79], [80, 84], [85, 91], [92, 104], [105, 123], [123, 124], [125, 128], [129, 131], [132, 141], [142, 145], [146, 148], [149, 162], [163, 174], [175, 178], [179, 188], [189, 196], [197, 203], [203, 204], [205, 210], [211, 214], [215, 222], [223, 232], [232, 233], [234, 236], [237, 241], [242, 248], [249, 252], [252, 260], [260, 261]]}
{"doc_key": "ai-dev-226", "ner": [[4, 5, "task"], [14, 14, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 14, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["w", "swojej", "pracy", "do", "wykrywania", "pieszych", ",", "kt\u00f3ra", "zosta\u0142a", "po", "raz", "pierwszy", "opisana", "na", "BMVC", "w", "2009", "roku", "."], "sentence-detokenized": "w swojej pracy do wykrywania pieszych, kt\u00f3ra zosta\u0142a po raz pierwszy opisana na BMVC w 2009 roku.", "token2charspan": [[0, 1], [2, 8], [9, 14], [15, 17], [18, 28], [29, 37], [37, 38], [39, 44], [45, 52], [53, 55], [56, 59], [60, 68], [69, 76], [77, 79], [80, 84], [85, 86], [87, 91], [92, 96], [96, 97]]}
{"doc_key": "ai-dev-227", "ner": [[5, 8, "conference"], [10, 10, "researcher"], [12, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 5, 8, "physical", "", false, false], [10, 10, 5, 8, "role", "", false, false], [10, 10, 12, 20, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["W", "2007", "roku", ",", "na", "Mi\u0119dzynarodowej", "Konferencji", "Widzenia", "Komputerowego", ",", "Terzopoulos", "otrzyma\u0142", "inauguracyjn\u0105", "nagrod\u0119", "IEEE", "PAMI", "Computer", "Vision", "Distinguished", "Researcher", "Award", "za", "pionierskie", "i", "trwa\u0142e", "badania", "nad", "modelami", "deformowalnymi", "i", "ich", "zastosowaniami", "."], "sentence-detokenized": "W 2007 roku, na Mi\u0119dzynarodowej Konferencji Widzenia Komputerowego, Terzopoulos otrzyma\u0142 inauguracyjn\u0105 nagrod\u0119 IEEE PAMI Computer Vision Distinguished Researcher Award za pionierskie i trwa\u0142e badania nad modelami deformowalnymi i ich zastosowaniami.", "token2charspan": [[0, 1], [2, 6], [7, 11], [11, 12], [13, 15], [16, 31], [32, 43], [44, 52], [53, 66], [66, 67], [68, 79], [80, 88], [89, 102], [103, 110], [111, 115], [116, 120], [121, 129], [130, 136], [137, 150], [151, 161], [162, 167], [168, 170], [171, 182], [183, 184], [185, 191], [192, 199], [200, 203], [204, 212], [213, 227], [228, 229], [230, 233], [234, 248], [248, 249]]}
{"doc_key": "ai-dev-228", "ner": [[0, 1, "task"], [3, 4, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 3, 4, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["Analiza", "klastr\u00f3w", "lub", "analiza", "skupie\u0144", "polega", "na", "przypisaniu", "punkt\u00f3w", "danych", "do", "skupie\u0144", "w", "taki", "spos\u00f3b", ",", "aby", "elementy", "w", "tym", "samym", "skupieniu", "by\u0142y", "jak", "najbardziej", "podobne", ",", "natomiast", "elementy", "nale\u017c\u0105ce", "do", "r\u00f3\u017cnych", "skupie\u0144", "by\u0142y", "jak", "najbardziej", "niepodobne", "."], "sentence-detokenized": "Analiza klastr\u00f3w lub analiza skupie\u0144 polega na przypisaniu punkt\u00f3w danych do skupie\u0144 w taki spos\u00f3b, aby elementy w tym samym skupieniu by\u0142y jak najbardziej podobne, natomiast elementy nale\u017c\u0105ce do r\u00f3\u017cnych skupie\u0144 by\u0142y jak najbardziej niepodobne.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 28], [29, 36], [37, 43], [44, 46], [47, 58], [59, 66], [67, 73], [74, 76], [77, 84], [85, 86], [87, 91], [92, 98], [98, 99], [100, 103], [104, 112], [113, 114], [115, 118], [119, 124], [125, 134], [135, 139], [140, 143], [144, 155], [156, 163], [163, 164], [165, 174], [175, 183], [184, 192], [193, 195], [196, 203], [204, 211], [212, 216], [217, 220], [221, 232], [233, 243], [243, 244]]}
{"doc_key": "ai-dev-229", "ner": [[8, 9, "field"], [13, 14, "field"], [16, 17, "task"], [19, 22, "field"], [23, 23, "field"], [26, 27, "field"], [30, 31, "field"], [33, 34, "task"], [36, 36, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[8, 9, 13, 14, "named", "", false, false], [8, 9, 19, 22, "named", "", false, false], [8, 9, 26, 27, "named", "", false, false], [16, 17, 13, 14, "part-of", "task_part_of_field", false, false], [23, 23, 19, 22, "part-of", "", false, false], [30, 31, 26, 27, "part-of", "", false, false], [33, 34, 30, 31, "part-of", "", false, false], [36, 36, 30, 31, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["(", "2005", ")", "mo\u017cemy", "wyr\u00f3\u017cni\u0107", "trzy", "r\u00f3\u017cne", "perspektywy", "text", "mining", ",", "a", "mianowicie", "text", "mining", "jako", "ekstrakcj\u0119", "informacji", ",", "text", "mining", "jako", "eksploracj\u0119", "danych", "tekstowych", "oraz", "text", "mining", "jako", "proces", "Data", "mining", "(", "Knowledge", "Discovery", "in", "Databases", ")", ".", "Hotho", ",", "A", ".", ",", "N\u00fcrnberger", ",", "A", ".", "i", "Paa\u00df", ",", "G", ".", "(", "2005", ")", "."], "sentence-detokenized": "(2005) mo\u017cemy wyr\u00f3\u017cni\u0107 trzy r\u00f3\u017cne perspektywy text mining, a mianowicie text mining jako ekstrakcj\u0119 informacji, text mining jako eksploracj\u0119 danych tekstowych oraz text mining jako proces Data mining (Knowledge Discovery in Databases).Hotho, A., N\u00fcrnberger, A. i Paa\u00df, G. (2005).", "token2charspan": [[0, 1], [1, 5], [5, 6], [7, 13], [14, 22], [23, 27], [28, 33], [34, 45], [46, 50], [51, 57], [57, 58], [59, 60], [61, 71], [72, 76], [77, 83], [84, 88], [89, 99], [100, 110], [110, 111], [112, 116], [117, 123], [124, 128], [129, 140], [141, 147], [148, 158], [159, 163], [164, 168], [169, 175], [176, 180], [181, 187], [188, 192], [193, 199], [200, 201], [201, 210], [211, 220], [221, 223], [224, 233], [233, 234], [234, 235], [235, 240], [240, 241], [242, 243], [243, 244], [244, 245], [246, 256], [256, 257], [258, 259], [259, 260], [261, 262], [263, 267], [267, 268], [269, 270], [270, 271], [272, 273], [273, 277], [277, 278], [278, 279]]}
{"doc_key": "ai-dev-230", "ner": [[0, 1, "product"], [12, 17, "location"], [19, 19, "location"], [21, 21, "location"], [30, 32, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 12, 17, "related-to", "developed_for", false, false], [12, 17, 19, 19, "physical", "", false, false], [19, 19, 21, 21, "physical", "", false, false], [30, 32, 0, 1, "role", "buys", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Rami\u0119", "Rancho", "zosta\u0142o", "opracowane", "jako", "robotyczne", "rami\u0119", "do", "pomocy", "niepe\u0142nosprawnym", "pacjentom", "w", "Narodowym", "Centrum", "Rehabilitacji", "Rancho", "Los", "Amigos", "w", "Downey", "w", "Kalifornii", ";", "to", "sterowane", "komputerowo", "rami\u0119", "zosta\u0142o", "zakupione", "przez", "Uniwersytet", "Stanforda", "w", "1963", "roku", "."], "sentence-detokenized": "Rami\u0119 Rancho zosta\u0142o opracowane jako robotyczne rami\u0119 do pomocy niepe\u0142nosprawnym pacjentom w Narodowym Centrum Rehabilitacji Rancho Los Amigos w Downey w Kalifornii; to sterowane komputerowo rami\u0119 zosta\u0142o zakupione przez Uniwersytet Stanforda w 1963 roku.", "token2charspan": [[0, 5], [6, 12], [13, 20], [21, 31], [32, 36], [37, 47], [48, 53], [54, 56], [57, 63], [64, 80], [81, 90], [91, 92], [93, 102], [103, 110], [111, 124], [125, 131], [132, 135], [136, 142], [143, 144], [145, 151], [152, 153], [154, 164], [164, 165], [166, 168], [169, 178], [179, 190], [191, 196], [197, 204], [205, 214], [215, 220], [221, 232], [233, 242], [243, 244], [245, 249], [250, 254], [254, 255]]}
{"doc_key": "ai-dev-231", "ner": [[1, 1, "university"], [2, 2, "researcher"], [5, 8, "organisation"], [13, 15, "organisation"], [19, 20, "researcher"], [22, 25, "researcher"], [40, 40, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 2, 1, 1, "physical", "", false, false], [2, 2, 1, 1, "role", "", false, false], [2, 2, 5, 8, "role", "founder", false, false], [2, 2, 13, 15, "role", "founder", false, false], [13, 15, 40, 40, "physical", "", false, false], [19, 20, 13, 15, "role", "founder", false, false], [22, 25, 13, 15, "role", "founder", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Na", "UCSD", "Norman", "by\u0142", "za\u0142o\u017cycielem", "Institute", "for", "Cognitive", "Science", "i", "jednym", "z", "organizator\u00f3w", "Cognitive", "Science", "Society", "(", "wraz", "z", "Rogerem", "Schankiem", ",", "Allanem", "M", ".", "Collinsem", "i", "innymi", ")", ",", "kt\u00f3re", "w", "1979", "roku", "zorganizowa\u0142o", "swoje", "pierwsze", "spotkanie", "na", "kampusie", "UCSD", "."], "sentence-detokenized": "Na UCSD Norman by\u0142 za\u0142o\u017cycielem Institute for Cognitive Science i jednym z organizator\u00f3w Cognitive Science Society (wraz z Rogerem Schankiem, Allanem M. Collinsem i innymi), kt\u00f3re w 1979 roku zorganizowa\u0142o swoje pierwsze spotkanie na kampusie UCSD.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 18], [19, 31], [32, 41], [42, 45], [46, 55], [56, 63], [64, 65], [66, 72], [73, 74], [75, 88], [89, 98], [99, 106], [107, 114], [115, 116], [116, 120], [121, 122], [123, 130], [131, 140], [140, 141], [142, 149], [150, 151], [151, 152], [153, 162], [163, 164], [165, 171], [171, 172], [172, 173], [174, 179], [180, 181], [182, 186], [187, 191], [192, 205], [206, 211], [212, 220], [221, 230], [231, 233], [234, 242], [243, 247], [247, 248]]}
{"doc_key": "ai-dev-232", "ner": [[6, 6, "product"], [9, 9, "product"], [12, 12, "product"], [16, 17, "product"], [21, 21, "product"], [23, 25, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[21, 21, 16, 17, "type-of", "", false, false], [23, 25, 16, 17, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Najcz\u0119\u015bciej", "stosowane", "konfiguracje", "robot\u00f3w", "to", "roboty", "przegubowe", ",", "roboty", "SCARA", ",", "roboty", "delta", "oraz", "roboty", "o", "wsp\u00f3\u0142rz\u0119dnych", "kartezja\u0144skich", ",", "(", "roboty", "gantry", "lub", "roboty", "x-y-", "z", ")", "."], "sentence-detokenized": "Najcz\u0119\u015bciej stosowane konfiguracje robot\u00f3w to roboty przegubowe, roboty SCARA, roboty delta oraz roboty o wsp\u00f3\u0142rz\u0119dnych kartezja\u0144skich, (roboty gantry lub roboty x-y-z).", "token2charspan": [[0, 11], [12, 21], [22, 34], [35, 42], [43, 45], [46, 52], [53, 63], [63, 64], [65, 71], [72, 77], [77, 78], [79, 85], [86, 91], [92, 96], [97, 103], [104, 105], [106, 119], [120, 134], [134, 135], [136, 137], [137, 143], [144, 150], [151, 154], [155, 161], [162, 166], [166, 167], [167, 168], [168, 169]]}
{"doc_key": "ai-dev-233", "ner": [[6, 6, "programlang"], [7, 8, "misc"], [13, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 6, 6, "part-of", "", false, false], [13, 13, 7, 8, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Alternatywnie", "mo\u017cna", "go", "u\u017cywa\u0107", "bezpo\u015brednio", "z", "Perl", "Module", "TM", "(", "kt\u00f3ry", "r\u00f3wnie\u017c", "obs\u0142uguje", "LTM", ")", "."], "sentence-detokenized": "Alternatywnie mo\u017cna go u\u017cywa\u0107 bezpo\u015brednio z Perl Module TM (kt\u00f3ry r\u00f3wnie\u017c obs\u0142uguje LTM).", "token2charspan": [[0, 13], [14, 19], [20, 22], [23, 29], [30, 42], [43, 44], [45, 49], [50, 56], [57, 59], [60, 61], [61, 66], [67, 74], [75, 84], [85, 88], [88, 89], [89, 90]]}
{"doc_key": "ai-dev-234", "ner": [[4, 6, "country"], [7, 8, "organisation"], [15, 15, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 4, 6, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Wygra\u0142", "go", "zesp\u00f3\u0142", "ze", "Stan\u00f3w", "Zjednoczonych", "z", "Newton", "Labs", ",", "a", "zawody", "by\u0142y", "pokazywane", "w", "CNN", "."], "sentence-detokenized": "Wygra\u0142 go zesp\u00f3\u0142 ze Stan\u00f3w Zjednoczonych z Newton Labs, a zawody by\u0142y pokazywane w CNN.", "token2charspan": [[0, 6], [7, 9], [10, 16], [17, 19], [20, 26], [27, 40], [41, 42], [43, 49], [50, 54], [54, 55], [56, 57], [58, 64], [65, 69], [70, 80], [81, 82], [83, 86], [86, 87]]}
{"doc_key": "ai-dev-235", "ner": [[0, 1, "misc"], [7, 8, "person"], [12, 13, "person"], [15, 16, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 0, 1, "role", "directs", false, false], [12, 13, 0, 1, "role", "acts_in", false, false], [15, 16, 0, 1, "role", "acts_in", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Zakochany", "Butler", "-", "film", "kr\u00f3tkometra\u017cowy", "w", "re\u017cyserii", "Davida", "Arquette'a", ",", "z", "udzia\u0142em", "Elizabeth", "Berkley", "i", "Thomasa", "Jane'a", ",", "ukaza\u0142", "si\u0119", "23", "czerwca", "2008", "roku", "."], "sentence-detokenized": "Zakochany Butler - film kr\u00f3tkometra\u017cowy w re\u017cyserii Davida Arquette'a, z udzia\u0142em Elizabeth Berkley i Thomasa Jane'a, ukaza\u0142 si\u0119 23 czerwca 2008 roku.", "token2charspan": [[0, 9], [10, 16], [17, 18], [19, 23], [24, 39], [40, 41], [42, 51], [52, 58], [59, 69], [69, 70], [71, 72], [73, 81], [82, 91], [92, 99], [100, 101], [102, 109], [110, 116], [116, 117], [118, 124], [125, 128], [129, 131], [132, 139], [140, 144], [145, 149], [149, 150]]}
{"doc_key": "ai-dev-236", "ner": [[2, 2, "product"], [6, 6, "field"], [12, 12, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 12, 12, "general-affiliation", "", false, false], [6, 6, 2, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Na", "przyk\u0142ad", "WordNet", "jest", "zasobem", "zawieraj\u0105cym", "taksonomi\u0119", ",", "kt\u00f3rej", "elementami", "s\u0105", "znaczenia", "angielskich", "s\u0142\u00f3w", "."], "sentence-detokenized": "Na przyk\u0142ad WordNet jest zasobem zawieraj\u0105cym taksonomi\u0119, kt\u00f3rej elementami s\u0105 znaczenia angielskich s\u0142\u00f3w.", "token2charspan": [[0, 2], [3, 11], [12, 19], [20, 24], [25, 32], [33, 45], [46, 56], [56, 57], [58, 64], [65, 75], [76, 78], [79, 88], [89, 100], [101, 105], [105, 106]]}
{"doc_key": "ai-dev-237", "ner": [[1, 3, "product"], [7, 7, "product"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 1, 3, "type-of", "", false, false], [9, 9, 1, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 2], "sentence": ["Istniej\u0105ce", "systemy", "robot\u00f3w", "humanoidalnych", ",", "takie", "jak", "ASIMO", "i", "QRIO", ",", "wykorzystuj\u0105", "wiele", "silnik\u00f3w", "do", "osi\u0105gni\u0119cia", "lokomocji", "."], "sentence-detokenized": "Istniej\u0105ce systemy robot\u00f3w humanoidalnych, takie jak ASIMO i QRIO, wykorzystuj\u0105 wiele silnik\u00f3w do osi\u0105gni\u0119cia lokomocji.", "token2charspan": [[0, 10], [11, 18], [19, 26], [27, 41], [41, 42], [43, 48], [49, 52], [53, 58], [59, 60], [61, 65], [65, 66], [67, 79], [80, 85], [86, 94], [95, 97], [98, 109], [110, 119], [119, 120]]}
{"doc_key": "ai-dev-238", "ner": [[0, 0, "metrics"], [10, 12, "metrics"], [14, 14, "metrics"], [16, 21, "misc"], [23, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 12, 0, 0, "part-of", "", false, false], [14, 14, 0, 0, "part-of", "", false, false], [16, 21, 0, 0, "part-of", "", false, false], [23, 23, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LEPOR", "zosta\u0142", "zaprojektowany", "z", "uwzgl\u0119dnieniem", "czynnik\u00f3w", "takich", "jak", ":", "wzmocniona", "kara", "za", "d\u0142ugo\u015b\u0107", ",", "precyzja", ",", "kara", "za", "porz\u0105dek", "s\u0142\u00f3w", "w", "n-gramie", "oraz", "wycofanie", "."], "sentence-detokenized": "LEPOR zosta\u0142 zaprojektowany z uwzgl\u0119dnieniem czynnik\u00f3w takich jak: wzmocniona kara za d\u0142ugo\u015b\u0107, precyzja, kara za porz\u0105dek s\u0142\u00f3w w n-gramie oraz wycofanie.", "token2charspan": [[0, 5], [6, 12], [13, 27], [28, 29], [30, 44], [45, 54], [55, 61], [62, 65], [65, 66], [67, 77], [78, 82], [83, 85], [86, 93], [93, 94], [95, 103], [103, 104], [105, 109], [110, 112], [113, 121], [122, 126], [127, 128], [129, 137], [138, 142], [143, 152], [152, 153]]}
{"doc_key": "ai-dev-239", "ner": [[4, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Jest", "on", "oparty", "na", "metryce", "Bilingual", "evaluation", "understudy", ",", "ale", "z", "pewnymi", "zmianami", "."], "sentence-detokenized": "Jest on oparty na metryce Bilingual evaluation understudy, ale z pewnymi zmianami.", "token2charspan": [[0, 4], [5, 7], [8, 14], [15, 17], [18, 25], [26, 35], [36, 46], [47, 57], [57, 58], [59, 62], [63, 64], [65, 72], [73, 81], [81, 82]]}
{"doc_key": "ai-dev-240", "ner": [[5, 5, "product"], [7, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Jest", "to", "przyk\u0142adowa", "implementacja", "w", "MATLAB", "/", "Octave", ":"], "sentence-detokenized": "Jest to przyk\u0142adowa implementacja w MATLAB / Octave:", "token2charspan": [[0, 4], [5, 7], [8, 19], [20, 33], [34, 35], [36, 42], [43, 44], [45, 51], [51, 52]]}
{"doc_key": "ai-dev-241", "ner": [[15, 15, "programlang"], [17, 17, "programlang"], [19, 19, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Zosta\u0142", "zaprojektowany", "tak", ",", "aby", "m\u00f3g\u0142", "by\u0107", "u\u017cywany", "przez", "wiele", "j\u0119zyk\u00f3w", "komputerowych", ",", "w", "tym", "Python", ",", "Ruby", "i", "Scheme", "."], "sentence-detokenized": "Zosta\u0142 zaprojektowany tak, aby m\u00f3g\u0142 by\u0107 u\u017cywany przez wiele j\u0119zyk\u00f3w komputerowych, w tym Python, Ruby i Scheme.", "token2charspan": [[0, 6], [7, 21], [22, 25], [25, 26], [27, 30], [31, 35], [36, 39], [40, 47], [48, 53], [54, 59], [60, 67], [68, 81], [81, 82], [83, 84], [85, 88], [89, 95], [95, 96], [97, 101], [102, 103], [104, 110], [110, 111]]}
{"doc_key": "ai-dev-242", "ner": [[0, 0, "researcher"], [4, 4, "organisation"], [9, 9, "conference"], [13, 14, "academicjournal"], [17, 19, "organisation"], [22, 26, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 4, 4, "role", "", false, false], [0, 0, 9, 9, "role", "", false, false], [0, 0, 13, 14, "role", "", false, false], [0, 0, 17, 19, "role", "", false, false], [0, 0, 22, 26, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hayes", "pe\u0142ni\u0142", "funkcj\u0119", "sekretarza", "AISB", ",", "przewodnicz\u0105cego", "i", "powiernika", "IJCAI", ",", "redaktora", "stowarzyszonego", "Artificial", "Intelligence", ",", "gubernatora", "Cognitive", "Science", "Society", "oraz", "prezesa", "American", "Association", "for", "Artificial", "Intelligence", "."], "sentence-detokenized": "Hayes pe\u0142ni\u0142 funkcj\u0119 sekretarza AISB, przewodnicz\u0105cego i powiernika IJCAI, redaktora stowarzyszonego Artificial Intelligence, gubernatora Cognitive Science Society oraz prezesa American Association for Artificial Intelligence.", "token2charspan": [[0, 5], [6, 12], [13, 20], [21, 31], [32, 36], [36, 37], [38, 54], [55, 56], [57, 67], [68, 73], [73, 74], [75, 84], [85, 100], [101, 111], [112, 124], [124, 125], [126, 137], [138, 147], [148, 155], [156, 163], [164, 168], [169, 176], [177, 185], [186, 197], [198, 201], [202, 212], [213, 225], [225, 226]]}
{"doc_key": "ai-dev-243", "ner": [[4, 18, "misc"], [16, 16, "misc"], [23, 24, "person"], [29, 33, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 24, 4, 18, "role", "directed_by", false, false], [23, 24, 16, 16, "role", "directed_by", false, false], [23, 24, 29, 33, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dwa", "z", "nich", ",", "Now", "is", "the", "Time", "(", "to", "Put", "On", "Your", "Glasses", ")", "i", "Around", "is", "Around", ",", "zosta\u0142y", "wyre\u017cyserowane", "przez", "Normana", "McLarena", "w", "1951", "roku", "dla", "National", "Film", "Board", "of", "Canada", "."], "sentence-detokenized": "Dwa z nich, Now is the Time (to Put On Your Glasses) i Around is Around, zosta\u0142y wyre\u017cyserowane przez Normana McLarena w 1951 roku dla National Film Board of Canada.", "token2charspan": [[0, 3], [4, 5], [6, 10], [10, 11], [12, 15], [16, 18], [19, 22], [23, 27], [28, 29], [29, 31], [32, 35], [36, 38], [39, 43], [44, 51], [51, 52], [53, 54], [55, 61], [62, 64], [65, 71], [71, 72], [73, 80], [81, 95], [96, 101], [102, 109], [110, 118], [119, 120], [121, 125], [126, 130], [131, 134], [135, 143], [144, 148], [149, 154], [155, 157], [158, 164], [164, 165]]}
{"doc_key": "ai-dev-244", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["System", "rekomenduj\u0105cy", "ma", "na", "celu", "przewidywanie", "preferencji", "dla", "danego", "przedmiotu", "u\u017cytkownika", "docelowego", "."], "sentence-detokenized": "System rekomenduj\u0105cy ma na celu przewidywanie preferencji dla danego przedmiotu u\u017cytkownika docelowego.", "token2charspan": [[0, 6], [7, 20], [21, 23], [24, 26], [27, 31], [32, 45], [46, 57], [58, 61], [62, 68], [69, 79], [80, 91], [92, 102], [102, 103]]}
{"doc_key": "ai-dev-245", "ner": [[0, 0, "algorithm"], [4, 4, "field"], [6, 6, "field"], [8, 9, "field"], [12, 15, "field"], [16, 16, "field"], [18, 18, "field"], [20, 20, "field"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 4, "part-of", "", true, false], [0, 0, 6, 6, "part-of", "", true, false], [0, 0, 8, 9, "part-of", "", true, false], [0, 0, 12, 15, "part-of", "", true, false], [0, 0, 16, 16, "part-of", "", true, false], [0, 0, 18, 18, "part-of", "", true, false], [0, 0, 20, 20, "part-of", "", true, false], [0, 0, 22, 23, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Konwolucja", "ma", "zastosowania", "obejmuj\u0105ce", "prawdopodobie\u0144stwo", ",", "statystyk\u0119", ",", "widzenie", "komputerowe", ",", "przetwarzanie", "j\u0119zyka", "naturalnego", ",", "przetwarzanie", "obraz\u00f3w", "i", "sygna\u0142\u00f3w", ",", "in\u017cynieri\u0119", "i", "r\u00f3wnania", "r\u00f3\u017cniczkowe", "."], "sentence-detokenized": "Konwolucja ma zastosowania obejmuj\u0105ce prawdopodobie\u0144stwo, statystyk\u0119, widzenie komputerowe, przetwarzanie j\u0119zyka naturalnego, przetwarzanie obraz\u00f3w i sygna\u0142\u00f3w, in\u017cynieri\u0119 i r\u00f3wnania r\u00f3\u017cniczkowe.", "token2charspan": [[0, 10], [11, 13], [14, 26], [27, 37], [38, 56], [56, 57], [58, 68], [68, 69], [70, 78], [79, 90], [90, 91], [92, 105], [106, 112], [113, 124], [124, 125], [126, 139], [140, 147], [148, 149], [150, 158], [158, 159], [160, 170], [171, 172], [173, 181], [182, 193], [193, 194]]}
{"doc_key": "ai-dev-246", "ner": [[1, 1, "field"], [3, 5, "task"], [7, 8, "task"], [10, 10, "task"], [12, 12, "task"], [11, 11, "task"], [14, 15, "task"], [17, 18, "task"], [20, 21, "task"], [26, 27, "task"], [29, 29, "field"], [31, 31, "field"], [33, 35, "field"], [37, 37, "field"], [39, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15], "relations": [[1, 1, 3, 5, "part-of", "", true, false], [1, 1, 7, 8, "part-of", "", true, false], [1, 1, 10, 10, "part-of", "", true, false], [1, 1, 12, 12, "part-of", "", true, false], [1, 1, 11, 11, "part-of", "", true, false], [1, 1, 14, 15, "part-of", "", true, false], [1, 1, 17, 18, "part-of", "", true, false], [1, 1, 20, 21, "part-of", "", true, false], [1, 1, 26, 27, "part-of", "", true, false], [1, 1, 29, 29, "part-of", "", true, false], [1, 1, 31, 31, "part-of", "", true, false], [1, 1, 33, 35, "part-of", "", true, false], [1, 1, 37, 37, "part-of", "", true, false], [1, 1, 39, 39, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14], "sentence": ["Zastosowania", "DSP", "obejmuj\u0105", "przetwarzanie", "sygna\u0142\u00f3w", "audio", ",", "kompresj\u0119", "audio", ",", "cyfrowe", "przetwarzanie", "obraz\u00f3w", ",", "kompresj\u0119", "wideo", ",", "przetwarzanie", "mowy", ",", "rozpoznawanie", "mowy", ",", "komunikacj\u0119", "cyfrow\u0105", ",", "syntezatory", "cyfrowe", ",", "radar", ",", "sonar", ",", "przetwarzanie", "sygna\u0142\u00f3w", "finansowych", ",", "sejsmologi\u0119", "i", "biomedycyn\u0119", "."], "sentence-detokenized": "Zastosowania DSP obejmuj\u0105 przetwarzanie sygna\u0142\u00f3w audio, kompresj\u0119 audio, cyfrowe przetwarzanie obraz\u00f3w, kompresj\u0119 wideo, przetwarzanie mowy, rozpoznawanie mowy, komunikacj\u0119 cyfrow\u0105, syntezatory cyfrowe, radar, sonar, przetwarzanie sygna\u0142\u00f3w finansowych, sejsmologi\u0119 i biomedycyn\u0119.", "token2charspan": [[0, 12], [13, 16], [17, 25], [26, 39], [40, 48], [49, 54], [54, 55], [56, 65], [66, 71], [71, 72], [73, 80], [81, 94], [95, 102], [102, 103], [104, 113], [114, 119], [119, 120], [121, 134], [135, 139], [139, 140], [141, 154], [155, 159], [159, 160], [161, 172], [173, 180], [180, 181], [182, 193], [194, 201], [201, 202], [203, 208], [208, 209], [210, 215], [215, 216], [217, 230], [231, 239], [240, 251], [251, 252], [253, 264], [265, 266], [267, 278], [278, 279]]}
{"doc_key": "ai-dev-247", "ner": [[10, 11, "misc"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["(", "20", "lutego", "1912", "-", "11", "sierpnia", "2011", ")", "by\u0142", "ameryka\u0144skim", "wynalazc\u0105", ",", "najbardziej", "znanym", "ze", "stworzenia", "Unimate", ",", "pierwszego", "robota", "przemys\u0142owego", "."], "sentence-detokenized": "(20 lutego 1912 - 11 sierpnia 2011) by\u0142 ameryka\u0144skim wynalazc\u0105, najbardziej znanym ze stworzenia Unimate, pierwszego robota przemys\u0142owego.", "token2charspan": [[0, 1], [1, 3], [4, 10], [11, 15], [16, 17], [18, 20], [21, 29], [30, 34], [34, 35], [36, 39], [40, 52], [53, 62], [62, 63], [64, 75], [76, 82], [83, 85], [86, 96], [97, 104], [104, 105], [106, 116], [117, 123], [124, 137], [137, 138]]}
{"doc_key": "ai-dev-248", "ner": [[1, 4, "researcher"], [6, 9, "researcher"], [11, 11, "researcher"], [23, 26, "algorithm"], [29, 31, "algorithm"], [37, 38, "task"], [39, 39, "algorithm"], [45, 45, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[1, 4, 23, 26, "related-to", "writes_about", true, false], [6, 9, 23, 26, "related-to", "writes_about", true, false], [11, 11, 23, 26, "related-to", "writes_about", true, false], [23, 26, 29, 31, "related-to", "", true, false], [37, 38, 39, 39, "related-to", "", true, false], [45, 45, 39, 39, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Z", "Davidem", "E", ".", "Rumelhartem", "i", "Ronaldem", "J", ".", "Williamsem", ",", "Hinton", "by\u0142", "wsp\u00f3\u0142autorem", "wysoko", "cytowanej", "pracy", "opublikowanej", "w", "1986", "roku", ",", "kt\u00f3ra", "spopularyzowa\u0142a", "algorytm", "wstecznej", "propagacji", "do", "szkolenia", "wielowarstwowych", "sieci", "neuronowych", ",", "Dramatyczny", "kamie\u0144", "milowy", "w", "rozpoznawaniu", "obraz\u00f3w", "AlexNet", "zaprojektowany", "przez", "jego", "studenta", "Alexa", "Krizhevsky'ego", "{", "{", "cite", "web"], "sentence-detokenized": "Z Davidem E. Rumelhartem i Ronaldem J. Williamsem, Hinton by\u0142 wsp\u00f3\u0142autorem wysoko cytowanej pracy opublikowanej w 1986 roku, kt\u00f3ra spopularyzowa\u0142a algorytm wstecznej propagacji do szkolenia wielowarstwowych sieci neuronowych, Dramatyczny kamie\u0144 milowy w rozpoznawaniu obraz\u00f3w AlexNet zaprojektowany przez jego studenta Alexa Krizhevsky'ego {{cite web", "token2charspan": [[0, 1], [2, 9], [10, 11], [11, 12], [13, 24], [25, 26], [27, 35], [36, 37], [37, 38], [39, 49], [49, 50], [51, 57], [58, 61], [62, 74], [75, 81], [82, 91], [92, 97], [98, 111], [112, 113], [114, 118], [119, 123], [123, 124], [125, 130], [131, 146], [147, 155], [156, 165], [166, 176], [177, 179], [180, 189], [190, 206], [207, 212], [213, 224], [224, 225], [226, 237], [238, 244], [245, 251], [252, 253], [254, 267], [268, 275], [276, 283], [284, 298], [299, 304], [305, 309], [310, 318], [319, 324], [325, 339], [340, 341], [341, 342], [342, 346], [347, 350]]}
{"doc_key": "ai-dev-249", "ner": [[12, 13, "metrics"], [15, 17, "metrics"], [19, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Gdy", "przewidywana", "warto\u015b\u0107", "ma", "rozk\u0142ad", "ci\u0105g\u0142y", ",", "do", "podsumowania", "b\u0142\u0119d\u00f3w", "mo\u017cna", "u\u017cy\u0107", "b\u0142\u0119du", "\u015bredniokwadratowego", ",", "b\u0142\u0119du", "\u015bredniokwadratowego", "pierwiastkowego", "lub", "mediany", "odchylenia", "bezwzgl\u0119dnego", "."], "sentence-detokenized": "Gdy przewidywana warto\u015b\u0107 ma rozk\u0142ad ci\u0105g\u0142y, do podsumowania b\u0142\u0119d\u00f3w mo\u017cna u\u017cy\u0107 b\u0142\u0119du \u015bredniokwadratowego, b\u0142\u0119du \u015bredniokwadratowego pierwiastkowego lub mediany odchylenia bezwzgl\u0119dnego.", "token2charspan": [[0, 3], [4, 16], [17, 24], [25, 27], [28, 35], [36, 42], [42, 43], [44, 46], [47, 59], [60, 66], [67, 72], [73, 77], [78, 83], [84, 103], [103, 104], [105, 110], [111, 130], [131, 146], [147, 150], [151, 158], [159, 169], [170, 183], [183, 184]]}
{"doc_key": "ai-dev-250", "ner": [[0, 1, "algorithm"], [12, 12, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 12, 12, "part-of", "", true, false], [0, 1, 13, 14, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Klasteryzacja", "poj\u0119ciowa", "rozwija\u0142a", "si\u0119", "g\u0142\u00f3wnie", "w", "latach", "80-tych", ",", "jako", "paradygmat", "uczenia", "maszynowego", "bez", "nadzoru", "."], "sentence-detokenized": "Klasteryzacja poj\u0119ciowa rozwija\u0142a si\u0119 g\u0142\u00f3wnie w latach 80-tych, jako paradygmat uczenia maszynowego bez nadzoru.", "token2charspan": [[0, 13], [14, 23], [24, 33], [34, 37], [38, 45], [46, 47], [48, 54], [55, 62], [62, 63], [64, 68], [69, 79], [80, 87], [88, 99], [100, 103], [104, 111], [111, 112]]}
{"doc_key": "ai-dev-251", "ner": [[8, 9, "product"], [27, 28, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Je\u015bli", "jednostki", "nazwane", "nie", "mog\u0105", "by\u0107", "rozpoznane", "przez", "t\u0142umacza", "maszynowego", ",", "mog\u0105", "zosta\u0107", "b\u0142\u0119dnie", "przet\u0142umaczone", "jako", "rzeczowniki", "pospolite", ",", "co", "najprawdopodobniej", "nie", "wp\u0142yn\u0119\u0142oby", "na", "ocen\u0119", "t\u0142umaczenia", "w", "ocenie", "dwuj\u0119zycznej", ",", "ale", "zmieni\u0142oby", "czytelno\u015b\u0107", "tekstu", "dla", "cz\u0142owieka", "."], "sentence-detokenized": "Je\u015bli jednostki nazwane nie mog\u0105 by\u0107 rozpoznane przez t\u0142umacza maszynowego, mog\u0105 zosta\u0107 b\u0142\u0119dnie przet\u0142umaczone jako rzeczowniki pospolite, co najprawdopodobniej nie wp\u0142yn\u0119\u0142oby na ocen\u0119 t\u0142umaczenia w ocenie dwuj\u0119zycznej, ale zmieni\u0142oby czytelno\u015b\u0107 tekstu dla cz\u0142owieka.", "token2charspan": [[0, 5], [6, 15], [16, 23], [24, 27], [28, 32], [33, 36], [37, 47], [48, 53], [54, 62], [63, 74], [74, 75], [76, 80], [81, 87], [88, 95], [96, 110], [111, 115], [116, 127], [128, 137], [137, 138], [139, 141], [142, 160], [161, 164], [165, 175], [176, 178], [179, 184], [185, 196], [197, 198], [199, 205], [206, 218], [218, 219], [220, 223], [224, 234], [235, 245], [246, 252], [253, 256], [257, 266], [266, 267]]}
{"doc_key": "ai-dev-252", "ner": [[0, 1, "researcher"], [10, 11, "misc"], [12, 18, "conference"], [20, 21, "location"], [23, 23, "country"], [37, 38, "researcher"], [45, 45, "researcher"], [47, 48, "university"], [52, 53, "researcher"], [55, 56, "researcher"], [58, 59, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 11, "related-to", "writes_about", false, false], [0, 1, 12, 18, "temporal", "", true, false], [12, 18, 20, 21, "physical", "", false, false], [20, 21, 23, 23, "physical", "", false, false], [45, 45, 47, 48, "physical", "", false, false], [45, 45, 47, 48, "role", "", false, false], [52, 53, 47, 48, "physical", "", false, false], [52, 53, 47, 48, "role", "", false, false], [55, 56, 47, 48, "physical", "", false, false], [55, 56, 47, 48, "role", "", false, false], [58, 59, 47, 48, "physical", "", false, false], [58, 59, 47, 48, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Roger", "Schank", ",", "1969", ",", "A", "conceptual", "dependency", "parser", "for", "natural", "language", "Proceedings", "of", "the", "1969", "on", "Computational", "linguistics", ",", "S\u00e5ng-", "S\u00e4by", ",", "Sweden", ",", "s", ".", "1", "-", "3", "Model", "ten", ",", "cz\u0119\u015bciowo", "pod", "wp\u0142ywem", "prac", "Sydneya", "Lamba", ",", "by\u0142", "szeroko", "wykorzystywany", "przez", "student\u00f3w", "Schanka", "na", "Uniwersytecie", "Yale", ",", "takich", "jak", "Robert", "Wilensky", ",", "Wendy", "Lehnert", "i", "Janet", "Kolodner", "."], "sentence-detokenized": "Roger Schank, 1969, A conceptual dependency parser for natural language Proceedings of the 1969 on Computational linguistics, S\u00e5ng-S\u00e4by, Sweden, s. 1-3 Model ten, cz\u0119\u015bciowo pod wp\u0142ywem prac Sydneya Lamba, by\u0142 szeroko wykorzystywany przez student\u00f3w Schanka na Uniwersytecie Yale, takich jak Robert Wilensky, Wendy Lehnert i Janet Kolodner.", "token2charspan": [[0, 5], [6, 12], [12, 13], [14, 18], [18, 19], [20, 21], [22, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 71], [72, 83], [84, 86], [87, 90], [91, 95], [96, 98], [99, 112], [113, 124], [124, 125], [126, 131], [131, 135], [135, 136], [137, 143], [143, 144], [145, 146], [146, 147], [148, 149], [149, 150], [150, 151], [152, 157], [158, 161], [161, 162], [163, 172], [173, 176], [177, 184], [185, 189], [190, 197], [198, 203], [203, 204], [205, 208], [209, 216], [217, 231], [232, 237], [238, 247], [248, 255], [256, 258], [259, 272], [273, 277], [277, 278], [279, 285], [286, 289], [290, 296], [297, 305], [305, 306], [307, 312], [313, 320], [321, 322], [323, 328], [329, 337], [337, 338]]}
{"doc_key": "ai-dev-253", "ner": [[1, 3, "algorithm"], [5, 5, "algorithm"], [11, 11, "algorithm"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 1, 3, "named", "", false, false], [11, 11, 1, 3, "named", "", false, false], [13, 14, 1, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Ulepszona", "metoda", "maksymalnego", "prawdopodobie\u0144stwa", "(", "IMLM", ")", "jest", "po\u0142\u0105czeniem", "dw\u00f3ch", "estymator\u00f3w", "MLM", "(", "maximum", "likelihood", ")", "."], "sentence-detokenized": "Ulepszona metoda maksymalnego prawdopodobie\u0144stwa (IMLM) jest po\u0142\u0105czeniem dw\u00f3ch estymator\u00f3w MLM (maximum likelihood).", "token2charspan": [[0, 9], [10, 16], [17, 29], [30, 48], [49, 50], [50, 54], [54, 55], [56, 60], [61, 72], [73, 78], [79, 90], [91, 94], [95, 96], [96, 103], [104, 114], [114, 115], [115, 116]]}
{"doc_key": "ai-dev-254", "ner": [[18, 19, "metrics"], [22, 23, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[22, 23, 18, 19, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Metody", "te", "mog\u0105", "r\u00f3wnie\u017c", "analizowa\u0107", "dane", "wyj\u015bciowe", "programu", "i", "jego", "u\u017cyteczno\u015b\u0107", ",", "a", "wi\u0119c", "mog\u0105", "obejmowa\u0107", "analiz\u0119", "jego", "macierzy", "konfuzji", "(", "lub", "tabeli", "konfuzji", ")", "."], "sentence-detokenized": "Metody te mog\u0105 r\u00f3wnie\u017c analizowa\u0107 dane wyj\u015bciowe programu i jego u\u017cyteczno\u015b\u0107, a wi\u0119c mog\u0105 obejmowa\u0107 analiz\u0119 jego macierzy konfuzji (lub tabeli konfuzji).", "token2charspan": [[0, 6], [7, 9], [10, 14], [15, 22], [23, 33], [34, 38], [39, 48], [49, 57], [58, 59], [60, 64], [65, 76], [76, 77], [78, 79], [80, 84], [85, 89], [90, 99], [100, 107], [108, 112], [113, 121], [122, 130], [131, 132], [132, 135], [136, 142], [143, 151], [151, 152], [152, 153]]}
{"doc_key": "ai-dev-255", "ner": [[0, 0, "product"], [7, 8, "researcher"], [10, 11, "researcher"], [14, 16, "researcher"], [19, 25, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 7, 8, "origin", "", false, false], [0, 0, 10, 11, "origin", "", false, false], [0, 0, 14, 16, "origin", "", false, false], [0, 0, 19, 25, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SURF", "zosta\u0142", "po", "raz", "pierwszy", "opublikowany", "przez", "Herberta", "Baya", ",", "Tinne", "Tuytelaars", "i", "Luca", "Van", "Goola", "i", "zaprezentowany", "na", "Europejskiej", "Konferencji", "Widzenia", "Komputerowego", "w", "2006", "roku", "."], "sentence-detokenized": "SURF zosta\u0142 po raz pierwszy opublikowany przez Herberta Baya, Tinne Tuytelaars i Luca Van Goola i zaprezentowany na Europejskiej Konferencji Widzenia Komputerowego w 2006 roku.", "token2charspan": [[0, 4], [5, 11], [12, 14], [15, 18], [19, 27], [28, 40], [41, 46], [47, 55], [56, 60], [60, 61], [62, 67], [68, 78], [79, 80], [81, 85], [86, 89], [90, 95], [96, 97], [98, 112], [113, 115], [116, 128], [129, 140], [141, 149], [150, 163], [164, 165], [166, 170], [171, 175], [175, 176]]}
{"doc_key": "ai-dev-256", "ner": [[0, 0, "task"], [6, 7, "field"], [9, 10, "field"], [12, 12, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 7, "part-of", "", false, false], [0, 0, 9, 10, "part-of", "", false, false], [0, 0, 12, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OCR", "to", "dziedzina", "bada\u0144", "z", "zakresu", "rozpoznawania", "wzorc\u00f3w", ",", "sztucznej", "inteligencji", "i", "wizji", "komputerowej", "."], "sentence-detokenized": "OCR to dziedzina bada\u0144 z zakresu rozpoznawania wzorc\u00f3w, sztucznej inteligencji i wizji komputerowej.", "token2charspan": [[0, 3], [4, 6], [7, 16], [17, 22], [23, 24], [25, 32], [33, 46], [47, 54], [54, 55], [56, 65], [66, 78], [79, 80], [81, 86], [87, 99], [99, 100]]}
{"doc_key": "ai-dev-257", "ner": [[4, 6, "metrics"], [8, 10, "algorithm"], [12, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 12, 8, 10, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Kontynuuj\u0105c", "przyk\u0142ad", "z", "wykorzystaniem", "estymatora", "maksymalnego", "prawdopodobie\u0144stwa", ",", "funkcja", "g\u0119sto\u015bci", "prawdopodobie\u0144stwa", "(", "pdf", ")", "szumu", "dla", "jednej", "pr\u00f3bki", "mathwn", "/", "math", "wynosi"], "sentence-detokenized": "Kontynuuj\u0105c przyk\u0142ad z wykorzystaniem estymatora maksymalnego prawdopodobie\u0144stwa, funkcja g\u0119sto\u015bci prawdopodobie\u0144stwa (pdf) szumu dla jednej pr\u00f3bki mathwn / math wynosi", "token2charspan": [[0, 11], [12, 20], [21, 22], [23, 37], [38, 48], [49, 61], [62, 80], [80, 81], [82, 89], [90, 98], [99, 117], [118, 119], [119, 122], [122, 123], [124, 129], [130, 133], [134, 140], [141, 147], [148, 154], [155, 156], [157, 161], [162, 168]]}
{"doc_key": "ai-dev-258", "ner": [[1, 2, "field"], [4, 5, "task"], [7, 8, "task"], [10, 11, "task"], [13, 14, "task"], [16, 18, "task"], [20, 21, "task"], [23, 23, "task"], [25, 26, "task"], [28, 29, "task"], [31, 33, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[4, 5, 1, 2, "part-of", "", false, false], [7, 8, 1, 2, "part-of", "", false, false], [10, 11, 1, 2, "part-of", "", false, false], [13, 14, 1, 2, "part-of", "", false, false], [16, 18, 1, 2, "part-of", "", false, false], [20, 21, 1, 2, "part-of", "", false, false], [23, 23, 1, 2, "part-of", "", false, false], [25, 26, 1, 2, "part-of", "", false, false], [28, 29, 1, 2, "part-of", "", false, false], [31, 33, 1, 2, "part-of", "", false, false], [35, 36, 1, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Subdomenami", "wizji", "komputerowej", "s\u0105", "rekonstrukcja", "sceny", ",", "detekcja", "zdarze\u0144", ",", "\u015bledzenie", "wideo", ",", "rozpoznawanie", "obiekt\u00f3w", ",", "estymacja", "pozy", "3D", ",", "uczenie", "si\u0119", ",", "indeksowanie", ",", "estymacja", "ruchu", ",", "serwomechanizm", "wizualny", ",", "modelowanie", "sceny", "3D", "i", "odtwarzanie", "obrazu", "."], "sentence-detokenized": "Subdomenami wizji komputerowej s\u0105 rekonstrukcja sceny, detekcja zdarze\u0144, \u015bledzenie wideo, rozpoznawanie obiekt\u00f3w, estymacja pozy 3D, uczenie si\u0119, indeksowanie, estymacja ruchu, serwomechanizm wizualny, modelowanie sceny 3D i odtwarzanie obrazu.", "token2charspan": [[0, 11], [12, 17], [18, 30], [31, 33], [34, 47], [48, 53], [53, 54], [55, 63], [64, 71], [71, 72], [73, 82], [83, 88], [88, 89], [90, 103], [104, 112], [112, 113], [114, 123], [124, 128], [129, 131], [131, 132], [133, 140], [141, 144], [144, 145], [146, 158], [158, 159], [160, 169], [170, 175], [175, 176], [177, 191], [192, 200], [200, 201], [202, 213], [214, 219], [220, 222], [223, 224], [225, 236], [237, 243], [243, 244]]}
{"doc_key": "ai-dev-259", "ner": [[4, 8, "conference"], [9, 9, "researcher"], [11, 12, "misc"], [15, 19, "conference"], [20, 20, "researcher"], [22, 22, "researcher"], [25, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 8, 15, 19, "named", "", false, false], [9, 9, 11, 12, "win-defeat", "", false, false], [9, 9, 25, 27, "related-to", "writes_about", true, false], [11, 12, 4, 8, "temporal", "", false, false], [20, 20, 11, 12, "win-defeat", "", false, true], [20, 20, 25, 27, "related-to", "writes_about", true, false], [22, 22, 11, 12, "win-defeat", "", false, true], [22, 22, 25, 27, "related-to", "writes_about", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["W", "2013", "roku", "na", "International", "Conference", "on", "Computer", "Vision", "Terzopoulos", "otrzyma\u0142", "nagrod\u0119", "Helmholtza", "za", "prac\u0119", "ICCV", "z", "1987", "roku", "z", "Kassem", "i", "Witkinem", "na", "temat", "aktywnych", "modeli", "konturowych", "."], "sentence-detokenized": "W 2013 roku na International Conference on Computer Vision Terzopoulos otrzyma\u0142 nagrod\u0119 Helmholtza za prac\u0119 ICCV z 1987 roku z Kassem i Witkinem na temat aktywnych modeli konturowych.", "token2charspan": [[0, 1], [2, 6], [7, 11], [12, 14], [15, 28], [29, 39], [40, 42], [43, 51], [52, 58], [59, 70], [71, 79], [80, 87], [88, 98], [99, 101], [102, 107], [108, 112], [113, 114], [115, 119], [120, 124], [125, 126], [127, 133], [134, 135], [136, 144], [145, 147], [148, 153], [154, 163], [164, 170], [171, 182], [182, 183]]}
{"doc_key": "ai-dev-260", "ner": [[14, 15, "task"], [18, 20, "algorithm"], [22, 23, "algorithm"], [25, 25, "algorithm"], [27, 28, "algorithm"], [30, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 15, 18, 20, "usage", "", true, false], [14, 15, 22, 23, "usage", "", true, false], [14, 15, 25, 25, "usage", "", true, false], [14, 15, 27, 28, "usage", "", true, false], [14, 15, 30, 31, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Je\u015bli", "funkcja", "regularno\u015bci", "Wiele", "algorytm\u00f3w", "istnieje", "do", "rozwi\u0105zywania", "takich", "problem\u00f3w", ";", "do", "popularnych", "dla", "klasyfikacji", "liniowej", "nale\u017c\u0105", ":", "stochastyczne", "zej\u015bcie", "gradientowe", ")", "gradient", "descent", ",", "L-BFGS", ",", "zej\u015bcie", "wsp\u00f3\u0142rz\u0119dnych", "i", "metody", "Newtona", "."], "sentence-detokenized": "Je\u015bli funkcja regularno\u015bci Wiele algorytm\u00f3w istnieje do rozwi\u0105zywania takich problem\u00f3w; do popularnych dla klasyfikacji liniowej nale\u017c\u0105: stochastyczne zej\u015bcie gradientowe) gradient descent, L-BFGS, zej\u015bcie wsp\u00f3\u0142rz\u0119dnych i metody Newtona.", "token2charspan": [[0, 5], [6, 13], [14, 26], [27, 32], [33, 43], [44, 52], [53, 55], [56, 69], [70, 76], [77, 86], [86, 87], [88, 90], [91, 102], [103, 106], [107, 119], [120, 128], [129, 135], [135, 136], [137, 150], [151, 158], [159, 170], [170, 171], [172, 180], [181, 188], [188, 189], [190, 196], [196, 197], [198, 205], [206, 219], [220, 221], [222, 228], [229, 236], [236, 237]]}
{"doc_key": "ai-dev-261", "ner": [[3, 5, "algorithm"], [1, 1, "algorithm"], [10, 11, "researcher"], [13, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 5, 10, 11, "origin", "", false, false], [1, 1, 3, 5, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Sieci", "LSTM", "(", "Long", "Short-term", "Memory", ")", "zosta\u0142y", "wynalezione", "przez", "Seppa", "Hochreitera", "i", "J\u00fcrgena", "Schmidhubera", "w", "1997", "roku", "i", "ustanowi\u0142y", "rekordy", "dok\u0142adno\u015bci", "w", "wielu", "dziedzinach", "zastosowa\u0144", "."], "sentence-detokenized": "Sieci LSTM (Long Short-term Memory) zosta\u0142y wynalezione przez Seppa Hochreitera i J\u00fcrgena Schmidhubera w 1997 roku i ustanowi\u0142y rekordy dok\u0142adno\u015bci w wielu dziedzinach zastosowa\u0144.", "token2charspan": [[0, 5], [6, 10], [11, 12], [12, 16], [17, 27], [28, 34], [34, 35], [36, 43], [44, 55], [56, 61], [62, 67], [68, 79], [80, 81], [82, 89], [90, 102], [103, 104], [105, 109], [110, 114], [115, 116], [117, 127], [128, 135], [136, 147], [148, 149], [150, 155], [156, 167], [168, 178], [178, 179]]}
{"doc_key": "ai-dev-262", "ner": [[0, 0, "product"], [4, 6, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 6, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["TN", "zosta\u0142", "opracowany", "w", "Massachusetts", "General", "Hospital", "i", "by\u0142", "testowany", "w", "wielu", "scenariuszach", ",", "w", "tym", "do", "ekstrakcji", "statusu", "palenia", ",", "rodzinnej", "historii", "choroby", "wie\u0144cowej", ",", "identyfikacji", "pacjent\u00f3w", "z", "zaburzeniami", "snu", ","], "sentence-detokenized": "TN zosta\u0142 opracowany w Massachusetts General Hospital i by\u0142 testowany w wielu scenariuszach, w tym do ekstrakcji statusu palenia, rodzinnej historii choroby wie\u0144cowej, identyfikacji pacjent\u00f3w z zaburzeniami snu,", "token2charspan": [[0, 2], [3, 9], [10, 20], [21, 22], [23, 36], [37, 44], [45, 53], [54, 55], [56, 59], [60, 69], [70, 71], [72, 77], [78, 91], [91, 92], [93, 94], [95, 98], [99, 101], [102, 112], [113, 120], [121, 128], [128, 129], [130, 139], [140, 148], [149, 156], [157, 166], [166, 167], [168, 181], [182, 191], [192, 193], [194, 206], [207, 210], [210, 211]]}
{"doc_key": "ai-dev-263", "ner": [[3, 3, "researcher"], [8, 8, "product"], [17, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 8, 8, "role", "sells", false, false], [8, 8, 17, 18, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["W", "1960", "roku", "Devol", "osobi\u015bcie", "sprzeda\u0142", "pierwszego", "robota", "Unimate", ",", "kt\u00f3ry", "w", "1961", "roku", "zosta\u0142", "wys\u0142any", "do", "General", "Motors", "."], "sentence-detokenized": "W 1960 roku Devol osobi\u015bcie sprzeda\u0142 pierwszego robota Unimate, kt\u00f3ry w 1961 roku zosta\u0142 wys\u0142any do General Motors.", "token2charspan": [[0, 1], [2, 6], [7, 11], [12, 17], [18, 27], [28, 36], [37, 47], [48, 54], [55, 62], [62, 63], [64, 69], [70, 71], [72, 76], [77, 81], [82, 88], [89, 96], [97, 99], [100, 107], [108, 114], [114, 115]]}
{"doc_key": "ai-dev-264", "ner": [[0, 2, "conference"], [15, 16, "location"], [18, 18, "location"], [21, 21, "country"], [33, 34, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 15, 16, "physical", "", false, false], [15, 16, 18, 18, "physical", "", false, false], [18, 18, 21, 21, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Campus", "Party", "Europe", "odby\u0142o", "si\u0119", "w", "dniach", "14", "-", "18", "kwietnia", "2010", "r", ".", "w", "Caja", "M\u00e1gica", "w", "Madrycie", ",", "w", "Hiszpanii", ",", "z", "udzia\u0142em", "800", "uczestnik\u00f3w", "z", "ka\u017cdego", "z", "27", "pa\u0144stw", "cz\u0142onkowskich", "Unii", "Europejskiej", "."], "sentence-detokenized": "Campus Party Europe odby\u0142o si\u0119 w dniach 14-18 kwietnia 2010 r. w Caja M\u00e1gica w Madrycie, w Hiszpanii, z udzia\u0142em 800 uczestnik\u00f3w z ka\u017cdego z 27 pa\u0144stw cz\u0142onkowskich Unii Europejskiej.", "token2charspan": [[0, 6], [7, 12], [13, 19], [20, 26], [27, 30], [31, 32], [33, 39], [40, 42], [42, 43], [43, 45], [46, 54], [55, 59], [60, 61], [61, 62], [63, 64], [65, 69], [70, 76], [77, 78], [79, 87], [87, 88], [89, 90], [91, 100], [100, 101], [102, 103], [104, 112], [113, 116], [117, 128], [129, 130], [131, 138], [139, 140], [141, 143], [144, 150], [151, 164], [165, 169], [170, 182], [182, 183]]}
{"doc_key": "ai-dev-265", "ner": [[6, 6, "organisation"], [8, 10, "organisation"], [16, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 20, 6, 6, "origin", "", false, false], [16, 20, 8, 10, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["W", "lipcu", "2016", "roku", "og\u0142oszono", "wsp\u00f3\u0142prac\u0119", "DeepMind", "z", "Moorfields", "Eye", "Hospital", ",", "kt\u00f3rej", "celem", "jest", "opracowanie", "aplikacji", "AI", "dla", "s\u0142u\u017cby", "zdrowia", "."], "sentence-detokenized": "W lipcu 2016 roku og\u0142oszono wsp\u00f3\u0142prac\u0119 DeepMind z Moorfields Eye Hospital, kt\u00f3rej celem jest opracowanie aplikacji AI dla s\u0142u\u017cby zdrowia.", "token2charspan": [[0, 1], [2, 7], [8, 12], [13, 17], [18, 27], [28, 38], [39, 47], [48, 49], [50, 60], [61, 64], [65, 73], [73, 74], [75, 81], [82, 87], [88, 92], [93, 104], [105, 114], [115, 117], [118, 121], [122, 128], [129, 136], [136, 137]]}
{"doc_key": "ai-dev-266", "ner": [[3, 3, "misc"], [9, 11, "university"], [13, 13, "university"], [15, 16, "university"], [18, 19, "university"], [21, 21, "university"], [23, 23, "university"], [25, 26, "university"], [28, 29, "university"], [31, 32, "university"], [34, 34, "university"], [36, 38, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[3, 3, 9, 11, "physical", "", false, false], [3, 3, 13, 13, "physical", "", false, false], [3, 3, 15, 16, "physical", "", false, false], [3, 3, 18, 19, "physical", "", false, false], [3, 3, 21, 21, "physical", "", false, false], [3, 3, 23, 23, "physical", "", false, false], [3, 3, 25, 26, "physical", "", false, false], [3, 3, 28, 29, "physical", "", false, false], [3, 3, 31, 32, "physical", "", false, false], [3, 3, 34, 34, "physical", "", false, false], [3, 3, 36, 38, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Ostatecznie", "przyznali", "jedena\u015bcie", "PR2", "r\u00f3\u017cnym", "instytucjom", ",", "w", "tym", "Uniwersytetowi", "we", "Freiburgu", ",", "Boschowi", ",", "Georgia", "Tech", ",", "KU", "Leuven", ",", "MIT", ",", "Stanfordowi", ",", "Politechnice", "Monachijskiej", ",", "UC", "Berkeley", ",", "U", "Penn", ",", "USC", "i", "Uniwersytetowi", "w", "Tokio", "."], "sentence-detokenized": "Ostatecznie przyznali jedena\u015bcie PR2 r\u00f3\u017cnym instytucjom, w tym Uniwersytetowi we Freiburgu, Boschowi, Georgia Tech, KU Leuven, MIT, Stanfordowi, Politechnice Monachijskiej, UC Berkeley, U Penn, USC i Uniwersytetowi w Tokio.", "token2charspan": [[0, 11], [12, 21], [22, 32], [33, 36], [37, 43], [44, 55], [55, 56], [57, 58], [59, 62], [63, 77], [78, 80], [81, 90], [90, 91], [92, 100], [100, 101], [102, 109], [110, 114], [114, 115], [116, 118], [119, 125], [125, 126], [127, 130], [130, 131], [132, 143], [143, 144], [145, 157], [158, 171], [171, 172], [173, 175], [176, 184], [184, 185], [186, 187], [188, 192], [192, 193], [194, 197], [198, 199], [200, 214], [215, 216], [217, 222], [222, 223]]}
{"doc_key": "ai-dev-267", "ner": [[1, 1, "metrics"], [3, 3, "metrics"], [5, 5, "metrics"], [7, 7, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 14, 15, "part-of", "", false, false], [3, 3, 14, 15, "part-of", "", false, false], [5, 5, 14, 15, "part-of", "", false, false], [7, 7, 14, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Zliczenia", "TP", ",", "TN", ",", "FP", "i", "FN", "przechowywane", "s\u0105", "zwykle", "w", "tabeli", "zwanej", "macierz\u0105", "konfuzji", "."], "sentence-detokenized": "Zliczenia TP, TN, FP i FN przechowywane s\u0105 zwykle w tabeli zwanej macierz\u0105 konfuzji.", "token2charspan": [[0, 9], [10, 12], [12, 13], [14, 16], [16, 17], [18, 20], [21, 22], [23, 25], [26, 39], [40, 42], [43, 49], [50, 51], [52, 58], [59, 65], [66, 74], [75, 83], [83, 84]]}
{"doc_key": "ai-dev-268", "ner": [[6, 7, "metrics"], [9, 10, "metrics"], [12, 13, "metrics"], [16, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Jako", "zestaw", "cech", "najcz\u0119\u015bciej", "stosuje", "si\u0119", "zysk", "informacyjny", ",", "entropi\u0119", "krzy\u017cow\u0105", ",", "informacj\u0119", "wzajemn\u0105", "i", "iloraz", "szans", "."], "sentence-detokenized": "Jako zestaw cech najcz\u0119\u015bciej stosuje si\u0119 zysk informacyjny, entropi\u0119 krzy\u017cow\u0105, informacj\u0119 wzajemn\u0105 i iloraz szans.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 28], [29, 36], [37, 40], [41, 45], [46, 58], [58, 59], [60, 68], [69, 77], [77, 78], [79, 89], [90, 98], [99, 100], [101, 107], [108, 113], [113, 114]]}
{"doc_key": "ai-dev-269", "ner": [[12, 13, "task"], [15, 17, "task"], [19, 19, "task"], [22, 22, "task"], [24, 24, "task"], [26, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[26, 26, 24, 24, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Zosta\u0142a", "ona", "z", "powodzeniem", "zastosowana", "do", "r\u00f3\u017cnych", "problem\u00f3w", ",", "w", "tym", "do", "sterowania", "robotami", ",", "harmonogramu", "pracy", "wind", ",", "telekomunikacji", ",", ",", "warcab\u00f3w", "i", "Go", "(", "AlphaGo", ")", "."], "sentence-detokenized": "Zosta\u0142a ona z powodzeniem zastosowana do r\u00f3\u017cnych problem\u00f3w, w tym do sterowania robotami, harmonogramu pracy wind, telekomunikacji,, warcab\u00f3w i Go (AlphaGo).", "token2charspan": [[0, 7], [8, 11], [12, 13], [14, 25], [26, 37], [38, 40], [41, 48], [49, 58], [58, 59], [60, 61], [62, 65], [66, 68], [69, 79], [80, 88], [88, 89], [90, 102], [103, 108], [109, 113], [113, 114], [115, 130], [130, 131], [131, 132], [133, 141], [142, 143], [144, 146], [147, 148], [148, 155], [155, 156], [156, 157]]}
{"doc_key": "ai-dev-270", "ner": [[9, 10, "misc"], [15, 18, "university"], [20, 20, "location"], [22, 22, "location"], [25, 28, "location"], [31, 33, "location"], [35, 35, "location"], [36, 36, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[9, 10, 15, 18, "physical", "", false, false], [15, 18, 20, 20, "physical", "", false, false], [20, 20, 22, 22, "physical", "", false, false], [25, 28, 31, 33, "physical", "", false, false], [31, 33, 35, 35, "physical", "", false, false], [35, 35, 36, 36, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["W", "2018", "roku", ",", "inauguracyjnym", "roku", "misji", "8", ",", "American", "Venue", "odby\u0142o", "si\u0119", "na", "kampusie", "Georgia", "Institute", "of", "Technology", "w", "Atlancie", ",", "Georgia", ",", "a", "Asia", "/", "Pacific", "Venue", "przeprowadzono", "w", "Beihang", "University", "Gymnasium", "w", "Pekinie", "Chiny", "."], "sentence-detokenized": "W 2018 roku, inauguracyjnym roku misji 8, American Venue odby\u0142o si\u0119 na kampusie Georgia Institute of Technology w Atlancie, Georgia, a Asia / Pacific Venue przeprowadzono w Beihang University Gymnasium w Pekinie Chiny.", "token2charspan": [[0, 1], [2, 6], [7, 11], [11, 12], [13, 27], [28, 32], [33, 38], [39, 40], [40, 41], [42, 50], [51, 56], [57, 63], [64, 67], [68, 70], [71, 79], [80, 87], [88, 97], [98, 100], [101, 111], [112, 113], [114, 122], [122, 123], [124, 131], [131, 132], [133, 134], [135, 139], [140, 141], [142, 149], [150, 155], [156, 170], [171, 172], [173, 180], [181, 191], [192, 201], [202, 203], [204, 211], [212, 217], [217, 218]]}
{"doc_key": "ai-dev-271", "ner": [[0, 1, "field"], [6, 7, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "origin", "", false, false], [0, 1, 6, 7, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Uczenie", "maszynowe", "jest", "silnie", "zwi\u0105zane", "z", "rozpoznawaniem", "wzorc\u00f3w", "i", "wywodzi", "si\u0119", "ze", "sztucznej", "inteligencji", "."], "sentence-detokenized": "Uczenie maszynowe jest silnie zwi\u0105zane z rozpoznawaniem wzorc\u00f3w i wywodzi si\u0119 ze sztucznej inteligencji.", "token2charspan": [[0, 7], [8, 17], [18, 22], [23, 29], [30, 38], [39, 40], [41, 55], [56, 63], [64, 65], [66, 73], [74, 77], [78, 80], [81, 90], [91, 103], [103, 104]]}
{"doc_key": "ai-dev-272", "ner": [[6, 6, "programlang"], [18, 19, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["W", "zestawie", "znajduj\u0105", "si\u0119", "3", "gry", "Java", ",", "kt\u00f3re", "s\u0105", "sterowane", "za", "pomoc\u0105", "pilota", "i", "wy\u015bwietlane", "na", "jego", "ekranie", "LCD", "."], "sentence-detokenized": "W zestawie znajduj\u0105 si\u0119 3 gry Java, kt\u00f3re s\u0105 sterowane za pomoc\u0105 pilota i wy\u015bwietlane na jego ekranie LCD.", "token2charspan": [[0, 1], [2, 10], [11, 19], [20, 23], [24, 25], [26, 29], [30, 34], [34, 35], [36, 41], [42, 44], [45, 54], [55, 57], [58, 64], [65, 71], [72, 73], [74, 85], [86, 88], [89, 93], [94, 101], [102, 105], [105, 106]]}
{"doc_key": "ai-dev-273", "ner": [[5, 12, "task"], [14, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 16, 5, 12, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Komercyjn\u0105", ",", "lecz", "wyspecjalizowan\u0105", "technik\u0105", "estymacji", "pozycji", "cia\u0142a", "przegubowego", "opart\u0105", "na", "wizji", "komputerowej", "jest", "optyczna", "rejestracja", "ruchu", "."], "sentence-detokenized": "Komercyjn\u0105, lecz wyspecjalizowan\u0105 technik\u0105 estymacji pozycji cia\u0142a przegubowego opart\u0105 na wizji komputerowej jest optyczna rejestracja ruchu.", "token2charspan": [[0, 10], [10, 11], [12, 16], [17, 33], [34, 42], [43, 52], [53, 60], [61, 66], [67, 79], [80, 86], [87, 89], [90, 95], [96, 108], [109, 113], [114, 122], [123, 134], [135, 140], [140, 141]]}
{"doc_key": "ai-dev-274", "ner": [[0, 0, "organisation"], [7, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 7, 8, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["SMC", "jest", "bardzo", "podobny", "do", "bardziej", "popularnego", "indeksu", "Jaccarda", "."], "sentence-detokenized": "SMC jest bardzo podobny do bardziej popularnego indeksu Jaccarda.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 23], [24, 26], [27, 35], [36, 47], [48, 55], [56, 64], [64, 65]]}
{"doc_key": "ai-dev-275", "ner": [[0, 0, "product"], [2, 6, "product"], [9, 12, "product"], [20, 21, "researcher"], [26, 26, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 9, 12, "named", "", false, false], [0, 0, 20, 21, "artifact", "", false, false], [0, 0, 26, 26, "artifact", "", false, false], [2, 6, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ",", "czyli", "Programowalne", "Uniwersalne", "Rami\u0119", "Manipulacyjne", ")", "to", "rami\u0119", "robota", "przemys\u0142owego", "opracowane", "przez", "Victora", "Scheinmana", "w", "pionierskiej", "firmie", "robotycznej", "Unimation", "."], "sentence-detokenized": "PUMA (Programmable Universal Machine for Assembly, czyli Programowalne Uniwersalne Rami\u0119 Manipulacyjne) to rami\u0119 robota przemys\u0142owego opracowane przez Victora Scheinmana w pionierskiej firmie robotycznej Unimation.", "token2charspan": [[0, 4], [5, 6], [6, 18], [19, 28], [29, 36], [37, 40], [41, 49], [49, 50], [51, 56], [57, 70], [71, 82], [83, 88], [89, 102], [102, 103], [104, 106], [107, 112], [113, 119], [120, 133], [134, 144], [145, 150], [151, 158], [159, 169], [170, 171], [172, 184], [185, 191], [192, 203], [204, 213], [213, 214]]}
{"doc_key": "ai-dev-276", "ner": [[5, 5, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Jest", "on", "napisany", "w", "j\u0119zyku", "Python", "."], "sentence-detokenized": "Jest on napisany w j\u0119zyku Python.", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 18], [19, 25], [26, 32], [32, 33]]}
{"doc_key": "ai-dev-277", "ner": [[0, 1, "misc"], [3, 3, "misc"], [14, 14, "field"], [16, 17, "field"], [19, 20, "field"], [22, 22, "field"], [24, 25, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 3, 3, "related-to", "metric_for", true, false], [0, 1, 14, 14, "part-of", "", false, false], [0, 1, 16, 17, "part-of", "", false, false], [0, 1, 19, 20, "part-of", "", false, false], [0, 1, 22, 22, "part-of", "", false, false], [0, 1, 24, 25, "part-of", "", false, false], [0, 1, 27, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Szeroko\u015b\u0107", "pasma", "w", "hercach", "jest", "centralnym", "poj\u0119ciem", "w", "wielu", "dziedzinach", ",", "w", "tym", "w", "elektronice", ",", "teorii", "informacji", ",", "komunikacji", "cyfrowej", ",", "radiokomunikacji", ",", "przetwarzaniu", "sygna\u0142\u00f3w", "i", "spektroskopii", "i", "jest", "jednym", "z", "wyznacznik\u00f3w", "pojemno\u015bci", "danego", "kana\u0142u", "komunikacyjnego", "."], "sentence-detokenized": "Szeroko\u015b\u0107 pasma w hercach jest centralnym poj\u0119ciem w wielu dziedzinach, w tym w elektronice, teorii informacji, komunikacji cyfrowej, radiokomunikacji, przetwarzaniu sygna\u0142\u00f3w i spektroskopii i jest jednym z wyznacznik\u00f3w pojemno\u015bci danego kana\u0142u komunikacyjnego.", "token2charspan": [[0, 9], [10, 15], [16, 17], [18, 25], [26, 30], [31, 41], [42, 50], [51, 52], [53, 58], [59, 70], [70, 71], [72, 73], [74, 77], [78, 79], [80, 91], [91, 92], [93, 99], [100, 110], [110, 111], [112, 123], [124, 132], [132, 133], [134, 150], [150, 151], [152, 165], [166, 174], [175, 176], [177, 190], [191, 192], [193, 197], [198, 204], [205, 206], [207, 219], [220, 230], [231, 237], [238, 244], [245, 260], [260, 261]]}
{"doc_key": "ai-dev-278", "ner": [[8, 8, "algorithm"], [10, 10, "algorithm"], [14, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 14, 16, "part-of", "", false, false], [10, 10, 14, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Je\u015bli", "wykorzystuje", "si\u0119", "wypuk\u0142\u0105", "strat\u0119", "(", "jak", "w", "AdaBoost", ",", "LogitBoost", "i", "wszystkich", "cz\u0142onk\u00f3w", "rodziny", "AnyBoost", "algorytm\u00f3w", ")", ",", "to", "przyk\u0142ad", "z", "wy\u017cszym", "marginesem", "otrzyma", "mniejsz\u0105", "(", "lub", "r\u00f3wn\u0105", ")", "wag\u0119", "ni\u017c", "przyk\u0142ad", "z", "ni\u017cszym", "marginesem", "."], "sentence-detokenized": "Je\u015bli wykorzystuje si\u0119 wypuk\u0142\u0105 strat\u0119 (jak w AdaBoost, LogitBoost i wszystkich cz\u0142onk\u00f3w rodziny AnyBoost algorytm\u00f3w), to przyk\u0142ad z wy\u017cszym marginesem otrzyma mniejsz\u0105 (lub r\u00f3wn\u0105) wag\u0119 ni\u017c przyk\u0142ad z ni\u017cszym marginesem.", "token2charspan": [[0, 5], [6, 18], [19, 22], [23, 30], [31, 37], [38, 39], [39, 42], [43, 44], [45, 53], [53, 54], [55, 65], [66, 67], [68, 78], [79, 87], [88, 95], [96, 104], [105, 115], [115, 116], [116, 117], [118, 120], [121, 129], [130, 131], [132, 139], [140, 150], [151, 158], [159, 167], [168, 169], [169, 172], [173, 178], [178, 179], [180, 184], [185, 188], [189, 197], [198, 199], [200, 207], [208, 218], [218, 219]]}
{"doc_key": "ai-dev-279", "ner": [[3, 3, "researcher"], [7, 8, "researcher"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 7, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Praca", "dyplomowa", "Seppa", "Hochreitera", "z", "1991", "roku", "Sepp", "Hochreiter", "."], "sentence-detokenized": "Praca dyplomowa Seppa Hochreitera z 1991 roku Sepp Hochreiter.", "token2charspan": [[0, 5], [6, 15], [16, 21], [22, 33], [34, 35], [36, 40], [41, 45], [46, 50], [51, 61], [61, 62]]}
{"doc_key": "ai-dev-280", "ner": [[4, 5, "algorithm"], [7, 7, "algorithm"], [10, 12, "algorithm"], [14, 14, "algorithm"], [17, 19, "algorithm"], [21, 21, "algorithm"], [26, 27, "algorithm"], [30, 31, "algorithm"], [33, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[7, 7, 4, 5, "named", "", false, false], [14, 14, 10, 12, "named", "", false, false], [17, 19, 26, 27, "related-to", "", true, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Typowe", "modele", "dyskryminacyjne", "obejmuj\u0105", "regresj\u0119", "logistyczn\u0105", "(", "LR", ")", ",", "maszyny", "wektor\u00f3w", "wsparcia", "(", "SVM", ")", ",", "warunkowe", "pola", "losowe", "(", "CRF", ")", "(", "okre\u015blone", "na", "grafie", "nieskierowanym", ")", ",", "drzewa", "decyzyjne", ",", "sieci", "neuronowe", "i", "wiele", "innych", "."], "sentence-detokenized": "Typowe modele dyskryminacyjne obejmuj\u0105 regresj\u0119 logistyczn\u0105 (LR), maszyny wektor\u00f3w wsparcia (SVM), warunkowe pola losowe (CRF) (okre\u015blone na grafie nieskierowanym), drzewa decyzyjne, sieci neuronowe i wiele innych.", "token2charspan": [[0, 6], [7, 13], [14, 29], [30, 38], [39, 47], [48, 59], [60, 61], [61, 63], [63, 64], [64, 65], [66, 73], [74, 82], [83, 91], [92, 93], [93, 96], [96, 97], [97, 98], [99, 108], [109, 113], [114, 120], [121, 122], [122, 125], [125, 126], [127, 128], [128, 137], [138, 140], [141, 147], [148, 162], [162, 163], [163, 164], [165, 171], [172, 181], [181, 182], [183, 188], [189, 198], [199, 200], [201, 206], [207, 213], [213, 214]]}
{"doc_key": "ai-dev-281", "ner": [[8, 10, "metrics"], [28, 29, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Nast\u0119pnie", "mo\u017cna", "r\u00f3wnie\u017c", "u\u017cy\u0107", "tych", "prawdopodobie\u0144stw", "i", "oceni\u0107", "\u015bredni", "b\u0142\u0105d", "kwadratowy", "(", "lub", "inn\u0105", "podobn\u0105", "miar\u0119", ")", "mi\u0119dzy", "prawdopodobie\u0144stwami", "a", "rzeczywistymi", "warto\u015bciami", ",", "a", "nast\u0119pnie", "po\u0142\u0105czy\u0107", "to", "z", "macierz\u0105", "konfuzji", ",", "aby", "stworzy\u0107", "bardzo", "wydajne", "funkcje", "fitness", "dla", "regresji", "logistycznej", "."], "sentence-detokenized": "Nast\u0119pnie mo\u017cna r\u00f3wnie\u017c u\u017cy\u0107 tych prawdopodobie\u0144stw i oceni\u0107 \u015bredni b\u0142\u0105d kwadratowy (lub inn\u0105 podobn\u0105 miar\u0119) mi\u0119dzy prawdopodobie\u0144stwami a rzeczywistymi warto\u015bciami, a nast\u0119pnie po\u0142\u0105czy\u0107 to z macierz\u0105 konfuzji, aby stworzy\u0107 bardzo wydajne funkcje fitness dla regresji logistycznej.", "token2charspan": [[0, 9], [10, 15], [16, 23], [24, 28], [29, 33], [34, 51], [52, 53], [54, 60], [61, 67], [68, 72], [73, 83], [84, 85], [85, 88], [89, 93], [94, 101], [102, 107], [107, 108], [109, 115], [116, 136], [137, 138], [139, 152], [153, 164], [164, 165], [166, 167], [168, 177], [178, 186], [187, 189], [190, 191], [192, 200], [201, 209], [209, 210], [211, 214], [215, 223], [224, 230], [231, 238], [239, 246], [247, 254], [255, 258], [259, 267], [268, 280], [280, 281]]}
{"doc_key": "ai-dev-282", "ner": [[0, 1, "product"], [12, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 12, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Funkcja", "VoiceOver", "po", "raz", "pierwszy", "pojawi\u0142a", "si\u0119", "w", "2005", "roku", "w", "systemie", "Mac", "OS", "X", "Tiger", "(", "10.4", ")", "."], "sentence-detokenized": "Funkcja VoiceOver po raz pierwszy pojawi\u0142a si\u0119 w 2005 roku w systemie Mac OS X Tiger (10.4).", "token2charspan": [[0, 7], [8, 17], [18, 20], [21, 24], [25, 33], [34, 42], [43, 46], [47, 48], [49, 53], [54, 58], [59, 60], [61, 69], [70, 73], [74, 76], [77, 78], [79, 84], [85, 86], [86, 90], [90, 91], [91, 92]]}
{"doc_key": "ai-dev-283", "ner": [[13, 13, "algorithm"], [15, 16, "misc"], [21, 22, "metrics"], [24, 26, "algorithm"], [55, 57, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 13, 15, 16, "related-to", "applied_to", false, false], [21, 22, 15, 16, "type-of", "", false, false], [21, 22, 24, 26, "related-to", "used_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["W", "praktyce", "algorytmy", "uczenia", "maszynowego", "radz\u0105", "sobie", "z", "tym", "albo", "poprzez", "zastosowanie", "wypuk\u0142ego", "przybli\u017cenia", "do", "funkcji", "straty", "0", "-1", "(", "jak", "strata", "zawiasowa", "dla", "maszyny", "wektor\u00f3w", "wsparcia", ")", ",", "kt\u00f3ra", "jest", "\u0142atwiejsza", "do", "zoptymalizowania", ",", "albo", "poprzez", "narzucenie", "za\u0142o\u017ce\u0144", "dotycz\u0105cych", "dystrybucji", "mathP", "(", "x", ",", "y", ")", "/", "math", "(", "i", "tym", "samym", "przestaj\u0105", "by\u0107", "agnostycznymi", "algorytmami", "uczenia", ",", "do", "kt\u00f3rych", "stosuje", "si\u0119", "powy\u017cszy", "wynik", ")", "."], "sentence-detokenized": "W praktyce algorytmy uczenia maszynowego radz\u0105 sobie z tym albo poprzez zastosowanie wypuk\u0142ego przybli\u017cenia do funkcji straty 0-1 (jak strata zawiasowa dla maszyny wektor\u00f3w wsparcia), kt\u00f3ra jest \u0142atwiejsza do zoptymalizowania, albo poprzez narzucenie za\u0142o\u017ce\u0144 dotycz\u0105cych dystrybucji mathP (x, y) / math (i tym samym przestaj\u0105 by\u0107 agnostycznymi algorytmami uczenia, do kt\u00f3rych stosuje si\u0119 powy\u017cszy wynik).", "token2charspan": [[0, 1], [2, 10], [11, 20], [21, 28], [29, 40], [41, 46], [47, 52], [53, 54], [55, 58], [59, 63], [64, 71], [72, 84], [85, 94], [95, 107], [108, 110], [111, 118], [119, 125], [126, 127], [127, 129], [130, 131], [131, 134], [135, 141], [142, 151], [152, 155], [156, 163], [164, 172], [173, 181], [181, 182], [182, 183], [184, 189], [190, 194], [195, 205], [206, 208], [209, 225], [225, 226], [227, 231], [232, 239], [240, 250], [251, 258], [259, 270], [271, 282], [283, 288], [289, 290], [290, 291], [291, 292], [293, 294], [294, 295], [296, 297], [298, 302], [303, 304], [304, 305], [306, 309], [310, 315], [316, 325], [326, 329], [330, 343], [344, 355], [356, 363], [363, 364], [365, 367], [368, 375], [376, 383], [384, 387], [388, 396], [397, 402], [402, 403], [403, 404]]}
{"doc_key": "ai-dev-284", "ner": [[0, 0, "misc"], [12, 14, "field"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 12, 14, "usage", "", false, false], [0, 0, 22, 22, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Westworld", "(", "1973", ")", "by\u0142", "pierwszym", "filmem", "fabularnym", ",", "w", "kt\u00f3rym", "zastosowano", "cyfrowe", "przetwarzanie", "obrazu", "do", "fotografii", "w", "celu", "symulacji", "punktu", "widzenia", "androida", "."], "sentence-detokenized": "Westworld (1973) by\u0142 pierwszym filmem fabularnym, w kt\u00f3rym zastosowano cyfrowe przetwarzanie obrazu do fotografii w celu symulacji punktu widzenia androida.", "token2charspan": [[0, 9], [10, 11], [11, 15], [15, 16], [17, 20], [21, 30], [31, 37], [38, 48], [48, 49], [50, 51], [52, 58], [59, 70], [71, 78], [79, 92], [93, 99], [100, 102], [103, 113], [114, 115], [116, 120], [121, 130], [131, 137], [138, 146], [147, 155], [155, 156]]}
{"doc_key": "ai-dev-285", "ner": [[7, 8, "task"], [10, 11, "task"], [13, 13, "task"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Obecnie", "jest", "on", "r\u00f3wnie\u017c", "powszechnie", "stosowany", "w", "rozpoznawaniu", "mowy", ",", "syntezie", "mowy", ",", "diarystyce", ",", "Xavier", "Anguera", "et", "al", "."], "sentence-detokenized": "Obecnie jest on r\u00f3wnie\u017c powszechnie stosowany w rozpoznawaniu mowy, syntezie mowy, diarystyce, Xavier Anguera et al.", "token2charspan": [[0, 7], [8, 12], [13, 15], [16, 23], [24, 35], [36, 45], [46, 47], [48, 61], [62, 66], [66, 67], [68, 76], [77, 81], [81, 82], [83, 93], [93, 94], [95, 101], [102, 109], [110, 112], [113, 115], [115, 116]]}
{"doc_key": "ai-dev-286", "ner": [[5, 12, "algorithm"], [13, 13, "algorithm"], [15, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 13, 5, 12, "type-of", "", false, false], [15, 17, 5, 12, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Tutaj", "math", "/", "sigma", "jest", "funkcj\u0105", "aktywacji", "element-", "wise", ",", "tak\u0105", "jak", "funkcja", "sigmoidalna", "lub", "rektyfikowana", "jednostka", "liniowa", "."], "sentence-detokenized": "Tutaj math / sigma jest funkcj\u0105 aktywacji element-wise, tak\u0105 jak funkcja sigmoidalna lub rektyfikowana jednostka liniowa.", "token2charspan": [[0, 5], [6, 10], [11, 12], [13, 18], [19, 23], [24, 31], [32, 41], [42, 50], [50, 54], [54, 55], [56, 60], [61, 64], [65, 72], [73, 84], [85, 88], [89, 102], [103, 112], [113, 120], [120, 121]]}
{"doc_key": "ai-dev-287", "ner": [[12, 14, "algorithm"], [23, 23, "misc"], [25, 25, "misc"], [22, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Tradycyjne", "podej\u015bcia", "oparte", "na", "fonetyce", "(", "tj", ".", "wszystkie", "modele", "oparte", "na", "ukrytym", "modelu", "Markowa", ")", "wymaga\u0142y", "oddzielnych", "komponent\u00f3w", "i", "treningu", "dla", "modelu", "wymowy", ",", "akustycznego", "i", "j\u0119zykowego", "."], "sentence-detokenized": "Tradycyjne podej\u015bcia oparte na fonetyce (tj. wszystkie modele oparte na ukrytym modelu Markowa) wymaga\u0142y oddzielnych komponent\u00f3w i treningu dla modelu wymowy, akustycznego i j\u0119zykowego.", "token2charspan": [[0, 10], [11, 20], [21, 27], [28, 30], [31, 39], [40, 41], [41, 43], [43, 44], [45, 54], [55, 61], [62, 68], [69, 71], [72, 79], [80, 86], [87, 94], [94, 95], [96, 104], [105, 116], [117, 128], [129, 130], [131, 139], [140, 143], [144, 150], [151, 157], [157, 158], [159, 171], [172, 173], [174, 184], [184, 185]]}
{"doc_key": "ai-dev-288", "ner": [[0, 2, "algorithm"], [6, 7, "field"], [9, 10, "field"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 12, 13, "related-to", "used_for", false, false], [6, 7, 0, 2, "usage", "", false, false], [9, 10, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Operator", "krzy\u017cowy", "Robertsa", "jest", "stosowany", "w", "przetwarzaniu", "obraz\u00f3w", "i", "wizji", "komputerowej", "do", "wykrywania", "kraw\u0119dzi", "."], "sentence-detokenized": "Operator krzy\u017cowy Robertsa jest stosowany w przetwarzaniu obraz\u00f3w i wizji komputerowej do wykrywania kraw\u0119dzi.", "token2charspan": [[0, 8], [9, 17], [18, 26], [27, 31], [32, 41], [42, 43], [44, 57], [58, 65], [66, 67], [68, 73], [74, 86], [87, 89], [90, 100], [101, 109], [109, 110]]}
{"doc_key": "ai-dev-289", "ner": [[1, 1, "metrics"], [3, 3, "metrics"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 20, 20, "opposite", "", false, false], [3, 3, 20, 20, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Warto\u015bci", "czu\u0142o\u015bci", "i", "specyficzno\u015bci", "s\u0105", "agnostyczne", "wobec", "procentu", "pozytywnych", "przypadk\u00f3w", "w", "interesuj\u0105cej", "nas", "populacji", "(", "w", "przeciwie\u0144stwie", "do", "np", ".", "precyzji", ")", "."], "sentence-detokenized": "Warto\u015bci czu\u0142o\u015bci i specyficzno\u015bci s\u0105 agnostyczne wobec procentu pozytywnych przypadk\u00f3w w interesuj\u0105cej nas populacji (w przeciwie\u0144stwie do np. precyzji).", "token2charspan": [[0, 8], [9, 17], [18, 19], [20, 34], [35, 37], [38, 49], [50, 55], [56, 64], [65, 76], [77, 87], [88, 89], [90, 103], [104, 107], [108, 117], [118, 119], [119, 120], [121, 136], [137, 139], [140, 142], [142, 143], [144, 152], [152, 153], [153, 154]]}
{"doc_key": "ai-dev-290", "ner": [[1, 2, "algorithm"], [10, 10, "misc"], [12, 13, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 10, 1, 2, "topic", "", false, false], [10, 10, 12, 13, "artifact", "", false, false], [10, 10, 15, 16, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Jednak", "modele", "perceptronowe", "sta\u0142y", "si\u0119", "bardzo", "niepopularne", "za", "spraw\u0105", "ksi\u0105\u017cki", "Perceptrony", "autorstwa", "Marvina", "Minsky'ego", "i", "Seymoura", "Paperta", ",", "wydanej", "w", "1969", "roku", "."], "sentence-detokenized": "Jednak modele perceptronowe sta\u0142y si\u0119 bardzo niepopularne za spraw\u0105 ksi\u0105\u017cki Perceptrony autorstwa Marvina Minsky'ego i Seymoura Paperta, wydanej w 1969 roku.", "token2charspan": [[0, 6], [7, 13], [14, 27], [28, 33], [34, 37], [38, 44], [45, 57], [58, 60], [61, 67], [68, 75], [76, 87], [88, 97], [98, 105], [106, 116], [117, 118], [119, 127], [128, 135], [135, 136], [137, 144], [145, 146], [147, 151], [152, 156], [156, 157]]}
{"doc_key": "ai-dev-291", "ner": [[1, 3, "conference"], [8, 8, "organisation"], [17, 19, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 3, 17, 19, "topic", "", false, false], [8, 8, 1, 3, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Na", "konferencjach", "Document", "Understanding", ",", "prowadzonych", "corocznie", "przez", "NIST", ",", "opracowano", "zaawansowane", "kryteria", "oceny", "technik", "podejmuj\u0105cych", "wyzwanie", "podsumowania", "wielu", "dokument\u00f3w", "."], "sentence-detokenized": "Na konferencjach Document Understanding, prowadzonych corocznie przez NIST, opracowano zaawansowane kryteria oceny technik podejmuj\u0105cych wyzwanie podsumowania wielu dokument\u00f3w.", "token2charspan": [[0, 2], [3, 16], [17, 25], [26, 39], [39, 40], [41, 53], [54, 63], [64, 69], [70, 74], [74, 75], [76, 86], [87, 99], [100, 108], [109, 114], [115, 122], [123, 136], [137, 145], [146, 158], [159, 164], [165, 175], [175, 176]]}
{"doc_key": "ai-dev-292", "ner": [[1, 1, "product"], [28, 28, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 1, 28, 28, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Manipulator", "r\u00f3wnoleg\u0142y", "jest", "tak", "zaprojektowany", ",", "\u017ce", "ka\u017cdy", "\u0142a\u0144cuch", "jest", "zazwyczaj", "kr\u00f3tki", ",", "prosty", "i", "dzi\u0119ki", "temu", "mo\u017ce", "by\u0107", "sztywny", "przed", "niepo\u017c\u0105danym", "ruchem", ",", "w", "por\u00f3wnaniu", "do", "manipulatora", "szeregowego", "."], "sentence-detokenized": "Manipulator r\u00f3wnoleg\u0142y jest tak zaprojektowany, \u017ce ka\u017cdy \u0142a\u0144cuch jest zazwyczaj kr\u00f3tki, prosty i dzi\u0119ki temu mo\u017ce by\u0107 sztywny przed niepo\u017c\u0105danym ruchem, w por\u00f3wnaniu do manipulatora szeregowego.", "token2charspan": [[0, 11], [12, 22], [23, 27], [28, 31], [32, 46], [46, 47], [48, 50], [51, 56], [57, 64], [65, 69], [70, 79], [80, 86], [86, 87], [88, 94], [95, 96], [97, 103], [104, 108], [109, 113], [114, 117], [118, 125], [126, 131], [132, 144], [145, 151], [151, 152], [153, 154], [155, 165], [166, 168], [169, 181], [182, 193], [193, 194]]}
{"doc_key": "ai-dev-293", "ner": [[26, 26, "misc"], [28, 31, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Manipulator", "jest", "tym", ",", "co", "sprawia", ",", "\u017ce", "robot", "si\u0119", "porusza", ",", "a", "konstrukcja", "tych", "system\u00f3w", "mo\u017ce", "by\u0107", "skategoryzowana", "na", "kilka", "wsp\u00f3lnych", "typ\u00f3w", ",", "takich", "jak", "SCARA", "i", "robot", "o", "wsp\u00f3\u0142rz\u0119dnych", "kartezja\u0144skich", ",", "kt\u00f3re", "wykorzystuj\u0105", "r\u00f3\u017cne", "uk\u0142ady", "wsp\u00f3\u0142rz\u0119dnych", "do", "kierowania", "ramionami", "maszyny", "."], "sentence-detokenized": "Manipulator jest tym, co sprawia, \u017ce robot si\u0119 porusza, a konstrukcja tych system\u00f3w mo\u017ce by\u0107 skategoryzowana na kilka wsp\u00f3lnych typ\u00f3w, takich jak SCARA i robot o wsp\u00f3\u0142rz\u0119dnych kartezja\u0144skich, kt\u00f3re wykorzystuj\u0105 r\u00f3\u017cne uk\u0142ady wsp\u00f3\u0142rz\u0119dnych do kierowania ramionami maszyny.", "token2charspan": [[0, 11], [12, 16], [17, 20], [20, 21], [22, 24], [25, 32], [32, 33], [34, 36], [37, 42], [43, 46], [47, 54], [54, 55], [56, 57], [58, 69], [70, 74], [75, 83], [84, 88], [89, 92], [93, 108], [109, 111], [112, 117], [118, 127], [128, 133], [133, 134], [135, 141], [142, 145], [146, 151], [152, 153], [154, 159], [160, 161], [162, 175], [176, 190], [190, 191], [192, 197], [198, 210], [211, 216], [217, 223], [224, 237], [238, 240], [241, 251], [252, 261], [262, 269], [269, 270]]}
{"doc_key": "ai-dev-294", "ner": [[1, 2, "country"], [5, 8, "organisation"], [10, 15, "organisation"], [17, 20, "organisation"], [23, 24, "organisation"], [28, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 8, 1, 2, "physical", "", false, false], [10, 15, 1, 2, "physical", "", false, false], [17, 20, 1, 2, "physical", "", false, false], [23, 24, 1, 2, "physical", "", false, false], [28, 32, 1, 2, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["W", "Stanach", "Zjednoczonych", "jest", "cz\u0142onkiem", "National", "Academy", "of", "Sciences", ",", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "Linguistic", "Society", "of", "America", ",", "American", "Philosophical", "Association", "oraz", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "W Stanach Zjednoczonych jest cz\u0142onkiem National Academy of Sciences, American Academy of Arts and Sciences, Linguistic Society of America, American Philosophical Association oraz American Association for the Advancement of Science.", "token2charspan": [[0, 1], [2, 9], [10, 23], [24, 28], [29, 38], [39, 47], [48, 55], [56, 58], [59, 67], [67, 68], [69, 77], [78, 85], [86, 88], [89, 93], [94, 97], [98, 106], [106, 107], [108, 118], [119, 126], [127, 129], [130, 137], [137, 138], [139, 147], [148, 161], [162, 173], [174, 178], [179, 187], [188, 199], [200, 203], [204, 207], [208, 219], [220, 222], [223, 230], [230, 231]]}
{"doc_key": "ai-dev-295", "ner": [[6, 8, "algorithm"], [10, 10, "algorithm"], [22, 23, "algorithm"], [26, 27, "algorithm"], [32, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 8, 22, 23, "named", "", false, false], [10, 10, 6, 8, "named", "", false, false], [22, 23, 26, 27, "compare", "", false, false], [22, 23, 32, 34, "related-to", "performs", false, false], [26, 27, 32, 34, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Ich", "popularno\u015b\u0107", "wzros\u0142a", "wraz", "z", "popularno\u015bci\u0105", "maszyny", "wektorowej", "wsparcia", "(", "SVM", ")", "w", "latach", "90-tych", ",", "kiedy", "to", "okaza\u0142o", "si\u0119", ",", "\u017ce", "SVM", "jest", "konkurencyjna", "wobec", "sieci", "neuronowych", "w", "zadaniach", "takich", "jak", "rozpoznawanie", "pisma", "r\u0119cznego", "."], "sentence-detokenized": "Ich popularno\u015b\u0107 wzros\u0142a wraz z popularno\u015bci\u0105 maszyny wektorowej wsparcia (SVM) w latach 90-tych, kiedy to okaza\u0142o si\u0119, \u017ce SVM jest konkurencyjna wobec sieci neuronowych w zadaniach takich jak rozpoznawanie pisma r\u0119cznego.", "token2charspan": [[0, 3], [4, 15], [16, 23], [24, 28], [29, 30], [31, 44], [45, 52], [53, 63], [64, 72], [73, 74], [74, 77], [77, 78], [79, 80], [81, 87], [88, 95], [95, 96], [97, 102], [103, 105], [106, 113], [114, 117], [117, 118], [119, 121], [122, 125], [126, 130], [131, 144], [145, 150], [151, 156], [157, 168], [169, 170], [171, 180], [181, 187], [188, 191], [192, 205], [206, 211], [212, 220], [220, 221]]}
{"doc_key": "ai-dev-296", "ner": [[1, 2, "misc"], [7, 7, "misc"], [12, 13, "algorithm"], [21, 22, "misc"], [27, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 7, 7, "usage", "", false, false], [1, 2, 21, 22, "usage", "", false, false], [7, 7, 12, 13, "origin", "result_of_algorithm", false, false], [21, 22, 27, 28, "origin", "result_of_algorithm", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Empiryczn\u0105", "transformat\u0119", "wybielaj\u0105c\u0105", "uzyskuje", "si\u0119", "poprzez", "oszacowanie", "kowariancji", "(", "np", ".", "metod\u0105", "najwi\u0119kszego", "prawdopodobie\u0144stwa", ")", ",", "a", "nast\u0119pnie", "skonstruowanie", "odpowiedniej", "szacunkowej", "macierzy", "wybielaj\u0105cej", "(", "np", ".", "metod\u0105", "rozk\u0142adu", "Cholesky'ego", ")", "."], "sentence-detokenized": "Empiryczn\u0105 transformat\u0119 wybielaj\u0105c\u0105 uzyskuje si\u0119 poprzez oszacowanie kowariancji (np. metod\u0105 najwi\u0119kszego prawdopodobie\u0144stwa), a nast\u0119pnie skonstruowanie odpowiedniej szacunkowej macierzy wybielaj\u0105cej (np. metod\u0105 rozk\u0142adu Cholesky'ego).", "token2charspan": [[0, 10], [11, 23], [24, 35], [36, 44], [45, 48], [49, 56], [57, 68], [69, 80], [81, 82], [82, 84], [84, 85], [86, 92], [93, 105], [106, 124], [124, 125], [125, 126], [127, 128], [129, 138], [139, 153], [154, 166], [167, 178], [179, 187], [188, 200], [201, 202], [202, 204], [204, 205], [206, 212], [213, 221], [222, 234], [234, 235], [235, 236]]}
{"doc_key": "ai-dev-297", "ner": [[0, 0, "organisation"], [6, 9, "product"], [19, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 9, 0, 0, "artifact", "", false, false], [19, 19, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["IAI", "jest", "najwi\u0119kszym", "na", "\u015bwiecie", "producentem", "robot\u00f3w", "o", "wsp\u00f3\u0142rz\u0119dnych", "kartezja\u0144skich", "i", "uznanym", "liderem", "w", "dziedzinie", "tanich", ",", "wysokowydajnych", "robot\u00f3w", "SCARA", "."], "sentence-detokenized": "IAI jest najwi\u0119kszym na \u015bwiecie producentem robot\u00f3w o wsp\u00f3\u0142rz\u0119dnych kartezja\u0144skich i uznanym liderem w dziedzinie tanich, wysokowydajnych robot\u00f3w SCARA.", "token2charspan": [[0, 3], [4, 8], [9, 20], [21, 23], [24, 31], [32, 43], [44, 51], [52, 53], [54, 67], [68, 82], [83, 84], [85, 92], [93, 100], [101, 102], [103, 113], [114, 120], [120, 121], [122, 137], [138, 145], [146, 151], [151, 152]]}
{"doc_key": "ai-dev-298", "ner": [[11, 11, "field"], [14, 14, "field"], [16, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 28, "field"], [30, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [], "relations_mapping_to_source": [], "sentence": ["Formalna", "analiza", "poj\u0119\u0107", "znajduje", "praktyczne", "zastosowanie", "w", "takich", "dziedzinach", "jak", "eksploracja", "danych", ",", "eksploracja", "tekstu", ",", "uczenie", "maszynowe", ",", "zarz\u0105dzanie", "wiedz\u0105", ",", "sie\u0107", "semantyczna", ",", "tworzenie", "oprogramowania", ",", "chemia", "i", "biologia", "."], "sentence-detokenized": "Formalna analiza poj\u0119\u0107 znajduje praktyczne zastosowanie w takich dziedzinach jak eksploracja danych, eksploracja tekstu, uczenie maszynowe, zarz\u0105dzanie wiedz\u0105, sie\u0107 semantyczna, tworzenie oprogramowania, chemia i biologia.", "token2charspan": [[0, 8], [9, 16], [17, 22], [23, 31], [32, 42], [43, 55], [56, 57], [58, 64], [65, 76], [77, 80], [81, 92], [93, 99], [99, 100], [101, 112], [113, 119], [119, 120], [121, 128], [129, 138], [138, 139], [140, 151], [152, 158], [158, 159], [160, 164], [165, 176], [176, 177], [178, 187], [188, 202], [202, 203], [204, 210], [211, 212], [213, 221], [221, 222]]}
{"doc_key": "ai-dev-299", "ner": [[1, 1, "field"], [3, 6, "field"], [11, 13, "field"], [17, 18, "field"], [26, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 6, 17, 18, "part-of", "", false, false], [3, 6, 26, 26, "topic", "", false, false], [11, 13, 3, 6, "named", "", false, false], [17, 18, 1, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["W", "informatyce", ",", "obliczeniowa", "teoria", "uczenia", "si\u0119", "(", "lub", "po", "prostu", "teoria", "uczenia", "si\u0119", ")", "jest", "subdomen\u0105", "sztucznej", "inteligencji", "po\u015bwi\u0119con\u0105", "badaniu", "projektowania", "i", "analizy", "algorytm\u00f3w", "uczenia", "maszynowego", "."], "sentence-detokenized": "W informatyce, obliczeniowa teoria uczenia si\u0119 (lub po prostu teoria uczenia si\u0119) jest subdomen\u0105 sztucznej inteligencji po\u015bwi\u0119con\u0105 badaniu projektowania i analizy algorytm\u00f3w uczenia maszynowego.", "token2charspan": [[0, 1], [2, 13], [13, 14], [15, 27], [28, 34], [35, 42], [43, 46], [47, 48], [48, 51], [52, 54], [55, 61], [62, 68], [69, 76], [77, 80], [80, 81], [82, 86], [87, 96], [97, 106], [107, 119], [120, 130], [131, 138], [139, 152], [153, 154], [155, 162], [163, 173], [174, 181], [182, 193], [193, 194]]}
{"doc_key": "ai-dev-300", "ner": [[0, 1, "algorithm"], [3, 3, "algorithm"], [9, 10, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 0, 1, "named", "", false, false], [9, 10, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Collaborative", "filtering", "(", "CF", ")", "to", "technika", "wykorzystywana", "przez", "systemy", "rekomendacyjne", "."], "sentence-detokenized": "Collaborative filtering (CF) to technika wykorzystywana przez systemy rekomendacyjne.", "token2charspan": [[0, 13], [14, 23], [24, 25], [25, 27], [27, 28], [29, 31], [32, 40], [41, 55], [56, 61], [62, 69], [70, 84], [84, 85]]}
{"doc_key": "ai-dev-301", "ner": [[0, 2, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Wska\u017anik", "FALSE", "pozytywny", "jest", "proporcj\u0105", "wszystkich", "negatywnych", "wynik\u00f3w", ",", "kt\u00f3re", "nadal", "daj\u0105", "pozytywne", "wyniki", "bada\u0144", ",", "tj", ".", "warunkowe", "prawdopodobie\u0144stwo", "pozytywnego", "wyniku", "badania", "przy", "zdarzeniu", ",", "kt\u00f3re", "nie", "mia\u0142o", "miejsca", "."], "sentence-detokenized": "Wska\u017anik FALSE pozytywny jest proporcj\u0105 wszystkich negatywnych wynik\u00f3w, kt\u00f3re nadal daj\u0105 pozytywne wyniki bada\u0144, tj. warunkowe prawdopodobie\u0144stwo pozytywnego wyniku badania przy zdarzeniu, kt\u00f3re nie mia\u0142o miejsca.", "token2charspan": [[0, 8], [9, 14], [15, 24], [25, 29], [30, 39], [40, 50], [51, 62], [63, 70], [70, 71], [72, 77], [78, 83], [84, 88], [89, 98], [99, 105], [106, 111], [111, 112], [113, 115], [115, 116], [117, 126], [127, 145], [146, 157], [158, 164], [165, 172], [173, 177], [178, 187], [187, 188], [189, 194], [195, 198], [199, 204], [205, 212], [212, 213]]}
{"doc_key": "ai-dev-302", "ner": [[1, 14, "misc"], [37, 37, "metrics"], [41, 41, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 14, 37, 37, "topic", "", false, false], [1, 14, 41, 41, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "VLDB", "'8", ":", "Proceedings", "of", "the", "34th", "International", "Conference", "on", "Very", "Large", "Data", "Bases", ",", "pages", "422--", "433", ".", "wykaza\u0142", ",", "\u017ce", "podane", "warto\u015bci", "dla", "mathC", "/", "math", "i", "mathK", "/", "math", "generalnie", "implikuj\u0105", "stosunkowo", "nisk\u0105", "dok\u0142adno\u015b\u0107", "iteracyjnie", "obliczonych", "wynik\u00f3w", "SimRank", "."], "sentence-detokenized": "In VLDB '8: Proceedings of the 34th International Conference on Very Large Data Bases, pages 422--433. wykaza\u0142, \u017ce podane warto\u015bci dla mathC / math i mathK / math generalnie implikuj\u0105 stosunkowo nisk\u0105 dok\u0142adno\u015b\u0107 iteracyjnie obliczonych wynik\u00f3w SimRank.", "token2charspan": [[0, 2], [3, 7], [8, 10], [10, 11], [12, 23], [24, 26], [27, 30], [31, 35], [36, 49], [50, 60], [61, 63], [64, 68], [69, 74], [75, 79], [80, 85], [85, 86], [87, 92], [93, 98], [98, 101], [101, 102], [103, 110], [110, 111], [112, 114], [115, 121], [122, 130], [131, 134], [135, 140], [141, 142], [143, 147], [148, 149], [150, 155], [156, 157], [158, 162], [163, 173], [174, 183], [184, 194], [195, 200], [201, 211], [212, 223], [224, 235], [236, 243], [244, 251], [251, 252]]}
{"doc_key": "ai-dev-303", "ner": [[5, 7, "misc"], [8, 8, "misc"], [0, 17, "person"], [19, 22, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 5, 7, "general-affiliation", "", false, false], [8, 8, 0, 17, "artifact", "", false, false], [8, 8, 19, 22, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["W", "czerwcu", "2015", "roku", "zadebiutowa\u0142", "dramat", "science", "fiction", "Sense8", ",", "kt\u00f3ry", "zosta\u0142", "napisany", "i", "wyprodukowany", "przez", "The", "Wachowskis", "i", "J", ".", "Michaela", "Straczynskiego", "."], "sentence-detokenized": "W czerwcu 2015 roku zadebiutowa\u0142 dramat science fiction Sense8, kt\u00f3ry zosta\u0142 napisany i wyprodukowany przez The Wachowskis i J. Michaela Straczynskiego.", "token2charspan": [[0, 1], [2, 9], [10, 14], [15, 19], [20, 32], [33, 39], [40, 47], [48, 55], [56, 62], [62, 63], [64, 69], [70, 76], [77, 85], [86, 87], [88, 101], [102, 107], [108, 111], [112, 122], [123, 124], [125, 126], [126, 127], [128, 136], [137, 151], [151, 152]]}
{"doc_key": "ai-dev-304", "ner": [[1, 1, "misc"], [6, 7, "product"], [22, 26, "misc"], [33, 33, "country"], [35, 35, "country"], [37, 37, "country"], [39, 39, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 1, 6, 7, "topic", "", false, false], [33, 33, 22, 26, "type-of", "", false, false], [35, 35, 22, 26, "type-of", "", false, false], [37, 37, 22, 26, "type-of", "", false, false], [39, 39, 22, 26, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Chocia\u017c", "Eurotra", "nigdy", "nie", "dostarczy\u0142a", "dzia\u0142aj\u0105cego", "systemu", "MT", ",", "projekt", "wywar\u0142", "daleko", "id\u0105cy", ",", "d\u0142ugoterminowy", "wp\u0142yw", "na", "rodz\u0105ce", "si\u0119", "bran\u017ce", "j\u0119zykowe", "w", "europejskich", "pa\u0144stwach", "cz\u0142onkowskich", ",", "w", "szczeg\u00f3lno\u015bci", "w", "po\u0142udniowych", "krajach", "takich", "jak", "Grecja", ",", "W\u0142ochy", ",", "Hiszpania", "i", "Portugalia", "."], "sentence-detokenized": "Chocia\u017c Eurotra nigdy nie dostarczy\u0142a dzia\u0142aj\u0105cego systemu MT, projekt wywar\u0142 daleko id\u0105cy, d\u0142ugoterminowy wp\u0142yw na rodz\u0105ce si\u0119 bran\u017ce j\u0119zykowe w europejskich pa\u0144stwach cz\u0142onkowskich, w szczeg\u00f3lno\u015bci w po\u0142udniowych krajach takich jak Grecja, W\u0142ochy, Hiszpania i Portugalia.", "token2charspan": [[0, 7], [8, 15], [16, 21], [22, 25], [26, 37], [38, 50], [51, 58], [59, 61], [61, 62], [63, 70], [71, 77], [78, 84], [85, 90], [90, 91], [92, 106], [107, 112], [113, 115], [116, 123], [124, 127], [128, 134], [135, 143], [144, 145], [146, 158], [159, 168], [169, 182], [182, 183], [184, 185], [186, 199], [200, 201], [202, 214], [215, 222], [223, 229], [230, 233], [234, 240], [240, 241], [242, 248], [248, 249], [250, 259], [260, 261], [262, 272], [272, 273]]}
{"doc_key": "ai-dev-305", "ner": [[0, 2, "algorithm"], [6, 7, "task"], [16, 18, "task"], [20, 20, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 7, 0, 2, "usage", "", true, false], [16, 18, 6, 7, "named", "", false, false], [20, 20, 16, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Autoenkoder", "zosta\u0142", "z", "powodzeniem", "zastosowany", "do", "maszynowego", "t\u0142umaczenia", "j\u0119zyk\u00f3w", "ludzkich", ",", "kt\u00f3re", "zwykle", "okre\u015bla", "si\u0119", "mianem", "neuronowego", "t\u0142umaczenia", "maszynowego", "(", "NMT", ")", "."], "sentence-detokenized": "Autoenkoder zosta\u0142 z powodzeniem zastosowany do maszynowego t\u0142umaczenia j\u0119zyk\u00f3w ludzkich, kt\u00f3re zwykle okre\u015bla si\u0119 mianem neuronowego t\u0142umaczenia maszynowego (NMT).", "token2charspan": [[0, 11], [12, 18], [19, 20], [21, 32], [33, 44], [45, 47], [48, 59], [60, 71], [72, 79], [80, 88], [88, 89], [90, 95], [96, 102], [103, 110], [111, 114], [115, 121], [122, 133], [134, 145], [146, 157], [158, 159], [159, 162], [162, 163], [163, 164]]}
{"doc_key": "ai-dev-306", "ner": [[8, 10, "metrics"], [12, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Popularne", "przyk\u0142ady", "funkcji", "fitness", "opartych", "na", "prawdopodobie\u0144stwach", "obejmuj\u0105", "estymacj\u0119", "maksymalnego", "prawdopodobie\u0144stwa", "i", "strat\u0119", "zawiasow\u0105", "."], "sentence-detokenized": "Popularne przyk\u0142ady funkcji fitness opartych na prawdopodobie\u0144stwach obejmuj\u0105 estymacj\u0119 maksymalnego prawdopodobie\u0144stwa i strat\u0119 zawiasow\u0105.", "token2charspan": [[0, 9], [10, 19], [20, 27], [28, 35], [36, 44], [45, 47], [48, 68], [69, 77], [78, 87], [88, 100], [101, 119], [120, 121], [122, 128], [129, 138], [138, 139]]}
{"doc_key": "ai-dev-307", "ner": [[1, 1, "field"], [0, 12, "task"], [14, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 12, 1, 1, "part-of", "", false, false], [14, 16, 1, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Eksploracja", "danych", "jest", "pokrewn\u0105", "dziedzin\u0105", "nauki", ",", "skupiaj\u0105c\u0105", "si\u0119", "na", "eksploracyjnej", "analizie", "danych", "poprzez", "uczenie", "bez", "nadzoru", "."], "sentence-detokenized": "Eksploracja danych jest pokrewn\u0105 dziedzin\u0105 nauki, skupiaj\u0105c\u0105 si\u0119 na eksploracyjnej analizie danych poprzez uczenie bez nadzoru.", "token2charspan": [[0, 11], [12, 18], [19, 23], [24, 32], [33, 42], [43, 48], [48, 49], [50, 60], [61, 64], [65, 67], [68, 82], [83, 91], [92, 98], [99, 106], [107, 114], [115, 118], [119, 126], [126, 127]]}
{"doc_key": "ai-dev-308", "ner": [[0, 1, "algorithm"], [14, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 14, 15, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Collaborative", "filtering", "obejmuje", "techniki", "kojarzenia", "os\u00f3b", "o", "podobnych", "zainteresowaniach", "i", "tworzenia", "na", "tej", "podstawie", "systemu", "rekomendacji", "."], "sentence-detokenized": "Collaborative filtering obejmuje techniki kojarzenia os\u00f3b o podobnych zainteresowaniach i tworzenia na tej podstawie systemu rekomendacji.", "token2charspan": [[0, 13], [14, 23], [24, 32], [33, 41], [42, 52], [53, 57], [58, 59], [60, 69], [70, 87], [88, 89], [90, 99], [100, 102], [103, 106], [107, 116], [117, 124], [125, 137], [137, 138]]}
{"doc_key": "ai-dev-309", "ner": [[1, 6, "algorithm"], [10, 11, "programlang"], [13, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 16, 1, 6, "type-of", "", false, false], [13, 16, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Szereg", "algorytm\u00f3w", "podobie\u0144stwa", "s\u0142\u00f3w", "opartych", "na", "WordNecie", "zaimplementowano", "w", "pakiecie", "Perla", "o", "nazwie", "WordNet", ":", ":", "Similarity", "."], "sentence-detokenized": "Szereg algorytm\u00f3w podobie\u0144stwa s\u0142\u00f3w opartych na WordNecie zaimplementowano w pakiecie Perla o nazwie WordNet:: Similarity.", "token2charspan": [[0, 6], [7, 17], [18, 30], [31, 35], [36, 44], [45, 47], [48, 57], [58, 74], [75, 76], [77, 85], [86, 91], [92, 93], [94, 100], [101, 108], [108, 109], [109, 110], [111, 121], [121, 122]]}
{"doc_key": "ai-dev-310", "ner": [[8, 8, "conference"], [10, 10, "conference"], [14, 15, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 10, 8, 8, "named", "", false, false], [14, 15, 8, 8, "temporal", "", false, false], [17, 18, 8, 8, "temporal", "", false, false], [20, 21, 8, 8, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Om\u00f3wiona", "zostanie", "r\u00f3wnie\u017c", "inna", "praca", ",", "zaprezentowana", "na", "CVPR", "(", "CVPR", ")", "2000", "przez", "Erika", "Millera", ",", "Nicholasa", "Matsakisa", "i", "Paula", "Viola", "."], "sentence-detokenized": "Om\u00f3wiona zostanie r\u00f3wnie\u017c inna praca, zaprezentowana na CVPR (CVPR) 2000 przez Erika Millera, Nicholasa Matsakisa i Paula Viola.", "token2charspan": [[0, 8], [9, 17], [18, 25], [26, 30], [31, 36], [36, 37], [38, 52], [53, 55], [56, 60], [61, 62], [62, 66], [66, 67], [68, 72], [73, 78], [79, 84], [85, 92], [92, 93], [94, 103], [104, 113], [114, 115], [116, 121], [122, 127], [127, 128]]}
{"doc_key": "ai-dev-311", "ner": [[0, 0, "algorithm"], [10, 11, "misc"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 14, 15, "compare", "", false, false], [14, 15, 10, 11, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["QC", "nie", "by\u0142", "oceniany", "w", "stosunku", "do", "tradycyjnych", ",", "nowoczesnych", "algorytm\u00f3w", "klastrowania", ",", "poza", "indeksem", "Jaccarda", "."], "sentence-detokenized": "QC nie by\u0142 oceniany w stosunku do tradycyjnych, nowoczesnych algorytm\u00f3w klastrowania, poza indeksem Jaccarda.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 19], [20, 21], [22, 30], [31, 33], [34, 46], [46, 47], [48, 60], [61, 71], [72, 84], [84, 85], [86, 90], [91, 99], [100, 108], [108, 109]]}
{"doc_key": "ai-dev-312", "ner": [[1, 4, "misc"], [10, 11, "misc"], [6, 8, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 1, 4, "physical", "", false, false], [10, 11, 6, 8, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Podczas", "VEX", "Robotics", "World", "Championship", "w", "Freedom", "Hall", "odbywa", "si\u0119", "Parada", "Narod\u00f3w", ",", "w", "kt\u00f3rej", "bior\u0105", "udzia\u0142", "setki", "student\u00f3w", "z", "ponad", "30", "kraj\u00f3w", "."], "sentence-detokenized": "Podczas VEX Robotics World Championship w Freedom Hall odbywa si\u0119 Parada Narod\u00f3w, w kt\u00f3rej bior\u0105 udzia\u0142 setki student\u00f3w z ponad 30 kraj\u00f3w.", "token2charspan": [[0, 7], [8, 11], [12, 20], [21, 26], [27, 39], [40, 41], [42, 49], [50, 54], [55, 61], [62, 65], [66, 72], [73, 80], [80, 81], [82, 83], [84, 90], [91, 96], [97, 103], [104, 109], [110, 119], [120, 121], [122, 127], [128, 130], [131, 137], [137, 138]]}
{"doc_key": "ai-dev-313", "ner": [[4, 7, "metrics"], [9, 9, "metrics"], [12, 14, "metrics"], [16, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 4, 7, "named", "", false, false], [16, 16, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Inne", "miary", "dok\u0142adno\u015bci", "to", "Single", "Word", "Error", "Rate", "(", "SWER", ")", "i", "Command", "Success", "Rate", "(", "CSR", ")", "."], "sentence-detokenized": "Inne miary dok\u0142adno\u015bci to Single Word Error Rate (SWER) i Command Success Rate (CSR).", "token2charspan": [[0, 4], [5, 10], [11, 22], [23, 25], [26, 32], [33, 37], [38, 43], [44, 48], [49, 50], [50, 54], [54, 55], [56, 57], [58, 65], [66, 73], [74, 78], [79, 80], [80, 83], [83, 84], [84, 85]]}
{"doc_key": "ai-dev-314", "ner": [[6, 7, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Swoj\u0105", "metod\u0119", "i", "wyniki", "zaprezentowali", "w", "SIGGRAPH", "2000", "."], "sentence-detokenized": "Swoj\u0105 metod\u0119 i wyniki zaprezentowali w SIGGRAPH 2000.", "token2charspan": [[0, 5], [6, 12], [13, 14], [15, 21], [22, 36], [37, 38], [39, 47], [48, 52], [52, 53]]}
{"doc_key": "ai-dev-315", "ner": [[0, 1, "conference"], [5, 5, "misc"], [7, 11, "misc"], [14, 15, "conference"], [21, 26, "researcher"], [35, 37, "researcher"], [41, 43, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 5, 5, "origin", "", false, false], [5, 5, 14, 15, "physical", "", false, false], [5, 5, 14, 15, "temporal", "", false, false], [5, 5, 21, 26, "origin", "", false, false], [5, 5, 35, 37, "origin", "", false, false], [7, 11, 5, 5, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Konferencja", "KDD", "wyros\u0142a", "z", "warsztat\u00f3w", "KDD", "(", "Knowledge", "Discovery", "and", "Data", "Mining", ")", "na", "konferencjach", "AAAI", ",", "kt\u00f3re", "zosta\u0142y", "zapocz\u0105tkowane", "przez", "Gregory'ego", "I", ".", "Piatetsky", "-", "Shapiro", "w", "1989", ",", "1991", "i", "1993", "roku", "oraz", "Usam\u0119", "Fayyada", "w", "1994", "roku", ".", "Machinery", "|", "ACM", "."], "sentence-detokenized": "Konferencja KDD wyros\u0142a z warsztat\u00f3w KDD (Knowledge Discovery and Data Mining) na konferencjach AAAI, kt\u00f3re zosta\u0142y zapocz\u0105tkowane przez Gregory'ego I. Piatetsky-Shapiro w 1989, 1991 i 1993 roku oraz Usam\u0119 Fayyada w 1994 roku. Machinery | ACM.", "token2charspan": [[0, 11], [12, 15], [16, 23], [24, 25], [26, 36], [37, 40], [41, 42], [42, 51], [52, 61], [62, 65], [66, 70], [71, 77], [77, 78], [79, 81], [82, 95], [96, 100], [100, 101], [102, 107], [108, 115], [116, 130], [131, 136], [137, 148], [149, 150], [150, 151], [152, 161], [161, 162], [162, 169], [170, 171], [172, 176], [176, 177], [178, 182], [183, 184], [185, 189], [190, 194], [195, 199], [200, 205], [206, 213], [214, 215], [216, 220], [221, 225], [225, 226], [227, 236], [237, 238], [239, 242], [242, 243]]}
{"doc_key": "ai-dev-316", "ner": [[4, 7, "conference"], [9, 9, "conference"], [12, 17, "organisation"], [19, 19, "organisation"], [22, 26, "conference"], [28, 28, "conference"], [34, 37, "conference"], [39, 39, "conference"], [42, 47, "conference"], [49, 49, "conference"], [52, 57, "conference"], [59, 59, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[9, 9, 4, 7, "named", "", false, false], [19, 19, 12, 17, "named", "", false, false], [28, 28, 22, 26, "named", "", false, false], [39, 39, 34, 37, "named", "", false, false], [49, 49, 42, 47, "named", "", false, false], [59, 59, 52, 57, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Zosta\u0142", "wybrany", "na", "cz\u0142onka", "Association", "for", "Computing", "Machinery", "(", "ACM", ")", ",", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", ",", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", ",", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", ",", "American", "Association", "for", "Advancement", "of", "Science", "(", "AAAS", ")", "oraz", "Society", "for", "Optics", "and", "Photonics", "Technology", "(", "SPIE", ")", "."], "sentence-detokenized": "Zosta\u0142 wybrany na cz\u0142onka Association for Computing Machinery (ACM), Institute of Electrical and Electronics Engineers (IEEE), International Association for Pattern Recognition (IAPR), Association for the Advancement of Artificial Intelligence (AAAI), American Association for Advancement of Science (AAAS) oraz Society for Optics and Photonics Technology (SPIE).", "token2charspan": [[0, 6], [7, 14], [15, 17], [18, 25], [26, 37], [38, 41], [42, 51], [52, 61], [62, 63], [63, 66], [66, 67], [67, 68], [69, 78], [79, 81], [82, 92], [93, 96], [97, 108], [109, 118], [119, 120], [120, 124], [124, 125], [125, 126], [127, 140], [141, 152], [153, 156], [157, 164], [165, 176], [177, 178], [178, 182], [182, 183], [183, 184], [185, 196], [197, 200], [201, 204], [205, 216], [217, 219], [220, 230], [231, 243], [244, 245], [245, 249], [249, 250], [250, 251], [252, 260], [261, 272], [273, 276], [277, 288], [289, 291], [292, 299], [300, 301], [301, 305], [305, 306], [307, 311], [312, 319], [320, 323], [324, 330], [331, 334], [335, 344], [345, 355], [356, 357], [357, 361], [361, 362], [362, 363]]}
{"doc_key": "ai-dev-317", "ner": [[0, 1, "field"], [3, 4, "field"], [18, 19, "field"], [34, 35, "field"], [52, 56, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 18, 19, "named", "", false, false], [3, 4, 34, 35, "named", "", false, false], [34, 35, 52, 56, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Uczenie", "maszynowe", "i", "eksploracja", "danych", "cz\u0119sto", "wykorzystuj\u0105", "te", "same", "metody", "i", "znacz\u0105co", "si\u0119", "pokrywaj\u0105", ",", "ale", "podczas", "gdy", "uczenie", "maszynowe", "skupia", "si\u0119", "na", "przewidywaniu", ",", "na", "podstawie", "znanych", "w\u0142a\u015bciwo\u015bci", "wyuczonych", "z", "danych", "treningowych", ",", "eksploracja", "danych", "skupia", "si\u0119", "na", "odkrywaniu", "(", "wcze\u015bniej", ")", "nieznanych", "w\u0142a\u015bciwo\u015bci", "w", "danych", "(", "jest", "to", "etap", "analizy", "odkrywania", "wiedzy", "w", "bazach", "danych", ")", "."], "sentence-detokenized": "Uczenie maszynowe i eksploracja danych cz\u0119sto wykorzystuj\u0105 te same metody i znacz\u0105co si\u0119 pokrywaj\u0105, ale podczas gdy uczenie maszynowe skupia si\u0119 na przewidywaniu, na podstawie znanych w\u0142a\u015bciwo\u015bci wyuczonych z danych treningowych, eksploracja danych skupia si\u0119 na odkrywaniu (wcze\u015bniej) nieznanych w\u0142a\u015bciwo\u015bci w danych (jest to etap analizy odkrywania wiedzy w bazach danych).", "token2charspan": [[0, 7], [8, 17], [18, 19], [20, 31], [32, 38], [39, 45], [46, 58], [59, 61], [62, 66], [67, 73], [74, 75], [76, 84], [85, 88], [89, 98], [98, 99], [100, 103], [104, 111], [112, 115], [116, 123], [124, 133], [134, 140], [141, 144], [145, 147], [148, 161], [161, 162], [163, 165], [166, 175], [176, 183], [184, 195], [196, 206], [207, 208], [209, 215], [216, 228], [228, 229], [230, 241], [242, 248], [249, 255], [256, 259], [260, 262], [263, 273], [274, 275], [275, 284], [284, 285], [286, 296], [297, 308], [309, 310], [311, 317], [318, 319], [319, 323], [324, 326], [327, 331], [332, 339], [340, 350], [351, 357], [358, 359], [360, 366], [367, 373], [373, 374], [374, 375]]}
{"doc_key": "ai-dev-318", "ner": [[0, 0, "product"], [5, 5, "programlang"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 5, 5, "general-affiliation", "", false, false], [0, 0, 5, 5, "related-to", "runs_on", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Indy", "jest", "napisany", "w", "j\u0119zyku", "Java", "i", "dlatego", "dzia\u0142a", "na", "wi\u0119kszo\u015bci", "nowoczesnych", "system\u00f3w", "operacyjnych", "."], "sentence-detokenized": "Indy jest napisany w j\u0119zyku Java i dlatego dzia\u0142a na wi\u0119kszo\u015bci nowoczesnych system\u00f3w operacyjnych.", "token2charspan": [[0, 4], [5, 9], [10, 18], [19, 20], [21, 27], [28, 32], [33, 34], [35, 42], [43, 49], [50, 52], [53, 63], [64, 76], [77, 85], [86, 98], [98, 99]]}
{"doc_key": "ai-dev-319", "ner": [[0, 0, "algorithm"], [3, 5, "algorithm"], [7, 7, "algorithm"], [12, 14, "algorithm"], [16, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 5, "type-of", "", true, false], [7, 7, 3, 5, "named", "", false, false], [12, 14, 3, 5, "type-of", "", true, false], [16, 16, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["NMF", "jest", "instancj\u0105", "nieujemnego", "programowania", "kwadratowego", "(", "NQP", ")", ",", "podobnie", "jak", "maszyna", "wektor\u00f3w", "wsparcia", "(", "SVM", ")", "."], "sentence-detokenized": "NMF jest instancj\u0105 nieujemnego programowania kwadratowego (NQP), podobnie jak maszyna wektor\u00f3w wsparcia (SVM).", "token2charspan": [[0, 3], [4, 8], [9, 18], [19, 30], [31, 44], [45, 57], [58, 59], [59, 62], [62, 63], [63, 64], [65, 73], [74, 77], [78, 85], [86, 94], [95, 103], [104, 105], [105, 108], [108, 109], [109, 110]]}
{"doc_key": "ai-dev-320", "ner": [[6, 7, "misc"], [10, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 10, 13, "usage", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Metoda", "ta", "opiera", "si\u0119", "na", "estymacji", "prawdopodobie\u0144stw", "warunkowych", "za", "pomoc\u0105", "nieparametrycznej", "metody", "najwi\u0119kszego", "prawdopodobie\u0144stwa", ",", "co", "prowadzi", "do"], "sentence-detokenized": "Metoda ta opiera si\u0119 na estymacji prawdopodobie\u0144stw warunkowych za pomoc\u0105 nieparametrycznej metody najwi\u0119kszego prawdopodobie\u0144stwa, co prowadzi do", "token2charspan": [[0, 6], [7, 9], [10, 16], [17, 20], [21, 23], [24, 33], [34, 51], [52, 63], [64, 66], [67, 73], [74, 91], [92, 98], [99, 111], [112, 130], [130, 131], [132, 134], [135, 143], [144, 146]]}
{"doc_key": "ai-dev-321", "ner": [[7, 7, "algorithm"], [9, 11, "algorithm"], [13, 14, "metrics"], [16, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Podstawowe", "poj\u0119cia", "zwi\u0105zane", "z", "estymacj\u0105", "widmow\u0105", "to", "autokorelacja", ",", "wielodost\u0119pna", "transformata", "Fouriera", ",", "b\u0142\u0105d", "\u015bredniokwadratowy", "i", "entropia", "."], "sentence-detokenized": "Podstawowe poj\u0119cia zwi\u0105zane z estymacj\u0105 widmow\u0105 to autokorelacja, wielodost\u0119pna transformata Fouriera, b\u0142\u0105d \u015bredniokwadratowy i entropia.", "token2charspan": [[0, 10], [11, 18], [19, 27], [28, 29], [30, 39], [40, 47], [48, 50], [51, 64], [64, 65], [66, 79], [80, 92], [93, 101], [101, 102], [103, 107], [108, 125], [126, 127], [128, 136], [136, 137]]}
{"doc_key": "ai-dev-322", "ner": [[2, 3, "algorithm"], [8, 8, "field"], [10, 10, "algorithm"], [12, 14, "algorithm"], [16, 17, "task"], [19, 21, "field"], [23, 24, "task"], [26, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6, 7, 8], "relations": [[2, 3, 8, 8, "part-of", "", false, false], [2, 3, 10, 10, "part-of", "", false, false], [2, 3, 12, 14, "part-of", "", false, false], [2, 3, 16, 17, "part-of", "", false, false], [2, 3, 19, 21, "part-of", "", false, false], [2, 3, 23, 24, "part-of", "", false, false], [2, 3, 26, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5, 6, 7], "sentence": ["Obszary", "zastosowa\u0144", "metod", "kernelowych", "s\u0105", "r\u00f3\u017cnorodne", "i", "obejmuj\u0105", "geostatystyk\u0119", ",", "kriging", ",", "odwrotne", "wa\u017cenie", "odleg\u0142o\u015bci", ",", "rekonstrukcj\u0119", "3D", ",", "bioinformatyk\u0119", ",", "chemoinformatyk\u0119", ",", "ekstrakcj\u0119", "informacji", "oraz", "rozpoznawanie", "pisma", "r\u0119cznego", "."], "sentence-detokenized": "Obszary zastosowa\u0144 metod kernelowych s\u0105 r\u00f3\u017cnorodne i obejmuj\u0105 geostatystyk\u0119, kriging, odwrotne wa\u017cenie odleg\u0142o\u015bci, rekonstrukcj\u0119 3D, bioinformatyk\u0119, chemoinformatyk\u0119, ekstrakcj\u0119 informacji oraz rozpoznawanie pisma r\u0119cznego.", "token2charspan": [[0, 7], [8, 18], [19, 24], [25, 36], [37, 39], [40, 50], [51, 52], [53, 61], [62, 75], [75, 76], [77, 84], [84, 85], [86, 94], [95, 102], [103, 113], [113, 114], [115, 128], [129, 131], [131, 132], [133, 147], [147, 148], [149, 165], [165, 166], [167, 177], [178, 188], [189, 193], [194, 207], [208, 213], [214, 222], [222, 223]]}
{"doc_key": "ai-dev-323", "ner": [[22, 22, "organisation"], [13, 17, "product"], [19, 19, "product"], [25, 28, "product"], [30, 30, "product"], [35, 35, "product"], [37, 39, "product"], [42, 45, "product"], [47, 48, "product"], [53, 53, "product"], [55, 56, "product"], [60, 63, "product"], [67, 70, "product"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[13, 17, 22, 22, "artifact", "", false, false], [13, 17, 35, 35, "compare", "", false, false], [13, 17, 37, 39, "compare", "", false, false], [13, 17, 42, 45, "compare", "", false, false], [13, 17, 47, 48, "compare", "", false, false], [13, 17, 53, 53, "compare", "", false, false], [13, 17, 55, 56, "compare", "", false, false], [13, 17, 60, 63, "compare", "", false, false], [13, 17, 67, 70, "compare", "", false, false], [19, 19, 13, 17, "named", "", false, false], [25, 28, 35, 35, "compare", "", false, false], [25, 28, 37, 39, "compare", "", false, false], [25, 28, 42, 45, "compare", "", false, false], [25, 28, 47, 48, "compare", "", false, false], [25, 28, 53, 53, "compare", "", false, false], [25, 28, 55, 56, "compare", "", false, false], [25, 28, 60, 63, "compare", "", false, false], [25, 28, 67, 70, "compare", "", false, false], [30, 30, 25, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19], "sentence": ["Roboty", "mog\u0105", "by\u0107", "autonomiczne", "lub", "p\u00f3\u0142autonomiczne", "i", "si\u0119gaj\u0105", "od", "humanoid\u00f3w", ",", "takich", "jak", "Advanced", "Step", "in", "Innovative", "Mobility", "(", "ASIMO", ")", "firmy", "Honda", "i", "TOSY", "Ping", "Pong", "Playing", "Robot", "(", "TOPIO", ")", ",", "po", "roboty", "przemys\u0142owe", ",", "medyczne", "roboty", "operacyjne", ",", "roboty", "wspomagaj\u0105ce", "pacjent\u00f3w", ",", "roboty", "do", "terapii", "ps\u00f3w", ",", "kolektywnie", "zaprogramowane", "roboty", "rojowe", ",", "drony", "UAV", ",", "takie", "jak", "General", "Atomics", "MQ-1", "Predator", ",", "a", "nawet", "mikroskopijne", "nano", "-", "roboty", "."], "sentence-detokenized": "Roboty mog\u0105 by\u0107 autonomiczne lub p\u00f3\u0142autonomiczne i si\u0119gaj\u0105 od humanoid\u00f3w, takich jak Advanced Step in Innovative Mobility (ASIMO) firmy Honda i TOSY Ping Pong Playing Robot (TOPIO), po roboty przemys\u0142owe, medyczne roboty operacyjne, roboty wspomagaj\u0105ce pacjent\u00f3w, roboty do terapii ps\u00f3w, kolektywnie zaprogramowane roboty rojowe, drony UAV, takie jak General Atomics MQ-1 Predator, a nawet mikroskopijne nano-roboty.", "token2charspan": [[0, 6], [7, 11], [12, 15], [16, 28], [29, 32], [33, 48], [49, 50], [51, 58], [59, 61], [62, 72], [72, 73], [74, 80], [81, 84], [85, 93], [94, 98], [99, 101], [102, 112], [113, 121], [122, 123], [123, 128], [128, 129], [130, 135], [136, 141], [142, 143], [144, 148], [149, 153], [154, 158], [159, 166], [167, 172], [173, 174], [174, 179], [179, 180], [180, 181], [182, 184], [185, 191], [192, 203], [203, 204], [205, 213], [214, 220], [221, 231], [231, 232], [233, 239], [240, 252], [253, 262], [262, 263], [264, 270], [271, 273], [274, 281], [282, 286], [286, 287], [288, 299], [300, 314], [315, 321], [322, 328], [328, 329], [330, 335], [336, 339], [339, 340], [341, 346], [347, 350], [351, 358], [359, 366], [367, 371], [372, 380], [380, 381], [382, 383], [384, 389], [390, 403], [404, 408], [408, 409], [409, 415], [415, 416]]}
{"doc_key": "ai-dev-324", "ner": [[0, 0, "product"], [2, 3, "product"], [8, 13, "university"], [16, 16, "researcher"], [18, 19, "researcher"], [21, 23, "researcher"], [24, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 16, 16, "artifact", "", false, false], [0, 0, 18, 19, "artifact", "", false, false], [0, 0, 21, 23, "artifact", "", false, false], [0, 0, 24, 25, "artifact", "", false, false], [2, 3, 16, 16, "artifact", "", false, false], [2, 3, 18, 19, "artifact", "", false, false], [2, 3, 21, 23, "artifact", "", false, false], [2, 3, 24, 25, "artifact", "", false, false], [16, 16, 8, 13, "physical", "", false, false], [18, 19, 8, 13, "physical", "", false, false], [21, 23, 8, 13, "physical", "", false, false], [24, 25, 8, 13, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Freddy", "i", "Freddy", "II", "by\u0142y", "robotami", "zbudowanymi", "w", "University", "of", "Edinburgh", "School", "of", "Informatics", "przez", "Pata", "Amblera", ",", "Robina", "Popplestone'a", ",", "Austina", "Tate'a", "i", "Donalda", "Mitchie'ego", "i", "by\u0142y", "w", "stanie", "z\u0142o\u017cy\u0107", "drewniane", "klocki", "w", "ci\u0105gu", "kilku", "godzin", "."], "sentence-detokenized": "Freddy i Freddy II by\u0142y robotami zbudowanymi w University of Edinburgh School of Informatics przez Pata Amblera, Robina Popplestone'a, Austina Tate'a i Donalda Mitchie'ego i by\u0142y w stanie z\u0142o\u017cy\u0107 drewniane klocki w ci\u0105gu kilku godzin.", "token2charspan": [[0, 6], [7, 8], [9, 15], [16, 18], [19, 23], [24, 32], [33, 44], [45, 46], [47, 57], [58, 60], [61, 70], [71, 77], [78, 80], [81, 92], [93, 98], [99, 103], [104, 111], [111, 112], [113, 119], [120, 133], [133, 134], [135, 142], [143, 149], [150, 151], [152, 159], [160, 171], [172, 173], [174, 178], [179, 180], [181, 187], [188, 194], [195, 204], [205, 211], [212, 213], [214, 219], [220, 225], [226, 232], [232, 233]]}
{"doc_key": "ai-dev-325", "ner": [[3, 3, "location"], [10, 11, "country"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Dzieci\u0144stwo", "sp\u0119dzi\u0142", "w", "Pary\u017cu", ",", "gdzie", "jego", "rodzice", "wyemigrowali", "z", "Litwy", "na", "pocz\u0105tku", "lat", "20", "."], "sentence-detokenized": "Dzieci\u0144stwo sp\u0119dzi\u0142 w Pary\u017cu, gdzie jego rodzice wyemigrowali z Litwy na pocz\u0105tku lat 20.", "token2charspan": [[0, 11], [12, 19], [20, 21], [22, 28], [28, 29], [30, 35], [36, 40], [41, 48], [49, 61], [62, 63], [64, 69], [70, 72], [73, 81], [82, 85], [86, 88], [88, 89]]}
{"doc_key": "ai-dev-326", "ner": [[1, 2, "researcher"], [5, 9, "misc"], [11, 14, "organisation"], [16, 18, "university"], [25, 26, "university"], [32, 33, "university"], [35, 37, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 2, 5, 9, "role", "", false, false], [1, 2, 16, 18, "physical", "", false, false], [1, 2, 25, 26, "role", "", false, false], [1, 2, 32, 33, "role", "", false, false], [1, 2, 35, 37, "role", "", false, false], [5, 9, 11, 14, "part-of", "", false, false], [11, 14, 16, 18, "part-of", "", false, false], [32, 33, 25, 26, "part-of", "", false, false], [35, 37, 25, 26, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Wcze\u015bniej", "dr", "Paulos", "zajmowa\u0142", "stanowisko", "profesora", "nadzwyczajnego", "Cooper", "-", "Siegel", "w", "School", "of", "Computer", "Science", "na", "Uniwersytecie", "Carnegie", "Mellon", ",", "gdzie", "by\u0142", "wyk\u0142adowc\u0105", "w", "Instytucie", "Interakcji", "Cz\u0142owiek-Komputer", ",", "a", "tak\u017ce", "pracowa\u0142", "w", "Instytucie", "Robotyki", "i", "Centrum", "Technologii", "Rozrywkowych", "."], "sentence-detokenized": "Wcze\u015bniej dr Paulos zajmowa\u0142 stanowisko profesora nadzwyczajnego Cooper-Siegel w School of Computer Science na Uniwersytecie Carnegie Mellon, gdzie by\u0142 wyk\u0142adowc\u0105 w Instytucie Interakcji Cz\u0142owiek-Komputer, a tak\u017ce pracowa\u0142 w Instytucie Robotyki i Centrum Technologii Rozrywkowych.", "token2charspan": [[0, 9], [10, 12], [13, 19], [20, 28], [29, 39], [40, 49], [50, 64], [65, 71], [71, 72], [72, 78], [79, 80], [81, 87], [88, 90], [91, 99], [100, 107], [108, 110], [111, 124], [125, 133], [134, 140], [140, 141], [142, 147], [148, 151], [152, 162], [163, 164], [165, 175], [176, 186], [187, 204], [204, 205], [206, 207], [208, 213], [214, 222], [223, 224], [225, 235], [236, 244], [245, 246], [247, 254], [255, 266], [267, 279], [279, 280]]}
{"doc_key": "ai-dev-327", "ner": [[3, 4, "researcher"], [6, 7, "university"], [9, 10, "product"], [15, 17, "product"], [22, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 6, 7, "physical", "", false, false], [3, 4, 6, 7, "role", "", false, false], [9, 10, 3, 4, "artifact", "", false, false], [9, 10, 15, 17, "type-of", "", false, false], [9, 10, 22, 23, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["W", "1969", "roku", "Victor", "Scheinman", "z", "Uniwersytetu", "Stanforda", "wynalaz\u0142", "rami\u0119", "Stanforda", ",", "ca\u0142kowicie", "elektrycznego", ",", "6-osiowego", "robota", "przegubowego", "zaprojektowanego", "w", "celu", "umo\u017cliwienia", "rozwi\u0105zania", "ramienia", "."], "sentence-detokenized": "W 1969 roku Victor Scheinman z Uniwersytetu Stanforda wynalaz\u0142 rami\u0119 Stanforda, ca\u0142kowicie elektrycznego, 6-osiowego robota przegubowego zaprojektowanego w celu umo\u017cliwienia rozwi\u0105zania ramienia.", "token2charspan": [[0, 1], [2, 6], [7, 11], [12, 18], [19, 28], [29, 30], [31, 43], [44, 53], [54, 62], [63, 68], [69, 78], [78, 79], [80, 90], [91, 104], [104, 105], [106, 116], [117, 123], [124, 136], [137, 153], [154, 155], [156, 160], [161, 173], [174, 185], [186, 194], [194, 195]]}
{"doc_key": "ai-dev-328", "ner": [[3, 3, "product"], [13, 14, "field"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 13, 14, "related-to", "", false, false], [3, 3, 16, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Tworzenie", "i", "wdra\u017canie", "chatbot\u00f3w", "to", "wci\u0105\u017c", "rozwijaj\u0105ca", "si\u0119", "dziedzina", ",", "mocno", "zwi\u0105zana", "ze", "sztuczn\u0105", "inteligencj\u0105", "i", "uczeniem", "maszynowym", ",", "dlatego", "dostarczane", "rozwi\u0105zania", ",", "cho\u0107", "posiadaj\u0105", "oczywiste", "zalety", ",", "maj\u0105", "pewne", "istotne", "ograniczenia", "w", "zakresie", "funkcjonalno\u015bci", "i", "przypadk\u00f3w", "u\u017cycia", "."], "sentence-detokenized": "Tworzenie i wdra\u017canie chatbot\u00f3w to wci\u0105\u017c rozwijaj\u0105ca si\u0119 dziedzina, mocno zwi\u0105zana ze sztuczn\u0105 inteligencj\u0105 i uczeniem maszynowym, dlatego dostarczane rozwi\u0105zania, cho\u0107 posiadaj\u0105 oczywiste zalety, maj\u0105 pewne istotne ograniczenia w zakresie funkcjonalno\u015bci i przypadk\u00f3w u\u017cycia.", "token2charspan": [[0, 9], [10, 11], [12, 21], [22, 31], [32, 34], [35, 40], [41, 52], [53, 56], [57, 66], [66, 67], [68, 73], [74, 82], [83, 85], [86, 94], [95, 107], [108, 109], [110, 118], [119, 129], [129, 130], [131, 138], [139, 150], [151, 162], [162, 163], [164, 168], [169, 178], [179, 188], [189, 195], [195, 196], [197, 201], [202, 207], [208, 215], [216, 228], [229, 230], [231, 239], [240, 255], [256, 257], [258, 268], [269, 275], [275, 276]]}
{"doc_key": "ai-dev-329", "ner": [[10, 12, "university"], [7, 9, "product"], [24, 25, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 10, 12, "part-of", "", true, false], [24, 25, 7, 9, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Je\u015bli", "chodzi", "o", "swobodnie", "dost\u0119pne", "zasoby", ",", "zestaw", "narz\u0119dzi", "Sphinx", "Uniwersytetu", "Carnegie", "Mellon", "jest", "jednym", "z", "miejsc", ",", "gdzie", "mo\u017cna", "rozpocz\u0105\u0107", "zar\u00f3wno", "nauk\u0119", "o", "rozpoznawaniu", "mowy", ",", "jak", "i", "rozpocz\u0105\u0107", "eksperymentowanie", "."], "sentence-detokenized": "Je\u015bli chodzi o swobodnie dost\u0119pne zasoby, zestaw narz\u0119dzi Sphinx Uniwersytetu Carnegie Mellon jest jednym z miejsc, gdzie mo\u017cna rozpocz\u0105\u0107 zar\u00f3wno nauk\u0119 o rozpoznawaniu mowy, jak i rozpocz\u0105\u0107 eksperymentowanie.", "token2charspan": [[0, 5], [6, 12], [13, 14], [15, 24], [25, 33], [34, 40], [40, 41], [42, 48], [49, 57], [58, 64], [65, 77], [78, 86], [87, 93], [94, 98], [99, 105], [106, 107], [108, 114], [114, 115], [116, 121], [122, 127], [128, 137], [138, 145], [146, 151], [152, 153], [154, 167], [168, 172], [172, 173], [174, 177], [178, 179], [180, 189], [190, 207], [207, 208]]}
{"doc_key": "ai-dev-330", "ner": [[1, 2, "misc"], [9, 15, "misc"], [17, 17, "misc"], [21, 21, "university"], [23, 24, "location"], [25, 25, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 2, 9, 15, "temporal", "", false, false], [17, 17, 9, 15, "named", "", false, false], [17, 17, 23, 24, "physical", "", false, false], [21, 21, 17, 17, "role", "", false, false], [23, 24, 25, 25, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Formalne", "zawody", "RoboCup", "poprzedzi\u0142", "(", "cz\u0119sto", "nieuznawany", ")", "pierwszy", "Mi\u0119dzynarodowy", "Turniej", "Pi\u0142karski", "Micro", "Robot", "World", "Cup", "(", "MIROSOT", ")", "zorganizowany", "przez", "KAIST", "w", "Taejon", "w", "Korei", "w", "listopadzie", "1996", "roku", "."], "sentence-detokenized": "Formalne zawody RoboCup poprzedzi\u0142 (cz\u0119sto nieuznawany) pierwszy Mi\u0119dzynarodowy Turniej Pi\u0142karski Micro Robot World Cup (MIROSOT) zorganizowany przez KAIST w Taejon w Korei w listopadzie 1996 roku.", "token2charspan": [[0, 8], [9, 15], [16, 23], [24, 34], [35, 36], [36, 42], [43, 54], [54, 55], [56, 64], [65, 79], [80, 87], [88, 97], [98, 103], [104, 109], [110, 115], [116, 119], [120, 121], [121, 128], [128, 129], [130, 143], [144, 149], [150, 155], [156, 157], [158, 164], [165, 166], [167, 172], [173, 174], [175, 186], [187, 191], [192, 196], [196, 197]]}
{"doc_key": "ai-dev-331", "ner": [[2, 3, "metrics"], [19, 20, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Opr\u00f3cz", "standardowej", "straty", "zawiasowej", "math", "(", "1-yf", "(", "x", ")", ")", "_", "+", "/", "math", "dla", "danych", "etykietowanych", ",", "funkcja", "straty", "math", "(", "-", "1", "|", "f", "(", "x", ")", "|", ")", "_", "+", "/", "math", "jest", "wprowadzana", "nad", "nieoznakowanymi", "danymi", "poprzez", "dopuszczenie", "mathy", "=", "operatorname", "{", "sign", "}", "{", "f", "(", "x", ")", "}", "/", "math", "."], "sentence-detokenized": "Opr\u00f3cz standardowej straty zawiasowej math (1-yf (x)) _ + / math dla danych etykietowanych, funkcja straty math (-1 | f (x) |) _ + / math jest wprowadzana nad nieoznakowanymi danymi poprzez dopuszczenie mathy = operatorname {sign} {f (x)} / math.", "token2charspan": [[0, 6], [7, 19], [20, 26], [27, 37], [38, 42], [43, 44], [44, 48], [49, 50], [50, 51], [51, 52], [52, 53], [54, 55], [56, 57], [58, 59], [60, 64], [65, 68], [69, 75], [76, 90], [90, 91], [92, 99], [100, 106], [107, 111], [112, 113], [113, 114], [114, 115], [116, 117], [118, 119], [120, 121], [121, 122], [122, 123], [124, 125], [125, 126], [127, 128], [129, 130], [131, 132], [133, 137], [138, 142], [143, 154], [155, 158], [159, 174], [175, 181], [182, 189], [190, 202], [203, 208], [209, 210], [211, 223], [224, 225], [225, 229], [229, 230], [231, 232], [232, 233], [234, 235], [235, 236], [236, 237], [237, 238], [239, 240], [241, 245], [245, 246]]}
{"doc_key": "ai-dev-332", "ner": [[2, 2, "misc"], [9, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 9, 11, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["W", "szczeg\u00f3lno\u015bci", "RLS", "jest", "zaprojektowany", "tak", ",", "aby", "zminimalizowa\u0107", "\u015bredni", "b\u0142\u0105d", "kwadratowy", "mi\u0119dzy", "przewidywanymi", "warto\u015bciami", "a", "etykietami", "TRUE", ",", "z", "zastrze\u017ceniem", "regularno\u015bci", "."], "sentence-detokenized": "W szczeg\u00f3lno\u015bci RLS jest zaprojektowany tak, aby zminimalizowa\u0107 \u015bredni b\u0142\u0105d kwadratowy mi\u0119dzy przewidywanymi warto\u015bciami a etykietami TRUE, z zastrze\u017ceniem regularno\u015bci.", "token2charspan": [[0, 1], [2, 15], [16, 19], [20, 24], [25, 39], [40, 43], [43, 44], [45, 48], [49, 63], [64, 70], [71, 75], [76, 86], [87, 93], [94, 108], [109, 120], [121, 122], [123, 133], [134, 138], [138, 139], [140, 141], [142, 155], [156, 168], [168, 169]]}
{"doc_key": "ai-dev-333", "ner": [[3, 6, "algorithm"], [8, 9, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 6, 8, 9, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Zasadniczo", "\u0142\u0105czy", "to", "estymacj\u0119", "z", "maksymalnym", "prawdopodobie\u0144stwem", "z", "procedur\u0105", "regularyzacji", ",", "kt\u00f3ra", "faworyzuje", "prostsze", "modele", "nad", "bardziej", "z\u0142o\u017conymi", "."], "sentence-detokenized": "Zasadniczo \u0142\u0105czy to estymacj\u0119 z maksymalnym prawdopodobie\u0144stwem z procedur\u0105 regularyzacji, kt\u00f3ra faworyzuje prostsze modele nad bardziej z\u0142o\u017conymi.", "token2charspan": [[0, 10], [11, 16], [17, 19], [20, 29], [30, 31], [32, 43], [44, 63], [64, 65], [66, 75], [76, 89], [89, 90], [91, 96], [97, 107], [108, 116], [117, 123], [124, 127], [128, 136], [137, 146], [146, 147]]}
{"doc_key": "ai-dev-334", "ner": [[0, 2, "metrics"], [7, 7, "metrics"], [9, 9, "metrics"], [11, 12, "misc"], [15, 16, "misc"], [24, 27, "algorithm"], [28, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[7, 7, 0, 2, "named", "", false, false], [9, 9, 0, 2, "named", "", false, false], [11, 12, 15, 16, "related-to", "", false, false], [11, 12, 24, 27, "related-to", "ratio", false, false], [24, 27, 28, 29, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Wsp\u00f3\u0142czynnik", "prawdziwych", "alarm\u00f3w", "jest", "r\u00f3wnie\u017c", "znany", "jako", "czu\u0142o\u015b\u0107", ",", "wycofanie", "lub", "prawdopodobie\u0144stwo", "wykrycia", "matematyki", "do", "progu", "dyskryminacji", ")", "prawdopodobie\u0144stwa", "wykrycia", "na", "osi", "y", "versus", "skumulowana", "funkcja", "rozk\u0142adu", "prawdopodobie\u0144stwa", "fa\u0142szywych", "alarm\u00f3w", "na", "osi", "x", "."], "sentence-detokenized": "Wsp\u00f3\u0142czynnik prawdziwych alarm\u00f3w jest r\u00f3wnie\u017c znany jako czu\u0142o\u015b\u0107, wycofanie lub prawdopodobie\u0144stwo wykrycia matematyki do progu dyskryminacji) prawdopodobie\u0144stwa wykrycia na osi y versus skumulowana funkcja rozk\u0142adu prawdopodobie\u0144stwa fa\u0142szywych alarm\u00f3w na osi x.", "token2charspan": [[0, 12], [13, 24], [25, 32], [33, 37], [38, 45], [46, 51], [52, 56], [57, 64], [64, 65], [66, 75], [76, 79], [80, 98], [99, 107], [108, 118], [119, 121], [122, 127], [128, 141], [141, 142], [143, 161], [162, 170], [171, 173], [174, 177], [178, 179], [180, 186], [187, 198], [199, 206], [207, 215], [216, 234], [235, 245], [246, 253], [254, 256], [257, 260], [261, 262], [262, 263]]}
{"doc_key": "ai-dev-335", "ner": [[2, 2, "misc"], [7, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 7, 2, 2, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["W", "j\u0119zyku", "angielskim", "przyk\u0142adem", "sieci", "semantycznej", "jest", "WordNet", "."], "sentence-detokenized": "W j\u0119zyku angielskim przyk\u0142adem sieci semantycznej jest WordNet.", "token2charspan": [[0, 1], [2, 8], [9, 19], [20, 30], [31, 36], [37, 49], [50, 54], [55, 62], [62, 63]]}
{"doc_key": "ai-dev-336", "ner": [[2, 6, "product"], [9, 10, "product"], [20, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[20, 21, 2, 6, "usage", "", false, false], [20, 21, 9, 10, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Przed\u0142u\u017cone", "stosowanie", "oprogramowania", "do", "rozpoznawania", "mowy", "w", "po\u0142\u0105czeniu", "z", "edytorami", "tekstu", "wykaza\u0142o", "korzy\u015bci", "dla", "wzmocnienia", "pami\u0119ci", "kr\u00f3tkotrwa\u0142ej", "u", "pacjent\u00f3w", "z", "AVM", "m\u00f3zgu", ",", "kt\u00f3rzy", "byli", "leczeni", "resekcj\u0105", "."], "sentence-detokenized": "Przed\u0142u\u017cone stosowanie oprogramowania do rozpoznawania mowy w po\u0142\u0105czeniu z edytorami tekstu wykaza\u0142o korzy\u015bci dla wzmocnienia pami\u0119ci kr\u00f3tkotrwa\u0142ej u pacjent\u00f3w z AVM m\u00f3zgu, kt\u00f3rzy byli leczeni resekcj\u0105.", "token2charspan": [[0, 11], [12, 22], [23, 37], [38, 40], [41, 54], [55, 59], [60, 61], [62, 72], [73, 74], [75, 84], [85, 91], [92, 100], [101, 109], [110, 113], [114, 125], [126, 133], [134, 147], [148, 149], [150, 159], [160, 161], [162, 165], [166, 171], [171, 172], [173, 179], [180, 184], [185, 192], [193, 201], [201, 202]]}
{"doc_key": "ai-dev-337", "ner": [[5, 6, "researcher"], [8, 9, "researcher"], [11, 12, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Jej", "za\u0142o\u017cycielskimi", "redaktorami", "naczelnymi", "byli", "Ron", "Sun", ",", "Vasant", "Honavar", "i", "Gregg", "Oden", "(", "od", "1999", "do", "2014", ")", "."], "sentence-detokenized": "Jej za\u0142o\u017cycielskimi redaktorami naczelnymi byli Ron Sun, Vasant Honavar i Gregg Oden (od 1999 do 2014).", "token2charspan": [[0, 3], [4, 19], [20, 31], [32, 42], [43, 47], [48, 51], [52, 55], [55, 56], [57, 63], [64, 71], [72, 73], [74, 79], [80, 84], [85, 86], [86, 88], [89, 93], [94, 96], [97, 101], [101, 102], [102, 103]]}
{"doc_key": "ai-dev-338", "ner": [[9, 26, "product"], [17, 18, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 26, 17, 18, "opposite", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Ich", "\"", "r\u00f3wnoleg\u0142e", "\"", "odr\u00f3\u017cnienie", ",", "w", "przeciwie\u0144stwie", "do", "manipulatora", "szeregowego", ",", "polega", "na", "tym", ",", "\u017ce", "efektor", "ko\u0144cowy", "(", "lub", "\"", "r\u0119ka", "\"", ")", "tego", "manipulatora", "(", "lub", "\"", "ramienia", "\"", ")", "jest", "bezpo\u015brednio", "po\u0142\u0105czony", "z", "jego", "podstaw\u0105", "za", "pomoc\u0105", "szeregu", "(", "zwykle", "trzech", "lub", "sze\u015bciu", ")", "oddzielnych", "i", "niezale\u017cnych", "po\u0142\u0105cze\u0144", "dzia\u0142aj\u0105cych", "jednocze\u015bnie", "."], "sentence-detokenized": "Ich \"r\u00f3wnoleg\u0142e\" odr\u00f3\u017cnienie, w przeciwie\u0144stwie do manipulatora szeregowego, polega na tym, \u017ce efektor ko\u0144cowy (lub \"r\u0119ka\") tego manipulatora (lub \"ramienia\") jest bezpo\u015brednio po\u0142\u0105czony z jego podstaw\u0105 za pomoc\u0105 szeregu (zwykle trzech lub sze\u015bciu) oddzielnych i niezale\u017cnych po\u0142\u0105cze\u0144 dzia\u0142aj\u0105cych jednocze\u015bnie.", "token2charspan": [[0, 3], [4, 5], [5, 15], [15, 16], [17, 28], [28, 29], [30, 31], [32, 47], [48, 50], [51, 63], [64, 75], [75, 76], [77, 83], [84, 86], [87, 90], [90, 91], [92, 94], [95, 102], [103, 110], [111, 112], [112, 115], [116, 117], [117, 121], [121, 122], [122, 123], [124, 128], [129, 141], [142, 143], [143, 146], [147, 148], [148, 156], [156, 157], [157, 158], [159, 163], [164, 176], [177, 186], [187, 188], [189, 193], [194, 202], [203, 205], [206, 212], [213, 220], [221, 222], [222, 228], [229, 235], [236, 239], [240, 247], [247, 248], [249, 260], [261, 262], [263, 275], [276, 284], [285, 297], [298, 310], [310, 311]]}
{"doc_key": "ai-dev-339", "ner": [[8, 9, "researcher"], [21, 22, "researcher"], [23, 24, "researcher"], [26, 27, "researcher"], [29, 30, "researcher"], [32, 33, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Jego", "doradc\u0105", "w", "sprawie", "pracy", "dyplomowej", "by\u0142", "profesor", "Cordell", "Green", ",", "a", "w", "sk\u0142ad", "jego", "komisji", "dyplomowej", "/", "ustnej", "wchodzili", "profesorowie", "Edward", "Feigenbaum", "Joshua", "Lederberg", ",", "Paul", "Cohen", ",", "Allen", "Newell", ",", "Herbert", "Simon", ",", "."], "sentence-detokenized": "Jego doradc\u0105 w sprawie pracy dyplomowej by\u0142 profesor Cordell Green, a w sk\u0142ad jego komisji dyplomowej / ustnej wchodzili profesorowie Edward Feigenbaum Joshua Lederberg, Paul Cohen, Allen Newell, Herbert Simon,.", "token2charspan": [[0, 4], [5, 12], [13, 14], [15, 22], [23, 28], [29, 39], [40, 43], [44, 52], [53, 60], [61, 66], [66, 67], [68, 69], [70, 71], [72, 77], [78, 82], [83, 90], [91, 101], [102, 103], [104, 110], [111, 120], [121, 133], [134, 140], [141, 151], [152, 158], [159, 168], [168, 169], [170, 174], [175, 180], [180, 181], [182, 187], [188, 194], [194, 195], [196, 203], [204, 209], [209, 210], [210, 211]]}
{"doc_key": "ai-dev-340", "ner": [[3, 4, "metrics"], [8, 8, "metrics"], [11, 14, "metrics"], [15, 16, "metrics"], [25, 25, "metrics"], [23, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Funkcje", "takie", "obejmuj\u0105", "b\u0142\u0105d", "\u015bredniokwadratowy", ",", "b\u0142\u0105d", "\u015bredniokwadratowy", "pierwiastkowy", ",", "b\u0142\u0105d", "\u015bredni", "bezwzgl\u0119dny", ",", "b\u0142\u0105d", "wzgl\u0119dny", "kwadratowy", ",", "b\u0142\u0105d", "wzgl\u0119dny", "kwadratowy", "pierwiastkowy", ",", "b\u0142\u0105d", "bezwzgl\u0119dny", "wzgl\u0119dny", "i", "inne", "."], "sentence-detokenized": "Funkcje takie obejmuj\u0105 b\u0142\u0105d \u015bredniokwadratowy, b\u0142\u0105d \u015bredniokwadratowy pierwiastkowy, b\u0142\u0105d \u015bredni bezwzgl\u0119dny, b\u0142\u0105d wzgl\u0119dny kwadratowy, b\u0142\u0105d wzgl\u0119dny kwadratowy pierwiastkowy, b\u0142\u0105d bezwzgl\u0119dny wzgl\u0119dny i inne.", "token2charspan": [[0, 7], [8, 13], [14, 22], [23, 27], [28, 45], [45, 46], [47, 51], [52, 69], [70, 83], [83, 84], [85, 89], [90, 96], [97, 108], [108, 109], [110, 114], [115, 123], [124, 134], [134, 135], [136, 140], [141, 149], [150, 160], [161, 174], [174, 175], [176, 180], [181, 192], [193, 201], [202, 203], [204, 208], [208, 209]]}
{"doc_key": "ai-dev-341", "ner": [[4, 4, "programlang"], [6, 6, "programlang"], [8, 8, "product"], [10, 10, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Istniej\u0105", "wi\u0105zania", "w", "j\u0119zyku", "Python", ",", "Java", "i", "MATLAB", "/", "OCTAVE", "."], "sentence-detokenized": "Istniej\u0105 wi\u0105zania w j\u0119zyku Python, Java i MATLAB / OCTAVE.", "token2charspan": [[0, 8], [9, 17], [18, 19], [20, 26], [27, 33], [33, 34], [35, 39], [40, 41], [42, 48], [49, 50], [51, 57], [57, 58]]}
{"doc_key": "ai-dev-342", "ner": [[2, 2, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Implementacj\u0119", "w", "MATLABie", "mo\u017cna", "znale\u017a\u0107", "na", "stronie", "."], "sentence-detokenized": "Implementacj\u0119 w MATLABie mo\u017cna znale\u017a\u0107 na stronie.", "token2charspan": [[0, 13], [14, 15], [16, 24], [25, 30], [31, 38], [39, 41], [42, 49], [49, 50]]}
{"doc_key": "ai-dev-343", "ner": [[0, 1, "researcher"], [7, 8, "field"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 24, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 8, 0, 1, "origin", "", false, false], [7, 8, 12, 13, "origin", "", false, false], [7, 8, 15, 16, "origin", "", false, false], [7, 8, 18, 19, "origin", "", false, false], [7, 8, 21, 24, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["John", "McCarthy", "jest", "jednym", "z", "ojc\u00f3w", "za\u0142o\u017cycieli", "sztucznej", "inteligencji", ",", "wraz", "z", "Alanem", "Turingiem", ",", "Marvinem", "Minsky'm", ",", "Allenem", "Newellem", "i", "Herbertem", "A", ".", "Simonem", "."], "sentence-detokenized": "John McCarthy jest jednym z ojc\u00f3w za\u0142o\u017cycieli sztucznej inteligencji, wraz z Alanem Turingiem, Marvinem Minsky'm, Allenem Newellem i Herbertem A. Simonem.", "token2charspan": [[0, 4], [5, 13], [14, 18], [19, 25], [26, 27], [28, 33], [34, 45], [46, 55], [56, 68], [68, 69], [70, 74], [75, 76], [77, 83], [84, 93], [93, 94], [95, 103], [104, 112], [112, 113], [114, 121], [122, 130], [131, 132], [133, 142], [143, 144], [144, 145], [146, 153], [153, 154]]}
{"doc_key": "ai-dev-344", "ner": [[7, 8, "product"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Manipulator", "r\u00f3wnoleg\u0142y", "to", "uk\u0142ad", "mechaniczny", "wykorzystuj\u0105cy", "kilka", "manipulator\u00f3w", "szeregowych", "do", "obs\u0142ugi", "pojedynczej", "platformy", "lub", "efektora", "ko\u0144cowego", "."], "sentence-detokenized": "Manipulator r\u00f3wnoleg\u0142y to uk\u0142ad mechaniczny wykorzystuj\u0105cy kilka manipulator\u00f3w szeregowych do obs\u0142ugi pojedynczej platformy lub efektora ko\u0144cowego.", "token2charspan": [[0, 11], [12, 22], [23, 25], [26, 31], [32, 43], [44, 58], [59, 64], [65, 78], [79, 90], [91, 93], [94, 101], [102, 113], [114, 123], [124, 127], [128, 136], [137, 146], [146, 147]]}
{"doc_key": "ai-dev-345", "ner": [[0, 0, "product"], [3, 4, "task"], [7, 7, "product"], [9, 15, "product"], [25, 25, "misc"], [27, 27, "misc"], [29, 30, "misc"], [33, 33, "task"], [35, 39, "product"], [41, 42, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[7, 7, 0, 0, "part-of", "", false, false], [7, 7, 3, 4, "type-of", "", false, false], [9, 15, 7, 7, "named", "", false, false], [25, 25, 7, 7, "part-of", "", false, false], [27, 27, 7, 7, "part-of", "", false, false], [29, 30, 7, 7, "part-of", "", false, false], [33, 33, 7, 7, "part-of", "", false, false], [35, 39, 7, 7, "part-of", "", false, false], [41, 42, 7, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["GATE", "zawiera", "system", "ekstrakcji", "informacji", "o", "nazwie", "ANNIE", "(", "A", "Nearly", "-", "New", "Information", "Extraction", "System", ")", ",", "kt\u00f3ry", "jest", "zestawem", "modu\u0142\u00f3w", "sk\u0142adaj\u0105cych", "si\u0119", "z", "tokenizera", ",", "gazetteera", ",", "dzielnika", "zda\u0144", ",", "znacznika", "Part-of-speech", ",", "przetwornika", "do", "rozpoznawania", "encji", "nazwanych", "oraz", "znacznika", "rdzeniowego", "."], "sentence-detokenized": "GATE zawiera system ekstrakcji informacji o nazwie ANNIE (A Nearly-New Information Extraction System), kt\u00f3ry jest zestawem modu\u0142\u00f3w sk\u0142adaj\u0105cych si\u0119 z tokenizera, gazetteera, dzielnika zda\u0144, znacznika Part-of-speech, przetwornika do rozpoznawania encji nazwanych oraz znacznika rdzeniowego.", "token2charspan": [[0, 4], [5, 12], [13, 19], [20, 30], [31, 41], [42, 43], [44, 50], [51, 56], [57, 58], [58, 59], [60, 66], [66, 67], [67, 70], [71, 82], [83, 93], [94, 100], [100, 101], [101, 102], [103, 108], [109, 113], [114, 122], [123, 130], [131, 143], [144, 147], [148, 149], [150, 160], [160, 161], [162, 172], [172, 173], [174, 183], [184, 188], [188, 189], [190, 199], [200, 214], [214, 215], [216, 228], [229, 231], [232, 245], [246, 251], [252, 261], [262, 266], [267, 276], [277, 288], [288, 289]]}
{"doc_key": "ai-dev-346", "ner": [[1, 3, "university"], [20, 21, "country"], [13, 17, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Uko\u0144czy\u0142", "Moskiewski", "Uniwersytet", "Pa\u0144stwowy", ",", "a", "w", "listopadzie", "1978", "roku", "dzi\u0119ki", "osobistej", "interwencji", "senatora", "Edwarda", "M", ".", "Kennedy'ego", "wyjecha\u0142", "do", "Stan\u00f3w", "Zjednoczonych", ".", ".", ".", "."], "sentence-detokenized": "Uko\u0144czy\u0142 Moskiewski Uniwersytet Pa\u0144stwowy, a w listopadzie 1978 roku dzi\u0119ki osobistej interwencji senatora Edwarda M. Kennedy'ego wyjecha\u0142 do Stan\u00f3w Zjednoczonych....", "token2charspan": [[0, 8], [9, 19], [20, 31], [32, 41], [41, 42], [43, 44], [45, 46], [47, 58], [59, 63], [64, 68], [69, 75], [76, 85], [86, 97], [98, 106], [107, 114], [115, 116], [116, 117], [118, 129], [130, 138], [139, 141], [142, 148], [149, 162], [162, 163], [163, 164], [164, 165], [165, 166]]}
{"doc_key": "ai-dev-347", "ner": [[3, 5, "organisation"], [7, 11, "misc"], [17, 17, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 7, 11, "win-defeat", "", false, false], [7, 11, 17, 17, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["W", "2017", "roku", "zesp\u00f3\u0142", "DeepMind", "AlphaGo", "otrzyma\u0142", "inauguracyjny", "medal", "IJCAI", "Marvin", "Minsky", "za", "wybitne", "osi\u0105gni\u0119cia", "w", "dziedzinie", "AI", "."], "sentence-detokenized": "W 2017 roku zesp\u00f3\u0142 DeepMind AlphaGo otrzyma\u0142 inauguracyjny medal IJCAI Marvin Minsky za wybitne osi\u0105gni\u0119cia w dziedzinie AI.", "token2charspan": [[0, 1], [2, 6], [7, 11], [12, 18], [19, 27], [28, 35], [36, 44], [45, 58], [59, 64], [65, 70], [71, 77], [78, 84], [85, 87], [88, 95], [96, 107], [108, 109], [110, 120], [121, 123], [123, 124]]}
{"doc_key": "ai-dev-348", "ner": [[3, 4, "misc"], [6, 6, "misc"], [10, 10, "misc"], [19, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 6, 6, "related-to", "is_recorded_by", false, false], [6, 6, 10, 10, "cause-effect", "", false, false], [6, 6, 10, 10, "physical", "", false, false], [6, 6, 19, 19, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Inne", "sposoby", "rejestrowania", "anomalnej", "propagacji", "to", "troposkatery", "powoduj\u0105ce", "nier\u00f3wno\u015bci", "w", "troposferze", ",", "rozpraszanie", "spowodowane", "meteorami", ",", "refrakcja", "w", "zjonizowanych", "regionach", "i", "warstwach", "jonosfery", "oraz", "odbicie", "od", "jonosfery", "."], "sentence-detokenized": "Inne sposoby rejestrowania anomalnej propagacji to troposkatery powoduj\u0105ce nier\u00f3wno\u015bci w troposferze, rozpraszanie spowodowane meteorami, refrakcja w zjonizowanych regionach i warstwach jonosfery oraz odbicie od jonosfery.", "token2charspan": [[0, 4], [5, 12], [13, 26], [27, 36], [37, 47], [48, 50], [51, 63], [64, 74], [75, 86], [87, 88], [89, 100], [100, 101], [102, 114], [115, 126], [127, 136], [136, 137], [138, 147], [148, 149], [150, 163], [164, 173], [174, 175], [176, 185], [186, 195], [196, 200], [201, 208], [209, 211], [212, 221], [221, 222]]}
{"doc_key": "ai-dev-349", "ner": [[0, 2, "field"], [4, 4, "field"], [8, 8, "field"], [10, 10, "field"], [12, 13, "field"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 8, 8, "part-of", "", false, false], [0, 2, 10, 10, "part-of", "", false, false], [0, 2, 12, 13, "part-of", "", false, false], [0, 2, 15, 16, "part-of", "", false, false], [4, 4, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Przetwarzanie", "j\u0119zyka", "naturalnego", "(", "NLP", ")", "to", "dziedzina", "lingwistyki", ",", "informatyki", ",", "in\u017cynierii", "informacyjnej", "i", "sztucznej", "inteligencji", "zajmuj\u0105ca", "si\u0119", "interakcjami", "mi\u0119dzy", "komputerami", "a", "ludzkimi", "(", "naturalnymi", ")", "j\u0119zykami", ",", "w", "szczeg\u00f3lno\u015bci", "tym", ",", "jak", "zaprogramowa\u0107", "komputery", "do", "przetwarzania", "i", "analizowania", "du\u017cych", "ilo\u015bci", "danych", "w", "j\u0119zyku", "naturalnym", "."], "sentence-detokenized": "Przetwarzanie j\u0119zyka naturalnego (NLP) to dziedzina lingwistyki, informatyki, in\u017cynierii informacyjnej i sztucznej inteligencji zajmuj\u0105ca si\u0119 interakcjami mi\u0119dzy komputerami a ludzkimi (naturalnymi) j\u0119zykami, w szczeg\u00f3lno\u015bci tym, jak zaprogramowa\u0107 komputery do przetwarzania i analizowania du\u017cych ilo\u015bci danych w j\u0119zyku naturalnym.", "token2charspan": [[0, 13], [14, 20], [21, 32], [33, 34], [34, 37], [37, 38], [39, 41], [42, 51], [52, 63], [63, 64], [65, 76], [76, 77], [78, 88], [89, 102], [103, 104], [105, 114], [115, 127], [128, 137], [138, 141], [142, 154], [155, 161], [162, 173], [174, 175], [176, 184], [185, 186], [186, 197], [197, 198], [199, 207], [207, 208], [209, 210], [211, 224], [225, 228], [228, 229], [230, 233], [234, 247], [248, 257], [258, 260], [261, 274], [275, 276], [277, 289], [290, 296], [297, 303], [304, 310], [311, 312], [313, 319], [320, 330], [330, 331]]}
{"doc_key": "ai-dev-350", "ner": [[6, 7, "organisation"], [9, 10, "organisation"], [12, 14, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Inne", "aktywne", "m\u0142odzie\u017cowe", "grupy", "klimatyczne", "to", "Extinction", "Rebellion", ",", "Sunrise", "Movement", ",", "SustainUS", ",", "i", "inne", ",", "dzia\u0142aj\u0105ce", "zar\u00f3wno", "na", "poziomie", "mi\u0119dzynarodowym", ",", "jak", "i", "lokalnym", "."], "sentence-detokenized": "Inne aktywne m\u0142odzie\u017cowe grupy klimatyczne to Extinction Rebellion, Sunrise Movement, SustainUS, i inne, dzia\u0142aj\u0105ce zar\u00f3wno na poziomie mi\u0119dzynarodowym, jak i lokalnym.", "token2charspan": [[0, 4], [5, 12], [13, 24], [25, 30], [31, 42], [43, 45], [46, 56], [57, 66], [66, 67], [68, 75], [76, 84], [84, 85], [86, 95], [95, 96], [97, 98], [99, 103], [103, 104], [105, 115], [116, 123], [124, 126], [127, 135], [136, 151], [151, 152], [153, 156], [157, 158], [159, 167], [167, 168]]}
