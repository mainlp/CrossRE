{"doc_key": "ai-test-1", "ner": [[6, 8, "algorithm"], [10, 12, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typowe", "podej\u015bcia", "do", "modeli", "generatywnych", "obejmuj\u0105", "naiwne", "klasyfikatory", "Bayesa", ",", "gaussowskie", "modele", "mieszankowe", ",", "wariacyjne", "autoenkodery", "i", "inne", "."], "sentence-detokenized": "Typowe podej\u015bcia do modeli generatywnych obejmuj\u0105 naiwne klasyfikatory Bayesa, gaussowskie modele mieszankowe, wariacyjne autoenkodery i inne.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 26], [27, 40], [41, 49], [50, 56], [57, 70], [71, 77], [77, 78], [79, 90], [91, 97], [98, 109], [109, 110], [111, 121], [122, 134], [135, 136], [137, 141], [141, 142]]}
{"doc_key": "ai-test-2", "ner": [[5, 5, "organisation"], [9, 9, "conference"], [12, 17, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 9, 9, "role", "", false, false], [12, 17, 9, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Wreszcie", ",", "co", "drugi", "rok", "ELRA", "organizuje", "du\u017c\u0105", "konferencj\u0119", "LREC", ",", "czyli", "International", "Language", "Resources", "and", "Evaluation", "Conference", "."], "sentence-detokenized": "Wreszcie, co drugi rok ELRA organizuje du\u017c\u0105 konferencj\u0119 LREC, czyli International Language Resources and Evaluation Conference.", "token2charspan": [[0, 8], [8, 9], [10, 12], [13, 18], [19, 22], [23, 27], [28, 38], [39, 43], [44, 55], [56, 60], [60, 61], [62, 67], [68, 81], [82, 90], [91, 100], [101, 104], [105, 115], [116, 126], [126, 127]]}
{"doc_key": "ai-test-3", "ner": [[5, 10, "algorithm"], [7, 8, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Zadanie", "polega", "zwykle", "na", "wyprowadzeniu", "estymacji", "parametr\u00f3w", "HMM", "z", "maksymalnym", "prawdopodobie\u0144stwem", ",", "bior\u0105c", "pod", "uwag\u0119", "sekwencje", "wyj\u015bciowe", "."], "sentence-detokenized": "Zadanie polega zwykle na wyprowadzeniu estymacji parametr\u00f3w HMM z maksymalnym prawdopodobie\u0144stwem, bior\u0105c pod uwag\u0119 sekwencje wyj\u015bciowe.", "token2charspan": [[0, 7], [8, 14], [15, 21], [22, 24], [25, 38], [39, 48], [49, 59], [60, 63], [64, 65], [66, 77], [78, 97], [97, 98], [99, 105], [106, 109], [110, 115], [116, 125], [126, 135], [135, 136]]}
{"doc_key": "ai-test-4", "ner": [[3, 4, "algorithm"], [6, 8, "algorithm"], [12, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 12, 12, "compare", "", false, false], [6, 8, 12, 12, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["W", "przeciwie\u0144stwie", "do", "sieci", "neuronowych", "i", "maszyny", "wektor\u00f3w", "wsparcia", ",", "proces", "szkolenia", "AdaBoost", "wybiera", "tylko", "te", "cechy", ",", "o", "kt\u00f3rych", "wiadomo", ",", "\u017ce", "poprawiaj\u0105", "moc", "predykcyjn\u0105", "modelu", ",", "zmniejszaj\u0105c", "wymiarowo\u015b\u0107", "i", "potencjalnie", "poprawiaj\u0105c", "czas", "wykonania", ",", "poniewa\u017c", "nieistotne", "cechy", "nie", "musz\u0105", "by\u0107", "obliczane", "."], "sentence-detokenized": "W przeciwie\u0144stwie do sieci neuronowych i maszyny wektor\u00f3w wsparcia, proces szkolenia AdaBoost wybiera tylko te cechy, o kt\u00f3rych wiadomo, \u017ce poprawiaj\u0105 moc predykcyjn\u0105 modelu, zmniejszaj\u0105c wymiarowo\u015b\u0107 i potencjalnie poprawiaj\u0105c czas wykonania, poniewa\u017c nieistotne cechy nie musz\u0105 by\u0107 obliczane.", "token2charspan": [[0, 1], [2, 17], [18, 20], [21, 26], [27, 38], [39, 40], [41, 48], [49, 57], [58, 66], [66, 67], [68, 74], [75, 84], [85, 93], [94, 101], [102, 107], [108, 110], [111, 116], [116, 117], [118, 119], [120, 127], [128, 135], [135, 136], [137, 139], [140, 150], [151, 154], [155, 166], [167, 173], [173, 174], [175, 187], [188, 199], [200, 201], [202, 214], [215, 226], [227, 231], [232, 241], [241, 242], [243, 251], [252, 262], [263, 268], [269, 272], [273, 278], [279, 282], [283, 292], [292, 293]]}
{"doc_key": "ai-test-5", "ner": [[0, 0, "misc"], [9, 10, "misc"], [11, 12, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 9, 10, "part-of", "", false, false], [9, 10, 11, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Troponimia", "jest", "jedn\u0105", "z", "mo\u017cliwych", "relacji", "mi\u0119dzy", "czasownikami", "w", "sieci", "semantycznej", "bazy", "WordNet", "."], "sentence-detokenized": "Troponimia jest jedn\u0105 z mo\u017cliwych relacji mi\u0119dzy czasownikami w sieci semantycznej bazy WordNet.", "token2charspan": [[0, 10], [11, 15], [16, 21], [22, 23], [24, 33], [34, 41], [42, 48], [49, 61], [62, 63], [64, 69], [70, 82], [83, 87], [88, 95], [95, 96]]}
{"doc_key": "ai-test-6", "ner": [[6, 7, "task"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 9, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["J\u0119zyk", "ramowy", "to", "technologia", "u\u017cywana", "do", "reprezentacji", "wiedzy", "w", "sztucznej", "inteligencji", "."], "sentence-detokenized": "J\u0119zyk ramowy to technologia u\u017cywana do reprezentacji wiedzy w sztucznej inteligencji.", "token2charspan": [[0, 5], [6, 12], [13, 15], [16, 27], [28, 35], [36, 38], [39, 52], [53, 59], [60, 61], [62, 71], [72, 84], [84, 85]]}
{"doc_key": "ai-test-7", "ner": [[0, 0, "metrics"], [5, 7, "metrics"], [10, 12, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 5, 7, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "r\u00f3\u017cni", "si\u0119", "r\u00f3wnie\u017c", "od", "Bilingual", "evaluation", "understudy", "w", "obliczaniu", "kary", "za", "zwi\u0119z\u0142o\u015b\u0107", ",", "poniewa\u017c", "ma\u0142e", "r\u00f3\u017cnice", "w", "d\u0142ugo\u015bci", "t\u0142umaczenia", "nie", "wp\u0142ywaj\u0105", "tak", "bardzo", "na", "og\u00f3lny", "wynik", "."], "sentence-detokenized": "NIST r\u00f3\u017cni si\u0119 r\u00f3wnie\u017c od Bilingual evaluation understudy w obliczaniu kary za zwi\u0119z\u0142o\u015b\u0107, poniewa\u017c ma\u0142e r\u00f3\u017cnice w d\u0142ugo\u015bci t\u0142umaczenia nie wp\u0142ywaj\u0105 tak bardzo na og\u00f3lny wynik.", "token2charspan": [[0, 4], [5, 10], [11, 14], [15, 22], [23, 25], [26, 35], [36, 46], [47, 57], [58, 59], [60, 70], [71, 75], [76, 78], [79, 88], [88, 89], [90, 98], [99, 103], [104, 111], [112, 113], [114, 122], [123, 134], [135, 138], [139, 147], [148, 151], [152, 158], [159, 161], [162, 168], [169, 174], [174, 175]]}
{"doc_key": "ai-test-8", "ner": [[13, 14, "algorithm"], [16, 18, "algorithm"], [29, 34, "field"], [42, 42, "algorithm"], [44, 46, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 14, 29, 34, "usage", "", false, false], [16, 18, 29, 34, "usage", "", false, false], [42, 42, 29, 34, "type-of", "", false, false], [44, 46, 29, 34, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Model", "jest", "wst\u0119pnie", "dopasowywany", "do", "zbioru", "danych", "treningowych", ",", "Model", "(", "np", ".", "sie\u0107", "neuronowa", "lub", "naiwny", "klasyfikator", "Bayesa", ")", "jest", "trenowany", "na", "zbiorze", "danych", "treningowych", "przy", "u\u017cyciu", "metody", "uczenia", "nadzorowanego", ",", "na", "przyk\u0142ad", "przy", "u\u017cyciu", "metod", "optymalizacji", ",", "takich", "jak", "zej\u015bcie", "gradientowe", "lub", "stochastyczne", "zej\u015bcie", "gradientowe", "."], "sentence-detokenized": "Model jest wst\u0119pnie dopasowywany do zbioru danych treningowych, Model (np. sie\u0107 neuronowa lub naiwny klasyfikator Bayesa) jest trenowany na zbiorze danych treningowych przy u\u017cyciu metody uczenia nadzorowanego, na przyk\u0142ad przy u\u017cyciu metod optymalizacji, takich jak zej\u015bcie gradientowe lub stochastyczne zej\u015bcie gradientowe.", "token2charspan": [[0, 5], [6, 10], [11, 19], [20, 32], [33, 35], [36, 42], [43, 49], [50, 62], [62, 63], [64, 69], [70, 71], [71, 73], [73, 74], [75, 79], [80, 89], [90, 93], [94, 100], [101, 113], [114, 120], [120, 121], [122, 126], [127, 136], [137, 139], [140, 147], [148, 154], [155, 167], [168, 172], [173, 179], [180, 186], [187, 194], [195, 208], [208, 209], [210, 212], [213, 221], [222, 226], [227, 233], [234, 239], [240, 253], [253, 254], [255, 261], [262, 265], [266, 273], [274, 285], [286, 289], [290, 303], [304, 311], [312, 323], [323, 324]]}
{"doc_key": "ai-test-9", "ner": [[0, 0, "product"], [7, 9, "task"], [11, 11, "task"], [13, 15, "task"], [17, 18, "task"], [25, 27, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 9, 0, 0, "usage", "", true, false], [11, 11, 0, 0, "usage", "", true, false], [13, 15, 0, 0, "usage", "", true, false], [17, 18, 0, 0, "usage", "", true, false], [25, 27, 0, 0, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["FrameNet", "zosta\u0142", "wykorzystany", "w", "takich", "zastosowaniach", "jak", "odpowiadanie", "na", "pytania", ",", "parafrazowanie", ",", "rozpoznawanie", "entailmentu", "tekstowego", "oraz", "ekstrakcja", "informacji", ",", "bezpo\u015brednio", "lub", "za", "pomoc\u0105", "narz\u0119dzi", "Semantic", "Role", "Labeling", "."], "sentence-detokenized": "FrameNet zosta\u0142 wykorzystany w takich zastosowaniach jak odpowiadanie na pytania, parafrazowanie, rozpoznawanie entailmentu tekstowego oraz ekstrakcja informacji, bezpo\u015brednio lub za pomoc\u0105 narz\u0119dzi Semantic Role Labeling.", "token2charspan": [[0, 8], [9, 15], [16, 28], [29, 30], [31, 37], [38, 52], [53, 56], [57, 69], [70, 72], [73, 80], [80, 81], [82, 96], [96, 97], [98, 111], [112, 123], [124, 134], [135, 139], [140, 150], [151, 161], [161, 162], [163, 175], [176, 179], [180, 182], [183, 189], [190, 198], [199, 207], [208, 212], [213, 221], [221, 222]]}
{"doc_key": "ai-test-10", "ner": [[7, 10, "field"], [12, 13, "misc"], [17, 17, "product"], [20, 21, "misc"], [25, 25, "product"], [28, 31, "field"], [33, 33, "product"], [36, 38, "misc"], [42, 42, "product"], [44, 44, "product"], [46, 46, "product"], [49, 50, "misc"], [54, 55, "product"], [57, 58, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[17, 17, 12, 13, "general-affiliation", "", false, false], [25, 25, 20, 21, "general-affiliation", "", false, false], [33, 33, 28, 31, "general-affiliation", "", false, false], [42, 42, 36, 38, "type-of", "", false, false], [44, 44, 36, 38, "type-of", "", false, false], [46, 46, 36, 38, "type-of", "", false, false], [54, 55, 49, 50, "general-affiliation", "", false, false], [57, 58, 49, 50, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Obejmowa\u0142oby", "to", "programy", "takie", "jak", "narz\u0119dzia", "do", "analizy", "i", "ekstrakcji", "danych", ",", "arkusze", "kalkulacyjne", "(", "np", ".", "Excel", ")", ",", "bazy", "danych", "(", "np", ".", "Access", ")", ",", "analizy", "statystyczne", "(", "np", ".", "SAS", ")", ",", "uog\u00f3lnione", "oprogramowanie", "audytowe", "(", "np", ".", "ACL", ",", "Arbutus", ",", "EAS", ")", ",", "business", "intelligence", "(", "np", ".", "Crystal", "Reports", "i", "Business", "Objects", ")", "itp", "."], "sentence-detokenized": "Obejmowa\u0142oby to programy takie jak narz\u0119dzia do analizy i ekstrakcji danych, arkusze kalkulacyjne (np. Excel), bazy danych (np. Access), analizy statystyczne (np. SAS), uog\u00f3lnione oprogramowanie audytowe (np. ACL, Arbutus, EAS), business intelligence (np. Crystal Reports i Business Objects) itp.", "token2charspan": [[0, 12], [13, 15], [16, 24], [25, 30], [31, 34], [35, 44], [45, 47], [48, 55], [56, 57], [58, 68], [69, 75], [75, 76], [77, 84], [85, 97], [98, 99], [99, 101], [101, 102], [103, 108], [108, 109], [109, 110], [111, 115], [116, 122], [123, 124], [124, 126], [126, 127], [128, 134], [134, 135], [135, 136], [137, 144], [145, 157], [158, 159], [159, 161], [161, 162], [163, 166], [166, 167], [167, 168], [169, 179], [180, 194], [195, 203], [204, 205], [205, 207], [207, 208], [209, 212], [212, 213], [214, 221], [221, 222], [223, 226], [226, 227], [227, 228], [229, 237], [238, 250], [251, 252], [252, 254], [254, 255], [256, 263], [264, 271], [272, 273], [274, 282], [283, 290], [290, 291], [292, 295], [295, 296]]}
{"doc_key": "ai-test-11", "ner": [[0, 2, "organisation"], [6, 7, "researcher"], [12, 12, "organisation"], [15, 16, "product"], [22, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 6, 7, "origin", "", false, false], [6, 7, 12, 12, "role", "", false, false], [15, 16, 22, 23, "type-of", "", false, false], [22, 23, 6, 7, "origin", "introduced_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Firma", "Rethink", "Robotics", "-", "za\u0142o\u017cona", "przez", "Rodneya", "Brooksa", ",", "wcze\u015bniej", "zwi\u0105zanego", "z", "iRobotem", "-", "zaprezentowa\u0142a", "Baxtera", "we", "wrze\u015bniu", "2012", "roku", ";", "jako", "robota", "przemys\u0142owego", "zaprojektowanego", "do", "bezpiecznej", "interakcji", "z", "s\u0105siaduj\u0105cymi", "pracownikami", "ludzkimi", "i", "daj\u0105cego", "si\u0119", "zaprogramowa\u0107", "do", "wykonywania", "prostych", "zada\u0144", "."], "sentence-detokenized": "Firma Rethink Robotics - za\u0142o\u017cona przez Rodneya Brooksa, wcze\u015bniej zwi\u0105zanego z iRobotem - zaprezentowa\u0142a Baxtera we wrze\u015bniu 2012 roku; jako robota przemys\u0142owego zaprojektowanego do bezpiecznej interakcji z s\u0105siaduj\u0105cymi pracownikami ludzkimi i daj\u0105cego si\u0119 zaprogramowa\u0107 do wykonywania prostych zada\u0144.", "token2charspan": [[0, 5], [6, 13], [14, 22], [23, 24], [25, 33], [34, 39], [40, 47], [48, 55], [55, 56], [57, 66], [67, 77], [78, 79], [80, 88], [89, 90], [91, 105], [106, 113], [114, 116], [117, 125], [126, 130], [131, 135], [135, 136], [137, 141], [142, 148], [149, 162], [163, 179], [180, 182], [183, 194], [195, 205], [206, 207], [208, 221], [222, 234], [235, 243], [244, 245], [246, 254], [255, 258], [259, 272], [273, 275], [276, 287], [288, 296], [297, 302], [302, 303]]}
{"doc_key": "ai-test-12", "ner": [[2, 3, "field"], [5, 6, "task"], [8, 9, "task"], [11, 14, "task"], [16, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 29, "task"], [37, 39, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 6, 2, 3, "part-of", "task_part_of_field", false, false], [8, 9, 2, 3, "part-of", "task_part_of_field", false, false], [11, 14, 2, 3, "part-of", "task_part_of_field", false, false], [16, 18, 2, 3, "part-of", "task_part_of_field", false, false], [20, 21, 2, 3, "part-of", "task_part_of_field", false, false], [23, 24, 2, 3, "part-of", "task_part_of_field", false, false], [26, 29, 2, 3, "part-of", "task_part_of_field", false, false], [37, 39, 2, 3, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Typowe", "zadania", "eksploracji", "tekstu", "obejmuj\u0105", "kategoryzacj\u0119", "tekstu", ",", "grupowanie", "tekstu", ",", "ekstrakcj\u0119", "poj\u0119\u0107", "/", "encji", ",", "tworzenie", "granularnych", "taksonomii", ",", "analiz\u0119", "sentymentu", ",", "streszczanie", "dokument\u00f3w", "i", "modelowanie", "relacji", "mi\u0119dzy", "podmiotami", "(", "tj", ".", "uczenie", "si\u0119", "relacji", "mi\u0119dzy", "rozpoznawaniem", "nazwanych", "podmiot\u00f3w", ")", "."], "sentence-detokenized": "Typowe zadania eksploracji tekstu obejmuj\u0105 kategoryzacj\u0119 tekstu, grupowanie tekstu, ekstrakcj\u0119 poj\u0119\u0107 / encji, tworzenie granularnych taksonomii, analiz\u0119 sentymentu, streszczanie dokument\u00f3w i modelowanie relacji mi\u0119dzy podmiotami (tj. uczenie si\u0119 relacji mi\u0119dzy rozpoznawaniem nazwanych podmiot\u00f3w).", "token2charspan": [[0, 6], [7, 14], [15, 26], [27, 33], [34, 42], [43, 56], [57, 63], [63, 64], [65, 75], [76, 82], [82, 83], [84, 94], [95, 100], [101, 102], [103, 108], [108, 109], [110, 119], [120, 132], [133, 143], [143, 144], [145, 152], [153, 163], [163, 164], [165, 177], [178, 188], [189, 190], [191, 202], [203, 210], [211, 217], [218, 228], [229, 230], [230, 232], [232, 233], [234, 241], [242, 245], [246, 253], [254, 260], [261, 275], [276, 285], [286, 295], [295, 296], [296, 297]]}
{"doc_key": "ai-test-13", "ner": [[5, 5, "metrics"], [8, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Niemniej", "jednak", ",", "stemming", "zmniejsza", "precyzj\u0119", ",", "czyli", "wska\u017anik", "TRUE", "negative", ",", "dla", "takich", "system\u00f3w", "."], "sentence-detokenized": "Niemniej jednak, stemming zmniejsza precyzj\u0119, czyli wska\u017anik TRUE negative, dla takich system\u00f3w.", "token2charspan": [[0, 8], [9, 15], [15, 16], [17, 25], [26, 35], [36, 44], [44, 45], [46, 51], [52, 60], [61, 65], [66, 74], [74, 75], [76, 79], [80, 86], [87, 95], [95, 96]]}
{"doc_key": "ai-test-14", "ner": [[2, 4, "task"], [7, 8, "misc"], [12, 13, "misc"], [23, 23, "product"], [25, 25, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 8, 2, 4, "temporal", "", false, false], [12, 13, 7, 8, "named", "", false, false], [23, 23, 7, 8, "usage", "", false, false], [25, 25, 7, 8, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Szczeg\u00f3lnym", "przypadkiem", "spottingu", "s\u0142\u00f3w", "kluczowych", "jest", "wykrywanie", "s\u0142owa", "budz\u0105cego", "(", "zwanego", "r\u00f3wnie\u017c", "gor\u0105cym", "s\u0142owem", ")", "u\u017cywanego", "przez", "osobistych", "asystent\u00f3w", "cyfrowych", ",", "takich", "jak", "Alexa", "lub", "Siri", ",", "aby", "obudzi\u0107", "si\u0119", ",", "gdy", "ich", "nazwa", "zostanie", "wypowiedziana", "."], "sentence-detokenized": "Szczeg\u00f3lnym przypadkiem spottingu s\u0142\u00f3w kluczowych jest wykrywanie s\u0142owa budz\u0105cego (zwanego r\u00f3wnie\u017c gor\u0105cym s\u0142owem) u\u017cywanego przez osobistych asystent\u00f3w cyfrowych, takich jak Alexa lub Siri, aby obudzi\u0107 si\u0119, gdy ich nazwa zostanie wypowiedziana.", "token2charspan": [[0, 11], [12, 23], [24, 33], [34, 38], [39, 49], [50, 54], [55, 65], [66, 71], [72, 81], [82, 83], [83, 90], [91, 98], [99, 106], [107, 113], [113, 114], [115, 124], [125, 130], [131, 141], [142, 152], [153, 162], [162, 163], [164, 170], [171, 174], [175, 180], [181, 184], [185, 189], [189, 190], [191, 194], [195, 202], [203, 206], [206, 207], [208, 211], [212, 215], [216, 221], [222, 230], [231, 244], [244, 245]]}
{"doc_key": "ai-test-15", "ner": [[0, 0, "programlang"], [9, 9, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 0, 0, "part-of", "", false, false], [11, 11, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prova", "to", "j\u0119zyk", "programowania", "open", "source", ",", "kt\u00f3ry", "\u0142\u0105czy", "Prolog", "z", "Jav\u0105", "."], "sentence-detokenized": "Prova to j\u0119zyk programowania open source, kt\u00f3ry \u0142\u0105czy Prolog z Jav\u0105.", "token2charspan": [[0, 5], [6, 8], [9, 14], [15, 28], [29, 33], [34, 40], [40, 41], [42, 47], [48, 53], [54, 60], [61, 62], [63, 67], [67, 68]]}
{"doc_key": "ai-test-16", "ner": [[4, 5, "organisation"], [10, 10, "organisation"], [17, 18, "product"], [29, 33, "country"], [36, 36, "organisation"], [49, 49, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 10, 10, "part-of", "", false, false], [4, 5, 10, 10, "role", "sells", false, false], [4, 5, 29, 33, "role", "sells_to", false, false], [36, 36, 49, 49, "opposite", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["W", "1987", "r", ".", "Tocibai", "Machine", ",", "sp\u00f3\u0142ka", "zale\u017cna", "firmy", "Toshiba", ",", "zosta\u0142a", "oskar\u017cona", "o", "nielegaln\u0105", "sprzeda\u017c", "frez\u00f3w", "CNC", "wykorzystywanych", "do", "produkcji", "bardzo", "cichych", "\u015bmigie\u0142", "do", "\u0142odzi", "podwodnych", "do", "Zwi\u0105zku", "Radzieckiego", ",", "co", "stanowi\u0142o", "naruszenie", "umowy", "CoCom", ",", "czyli", "mi\u0119dzynarodowego", "embarga", "na\u0142o\u017conego", "na", "niekt\u00f3re", "kraje", "na", "kraje", "nale\u017c\u0105ce", "do", "COMECON", "."], "sentence-detokenized": "W 1987 r. Tocibai Machine, sp\u00f3\u0142ka zale\u017cna firmy Toshiba, zosta\u0142a oskar\u017cona o nielegaln\u0105 sprzeda\u017c frez\u00f3w CNC wykorzystywanych do produkcji bardzo cichych \u015bmigie\u0142 do \u0142odzi podwodnych do Zwi\u0105zku Radzieckiego, co stanowi\u0142o naruszenie umowy CoCom, czyli mi\u0119dzynarodowego embarga na\u0142o\u017conego na niekt\u00f3re kraje na kraje nale\u017c\u0105ce do COMECON.", "token2charspan": [[0, 1], [2, 6], [7, 8], [8, 9], [10, 17], [18, 25], [25, 26], [27, 33], [34, 41], [42, 47], [48, 55], [55, 56], [57, 64], [65, 74], [75, 76], [77, 87], [88, 96], [97, 103], [104, 107], [108, 124], [125, 127], [128, 137], [138, 144], [145, 152], [153, 160], [161, 163], [164, 169], [170, 180], [181, 183], [184, 191], [192, 204], [204, 205], [206, 208], [209, 218], [219, 229], [230, 235], [236, 241], [241, 242], [243, 248], [249, 265], [266, 273], [274, 284], [285, 287], [288, 296], [297, 302], [303, 305], [306, 311], [312, 320], [321, 323], [324, 331], [331, 332]]}
{"doc_key": "ai-test-17", "ner": [[2, 2, "researcher"], [4, 7, "product"], [16, 20, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 7, 2, 2, "artifact", "", false, false], [4, 7, 16, 20, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Najs\u0142ynniejszy", "wynalazek", "Engelbergera", ",", "robotyczne", "rami\u0119", "przemys\u0142owe", "Unimate", ",", "znalaz\u0142", "si\u0119", "w\u015br\u00f3d", "pierwszych", "os\u00f3b", "wprowadzonych", "do", "Robot", "Hall", "of", "Fame", "w", "2003", "roku", "."], "sentence-detokenized": "Najs\u0142ynniejszy wynalazek Engelbergera, robotyczne rami\u0119 przemys\u0142owe Unimate, znalaz\u0142 si\u0119 w\u015br\u00f3d pierwszych os\u00f3b wprowadzonych do Robot Hall of Fame w 2003 roku.", "token2charspan": [[0, 14], [15, 24], [25, 37], [37, 38], [39, 49], [50, 55], [56, 67], [68, 75], [75, 76], [77, 84], [85, 88], [89, 94], [95, 105], [106, 110], [111, 124], [125, 127], [128, 133], [134, 138], [139, 141], [142, 146], [147, 148], [149, 153], [154, 158], [158, 159]]}
{"doc_key": "ai-test-18", "ner": [[6, 10, "misc"], [12, 15, "misc"], [17, 17, "person"], [24, 25, "field"], [22, 23, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 10, 12, 15, "usage", "", false, false], [17, 17, 24, 25, "role", "", false, false], [24, 25, 22, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Pierwotnie", "sterowanie", "odbywa\u0142o", "si\u0119", "za", "pomoc\u0105", "statycznych", "stron", "internetowych", "html", "z", "wykorzystaniem", "CGI", ".", "W", "ramach", "prac", "Daltona", "wprowadzono", "interfejs", "oparty", "na", "Javie", "z", "rozszerzon\u0105", "rzeczywisto\u015bci\u0105", ",", "kt\u00f3ry", "odni\u00f3s\u0142", "ograniczony", "sukces", "."], "sentence-detokenized": "Pierwotnie sterowanie odbywa\u0142o si\u0119 za pomoc\u0105 statycznych stron internetowych html z wykorzystaniem CGI. W ramach prac Daltona wprowadzono interfejs oparty na Javie z rozszerzon\u0105 rzeczywisto\u015bci\u0105, kt\u00f3ry odni\u00f3s\u0142 ograniczony sukces.", "token2charspan": [[0, 10], [11, 21], [22, 30], [31, 34], [35, 37], [38, 44], [45, 56], [57, 62], [63, 76], [77, 81], [82, 83], [84, 98], [99, 102], [102, 103], [104, 105], [106, 112], [113, 117], [118, 125], [126, 137], [138, 147], [148, 154], [155, 157], [158, 163], [164, 165], [166, 177], [178, 193], [193, 194], [195, 200], [201, 208], [209, 220], [221, 227], [227, 228]]}
{"doc_key": "ai-test-19", "ner": [[3, 6, "task"], [9, 9, "organisation"], [29, 29, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 6, 9, 9, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Pierwsza", "publikacja", "o", "specyfikacji", "LMF", "w", "wersji", "ratyfikowanej", "przez", "ISO", "(", "praca", "ta", "sta\u0142a", "si\u0119", "(", "w", "2015", "r", ".", ")", "9", ".", "najcz\u0119\u015bciej", "cytowan\u0105", "prac\u0105", "w", "ramach", "konferencji", "LREC", "z", "referat\u00f3w", "LREC", ")", ":"], "sentence-detokenized": "Pierwsza publikacja o specyfikacji LMF w wersji ratyfikowanej przez ISO (praca ta sta\u0142a si\u0119 (w 2015 r.) 9. najcz\u0119\u015bciej cytowan\u0105 prac\u0105 w ramach konferencji LREC z referat\u00f3w LREC):", "token2charspan": [[0, 8], [9, 19], [20, 21], [22, 34], [35, 38], [39, 40], [41, 47], [48, 61], [62, 67], [68, 71], [72, 73], [73, 78], [79, 81], [82, 87], [88, 91], [92, 93], [93, 94], [95, 99], [100, 101], [101, 102], [102, 103], [104, 105], [105, 106], [107, 118], [119, 127], [128, 133], [134, 135], [136, 142], [143, 154], [155, 159], [160, 161], [162, 171], [172, 176], [176, 177], [177, 178]]}
{"doc_key": "ai-test-20", "ner": [[0, 1, "metrics"], [12, 12, "metrics"], [13, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 12, 0, 1, "usage", "", false, false], [12, 12, 13, 16, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Macierz", "konfuzji", "lub", "macierz", "dopasowania", "jest", "cz\u0119sto", "u\u017cywana", "jako", "narz\u0119dzie", "do", "walidacji", "dok\u0142adno\u015bci", "klasyfikacji", "k", "-", "NN", "."], "sentence-detokenized": "Macierz konfuzji lub macierz dopasowania jest cz\u0119sto u\u017cywana jako narz\u0119dzie do walidacji dok\u0142adno\u015bci klasyfikacji k -NN.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 28], [29, 40], [41, 45], [46, 52], [53, 60], [61, 65], [66, 75], [76, 78], [79, 88], [89, 100], [101, 113], [114, 115], [116, 117], [117, 119], [119, 120]]}
{"doc_key": "ai-test-21", "ner": [[1, 1, "algorithm"], [12, 12, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 12, 12, "part-of", "", false, false], [1, 1, 14, 15, "part-of", "", false, false], [1, 1, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Uczenie", "drzew", "decyzyjnych", "jest", "jednym", "z", "podej\u015b\u0107", "do", "modelowania", "predykcyjnego", "stosowanym", "w", "statystyce", ",", "eksploracji", "danych", "i", "uczeniu", "maszynowym", "."], "sentence-detokenized": "Uczenie drzew decyzyjnych jest jednym z podej\u015b\u0107 do modelowania predykcyjnego stosowanym w statystyce, eksploracji danych i uczeniu maszynowym.", "token2charspan": [[0, 7], [8, 13], [14, 25], [26, 30], [31, 37], [38, 39], [40, 47], [48, 50], [51, 62], [63, 76], [77, 87], [88, 89], [90, 100], [100, 101], [102, 113], [114, 120], [121, 122], [123, 130], [131, 141], [141, 142]]}
{"doc_key": "ai-test-22", "ner": [[5, 5, "misc"], [16, 17, "field"], [21, 23, "algorithm"], [25, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 16, 17, "related-to", "", true, false], [21, 23, 16, 17, "type-of", "", false, false], [25, 25, 16, 17, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["W", "czasie", "pracy", ",", "docelowa", "prozodia", "zdania", "jest", "nak\u0142adana", "na", "te", "minimalne", "jednostki", "za", "pomoc\u0105", "technik", "przetwarzania", "sygna\u0142u", ",", "takich", "jak", "liniowe", "kodowanie", "predykcyjne", ",", "PSOLA"], "sentence-detokenized": "W czasie pracy, docelowa prozodia zdania jest nak\u0142adana na te minimalne jednostki za pomoc\u0105 technik przetwarzania sygna\u0142u, takich jak liniowe kodowanie predykcyjne, PSOLA", "token2charspan": [[0, 1], [2, 8], [9, 14], [14, 15], [16, 24], [25, 33], [34, 40], [41, 45], [46, 55], [56, 58], [59, 61], [62, 71], [72, 81], [82, 84], [85, 91], [92, 99], [100, 113], [114, 121], [121, 122], [123, 129], [130, 133], [134, 141], [142, 151], [152, 163], [163, 164], [165, 170]]}
{"doc_key": "ai-test-23", "ner": [[4, 5, "field"], [7, 8, "field"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 19, 4, 5, "usage", "", true, false], [18, 19, 7, 8, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["W", "tym", "podej\u015bciu", "wykorzystano", "sztuczn\u0105", "inteligencj\u0119", "i", "uczenie", "maszynowe", ",", "aby", "umo\u017cliwi\u0107", "badaczom", "widoczne", "por\u00f3wnanie", "konwencjonalnych", "i", "termicznych", "obraz\u00f3w", "twarzy", "."], "sentence-detokenized": "W tym podej\u015bciu wykorzystano sztuczn\u0105 inteligencj\u0119 i uczenie maszynowe, aby umo\u017cliwi\u0107 badaczom widoczne por\u00f3wnanie konwencjonalnych i termicznych obraz\u00f3w twarzy.", "token2charspan": [[0, 1], [2, 5], [6, 15], [16, 28], [29, 37], [38, 50], [51, 52], [53, 60], [61, 70], [70, 71], [72, 75], [76, 85], [86, 94], [95, 103], [104, 114], [115, 131], [132, 133], [134, 145], [146, 153], [154, 160], [160, 161]]}
{"doc_key": "ai-test-24", "ner": [[1, 1, "field"], [2, 3, "algorithm"], [7, 8, "task"], [10, 11, "misc"], [16, 17, "field"], [19, 20, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 1, 1, "part-of", "", false, false], [2, 3, 7, 8, "topic", "", false, false], [7, 8, 10, 11, "origin", "", false, false], [16, 17, 1, 1, "part-of", "", false, false], [16, 17, 2, 3, "topic", "", false, false], [19, 20, 1, 1, "part-of", "", false, false], [19, 20, 2, 3, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["W", "informatyce", "obliczenia", "ewolucyjne", "to", "rodzina", "algorytm\u00f3w", "globalnej", "optymalizacji", "inspirowanych", "ewolucj\u0105", "biologiczn\u0105", ",", "a", "tak\u017ce", "subdziedzina", "sztucznej", "inteligencji", "i", "soft", "computingu", "badaj\u0105ca", "te", "algorytmy", "."], "sentence-detokenized": "W informatyce obliczenia ewolucyjne to rodzina algorytm\u00f3w globalnej optymalizacji inspirowanych ewolucj\u0105 biologiczn\u0105, a tak\u017ce subdziedzina sztucznej inteligencji i soft computingu badaj\u0105ca te algorytmy.", "token2charspan": [[0, 1], [2, 13], [14, 24], [25, 35], [36, 38], [39, 46], [47, 57], [58, 67], [68, 81], [82, 95], [96, 104], [105, 116], [116, 117], [118, 119], [120, 125], [126, 138], [139, 148], [149, 161], [162, 163], [164, 168], [169, 179], [180, 188], [189, 191], [192, 201], [201, 202]]}
{"doc_key": "ai-test-25", "ner": [[8, 9, "metrics"], [11, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Na", "przyk\u0142ad", "mo\u017cna", "po\u0142\u0105czy\u0107", "jak\u0105\u015b", "miar\u0119", "opart\u0105", "na", "macierzy", "konfuzji", "ze", "\u015brednim", "b\u0142\u0119dem", "kwadratowym", "ocenianym", "mi\u0119dzy", "surowymi", "wyj\u015bciami", "modelu", "a", "rzeczywistymi", "warto\u015bciami", "."], "sentence-detokenized": "Na przyk\u0142ad mo\u017cna po\u0142\u0105czy\u0107 jak\u0105\u015b miar\u0119 opart\u0105 na macierzy konfuzji ze \u015brednim b\u0142\u0119dem kwadratowym ocenianym mi\u0119dzy surowymi wyj\u015bciami modelu a rzeczywistymi warto\u015bciami.", "token2charspan": [[0, 2], [3, 11], [12, 17], [18, 26], [27, 32], [33, 38], [39, 45], [46, 48], [49, 57], [58, 66], [67, 69], [70, 77], [78, 84], [85, 96], [97, 106], [107, 113], [114, 122], [123, 132], [133, 139], [140, 141], [142, 155], [156, 167], [167, 168]]}
{"doc_key": "ai-test-26", "ner": [[3, 3, "product"], [7, 7, "researcher"], [4, 4, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 7, 7, "origin", "", false, false], [3, 3, 4, 4, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Wi\u0119kszo\u015b\u0107", "to", "wyniki", "modelu", "word2vec", "opracowanego", "przez", "Mikolova", "i", "in", ".", "lub", "jego", "warianty", "."], "sentence-detokenized": "Wi\u0119kszo\u015b\u0107 to wyniki modelu word2vec opracowanego przez Mikolova i in. lub jego warianty.", "token2charspan": [[0, 9], [10, 12], [13, 19], [20, 26], [27, 35], [36, 48], [49, 54], [55, 63], [64, 65], [66, 68], [68, 69], [70, 73], [74, 78], [79, 87], [87, 88]]}
{"doc_key": "ai-test-27", "ner": [[10, 10, "conference"], [12, 16, "conference"], [18, 18, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 18, 12, 16, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["To", "w", "tym", "czasie", "\u0142\u0105cznie", "43", "publikacje", "zosta\u0142y", "uznane", "przez", "CVPR", "i", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "."], "sentence-detokenized": "To w tym czasie \u0142\u0105cznie 43 publikacje zosta\u0142y uznane przez CVPR i International Conference on Computer Vision (ICCV).", "token2charspan": [[0, 2], [3, 4], [5, 8], [9, 15], [16, 23], [24, 26], [27, 37], [38, 45], [46, 52], [53, 58], [59, 63], [64, 65], [66, 79], [80, 90], [91, 93], [94, 102], [103, 109], [110, 111], [111, 115], [115, 116], [116, 117]]}
{"doc_key": "ai-test-28", "ner": [[0, 0, "product"], [12, 13, "field"], [19, 20, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 12, 13, "general-affiliation", "platform_for_education_about", false, false], [19, 20, 0, 0, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["AIBO", "by\u0142", "cz\u0119sto", "u\u017cywany", "jako", "niedroga", "platforma", "do", "edukacji", "i", "bada\u0144", "nad", "sztuczn\u0105", "inteligencj\u0105", ",", "poniewa\u017c", "integruje", "komputer", ",", "wizj\u0119", "komputerow\u0105", "i", "artykulatory", "w", "pakiecie", "znacznie", "ta\u0144szym", "ni\u017c", "konwencjonalne", "roboty", "badawcze", "."], "sentence-detokenized": "AIBO by\u0142 cz\u0119sto u\u017cywany jako niedroga platforma do edukacji i bada\u0144 nad sztuczn\u0105 inteligencj\u0105, poniewa\u017c integruje komputer, wizj\u0119 komputerow\u0105 i artykulatory w pakiecie znacznie ta\u0144szym ni\u017c konwencjonalne roboty badawcze.", "token2charspan": [[0, 4], [5, 8], [9, 15], [16, 23], [24, 28], [29, 37], [38, 47], [48, 50], [51, 59], [60, 61], [62, 67], [68, 71], [72, 80], [81, 93], [93, 94], [95, 103], [104, 113], [114, 122], [122, 123], [124, 129], [130, 141], [142, 143], [144, 156], [157, 158], [159, 167], [168, 176], [177, 184], [185, 188], [189, 203], [204, 210], [211, 219], [219, 220]]}
{"doc_key": "ai-test-29", "ner": [[4, 10, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Pe\u0142ni\u0142a", "funkcj\u0119", "Program", "Chair", "konferencji", "International", "Conference", "on", "Computer", "Vision", "2021", "."], "sentence-detokenized": "Pe\u0142ni\u0142a funkcj\u0119 Program Chair konferencji International Conference on Computer Vision 2021.", "token2charspan": [[0, 7], [8, 15], [16, 23], [24, 29], [30, 41], [42, 55], [56, 66], [67, 69], [70, 78], [79, 85], [86, 90], [90, 91]]}
{"doc_key": "ai-test-30", "ner": [[0, 0, "researcher"], [6, 6, "organisation"], [15, 15, "organisation"], [20, 21, "organisation"], [32, 36, "product"], [38, 38, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 6, "role", "", false, false], [0, 0, 15, 15, "role", "", true, false], [15, 15, 20, 21, "role", "develops_with", false, false], [32, 36, 15, 15, "artifact", "", false, false], [38, 38, 32, 36, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Scheinman", ",", "po", "otrzymaniu", "stypendium", "od", "Unimation", "na", "rozw\u00f3j", "swoich", "projekt\u00f3w", ",", "sprzeda\u0142", "je", "firmie", "Unimation", ",", "kt\u00f3ra", "przy", "wsparciu", "General", "Motors", "dalej", "je", "rozwija\u0142a", ",", "a", "nast\u0119pnie", "wprowadzi\u0142a", "na", "rynek", "jako", "programowaln\u0105", "uniwersaln\u0105", "maszyn\u0119", "do", "monta\u017cu", "(", "PUMA", ")", "."], "sentence-detokenized": "Scheinman, po otrzymaniu stypendium od Unimation na rozw\u00f3j swoich projekt\u00f3w, sprzeda\u0142 je firmie Unimation, kt\u00f3ra przy wsparciu General Motors dalej je rozwija\u0142a, a nast\u0119pnie wprowadzi\u0142a na rynek jako programowaln\u0105 uniwersaln\u0105 maszyn\u0119 do monta\u017cu (PUMA).", "token2charspan": [[0, 9], [9, 10], [11, 13], [14, 24], [25, 35], [36, 38], [39, 48], [49, 51], [52, 58], [59, 65], [66, 75], [75, 76], [77, 85], [86, 88], [89, 95], [96, 105], [105, 106], [107, 112], [113, 117], [118, 126], [127, 134], [135, 141], [142, 147], [148, 150], [151, 160], [160, 161], [162, 163], [164, 173], [174, 185], [186, 188], [189, 194], [195, 199], [200, 213], [214, 225], [226, 233], [234, 236], [237, 244], [245, 246], [246, 250], [250, 251], [251, 252]]}
{"doc_key": "ai-test-31", "ner": [[5, 6, "task"], [4, 8, "task"], [10, 10, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 5, 6, "general-affiliation", "works_with", false, false], [10, 10, 4, 8, "general-affiliation", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Przegl\u0105d", "metod", "kalibracji", "dla", "zada\u0144", "klasyfikacji", "binarnej", "i", "wieloklasowej", "przedstawia", "Gebel", "(", "2009", ")"], "sentence-detokenized": "Przegl\u0105d metod kalibracji dla zada\u0144 klasyfikacji binarnej i wieloklasowej przedstawia Gebel (2009)", "token2charspan": [[0, 8], [9, 14], [15, 25], [26, 29], [30, 35], [36, 48], [49, 57], [58, 59], [60, 73], [74, 85], [86, 91], [92, 93], [93, 97], [97, 98]]}
{"doc_key": "ai-test-32", "ner": [[5, 7, "task"], [9, 9, "task"], [12, 13, "task"], [16, 17, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 5, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Zajmuje", "si\u0119", "takimi", "dziedzinami", "jak", "optyczne", "rozpoznawanie", "znak\u00f3w", "(", "OCR", ")", ",", "synteza", "mowy", ",", "technologia", "rozpoznawania", "mowy", "oraz", "elektroniczne", "instrumenty", "klawiszowe", "."], "sentence-detokenized": "Zajmuje si\u0119 takimi dziedzinami jak optyczne rozpoznawanie znak\u00f3w (OCR), synteza mowy, technologia rozpoznawania mowy oraz elektroniczne instrumenty klawiszowe.", "token2charspan": [[0, 7], [8, 11], [12, 18], [19, 30], [31, 34], [35, 43], [44, 57], [58, 64], [65, 66], [66, 69], [69, 70], [70, 71], [72, 79], [80, 84], [84, 85], [86, 97], [98, 111], [112, 116], [117, 121], [122, 135], [136, 147], [148, 158], [158, 159]]}
{"doc_key": "ai-test-33", "ner": [[9, 11, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["W", "przypadku", "nowszych", "i", "najnowocze\u015bniejszych", "technik", "mo\u017cna", "skorzysta\u0107", "z", "zestawu", "narz\u0119dzi", "Kaldi", "."], "sentence-detokenized": "W przypadku nowszych i najnowocze\u015bniejszych technik mo\u017cna skorzysta\u0107 z zestawu narz\u0119dzi Kaldi.", "token2charspan": [[0, 1], [2, 11], [12, 20], [21, 22], [23, 43], [44, 51], [52, 57], [58, 68], [69, 70], [71, 78], [79, 87], [88, 93], [93, 94]]}
{"doc_key": "ai-test-34", "ner": [[0, 0, "researcher"], [5, 7, "organisation"], [12, 17, "organisation"], [18, 19, "organisation"], [21, 22, "researcher"], [26, 36, "organisation"], [34, 34, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 5, 7, "role", "", false, false], [0, 0, 12, 17, "role", "", false, false], [0, 0, 18, 19, "role", "", false, false], [0, 0, 26, 36, "role", "", false, false], [0, 0, 34, 34, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Johnson-Laird", "jest", "Fellow", "of", "the", "American", "Philosophical", "Society", ",", "Fellow", "of", "the", "Royal", "Society", ",", "Fellow", "of", "the", "British", "Academy", ",", "William", "James", "Fellow", "of", "the", "Association", "for", "Psychological", "Science", "oraz", "Fellow", "of", "the", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Johnson-Laird jest Fellow of the American Philosophical Society, Fellow of the Royal Society, Fellow of the British Academy, William James Fellow of the Association for Psychological Science oraz Fellow of the Cognitive Science Society.", "token2charspan": [[0, 13], [14, 18], [19, 25], [26, 28], [29, 32], [33, 41], [42, 55], [56, 63], [63, 64], [65, 71], [72, 74], [75, 78], [79, 84], [85, 92], [92, 93], [94, 100], [101, 103], [104, 107], [108, 115], [116, 123], [123, 124], [125, 132], [133, 138], [139, 145], [146, 148], [149, 152], [153, 164], [165, 168], [169, 182], [183, 190], [191, 195], [196, 202], [203, 205], [206, 209], [210, 219], [220, 227], [228, 235], [235, 236]]}
{"doc_key": "ai-test-35", "ner": [[1, 6, "conference"], [9, 10, "researcher"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "algorithm"], [23, 27, "task"], [29, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 10, 1, 6, "physical", "", false, false], [9, 10, 1, 6, "temporal", "", false, false], [12, 13, 1, 6, "physical", "", false, false], [12, 13, 1, 6, "temporal", "", false, false], [15, 16, 1, 6, "physical", "", false, false], [15, 16, 1, 6, "temporal", "", false, false], [18, 19, 15, 16, "role", "extends", false, false], [23, 27, 15, 16, "role", "extends", false, false], [29, 29, 23, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Na", "Mi\u0119dzynarodowej", "Konferencji", "Przetwarzania", "Obraz\u00f3w", "IEEE", "w", "2010", "roku", "Rui", "Hu", ",", "Mark", "Banard", "i", "John", "Collomosse", "rozszerzyli", "deskryptor", "HOG", "do", "zastosowania", "w", "wyszukiwaniu", "obraz\u00f3w", "na", "podstawie", "szkicu", "(", "SBIR", ")", "."], "sentence-detokenized": "Na Mi\u0119dzynarodowej Konferencji Przetwarzania Obraz\u00f3w IEEE w 2010 roku Rui Hu, Mark Banard i John Collomosse rozszerzyli deskryptor HOG do zastosowania w wyszukiwaniu obraz\u00f3w na podstawie szkicu (SBIR).", "token2charspan": [[0, 2], [3, 18], [19, 30], [31, 44], [45, 52], [53, 57], [58, 59], [60, 64], [65, 69], [70, 73], [74, 76], [76, 77], [78, 82], [83, 89], [90, 91], [92, 96], [97, 107], [108, 119], [120, 130], [131, 134], [135, 137], [138, 150], [151, 152], [153, 165], [166, 173], [174, 176], [177, 186], [187, 193], [194, 195], [195, 199], [199, 200], [200, 201]]}
{"doc_key": "ai-test-36", "ner": [[0, 0, "metrics"], [4, 4, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 4, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["BLEU", "wykorzystuje", "zmodyfikowan\u0105", "form\u0119", "precyzji", "do", "por\u00f3wnania", "t\u0142umaczenia", "kandyduj\u0105cego", "z", "wieloma", "t\u0142umaczeniami", "referencyjnymi", "."], "sentence-detokenized": "BLEU wykorzystuje zmodyfikowan\u0105 form\u0119 precyzji do por\u00f3wnania t\u0142umaczenia kandyduj\u0105cego z wieloma t\u0142umaczeniami referencyjnymi.", "token2charspan": [[0, 4], [5, 17], [18, 31], [32, 37], [38, 46], [47, 49], [50, 60], [61, 72], [73, 86], [87, 88], [89, 96], [97, 110], [111, 125], [125, 126]]}
{"doc_key": "ai-test-37", "ner": [[35, 36, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Dla", "przypadku", "og\u00f3lnej", "przestrzeni", "bazowej", "math", "(", "Y", ",", "\u02d9", "mathcal", "{", "B", "}", ",", "\u02d9", "nu", ")", "/", "math", "(", "tzn", ".", "przestrzeni", "bazowej", ",", "kt\u00f3ra", "nie", "jest", "policzalna", ")", ",", "zwykle", "rozwa\u017ca", "si\u0119", "entropi\u0119", "wzgl\u0119dn\u0105", "."], "sentence-detokenized": "Dla przypadku og\u00f3lnej przestrzeni bazowej math (Y,\u02d9 mathcal {B},\u02d9 nu) / math (tzn. przestrzeni bazowej, kt\u00f3ra nie jest policzalna), zwykle rozwa\u017ca si\u0119 entropi\u0119 wzgl\u0119dn\u0105.", "token2charspan": [[0, 3], [4, 13], [14, 21], [22, 33], [34, 41], [42, 46], [47, 48], [48, 49], [49, 50], [50, 51], [52, 59], [60, 61], [61, 62], [62, 63], [63, 64], [64, 65], [66, 68], [68, 69], [70, 71], [72, 76], [77, 78], [78, 81], [81, 82], [83, 94], [95, 102], [102, 103], [104, 109], [110, 113], [114, 118], [119, 129], [129, 130], [130, 131], [132, 138], [139, 146], [147, 150], [151, 159], [160, 168], [168, 169]]}
{"doc_key": "ai-test-38", "ner": [[12, 13, "country"], [9, 11, "organisation"], [15, 15, "organisation"], [18, 18, "country"], [19, 20, "organisation"], [22, 22, "organisation"], [25, 27, "organisation"], [29, 29, "country"], [30, 35, "organisation"], [37, 37, "organisation"], [45, 45, "misc"], [43, 44, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[9, 11, 12, 13, "physical", "", false, false], [15, 15, 9, 11, "named", "", false, false], [19, 20, 18, 18, "physical", "", false, false], [22, 22, 19, 20, "named", "", false, false], [30, 35, 29, 29, "physical", "", false, false], [37, 37, 30, 35, "named", "", false, false], [45, 45, 43, 44, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Od", "pa\u017adziernika", "2011", "roku", ",", "istniej\u0105ce", "ju\u017c", "partnerstwo", "z", "Narodow\u0105", "S\u0142u\u017cb\u0105", "Park\u00f3w", "Stan\u00f3w", "Zjednoczonych", "(", "NPS", ")", ",", "brytyjsk\u0105", "Historyczn\u0105", "Szkocj\u0105", "(", "HS", ")", ",", "World", "Monuments", "Fund", "oraz", "meksyka\u0144skim", "Instituto", "Nacional", "de", "Antropolog\u00eda", "y", "Historia", "(", "INAH", ")", "zosta\u0142o", "znacznie", "rozszerzone", ",", "strona", "internetowa", "CyArk"], "sentence-detokenized": "Od pa\u017adziernika 2011 roku, istniej\u0105ce ju\u017c partnerstwo z Narodow\u0105 S\u0142u\u017cb\u0105 Park\u00f3w Stan\u00f3w Zjednoczonych (NPS), brytyjsk\u0105 Historyczn\u0105 Szkocj\u0105 (HS), World Monuments Fund oraz meksyka\u0144skim Instituto Nacional de Antropolog\u00eda y Historia (INAH) zosta\u0142o znacznie rozszerzone, strona internetowa CyArk", "token2charspan": [[0, 2], [3, 15], [16, 20], [21, 25], [25, 26], [27, 37], [38, 41], [42, 53], [54, 55], [56, 64], [65, 71], [72, 78], [79, 85], [86, 99], [100, 101], [101, 104], [104, 105], [105, 106], [107, 116], [117, 128], [129, 136], [137, 138], [138, 140], [140, 141], [141, 142], [143, 148], [149, 158], [159, 163], [164, 168], [169, 181], [182, 191], [192, 200], [201, 203], [204, 216], [217, 218], [219, 227], [228, 229], [229, 233], [233, 234], [235, 242], [243, 251], [252, 263], [263, 264], [265, 271], [272, 283], [284, 289]]}
{"doc_key": "ai-test-39", "ner": [[0, 1, "algorithm"], [9, 10, "field"], [14, 14, "product"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 14, 14, "part-of", "", false, false], [0, 1, 16, 16, "part-of", "", false, false], [14, 14, 9, 10, "general-affiliation", "", false, false], [16, 16, 9, 10, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kernel", "SVM", "s\u0105", "dost\u0119pne", "w", "wielu", "zestawach", "narz\u0119dzi", "do", "uczenia", "maszynowego", ",", "w", "tym", "LIBSVM", ",", "MATLAB", "i", "innych", "."], "sentence-detokenized": "Kernel SVM s\u0105 dost\u0119pne w wielu zestawach narz\u0119dzi do uczenia maszynowego, w tym LIBSVM, MATLAB i innych.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 22], [23, 24], [25, 30], [31, 40], [41, 49], [50, 52], [53, 60], [61, 72], [72, 73], [74, 75], [76, 79], [80, 86], [86, 87], [88, 94], [95, 96], [97, 103], [103, 104]]}
{"doc_key": "ai-test-40", "ner": [[0, 3, "misc"], [11, 12, "location"], [14, 14, "location"], [15, 16, "country"], [19, 21, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 11, 12, "physical", "", false, false], [0, 3, 19, 21, "temporal", "", false, false], [11, 12, 14, 14, "physical", "", false, false], [14, 14, 15, 16, "physical", "", false, false], [19, 21, 11, 12, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Konkurs", "o", "Nagrod\u0119", "Loebnera", "2009", "odby\u0142", "si\u0119", "6", "wrze\u015bnia", "2009", "w", "Brighton", "Centre", ",", "Brighton", "UK", "w", "po\u0142\u0105czeniu", "z", "konferencj\u0105", "Interspeech", "2009", "."], "sentence-detokenized": "Konkurs o Nagrod\u0119 Loebnera 2009 odby\u0142 si\u0119 6 wrze\u015bnia 2009 w Brighton Centre, Brighton UK w po\u0142\u0105czeniu z konferencj\u0105 Interspeech 2009.", "token2charspan": [[0, 7], [8, 9], [10, 17], [18, 26], [27, 31], [32, 37], [38, 41], [42, 43], [44, 52], [53, 57], [58, 59], [60, 68], [69, 75], [75, 76], [77, 85], [86, 88], [89, 90], [91, 101], [102, 103], [104, 115], [116, 127], [128, 132], [132, 133]]}
{"doc_key": "ai-test-41", "ner": [[1, 2, "product"], [7, 7, "product"], [16, 16, "product"], [14, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 17, 1, 2, "part-of", "", false, false], [14, 17, 7, 7, "part-of", "", false, false], [14, 17, 16, 16, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Humanoidalny", "robot", "QRIO", "zosta\u0142", "zaprojektowany", "jako", "nast\u0119pca", "AIBO", "i", "dzia\u0142a", "na", "tym", "samym", "bazowym", "systemie", "operacyjnym", "R-CODE", "Aperios", "."], "sentence-detokenized": "Humanoidalny robot QRIO zosta\u0142 zaprojektowany jako nast\u0119pca AIBO i dzia\u0142a na tym samym bazowym systemie operacyjnym R-CODE Aperios.", "token2charspan": [[0, 12], [13, 18], [19, 23], [24, 30], [31, 45], [46, 50], [51, 59], [60, 64], [65, 66], [67, 73], [74, 76], [77, 80], [81, 86], [87, 94], [95, 103], [104, 115], [116, 122], [123, 130], [130, 131]]}
{"doc_key": "ai-test-42", "ner": [[0, 1, "misc"], [6, 7, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 0, 1, "cause-effect", "", true, false], [11, 12, 0, 1, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Przebiegi", "mowy", "s\u0105", "generowane", "z", "samych", "HMM", "w", "oparciu", "o", "kryterium", "maksymalnego", "prawdopodobie\u0144stwa", "."], "sentence-detokenized": "Przebiegi mowy s\u0105 generowane z samych HMM w oparciu o kryterium maksymalnego prawdopodobie\u0144stwa.", "token2charspan": [[0, 9], [10, 14], [15, 17], [18, 28], [29, 30], [31, 37], [38, 41], [42, 43], [44, 51], [52, 53], [54, 63], [64, 76], [77, 95], [95, 96]]}
{"doc_key": "ai-test-43", "ner": [[0, 1, "product"], [4, 8, "task"], [10, 12, "task"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 8, "type-of", "", false, false], [0, 1, 10, 12, "type-of", "", false, false], [0, 1, 15, 15, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Google", "Translate", "to", "darmowa", "wieloj\u0119zyczna", "us\u0142uga", "statystycznego", "t\u0142umaczenia", "maszynowego", "i", "neuronowego", "t\u0142umaczenia", "maszynowego", "opracowana", "przez", "Google", ",", "s\u0142u\u017c\u0105ca", "do", "t\u0142umaczenia", "tekstu", "i", "stron", "internetowych", "z", "jednego", "j\u0119zyka", "na", "drugi", "."], "sentence-detokenized": "Google Translate to darmowa wieloj\u0119zyczna us\u0142uga statystycznego t\u0142umaczenia maszynowego i neuronowego t\u0142umaczenia maszynowego opracowana przez Google, s\u0142u\u017c\u0105ca do t\u0142umaczenia tekstu i stron internetowych z jednego j\u0119zyka na drugi.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 27], [28, 41], [42, 48], [49, 63], [64, 75], [76, 87], [88, 89], [90, 101], [102, 113], [114, 125], [126, 136], [137, 142], [143, 149], [149, 150], [151, 158], [159, 161], [162, 173], [174, 180], [181, 182], [183, 188], [189, 202], [203, 204], [205, 212], [213, 219], [220, 222], [223, 228], [228, 229]]}
{"doc_key": "ai-test-44", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 12, "field"], [14, 17, "field"], [21, 23, "task"], [26, 27, "task"], [29, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[21, 23, 5, 6, "part-of", "", false, true], [21, 23, 8, 9, "part-of", "", false, true], [21, 23, 11, 12, "part-of", "", false, true], [26, 27, 5, 6, "part-of", "", false, true], [26, 27, 8, 9, "part-of", "", false, true], [26, 27, 11, 12, "part-of", "", false, true], [29, 32, 5, 6, "part-of", "", false, true], [29, 32, 8, 9, "part-of", "", false, true], [29, 32, 11, 12, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Szkielety", "s\u0105", "szeroko", "stosowane", "w", "wizji", "komputerowej", ",", "analizie", "obrazu", ",", "rozpoznawaniu", "wzorc\u00f3w", "i", "przetwarzaniu", "obraz\u00f3w", "cyfrowych", "w", "celach", "takich", "jak", "optyczne", "rozpoznawanie", "znak\u00f3w", ",", "rozpoznawanie", "odcisk\u00f3w", "palc\u00f3w", ",", "inspekcja", "wizualna", "lub", "kompresja", "."], "sentence-detokenized": "Szkielety s\u0105 szeroko stosowane w wizji komputerowej, analizie obrazu, rozpoznawaniu wzorc\u00f3w i przetwarzaniu obraz\u00f3w cyfrowych w celach takich jak optyczne rozpoznawanie znak\u00f3w, rozpoznawanie odcisk\u00f3w palc\u00f3w, inspekcja wizualna lub kompresja.", "token2charspan": [[0, 9], [10, 12], [13, 20], [21, 30], [31, 32], [33, 38], [39, 51], [51, 52], [53, 61], [62, 68], [68, 69], [70, 83], [84, 91], [92, 93], [94, 107], [108, 115], [116, 125], [126, 127], [128, 134], [135, 141], [142, 145], [146, 154], [155, 168], [169, 175], [175, 176], [177, 190], [191, 199], [200, 206], [206, 207], [208, 217], [218, 226], [227, 230], [231, 240], [240, 241]]}
{"doc_key": "ai-test-45", "ner": [[0, 5, "conference"], [9, 12, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 5, 9, 12, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "to", "benchmark", "w", "klasyfikacji", "i", "detekcji", "obiekt\u00f3w", ",", "z", "milionami", "obraz\u00f3w", "i", "setkami", "klas", "obiekt\u00f3w", "."], "sentence-detokenized": "ImageNet Large Scale Visual Recognition Challenge to benchmark w klasyfikacji i detekcji obiekt\u00f3w, z milionami obraz\u00f3w i setkami klas obiekt\u00f3w.", "token2charspan": [[0, 8], [9, 14], [15, 20], [21, 27], [28, 39], [40, 49], [50, 52], [53, 62], [63, 64], [65, 77], [78, 79], [80, 88], [89, 97], [97, 98], [99, 100], [101, 110], [111, 118], [119, 120], [121, 128], [129, 133], [134, 142], [142, 143]]}
{"doc_key": "ai-test-46", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [15, 17, "misc"], [19, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 15, 17, "part-of", "", false, false], [0, 0, 19, 22, "part-of", "", false, false], [4, 5, 15, 17, "part-of", "", false, false], [4, 5, 19, 22, "part-of", "", false, false], [7, 8, 15, 17, "part-of", "", false, false], [7, 8, 19, 22, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Bengio", ",", "wraz", "z", "Geoffreyem", "Hintonem", "i", "Yannem", "LeCunem", ",", "jest", "przez", "niekt\u00f3rych", "okre\u015blany", "mianem", "ojc\u00f3w", "chrzestnych", "AI", "i", "ojc\u00f3w", "chrzestnych", "Deep", "Learningu", "."], "sentence-detokenized": "Bengio, wraz z Geoffreyem Hintonem i Yannem LeCunem, jest przez niekt\u00f3rych okre\u015blany mianem ojc\u00f3w chrzestnych AI i ojc\u00f3w chrzestnych Deep Learningu.", "token2charspan": [[0, 6], [6, 7], [8, 12], [13, 14], [15, 25], [26, 34], [35, 36], [37, 43], [44, 51], [51, 52], [53, 57], [58, 63], [64, 74], [75, 84], [85, 91], [92, 97], [98, 109], [110, 112], [113, 114], [115, 120], [121, 132], [133, 137], [138, 147], [147, 148]]}
{"doc_key": "ai-test-47", "ner": [[4, 4, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Jest", "Life", "Fellow", "of", "IEEE", "."], "sentence-detokenized": "Jest Life Fellow of IEEE.", "token2charspan": [[0, 4], [5, 9], [10, 16], [17, 19], [20, 24], [24, 25]]}
{"doc_key": "ai-test-48", "ner": [[0, 1, "organisation"], [13, 18, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 13, 18, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NSA", "Bethesda", "jest", "odpowiedzialna", "za", "wsparcie", "operacyjne", "bazy", "dla", "jej", "g\u0142\u00f3wnego", "najemcy", "-", "Walter", "Reed", "National", "Military", "Medical", "Center", "."], "sentence-detokenized": "NSA Bethesda jest odpowiedzialna za wsparcie operacyjne bazy dla jej g\u0142\u00f3wnego najemcy - Walter Reed National Military Medical Center.", "token2charspan": [[0, 3], [4, 12], [13, 17], [18, 32], [33, 35], [36, 44], [45, 55], [56, 60], [61, 64], [65, 68], [69, 77], [78, 85], [86, 87], [88, 94], [95, 99], [100, 108], [109, 117], [118, 125], [126, 132], [132, 133]]}
{"doc_key": "ai-test-49", "ner": [[7, 7, "field"], [10, 11, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Trzy", "g\u0142\u00f3wne", "paradygmaty", "uczenia", "si\u0119", "to", "uczenie", "nadzorowane", ",", "uczenie", "bez", "nadzoru", "i", "uczenie", "wzmacniaj\u0105ce", "."], "sentence-detokenized": "Trzy g\u0142\u00f3wne paradygmaty uczenia si\u0119 to uczenie nadzorowane, uczenie bez nadzoru i uczenie wzmacniaj\u0105ce.", "token2charspan": [[0, 4], [5, 11], [12, 23], [24, 31], [32, 35], [36, 38], [39, 46], [47, 58], [58, 59], [60, 67], [68, 71], [72, 79], [80, 81], [82, 89], [90, 102], [102, 103]]}
{"doc_key": "ai-test-50", "ner": [[2, 2, "task"], [4, 6, "task"], [10, 15, "task"], [17, 19, "task"], [21, 23, "task"], [26, 26, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Przyk\u0142ady", "obejmuj\u0105", "kontrol\u0119", ",", "planowanie", "i", "harmonogramy", ",", "zdolno\u015b\u0107", "do", "odpowiadania", "na", "pytania", "diagnostyczne", "i", "konsumenckie", ",", "rozpoznawanie", "pisma", "r\u0119cznego", ",", "rozumienie", "j\u0119zyka", "naturalnego", ",", "rozpoznawanie", "mowy", "i", "rozpoznawanie", "twarzy", "."], "sentence-detokenized": "Przyk\u0142ady obejmuj\u0105 kontrol\u0119, planowanie i harmonogramy, zdolno\u015b\u0107 do odpowiadania na pytania diagnostyczne i konsumenckie, rozpoznawanie pisma r\u0119cznego, rozumienie j\u0119zyka naturalnego, rozpoznawanie mowy i rozpoznawanie twarzy.", "token2charspan": [[0, 9], [10, 18], [19, 27], [27, 28], [29, 39], [40, 41], [42, 54], [54, 55], [56, 64], [65, 67], [68, 80], [81, 83], [84, 91], [92, 105], [106, 107], [108, 120], [120, 121], [122, 135], [136, 141], [142, 150], [150, 151], [152, 162], [163, 169], [170, 181], [181, 182], [183, 196], [197, 201], [202, 203], [204, 217], [218, 224], [224, 225]]}
{"doc_key": "ai-test-51", "ner": [[7, 13, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["W", "1991", "roku", "zosta\u0142", "wybrany", "na", "fellow", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "1990", ",", "founding", "fellow", ")", "."], "sentence-detokenized": "W 1991 roku zosta\u0142 wybrany na fellow Association for the Advancement of Artificial Intelligence (1990, founding fellow).", "token2charspan": [[0, 1], [2, 6], [7, 11], [12, 18], [19, 26], [27, 29], [30, 36], [37, 48], [49, 52], [53, 56], [57, 68], [69, 71], [72, 82], [83, 95], [96, 97], [97, 101], [101, 102], [103, 111], [112, 118], [118, 119], [119, 120]]}
{"doc_key": "ai-test-52", "ner": [[5, 6, "misc"], [9, 10, "algorithm"], [20, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Jednak", "formu\u0142uj\u0105c", "problem", "jako", "rozwi\u0105zanie", "macierzy", "Toeplitza", "i", "stosuj\u0105c", "rekurencj\u0119", "Levinsona", ",", "mo\u017cemy", "stosunkowo", "szybko", "oszacowa\u0107", "filtr", "z", "najmniejszym", "mo\u017cliwym", "b\u0142\u0119dem", "\u015bredniokwadratowym", "."], "sentence-detokenized": "Jednak formu\u0142uj\u0105c problem jako rozwi\u0105zanie macierzy Toeplitza i stosuj\u0105c rekurencj\u0119 Levinsona, mo\u017cemy stosunkowo szybko oszacowa\u0107 filtr z najmniejszym mo\u017cliwym b\u0142\u0119dem \u015bredniokwadratowym.", "token2charspan": [[0, 6], [7, 17], [18, 25], [26, 30], [31, 42], [43, 51], [52, 61], [62, 63], [64, 72], [73, 83], [84, 93], [93, 94], [95, 101], [102, 112], [113, 119], [120, 129], [130, 135], [136, 137], [138, 150], [151, 159], [160, 166], [167, 185], [185, 186]]}
{"doc_key": "ai-test-53", "ner": [[14, 18, "conference"], [5, 9, "location"], [11, 13, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 18, 5, 9, "physical", "", false, false], [5, 9, 11, 13, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["W", "lipcu", "2011", "roku", "w", "City", "of", "Arts", "and", "Sciences", "w", "Walencji", "odb\u0119dzie", "si\u0119", "15", "edycja", "Campus", "Party", "Spain", "."], "sentence-detokenized": "W lipcu 2011 roku w City of Arts and Sciences w Walencji odb\u0119dzie si\u0119 15 edycja Campus Party Spain.", "token2charspan": [[0, 1], [2, 7], [8, 12], [13, 17], [18, 19], [20, 24], [25, 27], [28, 32], [33, 36], [37, 45], [46, 47], [48, 56], [57, 65], [66, 69], [70, 72], [73, 79], [80, 86], [87, 92], [93, 98], [98, 99]]}
{"doc_key": "ai-test-54", "ner": [[15, 15, "product"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Cz\u0119sto", "jest", "to", "mo\u017cliwe", "na", "og\u00f3\u0142", "tylko", "na", "samym", "ko\u0144cu", "skomplikowanych", "gier", ",", "takich", "jak", "szachy", "lub", "go", ",", "poniewa\u017c", "nie", "jest", "obliczeniowo", "wykonalne", ",", "aby", "spojrze\u0107", "w", "przysz\u0142o\u015b\u0107", "tak", "daleko", ",", "jak", "zako\u0144czenie", "gry", ",", "z", "wyj\u0105tkiem", "pod", "koniec", ",", "a", "zamiast", "tego", "pozycje", "otrzymuj\u0105", "sko\u0144czone", "warto\u015bci", "jako", "szacunki", "stopnia", "wiary", ",", "\u017ce", "doprowadz\u0105", "do", "zwyci\u0119stwa", "dla", "jednego", "lub", "drugiego", "gracza", "."], "sentence-detokenized": "Cz\u0119sto jest to mo\u017cliwe na og\u00f3\u0142 tylko na samym ko\u0144cu skomplikowanych gier, takich jak szachy lub go, poniewa\u017c nie jest obliczeniowo wykonalne, aby spojrze\u0107 w przysz\u0142o\u015b\u0107 tak daleko, jak zako\u0144czenie gry, z wyj\u0105tkiem pod koniec, a zamiast tego pozycje otrzymuj\u0105 sko\u0144czone warto\u015bci jako szacunki stopnia wiary, \u017ce doprowadz\u0105 do zwyci\u0119stwa dla jednego lub drugiego gracza.", "token2charspan": [[0, 6], [7, 11], [12, 14], [15, 22], [23, 25], [26, 30], [31, 36], [37, 39], [40, 45], [46, 51], [52, 67], [68, 72], [72, 73], [74, 80], [81, 84], [85, 91], [92, 95], [96, 98], [98, 99], [100, 108], [109, 112], [113, 117], [118, 130], [131, 140], [140, 141], [142, 145], [146, 154], [155, 156], [157, 167], [168, 171], [172, 178], [178, 179], [180, 183], [184, 195], [196, 199], [199, 200], [201, 202], [203, 212], [213, 216], [217, 223], [223, 224], [225, 226], [227, 234], [235, 239], [240, 247], [248, 257], [258, 267], [268, 276], [277, 281], [282, 290], [291, 298], [299, 304], [304, 305], [306, 308], [309, 319], [320, 322], [323, 333], [334, 337], [338, 345], [346, 349], [350, 358], [359, 365], [365, 366]]}
{"doc_key": "ai-test-55", "ner": [[2, 4, "algorithm"], [21, 22, "algorithm"], [24, 26, "algorithm"], [28, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 4, 21, 22, "compare", "", false, false], [2, 4, 24, 26, "compare", "", false, false], [2, 4, 28, 30, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["R\u00f3\u017cnica", "mi\u0119dzy", "wielomianowym", "modelem", "logitowym", "a", "licznymi", "innymi", "metodami", ",", "modelami", ",", "algorytmami", "itp", ".", "o", "tej", "samej", "podstawowej", "konfiguracji", "(", "algorytm", "perceptronowy", ",", "maszyny", "wektor\u00f3w", "wsparcia", ",", "liniowa", "analiza", "dyskryminacyjna", "itp", "."], "sentence-detokenized": "R\u00f3\u017cnica mi\u0119dzy wielomianowym modelem logitowym a licznymi innymi metodami, modelami, algorytmami itp. o tej samej podstawowej konfiguracji (algorytm perceptronowy, maszyny wektor\u00f3w wsparcia, liniowa analiza dyskryminacyjna itp.", "token2charspan": [[0, 7], [8, 14], [15, 28], [29, 36], [37, 46], [47, 48], [49, 57], [58, 64], [65, 73], [73, 74], [75, 83], [83, 84], [85, 96], [97, 100], [100, 101], [102, 103], [104, 107], [108, 113], [114, 125], [126, 138], [139, 140], [140, 148], [149, 162], [162, 163], [164, 171], [172, 180], [181, 189], [189, 190], [191, 198], [199, 206], [207, 222], [223, 226], [226, 227]]}
{"doc_key": "ai-test-56", "ner": [[0, 3, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Association", "for", "Computational", "Linguistics", ",", "opublikowane", "przez"], "sentence-detokenized": "Association for Computational Linguistics, opublikowane przez", "token2charspan": [[0, 11], [12, 15], [16, 29], [30, 41], [41, 42], [43, 55], [56, 61]]}
{"doc_key": "ai-test-57", "ner": [[2, 4, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["W", "komputerowym", "systemie", "rozpoznawania", "twarzy", "ka\u017cda", "twarz", "jest", "reprezentowana", "przez", "du\u017c\u0105", "liczb\u0119", "warto\u015bci", "pikseli", "."], "sentence-detokenized": "W komputerowym systemie rozpoznawania twarzy ka\u017cda twarz jest reprezentowana przez du\u017c\u0105 liczb\u0119 warto\u015bci pikseli.", "token2charspan": [[0, 1], [2, 14], [15, 23], [24, 37], [38, 44], [45, 50], [51, 56], [57, 61], [62, 76], [77, 82], [83, 87], [88, 94], [95, 103], [104, 111], [111, 112]]}
{"doc_key": "ai-test-58", "ner": [[6, 7, "person"], [12, 14, "organisation"], [20, 20, "country"], [24, 25, "person"], [33, 35, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 7, 12, 14, "role", "", false, false], [6, 7, 20, 20, "physical", "", false, false], [24, 25, 33, 35, "origin", "", false, false], [24, 25, 33, 35, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["W", "2002", "roku", "jego", "syn", ",", "Daniel", "Pearl", ",", "dziennikarz", "pracuj\u0105cy", "dla", "Wall", "Street", "Journal", "zosta\u0142", "porwany", "i", "zamordowany", "w", "Pakistanie", ",", "co", "sk\u0142oni\u0142o", "Jude\u0119", "i", "pozosta\u0142ych", "cz\u0142onk\u00f3w", "rodziny", "oraz", "przyjaci\u00f3\u0142", "do", "stworzenia", "Fundacji", "Daniela", "Pearla", "."], "sentence-detokenized": "W 2002 roku jego syn, Daniel Pearl, dziennikarz pracuj\u0105cy dla Wall Street Journal zosta\u0142 porwany i zamordowany w Pakistanie, co sk\u0142oni\u0142o Jude\u0119 i pozosta\u0142ych cz\u0142onk\u00f3w rodziny oraz przyjaci\u00f3\u0142 do stworzenia Fundacji Daniela Pearla.", "token2charspan": [[0, 1], [2, 6], [7, 11], [12, 16], [17, 20], [20, 21], [22, 28], [29, 34], [34, 35], [36, 47], [48, 57], [58, 61], [62, 66], [67, 73], [74, 81], [82, 88], [89, 96], [97, 98], [99, 110], [111, 112], [113, 123], [123, 124], [125, 127], [128, 136], [137, 142], [143, 144], [145, 156], [157, 165], [166, 173], [174, 178], [179, 189], [190, 192], [193, 203], [204, 212], [213, 220], [221, 227], [227, 228]]}
{"doc_key": "ai-test-59", "ner": [[4, 6, "organisation"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 18, 19, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Od", "ko\u0144ca", "2006", "roku", "Red", "Envelope", "Entertainment", "rozszerzy\u0142o", "swoj\u0105", "dzia\u0142alno\u015b\u0107", "o", "produkcj\u0119", "oryginalnych", "tre\u015bci", "z", "takimi", "tw\u00f3rcami", "jak", "John", "Waters", "."], "sentence-detokenized": "Od ko\u0144ca 2006 roku Red Envelope Entertainment rozszerzy\u0142o swoj\u0105 dzia\u0142alno\u015b\u0107 o produkcj\u0119 oryginalnych tre\u015bci z takimi tw\u00f3rcami jak John Waters.", "token2charspan": [[0, 2], [3, 8], [9, 13], [14, 18], [19, 22], [23, 31], [32, 45], [46, 57], [58, 63], [64, 75], [76, 77], [78, 87], [88, 100], [101, 107], [108, 109], [110, 116], [117, 125], [126, 129], [130, 134], [135, 141], [141, 142]]}
{"doc_key": "ai-test-60", "ner": [[4, 8, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Budynek", "jest", "obecnie", "cz\u0119\u015bci\u0105", "Beth", "Israel", "Deaconess", "Medical", "Center", "."], "sentence-detokenized": "Budynek jest obecnie cz\u0119\u015bci\u0105 Beth Israel Deaconess Medical Center.", "token2charspan": [[0, 7], [8, 12], [13, 20], [21, 28], [29, 33], [34, 40], [41, 50], [51, 58], [59, 65], [65, 66]]}
{"doc_key": "ai-test-61", "ner": [[14, 15, "field"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Wsp\u00f3lnym", "tematem", "tych", "prac", "jest", "przyj\u0119cie", "perspektywy", "znakowo", "-", "teoretycznej", "na", "zagadnienia", "zwi\u0105zane", "ze", "sztuczn\u0105", "inteligencj\u0105", "i", "reprezentacj\u0105", "wiedzy", "."], "sentence-detokenized": "Wsp\u00f3lnym tematem tych prac jest przyj\u0119cie perspektywy znakowo-teoretycznej na zagadnienia zwi\u0105zane ze sztuczn\u0105 inteligencj\u0105 i reprezentacj\u0105 wiedzy.", "token2charspan": [[0, 8], [9, 16], [17, 21], [22, 26], [27, 31], [32, 41], [42, 53], [54, 61], [61, 62], [62, 74], [75, 77], [78, 89], [90, 98], [99, 101], [102, 110], [111, 123], [124, 125], [126, 139], [140, 146], [146, 147]]}
{"doc_key": "ai-test-62", "ner": [[4, 6, "task"], [8, 8, "task"], [20, 21, "task"], [37, 38, "task"], [40, 41, "task"], [47, 49, "task"], [51, 51, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 6, 20, 21, "type-of", "", false, false], [4, 6, 47, 49, "compare", "", false, false], [4, 6, 47, 49, "opposite", "", false, false], [8, 8, 4, 6, "named", "", false, false], [37, 38, 47, 49, "part-of", "", false, false], [40, 41, 47, 49, "part-of", "", false, false], [47, 49, 20, 21, "type-of", "", false, false], [51, 51, 47, 49, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Na", "przyk\u0142ad", ",", "termin", "neuronowe", "t\u0142umaczenie", "maszynowe", "(", "NMT", ")", "podkre\u015bla", "fakt", ",", "\u017ce", "oparte", "na", "g\u0142\u0119bokim", "uczeniu", "podej\u015bcia", "do", "t\u0142umaczenia", "maszynowego", "bezpo\u015brednio", "ucz\u0105", "si\u0119", "transformacji", "sekwencji", "do", "sekwencji", ",", "eliminuj\u0105c", "potrzeb\u0119", "etap\u00f3w", "po\u015brednich", ",", "takich", "jak", "wyr\u00f3wnanie", "s\u0142\u00f3w", "i", "modelowanie", "j\u0119zyka", ",", "kt\u00f3re", "by\u0142y", "stosowane", "w", "statystycznym", "t\u0142umaczeniu", "maszynowym", "(", "SMT", ")", "."], "sentence-detokenized": "Na przyk\u0142ad, termin neuronowe t\u0142umaczenie maszynowe (NMT) podkre\u015bla fakt, \u017ce oparte na g\u0142\u0119bokim uczeniu podej\u015bcia do t\u0142umaczenia maszynowego bezpo\u015brednio ucz\u0105 si\u0119 transformacji sekwencji do sekwencji, eliminuj\u0105c potrzeb\u0119 etap\u00f3w po\u015brednich, takich jak wyr\u00f3wnanie s\u0142\u00f3w i modelowanie j\u0119zyka, kt\u00f3re by\u0142y stosowane w statystycznym t\u0142umaczeniu maszynowym (SMT).", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 19], [20, 29], [30, 41], [42, 51], [52, 53], [53, 56], [56, 57], [58, 67], [68, 72], [72, 73], [74, 76], [77, 83], [84, 86], [87, 95], [96, 103], [104, 113], [114, 116], [117, 128], [129, 140], [141, 153], [154, 158], [159, 162], [163, 176], [177, 186], [187, 189], [190, 199], [199, 200], [201, 211], [212, 220], [221, 227], [228, 238], [238, 239], [240, 246], [247, 250], [251, 261], [262, 266], [267, 268], [269, 280], [281, 287], [287, 288], [289, 294], [295, 299], [300, 309], [310, 311], [312, 325], [326, 337], [338, 348], [349, 350], [350, 353], [353, 354], [354, 355]]}
{"doc_key": "ai-test-63", "ner": [[4, 4, "field"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 9, 9, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Wi\u0119kszo\u015b\u0107", "bada\u0144", "w", "dziedzinie", "WSD", "jest", "wykonywana", "przy", "u\u017cyciu", "WordNetu", "jako", "referencyjnego", "zasobu", "sens\u00f3w", "dla", "."], "sentence-detokenized": "Wi\u0119kszo\u015b\u0107 bada\u0144 w dziedzinie WSD jest wykonywana przy u\u017cyciu WordNetu jako referencyjnego zasobu sens\u00f3w dla.", "token2charspan": [[0, 9], [10, 15], [16, 17], [18, 28], [29, 32], [33, 37], [38, 48], [49, 53], [54, 60], [61, 69], [70, 74], [75, 89], [90, 96], [97, 103], [104, 107], [107, 108]]}
{"doc_key": "ai-test-64", "ner": [[3, 3, "misc"], [10, 12, "researcher"], [13, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 12, 3, 3, "general-affiliation", "", false, true], [13, 14, 3, 3, "general-affiliation", "", false, true]], "relations_mapping_to_source": [0, 1], "sentence": ["Godnymi", "uwagi", "by\u0142ymi", "doktorantami", "i", "postdoktorantami", "z", "jego", "grupy", "s\u0105", "Richard", "Zemel", "i", "Zoubin", "Ghahramani", "."], "sentence-detokenized": "Godnymi uwagi by\u0142ymi doktorantami i postdoktorantami z jego grupy s\u0105 Richard Zemel i Zoubin Ghahramani.", "token2charspan": [[0, 7], [8, 13], [14, 20], [21, 33], [34, 35], [36, 52], [53, 54], [55, 59], [60, 65], [66, 68], [69, 76], [77, 82], [83, 84], [85, 91], [92, 102], [102, 103]]}
{"doc_key": "ai-test-65", "ner": [[5, 6, "metrics"], [12, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 12, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Ka\u017cdy", "wynik", "predykcji", "lub", "instancja", "macierzy", "konfuzji", "reprezentuje", "jeden", "punkt", "w", "przestrzeni", "ROC", "."], "sentence-detokenized": "Ka\u017cdy wynik predykcji lub instancja macierzy konfuzji reprezentuje jeden punkt w przestrzeni ROC.", "token2charspan": [[0, 5], [6, 11], [12, 21], [22, 25], [26, 35], [36, 44], [45, 53], [54, 66], [67, 72], [73, 78], [79, 80], [81, 92], [93, 96], [96, 97]]}
{"doc_key": "ai-test-66", "ner": [[3, 3, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [21, 23, "product"], [14, 16, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 14, 16, "physical", "", false, false], [7, 8, 14, 16, "physical", "", false, false], [10, 11, 14, 16, "physical", "", false, false], [21, 23, 3, 3, "artifact", "", false, false], [21, 23, 7, 8, "artifact", "", false, false], [21, 23, 10, 11, "artifact", "", false, false], [21, 23, 14, 16, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["W", "1997", "roku", "Thrun", "wraz", "z", "kolegami", "Wolframem", "Burgardem", "i", "Dieterem", "Foxem", "stworzy\u0142", "w", "Deutsches", "Museum", "Bonn", "pierwszego", "na", "\u015bwiecie", "zrobotyzowanego", "przewodnika", "po", "mie\u015bcie", "(", "1997", ")", "."], "sentence-detokenized": "W 1997 roku Thrun wraz z kolegami Wolframem Burgardem i Dieterem Foxem stworzy\u0142 w Deutsches Museum Bonn pierwszego na \u015bwiecie zrobotyzowanego przewodnika po mie\u015bcie (1997).", "token2charspan": [[0, 1], [2, 6], [7, 11], [12, 17], [18, 22], [23, 24], [25, 33], [34, 43], [44, 53], [54, 55], [56, 64], [65, 70], [71, 79], [80, 81], [82, 91], [92, 98], [99, 103], [104, 114], [115, 117], [118, 125], [126, 141], [142, 153], [154, 156], [157, 164], [165, 166], [166, 170], [170, 171], [171, 172]]}
{"doc_key": "ai-test-67", "ner": [[0, 0, "product"], [5, 6, "misc"], [19, 21, "field"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 0, 0, "part-of", "", false, false], [19, 21, 0, 0, "usage", "", false, false], [24, 25, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["WordNet", "jest", "leksykaln\u0105", "baz\u0105", "danych", "relacji", "semantycznych", "mi\u0119dzy", "s\u0142owami", "w", "ponad", "200", "j\u0119zykach", ".", "jego", "g\u0142\u00f3wne", "zastosowanie", "to", "automatyczne", "przetwarzanie", "j\u0119zyka", "naturalnego", "i", "aplikacje", "sztucznej", "inteligencji", "."], "sentence-detokenized": "WordNet jest leksykaln\u0105 baz\u0105 danych relacji semantycznych mi\u0119dzy s\u0142owami w ponad 200 j\u0119zykach. jego g\u0142\u00f3wne zastosowanie to automatyczne przetwarzanie j\u0119zyka naturalnego i aplikacje sztucznej inteligencji.", "token2charspan": [[0, 7], [8, 12], [13, 23], [24, 28], [29, 35], [36, 43], [44, 57], [58, 64], [65, 72], [73, 74], [75, 80], [81, 84], [85, 93], [93, 94], [95, 99], [100, 106], [107, 119], [120, 122], [123, 135], [136, 149], [150, 156], [157, 168], [169, 170], [171, 180], [181, 190], [191, 203], [203, 204]]}
{"doc_key": "ai-test-68", "ner": [[3, 5, "field"], [9, 12, "conference"], [14, 22, "conference"], [24, 24, "conference"], [27, 27, "conference"], [33, 34, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 12, 3, 5, "topic", "", false, false], [9, 12, 33, 34, "topic", "", false, false], [14, 22, 3, 5, "topic", "", false, false], [14, 22, 33, 34, "topic", "", false, false], [24, 24, 3, 5, "topic", "", false, false], [24, 24, 33, 34, "topic", "", false, false], [27, 27, 3, 5, "topic", "", false, false], [27, 27, 33, 34, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Konferencje", "z", "zakresu", "przetwarzania", "j\u0119zyka", "naturalnego", ",", "takie", "jak", "Association", "for", "Computational", "Linguistics", ",", "North", "American", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "EMNLP", ",", "czy", "HLT", ",", "zaczynaj\u0105", "zawiera\u0107", "referaty", "dotycz\u0105ce", "przetwarzania", "mowy", "."], "sentence-detokenized": "Konferencje z zakresu przetwarzania j\u0119zyka naturalnego, takie jak Association for Computational Linguistics, North American Chapter of the Association for Computational Linguistics, EMNLP, czy HLT, zaczynaj\u0105 zawiera\u0107 referaty dotycz\u0105ce przetwarzania mowy.", "token2charspan": [[0, 11], [12, 13], [14, 21], [22, 35], [36, 42], [43, 54], [54, 55], [56, 61], [62, 65], [66, 77], [78, 81], [82, 95], [96, 107], [107, 108], [109, 114], [115, 123], [124, 131], [132, 134], [135, 138], [139, 150], [151, 154], [155, 168], [169, 180], [180, 181], [182, 187], [187, 188], [189, 192], [193, 196], [196, 197], [198, 207], [208, 216], [217, 225], [226, 235], [236, 249], [250, 254], [254, 255]]}
{"doc_key": "ai-test-69", "ner": [[4, 4, "programlang"], [18, 19, "misc"], [31, 33, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Zestaw", "program\u00f3w", "w", "j\u0119zyku", "Java", "wykorzystuje", "leksykon", "do", "pracy", "nad", "odmianami", "tekst\u00f3w", "biomedycznych", "poprzez", "powi\u0105zanie", "s\u0142\u00f3w", "z", "ich", "cz\u0119\u015bciami", "mowy", ",", "co", "mo\u017ce", "by\u0107", "pomocne", "w", "wyszukiwaniu", "w", "sieci", "lub", "w", "elektronicznej", "dokumentacji", "medycznej", "."], "sentence-detokenized": "Zestaw program\u00f3w w j\u0119zyku Java wykorzystuje leksykon do pracy nad odmianami tekst\u00f3w biomedycznych poprzez powi\u0105zanie s\u0142\u00f3w z ich cz\u0119\u015bciami mowy, co mo\u017ce by\u0107 pomocne w wyszukiwaniu w sieci lub w elektronicznej dokumentacji medycznej.", "token2charspan": [[0, 6], [7, 16], [17, 18], [19, 25], [26, 30], [31, 43], [44, 52], [53, 55], [56, 61], [62, 65], [66, 75], [76, 83], [84, 97], [98, 105], [106, 116], [117, 121], [122, 123], [124, 127], [128, 137], [138, 142], [142, 143], [144, 146], [147, 151], [152, 155], [156, 163], [164, 165], [166, 178], [179, 180], [181, 186], [187, 190], [191, 192], [193, 207], [208, 220], [221, 230], [230, 231]]}
{"doc_key": "ai-test-70", "ner": [[6, 6, "algorithm"], [8, 8, "algorithm"], [10, 10, "algorithm"], [12, 12, "algorithm"], [14, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Istnieje", "wiele", "nowszych", "algorytm\u00f3w", "takich", "jak", "LPBoost", ",", "TotalBoost", ",", "BrownBoost", ",", "xgboost", ",", "MadaBoost", ",", ",", ",", "i", "inne", "."], "sentence-detokenized": "Istnieje wiele nowszych algorytm\u00f3w takich jak LPBoost, TotalBoost, BrownBoost, xgboost, MadaBoost,,, i inne.", "token2charspan": [[0, 8], [9, 14], [15, 23], [24, 34], [35, 41], [42, 45], [46, 53], [53, 54], [55, 65], [65, 66], [67, 77], [77, 78], [79, 86], [86, 87], [88, 97], [97, 98], [98, 99], [99, 100], [101, 102], [103, 107], [107, 108]]}
{"doc_key": "ai-test-71", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Jest", "to", "przyk\u0142adowa", "implementacja", "w", "j\u0119zyku", "Python", ":"], "sentence-detokenized": "Jest to przyk\u0142adowa implementacja w j\u0119zyku Python:", "token2charspan": [[0, 4], [5, 7], [8, 19], [20, 33], [34, 35], [36, 42], [43, 49], [49, 50]]}
{"doc_key": "ai-test-72", "ner": [[5, 5, "organisation"], [3, 4, "product"], [11, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 5, 5, "artifact", "made_by_company", false, false], [11, 13, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Konsola", "do", "gier", "Intellivision", "firmy", "Mattel", "oferowa\u0142a", "w", "1982", "roku", "modu\u0142", "syntezy", "g\u0142osu", "Intellivoice", "."], "sentence-detokenized": "Konsola do gier Intellivision firmy Mattel oferowa\u0142a w 1982 roku modu\u0142 syntezy g\u0142osu Intellivoice.", "token2charspan": [[0, 7], [8, 10], [11, 15], [16, 29], [30, 35], [36, 42], [43, 52], [53, 54], [55, 59], [60, 64], [65, 70], [71, 78], [79, 84], [85, 97], [97, 98]]}
{"doc_key": "ai-test-73", "ner": [[3, 4, "task"], [8, 14, "task"], [19, 20, "field"], [22, 24, "task"], [28, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 14, 3, 4, "part-of", "", false, false], [19, 20, 3, 4, "part-of", "", false, false], [22, 24, 3, 4, "part-of", "", false, false], [28, 32, 22, 24, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Pracowa\u0142", "r\u00f3wnie\u017c", "nad", "t\u0142umaczeniem", "maszynowym", ",", "zar\u00f3wno", "nad", "MT", "opartym", "na", "wiedzy", "o", "wysokiej", "dok\u0142adno\u015bci", ",", "jak", "i", "nad", "uczeniem", "maszynowym", "dla", "statystycznego", "t\u0142umaczenia", "maszynowego", "(", "np", ".", "MT", "oparte", "na", "uog\u00f3lnionych", "przyk\u0142adach", ")", "."], "sentence-detokenized": "Pracowa\u0142 r\u00f3wnie\u017c nad t\u0142umaczeniem maszynowym, zar\u00f3wno nad MT opartym na wiedzy o wysokiej dok\u0142adno\u015bci, jak i nad uczeniem maszynowym dla statystycznego t\u0142umaczenia maszynowego (np. MT oparte na uog\u00f3lnionych przyk\u0142adach).", "token2charspan": [[0, 8], [9, 16], [17, 20], [21, 33], [34, 44], [44, 45], [46, 53], [54, 57], [58, 60], [61, 68], [69, 71], [72, 78], [79, 80], [81, 89], [90, 101], [101, 102], [103, 106], [107, 108], [109, 112], [113, 121], [122, 132], [133, 136], [137, 151], [152, 163], [164, 175], [176, 177], [177, 179], [179, 180], [181, 183], [184, 190], [191, 193], [194, 206], [207, 218], [218, 219], [219, 220]]}
{"doc_key": "ai-test-74", "ner": [[0, 1, "misc"], [6, 6, "misc"], [19, 20, "algorithm"], [22, 23, "field"], [25, 26, "field"], [28, 28, "field"], [30, 32, "field"], [34, 34, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 19, 20, "general-affiliation", "", false, false], [0, 1, 22, 23, "general-affiliation", "", false, false], [0, 1, 25, 26, "general-affiliation", "", false, false], [0, 1, 28, 28, "general-affiliation", "", false, false], [0, 1, 30, 32, "general-affiliation", "", false, false], [0, 1, 34, 34, "general-affiliation", "", false, false], [6, 6, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Wolfram", "Mathematica", "(", "zwykle", "okre\u015blana", "jako", "Mathematica", ")", "to", "nowoczesny", "system", "obliczeniowy", "obejmuj\u0105cy", "wi\u0119kszo\u015b\u0107", "dziedzin", "technicznych", "-", "w", "tym", "sieci", "neuronowe", ",", "uczenie", "maszynowe", ",", "przetwarzanie", "obraz\u00f3w", ",", "geometri\u0119", ",", "nauk\u0119", "o", "danych", ",", "wizualizacje", "i", "inne", "."], "sentence-detokenized": "Wolfram Mathematica (zwykle okre\u015blana jako Mathematica) to nowoczesny system obliczeniowy obejmuj\u0105cy wi\u0119kszo\u015b\u0107 dziedzin technicznych - w tym sieci neuronowe, uczenie maszynowe, przetwarzanie obraz\u00f3w, geometri\u0119, nauk\u0119 o danych, wizualizacje i inne.", "token2charspan": [[0, 7], [8, 19], [20, 21], [21, 27], [28, 37], [38, 42], [43, 54], [54, 55], [56, 58], [59, 69], [70, 76], [77, 89], [90, 100], [101, 110], [111, 119], [120, 132], [133, 134], [135, 136], [137, 140], [141, 146], [147, 156], [156, 157], [158, 165], [166, 175], [175, 176], [177, 190], [191, 198], [198, 199], [200, 209], [209, 210], [211, 216], [217, 218], [219, 225], [225, 226], [227, 239], [240, 241], [242, 246], [246, 247]]}
{"doc_key": "ai-test-75", "ner": [[1, 5, "product"], [9, 10, "researcher"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 17, 1, 5, "type-of", "", false, false], [17, 17, 9, 10, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pierwszy", "cyfrowo", "sterowany", "i", "programowalny", "robot", "zosta\u0142", "wynaleziony", "przez", "George'a", "Devola", "w", "1954", "roku", "i", "ostatecznie", "nazwany", "Unimate", "."], "sentence-detokenized": "Pierwszy cyfrowo sterowany i programowalny robot zosta\u0142 wynaleziony przez George'a Devola w 1954 roku i ostatecznie nazwany Unimate.", "token2charspan": [[0, 8], [9, 16], [17, 26], [27, 28], [29, 42], [43, 48], [49, 55], [56, 67], [68, 73], [74, 82], [83, 89], [90, 91], [92, 96], [97, 101], [102, 103], [104, 115], [116, 123], [124, 131], [131, 132]]}
{"doc_key": "ai-test-76", "ner": [[2, 2, "algorithm"], [4, 4, "algorithm"], [19, 20, "task"], [22, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 2, 4, 4, "compare", "", false, false], [4, 4, 19, 20, "general-affiliation", "", false, false], [4, 4, 22, 23, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Podobnie", "jak", "DBN", ",", "DBM", "mog\u0105", "uczy\u0107", "si\u0119", "z\u0142o\u017conych", "i", "abstrakcyjnych", "wewn\u0119trznych", "reprezentacji", "danych", "wej\u015bciowych", "w", "zadaniach", "takich", "jak", "rozpoznawanie", "obiekt\u00f3w", "lub", "rozpoznawanie", "mowy", ",", "wykorzystuj\u0105c", "ograniczone", ",", "oznakowane", "dane", "do", "dostrojenia", "reprezentacji", "zbudowanych", "przy", "u\u017cyciu", "du\u017cego", "zestawu", "nieznakowanych", "sensorycznych", "danych", "wej\u015bciowych", "."], "sentence-detokenized": "Podobnie jak DBN, DBM mog\u0105 uczy\u0107 si\u0119 z\u0142o\u017conych i abstrakcyjnych wewn\u0119trznych reprezentacji danych wej\u015bciowych w zadaniach takich jak rozpoznawanie obiekt\u00f3w lub rozpoznawanie mowy, wykorzystuj\u0105c ograniczone, oznakowane dane do dostrojenia reprezentacji zbudowanych przy u\u017cyciu du\u017cego zestawu nieznakowanych sensorycznych danych wej\u015bciowych.", "token2charspan": [[0, 8], [9, 12], [13, 16], [16, 17], [18, 21], [22, 26], [27, 32], [33, 36], [37, 46], [47, 48], [49, 63], [64, 76], [77, 90], [91, 97], [98, 109], [110, 111], [112, 121], [122, 128], [129, 132], [133, 146], [147, 155], [156, 159], [160, 173], [174, 178], [178, 179], [180, 193], [194, 205], [205, 206], [207, 217], [218, 222], [223, 225], [226, 237], [238, 251], [252, 263], [264, 268], [269, 275], [276, 282], [283, 290], [291, 305], [306, 319], [320, 326], [327, 338], [338, 339]]}
{"doc_key": "ai-test-77", "ner": [[9, 14, "task"], [16, 16, "conference"], [18, 18, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 16, 9, 14, "topic", "", false, false], [18, 18, 9, 14, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Konferencje", "naukowe", ",", "na", "kt\u00f3rych", "cz\u0119sto", "pojawiaj\u0105", "si\u0119", "prace", "dotycz\u0105ce", "rozpoznawania", "aktywno\u015bci", "na", "podstawie", "wizji", "to", "ICCV", "i", "CVPR", "."], "sentence-detokenized": "Konferencje naukowe, na kt\u00f3rych cz\u0119sto pojawiaj\u0105 si\u0119 prace dotycz\u0105ce rozpoznawania aktywno\u015bci na podstawie wizji to ICCV i CVPR.", "token2charspan": [[0, 11], [12, 19], [19, 20], [21, 23], [24, 31], [32, 38], [39, 48], [49, 52], [53, 58], [59, 68], [69, 82], [83, 93], [94, 96], [97, 106], [107, 112], [113, 115], [116, 120], [121, 122], [123, 127], [127, 128]]}
{"doc_key": "ai-test-78", "ner": [[1, 1, "field"], [3, 5, "algorithm"], [7, 7, "algorithm"], [13, 14, "metrics"], [16, 18, "metrics"], [20, 20, "metrics"], [34, 35, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 5, 1, 1, "part-of", "", false, false], [3, 5, 13, 14, "related-to", "finds", false, false], [3, 5, 16, 18, "related-to", "finds", false, false], [3, 5, 34, 35, "related-to", "", false, false], [7, 7, 3, 5, "named", "", false, false], [20, 20, 16, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["W", "statystyce", "algorytm", "oczekiwania", "-", "maksymalizacji", "(", "EM", ")", "jest", "iteracyjn\u0105", "metod\u0105", "znajdowania", "maksymalnego", "prawdopodobie\u0144stwa", "lub", "maksymalnego", "a", "posteriori", "(", "MAP", ")", "oszacowa\u0144", "parametr\u00f3w", "w", "modelach", "statystycznych", ",", "w", "kt\u00f3rych", "model", "zale\u017cy", "od", "nieobserwowanych", "zmiennych", "latentnych", "."], "sentence-detokenized": "W statystyce algorytm oczekiwania-maksymalizacji (EM) jest iteracyjn\u0105 metod\u0105 znajdowania maksymalnego prawdopodobie\u0144stwa lub maksymalnego a posteriori (MAP) oszacowa\u0144 parametr\u00f3w w modelach statystycznych, w kt\u00f3rych model zale\u017cy od nieobserwowanych zmiennych latentnych.", "token2charspan": [[0, 1], [2, 12], [13, 21], [22, 33], [33, 34], [34, 48], [49, 50], [50, 52], [52, 53], [54, 58], [59, 69], [70, 76], [77, 88], [89, 101], [102, 120], [121, 124], [125, 137], [138, 139], [140, 150], [151, 152], [152, 155], [155, 156], [157, 166], [167, 177], [178, 179], [180, 188], [189, 203], [203, 204], [205, 206], [207, 214], [215, 220], [221, 227], [228, 230], [231, 247], [248, 257], [258, 268], [268, 269]]}
{"doc_key": "ai-test-79", "ner": [[4, 6, "metrics"], [8, 8, "metrics"], [13, 15, "metrics"], [17, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 4, 6, "named", "", false, false], [17, 17, 13, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Podobnie", "badacze", "czasami", "podaj\u0105", "wska\u017anik", "FALSE", "pozytywnych", "(", "FPR", ")", ",", "jak", "r\u00f3wnie\u017c", "wska\u017anik", "FALSE", "negatywnych", "(", "FNR", ")", "."], "sentence-detokenized": "Podobnie badacze czasami podaj\u0105 wska\u017anik FALSE pozytywnych (FPR), jak r\u00f3wnie\u017c wska\u017anik FALSE negatywnych (FNR).", "token2charspan": [[0, 8], [9, 16], [17, 24], [25, 31], [32, 40], [41, 46], [47, 58], [59, 60], [60, 63], [63, 64], [64, 65], [66, 69], [70, 77], [78, 86], [87, 92], [93, 104], [105, 106], [106, 109], [109, 110], [110, 111]]}
{"doc_key": "ai-test-80", "ner": [[5, 8, "metrics"], [11, 12, "field"], [14, 15, "metrics"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 12, 5, 8, "usage", "", false, false], [18, 19, 14, 15, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Koncepcja", "ta", "jest", "podobna", "do", "stosunku", "sygna\u0142u", "do", "szumu", "stosowanego", "w", "naukach", "\u015bcis\u0142ych", "i", "macierzy", "konfuzji", "stosowanej", "w", "sztucznej", "inteligencji", "."], "sentence-detokenized": "Koncepcja ta jest podobna do stosunku sygna\u0142u do szumu stosowanego w naukach \u015bcis\u0142ych i macierzy konfuzji stosowanej w sztucznej inteligencji.", "token2charspan": [[0, 9], [10, 12], [13, 17], [18, 25], [26, 28], [29, 37], [38, 45], [46, 48], [49, 54], [55, 66], [67, 68], [69, 76], [77, 85], [86, 87], [88, 96], [97, 105], [106, 116], [117, 118], [119, 128], [129, 141], [141, 142]]}
{"doc_key": "ai-test-81", "ner": [[3, 4, "field"], [11, 12, "researcher"], [20, 21, "researcher"], [23, 25, "researcher"], [33, 36, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 11, 12, "general-affiliation", "", false, false], [3, 4, 20, 21, "general-affiliation", "", false, false], [3, 4, 23, 25, "general-affiliation", "", false, false], [33, 36, 3, 4, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kodeks", "Etyczny", "dotycz\u0105cy", "Augmentacji", "Cz\u0142owieka", ",", "kt\u00f3ry", "zosta\u0142", "pierwotnie", "wprowadzony", "przez", "Steve'a", "Manna", "w", "2004", "roku", "i", "dopracowany", "wraz", "z", "Rayem", "Kurzweilem", "i", "Marvinem", "Minsky'm", "w", "2013", "roku", ",", "zosta\u0142", "ostatecznie", "ratyfikowany", "podczas", "konferencji", "Virtual", "Reality", "Toronto", "25", "czerwca", "2017", "roku", "."], "sentence-detokenized": "Kodeks Etyczny dotycz\u0105cy Augmentacji Cz\u0142owieka, kt\u00f3ry zosta\u0142 pierwotnie wprowadzony przez Steve'a Manna w 2004 roku i dopracowany wraz z Rayem Kurzweilem i Marvinem Minsky'm w 2013 roku, zosta\u0142 ostatecznie ratyfikowany podczas konferencji Virtual Reality Toronto 25 czerwca 2017 roku.", "token2charspan": [[0, 6], [7, 14], [15, 24], [25, 36], [37, 46], [46, 47], [48, 53], [54, 60], [61, 71], [72, 83], [84, 89], [90, 97], [98, 103], [104, 105], [106, 110], [111, 115], [116, 117], [118, 129], [130, 134], [135, 136], [137, 142], [143, 153], [154, 155], [156, 164], [165, 173], [174, 175], [176, 180], [181, 185], [185, 186], [187, 193], [194, 205], [206, 218], [219, 226], [227, 238], [239, 246], [247, 254], [255, 262], [263, 265], [266, 273], [274, 278], [279, 283], [283, 284]]}
{"doc_key": "ai-test-82", "ner": [[3, 6, "person"], [11, 12, "organisation"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 6, 11, 12, "role", "directed_for", false, false], [3, 6, 18, 19, "role", "collaborator", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["W", "1913", "roku", "Walter", "R", ".", "Booth", "wyre\u017cyserowa\u0142", "10", "film\u00f3w", "dla", "brytyjskiego", "Kinoplastikonu", ",", "przypuszczalnie", "we", "wsp\u00f3\u0142pracy", "z", "Cecilem", "Hepworthem", "."], "sentence-detokenized": "W 1913 roku Walter R. Booth wyre\u017cyserowa\u0142 10 film\u00f3w dla brytyjskiego Kinoplastikonu, przypuszczalnie we wsp\u00f3\u0142pracy z Cecilem Hepworthem.", "token2charspan": [[0, 1], [2, 6], [7, 11], [12, 18], [19, 20], [20, 21], [22, 27], [28, 41], [42, 44], [45, 51], [52, 55], [56, 68], [69, 83], [83, 84], [85, 100], [101, 103], [104, 114], [115, 116], [117, 124], [125, 135], [135, 136]]}
{"doc_key": "ai-test-83", "ner": [[10, 10, "location"], [11, 12, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 10, 10, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Swojego", "nowego", "robota", "przedstawili", "w", "1961", "roku", "na", "targach", "w", "chicagowskim", "Cow", "Palace", "."], "sentence-detokenized": "Swojego nowego robota przedstawili w 1961 roku na targach w chicagowskim Cow Palace.", "token2charspan": [[0, 7], [8, 14], [15, 21], [22, 34], [35, 36], [37, 41], [42, 46], [47, 49], [50, 57], [58, 59], [60, 72], [73, 76], [77, 83], [83, 84]]}
{"doc_key": "ai-test-84", "ner": [[4, 4, "product"], [8, 9, "task"], [12, 14, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 8, 9, "usage", "", false, false], [4, 4, 12, 14, "usage", "", false, false], [4, 4, 17, 18, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Podczas", "gdy", "niekt\u00f3re", "aplikacje", "chatbotowe", "wykorzystuj\u0105", "rozbudowane", "procesy", "klasyfikacji", "s\u0142\u00f3w", ",", "procesory", "przetwarzania", "j\u0119zyka", "naturalnego", "i", "wyrafinowan\u0105", "sztuczn\u0105", "inteligencj\u0119", ",", "inne", "po", "prostu", "skanuj\u0105", "pod", "k\u0105tem", "og\u00f3lnych", "s\u0142\u00f3w", "kluczowych", "i", "generuj\u0105", "odpowiedzi", "przy", "u\u017cyciu", "popularnych", "fraz", "uzyskanych", "z", "powi\u0105zanej", "biblioteki", "lub", "bazy", "danych", "."], "sentence-detokenized": "Podczas gdy niekt\u00f3re aplikacje chatbotowe wykorzystuj\u0105 rozbudowane procesy klasyfikacji s\u0142\u00f3w, procesory przetwarzania j\u0119zyka naturalnego i wyrafinowan\u0105 sztuczn\u0105 inteligencj\u0119, inne po prostu skanuj\u0105 pod k\u0105tem og\u00f3lnych s\u0142\u00f3w kluczowych i generuj\u0105 odpowiedzi przy u\u017cyciu popularnych fraz uzyskanych z powi\u0105zanej biblioteki lub bazy danych.", "token2charspan": [[0, 7], [8, 11], [12, 20], [21, 30], [31, 41], [42, 54], [55, 66], [67, 74], [75, 87], [88, 92], [92, 93], [94, 103], [104, 117], [118, 124], [125, 136], [137, 138], [139, 151], [152, 160], [161, 173], [173, 174], [175, 179], [180, 182], [183, 189], [190, 197], [198, 201], [202, 207], [208, 216], [217, 221], [222, 232], [233, 234], [235, 243], [244, 254], [255, 259], [260, 266], [267, 278], [279, 283], [284, 294], [295, 296], [297, 307], [308, 318], [319, 322], [323, 327], [328, 334], [334, 335]]}
{"doc_key": "ai-test-85", "ner": [[5, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Zaproponowany", "w", "2016", "roku", "model", "WaveNet", "osi\u0105ga", "\u015bwietne", "wyniki", "w", "zakresie", "jako\u015bci", "mowy", "."], "sentence-detokenized": "Zaproponowany w 2016 roku model WaveNet osi\u0105ga \u015bwietne wyniki w zakresie jako\u015bci mowy.", "token2charspan": [[0, 13], [14, 15], [16, 20], [21, 25], [26, 31], [32, 39], [40, 46], [47, 54], [55, 61], [62, 63], [64, 72], [73, 80], [81, 85], [85, 86]]}
{"doc_key": "ai-test-86", "ner": [[4, 4, "product"], [6, 7, "misc"], [9, 12, "misc"], [14, 15, "misc"], [17, 20, "misc"], [22, 24, "organisation"], [26, 26, "organisation"], [28, 31, "organisation"], [33, 33, "organisation"], [35, 38, "organisation"], [40, 41, "organisation"], [43, 45, "organisation"], [47, 49, "organisation"], [52, 52, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 4, 6, 7, "general-affiliation", "", false, false], [4, 4, 9, 12, "general-affiliation", "", false, false], [4, 4, 14, 15, "general-affiliation", "", false, false], [4, 4, 17, 20, "general-affiliation", "", false, false], [22, 24, 4, 4, "usage", "", false, false], [26, 26, 4, 4, "usage", "", false, false], [28, 31, 4, 4, "usage", "", false, false], [33, 33, 4, 4, "usage", "", false, false], [35, 38, 4, 4, "usage", "", false, false], [40, 41, 4, 4, "usage", "", false, false], [43, 45, 4, 4, "usage", "", false, false], [47, 49, 4, 4, "usage", "", false, false], [52, 52, 4, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Organizacje", "znane", "z", "u\u017cywania", "ALE", "do", "zarz\u0105dzania", "kryzysowego", ",", "pomocy", "w", "przypadku", "katastrof", ",", "zwyk\u0142ej", "komunikacji", "lub", "reagowania", "w", "sytuacjach", "nadzwyczajnych", ":", "American", "Red", "Cross", ",", "FEMA", ",", "Disaster", "Medical", "Assistance", "Teams", ",", "NATO", ",", "Federal", "Bureau", "of", "Investigation", ",", "United", "Nations", ",", "AT", "&", "T", ",", "Civil", "Air", "Patrol", ",", "(", "ARES", ")", "."], "sentence-detokenized": "Organizacje znane z u\u017cywania ALE do zarz\u0105dzania kryzysowego, pomocy w przypadku katastrof, zwyk\u0142ej komunikacji lub reagowania w sytuacjach nadzwyczajnych: American Red Cross, FEMA, Disaster Medical Assistance Teams, NATO, Federal Bureau of Investigation, United Nations, AT & T, Civil Air Patrol, (ARES).", "token2charspan": [[0, 11], [12, 17], [18, 19], [20, 28], [29, 32], [33, 35], [36, 47], [48, 59], [59, 60], [61, 67], [68, 69], [70, 79], [80, 89], [89, 90], [91, 98], [99, 110], [111, 114], [115, 125], [126, 127], [128, 138], [139, 153], [153, 154], [155, 163], [164, 167], [168, 173], [173, 174], [175, 179], [179, 180], [181, 189], [190, 197], [198, 208], [209, 214], [214, 215], [216, 220], [220, 221], [222, 229], [230, 236], [237, 239], [240, 253], [253, 254], [255, 261], [262, 269], [269, 270], [271, 273], [274, 275], [276, 277], [277, 278], [279, 284], [285, 288], [289, 295], [295, 296], [297, 298], [298, 302], [302, 303], [303, 304]]}
{"doc_key": "ai-test-87", "ner": [[5, 6, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Tutaj", "dla", "uproszczenia", "stosuje", "si\u0119", "delt\u0119", "Kroneckera", "(", "por", ".", "pochodna", "funkcji", "sigmoidalnej", ",", "wyra\u017cana", "poprzez", "sam\u0105", "funkcj\u0119", ")", "."], "sentence-detokenized": "Tutaj dla uproszczenia stosuje si\u0119 delt\u0119 Kroneckera (por. pochodna funkcji sigmoidalnej, wyra\u017cana poprzez sam\u0105 funkcj\u0119).", "token2charspan": [[0, 5], [6, 9], [10, 22], [23, 30], [31, 34], [35, 40], [41, 51], [52, 53], [53, 56], [56, 57], [58, 66], [67, 74], [75, 87], [87, 88], [89, 97], [98, 105], [106, 110], [111, 118], [118, 119], [119, 120]]}
{"doc_key": "ai-test-88", "ner": [[12, 13, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Teoria", "ta", "opiera", "si\u0119", "na", "podstawach", "filozoficznych", ",", "a", "za\u0142o\u017cona", "zosta\u0142a", "przez", "Raya", "Solomonoffa", "oko\u0142o", "1960", "roku", ".", "Samuel", "Rathmanner", "i", "Marcus", "Hutter", "."], "sentence-detokenized": "Teoria ta opiera si\u0119 na podstawach filozoficznych, a za\u0142o\u017cona zosta\u0142a przez Raya Solomonoffa oko\u0142o 1960 roku. Samuel Rathmanner i Marcus Hutter.", "token2charspan": [[0, 6], [7, 9], [10, 16], [17, 20], [21, 23], [24, 34], [35, 49], [49, 50], [51, 52], [53, 61], [62, 69], [70, 75], [76, 80], [81, 92], [93, 98], [99, 103], [104, 108], [108, 109], [110, 116], [117, 127], [128, 129], [130, 136], [137, 143], [143, 144]]}
{"doc_key": "ai-test-89", "ner": [[0, 0, "product"], [10, 11, "misc"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 10, 11, "type-of", "", false, false], [0, 0, 14, 15, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["WordNet", ",", "swobodnie", "dost\u0119pna", "baza", "danych", ",", "pierwotnie", "zaprojektowana", "jako", "sie\u0107", "semantyczna", "oparta", "na", "zasadach", "psycholingwistycznych", ",", "zosta\u0142a", "rozbudowana", "poprzez", "dodanie", "definicji", "i", "obecnie", "jest", "r\u00f3wnie\u017c", "postrzegana", "jako", "s\u0142ownik", "."], "sentence-detokenized": "WordNet, swobodnie dost\u0119pna baza danych, pierwotnie zaprojektowana jako sie\u0107 semantyczna oparta na zasadach psycholingwistycznych, zosta\u0142a rozbudowana poprzez dodanie definicji i obecnie jest r\u00f3wnie\u017c postrzegana jako s\u0142ownik.", "token2charspan": [[0, 7], [7, 8], [9, 18], [19, 27], [28, 32], [33, 39], [39, 40], [41, 51], [52, 66], [67, 71], [72, 76], [77, 88], [89, 95], [96, 98], [99, 107], [108, 129], [129, 130], [131, 138], [139, 150], [151, 158], [159, 166], [167, 176], [177, 178], [179, 186], [187, 191], [192, 199], [200, 211], [212, 216], [217, 224], [224, 225]]}
{"doc_key": "ai-test-90", "ner": [[5, 6, "field"], [17, 17, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 17, 5, 6, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Post\u0119py", "w", "dziedzinie", "bada\u0144", "nad", "obrazowaniem", "obliczeniowym", "s\u0105", "prezentowane", "w", "kilku", "miejscach", ",", "w", "tym", "w", "publikacjach", "SIGGRAPH", "i", "."], "sentence-detokenized": "Post\u0119py w dziedzinie bada\u0144 nad obrazowaniem obliczeniowym s\u0105 prezentowane w kilku miejscach, w tym w publikacjach SIGGRAPH i.", "token2charspan": [[0, 7], [8, 9], [10, 20], [21, 26], [27, 30], [31, 43], [44, 57], [58, 60], [61, 73], [74, 75], [76, 81], [82, 91], [91, 92], [93, 94], [95, 98], [99, 100], [101, 113], [114, 122], [123, 124], [124, 125]]}
{"doc_key": "ai-test-91", "ner": [[1, 1, "task"], [11, 11, "task"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 1, 1, "part-of", "", false, false], [13, 14, 1, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["O", "klasyfikacji", "mo\u017cna", "my\u015ble\u0107", "jako", "o", "dw\u00f3ch", "odr\u0119bnych", "problemach", "-", "klasyfikacji", "binarnej", "i", "klasyfikacji", "wieloklasowej", "."], "sentence-detokenized": "O klasyfikacji mo\u017cna my\u015ble\u0107 jako o dw\u00f3ch odr\u0119bnych problemach - klasyfikacji binarnej i klasyfikacji wieloklasowej.", "token2charspan": [[0, 1], [2, 14], [15, 20], [21, 27], [28, 32], [33, 34], [35, 40], [41, 50], [51, 61], [62, 63], [64, 76], [77, 85], [86, 87], [88, 100], [101, 114], [114, 115]]}
{"doc_key": "ai-test-92", "ner": [[13, 14, "algorithm"], [18, 20, "algorithm"], [22, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 20, 13, 14, "type-of", "", false, false], [22, 22, 18, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Zaawansowane", "wyszukiwarki", "gen\u00f3w", "zar\u00f3wno", "dla", "genom\u00f3w", "prokariotycznych", "jak", "i", "eukariotycznych", "zazwyczaj", "wykorzystuj\u0105", "z\u0142o\u017cone", "modele", "probabilistyczne", ",", "takie", "jak", "ukryte", "modele", "Markowa", "(", "HMM", ")", "do", "\u0142\u0105czenia", "informacji", "z", "wielu", "r\u00f3\u017cnych", "pomiar\u00f3w", "sygna\u0142u", "i", "zawarto\u015bci", "."], "sentence-detokenized": "Zaawansowane wyszukiwarki gen\u00f3w zar\u00f3wno dla genom\u00f3w prokariotycznych jak i eukariotycznych zazwyczaj wykorzystuj\u0105 z\u0142o\u017cone modele probabilistyczne, takie jak ukryte modele Markowa (HMM) do \u0142\u0105czenia informacji z wielu r\u00f3\u017cnych pomiar\u00f3w sygna\u0142u i zawarto\u015bci.", "token2charspan": [[0, 12], [13, 25], [26, 31], [32, 39], [40, 43], [44, 51], [52, 68], [69, 72], [73, 74], [75, 90], [91, 100], [101, 113], [114, 121], [122, 128], [129, 145], [145, 146], [147, 152], [153, 156], [157, 163], [164, 170], [171, 178], [179, 180], [180, 183], [183, 184], [185, 187], [188, 196], [197, 207], [208, 209], [210, 215], [216, 223], [224, 232], [233, 240], [241, 242], [243, 253], [253, 254]]}
{"doc_key": "ai-test-93", "ner": [[0, 0, "misc"], [3, 5, "misc"], [9, 10, "field"], [14, 15, "algorithm"], [18, 20, "algorithm"], [22, 22, "algorithm"], [32, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 9, 10, "part-of", "", false, false], [0, 0, 14, 15, "usage", "", false, false], [3, 5, 0, 0, "named", "", false, false], [18, 20, 0, 0, "origin", "", true, false], [22, 22, 18, 20, "named", "", false, false], [32, 33, 0, 0, "origin", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Neuroewolucja", ",", "lub", "neuro", "-", "ewolucja", ",", "jest", "form\u0105", "sztucznej", "inteligencji", ",", "kt\u00f3ra", "wykorzystuje", "algorytmy", "ewolucyjne", "do", "generowania", "sztucznych", "sieci", "neuronowych", "(", "ANN", ")", ",", "parametr\u00f3w", ",", "topologii", "i", "regu\u0142", ".", "i", "robotyki", "ewolucyjnej", "."], "sentence-detokenized": "Neuroewolucja, lub neuro-ewolucja, jest form\u0105 sztucznej inteligencji, kt\u00f3ra wykorzystuje algorytmy ewolucyjne do generowania sztucznych sieci neuronowych (ANN), parametr\u00f3w, topologii i regu\u0142. i robotyki ewolucyjnej.", "token2charspan": [[0, 13], [13, 14], [15, 18], [19, 24], [24, 25], [25, 33], [33, 34], [35, 39], [40, 45], [46, 55], [56, 68], [68, 69], [70, 75], [76, 88], [89, 98], [99, 109], [110, 112], [113, 124], [125, 135], [136, 141], [142, 153], [154, 155], [155, 158], [158, 159], [159, 160], [161, 171], [171, 172], [173, 182], [183, 184], [185, 190], [190, 191], [192, 193], [194, 202], [203, 214], [214, 215]]}
{"doc_key": "ai-test-94", "ner": [[1, 1, "organisation"], [6, 6, "metrics"], [7, 7, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 1, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Poniewa\u017c", "IBM", "zaproponowa\u0142", "i", "zrealizowa\u0142", "system", "BLEU", "Papineni", "i", "in", "."], "sentence-detokenized": "Poniewa\u017c IBM zaproponowa\u0142 i zrealizowa\u0142 system BLEU Papineni i in.", "token2charspan": [[0, 8], [9, 12], [13, 25], [26, 27], [28, 39], [40, 46], [47, 51], [52, 60], [61, 62], [63, 65], [65, 66]]}
{"doc_key": "ai-test-95", "ner": [[9, 15, "conference"], [17, 17, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 17, 9, 15, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["W", "2009", "roku", "eksperci", "uczestniczyli", "w", "konferencji", "zorganizowanej", "przez", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", ",", "aby", "przedyskutowa\u0107", ",", "czy", "komputery", "i", "roboty", "b\u0119d\u0105", "w", "stanie", "uzyska\u0107", "jak\u0105kolwiek", "autonomi\u0119", "i", "na", "ile", "te", "zdolno\u015bci", "mog\u0105", "stanowi\u0107", "zagro\u017cenie", "lub", "niebezpiecze\u0144stwo", "."], "sentence-detokenized": "W 2009 roku eksperci uczestniczyli w konferencji zorganizowanej przez Association for the Advancement of Artificial Intelligence (AAAI), aby przedyskutowa\u0107, czy komputery i roboty b\u0119d\u0105 w stanie uzyska\u0107 jak\u0105kolwiek autonomi\u0119 i na ile te zdolno\u015bci mog\u0105 stanowi\u0107 zagro\u017cenie lub niebezpiecze\u0144stwo.", "token2charspan": [[0, 1], [2, 6], [7, 11], [12, 20], [21, 34], [35, 36], [37, 48], [49, 63], [64, 69], [70, 81], [82, 85], [86, 89], [90, 101], [102, 104], [105, 115], [116, 128], [129, 130], [130, 134], [134, 135], [135, 136], [137, 140], [141, 155], [155, 156], [157, 160], [161, 170], [171, 172], [173, 179], [180, 184], [185, 186], [187, 193], [194, 201], [202, 213], [214, 223], [224, 225], [226, 228], [229, 232], [233, 235], [236, 245], [246, 250], [251, 259], [260, 270], [271, 274], [275, 292], [292, 293]]}
{"doc_key": "ai-test-96", "ner": [[21, 23, "metrics"], [24, 27, "researcher"], [29, 31, "researcher"], [33, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[33, 36, 21, 23, "topic", "", false, false], [33, 36, 24, 27, "artifact", "", false, false], [33, 36, 29, 31, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Po", "boostingu", ",", "klasyfikator", "skonstruowany", "z", "200", "cech", "m\u00f3g\u0142", "da\u0107", "95", "%", "wska\u017anik", "wykrywalno\u015bci", "przy", "^", "{", "-5", "}", "/", "math", "FALSE", "positive", "rate", ".", "P", ".", "Viola", ",", "M", ".", "Jones", ",", "Robust", "Real-time", "Object", "Detection", ",", "2001", "."], "sentence-detokenized": "Po boostingu, klasyfikator skonstruowany z 200 cech m\u00f3g\u0142 da\u0107 95% wska\u017anik wykrywalno\u015bci przy ^ {-5} / math FALSE positive rate .P. Viola, M. Jones, Robust Real-time Object Detection, 2001.", "token2charspan": [[0, 2], [3, 12], [12, 13], [14, 26], [27, 40], [41, 42], [43, 46], [47, 51], [52, 56], [57, 60], [61, 63], [63, 64], [65, 73], [74, 87], [88, 92], [93, 94], [95, 96], [96, 98], [98, 99], [100, 101], [102, 106], [107, 112], [113, 121], [122, 126], [127, 128], [128, 129], [129, 130], [131, 136], [136, 137], [138, 139], [139, 140], [141, 146], [146, 147], [148, 154], [155, 164], [165, 171], [172, 181], [181, 182], [183, 187], [187, 188]]}
{"doc_key": "ai-test-97", "ner": [[5, 5, "programlang"], [8, 8, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Strona", "by\u0142a", "pierwotnie", "oparta", "na", "Perlu", ",", "ale", "IMDb", "nie", "ujawnia", "ju\u017c", ",", "jakiego", "oprogramowania", "u\u017cywa", "ze", "wzgl\u0119d\u00f3w", "bezpiecze\u0144stwa", "."], "sentence-detokenized": "Strona by\u0142a pierwotnie oparta na Perlu, ale IMDb nie ujawnia ju\u017c, jakiego oprogramowania u\u017cywa ze wzgl\u0119d\u00f3w bezpiecze\u0144stwa.", "token2charspan": [[0, 6], [7, 11], [12, 22], [23, 29], [30, 32], [33, 38], [38, 39], [40, 43], [44, 48], [49, 52], [53, 60], [61, 64], [64, 65], [66, 73], [74, 88], [89, 94], [95, 97], [98, 106], [107, 121], [121, 122]]}
{"doc_key": "ai-test-98", "ner": [[6, 7, "researcher"], [9, 10, "researcher"], [12, 13, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Start", "-", "up", "zosta\u0142", "za\u0142o\u017cony", "przez", "Demisa", "Hassabisa", ",", "Shane'a", "Legga", "i", "Mustaf\u0119", "Suleymana", "w", "2010", "roku", "."], "sentence-detokenized": "Start-up zosta\u0142 za\u0142o\u017cony przez Demisa Hassabisa, Shane'a Legga i Mustaf\u0119 Suleymana w 2010 roku.", "token2charspan": [[0, 5], [5, 6], [6, 8], [9, 15], [16, 24], [25, 30], [31, 37], [38, 47], [47, 48], [49, 56], [57, 62], [63, 64], [65, 72], [73, 82], [83, 84], [85, 89], [90, 94], [94, 95]]}
{"doc_key": "ai-test-99", "ner": [[4, 5, "misc"], [7, 9, "metrics"], [23, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 4, 5, "type-of", "", false, false], [23, 24, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Dwie", "bardzo", "powszechnie", "stosowane", "funkcje", "strat", "to", "\u015bredni", "b\u0142\u0105d", "kwadratowy", ",", "mathL", "(", "a", ")", "=", "a", "^", "2", "/", "math", ",", "oraz", "strata", "bezwzgl\u0119dna", ",", "mathL", "(", "a", ")", "=", "|", "a", "|", "/", "math", "."], "sentence-detokenized": "Dwie bardzo powszechnie stosowane funkcje strat to \u015bredni b\u0142\u0105d kwadratowy, mathL (a) = a ^ 2 / math, oraz strata bezwzgl\u0119dna, mathL (a) = | a | / math.", "token2charspan": [[0, 4], [5, 11], [12, 23], [24, 33], [34, 41], [42, 47], [48, 50], [51, 57], [58, 62], [63, 73], [73, 74], [75, 80], [81, 82], [82, 83], [83, 84], [85, 86], [87, 88], [89, 90], [91, 92], [93, 94], [95, 99], [99, 100], [101, 105], [106, 112], [113, 124], [124, 125], [126, 131], [132, 133], [133, 134], [134, 135], [136, 137], [138, 139], [140, 141], [142, 143], [144, 145], [146, 150], [150, 151]]}
{"doc_key": "ai-test-100", "ner": [[2, 4, "algorithm"], [10, 12, "algorithm"], [14, 14, "algorithm"], [17, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 4, 10, 12, "type-of", "example_of", false, false], [10, 12, 17, 18, "related-to", "", false, false], [14, 14, 10, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Opisana", "powy\u017cej", "maszyna", "wektor\u00f3w", "wspieraj\u0105cych", "o", "mi\u0119kkiej", "mar\u017cy", "jest", "przyk\u0142adem", "empirycznej", "minimalizacji", "ryzyka", "(", "ERM", ")", "dla", "straty", "zawiasowej", "."], "sentence-detokenized": "Opisana powy\u017cej maszyna wektor\u00f3w wspieraj\u0105cych o mi\u0119kkiej mar\u017cy jest przyk\u0142adem empirycznej minimalizacji ryzyka (ERM) dla straty zawiasowej.", "token2charspan": [[0, 7], [8, 15], [16, 23], [24, 32], [33, 46], [47, 48], [49, 57], [58, 63], [64, 68], [69, 79], [80, 91], [92, 105], [106, 112], [113, 114], [114, 117], [117, 118], [119, 122], [123, 129], [130, 140], [140, 141]]}
{"doc_key": "ai-test-101", "ner": [[5, 6, "field"], [2, 2, "task"], [8, 12, "task"], [19, 19, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 12, 5, 6, "origin", "", false, false], [8, 12, 2, 2, "type-of", "", false, false], [19, 19, 8, 12, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Podej\u015bcie", "do", "MT", "oparte", "na", "g\u0142\u0119bokim", "uczeniu", ",", "neuronowe", "t\u0142umaczenie", "maszynowe", "poczyni\u0142o", "w", "ostatnich", "latach", "szybkie", "post\u0119py", ",", "a", "Google", "og\u0142osi\u0142o", ",", "\u017ce", "jego", "us\u0142ugi", "t\u0142umaczeniowe", "korzystaj\u0105", "teraz", "z", "tej", "technologii", "zamiast", "poprzednich", "metod", "statystycznych", "."], "sentence-detokenized": "Podej\u015bcie do MT oparte na g\u0142\u0119bokim uczeniu, neuronowe t\u0142umaczenie maszynowe poczyni\u0142o w ostatnich latach szybkie post\u0119py, a Google og\u0142osi\u0142o, \u017ce jego us\u0142ugi t\u0142umaczeniowe korzystaj\u0105 teraz z tej technologii zamiast poprzednich metod statystycznych.", "token2charspan": [[0, 9], [10, 12], [13, 15], [16, 22], [23, 25], [26, 34], [35, 42], [42, 43], [44, 53], [54, 65], [66, 75], [76, 85], [86, 87], [88, 97], [98, 104], [105, 112], [113, 120], [120, 121], [122, 123], [124, 130], [131, 139], [139, 140], [141, 143], [144, 148], [149, 155], [156, 169], [170, 180], [181, 186], [187, 188], [189, 192], [193, 204], [205, 212], [213, 224], [225, 230], [231, 245], [245, 246]]}
{"doc_key": "ai-test-102", "ner": [[8, 8, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Przy", "pracy", "z", "du\u017cymi", "korpusami", ",", "takimi", "jak", "WordNet", ",", "daje", "to", "zwykle", "bardzo", "du\u017cy", "wzrost", "wydajno\u015bci", "."], "sentence-detokenized": "Przy pracy z du\u017cymi korpusami, takimi jak WordNet, daje to zwykle bardzo du\u017cy wzrost wydajno\u015bci.", "token2charspan": [[0, 4], [5, 10], [11, 12], [13, 19], [20, 29], [29, 30], [31, 37], [38, 41], [42, 49], [49, 50], [51, 55], [56, 58], [59, 65], [66, 72], [73, 77], [78, 84], [85, 95], [95, 96]]}
{"doc_key": "ai-test-103", "ner": [[0, 1, "task"], [5, 5, "field"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 15, 17, "part-of", "", false, false], [15, 17, 5, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Wykrywanie", "twarzy", "jest", "wykorzystywane", "w", "biometrii", ",", "cz\u0119sto", "jako", "cz\u0119\u015b\u0107", "(", "lub", "razem", "z", ")", "systemem", "rozpoznawania", "twarzy", "."], "sentence-detokenized": "Wykrywanie twarzy jest wykorzystywane w biometrii, cz\u0119sto jako cz\u0119\u015b\u0107 (lub razem z) systemem rozpoznawania twarzy.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 37], [38, 39], [40, 49], [49, 50], [51, 57], [58, 62], [63, 68], [69, 70], [70, 73], [74, 79], [80, 81], [81, 82], [83, 91], [92, 105], [106, 112], [112, 113]]}
{"doc_key": "ai-test-104", "ner": [[3, 6, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["przeszkolonych", "za", "pomoc\u0105", "estymacji", "z", "maksymalnym", "prawdopodobie\u0144stwem", "."], "sentence-detokenized": "przeszkolonych za pomoc\u0105 estymacji z maksymalnym prawdopodobie\u0144stwem.", "token2charspan": [[0, 14], [15, 17], [18, 24], [25, 34], [35, 36], [37, 48], [49, 68], [68, 69]]}
{"doc_key": "ai-test-105", "ner": [[4, 4, "country"], [6, 12, "organisation"], [17, 18, "location"], [19, 19, "country"], [21, 25, "organisation"], [27, 29, "country"], [33, 33, "organisation"], [40, 43, "organisation"], [45, 48, "country"], [60, 64, "organisation"], [66, 67, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[6, 12, 17, 18, "physical", "", false, false], [17, 18, 19, 19, "physical", "", false, false], [21, 25, 27, 29, "physical", "", false, false], [40, 43, 45, 48, "physical", "", false, false], [60, 64, 66, 67, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": [",", "Ltd", ".", "w", "Tajlandii", ";", "Komatsu", "(", "Shanghai", ")", "Ltd", ".", "w", "1996", "r", ".", "w", "Szanghaju", "w", "Chinach", ";", "Industrial", "Power", "Alliance", "Ltd", ".", "w", "Japonii", ",", "sp\u00f3\u0142ka", "joint", "venture", "z", "Cummins", ",", "w", "1998", "r", ".", ";", "L", "&", "T-Komatsu", "Limited", "w", "Indiach", "w", "1998", "r", ".", "(", "udzia\u0142y", "sprzedane", "w", "2013", "r", ".", ")", ";", "oraz", "Komatsu", "Brasil", "International", "Ltda", ".", "w", "Brazylii", "w", "1998", "r", "."], "sentence-detokenized": ", Ltd. w Tajlandii; Komatsu (Shanghai) Ltd. w 1996 r. w Szanghaju w Chinach; Industrial Power Alliance Ltd. w Japonii, sp\u00f3\u0142ka joint venture z Cummins, w 1998 r.; L & T-Komatsu Limited w Indiach w 1998 r. (udzia\u0142y sprzedane w 2013 r.); oraz Komatsu Brasil International Ltda. w Brazylii w 1998 r.", "token2charspan": [[0, 1], [2, 5], [5, 6], [7, 8], [9, 18], [18, 19], [20, 27], [28, 29], [29, 37], [37, 38], [39, 42], [42, 43], [44, 45], [46, 50], [51, 52], [52, 53], [54, 55], [56, 65], [66, 67], [68, 75], [75, 76], [77, 87], [88, 93], [94, 102], [103, 106], [106, 107], [108, 109], [110, 117], [117, 118], [119, 125], [126, 131], [132, 139], [140, 141], [142, 149], [149, 150], [151, 152], [153, 157], [158, 159], [159, 160], [160, 161], [162, 163], [164, 165], [166, 175], [176, 183], [184, 185], [186, 193], [194, 195], [196, 200], [201, 202], [202, 203], [204, 205], [205, 212], [213, 222], [223, 224], [225, 229], [230, 231], [231, 232], [232, 233], [233, 234], [235, 239], [240, 247], [248, 254], [255, 268], [269, 273], [273, 274], [275, 276], [277, 285], [286, 287], [288, 292], [293, 294], [294, 295]]}
{"doc_key": "ai-test-106", "ner": [[0, 0, "organisation"], [4, 6, "misc"], [11, 11, "misc"], [12, 13, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 13, 0, 0, "physical", "", false, false], [12, 13, 4, 6, "general-affiliation", "", false, false], [12, 13, 11, 11, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["dgp", "go\u015bci", "r\u00f3wnie\u017c", "czasami", "artyst\u00f3w", "-", "rezydent\u00f3w", "(", "np", ".", "zdobywc\u0119", "Oscara", "Chrisa", "Landretha", "."], "sentence-detokenized": "dgp go\u015bci r\u00f3wnie\u017c czasami artyst\u00f3w-rezydent\u00f3w (np. zdobywc\u0119 Oscara Chrisa Landretha.", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 25], [26, 34], [34, 35], [35, 45], [46, 47], [47, 49], [49, 50], [51, 59], [60, 66], [67, 73], [74, 83], [83, 84]]}
{"doc_key": "ai-test-107", "ner": [[6, 8, "misc"], [11, 12, "misc"], [14, 17, "misc"], [21, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Obecnie", "obejmuje", "on", "cztery", "podkonkursy", "-", "RoboMaster", "Robotics", "Competition", ",", "RoboMaster", "Technical", "Challenge", ",", "ICRA", "RoboMaster", "AI", "Challenge", "oraz", "nowy", "RoboMaster", "Youth", "Tournament", "."], "sentence-detokenized": "Obecnie obejmuje on cztery podkonkursy - RoboMaster Robotics Competition, RoboMaster Technical Challenge, ICRA RoboMaster AI Challenge oraz nowy RoboMaster Youth Tournament.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 26], [27, 38], [39, 40], [41, 51], [52, 60], [61, 72], [72, 73], [74, 84], [85, 94], [95, 104], [104, 105], [106, 110], [111, 121], [122, 124], [125, 134], [135, 139], [140, 144], [145, 155], [156, 161], [162, 172], [172, 173]]}
{"doc_key": "ai-test-108", "ner": [[6, 7, "field"], [11, 13, "algorithm"], [18, 19, "algorithm"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 7, 18, 19, "usage", "", false, false], [6, 7, 21, 22, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Do", "pocz\u0105tku", "XXI", "wieku", "dominuj\u0105ca", "strategia", "przetwarzania", "mowy", "zacz\u0119\u0142a", "odchodzi\u0107", "od", "Ukrytego", "Modelu", "Markowa", "w", "kierunku", "bardziej", "nowoczesnych", "sieci", "neuronowych", "i", "g\u0142\u0119bokiego", "uczenia", "."], "sentence-detokenized": "Do pocz\u0105tku XXI wieku dominuj\u0105ca strategia przetwarzania mowy zacz\u0119\u0142a odchodzi\u0107 od Ukrytego Modelu Markowa w kierunku bardziej nowoczesnych sieci neuronowych i g\u0142\u0119bokiego uczenia.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 21], [22, 32], [33, 42], [43, 56], [57, 61], [62, 69], [70, 79], [80, 82], [83, 91], [92, 98], [99, 106], [107, 108], [109, 117], [118, 126], [127, 139], [140, 145], [146, 157], [158, 159], [160, 170], [171, 178], [178, 179]]}
{"doc_key": "ai-test-109", "ner": [[6, 8, "misc"], [15, 16, "metrics"], [19, 20, "metrics"], [27, 28, "metrics"], [32, 34, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 16, 19, 20, "related-to", "equal", false, false], [27, 28, 32, 34, "related-to", "equal", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Innym", "r\u00f3wnowa\u017cnym", "wyra\u017ceniem", ",", "w", "przypadku", "binarnego", "wska\u017anika", "docelowego", ",", "jest", "to", ",", "\u017ce", "wska\u017anik", "pozytywny", "TRUE", "i", "wska\u017anik", "pozytywny", "FALSE", "s\u0105", "r\u00f3wne", "(", "a", "zatem", "wska\u017anik", "negatywny", "FALSE", "i", "wska\u017anik", "negatywny", "TRUE", "s\u0105", "r\u00f3wne", ")", "dla", "ka\u017cdej", "warto\u015bci", "cechy", "wra\u017cliwej", ":"], "sentence-detokenized": "Innym r\u00f3wnowa\u017cnym wyra\u017ceniem, w przypadku binarnego wska\u017anika docelowego, jest to, \u017ce wska\u017anik pozytywny TRUE i wska\u017anik pozytywny FALSE s\u0105 r\u00f3wne (a zatem wska\u017anik negatywny FALSE i wska\u017anik negatywny TRUE s\u0105 r\u00f3wne) dla ka\u017cdej warto\u015bci cechy wra\u017cliwej:", "token2charspan": [[0, 5], [6, 17], [18, 28], [28, 29], [30, 31], [32, 41], [42, 51], [52, 61], [62, 72], [72, 73], [74, 78], [79, 81], [81, 82], [83, 85], [86, 94], [95, 104], [105, 109], [110, 111], [112, 120], [121, 130], [131, 136], [137, 139], [140, 145], [146, 147], [147, 148], [149, 154], [155, 163], [164, 173], [174, 179], [180, 181], [182, 190], [191, 200], [201, 205], [206, 208], [209, 214], [214, 215], [216, 219], [220, 226], [227, 235], [236, 241], [242, 251], [251, 252]]}
{"doc_key": "ai-test-110", "ner": [[1, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Funkcja", "MATLAB", ","], "sentence-detokenized": "Funkcja MATLAB,", "token2charspan": [[0, 7], [8, 14], [14, 15]]}
{"doc_key": "ai-test-111", "ner": [[0, 1, "product"], [5, 6, "misc"], [14, 14, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 0, 1, "part-of", "", false, false], [14, 14, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Robot", "przegubowy", "to", "robot", "posiadaj\u0105cy", "stawy", "obrotowe", "(", "np", ".", "robot", "noga", "lub", "robot", "przemys\u0142owy", ")", "."], "sentence-detokenized": "Robot przegubowy to robot posiadaj\u0105cy stawy obrotowe (np. robot noga lub robot przemys\u0142owy).", "token2charspan": [[0, 5], [6, 16], [17, 19], [20, 25], [26, 37], [38, 43], [44, 52], [53, 54], [54, 56], [56, 57], [58, 63], [64, 68], [69, 72], [73, 78], [79, 90], [90, 91], [91, 92]]}
{"doc_key": "ai-test-112", "ner": [[0, 0, "product"], [6, 6, "product"], [8, 9, "product"], [12, 12, "misc"], [18, 20, "product"], [23, 27, "misc"], [30, 30, "location"], [32, 32, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 12, 12, "general-affiliation", "nationality", false, false], [0, 0, 23, 27, "usage", "", false, false], [0, 0, 30, 30, "physical", "", false, false], [6, 6, 0, 0, "named", "", false, false], [8, 9, 0, 0, "named", "", false, false], [30, 30, 32, 32, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pandora", "(", "znana", "r\u00f3wnie\u017c", "jako", "Pandora", "Media", "lub", "Pandora", "Radio", ")", "to", "ameryka\u0144ska", "muzyczna", "us\u0142uga", "radiowa", "strumieniowa", "i", "automatyczny", "system", "Recommender", "zasilany", "przez", "Music", "Genome", "Project", "i", "z", "siedzib\u0105", "w", "Oakland", "w", "Kalifornii", "."], "sentence-detokenized": "Pandora (znana r\u00f3wnie\u017c jako Pandora Media lub Pandora Radio) to ameryka\u0144ska muzyczna us\u0142uga radiowa strumieniowa i automatyczny system Recommender zasilany przez Music Genome Project i z siedzib\u0105 w Oakland w Kalifornii.", "token2charspan": [[0, 7], [8, 9], [9, 14], [15, 22], [23, 27], [28, 35], [36, 41], [42, 45], [46, 53], [54, 59], [59, 60], [61, 63], [64, 75], [76, 84], [85, 91], [92, 99], [100, 112], [113, 114], [115, 127], [128, 134], [135, 146], [147, 155], [156, 161], [162, 167], [168, 174], [175, 182], [183, 184], [185, 186], [187, 195], [196, 197], [198, 205], [206, 207], [208, 218], [218, 219]]}
{"doc_key": "ai-test-113", "ner": [[3, 6, "organisation"], [10, 12, "organisation"], [18, 19, "conference"], [31, 31, "conference"], [33, 33, "conference"], [35, 35, "conference"], [37, 37, "conference"], [39, 39, "conference"], [41, 41, "conference"], [43, 43, "conference"], [45, 45, "conference"], [47, 47, "conference"], [49, 49, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [], "relations_mapping_to_source": [], "sentence": ["Jest", "cz\u0142onkiem", "zarz\u0105du", "International", "Machine", "Learning", "Society", ",", "by\u0142a", "cz\u0142onkiem", "rady", "wykonawczej", "AAAI", ",", "by\u0142a", "PC", "co", "-chair", "ICML", "2011", ",", "i", "s\u0142u\u017cy\u0142a", "jako", "senior", "PC", "member", "na", "konferencjach", "takich", "jak", "AAAI", ",", "ICML", ",", "IJCAI", ",", "ISWC", ",", "KDD", ",", "SIGMOD", ",", "UAI", ",", "VLDB", ",", "WSDM", "i", "WWW", "."], "sentence-detokenized": "Jest cz\u0142onkiem zarz\u0105du International Machine Learning Society, by\u0142a cz\u0142onkiem rady wykonawczej AAAI, by\u0142a PC co-chair ICML 2011, i s\u0142u\u017cy\u0142a jako senior PC member na konferencjach takich jak AAAI, ICML, IJCAI, ISWC, KDD, SIGMOD, UAI, VLDB, WSDM i WWW.", "token2charspan": [[0, 4], [5, 14], [15, 22], [23, 36], [37, 44], [45, 53], [54, 61], [61, 62], [63, 67], [68, 77], [78, 82], [83, 94], [95, 99], [99, 100], [101, 105], [106, 108], [109, 111], [111, 117], [118, 122], [123, 127], [127, 128], [129, 130], [131, 138], [139, 143], [144, 150], [151, 153], [154, 160], [161, 163], [164, 177], [178, 184], [185, 188], [189, 193], [193, 194], [195, 199], [199, 200], [201, 206], [206, 207], [208, 212], [212, 213], [214, 217], [217, 218], [219, 225], [225, 226], [227, 230], [230, 231], [232, 236], [236, 237], [238, 242], [243, 244], [245, 248], [248, 249]]}
{"doc_key": "ai-test-114", "ner": [[0, 3, "researcher"], [5, 10, "organisation"], [12, 12, "organisation"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 5, 10, "role", "", false, false], [12, 12, 5, 10, "named", "", false, false], [15, 15, 0, 3, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["James", "S", ".", "Albus", "z", "National", "Institute", "of", "Standards", "and", "Technology", "(", "NIST", ")", "opracowa\u0142", "Robocrane", ",", "w", "kt\u00f3rym", "platforma", "zamiast", "by\u0107", "podtrzymywana", "przez", "sze\u015b\u0107", "podno\u015bnik\u00f3w", ",", "wisi", "na", "sze\u015bciu", "kablach", "."], "sentence-detokenized": "James S. Albus z National Institute of Standards and Technology (NIST) opracowa\u0142 Robocrane, w kt\u00f3rym platforma zamiast by\u0107 podtrzymywana przez sze\u015b\u0107 podno\u015bnik\u00f3w, wisi na sze\u015bciu kablach.", "token2charspan": [[0, 5], [6, 7], [7, 8], [9, 14], [15, 16], [17, 25], [26, 35], [36, 38], [39, 48], [49, 52], [53, 63], [64, 65], [65, 69], [69, 70], [71, 80], [81, 90], [90, 91], [92, 93], [94, 100], [101, 110], [111, 118], [119, 122], [123, 136], [137, 142], [143, 148], [149, 160], [160, 161], [162, 166], [167, 169], [170, 177], [178, 185], [185, 186]]}
{"doc_key": "ai-test-115", "ner": [[2, 4, "algorithm"], [8, 8, "algorithm"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 2, 4, "type-of", "", false, false], [12, 13, 8, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Inn\u0105", "klas\u0105", "algorytm\u00f3w", "wyszukiwania", "bezpo\u015bredniego", "s\u0105", "r\u00f3\u017cne", "algorytmy", "ewolucyjne", ",", "np", ".", "algorytmy", "genetyczne", "."], "sentence-detokenized": "Inn\u0105 klas\u0105 algorytm\u00f3w wyszukiwania bezpo\u015bredniego s\u0105 r\u00f3\u017cne algorytmy ewolucyjne, np. algorytmy genetyczne.", "token2charspan": [[0, 4], [5, 10], [11, 21], [22, 34], [35, 49], [50, 52], [53, 58], [59, 68], [69, 79], [79, 80], [81, 83], [83, 84], [85, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-test-116", "ner": [[0, 0, "organisation"], [2, 3, "misc"], [4, 5, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 3, 0, 0, "named", "", false, false], [4, 5, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["KUKA", "to", "niemiecki", "producent", "robot\u00f3w", "przemys\u0142owych", "i", "rozwi\u0105za\u0144", "dla", "automatyzacji", "fabryk", "."], "sentence-detokenized": "KUKA to niemiecki producent robot\u00f3w przemys\u0142owych i rozwi\u0105za\u0144 dla automatyzacji fabryk.", "token2charspan": [[0, 4], [5, 7], [8, 17], [18, 27], [28, 35], [36, 49], [50, 51], [52, 61], [62, 65], [66, 79], [80, 86], [86, 87]]}
{"doc_key": "ai-test-117", "ner": [[13, 13, "misc"], [23, 24, "person"], [16, 21, "misc"], [29, 30, "person"], [27, 27, "misc"], [36, 37, "person"], [33, 34, "misc"], [44, 45, "person"], [40, 42, "misc"], [52, 54, "person"], [48, 50, "misc"], [60, 61, "person"], [57, 63, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[23, 24, 13, 13, "usage", "", false, false], [16, 21, 23, 24, "artifact", "", false, false], [29, 30, 13, 13, "usage", "", false, false], [27, 27, 29, 30, "artifact", "", false, false], [36, 37, 13, 13, "usage", "", false, false], [33, 34, 36, 37, "artifact", "", false, false], [44, 45, 13, 13, "usage", "", false, false], [40, 42, 44, 45, "artifact", "", false, false], [52, 54, 13, 13, "usage", "", false, false], [48, 50, 52, 54, "artifact", "", false, false], [60, 61, 13, 13, "usage", "", false, false], [57, 63, 60, 61, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Inne", "filmy", "w", "latach", "2016", "-", "2020", ",", "kt\u00f3re", "uchwycono", "za", "pomoc\u0105", "kamer", "IMAX", "to", "\"", "Batman", "v", "Superman", ":", "\u015awit", "sprawiedliwo\u015bci", "\"", "Zacka", "Snydera", ",", "\"", "Sully", "\"", "Clinta", "Eastwooda", ",", "\"", "First", "Man", "\"", "Damiena", "Chazelle'a", ",", "\"", "Wonder", "Woman", "1984", "\"", "Patty", "Jenkins", ",", "\"", "Nie", "czas", "umiera\u0107", "\"", "Cary'ego", "Joji", "Fukunagi", "i", "\"", "Top", "Gun", "\"", "Josepha", "Kosinskiego", ":", "Maverick", "."], "sentence-detokenized": "Inne filmy w latach 2016-2020, kt\u00f3re uchwycono za pomoc\u0105 kamer IMAX to \"Batman v Superman: \u015awit sprawiedliwo\u015bci\" Zacka Snydera, \"Sully\" Clinta Eastwooda, \"First Man\" Damiena Chazelle'a, \"Wonder Woman 1984\" Patty Jenkins, \"Nie czas umiera\u0107\" Cary'ego Joji Fukunagi i \"Top Gun\" Josepha Kosinskiego: Maverick.", "token2charspan": [[0, 4], [5, 10], [11, 12], [13, 19], [20, 24], [24, 25], [25, 29], [29, 30], [31, 36], [37, 46], [47, 49], [50, 56], [57, 62], [63, 67], [68, 70], [71, 72], [72, 78], [79, 80], [81, 89], [89, 90], [91, 95], [96, 111], [111, 112], [113, 118], [119, 126], [126, 127], [128, 129], [129, 134], [134, 135], [136, 142], [143, 152], [152, 153], [154, 155], [155, 160], [161, 164], [164, 165], [166, 173], [174, 184], [184, 185], [186, 187], [187, 193], [194, 199], [200, 204], [204, 205], [206, 211], [212, 219], [219, 220], [221, 222], [222, 225], [226, 230], [231, 238], [238, 239], [240, 248], [249, 253], [254, 262], [263, 264], [265, 266], [266, 269], [270, 273], [273, 274], [275, 282], [283, 294], [294, 295], [296, 304], [304, 305]]}
{"doc_key": "ai-test-118", "ner": [[2, 3, "misc"], [10, 11, "organisation"], [14, 14, "organisation"], [25, 25, "misc"], [30, 31, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 25, 25, "named", "", false, false], [10, 11, 2, 3, "usage", "", false, false], [10, 11, 30, 31, "physical", "", false, false], [14, 14, 10, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Pr\u00f3ba", "czcionki", "MICR", "E13B", "zosta\u0142a", "pokazana", "w", "lipcu", "1956", "roku", "Ameryka\u0144skiemu", "Stowarzyszeniu", "Bankier\u00f3w", "(", "ABA", ")", ",", "kt\u00f3re", "przyj\u0119\u0142o", "j\u0105", "w", "1958", "roku", "jako", "standard", "MICR", "dla", "dokument\u00f3w", "zbywalnych", "w", "Stanach", "Zjednoczonych", "."], "sentence-detokenized": "Pr\u00f3ba czcionki MICR E13B zosta\u0142a pokazana w lipcu 1956 roku Ameryka\u0144skiemu Stowarzyszeniu Bankier\u00f3w (ABA), kt\u00f3re przyj\u0119\u0142o j\u0105 w 1958 roku jako standard MICR dla dokument\u00f3w zbywalnych w Stanach Zjednoczonych.", "token2charspan": [[0, 5], [6, 14], [15, 19], [20, 24], [25, 32], [33, 41], [42, 43], [44, 49], [50, 54], [55, 59], [60, 74], [75, 89], [90, 99], [100, 101], [101, 104], [104, 105], [105, 106], [107, 112], [113, 121], [122, 124], [125, 126], [127, 131], [132, 136], [137, 141], [142, 150], [151, 155], [156, 159], [160, 170], [171, 181], [182, 183], [184, 191], [192, 205], [205, 206]]}
{"doc_key": "ai-test-119", "ner": [[0, 2, "misc"], [16, 16, "field"], [20, 21, "field"], [24, 24, "field"], [26, 27, "field"], [29, 29, "field"], [31, 31, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[16, 16, 0, 2, "usage", "", false, false], [20, 21, 16, 16, "part-of", "", false, false], [24, 24, 0, 2, "usage", "", false, false], [26, 27, 0, 2, "usage", "", false, false], [29, 29, 0, 2, "usage", "", false, false], [31, 31, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Algorytmy", "przeszukiwania", "lokalnego", "s\u0105", "szeroko", "stosowane", "do", "wielu", "trudnych", "problem\u00f3w", "obliczeniowych", ",", "w", "tym", "problem\u00f3w", "z", "informatyki", "(", "w", "szczeg\u00f3lno\u015bci", "sztucznej", "inteligencji", ")", ",", "matematyki", ",", "bada\u0144", "operacyjnych", ",", "in\u017cynierii", "i", "bioinformatyki", "."], "sentence-detokenized": "Algorytmy przeszukiwania lokalnego s\u0105 szeroko stosowane do wielu trudnych problem\u00f3w obliczeniowych, w tym problem\u00f3w z informatyki (w szczeg\u00f3lno\u015bci sztucznej inteligencji), matematyki, bada\u0144 operacyjnych, in\u017cynierii i bioinformatyki.", "token2charspan": [[0, 9], [10, 24], [25, 34], [35, 37], [38, 45], [46, 55], [56, 58], [59, 64], [65, 73], [74, 83], [84, 98], [98, 99], [100, 101], [102, 105], [106, 115], [116, 117], [118, 129], [130, 131], [131, 132], [133, 146], [147, 156], [157, 169], [169, 170], [170, 171], [172, 182], [182, 183], [184, 189], [190, 202], [202, 203], [204, 214], [215, 216], [217, 231], [231, 232]]}
{"doc_key": "ai-test-120", "ner": [[0, 1, "researcher"], [9, 9, "location"], [11, 11, "country"], [14, 14, "country"], [20, 21, "algorithm"], [23, 23, "algorithm"], [25, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 9, 9, "physical", "", false, false], [0, 1, 14, 14, "general-affiliation", "nationality", false, false], [0, 1, 20, 21, "general-affiliation", "topic_of_study", false, false], [0, 1, 23, 23, "general-affiliation", "topic_of_study", false, false], [9, 9, 11, 11, "physical", "", false, false], [23, 23, 25, 26, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gerd", "Gigerenzer", "(", "ur", ".", "3", "wrze\u015bnia", "1947", ",", "Wallersdorf", ",", "Niemcy", ")", "to", "niemiecki", "psycholog", ",", "kt\u00f3ry", "bada\u0142", "wykorzystanie", "ograniczonej", "racjonalno\u015bci", "i", "heurystyki", "w", "podejmowaniu", "decyzji", "."], "sentence-detokenized": "Gerd Gigerenzer (ur. 3 wrze\u015bnia 1947, Wallersdorf, Niemcy) to niemiecki psycholog, kt\u00f3ry bada\u0142 wykorzystanie ograniczonej racjonalno\u015bci i heurystyki w podejmowaniu decyzji.", "token2charspan": [[0, 4], [5, 15], [16, 17], [17, 19], [19, 20], [21, 22], [23, 31], [32, 36], [36, 37], [38, 49], [49, 50], [51, 57], [57, 58], [59, 61], [62, 71], [72, 81], [81, 82], [83, 88], [89, 94], [95, 108], [109, 121], [122, 135], [136, 137], [138, 148], [149, 150], [151, 163], [164, 171], [171, 172]]}
{"doc_key": "ai-test-121", "ner": [[2, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["aby", "zminimalizowa\u0107", "b\u0142\u0105d", "\u015bredniokwadratowy", "."], "sentence-detokenized": "aby zminimalizowa\u0107 b\u0142\u0105d \u015bredniokwadratowy.", "token2charspan": [[0, 3], [4, 18], [19, 23], [24, 41], [41, 42]]}
{"doc_key": "ai-test-122", "ner": [[11, 12, "misc"], [14, 15, "organisation"], [27, 29, "field"], [47, 48, "misc"], [58, 60, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 12, 14, 15, "origin", "", false, false], [47, 48, 58, 60, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Ale", "nawet", "j\u0119zyk", "urz\u0119dowy", "z", "reguluj\u0105c\u0105", "akademi\u0105", ",", "jak", "np", ".", "standardowy", "francuski", "z", "Acad\u00e9mie", "fran\u00e7aise", ",", "jest", "klasyfikowany", "jako", "j\u0119zyk", "naturalny", "(", "na", "przyk\u0142ad", "w", "dziedzinie", "przetwarzania", "j\u0119zyka", "naturalnego", ")", ",", "poniewa\u017c", "jego", "punkty", "normatywne", "nie", "czyni\u0105", "go", "ani", "wystarczaj\u0105co", "skonstruowanym", ",", "aby", "by\u0142", "klasyfikowany", "jako", "j\u0119zyk", "skonstruowany", ",", "ani", "wystarczaj\u0105co", "kontrolowanym", ",", "aby", "by\u0142", "klasyfikowany", "jako", "kontrolowany", "j\u0119zyk", "naturalny", "."], "sentence-detokenized": "Ale nawet j\u0119zyk urz\u0119dowy z reguluj\u0105c\u0105 akademi\u0105, jak np. standardowy francuski z Acad\u00e9mie fran\u00e7aise, jest klasyfikowany jako j\u0119zyk naturalny (na przyk\u0142ad w dziedzinie przetwarzania j\u0119zyka naturalnego), poniewa\u017c jego punkty normatywne nie czyni\u0105 go ani wystarczaj\u0105co skonstruowanym, aby by\u0142 klasyfikowany jako j\u0119zyk skonstruowany, ani wystarczaj\u0105co kontrolowanym, aby by\u0142 klasyfikowany jako kontrolowany j\u0119zyk naturalny.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 24], [25, 26], [27, 37], [38, 46], [46, 47], [48, 51], [52, 54], [54, 55], [56, 67], [68, 77], [78, 79], [80, 88], [89, 98], [98, 99], [100, 104], [105, 118], [119, 123], [124, 129], [130, 139], [140, 141], [141, 143], [144, 152], [153, 154], [155, 165], [166, 179], [180, 186], [187, 198], [198, 199], [199, 200], [201, 209], [210, 214], [215, 221], [222, 232], [233, 236], [237, 243], [244, 246], [247, 250], [251, 264], [265, 279], [279, 280], [281, 284], [285, 288], [289, 302], [303, 307], [308, 313], [314, 327], [327, 328], [329, 332], [333, 346], [347, 360], [360, 361], [362, 365], [366, 369], [370, 383], [384, 388], [389, 401], [402, 407], [408, 417], [417, 418]]}
{"doc_key": "ai-test-123", "ner": [[9, 9, "metrics"], [11, 12, "metrics"], [14, 14, "metrics"], [30, 31, "metrics"], [33, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 14, 11, 12, "named", "", false, false], [33, 33, 30, 31, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Istnieje", "wiele", "innych", "metryk", ",", "z", "kt\u00f3rych", "najprostsz\u0105", "jest", "dok\u0142adno\u015b\u0107", "lub", "Frakcja", "Poprawna", "(", "FC", ")", ",", "kt\u00f3ra", "mierzy", "frakcj\u0119", "wszystkich", "instancji", ",", "kt\u00f3re", "s\u0105", "poprawnie", "skategoryzowane", ";", "uzupe\u0142nieniem", "jest", "Frakcja", "Niepoprawna", "(", "FiC", ")", "."], "sentence-detokenized": "Istnieje wiele innych metryk, z kt\u00f3rych najprostsz\u0105 jest dok\u0142adno\u015b\u0107 lub Frakcja Poprawna (FC), kt\u00f3ra mierzy frakcj\u0119 wszystkich instancji, kt\u00f3re s\u0105 poprawnie skategoryzowane; uzupe\u0142nieniem jest Frakcja Niepoprawna (FiC).", "token2charspan": [[0, 8], [9, 14], [15, 21], [22, 28], [28, 29], [30, 31], [32, 39], [40, 51], [52, 56], [57, 67], [68, 71], [72, 79], [80, 88], [89, 90], [90, 92], [92, 93], [93, 94], [95, 100], [101, 107], [108, 115], [116, 126], [127, 136], [136, 137], [138, 143], [144, 146], [147, 156], [157, 172], [172, 173], [174, 187], [188, 192], [193, 200], [201, 212], [213, 214], [214, 217], [217, 218], [218, 219]]}
{"doc_key": "ai-test-124", "ner": [[0, 0, "researcher"], [7, 11, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 7, 11, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cardie", "zosta\u0142", "w", "2016", "roku", "Fellow", "of", "the", "Association", "for", "Computational", "Linguistics", "."], "sentence-detokenized": "Cardie zosta\u0142 w 2016 roku Fellow of the Association for Computational Linguistics.", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 20], [21, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 69], [70, 81], [81, 82]]}
{"doc_key": "ai-test-125", "ner": [[19, 22, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Uczenie", "si\u0119", "parametr\u00f3w", "mathp", "(", "Y", "_", "i", "|", "X", "_", "i;\u0105", ")", "/", "math", "jest", "zwykle", "wykonywane", "przez", "uczenie", "z", "maksymalnym", "prawdopodobie\u0144stwem", "dla", "mathp", "(", "Y", "_", "i", "|", "X", "_", "i;\u0105", ")", "/", "math", "."], "sentence-detokenized": "Uczenie si\u0119 parametr\u00f3w mathp (Y _ i | X _ i;\u0105) / math jest zwykle wykonywane przez uczenie z maksymalnym prawdopodobie\u0144stwem dla mathp (Y _ i | X _ i;\u0105) / math.", "token2charspan": [[0, 7], [8, 11], [12, 22], [23, 28], [29, 30], [30, 31], [32, 33], [34, 35], [36, 37], [38, 39], [40, 41], [42, 45], [45, 46], [47, 48], [49, 53], [54, 58], [59, 65], [66, 76], [77, 82], [83, 90], [91, 92], [93, 104], [105, 124], [125, 128], [129, 134], [135, 136], [136, 137], [138, 139], [140, 141], [142, 143], [144, 145], [146, 147], [148, 151], [151, 152], [153, 154], [155, 159], [159, 160]]}
{"doc_key": "ai-test-126", "ner": [[0, 1, "task"], [4, 6, "algorithm"], [9, 9, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 0, 1, "usage", "", true, false], [9, 9, 4, 6, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Analiza", "skupie\u0144", ",", "oraz", "faktoryzacja", "macierzy", "nieujemnej", "dla", "eksploracji", "opisowej", "."], "sentence-detokenized": "Analiza skupie\u0144, oraz faktoryzacja macierzy nieujemnej dla eksploracji opisowej.", "token2charspan": [[0, 7], [8, 15], [15, 16], [17, 21], [22, 34], [35, 43], [44, 54], [55, 58], [59, 70], [71, 79], [79, 80]]}
{"doc_key": "ai-test-127", "ner": [[1, 1, "field"], [5, 7, "field"], [15, 17, "field"], [19, 20, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 17, 1, 1, "part-of", "", false, false], [15, 17, 5, 7, "part-of", "", false, false], [19, 20, 1, 1, "part-of", "", false, false], [19, 20, 5, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["W", "informatyce", "i", "umo\u017cliwiaj\u0105cych", "j\u0105", "technologiach", "informatycznych", "od", "d\u0142u\u017cszego", "czasu", "kr\u00f3luje", "zdolno\u015b\u0107", "w", "komputerach", "do", "przetwarzania", "j\u0119zyka", "naturalnego", "i", "uczenia", "maszynowego", "."], "sentence-detokenized": "W informatyce i umo\u017cliwiaj\u0105cych j\u0105 technologiach informatycznych od d\u0142u\u017cszego czasu kr\u00f3luje zdolno\u015b\u0107 w komputerach do przetwarzania j\u0119zyka naturalnego i uczenia maszynowego.", "token2charspan": [[0, 1], [2, 13], [14, 15], [16, 31], [32, 34], [35, 48], [49, 64], [65, 67], [68, 77], [78, 83], [84, 91], [92, 100], [101, 102], [103, 114], [115, 117], [118, 131], [132, 138], [139, 150], [151, 152], [153, 160], [161, 172], [172, 173]]}
{"doc_key": "ai-test-128", "ner": [[3, 5, "algorithm"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 5, 9, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "Kod", "do", "ekstrakcji", "cech", "Gabora", "z", "obraz\u00f3w", "w", "MATLABie", "mo\u017cna", "znale\u017a\u0107", "na", "stronie"], "sentence-detokenized": "(Kod do ekstrakcji cech Gabora z obraz\u00f3w w MATLABie mo\u017cna znale\u017a\u0107 na stronie", "token2charspan": [[0, 1], [1, 4], [5, 7], [8, 18], [19, 23], [24, 30], [31, 32], [33, 40], [41, 42], [43, 51], [52, 57], [58, 65], [66, 68], [69, 76]]}
{"doc_key": "ai-test-129", "ner": [[0, 0, "misc"], [13, 14, "algorithm"], [17, 17, "task"], [19, 19, "task"], [21, 22, "task"], [24, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 13, 14, "general-affiliation", "", false, false], [0, 0, 17, 17, "related-to", "solves_problem_of_type", false, false], [0, 0, 19, 19, "related-to", "solves_problem_of_type", false, false], [0, 0, 21, 22, "related-to", "solves_problem_of_type", false, false], [0, 0, 24, 25, "related-to", "solves_problem_of_type", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["NeuralExpert", "centruje", "specyfikacje", "projektowe", "wok\u00f3\u0142", "typu", "problemu", ",", "kt\u00f3ry", "u\u017cytkownik", "chcia\u0142by", ",", "aby", "sie\u0107", "neuronowa", "rozwi\u0105za\u0142a", "(", "Klasyfikacja", ",", "Predykcja", ",", "aproksymacja", "funkcji", "lub", "analiza", "skupie\u0144", ")", "."], "sentence-detokenized": "NeuralExpert centruje specyfikacje projektowe wok\u00f3\u0142 typu problemu, kt\u00f3ry u\u017cytkownik chcia\u0142by, aby sie\u0107 neuronowa rozwi\u0105za\u0142a (Klasyfikacja, Predykcja, aproksymacja funkcji lub analiza skupie\u0144).", "token2charspan": [[0, 12], [13, 21], [22, 34], [35, 45], [46, 51], [52, 56], [57, 65], [65, 66], [67, 72], [73, 83], [84, 92], [92, 93], [94, 97], [98, 102], [103, 112], [113, 123], [124, 125], [125, 137], [137, 138], [139, 148], [148, 149], [150, 162], [163, 170], [171, 174], [175, 182], [183, 190], [190, 191], [191, 192]]}
{"doc_key": "ai-test-130", "ner": [[1, 3, "misc"], [22, 24, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Gdy", "wielko\u015b\u0107", "kroku", "kwantyzacji", "(", "\u0394", ")", "jest", "ma\u0142a", "w", "stosunku", "do", "zmienno\u015bci", "kwantyzowanego", "sygna\u0142u", ",", "stosunkowo", "\u0142atwo", "jest", "pokaza\u0107", ",", "\u017ce", "\u015bredni", "b\u0142\u0105d", "kwadratowy", "wytworzony", "przez", "tak\u0105", "operacj\u0119", "zaokr\u0105glania", "b\u0119dzie", "w", "przybli\u017ceniu", "matematyczny", "Delta", "^", "2", "/", "12", "/", "math.math"], "sentence-detokenized": "Gdy wielko\u015b\u0107 kroku kwantyzacji (\u0394) jest ma\u0142a w stosunku do zmienno\u015bci kwantyzowanego sygna\u0142u, stosunkowo \u0142atwo jest pokaza\u0107, \u017ce \u015bredni b\u0142\u0105d kwadratowy wytworzony przez tak\u0105 operacj\u0119 zaokr\u0105glania b\u0119dzie w przybli\u017ceniu matematyczny Delta ^ 2 / 12 / math.math", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 30], [31, 32], [32, 33], [33, 34], [35, 39], [40, 44], [45, 46], [47, 55], [56, 58], [59, 69], [70, 84], [85, 92], [92, 93], [94, 104], [105, 110], [111, 115], [116, 123], [123, 124], [125, 127], [128, 134], [135, 139], [140, 150], [151, 161], [162, 167], [168, 172], [173, 181], [182, 194], [195, 201], [202, 203], [204, 216], [217, 229], [230, 235], [236, 237], [238, 239], [240, 241], [242, 244], [245, 246], [247, 256]]}
{"doc_key": "ai-test-131", "ner": [[13, 13, "product"], [19, 23, "researcher"], [25, 27, "researcher"], [29, 33, "researcher"], [35, 37, "researcher"], [39, 41, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Budowa", "bogatego", "leksykonu", "z", "odpowiedni\u0105", "ontologi\u0105", "wymaga", "znacznego", "wysi\u0142ku", ",", "np", ".", "leksykon", "Wordnet", "wymaga\u0142", "wielu", "osobo-lat", "pracy", ".", "G", ".", "A", ".", "Miller", ",", "R", ".", "Beckwith", ",", "C", ".", "D", ".", "Fellbaum", ",", "D", ".", "Gross", ",", "K", ".", "Miller", "."], "sentence-detokenized": "Budowa bogatego leksykonu z odpowiedni\u0105 ontologi\u0105 wymaga znacznego wysi\u0142ku, np. leksykon Wordnet wymaga\u0142 wielu osobo-lat pracy. G. A. Miller, R. Beckwith, C. D. Fellbaum, D. Gross, K. Miller.", "token2charspan": [[0, 6], [7, 15], [16, 25], [26, 27], [28, 39], [40, 49], [50, 56], [57, 66], [67, 74], [74, 75], [76, 78], [78, 79], [80, 88], [89, 96], [97, 104], [105, 110], [111, 120], [121, 126], [126, 127], [128, 129], [129, 130], [131, 132], [132, 133], [134, 140], [140, 141], [142, 143], [143, 144], [145, 153], [153, 154], [155, 156], [156, 157], [158, 159], [159, 160], [161, 169], [169, 170], [171, 172], [172, 173], [174, 179], [179, 180], [181, 182], [182, 183], [184, 190], [190, 191]]}
{"doc_key": "ai-test-132", "ner": [[1, 1, "organisation"], [17, 18, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 18, 1, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Portfolio", "Kawasaki", "obejmuje", "r\u00f3wnie\u017c", "chowane", "dachy", ",", "pod\u0142ogi", "i", "inne", "gigantyczne", "struktury", ",", "jednym", "z", "przyk\u0142ad\u00f3w", "jest", "Sapporo", "Dome", "'", "chowana", "powierzchnia", "."], "sentence-detokenized": "Portfolio Kawasaki obejmuje r\u00f3wnie\u017c chowane dachy, pod\u0142ogi i inne gigantyczne struktury, jednym z przyk\u0142ad\u00f3w jest Sapporo Dome 'chowana powierzchnia.", "token2charspan": [[0, 9], [10, 18], [19, 27], [28, 35], [36, 43], [44, 49], [49, 50], [51, 58], [59, 60], [61, 65], [66, 77], [78, 87], [87, 88], [89, 95], [96, 97], [98, 108], [109, 113], [114, 121], [122, 126], [127, 128], [128, 135], [136, 148], [148, 149]]}
{"doc_key": "ai-test-133", "ner": [[0, 1, "metrics"], [6, 6, "metrics"], [8, 11, "metrics"], [14, 15, "metrics"], [36, 36, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 14, 15, "related-to", "", false, false], [0, 1, 36, 36, "opposite", "alternative_to", false, false], [6, 6, 0, 1, "type-of", "", false, false], [8, 11, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Statystyki", "kappa", ",", "takie", "jak", "kappa", "Fleissa", "i", "kappa", "Cohena", ",", "s\u0105", "metodami", "obliczania", "wiarygodno\u015bci", "mi\u0119dzyosobowej", "opartymi", "na", "r\u00f3\u017cnych", "za\u0142o\u017ceniach", "dotycz\u0105cych", "rozk\u0142ad\u00f3w", "kra\u0144cowych", "lub", "uprzednich", "i", "s\u0105", "coraz", "cz\u0119\u015bciej", "stosowane", "jako", "skorygowane", "o", "szans\u0119", "alternatywy", "dla", "dok\u0142adno\u015bci", "w", "innych", "kontekstach", "."], "sentence-detokenized": "Statystyki kappa, takie jak kappa Fleissa i kappa Cohena, s\u0105 metodami obliczania wiarygodno\u015bci mi\u0119dzyosobowej opartymi na r\u00f3\u017cnych za\u0142o\u017ceniach dotycz\u0105cych rozk\u0142ad\u00f3w kra\u0144cowych lub uprzednich i s\u0105 coraz cz\u0119\u015bciej stosowane jako skorygowane o szans\u0119 alternatywy dla dok\u0142adno\u015bci w innych kontekstach.", "token2charspan": [[0, 10], [11, 16], [16, 17], [18, 23], [24, 27], [28, 33], [34, 41], [42, 43], [44, 49], [50, 56], [56, 57], [58, 60], [61, 69], [70, 80], [81, 94], [95, 109], [110, 118], [119, 121], [122, 129], [130, 141], [142, 153], [154, 163], [164, 174], [175, 178], [179, 189], [190, 191], [192, 194], [195, 200], [201, 209], [210, 219], [220, 224], [225, 236], [237, 238], [239, 245], [246, 257], [258, 261], [262, 273], [274, 275], [276, 282], [283, 294], [294, 295]]}
{"doc_key": "ai-test-134", "ner": [[4, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [17, 17, "researcher"], [24, 26, "algorithm"], [28, 29, "algorithm"], [31, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 17, 17, "role", "student_of", false, false], [7, 8, 17, 17, "role", "student_of", false, false], [10, 11, 17, 17, "role", "student_of", false, false], [13, 14, 17, 17, "role", "student_of", false, false], [28, 29, 4, 5, "origin", "", false, false], [28, 29, 7, 8, "origin", "", false, false], [28, 29, 10, 11, "origin", "", false, false], [28, 29, 13, 14, "origin", "", false, false], [28, 29, 17, 17, "origin", "", false, false], [28, 29, 24, 26, "type-of", "", false, false], [31, 31, 28, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Wraz", "ze", "swoimi", "studentami", "Seppem", "Hochreiterem", ",", "Felixem", "Gersem", ",", "Fredem", "Cumminsem", ",", "Alexem", "Gravesem", "i", "innymi", "Schmidhuber", "publikowa\u0142", "coraz", "bardziej", "wyrafinowane", "wersje", "typu", "rekurencyjnej", "sieci", "neuronowej", "zwanej", "pami\u0119ci\u0105", "d\u0142ugotrwa\u0142\u0105", "(", "LSTM", ")", "."], "sentence-detokenized": "Wraz ze swoimi studentami Seppem Hochreiterem, Felixem Gersem, Fredem Cumminsem, Alexem Gravesem i innymi Schmidhuber publikowa\u0142 coraz bardziej wyrafinowane wersje typu rekurencyjnej sieci neuronowej zwanej pami\u0119ci\u0105 d\u0142ugotrwa\u0142\u0105 (LSTM).", "token2charspan": [[0, 4], [5, 7], [8, 14], [15, 25], [26, 32], [33, 45], [45, 46], [47, 54], [55, 61], [61, 62], [63, 69], [70, 79], [79, 80], [81, 87], [88, 96], [97, 98], [99, 105], [106, 117], [118, 128], [129, 134], [135, 143], [144, 156], [157, 163], [164, 168], [169, 182], [183, 188], [189, 199], [200, 206], [207, 215], [216, 227], [228, 229], [229, 233], [233, 234], [234, 235]]}
{"doc_key": "ai-test-135", "ner": [[6, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2004", "-", "Na", "rynek", "trafia", "pierwszy", "Cobot", "KUKA", "LBR", "3", "."], "sentence-detokenized": "2004 - Na rynek trafia pierwszy Cobot KUKA LBR 3.", "token2charspan": [[0, 4], [5, 6], [7, 9], [10, 15], [16, 22], [23, 31], [32, 37], [38, 42], [43, 46], [47, 48], [48, 49]]}
{"doc_key": "ai-test-136", "ner": [[11, 13, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Dwa", "p\u0142ytkie", "podej\u015bcia", "stosowane", "do", "trenowania", ",", "a", "nast\u0119pnie", "rozr\u00f3\u017cniania", "to", "klasyfikator", "Naive", "Bayes", "i", "drzewa", "decyzyjne", "."], "sentence-detokenized": "Dwa p\u0142ytkie podej\u015bcia stosowane do trenowania, a nast\u0119pnie rozr\u00f3\u017cniania to klasyfikator Naive Bayes i drzewa decyzyjne.", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 31], [32, 34], [35, 45], [45, 46], [47, 48], [49, 58], [59, 71], [72, 74], [75, 87], [88, 93], [94, 99], [100, 101], [102, 108], [109, 118], [118, 119]]}
{"doc_key": "ai-test-137", "ner": [[3, 3, "misc"], [12, 12, "person"], [14, 16, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 12, 12, "origin", "", false, false], [3, 3, 14, 16, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pierwsze", "praktyczne", "formy", "fotografii", "zosta\u0142y", "wprowadzone", "w", "styczniu", "1839", "roku", "przez", "Louisa", "Daguerre'a", "i", "Henry'ego", "Foxa", "Talbota", "."], "sentence-detokenized": "Pierwsze praktyczne formy fotografii zosta\u0142y wprowadzone w styczniu 1839 roku przez Louisa Daguerre'a i Henry'ego Foxa Talbota.", "token2charspan": [[0, 8], [9, 19], [20, 25], [26, 36], [37, 44], [45, 56], [57, 58], [59, 67], [68, 72], [73, 77], [78, 83], [84, 90], [91, 101], [102, 103], [104, 113], [114, 118], [119, 126], [126, 127]]}
{"doc_key": "ai-test-138", "ner": [[2, 4, "task"], [7, 8, "task"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 4, 18, 19, "part-of", "task_part_of_field", false, false], [7, 8, 18, 19, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Na", "przyk\u0142ad", "synteza", "mowy", "w", "po\u0142\u0105czeniu", "z", "rozpoznawaniem", "mowy", "pozwala", "na", "interakcj\u0119", "z", "urz\u0105dzeniami", "mobilnymi", "za", "pomoc\u0105", "interfejs\u00f3w", "przetwarzania", "j\u0119zyka", "."], "sentence-detokenized": "Na przyk\u0142ad synteza mowy w po\u0142\u0105czeniu z rozpoznawaniem mowy pozwala na interakcj\u0119 z urz\u0105dzeniami mobilnymi za pomoc\u0105 interfejs\u00f3w przetwarzania j\u0119zyka.", "token2charspan": [[0, 2], [3, 11], [12, 19], [20, 24], [25, 26], [27, 37], [38, 39], [40, 54], [55, 59], [60, 67], [68, 70], [71, 81], [82, 83], [84, 96], [97, 106], [107, 109], [110, 116], [117, 128], [129, 142], [143, 149], [149, 150]]}
{"doc_key": "ai-test-139", "ner": [[0, 0, "product"], [13, 13, "programlang"], [15, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 13, 13, "general-affiliation", "", false, false], [0, 0, 15, 16, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Phidgety", "mog\u0105", "by\u0107", "programowane", "przy", "u\u017cyciu", "r\u00f3\u017cnych", "program\u00f3w", "i", "j\u0119zyk\u00f3w", "programowania", ",", "od", "Javy", "po", "Microsoft", "Excel", "."], "sentence-detokenized": "Phidgety mog\u0105 by\u0107 programowane przy u\u017cyciu r\u00f3\u017cnych program\u00f3w i j\u0119zyk\u00f3w programowania, od Javy po Microsoft Excel.", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 30], [31, 35], [36, 42], [43, 50], [51, 60], [61, 62], [63, 70], [71, 84], [84, 85], [86, 88], [89, 93], [94, 96], [97, 106], [107, 112], [112, 113]]}
{"doc_key": "ai-test-140", "ner": [[1, 2, "field"], [9, 10, "researcher"], [12, 14, "misc"], [19, 20, "field"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 9, 10, "origin", "", false, false], [9, 10, 19, 20, "general-affiliation", "topic_of_study", false, false], [9, 10, 22, 23, "general-affiliation", "topic_of_study", false, false], [12, 14, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Termin", "uczenie", "maszynowe", "zosta\u0142", "ukuty", "w", "1959", "roku", "przez", "Arthura", "Samuela", ",", "ameryka\u0144skiego", "pracownika", "IBM", "i", "pioniera", "w", "dziedzinie", "gier", "komputerowych", "i", "sztucznej", "inteligencji", "."], "sentence-detokenized": "Termin uczenie maszynowe zosta\u0142 ukuty w 1959 roku przez Arthura Samuela, ameryka\u0144skiego pracownika IBM i pioniera w dziedzinie gier komputerowych i sztucznej inteligencji.", "token2charspan": [[0, 6], [7, 14], [15, 24], [25, 31], [32, 37], [38, 39], [40, 44], [45, 49], [50, 55], [56, 63], [64, 71], [71, 72], [73, 87], [88, 98], [99, 102], [103, 104], [105, 113], [114, 115], [116, 126], [127, 131], [132, 145], [146, 147], [148, 157], [158, 170], [170, 171]]}
{"doc_key": "ai-test-141", "ner": [[0, 1, "misc"], [2, 3, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Izraelski", "poeta", "David", "Avidan", ",", "zafascynowany", "technologiami", "przysz\u0142o\u015bci", "i", "ich", "zwi\u0105zkiem", "ze", "sztuk\u0105", ",", "zapragn\u0105\u0142", "zbada\u0107", "zastosowanie", "komputer\u00f3w", "do", "pisania", "literatury", "."], "sentence-detokenized": "Izraelski poeta David Avidan, zafascynowany technologiami przysz\u0142o\u015bci i ich zwi\u0105zkiem ze sztuk\u0105, zapragn\u0105\u0142 zbada\u0107 zastosowanie komputer\u00f3w do pisania literatury.", "token2charspan": [[0, 9], [10, 15], [16, 21], [22, 28], [28, 29], [30, 43], [44, 57], [58, 69], [70, 71], [72, 75], [76, 85], [86, 88], [89, 95], [95, 96], [97, 106], [107, 113], [114, 126], [127, 137], [138, 140], [141, 148], [149, 159], [159, 160]]}
{"doc_key": "ai-test-142", "ner": [[0, 3, "misc"], [7, 7, "organisation"], [14, 14, "location"], [23, 23, "location"], [24, 26, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 7, 0, 3, "part-of", "", false, false], [24, 26, 23, 23, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["W", "ramach", "projektu", "GATEway", "w", "2017", "roku", "Oxbotica", "przetestowa\u0142a", "siedem", "autonomicznych", "autobus\u00f3w", "wahad\u0142owych", "w", "Greenwich", ",", "nawiguj\u0105c", "po", "dwumilowej", "\u015bcie\u017cce", "nadrzecznej", "w", "pobli\u017cu", "londy\u0144skiej", "The", "O2", "Arena", "na", "trasie", "u\u017cywanej", "r\u00f3wnie\u017c", "przez", "pieszych", "i", "rowerzyst\u00f3w", "."], "sentence-detokenized": "W ramach projektu GATEway w 2017 roku Oxbotica przetestowa\u0142a siedem autonomicznych autobus\u00f3w wahad\u0142owych w Greenwich, nawiguj\u0105c po dwumilowej \u015bcie\u017cce nadrzecznej w pobli\u017cu londy\u0144skiej The O2 Arena na trasie u\u017cywanej r\u00f3wnie\u017c przez pieszych i rowerzyst\u00f3w.", "token2charspan": [[0, 1], [2, 8], [9, 17], [18, 25], [26, 27], [28, 32], [33, 37], [38, 46], [47, 60], [61, 67], [68, 82], [83, 92], [93, 104], [105, 106], [107, 116], [116, 117], [118, 127], [128, 130], [131, 141], [142, 149], [150, 161], [162, 163], [164, 171], [172, 183], [184, 187], [188, 190], [191, 196], [197, 199], [200, 206], [207, 215], [216, 223], [224, 229], [230, 238], [239, 240], [241, 252], [252, 253]]}
{"doc_key": "ai-test-143", "ner": [[9, 10, "task"], [12, 12, "metrics"], [19, 20, "misc"], [21, 21, "metrics"], [23, 23, "metrics"], [26, 26, "metrics"], [28, 28, "metrics"], [30, 32, "metrics"], [35, 35, "metrics"], [37, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[12, 12, 19, 20, "related-to", "is_a", false, false], [12, 12, 21, 21, "usage", "", false, false], [12, 12, 23, 23, "usage", "", false, false], [21, 21, 26, 26, "named", "same", false, false], [23, 23, 37, 37, "named", "same", false, false], [26, 26, 35, 35, "opposite", "", false, false], [26, 26, 37, 37, "opposite", "", false, false], [28, 28, 26, 26, "named", "", false, false], [30, 32, 26, 26, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Niepowi\u0105zan\u0105", ",", "ale", "powszechnie", "stosowan\u0105", "kombinacj\u0105", "podstawowych", "statystyk", "z", "wyszukiwania", "informacji", "jest", "F-score", ",", "b\u0119d\u0105cy", "(", "ewentualnie", "wa\u017con\u0105", ")", "\u015bredni\u0105", "harmoniczn\u0105", "wycofania", "i", "precyzji", ",", "gdzie", "wycofanie", "=", "czu\u0142o\u015b\u0107", "=", "TRUE", "positive", "rate", ",", "ale", "specyficzno\u015b\u0107", "i", "precyzja", "to", "zupe\u0142nie", "inne", "miary", "."], "sentence-detokenized": "Niepowi\u0105zan\u0105, ale powszechnie stosowan\u0105 kombinacj\u0105 podstawowych statystyk z wyszukiwania informacji jest F-score, b\u0119d\u0105cy (ewentualnie wa\u017con\u0105) \u015bredni\u0105 harmoniczn\u0105 wycofania i precyzji, gdzie wycofanie = czu\u0142o\u015b\u0107 = TRUE positive rate, ale specyficzno\u015b\u0107 i precyzja to zupe\u0142nie inne miary.", "token2charspan": [[0, 12], [12, 13], [14, 17], [18, 29], [30, 39], [40, 50], [51, 63], [64, 73], [74, 75], [76, 88], [89, 99], [100, 104], [105, 112], [112, 113], [114, 120], [121, 122], [122, 133], [134, 140], [140, 141], [142, 149], [150, 161], [162, 171], [172, 173], [174, 182], [182, 183], [184, 189], [190, 199], [200, 201], [202, 209], [210, 211], [212, 216], [217, 225], [226, 230], [230, 231], [232, 235], [236, 249], [250, 251], [252, 260], [261, 263], [264, 272], [273, 277], [278, 283], [283, 284]]}
{"doc_key": "ai-test-144", "ner": [[0, 1, "field"], [10, 10, "field"], [12, 12, "field"], [14, 14, "field"], [16, 16, "field"], [18, 20, "field"], [29, 30, "product"], [32, 35, "product"], [38, 40, "product"], [41, 42, "product"], [54, 56, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 10, "origin", "takes_inspiration_from", false, false], [0, 1, 12, 12, "origin", "takes_inspiration_from", false, false], [0, 1, 14, 14, "origin", "takes_inspiration_from", false, false], [0, 1, 16, 16, "origin", "takes_inspiration_from", false, false], [0, 1, 18, 20, "origin", "takes_inspiration_from", false, false], [29, 30, 0, 1, "origin", "", false, false], [32, 35, 0, 1, "origin", "", false, false], [38, 40, 0, 1, "origin", "", false, false], [41, 42, 0, 1, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In\u017cynieria", "neuromorficzna", "jest", "interdyscyplinarnym", "przedmiotem", ",", "kt\u00f3ry", "czerpie", "inspiracje", "z", "biologii", ",", "fizyki", ",", "matematyki", ",", "informatyki", "i", "in\u017cynierii", "elektronicznej", "w", "celu", "projektowania", "sztucznych", "system\u00f3w", "neuronowych", ",", "takich", "jak", "systemy", "wizyjne", ",", "systemy", "typu", "\"", "g\u0142owa-oko", "\"", ",", "procesory", "s\u0142uchowe", "i", "autonomiczne", "roboty", ",", "kt\u00f3rych", "architektura", "fizyczna", "i", "zasady", "projektowania", "opieraj\u0105", "si\u0119", "na", "zasadach", "biologicznych", "system\u00f3w", "nerwowych", "."], "sentence-detokenized": "In\u017cynieria neuromorficzna jest interdyscyplinarnym przedmiotem, kt\u00f3ry czerpie inspiracje z biologii, fizyki, matematyki, informatyki i in\u017cynierii elektronicznej w celu projektowania sztucznych system\u00f3w neuronowych, takich jak systemy wizyjne, systemy typu \"g\u0142owa-oko\", procesory s\u0142uchowe i autonomiczne roboty, kt\u00f3rych architektura fizyczna i zasady projektowania opieraj\u0105 si\u0119 na zasadach biologicznych system\u00f3w nerwowych.", "token2charspan": [[0, 10], [11, 25], [26, 30], [31, 50], [51, 62], [62, 63], [64, 69], [70, 77], [78, 88], [89, 90], [91, 99], [99, 100], [101, 107], [107, 108], [109, 119], [119, 120], [121, 132], [133, 134], [135, 145], [146, 160], [161, 162], [163, 167], [168, 181], [182, 192], [193, 201], [202, 213], [213, 214], [215, 221], [222, 225], [226, 233], [234, 241], [241, 242], [243, 250], [251, 255], [256, 257], [257, 266], [266, 267], [267, 268], [269, 278], [279, 287], [288, 289], [290, 302], [303, 309], [309, 310], [311, 318], [319, 331], [332, 340], [341, 342], [343, 349], [350, 363], [364, 372], [373, 376], [377, 379], [380, 388], [389, 402], [403, 411], [412, 421], [421, 422]]}
{"doc_key": "ai-test-145", "ner": [[3, 5, "metrics"], [9, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 9, 3, 5, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["M\u00f3wi\u0105c", "konkretnie", ",", "kryterium", "stabilno\u015bci", "BIBO", "wymaga", ",", "aby", "ROC", "uk\u0142adu", "obejmowa\u0142", "okr\u0105g", "jednostkowy", "."], "sentence-detokenized": "M\u00f3wi\u0105c konkretnie, kryterium stabilno\u015bci BIBO wymaga, aby ROC uk\u0142adu obejmowa\u0142 okr\u0105g jednostkowy.", "token2charspan": [[0, 6], [7, 17], [17, 18], [19, 28], [29, 40], [41, 45], [46, 52], [52, 53], [54, 57], [58, 61], [62, 68], [69, 78], [79, 84], [85, 96], [96, 97]]}
{"doc_key": "ai-test-146", "ner": [[5, 5, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2", "Program", "zosta\u0142", "przepisany", "w", "Javie", "pocz\u0105wszy", "od", "1998", "roku", "."], "sentence-detokenized": "2 Program zosta\u0142 przepisany w Javie pocz\u0105wszy od 1998 roku.", "token2charspan": [[0, 1], [2, 9], [10, 16], [17, 27], [28, 29], [30, 35], [36, 45], [46, 48], [49, 53], [54, 58], [58, 59]]}
{"doc_key": "ai-test-147", "ner": [[0, 0, "metrics"], [5, 6, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 5, 6, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MCC", "mo\u017cna", "obliczy\u0107", "bezpo\u015brednio", "z", "macierzy", "konfuzji", "korzystaj\u0105c", "ze", "wzoru", ":"], "sentence-detokenized": "MCC mo\u017cna obliczy\u0107 bezpo\u015brednio z macierzy konfuzji korzystaj\u0105c ze wzoru:", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 31], [32, 33], [34, 42], [43, 51], [52, 63], [64, 66], [67, 72], [72, 73]]}
{"doc_key": "ai-test-148", "ner": [[5, 8, "organisation"], [15, 20, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 8, 15, 20, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Zosta\u0142a", "opracowana", "przez", "zesp\u00f3\u0142", "w", "MIT-IBM", "Watson", "AI", "Lab", "i", "po", "raz", "pierwszy", "zaprezentowana", "na", "2018", "International", "Conference", "on", "Learning", "Representations", "."], "sentence-detokenized": "Zosta\u0142a opracowana przez zesp\u00f3\u0142 w MIT-IBM Watson AI Lab i po raz pierwszy zaprezentowana na 2018 International Conference on Learning Representations.", "token2charspan": [[0, 7], [8, 18], [19, 24], [25, 31], [32, 33], [34, 41], [42, 48], [49, 51], [52, 55], [56, 57], [58, 60], [61, 64], [65, 73], [74, 88], [89, 91], [92, 96], [97, 110], [111, 121], [122, 124], [125, 133], [134, 149], [149, 150]]}
{"doc_key": "ai-test-149", "ner": [[1, 2, "metrics"], [13, 14, "metrics"], [16, 16, "metrics"], [37, 37, "metrics"], [39, 39, "metrics"], [45, 46, "metrics"], [49, 49, "metrics"], [51, 51, "metrics"], [53, 53, "metrics"], [58, 58, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[13, 14, 37, 37, "type-of", "", false, false], [13, 14, 45, 46, "related-to", "collapses_to_identity", false, false], [16, 16, 39, 39, "type-of", "", false, false], [16, 16, 45, 46, "related-to", "collapses_to_identity", false, false], [16, 16, 53, 53, "named", "same", false, false], [49, 49, 58, 58, "related-to", "collapses_to_identity", false, false], [51, 51, 58, 58, "related-to", "collapses_to_identity", false, false], [53, 53, 58, 58, "related-to", "collapses_to_identity", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Gdy", "TRUE", "prevalences", "dla", "dw\u00f3ch", "pozytywnych", "zmiennych", "s\u0105", "r\u00f3wne", ",", "jak", "za\u0142o\u017cono", "w", "Fleiss", "kappa", "i", "F-score", ",", "czyli", "liczba", "pozytywnych", "predykcji", "pokrywa", "si\u0119", "z", "liczb\u0105", "pozytywnych", "klas", "w", "przypadku", "dychotomicznym", "(", "dwuklasowym", ")", ",", "r\u00f3\u017cne", "miary", "kappa", "i", "korelacji", "za\u0142amuj\u0105", "si\u0119", "do", "to\u017csamo\u015bci", "z", "Youden's", "J", ",", "a", "recall", ",", "precision", "i", "F-score", "s\u0105", "podobnie", "identyczne", "z", "dok\u0142adno\u015bci\u0105", "."], "sentence-detokenized": "Gdy TRUE prevalences dla dw\u00f3ch pozytywnych zmiennych s\u0105 r\u00f3wne, jak za\u0142o\u017cono w Fleiss kappa i F-score, czyli liczba pozytywnych predykcji pokrywa si\u0119 z liczb\u0105 pozytywnych klas w przypadku dychotomicznym (dwuklasowym), r\u00f3\u017cne miary kappa i korelacji za\u0142amuj\u0105 si\u0119 do to\u017csamo\u015bci z Youden's J, a recall, precision i F-score s\u0105 podobnie identyczne z dok\u0142adno\u015bci\u0105.", "token2charspan": [[0, 3], [4, 8], [9, 20], [21, 24], [25, 30], [31, 42], [43, 52], [53, 55], [56, 61], [61, 62], [63, 66], [67, 75], [76, 77], [78, 84], [85, 90], [91, 92], [93, 100], [100, 101], [102, 107], [108, 114], [115, 126], [127, 136], [137, 144], [145, 148], [149, 150], [151, 157], [158, 169], [170, 174], [175, 176], [177, 186], [187, 201], [202, 203], [203, 214], [214, 215], [215, 216], [217, 222], [223, 228], [229, 234], [235, 236], [237, 246], [247, 255], [256, 259], [260, 262], [263, 273], [274, 275], [276, 284], [285, 286], [286, 287], [288, 289], [290, 296], [296, 297], [298, 307], [308, 309], [310, 317], [318, 320], [321, 329], [330, 340], [341, 342], [343, 355], [355, 356]]}
{"doc_key": "ai-test-150", "ner": [[0, 3, "misc"], [5, 5, "misc"], [8, 8, "conference"], [13, 16, "task"], [17, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 8, 8, "part-of", "", false, false], [0, 3, 8, 8, "physical", "", false, false], [0, 3, 8, 8, "temporal", "", false, false], [5, 5, 0, 3, "named", "", false, false], [13, 16, 0, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Warsztaty", "Building", "Educational", "Applications", "(", "BEA", ")", "na", "NAACL", "2013", "by\u0142y", "gospodarzem", "inauguracyjnego", "zadania", "wsp\u00f3lnego", "NLI", ".", "Tetreault", "et", "al", ",", "2013", "W", "wyniku", "konkursu", "wp\u0142yn\u0119\u0142o", "29", "zg\u0142osze\u0144", "od", "zespo\u0142\u00f3w", "z", "ca\u0142ego", "\u015bwiata", ",", "z", "kt\u00f3rych", "24", "opublikowa\u0142o", "r\u00f3wnie\u017c", "prac\u0119", "opisuj\u0105c\u0105", "ich", "systemy", "i", "podej\u015bcia", "."], "sentence-detokenized": "Warsztaty Building Educational Applications (BEA) na NAACL 2013 by\u0142y gospodarzem inauguracyjnego zadania wsp\u00f3lnego NLI. Tetreault et al, 2013 W wyniku konkursu wp\u0142yn\u0119\u0142o 29 zg\u0142osze\u0144 od zespo\u0142\u00f3w z ca\u0142ego \u015bwiata, z kt\u00f3rych 24 opublikowa\u0142o r\u00f3wnie\u017c prac\u0119 opisuj\u0105c\u0105 ich systemy i podej\u015bcia.", "token2charspan": [[0, 9], [10, 18], [19, 30], [31, 43], [44, 45], [45, 48], [48, 49], [50, 52], [53, 58], [59, 63], [64, 68], [69, 80], [81, 96], [97, 104], [105, 114], [115, 118], [118, 119], [120, 129], [130, 132], [133, 135], [135, 136], [137, 141], [142, 143], [144, 150], [151, 159], [160, 168], [169, 171], [172, 180], [181, 183], [184, 192], [193, 194], [195, 201], [202, 208], [208, 209], [210, 211], [212, 219], [220, 222], [223, 235], [236, 243], [244, 249], [250, 259], [260, 263], [264, 271], [272, 273], [274, 283], [283, 284]]}
{"doc_key": "ai-test-151", "ner": [[0, 1, "algorithm"], [4, 5, "algorithm"], [12, 13, "misc"], [15, 16, "misc"], [28, 34, "misc"], [32, 32, "algorithm"], [36, 36, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 4, 5, "type-of", "", false, false], [0, 1, 12, 13, "related-to", "finds", false, false], [15, 16, 12, 13, "type-of", "", false, false], [36, 36, 32, 32, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Algorytm", "Viterbiego", "jest", "algorytmem", "programowania", "dynamicznego", "s\u0142u\u017c\u0105cym", "do", "znalezienia", "najbardziej", "prawdopodobnej", "sekwencji", "stan\u00f3w", "ukrytych", "zwanej", "\u015bcie\u017ck\u0105", "Viterbiego", ",", "kt\u00f3rej", "wynikiem", "jest", "sekwencja", "obserwowanych", "zdarze\u0144", ",", "zw\u0142aszcza", "w", "kontek\u015bcie", "Markowskich", "\u017ar\u00f3de\u0142", "informacji", "i", "ukrytych", "modeli", "Markowa", "(", "HMM", ")", "."], "sentence-detokenized": "Algorytm Viterbiego jest algorytmem programowania dynamicznego s\u0142u\u017c\u0105cym do znalezienia najbardziej prawdopodobnej sekwencji stan\u00f3w ukrytych zwanej \u015bcie\u017ck\u0105 Viterbiego, kt\u00f3rej wynikiem jest sekwencja obserwowanych zdarze\u0144, zw\u0142aszcza w kontek\u015bcie Markowskich \u017ar\u00f3de\u0142 informacji i ukrytych modeli Markowa (HMM).", "token2charspan": [[0, 8], [9, 19], [20, 24], [25, 35], [36, 49], [50, 62], [63, 71], [72, 74], [75, 86], [87, 98], [99, 113], [114, 123], [124, 130], [131, 139], [140, 146], [147, 154], [155, 165], [165, 166], [167, 173], [174, 182], [183, 187], [188, 197], [198, 211], [212, 219], [219, 220], [221, 230], [231, 232], [233, 243], [244, 255], [256, 262], [263, 273], [274, 275], [276, 284], [285, 291], [292, 299], [300, 301], [301, 304], [304, 305], [305, 306]]}
{"doc_key": "ai-test-152", "ner": [[1, 1, "field"], [2, 4, "algorithm"], [6, 7, "misc"], [11, 12, "algorithm"], [14, 15, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 1, 1, "part-of", "", false, false], [2, 4, 6, 7, "general-affiliation", "", false, false], [2, 4, 11, 12, "related-to", "generalizes_from", false, false], [2, 4, 14, 15, "related-to", "generalizes_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["W", "statystyce", "wielomianowa", "regresja", "logistyczna", "jest", "metod\u0105", "klasyfikacji", ",", "kt\u00f3ra", "uog\u00f3lnia", "regresj\u0119", "logistyczn\u0105", "do", "klasyfikacji", "wieloklasowej", ",", "tj", ".", "z", "wi\u0119cej", "ni\u017c", "dwoma", "mo\u017cliwymi", "dyskretnymi", "wynikami", "."], "sentence-detokenized": "W statystyce wielomianowa regresja logistyczna jest metod\u0105 klasyfikacji, kt\u00f3ra uog\u00f3lnia regresj\u0119 logistyczn\u0105 do klasyfikacji wieloklasowej, tj. z wi\u0119cej ni\u017c dwoma mo\u017cliwymi dyskretnymi wynikami.", "token2charspan": [[0, 1], [2, 12], [13, 25], [26, 34], [35, 46], [47, 51], [52, 58], [59, 71], [71, 72], [73, 78], [79, 87], [88, 96], [97, 108], [109, 111], [112, 124], [125, 138], [138, 139], [140, 142], [142, 143], [144, 145], [146, 152], [153, 156], [157, 162], [163, 172], [173, 184], [185, 193], [193, 194]]}
{"doc_key": "ai-test-153", "ner": [[0, 2, "algorithm"], [0, 9, "field"], [11, 13, "field"], [17, 17, "task"], [20, 21, "task"], [24, 24, "task"], [26, 27, "researcher"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 0, 9, "part-of", "", false, false], [0, 2, 11, 13, "part-of", "", false, false], [17, 17, 0, 2, "usage", "", true, false], [20, 21, 0, 2, "usage", "", true, false], [24, 24, 0, 2, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Ukryte", "modele", "Markowa", "znane", "s\u0105", "z", "zastosowa\u0144", "w", "uczeniu", "wzmacniaj\u0105cym", "i", "czasowym", "rozpoznawaniu", "wzorc\u00f3w", ",", "takich", "jak", "mowa", ",", "rozpoznawanie", "pisma", "r\u0119cznego", ",", "rozpoznawanie", "gest\u00f3w", ",", "Thad", "Starner", ",", "Alex", "Pentland", "."], "sentence-detokenized": "Ukryte modele Markowa znane s\u0105 z zastosowa\u0144 w uczeniu wzmacniaj\u0105cym i czasowym rozpoznawaniu wzorc\u00f3w, takich jak mowa, rozpoznawanie pisma r\u0119cznego, rozpoznawanie gest\u00f3w, Thad Starner, Alex Pentland.", "token2charspan": [[0, 6], [7, 13], [14, 21], [22, 27], [28, 30], [31, 32], [33, 43], [44, 45], [46, 53], [54, 67], [68, 69], [70, 78], [79, 92], [93, 100], [100, 101], [102, 108], [109, 112], [113, 117], [117, 118], [119, 132], [133, 138], [139, 147], [147, 148], [149, 162], [163, 169], [169, 170], [171, 175], [176, 183], [183, 184], [185, 189], [190, 198], [198, 199]]}
{"doc_key": "ai-test-154", "ner": [[28, 30, "metrics"], [32, 33, "misc"]], "ner_mapping_to_source": [1, 2], "relations": [[28, 30, 32, 33, "related-to", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Zasadniczo", "oznacza", "to", ",", "\u017ce", "je\u015bli", "\u00f3wn-", "gram", "by\u0142", "widziany", "wi\u0119cej", "ni\u017c", "k", "razy", "w", "treningu", ",", "warunkowe", "prawdopodobie\u0144stwo", "s\u0142owa", "bior\u0105c", "pod", "uwag\u0119", "jego", "histori\u0119", "jest", "proporcjonalne", "do", "oszacowania", "maksymalnego", "prawdopodobie\u0144stwa", "tegon", "-", "gramu", "."], "sentence-detokenized": "Zasadniczo oznacza to, \u017ce je\u015bli \u00f3wn-gram by\u0142 widziany wi\u0119cej ni\u017c k razy w treningu, warunkowe prawdopodobie\u0144stwo s\u0142owa bior\u0105c pod uwag\u0119 jego histori\u0119 jest proporcjonalne do oszacowania maksymalnego prawdopodobie\u0144stwa tegon -gramu.", "token2charspan": [[0, 10], [11, 18], [19, 21], [21, 22], [23, 25], [26, 31], [32, 36], [36, 40], [41, 44], [45, 53], [54, 60], [61, 64], [65, 66], [67, 71], [72, 73], [74, 82], [82, 83], [84, 93], [94, 112], [113, 118], [119, 125], [126, 129], [130, 135], [136, 140], [141, 149], [150, 154], [155, 169], [170, 172], [173, 184], [185, 197], [198, 216], [217, 222], [223, 224], [224, 229], [229, 230]]}
{"doc_key": "ai-test-155", "ner": [[2, 3, "task"], [5, 6, "task"], [8, 10, "task"], [15, 17, "task"], [25, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[25, 26, 15, 17, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Interesuje", "si\u0119", "reprezentacj\u0105", "wiedzy", ",", "rozumowaniem", "zdroworozs\u0105dkowym", "i", "rozumieniem", "j\u0119zyka", "naturalnego", ",", "wierz\u0105c", ",", "\u017ce", "g\u0142\u0119bokie", "rozumienie", "j\u0119zyka", "mo\u017ce", "by\u0107", "obecnie", "osi\u0105gni\u0119te", "jedynie", "poprzez", "znacz\u0105ce", "r\u0119czne", "konstruowanie", "bogatych", "semantycznie", "formalizm\u00f3w", "w", "po\u0142\u0105czeniu", "z", "preferencjami", "statystycznymi", "."], "sentence-detokenized": "Interesuje si\u0119 reprezentacj\u0105 wiedzy, rozumowaniem zdroworozs\u0105dkowym i rozumieniem j\u0119zyka naturalnego, wierz\u0105c, \u017ce g\u0142\u0119bokie rozumienie j\u0119zyka mo\u017ce by\u0107 obecnie osi\u0105gni\u0119te jedynie poprzez znacz\u0105ce r\u0119czne konstruowanie bogatych semantycznie formalizm\u00f3w w po\u0142\u0105czeniu z preferencjami statystycznymi.", "token2charspan": [[0, 10], [11, 14], [15, 28], [29, 35], [35, 36], [37, 49], [50, 67], [68, 69], [70, 81], [82, 88], [89, 100], [100, 101], [102, 109], [109, 110], [111, 113], [114, 122], [123, 133], [134, 140], [141, 145], [146, 149], [150, 157], [158, 168], [169, 176], [177, 184], [185, 193], [194, 200], [201, 214], [215, 223], [224, 236], [237, 248], [249, 250], [251, 261], [262, 263], [264, 277], [278, 292], [292, 293]]}
{"doc_key": "ai-test-156", "ner": [[1, 1, "programlang"], [3, 3, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["W", "JavaScript", ",", "Pythonie", "lub"], "sentence-detokenized": "W JavaScript, Pythonie lub", "token2charspan": [[0, 1], [2, 12], [12, 13], [14, 22], [23, 26]]}
{"doc_key": "ai-test-157", "ner": [[0, 1, "misc"], [5, 6, "misc"], [9, 9, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 5, 6, "part-of", "", false, false], [5, 6, 9, 9, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Nagrody", "Newcomb", "s\u0105", "og\u0142aszane", "w", "AI", "Magazine", "wydawanym", "przez", "AAAI", "."], "sentence-detokenized": "Nagrody Newcomb s\u0105 og\u0142aszane w AI Magazine wydawanym przez AAAI.", "token2charspan": [[0, 7], [8, 15], [16, 18], [19, 28], [29, 30], [31, 33], [34, 42], [43, 52], [53, 58], [59, 63], [63, 64]]}
{"doc_key": "ai-test-158", "ner": [[0, 2, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["\u015aredni", "b\u0142\u0105d", "kwadratowy", "na", "zestawie", "testowym", "100", "exemplarzy", "wynosi", "0,084", "i", "jest", "mniejszy", "od", "b\u0142\u0119du", "nienormalizowanego", "."], "sentence-detokenized": "\u015aredni b\u0142\u0105d kwadratowy na zestawie testowym 100 exemplarzy wynosi 0,084 i jest mniejszy od b\u0142\u0119du nienormalizowanego.", "token2charspan": [[0, 6], [7, 11], [12, 22], [23, 25], [26, 34], [35, 43], [44, 47], [48, 58], [59, 65], [66, 71], [72, 73], [74, 78], [79, 87], [88, 90], [91, 96], [97, 115], [115, 116]]}
{"doc_key": "ai-test-159", "ner": [[1, 1, "metrics"], [8, 10, "field"], [16, 18, "task"], [20, 20, "task"], [23, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 10, 1, 1, "usage", "", false, false], [16, 18, 8, 10, "part-of", "task_part_of_field", false, false], [20, 20, 16, 18, "named", "", false, false], [23, 23, 8, 10, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Wska\u017anik", "F-score", "by\u0142", "szeroko", "stosowany", "w", "literaturze", "dotycz\u0105cej", "przetwarzania", "j\u0119zyka", "naturalnego", ",", "np", ".", "w", "ocenie", "rozpoznawania", "nazwanych", "podmiot\u00f3w", "(", "NER", ")", "i", "segmentacji", "s\u0142\u00f3w", "."], "sentence-detokenized": "Wska\u017anik F-score by\u0142 szeroko stosowany w literaturze dotycz\u0105cej przetwarzania j\u0119zyka naturalnego, np. w ocenie rozpoznawania nazwanych podmiot\u00f3w (NER) i segmentacji s\u0142\u00f3w.", "token2charspan": [[0, 8], [9, 16], [17, 20], [21, 28], [29, 38], [39, 40], [41, 52], [53, 63], [64, 77], [78, 84], [85, 96], [96, 97], [98, 100], [100, 101], [102, 103], [104, 110], [111, 124], [125, 134], [135, 144], [145, 146], [146, 149], [149, 150], [151, 152], [153, 164], [165, 169], [169, 170]]}
{"doc_key": "ai-test-160", "ner": [[0, 0, "product"], [5, 6, "product"], [16, 16, "misc"], [20, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 16, 16, "related-to", "performs_task", false, false], [0, 0, 20, 21, "related-to", "performs_task", false, false], [5, 6, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Chatboty", "s\u0105", "zazwyczaj", "wykorzystywane", "w", "systemach", "dialogowych", "do", "r\u00f3\u017cnych", "cel\u00f3w", ",", "w", "tym", "obs\u0142ugi", "klienta", ",", "kierowania", "zapyta\u0144", "lub", "do", "zbierania", "informacji", "."], "sentence-detokenized": "Chatboty s\u0105 zazwyczaj wykorzystywane w systemach dialogowych do r\u00f3\u017cnych cel\u00f3w, w tym obs\u0142ugi klienta, kierowania zapyta\u0144 lub do zbierania informacji.", "token2charspan": [[0, 8], [9, 11], [12, 21], [22, 36], [37, 38], [39, 48], [49, 60], [61, 63], [64, 71], [72, 77], [77, 78], [79, 80], [81, 84], [85, 92], [93, 100], [100, 101], [102, 112], [113, 120], [121, 124], [125, 127], [128, 137], [138, 148], [148, 149]]}
{"doc_key": "ai-test-161", "ner": [[4, 10, "conference"], [17, 23, "conference"], [31, 42, "conference"], [48, 48, "conference"], [51, 54, "conference"], [57, 57, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[17, 23, 4, 10, "named", "", false, false], [31, 42, 4, 10, "named", "", false, false], [48, 48, 31, 42, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Do", "wa\u017cnych", "czasopism", "nale\u017c\u0105", "IEEE", "Transactions", "on", "Speech", "and", "Audio", "Processing", "(", "p\u00f3\u017aniej", "przemianowane", "na", "IEEE", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", ",", "a", "od", "wrze\u015bnia", "2014", "roku", "przemianowane", "na", "IEEE", "/", "ACM", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "-", "po", "po\u0142\u0105czeniu", "z", "publikacj\u0105", "ACM", ")", ",", "Computer", "Speech", "and", "Language", "oraz", "Speech", "Communication", "."], "sentence-detokenized": "Do wa\u017cnych czasopism nale\u017c\u0105 IEEE Transactions on Speech and Audio Processing (p\u00f3\u017aniej przemianowane na IEEE Transactions on Audio, Speech and Language Processing, a od wrze\u015bnia 2014 roku przemianowane na IEEE / ACM Transactions on Audio, Speech and Language Processing - po po\u0142\u0105czeniu z publikacj\u0105 ACM), Computer Speech and Language oraz Speech Communication.", "token2charspan": [[0, 2], [3, 10], [11, 20], [21, 27], [28, 32], [33, 45], [46, 48], [49, 55], [56, 59], [60, 65], [66, 76], [77, 78], [78, 85], [86, 99], [100, 102], [103, 107], [108, 120], [121, 123], [124, 129], [129, 130], [131, 137], [138, 141], [142, 150], [151, 161], [161, 162], [163, 164], [165, 167], [168, 176], [177, 181], [182, 186], [187, 200], [201, 203], [204, 208], [209, 210], [211, 214], [215, 227], [228, 230], [231, 236], [236, 237], [238, 244], [245, 248], [249, 257], [258, 268], [269, 270], [271, 273], [274, 284], [285, 286], [287, 297], [298, 301], [301, 302], [302, 303], [304, 312], [313, 319], [320, 323], [324, 332], [333, 337], [338, 344], [345, 358], [358, 359]]}
{"doc_key": "ai-test-162", "ner": [[0, 0, "algorithm"], [5, 6, "task"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 0, 0, "usage", "", false, false], [5, 6, 8, 9, "part-of", "task_part_of_field", false, false], [5, 6, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["EM", "jest", "cz\u0119sto", "stosowany", "do", "klasteryzacji", "danych", "w", "uczeniu", "maszynowym", "i", "wizji", "komputerowej", "."], "sentence-detokenized": "EM jest cz\u0119sto stosowany do klasteryzacji danych w uczeniu maszynowym i wizji komputerowej.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 24], [25, 27], [28, 41], [42, 48], [49, 50], [51, 58], [59, 69], [70, 71], [72, 77], [78, 90], [90, 91]]}
{"doc_key": "ai-test-163", "ner": [[7, 8, "metrics"], [21, 23, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 21, 23, "related-to", "described_by", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cho\u0107", "nie", "ma", "idealnego", "sposobu", "na", "opisanie", "macierzy", "konfuzji", "pozytyw\u00f3w", "i", "negatyw\u00f3w", "TRUE", "i", "FALSE", "za", "pomoc\u0105", "jednej", "liczby", ",", "to", "wsp\u00f3\u0142czynnik", "korelacji", "Matthewsa", "jest", "powszechnie", "uwa\u017cany", "za", "jedn\u0105", "z", "najlepszych", "takich", "miar", "."], "sentence-detokenized": "Cho\u0107 nie ma idealnego sposobu na opisanie macierzy konfuzji pozytyw\u00f3w i negatyw\u00f3w TRUE i FALSE za pomoc\u0105 jednej liczby, to wsp\u00f3\u0142czynnik korelacji Matthewsa jest powszechnie uwa\u017cany za jedn\u0105 z najlepszych takich miar.", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 21], [22, 29], [30, 32], [33, 41], [42, 50], [51, 59], [60, 69], [70, 71], [72, 81], [82, 86], [87, 88], [89, 94], [95, 97], [98, 104], [105, 111], [112, 118], [118, 119], [120, 122], [123, 135], [136, 145], [146, 155], [156, 160], [161, 172], [173, 180], [181, 183], [184, 189], [190, 191], [192, 203], [204, 210], [211, 215], [215, 216]]}
{"doc_key": "ai-test-164", "ner": [[16, 17, "field"], [31, 31, "field"], [36, 37, "field"], [41, 42, "algorithm"], [44, 45, "task"], [47, 48, "algorithm"], [55, 58, "algorithm"], [60, 63, "algorithm"], [68, 70, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[36, 37, 31, 31, "part-of", "subfield", false, false], [41, 42, 36, 37, "part-of", "", false, true], [44, 45, 36, 37, "part-of", "", false, true], [47, 48, 36, 37, "part-of", "", false, true], [55, 58, 36, 37, "part-of", "", false, true], [60, 63, 36, 37, "part-of", "", false, true], [68, 70, 36, 37, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["W", "miar\u0119", "jak", "zbiory", "danych", "stawa\u0142y", "si\u0119", "coraz", "wi\u0119ksze", "i", "bardziej", "z\u0142o\u017cone", ",", "bezpo\u015brednia", ",", "praktyczna", "analiza", "danych", "zosta\u0142a", "uzupe\u0142niona", "po\u015brednim", ",", "zautomatyzowanym", "przetwarzaniem", "danych", ",", "wspomaganym", "przez", "inne", "odkrycia", "w", "informatyce", ",", "zw\u0142aszcza", "w", "dziedzinie", "uczenia", "maszynowego", ",", "takie", "jak", "sieci", "neuronowe", ",", "analiza", "skupie\u0144", ",", "algorytmy", "genetyczne", "(", "lata", "50", ".", ")", ",", "uczenie", "si\u0119", "drzew", "decyzyjnych", "i", "regu\u0142", "decyzyjnych", "(", "lata", "60", ".", ")", "oraz", "maszyny", "wektor\u00f3w", "wsparcia", "(", "lata", "90", ".", ")", "."], "sentence-detokenized": "W miar\u0119 jak zbiory danych stawa\u0142y si\u0119 coraz wi\u0119ksze i bardziej z\u0142o\u017cone, bezpo\u015brednia, praktyczna analiza danych zosta\u0142a uzupe\u0142niona po\u015brednim, zautomatyzowanym przetwarzaniem danych, wspomaganym przez inne odkrycia w informatyce, zw\u0142aszcza w dziedzinie uczenia maszynowego, takie jak sieci neuronowe, analiza skupie\u0144, algorytmy genetyczne (lata 50.), uczenie si\u0119 drzew decyzyjnych i regu\u0142 decyzyjnych (lata 60.) oraz maszyny wektor\u00f3w wsparcia (lata 90.).", "token2charspan": [[0, 1], [2, 7], [8, 11], [12, 18], [19, 25], [26, 33], [34, 37], [38, 43], [44, 51], [52, 53], [54, 62], [63, 70], [70, 71], [72, 84], [84, 85], [86, 96], [97, 104], [105, 111], [112, 119], [120, 131], [132, 141], [141, 142], [143, 159], [160, 174], [175, 181], [181, 182], [183, 194], [195, 200], [201, 205], [206, 214], [215, 216], [217, 228], [228, 229], [230, 239], [240, 241], [242, 252], [253, 260], [261, 272], [272, 273], [274, 279], [280, 283], [284, 289], [290, 299], [299, 300], [301, 308], [309, 316], [316, 317], [318, 327], [328, 338], [339, 340], [340, 344], [345, 347], [347, 348], [348, 349], [349, 350], [351, 358], [359, 362], [363, 368], [369, 380], [381, 382], [383, 388], [389, 400], [401, 402], [402, 406], [407, 409], [409, 410], [410, 411], [412, 416], [417, 424], [425, 433], [434, 442], [443, 444], [444, 448], [449, 451], [451, 452], [452, 453], [453, 454]]}
{"doc_key": "ai-test-165", "ner": [[3, 3, "researcher"], [16, 17, "misc"], [10, 11, "researcher"], [13, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 17, 3, 3, "artifact", "", false, false], [16, 17, 10, 11, "artifact", "", false, false], [16, 17, 13, 14, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Jesieni\u0105", "2005", "roku", "Thrun", "opublikowa\u0142", "wraz", "ze", "swoimi", "wieloletnimi", "wsp\u00f3\u0142pracownikami", "Dieterem", "Foxem", "i", "Wolframem", "Burgardem", "podr\u0119cznik", "Probabilistic", "Robotics", "."], "sentence-detokenized": "Jesieni\u0105 2005 roku Thrun opublikowa\u0142 wraz ze swoimi wieloletnimi wsp\u00f3\u0142pracownikami Dieterem Foxem i Wolframem Burgardem podr\u0119cznik Probabilistic Robotics.", "token2charspan": [[0, 8], [9, 13], [14, 18], [19, 24], [25, 36], [37, 41], [42, 44], [45, 51], [52, 64], [65, 82], [83, 91], [92, 97], [98, 99], [100, 109], [110, 119], [120, 130], [131, 144], [145, 153], [153, 154]]}
{"doc_key": "ai-test-166", "ner": [[0, 3, "researcher"], [5, 6, "researcher"], [8, 9, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["John", "D", ".", "Lafferty", ",", "Andrew", "McCallum", "i", "Pereiramath", "w", "nast\u0119puj\u0105cy", "spos\u00f3b", ":"], "sentence-detokenized": "John D. Lafferty, Andrew McCallum i Pereiramath w nast\u0119puj\u0105cy spos\u00f3b:", "token2charspan": [[0, 4], [5, 6], [6, 7], [8, 16], [16, 17], [18, 24], [25, 33], [34, 35], [36, 47], [48, 49], [50, 61], [62, 68], [68, 69]]}
{"doc_key": "ai-test-167", "ner": [[0, 7, "task"], [9, 9, "task"], [13, 15, "field"], [16, 17, "field"], [19, 21, "field"], [23, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 7, 16, 17, "part-of", "task_part_of_field", false, false], [0, 7, 19, 21, "part-of", "task_part_of_field", false, false], [9, 9, 0, 7, "named", "", false, false], [16, 17, 13, 15, "part-of", "subfield", false, false], [19, 21, 13, 15, "part-of", "subfield", false, false], [23, 23, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Odpowiadanie", "na", "pytania", "(", "ang", ".", "Question", "answering", ",", "QA", ")", "to", "dziedzina", "informatyki", "z", "zakresu", "wyszukiwania", "informacji", "i", "przetwarzania", "j\u0119zyka", "naturalnego", "(", "NLP", ")", ",", "zajmuj\u0105ca", "si\u0119", "budow\u0105", "system\u00f3w", "automatycznie", "odpowiadaj\u0105cych", "na", "pytania", "zadawane", "przez", "ludzi", "w", "j\u0119zyku", "naturalnym", "."], "sentence-detokenized": "Odpowiadanie na pytania (ang. Question answering, QA) to dziedzina informatyki z zakresu wyszukiwania informacji i przetwarzania j\u0119zyka naturalnego (NLP), zajmuj\u0105ca si\u0119 budow\u0105 system\u00f3w automatycznie odpowiadaj\u0105cych na pytania zadawane przez ludzi w j\u0119zyku naturalnym.", "token2charspan": [[0, 12], [13, 15], [16, 23], [24, 25], [25, 28], [28, 29], [30, 38], [39, 48], [48, 49], [50, 52], [52, 53], [54, 56], [57, 66], [67, 78], [79, 80], [81, 88], [89, 101], [102, 112], [113, 114], [115, 128], [129, 135], [136, 147], [148, 149], [149, 152], [152, 153], [153, 154], [155, 164], [165, 168], [169, 175], [176, 184], [185, 198], [199, 214], [215, 217], [218, 225], [226, 234], [235, 240], [241, 246], [247, 248], [249, 255], [256, 266], [266, 267]]}
{"doc_key": "ai-test-168", "ner": [[7, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Jednak", "w", "wersji", "metryki", "stosowanej", "w", "ocenach", "NIST", "przed", "2009", "rokiem", ",", "zamiast", "tego", "u\u017cywano", "najkr\u00f3tszego", "zdania", "referencyjnego", "."], "sentence-detokenized": "Jednak w wersji metryki stosowanej w ocenach NIST przed 2009 rokiem, zamiast tego u\u017cywano najkr\u00f3tszego zdania referencyjnego.", "token2charspan": [[0, 6], [7, 8], [9, 15], [16, 23], [24, 34], [35, 36], [37, 44], [45, 49], [50, 55], [56, 60], [61, 67], [67, 68], [69, 76], [77, 81], [82, 89], [90, 102], [103, 109], [110, 124], [124, 125]]}
{"doc_key": "ai-test-169", "ner": [[4, 4, "person"], [13, 13, "organisation"], [11, 11, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 11, 11, "related-to", "invests_in", false, false], [11, 11, 13, 13, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["27", "sierpnia", "2018", "roku", "Toyota", "og\u0142osi\u0142a", "inwestycj\u0119", "500", "milion\u00f3w", "dolar\u00f3w", "w", "autonomiczne", "samochody", "Ubera", "."], "sentence-detokenized": "27 sierpnia 2018 roku Toyota og\u0142osi\u0142a inwestycj\u0119 500 milion\u00f3w dolar\u00f3w w autonomiczne samochody Ubera.", "token2charspan": [[0, 2], [3, 11], [12, 16], [17, 21], [22, 28], [29, 37], [38, 48], [49, 52], [53, 61], [62, 69], [70, 71], [72, 84], [85, 94], [95, 100], [100, 101]]}
{"doc_key": "ai-test-170", "ner": [[4, 6, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Maksimum", "z", "pr\u00f3by", "jest", "estymatorem", "maksymalnego", "prawdopodobie\u0144stwa", "dla", "maksimum", "z", "populacji", ",", "ale", ",", "jak", "om\u00f3wiono", "powy\u017cej", ",", "jest", "ono", "tendencyjne", "."], "sentence-detokenized": "Maksimum z pr\u00f3by jest estymatorem maksymalnego prawdopodobie\u0144stwa dla maksimum z populacji, ale, jak om\u00f3wiono powy\u017cej, jest ono tendencyjne.", "token2charspan": [[0, 8], [9, 10], [11, 16], [17, 21], [22, 33], [34, 46], [47, 65], [66, 69], [70, 78], [79, 80], [81, 90], [90, 91], [92, 95], [95, 96], [97, 100], [101, 109], [110, 117], [117, 118], [119, 123], [124, 127], [128, 139], [139, 140]]}
{"doc_key": "ai-test-171", "ner": [[0, 0, "task"], [3, 3, "misc"], [6, 6, "metrics"], [13, 17, "algorithm"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 3, "related-to", "overcomes", false, false], [0, 0, 6, 6, "related-to", "increases", false, false], [3, 3, 13, 17, "opposite", "", false, false], [3, 3, 19, 21, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LSI", "pomaga", "przezwyci\u0119\u017cy\u0107", "synonimi\u0119", ",", "zwi\u0119kszaj\u0105c", "recall", ",", "jedno", "z", "najbardziej", "problematycznych", "ogranicze\u0144", "boolowskich", "zapyta\u0144", "o", "s\u0142owa", "kluczowe", "i", "modeli", "przestrzeni", "wektorowej", "."], "sentence-detokenized": "LSI pomaga przezwyci\u0119\u017cy\u0107 synonimi\u0119, zwi\u0119kszaj\u0105c recall, jedno z najbardziej problematycznych ogranicze\u0144 boolowskich zapyta\u0144 o s\u0142owa kluczowe i modeli przestrzeni wektorowej.", "token2charspan": [[0, 3], [4, 10], [11, 24], [25, 34], [34, 35], [36, 47], [48, 54], [54, 55], [56, 61], [62, 63], [64, 75], [76, 92], [93, 103], [104, 115], [116, 123], [124, 125], [126, 131], [132, 140], [141, 142], [143, 149], [150, 161], [162, 172], [172, 173]]}
{"doc_key": "ai-test-172", "ner": [[2, 3, "task"], [20, 20, "programlang"], [22, 22, "programlang"], [24, 24, "programlang"], [26, 28, "programlang"], [31, 31, "programlang"], [33, 33, "programlang"], [35, 35, "programlang"], [37, 37, "programlang"], [39, 39, "programlang"], [41, 41, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[2, 3, 20, 20, "general-affiliation", "", false, false], [2, 3, 22, 22, "general-affiliation", "", false, false], [2, 3, 24, 24, "general-affiliation", "", false, false], [2, 3, 26, 28, "general-affiliation", "", false, false], [2, 3, 31, 31, "general-affiliation", "", false, false], [2, 3, 33, 33, "general-affiliation", "", false, false], [2, 3, 35, 35, "general-affiliation", "", false, false], [2, 3, 37, 37, "general-affiliation", "", false, false], [2, 3, 39, 39, "general-affiliation", "", false, false], [2, 3, 41, 41, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Aplikacje", "do", "akwizycji", "danych", "s\u0105", "zwykle", "kontrolowane", "przez", "programy", "opracowane", "przy", "u\u017cyciu", "r\u00f3\u017cnych", "j\u0119zyk\u00f3w", "programowania", "og\u00f3lnego", "przeznaczenia", ",", "takich", "jak", "Assembly", ",", "BASIC", ",", "C", ",", "C", "+", "+", ",", "C", "#", ",", "Fortran", ",", "Java", ",", "LabVIEW", ",", "Lisp", ",", "Pascal", "itp", "."], "sentence-detokenized": "Aplikacje do akwizycji danych s\u0105 zwykle kontrolowane przez programy opracowane przy u\u017cyciu r\u00f3\u017cnych j\u0119zyk\u00f3w programowania og\u00f3lnego przeznaczenia, takich jak Assembly, BASIC, C, C + +, C #, Fortran, Java, LabVIEW, Lisp, Pascal itp.", "token2charspan": [[0, 9], [10, 12], [13, 22], [23, 29], [30, 32], [33, 39], [40, 52], [53, 58], [59, 67], [68, 78], [79, 83], [84, 90], [91, 98], [99, 106], [107, 120], [121, 129], [130, 143], [143, 144], [145, 151], [152, 155], [156, 164], [164, 165], [166, 171], [171, 172], [173, 174], [174, 175], [176, 177], [178, 179], [180, 181], [181, 182], [183, 184], [185, 186], [186, 187], [188, 195], [195, 196], [197, 201], [201, 202], [203, 210], [210, 211], [212, 216], [216, 217], [218, 224], [225, 228], [228, 229]]}
{"doc_key": "ai-test-173", "ner": [[3, 3, "organisation"], [12, 12, "product"], [6, 7, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 12, 3, 3, "artifact", "", false, false], [12, 12, 6, 7, "physical", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["W", "2003", "roku", "Honda", "wypu\u015bci\u0142a", "w", "Wielkiej", "Brytanii", "i", "w", "Internecie", "reklam\u0119", "Cog", "."], "sentence-detokenized": "W 2003 roku Honda wypu\u015bci\u0142a w Wielkiej Brytanii i w Internecie reklam\u0119 Cog.", "token2charspan": [[0, 1], [2, 6], [7, 11], [12, 17], [18, 27], [28, 29], [30, 38], [39, 47], [48, 49], [50, 51], [52, 62], [63, 70], [71, 74], [74, 75]]}
{"doc_key": "ai-test-174", "ner": [[0, 3, "conference"], [6, 6, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 6, 6, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Association", "for", "Computational", "Linguistics", "definiuje", "lingwistyk\u0119", "obliczeniow\u0105", "jako", ":"], "sentence-detokenized": "Association for Computational Linguistics definiuje lingwistyk\u0119 obliczeniow\u0105 jako:", "token2charspan": [[0, 11], [12, 15], [16, 29], [30, 41], [42, 51], [52, 63], [64, 76], [77, 81], [81, 82]]}
{"doc_key": "ai-test-175", "ner": [[0, 2, "algorithm"], [1, 11, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 1, 11, "related-to", "calculates", false, false]], "relations_mapping_to_source": [0], "sentence": ["Algorytmy", "maksymalizacji", "oczekiwa\u0144", "mog\u0105", "by\u0107", "stosowane", "do", "obliczania", "przybli\u017conych", "oszacowa\u0144", "maksymalnego", "prawdopodobie\u0144stwa", "nieznanych", "parametr\u00f3w", "przestrzeni", "stan\u00f3w", "w", "filtrach", "o", "minimalnej", "wariancji", "i", "wyg\u0142adzaczach", "."], "sentence-detokenized": "Algorytmy maksymalizacji oczekiwa\u0144 mog\u0105 by\u0107 stosowane do obliczania przybli\u017conych oszacowa\u0144 maksymalnego prawdopodobie\u0144stwa nieznanych parametr\u00f3w przestrzeni stan\u00f3w w filtrach o minimalnej wariancji i wyg\u0142adzaczach.", "token2charspan": [[0, 9], [10, 24], [25, 34], [35, 39], [40, 43], [44, 53], [54, 56], [57, 67], [68, 81], [82, 91], [92, 104], [105, 123], [124, 134], [135, 145], [146, 157], [158, 164], [165, 166], [167, 175], [176, 177], [178, 188], [189, 198], [199, 200], [201, 214], [214, 215]]}
{"doc_key": "ai-test-176", "ner": [[6, 6, "misc"], [8, 9, "person"], [11, 12, "person"], [14, 15, "person"], [18, 19, "misc"], [20, 21, "person"], [24, 25, "person"], [29, 29, "person"], [31, 32, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[8, 9, 6, 6, "role", "actor_in", false, false], [11, 12, 6, 6, "role", "actor_in", false, false], [14, 15, 6, 6, "role", "actor_in", false, false], [20, 21, 18, 19, "role", "model_for", false, false], [29, 29, 31, 32, "social", "family", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["W\u015br\u00f3d", "korespondent\u00f3w", "znalaz\u0142y", "si\u0119", "by\u0142e", "aktorki", "Baywatch", ":", "Donna", "D'Errico", ",", "Carmen", "Electra", "i", "Traci", "Bingham", ",", "by\u0142a", "Playboy", "Playmate", "Heidi", "Mark", ",", "komik", "Arj", "Barker", "oraz", "identyczne", "bli\u017aniaki", "Randy", "i", "Jason", "Sklar", "."], "sentence-detokenized": "W\u015br\u00f3d korespondent\u00f3w znalaz\u0142y si\u0119 by\u0142e aktorki Baywatch: Donna D'Errico, Carmen Electra i Traci Bingham, by\u0142a Playboy Playmate Heidi Mark, komik Arj Barker oraz identyczne bli\u017aniaki Randy i Jason Sklar.", "token2charspan": [[0, 5], [6, 20], [21, 29], [30, 33], [34, 38], [39, 46], [47, 55], [55, 56], [57, 62], [63, 71], [71, 72], [73, 79], [80, 87], [88, 89], [90, 95], [96, 103], [103, 104], [105, 109], [110, 117], [118, 126], [127, 132], [133, 137], [137, 138], [139, 144], [145, 148], [149, 155], [156, 160], [161, 171], [172, 181], [182, 187], [188, 189], [190, 195], [196, 201], [201, 202]]}
{"doc_key": "ai-test-177", "ner": [[9, 10, "task"], [12, 12, "task"], [17, 19, "product"], [22, 23, "task"], [25, 25, "task"], [30, 31, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 12, 9, 10, "named", "", false, false], [17, 19, 9, 10, "general-affiliation", "", false, false], [25, 25, 22, 23, "named", "", false, false], [30, 31, 22, 23, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Jest", "on", "powszechnie", "stosowany", "do", "generowania", "reprezentacji", "na", "potrzeby", "rozpoznawania", "mowy", "(", "ASR", ")", ",", "np", ".", "system", "CMU", "Sphinx", ",", "oraz", "syntezy", "mowy", "(", "TTS", ")", ",", "np", ".", "system", "Festival", "."], "sentence-detokenized": "Jest on powszechnie stosowany do generowania reprezentacji na potrzeby rozpoznawania mowy (ASR), np. system CMU Sphinx, oraz syntezy mowy (TTS), np. system Festival.", "token2charspan": [[0, 4], [5, 7], [8, 19], [20, 29], [30, 32], [33, 44], [45, 58], [59, 61], [62, 70], [71, 84], [85, 89], [90, 91], [91, 94], [94, 95], [95, 96], [97, 99], [99, 100], [101, 107], [108, 111], [112, 118], [118, 119], [120, 124], [125, 132], [133, 137], [138, 139], [139, 142], [142, 143], [143, 144], [145, 147], [147, 148], [149, 155], [156, 164], [164, 165]]}
{"doc_key": "ai-test-178", "ner": [[0, 0, "metrics"], [2, 5, "metrics"], [7, 7, "metrics"], [13, 13, "metrics"], [27, 28, "metrics"], [30, 30, "metrics"], [41, 42, "metrics"], [44, 44, "metrics"], [46, 48, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 5, 0, 0, "named", "", false, false], [7, 7, 2, 5, "named", "", false, false], [13, 13, 0, 0, "named", "", false, false], [30, 30, 27, 28, "named", "", false, false], [44, 44, 41, 42, "named", "", false, false], [46, 48, 41, 42, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Czu\u0142o\u015b\u0107", "lub", "wska\u017anik", "TRUE", "Positive", "Rate", "(", "TPR", ")", ",", "znany", "r\u00f3wnie\u017c", "jako", "recall", ",", "jest", "proporcj\u0105", "os\u00f3b", ",", "kt\u00f3re", "przesz\u0142y", "test", "pozytywny", "i", "s\u0105", "pozytywne", "(", "TRUE", "Positive", ",", "TP", ")", "do", "wszystkich", "os\u00f3b", ",", "kt\u00f3re", "faktycznie", "s\u0105", "pozytywne", "(", "Condition", "Positive", ",", "CP", "=", "TP", "+", "FN", ")", "."], "sentence-detokenized": "Czu\u0142o\u015b\u0107 lub wska\u017anik TRUE Positive Rate (TPR), znany r\u00f3wnie\u017c jako recall, jest proporcj\u0105 os\u00f3b, kt\u00f3re przesz\u0142y test pozytywny i s\u0105 pozytywne (TRUE Positive, TP) do wszystkich os\u00f3b, kt\u00f3re faktycznie s\u0105 pozytywne (Condition Positive, CP = TP + FN).", "token2charspan": [[0, 7], [8, 11], [12, 20], [21, 25], [26, 34], [35, 39], [40, 41], [41, 44], [44, 45], [45, 46], [47, 52], [53, 60], [61, 65], [66, 72], [72, 73], [74, 78], [79, 88], [89, 93], [93, 94], [95, 100], [101, 109], [110, 114], [115, 124], [125, 126], [127, 129], [130, 139], [140, 141], [141, 145], [146, 154], [154, 155], [156, 158], [158, 159], [160, 162], [163, 173], [174, 178], [178, 179], [180, 185], [186, 196], [197, 199], [200, 209], [210, 211], [211, 220], [221, 229], [229, 230], [231, 233], [234, 235], [236, 238], [239, 240], [241, 243], [243, 244], [244, 245]]}
{"doc_key": "ai-test-179", "ner": [[3, 4, "task"], [12, 12, "conference"], [14, 15, "conference"], [17, 17, "conference"], [19, 19, "conference"], [21, 21, "conference"], [23, 24, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 12, 3, 4, "topic", "", false, false], [14, 15, 3, 4, "topic", "", false, false], [17, 17, 3, 4, "topic", "", false, false], [19, 19, 3, 4, "topic", "", false, false], [21, 21, 3, 4, "topic", "", false, false], [23, 24, 3, 4, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Popularne", "konferencje", "dotycz\u0105ce", "rozpoznawania", "mowy", "odbywaj\u0105ce", "si\u0119", "co", "roku", "lub", "dwa", "to", "SpeechTEK", "i", "SpeechTEK", "Europe", ",", "ICASSP", ",", "Interspeech", "/", "Eurospeech", "oraz", "IEEE", "ASRU", "."], "sentence-detokenized": "Popularne konferencje dotycz\u0105ce rozpoznawania mowy odbywaj\u0105ce si\u0119 co roku lub dwa to SpeechTEK i SpeechTEK Europe, ICASSP, Interspeech / Eurospeech oraz IEEE ASRU.", "token2charspan": [[0, 9], [10, 21], [22, 31], [32, 45], [46, 50], [51, 61], [62, 65], [66, 68], [69, 73], [74, 77], [78, 81], [82, 84], [85, 94], [95, 96], [97, 106], [107, 113], [113, 114], [115, 121], [121, 122], [123, 134], [135, 136], [137, 147], [148, 152], [153, 157], [158, 162], [162, 163]]}
{"doc_key": "ai-test-180", "ner": [[0, 0, "researcher"], [3, 3, "researcher"], [15, 16, "product"], [19, 19, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[19, 19, 0, 0, "artifact", "", false, false], [19, 19, 3, 3, "artifact", "", false, false], [19, 19, 15, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Devol", "wsp\u00f3\u0142pracowa\u0142", "z", "Engelbergerem", ",", "kt\u00f3ry", "pe\u0142ni\u0142", "funkcj\u0119", "prezesa", "firmy", ",", "przy", "projektowaniu", "i", "produkcji", "robota", "przemys\u0142owego", "pod", "mark\u0105", "Unimate", "."], "sentence-detokenized": "Devol wsp\u00f3\u0142pracowa\u0142 z Engelbergerem, kt\u00f3ry pe\u0142ni\u0142 funkcj\u0119 prezesa firmy, przy projektowaniu i produkcji robota przemys\u0142owego pod mark\u0105 Unimate.", "token2charspan": [[0, 5], [6, 19], [20, 21], [22, 35], [35, 36], [37, 42], [43, 49], [50, 57], [58, 65], [66, 71], [71, 72], [73, 77], [78, 91], [92, 93], [94, 103], [104, 110], [111, 124], [125, 128], [129, 134], [135, 142], [142, 143]]}
{"doc_key": "ai-test-181", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [7, 9, "algorithm"], [20, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 7, 9, "general-affiliation", "", false, false], [4, 4, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Ukryty", "model", "Markowa", "(", "HMM", ")", "jest", "statystycznym", "modelem", "Markowa", ",", "w", "kt\u00f3rym", "zak\u0142ada", "si\u0119", ",", "\u017ce", "modelowany", "system", "jest", "procesem", "Markowa", "o", "nieobserwowanych", "(", "ukrytych", ")", "stanach", "."], "sentence-detokenized": "Ukryty model Markowa (HMM) jest statystycznym modelem Markowa, w kt\u00f3rym zak\u0142ada si\u0119, \u017ce modelowany system jest procesem Markowa o nieobserwowanych (ukrytych) stanach.", "token2charspan": [[0, 6], [7, 12], [13, 20], [21, 22], [22, 25], [25, 26], [27, 31], [32, 45], [46, 53], [54, 61], [61, 62], [63, 64], [65, 71], [72, 79], [80, 83], [83, 84], [85, 87], [88, 98], [99, 105], [106, 110], [111, 119], [120, 127], [128, 129], [130, 146], [147, 148], [148, 156], [156, 157], [158, 165], [165, 166]]}
{"doc_key": "ai-test-182", "ner": [[17, 19, "metrics"], [25, 25, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["W\u0142a\u015bciwo\u015b\u0107", "ta", ",", "niepo\u017c\u0105dana", "w", "wielu", "zastosowaniach", ",", "sk\u0142oni\u0142a", "badaczy", "do", "stosowania", "alternatywnych", "rozwi\u0105za\u0144", ",", "takich", "jak", "\u015bredni", "b\u0142\u0105d", "bezwzgl\u0119dny", ",", "czy", "te\u017c", "opartych", "na", "medianie", "."], "sentence-detokenized": "W\u0142a\u015bciwo\u015b\u0107 ta, niepo\u017c\u0105dana w wielu zastosowaniach, sk\u0142oni\u0142a badaczy do stosowania alternatywnych rozwi\u0105za\u0144, takich jak \u015bredni b\u0142\u0105d bezwzgl\u0119dny, czy te\u017c opartych na medianie.", "token2charspan": [[0, 10], [11, 13], [13, 14], [15, 26], [27, 28], [29, 34], [35, 49], [49, 50], [51, 59], [60, 67], [68, 70], [71, 81], [82, 96], [97, 106], [106, 107], [108, 114], [115, 118], [119, 125], [126, 130], [131, 142], [142, 143], [144, 147], [148, 151], [152, 160], [161, 163], [164, 172], [172, 173]]}
{"doc_key": "ai-test-183", "ner": [[16, 16, "algorithm"], [23, 23, "field"], [26, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 16, 23, 23, "part-of", "", false, false], [16, 16, 26, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Taka", "sekwencja", "(", "kt\u00f3ra", "na", "ka\u017cdym", "etapie", "zale\u017cy", "od", "wyniku", "badania", "poprzednich", "atrybut\u00f3w", ")", "nazywana", "jest", "drzewem", "decyzyjnym", "i", "stosowana", "w", "dziedzinie", "uczenia", "maszynowego", "znanej", "jako", "uczenie", "drzew", "decyzyjnych", "."], "sentence-detokenized": "Taka sekwencja (kt\u00f3ra na ka\u017cdym etapie zale\u017cy od wyniku badania poprzednich atrybut\u00f3w) nazywana jest drzewem decyzyjnym i stosowana w dziedzinie uczenia maszynowego znanej jako uczenie drzew decyzyjnych.", "token2charspan": [[0, 4], [5, 14], [15, 16], [16, 21], [22, 24], [25, 31], [32, 38], [39, 45], [46, 48], [49, 55], [56, 63], [64, 75], [76, 85], [85, 86], [87, 95], [96, 100], [101, 108], [109, 119], [120, 121], [122, 131], [132, 133], [134, 144], [145, 152], [153, 164], [165, 171], [172, 176], [177, 184], [185, 190], [191, 202], [202, 203]]}
{"doc_key": "ai-test-184", "ner": [[3, 4, "task"], [6, 6, "algorithm"], [20, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 6, 6, "compare", "", false, false], [20, 21, 6, 6, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Podobnie", "jak", "w", "analizie", "czynnikowej", ",", "LCA", "mo\u017ce", "by\u0107", "r\u00f3wnie\u017c", "wykorzystana", "do", "klasyfikacji", "przypadku", "wed\u0142ug", "ich", "przynale\u017cno\u015bci", "do", "klasy", "z", "maksymalnym", "prawdopodobie\u0144stwem", "."], "sentence-detokenized": "Podobnie jak w analizie czynnikowej, LCA mo\u017ce by\u0107 r\u00f3wnie\u017c wykorzystana do klasyfikacji przypadku wed\u0142ug ich przynale\u017cno\u015bci do klasy z maksymalnym prawdopodobie\u0144stwem.", "token2charspan": [[0, 8], [9, 12], [13, 14], [15, 23], [24, 35], [35, 36], [37, 40], [41, 45], [46, 49], [50, 57], [58, 70], [71, 73], [74, 86], [87, 96], [97, 103], [104, 107], [108, 122], [123, 125], [126, 131], [132, 133], [134, 145], [146, 165], [165, 166]]}
{"doc_key": "ai-test-185", "ner": [[0, 2, "algorithm"], [8, 9, "metrics"], [11, 11, "metrics"], [6, 7, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 8, 9, "usage", "", false, false], [8, 9, 6, 7, "related-to", "", false, false], [11, 11, 8, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Nadzorowane", "sieci", "neuronowe", ",", "kt\u00f3re", "wykorzystuj\u0105", "funkcj\u0119", "kosztu", "b\u0142\u0119du", "\u015bredniokwadratowego", "(", "MSE", ")", ",", "mog\u0105", "wykorzystywa\u0107", "formalne", "metody", "statystyczne", "do", "okre\u015blania", "pewno\u015bci", "trenowanego", "modelu", "."], "sentence-detokenized": "Nadzorowane sieci neuronowe, kt\u00f3re wykorzystuj\u0105 funkcj\u0119 kosztu b\u0142\u0119du \u015bredniokwadratowego (MSE), mog\u0105 wykorzystywa\u0107 formalne metody statystyczne do okre\u015blania pewno\u015bci trenowanego modelu.", "token2charspan": [[0, 11], [12, 17], [18, 27], [27, 28], [29, 34], [35, 47], [48, 55], [56, 62], [63, 68], [69, 88], [89, 90], [90, 93], [93, 94], [94, 95], [96, 100], [101, 114], [115, 123], [124, 130], [131, 143], [144, 146], [147, 157], [158, 166], [167, 178], [179, 185], [185, 186]]}
{"doc_key": "ai-test-186", "ner": [[13, 14, "algorithm"], [16, 18, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 14, 16, 18, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Mo\u017cna", "to", "bezpo\u015brednio", "wyrazi\u0107", "jako", "program", "liniowy", ",", "ale", "jest", "to", "r\u00f3wnie\u017c", "r\u00f3wnowa\u017cne", "regularno\u015bci", "Tikhonova", "z", "funkcj\u0105", "straty", "zawiasowej", ",", "mathV", "(", "f", "(", "x", ")", ",", "y", ")", "=", "max", "(", "0", ",", "1", "-", "yf", "(", "x", ")", ")", "/", "math", ":"], "sentence-detokenized": "Mo\u017cna to bezpo\u015brednio wyrazi\u0107 jako program liniowy, ale jest to r\u00f3wnie\u017c r\u00f3wnowa\u017cne regularno\u015bci Tikhonova z funkcj\u0105 straty zawiasowej, mathV (f (x), y) = max (0, 1 - yf (x)) / math:", "token2charspan": [[0, 5], [6, 8], [9, 21], [22, 29], [30, 34], [35, 42], [43, 50], [50, 51], [52, 55], [56, 60], [61, 63], [64, 71], [72, 82], [83, 95], [96, 105], [106, 107], [108, 115], [116, 122], [123, 133], [133, 134], [135, 140], [141, 142], [142, 143], [144, 145], [145, 146], [146, 147], [147, 148], [149, 150], [150, 151], [152, 153], [154, 157], [158, 159], [159, 160], [160, 161], [162, 163], [164, 165], [166, 168], [169, 170], [170, 171], [171, 172], [172, 173], [174, 175], [176, 180], [180, 181]]}
{"doc_key": "ai-test-187", "ner": [[7, 7, "researcher"], [12, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Poni\u017csza", "technika", "zosta\u0142a", "opisana", "w", "oryginalnej", "pracy", "Breimana", "i", "jest", "zaimplementowana", "w", "pakiecie", "R", "randomForest", "."], "sentence-detokenized": "Poni\u017csza technika zosta\u0142a opisana w oryginalnej pracy Breimana i jest zaimplementowana w pakiecie R randomForest.", "token2charspan": [[0, 8], [9, 17], [18, 25], [26, 33], [34, 35], [36, 47], [48, 53], [54, 62], [63, 64], [65, 69], [70, 86], [87, 88], [89, 97], [98, 99], [100, 112], [112, 113]]}
{"doc_key": "ai-test-188", "ner": [[7, 7, "metrics"], [33, 33, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Tradycyjne", "miary", "jako\u015bci", "obrazu", ",", "takie", "jak", "PSNR", ",", "s\u0105", "zazwyczaj", "wykonywane", "na", "obrazach", "o", "sta\u0142ej", "rozdzielczo\u015bci", "i", "nie", "uwzgl\u0119dniaj\u0105", "niekt\u00f3rych", "aspekt\u00f3w", "ludzkiego", "systemu", "wizualnego", ",", "takich", "jak", "zmiana", "rozdzielczo\u015bci", "przestrzennej", "w", "obr\u0119bie", "siatk\u00f3wki", "."], "sentence-detokenized": "Tradycyjne miary jako\u015bci obrazu, takie jak PSNR, s\u0105 zazwyczaj wykonywane na obrazach o sta\u0142ej rozdzielczo\u015bci i nie uwzgl\u0119dniaj\u0105 niekt\u00f3rych aspekt\u00f3w ludzkiego systemu wizualnego, takich jak zmiana rozdzielczo\u015bci przestrzennej w obr\u0119bie siatk\u00f3wki.", "token2charspan": [[0, 10], [11, 16], [17, 24], [25, 31], [31, 32], [33, 38], [39, 42], [43, 47], [47, 48], [49, 51], [52, 61], [62, 72], [73, 75], [76, 84], [85, 86], [87, 93], [94, 108], [109, 110], [111, 114], [115, 127], [128, 138], [139, 147], [148, 157], [158, 165], [166, 176], [176, 177], [178, 184], [185, 188], [189, 195], [196, 210], [211, 224], [225, 226], [227, 234], [235, 244], [244, 245]]}
{"doc_key": "ai-test-189", "ner": [[0, 1, "person"], [3, 4, "person"], [6, 7, "person"], [12, 13, "person"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 14, 15, "role", "", false, false], [3, 4, 14, 15, "role", "", false, false], [6, 7, 14, 15, "role", "", false, false], [14, 15, 12, 13, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["John", "Ireland", ",", "Joanne", "Dru", "i", "Macdonald", "Carey", "wyst\u0105pili", "w", "kolorowej", "produkcji", "Jacka", "Brodera", "Hannah", "Lee", ",", "kt\u00f3rej", "premiera", "odby\u0142a", "si\u0119", "19", "czerwca", "1953", "roku", "."], "sentence-detokenized": "John Ireland, Joanne Dru i Macdonald Carey wyst\u0105pili w kolorowej produkcji Jacka Brodera Hannah Lee, kt\u00f3rej premiera odby\u0142a si\u0119 19 czerwca 1953 roku.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 20], [21, 24], [25, 26], [27, 36], [37, 42], [43, 52], [53, 54], [55, 64], [65, 74], [75, 80], [81, 88], [89, 95], [96, 99], [99, 100], [101, 107], [108, 116], [117, 123], [124, 127], [128, 130], [131, 138], [139, 143], [144, 148], [148, 149]]}
{"doc_key": "ai-test-190", "ner": [[4, 5, "task"], [10, 11, "field"], [16, 16, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 10, 11, "usage", "", false, false], [16, 16, 10, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Proces", "ten", "nazywany", "jest", "rejestracj\u0105", "obrazu", "i", "wykorzystuje", "r\u00f3\u017cne", "metody", "widzenia", "komputerowego", ",", "g\u0142\u00f3wnie", "zwi\u0105zane", "ze", "\u015bledzeniem", "."], "sentence-detokenized": "Proces ten nazywany jest rejestracj\u0105 obrazu i wykorzystuje r\u00f3\u017cne metody widzenia komputerowego, g\u0142\u00f3wnie zwi\u0105zane ze \u015bledzeniem.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 24], [25, 36], [37, 43], [44, 45], [46, 58], [59, 64], [65, 71], [72, 80], [81, 94], [94, 95], [96, 103], [104, 112], [113, 115], [116, 126], [126, 127]]}
{"doc_key": "ai-test-191", "ner": [[12, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Teraz", "zacznijmy", "wyja\u015bnia\u0107", "r\u00f3\u017cne", "mo\u017cliwe", "relacje", "mi\u0119dzy", "przewidywanym", "i", "rzeczywistym", "wynikiem", ":", "Macierz", "konfuzji"], "sentence-detokenized": "Teraz zacznijmy wyja\u015bnia\u0107 r\u00f3\u017cne mo\u017cliwe relacje mi\u0119dzy przewidywanym i rzeczywistym wynikiem: Macierz konfuzji", "token2charspan": [[0, 5], [6, 15], [16, 25], [26, 31], [32, 39], [40, 47], [48, 54], [55, 68], [69, 70], [71, 83], [84, 92], [92, 93], [94, 101], [102, 110]]}
{"doc_key": "ai-test-192", "ner": [[5, 5, "product"], [0, 4, "misc"], [7, 7, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 0, 4, "part-of", "", false, false], [5, 5, 0, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Zestaw", "narz\u0119dzi", "do", "przetwarzania", "mowy", "VOICEBOX", "dla", "MATLABa", "implementuje", "konwersj\u0119", "i", "jej", "odwrotno\u015b\u0107", "jako", ":"], "sentence-detokenized": "Zestaw narz\u0119dzi do przetwarzania mowy VOICEBOX dla MATLABa implementuje konwersj\u0119 i jej odwrotno\u015b\u0107 jako:", "token2charspan": [[0, 6], [7, 15], [16, 18], [19, 32], [33, 37], [38, 46], [47, 50], [51, 58], [59, 71], [72, 81], [82, 83], [84, 87], [88, 98], [99, 103], [103, 104]]}
{"doc_key": "ai-test-193", "ner": [[0, 0, "programlang"], [7, 8, "field"], [10, 11, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 7, 8, "general-affiliation", "", false, false], [0, 0, 10, 11, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolog", "to", "j\u0119zyk", "programowania", "logicznego", "zwi\u0105zany", "ze", "sztuczn\u0105", "inteligencj\u0105", "i", "lingwistyk\u0105", "obliczeniow\u0105", "."], "sentence-detokenized": "Prolog to j\u0119zyk programowania logicznego zwi\u0105zany ze sztuczn\u0105 inteligencj\u0105 i lingwistyk\u0105 obliczeniow\u0105.", "token2charspan": [[0, 6], [7, 9], [10, 15], [16, 29], [30, 40], [41, 49], [50, 52], [53, 61], [62, 74], [75, 76], [77, 88], [89, 101], [101, 102]]}
{"doc_key": "ai-test-194", "ner": [[0, 0, "researcher"], [8, 8, "field"], [10, 10, "field"], [16, 19, "organisation"], [21, 24, "organisation"], [26, 29, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 8, 8, "related-to", "works_with_topic", false, false], [0, 0, 10, 10, "related-to", "works_with_topic", false, false], [0, 0, 16, 19, "role", "", false, false], [0, 0, 21, 24, "role", "", false, false], [0, 0, 26, 29, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Milner", "otrzyma\u0142a", "liczne", "nagrody", "za", "sw\u00f3j", "wk\u0142ad", "w", "neuronauk\u0119", "i", "psychologi\u0119", ",", "w", "tym", "cz\u0142onkostwo", "w", "Royal", "Society", "of", "London", ",", "Royal", "Society", "of", "Canada", "i", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Milner otrzyma\u0142a liczne nagrody za sw\u00f3j wk\u0142ad w neuronauk\u0119 i psychologi\u0119, w tym cz\u0142onkostwo w Royal Society of London, Royal Society of Canada i National Academy of Sciences.", "token2charspan": [[0, 6], [7, 16], [17, 23], [24, 31], [32, 34], [35, 39], [40, 45], [46, 47], [48, 58], [59, 60], [61, 72], [72, 73], [74, 75], [76, 79], [80, 91], [92, 93], [94, 99], [100, 107], [108, 110], [111, 117], [117, 118], [119, 124], [125, 132], [133, 135], [136, 142], [143, 144], [145, 153], [154, 161], [162, 164], [165, 173], [173, 174]]}
{"doc_key": "ai-test-195", "ner": [[9, 10, "field"], [14, 15, "task"], [17, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 15, 9, 10, "part-of", "task_part_of_field", false, false], [17, 18, 9, 10, "part-of", "task_part_of_field", false, false], [20, 21, 9, 10, "part-of", "task_part_of_field", false, false], [23, 24, 9, 10, "part-of", "task_part_of_field", false, false], [26, 26, 9, 10, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["\u0141\u0105cz\u0105c", "te", "operatory", "mo\u017cna", "uzyska\u0107", "algorytmy", "dla", "wielu", "zada\u0144", "przetwarzania", "obraz\u00f3w", ",", "takich", "jak", "ekstrakcja", "cech", ",", "segmentacja", "obrazu", ",", "wyostrzanie", "obrazu", ",", "filtrowanie", "obrazu", "czy", "klasyfikacja", "."], "sentence-detokenized": "\u0141\u0105cz\u0105c te operatory mo\u017cna uzyska\u0107 algorytmy dla wielu zada\u0144 przetwarzania obraz\u00f3w, takich jak ekstrakcja cech, segmentacja obrazu, wyostrzanie obrazu, filtrowanie obrazu czy klasyfikacja.", "token2charspan": [[0, 6], [7, 9], [10, 19], [20, 25], [26, 33], [34, 43], [44, 47], [48, 53], [54, 59], [60, 73], [74, 81], [81, 82], [83, 89], [90, 93], [94, 104], [105, 109], [109, 110], [111, 122], [123, 129], [129, 130], [131, 142], [143, 149], [149, 150], [151, 162], [163, 169], [170, 173], [174, 186], [186, 187]]}
{"doc_key": "ai-test-196", "ner": [[6, 8, "university"], [15, 17, "organisation"], [19, 20, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 20, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Od", "2017", "roku", "jest", "profesorem", "w", "Coll\u00e8ge", "de", "France", ",", "a", "od", "1989", "roku", "dyrektorem", "INSERM", "Unit", "562", ",", "Cognitive", "Neuroimaging", "."], "sentence-detokenized": "Od 2017 roku jest profesorem w Coll\u00e8ge de France, a od 1989 roku dyrektorem INSERM Unit 562, Cognitive Neuroimaging.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 17], [18, 28], [29, 30], [31, 38], [39, 41], [42, 48], [48, 49], [50, 51], [52, 54], [55, 59], [60, 64], [65, 75], [76, 82], [83, 87], [88, 91], [91, 92], [93, 102], [103, 115], [115, 116]]}
{"doc_key": "ai-test-197", "ner": [[12, 14, "algorithm"], [16, 19, "algorithm"], [23, 23, "algorithm"], [25, 31, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 25, 31, "temporal", "", false, true]], "relations_mapping_to_source": [0], "sentence": ["Istnieje", "wiele", "podej\u015b\u0107", "do", "uczenia", "tych", "embedding\u00f3w", ",", "w", "szczeg\u00f3lno\u015bci", "przy", "u\u017cyciu", "ram", "Bayesian", "clustering", "lub", "ram", "opartych", "na", "energii", ",", "a", "ostatnio", "TransE", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", "2013", ")", "."], "sentence-detokenized": "Istnieje wiele podej\u015b\u0107 do uczenia tych embedding\u00f3w, w szczeg\u00f3lno\u015bci przy u\u017cyciu ram Bayesian clustering lub ram opartych na energii, a ostatnio TransE (Conference on Neural Information Processing Systems 2013).", "token2charspan": [[0, 8], [9, 14], [15, 22], [23, 25], [26, 33], [34, 38], [39, 50], [50, 51], [52, 53], [54, 67], [68, 72], [73, 79], [80, 83], [84, 92], [93, 103], [104, 107], [108, 111], [112, 120], [121, 123], [124, 131], [131, 132], [133, 134], [135, 143], [144, 150], [151, 152], [152, 162], [163, 165], [166, 172], [173, 184], [185, 195], [196, 203], [204, 208], [208, 209], [209, 210]]}
{"doc_key": "ai-test-198", "ner": [[9, 10, "metrics"], [12, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 14, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Jest", "to", "alternatywa", "dla", "stosowanego", "w", "kilku", "krajach", "wska\u017anika", "b\u0142\u0119du", "s\u0142owa", "(", "Word", "Error", "Rate", ")", "."], "sentence-detokenized": "Jest to alternatywa dla stosowanego w kilku krajach wska\u017anika b\u0142\u0119du s\u0142owa (Word Error Rate).", "token2charspan": [[0, 4], [5, 7], [8, 19], [20, 23], [24, 35], [36, 37], [38, 43], [44, 51], [52, 61], [62, 67], [68, 73], [74, 75], [75, 79], [80, 85], [86, 90], [90, 91], [91, 92]]}
{"doc_key": "ai-test-199", "ner": [[0, 0, "algorithm"], [10, 11, "task"], [13, 14, "task"], [16, 17, "task"], [19, 21, "task"], [23, 28, "task"], [30, 31, "task"], [47, 47, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 11, 0, 0, "usage", "", false, false], [13, 14, 0, 0, "usage", "", false, false], [16, 17, 0, 0, "usage", "", false, false], [19, 21, 0, 0, "usage", "", false, false], [23, 28, 0, 0, "usage", "", false, false], [30, 31, 0, 0, "usage", "", false, false], [47, 47, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["ANN", "zosta\u0142y", "wykorzystane", "do", "r\u00f3\u017cnych", "zada\u0144", ",", "w", "tym", "do", "wizji", "komputerowej", ",", "rozpoznawania", "mowy", ",", "t\u0142umaczenia", "maszynowego", ",", "filtrowania", "sieci", "spo\u0142eczno\u015bciowych", ",", "grania", "w", "gry", "planszowe", "i", "wideo", ",", "diagnostyki", "medycznej", ",", "a", "nawet", "w", "czynno\u015bciach", ",", "kt\u00f3re", "tradycyjnie", "uwa\u017cano", "za", "zarezerwowane", "dla", "ludzi", ",", "jak", "malowanie", "."], "sentence-detokenized": "ANN zosta\u0142y wykorzystane do r\u00f3\u017cnych zada\u0144, w tym do wizji komputerowej, rozpoznawania mowy, t\u0142umaczenia maszynowego, filtrowania sieci spo\u0142eczno\u015bciowych, grania w gry planszowe i wideo, diagnostyki medycznej, a nawet w czynno\u015bciach, kt\u00f3re tradycyjnie uwa\u017cano za zarezerwowane dla ludzi, jak malowanie.", "token2charspan": [[0, 3], [4, 11], [12, 24], [25, 27], [28, 35], [36, 41], [41, 42], [43, 44], [45, 48], [49, 51], [52, 57], [58, 70], [70, 71], [72, 85], [86, 90], [90, 91], [92, 103], [104, 115], [115, 116], [117, 128], [129, 134], [135, 152], [152, 153], [154, 160], [161, 162], [163, 166], [167, 176], [177, 178], [179, 184], [184, 185], [186, 197], [198, 207], [207, 208], [209, 210], [211, 216], [217, 218], [219, 231], [231, 232], [233, 238], [239, 250], [251, 258], [259, 261], [262, 275], [276, 279], [280, 285], [285, 286], [287, 290], [291, 300], [300, 301]]}
{"doc_key": "ai-test-200", "ner": [[0, 3, "product"], [5, 5, "product"], [16, 26, "field"], [28, 28, "field"], [33, 33, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 16, 26, "related-to", "", false, false], [0, 3, 33, 33, "general-affiliation", "", false, false], [5, 5, 0, 3, "named", "", false, false], [28, 28, 16, 26, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Modular", "Audio", "Recognition", "Framework", "(", "MARF", ")", "jest", "platform\u0105", "badawcz\u0105", "typu", "open-", "source", "oraz", "zbiorem", "algorytm\u00f3w", "przetwarzania", "g\u0142osu", ",", "d\u017awi\u0119ku", ",", "mowy", ",", "tekstu", "i", "j\u0119zyka", "naturalnego", "(", "NLP", ")", "napisanych", "w", "j\u0119zyku", "Java", "i", "u\u0142o\u017conych", "w", "modu\u0142ow\u0105", "i", "rozszerzaln\u0105", "struktur\u0119", ",", "kt\u00f3ra", "stara", "si\u0119", "u\u0142atwi\u0107", "dodawanie", "nowych", "algorytm\u00f3w", "."], "sentence-detokenized": "Modular Audio Recognition Framework (MARF) jest platform\u0105 badawcz\u0105 typu open-source oraz zbiorem algorytm\u00f3w przetwarzania g\u0142osu, d\u017awi\u0119ku, mowy, tekstu i j\u0119zyka naturalnego (NLP) napisanych w j\u0119zyku Java i u\u0142o\u017conych w modu\u0142ow\u0105 i rozszerzaln\u0105 struktur\u0119, kt\u00f3ra stara si\u0119 u\u0142atwi\u0107 dodawanie nowych algorytm\u00f3w.", "token2charspan": [[0, 7], [8, 13], [14, 25], [26, 35], [36, 37], [37, 41], [41, 42], [43, 47], [48, 57], [58, 66], [67, 71], [72, 77], [77, 83], [84, 88], [89, 96], [97, 107], [108, 121], [122, 127], [127, 128], [129, 136], [136, 137], [138, 142], [142, 143], [144, 150], [151, 152], [153, 159], [160, 171], [172, 173], [173, 176], [176, 177], [178, 188], [189, 190], [191, 197], [198, 202], [203, 204], [205, 214], [215, 216], [217, 225], [226, 227], [228, 240], [241, 250], [250, 251], [252, 257], [258, 263], [264, 267], [268, 275], [276, 285], [286, 292], [293, 303], [303, 304]]}
{"doc_key": "ai-test-201", "ner": [[6, 8, "organisation"], [22, 22, "country"], [26, 28, "organisation"], [30, 31, "organisation"], [34, 36, "task"], [52, 54, "organisation"], [56, 57, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[26, 28, 22, 22, "physical", "", false, false], [26, 28, 34, 36, "usage", "", false, false], [26, 28, 52, 54, "named", "", false, false], [30, 31, 22, 22, "physical", "", false, false], [30, 31, 34, 36, "usage", "", false, false], [52, 54, 56, 57, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["W", "2018", "r", ".", "raport", "organizacji", "Big", "Brother", "Watch", "zajmuj\u0105cej", "si\u0119", "kampani\u0105", "na", "rzecz", "swob\u00f3d", "obywatelskich", "i", "praw", "ujawni\u0142", ",", "\u017ce", "dwie", "brytyjskie", "si\u0142y", "policyjne", ",", "South", "Wales", "Police", "i", "Metropolitan", "Police", ",", "u\u017cywa\u0142y", "rozpoznawania", "twarzy", "na", "\u017cywo", "podczas", "wydarze\u0144", "publicznych", "i", "w", "przestrzeni", "publicznej", ",", "we", "wrze\u015bniu", "2019", "r", ".", ",", "South", "Wales", "Police", "u\u017cycie", "rozpoznawania", "twarzy", "zosta\u0142o", "uznane", "za", "zgodne", "z", "prawem", "."], "sentence-detokenized": "W 2018 r. raport organizacji Big Brother Watch zajmuj\u0105cej si\u0119 kampani\u0105 na rzecz swob\u00f3d obywatelskich i praw ujawni\u0142, \u017ce dwie brytyjskie si\u0142y policyjne, South Wales Police i Metropolitan Police, u\u017cywa\u0142y rozpoznawania twarzy na \u017cywo podczas wydarze\u0144 publicznych i w przestrzeni publicznej, we wrze\u015bniu 2019 r., South Wales Police u\u017cycie rozpoznawania twarzy zosta\u0142o uznane za zgodne z prawem.", "token2charspan": [[0, 1], [2, 6], [7, 8], [8, 9], [10, 16], [17, 28], [29, 32], [33, 40], [41, 46], [47, 57], [58, 61], [62, 70], [71, 73], [74, 79], [80, 86], [87, 100], [101, 102], [103, 107], [108, 115], [115, 116], [117, 119], [120, 124], [125, 135], [136, 140], [141, 150], [150, 151], [152, 157], [158, 163], [164, 170], [171, 172], [173, 185], [186, 192], [192, 193], [194, 201], [202, 215], [216, 222], [223, 225], [226, 230], [231, 238], [239, 247], [248, 259], [260, 261], [262, 263], [264, 275], [276, 286], [286, 287], [288, 290], [291, 299], [300, 304], [305, 306], [306, 307], [307, 308], [309, 314], [315, 320], [321, 327], [328, 334], [335, 348], [349, 355], [356, 363], [364, 370], [371, 373], [374, 380], [381, 382], [383, 389], [389, 390]]}
{"doc_key": "ai-test-202", "ner": [[0, 0, "product"], [4, 4, "programlang"], [12, 13, "field"], [15, 15, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 4, "general-affiliation", "", false, false], [0, 0, 12, 13, "related-to", "", false, false], [0, 0, 15, 15, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["ANIMAL", "zosta\u0142", "przeniesiony", "do", "R", ",", "swobodnie", "dost\u0119pnego", "j\u0119zyka", "i", "\u015brodowiska", "do", "oblicze\u0144", "statystycznych", "i", "grafiki", "."], "sentence-detokenized": "ANIMAL zosta\u0142 przeniesiony do R, swobodnie dost\u0119pnego j\u0119zyka i \u015brodowiska do oblicze\u0144 statystycznych i grafiki.", "token2charspan": [[0, 6], [7, 13], [14, 26], [27, 29], [30, 31], [31, 32], [33, 42], [43, 53], [54, 60], [61, 62], [63, 73], [74, 76], [77, 85], [86, 100], [101, 102], [103, 110], [110, 111]]}
{"doc_key": "ai-test-203", "ner": [[0, 4, "algorithm"], [6, 6, "algorithm"], [11, 13, "algorithm"], [15, 15, "algorithm"], [18, 20, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 11, 13, "opposite", "alternative to", false, false], [6, 6, 0, 4, "named", "", false, false], [15, 15, 11, 13, "named", "", false, false], [18, 20, 0, 4, "usage", "", false, false], [18, 20, 11, 13, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Time-", "inhomogeneous", "hidden", "Bernoulli", "model", "(", "TI-HBM", ")", "jest", "alternatyw\u0105", "dla", "ukrytego", "modelu", "Markowa", "(", "HMM", ")", "w", "automatycznym", "rozpoznawaniu", "mowy", "."], "sentence-detokenized": "Time-inhomogeneous hidden Bernoulli model (TI-HBM) jest alternatyw\u0105 dla ukrytego modelu Markowa (HMM) w automatycznym rozpoznawaniu mowy.", "token2charspan": [[0, 5], [5, 18], [19, 25], [26, 35], [36, 41], [42, 43], [43, 49], [49, 50], [51, 55], [56, 67], [68, 71], [72, 80], [81, 87], [88, 95], [96, 97], [97, 100], [100, 101], [102, 103], [104, 117], [118, 131], [132, 136], [136, 137]]}
{"doc_key": "ai-test-204", "ner": [[4, 5, "organisation"], [7, 7, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 7, 7, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["W", "lipcu", "2016", "roku", "Nvidia", "zademonstrowa\u0142a", "podczas", "SIGGRAPH", "now\u0105", "metod\u0119", "foveated", "rendering", "twierdz\u0105c", ",", "\u017ce", "jest", "ona", "niewidoczna", "dla", "u\u017cytkownik\u00f3w", "."], "sentence-detokenized": "W lipcu 2016 roku Nvidia zademonstrowa\u0142a podczas SIGGRAPH now\u0105 metod\u0119 foveated rendering twierdz\u0105c, \u017ce jest ona niewidoczna dla u\u017cytkownik\u00f3w.", "token2charspan": [[0, 1], [2, 7], [8, 12], [13, 17], [18, 24], [25, 40], [41, 48], [49, 57], [58, 62], [63, 69], [70, 78], [79, 88], [89, 98], [98, 99], [100, 102], [103, 107], [108, 111], [112, 123], [124, 127], [128, 140], [140, 141]]}
{"doc_key": "ai-test-205", "ner": [[4, 6, "misc"], [9, 12, "researcher"], [18, 19, "researcher"], [21, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 9, 12, "origin", "", false, false], [4, 6, 18, 19, "origin", "", false, false], [4, 6, 21, 21, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Obie", "opieraj\u0105", "si\u0119", "na", "teorii", "akt\u00f3w", "mowy", "opracowanej", "przez", "Johna", "Searle'a", "w", "latach", "60", ".", "i", "wzbogaconej", "przez", "Terry'ego", "Winograda", "i", "Floresa", "w", "latach", "70", "."], "sentence-detokenized": "Obie opieraj\u0105 si\u0119 na teorii akt\u00f3w mowy opracowanej przez Johna Searle'a w latach 60. i wzbogaconej przez Terry'ego Winograda i Floresa w latach 70.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 20], [21, 27], [28, 33], [34, 38], [39, 50], [51, 56], [57, 62], [63, 71], [72, 73], [74, 80], [81, 83], [83, 84], [85, 86], [87, 98], [99, 104], [105, 114], [115, 124], [125, 126], [127, 134], [135, 136], [137, 143], [144, 146], [146, 147]]}
{"doc_key": "ai-test-206", "ner": [[0, 2, "algorithm"], [19, 20, "researcher"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 19, 20, "related-to", "", false, false], [18, 18, 19, 20, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Modele", "sieci", "neuronowych", "dotycz\u0105ce", "tworzenia", "poj\u0119\u0107", "i", "struktury", "wiedzy", "otworzy\u0142y", "pot\u0119\u017cne", "hierarchiczne", "modele", "organizacji", "wiedzy", ",", "takie", "jak", "Wordnet", "George'a", "Millera", "."], "sentence-detokenized": "Modele sieci neuronowych dotycz\u0105ce tworzenia poj\u0119\u0107 i struktury wiedzy otworzy\u0142y pot\u0119\u017cne hierarchiczne modele organizacji wiedzy, takie jak Wordnet George'a Millera.", "token2charspan": [[0, 6], [7, 12], [13, 24], [25, 34], [35, 44], [45, 50], [51, 52], [53, 62], [63, 69], [70, 79], [80, 87], [88, 101], [102, 108], [109, 120], [121, 127], [127, 128], [129, 134], [135, 138], [139, 146], [147, 155], [156, 163], [163, 164]]}
{"doc_key": "ai-test-207", "ner": [[0, 1, "algorithm"], [12, 17, "field"], [16, 18, "product"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 12, 17, "part-of", "", false, false], [0, 1, 21, 23, "part-of", "", false, false], [16, 18, 12, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dopasowywanie", "szablon\u00f3w", "ma", "r\u00f3\u017cne", "zastosowania", "i", "jest", "wykorzystywane", "w", "takich", "dziedzinach", "jak", "rozpoznawanie", "twarzy", "(", "patrz", "system", "rozpoznawania", "twarzy", ")", "czy", "przetwarzanie", "obraz\u00f3w", "medycznych", "."], "sentence-detokenized": "Dopasowywanie szablon\u00f3w ma r\u00f3\u017cne zastosowania i jest wykorzystywane w takich dziedzinach jak rozpoznawanie twarzy (patrz system rozpoznawania twarzy) czy przetwarzanie obraz\u00f3w medycznych.", "token2charspan": [[0, 13], [14, 23], [24, 26], [27, 32], [33, 45], [46, 47], [48, 52], [53, 67], [68, 69], [70, 76], [77, 88], [89, 92], [93, 106], [107, 113], [114, 115], [115, 120], [121, 127], [128, 141], [142, 148], [148, 149], [150, 153], [154, 167], [168, 175], [176, 186], [186, 187]]}
{"doc_key": "ai-test-208", "ner": [[12, 13, "researcher"], [15, 16, "researcher"], [20, 28, "organisation"], [30, 30, "organisation"], [38, 39, "algorithm"], [41, 46, "conference"], [48, 48, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 13, 20, 28, "role", "", false, false], [12, 13, 41, 46, "physical", "", false, false], [12, 13, 41, 46, "temporal", "", false, false], [12, 13, 48, 48, "physical", "", false, false], [15, 16, 20, 28, "role", "", false, false], [15, 16, 41, 46, "temporal", "", false, false], [30, 30, 20, 28, "named", "", false, false], [41, 46, 38, 39, "topic", "", false, false], [48, 48, 41, 46, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Jednak", "ich", "u\u017cycie", "sta\u0142o", "si\u0119", "powszechne", "dopiero", "w", "2005", "roku", ",", "kiedy", "Navneet", "Dalal", "i", "Bill", "Triggs", ",", "naukowcy", "z", "francuskiego", "Narodowego", "Instytutu", "Bada\u0144", "w", "Dziedzinie", "Informatyki", "i", "Automatyki", "(", "INRIA", ")", ",", "przedstawili", "swoj\u0105", "dodatkow\u0105", "prac\u0119", "nad", "deskryptorami", "HOG", "na", "konferencji", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "."], "sentence-detokenized": "Jednak ich u\u017cycie sta\u0142o si\u0119 powszechne dopiero w 2005 roku, kiedy Navneet Dalal i Bill Triggs, naukowcy z francuskiego Narodowego Instytutu Bada\u0144 w Dziedzinie Informatyki i Automatyki (INRIA), przedstawili swoj\u0105 dodatkow\u0105 prac\u0119 nad deskryptorami HOG na konferencji Computer Vision and Pattern Recognition (CVPR).", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 23], [24, 27], [28, 38], [39, 46], [47, 48], [49, 53], [54, 58], [58, 59], [60, 65], [66, 73], [74, 79], [80, 81], [82, 86], [87, 93], [93, 94], [95, 103], [104, 105], [106, 118], [119, 129], [130, 139], [140, 145], [146, 147], [148, 158], [159, 170], [171, 172], [173, 183], [184, 185], [185, 190], [190, 191], [191, 192], [193, 205], [206, 211], [212, 221], [222, 227], [228, 231], [232, 245], [246, 249], [250, 252], [253, 264], [265, 273], [274, 280], [281, 284], [285, 292], [293, 304], [305, 306], [306, 310], [310, 311], [311, 312]]}
{"doc_key": "ai-test-209", "ner": [[4, 4, "university"], [17, 20, "organisation"], [22, 23, "organisation"], [30, 30, "field"], [36, 39, "researcher"], [41, 44, "researcher"], [46, 49, "researcher"], [51, 54, "organisation"], [57, 59, "organisation"], [64, 66, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[22, 23, 30, 30, "related-to", "", false, false], [36, 39, 22, 23, "physical", "", false, false], [36, 39, 22, 23, "role", "", false, false], [41, 44, 22, 23, "physical", "", false, false], [41, 44, 22, 23, "role", "", false, false], [46, 49, 22, 23, "physical", "", false, false], [46, 49, 22, 23, "role", "", false, false], [64, 66, 57, 59, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Przed", "do\u0142\u0105czeniem", "do", "wydzia\u0142u", "Penn", "w", "2002", "roku", ",", "sp\u0119dzi\u0142", "dekad\u0119", "(", "1991", "-", "2001", ")", "w", "AT", "&", "T", "Labs", "i", "Bell", "Labs", ",", "w", "tym", "jako", "szef", "dzia\u0142u", "AI", "z", "kolegami", ",", "w", "tym", "Michael", "L", ".", "Littman", ",", "David", "A", ".", "McAllester", "i", "Richard", "S", ".", "Sutton", ";", "dzia\u0142", "Secure", "Systems", "Research", ";", "i", "dzia\u0142", "Machine", "Learning", "z", "cz\u0142onkami", "takimi", "jak", "Michael", "Collins", "i", "lider", ")", "."], "sentence-detokenized": "Przed do\u0142\u0105czeniem do wydzia\u0142u Penn w 2002 roku, sp\u0119dzi\u0142 dekad\u0119 (1991-2001) w AT & T Labs i Bell Labs, w tym jako szef dzia\u0142u AI z kolegami, w tym Michael L. Littman, David A. McAllester i Richard S. Sutton; dzia\u0142 Secure Systems Research; i dzia\u0142 Machine Learning z cz\u0142onkami takimi jak Michael Collins i lider).", "token2charspan": [[0, 5], [6, 17], [18, 20], [21, 29], [30, 34], [35, 36], [37, 41], [42, 46], [46, 47], [48, 55], [56, 62], [63, 64], [64, 68], [68, 69], [69, 73], [73, 74], [75, 76], [77, 79], [80, 81], [82, 83], [84, 88], [89, 90], [91, 95], [96, 100], [100, 101], [102, 103], [104, 107], [108, 112], [113, 117], [118, 124], [125, 127], [128, 129], [130, 138], [138, 139], [140, 141], [142, 145], [146, 153], [154, 155], [155, 156], [157, 164], [164, 165], [166, 171], [172, 173], [173, 174], [175, 185], [186, 187], [188, 195], [196, 197], [197, 198], [199, 205], [205, 206], [207, 212], [213, 219], [220, 227], [228, 236], [236, 237], [238, 239], [240, 245], [246, 253], [254, 262], [263, 264], [265, 274], [275, 281], [282, 285], [286, 293], [294, 301], [302, 303], [304, 309], [309, 310], [310, 311]]}
{"doc_key": "ai-test-210", "ner": [[5, 7, "field"], [16, 17, "field"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 7, 16, 17, "compare", "", false, false], [23, 24, 16, 17, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Gdy", "dane", "s\u0105", "nieoznakowane", ",", "uczenie", "nadzorowane", "nie", "jest", "mo\u017cliwe", "i", "wymagane", "jest", "podej\u015bcie", "do", "uczenia", "bez", "nadzoru", ",", "kt\u00f3re", "pr\u00f3buje", "znale\u017a\u0107", "naturaln\u0105", "analiz\u0119", "Cluster", "do", "grup", ",", "a", "nast\u0119pnie", "mapowa\u0107", "nowe", "dane", "do", "tych", "utworzonych", "grup", "."], "sentence-detokenized": "Gdy dane s\u0105 nieoznakowane, uczenie nadzorowane nie jest mo\u017cliwe i wymagane jest podej\u015bcie do uczenia bez nadzoru, kt\u00f3re pr\u00f3buje znale\u017a\u0107 naturaln\u0105 analiz\u0119 Cluster do grup, a nast\u0119pnie mapowa\u0107 nowe dane do tych utworzonych grup.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 25], [25, 26], [27, 34], [35, 46], [47, 50], [51, 55], [56, 63], [64, 65], [66, 74], [75, 79], [80, 89], [90, 92], [93, 100], [101, 104], [105, 112], [112, 113], [114, 119], [120, 127], [128, 135], [136, 145], [146, 153], [154, 161], [162, 164], [165, 169], [169, 170], [171, 172], [173, 182], [183, 190], [191, 195], [196, 200], [201, 203], [204, 208], [209, 220], [221, 225], [225, 226]]}
{"doc_key": "ai-test-211", "ner": [[2, 2, "field"], [15, 18, "organisation"], [23, 24, "field"], [26, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 2, 15, 18, "origin", "", false, false], [2, 2, 23, 24, "part-of", "", false, false], [2, 2, 26, 26, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Ta", "dziedzina", "informatyki", "rozwin\u0119\u0142a", "si\u0119", "w", "latach", "50", ".", "w", "instytucjach", "akademickich", ",", "takich", "jak", "MIT", "A.I", ".", "Lab", ",", "pocz\u0105tkowo", "jako", "ga\u0142\u0105\u017a", "sztucznej", "inteligencji", "i", "robotyki", "."], "sentence-detokenized": "Ta dziedzina informatyki rozwin\u0119\u0142a si\u0119 w latach 50. w instytucjach akademickich, takich jak MIT A.I. Lab, pocz\u0105tkowo jako ga\u0142\u0105\u017a sztucznej inteligencji i robotyki.", "token2charspan": [[0, 2], [3, 12], [13, 24], [25, 34], [35, 38], [39, 40], [41, 47], [48, 50], [50, 51], [52, 53], [54, 66], [67, 79], [79, 80], [81, 87], [88, 91], [92, 95], [96, 99], [99, 100], [101, 104], [104, 105], [106, 116], [117, 121], [122, 127], [128, 137], [138, 150], [151, 152], [153, 161], [161, 162]]}
{"doc_key": "ai-test-212", "ner": [[6, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Mo\u017cna", "go", "r\u00f3wnie\u017c", "zast\u0105pi\u0107", "poni\u017cszym", "r\u00f3wnaniem", "Log", "loss", ":"], "sentence-detokenized": "Mo\u017cna go r\u00f3wnie\u017c zast\u0105pi\u0107 poni\u017cszym r\u00f3wnaniem Log loss:", "token2charspan": [[0, 5], [6, 8], [9, 16], [17, 25], [26, 35], [36, 45], [46, 49], [50, 54], [54, 55]]}
{"doc_key": "ai-test-213", "ner": [[5, 7, "organisation"], [11, 13, "organisation"], [18, 20, "university"], [22, 22, "university"], [24, 25, "university"], [27, 29, "university"], [31, 31, "country"], [3, 3, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[5, 7, 3, 3, "related-to", "research_leader_in_field", false, false], [11, 13, 5, 7, "named", "", false, false], [11, 13, 3, 3, "related-to", "research_leader_in_field", false, false], [18, 20, 3, 3, "related-to", "research_leader_in_field", false, false], [22, 22, 3, 3, "related-to", "research_leader_in_field", false, false], [24, 25, 3, 3, "related-to", "research_leader_in_field", false, false], [27, 29, 31, 31, "physical", "", false, false], [27, 29, 3, 3, "related-to", "research_leader_in_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Liderami", "bada\u0144", "nad", "biomechatronik\u0105", "s\u0105", "Shirley", "Ryan", "AbilityLab", "(", "dawniej", "Rehabilitation", "Institute", "of", "Chicago", ")", ",", "University", "of", "California", "at", "Berkeley", ",", "MIT", ",", "Stanford", "University", "oraz", "University", "of", "Twente", "w", "Holandii", "."], "sentence-detokenized": "Liderami bada\u0144 nad biomechatronik\u0105 s\u0105 Shirley Ryan AbilityLab (dawniej Rehabilitation Institute of Chicago), University of California at Berkeley, MIT, Stanford University oraz University of Twente w Holandii.", "token2charspan": [[0, 8], [9, 14], [15, 18], [19, 34], [35, 37], [38, 45], [46, 50], [51, 61], [62, 63], [63, 70], [71, 85], [86, 95], [96, 98], [99, 106], [106, 107], [107, 108], [109, 119], [120, 122], [123, 133], [134, 136], [137, 145], [145, 146], [147, 150], [150, 151], [152, 160], [161, 171], [172, 176], [177, 187], [188, 190], [191, 197], [198, 199], [200, 208], [208, 209]]}
{"doc_key": "ai-test-214", "ner": [[25, 28, "metrics"], [39, 39, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Bior\u0105c", "pod", "uwag\u0119", "zbi\u00f3r", "warto\u015bci", "przewidywanych", "i", "odpowiadaj\u0105cy", "im", "zbi\u00f3r", "warto\u015bci", "rzeczywistych", "dla", "X", "dla", "r\u00f3\u017cnych", "okres\u00f3w", "czasu", ",", "powszechnie", "stosowan\u0105", "technik\u0105", "oceny", "jest", "wykorzystanie", "\u015bredniego", "kwadratowego", "b\u0142\u0119du", "predykcji", ";", "dost\u0119pne", "s\u0105", "r\u00f3wnie\u017c", "inne", "miary", "(", "patrz", "prognozowanie", "#", "dok\u0142adno\u015b\u0107", "prognozowania", ")", "."], "sentence-detokenized": "Bior\u0105c pod uwag\u0119 zbi\u00f3r warto\u015bci przewidywanych i odpowiadaj\u0105cy im zbi\u00f3r warto\u015bci rzeczywistych dla X dla r\u00f3\u017cnych okres\u00f3w czasu, powszechnie stosowan\u0105 technik\u0105 oceny jest wykorzystanie \u015bredniego kwadratowego b\u0142\u0119du predykcji; dost\u0119pne s\u0105 r\u00f3wnie\u017c inne miary (patrz prognozowanie # dok\u0142adno\u015b\u0107 prognozowania).", "token2charspan": [[0, 6], [7, 10], [11, 16], [17, 22], [23, 31], [32, 46], [47, 48], [49, 62], [63, 65], [66, 71], [72, 80], [81, 94], [95, 98], [99, 100], [101, 104], [105, 112], [113, 120], [121, 126], [126, 127], [128, 139], [140, 149], [150, 158], [159, 164], [165, 169], [170, 183], [184, 193], [194, 206], [207, 212], [213, 222], [222, 223], [224, 232], [233, 235], [236, 243], [244, 248], [249, 254], [255, 256], [256, 261], [262, 275], [276, 277], [278, 288], [289, 302], [302, 303], [303, 304]]}
{"doc_key": "ai-test-215", "ner": [[12, 12, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Inne", "miary", ",", "takie", "jak", "proporcja", "poprawnych", "przewidywa\u0144", "(", "okre\u015blana", "r\u00f3wnie\u017c", "jako", "dok\u0142adno\u015b\u0107", ")", ",", "nie", "s\u0105", "przydatne", ",", "gdy", "dwie", "klasy", "s\u0105", "bardzo", "r\u00f3\u017cne", "."], "sentence-detokenized": "Inne miary, takie jak proporcja poprawnych przewidywa\u0144 (okre\u015blana r\u00f3wnie\u017c jako dok\u0142adno\u015b\u0107), nie s\u0105 przydatne, gdy dwie klasy s\u0105 bardzo r\u00f3\u017cne.", "token2charspan": [[0, 4], [5, 10], [10, 11], [12, 17], [18, 21], [22, 31], [32, 42], [43, 54], [55, 56], [56, 65], [66, 73], [74, 78], [79, 89], [89, 90], [90, 91], [92, 95], [96, 98], [99, 108], [108, 109], [110, 113], [114, 118], [119, 124], [125, 127], [128, 134], [135, 140], [140, 141]]}
{"doc_key": "ai-test-216", "ner": [[3, 3, "product"], [9, 13, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 9, 13, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Pierwsza", "wersja", "alfa", "OpenCV", "zosta\u0142a", "udost\u0119pniona", "publicznie", "na", "konferencji", "Computer", "Vision", "and", "Pattern", "Recognition", "w", "2000", "roku", ",", "a", "w", "latach", "2001", "-", "2005", "wydano", "pi\u0119\u0107", "wersji", "beta", "."], "sentence-detokenized": "Pierwsza wersja alfa OpenCV zosta\u0142a udost\u0119pniona publicznie na konferencji Computer Vision and Pattern Recognition w 2000 roku, a w latach 2001-2005 wydano pi\u0119\u0107 wersji beta.", "token2charspan": [[0, 8], [9, 15], [16, 20], [21, 27], [28, 35], [36, 48], [49, 59], [60, 62], [63, 74], [75, 83], [84, 90], [91, 94], [95, 102], [103, 114], [115, 116], [117, 121], [122, 126], [126, 127], [128, 129], [130, 131], [132, 138], [139, 143], [143, 144], [144, 148], [149, 155], [156, 160], [161, 167], [168, 172], [172, 173]]}
{"doc_key": "ai-test-217", "ner": [[19, 20, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Przedstawiono", "wyniki", ",", "kt\u00f3re", "daj\u0105", "korelacj\u0119", "do", "0,964", "z", "ludzk\u0105", "ocen\u0105", "na", "poziomie", "korpusu", ",", "w", "por\u00f3wnaniu", "do", "osi\u0105gni\u0119cia", "BLEU", "na", "poziomie", "0", ",817", "na", "tym", "samym", "zestawie", "danych", "."], "sentence-detokenized": "Przedstawiono wyniki, kt\u00f3re daj\u0105 korelacj\u0119 do 0,964 z ludzk\u0105 ocen\u0105 na poziomie korpusu, w por\u00f3wnaniu do osi\u0105gni\u0119cia BLEU na poziomie 0,817 na tym samym zestawie danych.", "token2charspan": [[0, 13], [14, 20], [20, 21], [22, 27], [28, 32], [33, 42], [43, 45], [46, 51], [52, 53], [54, 60], [61, 66], [67, 69], [70, 78], [79, 86], [86, 87], [88, 89], [90, 100], [101, 103], [104, 115], [116, 120], [121, 123], [124, 132], [133, 134], [134, 138], [139, 141], [142, 145], [146, 151], [152, 160], [161, 167], [167, 168]]}
{"doc_key": "ai-test-218", "ner": [[5, 5, "metrics"], [16, 16, "metrics"], [18, 20, "metrics"], [22, 24, "metrics"], [33, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 5, 16, 16, "compare", "", false, false], [5, 5, 18, 20, "compare", "", false, false], [5, 5, 22, 24, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Wykazano", ",", "\u017ce", "wczesna", "wersja", "VMAF", "przewy\u017csza", "inne", "metryki", "jako\u015bci", "obrazu", "i", "wideo", ",", "takie", "jak", "SSIM", ",", "PSNR", "-", "HVS", "i", "VQM", "-", "VFD", "na", "trzech", "z", "czterech", "zestaw\u00f3w", "danych", "pod", "wzgl\u0119dem", "dok\u0142adno\u015bci", "przewidywania", ",", "w", "por\u00f3wnaniu", "z", "subiektywnymi", "ocenami", "."], "sentence-detokenized": "Wykazano, \u017ce wczesna wersja VMAF przewy\u017csza inne metryki jako\u015bci obrazu i wideo, takie jak SSIM, PSNR -HVS i VQM-VFD na trzech z czterech zestaw\u00f3w danych pod wzgl\u0119dem dok\u0142adno\u015bci przewidywania, w por\u00f3wnaniu z subiektywnymi ocenami.", "token2charspan": [[0, 8], [8, 9], [10, 12], [13, 20], [21, 27], [28, 32], [33, 43], [44, 48], [49, 56], [57, 64], [65, 71], [72, 73], [74, 79], [79, 80], [81, 86], [87, 90], [91, 95], [95, 96], [97, 101], [102, 103], [103, 106], [107, 108], [109, 112], [112, 113], [113, 116], [117, 119], [120, 126], [127, 128], [129, 137], [138, 146], [147, 153], [154, 157], [158, 166], [167, 178], [179, 192], [192, 193], [194, 195], [196, 206], [207, 208], [209, 222], [223, 230], [230, 231]]}
{"doc_key": "ai-test-219", "ner": [[16, 17, "task"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 17, 23, 24, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Na", "przyk\u0142ad", "wieloznaczno\u015b\u0107", "s\u0142owa", "\"", "mysz", "\"", "(", "zwierz\u0119", "lub", "urz\u0105dzenie", ")", "nie", "jest", "istotna", "w", "t\u0142umaczeniu", "maszynowym", ",", "ale", "jest", "istotna", "w", "wyszukiwaniu", "informacji", "."], "sentence-detokenized": "Na przyk\u0142ad wieloznaczno\u015b\u0107 s\u0142owa \"mysz\" (zwierz\u0119 lub urz\u0105dzenie) nie jest istotna w t\u0142umaczeniu maszynowym, ale jest istotna w wyszukiwaniu informacji.", "token2charspan": [[0, 2], [3, 11], [12, 26], [27, 32], [33, 34], [34, 38], [38, 39], [40, 41], [41, 48], [49, 52], [53, 63], [63, 64], [65, 68], [69, 73], [74, 81], [82, 83], [84, 95], [96, 106], [106, 107], [108, 111], [112, 116], [117, 124], [125, 126], [127, 139], [140, 150], [150, 151]]}
{"doc_key": "ai-test-220", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [9, 10, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 0, 1, "usage", "", false, false], [9, 10, 6, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Geometryczne", "haszowanie", "zosta\u0142o", "pierwotnie", "zaproponowane", "w", "wizji", "komputerowej", "do", "rozpoznawania", "obiekt\u00f3w", "w", "2D", "i", "3D", ","], "sentence-detokenized": "Geometryczne haszowanie zosta\u0142o pierwotnie zaproponowane w wizji komputerowej do rozpoznawania obiekt\u00f3w w 2D i 3D,", "token2charspan": [[0, 12], [13, 23], [24, 31], [32, 42], [43, 56], [57, 58], [59, 64], [65, 77], [78, 80], [81, 94], [95, 103], [104, 105], [106, 108], [109, 110], [111, 113], [113, 114]]}
{"doc_key": "ai-test-221", "ner": [[6, 7, "field"], [11, 11, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 6, 7, "part-of", "subfield", false, false], [13, 14, 6, 7, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Stanowi", "jedn\u0105", "z", "trzech", "g\u0142\u00f3wnych", "kategorii", "uczenia", "maszynowego", ",", "obok", "uczenia", "nadzorowanego", "i", "uczenia", "wzmacniaj\u0105cego", "."], "sentence-detokenized": "Stanowi jedn\u0105 z trzech g\u0142\u00f3wnych kategorii uczenia maszynowego, obok uczenia nadzorowanego i uczenia wzmacniaj\u0105cego.", "token2charspan": [[0, 7], [8, 13], [14, 15], [16, 22], [23, 31], [32, 41], [42, 49], [50, 61], [61, 62], [63, 67], [68, 75], [76, 89], [90, 91], [92, 99], [100, 114], [114, 115]]}
{"doc_key": "ai-test-222", "ner": [[0, 3, "field"], [20, 20, "field"], [19, 23, "field"], [25, 26, "field"], [22, 29, "field"], [31, 34, "field"], [36, 37, "field"], [39, 40, "field"], [42, 42, "field"], [44, 45, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 3, 20, 20, "part-of", "subfield", false, false], [0, 3, 19, 23, "part-of", "subfield", false, false], [0, 3, 25, 26, "part-of", "subfield", false, false], [0, 3, 22, 29, "part-of", "subfield", false, false], [0, 3, 31, 34, "part-of", "subfield", false, false], [0, 3, 36, 37, "part-of", "subfield", false, false], [0, 3, 39, 40, "part-of", "subfield", false, false], [0, 3, 42, 42, "part-of", "subfield", false, false], [0, 3, 44, 45, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Uczenie", "wzmacniaj\u0105ce", ",", "ze", "wzgl\u0119du", "na", "swoj\u0105", "og\u00f3lno\u015b\u0107", ",", "jest", "badane", "w", "wielu", "innych", "dyscyplinach", ",", "takich", "jak", ":", "teoria", "gier", ",", "teoria", "sterowania", ",", "badania", "operacyjne", ",", "teoria", "informacji", ",", "optymalizacja", "oparta", "na", "symulacji", ",", "systemy", "wieloagentowe", ",", "inteligencja", "rojowa", ",", "statystyka", "i", "algorytmy", "genetyczne", "."], "sentence-detokenized": "Uczenie wzmacniaj\u0105ce, ze wzgl\u0119du na swoj\u0105 og\u00f3lno\u015b\u0107, jest badane w wielu innych dyscyplinach, takich jak: teoria gier, teoria sterowania, badania operacyjne, teoria informacji, optymalizacja oparta na symulacji, systemy wieloagentowe, inteligencja rojowa, statystyka i algorytmy genetyczne.", "token2charspan": [[0, 7], [8, 20], [20, 21], [22, 24], [25, 32], [33, 35], [36, 41], [42, 50], [50, 51], [52, 56], [57, 63], [64, 65], [66, 71], [72, 78], [79, 91], [91, 92], [93, 99], [100, 103], [103, 104], [105, 111], [112, 116], [116, 117], [118, 124], [125, 135], [135, 136], [137, 144], [145, 155], [155, 156], [157, 163], [164, 174], [174, 175], [176, 189], [190, 196], [197, 199], [200, 209], [209, 210], [211, 218], [219, 232], [232, 233], [234, 246], [247, 253], [253, 254], [255, 265], [266, 267], [268, 277], [278, 288], [288, 289]]}
{"doc_key": "ai-test-223", "ner": [[0, 1, "field"], [6, 7, "field"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "related-to", "", false, false], [0, 1, 9, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Rozpoznawanie", "wzorc\u00f3w", "jest", "\u015bci\u015ble", "zwi\u0105zane", "ze", "sztuczn\u0105", "inteligencj\u0105", "i", "uczeniem", "maszynowym", ","], "sentence-detokenized": "Rozpoznawanie wzorc\u00f3w jest \u015bci\u015ble zwi\u0105zane ze sztuczn\u0105 inteligencj\u0105 i uczeniem maszynowym,", "token2charspan": [[0, 13], [14, 21], [22, 26], [27, 33], [34, 42], [43, 45], [46, 54], [55, 67], [68, 69], [70, 78], [79, 89], [89, 90]]}
{"doc_key": "ai-test-224", "ner": [[9, 10, "algorithm"], [12, 13, "field"], [15, 16, "field"], [27, 28, "task"], [30, 30, "task"], [32, 33, "task"], [35, 36, "algorithm"], [38, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[9, 10, 12, 13, "related-to", "", false, false], [9, 10, 15, 16, "related-to", "", false, false], [27, 28, 9, 10, "usage", "", true, false], [30, 30, 9, 10, "usage", "", true, false], [32, 33, 9, 10, "usage", "", true, false], [35, 36, 9, 10, "usage", "", true, false], [38, 40, 9, 10, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Oprogramowanie", "s\u0142u\u017cy", "do", "projektowania", ",", "trenowania", "i", "wdra\u017cania", "modeli", "sieci", "neuronowych", "(", "uczenie", "nadzorowane", "i", "uczenie", "nienadzorowane", ")", "w", "celu", "wykonania", "szerokiego", "zakresu", "zada\u0144", ",", "takich", "jak", "eksploracja", "danych", ",", "klasyfikacja", ",", "aproksymacja", "funkcji", ",", "regresja", "wielowymiarowa", "i", "przewidywanie", "szereg\u00f3w", "czasowych", "."], "sentence-detokenized": "Oprogramowanie s\u0142u\u017cy do projektowania, trenowania i wdra\u017cania modeli sieci neuronowych (uczenie nadzorowane i uczenie nienadzorowane) w celu wykonania szerokiego zakresu zada\u0144, takich jak eksploracja danych, klasyfikacja, aproksymacja funkcji, regresja wielowymiarowa i przewidywanie szereg\u00f3w czasowych.", "token2charspan": [[0, 14], [15, 20], [21, 23], [24, 37], [37, 38], [39, 49], [50, 51], [52, 61], [62, 68], [69, 74], [75, 86], [87, 88], [88, 95], [96, 107], [108, 109], [110, 117], [118, 132], [132, 133], [134, 135], [136, 140], [141, 150], [151, 161], [162, 169], [170, 175], [175, 176], [177, 183], [184, 187], [188, 199], [200, 206], [206, 207], [208, 220], [220, 221], [222, 234], [235, 242], [242, 243], [244, 252], [253, 267], [268, 269], [270, 283], [284, 292], [293, 302], [302, 303]]}
{"doc_key": "ai-test-225", "ner": [[7, 13, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["W", "2016", "roku", "zosta\u0142", "wybrany", "Fellow", "of", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "W 2016 roku zosta\u0142 wybrany Fellow of Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 1], [2, 6], [7, 11], [12, 18], [19, 26], [27, 33], [34, 36], [37, 48], [49, 52], [53, 56], [57, 68], [69, 71], [72, 82], [83, 95], [95, 96]]}
{"doc_key": "ai-test-226", "ner": [[2, 5, "organisation"], [11, 16, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Jest", "cz\u0142onkiem", "National", "Academy", "of", "Sciences", "(", "od", "2005", ")", ",", "American", "Academy", "of", "Arts", "and", "Sciences", "(", "od", "2009", ")", ","], "sentence-detokenized": "Jest cz\u0142onkiem National Academy of Sciences (od 2005), American Academy of Arts and Sciences (od 2009),", "token2charspan": [[0, 4], [5, 14], [15, 23], [24, 31], [32, 34], [35, 43], [44, 45], [45, 47], [48, 52], [52, 53], [53, 54], [55, 63], [64, 71], [72, 74], [75, 79], [80, 83], [84, 92], [93, 94], [94, 96], [97, 101], [101, 102], [102, 103]]}
{"doc_key": "ai-test-227", "ner": [[1, 3, "misc"], [12, 15, "product"], [17, 17, "country"], [19, 19, "country"], [23, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 15, 1, 3, "temporal", "", false, false], [12, 15, 17, 17, "physical", "", false, false], [12, 15, 19, 19, "physical", "", false, false], [12, 15, 23, 24, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Podczas", "wojny", "Jom", "Kippur", "w", "1973", "r", ".", "dostarczane", "przez", "Sowiet\u00f3w", "baterie", "rakiet", "ziemia", "-", "powietrze", "w", "Egipcie", "i", "Syrii", "zada\u0142y", "ci\u0119\u017ckie", "obra\u017cenia", "izraelskim", "odrzutowcom", "."], "sentence-detokenized": "Podczas wojny Jom Kippur w 1973 r. dostarczane przez Sowiet\u00f3w baterie rakiet ziemia-powietrze w Egipcie i Syrii zada\u0142y ci\u0119\u017ckie obra\u017cenia izraelskim odrzutowcom.", "token2charspan": [[0, 7], [8, 13], [14, 17], [18, 24], [25, 26], [27, 31], [32, 33], [33, 34], [35, 46], [47, 52], [53, 61], [62, 69], [70, 76], [77, 83], [83, 84], [84, 93], [94, 95], [96, 103], [104, 105], [106, 111], [112, 118], [119, 126], [127, 136], [137, 147], [148, 159], [159, 160]]}
{"doc_key": "ai-test-228", "ner": [[11, 12, "product"], [17, 19, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 19, 11, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Innym", "zasobem", "(", "darmowym", ",", "ale", "chronionym", "prawem", "autorskim", ")", "jest", "ksi\u0105\u017cka", "HTK", "(", "i", "towarzysz\u0105cy", "jej", "zestaw", "narz\u0119dzi", "HTK", ")", "."], "sentence-detokenized": "Innym zasobem (darmowym, ale chronionym prawem autorskim) jest ksi\u0105\u017cka HTK (i towarzysz\u0105cy jej zestaw narz\u0119dzi HTK).", "token2charspan": [[0, 5], [6, 13], [14, 15], [15, 23], [23, 24], [25, 28], [29, 39], [40, 46], [47, 56], [56, 57], [58, 62], [63, 70], [71, 74], [75, 76], [76, 77], [78, 90], [91, 94], [95, 101], [102, 110], [111, 114], [114, 115], [115, 116]]}
{"doc_key": "ai-test-229", "ner": [[6, 9, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["-", "zosta\u0142y", "podj\u0119te", "na", "Wiosennym", "Sympozjum", "AAAI", "w", "2004", "roku", ",", "gdzie", "lingwi\u015bci", ",", "informatycy", "i", "inni", "zainteresowani", "badacze", "po", "raz", "pierwszy", "uzgodnili", "interesy", "i", "zaproponowali", "wsp\u00f3lne", "zadania", "i", "zestawy", "danych", "wzorcowych", "dla", "systematycznych", "bada\u0144", "obliczeniowych", "nad", "afektem", ",", "atrakcyjno\u015bci\u0105", ",", "subiektywno\u015bci\u0105", "i", "sentymentem", "w", "tek\u015bcie", "."], "sentence-detokenized": "- zosta\u0142y podj\u0119te na Wiosennym Sympozjum AAAI w 2004 roku, gdzie lingwi\u015bci, informatycy i inni zainteresowani badacze po raz pierwszy uzgodnili interesy i zaproponowali wsp\u00f3lne zadania i zestawy danych wzorcowych dla systematycznych bada\u0144 obliczeniowych nad afektem, atrakcyjno\u015bci\u0105, subiektywno\u015bci\u0105 i sentymentem w tek\u015bcie.", "token2charspan": [[0, 1], [2, 9], [10, 17], [18, 20], [21, 30], [31, 40], [41, 45], [46, 47], [48, 52], [53, 57], [57, 58], [59, 64], [65, 74], [74, 75], [76, 87], [88, 89], [90, 94], [95, 109], [110, 117], [118, 120], [121, 124], [125, 133], [134, 143], [144, 152], [153, 154], [155, 168], [169, 176], [177, 184], [185, 186], [187, 194], [195, 201], [202, 212], [213, 216], [217, 232], [233, 238], [239, 253], [254, 257], [258, 265], [265, 266], [267, 281], [281, 282], [283, 298], [299, 300], [301, 312], [313, 314], [315, 322], [322, 323]]}
{"doc_key": "ai-test-230", "ner": [[10, 11, "task"], [18, 19, "task"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Pojedyncza", "siatka", "mo\u017ce", "by\u0107", "analizowana", "zar\u00f3wno", "pod", "wzgl\u0119dem", "zawarto\u015bci", "(", "kontrola", "wzrokowa", ")", ",", "jak", "i", "struktury", "(", "analiza", "skupie\u0144", ",", "analiza", "g\u0142\u00f3wnych", "sk\u0142adowych", "oraz", "r\u00f3\u017cne", "wska\u017aniki", "strukturalne", "odnosz\u0105ce", "si\u0119", "do", "z\u0142o\u017cono\u015bci", "i", "zakresu", "ocen", "s\u0105", "g\u0142\u00f3wnymi", "stosowanymi", "technikami", ")", "."], "sentence-detokenized": "Pojedyncza siatka mo\u017ce by\u0107 analizowana zar\u00f3wno pod wzgl\u0119dem zawarto\u015bci (kontrola wzrokowa), jak i struktury (analiza skupie\u0144, analiza g\u0142\u00f3wnych sk\u0142adowych oraz r\u00f3\u017cne wska\u017aniki strukturalne odnosz\u0105ce si\u0119 do z\u0142o\u017cono\u015bci i zakresu ocen s\u0105 g\u0142\u00f3wnymi stosowanymi technikami).", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 26], [27, 38], [39, 46], [47, 50], [51, 59], [60, 70], [71, 72], [72, 80], [81, 89], [89, 90], [90, 91], [92, 95], [96, 97], [98, 107], [108, 109], [109, 116], [117, 124], [124, 125], [126, 133], [134, 142], [143, 153], [154, 158], [159, 164], [165, 174], [175, 187], [188, 197], [198, 201], [202, 204], [205, 215], [216, 217], [218, 225], [226, 230], [231, 233], [234, 242], [243, 254], [255, 265], [265, 266], [266, 267]]}
{"doc_key": "ai-test-231", "ner": [[3, 3, "organisation"], [11, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["W", "2018", "roku", "Toyota", "by\u0142a", "uwa\u017cana", "za", "b\u0119d\u0105c\u0105", "w", "tyle", "w", "Self-driving", "car", "i", "potrzebuj\u0105c\u0105", "innowacji", "."], "sentence-detokenized": "W 2018 roku Toyota by\u0142a uwa\u017cana za b\u0119d\u0105c\u0105 w tyle w Self-driving car i potrzebuj\u0105c\u0105 innowacji.", "token2charspan": [[0, 1], [2, 6], [7, 11], [12, 18], [19, 23], [24, 31], [32, 34], [35, 41], [42, 43], [44, 48], [49, 50], [51, 63], [64, 67], [68, 69], [70, 82], [83, 92], [92, 93]]}
{"doc_key": "ai-test-232", "ner": [[43, 44, "misc"], [48, 48, "misc"], [50, 53, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Do", "takich", "cel\u00f3w", "nale\u017c\u0105", "obiekty", "naturalne", ",", "takie", "jak", "ziemia", ",", "morze", ",", "opady", "atmosferyczne", "(", "takie", "jak", "deszcz", ",", "\u015bnieg", "lub", "grad", ")", ",", "burze", "piaskowe", ",", "zwierz\u0119ta", "(", "zw\u0142aszcza", "ptaki", ")", ",", "turbulencje", "atmosferyczne", "oraz", "inne", "efekty", "atmosferyczne", ",", "takie", "jak", "odbicia", "od", "jonosfery", ",", "smugi", "meteor\u00f3w", "i", "szpica", "rozproszenia", "trzech", "cia\u0142", "."], "sentence-detokenized": "Do takich cel\u00f3w nale\u017c\u0105 obiekty naturalne, takie jak ziemia, morze, opady atmosferyczne (takie jak deszcz, \u015bnieg lub grad), burze piaskowe, zwierz\u0119ta (zw\u0142aszcza ptaki), turbulencje atmosferyczne oraz inne efekty atmosferyczne, takie jak odbicia od jonosfery, smugi meteor\u00f3w i szpica rozproszenia trzech cia\u0142.", "token2charspan": [[0, 2], [3, 9], [10, 15], [16, 22], [23, 30], [31, 40], [40, 41], [42, 47], [48, 51], [52, 58], [58, 59], [60, 65], [65, 66], [67, 72], [73, 86], [87, 88], [88, 93], [94, 97], [98, 104], [104, 105], [106, 111], [112, 115], [116, 120], [120, 121], [121, 122], [123, 128], [129, 137], [137, 138], [139, 148], [149, 150], [150, 159], [160, 165], [165, 166], [166, 167], [168, 179], [180, 193], [194, 198], [199, 203], [204, 210], [211, 224], [224, 225], [226, 231], [232, 235], [236, 243], [244, 246], [247, 256], [256, 257], [258, 263], [264, 272], [273, 274], [275, 281], [282, 294], [295, 301], [302, 306], [306, 307]]}
{"doc_key": "ai-test-233", "ner": [[15, 15, "product"], [38, 38, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["W", "planowaniu", "i", "sterowaniu", "zasadnicza", "r\u00f3\u017cnica", "mi\u0119dzy", "humanoidami", "a", "innymi", "rodzajami", "robot\u00f3w", "(", "np", ".", "przemys\u0142owymi", ")", "polega", "na", "tym", ",", "\u017ce", "ruch", "robota", "musi", "by\u0107", "zbli\u017cony", "do", "ludzkiego", ",", "z", "wykorzystaniem", "lokomocji", "na", "nogach", ",", "zw\u0142aszcza", "chodu", "dwuno\u017cnego", "."], "sentence-detokenized": "W planowaniu i sterowaniu zasadnicza r\u00f3\u017cnica mi\u0119dzy humanoidami a innymi rodzajami robot\u00f3w (np. przemys\u0142owymi) polega na tym, \u017ce ruch robota musi by\u0107 zbli\u017cony do ludzkiego, z wykorzystaniem lokomocji na nogach, zw\u0142aszcza chodu dwuno\u017cnego.", "token2charspan": [[0, 1], [2, 12], [13, 14], [15, 25], [26, 36], [37, 44], [45, 51], [52, 63], [64, 65], [66, 72], [73, 82], [83, 90], [91, 92], [92, 94], [94, 95], [96, 109], [109, 110], [111, 117], [118, 120], [121, 124], [124, 125], [126, 128], [129, 133], [134, 140], [141, 145], [146, 149], [150, 158], [159, 161], [162, 171], [171, 172], [173, 174], [175, 189], [190, 199], [200, 202], [203, 209], [209, 210], [211, 220], [221, 226], [227, 237], [237, 238]]}
{"doc_key": "ai-test-234", "ner": [[0, 1, "algorithm"], [9, 10, "misc"], [13, 13, "metrics"], [16, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Zej\u015bcie", "gradientowe", "mo\u017ce", "zaj\u0105\u0107", "wiele", "iteracji", ",", "aby", "obliczy\u0107", "lokalne", "minimum", "z", "wymagan\u0105", "dok\u0142adno\u015bci\u0105", ",", "je\u015bli", "krzywizny", "w", "r\u00f3\u017cnych", "kierunkach", "s\u0105", "bardzo", "r\u00f3\u017cne", "dla", "danej", "funkcji", "."], "sentence-detokenized": "Zej\u015bcie gradientowe mo\u017ce zaj\u0105\u0107 wiele iteracji, aby obliczy\u0107 lokalne minimum z wymagan\u0105 dok\u0142adno\u015bci\u0105, je\u015bli krzywizny w r\u00f3\u017cnych kierunkach s\u0105 bardzo r\u00f3\u017cne dla danej funkcji.", "token2charspan": [[0, 7], [8, 19], [20, 24], [25, 30], [31, 36], [37, 45], [45, 46], [47, 50], [51, 59], [60, 67], [68, 75], [76, 77], [78, 86], [87, 99], [99, 100], [101, 106], [107, 116], [117, 118], [119, 126], [127, 137], [138, 140], [141, 147], [148, 153], [154, 157], [158, 163], [164, 171], [171, 172]]}
{"doc_key": "ai-test-235", "ner": [[0, 5, "misc"], [9, 9, "misc"], [14, 19, "conference"], [25, 26, "location"], [27, 28, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 5, 9, 9, "part-of", "", true, false], [14, 19, 25, 26, "physical", "", false, true], [25, 26, 27, 28, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["RoboCup", "2D", "Soccer", "Simulation", "League", "1997", "by\u0142", "pierwszym", "konkursem", "RoboCup", "promowanym", "w", "zwi\u0105zku", "z", "International", "Joint", "Conference", "on", "Artificial", "Intelligence", ",", "kt\u00f3ra", "odby\u0142a", "si\u0119", "w", "Nagoi", "w", "Japonii", "w", "dniach", "23", "-", "29", "sierpnia", "1997", "roku", "."], "sentence-detokenized": "RoboCup 2D Soccer Simulation League 1997 by\u0142 pierwszym konkursem RoboCup promowanym w zwi\u0105zku z International Joint Conference on Artificial Intelligence, kt\u00f3ra odby\u0142a si\u0119 w Nagoi w Japonii w dniach 23-29 sierpnia 1997 roku.", "token2charspan": [[0, 7], [8, 10], [11, 17], [18, 28], [29, 35], [36, 40], [41, 44], [45, 54], [55, 64], [65, 72], [73, 83], [84, 85], [86, 93], [94, 95], [96, 109], [110, 115], [116, 126], [127, 129], [130, 140], [141, 153], [153, 154], [155, 160], [161, 167], [168, 171], [172, 173], [174, 179], [180, 181], [182, 189], [190, 191], [192, 198], [199, 201], [201, 202], [202, 204], [205, 213], [214, 218], [219, 223], [223, 224]]}
{"doc_key": "ai-test-236", "ner": [[6, 6, "programlang"], [11, 11, "programlang"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Inne", "opcje", "programowania", "obejmuj\u0105", "wbudowane", "\u015brodowisko", "Python", ",", "a", "tak\u017ce", "konsol\u0119", "R", "oraz", "wsparcie", "dla", "Rserve", "."], "sentence-detokenized": "Inne opcje programowania obejmuj\u0105 wbudowane \u015brodowisko Python, a tak\u017ce konsol\u0119 R oraz wsparcie dla Rserve.", "token2charspan": [[0, 4], [5, 10], [11, 24], [25, 33], [34, 43], [44, 54], [55, 61], [61, 62], [63, 64], [65, 70], [71, 78], [79, 80], [81, 85], [86, 94], [95, 98], [99, 105], [105, 106]]}
{"doc_key": "ai-test-237", "ner": [[1, 1, "location"], [6, 7, "field"], [9, 9, "field"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"], [30, 30, "field"], [34, 35, "field"], [38, 39, "field"], [43, 45, "field"], [47, 50, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[12, 13, 9, 9, "related-to", "contributes_to_field", true, false], [15, 16, 9, 9, "related-to", "contributes_to_field", true, false], [18, 19, 9, 9, "related-to", "contributes_to_field", true, false], [38, 39, 34, 35, "part-of", "", false, false], [43, 45, 38, 39, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Z", "Bonn", "wni\u00f3s\u0142", "zasadniczy", "wk\u0142ad", "do", "sztucznej", "inteligencji", "i", "robotyki", "(", "z", "Wolframem", "Burgardem", ",", "Dieterem", "Foxem", ",", "Sebastianem", "Thrunem", "w\u015br\u00f3d", "swoich", "uczni\u00f3w", ")", ",", "a", "tak\u017ce", "do", "rozwoju", "in\u017cynierii", "oprogramowania", ",", "szczeg\u00f3lnie", "w", "in\u017cynierii", "l\u0105dowej", ",", "i", "system\u00f3w", "informacyjnych", ",", "szczeg\u00f3lnie", "w", "naukach", "geologicznych", ".", "zdoby\u0142", "nagrod\u0119", "AAAI", "Classic", "Paper", "z", "2016.2014", "."], "sentence-detokenized": "Z Bonn wni\u00f3s\u0142 zasadniczy wk\u0142ad do sztucznej inteligencji i robotyki (z Wolframem Burgardem, Dieterem Foxem, Sebastianem Thrunem w\u015br\u00f3d swoich uczni\u00f3w), a tak\u017ce do rozwoju in\u017cynierii oprogramowania, szczeg\u00f3lnie w in\u017cynierii l\u0105dowej, i system\u00f3w informacyjnych, szczeg\u00f3lnie w naukach geologicznych. zdoby\u0142 nagrod\u0119 AAAI Classic Paper z 2016.2014.", "token2charspan": [[0, 1], [2, 6], [7, 13], [14, 24], [25, 30], [31, 33], [34, 43], [44, 56], [57, 58], [59, 67], [68, 69], [69, 70], [71, 80], [81, 90], [90, 91], [92, 100], [101, 106], [106, 107], [108, 119], [120, 127], [128, 133], [134, 140], [141, 148], [148, 149], [149, 150], [151, 152], [153, 158], [159, 161], [162, 169], [170, 180], [181, 195], [195, 196], [197, 208], [209, 210], [211, 221], [222, 229], [229, 230], [231, 232], [233, 241], [242, 256], [256, 257], [258, 269], [270, 271], [272, 279], [280, 293], [293, 294], [295, 301], [302, 309], [310, 314], [315, 322], [323, 328], [329, 330], [331, 340], [340, 341]]}
{"doc_key": "ai-test-238", "ner": [[1, 7, "conference"], [14, 16, "location"], [17, 17, "location"], [20, 20, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 7, 14, 16, "physical", "", false, false], [14, 16, 17, 17, "physical", "", false, false], [17, 17, 20, 20, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Pierwsza", "ameryka\u0144ska", "edycja", "Campus", "Party", "odb\u0119dzie", "si\u0119", "w", "dniach", "20", "-", "22", "sierpnia", "w", "TCF", "Center", "w", "Detroit", "w", "stanie", "Michigan", "."], "sentence-detokenized": "Pierwsza ameryka\u0144ska edycja Campus Party odb\u0119dzie si\u0119 w dniach 20-22 sierpnia w TCF Center w Detroit w stanie Michigan.", "token2charspan": [[0, 8], [9, 20], [21, 27], [28, 34], [35, 40], [41, 49], [50, 53], [54, 55], [56, 62], [63, 65], [65, 66], [66, 68], [69, 77], [78, 79], [80, 83], [84, 90], [91, 92], [93, 100], [101, 102], [103, 109], [110, 118], [118, 119]]}
{"doc_key": "ai-test-239", "ner": [[2, 3, "researcher"], [6, 7, "researcher"], [9, 9, "researcher"], [12, 13, "misc"], [22, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 12, 13, "win-defeat", "", false, false], [6, 7, 12, 13, "win-defeat", "", false, false], [9, 9, 12, 13, "win-defeat", "", false, false], [12, 13, 22, 24, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Wraz", "z", "Yannem", "LeCunem", ",", "i", "Yoshua", "Bengio", ",", "Hinton", "zdoby\u0142", "2018", "Turing", "Award", "za", "koncepcyjne", "i", "in\u017cynieryjne", "prze\u0142omy", ",", "kt\u00f3re", "uczyni\u0142y", "g\u0142\u0119bokie", "sieci", "neuronowe", "krytycznym", "elementem", "oblicze\u0144", "."], "sentence-detokenized": "Wraz z Yannem LeCunem, i Yoshua Bengio, Hinton zdoby\u0142 2018 Turing Award za koncepcyjne i in\u017cynieryjne prze\u0142omy, kt\u00f3re uczyni\u0142y g\u0142\u0119bokie sieci neuronowe krytycznym elementem oblicze\u0144.", "token2charspan": [[0, 4], [5, 6], [7, 13], [14, 21], [21, 22], [23, 24], [25, 31], [32, 38], [38, 39], [40, 46], [47, 53], [54, 58], [59, 65], [66, 71], [72, 74], [75, 86], [87, 88], [89, 101], [102, 110], [110, 111], [112, 117], [118, 126], [127, 135], [136, 141], [142, 151], [152, 162], [163, 172], [173, 181], [181, 182]]}
{"doc_key": "ai-test-240", "ner": [[0, 2, "product"], [8, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 8, 8, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Euler", "Math", "Toolbox", "u\u017cywa", "j\u0119zyka", "macierzowego", "podobnego", "do", "MATLABa", ",", "systemu", ",", "nad", "kt\u00f3rym", "prace", "trwa\u0142y", "od", "lat", "70-tych", "."], "sentence-detokenized": "Euler Math Toolbox u\u017cywa j\u0119zyka macierzowego podobnego do MATLABa, systemu, nad kt\u00f3rym prace trwa\u0142y od lat 70-tych.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 24], [25, 31], [32, 44], [45, 54], [55, 57], [58, 65], [65, 66], [67, 74], [74, 75], [76, 79], [80, 86], [87, 92], [93, 99], [100, 102], [103, 106], [107, 114], [114, 115]]}
{"doc_key": "ai-test-241", "ner": [[8, 8, "programlang"], [10, 11, "programlang"], [13, 13, "programlang"], [15, 15, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Niekt\u00f3re", "j\u0119zyki", "umo\u017cliwiaj\u0105", "to", "przeno\u015bnie", "(", "np", ".", "Scheme", ",", "Common", "Lisp", ",", "Perl", "lub", "D", ")", "."], "sentence-detokenized": "Niekt\u00f3re j\u0119zyki umo\u017cliwiaj\u0105 to przeno\u015bnie (np. Scheme, Common Lisp, Perl lub D).", "token2charspan": [[0, 8], [9, 15], [16, 27], [28, 30], [31, 41], [42, 43], [43, 45], [45, 46], [47, 53], [53, 54], [55, 61], [62, 66], [66, 67], [68, 72], [73, 76], [77, 78], [78, 79], [79, 80]]}
{"doc_key": "ai-test-242", "ner": [[6, 6, "misc"], [8, 9, "researcher"], [11, 12, "researcher"], [24, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 8, 9, "artifact", "", false, false], [6, 6, 11, 12, "artifact", "", false, false], [6, 6, 24, 25, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["W", "1969", "roku", "w", "s\u0142ynnej", "ksi\u0105\u017cce", "Perceptrony", "autorstwa", "Marvina", "Minsky'ego", "i", "Seymoura", "Paperta", "wykazano", ",", "\u017ce", "dla", "tych", "klas", "sieci", "niemo\u017cliwe", "jest", "nauczenie", "si\u0119", "funkcji", "XOR", "."], "sentence-detokenized": "W 1969 roku w s\u0142ynnej ksi\u0105\u017cce Perceptrony autorstwa Marvina Minsky'ego i Seymoura Paperta wykazano, \u017ce dla tych klas sieci niemo\u017cliwe jest nauczenie si\u0119 funkcji XOR.", "token2charspan": [[0, 1], [2, 6], [7, 11], [12, 13], [14, 21], [22, 29], [30, 41], [42, 51], [52, 59], [60, 70], [71, 72], [73, 81], [82, 89], [90, 98], [98, 99], [100, 102], [103, 106], [107, 111], [112, 116], [117, 122], [123, 133], [134, 138], [139, 148], [149, 152], [153, 160], [161, 164], [164, 165]]}
{"doc_key": "ai-test-243", "ner": [[2, 6, "misc"], [11, 11, "product"], [14, 17, "organisation"], [20, 25, "organisation"], [28, 31, "location"], [33, 33, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 17, 11, 11, "usage", "", false, false], [14, 17, 28, 31, "physical", "", false, false], [20, 25, 14, 17, "named", "", false, false], [28, 31, 33, 33, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Du\u017ca", "liczba", "rosyjskich", "dokument\u00f3w", "naukowych", "i", "technicznych", "zosta\u0142a", "przet\u0142umaczona", "przy", "u\u017cyciu", "SYSTRANU", "pod", "auspicjami", "Wydzia\u0142u", "Technologii", "Zagranicznych", "USAF", "(", "p\u00f3\u017aniej", "National", "Air", "and", "Space", "Intelligence", "Center", ")", "w", "Wright-Patterson", "Air", "Force", "Base", ",", "Ohio", "."], "sentence-detokenized": "Du\u017ca liczba rosyjskich dokument\u00f3w naukowych i technicznych zosta\u0142a przet\u0142umaczona przy u\u017cyciu SYSTRANU pod auspicjami Wydzia\u0142u Technologii Zagranicznych USAF (p\u00f3\u017aniej National Air and Space Intelligence Center) w Wright-Patterson Air Force Base, Ohio.", "token2charspan": [[0, 4], [5, 11], [12, 22], [23, 33], [34, 43], [44, 45], [46, 58], [59, 66], [67, 81], [82, 86], [87, 93], [94, 102], [103, 106], [107, 117], [118, 126], [127, 138], [139, 152], [153, 157], [158, 159], [159, 166], [167, 175], [176, 179], [180, 183], [184, 189], [190, 202], [203, 209], [209, 210], [211, 212], [213, 229], [230, 233], [234, 239], [240, 244], [244, 245], [246, 250], [250, 251]]}
{"doc_key": "ai-test-244", "ner": [[0, 1, "field"], [5, 6, "field"], [7, 17, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Uczenie", "p\u00f3\u0142nadzorowane", "mie\u015bci", "si\u0119", "pomi\u0119dzy", "uczeniem", "bez", "nadzoru", "(", "bez", "\u017cadnych", "oznaczonych", "danych", "treningowych", ")", "a", "uczeniem", "nadzorowanym", "(", "z", "ca\u0142kowicie", "oznaczonymi", "danymi", "treningowymi", ")", "."], "sentence-detokenized": "Uczenie p\u00f3\u0142nadzorowane mie\u015bci si\u0119 pomi\u0119dzy uczeniem bez nadzoru (bez \u017cadnych oznaczonych danych treningowych) a uczeniem nadzorowanym (z ca\u0142kowicie oznaczonymi danymi treningowymi).", "token2charspan": [[0, 7], [8, 22], [23, 29], [30, 33], [34, 42], [43, 51], [52, 55], [56, 63], [64, 65], [65, 68], [69, 76], [77, 88], [89, 95], [96, 108], [108, 109], [110, 111], [112, 120], [121, 133], [134, 135], [135, 136], [137, 147], [148, 159], [160, 166], [167, 179], [179, 180], [180, 181]]}
{"doc_key": "ai-test-245", "ner": [[0, 3, "algorithm"], [6, 8, "algorithm"], [26, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 6, 8, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Ann", "-", "gram", "model", "jest", "rodzajem", "probabilistycznego", "modelu", "j\u0119zykowego", "s\u0142u\u017c\u0105cego", "do", "przewidywania", "nast\u0119pnego", "elementu", "w", "takiej", "sekwencji", "w", "postaci", "(", "n", "-", "1", ")", "-", "rz\u0119dowego", "modelu", "Markowa", ".", "efektywnie", "."], "sentence-detokenized": "Ann -gram model jest rodzajem probabilistycznego modelu j\u0119zykowego s\u0142u\u017c\u0105cego do przewidywania nast\u0119pnego elementu w takiej sekwencji w postaci (n - 1) -rz\u0119dowego modelu Markowa .efektywnie.", "token2charspan": [[0, 3], [4, 5], [5, 9], [10, 15], [16, 20], [21, 29], [30, 48], [49, 55], [56, 66], [67, 76], [77, 79], [80, 93], [94, 104], [105, 113], [114, 115], [116, 122], [123, 132], [133, 134], [135, 142], [143, 144], [144, 145], [146, 147], [148, 149], [149, 150], [151, 152], [152, 161], [162, 168], [169, 176], [177, 178], [178, 188], [188, 189]]}
{"doc_key": "ai-test-246", "ner": [[0, 2, "organisation"], [4, 4, "product"], [7, 14, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 4, 4, "usage", "", false, false], [7, 14, 0, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Klinika", "w", "Cleveland", "wykorzysta\u0142a", "Cyc", "do", "opracowania", "interfejsu", "zapyta\u0144", "w", "j\u0119zyku", "naturalnym", "o", "informacje", "biomedyczne", ",", "obejmuj\u0105ce", "dekady", "informacji", "o", "operacjach", "kardiochirurgicznych", "."], "sentence-detokenized": "Klinika w Cleveland wykorzysta\u0142a Cyc do opracowania interfejsu zapyta\u0144 w j\u0119zyku naturalnym o informacje biomedyczne, obejmuj\u0105ce dekady informacji o operacjach kardiochirurgicznych.", "token2charspan": [[0, 7], [8, 9], [10, 19], [20, 32], [33, 36], [37, 39], [40, 51], [52, 62], [63, 70], [71, 72], [73, 79], [80, 90], [91, 92], [93, 103], [104, 115], [115, 116], [117, 127], [128, 134], [135, 145], [146, 147], [148, 158], [159, 179], [179, 180]]}
{"doc_key": "ai-test-247", "ner": [[6, 6, "country"], [8, 9, "country"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 6, 8, 9, "opposite", "strained_relations", false, false]], "relations_mapping_to_source": [0], "sentence": ["Incydent", "ten", "nadwer\u0119\u017cy\u0142", "stosunki", "mi\u0119dzy", "Stanami", "Zjednoczonymi", "a", "Japoni\u0105", "i", "doprowadzi\u0142", "do", "aresztowania", "i", "postawienia", "przed", "s\u0105dem", "dw\u00f3ch", "cz\u0142onk\u00f3w", "zarz\u0105du", ",", "a", "tak\u017ce", "do", "na\u0142o\u017cenia", "na", "firm\u0119", "sankcji", "przez", "oba", "kraje", "."], "sentence-detokenized": "Incydent ten nadwer\u0119\u017cy\u0142 stosunki mi\u0119dzy Stanami Zjednoczonymi a Japoni\u0105 i doprowadzi\u0142 do aresztowania i postawienia przed s\u0105dem dw\u00f3ch cz\u0142onk\u00f3w zarz\u0105du, a tak\u017ce do na\u0142o\u017cenia na firm\u0119 sankcji przez oba kraje.", "token2charspan": [[0, 8], [9, 12], [13, 23], [24, 32], [33, 39], [40, 47], [48, 61], [62, 63], [64, 71], [72, 73], [74, 85], [86, 88], [89, 101], [102, 103], [104, 115], [116, 121], [122, 127], [128, 133], [134, 142], [143, 150], [150, 151], [152, 153], [154, 159], [160, 162], [163, 172], [173, 175], [176, 181], [182, 189], [190, 195], [196, 199], [200, 205], [205, 206]]}
{"doc_key": "ai-test-248", "ner": [[6, 8, "algorithm"], [11, 12, "field"], [18, 18, "misc"], [26, 26, "misc"], [30, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 8, 11, 12, "type-of", "", false, false], [18, 18, 11, 12, "part-of", "", true, false], [26, 26, 11, 12, "part-of", "", true, false], [30, 31, 11, 12, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Je\u015bli", "modelowanie", "odbywa", "si\u0119", "za", "pomoc\u0105", "sztucznej", "sieci", "neuronowej", "lub", "innego", "uczenia", "maszynowego", ",", "optymalizacja", "parametr\u00f3w", "nazywana", "jest", "treningiem", ",", "natomiast", "optymalizacja", "hiperparametr\u00f3w", "modelu", "nazywana", "jest", "strojeniem", "i", "cz\u0119sto", "wykorzystuje", "walidacj\u0119", "krzy\u017cow\u0105", ".", ".", "."], "sentence-detokenized": "Je\u015bli modelowanie odbywa si\u0119 za pomoc\u0105 sztucznej sieci neuronowej lub innego uczenia maszynowego, optymalizacja parametr\u00f3w nazywana jest treningiem, natomiast optymalizacja hiperparametr\u00f3w modelu nazywana jest strojeniem i cz\u0119sto wykorzystuje walidacj\u0119 krzy\u017cow\u0105...", "token2charspan": [[0, 5], [6, 17], [18, 24], [25, 28], [29, 31], [32, 38], [39, 48], [49, 54], [55, 65], [66, 69], [70, 76], [77, 84], [85, 96], [96, 97], [98, 111], [112, 122], [123, 131], [132, 136], [137, 147], [147, 148], [149, 158], [159, 172], [173, 188], [189, 195], [196, 204], [205, 209], [210, 220], [221, 222], [223, 229], [230, 242], [243, 252], [253, 261], [261, 262], [262, 263], [263, 264]]}
{"doc_key": "ai-test-249", "ner": [[6, 6, "country"], [8, 8, "country"], [10, 10, "country"], [15, 16, "organisation"], [18, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 16, 18, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Zlokalizowane", "wersje", "serwisu", "dost\u0119pne", "w", "Wielkiej", "Brytanii", ",", "Indiach", "i", "Australii", "zosta\u0142y", "wycofane", "po", "przej\u0119ciu", "Rotten", "Tomatoes", "przez", "Fandango", "."], "sentence-detokenized": "Zlokalizowane wersje serwisu dost\u0119pne w Wielkiej Brytanii, Indiach i Australii zosta\u0142y wycofane po przej\u0119ciu Rotten Tomatoes przez Fandango.", "token2charspan": [[0, 13], [14, 20], [21, 28], [29, 37], [38, 39], [40, 48], [49, 57], [57, 58], [59, 66], [67, 68], [69, 78], [79, 86], [87, 95], [96, 98], [99, 108], [109, 115], [116, 124], [125, 130], [131, 139], [139, 140]]}
{"doc_key": "ai-test-250", "ner": [[1, 1, "task"], [8, 8, "metrics"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 8, 8, "related-to", "", false, false], [8, 8, 23, 24, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Model", "NER", "jest", "jedn\u0105", "z", "wielu", "metod", "okre\u015blania", "dok\u0142adno\u015bci", "napis\u00f3w", "na", "\u017cywo", "w", "transmisjach", "telewizyjnych", "i", "wydarzeniach", ",", "kt\u00f3re", "s\u0105", "produkowane", "przy", "u\u017cyciu", "rozpoznawania", "mowy", "."], "sentence-detokenized": "Model NER jest jedn\u0105 z wielu metod okre\u015blania dok\u0142adno\u015bci napis\u00f3w na \u017cywo w transmisjach telewizyjnych i wydarzeniach, kt\u00f3re s\u0105 produkowane przy u\u017cyciu rozpoznawania mowy.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 20], [21, 22], [23, 28], [29, 34], [35, 45], [46, 57], [58, 65], [66, 68], [69, 73], [74, 75], [76, 88], [89, 102], [103, 104], [105, 117], [117, 118], [119, 124], [125, 127], [128, 139], [140, 144], [145, 151], [152, 165], [166, 170], [170, 171]]}
{"doc_key": "ai-test-251", "ner": [[0, 0, "researcher"], [3, 4, "university"], [6, 7, "university"], [9, 9, "location"], [11, 15, "university"], [17, 18, "university"], [20, 20, "location"], [22, 27, "university"], [29, 30, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 3, 4, "physical", "", false, false], [0, 0, 3, 4, "role", "", false, false], [0, 0, 6, 7, "physical", "", false, false], [0, 0, 6, 7, "role", "", false, false], [0, 0, 11, 15, "physical", "", false, false], [0, 0, 11, 15, "role", "", false, false], [0, 0, 17, 18, "physical", "", false, false], [0, 0, 17, 18, "role", "", false, false], [0, 0, 22, 27, "physical", "", false, false], [0, 0, 22, 27, "role", "", false, false], [6, 7, 9, 9, "physical", "", false, false], [11, 15, 20, 20, "physical", "", false, false], [17, 18, 20, 20, "physical", "", false, false], [22, 27, 29, 30, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Atran", "wyk\u0142ada\u0142", "na", "Uniwersytecie", "Cambridge", ",", "Uniwersytecie", "Hebrajskim", "w", "Jerozolimie", ",", "\u00c9cole", "pratique", "des", "hautes", "\u00e9tudes", "i", "\u00c9cole", "Polytechnique", "w", "Pary\u017cu", "oraz", "John", "Jay", "College", "of", "Criminal", "Justice", "w", "Nowym", "Jorku", "."], "sentence-detokenized": "Atran wyk\u0142ada\u0142 na Uniwersytecie Cambridge, Uniwersytecie Hebrajskim w Jerozolimie, \u00c9cole pratique des hautes \u00e9tudes i \u00c9cole Polytechnique w Pary\u017cu oraz John Jay College of Criminal Justice w Nowym Jorku.", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 31], [32, 41], [41, 42], [43, 56], [57, 67], [68, 69], [70, 81], [81, 82], [83, 88], [89, 97], [98, 101], [102, 108], [109, 115], [116, 117], [118, 123], [124, 137], [138, 139], [140, 146], [147, 151], [152, 156], [157, 160], [161, 168], [169, 171], [172, 180], [181, 188], [189, 190], [191, 196], [197, 202], [202, 203]]}
{"doc_key": "ai-test-252", "ner": [[0, 0, "product"], [6, 8, "task"], [12, 14, "researcher"], [15, 15, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 8, "origin", "", false, false], [0, 0, 6, 8, "related-to", "", false, false], [6, 8, 15, 15, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["SHRDLU", "by\u0142", "wczesnym", "programem", "komputerowym", "do", "rozumienia", "j\u0119zyka", "naturalnego", ",", "opracowanym", "przez", "Terry'ego", "Winograda", "w", "MIT", "w", "latach", "1968", "-", "1970"], "sentence-detokenized": "SHRDLU by\u0142 wczesnym programem komputerowym do rozumienia j\u0119zyka naturalnego, opracowanym przez Terry'ego Winograda w MIT w latach 1968-1970", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 29], [30, 42], [43, 45], [46, 56], [57, 63], [64, 75], [75, 76], [77, 88], [89, 94], [95, 104], [105, 114], [115, 116], [117, 120], [121, 122], [123, 129], [130, 134], [134, 135], [135, 139]]}
{"doc_key": "ai-test-253", "ner": [[2, 5, "misc"], [8, 9, "field"], [11, 17, "university"], [18, 19, "location"], [20, 21, "country"], [32, 34, "university"], [35, 38, "misc"], [41, 45, "field"], [50, 52, "university"], [53, 56, "misc"], [59, 60, "field"], [67, 71, "misc"], [77, 80, "university"], [84, 85, "field"], [89, 90, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "relations": [[2, 5, 8, 9, "topic", "", false, false], [2, 5, 11, 17, "origin", "", false, false], [11, 17, 18, 19, "physical", "", false, false], [11, 17, 32, 34, "role", "affiliated_with", false, false], [18, 19, 20, 21, "physical", "", false, false], [35, 38, 41, 45, "topic", "", false, false], [35, 38, 50, 52, "origin", "", false, false], [53, 56, 59, 60, "topic", "", false, false], [67, 71, 77, 80, "origin", "", false, false], [67, 71, 84, 85, "topic", "", false, false], [89, 90, 77, 80, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Otrzyma\u0142", "tytu\u0142", "B", ".", "E", ".", "w", "dziedzinie", "in\u017cynierii", "elektronicznej", "w", "B.M", ".S", ".", "College", "of", "Engineering", "w", "Bangalore", "w", "Indiach", "w", "1982", "roku", ",", "kiedy", "by\u0142", "on", "powi\u0105zany", "z", "Uniwersytetem", "w", "Bangalore", ",", "tytu\u0142", "M", ".", "S", ".", "w", "dziedzinie", "in\u017cynierii", "elektrycznej", "i", "komputerowej", "w", "1984", "roku", "na", "Uniwersytecie", "Drexel", "oraz", "tytu\u0142", "M", ".", "S", ".", "w", "dziedzinie", "informatyki", "w", "1989", "roku", ",", "a", "tak\u017ce", "tytu\u0142", "Ph", ".", "D", ".", "w", "1990", "roku", ",", "odpowiednio", "na", "Uniwersytecie", "Wisconsin", "-", "Madison", ",", "gdzie", "studiowa\u0142", "sztuczn\u0105", "inteligencj\u0119", "i", "pracowa\u0142", "z", "Leonardem", "Uhr", "."], "sentence-detokenized": "Otrzyma\u0142 tytu\u0142 B.E. w dziedzinie in\u017cynierii elektronicznej w B.M.S. College of Engineering w Bangalore w Indiach w 1982 roku, kiedy by\u0142 on powi\u0105zany z Uniwersytetem w Bangalore, tytu\u0142 M.S. w dziedzinie in\u017cynierii elektrycznej i komputerowej w 1984 roku na Uniwersytecie Drexel oraz tytu\u0142 M.S. w dziedzinie informatyki w 1989 roku, a tak\u017ce tytu\u0142 Ph.D. w 1990 roku, odpowiednio na Uniwersytecie Wisconsin-Madison, gdzie studiowa\u0142 sztuczn\u0105 inteligencj\u0119 i pracowa\u0142 z Leonardem Uhr.", "token2charspan": [[0, 8], [9, 14], [15, 16], [16, 17], [17, 18], [18, 19], [20, 21], [22, 32], [33, 43], [44, 58], [59, 60], [61, 64], [64, 66], [66, 67], [68, 75], [76, 78], [79, 90], [91, 92], [93, 102], [103, 104], [105, 112], [113, 114], [115, 119], [120, 124], [124, 125], [126, 131], [132, 135], [136, 138], [139, 148], [149, 150], [151, 164], [165, 166], [167, 176], [176, 177], [178, 183], [184, 185], [185, 186], [186, 187], [187, 188], [189, 190], [191, 201], [202, 212], [213, 225], [226, 227], [228, 240], [241, 242], [243, 247], [248, 252], [253, 255], [256, 269], [270, 276], [277, 281], [282, 287], [288, 289], [289, 290], [290, 291], [291, 292], [293, 294], [295, 305], [306, 317], [318, 319], [320, 324], [325, 329], [329, 330], [331, 332], [333, 338], [339, 344], [345, 347], [347, 348], [348, 349], [349, 350], [351, 352], [353, 357], [358, 362], [362, 363], [364, 375], [376, 378], [379, 392], [393, 402], [402, 403], [403, 410], [410, 411], [412, 417], [418, 427], [428, 436], [437, 449], [450, 451], [452, 460], [461, 462], [463, 472], [473, 476], [476, 477]]}
{"doc_key": "ai-test-254", "ner": [[7, 8, "metrics"], [10, 10, "metrics"], [6, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 7, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Dok\u0142adno\u015b\u0107", "jest", "zwykle", "oceniana", "za", "pomoc\u0105", "wsp\u00f3\u0142czynnika", "b\u0142\u0119du", "s\u0142owa", "(", "WER", ")", ",", "natomiast", "szybko\u015b\u0107", "jest", "mierzona", "za", "pomoc\u0105", "wsp\u00f3\u0142czynnika", "czasu", "rzeczywistego", "."], "sentence-detokenized": "Dok\u0142adno\u015b\u0107 jest zwykle oceniana za pomoc\u0105 wsp\u00f3\u0142czynnika b\u0142\u0119du s\u0142owa (WER), natomiast szybko\u015b\u0107 jest mierzona za pomoc\u0105 wsp\u00f3\u0142czynnika czasu rzeczywistego.", "token2charspan": [[0, 10], [11, 15], [16, 22], [23, 31], [32, 34], [35, 41], [42, 55], [56, 61], [62, 67], [68, 69], [69, 72], [72, 73], [73, 74], [75, 84], [85, 93], [94, 98], [99, 107], [108, 110], [111, 117], [118, 131], [132, 137], [138, 151], [151, 152]]}
{"doc_key": "ai-test-255", "ner": [[3, 4, "researcher"], [8, 10, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 8, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["W", "1971", "roku", "Terry", "Winograd", "opracowa\u0142", "wczesny", "silnik", "przetwarzania", "j\u0119zyka", "naturalnego", "zdolny", "do", "interpretowania", "naturalnie", "napisanych", "polece\u0144", "w", "ramach", "prostego", "\u015brodowiska", "rz\u0105dzonego", "regu\u0142ami", "."], "sentence-detokenized": "W 1971 roku Terry Winograd opracowa\u0142 wczesny silnik przetwarzania j\u0119zyka naturalnego zdolny do interpretowania naturalnie napisanych polece\u0144 w ramach prostego \u015brodowiska rz\u0105dzonego regu\u0142ami.", "token2charspan": [[0, 1], [2, 6], [7, 11], [12, 17], [18, 26], [27, 36], [37, 44], [45, 51], [52, 65], [66, 72], [73, 84], [85, 91], [92, 94], [95, 110], [111, 121], [122, 132], [133, 140], [141, 142], [143, 149], [150, 158], [159, 169], [170, 180], [181, 189], [189, 190]]}
{"doc_key": "ai-test-256", "ner": [[1, 2, "field"], [5, 6, "researcher"], [8, 14, "researcher"], [13, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 2, 5, 6, "related-to", "", false, false], [1, 2, 8, 14, "related-to", "", false, false], [1, 2, 13, 14, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["W", "sztucznej", "inteligencji", "wyr\u00f3\u017cniaj\u0105", "si\u0119", "Marvin", "Minsky", ",", "Herbert", "A", ".", "Simon", "i", "Allen", "Newell", "."], "sentence-detokenized": "W sztucznej inteligencji wyr\u00f3\u017cniaj\u0105 si\u0119 Marvin Minsky, Herbert A. Simon i Allen Newell.", "token2charspan": [[0, 1], [2, 11], [12, 24], [25, 35], [36, 39], [40, 46], [47, 53], [53, 54], [55, 62], [63, 64], [64, 65], [66, 71], [72, 73], [74, 79], [80, 86], [86, 87]]}
{"doc_key": "ai-test-257", "ner": [[6, 7, "field"], [26, 26, "field"], [29, 29, "field"], [36, 36, "field"], [45, 48, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[26, 26, 6, 7, "origin", "", true, false], [26, 26, 6, 7, "part-of", "", false, false], [26, 26, 36, 36, "compare", "", false, false], [29, 29, 6, 7, "origin", "", true, false], [29, 29, 6, 7, "part-of", "", false, false], [29, 29, 36, 36, "compare", "", false, false], [36, 36, 6, 7, "origin", "", true, false], [36, 36, 6, 7, "part-of", "", false, false], [36, 36, 45, 48, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["W", "drugiej", "po\u0142owie", "XX", "wieku", "sama", "in\u017cynieria", "elektryczna", "rozdzieli\u0142a", "si\u0119", "na", "kilka", "dyscyplin", ",", "specjalizuj\u0105cych", "si\u0119", "w", "projektowaniu", "i", "analizie", "system\u00f3w", "manipuluj\u0105cych", "sygna\u0142ami", "fizycznymi", ";", "in\u017cynieria", "elektroniczna", "i", "in\u017cynieria", "komputerowa", "jako", "przyk\u0142ady", ";", "podczas", "gdy", "in\u017cynieria", "projektowa", "rozwin\u0119\u0142a", "si\u0119", ",", "aby", "zaj\u0105\u0107", "si\u0119", "funkcjonalnym", "projektowaniem", "interfejs\u00f3w", "u\u017cytkownika", "-", "maszyny", "."], "sentence-detokenized": "W drugiej po\u0142owie XX wieku sama in\u017cynieria elektryczna rozdzieli\u0142a si\u0119 na kilka dyscyplin, specjalizuj\u0105cych si\u0119 w projektowaniu i analizie system\u00f3w manipuluj\u0105cych sygna\u0142ami fizycznymi; in\u017cynieria elektroniczna i in\u017cynieria komputerowa jako przyk\u0142ady; podczas gdy in\u017cynieria projektowa rozwin\u0119\u0142a si\u0119, aby zaj\u0105\u0107 si\u0119 funkcjonalnym projektowaniem interfejs\u00f3w u\u017cytkownika-maszyny.", "token2charspan": [[0, 1], [2, 9], [10, 17], [18, 20], [21, 26], [27, 31], [32, 42], [43, 54], [55, 66], [67, 70], [71, 73], [74, 79], [80, 89], [89, 90], [91, 107], [108, 111], [112, 113], [114, 127], [128, 129], [130, 138], [139, 147], [148, 162], [163, 172], [173, 183], [183, 184], [185, 195], [196, 209], [210, 211], [212, 222], [223, 234], [235, 239], [240, 249], [249, 250], [251, 258], [259, 262], [263, 273], [274, 284], [285, 294], [295, 298], [298, 299], [300, 303], [304, 309], [310, 313], [314, 327], [328, 342], [343, 354], [355, 366], [366, 367], [367, 374], [374, 375]]}
{"doc_key": "ai-test-258", "ner": [[5, 5, "metrics"], [7, 8, "metrics"], [10, 10, "metrics"], [39, 41, "metrics"], [50, 50, "metrics"], [58, 60, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 10, 7, 8, "named", "", false, false], [39, 41, 50, 50, "named", "", false, false], [50, 50, 58, 60, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["By\u0107", "mo\u017ce", "najprostsz\u0105", "statystyk\u0105", "jest", "dok\u0142adno\u015b\u0107", "lub", "Frakcja", "Poprawna", "(", "FC", ")", ",", "kt\u00f3ra", "mierzy", "frakcj\u0119", "wszystkich", "instancji", ",", "kt\u00f3re", "s\u0105", "poprawnie", "skategoryzowane", ";", "jest", "to", "stosunek", "liczby", "poprawnych", "klasyfikacji", "do", "ca\u0142kowitej", "liczby", "poprawnych", "lub", "niepoprawnych", "klasyfikacji", ":", "(", "TP", "+", "TN", ")", "/", "Ca\u0142kowita", "Populacja", "=", "(", "TP", "+", "TN", ")", "/", "(", "TP", "+", "TN", "+", "FP", "+", "FN", ")", "."], "sentence-detokenized": "By\u0107 mo\u017ce najprostsz\u0105 statystyk\u0105 jest dok\u0142adno\u015b\u0107 lub Frakcja Poprawna (FC), kt\u00f3ra mierzy frakcj\u0119 wszystkich instancji, kt\u00f3re s\u0105 poprawnie skategoryzowane; jest to stosunek liczby poprawnych klasyfikacji do ca\u0142kowitej liczby poprawnych lub niepoprawnych klasyfikacji: (TP + TN) / Ca\u0142kowita Populacja = (TP + TN) / (TP + TN + FP + FN).", "token2charspan": [[0, 3], [4, 8], [9, 20], [21, 31], [32, 36], [37, 47], [48, 51], [52, 59], [60, 68], [69, 70], [70, 72], [72, 73], [73, 74], [75, 80], [81, 87], [88, 95], [96, 106], [107, 116], [116, 117], [118, 123], [124, 126], [127, 136], [137, 152], [152, 153], [154, 158], [159, 161], [162, 170], [171, 177], [178, 188], [189, 201], [202, 204], [205, 215], [216, 222], [223, 233], [234, 237], [238, 251], [252, 264], [264, 265], [266, 267], [267, 269], [270, 271], [272, 274], [274, 275], [276, 277], [278, 287], [288, 297], [298, 299], [300, 301], [301, 303], [304, 305], [306, 308], [308, 309], [310, 311], [312, 313], [313, 315], [316, 317], [318, 320], [321, 322], [323, 325], [326, 327], [328, 330], [330, 331], [331, 332]]}
{"doc_key": "ai-test-259", "ner": [[21, 28, "conference"], [30, 32, "conference"], [16, 16, "location"], [19, 19, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 28, 16, 16, "physical", "", false, false], [30, 32, 21, 28, "named", "", false, false], [19, 19, 21, 28, "role", "sponsors", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["W", "\u015brodowisku", "akademickim", "g\u0142\u00f3wne", "fora", "dla", "bada\u0144", "rozpocz\u0119\u0142y", "si\u0119", "w", "1995", "roku", ",", "kiedy", "to", "w", "Montrealu", "pod", "patronatem", "AAAI", "rozpocz\u0119to", "pierwsz\u0105", "mi\u0119dzynarodow\u0105", "konferencj\u0119", "Data", "Mining", "and", "Knowledge", "Discovery", "(", "KDD", "-", "95", ")", "."], "sentence-detokenized": "W \u015brodowisku akademickim g\u0142\u00f3wne fora dla bada\u0144 rozpocz\u0119\u0142y si\u0119 w 1995 roku, kiedy to w Montrealu pod patronatem AAAI rozpocz\u0119to pierwsz\u0105 mi\u0119dzynarodow\u0105 konferencj\u0119 Data Mining and Knowledge Discovery (KDD-95).", "token2charspan": [[0, 1], [2, 12], [13, 24], [25, 31], [32, 36], [37, 40], [41, 46], [47, 57], [58, 61], [62, 63], [64, 68], [69, 73], [73, 74], [75, 80], [81, 83], [84, 85], [86, 95], [96, 99], [100, 110], [111, 115], [116, 126], [127, 135], [136, 150], [151, 162], [163, 167], [168, 174], [175, 178], [179, 188], [189, 198], [199, 200], [200, 203], [203, 204], [204, 206], [206, 207], [207, 208]]}
{"doc_key": "ai-test-260", "ner": [[12, 12, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["W", "tym", "podej\u015bciu", ",", "modele", "s\u0105", "opracowywane", "przy", "u\u017cyciu", "r\u00f3\u017cnych", "algorytm\u00f3w", "eksploracji", "danych", ",", "uczenia", "maszynowego", ",", "aby", "przewidzie\u0107", "ocen\u0119", "u\u017cytkownik\u00f3w", "dla", "nieocenionych", "element\u00f3w", "."], "sentence-detokenized": "W tym podej\u015bciu, modele s\u0105 opracowywane przy u\u017cyciu r\u00f3\u017cnych algorytm\u00f3w eksploracji danych, uczenia maszynowego, aby przewidzie\u0107 ocen\u0119 u\u017cytkownik\u00f3w dla nieocenionych element\u00f3w.", "token2charspan": [[0, 1], [2, 5], [6, 15], [15, 16], [17, 23], [24, 26], [27, 39], [40, 44], [45, 51], [52, 59], [60, 70], [71, 82], [83, 89], [89, 90], [91, 98], [99, 110], [110, 111], [112, 115], [116, 127], [128, 133], [134, 146], [147, 150], [151, 164], [165, 174], [174, 175]]}
{"doc_key": "ai-test-261", "ner": [[8, 8, "algorithm"], [11, 12, "algorithm"], [14, 15, "algorithm"], [21, 22, "misc"], [25, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 8, 11, 12, "related-to", "equivalent", false, false], [11, 12, 14, 15, "usage", "", false, false], [14, 15, 25, 25, "usage", "", false, false], [25, 25, 21, 22, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["W", "\u015bwietle", "powy\u017cszej", "dyskusji", "widzimy", ",", "\u017ce", "technika", "SVM", "jest", "r\u00f3wnowa\u017cna", "ryzyku", "empirycznemu", "z", "regularyzacj\u0105", "Tichonowa", ",", "gdzie", "w", "tym", "przypadku", "funkcj\u0105", "straty", "jest", "strata", "zawiasowa"], "sentence-detokenized": "W \u015bwietle powy\u017cszej dyskusji widzimy, \u017ce technika SVM jest r\u00f3wnowa\u017cna ryzyku empirycznemu z regularyzacj\u0105 Tichonowa, gdzie w tym przypadku funkcj\u0105 straty jest strata zawiasowa", "token2charspan": [[0, 1], [2, 9], [10, 19], [20, 28], [29, 36], [36, 37], [38, 40], [41, 49], [50, 53], [54, 58], [59, 69], [70, 76], [77, 89], [90, 91], [92, 105], [106, 115], [115, 116], [117, 122], [123, 124], [125, 128], [129, 138], [139, 146], [147, 153], [154, 158], [159, 165], [166, 175]]}
{"doc_key": "ai-test-262", "ner": [[4, 5, "person"], [9, 10, "person"], [14, 14, "organisation"], [15, 16, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 16, 14, 14, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Gospodarzem", "edycji", "2015", "by\u0142a", "Molly", "McGrath", ",", "a", "komentatorami", "Chris", "Rose", "i", "by\u0142y", "zawodnik", "UFC", "Kenny", "Florian", "."], "sentence-detokenized": "Gospodarzem edycji 2015 by\u0142a Molly McGrath, a komentatorami Chris Rose i by\u0142y zawodnik UFC Kenny Florian.", "token2charspan": [[0, 11], [12, 18], [19, 23], [24, 28], [29, 34], [35, 42], [42, 43], [44, 45], [46, 59], [60, 65], [66, 70], [71, 72], [73, 77], [78, 86], [87, 90], [91, 96], [97, 104], [104, 105]]}
{"doc_key": "ai-test-263", "ner": [[2, 2, "product"], [6, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [15, 15, "researcher"], [20, 20, "researcher"], [30, 30, "researcher"], [27, 29, "task"], [31, 33, "product"], [34, 35, "researcher"], [38, 38, "task"], [41, 42, "researcher"], [44, 46, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[2, 2, 6, 8, "origin", "", false, false], [2, 2, 10, 11, "origin", "", false, false], [2, 2, 13, 14, "origin", "", false, false], [2, 2, 15, 15, "origin", "", false, false], [10, 11, 34, 35, "named", "same", false, false], [13, 14, 20, 20, "named", "same", false, false], [13, 14, 30, 30, "named", "same", false, false], [27, 29, 31, 33, "related-to", "", false, false], [31, 33, 30, 30, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Podzbi\u00f3r", "nazwany", "Micro-Planner", "zosta\u0142", "zaimplementowany", "przez", "Geralda", "Jaya", "Sussmana", ",", "Eugene'a", "Charniaka", "i", "Terry'ego", "Winograda", "Sussman", ",", ",", ",", "i", "Winograda", "1971", "i", "zosta\u0142", "wykorzystany", "w", "programie", "rozumienia", "j\u0119zyka", "naturalnego", "Winograda", "SHRDLU", ",", "pracy", "Eugene'a", "Charniaka", "nad", "rozumieniem", "opowie\u015bci", ",", "pracy", "Thorne'a", "McCarty'ego", "nad", "rozumowaniem", "prawniczym", "i", "kilku", "innych", "projektach", "."], "sentence-detokenized": "Podzbi\u00f3r nazwany Micro-Planner zosta\u0142 zaimplementowany przez Geralda Jaya Sussmana, Eugene'a Charniaka i Terry'ego Winograda Sussman,,, i Winograda 1971 i zosta\u0142 wykorzystany w programie rozumienia j\u0119zyka naturalnego Winograda SHRDLU, pracy Eugene'a Charniaka nad rozumieniem opowie\u015bci, pracy Thorne'a McCarty'ego nad rozumowaniem prawniczym i kilku innych projektach.", "token2charspan": [[0, 8], [9, 16], [17, 30], [31, 37], [38, 54], [55, 60], [61, 68], [69, 73], [74, 82], [82, 83], [84, 92], [93, 102], [103, 104], [105, 114], [115, 124], [125, 132], [132, 133], [133, 134], [134, 135], [136, 137], [138, 147], [148, 152], [153, 154], [155, 161], [162, 174], [175, 176], [177, 186], [187, 197], [198, 204], [205, 216], [217, 226], [227, 233], [233, 234], [235, 240], [241, 249], [250, 259], [260, 263], [264, 275], [276, 285], [285, 286], [287, 292], [293, 301], [302, 313], [314, 317], [318, 330], [331, 341], [342, 343], [344, 349], [350, 356], [357, 367], [367, 368]]}
{"doc_key": "ai-test-264", "ner": [[0, 0, "product"], [7, 8, "product"], [13, 13, "task"], [16, 17, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "task"], [31, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[7, 8, 0, 0, "usage", "", true, false], [13, 13, 7, 8, "part-of", "", true, false], [16, 17, 7, 8, "part-of", "", true, false], [20, 21, 7, 8, "part-of", "", true, false], [23, 24, 7, 8, "part-of", "", true, false], [26, 27, 7, 8, "part-of", "", true, false], [31, 33, 7, 8, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["WordNet", "zosta\u0142", "wykorzystany", "do", "wielu", "cel\u00f3w", "w", "systemach", "informacyjnych", ",", "w", "tym", "do", "dezambiguacji", "s\u0142owotw\u00f3rczej", ",", "wyszukiwania", "informacji", ",", "automatycznej", "klasyfikacji", "tekstu", ",", "automatycznego", "streszczania", ",", "t\u0142umaczenia", "maszynowego", ",", "a", "nawet", "automatycznego", "generowania", "krzy\u017c\u00f3wek", "."], "sentence-detokenized": "WordNet zosta\u0142 wykorzystany do wielu cel\u00f3w w systemach informacyjnych, w tym do dezambiguacji s\u0142owotw\u00f3rczej, wyszukiwania informacji, automatycznej klasyfikacji tekstu, automatycznego streszczania, t\u0142umaczenia maszynowego, a nawet automatycznego generowania krzy\u017c\u00f3wek.", "token2charspan": [[0, 7], [8, 14], [15, 27], [28, 30], [31, 36], [37, 42], [43, 44], [45, 54], [55, 69], [69, 70], [71, 72], [73, 76], [77, 79], [80, 93], [94, 107], [107, 108], [109, 121], [122, 132], [132, 133], [134, 147], [148, 160], [161, 167], [167, 168], [169, 183], [184, 196], [196, 197], [198, 209], [210, 221], [221, 222], [223, 224], [225, 230], [231, 245], [246, 257], [258, 267], [267, 268]]}
{"doc_key": "ai-test-265", "ner": [[0, 0, "researcher"], [6, 6, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 6, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Keutzer", "otrzyma\u0142", "tytu\u0142", "Fellow", "of", "the", "IEEE", "w", "1996", "roku", "."], "sentence-detokenized": "Keutzer otrzyma\u0142 tytu\u0142 Fellow of the IEEE w 1996 roku.", "token2charspan": [[0, 7], [8, 16], [17, 22], [23, 29], [30, 32], [33, 36], [37, 41], [42, 43], [44, 48], [49, 53], [53, 54]]}
{"doc_key": "ai-test-266", "ner": [[5, 7, "algorithm"], [45, 46, "misc"], [55, 56, "algorithm"], [59, 59, "algorithm"], [62, 62, "algorithm"], [65, 65, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[55, 56, 45, 46, "type-of", "", false, false], [59, 59, 45, 46, "type-of", "", false, false], [62, 62, 45, 46, "type-of", "", false, false], [65, 65, 45, 46, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Szeroko", "stosowanym", "typem", "kompozycji", "jest", "nieliniowa", "suma", "wa\u017cona", ",", "gdzie", "matematyka", "f", "(", "x", ")", "=", "K", "lewo", "(", "suma", "_", "i", "w", "_", "i", "g", "_", "i", "(", "x", ")", "\u0105", "prawo", ")", "/", "matematyka", ",", "gdzie", "matematyka", "K", "/", "matematyka", "(", "potocznie", "nazywana", "funkcj\u0105", "aktywacji", ")", "jest", "jak\u0105\u015b", "predefiniowan\u0105", "funkcj\u0105", ",", "tak\u0105", "jak", "tangens", "hiperboliczny", ",", "funkcja", "sigmoidalna", ",", "funkcja", "softmax", "lub", "funkcja", "prostownika", "."], "sentence-detokenized": "Szeroko stosowanym typem kompozycji jest nieliniowa suma wa\u017cona, gdzie matematyka f (x) = K lewo (suma _ i w _ i g _ i (x)\u0105 prawo) / matematyka, gdzie matematyka K / matematyka (potocznie nazywana funkcj\u0105 aktywacji) jest jak\u0105\u015b predefiniowan\u0105 funkcj\u0105, tak\u0105 jak tangens hiperboliczny, funkcja sigmoidalna, funkcja softmax lub funkcja prostownika.", "token2charspan": [[0, 7], [8, 18], [19, 24], [25, 35], [36, 40], [41, 51], [52, 56], [57, 63], [63, 64], [65, 70], [71, 81], [82, 83], [84, 85], [85, 86], [86, 87], [88, 89], [90, 91], [92, 96], [97, 98], [98, 102], [103, 104], [105, 106], [107, 108], [109, 110], [111, 112], [113, 114], [115, 116], [117, 118], [119, 120], [120, 121], [121, 122], [122, 123], [124, 129], [129, 130], [131, 132], [133, 143], [143, 144], [145, 150], [151, 161], [162, 163], [164, 165], [166, 176], [177, 178], [178, 187], [188, 196], [197, 204], [205, 214], [214, 215], [216, 220], [221, 226], [227, 241], [242, 249], [249, 250], [251, 255], [256, 259], [260, 267], [268, 281], [281, 282], [283, 290], [291, 302], [302, 303], [304, 311], [312, 319], [320, 323], [324, 331], [332, 343], [343, 344]]}
{"doc_key": "ai-test-267", "ner": [[2, 2, "misc"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["W", "filmie", "Westworld", ",", "\u017ce\u0144skie", "roboty", "rzeczywi\u015bcie", "zaanga\u017cowa\u0142y", "si\u0119", "w", "stosunek", "p\u0142ciowy", "z", "ludzkimi", "m\u0119\u017cczyznami", ",", "jako", "cz\u0119\u015b\u0107", "fa\u0142szywego", "\u015bwiata", "wakacji", ",", "za", "kt\u00f3re", "p\u0142acili", "ludzcy", "klienci", "."], "sentence-detokenized": "W filmie Westworld, \u017ce\u0144skie roboty rzeczywi\u015bcie zaanga\u017cowa\u0142y si\u0119 w stosunek p\u0142ciowy z ludzkimi m\u0119\u017cczyznami, jako cz\u0119\u015b\u0107 fa\u0142szywego \u015bwiata wakacji, za kt\u00f3re p\u0142acili ludzcy klienci.", "token2charspan": [[0, 1], [2, 8], [9, 18], [18, 19], [20, 27], [28, 34], [35, 47], [48, 60], [61, 64], [65, 66], [67, 75], [76, 83], [84, 85], [86, 94], [95, 106], [106, 107], [108, 112], [113, 118], [119, 129], [130, 136], [137, 144], [144, 145], [146, 148], [149, 154], [155, 162], [163, 169], [170, 177], [177, 178]]}
{"doc_key": "ai-test-268", "ner": [[5, 6, "task"], [21, 22, "task"], [25, 25, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 21, 22, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Zazwyczaj", "proces", "rozpoczyna", "si\u0119", "od", "ekstrakcji", "terminologii", "i", "poj\u0119\u0107", "lub", "fraz", "rzeczownikowych", "ze", "zwyk\u0142ego", "tekstu", "przy", "u\u017cyciu", "procesor\u00f3w", "lingwistycznych", "takich", "jak", "part-of-speech", "tagging", "i", "phrase", "chunking", "."], "sentence-detokenized": "Zazwyczaj proces rozpoczyna si\u0119 od ekstrakcji terminologii i poj\u0119\u0107 lub fraz rzeczownikowych ze zwyk\u0142ego tekstu przy u\u017cyciu procesor\u00f3w lingwistycznych takich jak part-of-speech tagging i phrase chunking.", "token2charspan": [[0, 9], [10, 16], [17, 27], [28, 31], [32, 34], [35, 45], [46, 58], [59, 60], [61, 66], [67, 70], [71, 75], [76, 91], [92, 94], [95, 103], [104, 110], [111, 115], [116, 122], [123, 133], [134, 149], [150, 156], [157, 160], [161, 175], [176, 183], [184, 185], [186, 192], [193, 201], [201, 202]]}
{"doc_key": "ai-test-269", "ner": [[8, 9, "field"], [14, 16, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 16, 8, 9, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0], "sentence": ["Zademonstrowali", "jego", "dzia\u0142anie", "na", "szeregu", "problem\u00f3w", "interesuj\u0105cych", "spo\u0142eczno\u015b\u0107", "uczenia", "maszynowego", ",", "w", "tym", "na", "rozpoznawaniu", "pisma", "r\u0119cznego", "."], "sentence-detokenized": "Zademonstrowali jego dzia\u0142anie na szeregu problem\u00f3w interesuj\u0105cych spo\u0142eczno\u015b\u0107 uczenia maszynowego, w tym na rozpoznawaniu pisma r\u0119cznego.", "token2charspan": [[0, 15], [16, 20], [21, 30], [31, 33], [34, 41], [42, 51], [52, 66], [67, 78], [79, 86], [87, 98], [98, 99], [100, 101], [102, 105], [106, 108], [109, 122], [123, 128], [129, 137], [137, 138]]}
{"doc_key": "ai-test-270", "ner": [[3, 3, "university"], [4, 4, "researcher"], [9, 10, "researcher"], [13, 13, "product"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 3, 3, "physical", "", false, false], [4, 4, 3, 3, "role", "", false, false], [13, 13, 9, 10, "origin", "", false, false], [13, 13, 16, 17, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Podczas", "studi\u00f3w", "na", "Stanfordzie", "Scheinman", "otrzyma\u0142", "stypendium", "sponsorowane", "przez", "George'a", "Devola", ",", "wynalazc\u0119", "Unimate", ",", "pierwszego", "robota", "przemys\u0142owego", "."], "sentence-detokenized": "Podczas studi\u00f3w na Stanfordzie Scheinman otrzyma\u0142 stypendium sponsorowane przez George'a Devola, wynalazc\u0119 Unimate, pierwszego robota przemys\u0142owego.", "token2charspan": [[0, 7], [8, 15], [16, 18], [19, 30], [31, 40], [41, 49], [50, 60], [61, 73], [74, 79], [80, 88], [89, 95], [95, 96], [97, 106], [107, 114], [114, 115], [116, 126], [127, 133], [134, 147], [147, 148]]}
{"doc_key": "ai-test-271", "ner": [[5, 6, "task"], [8, 10, "metrics"], [12, 12, "metrics"], [20, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 8, 10, "usage", "", true, false], [12, 12, 8, 10, "named", "", false, false], [20, 22, 8, 10, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Chocia\u017c", "pierwotnie", "u\u017cywana", "do", "oceny", "t\u0142umacze\u0144", "maszynowych", ",", "dwuj\u0119zyczna", "ocena", "niedostateczna", "(", "BLEU", ")", "zosta\u0142a", "z", "powodzeniem", "wykorzystana", "do", "oceny", "modeli", "generowania", "parafraz", "."], "sentence-detokenized": "Chocia\u017c pierwotnie u\u017cywana do oceny t\u0142umacze\u0144 maszynowych, dwuj\u0119zyczna ocena niedostateczna (BLEU) zosta\u0142a z powodzeniem wykorzystana do oceny modeli generowania parafraz.", "token2charspan": [[0, 7], [8, 18], [19, 26], [27, 29], [30, 35], [36, 45], [46, 57], [57, 58], [59, 70], [71, 76], [77, 91], [92, 93], [93, 97], [97, 98], [99, 106], [107, 108], [109, 120], [121, 133], [134, 136], [137, 142], [143, 149], [150, 161], [162, 170], [170, 171]]}
{"doc_key": "ai-test-272", "ner": [[0, 0, "organisation"], [8, 10, "organisation"], [12, 12, "organisation"], [15, 15, "product"], [18, 18, "country"], [20, 20, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 8, 10, "role", "licenses_to", false, false], [0, 0, 12, 12, "role", "licenses_to", false, false], [8, 10, 18, 18, "physical", "", false, false], [12, 12, 20, 20, "physical", "", false, false], [15, 15, 8, 10, "artifact", "produces", false, false], [15, 15, 12, 12, "artifact", "produces", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Unimation", "udzieli\u0142o", "p\u00f3\u017aniej", "licencji", "na", "swoj\u0105", "technologi\u0119", "firmom", "Kawasaki", "Heavy", "Industries", "i", "GKN", ",", "produkuj\u0105cym", "Unimaty", "odpowiednio", "w", "Japonii", "i", "Anglii", "."], "sentence-detokenized": "Unimation udzieli\u0142o p\u00f3\u017aniej licencji na swoj\u0105 technologi\u0119 firmom Kawasaki Heavy Industries i GKN, produkuj\u0105cym Unimaty odpowiednio w Japonii i Anglii.", "token2charspan": [[0, 9], [10, 19], [20, 27], [28, 36], [37, 39], [40, 45], [46, 57], [58, 64], [65, 73], [74, 79], [80, 90], [91, 92], [93, 96], [96, 97], [98, 110], [111, 118], [119, 130], [131, 132], [133, 140], [141, 142], [143, 149], [149, 150]]}
{"doc_key": "ai-test-273", "ner": [[17, 20, "conference"], [34, 35, "field"], [52, 63, "field"], [58, 58, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[34, 35, 52, 63, "compare", "", false, false], [58, 58, 52, 63, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Wiele", "nieporozumie\u0144", "pomi\u0119dzy", "tymi", "dwoma", "\u015brodowiskami", "badawczymi", "(", "kt\u00f3re", "cz\u0119sto", "maj\u0105", "osobne", "konferencje", "i", "osobne", "czasopisma", ",", "ECML", "PKDD", "jest", "tu", "g\u0142\u00f3wnym", "wyj\u0105tkiem", ")", "wynika", "z", "podstawowych", "za\u0142o\u017ce\u0144", ",", "na", "jakich", "pracuj\u0105", ":", "w", "uczeniu", "maszynowym", "wydajno\u015b\u0107", "jest", "zwykle", "oceniana", "w", "odniesieniu", "do", "zdolno\u015bci", "do", "odtwarzania", "znanej", "wiedzy", ",", "podczas", "gdy", "w", "odkrywaniu", "wiedzy", "i", "eksploracji", "danych", "(", "KDD", ")", "kluczowym", "zadaniem", "jest", "odkrywanie", "wcze\u015bniej", "nieznanej", "wiedzy", "."], "sentence-detokenized": "Wiele nieporozumie\u0144 pomi\u0119dzy tymi dwoma \u015brodowiskami badawczymi (kt\u00f3re cz\u0119sto maj\u0105 osobne konferencje i osobne czasopisma, ECML PKDD jest tu g\u0142\u00f3wnym wyj\u0105tkiem) wynika z podstawowych za\u0142o\u017ce\u0144, na jakich pracuj\u0105: w uczeniu maszynowym wydajno\u015b\u0107 jest zwykle oceniana w odniesieniu do zdolno\u015bci do odtwarzania znanej wiedzy, podczas gdy w odkrywaniu wiedzy i eksploracji danych (KDD) kluczowym zadaniem jest odkrywanie wcze\u015bniej nieznanej wiedzy.", "token2charspan": [[0, 5], [6, 19], [20, 28], [29, 33], [34, 39], [40, 52], [53, 63], [64, 65], [65, 70], [71, 77], [78, 82], [83, 89], [90, 101], [102, 103], [104, 110], [111, 121], [121, 122], [123, 127], [128, 132], [133, 137], [138, 140], [141, 148], [149, 158], [158, 159], [160, 166], [167, 168], [169, 181], [182, 189], [189, 190], [191, 193], [194, 200], [201, 208], [208, 209], [210, 211], [212, 219], [220, 230], [231, 240], [241, 245], [246, 252], [253, 261], [262, 263], [264, 275], [276, 278], [279, 288], [289, 291], [292, 303], [304, 310], [311, 317], [317, 318], [319, 326], [327, 330], [331, 332], [333, 343], [344, 350], [351, 352], [353, 364], [365, 371], [372, 373], [373, 376], [376, 377], [378, 387], [388, 396], [397, 401], [402, 412], [413, 422], [423, 432], [433, 439], [439, 440]]}
{"doc_key": "ai-test-274", "ner": [[0, 2, "algorithm"], [7, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 7, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Ukryte", "modele", "Markowa", "s\u0105", "podstaw\u0105", "wi\u0119kszo\u015bci", "wsp\u00f3\u0142czesnych", "system\u00f3w", "automatycznego", "rozpoznawania", "mowy", "."], "sentence-detokenized": "Ukryte modele Markowa s\u0105 podstaw\u0105 wi\u0119kszo\u015bci wsp\u00f3\u0142czesnych system\u00f3w automatycznego rozpoznawania mowy.", "token2charspan": [[0, 6], [7, 13], [14, 21], [22, 24], [25, 33], [34, 44], [45, 58], [59, 67], [68, 82], [83, 96], [97, 101], [101, 102]]}
{"doc_key": "ai-test-275", "ner": [[2, 2, "location"], [4, 4, "country"], [10, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 4, 4, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Firma", "z", "Bangalore", "w", "Indiach", "specjalizuj\u0105ca", "si\u0119", "w", "oprogramowaniu", "do", "rozpoznawania", "pisma", "r\u0119cznego", "online", "."], "sentence-detokenized": "Firma z Bangalore w Indiach specjalizuj\u0105ca si\u0119 w oprogramowaniu do rozpoznawania pisma r\u0119cznego online.", "token2charspan": [[0, 5], [6, 7], [8, 17], [18, 19], [20, 27], [28, 42], [43, 46], [47, 48], [49, 63], [64, 66], [67, 80], [81, 86], [87, 95], [96, 102], [102, 103]]}
{"doc_key": "ai-test-276", "ner": [[21, 22, "misc"], [43, 43, "metrics"], [45, 47, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[43, 43, 45, 47, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Czy", "powtarzane", "t\u0142umaczenia", "zbiegaj\u0105", "si\u0119", "do", "jednego", "wyra\u017cenia", "w", "obu", "j\u0119zykach", "?", "Tzn", ".", "czy", "metoda", "t\u0142umaczenia", "wykazuje", "stacjonarno\u015b\u0107", "lub", "wytwarza", "form\u0119", "kanoniczn\u0105", "?", "Czy", "t\u0142umaczenie", "staje", "si\u0119", "stacjonarne", "bez", "utraty", "oryginalnego", "znaczenia", "?", "Metryka", "ta", "by\u0142a", "krytykowana", "jako", "s\u0142abo", "skorelowana", "z", "punktacj\u0105", "BLEU", "(", "BiLingual", "Evaluation", "Understudy", ")", "."], "sentence-detokenized": "Czy powtarzane t\u0142umaczenia zbiegaj\u0105 si\u0119 do jednego wyra\u017cenia w obu j\u0119zykach? Tzn. czy metoda t\u0142umaczenia wykazuje stacjonarno\u015b\u0107 lub wytwarza form\u0119 kanoniczn\u0105? Czy t\u0142umaczenie staje si\u0119 stacjonarne bez utraty oryginalnego znaczenia? Metryka ta by\u0142a krytykowana jako s\u0142abo skorelowana z punktacj\u0105 BLEU (BiLingual Evaluation Understudy).", "token2charspan": [[0, 3], [4, 14], [15, 26], [27, 35], [36, 39], [40, 42], [43, 50], [51, 60], [61, 62], [63, 66], [67, 75], [75, 76], [77, 80], [80, 81], [82, 85], [86, 92], [93, 104], [105, 113], [114, 127], [128, 131], [132, 140], [141, 146], [147, 157], [157, 158], [159, 162], [163, 174], [175, 180], [181, 184], [185, 196], [197, 200], [201, 207], [208, 220], [221, 230], [230, 231], [232, 239], [240, 242], [243, 247], [248, 259], [260, 264], [265, 270], [271, 282], [283, 284], [285, 294], [295, 299], [300, 301], [301, 310], [311, 321], [322, 332], [332, 333], [333, 334]]}
{"doc_key": "ai-test-277", "ner": [[2, 6, "organisation"], [8, 15, "organisation"], [17, 18, "university"], [20, 20, "university"], [23, 24, "field"], [27, 30, "organisation"], [32, 34, "organisation"], [46, 49, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[8, 15, 17, 18, "part-of", "", false, false], [20, 20, 23, 24, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Jest", "stypendyst\u0105", "American", "Association", "for", "Artificial", "Intelligence", ",", "Center", "for", "Advanced", "Study", "in", "the", "Behavioral", "Sciences", "na", "Uniwersytecie", "Stanforda", ",", "MIT", "Center", "for", "Cognitive", "Science", ",", "Canadian", "Institute", "for", "Advanced", "Research", ",", "Canadian", "Psychological", "Association", ",", "a", "w", "1998", "roku", "zosta\u0142", "wybrany", "na", "Fellow", "of", "the", "Royal", "Society", "of", "Canada", "."], "sentence-detokenized": "Jest stypendyst\u0105 American Association for Artificial Intelligence, Center for Advanced Study in the Behavioral Sciences na Uniwersytecie Stanforda, MIT Center for Cognitive Science, Canadian Institute for Advanced Research, Canadian Psychological Association, a w 1998 roku zosta\u0142 wybrany na Fellow of the Royal Society of Canada.", "token2charspan": [[0, 4], [5, 16], [17, 25], [26, 37], [38, 41], [42, 52], [53, 65], [65, 66], [67, 73], [74, 77], [78, 86], [87, 92], [93, 95], [96, 99], [100, 110], [111, 119], [120, 122], [123, 136], [137, 146], [146, 147], [148, 151], [152, 158], [159, 162], [163, 172], [173, 180], [180, 181], [182, 190], [191, 200], [201, 204], [205, 213], [214, 222], [222, 223], [224, 232], [233, 246], [247, 258], [258, 259], [260, 261], [262, 263], [264, 268], [269, 273], [274, 280], [281, 288], [289, 291], [292, 298], [299, 301], [302, 305], [306, 311], [312, 319], [320, 322], [323, 329], [329, 330]]}
{"doc_key": "ai-test-278", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [15, 17, "misc"], [19, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 15, 17, "part-of", "", false, false], [0, 0, 19, 22, "part-of", "", false, false], [4, 5, 15, 17, "part-of", "", false, false], [4, 5, 19, 22, "part-of", "", false, false], [7, 8, 15, 17, "part-of", "", false, false], [7, 8, 19, 22, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Hinton", "-", "wraz", "z", "Yoshua", "Bengio", "i", "Yannem", "LeCunem", "-", "jest", "przez", "niekt\u00f3rych", "okre\u015blany", "mianem", "ojc\u00f3w", "chrzestnych", "AI", "i", "ojc\u00f3w", "chrzestnych", "Deep", "Learning", "."], "sentence-detokenized": "Hinton - wraz z Yoshua Bengio i Yannem LeCunem - jest przez niekt\u00f3rych okre\u015blany mianem ojc\u00f3w chrzestnych AI i ojc\u00f3w chrzestnych Deep Learning.", "token2charspan": [[0, 6], [7, 8], [9, 13], [14, 15], [16, 22], [23, 29], [30, 31], [32, 38], [39, 46], [47, 48], [49, 53], [54, 59], [60, 70], [71, 80], [81, 87], [88, 93], [94, 105], [106, 108], [109, 110], [111, 116], [117, 128], [129, 133], [134, 142], [142, 143]]}
{"doc_key": "ai-test-279", "ner": [[5, 5, "product"], [16, 16, "misc"], [18, 29, "misc"], [20, 20, "product"], [24, 25, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 5, 16, 16, "related-to", "", false, false], [5, 5, 18, 29, "related-to", "", false, false], [16, 16, 20, 20, "named", "same", false, false], [24, 25, 20, 20, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Lekki", "projekt", "mowy", "open-", "source", "eSpeak", ",", "kt\u00f3ry", "ma", "w\u0142asne", "podej\u015bcie", "do", "syntezy", ",", "eksperymentowa\u0142", "z", "mandary\u0144skim", "i", "kanto\u0144skim", ".", "eSpeak", "by\u0142", "u\u017cywany", "przez", "Google", "Translate", "od", "maja", "20102010", "."], "sentence-detokenized": "Lekki projekt mowy open-source eSpeak, kt\u00f3ry ma w\u0142asne podej\u015bcie do syntezy, eksperymentowa\u0142 z mandary\u0144skim i kanto\u0144skim. eSpeak by\u0142 u\u017cywany przez Google Translate od maja 20102010.", "token2charspan": [[0, 5], [6, 13], [14, 18], [19, 24], [24, 30], [31, 37], [37, 38], [39, 44], [45, 47], [48, 54], [55, 64], [65, 67], [68, 75], [75, 76], [77, 92], [93, 94], [95, 107], [108, 109], [110, 120], [120, 121], [122, 128], [129, 132], [133, 140], [141, 146], [147, 153], [154, 163], [164, 166], [167, 171], [172, 180], [180, 181]]}
{"doc_key": "ai-test-280", "ner": [[5, 7, "product"], [13, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 13, 16, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Wydany", "r\u00f3wnie\u017c", "w", "1982", "roku", "Software", "Automatic", "Mouth", "by\u0142", "pierwszym", "komercyjnym", ",", "ca\u0142kowicie", "programowym", "programem", "do", "syntezy", "g\u0142osu", "."], "sentence-detokenized": "Wydany r\u00f3wnie\u017c w 1982 roku Software Automatic Mouth by\u0142 pierwszym komercyjnym, ca\u0142kowicie programowym programem do syntezy g\u0142osu.", "token2charspan": [[0, 6], [7, 14], [15, 16], [17, 21], [22, 26], [27, 35], [36, 45], [46, 51], [52, 55], [56, 65], [66, 77], [77, 78], [79, 89], [90, 101], [102, 111], [112, 114], [115, 122], [123, 128], [128, 129]]}
{"doc_key": "ai-test-281", "ner": [[3, 5, "metrics"], [7, 7, "metrics"], [10, 10, "metrics"], [12, 12, "metrics"], [15, 22, "metrics"], [26, 28, "metrics"], [30, 30, "metrics"], [34, 40, "metrics"], [43, 45, "metrics"], [47, 47, "metrics"], [50, 50, "metrics"], [52, 52, "metrics"], [56, 62, "metrics"], [66, 68, "metrics"], [70, 70, "metrics"], [73, 79, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[7, 7, 3, 5, "named", "", false, false], [10, 10, 3, 5, "named", "", false, false], [12, 12, 3, 5, "named", "", false, false], [15, 22, 3, 5, "named", "", false, false], [30, 30, 26, 28, "named", "", false, false], [34, 40, 26, 28, "named", "", false, false], [47, 47, 43, 45, "named", "", false, false], [50, 50, 43, 45, "named", "", false, false], [52, 52, 43, 45, "named", "", false, false], [56, 62, 43, 45, "named", "", false, false], [70, 70, 66, 68, "named", "", false, false], [73, 79, 66, 68, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Wsp\u00f3\u0142czynniki", "kolumnowe", "to", "TRUE", "Positive", "Rate", "(", "TPR", ",", "aka", "Sensitivity", "lub", "recall", ")", "(", "TP", "/", "(", "TP", "+", "FN", ")", ")", ",", "z", "uzupe\u0142nieniem", "FALSE", "Negative", "Rate", "(", "FNR", ")", "(", "FN", "/", "(", "TP", "+", "FN", ")", ")", ";", "oraz", "TRUE", "Negative", "Rate", "(", "TNR", ",", "aka", "Specificity", ",", "SPC", ")", "(", "TN", "/", "(", "TN", "+", "FP", ")", ")", ",", "z", "uzupe\u0142nieniem", "FALSE", "Positive", "Rate", "(", "FPR", ")", "(", "FP", "/", "(", "TN", "+", "FP", ")", ")", "."], "sentence-detokenized": "Wsp\u00f3\u0142czynniki kolumnowe to TRUE Positive Rate (TPR, aka Sensitivity lub recall) (TP / (TP + FN)), z uzupe\u0142nieniem FALSE Negative Rate (FNR) (FN / (TP + FN)); oraz TRUE Negative Rate (TNR, aka Specificity, SPC) (TN / (TN + FP)), z uzupe\u0142nieniem FALSE Positive Rate (FPR) (FP / (TN + FP)).", "token2charspan": [[0, 13], [14, 23], [24, 26], [27, 31], [32, 40], [41, 45], [46, 47], [47, 50], [50, 51], [52, 55], [56, 67], [68, 71], [72, 78], [78, 79], [80, 81], [81, 83], [84, 85], [86, 87], [87, 89], [90, 91], [92, 94], [94, 95], [95, 96], [96, 97], [98, 99], [100, 113], [114, 119], [120, 128], [129, 133], [134, 135], [135, 138], [138, 139], [140, 141], [141, 143], [144, 145], [146, 147], [147, 149], [150, 151], [152, 154], [154, 155], [155, 156], [156, 157], [158, 162], [163, 167], [168, 176], [177, 181], [182, 183], [183, 186], [186, 187], [188, 191], [192, 203], [203, 204], [205, 208], [208, 209], [210, 211], [211, 213], [214, 215], [216, 217], [217, 219], [220, 221], [222, 224], [224, 225], [225, 226], [226, 227], [228, 229], [230, 243], [244, 249], [250, 258], [259, 263], [264, 265], [265, 268], [268, 269], [270, 271], [271, 273], [274, 275], [276, 277], [277, 279], [280, 281], [282, 284], [284, 285], [285, 286], [286, 287]]}
{"doc_key": "ai-test-282", "ner": [[0, 0, "person"], [2, 2, "person"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 16, 16, "role", "working_with", false, false], [2, 2, 16, 16, "role", "working_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Edsinger", "i", "Weber", "wsp\u00f3\u0142pracowali", "tak\u017ce", "nad", "wieloma", "innymi", "robotami", ",", "a", "ich", "do\u015bwiadczenie", "w", "pracy", "z", "Kismetem"], "sentence-detokenized": "Edsinger i Weber wsp\u00f3\u0142pracowali tak\u017ce nad wieloma innymi robotami, a ich do\u015bwiadczenie w pracy z Kismetem", "token2charspan": [[0, 8], [9, 10], [11, 16], [17, 31], [32, 37], [38, 41], [42, 49], [50, 56], [57, 65], [65, 66], [67, 68], [69, 72], [73, 86], [87, 88], [89, 94], [95, 96], [97, 105]]}
{"doc_key": "ai-test-283", "ner": [[1, 1, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 1, 11, 11, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Funkcjonalno\u015b\u0107", "R", "jest", "dost\u0119pna", "z", "kilku", "j\u0119zyk\u00f3w", "skryptowych", ",", "takich", "jak", "Python", ",", "s\u0105", "r\u00f3wnie\u017c", "dost\u0119pne", "."], "sentence-detokenized": "Funkcjonalno\u015b\u0107 R jest dost\u0119pna z kilku j\u0119zyk\u00f3w skryptowych, takich jak Python, s\u0105 r\u00f3wnie\u017c dost\u0119pne.", "token2charspan": [[0, 14], [15, 16], [17, 21], [22, 30], [31, 32], [33, 38], [39, 46], [47, 58], [58, 59], [60, 66], [67, 70], [71, 77], [77, 78], [79, 81], [82, 89], [90, 98], [98, 99]]}
{"doc_key": "ai-test-284", "ner": [[0, 0, "programlang"], [11, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VAL", "by\u0142", "jednym", "z", "pierwszych", "j\u0119zyk\u00f3w", "robot\u00f3w", "i", "by\u0142", "u\u017cywany", "w", "robotach", "Unimate", "."], "sentence-detokenized": "VAL by\u0142 jednym z pierwszych j\u0119zyk\u00f3w robot\u00f3w i by\u0142 u\u017cywany w robotach Unimate.", "token2charspan": [[0, 3], [4, 7], [8, 14], [15, 16], [17, 27], [28, 35], [36, 43], [44, 45], [46, 49], [50, 57], [58, 59], [60, 68], [69, 76], [76, 77]]}
{"doc_key": "ai-test-285", "ner": [[11, 19, "conference"], [21, 21, "conference"], [24, 24, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 19, 24, 24, "physical", "", false, false], [21, 21, 11, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Swoj\u0105", "baz\u0119", "danych", "zaprezentowali", "po", "raz", "pierwszy", "w", "formie", "plakatu", "na", "konferencji", "2009", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "na", "Florydzie", "."], "sentence-detokenized": "Swoj\u0105 baz\u0119 danych zaprezentowali po raz pierwszy w formie plakatu na konferencji 2009 Conference on Computer Vision and Pattern Recognition (CVPR) na Florydzie.", "token2charspan": [[0, 5], [6, 10], [11, 17], [18, 32], [33, 35], [36, 39], [40, 48], [49, 50], [51, 57], [58, 65], [66, 68], [69, 80], [81, 85], [86, 96], [97, 99], [100, 108], [109, 115], [116, 119], [120, 127], [128, 139], [140, 141], [141, 145], [145, 146], [147, 149], [150, 159], [159, 160]]}
{"doc_key": "ai-test-286", "ner": [[0, 0, "misc"], [13, 15, "task"], [17, 19, "field"], [21, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 15, 0, 0, "type-of", "", false, false], [17, 19, 0, 0, "type-of", "", false, false], [21, 22, 0, 0, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Zadania", "kategoryzacji", ",", "w", "kt\u00f3rych", "nie", "s\u0105", "dostarczane", "etykiety", ",", "s\u0105", "okre\u015blane", "jako", "klasyfikacja", "bez", "nadzoru", ",", "uczenie", "bez", "nadzoru", ",", "analiza", "skupie\u0144", "."], "sentence-detokenized": "Zadania kategoryzacji, w kt\u00f3rych nie s\u0105 dostarczane etykiety, s\u0105 okre\u015blane jako klasyfikacja bez nadzoru, uczenie bez nadzoru, analiza skupie\u0144.", "token2charspan": [[0, 7], [8, 21], [21, 22], [23, 24], [25, 32], [33, 36], [37, 39], [40, 51], [52, 60], [60, 61], [62, 64], [65, 74], [75, 79], [80, 92], [93, 96], [97, 104], [104, 105], [106, 113], [114, 117], [118, 125], [125, 126], [127, 134], [135, 142], [142, 143]]}
{"doc_key": "ai-test-287", "ner": [[1, 2, "task"], [10, 11, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Potrzebuje", "rozpoznawania", "obiekt\u00f3w", ",", "rozpoznawania", "i", "lokalizowania", "ludzi", "oraz", "dalszego", "rozpoznawania", "emocji", "."], "sentence-detokenized": "Potrzebuje rozpoznawania obiekt\u00f3w, rozpoznawania i lokalizowania ludzi oraz dalszego rozpoznawania emocji.", "token2charspan": [[0, 10], [11, 24], [25, 33], [33, 34], [35, 48], [49, 50], [51, 64], [65, 70], [71, 75], [76, 84], [85, 98], [99, 105], [105, 106]]}
{"doc_key": "ai-test-288", "ner": [[6, 6, "misc"], [10, 10, "misc"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Proces", "ten", "jest", "z\u0142o\u017cony", "i", "zawiera", "kodowanie", "i", "przypominanie", "lub", "pobieranie", "."], "sentence-detokenized": "Proces ten jest z\u0142o\u017cony i zawiera kodowanie i przypominanie lub pobieranie.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 23], [24, 25], [26, 33], [34, 43], [44, 45], [46, 59], [60, 63], [64, 74], [74, 75]]}
{"doc_key": "ai-test-289", "ner": [[7, 8, "product"], [12, 12, "product"], [30, 30, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 12, 12, "named", "", false, false], [7, 8, 30, 30, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Znane", "r\u00f3wnie\u017c", "jako", "roboty", "r\u00f3wnoleg\u0142e", "lub", "uog\u00f3lnione", "platformy", "Stewarta", "(", "w", "platformie", "Stewarta", "si\u0142owniki", "s\u0105", "sparowane", "zar\u00f3wno", "na", "podstawie", ",", "jak", "i", "na", "platformie", ")", ",", "systemy", "te", "s\u0105", "robotami", "przegubowymi", ",", "kt\u00f3re", "wykorzystuj\u0105", "podobne", "mechanizmy", "do", "ruchu", "albo", "robota", "na", "podstawie", ",", "albo", "jednego", "lub", "wi\u0119cej", "ramion", "manipulator\u00f3w", "."], "sentence-detokenized": "Znane r\u00f3wnie\u017c jako roboty r\u00f3wnoleg\u0142e lub uog\u00f3lnione platformy Stewarta (w platformie Stewarta si\u0142owniki s\u0105 sparowane zar\u00f3wno na podstawie, jak i na platformie), systemy te s\u0105 robotami przegubowymi, kt\u00f3re wykorzystuj\u0105 podobne mechanizmy do ruchu albo robota na podstawie, albo jednego lub wi\u0119cej ramion manipulator\u00f3w.", "token2charspan": [[0, 5], [6, 13], [14, 18], [19, 25], [26, 36], [37, 40], [41, 51], [52, 61], [62, 70], [71, 72], [72, 73], [74, 84], [85, 93], [94, 103], [104, 106], [107, 116], [117, 124], [125, 127], [128, 137], [137, 138], [139, 142], [143, 144], [145, 147], [148, 158], [158, 159], [159, 160], [161, 168], [169, 171], [172, 174], [175, 183], [184, 196], [196, 197], [198, 203], [204, 216], [217, 224], [225, 235], [236, 238], [239, 244], [245, 249], [250, 256], [257, 259], [260, 269], [269, 270], [271, 275], [276, 283], [284, 287], [288, 294], [295, 301], [302, 315], [315, 316]]}
{"doc_key": "ai-test-290", "ner": [[0, 1, "field"], [4, 5, "field"], [13, 13, "field"], [17, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 5, "part-of", "subfield", false, false], [0, 1, 13, 13, "compare", "", false, false], [13, 13, 17, 17, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Widzenie", "maszynowe", "jako", "dyscyplina", "in\u017cynierii", "system\u00f3w", "mo\u017ce", "by\u0107", "uwa\u017cane", "za", "odr\u0119bne", "od", "widzenia", "komputerowego", ",", "b\u0119d\u0105cego", "form\u0105", "informatyki", "."], "sentence-detokenized": "Widzenie maszynowe jako dyscyplina in\u017cynierii system\u00f3w mo\u017ce by\u0107 uwa\u017cane za odr\u0119bne od widzenia komputerowego, b\u0119d\u0105cego form\u0105 informatyki.", "token2charspan": [[0, 8], [9, 18], [19, 23], [24, 34], [35, 45], [46, 54], [55, 59], [60, 63], [64, 71], [72, 74], [75, 82], [83, 85], [86, 94], [95, 108], [108, 109], [110, 118], [119, 124], [125, 136], [136, 137]]}
{"doc_key": "ai-test-291", "ner": [[2, 3, "algorithm"], [6, 7, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 6, 7, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Funkcj\u0105", "aktywacji", "bramek", "LSTM", "jest", "cz\u0119sto", "logistyczna", "funkcja", "sigmoidalna", "."], "sentence-detokenized": "Funkcj\u0105 aktywacji bramek LSTM jest cz\u0119sto logistyczna funkcja sigmoidalna.", "token2charspan": [[0, 7], [8, 17], [18, 24], [25, 29], [30, 34], [35, 41], [42, 53], [54, 61], [62, 73], [73, 74]]}
{"doc_key": "ai-test-292", "ner": [[3, 5, "metrics"], [19, 21, "metrics"], [23, 23, "metrics"], [32, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 5, 19, 21, "named", "", false, false], [3, 5, 32, 33, "named", "", false, false], [23, 23, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Innymi", "s\u0142owy", ",", "\u015brednia", "z", "pr\u00f3by", "jest", "(", "koniecznie", "jedynym", ")", "efektywnym", "estymatorem", ",", "a", "wi\u0119c", "tak\u017ce", "estymatorem", "o", "minimalnej", "wariancji", "bezstronnym", "(", "MVUE", ")", ",", "opr\u00f3cz", "tego", ",", "\u017ce", "jest", "estymatorem", "maksymalnego", "prawdopodobie\u0144stwa", "."], "sentence-detokenized": "Innymi s\u0142owy, \u015brednia z pr\u00f3by jest (koniecznie jedynym) efektywnym estymatorem, a wi\u0119c tak\u017ce estymatorem o minimalnej wariancji bezstronnym (MVUE), opr\u00f3cz tego, \u017ce jest estymatorem maksymalnego prawdopodobie\u0144stwa.", "token2charspan": [[0, 6], [7, 12], [12, 13], [14, 21], [22, 23], [24, 29], [30, 34], [35, 36], [36, 46], [47, 54], [54, 55], [56, 66], [67, 78], [78, 79], [80, 81], [82, 86], [87, 92], [93, 104], [105, 106], [107, 117], [118, 127], [128, 139], [140, 141], [141, 145], [145, 146], [146, 147], [148, 154], [155, 159], [159, 160], [161, 163], [164, 168], [169, 180], [181, 193], [194, 212], [212, 213]]}
{"doc_key": "ai-test-293", "ner": [[2, 4, "academicjournal"], [7, 7, "researcher"], [9, 10, "researcher"], [12, 13, "researcher"], [19, 20, "product"], [22, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 4, 19, 20, "topic", "", false, false], [2, 4, 22, 23, "topic", "", false, false], [7, 7, 2, 4, "role", "", false, false], [9, 10, 2, 4, "role", "", false, false], [12, 13, 2, 4, "role", "", false, false], [19, 20, 22, 23, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["W", "artykule", "Scientific", "American", "z", "2001", "roku", "Berners-Lee", ",", "James", "Hendler", "i", "Ora", "Lassila", "opisali", "spodziewan\u0105", "ewolucj\u0119", "istniej\u0105cej", "sieci", "Web", "w", "kierunku", "Semantic", "Web", "."], "sentence-detokenized": "W artykule Scientific American z 2001 roku Berners-Lee, James Hendler i Ora Lassila opisali spodziewan\u0105 ewolucj\u0119 istniej\u0105cej sieci Web w kierunku Semantic Web.", "token2charspan": [[0, 1], [2, 10], [11, 21], [22, 30], [31, 32], [33, 37], [38, 42], [43, 54], [54, 55], [56, 61], [62, 69], [70, 71], [72, 75], [76, 83], [84, 91], [92, 103], [104, 112], [113, 124], [125, 130], [131, 134], [135, 136], [137, 145], [146, 154], [155, 158], [158, 159]]}
{"doc_key": "ai-test-294", "ner": [[0, 2, "misc"], [10, 11, "person"], [13, 13, "person"], [20, 20, "person"], [33, 33, "person"], [42, 43, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 11, 0, 2, "role", "actor_in_work", false, false], [13, 13, 10, 11, "named", "", false, false], [13, 13, 10, 11, "origin", "", false, false], [20, 20, 13, 13, "part-of", "", false, false], [42, 43, 13, 13, "role", "auditioned_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["W", "Blade", "Runnerze", "wykorzystano", "wielu", "mniej", "znanych", "w\u00f3wczas", "aktor\u00f3w", ":", "Sean", "Young", "portretuje", "Rachael", ",", "eksperymentalnego", "replikanta", "wszczepionego", "wspomnieniami", "siostrzenicy", "Tyrella", ",", "co", "powoduje", ",", "\u017ce", "wierzy", "ona", ",", "\u017ce", "jest", "cz\u0142owiekiem", ";", "Sammon", ",", "s", ".", "92-93", "Do", "roli", "przes\u0142uchiwana", "by\u0142a", "Nina", "Axelrod", "."], "sentence-detokenized": "W Blade Runnerze wykorzystano wielu mniej znanych w\u00f3wczas aktor\u00f3w: Sean Young portretuje Rachael, eksperymentalnego replikanta wszczepionego wspomnieniami siostrzenicy Tyrella, co powoduje, \u017ce wierzy ona, \u017ce jest cz\u0142owiekiem; Sammon, s. 92-93 Do roli przes\u0142uchiwana by\u0142a Nina Axelrod.", "token2charspan": [[0, 1], [2, 7], [8, 16], [17, 29], [30, 35], [36, 41], [42, 49], [50, 57], [58, 65], [65, 66], [67, 71], [72, 77], [78, 88], [89, 96], [96, 97], [98, 115], [116, 126], [127, 140], [141, 154], [155, 167], [168, 175], [175, 176], [177, 179], [180, 188], [188, 189], [190, 192], [193, 199], [200, 203], [203, 204], [205, 207], [208, 212], [213, 224], [224, 225], [226, 232], [232, 233], [234, 235], [235, 236], [237, 242], [243, 245], [246, 250], [251, 265], [266, 270], [271, 275], [276, 283], [283, 284]]}
{"doc_key": "ai-test-295", "ner": [[0, 1, "researcher"], [3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [12, 15, "university"], [22, 24, "product"], [26, 26, "product"], [40, 40, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 12, 15, "physical", "", false, false], [3, 4, 12, 15, "physical", "", false, false], [6, 7, 12, 15, "physical", "", false, false], [9, 10, 12, 15, "physical", "", false, false], [12, 15, 40, 40, "physical", "", true, false], [22, 24, 12, 15, "temporal", "", false, false], [26, 26, 12, 15, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Gerry", "Sussman", ",", "Eugene", "Charniak", ",", "Seymour", "Papert", "i", "Terry", "Winograd", "odwiedzili", "Uniwersytet", "w", "Edynburgu", "w", "1971", "roku", ",", "rozprzestrzeniaj\u0105c", "wie\u015bci", "o", "Micro", "-", "Plannerze", "i", "SHRDLU", "oraz", "podaj\u0105c", "w", "w\u0105tpliwo\u015b\u0107", "podej\u015bcie", "Resolution", "Uniform", "Proof", "Procedure", ",", "kt\u00f3re", "by\u0142o", "ostoj\u0105", "edynburskich", "logik\u00f3w", "."], "sentence-detokenized": "Gerry Sussman, Eugene Charniak, Seymour Papert i Terry Winograd odwiedzili Uniwersytet w Edynburgu w 1971 roku, rozprzestrzeniaj\u0105c wie\u015bci o Micro-Plannerze i SHRDLU oraz podaj\u0105c w w\u0105tpliwo\u015b\u0107 podej\u015bcie Resolution Uniform Proof Procedure, kt\u00f3re by\u0142o ostoj\u0105 edynburskich logik\u00f3w.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 21], [22, 30], [30, 31], [32, 39], [40, 46], [47, 48], [49, 54], [55, 63], [64, 74], [75, 86], [87, 88], [89, 98], [99, 100], [101, 105], [106, 110], [110, 111], [112, 130], [131, 137], [138, 139], [140, 145], [145, 146], [146, 155], [156, 157], [158, 164], [165, 169], [170, 177], [178, 179], [180, 190], [191, 200], [201, 211], [212, 219], [220, 225], [226, 235], [235, 236], [237, 242], [243, 247], [248, 254], [255, 267], [268, 275], [275, 276]]}
{"doc_key": "ai-test-296", "ner": [[1, 1, "researcher"], [6, 6, "field"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 10, 11, "role", "inspires", false, false], [1, 1, 13, 14, "role", "inspires", false, false], [1, 1, 16, 17, "role", "inspires", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Praca", "Waltera", "zainspirowa\u0142a", "kolejne", "pokolenia", "badaczy", "robotyki", ",", "takich", "jak", "Rodney", "Brooks", ",", "Hans", "Moravec", "czy", "Mark", "Tilden", "."], "sentence-detokenized": "Praca Waltera zainspirowa\u0142a kolejne pokolenia badaczy robotyki, takich jak Rodney Brooks, Hans Moravec czy Mark Tilden.", "token2charspan": [[0, 5], [6, 13], [14, 27], [28, 35], [36, 45], [46, 53], [54, 62], [62, 63], [64, 70], [71, 74], [75, 81], [82, 88], [88, 89], [90, 94], [95, 102], [103, 106], [107, 111], [112, 118], [118, 119]]}
{"doc_key": "ai-test-297", "ner": [[2, 2, "algorithm"], [8, 9, "researcher"], [14, 20, "event"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 8, 9, "origin", "", false, false], [2, 2, 14, 20, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Nast\u0119pnie", "podobna", "CNN", "oparta", "na", "procesorze", "graficznym", "autorstwa", "Alexa", "Krizhevsky'ego", "i", "in", ".", "wygra\u0142a", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "2012", "."], "sentence-detokenized": "Nast\u0119pnie podobna CNN oparta na procesorze graficznym autorstwa Alexa Krizhevsky'ego i in. wygra\u0142a ImageNet Large Scale Visual Recognition Challenge 2012.", "token2charspan": [[0, 9], [10, 17], [18, 21], [22, 28], [29, 31], [32, 42], [43, 53], [54, 63], [64, 69], [70, 84], [85, 86], [87, 89], [89, 90], [91, 98], [99, 107], [108, 113], [114, 119], [120, 126], [127, 138], [139, 148], [149, 153], [153, 154]]}
{"doc_key": "ai-test-298", "ner": [[2, 3, "misc"], [8, 9, "metrics"], [11, 12, "metrics"], [16, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 2, 3, "type-of", "", false, false], [11, 12, 2, 3, "type-of", "", false, false], [11, 12, 16, 18, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Powszechnie", "stosowane", "funkcje", "straty", "dla", "klasyfikacji", "probabilistycznej", "obejmuj\u0105", "strat\u0119", "logiczn\u0105", "i", "wynik", "Briera", "pomi\u0119dzy", "przewidywanymi", "i", "TRUE", "rozk\u0142adami", "prawdopodobie\u0144stwa", "."], "sentence-detokenized": "Powszechnie stosowane funkcje straty dla klasyfikacji probabilistycznej obejmuj\u0105 strat\u0119 logiczn\u0105 i wynik Briera pomi\u0119dzy przewidywanymi i TRUE rozk\u0142adami prawdopodobie\u0144stwa.", "token2charspan": [[0, 11], [12, 21], [22, 29], [30, 36], [37, 40], [41, 53], [54, 71], [72, 80], [81, 87], [88, 96], [97, 98], [99, 104], [105, 111], [112, 120], [121, 135], [136, 137], [138, 142], [143, 153], [154, 172], [172, 173]]}
{"doc_key": "ai-test-299", "ner": [[4, 4, "organisation"], [11, 11, "field"], [13, 13, "organisation"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 11, 11, "general-affiliation", "field_of_study", false, false], [4, 4, 16, 17, "part-of", "", false, false], [13, 13, 4, 4, "role", "admits_E2_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["W", "maju", "2016", "roku", "NtechLab", "zosta\u0142", "dopuszczony", "do", "oficjalnego", "testowania", "technologii", "biometrycznej", "przez", "NIST", "w\u015br\u00f3d", "trzech", "rosyjskich", "firm", "."], "sentence-detokenized": "W maju 2016 roku NtechLab zosta\u0142 dopuszczony do oficjalnego testowania technologii biometrycznej przez NIST w\u015br\u00f3d trzech rosyjskich firm.", "token2charspan": [[0, 1], [2, 6], [7, 11], [12, 16], [17, 25], [26, 32], [33, 44], [45, 47], [48, 59], [60, 70], [71, 82], [83, 96], [97, 102], [103, 107], [108, 113], [114, 120], [121, 131], [132, 136], [136, 137]]}
{"doc_key": "ai-test-300", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["Jednak", "liczby", "zmiennoprzecinkowe", "maj\u0105", "tylko", "pewn\u0105", "precyzj\u0119", "matematyczn\u0105", "."], "sentence-detokenized": "Jednak liczby zmiennoprzecinkowe maj\u0105 tylko pewn\u0105 precyzj\u0119 matematyczn\u0105.", "token2charspan": [[0, 6], [7, 13], [14, 32], [33, 37], [38, 43], [44, 49], [50, 58], [59, 71], [71, 72]]}
{"doc_key": "ai-test-301", "ner": [[6, 6, "organisation"], [10, 15, "conference"], [17, 17, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 10, 15, "role", "contributes_to", false, false], [17, 17, 10, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["W", "ci\u0105gu", "2015", "roku", "wiele", "referat\u00f3w", "SenseTime", "zosta\u0142o", "przyj\u0119tych", "na", "Konferencj\u0119", "Widzenia", "Komputerowego", "i", "Rozpoznawania", "Wzorc\u00f3w", "(", "CVPR", ")", "."], "sentence-detokenized": "W ci\u0105gu 2015 roku wiele referat\u00f3w SenseTime zosta\u0142o przyj\u0119tych na Konferencj\u0119 Widzenia Komputerowego i Rozpoznawania Wzorc\u00f3w (CVPR).", "token2charspan": [[0, 1], [2, 7], [8, 12], [13, 17], [18, 23], [24, 33], [34, 43], [44, 51], [52, 62], [63, 65], [66, 77], [78, 86], [87, 100], [101, 102], [103, 116], [117, 124], [125, 126], [126, 130], [130, 131], [131, 132]]}
{"doc_key": "ai-test-302", "ner": [[4, 6, "task"], [8, 8, "task"], [11, 12, "task"], [14, 17, "task"], [20, 20, "field"], [22, 24, "misc"], [26, 32, "conference"], [40, 42, "misc"], [44, 45, "conference"], [59, 61, "misc"], [63, 63, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[4, 6, 20, 20, "part-of", "task_part_of_field", false, false], [8, 8, 4, 6, "named", "", false, false], [11, 12, 20, 20, "part-of", "task_part_of_field", false, false], [14, 17, 11, 12, "named", "", false, false], [22, 24, 26, 32, "temporal", "", false, false], [40, 42, 44, 45, "temporal", "", false, false], [59, 61, 63, 63, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Wsp\u00f3\u0142tworzy\u0142", "optymalne", "algorytmy", "dla", "Structure", "From", "Motion", "(", "SFM", ",", "czyli", "Visual", "SLAM", ",", "jednoczesna", "lokalizacja", "i", "odwzorowanie", ",", "w", "Robotics", ";", "Best", "Paper", "Award", "na", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "1998", ")", ",", "scharakteryzowa\u0142", "jego", "niejednoznaczno\u015bci", "(", "David", "Marr", "Prize", "na", "ICCV", "1999", ")", ",", "scharakteryzowa\u0142", "tak\u017ce", "identyfikowalno\u015b\u0107", "i", "obserwowalno\u015b\u0107", "fuzji", "sensor\u00f3w", "wizualno", "-", "inercyjnych", "(", "Best", "Paper", "Award", "na", "Robotics", "2015", ")", "."], "sentence-detokenized": "Wsp\u00f3\u0142tworzy\u0142 optymalne algorytmy dla Structure From Motion (SFM, czyli Visual SLAM, jednoczesna lokalizacja i odwzorowanie, w Robotics; Best Paper Award na Conference on Computer Vision and Pattern Recognition 1998), scharakteryzowa\u0142 jego niejednoznaczno\u015bci (David Marr Prize na ICCV 1999), scharakteryzowa\u0142 tak\u017ce identyfikowalno\u015b\u0107 i obserwowalno\u015b\u0107 fuzji sensor\u00f3w wizualno-inercyjnych (Best Paper Award na Robotics 2015).", "token2charspan": [[0, 12], [13, 22], [23, 32], [33, 36], [37, 46], [47, 51], [52, 58], [59, 60], [60, 63], [63, 64], [65, 70], [71, 77], [78, 82], [82, 83], [84, 95], [96, 107], [108, 109], [110, 122], [122, 123], [124, 125], [126, 134], [134, 135], [136, 140], [141, 146], [147, 152], [153, 155], [156, 166], [167, 169], [170, 178], [179, 185], [186, 189], [190, 197], [198, 209], [210, 214], [214, 215], [215, 216], [217, 233], [234, 238], [239, 257], [258, 259], [259, 264], [265, 269], [270, 275], [276, 278], [279, 283], [284, 288], [288, 289], [289, 290], [291, 307], [308, 313], [314, 331], [332, 333], [334, 348], [349, 354], [355, 363], [364, 372], [372, 373], [373, 384], [385, 386], [386, 390], [391, 396], [397, 402], [403, 405], [406, 414], [415, 419], [419, 420], [420, 421]]}
{"doc_key": "ai-test-303", "ner": [[0, 3, "researcher"], [4, 4, "organisation"], [6, 6, "organisation"], [8, 14, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Stephen", "H", ".", "Muggleton", "FBCS", ",", "FIET", ",", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ","], "sentence-detokenized": "Stephen H. Muggleton FBCS, FIET, Association for the Advancement of Artificial Intelligence,", "token2charspan": [[0, 7], [8, 9], [9, 10], [11, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 44], [45, 48], [49, 52], [53, 64], [65, 67], [68, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-304", "ner": [[0, 1, "task"], [6, 7, "field"], [9, 10, "field"], [12, 12, "field"], [17, 18, "task"], [20, 21, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 6, 7, "part-of", "task_part_of_field", false, false], [0, 1, 9, 10, "part-of", "task_part_of_field", false, false], [0, 1, 12, 12, "part-of", "task_part_of_field", false, false], [0, 1, 17, 18, "part-of", "", false, false], [0, 1, 20, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Wykrywanie", "kraw\u0119dzi", "jest", "podstawowym", "narz\u0119dziem", "w", "przetwarzaniu", "obraz\u00f3w", ",", "widzeniu", "maszynowym", "i", "komputerowym", ",", "szczeg\u00f3lnie", "w", "obszarach", "wykrywania", "cech", "i", "ekstrakcji", "cech", "."], "sentence-detokenized": "Wykrywanie kraw\u0119dzi jest podstawowym narz\u0119dziem w przetwarzaniu obraz\u00f3w, widzeniu maszynowym i komputerowym, szczeg\u00f3lnie w obszarach wykrywania cech i ekstrakcji cech.", "token2charspan": [[0, 10], [11, 19], [20, 24], [25, 36], [37, 47], [48, 49], [50, 63], [64, 71], [71, 72], [73, 81], [82, 92], [93, 94], [95, 107], [107, 108], [109, 120], [121, 122], [123, 132], [133, 143], [144, 148], [149, 150], [151, 161], [162, 166], [166, 167]]}
{"doc_key": "ai-test-305", "ner": [[6, 7, "misc"], [25, 29, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Przyk\u0142adem", "mo\u017ce", "by\u0107", "zmienna", "taka", "jak", "temperatura", "zewn\u0119trzna", "(", "mathtemp", "/", "math", ")", ",", "kt\u00f3ra", "w", "danej", "aplikacji", "mo\u017ce", "by\u0107", "zapisana", "z", "dok\u0142adno\u015bci\u0105", "do", "kilku", "miejsc", "po", "przecinku", "(", "w", "zale\u017cno\u015bci", "od", "aparatury", "pomiarowej", ")", "."], "sentence-detokenized": "Przyk\u0142adem mo\u017ce by\u0107 zmienna taka jak temperatura zewn\u0119trzna (mathtemp / math), kt\u00f3ra w danej aplikacji mo\u017ce by\u0107 zapisana z dok\u0142adno\u015bci\u0105 do kilku miejsc po przecinku (w zale\u017cno\u015bci od aparatury pomiarowej).", "token2charspan": [[0, 10], [11, 15], [16, 19], [20, 27], [28, 32], [33, 36], [37, 48], [49, 59], [60, 61], [61, 69], [70, 71], [72, 76], [76, 77], [77, 78], [79, 84], [85, 86], [87, 92], [93, 102], [103, 107], [108, 111], [112, 120], [121, 122], [123, 135], [136, 138], [139, 144], [145, 151], [152, 154], [155, 164], [165, 166], [166, 167], [168, 178], [179, 181], [182, 191], [192, 202], [202, 203], [203, 204]]}
{"doc_key": "ai-test-306", "ner": [[3, 4, "person"], [6, 7, "person"], [9, 10, "person"], [17, 18, "person"], [21, 21, "misc"], [25, 25, "misc"], [26, 27, "person"], [30, 30, "organisation"], [31, 32, "person"], [35, 35, "organisation"], [36, 37, "person"], [42, 42, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[26, 27, 21, 21, "part-of", "", false, false], [26, 27, 25, 25, "role", "", false, false], [31, 32, 30, 30, "role", "", false, false], [36, 37, 35, 35, "role", "youtuber", false, false], [42, 42, 36, 37, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Powracaj\u0105cymi", "s\u0119dziami", "s\u0105", "Fon", "Davis", ",", "Jessica", "Chobot", "i", "Leland", "Melvin", ",", "a", "tak\u017ce", "go\u015bcinnie", "wyst\u0119puj\u0105cy", "aktorzy", "Clark", "Gregg", ",", "gospodarz", "MythBusters", "i", "by\u0142y", "budowniczy", "Battlebots", "Adam", "Savage", ",", "zawodnik", "NFL", "Vernon", "Davis", "oraz", "gwiazda", "YouTube", "Michael", "Stevens", "a.k", ".", "a", ".", "Vsauce", "."], "sentence-detokenized": "Powracaj\u0105cymi s\u0119dziami s\u0105 Fon Davis, Jessica Chobot i Leland Melvin, a tak\u017ce go\u015bcinnie wyst\u0119puj\u0105cy aktorzy Clark Gregg, gospodarz MythBusters i by\u0142y budowniczy Battlebots Adam Savage, zawodnik NFL Vernon Davis oraz gwiazda YouTube Michael Stevens a.k.a. Vsauce.", "token2charspan": [[0, 13], [14, 22], [23, 25], [26, 29], [30, 35], [35, 36], [37, 44], [45, 51], [52, 53], [54, 60], [61, 67], [67, 68], [69, 70], [71, 76], [77, 86], [87, 98], [99, 106], [107, 112], [113, 118], [118, 119], [120, 129], [130, 141], [142, 143], [144, 148], [149, 159], [160, 170], [171, 175], [176, 182], [182, 183], [184, 192], [193, 196], [197, 203], [204, 209], [210, 214], [215, 222], [223, 230], [231, 238], [239, 246], [247, 250], [250, 251], [251, 252], [252, 253], [254, 260], [260, 261]]}
{"doc_key": "ai-test-307", "ner": [[11, 13, "algorithm"], [15, 17, "algorithm"], [19, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 13, 19, 19, "part-of", "", false, false], [15, 17, 19, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Jednak", "metody", "te", "nigdy", "nie", "wygra\u0142y", "z", "technologi\u0105", "niejednolitego", ",", "wewn\u0119trznego", "modelu", "mieszanki", "gaussowskiej", "/", "ukrytego", "modelu", "Markowa", "(", "GMM-HMM", ")", "opartego", "na", "generatywnych", "modelach", "mowy", "trenowanych", "dyskryminacyjnie", "."], "sentence-detokenized": "Jednak metody te nigdy nie wygra\u0142y z technologi\u0105 niejednolitego, wewn\u0119trznego modelu mieszanki gaussowskiej / ukrytego modelu Markowa (GMM-HMM) opartego na generatywnych modelach mowy trenowanych dyskryminacyjnie.", "token2charspan": [[0, 6], [7, 13], [14, 16], [17, 22], [23, 26], [27, 34], [35, 36], [37, 48], [49, 63], [63, 64], [65, 77], [78, 84], [85, 94], [95, 107], [108, 109], [110, 118], [119, 125], [126, 133], [134, 135], [135, 142], [142, 143], [144, 152], [153, 155], [156, 169], [170, 178], [179, 183], [184, 195], [196, 212], [212, 213]]}
{"doc_key": "ai-test-308", "ner": [[4, 4, "product"], [6, 7, "programlang"], [9, 9, "programlang"], [11, 11, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Pakiety", "oprogramowania", "takie", "jak", "MATLAB", ",", "GNU", "Octave", ",", "Scilab", "i", "SciPy", "zapewniaj\u0105", "wygodne", "sposoby", "zastosowania", "tych", "r\u00f3\u017cnych", "metod", "."], "sentence-detokenized": "Pakiety oprogramowania takie jak MATLAB, GNU Octave, Scilab i SciPy zapewniaj\u0105 wygodne sposoby zastosowania tych r\u00f3\u017cnych metod.", "token2charspan": [[0, 7], [8, 22], [23, 28], [29, 32], [33, 39], [39, 40], [41, 44], [45, 51], [51, 52], [53, 59], [60, 61], [62, 67], [68, 78], [79, 86], [87, 94], [95, 107], [108, 112], [113, 120], [121, 126], [126, 127]]}
{"doc_key": "ai-test-309", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [8, 9, "task"], [17, 18, "researcher"], [20, 21, "university"], [23, 24, "researcher"], [26, 29, "organisation"], [31, 31, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 8, 9, "related-to", "", false, false], [0, 2, 17, 18, "origin", "", false, false], [0, 2, 23, 24, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [17, 18, 20, 21, "physical", "", false, false], [17, 18, 20, 21, "role", "", false, false], [23, 24, 26, 29, "physical", "", false, false], [23, 24, 26, 29, "role", "", false, false], [31, 31, 26, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Linear", "predictive", "coding", "(", "LPC", ")", ",", "algorytm", "przetwarzania", "mowy", ",", "zosta\u0142", "po", "raz", "pierwszy", "zaproponowany", "przez", "Fumitad\u0119", "Itakur\u0119", "z", "Uniwersytetu", "Nagoya", "i", "Shuzo", "Saito", "z", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "w", "1966", "roku", "."], "sentence-detokenized": "Linear predictive coding (LPC), algorytm przetwarzania mowy, zosta\u0142 po raz pierwszy zaproponowany przez Fumitad\u0119 Itakur\u0119 z Uniwersytetu Nagoya i Shuzo Saito z Nippon Telegraph and Telephone (NTT) w 1966 roku.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [30, 31], [32, 40], [41, 54], [55, 59], [59, 60], [61, 67], [68, 70], [71, 74], [75, 83], [84, 97], [98, 103], [104, 112], [113, 120], [121, 122], [123, 135], [136, 142], [143, 144], [145, 150], [151, 156], [157, 158], [159, 165], [166, 175], [176, 179], [180, 189], [190, 191], [191, 194], [194, 195], [196, 197], [198, 202], [203, 207], [207, 208]]}
{"doc_key": "ai-test-310", "ner": [[10, 16, "conference"], [18, 18, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 18, 10, 16, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["W", "2006", "roku", ",", "z", "okazji", "25-lecia", "algorytmu", ",", "na", "Mi\u0119dzynarodowej", "Konferencji", "Widzenia", "Komputerowego", "i", "Rozpoznawania", "Wzorc\u00f3w", "(", "CVPR", ")", "zorganizowano", "warsztaty", "podsumowuj\u0105ce", "najnowszy", "wk\u0142ad", "i", "wariacje", "na", "temat", "oryginalnego", "algorytmu", ",", "maj\u0105ce", "na", "celu", "g\u0142\u00f3wnie", "popraw\u0119", "szybko\u015bci", "dzia\u0142ania", "algorytmu", ",", "odporno\u015bci", "i", "dok\u0142adno\u015bci", "szacowanego", "rozwi\u0105zania", "oraz", "zmniejszenie", "zale\u017cno\u015bci", "od", "sta\u0142ych", "definiowanych", "przez", "u\u017cytkownika", "."], "sentence-detokenized": "W 2006 roku, z okazji 25-lecia algorytmu, na Mi\u0119dzynarodowej Konferencji Widzenia Komputerowego i Rozpoznawania Wzorc\u00f3w (CVPR) zorganizowano warsztaty podsumowuj\u0105ce najnowszy wk\u0142ad i wariacje na temat oryginalnego algorytmu, maj\u0105ce na celu g\u0142\u00f3wnie popraw\u0119 szybko\u015bci dzia\u0142ania algorytmu, odporno\u015bci i dok\u0142adno\u015bci szacowanego rozwi\u0105zania oraz zmniejszenie zale\u017cno\u015bci od sta\u0142ych definiowanych przez u\u017cytkownika.", "token2charspan": [[0, 1], [2, 6], [7, 11], [11, 12], [13, 14], [15, 21], [22, 30], [31, 40], [40, 41], [42, 44], [45, 60], [61, 72], [73, 81], [82, 95], [96, 97], [98, 111], [112, 119], [120, 121], [121, 125], [125, 126], [127, 140], [141, 150], [151, 164], [165, 174], [175, 180], [181, 182], [183, 191], [192, 194], [195, 200], [201, 213], [214, 223], [223, 224], [225, 231], [232, 234], [235, 239], [240, 247], [248, 255], [256, 265], [266, 275], [276, 285], [285, 286], [287, 297], [298, 299], [300, 311], [312, 323], [324, 335], [336, 340], [341, 353], [354, 364], [365, 367], [368, 375], [376, 389], [390, 395], [396, 407], [407, 408]]}
{"doc_key": "ai-test-311", "ner": [[3, 5, "university"], [7, 9, "organisation"], [11, 13, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Cz\u0142onkowie", "wyjechali", "na", "Uniwersytet", "w", "Debreczynie", ",", "W\u0119giersk\u0105", "Akademi\u0119", "Nauk", ",", "Uniwersytet", "E\u00f6tv\u00f6s", "Lor\u00e1nd", "itd", "."], "sentence-detokenized": "Cz\u0142onkowie wyjechali na Uniwersytet w Debreczynie, W\u0119giersk\u0105 Akademi\u0119 Nauk, Uniwersytet E\u00f6tv\u00f6s Lor\u00e1nd itd.", "token2charspan": [[0, 10], [11, 20], [21, 23], [24, 35], [36, 37], [38, 49], [49, 50], [51, 60], [61, 69], [70, 74], [74, 75], [76, 87], [88, 94], [95, 101], [102, 105], [105, 106]]}
{"doc_key": "ai-test-312", "ner": [[2, 2, "algorithm"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 15, 16, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Aby", "rozszerzy\u0107", "SVM", "na", "przypadki", ",", "w", "kt\u00f3rych", "dane", "nie", "s\u0105", "liniowo", "separowalne", ",", "wprowadzamy", "funkcj\u0119", "straty", ","], "sentence-detokenized": "Aby rozszerzy\u0107 SVM na przypadki, w kt\u00f3rych dane nie s\u0105 liniowo separowalne, wprowadzamy funkcj\u0119 straty,", "token2charspan": [[0, 3], [4, 14], [15, 18], [19, 21], [22, 31], [31, 32], [33, 34], [35, 42], [43, 47], [48, 51], [52, 54], [55, 62], [63, 74], [74, 75], [76, 87], [88, 95], [96, 102], [102, 103]]}
{"doc_key": "ai-test-313", "ner": [[0, 0, "programlang"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 11, 12, "origin", "", false, false], [0, 0, 14, 15, "origin", "", false, false], [0, 0, 17, 18, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Logo", "to", "edukacyjny", "j\u0119zyk", "programowania", ",", "zaprojektowany", "w", "1967", "roku", "przez", "Wally'ego", "Feurzeiga", ",", "Seymoura", "Paperta", "i", "Cynthi\u0119", "Solomon", "."], "sentence-detokenized": "Logo to edukacyjny j\u0119zyk programowania, zaprojektowany w 1967 roku przez Wally'ego Feurzeiga, Seymoura Paperta i Cynthi\u0119 Solomon.", "token2charspan": [[0, 4], [5, 7], [8, 18], [19, 24], [25, 38], [38, 39], [40, 54], [55, 56], [57, 61], [62, 66], [67, 72], [73, 82], [83, 92], [92, 93], [94, 102], [103, 110], [111, 112], [113, 120], [121, 128], [128, 129]]}
{"doc_key": "ai-test-314", "ner": [[0, 2, "organisation"], [6, 13, "organisation"], [15, 19, "location"], [21, 21, "location"], [23, 24, "location"], [31, 34, "product"], [42, 45, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 6, 13, "role", "works_for", false, false], [6, 13, 15, 19, "physical", "", false, false], [15, 19, 21, 21, "physical", "", false, false], [21, 21, 23, 24, "physical", "", false, false], [31, 34, 0, 2, "origin", "", false, false], [42, 45, 31, 34, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Eyring", "Research", "Institute", "by\u0142", "instrumentem", "dla", "U", ".", "S", ".", "Air", "Force", "Missile", "Directorate", "w", "Hill", "Air", "Force", "Base", "w", "pobli\u017cu", "Ogden", ",", "Utah", "do", "produkcji", "w", "najwy\u017cszej", "tajemnicy", "wojskowej", ",", "Intelligent", "Systems", "Technology", "Software", ",", "kt\u00f3ry", "by\u0142", "podstaw\u0105", "do", "p\u00f3\u017aniej", "nazwanego", "Reagan", "Star", "Wars", "programu", "."], "sentence-detokenized": "Eyring Research Institute by\u0142 instrumentem dla U.S. Air Force Missile Directorate w Hill Air Force Base w pobli\u017cu Ogden, Utah do produkcji w najwy\u017cszej tajemnicy wojskowej, Intelligent Systems Technology Software, kt\u00f3ry by\u0142 podstaw\u0105 do p\u00f3\u017aniej nazwanego Reagan Star Wars programu.", "token2charspan": [[0, 6], [7, 15], [16, 25], [26, 29], [30, 42], [43, 46], [47, 48], [48, 49], [49, 50], [50, 51], [52, 55], [56, 61], [62, 69], [70, 81], [82, 83], [84, 88], [89, 92], [93, 98], [99, 103], [104, 105], [106, 113], [114, 119], [119, 120], [121, 125], [126, 128], [129, 138], [139, 140], [141, 151], [152, 161], [162, 171], [171, 172], [173, 184], [185, 192], [193, 203], [204, 212], [212, 213], [214, 219], [220, 223], [224, 232], [233, 235], [236, 243], [244, 253], [254, 260], [261, 265], [266, 270], [271, 279], [279, 280]]}
{"doc_key": "ai-test-315", "ner": [[7, 7, "field"], [16, 19, "researcher"], [21, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Przez", "dziesi\u0119ciolecia", "bada\u0142", "i", "rozwija\u0142", "powstaj\u0105ce", "dziedziny", "informatyki", "od", "kompilatora", ",", "j\u0119zyk\u00f3w", "programowania", "i", "architektury", "system\u00f3w", "John", "F", ".", "Sowa", "i", "John", "Zachman", "(", "1992", ")", "."], "sentence-detokenized": "Przez dziesi\u0119ciolecia bada\u0142 i rozwija\u0142 powstaj\u0105ce dziedziny informatyki od kompilatora, j\u0119zyk\u00f3w programowania i architektury system\u00f3w John F. Sowa i John Zachman (1992).", "token2charspan": [[0, 5], [6, 21], [22, 27], [28, 29], [30, 38], [39, 49], [50, 59], [60, 71], [72, 74], [75, 86], [86, 87], [88, 95], [96, 109], [110, 111], [112, 124], [125, 133], [134, 138], [139, 140], [140, 141], [142, 146], [147, 148], [149, 153], [154, 161], [162, 163], [163, 167], [167, 168], [168, 169]]}
{"doc_key": "ai-test-316", "ner": [[0, 5, "algorithm"], [6, 6, "algorithm"], [8, 9, "algorithm"], [14, 15, "field"], [17, 18, "field"], [23, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 6, 0, 5, "named", "", false, false], [8, 9, 0, 5, "named", "", false, false], [14, 15, 0, 5, "usage", "", false, false], [17, 18, 0, 5, "usage", "", false, false], [23, 25, 0, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Operator", "Sobela", ",", "zwany", "czasem", "operatorem", "Sobela-Feldmana", "lub", "filtrem", "Sobela", ",", "jest", "stosowany", "w", "przetwarzaniu", "obraz\u00f3w", "i", "wizji", "komputerowej", ",", "szczeg\u00f3lnie", "w", "ramach", "algorytm\u00f3w", "wykrywania", "kraw\u0119dzi", ",", "gdzie", "tworzy", "obraz", "podkre\u015blaj\u0105cy", "kraw\u0119dzie", "."], "sentence-detokenized": "Operator Sobela, zwany czasem operatorem Sobela-Feldmana lub filtrem Sobela, jest stosowany w przetwarzaniu obraz\u00f3w i wizji komputerowej, szczeg\u00f3lnie w ramach algorytm\u00f3w wykrywania kraw\u0119dzi, gdzie tworzy obraz podkre\u015blaj\u0105cy kraw\u0119dzie.", "token2charspan": [[0, 8], [9, 15], [15, 16], [17, 22], [23, 29], [30, 40], [41, 56], [57, 60], [61, 68], [69, 75], [75, 76], [77, 81], [82, 91], [92, 93], [94, 107], [108, 115], [116, 117], [118, 123], [124, 136], [136, 137], [138, 149], [150, 151], [152, 158], [159, 169], [170, 180], [181, 189], [189, 190], [191, 196], [197, 203], [204, 209], [210, 223], [224, 233], [233, 234]]}
{"doc_key": "ai-test-317", "ner": [[0, 0, "algorithm"], [3, 4, "field"], [12, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 3, 4, "compare", "", false, false], [0, 0, 3, 4, "type-of", "", false, false], [0, 0, 12, 12, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["LDA", "jest", "algorytmem", "uczenia", "nadzorowanego", ",", "kt\u00f3ry", "wykorzystuje", "etykiety", "danych", ",", "natomiast", "PCA", "jest", "algorytmem", "uczenia", "ignoruj\u0105cym", "etykiety", "."], "sentence-detokenized": "LDA jest algorytmem uczenia nadzorowanego, kt\u00f3ry wykorzystuje etykiety danych, natomiast PCA jest algorytmem uczenia ignoruj\u0105cym etykiety.", "token2charspan": [[0, 3], [4, 8], [9, 19], [20, 27], [28, 41], [41, 42], [43, 48], [49, 61], [62, 70], [71, 77], [77, 78], [79, 88], [89, 92], [93, 97], [98, 108], [109, 116], [117, 128], [129, 137], [137, 138]]}
{"doc_key": "ai-test-318", "ner": [[5, 5, "algorithm"], [7, 9, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Inne", "liniowe", "algorytmy", "klasyfikacji", "to", "Winnow", ",", "maszyna", "wektor\u00f3w", "wsparcia", "i", "regresja", "logistyczna", "."], "sentence-detokenized": "Inne liniowe algorytmy klasyfikacji to Winnow, maszyna wektor\u00f3w wsparcia i regresja logistyczna.", "token2charspan": [[0, 4], [5, 12], [13, 22], [23, 35], [36, 38], [39, 45], [45, 46], [47, 54], [55, 63], [64, 72], [73, 74], [75, 83], [84, 95], [95, 96]]}
{"doc_key": "ai-test-319", "ner": [[0, 0, "product"], [6, 8, "programlang"], [17, 19, "product"], [21, 21, "programlang"], [23, 23, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 8, "general-affiliation", "", true, false], [0, 0, 17, 19, "general-affiliation", "", true, false], [0, 0, 21, 21, "general-affiliation", "", true, false], [0, 0, 23, 23, "general-affiliation", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["VTK", "sk\u0142ada", "si\u0119", "z", "biblioteki", "klas", "C", "+", "+", "i", "kilku", "interpretowanych", "warstw", "interfejsu", ",", "w", "tym", "Tcl", "/", "Tk", ",", "Java", "i", "Python", "."], "sentence-detokenized": "VTK sk\u0142ada si\u0119 z biblioteki klas C + + i kilku interpretowanych warstw interfejsu, w tym Tcl / Tk, Java i Python.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 16], [17, 27], [28, 32], [33, 34], [35, 36], [37, 38], [39, 40], [41, 46], [47, 63], [64, 70], [71, 81], [81, 82], [83, 84], [85, 88], [89, 92], [93, 94], [95, 97], [97, 98], [99, 103], [104, 105], [106, 112], [112, 113]]}
{"doc_key": "ai-test-320", "ner": [[10, 12, "task"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["R\u00f3wnie\u017c", "tekst", "powsta\u0142y", "w", "wyniku", "przetwarzania", "mowy", "spontanicznej", "za", "pomoc\u0105", "automatycznego", "rozpoznawania", "mowy", "oraz", "tekst", "drukowany", "lub", "pisany", "r\u0119cznie", "za", "pomoc\u0105", "optycznego", "rozpoznawania", "znak\u00f3w", "zawiera", "szumy", "przetwarzania", "."], "sentence-detokenized": "R\u00f3wnie\u017c tekst powsta\u0142y w wyniku przetwarzania mowy spontanicznej za pomoc\u0105 automatycznego rozpoznawania mowy oraz tekst drukowany lub pisany r\u0119cznie za pomoc\u0105 optycznego rozpoznawania znak\u00f3w zawiera szumy przetwarzania.", "token2charspan": [[0, 7], [8, 13], [14, 22], [23, 24], [25, 31], [32, 45], [46, 50], [51, 64], [65, 67], [68, 74], [75, 89], [90, 103], [104, 108], [109, 113], [114, 119], [120, 129], [130, 133], [134, 140], [141, 148], [149, 151], [152, 158], [159, 169], [170, 183], [184, 190], [191, 198], [199, 204], [205, 218], [218, 219]]}
{"doc_key": "ai-test-321", "ner": [[0, 0, "researcher"], [7, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 7, 7, "role", "directs_development_of", false, false]], "relations_mapping_to_source": [0], "sentence": ["Miller", "napisa\u0142", "kilka", "ksi\u0105\u017cek", "i", "kierowa\u0142", "rozwojem", "WordNetu", ",", "internetowej", "bazy", "danych", "o", "powi\u0105zaniach", "s\u0142\u00f3w", ",", "kt\u00f3r\u0105", "mo\u017cna", "wykorzysta\u0107", "w", "programach", "komputerowych", "."], "sentence-detokenized": "Miller napisa\u0142 kilka ksi\u0105\u017cek i kierowa\u0142 rozwojem WordNetu, internetowej bazy danych o powi\u0105zaniach s\u0142\u00f3w, kt\u00f3r\u0105 mo\u017cna wykorzysta\u0107 w programach komputerowych.", "token2charspan": [[0, 6], [7, 14], [15, 20], [21, 28], [29, 30], [31, 39], [40, 48], [49, 57], [57, 58], [59, 71], [72, 76], [77, 83], [84, 85], [86, 98], [99, 103], [103, 104], [105, 110], [111, 116], [117, 128], [129, 130], [131, 141], [142, 155], [155, 156]]}
{"doc_key": "ai-test-322", "ner": [[1, 1, "field"], [6, 8, "organisation"], [11, 11, "country"], [13, 14, "person"], [16, 18, "person"], [20, 21, "person"], [23, 24, "person"], [26, 27, "country"], [29, 32, "location"], [33, 34, "misc"], [35, 36, "person"], [38, 39, "person"], [41, 41, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[6, 8, 11, 11, "physical", "", false, false], [13, 14, 26, 27, "physical", "", false, false], [16, 18, 26, 27, "physical", "", false, false], [20, 21, 26, 27, "physical", "", false, false], [23, 24, 26, 27, "physical", "", false, false], [29, 32, 1, 1, "general-affiliation", "", false, false], [29, 32, 35, 36, "artifact", "", false, false], [33, 34, 35, 36, "named", "", false, false], [38, 39, 41, 41, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Wsp\u00f3\u0142czesne", "automaty", "reprezentowane", "s\u0105", "przez", "prace", "Cabaret", "Mechanical", "Theatre", "w", "Wielkiej", "Brytanii", ",", "Dug", "North", "i", "Chomick", "+", "Meder", ",", "Arthur", "Ganson", ",", "Joe", "Jones", "w", "Stanach", "Zjednoczonych", ",", "Le", "D\u00e9fenseur", "du", "Temps", "francuskiego", "artysty", "Jacquesa", "Monestiera", "oraz", "Fran\u00e7ois", "Junoda", "w", "Szwajcarii", "."], "sentence-detokenized": "Wsp\u00f3\u0142czesne automaty reprezentowane s\u0105 przez prace Cabaret Mechanical Theatre w Wielkiej Brytanii, Dug North i Chomick + Meder, Arthur Ganson, Joe Jones w Stanach Zjednoczonych, Le D\u00e9fenseur du Temps francuskiego artysty Jacquesa Monestiera oraz Fran\u00e7ois Junoda w Szwajcarii.", "token2charspan": [[0, 11], [12, 20], [21, 35], [36, 38], [39, 44], [45, 50], [51, 58], [59, 69], [70, 77], [78, 79], [80, 88], [89, 97], [97, 98], [99, 102], [103, 108], [109, 110], [111, 118], [119, 120], [121, 126], [126, 127], [128, 134], [135, 141], [141, 142], [143, 146], [147, 152], [153, 154], [155, 162], [163, 176], [176, 177], [178, 180], [181, 190], [191, 193], [194, 199], [200, 212], [213, 220], [221, 229], [230, 240], [241, 245], [246, 254], [255, 261], [262, 263], [264, 274], [274, 275]]}
{"doc_key": "ai-test-323", "ner": [[0, 0, "product"], [23, 23, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 23, 23, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MATLAB", "zawiera", "standardowe", "p\u0119tle", "codefor", "/", "code", "i", "codewhile", "/", "code", ",", "ale", "(", "podobnie", "jak", "w", "innych", "podobnych", "aplikacjach", ",", "takich", "jak", "R", ")", ",", "u\u017cywanie", "notacji", "wektorowej", "jest", "zach\u0119cane", "i", "cz\u0119sto", "jest", "szybsze", "do", "wykonania", "."], "sentence-detokenized": "MATLAB zawiera standardowe p\u0119tle codefor / code i codewhile / code, ale (podobnie jak w innych podobnych aplikacjach, takich jak R), u\u017cywanie notacji wektorowej jest zach\u0119cane i cz\u0119sto jest szybsze do wykonania.", "token2charspan": [[0, 6], [7, 14], [15, 26], [27, 32], [33, 40], [41, 42], [43, 47], [48, 49], [50, 59], [60, 61], [62, 66], [66, 67], [68, 71], [72, 73], [73, 81], [82, 85], [86, 87], [88, 94], [95, 104], [105, 116], [116, 117], [118, 124], [125, 128], [129, 130], [130, 131], [131, 132], [133, 141], [142, 149], [150, 160], [161, 165], [166, 175], [176, 177], [178, 184], [185, 189], [190, 197], [198, 200], [201, 210], [210, 211]]}
{"doc_key": "ai-test-324", "ner": [[3, 3, "researcher"], [8, 11, "conference"], [17, 18, "field"], [20, 26, "misc"], [28, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 20, 26, "win-defeat", "", false, false], [3, 3, 28, 37, "win-defeat", "", false, false], [20, 26, 8, 11, "temporal", "", false, false], [20, 26, 17, 18, "topic", "", false, false], [28, 37, 8, 11, "temporal", "", false, false], [28, 37, 17, 18, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["W", "2007", "roku", "Pausch", "otrzyma\u0142", "dwie", "nagrody", "od", "Association", "for", "Computing", "Machinery", "za", "swoje", "osi\u0105gni\u0119cia", "w", "dziedzinie", "edukacji", "informatycznej", ":", "Karl", "V", ".", "Karlstrom", "Outstanding", "Educator", "Award", "oraz", "ACM", "SIGCSE", "Award", "for", "Outstanding", "Contributions", "to", "Computer", "Science", "Education", "."], "sentence-detokenized": "W 2007 roku Pausch otrzyma\u0142 dwie nagrody od Association for Computing Machinery za swoje osi\u0105gni\u0119cia w dziedzinie edukacji informatycznej: Karl V. Karlstrom Outstanding Educator Award oraz ACM SIGCSE Award for Outstanding Contributions to Computer Science Education.", "token2charspan": [[0, 1], [2, 6], [7, 11], [12, 18], [19, 27], [28, 32], [33, 40], [41, 43], [44, 55], [56, 59], [60, 69], [70, 79], [80, 82], [83, 88], [89, 100], [101, 102], [103, 113], [114, 122], [123, 137], [137, 138], [139, 143], [144, 145], [145, 146], [147, 156], [157, 168], [169, 177], [178, 183], [184, 188], [189, 192], [193, 199], [200, 205], [206, 209], [210, 221], [222, 235], [236, 238], [239, 247], [248, 255], [256, 265], [265, 266]]}
{"doc_key": "ai-test-325", "ner": [[3, 3, "person"], [8, 8, "product"], [7, 7, "product"], [17, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 8, 8, "role", "sells", false, false], [8, 8, 7, 7, "general-affiliation", "", false, false], [8, 8, 17, 18, "physical", "shipped_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["W", "1960", "roku", "Devol", "osobi\u015bcie", "sprzeda\u0142", "pierwszego", "robota", "Unimate", ",", "kt\u00f3ry", "w", "1961", "roku", "zosta\u0142", "wys\u0142any", "do", "General", "Motors", "."], "sentence-detokenized": "W 1960 roku Devol osobi\u015bcie sprzeda\u0142 pierwszego robota Unimate, kt\u00f3ry w 1961 roku zosta\u0142 wys\u0142any do General Motors.", "token2charspan": [[0, 1], [2, 6], [7, 11], [12, 17], [18, 27], [28, 36], [37, 47], [48, 54], [55, 62], [62, 63], [64, 69], [70, 71], [72, 76], [77, 81], [82, 88], [89, 96], [97, 99], [100, 107], [108, 114], [114, 115]]}
{"doc_key": "ai-test-326", "ner": [[0, 1, "algorithm"], [6, 8, "field"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 13, 0, 1, "usage", "", false, false], [12, 13, 6, 8, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Sieci", "semantyczne", "s\u0105", "wykorzystywane", "w", "aplikacjach", "przetwarzania", "j\u0119zyka", "naturalnego", ",", "takich", "jak", "parsowanie", "semantyczne", "."], "sentence-detokenized": "Sieci semantyczne s\u0105 wykorzystywane w aplikacjach przetwarzania j\u0119zyka naturalnego, takich jak parsowanie semantyczne.", "token2charspan": [[0, 5], [6, 17], [18, 20], [21, 35], [36, 37], [38, 49], [50, 63], [64, 70], [71, 82], [82, 83], [84, 90], [91, 94], [95, 105], [106, 117], [117, 118]]}
{"doc_key": "ai-test-327", "ner": [[3, 4, "field"], [6, 7, "field"], [9, 10, "task"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 24, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[6, 7, 3, 4, "usage", "", false, false], [9, 10, 3, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Niekt\u00f3re", "udane", "zastosowania", "g\u0142\u0119bokiego", "uczenia", "to", "wizja", "komputerowa", "i", "rozpoznawanie", "mowy", ".", "Honglak", "Lee", ",", "Roger", "Grosse", ",", "Rajesh", "Ranganath", ",", "Andrew", "Y", ".", "Ng", "."], "sentence-detokenized": "Niekt\u00f3re udane zastosowania g\u0142\u0119bokiego uczenia to wizja komputerowa i rozpoznawanie mowy. Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng.", "token2charspan": [[0, 8], [9, 14], [15, 27], [28, 38], [39, 46], [47, 49], [50, 55], [56, 67], [68, 69], [70, 83], [84, 88], [88, 89], [90, 97], [98, 101], [101, 102], [103, 108], [109, 115], [115, 116], [117, 123], [124, 133], [133, 134], [135, 141], [142, 143], [143, 144], [145, 147], [147, 148]]}
{"doc_key": "ai-test-328", "ner": [[2, 6, "product"], [11, 11, "misc"], [14, 14, "misc"], [19, 19, "product"], [23, 24, "task"], [26, 29, "task"], [30, 30, "task"], [32, 34, "field"], [36, 39, "task"], [41, 42, "field"], [44, 45, "task"], [47, 48, "task"], [50, 52, "task"], [54, 56, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[2, 6, 11, 11, "physical", "travels_to", false, false], [2, 6, 14, 14, "physical", "travels_to", false, false], [19, 19, 2, 6, "part-of", "", false, false], [19, 19, 2, 6, "role", "maintains", false, false], [19, 19, 23, 24, "related-to", "has_ability_to", false, false], [19, 19, 26, 29, "related-to", "has_ability_to", false, false], [19, 19, 30, 30, "related-to", "has_ability_to", false, false], [19, 19, 32, 34, "related-to", "has_ability_to", false, false], [19, 19, 36, 39, "related-to", "has_ability_to", false, false], [19, 19, 41, 42, "related-to", "has_ability_to", false, false], [19, 19, 44, 45, "related-to", "has_ability_to", false, false], [19, 19, 47, 48, "related-to", "has_ability_to", false, false], [19, 19, 50, 52, "related-to", "has_ability_to", false, false], [19, 19, 54, 56, "related-to", "has_ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Opr\u00f3cz", "utrzymywania", "system\u00f3w", "statku", "kosmicznego", "Discovery", "One", "podczas", "misji", "mi\u0119dzyplanetarnej", "na", "Jowisza", "(", "lub", "Saturna", "w", "powie\u015bci", ")", ",", "HAL", "jest", "zdolny", "do", "syntezy", "mowy", ",", "rozpoznawania", "mowy", ",", "rozpoznawania", "twarzy", ",", "przetwarzania", "j\u0119zyka", "naturalnego", ",", "czytania", "z", "ruchu", "warg", ",", "doceniania", "sztuki", ",", "Affective", "computing", ",", "automatycznego", "rozumowania", ",", "pilotowania", "statku", "kosmicznego", "i", "gry", "w", "szachy", "."], "sentence-detokenized": "Opr\u00f3cz utrzymywania system\u00f3w statku kosmicznego Discovery One podczas misji mi\u0119dzyplanetarnej na Jowisza (lub Saturna w powie\u015bci), HAL jest zdolny do syntezy mowy, rozpoznawania mowy, rozpoznawania twarzy, przetwarzania j\u0119zyka naturalnego, czytania z ruchu warg, doceniania sztuki, Affective computing, automatycznego rozumowania, pilotowania statku kosmicznego i gry w szachy.", "token2charspan": [[0, 6], [7, 19], [20, 28], [29, 35], [36, 47], [48, 57], [58, 61], [62, 69], [70, 75], [76, 93], [94, 96], [97, 104], [105, 106], [106, 109], [110, 117], [118, 119], [120, 128], [128, 129], [129, 130], [131, 134], [135, 139], [140, 146], [147, 149], [150, 157], [158, 162], [162, 163], [164, 177], [178, 182], [182, 183], [184, 197], [198, 204], [204, 205], [206, 219], [220, 226], [227, 238], [238, 239], [240, 248], [249, 250], [251, 256], [257, 261], [261, 262], [263, 273], [274, 280], [280, 281], [282, 291], [292, 301], [301, 302], [303, 317], [318, 329], [329, 330], [331, 342], [343, 349], [350, 361], [362, 363], [364, 367], [368, 369], [370, 376], [376, 377]]}
{"doc_key": "ai-test-329", "ner": [[0, 1, "researcher"], [4, 4, "country"], [6, 7, "country"], [10, 11, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 4, "physical", "", false, false], [0, 1, 6, 7, "physical", "", false, false], [0, 1, 10, 11, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dr", "Julesz", "wyemigrowa\u0142", "z", "W\u0119gier", "do", "Stan\u00f3w", "Zjednoczonych", "po", "inwazji", "sowieckiej", "w", "1956", "roku", "."], "sentence-detokenized": "Dr Julesz wyemigrowa\u0142 z W\u0119gier do Stan\u00f3w Zjednoczonych po inwazji sowieckiej w 1956 roku.", "token2charspan": [[0, 2], [3, 9], [10, 21], [22, 23], [24, 30], [31, 33], [34, 40], [41, 54], [55, 57], [58, 65], [66, 76], [77, 78], [79, 83], [84, 88], [88, 89]]}
{"doc_key": "ai-test-330", "ner": [[2, 3, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Funkcje", "aktywacji", "funkcji", "sigmoidalnych", "wykorzystuj\u0105", "drug\u0105", "nieliniowo\u015b\u0107", "dla", "du\u017cych", "danych", "wej\u015bciowych", ":", "math", "phi", "(", "v", "_", "i", ")", "=", "(", "1", "+", "exp", "(", "-v", "_", "i", ")", ")", "^", "{", "-1", "}", "/", "math", "."], "sentence-detokenized": "Funkcje aktywacji funkcji sigmoidalnych wykorzystuj\u0105 drug\u0105 nieliniowo\u015b\u0107 dla du\u017cych danych wej\u015bciowych: math phi (v _ i) = (1 + exp (-v _ i)) ^ {-1} / math.", "token2charspan": [[0, 7], [8, 17], [18, 25], [26, 39], [40, 52], [53, 58], [59, 71], [72, 75], [76, 82], [83, 89], [90, 101], [101, 102], [103, 107], [108, 111], [112, 113], [113, 114], [115, 116], [117, 118], [118, 119], [120, 121], [122, 123], [123, 124], [125, 126], [127, 130], [131, 132], [132, 134], [135, 136], [137, 138], [138, 139], [139, 140], [141, 142], [143, 144], [144, 146], [146, 147], [148, 149], [150, 154], [154, 155]]}
{"doc_key": "ai-test-331", "ner": [[12, 15, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Prawdopodobie\u0144stwa", "te", "s\u0105", "wykorzystywane", "do", "okre\u015blenia", ",", "co", "jest", "celem", "przy", "u\u017cyciu", "decyzji", "o", "maksymalnym", "prawdopodobie\u0144stwie", "."], "sentence-detokenized": "Prawdopodobie\u0144stwa te s\u0105 wykorzystywane do okre\u015blenia, co jest celem przy u\u017cyciu decyzji o maksymalnym prawdopodobie\u0144stwie.", "token2charspan": [[0, 18], [19, 21], [22, 24], [25, 39], [40, 42], [43, 53], [53, 54], [55, 57], [58, 62], [63, 68], [69, 73], [74, 80], [81, 88], [89, 90], [91, 102], [103, 122], [122, 123]]}
{"doc_key": "ai-test-332", "ner": [[6, 8, "university"], [15, 17, "university"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["W", "1984", "roku", "przeni\u00f3s\u0142", "si\u0119", "na", "Uniwersytet", "w", "Konstancji", ",", "a", "w", "1990", "roku", "na", "Uniwersytet", "w", "Salzburgu", "."], "sentence-detokenized": "W 1984 roku przeni\u00f3s\u0142 si\u0119 na Uniwersytet w Konstancji, a w 1990 roku na Uniwersytet w Salzburgu.", "token2charspan": [[0, 1], [2, 6], [7, 11], [12, 21], [22, 25], [26, 28], [29, 40], [41, 42], [43, 53], [53, 54], [55, 56], [57, 58], [59, 63], [64, 68], [69, 71], [72, 83], [84, 85], [86, 95], [95, 96]]}
{"doc_key": "ai-test-333", "ner": [[6, 7, "metrics"], [9, 11, "metrics"], [13, 15, "metrics"], [17, 17, "metrics"], [19, 20, "metrics"], [22, 24, "metrics"], [26, 29, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 11, 6, 7, "origin", "based_on", false, false], [13, 15, 6, 7, "origin", "based_on", false, false], [17, 17, 6, 7, "origin", "based_on", false, false], [19, 20, 6, 7, "origin", "based_on", false, false], [22, 24, 6, 7, "origin", "based_on", false, false], [26, 29, 6, 7, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Niekt\u00f3re", "popularne", "funkcje", "fitness", "oparte", "na", "macierzy", "konfuzji", "obejmuj\u0105", "czu\u0142o\u015b\u0107", "/", "specyficzno\u015b\u0107", ",", "recall", "/", "precyzj\u0119", ",", "F-measure", ",", "podobie\u0144stwo", "Jaccard", ",", "wsp\u00f3\u0142czynnik", "korelacji", "Matthews", "i", "macierz", "koszt\u00f3w", "/", "zysk\u00f3w", ",", "kt\u00f3ra", "\u0142\u0105czy", "koszty", "i", "zyski", "przypisane", "do", "4", "r\u00f3\u017cnych", "typ\u00f3w", "klasyfikacji", "."], "sentence-detokenized": "Niekt\u00f3re popularne funkcje fitness oparte na macierzy konfuzji obejmuj\u0105 czu\u0142o\u015b\u0107 / specyficzno\u015b\u0107, recall / precyzj\u0119, F-measure, podobie\u0144stwo Jaccard, wsp\u00f3\u0142czynnik korelacji Matthews i macierz koszt\u00f3w / zysk\u00f3w, kt\u00f3ra \u0142\u0105czy koszty i zyski przypisane do 4 r\u00f3\u017cnych typ\u00f3w klasyfikacji.", "token2charspan": [[0, 8], [9, 18], [19, 26], [27, 34], [35, 41], [42, 44], [45, 53], [54, 62], [63, 71], [72, 79], [80, 81], [82, 95], [95, 96], [97, 103], [104, 105], [106, 114], [114, 115], [116, 125], [125, 126], [127, 139], [140, 147], [147, 148], [149, 161], [162, 171], [172, 180], [181, 182], [183, 190], [191, 198], [199, 200], [201, 207], [207, 208], [209, 214], [215, 220], [221, 227], [228, 229], [230, 235], [236, 246], [247, 249], [250, 251], [252, 259], [260, 265], [266, 278], [278, 279]]}
{"doc_key": "ai-test-334", "ner": [[7, 7, "product"], [9, 9, "product"], [11, 11, "product"], [13, 13, "product"], [15, 16, "programlang"], [28, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[28, 30, 7, 7, "part-of", "", false, false], [28, 30, 9, 9, "part-of", "", false, false], [28, 30, 11, 11, "part-of", "", false, false], [28, 30, 13, 13, "part-of", "", false, false], [28, 30, 15, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Popularne", "\u015brodowiska", "programowania", "numerycznego", ",", "takie", "jak", "MATLAB", ",", "SciLab", ",", "NumPy", ",", "Sklearn", "i", "j\u0119zyk", "R", ",", "dostarczaj\u0105", "niekt\u00f3re", "z", "prostszych", "technik", "ekstrakcji", "cech", "(", "np", ".", "analiza", "sk\u0142adowych", "g\u0142\u00f3wnych", ")", "poprzez", "wbudowane", "polecenia", "."], "sentence-detokenized": "Popularne \u015brodowiska programowania numerycznego, takie jak MATLAB, SciLab, NumPy, Sklearn i j\u0119zyk R, dostarczaj\u0105 niekt\u00f3re z prostszych technik ekstrakcji cech (np. analiza sk\u0142adowych g\u0142\u00f3wnych) poprzez wbudowane polecenia.", "token2charspan": [[0, 9], [10, 20], [21, 34], [35, 47], [47, 48], [49, 54], [55, 58], [59, 65], [65, 66], [67, 73], [73, 74], [75, 80], [80, 81], [82, 89], [90, 91], [92, 97], [98, 99], [99, 100], [101, 112], [113, 121], [122, 123], [124, 134], [135, 142], [143, 153], [154, 158], [159, 160], [160, 162], [162, 163], [164, 171], [172, 182], [183, 191], [191, 192], [193, 200], [201, 210], [211, 220], [220, 221]]}
{"doc_key": "ai-test-335", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Roboty", "przemys\u0142owe", "zosta\u0142y", "wdro\u017cone", "do", "wsp\u00f3\u0142pracy", "z", "cz\u0142owiekiem", "w", "celu", "realizacji", "zada\u0144", "zwi\u0105zanych", "z", "produkcj\u0105", "przemys\u0142ow\u0105", "."], "sentence-detokenized": "Roboty przemys\u0142owe zosta\u0142y wdro\u017cone do wsp\u00f3\u0142pracy z cz\u0142owiekiem w celu realizacji zada\u0144 zwi\u0105zanych z produkcj\u0105 przemys\u0142ow\u0105.", "token2charspan": [[0, 6], [7, 18], [19, 26], [27, 35], [36, 38], [39, 49], [50, 51], [52, 63], [64, 65], [66, 70], [71, 81], [82, 87], [88, 98], [99, 100], [101, 110], [111, 122], [122, 123]]}
{"doc_key": "ai-test-336", "ner": [[6, 6, "field"], [8, 11, "researcher"], [19, 20, "field"], [24, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[6, 6, 19, 20, "related-to", "", false, false], [6, 6, 24, 24, "related-to", "", false, false], [8, 11, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 2, 3], "sentence": ["W", "pierwszej", "opublikowanej", "pracy", "na", "temat", "CG", ",", "John", "F", ".", "Sowa", "zastosowa\u0142", "je", "do", "szerokiego", "zakresu", "temat\u00f3w", "w", "sztucznej", "inteligencji", ",", "informatyce", "i", "kognitywistyce", "."], "sentence-detokenized": "W pierwszej opublikowanej pracy na temat CG, John F. Sowa zastosowa\u0142 je do szerokiego zakresu temat\u00f3w w sztucznej inteligencji, informatyce i kognitywistyce.", "token2charspan": [[0, 1], [2, 11], [12, 25], [26, 31], [32, 34], [35, 40], [41, 43], [43, 44], [45, 49], [50, 51], [51, 52], [53, 57], [58, 68], [69, 71], [72, 74], [75, 85], [86, 93], [94, 101], [102, 103], [104, 113], [114, 126], [126, 127], [128, 139], [140, 141], [142, 156], [156, 157]]}
{"doc_key": "ai-test-337", "ner": [[0, 0, "metrics"], [5, 5, "metrics"], [8, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 5, 5, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "r\u00f3\u017cni", "si\u0119", "r\u00f3wnie\u017c", "od", "BLEU", "w", "obliczaniu", "kary", "za", "zwi\u0119z\u0142o\u015b\u0107", ",", "poniewa\u017c", "ma\u0142e", "r\u00f3\u017cnice", "w", "d\u0142ugo\u015bci", "t\u0142umaczenia", "nie", "maj\u0105", "a\u017c", "tak", "du\u017cego", "wp\u0142ywu", "na", "og\u00f3lny", "wynik", "."], "sentence-detokenized": "NIST r\u00f3\u017cni si\u0119 r\u00f3wnie\u017c od BLEU w obliczaniu kary za zwi\u0119z\u0142o\u015b\u0107, poniewa\u017c ma\u0142e r\u00f3\u017cnice w d\u0142ugo\u015bci t\u0142umaczenia nie maj\u0105 a\u017c tak du\u017cego wp\u0142ywu na og\u00f3lny wynik.", "token2charspan": [[0, 4], [5, 10], [11, 14], [15, 22], [23, 25], [26, 30], [31, 32], [33, 43], [44, 48], [49, 51], [52, 61], [61, 62], [63, 71], [72, 76], [77, 84], [85, 86], [87, 95], [96, 107], [108, 111], [112, 116], [117, 119], [120, 123], [124, 130], [131, 137], [138, 140], [141, 147], [148, 153], [153, 154]]}
{"doc_key": "ai-test-338", "ner": [[0, 4, "misc"], [13, 13, "conference"], [15, 17, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 13, 13, "temporal", "", false, false], [0, 4, 15, 17, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["IJCAI", "Award", "for", "Research", "Excellence", "to", "nagroda", "przyznawana", "co", "dwa", "lata", "na", "konferencji", "IJCAI", "badaczom", "sztucznej", "inteligencji", "w", "uznaniu", "doskona\u0142o\u015bci", "ich", "kariery", "."], "sentence-detokenized": "IJCAI Award for Research Excellence to nagroda przyznawana co dwa lata na konferencji IJCAI badaczom sztucznej inteligencji w uznaniu doskona\u0142o\u015bci ich kariery.", "token2charspan": [[0, 5], [6, 11], [12, 15], [16, 24], [25, 35], [36, 38], [39, 46], [47, 58], [59, 61], [62, 65], [66, 70], [71, 73], [74, 85], [86, 91], [92, 100], [101, 110], [111, 123], [124, 125], [126, 133], [134, 146], [147, 150], [151, 158], [158, 159]]}
{"doc_key": "ai-test-339", "ner": [[0, 0, "researcher"], [6, 6, "conference"], [15, 23, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 6, 6, "role", "", false, false], [0, 0, 15, 23, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lenat", "by\u0142", "jednym", "z", "pierwszych", "cz\u0142onk\u00f3w", "AAAI", "i", "jest", "jedyn\u0105", "osob\u0105", ",", "kt\u00f3ra", "zasiada", "w", "naukowych", "radach", "doradczych", "zar\u00f3wno", "Microsoftu", ",", "jak", "i", "Apple", "."], "sentence-detokenized": "Lenat by\u0142 jednym z pierwszych cz\u0142onk\u00f3w AAAI i jest jedyn\u0105 osob\u0105, kt\u00f3ra zasiada w naukowych radach doradczych zar\u00f3wno Microsoftu, jak i Apple.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 18], [19, 29], [30, 38], [39, 43], [44, 45], [46, 50], [51, 57], [58, 63], [63, 64], [65, 70], [71, 78], [79, 80], [81, 90], [91, 97], [98, 108], [109, 116], [117, 127], [127, 128], [129, 132], [133, 134], [135, 140], [140, 141]]}
{"doc_key": "ai-test-340", "ner": [[0, 0, "algorithm"], [6, 7, "misc"], [11, 13, "metrics"], [19, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 7, "related-to", "minimise", false, false], [11, 13, 6, 7, "type-of", "", false, false], [19, 19, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Autoenkodery", "s\u0105", "szkolone", "w", "celu", "zminimalizowania", "b\u0142\u0119d\u00f3w", "rekonstrukcji", "(", "takich", "jak", "Mean", "squared", "error", ")", ",", "cz\u0119sto", "okre\u015blanych", "jako", "strata", ":"], "sentence-detokenized": "Autoenkodery s\u0105 szkolone w celu zminimalizowania b\u0142\u0119d\u00f3w rekonstrukcji (takich jak Mean squared error), cz\u0119sto okre\u015blanych jako strata:", "token2charspan": [[0, 12], [13, 15], [16, 24], [25, 26], [27, 31], [32, 48], [49, 55], [56, 69], [70, 71], [71, 77], [78, 81], [82, 86], [87, 94], [95, 100], [100, 101], [101, 102], [103, 109], [110, 121], [122, 126], [127, 133], [133, 134]]}
{"doc_key": "ai-test-341", "ner": [[20, 22, "misc"], [26, 26, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[26, 26, 20, 22, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Alternatyw\u0105", "dla", "wykorzystania", "definicji", "jest", "rozwa\u017cenie", "og\u00f3lnego", "pokrewie\u0144stwa", "sens\u00f3w", "s\u0142\u00f3w", "i", "obliczenie", "podobie\u0144stwa", "ka\u017cdej", "pary", "sens\u00f3w", "s\u0142\u00f3w", "na", "podstawie", "danej", "bazy", "wiedzy", "leksykalnej", ",", "takiej", "jak", "WordNet", "."], "sentence-detokenized": "Alternatyw\u0105 dla wykorzystania definicji jest rozwa\u017cenie og\u00f3lnego pokrewie\u0144stwa sens\u00f3w s\u0142\u00f3w i obliczenie podobie\u0144stwa ka\u017cdej pary sens\u00f3w s\u0142\u00f3w na podstawie danej bazy wiedzy leksykalnej, takiej jak WordNet.", "token2charspan": [[0, 11], [12, 15], [16, 29], [30, 39], [40, 44], [45, 55], [56, 64], [65, 78], [79, 85], [86, 90], [91, 92], [93, 103], [104, 116], [117, 123], [124, 128], [129, 135], [136, 140], [141, 143], [144, 153], [154, 159], [160, 164], [165, 171], [172, 183], [183, 184], [185, 191], [192, 195], [196, 203], [203, 204]]}
{"doc_key": "ai-test-342", "ner": [[0, 0, "algorithm"], [7, 11, "researcher"], [21, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 7, 11, "origin", "", false, false], [7, 11, 21, 22, "role", "work_based_on_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["TD-Lambda", "to", "algorytm", "uczenia", "si\u0119", "wynaleziony", "przez", "Richarda", "S", ".", "Suttona", "na", "podstawie", "wcze\u015bniejszych", "prac", "nad", "uczeniem", "si\u0119", "r\u00f3\u017cnic", "czasowych", "autorstwa", "Arthura", "Samuela", "."], "sentence-detokenized": "TD-Lambda to algorytm uczenia si\u0119 wynaleziony przez Richarda S. Suttona na podstawie wcze\u015bniejszych prac nad uczeniem si\u0119 r\u00f3\u017cnic czasowych autorstwa Arthura Samuela.", "token2charspan": [[0, 9], [10, 12], [13, 21], [22, 29], [30, 33], [34, 45], [46, 51], [52, 60], [61, 62], [62, 63], [64, 71], [72, 74], [75, 84], [85, 99], [100, 104], [105, 108], [109, 117], [118, 121], [122, 128], [129, 138], [139, 148], [149, 156], [157, 164], [164, 165]]}
{"doc_key": "ai-test-343", "ner": [[1, 2, "field"], [4, 4, "field"], [6, 7, "task"], [12, 13, "task"], [15, 15, "task"], [19, 20, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 7, 1, 2, "part-of", "task_part_of_field", false, false], [6, 7, 4, 4, "part-of", "task_part_of_field", false, false], [12, 13, 6, 7, "named", "", false, false], [15, 15, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["W", "eksploracji", "danych", "i", "statystyce", ",", "hierarchiczne", "grupowanie", "(", "zwane", "r\u00f3wnie\u017c", "hierarchiczn\u0105", "analiz\u0105", "skupie\u0144", "lub", "HCA", ")", "jest", "metod\u0105", "analizy", "skupie\u0144", ",", "kt\u00f3ra", "d\u0105\u017cy", "do", "zbudowania", "hierarchii", "skupie\u0144", "."], "sentence-detokenized": "W eksploracji danych i statystyce, hierarchiczne grupowanie (zwane r\u00f3wnie\u017c hierarchiczn\u0105 analiz\u0105 skupie\u0144 lub HCA) jest metod\u0105 analizy skupie\u0144, kt\u00f3ra d\u0105\u017cy do zbudowania hierarchii skupie\u0144.", "token2charspan": [[0, 1], [2, 13], [14, 20], [21, 22], [23, 33], [33, 34], [35, 48], [49, 59], [60, 61], [61, 66], [67, 74], [75, 88], [89, 96], [97, 104], [105, 108], [109, 112], [112, 113], [114, 118], [119, 125], [126, 133], [134, 141], [141, 142], [143, 148], [149, 153], [154, 156], [157, 167], [168, 178], [179, 186], [186, 187]]}
{"doc_key": "ai-test-344", "ner": [[1, 1, "algorithm"], [7, 8, "field"], [10, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 7, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Poj\u0119cie", "dekonwolucji", "jest", "szeroko", "stosowane", "w", "technikach", "przetwarzania", "sygna\u0142\u00f3w", "i", "obraz\u00f3w", "."], "sentence-detokenized": "Poj\u0119cie dekonwolucji jest szeroko stosowane w technikach przetwarzania sygna\u0142\u00f3w i obraz\u00f3w.", "token2charspan": [[0, 7], [8, 20], [21, 25], [26, 33], [34, 43], [44, 45], [46, 56], [57, 70], [71, 79], [80, 81], [82, 89], [89, 90]]}
{"doc_key": "ai-test-345", "ner": [[0, 1, "algorithm"], [17, 18, "misc"], [22, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 17, 18, "related-to", "enhances", false, false], [0, 1, 17, 18, "related-to", "reduces", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Mapy", "poznawcze", "s\u0142u\u017c\u0105", "konstruowaniu", "i", "gromadzeniu", "wiedzy", "przestrzennej", ",", "pozwalaj\u0105c", "na", "wizualizacj\u0119", "obraz\u00f3w", "umys\u0142u", "w", "celu", "zmniejszenia", "obci\u0105\u017cenia", "poznawczego", ",", "zwi\u0119kszenia", "mo\u017cliwo\u015bci", "przypominania", "i", "uczenia", "si\u0119", "informacji", "."], "sentence-detokenized": "Mapy poznawcze s\u0142u\u017c\u0105 konstruowaniu i gromadzeniu wiedzy przestrzennej, pozwalaj\u0105c na wizualizacj\u0119 obraz\u00f3w umys\u0142u w celu zmniejszenia obci\u0105\u017cenia poznawczego, zwi\u0119kszenia mo\u017cliwo\u015bci przypominania i uczenia si\u0119 informacji.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 34], [35, 36], [37, 48], [49, 55], [56, 69], [69, 70], [71, 81], [82, 84], [85, 97], [98, 105], [106, 112], [113, 114], [115, 119], [120, 132], [133, 143], [144, 155], [155, 156], [157, 168], [169, 179], [180, 193], [194, 195], [196, 203], [204, 207], [208, 218], [218, 219]]}
{"doc_key": "ai-test-346", "ner": [[8, 8, "programlang"], [10, 12, "programlang"], [14, 14, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": [",", "zazwyczaj", "zapewniaj\u0105c", "wi\u0105zania", "do", "j\u0119zyk\u00f3w", "takich", "jak", "Python", ",", "C", "+", "+", ",", "Java", ")", "."], "sentence-detokenized": ", zazwyczaj zapewniaj\u0105c wi\u0105zania do j\u0119zyk\u00f3w takich jak Python, C ++, Java).", "token2charspan": [[0, 1], [2, 11], [12, 23], [24, 32], [33, 35], [36, 43], [44, 50], [51, 54], [55, 61], [61, 62], [63, 64], [65, 66], [66, 67], [67, 68], [69, 73], [73, 74], [74, 75]]}
{"doc_key": "ai-test-347", "ner": [[0, 3, "product"], [5, 5, "product"], [15, 16, "task"], [22, 24, "task"], [30, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 15, 16, "usage", "", false, false], [0, 3, 22, 24, "usage", "", false, false], [0, 3, 30, 33, "usage", "", false, false], [5, 5, 0, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Interfejs", "g\u0142osowo", "-", "u\u017cytkowy", "(", "VUI", ")", "umo\u017cliwia", "m\u00f3wion\u0105", "interakcj\u0119", "cz\u0142owieka", "z", "komputerem", ",", "wykorzystuj\u0105c", "rozpoznawanie", "mowy", "do", "rozumienia", "polece\u0144", "s\u0142ownych", "i", "odpowiedzi", "na", "pytania", ",", "a", "tak\u017ce", "zazwyczaj", "przetwarzanie", "tekstu", "na", "mow\u0119", "w", "celu", "odtworzenia", "odpowiedzi", "."], "sentence-detokenized": "Interfejs g\u0142osowo-u\u017cytkowy (VUI) umo\u017cliwia m\u00f3wion\u0105 interakcj\u0119 cz\u0142owieka z komputerem, wykorzystuj\u0105c rozpoznawanie mowy do rozumienia polece\u0144 s\u0142ownych i odpowiedzi na pytania, a tak\u017ce zazwyczaj przetwarzanie tekstu na mow\u0119 w celu odtworzenia odpowiedzi.", "token2charspan": [[0, 9], [10, 17], [17, 18], [18, 26], [27, 28], [28, 31], [31, 32], [33, 42], [43, 50], [51, 61], [62, 71], [72, 73], [74, 84], [84, 85], [86, 99], [100, 113], [114, 118], [119, 121], [122, 132], [133, 140], [141, 149], [150, 151], [152, 162], [163, 165], [166, 173], [173, 174], [175, 176], [177, 182], [183, 192], [193, 206], [207, 213], [214, 216], [217, 221], [222, 223], [224, 228], [229, 240], [241, 251], [251, 252]]}
{"doc_key": "ai-test-348", "ner": [[0, 0, "programlang"], [2, 3, "misc"], [6, 6, "programlang"], [12, 15, "researcher"], [17, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 2, 3, "general-affiliation", "is_a", false, false], [0, 0, 6, 6, "general-affiliation", "made_with", false, false], [0, 0, 12, 15, "origin", "", false, false], [12, 15, 17, 18, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Jess", "to", "silnik", "regu\u0142", "dla", "platformy", "Java", ",", "kt\u00f3ry", "zosta\u0142", "opracowany", "przez", "Ernesta", "Friedmana", "-", "Hilla", "z", "Sandia", "National", "."], "sentence-detokenized": "Jess to silnik regu\u0142 dla platformy Java, kt\u00f3ry zosta\u0142 opracowany przez Ernesta Friedmana-Hilla z Sandia National.", "token2charspan": [[0, 4], [5, 7], [8, 14], [15, 20], [21, 24], [25, 34], [35, 39], [39, 40], [41, 46], [47, 53], [54, 64], [65, 70], [71, 78], [79, 88], [88, 89], [89, 94], [95, 96], [97, 103], [104, 112], [112, 113]]}
{"doc_key": "ai-test-349", "ner": [[2, 3, "algorithm"], [18, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 18, 18, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["W", "przypadku", "perceptron\u00f3w", "wielowarstwowych", ",", "gdzie", "istnieje", "warstwa", "ukryta", ",", "nale\u017cy", "stosowa\u0107", "bardziej", "wyrafinowane", "algorytmy", ",", "takie", "jak", "backpropagacja", "."], "sentence-detokenized": "W przypadku perceptron\u00f3w wielowarstwowych, gdzie istnieje warstwa ukryta, nale\u017cy stosowa\u0107 bardziej wyrafinowane algorytmy, takie jak backpropagacja.", "token2charspan": [[0, 1], [2, 11], [12, 24], [25, 41], [41, 42], [43, 48], [49, 57], [58, 65], [66, 72], [72, 73], [74, 80], [81, 89], [90, 98], [99, 111], [112, 121], [121, 122], [123, 128], [129, 132], [133, 147], [147, 148]]}
{"doc_key": "ai-test-350", "ner": [[4, 5, "product"], [0, 3, "product"], [8, 11, "algorithm"], [16, 17, "field"], [21, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 4, 5, "part-of", "", false, false], [0, 3, 8, 11, "usage", "", false, true], [8, 11, 16, 17, "related-to", "performs", false, false], [21, 27, 16, 17, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Neuronowy", "system", "t\u0142umaczenia", "maszynowego", "Google", "Translate", "wykorzystuje", "du\u017c\u0105", "end-to-end", "sztuczn\u0105", "sie\u0107", "neuronow\u0105", ",", "kt\u00f3ra", "pr\u00f3buje", "przeprowadzi\u0107", "g\u0142\u0119bokie", "uczenie", ",", "w", "szczeg\u00f3lno\u015bci", "sieci", "pami\u0119ci", "kr\u00f3tkotrwa\u0142ej", "o", "d\u0142ugim", "czasie", "trwania", "."], "sentence-detokenized": "Neuronowy system t\u0142umaczenia maszynowego Google Translate wykorzystuje du\u017c\u0105 end-to-end sztuczn\u0105 sie\u0107 neuronow\u0105, kt\u00f3ra pr\u00f3buje przeprowadzi\u0107 g\u0142\u0119bokie uczenie, w szczeg\u00f3lno\u015bci sieci pami\u0119ci kr\u00f3tkotrwa\u0142ej o d\u0142ugim czasie trwania.", "token2charspan": [[0, 9], [10, 16], [17, 28], [29, 40], [41, 47], [48, 57], [58, 70], [71, 75], [76, 86], [87, 95], [96, 100], [101, 110], [110, 111], [112, 117], [118, 125], [126, 139], [140, 148], [149, 156], [156, 157], [158, 159], [160, 173], [174, 179], [180, 187], [188, 201], [202, 203], [204, 210], [211, 217], [218, 225], [225, 226]]}
{"doc_key": "ai-test-351", "ner": [[17, 17, "researcher"], [19, 19, "researcher"], [21, 21, "researcher"], [23, 24, "researcher"], [26, 27, "researcher"], [29, 29, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["R\u00f3\u017cne", "metody", "s\u0142u\u017c\u0105ce", "temu", "celowi", "zosta\u0142y", "opracowane", "w", "latach", "80", ".", "i", "na", "pocz\u0105tku", "90", ".", "przez", "Werbosa", ",", "Williamsa", ",", "Robinsona", ",", "J\u00fcrgena", "Schmidhubera", ",", "Seppa", "Hochreitera", ",", "Pearlmuttera", "i", "innych", "."], "sentence-detokenized": "R\u00f3\u017cne metody s\u0142u\u017c\u0105ce temu celowi zosta\u0142y opracowane w latach 80. i na pocz\u0105tku 90. przez Werbosa, Williamsa, Robinsona, J\u00fcrgena Schmidhubera, Seppa Hochreitera, Pearlmuttera i innych.", "token2charspan": [[0, 5], [6, 12], [13, 20], [21, 25], [26, 32], [33, 40], [41, 51], [52, 53], [54, 60], [61, 63], [63, 64], [65, 66], [67, 69], [70, 78], [79, 81], [81, 82], [83, 88], [89, 96], [96, 97], [98, 107], [107, 108], [109, 118], [118, 119], [120, 127], [128, 140], [140, 141], [142, 147], [148, 159], [159, 160], [161, 173], [174, 175], [176, 182], [182, 183]]}
{"doc_key": "ai-test-352", "ner": [[1, 1, "organisation"], [2, 3, "organisation"], [9, 9, "organisation"], [14, 15, "task"], [19, 19, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 9, 9, "role", "licenses_from", false, false], [2, 3, 1, 1, "named", "", false, false], [19, 19, 1, 1, "origin", "", false, false], [19, 19, 14, 15, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["|", "Apple", "Apple", "Inc", ".", "pierwotnie", "licencjonowa\u0142o", "oprogramowanie", "od", "Nuance", ",", "aby", "zapewni\u0107", "mo\u017cliwo\u015b\u0107", "rozpoznawania", "mowy", "swojemu", "cyfrowemu", "asystentowi", "Siri", "."], "sentence-detokenized": "| Apple Apple Inc. pierwotnie licencjonowa\u0142o oprogramowanie od Nuance, aby zapewni\u0107 mo\u017cliwo\u015b\u0107 rozpoznawania mowy swojemu cyfrowemu asystentowi Siri.", "token2charspan": [[0, 1], [2, 7], [8, 13], [14, 17], [17, 18], [19, 29], [30, 44], [45, 59], [60, 62], [63, 69], [69, 70], [71, 74], [75, 83], [84, 93], [94, 107], [108, 112], [113, 120], [121, 130], [131, 142], [143, 147], [147, 148]]}
{"doc_key": "ai-test-353", "ner": [[0, 0, "organisation"], [3, 4, "misc"], [7, 8, "person"], [12, 13, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 3, 4, "role", "releases_movies_in_genre", false, false], [7, 8, 0, 0, "role", "directs_for", false, false], [12, 13, 0, 0, "role", "directs_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Columbia", "wyda\u0142a", "kilka", "western\u00f3w", "3D", "wyprodukowanych", "przez", "Sama", "Katzmana", "i", "wyre\u017cyserowanych", "przez", "Williama", "Castle'a", "."], "sentence-detokenized": "Columbia wyda\u0142a kilka western\u00f3w 3D wyprodukowanych przez Sama Katzmana i wyre\u017cyserowanych przez Williama Castle'a.", "token2charspan": [[0, 8], [9, 15], [16, 21], [22, 31], [32, 34], [35, 50], [51, 56], [57, 61], [62, 70], [71, 72], [73, 89], [90, 95], [96, 104], [105, 113], [113, 114]]}
{"doc_key": "ai-test-354", "ner": [[6, 11, "field"], [8, 8, "field"], [10, 11, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Zawiera", "wiedz\u0119", "i", "badania", "z", "zakresu", "informatyki", ",", "lingwistyki", "i", "in\u017cynierii", "komputerowej", "."], "sentence-detokenized": "Zawiera wiedz\u0119 i badania z zakresu informatyki, lingwistyki i in\u017cynierii komputerowej.", "token2charspan": [[0, 7], [8, 14], [15, 16], [17, 24], [25, 26], [27, 34], [35, 46], [46, 47], [48, 59], [60, 61], [62, 72], [73, 85], [85, 86]]}
{"doc_key": "ai-test-355", "ner": [[5, 5, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Poni\u017cej", "znajduje", "si\u0119", "przyk\u0142ad", "kodu", "R", ":"], "sentence-detokenized": "Poni\u017cej znajduje si\u0119 przyk\u0142ad kodu R:", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 29], [30, 34], [35, 36], [36, 37]]}
{"doc_key": "ai-test-356", "ner": [[0, 1, "metrics"], [5, 7, "metrics"], [9, 9, "metrics"], [12, 14, "metrics"], [16, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 7, "part-of", "plotted_into", false, false], [0, 1, 12, 14, "part-of", "plotted_into", false, false], [9, 9, 5, 7, "named", "", false, false], [16, 16, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Krzywa", "ROC", "powstaje", "poprzez", "wykre\u015blenie", "wska\u017anika", "TRUE", "positive", "(", "TPR", ")", "wzgl\u0119dem", "wska\u017anika", "FALSE", "positive", "(", "FPR", ")", "przy", "r\u00f3\u017cnych", "ustawieniach", "prog\u00f3w", "."], "sentence-detokenized": "Krzywa ROC powstaje poprzez wykre\u015blenie wska\u017anika TRUE positive (TPR) wzgl\u0119dem wska\u017anika FALSE positive (FPR) przy r\u00f3\u017cnych ustawieniach prog\u00f3w.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 27], [28, 39], [40, 49], [50, 54], [55, 63], [64, 65], [65, 68], [68, 69], [70, 78], [79, 88], [89, 94], [95, 103], [104, 105], [105, 108], [108, 109], [110, 114], [115, 122], [123, 135], [136, 142], [142, 143]]}
{"doc_key": "ai-test-357", "ner": [[6, 7, "field"], [10, 11, "researcher"], [13, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 6, 7, "related-to", "researches_field", false, false], [13, 14, 6, 7, "related-to", "researches_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Stagnacja", "bada\u0144", "nast\u0105pi\u0142a", "po", "badaniach", "nad", "uczeniem", "maszynowym", "prowadzonych", "przez", "Marvina", "Minsky'ego", "i", "Seymoura", "Paperta", "(", "1969", ")", ","], "sentence-detokenized": "Stagnacja bada\u0144 nast\u0105pi\u0142a po badaniach nad uczeniem maszynowym prowadzonych przez Marvina Minsky'ego i Seymoura Paperta (1969),", "token2charspan": [[0, 9], [10, 15], [16, 25], [26, 28], [29, 38], [39, 42], [43, 51], [52, 62], [63, 75], [76, 81], [82, 89], [90, 100], [101, 102], [103, 111], [112, 119], [120, 121], [121, 125], [125, 126], [126, 127]]}
{"doc_key": "ai-test-358", "ner": [[10, 10, "task"], [13, 14, "programlang"], [16, 19, "product"], [21, 22, "programlang"], [24, 24, "product"], [26, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 10, 13, 14, "related-to", "used_to_build", false, false], [10, 10, 16, 19, "related-to", "used_to_build", false, false], [10, 10, 21, 22, "related-to", "used_to_build", false, false], [10, 10, 24, 24, "related-to", "used_to_build", false, false], [10, 10, 26, 26, "related-to", "used_to_build", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Inne", "\u015brodowiska", "programowania", ",", "kt\u00f3re", "s\u0105", "u\u017cywane", "do", "budowania", "aplikacji", "DAQ", ",", "obejmuj\u0105", "logik\u0119", "drabinkow\u0105", ",", "Visual", "C", "+", "+", ",", "Visual", "Basic", ",", "LabVIEW", "i", "MATLAB", "."], "sentence-detokenized": "Inne \u015brodowiska programowania, kt\u00f3re s\u0105 u\u017cywane do budowania aplikacji DAQ, obejmuj\u0105 logik\u0119 drabinkow\u0105, Visual C + +, Visual Basic, LabVIEW i MATLAB.", "token2charspan": [[0, 4], [5, 15], [16, 29], [29, 30], [31, 36], [37, 39], [40, 47], [48, 50], [51, 60], [61, 70], [71, 74], [74, 75], [76, 84], [85, 91], [92, 102], [102, 103], [104, 110], [111, 112], [113, 114], [115, 116], [116, 117], [118, 124], [125, 130], [130, 131], [132, 139], [140, 141], [142, 148], [148, 149]]}
{"doc_key": "ai-test-359", "ner": [[14, 15, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Metryka", "ta", "zosta\u0142a", "zaprojektowana", "tak", ",", "aby", "rozwi\u0105za\u0107", "niekt\u00f3re", "problemy", "wyst\u0119puj\u0105ce", "w", "bardziej", "popularnej", "metryce", "BLEU", ",", "a", "tak\u017ce", "uzyska\u0107", "dobr\u0105", "korelacj\u0119", "z", "ocen\u0105", "ludzk\u0105", "na", "poziomie", "zdania", "lub", "segmentu", "."], "sentence-detokenized": "Metryka ta zosta\u0142a zaprojektowana tak, aby rozwi\u0105za\u0107 niekt\u00f3re problemy wyst\u0119puj\u0105ce w bardziej popularnej metryce BLEU, a tak\u017ce uzyska\u0107 dobr\u0105 korelacj\u0119 z ocen\u0105 ludzk\u0105 na poziomie zdania lub segmentu.", "token2charspan": [[0, 7], [8, 10], [11, 18], [19, 33], [34, 37], [37, 38], [39, 42], [43, 52], [53, 61], [62, 70], [71, 82], [83, 84], [85, 93], [94, 104], [105, 112], [113, 117], [117, 118], [119, 120], [121, 126], [127, 134], [135, 140], [141, 150], [151, 152], [153, 158], [159, 165], [166, 168], [169, 177], [178, 184], [185, 188], [189, 197], [197, 198]]}
{"doc_key": "ai-test-360", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniki", "takie", "jak", "dynamiczne", "sieci", "Markowa", ",", "konwolucyjne", "sieci", "neuronowe", "i", "d\u0142uga", "pami\u0119\u0107", "kr\u00f3tkotrwa\u0142a", "s\u0105", "cz\u0119sto", "wykorzystywane", "do", "wykorzystania", "semantycznych", "korelacji", "pomi\u0119dzy", "kolejnymi", "klatkami", "wideo", "."], "sentence-detokenized": "Techniki takie jak dynamiczne sieci Markowa, konwolucyjne sieci neuronowe i d\u0142uga pami\u0119\u0107 kr\u00f3tkotrwa\u0142a s\u0105 cz\u0119sto wykorzystywane do wykorzystania semantycznych korelacji pomi\u0119dzy kolejnymi klatkami wideo.", "token2charspan": [[0, 8], [9, 14], [15, 18], [19, 29], [30, 35], [36, 43], [43, 44], [45, 57], [58, 63], [64, 73], [74, 75], [76, 81], [82, 88], [89, 101], [102, 104], [105, 111], [112, 126], [127, 129], [130, 143], [144, 157], [158, 167], [168, 176], [177, 186], [187, 195], [196, 201], [201, 202]]}
{"doc_key": "ai-test-361", "ner": [[2, 3, "product"], [5, 5, "product"], [12, 17, "product"], [22, 22, "product"], [38, 39, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 12, 17, "artifact", "", false, false], [2, 3, 38, 39, "named", "", false, false], [5, 5, 2, 3, "named", "", false, false], [22, 22, 12, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Masowo", "produkowane", "p\u0142ytki", "drukowane", "(", "PCB", ")", "s\u0105", "prawie", "wy\u0142\u0105cznie", "wytwarzane", "przez", "roboty", "typu", "pick-", "and", "-", "place", ",", "zazwyczaj", "z", "manipulatorami", "SCARA", ",", "kt\u00f3re", "wyjmuj\u0105", "drobne", "elementy", "elektroniczne", "z", "ta\u015bm", "lub", "tacek", "i", "umieszczaj\u0105", "je", "na", "p\u0142ytkach", "PCB", "z", "du\u017c\u0105", "dok\u0142adno\u015bci\u0105", "."], "sentence-detokenized": "Masowo produkowane p\u0142ytki drukowane (PCB) s\u0105 prawie wy\u0142\u0105cznie wytwarzane przez roboty typu pick-and-place, zazwyczaj z manipulatorami SCARA, kt\u00f3re wyjmuj\u0105 drobne elementy elektroniczne z ta\u015bm lub tacek i umieszczaj\u0105 je na p\u0142ytkach PCB z du\u017c\u0105 dok\u0142adno\u015bci\u0105.", "token2charspan": [[0, 6], [7, 18], [19, 25], [26, 35], [36, 37], [37, 40], [40, 41], [42, 44], [45, 51], [52, 61], [62, 72], [73, 78], [79, 85], [86, 90], [91, 96], [96, 99], [99, 100], [100, 105], [105, 106], [107, 116], [117, 118], [119, 133], [134, 139], [139, 140], [141, 146], [147, 154], [155, 161], [162, 170], [171, 184], [185, 186], [187, 191], [192, 195], [196, 201], [202, 203], [204, 215], [216, 218], [219, 221], [222, 230], [231, 234], [235, 236], [237, 241], [242, 254], [254, 255]]}
{"doc_key": "ai-test-362", "ner": [[2, 3, "field"], [11, 11, "algorithm"], [17, 18, "researcher"], [20, 21, "researcher"], [23, 26, "researcher"], [33, 34, "algorithm"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 11, 2, 3, "part-of", "", false, false], [11, 11, 17, 18, "origin", "", false, false], [11, 11, 20, 21, "origin", "", false, false], [11, 11, 23, 26, "origin", "", false, false], [11, 11, 33, 34, "type-of", "", false, false], [33, 34, 35, 36, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["W", "kontek\u015bcie", "uczenia", "maszynowego", ",", "gdzie", "jest", "dzi\u015b", "najszerzej", "stosowana", ",", "LDA", "zosta\u0142a", "ponownie", "odkryta", "niezale\u017cnie", "przez", "Davida", "Blei", ",", "Andrew", "Ng", "i", "Michaela", "I", ".", "Jordana", "w", "2003", "roku", "i", "przedstawiona", "jako", "grafowy", "model", "odkrywania", "temat\u00f3w", "."], "sentence-detokenized": "W kontek\u015bcie uczenia maszynowego, gdzie jest dzi\u015b najszerzej stosowana, LDA zosta\u0142a ponownie odkryta niezale\u017cnie przez Davida Blei, Andrew Ng i Michaela I. Jordana w 2003 roku i przedstawiona jako grafowy model odkrywania temat\u00f3w.", "token2charspan": [[0, 1], [2, 12], [13, 20], [21, 32], [32, 33], [34, 39], [40, 44], [45, 49], [50, 60], [61, 70], [70, 71], [72, 75], [76, 83], [84, 92], [93, 100], [101, 112], [113, 118], [119, 125], [126, 130], [130, 131], [132, 138], [139, 141], [142, 143], [144, 152], [153, 154], [154, 155], [156, 163], [164, 165], [166, 170], [171, 175], [176, 177], [178, 191], [192, 196], [197, 204], [205, 210], [211, 221], [222, 229], [229, 230]]}
{"doc_key": "ai-test-363", "ner": [[7, 8, "task"], [10, 10, "misc"], [13, 13, "metrics"], [15, 15, "metrics"], [12, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 8, 10, 10, "related-to", "task_across_domain", false, false]], "relations_mapping_to_source": [0], "sentence": ["Zmierzona", "wydajno\u015b\u0107", "na", "danych", "testowych", "o\u015bmiu", "naiwnych", "WSI", "w", "r\u00f3\u017cnych", "tauopatiach", "da\u0142a", "wynik", "recall", ",", "precision", "i", "F1", "odpowiednio", "0,92", ",", "0,72", "i", "0,81", "."], "sentence-detokenized": "Zmierzona wydajno\u015b\u0107 na danych testowych o\u015bmiu naiwnych WSI w r\u00f3\u017cnych tauopatiach da\u0142a wynik recall, precision i F1 odpowiednio 0,92, 0,72 i 0,81.", "token2charspan": [[0, 9], [10, 19], [20, 22], [23, 29], [30, 39], [40, 45], [46, 54], [55, 58], [59, 60], [61, 68], [69, 80], [81, 85], [86, 91], [92, 98], [98, 99], [100, 109], [110, 111], [112, 114], [115, 126], [127, 131], [131, 132], [133, 137], [138, 139], [140, 144], [144, 145]]}
{"doc_key": "ai-test-364", "ner": [[4, 4, "field"], [9, 10, "field"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Z", "pomoc\u0105", "zaawansowanych", "technologii", "AR", "(", "np", ".", "dodanie", "wizji", "komputerowej", ",", "wbudowanie", "kamer", "AR", "w", "smartfony", "i", "rozpoznawanie", "obiekt\u00f3w", ")", "informacje", "o", "otaczaj\u0105cym", "u\u017cytkownika", "\u015bwiecie", "rzeczywistym", "staj\u0105", "si\u0119", "interaktywne", "i", "poddawane", "cyfrowej", "manipulacji", "."], "sentence-detokenized": "Z pomoc\u0105 zaawansowanych technologii AR (np. dodanie wizji komputerowej, wbudowanie kamer AR w smartfony i rozpoznawanie obiekt\u00f3w) informacje o otaczaj\u0105cym u\u017cytkownika \u015bwiecie rzeczywistym staj\u0105 si\u0119 interaktywne i poddawane cyfrowej manipulacji.", "token2charspan": [[0, 1], [2, 8], [9, 23], [24, 35], [36, 38], [39, 40], [40, 42], [42, 43], [44, 51], [52, 57], [58, 70], [70, 71], [72, 82], [83, 88], [89, 91], [92, 93], [94, 103], [104, 105], [106, 119], [120, 128], [128, 129], [130, 140], [141, 142], [143, 154], [155, 166], [167, 174], [175, 187], [188, 193], [194, 197], [198, 210], [211, 212], [213, 222], [223, 231], [232, 243], [243, 244]]}
{"doc_key": "ai-test-365", "ner": [[3, 3, "researcher"], [6, 6, "organisation"], [13, 14, "field"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 6, 6, "role", "forms_company", false, false], [6, 6, 13, 14, "related-to", "works_with", false, false], [6, 6, 24, 24, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["W", "2014", "roku", "Schmidhuber", "za\u0142o\u017cy\u0142", "firm\u0119", "Nnaisense", ",", "aby", "pracowa\u0107", "nad", "komercyjnymi", "zastosowaniami", "sztucznej", "inteligencji", "w", "takich", "dziedzinach", "jak", "finanse", ",", "przemys\u0142", "ci\u0119\u017cki", "i", "samojezdne", "samochody", "."], "sentence-detokenized": "W 2014 roku Schmidhuber za\u0142o\u017cy\u0142 firm\u0119 Nnaisense, aby pracowa\u0107 nad komercyjnymi zastosowaniami sztucznej inteligencji w takich dziedzinach jak finanse, przemys\u0142 ci\u0119\u017cki i samojezdne samochody.", "token2charspan": [[0, 1], [2, 6], [7, 11], [12, 23], [24, 31], [32, 37], [38, 47], [47, 48], [49, 52], [53, 61], [62, 65], [66, 78], [79, 93], [94, 103], [104, 116], [117, 118], [119, 125], [126, 137], [138, 141], [142, 149], [149, 150], [151, 159], [160, 166], [167, 168], [169, 179], [180, 189], [189, 190]]}
{"doc_key": "ai-test-366", "ner": [[20, 21, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Nie", "tylko", "zmienia", "to", "wyniki", "wszystkich", "kolejnych", "test\u00f3w", "na", "zachowanym", "modelu", "obja\u015bniaj\u0105cym", ",", "ale", "mo\u017ce", "te\u017c", "wprowadzi\u0107", "stronniczo\u015b\u0107", "i", "zmieni\u0107", "b\u0142\u0105d", "\u015bredniokwadratowy", "w", "estymacji", "."], "sentence-detokenized": "Nie tylko zmienia to wyniki wszystkich kolejnych test\u00f3w na zachowanym modelu obja\u015bniaj\u0105cym, ale mo\u017ce te\u017c wprowadzi\u0107 stronniczo\u015b\u0107 i zmieni\u0107 b\u0142\u0105d \u015bredniokwadratowy w estymacji.", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 20], [21, 27], [28, 38], [39, 48], [49, 55], [56, 58], [59, 69], [70, 76], [77, 90], [90, 91], [92, 95], [96, 100], [101, 104], [105, 115], [116, 128], [129, 130], [131, 138], [139, 143], [144, 161], [162, 163], [164, 173], [173, 174]]}
{"doc_key": "ai-test-367", "ner": [[0, 0, "misc"], [6, 7, "algorithm"], [9, 10, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 0, 0, "usage", "", false, false], [6, 7, 9, 10, "topic", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Bigramy", "s\u0105", "wykorzystywane", "w", "wi\u0119kszo\u015bci", "udanych", "modeli", "j\u0119zykowych", "do", "rozpoznawania", "mowy", "."], "sentence-detokenized": "Bigramy s\u0105 wykorzystywane w wi\u0119kszo\u015bci udanych modeli j\u0119zykowych do rozpoznawania mowy.", "token2charspan": [[0, 7], [8, 10], [11, 25], [26, 27], [28, 38], [39, 46], [47, 53], [54, 64], [65, 67], [68, 81], [82, 86], [86, 87]]}
{"doc_key": "ai-test-368", "ner": [[4, 5, "field"], [8, 10, "misc"], [15, 17, "misc"], [21, 23, "organisation"], [25, 27, "misc"], [32, 34, "organisation"], [36, 38, "misc"], [43, 47, "organisation"], [49, 51, "misc"], [56, 58, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[8, 10, 4, 5, "topic", "", false, false], [15, 17, 21, 23, "origin", "", false, false], [25, 27, 32, 34, "origin", "", false, false], [36, 38, 43, 47, "origin", "", false, false], [49, 51, 56, 58, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Jego", "badania", "w", "dziedzinie", "psychologii", "poznawczej", "zdoby\u0142y", "nagrody", "Early", "Career", "Award", "(", "1984", ")", "i", "Boyd", "McCandless", "Award", "1986", ")", "od", "Ameryka\u0144skiego", "Towarzystwa", "Psychologicznego", ",", "Troland", "Research", "Award", "(", "1993", ")", "od", "Narodowej", "Akademii", "Nauk", ",", "Henry", "Dale", "Prize", "(", "2004", ")", "od", "Royal", "Institution", "of", "Great", "Britain", "oraz", "George", "Miller", "Prize", "(", "2010", ")", "od", "Cognitive", "Neuroscience", "Society", "."], "sentence-detokenized": "Jego badania w dziedzinie psychologii poznawczej zdoby\u0142y nagrody Early Career Award (1984) i Boyd McCandless Award 1986) od Ameryka\u0144skiego Towarzystwa Psychologicznego, Troland Research Award (1993) od Narodowej Akademii Nauk, Henry Dale Prize (2004) od Royal Institution of Great Britain oraz George Miller Prize (2010) od Cognitive Neuroscience Society.", "token2charspan": [[0, 4], [5, 12], [13, 14], [15, 25], [26, 37], [38, 48], [49, 56], [57, 64], [65, 70], [71, 77], [78, 83], [84, 85], [85, 89], [89, 90], [91, 92], [93, 97], [98, 108], [109, 114], [115, 119], [119, 120], [121, 123], [124, 138], [139, 150], [151, 167], [167, 168], [169, 176], [177, 185], [186, 191], [192, 193], [193, 197], [197, 198], [199, 201], [202, 211], [212, 220], [221, 225], [225, 226], [227, 232], [233, 237], [238, 243], [244, 245], [245, 249], [249, 250], [251, 253], [254, 259], [260, 271], [272, 274], [275, 280], [281, 288], [289, 293], [294, 300], [301, 307], [308, 313], [314, 315], [315, 319], [319, 320], [321, 323], [324, 333], [334, 346], [347, 354], [354, 355]]}
{"doc_key": "ai-test-369", "ner": [[0, 0, "misc"], [6, 6, "misc"], [8, 10, "product"], [14, 14, "researcher"], [16, 16, "researcher"], [23, 24, "researcher"], [26, 27, "researcher"], [29, 30, "task"], [32, 35, "researcher"], [37, 41, "researcher"], [42, 43, "task"], [45, 45, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[0, 0, 6, 6, "named", "", false, false], [0, 0, 45, 45, "named", "", false, false], [6, 6, 14, 14, "origin", "", false, false], [6, 6, 16, 16, "origin", "", false, false], [6, 6, 29, 30, "related-to", "used_for", false, false], [8, 10, 6, 6, "usage", "", false, false], [8, 10, 42, 43, "named", "", false, false], [23, 24, 6, 6, "usage", "", false, false], [23, 24, 32, 35, "named", "same", false, false], [26, 27, 6, 6, "usage", "", false, false], [26, 27, 37, 41, "named", "same", false, false], [42, 43, 45, 45, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Eigenface", "(", "Podej\u015bcie", "polegaj\u0105ce", "na", "wykorzystaniu", "eigenfaces", "w", "systemie", "rozpoznawania", "twarzy", "zosta\u0142o", "opracowane", "przez", "Sirovicha", "i", "Kirby'ego", "(", "1987", ")", "i", "wykorzystane", "przez", "Matthew", "Turka", "i", "Alexa", "Pentlanda", "w", "klasyfikacji", "twarzy", ".", "Turk", ",", "Matthew", "A", "and", "Pentland", ",", "Alex", "P", ".", "Face", "recognition", "using", "eigenfaces", "."], "sentence-detokenized": "Eigenface (Podej\u015bcie polegaj\u0105ce na wykorzystaniu eigenfaces w systemie rozpoznawania twarzy zosta\u0142o opracowane przez Sirovicha i Kirby'ego (1987) i wykorzystane przez Matthew Turka i Alexa Pentlanda w klasyfikacji twarzy. Turk, Matthew A and Pentland, Alex P. Face recognition using eigenfaces.", "token2charspan": [[0, 9], [10, 11], [11, 20], [21, 31], [32, 34], [35, 48], [49, 59], [60, 61], [62, 70], [71, 84], [85, 91], [92, 99], [100, 110], [111, 116], [117, 126], [127, 128], [129, 138], [139, 140], [140, 144], [144, 145], [146, 147], [148, 160], [161, 166], [167, 174], [175, 180], [181, 182], [183, 188], [189, 198], [199, 200], [201, 213], [214, 220], [220, 221], [222, 226], [226, 227], [228, 235], [236, 237], [238, 241], [242, 250], [250, 251], [252, 256], [257, 258], [258, 259], [260, 264], [265, 276], [277, 282], [283, 293], [293, 294]]}
{"doc_key": "ai-test-370", "ner": [[5, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["S\u0142ownik", "leksykalny", ",", "taki", "jak", "WordNet", ",", "mo\u017ce", "by\u0107", "nast\u0119pnie", "wykorzystany", "do", "zrozumienia", "kontekstu", "."], "sentence-detokenized": "S\u0142ownik leksykalny, taki jak WordNet, mo\u017ce by\u0107 nast\u0119pnie wykorzystany do zrozumienia kontekstu.", "token2charspan": [[0, 7], [8, 18], [18, 19], [20, 24], [25, 28], [29, 36], [36, 37], [38, 42], [43, 46], [47, 56], [57, 69], [70, 72], [73, 84], [85, 94], [94, 95]]}
{"doc_key": "ai-test-371", "ner": [[0, 0, "misc"], [6, 6, "misc"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 6, 6, "part-of", "", false, false], [6, 6, 15, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hiponimia", "jest", "najcz\u0119\u015bciej", "kodowan\u0105", "relacj\u0105", "w\u015br\u00f3d", "synset\u00f3w", "u\u017cywanych", "w", "leksykalnych", "bazach", "danych", ",", "takich", "jak", "WordNet", "."], "sentence-detokenized": "Hiponimia jest najcz\u0119\u015bciej kodowan\u0105 relacj\u0105 w\u015br\u00f3d synset\u00f3w u\u017cywanych w leksykalnych bazach danych, takich jak WordNet.", "token2charspan": [[0, 9], [10, 14], [15, 26], [27, 35], [36, 43], [44, 49], [50, 58], [59, 68], [69, 70], [71, 83], [84, 90], [91, 97], [97, 98], [99, 105], [106, 109], [110, 117], [117, 118]]}
{"doc_key": "ai-test-372", "ner": [[0, 0, "organisation"], [7, 9, "programlang"], [11, 11, "programlang"], [38, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 7, 9, "general-affiliation", "", false, false], [0, 0, 11, 11, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["OPeNDAP", "oferuje", "biblioteki", "open", "-", "source", "w", "C", "+", "+", "i", "Java", ",", "ale", "wielu", "klient\u00f3w", "polega", "na", "bibliotekach", "opracowanych", "przez", "spo\u0142eczno\u015b\u0107", ",", "takich", "jak", "biblioteki", "zawieraj\u0105", "wbudowane", "mo\u017cliwo\u015bci", "pobierania", "(", "w", "stylu", "tablicowym", ")", "danych", "z", "serwer\u00f3w", "DAP", "."], "sentence-detokenized": "OPeNDAP oferuje biblioteki open-source w C + + i Java, ale wielu klient\u00f3w polega na bibliotekach opracowanych przez spo\u0142eczno\u015b\u0107, takich jak biblioteki zawieraj\u0105 wbudowane mo\u017cliwo\u015bci pobierania (w stylu tablicowym) danych z serwer\u00f3w DAP.", "token2charspan": [[0, 7], [8, 15], [16, 26], [27, 31], [31, 32], [32, 38], [39, 40], [41, 42], [43, 44], [45, 46], [47, 48], [49, 53], [53, 54], [55, 58], [59, 64], [65, 73], [74, 80], [81, 83], [84, 96], [97, 109], [110, 115], [116, 127], [127, 128], [129, 135], [136, 139], [140, 150], [151, 160], [161, 170], [171, 181], [182, 192], [193, 194], [194, 195], [196, 201], [202, 212], [212, 213], [214, 220], [221, 222], [223, 231], [232, 235], [235, 236]]}
{"doc_key": "ai-test-373", "ner": [[3, 4, "misc"], [6, 6, "product"], [22, 23, "misc"], [34, 34, "organisation"], [33, 33, "product"], [40, 40, "organisation"], [36, 39, "product"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7], "relations": [[22, 23, 6, 6, "part-of", "", false, false], [33, 33, 34, 34, "artifact", "", false, false], [36, 39, 40, 40, "artifact", "", false, false]], "relations_mapping_to_source": [2, 3, 4], "sentence": ["Na", "tej", "stronie", "Samurai", "Damashii", "wyolbrzymia\u0142", "Senkousha", "jako", "krystalizacj\u0119", "czterech", "tysi\u0119cy", "lat", "chi\u0144skiej", "wiedzy", "naukowej", ",", "komentowa\u0142", "surowy", "design", "(", "np", ".", "chi\u0144ska", "armata", "na", "kroczu", ")", "i", "umieszcza\u0142", "jego", "wizerunek", "w\u015br\u00f3d", "zdj\u0119\u0107", "ASIMO", "Hondy", "i", "QRIO", "SDR", "-", "3X", "Sony", "dla", "zestawienia", "."], "sentence-detokenized": "Na tej stronie Samurai Damashii wyolbrzymia\u0142 Senkousha jako krystalizacj\u0119 czterech tysi\u0119cy lat chi\u0144skiej wiedzy naukowej, komentowa\u0142 surowy design (np. chi\u0144ska armata na kroczu) i umieszcza\u0142 jego wizerunek w\u015br\u00f3d zdj\u0119\u0107 ASIMO Hondy i QRIO SDR-3X Sony dla zestawienia.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 22], [23, 31], [32, 44], [45, 54], [55, 59], [60, 73], [74, 82], [83, 90], [91, 94], [95, 104], [105, 111], [112, 120], [120, 121], [122, 132], [133, 139], [140, 146], [147, 148], [148, 150], [150, 151], [152, 159], [160, 166], [167, 169], [170, 176], [176, 177], [178, 179], [180, 190], [191, 195], [196, 205], [206, 211], [212, 217], [218, 223], [224, 229], [230, 231], [232, 236], [237, 240], [240, 241], [241, 243], [244, 248], [249, 252], [253, 264], [264, 265]]}
{"doc_key": "ai-test-374", "ner": [[9, 10, "algorithm"], [22, 22, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 22, 22, "part-of", "includes_functionality_of", false, false], [9, 10, 24, 24, "part-of", "includes_functionality_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Istnieje", "r\u00f3wnie\u017c", "wiele", "bibliotek", "programistycznych", ",", "kt\u00f3re", "zawieraj\u0105", "funkcjonalno\u015b\u0107", "sieci", "neuronowych", "i", "kt\u00f3re", "mog\u0105", "by\u0107", "u\u017cywane", "w", "niestandardowych", "implementacjach", "(", "takich", "jak", "TensorFlow", ",", "Theano", "itp", "."], "sentence-detokenized": "Istnieje r\u00f3wnie\u017c wiele bibliotek programistycznych, kt\u00f3re zawieraj\u0105 funkcjonalno\u015b\u0107 sieci neuronowych i kt\u00f3re mog\u0105 by\u0107 u\u017cywane w niestandardowych implementacjach (takich jak TensorFlow, Theano itp.", "token2charspan": [[0, 8], [9, 16], [17, 22], [23, 32], [33, 50], [50, 51], [52, 57], [58, 67], [68, 82], [83, 88], [89, 100], [101, 102], [103, 108], [109, 113], [114, 117], [118, 125], [126, 127], [128, 144], [145, 160], [161, 162], [162, 168], [169, 172], [173, 183], [183, 184], [185, 191], [192, 195], [195, 196]]}
{"doc_key": "ai-test-375", "ner": [[3, 7, "conference"], [9, 9, "organisation"], [11, 17, "conference"], [19, 19, "conference"], [21, 21, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Jest", "Fellow", "of", "the", "Association", "for", "Computing", "Machinery", ",", "IEEE", ",", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "IAPR", "i", "SPIE", "."], "sentence-detokenized": "Jest Fellow of the Association for Computing Machinery, IEEE, American Association for the Advancement of Science, IAPR i SPIE.", "token2charspan": [[0, 4], [5, 11], [12, 14], [15, 18], [19, 30], [31, 34], [35, 44], [45, 54], [54, 55], [56, 60], [60, 61], [62, 70], [71, 82], [83, 86], [87, 90], [91, 102], [103, 105], [106, 113], [113, 114], [115, 119], [120, 121], [122, 126], [126, 127]]}
{"doc_key": "ai-test-376", "ner": [[1, 1, "organisation"], [7, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 1, 7, 9, "related-to", "runs_trials_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["Pr\u00f3ba", "RET", "w", "2011", "roku", "z", "kamerami", "systemu", "rozpoznawania", "twarzy", "zamontowanymi", "na", "tramwajach", "sprawi\u0142a", ",", "\u017ce", "osoby", ",", "kt\u00f3rym", "zakazano", "wjazdu", "do", "miejskich", "tramwaj\u00f3w", "i", "tak", "si\u0119", "nie", "skrada\u0142y", "."], "sentence-detokenized": "Pr\u00f3ba RET w 2011 roku z kamerami systemu rozpoznawania twarzy zamontowanymi na tramwajach sprawi\u0142a, \u017ce osoby, kt\u00f3rym zakazano wjazdu do miejskich tramwaj\u00f3w i tak si\u0119 nie skrada\u0142y.", "token2charspan": [[0, 5], [6, 9], [10, 11], [12, 16], [17, 21], [22, 23], [24, 32], [33, 40], [41, 54], [55, 61], [62, 75], [76, 78], [79, 89], [90, 98], [98, 99], [100, 102], [103, 108], [108, 109], [110, 116], [117, 125], [126, 132], [133, 135], [136, 145], [146, 155], [156, 157], [158, 161], [162, 165], [166, 169], [170, 178], [178, 179]]}
{"doc_key": "ai-test-377", "ner": [[9, 13, "person"], [7, 7, "organisation"], [20, 21, "person"], [23, 24, "person"], [28, 29, "person"], [31, 32, "person"], [34, 35, "person"], [37, 38, "person"], [40, 41, "person"], [43, 44, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[9, 13, 7, 7, "role", "works_for", false, false], [20, 21, 7, 7, "role", "works_for", false, false], [23, 24, 7, 7, "role", "works_for", false, false], [28, 29, 7, 7, "role", "works_for", false, false], [31, 32, 7, 7, "role", "works_for", false, false], [34, 35, 7, 7, "role", "works_for", false, false], [37, 38, 7, 7, "role", "works_for", false, false], [40, 41, 7, 7, "role", "works_for", false, false], [43, 44, 7, 7, "role", "works_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["W", "filmie", ",", "zaadaptowanym", "na", "podstawie", "popularnego", "broadwayowskiego", "musicalu", "Cole'a", "Portera", ",", "w", "rolach", "g\u0142\u00f3wnych", "wyst\u0105pi\u0142", "zesp\u00f3\u0142", "songbird\u00f3w", "MGM", "-", "Howard", "Keel", "i", "Kathryn", "Grayson", ",", "wspierani", "przez", "Ann", "Miller", ",", "Keenana", "Wynna", ",", "Bobby'ego", "Vana", ",", "Jamesa", "Whitmore'a", ",", "Kurta", "Kasznara", "i", "Tommy'ego", "Ralla", "."], "sentence-detokenized": "W filmie, zaadaptowanym na podstawie popularnego broadwayowskiego musicalu Cole'a Portera, w rolach g\u0142\u00f3wnych wyst\u0105pi\u0142 zesp\u00f3\u0142 songbird\u00f3w MGM - Howard Keel i Kathryn Grayson, wspierani przez Ann Miller, Keenana Wynna, Bobby'ego Vana, Jamesa Whitmore'a, Kurta Kasznara i Tommy'ego Ralla.", "token2charspan": [[0, 1], [2, 8], [8, 9], [10, 23], [24, 26], [27, 36], [37, 48], [49, 65], [66, 74], [75, 81], [82, 89], [89, 90], [91, 92], [93, 99], [100, 108], [109, 117], [118, 124], [125, 135], [136, 139], [140, 141], [142, 148], [149, 153], [154, 155], [156, 163], [164, 171], [171, 172], [173, 182], [183, 188], [189, 192], [193, 199], [199, 200], [201, 208], [209, 214], [214, 215], [216, 225], [226, 230], [230, 231], [232, 238], [239, 249], [249, 250], [251, 256], [257, 265], [266, 267], [268, 277], [278, 283], [283, 284]]}
{"doc_key": "ai-test-378", "ner": [[16, 20, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Takie", "aplikacje", "powinny", "usprawnia\u0107", "przep\u0142ywy", "po\u0142\u0105cze\u0144", ",", "minimalizowa\u0107", "podpowiedzi", ",", "eliminowa\u0107", "zb\u0119dne", "iteracje", "i", "umo\u017cliwia\u0107", "rozbudowane", "systemy", "dialogowe", "z", "inicjatyw\u0105", "mieszan\u0105", ",", "kt\u00f3re", "umo\u017cliwiaj\u0105", "dzwoni\u0105cym", "wprowadzenie", "kilku", "informacji", "w", "jednej", "wypowiedzi", "i", "w", "dowolnej", "kolejno\u015bci", "lub", "kombinacji", "."], "sentence-detokenized": "Takie aplikacje powinny usprawnia\u0107 przep\u0142ywy po\u0142\u0105cze\u0144, minimalizowa\u0107 podpowiedzi, eliminowa\u0107 zb\u0119dne iteracje i umo\u017cliwia\u0107 rozbudowane systemy dialogowe z inicjatyw\u0105 mieszan\u0105, kt\u00f3re umo\u017cliwiaj\u0105 dzwoni\u0105cym wprowadzenie kilku informacji w jednej wypowiedzi i w dowolnej kolejno\u015bci lub kombinacji.", "token2charspan": [[0, 5], [6, 15], [16, 23], [24, 34], [35, 44], [45, 53], [53, 54], [55, 68], [69, 80], [80, 81], [82, 92], [93, 99], [100, 108], [109, 110], [111, 121], [122, 133], [134, 141], [142, 151], [152, 153], [154, 164], [165, 173], [173, 174], [175, 180], [181, 192], [193, 203], [204, 216], [217, 222], [223, 233], [234, 235], [236, 242], [243, 253], [254, 255], [256, 257], [258, 266], [267, 277], [278, 281], [282, 292], [292, 293]]}
{"doc_key": "ai-test-379", "ner": [[9, 9, "algorithm"], [12, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 14, 9, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["W", "zwi\u0105zku", "z", "tym", "mo\u017cna", "dostosowa\u0107", "tradycyjne", "metody", "zst\u0119powania", "gradientowego", "(", "lub", "stochastycznego", "zst\u0119powania", "gradientowego", ")", ",", "w", "kt\u00f3rych", "zamiast", "kroku", "w", "kierunku", "gradientu", "funkcji", ",", "wykonuje", "si\u0119", "krok", "w", "kierunku", "wektora", "wybranego", "z", "podgradientu", "funkcji", "."], "sentence-detokenized": "W zwi\u0105zku z tym mo\u017cna dostosowa\u0107 tradycyjne metody zst\u0119powania gradientowego (lub stochastycznego zst\u0119powania gradientowego), w kt\u00f3rych zamiast kroku w kierunku gradientu funkcji, wykonuje si\u0119 krok w kierunku wektora wybranego z podgradientu funkcji.", "token2charspan": [[0, 1], [2, 9], [10, 11], [12, 15], [16, 21], [22, 32], [33, 43], [44, 50], [51, 62], [63, 76], [77, 78], [78, 81], [82, 97], [98, 109], [110, 123], [123, 124], [124, 125], [126, 127], [128, 135], [136, 143], [144, 149], [150, 151], [152, 160], [161, 170], [171, 178], [178, 179], [180, 188], [189, 192], [193, 197], [198, 199], [200, 208], [209, 216], [217, 226], [227, 228], [229, 241], [242, 249], [249, 250]]}
{"doc_key": "ai-test-380", "ner": [[8, 9, "metrics"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Je\u017celi", "przyjmie", "si\u0119", ",", "\u017ce", "zniekszta\u0142cenia", "mierzy", "si\u0119", "b\u0142\u0119dem", "\u015bredniokwadratowym", ",", "to", "zniekszta\u0142cenie", "D", ",", "jest", "dane", "przez", ":"], "sentence-detokenized": "Je\u017celi przyjmie si\u0119, \u017ce zniekszta\u0142cenia mierzy si\u0119 b\u0142\u0119dem \u015bredniokwadratowym, to zniekszta\u0142cenie D, jest dane przez:", "token2charspan": [[0, 6], [7, 15], [16, 19], [19, 20], [21, 23], [24, 39], [40, 46], [47, 50], [51, 57], [58, 76], [76, 77], [78, 80], [81, 96], [97, 98], [98, 99], [100, 104], [105, 109], [110, 115], [115, 116]]}
{"doc_key": "ai-test-381", "ner": [[0, 0, "algorithm"], [4, 5, "field"], [18, 19, "task"], [21, 22, "task"], [26, 27, "task"], [29, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 4, 5, "part-of", "", false, false], [18, 19, 0, 0, "part-of", "", false, false], [21, 22, 0, 0, "part-of", "", false, false], [26, 27, 0, 0, "part-of", "", false, false], [29, 30, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["MLP", "by\u0142y", "popularnym", "rozwi\u0105zaniem", "uczenia", "maszynowego", "w", "latach", "80-tych", ",", "znajduj\u0105c", "zastosowanie", "w", "zr\u00f3\u017cnicowanych", "dziedzinach", ",", "takich", "jak", "rozpoznawanie", "mowy", ",", "rozpoznawanie", "obraz\u00f3w", "i", "oprogramowanie", "do", "t\u0142umaczenia", "maszynowego", ",", "Sieci", "neuronowe", "."], "sentence-detokenized": "MLP by\u0142y popularnym rozwi\u0105zaniem uczenia maszynowego w latach 80-tych, znajduj\u0105c zastosowanie w zr\u00f3\u017cnicowanych dziedzinach, takich jak rozpoznawanie mowy, rozpoznawanie obraz\u00f3w i oprogramowanie do t\u0142umaczenia maszynowego, Sieci neuronowe.", "token2charspan": [[0, 3], [4, 8], [9, 19], [20, 32], [33, 40], [41, 52], [53, 54], [55, 61], [62, 69], [69, 70], [71, 80], [81, 93], [94, 95], [96, 110], [111, 122], [122, 123], [124, 130], [131, 134], [135, 148], [149, 153], [153, 154], [155, 168], [169, 176], [177, 178], [179, 193], [194, 196], [197, 208], [209, 220], [220, 221], [222, 227], [228, 237], [237, 238]]}
{"doc_key": "ai-test-382", "ner": [[0, 0, "researcher"], [3, 3, "misc"], [5, 7, "university"], [14, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 7, "physical", "", false, false], [0, 0, 5, 7, "role", "", false, false], [3, 3, 0, 0, "origin", "", false, false], [14, 17, 0, 0, "role", "supervised", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Allen", "uzyska\u0142", "tytu\u0142", "doktora", "na", "Uniwersytecie", "w", "Toronto", "w", "1979", "roku", ",", "pod", "kierunkiem", "C", ".", "Raymonda", "Perraulta", ","], "sentence-detokenized": "Allen uzyska\u0142 tytu\u0142 doktora na Uniwersytecie w Toronto w 1979 roku, pod kierunkiem C. Raymonda Perraulta,", "token2charspan": [[0, 5], [6, 13], [14, 19], [20, 27], [28, 30], [31, 44], [45, 46], [47, 54], [55, 56], [57, 61], [62, 66], [66, 67], [68, 71], [72, 82], [83, 84], [84, 85], [86, 94], [95, 104], [104, 105]]}
{"doc_key": "ai-test-383", "ner": [[0, 0, "product"], [5, 7, "field"], [5, 11, "product"], [13, 13, "product"], [15, 15, "product"], [21, 21, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 5, 7, "related-to", "supports", false, false], [5, 11, 5, 7, "type-of", "", true, false], [13, 13, 5, 7, "type-of", "", true, false], [15, 15, 5, 7, "type-of", "", true, false], [15, 15, 21, 21, "related-to", "converting_to", true, false], [24, 24, 5, 7, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["OpenCV", "obs\u0142uguje", "niekt\u00f3re", "modele", "z", "framework\u00f3w", "g\u0142\u0119bokiego", "uczenia", ",", "takich", "jak", "TensorFlow", ",", "Torch", ",", "PyTorch", "(", "po", "konwersji", "do", "modelu", "ONNX", ")", "i", "Caffe", "zgodnie", "ze", "zdefiniowan\u0105", "list\u0105", "obs\u0142ugiwanych", "warstw", "."], "sentence-detokenized": "OpenCV obs\u0142uguje niekt\u00f3re modele z framework\u00f3w g\u0142\u0119bokiego uczenia, takich jak TensorFlow, Torch, PyTorch (po konwersji do modelu ONNX) i Caffe zgodnie ze zdefiniowan\u0105 list\u0105 obs\u0142ugiwanych warstw.", "token2charspan": [[0, 6], [7, 16], [17, 25], [26, 32], [33, 34], [35, 46], [47, 57], [58, 65], [65, 66], [67, 73], [74, 77], [78, 88], [88, 89], [90, 95], [95, 96], [97, 104], [105, 106], [106, 108], [109, 118], [119, 121], [122, 128], [129, 133], [133, 134], [135, 136], [137, 142], [143, 150], [151, 153], [154, 166], [167, 172], [173, 186], [187, 193], [193, 194]]}
{"doc_key": "ai-test-384", "ner": [[1, 1, "researcher"], [5, 8, "organisation"], [10, 10, "organisation"], [13, 17, "organisation"], [21, 21, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 5, 8, "role", "", false, false], [1, 1, 13, 17, "role", "", false, false], [1, 1, 21, 21, "related-to", "lectures_in", false, false], [10, 10, 5, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Wcze\u015bniej", "Christensen", "by\u0142", "przewodnicz\u0105cym", "za\u0142o\u017cycielem", "European", "Robotics", "Research", "Network", "(", "EURON", ")", "oraz", "IEEE", "Robotics", "and", "Automation", "Society", "Distinguished", "Lecturer", "in", "Robotics", "."], "sentence-detokenized": "Wcze\u015bniej Christensen by\u0142 przewodnicz\u0105cym za\u0142o\u017cycielem European Robotics Research Network (EURON) oraz IEEE Robotics and Automation Society Distinguished Lecturer in Robotics.", "token2charspan": [[0, 9], [10, 21], [22, 25], [26, 41], [42, 54], [55, 63], [64, 72], [73, 81], [82, 89], [90, 91], [91, 96], [96, 97], [98, 102], [103, 107], [108, 116], [117, 120], [121, 131], [132, 139], [140, 153], [154, 162], [163, 165], [166, 174], [174, 175]]}
{"doc_key": "ai-test-385", "ner": [[2, 2, "field"], [8, 11, "university"], [13, 13, "location"], [15, 18, "country"], [21, 21, "misc"], [23, 23, "field"], [25, 29, "organisation"], [30, 30, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[8, 11, 13, 13, "physical", "", false, false], [13, 13, 15, 18, "physical", "", false, false], [21, 21, 23, 23, "topic", "", false, false], [25, 29, 30, 30, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Tytu\u0142", "magistra", "matematyki", "uzyska\u0142", "w", "1958", "roku", "na", "Pa\u0144stwowym", "Uniwersytecie", "w", "Samarkandzie", ",", "Samarkanda", ",", "Uzbecka", "Socjalistyczna", "Republika", "Radziecka", ",", "a", "doktorat", "ze", "statystyki", "w", "Instytucie", "Nauk", "o", "Kontroli", "w", "Moskwie", "w", "1964", "roku", "."], "sentence-detokenized": "Tytu\u0142 magistra matematyki uzyska\u0142 w 1958 roku na Pa\u0144stwowym Uniwersytecie w Samarkandzie, Samarkanda, Uzbecka Socjalistyczna Republika Radziecka, a doktorat ze statystyki w Instytucie Nauk o Kontroli w Moskwie w 1964 roku.", "token2charspan": [[0, 5], [6, 14], [15, 25], [26, 33], [34, 35], [36, 40], [41, 45], [46, 48], [49, 59], [60, 73], [74, 75], [76, 88], [88, 89], [90, 100], [100, 101], [102, 109], [110, 124], [125, 134], [135, 144], [144, 145], [146, 147], [148, 156], [157, 159], [160, 170], [171, 172], [173, 183], [184, 188], [189, 190], [191, 199], [200, 201], [202, 209], [210, 211], [212, 216], [217, 221], [221, 222]]}
{"doc_key": "ai-test-386", "ner": [[5, 5, "organisation"], [9, 10, "product"], [28, 29, "field"], [31, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 28, 29, "usage", "", false, false], [5, 5, 31, 33, "usage", "", false, false], [9, 10, 5, 5, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Coraz", "cz\u0119\u015bciej", "jednak", "praca", "w", "Cycorp", "polega", "na", "nadaniu", "systemowi", "Cyc", "zdolno\u015bci", "do", "komunikowania", "si\u0119", "z", "u\u017cytkownikami", "ko\u0144cowymi", "w", "j\u0119zyku", "naturalnym", "oraz", "do", "wspomagania", "procesu", "tworzenia", "wiedzy", "poprzez", "uczenie", "maszynowe", "i", "rozumienie", "j\u0119zyka", "naturalnego", "."], "sentence-detokenized": "Coraz cz\u0119\u015bciej jednak praca w Cycorp polega na nadaniu systemowi Cyc zdolno\u015bci do komunikowania si\u0119 z u\u017cytkownikami ko\u0144cowymi w j\u0119zyku naturalnym oraz do wspomagania procesu tworzenia wiedzy poprzez uczenie maszynowe i rozumienie j\u0119zyka naturalnego.", "token2charspan": [[0, 5], [6, 14], [15, 21], [22, 27], [28, 29], [30, 36], [37, 43], [44, 46], [47, 54], [55, 64], [65, 68], [69, 78], [79, 81], [82, 95], [96, 99], [100, 101], [102, 115], [116, 125], [126, 127], [128, 134], [135, 145], [146, 150], [151, 153], [154, 165], [166, 173], [174, 183], [184, 190], [191, 198], [199, 206], [207, 216], [217, 218], [219, 229], [230, 236], [237, 248], [248, 249]]}
{"doc_key": "ai-test-387", "ner": [[56, 56, "metrics"], [58, 58, "metrics"], [60, 60, "metrics"], [62, 62, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Na", "przyk\u0142ad", ",", "je\u015bli", "poszukiwany", "jest", "najbardziej", "odpowiedni", "klasyfikator", "dla", "problemu", ",", "zbi\u00f3r", "danych", "szkoleniowych", "jest", "u\u017cywany", "do", "szkolenia", "algorytm\u00f3w", "kandyduj\u0105cych", ",", "zbi\u00f3r", "danych", "walidacyjnych", "jest", "u\u017cywany", "do", "por\u00f3wnania", "ich", "wydajno\u015bci", "i", "podj\u0119cia", "decyzji", ",", "kt\u00f3ry", "z", "nich", "nale\u017cy", "wzi\u0105\u0107", ",", "a", "na", "koniec", "zbi\u00f3r", "danych", "testowych", "jest", "u\u017cywany", "do", "uzyskania", "charakterystyki", "wydajno\u015bci", ",", "takiej", "jak", "dok\u0142adno\u015b\u0107", ",", "czu\u0142o\u015b\u0107", ",", "specyficzno\u015b\u0107", ",", "F-measure", "i", "tak", "dalej", "."], "sentence-detokenized": "Na przyk\u0142ad, je\u015bli poszukiwany jest najbardziej odpowiedni klasyfikator dla problemu, zbi\u00f3r danych szkoleniowych jest u\u017cywany do szkolenia algorytm\u00f3w kandyduj\u0105cych, zbi\u00f3r danych walidacyjnych jest u\u017cywany do por\u00f3wnania ich wydajno\u015bci i podj\u0119cia decyzji, kt\u00f3ry z nich nale\u017cy wzi\u0105\u0107, a na koniec zbi\u00f3r danych testowych jest u\u017cywany do uzyskania charakterystyki wydajno\u015bci, takiej jak dok\u0142adno\u015b\u0107, czu\u0142o\u015b\u0107, specyficzno\u015b\u0107, F-measure i tak dalej.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 18], [19, 30], [31, 35], [36, 47], [48, 58], [59, 71], [72, 75], [76, 84], [84, 85], [86, 91], [92, 98], [99, 112], [113, 117], [118, 125], [126, 128], [129, 138], [139, 149], [150, 163], [163, 164], [165, 170], [171, 177], [178, 191], [192, 196], [197, 204], [205, 207], [208, 218], [219, 222], [223, 233], [234, 235], [236, 244], [245, 252], [252, 253], [254, 259], [260, 261], [262, 266], [267, 273], [274, 279], [279, 280], [281, 282], [283, 285], [286, 292], [293, 298], [299, 305], [306, 315], [316, 320], [321, 328], [329, 331], [332, 341], [342, 357], [358, 368], [368, 369], [370, 376], [377, 380], [381, 391], [391, 392], [393, 400], [400, 401], [402, 415], [415, 416], [417, 426], [427, 428], [429, 432], [433, 438], [438, 439]]}
{"doc_key": "ai-test-388", "ner": [[0, 2, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["\u015aredni", "b\u0142\u0105d", "kwadratowy", "wynosi", "0,15", "."], "sentence-detokenized": "\u015aredni b\u0142\u0105d kwadratowy wynosi 0,15.", "token2charspan": [[0, 6], [7, 11], [12, 22], [23, 29], [30, 34], [34, 35]]}
{"doc_key": "ai-test-389", "ner": [[7, 11, "misc"], [6, 6, "organisation"], [15, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 7, 11, "role", "", false, false], [15, 15, 7, 11, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["W", "1979", "roku", "zosta\u0142", "zorganizowany", "przez", "IEEE", "konkurs", "Micromouse", ",", "kt\u00f3ry", "zosta\u0142", "przedstawiony", "w", "magazynie", "Spectrum", "."], "sentence-detokenized": "W 1979 roku zosta\u0142 zorganizowany przez IEEE konkurs Micromouse, kt\u00f3ry zosta\u0142 przedstawiony w magazynie Spectrum.", "token2charspan": [[0, 1], [2, 6], [7, 11], [12, 18], [19, 32], [33, 38], [39, 43], [44, 51], [52, 62], [62, 63], [64, 69], [70, 76], [77, 90], [91, 92], [93, 102], [103, 111], [111, 112]]}
{"doc_key": "ai-test-390", "ner": [[0, 1, "algorithm"], [9, 9, "field"], [14, 16, "task"], [18, 19, "task"], [21, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 9, 9, "part-of", "", false, false], [14, 16, 9, 9, "part-of", "task_part_of_field", false, false], [18, 19, 9, 9, "part-of", "task_part_of_field", false, false], [21, 22, 9, 9, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Przestrze\u0144", "Gabora", "jest", "bardzo", "przydatna", "w", "zastosowaniach", "zwi\u0105zanych", "z", "przetwarzaniem", "obraz\u00f3w", ",", "takich", "jak", "optyczne", "rozpoznawanie", "znak\u00f3w", ",", "rozpoznawanie", "t\u0119cz\u00f3wki", "i", "odcisk\u00f3w", "palc\u00f3w", "."], "sentence-detokenized": "Przestrze\u0144 Gabora jest bardzo przydatna w zastosowaniach zwi\u0105zanych z przetwarzaniem obraz\u00f3w, takich jak optyczne rozpoznawanie znak\u00f3w, rozpoznawanie t\u0119cz\u00f3wki i odcisk\u00f3w palc\u00f3w.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 29], [30, 39], [40, 41], [42, 56], [57, 67], [68, 69], [70, 84], [85, 92], [92, 93], [94, 100], [101, 104], [105, 113], [114, 127], [128, 134], [134, 135], [136, 149], [150, 158], [159, 160], [161, 169], [170, 176], [176, 177]]}
{"doc_key": "ai-test-391", "ner": [[5, 5, "programlang"], [7, 7, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["lub", "poprzez", "wysokopoziomowe", "interfejsy", "do", "Javy", "i", "Tcl", "."], "sentence-detokenized": "lub poprzez wysokopoziomowe interfejsy do Javy i Tcl.", "token2charspan": [[0, 3], [4, 11], [12, 27], [28, 38], [39, 41], [42, 46], [47, 48], [49, 52], [52, 53]]}
{"doc_key": "ai-test-392", "ner": [[10, 12, "algorithm"], [18, 18, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 12, 18, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["W", "ostatnich", "badaniach", "metody", "oparte", "na", "j\u0105drze", ",", "takie", "jak", "maszyny", "wektor\u00f3w", "wsparcia", ",", "wykaza\u0142y", "wy\u017csz\u0105", "wydajno\u015b\u0107", "w", "nadzorowanych", "."], "sentence-detokenized": "W ostatnich badaniach metody oparte na j\u0105drze, takie jak maszyny wektor\u00f3w wsparcia, wykaza\u0142y wy\u017csz\u0105 wydajno\u015b\u0107 w nadzorowanych.", "token2charspan": [[0, 1], [2, 11], [12, 21], [22, 28], [29, 35], [36, 38], [39, 45], [45, 46], [47, 52], [53, 56], [57, 64], [65, 73], [74, 82], [82, 83], [84, 92], [93, 99], [100, 109], [110, 111], [112, 125], [125, 126]]}
{"doc_key": "ai-test-393", "ner": [[12, 12, "misc"], [19, 19, "researcher"], [21, 21, "researcher"], [29, 29, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[19, 19, 29, 29, "usage", "", false, false], [21, 21, 29, 29, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Aby", "zobrazowa\u0107", "podstawowe", "zasady", "workowania", ",", "poni\u017cej", "przedstawiono", "analiz\u0119", "dotycz\u0105c\u0105", "zale\u017cno\u015bci", "pomi\u0119dzy", "ozonem", "a", "temperatur\u0105", "(", "dane", "pochodz\u0105", "od", "Rousseeuw", "i", "Leroy", "(", "1986", ")", ",", "analiza", "wykonana", "w", "R", ")", "."], "sentence-detokenized": "Aby zobrazowa\u0107 podstawowe zasady workowania, poni\u017cej przedstawiono analiz\u0119 dotycz\u0105c\u0105 zale\u017cno\u015bci pomi\u0119dzy ozonem a temperatur\u0105 (dane pochodz\u0105 od Rousseeuw i Leroy (1986), analiza wykonana w R).", "token2charspan": [[0, 3], [4, 14], [15, 25], [26, 32], [33, 43], [43, 44], [45, 52], [53, 66], [67, 74], [75, 84], [85, 95], [96, 104], [105, 111], [112, 113], [114, 125], [126, 127], [127, 131], [132, 140], [141, 143], [144, 153], [154, 155], [156, 161], [162, 163], [163, 167], [167, 168], [168, 169], [170, 177], [178, 186], [187, 188], [189, 190], [190, 191], [191, 192]]}
{"doc_key": "ai-test-394", "ner": [[0, 1, "organisation"], [13, 15, "product"], [21, 22, "product"], [24, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 15, 0, 1, "artifact", "", false, false], [21, 22, 0, 1, "artifact", "", false, false], [24, 26, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Denso", "Wave", "jest", "sp\u00f3\u0142k\u0105", "zale\u017cn\u0105", ",", "kt\u00f3ra", "produkuje", "produkty", "do", "automatycznej", "identyfikacji", "(", "czytniki", "kod\u00f3w", "kreskowych", "i", "produkty", "pokrewne", ")", ",", "roboty", "przemys\u0142owe", "i", "programowalne", "kontrolery", "logiczne", "."], "sentence-detokenized": "Denso Wave jest sp\u00f3\u0142k\u0105 zale\u017cn\u0105, kt\u00f3ra produkuje produkty do automatycznej identyfikacji (czytniki kod\u00f3w kreskowych i produkty pokrewne), roboty przemys\u0142owe i programowalne kontrolery logiczne.", "token2charspan": [[0, 5], [6, 10], [11, 15], [16, 22], [23, 30], [30, 31], [32, 37], [38, 47], [48, 56], [57, 59], [60, 73], [74, 87], [88, 89], [89, 97], [98, 103], [104, 114], [115, 116], [117, 125], [126, 134], [134, 135], [135, 136], [137, 143], [144, 155], [156, 157], [158, 171], [172, 182], [183, 191], [191, 192]]}
{"doc_key": "ai-test-395", "ner": [[1, 3, "metrics"], [7, 9, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 3, 18, 18, "compare", "", false, false], [7, 9, 1, 3, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Gdzie", "Bilingual", "evaluation", "understudy", "po", "prostu", "oblicza", "precyzj\u0119n", "-", "gram\u00f3w", "dodaj\u0105c", "r\u00f3wn\u0105", "wag\u0119", "do", "ka\u017cdego", "z", "nich", ",", "NIST", "oblicza", "r\u00f3wnie\u017c", "jak", "informatywny", "jest", "danyn-", "gram", "."], "sentence-detokenized": "Gdzie Bilingual evaluation understudy po prostu oblicza precyzj\u0119n-gram\u00f3w dodaj\u0105c r\u00f3wn\u0105 wag\u0119 do ka\u017cdego z nich, NIST oblicza r\u00f3wnie\u017c jak informatywny jest danyn-gram.", "token2charspan": [[0, 5], [6, 15], [16, 26], [27, 37], [38, 40], [41, 47], [48, 55], [56, 65], [65, 66], [66, 72], [73, 80], [81, 86], [87, 91], [92, 94], [95, 102], [103, 104], [105, 109], [109, 110], [111, 115], [116, 123], [124, 131], [132, 135], [136, 148], [149, 153], [154, 160], [160, 164], [164, 165]]}
{"doc_key": "ai-test-396", "ner": [[12, 12, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["W", "szczeg\u00f3lno\u015bci", "s\u0105", "one", "wykorzystywane", "podczas", "obliczania", "prawdopodobie\u0144stwa", "drzewa", "(", "w", "podej\u015bciu", "bayesowskim", "i", "maksymalnego", "prawdopodobie\u0144stwa", "do", "estymacji", "drzew", ")", "oraz", "s\u0142u\u017c\u0105", "do", "szacowania", "odleg\u0142o\u015bci", "ewolucyjnej", "mi\u0119dzy", "sekwencjami", "na", "podstawie", "obserwowanych", "r\u00f3\u017cnic", "mi\u0119dzy", "sekwencjami", "."], "sentence-detokenized": "W szczeg\u00f3lno\u015bci s\u0105 one wykorzystywane podczas obliczania prawdopodobie\u0144stwa drzewa (w podej\u015bciu bayesowskim i maksymalnego prawdopodobie\u0144stwa do estymacji drzew) oraz s\u0142u\u017c\u0105 do szacowania odleg\u0142o\u015bci ewolucyjnej mi\u0119dzy sekwencjami na podstawie obserwowanych r\u00f3\u017cnic mi\u0119dzy sekwencjami.", "token2charspan": [[0, 1], [2, 15], [16, 18], [19, 22], [23, 37], [38, 45], [46, 56], [57, 75], [76, 82], [83, 84], [84, 85], [86, 95], [96, 107], [108, 109], [110, 122], [123, 141], [142, 144], [145, 154], [155, 160], [160, 161], [162, 166], [167, 172], [173, 175], [176, 186], [187, 197], [198, 209], [210, 216], [217, 228], [229, 231], [232, 241], [242, 255], [256, 262], [263, 269], [270, 281], [281, 282]]}
{"doc_key": "ai-test-397", "ner": [[0, 2, "conference"], [18, 19, "misc"], [21, 21, "misc"], [45, 46, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 21, 18, 19, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Audio", "Engineering", "Society", "zaleca", "cz\u0119stotliwo\u015b\u0107", "pr\u00f3bkowania", "48", "kHz", "dla", "wi\u0119kszo\u015bci", "zastosowa\u0144", ",", "ale", "uznaje", "cz\u0119stotliwo\u015b\u0107", "44,1", "kHz", "dla", "p\u0142yt", "kompaktowych", "(", "CD", ")", "i", "innych", "zastosowa\u0144", "konsumenckich", ",", "32", "kHz", "dla", "zastosowa\u0144", "zwi\u0105zanych", "z", "transmisj\u0105", "oraz", "96", "kHz", "w", "przypadku", "wi\u0119kszej", "szeroko\u015bci", "pasma", "lub", "zredukowanego", "filtra", "antyaliasingowego", "."], "sentence-detokenized": "Audio Engineering Society zaleca cz\u0119stotliwo\u015b\u0107 pr\u00f3bkowania 48 kHz dla wi\u0119kszo\u015bci zastosowa\u0144, ale uznaje cz\u0119stotliwo\u015b\u0107 44,1 kHz dla p\u0142yt kompaktowych (CD) i innych zastosowa\u0144 konsumenckich, 32 kHz dla zastosowa\u0144 zwi\u0105zanych z transmisj\u0105 oraz 96 kHz w przypadku wi\u0119kszej szeroko\u015bci pasma lub zredukowanego filtra antyaliasingowego.", "token2charspan": [[0, 5], [6, 17], [18, 25], [26, 32], [33, 46], [47, 58], [59, 61], [62, 65], [66, 69], [70, 80], [81, 91], [91, 92], [93, 96], [97, 103], [104, 117], [118, 122], [123, 126], [127, 130], [131, 135], [136, 148], [149, 150], [150, 152], [152, 153], [154, 155], [156, 162], [163, 173], [174, 187], [187, 188], [189, 191], [192, 195], [196, 199], [200, 210], [211, 221], [222, 223], [224, 234], [235, 239], [240, 242], [243, 246], [247, 248], [249, 258], [259, 267], [268, 278], [279, 284], [285, 288], [289, 302], [303, 309], [310, 327], [327, 328]]}
{"doc_key": "ai-test-398", "ner": [[9, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Zasoby", "dotycz\u0105ce", "afektywno\u015bci", "s\u0142\u00f3w", "i", "poj\u0119\u0107", "zosta\u0142y", "wykonane", "dla", "WordNet", "{", "{", "cite", "journal"], "sentence-detokenized": "Zasoby dotycz\u0105ce afektywno\u015bci s\u0142\u00f3w i poj\u0119\u0107 zosta\u0142y wykonane dla WordNet {{cite journal", "token2charspan": [[0, 6], [7, 16], [17, 29], [30, 34], [35, 36], [37, 42], [43, 50], [51, 59], [60, 63], [64, 71], [72, 73], [73, 74], [74, 78], [79, 86]]}
{"doc_key": "ai-test-399", "ner": [[1, 4, "misc"], [20, 21, "person"], [24, 28, "person"], [32, 34, "person"], [39, 43, "organisation"], [62, 62, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[24, 28, 32, 34, "role", "acts_in", false, false], [39, 43, 32, 34, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["W", "czerwono", "-", "zielonym", "anaglifie", "zaprezentowano", "widzom", "trzy", "szpule", "test\u00f3w", ",", "na", "kt\u00f3rych", "znalaz\u0142y", "si\u0119", "sceny", "wiejskie", ",", "pr\u00f3bne", "uj\u0119cia", "Marie", "Doro", ",", "segment", "Johna", "B", ".", "Masona", "graj\u0105cego", "kilka", "fragment\u00f3w", "z", "Jim", "the", "Penman", "(", "filmu", "wydanego", "przez", "Famous", "Players", "-", "Lasky", "w", "tym", "samym", "roku", ",", "ale", "nie", "w", "3D", ")", ",", "orientalne", "tancerki", "oraz", "szpula", "z", "materia\u0142em", "o", "wodospadzie", "Niagara", "."], "sentence-detokenized": "W czerwono-zielonym anaglifie zaprezentowano widzom trzy szpule test\u00f3w, na kt\u00f3rych znalaz\u0142y si\u0119 sceny wiejskie, pr\u00f3bne uj\u0119cia Marie Doro, segment Johna B. Masona graj\u0105cego kilka fragment\u00f3w z Jim the Penman (filmu wydanego przez Famous Players-Lasky w tym samym roku, ale nie w 3D), orientalne tancerki oraz szpula z materia\u0142em o wodospadzie Niagara.", "token2charspan": [[0, 1], [2, 10], [10, 11], [11, 19], [20, 29], [30, 44], [45, 51], [52, 56], [57, 63], [64, 70], [70, 71], [72, 74], [75, 82], [83, 91], [92, 95], [96, 101], [102, 110], [110, 111], [112, 118], [119, 125], [126, 131], [132, 136], [136, 137], [138, 145], [146, 151], [152, 153], [153, 154], [155, 161], [162, 171], [172, 177], [178, 188], [189, 190], [191, 194], [195, 198], [199, 205], [206, 207], [207, 212], [213, 221], [222, 227], [228, 234], [235, 242], [242, 243], [243, 248], [249, 250], [251, 254], [255, 260], [261, 265], [265, 266], [267, 270], [271, 274], [275, 276], [277, 279], [279, 280], [280, 281], [282, 292], [293, 301], [302, 306], [307, 313], [314, 315], [316, 326], [327, 328], [329, 340], [341, 348], [348, 349]]}
{"doc_key": "ai-test-400", "ner": [[5, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Jest", "to", "szczeg\u00f3lny", "spos\u00f3b", "implementacji", "estymacji", "maksymalnego", "prawdopodobie\u0144stwa", "dla", "tego", "problemu", "."], "sentence-detokenized": "Jest to szczeg\u00f3lny spos\u00f3b implementacji estymacji maksymalnego prawdopodobie\u0144stwa dla tego problemu.", "token2charspan": [[0, 4], [5, 7], [8, 18], [19, 25], [26, 39], [40, 49], [50, 62], [63, 81], [82, 85], [86, 90], [91, 99], [99, 100]]}
{"doc_key": "ai-test-401", "ner": [[0, 2, "product"], [9, 10, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Crawler-friendly", "Web", "Servers", ",", "i", "integruje", "cechy", "sitemaps", "i", "RSS", "feeds", "w", "zdecentralizowany", "mechanizm", "dla", "biolog\u00f3w", "obliczeniowych", "i", "bioinformatyk\u00f3w", "do", "otwartego", "nadawania", "i", "pobierania", "meta", "danych", "o", "zasobach", "biomedycznych", "."], "sentence-detokenized": "Crawler-friendly Web Servers, i integruje cechy sitemaps i RSS feeds w zdecentralizowany mechanizm dla biolog\u00f3w obliczeniowych i bioinformatyk\u00f3w do otwartego nadawania i pobierania meta danych o zasobach biomedycznych.", "token2charspan": [[0, 16], [17, 20], [21, 28], [28, 29], [30, 31], [32, 41], [42, 47], [48, 56], [57, 58], [59, 62], [63, 68], [69, 70], [71, 88], [89, 98], [99, 102], [103, 111], [112, 126], [127, 128], [129, 144], [145, 147], [148, 157], [158, 167], [168, 169], [170, 180], [181, 185], [186, 192], [193, 194], [195, 203], [204, 217], [217, 218]]}
{"doc_key": "ai-test-402", "ner": [[4, 11, "misc"], [15, 18, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Jest", "on", "obj\u0119ty", "norm\u0105", "American", "National", "Standards", "Institute", "/", "NISO", "standard", "Z39.50", ",", "oraz", "norm\u0105", "Mi\u0119dzynarodowej", "Organizacji", "Normalizacyjnej", "23950", "."], "sentence-detokenized": "Jest on obj\u0119ty norm\u0105 American National Standards Institute / NISO standard Z39.50, oraz norm\u0105 Mi\u0119dzynarodowej Organizacji Normalizacyjnej 23950.", "token2charspan": [[0, 4], [5, 7], [8, 14], [15, 20], [21, 29], [30, 38], [39, 48], [49, 58], [59, 60], [61, 65], [66, 74], [75, 81], [81, 82], [83, 87], [88, 93], [94, 109], [110, 121], [122, 137], [138, 143], [143, 144]]}
{"doc_key": "ai-test-403", "ner": [[12, 13, "misc"], [19, 19, "metrics"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Koder", "i", "dekoder", "s\u0105", "trenowane", "tak", ",", "aby", "wzi\u0105\u0107", "fraz\u0119", "i", "odtworzy\u0107", "rozk\u0142ad", "one-hot", "odpowiadaj\u0105cej", "jej", "parafrazy", "poprzez", "minimalizacj\u0119", "perplexity", "przy", "u\u017cyciu", "prostego", "stochastycznego", "zej\u015bcia", "gradientowego", "."], "sentence-detokenized": "Koder i dekoder s\u0105 trenowane tak, aby wzi\u0105\u0107 fraz\u0119 i odtworzy\u0107 rozk\u0142ad one-hot odpowiadaj\u0105cej jej parafrazy poprzez minimalizacj\u0119 perplexity przy u\u017cyciu prostego stochastycznego zej\u015bcia gradientowego.", "token2charspan": [[0, 5], [6, 7], [8, 15], [16, 18], [19, 28], [29, 32], [32, 33], [34, 37], [38, 43], [44, 49], [50, 51], [52, 61], [62, 69], [70, 77], [78, 92], [93, 96], [97, 106], [107, 114], [115, 128], [129, 139], [140, 144], [145, 151], [152, 160], [161, 176], [177, 184], [185, 198], [198, 199]]}
{"doc_key": "ai-test-404", "ner": [[4, 5, "field"], [7, 9, "task"], [11, 15, "task"], [27, 32, "task"], [34, 38, "task"], [40, 46, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 9, 4, 5, "part-of", "task_part_of_field", false, false], [11, 15, 4, 5, "part-of", "task_part_of_field", false, false], [27, 32, 4, 5, "part-of", "task_part_of_field", false, false], [34, 38, 4, 5, "part-of", "task_part_of_field", false, false], [40, 46, 4, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Inne", "typowe", "zastosowania", "technik", "rozpoznawania", "wzorc\u00f3w", "to", "automatyczne", "rozpoznawanie", "mowy", ",", "klasyfikacja", "tekstu", "na", "kilka", "kategorii", "(", "np", ".", "wiadomo\u015bci", "e-mail", "typu", "spam", "/", "niespam", ")", ",", "rozpoznawanie", "pisma", "r\u0119cznego", "na", "kopertach", "pocztowych", ",", "automatyczne", "rozpoznawanie", "obraz\u00f3w", "ludzkich", "twarzy", "czy", "ekstrakcja", "obrazu", "pisma", "r\u0119cznego", "z", "formularzy", "medycznych", "."], "sentence-detokenized": "Inne typowe zastosowania technik rozpoznawania wzorc\u00f3w to automatyczne rozpoznawanie mowy, klasyfikacja tekstu na kilka kategorii (np. wiadomo\u015bci e-mail typu spam/niespam), rozpoznawanie pisma r\u0119cznego na kopertach pocztowych, automatyczne rozpoznawanie obraz\u00f3w ludzkich twarzy czy ekstrakcja obrazu pisma r\u0119cznego z formularzy medycznych.", "token2charspan": [[0, 4], [5, 11], [12, 24], [25, 32], [33, 46], [47, 54], [55, 57], [58, 70], [71, 84], [85, 89], [89, 90], [91, 103], [104, 110], [111, 113], [114, 119], [120, 129], [130, 131], [131, 133], [133, 134], [135, 145], [146, 152], [153, 157], [158, 162], [162, 163], [163, 170], [170, 171], [171, 172], [173, 186], [187, 192], [193, 201], [202, 204], [205, 214], [215, 225], [225, 226], [227, 239], [240, 253], [254, 261], [262, 270], [271, 277], [278, 281], [282, 292], [293, 299], [300, 305], [306, 314], [315, 316], [317, 327], [328, 338], [338, 339]]}
{"doc_key": "ai-test-405", "ner": [[0, 2, "algorithm"], [12, 13, "field"], [15, 16, "task"], [18, 19, "task"], [21, 23, "task"], [25, 30, "task"], [32, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 13, 0, 2, "usage", "", false, false], [15, 16, 0, 2, "usage", "", false, false], [18, 19, 0, 2, "usage", "", false, false], [21, 23, 0, 2, "usage", "", false, false], [25, 30, 0, 2, "usage", "", false, false], [32, 33, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sztuczne", "sieci", "neuronowe", "zosta\u0142y", "wykorzystane", "do", "wielu", "zada\u0144", ",", "w", "tym", "do", "wizji", "komputerowej", ",", "rozpoznawania", "mowy", ",", "t\u0142umaczenia", "maszynowego", ",", "filtrowania", "sieci", "spo\u0142eczno\u015bciowych", ",", "grania", "w", "gry", "planszowe", "i", "wideo", "oraz", "diagnostyki", "medycznej", "."], "sentence-detokenized": "Sztuczne sieci neuronowe zosta\u0142y wykorzystane do wielu zada\u0144, w tym do wizji komputerowej, rozpoznawania mowy, t\u0142umaczenia maszynowego, filtrowania sieci spo\u0142eczno\u015bciowych, grania w gry planszowe i wideo oraz diagnostyki medycznej.", "token2charspan": [[0, 8], [9, 14], [15, 24], [25, 32], [33, 45], [46, 48], [49, 54], [55, 60], [60, 61], [62, 63], [64, 67], [68, 70], [71, 76], [77, 89], [89, 90], [91, 104], [105, 109], [109, 110], [111, 122], [123, 134], [134, 135], [136, 147], [148, 153], [154, 171], [171, 172], [173, 179], [180, 181], [182, 185], [186, 195], [196, 197], [198, 203], [204, 208], [209, 220], [221, 230], [230, 231]]}
{"doc_key": "ai-test-406", "ner": [[2, 3, "organisation"], [4, 4, "product"], [12, 12, "product"], [15, 15, "organisation"], [16, 17, "product"], [19, 19, "product"], [21, 23, "product"], [25, 25, "product"], [27, 27, "programlang"], [33, 34, "field"], [40, 40, "product"], [45, 45, "algorithm"], [47, 47, "algorithm"], [49, 49, "algorithm"], [52, 52, "product"], [60, 60, "task"], [65, 66, "algorithm"], [69, 69, "product"], [71, 71, "product"], [75, 77, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "relations": [[4, 4, 2, 3, "origin", "", false, false], [4, 4, 12, 12, "named", "same", false, false], [4, 4, 40, 40, "named", "same", false, false], [27, 27, 33, 34, "related-to", "used_for", false, false], [45, 45, 27, 27, "part-of", "", true, false], [45, 45, 40, 40, "origin", "", true, false], [47, 47, 27, 27, "part-of", "", true, false], [47, 47, 40, 40, "origin", "", true, false], [49, 49, 27, 27, "part-of", "", true, false], [49, 49, 40, 40, "origin", "", true, false], [52, 52, 60, 60, "related-to", "used_for", false, false], [65, 66, 52, 52, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Przyk\u0142ady", "to", "Salford", "Systems", "CART", "(", "kt\u00f3ry", "licencjonowa\u0142", "zastrze\u017cony", "kod", "oryginalnych", "autor\u00f3w", "CART", ")", ",", "IBM", "SPSS", "Modeler", ",", "RapidMiner", ",", "SAS", "Enterprise", "Miner", ",", "Matlab", ",", "R", "(", "\u015brodowisko", "oprogramowania", "open-source", "do", "oblicze\u0144", "statystycznych", ",", "kt\u00f3re", "zawiera", "kilka", "implementacji", "CART", ",", "takich", "jak", "pakiety", "rpart", ",", "party", "i", "randomForest", ")", ",", "Weka", "(", "darmowy", "i", "open-source", "pakiet", "do", "eksploracji", "danych", ",", "zawiera", "wiele", "algorytm\u00f3w", "drzew", "decyzyjnych", ")", ",", "Orange", ",", "KNIME", ",", "j\u0119zyk", "programowania", "Microsoft", "SQL", "Server", ")", "."], "sentence-detokenized": "Przyk\u0142ady to Salford Systems CART (kt\u00f3ry licencjonowa\u0142 zastrze\u017cony kod oryginalnych autor\u00f3w CART), IBM SPSS Modeler, RapidMiner, SAS Enterprise Miner, Matlab, R (\u015brodowisko oprogramowania open-source do oblicze\u0144 statystycznych, kt\u00f3re zawiera kilka implementacji CART, takich jak pakiety rpart, party i randomForest), Weka (darmowy i open-source pakiet do eksploracji danych, zawiera wiele algorytm\u00f3w drzew decyzyjnych), Orange, KNIME, j\u0119zyk programowania Microsoft SQL Server).", "token2charspan": [[0, 9], [10, 12], [13, 20], [21, 28], [29, 33], [34, 35], [35, 40], [41, 54], [55, 66], [67, 70], [71, 83], [84, 91], [92, 96], [96, 97], [97, 98], [99, 102], [103, 107], [108, 115], [115, 116], [117, 127], [127, 128], [129, 132], [133, 143], [144, 149], [149, 150], [151, 157], [157, 158], [159, 160], [161, 162], [162, 172], [173, 187], [188, 199], [200, 202], [203, 211], [212, 226], [226, 227], [228, 233], [234, 241], [242, 247], [248, 261], [262, 266], [266, 267], [268, 274], [275, 278], [279, 286], [287, 292], [292, 293], [294, 299], [300, 301], [302, 314], [314, 315], [315, 316], [317, 321], [322, 323], [323, 330], [331, 332], [333, 344], [345, 351], [352, 354], [355, 366], [367, 373], [373, 374], [375, 382], [383, 388], [389, 399], [400, 405], [406, 417], [417, 418], [418, 419], [420, 426], [426, 427], [428, 433], [433, 434], [435, 440], [441, 454], [455, 464], [465, 468], [469, 475], [475, 476], [476, 477]]}
{"doc_key": "ai-test-407", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [12, 13, "researcher"], [15, 16, "university"], [18, 19, "researcher"], [21, 24, "organisation"], [26, 26, "organisation"], [37, 40, "researcher"], [42, 46, "researcher"], [47, 49, "organisation"], [61, 65, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 2, 12, 13, "origin", "", false, false], [0, 2, 18, 19, "origin", "", false, false], [0, 2, 37, 40, "origin", "", false, false], [0, 2, 42, 46, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [12, 13, 15, 16, "physical", "", false, false], [12, 13, 15, 16, "role", "", false, false], [18, 19, 21, 24, "physical", "", false, false], [18, 19, 21, 24, "role", "", false, false], [26, 26, 21, 24, "named", "", false, false], [37, 40, 47, 49, "physical", "", false, false], [37, 40, 47, 49, "role", "", false, false], [42, 46, 47, 49, "physical", "", false, false], [42, 46, 47, 49, "role", "", false, false], [61, 65, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Liniowe", "kodowanie", "predykcyjne", "(", "LPC", ")", "zosta\u0142o", "po", "raz", "pierwszy", "opracowane", "przez", "Fumitad\u0119", "Itakur\u0119", "z", "Uniwersytetu", "Nagoya", "i", "Shuzo", "Saito", "z", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "w", "1966", "roku", ",", "a", "nast\u0119pnie", "dalej", "rozwijane", "przez", "Bishnu", "S", ".", "Atala", "i", "Manfreda", "R", ".", "Schroedera", "w", "Bell", "Labs", "we", "wczesnych", "i", "\u015brednich", "latach", "70-tych", ",", "staj\u0105c", "si\u0119", "podstaw\u0105", "pierwszych", "uk\u0142ad\u00f3w", "DSP", "z", "syntez\u0105", "mowy", "pod", "koniec", "lat", "70-tych", "."], "sentence-detokenized": "Liniowe kodowanie predykcyjne (LPC) zosta\u0142o po raz pierwszy opracowane przez Fumitad\u0119 Itakur\u0119 z Uniwersytetu Nagoya i Shuzo Saito z Nippon Telegraph and Telephone (NTT) w 1966 roku, a nast\u0119pnie dalej rozwijane przez Bishnu S. Atala i Manfreda R. Schroedera w Bell Labs we wczesnych i \u015brednich latach 70-tych, staj\u0105c si\u0119 podstaw\u0105 pierwszych uk\u0142ad\u00f3w DSP z syntez\u0105 mowy pod koniec lat 70-tych.", "token2charspan": [[0, 7], [8, 17], [18, 29], [30, 31], [31, 34], [34, 35], [36, 43], [44, 46], [47, 50], [51, 59], [60, 70], [71, 76], [77, 85], [86, 93], [94, 95], [96, 108], [109, 115], [116, 117], [118, 123], [124, 129], [130, 131], [132, 138], [139, 148], [149, 152], [153, 162], [163, 164], [164, 167], [167, 168], [169, 170], [171, 175], [176, 180], [180, 181], [182, 183], [184, 193], [194, 199], [200, 209], [210, 215], [216, 222], [223, 224], [224, 225], [226, 231], [232, 233], [234, 242], [243, 244], [244, 245], [246, 256], [257, 258], [259, 263], [264, 268], [269, 271], [272, 281], [282, 283], [284, 292], [293, 299], [300, 307], [307, 308], [309, 315], [316, 319], [320, 328], [329, 339], [340, 347], [348, 351], [352, 353], [354, 361], [362, 366], [367, 370], [371, 377], [378, 381], [382, 389], [389, 390]]}
{"doc_key": "ai-test-408", "ner": [[0, 0, "metrics"], [3, 3, "metrics"], [5, 5, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 0, 0, "part-of", "", false, false], [5, 5, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["F-score", "jest", "po\u0142\u0105czeniem", "precyzji", "i", "recall", ",", "daj\u0105c", "pojedynczy", "wynik", "."], "sentence-detokenized": "F-score jest po\u0142\u0105czeniem precyzji i recall, daj\u0105c pojedynczy wynik.", "token2charspan": [[0, 7], [8, 12], [13, 24], [25, 33], [34, 35], [36, 42], [42, 43], [44, 49], [50, 60], [61, 66], [66, 67]]}
{"doc_key": "ai-test-409", "ner": [[3, 4, "field"], [10, 14, "task"], [19, 21, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 14, 3, 4, "part-of", "task_part_of_field", false, false], [19, 21, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Zadania", "zwi\u0105zane", "z", "analiz\u0105", "obrazu", "mog\u0105", "by\u0107", "tak", "proste", "jak", "odczytywanie", "kod\u00f3w", "kreskowych", "d", "tag\u00f3w", "lub", "tak", "zaawansowane", "jak", "system", "rozpoznawania", "twarzy", "."], "sentence-detokenized": "Zadania zwi\u0105zane z analiz\u0105 obrazu mog\u0105 by\u0107 tak proste jak odczytywanie kod\u00f3w kreskowych d tag\u00f3w lub tak zaawansowane jak system rozpoznawania twarzy.", "token2charspan": [[0, 7], [8, 16], [17, 18], [19, 26], [27, 33], [34, 38], [39, 42], [43, 46], [47, 53], [54, 57], [58, 70], [71, 76], [77, 87], [88, 89], [90, 95], [96, 99], [100, 103], [104, 116], [117, 120], [121, 127], [128, 141], [142, 148], [148, 149]]}
{"doc_key": "ai-test-410", "ner": [[3, 5, "algorithm"], [22, 23, "algorithm"], [29, 31, "algorithm"], [35, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[29, 31, 22, 23, "type-of", "", false, false], [35, 35, 29, 31, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Szczeg\u00f3lny", "przypadek", "liniowych", "maszyn", "wektorowych", "wsparcia", "mo\u017ce", "by\u0107", "rozwi\u0105zany", "bardziej", "efektywnie", "przez", "ten", "sam", "rodzaj", "algorytm\u00f3w", "do", "optymalizacji", "jego", "bliskiego", "kuzyna", ",", "regresji", "logistycznej", ";", "ta", "klasa", "algorytm\u00f3w", "obejmuje", "Stochastic", "gradient", "descent", "(", "np", ".", "PEGASOS", ")", "."], "sentence-detokenized": "Szczeg\u00f3lny przypadek liniowych maszyn wektorowych wsparcia mo\u017ce by\u0107 rozwi\u0105zany bardziej efektywnie przez ten sam rodzaj algorytm\u00f3w do optymalizacji jego bliskiego kuzyna, regresji logistycznej; ta klasa algorytm\u00f3w obejmuje Stochastic gradient descent (np. PEGASOS).", "token2charspan": [[0, 10], [11, 20], [21, 30], [31, 37], [38, 49], [50, 58], [59, 63], [64, 67], [68, 78], [79, 87], [88, 98], [99, 104], [105, 108], [109, 112], [113, 119], [120, 130], [131, 133], [134, 147], [148, 152], [153, 162], [163, 169], [169, 170], [171, 179], [180, 192], [192, 193], [194, 196], [197, 202], [203, 213], [214, 222], [223, 233], [234, 242], [243, 250], [251, 252], [252, 254], [254, 255], [256, 263], [263, 264], [264, 265]]}
{"doc_key": "ai-test-411", "ner": [[1, 1, "product"], [6, 6, "product"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 6, 6, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Kiedy", "Siri", "na", "urz\u0105dzeniu", "z", "systemem", "iOS", "jest", "pytana", "Czy", "masz", "zwierzaka", "?", ",", "jedn\u0105", "z", "odpowiedzi", "jest", "I", "used", "to", "have", "an", "AIBO", "."], "sentence-detokenized": "Kiedy Siri na urz\u0105dzeniu z systemem iOS jest pytana Czy masz zwierzaka?, jedn\u0105 z odpowiedzi jest I used to have an AIBO.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 24], [25, 26], [27, 35], [36, 39], [40, 44], [45, 51], [52, 55], [56, 60], [61, 70], [70, 71], [71, 72], [73, 78], [79, 80], [81, 91], [92, 96], [97, 98], [99, 103], [104, 106], [107, 111], [112, 114], [115, 119], [119, 120]]}
{"doc_key": "ai-test-412", "ner": [[1, 2, "task"], [3, 5, "metrics"], [11, 11, "metrics"], [13, 13, "metrics"]], "ner_mapping_to_source": [0, 1, 3, 4], "relations": [[3, 5, 1, 2, "part-of", "", false, false], [11, 11, 1, 2, "part-of", "", false, false], [13, 13, 11, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 2, 3], "sentence": ["W", "wyszukiwaniu", "informacji", "pozytywna", "warto\u015b\u0107", "predykcyjna", "nazywana", "jest", "precyzj\u0105", ",", "a", "czu\u0142o\u015b\u0107", "-", "recall", "."], "sentence-detokenized": "W wyszukiwaniu informacji pozytywna warto\u015b\u0107 predykcyjna nazywana jest precyzj\u0105, a czu\u0142o\u015b\u0107 - recall.", "token2charspan": [[0, 1], [2, 14], [15, 25], [26, 35], [36, 43], [44, 55], [56, 64], [65, 69], [70, 78], [78, 79], [80, 81], [82, 89], [90, 91], [92, 98], [98, 99]]}
{"doc_key": "ai-test-413", "ner": [[11, 11, "field"], [13, 13, "task"], [15, 15, "task"], [17, 18, "task"], [32, 33, "task"], [35, 36, "task"], [38, 43, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 13, 11, 11, "part-of", "task_part_of_field", false, false], [15, 15, 11, 11, "part-of", "task_part_of_field", false, false], [17, 18, 11, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["W", "szczeg\u00f3lno\u015bci", "jego", "badania", "koncentrowa\u0142y", "si\u0119", "na", "takich", "obszarach", "jak", "eksploracja", "tekstu", "(", "ekstrakcja", ",", "kategoryzacja", ",", "wykrywanie", "nowo\u015bci", ")", "oraz", "na", "nowych", "ramach", "teoretycznych", ",", "takich", "jak", "zunifikowana", "teoria", "u\u017cyteczno\u015bci", "\u0142\u0105cz\u0105ca", "wyszukiwanie", "informacji", ",", "automatyczne", "streszczanie", ",", "odpowiadanie", "na", "pytania", "w", "wolnym", "tek\u015bcie", "i", "pokrewne", "zadania", "."], "sentence-detokenized": "W szczeg\u00f3lno\u015bci jego badania koncentrowa\u0142y si\u0119 na takich obszarach jak eksploracja tekstu (ekstrakcja, kategoryzacja, wykrywanie nowo\u015bci) oraz na nowych ramach teoretycznych, takich jak zunifikowana teoria u\u017cyteczno\u015bci \u0142\u0105cz\u0105ca wyszukiwanie informacji, automatyczne streszczanie, odpowiadanie na pytania w wolnym tek\u015bcie i pokrewne zadania.", "token2charspan": [[0, 1], [2, 15], [16, 20], [21, 28], [29, 42], [43, 46], [47, 49], [50, 56], [57, 66], [67, 70], [71, 82], [83, 89], [90, 91], [91, 101], [101, 102], [103, 116], [116, 117], [118, 128], [129, 136], [136, 137], [138, 142], [143, 145], [146, 152], [153, 159], [160, 173], [173, 174], [175, 181], [182, 185], [186, 198], [199, 205], [206, 218], [219, 226], [227, 239], [240, 250], [250, 251], [252, 264], [265, 277], [277, 278], [279, 291], [292, 294], [295, 302], [303, 304], [305, 311], [312, 319], [320, 321], [322, 330], [331, 338], [338, 339]]}
{"doc_key": "ai-test-414", "ner": [[0, 1, "product"], [6, 7, "product"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 0, 1, "part-of", "", false, false], [15, 16, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Roboty", "Delta", "maj\u0105", "zamontowane", "w", "podstawie", "si\u0142owniki", "obrotowe", ",", "kt\u00f3re", "poruszaj\u0105", "lekkim", ",", "sztywnym", ",", "r\u00f3wnoleg\u0142obocznym", "ramieniem", "."], "sentence-detokenized": "Roboty Delta maj\u0105 zamontowane w podstawie si\u0142owniki obrotowe, kt\u00f3re poruszaj\u0105 lekkim, sztywnym, r\u00f3wnoleg\u0142obocznym ramieniem.", "token2charspan": [[0, 6], [7, 12], [13, 17], [18, 29], [30, 31], [32, 41], [42, 51], [52, 60], [60, 61], [62, 67], [68, 77], [78, 84], [84, 85], [86, 94], [94, 95], [96, 113], [114, 123], [123, 124]]}
{"doc_key": "ai-test-415", "ner": [[6, 10, "metrics"], [12, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Cztery", "wyniki", "mo\u017cna", "sformu\u0142owa\u0107", "w", "postaci", "tabeli", "kontyngencji", "2", "\u00d7", "2", "lub", "macierzy", "konfuzji", ",", "w", "nast\u0119puj\u0105cy", "spos\u00f3b", ":"], "sentence-detokenized": "Cztery wyniki mo\u017cna sformu\u0142owa\u0107 w postaci tabeli kontyngencji 2 \u00d7 2 lub macierzy konfuzji, w nast\u0119puj\u0105cy spos\u00f3b:", "token2charspan": [[0, 6], [7, 13], [14, 19], [20, 31], [32, 33], [34, 41], [42, 48], [49, 61], [62, 63], [64, 65], [66, 67], [68, 71], [72, 80], [81, 89], [89, 90], [91, 92], [93, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-test-416", "ner": [[26, 27, "task"], [33, 34, "task"], [41, 42, "task"], [45, 46, "task"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["W\u0142a\u015bciwe", "zadanie", "eksploracji", "danych", "to", "p\u00f3\u0142automatyczna", "lub", "automatyczna", "analiza", "du\u017cych", "ilo\u015bci", "danych", "w", "celu", "wydobycia", "nieznanych", ",", "interesuj\u0105cych", "wzorc\u00f3w", ",", "takich", "jak", "grupy", "rekord\u00f3w", "danych", "(", "analiza", "skupie\u0144", ")", ",", "nietypowe", "rekordy", "(", "wykrywanie", "anomalii", ")", ",", "czy", "zale\u017cno\u015bci", "(", "eksploracja", "regu\u0142", "asocjacyjnych", ",", "eksploracja", "wzorc\u00f3w", "sekwencyjnych", ")", "."], "sentence-detokenized": "W\u0142a\u015bciwe zadanie eksploracji danych to p\u00f3\u0142automatyczna lub automatyczna analiza du\u017cych ilo\u015bci danych w celu wydobycia nieznanych, interesuj\u0105cych wzorc\u00f3w, takich jak grupy rekord\u00f3w danych (analiza skupie\u0144), nietypowe rekordy (wykrywanie anomalii), czy zale\u017cno\u015bci (eksploracja regu\u0142 asocjacyjnych, eksploracja wzorc\u00f3w sekwencyjnych).", "token2charspan": [[0, 8], [9, 16], [17, 28], [29, 35], [36, 38], [39, 54], [55, 58], [59, 71], [72, 79], [80, 86], [87, 93], [94, 100], [101, 102], [103, 107], [108, 117], [118, 128], [128, 129], [130, 144], [145, 152], [152, 153], [154, 160], [161, 164], [165, 170], [171, 179], [180, 186], [187, 188], [188, 195], [196, 203], [203, 204], [204, 205], [206, 215], [216, 223], [224, 225], [225, 235], [236, 244], [244, 245], [245, 246], [247, 250], [251, 261], [262, 263], [263, 274], [275, 280], [281, 294], [294, 295], [296, 307], [308, 315], [316, 329], [329, 330], [330, 331]]}
{"doc_key": "ai-test-417", "ner": [[1, 2, "product"], [3, 4, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 3, 4, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Dla", "systemu", "rekomendacyjnego", "analiza", "sentymentu", "okaza\u0142a", "si\u0119", "cenn\u0105", "technik\u0105", "."], "sentence-detokenized": "Dla systemu rekomendacyjnego analiza sentymentu okaza\u0142a si\u0119 cenn\u0105 technik\u0105.", "token2charspan": [[0, 3], [4, 11], [12, 28], [29, 36], [37, 47], [48, 55], [56, 59], [60, 65], [66, 74], [74, 75]]}
{"doc_key": "ai-test-418", "ner": [[1, 1, "misc"], [8, 8, "product"], [26, 26, "organisation"], [28, 29, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 8, 8, "usage", "", false, false], [26, 26, 28, 29, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Przypadkowo", "Niemcy", "bardzo", "\u017ale", "dobrali", "cz\u0119stotliwo\u015b\u0107", "pracy", "systemu", "Wotan", ";", "pracowa\u0142", "on", "na", "45", "MHz", ",", "co", "akurat", "by\u0142o", "cz\u0119stotliwo\u015bci\u0105", "pot\u0119\u017cnego", ",", "ale", "u\u015bpionego", "nadajnika", "telewizji", "BBC", "w", "Alexandra", "Palace", "."], "sentence-detokenized": "Przypadkowo Niemcy bardzo \u017ale dobrali cz\u0119stotliwo\u015b\u0107 pracy systemu Wotan; pracowa\u0142 on na 45 MHz, co akurat by\u0142o cz\u0119stotliwo\u015bci\u0105 pot\u0119\u017cnego, ale u\u015bpionego nadajnika telewizji BBC w Alexandra Palace.", "token2charspan": [[0, 11], [12, 18], [19, 25], [26, 29], [30, 37], [38, 51], [52, 57], [58, 65], [66, 71], [71, 72], [73, 81], [82, 84], [85, 87], [88, 90], [91, 94], [94, 95], [96, 98], [99, 105], [106, 110], [111, 126], [127, 136], [136, 137], [138, 141], [142, 151], [152, 161], [162, 171], [172, 175], [176, 177], [178, 187], [188, 194], [194, 195]]}
{"doc_key": "ai-test-419", "ner": [[6, 10, "metrics"], [12, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Cztery", "wyniki", "mo\u017cna", "sformu\u0142owa\u0107", "w", "postaci", "tabeli", "kontyngencji", "2", "\u00d7", "2", "lub", "macierzy", "konfuzji", ",", "w", "nast\u0119puj\u0105cy", "spos\u00f3b", ":"], "sentence-detokenized": "Cztery wyniki mo\u017cna sformu\u0142owa\u0107 w postaci tabeli kontyngencji 2 \u00d7 2 lub macierzy konfuzji, w nast\u0119puj\u0105cy spos\u00f3b:", "token2charspan": [[0, 6], [7, 13], [14, 19], [20, 31], [32, 33], [34, 41], [42, 48], [49, 61], [62, 63], [64, 65], [66, 67], [68, 71], [72, 80], [81, 89], [89, 90], [91, 92], [93, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-test-420", "ner": [[1, 3, "misc"], [11, 11, "misc"], [15, 15, "product"], [17, 17, "product"], [19, 21, "product"], [29, 29, "misc"], [45, 47, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 15, 11, 11, "usage", "", false, false], [17, 17, 11, 11, "usage", "", false, false], [19, 21, 17, 17, "named", "", false, false], [29, 29, 11, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["W", "aplikacjach", "Semantic", "Web", ",", "a", "tak\u017ce", "w", "stosunkowo", "popularnych", "zastosowaniach", "RDF", ",", "takich", "jak", "RSS", "czy", "FOAF", "(", "Friend", "a", "Friend", ")", ",", "zasoby", "s\u0105", "zwykle", "reprezentowane", "przez", "URI", ",", "kt\u00f3re", "celowo", "oznaczaj\u0105", "i", "mog\u0105", "by\u0107", "u\u017cyte", "do", "uzyskania", "dost\u0119pu", "do", "rzeczywistych", "danych", "w", "World", "Wide", "Web", "."], "sentence-detokenized": "W aplikacjach Semantic Web, a tak\u017ce w stosunkowo popularnych zastosowaniach RDF, takich jak RSS czy FOAF (Friend a Friend), zasoby s\u0105 zwykle reprezentowane przez URI, kt\u00f3re celowo oznaczaj\u0105 i mog\u0105 by\u0107 u\u017cyte do uzyskania dost\u0119pu do rzeczywistych danych w World Wide Web.", "token2charspan": [[0, 1], [2, 13], [14, 22], [23, 26], [26, 27], [28, 29], [30, 35], [36, 37], [38, 48], [49, 60], [61, 75], [76, 79], [79, 80], [81, 87], [88, 91], [92, 95], [96, 99], [100, 104], [105, 106], [106, 112], [113, 114], [115, 121], [121, 122], [122, 123], [124, 130], [131, 133], [134, 140], [141, 155], [156, 161], [162, 165], [165, 166], [167, 172], [173, 179], [180, 189], [190, 191], [192, 196], [197, 200], [201, 206], [207, 209], [210, 219], [220, 227], [228, 230], [231, 244], [245, 251], [252, 253], [254, 259], [260, 264], [265, 268], [268, 269]]}
{"doc_key": "ai-test-421", "ner": [[0, 5, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Stowarzyszenie", "na", "rzecz", "rozwoju", "sztucznej", "inteligencji", "dog\u0142\u0119bnie", "zbada\u0142o", "ten", "temat"], "sentence-detokenized": "Stowarzyszenie na rzecz rozwoju sztucznej inteligencji dog\u0142\u0119bnie zbada\u0142o ten temat", "token2charspan": [[0, 14], [15, 17], [18, 23], [24, 31], [32, 41], [42, 54], [55, 64], [65, 72], [73, 76], [77, 82]]}
{"doc_key": "ai-test-422", "ner": [[4, 7, "product"], [14, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 14, 4, 7, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Zaczynaj\u0105c", "jako", "ciekawostka", ",", "system", "mowy", "Apple", "Macintosh", "rozwin\u0105\u0142", "si\u0119", "w", "pe\u0142ni", "obs\u0142ugiwany", "program", "PlainTalk", ",", "dla", "os\u00f3b", "z", "problemami", "wzroku", "."], "sentence-detokenized": "Zaczynaj\u0105c jako ciekawostka, system mowy Apple Macintosh rozwin\u0105\u0142 si\u0119 w pe\u0142ni obs\u0142ugiwany program PlainTalk, dla os\u00f3b z problemami wzroku.", "token2charspan": [[0, 10], [11, 15], [16, 27], [27, 28], [29, 35], [36, 40], [41, 46], [47, 56], [57, 65], [66, 69], [70, 71], [72, 77], [78, 89], [90, 97], [98, 107], [107, 108], [109, 112], [113, 117], [118, 119], [120, 130], [131, 137], [137, 138]]}
{"doc_key": "ai-test-423", "ner": [[5, 5, "field"], [7, 8, "task"], [10, 11, "task"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 5, 5, "part-of", "task_part_of_field", false, false], [10, 11, 5, 5, "part-of", "task_part_of_field", false, false], [13, 14, 5, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Inne", "obszary", "wykorzystania", "ontologii", "w", "NLP", "to", "wyszukiwanie", "informacji", ",", "ekstrakcja", "informacji", "i", "automatyczne", "streszczanie", "."], "sentence-detokenized": "Inne obszary wykorzystania ontologii w NLP to wyszukiwanie informacji, ekstrakcja informacji i automatyczne streszczanie.", "token2charspan": [[0, 4], [5, 12], [13, 26], [27, 36], [37, 38], [39, 42], [43, 45], [46, 58], [59, 69], [69, 70], [71, 81], [82, 92], [93, 94], [95, 107], [108, 120], [120, 121]]}
{"doc_key": "ai-test-424", "ner": [[4, 11, "organisation"], [13, 17, "organisation"], [19, 23, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Instytut", "\u015bci\u015ble", "wsp\u00f3\u0142pracowa\u0142", "z", "Janelia", "Farm", "Campus", "of", "Howard", "Hughes", "Medical", "Institute", ",", "Allen", "Institute", "for", "Brain", "Science", "oraz", "National", "Institutes", "of", "Health", "w", "celu", "opracowania", "lepszych", "metod", "rekonstrukcji", "architektur", "neuron\u00f3w", "."], "sentence-detokenized": "Instytut \u015bci\u015ble wsp\u00f3\u0142pracowa\u0142 z Janelia Farm Campus of Howard Hughes Medical Institute, Allen Institute for Brain Science oraz National Institutes of Health w celu opracowania lepszych metod rekonstrukcji architektur neuron\u00f3w.", "token2charspan": [[0, 8], [9, 15], [16, 29], [30, 31], [32, 39], [40, 44], [45, 51], [52, 54], [55, 61], [62, 68], [69, 76], [77, 86], [86, 87], [88, 93], [94, 103], [104, 107], [108, 113], [114, 121], [122, 126], [127, 135], [136, 146], [147, 149], [150, 156], [157, 158], [159, 163], [164, 175], [176, 184], [185, 190], [191, 204], [205, 216], [217, 225], [225, 226]]}
{"doc_key": "ai-test-425", "ner": [[1, 1, "organisation"], [5, 6, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 1, 1, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Niedawno", "Google", "og\u0142osi\u0142o", ",", "\u017ce", "Google", "Translate", "t\u0142umaczy", "mniej", "wi\u0119cej", "tyle", "tekstu", ",", "by", "zape\u0142ni\u0107", "1", "milion", "ksi\u0105\u017cek", "w", "ci\u0105gu", "jednego", "dnia", "(", "2012", ")", "."], "sentence-detokenized": "Niedawno Google og\u0142osi\u0142o, \u017ce Google Translate t\u0142umaczy mniej wi\u0119cej tyle tekstu, by zape\u0142ni\u0107 1 milion ksi\u0105\u017cek w ci\u0105gu jednego dnia (2012).", "token2charspan": [[0, 8], [9, 15], [16, 24], [24, 25], [26, 28], [29, 35], [36, 45], [46, 54], [55, 60], [61, 67], [68, 72], [73, 79], [79, 80], [81, 83], [84, 92], [93, 94], [95, 101], [102, 109], [110, 111], [112, 117], [118, 125], [126, 130], [131, 132], [132, 136], [136, 137], [137, 138]]}
{"doc_key": "ai-test-426", "ner": [[14, 14, "country"], [16, 17, "country"], [19, 19, "country"], [21, 21, "country"], [23, 23, "country"], [25, 26, "country"], [37, 38, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Imprezy", "odbywaj\u0105", "si\u0119", "na", "ca\u0142ym", "\u015bwiecie", ",", "a", "najwi\u0119ksz\u0105", "popularno\u015bci\u0105", "ciesz\u0105", "si\u0119", "w", "Wielkiej", "Brytanii", ",", "Stanach", "Zjednoczonych", ",", "Japonii", ",", "Singapurze", ",", "Indiach", ",", "Korei", "Po\u0142udniowej", "i", "staj\u0105", "si\u0119", "popularne", "w", "krajach", "subkontynentalnych", ",", "takich", "jak", "Sri", "Lanka", "."], "sentence-detokenized": "Imprezy odbywaj\u0105 si\u0119 na ca\u0142ym \u015bwiecie, a najwi\u0119ksz\u0105 popularno\u015bci\u0105 ciesz\u0105 si\u0119 w Wielkiej Brytanii, Stanach Zjednoczonych, Japonii, Singapurze, Indiach, Korei Po\u0142udniowej i staj\u0105 si\u0119 popularne w krajach subkontynentalnych, takich jak Sri Lanka.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 23], [24, 29], [30, 37], [37, 38], [39, 40], [41, 51], [52, 65], [66, 72], [73, 76], [77, 78], [79, 87], [88, 96], [96, 97], [98, 105], [106, 119], [119, 120], [121, 128], [128, 129], [130, 140], [140, 141], [142, 149], [149, 150], [151, 156], [157, 168], [169, 170], [171, 176], [177, 180], [181, 190], [191, 192], [193, 200], [201, 219], [219, 220], [221, 227], [228, 231], [232, 235], [236, 241], [241, 242]]}
{"doc_key": "ai-test-427", "ner": [[6, 6, "programlang"], [11, 11, "programlang"], [13, 13, "programlang"], [15, 17, "programlang"], [19, 19, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Pakiety", "te", "s\u0105", "opracowywane", "g\u0142\u00f3wnie", "w", "R", ",", "a", "czasami", "w", "Javie", ",", "C", ",", "C", "+", "+", "i", "Fortran", "."], "sentence-detokenized": "Pakiety te s\u0105 opracowywane g\u0142\u00f3wnie w R, a czasami w Javie, C, C ++ i Fortran.", "token2charspan": [[0, 7], [8, 10], [11, 13], [14, 26], [27, 34], [35, 36], [37, 38], [38, 39], [40, 41], [42, 49], [50, 51], [52, 57], [57, 58], [59, 60], [60, 61], [62, 63], [64, 65], [65, 66], [67, 68], [69, 76], [76, 77]]}
{"doc_key": "ai-test-428", "ner": [[2, 9, "conference"], [7, 7, "conference"], [11, 11, "researcher"], [13, 13, "researcher"], [16, 17, "researcher"], [19, 20, "algorithm"], [23, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[7, 7, 2, 9, "named", "", false, false], [11, 11, 2, 9, "physical", "", false, false], [11, 11, 2, 9, "role", "", false, false], [11, 11, 16, 17, "role", "teams_up_with", false, false], [11, 11, 19, 20, "usage", "", false, false], [13, 13, 2, 9, "physical", "", false, false], [13, 13, 2, 9, "role", "", false, false], [13, 13, 16, 17, "role", "teams_up_with", false, false], [13, 13, 19, 20, "usage", "", false, false], [16, 17, 2, 9, "physical", "", false, false], [16, 17, 2, 9, "role", "", false, false], [16, 17, 19, 20, "usage", "", false, false], [19, 20, 23, 29, "related-to", "used_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["W", "ramach", "Europejskiej", "Konferencji", "Widzenia", "Komputerowego", "(", "ECCV", ")", "2006", ",", "Dalal", "i", "Triggs", "wraz", "z", "Cordeli\u0105", "Schmid", "zastosowali", "detektory", "HOG", "do", "problemu", "wykrywania", "ludzi", "w", "filmach", "i", "nagraniach", "wideo", "."], "sentence-detokenized": "W ramach Europejskiej Konferencji Widzenia Komputerowego (ECCV) 2006, Dalal i Triggs wraz z Cordeli\u0105 Schmid zastosowali detektory HOG do problemu wykrywania ludzi w filmach i nagraniach wideo.", "token2charspan": [[0, 1], [2, 8], [9, 21], [22, 33], [34, 42], [43, 56], [57, 58], [58, 62], [62, 63], [64, 68], [68, 69], [70, 75], [76, 77], [78, 84], [85, 89], [90, 91], [92, 100], [101, 107], [108, 119], [120, 129], [130, 133], [134, 136], [137, 145], [146, 156], [157, 162], [163, 164], [165, 172], [173, 174], [175, 185], [186, 191], [191, 192]]}
{"doc_key": "ai-test-429", "ner": [[1, 1, "metrics"], [3, 3, "metrics"], [6, 8, "task"], [13, 15, "metrics"], [17, 17, "metrics"], [22, 22, "metrics"], [25, 27, "metrics"], [29, 29, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[1, 1, 6, 8, "related-to", "measured_with", false, false], [3, 3, 6, 8, "related-to", "measured_with", false, false], [13, 15, 6, 8, "related-to", "measured_with", false, false], [17, 17, 13, 15, "named", "", false, false], [22, 22, 13, 15, "named", "", false, false], [29, 29, 25, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Opr\u00f3cz", "czu\u0142o\u015bci", "i", "swoisto\u015bci", ",", "wydajno\u015b\u0107", "binarnego", "testu", "klasyfikacyjnego", "mo\u017cna", "mierzy\u0107", "za", "pomoc\u0105", "pozytywnej", "warto\u015bci", "predykcyjnej", "(", "PPV", ")", ",", "zwanej", "r\u00f3wnie\u017c", "precyzj\u0105", ",", "oraz", "negatywnej", "warto\u015bci", "predykcyjnej", "(", "NPV", ")", "."], "sentence-detokenized": "Opr\u00f3cz czu\u0142o\u015bci i swoisto\u015bci, wydajno\u015b\u0107 binarnego testu klasyfikacyjnego mo\u017cna mierzy\u0107 za pomoc\u0105 pozytywnej warto\u015bci predykcyjnej (PPV), zwanej r\u00f3wnie\u017c precyzj\u0105, oraz negatywnej warto\u015bci predykcyjnej (NPV).", "token2charspan": [[0, 6], [7, 15], [16, 17], [18, 28], [28, 29], [30, 39], [40, 49], [50, 55], [56, 72], [73, 78], [79, 86], [87, 89], [90, 96], [97, 107], [108, 116], [117, 129], [130, 131], [131, 134], [134, 135], [135, 136], [137, 143], [144, 151], [152, 160], [160, 161], [162, 166], [167, 177], [178, 186], [187, 199], [200, 201], [201, 204], [204, 205], [205, 206]]}
{"doc_key": "ai-test-430", "ner": [[15, 17, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Takie", "modele", "mog\u0105", "dawa\u0107", "cz\u0119\u015bciowy", "kredyt", "dla", "pokrywaj\u0105cych", "si\u0119", "dopasowa\u0144", "(", "np", ".", "przy", "u\u017cyciu", "kryterium", "indeksu", "Jaccarda", "."], "sentence-detokenized": "Takie modele mog\u0105 dawa\u0107 cz\u0119\u015bciowy kredyt dla pokrywaj\u0105cych si\u0119 dopasowa\u0144 (np. przy u\u017cyciu kryterium indeksu Jaccarda.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 23], [24, 33], [34, 40], [41, 44], [45, 58], [59, 62], [63, 72], [73, 74], [74, 76], [76, 77], [78, 82], [83, 89], [90, 99], [100, 107], [108, 116], [116, 117]]}
{"doc_key": "ai-test-431", "ner": [[18, 23, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ponadto", ",", "w", "przypadku", "estymacji", "na", "podstawie", "pojedynczej", "pr\u00f3by", ",", "pokazuje", "zagadnienia", "filozoficzne", "i", "mo\u017cliwe", "nieporozumienia", "w", "stosowaniu", "estymator\u00f3w", "maksymalnego", "prawdopodobie\u0144stwa", "i", "funkcji", "prawdopodobie\u0144stwa", "."], "sentence-detokenized": "Ponadto, w przypadku estymacji na podstawie pojedynczej pr\u00f3by, pokazuje zagadnienia filozoficzne i mo\u017cliwe nieporozumienia w stosowaniu estymator\u00f3w maksymalnego prawdopodobie\u0144stwa i funkcji prawdopodobie\u0144stwa.", "token2charspan": [[0, 7], [7, 8], [9, 10], [11, 20], [21, 30], [31, 33], [34, 43], [44, 55], [56, 61], [61, 62], [63, 71], [72, 83], [84, 96], [97, 98], [99, 106], [107, 122], [123, 124], [125, 135], [136, 147], [148, 160], [161, 179], [180, 181], [182, 189], [190, 208], [208, 209]]}
