{"doc_key": "ai-test-1", "ner": [[7, 9, "algorithm"], [12, 14, "algorithm"], [16, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["As", "abordagens", "t\u00edpicas", "de", "modelos", "generativos", "incluem", "classificadores", "Bayes", "ing\u00e9nuos", ",", "modelos", "de", "misturas", "Gaussianas", ",", "autocodificadores", "variacionais", "e", "outros", "."], "sentence-detokenized": "As abordagens t\u00edpicas de modelos generativos incluem classificadores Bayes ing\u00e9nuos, modelos de misturas Gaussianas, autocodificadores variacionais e outros.", "token2charspan": [[0, 2], [3, 13], [14, 21], [22, 24], [25, 32], [33, 44], [45, 52], [53, 68], [69, 74], [75, 83], [83, 84], [85, 92], [93, 95], [96, 104], [105, 115], [115, 116], [117, 134], [135, 147], [148, 149], [150, 156], [156, 157]]}
{"doc_key": "ai-test-2", "ner": [[8, 8, "organisation"], [13, 13, "conference"], [16, 22, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 13, 13, "role", "", false, false], [16, 22, 13, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Finalmente", ",", "de", "dois", "em", "dois", "anos", ",", "ELRA", "organiza", "uma", "grande", "confer\u00eancia", "LREC", ",", "a", "Confer\u00eancia", "Internacional", "de", "Avalia\u00e7\u00e3o", "e", "Recursos", "Lingu\u00edsticos", "."], "sentence-detokenized": "Finalmente, de dois em dois anos, ELRA organiza uma grande confer\u00eancia LREC, a Confer\u00eancia Internacional de Avalia\u00e7\u00e3o e Recursos Lingu\u00edsticos.", "token2charspan": [[0, 10], [10, 11], [12, 14], [15, 19], [20, 22], [23, 27], [28, 32], [32, 33], [34, 38], [39, 47], [48, 51], [52, 58], [59, 70], [71, 75], [75, 76], [77, 78], [79, 90], [91, 104], [105, 107], [108, 117], [118, 119], [120, 128], [129, 141], [141, 142]]}
{"doc_key": "ai-test-3", "ner": [[7, 10, "algorithm"], [14, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "tarefa", "consiste", "geralmente", "em", "obter", "a", "estimativa", "da", "m\u00e1xima", "probabilidade", "dos", "par\u00e2metros", "do", "HMM", ",", "dadas", "as", "sequ\u00eancias", "de", "sa\u00edda", "."], "sentence-detokenized": "A tarefa consiste geralmente em obter a estimativa da m\u00e1xima probabilidade dos par\u00e2metros do HMM, dadas as sequ\u00eancias de sa\u00edda.", "token2charspan": [[0, 1], [2, 8], [9, 17], [18, 28], [29, 31], [32, 37], [38, 39], [40, 50], [51, 53], [54, 60], [61, 74], [75, 78], [79, 89], [90, 92], [93, 96], [96, 97], [98, 103], [104, 106], [107, 117], [118, 120], [121, 126], [126, 127]]}
{"doc_key": "ai-test-4", "ner": [[3, 4, "algorithm"], [7, 10, "algorithm"], [16, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 16, 16, "compare", "", false, false], [7, 10, 16, 16, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Ao", "contr\u00e1rio", "das", "redes", "neurais", "e", "da", "m\u00e1quina", "vectorial", "de", "suporte", ",", "o", "processo", "de", "treino", "AdaBoost", "selecciona", "apenas", "as", "caracter\u00edsticas", "conhecidas", "para", "melhorar", "o", "poder", "preditivo", "do", "modelo", ",", "reduzindo", "a", "dimensionalidade", "e", "melhorando", "potencialmente", "o", "tempo", "de", "execu\u00e7\u00e3o", "como", "caracter\u00edsticas", "irrelevantes", "n\u00e3o", "precisam", "de", "ser", "computadas", "."], "sentence-detokenized": "Ao contr\u00e1rio das redes neurais e da m\u00e1quina vectorial de suporte, o processo de treino AdaBoost selecciona apenas as caracter\u00edsticas conhecidas para melhorar o poder preditivo do modelo, reduzindo a dimensionalidade e melhorando potencialmente o tempo de execu\u00e7\u00e3o como caracter\u00edsticas irrelevantes n\u00e3o precisam de ser computadas.", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 22], [23, 30], [31, 32], [33, 35], [36, 43], [44, 53], [54, 56], [57, 64], [64, 65], [66, 67], [68, 76], [77, 79], [80, 86], [87, 95], [96, 106], [107, 113], [114, 116], [117, 132], [133, 143], [144, 148], [149, 157], [158, 159], [160, 165], [166, 175], [176, 178], [179, 185], [185, 186], [187, 196], [197, 198], [199, 215], [216, 217], [218, 228], [229, 243], [244, 245], [246, 251], [252, 254], [255, 263], [264, 268], [269, 284], [285, 297], [298, 301], [302, 310], [311, 313], [314, 317], [318, 328], [328, 329]]}
{"doc_key": "ai-test-5", "ner": [[0, 0, "misc"], [10, 11, "misc"], [13, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 10, 11, "part-of", "", false, false], [10, 11, 13, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Troponymy", "\u00e9", "uma", "das", "rela\u00e7\u00f5es", "poss\u00edveis", "entre", "os", "verbos", "na", "rede", "sem\u00e2ntica", "da", "base", "de", "dados", "WordNet", "."], "sentence-detokenized": "Troponymy \u00e9 uma das rela\u00e7\u00f5es poss\u00edveis entre os verbos na rede sem\u00e2ntica da base de dados WordNet.", "token2charspan": [[0, 9], [10, 11], [12, 15], [16, 19], [20, 28], [29, 38], [39, 44], [45, 47], [48, 54], [55, 57], [58, 62], [63, 72], [73, 75], [76, 80], [81, 83], [84, 89], [90, 97], [97, 98]]}
{"doc_key": "ai-test-6", "ner": [[10, 12, "task"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 12, 14, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Uma", "linguagem", "de", "enquadramento", "\u00e9", "uma", "tecnologia", "utilizada", "para", "a", "representa\u00e7\u00e3o", "do", "conhecimento", "em", "intelig\u00eancia", "artificial", "."], "sentence-detokenized": "Uma linguagem de enquadramento \u00e9 uma tecnologia utilizada para a representa\u00e7\u00e3o do conhecimento em intelig\u00eancia artificial.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 30], [31, 32], [33, 36], [37, 47], [48, 57], [58, 62], [63, 64], [65, 78], [79, 81], [82, 94], [95, 97], [98, 110], [111, 121], [121, 122]]}
{"doc_key": "ai-test-7", "ner": [[0, 1, "metrics"], [5, 6, "metrics"], [11, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 5, 6, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["O", "NIST", "tamb\u00e9m", "difere", "da", "avalia\u00e7\u00e3o", "bilingue", "no", "seu", "c\u00e1lculo", "da", "pena", "de", "brevidade", "na", "medida", "em", "que", "pequenas", "varia\u00e7\u00f5es", "na", "dura\u00e7\u00e3o", "da", "tradu\u00e7\u00e3o", "n\u00e3o", "t\u00eam", "tanto", "impacto", "na", "pontua\u00e7\u00e3o", "global", "."], "sentence-detokenized": "O NIST tamb\u00e9m difere da avalia\u00e7\u00e3o bilingue no seu c\u00e1lculo da pena de brevidade na medida em que pequenas varia\u00e7\u00f5es na dura\u00e7\u00e3o da tradu\u00e7\u00e3o n\u00e3o t\u00eam tanto impacto na pontua\u00e7\u00e3o global.", "token2charspan": [[0, 1], [2, 6], [7, 13], [14, 20], [21, 23], [24, 33], [34, 42], [43, 45], [46, 49], [50, 57], [58, 60], [61, 65], [66, 68], [69, 78], [79, 81], [82, 88], [89, 91], [92, 95], [96, 104], [105, 114], [115, 117], [118, 125], [126, 128], [129, 137], [138, 141], [142, 145], [146, 151], [152, 159], [160, 162], [163, 172], [173, 179], [179, 180]]}
{"doc_key": "ai-test-8", "ner": [[20, 21, "algorithm"], [24, 26, "algorithm"], [40, 41, "field"], [52, 54, "algorithm"], [56, 59, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[20, 21, 40, 41, "usage", "", false, false], [24, 26, 40, 41, "usage", "", false, false], [52, 54, 40, 41, "type-of", "", false, false], [56, 59, 40, 41, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["O", "modelo", "\u00e9", "inicialmente", "adequado", "a", "um", "conjunto", "de", "dados", "de", "forma\u00e7\u00e3o", ",", "O", "modelo", "(", "por", "exemplo", ",", "uma", "rede", "neural", "ou", "um", "classificador", "Bayes", "ing\u00e9nuo", ")", "\u00e9", "treinado", "no", "conjunto", "de", "dados", "de", "forma\u00e7\u00e3o", "usando", "um", "m\u00e9todo", "de", "aprendizagem", "supervisionado", ",", "por", "exemplo", ",", "usando", "m\u00e9todos", "de", "optimiza\u00e7\u00e3o", "tais", "como", "descida", "de", "gradiente", "ou", "descida", "de", "gradiente", "estoc\u00e1stico", "."], "sentence-detokenized": "O modelo \u00e9 inicialmente adequado a um conjunto de dados de forma\u00e7\u00e3o, O modelo (por exemplo, uma rede neural ou um classificador Bayes ing\u00e9nuo) \u00e9 treinado no conjunto de dados de forma\u00e7\u00e3o usando um m\u00e9todo de aprendizagem supervisionado, por exemplo, usando m\u00e9todos de optimiza\u00e7\u00e3o tais como descida de gradiente ou descida de gradiente estoc\u00e1stico.", "token2charspan": [[0, 1], [2, 8], [9, 10], [11, 23], [24, 32], [33, 34], [35, 37], [38, 46], [47, 49], [50, 55], [56, 58], [59, 67], [67, 68], [69, 70], [71, 77], [78, 79], [79, 82], [83, 90], [90, 91], [92, 95], [96, 100], [101, 107], [108, 110], [111, 113], [114, 127], [128, 133], [134, 141], [141, 142], [143, 144], [145, 153], [154, 156], [157, 165], [166, 168], [169, 174], [175, 177], [178, 186], [187, 193], [194, 196], [197, 203], [204, 206], [207, 219], [220, 234], [234, 235], [236, 239], [240, 247], [247, 248], [249, 255], [256, 263], [264, 266], [267, 278], [279, 283], [284, 288], [289, 296], [297, 299], [300, 309], [310, 312], [313, 320], [321, 323], [324, 333], [334, 345], [345, 346]]}
{"doc_key": "ai-test-9", "ner": [[0, 0, "product"], [7, 9, "task"], [11, 11, "task"], [13, 16, "task"], [19, 21, "task"], [31, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 9, 0, 0, "usage", "", true, false], [11, 11, 0, 0, "usage", "", true, false], [13, 16, 0, 0, "usage", "", true, false], [19, 21, 0, 0, "usage", "", true, false], [31, 34, 0, 0, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["FrameNet", "tem", "sido", "utilizado", "em", "aplica\u00e7\u00f5es", "como", "resposta", "a", "perguntas", ",", "par\u00e1frases", ",", "reconhecimento", "de", "vincula\u00e7\u00e3o", "textual", ",", "e", "extrac\u00e7\u00e3o", "de", "informa\u00e7\u00e3o", ",", "quer", "directamente", ",", "quer", "atrav\u00e9s", "de", "ferramentas", "de", "etiquetagem", "de", "papel", "sem\u00e2ntico", "."], "sentence-detokenized": "FrameNet tem sido utilizado em aplica\u00e7\u00f5es como resposta a perguntas, par\u00e1frases, reconhecimento de vincula\u00e7\u00e3o textual, e extrac\u00e7\u00e3o de informa\u00e7\u00e3o, quer directamente, quer atrav\u00e9s de ferramentas de etiquetagem de papel sem\u00e2ntico.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 27], [28, 30], [31, 41], [42, 46], [47, 55], [56, 57], [58, 67], [67, 68], [69, 79], [79, 80], [81, 95], [96, 98], [99, 109], [110, 117], [117, 118], [119, 120], [121, 130], [131, 133], [134, 144], [144, 145], [146, 150], [151, 163], [163, 164], [165, 169], [170, 177], [178, 180], [181, 192], [193, 195], [196, 207], [208, 210], [211, 216], [217, 226], [226, 227]]}
{"doc_key": "ai-test-10", "ner": [[5, 11, "field"], [13, 15, "misc"], [18, 18, "product"], [21, 23, "misc"], [27, 27, "product"], [30, 31, "field"], [34, 34, "product"], [37, 40, "misc"], [43, 43, "product"], [45, 45, "product"], [47, 47, "product"], [50, 51, "misc"], [55, 56, "product"], [58, 59, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[18, 18, 13, 15, "general-affiliation", "", false, false], [27, 27, 21, 23, "general-affiliation", "", false, false], [34, 34, 30, 31, "general-affiliation", "", false, false], [43, 43, 37, 40, "type-of", "", false, false], [45, 45, 37, 40, "type-of", "", false, false], [47, 47, 37, 40, "type-of", "", false, false], [55, 56, 50, 51, "general-affiliation", "", false, false], [58, 59, 50, 51, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Isto", "incluiria", "programas", "tais", "como", "an\u00e1lise", "e", "ferramentas", "de", "extrac\u00e7\u00e3o", "de", "dados", ",", "folhas", "de", "c\u00e1lculo", "(", "ex.", "Excel", ")", ",", "bases", "de", "dados", "(", "ex", ".", "Access", ")", ",", "an\u00e1lise", "estat\u00edstica", "(", "ex.", "SAS", ")", ",", "software", "de", "auditoria", "generalizada", "(", "ex.", "ACL", ",", "Arbutus", ",", "EAS", ")", ",", "business", "intelligence", "(", "ex", ".", "Crystal", "Reports", "e", "Business", "Objects", ")", ",", "etc."], "sentence-detokenized": "Isto incluiria programas tais como an\u00e1lise e ferramentas de extrac\u00e7\u00e3o de dados, folhas de c\u00e1lculo (ex. Excel), bases de dados (ex. Access), an\u00e1lise estat\u00edstica (ex. SAS), software de auditoria generalizada (ex. ACL, Arbutus, EAS), business intelligence (ex. Crystal Reports e Business Objects), etc.", "token2charspan": [[0, 4], [5, 14], [15, 24], [25, 29], [30, 34], [35, 42], [43, 44], [45, 56], [57, 59], [60, 69], [70, 72], [73, 78], [78, 79], [80, 86], [87, 89], [90, 97], [98, 99], [99, 102], [103, 108], [108, 109], [109, 110], [111, 116], [117, 119], [120, 125], [126, 127], [127, 129], [129, 130], [131, 137], [137, 138], [138, 139], [140, 147], [148, 159], [160, 161], [161, 164], [165, 168], [168, 169], [169, 170], [171, 179], [180, 182], [183, 192], [193, 205], [206, 207], [207, 210], [211, 214], [214, 215], [216, 223], [223, 224], [225, 228], [228, 229], [229, 230], [231, 239], [240, 252], [253, 254], [254, 256], [256, 257], [258, 265], [266, 273], [274, 275], [276, 284], [285, 292], [292, 293], [293, 294], [295, 299]]}
{"doc_key": "ai-test-11", "ner": [[0, 2, "organisation"], [6, 7, "researcher"], [11, 11, "organisation"], [15, 15, "product"], [23, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 6, 7, "origin", "", false, false], [6, 7, 11, 11, "role", "", false, false], [15, 15, 23, 24, "type-of", "", false, false], [23, 24, 6, 7, "origin", "introduced_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "Rethink", "Robotics", "-", "fundada", "por", "Rodney", "Brooks", ",", "anteriormente", "com", "iRobot", "-", "introduziu", "a", "Baxter", "em", "Setembro", "de", "2012", ";", "como", "um", "rob\u00f4", "industrial", "concebido", "para", "interagir", "com", "seguran\u00e7a", "com", "trabalhadores", "humanos", "vizinhos", ",", "e", "ser", "program\u00e1vel", "para", "executar", "tarefas", "simples", "."], "sentence-detokenized": "A Rethink Robotics - fundada por Rodney Brooks, anteriormente com iRobot - introduziu a Baxter em Setembro de 2012; como um rob\u00f4 industrial concebido para interagir com seguran\u00e7a com trabalhadores humanos vizinhos, e ser program\u00e1vel para executar tarefas simples.", "token2charspan": [[0, 1], [2, 9], [10, 18], [19, 20], [21, 28], [29, 32], [33, 39], [40, 46], [46, 47], [48, 61], [62, 65], [66, 72], [73, 74], [75, 85], [86, 87], [88, 94], [95, 97], [98, 106], [107, 109], [110, 114], [114, 115], [116, 120], [121, 123], [124, 128], [129, 139], [140, 149], [150, 154], [155, 164], [165, 168], [169, 178], [179, 182], [183, 196], [197, 204], [205, 213], [213, 214], [215, 216], [217, 220], [221, 232], [233, 237], [238, 246], [247, 254], [255, 262], [262, 263]]}
{"doc_key": "ai-test-12", "ner": [[4, 6, "field"], [8, 10, "task"], [12, 14, "task"], [16, 20, "task"], [22, 25, "task"], [27, 29, "task"], [31, 33, "task"], [36, 40, "task"], [49, 52, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[8, 10, 4, 6, "part-of", "task_part_of_field", false, false], [12, 14, 4, 6, "part-of", "task_part_of_field", false, false], [16, 20, 4, 6, "part-of", "task_part_of_field", false, false], [22, 25, 4, 6, "part-of", "task_part_of_field", false, false], [27, 29, 4, 6, "part-of", "task_part_of_field", false, false], [31, 33, 4, 6, "part-of", "task_part_of_field", false, false], [36, 40, 4, 6, "part-of", "task_part_of_field", false, false], [49, 52, 4, 6, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["As", "tarefas", "t\u00edpicas", "de", "minera\u00e7\u00e3o", "de", "texto", "incluem", "categoriza\u00e7\u00e3o", "de", "texto", ",", "agrupamento", "de", "textos", ",", "extrac\u00e7\u00e3o", "de", "conceitos", "/", "entidades", ",", "produ\u00e7\u00e3o", "de", "taxonomias", "granulares", ",", "an\u00e1lise", "de", "sentimentos", ",", "sumariza\u00e7\u00e3o", "de", "documentos", ",", "e", "modela\u00e7\u00e3o", "de", "rela\u00e7\u00f5es", "de", "entidades", "(", "ou", "seja", ",", "rela\u00e7\u00f5es", "de", "aprendizagem", "entre", "reconhecimento", "de", "entidades", "nomeadas", ")", "."], "sentence-detokenized": "As tarefas t\u00edpicas de minera\u00e7\u00e3o de texto incluem categoriza\u00e7\u00e3o de texto, agrupamento de textos, extrac\u00e7\u00e3o de conceitos/entidades, produ\u00e7\u00e3o de taxonomias granulares, an\u00e1lise de sentimentos, sumariza\u00e7\u00e3o de documentos, e modela\u00e7\u00e3o de rela\u00e7\u00f5es de entidades (ou seja, rela\u00e7\u00f5es de aprendizagem entre reconhecimento de entidades nomeadas).", "token2charspan": [[0, 2], [3, 10], [11, 18], [19, 21], [22, 31], [32, 34], [35, 40], [41, 48], [49, 62], [63, 65], [66, 71], [71, 72], [73, 84], [85, 87], [88, 94], [94, 95], [96, 105], [106, 108], [109, 118], [118, 119], [119, 128], [128, 129], [130, 138], [139, 141], [142, 152], [153, 163], [163, 164], [165, 172], [173, 175], [176, 187], [187, 188], [189, 200], [201, 203], [204, 214], [214, 215], [216, 217], [218, 227], [228, 230], [231, 239], [240, 242], [243, 252], [253, 254], [254, 256], [257, 261], [261, 262], [263, 271], [272, 274], [275, 287], [288, 293], [294, 308], [309, 311], [312, 321], [322, 330], [330, 331], [331, 332]]}
{"doc_key": "ai-test-13", "ner": [[7, 7, "metrics"], [11, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["No", "entanto", ",", "o", "corte", "reduz", "a", "precis\u00e3o", ",", "ou", "a", "VERDADEIRA", "taxa", "negativa", ",", "para", "tais", "sistemas", "."], "sentence-detokenized": "No entanto, o corte reduz a precis\u00e3o, ou a VERDADEIRA taxa negativa, para tais sistemas.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 13], [14, 19], [20, 25], [26, 27], [28, 36], [36, 37], [38, 40], [41, 42], [43, 53], [54, 58], [59, 67], [67, 68], [69, 73], [74, 78], [79, 87], [87, 88]]}
{"doc_key": "ai-test-14", "ner": [[4, 6, "task"], [11, 12, "misc"], [16, 17, "misc"], [25, 25, "product"], [27, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 12, 4, 6, "temporal", "", false, false], [16, 17, 11, 12, "named", "", false, false], [25, 25, 11, 12, "usage", "", false, false], [27, 27, 11, 12, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Um", "caso", "especial", "de", "detec\u00e7\u00e3o", "de", "palavras-chave", "\u00e9", "a", "detec\u00e7\u00e3o", "da", "palavra", "despertar", "(", "tamb\u00e9m", "chamada", "hot", "word", ")", "utilizada", "por", "assistentes", "digitais", "pessoais", "como", "Alexa", "ou", "Siri", "para", "acordar", "quando", "o", "seu", "nome", "\u00e9", "falado", "."], "sentence-detokenized": "Um caso especial de detec\u00e7\u00e3o de palavras-chave \u00e9 a detec\u00e7\u00e3o da palavra despertar (tamb\u00e9m chamada hot word) utilizada por assistentes digitais pessoais como Alexa ou Siri para acordar quando o seu nome \u00e9 falado.", "token2charspan": [[0, 2], [3, 7], [8, 16], [17, 19], [20, 28], [29, 31], [32, 46], [47, 48], [49, 50], [51, 59], [60, 62], [63, 70], [71, 80], [81, 82], [82, 88], [89, 96], [97, 100], [101, 105], [105, 106], [107, 116], [117, 120], [121, 132], [133, 141], [142, 150], [151, 155], [156, 161], [162, 164], [165, 169], [170, 174], [175, 182], [183, 189], [190, 191], [192, 195], [196, 200], [201, 202], [203, 209], [209, 210]]}
{"doc_key": "ai-test-15", "ner": [[0, 0, "programlang"], [11, 11, "programlang"], [13, 13, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 0, 0, "part-of", "", false, false], [13, 13, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prova", "\u00e9", "uma", "linguagem", "de", "programa\u00e7\u00e3o", "de", "c\u00f3digo", "aberto", "que", "combina", "Prolog", "com", "Java", "."], "sentence-detokenized": "Prova \u00e9 uma linguagem de programa\u00e7\u00e3o de c\u00f3digo aberto que combina Prolog com Java.", "token2charspan": [[0, 5], [6, 7], [8, 11], [12, 21], [22, 24], [25, 36], [37, 39], [40, 46], [47, 53], [54, 57], [58, 65], [66, 72], [73, 76], [77, 81], [81, 82]]}
{"doc_key": "ai-test-16", "ner": [[4, 5, "organisation"], [10, 10, "organisation"], [21, 22, "product"], [18, 20, "country"], [35, 36, "organisation"], [45, 45, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 10, 10, "part-of", "", false, false], [4, 5, 10, 10, "role", "sells", false, false], [4, 5, 18, 20, "role", "sells_to", false, false], [35, 36, 45, 45, "opposite", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Em", "1987", ",", "a", "Tocibai", "Machine", ",", "uma", "subsidi\u00e1ria", "da", "Toshiba", ",", "foi", "acusada", "de", "vender", "ilegalmente", "\u00e0", "Uni\u00e3o", "Sovi\u00e9tica", "as", "fresas", "CNC", "utilizadas", "para", "produzir", "h\u00e9lices", "submarinas", "muito", "silenciosas", ",", "em", "viola\u00e7\u00e3o", "do", "acordo", "do", "CoCom", ",", "um", "embargo", "internacional", "a", "certos", "pa\u00edses", "ao", "COMECON", "."], "sentence-detokenized": "Em 1987, a Tocibai Machine, uma subsidi\u00e1ria da Toshiba, foi acusada de vender ilegalmente \u00e0 Uni\u00e3o Sovi\u00e9tica as fresas CNC utilizadas para produzir h\u00e9lices submarinas muito silenciosas, em viola\u00e7\u00e3o do acordo do CoCom, um embargo internacional a certos pa\u00edses ao COMECON.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 18], [19, 26], [26, 27], [28, 31], [32, 43], [44, 46], [47, 54], [54, 55], [56, 59], [60, 67], [68, 70], [71, 77], [78, 89], [90, 91], [92, 97], [98, 107], [108, 110], [111, 117], [118, 121], [122, 132], [133, 137], [138, 146], [147, 154], [155, 165], [166, 171], [172, 183], [183, 184], [185, 187], [188, 196], [197, 199], [200, 206], [207, 209], [210, 215], [215, 216], [217, 219], [220, 227], [228, 241], [242, 243], [244, 250], [251, 257], [258, 260], [261, 268], [268, 269]]}
{"doc_key": "ai-test-17", "ner": [[5, 5, "researcher"], [8, 11, "product"], [20, 24, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 11, 5, 5, "artifact", "", false, false], [8, 11, 20, 24, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "mais", "famosa", "co-inven\u00e7\u00e3o", "da", "Engelberger", ",", "o", "bra\u00e7o", "rob\u00f3tico", "industrial", "Unimate", ",", "esteve", "entre", "os", "primeiros", "a", "entrar", "no", "Hall", "da", "Fama", "dos", "Rob\u00f4s", ",", "em", "2003", "."], "sentence-detokenized": "A mais famosa co-inven\u00e7\u00e3o da Engelberger, o bra\u00e7o rob\u00f3tico industrial Unimate, esteve entre os primeiros a entrar no Hall da Fama dos Rob\u00f4s, em 2003.", "token2charspan": [[0, 1], [2, 6], [7, 13], [14, 25], [26, 28], [29, 40], [40, 41], [42, 43], [44, 49], [50, 58], [59, 69], [70, 77], [77, 78], [79, 85], [86, 91], [92, 94], [95, 104], [105, 106], [107, 113], [114, 116], [117, 121], [122, 124], [125, 129], [130, 133], [134, 139], [139, 140], [141, 143], [144, 148], [148, 149]]}
{"doc_key": "ai-test-18", "ner": [[6, 7, "misc"], [9, 9, "misc"], [14, 14, "person"], [25, 26, "field"], [23, 24, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 7, 9, 9, "usage", "", false, false], [14, 14, 25, 26, "role", "", false, false], [25, 26, 23, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Originalmente", "controlado", "atrav\u00e9s", "de", "p\u00e1ginas", "web", "html", "est\u00e1ticas", "usando", "CGI", ",", "o", "trabalho", "de", "Dalton", "viu", "a", "introdu\u00e7\u00e3o", "de", "uma", "interface", "baseada", "em", "Java", "de", "realidade", "aumentada", "que", "teve", "um", "sucesso", "limitado", "."], "sentence-detokenized": "Originalmente controlado atrav\u00e9s de p\u00e1ginas web html est\u00e1ticas usando CGI, o trabalho de Dalton viu a introdu\u00e7\u00e3o de uma interface baseada em Java de realidade aumentada que teve um sucesso limitado.", "token2charspan": [[0, 13], [14, 24], [25, 32], [33, 35], [36, 43], [44, 47], [48, 52], [53, 62], [63, 69], [70, 73], [73, 74], [75, 76], [77, 85], [86, 88], [89, 95], [96, 99], [100, 101], [102, 112], [113, 115], [116, 119], [120, 129], [130, 137], [138, 140], [141, 145], [146, 148], [149, 158], [159, 168], [169, 172], [173, 177], [178, 180], [181, 188], [189, 197], [197, 198]]}
{"doc_key": "ai-test-19", "ner": [[5, 6, "task"], [12, 12, "organisation"], [30, 30, "conference"], [33, 33, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 12, 12, "origin", "", false, false], [30, 30, 33, 33, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "primeira", "publica\u00e7\u00e3o", "sobre", "a", "especifica\u00e7\u00e3o", "LMF", "tal", "como", "foi", "ratificada", "pela", "ISO", "(", "este", "documento", "tornou-se", "(", "em", "2015", ")", "o", "9\u00ba", "documento", "mais", "citado", "no", "\u00e2mbito", "das", "confer\u00eancias", "LREC", "dos", "documentos", "LREC", ")", ":"], "sentence-detokenized": "A primeira publica\u00e7\u00e3o sobre a especifica\u00e7\u00e3o LMF tal como foi ratificada pela ISO (este documento tornou-se (em 2015) o 9\u00ba documento mais citado no \u00e2mbito das confer\u00eancias LREC dos documentos LREC):", "token2charspan": [[0, 1], [2, 10], [11, 21], [22, 27], [28, 29], [30, 43], [44, 47], [48, 51], [52, 56], [57, 60], [61, 71], [72, 76], [77, 80], [81, 82], [82, 86], [87, 96], [97, 106], [107, 108], [108, 110], [111, 115], [115, 116], [117, 118], [119, 121], [122, 131], [132, 136], [137, 143], [144, 146], [147, 153], [154, 157], [158, 170], [171, 175], [176, 179], [180, 190], [191, 195], [195, 196], [196, 197]]}
{"doc_key": "ai-test-20", "ner": [[1, 3, "metrics"], [16, 17, "metrics"], [18, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 17, 1, 3, "usage", "", false, false], [16, 17, 18, 20, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Uma", "matriz", "de", "confus\u00e3o", "ou", "matriz", "de", "correspond\u00eancia", "\u00e9", "frequentemente", "utilizada", "como", "ferramenta", "para", "validar", "a", "precis\u00e3o", "da", "classifica\u00e7\u00e3o", "k", "-NN", "."], "sentence-detokenized": "Uma matriz de confus\u00e3o ou matriz de correspond\u00eancia \u00e9 frequentemente utilizada como ferramenta para validar a precis\u00e3o da classifica\u00e7\u00e3o k -NN.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 22], [23, 25], [26, 32], [33, 35], [36, 51], [52, 53], [54, 68], [69, 78], [79, 83], [84, 94], [95, 99], [100, 107], [108, 109], [110, 118], [119, 121], [122, 135], [136, 137], [138, 141], [141, 142]]}
{"doc_key": "ai-test-21", "ner": [[2, 5, "algorithm"], [15, 15, "field"], [17, 19, "field"], [21, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 5, 15, 15, "part-of", "", false, false], [2, 5, 17, 19, "part-of", "", false, false], [2, 5, 21, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "aprendizagem", "em", "\u00e1rvore", "de", "decis\u00e3o", "\u00e9", "uma", "das", "abordagens", "de", "modela\u00e7\u00e3o", "preditiva", "utilizada", "em", "estat\u00edstica", ",", "minera\u00e7\u00e3o", "de", "dados", "e", "aprendizagem", "de", "m\u00e1quinas", "."], "sentence-detokenized": "A aprendizagem em \u00e1rvore de decis\u00e3o \u00e9 uma das abordagens de modela\u00e7\u00e3o preditiva utilizada em estat\u00edstica, minera\u00e7\u00e3o de dados e aprendizagem de m\u00e1quinas.", "token2charspan": [[0, 1], [2, 14], [15, 17], [18, 24], [25, 27], [28, 35], [36, 37], [38, 41], [42, 45], [46, 56], [57, 59], [60, 69], [70, 79], [80, 89], [90, 92], [93, 104], [104, 105], [106, 115], [116, 118], [119, 124], [125, 126], [127, 139], [140, 142], [143, 151], [151, 152]]}
{"doc_key": "ai-test-22", "ner": [[6, 6, "misc"], [22, 28, "field"], [29, 31, "algorithm"], [33, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 22, 28, "related-to", "", true, false], [29, 31, 22, 28, "type-of", "", false, false], [33, 33, 22, 28, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Em", "tempo", "de", "execu\u00e7\u00e3o", ",", "a", "pros\u00f3dia", "alvo", "de", "uma", "frase", "\u00e9", "sobreposta", "a", "estas", "unidades", "m\u00ednimas", "por", "meio", "de", "t\u00e9cnicas", "de", "processamento", "de", "sinais", ",", "tais", "como", "a", "codifica\u00e7\u00e3o", "preditiva", "linear", ",", "PSOLA"], "sentence-detokenized": "Em tempo de execu\u00e7\u00e3o, a pros\u00f3dia alvo de uma frase \u00e9 sobreposta a estas unidades m\u00ednimas por meio de t\u00e9cnicas de processamento de sinais, tais como a codifica\u00e7\u00e3o preditiva linear, PSOLA", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 20], [20, 21], [22, 23], [24, 32], [33, 37], [38, 40], [41, 44], [45, 50], [51, 52], [53, 63], [64, 65], [66, 71], [72, 80], [81, 88], [89, 92], [93, 97], [98, 100], [101, 109], [110, 112], [113, 126], [127, 129], [130, 136], [136, 137], [138, 142], [143, 147], [148, 149], [150, 161], [162, 171], [172, 178], [178, 179], [180, 185]]}
{"doc_key": "ai-test-23", "ner": [[4, 5, "field"], [8, 9, "field"], [16, 17, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 17, 4, 5, "usage", "", true, false], [16, 17, 8, 9, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Esta", "abordagem", "utilizou", "a", "intelig\u00eancia", "artificial", "e", "a", "aprendizagem", "mec\u00e2nica", "para", "permitir", "aos", "investigadores", "comparar", "visivelmente", "imagens", "faciais", "convencionais", "e", "t\u00e9rmicas", "."], "sentence-detokenized": "Esta abordagem utilizou a intelig\u00eancia artificial e a aprendizagem mec\u00e2nica para permitir aos investigadores comparar visivelmente imagens faciais convencionais e t\u00e9rmicas.", "token2charspan": [[0, 4], [5, 14], [15, 23], [24, 25], [26, 38], [39, 49], [50, 51], [52, 53], [54, 66], [67, 75], [76, 80], [81, 89], [90, 93], [94, 108], [109, 117], [118, 130], [131, 138], [139, 146], [147, 160], [161, 162], [163, 171], [171, 172]]}
{"doc_key": "ai-test-24", "ner": [[1, 1, "field"], [4, 5, "algorithm"], [12, 13, "task"], [16, 17, "misc"], [23, 24, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 1, 1, "part-of", "", false, false], [4, 5, 12, 13, "topic", "", false, false], [12, 13, 16, 17, "origin", "", false, false], [23, 24, 1, 1, "part-of", "", false, false], [23, 24, 4, 5, "topic", "", false, false], [27, 28, 1, 1, "part-of", "", false, false], [27, 28, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Na", "inform\u00e1tica", ",", "a", "computa\u00e7\u00e3o", "evolutiva", "\u00e9", "uma", "fam\u00edlia", "de", "algoritmos", "para", "optimiza\u00e7\u00e3o", "global", "inspirada", "na", "evolu\u00e7\u00e3o", "biol\u00f3gica", ",", "e", "o", "subcampo", "da", "intelig\u00eancia", "artificial", "e", "da", "computa\u00e7\u00e3o", "suave", "que", "estuda", "estes", "algoritmos", "."], "sentence-detokenized": "Na inform\u00e1tica, a computa\u00e7\u00e3o evolutiva \u00e9 uma fam\u00edlia de algoritmos para optimiza\u00e7\u00e3o global inspirada na evolu\u00e7\u00e3o biol\u00f3gica, e o subcampo da intelig\u00eancia artificial e da computa\u00e7\u00e3o suave que estuda estes algoritmos.", "token2charspan": [[0, 2], [3, 14], [14, 15], [16, 17], [18, 28], [29, 38], [39, 40], [41, 44], [45, 52], [53, 55], [56, 66], [67, 71], [72, 83], [84, 90], [91, 100], [101, 103], [104, 112], [113, 122], [122, 123], [124, 125], [126, 127], [128, 136], [137, 139], [140, 152], [153, 163], [164, 165], [166, 168], [169, 179], [180, 185], [186, 189], [190, 196], [197, 202], [203, 213], [213, 214]]}
{"doc_key": "ai-test-25", "ner": [[9, 11, "metrics"], [14, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Por", "exemplo", ",", "pode-se", "combinar", "alguma", "medida", "baseada", "na", "matriz", "de", "confus\u00e3o", "com", "o", "erro", "m\u00e9dio", "ao", "quadrado", "avaliado", "entre", "as", "sa\u00eddas", "do", "modelo", "em", "bruto", "e", "os", "valores", "reais", "."], "sentence-detokenized": "Por exemplo, pode-se combinar alguma medida baseada na matriz de confus\u00e3o com o erro m\u00e9dio ao quadrado avaliado entre as sa\u00eddas do modelo em bruto e os valores reais.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 20], [21, 29], [30, 36], [37, 43], [44, 51], [52, 54], [55, 61], [62, 64], [65, 73], [74, 77], [78, 79], [80, 84], [85, 90], [91, 93], [94, 102], [103, 111], [112, 117], [118, 120], [121, 127], [128, 130], [131, 137], [138, 140], [141, 146], [147, 148], [149, 151], [152, 159], [160, 165], [165, 166]]}
{"doc_key": "ai-test-26", "ner": [[5, 7, "product"], [10, 10, "researcher"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 7, 10, 10, "origin", "", false, false], [5, 7, 16, 16, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "maioria", "s\u00e3o", "resultados", "do", "modelo", "word2", "vec", "desenvolvido", "por", "Mikolov", "et", "al", "ou", "variantes", "do", "word2vec", "."], "sentence-detokenized": "A maioria s\u00e3o resultados do modelo word2vec desenvolvido por Mikolov et al ou variantes do word2vec.", "token2charspan": [[0, 1], [2, 9], [10, 13], [14, 24], [25, 27], [28, 34], [35, 40], [40, 43], [44, 56], [57, 60], [61, 68], [69, 71], [72, 74], [75, 77], [78, 87], [88, 90], [91, 99], [99, 100]]}
{"doc_key": "ai-test-27", "ner": [[13, 13, "conference"], [16, 20, "conference"], [22, 22, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 22, 16, 20, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Foi", "durante", "este", "tempo", "que", "um", "total", "de", "43", "publica\u00e7\u00f5es", "foram", "reconhecidas", "pela", "CVPR", "e", "pela", "Confer\u00eancia", "Internacional", "sobre", "Vis\u00e3o", "Inform\u00e1tica", "(", "ICCV", ")", "."], "sentence-detokenized": "Foi durante este tempo que um total de 43 publica\u00e7\u00f5es foram reconhecidas pela CVPR e pela Confer\u00eancia Internacional sobre Vis\u00e3o Inform\u00e1tica (ICCV).", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 22], [23, 26], [27, 29], [30, 35], [36, 38], [39, 41], [42, 53], [54, 59], [60, 72], [73, 77], [78, 82], [83, 84], [85, 89], [90, 101], [102, 115], [116, 121], [122, 127], [128, 139], [140, 141], [141, 145], [145, 146], [146, 147]]}
{"doc_key": "ai-test-28", "ner": [[1, 1, "product"], [16, 17, "field"], [24, 26, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 16, 17, "general-affiliation", "platform_for_education_about", false, false], [24, 26, 1, 1, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "AIBO", "tem", "visto", "muito", "uso", "como", "uma", "plataforma", "barata", "para", "a", "educa\u00e7\u00e3o", "e", "investiga\u00e7\u00e3o", "de", "intelig\u00eancia", "artificial", ",", "porque", "integra", "um", "computador", ",", "vis\u00e3o", "de", "computador", ",", "e", "articuladores", "num", "pacote", "vastamente", "mais", "barato", "do", "que", "os", "rob\u00f4s", "de", "investiga\u00e7\u00e3o", "convencionais", "."], "sentence-detokenized": "A AIBO tem visto muito uso como uma plataforma barata para a educa\u00e7\u00e3o e investiga\u00e7\u00e3o de intelig\u00eancia artificial, porque integra um computador, vis\u00e3o de computador, e articuladores num pacote vastamente mais barato do que os rob\u00f4s de investiga\u00e7\u00e3o convencionais.", "token2charspan": [[0, 1], [2, 6], [7, 10], [11, 16], [17, 22], [23, 26], [27, 31], [32, 35], [36, 46], [47, 53], [54, 58], [59, 60], [61, 69], [70, 71], [72, 84], [85, 87], [88, 100], [101, 111], [111, 112], [113, 119], [120, 127], [128, 130], [131, 141], [141, 142], [143, 148], [149, 151], [152, 162], [162, 163], [164, 165], [166, 179], [180, 183], [184, 190], [191, 201], [202, 206], [207, 213], [214, 216], [217, 220], [221, 223], [224, 229], [230, 232], [233, 245], [246, 259], [259, 260]]}
{"doc_key": "ai-test-29", "ner": [[5, 10, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Foi", "Presidente", "do", "Programa", "da", "Confer\u00eancia", "Internacional", "sobre", "Vis\u00e3o", "Inform\u00e1tica", "2021", "."], "sentence-detokenized": "Foi Presidente do Programa da Confer\u00eancia Internacional sobre Vis\u00e3o Inform\u00e1tica 2021.", "token2charspan": [[0, 3], [4, 14], [15, 17], [18, 26], [27, 29], [30, 41], [42, 55], [56, 61], [62, 67], [68, 79], [80, 84], [84, 85]]}
{"doc_key": "ai-test-30", "ner": [[0, 0, "researcher"], [8, 8, "organisation"], [19, 19, "organisation"], [27, 28, "organisation"], [36, 40, "product"], [42, 42, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 8, 8, "role", "", false, false], [0, 0, 19, 19, "role", "", true, false], [19, 19, 27, 28, "role", "develops_with", false, false], [36, 40, 19, 19, "artifact", "", false, false], [42, 42, 36, 40, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Scheinman", ",", "depois", "de", "receber", "uma", "bolsa", "da", "Unimation", "para", "desenvolver", "os", "seus", "desenhos", ",", "vendeu", "esses", "desenhos", "\u00e0", "Unimation", "que", "os", "desenvolveu", "com", "o", "apoio", "da", "General", "Motors", "e", "mais", "tarde", "a", "comercializou", "como", "a", "M\u00e1quina", "Universal", "Program\u00e1vel", "para", "Montagem", "(", "PUMA", ")", "."], "sentence-detokenized": "Scheinman, depois de receber uma bolsa da Unimation para desenvolver os seus desenhos, vendeu esses desenhos \u00e0 Unimation que os desenvolveu com o apoio da General Motors e mais tarde a comercializou como a M\u00e1quina Universal Program\u00e1vel para Montagem (PUMA).", "token2charspan": [[0, 9], [9, 10], [11, 17], [18, 20], [21, 28], [29, 32], [33, 38], [39, 41], [42, 51], [52, 56], [57, 68], [69, 71], [72, 76], [77, 85], [85, 86], [87, 93], [94, 99], [100, 108], [109, 110], [111, 120], [121, 124], [125, 127], [128, 139], [140, 143], [144, 145], [146, 151], [152, 154], [155, 162], [163, 169], [170, 171], [172, 176], [177, 182], [183, 184], [185, 198], [199, 203], [204, 205], [206, 213], [214, 223], [224, 235], [236, 240], [241, 249], [250, 251], [251, 255], [255, 256], [256, 257]]}
{"doc_key": "ai-test-31", "ner": [[15, 16, "task"], [13, 20, "task"], [0, 0, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 15, 16, "general-affiliation", "works_with", false, false], [0, 0, 13, 20, "general-affiliation", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Gebel", "(", "2009", ")", "apresenta", "uma", "vis\u00e3o", "geral", "dos", "m\u00e9todos", "de", "calibra\u00e7\u00e3o", "para", "tarefas", "de", "classifica\u00e7\u00e3o", "bin\u00e1ria", "e", "de", "classifica\u00e7\u00e3o", "multiclasse"], "sentence-detokenized": "Gebel (2009) apresenta uma vis\u00e3o geral dos m\u00e9todos de calibra\u00e7\u00e3o para tarefas de classifica\u00e7\u00e3o bin\u00e1ria e de classifica\u00e7\u00e3o multiclasse", "token2charspan": [[0, 5], [6, 7], [7, 11], [11, 12], [13, 22], [23, 26], [27, 32], [33, 38], [39, 42], [43, 50], [51, 53], [54, 64], [65, 69], [70, 77], [78, 80], [81, 94], [95, 102], [103, 104], [105, 107], [108, 121], [122, 133]]}
{"doc_key": "ai-test-32", "ner": [[6, 9, "task"], [11, 11, "task"], [14, 16, "task"], [20, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 6, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Est\u00e1", "envolvido", "em", "campos", "como", "o", "reconhecimento", "\u00f3ptico", "de", "caracteres", "(", "OCR", ")", ",", "s\u00edntese", "de", "voz", ",", "tecnologia", "de", "reconhecimento", "de", "voz", ",", "e", "instrumentos", "electr\u00f3nicos", "de", "teclado", "."], "sentence-detokenized": "Est\u00e1 envolvido em campos como o reconhecimento \u00f3ptico de caracteres (OCR), s\u00edntese de voz, tecnologia de reconhecimento de voz, e instrumentos electr\u00f3nicos de teclado.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 24], [25, 29], [30, 31], [32, 46], [47, 53], [54, 56], [57, 67], [68, 69], [69, 72], [72, 73], [73, 74], [75, 82], [83, 85], [86, 89], [89, 90], [91, 101], [102, 104], [105, 119], [120, 122], [123, 126], [126, 127], [128, 129], [130, 142], [143, 155], [156, 158], [159, 166], [166, 167]]}
{"doc_key": "ai-test-33", "ner": [[13, 16, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Para", "t\u00e9cnicas", "mais", "recentes", "e", "de", "\u00faltima", "gera\u00e7\u00e3o", ",", "pode", "ser", "utilizado", "o", "conjunto", "de", "ferramentas", "Kaldi", "."], "sentence-detokenized": "Para t\u00e9cnicas mais recentes e de \u00faltima gera\u00e7\u00e3o, pode ser utilizado o conjunto de ferramentas Kaldi.", "token2charspan": [[0, 4], [5, 13], [14, 18], [19, 27], [28, 29], [30, 32], [33, 39], [40, 47], [47, 48], [49, 53], [54, 57], [58, 67], [68, 69], [70, 78], [79, 81], [82, 93], [94, 99], [99, 100]]}
{"doc_key": "ai-test-34", "ner": [[0, 0, "researcher"], [5, 7, "organisation"], [12, 13, "organisation"], [18, 19, "organisation"], [22, 23, "researcher"], [26, 30, "organisation"], [36, 39, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 5, 7, "role", "", false, false], [0, 0, 12, 13, "role", "", false, false], [0, 0, 18, 19, "role", "", false, false], [0, 0, 26, 30, "role", "", false, false], [0, 0, 36, 39, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Johnson-Laird", "\u00e9", "um", "Fellow", "da", "Sociedade", "Filos\u00f3fica", "Americana", ",", "um", "Fellow", "da", "Sociedade", "Real", ",", "um", "Fellow", "da", "Academia", "Brit\u00e2nica", ",", "um", "William", "James", "Fellow", "da", "Associa\u00e7\u00e3o", "para", "as", "Ci\u00eancias", "Psicol\u00f3gicas", ",", "e", "um", "Fellow", "da", "Sociedade", "das", "Ci\u00eancias", "Cognitivas", "."], "sentence-detokenized": "Johnson-Laird \u00e9 um Fellow da Sociedade Filos\u00f3fica Americana, um Fellow da Sociedade Real, um Fellow da Academia Brit\u00e2nica, um William James Fellow da Associa\u00e7\u00e3o para as Ci\u00eancias Psicol\u00f3gicas, e um Fellow da Sociedade das Ci\u00eancias Cognitivas.", "token2charspan": [[0, 13], [14, 15], [16, 18], [19, 25], [26, 28], [29, 38], [39, 49], [50, 59], [59, 60], [61, 63], [64, 70], [71, 73], [74, 83], [84, 88], [88, 89], [90, 92], [93, 99], [100, 102], [103, 111], [112, 121], [121, 122], [123, 125], [126, 133], [134, 139], [140, 146], [147, 149], [150, 160], [161, 165], [166, 168], [169, 177], [178, 190], [190, 191], [192, 193], [194, 196], [197, 203], [204, 206], [207, 216], [217, 220], [221, 229], [230, 240], [240, 241]]}
{"doc_key": "ai-test-35", "ner": [[1, 7, "conference"], [11, 12, "researcher"], [14, 15, "researcher"], [18, 19, "researcher"], [22, 23, "algorithm"], [27, 32, "task"], [34, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 12, 1, 7, "physical", "", false, false], [11, 12, 1, 7, "temporal", "", false, false], [14, 15, 1, 7, "physical", "", false, false], [14, 15, 1, 7, "temporal", "", false, false], [18, 19, 1, 7, "physical", "", false, false], [18, 19, 1, 7, "temporal", "", false, false], [22, 23, 18, 19, "role", "extends", false, false], [27, 32, 18, 19, "role", "extends", false, false], [34, 34, 27, 32, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Na", "Confer\u00eancia", "Internacional", "IEEE", "sobre", "Processamento", "de", "Imagem", "em", "2010", ",", "Rui", "Hu", ",", "Mark", "Banard", ",", "e", "John", "Collomosse", "estenderam", "o", "descritor", "HOG", "para", "utiliza\u00e7\u00e3o", "na", "recupera\u00e7\u00e3o", "de", "imagem", "baseada", "em", "esbo\u00e7os", "(", "SBIR", ")", "."], "sentence-detokenized": "Na Confer\u00eancia Internacional IEEE sobre Processamento de Imagem em 2010, Rui Hu, Mark Banard, e John Collomosse estenderam o descritor HOG para utiliza\u00e7\u00e3o na recupera\u00e7\u00e3o de imagem baseada em esbo\u00e7os (SBIR).", "token2charspan": [[0, 2], [3, 14], [15, 28], [29, 33], [34, 39], [40, 53], [54, 56], [57, 63], [64, 66], [67, 71], [71, 72], [73, 76], [77, 79], [79, 80], [81, 85], [86, 92], [92, 93], [94, 95], [96, 100], [101, 111], [112, 122], [123, 124], [125, 134], [135, 138], [139, 143], [144, 154], [155, 157], [158, 169], [170, 172], [173, 179], [180, 187], [188, 190], [191, 198], [199, 200], [200, 204], [204, 205], [205, 206]]}
{"doc_key": "ai-test-36", "ner": [[0, 1, "metrics"], [7, 7, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 7, 7, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "BLEU", "utiliza", "uma", "forma", "modificada", "de", "precis\u00e3o", "para", "comparar", "uma", "tradu\u00e7\u00e3o", "candidata", "com", "m\u00faltiplas", "tradu\u00e7\u00f5es", "de", "refer\u00eancia", "."], "sentence-detokenized": "A BLEU utiliza uma forma modificada de precis\u00e3o para comparar uma tradu\u00e7\u00e3o candidata com m\u00faltiplas tradu\u00e7\u00f5es de refer\u00eancia.", "token2charspan": [[0, 1], [2, 6], [7, 14], [15, 18], [19, 24], [25, 35], [36, 38], [39, 47], [48, 52], [53, 61], [62, 65], [66, 74], [75, 84], [85, 88], [89, 98], [99, 108], [109, 111], [112, 122], [122, 123]]}
{"doc_key": "ai-test-37", "ner": [[34, 35, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Para", "o", "caso", "de", "um", "espa\u00e7o", "de", "base", "geral", "matem\u00e1tica", "(", "Y,{B}", ",", "nu", ")", "/", "matem\u00e1tica", "(", "isto", "\u00e9", ",", "um", "espa\u00e7o", "de", "base", "que", "n\u00e3o", "\u00e9", "contabiliz\u00e1vel", ")", ",", "considera-se", "tipicamente", "a", "entropia", "relativa", "."], "sentence-detokenized": "Para o caso de um espa\u00e7o de base geral matem\u00e1tica (Y,{B},nu) / matem\u00e1tica (isto \u00e9, um espa\u00e7o de base que n\u00e3o \u00e9 contabiliz\u00e1vel), considera-se tipicamente a entropia relativa.", "token2charspan": [[0, 4], [5, 6], [7, 11], [12, 14], [15, 17], [18, 24], [25, 27], [28, 32], [33, 38], [39, 49], [50, 51], [51, 56], [56, 57], [57, 59], [59, 60], [61, 62], [63, 73], [74, 75], [75, 79], [80, 81], [81, 82], [83, 85], [86, 92], [93, 95], [96, 100], [101, 104], [105, 108], [109, 110], [111, 125], [125, 126], [126, 127], [128, 140], [141, 152], [153, 154], [155, 163], [164, 172], [172, 173]]}
{"doc_key": "ai-test-38", "ner": [[18, 19, "country"], [11, 13, "organisation"], [15, 15, "organisation"], [28, 29, "country"], [22, 23, "organisation"], [25, 25, "organisation"], [32, 34, "organisation"], [47, 47, "country"], [37, 42, "organisation"], [44, 44, "organisation"], [53, 53, "misc"], [54, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[11, 13, 18, 19, "physical", "", false, false], [15, 15, 11, 13, "named", "", false, false], [22, 23, 28, 29, "physical", "", false, false], [25, 25, 22, 23, "named", "", false, false], [37, 42, 47, 47, "physical", "", false, false], [44, 44, 37, 42, "named", "", false, false], [53, 53, 54, 54, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Desde", "Outubro", "de", "2011", ",", "as", "parcerias", "j\u00e1", "existentes", "com", "o", "National", "Park", "Service", "(", "NPS", ")", "dos", "Estados", "Unidos", ",", "o", "Historic", "Scotland", "(", "HS", ")", "do", "Reino", "Unido", ",", "o", "World", "Monuments", "Fund", "e", "o", "Instituto", "Nacional", "de", "Antropolog\u00eda", "y", "Historia", "(", "INAH", ")", "do", "M\u00e9xico", "tinham", "sido", "grandemente", "expandidas", ",", "CyArk", "website"], "sentence-detokenized": "Desde Outubro de 2011, as parcerias j\u00e1 existentes com o National Park Service (NPS) dos Estados Unidos, o Historic Scotland (HS) do Reino Unido, o World Monuments Fund e o Instituto Nacional de Antropolog\u00eda y Historia (INAH) do M\u00e9xico tinham sido grandemente expandidas, CyArk website", "token2charspan": [[0, 5], [6, 13], [14, 16], [17, 21], [21, 22], [23, 25], [26, 35], [36, 38], [39, 49], [50, 53], [54, 55], [56, 64], [65, 69], [70, 77], [78, 79], [79, 82], [82, 83], [84, 87], [88, 95], [96, 102], [102, 103], [104, 105], [106, 114], [115, 123], [124, 125], [125, 127], [127, 128], [129, 131], [132, 137], [138, 143], [143, 144], [145, 146], [147, 152], [153, 162], [163, 167], [168, 169], [170, 171], [172, 181], [182, 190], [191, 193], [194, 206], [207, 208], [209, 217], [218, 219], [219, 223], [223, 224], [225, 227], [228, 234], [235, 241], [242, 246], [247, 258], [259, 269], [269, 270], [271, 276], [277, 284]]}
{"doc_key": "ai-test-39", "ner": [[0, 2, "algorithm"], [11, 13, "field"], [16, 16, "product"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 16, 16, "part-of", "", false, false], [0, 2, 18, 18, "part-of", "", false, false], [16, 16, 11, 13, "general-affiliation", "", false, false], [18, 18, 11, 13, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Os", "Kernel", "SVMs", "est\u00e3o", "dispon\u00edveis", "em", "muitos", "conjuntos", "de", "ferramentas", "de", "aprendizagem", "por", "m\u00e1quina", ",", "incluindo", "LIBSVM", ",", "MATLAB", ",", "e", "outros", "."], "sentence-detokenized": "Os Kernel SVMs est\u00e3o dispon\u00edveis em muitos conjuntos de ferramentas de aprendizagem por m\u00e1quina, incluindo LIBSVM, MATLAB, e outros.", "token2charspan": [[0, 2], [3, 9], [10, 14], [15, 20], [21, 32], [33, 35], [36, 42], [43, 52], [53, 55], [56, 67], [68, 70], [71, 83], [84, 87], [88, 95], [95, 96], [97, 106], [107, 113], [113, 114], [115, 121], [121, 122], [123, 124], [125, 131], [131, 132]]}
{"doc_key": "ai-test-40", "ner": [[1, 4, "misc"], [14, 15, "location"], [17, 17, "location"], [18, 20, "country"], [24, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 4, 14, 15, "physical", "", false, false], [1, 4, 24, 26, "temporal", "", false, false], [14, 15, 17, 17, "physical", "", false, false], [17, 17, 18, 20, "physical", "", false, false], [24, 26, 14, 15, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["O", "Concurso", "do", "Pr\u00e9mio", "Loebner", "2009", "realizou-se", "a", "6", "de", "Setembro", "de", "2009", "no", "Brighton", "Centre", ",", "Brighton", "UK", ",", "em", "conjunto", "com", "a", "confer\u00eancia", "Interspeech", "2009", "."], "sentence-detokenized": "O Concurso do Pr\u00e9mio Loebner 2009 realizou-se a 6 de Setembro de 2009 no Brighton Centre, Brighton UK, em conjunto com a confer\u00eancia Interspeech 2009.", "token2charspan": [[0, 1], [2, 10], [11, 13], [14, 20], [21, 28], [29, 33], [34, 45], [46, 47], [48, 49], [50, 52], [53, 61], [62, 64], [65, 69], [70, 72], [73, 81], [82, 88], [88, 89], [90, 98], [99, 101], [101, 102], [103, 105], [106, 114], [115, 118], [119, 120], [121, 132], [133, 144], [145, 149], [149, 150]]}
{"doc_key": "ai-test-41", "ner": [[1, 3, "product"], [10, 10, "product"], [21, 21, "product"], [17, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[17, 22, 1, 3, "part-of", "", false, false], [17, 22, 10, 10, "part-of", "", false, false], [17, 22, 21, 21, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["O", "rob\u00f4", "human\u00f3ide", "QRIO", "foi", "concebido", "como", "o", "sucessor", "do", "AIBO", ",", "e", "funciona", "com", "o", "mesmo", "sistema", "operativo", "de", "base", "R-CODE", "Aperios", "."], "sentence-detokenized": "O rob\u00f4 human\u00f3ide QRIO foi concebido como o sucessor do AIBO, e funciona com o mesmo sistema operativo de base R-CODE Aperios.", "token2charspan": [[0, 1], [2, 6], [7, 16], [17, 21], [22, 25], [26, 35], [36, 40], [41, 42], [43, 51], [52, 54], [55, 59], [59, 60], [61, 62], [63, 71], [72, 75], [76, 77], [78, 83], [84, 91], [92, 101], [102, 104], [105, 109], [110, 116], [117, 124], [124, 125]]}
{"doc_key": "ai-test-42", "ner": [[0, 5, "misc"], [12, 12, "algorithm"], [18, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 12, 0, 5, "cause-effect", "", true, false], [18, 19, 0, 5, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "formas", "de", "onda", "de", "fala", "s\u00e3o", "geradas", "a", "partir", "dos", "pr\u00f3prios", "HMMs", "com", "base", "no", "crit\u00e9rio", "da", "m\u00e1xima", "probabilidade", "."], "sentence-detokenized": "As formas de onda de fala s\u00e3o geradas a partir dos pr\u00f3prios HMMs com base no crit\u00e9rio da m\u00e1xima probabilidade.", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 17], [18, 20], [21, 25], [26, 29], [30, 37], [38, 39], [40, 46], [47, 50], [51, 59], [60, 64], [65, 68], [69, 73], [74, 76], [77, 85], [86, 88], [89, 95], [96, 109], [109, 110]]}
{"doc_key": "ai-test-43", "ner": [[0, 1, "product"], [7, 10, "task"], [13, 15, "task"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 7, 10, "type-of", "", false, false], [0, 1, 13, 15, "type-of", "", false, false], [0, 1, 18, 18, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Google", "Translate", "\u00e9", "um", "servi\u00e7o", "gratuito", "de", "tradu\u00e7\u00e3o", "autom\u00e1tica", "estat\u00edstica", "multilingue", "e", "de", "tradu\u00e7\u00e3o", "autom\u00e1tica", "neural", "desenvolvido", "pelo", "Google", ",", "para", "traduzir", "textos", "e", "websites", "de", "uma", "l\u00edngua", "para", "outra", "."], "sentence-detokenized": "Google Translate \u00e9 um servi\u00e7o gratuito de tradu\u00e7\u00e3o autom\u00e1tica estat\u00edstica multilingue e de tradu\u00e7\u00e3o autom\u00e1tica neural desenvolvido pelo Google, para traduzir textos e websites de uma l\u00edngua para outra.", "token2charspan": [[0, 6], [7, 16], [17, 18], [19, 21], [22, 29], [30, 38], [39, 41], [42, 50], [51, 61], [62, 73], [74, 85], [86, 87], [88, 90], [91, 99], [100, 110], [111, 117], [118, 130], [131, 135], [136, 142], [142, 143], [144, 148], [149, 157], [158, 164], [165, 166], [167, 175], [176, 178], [179, 182], [183, 189], [190, 194], [195, 200], [200, 201]]}
{"doc_key": "ai-test-44", "ner": [[6, 8, "field"], [10, 12, "field"], [14, 16, "field"], [18, 21, "field"], [26, 29, "task"], [31, 34, "task"], [36, 39, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[26, 29, 6, 8, "part-of", "", false, true], [26, 29, 10, 12, "part-of", "", false, true], [26, 29, 14, 16, "part-of", "", false, true], [31, 34, 6, 8, "part-of", "", false, true], [31, 34, 10, 12, "part-of", "", false, true], [31, 34, 14, 16, "part-of", "", false, true], [36, 39, 6, 8, "part-of", "", false, true], [36, 39, 10, 12, "part-of", "", false, true], [36, 39, 14, 16, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Os", "esqueletos", "s\u00e3o", "amplamente", "utilizados", "na", "vis\u00e3o", "por", "computador", ",", "an\u00e1lise", "de", "imagem", ",", "reconhecimento", "de", "padr\u00f5es", "e", "processamento", "digital", "de", "imagem", "para", "fins", "tais", "como", "reconhecimento", "\u00f3ptico", "de", "caracteres", ",", "reconhecimento", "de", "impress\u00f5es", "digitais", ",", "inspec\u00e7\u00e3o", "visual", "ou", "compress\u00e3o", "."], "sentence-detokenized": "Os esqueletos s\u00e3o amplamente utilizados na vis\u00e3o por computador, an\u00e1lise de imagem, reconhecimento de padr\u00f5es e processamento digital de imagem para fins tais como reconhecimento \u00f3ptico de caracteres, reconhecimento de impress\u00f5es digitais, inspec\u00e7\u00e3o visual ou compress\u00e3o.", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 28], [29, 39], [40, 42], [43, 48], [49, 52], [53, 63], [63, 64], [65, 72], [73, 75], [76, 82], [82, 83], [84, 98], [99, 101], [102, 109], [110, 111], [112, 125], [126, 133], [134, 136], [137, 143], [144, 148], [149, 153], [154, 158], [159, 163], [164, 178], [179, 185], [186, 188], [189, 199], [199, 200], [201, 215], [216, 218], [219, 229], [230, 238], [238, 239], [240, 249], [250, 256], [257, 259], [260, 270], [270, 271]]}
{"doc_key": "ai-test-45", "ner": [[1, 9, "conference"], [14, 18, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 9, 14, 18, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["O", "Desafio", "de", "Reconhecimento", "Visual", "em", "Grande", "Escala", "da", "ImageNet", "\u00e9", "uma", "refer\u00eancia", "na", "classifica\u00e7\u00e3o", "e", "detec\u00e7\u00e3o", "de", "objectos", ",", "com", "milh\u00f5es", "de", "imagens", "e", "centenas", "de", "classes", "de", "objectos", "."], "sentence-detokenized": "O Desafio de Reconhecimento Visual em Grande Escala da ImageNet \u00e9 uma refer\u00eancia na classifica\u00e7\u00e3o e detec\u00e7\u00e3o de objectos, com milh\u00f5es de imagens e centenas de classes de objectos.", "token2charspan": [[0, 1], [2, 9], [10, 12], [13, 27], [28, 34], [35, 37], [38, 44], [45, 51], [52, 54], [55, 63], [64, 65], [66, 69], [70, 80], [81, 83], [84, 97], [98, 99], [100, 108], [109, 111], [112, 120], [120, 121], [122, 125], [126, 133], [134, 136], [137, 144], [145, 146], [147, 155], [156, 158], [159, 166], [167, 169], [170, 178], [178, 179]]}
{"doc_key": "ai-test-46", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [16, 18, "misc"], [21, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 16, 18, "part-of", "", false, false], [0, 0, 21, 24, "part-of", "", false, false], [4, 5, 16, 18, "part-of", "", false, false], [4, 5, 21, 24, "part-of", "", false, false], [7, 8, 16, 18, "part-of", "", false, false], [7, 8, 21, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Bengio", ",", "juntamente", "com", "Geoffrey", "Hinton", "e", "Yann", "LeCun", ",", "s\u00e3o", "referidos", "por", "alguns", "como", "os", "Padrinhos", "da", "IA", "e", "os", "Padrinhos", "do", "Ensino", "Profundo", "."], "sentence-detokenized": "Bengio, juntamente com Geoffrey Hinton e Yann LeCun, s\u00e3o referidos por alguns como os Padrinhos da IA e os Padrinhos do Ensino Profundo.", "token2charspan": [[0, 6], [6, 7], [8, 18], [19, 22], [23, 31], [32, 38], [39, 40], [41, 45], [46, 51], [51, 52], [53, 56], [57, 66], [67, 70], [71, 77], [78, 82], [83, 85], [86, 95], [96, 98], [99, 101], [102, 103], [104, 106], [107, 116], [117, 119], [120, 126], [127, 135], [135, 136]]}
{"doc_key": "ai-test-47", "ner": [[6, 6, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ele", "\u00e9", "um", "Life", "Fellow", "do", "IEEE", "."], "sentence-detokenized": "Ele \u00e9 um Life Fellow do IEEE.", "token2charspan": [[0, 3], [4, 5], [6, 8], [9, 13], [14, 20], [21, 23], [24, 28], [28, 29]]}
{"doc_key": "ai-test-48", "ner": [[0, 2, "organisation"], [16, 21, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 16, 21, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "NSA", "Bethesda", "\u00e9", "respons\u00e1vel", "pelo", "apoio", "operacional", "de", "base", "ao", "seu", "principal", "inquilino", ",", "o", "Centro", "M\u00e9dico", "Militar", "Nacional", "Walter", "Reed", "."], "sentence-detokenized": "A NSA Bethesda \u00e9 respons\u00e1vel pelo apoio operacional de base ao seu principal inquilino, o Centro M\u00e9dico Militar Nacional Walter Reed.", "token2charspan": [[0, 1], [2, 5], [6, 14], [15, 16], [17, 28], [29, 33], [34, 39], [40, 51], [52, 54], [55, 59], [60, 62], [63, 66], [67, 76], [77, 86], [86, 87], [88, 89], [90, 96], [97, 103], [104, 111], [112, 120], [121, 127], [128, 132], [132, 133]]}
{"doc_key": "ai-test-49", "ner": [[8, 9, "field"], [12, 14, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Os", "tr\u00eas", "principais", "paradigmas", "de", "aprendizagem", "s\u00e3o", "a", "aprendizagem", "supervisionada", ",", "a", "aprendizagem", "n\u00e3o", "supervisionada", "e", "a", "aprendizagem", "refor\u00e7ada", "."], "sentence-detokenized": "Os tr\u00eas principais paradigmas de aprendizagem s\u00e3o a aprendizagem supervisionada, a aprendizagem n\u00e3o supervisionada e a aprendizagem refor\u00e7ada.", "token2charspan": [[0, 2], [3, 7], [8, 18], [19, 29], [30, 32], [33, 45], [46, 49], [50, 51], [52, 64], [65, 79], [79, 80], [81, 82], [83, 95], [96, 99], [100, 114], [115, 116], [117, 118], [119, 131], [132, 141], [141, 142]]}
{"doc_key": "ai-test-50", "ner": [[3, 3, "task"], [5, 7, "task"], [11, 18, "task"], [20, 22, "task"], [24, 27, "task"], [29, 31, "task"], [33, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Os", "exemplos", "incluem", "controlo", ",", "planeamento", "e", "calendariza\u00e7\u00e3o", ",", "capacidade", "de", "responder", "a", "quest\u00f5es", "de", "diagn\u00f3stico", "e", "de", "consumo", ",", "reconhecimento", "da", "caligrafia", ",", "compreens\u00e3o", "da", "linguagem", "natural", ",", "reconhecimento", "da", "fala", "e", "reconhecimento", "facial", "."], "sentence-detokenized": "Os exemplos incluem controlo, planeamento e calendariza\u00e7\u00e3o, capacidade de responder a quest\u00f5es de diagn\u00f3stico e de consumo, reconhecimento da caligrafia, compreens\u00e3o da linguagem natural, reconhecimento da fala e reconhecimento facial.", "token2charspan": [[0, 2], [3, 11], [12, 19], [20, 28], [28, 29], [30, 41], [42, 43], [44, 58], [58, 59], [60, 70], [71, 73], [74, 83], [84, 85], [86, 94], [95, 97], [98, 109], [110, 111], [112, 114], [115, 122], [122, 123], [124, 138], [139, 141], [142, 152], [152, 153], [154, 165], [166, 168], [169, 178], [179, 186], [186, 187], [188, 202], [203, 205], [206, 210], [211, 212], [213, 227], [228, 234], [234, 235]]}
{"doc_key": "ai-test-51", "ner": [[7, 13, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Em", "1991", "foi", "eleito", "como", "membro", "da", "Associa\u00e7\u00e3o", "para", "o", "Progresso", "da", "Intelig\u00eancia", "Artificial", "(", "1990", ",", "membro", "fundador", ")", "."], "sentence-detokenized": "Em 1991 foi eleito como membro da Associa\u00e7\u00e3o para o Progresso da Intelig\u00eancia Artificial (1990, membro fundador).", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 18], [19, 23], [24, 30], [31, 33], [34, 44], [45, 49], [50, 51], [52, 61], [62, 64], [65, 77], [78, 88], [89, 90], [90, 94], [94, 95], [96, 102], [103, 111], [111, 112], [112, 113]]}
{"doc_key": "ai-test-52", "ner": [[10, 12, "misc"], [16, 18, "algorithm"], [29, 32, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Contudo", ",", "formulando", "o", "problema", "como", "a", "solu\u00e7\u00e3o", "de", "uma", "matriz", "de", "Toeplitz", "e", "utilizando", "a", "recorr\u00eancia", "de", "Levinson", ",", "podemos", "estimar", "relativamente", "depressa", "um", "filtro", "com", "o", "menor", "erro", "m\u00e9dio", "ao", "quadrado", "poss\u00edvel", "."], "sentence-detokenized": "Contudo, formulando o problema como a solu\u00e7\u00e3o de uma matriz de Toeplitz e utilizando a recorr\u00eancia de Levinson, podemos estimar relativamente depressa um filtro com o menor erro m\u00e9dio ao quadrado poss\u00edvel.", "token2charspan": [[0, 7], [7, 8], [9, 19], [20, 21], [22, 30], [31, 35], [36, 37], [38, 45], [46, 48], [49, 52], [53, 59], [60, 62], [63, 71], [72, 73], [74, 84], [85, 86], [87, 98], [99, 101], [102, 110], [110, 111], [112, 119], [120, 127], [128, 141], [142, 150], [151, 153], [154, 160], [161, 164], [165, 166], [167, 172], [173, 177], [178, 183], [184, 186], [187, 195], [196, 204], [204, 205]]}
{"doc_key": "ai-test-53", "ner": [[6, 11, "conference"], [15, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 11, 15, 20, "physical", "", false, false], [15, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Em", "Julho", "de", "20", "11", "a", "15\u00aa", "edi\u00e7\u00e3o", "do", "Campus", "Party", "Espanha", "ter\u00e1", "lugar", "na", "Cidade", "das", "Artes", "e", "das", "Ci\u00eancias", "em", "Val\u00eancia", "."], "sentence-detokenized": "Em Julho de 2011 a 15\u00aa edi\u00e7\u00e3o do Campus Party Espanha ter\u00e1 lugar na Cidade das Artes e das Ci\u00eancias em Val\u00eancia.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 14], [14, 16], [17, 18], [19, 22], [23, 29], [30, 32], [33, 39], [40, 45], [46, 53], [54, 58], [59, 64], [65, 67], [68, 74], [75, 78], [79, 84], [85, 86], [87, 90], [91, 99], [100, 102], [103, 111], [111, 112]]}
{"doc_key": "ai-test-54", "ner": [[14, 14, "product"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Muitas", "vezes", "isto", "s\u00f3", "\u00e9", "geralmente", "poss\u00edvel", "no", "final", "de", "jogos", "complicados", "como", "o", "xadrez", "ou", "a", "partida", ",", "uma", "vez", "que", "n\u00e3o", "\u00e9", "computacionalmente", "vi\u00e1vel", "olhar", "em", "frente", "at\u00e9", "\u00e0", "conclus\u00e3o", "do", "jogo", ",", "excepto", "no", "final", ",", "e", "em", "vez", "disso", ",", "s\u00e3o", "dados", "valores", "finitos", "como", "estimativas", "do", "grau", "de", "cren\u00e7a", "de", "que", "levar\u00e3o", "a", "uma", "vit\u00f3ria", "para", "um", "ou", "outro", "jogador", "."], "sentence-detokenized": "Muitas vezes isto s\u00f3 \u00e9 geralmente poss\u00edvel no final de jogos complicados como o xadrez ou a partida, uma vez que n\u00e3o \u00e9 computacionalmente vi\u00e1vel olhar em frente at\u00e9 \u00e0 conclus\u00e3o do jogo, excepto no final, e em vez disso, s\u00e3o dados valores finitos como estimativas do grau de cren\u00e7a de que levar\u00e3o a uma vit\u00f3ria para um ou outro jogador.", "token2charspan": [[0, 6], [7, 12], [13, 17], [18, 20], [21, 22], [23, 33], [34, 42], [43, 45], [46, 51], [52, 54], [55, 60], [61, 72], [73, 77], [78, 79], [80, 86], [87, 89], [90, 91], [92, 99], [99, 100], [101, 104], [105, 108], [109, 112], [113, 116], [117, 118], [119, 137], [138, 144], [145, 150], [151, 153], [154, 160], [161, 164], [165, 166], [167, 176], [177, 179], [180, 184], [184, 185], [186, 193], [194, 196], [197, 202], [202, 203], [204, 205], [206, 208], [209, 212], [213, 218], [218, 219], [220, 223], [224, 229], [230, 237], [238, 245], [246, 250], [251, 262], [263, 265], [266, 270], [271, 273], [274, 280], [281, 283], [284, 287], [288, 295], [296, 297], [298, 301], [302, 309], [310, 314], [315, 317], [318, 320], [321, 326], [327, 334], [334, 335]]}
{"doc_key": "ai-test-55", "ner": [[4, 6, "algorithm"], [24, 25, "algorithm"], [27, 30, "algorithm"], [32, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 24, 25, "compare", "", false, false], [4, 6, 27, 30, "compare", "", false, false], [4, 6, 32, 34, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "diferen\u00e7a", "entre", "o", "modelo", "logit", "multinomial", "e", "numerosos", "outros", "m\u00e9todos", ",", "modelos", ",", "algoritmos", ",", "etc.", "com", "a", "mesma", "configura\u00e7\u00e3o", "b\u00e1sica", "(", "o", "algoritmo", "perceptron", ",", "m\u00e1quinas", "vectoriais", "de", "suporte", ",", "an\u00e1lise", "linear", "discriminante", ",", "etc.", ")", "."], "sentence-detokenized": "A diferen\u00e7a entre o modelo logit multinomial e numerosos outros m\u00e9todos, modelos, algoritmos, etc. com a mesma configura\u00e7\u00e3o b\u00e1sica (o algoritmo perceptron, m\u00e1quinas vectoriais de suporte, an\u00e1lise linear discriminante, etc.).", "token2charspan": [[0, 1], [2, 11], [12, 17], [18, 19], [20, 26], [27, 32], [33, 44], [45, 46], [47, 56], [57, 63], [64, 71], [71, 72], [73, 80], [80, 81], [82, 92], [92, 93], [94, 98], [99, 102], [103, 104], [105, 110], [111, 123], [124, 130], [131, 132], [132, 133], [134, 143], [144, 154], [154, 155], [156, 164], [165, 175], [176, 178], [179, 186], [186, 187], [188, 195], [196, 202], [203, 216], [216, 217], [218, 222], [222, 223], [223, 224]]}
{"doc_key": "ai-test-56", "ner": [[0, 3, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Association", "for", "Computational", "Linguistics", ",", "publicado", "por"], "sentence-detokenized": "Association for Computational Linguistics, publicado por", "token2charspan": [[0, 11], [12, 15], [16, 29], [30, 41], [41, 42], [43, 52], [53, 56]]}
{"doc_key": "ai-test-57", "ner": [[1, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["No", "sistema", "informatizado", "de", "reconhecimento", "facial", ",", "cada", "rosto", "\u00e9", "representado", "por", "um", "grande", "n\u00famero", "de", "valores", "de", "p\u00edxeis", "."], "sentence-detokenized": "No sistema informatizado de reconhecimento facial, cada rosto \u00e9 representado por um grande n\u00famero de valores de p\u00edxeis.", "token2charspan": [[0, 2], [3, 10], [11, 24], [25, 27], [28, 42], [43, 49], [49, 50], [51, 55], [56, 61], [62, 63], [64, 76], [77, 80], [81, 83], [84, 90], [91, 97], [98, 100], [101, 108], [109, 111], [112, 118], [118, 119]]}
{"doc_key": "ai-test-58", "ner": [[7, 8, "person"], [12, 14, "organisation"], [21, 21, "country"], [25, 25, "person"], [37, 39, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 8, 12, 14, "role", "", false, false], [7, 8, 21, 21, "physical", "", false, false], [25, 25, 37, 39, "origin", "", false, false], [25, 25, 37, 39, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Em", "2002", ",", "o", "seu", "filho", ",", "Daniel", "Pearl", ",", "jornalista", "do", "Wall", "Street", "Journal", ",", "foi", "raptado", "e", "assassinado", "no", "Paquist\u00e3o", ",", "levando", "a", "Judeia", "e", "os", "outros", "membros", "da", "fam\u00edlia", "e", "amigos", "a", "criar", "a", "Funda\u00e7\u00e3o", "Daniel", "Pearl", "."], "sentence-detokenized": "Em 2002, o seu filho, Daniel Pearl, jornalista do Wall Street Journal, foi raptado e assassinado no Paquist\u00e3o, levando a Judeia e os outros membros da fam\u00edlia e amigos a criar a Funda\u00e7\u00e3o Daniel Pearl.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 14], [15, 20], [20, 21], [22, 28], [29, 34], [34, 35], [36, 46], [47, 49], [50, 54], [55, 61], [62, 69], [69, 70], [71, 74], [75, 82], [83, 84], [85, 96], [97, 99], [100, 109], [109, 110], [111, 118], [119, 120], [121, 127], [128, 129], [130, 132], [133, 139], [140, 147], [148, 150], [151, 158], [159, 160], [161, 167], [168, 169], [170, 175], [176, 177], [178, 186], [187, 193], [194, 199], [199, 200]]}
{"doc_key": "ai-test-59", "ner": [[8, 10, "organisation"], [20, 21, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 10, 20, 21, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "partir", "de", "finais", "de", "2006", ",", "a", "Red", "Envelope", "Entertainment", "expandiu-se", "tamb\u00e9m", "para", "produzir", "conte\u00fados", "originais", "com", "cineastas", "como", "John", "Waters", "."], "sentence-detokenized": "A partir de finais de 2006, a Red Envelope Entertainment expandiu-se tamb\u00e9m para produzir conte\u00fados originais com cineastas como John Waters.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 18], [19, 21], [22, 26], [26, 27], [28, 29], [30, 33], [34, 42], [43, 56], [57, 68], [69, 75], [76, 80], [81, 89], [90, 99], [100, 109], [110, 113], [114, 123], [124, 128], [129, 133], [134, 140], [140, 141]]}
{"doc_key": "ai-test-60", "ner": [[6, 12, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["O", "edif\u00edcio", "faz", "agora", "parte", "do", "Centro", "M\u00e9dico", "da", "Diaconisa", "de", "Beth", "Israel", "."], "sentence-detokenized": "O edif\u00edcio faz agora parte do Centro M\u00e9dico da Diaconisa de Beth Israel.", "token2charspan": [[0, 1], [2, 10], [11, 14], [15, 20], [21, 26], [27, 29], [30, 36], [37, 43], [44, 46], [47, 56], [57, 59], [60, 64], [65, 71], [71, 72]]}
{"doc_key": "ai-test-61", "ner": [[17, 18, "field"], [20, 22, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Um", "tema", "comum", "deste", "trabalho", "\u00e9", "a", "adop\u00e7\u00e3o", "de", "uma", "perspectiva", "te\u00f3rica", "dos", "sinais", "sobre", "quest\u00f5es", "de", "intelig\u00eancia", "artificial", "e", "representa\u00e7\u00e3o", "do", "conhecimento", "."], "sentence-detokenized": "Um tema comum deste trabalho \u00e9 a adop\u00e7\u00e3o de uma perspectiva te\u00f3rica dos sinais sobre quest\u00f5es de intelig\u00eancia artificial e representa\u00e7\u00e3o do conhecimento.", "token2charspan": [[0, 2], [3, 7], [8, 13], [14, 19], [20, 28], [29, 30], [31, 32], [33, 40], [41, 43], [44, 47], [48, 59], [60, 67], [68, 71], [72, 78], [79, 84], [85, 93], [94, 96], [97, 109], [110, 120], [121, 122], [123, 136], [137, 139], [140, 152], [152, 153]]}
{"doc_key": "ai-test-62", "ner": [[5, 7, "task"], [9, 9, "task"], [23, 24, "task"], [41, 43, "task"], [46, 47, "task"], [52, 54, "task"], [56, 56, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 7, 23, 24, "type-of", "", false, false], [5, 7, 52, 54, "compare", "", false, false], [5, 7, 52, 54, "opposite", "", false, false], [9, 9, 5, 7, "named", "", false, false], [41, 43, 52, 54, "part-of", "", false, false], [46, 47, 52, 54, "part-of", "", false, false], [52, 54, 23, 24, "type-of", "", false, false], [56, 56, 52, 54, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Por", "exemplo", ",", "o", "termo", "tradu\u00e7\u00e3o", "autom\u00e1tica", "neural", "(", "NMT", ")", "enfatiza", "o", "facto", "de", "que", "as", "abordagens", "baseadas", "na", "aprendizagem", "profunda", "da", "tradu\u00e7\u00e3o", "autom\u00e1tica", "aprendem", "directamente", "transforma\u00e7\u00f5es", "de", "sequ\u00eancia", "a", "sequ\u00eancia", ",", "obviando", "a", "necessidade", "de", "passos", "interm\u00e9dios", "como", "o", "alinhamento", "de", "palavras", "e", "a", "modela\u00e7\u00e3o", "lingu\u00edstica", "que", "foi", "utilizada", "na", "tradu\u00e7\u00e3o", "autom\u00e1tica", "estat\u00edstica", "(", "SMT", ")", "."], "sentence-detokenized": "Por exemplo, o termo tradu\u00e7\u00e3o autom\u00e1tica neural (NMT) enfatiza o facto de que as abordagens baseadas na aprendizagem profunda da tradu\u00e7\u00e3o autom\u00e1tica aprendem directamente transforma\u00e7\u00f5es de sequ\u00eancia a sequ\u00eancia, obviando a necessidade de passos interm\u00e9dios como o alinhamento de palavras e a modela\u00e7\u00e3o lingu\u00edstica que foi utilizada na tradu\u00e7\u00e3o autom\u00e1tica estat\u00edstica (SMT).", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 14], [15, 20], [21, 29], [30, 40], [41, 47], [48, 49], [49, 52], [52, 53], [54, 62], [63, 64], [65, 70], [71, 73], [74, 77], [78, 80], [81, 91], [92, 100], [101, 103], [104, 116], [117, 125], [126, 128], [129, 137], [138, 148], [149, 157], [158, 170], [171, 185], [186, 188], [189, 198], [199, 200], [201, 210], [210, 211], [212, 220], [221, 222], [223, 234], [235, 237], [238, 244], [245, 256], [257, 261], [262, 263], [264, 275], [276, 278], [279, 287], [288, 289], [290, 291], [292, 301], [302, 313], [314, 317], [318, 321], [322, 331], [332, 334], [335, 343], [344, 354], [355, 366], [367, 368], [368, 371], [371, 372], [372, 373]]}
{"doc_key": "ai-test-63", "ner": [[8, 8, "field"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 8, 12, 12, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "maior", "parte", "da", "investiga\u00e7\u00e3o", "no", "campo", "da", "WSD", "\u00e9", "realizada", "utilizando", "WordNet", "como", "invent\u00e1rio", "de", "sentido", "de", "refer\u00eancia", "para", "."], "sentence-detokenized": "A maior parte da investiga\u00e7\u00e3o no campo da WSD \u00e9 realizada utilizando WordNet como invent\u00e1rio de sentido de refer\u00eancia para.", "token2charspan": [[0, 1], [2, 7], [8, 13], [14, 16], [17, 29], [30, 32], [33, 38], [39, 41], [42, 45], [46, 47], [48, 57], [58, 68], [69, 76], [77, 81], [82, 92], [93, 95], [96, 103], [104, 106], [107, 117], [118, 122], [122, 123]]}
{"doc_key": "ai-test-64", "ner": [[4, 4, "misc"], [14, 15, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 15, 4, 4, "general-affiliation", "", false, true], [18, 19, 4, 4, "general-affiliation", "", false, true]], "relations_mapping_to_source": [0, 1], "sentence": ["Entre", "os", "ex-alunos", "de", "doutoramento", "e", "investigadores", "de", "p\u00f3s-doutoramento", "not\u00e1veis", "do", "seu", "grupo", "encontram-se", "Richard", "Zemel", ",", "e", "Zoubin", "Ghahramani", "."], "sentence-detokenized": "Entre os ex-alunos de doutoramento e investigadores de p\u00f3s-doutoramento not\u00e1veis do seu grupo encontram-se Richard Zemel, e Zoubin Ghahramani.", "token2charspan": [[0, 5], [6, 8], [9, 18], [19, 21], [22, 34], [35, 36], [37, 51], [52, 54], [55, 71], [72, 80], [81, 83], [84, 87], [88, 93], [94, 106], [107, 114], [115, 120], [120, 121], [122, 123], [124, 130], [131, 141], [141, 142]]}
{"doc_key": "ai-test-65", "ner": [[8, 10, "metrics"], [16, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 10, 16, 16, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cada", "resultado", "de", "previs\u00e3o", "ou", "inst\u00e2ncia", "de", "uma", "matriz", "de", "confus\u00e3o", "representa", "um", "ponto", "no", "espa\u00e7o", "ROC", "."], "sentence-detokenized": "Cada resultado de previs\u00e3o ou inst\u00e2ncia de uma matriz de confus\u00e3o representa um ponto no espa\u00e7o ROC.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 26], [27, 29], [30, 39], [40, 42], [43, 46], [47, 53], [54, 56], [57, 65], [66, 76], [77, 79], [80, 85], [86, 88], [89, 95], [96, 99], [99, 100]]}
{"doc_key": "ai-test-66", "ner": [[3, 3, "researcher"], [8, 9, "researcher"], [11, 12, "researcher"], [16, 19, "product"], [22, 24, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 22, 24, "physical", "", false, false], [8, 9, 22, 24, "physical", "", false, false], [11, 12, 22, 24, "physical", "", false, false], [16, 19, 3, 3, "artifact", "", false, false], [16, 19, 8, 9, "artifact", "", false, false], [16, 19, 11, 12, "artifact", "", false, false], [16, 19, 22, 24, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Em", "1997", ",", "Thrun", "e", "os", "seus", "colegas", "Wolfram", "Burgard", "e", "Dieter", "Fox", "desenvolveram", "o", "primeiro", "guia", "tur\u00edstico", "rob\u00f3tico", "do", "mundo", "no", "Deutsches", "Museum", "Bonn", "(", "1997", ")", "."], "sentence-detokenized": "Em 1997, Thrun e os seus colegas Wolfram Burgard e Dieter Fox desenvolveram o primeiro guia tur\u00edstico rob\u00f3tico do mundo no Deutsches Museum Bonn (1997).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 16], [17, 19], [20, 24], [25, 32], [33, 40], [41, 48], [49, 50], [51, 57], [58, 61], [62, 75], [76, 77], [78, 86], [87, 91], [92, 101], [102, 110], [111, 113], [114, 119], [120, 122], [123, 132], [133, 139], [140, 144], [145, 146], [146, 150], [150, 151], [151, 152]]}
{"doc_key": "ai-test-67", "ner": [[0, 0, "product"], [8, 9, "misc"], [24, 28, "field"], [32, 33, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 0, 0, "part-of", "", false, false], [24, 28, 0, 0, "usage", "", false, false], [32, 33, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["WordNet", "\u00e9", "uma", "base", "de", "dados", "l\u00e9xica", "de", "rela\u00e7\u00f5es", "sem\u00e2nticas", "entre", "palavras", "em", "mais", "de", "200", "l\u00ednguas", ".", "a", "sua", "utiliza\u00e7\u00e3o", "principal", "\u00e9", "no", "processamento", "autom\u00e1tico", "de", "linguagem", "natural", "e", "aplica\u00e7\u00f5es", "de", "intelig\u00eancia", "artificial", "."], "sentence-detokenized": "WordNet \u00e9 uma base de dados l\u00e9xica de rela\u00e7\u00f5es sem\u00e2nticas entre palavras em mais de 200 l\u00ednguas. a sua utiliza\u00e7\u00e3o principal \u00e9 no processamento autom\u00e1tico de linguagem natural e aplica\u00e7\u00f5es de intelig\u00eancia artificial.", "token2charspan": [[0, 7], [8, 9], [10, 13], [14, 18], [19, 21], [22, 27], [28, 34], [35, 37], [38, 46], [47, 57], [58, 63], [64, 72], [73, 75], [76, 80], [81, 83], [84, 87], [88, 95], [95, 96], [97, 98], [99, 102], [103, 113], [114, 123], [124, 125], [126, 128], [129, 142], [143, 153], [154, 156], [157, 166], [167, 174], [175, 176], [177, 187], [188, 190], [191, 203], [204, 214], [214, 215]]}
{"doc_key": "ai-test-68", "ner": [[4, 7, "field"], [12, 15, "conference"], [18, 24, "conference"], [26, 26, "conference"], [29, 29, "conference"], [39, 41, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 15, 4, 7, "topic", "", false, false], [12, 15, 39, 41, "topic", "", false, false], [18, 24, 4, 7, "topic", "", false, false], [18, 24, 39, 41, "topic", "", false, false], [26, 26, 4, 7, "topic", "", false, false], [26, 26, 39, 41, "topic", "", false, false], [29, 29, 4, 7, "topic", "", false, false], [29, 29, 39, 41, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Confer\u00eancias", "no", "campo", "do", "processamento", "da", "linguagem", "natural", ",", "tais", "como", "a", "Association", "for", "Computational", "Linguistics", ",", "o", "cap\u00edtulo", "norte-americano", "da", "Association", "for", "Computational", "Linguistics", ",", "EMNLP", ",", "e", "HLT", ",", "est\u00e3o", "a", "come\u00e7ar", "a", "incluir", "trabalhos", "sobre", "o", "processamento", "da", "fala", "."], "sentence-detokenized": "Confer\u00eancias no campo do processamento da linguagem natural, tais como a Association for Computational Linguistics, o cap\u00edtulo norte-americano da Association for Computational Linguistics, EMNLP, e HLT, est\u00e3o a come\u00e7ar a incluir trabalhos sobre o processamento da fala.", "token2charspan": [[0, 12], [13, 15], [16, 21], [22, 24], [25, 38], [39, 41], [42, 51], [52, 59], [59, 60], [61, 65], [66, 70], [71, 72], [73, 84], [85, 88], [89, 102], [103, 114], [114, 115], [116, 117], [118, 126], [127, 142], [143, 145], [146, 157], [158, 161], [162, 175], [176, 187], [187, 188], [189, 194], [194, 195], [196, 197], [198, 201], [201, 202], [203, 208], [209, 210], [211, 218], [219, 220], [221, 228], [229, 238], [239, 244], [245, 246], [247, 260], [261, 263], [264, 268], [268, 269]]}
{"doc_key": "ai-test-69", "ner": [[4, 4, "programlang"], [21, 23, "misc"], [39, 41, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Um", "conjunto", "de", "programas", "Java", "utiliza", "o", "l\u00e9xico", "para", "trabalhar", "atrav\u00e9s", "das", "varia\u00e7\u00f5es", "dos", "textos", "biom\u00e9dicos", ",", "relacionando", "palavras", "pelas", "suas", "partes", "da", "fala", ",", "o", "que", "pode", "ser", "\u00fatil", "em", "pesquisas", "na", "web", "ou", "pesquisas", "atrav\u00e9s", "de", "um", "registo", "m\u00e9dico", "electr\u00f3nico", "."], "sentence-detokenized": "Um conjunto de programas Java utiliza o l\u00e9xico para trabalhar atrav\u00e9s das varia\u00e7\u00f5es dos textos biom\u00e9dicos, relacionando palavras pelas suas partes da fala, o que pode ser \u00fatil em pesquisas na web ou pesquisas atrav\u00e9s de um registo m\u00e9dico electr\u00f3nico.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 24], [25, 29], [30, 37], [38, 39], [40, 46], [47, 51], [52, 61], [62, 69], [70, 73], [74, 83], [84, 87], [88, 94], [95, 105], [105, 106], [107, 119], [120, 128], [129, 134], [135, 139], [140, 146], [147, 149], [150, 154], [154, 155], [156, 157], [158, 161], [162, 166], [167, 170], [171, 175], [176, 178], [179, 188], [189, 191], [192, 195], [196, 198], [199, 208], [209, 216], [217, 219], [220, 222], [223, 230], [231, 237], [238, 249], [249, 250]]}
{"doc_key": "ai-test-70", "ner": [[7, 7, "algorithm"], [9, 9, "algorithm"], [11, 11, "algorithm"], [13, 13, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Existem", "muitos", "algoritmos", "mais", "recentes", "tais", "como", "LPBoost", ",", "TotalBoost", ",", "BrownBoost", ",", "xgboost", ",", "MadaBoost", ",", "e", "outros", "."], "sentence-detokenized": "Existem muitos algoritmos mais recentes tais como LPBoost, TotalBoost, BrownBoost, xgboost, MadaBoost, e outros.", "token2charspan": [[0, 7], [8, 14], [15, 25], [26, 30], [31, 39], [40, 44], [45, 49], [50, 57], [57, 58], [59, 69], [69, 70], [71, 81], [81, 82], [83, 90], [90, 91], [92, 101], [101, 102], [103, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-test-71", "ner": [[7, 7, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Este", "\u00e9", "um", "exemplo", "de", "implementa\u00e7\u00e3o", "em", "Python", ":"], "sentence-detokenized": "Este \u00e9 um exemplo de implementa\u00e7\u00e3o em Python:", "token2charspan": [[0, 4], [5, 6], [7, 9], [10, 17], [18, 20], [21, 34], [35, 37], [38, 44], [44, 45]]}
{"doc_key": "ai-test-72", "ner": [[4, 4, "organisation"], [5, 5, "product"], [10, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 4, 4, "artifact", "made_by_company", false, false], [10, 13, 5, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "consola", "de", "jogos", "Mattel", "Intellivision", "ofereceu", "o", "m\u00f3dulo", "de", "S\u00edntese", "de", "Voz", "Intellivoice", "em", "1982", "."], "sentence-detokenized": "A consola de jogos Mattel Intellivision ofereceu o m\u00f3dulo de S\u00edntese de Voz Intellivoice em 1982.", "token2charspan": [[0, 1], [2, 9], [10, 12], [13, 18], [19, 25], [26, 39], [40, 48], [49, 50], [51, 57], [58, 60], [61, 68], [69, 71], [72, 75], [76, 88], [89, 91], [92, 96], [96, 97]]}
{"doc_key": "ai-test-73", "ner": [[3, 4, "task"], [8, 14, "task"], [17, 18, "field"], [20, 22, "task"], [26, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 14, 3, 4, "part-of", "", false, false], [17, 18, 3, 4, "part-of", "", false, false], [20, 22, 3, 4, "part-of", "", false, false], [26, 30, 20, 22, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Tamb\u00e9m", "trabalhou", "em", "tradu\u00e7\u00e3o", "autom\u00e1tica", ",", "tanto", "em", "MT", "baseada", "no", "conhecimento", "de", "alta", "precis\u00e3o", "como", "em", "aprendizagem", "autom\u00e1tica", "para", "tradu\u00e7\u00e3o", "autom\u00e1tica", "estat\u00edstica", "(", "tal", "como", "MT", "baseada", "em", "exemplos", "generalizados", ")", "."], "sentence-detokenized": "Tamb\u00e9m trabalhou em tradu\u00e7\u00e3o autom\u00e1tica, tanto em MT baseada no conhecimento de alta precis\u00e3o como em aprendizagem autom\u00e1tica para tradu\u00e7\u00e3o autom\u00e1tica estat\u00edstica (tal como MT baseada em exemplos generalizados).", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 28], [29, 39], [39, 40], [41, 46], [47, 49], [50, 52], [53, 60], [61, 63], [64, 76], [77, 79], [80, 84], [85, 93], [94, 98], [99, 101], [102, 114], [115, 125], [126, 130], [131, 139], [140, 150], [151, 162], [163, 164], [164, 167], [168, 172], [173, 175], [176, 183], [184, 186], [187, 195], [196, 209], [209, 210], [210, 211]]}
{"doc_key": "ai-test-74", "ner": [[0, 1, "misc"], [5, 5, "misc"], [23, 24, "algorithm"], [26, 28, "field"], [30, 32, "field"], [34, 34, "field"], [36, 38, "field"], [40, 40, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 23, 24, "general-affiliation", "", false, false], [0, 1, 26, 28, "general-affiliation", "", false, false], [0, 1, 30, 32, "general-affiliation", "", false, false], [0, 1, 34, 34, "general-affiliation", "", false, false], [0, 1, 36, 38, "general-affiliation", "", false, false], [0, 1, 40, 40, "general-affiliation", "", false, false], [5, 5, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Wolfram", "Mathematica", "(", "normalmente", "denominado", "Mathematica", ")", "\u00e9", "um", "sistema", "t\u00e9cnico", "moderno", "de", "computa\u00e7\u00e3o", "que", "abrange", "a", "maioria", "das", "\u00e1reas", "t\u00e9cnicas", "-", "incluindo", "redes", "neurais", ",", "aprendizagem", "de", "m\u00e1quinas", ",", "processamento", "de", "imagem", ",", "geometria", ",", "ci\u00eancia", "de", "dados", ",", "visualiza\u00e7\u00f5es", ",", "e", "outras", "."], "sentence-detokenized": "Wolfram Mathematica (normalmente denominado Mathematica) \u00e9 um sistema t\u00e9cnico moderno de computa\u00e7\u00e3o que abrange a maioria das \u00e1reas t\u00e9cnicas - incluindo redes neurais, aprendizagem de m\u00e1quinas, processamento de imagem, geometria, ci\u00eancia de dados, visualiza\u00e7\u00f5es, e outras.", "token2charspan": [[0, 7], [8, 19], [20, 21], [21, 32], [33, 43], [44, 55], [55, 56], [57, 58], [59, 61], [62, 69], [70, 77], [78, 85], [86, 88], [89, 99], [100, 103], [104, 111], [112, 113], [114, 121], [122, 125], [126, 131], [132, 140], [141, 142], [143, 152], [153, 158], [159, 166], [166, 167], [168, 180], [181, 183], [184, 192], [192, 193], [194, 207], [208, 210], [211, 217], [217, 218], [219, 228], [228, 229], [230, 237], [238, 240], [241, 246], [246, 247], [248, 261], [261, 262], [263, 264], [265, 271], [271, 272]]}
{"doc_key": "ai-test-75", "ner": [[2, 6, "product"], [10, 11, "researcher"], [20, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[20, 20, 2, 6, "type-of", "", false, false], [20, 20, 10, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["O", "primeiro", "rob\u00f4", "operado", "digitalmente", "e", "program\u00e1vel", "foi", "inventado", "por", "George", "Devol", "em", "1954", "e", "acabou", "por", "ser", "chamado", "de", "Unimate", "."], "sentence-detokenized": "O primeiro rob\u00f4 operado digitalmente e program\u00e1vel foi inventado por George Devol em 1954 e acabou por ser chamado de Unimate.", "token2charspan": [[0, 1], [2, 10], [11, 15], [16, 23], [24, 36], [37, 38], [39, 50], [51, 54], [55, 64], [65, 68], [69, 75], [76, 81], [82, 84], [85, 89], [90, 91], [92, 98], [99, 102], [103, 106], [107, 114], [115, 117], [118, 125], [125, 126]]}
{"doc_key": "ai-test-76", "ner": [[3, 3, "algorithm"], [5, 6, "algorithm"], [20, 22, "task"], [24, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 5, 6, "compare", "", false, false], [5, 6, 20, 22, "general-affiliation", "", false, false], [5, 6, 24, 26, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Tal", "como", "os", "DBNs", ",", "os", "DBMs", "podem", "aprender", "representa\u00e7\u00f5es", "internas", "complexas", "e", "abstractas", "da", "entrada", "em", "tarefas", "tais", "como", "reconhecimento", "de", "objectos", "ou", "reconhecimento", "de", "fala", ",", "usando", "dados", "limitados", "e", "rotulados", "para", "afinar", "as", "representa\u00e7\u00f5es", "constru\u00eddas", "usando", "um", "grande", "conjunto", "de", "dados", "de", "entrada", "sensoriais", "n\u00e3o", "rotulados", "."], "sentence-detokenized": "Tal como os DBNs, os DBMs podem aprender representa\u00e7\u00f5es internas complexas e abstractas da entrada em tarefas tais como reconhecimento de objectos ou reconhecimento de fala, usando dados limitados e rotulados para afinar as representa\u00e7\u00f5es constru\u00eddas usando um grande conjunto de dados de entrada sensoriais n\u00e3o rotulados.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 16], [16, 17], [18, 20], [21, 25], [26, 31], [32, 40], [41, 55], [56, 64], [65, 74], [75, 76], [77, 87], [88, 90], [91, 98], [99, 101], [102, 109], [110, 114], [115, 119], [120, 134], [135, 137], [138, 146], [147, 149], [150, 164], [165, 167], [168, 172], [172, 173], [174, 180], [181, 186], [187, 196], [197, 198], [199, 208], [209, 213], [214, 220], [221, 223], [224, 238], [239, 250], [251, 257], [258, 260], [261, 267], [268, 276], [277, 279], [280, 285], [286, 288], [289, 296], [297, 307], [308, 311], [312, 321], [321, 322]]}
{"doc_key": "ai-test-77", "ner": [[7, 12, "task"], [16, 16, "conference"], [18, 18, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 16, 7, 12, "topic", "", false, false], [18, 18, 7, 12, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "confer\u00eancias", "cient\u00edficas", "onde", "o", "trabalho", "de", "reconhecimento", "da", "actividade", "baseada", "na", "vis\u00e3o", "aparece", "frequentemente", "s\u00e3o", "ICCV", "e", "CVPR", "."], "sentence-detokenized": "As confer\u00eancias cient\u00edficas onde o trabalho de reconhecimento da actividade baseada na vis\u00e3o aparece frequentemente s\u00e3o ICCV e CVPR.", "token2charspan": [[0, 2], [3, 15], [16, 27], [28, 32], [33, 34], [35, 43], [44, 46], [47, 61], [62, 64], [65, 75], [76, 83], [84, 86], [87, 92], [93, 100], [101, 115], [116, 119], [120, 124], [125, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-test-78", "ner": [[1, 1, "field"], [6, 6, "algorithm"], [8, 8, "algorithm"], [17, 18, "metrics"], [21, 23, "metrics"], [25, 25, "metrics"], [38, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[6, 6, 1, 1, "part-of", "", false, false], [6, 6, 17, 18, "related-to", "finds", false, false], [6, 6, 21, 23, "related-to", "finds", false, false], [6, 6, 38, 39, "related-to", "", false, false], [8, 8, 6, 6, "named", "", false, false], [25, 25, 21, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Em", "estat\u00edstica", ",", "um", "algoritmo", "de", "expectativa-maximiza\u00e7\u00e3o", "(", "EM", ")", "\u00e9", "um", "m\u00e9todo", "iterativo", "para", "encontrar", "a", "m\u00e1xima", "probabilidade", "ou", "estimativas", "m\u00e1ximas", "a", "posteriori", "(", "MAP", ")", "de", "par\u00e2metros", "em", "modelos", "estat\u00edsticos", ",", "onde", "o", "modelo", "depende", "de", "vari\u00e1veis", "latentes", "n\u00e3o", "observadas", "."], "sentence-detokenized": "Em estat\u00edstica, um algoritmo de expectativa-maximiza\u00e7\u00e3o (EM) \u00e9 um m\u00e9todo iterativo para encontrar a m\u00e1xima probabilidade ou estimativas m\u00e1ximas a posteriori (MAP) de par\u00e2metros em modelos estat\u00edsticos, onde o modelo depende de vari\u00e1veis latentes n\u00e3o observadas.", "token2charspan": [[0, 2], [3, 14], [14, 15], [16, 18], [19, 28], [29, 31], [32, 55], [56, 57], [57, 59], [59, 60], [61, 62], [63, 65], [66, 72], [73, 82], [83, 87], [88, 97], [98, 99], [100, 106], [107, 120], [121, 123], [124, 135], [136, 143], [144, 145], [146, 156], [157, 158], [158, 161], [161, 162], [163, 165], [166, 176], [177, 179], [180, 187], [188, 200], [200, 201], [202, 206], [207, 208], [209, 215], [216, 223], [224, 226], [227, 236], [237, 245], [246, 249], [250, 260], [260, 261]]}
{"doc_key": "ai-test-79", "ner": [[10, 12, "metrics"], [14, 14, "metrics"], [19, 21, "metrics"], [23, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 14, 10, 12, "named", "", false, false], [23, 23, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Da", "mesma", "forma", ",", "os", "investigadores", "relatam", "por", "vezes", "a", "Taxa", "Positiva", "FALSE", "(", "FPR", ")", "bem", "como", "a", "Taxa", "Negativa", "FALSE", "(", "FNR", ")", "."], "sentence-detokenized": "Da mesma forma, os investigadores relatam por vezes a Taxa Positiva FALSE (FPR) bem como a Taxa Negativa FALSE (FNR).", "token2charspan": [[0, 2], [3, 8], [9, 14], [14, 15], [16, 18], [19, 33], [34, 41], [42, 45], [46, 51], [52, 53], [54, 58], [59, 67], [68, 73], [74, 75], [75, 78], [78, 79], [80, 83], [84, 88], [89, 90], [91, 95], [96, 104], [105, 110], [111, 112], [112, 115], [115, 116], [116, 117]]}
{"doc_key": "ai-test-80", "ner": [[5, 6, "metrics"], [9, 9, "field"], [12, 14, "metrics"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 5, 6, "usage", "", false, false], [17, 18, 12, 14, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["O", "conceito", "\u00e9", "semelhante", "\u00e0", "rela\u00e7\u00e3o", "sinal/ru\u00eddo", "utilizada", "nas", "ci\u00eancias", "e", "\u00e0", "matriz", "de", "confus\u00e3o", "utilizada", "na", "intelig\u00eancia", "artificial", "."], "sentence-detokenized": "O conceito \u00e9 semelhante \u00e0 rela\u00e7\u00e3o sinal/ru\u00eddo utilizada nas ci\u00eancias e \u00e0 matriz de confus\u00e3o utilizada na intelig\u00eancia artificial.", "token2charspan": [[0, 1], [2, 10], [11, 12], [13, 23], [24, 25], [26, 33], [34, 45], [46, 55], [56, 59], [60, 68], [69, 70], [71, 72], [73, 79], [80, 82], [83, 91], [92, 101], [102, 104], [105, 117], [118, 128], [128, 129]]}
{"doc_key": "ai-test-81", "ner": [[6, 7, "field"], [14, 15, "researcher"], [21, 22, "researcher"], [24, 25, "researcher"], [33, 38, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 7, 14, 15, "general-affiliation", "", false, false], [6, 7, 21, 22, "general-affiliation", "", false, false], [6, 7, 24, 25, "general-affiliation", "", false, false], [33, 38, 6, 7, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["O", "C\u00f3digo", "de", "\u00c9tica", "para", "o", "Aumento", "Humano", ",", "que", "foi", "originalmente", "introduzido", "por", "Steve", "Mann", "em", "2004", "e", "aperfei\u00e7oado", "com", "Ray", "Kurzweil", "e", "Marvin", "Minsky", "em", "2013", ",", "foi", "finalmente", "ratificado", "na", "confer\u00eancia", "sobre", "Realidade", "Virtual", "de", "Toronto", "em", "25", "de", "Junho", "de", "2017", "."], "sentence-detokenized": "O C\u00f3digo de \u00c9tica para o Aumento Humano, que foi originalmente introduzido por Steve Mann em 2004 e aperfei\u00e7oado com Ray Kurzweil e Marvin Minsky em 2013, foi finalmente ratificado na confer\u00eancia sobre Realidade Virtual de Toronto em 25 de Junho de 2017.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 17], [18, 22], [23, 24], [25, 32], [33, 39], [39, 40], [41, 44], [45, 48], [49, 62], [63, 74], [75, 78], [79, 84], [85, 89], [90, 92], [93, 97], [98, 99], [100, 112], [113, 116], [117, 120], [121, 129], [130, 131], [132, 138], [139, 145], [146, 148], [149, 153], [153, 154], [155, 158], [159, 169], [170, 180], [181, 183], [184, 195], [196, 201], [202, 211], [212, 219], [220, 222], [223, 230], [231, 233], [234, 236], [237, 239], [240, 245], [246, 248], [249, 253], [253, 254]]}
{"doc_key": "ai-test-82", "ner": [[3, 5, "person"], [11, 14, "organisation"], [20, 21, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 11, 14, "role", "directed_for", false, false], [3, 5, 20, 21, "role", "collaborator", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Em", "1913", ",", "Walter", "R.", "Booth", "dirigiu", "10", "filmes", "para", "o", "Kinoplastikon", "do", "Reino", "Unido", ",", "presumivelmente", "em", "colabora\u00e7\u00e3o", "com", "Cecil", "Hepworth", "."], "sentence-detokenized": "Em 1913, Walter R. Booth dirigiu 10 filmes para o Kinoplastikon do Reino Unido, presumivelmente em colabora\u00e7\u00e3o com Cecil Hepworth.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 18], [19, 24], [25, 32], [33, 35], [36, 42], [43, 47], [48, 49], [50, 63], [64, 66], [67, 72], [73, 78], [78, 79], [80, 95], [96, 98], [99, 110], [111, 114], [115, 120], [121, 129], [129, 130]]}
{"doc_key": "ai-test-83", "ner": [[11, 11, "location"], [12, 13, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 13, 11, 11, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Apresentaram", "o", "seu", "novo", "rob\u00f4", "em", "1961", "numa", "feira", "comercial", "no", "Chicago's", "Cow", "Palace", "."], "sentence-detokenized": "Apresentaram o seu novo rob\u00f4 em 1961 numa feira comercial no Chicago's Cow Palace.", "token2charspan": [[0, 12], [13, 14], [15, 18], [19, 23], [24, 28], [29, 31], [32, 36], [37, 41], [42, 47], [48, 57], [58, 60], [61, 70], [71, 74], [75, 81], [81, 82]]}
{"doc_key": "ai-test-84", "ner": [[3, 3, "product"], [8, 10, "task"], [14, 17, "field"], [20, 21, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 8, 10, "usage", "", false, false], [3, 3, 14, 17, "usage", "", false, false], [3, 3, 20, 21, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Enquanto", "algumas", "aplica\u00e7\u00f5es", "chatbot", "utilizam", "extensos", "processos", "de", "classifica\u00e7\u00e3o", "de", "palavras", ",", "processadores", "de", "processamento", "de", "linguagem", "natural", ",", "e", "intelig\u00eancia", "artificial", "sofisticada", ",", "outras", "simplesmente", "procuram", "palavras-chave", "gerais", "e", "geram", "respostas", "utilizando", "frases", "comuns", "obtidas", "de", "uma", "biblioteca", "ou", "base", "de", "dados", "associada", "."], "sentence-detokenized": "Enquanto algumas aplica\u00e7\u00f5es chatbot utilizam extensos processos de classifica\u00e7\u00e3o de palavras, processadores de processamento de linguagem natural, e intelig\u00eancia artificial sofisticada, outras simplesmente procuram palavras-chave gerais e geram respostas utilizando frases comuns obtidas de uma biblioteca ou base de dados associada.", "token2charspan": [[0, 8], [9, 16], [17, 27], [28, 35], [36, 44], [45, 53], [54, 63], [64, 66], [67, 80], [81, 83], [84, 92], [92, 93], [94, 107], [108, 110], [111, 124], [125, 127], [128, 137], [138, 145], [145, 146], [147, 148], [149, 161], [162, 172], [173, 184], [184, 185], [186, 192], [193, 205], [206, 214], [215, 229], [230, 236], [237, 238], [239, 244], [245, 254], [255, 265], [266, 272], [273, 279], [280, 287], [288, 290], [291, 294], [295, 305], [306, 308], [309, 313], [314, 316], [317, 322], [323, 332], [332, 333]]}
{"doc_key": "ai-test-85", "ner": [[2, 2, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["O", "modelo", "WaveNet", "proposto", "em", "2016", "atinge", "um", "grande", "desempenho", "na", "qualidade", "da", "fala", "."], "sentence-detokenized": "O modelo WaveNet proposto em 2016 atinge um grande desempenho na qualidade da fala.", "token2charspan": [[0, 1], [2, 8], [9, 16], [17, 25], [26, 28], [29, 33], [34, 40], [41, 43], [44, 50], [51, 61], [62, 64], [65, 74], [75, 77], [78, 82], [82, 83]]}
{"doc_key": "ai-test-86", "ner": [[5, 5, "product"], [8, 10, "misc"], [12, 16, "misc"], [18, 19, "misc"], [21, 24, "misc"], [26, 28, "organisation"], [30, 30, "organisation"], [32, 37, "organisation"], [39, 39, "organisation"], [41, 44, "organisation"], [46, 47, "organisation"], [49, 51, "organisation"], [53, 55, "organisation"], [58, 58, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[5, 5, 8, 10, "general-affiliation", "", false, false], [5, 5, 12, 16, "general-affiliation", "", false, false], [5, 5, 18, 19, "general-affiliation", "", false, false], [5, 5, 21, 24, "general-affiliation", "", false, false], [26, 28, 5, 5, "usage", "", false, false], [30, 30, 5, 5, "usage", "", false, false], [32, 37, 5, 5, "usage", "", false, false], [39, 39, 5, 5, "usage", "", false, false], [41, 44, 5, 5, "usage", "", false, false], [46, 47, 5, 5, "usage", "", false, false], [49, 51, 5, 5, "usage", "", false, false], [53, 55, 5, 5, "usage", "", false, false], [58, 58, 5, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Organiza\u00e7\u00f5es", "conhecidas", "pela", "utiliza\u00e7\u00e3o", "da", "ALE", "para", "a", "gest\u00e3o", "de", "emerg\u00eancias", ",", "ajuda", "em", "caso", "de", "cat\u00e1strofe", ",", "comunica\u00e7\u00e3o", "ordin\u00e1ria", "ou", "resposta", "a", "situa\u00e7\u00f5es", "extraordin\u00e1rias", ":", "Cruz", "Vermelha", "Americana", ",", "FEMA", ",", "Equipas", "de", "Assist\u00eancia", "M\u00e9dica", "em", "Cat\u00e1strofes", ",", "NATO", ",", "Bureau", "Federal", "de", "Investiga\u00e7\u00e3o", ",", "Na\u00e7\u00f5es", "Unidas", ",", "AT", "&", "T", ",", "Patrulha", "A\u00e9rea", "Civil", ",", "(", "ARES", ")", "."], "sentence-detokenized": "Organiza\u00e7\u00f5es conhecidas pela utiliza\u00e7\u00e3o da ALE para a gest\u00e3o de emerg\u00eancias, ajuda em caso de cat\u00e1strofe, comunica\u00e7\u00e3o ordin\u00e1ria ou resposta a situa\u00e7\u00f5es extraordin\u00e1rias: Cruz Vermelha Americana, FEMA, Equipas de Assist\u00eancia M\u00e9dica em Cat\u00e1strofes, NATO, Bureau Federal de Investiga\u00e7\u00e3o, Na\u00e7\u00f5es Unidas, AT & T, Patrulha A\u00e9rea Civil, (ARES).", "token2charspan": [[0, 12], [13, 23], [24, 28], [29, 39], [40, 42], [43, 46], [47, 51], [52, 53], [54, 60], [61, 63], [64, 75], [75, 76], [77, 82], [83, 85], [86, 90], [91, 93], [94, 104], [104, 105], [106, 117], [118, 127], [128, 130], [131, 139], [140, 141], [142, 151], [152, 167], [167, 168], [169, 173], [174, 182], [183, 192], [192, 193], [194, 198], [198, 199], [200, 207], [208, 210], [211, 222], [223, 229], [230, 232], [233, 244], [244, 245], [246, 250], [250, 251], [252, 258], [259, 266], [267, 269], [270, 282], [282, 283], [284, 290], [291, 297], [297, 298], [299, 301], [302, 303], [304, 305], [305, 306], [307, 315], [316, 321], [322, 327], [327, 328], [329, 330], [330, 334], [334, 335], [335, 336]]}
{"doc_key": "ai-test-87", "ner": [[3, 4, "algorithm"], [15, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Aqui", ",", "o", "delta", "Kronecker", "\u00e9", "utilizado", "para", "simplificar", "(", "cf.", "a", "derivada", "de", "uma", "fun\u00e7\u00e3o", "sigm\u00f3ide", ",", "sendo", "expressa", "atrav\u00e9s", "da", "pr\u00f3pria", "fun\u00e7\u00e3o", ")", "."], "sentence-detokenized": "Aqui, o delta Kronecker \u00e9 utilizado para simplificar (cf. a derivada de uma fun\u00e7\u00e3o sigm\u00f3ide, sendo expressa atrav\u00e9s da pr\u00f3pria fun\u00e7\u00e3o).", "token2charspan": [[0, 4], [4, 5], [6, 7], [8, 13], [14, 23], [24, 25], [26, 35], [36, 40], [41, 52], [53, 54], [54, 57], [58, 59], [60, 68], [69, 71], [72, 75], [76, 82], [83, 91], [91, 92], [93, 98], [99, 107], [108, 115], [116, 118], [119, 126], [127, 133], [133, 134], [134, 135]]}
{"doc_key": "ai-test-88", "ner": [[11, 12, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "teoria", "baseia-se", "em", "fundamentos", "filos\u00f3ficos", ",", "e", "foi", "fundada", "por", "Ray", "Solomonoff", "por", "volta", "de", "1960", ".", "Samuel", "Rathmanner", "e", "Marcus", "Hutter", "."], "sentence-detokenized": "A teoria baseia-se em fundamentos filos\u00f3ficos, e foi fundada por Ray Solomonoff por volta de 1960. Samuel Rathmanner e Marcus Hutter.", "token2charspan": [[0, 1], [2, 8], [9, 18], [19, 21], [22, 33], [34, 45], [45, 46], [47, 48], [49, 52], [53, 60], [61, 64], [65, 68], [69, 79], [80, 83], [84, 89], [90, 92], [93, 97], [97, 98], [99, 105], [106, 116], [117, 118], [119, 125], [126, 132], [132, 133]]}
{"doc_key": "ai-test-89", "ner": [[0, 0, "product"], [12, 13, "misc"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 12, 13, "type-of", "", false, false], [0, 0, 16, 17, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["WordNet", ",", "uma", "base", "de", "dados", "livremente", "dispon\u00edvel", "originalmente", "concebida", "como", "uma", "rede", "sem\u00e2ntica", "baseada", "em", "princ\u00edpios", "psicolingu\u00edsticos", ",", "foi", "expandida", "atrav\u00e9s", "da", "adi\u00e7\u00e3o", "de", "defini\u00e7\u00f5es", "e", "\u00e9", "agora", "tamb\u00e9m", "vista", "como", "um", "dicion\u00e1rio", "."], "sentence-detokenized": "WordNet, uma base de dados livremente dispon\u00edvel originalmente concebida como uma rede sem\u00e2ntica baseada em princ\u00edpios psicolingu\u00edsticos, foi expandida atrav\u00e9s da adi\u00e7\u00e3o de defini\u00e7\u00f5es e \u00e9 agora tamb\u00e9m vista como um dicion\u00e1rio.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 17], [18, 20], [21, 26], [27, 37], [38, 48], [49, 62], [63, 72], [73, 77], [78, 81], [82, 86], [87, 96], [97, 104], [105, 107], [108, 118], [119, 136], [136, 137], [138, 141], [142, 151], [152, 159], [160, 162], [163, 169], [170, 172], [173, 183], [184, 185], [186, 187], [188, 193], [194, 200], [201, 206], [207, 211], [212, 214], [215, 225], [225, 226]]}
{"doc_key": "ai-test-90", "ner": [[6, 7, "field"], [17, 20, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 20, 6, 7, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Avan\u00e7os", "no", "campo", "da", "investiga\u00e7\u00e3o", "de", "imagem", "computacional", "s\u00e3o", "apresentados", "em", "v\u00e1rios", "locais", ",", "incluindo", "publica\u00e7\u00f5es", "do", "SIGGRAPH", "e", "do", "SIGGRAPH", "."], "sentence-detokenized": "Avan\u00e7os no campo da investiga\u00e7\u00e3o de imagem computacional s\u00e3o apresentados em v\u00e1rios locais, incluindo publica\u00e7\u00f5es do SIGGRAPH e do SIGGRAPH.", "token2charspan": [[0, 7], [8, 10], [11, 16], [17, 19], [20, 32], [33, 35], [36, 42], [43, 56], [57, 60], [61, 73], [74, 76], [77, 83], [84, 90], [90, 91], [92, 101], [102, 113], [114, 116], [117, 125], [126, 127], [128, 130], [131, 139], [139, 140]]}
{"doc_key": "ai-test-91", "ner": [[0, 1, "task"], [10, 11, "task"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 0, 1, "part-of", "", false, false], [13, 14, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "classifica\u00e7\u00e3o", "pode", "ser", "pensada", "como", "dois", "problemas", "distintos", "-", "classifica\u00e7\u00e3o", "bin\u00e1ria", "e", "classifica\u00e7\u00e3o", "multiclasse", "."], "sentence-detokenized": "A classifica\u00e7\u00e3o pode ser pensada como dois problemas distintos - classifica\u00e7\u00e3o bin\u00e1ria e classifica\u00e7\u00e3o multiclasse.", "token2charspan": [[0, 1], [2, 15], [16, 20], [21, 24], [25, 32], [33, 37], [38, 42], [43, 52], [53, 62], [63, 64], [65, 78], [79, 86], [87, 88], [89, 102], [103, 114], [114, 115]]}
{"doc_key": "ai-test-92", "ner": [[13, 14, "algorithm"], [19, 21, "algorithm"], [23, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 21, 13, 14, "type-of", "", false, false], [23, 23, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Os", "descobridores", "avan\u00e7ados", "de", "genes", "tanto", "para", "genomas", "procari\u00f3ticos", "como", "eucari\u00f3ticos", "utilizam", "tipicamente", "modelos", "probabil\u00edsticos", "complexos", ",", "tais", "como", "modelos", "Markov", "escondidos", "(", "HMMs", ")", "para", "combinar", "informa\u00e7\u00e3o", "de", "uma", "variedade", "de", "diferentes", "medi\u00e7\u00f5es", "de", "sinal", "e", "conte\u00fado", "."], "sentence-detokenized": "Os descobridores avan\u00e7ados de genes tanto para genomas procari\u00f3ticos como eucari\u00f3ticos utilizam tipicamente modelos probabil\u00edsticos complexos, tais como modelos Markov escondidos (HMMs) para combinar informa\u00e7\u00e3o de uma variedade de diferentes medi\u00e7\u00f5es de sinal e conte\u00fado.", "token2charspan": [[0, 2], [3, 16], [17, 26], [27, 29], [30, 35], [36, 41], [42, 46], [47, 54], [55, 68], [69, 73], [74, 86], [87, 95], [96, 107], [108, 115], [116, 131], [132, 141], [141, 142], [143, 147], [148, 152], [153, 160], [161, 167], [168, 178], [179, 180], [180, 184], [184, 185], [186, 190], [191, 199], [200, 210], [211, 213], [214, 217], [218, 227], [228, 230], [231, 241], [242, 250], [251, 253], [254, 259], [260, 261], [262, 270], [270, 271]]}
{"doc_key": "ai-test-93", "ner": [[0, 1, "misc"], [4, 4, "misc"], [10, 11, "field"], [14, 15, "algorithm"], [18, 20, "algorithm"], [22, 22, "algorithm"], [32, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 10, 11, "part-of", "", false, false], [0, 1, 14, 15, "usage", "", false, false], [4, 4, 0, 1, "named", "", false, false], [18, 20, 0, 1, "origin", "", true, false], [22, 22, 18, 20, "named", "", false, false], [32, 33, 0, 1, "origin", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["A", "neuroevolu\u00e7\u00e3o", ",", "ou", "neuro-evolu\u00e7\u00e3o", ",", "\u00e9", "uma", "forma", "de", "intelig\u00eancia", "artificial", "que", "utiliza", "algoritmos", "evolutivos", "para", "gerar", "redes", "neurais", "artificiais", "(", "ANN", ")", ",", "par\u00e2metros", ",", "topologia", "e", "regras", ".", "e", "rob\u00f3tica", "evolutiva", "."], "sentence-detokenized": "A neuroevolu\u00e7\u00e3o, ou neuro-evolu\u00e7\u00e3o, \u00e9 uma forma de intelig\u00eancia artificial que utiliza algoritmos evolutivos para gerar redes neurais artificiais (ANN), par\u00e2metros, topologia e regras. e rob\u00f3tica evolutiva.", "token2charspan": [[0, 1], [2, 15], [15, 16], [17, 19], [20, 34], [34, 35], [36, 37], [38, 41], [42, 47], [48, 50], [51, 63], [64, 74], [75, 78], [79, 86], [87, 97], [98, 108], [109, 113], [114, 119], [120, 125], [126, 133], [134, 145], [146, 147], [147, 150], [150, 151], [151, 152], [153, 163], [163, 164], [165, 174], [175, 176], [177, 183], [183, 184], [185, 186], [187, 195], [196, 205], [205, 206]]}
{"doc_key": "ai-test-94", "ner": [[2, 3, "organisation"], [10, 10, "metrics"], [11, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 2, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Desde", "que", "a", "IBM", "prop\u00f4s", "e", "realizou", "o", "sistema", "de", "BLEU", "Papineni", "et", "al", "."], "sentence-detokenized": "Desde que a IBM prop\u00f4s e realizou o sistema de BLEU Papineni et al.", "token2charspan": [[0, 5], [6, 9], [10, 11], [12, 15], [16, 22], [23, 24], [25, 33], [34, 35], [36, 43], [44, 46], [47, 51], [52, 60], [61, 63], [64, 66], [66, 67]]}
{"doc_key": "ai-test-95", "ner": [[9, 15, "conference"], [17, 17, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 17, 9, 15, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Em", "2009", ",", "peritos", "participaram", "numa", "confer\u00eancia", "organizada", "pela", "Associa\u00e7\u00e3o", "para", "o", "Progresso", "da", "Intelig\u00eancia", "Artificial", "(", "AAAI", ")", "para", "discutir", "se", "os", "computadores", "e", "rob\u00f4s", "poderiam", "adquirir", "alguma", "autonomia", ",", "e", "em", "que", "medida", "estas", "capacidades", "poderiam", "constituir", "uma", "amea\u00e7a", "ou", "perigo", "."], "sentence-detokenized": "Em 2009, peritos participaram numa confer\u00eancia organizada pela Associa\u00e7\u00e3o para o Progresso da Intelig\u00eancia Artificial (AAAI) para discutir se os computadores e rob\u00f4s poderiam adquirir alguma autonomia, e em que medida estas capacidades poderiam constituir uma amea\u00e7a ou perigo.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 29], [30, 34], [35, 46], [47, 57], [58, 62], [63, 73], [74, 78], [79, 80], [81, 90], [91, 93], [94, 106], [107, 117], [118, 119], [119, 123], [123, 124], [125, 129], [130, 138], [139, 141], [142, 144], [145, 157], [158, 159], [160, 165], [166, 174], [175, 183], [184, 190], [191, 200], [200, 201], [202, 203], [204, 206], [207, 210], [211, 217], [218, 223], [224, 235], [236, 244], [245, 255], [256, 259], [260, 266], [267, 269], [270, 276], [276, 277]]}
{"doc_key": "ai-test-96", "ner": [[28, 30, "metrics"], [32, 33, "researcher"], [35, 36, "researcher"], [38, 41, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[38, 41, 28, 30, "topic", "", false, false], [38, 41, 32, 33, "artifact", "", false, false], [38, 41, 35, 36, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Depois", "de", "impulsionado", ",", "um", "classificador", "constru\u00eddo", "a", "partir", "de", "200", "caracter\u00edsticas", "poderia", "produzir", "uma", "taxa", "de", "detec\u00e7\u00e3o", "de", "95", "%", "sob", "um", "^", "{", "-5", "}", "/", "taxa", "positiva", "FALSA", "matem\u00e1tica", ".P.", "Viola", ",", "M.", "Jones", ",", "Robust", "Real-time", "Object", "Detection", ",", "2001", "."], "sentence-detokenized": "Depois de impulsionado, um classificador constru\u00eddo a partir de 200 caracter\u00edsticas poderia produzir uma taxa de detec\u00e7\u00e3o de 95% sob um ^ {-5} / taxa positiva FALSA matem\u00e1tica .P. Viola, M. Jones, Robust Real-time Object Detection, 2001.", "token2charspan": [[0, 6], [7, 9], [10, 22], [22, 23], [24, 26], [27, 40], [41, 51], [52, 53], [54, 60], [61, 63], [64, 67], [68, 83], [84, 91], [92, 100], [101, 104], [105, 109], [110, 112], [113, 121], [122, 124], [125, 127], [127, 128], [129, 132], [133, 135], [136, 137], [138, 139], [139, 141], [141, 142], [143, 144], [145, 149], [150, 158], [159, 164], [165, 175], [176, 179], [180, 185], [185, 186], [187, 189], [190, 195], [195, 196], [197, 203], [204, 213], [214, 220], [221, 230], [230, 231], [232, 236], [236, 237]]}
{"doc_key": "ai-test-97", "ner": [[6, 6, "programlang"], [9, 10, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["O", "website", "era", "originalmente", "baseado", "em", "Perl", ",", "mas", "o", "IMDb", "j\u00e1", "n\u00e3o", "revela", "que", "software", "utiliza", "por", "raz\u00f5es", "de", "seguran\u00e7a", "."], "sentence-detokenized": "O website era originalmente baseado em Perl, mas o IMDb j\u00e1 n\u00e3o revela que software utiliza por raz\u00f5es de seguran\u00e7a.", "token2charspan": [[0, 1], [2, 9], [10, 13], [14, 27], [28, 35], [36, 38], [39, 43], [43, 44], [45, 48], [49, 50], [51, 55], [56, 58], [59, 62], [63, 69], [70, 73], [74, 82], [83, 90], [91, 94], [95, 101], [102, 104], [105, 114], [114, 115]]}
{"doc_key": "ai-test-98", "ner": [[5, 6, "researcher"], [8, 9, "researcher"], [11, 12, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["O", "arranque", "foi", "fundado", "por", "Demis", "Hassabis", ",", "Shane", "Legg", "e", "Mustafa", "Suleyman", "em", "2010", "."], "sentence-detokenized": "O arranque foi fundado por Demis Hassabis, Shane Legg e Mustafa Suleyman em 2010.", "token2charspan": [[0, 1], [2, 10], [11, 14], [15, 22], [23, 26], [27, 32], [33, 41], [41, 42], [43, 48], [49, 53], [54, 55], [56, 63], [64, 72], [73, 75], [76, 80], [80, 81]]}
{"doc_key": "ai-test-99", "ner": [[1, 3, "misc"], [9, 11, "metrics"], [26, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 11, 1, 3, "type-of", "", false, false], [26, 27, 1, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Duas", "fun\u00e7\u00f5es", "de", "perda", "muito", "frequentemente", "utilizadas", "s\u00e3o", "o", "erro", "quadr\u00e1tico", "m\u00e9dio", ",", "matem\u00e1tica", "(", "a", ")", "=", "a", "^", "2", "/", "matem\u00e1tica", ",", "e", "a", "perda", "absoluta", ",", "matem\u00e1tica", "(", "a", ")", "=", "|", "a", "|", "a", "|", "/", "matem\u00e1tica", "."], "sentence-detokenized": "Duas fun\u00e7\u00f5es de perda muito frequentemente utilizadas s\u00e3o o erro quadr\u00e1tico m\u00e9dio, matem\u00e1tica (a) = a ^ 2 / matem\u00e1tica, e a perda absoluta, matem\u00e1tica (a) = | a | a | / matem\u00e1tica.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 21], [22, 27], [28, 42], [43, 53], [54, 57], [58, 59], [60, 64], [65, 75], [76, 81], [81, 82], [83, 93], [94, 95], [95, 96], [96, 97], [98, 99], [100, 101], [102, 103], [104, 105], [106, 107], [108, 118], [118, 119], [120, 121], [122, 123], [124, 129], [130, 138], [138, 139], [140, 150], [151, 152], [152, 153], [153, 154], [155, 156], [157, 158], [159, 160], [161, 162], [163, 164], [165, 166], [167, 168], [169, 179], [179, 180]]}
{"doc_key": "ai-test-100", "ner": [[1, 5, "algorithm"], [15, 18, "algorithm"], [20, 20, "algorithm"], [24, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 5, 15, 18, "type-of", "example_of", false, false], [15, 18, 24, 26, "related-to", "", false, false], [20, 20, 15, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "m\u00e1quina", "vectorial", "de", "suporte", "de", "margens", "macias", "descrita", "acima", "\u00e9", "um", "exemplo", "de", "uma", "minimiza\u00e7\u00e3o", "de", "risco", "emp\u00edrico", "(", "ERM", ")", "para", "a", "perda", "da", "dobradi\u00e7a", "."], "sentence-detokenized": "A m\u00e1quina vectorial de suporte de margens macias descrita acima \u00e9 um exemplo de uma minimiza\u00e7\u00e3o de risco emp\u00edrico (ERM) para a perda da dobradi\u00e7a.", "token2charspan": [[0, 1], [2, 9], [10, 19], [20, 22], [23, 30], [31, 33], [34, 41], [42, 48], [49, 57], [58, 63], [64, 65], [66, 68], [69, 76], [77, 79], [80, 83], [84, 95], [96, 98], [99, 104], [105, 113], [114, 115], [115, 118], [118, 119], [120, 124], [125, 126], [127, 132], [133, 135], [136, 145], [145, 146]]}
{"doc_key": "ai-test-101", "ner": [[2, 5, "field"], [7, 7, "task"], [9, 11, "task"], [21, 22, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 11, 2, 5, "origin", "", false, false], [9, 11, 7, 7, "type-of", "", false, false], [21, 22, 9, 11, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Uma", "abordagem", "profunda", "baseada", "na", "aprendizagem", "da", "MT", ",", "tradu\u00e7\u00e3o", "autom\u00e1tica", "neural", "tem", "feito", "r\u00e1pidos", "progressos", "nos", "\u00faltimos", "anos", ",", "e", "a", "Google", "anunciou", "que", "os", "seus", "servi\u00e7os", "de", "tradu\u00e7\u00e3o", "est\u00e3o", "agora", "a", "utilizar", "esta", "tecnologia", "em", "vez", "dos", "seus", "m\u00e9todos", "estat\u00edsticos", "anteriores", "."], "sentence-detokenized": "Uma abordagem profunda baseada na aprendizagem da MT, tradu\u00e7\u00e3o autom\u00e1tica neural tem feito r\u00e1pidos progressos nos \u00faltimos anos, e a Google anunciou que os seus servi\u00e7os de tradu\u00e7\u00e3o est\u00e3o agora a utilizar esta tecnologia em vez dos seus m\u00e9todos estat\u00edsticos anteriores.", "token2charspan": [[0, 3], [4, 13], [14, 22], [23, 30], [31, 33], [34, 46], [47, 49], [50, 52], [52, 53], [54, 62], [63, 73], [74, 80], [81, 84], [85, 90], [91, 98], [99, 109], [110, 113], [114, 121], [122, 126], [126, 127], [128, 129], [130, 131], [132, 138], [139, 147], [148, 151], [152, 154], [155, 159], [160, 168], [169, 171], [172, 180], [181, 186], [187, 192], [193, 194], [195, 203], [204, 208], [209, 219], [220, 222], [223, 226], [227, 230], [231, 235], [236, 243], [244, 256], [257, 267], [267, 268]]}
{"doc_key": "ai-test-102", "ner": [[17, 17, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Isto", "tende", "a", "produzir", "ganhos", "de", "desempenho", "muito", "grandes", "quando", "se", "trabalha", "com", "grandes", "corpora", "como", "o", "WordNet", "."], "sentence-detokenized": "Isto tende a produzir ganhos de desempenho muito grandes quando se trabalha com grandes corpora como o WordNet.", "token2charspan": [[0, 4], [5, 10], [11, 12], [13, 21], [22, 28], [29, 31], [32, 42], [43, 48], [49, 56], [57, 63], [64, 66], [67, 75], [76, 79], [80, 87], [88, 95], [96, 100], [101, 102], [103, 110], [110, 111]]}
{"doc_key": "ai-test-103", "ner": [[0, 2, "task"], [6, 6, "field"], [20, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 20, 23, "part-of", "", false, false], [20, 23, 6, 6, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "detec\u00e7\u00e3o", "facial", "\u00e9", "utilizada", "em", "biometria", ",", "muitas", "vezes", "como", "parte", "de", "(", "ou", "em", "conjunto", "com", ")", "um", "sistema", "de", "reconhecimento", "facial", "."], "sentence-detokenized": "A detec\u00e7\u00e3o facial \u00e9 utilizada em biometria, muitas vezes como parte de (ou em conjunto com) um sistema de reconhecimento facial.", "token2charspan": [[0, 1], [2, 10], [11, 17], [18, 19], [20, 29], [30, 32], [33, 42], [42, 43], [44, 50], [51, 56], [57, 61], [62, 67], [68, 70], [71, 72], [72, 74], [75, 77], [78, 86], [87, 90], [90, 91], [92, 94], [95, 102], [103, 105], [106, 120], [121, 127], [127, 128]]}
{"doc_key": "ai-test-104", "ner": [[2, 5, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["treinados", "por", "estimativa", "de", "m\u00e1xima", "verosimilhan\u00e7a", "."], "sentence-detokenized": "treinados por estimativa de m\u00e1xima verosimilhan\u00e7a.", "token2charspan": [[0, 9], [10, 13], [14, 24], [25, 27], [28, 34], [35, 49], [49, 50]]}
{"doc_key": "ai-test-105", "ner": [[2, 2, "country"], [4, 8, "organisation"], [12, 12, "location"], [14, 14, "country"], [16, 19, "organisation"], [21, 21, "country"], [28, 28, "organisation"], [33, 36, "organisation"], [38, 38, "country"], [49, 53, "organisation"], [55, 55, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[4, 8, 12, 12, "physical", "", false, false], [12, 12, 14, 14, "physical", "", false, false], [16, 19, 21, 21, "physical", "", false, false], [33, 36, 38, 38, "physical", "", false, false], [49, 53, 55, 55, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Ltd.", "na", "Tail\u00e2ndia", ";", "Komatsu", "(", "Shanghai", ")", "Ltd.", "em", "1996", "em", "Shanghai", ",", "China", ";", "Industrial", "Power", "Alliance", "Ltd.", "no", "Jap\u00e3o", ",", "uma", "joint", "venture", "com", "a", "Cummins", ",", "em", "1998", ";", "L", "&", "T-Komatsu", "Limited", "na", "\u00cdndia", "em", "1998", "(", "ac\u00e7\u00f5es", "vendidas", "em", "2013", ")", ";", "e", "Komatsu", "Brasil", "International", "Ltda", ".", "no", "Brasil", "em", "1998", "."], "sentence-detokenized": "Ltd. na Tail\u00e2ndia; Komatsu (Shanghai) Ltd. em 1996 em Shanghai, China; Industrial Power Alliance Ltd. no Jap\u00e3o, uma joint venture com a Cummins, em 1998; L & T-Komatsu Limited na \u00cdndia em 1998 (ac\u00e7\u00f5es vendidas em 2013); e Komatsu Brasil International Ltda. no Brasil em 1998.", "token2charspan": [[0, 4], [5, 7], [8, 17], [17, 18], [19, 26], [27, 28], [28, 36], [36, 37], [38, 42], [43, 45], [46, 50], [51, 53], [54, 62], [62, 63], [64, 69], [69, 70], [71, 81], [82, 87], [88, 96], [97, 101], [102, 104], [105, 110], [110, 111], [112, 115], [116, 121], [122, 129], [130, 133], [134, 135], [136, 143], [143, 144], [145, 147], [148, 152], [152, 153], [154, 155], [156, 157], [158, 167], [168, 175], [176, 178], [179, 184], [185, 187], [188, 192], [193, 194], [194, 200], [201, 209], [210, 212], [213, 217], [217, 218], [218, 219], [220, 221], [222, 229], [230, 236], [237, 250], [251, 255], [255, 256], [257, 259], [260, 266], [267, 269], [270, 274], [274, 275]]}
{"doc_key": "ai-test-106", "ner": [[0, 1, "organisation"], [5, 7, "misc"], [12, 12, "misc"], [14, 15, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 15, 0, 1, "physical", "", false, false], [14, 15, 5, 7, "general-affiliation", "", false, false], [14, 15, 12, 12, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "dgp", "tamb\u00e9m", "recebe", "ocasionalmente", "artistas", "em", "resid\u00eancia", "(", "por", "exemplo", ",", "Oscar", "-winner", "Chris", "Landreth", "."], "sentence-detokenized": "A dgp tamb\u00e9m recebe ocasionalmente artistas em resid\u00eancia (por exemplo, Oscar -winner Chris Landreth.", "token2charspan": [[0, 1], [2, 5], [6, 12], [13, 19], [20, 34], [35, 43], [44, 46], [47, 57], [58, 59], [59, 62], [63, 70], [70, 71], [72, 77], [78, 85], [86, 91], [92, 100], [100, 101]]}
{"doc_key": "ai-test-107", "ner": [[6, 8, "misc"], [11, 13, "misc"], [16, 19, "misc"], [24, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Inclui", "actualmente", "quatro", "sub-competi\u00e7\u00f5es", "-", "o", "RoboMaster", "Robotics", "Competition", ",", "o", "RoboMaster", "Technical", "Challenge", ",", "o", "ICRA", "RoboMaster", "AI", "Challenge", ",", "e", "o", "novo", "RoboMaster", "Youth", "Tournament", "."], "sentence-detokenized": "Inclui actualmente quatro sub-competi\u00e7\u00f5es - o RoboMaster Robotics Competition, o RoboMaster Technical Challenge, o ICRA RoboMaster AI Challenge, e o novo RoboMaster Youth Tournament.", "token2charspan": [[0, 6], [7, 18], [19, 25], [26, 41], [42, 43], [44, 45], [46, 56], [57, 65], [66, 77], [77, 78], [79, 80], [81, 91], [92, 101], [102, 111], [111, 112], [113, 114], [115, 119], [120, 130], [131, 133], [134, 143], [143, 144], [145, 146], [147, 148], [149, 153], [154, 164], [165, 170], [171, 181], [181, 182]]}
{"doc_key": "ai-test-108", "ner": [[10, 12, "field"], [17, 20, "algorithm"], [22, 23, "algorithm"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 12, 22, 23, "usage", "", false, false], [10, 12, 27, 28, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["No", "in\u00edcio", "dos", "anos", "2000", ",", "a", "estrat\u00e9gia", "dominante", "de", "processamento", "da", "fala", "come\u00e7ou", "a", "afastar-se", "do", "modelo", "de", "Markov", "Escondido", "para", "redes", "neuronais", "mais", "modernas", "e", "aprendizagem", "profunda", "."], "sentence-detokenized": "No in\u00edcio dos anos 2000, a estrat\u00e9gia dominante de processamento da fala come\u00e7ou a afastar-se do modelo de Markov Escondido para redes neuronais mais modernas e aprendizagem profunda.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 18], [19, 23], [23, 24], [25, 26], [27, 37], [38, 47], [48, 50], [51, 64], [65, 67], [68, 72], [73, 80], [81, 82], [83, 93], [94, 96], [97, 103], [104, 106], [107, 113], [114, 123], [124, 128], [129, 134], [135, 144], [145, 149], [150, 158], [159, 160], [161, 173], [174, 182], [182, 183]]}
{"doc_key": "ai-test-109", "ner": [[8, 10, "misc"], [15, 17, "metrics"], [20, 22, "metrics"], [29, 31, "metrics"], [34, 36, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 17, 20, 22, "related-to", "equal", false, false], [29, 31, 34, 36, "related-to", "equal", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Outra", "express\u00e3o", "equivalente", ",", "no", "caso", "de", "uma", "taxa", "alvo", "bin\u00e1ria", ",", "\u00e9", "que", "a", "taxa", "VERDADEIRA", "positiva", "e", "a", "taxa", "FALSA", "positiva", "s\u00e3o", "iguais", "(", "e", "portanto", "a", "taxa", "FALSA", "negativa", "e", "a", "taxa", "VERDADEIRA", "negativa", "s\u00e3o", "iguais", ")", "para", "cada", "valor", "das", "caracter\u00edsticas", "sens\u00edveis", ":"], "sentence-detokenized": "Outra express\u00e3o equivalente, no caso de uma taxa alvo bin\u00e1ria, \u00e9 que a taxa VERDADEIRA positiva e a taxa FALSA positiva s\u00e3o iguais (e portanto a taxa FALSA negativa e a taxa VERDADEIRA negativa s\u00e3o iguais) para cada valor das caracter\u00edsticas sens\u00edveis:", "token2charspan": [[0, 5], [6, 15], [16, 27], [27, 28], [29, 31], [32, 36], [37, 39], [40, 43], [44, 48], [49, 53], [54, 61], [61, 62], [63, 64], [65, 68], [69, 70], [71, 75], [76, 86], [87, 95], [96, 97], [98, 99], [100, 104], [105, 110], [111, 119], [120, 123], [124, 130], [131, 132], [132, 133], [134, 142], [143, 144], [145, 149], [150, 155], [156, 164], [165, 166], [167, 168], [169, 173], [174, 184], [185, 193], [194, 197], [198, 204], [204, 205], [206, 210], [211, 215], [216, 221], [222, 225], [226, 241], [242, 251], [251, 252]]}
{"doc_key": "ai-test-110", "ner": [[2, 2, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "fun\u00e7\u00e3o", "MATLAB", ","], "sentence-detokenized": "A fun\u00e7\u00e3o MATLAB,", "token2charspan": [[0, 1], [2, 8], [9, 15], [15, 16]]}
{"doc_key": "ai-test-111", "ner": [[1, 2, "product"], [7, 8, "misc"], [19, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 1, 2, "part-of", "", false, false], [19, 20, 1, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Um", "rob\u00f4", "articulado", "\u00e9", "um", "rob\u00f4", "com", "juntas", "rotativas", "(", "por", "exemplo", ",", "um", "rob\u00f4", "com", "pernas", "ou", "um", "rob\u00f4", "industrial", ")", "."], "sentence-detokenized": "Um rob\u00f4 articulado \u00e9 um rob\u00f4 com juntas rotativas (por exemplo, um rob\u00f4 com pernas ou um rob\u00f4 industrial).", "token2charspan": [[0, 2], [3, 7], [8, 18], [19, 20], [21, 23], [24, 28], [29, 32], [33, 39], [40, 49], [50, 51], [51, 54], [55, 62], [62, 63], [64, 66], [67, 71], [72, 75], [76, 82], [83, 85], [86, 88], [89, 93], [94, 104], [104, 105], [105, 106]]}
{"doc_key": "ai-test-112", "ner": [[0, 0, "product"], [5, 6, "product"], [8, 9, "product"], [18, 18, "misc"], [21, 25, "product"], [34, 36, "misc"], [40, 40, "location"], [42, 42, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 18, 18, "general-affiliation", "nationality", false, false], [0, 0, 34, 36, "usage", "", false, false], [0, 0, 40, 40, "physical", "", false, false], [5, 6, 0, 0, "named", "", false, false], [8, 9, 0, 0, "named", "", false, false], [40, 40, 42, 42, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pandora", "(", "tamb\u00e9m", "conhecida", "como", "Pandora", "Media", "ou", "Pandora", "Radio", ")", "\u00e9", "um", "servi\u00e7o", "de", "streaming", "de", "m\u00fasica", "americana", "e", "um", "sistema", "automatizado", "de", "recomenda\u00e7\u00e3o", "de", "servi\u00e7os", "de", "r\u00e1dio", "pela", "Internet", ",", "alimentado", "pelo", "Projecto", "Genoma", "Musical", "e", "sediado", "em", "Oakland", ",", "Calif\u00f3rnia", "."], "sentence-detokenized": "Pandora (tamb\u00e9m conhecida como Pandora Media ou Pandora Radio) \u00e9 um servi\u00e7o de streaming de m\u00fasica americana e um sistema automatizado de recomenda\u00e7\u00e3o de servi\u00e7os de r\u00e1dio pela Internet, alimentado pelo Projecto Genoma Musical e sediado em Oakland, Calif\u00f3rnia.", "token2charspan": [[0, 7], [8, 9], [9, 15], [16, 25], [26, 30], [31, 38], [39, 44], [45, 47], [48, 55], [56, 61], [61, 62], [63, 64], [65, 67], [68, 75], [76, 78], [79, 88], [89, 91], [92, 98], [99, 108], [109, 110], [111, 113], [114, 121], [122, 134], [135, 137], [138, 150], [151, 153], [154, 162], [163, 165], [166, 171], [172, 176], [177, 185], [185, 186], [187, 197], [198, 202], [203, 211], [212, 218], [219, 226], [227, 228], [229, 236], [237, 239], [240, 247], [247, 248], [249, 259], [259, 260]]}
{"doc_key": "ai-test-113", "ner": [[5, 8, "organisation"], [13, 16, "organisation"], [21, 22, "conference"], [34, 34, "conference"], [36, 36, "conference"], [38, 38, "conference"], [40, 40, "conference"], [42, 42, "conference"], [44, 44, "conference"], [46, 46, "conference"], [48, 48, "conference"], [50, 50, "conference"], [52, 52, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [], "relations_mapping_to_source": [], "sentence": ["\u00c9", "membro", "da", "direc\u00e7\u00e3o", "da", "International", "Machine", "Learning", "Society", ",", "foi", "membro", "do", "conselho", "executivo", "da", "AAAI", ",", "foi", "co-presidente", "do", "ICML", "2011", ",", "e", "serviu", "como", "membro", "s\u00e9nior", "do", "PC", "em", "confer\u00eancias", "incluindo", "AAAI", ",", "ICML", ",", "IJCAI", ",", "ISWC", ",", "KDD", ",", "SIGMOD", ",", "UAI", ",", "VLDB", ",", "WSDM", "e", "WWW", "."], "sentence-detokenized": "\u00c9 membro da direc\u00e7\u00e3o da International Machine Learning Society, foi membro do conselho executivo da AAAI, foi co-presidente do ICML 2011, e serviu como membro s\u00e9nior do PC em confer\u00eancias incluindo AAAI, ICML, IJCAI, ISWC, KDD, SIGMOD, UAI, VLDB, WSDM e WWW.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 20], [21, 23], [24, 37], [38, 45], [46, 54], [55, 62], [62, 63], [64, 67], [68, 74], [75, 77], [78, 86], [87, 96], [97, 99], [100, 104], [104, 105], [106, 109], [110, 123], [124, 126], [127, 131], [132, 136], [136, 137], [138, 139], [140, 146], [147, 151], [152, 158], [159, 165], [166, 168], [169, 171], [172, 174], [175, 187], [188, 197], [198, 202], [202, 203], [204, 208], [208, 209], [210, 215], [215, 216], [217, 221], [221, 222], [223, 226], [226, 227], [228, 234], [234, 235], [236, 239], [239, 240], [241, 245], [245, 246], [247, 251], [252, 253], [254, 257], [257, 258]]}
{"doc_key": "ai-test-114", "ner": [[0, 2, "researcher"], [4, 9, "organisation"], [11, 11, "organisation"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 4, 9, "role", "", false, false], [11, 11, 4, 9, "named", "", false, false], [15, 15, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["James", "S.", "Albus", "do", "Instituto", "Nacional", "de", "Normas", "e", "Tecnologia", "(", "NIST", ")", "desenvolveu", "o", "Robocrane", ",", "onde", "a", "plataforma", "pendura", "a", "partir", "de", "seis", "cabos", "em", "vez", "de", "ser", "suportada", "por", "seis", "macacos", "."], "sentence-detokenized": "James S. Albus do Instituto Nacional de Normas e Tecnologia (NIST) desenvolveu o Robocrane, onde a plataforma pendura a partir de seis cabos em vez de ser suportada por seis macacos.", "token2charspan": [[0, 5], [6, 8], [9, 14], [15, 17], [18, 27], [28, 36], [37, 39], [40, 46], [47, 48], [49, 59], [60, 61], [61, 65], [65, 66], [67, 78], [79, 80], [81, 90], [90, 91], [92, 96], [97, 98], [99, 109], [110, 117], [118, 119], [120, 126], [127, 129], [130, 134], [135, 140], [141, 143], [144, 147], [148, 150], [151, 154], [155, 164], [165, 168], [169, 173], [174, 181], [181, 182]]}
{"doc_key": "ai-test-115", "ner": [[3, 6, "algorithm"], [10, 11, "algorithm"], [17, 18, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 3, 6, "type-of", "", false, false], [17, 18, 10, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Outra", "classe", "de", "algoritmos", "de", "pesquisa", "directa", "s\u00e3o", "os", "v\u00e1rios", "algoritmos", "evolutivos", ",", "por", "exemplo", ",", "os", "algoritmos", "gen\u00e9ticos", "."], "sentence-detokenized": "Outra classe de algoritmos de pesquisa directa s\u00e3o os v\u00e1rios algoritmos evolutivos, por exemplo, os algoritmos gen\u00e9ticos.", "token2charspan": [[0, 5], [6, 12], [13, 15], [16, 26], [27, 29], [30, 38], [39, 46], [47, 50], [51, 53], [54, 60], [61, 71], [72, 82], [82, 83], [84, 87], [88, 95], [95, 96], [97, 99], [100, 110], [111, 120], [120, 121]]}
{"doc_key": "ai-test-116", "ner": [[0, 1, "organisation"], [4, 5, "misc"], [7, 8, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 0, 1, "named", "", false, false], [7, 8, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "KUKA", "\u00e9", "um", "fabricante", "alem\u00e3o", "de", "rob\u00f4s", "industriais", "e", "solu\u00e7\u00f5es", "para", "automa\u00e7\u00e3o", "industrial", "."], "sentence-detokenized": "A KUKA \u00e9 um fabricante alem\u00e3o de rob\u00f4s industriais e solu\u00e7\u00f5es para automa\u00e7\u00e3o industrial.", "token2charspan": [[0, 1], [2, 6], [7, 8], [9, 11], [12, 22], [23, 29], [30, 32], [33, 38], [39, 50], [51, 52], [53, 61], [62, 66], [67, 76], [77, 87], [87, 88]]}
{"doc_key": "ai-test-117", "ner": [[9, 9, "misc"], [14, 15, "person"], [12, 22, "misc"], [24, 25, "person"], [26, 26, "misc"], [28, 29, "person"], [30, 31, "misc"], [33, 34, "person"], [36, 38, "misc"], [40, 42, "person"], [43, 46, "misc"], [48, 49, "person"], [50, 53, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[14, 15, 9, 9, "usage", "", false, false], [12, 22, 14, 15, "artifact", "", false, false], [24, 25, 9, 9, "usage", "", false, false], [26, 26, 24, 25, "artifact", "", false, false], [28, 29, 9, 9, "usage", "", false, false], [30, 31, 28, 29, "artifact", "", false, false], [33, 34, 9, 9, "usage", "", false, false], [36, 38, 33, 34, "artifact", "", false, false], [40, 42, 9, 9, "usage", "", false, false], [43, 46, 40, 42, "artifact", "", false, false], [48, 49, 9, 9, "usage", "", false, false], [50, 53, 48, 49, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Outros", "filmes", "captados", "entre", "2016", "e", "2020", "com", "c\u00e2maras", "IMAX", "foram", "o", "Batman", "de", "Zack", "Snyder", "contra", "o", "Super-Homem", ":", "Dawn", "of", "Justice", ",", "Clint", "Eastwood's", "Sully", ",", "Damien", "Chazelle's", "First", "Man", ",", "Patty", "Jenkins", "'", "Wonder", "Woman", "1984", ",", "Cary", "Joji", "Fukunaga's", "No", "Time", "to", "Die", "e", "Joseph", "Kosinski's", "Top", "Gun", ":", "Maverick", "."], "sentence-detokenized": "Outros filmes captados entre 2016 e 2020 com c\u00e2maras IMAX foram o Batman de Zack Snyder contra o Super-Homem: Dawn of Justice, Clint Eastwood's Sully, Damien Chazelle's First Man, Patty Jenkins' Wonder Woman 1984, Cary Joji Fukunaga's No Time to Die e Joseph Kosinski's Top Gun: Maverick.", "token2charspan": [[0, 6], [7, 13], [14, 22], [23, 28], [29, 33], [34, 35], [36, 40], [41, 44], [45, 52], [53, 57], [58, 63], [64, 65], [66, 72], [73, 75], [76, 80], [81, 87], [88, 94], [95, 96], [97, 108], [108, 109], [110, 114], [115, 117], [118, 125], [125, 126], [127, 132], [133, 143], [144, 149], [149, 150], [151, 157], [158, 168], [169, 174], [175, 178], [178, 179], [180, 185], [186, 193], [193, 194], [195, 201], [202, 207], [208, 212], [212, 213], [214, 218], [219, 223], [224, 234], [235, 237], [238, 242], [243, 245], [246, 249], [250, 251], [252, 258], [259, 269], [270, 273], [274, 277], [277, 278], [279, 287], [287, 288]]}
{"doc_key": "ai-test-118", "ner": [[4, 5, "misc"], [9, 11, "organisation"], [13, 13, "organisation"], [28, 28, "misc"], [33, 34, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 28, 28, "named", "", false, false], [9, 11, 4, 5, "usage", "", false, false], [9, 11, 33, 34, "physical", "", false, false], [13, 13, 9, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["O", "julgamento", "da", "fonte", "MICR", "E13B", "foi", "mostrado", "\u00e0", "American", "Bankers", "Association", "(", "ABA", ")", "em", "Julho", "de", "1956", ",", "que", "a", "adoptou", "em", "1958", "como", "a", "norma", "MICR", "para", "documentos", "negoci\u00e1veis", "nos", "Estados", "Unidos", "."], "sentence-detokenized": "O julgamento da fonte MICR E13B foi mostrado \u00e0 American Bankers Association (ABA) em Julho de 1956, que a adoptou em 1958 como a norma MICR para documentos negoci\u00e1veis nos Estados Unidos.", "token2charspan": [[0, 1], [2, 12], [13, 15], [16, 21], [22, 26], [27, 31], [32, 35], [36, 44], [45, 46], [47, 55], [56, 63], [64, 75], [76, 77], [77, 80], [80, 81], [82, 84], [85, 90], [91, 93], [94, 98], [98, 99], [100, 103], [104, 105], [106, 113], [114, 116], [117, 121], [122, 126], [127, 128], [129, 134], [135, 139], [140, 144], [145, 155], [156, 167], [168, 171], [172, 179], [180, 186], [186, 187]]}
{"doc_key": "ai-test-119", "ner": [[0, 4, "misc"], [17, 17, "field"], [20, 21, "field"], [24, 24, "field"], [26, 28, "field"], [30, 30, "field"], [33, 33, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[17, 17, 0, 4, "usage", "", false, false], [20, 21, 17, 17, "part-of", "", false, false], [24, 24, 0, 4, "usage", "", false, false], [26, 28, 0, 4, "usage", "", false, false], [30, 30, 0, 4, "usage", "", false, false], [33, 33, 0, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Os", "algoritmos", "de", "pesquisa", "locais", "s\u00e3o", "amplamente", "aplicados", "a", "numerosos", "problemas", "computacionais", "dif\u00edceis", ",", "incluindo", "problemas", "de", "inform\u00e1tica", "(", "particularmente", "intelig\u00eancia", "artificial", ")", ",", "matem\u00e1tica", ",", "investiga\u00e7\u00e3o", "de", "opera\u00e7\u00f5es", ",", "engenharia", ",", "e", "bioinform\u00e1tica", "."], "sentence-detokenized": "Os algoritmos de pesquisa locais s\u00e3o amplamente aplicados a numerosos problemas computacionais dif\u00edceis, incluindo problemas de inform\u00e1tica (particularmente intelig\u00eancia artificial), matem\u00e1tica, investiga\u00e7\u00e3o de opera\u00e7\u00f5es, engenharia, e bioinform\u00e1tica.", "token2charspan": [[0, 2], [3, 13], [14, 16], [17, 25], [26, 32], [33, 36], [37, 47], [48, 57], [58, 59], [60, 69], [70, 79], [80, 94], [95, 103], [103, 104], [105, 114], [115, 124], [125, 127], [128, 139], [140, 141], [141, 156], [157, 169], [170, 180], [180, 181], [181, 182], [183, 193], [193, 194], [195, 207], [208, 210], [211, 220], [220, 221], [222, 232], [232, 233], [234, 235], [236, 250], [250, 251]]}
{"doc_key": "ai-test-120", "ner": [[0, 1, "researcher"], [11, 11, "location"], [13, 13, "country"], [18, 18, "country"], [24, 25, "algorithm"], [27, 27, "algorithm"], [29, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 11, 11, "physical", "", false, false], [0, 1, 18, 18, "general-affiliation", "nationality", false, false], [0, 1, 24, 25, "general-affiliation", "topic_of_study", false, false], [0, 1, 27, 27, "general-affiliation", "topic_of_study", false, false], [11, 11, 13, 13, "physical", "", false, false], [27, 27, 29, 31, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gerd", "Gigerenzer", "(", "nascido", "a", "3", "de", "Setembro", "de", "1947", ",", "Wallersdorf", ",", "Alemanha", ")", "\u00e9", "um", "psic\u00f3logo", "alem\u00e3o", "que", "estudou", "o", "uso", "de", "racionalidade", "limitada", "e", "heur\u00edstica", "na", "tomada", "de", "decis\u00f5es", "."], "sentence-detokenized": "Gerd Gigerenzer (nascido a 3 de Setembro de 1947, Wallersdorf, Alemanha) \u00e9 um psic\u00f3logo alem\u00e3o que estudou o uso de racionalidade limitada e heur\u00edstica na tomada de decis\u00f5es.", "token2charspan": [[0, 4], [5, 15], [16, 17], [17, 24], [25, 26], [27, 28], [29, 31], [32, 40], [41, 43], [44, 48], [48, 49], [50, 61], [61, 62], [63, 71], [71, 72], [73, 74], [75, 77], [78, 87], [88, 94], [95, 98], [99, 106], [107, 108], [109, 112], [113, 115], [116, 129], [130, 138], [139, 140], [141, 151], [152, 154], [155, 161], [162, 164], [165, 173], [173, 174]]}
{"doc_key": "ai-test-121", "ner": [[3, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["para", "minimizar", "o", "erro", "quadr\u00e1tico", "m\u00e9dio", "."], "sentence-detokenized": "para minimizar o erro quadr\u00e1tico m\u00e9dio.", "token2charspan": [[0, 4], [5, 14], [15, 16], [17, 21], [22, 32], [33, 38], [38, 39]]}
{"doc_key": "ai-test-122", "ner": [[12, 13, "misc"], [16, 17, "organisation"], [32, 35, "field"], [55, 56, "misc"], [65, 67, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 13, 16, 17, "origin", "", false, false], [55, 56, 65, 67, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Mas", "mesmo", "uma", "l\u00edngua", "oficial", "com", "uma", "academia", "reguladora", ",", "como", "o", "franc\u00eas", "padr\u00e3o", "com", "a", "Acad\u00e9mie", "fran\u00e7aise", ",", "\u00e9", "classificada", "como", "uma", "l\u00edngua", "natural", "(", "por", "exemplo", ",", "no", "campo", "do", "processamento", "da", "l\u00edngua", "natural", ")", ",", "uma", "vez", "que", "os", "seus", "pontos", "prescritivos", "n\u00e3o", "a", "tornam", "suficientemente", "constru\u00edda", "para", "ser", "classificada", "como", "uma", "l\u00edngua", "constru\u00edda", "ou", "suficientemente", "controlada", "para", "ser", "classificada", "como", "uma", "l\u00edngua", "natural", "controlada", "."], "sentence-detokenized": "Mas mesmo uma l\u00edngua oficial com uma academia reguladora, como o franc\u00eas padr\u00e3o com a Acad\u00e9mie fran\u00e7aise, \u00e9 classificada como uma l\u00edngua natural (por exemplo, no campo do processamento da l\u00edngua natural), uma vez que os seus pontos prescritivos n\u00e3o a tornam suficientemente constru\u00edda para ser classificada como uma l\u00edngua constru\u00edda ou suficientemente controlada para ser classificada como uma l\u00edngua natural controlada.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 20], [21, 28], [29, 32], [33, 36], [37, 45], [46, 56], [56, 57], [58, 62], [63, 64], [65, 72], [73, 79], [80, 83], [84, 85], [86, 94], [95, 104], [104, 105], [106, 107], [108, 120], [121, 125], [126, 129], [130, 136], [137, 144], [145, 146], [146, 149], [150, 157], [157, 158], [159, 161], [162, 167], [168, 170], [171, 184], [185, 187], [188, 194], [195, 202], [202, 203], [203, 204], [205, 208], [209, 212], [213, 216], [217, 219], [220, 224], [225, 231], [232, 244], [245, 248], [249, 250], [251, 257], [258, 273], [274, 284], [285, 289], [290, 293], [294, 306], [307, 311], [312, 315], [316, 322], [323, 333], [334, 336], [337, 352], [353, 363], [364, 368], [369, 372], [373, 385], [386, 390], [391, 394], [395, 401], [402, 409], [410, 420], [420, 421]]}
{"doc_key": "ai-test-123", "ner": [[10, 10, "metrics"], [12, 13, "metrics"], [15, 15, "metrics"], [35, 36, "metrics"], [38, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 15, 12, 13, "named", "", false, false], [38, 38, 35, 36, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["H\u00e1", "uma", "s\u00e9rie", "de", "outras", "m\u00e9tricas", ",", "mais", "simplesmente", "a", "exactid\u00e3o", "ou", "Fracction", "Correct", "(", "FC", ")", ",", "que", "mede", "a", "frac\u00e7\u00e3o", "de", "todas", "as", "inst\u00e2ncias", "que", "est\u00e3o", "correctamente", "categorizadas", ";", "o", "complemento", "\u00e9", "a", "Fraction", "Incorrect", "(", "FiC", ")", "."], "sentence-detokenized": "H\u00e1 uma s\u00e9rie de outras m\u00e9tricas, mais simplesmente a exactid\u00e3o ou Fracction Correct (FC), que mede a frac\u00e7\u00e3o de todas as inst\u00e2ncias que est\u00e3o correctamente categorizadas; o complemento \u00e9 a Fraction Incorrect (FiC).", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 22], [23, 31], [31, 32], [33, 37], [38, 50], [51, 52], [53, 62], [63, 65], [66, 75], [76, 83], [84, 85], [85, 87], [87, 88], [88, 89], [90, 93], [94, 98], [99, 100], [101, 108], [109, 111], [112, 117], [118, 120], [121, 131], [132, 135], [136, 141], [142, 155], [156, 169], [169, 170], [171, 172], [173, 184], [185, 186], [187, 188], [189, 197], [198, 207], [208, 209], [209, 212], [212, 213], [213, 214]]}
{"doc_key": "ai-test-124", "ner": [[0, 0, "researcher"], [4, 8, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 8, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cardie", "tornou-se", "membro", "da", "Associa\u00e7\u00e3o", "para", "a", "Lingu\u00edstica", "Computacional", "em", "2016", "."], "sentence-detokenized": "Cardie tornou-se membro da Associa\u00e7\u00e3o para a Lingu\u00edstica Computacional em 2016.", "token2charspan": [[0, 6], [7, 16], [17, 23], [24, 26], [27, 37], [38, 42], [43, 44], [45, 56], [57, 70], [71, 73], [74, 78], [78, 79]]}
{"doc_key": "ai-test-125", "ner": [[12, 15, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "aprendizagem", "dos", "par\u00e2metros", "matem\u00e1tica", "teta", "/", "matem\u00e1tica", "\u00e9", "geralmente", "feita", "pela", "m\u00e1xima", "probabilidade", "de", "aprendizagem", "de", "matem\u00e1tica", "(", "Y", "_", "i", "|", "X", "_", "i", ";", "\\", "theta", ")", "/", "matem\u00e1tica", "."], "sentence-detokenized": "A aprendizagem dos par\u00e2metros matem\u00e1tica teta / matem\u00e1tica \u00e9 geralmente feita pela m\u00e1xima probabilidade de aprendizagem de matem\u00e1tica (Y _ i | X _ i;\\ theta) / matem\u00e1tica.", "token2charspan": [[0, 1], [2, 14], [15, 18], [19, 29], [30, 40], [41, 45], [46, 47], [48, 58], [59, 60], [61, 71], [72, 77], [78, 82], [83, 89], [90, 103], [104, 106], [107, 119], [120, 122], [123, 133], [134, 135], [135, 136], [137, 138], [139, 140], [141, 142], [143, 144], [145, 146], [147, 148], [148, 149], [149, 150], [151, 156], [156, 157], [158, 159], [160, 170], [170, 171]]}
{"doc_key": "ai-test-126", "ner": [[0, 2, "task"], [5, 8, "algorithm"], [10, 11, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 0, 2, "usage", "", true, false], [10, 11, 5, 8, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An\u00e1lise", "de", "agrupamento", ",", "e", "factoriza\u00e7\u00e3o", "de", "matriz", "n\u00e3o-negativa", "para", "minera\u00e7\u00e3o", "descritiva", "."], "sentence-detokenized": "An\u00e1lise de agrupamento, e factoriza\u00e7\u00e3o de matriz n\u00e3o-negativa para minera\u00e7\u00e3o descritiva.", "token2charspan": [[0, 7], [8, 10], [11, 22], [22, 23], [24, 25], [26, 38], [39, 41], [42, 48], [49, 61], [62, 66], [67, 76], [77, 87], [87, 88]]}
{"doc_key": "ai-test-127", "ner": [[1, 1, "field"], [4, 6, "field"], [25, 28, "field"], [30, 32, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[25, 28, 1, 1, "part-of", "", false, false], [25, 28, 4, 6, "part-of", "", false, false], [30, 32, 1, 1, "part-of", "", false, false], [30, 32, 4, 6, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Na", "inform\u00e1tica", "e", "na", "tecnologia", "da", "informa\u00e7\u00e3o", "que", "ela", "permite", ",", "tem", "sido", "um", "desafio", "a", "longo", "prazo", "para", "a", "capacidade", "dos", "computadores", "para", "fazer", "processamento", "de", "linguagem", "natural", "e", "aprendizagem", "de", "m\u00e1quinas", "."], "sentence-detokenized": "Na inform\u00e1tica e na tecnologia da informa\u00e7\u00e3o que ela permite, tem sido um desafio a longo prazo para a capacidade dos computadores para fazer processamento de linguagem natural e aprendizagem de m\u00e1quinas.", "token2charspan": [[0, 2], [3, 14], [15, 16], [17, 19], [20, 30], [31, 33], [34, 44], [45, 48], [49, 52], [53, 60], [60, 61], [62, 65], [66, 70], [71, 73], [74, 81], [82, 83], [84, 89], [90, 95], [96, 100], [101, 102], [103, 113], [114, 117], [118, 130], [131, 135], [136, 141], [142, 155], [156, 158], [159, 168], [169, 176], [177, 178], [179, 191], [192, 194], [195, 203], [203, 204]]}
{"doc_key": "ai-test-128", "ner": [[3, 4, "algorithm"], [8, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 8, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "C\u00f3digo", "para", "Gabor", "extra\u00eddo", "de", "imagens", "em", "MATLAB", "pode", "ser", "encontrado", "em"], "sentence-detokenized": "(C\u00f3digo para Gabor extra\u00eddo de imagens em MATLAB pode ser encontrado em", "token2charspan": [[0, 1], [1, 7], [8, 12], [13, 18], [19, 27], [28, 30], [31, 38], [39, 41], [42, 48], [49, 53], [54, 57], [58, 68], [69, 71]]}
{"doc_key": "ai-test-129", "ner": [[1, 1, "misc"], [19, 20, "algorithm"], [23, 23, "task"], [25, 25, "task"], [27, 29, "task"], [31, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 1, 19, 20, "general-affiliation", "", false, false], [1, 1, 23, 23, "related-to", "solves_problem_of_type", false, false], [1, 1, 25, 25, "related-to", "solves_problem_of_type", false, false], [1, 1, 27, 29, "related-to", "solves_problem_of_type", false, false], [1, 1, 31, 33, "related-to", "solves_problem_of_type", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["O", "NeuralExpert", "centra", "as", "especifica\u00e7\u00f5es", "de", "concep\u00e7\u00e3o", "em", "torno", "do", "tipo", "de", "problema", "que", "o", "utilizador", "gostaria", "que", "a", "rede", "neural", "resolvesse", "(", "Classifica\u00e7\u00e3o", ",", "Predi\u00e7\u00e3o", ",", "Aproxima\u00e7\u00e3o", "de", "Fun\u00e7\u00f5es", "ou", "An\u00e1lise", "de", "Cluster", ")", "."], "sentence-detokenized": "O NeuralExpert centra as especifica\u00e7\u00f5es de concep\u00e7\u00e3o em torno do tipo de problema que o utilizador gostaria que a rede neural resolvesse (Classifica\u00e7\u00e3o, Predi\u00e7\u00e3o, Aproxima\u00e7\u00e3o de Fun\u00e7\u00f5es ou An\u00e1lise de Cluster).", "token2charspan": [[0, 1], [2, 14], [15, 21], [22, 24], [25, 39], [40, 42], [43, 52], [53, 55], [56, 61], [62, 64], [65, 69], [70, 72], [73, 81], [82, 85], [86, 87], [88, 98], [99, 107], [108, 111], [112, 113], [114, 118], [119, 125], [126, 136], [137, 138], [138, 151], [151, 152], [153, 161], [161, 162], [163, 174], [175, 177], [178, 185], [186, 188], [189, 196], [197, 199], [200, 207], [207, 208], [208, 209]]}
{"doc_key": "ai-test-130", "ner": [[2, 6, "misc"], [27, 29, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Quando", "o", "tamanho", "do", "passo", "de", "quantiza\u00e7\u00e3o", "(", "\u0394", ")", "\u00e9", "pequeno", "relativamente", "\u00e0", "varia\u00e7\u00e3o", "do", "sinal", "a", "ser", "quantificado", ",", "\u00e9", "relativamente", "simples", "mostrar", "que", "o", "erro", "quadr\u00e1tico", "m\u00e9dio", "produzido", "por", "tal", "opera\u00e7\u00e3o", "de", "arredondamento", "ser\u00e1", "aproximadamente", "matem\u00e1tico", "^", "2", "/", "12", "/", "matem\u00e1tico"], "sentence-detokenized": "Quando o tamanho do passo de quantiza\u00e7\u00e3o (\u0394) \u00e9 pequeno relativamente \u00e0 varia\u00e7\u00e3o do sinal a ser quantificado, \u00e9 relativamente simples mostrar que o erro quadr\u00e1tico m\u00e9dio produzido por tal opera\u00e7\u00e3o de arredondamento ser\u00e1 aproximadamente matem\u00e1tico ^ 2 / 12 / matem\u00e1tico", "token2charspan": [[0, 6], [7, 8], [9, 16], [17, 19], [20, 25], [26, 28], [29, 40], [41, 42], [42, 43], [43, 44], [45, 46], [47, 54], [55, 68], [69, 70], [71, 79], [80, 82], [83, 88], [89, 90], [91, 94], [95, 107], [107, 108], [109, 110], [111, 124], [125, 132], [133, 140], [141, 144], [145, 146], [147, 151], [152, 162], [163, 168], [169, 178], [179, 182], [183, 186], [187, 195], [196, 198], [199, 213], [214, 218], [219, 234], [235, 245], [246, 247], [248, 249], [250, 251], [252, 254], [255, 256], [257, 267]]}
{"doc_key": "ai-test-131", "ner": [[20, 20, "product"], [28, 30, "researcher"], [32, 33, "researcher"], [35, 37, "researcher"], [39, 40, "researcher"], [42, 43, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "constru\u00e7\u00e3o", "de", "um", "l\u00e9xico", "rico", "com", "uma", "ontologia", "adequada", "requer", "um", "esfor\u00e7o", "significativo", ",", "por", "exemplo", ",", "o", "l\u00e9xico", "Wordnet", "exigiu", "muitos", "anos", "de", "esfor\u00e7o", "pessoal", ".", "G.", "A.", "Miller", ",", "R.", "Beckwith", ",", "C.", "D.", "Fellbaum", ",", "D.", "Gross", ",", "K.", "Miller", "."], "sentence-detokenized": "A constru\u00e7\u00e3o de um l\u00e9xico rico com uma ontologia adequada requer um esfor\u00e7o significativo, por exemplo, o l\u00e9xico Wordnet exigiu muitos anos de esfor\u00e7o pessoal. G. A. Miller, R. Beckwith, C. D. Fellbaum, D. Gross, K. Miller.", "token2charspan": [[0, 1], [2, 12], [13, 15], [16, 18], [19, 25], [26, 30], [31, 34], [35, 38], [39, 48], [49, 57], [58, 64], [65, 67], [68, 75], [76, 89], [89, 90], [91, 94], [95, 102], [102, 103], [104, 105], [106, 112], [113, 120], [121, 127], [128, 134], [135, 139], [140, 142], [143, 150], [151, 158], [158, 159], [160, 162], [163, 165], [166, 172], [172, 173], [174, 176], [177, 185], [185, 186], [187, 189], [190, 192], [193, 201], [201, 202], [203, 205], [206, 211], [211, 212], [213, 215], [216, 222], [222, 223]]}
{"doc_key": "ai-test-132", "ner": [[3, 3, "organisation"], [19, 20, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[19, 20, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["O", "portf\u00f3lio", "da", "Kawasaki", "inclui", "tamb\u00e9m", "telhados", "retr\u00e1cteis", ",", "pavimentos", "e", "outras", "estruturas", "gigantes", ",", "a", "\"", "superf\u00edcie", "retr\u00e1ctil", "Sapporo", "Dome", "\"", "\u00e9", "um", "exemplo", "."], "sentence-detokenized": "O portf\u00f3lio da Kawasaki inclui tamb\u00e9m telhados retr\u00e1cteis, pavimentos e outras estruturas gigantes, a \"superf\u00edcie retr\u00e1ctil Sapporo Dome\" \u00e9 um exemplo.", "token2charspan": [[0, 1], [2, 11], [12, 14], [15, 23], [24, 30], [31, 37], [38, 46], [47, 57], [57, 58], [59, 69], [70, 71], [72, 78], [79, 89], [90, 98], [98, 99], [100, 101], [102, 103], [103, 113], [114, 123], [124, 131], [132, 136], [136, 137], [138, 139], [140, 142], [143, 150], [150, 151]]}
{"doc_key": "ai-test-133", "ner": [[0, 2, "metrics"], [7, 9, "metrics"], [12, 14, "metrics"], [19, 23, "metrics"], [50, 50, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 19, 23, "related-to", "", false, false], [0, 2, 50, 50, "opposite", "alternative_to", false, false], [7, 9, 0, 2, "type-of", "", false, false], [12, 14, 0, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["As", "estat\u00edsticas", "Kappa", ",", "tais", "como", "a", "kappa", "de", "Fleiss", "e", "a", "kappa", "de", "Cohen", "s\u00e3o", "m\u00e9todos", "para", "calcular", "a", "fiabilidade", "entre", "os", "avaliadores", "com", "base", "em", "diferentes", "hip\u00f3teses", "sobre", "as", "distribui\u00e7\u00f5es", "marginais", "ou", "pr\u00e9vias", ",", "e", "s\u00e3o", "cada", "vez", "mais", "utilizadas", "como", "alternativas", "corrigidas", "ao", "acaso", "em", "rela\u00e7\u00e3o", "\u00e0", "precis\u00e3o", "noutros", "contextos", "."], "sentence-detokenized": "As estat\u00edsticas Kappa, tais como a kappa de Fleiss e a kappa de Cohen s\u00e3o m\u00e9todos para calcular a fiabilidade entre os avaliadores com base em diferentes hip\u00f3teses sobre as distribui\u00e7\u00f5es marginais ou pr\u00e9vias, e s\u00e3o cada vez mais utilizadas como alternativas corrigidas ao acaso em rela\u00e7\u00e3o \u00e0 precis\u00e3o noutros contextos.", "token2charspan": [[0, 2], [3, 15], [16, 21], [21, 22], [23, 27], [28, 32], [33, 34], [35, 40], [41, 43], [44, 50], [51, 52], [53, 54], [55, 60], [61, 63], [64, 69], [70, 73], [74, 81], [82, 86], [87, 95], [96, 97], [98, 109], [110, 115], [116, 118], [119, 130], [131, 134], [135, 139], [140, 142], [143, 153], [154, 163], [164, 169], [170, 172], [173, 186], [187, 196], [197, 199], [200, 207], [207, 208], [209, 210], [211, 214], [215, 219], [220, 223], [224, 228], [229, 239], [240, 244], [245, 257], [258, 268], [269, 271], [272, 277], [278, 280], [281, 288], [289, 290], [291, 299], [300, 307], [308, 317], [317, 318]]}
{"doc_key": "ai-test-134", "ner": [[4, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [19, 19, "researcher"], [30, 32, "algorithm"], [35, 38, "algorithm"], [40, 40, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 19, 19, "role", "student_of", false, false], [7, 8, 19, 19, "role", "student_of", false, false], [10, 11, 19, 19, "role", "student_of", false, false], [13, 14, 19, 19, "role", "student_of", false, false], [35, 38, 4, 5, "origin", "", false, false], [35, 38, 7, 8, "origin", "", false, false], [35, 38, 10, 11, "origin", "", false, false], [35, 38, 13, 14, "origin", "", false, false], [35, 38, 19, 19, "origin", "", false, false], [35, 38, 30, 32, "type-of", "", false, false], [40, 40, 35, 38, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Com", "os", "seus", "alunos", "Sepp", "Hochreiter", ",", "Felix", "Gers", ",", "Fred", "Cummins", ",", "Alex", "Graves", ",", "e", "outros", ",", "Schmidhuber", "publicou", "vers\u00f5es", "cada", "vez", "mais", "sofisticadas", "de", "um", "tipo", "de", "rede", "neural", "recorrente", "chamada", "de", "mem\u00f3ria", "de", "longo", "prazo", "(", "LSTM", ")", "."], "sentence-detokenized": "Com os seus alunos Sepp Hochreiter, Felix Gers, Fred Cummins, Alex Graves, e outros, Schmidhuber publicou vers\u00f5es cada vez mais sofisticadas de um tipo de rede neural recorrente chamada de mem\u00f3ria de longo prazo (LSTM).", "token2charspan": [[0, 3], [4, 6], [7, 11], [12, 18], [19, 23], [24, 34], [34, 35], [36, 41], [42, 46], [46, 47], [48, 52], [53, 60], [60, 61], [62, 66], [67, 73], [73, 74], [75, 76], [77, 83], [83, 84], [85, 96], [97, 105], [106, 113], [114, 118], [119, 122], [123, 127], [128, 140], [141, 143], [144, 146], [147, 151], [152, 154], [155, 159], [160, 166], [167, 177], [178, 185], [186, 188], [189, 196], [197, 199], [200, 205], [206, 211], [212, 213], [213, 217], [217, 218], [218, 219]]}
{"doc_key": "ai-test-135", "ner": [[6, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2004", "-", "\u00c9", "lan\u00e7ada", "a", "primeira", "Cobot", "KUKA", "LBR", "3", "."], "sentence-detokenized": "2004 - \u00c9 lan\u00e7ada a primeira Cobot KUKA LBR 3.", "token2charspan": [[0, 4], [5, 6], [7, 8], [9, 16], [17, 18], [19, 27], [28, 33], [34, 38], [39, 42], [43, 44], [44, 45]]}
{"doc_key": "ai-test-136", "ner": [[11, 13, "algorithm"], [16, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Duas", "abordagens", "superficiais", "utilizadas", "para", "treinar", "e", "depois", "desambiguar", "s\u00e3o", "a", "classificadora", "Naive", "Bayes", "e", "as", "\u00e1rvores", "de", "decis\u00e3o", "."], "sentence-detokenized": "Duas abordagens superficiais utilizadas para treinar e depois desambiguar s\u00e3o a classificadora Naive Bayes e as \u00e1rvores de decis\u00e3o.", "token2charspan": [[0, 4], [5, 15], [16, 28], [29, 39], [40, 44], [45, 52], [53, 54], [55, 61], [62, 73], [74, 77], [78, 79], [80, 94], [95, 100], [101, 106], [107, 108], [109, 111], [112, 119], [120, 122], [123, 130], [130, 131]]}
{"doc_key": "ai-test-137", "ner": [[5, 5, "misc"], [13, 14, "person"], [16, 18, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 13, 14, "origin", "", false, false], [5, 5, 16, 18, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "primeiras", "formas", "pr\u00e1ticas", "de", "fotografia", "foram", "introduzidas", "em", "Janeiro", "de", "1839", "por", "Louis", "Daguerre", "e", "Henry", "Fox", "Talbot", "."], "sentence-detokenized": "As primeiras formas pr\u00e1ticas de fotografia foram introduzidas em Janeiro de 1839 por Louis Daguerre e Henry Fox Talbot.", "token2charspan": [[0, 2], [3, 12], [13, 19], [20, 28], [29, 31], [32, 42], [43, 48], [49, 61], [62, 64], [65, 72], [73, 75], [76, 80], [81, 84], [85, 90], [91, 99], [100, 101], [102, 107], [108, 111], [112, 118], [118, 119]]}
{"doc_key": "ai-test-138", "ner": [[4, 6, "task"], [11, 13, "task"], [25, 27, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 25, 27, "part-of", "task_part_of_field", false, false], [11, 13, 25, 27, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Por", "exemplo", ",", "a", "s\u00edntese", "da", "fala", ",", "combinada", "com", "o", "reconhecimento", "da", "fala", ",", "permite", "a", "interac\u00e7\u00e3o", "com", "dispositivos", "m\u00f3veis", "atrav\u00e9s", "de", "interfaces", "de", "processamento", "de", "linguagem", "."], "sentence-detokenized": "Por exemplo, a s\u00edntese da fala, combinada com o reconhecimento da fala, permite a interac\u00e7\u00e3o com dispositivos m\u00f3veis atrav\u00e9s de interfaces de processamento de linguagem.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 14], [15, 22], [23, 25], [26, 30], [30, 31], [32, 41], [42, 45], [46, 47], [48, 62], [63, 65], [66, 70], [70, 71], [72, 79], [80, 81], [82, 92], [93, 96], [97, 109], [110, 116], [117, 124], [125, 127], [128, 138], [139, 141], [142, 155], [156, 158], [159, 168], [168, 169]]}
{"doc_key": "ai-test-139", "ner": [[0, 1, "product"], [16, 16, "programlang"], [18, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 16, 16, "general-affiliation", "", false, false], [0, 1, 18, 19, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Os", "Phidgets", "podem", "ser", "programados", "utilizando", "uma", "variedade", "de", "software", "e", "linguagens", "de", "programa\u00e7\u00e3o", ",", "desde", "Java", "at\u00e9", "Microsoft", "Excel", "."], "sentence-detokenized": "Os Phidgets podem ser programados utilizando uma variedade de software e linguagens de programa\u00e7\u00e3o, desde Java at\u00e9 Microsoft Excel.", "token2charspan": [[0, 2], [3, 11], [12, 17], [18, 21], [22, 33], [34, 44], [45, 48], [49, 58], [59, 61], [62, 70], [71, 72], [73, 83], [84, 86], [87, 98], [98, 99], [100, 105], [106, 110], [111, 114], [115, 124], [125, 130], [130, 131]]}
{"doc_key": "ai-test-140", "ner": [[2, 3, "field"], [9, 10, "researcher"], [13, 14, "misc"], [20, 22, "field"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 9, 10, "origin", "", false, false], [9, 10, 20, 22, "general-affiliation", "topic_of_study", false, false], [9, 10, 24, 25, "general-affiliation", "topic_of_study", false, false], [13, 14, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["O", "termo", "aprendizagem", "mec\u00e2nica", "foi", "cunhado", "em", "1959", "por", "Arthur", "Samuel", ",", "um", "IBMer", "americano", "e", "pioneiro", "no", "campo", "dos", "jogos", "de", "computador", "e", "intelig\u00eancia", "artificial", "."], "sentence-detokenized": "O termo aprendizagem mec\u00e2nica foi cunhado em 1959 por Arthur Samuel, um IBMer americano e pioneiro no campo dos jogos de computador e intelig\u00eancia artificial.", "token2charspan": [[0, 1], [2, 7], [8, 20], [21, 29], [30, 33], [34, 41], [42, 44], [45, 49], [50, 53], [54, 60], [61, 67], [67, 68], [69, 71], [72, 77], [78, 87], [88, 89], [90, 98], [99, 101], [102, 107], [108, 111], [112, 117], [118, 120], [121, 131], [132, 133], [134, 146], [147, 157], [157, 158]]}
{"doc_key": "ai-test-141", "ner": [[1, 2, "misc"], [3, 4, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 1, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["O", "poeta", "israelita", "David", "Avidan", ",", "que", "estava", "fascinado", "com", "as", "futuras", "tecnologias", "e", "a", "sua", "rela\u00e7\u00e3o", "com", "a", "arte", ",", "desejava", "explorar", "a", "utiliza\u00e7\u00e3o", "de", "computadores", "para", "escrever", "literatura", "."], "sentence-detokenized": "O poeta israelita David Avidan, que estava fascinado com as futuras tecnologias e a sua rela\u00e7\u00e3o com a arte, desejava explorar a utiliza\u00e7\u00e3o de computadores para escrever literatura.", "token2charspan": [[0, 1], [2, 7], [8, 17], [18, 23], [24, 30], [30, 31], [32, 35], [36, 42], [43, 52], [53, 56], [57, 59], [60, 67], [68, 79], [80, 81], [82, 83], [84, 87], [88, 95], [96, 99], [100, 101], [102, 106], [106, 107], [108, 116], [117, 125], [126, 127], [128, 138], [139, 141], [142, 154], [155, 159], [160, 168], [169, 179], [179, 180]]}
{"doc_key": "ai-test-142", "ner": [[3, 4, "misc"], [8, 8, "organisation"], [16, 16, "location"], [33, 33, "location"], [29, 32, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 8, 3, 4, "part-of", "", false, false], [29, 32, 33, 33, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Como", "parte", "do", "Projecto", "GATEway", "em", "2017", ",", "Oxbotica", "experimentou", "sete", "autocarros", "de", "vaiv\u00e9m", "aut\u00f3nomos", "em", "Greenwich", ",", "navegando", "num", "percurso", "de", "duas", "milhas", "\u00e0", "beira", "rio", "perto", "da", "The", "O2", "Arena", "de", "Londres", ",", "numa", "rota", "tamb\u00e9m", "utilizada", "por", "pe\u00f5es", "e", "ciclistas", "."], "sentence-detokenized": "Como parte do Projecto GATEway em 2017, Oxbotica experimentou sete autocarros de vaiv\u00e9m aut\u00f3nomos em Greenwich, navegando num percurso de duas milhas \u00e0 beira rio perto da The O2 Arena de Londres, numa rota tamb\u00e9m utilizada por pe\u00f5es e ciclistas.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 30], [31, 33], [34, 38], [38, 39], [40, 48], [49, 61], [62, 66], [67, 77], [78, 80], [81, 87], [88, 97], [98, 100], [101, 110], [110, 111], [112, 121], [122, 125], [126, 134], [135, 137], [138, 142], [143, 149], [150, 151], [152, 157], [158, 161], [162, 167], [168, 170], [171, 174], [175, 177], [178, 183], [184, 186], [187, 194], [194, 195], [196, 200], [201, 205], [206, 212], [213, 222], [223, 226], [227, 232], [233, 234], [235, 244], [244, 245]]}
{"doc_key": "ai-test-143", "ner": [[11, 13, "task"], [16, 17, "metrics"], [21, 22, "misc"], [28, 28, "metrics"], [30, 30, "metrics"], [32, 32, "metrics"], [34, 34, "metrics"], [36, 38, "metrics"], [41, 41, "metrics"], [43, 43, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[16, 17, 21, 22, "related-to", "is_a", false, false], [16, 17, 28, 28, "usage", "", false, false], [16, 17, 30, 30, "usage", "", false, false], [28, 28, 32, 32, "named", "same", false, false], [30, 30, 43, 43, "named", "same", false, false], [32, 32, 41, 41, "opposite", "", false, false], [32, 32, 43, 43, "opposite", "", false, false], [34, 34, 32, 32, "named", "", false, false], [36, 38, 32, 32, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Uma", "combina\u00e7\u00e3o", "n\u00e3o", "relacionada", "mas", "comummente", "utilizada", "de", "estat\u00edsticas", "b\u00e1sicas", "da", "recupera\u00e7\u00e3o", "de", "informa\u00e7\u00e3o", "\u00e9", "a", "pontua\u00e7\u00e3o", "F", ",", "sendo", "uma", "m\u00e9dia", "harm\u00f3nica", "(", "possivelmente", "ponderada", ")", "de", "recorda\u00e7\u00e3o", "e", "precis\u00e3o", "onde", "recorda\u00e7\u00e3o", "=", "sensibilidade", "=", "VERDADEIRA", "taxa", "positiva", ",", "mas", "especificidade", "e", "precis\u00e3o", "s\u00e3o", "medidas", "totalmente", "diferentes", "."], "sentence-detokenized": "Uma combina\u00e7\u00e3o n\u00e3o relacionada mas comummente utilizada de estat\u00edsticas b\u00e1sicas da recupera\u00e7\u00e3o de informa\u00e7\u00e3o \u00e9 a pontua\u00e7\u00e3o F, sendo uma m\u00e9dia harm\u00f3nica (possivelmente ponderada) de recorda\u00e7\u00e3o e precis\u00e3o onde recorda\u00e7\u00e3o = sensibilidade = VERDADEIRA taxa positiva, mas especificidade e precis\u00e3o s\u00e3o medidas totalmente diferentes.", "token2charspan": [[0, 3], [4, 14], [15, 18], [19, 30], [31, 34], [35, 45], [46, 55], [56, 58], [59, 71], [72, 79], [80, 82], [83, 94], [95, 97], [98, 108], [109, 110], [111, 112], [113, 122], [123, 124], [124, 125], [126, 131], [132, 135], [136, 141], [142, 151], [152, 153], [153, 166], [167, 176], [176, 177], [178, 180], [181, 191], [192, 193], [194, 202], [203, 207], [208, 218], [219, 220], [221, 234], [235, 236], [237, 247], [248, 252], [253, 261], [261, 262], [263, 266], [267, 281], [282, 283], [284, 292], [293, 296], [297, 304], [305, 315], [316, 326], [326, 327]]}
{"doc_key": "ai-test-144", "ner": [[0, 2, "field"], [11, 11, "field"], [13, 13, "field"], [15, 15, "field"], [17, 17, "field"], [19, 20, "field"], [29, 31, "product"], [33, 35, "product"], [37, 38, "product"], [40, 41, "product"], [54, 56, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 2, 11, 11, "origin", "takes_inspiration_from", false, false], [0, 2, 13, 13, "origin", "takes_inspiration_from", false, false], [0, 2, 15, 15, "origin", "takes_inspiration_from", false, false], [0, 2, 17, 17, "origin", "takes_inspiration_from", false, false], [0, 2, 19, 20, "origin", "takes_inspiration_from", false, false], [29, 31, 0, 2, "origin", "", false, false], [33, 35, 0, 2, "origin", "", false, false], [37, 38, 0, 2, "origin", "", false, false], [40, 41, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["A", "engenharia", "neurom\u00f3rfica", "\u00e9", "uma", "disciplina", "interdisciplinar", "que", "se", "inspira", "na", "biologia", ",", "f\u00edsica", ",", "matem\u00e1tica", ",", "inform\u00e1tica", "e", "engenharia", "electr\u00f3nica", "para", "conceber", "sistemas", "neurais", "artificiais", ",", "tais", "como", "sistemas", "de", "vis\u00e3o", ",", "sistemas", "de", "cabe\u00e7a-olho", ",", "processadores", "auditivos", "e", "rob\u00f4s", "aut\u00f3nomos", ",", "cuja", "arquitectura", "f\u00edsica", "e", "princ\u00edpios", "de", "concep\u00e7\u00e3o", "se", "baseiam", "nos", "dos", "sistemas", "nervosos", "biol\u00f3gicos", "."], "sentence-detokenized": "A engenharia neurom\u00f3rfica \u00e9 uma disciplina interdisciplinar que se inspira na biologia, f\u00edsica, matem\u00e1tica, inform\u00e1tica e engenharia electr\u00f3nica para conceber sistemas neurais artificiais, tais como sistemas de vis\u00e3o, sistemas de cabe\u00e7a-olho, processadores auditivos e rob\u00f4s aut\u00f3nomos, cuja arquitectura f\u00edsica e princ\u00edpios de concep\u00e7\u00e3o se baseiam nos dos sistemas nervosos biol\u00f3gicos.", "token2charspan": [[0, 1], [2, 12], [13, 25], [26, 27], [28, 31], [32, 42], [43, 59], [60, 63], [64, 66], [67, 74], [75, 77], [78, 86], [86, 87], [88, 94], [94, 95], [96, 106], [106, 107], [108, 119], [120, 121], [122, 132], [133, 144], [145, 149], [150, 158], [159, 167], [168, 175], [176, 187], [187, 188], [189, 193], [194, 198], [199, 207], [208, 210], [211, 216], [216, 217], [218, 226], [227, 229], [230, 241], [241, 242], [243, 256], [257, 266], [267, 268], [269, 274], [275, 284], [284, 285], [286, 290], [291, 303], [304, 310], [311, 312], [313, 323], [324, 326], [327, 336], [337, 339], [340, 347], [348, 351], [352, 355], [356, 364], [365, 373], [374, 384], [384, 385]]}
{"doc_key": "ai-test-145", "ner": [[5, 9, "metrics"], [13, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 13, 5, 9, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Para", "ser", "espec\u00edfico", ",", "o", "crit\u00e9rio", "de", "estabilidade", "da", "BIBO", "exige", "que", "o", "ROC", "do", "sistema", "inclua", "o", "c\u00edrculo", "unit\u00e1rio", "."], "sentence-detokenized": "Para ser espec\u00edfico, o crit\u00e9rio de estabilidade da BIBO exige que o ROC do sistema inclua o c\u00edrculo unit\u00e1rio.", "token2charspan": [[0, 4], [5, 8], [9, 19], [19, 20], [21, 22], [23, 31], [32, 34], [35, 47], [48, 50], [51, 55], [56, 61], [62, 65], [66, 67], [68, 71], [72, 74], [75, 82], [83, 89], [90, 91], [92, 99], [100, 108], [108, 109]]}
{"doc_key": "ai-test-146", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2", "O", "programa", "foi", "reescrito", "em", "Java", "a", "partir", "de", "1998", "."], "sentence-detokenized": "2 O programa foi reescrito em Java a partir de 1998.", "token2charspan": [[0, 1], [2, 3], [4, 12], [13, 16], [17, 26], [27, 29], [30, 34], [35, 36], [37, 43], [44, 46], [47, 51], [51, 52]]}
{"doc_key": "ai-test-147", "ner": [[1, 1, "metrics"], [9, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 1, 9, 11, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["O", "MCC", "pode", "ser", "calculado", "directamente", "a", "partir", "da", "matriz", "de", "confus\u00e3o", "usando", "a", "f\u00f3rmula", ":"], "sentence-detokenized": "O MCC pode ser calculado directamente a partir da matriz de confus\u00e3o usando a f\u00f3rmula:", "token2charspan": [[0, 1], [2, 5], [6, 10], [11, 14], [15, 24], [25, 37], [38, 39], [40, 46], [47, 49], [50, 56], [57, 59], [60, 68], [69, 75], [76, 77], [78, 85], [85, 86]]}
{"doc_key": "ai-test-148", "ner": [[6, 9, "organisation"], [16, 23, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 9, 16, 23, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Foi", "desenvolvido", "por", "uma", "equipa", "do", "MIT-IBM", "Watson", "AI", "Lab", "e", "apresentado", "pela", "primeira", "vez", "na", "Confer\u00eancia", "Internacional", "sobre", "Representa\u00e7\u00f5es", "de", "Aprendizagem", "de", "2018", "."], "sentence-detokenized": "Foi desenvolvido por uma equipa do MIT-IBM Watson AI Lab e apresentado pela primeira vez na Confer\u00eancia Internacional sobre Representa\u00e7\u00f5es de Aprendizagem de 2018.", "token2charspan": [[0, 3], [4, 16], [17, 20], [21, 24], [25, 31], [32, 34], [35, 42], [43, 49], [50, 52], [53, 56], [57, 58], [59, 70], [71, 75], [76, 84], [85, 88], [89, 91], [92, 103], [104, 117], [118, 123], [124, 138], [139, 141], [142, 154], [155, 157], [158, 162], [162, 163]]}
{"doc_key": "ai-test-149", "ner": [[2, 3, "metrics"], [14, 15, "metrics"], [17, 17, "metrics"], [43, 43, "metrics"], [45, 45, "metrics"], [52, 55, "metrics"], [59, 59, "metrics"], [61, 61, "metrics"], [63, 63, "metrics"], [68, 68, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[14, 15, 43, 43, "type-of", "", false, false], [14, 15, 52, 55, "related-to", "collapses_to_identity", false, false], [17, 17, 45, 45, "type-of", "", false, false], [17, 17, 52, 55, "related-to", "collapses_to_identity", false, false], [17, 17, 63, 63, "named", "same", false, false], [59, 59, 68, 68, "related-to", "collapses_to_identity", false, false], [61, 61, 68, 68, "related-to", "collapses_to_identity", false, false], [63, 63, 68, 68, "related-to", "collapses_to_identity", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Quando", "as", "preval\u00eancias", "VERDADEIRAS", "para", "as", "duas", "vari\u00e1veis", "positivas", "s\u00e3o", "iguais", "\u00e0s", "assumidas", "em", "Fleiss", "kappa", "e", "F-score", ",", "ou", "seja", ",", "o", "n\u00famero", "de", "previs\u00f5es", "positivas", "corresponde", "ao", "n\u00famero", "de", "classes", "positivas", "no", "caso", "dicot\u00f3mico", "(", "duas", "classes", ")", ",", "as", "diferentes", "kappa", "e", "correla\u00e7\u00e3o", "medem", "o", "colapso", "da", "identidade", "com", "o", "J", "de", "Youden", ",", "e", "a", "recorda\u00e7\u00e3o", ",", "precis\u00e3o", "e", "F-score", "s\u00e3o", "igualmente", "id\u00eanticas", "com", "precis\u00e3o", "."], "sentence-detokenized": "Quando as preval\u00eancias VERDADEIRAS para as duas vari\u00e1veis positivas s\u00e3o iguais \u00e0s assumidas em Fleiss kappa e F-score, ou seja, o n\u00famero de previs\u00f5es positivas corresponde ao n\u00famero de classes positivas no caso dicot\u00f3mico (duas classes), as diferentes kappa e correla\u00e7\u00e3o medem o colapso da identidade com o J de Youden, e a recorda\u00e7\u00e3o, precis\u00e3o e F-score s\u00e3o igualmente id\u00eanticas com precis\u00e3o.", "token2charspan": [[0, 6], [7, 9], [10, 22], [23, 34], [35, 39], [40, 42], [43, 47], [48, 57], [58, 67], [68, 71], [72, 78], [79, 81], [82, 91], [92, 94], [95, 101], [102, 107], [108, 109], [110, 117], [117, 118], [119, 121], [122, 126], [126, 127], [128, 129], [130, 136], [137, 139], [140, 149], [150, 159], [160, 171], [172, 174], [175, 181], [182, 184], [185, 192], [193, 202], [203, 205], [206, 210], [211, 221], [222, 223], [223, 227], [228, 235], [235, 236], [236, 237], [238, 240], [241, 251], [252, 257], [258, 259], [260, 270], [271, 276], [277, 278], [279, 286], [287, 289], [290, 300], [301, 304], [305, 306], [307, 308], [309, 311], [312, 318], [318, 319], [320, 321], [322, 323], [324, 334], [334, 335], [336, 344], [345, 346], [347, 354], [355, 358], [359, 369], [370, 379], [380, 383], [384, 392], [392, 393]]}
{"doc_key": "ai-test-150", "ner": [[1, 4, "misc"], [6, 6, "misc"], [9, 9, "conference"], [13, 17, "task"], [18, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 4, 9, 9, "part-of", "", false, false], [1, 4, 9, 9, "physical", "", false, false], [1, 4, 9, 9, "temporal", "", false, false], [6, 6, 1, 4, "named", "", false, false], [13, 17, 1, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["O", "workshop", "Building", "Educational", "Applications", "(", "BEA", ")", "na", "NAACL", "2013", "acolheu", "a", "tarefa", "comum", "inaugural", "NLI", ".", "Tetreault", "et", "al", ",", "2013", "O", "concurso", "resultou", "em", "29", "participa\u00e7\u00f5es", "de", "equipas", "de", "todo", "o", "mundo", ",", "24", "das", "quais", "tamb\u00e9m", "publicaram", "um", "artigo", "descrevendo", "os", "seus", "sistemas", "e", "abordagens", "."], "sentence-detokenized": "O workshop Building Educational Applications (BEA) na NAACL 2013 acolheu a tarefa comum inaugural NLI. Tetreault et al, 2013 O concurso resultou em 29 participa\u00e7\u00f5es de equipas de todo o mundo, 24 das quais tamb\u00e9m publicaram um artigo descrevendo os seus sistemas e abordagens.", "token2charspan": [[0, 1], [2, 10], [11, 19], [20, 31], [32, 44], [45, 46], [46, 49], [49, 50], [51, 53], [54, 59], [60, 64], [65, 72], [73, 74], [75, 81], [82, 87], [88, 97], [98, 101], [101, 102], [103, 112], [113, 115], [116, 118], [118, 119], [120, 124], [125, 126], [127, 135], [136, 144], [145, 147], [148, 150], [151, 164], [165, 167], [168, 175], [176, 178], [179, 183], [184, 185], [186, 191], [191, 192], [193, 195], [196, 199], [200, 205], [206, 212], [213, 223], [224, 226], [227, 233], [234, 245], [246, 248], [249, 253], [254, 262], [263, 264], [265, 275], [275, 276]]}
{"doc_key": "ai-test-151", "ner": [[1, 3, "algorithm"], [6, 9, "algorithm"], [17, 18, "misc"], [20, 22, "misc"], [36, 38, "misc"], [40, 42, "algorithm"], [44, 44, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 3, 6, 9, "type-of", "", false, false], [1, 3, 17, 18, "related-to", "finds", false, false], [20, 22, 17, 18, "type-of", "", false, false], [44, 44, 40, 42, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["O", "algoritmo", "de", "Viterbi", "\u00e9", "um", "algoritmo", "din\u00e2mico", "de", "programa\u00e7\u00e3o", "para", "encontrar", "a", "sequ\u00eancia", "mais", "prov\u00e1vel", "de", "estados", "ocultos", "chamada", "caminho", "de", "Viterbi", "que", "resulta", "numa", "sequ\u00eancia", "de", "eventos", "observados", ",", "especialmente", "no", "contexto", "de", "fontes", "de", "informa\u00e7\u00e3o", "Markov", "e", "modelos", "Markov", "ocultos", "(", "HMM", ")", "."], "sentence-detokenized": "O algoritmo de Viterbi \u00e9 um algoritmo din\u00e2mico de programa\u00e7\u00e3o para encontrar a sequ\u00eancia mais prov\u00e1vel de estados ocultos chamada caminho de Viterbi que resulta numa sequ\u00eancia de eventos observados, especialmente no contexto de fontes de informa\u00e7\u00e3o Markov e modelos Markov ocultos (HMM).", "token2charspan": [[0, 1], [2, 11], [12, 14], [15, 22], [23, 24], [25, 27], [28, 37], [38, 46], [47, 49], [50, 61], [62, 66], [67, 76], [77, 78], [79, 88], [89, 93], [94, 102], [103, 105], [106, 113], [114, 121], [122, 129], [130, 137], [138, 140], [141, 148], [149, 152], [153, 160], [161, 165], [166, 175], [176, 178], [179, 186], [187, 197], [197, 198], [199, 212], [213, 215], [216, 224], [225, 227], [228, 234], [235, 237], [238, 248], [249, 255], [256, 257], [258, 265], [266, 272], [273, 280], [281, 282], [282, 285], [285, 286], [286, 287]]}
{"doc_key": "ai-test-152", "ner": [[1, 1, "field"], [4, 6, "algorithm"], [9, 11, "misc"], [15, 16, "algorithm"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 1, 1, "part-of", "", false, false], [4, 6, 9, 11, "general-affiliation", "", false, false], [4, 6, 15, 16, "related-to", "generalizes_from", false, false], [4, 6, 18, 19, "related-to", "generalizes_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Em", "estat\u00edstica", ",", "a", "regress\u00e3o", "log\u00edstica", "multinomial", "\u00e9", "um", "m\u00e9todo", "de", "classifica\u00e7\u00e3o", "que", "generaliza", "a", "regress\u00e3o", "log\u00edstica", "\u00e0", "classifica\u00e7\u00e3o", "multiclasse", ",", "ou", "seja", ",", "com", "mais", "de", "dois", "poss\u00edveis", "resultados", "discretos", "."], "sentence-detokenized": "Em estat\u00edstica, a regress\u00e3o log\u00edstica multinomial \u00e9 um m\u00e9todo de classifica\u00e7\u00e3o que generaliza a regress\u00e3o log\u00edstica \u00e0 classifica\u00e7\u00e3o multiclasse, ou seja, com mais de dois poss\u00edveis resultados discretos.", "token2charspan": [[0, 2], [3, 14], [14, 15], [16, 17], [18, 27], [28, 37], [38, 49], [50, 51], [52, 54], [55, 61], [62, 64], [65, 78], [79, 82], [83, 93], [94, 95], [96, 105], [106, 115], [116, 117], [118, 131], [132, 143], [143, 144], [145, 147], [148, 152], [152, 153], [154, 157], [158, 162], [163, 165], [166, 170], [171, 180], [181, 191], [192, 201], [201, 202]]}
{"doc_key": "ai-test-153", "ner": [[0, 3, "algorithm"], [10, 12, "field"], [15, 18, "field"], [21, 21, "task"], [24, 26, "task"], [29, 31, "task"], [33, 34, "researcher"], [36, 37, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 3, 10, 12, "part-of", "", false, false], [0, 3, 15, 18, "part-of", "", false, false], [21, 21, 0, 3, "usage", "", true, false], [24, 26, 0, 3, "usage", "", true, false], [29, 31, 0, 3, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Os", "modelos", "Markov", "escondidos", "s\u00e3o", "conhecidos", "pelas", "suas", "aplica\u00e7\u00f5es", "para", "refor\u00e7ar", "a", "aprendizagem", "e", "o", "reconhecimento", "de", "padr\u00f5es", "temporais", "como", "a", "fala", ",", "o", "reconhecimento", "da", "caligrafia", ",", "o", "reconhecimento", "de", "gestos", ",", "Thad", "Starner", ",", "Alex", "Pentland", "."], "sentence-detokenized": "Os modelos Markov escondidos s\u00e3o conhecidos pelas suas aplica\u00e7\u00f5es para refor\u00e7ar a aprendizagem e o reconhecimento de padr\u00f5es temporais como a fala, o reconhecimento da caligrafia, o reconhecimento de gestos, Thad Starner, Alex Pentland.", "token2charspan": [[0, 2], [3, 10], [11, 17], [18, 28], [29, 32], [33, 43], [44, 49], [50, 54], [55, 65], [66, 70], [71, 79], [80, 81], [82, 94], [95, 96], [97, 98], [99, 113], [114, 116], [117, 124], [125, 134], [135, 139], [140, 141], [142, 146], [146, 147], [148, 149], [150, 164], [165, 167], [168, 178], [178, 179], [180, 181], [182, 196], [197, 199], [200, 206], [206, 207], [208, 212], [213, 220], [220, 221], [222, 226], [227, 235], [235, 236]]}
{"doc_key": "ai-test-154", "ner": [[6, 6, "misc"], [30, 33, "metrics"], [35, 35, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 35, 35, "named", "", false, false], [30, 33, 35, 35, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Essencialmente", ",", "isto", "significa", "que", "se", "ent\u00e3o-grama", "foi", "visto", "mais", "do", "que", "k", "vezes", "em", "treino", ",", "a", "probabilidade", "condicional", "de", "uma", "palavra", "dada", "a", "sua", "hist\u00f3ria", "\u00e9", "proporcional", "\u00e0", "estimativa", "de", "m\u00e1xima", "probabilidade", "desse", "-grama", "."], "sentence-detokenized": "Essencialmente, isto significa que se ent\u00e3o-grama foi visto mais do que k vezes em treino, a probabilidade condicional de uma palavra dada a sua hist\u00f3ria \u00e9 proporcional \u00e0 estimativa de m\u00e1xima probabilidade desse -grama.", "token2charspan": [[0, 14], [14, 15], [16, 20], [21, 30], [31, 34], [35, 37], [38, 49], [50, 53], [54, 59], [60, 64], [65, 67], [68, 71], [72, 73], [74, 79], [80, 82], [83, 89], [89, 90], [91, 92], [93, 106], [107, 118], [119, 121], [122, 125], [126, 133], [134, 138], [139, 140], [141, 144], [145, 153], [154, 155], [156, 168], [169, 170], [171, 181], [182, 184], [185, 191], [192, 205], [206, 211], [212, 218], [218, 219]]}
{"doc_key": "ai-test-155", "ner": [[3, 5, "task"], [8, 9, "task"], [12, 15, "task"], [23, 26, "task"], [35, 36, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[35, 36, 23, 26, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Est\u00e1", "interessado", "na", "representa\u00e7\u00e3o", "do", "conhecimento", ",", "no", "racioc\u00ednio", "comum", "e", "na", "compreens\u00e3o", "da", "linguagem", "natural", ",", "acreditando", "que", ",", "actualmente", ",", "a", "compreens\u00e3o", "profunda", "da", "linguagem", "s\u00f3", "pode", "ser", "alcan\u00e7ada", "atrav\u00e9s", "de", "uma", "significativa", "engenharia", "manual", "de", "formalismos", "semanticamente", "ricos", "aliada", "a", "prefer\u00eancias", "estat\u00edsticas", "."], "sentence-detokenized": "Est\u00e1 interessado na representa\u00e7\u00e3o do conhecimento, no racioc\u00ednio comum e na compreens\u00e3o da linguagem natural, acreditando que, actualmente, a compreens\u00e3o profunda da linguagem s\u00f3 pode ser alcan\u00e7ada atrav\u00e9s de uma significativa engenharia manual de formalismos semanticamente ricos aliada a prefer\u00eancias estat\u00edsticas.", "token2charspan": [[0, 4], [5, 16], [17, 19], [20, 33], [34, 36], [37, 49], [49, 50], [51, 53], [54, 64], [65, 70], [71, 72], [73, 75], [76, 87], [88, 90], [91, 100], [101, 108], [108, 109], [110, 121], [122, 125], [125, 126], [127, 138], [138, 139], [140, 141], [142, 153], [154, 162], [163, 165], [166, 175], [176, 178], [179, 183], [184, 187], [188, 197], [198, 205], [206, 208], [209, 212], [213, 226], [227, 237], [238, 244], [245, 247], [248, 259], [260, 274], [275, 280], [281, 287], [288, 289], [290, 302], [303, 315], [315, 316]]}
{"doc_key": "ai-test-156", "ner": [[1, 1, "programlang"], [3, 3, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Em", "JavaScript", ",", "Python", "ou"], "sentence-detokenized": "Em JavaScript, Python ou", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 21], [22, 24]]}
{"doc_key": "ai-test-157", "ner": [[1, 2, "misc"], [6, 7, "misc"], [10, 10, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 6, 7, "part-of", "", false, false], [6, 7, 10, 10, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Os", "Pr\u00e9mios", "Newcomb", "s\u00e3o", "anunciados", "na", "Revista", "AI", "publicada", "pela", "AAAI", "."], "sentence-detokenized": "Os Pr\u00e9mios Newcomb s\u00e3o anunciados na Revista AI publicada pela AAAI.", "token2charspan": [[0, 2], [3, 10], [11, 18], [19, 22], [23, 33], [34, 36], [37, 44], [45, 47], [48, 57], [58, 62], [63, 67], [67, 68]]}
{"doc_key": "ai-test-158", "ner": [[1, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["O", "erro", "m\u00e9dio", "ao", "quadrado", "num", "conjunto", "de", "100", "exemplares", "\u00e9", "de", "0,084", ",", "menor", "do", "que", "o", "erro", "n\u00e3o", "normalizado", "."], "sentence-detokenized": "O erro m\u00e9dio ao quadrado num conjunto de 100 exemplares \u00e9 de 0,084, menor do que o erro n\u00e3o normalizado.", "token2charspan": [[0, 1], [2, 6], [7, 12], [13, 15], [16, 24], [25, 28], [29, 37], [38, 40], [41, 44], [45, 55], [56, 57], [58, 60], [61, 66], [66, 67], [68, 73], [74, 76], [77, 80], [81, 82], [83, 87], [88, 91], [92, 103], [103, 104]]}
{"doc_key": "ai-test-159", "ner": [[1, 1, "metrics"], [9, 12, "field"], [19, 22, "task"], [24, 24, "task"], [28, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 12, 1, 1, "usage", "", false, false], [19, 22, 9, 12, "part-of", "task_part_of_field", false, false], [24, 24, 19, 22, "named", "", false, false], [28, 30, 9, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["O", "F-score", "tem", "sido", "amplamente", "utilizado", "na", "literatura", "de", "processamento", "da", "linguagem", "natural", ",", "tal", "como", "a", "avalia\u00e7\u00e3o", "do", "reconhecimento", "da", "entidade", "nomeada", "(", "NER", ")", "e", "a", "segmenta\u00e7\u00e3o", "de", "palavras", "."], "sentence-detokenized": "O F-score tem sido amplamente utilizado na literatura de processamento da linguagem natural, tal como a avalia\u00e7\u00e3o do reconhecimento da entidade nomeada (NER) e a segmenta\u00e7\u00e3o de palavras.", "token2charspan": [[0, 1], [2, 9], [10, 13], [14, 18], [19, 29], [30, 39], [40, 42], [43, 53], [54, 56], [57, 70], [71, 73], [74, 83], [84, 91], [91, 92], [93, 96], [97, 101], [102, 103], [104, 113], [114, 116], [117, 131], [132, 134], [135, 143], [144, 151], [152, 153], [153, 156], [156, 157], [158, 159], [160, 161], [162, 173], [174, 176], [177, 185], [185, 186]]}
{"doc_key": "ai-test-160", "ner": [[0, 1, "product"], [6, 8, "product"], [18, 20, "misc"], [25, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 18, 20, "related-to", "performs_task", false, false], [0, 1, 25, 27, "related-to", "performs_task", false, false], [6, 8, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Os", "Chatbots", "s\u00e3o", "tipicamente", "utilizados", "em", "sistemas", "de", "di\u00e1logo", "para", "v\u00e1rios", "fins", ",", "incluindo", "servi\u00e7o", "ao", "cliente", ",", "encaminhamento", "de", "pedidos", ",", "ou", "para", "a", "recolha", "de", "informa\u00e7\u00f5es", "."], "sentence-detokenized": "Os Chatbots s\u00e3o tipicamente utilizados em sistemas de di\u00e1logo para v\u00e1rios fins, incluindo servi\u00e7o ao cliente, encaminhamento de pedidos, ou para a recolha de informa\u00e7\u00f5es.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 27], [28, 38], [39, 41], [42, 50], [51, 53], [54, 61], [62, 66], [67, 73], [74, 78], [78, 79], [80, 89], [90, 97], [98, 100], [101, 108], [108, 109], [110, 124], [125, 127], [128, 135], [135, 136], [137, 139], [140, 144], [145, 146], [147, 154], [155, 157], [158, 169], [169, 170]]}
{"doc_key": "ai-test-161", "ner": [[5, 11, "conference"], [16, 24, "conference"], [31, 41, "conference"], [48, 48, "conference"], [51, 54, "conference"], [57, 58, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[16, 24, 5, 11, "named", "", false, false], [31, 41, 5, 11, "named", "", false, false], [48, 48, 31, 41, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["As", "revistas", "importantes", "incluem", "as", "IEEE", "Transactions", "on", "Speech", "and", "Audio", "Processing", "(", "mais", "tarde", "rebaptizada", "IEEE", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "e", "desde", "Setembro", "de", "2014", "rebaptizada", "IEEE", "/", "ACM", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "-", "ap\u00f3s", "fus\u00e3o", "com", "uma", "publica\u00e7\u00e3o", "ACM", ")", ",", "Computer", "Speech", "and", "Language", ",", "e", "Speech", "Communication", "."], "sentence-detokenized": "As revistas importantes incluem as IEEE Transactions on Speech and Audio Processing (mais tarde rebaptizada IEEE Transactions on Audio, Speech and Language Processing e desde Setembro de 2014 rebaptizada IEEE / ACM Transactions on Audio, Speech and Language Processing - ap\u00f3s fus\u00e3o com uma publica\u00e7\u00e3o ACM), Computer Speech and Language, e Speech Communication.", "token2charspan": [[0, 2], [3, 11], [12, 23], [24, 31], [32, 34], [35, 39], [40, 52], [53, 55], [56, 62], [63, 66], [67, 72], [73, 83], [84, 85], [85, 89], [90, 95], [96, 107], [108, 112], [113, 125], [126, 128], [129, 134], [134, 135], [136, 142], [143, 146], [147, 155], [156, 166], [167, 168], [169, 174], [175, 183], [184, 186], [187, 191], [192, 203], [204, 208], [209, 210], [211, 214], [215, 227], [228, 230], [231, 236], [236, 237], [238, 244], [245, 248], [249, 257], [258, 268], [269, 270], [271, 275], [276, 281], [282, 285], [286, 289], [290, 300], [301, 304], [304, 305], [305, 306], [307, 315], [316, 322], [323, 326], [327, 335], [335, 336], [337, 338], [339, 345], [346, 359], [359, 360]]}
{"doc_key": "ai-test-162", "ner": [[0, 1, "algorithm"], [6, 8, "task"], [10, 12, "field"], [14, 16, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 8, 0, 1, "usage", "", false, false], [6, 8, 10, 12, "part-of", "task_part_of_field", false, false], [6, 8, 14, 16, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["O", "EM", "\u00e9", "frequentemente", "utilizado", "para", "agrupamento", "de", "dados", "na", "aprendizagem", "de", "m\u00e1quinas", "e", "vis\u00e3o", "por", "computador", "."], "sentence-detokenized": "O EM \u00e9 frequentemente utilizado para agrupamento de dados na aprendizagem de m\u00e1quinas e vis\u00e3o por computador.", "token2charspan": [[0, 1], [2, 4], [5, 6], [7, 21], [22, 31], [32, 36], [37, 48], [49, 51], [52, 57], [58, 60], [61, 73], [74, 76], [77, 85], [86, 87], [88, 93], [94, 97], [98, 108], [108, 109]]}
{"doc_key": "ai-test-163", "ner": [[9, 11, "metrics"], [25, 30, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 25, 30, "related-to", "described_by", false, false]], "relations_mapping_to_source": [0], "sentence": ["Embora", "n\u00e3o", "exista", "uma", "forma", "perfeita", "de", "descrever", "a", "matriz", "de", "confus\u00e3o", "de", "VERDADEIRO", "e", "FALSO", "positivo", "e", "negativo", "por", "um", "\u00fanico", "n\u00famero", ",", "o", "coeficiente", "de", "correla\u00e7\u00e3o", "de", "Matthews", "\u00e9", "geralmente", "considerado", "como", "sendo", "uma", "das", "melhores", "medidas", "deste", "tipo", "."], "sentence-detokenized": "Embora n\u00e3o exista uma forma perfeita de descrever a matriz de confus\u00e3o de VERDADEIRO e FALSO positivo e negativo por um \u00fanico n\u00famero, o coeficiente de correla\u00e7\u00e3o de Matthews \u00e9 geralmente considerado como sendo uma das melhores medidas deste tipo.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 21], [22, 27], [28, 36], [37, 39], [40, 49], [50, 51], [52, 58], [59, 61], [62, 70], [71, 73], [74, 84], [85, 86], [87, 92], [93, 101], [102, 103], [104, 112], [113, 116], [117, 119], [120, 125], [126, 132], [132, 133], [134, 135], [136, 147], [148, 150], [151, 161], [162, 164], [165, 173], [174, 175], [176, 186], [187, 198], [199, 203], [204, 209], [210, 213], [214, 217], [218, 226], [227, 234], [235, 240], [241, 245], [245, 246]]}
{"doc_key": "ai-test-164", "ner": [[14, 17, "field"], [35, 35, "field"], [41, 43, "field"], [47, 48, "algorithm"], [50, 52, "task"], [54, 55, "algorithm"], [60, 64, "algorithm"], [66, 68, "algorithm"], [74, 77, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[41, 43, 35, 35, "part-of", "subfield", false, false], [47, 48, 41, 43, "part-of", "", false, true], [50, 52, 41, 43, "part-of", "", false, true], [54, 55, 41, 43, "part-of", "", false, true], [60, 64, 41, 43, "part-of", "", false, true], [66, 68, 41, 43, "part-of", "", false, true], [74, 77, 41, 43, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["\u00c0", "medida", "que", "os", "conjuntos", "de", "dados", "cresceram", "em", "tamanho", "e", "complexidade", ",", "a", "an\u00e1lise", "directa", "de", "dados", "pr\u00e1ticos", "foi", "aumentada", "com", "o", "processamento", "indirecto", "e", "automatizado", "de", "dados", ",", "auxiliado", "por", "outras", "descobertas", "na", "inform\u00e1tica", ",", "especialmente", "no", "campo", "da", "aprendizagem", "de", "m\u00e1quinas", ",", "tais", "como", "redes", "neurais", ",", "an\u00e1lise", "de", "clusters", ",", "algoritmos", "gen\u00e9ticos", "(", "1950s", ")", ",", "aprendizagem", "em", "\u00e1rvore", "de", "decis\u00e3o", "e", "regras", "de", "decis\u00e3o", "(", "1960s", ")", ",", "e", "m\u00e1quinas", "vectoriais", "de", "apoio", "(", "1990s", ")", "."], "sentence-detokenized": "\u00c0 medida que os conjuntos de dados cresceram em tamanho e complexidade, a an\u00e1lise directa de dados pr\u00e1ticos foi aumentada com o processamento indirecto e automatizado de dados, auxiliado por outras descobertas na inform\u00e1tica, especialmente no campo da aprendizagem de m\u00e1quinas, tais como redes neurais, an\u00e1lise de clusters, algoritmos gen\u00e9ticos (1950s), aprendizagem em \u00e1rvore de decis\u00e3o e regras de decis\u00e3o (1960s), e m\u00e1quinas vectoriais de apoio (1990s).", "token2charspan": [[0, 1], [2, 8], [9, 12], [13, 15], [16, 25], [26, 28], [29, 34], [35, 44], [45, 47], [48, 55], [56, 57], [58, 70], [70, 71], [72, 73], [74, 81], [82, 89], [90, 92], [93, 98], [99, 107], [108, 111], [112, 121], [122, 125], [126, 127], [128, 141], [142, 151], [152, 153], [154, 166], [167, 169], [170, 175], [175, 176], [177, 186], [187, 190], [191, 197], [198, 209], [210, 212], [213, 224], [224, 225], [226, 239], [240, 242], [243, 248], [249, 251], [252, 264], [265, 267], [268, 276], [276, 277], [278, 282], [283, 287], [288, 293], [294, 301], [301, 302], [303, 310], [311, 313], [314, 322], [322, 323], [324, 334], [335, 344], [345, 346], [346, 351], [351, 352], [352, 353], [354, 366], [367, 369], [370, 376], [377, 379], [380, 387], [388, 389], [390, 396], [397, 399], [400, 407], [408, 409], [409, 414], [414, 415], [415, 416], [417, 418], [419, 427], [428, 438], [439, 441], [442, 447], [448, 449], [449, 454], [454, 455], [455, 456]]}
{"doc_key": "ai-test-165", "ner": [[5, 5, "researcher"], [10, 11, "misc"], [20, 21, "researcher"], [23, 24, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 11, 5, 5, "artifact", "", false, false], [10, 11, 20, 21, "artifact", "", false, false], [10, 11, 23, 24, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["No", "Outono", "de", "2005", ",", "Thrun", "publicou", "um", "livro", "intitulado", "Rob\u00f3tica", "Probabil\u00edstica", "juntamente", "com", "os", "seus", "colegas", "de", "longa", "data", "Dieter", "Fox", "e", "Wolfram", "Burgard", "."], "sentence-detokenized": "No Outono de 2005, Thrun publicou um livro intitulado Rob\u00f3tica Probabil\u00edstica juntamente com os seus colegas de longa data Dieter Fox e Wolfram Burgard.", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 17], [17, 18], [19, 24], [25, 33], [34, 36], [37, 42], [43, 53], [54, 62], [63, 77], [78, 88], [89, 92], [93, 95], [96, 100], [101, 108], [109, 111], [112, 117], [118, 122], [123, 129], [130, 133], [134, 135], [136, 143], [144, 151], [151, 152]]}
{"doc_key": "ai-test-166", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 7, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["John", "D.", "Lafferty", ",", "Andrew", "McCallum", "e", "Pereiramath", ",", "como", "se", "segue", ":"], "sentence-detokenized": "John D. Lafferty, Andrew McCallum e Pereiramath, como se segue:", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 24], [25, 33], [34, 35], [36, 47], [47, 48], [49, 53], [54, 56], [57, 62], [62, 63]]}
{"doc_key": "ai-test-167", "ner": [[0, 3, "task"], [5, 5, "task"], [15, 17, "field"], [19, 22, "field"], [24, 24, "field"]], "ner_mapping_to_source": [0, 1, 3, 4, 5], "relations": [[0, 3, 15, 17, "part-of", "task_part_of_field", false, false], [0, 3, 19, 22, "part-of", "task_part_of_field", false, false], [5, 5, 0, 3, "named", "", false, false], [24, 24, 19, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 5], "sentence": ["A", "resposta", "a", "perguntas", "(", "GQ", ")", "\u00e9", "uma", "disciplina", "inform\u00e1tica", "dentro", "dos", "campos", "da", "recupera\u00e7\u00e3o", "de", "informa\u00e7\u00e3o", "e", "processamento", "de", "linguagem", "natural", "(", "PNL", ")", ",", "que", "se", "ocupa", "da", "constru\u00e7\u00e3o", "de", "sistemas", "que", "respondem", "automaticamente", "a", "perguntas", "feitas", "por", "seres", "humanos", "numa", "linguagem", "natural", "."], "sentence-detokenized": "A resposta a perguntas (GQ) \u00e9 uma disciplina inform\u00e1tica dentro dos campos da recupera\u00e7\u00e3o de informa\u00e7\u00e3o e processamento de linguagem natural (PNL), que se ocupa da constru\u00e7\u00e3o de sistemas que respondem automaticamente a perguntas feitas por seres humanos numa linguagem natural.", "token2charspan": [[0, 1], [2, 10], [11, 12], [13, 22], [23, 24], [24, 26], [26, 27], [28, 29], [30, 33], [34, 44], [45, 56], [57, 63], [64, 67], [68, 74], [75, 77], [78, 89], [90, 92], [93, 103], [104, 105], [106, 119], [120, 122], [123, 132], [133, 140], [141, 142], [142, 145], [145, 146], [146, 147], [148, 151], [152, 154], [155, 160], [161, 163], [164, 174], [175, 177], [178, 186], [187, 190], [191, 200], [201, 216], [217, 218], [219, 228], [229, 235], [236, 239], [240, 245], [246, 253], [254, 258], [259, 268], [269, 276], [276, 277]]}
{"doc_key": "ai-test-168", "ner": [[10, 10, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["No", "entanto", ",", "na", "vers\u00e3o", "da", "m\u00e9trica", "utilizada", "pelas", "avalia\u00e7\u00f5es", "NIST", "anteriores", "a", "2009", ",", "a", "frase", "de", "refer\u00eancia", "mais", "curta", "tinha", "sido", "utilizada", "em", "vez", "disso", "."], "sentence-detokenized": "No entanto, na vers\u00e3o da m\u00e9trica utilizada pelas avalia\u00e7\u00f5es NIST anteriores a 2009, a frase de refer\u00eancia mais curta tinha sido utilizada em vez disso.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 14], [15, 21], [22, 24], [25, 32], [33, 42], [43, 48], [49, 59], [60, 64], [65, 75], [76, 77], [78, 82], [82, 83], [84, 85], [86, 91], [92, 94], [95, 105], [106, 110], [111, 116], [117, 122], [123, 127], [128, 137], [138, 140], [141, 144], [145, 150], [150, 151]]}
{"doc_key": "ai-test-169", "ner": [[7, 8, "person"], [21, 21, "organisation"], [18, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 18, 19, "related-to", "invests_in", false, false], [18, 19, 21, 21, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "27", "de", "Agosto", "de", "2018", ",", "a", "Toyota", "anunciou", "um", "investimento", "de", "500", "milh\u00f5es", "de", "d\u00f3lares", "em", "autom\u00f3veis", "aut\u00f3nomos", "de", "Uber", "."], "sentence-detokenized": "A 27 de Agosto de 2018, a Toyota anunciou um investimento de 500 milh\u00f5es de d\u00f3lares em autom\u00f3veis aut\u00f3nomos de Uber.", "token2charspan": [[0, 1], [2, 4], [5, 7], [8, 14], [15, 17], [18, 22], [22, 23], [24, 25], [26, 32], [33, 41], [42, 44], [45, 57], [58, 60], [61, 64], [65, 72], [73, 75], [76, 83], [84, 86], [87, 97], [98, 107], [108, 110], [111, 115], [115, 116]]}
{"doc_key": "ai-test-170", "ner": [[5, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "amostra", "m\u00e1xima", "\u00e9", "o", "estimador", "de", "m\u00e1xima", "probabilidade", "para", "a", "popula\u00e7\u00e3o", "m\u00e1xima", ",", "mas", ",", "como", "discutido", "acima", ",", "\u00e9", "tendencioso", "."], "sentence-detokenized": "A amostra m\u00e1xima \u00e9 o estimador de m\u00e1xima probabilidade para a popula\u00e7\u00e3o m\u00e1xima, mas, como discutido acima, \u00e9 tendencioso.", "token2charspan": [[0, 1], [2, 9], [10, 16], [17, 18], [19, 20], [21, 30], [31, 33], [34, 40], [41, 54], [55, 59], [60, 61], [62, 71], [72, 78], [78, 79], [80, 83], [83, 84], [85, 89], [90, 99], [100, 105], [105, 106], [107, 108], [109, 120], [120, 121]]}
{"doc_key": "ai-test-171", "ner": [[0, 1, "task"], [6, 6, "misc"], [10, 10, "metrics"], [18, 21, "algorithm"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 6, 6, "related-to", "overcomes", false, false], [0, 1, 10, 10, "related-to", "increases", false, false], [6, 6, 18, 21, "opposite", "", false, false], [6, 6, 23, 25, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["O", "LSI", "ajuda", "a", "ultrapassar", "a", "sinon\u00edmia", ",", "aumentando", "a", "recorda\u00e7\u00e3o", ",", "uma", "das", "restri\u00e7\u00f5es", "mais", "problem\u00e1ticas", "das", "consultas", "de", "palavras-chave", "booleanas", "e", "modelos", "espaciais", "vectoriais", "."], "sentence-detokenized": "O LSI ajuda a ultrapassar a sinon\u00edmia, aumentando a recorda\u00e7\u00e3o, uma das restri\u00e7\u00f5es mais problem\u00e1ticas das consultas de palavras-chave booleanas e modelos espaciais vectoriais.", "token2charspan": [[0, 1], [2, 5], [6, 11], [12, 13], [14, 25], [26, 27], [28, 37], [37, 38], [39, 49], [50, 51], [52, 62], [62, 63], [64, 67], [68, 71], [72, 82], [83, 87], [88, 101], [102, 105], [106, 115], [116, 118], [119, 133], [134, 143], [144, 145], [146, 153], [154, 163], [164, 174], [174, 175]]}
{"doc_key": "ai-test-172", "ner": [[3, 5, "task"], [25, 25, "programlang"], [27, 27, "programlang"], [29, 29, "programlang"], [31, 33, "programlang"], [35, 36, "programlang"], [38, 38, "programlang"], [40, 40, "programlang"], [42, 42, "programlang"], [44, 44, "programlang"], [46, 46, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[3, 5, 25, 25, "general-affiliation", "", false, false], [3, 5, 27, 27, "general-affiliation", "", false, false], [3, 5, 29, 29, "general-affiliation", "", false, false], [3, 5, 31, 33, "general-affiliation", "", false, false], [3, 5, 35, 36, "general-affiliation", "", false, false], [3, 5, 38, 38, "general-affiliation", "", false, false], [3, 5, 40, 40, "general-affiliation", "", false, false], [3, 5, 42, 42, "general-affiliation", "", false, false], [3, 5, 44, 44, "general-affiliation", "", false, false], [3, 5, 46, 46, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["As", "aplica\u00e7\u00f5es", "de", "aquisi\u00e7\u00e3o", "de", "dados", "s\u00e3o", "geralmente", "controladas", "por", "programas", "de", "software", "desenvolvidos", "utilizando", "v\u00e1rias", "linguagens", "de", "programa\u00e7\u00e3o", "de", "uso", "geral", ",", "tais", "como", "Assembly", ",", "BASIC", ",", "C", ",", "C", "+", "+", ",", "C", "#", ",", "Fortran", ",", "Java", ",", "LabVIEW", ",", "Lisp", ",", "Pascal", ",", "etc."], "sentence-detokenized": "As aplica\u00e7\u00f5es de aquisi\u00e7\u00e3o de dados s\u00e3o geralmente controladas por programas de software desenvolvidos utilizando v\u00e1rias linguagens de programa\u00e7\u00e3o de uso geral, tais como Assembly, BASIC, C, C + +, C #, Fortran, Java, LabVIEW, Lisp, Pascal, etc.", "token2charspan": [[0, 2], [3, 13], [14, 16], [17, 26], [27, 29], [30, 35], [36, 39], [40, 50], [51, 62], [63, 66], [67, 76], [77, 79], [80, 88], [89, 102], [103, 113], [114, 120], [121, 131], [132, 134], [135, 146], [147, 149], [150, 153], [154, 159], [159, 160], [161, 165], [166, 170], [171, 179], [179, 180], [181, 186], [186, 187], [188, 189], [189, 190], [191, 192], [193, 194], [195, 196], [196, 197], [198, 199], [200, 201], [201, 202], [203, 210], [210, 211], [212, 216], [216, 217], [218, 225], [225, 226], [227, 231], [231, 232], [233, 239], [239, 240], [241, 245]]}
{"doc_key": "ai-test-173", "ner": [[3, 6, "organisation"], [10, 10, "product"], [12, 13, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 3, 6, "artifact", "", false, false], [10, 10, 12, 13, "physical", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Em", "2003", ",", "a", "Honda", "lan\u00e7ou", "o", "seu", "an\u00fancio", "da", "Cog", "no", "Reino", "Unido", "e", "na", "Internet", "."], "sentence-detokenized": "Em 2003, a Honda lan\u00e7ou o seu an\u00fancio da Cog no Reino Unido e na Internet.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 16], [17, 23], [24, 25], [26, 29], [30, 37], [38, 40], [41, 44], [45, 47], [48, 53], [54, 59], [60, 61], [62, 64], [65, 73], [73, 74]]}
{"doc_key": "ai-test-174", "ner": [[1, 5, "conference"], [8, 9, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 5, 8, 9, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "Associa\u00e7\u00e3o", "para", "a", "Lingu\u00edstica", "Computacional", "define", "a", "Lingu\u00edstica", "Computacional", "como", ":"], "sentence-detokenized": "A Associa\u00e7\u00e3o para a Lingu\u00edstica Computacional define a Lingu\u00edstica Computacional como:", "token2charspan": [[0, 1], [2, 12], [13, 17], [18, 19], [20, 31], [32, 45], [46, 52], [53, 54], [55, 66], [67, 80], [81, 85], [85, 86]]}
{"doc_key": "ai-test-175", "ner": [[0, 4, "algorithm"], [10, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 4, 10, 14, "related-to", "calculates", false, false]], "relations_mapping_to_source": [0], "sentence": ["Algoritmos", "de", "maximiza\u00e7\u00e3o", "de", "expectativas", "podem", "ser", "utilizados", "para", "calcular", "estimativas", "aproximadas", "da", "m\u00e1xima", "verosimilhan\u00e7a", "de", "par\u00e2metros", "de", "estado-espa\u00e7o", "desconhecidos", "dentro", "de", "filtros", "e", "alisadores", "de", "varia\u00e7\u00e3o", "m\u00ednima", "."], "sentence-detokenized": "Algoritmos de maximiza\u00e7\u00e3o de expectativas podem ser utilizados para calcular estimativas aproximadas da m\u00e1xima verosimilhan\u00e7a de par\u00e2metros de estado-espa\u00e7o desconhecidos dentro de filtros e alisadores de varia\u00e7\u00e3o m\u00ednima.", "token2charspan": [[0, 10], [11, 13], [14, 25], [26, 28], [29, 41], [42, 47], [48, 51], [52, 62], [63, 67], [68, 76], [77, 88], [89, 100], [101, 103], [104, 110], [111, 125], [126, 128], [129, 139], [140, 142], [143, 156], [157, 170], [171, 177], [178, 180], [181, 188], [189, 190], [191, 201], [202, 204], [205, 213], [214, 220], [220, 221]]}
{"doc_key": "ai-test-176", "ner": [[6, 7, "misc"], [8, 9, "person"], [11, 12, "person"], [15, 16, "person"], [20, 21, "misc"], [22, 23, "person"], [27, 28, "person"], [32, 32, "person"], [34, 35, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[8, 9, 6, 7, "role", "actor_in", false, false], [11, 12, 6, 7, "role", "actor_in", false, false], [15, 16, 6, 7, "role", "actor_in", false, false], [22, 23, 20, 21, "role", "model_for", false, false], [32, 32, 34, 35, "social", "family", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Os", "correspondentes", "inclu\u00edam", "as", "antigas", "actrizes", "do", "Baywatch", "Donna", "D'Errico", ",", "Carmen", "Electra", ",", "e", "Traci", "Bingham", ",", "a", "antiga", "Playboy", "Playmate", "Heidi", "Mark", ",", "o", "comediante", "Arj", "Barker", "e", "g\u00e9meos", "id\u00eanticos", "Randy", "e", "Jason", "Sklar", "."], "sentence-detokenized": "Os correspondentes inclu\u00edam as antigas actrizes do Baywatch Donna D'Errico, Carmen Electra, e Traci Bingham, a antiga Playboy Playmate Heidi Mark, o comediante Arj Barker e g\u00e9meos id\u00eanticos Randy e Jason Sklar.", "token2charspan": [[0, 2], [3, 18], [19, 27], [28, 30], [31, 38], [39, 47], [48, 50], [51, 59], [60, 65], [66, 74], [74, 75], [76, 82], [83, 90], [90, 91], [92, 93], [94, 99], [100, 107], [107, 108], [109, 110], [111, 117], [118, 125], [126, 134], [135, 140], [141, 145], [145, 146], [147, 148], [149, 159], [160, 163], [164, 170], [171, 172], [173, 179], [180, 189], [190, 195], [196, 197], [198, 203], [204, 209], [209, 210]]}
{"doc_key": "ai-test-177", "ner": [[8, 10, "task"], [12, 12, "task"], [19, 21, "product"], [24, 26, "task"], [28, 28, "task"], [35, 37, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 12, 8, 10, "named", "", false, false], [19, 21, 8, 10, "general-affiliation", "", false, false], [28, 28, 24, 26, "named", "", false, false], [35, 37, 24, 26, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["\u00c9", "normalmente", "usado", "para", "gerar", "representa\u00e7\u00f5es", "para", "o", "reconhecimento", "da", "fala", "(", "ASR", ")", ",", "por", "exemplo", ",", "o", "sistema", "CMU", "Sphinx", ",", "e", "s\u00edntese", "da", "fala", "(", "TTS", ")", ",", "por", "exemplo", ",", "o", "sistema", "do", "Festival", "."], "sentence-detokenized": "\u00c9 normalmente usado para gerar representa\u00e7\u00f5es para o reconhecimento da fala (ASR), por exemplo, o sistema CMU Sphinx, e s\u00edntese da fala (TTS), por exemplo, o sistema do Festival.", "token2charspan": [[0, 1], [2, 13], [14, 19], [20, 24], [25, 30], [31, 45], [46, 50], [51, 52], [53, 67], [68, 70], [71, 75], [76, 77], [77, 80], [80, 81], [81, 82], [83, 86], [87, 94], [94, 95], [96, 97], [98, 105], [106, 109], [110, 116], [116, 117], [118, 119], [120, 127], [128, 130], [131, 135], [136, 137], [137, 140], [140, 141], [141, 142], [143, 146], [147, 154], [154, 155], [156, 157], [158, 165], [166, 168], [169, 177], [177, 178]]}
{"doc_key": "ai-test-178", "ner": [[0, 0, "metrics"], [2, 4, "metrics"], [6, 6, "metrics"], [12, 12, "metrics"], [26, 27, "metrics"], [29, 29, "metrics"], [40, 41, "metrics"], [43, 43, "metrics"], [45, 47, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 4, 0, 0, "named", "", false, false], [6, 6, 2, 4, "named", "", false, false], [12, 12, 0, 0, "named", "", false, false], [29, 29, 26, 27, "named", "", false, false], [43, 43, 40, 41, "named", "", false, false], [45, 47, 40, 41, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sensibilidade", "ou", "TRUE", "Positive", "Rate", "(", "TPR", ")", ",", "tamb\u00e9m", "conhecida", "como", "recall", ",", "\u00e9", "a", "propor\u00e7\u00e3o", "de", "pessoas", "que", "testaram", "positivo", "e", "s\u00e3o", "positivas", "(", "TRUE", "Positive", ",", "TP", ")", "de", "todas", "as", "pessoas", "que", "s\u00e3o", "realmente", "positivas", "(", "Condi\u00e7\u00e3o", "Positiva", ",", "CP", "=", "TP", "+", "FN", ")", "."], "sentence-detokenized": "Sensibilidade ou TRUE Positive Rate (TPR), tamb\u00e9m conhecida como recall, \u00e9 a propor\u00e7\u00e3o de pessoas que testaram positivo e s\u00e3o positivas (TRUE Positive, TP) de todas as pessoas que s\u00e3o realmente positivas (Condi\u00e7\u00e3o Positiva, CP = TP + FN).", "token2charspan": [[0, 13], [14, 16], [17, 21], [22, 30], [31, 35], [36, 37], [37, 40], [40, 41], [41, 42], [43, 49], [50, 59], [60, 64], [65, 71], [71, 72], [73, 74], [75, 76], [77, 86], [87, 89], [90, 97], [98, 101], [102, 110], [111, 119], [120, 121], [122, 125], [126, 135], [136, 137], [137, 141], [142, 150], [150, 151], [152, 154], [154, 155], [156, 158], [159, 164], [165, 167], [168, 175], [176, 179], [180, 183], [184, 193], [194, 203], [204, 205], [205, 213], [214, 222], [222, 223], [224, 226], [227, 228], [229, 231], [232, 233], [234, 236], [236, 237], [237, 238]]}
{"doc_key": "ai-test-179", "ner": [[4, 6, "task"], [14, 14, "conference"], [16, 17, "conference"], [19, 19, "conference"], [21, 21, "conference"], [23, 23, "conference"], [27, 28, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[14, 14, 4, 6, "topic", "", false, false], [16, 17, 4, 6, "topic", "", false, false], [19, 19, 4, 6, "topic", "", false, false], [21, 21, 4, 6, "topic", "", false, false], [23, 23, 4, 6, "topic", "", false, false], [27, 28, 4, 6, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["As", "confer\u00eancias", "populares", "de", "reconhecimento", "de", "discursos", "realizadas", "todos", "os", "anos", "ou", "duas", "incluem", "SpeechTEK", "e", "SpeechTEK", "Europe", ",", "ICASSP", ",", "Interspeech", "/", "Eurospeech", ",", "e", "o", "IEEE", "ASRU", "."], "sentence-detokenized": "As confer\u00eancias populares de reconhecimento de discursos realizadas todos os anos ou duas incluem SpeechTEK e SpeechTEK Europe, ICASSP, Interspeech / Eurospeech, e o IEEE ASRU.", "token2charspan": [[0, 2], [3, 15], [16, 25], [26, 28], [29, 43], [44, 46], [47, 56], [57, 67], [68, 73], [74, 76], [77, 81], [82, 84], [85, 89], [90, 97], [98, 107], [108, 109], [110, 119], [120, 126], [126, 127], [128, 134], [134, 135], [136, 147], [148, 149], [150, 160], [160, 161], [162, 163], [164, 165], [166, 170], [171, 175], [175, 176]]}
{"doc_key": "ai-test-180", "ner": [[0, 0, "researcher"], [3, 3, "researcher"], [17, 18, "product"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 22, 0, 0, "artifact", "", false, false], [22, 22, 3, 3, "artifact", "", false, false], [22, 22, 17, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Devol", "colaborou", "com", "Engelberger", ",", "que", "serviu", "como", "presidente", "da", "empresa", ",", "para", "conceber", "e", "produzir", "um", "rob\u00f4", "industrial", "sob", "a", "marca", "Unimate", "."], "sentence-detokenized": "Devol colaborou com Engelberger, que serviu como presidente da empresa, para conceber e produzir um rob\u00f4 industrial sob a marca Unimate.", "token2charspan": [[0, 5], [6, 15], [16, 19], [20, 31], [31, 32], [33, 36], [37, 43], [44, 48], [49, 59], [60, 62], [63, 70], [70, 71], [72, 76], [77, 85], [86, 87], [88, 96], [97, 99], [100, 104], [105, 115], [116, 119], [120, 121], [122, 127], [128, 135], [135, 136]]}
{"doc_key": "ai-test-181", "ner": [[1, 3, "algorithm"], [5, 5, "algorithm"], [9, 11, "algorithm"], [24, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 3, 9, 11, "general-affiliation", "", false, false], [5, 5, 1, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Um", "modelo", "Markov", "oculto", "(", "HMM", ")", "\u00e9", "um", "modelo", "Markov", "estat\u00edstico", "no", "qual", "o", "sistema", "a", "ser", "modelado", "\u00e9", "assumido", "como", "sendo", "um", "processo", "Markov", "com", "estados", "n\u00e3o", "observados", "(", "ocultos", ")", "."], "sentence-detokenized": "Um modelo Markov oculto (HMM) \u00e9 um modelo Markov estat\u00edstico no qual o sistema a ser modelado \u00e9 assumido como sendo um processo Markov com estados n\u00e3o observados (ocultos).", "token2charspan": [[0, 2], [3, 9], [10, 16], [17, 23], [24, 25], [25, 28], [28, 29], [30, 31], [32, 34], [35, 41], [42, 48], [49, 60], [61, 63], [64, 68], [69, 70], [71, 78], [79, 80], [81, 84], [85, 93], [94, 95], [96, 104], [105, 109], [110, 115], [116, 118], [119, 127], [128, 134], [135, 138], [139, 146], [147, 150], [151, 161], [162, 163], [163, 170], [170, 171], [171, 172]]}
{"doc_key": "ai-test-182", "ner": [[17, 19, "metrics"], [25, 25, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Esta", "propriedade", ",", "indesej\u00e1vel", "em", "muitas", "aplica\u00e7\u00f5es", ",", "levou", "os", "investigadores", "a", "utilizar", "alternativas", "tais", "como", "o", "erro", "m\u00e9dio", "absoluto", ",", "ou", "aquelas", "baseadas", "na", "mediana", "."], "sentence-detokenized": "Esta propriedade, indesej\u00e1vel em muitas aplica\u00e7\u00f5es, levou os investigadores a utilizar alternativas tais como o erro m\u00e9dio absoluto, ou aquelas baseadas na mediana.", "token2charspan": [[0, 4], [5, 16], [16, 17], [18, 29], [30, 32], [33, 39], [40, 50], [50, 51], [52, 57], [58, 60], [61, 75], [76, 77], [78, 86], [87, 99], [100, 104], [105, 109], [110, 111], [112, 116], [117, 122], [123, 131], [131, 132], [133, 135], [136, 143], [144, 152], [153, 155], [156, 163], [163, 164]]}
{"doc_key": "ai-test-183", "ner": [[18, 20, "algorithm"], [26, 28, "field"], [31, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 20, 26, 28, "part-of", "", false, false], [18, 20, 31, 35, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Tal", "sequ\u00eancia", "(", "que", "depende", "do", "resultado", "da", "investiga\u00e7\u00e3o", "de", "atributos", "anteriores", "em", "cada", "fase", ")", "\u00e9", "chamada", "\u00e1rvore", "de", "decis\u00e3o", "e", "aplicada", "na", "\u00e1rea", "de", "aprendizagem", "de", "m\u00e1quinas", "conhecida", "como", "aprendizagem", "em", "\u00e1rvore", "de", "decis\u00e3o", "."], "sentence-detokenized": "Tal sequ\u00eancia (que depende do resultado da investiga\u00e7\u00e3o de atributos anteriores em cada fase) \u00e9 chamada \u00e1rvore de decis\u00e3o e aplicada na \u00e1rea de aprendizagem de m\u00e1quinas conhecida como aprendizagem em \u00e1rvore de decis\u00e3o.", "token2charspan": [[0, 3], [4, 13], [14, 15], [15, 18], [19, 26], [27, 29], [30, 39], [40, 42], [43, 55], [56, 58], [59, 68], [69, 79], [80, 82], [83, 87], [88, 92], [92, 93], [94, 95], [96, 103], [104, 110], [111, 113], [114, 121], [122, 123], [124, 132], [133, 135], [136, 140], [141, 143], [144, 156], [157, 159], [160, 168], [169, 178], [179, 183], [184, 196], [197, 199], [200, 206], [207, 209], [210, 217], [217, 218]]}
{"doc_key": "ai-test-184", "ner": [[3, 5, "task"], [8, 8, "algorithm"], [22, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 8, 8, "compare", "", false, false], [22, 24, 8, 8, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Tal", "como", "na", "an\u00e1lise", "de", "factores", ",", "a", "ACV", "tamb\u00e9m", "pode", "ser", "utilizada", "para", "classificar", "os", "casos", "de", "acordo", "com", "a", "sua", "probabilidade", "m\u00e1xima", "de", "pertencer", "a", "uma", "classe", "."], "sentence-detokenized": "Tal como na an\u00e1lise de factores, a ACV tamb\u00e9m pode ser utilizada para classificar os casos de acordo com a sua probabilidade m\u00e1xima de pertencer a uma classe.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 19], [20, 22], [23, 31], [31, 32], [33, 34], [35, 38], [39, 45], [46, 50], [51, 54], [55, 64], [65, 69], [70, 81], [82, 84], [85, 90], [91, 93], [94, 100], [101, 104], [105, 106], [107, 110], [111, 124], [125, 131], [132, 134], [135, 144], [145, 146], [147, 150], [151, 157], [157, 158]]}
{"doc_key": "ai-test-185", "ner": [[0, 3, "algorithm"], [11, 13, "metrics"], [15, 15, "metrics"], [7, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 11, 13, "usage", "", false, false], [11, 13, 7, 10, "related-to", "", false, false], [15, 15, 11, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["As", "redes", "neurais", "supervisionadas", "que", "utilizam", "uma", "fun\u00e7\u00e3o", "de", "custo", "de", "erro", "quadr\u00e1tico", "m\u00e9dio", "(", "MSE", ")", "podem", "utilizar", "m\u00e9todos", "estat\u00edsticos", "formais", "para", "determinar", "a", "confian\u00e7a", "do", "modelo", "treinado", "."], "sentence-detokenized": "As redes neurais supervisionadas que utilizam uma fun\u00e7\u00e3o de custo de erro quadr\u00e1tico m\u00e9dio (MSE) podem utilizar m\u00e9todos estat\u00edsticos formais para determinar a confian\u00e7a do modelo treinado.", "token2charspan": [[0, 2], [3, 8], [9, 16], [17, 32], [33, 36], [37, 45], [46, 49], [50, 56], [57, 59], [60, 65], [66, 68], [69, 73], [74, 84], [85, 90], [91, 92], [92, 95], [95, 96], [97, 102], [103, 111], [112, 119], [120, 132], [133, 140], [141, 145], [146, 156], [157, 158], [159, 168], [169, 171], [172, 178], [179, 187], [187, 188]]}
{"doc_key": "ai-test-186", "ner": [[15, 17, "algorithm"], [20, 24, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 17, 20, 24, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Isto", "pode", "ser", "directamente", "expresso", "como", "um", "programa", "linear", ",", "mas", "\u00e9", "tamb\u00e9m", "equivalente", "\u00e0", "regulariza\u00e7\u00e3o", "de", "Tikhonov", "com", "a", "fun\u00e7\u00e3o", "de", "perda", "de", "dobradi\u00e7as", ",", "VHV", "matem\u00e1tica", "(", "f", "(", "x", ")", ",", "y", ")", "=", "\\", "max", "(", "0", ",", "1", "-", "yf", "(", "x", ")", ")", "/", "matem\u00e1tica", ":"], "sentence-detokenized": "Isto pode ser directamente expresso como um programa linear, mas \u00e9 tamb\u00e9m equivalente \u00e0 regulariza\u00e7\u00e3o de Tikhonov com a fun\u00e7\u00e3o de perda de dobradi\u00e7as, VHV matem\u00e1tica (f (x), y) =\\ max (0, 1 - yf (x)) / matem\u00e1tica:", "token2charspan": [[0, 4], [5, 9], [10, 13], [14, 26], [27, 35], [36, 40], [41, 43], [44, 52], [53, 59], [59, 60], [61, 64], [65, 66], [67, 73], [74, 85], [86, 87], [88, 101], [102, 104], [105, 113], [114, 117], [118, 119], [120, 126], [127, 129], [130, 135], [136, 138], [139, 149], [149, 150], [151, 154], [155, 165], [166, 167], [167, 168], [169, 170], [170, 171], [171, 172], [172, 173], [174, 175], [175, 176], [177, 178], [178, 179], [180, 183], [184, 185], [185, 186], [186, 187], [188, 189], [190, 191], [192, 194], [195, 196], [196, 197], [197, 198], [198, 199], [200, 201], [202, 212], [212, 213]]}
{"doc_key": "ai-test-187", "ner": [[9, 9, "researcher"], [14, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "seguinte", "t\u00e9cnica", "foi", "descrita", "no", "papel", "original", "de", "Breiman", "e", "\u00e9", "implementada", "no", "pacote", "R", "randomForest", "."], "sentence-detokenized": "A seguinte t\u00e9cnica foi descrita no papel original de Breiman e \u00e9 implementada no pacote R randomForest.", "token2charspan": [[0, 1], [2, 10], [11, 18], [19, 22], [23, 31], [32, 34], [35, 40], [41, 49], [50, 52], [53, 60], [61, 62], [63, 64], [65, 77], [78, 80], [81, 87], [88, 89], [90, 102], [102, 103]]}
{"doc_key": "ai-test-188", "ner": [[10, 10, "metrics"], [41, 41, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["As", "medidas", "tradicionais", "de", "qualidade", "de", "imagem", ",", "como", "a", "PSNR", ",", "s\u00e3o", "tipicamente", "realizadas", "em", "imagens", "de", "resolu\u00e7\u00e3o", "fixa", "e", "n\u00e3o", "t\u00eam", "em", "conta", "alguns", "aspectos", "do", "sistema", "visual", "humano", ",", "como", "a", "mudan\u00e7a", "na", "resolu\u00e7\u00e3o", "espacial", "em", "toda", "a", "retina", "."], "sentence-detokenized": "As medidas tradicionais de qualidade de imagem, como a PSNR, s\u00e3o tipicamente realizadas em imagens de resolu\u00e7\u00e3o fixa e n\u00e3o t\u00eam em conta alguns aspectos do sistema visual humano, como a mudan\u00e7a na resolu\u00e7\u00e3o espacial em toda a retina.", "token2charspan": [[0, 2], [3, 10], [11, 23], [24, 26], [27, 36], [37, 39], [40, 46], [46, 47], [48, 52], [53, 54], [55, 59], [59, 60], [61, 64], [65, 76], [77, 87], [88, 90], [91, 98], [99, 101], [102, 111], [112, 116], [117, 118], [119, 122], [123, 126], [127, 129], [130, 135], [136, 142], [143, 151], [152, 154], [155, 162], [163, 169], [170, 176], [176, 177], [178, 182], [183, 184], [185, 192], [193, 195], [196, 205], [206, 214], [215, 217], [218, 222], [223, 224], [225, 231], [231, 232]]}
{"doc_key": "ai-test-189", "ner": [[0, 1, "person"], [3, 4, "person"], [6, 7, "person"], [14, 15, "person"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 16, 17, "role", "", false, false], [3, 4, 16, 17, "role", "", false, false], [6, 7, 16, 17, "role", "", false, false], [16, 17, 14, 15, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["John", "Ireland", ",", "Joanne", "Dru", "e", "Macdonald", "Carey", "estrelaram", "na", "produ\u00e7\u00e3o", "de", "cor", "de", "Jack", "Broder", "Hannah", "Lee", ",", "que", "estreou", "a", "19", "de", "Junho", "de", "1953", "."], "sentence-detokenized": "John Ireland, Joanne Dru e Macdonald Carey estrelaram na produ\u00e7\u00e3o de cor de Jack Broder Hannah Lee, que estreou a 19 de Junho de 1953.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 20], [21, 24], [25, 26], [27, 36], [37, 42], [43, 53], [54, 56], [57, 65], [66, 68], [69, 72], [73, 75], [76, 80], [81, 87], [88, 94], [95, 98], [98, 99], [100, 103], [104, 111], [112, 113], [114, 116], [117, 119], [120, 125], [126, 128], [129, 133], [133, 134]]}
{"doc_key": "ai-test-190", "ner": [[3, 5, "task"], [12, 14, "field"], [22, 22, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 12, 14, "usage", "", false, false], [22, 22, 12, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Este", "processo", "chama-se", "registo", "de", "imagem", ",", "e", "utiliza", "diferentes", "m\u00e9todos", "de", "vis\u00e3o", "por", "computador", ",", "na", "sua", "maioria", "relacionados", "com", "o", "rastreio", "."], "sentence-detokenized": "Este processo chama-se registo de imagem, e utiliza diferentes m\u00e9todos de vis\u00e3o por computador, na sua maioria relacionados com o rastreio.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 30], [31, 33], [34, 40], [40, 41], [42, 43], [44, 51], [52, 62], [63, 70], [71, 73], [74, 79], [80, 83], [84, 94], [94, 95], [96, 98], [99, 102], [103, 110], [111, 123], [124, 127], [128, 129], [130, 138], [138, 139]]}
{"doc_key": "ai-test-191", "ner": [[16, 18, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Comecemos", "agora", "a", "explicar", "as", "diferentes", "rela\u00e7\u00f5es", "poss\u00edveis", "entre", "o", "resultado", "previsto", "e", "o", "real", ":", "Matriz", "de", "confus\u00e3o"], "sentence-detokenized": "Comecemos agora a explicar as diferentes rela\u00e7\u00f5es poss\u00edveis entre o resultado previsto e o real: Matriz de confus\u00e3o", "token2charspan": [[0, 9], [10, 15], [16, 17], [18, 26], [27, 29], [30, 40], [41, 49], [50, 59], [60, 65], [66, 67], [68, 77], [78, 86], [87, 88], [89, 90], [91, 95], [95, 96], [97, 103], [104, 106], [107, 115]]}
{"doc_key": "ai-test-192", "ner": [[8, 8, "product"], [1, 7, "misc"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 1, 7, "part-of", "", false, false], [8, 8, 1, 7, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "caixa", "de", "ferramentas", "de", "processamento", "de", "fala", "VOICEBOX", "para", "MATLAB", "implementa", "a", "convers\u00e3o", "e", "o", "seu", "inverso", "como", ":"], "sentence-detokenized": "A caixa de ferramentas de processamento de fala VOICEBOX para MATLAB implementa a convers\u00e3o e o seu inverso como:", "token2charspan": [[0, 1], [2, 7], [8, 10], [11, 22], [23, 25], [26, 39], [40, 42], [43, 47], [48, 56], [57, 61], [62, 68], [69, 79], [80, 81], [82, 91], [92, 93], [94, 95], [96, 99], [100, 107], [108, 112], [112, 113]]}
{"doc_key": "ai-test-193", "ner": [[0, 0, "programlang"], [9, 10, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 9, 10, "general-affiliation", "", false, false], [0, 0, 13, 14, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolog", "\u00e9", "uma", "linguagem", "de", "programa\u00e7\u00e3o", "l\u00f3gica", "associada", "\u00e0", "intelig\u00eancia", "artificial", "e", "\u00e0", "lingu\u00edstica", "computacional", "."], "sentence-detokenized": "Prolog \u00e9 uma linguagem de programa\u00e7\u00e3o l\u00f3gica associada \u00e0 intelig\u00eancia artificial e \u00e0 lingu\u00edstica computacional.", "token2charspan": [[0, 6], [7, 8], [9, 12], [13, 22], [23, 25], [26, 37], [38, 44], [45, 54], [55, 56], [57, 69], [70, 80], [81, 82], [83, 84], [85, 96], [97, 110], [110, 111]]}
{"doc_key": "ai-test-194", "ner": [[0, 0, "researcher"], [8, 8, "field"], [10, 10, "field"], [17, 20, "organisation"], [23, 26, "organisation"], [29, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 8, 8, "related-to", "works_with_topic", false, false], [0, 0, 10, 10, "related-to", "works_with_topic", false, false], [0, 0, 17, 20, "role", "", false, false], [0, 0, 23, 26, "role", "", false, false], [0, 0, 29, 32, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Milner", "recebeu", "in\u00fameros", "pr\u00e9mios", "pelas", "suas", "contribui\u00e7\u00f5es", "em", "neuroci\u00eancia", "e", "psicologia", ",", "incluindo", "a", "sua", "perten\u00e7a", "\u00e0", "Royal", "Society", "of", "London", ",", "\u00e0", "Royal", "Society", "of", "Canada", "e", "\u00e0", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Milner recebeu in\u00fameros pr\u00e9mios pelas suas contribui\u00e7\u00f5es em neuroci\u00eancia e psicologia, incluindo a sua perten\u00e7a \u00e0 Royal Society of London, \u00e0 Royal Society of Canada e \u00e0 National Academy of Sciences.", "token2charspan": [[0, 6], [7, 14], [15, 23], [24, 31], [32, 37], [38, 42], [43, 56], [57, 59], [60, 72], [73, 74], [75, 85], [85, 86], [87, 96], [97, 98], [99, 102], [103, 111], [112, 113], [114, 119], [120, 127], [128, 130], [131, 137], [137, 138], [139, 140], [141, 146], [147, 154], [155, 157], [158, 164], [165, 166], [167, 168], [169, 177], [178, 185], [186, 188], [189, 197], [197, 198]]}
{"doc_key": "ai-test-195", "ner": [[12, 14, "field"], [18, 20, "task"], [22, 24, "task"], [26, 28, "task"], [30, 32, "task"], [35, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[18, 20, 12, 14, "part-of", "task_part_of_field", false, false], [22, 24, 12, 14, "part-of", "task_part_of_field", false, false], [26, 28, 12, 14, "part-of", "task_part_of_field", false, false], [30, 32, 12, 14, "part-of", "task_part_of_field", false, false], [35, 35, 12, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Ao", "combinar", "estes", "operadores", "\u00e9", "poss\u00edvel", "obter", "algoritmos", "para", "muitas", "tarefas", "de", "processamento", "de", "imagem", ",", "tais", "como", "extrac\u00e7\u00e3o", "de", "caracter\u00edsticas", ",", "segmenta\u00e7\u00e3o", "de", "imagem", ",", "nitidez", "de", "imagem", ",", "filtragem", "de", "imagem", ",", "e", "classifica\u00e7\u00e3o", "."], "sentence-detokenized": "Ao combinar estes operadores \u00e9 poss\u00edvel obter algoritmos para muitas tarefas de processamento de imagem, tais como extrac\u00e7\u00e3o de caracter\u00edsticas, segmenta\u00e7\u00e3o de imagem, nitidez de imagem, filtragem de imagem, e classifica\u00e7\u00e3o.", "token2charspan": [[0, 2], [3, 11], [12, 17], [18, 28], [29, 30], [31, 39], [40, 45], [46, 56], [57, 61], [62, 68], [69, 76], [77, 79], [80, 93], [94, 96], [97, 103], [103, 104], [105, 109], [110, 114], [115, 124], [125, 127], [128, 143], [143, 144], [145, 156], [157, 159], [160, 166], [166, 167], [168, 175], [176, 178], [179, 185], [185, 186], [187, 196], [197, 199], [200, 206], [206, 207], [208, 209], [210, 223], [223, 224]]}
{"doc_key": "ai-test-196", "ner": [[8, 10, "university"], [18, 21, "organisation"], [23, 24, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 24, 18, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "partir", "de", "2017", ",", "\u00e9", "professor", "no", "Coll\u00e8ge", "de", "France", "e", ",", "desde", "1989", ",", "director", "da", "Unidade", "562", "do", "INSERM", ",", "Cognitive", "Neuroimaging", "."], "sentence-detokenized": "A partir de 2017, \u00e9 professor no Coll\u00e8ge de France e, desde 1989, director da Unidade 562 do INSERM, Cognitive Neuroimaging.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 16], [16, 17], [18, 19], [20, 29], [30, 32], [33, 40], [41, 43], [44, 50], [51, 52], [52, 53], [54, 59], [60, 64], [64, 65], [66, 74], [75, 77], [78, 85], [86, 89], [90, 92], [93, 99], [99, 100], [101, 110], [111, 123], [123, 124]]}
{"doc_key": "ai-test-197", "ner": [[10, 13, "algorithm"], [15, 18, "algorithm"], [24, 24, "algorithm"], [26, 34, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[24, 24, 26, 34, "temporal", "", false, true]], "relations_mapping_to_source": [0], "sentence": ["H\u00e1", "muitas", "abordagens", "para", "aprender", "estas", "incorpora\u00e7\u00f5es", ",", "nomeadamente", "utilizando", "estruturas", "de", "agrupamento", "Bayesianas", "ou", "estruturas", "baseadas", "em", "energia", ",", "e", "mais", "recentemente", ",", "TransE", "(", "Confer\u00eancia", "sobre", "Sistemas", "de", "Processamento", "de", "Informa\u00e7\u00e3o", "Neural", "2013", ")", "."], "sentence-detokenized": "H\u00e1 muitas abordagens para aprender estas incorpora\u00e7\u00f5es, nomeadamente utilizando estruturas de agrupamento Bayesianas ou estruturas baseadas em energia, e mais recentemente, TransE (Confer\u00eancia sobre Sistemas de Processamento de Informa\u00e7\u00e3o Neural 2013).", "token2charspan": [[0, 2], [3, 9], [10, 20], [21, 25], [26, 34], [35, 40], [41, 54], [54, 55], [56, 68], [69, 79], [80, 90], [91, 93], [94, 105], [106, 116], [117, 119], [120, 130], [131, 139], [140, 142], [143, 150], [150, 151], [152, 153], [154, 158], [159, 171], [171, 172], [173, 179], [180, 181], [181, 192], [193, 198], [199, 207], [208, 210], [211, 224], [225, 227], [228, 238], [239, 245], [246, 250], [250, 251], [251, 252]]}
{"doc_key": "ai-test-198", "ner": [[4, 8, "metrics"], [10, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 12, 4, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["\u00c9", "uma", "alternativa", "\u00e0", "taxa", "de", "erro", "do", "Word", "(", "Word", "Error", "Rate", ")", "utilizada", "em", "v\u00e1rios", "pa\u00edses", "."], "sentence-detokenized": "\u00c9 uma alternativa \u00e0 taxa de erro do Word (Word Error Rate) utilizada em v\u00e1rios pa\u00edses.", "token2charspan": [[0, 1], [2, 5], [6, 17], [18, 19], [20, 24], [25, 27], [28, 32], [33, 35], [36, 40], [41, 42], [42, 46], [47, 52], [53, 57], [57, 58], [59, 68], [69, 71], [72, 78], [79, 85], [85, 86]]}
{"doc_key": "ai-test-199", "ner": [[0, 1, "algorithm"], [11, 13, "task"], [15, 17, "task"], [19, 20, "task"], [22, 25, "task"], [28, 32, "task"], [34, 35, "task"], [53, 53, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 13, 0, 1, "usage", "", false, false], [15, 17, 0, 1, "usage", "", false, false], [19, 20, 0, 1, "usage", "", false, false], [22, 25, 0, 1, "usage", "", false, false], [28, 32, 0, 1, "usage", "", false, false], [34, 35, 0, 1, "usage", "", false, false], [53, 53, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["As", "ANN", "t\u00eam", "sido", "utilizadas", "numa", "variedade", "de", "tarefas", ",", "incluindo", "vis\u00e3o", "por", "computador", ",", "reconhecimento", "da", "fala", ",", "tradu\u00e7\u00e3o", "autom\u00e1tica", ",", "filtragem", "de", "redes", "sociais", ",", "jogos", "de", "mesa", "e", "de", "v\u00eddeo", ",", "diagn\u00f3stico", "m\u00e9dico", ",", "e", "mesmo", "em", "actividades", "que", "t\u00eam", "sido", "tradicionalmente", "consideradas", "como", "reservadas", "aos", "humanos", ",", "como", "a", "pintura", "."], "sentence-detokenized": "As ANN t\u00eam sido utilizadas numa variedade de tarefas, incluindo vis\u00e3o por computador, reconhecimento da fala, tradu\u00e7\u00e3o autom\u00e1tica, filtragem de redes sociais, jogos de mesa e de v\u00eddeo, diagn\u00f3stico m\u00e9dico, e mesmo em actividades que t\u00eam sido tradicionalmente consideradas como reservadas aos humanos, como a pintura.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 15], [16, 26], [27, 31], [32, 41], [42, 44], [45, 52], [52, 53], [54, 63], [64, 69], [70, 73], [74, 84], [84, 85], [86, 100], [101, 103], [104, 108], [108, 109], [110, 118], [119, 129], [129, 130], [131, 140], [141, 143], [144, 149], [150, 157], [157, 158], [159, 164], [165, 167], [168, 172], [173, 174], [175, 177], [178, 183], [183, 184], [185, 196], [197, 203], [203, 204], [205, 206], [207, 212], [213, 215], [216, 227], [228, 231], [232, 235], [236, 240], [241, 257], [258, 270], [271, 275], [276, 286], [287, 290], [291, 298], [298, 299], [300, 304], [305, 306], [307, 314], [314, 315]]}
{"doc_key": "ai-test-200", "ner": [[0, 4, "product"], [6, 6, "product"], [22, 33, "field"], [35, 35, "field"], [39, 39, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 22, 33, "related-to", "", false, false], [0, 4, 39, 39, "general-affiliation", "", false, false], [6, 6, 0, 4, "named", "", false, false], [35, 35, 22, 33, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["O", "Modular", "Audio", "Recognition", "Framework", "(", "MARF", ")", "\u00e9", "uma", "plataforma", "de", "pesquisa", "de", "c\u00f3digo", "aberto", "e", "uma", "colec\u00e7\u00e3o", "de", "algoritmos", "de", "processamento", "de", "voz", ",", "som", ",", "fala", ",", "texto", "e", "linguagem", "natural", "(", "PNL", ")", "escritos", "em", "Java", "e", "dispostos", "numa", "estrutura", "modular", "e", "extens\u00edvel", "que", "tenta", "facilitar", "a", "adi\u00e7\u00e3o", "de", "novos", "algoritmos", "."], "sentence-detokenized": "O Modular Audio Recognition Framework (MARF) \u00e9 uma plataforma de pesquisa de c\u00f3digo aberto e uma colec\u00e7\u00e3o de algoritmos de processamento de voz, som, fala, texto e linguagem natural (PNL) escritos em Java e dispostos numa estrutura modular e extens\u00edvel que tenta facilitar a adi\u00e7\u00e3o de novos algoritmos.", "token2charspan": [[0, 1], [2, 9], [10, 15], [16, 27], [28, 37], [38, 39], [39, 43], [43, 44], [45, 46], [47, 50], [51, 61], [62, 64], [65, 73], [74, 76], [77, 83], [84, 90], [91, 92], [93, 96], [97, 105], [106, 108], [109, 119], [120, 122], [123, 136], [137, 139], [140, 143], [143, 144], [145, 148], [148, 149], [150, 154], [154, 155], [156, 161], [162, 163], [164, 173], [174, 181], [182, 183], [183, 186], [186, 187], [188, 196], [197, 199], [200, 204], [205, 206], [207, 216], [217, 221], [222, 231], [232, 239], [240, 241], [242, 252], [253, 256], [257, 262], [263, 272], [273, 274], [275, 281], [282, 284], [285, 290], [291, 301], [301, 302]]}
{"doc_key": "ai-test-201", "ner": [[14, 16, "organisation"], [23, 24, "country"], [27, 33, "organisation"], [36, 37, "organisation"], [43, 44, "task"], [66, 72, "organisation"], [63, 65, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[27, 33, 23, 24, "physical", "", false, false], [27, 33, 43, 44, "usage", "", false, false], [27, 33, 66, 72, "named", "", false, false], [36, 37, 23, 24, "physical", "", false, false], [36, 37, 43, 44, "usage", "", false, false], [66, 72, 63, 65, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Em", "2018", ",", "um", "relat\u00f3rio", "da", "organiza\u00e7\u00e3o", "de", "defesa", "das", "liberdades", "e", "direitos", "civis", "Big", "Brother", "Watch", "revelou", "que", "duas", "for\u00e7as", "policiais", "do", "Reino", "Unido", ",", "a", "Pol\u00edcia", "do", "Pa\u00eds", "de", "Gales", "do", "Sul", "e", "a", "Pol\u00edcia", "Metropolitana", ",", "estavam", "a", "utilizar", "o", "reconhecimento", "facial", "ao", "vivo", "em", "eventos", "p\u00fablicos", "e", "em", "espa\u00e7os", "p\u00fablicos", ",", "em", "Setembro", "de", "2019", ",", "o", "uso", "do", "reconhecimento", "facial", "pela", "Pol\u00edcia", "do", "Pa\u00eds", "de", "Gales", "do", "Sul", "foi", "considerado", "legal", "."], "sentence-detokenized": "Em 2018, um relat\u00f3rio da organiza\u00e7\u00e3o de defesa das liberdades e direitos civis Big Brother Watch revelou que duas for\u00e7as policiais do Reino Unido, a Pol\u00edcia do Pa\u00eds de Gales do Sul e a Pol\u00edcia Metropolitana, estavam a utilizar o reconhecimento facial ao vivo em eventos p\u00fablicos e em espa\u00e7os p\u00fablicos, em Setembro de 2019, o uso do reconhecimento facial pela Pol\u00edcia do Pa\u00eds de Gales do Sul foi considerado legal.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 21], [22, 24], [25, 36], [37, 39], [40, 46], [47, 50], [51, 61], [62, 63], [64, 72], [73, 78], [79, 82], [83, 90], [91, 96], [97, 104], [105, 108], [109, 113], [114, 120], [121, 130], [131, 133], [134, 139], [140, 145], [145, 146], [147, 148], [149, 156], [157, 159], [160, 164], [165, 167], [168, 173], [174, 176], [177, 180], [181, 182], [183, 184], [185, 192], [193, 206], [206, 207], [208, 215], [216, 217], [218, 226], [227, 228], [229, 243], [244, 250], [251, 253], [254, 258], [259, 261], [262, 269], [270, 278], [279, 280], [281, 283], [284, 291], [292, 300], [300, 301], [302, 304], [305, 313], [314, 316], [317, 321], [321, 322], [323, 324], [325, 328], [329, 331], [332, 346], [347, 353], [354, 358], [359, 366], [367, 369], [370, 374], [375, 377], [378, 383], [384, 386], [387, 390], [391, 394], [395, 406], [407, 412], [412, 413]]}
{"doc_key": "ai-test-202", "ner": [[0, 0, "product"], [4, 4, "programlang"], [13, 14, "field"], [16, 16, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 4, "general-affiliation", "", false, false], [0, 0, 13, 14, "related-to", "", false, false], [0, 0, 16, 16, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["ANIMAL", "foi", "portado", "para", "R", ",", "uma", "linguagem", "e", "ambiente", "livremente", "dispon\u00edveis", "para", "computa\u00e7\u00e3o", "estat\u00edstica", "e", "gr\u00e1fica", "."], "sentence-detokenized": "ANIMAL foi portado para R, uma linguagem e ambiente livremente dispon\u00edveis para computa\u00e7\u00e3o estat\u00edstica e gr\u00e1fica.", "token2charspan": [[0, 6], [7, 10], [11, 18], [19, 23], [24, 25], [25, 26], [27, 30], [31, 40], [41, 42], [43, 51], [52, 62], [63, 74], [75, 79], [80, 90], [91, 102], [103, 104], [105, 112], [112, 113]]}
{"doc_key": "ai-test-203", "ner": [[0, 6, "algorithm"], [8, 8, "algorithm"], [14, 16, "algorithm"], [18, 18, "algorithm"], [22, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 6, 14, 16, "opposite", "alternative to", false, false], [8, 8, 0, 6, "named", "", false, false], [18, 18, 14, 16, "named", "", false, false], [22, 25, 0, 6, "usage", "", false, false], [22, 25, 14, 16, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["O", "modelo", "Bernoulli", "oculto", "de", "tempo", "inomog\u00e9neo", "(", "TI-HBM", ")", "\u00e9", "uma", "alternativa", "ao", "modelo", "Markov", "oculto", "(", "HMM", ")", "para", "o", "reconhecimento", "autom\u00e1tico", "da", "fala", "."], "sentence-detokenized": "O modelo Bernoulli oculto de tempo inomog\u00e9neo (TI-HBM) \u00e9 uma alternativa ao modelo Markov oculto (HMM) para o reconhecimento autom\u00e1tico da fala.", "token2charspan": [[0, 1], [2, 8], [9, 18], [19, 25], [26, 28], [29, 34], [35, 45], [46, 47], [47, 53], [53, 54], [55, 56], [57, 60], [61, 72], [73, 75], [76, 82], [83, 89], [90, 96], [97, 98], [98, 101], [101, 102], [103, 107], [108, 109], [110, 124], [125, 135], [136, 138], [139, 143], [143, 144]]}
{"doc_key": "ai-test-204", "ner": [[5, 5, "organisation"], [9, 9, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 9, 9, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Em", "Julho", "de", "2016", ",", "Nvidia", "demonstrou", "durante", "o", "SIGGRAPH", "um", "novo", "m\u00e9todo", "de", "rendi\u00e7\u00e3o", "de", "foveated", "afirmado", "ser", "invis\u00edvel", "para", "os", "utilizadores", "."], "sentence-detokenized": "Em Julho de 2016, Nvidia demonstrou durante o SIGGRAPH um novo m\u00e9todo de rendi\u00e7\u00e3o de foveated afirmado ser invis\u00edvel para os utilizadores.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 16], [16, 17], [18, 24], [25, 35], [36, 43], [44, 45], [46, 54], [55, 57], [58, 62], [63, 69], [70, 72], [73, 81], [82, 84], [85, 93], [94, 102], [103, 106], [107, 116], [117, 121], [122, 124], [125, 137], [137, 138]]}
{"doc_key": "ai-test-205", "ner": [[4, 8, "misc"], [11, 13, "researcher"], [19, 20, "researcher"], [22, 23, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 8, 11, 13, "origin", "", false, false], [4, 8, 19, 20, "origin", "", false, false], [4, 8, 22, 23, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Ambos", "se", "baseiam", "na", "teoria", "do", "acto", "de", "fala", "desenvolvida", "por", "John", "Searle", "nos", "anos", "60", "e", "refor\u00e7ada", "por", "Terry", "Winograd", "e", "Flores", "nos", "anos", "70", "."], "sentence-detokenized": "Ambos se baseiam na teoria do acto de fala desenvolvida por John Searle nos anos 60 e refor\u00e7ada por Terry Winograd e Flores nos anos 70.", "token2charspan": [[0, 5], [6, 8], [9, 16], [17, 19], [20, 26], [27, 29], [30, 34], [35, 37], [38, 42], [43, 55], [56, 59], [60, 64], [65, 71], [72, 75], [76, 80], [81, 83], [84, 85], [86, 95], [96, 99], [100, 105], [106, 114], [115, 116], [117, 123], [124, 127], [128, 132], [133, 135], [135, 136]]}
{"doc_key": "ai-test-206", "ner": [[0, 4, "algorithm"], [28, 29, "researcher"], [26, 26, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 28, 29, "related-to", "", false, false], [26, 26, 28, 29, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Os", "modelos", "de", "redes", "neurais", "de", "forma\u00e7\u00e3o", "de", "conceitos", "e", "a", "estrutura", "do", "conhecimento", "abriram", "poderosos", "modelos", "hier\u00e1rquicos", "de", "organiza\u00e7\u00e3o", "do", "conhecimento", ",", "tais", "como", "o", "Wordnet", "de", "George", "Miller", "."], "sentence-detokenized": "Os modelos de redes neurais de forma\u00e7\u00e3o de conceitos e a estrutura do conhecimento abriram poderosos modelos hier\u00e1rquicos de organiza\u00e7\u00e3o do conhecimento, tais como o Wordnet de George Miller.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 19], [20, 27], [28, 30], [31, 39], [40, 42], [43, 52], [53, 54], [55, 56], [57, 66], [67, 69], [70, 82], [83, 90], [91, 100], [101, 108], [109, 121], [122, 124], [125, 136], [137, 139], [140, 152], [152, 153], [154, 158], [159, 163], [164, 165], [166, 173], [174, 176], [177, 183], [184, 190], [190, 191]]}
{"doc_key": "ai-test-207", "ner": [[0, 3, "algorithm"], [14, 15, "field"], [18, 21, "product"], [25, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 14, 15, "part-of", "", false, false], [0, 3, 25, 28, "part-of", "", false, false], [18, 21, 14, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "correspond\u00eancia", "de", "modelos", "tem", "v\u00e1rias", "aplica\u00e7\u00f5es", "e", "\u00e9", "utilizada", "em", "campos", "como", "o", "reconhecimento", "facial", "(", "ver", "sistema", "de", "reconhecimento", "facial", ")", "e", "o", "processamento", "de", "imagens", "m\u00e9dicas", "."], "sentence-detokenized": "A correspond\u00eancia de modelos tem v\u00e1rias aplica\u00e7\u00f5es e \u00e9 utilizada em campos como o reconhecimento facial (ver sistema de reconhecimento facial) e o processamento de imagens m\u00e9dicas.", "token2charspan": [[0, 1], [2, 17], [18, 20], [21, 28], [29, 32], [33, 39], [40, 50], [51, 52], [53, 54], [55, 64], [65, 67], [68, 74], [75, 79], [80, 81], [82, 96], [97, 103], [104, 105], [105, 108], [109, 116], [117, 119], [120, 134], [135, 141], [141, 142], [143, 144], [145, 146], [147, 160], [161, 163], [164, 171], [172, 179], [179, 180]]}
{"doc_key": "ai-test-208", "ner": [[10, 11, "researcher"], [13, 14, "researcher"], [18, 26, "organisation"], [28, 28, "organisation"], [38, 39, "algorithm"], [41, 48, "conference"], [50, 50, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 11, 18, 26, "role", "", false, false], [10, 11, 41, 48, "physical", "", false, false], [10, 11, 41, 48, "temporal", "", false, false], [10, 11, 50, 50, "physical", "", false, false], [13, 14, 18, 26, "role", "", false, false], [13, 14, 41, 48, "temporal", "", false, false], [28, 28, 18, 26, "named", "", false, false], [41, 48, 38, 39, "topic", "", false, false], [50, 50, 41, 48, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Contudo", ",", "a", "utiliza\u00e7\u00e3o", "s\u00f3", "se", "generalizou", "em", "2005", "quando", "Navneet", "Dalal", "e", "Bill", "Triggs", ",", "investigadores", "do", "Instituto", "Nacional", "Franc\u00eas", "de", "Investiga\u00e7\u00e3o", "em", "Inform\u00e1tica", "e", "Automa\u00e7\u00e3o", "(", "INRIA", ")", ",", "apresentaram", "o", "seu", "trabalho", "suplementar", "sobre", "os", "descritores", "HOG", "na", "Confer\u00eancia", "sobre", "Vis\u00e3o", "Inform\u00e1tica", "e", "Reconhecimento", "de", "Padr\u00f5es", "(", "CVPR", ")", "."], "sentence-detokenized": "Contudo, a utiliza\u00e7\u00e3o s\u00f3 se generalizou em 2005 quando Navneet Dalal e Bill Triggs, investigadores do Instituto Nacional Franc\u00eas de Investiga\u00e7\u00e3o em Inform\u00e1tica e Automa\u00e7\u00e3o (INRIA), apresentaram o seu trabalho suplementar sobre os descritores HOG na Confer\u00eancia sobre Vis\u00e3o Inform\u00e1tica e Reconhecimento de Padr\u00f5es (CVPR).", "token2charspan": [[0, 7], [7, 8], [9, 10], [11, 21], [22, 24], [25, 27], [28, 39], [40, 42], [43, 47], [48, 54], [55, 62], [63, 68], [69, 70], [71, 75], [76, 82], [82, 83], [84, 98], [99, 101], [102, 111], [112, 120], [121, 128], [129, 131], [132, 144], [145, 147], [148, 159], [160, 161], [162, 171], [172, 173], [173, 178], [178, 179], [179, 180], [181, 193], [194, 195], [196, 199], [200, 208], [209, 220], [221, 226], [227, 229], [230, 241], [242, 245], [246, 248], [249, 260], [261, 266], [267, 272], [273, 284], [285, 286], [287, 301], [302, 304], [305, 312], [313, 314], [314, 318], [318, 319], [319, 320]]}
{"doc_key": "ai-test-209", "ner": [[6, 6, "university"], [17, 20, "organisation"], [22, 23, "organisation"], [31, 31, "field"], [35, 37, "researcher"], [39, 42, "researcher"], [45, 47, "researcher"], [49, 54, "organisation"], [57, 61, "organisation"], [65, 66, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[22, 23, 31, 31, "related-to", "", false, false], [35, 37, 22, 23, "physical", "", false, false], [35, 37, 22, 23, "role", "", false, false], [39, 42, 22, 23, "physical", "", false, false], [39, 42, 22, 23, "role", "", false, false], [45, 47, 22, 23, "physical", "", false, false], [45, 47, 22, 23, "role", "", false, false], [65, 66, 57, 61, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Antes", "de", "entrar", "para", "a", "faculdade", "Penn", "em", "2002", ",", "passou", "uma", "d\u00e9cada", "(", "1991-2001", ")", "na", "AT", "&", "T", "Labs", "e", "Bell", "Labs", ",", "incluindo", "como", "chefe", "do", "departamento", "de", "IA", "com", "colegas", "como", "Michael", "L.", "Littman", ",", "David", "A", ".", "McAllester", ",", "e", "Richard", "S.", "Sutton", ";", "departamento", "de", "Investiga\u00e7\u00e3o", "de", "Sistemas", "Seguros", ";", "e", "departamento", "de", "Aprendizagem", "de", "M\u00e1quinas", "com", "membros", "como", "Michael", "Collins", "e", "o", "l\u00edder", ")", "."], "sentence-detokenized": "Antes de entrar para a faculdade Penn em 2002, passou uma d\u00e9cada (1991-2001) na AT & T Labs e Bell Labs, incluindo como chefe do departamento de IA com colegas como Michael L. Littman, David A. McAllester, e Richard S. Sutton; departamento de Investiga\u00e7\u00e3o de Sistemas Seguros; e departamento de Aprendizagem de M\u00e1quinas com membros como Michael Collins e o l\u00edder).", "token2charspan": [[0, 5], [6, 8], [9, 15], [16, 20], [21, 22], [23, 32], [33, 37], [38, 40], [41, 45], [45, 46], [47, 53], [54, 57], [58, 64], [65, 66], [66, 75], [75, 76], [77, 79], [80, 82], [83, 84], [85, 86], [87, 91], [92, 93], [94, 98], [99, 103], [103, 104], [105, 114], [115, 119], [120, 125], [126, 128], [129, 141], [142, 144], [145, 147], [148, 151], [152, 159], [160, 164], [165, 172], [173, 175], [176, 183], [183, 184], [185, 190], [191, 192], [192, 193], [194, 204], [204, 205], [206, 207], [208, 215], [216, 218], [219, 225], [225, 226], [227, 239], [240, 242], [243, 255], [256, 258], [259, 267], [268, 275], [275, 276], [277, 278], [279, 291], [292, 294], [295, 307], [308, 310], [311, 319], [320, 323], [324, 331], [332, 336], [337, 344], [345, 352], [353, 354], [355, 356], [357, 362], [362, 363], [363, 364]]}
{"doc_key": "ai-test-210", "ner": [[11, 12, "field"], [20, 22, "field"], [27, 30, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 20, 22, "compare", "", false, false], [27, 30, 20, 22, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Quando", "os", "dados", "n\u00e3o", "s\u00e3o", "rotulados", ",", "n\u00e3o", "\u00e9", "poss\u00edvel", "uma", "aprendizagem", "supervisionada", ",", "e", "\u00e9", "necess\u00e1ria", "uma", "abordagem", "de", "aprendizagem", "n\u00e3o", "supervisionada", "que", "tente", "encontrar", "uma", "an\u00e1lise", "natural", "de", "Cluster", "para", "grupos", ",", "e", "depois", "mapear", "novos", "dados", "para", "estes", "grupos", "formados", "."], "sentence-detokenized": "Quando os dados n\u00e3o s\u00e3o rotulados, n\u00e3o \u00e9 poss\u00edvel uma aprendizagem supervisionada, e \u00e9 necess\u00e1ria uma abordagem de aprendizagem n\u00e3o supervisionada que tente encontrar uma an\u00e1lise natural de Cluster para grupos, e depois mapear novos dados para estes grupos formados.", "token2charspan": [[0, 6], [7, 9], [10, 15], [16, 19], [20, 23], [24, 33], [33, 34], [35, 38], [39, 40], [41, 49], [50, 53], [54, 66], [67, 81], [81, 82], [83, 84], [85, 86], [87, 97], [98, 101], [102, 111], [112, 114], [115, 127], [128, 131], [132, 146], [147, 150], [151, 156], [157, 166], [167, 170], [171, 178], [179, 186], [187, 189], [190, 197], [198, 202], [203, 209], [209, 210], [211, 212], [213, 219], [220, 226], [227, 232], [233, 238], [239, 243], [244, 249], [250, 256], [257, 265], [265, 266]]}
{"doc_key": "ai-test-211", "ner": [[3, 3, "field"], [13, 15, "organisation"], [22, 23, "field"], [25, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 13, 15, "origin", "", false, false], [3, 3, 22, 23, "part-of", "", false, false], [3, 3, 25, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Este", "campo", "da", "inform\u00e1tica", "desenvolveu-se", "nos", "anos", "50", "em", "institui\u00e7\u00f5es", "acad\u00e9micas", "como", "o", "MIT", "A.I.", "Lab", ",", "originalmente", "como", "um", "ramo", "da", "intelig\u00eancia", "artificial", "e", "rob\u00f3tica", "."], "sentence-detokenized": "Este campo da inform\u00e1tica desenvolveu-se nos anos 50 em institui\u00e7\u00f5es acad\u00e9micas como o MIT A.I. Lab, originalmente como um ramo da intelig\u00eancia artificial e rob\u00f3tica.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 25], [26, 40], [41, 44], [45, 49], [50, 52], [53, 55], [56, 68], [69, 79], [80, 84], [85, 86], [87, 90], [91, 95], [96, 99], [99, 100], [101, 114], [115, 119], [120, 122], [123, 127], [128, 130], [131, 143], [144, 154], [155, 156], [157, 165], [165, 166]]}
{"doc_key": "ai-test-212", "ner": [[7, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Tamb\u00e9m", "poderia", "ser", "substitu\u00edda", "pela", "equa\u00e7\u00e3o", "de", "perda", "de", "registo", "abaixo", ":"], "sentence-detokenized": "Tamb\u00e9m poderia ser substitu\u00edda pela equa\u00e7\u00e3o de perda de registo abaixo:", "token2charspan": [[0, 6], [7, 14], [15, 18], [19, 30], [31, 35], [36, 43], [44, 46], [47, 52], [53, 55], [56, 63], [64, 70], [70, 71]]}
{"doc_key": "ai-test-213", "ner": [[1, 3, "organisation"], [6, 10, "organisation"], [13, 17, "university"], [19, 19, "university"], [21, 23, "university"], [26, 28, "university"], [30, 30, "country"], [38, 38, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[1, 3, 38, 38, "related-to", "research_leader_in_field", false, false], [6, 10, 1, 3, "named", "", false, false], [6, 10, 38, 38, "related-to", "research_leader_in_field", false, false], [13, 17, 38, 38, "related-to", "research_leader_in_field", false, false], [19, 19, 38, 38, "related-to", "research_leader_in_field", false, false], [21, 23, 38, 38, "related-to", "research_leader_in_field", false, false], [26, 28, 30, 30, "physical", "", false, false], [26, 28, 38, 38, "related-to", "research_leader_in_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["O", "Shirley", "Ryan", "AbilityLab", "(", "antigo", "Instituto", "de", "Reabilita\u00e7\u00e3o", "de", "Chicago", ")", ",", "Universidade", "da", "Calif\u00f3rnia", "em", "Berkeley", ",", "MIT", ",", "Universidade", "de", "Stanford", ",", "e", "Universidade", "de", "Twente", "na", "Holanda", ",", "s\u00e3o", "os", "l\u00edderes", "da", "investiga\u00e7\u00e3o", "em", "biomecatr\u00f3nica", "."], "sentence-detokenized": "O Shirley Ryan AbilityLab (antigo Instituto de Reabilita\u00e7\u00e3o de Chicago), Universidade da Calif\u00f3rnia em Berkeley, MIT, Universidade de Stanford, e Universidade de Twente na Holanda, s\u00e3o os l\u00edderes da investiga\u00e7\u00e3o em biomecatr\u00f3nica.", "token2charspan": [[0, 1], [2, 9], [10, 14], [15, 25], [26, 27], [27, 33], [34, 43], [44, 46], [47, 59], [60, 62], [63, 70], [70, 71], [71, 72], [73, 85], [86, 88], [89, 99], [100, 102], [103, 111], [111, 112], [113, 116], [116, 117], [118, 130], [131, 133], [134, 142], [142, 143], [144, 145], [146, 158], [159, 161], [162, 168], [169, 171], [172, 179], [179, 180], [181, 184], [185, 187], [188, 195], [196, 198], [199, 211], [212, 214], [215, 229], [229, 230]]}
{"doc_key": "ai-test-214", "ner": [[29, 34, "metrics"], [45, 47, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Dado", "um", "conjunto", "de", "valores", "previstos", "e", "um", "conjunto", "correspondente", "de", "valores", "reais", "para", "X", "durante", "v\u00e1rios", "per\u00edodos", "de", "tempo", ",", "uma", "t\u00e9cnica", "de", "avalia\u00e7\u00e3o", "comum", "\u00e9", "utilizar", "o", "erro", "m\u00e9dio", "de", "previs\u00e3o", "ao", "quadrado", ";", "outras", "medidas", "tamb\u00e9m", "est\u00e3o", "dispon\u00edveis", "(", "ver", "previs\u00e3o", "#", "precis\u00e3o", "da", "previs\u00e3o", ")", "."], "sentence-detokenized": "Dado um conjunto de valores previstos e um conjunto correspondente de valores reais para X durante v\u00e1rios per\u00edodos de tempo, uma t\u00e9cnica de avalia\u00e7\u00e3o comum \u00e9 utilizar o erro m\u00e9dio de previs\u00e3o ao quadrado; outras medidas tamb\u00e9m est\u00e3o dispon\u00edveis (ver previs\u00e3o # precis\u00e3o da previs\u00e3o).", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 19], [20, 27], [28, 37], [38, 39], [40, 42], [43, 51], [52, 66], [67, 69], [70, 77], [78, 83], [84, 88], [89, 90], [91, 98], [99, 105], [106, 114], [115, 117], [118, 123], [123, 124], [125, 128], [129, 136], [137, 139], [140, 149], [150, 155], [156, 157], [158, 166], [167, 168], [169, 173], [174, 179], [180, 182], [183, 191], [192, 194], [195, 203], [203, 204], [205, 211], [212, 219], [220, 226], [227, 232], [233, 244], [245, 246], [246, 249], [250, 258], [259, 260], [261, 269], [270, 272], [273, 281], [281, 282], [282, 283]]}
{"doc_key": "ai-test-215", "ner": [[14, 14, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Outras", "medidas", ",", "tais", "como", "a", "propor\u00e7\u00e3o", "de", "previs\u00f5es", "correctas", "(", "tamb\u00e9m", "conhecidas", "como", "exactid\u00e3o", ")", ",", "n\u00e3o", "s\u00e3o", "\u00fateis", "quando", "as", "duas", "classes", "s\u00e3o", "de", "tamanhos", "muito", "diferentes", "."], "sentence-detokenized": "Outras medidas, tais como a propor\u00e7\u00e3o de previs\u00f5es correctas (tamb\u00e9m conhecidas como exactid\u00e3o), n\u00e3o s\u00e3o \u00fateis quando as duas classes s\u00e3o de tamanhos muito diferentes.", "token2charspan": [[0, 6], [7, 14], [14, 15], [16, 20], [21, 25], [26, 27], [28, 37], [38, 40], [41, 50], [51, 60], [61, 62], [62, 68], [69, 79], [80, 84], [85, 94], [94, 95], [95, 96], [97, 100], [101, 104], [105, 110], [111, 117], [118, 120], [121, 125], [126, 133], [134, 137], [138, 140], [141, 149], [150, 155], [156, 166], [166, 167]]}
{"doc_key": "ai-test-216", "ner": [[5, 5, "product"], [13, 18, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 13, 18, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "primeira", "vers\u00e3o", "alfa", "do", "OpenCV", "foi", "divulgada", "ao", "p\u00fablico", "na", "Confer\u00eancia", "sobre", "Vis\u00e3o", "Inform\u00e1tica", "e", "Reconhecimento", "de", "Padr\u00f5es", "em", "2000", ",", "e", "cinco", "betas", "foram", "lan\u00e7ados", "entre", "2001", "e", "2005", "."], "sentence-detokenized": "A primeira vers\u00e3o alfa do OpenCV foi divulgada ao p\u00fablico na Confer\u00eancia sobre Vis\u00e3o Inform\u00e1tica e Reconhecimento de Padr\u00f5es em 2000, e cinco betas foram lan\u00e7ados entre 2001 e 2005.", "token2charspan": [[0, 1], [2, 10], [11, 17], [18, 22], [23, 25], [26, 32], [33, 36], [37, 46], [47, 49], [50, 57], [58, 60], [61, 72], [73, 78], [79, 84], [85, 96], [97, 98], [99, 113], [114, 116], [117, 124], [125, 127], [128, 132], [132, 133], [134, 135], [136, 141], [142, 147], [148, 153], [154, 162], [163, 168], [169, 173], [174, 175], [176, 180], [180, 181]]}
{"doc_key": "ai-test-217", "ner": [[25, 25, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Foram", "apresentados", "resultados", "que", "d\u00e3o", "uma", "correla\u00e7\u00e3o", "de", "at\u00e9", "0,964", "com", "o", "julgamento", "humano", "ao", "n\u00edvel", "do", "corpus", ",", "em", "compara\u00e7\u00e3o", "com", "a", "realiza\u00e7\u00e3o", "da", "BLEU", "de", "0,817", "no", "mesmo", "conjunto", "de", "dados", "."], "sentence-detokenized": "Foram apresentados resultados que d\u00e3o uma correla\u00e7\u00e3o de at\u00e9 0,964 com o julgamento humano ao n\u00edvel do corpus, em compara\u00e7\u00e3o com a realiza\u00e7\u00e3o da BLEU de 0,817 no mesmo conjunto de dados.", "token2charspan": [[0, 5], [6, 18], [19, 29], [30, 33], [34, 37], [38, 41], [42, 52], [53, 55], [56, 59], [60, 65], [66, 69], [70, 71], [72, 82], [83, 89], [90, 92], [93, 98], [99, 101], [102, 108], [108, 109], [110, 112], [113, 123], [124, 127], [128, 129], [130, 140], [141, 143], [144, 148], [149, 151], [152, 157], [158, 160], [161, 166], [167, 175], [176, 178], [179, 184], [184, 185]]}
{"doc_key": "ai-test-218", "ner": [[4, 4, "metrics"], [22, 22, "metrics"], [24, 25, "metrics"], [27, 27, "metrics"], [38, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 22, 22, "compare", "", false, false], [4, 4, 24, 25, "compare", "", false, false], [4, 4, 27, 27, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Uma", "vers\u00e3o", "inicial", "do", "VMAF", "demonstrou", "ter", "um", "desempenho", "superior", "a", "outras", "m\u00e9tricas", "de", "qualidade", "de", "imagem", "e", "v\u00eddeo", ",", "tais", "como", "SSIM", ",", "PSNR", "-HVS", "e", "VQM-VFD", "em", "tr\u00eas", "de", "quatro", "conjuntos", "de", "dados", "em", "termos", "de", "precis\u00e3o", "de", "previs\u00e3o", ",", "quando", "comparados", "com", "classifica\u00e7\u00f5es", "subjectivas", "."], "sentence-detokenized": "Uma vers\u00e3o inicial do VMAF demonstrou ter um desempenho superior a outras m\u00e9tricas de qualidade de imagem e v\u00eddeo, tais como SSIM, PSNR -HVS e VQM-VFD em tr\u00eas de quatro conjuntos de dados em termos de precis\u00e3o de previs\u00e3o, quando comparados com classifica\u00e7\u00f5es subjectivas.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 21], [22, 26], [27, 37], [38, 41], [42, 44], [45, 55], [56, 64], [65, 66], [67, 73], [74, 82], [83, 85], [86, 95], [96, 98], [99, 105], [106, 107], [108, 113], [113, 114], [115, 119], [120, 124], [125, 129], [129, 130], [131, 135], [136, 140], [141, 142], [143, 150], [151, 153], [154, 158], [159, 161], [162, 168], [169, 178], [179, 181], [182, 187], [188, 190], [191, 197], [198, 200], [201, 209], [210, 212], [213, 221], [221, 222], [223, 229], [230, 240], [241, 244], [245, 259], [260, 271], [271, 272]]}
{"doc_key": "ai-test-219", "ner": [[18, 19, "task"], [25, 27, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 19, 25, 27, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Por", "exemplo", ",", "a", "ambiguidade", "do", "'", "rato", "'", "(", "animal", "ou", "dispositivo", ")", "n\u00e3o", "\u00e9", "relevante", "na", "tradu\u00e7\u00e3o", "autom\u00e1tica", ",", "mas", "\u00e9", "relevante", "na", "recupera\u00e7\u00e3o", "de", "informa\u00e7\u00e3o", "."], "sentence-detokenized": "Por exemplo, a ambiguidade do 'rato' (animal ou dispositivo) n\u00e3o \u00e9 relevante na tradu\u00e7\u00e3o autom\u00e1tica, mas \u00e9 relevante na recupera\u00e7\u00e3o de informa\u00e7\u00e3o.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 14], [15, 26], [27, 29], [30, 31], [31, 35], [35, 36], [37, 38], [38, 44], [45, 47], [48, 59], [59, 60], [61, 64], [65, 66], [67, 76], [77, 79], [80, 88], [89, 99], [99, 100], [101, 104], [105, 106], [107, 116], [117, 119], [120, 131], [132, 134], [135, 145], [145, 146]]}
{"doc_key": "ai-test-220", "ner": [[0, 2, "algorithm"], [7, 9, "field"], [12, 14, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 0, 2, "usage", "", false, false], [12, 14, 7, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["O", "hashing", "geom\u00e9trico", "foi", "originalmente", "sugerido", "na", "vis\u00e3o", "por", "computador", "para", "o", "reconhecimento", "de", "objectos", "em", "2D", "e", "3D", ","], "sentence-detokenized": "O hashing geom\u00e9trico foi originalmente sugerido na vis\u00e3o por computador para o reconhecimento de objectos em 2D e 3D,", "token2charspan": [[0, 1], [2, 9], [10, 20], [21, 24], [25, 38], [39, 47], [48, 50], [51, 56], [57, 60], [61, 71], [72, 76], [77, 78], [79, 93], [94, 96], [97, 105], [106, 108], [109, 111], [112, 113], [114, 116], [116, 117]]}
{"doc_key": "ai-test-221", "ner": [[7, 8, "field"], [13, 14, "field"], [17, 19, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 14, 7, 8, "part-of", "subfield", false, false], [17, 19, 7, 8, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Forma", "uma", "das", "tr\u00eas", "principais", "categorias", "da", "aprendizagem", "mec\u00e2nica", ",", "juntamente", "com", "a", "aprendizagem", "supervisionada", "e", "a", "aprendizagem", "de", "refor\u00e7o", "."], "sentence-detokenized": "Forma uma das tr\u00eas principais categorias da aprendizagem mec\u00e2nica, juntamente com a aprendizagem supervisionada e a aprendizagem de refor\u00e7o.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 18], [19, 29], [30, 40], [41, 43], [44, 56], [57, 65], [65, 66], [67, 77], [78, 81], [82, 83], [84, 96], [97, 111], [112, 113], [114, 115], [116, 128], [129, 131], [132, 139], [139, 140]]}
{"doc_key": "ai-test-222", "ner": [[0, 3, "field"], [19, 19, "field"], [21, 23, "field"], [25, 27, "field"], [29, 31, "field"], [33, 36, "field"], [38, 39, "field"], [41, 43, "field"], [45, 45, "field"], [47, 48, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 3, 19, 19, "part-of", "subfield", false, false], [0, 3, 21, 23, "part-of", "subfield", false, false], [0, 3, 25, 27, "part-of", "subfield", false, false], [0, 3, 29, 31, "part-of", "subfield", false, false], [0, 3, 33, 36, "part-of", "subfield", false, false], [0, 3, 38, 39, "part-of", "subfield", false, false], [0, 3, 41, 43, "part-of", "subfield", false, false], [0, 3, 45, 45, "part-of", "subfield", false, false], [0, 3, 47, 48, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["A", "aprendizagem", "do", "refor\u00e7o", ",", "devido", "\u00e0", "sua", "generalidade", ",", "\u00e9", "estudada", "em", "muitas", "outras", "disciplinas", ",", "tais", "como", "jogo", ",", "teoria", "de", "controlo", ",", "investiga\u00e7\u00e3o", "de", "opera\u00e7\u00f5es", ",", "teoria", "da", "informa\u00e7\u00e3o", ",", "optimiza\u00e7\u00e3o", "baseada", "na", "simula\u00e7\u00e3o", ",", "sistemas", "multi-agentes", ",", "intelig\u00eancia", "de", "enxame", ",", "estat\u00edstica", "e", "algoritmos", "gen\u00e9ticos", "."], "sentence-detokenized": "A aprendizagem do refor\u00e7o, devido \u00e0 sua generalidade, \u00e9 estudada em muitas outras disciplinas, tais como jogo, teoria de controlo, investiga\u00e7\u00e3o de opera\u00e7\u00f5es, teoria da informa\u00e7\u00e3o, optimiza\u00e7\u00e3o baseada na simula\u00e7\u00e3o, sistemas multi-agentes, intelig\u00eancia de enxame, estat\u00edstica e algoritmos gen\u00e9ticos.", "token2charspan": [[0, 1], [2, 14], [15, 17], [18, 25], [25, 26], [27, 33], [34, 35], [36, 39], [40, 52], [52, 53], [54, 55], [56, 64], [65, 67], [68, 74], [75, 81], [82, 93], [93, 94], [95, 99], [100, 104], [105, 109], [109, 110], [111, 117], [118, 120], [121, 129], [129, 130], [131, 143], [144, 146], [147, 156], [156, 157], [158, 164], [165, 167], [168, 178], [178, 179], [180, 191], [192, 199], [200, 202], [203, 212], [212, 213], [214, 222], [223, 236], [236, 237], [238, 250], [251, 253], [254, 260], [260, 261], [262, 273], [274, 275], [276, 286], [287, 296], [296, 297]]}
{"doc_key": "ai-test-223", "ner": [[0, 3, "field"], [9, 10, "field"], [13, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 9, 10, "related-to", "", false, false], [0, 3, 13, 15, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["O", "reconhecimento", "de", "padr\u00f5es", "est\u00e1", "intimamente", "relacionado", "com", "a", "intelig\u00eancia", "artificial", "e", "a", "aprendizagem", "de", "m\u00e1quinas", ","], "sentence-detokenized": "O reconhecimento de padr\u00f5es est\u00e1 intimamente relacionado com a intelig\u00eancia artificial e a aprendizagem de m\u00e1quinas,", "token2charspan": [[0, 1], [2, 16], [17, 19], [20, 27], [28, 32], [33, 44], [45, 56], [57, 60], [61, 62], [63, 75], [76, 86], [87, 88], [89, 90], [91, 103], [104, 106], [107, 115], [115, 116]]}
{"doc_key": "ai-test-224", "ner": [[12, 13, "algorithm"], [15, 16, "field"], [18, 20, "field"], [32, 34, "task"], [36, 36, "task"], [38, 40, "task"], [42, 43, "algorithm"], [45, 48, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[12, 13, 15, 16, "related-to", "", false, false], [12, 13, 18, 20, "related-to", "", false, false], [32, 34, 12, 13, "usage", "", true, false], [36, 36, 12, 13, "usage", "", true, false], [38, 40, 12, 13, "usage", "", true, false], [42, 43, 12, 13, "usage", "", true, false], [45, 48, 12, 13, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["O", "software", "\u00e9", "utilizado", "para", "conceber", ",", "treinar", "e", "implementar", "modelos", "de", "rede", "neural", "(", "aprendizagem", "supervisionada", "e", "aprendizagem", "n\u00e3o", "supervisionada", ")", "para", "executar", "uma", "grande", "variedade", "de", "tarefas", ",", "tais", "como", "extrac\u00e7\u00e3o", "de", "dados", ",", "classifica\u00e7\u00e3o", ",", "aproxima\u00e7\u00e3o", "de", "fun\u00e7\u00f5es", ",", "regress\u00e3o", "multivariada", "e", "previs\u00e3o", "de", "s\u00e9ries", "temporais", "."], "sentence-detokenized": "O software \u00e9 utilizado para conceber, treinar e implementar modelos de rede neural (aprendizagem supervisionada e aprendizagem n\u00e3o supervisionada) para executar uma grande variedade de tarefas, tais como extrac\u00e7\u00e3o de dados, classifica\u00e7\u00e3o, aproxima\u00e7\u00e3o de fun\u00e7\u00f5es, regress\u00e3o multivariada e previs\u00e3o de s\u00e9ries temporais.", "token2charspan": [[0, 1], [2, 10], [11, 12], [13, 22], [23, 27], [28, 36], [36, 37], [38, 45], [46, 47], [48, 59], [60, 67], [68, 70], [71, 75], [76, 82], [83, 84], [84, 96], [97, 111], [112, 113], [114, 126], [127, 130], [131, 145], [145, 146], [147, 151], [152, 160], [161, 164], [165, 171], [172, 181], [182, 184], [185, 192], [192, 193], [194, 198], [199, 203], [204, 213], [214, 216], [217, 222], [222, 223], [224, 237], [237, 238], [239, 250], [251, 253], [254, 261], [261, 262], [263, 272], [273, 285], [286, 287], [288, 296], [297, 299], [300, 306], [307, 316], [316, 317]]}
{"doc_key": "ai-test-225", "ner": [[7, 13, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Em", "2016", ",", "foi", "eleito", "Fellow", "of", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "Em 2016, foi eleito Fellow of Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 19], [20, 26], [27, 29], [30, 41], [42, 45], [46, 49], [50, 61], [62, 64], [65, 75], [76, 88], [88, 89]]}
{"doc_key": "ai-test-226", "ner": [[3, 6, "organisation"], [12, 17, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["\u00c9", "membro", "da", "Academia", "Nacional", "das", "Ci\u00eancias", "(", "desde", "2005", ")", ",", "Academia", "Americana", "de", "Artes", "e", "Ci\u00eancias", "(", "desde", "2009", ")", ","], "sentence-detokenized": "\u00c9 membro da Academia Nacional das Ci\u00eancias (desde 2005), Academia Americana de Artes e Ci\u00eancias (desde 2009),", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 20], [21, 29], [30, 33], [34, 42], [43, 44], [44, 49], [50, 54], [54, 55], [55, 56], [57, 65], [66, 75], [76, 78], [79, 84], [85, 86], [87, 95], [96, 97], [97, 102], [103, 107], [107, 108], [108, 109]]}
{"doc_key": "ai-test-227", "ner": [[2, 5, "misc"], [12, 13, "product"], [18, 18, "country"], [21, 21, "country"], [26, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 13, 2, 5, "temporal", "", false, false], [12, 13, 18, 18, "physical", "", false, false], [12, 13, 21, 21, "physical", "", false, false], [12, 13, 26, 27, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Durante", "a", "Guerra", "do", "Yom", "Kippur", "de", "1973", ",", "as", "baterias", "de", "m\u00edsseis", "terra-ar", "fornecidas", "pelos", "sovi\u00e9ticos", "no", "Egipto", "e", "na", "S\u00edria", "causaram", "pesados", "danos", "aos", "ca\u00e7as", "israelitas", "."], "sentence-detokenized": "Durante a Guerra do Yom Kippur de 1973, as baterias de m\u00edsseis terra-ar fornecidas pelos sovi\u00e9ticos no Egipto e na S\u00edria causaram pesados danos aos ca\u00e7as israelitas.", "token2charspan": [[0, 7], [8, 9], [10, 16], [17, 19], [20, 23], [24, 30], [31, 33], [34, 38], [38, 39], [40, 42], [43, 51], [52, 54], [55, 62], [63, 71], [72, 82], [83, 88], [89, 99], [100, 102], [103, 109], [110, 111], [112, 114], [115, 120], [121, 129], [130, 137], [138, 143], [144, 147], [148, 153], [154, 164], [164, 165]]}
{"doc_key": "ai-test-228", "ner": [[12, 13, "product"], [17, 20, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 20, 12, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Outro", "recurso", "(", "gratuito", "mas", "com", "direitos", "de", "autor", ")", "\u00e9", "o", "livro", "HTK", "(", "e", "o", "conjunto", "de", "ferramentas", "HTK", "que", "o", "acompanha", ")", "."], "sentence-detokenized": "Outro recurso (gratuito mas com direitos de autor) \u00e9 o livro HTK (e o conjunto de ferramentas HTK que o acompanha).", "token2charspan": [[0, 5], [6, 13], [14, 15], [15, 23], [24, 27], [28, 31], [32, 40], [41, 43], [44, 49], [49, 50], [51, 52], [53, 54], [55, 60], [61, 64], [65, 66], [66, 67], [68, 69], [70, 78], [79, 81], [82, 93], [94, 97], [98, 101], [102, 103], [104, 113], [113, 114], [114, 115]]}
{"doc_key": "ai-test-229", "ner": [[8, 10, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["-", "foram", "tomadas", "no", "Simp\u00f3sio", "da", "Primavera", "de", "2004", "da", "AAAI", ",", "onde", "linguistas", ",", "cientistas", "inform\u00e1ticos", ",", "e", "outros", "investigadores", "interessados", "alinharam", "primeiro", "os", "interesses", "e", "propuseram", "tarefas", "partilhadas", "e", "conjuntos", "de", "dados", "de", "refer\u00eancia", "para", "a", "investiga\u00e7\u00e3o", "computacional", "sistem\u00e1tica", "sobre", "o", "afecto", ",", "o", "apelo", ",", "a", "subjectividade", ",", "e", "o", "sentimento", "em", "texto", "."], "sentence-detokenized": "- foram tomadas no Simp\u00f3sio da Primavera de 2004 da AAAI, onde linguistas, cientistas inform\u00e1ticos, e outros investigadores interessados alinharam primeiro os interesses e propuseram tarefas partilhadas e conjuntos de dados de refer\u00eancia para a investiga\u00e7\u00e3o computacional sistem\u00e1tica sobre o afecto, o apelo, a subjectividade, e o sentimento em texto.", "token2charspan": [[0, 1], [2, 7], [8, 15], [16, 18], [19, 27], [28, 30], [31, 40], [41, 43], [44, 48], [49, 51], [52, 56], [56, 57], [58, 62], [63, 73], [73, 74], [75, 85], [86, 98], [98, 99], [100, 101], [102, 108], [109, 123], [124, 136], [137, 146], [147, 155], [156, 158], [159, 169], [170, 171], [172, 182], [183, 190], [191, 202], [203, 204], [205, 214], [215, 217], [218, 223], [224, 226], [227, 237], [238, 242], [243, 244], [245, 257], [258, 271], [272, 283], [284, 289], [290, 291], [292, 298], [298, 299], [300, 301], [302, 307], [307, 308], [309, 310], [311, 325], [325, 326], [327, 328], [329, 330], [331, 341], [342, 344], [345, 350], [350, 351]]}
{"doc_key": "ai-test-230", "ner": [[11, 12, "task"], [19, 21, "task"], [23, 26, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Uma", "\u00fanica", "grelha", "pode", "ser", "analisada", "tanto", "para", "o", "conte\u00fado", "(", "inspec\u00e7\u00e3o", "ocular", ")", "como", "para", "a", "estrutura", "(", "an\u00e1lise", "de", "agrupamento", ",", "an\u00e1lise", "de", "componentes", "principais", ",", "e", "uma", "variedade", "de", "\u00edndices", "estruturais", "relacionados", "com", "a", "complexidade", "e", "o", "alcance", "das", "classifica\u00e7\u00f5es", "que", "s\u00e3o", "as", "t\u00e9cnicas", "principais", "utilizadas", ")", "."], "sentence-detokenized": "Uma \u00fanica grelha pode ser analisada tanto para o conte\u00fado (inspec\u00e7\u00e3o ocular) como para a estrutura (an\u00e1lise de agrupamento, an\u00e1lise de componentes principais, e uma variedade de \u00edndices estruturais relacionados com a complexidade e o alcance das classifica\u00e7\u00f5es que s\u00e3o as t\u00e9cnicas principais utilizadas).", "token2charspan": [[0, 3], [4, 9], [10, 16], [17, 21], [22, 25], [26, 35], [36, 41], [42, 46], [47, 48], [49, 57], [58, 59], [59, 68], [69, 75], [75, 76], [77, 81], [82, 86], [87, 88], [89, 98], [99, 100], [100, 107], [108, 110], [111, 122], [122, 123], [124, 131], [132, 134], [135, 146], [147, 157], [157, 158], [159, 160], [161, 164], [165, 174], [175, 177], [178, 185], [186, 197], [198, 210], [211, 214], [215, 216], [217, 229], [230, 231], [232, 233], [234, 241], [242, 245], [246, 260], [261, 264], [265, 268], [269, 271], [272, 280], [281, 291], [292, 302], [302, 303], [303, 304]]}
{"doc_key": "ai-test-231", "ner": [[3, 5, "organisation"], [11, 11, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Em", "2018", ",", "a", "Toyota", "era", "considerada", "como", "estando", "atrasada", "no", "auto-condu\u00e7\u00e3o", "e", "necessitando", "de", "inova\u00e7\u00e3o", "."], "sentence-detokenized": "Em 2018, a Toyota era considerada como estando atrasada no auto-condu\u00e7\u00e3o e necessitando de inova\u00e7\u00e3o.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 17], [18, 21], [22, 33], [34, 38], [39, 46], [47, 55], [56, 58], [59, 72], [73, 74], [75, 87], [88, 90], [91, 99], [99, 100]]}
{"doc_key": "ai-test-232", "ner": [[43, 45, "misc"], [47, 49, "misc"], [52, 57, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Tais", "alvos", "incluem", "objectos", "naturais", "como", "o", "solo", ",", "o", "mar", ",", "a", "precipita\u00e7\u00e3o", "(", "como", "chuva", ",", "neve", "ou", "granizo", ")", ",", "tempestades", "de", "areia", ",", "animais", "(", "especialmente", "aves", ")", ",", "turbul\u00eancia", "atmosf\u00e9rica", ",", "e", "outros", "efeitos", "atmosf\u00e9ricos", ",", "tais", "como", "reflexos", "da", "ionosfera", ",", "trilhos", "de", "meteoros", ",", "e", "tr\u00eas", "espig\u00f5es", "de", "dispers\u00e3o", "de", "corpos", "."], "sentence-detokenized": "Tais alvos incluem objectos naturais como o solo, o mar, a precipita\u00e7\u00e3o (como chuva, neve ou granizo), tempestades de areia, animais (especialmente aves), turbul\u00eancia atmosf\u00e9rica, e outros efeitos atmosf\u00e9ricos, tais como reflexos da ionosfera, trilhos de meteoros, e tr\u00eas espig\u00f5es de dispers\u00e3o de corpos.", "token2charspan": [[0, 4], [5, 10], [11, 18], [19, 27], [28, 36], [37, 41], [42, 43], [44, 48], [48, 49], [50, 51], [52, 55], [55, 56], [57, 58], [59, 71], [72, 73], [73, 77], [78, 83], [83, 84], [85, 89], [90, 92], [93, 100], [100, 101], [101, 102], [103, 114], [115, 117], [118, 123], [123, 124], [125, 132], [133, 134], [134, 147], [148, 152], [152, 153], [153, 154], [155, 166], [167, 178], [178, 179], [180, 181], [182, 188], [189, 196], [197, 209], [209, 210], [211, 215], [216, 220], [221, 229], [230, 232], [233, 242], [242, 243], [244, 251], [252, 254], [255, 263], [263, 264], [265, 266], [267, 271], [272, 280], [281, 283], [284, 293], [294, 296], [297, 303], [303, 304]]}
{"doc_key": "ai-test-233", "ner": [[18, 18, "product"], [38, 39, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["No", "planeamento", "e", "controlo", ",", "a", "diferen\u00e7a", "essencial", "entre", "human\u00f3ides", "e", "outros", "tipos", "de", "rob\u00f4s", "(", "como", "os", "industriais", ")", "\u00e9", "que", "o", "movimento", "do", "rob\u00f4", "deve", "ser", "semelhante", "ao", "humano", ",", "utilizando", "locomo\u00e7\u00e3o", "de", "pernas", ",", "especialmente", "marcha", "b\u00edpede", "."], "sentence-detokenized": "No planeamento e controlo, a diferen\u00e7a essencial entre human\u00f3ides e outros tipos de rob\u00f4s (como os industriais) \u00e9 que o movimento do rob\u00f4 deve ser semelhante ao humano, utilizando locomo\u00e7\u00e3o de pernas, especialmente marcha b\u00edpede.", "token2charspan": [[0, 2], [3, 14], [15, 16], [17, 25], [25, 26], [27, 28], [29, 38], [39, 48], [49, 54], [55, 65], [66, 67], [68, 74], [75, 80], [81, 83], [84, 89], [90, 91], [91, 95], [96, 98], [99, 110], [110, 111], [112, 113], [114, 117], [118, 119], [120, 129], [130, 132], [133, 137], [138, 142], [143, 146], [147, 157], [158, 160], [161, 167], [167, 168], [169, 179], [180, 189], [190, 192], [193, 199], [199, 200], [201, 214], [215, 221], [222, 228], [228, 229]]}
{"doc_key": "ai-test-234", "ner": [[1, 3, "algorithm"], [11, 12, "misc"], [15, 15, "metrics"], [20, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "descida", "de", "declive", "pode", "levar", "muitas", "itera\u00e7\u00f5es", "para", "calcular", "um", "m\u00ednimo", "local", "com", "a", "precis\u00e3o", "necess\u00e1ria", ",", "se", "a", "curvatura", "em", "diferentes", "direc\u00e7\u00f5es", "for", "muito", "diferente", "para", "a", "fun\u00e7\u00e3o", "em", "quest\u00e3o", "."], "sentence-detokenized": "A descida de declive pode levar muitas itera\u00e7\u00f5es para calcular um m\u00ednimo local com a precis\u00e3o necess\u00e1ria, se a curvatura em diferentes direc\u00e7\u00f5es for muito diferente para a fun\u00e7\u00e3o em quest\u00e3o.", "token2charspan": [[0, 1], [2, 9], [10, 12], [13, 20], [21, 25], [26, 31], [32, 38], [39, 48], [49, 53], [54, 62], [63, 65], [66, 72], [73, 78], [79, 82], [83, 84], [85, 93], [94, 104], [104, 105], [106, 108], [109, 110], [111, 120], [121, 123], [124, 134], [135, 144], [145, 148], [149, 154], [155, 164], [165, 169], [170, 171], [172, 178], [179, 181], [182, 189], [189, 190]]}
{"doc_key": "ai-test-235", "ner": [[1, 9, "misc"], [14, 14, "misc"], [20, 25, "conference"], [28, 28, "location"], [30, 30, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 9, 14, 14, "part-of", "", true, false], [20, 25, 28, 28, "physical", "", false, true], [28, 28, 30, 30, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "Liga", "de", "Simula\u00e7\u00e3o", "de", "Futebol", "RoboCup", "2D", "de", "1997", "foi", "a", "primeira", "competi\u00e7\u00e3o", "RoboCup", "promovida", "em", "conjunto", "com", "a", "Confer\u00eancia", "Internacional", "Conjunta", "sobre", "Intelig\u00eancia", "Artificial", "realizada", "em", "Nagoya", ",", "Jap\u00e3o", ",", "de", "23", "a", "29", "de", "Agosto", "de", "1997", "."], "sentence-detokenized": "A Liga de Simula\u00e7\u00e3o de Futebol RoboCup 2D de 1997 foi a primeira competi\u00e7\u00e3o RoboCup promovida em conjunto com a Confer\u00eancia Internacional Conjunta sobre Intelig\u00eancia Artificial realizada em Nagoya, Jap\u00e3o, de 23 a 29 de Agosto de 1997.", "token2charspan": [[0, 1], [2, 6], [7, 9], [10, 19], [20, 22], [23, 30], [31, 38], [39, 41], [42, 44], [45, 49], [50, 53], [54, 55], [56, 64], [65, 75], [76, 83], [84, 93], [94, 96], [97, 105], [106, 109], [110, 111], [112, 123], [124, 137], [138, 146], [147, 152], [153, 165], [166, 176], [177, 186], [187, 189], [190, 196], [196, 197], [198, 203], [203, 204], [205, 207], [208, 210], [211, 212], [213, 215], [216, 218], [219, 225], [226, 228], [229, 233], [233, 234]]}
{"doc_key": "ai-test-236", "ner": [[7, 7, "programlang"], [13, 13, "programlang"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Outras", "op\u00e7\u00f5es", "de", "programa\u00e7\u00e3o", "incluem", "um", "ambiente", "Python", "incorporado", ",", "e", "uma", "Consola", "R", "mais", "suporte", "para", "Rserve", "."], "sentence-detokenized": "Outras op\u00e7\u00f5es de programa\u00e7\u00e3o incluem um ambiente Python incorporado, e uma Consola R mais suporte para Rserve.", "token2charspan": [[0, 6], [7, 13], [14, 16], [17, 28], [29, 36], [37, 39], [40, 48], [49, 55], [56, 67], [67, 68], [69, 70], [71, 74], [75, 82], [83, 84], [85, 89], [90, 97], [98, 102], [103, 109], [109, 110]]}
{"doc_key": "ai-test-237", "ner": [[1, 1, "location"], [6, 7, "field"], [9, 9, "field"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"], [31, 33, "field"], [37, 38, "field"], [41, 43, "field"], [47, 48, "field"], [51, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[12, 13, 9, 9, "related-to", "contributes_to_field", true, false], [15, 16, 9, 9, "related-to", "contributes_to_field", true, false], [18, 19, 9, 9, "related-to", "contributes_to_field", true, false], [41, 43, 37, 38, "part-of", "", false, false], [47, 48, 41, 43, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["De", "Bona", "contribuiu", "fundamentalmente", "para", "a", "intelig\u00eancia", "artificial", "e", "rob\u00f3tica", "(", "com", "Wolfram", "Burgard", ",", "Dieter", "Fox", ",", "Sebastian", "Thrun", "entre", "os", "seus", "alunos", ")", ",", "e", "para", "o", "desenvolvimento", "da", "engenharia", "de", "software", ",", "particularmente", "na", "engenharia", "civil", ",", "e", "sistemas", "de", "informa\u00e7\u00e3o", ",", "particularmente", "nas", "geoci\u00eancias", ".", "ganhou", "o", "pr\u00e9mio", "AAAI", "Classic", "Paper", "de", "2016.2014", "."], "sentence-detokenized": "De Bona contribuiu fundamentalmente para a intelig\u00eancia artificial e rob\u00f3tica (com Wolfram Burgard, Dieter Fox, Sebastian Thrun entre os seus alunos), e para o desenvolvimento da engenharia de software, particularmente na engenharia civil, e sistemas de informa\u00e7\u00e3o, particularmente nas geoci\u00eancias. ganhou o pr\u00e9mio AAAI Classic Paper de 2016.2014.", "token2charspan": [[0, 2], [3, 7], [8, 18], [19, 35], [36, 40], [41, 42], [43, 55], [56, 66], [67, 68], [69, 77], [78, 79], [79, 82], [83, 90], [91, 98], [98, 99], [100, 106], [107, 110], [110, 111], [112, 121], [122, 127], [128, 133], [134, 136], [137, 141], [142, 148], [148, 149], [149, 150], [151, 152], [153, 157], [158, 159], [160, 175], [176, 178], [179, 189], [190, 192], [193, 201], [201, 202], [203, 218], [219, 221], [222, 232], [233, 238], [238, 239], [240, 241], [242, 250], [251, 253], [254, 264], [264, 265], [266, 281], [282, 285], [286, 297], [297, 298], [299, 305], [306, 307], [308, 314], [315, 319], [320, 327], [328, 333], [334, 336], [337, 346], [346, 347]]}
{"doc_key": "ai-test-238", "ner": [[2, 6, "conference"], [16, 17, "location"], [19, 19, "location"], [21, 21, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 6, 16, 17, "physical", "", false, false], [16, 17, 19, 19, "physical", "", false, false], [19, 19, 21, 21, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "primeira", "edi\u00e7\u00e3o", "americana", "do", "Campus", "Party", "ter\u00e1", "lugar", "de", "20", "a", "22", "de", "Agosto", "no", "TCF", "Center", "em", "Detroit", ",", "Michigan", "."], "sentence-detokenized": "A primeira edi\u00e7\u00e3o americana do Campus Party ter\u00e1 lugar de 20 a 22 de Agosto no TCF Center em Detroit, Michigan.", "token2charspan": [[0, 1], [2, 10], [11, 17], [18, 27], [28, 30], [31, 37], [38, 43], [44, 48], [49, 54], [55, 57], [58, 60], [61, 62], [63, 65], [66, 68], [69, 75], [76, 78], [79, 82], [83, 89], [90, 92], [93, 100], [100, 101], [102, 110], [110, 111]]}
{"doc_key": "ai-test-239", "ner": [[2, 3, "researcher"], [6, 7, "researcher"], [9, 9, "researcher"], [12, 14, "misc"], [25, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 12, 14, "win-defeat", "", false, false], [6, 7, 12, 14, "win-defeat", "", false, false], [9, 9, 12, 14, "win-defeat", "", false, false], [12, 14, 25, 27, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Juntamente", "com", "Yann", "LeCun", ",", "e", "Yoshua", "Bengio", ",", "Hinton", "ganhou", "o", "Pr\u00e9mio", "Turing", "de", "2018", "por", "avan\u00e7os", "conceptuais", "e", "de", "engenharia", "que", "fizeram", "das", "redes", "neurais", "profundas", "um", "componente", "cr\u00edtico", "da", "computa\u00e7\u00e3o", "."], "sentence-detokenized": "Juntamente com Yann LeCun, e Yoshua Bengio, Hinton ganhou o Pr\u00e9mio Turing de 2018 por avan\u00e7os conceptuais e de engenharia que fizeram das redes neurais profundas um componente cr\u00edtico da computa\u00e7\u00e3o.", "token2charspan": [[0, 10], [11, 14], [15, 19], [20, 25], [25, 26], [27, 28], [29, 35], [36, 42], [42, 43], [44, 50], [51, 57], [58, 59], [60, 66], [67, 73], [74, 76], [77, 81], [82, 85], [86, 93], [94, 105], [106, 107], [108, 110], [111, 121], [122, 125], [126, 133], [134, 137], [138, 143], [144, 151], [152, 161], [162, 164], [165, 175], [176, 183], [184, 186], [187, 197], [197, 198]]}
{"doc_key": "ai-test-240", "ner": [[0, 2, "product"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 9, 9, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Euler", "Math", "Toolbox", "utiliza", "uma", "linguagem", "matricial", "semelhante", "\u00e0", "MATLAB", ",", "um", "sistema", "que", "estava", "em", "desenvolvimento", "desde", "os", "anos", "70", "."], "sentence-detokenized": "Euler Math Toolbox utiliza uma linguagem matricial semelhante \u00e0 MATLAB, um sistema que estava em desenvolvimento desde os anos 70.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 26], [27, 30], [31, 40], [41, 50], [51, 61], [62, 63], [64, 70], [70, 71], [72, 74], [75, 82], [83, 86], [87, 93], [94, 96], [97, 112], [113, 118], [119, 121], [122, 126], [127, 129], [129, 130]]}
{"doc_key": "ai-test-241", "ner": [[12, 12, "programlang"], [14, 15, "programlang"], [17, 17, "programlang"], [19, 19, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Algumas", "l\u00ednguas", "tornam", "isso", "poss\u00edvel", "de", "forma", "port\u00e1til", "(", "por", "exemplo", ",", "Scheme", ",", "Common", "Lisp", ",", "Perl", "ou", "D", ")", "."], "sentence-detokenized": "Algumas l\u00ednguas tornam isso poss\u00edvel de forma port\u00e1til (por exemplo, Scheme, Common Lisp, Perl ou D).", "token2charspan": [[0, 7], [8, 15], [16, 22], [23, 27], [28, 36], [37, 39], [40, 45], [46, 54], [55, 56], [56, 59], [60, 67], [67, 68], [69, 75], [75, 76], [77, 83], [84, 88], [88, 89], [90, 94], [95, 97], [98, 99], [99, 100], [100, 101]]}
{"doc_key": "ai-test-242", "ner": [[7, 7, "misc"], [9, 10, "researcher"], [12, 13, "researcher"], [25, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 9, 10, "artifact", "", false, false], [7, 7, 12, 13, "artifact", "", false, false], [7, 7, 25, 26, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Em", "1969", ",", "um", "famoso", "livro", "intitulado", "Perceptrons", "de", "Marvin", "Minsky", "e", "Seymour", "Papert", "mostrou", "que", "era", "imposs\u00edvel", "para", "estas", "classes", "de", "rede", "aprender", "uma", "fun\u00e7\u00e3o", "XOR", "."], "sentence-detokenized": "Em 1969, um famoso livro intitulado Perceptrons de Marvin Minsky e Seymour Papert mostrou que era imposs\u00edvel para estas classes de rede aprender uma fun\u00e7\u00e3o XOR.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 18], [19, 24], [25, 35], [36, 47], [48, 50], [51, 57], [58, 64], [65, 66], [67, 74], [75, 81], [82, 89], [90, 93], [94, 97], [98, 108], [109, 113], [114, 119], [120, 127], [128, 130], [131, 135], [136, 144], [145, 148], [149, 155], [156, 159], [159, 160]]}
{"doc_key": "ai-test-243", "ner": [[3, 7, "misc"], [12, 14, "product"], [17, 22, "organisation"], [26, 32, "organisation"], [35, 38, "location"], [40, 40, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[17, 22, 12, 14, "usage", "", false, false], [17, 22, 35, 38, "physical", "", false, false], [26, 32, 17, 22, "named", "", false, false], [35, 38, 40, 40, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Grande", "n\u00famero", "de", "documentos", "cient\u00edficos", "e", "t\u00e9cnicos", "russos", "foram", "traduzidos", "usando", "o", "SYSTRAN", "sob", "os", "ausp\u00edcios", "da", "Divis\u00e3o", "de", "Tecnologia", "Estrangeira", "da", "USAF", "(", "mais", "tarde", "Centro", "Nacional", "de", "Intelig\u00eancia", "A\u00e9rea", "e", "Espacial", ")", "na", "Base", "A\u00e9rea", "de", "Wright-Patterson", ",", "Ohio", "."], "sentence-detokenized": "Grande n\u00famero de documentos cient\u00edficos e t\u00e9cnicos russos foram traduzidos usando o SYSTRAN sob os ausp\u00edcios da Divis\u00e3o de Tecnologia Estrangeira da USAF (mais tarde Centro Nacional de Intelig\u00eancia A\u00e9rea e Espacial) na Base A\u00e9rea de Wright-Patterson, Ohio.", "token2charspan": [[0, 6], [7, 13], [14, 16], [17, 27], [28, 39], [40, 41], [42, 50], [51, 57], [58, 63], [64, 74], [75, 81], [82, 83], [84, 91], [92, 95], [96, 98], [99, 108], [109, 111], [112, 119], [120, 122], [123, 133], [134, 145], [146, 148], [149, 153], [154, 155], [155, 159], [160, 165], [166, 172], [173, 181], [182, 184], [185, 197], [198, 203], [204, 205], [206, 214], [214, 215], [216, 218], [219, 223], [224, 229], [230, 232], [233, 249], [249, 250], [251, 255], [255, 256]]}
{"doc_key": "ai-test-244", "ner": [[0, 2, "field"], [6, 8, "field"], [19, 20, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "aprendizagem", "semi-supervisionada", "situa-se", "entre", "a", "aprendizagem", "n\u00e3o", "supervisionada", "(", "sem", "quaisquer", "dados", "de", "forma\u00e7\u00e3o", "rotulada", ")", "e", "a", "aprendizagem", "supervisionada", "(", "com", "dados", "de", "forma\u00e7\u00e3o", "completamente", "rotulada", ")", "."], "sentence-detokenized": "A aprendizagem semi-supervisionada situa-se entre a aprendizagem n\u00e3o supervisionada (sem quaisquer dados de forma\u00e7\u00e3o rotulada) e a aprendizagem supervisionada (com dados de forma\u00e7\u00e3o completamente rotulada).", "token2charspan": [[0, 1], [2, 14], [15, 34], [35, 43], [44, 49], [50, 51], [52, 64], [65, 68], [69, 83], [84, 85], [85, 88], [89, 98], [99, 104], [105, 107], [108, 116], [117, 125], [125, 126], [127, 128], [129, 130], [131, 143], [144, 158], [159, 160], [160, 163], [164, 169], [170, 172], [173, 181], [182, 195], [196, 204], [204, 205], [205, 206]]}
{"doc_key": "ai-test-245", "ner": [[0, 3, "algorithm"], [8, 11, "algorithm"], [31, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 8, 11, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["O", "modelo", "Ann", "-gram", "\u00e9", "um", "tipo", "de", "modelo", "de", "linguagem", "probabil\u00edstico", "para", "prever", "o", "pr\u00f3ximo", "item", "em", "tal", "sequ\u00eancia", "sob", "a", "forma", "de", "um", "(", "n", "-", "1", ")", "-", "modelo", "Markov", "de", "ordem", ".eficiente", "."], "sentence-detokenized": "O modelo Ann -gram \u00e9 um tipo de modelo de linguagem probabil\u00edstico para prever o pr\u00f3ximo item em tal sequ\u00eancia sob a forma de um (n - 1) - modelo Markov de ordem .eficiente.", "token2charspan": [[0, 1], [2, 8], [9, 12], [13, 18], [19, 20], [21, 23], [24, 28], [29, 31], [32, 38], [39, 41], [42, 51], [52, 66], [67, 71], [72, 78], [79, 80], [81, 88], [89, 93], [94, 96], [97, 100], [101, 110], [111, 114], [115, 116], [117, 122], [123, 125], [126, 128], [129, 130], [130, 131], [132, 133], [134, 135], [135, 136], [137, 138], [139, 145], [146, 152], [153, 155], [156, 161], [162, 172], [172, 173]]}
{"doc_key": "ai-test-246", "ner": [[1, 2, "organisation"], [4, 4, "product"], [8, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 4, 4, "usage", "", false, false], [8, 16, 1, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "Cl\u00ednica", "Cleveland", "utilizou", "Cyc", "para", "desenvolver", "uma", "interface", "de", "consulta", "em", "linguagem", "natural", "de", "informa\u00e7\u00e3o", "biom\u00e9dica", ",", "abrangendo", "d\u00e9cadas", "de", "informa\u00e7\u00e3o", "sobre", "cirurgias", "cardiotor\u00e1cicas", "."], "sentence-detokenized": "A Cl\u00ednica Cleveland utilizou Cyc para desenvolver uma interface de consulta em linguagem natural de informa\u00e7\u00e3o biom\u00e9dica, abrangendo d\u00e9cadas de informa\u00e7\u00e3o sobre cirurgias cardiotor\u00e1cicas.", "token2charspan": [[0, 1], [2, 9], [10, 19], [20, 28], [29, 32], [33, 37], [38, 49], [50, 53], [54, 63], [64, 66], [67, 75], [76, 78], [79, 88], [89, 96], [97, 99], [100, 110], [111, 120], [120, 121], [122, 132], [133, 140], [141, 143], [144, 154], [155, 160], [161, 170], [171, 186], [186, 187]]}
{"doc_key": "ai-test-247", "ner": [[7, 8, "country"], [11, 11, "country"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 11, 11, "opposite", "strained_relations", false, false]], "relations_mapping_to_source": [0], "sentence": ["O", "incidente", "esticou", "as", "rela\u00e7\u00f5es", "entre", "os", "Estados", "Unidos", "e", "o", "Jap\u00e3o", ",", "e", "resultou", "na", "deten\u00e7\u00e3o", "e", "acusa\u00e7\u00e3o", "de", "dois", "altos", "executivos", ",", "bem", "como", "na", "imposi\u00e7\u00e3o", "de", "san\u00e7\u00f5es", "\u00e0", "empresa", "por", "ambos", "os", "pa\u00edses", "."], "sentence-detokenized": "O incidente esticou as rela\u00e7\u00f5es entre os Estados Unidos e o Jap\u00e3o, e resultou na deten\u00e7\u00e3o e acusa\u00e7\u00e3o de dois altos executivos, bem como na imposi\u00e7\u00e3o de san\u00e7\u00f5es \u00e0 empresa por ambos os pa\u00edses.", "token2charspan": [[0, 1], [2, 11], [12, 19], [20, 22], [23, 31], [32, 37], [38, 40], [41, 48], [49, 55], [56, 57], [58, 59], [60, 65], [65, 66], [67, 68], [69, 77], [78, 80], [81, 89], [90, 91], [92, 100], [101, 103], [104, 108], [109, 114], [115, 125], [125, 126], [127, 130], [131, 135], [136, 138], [139, 148], [149, 151], [152, 159], [160, 161], [162, 169], [170, 173], [174, 179], [180, 182], [183, 189], [189, 190]]}
{"doc_key": "ai-test-248", "ner": [[7, 9, "algorithm"], [12, 13, "field"], [21, 21, "misc"], [32, 32, "misc"], [37, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 9, 12, 13, "type-of", "", false, false], [21, 21, 12, 13, "part-of", "", true, false], [32, 32, 12, 13, "part-of", "", true, false], [37, 38, 12, 13, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Se", "a", "modelagem", "\u00e9", "feita", "por", "uma", "rede", "neural", "artificial", "ou", "outra", "aprendizagem", "mec\u00e2nica", ",", "a", "optimiza\u00e7\u00e3o", "dos", "par\u00e2metros", "\u00e9", "chamada", "forma\u00e7\u00e3o", ",", "enquanto", "a", "optimiza\u00e7\u00e3o", "dos", "hiperpar\u00e2metros", "do", "modelo", "\u00e9", "chamada", "tuning", "e", "usa", "frequentemente", "a", "valida\u00e7\u00e3o", "cruzada", "."], "sentence-detokenized": "Se a modelagem \u00e9 feita por uma rede neural artificial ou outra aprendizagem mec\u00e2nica, a optimiza\u00e7\u00e3o dos par\u00e2metros \u00e9 chamada forma\u00e7\u00e3o, enquanto a optimiza\u00e7\u00e3o dos hiperpar\u00e2metros do modelo \u00e9 chamada tuning e usa frequentemente a valida\u00e7\u00e3o cruzada.", "token2charspan": [[0, 2], [3, 4], [5, 14], [15, 16], [17, 22], [23, 26], [27, 30], [31, 35], [36, 42], [43, 53], [54, 56], [57, 62], [63, 75], [76, 84], [84, 85], [86, 87], [88, 99], [100, 103], [104, 114], [115, 116], [117, 124], [125, 133], [133, 134], [135, 143], [144, 145], [146, 157], [158, 161], [162, 177], [178, 180], [181, 187], [188, 189], [190, 197], [198, 204], [205, 206], [207, 210], [211, 225], [226, 227], [228, 237], [238, 245], [245, 246]]}
{"doc_key": "ai-test-249", "ner": [[7, 8, "country"], [10, 10, "country"], [12, 12, "country"], [19, 20, "organisation"], [22, 22, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 20, 22, 22, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "vers\u00f5es", "localizadas", "do", "site", "dispon\u00edveis", "no", "Reino", "Unido", ",", "\u00cdndia", "e", "Austr\u00e1lia", "foram", "descontinuadas", "ap\u00f3s", "a", "aquisi\u00e7\u00e3o", "de", "Tomate", "Podre", "pela", "Fandango", "."], "sentence-detokenized": "As vers\u00f5es localizadas do site dispon\u00edveis no Reino Unido, \u00cdndia e Austr\u00e1lia foram descontinuadas ap\u00f3s a aquisi\u00e7\u00e3o de Tomate Podre pela Fandango.", "token2charspan": [[0, 2], [3, 10], [11, 22], [23, 25], [26, 30], [31, 42], [43, 45], [46, 51], [52, 57], [57, 58], [59, 64], [65, 66], [67, 76], [77, 82], [83, 97], [98, 102], [103, 104], [105, 114], [115, 117], [118, 124], [125, 130], [131, 135], [136, 144], [144, 145]]}
{"doc_key": "ai-test-250", "ner": [[2, 2, "task"], [11, 11, "metrics"], [27, 29, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 11, 11, "related-to", "", false, false], [11, 11, 27, 29, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["O", "modelo", "NER", "\u00e9", "um", "dos", "v\u00e1rios", "m\u00e9todos", "para", "determinar", "a", "precis\u00e3o", "das", "legendas", "ao", "vivo", "em", "emiss\u00f5es", "de", "televis\u00e3o", "e", "eventos", "que", "s\u00e3o", "produzidos", "utilizando", "o", "reconhecimento", "da", "fala", "."], "sentence-detokenized": "O modelo NER \u00e9 um dos v\u00e1rios m\u00e9todos para determinar a precis\u00e3o das legendas ao vivo em emiss\u00f5es de televis\u00e3o e eventos que s\u00e3o produzidos utilizando o reconhecimento da fala.", "token2charspan": [[0, 1], [2, 8], [9, 12], [13, 14], [15, 17], [18, 21], [22, 28], [29, 36], [37, 41], [42, 52], [53, 54], [55, 63], [64, 67], [68, 76], [77, 79], [80, 84], [85, 87], [88, 96], [97, 99], [100, 109], [110, 111], [112, 119], [120, 123], [124, 127], [128, 138], [139, 149], [150, 151], [152, 166], [167, 169], [170, 174], [174, 175]]}
{"doc_key": "ai-test-251", "ner": [[0, 1, "researcher"], [4, 6, "university"], [9, 10, "university"], [12, 12, "location"], [15, 19, "university"], [22, 23, "university"], [25, 25, "location"], [29, 34, "university"], [36, 39, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 1, 4, 6, "physical", "", false, false], [0, 1, 4, 6, "role", "", false, false], [0, 1, 9, 10, "physical", "", false, false], [0, 1, 9, 10, "role", "", false, false], [0, 1, 15, 19, "physical", "", false, false], [0, 1, 15, 19, "role", "", false, false], [0, 1, 22, 23, "physical", "", false, false], [0, 1, 22, 23, "role", "", false, false], [0, 1, 29, 34, "physical", "", false, false], [0, 1, 29, 34, "role", "", false, false], [9, 10, 12, 12, "physical", "", false, false], [15, 19, 25, 25, "physical", "", false, false], [22, 23, 25, 25, "physical", "", false, false], [29, 34, 36, 39, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["A", "Atran", "ensinou", "na", "Universidade", "de", "Cambridge", ",", "na", "Universidade", "Hebraica", "em", "Jerusal\u00e9m", ",", "na", "\u00c9cole", "pratique", "des", "hautes", "\u00e9tudes", "e", "na", "\u00c9cole", "Polytechnique", "em", "Paris", ",", "e", "no", "John", "Jay", "College", "of", "Criminal", "Justice", "na", "cidade", "de", "Nova", "Iorque", "."], "sentence-detokenized": "A Atran ensinou na Universidade de Cambridge, na Universidade Hebraica em Jerusal\u00e9m, na \u00c9cole pratique des hautes \u00e9tudes e na \u00c9cole Polytechnique em Paris, e no John Jay College of Criminal Justice na cidade de Nova Iorque.", "token2charspan": [[0, 1], [2, 7], [8, 15], [16, 18], [19, 31], [32, 34], [35, 44], [44, 45], [46, 48], [49, 61], [62, 70], [71, 73], [74, 83], [83, 84], [85, 87], [88, 93], [94, 102], [103, 106], [107, 113], [114, 120], [121, 122], [123, 125], [126, 131], [132, 145], [146, 148], [149, 154], [154, 155], [156, 157], [158, 160], [161, 165], [166, 169], [170, 177], [178, 180], [181, 189], [190, 197], [198, 200], [201, 207], [208, 210], [211, 215], [216, 222], [222, 223]]}
{"doc_key": "ai-test-252", "ner": [[0, 0, "product"], [6, 10, "task"], [14, 15, "researcher"], [17, 17, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 10, "origin", "", false, false], [0, 0, 6, 10, "related-to", "", false, false], [6, 10, 17, 17, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["SHRDLU", "foi", "um", "programa", "inform\u00e1tico", "de", "compreens\u00e3o", "precoce", "da", "linguagem", "natural", ",", "desenvolvido", "por", "Terry", "Winograd", "no", "MIT", "em", "1968-1970"], "sentence-detokenized": "SHRDLU foi um programa inform\u00e1tico de compreens\u00e3o precoce da linguagem natural, desenvolvido por Terry Winograd no MIT em 1968-1970", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 22], [23, 34], [35, 37], [38, 49], [50, 57], [58, 60], [61, 70], [71, 78], [78, 79], [80, 92], [93, 96], [97, 102], [103, 111], [112, 114], [115, 118], [119, 121], [122, 131]]}
{"doc_key": "ai-test-253", "ner": [[2, 2, "misc"], [4, 5, "field"], [7, 10, "university"], [12, 12, "location"], [14, 14, "country"], [23, 25, "university"], [28, 28, "misc"], [30, 33, "field"], [37, 39, "university"], [43, 43, "misc"], [45, 46, "field"], [52, 52, "misc"], [59, 61, "university"], [65, 66, "field"], [70, 71, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "relations": [[2, 2, 4, 5, "topic", "", false, false], [2, 2, 7, 10, "origin", "", false, false], [7, 10, 12, 12, "physical", "", false, false], [7, 10, 23, 25, "role", "affiliated_with", false, false], [12, 12, 14, 14, "physical", "", false, false], [28, 28, 30, 33, "topic", "", false, false], [28, 28, 37, 39, "origin", "", false, false], [43, 43, 45, 46, "topic", "", false, false], [52, 52, 59, 61, "origin", "", false, false], [52, 52, 65, 66, "topic", "", false, false], [70, 71, 59, 61, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Recebeu", "um", "B.E.", "em", "engenharia", "electr\u00f3nica", "pelo", "B.M.S.", "College", "of", "Engineering", "em", "Bangalore", ",", "\u00cdndia", ",", "em", "1982", ",", "quando", "foi", "filiado", "na", "Universidade", "de", "Bangalore", ",", "um", "M.S.", "em", "engenharia", "el\u00e9ctrica", "e", "inform\u00e1tica", "em", "1984", "pela", "Universidade", "de", "Drexel", ",", "e", "um", "M.S.", "em", "ci\u00eancias", "inform\u00e1ticas", "em", "1989", ",", "e", "um", "Ph.D.", "em", "1990", ",", "respectivamente", ",", "pela", "Universidade", "de", "Wisconsin-Madison", ",", "onde", "estudou", "Intelig\u00eancia", "Artificial", "e", "trabalhou", "com", "Leonard", "Uhr", "."], "sentence-detokenized": "Recebeu um B.E. em engenharia electr\u00f3nica pelo B.M.S. College of Engineering em Bangalore, \u00cdndia, em 1982, quando foi filiado na Universidade de Bangalore, um M.S. em engenharia el\u00e9ctrica e inform\u00e1tica em 1984 pela Universidade de Drexel, e um M.S. em ci\u00eancias inform\u00e1ticas em 1989, e um Ph.D. em 1990, respectivamente, pela Universidade de Wisconsin-Madison, onde estudou Intelig\u00eancia Artificial e trabalhou com Leonard Uhr.", "token2charspan": [[0, 7], [8, 10], [11, 15], [16, 18], [19, 29], [30, 41], [42, 46], [47, 53], [54, 61], [62, 64], [65, 76], [77, 79], [80, 89], [89, 90], [91, 96], [96, 97], [98, 100], [101, 105], [105, 106], [107, 113], [114, 117], [118, 125], [126, 128], [129, 141], [142, 144], [145, 154], [154, 155], [156, 158], [159, 163], [164, 166], [167, 177], [178, 187], [188, 189], [190, 201], [202, 204], [205, 209], [210, 214], [215, 227], [228, 230], [231, 237], [237, 238], [239, 240], [241, 243], [244, 248], [249, 251], [252, 260], [261, 273], [274, 276], [277, 281], [281, 282], [283, 284], [285, 287], [288, 293], [294, 296], [297, 301], [301, 302], [303, 318], [318, 319], [320, 324], [325, 337], [338, 340], [341, 358], [358, 359], [360, 364], [365, 372], [373, 385], [386, 396], [397, 398], [399, 408], [409, 412], [413, 420], [421, 424], [424, 425]]}
{"doc_key": "ai-test-254", "ner": [[7, 11, "metrics"], [13, 13, "metrics"], [24, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 13, 7, 11, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "precis\u00e3o", "\u00e9", "normalmente", "avaliada", "com", "a", "taxa", "de", "erro", "de", "palavras", "(", "WER", ")", ",", "enquanto", "que", "a", "velocidade", "\u00e9", "medida", "com", "o", "factor", "tempo", "real", "."], "sentence-detokenized": "A precis\u00e3o \u00e9 normalmente avaliada com a taxa de erro de palavras (WER), enquanto que a velocidade \u00e9 medida com o factor tempo real.", "token2charspan": [[0, 1], [2, 10], [11, 12], [13, 24], [25, 33], [34, 37], [38, 39], [40, 44], [45, 47], [48, 52], [53, 55], [56, 64], [65, 66], [66, 69], [69, 70], [70, 71], [72, 80], [81, 84], [85, 86], [87, 97], [98, 99], [100, 106], [107, 110], [111, 112], [113, 119], [120, 125], [126, 130], [130, 131]]}
{"doc_key": "ai-test-255", "ner": [[3, 4, "researcher"], [10, 13, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 10, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Em", "1971", ",", "Terry", "Winograd", "desenvolveu", "um", "motor", "precoce", "de", "processamento", "de", "linguagem", "natural", "capaz", "de", "interpretar", "comandos", "escritos", "naturalmente", "dentro", "de", "um", "simples", "ambiente", "governado", "por", "regras", "."], "sentence-detokenized": "Em 1971, Terry Winograd desenvolveu um motor precoce de processamento de linguagem natural capaz de interpretar comandos escritos naturalmente dentro de um simples ambiente governado por regras.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 35], [36, 38], [39, 44], [45, 52], [53, 55], [56, 69], [70, 72], [73, 82], [83, 90], [91, 96], [97, 99], [100, 111], [112, 120], [121, 129], [130, 142], [143, 149], [150, 152], [153, 155], [156, 163], [164, 172], [173, 182], [183, 186], [187, 193], [193, 194]]}
{"doc_key": "ai-test-256", "ner": [[1, 2, "field"], [4, 5, "researcher"], [7, 9, "researcher"], [12, 13, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 2, 4, 5, "related-to", "", false, false], [1, 2, 7, 9, "related-to", "", false, false], [1, 2, 12, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Na", "intelig\u00eancia", "artificial", ",", "Marvin", "Minsky", ",", "Herbert", "A.", "Simon", ",", "e", "Allen", "Newell", "s\u00e3o", "proeminentes", "."], "sentence-detokenized": "Na intelig\u00eancia artificial, Marvin Minsky, Herbert A. Simon, e Allen Newell s\u00e3o proeminentes.", "token2charspan": [[0, 2], [3, 15], [16, 26], [26, 27], [28, 34], [35, 41], [41, 42], [43, 50], [51, 53], [54, 59], [59, 60], [61, 62], [63, 68], [69, 75], [76, 79], [80, 92], [92, 93]]}
{"doc_key": "ai-test-257", "ner": [[9, 10, "field"], [28, 29, "field"], [31, 32, "field"], [38, 41, "field"], [51, 52, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[28, 29, 9, 10, "origin", "", true, false], [28, 29, 9, 10, "part-of", "", false, false], [28, 29, 38, 41, "compare", "", false, false], [31, 32, 9, 10, "origin", "", true, false], [31, 32, 9, 10, "part-of", "", false, false], [31, 32, 38, 41, "compare", "", false, false], [38, 41, 9, 10, "origin", "", true, false], [38, 41, 9, 10, "part-of", "", false, false], [38, 41, 51, 52, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Na", "segunda", "metade", "do", "s\u00e9culo", "XX", ",", "a", "pr\u00f3pria", "engenharia", "el\u00e9ctrica", "separou-se", "em", "v\u00e1rias", "disciplinas", ",", "especializando-se", "na", "concep\u00e7\u00e3o", "e", "an\u00e1lise", "de", "sistemas", "que", "manipulam", "sinais", "f\u00edsicos", ";", "engenharia", "electr\u00f3nica", "e", "engenharia", "inform\u00e1tica", "como", "exemplos", ";", "enquanto", "que", "a", "engenharia", "de", "concep\u00e7\u00e3o", "se", "desenvolveu", "para", "lidar", "com", "a", "concep\u00e7\u00e3o", "funcional", "de", "interfaces", "utilizador-m\u00e1quina", "."], "sentence-detokenized": "Na segunda metade do s\u00e9culo XX, a pr\u00f3pria engenharia el\u00e9ctrica separou-se em v\u00e1rias disciplinas, especializando-se na concep\u00e7\u00e3o e an\u00e1lise de sistemas que manipulam sinais f\u00edsicos; engenharia electr\u00f3nica e engenharia inform\u00e1tica como exemplos; enquanto que a engenharia de concep\u00e7\u00e3o se desenvolveu para lidar com a concep\u00e7\u00e3o funcional de interfaces utilizador-m\u00e1quina.", "token2charspan": [[0, 2], [3, 10], [11, 17], [18, 20], [21, 27], [28, 30], [30, 31], [32, 33], [34, 41], [42, 52], [53, 62], [63, 73], [74, 76], [77, 83], [84, 95], [95, 96], [97, 114], [115, 117], [118, 127], [128, 129], [130, 137], [138, 140], [141, 149], [150, 153], [154, 163], [164, 170], [171, 178], [178, 179], [180, 190], [191, 202], [203, 204], [205, 215], [216, 227], [228, 232], [233, 241], [241, 242], [243, 251], [252, 255], [256, 257], [258, 268], [269, 271], [272, 281], [282, 284], [285, 296], [297, 301], [302, 307], [308, 311], [312, 313], [314, 323], [324, 333], [334, 336], [337, 347], [348, 366], [366, 367]]}
{"doc_key": "ai-test-258", "ner": [[7, 7, "metrics"], [9, 10, "metrics"], [12, 12, "metrics"], [48, 50, "metrics"], [57, 59, "metrics"], [63, 69, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 12, 9, 10, "named", "", false, false], [48, 50, 57, 59, "named", "", false, false], [57, 59, 63, 69, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Talvez", "a", "estat\u00edstica", "mais", "simples", "seja", "a", "exactid\u00e3o", "ou", "Fraction", "Correct", "(", "FC", ")", ",", "que", "mede", "a", "frac\u00e7\u00e3o", "de", "todas", "as", "inst\u00e2ncias", "que", "est\u00e3o", "correctamente", "categorizadas", ";", "\u00e9", "o", "r\u00e1cio", "entre", "o", "n\u00famero", "de", "classifica\u00e7\u00f5es", "correctas", "e", "o", "n\u00famero", "total", "de", "classifica\u00e7\u00f5es", "correctas", "ou", "incorrectas", ":", "(", "TP", "+", "TN", ")", "/", "Popula\u00e7\u00e3o", "Total", "=", "(", "TP", "+", "TN", ")", "/", "(", "TP", "+", "TN", "+", "FP", "+", "FN", ")", "."], "sentence-detokenized": "Talvez a estat\u00edstica mais simples seja a exactid\u00e3o ou Fraction Correct (FC), que mede a frac\u00e7\u00e3o de todas as inst\u00e2ncias que est\u00e3o correctamente categorizadas; \u00e9 o r\u00e1cio entre o n\u00famero de classifica\u00e7\u00f5es correctas e o n\u00famero total de classifica\u00e7\u00f5es correctas ou incorrectas: (TP + TN) / Popula\u00e7\u00e3o Total = (TP + TN) / (TP + TN + FP + FN).", "token2charspan": [[0, 6], [7, 8], [9, 20], [21, 25], [26, 33], [34, 38], [39, 40], [41, 50], [51, 53], [54, 62], [63, 70], [71, 72], [72, 74], [74, 75], [75, 76], [77, 80], [81, 85], [86, 87], [88, 95], [96, 98], [99, 104], [105, 107], [108, 118], [119, 122], [123, 128], [129, 142], [143, 156], [156, 157], [158, 159], [160, 161], [162, 167], [168, 173], [174, 175], [176, 182], [183, 185], [186, 200], [201, 210], [211, 212], [213, 214], [215, 221], [222, 227], [228, 230], [231, 245], [246, 255], [256, 258], [259, 270], [270, 271], [272, 273], [273, 275], [276, 277], [278, 280], [280, 281], [282, 283], [284, 293], [294, 299], [300, 301], [302, 303], [303, 305], [306, 307], [308, 310], [310, 311], [312, 313], [314, 315], [315, 317], [318, 319], [320, 322], [323, 324], [325, 327], [328, 329], [330, 332], [332, 333], [333, 334]]}
{"doc_key": "ai-test-259", "ner": [[15, 23, "conference"], [25, 25, "conference"], [30, 30, "location"], [34, 35, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 23, 30, 30, "physical", "", false, false], [25, 25, 15, 23, "named", "", false, false], [34, 35, 15, 23, "role", "sponsors", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Na", "comunidade", "acad\u00e9mica", ",", "os", "principais", "f\u00f3runs", "de", "investiga\u00e7\u00e3o", "come\u00e7aram", "em", "1995", ",", "quando", "a", "Primeira", "Confer\u00eancia", "Internacional", "sobre", "Data", "Mining", "and", "Knowledge", "Discovery", "(", "KDD-95", ")", "foi", "iniciada", "em", "Montreal", "sob", "o", "patroc\u00ednio", "da", "AAAI", "."], "sentence-detokenized": "Na comunidade acad\u00e9mica, os principais f\u00f3runs de investiga\u00e7\u00e3o come\u00e7aram em 1995, quando a Primeira Confer\u00eancia Internacional sobre Data Mining and Knowledge Discovery (KDD-95) foi iniciada em Montreal sob o patroc\u00ednio da AAAI.", "token2charspan": [[0, 2], [3, 13], [14, 23], [23, 24], [25, 27], [28, 38], [39, 45], [46, 48], [49, 61], [62, 71], [72, 74], [75, 79], [79, 80], [81, 87], [88, 89], [90, 98], [99, 110], [111, 124], [125, 130], [131, 135], [136, 142], [143, 146], [147, 156], [157, 166], [167, 168], [168, 174], [174, 175], [176, 179], [180, 188], [189, 191], [192, 200], [201, 204], [205, 206], [207, 217], [218, 220], [221, 225], [225, 226]]}
{"doc_key": "ai-test-260", "ner": [[10, 13, "field"], [17, 19, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Nesta", "abordagem", ",", "os", "modelos", "s\u00e3o", "desenvolvidos", "utilizando", "diferentes", "m\u00e9todos", "de", "minera\u00e7\u00e3o", "de", "dados", ",", "algoritmos", "de", "aprendizagem", "de", "m\u00e1quinas", "para", "prever", "a", "classifica\u00e7\u00e3o", "dos", "utilizadores", "de", "itens", "n\u00e3o", "classificados", "."], "sentence-detokenized": "Nesta abordagem, os modelos s\u00e3o desenvolvidos utilizando diferentes m\u00e9todos de minera\u00e7\u00e3o de dados, algoritmos de aprendizagem de m\u00e1quinas para prever a classifica\u00e7\u00e3o dos utilizadores de itens n\u00e3o classificados.", "token2charspan": [[0, 5], [6, 15], [15, 16], [17, 19], [20, 27], [28, 31], [32, 45], [46, 56], [57, 67], [68, 75], [76, 78], [79, 88], [89, 91], [92, 97], [97, 98], [99, 109], [110, 112], [113, 125], [126, 128], [129, 137], [138, 142], [143, 149], [150, 151], [152, 165], [166, 169], [170, 182], [183, 185], [186, 191], [192, 195], [196, 209], [209, 210]]}
{"doc_key": "ai-test-261", "ner": [[10, 10, "algorithm"], [14, 15, "algorithm"], [18, 19, "algorithm"], [26, 28, "misc"], [31, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 10, 14, 15, "related-to", "equivalent", false, false], [14, 15, 18, 19, "usage", "", false, false], [18, 19, 31, 33, "usage", "", false, false], [31, 33, 26, 28, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["luz", "da", "discuss\u00e3o", "acima", "referida", ",", "vemos", "que", "a", "t\u00e9cnica", "SVM", "\u00e9", "equivalente", "ao", "risco", "emp\u00edrico", "com", "a", "regulariza\u00e7\u00e3o", "Tikhonov", ",", "em", "que", "neste", "caso", "a", "fun\u00e7\u00e3o", "de", "perda", "\u00e9", "a", "perda", "da", "dobradi\u00e7a"], "sentence-detokenized": "luz da discuss\u00e3o acima referida, vemos que a t\u00e9cnica SVM \u00e9 equivalente ao risco emp\u00edrico com a regulariza\u00e7\u00e3o Tikhonov, em que neste caso a fun\u00e7\u00e3o de perda \u00e9 a perda da dobradi\u00e7a", "token2charspan": [[0, 3], [4, 6], [7, 16], [17, 22], [23, 31], [31, 32], [33, 38], [39, 42], [43, 44], [45, 52], [53, 56], [57, 58], [59, 70], [71, 73], [74, 79], [80, 88], [89, 92], [93, 94], [95, 108], [109, 117], [117, 118], [119, 121], [122, 125], [126, 131], [132, 136], [137, 138], [139, 145], [146, 148], [149, 154], [155, 156], [157, 158], [159, 164], [165, 167], [168, 177]]}
{"doc_key": "ai-test-262", "ner": [[7, 8, "person"], [11, 12, "person"], [17, 18, "organisation"], [19, 20, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[19, 20, 17, 18, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "edi\u00e7\u00e3o", "de", "2015", "foi", "organizada", "por", "Molly", "McGrath", ",", "com", "Chris", "Rose", "e", "o", "antigo", "combatente", "da", "UFC", "Kenny", "Florian", "como", "comentadores", "."], "sentence-detokenized": "A edi\u00e7\u00e3o de 2015 foi organizada por Molly McGrath, com Chris Rose e o antigo combatente da UFC Kenny Florian como comentadores.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 16], [17, 20], [21, 31], [32, 35], [36, 41], [42, 49], [49, 50], [51, 54], [55, 60], [61, 65], [66, 67], [68, 69], [70, 76], [77, 87], [88, 90], [91, 94], [95, 100], [101, 108], [109, 113], [114, 126], [126, 127]]}
{"doc_key": "ai-test-263", "ner": [[3, 3, "product"], [7, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"], [16, 16, "researcher"], [19, 19, "researcher"], [33, 33, "researcher"], [28, 32, "task"], [34, 34, "product"], [43, 44, "researcher"], [39, 41, "task"], [49, 50, "researcher"], [53, 54, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[3, 3, 7, 9, "origin", "", false, false], [3, 3, 11, 12, "origin", "", false, false], [3, 3, 14, 15, "origin", "", false, false], [3, 3, 16, 16, "origin", "", false, false], [11, 12, 43, 44, "named", "same", false, false], [14, 15, 19, 19, "named", "same", false, false], [14, 15, 33, 33, "named", "same", false, false], [28, 32, 34, 34, "related-to", "", false, false], [34, 34, 33, 33, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Um", "subconjunto", "chamado", "Micro-Planner", "foi", "implementado", "por", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "e", "Terry", "Winograd", "Sussman", ",", "e", "Winograd", "1971", ",", "e", "foi", "utilizado", "no", "programa", "de", "compreens\u00e3o", "da", "l\u00edngua", "natural", "de", "Winograd", "SHRDLU", ",", "no", "trabalho", "de", "compreens\u00e3o", "da", "hist\u00f3ria", "de", "Eugene", "Charniak", ",", "no", "trabalho", "de", "Thorne", "McCarty", "sobre", "o", "racioc\u00ednio", "jur\u00eddico", ",", "e", "em", "alguns", "outros", "projectos", "."], "sentence-detokenized": "Um subconjunto chamado Micro-Planner foi implementado por Gerald Jay Sussman, Eugene Charniak e Terry Winograd Sussman, e Winograd 1971, e foi utilizado no programa de compreens\u00e3o da l\u00edngua natural de Winograd SHRDLU, no trabalho de compreens\u00e3o da hist\u00f3ria de Eugene Charniak, no trabalho de Thorne McCarty sobre o racioc\u00ednio jur\u00eddico, e em alguns outros projectos.", "token2charspan": [[0, 2], [3, 14], [15, 22], [23, 36], [37, 40], [41, 53], [54, 57], [58, 64], [65, 68], [69, 76], [76, 77], [78, 84], [85, 93], [94, 95], [96, 101], [102, 110], [111, 118], [118, 119], [120, 121], [122, 130], [131, 135], [135, 136], [137, 138], [139, 142], [143, 152], [153, 155], [156, 164], [165, 167], [168, 179], [180, 182], [183, 189], [190, 197], [198, 200], [201, 209], [210, 216], [216, 217], [218, 220], [221, 229], [230, 232], [233, 244], [245, 247], [248, 256], [257, 259], [260, 266], [267, 275], [275, 276], [277, 279], [280, 288], [289, 291], [292, 298], [299, 306], [307, 312], [313, 314], [315, 325], [326, 334], [334, 335], [336, 337], [338, 340], [341, 347], [348, 354], [355, 364], [364, 365]]}
{"doc_key": "ai-test-264", "ner": [[0, 0, "product"], [10, 12, "product"], [15, 19, "task"], [21, 23, "task"], [25, 28, "task"], [30, 31, "task"], [33, 34, "task"], [38, 42, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 12, 0, 0, "usage", "", true, false], [15, 19, 10, 12, "part-of", "", true, false], [21, 23, 10, 12, "part-of", "", true, false], [25, 28, 10, 12, "part-of", "", true, false], [30, 31, 10, 12, "part-of", "", true, false], [33, 34, 10, 12, "part-of", "", true, false], [38, 42, 10, 12, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["WordNet", "tem", "sido", "utilizado", "para", "uma", "s\u00e9rie", "de", "fins", "em", "sistemas", "de", "informa\u00e7\u00e3o", ",", "incluindo", "desambigua\u00e7\u00e3o", "de", "sentido", "de", "palavras", ",", "recupera\u00e7\u00e3o", "de", "informa\u00e7\u00e3o", ",", "classifica\u00e7\u00e3o", "autom\u00e1tica", "de", "texto", ",", "resumo", "autom\u00e1tico", ",", "tradu\u00e7\u00e3o", "autom\u00e1tica", "e", "at\u00e9", "mesmo", "gera\u00e7\u00e3o", "autom\u00e1tica", "de", "palavras", "cruzadas", "."], "sentence-detokenized": "WordNet tem sido utilizado para uma s\u00e9rie de fins em sistemas de informa\u00e7\u00e3o, incluindo desambigua\u00e7\u00e3o de sentido de palavras, recupera\u00e7\u00e3o de informa\u00e7\u00e3o, classifica\u00e7\u00e3o autom\u00e1tica de texto, resumo autom\u00e1tico, tradu\u00e7\u00e3o autom\u00e1tica e at\u00e9 mesmo gera\u00e7\u00e3o autom\u00e1tica de palavras cruzadas.", "token2charspan": [[0, 7], [8, 11], [12, 16], [17, 26], [27, 31], [32, 35], [36, 41], [42, 44], [45, 49], [50, 52], [53, 61], [62, 64], [65, 75], [75, 76], [77, 86], [87, 100], [101, 103], [104, 111], [112, 114], [115, 123], [123, 124], [125, 136], [137, 139], [140, 150], [150, 151], [152, 165], [166, 176], [177, 179], [180, 185], [185, 186], [187, 193], [194, 204], [204, 205], [206, 214], [215, 225], [226, 227], [228, 231], [232, 237], [238, 245], [246, 256], [257, 259], [260, 268], [269, 277], [277, 278]]}
{"doc_key": "ai-test-265", "ner": [[0, 0, "researcher"], [6, 6, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 6, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Keutzer", "foi", "nomeado", "Fellow", "of", "the", "IEEE", "em", "1996", "."], "sentence-detokenized": "Keutzer foi nomeado Fellow of the IEEE em 1996.", "token2charspan": [[0, 7], [8, 11], [12, 19], [20, 26], [27, 29], [30, 33], [34, 38], [39, 41], [42, 46], [46, 47]]}
{"doc_key": "ai-test-266", "ner": [[8, 10, "algorithm"], [52, 54, "misc"], [63, 64, "algorithm"], [66, 67, "algorithm"], [69, 70, "algorithm"], [73, 74, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[63, 64, 52, 54, "type-of", "", false, false], [66, 67, 52, 54, "type-of", "", false, false], [69, 70, 52, 54, "type-of", "", false, false], [73, 74, 52, 54, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Um", "tipo", "de", "composi\u00e7\u00e3o", "amplamente", "utilizado", "\u00e9", "a", "soma", "n\u00e3o-linear", "ponderada", ",", "onde", "matem\u00e1tica", "f", "(", "x", ")", "=", "K", "\\", "esquerda", "(", "\\", "soma", "_", "i", "w", "_", "i", "g", "_", "i", "(", "x", ")", "\\", "direita", ")", "/", "matem\u00e1tica", ",", "onde", "matem\u00e1tica", "K", "/", "matem\u00e1tica", "(", "comummente", "referida", "como", "a", "fun\u00e7\u00e3o", "de", "activa\u00e7\u00e3o", ")", "\u00e9", "alguma", "fun\u00e7\u00e3o", "predefinida", ",", "como", "a", "tangente", "hiperb\u00f3lica", ",", "fun\u00e7\u00e3o", "sigm\u00f3ide", ",", "fun\u00e7\u00e3o", "softmax", ",", "ou", "fun\u00e7\u00e3o", "rectificadora", "."], "sentence-detokenized": "Um tipo de composi\u00e7\u00e3o amplamente utilizado \u00e9 a soma n\u00e3o-linear ponderada, onde matem\u00e1tica f (x) = K\\ esquerda (\\ soma _ i w _ i g _ i (x)\\ direita) / matem\u00e1tica, onde matem\u00e1tica K/ matem\u00e1tica (comummente referida como a fun\u00e7\u00e3o de activa\u00e7\u00e3o) \u00e9 alguma fun\u00e7\u00e3o predefinida, como a tangente hiperb\u00f3lica, fun\u00e7\u00e3o sigm\u00f3ide, fun\u00e7\u00e3o softmax, ou fun\u00e7\u00e3o rectificadora.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 21], [22, 32], [33, 42], [43, 44], [45, 46], [47, 51], [52, 62], [63, 72], [72, 73], [74, 78], [79, 89], [90, 91], [92, 93], [93, 94], [94, 95], [96, 97], [98, 99], [99, 100], [101, 109], [110, 111], [111, 112], [113, 117], [118, 119], [120, 121], [122, 123], [124, 125], [126, 127], [128, 129], [130, 131], [132, 133], [134, 135], [135, 136], [136, 137], [137, 138], [139, 146], [146, 147], [148, 149], [150, 160], [160, 161], [162, 166], [167, 177], [178, 179], [179, 180], [181, 191], [192, 193], [193, 203], [204, 212], [213, 217], [218, 219], [220, 226], [227, 229], [230, 239], [239, 240], [241, 242], [243, 249], [250, 256], [257, 268], [268, 269], [270, 274], [275, 276], [277, 285], [286, 297], [297, 298], [299, 305], [306, 314], [314, 315], [316, 322], [323, 330], [330, 331], [332, 334], [335, 341], [342, 355], [355, 356]]}
{"doc_key": "ai-test-267", "ner": [[2, 2, "misc"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["No", "filme", "Westworld", ",", "as", "rob\u00f4s", "femininas", "tiveram", "efectivamente", "rela\u00e7\u00f5es", "sexuais", "com", "homens", "humanos", "como", "parte", "do", "mundo", "do", "faz-de-contagem", "de", "f\u00e9rias", "que", "os", "clientes", "humanos", "pagaram", "para", "assistir", "."], "sentence-detokenized": "No filme Westworld, as rob\u00f4s femininas tiveram efectivamente rela\u00e7\u00f5es sexuais com homens humanos como parte do mundo do faz-de-contagem de f\u00e9rias que os clientes humanos pagaram para assistir.", "token2charspan": [[0, 2], [3, 8], [9, 18], [18, 19], [20, 22], [23, 28], [29, 38], [39, 46], [47, 60], [61, 69], [70, 77], [78, 81], [82, 88], [89, 96], [97, 101], [102, 107], [108, 110], [111, 116], [117, 119], [120, 135], [136, 138], [139, 145], [146, 149], [150, 152], [153, 161], [162, 169], [170, 177], [178, 182], [183, 191], [191, 192]]}
{"doc_key": "ai-test-268", "ner": [[6, 8, "task"], [25, 29, "task"], [32, 34, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 8, 25, 29, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Tipicamente", ",", "o", "processo", "come\u00e7a", "pela", "extrac\u00e7\u00e3o", "de", "terminologia", "e", "conceitos", "ou", "frases", "de", "substantivos", "a", "partir", "de", "texto", "simples", "utilizando", "processadores", "lingu\u00edsticos", "como", "a", "etiquetagem", "de", "parte", "da", "fala", "e", "a", "frase", "em", "peda\u00e7os", "."], "sentence-detokenized": "Tipicamente, o processo come\u00e7a pela extrac\u00e7\u00e3o de terminologia e conceitos ou frases de substantivos a partir de texto simples utilizando processadores lingu\u00edsticos como a etiquetagem de parte da fala e a frase em peda\u00e7os.", "token2charspan": [[0, 11], [11, 12], [13, 14], [15, 23], [24, 30], [31, 35], [36, 45], [46, 48], [49, 61], [62, 63], [64, 73], [74, 76], [77, 83], [84, 86], [87, 99], [100, 101], [102, 108], [109, 111], [112, 117], [118, 125], [126, 136], [137, 150], [151, 163], [164, 168], [169, 170], [171, 182], [183, 185], [186, 191], [192, 194], [195, 199], [200, 201], [202, 203], [204, 209], [210, 212], [213, 220], [220, 221]]}
{"doc_key": "ai-test-269", "ner": [[14, 16, "field"], [20, 22, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 22, 14, 16, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0], "sentence": ["Demonstraram", "o", "seu", "desempenho", "numa", "s\u00e9rie", "de", "problemas", "de", "interesse", "para", "a", "comunidade", "de", "aprendizagem", "de", "m\u00e1quinas", ",", "incluindo", "o", "reconhecimento", "da", "caligrafia", "."], "sentence-detokenized": "Demonstraram o seu desempenho numa s\u00e9rie de problemas de interesse para a comunidade de aprendizagem de m\u00e1quinas, incluindo o reconhecimento da caligrafia.", "token2charspan": [[0, 12], [13, 14], [15, 18], [19, 29], [30, 34], [35, 40], [41, 43], [44, 53], [54, 56], [57, 66], [67, 71], [72, 73], [74, 84], [85, 87], [88, 100], [101, 103], [104, 112], [112, 113], [114, 123], [124, 125], [126, 140], [141, 143], [144, 154], [154, 155]]}
{"doc_key": "ai-test-270", "ner": [[3, 3, "university"], [5, 5, "researcher"], [11, 12, "researcher"], [17, 17, "product"], [21, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 5, 3, 3, "physical", "", false, false], [5, 5, 3, 3, "role", "", false, false], [17, 17, 11, 12, "origin", "", false, false], [17, 17, 21, 22, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Enquanto", "estudava", "em", "Stanford", ",", "Scheinman", "recebeu", "uma", "bolsa", "patrocinada", "por", "George", "Devol", ",", "o", "inventor", "da", "Unimate", ",", "o", "primeiro", "rob\u00f4", "industrial", "."], "sentence-detokenized": "Enquanto estudava em Stanford, Scheinman recebeu uma bolsa patrocinada por George Devol, o inventor da Unimate, o primeiro rob\u00f4 industrial.", "token2charspan": [[0, 8], [9, 17], [18, 20], [21, 29], [29, 30], [31, 40], [41, 48], [49, 52], [53, 58], [59, 70], [71, 74], [75, 81], [82, 87], [87, 88], [89, 90], [91, 99], [100, 102], [103, 110], [110, 111], [112, 113], [114, 122], [123, 127], [128, 138], [138, 139]]}
{"doc_key": "ai-test-271", "ner": [[5, 6, "task"], [9, 12, "metrics"], [14, 14, "metrics"], [24, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 9, 12, "usage", "", true, false], [14, 14, 9, 12, "named", "", false, false], [24, 28, 9, 12, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Embora", "originalmente", "utilizado", "para", "avaliar", "tradu\u00e7\u00f5es", "autom\u00e1ticas", ",", "o", "subestudo", "de", "avalia\u00e7\u00e3o", "bilingue", "(", "BLEU", ")", "tamb\u00e9m", "tem", "sido", "utilizado", "com", "sucesso", "para", "avaliar", "modelos", "de", "gera\u00e7\u00e3o", "de", "par\u00e1frases", "."], "sentence-detokenized": "Embora originalmente utilizado para avaliar tradu\u00e7\u00f5es autom\u00e1ticas, o subestudo de avalia\u00e7\u00e3o bilingue (BLEU) tamb\u00e9m tem sido utilizado com sucesso para avaliar modelos de gera\u00e7\u00e3o de par\u00e1frases.", "token2charspan": [[0, 6], [7, 20], [21, 30], [31, 35], [36, 43], [44, 53], [54, 65], [65, 66], [67, 68], [69, 78], [79, 81], [82, 91], [92, 100], [101, 102], [102, 106], [106, 107], [108, 114], [115, 118], [119, 123], [124, 133], [134, 137], [138, 145], [146, 150], [151, 158], [159, 166], [167, 169], [170, 177], [178, 180], [181, 191], [191, 192]]}
{"doc_key": "ai-test-272", "ner": [[0, 1, "organisation"], [9, 11, "organisation"], [14, 14, "organisation"], [17, 17, "product"], [19, 19, "country"], [22, 22, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 9, 11, "role", "licenses_to", false, false], [0, 1, 14, 14, "role", "licenses_to", false, false], [9, 11, 19, 19, "physical", "", false, false], [14, 14, 22, 22, "physical", "", false, false], [17, 17, 9, 11, "artifact", "produces", false, false], [17, 17, 14, 14, "artifact", "produces", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["A", "Unimation", "licenciou", "mais", "tarde", "a", "sua", "tecnologia", "\u00e0", "Kawasaki", "Heavy", "Industries", "e", "\u00e0", "GKN", ",", "fabricando", "Unimates", "no", "Jap\u00e3o", "e", "em", "Inglaterra", ",", "respectivamente", "."], "sentence-detokenized": "A Unimation licenciou mais tarde a sua tecnologia \u00e0 Kawasaki Heavy Industries e \u00e0 GKN, fabricando Unimates no Jap\u00e3o e em Inglaterra, respectivamente.", "token2charspan": [[0, 1], [2, 11], [12, 21], [22, 26], [27, 32], [33, 34], [35, 38], [39, 49], [50, 51], [52, 60], [61, 66], [67, 77], [78, 79], [80, 81], [82, 85], [85, 86], [87, 97], [98, 106], [107, 109], [110, 115], [116, 117], [118, 120], [121, 131], [131, 132], [133, 148], [148, 149]]}
{"doc_key": "ai-test-273", "ner": [[21, 22, "conference"], [36, 37, "field"], [57, 64, "field"], [66, 66, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[36, 37, 57, 64, "compare", "", false, false], [66, 66, 57, 64, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Grande", "parte", "da", "confus\u00e3o", "entre", "estas", "duas", "comunidades", "de", "investiga\u00e7\u00e3o", "(", "que", "t\u00eam", "frequentemente", "confer\u00eancias", "e", "revistas", "separadas", ",", "sendo", "o", "ECML", "PKDD", "uma", "grande", "excep\u00e7\u00e3o", ")", "prov\u00e9m", "dos", "pressupostos", "b\u00e1sicos", "com", "que", "trabalham", ":", "na", "aprendizagem", "mec\u00e2nica", ",", "o", "desempenho", "\u00e9", "geralmente", "avaliado", "em", "rela\u00e7\u00e3o", "\u00e0", "capacidade", "de", "reproduzir", "o", "conhecimento", "conhecido", ",", "enquanto", "que", "na", "descoberta", "do", "conhecimento", "e", "na", "extrac\u00e7\u00e3o", "de", "dados", "(", "KDD", ")", "a", "tarefa", "chave", "\u00e9", "a", "descoberta", "de", "conhecimento", "anteriormente", "desconhecido", "."], "sentence-detokenized": "Grande parte da confus\u00e3o entre estas duas comunidades de investiga\u00e7\u00e3o (que t\u00eam frequentemente confer\u00eancias e revistas separadas, sendo o ECML PKDD uma grande excep\u00e7\u00e3o) prov\u00e9m dos pressupostos b\u00e1sicos com que trabalham: na aprendizagem mec\u00e2nica, o desempenho \u00e9 geralmente avaliado em rela\u00e7\u00e3o \u00e0 capacidade de reproduzir o conhecimento conhecido, enquanto que na descoberta do conhecimento e na extrac\u00e7\u00e3o de dados (KDD) a tarefa chave \u00e9 a descoberta de conhecimento anteriormente desconhecido.", "token2charspan": [[0, 6], [7, 12], [13, 15], [16, 24], [25, 30], [31, 36], [37, 41], [42, 53], [54, 56], [57, 69], [70, 71], [71, 74], [75, 78], [79, 93], [94, 106], [107, 108], [109, 117], [118, 127], [127, 128], [129, 134], [135, 136], [137, 141], [142, 146], [147, 150], [151, 157], [158, 166], [166, 167], [168, 174], [175, 178], [179, 191], [192, 199], [200, 203], [204, 207], [208, 217], [217, 218], [219, 221], [222, 234], [235, 243], [243, 244], [245, 246], [247, 257], [258, 259], [260, 270], [271, 279], [280, 282], [283, 290], [291, 292], [293, 303], [304, 306], [307, 317], [318, 319], [320, 332], [333, 342], [342, 343], [344, 352], [353, 356], [357, 359], [360, 370], [371, 373], [374, 386], [387, 388], [389, 391], [392, 401], [402, 404], [405, 410], [411, 412], [412, 415], [415, 416], [417, 418], [419, 425], [426, 431], [432, 433], [434, 435], [436, 446], [447, 449], [450, 462], [463, 476], [477, 489], [489, 490]]}
{"doc_key": "ai-test-274", "ner": [[1, 3, "algorithm"], [11, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 3, 11, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Os", "modelos", "Markov", "escondidos", "s\u00e3o", "a", "base", "para", "a", "maioria", "dos", "sistemas", "modernos", "de", "reconhecimento", "autom\u00e1tico", "da", "fala", "."], "sentence-detokenized": "Os modelos Markov escondidos s\u00e3o a base para a maioria dos sistemas modernos de reconhecimento autom\u00e1tico da fala.", "token2charspan": [[0, 2], [3, 10], [11, 17], [18, 28], [29, 32], [33, 34], [35, 39], [40, 44], [45, 46], [47, 54], [55, 58], [59, 67], [68, 76], [77, 79], [80, 94], [95, 105], [106, 108], [109, 113], [113, 114]]}
{"doc_key": "ai-test-275", "ner": [[4, 4, "location"], [6, 6, "country"], [12, 14, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 6, 6, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": [",", "uma", "empresa", "em", "Bangalore", ",", "\u00cdndia", ",", "especializada", "em", "software", "de", "reconhecimento", "de", "caligrafia", "online", "."], "sentence-detokenized": ", uma empresa em Bangalore, \u00cdndia, especializada em software de reconhecimento de caligrafia online.", "token2charspan": [[0, 1], [2, 5], [6, 13], [14, 16], [17, 26], [26, 27], [28, 33], [33, 34], [35, 48], [49, 51], [52, 60], [61, 63], [64, 78], [79, 81], [82, 92], [93, 99], [99, 100]]}
{"doc_key": "ai-test-276", "ner": [[25, 26, "misc"], [51, 51, "metrics"], [53, 55, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[51, 51, 53, 55, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "tradu\u00e7\u00f5es", "repetidas", "convergem", "para", "uma", "\u00fanica", "express\u00e3o", "em", "ambas", "as", "l\u00ednguas", "?", "Isto", "\u00e9", ",", "o", "m\u00e9todo", "de", "tradu\u00e7\u00e3o", "mostra", "estacionaridade", "ou", "produz", "uma", "forma", "can\u00f3nica", "?", "A", "tradu\u00e7\u00e3o", "torna-se", "estacion\u00e1ria", "sem", "perder", "o", "significado", "original", "?", "Esta", "m\u00e9trica", "tem", "sido", "criticada", "como", "n\u00e3o", "estando", "bem", "correlacionada", "com", "a", "pontua\u00e7\u00e3o", "BLEU", "(", "BiLingual", "Evaluation", "Understudy", ")", "."], "sentence-detokenized": "As tradu\u00e7\u00f5es repetidas convergem para uma \u00fanica express\u00e3o em ambas as l\u00ednguas? Isto \u00e9, o m\u00e9todo de tradu\u00e7\u00e3o mostra estacionaridade ou produz uma forma can\u00f3nica? A tradu\u00e7\u00e3o torna-se estacion\u00e1ria sem perder o significado original? Esta m\u00e9trica tem sido criticada como n\u00e3o estando bem correlacionada com a pontua\u00e7\u00e3o BLEU (BiLingual Evaluation Understudy).", "token2charspan": [[0, 2], [3, 12], [13, 22], [23, 32], [33, 37], [38, 41], [42, 47], [48, 57], [58, 60], [61, 66], [67, 69], [70, 77], [77, 78], [79, 83], [84, 85], [85, 86], [87, 88], [89, 95], [96, 98], [99, 107], [108, 114], [115, 130], [131, 133], [134, 140], [141, 144], [145, 150], [151, 159], [159, 160], [161, 162], [163, 171], [172, 180], [181, 193], [194, 197], [198, 204], [205, 206], [207, 218], [219, 227], [227, 228], [229, 233], [234, 241], [242, 245], [246, 250], [251, 260], [261, 265], [266, 269], [270, 277], [278, 281], [282, 296], [297, 300], [301, 302], [303, 312], [313, 317], [318, 319], [319, 328], [329, 339], [340, 350], [350, 351], [351, 352]]}
{"doc_key": "ai-test-277", "ner": [[3, 7, "organisation"], [10, 16, "organisation"], [18, 20, "university"], [23, 23, "university"], [26, 27, "field"], [30, 34, "organisation"], [37, 39, "organisation"], [46, 49, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 16, 18, 20, "part-of", "", false, false], [23, 23, 26, 27, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Tem", "bolsas", "na", "Associa\u00e7\u00e3o", "Americana", "de", "Intelig\u00eancia", "Artificial", ",", "no", "Centro", "de", "Estudos", "Avan\u00e7ados", "em", "Ci\u00eancias", "Comportamentais", "da", "Universidade", "de", "Stanford", ",", "no", "MIT", "Center", "for", "Cognitive", "Science", ",", "no", "Canadian", "Institute", "for", "Advanced", "Research", ",", "na", "Canadian", "Psychological", "Association", ",", "e", "foi", "eleito", "Fellow", "da", "Royal", "Society", "of", "Canada", "em", "1998", "."], "sentence-detokenized": "Tem bolsas na Associa\u00e7\u00e3o Americana de Intelig\u00eancia Artificial, no Centro de Estudos Avan\u00e7ados em Ci\u00eancias Comportamentais da Universidade de Stanford, no MIT Center for Cognitive Science, no Canadian Institute for Advanced Research, na Canadian Psychological Association, e foi eleito Fellow da Royal Society of Canada em 1998.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 24], [25, 34], [35, 37], [38, 50], [51, 61], [61, 62], [63, 65], [66, 72], [73, 75], [76, 83], [84, 93], [94, 96], [97, 105], [106, 121], [122, 124], [125, 137], [138, 140], [141, 149], [149, 150], [151, 153], [154, 157], [158, 164], [165, 168], [169, 178], [179, 186], [186, 187], [188, 190], [191, 199], [200, 209], [210, 213], [214, 222], [223, 231], [231, 232], [233, 235], [236, 244], [245, 258], [259, 270], [270, 271], [272, 273], [274, 277], [278, 284], [285, 291], [292, 294], [295, 300], [301, 308], [309, 311], [312, 318], [319, 321], [322, 326], [326, 327]]}
{"doc_key": "ai-test-278", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [16, 18, "misc"], [21, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 16, 18, "part-of", "", false, false], [0, 0, 21, 24, "part-of", "", false, false], [4, 5, 16, 18, "part-of", "", false, false], [4, 5, 21, 24, "part-of", "", false, false], [7, 8, 16, 18, "part-of", "", false, false], [7, 8, 21, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Hinton", "-", "juntamente", "com", "Yoshua", "Bengio", "e", "Yann", "LeCun", "-", "s\u00e3o", "referidos", "por", "alguns", "como", "os", "Padrinhos", "da", "IA", "e", "os", "Padrinhos", "do", "Ensino", "Profundo", "."], "sentence-detokenized": "Hinton - juntamente com Yoshua Bengio e Yann LeCun - s\u00e3o referidos por alguns como os Padrinhos da IA e os Padrinhos do Ensino Profundo.", "token2charspan": [[0, 6], [7, 8], [9, 19], [20, 23], [24, 30], [31, 37], [38, 39], [40, 44], [45, 50], [51, 52], [53, 56], [57, 66], [67, 70], [71, 77], [78, 82], [83, 85], [86, 95], [96, 98], [99, 101], [102, 103], [104, 106], [107, 116], [117, 119], [120, 126], [127, 135], [135, 136]]}
{"doc_key": "ai-test-279", "ner": [[2, 2, "product"], [15, 15, "misc"], [17, 18, "misc"], [19, 19, "product"], [23, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 15, 15, "related-to", "", false, false], [2, 2, 17, 18, "related-to", "", false, false], [15, 15, 19, 19, "named", "same", false, false], [23, 24, 19, 19, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["O", "projecto", "eSpeak", ",", "que", "tem", "a", "sua", "pr\u00f3pria", "abordagem", "de", "s\u00edntese", ",", "experimentou", "com", "mandarim", "e", "canton\u00eas", ".", "eSpeak", "foi", "utilizado", "pelo", "Google", "Translate", "a", "partir", "de", "Maio", "de", "20102010", "."], "sentence-detokenized": "O projecto eSpeak, que tem a sua pr\u00f3pria abordagem de s\u00edntese, experimentou com mandarim e canton\u00eas. eSpeak foi utilizado pelo Google Translate a partir de Maio de 20102010.", "token2charspan": [[0, 1], [2, 10], [11, 17], [17, 18], [19, 22], [23, 26], [27, 28], [29, 32], [33, 40], [41, 50], [51, 53], [54, 61], [61, 62], [63, 75], [76, 79], [80, 88], [89, 90], [91, 99], [99, 100], [101, 107], [108, 111], [112, 121], [122, 126], [127, 133], [134, 143], [144, 145], [146, 152], [153, 155], [156, 160], [161, 163], [164, 172], [172, 173]]}
{"doc_key": "ai-test-280", "ner": [[5, 7, "product"], [11, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 11, 15, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Tamb\u00e9m", "lan\u00e7ado", "em", "1982", ",", "Software", "Autom\u00e1tico", "Boca", "foi", "o", "primeiro", "programa", "comercial", "de", "s\u00edntese", "de", "voz", "totalmente", "em", "software", "."], "sentence-detokenized": "Tamb\u00e9m lan\u00e7ado em 1982, Software Autom\u00e1tico Boca foi o primeiro programa comercial de s\u00edntese de voz totalmente em software.", "token2charspan": [[0, 6], [7, 14], [15, 17], [18, 22], [22, 23], [24, 32], [33, 43], [44, 48], [49, 52], [53, 54], [55, 63], [64, 72], [73, 82], [83, 85], [86, 93], [94, 96], [97, 100], [101, 111], [112, 114], [115, 123], [123, 124]]}
{"doc_key": "ai-test-281", "ner": [[5, 7, "metrics"], [9, 9, "metrics"], [12, 12, "metrics"], [14, 14, "metrics"], [17, 23, "metrics"], [29, 31, "metrics"], [33, 33, "metrics"], [36, 42, "metrics"], [46, 48, "metrics"], [50, 50, "metrics"], [53, 53, "metrics"], [55, 55, "metrics"], [58, 64, "metrics"], [70, 72, "metrics"], [74, 74, "metrics"], [77, 83, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[9, 9, 5, 7, "named", "", false, false], [12, 12, 5, 7, "named", "", false, false], [14, 14, 5, 7, "named", "", false, false], [17, 23, 5, 7, "named", "", false, false], [33, 33, 29, 31, "named", "", false, false], [36, 42, 29, 31, "named", "", false, false], [50, 50, 46, 48, "named", "", false, false], [53, 53, 46, 48, "named", "", false, false], [55, 55, 46, 48, "named", "", false, false], [58, 64, 46, 48, "named", "", false, false], [74, 74, 70, 72, "named", "", false, false], [77, 83, 70, 72, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Os", "r\u00e1cios", "da", "coluna", "s\u00e3o", "TRUE", "Positive", "Rate", "(", "TPR", ",", "aka", "Sensitivity", "ou", "recall", ")", "(", "TP", "/", "(", "TP", "+", "FN", ")", ")", ",", "com", "o", "complemento", "FALSE", "Negative", "Rate", "(", "FNR", ")", "(", "FN", "/", "(", "TP", "+", "FN", ")", ")", ";", "e", "TRUE", "Negative", "Rate", "(", "TNR", ",", "aka", "Specificity", ",", "SPC", ")", "(", "TN", "/", "(", "TN", "+", "FP", ")", ")", ",", "com", "o", "complemento", "FALSE", "Positive", "Rate", "(", "FPR", ")", "(", "FP", "/", "(", "TN", "+", "FP", ")", ")", "."], "sentence-detokenized": "Os r\u00e1cios da coluna s\u00e3o TRUE Positive Rate (TPR, aka Sensitivity ou recall) (TP / (TP + FN)), com o complemento FALSE Negative Rate (FNR) (FN / (TP + FN)); e TRUE Negative Rate (TNR, aka Specificity, SPC) (TN / (TN + FP)), com o complemento FALSE Positive Rate (FPR) (FP / (TN + FP)).", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 19], [20, 23], [24, 28], [29, 37], [38, 42], [43, 44], [44, 47], [47, 48], [49, 52], [53, 64], [65, 67], [68, 74], [74, 75], [76, 77], [77, 79], [80, 81], [82, 83], [83, 85], [86, 87], [88, 90], [90, 91], [91, 92], [92, 93], [94, 97], [98, 99], [100, 111], [112, 117], [118, 126], [127, 131], [132, 133], [133, 136], [136, 137], [138, 139], [139, 141], [142, 143], [144, 145], [145, 147], [148, 149], [150, 152], [152, 153], [153, 154], [154, 155], [156, 157], [158, 162], [163, 171], [172, 176], [177, 178], [178, 181], [181, 182], [183, 186], [187, 198], [198, 199], [200, 203], [203, 204], [205, 206], [206, 208], [209, 210], [211, 212], [212, 214], [215, 216], [217, 219], [219, 220], [220, 221], [221, 222], [223, 226], [227, 228], [229, 240], [241, 246], [247, 255], [256, 260], [261, 262], [262, 265], [265, 266], [267, 268], [268, 270], [271, 272], [273, 274], [274, 276], [277, 278], [279, 281], [281, 282], [282, 283], [283, 284]]}
{"doc_key": "ai-test-282", "ner": [[0, 0, "person"], [2, 2, "person"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 18, 18, "role", "working_with", false, false], [2, 2, 18, 18, "role", "working_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Edsinger", "e", "Weber", "tamb\u00e9m", "colaboraram", "em", "muitos", "outros", "rob\u00f4s", ",", "e", "a", "sua", "experi\u00eancia", "de", "trabalho", "com", "o", "Kismet"], "sentence-detokenized": "Edsinger e Weber tamb\u00e9m colaboraram em muitos outros rob\u00f4s, e a sua experi\u00eancia de trabalho com o Kismet", "token2charspan": [[0, 8], [9, 10], [11, 16], [17, 23], [24, 35], [36, 38], [39, 45], [46, 52], [53, 58], [58, 59], [60, 61], [62, 63], [64, 67], [68, 79], [80, 82], [83, 91], [92, 95], [96, 97], [98, 104]]}
{"doc_key": "ai-test-283", "ner": [[2, 2, "programlang"], [15, 15, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 15, 15, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "funcionalidade", "R", "\u00e9", "acess\u00edvel", "a", "partir", "de", "v\u00e1rias", "linguagens", "de", "scripting", ",", "tais", "como", "Python", ",", "tamb\u00e9m", "est\u00e3o", "dispon\u00edveis", "."], "sentence-detokenized": "A funcionalidade R \u00e9 acess\u00edvel a partir de v\u00e1rias linguagens de scripting, tais como Python, tamb\u00e9m est\u00e3o dispon\u00edveis.", "token2charspan": [[0, 1], [2, 16], [17, 18], [19, 20], [21, 30], [31, 32], [33, 39], [40, 42], [43, 49], [50, 60], [61, 63], [64, 73], [73, 74], [75, 79], [80, 84], [85, 91], [91, 92], [93, 99], [100, 105], [106, 117], [117, 118]]}
{"doc_key": "ai-test-284", "ner": [[0, 1, "programlang"], [13, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 14, 0, 1, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["O", "VAL", "foi", "uma", "das", "primeiras", "l\u00ednguas", "dos", "rob\u00f4s", "e", "foi", "utilizado", "em", "rob\u00f4s", "Unimate", "."], "sentence-detokenized": "O VAL foi uma das primeiras l\u00ednguas dos rob\u00f4s e foi utilizado em rob\u00f4s Unimate.", "token2charspan": [[0, 1], [2, 5], [6, 9], [10, 13], [14, 17], [18, 27], [28, 35], [36, 39], [40, 45], [46, 47], [48, 51], [52, 61], [62, 64], [65, 70], [71, 78], [78, 79]]}
{"doc_key": "ai-test-285", "ner": [[12, 24, "conference"], [21, 21, "conference"], [26, 26, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 24, 26, 26, "physical", "", false, false], [21, 21, 12, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Apresentaram", "a", "sua", "base", "de", "dados", "pela", "primeira", "vez", "como", "cartaz", "na", "Confer\u00eancia", "sobre", "Vis\u00e3o", "Inform\u00e1tica", "e", "Reconhecimento", "de", "Padr\u00f5es", "(", "CVPR", ")", "de", "2009", "na", "Florida", "."], "sentence-detokenized": "Apresentaram a sua base de dados pela primeira vez como cartaz na Confer\u00eancia sobre Vis\u00e3o Inform\u00e1tica e Reconhecimento de Padr\u00f5es (CVPR) de 2009 na Florida.", "token2charspan": [[0, 12], [13, 14], [15, 18], [19, 23], [24, 26], [27, 32], [33, 37], [38, 46], [47, 50], [51, 55], [56, 62], [63, 65], [66, 77], [78, 83], [84, 89], [90, 101], [102, 103], [104, 118], [119, 121], [122, 129], [130, 131], [131, 135], [135, 136], [137, 139], [140, 144], [145, 147], [148, 155], [155, 156]]}
{"doc_key": "ai-test-286", "ner": [[0, 3, "misc"], [13, 15, "task"], [17, 19, "field"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 15, 0, 3, "type-of", "", false, false], [17, 19, 0, 3, "type-of", "", false, false], [21, 23, 0, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["As", "tarefas", "de", "categoriza\u00e7\u00e3o", "em", "que", "n\u00e3o", "s\u00e3o", "fornecidas", "etiquetas", "s\u00e3o", "referidas", "como", "classifica\u00e7\u00e3o", "n\u00e3o", "supervisionada", ",", "aprendizagem", "n\u00e3o", "supervisionada", ",", "an\u00e1lise", "de", "agrupamento", "."], "sentence-detokenized": "As tarefas de categoriza\u00e7\u00e3o em que n\u00e3o s\u00e3o fornecidas etiquetas s\u00e3o referidas como classifica\u00e7\u00e3o n\u00e3o supervisionada, aprendizagem n\u00e3o supervisionada, an\u00e1lise de agrupamento.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 27], [28, 30], [31, 34], [35, 38], [39, 42], [43, 53], [54, 63], [64, 67], [68, 77], [78, 82], [83, 96], [97, 100], [101, 115], [115, 116], [117, 129], [130, 133], [134, 148], [148, 149], [150, 157], [158, 160], [161, 172], [172, 173]]}
{"doc_key": "ai-test-287", "ner": [[2, 4, "task"], [14, 16, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Precisa", "de", "Objectar", "o", "reconhecimento", ",", "reconhecer", "e", "localizar", "os", "seres", "humanos", "e", "mais", "reconhecimento", "das", "emo\u00e7\u00f5es", "."], "sentence-detokenized": "Precisa de Objectar o reconhecimento, reconhecer e localizar os seres humanos e mais reconhecimento das emo\u00e7\u00f5es.", "token2charspan": [[0, 7], [8, 10], [11, 19], [20, 21], [22, 36], [36, 37], [38, 48], [49, 50], [51, 60], [61, 63], [64, 69], [70, 77], [78, 79], [80, 84], [85, 99], [100, 103], [104, 111], [111, 112]]}
{"doc_key": "ai-test-288", "ner": [[7, 7, "misc"], [10, 10, "misc"], [12, 12, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["O", "processo", "\u00e9", "complexo", "e", "cont\u00e9m", "a", "codifica\u00e7\u00e3o", "e", "a", "recolha", "ou", "recupera\u00e7\u00e3o", "."], "sentence-detokenized": "O processo \u00e9 complexo e cont\u00e9m a codifica\u00e7\u00e3o e a recolha ou recupera\u00e7\u00e3o.", "token2charspan": [[0, 1], [2, 10], [11, 12], [13, 21], [22, 23], [24, 30], [31, 32], [33, 44], [45, 46], [47, 48], [49, 56], [57, 59], [60, 71], [71, 72]]}
{"doc_key": "ai-test-289", "ner": [[7, 8, "product"], [12, 13, "product"], [30, 31, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 12, 13, "named", "", false, false], [7, 8, 30, 31, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Tamb\u00e9m", "conhecidos", "como", "rob\u00f4s", "paralelos", ",", "ou", "plataformas", "Stewart", "generalizadas", "(", "na", "plataforma", "Stewart", ",", "os", "actuadores", "s\u00e3o", "emparelhados", "tanto", "na", "base", "como", "na", "plataforma", ")", ",", "estes", "sistemas", "s\u00e3o", "rob\u00f4s", "articulados", "que", "utilizam", "mecanismos", "semelhantes", "para", "o", "movimento", "quer", "do", "rob\u00f4", "na", "sua", "base", ",", "quer", "de", "um", "ou", "mais", "bra\u00e7os", "manipuladores", "."], "sentence-detokenized": "Tamb\u00e9m conhecidos como rob\u00f4s paralelos, ou plataformas Stewart generalizadas (na plataforma Stewart, os actuadores s\u00e3o emparelhados tanto na base como na plataforma), estes sistemas s\u00e3o rob\u00f4s articulados que utilizam mecanismos semelhantes para o movimento quer do rob\u00f4 na sua base, quer de um ou mais bra\u00e7os manipuladores.", "token2charspan": [[0, 6], [7, 17], [18, 22], [23, 28], [29, 38], [38, 39], [40, 42], [43, 54], [55, 62], [63, 76], [77, 78], [78, 80], [81, 91], [92, 99], [99, 100], [101, 103], [104, 114], [115, 118], [119, 131], [132, 137], [138, 140], [141, 145], [146, 150], [151, 153], [154, 164], [164, 165], [165, 166], [167, 172], [173, 181], [182, 185], [186, 191], [192, 203], [204, 207], [208, 216], [217, 227], [228, 239], [240, 244], [245, 246], [247, 256], [257, 261], [262, 264], [265, 269], [270, 272], [273, 276], [277, 281], [281, 282], [283, 287], [288, 290], [291, 293], [294, 296], [297, 301], [302, 308], [309, 322], [322, 323]]}
{"doc_key": "ai-test-290", "ner": [[0, 2, "field"], [6, 8, "field"], [14, 15, "field"], [20, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 6, 8, "part-of", "subfield", false, false], [0, 2, 14, 15, "compare", "", false, false], [14, 15, 20, 22, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "vis\u00e3o", "mec\u00e2nica", "como", "disciplina", "de", "engenharia", "de", "sistemas", "pode", "ser", "considerada", "distinta", "da", "vis\u00e3o", "computacional", ",", "uma", "forma", "de", "ci\u00eancia", "da", "computa\u00e7\u00e3o", "."], "sentence-detokenized": "A vis\u00e3o mec\u00e2nica como disciplina de engenharia de sistemas pode ser considerada distinta da vis\u00e3o computacional, uma forma de ci\u00eancia da computa\u00e7\u00e3o.", "token2charspan": [[0, 1], [2, 7], [8, 16], [17, 21], [22, 32], [33, 35], [36, 46], [47, 49], [50, 58], [59, 63], [64, 67], [68, 79], [80, 88], [89, 91], [92, 97], [98, 111], [111, 112], [113, 116], [117, 122], [123, 125], [126, 133], [134, 136], [137, 147], [147, 148]]}
{"doc_key": "ai-test-291", "ner": [[5, 6, "algorithm"], [11, 13, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 11, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "fun\u00e7\u00e3o", "de", "activa\u00e7\u00e3o", "dos", "port\u00f5es", "LSTM", "\u00e9", "muitas", "vezes", "a", "fun\u00e7\u00e3o", "sigm\u00f3ide", "log\u00edstica", "."], "sentence-detokenized": "A fun\u00e7\u00e3o de activa\u00e7\u00e3o dos port\u00f5es LSTM \u00e9 muitas vezes a fun\u00e7\u00e3o sigm\u00f3ide log\u00edstica.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 21], [22, 25], [26, 33], [34, 38], [39, 40], [41, 47], [48, 53], [54, 55], [56, 62], [63, 71], [72, 81], [81, 82]]}
{"doc_key": "ai-test-292", "ner": [[5, 7, "metrics"], [21, 25, "metrics"], [27, 27, "metrics"], [35, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 7, 21, 25, "named", "", false, false], [5, 7, 35, 38, "named", "", false, false], [27, 27, 21, 25, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Por", "outras", "palavras", ",", "a", "m\u00e9dia", "da", "amostra", "\u00e9", "o", "estimador", "(", "necessariamente", "\u00fanico", ")", "eficiente", ",", "e", "portanto", "tamb\u00e9m", "o", "estimador", "de", "vari\u00e2ncia", "m\u00ednima", "imparcial", "(", "MVUE", ")", ",", "para", "al\u00e9m", "de", "ser", "o", "estimador", "de", "m\u00e1xima", "probabilidade", "."], "sentence-detokenized": "Por outras palavras, a m\u00e9dia da amostra \u00e9 o estimador (necessariamente \u00fanico) eficiente, e portanto tamb\u00e9m o estimador de vari\u00e2ncia m\u00ednima imparcial (MVUE), para al\u00e9m de ser o estimador de m\u00e1xima probabilidade.", "token2charspan": [[0, 3], [4, 10], [11, 19], [19, 20], [21, 22], [23, 28], [29, 31], [32, 39], [40, 41], [42, 43], [44, 53], [54, 55], [55, 70], [71, 76], [76, 77], [78, 87], [87, 88], [89, 90], [91, 99], [100, 106], [107, 108], [109, 118], [119, 121], [122, 131], [132, 138], [139, 148], [149, 150], [150, 154], [154, 155], [155, 156], [157, 161], [162, 166], [167, 169], [170, 173], [174, 175], [176, 185], [186, 188], [189, 195], [196, 209], [209, 210]]}
{"doc_key": "ai-test-293", "ner": [[2, 4, "academicjournal"], [7, 7, "researcher"], [9, 10, "researcher"], [13, 14, "researcher"], [20, 20, "product"], [24, 25, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 4, 20, 20, "topic", "", false, false], [2, 4, 24, 25, "topic", "", false, false], [7, 7, 2, 4, "role", "", false, false], [9, 10, 2, 4, "role", "", false, false], [13, 14, 2, 4, "role", "", false, false], [20, 20, 24, 25, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["O", "artigo", "cient\u00edfico", "americano", "de", "2001", "de", "Berners-Lee", ",", "James", "Hendler", ",", "e", "Ora", "Lassila", "descreveu", "uma", "evolu\u00e7\u00e3o", "esperada", "da", "Web", "existente", "para", "uma", "Web", "Sem\u00e2ntica", "."], "sentence-detokenized": "O artigo cient\u00edfico americano de 2001 de Berners-Lee, James Hendler, e Ora Lassila descreveu uma evolu\u00e7\u00e3o esperada da Web existente para uma Web Sem\u00e2ntica.", "token2charspan": [[0, 1], [2, 8], [9, 19], [20, 29], [30, 32], [33, 37], [38, 40], [41, 52], [52, 53], [54, 59], [60, 67], [67, 68], [69, 70], [71, 74], [75, 82], [83, 92], [93, 96], [97, 105], [106, 114], [115, 117], [118, 121], [122, 131], [132, 136], [137, 140], [141, 144], [145, 154], [154, 155]]}
{"doc_key": "ai-test-294", "ner": [[0, 1, "misc"], [11, 12, "person"], [14, 14, "person"], [26, 26, "person"], [34, 34, "person"], [38, 39, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 12, 0, 1, "role", "actor_in_work", false, false], [14, 14, 11, 12, "named", "", false, false], [14, 14, 11, 12, "origin", "", false, false], [26, 26, 14, 14, "part-of", "", false, false], [38, 39, 14, 14, "role", "auditioned_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Blade", "Runner", "utilizou", "um", "n\u00famero", "de", "actores", "ent\u00e3o", "menos", "conhecidos", ":", "Sean", "Young", "retrata", "Rachael", ",", "um", "replicante", "experimental", "implantado", "com", "as", "mem\u00f3rias", "da", "sobrinha", "de", "Tyrell", ",", "fazendo-a", "acreditar", "que", "\u00e9", "humana", ";", "Sammon", ",", "pp.", "92-93", "Nina", "Axelrod", "fez", "uma", "audi\u00e7\u00e3o", "para", "o", "papel", "."], "sentence-detokenized": "Blade Runner utilizou um n\u00famero de actores ent\u00e3o menos conhecidos: Sean Young retrata Rachael, um replicante experimental implantado com as mem\u00f3rias da sobrinha de Tyrell, fazendo-a acreditar que \u00e9 humana; Sammon, pp. 92-93 Nina Axelrod fez uma audi\u00e7\u00e3o para o papel.", "token2charspan": [[0, 5], [6, 12], [13, 21], [22, 24], [25, 31], [32, 34], [35, 42], [43, 48], [49, 54], [55, 65], [65, 66], [67, 71], [72, 77], [78, 85], [86, 93], [93, 94], [95, 97], [98, 108], [109, 121], [122, 132], [133, 136], [137, 139], [140, 148], [149, 151], [152, 160], [161, 163], [164, 170], [170, 171], [172, 181], [182, 191], [192, 195], [196, 197], [198, 204], [204, 205], [206, 212], [212, 213], [214, 217], [218, 223], [224, 228], [229, 236], [237, 240], [241, 244], [245, 252], [253, 257], [258, 259], [260, 265], [265, 266]]}
{"doc_key": "ai-test-295", "ner": [[0, 1, "researcher"], [3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [13, 15, "university"], [22, 22, "product"], [24, 24, "product"], [46, 46, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 13, 15, "physical", "", false, false], [3, 4, 13, 15, "physical", "", false, false], [6, 7, 13, 15, "physical", "", false, false], [9, 10, 13, 15, "physical", "", false, false], [13, 15, 46, 46, "physical", "", true, false], [22, 22, 13, 15, "temporal", "", false, false], [24, 24, 13, 15, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Gerry", "Sussman", ",", "Eugene", "Charniak", ",", "Seymour", "Papert", "e", "Terry", "Winograd", "visitaram", "a", "Universidade", "de", "Edimburgo", "em", "1971", "divulgando", "as", "not\u00edcias", "sobre", "Micro-Planner", "e", "SHRDLU", "e", "lan\u00e7ando", "d\u00favidas", "sobre", "a", "abordagem", "do", "procedimento", "de", "prova", "uniforme", "da", "resolu\u00e7\u00e3o", "que", "tinha", "sido", "a", "base", "da", "L\u00f3gica", "de", "Edimburgo", "."], "sentence-detokenized": "Gerry Sussman, Eugene Charniak, Seymour Papert e Terry Winograd visitaram a Universidade de Edimburgo em 1971 divulgando as not\u00edcias sobre Micro-Planner e SHRDLU e lan\u00e7ando d\u00favidas sobre a abordagem do procedimento de prova uniforme da resolu\u00e7\u00e3o que tinha sido a base da L\u00f3gica de Edimburgo.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 21], [22, 30], [30, 31], [32, 39], [40, 46], [47, 48], [49, 54], [55, 63], [64, 73], [74, 75], [76, 88], [89, 91], [92, 101], [102, 104], [105, 109], [110, 120], [121, 123], [124, 132], [133, 138], [139, 152], [153, 154], [155, 161], [162, 163], [164, 172], [173, 180], [181, 186], [187, 188], [189, 198], [199, 201], [202, 214], [215, 217], [218, 223], [224, 232], [233, 235], [236, 245], [246, 249], [250, 255], [256, 260], [261, 262], [263, 267], [268, 270], [271, 277], [278, 280], [281, 290], [290, 291]]}
{"doc_key": "ai-test-296", "ner": [[3, 3, "researcher"], [11, 11, "field"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 13, 14, "role", "inspires", false, false], [3, 3, 16, 17, "role", "inspires", false, false], [3, 3, 19, 20, "role", "inspires", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["O", "trabalho", "de", "Walter", "inspirou", "as", "gera\u00e7\u00f5es", "seguintes", "de", "investigadores", "em", "rob\u00f3tica", "como", "Rodney", "Brooks", ",", "Hans", "Moravec", "e", "Mark", "Tilden", "."], "sentence-detokenized": "O trabalho de Walter inspirou as gera\u00e7\u00f5es seguintes de investigadores em rob\u00f3tica como Rodney Brooks, Hans Moravec e Mark Tilden.", "token2charspan": [[0, 1], [2, 10], [11, 13], [14, 20], [21, 29], [30, 32], [33, 41], [42, 51], [52, 54], [55, 69], [70, 72], [73, 81], [82, 86], [87, 93], [94, 100], [100, 101], [102, 106], [107, 114], [115, 116], [117, 121], [122, 128], [128, 129]]}
{"doc_key": "ai-test-297", "ner": [[3, 3, "algorithm"], [9, 10, "researcher"], [15, 23, "event"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 9, 10, "origin", "", false, false], [3, 3, 15, 23, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Subsequentemente", ",", "uma", "CNN", "semelhante", "baseada", "em", "GPU", "por", "Alex", "Krizhevsky", "et", "al.", "ganhou", "o", "Desafio", "de", "Reconhecimento", "Visual", "em", "Grande", "Escala", "ImageNet", "2012", "."], "sentence-detokenized": "Subsequentemente, uma CNN semelhante baseada em GPU por Alex Krizhevsky et al. ganhou o Desafio de Reconhecimento Visual em Grande Escala ImageNet 2012.", "token2charspan": [[0, 16], [16, 17], [18, 21], [22, 25], [26, 36], [37, 44], [45, 47], [48, 51], [52, 55], [56, 60], [61, 71], [72, 74], [75, 78], [79, 85], [86, 87], [88, 95], [96, 98], [99, 113], [114, 120], [121, 123], [124, 130], [131, 137], [138, 146], [147, 151], [151, 152]]}
{"doc_key": "ai-test-298", "ner": [[0, 3, "misc"], [11, 13, "metrics"], [16, 17, "metrics"], [22, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 13, 0, 3, "type-of", "", false, false], [16, 17, 0, 3, "type-of", "", false, false], [16, 17, 22, 26, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["As", "fun\u00e7\u00f5es", "de", "perda", "comummente", "utilizadas", "para", "classifica\u00e7\u00e3o", "probabil\u00edstica", "incluem", "a", "perda", "de", "registo", "e", "a", "pontua\u00e7\u00e3o", "Brier", "entre", "a", "distribui\u00e7\u00e3o", "de", "probabilidade", "prevista", "e", "a", "VERDADEIRA", "."], "sentence-detokenized": "As fun\u00e7\u00f5es de perda comummente utilizadas para classifica\u00e7\u00e3o probabil\u00edstica incluem a perda de registo e a pontua\u00e7\u00e3o Brier entre a distribui\u00e7\u00e3o de probabilidade prevista e a VERDADEIRA.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 19], [20, 30], [31, 41], [42, 46], [47, 60], [61, 75], [76, 83], [84, 85], [86, 91], [92, 94], [95, 102], [103, 104], [105, 106], [107, 116], [117, 122], [123, 128], [129, 130], [131, 143], [144, 146], [147, 160], [161, 169], [170, 171], [172, 173], [174, 184], [184, 185]]}
{"doc_key": "ai-test-299", "ner": [[6, 6, "organisation"], [14, 14, "field"], [16, 16, "organisation"], [20, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 14, 14, "general-affiliation", "field_of_study", false, false], [6, 6, 20, 21, "part-of", "", false, false], [16, 16, 6, 6, "role", "admits_E2_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Em", "Maio", "de", "2016", ",", "o", "NtechLab", "foi", "admitido", "no", "teste", "oficial", "da", "tecnologia", "biom\u00e9trica", "pelo", "NIST", "entre", "as", "tr\u00eas", "empresas", "russas", "."], "sentence-detokenized": "Em Maio de 2016, o NtechLab foi admitido no teste oficial da tecnologia biom\u00e9trica pelo NIST entre as tr\u00eas empresas russas.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 15], [15, 16], [17, 18], [19, 27], [28, 31], [32, 40], [41, 43], [44, 49], [50, 57], [58, 60], [61, 71], [72, 82], [83, 87], [88, 92], [93, 98], [99, 101], [102, 106], [107, 115], [116, 122], [122, 123]]}
{"doc_key": "ai-test-300", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["No", "entanto", ",", "os", "n\u00fameros", "de", "ponto", "flutuante", "t\u00eam", "apenas", "uma", "certa", "precis\u00e3o", "matem\u00e1tica", "."], "sentence-detokenized": "No entanto, os n\u00fameros de ponto flutuante t\u00eam apenas uma certa precis\u00e3o matem\u00e1tica.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 14], [15, 22], [23, 25], [26, 31], [32, 41], [42, 45], [46, 52], [53, 56], [57, 62], [63, 71], [72, 82], [82, 83]]}
{"doc_key": "ai-test-301", "ner": [[7, 7, "organisation"], [11, 18, "conference"], [20, 20, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 11, 18, "role", "contributes_to", false, false], [20, 20, 11, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Durante", "2015", ",", "muitos", "dos", "artigos", "da", "SenseTime", "foram", "aceites", "na", "Confer\u00eancia", "sobre", "Vis\u00e3o", "Inform\u00e1tica", "e", "Reconhecimento", "de", "Padr\u00f5es", "(", "CVPR", ")", "."], "sentence-detokenized": "Durante 2015, muitos dos artigos da SenseTime foram aceites na Confer\u00eancia sobre Vis\u00e3o Inform\u00e1tica e Reconhecimento de Padr\u00f5es (CVPR).", "token2charspan": [[0, 7], [8, 12], [12, 13], [14, 20], [21, 24], [25, 32], [33, 35], [36, 45], [46, 51], [52, 59], [60, 62], [63, 74], [75, 80], [81, 86], [87, 98], [99, 100], [101, 115], [116, 118], [119, 126], [127, 128], [128, 132], [132, 133], [133, 134]]}
{"doc_key": "ai-test-302", "ner": [[4, 6, "task"], [8, 8, "task"], [11, 12, "task"], [14, 17, "task"], [20, 20, "field"], [22, 25, "misc"], [27, 35, "conference"], [44, 46, "misc"], [48, 49, "conference"], [64, 67, "misc"], [69, 69, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[4, 6, 20, 20, "part-of", "task_part_of_field", false, false], [8, 8, 4, 6, "named", "", false, false], [11, 12, 20, 20, "part-of", "task_part_of_field", false, false], [14, 17, 11, 12, "named", "", false, false], [22, 25, 27, 35, "temporal", "", false, false], [44, 46, 48, 49, "temporal", "", false, false], [64, 67, 69, 69, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Co-desenvolveu", "algoritmos", "\u00f3ptimos", "para", "Estrutura", "do", "Movimento", "(", "SFM", ",", "ou", "Visual", "SLAM", ",", "localiza\u00e7\u00e3o", "e", "mapeamento", "simult\u00e2neos", ",", "em", "Rob\u00f3tica", ";", "Pr\u00e9mio", "de", "Melhor", "Papel", "na", "Confer\u00eancia", "sobre", "Vis\u00e3o", "por", "Computador", "e", "Reconhecimento", "de", "Padr\u00f5es", "1998", ")", ",", "caracterizou", "as", "suas", "ambiguidades", "(", "Pr\u00e9mio", "David", "Marr", "no", "ICCV", "1999", ")", ",", "tamb\u00e9m", "caracterizou", "a", "identificabilidade", "e", "observabilidade", "da", "fus\u00e3o", "de", "sensores", "visuais-inerciais", "(", "Pr\u00e9mio", "de", "Melhor", "Papel", "na", "Rob\u00f3tica", "2015", ")", "."], "sentence-detokenized": "Co-desenvolveu algoritmos \u00f3ptimos para Estrutura do Movimento (SFM, ou Visual SLAM, localiza\u00e7\u00e3o e mapeamento simult\u00e2neos, em Rob\u00f3tica; Pr\u00e9mio de Melhor Papel na Confer\u00eancia sobre Vis\u00e3o por Computador e Reconhecimento de Padr\u00f5es 1998), caracterizou as suas ambiguidades (Pr\u00e9mio David Marr no ICCV 1999), tamb\u00e9m caracterizou a identificabilidade e observabilidade da fus\u00e3o de sensores visuais-inerciais (Pr\u00e9mio de Melhor Papel na Rob\u00f3tica 2015).", "token2charspan": [[0, 14], [15, 25], [26, 33], [34, 38], [39, 48], [49, 51], [52, 61], [62, 63], [63, 66], [66, 67], [68, 70], [71, 77], [78, 82], [82, 83], [84, 95], [96, 97], [98, 108], [109, 120], [120, 121], [122, 124], [125, 133], [133, 134], [135, 141], [142, 144], [145, 151], [152, 157], [158, 160], [161, 172], [173, 178], [179, 184], [185, 188], [189, 199], [200, 201], [202, 216], [217, 219], [220, 227], [228, 232], [232, 233], [233, 234], [235, 247], [248, 250], [251, 255], [256, 268], [269, 270], [270, 276], [277, 282], [283, 287], [288, 290], [291, 295], [296, 300], [300, 301], [301, 302], [303, 309], [310, 322], [323, 324], [325, 343], [344, 345], [346, 361], [362, 364], [365, 370], [371, 373], [374, 382], [383, 400], [401, 402], [402, 408], [409, 411], [412, 418], [419, 424], [425, 427], [428, 436], [437, 441], [441, 442], [442, 443]]}
{"doc_key": "ai-test-303", "ner": [[0, 2, "researcher"], [3, 3, "organisation"], [5, 5, "organisation"], [7, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Stephen", "H.", "Muggleton", "FBCS", ",", "FIET", ",", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ","], "sentence-detokenized": "Stephen H. Muggleton FBCS, FIET, Association for the Advancement of Artificial Intelligence,", "token2charspan": [[0, 7], [8, 10], [11, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 44], [45, 48], [49, 52], [53, 64], [65, 67], [68, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-304", "ner": [[0, 3, "task"], [9, 11, "field"], [13, 14, "field"], [16, 18, "field"], [24, 26, "task"], [28, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 3, 9, 11, "part-of", "task_part_of_field", false, false], [0, 3, 13, 14, "part-of", "task_part_of_field", false, false], [0, 3, 16, 18, "part-of", "task_part_of_field", false, false], [0, 3, 24, 26, "part-of", "", false, false], [0, 3, 28, 30, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["A", "detec\u00e7\u00e3o", "de", "bordas", "\u00e9", "uma", "ferramenta", "fundamental", "no", "processamento", "de", "imagem", ",", "vis\u00e3o", "mec\u00e2nica", "e", "vis\u00e3o", "por", "computador", ",", "particularmente", "nas", "\u00e1reas", "de", "detec\u00e7\u00e3o", "de", "caracter\u00edsticas", "e", "extrac\u00e7\u00e3o", "de", "caracter\u00edsticas", "."], "sentence-detokenized": "A detec\u00e7\u00e3o de bordas \u00e9 uma ferramenta fundamental no processamento de imagem, vis\u00e3o mec\u00e2nica e vis\u00e3o por computador, particularmente nas \u00e1reas de detec\u00e7\u00e3o de caracter\u00edsticas e extrac\u00e7\u00e3o de caracter\u00edsticas.", "token2charspan": [[0, 1], [2, 10], [11, 13], [14, 20], [21, 22], [23, 26], [27, 37], [38, 49], [50, 52], [53, 66], [67, 69], [70, 76], [76, 77], [78, 83], [84, 92], [93, 94], [95, 100], [101, 104], [105, 115], [115, 116], [117, 132], [133, 136], [137, 142], [143, 145], [146, 154], [155, 157], [158, 173], [174, 175], [176, 185], [186, 188], [189, 204], [204, 205]]}
{"doc_key": "ai-test-305", "ner": [[8, 9, "misc"], [26, 29, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Um", "exemplo", "disto", "seria", "uma", "vari\u00e1vel", "como", "a", "temperatura", "exterior", "(", "temperatura", "matem\u00e1tica", "/", "matem\u00e1tica", ")", ",", "que", "numa", "determinada", "aplica\u00e7\u00e3o", "poderia", "ser", "registada", "com", "v\u00e1rias", "casas", "decimais", "de", "precis\u00e3o", "(", "dependendo", "do", "aparelho", "de", "detec\u00e7\u00e3o", ")", "."], "sentence-detokenized": "Um exemplo disto seria uma vari\u00e1vel como a temperatura exterior (temperatura matem\u00e1tica / matem\u00e1tica), que numa determinada aplica\u00e7\u00e3o poderia ser registada com v\u00e1rias casas decimais de precis\u00e3o (dependendo do aparelho de detec\u00e7\u00e3o).", "token2charspan": [[0, 2], [3, 10], [11, 16], [17, 22], [23, 26], [27, 35], [36, 40], [41, 42], [43, 54], [55, 63], [64, 65], [65, 76], [77, 87], [88, 89], [90, 100], [100, 101], [101, 102], [103, 106], [107, 111], [112, 123], [124, 133], [134, 141], [142, 145], [146, 155], [156, 159], [160, 166], [167, 172], [173, 181], [182, 184], [185, 193], [194, 195], [195, 205], [206, 208], [209, 217], [218, 220], [221, 229], [229, 230], [230, 231]]}
{"doc_key": "ai-test-306", "ner": [[5, 6, "person"], [8, 9, "person"], [12, 13, "person"], [19, 20, "person"], [30, 30, "misc"], [35, 35, "misc"], [36, 37, "person"], [42, 42, "organisation"], [39, 41, "person"], [48, 48, "organisation"], [49, 50, "person"], [55, 55, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[36, 37, 30, 30, "part-of", "", false, false], [36, 37, 35, 35, "role", "", false, false], [39, 41, 42, 42, "role", "", false, false], [49, 50, 48, 48, "role", "youtuber", false, false], [55, 55, 49, 50, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Os", "ju\u00edzes", "que", "regressam", "s\u00e3o", "Fon", "Davis", ",", "Jessica", "Chobot", ",", "e", "Leland", "Melvin", ",", "bem", "como", "o", "actor", "Clark", "Gregg", ",", "actor", "convidado", "dos", "J\u00faris", ",", "o", "anfitri\u00e3o", "dos", "MythBusters", "e", "antigo", "construtor", "de", "Battlebots", "Adam", "Savage", ",", "Vernon", "Davis", "da", "NFL", ",", "e", "a", "estrela", "do", "YouTube", "Michael", "Stevens", ",", "tamb\u00e9m", "conhecido", "como", "Vsauce", "."], "sentence-detokenized": "Os ju\u00edzes que regressam s\u00e3o Fon Davis, Jessica Chobot, e Leland Melvin, bem como o actor Clark Gregg, actor convidado dos J\u00faris, o anfitri\u00e3o dos MythBusters e antigo construtor de Battlebots Adam Savage, Vernon Davis da NFL, e a estrela do YouTube Michael Stevens, tamb\u00e9m conhecido como Vsauce.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 23], [24, 27], [28, 31], [32, 37], [37, 38], [39, 46], [47, 53], [53, 54], [55, 56], [57, 63], [64, 70], [70, 71], [72, 75], [76, 80], [81, 82], [83, 88], [89, 94], [95, 100], [100, 101], [102, 107], [108, 117], [118, 121], [122, 127], [127, 128], [129, 130], [131, 140], [141, 144], [145, 156], [157, 158], [159, 165], [166, 176], [177, 179], [180, 190], [191, 195], [196, 202], [202, 203], [204, 210], [211, 216], [217, 219], [220, 223], [223, 224], [225, 226], [227, 228], [229, 236], [237, 239], [240, 247], [248, 255], [256, 263], [263, 264], [265, 271], [272, 281], [282, 286], [287, 293], [293, 294]]}
{"doc_key": "ai-test-307", "ner": [[8, 9, "algorithm"], [15, 16, "algorithm"], [18, 18, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 18, 18, "part-of", "", false, false], [15, 16, 18, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Mas", "estes", "m\u00e9todos", "nunca", "conquistaram", "a", "tecnologia", "da", "mistura", "Gaussiana", "n\u00e3o", "uniforme", "/", "modelo", "de", "Markov", "escondido", "(", "GMM-HMM", ")", "baseada", "em", "modelos", "generativos", "de", "fala", "treinados", "de", "forma", "discriminat\u00f3ria", "."], "sentence-detokenized": "Mas estes m\u00e9todos nunca conquistaram a tecnologia da mistura Gaussiana n\u00e3o uniforme / modelo de Markov escondido (GMM-HMM) baseada em modelos generativos de fala treinados de forma discriminat\u00f3ria.", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 23], [24, 36], [37, 38], [39, 49], [50, 52], [53, 60], [61, 70], [71, 74], [75, 83], [84, 85], [86, 92], [93, 95], [96, 102], [103, 112], [113, 114], [114, 121], [121, 122], [123, 130], [131, 133], [134, 141], [142, 153], [154, 156], [157, 161], [162, 171], [172, 174], [175, 180], [181, 196], [196, 197]]}
{"doc_key": "ai-test-308", "ner": [[4, 4, "product"], [6, 7, "programlang"], [9, 9, "programlang"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Pacotes", "de", "software", "como", "MATLAB", ",", "GNU", "Octave", ",", "Scilab", ",", "e", "SciPy", "fornecem", "formas", "convenientes", "de", "aplicar", "estes", "diferentes", "m\u00e9todos", "."], "sentence-detokenized": "Pacotes de software como MATLAB, GNU Octave, Scilab, e SciPy fornecem formas convenientes de aplicar estes diferentes m\u00e9todos.", "token2charspan": [[0, 7], [8, 10], [11, 19], [20, 24], [25, 31], [31, 32], [33, 36], [37, 43], [43, 44], [45, 51], [51, 52], [53, 54], [55, 60], [61, 69], [70, 76], [77, 89], [90, 92], [93, 100], [101, 106], [107, 117], [118, 125], [125, 126]]}
{"doc_key": "ai-test-309", "ner": [[0, 3, "algorithm"], [5, 5, "algorithm"], [11, 13, "task"], [21, 22, "researcher"], [24, 26, "university"], [28, 29, "researcher"], [31, 34, "organisation"], [36, 36, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 3, 11, 13, "related-to", "", false, false], [0, 3, 21, 22, "origin", "", false, false], [0, 3, 28, 29, "origin", "", false, false], [5, 5, 0, 3, "named", "", false, false], [21, 22, 24, 26, "physical", "", false, false], [21, 22, 24, 26, "role", "", false, false], [28, 29, 31, 34, "physical", "", false, false], [28, 29, 31, 34, "role", "", false, false], [36, 36, 31, 34, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["A", "codifica\u00e7\u00e3o", "preditiva", "linear", "(", "LPC", ")", ",", "um", "algoritmo", "de", "processamento", "de", "fala", ",", "foi", "proposta", "pela", "primeira", "vez", "por", "Fumitada", "Itakura", "da", "Universidade", "de", "Nagoya", "e", "Shuzo", "Saito", "da", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "em", "1966", "."], "sentence-detokenized": "A codifica\u00e7\u00e3o preditiva linear (LPC), um algoritmo de processamento de fala, foi proposta pela primeira vez por Fumitada Itakura da Universidade de Nagoya e Shuzo Saito da Nippon Telegraph and Telephone (NTT) em 1966.", "token2charspan": [[0, 1], [2, 13], [14, 23], [24, 30], [31, 32], [32, 35], [35, 36], [36, 37], [38, 40], [41, 50], [51, 53], [54, 67], [68, 70], [71, 75], [75, 76], [77, 80], [81, 89], [90, 94], [95, 103], [104, 107], [108, 111], [112, 120], [121, 128], [129, 131], [132, 144], [145, 147], [148, 154], [155, 156], [157, 162], [163, 168], [169, 171], [172, 178], [179, 188], [189, 192], [193, 202], [203, 204], [204, 207], [207, 208], [209, 211], [212, 216], [216, 217]]}
{"doc_key": "ai-test-310", "ner": [[15, 23, "conference"], [25, 25, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[25, 25, 15, 23, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Em", "2006", ",", "para", "o", "25\u00ba", "anivers\u00e1rio", "do", "algoritmo", ",", "foi", "organizado", "um", "workshop", "na", "Confer\u00eancia", "Internacional", "sobre", "Vis\u00e3o", "Computadorizada", "e", "Reconhecimento", "de", "Padr\u00f5es", "(", "CVPR", ")", "para", "resumir", "as", "mais", "recentes", "contribui\u00e7\u00f5es", "e", "varia\u00e7\u00f5es", "do", "algoritmo", "original", ",", "na", "sua", "maioria", "destinadas", "a", "melhorar", "a", "velocidade", "do", "algoritmo", ",", "a", "robustez", "e", "precis\u00e3o", "da", "solu\u00e7\u00e3o", "estimada", "e", "a", "diminuir", "a", "depend\u00eancia", "das", "constantes", "definidas", "pelo", "utilizador", "."], "sentence-detokenized": "Em 2006, para o 25\u00ba anivers\u00e1rio do algoritmo, foi organizado um workshop na Confer\u00eancia Internacional sobre Vis\u00e3o Computadorizada e Reconhecimento de Padr\u00f5es (CVPR) para resumir as mais recentes contribui\u00e7\u00f5es e varia\u00e7\u00f5es do algoritmo original, na sua maioria destinadas a melhorar a velocidade do algoritmo, a robustez e precis\u00e3o da solu\u00e7\u00e3o estimada e a diminuir a depend\u00eancia das constantes definidas pelo utilizador.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 13], [14, 15], [16, 19], [20, 31], [32, 34], [35, 44], [44, 45], [46, 49], [50, 60], [61, 63], [64, 72], [73, 75], [76, 87], [88, 101], [102, 107], [108, 113], [114, 129], [130, 131], [132, 146], [147, 149], [150, 157], [158, 159], [159, 163], [163, 164], [165, 169], [170, 177], [178, 180], [181, 185], [186, 194], [195, 208], [209, 210], [211, 220], [221, 223], [224, 233], [234, 242], [242, 243], [244, 246], [247, 250], [251, 258], [259, 269], [270, 271], [272, 280], [281, 282], [283, 293], [294, 296], [297, 306], [306, 307], [308, 309], [310, 318], [319, 320], [321, 329], [330, 332], [333, 340], [341, 349], [350, 351], [352, 353], [354, 362], [363, 364], [365, 376], [377, 380], [381, 391], [392, 401], [402, 406], [407, 417], [417, 418]]}
{"doc_key": "ai-test-311", "ner": [[4, 6, "university"], [9, 13, "organisation"], [16, 18, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Os", "membros", "frequentaram", "a", "Universidade", "de", "Debrecen", ",", "a", "Academia", "de", "Ci\u00eancias", "da", "Hungria", ",", "a", "Universidade", "E\u00f6tv\u00f6s", "Lor\u00e1nd", ",", "etc."], "sentence-detokenized": "Os membros frequentaram a Universidade de Debrecen, a Academia de Ci\u00eancias da Hungria, a Universidade E\u00f6tv\u00f6s Lor\u00e1nd, etc.", "token2charspan": [[0, 2], [3, 10], [11, 23], [24, 25], [26, 38], [39, 41], [42, 50], [50, 51], [52, 53], [54, 62], [63, 65], [66, 74], [75, 77], [78, 85], [85, 86], [87, 88], [89, 101], [102, 108], [109, 115], [115, 116], [117, 121]]}
{"doc_key": "ai-test-312", "ner": [[3, 3, "algorithm"], [17, 19, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 17, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Para", "estender", "a", "SVM", "aos", "casos", "em", "que", "os", "dados", "n\u00e3o", "s\u00e3o", "separ\u00e1veis", "linearmente", ",", "introduzimos", "a", "fun\u00e7\u00e3o", "de", "perda", ","], "sentence-detokenized": "Para estender a SVM aos casos em que os dados n\u00e3o s\u00e3o separ\u00e1veis linearmente, introduzimos a fun\u00e7\u00e3o de perda,", "token2charspan": [[0, 4], [5, 13], [14, 15], [16, 19], [20, 23], [24, 29], [30, 32], [33, 36], [37, 39], [40, 45], [46, 49], [50, 53], [54, 64], [65, 76], [76, 77], [78, 90], [91, 92], [93, 99], [100, 102], [103, 108], [108, 109]]}
{"doc_key": "ai-test-313", "ner": [[0, 1, "programlang"], [13, 14, "researcher"], [16, 17, "researcher"], [20, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 13, 14, "origin", "", false, false], [0, 1, 16, 17, "origin", "", false, false], [0, 1, 20, 21, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["O", "log\u00f3tipo", "\u00e9", "uma", "linguagem", "de", "programa\u00e7\u00e3o", "educacional", ",", "concebida", "em", "1967", "por", "Wally", "Feurzeig", ",", "Seymour", "Papert", ",", "e", "Cynthia", "Solomon", "."], "sentence-detokenized": "O log\u00f3tipo \u00e9 uma linguagem de programa\u00e7\u00e3o educacional, concebida em 1967 por Wally Feurzeig, Seymour Papert, e Cynthia Solomon.", "token2charspan": [[0, 1], [2, 10], [11, 12], [13, 16], [17, 26], [27, 29], [30, 41], [42, 53], [53, 54], [55, 64], [65, 67], [68, 72], [73, 76], [77, 82], [83, 91], [91, 92], [93, 100], [101, 107], [107, 108], [109, 110], [111, 118], [119, 126], [126, 127]]}
{"doc_key": "ai-test-314", "ner": [[0, 3, "organisation"], [8, 15, "organisation"], [17, 20, "location"], [24, 24, "location"], [26, 26, "location"], [37, 42, "product"], [48, 58, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 8, 15, "role", "works_for", false, false], [8, 15, 17, 20, "physical", "", false, false], [17, 20, 24, 24, "physical", "", false, false], [24, 24, 26, 26, "physical", "", false, false], [37, 42, 0, 3, "origin", "", false, false], [48, 58, 37, 42, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["O", "Eyring", "Research", "Institute", "foi", "fundamental", "para", "a", "Direc\u00e7\u00e3o", "de", "M\u00edsseis", "da", "For\u00e7a", "A\u00e9rea", "dos", "EUA", "na", "Base", "A\u00e9rea", "de", "Hill", ",", "perto", "de", "Ogden", ",", "Utah", ",", "para", "produzir", "em", "segredo", "militar", "de", "topo", ",", "o", "Software", "de", "Tecnologia", "de", "Sistemas", "Inteligentes", "que", "foi", "fundado", "para", "o", "programa", "Reagan", "Star", "Wars", ",", "mais", "tarde", "chamado", "Reagan", "Star", "Wars", "."], "sentence-detokenized": "O Eyring Research Institute foi fundamental para a Direc\u00e7\u00e3o de M\u00edsseis da For\u00e7a A\u00e9rea dos EUA na Base A\u00e9rea de Hill, perto de Ogden, Utah, para produzir em segredo militar de topo, o Software de Tecnologia de Sistemas Inteligentes que foi fundado para o programa Reagan Star Wars, mais tarde chamado Reagan Star Wars.", "token2charspan": [[0, 1], [2, 8], [9, 17], [18, 27], [28, 31], [32, 43], [44, 48], [49, 50], [51, 59], [60, 62], [63, 70], [71, 73], [74, 79], [80, 85], [86, 89], [90, 93], [94, 96], [97, 101], [102, 107], [108, 110], [111, 115], [115, 116], [117, 122], [123, 125], [126, 131], [131, 132], [133, 137], [137, 138], [139, 143], [144, 152], [153, 155], [156, 163], [164, 171], [172, 174], [175, 179], [179, 180], [181, 182], [183, 191], [192, 194], [195, 205], [206, 208], [209, 217], [218, 230], [231, 234], [235, 238], [239, 246], [247, 251], [252, 253], [254, 262], [263, 269], [270, 274], [275, 279], [279, 280], [281, 285], [286, 291], [292, 299], [300, 306], [307, 311], [312, 316], [316, 317]]}
{"doc_key": "ai-test-315", "ner": [[23, 25, "researcher"], [27, 28, "researcher"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Ao", "longo", "das", "d\u00e9cadas", "pesquisou", "e", "desenvolveu", "campos", "emergentes", "da", "inform\u00e1tica", "a", "partir", "de", "compiladores", ",", "linguagens", "de", "programa\u00e7\u00e3o", "e", "arquitectura", "de", "sistemas", "John", "F.", "Sowa", "e", "John", "Zachman", "(", "1992", ")", "."], "sentence-detokenized": "Ao longo das d\u00e9cadas pesquisou e desenvolveu campos emergentes da inform\u00e1tica a partir de compiladores, linguagens de programa\u00e7\u00e3o e arquitectura de sistemas John F. Sowa e John Zachman (1992).", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 20], [21, 30], [31, 32], [33, 44], [45, 51], [52, 62], [63, 65], [66, 77], [78, 79], [80, 86], [87, 89], [90, 102], [102, 103], [104, 114], [115, 117], [118, 129], [130, 131], [132, 144], [145, 147], [148, 156], [157, 161], [162, 164], [165, 169], [170, 171], [172, 176], [177, 184], [185, 186], [186, 190], [190, 191], [191, 192]]}
{"doc_key": "ai-test-316", "ner": [[1, 2, "algorithm"], [7, 8, "algorithm"], [10, 11, "algorithm"], [16, 18, "field"], [20, 22, "field"], [27, 31, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 8, 1, 2, "named", "", false, false], [10, 11, 1, 2, "named", "", false, false], [16, 18, 1, 2, "usage", "", false, false], [20, 22, 1, 2, "usage", "", false, false], [27, 31, 1, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["O", "operador", "Sobel", ",", "por", "vezes", "chamado", "operador", "Sobel-Feldman", "ou", "filtro", "Sobel", ",", "\u00e9", "utilizado", "no", "processamento", "de", "imagem", "e", "vis\u00e3o", "por", "computador", ",", "particularmente", "dentro", "de", "algoritmos", "de", "detec\u00e7\u00e3o", "de", "bordas", ",", "onde", "cria", "uma", "imagem", "que", "enfatiza", "as", "bordas", "."], "sentence-detokenized": "O operador Sobel, por vezes chamado operador Sobel-Feldman ou filtro Sobel, \u00e9 utilizado no processamento de imagem e vis\u00e3o por computador, particularmente dentro de algoritmos de detec\u00e7\u00e3o de bordas, onde cria uma imagem que enfatiza as bordas.", "token2charspan": [[0, 1], [2, 10], [11, 16], [16, 17], [18, 21], [22, 27], [28, 35], [36, 44], [45, 58], [59, 61], [62, 68], [69, 74], [74, 75], [76, 77], [78, 87], [88, 90], [91, 104], [105, 107], [108, 114], [115, 116], [117, 122], [123, 126], [127, 137], [137, 138], [139, 154], [155, 161], [162, 164], [165, 175], [176, 178], [179, 187], [188, 190], [191, 197], [197, 198], [199, 203], [204, 208], [209, 212], [213, 219], [220, 223], [224, 232], [233, 235], [236, 242], [242, 243]]}
{"doc_key": "ai-test-317", "ner": [[0, 0, "algorithm"], [5, 6, "field"], [16, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 5, 6, "compare", "", false, false], [0, 0, 5, 6, "type-of", "", false, false], [0, 0, 16, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["LDA", "\u00e9", "um", "algoritmo", "de", "aprendizagem", "supervisionado", "que", "utiliza", "as", "etiquetas", "dos", "dados", ",", "enquanto", "que", "PCA", "\u00e9", "um", "algoritmo", "de", "aprendizagem", "que", "ignora", "as", "etiquetas", "."], "sentence-detokenized": "LDA \u00e9 um algoritmo de aprendizagem supervisionado que utiliza as etiquetas dos dados, enquanto que PCA \u00e9 um algoritmo de aprendizagem que ignora as etiquetas.", "token2charspan": [[0, 3], [4, 5], [6, 8], [9, 18], [19, 21], [22, 34], [35, 49], [50, 53], [54, 61], [62, 64], [65, 74], [75, 78], [79, 84], [84, 85], [86, 94], [95, 98], [99, 102], [103, 104], [105, 107], [108, 117], [118, 120], [121, 133], [134, 137], [138, 144], [145, 147], [148, 157], [157, 158]]}
{"doc_key": "ai-test-318", "ner": [[6, 6, "algorithm"], [8, 11, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Outros", "algoritmos", "de", "classifica\u00e7\u00e3o", "linear", "incluem", "Winnow", ",", "m\u00e1quina", "de", "suporte", "vectorial", "e", "regress\u00e3o", "log\u00edstica", "."], "sentence-detokenized": "Outros algoritmos de classifica\u00e7\u00e3o linear incluem Winnow, m\u00e1quina de suporte vectorial e regress\u00e3o log\u00edstica.", "token2charspan": [[0, 6], [7, 17], [18, 20], [21, 34], [35, 41], [42, 49], [50, 56], [56, 57], [58, 65], [66, 68], [69, 76], [77, 86], [87, 88], [89, 98], [99, 108], [108, 109]]}
{"doc_key": "ai-test-319", "ner": [[0, 0, "product"], [6, 8, "programlang"], [16, 16, "product"], [18, 18, "programlang"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 8, "general-affiliation", "", true, false], [0, 0, 16, 16, "general-affiliation", "", true, false], [0, 0, 18, 18, "general-affiliation", "", true, false], [0, 0, 21, 21, "general-affiliation", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["VTK", "consiste", "numa", "biblioteca", "de", "classe", "C", "+", "+", "e", "v\u00e1rias", "camadas", "de", "interface", "interpretadas", "incluindo", "Tcl/Tk", ",", "Java", ",", "e", "Python", "."], "sentence-detokenized": "VTK consiste numa biblioteca de classe C + + e v\u00e1rias camadas de interface interpretadas incluindo Tcl/Tk, Java, e Python.", "token2charspan": [[0, 3], [4, 12], [13, 17], [18, 28], [29, 31], [32, 38], [39, 40], [41, 42], [43, 44], [45, 46], [47, 53], [54, 61], [62, 64], [65, 74], [75, 88], [89, 98], [99, 105], [105, 106], [107, 111], [111, 112], [113, 114], [115, 121], [121, 122]]}
{"doc_key": "ai-test-320", "ner": [[13, 16, "task"], [25, 28, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Al\u00e9m", "disso", ",", "o", "texto", "produzido", "pelo", "processamento", "da", "fala", "espont\u00e2nea", "usando", "o", "reconhecimento", "autom\u00e1tico", "da", "fala", "e", "o", "texto", "impresso", "ou", "manuscrito", "usando", "o", "reconhecimento", "\u00f3ptico", "de", "caracteres", "cont\u00e9m", "ru\u00eddo", "de", "processamento", "."], "sentence-detokenized": "Al\u00e9m disso, o texto produzido pelo processamento da fala espont\u00e2nea usando o reconhecimento autom\u00e1tico da fala e o texto impresso ou manuscrito usando o reconhecimento \u00f3ptico de caracteres cont\u00e9m ru\u00eddo de processamento.", "token2charspan": [[0, 4], [5, 10], [10, 11], [12, 13], [14, 19], [20, 29], [30, 34], [35, 48], [49, 51], [52, 56], [57, 67], [68, 74], [75, 76], [77, 91], [92, 102], [103, 105], [106, 110], [111, 112], [113, 114], [115, 120], [121, 129], [130, 132], [133, 143], [144, 150], [151, 152], [153, 167], [168, 174], [175, 177], [178, 188], [189, 195], [196, 201], [202, 204], [205, 218], [218, 219]]}
{"doc_key": "ai-test-321", "ner": [[0, 0, "researcher"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 9, 9, "role", "directs_development_of", false, false]], "relations_mapping_to_source": [0], "sentence": ["Miller", "escreveu", "v\u00e1rios", "livros", "e", "dirigiu", "o", "desenvolvimento", "do", "WordNet", ",", "uma", "base", "de", "dados", "de", "liga\u00e7\u00e3o", "de", "palavras", "em", "linha", "utiliz\u00e1vel", "por", "programas", "de", "computador", "."], "sentence-detokenized": "Miller escreveu v\u00e1rios livros e dirigiu o desenvolvimento do WordNet, uma base de dados de liga\u00e7\u00e3o de palavras em linha utiliz\u00e1vel por programas de computador.", "token2charspan": [[0, 6], [7, 15], [16, 22], [23, 29], [30, 31], [32, 39], [40, 41], [42, 57], [58, 60], [61, 68], [68, 69], [70, 73], [74, 78], [79, 81], [82, 87], [88, 90], [91, 98], [99, 101], [102, 110], [111, 113], [114, 119], [120, 130], [131, 134], [135, 144], [145, 147], [148, 158], [158, 159]]}
{"doc_key": "ai-test-322", "ner": [[0, 1, "field"], [8, 10, "organisation"], [12, 13, "country"], [15, 16, "person"], [18, 20, "person"], [22, 23, "person"], [25, 26, "person"], [28, 29, "country"], [31, 34, "location"], [36, 37, "misc"], [38, 39, "person"], [42, 43, "person"], [45, 45, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 10, 12, 13, "physical", "", false, false], [15, 16, 28, 29, "physical", "", false, false], [18, 20, 28, 29, "physical", "", false, false], [22, 23, 28, 29, "physical", "", false, false], [25, 26, 28, 29, "physical", "", false, false], [31, 34, 0, 1, "general-affiliation", "", false, false], [31, 34, 38, 39, "artifact", "", false, false], [36, 37, 38, 39, "named", "", false, false], [42, 43, 45, 45, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Os", "aut\u00f3matos", "contempor\u00e2neos", "s\u00e3o", "representados", "pelas", "obras", "do", "Cabaret", "Mechanical", "Theatre", "no", "Reino", "Unido", ",", "Dug", "North", "e", "Chomick", "+", "Meder", ",", "Arthur", "Ganson", ",", "Joe", "Jones", "nos", "Estados", "Unidos", ",", "Le", "D\u00e9fenseur", "du", "Temps", "do", "artista", "franc\u00eas", "Jacques", "Monestier", ",", "e", "Fran\u00e7ois", "Junod", "na", "Su\u00ed\u00e7a", "."], "sentence-detokenized": "Os aut\u00f3matos contempor\u00e2neos s\u00e3o representados pelas obras do Cabaret Mechanical Theatre no Reino Unido, Dug North e Chomick + Meder, Arthur Ganson, Joe Jones nos Estados Unidos, Le D\u00e9fenseur du Temps do artista franc\u00eas Jacques Monestier, e Fran\u00e7ois Junod na Su\u00ed\u00e7a.", "token2charspan": [[0, 2], [3, 12], [13, 27], [28, 31], [32, 45], [46, 51], [52, 57], [58, 60], [61, 68], [69, 79], [80, 87], [88, 90], [91, 96], [97, 102], [102, 103], [104, 107], [108, 113], [114, 115], [116, 123], [124, 125], [126, 131], [131, 132], [133, 139], [140, 146], [146, 147], [148, 151], [152, 157], [158, 161], [162, 169], [170, 176], [176, 177], [178, 180], [181, 190], [191, 193], [194, 199], [200, 202], [203, 210], [211, 218], [219, 226], [227, 236], [236, 237], [238, 239], [240, 248], [249, 254], [255, 257], [258, 263], [263, 264]]}
{"doc_key": "ai-test-323", "ner": [[0, 1, "product"], [24, 24, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 24, 24, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["O", "MATLAB", "inclui", "c\u00f3digos", "padr\u00e3o", "antes", "/", "c\u00f3digo", "e", "codificados", "/", "loops", "de", "c\u00f3digo", ",", "mas", "(", "como", "em", "outras", "aplica\u00e7\u00f5es", "semelhantes", ",", "como", "R", ")", ",", "a", "utiliza\u00e7\u00e3o", "da", "nota\u00e7\u00e3o", "vectorizada", "\u00e9", "encorajada", "e", "\u00e9", "muitas", "vezes", "mais", "r\u00e1pida", "de", "executar", "."], "sentence-detokenized": "O MATLAB inclui c\u00f3digos padr\u00e3o antes / c\u00f3digo e codificados / loops de c\u00f3digo, mas (como em outras aplica\u00e7\u00f5es semelhantes, como R), a utiliza\u00e7\u00e3o da nota\u00e7\u00e3o vectorizada \u00e9 encorajada e \u00e9 muitas vezes mais r\u00e1pida de executar.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 23], [24, 30], [31, 36], [37, 38], [39, 45], [46, 47], [48, 59], [60, 61], [62, 67], [68, 70], [71, 77], [77, 78], [79, 82], [83, 84], [84, 88], [89, 91], [92, 98], [99, 109], [110, 121], [121, 122], [123, 127], [128, 129], [129, 130], [130, 131], [132, 133], [134, 144], [145, 147], [148, 155], [156, 167], [168, 169], [170, 180], [181, 182], [183, 184], [185, 191], [192, 197], [198, 202], [203, 209], [210, 212], [213, 221], [221, 222]]}
{"doc_key": "ai-test-324", "ner": [[0, 0, "researcher"], [5, 8, "conference"], [15, 16, "field"], [19, 25, "misc"], [28, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 19, 25, "win-defeat", "", false, false], [0, 0, 28, 37, "win-defeat", "", false, false], [19, 25, 5, 8, "temporal", "", false, false], [19, 25, 15, 16, "topic", "", false, false], [28, 37, 5, 8, "temporal", "", false, false], [28, 37, 15, 16, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pausch", "recebeu", "dois", "pr\u00e9mios", "da", "Association", "for", "Computing", "Machinery", "em", "2007", "pelas", "suas", "realiza\u00e7\u00f5es", "na", "educa\u00e7\u00e3o", "inform\u00e1tica", ":", "o", "Pr\u00e9mio", "Karl", "V.", "Karlstrom", "de", "Educador", "Destacado", "e", "o", "Pr\u00e9mio", "ACM", "SIGCSE", "por", "Contribui\u00e7\u00f5es", "Destacadas", "para", "a", "Educa\u00e7\u00e3o", "Inform\u00e1tica", "."], "sentence-detokenized": "Pausch recebeu dois pr\u00e9mios da Association for Computing Machinery em 2007 pelas suas realiza\u00e7\u00f5es na educa\u00e7\u00e3o inform\u00e1tica: o Pr\u00e9mio Karl V. Karlstrom de Educador Destacado e o Pr\u00e9mio ACM SIGCSE por Contribui\u00e7\u00f5es Destacadas para a Educa\u00e7\u00e3o Inform\u00e1tica.", "token2charspan": [[0, 6], [7, 14], [15, 19], [20, 27], [28, 30], [31, 42], [43, 46], [47, 56], [57, 66], [67, 69], [70, 74], [75, 80], [81, 85], [86, 97], [98, 100], [101, 109], [110, 121], [121, 122], [123, 124], [125, 131], [132, 136], [137, 139], [140, 149], [150, 152], [153, 161], [162, 171], [172, 173], [174, 175], [176, 182], [183, 186], [187, 193], [194, 197], [198, 211], [212, 222], [223, 227], [228, 229], [230, 238], [239, 250], [250, 251]]}
{"doc_key": "ai-test-325", "ner": [[3, 4, "person"], [10, 10, "product"], [9, 9, "product"], [19, 20, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 10, 10, "role", "sells", false, false], [10, 10, 9, 9, "general-affiliation", "", false, false], [10, 10, 19, 20, "physical", "shipped_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Em", "1960", ",", "a", "Devol", "vendeu", "pessoalmente", "o", "primeiro", "rob\u00f4", "Unimate", ",", "que", "foi", "enviado", "em", "1961", "para", "a", "General", "Motors", "."], "sentence-detokenized": "Em 1960, a Devol vendeu pessoalmente o primeiro rob\u00f4 Unimate, que foi enviado em 1961 para a General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 16], [17, 23], [24, 36], [37, 38], [39, 47], [48, 52], [53, 60], [60, 61], [62, 65], [66, 69], [70, 77], [78, 80], [81, 85], [86, 90], [91, 92], [93, 100], [101, 107], [107, 108]]}
{"doc_key": "ai-test-326", "ner": [[0, 2, "algorithm"], [8, 14, "field"], [15, 17, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 17, 0, 2, "usage", "", false, false], [15, 17, 8, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "redes", "sem\u00e2nticas", "s\u00e3o", "utilizadas", "em", "aplica\u00e7\u00f5es", "de", "processamento", "de", "linguagem", "natural", ",", "tais", "como", "a", "an\u00e1lise", "sem\u00e2ntica", "."], "sentence-detokenized": "As redes sem\u00e2nticas s\u00e3o utilizadas em aplica\u00e7\u00f5es de processamento de linguagem natural, tais como a an\u00e1lise sem\u00e2ntica.", "token2charspan": [[0, 2], [3, 8], [9, 19], [20, 23], [24, 34], [35, 37], [38, 48], [49, 51], [52, 65], [66, 68], [69, 78], [79, 86], [86, 87], [88, 92], [93, 97], [98, 99], [100, 107], [108, 117], [117, 118]]}
{"doc_key": "ai-test-327", "ner": [[5, 6, "field"], [9, 11, "field"], [14, 16, "task"], [18, 19, "researcher"], [21, 22, "researcher"], [24, 25, "researcher"], [27, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 11, 5, 6, "usage", "", false, false], [14, 16, 5, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Algumas", "aplica\u00e7\u00f5es", "bem", "sucedidas", "de", "aprendizagem", "profunda", "s\u00e3o", "a", "vis\u00e3o", "por", "computador", "e", "o", "reconhecimento", "da", "fala", ".", "Honglak", "Lee", ",", "Roger", "Grosse", ",", "Rajesh", "Ranganath", ",", "Andrew", "Y", ".", "Ng", "."], "sentence-detokenized": "Algumas aplica\u00e7\u00f5es bem sucedidas de aprendizagem profunda s\u00e3o a vis\u00e3o por computador e o reconhecimento da fala. Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng.", "token2charspan": [[0, 7], [8, 18], [19, 22], [23, 32], [33, 35], [36, 48], [49, 57], [58, 61], [62, 63], [64, 69], [70, 73], [74, 84], [85, 86], [87, 88], [89, 103], [104, 106], [107, 111], [111, 112], [113, 120], [121, 124], [124, 125], [126, 131], [132, 138], [138, 139], [140, 146], [147, 156], [156, 157], [158, 164], [165, 166], [166, 167], [168, 170], [170, 171]]}
{"doc_key": "ai-test-328", "ner": [[4, 9, "product"], [15, 15, "misc"], [18, 18, "misc"], [23, 23, "product"], [27, 29, "task"], [31, 33, "task"], [35, 36, "task"], [38, 41, "field"], [43, 44, "task"], [46, 48, "field"], [50, 51, "task"], [53, 54, "task"], [56, 59, "task"], [61, 63, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 9, 15, 15, "physical", "travels_to", false, false], [4, 9, 18, 18, "physical", "travels_to", false, false], [23, 23, 4, 9, "part-of", "", false, false], [23, 23, 4, 9, "role", "maintains", false, false], [23, 23, 27, 29, "related-to", "has_ability_to", false, false], [23, 23, 31, 33, "related-to", "has_ability_to", false, false], [23, 23, 35, 36, "related-to", "has_ability_to", false, false], [23, 23, 38, 41, "related-to", "has_ability_to", false, false], [23, 23, 43, 44, "related-to", "has_ability_to", false, false], [23, 23, 46, 48, "related-to", "has_ability_to", false, false], [23, 23, 50, 51, "related-to", "has_ability_to", false, false], [23, 23, 53, 54, "related-to", "has_ability_to", false, false], [23, 23, 56, 59, "related-to", "has_ability_to", false, false], [23, 23, 61, 63, "related-to", "has_ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Al\u00e9m", "de", "manter", "os", "sistemas", "da", "nave", "espacial", "Discovery", "One", "durante", "a", "miss\u00e3o", "interplanet\u00e1ria", "a", "J\u00fapiter", "(", "ou", "Saturno", "no", "romance", ")", ",", "HAL", "\u00e9", "capaz", "de", "s\u00edntese", "da", "fala", ",", "reconhecimento", "da", "fala", ",", "reconhecimento", "facial", ",", "processamento", "da", "linguagem", "natural", ",", "leitura", "labial", ",", "aprecia\u00e7\u00e3o", "da", "arte", ",", "computa\u00e7\u00e3o", "afectiva", ",", "racioc\u00ednio", "automatizado", ",", "pilotagem", "de", "naves", "espaciais", "e", "jogo", "de", "xadrez", "."], "sentence-detokenized": "Al\u00e9m de manter os sistemas da nave espacial Discovery One durante a miss\u00e3o interplanet\u00e1ria a J\u00fapiter (ou Saturno no romance), HAL \u00e9 capaz de s\u00edntese da fala, reconhecimento da fala, reconhecimento facial, processamento da linguagem natural, leitura labial, aprecia\u00e7\u00e3o da arte, computa\u00e7\u00e3o afectiva, racioc\u00ednio automatizado, pilotagem de naves espaciais e jogo de xadrez.", "token2charspan": [[0, 4], [5, 7], [8, 14], [15, 17], [18, 26], [27, 29], [30, 34], [35, 43], [44, 53], [54, 57], [58, 65], [66, 67], [68, 74], [75, 90], [91, 92], [93, 100], [101, 102], [102, 104], [105, 112], [113, 115], [116, 123], [123, 124], [124, 125], [126, 129], [130, 131], [132, 137], [138, 140], [141, 148], [149, 151], [152, 156], [156, 157], [158, 172], [173, 175], [176, 180], [180, 181], [182, 196], [197, 203], [203, 204], [205, 218], [219, 221], [222, 231], [232, 239], [239, 240], [241, 248], [249, 255], [255, 256], [257, 267], [268, 270], [271, 275], [275, 276], [277, 287], [288, 296], [296, 297], [298, 308], [309, 321], [321, 322], [323, 332], [333, 335], [336, 341], [342, 351], [352, 353], [354, 358], [359, 361], [362, 368], [368, 369]]}
{"doc_key": "ai-test-329", "ner": [[0, 3, "researcher"], [6, 6, "country"], [8, 11, "country"], [15, 16, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 6, 6, "physical", "", false, false], [0, 3, 8, 11, "physical", "", false, false], [0, 3, 15, 16, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["O", "Dr", ".", "Julesz", "emigrou", "da", "Hungria", "para", "os", "Estados", "Unidos", "na", "sequ\u00eancia", "da", "invas\u00e3o", "sovi\u00e9tica", "de", "1956", "."], "sentence-detokenized": "O Dr. Julesz emigrou da Hungria para os Estados Unidos na sequ\u00eancia da invas\u00e3o sovi\u00e9tica de 1956.", "token2charspan": [[0, 1], [2, 4], [4, 5], [6, 12], [13, 20], [21, 23], [24, 31], [32, 36], [37, 39], [40, 47], [48, 54], [55, 57], [58, 67], [68, 70], [71, 78], [79, 88], [89, 91], [92, 96], [96, 97]]}
{"doc_key": "ai-test-330", "ner": [[5, 6, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["As", "fun\u00e7\u00f5es", "de", "activa\u00e7\u00e3o", "da", "fun\u00e7\u00e3o", "Sigmoid", "utilizam", "uma", "segunda", "n\u00e3o-linearidade", "para", "grandes", "entradas", ":", "matem\u00e1tica", "phi", "(", "v", "_", "i", ")", "=", "(", "1", "+", "\\", "exp", "(", "-v", "_", "i", ")", ")", "^", "{", "-1", "}", "/", "matem\u00e1tica", "."], "sentence-detokenized": "As fun\u00e7\u00f5es de activa\u00e7\u00e3o da fun\u00e7\u00e3o Sigmoid utilizam uma segunda n\u00e3o-linearidade para grandes entradas: matem\u00e1tica phi (v _ i) = (1 +\\ exp (-v _ i)) ^ {-1} / matem\u00e1tica.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 23], [24, 26], [27, 33], [34, 41], [42, 50], [51, 54], [55, 62], [63, 78], [79, 83], [84, 91], [92, 100], [100, 101], [102, 112], [113, 116], [117, 118], [118, 119], [120, 121], [122, 123], [123, 124], [125, 126], [127, 128], [128, 129], [130, 131], [131, 132], [133, 136], [137, 138], [138, 140], [141, 142], [143, 144], [144, 145], [145, 146], [147, 148], [149, 150], [150, 152], [152, 153], [154, 155], [156, 166], [166, 167]]}
{"doc_key": "ai-test-331", "ner": [[14, 17, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Estas", "probabilidades", "s\u00e3o", "utilizadas", "para", "determinar", "qual", "o", "alvo", "que", "est\u00e1", "a", "utilizar", "uma", "decis\u00e3o", "de", "m\u00e1xima", "probabilidade", "."], "sentence-detokenized": "Estas probabilidades s\u00e3o utilizadas para determinar qual o alvo que est\u00e1 a utilizar uma decis\u00e3o de m\u00e1xima probabilidade.", "token2charspan": [[0, 5], [6, 20], [21, 24], [25, 35], [36, 40], [41, 51], [52, 56], [57, 58], [59, 63], [64, 67], [68, 72], [73, 74], [75, 83], [84, 87], [88, 95], [96, 98], [99, 105], [106, 119], [119, 120]]}
{"doc_key": "ai-test-332", "ner": [[5, 7, "university"], [13, 15, "university"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Em", "1984", "mudou-se", "para", "a", "Universidade", "de", "Konstanz", "e", "em", "1990", "para", "a", "Universidade", "de", "Salzburgo", "."], "sentence-detokenized": "Em 1984 mudou-se para a Universidade de Konstanz e em 1990 para a Universidade de Salzburgo.", "token2charspan": [[0, 2], [3, 7], [8, 16], [17, 21], [22, 23], [24, 36], [37, 39], [40, 48], [49, 50], [51, 53], [54, 58], [59, 63], [64, 65], [66, 78], [79, 81], [82, 91], [91, 92]]}
{"doc_key": "ai-test-333", "ner": [[7, 9, "metrics"], [11, 13, "metrics"], [15, 17, "metrics"], [19, 20, "metrics"], [22, 23, "metrics"], [25, 28, "metrics"], [31, 35, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 13, 7, 9, "origin", "based_on", false, false], [15, 17, 7, 9, "origin", "based_on", false, false], [19, 20, 7, 9, "origin", "based_on", false, false], [22, 23, 7, 9, "origin", "based_on", false, false], [25, 28, 7, 9, "origin", "based_on", false, false], [31, 35, 7, 9, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Algumas", "fun\u00e7\u00f5es", "populares", "de", "aptid\u00e3o", "baseadas", "na", "matriz", "de", "confus\u00e3o", "incluem", "sensibilidade", "/", "especificidade", ",", "recorda\u00e7\u00e3o", "/", "precis\u00e3o", ",", "medida", "F", ",", "semelhan\u00e7a", "Jaccard", ",", "coeficiente", "de", "correla\u00e7\u00e3o", "Matthews", ",", "e", "matriz", "de", "custo", "/", "ganho", "que", "combina", "os", "custos", "e", "ganhos", "atribu\u00eddos", "aos", "4", "tipos", "diferentes", "de", "classifica\u00e7\u00f5es", "."], "sentence-detokenized": "Algumas fun\u00e7\u00f5es populares de aptid\u00e3o baseadas na matriz de confus\u00e3o incluem sensibilidade / especificidade, recorda\u00e7\u00e3o / precis\u00e3o, medida F, semelhan\u00e7a Jaccard, coeficiente de correla\u00e7\u00e3o Matthews, e matriz de custo / ganho que combina os custos e ganhos atribu\u00eddos aos 4 tipos diferentes de classifica\u00e7\u00f5es.", "token2charspan": [[0, 7], [8, 15], [16, 25], [26, 28], [29, 36], [37, 45], [46, 48], [49, 55], [56, 58], [59, 67], [68, 75], [76, 89], [90, 91], [92, 106], [106, 107], [108, 118], [119, 120], [121, 129], [129, 130], [131, 137], [138, 139], [139, 140], [141, 151], [152, 159], [159, 160], [161, 172], [173, 175], [176, 186], [187, 195], [195, 196], [197, 198], [199, 205], [206, 208], [209, 214], [215, 216], [217, 222], [223, 226], [227, 234], [235, 237], [238, 244], [245, 246], [247, 253], [254, 264], [265, 268], [269, 270], [271, 276], [277, 287], [288, 290], [291, 305], [305, 306]]}
{"doc_key": "ai-test-334", "ner": [[8, 8, "product"], [10, 10, "product"], [12, 12, "product"], [14, 14, "product"], [17, 18, "programlang"], [33, 36, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[33, 36, 8, 8, "part-of", "", false, false], [33, 36, 10, 10, "part-of", "", false, false], [33, 36, 12, 12, "part-of", "", false, false], [33, 36, 14, 14, "part-of", "", false, false], [33, 36, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Ambientes", "de", "programa\u00e7\u00e3o", "num\u00e9rica", "comuns", ",", "tais", "como", "MATLAB", ",", "SciLab", ",", "NumPy", ",", "Sklearn", "e", "a", "linguagem", "R", "fornecem", "algumas", "das", "t\u00e9cnicas", "mais", "simples", "de", "extrac\u00e7\u00e3o", "de", "caracter\u00edsticas", "(", "por", "exemplo", ",", "an\u00e1lise", "de", "componentes", "principais", ")", "atrav\u00e9s", "de", "comandos", "incorporados", "."], "sentence-detokenized": "Ambientes de programa\u00e7\u00e3o num\u00e9rica comuns, tais como MATLAB, SciLab, NumPy, Sklearn e a linguagem R fornecem algumas das t\u00e9cnicas mais simples de extrac\u00e7\u00e3o de caracter\u00edsticas (por exemplo, an\u00e1lise de componentes principais) atrav\u00e9s de comandos incorporados.", "token2charspan": [[0, 9], [10, 12], [13, 24], [25, 33], [34, 40], [40, 41], [42, 46], [47, 51], [52, 58], [58, 59], [60, 66], [66, 67], [68, 73], [73, 74], [75, 82], [83, 84], [85, 86], [87, 96], [97, 98], [99, 107], [108, 115], [116, 119], [120, 128], [129, 133], [134, 141], [142, 144], [145, 154], [155, 157], [158, 173], [174, 175], [175, 178], [179, 186], [186, 187], [188, 195], [196, 198], [199, 210], [211, 221], [221, 222], [223, 230], [231, 233], [234, 242], [243, 255], [255, 256]]}
{"doc_key": "ai-test-335", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Rob\u00f4s", "industriais", "t\u00eam", "sido", "implementados", "para", "colaborar", "com", "seres", "humanos", "na", "execu\u00e7\u00e3o", "de", "tarefas", "de", "fabrico", "industrial", "."], "sentence-detokenized": "Rob\u00f4s industriais t\u00eam sido implementados para colaborar com seres humanos na execu\u00e7\u00e3o de tarefas de fabrico industrial.", "token2charspan": [[0, 5], [6, 17], [18, 21], [22, 26], [27, 40], [41, 45], [46, 55], [56, 59], [60, 65], [66, 73], [74, 76], [77, 85], [86, 88], [89, 96], [97, 99], [100, 107], [108, 118], [118, 119]]}
{"doc_key": "ai-test-336", "ner": [[5, 5, "field"], [7, 9, "researcher"], [18, 19, "field"], [21, 23, "field"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 5, 18, 19, "related-to", "", false, false], [5, 5, 21, 23, "related-to", "", false, false], [5, 5, 25, 26, "related-to", "", false, false], [7, 9, 5, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["No", "primeiro", "artigo", "publicado", "sobre", "GC", ",", "John", "F.", "Sowa", "aplicou-os", "a", "uma", "vasta", "gama", "de", "t\u00f3picos", "em", "intelig\u00eancia", "artificial", ",", "ci\u00eancia", "da", "computa\u00e7\u00e3o", "e", "ci\u00eancia", "cognitiva", "."], "sentence-detokenized": "No primeiro artigo publicado sobre GC, John F. Sowa aplicou-os a uma vasta gama de t\u00f3picos em intelig\u00eancia artificial, ci\u00eancia da computa\u00e7\u00e3o e ci\u00eancia cognitiva.", "token2charspan": [[0, 2], [3, 11], [12, 18], [19, 28], [29, 34], [35, 37], [37, 38], [39, 43], [44, 46], [47, 51], [52, 62], [63, 64], [65, 68], [69, 74], [75, 79], [80, 82], [83, 90], [91, 93], [94, 106], [107, 117], [117, 118], [119, 126], [127, 129], [130, 140], [141, 142], [143, 150], [151, 160], [160, 161]]}
{"doc_key": "ai-test-337", "ner": [[0, 1, "metrics"], [5, 5, "metrics"], [10, 12, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 5, 5, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["O", "NIST", "tamb\u00e9m", "difere", "do", "BLEU", "no", "seu", "c\u00e1lculo", "da", "penalidade", "de", "brevidade", ",", "na", "medida", "em", "que", "pequenas", "varia\u00e7\u00f5es", "no", "comprimento", "de", "tradu\u00e7\u00e3o", "n\u00e3o", "t\u00eam", "tanto", "impacto", "na", "pontua\u00e7\u00e3o", "global", "."], "sentence-detokenized": "O NIST tamb\u00e9m difere do BLEU no seu c\u00e1lculo da penalidade de brevidade, na medida em que pequenas varia\u00e7\u00f5es no comprimento de tradu\u00e7\u00e3o n\u00e3o t\u00eam tanto impacto na pontua\u00e7\u00e3o global.", "token2charspan": [[0, 1], [2, 6], [7, 13], [14, 20], [21, 23], [24, 28], [29, 31], [32, 35], [36, 43], [44, 46], [47, 57], [58, 60], [61, 70], [70, 71], [72, 74], [75, 81], [82, 84], [85, 88], [89, 97], [98, 107], [108, 110], [111, 122], [123, 125], [126, 134], [135, 138], [139, 142], [143, 148], [149, 156], [157, 159], [160, 169], [170, 176], [176, 177]]}
{"doc_key": "ai-test-338", "ner": [[1, 6, "misc"], [14, 14, "conference"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 6, 14, 14, "temporal", "", false, false], [1, 6, 18, 19, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["O", "Pr\u00e9mio", "IJCAI", "de", "Excel\u00eancia", "em", "Investiga\u00e7\u00e3o", "\u00e9", "um", "pr\u00e9mio", "bianual", "atribu\u00eddo", "na", "confer\u00eancia", "IJCAI", "ao", "investigador", "em", "intelig\u00eancia", "artificial", "como", "reconhecimento", "da", "excel\u00eancia", "da", "sua", "carreira", "."], "sentence-detokenized": "O Pr\u00e9mio IJCAI de Excel\u00eancia em Investiga\u00e7\u00e3o \u00e9 um pr\u00e9mio bianual atribu\u00eddo na confer\u00eancia IJCAI ao investigador em intelig\u00eancia artificial como reconhecimento da excel\u00eancia da sua carreira.", "token2charspan": [[0, 1], [2, 8], [9, 14], [15, 17], [18, 28], [29, 31], [32, 44], [45, 46], [47, 49], [50, 56], [57, 64], [65, 74], [75, 77], [78, 89], [90, 95], [96, 98], [99, 111], [112, 114], [115, 127], [128, 138], [139, 143], [144, 158], [159, 161], [162, 172], [173, 175], [176, 179], [180, 188], [188, 189]]}
{"doc_key": "ai-test-339", "ner": [[0, 0, "researcher"], [7, 7, "conference"], [17, 25, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 7, 7, "role", "", false, false], [0, 0, 17, 25, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lenat", "foi", "um", "dos", "Fellows", "originais", "da", "AAAI", ",", "e", "\u00e9", "o", "\u00fanico", "indiv\u00edduo", "a", "ter", "nos", "Conselhos", "Consultivos", "Cient\u00edficos", "tanto", "da", "Microsoft", "como", "da", "Apple", "."], "sentence-detokenized": "Lenat foi um dos Fellows originais da AAAI, e \u00e9 o \u00fanico indiv\u00edduo a ter nos Conselhos Consultivos Cient\u00edficos tanto da Microsoft como da Apple.", "token2charspan": [[0, 5], [6, 9], [10, 12], [13, 16], [17, 24], [25, 34], [35, 37], [38, 42], [42, 43], [44, 45], [46, 47], [48, 49], [50, 55], [56, 65], [66, 67], [68, 71], [72, 75], [76, 85], [86, 97], [98, 109], [110, 115], [116, 118], [119, 128], [129, 133], [134, 136], [137, 142], [142, 143]]}
{"doc_key": "ai-test-340", "ner": [[0, 1, "algorithm"], [7, 9, "misc"], [13, 16, "metrics"], [23, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 7, 9, "related-to", "minimise", false, false], [13, 16, 7, 9, "type-of", "", false, false], [23, 23, 7, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Os", "auto-encoders", "s\u00e3o", "treinados", "para", "minimizar", "os", "erros", "de", "reconstru\u00e7\u00e3o", "(", "como", "o", "erro", "m\u00e9dio", "ao", "quadrado", ")", ",", "frequentemente", "referido", "como", "a", "perda", ":"], "sentence-detokenized": "Os auto-encoders s\u00e3o treinados para minimizar os erros de reconstru\u00e7\u00e3o (como o erro m\u00e9dio ao quadrado), frequentemente referido como a perda:", "token2charspan": [[0, 2], [3, 16], [17, 20], [21, 30], [31, 35], [36, 45], [46, 48], [49, 54], [55, 57], [58, 70], [71, 72], [72, 76], [77, 78], [79, 83], [84, 89], [90, 92], [93, 101], [101, 102], [102, 103], [104, 118], [119, 127], [128, 132], [133, 134], [135, 140], [140, 141]]}
{"doc_key": "ai-test-341", "ner": [[30, 33, "misc"], [37, 37, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[37, 37, 30, 33, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Uma", "alternativa", "\u00e0", "utiliza\u00e7\u00e3o", "das", "defini\u00e7\u00f5es", "\u00e9", "considerar", "a", "rela\u00e7\u00e3o", "geral", "entre", "palavra", "e", "sentido", "e", "calcular", "a", "similaridade", "de", "cada", "par", "de", "sentidos", "de", "palavra", "com", "base", "numa", "dada", "base", "de", "conhecimentos", "lexicais", ",", "como", "a", "WordNet", "."], "sentence-detokenized": "Uma alternativa \u00e0 utiliza\u00e7\u00e3o das defini\u00e7\u00f5es \u00e9 considerar a rela\u00e7\u00e3o geral entre palavra e sentido e calcular a similaridade de cada par de sentidos de palavra com base numa dada base de conhecimentos lexicais, como a WordNet.", "token2charspan": [[0, 3], [4, 15], [16, 17], [18, 28], [29, 32], [33, 43], [44, 45], [46, 56], [57, 58], [59, 66], [67, 72], [73, 78], [79, 86], [87, 88], [89, 96], [97, 98], [99, 107], [108, 109], [110, 122], [123, 125], [126, 130], [131, 134], [135, 137], [138, 146], [147, 149], [150, 157], [158, 161], [162, 166], [167, 171], [172, 176], [177, 181], [182, 184], [185, 198], [199, 207], [207, 208], [209, 213], [214, 215], [216, 223], [223, 224]]}
{"doc_key": "ai-test-342", "ner": [[0, 0, "algorithm"], [8, 10, "researcher"], [22, 23, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 10, "origin", "", false, false], [8, 10, 22, 23, "role", "work_based_on_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["TD-Lambda", "\u00e9", "um", "algoritmo", "de", "aprendizagem", "inventado", "por", "Richard", "S.", "Sutton", "com", "base", "em", "trabalho", "anterior", "sobre", "aprendizagem", "por", "diferen\u00e7as", "temporais", "de", "Arthur", "Samuel", "."], "sentence-detokenized": "TD-Lambda \u00e9 um algoritmo de aprendizagem inventado por Richard S. Sutton com base em trabalho anterior sobre aprendizagem por diferen\u00e7as temporais de Arthur Samuel.", "token2charspan": [[0, 9], [10, 11], [12, 14], [15, 24], [25, 27], [28, 40], [41, 50], [51, 54], [55, 62], [63, 65], [66, 72], [73, 76], [77, 81], [82, 84], [85, 93], [94, 102], [103, 108], [109, 121], [122, 125], [126, 136], [137, 146], [147, 149], [150, 156], [157, 163], [163, 164]]}
{"doc_key": "ai-test-343", "ner": [[1, 3, "field"], [5, 5, "field"], [8, 9, "task"], [13, 16, "task"], [18, 18, "task"], [24, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 1, 3, "part-of", "task_part_of_field", false, false], [8, 9, 5, 5, "part-of", "task_part_of_field", false, false], [13, 16, 8, 9, "named", "", false, false], [18, 18, 8, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Em", "minera\u00e7\u00e3o", "de", "dados", "e", "estat\u00edstica", ",", "a", "agrega\u00e7\u00e3o", "hier\u00e1rquica", "(", "tamb\u00e9m", "chamada", "an\u00e1lise", "hier\u00e1rquica", "de", "agregados", "ou", "HCA", ")", "\u00e9", "um", "m\u00e9todo", "de", "an\u00e1lise", "de", "agregados", "que", "procura", "construir", "uma", "hierarquia", "de", "agregados", "."], "sentence-detokenized": "Em minera\u00e7\u00e3o de dados e estat\u00edstica, a agrega\u00e7\u00e3o hier\u00e1rquica (tamb\u00e9m chamada an\u00e1lise hier\u00e1rquica de agregados ou HCA) \u00e9 um m\u00e9todo de an\u00e1lise de agregados que procura construir uma hierarquia de agregados.", "token2charspan": [[0, 2], [3, 12], [13, 15], [16, 21], [22, 23], [24, 35], [35, 36], [37, 38], [39, 48], [49, 60], [61, 62], [62, 68], [69, 76], [77, 84], [85, 96], [97, 99], [100, 109], [110, 112], [113, 116], [116, 117], [118, 119], [120, 122], [123, 129], [130, 132], [133, 140], [141, 143], [144, 153], [154, 157], [158, 165], [166, 175], [176, 179], [180, 190], [191, 193], [194, 203], [203, 204]]}
{"doc_key": "ai-test-344", "ner": [[3, 3, "algorithm"], [10, 12, "field"], [14, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 10, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["O", "conceito", "de", "deconvolu\u00e7\u00e3o", "\u00e9", "amplamente", "utilizado", "nas", "t\u00e9cnicas", "de", "processamento", "de", "sinais", "e", "processamento", "de", "imagem", "."], "sentence-detokenized": "O conceito de deconvolu\u00e7\u00e3o \u00e9 amplamente utilizado nas t\u00e9cnicas de processamento de sinais e processamento de imagem.", "token2charspan": [[0, 1], [2, 10], [11, 13], [14, 26], [27, 28], [29, 39], [40, 49], [50, 53], [54, 62], [63, 65], [66, 79], [80, 82], [83, 89], [90, 91], [92, 105], [106, 108], [109, 115], [115, 116]]}
{"doc_key": "ai-test-345", "ner": [[0, 2, "algorithm"], [24, 25, "misc"], [29, 29, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 24, 25, "related-to", "enhances", false, false], [0, 2, 24, 25, "related-to", "reduces", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Os", "mapas", "cognitivos", "servem", "a", "constru\u00e7\u00e3o", "e", "acumula\u00e7\u00e3o", "de", "conhecimento", "espacial", ",", "permitindo", "ao", "olho", "da", "mente", "visualizar", "imagens", "a", "fim", "de", "reduzir", "a", "carga", "cognitiva", ",", "melhorar", "a", "recorda\u00e7\u00e3o", "e", "a", "aprendizagem", "da", "informa\u00e7\u00e3o", "."], "sentence-detokenized": "Os mapas cognitivos servem a constru\u00e7\u00e3o e acumula\u00e7\u00e3o de conhecimento espacial, permitindo ao olho da mente visualizar imagens a fim de reduzir a carga cognitiva, melhorar a recorda\u00e7\u00e3o e a aprendizagem da informa\u00e7\u00e3o.", "token2charspan": [[0, 2], [3, 8], [9, 19], [20, 26], [27, 28], [29, 39], [40, 41], [42, 52], [53, 55], [56, 68], [69, 77], [77, 78], [79, 89], [90, 92], [93, 97], [98, 100], [101, 106], [107, 117], [118, 125], [126, 127], [128, 131], [132, 134], [135, 142], [143, 144], [145, 150], [151, 160], [160, 161], [162, 170], [171, 172], [173, 183], [184, 185], [186, 187], [188, 200], [201, 203], [204, 214], [214, 215]]}
{"doc_key": "ai-test-346", "ner": [[1, 1, "programlang"], [3, 5, "programlang"], [7, 7, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["(", "Python", ",", "C", "+", "+", ",", "Java", ")", "."], "sentence-detokenized": "(Python, C + +, Java).", "token2charspan": [[0, 1], [1, 7], [7, 8], [9, 10], [11, 12], [13, 14], [14, 15], [16, 20], [20, 21], [21, 22]]}
{"doc_key": "ai-test-347", "ner": [[1, 2, "product"], [4, 4, "product"], [17, 19, "task"], [25, 27, "task"], [31, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 17, 19, "usage", "", false, false], [1, 2, 25, 27, "usage", "", false, false], [1, 2, 31, 34, "usage", "", false, false], [4, 4, 1, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Uma", "interface", "voz-utilizador", "(", "VUI", ")", "torna", "poss\u00edvel", "a", "interac\u00e7\u00e3o", "humana", "falada", "com", "computadores", ",", "utilizando", "o", "reconhecimento", "da", "fala", "para", "compreender", "comandos", "falados", "e", "respostas", "a", "perguntas", ",", "e", "tipicamente", "texto", "para", "a", "fala", "para", "reproduzir", "uma", "resposta", "."], "sentence-detokenized": "Uma interface voz-utilizador (VUI) torna poss\u00edvel a interac\u00e7\u00e3o humana falada com computadores, utilizando o reconhecimento da fala para compreender comandos falados e respostas a perguntas, e tipicamente texto para a fala para reproduzir uma resposta.", "token2charspan": [[0, 3], [4, 13], [14, 28], [29, 30], [30, 33], [33, 34], [35, 40], [41, 49], [50, 51], [52, 62], [63, 69], [70, 76], [77, 80], [81, 93], [93, 94], [95, 105], [106, 107], [108, 122], [123, 125], [126, 130], [131, 135], [136, 147], [148, 156], [157, 164], [165, 166], [167, 176], [177, 178], [179, 188], [188, 189], [190, 191], [192, 203], [204, 209], [210, 214], [215, 216], [217, 221], [222, 226], [227, 237], [238, 241], [242, 250], [250, 251]]}
{"doc_key": "ai-test-348", "ner": [[0, 0, "programlang"], [3, 5, "misc"], [9, 9, "programlang"], [14, 15, "researcher"], [17, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 5, "general-affiliation", "is_a", false, false], [0, 0, 9, 9, "general-affiliation", "made_with", false, false], [0, 0, 14, 15, "origin", "", false, false], [14, 15, 17, 18, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Jess", "\u00e9", "um", "motor", "de", "regras", "para", "a", "plataforma", "Java", "que", "foi", "desenvolvido", "por", "Ernest", "Friedman-Hill", "of", "Sandia", "National", "."], "sentence-detokenized": "Jess \u00e9 um motor de regras para a plataforma Java que foi desenvolvido por Ernest Friedman-Hill of Sandia National.", "token2charspan": [[0, 4], [5, 6], [7, 9], [10, 15], [16, 18], [19, 25], [26, 30], [31, 32], [33, 43], [44, 48], [49, 52], [53, 56], [57, 69], [70, 73], [74, 80], [81, 94], [95, 97], [98, 104], [105, 113], [113, 114]]}
{"doc_key": "ai-test-349", "ner": [[1, 2, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 19, 20, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Para", "perceptrons", "multicamadas", ",", "onde", "existe", "uma", "camada", "oculta", ",", "devem", "ser", "utilizados", "algoritmos", "mais", "sofisticados", ",", "tais", "como", "a", "retropropaga\u00e7\u00e3o", "."], "sentence-detokenized": "Para perceptrons multicamadas, onde existe uma camada oculta, devem ser utilizados algoritmos mais sofisticados, tais como a retropropaga\u00e7\u00e3o.", "token2charspan": [[0, 4], [5, 16], [17, 29], [29, 30], [31, 35], [36, 42], [43, 46], [47, 53], [54, 60], [60, 61], [62, 67], [68, 71], [72, 82], [83, 93], [94, 98], [99, 111], [111, 112], [113, 117], [118, 122], [123, 124], [125, 140], [140, 141]]}
{"doc_key": "ai-test-350", "ner": [[7, 8, "product"], [1, 5, "product"], [12, 18, "algorithm"], [23, 24, "field"], [29, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 5, 7, 8, "part-of", "", false, false], [1, 5, 12, 18, "usage", "", false, true], [12, 18, 23, 24, "related-to", "performs", false, false], [29, 34, 23, 24, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["O", "sistema", "de", "tradu\u00e7\u00e3o", "autom\u00e1tica", "neural", "da", "Google", "Translate", "utiliza", "uma", "grande", "rede", "neural", "artificial", "de", "ponta", "a", "ponta", "que", "tenta", "realizar", "uma", "aprendizagem", "profunda", ",", "em", "particular", ",", "redes", "de", "mem\u00f3ria", "de", "longo", "prazo", "."], "sentence-detokenized": "O sistema de tradu\u00e7\u00e3o autom\u00e1tica neural da Google Translate utiliza uma grande rede neural artificial de ponta a ponta que tenta realizar uma aprendizagem profunda, em particular, redes de mem\u00f3ria de longo prazo.", "token2charspan": [[0, 1], [2, 9], [10, 12], [13, 21], [22, 32], [33, 39], [40, 42], [43, 49], [50, 59], [60, 67], [68, 71], [72, 78], [79, 83], [84, 90], [91, 101], [102, 104], [105, 110], [111, 112], [113, 118], [119, 122], [123, 128], [129, 137], [138, 141], [142, 154], [155, 163], [163, 164], [165, 167], [168, 178], [178, 179], [180, 185], [186, 188], [189, 196], [197, 199], [200, 205], [206, 211], [211, 212]]}
{"doc_key": "ai-test-351", "ner": [[16, 16, "researcher"], [18, 18, "researcher"], [20, 20, "researcher"], [22, 23, "researcher"], [25, 26, "researcher"], [28, 28, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["V\u00e1rios", "m\u00e9todos", "para", "o", "fazer", "foram", "desenvolvidos", "nos", "anos", "80", "e", "in\u00edcio", "dos", "anos", "90", "por", "Werbos", ",", "Williams", ",", "Robinson", ",", "J\u00fcrgen", "Schmidhuber", ",", "Sepp", "Hochreiter", ",", "Pearlmutter", "e", "outros", "."], "sentence-detokenized": "V\u00e1rios m\u00e9todos para o fazer foram desenvolvidos nos anos 80 e in\u00edcio dos anos 90 por Werbos, Williams, Robinson, J\u00fcrgen Schmidhuber, Sepp Hochreiter, Pearlmutter e outros.", "token2charspan": [[0, 6], [7, 14], [15, 19], [20, 21], [22, 27], [28, 33], [34, 47], [48, 51], [52, 56], [57, 59], [60, 61], [62, 68], [69, 72], [73, 77], [78, 80], [81, 84], [85, 91], [91, 92], [93, 101], [101, 102], [103, 111], [111, 112], [113, 119], [120, 131], [131, 132], [133, 137], [138, 148], [148, 149], [150, 161], [162, 163], [164, 170], [170, 171]]}
{"doc_key": "ai-test-352", "ner": [[1, 1, "organisation"], [2, 3, "organisation"], [8, 8, "organisation"], [13, 15, "task"], [20, 20, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 8, 8, "role", "licenses_from", false, false], [2, 3, 1, 1, "named", "", false, false], [20, 20, 1, 1, "origin", "", false, false], [20, 20, 13, 15, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["|", "Apple", "Apple", "Inc", "software", "originalmente", "licenciado", "pela", "Nuance", "para", "fornecer", "capacidade", "de", "reconhecimento", "da", "fala", "ao", "seu", "assistente", "digital", "Siri", "."], "sentence-detokenized": "| Apple Apple Inc software originalmente licenciado pela Nuance para fornecer capacidade de reconhecimento da fala ao seu assistente digital Siri.", "token2charspan": [[0, 1], [2, 7], [8, 13], [14, 17], [18, 26], [27, 40], [41, 51], [52, 56], [57, 63], [64, 68], [69, 77], [78, 88], [89, 91], [92, 106], [107, 109], [110, 114], [115, 117], [118, 121], [122, 132], [133, 140], [141, 145], [145, 146]]}
{"doc_key": "ai-test-353", "ner": [[0, 1, "organisation"], [4, 5, "misc"], [8, 9, "person"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 5, "role", "releases_movies_in_genre", false, false], [8, 9, 0, 1, "role", "directs_for", false, false], [13, 14, 0, 1, "role", "directs_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "Columbia", "lan\u00e7ou", "v\u00e1rios", "westerns", "3D", "produzidos", "por", "Sam", "Katzman", "e", "dirigidos", "por", "William", "Castle", "."], "sentence-detokenized": "A Columbia lan\u00e7ou v\u00e1rios westerns 3D produzidos por Sam Katzman e dirigidos por William Castle.", "token2charspan": [[0, 1], [2, 10], [11, 17], [18, 24], [25, 33], [34, 36], [37, 47], [48, 51], [52, 55], [56, 63], [64, 65], [66, 75], [76, 79], [80, 87], [88, 94], [94, 95]]}
{"doc_key": "ai-test-354", "ner": [[7, 7, "field"], [9, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Incorpora", "conhecimentos", "e", "investiga\u00e7\u00e3o", "nas", "\u00e1reas", "da", "inform\u00e1tica", ",", "lingu\u00edstica", "e", "engenharia", "inform\u00e1tica", "."], "sentence-detokenized": "Incorpora conhecimentos e investiga\u00e7\u00e3o nas \u00e1reas da inform\u00e1tica, lingu\u00edstica e engenharia inform\u00e1tica.", "token2charspan": [[0, 9], [10, 23], [24, 25], [26, 38], [39, 42], [43, 48], [49, 51], [52, 63], [63, 64], [65, 76], [77, 78], [79, 89], [90, 101], [101, 102]]}
{"doc_key": "ai-test-355", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Aqui", "est\u00e1", "um", "exemplo", "de", "c\u00f3digo", "R", ":"], "sentence-detokenized": "Aqui est\u00e1 um exemplo de c\u00f3digo R:", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 20], [21, 23], [24, 30], [31, 32], [32, 33]]}
{"doc_key": "ai-test-356", "ner": [[1, 2, "metrics"], [7, 9, "metrics"], [11, 11, "metrics"], [15, 17, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 7, 9, "part-of", "plotted_into", false, false], [1, 2, 15, 17, "part-of", "plotted_into", false, false], [11, 11, 7, 9, "named", "", false, false], [19, 19, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "curva", "ROC", "\u00e9", "criada", "tra\u00e7ando", "a", "TRUE", "positive", "rate", "(", "TPR", ")", "contra", "a", "FALSE", "positive", "rate", "(", "FPR", ")", "em", "v\u00e1rias", "defini\u00e7\u00f5es", "de", "limiar", "."], "sentence-detokenized": "A curva ROC \u00e9 criada tra\u00e7ando a TRUE positive rate (TPR) contra a FALSE positive rate (FPR) em v\u00e1rias defini\u00e7\u00f5es de limiar.", "token2charspan": [[0, 1], [2, 7], [8, 11], [12, 13], [14, 20], [21, 29], [30, 31], [32, 36], [37, 45], [46, 50], [51, 52], [52, 55], [55, 56], [57, 63], [64, 65], [66, 71], [72, 80], [81, 85], [86, 87], [87, 90], [90, 91], [92, 94], [95, 101], [102, 112], [113, 115], [116, 122], [122, 123]]}
{"doc_key": "ai-test-357", "ner": [[5, 6, "field"], [8, 9, "researcher"], [11, 12, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 5, 6, "related-to", "researches_field", false, false], [11, 12, 5, 6, "related-to", "researches_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Investiga\u00e7\u00e3o", "estagnada", "ap\u00f3s", "pesquisa", "de", "aprendizagem", "mec\u00e2nica", "por", "Marvin", "Minsky", "e", "Seymour", "Papert", "(", "1969", ")", ","], "sentence-detokenized": "Investiga\u00e7\u00e3o estagnada ap\u00f3s pesquisa de aprendizagem mec\u00e2nica por Marvin Minsky e Seymour Papert (1969),", "token2charspan": [[0, 12], [13, 22], [23, 27], [28, 36], [37, 39], [40, 52], [53, 61], [62, 65], [66, 72], [73, 79], [80, 81], [82, 89], [90, 96], [97, 98], [98, 102], [102, 103], [103, 104]]}
{"doc_key": "ai-test-358", "ner": [[10, 10, "task"], [12, 14, "programlang"], [16, 19, "product"], [21, 22, "programlang"], [24, 24, "product"], [27, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 10, 12, 14, "related-to", "used_to_build", false, false], [10, 10, 16, 19, "related-to", "used_to_build", false, false], [10, 10, 21, 22, "related-to", "used_to_build", false, false], [10, 10, 24, 24, "related-to", "used_to_build", false, false], [10, 10, 27, 27, "related-to", "used_to_build", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Outros", "ambientes", "de", "programa\u00e7\u00e3o", "que", "s\u00e3o", "usados", "para", "construir", "aplica\u00e7\u00f5es", "DAQ", "incluem", "l\u00f3gica", "de", "escada", ",", "Visual", "C", "+", "+", ",", "Visual", "Basic", ",", "LabVIEW", ",", "e", "MATLAB", "."], "sentence-detokenized": "Outros ambientes de programa\u00e7\u00e3o que s\u00e3o usados para construir aplica\u00e7\u00f5es DAQ incluem l\u00f3gica de escada, Visual C + +, Visual Basic, LabVIEW, e MATLAB.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 31], [32, 35], [36, 39], [40, 46], [47, 51], [52, 61], [62, 72], [73, 76], [77, 84], [85, 91], [92, 94], [95, 101], [101, 102], [103, 109], [110, 111], [112, 113], [114, 115], [115, 116], [117, 123], [124, 129], [129, 130], [131, 138], [138, 139], [140, 141], [142, 148], [148, 149]]}
{"doc_key": "ai-test-359", "ner": [[11, 14, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "m\u00e9trica", "foi", "concebida", "para", "corrigir", "alguns", "dos", "problemas", "encontrados", "na", "m\u00e9trica", "mais", "popular", "BLEU", ",", "e", "tamb\u00e9m", "produzir", "uma", "boa", "correla\u00e7\u00e3o", "com", "o", "julgamento", "humano", "ao", "n\u00edvel", "da", "senten\u00e7a", "ou", "segmento", "."], "sentence-detokenized": "A m\u00e9trica foi concebida para corrigir alguns dos problemas encontrados na m\u00e9trica mais popular BLEU, e tamb\u00e9m produzir uma boa correla\u00e7\u00e3o com o julgamento humano ao n\u00edvel da senten\u00e7a ou segmento.", "token2charspan": [[0, 1], [2, 9], [10, 13], [14, 23], [24, 28], [29, 37], [38, 44], [45, 48], [49, 58], [59, 70], [71, 73], [74, 81], [82, 86], [87, 94], [95, 99], [99, 100], [101, 102], [103, 109], [110, 118], [119, 122], [123, 126], [127, 137], [138, 141], [142, 143], [144, 154], [155, 161], [162, 164], [165, 170], [171, 173], [174, 182], [183, 185], [186, 194], [194, 195]]}
{"doc_key": "ai-test-360", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["T\u00e9cnicas", "como", "as", "Redes", "Markov", "din\u00e2micas", ",", "Rede", "neural", "Convolutiva", "e", "Mem\u00f3ria", "de", "longo", "prazo", "s\u00e3o", "frequentemente", "utilizadas", "para", "explorar", "as", "correla\u00e7\u00f5es", "sem\u00e2nticas", "entre", "frames", "de", "v\u00eddeo", "consecutivos", "."], "sentence-detokenized": "T\u00e9cnicas como as Redes Markov din\u00e2micas, Rede neural Convolutiva e Mem\u00f3ria de longo prazo s\u00e3o frequentemente utilizadas para explorar as correla\u00e7\u00f5es sem\u00e2nticas entre frames de v\u00eddeo consecutivos.", "token2charspan": [[0, 8], [9, 13], [14, 16], [17, 22], [23, 29], [30, 39], [39, 40], [41, 45], [46, 52], [53, 64], [65, 66], [67, 74], [75, 77], [78, 83], [84, 89], [90, 93], [94, 108], [109, 119], [120, 124], [125, 133], [134, 136], [137, 148], [149, 159], [160, 165], [166, 172], [173, 175], [176, 181], [182, 194], [194, 195]]}
{"doc_key": "ai-test-361", "ner": [[2, 4, "product"], [6, 6, "product"], [16, 17, "product"], [22, 22, "product"], [38, 38, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 16, 17, "artifact", "", false, false], [2, 4, 38, 38, "named", "", false, false], [6, 6, 2, 4, "named", "", false, false], [22, 22, 16, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["As", "placas", "de", "circuito", "impresso", "(", "PCB", ")", "produzidas", "em", "massa", "s\u00e3o", "quase", "exclusivamente", "fabricadas", "por", "robots", "pick-and-place", ",", "tipicamente", "com", "manipuladores", "SCARA", ",", "que", "removem", "min\u00fasculos", "componentes", "electr\u00f3nicos", "de", "tiras", "ou", "bandejas", ",", "e", "os", "colocam", "em", "PCBs", "com", "grande", "precis\u00e3o", "."], "sentence-detokenized": "As placas de circuito impresso (PCB) produzidas em massa s\u00e3o quase exclusivamente fabricadas por robots pick-and-place, tipicamente com manipuladores SCARA, que removem min\u00fasculos componentes electr\u00f3nicos de tiras ou bandejas, e os colocam em PCBs com grande precis\u00e3o.", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 21], [22, 30], [31, 32], [32, 35], [35, 36], [37, 47], [48, 50], [51, 56], [57, 60], [61, 66], [67, 81], [82, 92], [93, 96], [97, 103], [104, 118], [118, 119], [120, 131], [132, 135], [136, 149], [150, 155], [155, 156], [157, 160], [161, 168], [169, 179], [180, 191], [192, 204], [205, 207], [208, 213], [214, 216], [217, 225], [225, 226], [227, 228], [229, 231], [232, 239], [240, 242], [243, 247], [248, 251], [252, 258], [259, 267], [267, 268]]}
{"doc_key": "ai-test-362", "ner": [[3, 4, "field"], [13, 14, "algorithm"], [19, 20, "researcher"], [22, 23, "researcher"], [25, 27, "researcher"], [35, 36, "algorithm"], [39, 41, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 14, 3, 4, "part-of", "", false, false], [13, 14, 19, 20, "origin", "", false, false], [13, 14, 22, 23, "origin", "", false, false], [13, 14, 25, 27, "origin", "", false, false], [13, 14, 35, 36, "type-of", "", false, false], [35, 36, 39, 41, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["No", "contexto", "da", "aprendizagem", "mec\u00e2nica", ",", "onde", "\u00e9", "hoje", "mais", "amplamente", "aplicada", ",", "a", "LDA", "foi", "redescoberta", "independentemente", "por", "David", "Blei", ",", "Andrew", "Ng", "e", "Michael", "I.", "Jordan", "em", "2003", ",", "e", "apresentada", "como", "um", "modelo", "gr\u00e1fico", "para", "a", "descoberta", "de", "t\u00f3picos", "."], "sentence-detokenized": "No contexto da aprendizagem mec\u00e2nica, onde \u00e9 hoje mais amplamente aplicada, a LDA foi redescoberta independentemente por David Blei, Andrew Ng e Michael I. Jordan em 2003, e apresentada como um modelo gr\u00e1fico para a descoberta de t\u00f3picos.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 27], [28, 36], [36, 37], [38, 42], [43, 44], [45, 49], [50, 54], [55, 65], [66, 74], [74, 75], [76, 77], [78, 81], [82, 85], [86, 98], [99, 116], [117, 120], [121, 126], [127, 131], [131, 132], [133, 139], [140, 142], [143, 144], [145, 152], [153, 155], [156, 162], [163, 165], [166, 170], [170, 171], [172, 173], [174, 185], [186, 190], [191, 193], [194, 200], [201, 208], [209, 213], [214, 215], [216, 226], [227, 229], [230, 237], [237, 238]]}
{"doc_key": "ai-test-363", "ner": [[9, 9, "task"], [14, 14, "misc"], [17, 17, "metrics"], [19, 19, "metrics"], [23, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 9, 14, 14, "related-to", "task_across_domain", false, false]], "relations_mapping_to_source": [0], "sentence": ["O", "desempenho", "medido", "nos", "dados", "de", "teste", "de", "oito", "WSI", "ing\u00e9nuos", "atrav\u00e9s", "de", "v\u00e1rias", "tauopatias", "resultou", "na", "recolha", ",", "precis\u00e3o", ",", "e", "uma", "pontua\u00e7\u00e3o", "F1", "de", "0,92", ",", "0,72", ",", "e", "0,81", ",", "respectivamente", "."], "sentence-detokenized": "O desempenho medido nos dados de teste de oito WSI ing\u00e9nuos atrav\u00e9s de v\u00e1rias tauopatias resultou na recolha, precis\u00e3o, e uma pontua\u00e7\u00e3o F1 de 0,92, 0,72, e 0,81, respectivamente.", "token2charspan": [[0, 1], [2, 12], [13, 19], [20, 23], [24, 29], [30, 32], [33, 38], [39, 41], [42, 46], [47, 50], [51, 59], [60, 67], [68, 70], [71, 77], [78, 88], [89, 97], [98, 100], [101, 108], [108, 109], [110, 118], [118, 119], [120, 121], [122, 125], [126, 135], [136, 138], [139, 141], [142, 146], [146, 147], [148, 152], [152, 153], [154, 155], [156, 160], [160, 161], [162, 177], [177, 178]]}
{"doc_key": "ai-test-364", "ner": [[5, 5, "field"], [13, 15, "field"], [20, 20, "field"], [24, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 20, 20, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["Com", "a", "ajuda", "de", "tecnologias", "AR", "avan\u00e7adas", "(", "por", "exemplo", ",", "adi\u00e7\u00e3o", "de", "vis\u00e3o", "por", "computador", ",", "incorpora\u00e7\u00e3o", "de", "c\u00e2maras", "AR", "no", "smartphone", "e", "reconhecimento", "de", "objectos", ")", "a", "informa\u00e7\u00e3o", "sobre", "o", "mundo", "real", "circundante", "do", "utilizador", "torna-se", "interactiva", "e", "manipulada", "digitalmente", "."], "sentence-detokenized": "Com a ajuda de tecnologias AR avan\u00e7adas (por exemplo, adi\u00e7\u00e3o de vis\u00e3o por computador, incorpora\u00e7\u00e3o de c\u00e2maras AR no smartphone e reconhecimento de objectos) a informa\u00e7\u00e3o sobre o mundo real circundante do utilizador torna-se interactiva e manipulada digitalmente.", "token2charspan": [[0, 3], [4, 5], [6, 11], [12, 14], [15, 26], [27, 29], [30, 39], [40, 41], [41, 44], [45, 52], [52, 53], [54, 60], [61, 63], [64, 69], [70, 73], [74, 84], [84, 85], [86, 98], [99, 101], [102, 109], [110, 112], [113, 115], [116, 126], [127, 128], [129, 143], [144, 146], [147, 155], [155, 156], [157, 158], [159, 169], [170, 175], [176, 177], [178, 183], [184, 188], [189, 200], [201, 203], [204, 214], [215, 223], [224, 235], [236, 237], [238, 248], [249, 261], [261, 262]]}
{"doc_key": "ai-test-365", "ner": [[4, 4, "researcher"], [10, 10, "organisation"], [18, 19, "field"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 10, 10, "role", "forms_company", false, false], [10, 10, 18, 19, "related-to", "works_with", false, false], [10, 10, 28, 29, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Em", "2014", ",", "a", "Schmidhuber", "formou", "uma", "empresa", ",", "a", "Nnaisense", ",", "para", "trabalhar", "em", "aplica\u00e7\u00f5es", "comerciais", "de", "intelig\u00eancia", "artificial", "em", "campos", "como", "finan\u00e7as", ",", "ind\u00fastria", "pesada", "e", "auto-condu\u00e7\u00e3o", "de", "autom\u00f3veis", "."], "sentence-detokenized": "Em 2014, a Schmidhuber formou uma empresa, a Nnaisense, para trabalhar em aplica\u00e7\u00f5es comerciais de intelig\u00eancia artificial em campos como finan\u00e7as, ind\u00fastria pesada e auto-condu\u00e7\u00e3o de autom\u00f3veis.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 22], [23, 29], [30, 33], [34, 41], [41, 42], [43, 44], [45, 54], [54, 55], [56, 60], [61, 70], [71, 73], [74, 84], [85, 95], [96, 98], [99, 111], [112, 122], [123, 125], [126, 132], [133, 137], [138, 146], [146, 147], [148, 157], [158, 164], [165, 166], [167, 180], [181, 183], [184, 194], [194, 195]]}
{"doc_key": "ai-test-366", "ner": [[24, 26, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Isto", "n\u00e3o", "s\u00f3", "altera", "o", "desempenho", "de", "todos", "os", "testes", "subsequentes", "no", "modelo", "explicativo", "retido", ",", "como", "tamb\u00e9m", "pode", "introduzir", "parcialidade", "e", "alterar", "o", "erro", "quadr\u00e1tico", "m\u00e9dio", "na", "estimativa", "."], "sentence-detokenized": "Isto n\u00e3o s\u00f3 altera o desempenho de todos os testes subsequentes no modelo explicativo retido, como tamb\u00e9m pode introduzir parcialidade e alterar o erro quadr\u00e1tico m\u00e9dio na estimativa.", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 18], [19, 20], [21, 31], [32, 34], [35, 40], [41, 43], [44, 50], [51, 63], [64, 66], [67, 73], [74, 85], [86, 92], [92, 93], [94, 98], [99, 105], [106, 110], [111, 121], [122, 134], [135, 136], [137, 144], [145, 146], [147, 151], [152, 162], [163, 168], [169, 171], [172, 182], [182, 183]]}
{"doc_key": "ai-test-367", "ner": [[0, 1, "misc"], [5, 6, "algorithm"], [12, 14, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 0, 1, "usage", "", false, false], [5, 6, 12, 14, "topic", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Os", "bigrams", "s\u00e3o", "utilizados", "nos", "modelos", "lingu\u00edsticos", "mais", "bem", "sucedidos", "para", "o", "reconhecimento", "da", "fala", "."], "sentence-detokenized": "Os bigrams s\u00e3o utilizados nos modelos lingu\u00edsticos mais bem sucedidos para o reconhecimento da fala.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 25], [26, 29], [30, 37], [38, 50], [51, 55], [56, 59], [60, 69], [70, 74], [75, 76], [77, 91], [92, 94], [95, 99], [99, 100]]}
{"doc_key": "ai-test-368", "ner": [[4, 5, "field"], [8, 10, "misc"], [16, 18, "misc"], [22, 24, "organisation"], [27, 29, "misc"], [34, 37, "organisation"], [40, 42, "misc"], [47, 50, "organisation"], [54, 56, "misc"], [61, 64, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[8, 10, 4, 5, "topic", "", false, false], [16, 18, 22, 24, "origin", "", false, false], [27, 29, 34, 37, "origin", "", false, false], [40, 42, 47, 50, "origin", "", false, false], [54, 56, 61, 64, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["A", "sua", "investiga\u00e7\u00e3o", "em", "psicologia", "cognitiva", "ganhou", "o", "Pr\u00e9mio", "Early", "Career", "(", "1984", ")", "e", "o", "Pr\u00e9mio", "Boyd", "McCandless", "1986", ")", "da", "Associa\u00e7\u00e3o", "Psicol\u00f3gica", "Americana", ",", "o", "Pr\u00e9mio", "Troland", "Research", "(", "1993", ")", "da", "Academia", "Nacional", "de", "Ci\u00eancias", ",", "o", "Pr\u00e9mio", "Henry", "Dale", "(", "2004", ")", "da", "Institui\u00e7\u00e3o", "Real", "da", "Gr\u00e3-Bretanha", ",", "e", "o", "Pr\u00e9mio", "George", "Miller", "(", "2010", ")", "da", "Sociedade", "de", "Neuroci\u00eancia", "Cognitiva", "."], "sentence-detokenized": "A sua investiga\u00e7\u00e3o em psicologia cognitiva ganhou o Pr\u00e9mio Early Career (1984) e o Pr\u00e9mio Boyd McCandless 1986) da Associa\u00e7\u00e3o Psicol\u00f3gica Americana, o Pr\u00e9mio Troland Research (1993) da Academia Nacional de Ci\u00eancias, o Pr\u00e9mio Henry Dale (2004) da Institui\u00e7\u00e3o Real da Gr\u00e3-Bretanha, e o Pr\u00e9mio George Miller (2010) da Sociedade de Neuroci\u00eancia Cognitiva.", "token2charspan": [[0, 1], [2, 5], [6, 18], [19, 21], [22, 32], [33, 42], [43, 49], [50, 51], [52, 58], [59, 64], [65, 71], [72, 73], [73, 77], [77, 78], [79, 80], [81, 82], [83, 89], [90, 94], [95, 105], [106, 110], [110, 111], [112, 114], [115, 125], [126, 137], [138, 147], [147, 148], [149, 150], [151, 157], [158, 165], [166, 174], [175, 176], [176, 180], [180, 181], [182, 184], [185, 193], [194, 202], [203, 205], [206, 214], [214, 215], [216, 217], [218, 224], [225, 230], [231, 235], [236, 237], [237, 241], [241, 242], [243, 245], [246, 257], [258, 262], [263, 265], [266, 278], [278, 279], [280, 281], [282, 283], [284, 290], [291, 297], [298, 304], [305, 306], [306, 310], [310, 311], [312, 314], [315, 324], [325, 327], [328, 340], [341, 350], [350, 351]]}
{"doc_key": "ai-test-369", "ner": [[1, 2, "misc"], [13, 13, "misc"], [9, 12, "product"], [17, 17, "researcher"], [19, 19, "researcher"], [26, 27, "researcher"], [29, 30, "researcher"], [32, 33, "task"], [35, 38, "researcher"], [40, 43, "researcher"], [44, 45, "task"], [48, 48, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[1, 2, 13, 13, "named", "", false, false], [1, 2, 48, 48, "named", "", false, false], [13, 13, 17, 17, "origin", "", false, false], [13, 13, 19, 19, "origin", "", false, false], [13, 13, 32, 33, "related-to", "used_for", false, false], [9, 12, 13, 13, "usage", "", false, false], [9, 12, 44, 45, "named", "", false, false], [26, 27, 13, 13, "usage", "", false, false], [26, 27, 35, 38, "named", "same", false, false], [29, 30, 13, 13, "usage", "", false, false], [29, 30, 40, 43, "named", "same", false, false], [44, 45, 48, 48, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Um", "rosto", "pr\u00f3prio", "(", "A", "abordagem", "de", "utilizar", "o", "sistema", "de", "reconhecimento", "facial", "eigenface", "foi", "desenvolvida", "por", "Sirovich", "e", "Kirby", "(", "1987", ")", "e", "utilizada", "por", "Matthew", "Turk", "e", "Alex", "Pentland", "na", "classifica\u00e7\u00e3o", "facial", ".", "Turk", ",", "Matthew", "A", "e", "Pentland", ",", "Alex", "P.", "Reconhecimento", "facial", "utilizando", "o", "eigenface", "."], "sentence-detokenized": "Um rosto pr\u00f3prio (A abordagem de utilizar o sistema de reconhecimento facial eigenface foi desenvolvida por Sirovich e Kirby (1987) e utilizada por Matthew Turk e Alex Pentland na classifica\u00e7\u00e3o facial. Turk, Matthew A e Pentland, Alex P. Reconhecimento facial utilizando o eigenface.", "token2charspan": [[0, 2], [3, 8], [9, 16], [17, 18], [18, 19], [20, 29], [30, 32], [33, 41], [42, 43], [44, 51], [52, 54], [55, 69], [70, 76], [77, 86], [87, 90], [91, 103], [104, 107], [108, 116], [117, 118], [119, 124], [125, 126], [126, 130], [130, 131], [132, 133], [134, 143], [144, 147], [148, 155], [156, 160], [161, 162], [163, 167], [168, 176], [177, 179], [180, 193], [194, 200], [200, 201], [202, 206], [206, 207], [208, 215], [216, 217], [218, 219], [220, 228], [228, 229], [230, 234], [235, 237], [238, 252], [253, 259], [260, 270], [271, 272], [273, 282], [282, 283]]}
{"doc_key": "ai-test-370", "ner": [[5, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Um", "dicion\u00e1rio", "lexical", "como", "o", "WordNet", "pode", "ent\u00e3o", "ser", "utilizado", "para", "a", "compreens\u00e3o", "do", "contexto", "."], "sentence-detokenized": "Um dicion\u00e1rio lexical como o WordNet pode ent\u00e3o ser utilizado para a compreens\u00e3o do contexto.", "token2charspan": [[0, 2], [3, 13], [14, 21], [22, 26], [27, 28], [29, 36], [37, 41], [42, 47], [48, 51], [52, 61], [62, 66], [67, 68], [69, 80], [81, 83], [84, 92], [92, 93]]}
{"doc_key": "ai-test-371", "ner": [[0, 1, "misc"], [10, 10, "misc"], [19, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 10, 10, "part-of", "", false, false], [10, 10, 19, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "hipon\u00edmia", "\u00e9", "a", "rela\u00e7\u00e3o", "mais", "frequentemente", "codificada", "entre", "os", "synsets", "utilizados", "em", "bases", "de", "dados", "lexicais", "como", "a", "WordNet", "."], "sentence-detokenized": "A hipon\u00edmia \u00e9 a rela\u00e7\u00e3o mais frequentemente codificada entre os synsets utilizados em bases de dados lexicais como a WordNet.", "token2charspan": [[0, 1], [2, 11], [12, 13], [14, 15], [16, 23], [24, 28], [29, 43], [44, 54], [55, 60], [61, 63], [64, 71], [72, 82], [83, 85], [86, 91], [92, 94], [95, 100], [101, 109], [110, 114], [115, 116], [117, 124], [124, 125]]}
{"doc_key": "ai-test-372", "ner": [[0, 0, "organisation"], [7, 9, "programlang"], [11, 11, "programlang"], [42, 42, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 7, 9, "general-affiliation", "", false, false], [0, 0, 11, 11, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["OPeNDAP", "oferece", "bibliotecas", "de", "c\u00f3digo", "aberto", "em", "C", "+", "+", "e", "Java", ",", "mas", "muitos", "clientes", "confiam", "em", "bibliotecas", "desenvolvidas", "pela", "comunidade", ",", "tais", "como", "bibliotecas", "que", "incluem", "capacidades", "incorporadas", "para", "a", "recupera\u00e7\u00e3o", "(", "array-style", ")", "de", "dados", "a", "partir", "de", "servidores", "DAP", "."], "sentence-detokenized": "OPeNDAP oferece bibliotecas de c\u00f3digo aberto em C + + e Java, mas muitos clientes confiam em bibliotecas desenvolvidas pela comunidade, tais como bibliotecas que incluem capacidades incorporadas para a recupera\u00e7\u00e3o (array-style) de dados a partir de servidores DAP.", "token2charspan": [[0, 7], [8, 15], [16, 27], [28, 30], [31, 37], [38, 44], [45, 47], [48, 49], [50, 51], [52, 53], [54, 55], [56, 60], [60, 61], [62, 65], [66, 72], [73, 81], [82, 89], [90, 92], [93, 104], [105, 118], [119, 123], [124, 134], [134, 135], [136, 140], [141, 145], [146, 157], [158, 161], [162, 169], [170, 181], [182, 194], [195, 199], [200, 201], [202, 213], [214, 215], [215, 226], [226, 227], [228, 230], [231, 236], [237, 238], [239, 245], [246, 248], [249, 259], [260, 263], [263, 264]]}
{"doc_key": "ai-test-373", "ner": [[3, 4, "misc"], [7, 7, "product"], [19, 19, "country"], [30, 31, "misc"], [48, 48, "organisation"], [46, 47, "product"], [54, 54, "organisation"], [51, 52, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 4, 19, 19, "opposite", "", false, false], [7, 7, 19, 19, "artifact", "", false, false], [30, 31, 7, 7, "part-of", "", false, false], [46, 47, 48, 48, "artifact", "", false, false], [51, 52, 54, 54, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Nessa", "p\u00e1gina", ",", "Samurai", "Damashii", "exagerou", "o", "Senkousha", "como", "a", "cristaliza\u00e7\u00e3o", "dos", "quatro", "mil", "anos", "de", "conhecimento", "cient\u00edfico", "da", "China", ",", "comentou", "o", "desenho", "rudimentar", "(", "por", "exemplo", ",", "o", "Canh\u00e3o", "Chin\u00eas", "na", "sua", "virilha", ")", ",", "e", "colocou", "a", "sua", "imagem", "entre", "as", "imagens", "do", "ASIMO", "da", "Honda", "e", "do", "QRIO", "SDR-3X", "da", "Sony", "por", "justaposi\u00e7\u00e3o", "."], "sentence-detokenized": "Nessa p\u00e1gina, Samurai Damashii exagerou o Senkousha como a cristaliza\u00e7\u00e3o dos quatro mil anos de conhecimento cient\u00edfico da China, comentou o desenho rudimentar (por exemplo, o Canh\u00e3o Chin\u00eas na sua virilha), e colocou a sua imagem entre as imagens do ASIMO da Honda e do QRIO SDR-3X da Sony por justaposi\u00e7\u00e3o.", "token2charspan": [[0, 5], [6, 12], [12, 13], [14, 21], [22, 30], [31, 39], [40, 41], [42, 51], [52, 56], [57, 58], [59, 72], [73, 76], [77, 83], [84, 87], [88, 92], [93, 95], [96, 108], [109, 119], [120, 122], [123, 128], [128, 129], [130, 138], [139, 140], [141, 148], [149, 159], [160, 161], [161, 164], [165, 172], [172, 173], [174, 175], [176, 182], [183, 189], [190, 192], [193, 196], [197, 204], [204, 205], [205, 206], [207, 208], [209, 216], [217, 218], [219, 222], [223, 229], [230, 235], [236, 238], [239, 246], [247, 249], [250, 255], [256, 258], [259, 264], [265, 266], [267, 269], [270, 274], [275, 281], [282, 284], [285, 289], [290, 293], [294, 306], [306, 307]]}
{"doc_key": "ai-test-374", "ner": [[10, 11, "algorithm"], [23, 23, "product"], [25, 25, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 23, 23, "part-of", "includes_functionality_of", false, false], [10, 11, 25, 25, "part-of", "includes_functionality_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Existem", "tamb\u00e9m", "muitas", "bibliotecas", "de", "programa\u00e7\u00e3o", "que", "cont\u00eam", "funcionalidades", "de", "redes", "neurais", "e", "que", "podem", "ser", "utilizadas", "em", "implementa\u00e7\u00f5es", "personalizadas", "(", "tais", "como", "TensorFlow", ",", "Theano", ",", "etc.", ")", "."], "sentence-detokenized": "Existem tamb\u00e9m muitas bibliotecas de programa\u00e7\u00e3o que cont\u00eam funcionalidades de redes neurais e que podem ser utilizadas em implementa\u00e7\u00f5es personalizadas (tais como TensorFlow, Theano, etc.).", "token2charspan": [[0, 7], [8, 14], [15, 21], [22, 33], [34, 36], [37, 48], [49, 52], [53, 59], [60, 75], [76, 78], [79, 84], [85, 92], [93, 94], [95, 98], [99, 104], [105, 108], [109, 119], [120, 122], [123, 137], [138, 152], [153, 154], [154, 158], [159, 163], [164, 174], [174, 175], [176, 182], [182, 183], [184, 188], [188, 189], [189, 190]]}
{"doc_key": "ai-test-375", "ner": [[3, 6, "conference"], [8, 8, "organisation"], [10, 16, "conference"], [18, 18, "conference"], [20, 20, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["\u00c9", "membro", "da", "Association", "for", "Computing", "Machinery", ",", "IEEE", ",", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "IAPR", "e", "SPIE", "."], "sentence-detokenized": "\u00c9 membro da Association for Computing Machinery, IEEE, American Association for the Advancement of Science, IAPR e SPIE.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 23], [24, 27], [28, 37], [38, 47], [47, 48], [49, 53], [53, 54], [55, 63], [64, 75], [76, 79], [80, 83], [84, 95], [96, 98], [99, 106], [106, 107], [108, 112], [113, 114], [115, 119], [119, 120]]}
{"doc_key": "ai-test-376", "ner": [[3, 3, "organisation"], [9, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 9, 12, "related-to", "runs_trials_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["Um", "julgamento", "pela", "RET", "em", "2011", "com", "c\u00e2maras", "de", "sistema", "de", "reconhecimento", "facial", "montadas", "em", "el\u00e9ctricos", "certificou-se", "de", "que", "as", "pessoas", "eram", "proibidas", "de", "entrar", "nos", "el\u00e9ctricos", "da", "cidade", "de", "qualquer", "forma", "."], "sentence-detokenized": "Um julgamento pela RET em 2011 com c\u00e2maras de sistema de reconhecimento facial montadas em el\u00e9ctricos certificou-se de que as pessoas eram proibidas de entrar nos el\u00e9ctricos da cidade de qualquer forma.", "token2charspan": [[0, 2], [3, 13], [14, 18], [19, 22], [23, 25], [26, 30], [31, 34], [35, 42], [43, 45], [46, 53], [54, 56], [57, 71], [72, 78], [79, 87], [88, 90], [91, 101], [102, 115], [116, 118], [119, 122], [123, 125], [126, 133], [134, 138], [139, 148], [149, 151], [152, 158], [159, 162], [163, 173], [174, 176], [177, 183], [184, 186], [187, 195], [196, 201], [201, 202]]}
{"doc_key": "ai-test-377", "ner": [[7, 8, "person"], [9, 9, "organisation"], [18, 19, "person"], [21, 22, "person"], [28, 29, "person"], [31, 32, "person"], [34, 35, "person"], [37, 38, "person"], [40, 41, "person"], [43, 44, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[7, 8, 9, 9, "role", "works_for", false, false], [18, 19, 9, 9, "role", "works_for", false, false], [21, 22, 9, 9, "role", "works_for", false, false], [28, 29, 9, 9, "role", "works_for", false, false], [31, 32, 9, 9, "role", "works_for", false, false], [34, 35, 9, 9, "role", "works_for", false, false], [37, 38, 9, 9, "role", "works_for", false, false], [40, 41, 9, 9, "role", "works_for", false, false], [43, 44, 9, 9, "role", "works_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["O", "filme", ",", "adaptado", "do", "popular", "musical", "Cole", "Porter", "Broadway", ",", "estrelou", "a", "equipa", "songbird", "da", "MGM", "de", "Howard", "Keel", "e", "Kathryn", "Grayson", "como", "protagonistas", ",", "apoiado", "por", "Ann", "Miller", ",", "Keenan", "Wynn", ",", "Bobby", "Van", ",", "James", "Whitmore", ",", "Kurt", "Kasznar", "e", "Tommy", "Rall", "."], "sentence-detokenized": "O filme, adaptado do popular musical Cole Porter Broadway, estrelou a equipa songbird da MGM de Howard Keel e Kathryn Grayson como protagonistas, apoiado por Ann Miller, Keenan Wynn, Bobby Van, James Whitmore, Kurt Kasznar e Tommy Rall.", "token2charspan": [[0, 1], [2, 7], [7, 8], [9, 17], [18, 20], [21, 28], [29, 36], [37, 41], [42, 48], [49, 57], [57, 58], [59, 67], [68, 69], [70, 76], [77, 85], [86, 88], [89, 92], [93, 95], [96, 102], [103, 107], [108, 109], [110, 117], [118, 125], [126, 130], [131, 144], [144, 145], [146, 153], [154, 157], [158, 161], [162, 168], [168, 169], [170, 176], [177, 181], [181, 182], [183, 188], [189, 192], [192, 193], [194, 199], [200, 208], [208, 209], [210, 214], [215, 222], [223, 224], [225, 230], [231, 235], [235, 236]]}
{"doc_key": "ai-test-378", "ner": [[20, 25, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Tais", "aplica\u00e7\u00f5es", "devem", "racionalizar", "os", "fluxos", "de", "chamadas", ",", "minimizar", "as", "solicita\u00e7\u00f5es", ",", "eliminar", "itera\u00e7\u00f5es", "desnecess\u00e1rias", "e", "permitir", "um", "elaborado", "sistema", "de", "di\u00e1logo", "de", "iniciativa", "mista", ",", "que", "permite", "aos", "interlocutores", "introduzir", "v\u00e1rias", "informa\u00e7\u00f5es", "numa", "\u00fanica", "declara\u00e7\u00e3o", "e", "em", "qualquer", "ordem", "ou", "combina\u00e7\u00e3o", "."], "sentence-detokenized": "Tais aplica\u00e7\u00f5es devem racionalizar os fluxos de chamadas, minimizar as solicita\u00e7\u00f5es, eliminar itera\u00e7\u00f5es desnecess\u00e1rias e permitir um elaborado sistema de di\u00e1logo de iniciativa mista, que permite aos interlocutores introduzir v\u00e1rias informa\u00e7\u00f5es numa \u00fanica declara\u00e7\u00e3o e em qualquer ordem ou combina\u00e7\u00e3o.", "token2charspan": [[0, 4], [5, 15], [16, 21], [22, 34], [35, 37], [38, 44], [45, 47], [48, 56], [56, 57], [58, 67], [68, 70], [71, 83], [83, 84], [85, 93], [94, 103], [104, 118], [119, 120], [121, 129], [130, 132], [133, 142], [143, 150], [151, 153], [154, 161], [162, 164], [165, 175], [176, 181], [181, 182], [183, 186], [187, 194], [195, 198], [199, 213], [214, 224], [225, 231], [232, 243], [244, 248], [249, 254], [255, 265], [266, 267], [268, 270], [271, 279], [280, 285], [286, 288], [289, 299], [299, 300]]}
{"doc_key": "ai-test-379", "ner": [[7, 9, "algorithm"], [12, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 15, 7, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Como", "tal", ",", "os", "m\u00e9todos", "tradicionais", "de", "descida", "de", "gradiente", "(", "ou", "descida", "de", "gradiente", "estoc\u00e1stico", ")", "podem", "ser", "adaptados", ",", "onde", "de", "dar", "um", "passo", "na", "direc\u00e7\u00e3o", "do", "gradiente", "da", "fun\u00e7\u00e3o", ",", "\u00e9", "dado", "um", "passo", "na", "direc\u00e7\u00e3o", "de", "um", "vector", "seleccionado", "a", "partir", "do", "sub-gradiente", "da", "fun\u00e7\u00e3o", "."], "sentence-detokenized": "Como tal, os m\u00e9todos tradicionais de descida de gradiente (ou descida de gradiente estoc\u00e1stico) podem ser adaptados, onde de dar um passo na direc\u00e7\u00e3o do gradiente da fun\u00e7\u00e3o, \u00e9 dado um passo na direc\u00e7\u00e3o de um vector seleccionado a partir do sub-gradiente da fun\u00e7\u00e3o.", "token2charspan": [[0, 4], [5, 8], [8, 9], [10, 12], [13, 20], [21, 33], [34, 36], [37, 44], [45, 47], [48, 57], [58, 59], [59, 61], [62, 69], [70, 72], [73, 82], [83, 94], [94, 95], [96, 101], [102, 105], [106, 115], [115, 116], [117, 121], [122, 124], [125, 128], [129, 131], [132, 137], [138, 140], [141, 149], [150, 152], [153, 162], [163, 165], [166, 172], [172, 173], [174, 175], [176, 180], [181, 183], [184, 189], [190, 192], [193, 201], [202, 204], [205, 207], [208, 214], [215, 227], [228, 229], [230, 236], [237, 239], [240, 253], [254, 256], [257, 263], [263, 264]]}
{"doc_key": "ai-test-380", "ner": [[9, 12, "metrics"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Se", "se", "assumir", "que", "a", "distor\u00e7\u00e3o", "\u00e9", "medida", "por", "erro", "m\u00e9dio", "ao", "quadrado", ",", "a", "distor\u00e7\u00e3o", "D", ",", "\u00e9", "dada", "por", ":"], "sentence-detokenized": "Se se assumir que a distor\u00e7\u00e3o \u00e9 medida por erro m\u00e9dio ao quadrado, a distor\u00e7\u00e3o D, \u00e9 dada por:", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 17], [18, 19], [20, 29], [30, 31], [32, 38], [39, 42], [43, 47], [48, 53], [54, 56], [57, 65], [65, 66], [67, 68], [69, 78], [79, 80], [80, 81], [82, 83], [84, 88], [89, 92], [92, 93]]}
{"doc_key": "ai-test-381", "ner": [[0, 1, "algorithm"], [7, 9, "field"], [21, 23, "task"], [25, 27, "task"], [32, 33, "task"], [35, 36, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 7, 9, "part-of", "", false, false], [21, 23, 0, 1, "part-of", "", false, false], [25, 27, 0, 1, "part-of", "", false, false], [32, 33, 0, 1, "part-of", "", false, false], [35, 36, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Os", "MLPs", "foram", "uma", "solu\u00e7\u00e3o", "popular", "de", "aprendizagem", "autom\u00e1tica", "nos", "anos", "80", ",", "encontrando", "aplica\u00e7\u00f5es", "em", "diversos", "campos", ",", "tais", "como", "reconhecimento", "de", "voz", ",", "reconhecimento", "de", "imagem", ",", "e", "software", "de", "tradu\u00e7\u00e3o", "autom\u00e1tica", ",", "redes", "neurais", "."], "sentence-detokenized": "Os MLPs foram uma solu\u00e7\u00e3o popular de aprendizagem autom\u00e1tica nos anos 80, encontrando aplica\u00e7\u00f5es em diversos campos, tais como reconhecimento de voz, reconhecimento de imagem, e software de tradu\u00e7\u00e3o autom\u00e1tica, redes neurais.", "token2charspan": [[0, 2], [3, 7], [8, 13], [14, 17], [18, 25], [26, 33], [34, 36], [37, 49], [50, 60], [61, 64], [65, 69], [70, 72], [72, 73], [74, 85], [86, 96], [97, 99], [100, 108], [109, 115], [115, 116], [117, 121], [122, 126], [127, 141], [142, 144], [145, 148], [148, 149], [150, 164], [165, 167], [168, 174], [174, 175], [176, 177], [178, 186], [187, 189], [190, 198], [199, 209], [209, 210], [211, 216], [217, 224], [224, 225]]}
{"doc_key": "ai-test-382", "ner": [[0, 0, "researcher"], [4, 4, "misc"], [6, 8, "university"], [16, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 8, "physical", "", false, false], [0, 0, 6, 8, "role", "", false, false], [4, 4, 0, 0, "origin", "", false, false], [16, 18, 0, 0, "role", "supervised", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Allen", "recebeu", "o", "seu", "doutoramento", "da", "Universidade", "de", "Toronto", "em", "1979", ",", "sob", "a", "supervis\u00e3o", "de", "C.", "Raymond", "Perrault", ","], "sentence-detokenized": "Allen recebeu o seu doutoramento da Universidade de Toronto em 1979, sob a supervis\u00e3o de C. Raymond Perrault,", "token2charspan": [[0, 5], [6, 13], [14, 15], [16, 19], [20, 32], [33, 35], [36, 48], [49, 51], [52, 59], [60, 62], [63, 67], [67, 68], [69, 72], [73, 74], [75, 85], [86, 88], [89, 91], [92, 99], [100, 108], [108, 109]]}
{"doc_key": "ai-test-383", "ner": [[0, 1, "product"], [6, 9, "field"], [11, 11, "product"], [13, 13, "product"], [15, 15, "product"], [22, 22, "product"], [25, 25, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 6, 9, "related-to", "supports", false, false], [11, 11, 6, 9, "type-of", "", true, false], [13, 13, 6, 9, "type-of", "", true, false], [15, 15, 6, 9, "type-of", "", true, false], [15, 15, 22, 22, "related-to", "converting_to", true, false], [25, 25, 6, 9, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["O", "OpenCV", "suporta", "alguns", "modelos", "de", "estruturas", "de", "aprendizagem", "profunda", "como", "TensorFlow", ",", "Torch", ",", "PyTorch", "(", "ap\u00f3s", "convers\u00e3o", "para", "um", "modelo", "ONNX", ")", "e", "Caffe", "de", "acordo", "com", "uma", "lista", "definida", "de", "camadas", "suportadas", "."], "sentence-detokenized": "O OpenCV suporta alguns modelos de estruturas de aprendizagem profunda como TensorFlow, Torch, PyTorch (ap\u00f3s convers\u00e3o para um modelo ONNX) e Caffe de acordo com uma lista definida de camadas suportadas.", "token2charspan": [[0, 1], [2, 8], [9, 16], [17, 23], [24, 31], [32, 34], [35, 45], [46, 48], [49, 61], [62, 70], [71, 75], [76, 86], [86, 87], [88, 93], [93, 94], [95, 102], [103, 104], [104, 108], [109, 118], [119, 123], [124, 126], [127, 133], [134, 138], [138, 139], [140, 141], [142, 147], [148, 150], [151, 157], [158, 161], [162, 165], [166, 171], [172, 180], [181, 183], [184, 191], [192, 202], [202, 203]]}
{"doc_key": "ai-test-384", "ner": [[2, 2, "researcher"], [8, 11, "organisation"], [13, 13, "organisation"], [20, 24, "organisation"], [26, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 8, 11, "role", "", false, false], [2, 2, 20, 24, "role", "", false, false], [2, 2, 26, 26, "related-to", "lectures_in", false, false], [13, 13, 8, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Anteriormente", ",", "Christensen", "foi", "a", "Presidente", "Fundadora", "da", "European", "Robotics", "Research", "Network", "(", "EURON", ")", "e", "uma", "Conferencista", "Distinta", "da", "IEEE", "Robotics", "and", "Automation", "Society", "em", "Rob\u00f3tica", "."], "sentence-detokenized": "Anteriormente, Christensen foi a Presidente Fundadora da European Robotics Research Network (EURON) e uma Conferencista Distinta da IEEE Robotics and Automation Society em Rob\u00f3tica.", "token2charspan": [[0, 13], [13, 14], [15, 26], [27, 30], [31, 32], [33, 43], [44, 53], [54, 56], [57, 65], [66, 74], [75, 83], [84, 91], [92, 93], [93, 98], [98, 99], [100, 101], [102, 105], [106, 119], [120, 128], [129, 131], [132, 136], [137, 145], [146, 149], [150, 160], [161, 168], [169, 171], [172, 180], [180, 181]]}
{"doc_key": "ai-test-385", "ner": [[5, 5, "field"], [7, 10, "university"], [12, 12, "location"], [14, 17, "country"], [22, 22, "misc"], [24, 24, "field"], [26, 30, "organisation"], [32, 32, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[7, 10, 12, 12, "physical", "", false, false], [12, 12, 14, 17, "physical", "", false, false], [22, 22, 24, 24, "topic", "", false, false], [26, 30, 32, 32, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Recebeu", "o", "seu", "mestrado", "em", "matem\u00e1tica", "da", "Universidade", "Estatal", "de", "Samarkand", ",", "Samarkand", ",", "Rep\u00fablica", "Socialista", "Sovi\u00e9tica", "Uzbeque", "em", "1958", "e", "o", "doutoramento", "em", "estat\u00edstica", "no", "Instituto", "de", "Ci\u00eancias", "de", "Controlo", ",", "Moscovo", "em", "1964", "."], "sentence-detokenized": "Recebeu o seu mestrado em matem\u00e1tica da Universidade Estatal de Samarkand, Samarkand, Rep\u00fablica Socialista Sovi\u00e9tica Uzbeque em 1958 e o doutoramento em estat\u00edstica no Instituto de Ci\u00eancias de Controlo, Moscovo em 1964.", "token2charspan": [[0, 7], [8, 9], [10, 13], [14, 22], [23, 25], [26, 36], [37, 39], [40, 52], [53, 60], [61, 63], [64, 73], [73, 74], [75, 84], [84, 85], [86, 95], [96, 106], [107, 116], [117, 124], [125, 127], [128, 132], [133, 134], [135, 136], [137, 149], [150, 152], [153, 164], [165, 167], [168, 177], [178, 180], [181, 189], [190, 192], [193, 201], [201, 202], [203, 210], [211, 213], [214, 218], [218, 219]]}
{"doc_key": "ai-test-386", "ner": [[9, 9, "organisation"], [13, 14, "product"], [39, 41, "field"], [44, 47, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 39, 41, "usage", "", false, false], [9, 9, 44, 47, "usage", "", false, false], [13, 14, 9, 9, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Cada", "vez", "mais", ",", "por\u00e9m", ",", "o", "trabalho", "na", "Cycorp", "envolve", "dar", "ao", "sistema", "Cycorp", "a", "capacidade", "de", "comunicar", "com", "os", "utilizadores", "finais", "em", "linguagem", "natural", ",", "e", "de", "ajudar", "no", "processo", "de", "forma\u00e7\u00e3o", "cont\u00ednua", "de", "conhecimentos", "atrav\u00e9s", "da", "aprendizagem", "de", "m\u00e1quinas", "e", "da", "compreens\u00e3o", "da", "linguagem", "natural", "."], "sentence-detokenized": "Cada vez mais, por\u00e9m, o trabalho na Cycorp envolve dar ao sistema Cycorp a capacidade de comunicar com os utilizadores finais em linguagem natural, e de ajudar no processo de forma\u00e7\u00e3o cont\u00ednua de conhecimentos atrav\u00e9s da aprendizagem de m\u00e1quinas e da compreens\u00e3o da linguagem natural.", "token2charspan": [[0, 4], [5, 8], [9, 13], [13, 14], [15, 20], [20, 21], [22, 23], [24, 32], [33, 35], [36, 42], [43, 50], [51, 54], [55, 57], [58, 65], [66, 72], [73, 74], [75, 85], [86, 88], [89, 98], [99, 102], [103, 105], [106, 118], [119, 125], [126, 128], [129, 138], [139, 146], [146, 147], [148, 149], [150, 152], [153, 159], [160, 162], [163, 171], [172, 174], [175, 183], [184, 192], [193, 195], [196, 209], [210, 217], [218, 220], [221, 233], [234, 236], [237, 245], [246, 247], [248, 250], [251, 262], [263, 265], [266, 275], [276, 283], [283, 284]]}
{"doc_key": "ai-test-387", "ner": [[68, 68, "metrics"], [70, 70, "metrics"], [72, 72, "metrics"], [74, 75, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Por", "exemplo", ",", "se", "se", "procurar", "o", "classificador", "mais", "adequado", "para", "o", "problema", ",", "o", "conjunto", "de", "dados", "de", "forma\u00e7\u00e3o", "\u00e9", "utilizado", "para", "treinar", "os", "algoritmos", "candidatos", ",", "o", "conjunto", "de", "dados", "de", "valida\u00e7\u00e3o", "\u00e9", "utilizado", "para", "comparar", "os", "seus", "desempenhos", "e", "decidir", "qual", "deles", "deve", "ser", "utilizado", "e", ",", "finalmente", ",", "o", "conjunto", "de", "dados", "de", "teste", "\u00e9", "utilizado", "para", "obter", "as", "caracter\u00edsticas", "de", "desempenho", "tais", "como", "precis\u00e3o", ",", "sensibilidade", ",", "especificidade", ",", "medida", "F", ",", "e", "assim", "por", "diante", "."], "sentence-detokenized": "Por exemplo, se se procurar o classificador mais adequado para o problema, o conjunto de dados de forma\u00e7\u00e3o \u00e9 utilizado para treinar os algoritmos candidatos, o conjunto de dados de valida\u00e7\u00e3o \u00e9 utilizado para comparar os seus desempenhos e decidir qual deles deve ser utilizado e, finalmente, o conjunto de dados de teste \u00e9 utilizado para obter as caracter\u00edsticas de desempenho tais como precis\u00e3o, sensibilidade, especificidade, medida F, e assim por diante.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 18], [19, 27], [28, 29], [30, 43], [44, 48], [49, 57], [58, 62], [63, 64], [65, 73], [73, 74], [75, 76], [77, 85], [86, 88], [89, 94], [95, 97], [98, 106], [107, 108], [109, 118], [119, 123], [124, 131], [132, 134], [135, 145], [146, 156], [156, 157], [158, 159], [160, 168], [169, 171], [172, 177], [178, 180], [181, 190], [191, 192], [193, 202], [203, 207], [208, 216], [217, 219], [220, 224], [225, 236], [237, 238], [239, 246], [247, 251], [252, 257], [258, 262], [263, 266], [267, 276], [277, 278], [278, 279], [280, 290], [290, 291], [292, 293], [294, 302], [303, 305], [306, 311], [312, 314], [315, 320], [321, 322], [323, 332], [333, 337], [338, 343], [344, 346], [347, 362], [363, 365], [366, 376], [377, 381], [382, 386], [387, 395], [395, 396], [397, 410], [410, 411], [412, 426], [426, 427], [428, 434], [435, 436], [436, 437], [438, 439], [440, 445], [446, 449], [450, 456], [456, 457]]}
{"doc_key": "ai-test-388", "ner": [[1, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["O", "erro", "m\u00e9dio", "ao", "quadrado", "\u00e9", "de", "0,15", "."], "sentence-detokenized": "O erro m\u00e9dio ao quadrado \u00e9 de 0,15.", "token2charspan": [[0, 1], [2, 6], [7, 12], [13, 15], [16, 24], [25, 26], [27, 29], [30, 34], [34, 35]]}
{"doc_key": "ai-test-389", "ner": [[7, 8, "misc"], [5, 5, "organisation"], [14, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 7, 8, "role", "", false, false], [14, 14, 7, 8, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Em", "1979", "foi", "organizado", "pelo", "IEEE", "um", "concurso", "Micromouse", ",", "como", "mostra", "a", "revista", "Spectrum", "."], "sentence-detokenized": "Em 1979 foi organizado pelo IEEE um concurso Micromouse, como mostra a revista Spectrum.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 22], [23, 27], [28, 32], [33, 35], [36, 44], [45, 55], [55, 56], [57, 61], [62, 68], [69, 70], [71, 78], [79, 87], [87, 88]]}
{"doc_key": "ai-test-390", "ner": [[1, 2, "algorithm"], [9, 13, "field"], [14, 17, "task"], [19, 21, "task"], [23, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 9, 13, "part-of", "", false, false], [14, 17, 9, 13, "part-of", "task_part_of_field", false, false], [19, 21, 9, 13, "part-of", "task_part_of_field", false, false], [23, 26, 9, 13, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["O", "espa\u00e7o", "Gabor", "\u00e9", "muito", "\u00fatil", "em", "aplica\u00e7\u00f5es", "de", "processamento", "de", "imagem", "tais", "como", "reconhecimento", "\u00f3ptico", "de", "caracteres", ",", "reconhecimento", "da", "\u00edris", "e", "reconhecimento", "de", "impress\u00f5es", "digitais", "."], "sentence-detokenized": "O espa\u00e7o Gabor \u00e9 muito \u00fatil em aplica\u00e7\u00f5es de processamento de imagem tais como reconhecimento \u00f3ptico de caracteres, reconhecimento da \u00edris e reconhecimento de impress\u00f5es digitais.", "token2charspan": [[0, 1], [2, 8], [9, 14], [15, 16], [17, 22], [23, 27], [28, 30], [31, 41], [42, 44], [45, 58], [59, 61], [62, 68], [69, 73], [74, 78], [79, 93], [94, 100], [101, 103], [104, 114], [114, 115], [116, 130], [131, 133], [134, 138], [139, 140], [141, 155], [156, 158], [159, 169], [170, 178], [178, 179]]}
{"doc_key": "ai-test-391", "ner": [[8, 8, "programlang"], [10, 10, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["ou", "atrav\u00e9s", "de", "interfaces", "de", "alto", "n\u00edvel", "para", "Java", "e", "Tcl", "."], "sentence-detokenized": "ou atrav\u00e9s de interfaces de alto n\u00edvel para Java e Tcl.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 24], [25, 27], [28, 32], [33, 38], [39, 43], [44, 48], [49, 50], [51, 54], [54, 55]]}
{"doc_key": "ai-test-392", "ner": [[12, 14, "algorithm"], [21, 21, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 14, 21, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Em", "investiga\u00e7\u00e3o", "recente", ",", "m\u00e9todos", "baseados", "no", "n\u00facleo", ",", "tais", "como", "m\u00e1quinas", "de", "suporte", "vectorial", ",", "demonstraram", "um", "desempenho", "superior", "na", "supervis\u00e3o", "."], "sentence-detokenized": "Em investiga\u00e7\u00e3o recente, m\u00e9todos baseados no n\u00facleo, tais como m\u00e1quinas de suporte vectorial, demonstraram um desempenho superior na supervis\u00e3o.", "token2charspan": [[0, 2], [3, 15], [16, 23], [23, 24], [25, 32], [33, 41], [42, 44], [45, 51], [51, 52], [53, 57], [58, 62], [63, 71], [72, 74], [75, 82], [83, 92], [92, 93], [94, 106], [107, 109], [110, 120], [121, 129], [130, 132], [133, 143], [143, 144]]}
{"doc_key": "ai-test-393", "ner": [[15, 16, "misc"], [23, 23, "researcher"], [25, 25, "researcher"], [33, 33, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 33, 33, "usage", "", false, false], [25, 25, 33, 33, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Para", "ilustrar", "os", "princ\u00edpios", "b\u00e1sicos", "do", "ensacamento", ",", "segue-se", "uma", "an\u00e1lise", "sobre", "a", "rela\u00e7\u00e3o", "entre", "o", "ozono", "e", "a", "temperatura", "(", "dados", "de", "Rousseeuw", "e", "Leroy", "(", "1986", ")", ",", "an\u00e1lise", "feita", "em", "R", ")", "."], "sentence-detokenized": "Para ilustrar os princ\u00edpios b\u00e1sicos do ensacamento, segue-se uma an\u00e1lise sobre a rela\u00e7\u00e3o entre o ozono e a temperatura (dados de Rousseeuw e Leroy (1986), an\u00e1lise feita em R).", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 27], [28, 35], [36, 38], [39, 50], [50, 51], [52, 60], [61, 64], [65, 72], [73, 78], [79, 80], [81, 88], [89, 94], [95, 96], [97, 102], [103, 104], [105, 106], [107, 118], [119, 120], [120, 125], [126, 128], [129, 138], [139, 140], [141, 146], [147, 148], [148, 152], [152, 153], [153, 154], [155, 162], [163, 168], [169, 171], [172, 173], [173, 174], [174, 175]]}
{"doc_key": "ai-test-394", "ner": [[0, 1, "organisation"], [13, 16, "product"], [22, 23, "product"], [25, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 16, 0, 1, "artifact", "", false, false], [22, 23, 0, 1, "artifact", "", false, false], [25, 27, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Denso", "Wave", "\u00e9", "uma", "subsidi\u00e1ria", "que", "produz", "produtos", "de", "identifica\u00e7\u00e3o", "autom\u00e1tica", "(", "leitores", "de", "c\u00f3digos", "de", "barras", "e", "produtos", "relacionados", ")", ",", "robots", "industriais", "e", "controladores", "l\u00f3gicos", "program\u00e1veis", "."], "sentence-detokenized": "Denso Wave \u00e9 uma subsidi\u00e1ria que produz produtos de identifica\u00e7\u00e3o autom\u00e1tica (leitores de c\u00f3digos de barras e produtos relacionados), robots industriais e controladores l\u00f3gicos program\u00e1veis.", "token2charspan": [[0, 5], [6, 10], [11, 12], [13, 16], [17, 28], [29, 32], [33, 39], [40, 48], [49, 51], [52, 65], [66, 76], [77, 78], [78, 86], [87, 89], [90, 97], [98, 100], [101, 107], [108, 109], [110, 118], [119, 131], [131, 132], [132, 133], [134, 140], [141, 152], [153, 154], [155, 168], [169, 176], [177, 189], [189, 190]]}
{"doc_key": "ai-test-395", "ner": [[2, 5, "metrics"], [9, 9, "metrics"], [20, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 5, 20, 21, "compare", "", false, false], [9, 9, 2, 5, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Onde", "o", "sub-estudo", "de", "avalia\u00e7\u00e3o", "bilingue", "simplesmente", "calcula", "a", "precis\u00e3o", "do", "programa", "acrescentando", "o", "mesmo", "peso", "a", "cada", "um", ",", "o", "NIST", "tamb\u00e9m", "calcula", "o", "qu\u00e3o", "informativo", "\u00e9", "um", "determinado", "programa", "."], "sentence-detokenized": "Onde o sub-estudo de avalia\u00e7\u00e3o bilingue simplesmente calcula a precis\u00e3o do programa acrescentando o mesmo peso a cada um, o NIST tamb\u00e9m calcula o qu\u00e3o informativo \u00e9 um determinado programa.", "token2charspan": [[0, 4], [5, 6], [7, 17], [18, 20], [21, 30], [31, 39], [40, 52], [53, 60], [61, 62], [63, 71], [72, 74], [75, 83], [84, 97], [98, 99], [100, 105], [106, 110], [111, 112], [113, 117], [118, 120], [120, 121], [122, 123], [124, 128], [129, 135], [136, 143], [144, 145], [146, 150], [151, 162], [163, 164], [165, 167], [168, 179], [180, 188], [188, 189]]}
{"doc_key": "ai-test-396", "ner": [[15, 15, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Em", "particular", ",", "s\u00e3o", "utilizados", "durante", "o", "c\u00e1lculo", "da", "probabilidade", "de", "uma", "\u00e1rvore", "(", "em", "Bayesian", "e", "aproxima\u00e7\u00f5es", "de", "m\u00e1xima", "probabilidade", "\u00e0", "estimativa", "de", "\u00e1rvore", ")", "e", "s\u00e3o", "utilizados", "para", "estimar", "a", "dist\u00e2ncia", "evolutiva", "entre", "sequ\u00eancias", "a", "partir", "das", "diferen\u00e7as", "observadas", "entre", "as", "sequ\u00eancias", "."], "sentence-detokenized": "Em particular, s\u00e3o utilizados durante o c\u00e1lculo da probabilidade de uma \u00e1rvore (em Bayesian e aproxima\u00e7\u00f5es de m\u00e1xima probabilidade \u00e0 estimativa de \u00e1rvore) e s\u00e3o utilizados para estimar a dist\u00e2ncia evolutiva entre sequ\u00eancias a partir das diferen\u00e7as observadas entre as sequ\u00eancias.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 29], [30, 37], [38, 39], [40, 47], [48, 50], [51, 64], [65, 67], [68, 71], [72, 78], [79, 80], [80, 82], [83, 91], [92, 93], [94, 106], [107, 109], [110, 116], [117, 130], [131, 132], [133, 143], [144, 146], [147, 153], [153, 154], [155, 156], [157, 160], [161, 171], [172, 176], [177, 184], [185, 186], [187, 196], [197, 206], [207, 212], [213, 223], [224, 225], [226, 232], [233, 236], [237, 247], [248, 258], [259, 264], [265, 267], [268, 278], [278, 279]]}
{"doc_key": "ai-test-397", "ner": [[1, 3, "conference"], [24, 25, "misc"], [27, 27, "misc"], [55, 56, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[27, 27, 24, 25, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "Audio", "Engineering", "Society", "recomenda", "uma", "taxa", "de", "amostragem", "de", "48", "kHz", "para", "a", "maioria", "das", "aplica\u00e7\u00f5es", "mas", "d\u00e1", "reconhecimento", "a", "44,1", "kHz", "para", "discos", "compactos", "(", "CD", ")", "e", "outros", "usos", "de", "consumo", ",", "32", "kHz", "para", "aplica\u00e7\u00f5es", "relacionadas", "com", "a", "transmiss\u00e3o", ",", "e", "96", "kHz", "para", "uma", "maior", "largura", "de", "banda", "ou", "um", "filtro", "anti-aliasing", "relaxado", "."], "sentence-detokenized": "A Audio Engineering Society recomenda uma taxa de amostragem de 48 kHz para a maioria das aplica\u00e7\u00f5es mas d\u00e1 reconhecimento a 44,1 kHz para discos compactos (CD) e outros usos de consumo, 32 kHz para aplica\u00e7\u00f5es relacionadas com a transmiss\u00e3o, e 96 kHz para uma maior largura de banda ou um filtro anti-aliasing relaxado.", "token2charspan": [[0, 1], [2, 7], [8, 19], [20, 27], [28, 37], [38, 41], [42, 46], [47, 49], [50, 60], [61, 63], [64, 66], [67, 70], [71, 75], [76, 77], [78, 85], [86, 89], [90, 100], [101, 104], [105, 107], [108, 122], [123, 124], [125, 129], [130, 133], [134, 138], [139, 145], [146, 155], [156, 157], [157, 159], [159, 160], [161, 162], [163, 169], [170, 174], [175, 177], [178, 185], [185, 186], [187, 189], [190, 193], [194, 198], [199, 209], [210, 222], [223, 226], [227, 228], [229, 240], [240, 241], [242, 243], [244, 246], [247, 250], [251, 255], [256, 259], [260, 265], [266, 273], [274, 276], [277, 282], [283, 285], [286, 288], [289, 295], [296, 309], [310, 318], [318, 319]]}
{"doc_key": "ai-test-398", "ner": [[11, 11, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Foram", "feitos", "recursos", "para", "a", "afetividade", "de", "palavras", "e", "conceitos", "para", "WordNet", "{", "{", "{", "cite", "journal"], "sentence-detokenized": "Foram feitos recursos para a afetividade de palavras e conceitos para WordNet {{{cite journal", "token2charspan": [[0, 5], [6, 12], [13, 21], [22, 26], [27, 28], [29, 40], [41, 43], [44, 52], [53, 54], [55, 64], [65, 69], [70, 77], [78, 79], [79, 80], [80, 81], [81, 85], [86, 93]]}
{"doc_key": "ai-test-399", "ner": [[1, 2, "misc"], [20, 21, "person"], [26, 29, "person"], [36, 38, "person"], [44, 45, "organisation"], [64, 66, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[26, 29, 36, 38, "role", "acts_in", false, false], [44, 45, 36, 38, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["No", "an\u00e1glifo", "vermelho-verde", ",", "foram", "apresentados", "ao", "p\u00fablico", "tr\u00eas", "rolos", "de", "testes", ",", "que", "inclu\u00edram", "cenas", "rurais", ",", "filmagens", "de", "Marie", "Doro", ",", "um", "segmento", "de", "John", "B", ".", "Mason", "interpretando", "uma", "s\u00e9rie", "de", "passagens", "de", "Jim", "the", "Penman", "(", "um", "filme", "lan\u00e7ado", "por", "Famous", "Players-Lasky", "nesse", "ano", ",", "mas", "n\u00e3o", "em", "3D", ")", ",", "dan\u00e7arinos", "orientais", ",", "e", "um", "rolo", "de", "filmagens", "das", "Cataratas", "do", "Ni\u00e1gara", "."], "sentence-detokenized": "No an\u00e1glifo vermelho-verde, foram apresentados ao p\u00fablico tr\u00eas rolos de testes, que inclu\u00edram cenas rurais, filmagens de Marie Doro, um segmento de John B. Mason interpretando uma s\u00e9rie de passagens de Jim the Penman (um filme lan\u00e7ado por Famous Players-Lasky nesse ano, mas n\u00e3o em 3D), dan\u00e7arinos orientais, e um rolo de filmagens das Cataratas do Ni\u00e1gara.", "token2charspan": [[0, 2], [3, 11], [12, 26], [26, 27], [28, 33], [34, 46], [47, 49], [50, 57], [58, 62], [63, 68], [69, 71], [72, 78], [78, 79], [80, 83], [84, 93], [94, 99], [100, 106], [106, 107], [108, 117], [118, 120], [121, 126], [127, 131], [131, 132], [133, 135], [136, 144], [145, 147], [148, 152], [153, 154], [154, 155], [156, 161], [162, 175], [176, 179], [180, 185], [186, 188], [189, 198], [199, 201], [202, 205], [206, 209], [210, 216], [217, 218], [218, 220], [221, 226], [227, 234], [235, 238], [239, 245], [246, 259], [260, 265], [266, 269], [269, 270], [271, 274], [275, 278], [279, 281], [282, 284], [284, 285], [285, 286], [287, 297], [298, 307], [307, 308], [309, 310], [311, 313], [314, 318], [319, 321], [322, 331], [332, 335], [336, 345], [346, 348], [349, 356], [356, 357]]}
{"doc_key": "ai-test-400", "ner": [[8, 11, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Esta", "\u00e9", "uma", "forma", "particular", "de", "implementar", "a", "estimativa", "da", "m\u00e1xima", "probabilidade", "para", "este", "problema", "."], "sentence-detokenized": "Esta \u00e9 uma forma particular de implementar a estimativa da m\u00e1xima probabilidade para este problema.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 16], [17, 27], [28, 30], [31, 42], [43, 44], [45, 55], [56, 58], [59, 65], [66, 79], [80, 84], [85, 89], [90, 98], [98, 99]]}
{"doc_key": "ai-test-401", "ner": [[0, 4, "product"], [14, 14, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Servidores", "Web", "amigos", "do", "rastejador", ",", "e", "integra", "as", "caracter\u00edsticas", "dos", "sitesmaps", "e", "feeds", "RSS", "num", "mecanismo", "descentralizado", "para", "bi\u00f3logos", "computacionais", "e", "bio-inform\u00e1ticos", "transmitirem", "abertamente", "e", "recuperarem", "meta-dados", "sobre", "recursos", "biom\u00e9dicos", "."], "sentence-detokenized": "Servidores Web amigos do rastejador, e integra as caracter\u00edsticas dos sitesmaps e feeds RSS num mecanismo descentralizado para bi\u00f3logos computacionais e bio-inform\u00e1ticos transmitirem abertamente e recuperarem meta-dados sobre recursos biom\u00e9dicos.", "token2charspan": [[0, 10], [11, 14], [15, 21], [22, 24], [25, 35], [35, 36], [37, 38], [39, 46], [47, 49], [50, 65], [66, 69], [70, 79], [80, 81], [82, 87], [88, 91], [92, 95], [96, 105], [106, 121], [122, 126], [127, 135], [136, 150], [151, 152], [153, 169], [170, 182], [183, 194], [195, 196], [197, 208], [209, 219], [220, 225], [226, 234], [235, 245], [245, 246]]}
{"doc_key": "ai-test-402", "ner": [[3, 10, "misc"], [14, 19, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Est\u00e1", "coberto", "pelo", "American", "National", "Standards", "Institute", "/", "NISO", "standard", "Z39.50", ",", "e", "pela", "International", "Organization", "for", "Standardization", "standard", "23950", "."], "sentence-detokenized": "Est\u00e1 coberto pelo American National Standards Institute / NISO standard Z39.50, e pela International Organization for Standardization standard 23950.", "token2charspan": [[0, 4], [5, 12], [13, 17], [18, 26], [27, 35], [36, 45], [46, 55], [56, 57], [58, 62], [63, 71], [72, 78], [78, 79], [80, 81], [82, 86], [87, 100], [101, 113], [114, 117], [118, 133], [134, 142], [143, 148], [148, 149]]}
{"doc_key": "ai-test-403", "ner": [[13, 15, "misc"], [20, 21, "metrics"], [25, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Os", "codificadores", "e", "descodificadores", "s\u00e3o", "treinados", "para", "pegar", "numa", "frase", "e", "reproduzir", "a", "distribui\u00e7\u00e3o", "de", "uma", "par\u00e1frase", "correspondente", ",", "minimizando", "a", "perplexidade", "usando", "uma", "simples", "descida", "de", "gradiente", "estoc\u00e1stico", "."], "sentence-detokenized": "Os codificadores e descodificadores s\u00e3o treinados para pegar numa frase e reproduzir a distribui\u00e7\u00e3o de uma par\u00e1frase correspondente, minimizando a perplexidade usando uma simples descida de gradiente estoc\u00e1stico.", "token2charspan": [[0, 2], [3, 16], [17, 18], [19, 35], [36, 39], [40, 49], [50, 54], [55, 60], [61, 65], [66, 71], [72, 73], [74, 84], [85, 86], [87, 99], [100, 102], [103, 106], [107, 116], [117, 131], [131, 132], [133, 144], [145, 146], [147, 159], [160, 166], [167, 170], [171, 178], [179, 186], [187, 189], [190, 199], [200, 211], [211, 212]]}
{"doc_key": "ai-test-404", "ner": [[6, 8, "field"], [11, 14, "task"], [17, 22, "task"], [38, 43, "task"], [46, 52, "task"], [56, 65, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 14, 6, 8, "part-of", "task_part_of_field", false, false], [17, 22, 6, 8, "part-of", "task_part_of_field", false, false], [38, 43, 6, 8, "part-of", "task_part_of_field", false, false], [46, 52, 6, 8, "part-of", "task_part_of_field", false, false], [56, 65, 6, 8, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Outras", "aplica\u00e7\u00f5es", "t\u00edpicas", "das", "t\u00e9cnicas", "de", "reconhecimento", "de", "padr\u00f5es", "s\u00e3o", "o", "reconhecimento", "autom\u00e1tico", "da", "fala", ",", "a", "classifica\u00e7\u00e3o", "do", "texto", "em", "v\u00e1rias", "categorias", "(", "por", "exemplo", ",", "mensagens", "de", "correio", "electr\u00f3nico", "spam", "/", "n\u00e3o", "spam", ")", ",", "o", "reconhecimento", "da", "caligrafia", "em", "envelopes", "postais", ",", "o", "reconhecimento", "autom\u00e1tico", "de", "imagens", "de", "rostos", "humanos", ",", "ou", "a", "extrac\u00e7\u00e3o", "de", "imagens", "da", "caligrafia", "a", "partir", "de", "formul\u00e1rios", "m\u00e9dicos", "."], "sentence-detokenized": "Outras aplica\u00e7\u00f5es t\u00edpicas das t\u00e9cnicas de reconhecimento de padr\u00f5es s\u00e3o o reconhecimento autom\u00e1tico da fala, a classifica\u00e7\u00e3o do texto em v\u00e1rias categorias (por exemplo, mensagens de correio electr\u00f3nico spam / n\u00e3o spam), o reconhecimento da caligrafia em envelopes postais, o reconhecimento autom\u00e1tico de imagens de rostos humanos, ou a extrac\u00e7\u00e3o de imagens da caligrafia a partir de formul\u00e1rios m\u00e9dicos.", "token2charspan": [[0, 6], [7, 17], [18, 25], [26, 29], [30, 38], [39, 41], [42, 56], [57, 59], [60, 67], [68, 71], [72, 73], [74, 88], [89, 99], [100, 102], [103, 107], [107, 108], [109, 110], [111, 124], [125, 127], [128, 133], [134, 136], [137, 143], [144, 154], [155, 156], [156, 159], [160, 167], [167, 168], [169, 178], [179, 181], [182, 189], [190, 201], [202, 206], [207, 208], [209, 212], [213, 217], [217, 218], [218, 219], [220, 221], [222, 236], [237, 239], [240, 250], [251, 253], [254, 263], [264, 271], [271, 272], [273, 274], [275, 289], [290, 300], [301, 303], [304, 311], [312, 314], [315, 321], [322, 329], [329, 330], [331, 333], [334, 335], [336, 345], [346, 348], [349, 356], [357, 359], [360, 370], [371, 372], [373, 379], [380, 382], [383, 394], [395, 402], [402, 403]]}
{"doc_key": "ai-test-405", "ner": [[0, 3, "algorithm"], [13, 15, "field"], [17, 19, "task"], [21, 22, "task"], [24, 27, "task"], [30, 34, "task"], [36, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 15, 0, 3, "usage", "", false, false], [17, 19, 0, 3, "usage", "", false, false], [21, 22, 0, 3, "usage", "", false, false], [24, 27, 0, 3, "usage", "", false, false], [30, 34, 0, 3, "usage", "", false, false], [36, 37, 0, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["As", "redes", "neurais", "artificiais", "t\u00eam", "sido", "utilizadas", "numa", "variedade", "de", "tarefas", ",", "incluindo", "vis\u00e3o", "por", "computador", ",", "reconhecimento", "da", "fala", ",", "tradu\u00e7\u00e3o", "autom\u00e1tica", ",", "filtragem", "de", "redes", "sociais", ",", "jogos", "de", "tabuleiro", "e", "de", "v\u00eddeo", "e", "diagn\u00f3stico", "m\u00e9dico", "."], "sentence-detokenized": "As redes neurais artificiais t\u00eam sido utilizadas numa variedade de tarefas, incluindo vis\u00e3o por computador, reconhecimento da fala, tradu\u00e7\u00e3o autom\u00e1tica, filtragem de redes sociais, jogos de tabuleiro e de v\u00eddeo e diagn\u00f3stico m\u00e9dico.", "token2charspan": [[0, 2], [3, 8], [9, 16], [17, 28], [29, 32], [33, 37], [38, 48], [49, 53], [54, 63], [64, 66], [67, 74], [74, 75], [76, 85], [86, 91], [92, 95], [96, 106], [106, 107], [108, 122], [123, 125], [126, 130], [130, 131], [132, 140], [141, 151], [151, 152], [153, 162], [163, 165], [166, 171], [172, 179], [179, 180], [181, 186], [187, 189], [190, 199], [200, 201], [202, 204], [205, 210], [211, 212], [213, 224], [225, 231], [231, 232]]}
{"doc_key": "ai-test-406", "ner": [[2, 3, "organisation"], [4, 4, "product"], [15, 15, "product"], [18, 18, "organisation"], [19, 20, "product"], [22, 22, "product"], [24, 26, "product"], [28, 28, "product"], [30, 30, "programlang"], [40, 41, "field"], [47, 50, "product"], [52, 52, "algorithm"], [54, 54, "algorithm"], [56, 56, "algorithm"], [59, 59, "product"], [64, 66, "task"], [77, 79, "algorithm"], [82, 82, "product"], [84, 84, "product"], [89, 91, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "relations": [[4, 4, 2, 3, "origin", "", false, false], [4, 4, 15, 15, "named", "same", false, false], [4, 4, 47, 50, "named", "same", false, false], [30, 30, 40, 41, "related-to", "used_for", false, false], [52, 52, 30, 30, "part-of", "", true, false], [52, 52, 47, 50, "origin", "", true, false], [54, 54, 30, 30, "part-of", "", true, false], [54, 54, 47, 50, "origin", "", true, false], [56, 56, 30, 30, "part-of", "", true, false], [56, 56, 47, 50, "origin", "", true, false], [59, 59, 64, 66, "related-to", "used_for", false, false], [77, 79, 59, 59, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Exemplos", "incluem", "Salford", "Systems", "CART", "(", "que", "licenciou", "o", "c\u00f3digo", "propriet\u00e1rio", "dos", "autores", "originais", "do", "CART", ")", ",", "IBM", "SPSS", "Modeler", ",", "RapidMiner", ",", "SAS", "Enterprise", "Miner", ",", "Matlab", ",", "R", "(", "um", "ambiente", "de", "software", "de", "c\u00f3digo", "aberto", "para", "computa\u00e7\u00e3o", "estat\u00edstica", ",", "que", "inclui", "v\u00e1rias", "implementa\u00e7\u00f5es", "CART", ",", "tais", "como", "pacotes", "rpart", ",", "party", "e", "randomForest", ")", ",", "Weka", "(", "uma", "suite", "de", "minera\u00e7\u00e3o", "de", "dados", "gratuita", "e", "de", "c\u00f3digo", "aberto", ",", "cont\u00e9m", "muitos", "algoritmos", "de", "\u00e1rvore", "de", "decis\u00e3o", ")", ",", "Orange", ",", "KNIME", ",", "linguagem", "de", "programa\u00e7\u00e3o", "Microsoft", "SQL", "Server", ")", "."], "sentence-detokenized": "Exemplos incluem Salford Systems CART (que licenciou o c\u00f3digo propriet\u00e1rio dos autores originais do CART), IBM SPSS Modeler, RapidMiner, SAS Enterprise Miner, Matlab, R (um ambiente de software de c\u00f3digo aberto para computa\u00e7\u00e3o estat\u00edstica, que inclui v\u00e1rias implementa\u00e7\u00f5es CART, tais como pacotes rpart, party e randomForest), Weka (uma suite de minera\u00e7\u00e3o de dados gratuita e de c\u00f3digo aberto, cont\u00e9m muitos algoritmos de \u00e1rvore de decis\u00e3o), Orange, KNIME, linguagem de programa\u00e7\u00e3o Microsoft SQL Server).", "token2charspan": [[0, 8], [9, 16], [17, 24], [25, 32], [33, 37], [38, 39], [39, 42], [43, 52], [53, 54], [55, 61], [62, 74], [75, 78], [79, 86], [87, 96], [97, 99], [100, 104], [104, 105], [105, 106], [107, 110], [111, 115], [116, 123], [123, 124], [125, 135], [135, 136], [137, 140], [141, 151], [152, 157], [157, 158], [159, 165], [165, 166], [167, 168], [169, 170], [170, 172], [173, 181], [182, 184], [185, 193], [194, 196], [197, 203], [204, 210], [211, 215], [216, 226], [227, 238], [238, 239], [240, 243], [244, 250], [251, 257], [258, 272], [273, 277], [277, 278], [279, 283], [284, 288], [289, 296], [297, 302], [302, 303], [304, 309], [310, 311], [312, 324], [324, 325], [325, 326], [327, 331], [332, 333], [333, 336], [337, 342], [343, 345], [346, 355], [356, 358], [359, 364], [365, 373], [374, 375], [376, 378], [379, 385], [386, 392], [392, 393], [394, 400], [401, 407], [408, 418], [419, 421], [422, 428], [429, 431], [432, 439], [439, 440], [440, 441], [442, 448], [448, 449], [450, 455], [455, 456], [457, 466], [467, 469], [470, 481], [482, 491], [492, 495], [496, 502], [502, 503], [503, 504]]}
{"doc_key": "ai-test-407", "ner": [[0, 3, "algorithm"], [5, 5, "algorithm"], [11, 12, "researcher"], [14, 16, "university"], [18, 19, "researcher"], [21, 24, "organisation"], [26, 26, "organisation"], [35, 37, "researcher"], [39, 41, "researcher"], [43, 44, "organisation"], [59, 63, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 3, 11, 12, "origin", "", false, false], [0, 3, 18, 19, "origin", "", false, false], [0, 3, 35, 37, "origin", "", false, false], [0, 3, 39, 41, "origin", "", false, false], [5, 5, 0, 3, "named", "", false, false], [11, 12, 14, 16, "physical", "", false, false], [11, 12, 14, 16, "role", "", false, false], [18, 19, 21, 24, "physical", "", false, false], [18, 19, 21, 24, "role", "", false, false], [26, 26, 21, 24, "named", "", false, false], [35, 37, 43, 44, "physical", "", false, false], [35, 37, 43, 44, "role", "", false, false], [39, 41, 43, 44, "physical", "", false, false], [39, 41, 43, 44, "role", "", false, false], [59, 63, 0, 3, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["A", "codifica\u00e7\u00e3o", "preditiva", "linear", "(", "LPC", ")", "foi", "inicialmente", "desenvolvida", "por", "Fumitada", "Itakura", "da", "Universidade", "de", "Nagoya", "e", "Shuzo", "Saito", "da", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "em", "1966", ",", "e", "posteriormente", "desenvolvida", "por", "Bishnu", "S.", "Atal", "e", "Manfred", "R.", "Schroeder", "nos", "Bell", "Labs", "durante", "o", "in\u00edcio", "da", "d\u00e9cada", "de", "1970", ",", "tornando-se", "a", "base", "para", "o", "primeiro", "sintetizador", "de", "fala", "DSP", "chips", "no", "final", "da", "d\u00e9cada", "de", "1970", "."], "sentence-detokenized": "A codifica\u00e7\u00e3o preditiva linear (LPC) foi inicialmente desenvolvida por Fumitada Itakura da Universidade de Nagoya e Shuzo Saito da Nippon Telegraph and Telephone (NTT) em 1966, e posteriormente desenvolvida por Bishnu S. Atal e Manfred R. Schroeder nos Bell Labs durante o in\u00edcio da d\u00e9cada de 1970, tornando-se a base para o primeiro sintetizador de fala DSP chips no final da d\u00e9cada de 1970.", "token2charspan": [[0, 1], [2, 13], [14, 23], [24, 30], [31, 32], [32, 35], [35, 36], [37, 40], [41, 53], [54, 66], [67, 70], [71, 79], [80, 87], [88, 90], [91, 103], [104, 106], [107, 113], [114, 115], [116, 121], [122, 127], [128, 130], [131, 137], [138, 147], [148, 151], [152, 161], [162, 163], [163, 166], [166, 167], [168, 170], [171, 175], [175, 176], [177, 178], [179, 193], [194, 206], [207, 210], [211, 217], [218, 220], [221, 225], [226, 227], [228, 235], [236, 238], [239, 248], [249, 252], [253, 257], [258, 262], [263, 270], [271, 272], [273, 279], [280, 282], [283, 289], [290, 292], [293, 297], [297, 298], [299, 310], [311, 312], [313, 317], [318, 322], [323, 324], [325, 333], [334, 346], [347, 349], [350, 354], [355, 358], [359, 364], [365, 367], [368, 373], [374, 376], [377, 383], [384, 386], [387, 391], [391, 392]]}
{"doc_key": "ai-test-408", "ner": [[1, 1, "metrics"], [6, 6, "metrics"], [9, 9, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 1, 1, "part-of", "", false, false], [9, 9, 1, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Um", "F-score", "\u00e9", "uma", "combina\u00e7\u00e3o", "da", "precis\u00e3o", "e", "da", "recorda\u00e7\u00e3o", ",", "fornecendo", "uma", "\u00fanica", "pontua\u00e7\u00e3o", "."], "sentence-detokenized": "Um F-score \u00e9 uma combina\u00e7\u00e3o da precis\u00e3o e da recorda\u00e7\u00e3o, fornecendo uma \u00fanica pontua\u00e7\u00e3o.", "token2charspan": [[0, 2], [3, 10], [11, 12], [13, 16], [17, 27], [28, 30], [31, 39], [40, 41], [42, 44], [45, 55], [55, 56], [57, 67], [68, 71], [72, 77], [78, 87], [87, 88]]}
{"doc_key": "ai-test-409", "ner": [[3, 5, "field"], [12, 18, "task"], [24, 27, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 18, 3, 5, "part-of", "task_part_of_field", false, false], [24, 27, 3, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "tarefas", "de", "an\u00e1lise", "de", "imagem", "podem", "ser", "t\u00e3o", "simples", "como", "a", "leitura", "de", "c\u00f3digos", "de", "barras", "d", "tags", "ou", "t\u00e3o", "sofisticadas", "como", "o", "sistema", "de", "reconhecimento", "facial", "."], "sentence-detokenized": "As tarefas de an\u00e1lise de imagem podem ser t\u00e3o simples como a leitura de c\u00f3digos de barras d tags ou t\u00e3o sofisticadas como o sistema de reconhecimento facial.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 21], [22, 24], [25, 31], [32, 37], [38, 41], [42, 45], [46, 53], [54, 58], [59, 60], [61, 68], [69, 71], [72, 79], [80, 82], [83, 89], [90, 91], [92, 96], [97, 99], [100, 103], [104, 116], [117, 121], [122, 123], [124, 131], [132, 134], [135, 149], [150, 156], [156, 157]]}
{"doc_key": "ai-test-410", "ner": [[4, 7, "algorithm"], [26, 27, "algorithm"], [35, 38, "algorithm"], [43, 43, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[35, 38, 26, 27, "type-of", "", false, false], [43, 43, 35, 38, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["O", "caso", "especial", "das", "m\u00e1quinas", "de", "suporte", "linear-vector", "pode", "ser", "resolvido", "mais", "eficientemente", "pelo", "mesmo", "tipo", "de", "algoritmos", "para", "optimizar", "a", "sua", "prima", "pr\u00f3xima", ",", "a", "regress\u00e3o", "log\u00edstica", ";", "esta", "classe", "de", "algoritmos", "inclui", "a", "descida", "de", "gradiente", "estoc\u00e1stico", "(", "por", "exemplo", ",", "PEGASOS", ")", "."], "sentence-detokenized": "O caso especial das m\u00e1quinas de suporte linear-vector pode ser resolvido mais eficientemente pelo mesmo tipo de algoritmos para optimizar a sua prima pr\u00f3xima, a regress\u00e3o log\u00edstica; esta classe de algoritmos inclui a descida de gradiente estoc\u00e1stico (por exemplo, PEGASOS).", "token2charspan": [[0, 1], [2, 6], [7, 15], [16, 19], [20, 28], [29, 31], [32, 39], [40, 53], [54, 58], [59, 62], [63, 72], [73, 77], [78, 92], [93, 97], [98, 103], [104, 108], [109, 111], [112, 122], [123, 127], [128, 137], [138, 139], [140, 143], [144, 149], [150, 157], [157, 158], [159, 160], [161, 170], [171, 180], [180, 181], [182, 186], [187, 193], [194, 196], [197, 207], [208, 214], [215, 216], [217, 224], [225, 227], [228, 237], [238, 249], [250, 251], [251, 254], [255, 262], [262, 263], [264, 271], [271, 272], [272, 273]]}
{"doc_key": "ai-test-411", "ner": [[4, 4, "product"], [8, 8, "product"], [26, 26, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 8, 8, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Quando", "se", "pergunta", "ao", "Siri", "sobre", "um", "dispositivo", "iOS", "Se", "tem", "um", "animal", "de", "estima\u00e7\u00e3o", "?", ",", "uma", "das", "respostas", "\u00e9", "que", "eu", "costumava", "ter", "uma", "AIBO", "."], "sentence-detokenized": "Quando se pergunta ao Siri sobre um dispositivo iOS Se tem um animal de estima\u00e7\u00e3o?, uma das respostas \u00e9 que eu costumava ter uma AIBO.", "token2charspan": [[0, 6], [7, 9], [10, 18], [19, 21], [22, 26], [27, 32], [33, 35], [36, 47], [48, 51], [52, 54], [55, 58], [59, 61], [62, 68], [69, 71], [72, 81], [81, 82], [82, 83], [84, 87], [88, 91], [92, 101], [102, 103], [104, 107], [108, 110], [111, 120], [121, 124], [125, 128], [129, 133], [133, 134]]}
{"doc_key": "ai-test-412", "ner": [[1, 3, "task"], [6, 8, "metrics"], [10, 10, "metrics"], [14, 14, "metrics"], [16, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 8, 1, 3, "part-of", "", false, false], [10, 10, 6, 8, "named", "", false, false], [14, 14, 1, 3, "part-of", "", false, false], [16, 16, 14, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Na", "recupera\u00e7\u00e3o", "de", "informa\u00e7\u00e3o", ",", "o", "valor", "preditivo", "positivo", "chama-se", "precis\u00e3o", ",", "e", "a", "sensibilidade", "chama-se", "recorda\u00e7\u00e3o", "."], "sentence-detokenized": "Na recupera\u00e7\u00e3o de informa\u00e7\u00e3o, o valor preditivo positivo chama-se precis\u00e3o, e a sensibilidade chama-se recorda\u00e7\u00e3o.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 28], [28, 29], [30, 31], [32, 37], [38, 47], [48, 56], [57, 65], [66, 74], [74, 75], [76, 77], [78, 79], [80, 93], [94, 102], [103, 113], [113, 114]]}
{"doc_key": "ai-test-413", "ner": [[11, 13, "field"], [15, 15, "task"], [17, 17, "task"], [19, 21, "task"], [43, 45, "task"], [47, 48, "task"], [50, 55, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 15, 11, 13, "part-of", "task_part_of_field", false, false], [17, 17, 11, 13, "part-of", "task_part_of_field", false, false], [19, 21, 11, 13, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Em", "particular", ",", "a", "sua", "investiga\u00e7\u00e3o", "centrou-se", "em", "\u00e1reas", "como", "a", "extrac\u00e7\u00e3o", "de", "texto", "(", "extrac\u00e7\u00e3o", ",", "categoriza\u00e7\u00e3o", ",", "detec\u00e7\u00e3o", "de", "novidade", ")", "e", "em", "novos", "quadros", "te\u00f3ricos", ",", "tais", "como", "uma", "teoria", "unificada", "baseada", "em", "utilidades", "que", "faz", "a", "ponte", "entre", "a", "recupera\u00e7\u00e3o", "de", "informa\u00e7\u00e3o", ",", "sumariza\u00e7\u00e3o", "autom\u00e1tica", ",", "resposta", "a", "perguntas", "de", "texto", "livre", "e", "tarefas", "relacionadas", "."], "sentence-detokenized": "Em particular, a sua investiga\u00e7\u00e3o centrou-se em \u00e1reas como a extrac\u00e7\u00e3o de texto (extrac\u00e7\u00e3o, categoriza\u00e7\u00e3o, detec\u00e7\u00e3o de novidade) e em novos quadros te\u00f3ricos, tais como uma teoria unificada baseada em utilidades que faz a ponte entre a recupera\u00e7\u00e3o de informa\u00e7\u00e3o, sumariza\u00e7\u00e3o autom\u00e1tica, resposta a perguntas de texto livre e tarefas relacionadas.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 16], [17, 20], [21, 33], [34, 44], [45, 47], [48, 53], [54, 58], [59, 60], [61, 70], [71, 73], [74, 79], [80, 81], [81, 90], [90, 91], [92, 105], [105, 106], [107, 115], [116, 118], [119, 127], [127, 128], [129, 130], [131, 133], [134, 139], [140, 147], [148, 156], [156, 157], [158, 162], [163, 167], [168, 171], [172, 178], [179, 188], [189, 196], [197, 199], [200, 210], [211, 214], [215, 218], [219, 220], [221, 226], [227, 232], [233, 234], [235, 246], [247, 249], [250, 260], [260, 261], [262, 273], [274, 284], [284, 285], [286, 294], [295, 296], [297, 306], [307, 309], [310, 315], [316, 321], [322, 323], [324, 331], [332, 344], [344, 345]]}
{"doc_key": "ai-test-414", "ner": [[0, 2, "product"], [4, 5, "product"], [12, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 0, 2, "part-of", "", false, false], [12, 17, 0, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Os", "rob\u00f4s", "Delta", "t\u00eam", "actuadores", "rotativos", "montados", "em", "base", "que", "movem", "um", "bra\u00e7o", "leve", ",", "r\u00edgido", "e", "paralelogramo", "."], "sentence-detokenized": "Os rob\u00f4s Delta t\u00eam actuadores rotativos montados em base que movem um bra\u00e7o leve, r\u00edgido e paralelogramo.", "token2charspan": [[0, 2], [3, 8], [9, 14], [15, 18], [19, 29], [30, 39], [40, 48], [49, 51], [52, 56], [57, 60], [61, 66], [67, 69], [70, 75], [76, 80], [80, 81], [82, 88], [89, 90], [91, 104], [104, 105]]}
{"doc_key": "ai-test-415", "ner": [[7, 12, "metrics"], [14, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Os", "quatro", "resultados", "podem", "ser", "formulados", "numa", "tabela", "de", "conting\u00eancia", "2", "\u00d7", "2", "ou", "matriz", "de", "confus\u00e3o", ",", "como", "se", "segue", ":"], "sentence-detokenized": "Os quatro resultados podem ser formulados numa tabela de conting\u00eancia 2 \u00d7 2 ou matriz de confus\u00e3o, como se segue:", "token2charspan": [[0, 2], [3, 9], [10, 20], [21, 26], [27, 30], [31, 41], [42, 46], [47, 53], [54, 56], [57, 69], [70, 71], [72, 73], [74, 75], [76, 78], [79, 85], [86, 88], [89, 97], [97, 98], [99, 103], [104, 106], [107, 112], [112, 113]]}
{"doc_key": "ai-test-416", "ner": [[4, 6, "field"], [33, 35, "task"], [41, 43, "task"], [49, 53, "task"], [55, 58, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[33, 35, 4, 6, "part-of", "task_part_of_field", false, false], [41, 43, 4, 6, "part-of", "task_part_of_field", false, false], [49, 53, 4, 6, "part-of", "task_part_of_field", false, false], [55, 58, 4, 6, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "tarefa", "real", "de", "minera\u00e7\u00e3o", "de", "dados", "\u00e9", "a", "an\u00e1lise", "semi-autom\u00e1tica", "ou", "autom\u00e1tica", "de", "grandes", "quantidades", "de", "dados", "para", "extrair", "padr\u00f5es", "desconhecidos", "e", "interessantes", ",", "tais", "como", "grupos", "de", "registos", "de", "dados", "(", "an\u00e1lise", "de", "agrupamento", ")", ",", "registos", "invulgares", "(", "detec\u00e7\u00e3o", "de", "anomalias", ")", ",", "e", "depend\u00eancias", "(", "regra", "de", "associa\u00e7\u00e3o", "de", "minera\u00e7\u00e3o", ",", "minera\u00e7\u00e3o", "de", "padr\u00f5es", "sequenciais", ")", "."], "sentence-detokenized": "A tarefa real de minera\u00e7\u00e3o de dados \u00e9 a an\u00e1lise semi-autom\u00e1tica ou autom\u00e1tica de grandes quantidades de dados para extrair padr\u00f5es desconhecidos e interessantes, tais como grupos de registos de dados (an\u00e1lise de agrupamento), registos invulgares (detec\u00e7\u00e3o de anomalias), e depend\u00eancias (regra de associa\u00e7\u00e3o de minera\u00e7\u00e3o, minera\u00e7\u00e3o de padr\u00f5es sequenciais).", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 16], [17, 26], [27, 29], [30, 35], [36, 37], [38, 39], [40, 47], [48, 63], [64, 66], [67, 77], [78, 80], [81, 88], [89, 100], [101, 103], [104, 109], [110, 114], [115, 122], [123, 130], [131, 144], [145, 146], [147, 160], [160, 161], [162, 166], [167, 171], [172, 178], [179, 181], [182, 190], [191, 193], [194, 199], [200, 201], [201, 208], [209, 211], [212, 223], [223, 224], [224, 225], [226, 234], [235, 245], [246, 247], [247, 255], [256, 258], [259, 268], [268, 269], [269, 270], [271, 272], [273, 285], [286, 287], [287, 292], [293, 295], [296, 306], [307, 309], [310, 319], [319, 320], [321, 330], [331, 333], [334, 341], [342, 353], [353, 354], [354, 355]]}
{"doc_key": "ai-test-417", "ner": [[2, 4, "product"], [7, 9, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 4, 7, 9, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Para", "um", "sistema", "de", "recomenda\u00e7\u00e3o", ",", "a", "an\u00e1lise", "dos", "sentimentos", "provou", "ser", "uma", "t\u00e9cnica", "valiosa", "."], "sentence-detokenized": "Para um sistema de recomenda\u00e7\u00e3o, a an\u00e1lise dos sentimentos provou ser uma t\u00e9cnica valiosa.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 31], [31, 32], [33, 34], [35, 42], [43, 46], [47, 58], [59, 65], [66, 69], [70, 73], [74, 81], [82, 89], [89, 90]]}
{"doc_key": "ai-test-418", "ner": [[4, 4, "misc"], [15, 15, "product"], [40, 40, "organisation"], [42, 44, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 15, 15, "usage", "", false, false], [40, 40, 42, 44, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Por", "acaso", ",", "os", "alem\u00e3es", "tinham", "escolhido", "muito", "mal", "a", "frequ\u00eancia", "de", "funcionamento", "do", "sistema", "Wotan", ";", "este", "funcionava", "em", "45", "MHz", ",", "que", "por", "acaso", "era", "apenas", "a", "frequ\u00eancia", "do", "potente", ",", "mas", "dormente", ",", "transmissor", "de", "televis\u00e3o", "da", "BBC", "no", "Pal\u00e1cio", "de", "Alexandra", "."], "sentence-detokenized": "Por acaso, os alem\u00e3es tinham escolhido muito mal a frequ\u00eancia de funcionamento do sistema Wotan; este funcionava em 45 MHz, que por acaso era apenas a frequ\u00eancia do potente, mas dormente, transmissor de televis\u00e3o da BBC no Pal\u00e1cio de Alexandra.", "token2charspan": [[0, 3], [4, 9], [9, 10], [11, 13], [14, 21], [22, 28], [29, 38], [39, 44], [45, 48], [49, 50], [51, 61], [62, 64], [65, 78], [79, 81], [82, 89], [90, 95], [95, 96], [97, 101], [102, 112], [113, 115], [116, 118], [119, 122], [122, 123], [124, 127], [128, 131], [132, 137], [138, 141], [142, 148], [149, 150], [151, 161], [162, 164], [165, 172], [172, 173], [174, 177], [178, 186], [186, 187], [188, 199], [200, 202], [203, 212], [213, 215], [216, 219], [220, 222], [223, 230], [231, 233], [234, 243], [243, 244]]}
{"doc_key": "ai-test-419", "ner": [[7, 12, "metrics"], [14, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Os", "quatro", "resultados", "podem", "ser", "formulados", "numa", "tabela", "de", "conting\u00eancia", "2", "\u00d7", "2", "ou", "matriz", "de", "confus\u00e3o", ",", "como", "se", "segue", ":"], "sentence-detokenized": "Os quatro resultados podem ser formulados numa tabela de conting\u00eancia 2 \u00d7 2 ou matriz de confus\u00e3o, como se segue:", "token2charspan": [[0, 2], [3, 9], [10, 20], [21, 26], [27, 30], [31, 41], [42, 46], [47, 53], [54, 56], [57, 69], [70, 71], [72, 73], [74, 75], [76, 78], [79, 85], [86, 88], [89, 97], [97, 98], [99, 103], [104, 106], [107, 112], [112, 113]]}
{"doc_key": "ai-test-420", "ner": [[1, 4, "misc"], [12, 12, "misc"], [14, 14, "product"], [16, 16, "product"], [18, 20, "product"], [30, 30, "misc"], [45, 47, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[14, 14, 12, 12, "usage", "", false, false], [16, 16, 12, 12, "usage", "", false, false], [18, 20, 16, 16, "named", "", false, false], [30, 30, 12, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Em", "aplica\u00e7\u00f5es", "da", "Web", "Sem\u00e2ntica", ",", "e", "em", "aplica\u00e7\u00f5es", "relativamente", "populares", "de", "RDF", "como", "RSS", "e", "FOAF", "(", "Friend", "a", "Friend", ")", ",", "os", "recursos", "tendem", "a", "ser", "representados", "por", "URIs", "que", "intencionalmente", "denotam", ",", "e", "podem", "ser", "utilizados", "para", "aceder", "a", "dados", "reais", "na", "World", "Wide", "Web", "."], "sentence-detokenized": "Em aplica\u00e7\u00f5es da Web Sem\u00e2ntica, e em aplica\u00e7\u00f5es relativamente populares de RDF como RSS e FOAF (Friend a Friend), os recursos tendem a ser representados por URIs que intencionalmente denotam, e podem ser utilizados para aceder a dados reais na World Wide Web.", "token2charspan": [[0, 2], [3, 13], [14, 16], [17, 20], [21, 30], [30, 31], [32, 33], [34, 36], [37, 47], [48, 61], [62, 71], [72, 74], [75, 78], [79, 83], [84, 87], [88, 89], [90, 94], [95, 96], [96, 102], [103, 104], [105, 111], [111, 112], [112, 113], [114, 116], [117, 125], [126, 132], [133, 134], [135, 138], [139, 152], [153, 156], [157, 161], [162, 165], [166, 182], [183, 190], [190, 191], [192, 193], [194, 199], [200, 203], [204, 214], [215, 219], [220, 226], [227, 228], [229, 234], [235, 240], [241, 243], [244, 249], [250, 254], [255, 258], [258, 259]]}
{"doc_key": "ai-test-421", "ner": [[1, 7, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "Associa\u00e7\u00e3o", "para", "o", "Progresso", "da", "Intelig\u00eancia", "Artificial", "estudou", "este", "tema", "em", "profundidade"], "sentence-detokenized": "A Associa\u00e7\u00e3o para o Progresso da Intelig\u00eancia Artificial estudou este tema em profundidade", "token2charspan": [[0, 1], [2, 12], [13, 17], [18, 19], [20, 29], [30, 32], [33, 45], [46, 56], [57, 64], [65, 69], [70, 74], [75, 77], [78, 90]]}
{"doc_key": "ai-test-422", "ner": [[6, 11, "product"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 18, 6, 11, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Come\u00e7ando", "como", "uma", "curiosidade", ",", "o", "sistema", "de", "fala", "da", "Apple", "Macintosh", "evoluiu", "para", "um", "programa", "totalmente", "apoiado", "PlainTalk", ",", "para", "pessoas", "com", "problemas", "de", "vis\u00e3o", "."], "sentence-detokenized": "Come\u00e7ando como uma curiosidade, o sistema de fala da Apple Macintosh evoluiu para um programa totalmente apoiado PlainTalk, para pessoas com problemas de vis\u00e3o.", "token2charspan": [[0, 9], [10, 14], [15, 18], [19, 30], [30, 31], [32, 33], [34, 41], [42, 44], [45, 49], [50, 52], [53, 58], [59, 68], [69, 76], [77, 81], [82, 84], [85, 93], [94, 104], [105, 112], [113, 122], [122, 123], [124, 128], [129, 136], [137, 140], [141, 150], [151, 153], [154, 159], [159, 160]]}
{"doc_key": "ai-test-423", "ner": [[8, 8, "field"], [11, 13, "task"], [15, 17, "task"], [19, 20, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 13, 8, 8, "part-of", "task_part_of_field", false, false], [15, 17, 8, 8, "part-of", "task_part_of_field", false, false], [19, 20, 8, 8, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Outras", "\u00e1reas", "de", "utiliza\u00e7\u00e3o", "para", "ontologias", "dentro", "da", "PNL", "incluem", "a", "recupera\u00e7\u00e3o", "de", "informa\u00e7\u00e3o", ",", "extrac\u00e7\u00e3o", "de", "informa\u00e7\u00e3o", "e", "sumariza\u00e7\u00e3o", "autom\u00e1tica", "."], "sentence-detokenized": "Outras \u00e1reas de utiliza\u00e7\u00e3o para ontologias dentro da PNL incluem a recupera\u00e7\u00e3o de informa\u00e7\u00e3o, extrac\u00e7\u00e3o de informa\u00e7\u00e3o e sumariza\u00e7\u00e3o autom\u00e1tica.", "token2charspan": [[0, 6], [7, 12], [13, 15], [16, 26], [27, 31], [32, 42], [43, 49], [50, 52], [53, 56], [57, 64], [65, 66], [67, 78], [79, 81], [82, 92], [92, 93], [94, 103], [104, 106], [107, 117], [118, 119], [120, 131], [132, 142], [142, 143]]}
{"doc_key": "ai-test-424", "ner": [[7, 14, "organisation"], [17, 22, "organisation"], [25, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["O", "Instituto", "tem", "colaborado", "estreitamente", "com", "o", "Campus", "Agr\u00edcola", "Janelia", "do", "Instituto", "M\u00e9dico", "Howard", "Hughes", ",", "o", "Instituto", "Allen", "de", "Ci\u00eancia", "do", "C\u00e9rebro", "e", "os", "Institutos", "Nacionais", "de", "Sa\u00fade", "para", "desenvolver", "melhores", "m\u00e9todos", "de", "reconstru\u00e7\u00e3o", "de", "arquitecturas", "neuronais", "."], "sentence-detokenized": "O Instituto tem colaborado estreitamente com o Campus Agr\u00edcola Janelia do Instituto M\u00e9dico Howard Hughes, o Instituto Allen de Ci\u00eancia do C\u00e9rebro e os Institutos Nacionais de Sa\u00fade para desenvolver melhores m\u00e9todos de reconstru\u00e7\u00e3o de arquitecturas neuronais.", "token2charspan": [[0, 1], [2, 11], [12, 15], [16, 26], [27, 40], [41, 44], [45, 46], [47, 53], [54, 62], [63, 70], [71, 73], [74, 83], [84, 90], [91, 97], [98, 104], [104, 105], [106, 107], [108, 117], [118, 123], [124, 126], [127, 134], [135, 137], [138, 145], [146, 147], [148, 150], [151, 161], [162, 171], [172, 174], [175, 180], [181, 185], [186, 197], [198, 206], [207, 214], [215, 217], [218, 230], [231, 233], [234, 247], [248, 257], [257, 258]]}
{"doc_key": "ai-test-425", "ner": [[2, 3, "organisation"], [6, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 2, 3, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Recentemente", ",", "o", "Google", "anunciou", "que", "o", "Google", "Translate", "traduz", "aproximadamente", "texto", "suficiente", "para", "preencher", "1", "milh\u00e3o", "de", "livros", "num", "dia", "(", "2012", ")", "."], "sentence-detokenized": "Recentemente, o Google anunciou que o Google Translate traduz aproximadamente texto suficiente para preencher 1 milh\u00e3o de livros num dia (2012).", "token2charspan": [[0, 12], [12, 13], [14, 15], [16, 22], [23, 31], [32, 35], [36, 37], [38, 44], [45, 54], [55, 61], [62, 77], [78, 83], [84, 94], [95, 99], [100, 109], [110, 111], [112, 118], [119, 121], [122, 128], [129, 132], [133, 136], [137, 138], [138, 142], [142, 143], [143, 144]]}
{"doc_key": "ai-test-426", "ner": [[14, 15, "country"], [17, 18, "country"], [20, 20, "country"], [22, 22, "country"], [24, 24, "country"], [26, 28, "country"], [40, 41, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Os", "eventos", "s\u00e3o", "realizados", "em", "todo", "o", "mundo", ",", "e", "s\u00e3o", "mais", "populares", "no", "Reino", "Unido", ",", "Estados", "Unidos", ",", "Jap\u00e3o", ",", "Singapura", ",", "\u00cdndia", ",", "Coreia", "do", "Sul", "e", "est\u00e3o", "a", "tornar-se", "populares", "em", "pa\u00edses", "do", "subcontinente", "como", "o", "Sri", "Lanka", "."], "sentence-detokenized": "Os eventos s\u00e3o realizados em todo o mundo, e s\u00e3o mais populares no Reino Unido, Estados Unidos, Jap\u00e3o, Singapura, \u00cdndia, Coreia do Sul e est\u00e3o a tornar-se populares em pa\u00edses do subcontinente como o Sri Lanka.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 25], [26, 28], [29, 33], [34, 35], [36, 41], [41, 42], [43, 44], [45, 48], [49, 53], [54, 63], [64, 66], [67, 72], [73, 78], [78, 79], [80, 87], [88, 94], [94, 95], [96, 101], [101, 102], [103, 112], [112, 113], [114, 119], [119, 120], [121, 127], [128, 130], [131, 134], [135, 136], [137, 142], [143, 144], [145, 154], [155, 164], [165, 167], [168, 174], [175, 177], [178, 191], [192, 196], [197, 198], [199, 202], [203, 208], [208, 209]]}
{"doc_key": "ai-test-427", "ner": [[6, 6, "programlang"], [12, 12, "programlang"], [14, 14, "programlang"], [16, 18, "programlang"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Estes", "pacotes", "s\u00e3o", "desenvolvidos", "principalmente", "em", "R", ",", "e", "por", "vezes", "em", "Java", ",", "C", ",", "C", "+", "+", ",", "e", "Fortran", "."], "sentence-detokenized": "Estes pacotes s\u00e3o desenvolvidos principalmente em R, e por vezes em Java, C, C + +, e Fortran.", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 31], [32, 46], [47, 49], [50, 51], [51, 52], [53, 54], [55, 58], [59, 64], [65, 67], [68, 72], [72, 73], [74, 75], [75, 76], [77, 78], [79, 80], [81, 82], [82, 83], [84, 85], [86, 93], [93, 94]]}
{"doc_key": "ai-test-428", "ner": [[3, 12, "conference"], [9, 9, "conference"], [14, 14, "researcher"], [16, 16, "researcher"], [19, 20, "researcher"], [23, 24, "algorithm"], [28, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 9, 3, 12, "named", "", false, false], [14, 14, 3, 12, "physical", "", false, false], [14, 14, 3, 12, "role", "", false, false], [14, 14, 19, 20, "role", "teams_up_with", false, false], [14, 14, 23, 24, "usage", "", false, false], [16, 16, 3, 12, "physical", "", false, false], [16, 16, 3, 12, "role", "", false, false], [16, 16, 19, 20, "role", "teams_up_with", false, false], [16, 16, 23, 24, "usage", "", false, false], [19, 20, 3, 12, "physical", "", false, false], [19, 20, 3, 12, "role", "", false, false], [19, 20, 23, 24, "usage", "", false, false], [23, 24, 28, 33, "related-to", "used_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Como", "parte", "da", "Confer\u00eancia", "Europeia", "sobre", "Vis\u00e3o", "Inform\u00e1tica", "(", "ECCV", ")", "de", "2006", ",", "Dalal", "e", "Triggs", "juntaram-se", "a", "Cordelia", "Schmid", "para", "aplicar", "detectores", "HOG", "ao", "problema", "da", "detec\u00e7\u00e3o", "humana", "em", "filmes", "e", "v\u00eddeos", "."], "sentence-detokenized": "Como parte da Confer\u00eancia Europeia sobre Vis\u00e3o Inform\u00e1tica (ECCV) de 2006, Dalal e Triggs juntaram-se a Cordelia Schmid para aplicar detectores HOG ao problema da detec\u00e7\u00e3o humana em filmes e v\u00eddeos.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 25], [26, 34], [35, 40], [41, 46], [47, 58], [59, 60], [60, 64], [64, 65], [66, 68], [69, 73], [73, 74], [75, 80], [81, 82], [83, 89], [90, 101], [102, 103], [104, 112], [113, 119], [120, 124], [125, 132], [133, 143], [144, 147], [148, 150], [151, 159], [160, 162], [163, 171], [172, 178], [179, 181], [182, 188], [189, 190], [191, 197], [197, 198]]}
{"doc_key": "ai-test-429", "ner": [[3, 3, "metrics"], [5, 5, "metrics"], [13, 14, "task"], [19, 21, "metrics"], [23, 23, "metrics"], [29, 29, "metrics"], [32, 34, "metrics"], [36, 36, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 3, 13, 14, "related-to", "measured_with", false, false], [5, 5, 13, 14, "related-to", "measured_with", false, false], [19, 21, 13, 14, "related-to", "measured_with", false, false], [23, 23, 19, 21, "named", "", false, false], [29, 29, 19, 21, "named", "", false, false], [36, 36, 32, 34, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Para", "al\u00e9m", "da", "sensibilidade", "e", "especificidade", ",", "o", "desempenho", "de", "um", "teste", "de", "classifica\u00e7\u00e3o", "bin\u00e1ria", "pode", "ser", "medido", "com", "valor", "preditivo", "positivo", "(", "PPV", ")", ",", "tamb\u00e9m", "conhecido", "como", "precis\u00e3o", ",", "e", "valor", "preditivo", "negativo", "(", "NPV", ")", "."], "sentence-detokenized": "Para al\u00e9m da sensibilidade e especificidade, o desempenho de um teste de classifica\u00e7\u00e3o bin\u00e1ria pode ser medido com valor preditivo positivo (PPV), tamb\u00e9m conhecido como precis\u00e3o, e valor preditivo negativo (NPV).", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 26], [27, 28], [29, 43], [43, 44], [45, 46], [47, 57], [58, 60], [61, 63], [64, 69], [70, 72], [73, 86], [87, 94], [95, 99], [100, 103], [104, 110], [111, 114], [115, 120], [121, 130], [131, 139], [140, 141], [141, 144], [144, 145], [145, 146], [147, 153], [154, 163], [164, 168], [169, 177], [177, 178], [179, 180], [181, 186], [187, 196], [197, 205], [206, 207], [207, 210], [210, 211], [211, 212]]}
{"doc_key": "ai-test-430", "ner": [[14, 17, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Tais", "modelos", "podem", "dar", "cr\u00e9dito", "parcial", "por", "partidas", "sobrepostas", "(", "como", "a", "utiliza\u00e7\u00e3o", "do", "crit\u00e9rio", "do", "\u00edndice", "Jaccard", ")", "."], "sentence-detokenized": "Tais modelos podem dar cr\u00e9dito parcial por partidas sobrepostas (como a utiliza\u00e7\u00e3o do crit\u00e9rio do \u00edndice Jaccard).", "token2charspan": [[0, 4], [5, 12], [13, 18], [19, 22], [23, 30], [31, 38], [39, 42], [43, 51], [52, 63], [64, 65], [65, 69], [70, 71], [72, 82], [83, 85], [86, 94], [95, 97], [98, 104], [105, 112], [112, 113], [113, 114]]}
{"doc_key": "ai-test-431", "ner": [[21, 28, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Al\u00e9m", "disso", ",", "no", "caso", "de", "estimativa", "baseada", "numa", "\u00fanica", "amostra", ",", "demonstra", "quest\u00f5es", "filos\u00f3ficas", "e", "poss\u00edveis", "mal-entendidos", "na", "utiliza\u00e7\u00e3o", "de", "estimadores", "de", "m\u00e1xima", "verosimilhan\u00e7a", "e", "fun\u00e7\u00f5es", "de", "verosimilhan\u00e7a", "."], "sentence-detokenized": "Al\u00e9m disso, no caso de estimativa baseada numa \u00fanica amostra, demonstra quest\u00f5es filos\u00f3ficas e poss\u00edveis mal-entendidos na utiliza\u00e7\u00e3o de estimadores de m\u00e1xima verosimilhan\u00e7a e fun\u00e7\u00f5es de verosimilhan\u00e7a.", "token2charspan": [[0, 4], [5, 10], [10, 11], [12, 14], [15, 19], [20, 22], [23, 33], [34, 41], [42, 46], [47, 52], [53, 60], [60, 61], [62, 71], [72, 80], [81, 92], [93, 94], [95, 104], [105, 119], [120, 122], [123, 133], [134, 136], [137, 148], [149, 151], [152, 158], [159, 173], [174, 175], [176, 183], [184, 186], [187, 201], [201, 202]]}
