{"doc_key": "ai-train-1", "ner": [[4, 9, "product"], [16, 18, "field"], [20, 22, "task"], [24, 26, "task"], [30, 33, "task"], [36, 37, "field"], [38, 40, "researcher"], [42, 43, "researcher"], [45, 46, "researcher"], [48, 49, "researcher"], [51, 52, "researcher"], [54, 55, "researcher"], [57, 59, "researcher"], [61, 62, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 9, 16, 18, "part-of", "", false, false], [4, 9, 16, 18, "usage", "", false, false], [4, 9, 20, 22, "part-of", "", false, false], [4, 9, 20, 22, "usage", "", false, false], [4, 9, 24, 26, "part-of", "", false, false], [4, 9, 24, 26, "usage", "", false, false], [4, 9, 36, 37, "part-of", "", false, false], [4, 9, 36, 37, "usage", "", false, false], [30, 33, 24, 26, "part-of", "", false, false], [30, 33, 24, 26, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["As", "abordagens", "populares", "do", "sistema", "de", "recomenda\u00e7\u00e3o", "baseado", "na", "opini\u00e3o", "utilizam", "v\u00e1rias", "t\u00e9cnicas", ",", "incluindo", "a", "extrac\u00e7\u00e3o", "de", "texto", ",", "recupera\u00e7\u00e3o", "de", "informa\u00e7\u00e3o", ",", "an\u00e1lise", "de", "sentimentos", "(", "ver", "tamb\u00e9m", "An\u00e1lise", "Multimodal", "de", "Sentimentos", ")", "e", "aprendizagem", "profunda", "X.Y", ".", "Feng", ",", "H.", "Zhang", ",", "Y.J.", "Ren", ",", "P.H.", "Shang", ",", "Y.", "Zhu", ",", "Y.C.", "Liang", ",", "R.", "C.", "Guan", ",", "D.", "Xu", ",", "(", "2019", ")", ",", "21", "(", "5", ")", ":", "e12957", "."], "sentence-detokenized": "As abordagens populares do sistema de recomenda\u00e7\u00e3o baseado na opini\u00e3o utilizam v\u00e1rias t\u00e9cnicas, incluindo a extrac\u00e7\u00e3o de texto, recupera\u00e7\u00e3o de informa\u00e7\u00e3o, an\u00e1lise de sentimentos (ver tamb\u00e9m An\u00e1lise Multimodal de Sentimentos) e aprendizagem profunda X.Y. Feng, H. Zhang, Y.J. Ren, P.H. Shang, Y. Zhu, Y.C. Liang, R.C. Guan, D. Xu, (2019), 21 (5): e12957.", "token2charspan": [[0, 2], [3, 13], [14, 23], [24, 26], [27, 34], [35, 37], [38, 50], [51, 58], [59, 61], [62, 69], [70, 78], [79, 85], [86, 94], [94, 95], [96, 105], [106, 107], [108, 117], [118, 120], [121, 126], [126, 127], [128, 139], [140, 142], [143, 153], [153, 154], [155, 162], [163, 165], [166, 177], [178, 179], [179, 182], [183, 189], [190, 197], [198, 208], [209, 211], [212, 223], [223, 224], [225, 226], [227, 239], [240, 248], [249, 252], [252, 253], [254, 258], [258, 259], [260, 262], [263, 268], [268, 269], [270, 274], [275, 278], [278, 279], [280, 284], [285, 290], [290, 291], [292, 294], [295, 298], [298, 299], [300, 304], [305, 310], [310, 311], [312, 314], [314, 316], [317, 321], [321, 322], [323, 325], [326, 328], [328, 329], [330, 331], [331, 335], [335, 336], [336, 337], [338, 340], [341, 342], [342, 343], [343, 344], [344, 345], [346, 352], [352, 353]]}
{"doc_key": "ai-train-2", "ner": [[9, 9, "university"], [15, 16, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 16, 9, 9, "physical", "", false, false], [15, 16, 9, 9, "role", "", false, false], [18, 19, 9, 9, "physical", "", false, false], [18, 19, 9, 9, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Os", "defensores", "das", "representa\u00e7\u00f5es", "processuais", "estavam", "principalmente", "centrados", "no", "MIT", ",", "sob", "a", "lideran\u00e7a", "de", "Marvin", "Minsky", "e", "Seymour", "Papert", "."], "sentence-detokenized": "Os defensores das representa\u00e7\u00f5es processuais estavam principalmente centrados no MIT, sob a lideran\u00e7a de Marvin Minsky e Seymour Papert.", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 32], [33, 44], [45, 52], [53, 67], [68, 77], [78, 80], [81, 84], [84, 85], [86, 89], [90, 91], [92, 101], [102, 104], [105, 111], [112, 118], [119, 120], [121, 128], [129, 135], [135, 136]]}
{"doc_key": "ai-train-3", "ner": [[11, 11, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "interface", "padr\u00e3o", "e", "a", "interface", "da", "calculadora", "s\u00e3o", "escritas", "em", "Java", "."], "sentence-detokenized": "A interface padr\u00e3o e a interface da calculadora s\u00e3o escritas em Java.", "token2charspan": [[0, 1], [2, 11], [12, 18], [19, 20], [21, 22], [23, 32], [33, 35], [36, 47], [48, 51], [52, 60], [61, 63], [64, 68], [68, 69]]}
{"doc_key": "ai-train-4", "ner": [[0, 0, "product"], [27, 27, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 27, 27, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["Octave", "ajuda", "a", "resolver", "problemas", "lineares", "e", "n\u00e3o", "lineares", "numericamente", ",", "e", "a", "realizar", "outras", "experi\u00eancias", "num\u00e9ricas", "usando", "um", "que", "\u00e9", "na", "sua", "maioria", "compat\u00edvel", "com", "o", "MATLAB", "."], "sentence-detokenized": "Octave ajuda a resolver problemas lineares e n\u00e3o lineares numericamente, e a realizar outras experi\u00eancias num\u00e9ricas usando um que \u00e9 na sua maioria compat\u00edvel com o MATLAB.", "token2charspan": [[0, 6], [7, 12], [13, 14], [15, 23], [24, 33], [34, 42], [43, 44], [45, 48], [49, 57], [58, 71], [71, 72], [73, 74], [75, 76], [77, 85], [86, 92], [93, 105], [106, 115], [116, 122], [123, 125], [126, 129], [130, 131], [132, 134], [135, 138], [139, 146], [147, 157], [158, 161], [162, 163], [164, 170], [170, 171]]}
{"doc_key": "ai-train-5", "ner": [[2, 4, "algorithm"], [8, 10, "misc"], [12, 13, "researcher"], [17, 19, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 4, 12, 13, "origin", "", false, false], [8, 10, 12, 13, "origin", "", false, false], [12, 13, 17, 19, "physical", "", false, false], [12, 13, 17, 19, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Variantes", "do", "algoritmo", "de", "retropropaga\u00e7\u00e3o", ",", "bem", "como", "m\u00e9todos", "n\u00e3o", "supervisionados", "por", "Geoff", "Hinton", "e", "colegas", "da", "Universidade", "de", "Toronto", "podem", "ser", "utilizados", "para", "treinar", "arquitecturas", "neurais", "profundas", "e", "altamente", "n\u00e3o", "lineares", ",", "{", "{", "{", "cito", "journal"], "sentence-detokenized": "Variantes do algoritmo de retropropaga\u00e7\u00e3o, bem como m\u00e9todos n\u00e3o supervisionados por Geoff Hinton e colegas da Universidade de Toronto podem ser utilizados para treinar arquitecturas neurais profundas e altamente n\u00e3o lineares, {{{cito journal", "token2charspan": [[0, 9], [10, 12], [13, 22], [23, 25], [26, 41], [41, 42], [43, 46], [47, 51], [52, 59], [60, 63], [64, 79], [80, 83], [84, 89], [90, 96], [97, 98], [99, 106], [107, 109], [110, 122], [123, 125], [126, 133], [134, 139], [140, 143], [144, 154], [155, 159], [160, 167], [168, 181], [182, 189], [190, 199], [200, 201], [202, 211], [212, 215], [216, 224], [224, 225], [226, 227], [227, 228], [228, 229], [229, 233], [234, 241]]}
{"doc_key": "ai-train-6", "ner": [[7, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["ou", "de", "forma", "equivalente", ",", "utilizando", "nota\u00e7\u00e3o", "DCG", ":"], "sentence-detokenized": "ou de forma equivalente, utilizando nota\u00e7\u00e3o DCG:", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 23], [23, 24], [25, 35], [36, 43], [44, 47], [47, 48]]}
{"doc_key": "ai-train-7", "ner": [[0, 2, "algorithm"], [6, 8, "algorithm"], [11, 14, "algorithm"], [17, 21, "algorithm"], [25, 25, "algorithm"], [27, 28, "algorithm"], [44, 45, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 6, 8, "type-of", "", false, false], [0, 2, 11, 14, "usage", "part-of?", true, false], [11, 14, 17, 21, "compare", "", false, false], [25, 25, 17, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Os", "mapas", "auto-organizados", "diferem", "de", "outras", "redes", "neurais", "artificiais", "por", "aplicarem", "uma", "aprendizagem", "competitiva", "em", "oposi\u00e7\u00e3o", "\u00e0", "aprendizagem", "de", "correc\u00e7\u00e3o", "de", "erros", ",", "como", "a", "retropropaga\u00e7\u00e3o", "com", "descida", "gradual", ")", ",", "e", "no", "sentido", "em", "que", "utilizam", "uma", "fun\u00e7\u00e3o", "de", "vizinhan\u00e7a", "para", "preservar", "as", "propriedades", "topol\u00f3gicas", "do", "espa\u00e7o", "de", "entrada", "."], "sentence-detokenized": "Os mapas auto-organizados diferem de outras redes neurais artificiais por aplicarem uma aprendizagem competitiva em oposi\u00e7\u00e3o \u00e0 aprendizagem de correc\u00e7\u00e3o de erros, como a retropropaga\u00e7\u00e3o com descida gradual), e no sentido em que utilizam uma fun\u00e7\u00e3o de vizinhan\u00e7a para preservar as propriedades topol\u00f3gicas do espa\u00e7o de entrada.", "token2charspan": [[0, 2], [3, 8], [9, 25], [26, 33], [34, 36], [37, 43], [44, 49], [50, 57], [58, 69], [70, 73], [74, 83], [84, 87], [88, 100], [101, 112], [113, 115], [116, 124], [125, 126], [127, 139], [140, 142], [143, 152], [153, 155], [156, 161], [161, 162], [163, 167], [168, 169], [170, 185], [186, 189], [190, 197], [198, 205], [205, 206], [206, 207], [208, 209], [210, 212], [213, 220], [221, 223], [224, 227], [228, 236], [237, 240], [241, 247], [248, 250], [251, 261], [262, 266], [267, 276], [277, 279], [280, 292], [293, 304], [305, 307], [308, 314], [315, 317], [318, 325], [325, 326]]}
{"doc_key": "ai-train-8", "ner": [[16, 18, "organisation"], [30, 31, "misc"], [39, 43, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Desde", "o", "in\u00edcio", "dos", "anos", "90", ",", "tem", "sido", "recomendado", "por", "v\u00e1rias", "autoridades", ",", "incluindo", "a", "Audio", "Engineering", "Society", ",", "que", "as", "medi\u00e7\u00f5es", "da", "gama", "din\u00e2mica", "sejam", "feitas", "com", "um", "sinal", "\u00e1udio", "presente", ",", "que", "\u00e9", "depois", "filtrado", "na", "medi\u00e7\u00e3o", "do", "ru\u00eddo", "do", "ch\u00e3o", "utilizada", "na", "determina\u00e7\u00e3o", "da", "gama", "din\u00e2mica", ".", "Isto", "evita", "medi\u00e7\u00f5es", "question\u00e1veis", "com", "base", "na", "utiliza\u00e7\u00e3o", "de", "meios", "em", "branco", ",", "ou", "circuitos", "emudecidos", "."], "sentence-detokenized": "Desde o in\u00edcio dos anos 90, tem sido recomendado por v\u00e1rias autoridades, incluindo a Audio Engineering Society, que as medi\u00e7\u00f5es da gama din\u00e2mica sejam feitas com um sinal \u00e1udio presente, que \u00e9 depois filtrado na medi\u00e7\u00e3o do ru\u00eddo do ch\u00e3o utilizada na determina\u00e7\u00e3o da gama din\u00e2mica. Isto evita medi\u00e7\u00f5es question\u00e1veis com base na utiliza\u00e7\u00e3o de meios em branco, ou circuitos emudecidos.", "token2charspan": [[0, 5], [6, 7], [8, 14], [15, 18], [19, 23], [24, 26], [26, 27], [28, 31], [32, 36], [37, 48], [49, 52], [53, 59], [60, 71], [71, 72], [73, 82], [83, 84], [85, 90], [91, 102], [103, 110], [110, 111], [112, 115], [116, 118], [119, 127], [128, 130], [131, 135], [136, 144], [145, 150], [151, 157], [158, 161], [162, 164], [165, 170], [171, 176], [177, 185], [185, 186], [187, 190], [191, 192], [193, 199], [200, 208], [209, 211], [212, 219], [220, 222], [223, 228], [229, 231], [232, 236], [237, 246], [247, 249], [250, 262], [263, 265], [266, 270], [271, 279], [279, 280], [281, 285], [286, 291], [292, 300], [301, 314], [315, 318], [319, 323], [324, 326], [327, 337], [338, 340], [341, 346], [347, 349], [350, 356], [356, 357], [358, 360], [361, 370], [371, 381], [381, 382]]}
{"doc_key": "ai-train-9", "ner": [[6, 7, "misc"], [20, 21, "task"], [23, 27, "task"], [29, 30, "task"], [32, 34, "task"], [38, 38, "task"], [36, 43, "task"], [45, 48, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[6, 7, 20, 21, "part-of", "concept_used_in", true, false], [6, 7, 23, 27, "part-of", "concept_used_in", false, false], [6, 7, 29, 30, "part-of", "concept_used_in", false, false], [6, 7, 32, 34, "part-of", "concept_used_in", false, false], [6, 7, 38, 38, "part-of", "concept_used_in", false, false], [6, 7, 36, 43, "part-of", "concept_used_in", false, false], [6, 7, 45, 48, "part-of", "concept_used_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["A", "t\u00e9cnica", "utilizada", "na", "cria\u00e7\u00e3o", "de", "caras", "pr\u00f3prias", "e", "na", "sua", "utiliza\u00e7\u00e3o", "para", "o", "reconhecimento", "\u00e9", "tamb\u00e9m", "utilizada", "fora", "do", "reconhecimento", "facial", ":", "reconhecimento", "de", "escrita", "\u00e0", "m\u00e3o", ",", "leitura", "labial", ",", "reconhecimento", "de", "voz", ",", "interpreta\u00e7\u00e3o", "de", "linguagem", "gestual", "/", "gestos", "de", "m\u00e3o", "e", "an\u00e1lise", "de", "imagens", "m\u00e9dicas", "."], "sentence-detokenized": "A t\u00e9cnica utilizada na cria\u00e7\u00e3o de caras pr\u00f3prias e na sua utiliza\u00e7\u00e3o para o reconhecimento \u00e9 tamb\u00e9m utilizada fora do reconhecimento facial: reconhecimento de escrita \u00e0 m\u00e3o, leitura labial, reconhecimento de voz, interpreta\u00e7\u00e3o de linguagem gestual / gestos de m\u00e3o e an\u00e1lise de imagens m\u00e9dicas.", "token2charspan": [[0, 1], [2, 9], [10, 19], [20, 22], [23, 30], [31, 33], [34, 39], [40, 48], [49, 50], [51, 53], [54, 57], [58, 68], [69, 73], [74, 75], [76, 90], [91, 92], [93, 99], [100, 109], [110, 114], [115, 117], [118, 132], [133, 139], [139, 140], [141, 155], [156, 158], [159, 166], [167, 168], [169, 172], [172, 173], [174, 181], [182, 188], [188, 189], [190, 204], [205, 207], [208, 211], [211, 212], [213, 226], [227, 229], [230, 239], [240, 247], [248, 249], [250, 256], [257, 259], [260, 263], [264, 265], [266, 273], [274, 276], [277, 284], [285, 292], [292, 293]]}
{"doc_key": "ai-train-10", "ner": [[1, 3, "organisation"], [9, 13, "organisation"], [15, 15, "organisation"], [19, 23, "organisation"], [26, 31, "organisation"], [34, 38, "organisation"], [41, 45, "organisation"], [47, 47, "organisation"], [52, 55, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[9, 13, 1, 3, "part-of", "", false, false], [15, 15, 9, 13, "named", "", false, false], [19, 23, 1, 3, "part-of", "", false, false], [26, 31, 1, 3, "part-of", "", false, false], [34, 38, 1, 3, "part-of", "", false, false], [41, 45, 1, 3, "part-of", "", false, false], [47, 47, 41, 45, "named", "", false, false], [52, 55, 1, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["A", "National", "Science", "Foundation", "foi", "um", "guarda-chuva", "para", "a", "National", "Aeronautics", "and", "Space", "Administration", "(", "NASA", ")", ",", "o", "Departamento", "de", "Energia", "dos", "EUA", ",", "o", "Departamento", "de", "Com\u00e9rcio", "dos", "EUA", "NIST", ",", "o", "Departamento", "de", "Defesa", "dos", "EUA", ",", "a", "Defense", "Advanced", "Research", "Projects", "Agency", "(", "DARPA", ")", ",", "e", "o", "Office", "of", "Naval", "Research", "coordenaram", "estudos", "para", "informar", "os", "planeadores", "estrat\u00e9gicos", "nas", "suas", "delibera\u00e7\u00f5es", "."], "sentence-detokenized": "A National Science Foundation foi um guarda-chuva para a National Aeronautics and Space Administration (NASA), o Departamento de Energia dos EUA, o Departamento de Com\u00e9rcio dos EUA NIST, o Departamento de Defesa dos EUA, a Defense Advanced Research Projects Agency (DARPA), e o Office of Naval Research coordenaram estudos para informar os planeadores estrat\u00e9gicos nas suas delibera\u00e7\u00f5es.", "token2charspan": [[0, 1], [2, 10], [11, 18], [19, 29], [30, 33], [34, 36], [37, 49], [50, 54], [55, 56], [57, 65], [66, 77], [78, 81], [82, 87], [88, 102], [103, 104], [104, 108], [108, 109], [109, 110], [111, 112], [113, 125], [126, 128], [129, 136], [137, 140], [141, 144], [144, 145], [146, 147], [148, 160], [161, 163], [164, 172], [173, 176], [177, 180], [181, 185], [185, 186], [187, 188], [189, 201], [202, 204], [205, 211], [212, 215], [216, 219], [219, 220], [221, 222], [223, 230], [231, 239], [240, 248], [249, 257], [258, 264], [265, 266], [266, 271], [271, 272], [272, 273], [274, 275], [276, 277], [278, 284], [285, 287], [288, 293], [294, 302], [303, 314], [315, 322], [323, 327], [328, 336], [337, 339], [340, 351], [352, 364], [365, 368], [369, 373], [374, 386], [386, 387]]}
{"doc_key": "ai-train-11", "ner": [[7, 8, "metrics"], [11, 12, "algorithm"], [16, 17, "researcher"], [24, 24, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 11, 12, "part-of", "", false, false], [16, 17, 24, 24, "related-to", "added_appendix_to_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Um", "m\u00e9todo", "r\u00e1pido", "para", "calcular", "estimativas", "de", "m\u00e1xima", "probabilidade", "para", "o", "modelo", "probit", "foi", "proposto", "por", "Ronald", "Fisher", "como", "um", "ap\u00eandice", "do", "trabalho", "de", "Bliss", "em", "1935", "."], "sentence-detokenized": "Um m\u00e9todo r\u00e1pido para calcular estimativas de m\u00e1xima probabilidade para o modelo probit foi proposto por Ronald Fisher como um ap\u00eandice do trabalho de Bliss em 1935.", "token2charspan": [[0, 2], [3, 9], [10, 16], [17, 21], [22, 30], [31, 42], [43, 45], [46, 52], [53, 66], [67, 71], [72, 73], [74, 80], [81, 87], [88, 91], [92, 100], [101, 104], [105, 111], [112, 118], [119, 123], [124, 126], [127, 135], [136, 138], [139, 147], [148, 150], [151, 156], [157, 159], [160, 164], [164, 165]]}
{"doc_key": "ai-train-12", "ner": [[10, 11, "product"], [14, 15, "product"], [21, 21, "organisation"], [19, 19, "product"], [26, 26, "organisation"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[19, 19, 14, 15, "usage", "uses_software", false, false], [19, 19, 21, 21, "artifact", "", false, false], [19, 19, 24, 24, "named", "", false, false], [24, 24, 26, 26, "artifact", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["V\u00e1rios", "destes", "programas", "est\u00e3o", "dispon\u00edveis", "online", ",", "tais", "como", "o", "Google", "Translate", "e", "o", "sistema", "SYSTRAN", "que", "alimenta", "o", "BabelFish", "do", "AltaVista", "(", "agora", "Babelfish", "do", "Yahoo", "a", "partir", "de", "9", "de", "Maio", "de", "2008", ")", "."], "sentence-detokenized": "V\u00e1rios destes programas est\u00e3o dispon\u00edveis online, tais como o Google Translate e o sistema SYSTRAN que alimenta o BabelFish do AltaVista (agora Babelfish do Yahoo a partir de 9 de Maio de 2008).", "token2charspan": [[0, 6], [7, 13], [14, 23], [24, 29], [30, 41], [42, 48], [48, 49], [50, 54], [55, 59], [60, 61], [62, 68], [69, 78], [79, 80], [81, 82], [83, 90], [91, 98], [99, 102], [103, 111], [112, 113], [114, 123], [124, 126], [127, 136], [137, 138], [138, 143], [144, 153], [154, 156], [157, 162], [163, 164], [165, 171], [172, 174], [175, 176], [177, 179], [180, 184], [185, 187], [188, 192], [192, 193], [193, 194]]}
{"doc_key": "ai-train-13", "ner": [[2, 2, "researcher"], [5, 6, "researcher"], [8, 9, "researcher"], [18, 20, "field"], [23, 24, "misc"], [27, 29, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 18, 20, "related-to", "", true, false], [2, 2, 23, 24, "related-to", "", true, false], [2, 2, 27, 29, "related-to", "", true, false], [5, 6, 18, 20, "related-to", "", true, false], [5, 6, 23, 24, "related-to", "", true, false], [5, 6, 27, 29, "related-to", "", true, false], [8, 9, 18, 20, "related-to", "", true, false], [8, 9, 23, 24, "related-to", "", true, false], [8, 9, 27, 29, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Em", "2002", "Hutter", ",", "com", "J\u00fcrgen", "Schmidhuber", "e", "Shane", "Legg", ",", "desenvolveu", "e", "publicou", "uma", "teoria", "matem\u00e1tica", "de", "intelig\u00eancia", "geral", "artificial", "baseada", "em", "agentes", "inteligentes", "idealizados", "e", "aprendizagem", "de", "refor\u00e7o", "com", "motiva\u00e7\u00e3o", "para", "a", "guerra", "."], "sentence-detokenized": "Em 2002 Hutter, com J\u00fcrgen Schmidhuber e Shane Legg, desenvolveu e publicou uma teoria matem\u00e1tica de intelig\u00eancia geral artificial baseada em agentes inteligentes idealizados e aprendizagem de refor\u00e7o com motiva\u00e7\u00e3o para a guerra.", "token2charspan": [[0, 2], [3, 7], [8, 14], [14, 15], [16, 19], [20, 26], [27, 38], [39, 40], [41, 46], [47, 51], [51, 52], [53, 64], [65, 66], [67, 75], [76, 79], [80, 86], [87, 97], [98, 100], [101, 113], [114, 119], [120, 130], [131, 138], [139, 141], [142, 149], [150, 162], [163, 174], [175, 176], [177, 189], [190, 192], [193, 200], [201, 204], [205, 214], [215, 219], [220, 221], [222, 228], [228, 229]]}
{"doc_key": "ai-train-14", "ner": [[9, 9, "metrics"], [11, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 9, 11, 15, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "forma", "mais", "comum", "\u00e9", "utilizar", "a", "chamada", "medida", "ROUGE", "(", "Recall-Oriented", "Understudy", "for", "Gisting", "Evaluation", ")", "."], "sentence-detokenized": "A forma mais comum \u00e9 utilizar a chamada medida ROUGE (Recall-Oriented Understudy for Gisting Evaluation).", "token2charspan": [[0, 1], [2, 7], [8, 12], [13, 18], [19, 20], [21, 29], [30, 31], [32, 39], [40, 46], [47, 52], [53, 54], [54, 69], [70, 80], [81, 84], [85, 92], [93, 103], [103, 104], [104, 105]]}
{"doc_key": "ai-train-15", "ner": [[0, 0, "product"], [15, 15, "programlang"], [17, 17, "programlang"], [19, 20, "researcher"], [22, 23, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 15, 15, "related-to", "", false, false], [0, 0, 17, 17, "related-to", "", false, false], [19, 20, 22, 23, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["RapidMiner", "fornece", "esquemas", "de", "aprendizagem", ",", "modelos", "e", "algoritmos", "e", "pode", "ser", "alargado", "utilizando", "scripts", "R", "e", "Python", ".", "David", "Norris", ",", "Bloor", "Research", ",", "13", "de", "Novembro", "de", "2013", "."], "sentence-detokenized": "RapidMiner fornece esquemas de aprendizagem, modelos e algoritmos e pode ser alargado utilizando scripts R e Python. David Norris, Bloor Research, 13 de Novembro de 2013.", "token2charspan": [[0, 10], [11, 18], [19, 27], [28, 30], [31, 43], [43, 44], [45, 52], [53, 54], [55, 65], [66, 67], [68, 72], [73, 76], [77, 85], [86, 96], [97, 104], [105, 106], [107, 108], [109, 115], [115, 116], [117, 122], [123, 129], [129, 130], [131, 136], [137, 145], [145, 146], [147, 149], [150, 152], [153, 161], [162, 164], [165, 169], [169, 170]]}
{"doc_key": "ai-train-16", "ner": [[8, 8, "programlang"], [10, 11, "product"]], "ner_mapping_to_source": [4, 5], "relations": [[10, 11, 8, 8, "general-affiliation", "", true, false]], "relations_mapping_to_source": [4], "sentence": ["mas", "a", "vers\u00e3o", "mais", "recente", "totalmente", "baseada", "em", "Java", "(", "Weka", "3", ")", ",", "cujo", "desenvolvimento", "teve", "in\u00edcio", "em", "1997", ",", "\u00e9", "agora", "utilizada", "em", "muitas", "\u00e1reas", "de", "aplica\u00e7\u00e3o", "diferentes", ",", "em", "particular", "para", "fins", "educativos", "e", "de", "investiga\u00e7\u00e3o", "."], "sentence-detokenized": "mas a vers\u00e3o mais recente totalmente baseada em Java (Weka 3), cujo desenvolvimento teve in\u00edcio em 1997, \u00e9 agora utilizada em muitas \u00e1reas de aplica\u00e7\u00e3o diferentes, em particular para fins educativos e de investiga\u00e7\u00e3o.", "token2charspan": [[0, 3], [4, 5], [6, 12], [13, 17], [18, 25], [26, 36], [37, 44], [45, 47], [48, 52], [53, 54], [54, 58], [59, 60], [60, 61], [61, 62], [63, 67], [68, 83], [84, 88], [89, 95], [96, 98], [99, 103], [103, 104], [105, 106], [107, 112], [113, 122], [123, 125], [126, 132], [133, 138], [139, 141], [142, 151], [152, 162], [162, 163], [164, 166], [167, 177], [178, 182], [183, 187], [188, 198], [199, 200], [201, 203], [204, 216], [216, 217]]}
{"doc_key": "ai-train-17", "ner": [[0, 1, "product"], [16, 23, "misc"], [26, 29, "misc"], [31, 39, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 23, 0, 1, "topic", "", false, false], [16, 23, 26, 29, "win-defeat", "", false, false], [26, 29, 31, 39, "temporal", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "Eurisko", "fez", "muitas", "descobertas", "interessantes", "e", "gozou", "de", "aclama\u00e7\u00e3o", "significativa", ",", "com", "o", "seu", "jornal", "Heuretics", ":", "Te\u00f3rico", "e", "Estudo", "das", "Regras", "Heur\u00edsticas", "ganhando", "o", "pr\u00e9mio", "de", "Melhor", "Trabalho", "na", "Associa\u00e7\u00e3o", "para", "o", "Progresso", "da", "Intelig\u00eancia", "Artificial", "de", "1982", "."], "sentence-detokenized": "A Eurisko fez muitas descobertas interessantes e gozou de aclama\u00e7\u00e3o significativa, com o seu jornal Heuretics: Te\u00f3rico e Estudo das Regras Heur\u00edsticas ganhando o pr\u00e9mio de Melhor Trabalho na Associa\u00e7\u00e3o para o Progresso da Intelig\u00eancia Artificial de 1982.", "token2charspan": [[0, 1], [2, 9], [10, 13], [14, 20], [21, 32], [33, 46], [47, 48], [49, 54], [55, 57], [58, 67], [68, 81], [81, 82], [83, 86], [87, 88], [89, 92], [93, 99], [100, 109], [109, 110], [111, 118], [119, 120], [121, 127], [128, 131], [132, 138], [139, 150], [151, 159], [160, 161], [162, 168], [169, 171], [172, 178], [179, 187], [188, 190], [191, 201], [202, 206], [207, 208], [209, 218], [219, 221], [222, 234], [235, 245], [246, 248], [249, 253], [253, 254]]}
{"doc_key": "ai-train-18", "ner": [[8, 10, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Para", "permitir", "m\u00faltiplas", "entidades", ",", "\u00e9", "calculada", "uma", "perda", "de", "dobradi\u00e7a", "separada", "para", "cada", "c\u00e1psula", "."], "sentence-detokenized": "Para permitir m\u00faltiplas entidades, \u00e9 calculada uma perda de dobradi\u00e7a separada para cada c\u00e1psula.", "token2charspan": [[0, 4], [5, 13], [14, 23], [24, 33], [33, 34], [35, 36], [37, 46], [47, 50], [51, 56], [57, 59], [60, 69], [70, 78], [79, 83], [84, 88], [89, 96], [96, 97]]}
{"doc_key": "ai-train-19", "ner": [[9, 11, "product"], [14, 15, "product"], [18, 19, "product"], [22, 23, "product"], [26, 29, "product"], [32, 34, "product"], [44, 52, "product"], [54, 55, "product"], [58, 59, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[9, 11, 32, 34, "type-of", "", false, false], [14, 15, 32, 34, "type-of", "", false, false], [18, 19, 32, 34, "type-of", "", false, false], [22, 23, 32, 34, "type-of", "", false, false], [26, 29, 32, 34, "type-of", "", false, false], [54, 55, 44, 52, "type-of", "", false, false], [58, 59, 44, 52, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Com", "o", "aparecimento", "de", "assistentes", "de", "conversa\u00e7\u00e3o", "como", "o", "Siri", "da", "Apple", ",", "o", "Amazon", "Alexa", ",", "o", "Google", "Assistant", ",", "o", "Microsoft", "Cortana", ",", "e", "o", "Bixby", "da", "Samsung", ",", "os", "Portais", "de", "Voz", "podem", "agora", "ser", "acedidos", "atrav\u00e9s", "de", "dispositivos", "m\u00f3veis", "e", "altifalantes", "inteligentes", "de", "voz", "Far", "Field", ",", "tais", "como", "o", "Amazon", "Echo", "e", "o", "Google", "Home", "."], "sentence-detokenized": "Com o aparecimento de assistentes de conversa\u00e7\u00e3o como o Siri da Apple, o Amazon Alexa, o Google Assistant, o Microsoft Cortana, e o Bixby da Samsung, os Portais de Voz podem agora ser acedidos atrav\u00e9s de dispositivos m\u00f3veis e altifalantes inteligentes de voz Far Field, tais como o Amazon Echo e o Google Home.", "token2charspan": [[0, 3], [4, 5], [6, 18], [19, 21], [22, 33], [34, 36], [37, 48], [49, 53], [54, 55], [56, 60], [61, 63], [64, 69], [69, 70], [71, 72], [73, 79], [80, 85], [85, 86], [87, 88], [89, 95], [96, 105], [105, 106], [107, 108], [109, 118], [119, 126], [126, 127], [128, 129], [130, 131], [132, 137], [138, 140], [141, 148], [148, 149], [150, 152], [153, 160], [161, 163], [164, 167], [168, 173], [174, 179], [180, 183], [184, 192], [193, 200], [201, 203], [204, 216], [217, 223], [224, 225], [226, 238], [239, 251], [252, 254], [255, 258], [259, 262], [263, 268], [268, 269], [270, 274], [275, 279], [280, 281], [282, 288], [289, 293], [294, 295], [296, 297], [298, 304], [305, 309], [309, 310]]}
{"doc_key": "ai-train-20", "ner": [[2, 3, "field"], [6, 8, "algorithm"], [11, 14, "algorithm"], [16, 18, "algorithm"], [22, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 8, 2, 3, "type-of", "", false, false], [11, 14, 2, 3, "type-of", "", false, false], [16, 18, 2, 3, "type-of", "", false, false], [22, 22, 2, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Exemplos", "de", "aprendizagem", "supervisionada", "s\u00e3o", "o", "classificador", "Naive", "Bayes", ",", "a", "m\u00e1quina", "de", "suporte", "vectorial", ",", "misturas", "de", "gaussianos", ",", "e", "a", "rede", "."], "sentence-detokenized": "Exemplos de aprendizagem supervisionada s\u00e3o o classificador Naive Bayes, a m\u00e1quina de suporte vectorial, misturas de gaussianos, e a rede.", "token2charspan": [[0, 8], [9, 11], [12, 24], [25, 39], [40, 43], [44, 45], [46, 59], [60, 65], [66, 71], [71, 72], [73, 74], [75, 82], [83, 85], [86, 93], [94, 103], [103, 104], [105, 113], [114, 116], [117, 127], [127, 128], [129, 130], [131, 132], [133, 137], [137, 138]]}
{"doc_key": "ai-train-21", "ner": [[3, 4, "algorithm"], [23, 26, "algorithm"], [28, 28, "task"], [33, 35, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 23, 26, "part-of", "", true, false], [33, 35, 28, 28, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pode-se", "usar", "o", "algoritmo", "OSD", "para", "derivar", "matem\u00e1tica", "O", "(", "sqrt", "{", "T", "}", ")", "/", "c\u00e1lculos", "matem\u00e1ticos", "para", "a", "vers\u00e3o", "online", "da", "m\u00e1quina", "vectorial", "de", "suporte", "para", "classifica\u00e7\u00e3o", ",", "que", "utiliza", "a", "perda", "de", "dobradi\u00e7a", "matem\u00e1tica", "v", "_t", "(", "w", ")", "=", "\\", "max", "{", "0", ",", "1", "-", "y", "_t", "(", "w", "\\", "cdot", "x", "_t", ")", "}", "/", "matem\u00e1tica"], "sentence-detokenized": "Pode-se usar o algoritmo OSD para derivar matem\u00e1tica O (sqrt {T}) / c\u00e1lculos matem\u00e1ticos para a vers\u00e3o online da m\u00e1quina vectorial de suporte para classifica\u00e7\u00e3o, que utiliza a perda de dobradi\u00e7a matem\u00e1tica v _t (w) =\\ max {0, 1 - y _t (w\\ cdot x _t)} / matem\u00e1tica", "token2charspan": [[0, 7], [8, 12], [13, 14], [15, 24], [25, 28], [29, 33], [34, 41], [42, 52], [53, 54], [55, 56], [56, 60], [61, 62], [62, 63], [63, 64], [64, 65], [66, 67], [68, 76], [77, 88], [89, 93], [94, 95], [96, 102], [103, 109], [110, 112], [113, 120], [121, 130], [131, 133], [134, 141], [142, 146], [147, 160], [160, 161], [162, 165], [166, 173], [174, 175], [176, 181], [182, 184], [185, 194], [195, 205], [206, 207], [208, 210], [211, 212], [212, 213], [213, 214], [215, 216], [216, 217], [218, 221], [222, 223], [223, 224], [224, 225], [226, 227], [228, 229], [230, 231], [232, 234], [235, 236], [236, 237], [237, 238], [239, 243], [244, 245], [246, 248], [248, 249], [249, 250], [251, 252], [253, 263]]}
{"doc_key": "ai-train-22", "ner": [[4, 6, "task"], [8, 11, "task"], [10, 10, "task"], [13, 15, "task"], [17, 18, "task"], [20, 22, "task"], [24, 26, "task"], [28, 32, "task"], [34, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["As", "aplica\u00e7\u00f5es", "incluem", "o", "reconhecimento", "de", "objectos", ",", "mapeamento", "e", "navega\u00e7\u00e3o", "rob\u00f3tica", ",", "costura", "de", "imagens", ",", "modela\u00e7\u00e3o", "3D", ",", "reconhecimento", "de", "gestos", ",", "rastreio", "de", "v\u00eddeo", ",", "identifica\u00e7\u00e3o", "individual", "de", "vida", "selvagem", "e", "correspond\u00eancia", "de", "movimento", "."], "sentence-detokenized": "As aplica\u00e7\u00f5es incluem o reconhecimento de objectos, mapeamento e navega\u00e7\u00e3o rob\u00f3tica, costura de imagens, modela\u00e7\u00e3o 3D, reconhecimento de gestos, rastreio de v\u00eddeo, identifica\u00e7\u00e3o individual de vida selvagem e correspond\u00eancia de movimento.", "token2charspan": [[0, 2], [3, 13], [14, 21], [22, 23], [24, 38], [39, 41], [42, 50], [50, 51], [52, 62], [63, 64], [65, 74], [75, 83], [83, 84], [85, 92], [93, 95], [96, 103], [103, 104], [105, 114], [115, 117], [117, 118], [119, 133], [134, 136], [137, 143], [143, 144], [145, 153], [154, 156], [157, 162], [162, 163], [164, 177], [178, 188], [189, 191], [192, 196], [197, 205], [206, 207], [208, 223], [224, 226], [227, 236], [236, 237]]}
{"doc_key": "ai-train-23", "ner": [[7, 9, "task"], [14, 16, "university"], [18, 20, "university"], [22, 23, "university"], [25, 27, "university"], [29, 34, "university"], [36, 38, "university"], [40, 42, "university"], [44, 45, "university"], [47, 52, "university"], [54, 54, "university"], [59, 63, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[7, 9, 14, 16, "related-to", "", true, false], [7, 9, 18, 20, "related-to", "", true, false], [7, 9, 22, 23, "related-to", "", true, false], [7, 9, 25, 27, "related-to", "", true, false], [7, 9, 29, 34, "related-to", "", true, false], [7, 9, 36, 38, "related-to", "", true, false], [7, 9, 40, 42, "related-to", "", true, false], [7, 9, 44, 45, "related-to", "", true, false], [7, 9, 47, 52, "related-to", "", true, false], [7, 9, 54, 54, "related-to", "", true, false], [7, 9, 59, 63, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["V\u00e1rios", "grupos", "e", "empresas", "est\u00e3o", "a", "investigar", "estimativas", "de", "pose", ",", "incluindo", "grupos", "na", "Universidade", "de", "Brown", ",", "Carnegie", "Mellon", "University", ",", "MPI", "Saarbruecken", ",", "Universidade", "de", "Stanford", ",", "Universidade", "da", "Calif\u00f3rnia", ",", "San", "Diego", ",", "Universidade", "de", "Toronto", ",", "\u00c9cole", "Centrale", "Paris", ",", "ETH", "Zurich", ",", "Universidade", "Nacional", "de", "Ci\u00eancias", "e", "Tecnologia", "(", "NUST", ")", ",", "e", "a", "Universidade", "da", "Calif\u00f3rnia", ",", "Irvine", "."], "sentence-detokenized": "V\u00e1rios grupos e empresas est\u00e3o a investigar estimativas de pose, incluindo grupos na Universidade de Brown, Carnegie Mellon University, MPI Saarbruecken, Universidade de Stanford, Universidade da Calif\u00f3rnia, San Diego, Universidade de Toronto, \u00c9cole Centrale Paris, ETH Zurich, Universidade Nacional de Ci\u00eancias e Tecnologia (NUST), e a Universidade da Calif\u00f3rnia, Irvine.", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 24], [25, 30], [31, 32], [33, 43], [44, 55], [56, 58], [59, 63], [63, 64], [65, 74], [75, 81], [82, 84], [85, 97], [98, 100], [101, 106], [106, 107], [108, 116], [117, 123], [124, 134], [134, 135], [136, 139], [140, 152], [152, 153], [154, 166], [167, 169], [170, 178], [178, 179], [180, 192], [193, 195], [196, 206], [206, 207], [208, 211], [212, 217], [217, 218], [219, 231], [232, 234], [235, 242], [242, 243], [244, 249], [250, 258], [259, 264], [264, 265], [266, 269], [270, 276], [276, 277], [278, 290], [291, 299], [300, 302], [303, 311], [312, 313], [314, 324], [325, 326], [326, 330], [330, 331], [331, 332], [333, 334], [335, 336], [337, 349], [350, 352], [353, 363], [363, 364], [365, 371], [371, 372]]}
{"doc_key": "ai-train-24", "ner": [[0, 6, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Fun\u00e7\u00e3o", "sigm\u00f3ide", "A", "perda", "de", "entropia", "cruzada", "\u00e9", "utilizada", "para", "prever", "valores", "de", "probabilidade", "K", "independentes", "em", "matem\u00e1tica", "0,1", "/", "matem\u00e1tica", "."], "sentence-detokenized": "Fun\u00e7\u00e3o sigm\u00f3ide A perda de entropia cruzada \u00e9 utilizada para prever valores de probabilidade K independentes em matem\u00e1tica 0,1 / matem\u00e1tica.", "token2charspan": [[0, 6], [7, 15], [16, 17], [18, 23], [24, 26], [27, 35], [36, 43], [44, 45], [46, 55], [56, 60], [61, 67], [68, 75], [76, 78], [79, 92], [93, 94], [95, 108], [109, 111], [112, 122], [123, 126], [127, 128], [129, 139], [139, 140]]}
{"doc_key": "ai-train-25", "ner": [[3, 5, "misc"], [7, 7, "field"], [9, 9, "field"], [11, 13, "university"], [15, 15, "country"], [19, 21, "misc"], [23, 26, "university"], [28, 28, "country"], [36, 36, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 5, 7, 7, "topic", "", false, false], [3, 5, 9, 9, "topic", "", false, false], [3, 5, 11, 13, "physical", "", true, false], [11, 13, 15, 15, "physical", "", false, false], [19, 21, 23, 26, "physical", "", true, false], [23, 26, 28, 28, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Foi", "titular", "da", "C\u00e1tedra", "Johann", "Bernoulli", "de", "Matem\u00e1tica", "e", "Inform\u00e1tica", "na", "Universidade", "de", "Groningen", "na", "Holanda", ",", "e", "da", "C\u00e1tedra", "Toshiba", "Endowed", "no", "Instituto", "Tecnol\u00f3gico", "de", "T\u00f3quio", "no", "Jap\u00e3o", ",", "antes", "de", "se", "tornar", "Professor", "em", "Cambridge", "."], "sentence-detokenized": "Foi titular da C\u00e1tedra Johann Bernoulli de Matem\u00e1tica e Inform\u00e1tica na Universidade de Groningen na Holanda, e da C\u00e1tedra Toshiba Endowed no Instituto Tecnol\u00f3gico de T\u00f3quio no Jap\u00e3o, antes de se tornar Professor em Cambridge.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 29], [30, 39], [40, 42], [43, 53], [54, 55], [56, 67], [68, 70], [71, 83], [84, 86], [87, 96], [97, 99], [100, 107], [107, 108], [109, 110], [111, 113], [114, 121], [122, 129], [130, 137], [138, 140], [141, 150], [151, 162], [163, 165], [166, 172], [173, 175], [176, 181], [181, 182], [183, 188], [189, 191], [192, 194], [195, 201], [202, 211], [212, 214], [215, 224], [224, 225]]}
{"doc_key": "ai-train-26", "ner": [[5, 7, "algorithm"], [12, 15, "algorithm"], [17, 17, "algorithm"], [22, 23, "researcher"], [25, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 7, 12, 15, "usage", "", true, false], [12, 15, 22, 23, "origin", "", false, false], [12, 15, 25, 26, "origin", "", false, false], [17, 17, 12, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Outra", "t\u00e9cnica", "particularmente", "utilizada", "para", "redes", "neurais", "recorrentes", "\u00e9", "a", "rede", "de", "mem\u00f3ria", "a", "longo", "prazo", "(", "LSTM", ")", "de", "1997", "por", "Sepp", "Hochreiter", "&", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Outra t\u00e9cnica particularmente utilizada para redes neurais recorrentes \u00e9 a rede de mem\u00f3ria a longo prazo (LSTM) de 1997 por Sepp Hochreiter & J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 5], [6, 13], [14, 29], [30, 39], [40, 44], [45, 50], [51, 58], [59, 70], [71, 72], [73, 74], [75, 79], [80, 82], [83, 90], [91, 92], [93, 98], [99, 104], [105, 106], [106, 110], [110, 111], [112, 114], [115, 119], [120, 123], [124, 128], [129, 139], [140, 141], [142, 148], [149, 160], [160, 161]]}
{"doc_key": "ai-train-27", "ner": [[5, 7, "programlang"], [9, 9, "product"], [15, 16, "product"], [50, 50, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 5, 7, "general-affiliation", "", false, false], [9, 9, 15, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "inclus\u00e3o", "de", "um", "int\u00e9rprete", "C", "+", "+", "(", "CINT", "at\u00e9", "\u00e0", "vers\u00e3o", "5.34", ",", "Cling", "a", "partir", "da", "vers\u00e3o", "6", ")", "torna", "este", "pacote", "muito", "vers\u00e1til", ",", "uma", "vez", "que", "pode", "ser", "utilizado", "em", "modos", "interactivos", ",", "com", "scripts", "e", "compilados", "de", "forma", "semelhante", "aos", "produtos", "comerciais", "como", "o", "MATLAB", "."], "sentence-detokenized": "A inclus\u00e3o de um int\u00e9rprete C + + (CINT at\u00e9 \u00e0 vers\u00e3o 5.34, Cling a partir da vers\u00e3o 6) torna este pacote muito vers\u00e1til, uma vez que pode ser utilizado em modos interactivos, com scripts e compilados de forma semelhante aos produtos comerciais como o MATLAB.", "token2charspan": [[0, 1], [2, 10], [11, 13], [14, 16], [17, 27], [28, 29], [30, 31], [32, 33], [34, 35], [35, 39], [40, 43], [44, 45], [46, 52], [53, 57], [57, 58], [59, 64], [65, 66], [67, 73], [74, 76], [77, 83], [84, 85], [85, 86], [87, 92], [93, 97], [98, 104], [105, 110], [111, 119], [119, 120], [121, 124], [125, 128], [129, 132], [133, 137], [138, 141], [142, 151], [152, 154], [155, 160], [161, 173], [173, 174], [175, 178], [179, 186], [187, 188], [189, 199], [200, 202], [203, 208], [209, 219], [220, 223], [224, 232], [233, 243], [244, 248], [249, 250], [251, 257], [257, 258]]}
{"doc_key": "ai-train-28", "ner": [[0, 5, "product"], [27, 30, "field"], [33, 35, "task"], [37, 39, "task"], [41, 43, "task"], [46, 48, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 5, 27, 30, "related-to", "", false, false], [33, 35, 27, 30, "part-of", "", false, false], [37, 39, 27, 30, "part-of", "", false, false], [41, 43, 27, 30, "part-of", "", false, false], [46, 48, 27, 30, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["As", "interfaces", "de", "utilizador", "de", "voz", "que", "interpretam", "e", "gerem", "o", "estado", "de", "conversa\u00e7\u00e3o", "s\u00e3o", "dif\u00edceis", "de", "conceber", "devido", "\u00e0", "dificuldade", "inerente", "de", "integrar", "tarefas", "complexas", "de", "processamento", "de", "linguagem", "natural", "como", "a", "resolu\u00e7\u00e3o", "de", "refer\u00eancia", ",", "reconhecimento", "de", "identidade", ",", "recupera\u00e7\u00e3o", "de", "informa\u00e7\u00e3o", ",", "e", "gest\u00e3o", "de", "di\u00e1logo", "."], "sentence-detokenized": "As interfaces de utilizador de voz que interpretam e gerem o estado de conversa\u00e7\u00e3o s\u00e3o dif\u00edceis de conceber devido \u00e0 dificuldade inerente de integrar tarefas complexas de processamento de linguagem natural como a resolu\u00e7\u00e3o de refer\u00eancia, reconhecimento de identidade, recupera\u00e7\u00e3o de informa\u00e7\u00e3o, e gest\u00e3o de di\u00e1logo.", "token2charspan": [[0, 2], [3, 13], [14, 16], [17, 27], [28, 30], [31, 34], [35, 38], [39, 50], [51, 52], [53, 58], [59, 60], [61, 67], [68, 70], [71, 82], [83, 86], [87, 95], [96, 98], [99, 107], [108, 114], [115, 116], [117, 128], [129, 137], [138, 140], [141, 149], [150, 157], [158, 167], [168, 170], [171, 184], [185, 187], [188, 197], [198, 205], [206, 210], [211, 212], [213, 222], [223, 225], [226, 236], [236, 237], [238, 252], [253, 255], [256, 266], [266, 267], [268, 279], [280, 282], [283, 293], [293, 294], [295, 296], [297, 303], [304, 306], [307, 314], [314, 315]]}
{"doc_key": "ai-train-29", "ner": [[6, 8, "algorithm"], [11, 15, "algorithm"], [22, 23, "researcher"], [25, 29, "organisation"], [35, 37, "field"], [39, 41, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 8, 22, 23, "origin", "", false, false], [6, 8, 35, 37, "part-of", "", false, false], [6, 8, 39, 41, "part-of", "", false, false], [11, 15, 22, 23, "origin", "", false, false], [11, 15, 35, 37, "part-of", "", false, false], [11, 15, 39, 41, "part-of", "", false, false], [22, 23, 25, 29, "physical", "", false, false], [22, 23, 25, 29, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Entre", "2009", "e", "2012", ",", "as", "redes", "neurais", "recorrentes", "e", "as", "redes", "neurais", "de", "alimenta\u00e7\u00e3o", "profunda", "desenvolvidas", "no", "grupo", "de", "investiga\u00e7\u00e3o", "de", "J\u00fcrgen", "Schmidhuber", "no", "Laborat\u00f3rio", "Su\u00ed\u00e7o", "de", "IA", "IDSIA", "ganharam", "oito", "concursos", "internacionais", "de", "reconhecimento", "de", "padr\u00f5es", "e", "aprendizagem", "de", "m\u00e1quinas", "."], "sentence-detokenized": "Entre 2009 e 2012, as redes neurais recorrentes e as redes neurais de alimenta\u00e7\u00e3o profunda desenvolvidas no grupo de investiga\u00e7\u00e3o de J\u00fcrgen Schmidhuber no Laborat\u00f3rio Su\u00ed\u00e7o de IA IDSIA ganharam oito concursos internacionais de reconhecimento de padr\u00f5es e aprendizagem de m\u00e1quinas.", "token2charspan": [[0, 5], [6, 10], [11, 12], [13, 17], [17, 18], [19, 21], [22, 27], [28, 35], [36, 47], [48, 49], [50, 52], [53, 58], [59, 66], [67, 69], [70, 81], [82, 90], [91, 104], [105, 107], [108, 113], [114, 116], [117, 129], [130, 132], [133, 139], [140, 151], [152, 154], [155, 166], [167, 172], [173, 175], [176, 178], [179, 184], [185, 193], [194, 198], [199, 208], [209, 223], [224, 226], [227, 241], [242, 244], [245, 252], [253, 254], [255, 267], [268, 270], [271, 279], [279, 280]]}
{"doc_key": "ai-train-30", "ner": [[0, 3, "product"], [8, 9, "product"], [11, 12, "product"], [16, 18, "task"], [21, 21, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 8, 9, "usage", "", false, false], [0, 3, 11, 12, "usage", "", false, false], [0, 3, 16, 18, "usage", "", true, false], [0, 3, 21, 21, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Os", "sistemas", "desktop", "Windows", "modernos", "podem", "utilizar", "componentes", "SAPI", "4", "e", "SAPI", "5", "para", "suportar", "a", "s\u00edntese", "de", "voz", "e", "a", "fala", "."], "sentence-detokenized": "Os sistemas desktop Windows modernos podem utilizar componentes SAPI 4 e SAPI 5 para suportar a s\u00edntese de voz e a fala.", "token2charspan": [[0, 2], [3, 11], [12, 19], [20, 27], [28, 36], [37, 42], [43, 51], [52, 63], [64, 68], [69, 70], [71, 72], [73, 77], [78, 79], [80, 84], [85, 93], [94, 95], [96, 103], [104, 106], [107, 110], [111, 112], [113, 114], [115, 119], [119, 120]]}
{"doc_key": "ai-train-31", "ner": [[6, 11, "misc"], [13, 13, "field"], [15, 17, "university"], [24, 27, "field"], [29, 33, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 11, 13, 13, "topic", "topic_of_award", false, false], [6, 11, 15, 17, "origin", "", true, false], [24, 27, 29, 33, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Recebeu", "dois", "t\u00edtulos", "honor\u00edficos", ",", "um", "S.", "V.", "della", "laurea", "ad", "honorem", "em", "Psicologia", "pela", "Universidade", "de", "P\u00e1dua", "em", "1995", "e", "um", "doutorado", "em", "Desenho", "e", "Engenharia", "Industrial", "pela", "Universidade", "de", "Tecnologia", "de", "Delft", "."], "sentence-detokenized": "Recebeu dois t\u00edtulos honor\u00edficos, um S. V. della laurea ad honorem em Psicologia pela Universidade de P\u00e1dua em 1995 e um doutorado em Desenho e Engenharia Industrial pela Universidade de Tecnologia de Delft.", "token2charspan": [[0, 7], [8, 12], [13, 20], [21, 32], [32, 33], [34, 36], [37, 39], [40, 42], [43, 48], [49, 55], [56, 58], [59, 66], [67, 69], [70, 80], [81, 85], [86, 98], [99, 101], [102, 107], [108, 110], [111, 115], [116, 117], [118, 120], [121, 130], [131, 133], [134, 141], [142, 143], [144, 154], [155, 165], [166, 170], [171, 183], [184, 186], [187, 197], [198, 200], [201, 206], [206, 207]]}
{"doc_key": "ai-train-32", "ner": [[6, 7, "researcher"], [11, 14, "organisation"], [16, 16, "location"], [18, 18, "researcher"], [28, 29, "misc"], [43, 45, "misc"], [62, 63, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[6, 7, 11, 14, "physical", "", false, false], [6, 7, 11, 14, "role", "", false, false], [11, 14, 16, 16, "physical", "", false, false], [18, 18, 28, 29, "related-to", "works_with", true, false], [18, 18, 43, 45, "related-to", "works_with", true, false], [18, 18, 62, 63, "related-to", "works_with", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Com", "o", "colaborador", "de", "longa", "data", "Laurent", "Cohen", ",", "neurologista", "do", "Hospital", "Piti\u00e9", "-", "Salp\u00eatri\u00e8re", "em", "Paris", ",", "Dehaene", "tamb\u00e9m", "identificou", "pacientes", "com", "les\u00f5es", "em", "diferentes", "regi\u00f5es", "do", "lobo", "parietal", "com", "multiplica\u00e7\u00e3o", "deficiente", ",", "mas", "com", "subtrac\u00e7\u00e3o", "preservada", "(", "associada", "a", "les\u00f5es", "do", "lobo", "parietal", "inferior", ")", "e", "outros", "com", "subtrac\u00e7\u00e3o", "deficiente", ",", "mas", "com", "multiplica\u00e7\u00e3o", "preservada", "(", "associada", "a", "les\u00f5es", "do", "sulco", "intraparietal", ")", "."], "sentence-detokenized": "Com o colaborador de longa data Laurent Cohen, neurologista do Hospital Piti\u00e9-Salp\u00eatri\u00e8re em Paris, Dehaene tamb\u00e9m identificou pacientes com les\u00f5es em diferentes regi\u00f5es do lobo parietal com multiplica\u00e7\u00e3o deficiente, mas com subtrac\u00e7\u00e3o preservada (associada a les\u00f5es do lobo parietal inferior) e outros com subtrac\u00e7\u00e3o deficiente, mas com multiplica\u00e7\u00e3o preservada (associada a les\u00f5es do sulco intraparietal).", "token2charspan": [[0, 3], [4, 5], [6, 17], [18, 20], [21, 26], [27, 31], [32, 39], [40, 45], [45, 46], [47, 59], [60, 62], [63, 71], [72, 77], [77, 78], [78, 89], [90, 92], [93, 98], [98, 99], [100, 107], [108, 114], [115, 126], [127, 136], [137, 140], [141, 147], [148, 150], [151, 161], [162, 169], [170, 172], [173, 177], [178, 186], [187, 190], [191, 204], [205, 215], [215, 216], [217, 220], [221, 224], [225, 235], [236, 246], [247, 248], [248, 257], [258, 259], [260, 266], [267, 269], [270, 274], [275, 283], [284, 292], [292, 293], [294, 295], [296, 302], [303, 306], [307, 317], [318, 328], [328, 329], [330, 333], [334, 337], [338, 351], [352, 362], [363, 364], [364, 373], [374, 375], [376, 382], [383, 385], [386, 391], [392, 405], [405, 406], [406, 407]]}
{"doc_key": "ai-train-33", "ner": [[6, 8, "product"], [12, 14, "misc"], [16, 17, "misc"], [25, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 14, 6, 8, "topic", "", false, false], [16, 17, 6, 8, "topic", "", false, false], [25, 25, 6, 8, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Mais", "recentemente", ",", "representa\u00e7\u00f5es", "fict\u00edcias", "de", "rob\u00f4s", "artificialmente", "inteligentes", "em", "filmes", "como", "A.I.", "Artificial", "Intelligence", "e", "Ex", "Machina", "e", "a", "adapta\u00e7\u00e3o", "televisiva", "de", "2016", "da", "Westworld", "t\u00eam", "suscitado", "a", "simpatia", "do", "p\u00fablico", "pelos", "pr\u00f3prios", "rob\u00f4s", "."], "sentence-detokenized": "Mais recentemente, representa\u00e7\u00f5es fict\u00edcias de rob\u00f4s artificialmente inteligentes em filmes como A.I. Artificial Intelligence e Ex Machina e a adapta\u00e7\u00e3o televisiva de 2016 da Westworld t\u00eam suscitado a simpatia do p\u00fablico pelos pr\u00f3prios rob\u00f4s.", "token2charspan": [[0, 4], [5, 17], [17, 18], [19, 33], [34, 43], [44, 46], [47, 52], [53, 68], [69, 81], [82, 84], [85, 91], [92, 96], [97, 101], [102, 112], [113, 125], [126, 127], [128, 130], [131, 138], [139, 140], [141, 142], [143, 152], [153, 163], [164, 166], [167, 171], [172, 174], [175, 184], [185, 188], [189, 198], [199, 200], [201, 209], [210, 212], [213, 220], [221, 226], [227, 235], [236, 241], [241, 242]]}
{"doc_key": "ai-train-34", "ner": [[6, 8, "field"], [11, 14, "algorithm"], [17, 19, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 14, 6, 8, "part-of", "", false, false], [17, 19, 6, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Dois", "dos", "principais", "m\u00e9todos", "utilizados", "na", "aprendizagem", "n\u00e3o", "supervisionada", "s\u00e3o", "a", "an\u00e1lise", "de", "componentes", "principais", "e", "a", "an\u00e1lise", "de", "agregados", "."], "sentence-detokenized": "Dois dos principais m\u00e9todos utilizados na aprendizagem n\u00e3o supervisionada s\u00e3o a an\u00e1lise de componentes principais e a an\u00e1lise de agregados.", "token2charspan": [[0, 4], [5, 8], [9, 19], [20, 27], [28, 38], [39, 41], [42, 54], [55, 58], [59, 73], [74, 77], [78, 79], [80, 87], [88, 90], [91, 102], [103, 113], [114, 115], [116, 117], [118, 125], [126, 128], [129, 138], [138, 139]]}
{"doc_key": "ai-train-35", "ner": [[0, 3, "organisation"], [24, 25, "misc"], [30, 31, "misc"], [33, 35, "person"], [41, 42, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[24, 25, 0, 3, "artifact", "", false, false], [30, 31, 0, 3, "artifact", "", false, false], [30, 31, 33, 35, "role", "director_of", false, false], [30, 31, 41, 42, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "Walt", "Disney", "Company", "tamb\u00e9m", "come\u00e7ou", "a", "utilizar", "mais", "proeminentemente", "filmes", "3D", "em", "locais", "especiais", "para", "impressionar", "o", "p\u00fablico", ",", "sendo", "exemplos", "not\u00e1veis", "as", "Magic", "Journeys", "(", "1982", ")", "e", "Captain", "EO", "(", "Francis", "Ford", "Coppola", ",", "1986", ",", "estrelado", "por", "Michael", "Jackson", ")", "."], "sentence-detokenized": "A Walt Disney Company tamb\u00e9m come\u00e7ou a utilizar mais proeminentemente filmes 3D em locais especiais para impressionar o p\u00fablico, sendo exemplos not\u00e1veis as Magic Journeys (1982) e Captain EO (Francis Ford Coppola, 1986, estrelado por Michael Jackson).", "token2charspan": [[0, 1], [2, 6], [7, 13], [14, 21], [22, 28], [29, 36], [37, 38], [39, 47], [48, 52], [53, 69], [70, 76], [77, 79], [80, 82], [83, 89], [90, 99], [100, 104], [105, 117], [118, 119], [120, 127], [127, 128], [129, 134], [135, 143], [144, 152], [153, 155], [156, 161], [162, 170], [171, 172], [172, 176], [176, 177], [178, 179], [180, 187], [188, 190], [191, 192], [192, 199], [200, 204], [205, 212], [212, 213], [214, 218], [218, 219], [220, 229], [230, 233], [234, 241], [242, 249], [249, 250], [250, 251]]}
{"doc_key": "ai-train-36", "ner": [[12, 15, "field"], [20, 24, "task"], [27, 28, "task"], [30, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[20, 24, 12, 15, "part-of", "", false, false], [27, 28, 12, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Desde", "2002", ",", "a", "forma\u00e7\u00e3o", "de", "perceptron", "tornou-se", "popular", "no", "campo", "do", "processamento", "da", "linguagem", "natural", "para", "tarefas", "como", "a", "marca\u00e7\u00e3o", "de", "parte", "da", "fala", "e", "a", "an\u00e1lise", "sint\u00e1ctica", "(", "Collins", ",", "2002", ")", "."], "sentence-detokenized": "Desde 2002, a forma\u00e7\u00e3o de perceptron tornou-se popular no campo do processamento da linguagem natural para tarefas como a marca\u00e7\u00e3o de parte da fala e a an\u00e1lise sint\u00e1ctica (Collins, 2002).", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 13], [14, 22], [23, 25], [26, 36], [37, 46], [47, 54], [55, 57], [58, 63], [64, 66], [67, 80], [81, 83], [84, 93], [94, 101], [102, 106], [107, 114], [115, 119], [120, 121], [122, 130], [131, 133], [134, 139], [140, 142], [143, 147], [148, 149], [150, 151], [152, 159], [160, 170], [171, 172], [172, 179], [179, 180], [181, 185], [185, 186], [186, 187]]}
{"doc_key": "ai-train-37", "ner": [[2, 3, "product"], [9, 13, "organisation"], [15, 16, "organisation"], [18, 18, "country"], [22, 26, "product"], [30, 31, "researcher"], [41, 41, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 13, 2, 3, "role", "introduces_to_market", true, false], [15, 16, 2, 3, "role", "introduces_to_market", true, false], [15, 16, 18, 18, "physical", "", false, false], [22, 26, 41, 41, "related-to", "sold_to", true, false], [30, 31, 22, 26, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["O", "primeiro", "rob\u00f4", "paletizador", "foi", "introduzido", "em", "1963", "pela", "Fuji", "Yusoki", "Kogyo", "Company", ".", "pela", "rob\u00f3tica", "KUKA", "na", "Alemanha", ",", "e", "a", "M\u00e1quina", "Universal", "Program\u00e1vel", "para", "Montagem", "foi", "inventada", "por", "Victor", "Scheinman", "em", "1976", ",", "e", "o", "desenho", "foi", "vendido", "\u00e0", "Unimation", "."], "sentence-detokenized": "O primeiro rob\u00f4 paletizador foi introduzido em 1963 pela Fuji Yusoki Kogyo Company. pela rob\u00f3tica KUKA na Alemanha, e a M\u00e1quina Universal Program\u00e1vel para Montagem foi inventada por Victor Scheinman em 1976, e o desenho foi vendido \u00e0 Unimation.", "token2charspan": [[0, 1], [2, 10], [11, 15], [16, 27], [28, 31], [32, 43], [44, 46], [47, 51], [52, 56], [57, 61], [62, 68], [69, 74], [75, 82], [82, 83], [84, 88], [89, 97], [98, 102], [103, 105], [106, 114], [114, 115], [116, 117], [118, 119], [120, 127], [128, 137], [138, 149], [150, 154], [155, 163], [164, 167], [168, 177], [178, 181], [182, 188], [189, 198], [199, 201], [202, 206], [206, 207], [208, 209], [210, 211], [212, 219], [220, 223], [224, 231], [232, 233], [234, 243], [243, 244]]}
{"doc_key": "ai-train-38", "ner": [[10, 10, "conference"], [12, 12, "researcher"], [21, 21, "field"], [40, 41, "researcher"], [50, 51, "researcher"], [64, 64, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 12, 10, 10, "role", "president_of", false, false], [12, 12, 40, 41, "role", "colleagues", false, false], [21, 21, 64, 64, "named", "same", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Em", "meados", "dos", "anos", "90", ",", "enquanto", "era", "presidente", "da", "AAAI", ",", "Hayes", "come\u00e7ou", "uma", "s\u00e9rie", "de", "ataques", "a", "cr\u00edticos", "da", "IA", ",", "na", "sua", "maior", "parte", "formulados", "sob", "uma", "luz", "ir\u00f3nica", ",", "e", "(", "juntamente", "com", "o", "seu", "colega", "Kenneth", "Ford", ")", "inventou", "um", "pr\u00e9mio", "com", "o", "nome", "de", "Simon", "Newcomb", "para", "ser", "atribu\u00eddo", "pelo", "argumento", "mais", "rid\u00edculo", "que", "contestava", "a", "possibilidade", "da", "IA", "."], "sentence-detokenized": "Em meados dos anos 90, enquanto era presidente da AAAI, Hayes come\u00e7ou uma s\u00e9rie de ataques a cr\u00edticos da IA, na sua maior parte formulados sob uma luz ir\u00f3nica, e (juntamente com o seu colega Kenneth Ford) inventou um pr\u00e9mio com o nome de Simon Newcomb para ser atribu\u00eddo pelo argumento mais rid\u00edculo que contestava a possibilidade da IA.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 18], [19, 21], [21, 22], [23, 31], [32, 35], [36, 46], [47, 49], [50, 54], [54, 55], [56, 61], [62, 69], [70, 73], [74, 79], [80, 82], [83, 90], [91, 92], [93, 101], [102, 104], [105, 107], [107, 108], [109, 111], [112, 115], [116, 121], [122, 127], [128, 138], [139, 142], [143, 146], [147, 150], [151, 158], [158, 159], [160, 161], [162, 163], [163, 173], [174, 177], [178, 179], [180, 183], [184, 190], [191, 198], [199, 203], [203, 204], [205, 213], [214, 216], [217, 223], [224, 227], [228, 229], [230, 234], [235, 237], [238, 243], [244, 251], [252, 256], [257, 260], [261, 270], [271, 275], [276, 285], [286, 290], [291, 299], [300, 303], [304, 314], [315, 316], [317, 330], [331, 333], [334, 336], [336, 337]]}
{"doc_key": "ai-train-39", "ner": [[13, 17, "algorithm"], [41, 43, "algorithm"], [54, 58, "algorithm"], [61, 65, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 17, 41, 43, "named", "same", false, false], [54, 58, 13, 17, "type-of", "", false, false], [61, 65, 13, 17, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Um", "valor", "\u00f3ptimo", "para", "matem\u00e1tica", "alfa", "/", "matem\u00e1tica", "pode", "ser", "encontrado", "usando", "um", "algoritmo", "de", "busca", "de", "linha", ",", "ou", "seja", ",", "a", "magnitude", "da", "matem\u00e1tica", "alfa", "/", "matem\u00e1tica", "\u00e9", "determinada", "encontrando", "o", "valor", "que", "minimiza", "S", ",", "geralmente", "usando", "uma", "busca", "de", "linha", "no", "intervalo", "matem\u00e1tica", "0", "alfa", "1", "/", "matem\u00e1tica", "ou", "uma", "busca", "de", "linha", "de", "retrocesso", "como", "a", "busca", "de", "linha", "de", "Armijo-line", "."], "sentence-detokenized": "Um valor \u00f3ptimo para matem\u00e1tica alfa / matem\u00e1tica pode ser encontrado usando um algoritmo de busca de linha, ou seja, a magnitude da matem\u00e1tica alfa / matem\u00e1tica \u00e9 determinada encontrando o valor que minimiza S, geralmente usando uma busca de linha no intervalo matem\u00e1tica 0 alfa 1 / matem\u00e1tica ou uma busca de linha de retrocesso como a busca de linha de Armijo-line.", "token2charspan": [[0, 2], [3, 8], [9, 15], [16, 20], [21, 31], [32, 36], [37, 38], [39, 49], [50, 54], [55, 58], [59, 69], [70, 76], [77, 79], [80, 89], [90, 92], [93, 98], [99, 101], [102, 107], [107, 108], [109, 111], [112, 116], [116, 117], [118, 119], [120, 129], [130, 132], [133, 143], [144, 148], [149, 150], [151, 161], [162, 163], [164, 175], [176, 187], [188, 189], [190, 195], [196, 199], [200, 208], [209, 210], [210, 211], [212, 222], [223, 229], [230, 233], [234, 239], [240, 242], [243, 248], [249, 251], [252, 261], [262, 272], [273, 274], [275, 279], [280, 281], [282, 283], [284, 294], [295, 297], [298, 301], [302, 307], [308, 310], [311, 316], [317, 319], [320, 330], [331, 335], [336, 337], [338, 343], [344, 346], [347, 352], [353, 355], [356, 367], [367, 368]]}
{"doc_key": "ai-train-40", "ner": [[4, 5, "algorithm"], [7, 7, "algorithm"], [17, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Discute", "as", "t\u00e9cnicas", "de", "pesquisa", "Breadth-first", "e", "Depth-first", ",", "mas", "acaba", "por", "concluir", "que", "os", "resultados", "representam", "sistemas", "especializados", "que", "encarnam", "muitos", "conhecimentos", "t\u00e9cnicos", "mas", "n\u00e3o", "d\u00e3o", "muita", "luz", "sobre", "os", "processos", "mentais", "que", "os", "humanos", "utilizam", "para", "resolver", "tais", "puzzles", "."], "sentence-detokenized": "Discute as t\u00e9cnicas de pesquisa Breadth-first e Depth-first, mas acaba por concluir que os resultados representam sistemas especializados que encarnam muitos conhecimentos t\u00e9cnicos mas n\u00e3o d\u00e3o muita luz sobre os processos mentais que os humanos utilizam para resolver tais puzzles.", "token2charspan": [[0, 7], [8, 10], [11, 19], [20, 22], [23, 31], [32, 45], [46, 47], [48, 59], [59, 60], [61, 64], [65, 70], [71, 74], [75, 83], [84, 87], [88, 90], [91, 101], [102, 113], [114, 122], [123, 137], [138, 141], [142, 150], [151, 157], [158, 171], [172, 180], [181, 184], [185, 188], [189, 192], [193, 198], [199, 202], [203, 208], [209, 211], [212, 221], [222, 229], [230, 233], [234, 236], [237, 244], [245, 253], [254, 258], [259, 267], [268, 272], [273, 280], [280, 281]]}
{"doc_key": "ai-train-41", "ner": [[0, 3, "task"], [6, 8, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["O", "reconhecimento", "da", "fala", "e", "a", "s\u00edntese", "da", "fala", "tratam", "de", "como", "a", "linguagem", "falada", "pode", "ser", "compreendida", "ou", "criada", "utilizando", "computadores", "."], "sentence-detokenized": "O reconhecimento da fala e a s\u00edntese da fala tratam de como a linguagem falada pode ser compreendida ou criada utilizando computadores.", "token2charspan": [[0, 1], [2, 16], [17, 19], [20, 24], [25, 26], [27, 28], [29, 36], [37, 39], [40, 44], [45, 51], [52, 54], [55, 59], [60, 61], [62, 71], [72, 78], [79, 83], [84, 87], [88, 100], [101, 103], [104, 110], [111, 121], [122, 134], [134, 135]]}
{"doc_key": "ai-train-42", "ner": [[14, 15, "algorithm"], [34, 36, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Esta", "teta", "matem\u00e1tica", "^", "^", "/", "matem\u00e1tica", "\u00e9", "normalmente", "estimado", "usando", "um", "procedimento", "de", "M\u00e1xima", "Probabilidade", "(", "matem\u00e1tica", "teta", "^", "^", "{", "*", "}", "==", "teta", "^", "{", "ML", "}", "/", "matem\u00e1tica", ")", "ou", "M\u00e1ximo", "A", "Posteriori", "(", "matem\u00e1tica", "teta", "^", "{", "*", "}", "==", "teta", "^", "^", "{", "MAP", "}", "/", "matem\u00e1tica", ")", "."], "sentence-detokenized": "Esta teta matem\u00e1tica ^ ^ / matem\u00e1tica \u00e9 normalmente estimado usando um procedimento de M\u00e1xima Probabilidade (matem\u00e1tica teta ^ ^ {*} == teta ^ {ML} / matem\u00e1tica) ou M\u00e1ximo A Posteriori (matem\u00e1tica teta ^ {*} == teta ^ ^ {MAP} / matem\u00e1tica).", "token2charspan": [[0, 4], [5, 9], [10, 20], [21, 22], [23, 24], [25, 26], [27, 37], [38, 39], [40, 51], [52, 60], [61, 67], [68, 70], [71, 83], [84, 86], [87, 93], [94, 107], [108, 109], [109, 119], [120, 124], [125, 126], [127, 128], [129, 130], [130, 131], [131, 132], [133, 135], [136, 140], [141, 142], [143, 144], [144, 146], [146, 147], [148, 149], [150, 160], [160, 161], [162, 164], [165, 171], [172, 173], [174, 184], [185, 186], [186, 196], [197, 201], [202, 203], [204, 205], [205, 206], [206, 207], [208, 210], [211, 215], [216, 217], [218, 219], [220, 221], [221, 224], [224, 225], [226, 227], [228, 238], [238, 239], [239, 240]]}
{"doc_key": "ai-train-43", "ner": [[6, 8, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Algumas", "l\u00ednguas", "menos", "faladas", "utilizam", "o", "sintetizador", "eSpeak", "de", "c\u00f3digo", "aberto", "para", "a", "sua", "fala", ";", "produzindo", "uma", "voz", "rob\u00f3tica", "e", "embara\u00e7osa", "que", "pode", "ser", "dif\u00edcil", "de", "compreender", "."], "sentence-detokenized": "Algumas l\u00ednguas menos faladas utilizam o sintetizador eSpeak de c\u00f3digo aberto para a sua fala; produzindo uma voz rob\u00f3tica e embara\u00e7osa que pode ser dif\u00edcil de compreender.", "token2charspan": [[0, 7], [8, 15], [16, 21], [22, 29], [30, 38], [39, 40], [41, 53], [54, 60], [61, 63], [64, 70], [71, 77], [78, 82], [83, 84], [85, 88], [89, 93], [93, 94], [95, 105], [106, 109], [110, 113], [114, 122], [123, 124], [125, 135], [136, 139], [140, 144], [145, 148], [149, 156], [157, 159], [160, 171], [171, 172]]}
{"doc_key": "ai-train-44", "ner": [[20, 20, "programlang"], [41, 42, "programlang"], [44, 44, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[20, 20, 41, 42, "compare", "", false, false], [20, 20, 44, 44, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Embora", "utilizado", "principalmente", "por", "estat\u00edsticos", "e", "outros", "profissionais", "que", "requerem", "um", "ambiente", "para", "computa\u00e7\u00e3o", "estat\u00edstica", "e", "desenvolvimento", "de", "software", ",", "R", "pode", "tamb\u00e9m", "funcionar", "como", "uma", "caixa", "de", "ferramentas", "de", "c\u00e1lculo", "de", "matriz", "geral", "-", "com", "padr\u00f5es", "de", "desempenho", "compar\u00e1veis", "ao", "GNU", "Octave", "ou", "MATLAB", "."], "sentence-detokenized": "Embora utilizado principalmente por estat\u00edsticos e outros profissionais que requerem um ambiente para computa\u00e7\u00e3o estat\u00edstica e desenvolvimento de software, R pode tamb\u00e9m funcionar como uma caixa de ferramentas de c\u00e1lculo de matriz geral - com padr\u00f5es de desempenho compar\u00e1veis ao GNU Octave ou MATLAB.", "token2charspan": [[0, 6], [7, 16], [17, 31], [32, 35], [36, 48], [49, 50], [51, 57], [58, 71], [72, 75], [76, 84], [85, 87], [88, 96], [97, 101], [102, 112], [113, 124], [125, 126], [127, 142], [143, 145], [146, 154], [154, 155], [156, 157], [158, 162], [163, 169], [170, 179], [180, 184], [185, 188], [189, 194], [195, 197], [198, 209], [210, 212], [213, 220], [221, 223], [224, 230], [231, 236], [237, 238], [239, 242], [243, 250], [251, 253], [254, 264], [265, 276], [277, 279], [280, 283], [284, 290], [291, 293], [294, 300], [300, 301]]}
{"doc_key": "ai-train-45", "ner": [[0, 0, "algorithm"], [5, 7, "field"], [10, 11, "misc"], [12, 13, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 7, "part-of", "", false, false], [0, 0, 12, 13, "origin", "", false, false], [10, 11, 12, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Heterodyning", "\u00e9", "uma", "t\u00e9cnica", "de", "processamento", "de", "sinais", "inventada", "pelo", "inventor-engenheiro", "canadiano", "Reginald", "Fessenden", "que", "cria", "novas", "frequ\u00eancias", "atrav\u00e9s", "da", "combina\u00e7\u00e3o", "de", "duas", "frequ\u00eancias", "."], "sentence-detokenized": "Heterodyning \u00e9 uma t\u00e9cnica de processamento de sinais inventada pelo inventor-engenheiro canadiano Reginald Fessenden que cria novas frequ\u00eancias atrav\u00e9s da combina\u00e7\u00e3o de duas frequ\u00eancias.", "token2charspan": [[0, 12], [13, 14], [15, 18], [19, 26], [27, 29], [30, 43], [44, 46], [47, 53], [54, 63], [64, 68], [69, 88], [89, 98], [99, 107], [108, 117], [118, 121], [122, 126], [127, 132], [133, 144], [145, 152], [153, 155], [156, 166], [167, 169], [170, 174], [175, 186], [186, 187]]}
{"doc_key": "ai-train-46", "ner": [[16, 17, "person"], [18, 18, "misc"], [22, 23, "organisation"], [31, 31, "organisation"], [27, 29, "misc"], [33, 34, "person"], [42, 42, "organisation"], [38, 41, "misc"], [44, 45, "person"], [47, 48, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[16, 17, 18, 18, "role", "actor_in", false, false], [18, 18, 22, 23, "artifact", "", false, false], [27, 29, 31, 31, "artifact", "", false, false], [33, 34, 27, 29, "role", "actor_in", false, false], [38, 41, 42, 42, "artifact", "", false, false], [44, 45, 38, 41, "role", "actor_in", false, false], [47, 48, 38, 41, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["V\u00e1rias", "outras", "caracter\u00edsticas", "que", "ajudaram", "a", "recolocar", "o", "3D", "no", "mapa", "nesse", "m\u00eas", "foram", "a", "caracter\u00edstica", "John", "Wayne", "Hondo", "(", "distribu\u00edda", "pela", "Warner", "Bros.", ")", ",", "a", "Miss", "Sadie", "Thompson", "da", "Columbia", "com", "Rita", "Hayworth", ",", "e", "o", "Money", "From", "Home", "da", "Paramount", "com", "Dean", "Martin", "e", "Jerry", "Lewis", "."], "sentence-detokenized": "V\u00e1rias outras caracter\u00edsticas que ajudaram a recolocar o 3D no mapa nesse m\u00eas foram a caracter\u00edstica John Wayne Hondo (distribu\u00edda pela Warner Bros. ), a Miss Sadie Thompson da Columbia com Rita Hayworth, e o Money From Home da Paramount com Dean Martin e Jerry Lewis.", "token2charspan": [[0, 6], [7, 13], [14, 29], [30, 33], [34, 42], [43, 44], [45, 54], [55, 56], [57, 59], [60, 62], [63, 67], [68, 73], [74, 77], [78, 83], [84, 85], [86, 100], [101, 105], [106, 111], [112, 117], [118, 119], [119, 130], [131, 135], [136, 142], [143, 148], [149, 150], [150, 151], [152, 153], [154, 158], [159, 164], [165, 173], [174, 176], [177, 185], [186, 189], [190, 194], [195, 203], [203, 204], [205, 206], [207, 208], [209, 214], [215, 219], [220, 224], [225, 227], [228, 237], [238, 241], [242, 246], [247, 253], [254, 255], [256, 261], [262, 267], [267, 268]]}
{"doc_key": "ai-train-47", "ner": [[0, 0, "product"], [8, 9, "field"], [5, 7, "task"], [17, 17, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 7, "general-affiliation", "", false, false], [0, 0, 17, 17, "artifact", "", false, false], [5, 7, 8, 9, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["DeepFace", "\u00e9", "um", "sistema", "de", "reconhecimento", "facial", "de", "aprendizagem", "profunda", "criado", "por", "um", "grupo", "de", "pesquisa", "no", "Facebook", "."], "sentence-detokenized": "DeepFace \u00e9 um sistema de reconhecimento facial de aprendizagem profunda criado por um grupo de pesquisa no Facebook.", "token2charspan": [[0, 8], [9, 10], [11, 13], [14, 21], [22, 24], [25, 39], [40, 46], [47, 49], [50, 62], [63, 71], [72, 78], [79, 82], [83, 85], [86, 91], [92, 94], [95, 103], [104, 106], [107, 115], [115, 116]]}
{"doc_key": "ai-train-48", "ner": [[0, 3, "field"], [11, 11, "conference"], [18, 19, "field"], [26, 31, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 18, 19, "part-of", "subfield", false, false], [11, 11, 0, 3, "topic", "", false, false], [26, 31, 0, 3, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["O", "processamento", "de", "geometria", "\u00e9", "um", "t\u00f3pico", "de", "investiga\u00e7\u00e3o", "comum", "no", "SIGGRAPH", ",", "a", "principal", "confer\u00eancia", "acad\u00e9mica", "de", "computa\u00e7\u00e3o", "gr\u00e1fica", ",", "e", "o", "principal", "t\u00f3pico", "do", "Simp\u00f3sio", "anual", "sobre", "Processamento", "de", "Geometria", "."], "sentence-detokenized": "O processamento de geometria \u00e9 um t\u00f3pico de investiga\u00e7\u00e3o comum no SIGGRAPH, a principal confer\u00eancia acad\u00e9mica de computa\u00e7\u00e3o gr\u00e1fica, e o principal t\u00f3pico do Simp\u00f3sio anual sobre Processamento de Geometria.", "token2charspan": [[0, 1], [2, 15], [16, 18], [19, 28], [29, 30], [31, 33], [34, 40], [41, 43], [44, 56], [57, 62], [63, 65], [66, 74], [74, 75], [76, 77], [78, 87], [88, 99], [100, 109], [110, 112], [113, 123], [124, 131], [131, 132], [133, 134], [135, 136], [137, 146], [147, 153], [154, 156], [157, 165], [166, 171], [172, 177], [178, 191], [192, 194], [195, 204], [204, 205]]}
{"doc_key": "ai-train-49", "ner": [[0, 3, "task"], [6, 8, "task"], [17, 20, "algorithm"], [22, 22, "algorithm"], [26, 28, "algorithm"], [30, 30, "algorithm"], [36, 39, "algorithm"], [41, 41, "algorithm"], [46, 46, "misc"], [52, 53, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[17, 20, 46, 46, "general-affiliation", "", false, false], [22, 22, 17, 20, "named", "", false, false], [26, 28, 46, 46, "general-affiliation", "", false, false], [30, 30, 26, 28, "named", "", false, false], [36, 39, 46, 46, "general-affiliation", "", false, false], [41, 41, 36, 39, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["A", "extrac\u00e7\u00e3o", "de", "caracter\u00edsticas", "e", "a", "redu\u00e7\u00e3o", "de", "dimens\u00f5es", "podem", "ser", "combinadas", "numa", "s\u00f3", "etapa", "utilizando", "a", "An\u00e1lise", "de", "Componentes", "Principais", "(", "PCA", ")", ",", "a", "An\u00e1lise", "Linear", "Discriminante", "(", "LDA", ")", ",", "ou", "t\u00e9cnicas", "de", "An\u00e1lise", "de", "Correla\u00e7\u00e3o", "Can\u00f3nica", "(", "CCA", ")", "como", "etapa", "de", "pr\u00e9-processamento", ",", "seguida", "de", "agrupamento", "por", "k", "-NN", "em", "vectores", "de", "caracter\u00edsticas", "no", "espa\u00e7o", "de", "dimens\u00f5es", "reduzidas", "."], "sentence-detokenized": "A extrac\u00e7\u00e3o de caracter\u00edsticas e a redu\u00e7\u00e3o de dimens\u00f5es podem ser combinadas numa s\u00f3 etapa utilizando a An\u00e1lise de Componentes Principais (PCA), a An\u00e1lise Linear Discriminante (LDA), ou t\u00e9cnicas de An\u00e1lise de Correla\u00e7\u00e3o Can\u00f3nica (CCA) como etapa de pr\u00e9-processamento, seguida de agrupamento por k -NN em vectores de caracter\u00edsticas no espa\u00e7o de dimens\u00f5es reduzidas.", "token2charspan": [[0, 1], [2, 11], [12, 14], [15, 30], [31, 32], [33, 34], [35, 42], [43, 45], [46, 55], [56, 61], [62, 65], [66, 76], [77, 81], [82, 84], [85, 90], [91, 101], [102, 103], [104, 111], [112, 114], [115, 126], [127, 137], [138, 139], [139, 142], [142, 143], [143, 144], [145, 146], [147, 154], [155, 161], [162, 175], [176, 177], [177, 180], [180, 181], [181, 182], [183, 185], [186, 194], [195, 197], [198, 205], [206, 208], [209, 219], [220, 228], [229, 230], [230, 233], [233, 234], [235, 239], [240, 245], [246, 248], [249, 266], [266, 267], [268, 275], [276, 278], [279, 290], [291, 294], [295, 296], [297, 300], [301, 303], [304, 312], [313, 315], [316, 331], [332, 334], [335, 341], [342, 344], [345, 354], [355, 364], [364, 365]]}
{"doc_key": "ai-train-50", "ner": [[0, 3, "algorithm"], [11, 12, "field"], [15, 17, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 11, 12, "related-to", "good_at", true, false], [0, 3, 15, 17, "related-to", "good_at", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "redes", "neurais", "artificiais", "s\u00e3o", "modelos", "computacionais", "que", "se", "destacam", "na", "aprendizagem", "mec\u00e2nica", "e", "no", "reconhecimento", "de", "padr\u00f5es", "."], "sentence-detokenized": "As redes neurais artificiais s\u00e3o modelos computacionais que se destacam na aprendizagem mec\u00e2nica e no reconhecimento de padr\u00f5es.", "token2charspan": [[0, 2], [3, 8], [9, 16], [17, 28], [29, 32], [33, 40], [41, 55], [56, 59], [60, 62], [63, 71], [72, 74], [75, 87], [88, 96], [97, 98], [99, 101], [102, 116], [117, 119], [120, 127], [127, 128]]}
{"doc_key": "ai-train-51", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 11, "misc"], [13, 17, "conference"], [19, 19, "conference"], [33, 36, "algorithm"], [37, 38, "researcher"], [40, 41, "researcher"], [43, 49, "misc"], [51, 60, "conference"], [62, 62, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[7, 11, 0, 2, "artifact", "", false, false], [7, 11, 4, 5, "artifact", "", false, false], [7, 11, 13, 17, "temporal", "", false, false], [19, 19, 13, 17, "named", "", false, false], [43, 49, 33, 36, "topic", "", false, false], [43, 49, 37, 38, "artifact", "", false, false], [43, 49, 40, 41, "artifact", "", false, false], [43, 49, 51, 60, "temporal", "", false, false], [62, 62, 51, 60, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["C", ".", "Papageorgiou", "e", "T.", "Poggio", ",", "A", "Trainable", "Pedestrian", "Detection", "system", ",", "International", "Journal", "of", "Computer", "Vision", "(", "IJCV", ")", ",", "p\u00e1ginas", "1:", "15-33", ",", "2000", "outros", "usam", "caracter\u00edsticas", "locais", "como", "o", "histograma", "de", "gradientes", "orientados", "N.", "Dalal", ",", "B.", "Triggs", ",", "Histograms", "of", "oriented", "gradients", "for", "human", "detection", ",", "IEEE", "Computer", "Society", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", ",", "p\u00e1ginas", "1", ":", "886-893", ",", "2005", "descriptors", "."], "sentence-detokenized": "C. Papageorgiou e T. Poggio, A Trainable Pedestrian Detection system, International Journal of Computer Vision (IJCV), p\u00e1ginas 1: 15-33, 2000 outros usam caracter\u00edsticas locais como o histograma de gradientes orientados N. Dalal, B. Triggs, Histograms of oriented gradients for human detection, IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), p\u00e1ginas 1: 886-893, 2005 descriptors.", "token2charspan": [[0, 1], [1, 2], [3, 15], [16, 17], [18, 20], [21, 27], [27, 28], [29, 30], [31, 40], [41, 51], [52, 61], [62, 68], [68, 69], [70, 83], [84, 91], [92, 94], [95, 103], [104, 110], [111, 112], [112, 116], [116, 117], [117, 118], [119, 126], [127, 129], [130, 135], [135, 136], [137, 141], [142, 148], [149, 153], [154, 169], [170, 176], [177, 181], [182, 183], [184, 194], [195, 197], [198, 208], [209, 219], [220, 222], [223, 228], [228, 229], [230, 232], [233, 239], [239, 240], [241, 251], [252, 254], [255, 263], [264, 273], [274, 277], [278, 283], [284, 293], [293, 294], [295, 299], [300, 308], [309, 316], [317, 327], [328, 330], [331, 339], [340, 346], [347, 350], [351, 358], [359, 370], [371, 372], [372, 376], [376, 377], [377, 378], [379, 386], [387, 388], [388, 389], [390, 397], [397, 398], [399, 403], [404, 415], [415, 416]]}
{"doc_key": "ai-train-52", "ner": [[1, 1, "algorithm"], [6, 8, "algorithm"], [12, 14, "task"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 6, 8, "type-of", "", false, false], [12, 14, 1, 1, "usage", "", true, false], [12, 14, 18, 19, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Um", "autocodificador", "\u00e9", "um", "tipo", "de", "rede", "neural", "artificial", "utilizado", "para", "aprender", "Aprendizagem", "de", "caracter\u00edsticas", "de", "uma", "forma", "n\u00e3o", "supervisionada", "."], "sentence-detokenized": "Um autocodificador \u00e9 um tipo de rede neural artificial utilizado para aprender Aprendizagem de caracter\u00edsticas de uma forma n\u00e3o supervisionada.", "token2charspan": [[0, 2], [3, 18], [19, 20], [21, 23], [24, 28], [29, 31], [32, 36], [37, 43], [44, 54], [55, 64], [65, 69], [70, 78], [79, 91], [92, 94], [95, 110], [111, 113], [114, 117], [118, 123], [124, 127], [128, 142], [142, 143]]}
{"doc_key": "ai-train-53", "ner": [[0, 0, "researcher"], [5, 5, "organisation"], [10, 11, "field"], [13, 15, "field"], [20, 26, "organisation"], [28, 28, "organisation"], [34, 36, "field"], [38, 40, "field"], [46, 46, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 5, 5, "role", "fellow_of", false, false], [0, 0, 10, 11, "related-to", "contributes_to", false, false], [0, 0, 13, 15, "related-to", "contributes_to", false, false], [0, 0, 20, 26, "role", "fellow_of", false, false], [0, 0, 34, 36, "related-to", "contributes_to", false, false], [0, 0, 38, 40, "related-to", "contributes_to", false, false], [28, 28, 20, 26, "named", "", false, false], [46, 46, 20, 26, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Haralick", "\u00e9", "um", "Fellow", "do", "IEEE", "pelas", "suas", "contribui\u00e7\u00f5es", "em", "vis\u00e3o", "computacional", "e", "processamento", "de", "imagem", "e", "um", "Fellow", "da", "Associa\u00e7\u00e3o", "Internacional", "para", "o", "Reconhecimento", "de", "Padr\u00f5es", "(", "IAPR", ")", "pelas", "suas", "contribui\u00e7\u00f5es", "em", "reconhecimento", "de", "padr\u00f5es", ",", "processamento", "de", "imagem", ",", "e", "pelo", "servi\u00e7o", "ao", "IAPR", "."], "sentence-detokenized": "Haralick \u00e9 um Fellow do IEEE pelas suas contribui\u00e7\u00f5es em vis\u00e3o computacional e processamento de imagem e um Fellow da Associa\u00e7\u00e3o Internacional para o Reconhecimento de Padr\u00f5es (IAPR) pelas suas contribui\u00e7\u00f5es em reconhecimento de padr\u00f5es, processamento de imagem, e pelo servi\u00e7o ao IAPR.", "token2charspan": [[0, 8], [9, 10], [11, 13], [14, 20], [21, 23], [24, 28], [29, 34], [35, 39], [40, 53], [54, 56], [57, 62], [63, 76], [77, 78], [79, 92], [93, 95], [96, 102], [103, 104], [105, 107], [108, 114], [115, 117], [118, 128], [129, 142], [143, 147], [148, 149], [150, 164], [165, 167], [168, 175], [176, 177], [177, 181], [181, 182], [183, 188], [189, 193], [194, 207], [208, 210], [211, 225], [226, 228], [229, 236], [236, 237], [238, 251], [252, 254], [255, 261], [261, 262], [263, 264], [265, 269], [270, 277], [278, 280], [281, 285], [285, 286]]}
{"doc_key": "ai-train-54", "ner": [[4, 8, "task"], [14, 16, "algorithm"], [18, 18, "algorithm"], [22, 23, "researcher"], [25, 26, "organisation"], [28, 29, "researcher"], [31, 33, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 8, 14, 16, "usage", "", false, false], [14, 16, 22, 23, "origin", "", true, false], [14, 16, 28, 29, "origin", "", true, false], [18, 18, 14, 16, "named", "", false, false], [22, 23, 25, 26, "physical", "", false, false], [22, 23, 25, 26, "role", "", false, false], [28, 29, 31, 33, "physical", "", false, false], [28, 29, 31, 33, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["A", "primeira", "tentativa", "de", "ASR", "de", "ponta", "a", "ponta", "foi", "com", "sistemas", "baseados", "na", "Classifica\u00e7\u00e3o", "Temporal", "Connectionist", "(", "CTC", ")", "introduzida", "por", "Alex", "Graves", "do", "Google", "DeepMind", "e", "Navdeep", "Jaitly", "da", "Universidade", "de", "Toronto", "em", "2014", "."], "sentence-detokenized": "A primeira tentativa de ASR de ponta a ponta foi com sistemas baseados na Classifica\u00e7\u00e3o Temporal Connectionist (CTC) introduzida por Alex Graves do Google DeepMind e Navdeep Jaitly da Universidade de Toronto em 2014.", "token2charspan": [[0, 1], [2, 10], [11, 20], [21, 23], [24, 27], [28, 30], [31, 36], [37, 38], [39, 44], [45, 48], [49, 52], [53, 61], [62, 70], [71, 73], [74, 87], [88, 96], [97, 110], [111, 112], [112, 115], [115, 116], [117, 128], [129, 132], [133, 137], [138, 144], [145, 147], [148, 154], [155, 163], [164, 165], [166, 173], [174, 180], [181, 183], [184, 196], [197, 199], [200, 207], [208, 210], [211, 215], [215, 216]]}
{"doc_key": "ai-train-55", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [10, 11, "algorithm"], [13, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 0, 2, "named", "", false, false], [10, 11, 0, 2, "type-of", "", false, false], [13, 13, 10, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "programa\u00e7\u00e3o", "linear-fracional", "(", "LFP", ")", "\u00e9", "uma", "generaliza\u00e7\u00e3o", "da", "programa\u00e7\u00e3o", "linear", "(", "LP", ")", "."], "sentence-detokenized": "A programa\u00e7\u00e3o linear-fracional (LFP) \u00e9 uma generaliza\u00e7\u00e3o da programa\u00e7\u00e3o linear (LP).", "token2charspan": [[0, 1], [2, 13], [14, 30], [31, 32], [32, 35], [35, 36], [37, 38], [39, 42], [43, 56], [57, 59], [60, 71], [72, 78], [79, 80], [80, 82], [82, 83], [83, 84]]}
{"doc_key": "ai-train-56", "ner": [[0, 0, "researcher"], [7, 8, "misc"], [10, 17, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 7, 8, "win-defeat", "", false, false], [7, 8, 10, 17, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lafferty", "recebeu", "in\u00fameros", "pr\u00e9mios", ",", "incluindo", "dois", "Test-of-Time", "awards", "na", "Confer\u00eancia", "Internacional", "sobre", "Aprendizagem", "Autom\u00e1tica", "2011", "&", "2012", ","], "sentence-detokenized": "Lafferty recebeu in\u00fameros pr\u00e9mios, incluindo dois Test-of-Time awards na Confer\u00eancia Internacional sobre Aprendizagem Autom\u00e1tica 2011 & 2012,", "token2charspan": [[0, 8], [9, 16], [17, 25], [26, 33], [33, 34], [35, 44], [45, 49], [50, 62], [63, 69], [70, 72], [73, 84], [85, 98], [99, 104], [105, 117], [118, 128], [129, 133], [134, 135], [136, 140], [140, 141]]}
{"doc_key": "ai-train-57", "ner": [[9, 10, "product"], [12, 12, "programlang"], [26, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Com", "o", "advento", "de", "estruturas", "baseadas", "em", "componentes", "como", ".", "NET", "e", "Java", ",", "os", "ambientes", "de", "desenvolvimento", "baseados", "em", "componentes", "s\u00e3o", "capazes", "de", "implantar", "a", "rede", "neural", "desenvolvida", "nestas", "estruturas", "como", "componentes", "heredit\u00e1rios", "."], "sentence-detokenized": "Com o advento de estruturas baseadas em componentes como .NET e Java, os ambientes de desenvolvimento baseados em componentes s\u00e3o capazes de implantar a rede neural desenvolvida nestas estruturas como componentes heredit\u00e1rios.", "token2charspan": [[0, 3], [4, 5], [6, 13], [14, 16], [17, 27], [28, 36], [37, 39], [40, 51], [52, 56], [57, 58], [58, 61], [62, 63], [64, 68], [68, 69], [70, 72], [73, 82], [83, 85], [86, 101], [102, 110], [111, 113], [114, 125], [126, 129], [130, 137], [138, 140], [141, 150], [151, 152], [153, 157], [158, 164], [165, 177], [178, 184], [185, 195], [196, 200], [201, 212], [213, 225], [225, 226]]}
{"doc_key": "ai-train-58", "ner": [[3, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Tal", "como", "no", "BLEU", ",", "a", "unidade", "b\u00e1sica", "de", "avalia\u00e7\u00e3o", "\u00e9", "a", "frase", ",", "o", "algoritmo", "cria", "primeiro", "um", "alinhamento", "(", "ver", "ilustra\u00e7\u00f5es", ")", "entre", "duas", "frases", ",", "a", "cadeia", "de", "tradu\u00e7\u00e3o", "candidata", ",", "e", "a", "cadeia", "de", "tradu\u00e7\u00e3o", "de", "refer\u00eancia", "."], "sentence-detokenized": "Tal como no BLEU, a unidade b\u00e1sica de avalia\u00e7\u00e3o \u00e9 a frase, o algoritmo cria primeiro um alinhamento (ver ilustra\u00e7\u00f5es) entre duas frases, a cadeia de tradu\u00e7\u00e3o candidata, e a cadeia de tradu\u00e7\u00e3o de refer\u00eancia.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 16], [16, 17], [18, 19], [20, 27], [28, 34], [35, 37], [38, 47], [48, 49], [50, 51], [52, 57], [57, 58], [59, 60], [61, 70], [71, 75], [76, 84], [85, 87], [88, 99], [100, 101], [101, 104], [105, 116], [116, 117], [118, 123], [124, 128], [129, 135], [135, 136], [137, 138], [139, 145], [146, 148], [149, 157], [158, 167], [167, 168], [169, 170], [171, 172], [173, 179], [180, 182], [183, 191], [192, 194], [195, 205], [205, 206]]}
{"doc_key": "ai-train-59", "ner": [[5, 12, "conference"], [27, 27, "task"], [25, 30, "task"], [34, 35, "metrics"], [37, 41, "metrics"], [46, 49, "conference"], [51, 51, "conference"], [54, 54, "location"], [56, 56, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 12, 27, 27, "related-to", "subject_at", false, false], [5, 12, 25, 30, "related-to", "subject_at", false, false], [34, 35, 5, 12, "temporal", "", false, false], [37, 41, 34, 35, "named", "", true, false], [51, 51, 46, 49, "named", "", false, false], [54, 54, 56, 56, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Uma", "das", "m\u00e9tricas", "utilizadas", "nas", "Confer\u00eancias", "anuais", "de", "Compreens\u00e3o", "de", "Documentos", "do", "NIST", ",", "nas", "quais", "grupos", "de", "investiga\u00e7\u00e3o", "submetem", "os", "seus", "sistemas", "tanto", "para", "tarefas", "de", "sum\u00e1rio", "como", "de", "tradu\u00e7\u00e3o", ",", "\u00e9", "a", "m\u00e9trica", "ROUGE", "(", "Recall-Oriented", "Understudy", "for", "Gisting", "Evaluation", ",", "In", "Advances", "of", "Neural", "Information", "Processing", "Systems", "(", "NIPS", ")", ",", "Montreal", ",", "Canad\u00e1", ",", "Dezembro", "-", "2014", "."], "sentence-detokenized": "Uma das m\u00e9tricas utilizadas nas Confer\u00eancias anuais de Compreens\u00e3o de Documentos do NIST, nas quais grupos de investiga\u00e7\u00e3o submetem os seus sistemas tanto para tarefas de sum\u00e1rio como de tradu\u00e7\u00e3o, \u00e9 a m\u00e9trica ROUGE (Recall-Oriented Understudy for Gisting Evaluation, In Advances of Neural Information Processing Systems (NIPS), Montreal, Canad\u00e1, Dezembro - 2014.", "token2charspan": [[0, 3], [4, 7], [8, 16], [17, 27], [28, 31], [32, 44], [45, 51], [52, 54], [55, 66], [67, 69], [70, 80], [81, 83], [84, 88], [88, 89], [90, 93], [94, 99], [100, 106], [107, 109], [110, 122], [123, 131], [132, 134], [135, 139], [140, 148], [149, 154], [155, 159], [160, 167], [168, 170], [171, 178], [179, 183], [184, 186], [187, 195], [195, 196], [197, 198], [199, 200], [201, 208], [209, 214], [215, 216], [216, 231], [232, 242], [243, 246], [247, 254], [255, 265], [265, 266], [267, 269], [270, 278], [279, 281], [282, 288], [289, 300], [301, 311], [312, 319], [320, 321], [321, 325], [325, 326], [326, 327], [328, 336], [336, 337], [338, 344], [344, 345], [346, 354], [355, 356], [357, 361], [361, 362]]}
{"doc_key": "ai-train-60", "ner": [[7, 7, "programlang"], [9, 9, "product"], [11, 12, "programlang"], [16, 16, "product"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 7, 11, 12, "type-of", "", false, false], [7, 7, 22, 22, "named", "", false, false], [9, 9, 11, 12, "part-of", "", false, false], [9, 9, 16, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "mesma", "implementa\u00e7\u00e3o", ",", "para", "correr", "em", "Java", "com", "JShell", "(", "Java", "9", "m\u00ednimo", ")", ":", "codejshell", "scriptfile", "/", "codesyntaxhighlight", "lang", "=", "java"], "sentence-detokenized": "A mesma implementa\u00e7\u00e3o, para correr em Java com JShell (Java 9 m\u00ednimo): codejshell scriptfile / codesyntaxhighlight lang = java", "token2charspan": [[0, 1], [2, 7], [8, 21], [21, 22], [23, 27], [28, 34], [35, 37], [38, 42], [43, 46], [47, 53], [54, 55], [55, 59], [60, 61], [62, 68], [68, 69], [69, 70], [71, 81], [82, 92], [93, 94], [95, 114], [115, 119], [120, 121], [122, 126]]}
{"doc_key": "ai-train-61", "ner": [[1, 2, "metrics"], [6, 7, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 6, 7, "origin", "based_on", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "m\u00e9trica", "NIST", "\u00e9", "baseada", "na", "m\u00e9trica", "BLEU", ",", "mas", "com", "algumas", "altera\u00e7\u00f5es", "."], "sentence-detokenized": "A m\u00e9trica NIST \u00e9 baseada na m\u00e9trica BLEU, mas com algumas altera\u00e7\u00f5es.", "token2charspan": [[0, 1], [2, 9], [10, 14], [15, 16], [17, 24], [25, 27], [28, 35], [36, 40], [40, 41], [42, 45], [46, 49], [50, 57], [58, 68], [68, 69]]}
{"doc_key": "ai-train-62", "ner": [[8, 8, "country"], [10, 12, "university"], [14, 16, "university"], [23, 25, "product"], [29, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 12, 8, 8, "physical", "", false, false], [14, 16, 8, 8, "physical", "", false, false], [23, 25, 10, 12, "origin", "", false, false], [23, 25, 14, 16, "origin", "", false, false], [23, 25, 29, 30, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["No", "final", "dos", "anos", "80", ",", "duas", "universidades", "holandesas", ",", "Universidade", "de", "Groningen", "e", "Universidade", "de", "Twente", ",", "iniciaram", "conjuntamente", "um", "projecto", "chamado", "Gr\u00e1ficos", "do", "Conhecimento", ",", "que", "s\u00e3o", "redes", "sem\u00e2nticas", ",", "mas", "com", "o", "constrangimento", "adicional", "de", "que", "as", "bordas", "s\u00e3o", "restritas", "a", "ser", "de", "um", "conjunto", "limitado", "de", "rela\u00e7\u00f5es", "poss\u00edveis", ",", "para", "facilitar", "as", "alg\u00e9bricas", "no", "gr\u00e1fico", "."], "sentence-detokenized": "No final dos anos 80, duas universidades holandesas, Universidade de Groningen e Universidade de Twente, iniciaram conjuntamente um projecto chamado Gr\u00e1ficos do Conhecimento, que s\u00e3o redes sem\u00e2nticas, mas com o constrangimento adicional de que as bordas s\u00e3o restritas a ser de um conjunto limitado de rela\u00e7\u00f5es poss\u00edveis, para facilitar as alg\u00e9bricas no gr\u00e1fico.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 17], [18, 20], [20, 21], [22, 26], [27, 40], [41, 51], [51, 52], [53, 65], [66, 68], [69, 78], [79, 80], [81, 93], [94, 96], [97, 103], [103, 104], [105, 114], [115, 128], [129, 131], [132, 140], [141, 148], [149, 157], [158, 160], [161, 173], [173, 174], [175, 178], [179, 182], [183, 188], [189, 199], [199, 200], [201, 204], [205, 208], [209, 210], [211, 226], [227, 236], [237, 239], [240, 243], [244, 246], [247, 253], [254, 257], [258, 267], [268, 269], [270, 273], [274, 276], [277, 279], [280, 288], [289, 297], [298, 300], [301, 309], [310, 319], [319, 320], [321, 325], [326, 335], [336, 338], [339, 349], [350, 352], [353, 360], [360, 361]]}
{"doc_key": "ai-train-63", "ner": [[0, 2, "product"], [18, 20, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 18, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Os", "verificadores", "gramaticais", "s\u00e3o", "mais", "frequentemente", "implementados", "como", "uma", "caracter\u00edstica", "de", "um", "programa", "maior", ",", "tal", "como", "um", "processador", "de", "texto", ",", "mas", "tamb\u00e9m", "est\u00e3o", "dispon\u00edveis", "como", "uma", "aplica\u00e7\u00e3o", "aut\u00f3noma", "que", "pode", "ser", "activada", "a", "partir", "de", "programas", "que", "funcionam", "com", "texto", "edit\u00e1vel", "."], "sentence-detokenized": "Os verificadores gramaticais s\u00e3o mais frequentemente implementados como uma caracter\u00edstica de um programa maior, tal como um processador de texto, mas tamb\u00e9m est\u00e3o dispon\u00edveis como uma aplica\u00e7\u00e3o aut\u00f3noma que pode ser activada a partir de programas que funcionam com texto edit\u00e1vel.", "token2charspan": [[0, 2], [3, 16], [17, 28], [29, 32], [33, 37], [38, 52], [53, 66], [67, 71], [72, 75], [76, 90], [91, 93], [94, 96], [97, 105], [106, 111], [111, 112], [113, 116], [117, 121], [122, 124], [125, 136], [137, 139], [140, 145], [145, 146], [147, 150], [151, 157], [158, 163], [164, 175], [176, 180], [181, 184], [185, 194], [195, 203], [204, 207], [208, 212], [213, 216], [217, 225], [226, 227], [228, 234], [235, 237], [238, 247], [248, 251], [252, 261], [262, 265], [266, 271], [272, 280], [280, 281]]}
{"doc_key": "ai-train-64", "ner": [[3, 9, "organisation"], [11, 17, "conference"], [19, 22, "organisation"], [27, 29, "conference"], [31, 33, "conference"], [36, 38, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["\u00c9", "membro", "da", "Associa\u00e7\u00e3o", "Americana", "para", "o", "Progresso", "da", "Ci\u00eancia", ",", "Associa\u00e7\u00e3o", "para", "o", "Progresso", "da", "Intelig\u00eancia", "Artificial", "e", "Sociedade", "de", "Ci\u00eancia", "Cognitiva", ",", "e", "editor", "da", "J.", "Automated", "Reasoning", ",", "J.", "Learning", "Sciences", ",", "e", "J.", "Applied", "Ontology", "."], "sentence-detokenized": "\u00c9 membro da Associa\u00e7\u00e3o Americana para o Progresso da Ci\u00eancia, Associa\u00e7\u00e3o para o Progresso da Intelig\u00eancia Artificial e Sociedade de Ci\u00eancia Cognitiva, e editor da J. Automated Reasoning, J. Learning Sciences, e J. Applied Ontology.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 22], [23, 32], [33, 37], [38, 39], [40, 49], [50, 52], [53, 60], [60, 61], [62, 72], [73, 77], [78, 79], [80, 89], [90, 92], [93, 105], [106, 116], [117, 118], [119, 128], [129, 131], [132, 139], [140, 149], [149, 150], [151, 152], [153, 159], [160, 162], [163, 165], [166, 175], [176, 185], [185, 186], [187, 189], [190, 198], [199, 207], [207, 208], [209, 210], [211, 213], [214, 221], [222, 230], [230, 231]]}
{"doc_key": "ai-train-65", "ner": [[0, 3, "algorithm"], [5, 5, "algorithm"], [11, 13, "task"], [22, 23, "researcher"], [25, 27, "university"], [29, 30, "researcher"], [32, 35, "organisation"], [37, 37, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 3, 11, 13, "type-of", "", false, false], [0, 3, 22, 23, "origin", "", false, false], [0, 3, 29, 30, "origin", "", false, false], [5, 5, 0, 3, "named", "", false, false], [22, 23, 25, 27, "physical", "", false, false], [22, 23, 25, 27, "role", "", false, false], [29, 30, 32, 35, "role", "", false, false], [37, 37, 32, 35, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["A", "codifica\u00e7\u00e3o", "preditiva", "linear", "(", "LPC", ")", ",", "uma", "forma", "de", "codifica\u00e7\u00e3o", "de", "fala", ",", "come\u00e7ou", "a", "ser", "desenvolvida", "com", "o", "trabalho", "Fumitada", "Itakura", "da", "Universidade", "de", "Nagoya", "e", "Shuzo", "Saito", "da", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "em", "1966", "."], "sentence-detokenized": "A codifica\u00e7\u00e3o preditiva linear (LPC), uma forma de codifica\u00e7\u00e3o de fala, come\u00e7ou a ser desenvolvida com o trabalho Fumitada Itakura da Universidade de Nagoya e Shuzo Saito da Nippon Telegraph and Telephone (NTT) em 1966.", "token2charspan": [[0, 1], [2, 13], [14, 23], [24, 30], [31, 32], [32, 35], [35, 36], [36, 37], [38, 41], [42, 47], [48, 50], [51, 62], [63, 65], [66, 70], [70, 71], [72, 79], [80, 81], [82, 85], [86, 98], [99, 102], [103, 104], [105, 113], [114, 122], [123, 130], [131, 133], [134, 146], [147, 149], [150, 156], [157, 158], [159, 164], [165, 170], [171, 173], [174, 180], [181, 190], [191, 194], [195, 204], [205, 206], [206, 209], [209, 210], [211, 213], [214, 218], [218, 219]]}
{"doc_key": "ai-train-66", "ner": [[60, 62, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Se", "o", "sinal", "for", "mais", "erg\u00f3dico", ",", "todos", "os", "caminhos", "de", "amostra", "exibem", "a", "mesma", "m\u00e9dia", "temporal", "e", ",", "portanto", ",", "matem\u00e1tica", "_", "x", "^", "^", "{", "n", "/", "T", "_", "0", "}", "(", "tau", ")", "=", "}", "widehat", "{", "R", "}", "_", "x", "^", "{", "n", "/", "T", "_", "0", "}", "(", "tau", ")", "/", "matem\u00e1tica", "em", "sentido", "de", "erro", "quadr\u00e1tico", "m\u00e9dio", "."], "sentence-detokenized": "Se o sinal for mais erg\u00f3dico, todos os caminhos de amostra exibem a mesma m\u00e9dia temporal e, portanto, matem\u00e1tica _ x ^ ^ {n / T _ 0} (tau) =} widehat {R} _ x ^ {n / T _ 0} (tau) / matem\u00e1tica em sentido de erro quadr\u00e1tico m\u00e9dio.", "token2charspan": [[0, 2], [3, 4], [5, 10], [11, 14], [15, 19], [20, 28], [28, 29], [30, 35], [36, 38], [39, 47], [48, 50], [51, 58], [59, 65], [66, 67], [68, 73], [74, 79], [80, 88], [89, 90], [90, 91], [92, 100], [100, 101], [102, 112], [113, 114], [115, 116], [117, 118], [119, 120], [121, 122], [122, 123], [124, 125], [126, 127], [128, 129], [130, 131], [131, 132], [133, 134], [134, 137], [137, 138], [139, 140], [140, 141], [142, 149], [150, 151], [151, 152], [152, 153], [154, 155], [156, 157], [158, 159], [160, 161], [161, 162], [163, 164], [165, 166], [167, 168], [169, 170], [170, 171], [172, 173], [173, 176], [176, 177], [178, 179], [180, 190], [191, 193], [194, 201], [202, 204], [205, 209], [210, 220], [221, 226], [226, 227]]}
{"doc_key": "ai-train-67", "ner": [[0, 3, "task"], [6, 8, "task"], [16, 19, "algorithm"], [21, 21, "algorithm"], [24, 26, "algorithm"], [28, 28, "algorithm"], [31, 34, "algorithm"], [36, 36, "algorithm"], [42, 46, "algorithm"], [48, 48, "algorithm"], [52, 54, "misc"], [59, 59, "algorithm"], [61, 63, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[16, 19, 52, 54, "related-to", "", false, false], [21, 21, 16, 19, "named", "", false, false], [24, 26, 52, 54, "related-to", "", false, false], [28, 28, 24, 26, "named", "", false, false], [31, 34, 52, 54, "related-to", "", false, false], [36, 36, 31, 34, "named", "", false, false], [42, 46, 52, 54, "related-to", "", false, false], [48, 48, 42, 46, "named", "", false, false], [59, 59, 61, 63, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["A", "extrac\u00e7\u00e3o", "de", "caracter\u00edsticas", "e", "a", "redu\u00e7\u00e3o", "de", "dimens\u00f5es", "podem", "ser", "combinadas", "numa", "\u00fanica", "etapa", "utilizando", "an\u00e1lise", "de", "componentes", "principais", "(", "PCA", ")", ",", "an\u00e1lise", "linear", "discriminante", "(", "LDA", ")", ",", "an\u00e1lise", "de", "correla\u00e7\u00e3o", "can\u00f3nica", "(", "CCA", ")", ",", "ou", "t\u00e9cnicas", "de", "factoriza\u00e7\u00e3o", "de", "matriz", "n\u00e3o", "negativa", "(", "NMF", ")", "como", "uma", "etapa", "de", "pr\u00e9-processamento", "seguida", "de", "agrega\u00e7\u00e3o", "por", "K-NN", "em", "vectores", "de", "caracter\u00edsticas", "no", "espa\u00e7o", "de", "dimens\u00f5es", "reduzidas", "."], "sentence-detokenized": "A extrac\u00e7\u00e3o de caracter\u00edsticas e a redu\u00e7\u00e3o de dimens\u00f5es podem ser combinadas numa \u00fanica etapa utilizando an\u00e1lise de componentes principais (PCA), an\u00e1lise linear discriminante (LDA), an\u00e1lise de correla\u00e7\u00e3o can\u00f3nica (CCA), ou t\u00e9cnicas de factoriza\u00e7\u00e3o de matriz n\u00e3o negativa (NMF) como uma etapa de pr\u00e9-processamento seguida de agrega\u00e7\u00e3o por K-NN em vectores de caracter\u00edsticas no espa\u00e7o de dimens\u00f5es reduzidas.", "token2charspan": [[0, 1], [2, 11], [12, 14], [15, 30], [31, 32], [33, 34], [35, 42], [43, 45], [46, 55], [56, 61], [62, 65], [66, 76], [77, 81], [82, 87], [88, 93], [94, 104], [105, 112], [113, 115], [116, 127], [128, 138], [139, 140], [140, 143], [143, 144], [144, 145], [146, 153], [154, 160], [161, 174], [175, 176], [176, 179], [179, 180], [180, 181], [182, 189], [190, 192], [193, 203], [204, 212], [213, 214], [214, 217], [217, 218], [218, 219], [220, 222], [223, 231], [232, 234], [235, 247], [248, 250], [251, 257], [258, 261], [262, 270], [271, 272], [272, 275], [275, 276], [277, 281], [282, 285], [286, 291], [292, 294], [295, 312], [313, 320], [321, 323], [324, 333], [334, 337], [338, 342], [343, 345], [346, 354], [355, 357], [358, 373], [374, 376], [377, 383], [384, 386], [387, 396], [397, 406], [406, 407]]}
{"doc_key": "ai-train-68", "ner": [[4, 4, "programlang"], [6, 6, "programlang"], [8, 8, "programlang"], [10, 10, "programlang"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[16, 16, 4, 4, "related-to", "program_type_compatible_with", false, false], [16, 16, 6, 6, "related-to", "program_type_compatible_with", false, false], [16, 16, 8, 8, "related-to", "program_type_compatible_with", false, false], [16, 16, 10, 10, "related-to", "program_type_compatible_with", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["As", "bibliotecas", "escritas", "em", "Perl", ",", "Java", ",", "ActiveX", "ou", ".NET", "podem", "ser", "chamadas", "directamente", "da", "MATLAB", ","], "sentence-detokenized": "As bibliotecas escritas em Perl, Java, ActiveX ou .NET podem ser chamadas directamente da MATLAB,", "token2charspan": [[0, 2], [3, 14], [15, 23], [24, 26], [27, 31], [31, 32], [33, 37], [37, 38], [39, 46], [47, 49], [50, 54], [55, 60], [61, 64], [65, 73], [74, 86], [87, 89], [90, 96], [96, 97]]}
{"doc_key": "ai-train-69", "ner": [[3, 8, "task"], [10, 13, "task"], [30, 32, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 8, 10, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "tarefa", "de", "reconhecimento", "das", "entidades", "nomeadas", "no", "texto", "\u00e9", "Reconhecimento", "de", "Entidade", "Nomeada", ",", "enquanto", "a", "tarefa", "de", "determinar", "a", "identidade", "das", "entidades", "nomeadas", "mencionadas", "no", "texto", "\u00e9", "chamada", "Entidade", "de", "Liga\u00e7\u00e3o", "."], "sentence-detokenized": "A tarefa de reconhecimento das entidades nomeadas no texto \u00e9 Reconhecimento de Entidade Nomeada, enquanto a tarefa de determinar a identidade das entidades nomeadas mencionadas no texto \u00e9 chamada Entidade de Liga\u00e7\u00e3o.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 26], [27, 30], [31, 40], [41, 49], [50, 52], [53, 58], [59, 60], [61, 75], [76, 78], [79, 87], [88, 95], [95, 96], [97, 105], [106, 107], [108, 114], [115, 117], [118, 128], [129, 130], [131, 141], [142, 145], [146, 155], [156, 164], [165, 176], [177, 179], [180, 185], [186, 187], [188, 195], [196, 204], [205, 207], [208, 215], [215, 216]]}
{"doc_key": "ai-train-70", "ner": [[1, 2, "algorithm"], [26, 26, "programlang"], [25, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 25, 25, "part-of", "", true, false], [25, 25, 26, 26, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "fun\u00e7\u00f5es", "sigmoid", "e", "derivados", "utilizados", "no", "pacote", "foram", "originalmente", "inclu\u00eddos", "no", "pacote", ",", "a", "partir", "da", "vers\u00e3o", "0.8.0", ",", "estes", "foram", "lan\u00e7ados", "num", "pacote", "sigmoid", "R", "separado", ",", "com", "a", "inten\u00e7\u00e3o", "de", "permitir", "uma", "utiliza\u00e7\u00e3o", "mais", "geral", "."], "sentence-detokenized": "As fun\u00e7\u00f5es sigmoid e derivados utilizados no pacote foram originalmente inclu\u00eddos no pacote, a partir da vers\u00e3o 0.8.0, estes foram lan\u00e7ados num pacote sigmoid R separado, com a inten\u00e7\u00e3o de permitir uma utiliza\u00e7\u00e3o mais geral.", "token2charspan": [[0, 2], [3, 10], [11, 18], [19, 20], [21, 30], [31, 41], [42, 44], [45, 51], [52, 57], [58, 71], [72, 81], [82, 84], [85, 91], [91, 92], [93, 94], [95, 101], [102, 104], [105, 111], [112, 117], [117, 118], [119, 124], [125, 130], [131, 139], [140, 143], [144, 150], [151, 158], [159, 160], [161, 169], [169, 170], [171, 174], [175, 176], [177, 185], [186, 188], [189, 197], [198, 201], [202, 212], [213, 217], [218, 223], [223, 224]]}
{"doc_key": "ai-train-71", "ner": [[0, 1, "programlang"], [7, 11, "organisation"], [13, 13, "organisation"], [21, 21, "location"], [23, 23, "location"], [26, 27, "researcher"], [29, 30, "researcher"], [33, 34, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 26, 27, "artifact", "", true, false], [0, 1, 29, 30, "artifact", "", true, false], [0, 1, 33, 34, "artifact", "", true, false], [13, 13, 7, 11, "named", "", false, false], [13, 13, 21, 21, "physical", "", false, false], [21, 21, 23, 23, "physical", "", false, false], [26, 27, 7, 11, "role", "", false, false], [29, 30, 7, 11, "role", "", false, false], [33, 34, 7, 11, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["O", "logotipo", "foi", "criado", "em", "1967", "em", "Bolt", ",", "Beranek", "e", "Newman", "(", "BBN", ")", ",", "uma", "empresa", "de", "investiga\u00e7\u00e3o", "de", "Cambridge", ",", "Massachusetts", ",", "por", "Wally", "Feurzeig", ",", "Cynthia", "Solomon", ",", "e", "Seymour", "Papert", "."], "sentence-detokenized": "O logotipo foi criado em 1967 em Bolt, Beranek e Newman (BBN), uma empresa de investiga\u00e7\u00e3o de Cambridge, Massachusetts, por Wally Feurzeig, Cynthia Solomon, e Seymour Papert.", "token2charspan": [[0, 1], [2, 10], [11, 14], [15, 21], [22, 24], [25, 29], [30, 32], [33, 37], [37, 38], [39, 46], [47, 48], [49, 55], [56, 57], [57, 60], [60, 61], [61, 62], [63, 66], [67, 74], [75, 77], [78, 90], [91, 93], [94, 103], [103, 104], [105, 118], [118, 119], [120, 123], [124, 129], [130, 138], [138, 139], [140, 147], [148, 155], [155, 156], [157, 158], [159, 166], [167, 173], [173, 174]]}
{"doc_key": "ai-train-72", "ner": [[0, 1, "misc"], [10, 12, "field"], [23, 24, "field"], [28, 29, "algorithm"], [31, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 10, 12, "part-of", "", false, false], [0, 1, 23, 24, "compare", "", false, false], [28, 29, 23, 24, "part-of", "", false, false], [31, 32, 23, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "neuroevolu\u00e7\u00e3o", "\u00e9", "normalmente", "utilizada", "como", "parte", "do", "paradigma", "de", "aprendizagem", "de", "refor\u00e7o", ",", "e", "pode", "ser", "contrastada", "com", "as", "t\u00e9cnicas", "convencionais", "de", "aprendizagem", "profunda", "que", "utilizam", "a", "descida", "gradual", "numa", "rede", "neural", "com", "uma", "topologia", "fixa", "."], "sentence-detokenized": "A neuroevolu\u00e7\u00e3o \u00e9 normalmente utilizada como parte do paradigma de aprendizagem de refor\u00e7o, e pode ser contrastada com as t\u00e9cnicas convencionais de aprendizagem profunda que utilizam a descida gradual numa rede neural com uma topologia fixa.", "token2charspan": [[0, 1], [2, 15], [16, 17], [18, 29], [30, 39], [40, 44], [45, 50], [51, 53], [54, 63], [64, 66], [67, 79], [80, 82], [83, 90], [90, 91], [92, 93], [94, 98], [99, 102], [103, 114], [115, 118], [119, 121], [122, 130], [131, 144], [145, 147], [148, 160], [161, 169], [170, 173], [174, 182], [183, 184], [185, 192], [193, 200], [201, 205], [206, 210], [211, 217], [218, 221], [222, 225], [226, 235], [236, 240], [240, 241]]}
{"doc_key": "ai-train-73", "ner": [[2, 3, "algorithm"], [52, 54, "metrics"], [56, 56, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[56, 56, 52, 54, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Se", "utilizarmos", "menos", "quadrados", "para", "caber", "uma", "fun\u00e7\u00e3o", "na", "forma", "de", "um", "hiperplano", "\u0177", "=", "a", "+", "\u03b2", "supT", "/", "sup", "x", "aos", "dados", "(", "x", "sub", "i", "/", "sub", ",", "y", "sub", "i", "/", "sub", ")", "sub", "1", "\u2264", "i", "\u2264n", "/", "sub", ",", "poder\u00edamos", "ent\u00e3o", "avaliar", "o", "ajuste", "usando", "o", "erro", "quadr\u00e1tico", "m\u00e9dio", "(", "MSE", ")", "."], "sentence-detokenized": "Se utilizarmos menos quadrados para caber uma fun\u00e7\u00e3o na forma de um hiperplano \u0177 = a + \u03b2 supT / sup x aos dados (x sub i / sub, y sub i / sub) sub 1 \u2264 i \u2264n / sub, poder\u00edamos ent\u00e3o avaliar o ajuste usando o erro quadr\u00e1tico m\u00e9dio (MSE).", "token2charspan": [[0, 2], [3, 14], [15, 20], [21, 30], [31, 35], [36, 41], [42, 45], [46, 52], [53, 55], [56, 61], [62, 64], [65, 67], [68, 78], [79, 80], [81, 82], [83, 84], [85, 86], [87, 88], [89, 93], [94, 95], [96, 99], [100, 101], [102, 105], [106, 111], [112, 113], [113, 114], [115, 118], [119, 120], [121, 122], [123, 126], [126, 127], [128, 129], [130, 133], [134, 135], [136, 137], [138, 141], [141, 142], [143, 146], [147, 148], [149, 150], [151, 152], [153, 155], [156, 157], [158, 161], [161, 162], [163, 173], [174, 179], [180, 187], [188, 189], [190, 196], [197, 203], [204, 205], [206, 210], [211, 221], [222, 227], [228, 229], [229, 232], [232, 233], [233, 234]]}
{"doc_key": "ai-train-74", "ner": [[6, 6, "country"], [8, 8, "country"], [10, 10, "country"], [12, 12, "country"], [14, 14, "country"], [16, 16, "country"], [18, 18, "country"], [20, 20, "country"], [22, 22, "country"], [24, 24, "country"], [26, 26, "country"], [28, 28, "country"], [30, 30, "country"], [32, 32, "country"], [34, 34, "country"], [36, 38, "country"], [40, 40, "country"], [42, 42, "country"], [44, 44, "country"], [46, 46, "country"], [48, 49, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "empresa", "tem", "localiza\u00e7\u00f5es", "internacionais", "na", "Austr\u00e1lia", ",", "Brasil", ",", "Canad\u00e1", ",", "China", ",", "Alemanha", ",", "\u00cdndia", ",", "It\u00e1lia", ",", "Jap\u00e3o", ",", "Coreia", ",", "Litu\u00e2nia", ",", "Pol\u00f3nia", ",", "Mal\u00e1sia", ",", "Filipinas", ",", "R\u00fassia", ",", "Singapura", ",", "\u00c1frica", "do", "Sul", ",", "Espanha", ",", "Taiwan", ",", "Tail\u00e2ndia", ",", "Turquia", "e", "Reino", "Unido", "."], "sentence-detokenized": "A empresa tem localiza\u00e7\u00f5es internacionais na Austr\u00e1lia, Brasil, Canad\u00e1, China, Alemanha, \u00cdndia, It\u00e1lia, Jap\u00e3o, Coreia, Litu\u00e2nia, Pol\u00f3nia, Mal\u00e1sia, Filipinas, R\u00fassia, Singapura, \u00c1frica do Sul, Espanha, Taiwan, Tail\u00e2ndia, Turquia e Reino Unido.", "token2charspan": [[0, 1], [2, 9], [10, 13], [14, 26], [27, 41], [42, 44], [45, 54], [54, 55], [56, 62], [62, 63], [64, 70], [70, 71], [72, 77], [77, 78], [79, 87], [87, 88], [89, 94], [94, 95], [96, 102], [102, 103], [104, 109], [109, 110], [111, 117], [117, 118], [119, 127], [127, 128], [129, 136], [136, 137], [138, 145], [145, 146], [147, 156], [156, 157], [158, 164], [164, 165], [166, 175], [175, 176], [177, 183], [184, 186], [187, 190], [190, 191], [192, 199], [199, 200], [201, 207], [207, 208], [209, 218], [218, 219], [220, 227], [228, 229], [230, 235], [236, 241], [241, 242]]}
{"doc_key": "ai-train-75", "ner": [[1, 1, "misc"], [3, 6, "field"], [11, 11, "organisation"], [14, 18, "university"], [25, 27, "organisation"], [29, 35, "university"], [40, 41, "university"], [43, 45, "university"], [47, 49, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[1, 1, 3, 6, "topic", "", false, false], [1, 1, 11, 11, "origin", "", false, false], [1, 1, 14, 18, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["\u00c9", "licenciado", "em", "engenharia", "el\u00e9ctrica", "e", "inform\u00e1tica", "(", "2000", ")", "pela", "Inria", "e", "pela", "Universidade", "de", "Nice", "Sophia", "Antipolis", ",", "e", "ocupou", "posi\u00e7\u00f5es", "permanentes", "na", "Siemens", "Corporate", "Technology", ",", "\u00c9cole", "des", "ponts", "ParisTech", ",", "bem", "como", "posi\u00e7\u00f5es", "de", "visita", "na", "Universidade", "Rutgers", ",", "Universidade", "de", "Yale", "e", "Universidade", "de", "Houston", "."], "sentence-detokenized": "\u00c9 licenciado em engenharia el\u00e9ctrica e inform\u00e1tica (2000) pela Inria e pela Universidade de Nice Sophia Antipolis, e ocupou posi\u00e7\u00f5es permanentes na Siemens Corporate Technology, \u00c9cole des ponts ParisTech, bem como posi\u00e7\u00f5es de visita na Universidade Rutgers, Universidade de Yale e Universidade de Houston.", "token2charspan": [[0, 1], [2, 12], [13, 15], [16, 26], [27, 36], [37, 38], [39, 50], [51, 52], [52, 56], [56, 57], [58, 62], [63, 68], [69, 70], [71, 75], [76, 88], [89, 91], [92, 96], [97, 103], [104, 113], [113, 114], [115, 116], [117, 123], [124, 132], [133, 144], [145, 147], [148, 155], [156, 165], [166, 176], [176, 177], [178, 183], [184, 187], [188, 193], [194, 203], [203, 204], [205, 208], [209, 213], [214, 222], [223, 225], [226, 232], [233, 235], [236, 248], [249, 256], [256, 257], [258, 270], [271, 273], [274, 278], [279, 280], [281, 293], [294, 296], [297, 304], [304, 305]]}
{"doc_key": "ai-train-76", "ner": [[7, 8, "researcher"], [11, 11, "researcher"], [15, 16, "product"], [18, 19, "country"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 11, 7, 8, "role", "licensing_patent_to", false, false], [11, 11, 18, 19, "physical", "", false, false], [22, 22, 11, 11, "artifact", "", false, false], [22, 22, 15, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Licenciando", "a", "patente", "original", "concedida", "ao", "inventor", "George", "Devol", ",", "a", "Engelberger", "desenvolveu", "o", "primeiro", "rob\u00f4", "industrial", "nos", "Estados", "Unidos", ",", "o", "Unimate", ",", "nos", "anos", "50", "."], "sentence-detokenized": "Licenciando a patente original concedida ao inventor George Devol, a Engelberger desenvolveu o primeiro rob\u00f4 industrial nos Estados Unidos, o Unimate, nos anos 50.", "token2charspan": [[0, 11], [12, 13], [14, 21], [22, 30], [31, 40], [41, 43], [44, 52], [53, 59], [60, 65], [65, 66], [67, 68], [69, 80], [81, 92], [93, 94], [95, 103], [104, 108], [109, 119], [120, 123], [124, 131], [132, 138], [138, 139], [140, 141], [142, 149], [149, 150], [151, 154], [155, 159], [160, 162], [162, 163]]}
{"doc_key": "ai-train-77", "ner": [[3, 5, "task"], [10, 12, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "entrada", "chama-se", "reconhecimento", "da", "fala", "e", "a", "sa\u00edda", "chama-se", "s\u00edntese", "da", "fala", "."], "sentence-detokenized": "A entrada chama-se reconhecimento da fala e a sa\u00edda chama-se s\u00edntese da fala.", "token2charspan": [[0, 1], [2, 9], [10, 18], [19, 33], [34, 36], [37, 41], [42, 43], [44, 45], [46, 51], [52, 60], [61, 68], [69, 71], [72, 76], [76, 77]]}
{"doc_key": "ai-train-78", "ner": [[4, 4, "programlang"], [6, 6, "programlang"], [13, 13, "programlang"], [16, 16, "programlang"], [27, 27, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 13, 13, "named", "", false, false], [6, 6, 4, 4, "origin", "descendant_of", false, false], [6, 6, 16, 16, "general-affiliation", "", false, false], [6, 6, 27, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Os", "descendentes", "da", "linguagem", "CLIPS", "incluem", "Jess", "(", "por\u00e7\u00e3o", "baseada", "em", "regras", "do", "CLIPS", "reescrita", "em", "Java", ",", "que", "mais", "tarde", "cresceu", "numa", "direc\u00e7\u00e3o", "diferente", ")", ",", "JESS", "foi", "originalmente", "inspirada"], "sentence-detokenized": "Os descendentes da linguagem CLIPS incluem Jess (por\u00e7\u00e3o baseada em regras do CLIPS reescrita em Java, que mais tarde cresceu numa direc\u00e7\u00e3o diferente), JESS foi originalmente inspirada", "token2charspan": [[0, 2], [3, 15], [16, 18], [19, 28], [29, 34], [35, 42], [43, 47], [48, 49], [49, 55], [56, 63], [64, 66], [67, 73], [74, 76], [77, 82], [83, 92], [93, 95], [96, 100], [100, 101], [102, 105], [106, 110], [111, 116], [117, 124], [125, 129], [130, 138], [139, 148], [148, 149], [149, 150], [151, 155], [156, 159], [160, 173], [174, 183]]}
{"doc_key": "ai-train-79", "ner": [[5, 5, "product"], [9, 13, "product"], [16, 17, "organisation"], [22, 23, "product"], [41, 43, "product"], [45, 48, "product"], [67, 69, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 13, 5, 5, "type-of", "", false, false], [16, 17, 9, 13, "usage", "", false, false], [22, 23, 16, 17, "artifact", "", false, false], [41, 43, 16, 17, "origin", "", true, false], [41, 43, 67, 69, "related-to", "", true, false], [45, 48, 16, 17, "origin", "", true, false], [45, 48, 67, 69, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Tamb\u00e9m", "criou", "aplica\u00e7\u00f5es", "flex\u00edveis", "inteligentes", "AGV", ",", "concebendo", "o", "sistema", "de", "controlo", "da", "motividade", "utilizado", "pela", "RMT", "Robotics", "para", "desenvolver", "o", "seu", "ADAM", "iAGV", "(", "Self-Guided", "Vehicle", ")", ",", "utilizado", "para", "opera\u00e7\u00f5es", "complexas", "de", "recolha", "e", "coloca\u00e7\u00e3o", ",", "em", "conjunto", "com", "sistemas", "de", "p\u00f3rtico", "e", "bra\u00e7os", "de", "rob\u00f4s", "industriais", ",", "utilizados", "em", "f\u00e1bricas", "de", "abastecimento", "autom\u00f3vel", "de", "primeira", "linha", "para", "mover", "produtos", "de", "processo", "para", "processo", "em", "layouts", "n\u00e3o", "lineares", "."], "sentence-detokenized": "Tamb\u00e9m criou aplica\u00e7\u00f5es flex\u00edveis inteligentes AGV, concebendo o sistema de controlo da motividade utilizado pela RMT Robotics para desenvolver o seu ADAM iAGV (Self-Guided Vehicle), utilizado para opera\u00e7\u00f5es complexas de recolha e coloca\u00e7\u00e3o, em conjunto com sistemas de p\u00f3rtico e bra\u00e7os de rob\u00f4s industriais, utilizados em f\u00e1bricas de abastecimento autom\u00f3vel de primeira linha para mover produtos de processo para processo em layouts n\u00e3o lineares.", "token2charspan": [[0, 6], [7, 12], [13, 23], [24, 33], [34, 46], [47, 50], [50, 51], [52, 62], [63, 64], [65, 72], [73, 75], [76, 84], [85, 87], [88, 98], [99, 108], [109, 113], [114, 117], [118, 126], [127, 131], [132, 143], [144, 145], [146, 149], [150, 154], [155, 159], [160, 161], [161, 172], [173, 180], [180, 181], [181, 182], [183, 192], [193, 197], [198, 207], [208, 217], [218, 220], [221, 228], [229, 230], [231, 240], [240, 241], [242, 244], [245, 253], [254, 257], [258, 266], [267, 269], [270, 277], [278, 279], [280, 286], [287, 289], [290, 295], [296, 307], [307, 308], [309, 319], [320, 322], [323, 331], [332, 334], [335, 348], [349, 358], [359, 361], [362, 370], [371, 376], [377, 381], [382, 387], [388, 396], [397, 399], [400, 408], [409, 413], [414, 422], [423, 425], [426, 433], [434, 437], [438, 446], [446, 447]]}
{"doc_key": "ai-train-80", "ner": [[7, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Os", "par\u00e2metros", "\u03b2", "s\u00e3o", "tipicamente", "estimados", "pela", "m\u00e1xima", "probabilidade", "."], "sentence-detokenized": "Os par\u00e2metros \u03b2 s\u00e3o tipicamente estimados pela m\u00e1xima probabilidade.", "token2charspan": [[0, 2], [3, 13], [14, 15], [16, 19], [20, 31], [32, 41], [42, 46], [47, 53], [54, 67], [67, 68]]}
{"doc_key": "ai-train-81", "ner": [[3, 8, "task"], [9, 9, "metrics"], [11, 11, "metrics"], [13, 13, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 3, 8, "part-of", "", false, false], [11, 11, 3, 8, "part-of", "", false, false], [13, 13, 3, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["As", "m\u00e9tricas", "de", "recupera\u00e7\u00e3o", "de", "informa\u00e7\u00e3o", ",", "tais", "como", "precis\u00e3o", "e", "recolha", "ou", "DCG", ",", "s\u00e3o", "\u00fateis", "para", "avaliar", "a", "qualidade", "de", "um", "m\u00e9todo", "de", "recomenda\u00e7\u00e3o", "."], "sentence-detokenized": "As m\u00e9tricas de recupera\u00e7\u00e3o de informa\u00e7\u00e3o, tais como precis\u00e3o e recolha ou DCG, s\u00e3o \u00fateis para avaliar a qualidade de um m\u00e9todo de recomenda\u00e7\u00e3o.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 29], [30, 40], [40, 41], [42, 46], [47, 51], [52, 60], [61, 62], [63, 70], [71, 73], [74, 77], [77, 78], [79, 82], [83, 88], [89, 93], [94, 101], [102, 103], [104, 113], [114, 116], [117, 119], [120, 126], [127, 129], [130, 142], [142, 143]]}
{"doc_key": "ai-train-82", "ner": [[6, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Uma", "f\u00e1brica", "t\u00edpica", "cont\u00e9m", "centenas", "de", "rob\u00f4s", "industriais", "que", "trabalham", "em", "linhas", "de", "produ\u00e7\u00e3o", "totalmente", "automatizadas", ",", "com", "um", "rob\u00f4", "para", "cada", "dez", "trabalhadores", "humanos", "."], "sentence-detokenized": "Uma f\u00e1brica t\u00edpica cont\u00e9m centenas de rob\u00f4s industriais que trabalham em linhas de produ\u00e7\u00e3o totalmente automatizadas, com um rob\u00f4 para cada dez trabalhadores humanos.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 25], [26, 34], [35, 37], [38, 43], [44, 55], [56, 59], [60, 69], [70, 72], [73, 79], [80, 82], [83, 91], [92, 102], [103, 116], [116, 117], [118, 121], [122, 124], [125, 129], [130, 134], [135, 139], [140, 143], [144, 157], [158, 165], [165, 166]]}
{"doc_key": "ai-train-83", "ner": [[5, 10, "product"], [15, 17, "field"], [21, 23, "task"], [25, 27, "task"], [29, 30, "task"], [32, 34, "task"], [36, 38, "task"], [41, 43, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[15, 17, 5, 10, "usage", "", false, true], [21, 23, 15, 17, "part-of", "", false, false], [25, 27, 15, 17, "part-of", "", false, false], [29, 30, 15, 17, "part-of", "", false, false], [32, 34, 15, 17, "part-of", "", false, false], [36, 38, 15, 17, "part-of", "", false, false], [41, 43, 15, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Durante", "a", "\u00faltima", "d\u00e9cada", ",", "os", "PCNN", "t\u00eam", "sido", "utilizados", "numa", "variedade", "de", "aplica\u00e7\u00f5es", "de", "processamento", "de", "imagem", ",", "incluindo", ":", "segmenta\u00e7\u00e3o", "de", "imagem", ",", "gera\u00e7\u00e3o", "de", "caracter\u00edsticas", ",", "extrac\u00e7\u00e3o", "facial", ",", "detec\u00e7\u00e3o", "de", "movimento", ",", "crescimento", "da", "regi\u00e3o", ",", "e", "redu\u00e7\u00e3o", "de", "ru\u00eddo", "."], "sentence-detokenized": "Durante a \u00faltima d\u00e9cada, os PCNN t\u00eam sido utilizados numa variedade de aplica\u00e7\u00f5es de processamento de imagem, incluindo: segmenta\u00e7\u00e3o de imagem, gera\u00e7\u00e3o de caracter\u00edsticas, extrac\u00e7\u00e3o facial, detec\u00e7\u00e3o de movimento, crescimento da regi\u00e3o, e redu\u00e7\u00e3o de ru\u00eddo.", "token2charspan": [[0, 7], [8, 9], [10, 16], [17, 23], [23, 24], [25, 27], [28, 32], [33, 36], [37, 41], [42, 52], [53, 57], [58, 67], [68, 70], [71, 81], [82, 84], [85, 98], [99, 101], [102, 108], [108, 109], [110, 119], [119, 120], [121, 132], [133, 135], [136, 142], [142, 143], [144, 151], [152, 154], [155, 170], [170, 171], [172, 181], [182, 188], [188, 189], [190, 198], [199, 201], [202, 211], [211, 212], [213, 224], [225, 227], [228, 234], [234, 235], [236, 237], [238, 245], [246, 248], [249, 254], [254, 255]]}
{"doc_key": "ai-train-84", "ner": [[0, 0, "researcher"], [15, 16, "field"], [20, 23, "misc"], [25, 31, "conference"], [33, 33, "conference"], [38, 41, "misc"], [43, 49, "conference"], [50, 51, "conference"], [53, 57, "conference"], [59, 59, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 0, 15, 16, "related-to", "contributes_to", false, false], [0, 0, 20, 23, "win-defeat", "", false, false], [0, 0, 38, 41, "win-defeat", "", false, false], [20, 23, 25, 31, "temporal", "", false, false], [33, 33, 25, 31, "named", "", false, false], [38, 41, 43, 49, "temporal", "", false, false], [38, 41, 53, 57, "temporal", "", false, false], [50, 51, 43, 49, "named", "", false, false], [59, 59, 53, 57, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Xu", "publicou", "mais", "de", "50", "artigos", "em", "confer\u00eancias", "internacionais", "e", "em", "revistas", "no", "campo", "da", "vis\u00e3o", "inform\u00e1tica", "e", "ganhou", "o", "pr\u00e9mio", "de", "melhor", "artigo", "na", "confer\u00eancia", "internacional", "sobre", "Renderiza\u00e7\u00e3o", "N\u00e3o-Photorealista", "e", "Anima\u00e7\u00e3o", "(", "NPAR", ")", "2012", "e", "o", "pr\u00e9mio", "de", "melhor", "revisor", "nas", "confer\u00eancias", "internacionais", "Asian", "Conference", "on", "Computer", "Vision", "ACCV", "2012", "e", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "2015", "."], "sentence-detokenized": "Xu publicou mais de 50 artigos em confer\u00eancias internacionais e em revistas no campo da vis\u00e3o inform\u00e1tica e ganhou o pr\u00e9mio de melhor artigo na confer\u00eancia internacional sobre Renderiza\u00e7\u00e3o N\u00e3o-Photorealista e Anima\u00e7\u00e3o (NPAR) 2012 e o pr\u00e9mio de melhor revisor nas confer\u00eancias internacionais Asian Conference on Computer Vision ACCV 2012 e International Conference on Computer Vision (ICCV) 2015.", "token2charspan": [[0, 2], [3, 11], [12, 16], [17, 19], [20, 22], [23, 30], [31, 33], [34, 46], [47, 61], [62, 63], [64, 66], [67, 75], [76, 78], [79, 84], [85, 87], [88, 93], [94, 105], [106, 107], [108, 114], [115, 116], [117, 123], [124, 126], [127, 133], [134, 140], [141, 143], [144, 155], [156, 169], [170, 175], [176, 188], [189, 206], [207, 208], [209, 217], [218, 219], [219, 223], [223, 224], [225, 229], [230, 231], [232, 233], [234, 240], [241, 243], [244, 250], [251, 258], [259, 262], [263, 275], [276, 290], [291, 296], [297, 307], [308, 310], [311, 319], [320, 326], [327, 331], [332, 336], [337, 338], [339, 352], [353, 363], [364, 366], [367, 375], [376, 382], [383, 384], [384, 388], [388, 389], [390, 394], [394, 395]]}
{"doc_key": "ai-train-85", "ner": [[0, 0, "programlang"], [2, 2, "field"], [4, 5, "field"], [8, 9, "misc"], [16, 17, "researcher"], [12, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 2, 2, "part-of", "", false, false], [0, 0, 4, 5, "part-of", "", false, false], [0, 0, 8, 9, "type-of", "", false, false], [12, 14, 0, 0, "usage", "", false, false], [12, 14, 16, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["CycL", "em", "inform\u00e1tica", "e", "intelig\u00eancia", "artificial", "\u00e9", "uma", "linguagem", "ontol\u00f3gica", "utilizada", "pelo", "projecto", "Cyc", "artificial", "de", "Doug", "Lenat", "."], "sentence-detokenized": "CycL em inform\u00e1tica e intelig\u00eancia artificial \u00e9 uma linguagem ontol\u00f3gica utilizada pelo projecto Cyc artificial de Doug Lenat.", "token2charspan": [[0, 4], [5, 7], [8, 19], [20, 21], [22, 34], [35, 45], [46, 47], [48, 51], [52, 61], [62, 72], [73, 82], [83, 87], [88, 96], [97, 100], [101, 111], [112, 114], [115, 119], [120, 125], [125, 126]]}
{"doc_key": "ai-train-86", "ner": [[2, 4, "task"], [7, 9, "metrics"], [15, 19, "metrics"], [21, 26, "metrics"], [34, 36, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 9, 2, 4, "part-of", "", false, false], [15, 19, 7, 9, "named", "", false, false], [21, 26, 7, 9, "named", "", false, false], [34, 36, 7, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Tamb\u00e9m", "na", "an\u00e1lise", "de", "regress\u00e3o", ",", "o", "erro", "quadr\u00e1tico", "m\u00e9dio", ",", "muitas", "vezes", "referido", "como", "erro", "de", "previs\u00e3o", "quadr\u00e1tico", "m\u00e9dio", "ou", "erro", "quadr\u00e1tico", "m\u00e9dio", "fora", "da", "amostra", ",", "pode", "referir-se", "ao", "valor", "m\u00e9dio", "dos", "desvios", "quadr\u00e1ticos", "das", "previs\u00f5es", "em", "rela\u00e7\u00e3o", "aos", "valores", "VERDADEIROS", ",", "sobre", "um", "espa\u00e7o", "de", "teste", "fora", "da", "amostra", ",", "gerado", "por", "um", "modelo", "estimado", "sobre", "um", "determinado", "espa\u00e7o", "de", "amostra", "."], "sentence-detokenized": "Tamb\u00e9m na an\u00e1lise de regress\u00e3o, o erro quadr\u00e1tico m\u00e9dio, muitas vezes referido como erro de previs\u00e3o quadr\u00e1tico m\u00e9dio ou erro quadr\u00e1tico m\u00e9dio fora da amostra, pode referir-se ao valor m\u00e9dio dos desvios quadr\u00e1ticos das previs\u00f5es em rela\u00e7\u00e3o aos valores VERDADEIROS, sobre um espa\u00e7o de teste fora da amostra, gerado por um modelo estimado sobre um determinado espa\u00e7o de amostra.", "token2charspan": [[0, 6], [7, 9], [10, 17], [18, 20], [21, 30], [30, 31], [32, 33], [34, 38], [39, 49], [50, 55], [55, 56], [57, 63], [64, 69], [70, 78], [79, 83], [84, 88], [89, 91], [92, 100], [101, 111], [112, 117], [118, 120], [121, 125], [126, 136], [137, 142], [143, 147], [148, 150], [151, 158], [158, 159], [160, 164], [165, 175], [176, 178], [179, 184], [185, 190], [191, 194], [195, 202], [203, 214], [215, 218], [219, 228], [229, 231], [232, 239], [240, 243], [244, 251], [252, 263], [263, 264], [265, 270], [271, 273], [274, 280], [281, 283], [284, 289], [290, 294], [295, 297], [298, 305], [305, 306], [307, 313], [314, 317], [318, 320], [321, 327], [328, 336], [337, 342], [343, 345], [346, 357], [358, 364], [365, 367], [368, 375], [375, 376]]}
{"doc_key": "ai-train-87", "ner": [[8, 8, "algorithm"], [10, 10, "algorithm"], [18, 19, "algorithm"], [30, 32, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 10, 10, "compare", "", false, false], [8, 8, 18, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Quanto", "aos", "resultados", ",", "os", "descritores", "de", "blocos", "C-HOG", "e", "R-HOG", "t\u00eam", "um", "desempenho", "compar\u00e1vel", ",", "mantendo", "os", "descritores", "C-HOG", "uma", "ligeira", "vantagem", "na", "taxa", "de", "faltas", "de", "detec\u00e7\u00e3o", "com", "taxas", "positivas", "FALSO", "fixas", "em", "ambos", "os", "conjuntos", "de", "dados", "."], "sentence-detokenized": "Quanto aos resultados, os descritores de blocos C-HOG e R-HOG t\u00eam um desempenho compar\u00e1vel, mantendo os descritores C-HOG uma ligeira vantagem na taxa de faltas de detec\u00e7\u00e3o com taxas positivas FALSO fixas em ambos os conjuntos de dados.", "token2charspan": [[0, 6], [7, 10], [11, 21], [21, 22], [23, 25], [26, 37], [38, 40], [41, 47], [48, 53], [54, 55], [56, 61], [62, 65], [66, 68], [69, 79], [80, 90], [90, 91], [92, 100], [101, 103], [104, 115], [116, 121], [122, 125], [126, 133], [134, 142], [143, 145], [146, 150], [151, 153], [154, 160], [161, 163], [164, 172], [173, 176], [177, 182], [183, 192], [193, 198], [199, 204], [205, 207], [208, 213], [214, 216], [217, 226], [227, 229], [230, 235], [235, 236]]}
{"doc_key": "ai-train-88", "ner": [[7, 10, "algorithm"], [12, 13, "misc"], [15, 17, "algorithm"], [19, 20, "algorithm"], [23, 25, "algorithm"], [28, 30, "algorithm"], [33, 35, "algorithm"], [37, 38, "misc"], [42, 45, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[7, 10, 12, 13, "usage", "", false, false], [15, 17, 37, 38, "usage", "", false, false], [19, 20, 37, 38, "usage", "", false, false], [23, 25, 37, 38, "usage", "", false, false], [28, 30, 37, 38, "usage", "", false, false], [33, 35, 37, 38, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Os", "algoritmos", "de", "reconhecimento", "populares", "incluem", "a", "an\u00e1lise", "de", "componentes", "principais", "utilizando", "superf\u00edcies", "pr\u00f3prias", ",", "an\u00e1lise", "linear", "discriminante", ",", "correspond\u00eancia", "el\u00e1stica", "utilizando", "o", "algoritmo", "de", "Fisherface", ",", "o", "modelo", "Markov", "oculto", ",", "a", "aprendizagem", "subespacial", "multilinear", "utilizando", "representa\u00e7\u00e3o", "tensorial", ",", "e", "a", "correspond\u00eancia", "din\u00e2mica", "de", "liga\u00e7\u00e3o", "neuronal", "motivada", "."], "sentence-detokenized": "Os algoritmos de reconhecimento populares incluem a an\u00e1lise de componentes principais utilizando superf\u00edcies pr\u00f3prias, an\u00e1lise linear discriminante, correspond\u00eancia el\u00e1stica utilizando o algoritmo de Fisherface, o modelo Markov oculto, a aprendizagem subespacial multilinear utilizando representa\u00e7\u00e3o tensorial, e a correspond\u00eancia din\u00e2mica de liga\u00e7\u00e3o neuronal motivada.", "token2charspan": [[0, 2], [3, 13], [14, 16], [17, 31], [32, 41], [42, 49], [50, 51], [52, 59], [60, 62], [63, 74], [75, 85], [86, 96], [97, 108], [109, 117], [117, 118], [119, 126], [127, 133], [134, 147], [147, 148], [149, 164], [165, 173], [174, 184], [185, 186], [187, 196], [197, 199], [200, 210], [210, 211], [212, 213], [214, 220], [221, 227], [228, 234], [234, 235], [236, 237], [238, 250], [251, 262], [263, 274], [275, 285], [286, 299], [300, 309], [309, 310], [311, 312], [313, 314], [315, 330], [331, 339], [340, 342], [343, 350], [351, 359], [360, 368], [368, 369]]}
{"doc_key": "ai-train-89", "ner": [[3, 10, "misc"], [19, 21, "location"], [37, 39, "location"], [52, 52, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[19, 21, 3, 10, "temporal", "", false, false], [37, 39, 3, 10, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "partir", "do", "Festival", "Internacional", "de", "Cinema", "de", "Toronto", "de", "2019", ",", "os", "filmes", "podem", "agora", "ser", "exibidos", "no", "Scotiabank", "Theatre", "Toronto", "-", "um", "dos", "principais", "locais", "do", "festival", "-", "e", "exibidos", "noutros", "locais", "(", "tais", "como", "TIFF", "Bell", "Lightbox", "e", "outros", "cinemas", "locais", ")", "se", "distribu\u00eddos", "por", "um", "servi\u00e7o", "como", "o", "Netflix", "."], "sentence-detokenized": "A partir do Festival Internacional de Cinema de Toronto de 2019, os filmes podem agora ser exibidos no Scotiabank Theatre Toronto - um dos principais locais do festival - e exibidos noutros locais (tais como TIFF Bell Lightbox e outros cinemas locais) se distribu\u00eddos por um servi\u00e7o como o Netflix.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 20], [21, 34], [35, 37], [38, 44], [45, 47], [48, 55], [56, 58], [59, 63], [63, 64], [65, 67], [68, 74], [75, 80], [81, 86], [87, 90], [91, 99], [100, 102], [103, 113], [114, 121], [122, 129], [130, 131], [132, 134], [135, 138], [139, 149], [150, 156], [157, 159], [160, 168], [169, 170], [171, 172], [173, 181], [182, 189], [190, 196], [197, 198], [198, 202], [203, 207], [208, 212], [213, 217], [218, 226], [227, 228], [229, 235], [236, 243], [244, 250], [250, 251], [252, 254], [255, 267], [268, 271], [272, 274], [275, 282], [283, 287], [288, 289], [290, 297], [297, 298]]}
{"doc_key": "ai-train-90", "ner": [[0, 1, "organisation"], [4, 5, "researcher"], [6, 7, "organisation"], [16, 16, "researcher"], [26, 30, "product"], [47, 47, "researcher"], [42, 46, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 6, 7, "related-to", "purchases", false, false], [4, 5, 16, 16, "named", "same", false, false], [4, 5, 47, 47, "named", "same", false, false], [6, 7, 4, 5, "origin", "founded_by", false, false], [26, 30, 0, 1, "artifact", "", false, false], [42, 46, 47, 47, "artifact", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["A", "Unimation", "adquiriu", "a", "Victor", "Scheinman's", "Vicarm", "Inc.", "em", "1977", ",", "e", "com", "a", "ajuda", "de", "Scheinman", ",", "a", "empresa", "criou", "e", "come\u00e7ou", "a", "produzir", "a", "Programmable", "Universal", "Machine", "for", "Assembly", ",", "um", "novo", "modelo", "de", "bra\u00e7o", "rob\u00f3tico", ",", "e", "utilizando", "a", "linguagem", "de", "programa\u00e7\u00e3o", "VAL", "de", "Scheinman", "de", "vanguarda", "."], "sentence-detokenized": "A Unimation adquiriu a Victor Scheinman's Vicarm Inc. em 1977, e com a ajuda de Scheinman, a empresa criou e come\u00e7ou a produzir a Programmable Universal Machine for Assembly, um novo modelo de bra\u00e7o rob\u00f3tico, e utilizando a linguagem de programa\u00e7\u00e3o VAL de Scheinman de vanguarda.", "token2charspan": [[0, 1], [2, 11], [12, 20], [21, 22], [23, 29], [30, 41], [42, 48], [49, 53], [54, 56], [57, 61], [61, 62], [63, 64], [65, 68], [69, 70], [71, 76], [77, 79], [80, 89], [89, 90], [91, 92], [93, 100], [101, 106], [107, 108], [109, 116], [117, 118], [119, 127], [128, 129], [130, 142], [143, 152], [153, 160], [161, 164], [165, 173], [173, 174], [175, 177], [178, 182], [183, 189], [190, 192], [193, 198], [199, 207], [207, 208], [209, 210], [211, 221], [222, 223], [224, 233], [234, 236], [237, 248], [249, 252], [253, 255], [256, 265], [266, 268], [269, 278], [278, 279]]}
{"doc_key": "ai-train-91", "ner": [[0, 0, "product"], [4, 5, "programlang"], [9, 11, "algorithm"], [12, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 5, "general-affiliation", "", false, false], [0, 0, 9, 11, "origin", "implementation_of", false, false], [0, 0, 12, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["J48", "\u00e9", "uma", "implementa\u00e7\u00e3o", "Java", "de", "c\u00f3digo", "aberto", "do", "algoritmo", "C4.5", "na", "ferramenta", "de", "minera\u00e7\u00e3o", "de", "dados", "Weka", "."], "sentence-detokenized": "J48 \u00e9 uma implementa\u00e7\u00e3o Java de c\u00f3digo aberto do algoritmo C4.5 na ferramenta de minera\u00e7\u00e3o de dados Weka.", "token2charspan": [[0, 3], [4, 5], [6, 9], [10, 23], [24, 28], [29, 31], [32, 38], [39, 45], [46, 48], [49, 58], [59, 63], [64, 66], [67, 77], [78, 80], [81, 90], [91, 93], [94, 99], [100, 104], [104, 105]]}
{"doc_key": "ai-train-92", "ner": [[2, 2, "metrics"], [14, 15, "product"], [21, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 14, 15, "win-defeat", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["O", "documento", "SSIM", "2004", "foi", "citado", "mais", "de", "20.000", "vezes", "de", "acordo", "com", "o", "Google", "Scholar", ",", "e", "recebeu", "tamb\u00e9m", "o", "IEEE", "Signal", "Processing", "Society", "Sustained", "Impact", "Award", "para", "2016", ",", "indicativo", "de", "um", "documento", "com", "um", "impacto", "invulgarmente", "elevado", "durante", "pelo", "menos", "10", "anos", "ap\u00f3s", "a", "sua", "publica\u00e7\u00e3o", "."], "sentence-detokenized": "O documento SSIM 2004 foi citado mais de 20.000 vezes de acordo com o Google Scholar, e recebeu tamb\u00e9m o IEEE Signal Processing Society Sustained Impact Award para 2016, indicativo de um documento com um impacto invulgarmente elevado durante pelo menos 10 anos ap\u00f3s a sua publica\u00e7\u00e3o.", "token2charspan": [[0, 1], [2, 11], [12, 16], [17, 21], [22, 25], [26, 32], [33, 37], [38, 40], [41, 47], [48, 53], [54, 56], [57, 63], [64, 67], [68, 69], [70, 76], [77, 84], [84, 85], [86, 87], [88, 95], [96, 102], [103, 104], [105, 109], [110, 116], [117, 127], [128, 135], [136, 145], [146, 152], [153, 158], [159, 163], [164, 168], [168, 169], [170, 180], [181, 183], [184, 186], [187, 196], [197, 200], [201, 203], [204, 211], [212, 225], [226, 233], [234, 241], [242, 246], [247, 252], [253, 255], [256, 260], [261, 265], [266, 267], [268, 271], [272, 282], [282, 283]]}
{"doc_key": "ai-train-93", "ner": [[1, 3, "task"], [31, 32, "product"], [41, 43, "product"], [46, 46, "organisation"], [47, 47, "product"], [52, 52, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 3, 46, 46, "artifact", "", false, false], [31, 32, 1, 3, "related-to", "performs", false, false], [31, 32, 41, 43, "part-of", "", false, false], [46, 46, 52, 52, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "s\u00edntese", "da", "fala", "est\u00e1", "\u00e0", "beira", "de", "ser", "completamente", "indistingu\u00edvel", "da", "voz", "de", "um", "verdadeiro", "ser", "humano", "com", "a", "introdu\u00e7\u00e3o", "em", "2016", "do", "software", "de", "edi\u00e7\u00e3o", "e", "gera\u00e7\u00e3o", "de", "voz", "Adobe", "Voco", ",", "um", "prot\u00f3tipo", "previsto", "para", "fazer", "parte", "do", "Adobe", "Creative", "Suite", "e", "do", "DeepMind", "WaveNet", ",", "um", "prot\u00f3tipo", "do", "Google", "."], "sentence-detokenized": "A s\u00edntese da fala est\u00e1 \u00e0 beira de ser completamente indistingu\u00edvel da voz de um verdadeiro ser humano com a introdu\u00e7\u00e3o em 2016 do software de edi\u00e7\u00e3o e gera\u00e7\u00e3o de voz Adobe Voco, um prot\u00f3tipo previsto para fazer parte do Adobe Creative Suite e do DeepMind WaveNet, um prot\u00f3tipo do Google.", "token2charspan": [[0, 1], [2, 9], [10, 12], [13, 17], [18, 22], [23, 24], [25, 30], [31, 33], [34, 37], [38, 51], [52, 66], [67, 69], [70, 73], [74, 76], [77, 79], [80, 90], [91, 94], [95, 101], [102, 105], [106, 107], [108, 118], [119, 121], [122, 126], [127, 129], [130, 138], [139, 141], [142, 148], [149, 150], [151, 158], [159, 161], [162, 165], [166, 171], [172, 176], [176, 177], [178, 180], [181, 190], [191, 199], [200, 204], [205, 210], [211, 216], [217, 219], [220, 225], [226, 234], [235, 240], [241, 242], [243, 245], [246, 254], [255, 262], [262, 263], [264, 266], [267, 276], [277, 279], [280, 286], [286, 287]]}
{"doc_key": "ai-train-94", "ner": [[0, 0, "researcher"], [5, 9, "organisation"], [13, 18, "organisation"], [23, 23, "conference"], [28, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 9, "role", "", false, false], [0, 0, 13, 18, "role", "", false, false], [0, 0, 23, 23, "role", "", false, false], [0, 0, 28, 32, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Poggio", "\u00e9", "membro", "honor\u00e1rio", "do", "Programa", "de", "Investiga\u00e7\u00e3o", "em", "Neuroci\u00eancia", ",", "membro", "da", "Academia", "Americana", "de", "Artes", "e", "Ci\u00eancias", "e", "membro", "fundador", "da", "AAAI", "e", "membro", "fundador", "do", "McGovern", "Institute", "for", "Brain", "Research", "."], "sentence-detokenized": "Poggio \u00e9 membro honor\u00e1rio do Programa de Investiga\u00e7\u00e3o em Neuroci\u00eancia, membro da Academia Americana de Artes e Ci\u00eancias e membro fundador da AAAI e membro fundador do McGovern Institute for Brain Research.", "token2charspan": [[0, 6], [7, 8], [9, 15], [16, 25], [26, 28], [29, 37], [38, 40], [41, 53], [54, 56], [57, 69], [69, 70], [71, 77], [78, 80], [81, 89], [90, 99], [100, 102], [103, 108], [109, 110], [111, 119], [120, 121], [122, 128], [129, 137], [138, 140], [141, 145], [146, 147], [148, 154], [155, 163], [164, 166], [167, 175], [176, 185], [186, 189], [190, 195], [196, 204], [204, 205]]}
{"doc_key": "ai-train-95", "ner": [[9, 9, "task"], [11, 13, "task"], [20, 22, "task"], [29, 29, "misc"], [27, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 9, 20, 22, "cause-effect", "", false, false], [11, 13, 20, 22, "cause-effect", "", false, false], [27, 28, 20, 22, "topic", "", false, false], [27, 28, 29, 29, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Durante", "os", "anos", "90", ",", "encorajados", "pelos", "sucessos", "no", "reconhecimento", "e", "s\u00edntese", "da", "fala", ",", "come\u00e7ou", "a", "investiga\u00e7\u00e3o", "sobre", "a", "tradu\u00e7\u00e3o", "da", "fala", "com", "o", "desenvolvimento", "do", "projecto", "Verbmobil", "alem\u00e3o", "."], "sentence-detokenized": "Durante os anos 90, encorajados pelos sucessos no reconhecimento e s\u00edntese da fala, come\u00e7ou a investiga\u00e7\u00e3o sobre a tradu\u00e7\u00e3o da fala com o desenvolvimento do projecto Verbmobil alem\u00e3o.", "token2charspan": [[0, 7], [8, 10], [11, 15], [16, 18], [18, 19], [20, 31], [32, 37], [38, 46], [47, 49], [50, 64], [65, 66], [67, 74], [75, 77], [78, 82], [82, 83], [84, 91], [92, 93], [94, 106], [107, 112], [113, 114], [115, 123], [124, 126], [127, 131], [132, 135], [136, 137], [138, 153], [154, 156], [157, 165], [166, 175], [176, 182], [182, 183]]}
{"doc_key": "ai-train-96", "ner": [[3, 4, "researcher"], [9, 10, "researcher"], [12, 13, "researcher"], [16, 18, "algorithm"], [22, 23, "algorithm"], [27, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 9, 10, "role", "", false, false], [16, 18, 3, 4, "origin", "", false, false], [16, 18, 9, 10, "origin", "", false, false], [16, 18, 12, 13, "origin", "", false, false], [16, 18, 27, 27, "part-of", "", false, false], [22, 23, 16, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Em", "1999", ",", "Felix", "Gers", "e", "o", "seu", "conselheiro", "J\u00fcrgen", "Schmidhuber", "e", "Fred", "Cummins", "introduziram", "o", "port\u00e3o", "do", "esquecimento", "(", "tamb\u00e9m", "chamado", "keep", "gate", ")", "na", "arquitectura", "LSTM", ","], "sentence-detokenized": "Em 1999, Felix Gers e o seu conselheiro J\u00fcrgen Schmidhuber e Fred Cummins introduziram o port\u00e3o do esquecimento (tamb\u00e9m chamado keep gate) na arquitectura LSTM,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 19], [20, 21], [22, 23], [24, 27], [28, 39], [40, 46], [47, 58], [59, 60], [61, 65], [66, 73], [74, 86], [87, 88], [89, 95], [96, 98], [99, 111], [112, 113], [113, 119], [120, 127], [128, 132], [133, 137], [137, 138], [139, 141], [142, 154], [155, 159], [159, 160]]}
{"doc_key": "ai-train-97", "ner": [[3, 6, "field"], [1, 9, "field"], [12, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 14, 3, 6, "part-of", "", false, false], [12, 14, 1, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Na", "teoria", "do", "processamento", "de", "sinais", "digitais", "e", "da", "informa\u00e7\u00e3o", ",", "a", "fun\u00e7\u00e3o", "sinc", "normalizada", "\u00e9", "normalmente", "definida", "por"], "sentence-detokenized": "Na teoria do processamento de sinais digitais e da informa\u00e7\u00e3o, a fun\u00e7\u00e3o sinc normalizada \u00e9 normalmente definida por", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 26], [27, 29], [30, 36], [37, 45], [46, 47], [48, 50], [51, 61], [61, 62], [63, 64], [65, 71], [72, 76], [77, 88], [89, 90], [91, 102], [103, 111], [112, 115]]}
{"doc_key": "ai-train-98", "ner": [[3, 4, "field"], [11, 12, "researcher"], [18, 21, "conference"], [24, 28, "organisation"], [30, 30, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 11, 12, "origin", "coined_term", false, false], [11, 12, 18, 21, "role", "", false, false], [11, 12, 24, 28, "role", "", false, false], [30, 30, 24, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["O", "pr\u00f3prio", "termo", "lingu\u00edstica", "computacional", "foi", "cunhado", "pela", "primeira", "vez", "por", "David", "Hays", ",", "membro", "fundador", "tanto", "da", "Associa\u00e7\u00e3o", "de", "Lingu\u00edstica", "Computacional", "como", "do", "Comit\u00e9", "Internacional", "de", "Lingu\u00edstica", "Computacional", "(", "ICCL", ")", "."], "sentence-detokenized": "O pr\u00f3prio termo lingu\u00edstica computacional foi cunhado pela primeira vez por David Hays, membro fundador tanto da Associa\u00e7\u00e3o de Lingu\u00edstica Computacional como do Comit\u00e9 Internacional de Lingu\u00edstica Computacional (ICCL).", "token2charspan": [[0, 1], [2, 9], [10, 15], [16, 27], [28, 41], [42, 45], [46, 53], [54, 58], [59, 67], [68, 71], [72, 75], [76, 81], [82, 86], [86, 87], [88, 94], [95, 103], [104, 109], [110, 112], [113, 123], [124, 126], [127, 138], [139, 152], [153, 157], [158, 160], [161, 167], [168, 181], [182, 184], [185, 196], [197, 210], [211, 212], [212, 216], [216, 217], [217, 218]]}
{"doc_key": "ai-train-99", "ner": [[10, 12, "misc"], [8, 9, "misc"], [33, 35, "metrics"], [37, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[37, 37, 33, 35, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["59", ",", "pp.", "2547-2553", ",", "Out.", "2011", "Em", "DPD", "de", "mem\u00f3ria", "polinomial", "unidimensional", "(", "ou", "sem", "mem\u00f3ria", ")", ",", "a", "fim", "de", "resolver", "para", "os", "coeficientes", "polinomiais", "do", "pr\u00e9-distorcedor", "digital", "e", "minimizar", "o", "erro", "quadr\u00e1tico", "m\u00e9dio", "(", "MSE", ")", ",", "a", "sa\u00edda", "distorcida", "do", "sistema", "n\u00e3o", "linear", "deve", "ser", "sobreamostragem", "a", "uma", "taxa", "que", "permita", "a", "captura", "dos", "produtos", "n\u00e3o", "lineares", "da", "ordem", "do", "pr\u00e9-distorcedor", "digital", "."], "sentence-detokenized": "59, pp. 2547-2553, Out. 2011 Em DPD de mem\u00f3ria polinomial unidimensional (ou sem mem\u00f3ria), a fim de resolver para os coeficientes polinomiais do pr\u00e9-distorcedor digital e minimizar o erro quadr\u00e1tico m\u00e9dio (MSE), a sa\u00edda distorcida do sistema n\u00e3o linear deve ser sobreamostragem a uma taxa que permita a captura dos produtos n\u00e3o lineares da ordem do pr\u00e9-distorcedor digital.", "token2charspan": [[0, 2], [2, 3], [4, 7], [8, 17], [17, 18], [19, 23], [24, 28], [29, 31], [32, 35], [36, 38], [39, 46], [47, 57], [58, 72], [73, 74], [74, 76], [77, 80], [81, 88], [88, 89], [89, 90], [91, 92], [93, 96], [97, 99], [100, 108], [109, 113], [114, 116], [117, 129], [130, 141], [142, 144], [145, 160], [161, 168], [169, 170], [171, 180], [181, 182], [183, 187], [188, 198], [199, 204], [205, 206], [206, 209], [209, 210], [210, 211], [212, 213], [214, 219], [220, 230], [231, 233], [234, 241], [242, 245], [246, 252], [253, 257], [258, 261], [262, 277], [278, 279], [280, 283], [284, 288], [289, 292], [293, 300], [301, 302], [303, 310], [311, 314], [315, 323], [324, 327], [328, 336], [337, 339], [340, 345], [346, 348], [349, 364], [365, 372], [372, 373]]}
{"doc_key": "ai-train-100", "ner": [[0, 1, "researcher"], [14, 15, "location"], [17, 18, "country"], [24, 24, "country"], [40, 46, "organisation"], [48, 51, "organisation"], [53, 53, "location"], [57, 58, "organisation"]], "ner_mapping_to_source": [0, 2, 3, 5, 6, 7, 8, 9], "relations": [[0, 1, 48, 51, "physical", "", false, false], [0, 1, 57, 58, "role", "", false, false], [14, 15, 17, 18, "physical", "", false, false], [40, 46, 48, 51, "part-of", "", false, false], [48, 51, 53, 53, "physical", "", false, false], [57, 58, 40, 46, "part-of", "", false, false]], "relations_mapping_to_source": [1, 2, 4, 5, 6, 7], "sentence": ["Boris", "Katz", ",", "(", "nascido", "a", "5", "de", "Outubro", "de", "1947", ",", "Chi\u0219in\u0103u", ",", "Moldavo", "SSR", ",", "Uni\u00e3o", "Sovi\u00e9tica", ",", "(", "agora", "Chi\u0219in\u0103u", ",", "Mold\u00e1via", ")", ")", "\u00e9", "um", "dos", "principais", "cientistas", "de", "investiga\u00e7\u00e3o", "americanos", "(", "cientista", "inform\u00e1tico", ")", "no", "MIT", "Computer", "Science", "and", "Artificial", "Intelligence", "Laboratory", "do", "Massachusetts", "Institute", "of", "Technology", "em", "Cambridge", "e", "chefe", "do", "Grupo", "InfoLab", "do", "Laborat\u00f3rio", "."], "sentence-detokenized": "Boris Katz, (nascido a 5 de Outubro de 1947, Chi\u0219in\u0103u, Moldavo SSR, Uni\u00e3o Sovi\u00e9tica, (agora Chi\u0219in\u0103u, Mold\u00e1via)) \u00e9 um dos principais cientistas de investiga\u00e7\u00e3o americanos (cientista inform\u00e1tico) no MIT Computer Science and Artificial Intelligence Laboratory do Massachusetts Institute of Technology em Cambridge e chefe do Grupo InfoLab do Laborat\u00f3rio.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 13], [13, 20], [21, 22], [23, 24], [25, 27], [28, 35], [36, 38], [39, 43], [43, 44], [45, 53], [53, 54], [55, 62], [63, 66], [66, 67], [68, 73], [74, 83], [83, 84], [85, 86], [86, 91], [92, 100], [100, 101], [102, 110], [110, 111], [111, 112], [113, 114], [115, 117], [118, 121], [122, 132], [133, 143], [144, 146], [147, 159], [160, 170], [171, 172], [172, 181], [182, 193], [193, 194], [195, 197], [198, 201], [202, 210], [211, 218], [219, 222], [223, 233], [234, 246], [247, 257], [258, 260], [261, 274], [275, 284], [285, 287], [288, 298], [299, 301], [302, 311], [312, 313], [314, 319], [320, 322], [323, 328], [329, 336], [337, 339], [340, 351], [351, 352]]}
